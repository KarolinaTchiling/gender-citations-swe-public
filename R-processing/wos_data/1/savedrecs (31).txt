FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Zhu, YJ
   Mei, M
   Zheng, ZT
AF Zhu, Yujun
   Mei, Meng
   Zheng, Zetian
TI Scheduling algorithms for K-barrier coverage to improve transmission
   efficiency in WSNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor networks; K-barrier coverage; Sink-connected; Forwarding
   routing tree; Multi-channel scheduling
AB K-barrier coverage optimization problem is concentrating on how to select sensor nodes from the monitoring area of the wireless sensor networks (WSNs) to form the highest quality of k-barrier coverage. Sink-connected barrier coverage optimization problem (SCBCOP) focuses on how to choose the minimum number of forwarding nodes to make each detecting node sink-connected for the security requirements of the belt monitoring region. However, the existing algorithm, such as optimal node selection algorithm(ONSA), can find the optimized k-barrier coverage of sink-connected, but it may form a large number of data packets interference (or collisions) and cannot transfer the information to sink nodes in time because the different detecting nodes can transmit invasive information at the same time. The purpose of this paper is to discuss how to reduce interference among the nodes and select routing path to optimize k-barrier coverage and satisfy sink-connected. In this paper a scheduling algorithm is proposed to build the routing path and maintain sink-connected. The algorithms is present in detail through forwarding routing tree and multi-channel scheduling to further reduce the interference of packet transmission among sensor nodes. Moreover, the comparison between other approaches and our proposal is mentioned through the simulation to show the potential efficiency and better performance of interference of packet transmission among sensor nodes with the lower packet loss rate, the shorter packet delay and the larger network average throughput.
C1 [Zhu, Yujun; Zheng, Zetian] Anhui Normal Univ, Sch Comp & Informat, Wuhu 241002, Peoples R China.
   [Mei, Meng] Tongji Univ, Sch Elect & Informat Engn, Shanghai 201804, Peoples R China.
C3 Anhui Normal University; Tongji University
RP Mei, M (corresponding author), Tongji Univ, Sch Elect & Informat Engn, Shanghai 201804, Peoples R China.
EM meimeng_tju@163.com
RI wang, David/KFR-2555-2024; Zhu, Yu/O-6933-2014
CR Bhatia A, 2014, IEEE INT CONF DISTR, P294, DOI 10.1109/DCOSS.2014.44
   Elsts A, 2017, LOC COMP NETW WORKSH
   Fujimoto M, 2013, IEICE T COMMUN, VE96B, P3007, DOI 10.1587/transcom.E96.B.3007
   Ghosal A, 2012, WIREL NETW, V18, P165, DOI 10.1007/s11276-011-0393-0
   Hadi A, 2017, INT C CONTR EL REN E, P192, DOI DOI 10.1109/ICCEREC.2016.7814975
   Haghighi MS, 2015, IEEE T COMPUT, V64, P627, DOI 10.1109/TC.2013.2296773
   Huynh TT, 2014, INT C ADV TECHN COMM, P439
   Luo J, 2016, WIREL NETW, P1
   Mehrjoo S., 2010, 2010 5th International Symposium on Telecommunications (IST), P415, DOI 10.1109/ISTEL.2010.5734062
   Ren XJ, 2015, IEEE T COMPUT, V64, P1870, DOI 10.1109/TC.2014.2349521
   Santoso F, 2010, IET COMMUN, V4, P2041, DOI 10.1049/iet-com.2010.0112
   Shimada N, 2016, HLTH SERV RES 2, V42, P577
   Wang ZB, 2017, AD HOC NETW, V64, P65, DOI 10.1016/j.adhoc.2017.06.004
   Yamamoto N, 2011, IEEE INT C INTELL TR, P50, DOI 10.1109/ITSC.2011.6083001
   Yoo SE, 2010, IEEE T IND ELECTRON, V57, P3868, DOI 10.1109/TIE.2010.2040630
   Zhang YH, 2016, CHINA COMMUN, V13, P16, DOI 10.1109/CC.2016.7559071
   Zhuang Y, 2016, SENSORS, V17, P1
NR 17
TC 5
Z9 6
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10505
EP 10518
DI 10.1007/s11042-019-7316-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600042
DA 2024-07-18
ER

PT J
AU Aslam, S
   Ahmed, M
   Ahmed, I
   Khan, A
   Ahmad, A
   Imran, M
   Anjum, A
   Hussain, S
AF Aslam, Sidra
   Ahmed, Mansoor
   Ahmed, Imran
   Khan, Abid
   Ahmad, Awais
   Imran, Muhammad
   Anjum, Adeel
   Hussain, Shahid
TI OBAC: towards agent-based identification and classification of roles,
   objects, permissions (ROP) in distributed environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic Web; Ontology; Agent; Role-Based Access Control; Role; Objects;
   Permissions; Access Control; Distributed Systems
ID OPTIMIZATION; INTERNET
AB Access control is used to prevent data from access of unauthorized users. Over the years, several access control models have been proposed to meet requirements of various applications and domains. Role-based access control model is one such model which enforces security based on the roles. However, role-based access control model is static in nature and does not provide the dynamism of collaboration required in the multi-domain environment. This paper presents an Ontology-Based Access Control (OBAC) model, which provides a solution by using an ontology-based approach. In OBAC model, agents are used for the identification and classification of Roles, Objects and Permissions (ROP) in distributed environment. The proposed method exploits the ontology-based approach, where agent learns and adapts changes to identify roles, objects and permissions from a given dataset and classify them into ontology according to rules and policies. The proposed ontology also provides extensibility and reusability. Moreover, we simulated our technique on datasets of two different domains. The first dataset is related to the university environment and the second one is about hospital domain. The promising experimental results indicates the effectiveness of proposed approach.
C1 [Aslam, Sidra; Ahmed, Mansoor; Khan, Abid; Imran, Muhammad; Anjum, Adeel; Hussain, Shahid] COMSATS Univ, Dept Comp Sci, Pk Rd, Islamabad, Pakistan.
   [Ahmed, Imran; Ahmad, Awais] Inst Management Sci, Ctr Excellence Informat Technol, Peshawar, Pakistan.
   [Ahmed, Imran; Ahmad, Awais] Univ Milan, Dipartimento Informat, Milan, Italy.
C3 COMSATS University Islamabad (CUI); University of Milan
RP Ahmad, A (corresponding author), Inst Management Sci, Ctr Excellence Informat Technol, Peshawar, Pakistan.; Ahmad, A (corresponding author), Univ Milan, Dipartimento Informat, Milan, Italy.
EM sidra.cps@gmail.com; mansoor@comsats.edu.pk;
   imran.ahmed@imsciences.edu.pk; abidkhan@comsats.edu.pk;
   aahmad.marwat@gmail.com; mimran@comsats.edu.pk;
   adeel.anjum@comsats.edu.pk; shussain@comsats.edu.pk
RI Ahmed, Imran/HDL-7255-2022; Anjum, Adeel/L-4391-2013; Hussain,
   Shahid/AAP-5065-2021; Imran, Muhammad/M-9992-2013; Ahmed,
   Mansoor/IVU-8924-2023
OI Anjum, Adeel/0000-0001-5083-0019; Hussain, Shahid/0000-0003-4826-3339;
   Imran, Muhammad/0000-0003-1795-1040; Ahmed, Mansoor/0000-0003-2034-1403;
   Ahmad, Ph.D, Awais/0000-0001-5483-2732; Khan, Abid/0000-0003-2712-1956
CR Ahmad A, 2019, FUTURE GENER COMP SY, V92, P868, DOI 10.1016/j.future.2017.12.027
   Ahmad A, 2018, FUTURE GENER COMP SY, V82, P715, DOI 10.1016/j.future.2017.09.028
   Ahmad A, 2016, FUTURE GENER COMP SY, V56, P493, DOI 10.1016/j.future.2015.08.004
   Ahmad A, 2016, NEUROCOMPUTING, V174, P439, DOI 10.1016/j.neucom.2015.04.109
   Anisetti Marco, 2013, 2013 IEEE 20th International Conference on Web Services (ICWS), P475, DOI 10.1109/ICWS.2013.70
   Anisetti M., 2011, 2011 Proceedings of IEEE International Conference on Services Computing (SCC 2011), P456, DOI 10.1109/SCC.2011.27
   Anisetti M, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2014), P35, DOI 10.1109/SCC.2014.14
   [Anonymous], [No title captured]
   [Anonymous], 2016, SEMANTIC WEB IMPLICA
   [Anonymous], 2015, INDIAN J SCI TECHNOL
   Arshad H, 2018, INT J ADV COMPUT SC, V9, P191
   Balakrishnan SM, 2017, FUTURE GENER COMP SY, V74, P349, DOI 10.1016/j.future.2016.08.006
   Belchior Mairon, 2012, Web Engineering. Proceedings 12th International Conference, ICWE 2012, P106, DOI 10.1007/978-3-642-31753-8_8
   Charanya R, 2016, INDIAN J SCI TECHNOL, V9
   De Giacomo Giuseppe, 2018, A Comprehensive Guide Through the Italian Database Research Over the Last 25 Years, P187, DOI [DOI 10.1007/978-3-319-61893-711, 10.1007/978-3-319-61893-711]
   Heilili N, 2006, LECT NOTES COMPUT SC, V4092, P164
   Hussain M., 2018, J SUPERCOMPUT, P1
   Katal A, 2013, 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2013), P439, DOI 10.1109/ISCO.2013.6481195
   Kozaki Kouji, 2012, Knowledge Engineering and Knowledge Management. 18th International Conference, EKAW 2012. Proceedings, P227, DOI 10.1007/978-3-642-33876-2_21
   Kozaki K, 2006, P EON2006 ED UK
   Medhane DV, 2018, IEEE TETCI, V2, P194, DOI 10.1109/TETCI.2017.2769110
   Medhane DV, 2017, COMPUT ELECTR ENG, V58, P126, DOI 10.1016/j.compeleceng.2017.01.025
   Mivule K., 2013, 5 INT C ADV COGNITIV, P14
   Moulik S, 2015, IEEE I C ADV NETW TE
   Mouliswaran SC, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2027, DOI 10.1109/ICACCI.2015.7275915
   Ni Q, 2007, 2007 ACM SACMAT
   Qiu Jiong, 2011, 2011 International Conference on Electrical and Control Engineering, P5845, DOI 10.1109/ICECENG.2011.6057207
   Raje S., 2012, Proceedings of the 27th Annual ACM Symposium on Applied Computing, P763
   Rathore MM, 2016, IEEE GLOB COMM CONF
   Sahafizadeh E, 2010, 2010 2 INT C FUT COM
   Vishwasrao MD, 2017, IEEE T SUST COMPUT, V2, P49, DOI 10.1109/TSUSC.2017.2690378
   Wei-Tek Tsai, 2011, 2011 Tenth International Symposium on Autonomous Decentralized Systems (ISADS), P121, DOI 10.1109/ISADS.2011.21
   Zhenwu Wang, 2013, Journal of Networks, V8, P723, DOI 10.4304/jnw.8.3.723-730
NR 33
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34363
EP 34384
DI 10.1007/s11042-020-08764-2
EA MAR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000520701600001
DA 2024-07-18
ER

PT J
AU Ivan, A
   Park, IK
AF Ivan, Andre
   Park, In Kyu
TI A flexible and configurable GPGPU stereo matching framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo matching; Depth estimation; GPGPU; Cross-platform
ID OPTIMIZATION
AB This paper presents a practical framework that consists of various local to global stereo matching algorithms on a general purpose computing on graphics processing units platform. The flexible framework provides users with a selection of individual sub-algorithms in each step of stereo matching. The framework runs on either a central processing unit or graphic processing unit across three different platforms, including a smartphone, embedded board, and desktop. On the basis of the proposed framework, we investigate different combinations of stereo matching algorithms for specific use cases. Accordingly, we provide the framework's quantitative speed and accuracy analysis evaluated on the widely used stereo dataset. In addition, this paper also addresses the parallelization strategy on an embedded graphics processing unit. The experimental results show that the proposed framework is capable of real-time and accurate depth estimation of stereo input in video graphics array resolution on an embedded graphics processing unit.
C1 [Ivan, Andre; Park, In Kyu] Inha Univ, Dept Informat & Commun Engn, Incheon 22212, South Korea.
C3 Inha University
RP Park, IK (corresponding author), Inha Univ, Dept Informat & Commun Engn, Incheon 22212, South Korea.
EM andreivan13@gmail.com; pik@inha.ac.kr
RI Park, In Kyu/B-5967-2013
OI Park, In Kyu/0000-0003-4774-7841
FU Institute for Information AMP; communications Technology PlanningAMP;
   Evaluation(IITP) - Korea government(MSIT) [2017-0-00142]; Inha
   University Research Grant
FX This work was supported by Institute for Information & communications
   Technology Planning& Evaluation(IITP) grant funded by the Korea
   government(MSIT) (2017-0-00142). This work was supported by Inha
   University Research Grant.
CR [Anonymous], 2014, ACM T GRAPHIC, DOI DOI 10.1145/2601097.2601165
   [Anonymous], 2011, RGB-D Workshop on 3D Perception in Robotics at the European Robotics Forum
   [Anonymous], 2011, Nvidia Corporation
   Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Choi YK, 2012, P SIGN INF PROC ASS, P1
   Choi YK, 2013, IEEE COMPUT SOC CONF, P642, DOI 10.1109/CVPRW.2013.97
   COCHRAN SD, 1992, IEEE T PATTERN ANAL, V14, P981, DOI 10.1109/34.159902
   Hedman P, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201384
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hosni A, 2011, IEEE INT CON MULTI, DOI 10.1109/ICME.2011.6012131
   Hosni A, 2013, COMPUT VIS IMAGE UND, V117, P620, DOI 10.1016/j.cviu.2013.01.007
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hsu GS, 2014, IEEE T INF FOREN SEC, V9, P2110, DOI 10.1109/TIFS.2014.2361028
   Ivan A, 2018, P IEEE C COMP VIS PA, P634
   Kowalczuk J, 2013, IEEE T CIRC SYST VID, V23, P94, DOI 10.1109/TCSVT.2012.2203200
   Ma ZY, 2013, IEEE I CONF COMP VIS, P49, DOI 10.1109/ICCV.2013.13
   Meier Lorenz, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P5638, DOI 10.1109/ICRA.2017.7989662
   Mühlmann K, 2002, INT J COMPUT VISION, V47, P79, DOI 10.1023/A:1014581421794
   Park IK, 2011, IEEE T PARALL DISTR, V22, P91, DOI 10.1109/TPDS.2010.115
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Seiller N, 2014, MULTIMED TOOLS APPL, V70, P2347, DOI 10.1007/s11042-013-1440-x
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Williem, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.4.043110
   Williem IA, 2017, P PAC RIM C MULT, P928
   Yang Q., 2006, P 17 BRIT MACHINE VI, P989
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2016, J SUPERCOMPUT, V72, P2394, DOI 10.1007/s11227-016-1738-3
NR 34
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18367
EP 18386
DI 10.1007/s11042-020-08756-2
EA MAR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000518068900005
DA 2024-07-18
ER

PT J
AU Idrees, B
   Zafar, S
   Rashid, T
   Gao, W
AF Idrees, Bazgha
   Zafar, Sohail
   Rashid, Tabasam
   Gao, W.
TI Image encryption algorithm using S-box and dynamic Henon bit level
   permutation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; S-box; Bit-permutation; Henon map
ID CHAOS
AB For the secure transmission of data through the medium of internet, images have significant importance. Image encryption provides secure transmission of images by converting recognizable form of image into an unrecognizable form. Chaos is considered as a natural required ingredient for cryptography applications, by providing unpredictability, sensitivity of initial state and erogodicity. Therefore from the last decade, a number of chaos-based cryptosystems have been developed for the protection of transmitted images' content. In this paper, a chaos based algorithm is developed and experimented on six different standard empirical images. The proposed cryptosystem is based on substitution-permutation network (SPN) with cipher block chaining (CBC) mode of operation. A novel algorithm is proposed for the construction of substitution box by using chaotic sine map, which is applied on a block-input of bytes, followed by a permutation based on discretized Henon map, which is applied on a block-input of bits instead of bytes. The hyper chaotic Lu system, which is nonlinear and produces discrete values with long orbits, is used as pseudorandom generator to set new values to control parameters of discretized Henon map for bit-permutation for each block. Moreover, proposed bit-permutation is applied by a matrix formulation which accelerates the bit permutation process for a block-input. Security analysis and results obtained from simulations show that cryptosystem is good resistant to various well-known attacks and have good key space therefore is reliable for secure transmission of images.
C1 [Idrees, Bazgha; Zafar, Sohail; Rashid, Tabasam] Univ Management & Technol, Dept Math, Lahore 54770, Pakistan.
   [Gao, W.] Normal Univ, Sch Informat Sci & Technol, Kunming 650092, Yunnan, Peoples R China.
C3 University of Management & Technology (UMT)
RP Zafar, S (corresponding author), Univ Management & Technol, Dept Math, Lahore 54770, Pakistan.
EM ms.bazgha@gmail.com; sohailahmad04@gmail.com; tabasam.rashid@umt.edu.pk;
   gaowei@ynnu.edu.cn
RI Rashid, Tabasam/C-4855-2015
OI Rashid, Tabasam/0000-0002-8691-1088; IDREES, BAZGHA/0000-0002-3357-8269
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2008, INT J MATH COMPUTATI, DOI DOI 10.5281/ZENODO.1072660
   [Anonymous], 1999, AES PROPOSAL RIJNDAE
   Assad SE, 2014, 10 INT C COMM COMM B, DOI [10.1109/ICComm.2014.6866768, DOI 10.1109/ICCOMM.2014.6866768]
   Bashir Zia, 2016, Pacific Science Review A: Natural Science and Engineering, V18, P254, DOI 10.1016/j.psra.2016.11.003
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Bouyukliev I., 2017, ELECT NOTES DISCRETE, V57, P67, DOI DOI 10.1016/J.ENDM.2017.02.012
   Brickell E. F., 1987, C THEOR APPL CRYPT T, V263, DOI [10.1007/3-540-47721-7_1, DOI 10.1007/3-540-47721-7_1]
   Cui LG, 2007, INT J INNOV COMPUT I, V3, P751
   Daemen J, 1999, DESIGN RIJNDAEL AEST, DOI 10.1.1.36.640
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Hamidouche W, 2015, IEEE 40 INT C AC SPE
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jiayong Tang, 2017, International Journal of High Performance Computing and Networking, V10, P515
   Jizhong Wang, 2018, International Journal of High Performance Computing and Networking, V12, P111
   Karaahmetoglu O, 2013, INFORM PROCESS LETT, V113, P229, DOI 10.1016/j.ipl.2013.01.002
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Kwon D, 2004, LECT NOTES COMPUT SC, V2971, P432
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   LIU L, 2016, MULTIMED TOOLS APPL, V76, P16511
   Liu L, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2374-3
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Mamadolimov A, 2009, 5 AS MATH C AMC PUTR
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Peng F, 2013, IEEE T INF FOREN SEC, V8, P1688, DOI 10.1109/TIFS.2013.2259819
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Rakesh S., 2012, IJCIS, V2, P49
   Rivest R.L., 1998, RC6 BLOCK CIPHER, V1
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Seberry J., 1993, 1 ACM C COMP COMM SE
   Seberry J, 1993, LNCS, P49, DOI [10.1007/3-540-48329-2_5, DOI 10.1007/3-540-48329-2_5]
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Tang Y, 2010, COMMUN NONLINEAR SCI, V15, P2456, DOI 10.1016/j.cnsns.2009.09.023
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Tong XJ, 2015, ENTROPY-SWITZ, V17, P181, DOI 10.3390/e17010181
   Vergili I., 2001, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V9, P137
   Volos CK, 2013, SIGNAL PROCESS, V93, P1328, DOI 10.1016/j.sigpro.2012.11.008
   Wang XY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030503
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Webster AF, 1970, LNCS, P523, DOI [10.1007/3-540-39799-X_41, DOI 10.1007/3-540-39799-X_4]
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Yang YG, 2015, SCI REP-UK, V5, DOI 10.1038/srep07784
   Yen JC, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL IV, PROCEEDINGS, P121
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang J., 2019, International Journal of High Performance Computing and Networking, V13, P321, DOI 10.1504/IJHPCN.2019.098573
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 62
TC 41
Z9 41
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6135
EP 6162
DI 10.1007/s11042-019-08282-w
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900032
DA 2024-07-18
ER

PT J
AU Kharat, J
   Chougule, S
AF Kharat, Jayashree
   Chougule, Sangeeta
TI A passive blind forgery detection technique to identify frame
   duplication attack
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Passive blind forgery; Frame duplication attack; SIFT; RANSAC
ID VIDEO FORGERY; LOCALIZATION
AB This paper presents passive blind forgery detection to identify frame duplication attack in Moving Picture Experts Group-4 (MPEG-4) video. In this attack, one or more frames are copied and pasted at other location in the same video to hide or highlight particular activity. Since the tampered frames are from the same video, their statistical properties are uniform, which makes challenging to identify duplicate frames. In this paper, a two-step algorithm is proposed, in which the suspicious frames are identified, their features are extracted and compared with other frames of the test video to take the decision. Scale Invariant Feature Transform (SIFT) key-points are used as feature for comparison. Finally, Random Sample Consensus algorithm is used to locate duplicate frames. The proposed method is tested on compressed and uncompressed videos with variable compression rate. The simulation results show that the proposed scheme is competent to detect the tampered frames with 99.8% average accuracy. Comparative analysis is made for the proposed method with existing methods with respect to parameters Precision Rate (PR), Recall Rate (RR), Detection Accuracy (DA). The average values of PR, RR, and DA for the proposed method are 99.9%, 99.7%, 99.8% respectively, which are better than other methods. The proposed method needs average 33 seconds of simulation time, which is less as compared to other methods.
C1 [Kharat, Jayashree] TEI, Dept Elect Engn, Maharastra, India.
   [Chougule, Sangeeta] KITs Coll Engn, Dept Elect & Telecommun Engn, Kolhapur, Maharashtra, India.
RP Kharat, J (corresponding author), TEI, Dept Elect Engn, Maharastra, India.
EM jayashree2k2@gmail.com
RI Chougule, Sangeeta Rajendra/CAF-6072-2022; Gavade-Kharat,
   Jayashree/AAV-5763-2021; CHOUGULE, SANGEETA RAJENDRA/GYU-6046-2022
OI Chougule, Sangeeta Rajendra/0000-0002-3201-2853; CHOUGULE, SANGEETA
   RAJENDRA/0000-0002-3201-2853
CR Al-Sanjary OI, 2018, LECT NOTES DATA ENG, V5, DOI [10.1007/978-3-319-59427-9-41, DOI 10.1007/978-3-319-59427-9-41]
   Aparicio-Díaz E, 2019, J INTELL FUZZY SYST, V36, P5023, DOI 10.3233/JIFS-179048
   Bozkurt I, 2017, TURK J ELECTR ENG CO, V25, P4558, DOI 10.3906/elk-1703-125
   Fadl SM, 2019, IET IMAGE PROCESS, V13, P522, DOI 10.1049/iet-ipr.2018.5068
   Fadl SM, 2018, J FORENSIC SCI, V63, P1099, DOI 10.1111/1556-4029.13658
   Gupta Ankita, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P659, DOI 10.1109/ABLAZE.2015.7154945
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Hu YJ, 2012, INT J DIGIT CRIME FO, V4, P20, DOI 10.4018/jdcf.2012070102
   Kingra S, 2017, INT J ELECTR COMPUT, V7, P831, DOI DOI 10.11591/IJECE.V7I2.PP831-841
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Li ZH, 2016, SECUR COMMUN NETW, V9, P4548, DOI 10.1002/sec.1648
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Sharma S, 2016, ADV COMP COMM SYST I, V1, P1
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh RD, 2018, MULTIMEDIA SYST, V24, P211, DOI 10.1007/s00530-017-0538-9
   Singh RD, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501079
   Singh VK, 2015, L N INST COMP SCI SO, V157, P29, DOI 10.1007/978-3-319-25512-5_3
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Sulong G, 2015, J THEOR APPL INF TEC, V74
   Ulutas G, 2017, MULTIMEDIA SYST, P1
   Ulutas G, 2017, IET IMAGE PROCESS, V11, P333, DOI 10.1049/iet-ipr.2016.0321
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Yang JM, 2016, MULTIMED TOOLS APPL, V75, P1793, DOI 10.1007/s11042-014-2374-7
   Zhao DN, 2018, MULTIMED TOOLS APPL, V77, P25389, DOI 10.1007/s11042-018-5791-1
   Zhenzhen Zhang, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P94, DOI 10.1007/978-3-319-31960-5_9
NR 28
TC 16
Z9 17
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8107
EP 8123
DI 10.1007/s11042-019-08272-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100055
DA 2024-07-18
ER

PT J
AU Quaid, MAK
   Jalal, A
AF Quaid, Majid Ali Khan
   Jalal, Ahmad
TI Wearable sensors based human behavioral pattern recognition using
   statistical features and reweighted genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accelerometer; Genetic algorithm; Human behaviors; Statistical features
ID ACCELEROMETER; SEGMENTATION; SMARTWATCHES; SELECTION; SYSTEM; MODEL
AB Human behavior pattern recognition (BPR) from accelerometer signals is a challenging problem due to variations in signal durations of different behaviors. Analysis of human behaviors provides in depth observations of subject's routines, energy consumption and muscular stress. Such observations hold key importance for the athletes and physically ailing humans, who are highly sensitive to even minor injuries. A novel idea having variant of genetic algorithm is proposed in this paper to solve complex feature selection and classification problems using sensor data. The proposed BPR system, based on statistical dependencies between behaviors and respective signal data, has been used to extract statistical features along with acoustic signal features like zero crossing rate to maximize the possibility of getting optimal feature values. Then, reweighting of features is introduced in a feature selection phase to facilitate the segregation of behaviors. These reweighted features are further processed by biological operations of crossover and mutation to adapt varying signal patterns for significant accuracy results. Experiments on wearable sensors benchmark datasets HMP, WISDM and self-annotated IMSB datasets have been demonstrated to testify the efficacy of the proposed work over state-of-the-art methods.
C1 [Quaid, Majid Ali Khan; Jalal, Ahmad] Air Univ, E-9, Islamabad, Pakistan.
C3 Air University Islamabad
RP Jalal, A (corresponding author), Air Univ, E-9, Islamabad, Pakistan.
EM ahmadjalal@mail.au.edu.pk
CR Abdallah ZS, 2015, NEUROCOMPUTING, V150, P304, DOI 10.1016/j.neucom.2014.09.074
   Al-Ghannam R, 2016, ARAB J SCI ENG, V41, P4967, DOI 10.1007/s13369-016-2158-7
   Altini M, 2015, IEEE J BIOMED HEALTH, V19, P219, DOI 10.1109/JBHI.2014.2313039
   Atallah L, 2011, IEEE T BIOMED CIRC S, V5, P320, DOI 10.1109/TBCAS.2011.2160540
   Attal F, 2015, SENSORS-BASEL, V15, P31314, DOI 10.3390/s151229858
   Bonomi AG, 2009, MED SCI SPORT EXER, V41, P1770, DOI 10.1249/MSS.0b013e3181a24536
   Bruno B, 2013, IEEE INT CONF ROBOT, P1602, DOI 10.1109/ICRA.2013.6630784
   Cao L, 2018, J PARALLEL DISTR COM, V118, P67, DOI 10.1016/j.jpdc.2017.05.007
   Dungkaew T, 2017, PROC INT CONF INF TE, P182
   Elyan E, 2017, INFORM SCIENCES, V384, P220, DOI 10.1016/j.ins.2016.08.007
   Guo M, 2018, MULTIMED TOOLS APPL, V77, P21201, DOI 10.1007/s11042-017-5573-1
   Gupta P, 2014, IEEE T BIO-MED ENG, V61, P1780, DOI 10.1109/TBME.2014.2307069
   Hegde N, 2018, IEEE J BIOMED HEALTH, V22, P979, DOI 10.1109/JBHI.2017.2734803
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Ignatov AD, 2016, MULTIMED TOOLS APPL, V75, P7257, DOI 10.1007/s11042-015-2643-0
   Jalal A, 2017, PATTERN RECOGN, V61, P295, DOI 10.1016/j.patcog.2016.08.003
   Jansi R, 2018, MULTIMED TOOLS APPL, V77, P31261, DOI 10.1007/s11042-018-6117-z
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Kwon Y, 2014, EXPERT SYST APPL, V41, P6067, DOI 10.1016/j.eswa.2014.04.037
   Lessmann S, 2006, IEEE IJCNN, P3063
   Margarito J, 2016, IEEE T BIO-MED ENG, V63, P788, DOI 10.1109/TBME.2015.2471094
   Mortazavi B, 2015, SENSORS-BASEL, V15, P26783, DOI 10.3390/s151026783
   Moschetti A, 2017, IEEE SENS J, V17, P8395, DOI 10.1109/JSEN.2017.2764323
   Nam Y, 2013, IEEE J BIOMED HEALTH, V17, P420, DOI 10.1109/JBHI.2012.2235075
   Rezaie H, 2017, IEEE SENS J, V17, P5315, DOI 10.1109/JSEN.2017.2720725
   San-Segundo R, 2018, ENG APPL ARTIF INTEL, V72, P190, DOI 10.1016/j.engappai.2018.04.002
   Wang ZL, 2016, IEEE SENS J, V16, P3198, DOI 10.1109/JSEN.2016.2519679
   Weiss GM, 2016, 2016 3RD IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL AND HEALTH INFORMATICS, P426, DOI 10.1109/BHI.2016.7455925
   Yang JY, 2008, PATTERN RECOGN LETT, V29, P2213, DOI 10.1016/j.patrec.2008.08.002
   Zhenyu He, 2010, Proceedings 2010 International Conference on Progress in Informatics and Computing (PIC 2010), P499, DOI 10.1109/PIC.2010.5687572
   Zhou YH, 2015, MULTIMED TOOLS APPL, V74, P9387, DOI 10.1007/s11042-014-2111-2
   Zhu C, 2015, IEEE T AUTOM SCI ENG, V12, P1225, DOI 10.1109/TASE.2015.2474743
NR 32
TC 94
Z9 97
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6061
EP 6083
DI 10.1007/s11042-019-08463-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900029
DA 2024-07-18
ER

PT J
AU Zhu, CJ
   Gan, ZH
   Lu, Y
   Chai, XL
AF Zhu, Changjiang
   Gan, Zhihua
   Lu, Yang
   Chai, Xiuli
TI An image encryption algorithm based on 3-D DNA level permutation and
   substitution scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3-D DNA level hybrid permutation; 3-D DNA level substitution;
   Hyperchaotic system; Image encryption
ID SEQUENCE OPERATION; CELLULAR-AUTOMATA; CHAOS THEORY; SECURE; MAP;
   COMPRESSION; TRANSFORM; DIFFUSION; DESIGN; SYSTEM
AB In this paper, an image encryption algorithm based on 3-D DNA level permutation and substitution scheme is proposed. In order to improve the security level of the image encryption, a 3-D DNA level hybrid permutation scheme using chaotic sequence sorting and 3-D cat map is presented to effectively shuffle the element positions, a novel 3-D DNA level substitution method based on random number is given to directly change the elements of the 3-D DNA matrix, and dynamic and random DNA encoding rules and DNA decoding rules are designed to upgrade the randomness of the encryption results. Moreover, a 6-D hyperchaotic system is used to generate the chaotic sequence for all the encryption processes, and SHA 256 hash value of the plain image is utilized to compute the initial values of chaotic system and system parameters of the 3-D cat map. Simulation results and performance analyses demonstrate that the proposed encryption scheme has large key space, high key sensitivity and may resist against some typical attacks, and it may effectively secure the secret image information.
C1 [Zhu, Changjiang; Gan, Zhihua] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
   [Lu, Yang] Henan Univ, Acad Sci & Technol, Kaifeng 475004, Peoples R China.
   [Chai, Xiuli] Henan Univ, Sch Comp & Informat Engn, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
C3 Henan University; Henan University; Henan University
RP Lu, Y (corresponding author), Henan Univ, Acad Sci & Technol, Kaifeng 475004, Peoples R China.
EM lyhenu@126.com
OI yang, lu/0000-0002-4066-0826
CR Al-Sharif S, 2016, 8 IFIP INT C NEW TEC, V2016, P21
   Algredo-Badillo I, 2013, MICROPROCESS MICROSY, V37, P750, DOI 10.1016/j.micpro.2012.06.007
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   [Anonymous], 2002, FEDERAL INFORM PROCE
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Chen TG, 2016, OPT LASER TECHNOL, V84, P118, DOI 10.1016/j.optlastec.2016.05.012
   Dalhoum A. L. A., 2012, IEEE Multimedia, V19, P28, DOI 10.1109/MMUL.2011.54
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Ghafir I, 2018, J SUPERCOMPUT, V74, P4986, DOI 10.1007/s11227-018-2337-2
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hu T, 2017, NONLINEAR DYNAM, V87, P51, DOI 10.1007/s11071-016-3024-6
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2017, INFORM SCIENCES, V396, P97, DOI 10.1016/j.ins.2017.02.036
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Karam Y, 2012, UKSIM EURO SYMP COMP, P67, DOI 10.1109/EMS.2012.17
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar R, 2018, OPT LASER TECHNOL, V107, P353, DOI 10.1016/j.optlastec.2018.06.014
   Li CQ, 2019, IEEE T CIRCUITS-I, V66, P2322, DOI 10.1109/TCSI.2018.2888688
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Li LJ, 2013, HIGH DIMENSIONAL CHA
   Liu H, 2016, SIGNAL PROCESS-IMAGE, V45, P41, DOI 10.1016/j.image.2016.04.002
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Mackay M, 2012, COMPUT LAW SECUR REV, V28, P679, DOI 10.1016/j.clsr.2012.07.007
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Ping P, 2018, SIGNAL PROCESS, V150, P233, DOI 10.1016/j.sigpro.2018.04.018
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Tang ZJ, 2015, MULTIMED TOOLS APPL, V74, P5429, DOI 10.1007/s11042-014-1861-1
   Wang SG, 2017, IEEE T CYBERNETICS, V47, P232, DOI 10.1109/TCYB.2015.2512852
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2019, IEEE ACCESS, V7, P34570, DOI 10.1109/ACCESS.2019.2904174
   Weng SW, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010049
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu YZ, 2013, IEEE INT CONF AUTOM, P323, DOI 10.1109/ASE.2013.6693091
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zhang LY, 2018, IEEE T CYBERNETICS, V48, P1163, DOI 10.1109/TCYB.2017.2682561
   Zhang LM, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/10/100504
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang Q, 2013, OPTIK, V124, P6276, DOI 10.1016/j.ijleo.2013.05.009
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
   Zhang YS, 2013, NONLINEAR DYNAM, V72, P751, DOI 10.1007/s11071-013-0750-x
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 69
TC 36
Z9 36
U1 1
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7227
EP 7258
DI 10.1007/s11042-019-08226-4
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100015
DA 2024-07-18
ER

PT J
AU Prasertsakul, P
   Kondo, T
   Iida, H
   Phatrapornnant, T
AF Prasertsakul, Pawin
   Kondo, Toshiaki
   Iida, Hiroyuki
   Phatrapornnant, Teera
TI Camera operation estimation from video shot using 2D motion vector
   histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera operation estimation; 2D histogram; Shot classification; Motion
   vectors
ID ROOD PATTERN SEARCH; EVENT DETECTION; CLASSIFICATION; STABILIZATION;
   DESCRIPTOR; FEATURES; MODEL; FIELD
AB This paper presents a novel technique for classifying several camera operations in videos. First of all, we obtain a series of 2D motion vector (MV) fields by applying an existing MV estimation method. Then, a 2D MV histogram is generated in polar coordinates. The histogram shows that how many MVs in each frame share the similar magnitude and orientation. These two MV features are utilized simultaneously to classify the camera operations by representing on the 2D histogram. The proposed method can detect not only single camera operations but also a combination of two camera operations. The 2D histogram can describe the speed of the camera operations. Moreover, the 2D MV field itself can separate zoom-in and zoom-out camera operations that may produce exactly the same pattern in the 2D MV histogram. Especially, separating zoom-in and zoom-out camera operations because these two operations produce a similar 2D histogram. The proposed method can achieve a processing time of 5-10 millisecond per frame for a low-resolution video, while it takes 40-80 millisecond for a high-resolution video.
C1 [Prasertsakul, Pawin; Kondo, Toshiaki] Thammasat Univ, Sirindhorn Int Inst Technol, Sch Informat Comp & Commun Technol, Pathum Thani 12000, Thailand.
   [Prasertsakul, Pawin; Iida, Hiroyuki] Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa 9231211, Japan.
   [Phatrapornnant, Teera] NSTDA, Natl Elect & Comp Technol Ctr NECTEC, Khlong Nueng, Thailand.
C3 Thammasat University; Japan Advanced Institute of Science & Technology
   (JAIST); National Science & Technology Development Agency - Thailand;
   National Electronics & Computer Technology Center (NECTEC)
RP Prasertsakul, P (corresponding author), Thammasat Univ, Sirindhorn Int Inst Technol, Sch Informat Comp & Commun Technol, Pathum Thani 12000, Thailand.; Prasertsakul, P (corresponding author), Japan Adv Inst Sci & Technol, Sch Informat Sci, Nomi, Ishikawa 9231211, Japan.
EM prasertsakul.p@gmail.com
OI IIDA, HIROYUKI/0000-0001-8412-9837
FU Sirindhorn International Institute of Technology (SIIT), Thammasat
   University (TU); Japan Advanced Institute of Science and Technology
   (JAIST); National Science and Technology Development Agency (NSTDA);
   National Research University Project (NRU), Thailand Office of Higher
   Education Commission
FX This research is financially supported by Sirindhorn International
   Institute of Technology (SIIT), Thammasat University (TU), Japan
   Advanced Institute of Science and Technology (JAIST), National Science
   and Technology Development Agency (NSTDA), and National Research
   University Project (NRU), Thailand Office of Higher Education
   Commission.
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Bendraou Y, 2014, 2014 SECOND WORLD CONFERENCE ON COMPLEX SYSTEMS (WCCS), P665, DOI 10.1109/ICoCS.2014.7060883
   Canini L, 2013, MULTIMED TOOLS APPL, V62, P51, DOI 10.1007/s11042-011-0916-9
   Derue FX, 2017, LECT NOTES COMPUT SC, V10317, P173, DOI 10.1007/978-3-319-59876-5_20
   DESOUZA TT, 2013, P 28 ANN ACM S APPL, P961, DOI DOI 10.1145/2480362.2480547
   Duan LY, 2006, IEEE T MULTIMEDIA, V8, P323, DOI 10.1109/TMM.2005.864344
   Ertürk S, 2003, IEEE T CONSUM ELECTR, V49, P1320, DOI 10.1109/TCE.2003.1261235
   Ewerth R, 2004, INT C PATT RECOG, P512, DOI 10.1109/ICPR.2004.1334181
   Fakhar B, 2019, MULTIMED TOOLS APPL, V78, P16995, DOI 10.1007/s11042-018-7083-1
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hasan MA, 2015, MULTIMED TOOLS APPL, V74, P11073, DOI 10.1007/s11042-014-2218-5
   Hasan MA, 2014, IEEE T CIRC SYST VID, V24, P1682, DOI 10.1109/TCSVT.2014.2345933
   Hu WC, 2018, MULTIMED TOOLS APPL, V77, P1237, DOI 10.1007/s11042-016-4291-4
   Kim JG, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1171, DOI 10.1109/ICME.2000.871569
   Lee S, 2002, INT CONF ACOUST SPEE, P3664
   Mahabalagiri A, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P271, DOI 10.1109/AVSS.2014.6918680
   Meneses CT, 2010, J SYNCHROTRON RADIAT, V17, P348, DOI 10.1107/S0909049510009726
   Narayanan S, 2013, INT J SPRAY COMBUST, V5, P1
   NGUYEN NT, 2010, INT J INTELL SYST TE, V9, P228
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Nikitidis S, 2008, IEEE T CIRC SYST VID, V18, P1028, DOI 10.1109/TCSVT.2008.927107
   Okade M, 2016, IEEE T CIRC SYST VID, V26, P453, DOI 10.1109/TCSVT.2015.2412772
   Okade M, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P333, DOI 10.1109/PCS.2012.6213314
   Patel NV, 1997, PATTERN RECOGN, V30, P583, DOI 10.1016/S0031-3203(96)00114-8
   PRASERTSAKUL P, 2018, THESIS
   Prasertsakul P, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY (ECTI-CON), P202, DOI 10.1109/ECTICon.2017.8096208
   Puthenpurayil SP, 2016, IET CIRC DEVICE SYST, V10, P309, DOI 10.1049/iet-cds.2015.0108
   Shih HC, 2013, IEEE T BROADCAST, V59, P556, DOI 10.1109/TBC.2013.2265782
   Spampinato G, 2019, MULTIMED TOOLS APPL, V78, P13787, DOI 10.1007/s11042-018-6571-7
   Srinivasan MV, 1997, PATTERN RECOGN, V30, P593, DOI 10.1016/S0031-3203(96)00106-9
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tu YB, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1014, DOI 10.1145/3123266.3123354
   Wang R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P691, DOI 10.1109/ICIP.1999.817204
   Weng Y, 2011, IEEE T CONSUM ELECTR, V57, P1329, DOI 10.1109/TCE.2011.6018891
   Xiao QK, 2015, SOFT COMPUT, V19, P133, DOI 10.1007/s00500-014-1237-5
   Xiao QK, 2014, MULTIMED TOOLS APPL, V72, P951, DOI 10.1007/s11042-013-1416-x
   Xiao QK, 2011, NEUROCOMPUTING, V74, P3486, DOI 10.1016/j.neucom.2011.06.002
   Yan Chen, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P95, DOI 10.1109/IBICA.2011.28
   Yan CG, 2020, IEEE T MULTIMEDIA, V22, P229, DOI 10.1109/TMM.2019.2924576
   Yu J, 2015, IEEE T CYBERNETICS, V45, P767, DOI 10.1109/TCYB.2014.2336697
   Zhang L, 2014, VISUAL COMPUT, V30, P1123, DOI 10.1007/s00371-013-0882-5
   Zhu XQ, 2005, IEEE T MULTIMEDIA, V7, P648, DOI 10.1109/TMM.2005.850977
NR 43
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17403
EP 17426
DI 10.1007/s11042-019-08378-3
EA FEB 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516251700001
DA 2024-07-18
ER

PT J
AU Yaghmaee, F
   Peyvandi, K
AF Yaghmaee, Farzin
   Peyvandi, Kimia
TI Improving image inpainting quality by a new SVD-based decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image inpainting; Structure; Texture; SVD; Image decomposition
ID COMPLETION; ALGORITHM; MATRIX
AB In this paper, we present a new algorithm for image inpainting using structure and texture information. Our image decomposition to texture and structure is accomplished by the SVD method in the primary step, and then an algorithm for texture inpainting is applied. At the next level, edge detection is used in target region related to inpainted texture component. The detected edges demonstrate border of different textures in the target region, and the boundary pixels are ignored from mask temporarily. The other target pixels should be primarily inpainted, and then border pixels would be filled subsequently. Experimental results of this algorithm show better consistency in comparison with state of the art methods.
C1 [Yaghmaee, Farzin; Peyvandi, Kimia] Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
C3 Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Elect & Comp Engn Dept, Semnan, Iran.
EM f_yaghmaee@semnan.ac.ir; kpeyvandi@semnan.ac.ir
RI Yaghmaee, Farzin/AAZ-6590-2021
OI Yaghmaee, Farzin/0000-0001-7430-542X
CR Alilou VK, 2017, MULTIMED TOOLS APPL, V76, P7213, DOI 10.1007/s11042-016-3366-6
   Alotaibi N, 2015, PATTERN ANAL APPL, V18, P333, DOI 10.1007/s10044-013-0348-4
   [Anonymous], 2002, THESIS STANFORD U
   [Anonymous], 1999, ICCV
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bengua JA, 2017, IEEE T IMAGE PROCESS, V26, P2466, DOI 10.1109/TIP.2017.2672439
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bornemann F, 2007, J MATH IMAGING VIS, V28, P259, DOI 10.1007/s10851-007-0017-6
   Buyssens P, 2015, IEEE T IMAGE PROCESS, V24, P1809, DOI 10.1109/TIP.2015.2411437
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Chen ZH, 2016, J VIS COMMUN IMAGE R, V40, P312, DOI 10.1016/j.jvcir.2016.06.029
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Darabi S, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185578
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   Ghorai M, 2015, LECT NOTES COMPUT SC, V9009, P63, DOI 10.1007/978-3-319-16631-5_5
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Guo Q, 2018, IEEE T VIS COMPUT GR, V24, P2023, DOI 10.1109/TVCG.2017.2702738
   He KM, 2014, IEEE T PATTERN ANAL, V36, P2423, DOI 10.1109/TPAMI.2014.2330611
   He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2
   He LT, 2014, IEEE T IMAGE PROCESS, V23, P5470, DOI 10.1109/TIP.2014.2362051
   Isogawa M, 2017, MULTIMED TOOLS APPL, V76, P9443, DOI 10.1007/s11042-016-3550-8
   Jin X, 2018, IEEE ACCESS, V6, P49967, DOI 10.1109/ACCESS.2018.2866089
   Kumar V, 2016, IEEE T IMAGE PROCESS, V25, P5212, DOI 10.1109/TIP.2016.2605919
   Lee J, 2012, IEEE T CONSUM ELECTR, V58, P553, DOI 10.1109/TCE.2012.6227460
   Levin A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P305
   Liang X, 2016, J COMPUT SCI TECH-CH, V31, P525, DOI 10.1007/s11390-016-1645-3
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   MOONEN M, 1992, SIAM J MATRIX ANAL A, V13, P1015, DOI 10.1137/0613061
   Ogawa T, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-179
   PADMAVATHI S, 2012, SIGNAL IMAGE PROCESS, V3, P85
   Qin C, 2012, MULTIMED TOOLS APPL, V56, P469, DOI 10.1007/s11042-010-0601-4
   Ruzic T, 2015, IEEE T IMAGE PROCESS, V24, P444, DOI 10.1109/TIP.2014.2372479
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang HX, 2017, NEUROCOMPUTING, V269, P90, DOI 10.1016/j.neucom.2016.08.149
   Xu ZB, 2010, IEEE T IMAGE PROCESS, V19, P1153, DOI 10.1109/TIP.2010.2042098
   Ying H., 2017, INT C INF COMM TECHN
   Zhang J, 2014, IEEE T IMAGE PROCESS, V23, P3336, DOI 10.1109/TIP.2014.2323127
   Zhang LF, 2019, INFORM SCIENCES, V485, P154, DOI 10.1016/j.ins.2019.02.008
   Zhang LF, 2015, PATTERN RECOGN, V48, P3102, DOI 10.1016/j.patcog.2014.12.016
   Zhang M, 2017, INT JOINT C NEUR NET
NR 43
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13795
EP 13809
DI 10.1007/s11042-020-08650-x
EA FEB 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515805300002
DA 2024-07-18
ER

PT J
AU Anuradha, K
   Anand, V
   Raajan, NR
AF Anuradha, K.
   Anand, V
   Raajan, N. R.
TI Identification of human actor in various scenarios by applying
   background modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illumination variations; Background modeling; Fmeasure; Foreground
   detection; Dynamic background
ID SEGMENTATION; OBJECTS
AB The identification of human actors in various scenarios with dynamic backgrounds has increased significance in numerous video-based applications. Lot of problems relevant to the detection of actors in scenarios with a dynamic background has to be addressed. This work proposes an approach to identify human actions with dynamic backgrounds and illumination variations. To accurately detect the foreground, the proposed method applies background modeling. The proposed method was assessed with approaches such as FrmDiff, MoG and ACMMM03. The assessment was performed on renowned datasets such as CDnet,WALLFLOWER and I2R. The results of assessment demonstrate the accuracy and the enhancement of the proposed method over the other methods taken into account.
C1 [Anuradha, K.; Raajan, N. R.] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, Tamil Nadu, India.
   [Anand, V] SASTRA Deemed Univ, Sch Comp, Thanjavur 613401, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Anuradha, K (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, Tamil Nadu, India.
EM kanuradha@ece.sastra.edu; anang@mca.sastra.edu; nrraajan@ece.sastra.edu
RI Renga Raajan, Narasimhan/IST-5582-2023; N R, Dr. RAAJAN/HDN-4829-2022
OI N R, Dr. RAAJAN/0000-0002-9537-1140; V, Dr. ANAND/0000-0001-7623-8398;
   K, Dr. ANURADHA/0000-0002-7929-8019
CR [Anonymous], 2016, P IEEE 1 INT C POW E, DOI DOI 10.1109/ICPEICES.2016.7853536
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Chen T, 2017, IEEE T CIRC SYST VID, V27, P2333, DOI 10.1109/TCSVT.2016.2587387
   de Almeida IR, 2017, IEEE T CIRC SYST VID, V27, P603, DOI 10.1109/TCSVT.2016.2596199
   KaewTraKulPong P., 2001, Proc. European Workshop Advanced Video Based Surveillance Systems, V1, P1
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kim SW, 2013, MACH VISION APPL, V24, P1015, DOI 10.1007/s00138-012-0448-y
   Li L, 2003, ICCAD-2003: IEEE/ACM DIGEST OF TECHNICAL PAPERS, P2
   Liao SC, 2010, PROC CVPR IEEE, P1301, DOI 10.1109/CVPR.2010.5539817
   Lim T, 2012, PATTERN RECOGN, V45, P1696, DOI 10.1016/j.patcog.2011.10.018
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Liu Z, 2012, NEUROCOMPUTING, V83, P47, DOI 10.1016/j.neucom.2011.11.012
   Narayana M, 2014, MACH VISION APPL, V25, P1163, DOI 10.1007/s00138-013-0569-y
   Shah M, 2014, MACH VISION APPL, V25, P1105, DOI 10.1007/s00138-013-0552-7
   Shen Peng, 2013, Journal of Multimedia, V8, P519, DOI 10.4304/jmm.8.5.519-526
   Tran KN, 2012, PATTERN RECOGN, V45, P2562, DOI 10.1016/j.patcog.2011.12.028
   Wang Y, 2015, ADV DIFFER EQU-NY, DOI 10.1186/s13662-015-0358-1
   Wu HF, 2014, SIGNAL IMAGE VIDEO P, V8, P665, DOI 10.1007/s11760-013-0576-5
   Yin J, 2011, J COMPUT INF SYST, V10, P3599
   Zhong BN, 2014, NEUROCOMPUTING, V123, P344, DOI 10.1016/j.neucom.2013.06.044
   Zhou ZW, 2016, IET COMPUT VIS, V10, P603, DOI 10.1049/iet-cvi.2015.0298
NR 22
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3879
EP 3891
DI 10.1007/s11042-019-7443-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700043
DA 2024-07-18
ER

PT J
AU Arulanandam, S
   Selvarasu, S
AF Arulanandam, Srinivasan
   Selvarasu, Sadagopan
TI Adaptive weighted fuzzy region based optimization for brain MR image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Intensity non-uniformity; Fuzzy region; Bias
   calculation; Energy minimization
ID INTENSITY INHOMOGENEITY; CLASSIFICATION; INFORMATION; ALGORITHM
AB The recent trends in medical image segmentation and analysis are often used in many real world applications for analyzing different objects of interest. Analyzing the brain Magnetic Resonance (MR) images is found to be difficult task because of the existence of intensity non-uniformity. Although numerous models have been proposed to handle brain MR image segmentation, it is still a challenge to effectively approximate the Intensity Non-Uniformity (INU) and improve greater segmentation accuracy. Hence, an integrated energy minimization approach, namely adaptive weighted fuzzy region based optimization algorithm is developed for brain MR image segmentation. These adaptive fuzzy regions are iteratively weighted to estimate their membership values assigned to each pixel with respect to energy. Also, the optimal weighting parameter, membership values to each region, and bias fields are iteratively estimated and updated. Further, this algorithm is compared with the recent energy minimization approaches in simulated brain MR image dataset. The results of the quantitative evaluations demonstrate that the proposed algorithm gives more reliable segmentation and better accuracy in spite of initialization, noise, and intensity non-uniformity.
C1 [Arulanandam, Srinivasan] Anna Univ, Misrimal Navajee Munoth Jain Engn Coll, Dept Informat Technol, Chennai, Tamil Nadu, India.
   [Selvarasu, Sadagopan] Anna Univ, Jerusalem Coll Engn, Dept Comp Sci Engn, Chennai, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Anna University; Anna
   University Chennai
RP Arulanandam, S (corresponding author), Anna Univ, Misrimal Navajee Munoth Jain Engn Coll, Dept Informat Technol, Chennai, Tamil Nadu, India.
EM asrini30@gmail.com; mssadagopan@gmail.com
RI selvarasu, Sadagopan/AAX-8733-2020; Arulanandam,
   Srinivasan/AAF-5354-2021
OI selvarasu, Sadagopan/0000-0002-0719-9644; Arulanandam,
   Srinivasan/0000-0001-9058-4473
CR Chang H, 2016, IEEE T MED IMAGING, V13, P1
   Chen Y, 2012, IET COMPUT VIS, V6, P610, DOI 10.1049/iet-cvi.2011.0263
   Cocosco C.A., 1997, NeuroImage
   Hou ZJ, 2006, INT J BIOMED IMAGING, V2006, DOI 10.1155/IJBI/2006/49515
   Ji ZX, 2012, COMPUT METH PROG BIO, V108, P644, DOI 10.1016/j.cmpb.2011.10.010
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Kumar S, 2012, J APPL REMOTE SENS, V6, DOI 10.1117/1.JRS.6.063588
   Kuo WF, 2011, INT J INNOV COMPUT I, V7, P5255
   Li CM, 2014, MAGN RESON IMAGING, V32, P913, DOI 10.1016/j.mri.2014.03.010
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Likar B, 2001, IEEE T MED IMAGING, V20, P1398, DOI 10.1109/42.974934
   Lowry Nathan, 2011, P IEEE INT S BIOM IM
   REN Jijun, 2012, P IEEE INT C IND INF
   Shi Zhang, 2013, P IEEE C CONTR DEC C
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Wang L, 2013, HUM BRAIN MAPP, V34, P956, DOI 10.1002/hbm.21486
   Wang L, 2009, COMPUT MED IMAG GRAP, V33, P520, DOI 10.1016/j.compmedimag.2009.04.010
   Wang Y, 2013, PATTERN RECOGN, V46, P1734, DOI 10.1016/j.patcog.2012.12.006
   Yan Bei, 2010, P IEEE INT C APP COM
   Yang XF, 2011, MED PHYS, V38, P2879, DOI 10.1118/1.3584199
   Zhang HL, 2013, IEEE T IMAGE PROCESS, V22, P3842, DOI 10.1109/TIP.2013.2262291
   Zhang KH, 2015, IEEE T CYBERNETICS, V45, P1426, DOI 10.1109/TCYB.2014.2352343
   Zhang Kaihua, 2010, P IEEE INT C IM PROC
   Zhao F, 2013, DIGIT SIGNAL PROCESS, V23, P184, DOI 10.1016/j.dsp.2012.09.016
   Zheng Q, 2014, SIGNAL PROCESS, V97, P117, DOI 10.1016/j.sigpro.2013.10.008
NR 27
TC 2
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3603
EP 3621
DI 10.1007/s11042-018-6215-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700027
DA 2024-07-18
ER

PT J
AU David, DS
   Jayachandran, A
AF David, D. Stalin
   Jayachandran, A.
TI A new expert system based on hybrid colour and structure descriptor and
   machine learning algorithms for early glaucoma diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Feature extraction; Texture; Segmentation; Retinal
   images
ID LEVEL SET; ACTIVE CONTOURS; BRAIN-TUMOR; CLASSIFICATION; MODEL
AB Medical image classification system is widely used by the radiologists to segment the medical images into meaningful regions. Glaucoma is an optic neuropathy defined by characteristic damage to the optic nerve and accompanying visual field deficits. Early diagnosis and treatment are critical to prevent irreversible vision loss and ultimate blindness. Automatic detection of diabetic retinopathy in retinal image is vital as it delivers data about unusual tissues which is essential for planning treatment. Automating, this method is challenging due to the high variabiity in the appearance of tissue among dissimilar patients and in many circumstances, the comparison between abnormal and normal tissue. This paper presents a new methodology and a computerized diagnostic system for diabetic retinopathy. In this article, adaptive histogram equalization is used to convert colour images to gray scale images followed by significant features are selected using hybrid colour and structure descriptor (HCSD). Finally, various classifiers are used for classification of images into normal and glaucomatous classes. The overall classification accuracy of HCSD with Hybrid Radial Basis Kernel based Support vector Machine (HRKSVM) is 97.55%, HCSD with Support vector Machine (SVM) is 94.77% and HCSD with Hybrid Kernel Support Vector Machine (HKSVM) is 95.71%.
C1 [David, D. Stalin; Jayachandran, A.] PSN Coll Engn & Technol, Dept CSE, Tirunelveli, India.
RP David, DS (corresponding author), PSN Coll Engn & Technol, Dept CSE, Tirunelveli, India.
EM dstalindavid0011@gmail.com; ajaya1675@gmail.com
RI D, DR.STALIN DAVID/AAL-7893-2020
OI D, DR.STALIN DAVID/0000-0002-2174-8240
CR CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P599
   HUANG D, 1991, SCIENCE, V254, P1178, DOI 10.1126/science.1957169
   Jayachandran A, 2017, IRAN J FUZZY SYST, V14, P41
   Jayachandran A, 2014, ARAB J SCI ENG, V39, P7073, DOI 10.1007/s13369-014-1334-x
   Jayachandran A, 2013, J IMAGING SCI TECHN, V57, DOI 10.2352/J.ImagingSci.Technol.2013.57.1.010507
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Juuti-Uusitalo K, 2013, INVEST OPHTH VIS SCI, V54, P3510, DOI 10.1167/iovs.13-11800
   Kharmegasundaraj G, 2016, INT J FUZZY SYST, V17, P434
   KIMMEL R, 1995, IEEE T PATTERN ANAL, V17, P635, DOI 10.1109/34.387512
   Kolár R, 2008, RADIOENGINEERING, V17, P109
   Kramer G, 2016, COLOR RES APPL, V41, P457, DOI 10.1002/col.21979
   Kumar T., 2010, Int J Comput Appl, V7, P7, DOI DOI 10.5120/1140-1493
   Kurnar M, 2017, BIOMED SIGNAL PROCES, V31, P301, DOI 10.1016/j.bspc.2016.08.018
   Larose Daniel T., 2014, Discovering Knowledge in Data: An Introduction to Data Mining, P149, DOI [10.1002/9781118874059.ch7, DOI 10.1002/9781118874059.CH7, 10.1002/9781118874059.CH7, DOI 10.1002/0471687545.CH5]
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li Y, 2016, OPT LASER TECHNOL, V83, P99, DOI 10.1016/j.optlastec.2016.03.017
   Maheshwari S, 2017, IEEE J BIOMED HEALTH, V21, P803, DOI 10.1109/JBHI.2016.2544961
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Martínez-Rojas M, 2015, COMPUT-AIDED CIV INF, V30, P919, DOI 10.1111/mice.12179
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Osher S, 2001, J COMPUT PHYS, V169, P463, DOI 10.1006/jcph.2000.6636
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Schwartz SD, 2012, LANCET, V379, P713, DOI 10.1016/S0140-6736(12)60028-2
   Sethian JA, 2001, J COMPUT PHYS, V169, P503, DOI 10.1006/jcph.2000.6657
NR 28
TC 8
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5213
EP 5224
DI 10.1007/s11042-018-6265-1
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500056
DA 2024-07-18
ER

PT J
AU Li, B
   Bai, BX
   Han, C
AF Li, Bo
   Bai, Baoxing
   Han, Cheng
TI Upper body motion recognition based on key frame and random forest
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Upper body motion recognition; Upper limb motion; Kinect V2; AP
   clustering algorithm; Key frame; Random forest regression
AB There are limited approaches using Kinect for upper body motion recognition. Most of the available approaches are conducted when there is no joint occlusion, though some performed with joint occlusion only demonstrated recognition of a few motions at low recognition rates. This paper utilizes OptiTrack and its supporting software to obtain and transfer data into a human skeleton coordinates using Kinect v2, and selects the vector among key joint points and angles as the feature values; the AP clustering algorithm was adopted for the key frames of motions which are marked; then we conduct relative normalization of the feature values, and use the method of random forest regression to realize two functions: (1) conduct derivation based on joint offset of frames detected with Kinect v2 from those detected with OptiTrack, learn the joint offset regression function, and correct the skeleton based on the predictions on joint offset; (2) determine the motions based on predicted posture. This paper performs recognition of 8 types of upper body motions at an average accuracy of 90.86%.
C1 [Li, Bo; Han, Cheng] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun, Jilin, Peoples R China.
   [Bai, Baoxing] Changchun Univ Sci & Technol, Coll Opt & Elect Informat, Changchun, Jilin, Peoples R China.
C3 Changchun University of Science & Technology; Changchun University of
   Science & Technology
RP Bai, BX (corresponding author), Changchun Univ Sci & Technol, Coll Opt & Elect Informat, Changchun, Jilin, Peoples R China.
EM bolivarboli@163.com; 19546615@qq.com; hancheng@cust.edu.cn
CR [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], IEEE SOL STAT CIRC C
   [Anonymous], 2008, PROC 25 INT C MACH L
   [Anonymous], 2012, 2012 IEEE COMPUTER S, DOI DOI 10.1109/CVPRW.2012.6239231
   Batabyal T, 2015, IEEE IMAGE PROC, P4107, DOI 10.1109/ICIP.2015.7351578
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chen C, 2016, INT CONF ACOUST SPEE, P2712, DOI 10.1109/ICASSP.2016.7472170
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Du Y, 2016, IEEE T IMAGE PROCESS, V25, P3010, DOI 10.1109/TIP.2016.2552404
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Hsu SC, 2015, MACH VISION APPL, V26, P919, DOI 10.1007/s00138-015-0710-1
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Mahasseni B, 2016, PROC CVPR IEEE, P3054, DOI 10.1109/CVPR.2016.333
   Patsadu O., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P28, DOI 10.1109/JCSSE.2012.6261920
   Pisharady PK, 2013, PROC SPIE, V8768, DOI 10.1117/12.2009926
   Prakash A, 2016, IEEE CONF TECHNOL ED, P34, DOI [10.1109/T4E.2016.14, 10.1109/T4E.2016.015]
   Schwarz LA, 2012, IMAGE VISION COMPUT, V30, P217, DOI 10.1016/j.imavis.2011.12.001
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Sheth N. S., 2015, FUZZY SYST, V7, P1
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Le TL, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTING, MANAGEMENT AND TELECOMMUNICATIONS (COMMANTEL), P340, DOI 10.1109/ComManTel.2013.6482417
   Wang HQ, 2015, FINANC INNOV, V1, DOI 10.1186/s40854-015-0002-9
   Wang WJ, 2016, INT J ADV ROBOT SYST, V13, DOI 10.5772/62163
   Xia S, 2018, 171108126V2 ARXIV
   Xiang Li, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3130940
   Xiao Y, 2014, PRESENCE-VIRTUAL AUG, V23, P133, DOI 10.1162/PRES_a_00176
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zheng Xiao, 2012, 2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P344, DOI 10.1109/IHMSC.2012.92
NR 30
TC 16
Z9 16
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5197
EP 5212
DI 10.1007/s11042-018-6357-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500055
DA 2024-07-18
ER

PT J
AU Lu, H
   Shao, LP
AF Lu, Hai
   Shao, Liping
TI Full key dependent coverless test disguise method by
   interval-extension-based double authentications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coverless information hiding; Full key dependent; Random code; Test
   disguise; Double authentications based on interval extension
ID HISTOGRAMS
AB In traditional search-based coverless information hiding methods, there are some problems such as the low hidden capacity, high cost of database creation and search, dense transmission of data, and absence of authentication. To avoid these problems, we propose a full key dependent coverless test disguise method by interval-extension-based double authentications. We transform secret information into a coded sequence by a random codebook sequence that is generated by user keys. The initialized codebook sequence is used to hinder the direct transmission of secret information. Then, we use candidate answers' orders and question set indexes to express the coded index sequence. In the restoration process, the extracted information can be authenticated efficiently by the legal interval and a comparison. The experimental results and analysis show that our method achieves a high hidden capacity with a simpler test database, avoids dense transmission of data and authenticates extracted information well. Without the correct user keys, the secret information cannot be acquired.
C1 [Lu, Hai; Shao, Liping] Shaanxi Normal Univ, Sch Comp Sci, Xian, Peoples R China.
C3 Shaanxi Normal University
RP Shao, LP (corresponding author), Shaanxi Normal Univ, Sch Comp Sci, Xian, Peoples R China.
EM m15063732825@163.com; slpmaster@163.com
OI shao, liping/0000-0001-9200-0099
CR Adeli A, 2018, APPL INTELL, V48, P1609, DOI 10.1007/s10489-017-0989-x
   [Anonymous], INT J ADV SCI TECHNI
   Chen XY, 2019, SOFT COMPUT, V23, P6323, DOI 10.1007/s00500-018-3286-7
   Chen XY, 2017, J INTERNET TECHNOL, V18, P313, DOI 10.6138/JIT.2017.18.2.20160815
   Chen XM, 2015, IEEE COMMUN MAG, V53, P133, DOI 10.1109/MCOM.2015.7081086
   Fakhredanesh M, 2019, MULTIMED TOOLS APPL, V78, P18475, DOI 10.1007/s11042-019-7238-8
   Feng G., 2019, IEEE T CIRCUITS SYST
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Guo Y, 2017, IET IMAGE PROCESS, V11, P406, DOI 10.1049/iet-ipr.2016.0515
   Liu HH, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0458-z
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Rajendran Sujarani, 2017, International Journal of Network Security, V19, P593, DOI 10.6633/IJNS.201707.19(4).12
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Swain G, 2016, MULTIMED TOOLS APPL, V75, P13541, DOI 10.1007/s11042-015-2937-2
   Wen J, 2019, IEEE SIGNAL PROC LET, V26, P460, DOI 10.1109/LSP.2019.2895286
   Xia ZH, 2017, J INTERNET TECHNOL, V18, P1353, DOI 10.6138/JIT.2017.18.6.20160815b
   Yang JH, 2019, MULTIMED TOOLS APPL, V78, P8481, DOI 10.1007/s11042-018-6878-4
   Yin ZX, 2016, SECUR COMMUN NETW, V9, P721, DOI 10.1002/sec.1275
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
   Zhang JJ, 2017, LECT NOTES COMPUT SC, V10602, DOI 10.1007/978-3-319-68505-2_11
   Zhang X, 2018, IEEE T MULTIMEDIA, V20, P3223, DOI 10.1109/TMM.2018.2838334
   Zhang XP, 2014, J VIS COMMUN IMAGE R, V25, P322, DOI 10.1016/j.jvcir.2013.11.001
   Zhang YX, 2017, CHINESE J ELECTRON, V26, P1, DOI 10.1049/cje.2016.11.016
   Zheng SL, 2017, LECT NOTES ARTIF INT, V10363, P536, DOI 10.1007/978-3-319-63315-2_47
   Zhili Zhou, 2015, Cloud Computing and Security. First International Conference, ICCCS 2015. Revised Selected Papers: LNCS 9483, P123, DOI 10.1007/978-3-319-27051-7_11
   Zhou ZL, 2019, SOFT COMPUT, V23, P4927, DOI 10.1007/s00500-018-3151-8
   Zhou ZL, 2017, J INTERNET TECHNOL, V18, P1177, DOI 10.6138/JIT.2017.18.5.20160815b
   Zhou ZL, 2016, INT J SECUR APPL, V10, P309, DOI 10.14257/ijsia.2016.10.9.30
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 30
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13667
EP 13691
DI 10.1007/s11042-020-08622-1
EA FEB 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510371400004
DA 2024-07-18
ER

PT J
AU Agarwal, R
   Jalal, AS
   Arya, KV
AF Agarwal, Rohit
   Jalal, Anand Singh
   Arya, K. V.
TI A multimodal liveness detection using statistical texture features and
   spatial analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Fingerprints; Iris; D-S Theory; Liveness detection; GLCM;
   NGTDM; Texture features
ID FINGERPRINT; IRIS; SYSTEMS; FUSION; ATTACK; FACE
AB Biometric authentication can establish a person's identity from their exclusive features. In general, biometric authentication can vulnerable to spoofing attacks. Spoofing referred to presentation attack to mislead the biometric sensor. An anti-spoofing method is able to automatically differentiate between real biometric traits presented to the sensor and synthetically produced artifacts containing a biometric trait. There is a great need for a software-based liveness detection method that can classify the fake and real biometric traits. In this paper, we have proposed a liveness detection method using fingerprint and iris. In this method, statistical texture features and spatial analysis of the fingerprint pattern is utilized for fake or real classification. The approach is further improved by fusing iris modality with the fingerprint modality. The standard Haralick's statistical features based on the gray level co-occurrence matrix (GLCM) and Neighborhood Gray-Tone Difference Matrix (NGTDM) are used to generate a feature vector from the fingerprint. Texture feature from iris is used to boost the performance of the proposed liveness detection method. For the fusion Dempster-Shafer (D-S) approach is used at the decision level. Experiments have been performed on ATVS dataset and LivDet2011 dataset. The results show the convincing and effective outcomes of the proposed method.
C1 [Agarwal, Rohit; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
   [Arya, K. V.] IET Lucknow, Dept Comp Sci Engn, Lucknow, Uttar Pradesh, India.
C3 GLA University; Dr. A.P.J. Abdul Kalam Technical University (AKTU);
   Institute of Engineering & Technology Lucknow
RP Agarwal, R (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, Uttar Pradesh, India.
EM rohit.agrwal@gla.ac.in; asjalal@gla.ac.in; kvarya@ietlucknow.ac.in
OI Arya, Karm Veer/0000-0001-7117-1745; , Rohit/0000-0003-4192-726X; Jalal,
   Anand/0000-0002-7469-6608
CR Abate Andrea F., 2018, Cyberspace Safety and Security. 10th International Symposium, CSS 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11161), P270, DOI 10.1007/978-3-030-01689-0_21
   Abhishek K, 2015, PROCEDIA COMPUT SCI, V58, P447, DOI 10.1016/j.procs.2015.08.061
   Abhyankar A, 2006, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2006.313158
   Agarwal R, 2018, WIRELESS PERSONAL CO
   Ahmad SMS, 2012, INT J INNOV COMPUT I, V8, P7983
   Al-Ajlan A, 2013, I W BIOMETRIC FORENS
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 2015, INT J SCI TECHNICAL
   [Anonymous], 2007, Database
   [Anonymous], 2014, 2014 ANN IEEE INDIA, DOI DOI 10.1109/INDICON.2014.7030414
   Bhogal APS, 2017, 2017 5 INT WORKSH BI, P1
   Coli P, 2007, LECT NOTES COMPUT SC, V4642, P722
   Daugman J, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P715, DOI 10.1016/B978-0-12-374457-9.00025-1
   Dubey RK, 2016, IEEE T INF FOREN SEC, V11, P1461, DOI 10.1109/TIFS.2016.2535899
   Fierrez-Aguilar J, 2004, PROC SPIE, V5404, P544, DOI 10.1117/12.542800
   Galbally J., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P271, DOI 10.1109/ICB.2012.6199819
   Galbally J., 2016, Biometrics and Forensics (IWBF), 2016 4th International Workshop on, P1, DOI DOI 10.1109/IWBF.2016.7449676
   Galbally J., 2009, 2009 First IEEE International Conference on Biometrics, Identity and Security (BIdS), P1
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Ghiani L, 2012, INT C PATT RECOG, P537
   Gomez-Barrero M, 2014, PATTERN RECOGN LETT, V36, P243, DOI 10.1016/j.patrec.2013.04.029
   Gottschlich C, 2015, INT SYMP IMAGE SIG, P83, DOI 10.1109/ISPA.2015.7306037
   Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hezil N, 2017, IET BIOMETRICS, V6, P351, DOI 10.1049/iet-bmt.2016.0072
   Hu Y, 2016, PATTERN RECOGN LETT, V82, P242, DOI 10.1016/j.patrec.2015.10.010
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jia J, 2007, LECT NOTES COMPUT SC, V4681, P1140
   Nguyen K, 2015, IEEE T HUM-MACH SYST, V45, P132, DOI 10.1109/THMS.2014.2361437
   Marasco E., 2014, ACM COMPUT SURV, V47, P36
   Marasco E, 2012, PATTERN RECOGN LETT, V33, P1148, DOI 10.1016/j.patrec.2012.01.009
   Memon S., 2011, 2011 19th Telecommunications Forum Telfor (TELFOR), P619, DOI 10.1109/TELFOR.2011.6143624
   Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796
   Nikam SB, 2010, SIGNAL IMAGE VIDEO P, V4, P75, DOI 10.1007/s11760-008-0098-8
   Nikam SB, 2008, INT J BIOMETRICS, V1, P141, DOI 10.1504/IJBM.2008.020141
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Oloyede MO, 2016, IEEE ACCESS, V4, P7532, DOI 10.1109/ACCESS.2016.2614720
   Poh N, 2010, IEEE T SYST MAN CY A, V40, P539, DOI 10.1109/TSMCA.2010.2041660
   Raghavendra R, 2015, IEEE T INF FOREN SEC, V10, P703, DOI 10.1109/TIFS.2015.2400393
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Shafer G, 1976, MATH THEORY EVIDENCE, DOI DOI 10.1080/00401706.1978.10489628
   Singh YN, 2013, INT J BIOMETRICS, V5, P137, DOI 10.1504/IJBM.2013.052964
   Toth B., 2005, Information Security Bulletin, V10, P291
   Wang SQ, 2018, IEEE COMPUT GRAPH, V38, P47, DOI 10.1109/MCG.2016.46
   Wild P, 2016, PATTERN RECOGN, V50, P17, DOI 10.1016/j.patcog.2015.08.007
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810
   Yan C, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING (IEEE NLP-KE'05), P769
   Yuan CS, 2017, CMC-COMPUT MATER CON, V53, P357
   Zhang HY, 2016, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.2016.7532307
NR 53
TC 9
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13621
EP 13645
DI 10.1007/s11042-019-08313-6
EA JAN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515798800002
DA 2024-07-18
ER

PT J
AU Yeom, S
   Shin, D
   Shin, D
AF Yeom, Seongkyu
   Shin, Dongil
   Shin, Dongkyoo
TI Scenario-based cyber attack•defense education system on virtual machines
   integrated by web technologies for protection of multimedia contents in
   a network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Education system; Case of cyber incident; Malware; Scenario; Virtual
   machine
AB Security issues have been raised with the tremendous growth of social multimedia content evolving content distribution and social interaction. To protect the social multimedia contents in a network, information security education has been actively studied, and various educational systems are being provided. Even when trainees have completed the training that they can practice, such as DDoS(Distributed Denial of Services) response and database outbreak attack, most of the education methods are based on the theory or advance notification method designed as part of the scenario beforehand and it is difficult to apply these to actual situations. In addition, building new systems and learning to use them for each scenario lowers the training effectiveness. In this paper, we investigate various cases of cyber incident in the content distribution networks. Based on research, we develop Meltdown, Mirai malware, Carbanak APT(Advanced Persistent Threats), and Ransomware scenarios that assume a real multimedia contents distribution situation. We also build and store individual virtual environments for each scenario, integrating them into VMWare ESXI, so that attack and defense practices can be conducted similar to real world networks. The deployed environment is integrated with the Web through the VM API(Virtual Machine Application Programming Interfaces). When the trainee finishes the training, one utilizes the snapshot function of the virtual machine to return the virtual environment to the pre-training state. Trainees do not need to build a virtual environment for each scenario, but they are able to conduct training in an environment similar to a real network by calling a virtual environment with a simple operation from a web browser. Therefore, it is expected that the convenience of trainees and the efficiency of the education will be increased.
C1 [Yeom, Seongkyu; Shin, Dongil; Shin, Dongkyoo] Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
C3 Sejong University
RP Shin, D (corresponding author), Sejong Univ, Dept Comp Engn, 98 Gunja Dong, Seoul 143747, South Korea.
EM dae02159@gmail.com; dshin@sejong.ac.kr; shindk@sejong.ac.kr
RI Shin, Dongil/AAB-3750-2021
OI Shin, Dongkyoo/0000-0002-2665-3339
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [2018R1D1A1B07047395]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2018R1D1A1B07047395).
CR Abdelaal M.A., 2019, INT J CLOUD COMPUT, V8, P183, DOI [10.1504/IJCC.2019.101329, DOI 10.1504/IJCC.2019.101329]
   Ahnlab-ASEC, 2017, ASECREPORT, V87, P12
   [Anonymous], 2016, INT J ADV RES COMPUT
   Arduin PE, 2018, 3 CATEGORIES INSIDER, V10, P59, DOI [10.1002/9781119419785.ch3, DOI 10.1002/9781119419785.CH3]
   Bulusu ST, 2017, 2017 1ST CYBER SECURITY IN NETWORKING CONFERENCE (CSNET)
   Czejdo Bogdan Denny, 2010, International Journal of Social and Humanistic Computing, V1, P273, DOI 10.1504/IJSHC.2010.032688
   Du WL, 2011, IEEE SECUR PRIV, V9, P70, DOI 10.1109/MSP.2011.139
   Evans SC, 2008, SECURING WEBGOAT USI
   Garg S, 2019, IEEE T MULTIMEDIA, V21, P566, DOI 10.1109/TMM.2019.2893549
   Hack.me, HOUS RIS SANDB
   Hallman R, 2017, IOTBDS: PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INTERNET OF THINGS, BIG DATA AND SECURITY, P47, DOI 10.5220/0006246600470058
   HO EOM JUNG, 2015, [Journal of Security Engineering, 보안공학연구논문지], V12, P567, DOI 10.14257/jse.2015.12.05
   Kshetri N, 2016, BIG DATA'S BIG POTENTIAL IN DEVELOPING ECONOMIES: IMPACT ON AGRICULTURE, HEALTH AND ENVIRONMENTAL SECURITY, P1, DOI 10.1079/9781780648682.0001
   Li PD, 2019, IEEE ACCESS, V7, P103556, DOI 10.1109/ACCESS.2019.2932020
   Li QX, 2019, IEEE ACCESS, V7, P16066, DOI 10.1109/ACCESS.2019.2891772
   Lipp M, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P973
   McDuffie EL, 2014, COMPUTER, V47, P67, DOI 10.1109/MC.2014.224
   McGettrick A, 2013, IEEE SECUR PRIV, V11, P66, DOI 10.1109/MSP.2013.155
   황규희, 2014, [Korean Management Science Review, 경영과학], V31, P1, DOI 10.7737/KMSR.2014.31.4.001
   Roy SD, 2013, IEEE MULTIMEDIA, V20, P7, DOI 10.1109/MMUL.2013.9
   Tian YH, 2010, COMPUTER, V43, P27, DOI 10.1109/MC.2010.188
NR 21
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34085
EP 34101
DI 10.1007/s11042-019-08583-0
EA JAN 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000505360700001
DA 2024-07-18
ER

PT J
AU Huang, BY
   Juan, JST
AF Huang, Bo-Yuan
   Juan, Justie Su-Tzu
TI Flexible meaningful visual multi-secret sharing scheme by random grids
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Random grids; Pixel expansion; Meaningful
ID XOR; CRYPTOGRAPHY
AB With rapid developments in network technology, information security is becoming increasingly crucial. To ensure that secret images are not being stolen during transmission, a good countermeasure is to encrypt them before transmission. Visual secret sharing (VSS) is a type of secure communication technology in which a secret image is encrypted into some shares and then restored through human vision by superimposing shares. A random grid is a pivotal VSS technique. Because computation and pixel expansion is not needed in the decrypting phase, many scholars have researched random grids for VSS. To minimize time consumption, some researchers have proposed high-capacity visual multiple secret sharing (VMSS) schemes that can encrypt multiple images simultaneously, although some difficulty is encountered in share management. A meaningful VSS scheme provides a solution for both distinguishing and management problems; however, it cannot handle restrictions on the number of secret images. For avoiding the abovementioned problems, this study proposes an advanced meaningful VMSS scheme that can flexibly adjust the quality between shares and restored images. Our scheme offers seven attractive features that make it notably flexible in theoretical and practical use.
C1 [Huang, Bo-Yuan; Juan, Justie Su-Tzu] Natl Chi Nan Univ, Dept Comp Sci & Informat Engn, Nantou, Taiwan.
C3 National Chi Nan University
RP Juan, JST (corresponding author), Natl Chi Nan Univ, Dept Comp Sci & Informat Engn, Nantou, Taiwan.
EM jsjuan@ncnu.edu.tw
RI Juan, Justie Su-Tzu/HPF-1761-2023
OI Juan, Justie Su-Tzu/0000-0002-3654-2560
FU Ministry of Science and Technology of the Republic of China [MOST
   108-2221-E-260-008]
FX The authors would like to thank the Ministry of Science and Technology
   of the Republic of China for financially supporting this research under
   Contract No. MOST 108-2221-E-260-008.
CR Anila T., 2013, Mining Intelligence and Knowledge Exploration. First International Conference, MIKE 2013. Proceedings: LNCS 8284, P340, DOI 10.1007/978-3-319-03844-5_35
   CHANG JJY, 2012, WORLD ACAD SCI ENG T, V6, P914
   Chang JJY, 2018, CRYPTOGRAPHY-BASEL, V2, DOI 10.3390/cryptography2030024
   Chen TH, 2012, SIGNAL PROCESS, V92, P2229, DOI 10.1016/j.sigpro.2012.02.015
   Cheng TF, 2017, MULTIMED TOOLS APPL, V76, P9337, DOI 10.1007/s11042-016-3535-7
   Chiu PL, 2016, 2016 FIRST IEEE INTERNATIONAL CONFERENCE ON COMPUTER COMMUNICATION AND THE INTERNET (ICCCI 2016), P362, DOI 10.1109/CCI.2016.7778943
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Deshmukh M, 2018, MULTIMED TOOLS APPL, V77, P89, DOI 10.1007/s11042-016-4229-x
   Guo C, 2016, MULTIMED TOOLS APPL, V75, P11577, DOI 10.1007/s11042-015-2885-x
   HUNAG BY, 2017, 2017 GLOB C ENG APPL, P244
   Joy Jo-Yi Chang, 2010, 2010 10th International Symposium on Communications and Information Technologies (ISCIT 2010), P458, DOI 10.1109/ISCIT.2010.5664885
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Lee JS, 2015, DIGIT SIGNAL PROCESS, V40, P131, DOI 10.1016/j.dsp.2015.02.012
   Liu CL, 2015, COMPUT J, V58, P1598, DOI 10.1093/comjnl/bxu105
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Ou DH, 2016, MULTIMED TOOLS APPL, V75, P3517, DOI 10.1007/s11042-015-2462-3
   PAKNAHAD SM, 2016, 2016 10 INT S COMM S, P1
   Shivani S, 2018, MULTIMED TOOLS APPL, V77, P6287, DOI 10.1007/s11042-017-4536-x
   Shivani S, 2017, MULTIMED TOOLS APPL, V76, P3851, DOI 10.1007/s11042-016-4012-z
   Shyu SJ, 2012, IEEE T CIRC SYST VID, V22, P769, DOI 10.1109/TCSVT.2011.2180769
   Singh P, 2018, SIGNAL PROCESS, V142, P301, DOI 10.1016/j.sigpro.2017.06.015
   Ulutas M, 2010, MATH PROBL ENG, V2010, DOI 10.1155/2010/593236
NR 22
TC 11
Z9 11
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7705
EP 7729
DI 10.1007/s11042-019-08436-w
EA JAN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600003
DA 2024-07-18
ER

PT J
AU Jiang, FF
   Gao, TG
   Li, D
AF Jiang, Feifeng
   Gao, Tiegang
   Li, De
TI A robust zero-watermarking algorithm for color image based on tensor
   mode expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Zero-watermark; Tensor mode expansion; Singular value decomposition;
   Discrete cosine transform
ID SCHEME; DCT
AB Digital zero-watermarking technology is an effective measure to protect image copyright, and many algorithms have been proposed based on zero-watermark. However, most of the existing zero-watermarking algorithms are designed for grayscale images. In this paper, a new zero-watermarking algorithm for color image based on tensor mode expansion is proposed. In the proposed scheme, four images of R, G, B, and gray are firstly generated from the original image. Then, the four images are appropriately combined to construct two three-dimensional tensors, and tensor expansion is performed on the obtained tensors. By performing singular value decomposition (SVD) and discrete cosine transform (DCT) on the expanded data, a feature image containing the main information of the host image can be generated. Finally, the feature image is fused with the specified logo image to obtain a zero-watermark image. Experimental results show that the proposed algorithm is robust to noise attacks and common image processing attacks, and better performances compared with some existing algorithms are also achieved. In addition, since the proposed algorithm is based on color images, it can make full use of all aspects of color images.
C1 [Jiang, Feifeng; Gao, Tiegang] Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
   [Li, De] Yanbian Univ, Dept Comp Sci, Yanji 133000, Peoples R China.
C3 Nankai University; Yanbian University
RP Gao, TG (corresponding author), Nankai Univ, Coll Software, Tianjin 300350, Peoples R China.
EM 1036779510@qq.com; gaotiegang@nankai.edu.cn; leader1223@ybu.edu.cn
RI Gao, Tiegang/AAT-9599-2021
FU Program of Natural Science Fund of Tianjin, China [16JCYBJC15700]
FX The work was supported by the Program of Natural Science Fund of
   Tianjin, China (Grant NO. 16JCYBJC15700).
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   GOLEA EH, 2010, IEEE ACS INT C COMP
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Han SC, 2012, INT CONF SIGN PROCES, P1592, DOI 10.1109/ICoSP.2012.6491884
   Leng Xiao-xu, 2013, Advanced Materials Research, V765-767, P1113, DOI 10.4028/www.scientific.net/AMR.765-767.1113
   Li Z, 2011, IEEE IMAGE PROC
   Luo XQ, 2017, J VIS COMMUN IMAGE R, V45, P46, DOI 10.1016/j.jvcir.2017.02.006
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   POTDAR VM, 2005, SURVEY DIGITAL IMAGE
   RACHMAWANTO EH, 2016, TECHNOL INF COMMUN, P312
   Rani A, 2015, PROCEDIA COMPUT SCI, V70, P603, DOI 10.1016/j.procs.2015.10.046
   Rao Y, 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT)
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   SHEN Z, 2017, INT C WAV AN PATT RE
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wen Quan, 2003, Acta Electronica Sinica, V31, P214
   Zhang Q, 2015, INFORM FUSION, V24, P54, DOI 10.1016/j.inffus.2014.09.008
   Zhang Z, 2016, INT CONF SIGN PROCES, P805, DOI 10.1109/ICSP.2016.7877942
   USC SIPI IM DAT, V3
NR 24
TC 11
Z9 15
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7599
EP 7614
DI 10.1007/s11042-019-08459-3
EA JAN 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000505356600013
DA 2024-07-18
ER

PT J
AU Dixit, MM
AF Dixit, Mahendra M.
TI Image quality assessment of modified adaptable VQ used in DCT based
   image compression schemes implemented on DSP and FPGA platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; VQ; Image Compression; DSP; FPGA
AB The world of electronics in particularly in the field of image processing, numerous distinguishable and noteworthy contributions have been made available. Specifically, image compression domain with unique, contextually relevant and significant attributes are embedded into real-time applications to better suit present day technologies. In this context, an attempt is made to suggest modifications to existed standard Vector Quantization (VQ) matrix used in Discrete Cosine Transform (DCT) based image compression, evaluating performance of the algorithm by means of functional verification, on software platform. The assessment of reconstructed image quality is carried out by varying VQ levels (Q-Factor) from level 10 to 90, by using performance metrics such as Mean Square Error (MSE), Peak Signal to Noise Ratio (PSNR), Compression Ratio (CR), Bits per Pixel (bpp) and percentage Space Saving respectively. Here in this research endeavour, four different experimentations have been carried out. Amongst them, two experiments have been re-investigated through simulation process to check the correctness of the algorithms, without modifications and rest of the two experiments have been the revised versions of the same, respectively. Further, the algorithms are tested by implementing on Digital Signal Processor (DSP) DSK-TMS320C6713 and Field Programmable Gate Array (FPGA) Virtex5 XC5VSX50T. The work presented here also focus and discuss about the possible merits and demerits by incorporating comparative assessment of all the techniques.
C1 [Dixit, Mahendra M.] KLS VDIT, Dept Elect & Commun Engn, Haliyal, Karnataka, India.
RP Dixit, MM (corresponding author), KLS VDIT, Dept Elect & Commun Engn, Haliyal, Karnataka, India.
EM mmdixitmm@yahoo.co.in
CR Alkim E, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S0218126617501560
   [Anonymous], SYST GEN DSP GETT ST
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], INNOVATIONS COMPUTER
   [Anonymous], N4674 MPEG ISOMPEG
   [Anonymous], LECT NOTES NETWORKS
   Chang C-C, 2005, 19 INT C ADV INF NET, V1, DOI [10.1109/AINA.2005.55, DOI 10.1109/AINA.2005.55]
   Dixit Mahendra M., 2019, Journal of the Institution of Engineers (India): Series B (Electrical, Electronics & Telecommunication and Computer Engineering), V100, P447, DOI 10.1007/s40031-019-00392-1
   Dixit Mahendra M., 2019, International Journal of Information Technology, V11, P203, DOI 10.1007/s41870-018-0162-8
   Dixit MM, 2019, ENG SCI TECHNOL, V22, P840, DOI 10.1016/j.jestch.2018.12.010
   Hasnat A, 2017, J INTELL FUZZY SYST, V32, P3711, DOI 10.3233/JIFS-169304
   Hsieh CH, 2000, J VIS COMMUN IMAGE R, V11, P374, DOI 10.1006/jvci.2000.0452
   Kekre HB, 2010, IETE J RES, V56, P257, DOI 10.4103/0377-2063.72996
   Kornblum JD, 2008, DIGIT INVEST, V5, pS21, DOI 10.1016/j.diin.2008.05.004
   Qiming Fu, 2015, Journal of Communications, V10, P629, DOI 10.12720/jcm.10.8.629-637
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Tseng H-W., 2005, Informatica, V29
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yan CG, 2018, IEEE T MULTIMEDIA, V20, P3389, DOI 10.1109/TMM.2018.2838320
NR 19
TC 2
Z9 2
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 163
EP 182
DI 10.1007/s11042-019-07987-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600008
DA 2024-07-18
ER

PT J
AU Saba, T
   Bashardoost, M
   Kolivand, H
   Rahim, MSM
   Rehman, A
   Khan, MA
AF Saba, Tanzila
   Bashardoost, Morteza
   Kolivand, Hoshang
   Rahim, Mohd Shafry Mohd
   Rehman, Amjad
   Khan, Muhammad Attique
TI Enhancing fragility of zero-based text watermarking utilizing effective
   characters list
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Authentication; Tamper detection; Zero-based watermarking;
   Fragility; Effective characters list
AB Text is an important medium used for sharing information worldwide. For a text document, digital watermarking is an efficient way for copyright protection, authentication, tamper proofing, to name but a few. In this paper, a zero-based watermarking approach is proposed for document authentication and tamper detection. To enhance the fragility of watermark, the proposed text watermarking approach can be comfortably utilized - based on the Effective Characters List (ECL) for watermark generation. The ECL method is generated for English text zero-watermarking by maintaining the contents of the original document and constructing the watermark by formulating the smooth transition between the selected characters in the documents. The evaluation of the proposed watermarking approach is based on three famous watermarking attacks including deletion, insertion, and reordering with an accuracy of 80.76%, 80.36%, and 88.1%, respectively. For a fair evaluation, a comparison is put forth with a recent zero-based watermarking method - clearly showing that the proposed method outperforms existing with greater accuracy.
C1 [Saba, Tanzila] Prince Sultan Univ, Coll Comp & Informat Sci, Riyadh 11586, Saudi Arabia.
   [Bashardoost, Morteza; Rahim, Mohd Shafry Mohd] Univ Teknol Malaysia, UIRL, Inst Human Ctr, Media Ctr, Skudai, Johor, Malaysia.
   [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
   [Rehman, Amjad] Imam Mohammad Ibn Saud Islamic Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci & Engn, Museum Rd, Taxila, Pakistan.
C3 Prince Sultan University; Universiti Teknologi Malaysia; Liverpool John
   Moores University; University of Liverpool; Imam Mohammad Ibn Saud
   Islamic University (IMSIU); NITEC University
RP Rehman, A (corresponding author), Imam Mohammad Ibn Saud Islamic Univ, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM drtsaba@gmail.com; rkamjad@gmail.com
RI Kolivand, Hoshang/F-4736-2011; Rehman, Amjad/GXV-0915-2022; Khan, Dr.
   Muhammad Attique/AAX-2644-2021; khan, sajid/HGE-2406-2022; Saba,
   Tanzila/D-4593-2018; Kolivand, Hoshang/B-2501-2016
OI Rehman, Amjad/0000-0002-3817-2655; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Saba, Tanzila/0000-0003-3138-3801;
   Kolivand, Hoshang/0000-0001-5460-5679
FU Artificial Intelligence and Data Analytics (AIDA) Lab Prince Sultan
   University Riyadh Saudi Arabia
FX "This work is the output of the collaboration of Department of Computer
   Science, Liverpool John Moores University, Liverpool, UK, University
   Industry Research Laboratory (UIRL), Universiti Teknologi Malaysia UTM,
   Skudai, Johor, Malaysia This work was also collaborated, supported by
   Artificial Intelligence and Data Analytics (AIDA) Lab Prince Sultan
   University Riyadh Saudi Arabia. Authors are thankful for the support".
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Addison A., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI [10.1080/19409052.2016.1267657, DOI 10.17485/ijst/2016/v9i48/87787]
   Adnan G., 2010, Bahria University Journal of Information Communication Technology, V3, P68
   Ahmad AM, 2014, J INTELL SYST, V23, P451, DOI 10.1515/jisys-2014-0007
   Al-Wesabi FN, 2012, P NAT C REC TRENDS C
   Alkawaz MH, 2016, SECUR COMMUN NETW, V9, P6365, DOI 10.1002/sec.1738
   Alotaibi RA, 2018, APPL COMPUTING INFOR
   Alotaibi RA, 2018, J KING SAUD UNIV-COM, V30, P236, DOI 10.1016/j.jksuci.2016.12.007
   Ba-Alwi F. M., 2014, INT J APPL INFORM SY, V7, P25, DOI DOI 10.1109/NOORIC.2013.20
   Bashardoost M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0118-y
   BLACKWELL D, 1953, ANN MATH STAT, V24, P265, DOI 10.1214/aoms/1177729032
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Di Martino F, 2019, J AMB INTEL HUM COMP, V10, P2041, DOI 10.1007/s12652-018-0806-3
   Feng B, 2019, MOBILE NETW APPL, P1
   Ghilan MM., 2014, INT J COMPUTATIONAL, V5, P26
   Hemida O, 2018, MULTIMED TOOLS APPL, P1
   Husain A, 2015, PRINTED DOCUMENT FOR
   Jalil Z., 2010, WORLD ACAD SCI ENG T, V46, P592
   Kamaruddin NS, 2018, IEEE ACCESS, V6, P8011, DOI 10.1109/ACCESS.2018.2796585
   Krishna GJ, 2018, APPL SOFT COMPUT
   Patel H.A., 2018, ADV COMPUTER COMPUTA, P455, DOI DOI 10.1007/978-981-10-3773-3_44
   Pramoun T, 2009, 2009 9 INT S COMM IN
   Qin C, 2018, IEEE MULTIMEDIA, V25, P36, DOI 10.1109/MMUL.2018.112142509
   Saxena S, 2019, AIP C P
   Singh M, 2017, IMAGE WATERMARKING U
   Sinha Samman, 2018, Procedia Computer Science, V132, P557, DOI 10.1016/j.procs.2018.05.009
   Taleby Ahvanooey M, 2018, COMP ANAL INFORM HID
   Tan LN, 2019, MULTIMED TOOLS APPL, V78, P13189, DOI 10.1007/s11042-018-5771-5
   Tayan O, 2013, INT C ADV COMP INF T
   Tayan O, 2014, SCI WORLD J, DOI 10.1155/2014/514652
   Walke A., 2018, International Journal on Recent and Innovation Trends in Computing and Communication, V6, P35
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zheng W, 2018, 2018 13 IEEE C IND E
   Zhenjiu X, 2017, J IMAGE GRAPH, V3, P2
NR 35
TC 6
Z9 6
U1 5
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 341
EP 354
DI 10.1007/s11042-019-08084-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600014
DA 2024-07-18
ER

PT J
AU Xia, YF
   Lou, JW
   Dong, JY
   Qi, L
   Li, GF
   Yu, H
AF Xia, Yifan
   Lou, Jianwen
   Dong, Junyu
   Qi, Lin
   Li, Gongfa
   Yu, Hui
TI Hybrid regression and isophote curvature for accurate eye center
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; Eye tracking; Eye gaze estimation; Eye
   center localization
ID CENTER LOCATION; FACE DETECTION; RECOGNITION
AB The eye center localization is a crucial requirement for various human-computer interaction applications such as eye gaze estimation and eye tracking. However, although significant progress has been made in the field of eye center localization in recent years, it is still very challenging for tasks under the significant variability situations caused by different illumination, shape, color and viewing angles. In this paper, we propose a hybrid regression and isophote curvature for accurate eye center localization under low resolution. The proposed method first applies the regression method, which is called Supervised Descent Method (SDM), to obtain the rough location of eye region and eye centers. SDM is robust against the appearance variations in the eye region. To make the center points more accurate, isophote curvature method is employed on the obtained eye region to obtain several candidate points of eye center. Finally, the proposed method selects several estimated eye center locations from the isophote curvature method and SDM as our candidates and a SDM-based means of gradient method further refine the candidate points. Therefore, we combine regression and isophote curvature method to achieve robustness and accuracy. In the experiment, we have extensively evaluated the proposed method on the two public databases which are very challenging and realistic for eye center localization and compared our method with existing state-of-the-art methods. The results of the experiment confirm that the proposed method outperforms the state-of-the-art methods with a significant improvement in accuracy and robustness and has less computational complexity.
C1 [Xia, Yifan; Lou, Jianwen; Yu, Hui] Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.
   [Dong, Junyu; Qi, Lin] Ocean Univ China, Dept Comp Sci & Technol, Qingdao, Peoples R China.
   [Li, Gongfa] Wuhan Univ Sci & Technol, Key Lab Met Equipment & Control Technol, Wuhan, Peoples R China.
C3 University of Portsmouth; Ocean University of China; Wuhan University of
   Science & Technology
RP Yu, H (corresponding author), Univ Portsmouth, Sch Creat Technol, Portsmouth, Hants, England.; Li, GF (corresponding author), Wuhan Univ Sci & Technol, Key Lab Met Equipment & Control Technol, Wuhan, Peoples R China.
EM ligongfa@wust.edu.cn; hui.yu@port.ac.uk
RI wang, wjd/GSD-2051-2022; Yu, Hui/G-1115-2018
OI Yu, Hui/0000-0002-7655-9228
FU EPSRC through project 4D Facial Sensing and Modelling [EP/N025849/1];
   Royal Academy of Engineering through the project Multimodal Data-based
   Mental Workload and Stress Assessment for Assistive Brain-Computer
   Interface [NRCP1516/1/74]; Open Fund of the Key Laboratory for
   Metallurgical Equipment and Control of Ministry of Education in Wuhan
   University of Science and Technology [2017B05]; National Natural Science
   Foundation of China [51575407]; EPSRC [EP/N025849/1] Funding Source:
   UKRI
FX This work was supported by the EPSRC through project 4D Facial Sensing
   and Modelling (EP/N025849/1). This work was supported by the Royal
   Academy of Engineering through the project Multimodal Data-based Mental
   Workload and Stress Assessment for Assistive Brain-Computer Interface
   (NRCP1516/1/74). This work was supported in part by the Open Fund of the
   Key Laboratory for Metallurgical Equipment and Control of Ministry of
   Education in Wuhan University of Science and Technology [grant number
   2017B05]. And this work was supported by grants of National Natural
   Science Foundation of China (Grant No. 51575407).
CR [Anonymous], MULTIMEDIA TOOLS APP
   Asadifard M, 2010, LECT NOTES ENG COMP, P130
   Asteriadis S, 2006, INT S CONTR COMM SIG
   Bai L, 2006, INT C PATT RECOG, P511
   Bao HF, 2019, MULTIMED TOOLS APPL, V78, P14633, DOI 10.1007/s11042-018-6754-2
   Behnke S, 2002, LECT NOTES COMPUT SC, V2415, P1319
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cai HB, 2015, INT CONF MACH LEARN, P759, DOI 10.1109/ICMLC.2015.7340650
   Cai HB, 2016, LECT NOTES COMPUT SC, V9834, P300, DOI 10.1007/978-3-319-43506-0_26
   Campadelli P., 2006, BRIT MACHINE VISION, P187
   Chen D, 2006, LECT NOTES COMPUT SC, V3972, P20
   Cristinacce D., 2004, BMVC, P231
   Cyganek B, 2014, NEUROCOMPUTING, V126, P78, DOI 10.1016/j.neucom.2013.01.048
   George A, 2016, IET COMPUT VIS, V10, P660, DOI 10.1049/iet-cvi.2015.0316
   Gou C, 2016, INT C PATT RECOG, P3362, DOI 10.1109/ICPR.2016.7900153
   Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179
   Jang YM, 2014, NEUROCOMPUTING, V128, P421, DOI 10.1016/j.neucom.2013.08.008
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Kim S, 2007, PROC WRLD ACAD SCI E, V19, P483
   Kroon B., 2008, P 2008 INT C CONT BA, P379
   Leo M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102829
   Leo M, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033033
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Niu ZH, 2006, INT C PATT RECOG, P1216
   Soelistio YE, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P349, DOI 10.1109/MVA.2015.7153202
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Turkan Mehmet, 2007, VISAPP 2007. Second International Conference on Computer Vision Theory and Applications, P410
   Valenti R, 2008, PROC CVPR IEEE, P1452
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Villanueva A, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2501643.2501647
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang W, 2019, INT J AUTOM COMPUT, V16, P93, DOI 10.1007/s11633-016-1022-2
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhang C, 2018, MULTIMED TOOLS APPL, V77, P19679, DOI 10.1007/s11042-017-5426-y
   Zhang WH, 2016, J OPT SOC AM A, V33, P314, DOI 10.1364/JOSAA.33.000314
   Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006
NR 36
TC 8
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 805
EP 824
DI 10.1007/s11042-019-08160-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600033
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bao, ZY
   Zhang, GL
   Xiong, BS
   Gai, S
AF Bao, Zhongyun
   Zhang, Guolin
   Xiong, Bangshu
   Gai, Shan
TI New image denoising algorithm using monogenic wavelet transform and
   improved deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image de-noising; Monogenic wavelet transform; Neural network
ID COMPUTATION
AB The new image de-nosing algorithm based on improved deep convolutional neural network in the monogenic wavelet domain is proposed in this paper. The monogenic wavelet transform was employed to describe the amplitude and phase information of the noisy image. Then, the amplitude and phase information are simultaneously used as input of proposed improved convolutional neural network for denoising. Finally, the monogenic wavelet inverse transform is used to obtain the denoised image. The experimental results illustrate that the proposed algorithm achieves superior performance both in visual quality and objective peak signal-to-noise ratio values, compared with other state-of-the-art de-noising algorithms.
C1 [Bao, Zhongyun; Zhang, Guolin; Xiong, Bangshu; Gai, Shan] Nanchang Hangkong Univ, Sch Informat Engn, Nanchang 330063, Jiangxi, Peoples R China.
C3 Nanchang Hangkong University
RP Gai, S (corresponding author), Nanchang Hangkong Univ, Sch Informat Engn, Nanchang 330063, Jiangxi, Peoples R China.
EM gaishan886@163.com
FU National Natural Science Foundation of China [61563037, 61866027];
   Outstanding Youth Scheme of Jiangxi Province [20171BCB23057]; Key
   research project of Jiangxi Province [20171BBE50013]; Jiangxi Science
   Fund for Distinguished Young Scholars [20192ACB21032]
FX This work is partially supported by National Natural Science Foundation
   of China; the grant number is 61563037, 61866027; Outstanding Youth
   Scheme of Jiangxi Province; the grant number is 20171BCB23057; Key
   research project of Jiangxi Province under grant 20171BBE50013; The
   Jiangxi Science Fund for Distinguished Young Scholars under grand
   20192ACB21032, Key research project of Jiangxi Province under grant
   20171BBE50013.
CR Alessandrini M, 2013, IRBM, V34, P33, DOI 10.1016/j.irbm.2012.12.015
   Chang Y, 2017, 2017 IE C COMP VIS P, P21
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cheng WT, 2019, NEURAL COMPUT APPL, V31, P309, DOI 10.1007/s00521-018-3775-8
   Cho SI, 2018, IEEE T MULTIMEDIA, V20, P1738, DOI 10.1109/TMM.2017.2781371
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong QC, 2018, MULTIMED TOOLS APPL, V77, P31647, DOI 10.1007/s11042-018-6236-6
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DP, 2015, PROC CVPR IEEE, P213, DOI 10.1109/CVPR.2015.7298617
   Liu D, 2018, IEEE T IMAGE PROCESS, V27, P3432, DOI 10.1109/TIP.2018.2820807
   Luo BW, 2020, NEURAL COMPUT APPL, V32, P6327, DOI 10.1007/s00521-019-04141-9
   Olhede SC, 2014, IEEE T INFORM THEORY, V60, P6491, DOI 10.1109/TIT.2014.2342734
   Peng GJ, 2015, IEEE T SIGNAL PROCES, V63, P3946, DOI 10.1109/TSP.2015.2434323
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Schmidt U, 2014, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR.2014.349
   Soulard R, 2013, IEEE T IMAGE PROCESS, V22, P1070, DOI 10.1109/TIP.2012.2226902
   Unser M, 2008, IEEE T IMAGE PROCESS, V17, P2040, DOI 10.1109/TIP.2008.2004607
   Unser M, 2009, IEEE T IMAGE PROCESS, V18, P2402, DOI 10.1109/TIP.2009.2027628
   Van De Ville D, 2005, IEEE T IMAGE PROCESS, V14, P1798, DOI 10.1109/TIP.2005.857249
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Wen CB, 2018, J VIS COMMUN IMAGE R, V57, P84, DOI 10.1016/j.jvcir.2018.10.017
   Yang HF, 2018, IEEE T PATTERN ANAL, V40, P437, DOI 10.1109/TPAMI.2017.2666812
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zeng ZY, 2015, J VIS COMMUN IMAGE R, V33, P85, DOI 10.1016/j.jvcir.2015.08.014
   Zhang JJ, 2018, J VIS COMMUN IMAGE R, V55, P640, DOI 10.1016/j.jvcir.2018.07.011
   Zhang K., 2017, PROC CVPR IEEE, P3929, DOI [DOI 10.1109/CVPR.2017.300, 10.1109/CVPR.2017.300]
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang S, 2018, VIRTUAL REAL-LONDON, V22, P37, DOI 10.1007/s10055-017-0311-6
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 31
TC 9
Z9 9
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7401
EP 7412
DI 10.1007/s11042-019-08569-y
EA DEC 2019
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164600009
DA 2024-07-18
ER

PT J
AU Wang, XF
   Qi, C
AF Wang, Xiaofang
   Qi, Chun
TI Detecting action-relevant regions for action recognition using a
   three-stage saliency detection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Saliency detection; Action-relevant region; Dense
   tracking
ID MOTION; TRAJECTORIES; DESCRIPTORS; VECTOR; VIDEOS; DENSE
AB Dense tracking has been proven successful in action recognition, but it may produce a large number of features in background, which are not so relevant to actions and may hurt recognition performance. To obtain the action-relevant features for action recognition, this paper proposes a three-stage saliency detection technique to recover action-relevant regions. In the first stage, low-rank matrix recovery optimization is employed to decompose the overall motion of each sub-video (temporally split video) into a low-rank part and a sparse part, and the latter is used to compute initial saliency to discriminate candidate foreground from definite background. In the second stage, using the dictionary formed by the patches in definite background, the sparse representation for each patch in candidate foreground is obtained based on motion and appearance information to compute the refined saliency, which ensures the action-relevant regions tend to be distinguished more clearly from background. In the third stage, the saliency is spatially updated based on the motion and appearance similarity so that the action-relevant regions can be better highlighted due to the increase of spatial saliency coherence. Finally, a binary saliency map is created by comparing the updated saliency with a given threshold to indicate action-relevant regions, which is fused into dense tracking to extract action-relevant trajectory features in a video for action recognition. Experimental results on four benchmark datasets demonstrate that the proposed method performs better than the conventional dense tracking and competitively with its improved versions.
C1 [Wang, Xiaofang] Qilu Univ Technol, Shandong Acad Sci, Dept Phys, Sch Elect & Informat Engn, Jinan, Shandong, Peoples R China.
   [Qi, Chun] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Shaanxi, Peoples R China.
C3 Qilu University of Technology; Xi'an Jiaotong University
RP Wang, XF (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Dept Phys, Sch Elect & Informat Engn, Jinan, Shandong, Peoples R China.
EM wxf2012@stu.xjtu.edu.cn; qichun@mail.xjtu.edu.cn
FU National Natural Science Foundation of China [61572395]; Project of
   Shandong Province Higher Educational Science and Technology Program
   [J18KA345]
FX This work is supported in part by the National Natural Science
   Foundation of China (Grant No. 61572395) and the Project of Shandong
   Province Higher Educational Science and Technology Program (Grant No.
   J18KA345).
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], SPAMS SPARSE MODELIN
   [Anonymous], 2016, COMPUT INTEL NEUROSC, DOI DOI 10.1007/S00521-016-2680-2
   [Anonymous], BRIT MACH VIS C
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Candès EJ, 2008, J FOURIER ANAL APPL, V14, P877, DOI 10.1007/s00041-008-9045-x
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Cho J, 2014, PATTERN RECOGN, V47, P1813, DOI 10.1016/j.patcog.2013.12.004
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Jain H, 2018, IEEE IMAGE PROC, P1892, DOI 10.1109/ICIP.2018.8451237
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jiang YG, 2015, IEEE T IMAGE PROCESS, V24, P3781, DOI 10.1109/TIP.2015.2456412
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Lin Z, 2009, AUGMENTED LAGRANGE M, V9
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Lucas BD, 1981, NUTR CYCL AGROECOSYS, V83, P13
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Murthy OVR, 2015, IMAGE VISION COMPUT, V42, P22, DOI 10.1016/j.imavis.2015.06.009
   Nigam S, 2016, MULTIMED TOOLS APPL, V75, P17303, DOI 10.1007/s11042-015-3000-z
   Peng XJ, 2014, IMAGE VISION COMPUT, V32, P616, DOI 10.1016/j.imavis.2014.06.011
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Somasundaram G, 2014, COMPUT VIS IMAGE UND, V123, P1, DOI 10.1016/j.cviu.2014.01.002
   Soomro K, 2012, CRCVTR1201
   Souly N, 2016, INT J COMPUT VISION, V117, P93, DOI 10.1007/s11263-015-0853-6
   Sun J, 2010, IEEE INT CON MULTI, P322, DOI 10.1109/ICME.2010.5583046
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7
   Wang H, LEAR INRIA SUBMISSIO
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang X, 2016, J VIS COMMUN IMAGE R, V41
   Weng ZK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0250-5
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330
   Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397
   Wu YC, 2018, IEEE ACCESS, V6, P31677, DOI 10.1109/ACCESS.2018.2842428
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yao TT, 2017, PATTERN RECOGN, V64, P236, DOI 10.1016/j.patcog.2016.11.012
   Yi Y, 2018, MULTIMED TOOLS APPL, V77, P17709, DOI 10.1007/s11042-017-5209-5
NR 54
TC 4
Z9 4
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7413
EP 7433
DI 10.1007/s11042-019-08535-8
EA DEC 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164600002
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Wu, XQ
   Li, ZY
AF Pan, Zhibin
   Wu, Xiuquan
   Li, Zhengyi
TI Scale-adaptive local binary pattern for texture classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary pattern (LBP); Scale-adaptive; Majority vote strategy;
   Maximal difference magnitude; Scale invariance; Texture classification
ID GRAY-SCALE; ROTATION; RETRIEVAL; FEATURES
AB Local binary pattern (LBP) has already been proved to be a powerful measure of image texture with fixed sampling scheme: all P neighbor pixels in a single-scale are usually sampled by using a fixed radius R. It can effectively address grayscale and rotation variations. However, the LBP method is sensitive to image noise and fails to achieve desirable performance for texture classification with significant scale changes. With the aim to deal with these disadvantages of LBP, a new method named scale-adaptive local binary pattern (SALBP) is proposed in this paper. The essence of our proposed SALBP method is to adaptively find a single but optimal scale from multiple scales for each radial direction in accordance with the characteristics of a local area. First, we select candidates of neighbors by the majority vote strategy for signs. Second, we determine final neighbor pixels by the maximal difference magnitude selection strategy for magnitudes of candidates. This procedure lets each neighbor pixel to adaptively obtain its own optimal scale from multiple scales, which refers to the adaptive optimal sampling radius. Therefore, scale invariance can be significantly improved. Extensive experiments on four public texture databases (i.e., Outex, CUReT, UIUC and Brodatz) demonstrate that the proposed SALBP method achieves significantly better results than representative LBP variants for texture classification tasks with a smaller feature dimension.
C1 [Pan, Zhibin; Wu, Xiuquan; Li, Zhengyi] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Pan, Zhibin] Chinese Acad Sci, Key Lab Spectral Imaging Technol, Xian 710119, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Chinese Academy of Sciences
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.; Pan, ZB (corresponding author), Chinese Acad Sci, Key Lab Spectral Imaging Technol, Xian 710119, Shaanxi, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Zhejiang Provincial Natural Science Foundation of China [LQY19F010001]
FX This work is supported by Zhejiang Provincial Natural Science Foundation
   of China under Grant No. LQY19F010001.
CR Andrysiak T, 2005, INT J AP MAT COM-POL, V15, P471
   [Anonymous], 2014, Proceedings of the Eurographics Workshop on 3D Object Retrieval
   ANYS H, 1995, IEEE T GEOSCI REMOTE, V33, P1170, DOI 10.1109/36.469481
   Biasotti S, 2016, VISUAL COMPUT, V32, P217, DOI 10.1007/s00371-015-1146-3
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313
   DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P251, DOI 10.1109/TPAMI.1979.4766921
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Ji LP, 2018, IEEE T CYBERNETICS, V48, P2683, DOI 10.1109/TCYB.2017.2748500
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Li R, 2018, IEEE ACCESS, V6, P45681, DOI 10.1109/ACCESS.2018.2865627
   Li Z, 2012, IEEE T IMAGE PROCESS, V21, P2130, DOI 10.1109/TIP.2011.2173697
   Liu L, 2014, IEEE T IMAGE PROCESS, V23, P3071, DOI 10.1109/TIP.2014.2325777
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2017, EXPERT SYST APPL, V88, P238, DOI 10.1016/j.eswa.2017.07.007
   Pan ZB, 2017, IEEE SIGNAL PROC LET, V24, P828, DOI 10.1109/LSP.2017.2694460
   Pan ZB, 2015, IEEE T IMAGE PROCESS, V24, P5379, DOI 10.1109/TIP.2015.2476955
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Schaefer G, 2012, INT C PATT RECOG, P2500
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song W, 2018, EXPERT SYST APPL, V96, P347, DOI 10.1016/j.eswa.2017.12.006
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu XS, 2017, VISUAL COMPUT, V33, P317, DOI 10.1007/s00371-015-1202-z
   Xiao Y, 2017, INFORM SCIENCES, V420, P77, DOI 10.1016/j.ins.2017.08.059
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 37
TC 12
Z9 14
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5477
EP 5500
DI 10.1007/s11042-019-08205-9
EA DEC 2019
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000500863700005
DA 2024-07-18
ER

PT J
AU Talat, R
   Muzammal, M
   Shan, R
AF Talat, R.
   Muzammal, M.
   Shan, R.
TI A decentralised approach to scene completion using distributed feature
   hashgram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decentralised scene completion; Fog computing; Image synthesis
ID IMAGE; QUANTIZATION; ALGORITHMS
AB Scene completion is automated image reconstruction in a plausible way. Typically, semantically valid images are retrieved by pair-wise comparison and subsequently a completion candidate is selected. The primary challenge in scene completion is the computational cost of pair-wise comparisons which increases geometrically with the increase in the number of images. Another challenge is a large number of incoming completion requests which are to be completed on a centralised server. In this work, we propose a decentralised scene completion system using distributed feature hashgram. The system comprises of two principal components, (i) a deep signature-based decentralised image retrieval component that retrieves semantically valid images by way of signature comparison, and (ii) a fog computing enabled scene completion algorithm which finds optimal patches from the most suitable retrieved image to fill in the missing parts using graph-cut technique. A detailed experimental study on LabelMe dataset is performed to evaluate the quality of the solution. Another challenge in scene completion is the absence of ground truth. We propose an evaluation method to evaluate the image completion in the absence of ground truth. The results demonstrate the novelty of the system and the applicability of the solution for large image data repositories.
C1 [Talat, R.; Muzammal, M.] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
   [Shan, R.] COMSATS Univ, Dept Comp Sci, Abbottabad Campus, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Talat, R (corresponding author), Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
EM romanatalat.buic@bahria.edu.pk; mmuzammal.buic@bahria.edu.pk;
   shan@ciit.net.pk
RI Shan, Rafi us/AAC-9670-2020; Muzammal, Muhammad/AAE-8185-2022
OI Muzammal, Muhammad/0000-0001-8817-1629
CR Abbasi F, 2018, INT CONF DAT MIN WOR, P144, DOI 10.1109/ICDMW.2018.00027
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chum O, 2010, IEEE T PATTERN ANAL, V32, P371, DOI 10.1109/TPAMI.2009.166
   Chum Ondrej., 2008, BMVC, P1
   Criminisi A., 2003, PROC CVPR IEEE, V2, pII, DOI DOI 10.1109/CVPR.2003.1211538
   Demir U., 2018, Patch-based image inpainting with generative adversarial networks
   Ding D, 2018, PATTERN RECOGN, V83, P174, DOI 10.1016/j.patcog.2018.05.025
   Fan Q, 2018, MULTIMED TOOLS APPL, V77, P10807, DOI 10.1007/s11042-017-5077-z
   FEDOROV V, 2016, VISAPP
   Fergus R, 2003, PROC CVPR IEEE, P264
   FILALI J, 2019, INT C COMP VIS THEOR
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   He KM, 2012, LECT NOTES COMPUT SC, V7573, P16, DOI 10.1007/978-3-642-33709-3_2
   He KM, 2013, PROC CVPR IEEE, P2938, DOI 10.1109/CVPR.2013.378
   Heo JP, 2012, PROC CVPR IEEE, P2957, DOI 10.1109/CVPR.2012.6248024
   Hore S., 2018, Computer Vision: Concepts, Methodologies, Tools, and Applications, P601
   Jin DR, 2019, IEEE T CIRC SYST VID, V29, P1310, DOI 10.1109/TCSVT.2018.2839351
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Muthanna A, 2019, J SENS ACTUAT NETW, V8, DOI 10.3390/jsan8010015
   Muzammal M, 2020, INFORM FUSION, V53, P155, DOI 10.1016/j.inffus.2019.06.021
   Muzammal M, 2018, IEEE ACCESS, V6, P4895, DOI 10.1109/ACCESS.2017.2778690
   Muzammal M, 2011, LECT NOTES COMPUT SC, V7051, P118, DOI 10.1007/978-3-642-24577-0_12
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pelka O., 2018, P 11 INT JOINT C BIO, P179, DOI [10.5220/0006732301790187., DOI 10.5220/0006732301790187]
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Qu Q, 2019, FUTURE GENER COMP SY, V98, P208, DOI 10.1016/j.future.2019.03.038
   Rao B. Janardhana, 2018, IETE Journal of Education, V59, P26, DOI 10.1080/09747338.2018.1474808
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   VOGEL C, 2018, ARXIV181103721
   Wang HX, 2017, NEUROCOMPUTING, V269, P90, DOI 10.1016/j.neucom.2016.08.149
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Weiss P, 2008, INT CONF ACOUST SPEE, P1173, DOI 10.1109/ICASSP.2008.4517824
   Xiao M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0200404
   Yeh RA, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6772, DOI 10.1109/ICASSP.2018.8462317
   Yu JH, 2019, IEEE I CONF COMP VIS, P4470, DOI 10.1109/ICCV.2019.00457
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   YUHENG S, 2018, ARXIV180804121
   Zhao YN, 2019, IEEE WINT CONF APPL, P1514, DOI 10.1109/WACV.2019.00166
NR 46
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9799
EP 9817
DI 10.1007/s11042-019-08403-5
EA DEC 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000500178200003
DA 2024-07-18
ER

PT J
AU Li, L
   Sun, RZ
   Cai, SH
   Zhao, KY
   Zhang, QQ
AF Li, Li
   Sun, Ruizhi
   Cai, Saihua
   Zhao, Kaiyi
   Zhang, Qianqian
TI A review of improved extreme learning machine methods for data stream
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Data streams; Classification; Improved extreme leaning machine; Concept
   drifts; Imbalanced data streams; Uncertain data streams
ID INTRUSION DETECTION SYSTEM; DRIFTING DATA STREAMS; CLASS IMBALANCE;
   ONLINE; ENSEMBLE; ALGORITHM; UNCERTAIN; NETWORK; SCHEME; MODEL
AB Classification is a hotspot in data stream mining and has gained increasing interest from various research fields. Compared with traditional data stream classification methods, Extreme Learning Machine (ELM) has attracted much attention because of its efficiency and simplicity, which inspired the development of many improved ELM algorithms that have been proposed in the past few years. This paper mainly reviews the current state of ELM used to classify data streams and its variants. First, we introduce the principles of ELM and the existing problems of data stream classification. Then we provide an overview of various improvements made to ELM, which further improves its stability, accuracy and generalization ability and present the practical applications of ELM used in data stream classification. Finally, the paper highlights the existing problems of ELM used for data stream mining and development prospects of ELM in the future.
C1 [Li, Li; Sun, Ruizhi; Cai, Saihua; Zhao, Kaiyi; Zhang, Qianqian] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Sun, Ruizhi] Minist Agr, Sci Res Base Integrated Technol Precis Agr Anim H, Beijing 100083, Peoples R China.
C3 China Agricultural University; Ministry of Agriculture & Rural Affairs
RP Sun, RZ (corresponding author), China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.; Sun, RZ (corresponding author), Minist Agr, Sci Res Base Integrated Technol Precis Agr Anim H, Beijing 100083, Peoples R China.
EM sunruizhi@cau.edu.cn
OI Zhang, Qianqian/0000-0003-2825-6238; Cai, Saihua/0000-0003-0743-1156
CR AI-Behadili H, 2015, 2015 3 INT C IM INF
   Aljawarneh S, 2018, J COMPUT SCI-NETH, V25, P152, DOI 10.1016/j.jocs.2017.03.006
   [Anonymous], 2015, 2015 INT JOINT C NEU
   [Anonymous], 2015, INT J U E SERVICE SC
   [Anonymous], 2007, Data Streams, DOI DOI 10.1007/978
   [Anonymous], 2018, ARXIV180506525
   [Anonymous], INT C REL INF COMM T
   Atli BG, 2018, COGN COMPUT, V10, P848, DOI 10.1007/s12559-018-9564-y
   Bloodgood M., 2009, Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL, (Morristown, NJ, USA), P137
   Bordes A, 2005, J MACH LEARN RES, V6, P1579
   Cao JW, 2015, J FRANKLIN I, V352, P4528, DOI 10.1016/j.jfranklin.2015.07.002
   Cao JW, 2013, IEEE INT SYMP CIRC S, P2327, DOI 10.1109/ISCAS.2013.6572344
   Cao KY, 2016, NEUROCOMPUTING, V174, P194, DOI 10.1016/j.neucom.2015.05.121
   Cao KY, 2015, COGN COMPUT, V7, P150, DOI 10.1007/s12559-014-9279-7
   Cavalcante RC, 2015, IEEE IJCNN
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Deng SZ, 2020, IEEE T SYST MAN CY-S, V50, P123, DOI 10.1109/TSMC.2017.2757029
   Deng WY, 2016, NEUROCOMPUTING, V174, P72, DOI 10.1016/j.neucom.2015.06.087
   Deo RC, 2016, ENVIRON MONIT ASSESS, V188, DOI 10.1007/s10661-016-5094-9
   DING S, 2013, ARTIF INTELL, V44, P103, DOI DOI 10.1007/S10462-013-9405-Z
   Ding SF, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/129021
   Ding SY, 2018, NEUROCOMPUTING, V277, P139, DOI 10.1016/j.neucom.2017.02.102
   Ditzler G, 2013, IEEE T KNOWL DATA EN, V25, P2283, DOI 10.1109/TKDE.2012.136
   Domingos P., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P71, DOI 10.1145/347090.347107
   Dongre B., 2014, 2014 IEEE INT ADV CO
   Dongre PB, 2014, IEEE INT ADV COMPUT, P533
   Duan LJ, 2017, COGN COMPUT, V9, P758, DOI 10.1007/s12559-017-9494-0
   Duan LJ, 2016, PROC ADAPT LEARN OPT, V6, P361, DOI 10.1007/978-3-319-28397-5_28
   Eirola E, 2015, LECT NOTES COMPUT SC, V9095, P153, DOI 10.1007/978-3-319-19222-2_13
   Fan W, 2003, 3 IEEE INT C DAT MIN, V51
   Gao J, 2008, IEEE INTERNET COMPUT, V12, P37, DOI 10.1109/MIC.2008.119
   Ghazikhani A, 2013, NEUROCOMPUTING, V122, P535, DOI 10.1016/j.neucom.2013.05.003
   Gomes HM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054925
   Gu Y, 2014, NEUROCOMPUTING, V128, P119, DOI 10.1016/j.neucom.2013.02.047
   Guo W, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/6195387
   Nguyen HL, 2015, KNOWL INF SYST, V45, P535, DOI 10.1007/s10115-014-0808-1
   Han DH, 2015, J COMPUT SCI TECH-CH, V30, P874, DOI 10.1007/s11390-015-1566-6
   Han DH, 2018, NEUROCOMPUTING, V277, P149, DOI 10.1016/j.neucom.2017.03.094
   Han DH, 2015, APPL INTELL, V43, P773, DOI 10.1007/s10489-015-0675-9
   Han F, 2017, NEUROCOMPUTING, V228, P133, DOI 10.1016/j.neucom.2016.09.092
   Homayoun S., 2016, J ADV COMPUT SCI TEC, V5, P8, DOI [10.14419/jacst.v5i1.5225, DOI 10.14419/JACST.V5I1.5225]
   Huang G, 2015, NEURAL NETWORKS, V61, P32, DOI 10.1016/j.neunet.2014.10.001
   Huang GB, 2005, IEEE T NEURAL NETWOR, V16, P57, DOI 10.1109/TNN.2004.836241
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2004, IEEE T SYST MAN CY B, V34, P2284, DOI 10.1109/TSMCB.2004.834428
   Huang GB, 2008, NEUROCOMPUTING, V71, P3460, DOI 10.1016/j.neucom.2007.10.008
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Hulten G., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P97, DOI 10.1145/502512.502529
   Janardan SM, 2017, PROCEDIA COMPUT SCI, V122, P804, DOI 10.1016/j.procs.2017.11.440
   Junhai Z, 2014, IEEE INT C SYST MAN
   Kasun L. L. C., 2013, IEEE INTELL SYST
   Khan I, 2016, NEUROCOMPUTING, V191, P34, DOI 10.1016/j.neucom.2016.01.009
   Kim Y, 2013, NEUROCOMPUTING, V102, P65, DOI 10.1016/j.neucom.2011.12.048
   Krawczyk B, 2016, PROG ARTIF INTELL, V5, P221, DOI 10.1007/s13748-016-0094-0
   Krawczyk B, 2016, PROCEDIA COMPUT SCI, V80, P1692, DOI 10.1016/j.procs.2016.05.509
   Krawczyk B, 2015, NEUROCOMPUTING, V150, P238, DOI 10.1016/j.neucom.2014.10.025
   Kuang YX, 2017, CLUSTER COMPUT, V20, P3051, DOI 10.1007/s10586-017-0985-2
   Kumar S, 2018, ENERG BUILDINGS, V176, P275, DOI 10.1016/j.enbuild.2018.06.056
   Lan Y, 2009, NEUROCOMPUTING, V72, P3391, DOI 10.1016/j.neucom.2009.02.013
   Li PP, 2015, NEUROCOMPUTING, V166, P68, DOI 10.1016/j.neucom.2015.04.024
   Li PP, 2011, LECT NOTES ARTIF INT, V6634, P313, DOI 10.1007/978-3-642-20841-6_26
   Li YC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192216
   Liang NY, 2006, IEEE T NEURAL NETWOR, V17, P1411, DOI 10.1109/TNN.2006.880583
   Lindenbaum M, 2004, MACH LEARN, V54, P125, DOI 10.1023/B:MACH.0000011805.60520.fe
   Liu N, 2010, IEEE SIGNAL PROC LET, V17, P754, DOI 10.1109/LSP.2010.2053356
   Lu YW, 1997, NEURAL COMPUT, V9, P461, DOI 10.1162/neco.1997.9.2.461
   Luo X, 2015, INT J CONTROL AUTOM, V13, P539, DOI 10.1007/s12555-014-0309-8
   Mirza B, 2016, NEURAL NETWORKS, V80, P79, DOI 10.1016/j.neunet.2016.04.008
   Mirza B, 2015, IEEE INT SYMP CIRC S, P565, DOI 10.1109/ISCAS.2015.7168696
   Mirza B, 2015, NEUROCOMPUTING, V149, P316, DOI 10.1016/j.neucom.2014.03.075
   Mirza B, 2013, NEURAL PROCESS LETT, V38, P465, DOI 10.1007/s11063-013-9286-9
   Mohammadi K, 2015, COMPUT ELECTRON AGR, V117, P214, DOI 10.1016/j.compag.2015.08.008
   Ouyang ZZ, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL IV, PROCEEDINGS, P360, DOI 10.1109/AICI.2009.153
   Pan SR, 2010, LECT NOTES ARTIF INT, V6118, P488
   Platt J, 1991, NEURAL COMPUT, V3, P213, DOI 10.1162/neco.1991.3.2.213
   Polikar R, 2010, PATTERN RECOGN, V43, P3817, DOI 10.1016/j.patcog.2010.05.028
   Qiu JF, 2016, EURASIP J ADV SIG PR, DOI 10.1186/s13634-016-0355-x
   Ramírez-Gallego S, 2017, NEUROCOMPUTING, V239, P39, DOI 10.1016/j.neucom.2017.01.078
   Roshan S, 2018, J FRANKLIN I, V355, P1752, DOI 10.1016/j.jfranklin.2017.06.006
   Samat A, 2014, IEEE J-STARS, V7, P1060, DOI 10.1109/JSTARS.2014.2301775
   Savitha R, 2014, COGN COMPUT, V6, P253, DOI 10.1007/s12559-013-9223-2
   Scardapane S, 2015, IEEE T NEUR NET LEAR, V26, P2214, DOI 10.1109/TNNLS.2014.2382094
   Seliya Naeem, 2010, 2010 IEEE International Conference on Information Reuse & Integration (IRI 2010), P49, DOI 10.1109/IRI.2010.5558967
   Shamshirband S, 2016, CLIM DYNAM, V46, P1893, DOI 10.1007/s00382-015-2682-2
   Shao ZF, 2016, NEUROCOMPUTING, V173, P778, DOI 10.1016/j.neucom.2015.08.029
   Shukla A, 2017, 2017 7 INT C COMM SY
   Shukla S., 2015, 2015 IEEE International Conference on Computational Intelligence and Computing Research (ICCIC), P1
   Sun J, 2018, SEQUENTIAL HUMAN ACT
   Tennant M, 2017, FUTURE GENER COMP SY, V75, P187, DOI 10.1016/j.future.2017.03.026
   Tian HX, 2010, IEEE T AUTOM SCI ENG, V7, P73, DOI 10.1109/TASE.2008.2005640
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Wang GG, 2016, NEURAL COMPUT APPL, V27, P291, DOI 10.1007/s00521-015-1874-3
   Wang LY, 2016, NEUROCOMPUTING, V174, P278, DOI 10.1016/j.neucom.2015.03.114
   Wang YB, 2015, NEUROCOMPUTING, V149, P415, DOI 10.1016/j.neucom.2014.04.073
   Wang Z, 2012, J MACH LEARN RES, V13, P3103
   Wenhua Xu, 2011, Information Technology Journal, V10, P1926, DOI 10.3923/itj.2011.1926.1933
   Wu DG, 2016, NEUROCOMPUTING, V190, P35, DOI 10.1016/j.neucom.2015.11.095
   Xiao WD, 2017, NEUROCOMPUTING, V261, P70, DOI 10.1016/j.neucom.2016.09.120
   Xin Y, 2017, 2017 INT JOINT C NEU
   Xu SL, 2017, NEUROCOMPUTING, V238, P433, DOI 10.1016/j.neucom.2016.12.078
   Xu SL, 2016, EXPERT SYST APPL, V65, P332, DOI 10.1016/j.eswa.2016.08.052
   Xue XW, 2014, NEUROCOMPUTING, V129, P175, DOI 10.1016/j.neucom.2013.09.042
   Yadav B, 2016, MEASUREMENT, V92, P433, DOI 10.1016/j.measurement.2016.06.042
   Yang R, 2018, ALGORITHMS, V11, DOI 10.3390/a11070107
   Yu CH, 2014, INT J CONTROL AUTOM, V12, P618, DOI 10.1007/s12555-013-0238-y
   Yu HL, 2019, IEEE T NEUR NET LEAR, V30, P1088, DOI 10.1109/TNNLS.2018.2855446
   Yu HL, 2015, NEUROCOMPUTING, V166, P140, DOI 10.1016/j.neucom.2015.04.019
   Zhai JH, 2012, SOFT COMPUT, V16, P1493, DOI 10.1007/s00500-012-0824-6
   Zhang P, 2009, LECT NOTES ARTIF INT, V5476, P1021, DOI 10.1007/978-3-642-01307-2_109
   Zhang Y, 2017, J INTELL FUZZY SYST, V33, P1143, DOI 10.3233/JIFS-16724
   Zhao JW, 2012, NEUROCOMPUTING, V87, P79, DOI 10.1016/j.neucom.2012.02.003
   Zhenyu C, 2013, 2013 IEEE C CYB INT
   Zhiyuan M, 2016, 2016 8 INT C ADV COM
   Zhou WN, 2013, INT J CONTROL AUTOM, V11, P919, DOI 10.1007/s12555-012-9511-8
   Zhu Jingbo, 2007, P 2007 JOINT C EMP M
   Zhu X, 2002, IEEE T COMMUN, V50, P187, DOI 10.1109/26.983313
   Zong WW, 2013, NEUROCOMPUTING, V101, P229, DOI 10.1016/j.neucom.2012.08.010
NR 119
TC 18
Z9 21
U1 0
U2 70
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33375
EP 33400
DI 10.1007/s11042-019-7543-2
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600037
DA 2024-07-18
ER

PT J
AU Pal, K
   Govil, MC
   Ahmed, M
AF Pal, Kunwar
   Govil, Mahesh Chandra
   Ahmed, Mushtaq
TI FLHyO: fuzzy logic based hybrid overlay for P2P live video streaming
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE P2P; Peer-to-Peer network; Live video streaming; Overlay; Fuzzy logic;
   Resource utilization; Content delivery network
AB In recent times, enormous growth has been observed in the field of media streaming and real-time communication using peer-to-peer (P2P) network. The popularity of P2P network for live streaming can be credited to its fundamental characteristics such as a decentralized model, low complexity and scalability. Some of the key factors that affect the performance of P2P live streaming are overlay, scheduling schemes and selfish peer. Many structured and unstructured P2P overlay construction techniques have been introduced till now. But both type of overlays have proven to be inadequate in fulfilling the requirements of today's streaming systems. Generally, the peers in a P2P network are heterogeneous, isolated and mobile in nature. It is difficult to construct an overlay in such a way that resource utilization along with other QoS parameters in the network is maximal. So in this paper, we propose a novel Fuzzy Logic based Hybrid Overlay (FLHyO). FLHyO uses the fuzzy system for determining the priority of each peer during overlay creation. Some of the other factors considered by FLHyO for overlay creation are geographical location, upload bandwidth, age and utilization of a peer. A comparative analysis of FLHyO with some of the landmark overlay approaches verifies that our proposed approach provides better quality of service (QoS) in the network and also improves the video quality at receiver side.
C1 [Pal, Kunwar; Ahmed, Mushtaq] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
   [Govil, Mahesh Chandra] Natl Inst Technol, Sikkim, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur; National Institute of Technology (NIT
   System); National Institute of Technology Sikkim
RP Pal, K (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur, Rajasthan, India.
EM kunwar.11mar@gmail.com; govilmc@gmail.com; mahmed.cse@mnit.ac.in
RI Ahmed, Mushtaq/GSN-9818-2022; PAL, KUNWAR/A-5785-2019
OI PAL, KUNWAR/0000-0001-9482-696X; AHMED, MUSHTAQ/0000-0002-7576-2531
CR [Anonymous], 2003, P WORKSH EC PEER PEE
   [Anonymous], 2001, Pastry: Scalable, decentralized object location, and routing for large-scale peer-to-peer systems, DOI DOI 10.1007/3-540-45518-3_18
   [Anonymous], 2010, CONSUM COMM NETWORK
   [Anonymous], 2016, CISC VIS NETW IND GL
   Baccichet P, 2007, INT PACK VID WORKSH, V16, P173
   Baumgart I, 2007, 2007 IEEE GLOBAL INTERNET SYMPOSIUM, P79, DOI 10.1109/GI.2007.4301435
   Byun H, 2009, 11TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, PROCEEDINGS,, P840
   Chuiwei Lu, 2012, Journal of Networks, V7, P377, DOI 10.4304/jnw.7.2.377-384
   Hammami C, 2014, PROCEDIA COMPUT SCI, V32, P158, DOI 10.1016/j.procs.2014.05.410
   Huang Q, 2007, ICPPW 07, P55
   Iancu I., 2012, A Mamdani Type Fuzzy Logic Controller (Fuzzy Logic - Controls, Concepts, Theories and Applications)
   Jannotti J., 2000, OSDI 00 P 4 C S OPER, P14
   Jo YM, 2011, IEEE INT C SEMANT CO, P438, DOI 10.1109/ICSC.2011.61
   Karakaya M, 2009, IEEE INTERNET COMPUT, V13, P92, DOI 10.1109/MIC.2009.33
   Li B, 2007, IEEE J SEL AREA COMM, V25, P1627, DOI 10.1109/JSAC.2007.071203
   Liu HI, 2010, INT CON ADV INFO NET, P1136, DOI 10.1109/AINA.2010.144
   Loo BT, 2009, COMMUN ACM, V52, P87, DOI 10.1145/1592761.1592785
   Lua EK, 2005, IEEE COMMUN SURV TUT, V7, P72, DOI 10.1109/COMST.2005.1610546
   Magharei N, 2007, IEEE ACM T NETWORK, V17, P1052
   Magharei N., 2006, P 2006 INT WORKSH NE, P10
   Malkhi Dahlia., 2002, Proceedings of the 21st annual symposium on Principles of distributed computing PODC, P183
   MAMDANI EH, 1975, INT J MAN MACH STUD, V7, P1, DOI 10.1016/S0020-7373(75)80002-2
   Marchant T, 2007, IEEE T FUZZY SYST, V15, P238, DOI 10.1109/TFUZZ.2006.880000
   Maymounkov P, 2002, LECT NOTES COMPUT SC, V2429, P53
   Mol JJD, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P342, DOI 10.1109/ISM.2009.16
   Nen-Fu Huang, 2010, Proceedings of the 2010 International Conference on Communications and Mobile Computing (CMC 2010), P541, DOI 10.1109/CMC.2010.317
   Pal K., 2017, INT J INTELL ENG SYS, V10, P343
   Pal K, 2018, INT J COMMUN SYST, V2, P31
   Ratnasamy S, 2001, ACM SIGCOMM COMP COM, V31, P161, DOI 10.1145/964723.383072
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shah B, 2016, IEEE INT C SEMANT CO, P154, DOI 10.1109/ICSC.2016.39
   Shah B, 2014, 2014 IEEE 12TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC)/2014 IEEE 12TH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING (EMBEDDEDCOM)/2014 IEEE 12TH INTERNATIONAL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING (PICOM), P173, DOI 10.1109/DASC.2014.39
   Shen ZJ, 2011, P IEEE, V99, P2089, DOI 10.1109/JPROC.2011.2165330
   Stoica I, 2003, IEEE ACM T NETWORK, V11, P17, DOI 10.1109/TNET.2002.808407
   Szymkowiak M, 2016, STAT PROBABIL LETT, V111, P41, DOI 10.1016/j.spl.2016.01.004
   Venkataraman V., 2006, CHUNKYSPREAD MULTITR
   Vlavianos Aggelos., 2006, Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications, P1
   Wang Fu-bin, 2007, Natural Gas Industry, V27, P49
   Xie S, 2007, IEEE T MULTIMEDIA, V9, P1661, DOI 10.1109/TMM.2007.907469
   Zhang M, 2007, IEEE J SEL AREA COMM, V25, P1678, DOI 10.1109/JSAC.2007.071207
   Zhang X., 2005, P IEEE INFOCOM, V3, P13
   Zhao BY, 2004, IEEE J SEL AREA COMM, V22, P41, DOI 10.1109/JSAC.2003.818784
NR 42
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33679
EP 33702
DI 10.1007/s11042-019-08010-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600051
DA 2024-07-18
ER

PT J
AU Chaibou, MS
   Conze, PH
   Kalti, K
   Mahjoub, MA
   Solaiman, B
AF Chaibou, Mahaman Sani
   Conze, Pierre-Henri
   Kalti, Karim
   Mahjoub, Mohamed Ali
   Solaiman, Basel
TI Learning contextual superpixel similarity for consistent image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context description; Superpixels similarity; Machine learning; Random
   forests; Image segmentation; Region-growing
ID VIDEO SEGMENTATION; SALIENCY DETECTION; RECOGNITION; TRACKING; CUTS
AB This paper addresses the problem of image segmentation by iterative region aggregations starting from an initial superpixel decomposition. Classical approaches for this task compute superpixel similarity using distance measures between superpixel descriptor vectors. This usually poses the well-known problem of the semantic gap and fails to properly aggregate visually non-homogeneous superpixels that belong to the same high-level object. This work proposes to use random forests to learn the merging probability between adjacent superpixels in order to overcome the aforementioned issues. Compared to existing works, this approach learns the fusion rules without explicit similarity measure computation. We also introduce a new superpixel context descriptor to strengthen the learned characteristics towards better similarity prediction. Image segmentation is then achieved by iteratively merging the most similar superpixel pairs selected using a similarity weighting objective function. Experimental results of our approach on four datasets including DAVIS 2017 and ISIC 2018 show its potential compared to state-of-the-art approaches.
C1 [Chaibou, Mahaman Sani; Kalti, Karim; Mahjoub, Mohamed Ali] Univ Sousse, Ecole Natl Ingn Sousse, LATIS Lab Adv Technol & Intelligent Syst, Sousse 4023, Tunisia.
   [Chaibou, Mahaman Sani] Univ Sousse, Inst Super Informat & Tech Commun, Hammam Sousse 4011, Tunisia.
   [Chaibou, Mahaman Sani; Conze, Pierre-Henri; Solaiman, Basel] Technopole Brest Iroise, IMT Atlantique, CS 83818, F-29238 Brest 03, France.
   [Conze, Pierre-Henri] INSERM, IBRBS, LaTIM UMR 1101, 22 Rue Camille Desmoulins, F-29238 Brest, France.
   [Kalti, Karim] Univ Monastir, Fac Sci Monatir, Monastir 5019, Tunisia.
C3 Universite de Sousse; Universite de Sousse; IMT - Institut
   Mines-Telecom; IMT Atlantique; Institut National de la Sante et de la
   Recherche Medicale (Inserm); Universite de Bretagne Occidentale;
   Universite de Monastir
RP Chaibou, MS (corresponding author), Univ Sousse, Ecole Natl Ingn Sousse, LATIS Lab Adv Technol & Intelligent Syst, Sousse 4023, Tunisia.; Chaibou, MS (corresponding author), Univ Sousse, Inst Super Informat & Tech Commun, Hammam Sousse 4011, Tunisia.; Chaibou, MS (corresponding author), Technopole Brest Iroise, IMT Atlantique, CS 83818, F-29238 Brest 03, France.
EM sallaoudt@gmail.com
RI Mahjoub, Mohamed Ali/AAO-6170-2020; Conze, Pierre-Henri/AAE-9248-2020
OI Mahjoub, Mohamed Ali/0000-0002-8181-4684; Conze,
   Pierre-Henri/0000-0003-2214-3654
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   Audebert N, 2017, JOINT URB REMOTE SEN
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Bhatti AH, 2019, SIGNAL IMAGE VIDEO P, V13, P9, DOI 10.1007/s11760-018-1322-9
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Brahim K, 2019, SIGNAL IMAGE VIDEO P, V13, P1055, DOI 10.1007/s11760-019-01445-0
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breiman L., 2002, MANUAL SETTING USING, V1
   Chaibou MS, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.6.061605
   Chen CLZ, 2018, IEEE T MULTIMEDIA, V20, P3324, DOI 10.1109/TMM.2018.2839523
   Chen CZ, 2017, IEEE T IMAGE PROCESS, V26, P3156, DOI 10.1109/TIP.2017.2670143
   Conze PH, 2017, INT J COMPUT ASS RAD, V12, P223, DOI 10.1007/s11548-016-1493-1
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Fukuchi K, 2009, IEEE INT CON MULTI, P638, DOI 10.1109/ICME.2009.5202577
   Godec M, 2013, COMPUT VIS IMAGE UND, V117, P1245, DOI 10.1016/j.cviu.2012.11.005
   Granitto PM, 2006, CHEMOMETR INTELL LAB, V83, P83, DOI 10.1016/j.chemolab.2006.01.007
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Haller E, 2017, IEEE I CONF COMP VIS, P5095, DOI 10.1109/ICCV.2017.544
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Haralick R. M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V548, P2, DOI [10.1016/S0734-189X(85)90153-7, 10.1117/12.948400]
   Hsu CY, 2012, INT CONF SIGN PROCES, P1, DOI 10.1109/ICoSP.2012.6491517
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Louppe G., 2013, ADV NEURAL INFORM PR, P431, DOI DOI 10.5555/2999611.2999660
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Meila M, 2007, J MULTIVARIATE ANAL, V98, P873, DOI 10.1016/j.jmva.2006.11.013
   Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48
   Ozuysal M., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383123
   PAULY O, 2012, THESIS
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pont-Tuset J., 2017, ARXIV170400675
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   SANGSEFIDI N, 2017, COMPUTERS BIOL MED
   Santana A, 2016, IEEE INT ENTERP DIST, P30
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SILVA RE, 2017, ALTERNATIVE APPROACH
   Son J, 2015, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2015.350
   STUTZ D, 2016, CORR
   Tilquin F, 2018, LECT NOTES COMPUT SC, V11075, P39, DOI 10.1007/978-3-030-00500-9_5
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Vargas JE, 2015, INT GEOSCI REMOTE SE, P1132, DOI 10.1109/IGARSS.2015.7325970
   Vasconcelos M., 2015, COMPUTATIONAL EXPT B, P237
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Yang YF, 2016, OPTIK, V127, P161, DOI 10.1016/j.ijleo.2015.10.053
   Yeo D, 2017, PROC CVPR IEEE, P511, DOI 10.1109/CVPR.2017.62
   Yin Pei., 2007, P IEEE C COMPUTER VI, P1, DOI DOI 10.1109/CVPR.2007.383008
   YIN S, 2017, PATTERN RECOGNITION
   Yu H, 2013, IEEE T GEOSCI REMOTE, V51, P995, DOI 10.1109/TGRS.2012.2203604
   ZHANG D, 2013, VIDEO OBJECT SEGMENT
   Zhang YM, 2017, DESTECH TRANS COMP, P351
NR 52
TC 5
Z9 5
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2601
EP 2627
DI 10.1007/s11042-019-08391-6
EA NOV 2019
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NR2VD
UT WOS:000498201300001
DA 2024-07-18
ER

PT J
AU Mendez, MO
   Azpiroz-Leehan, J
   Sacristan-Rock, E
   Arce-Santana, ER
   Alba, A
   Arce-Guevara, VE
AF Mendez, Martin O.
   Azpiroz-Leehan, Joaquin
   Sacristan-Rock, Emilio
   Arce-Santana, Edgar R.
   Alba, Alfonso
   Arce-Guevara, Valdemar E.
TI Assisted quantification of abdominal adipose tissue based on magnetic
   resonance images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Segmentation; Abdominal fat; Active contours; Shape-based interpolation
ID INTENSITY INHOMOGENEITIES; UNSUPERVISED ASSESSMENT; INSULIN-RESISTANCE;
   UNITED-STATES; BODY-FAT; SEGMENTATION; SOFTWARE; OBESITY; PREVALENCE;
   CHILDREN
AB An assisted method to segment Visceral Adipose Tissue (VAT) and Subcutaneous Adipose Tissue (SAT) from Magnetic Resonance Imaging (MRI) slices is presented. The segmentation process, called shape-based segmentation, consists in three main steps: 1) to draw a series of closed curves at different slices that separates the abdominal structures of interest, 2) to generate a 3D model from the closed curves for each abdominal structure by using shape-based interpolation and 3) to apply a segmentation algorithm to define the adipose tissue. The 3D models considerably simplify the problem since the abdominal structures are separated, and in turn, this reduces the possibility of large segmentation errors. In addition, a fully automatic segmentation procedure was also implemented. Twenty slices of MRI at the abdominal region for each of twelve subjects were analysed. The results of the shape-based and automatic segmentation were compared with the expert segmentation carried out in the slice located at the umbilicus level. Correlation Coefficient (CC) and volume error (VE) were used as performance measures. The comparison between the expert and shape-based segmentation for SAT yielded results of CC= 0.974 and VE=-0.01 +/- 5.8 cm(3), while for VAT the performance indexes were CC= 0.993 and VE= 0.9 +/- 1.8 cm(3). The results suggest that the shape-based segmentation provides an accurate and simple assessment of the abdominal adiposity with minimal human intervention and it could be used as a simple tool in clinics.
C1 [Mendez, Martin O.; Arce-Santana, Edgar R.; Alba, Alfonso; Arce-Guevara, Valdemar E.] Univ Autonoma San Luis Potosi, Fac Ciencias, Lab Nacl CI3M, San Luis Potosi, San Luis Potosi, Mexico.
   [Mendez, Martin O.; Arce-Santana, Edgar R.; Alba, Alfonso; Arce-Guevara, Valdemar E.] Univ Autonoma San Luis Potosi, CICSaB, San Luis Potosi, San Luis Potosi, Mexico.
   [Azpiroz-Leehan, Joaquin; Sacristan-Rock, Emilio] Univ Autonoma Metropolitana Iztapalapa, Lab Nacl CI3M, Mexico City, DF, Mexico.
C3 Universidad Autonoma de San Luis Potosi; Universidad Autonoma de San
   Luis Potosi; Universidad Autonoma Metropolitana - Mexico
RP Mendez, MO (corresponding author), Univ Autonoma San Luis Potosi, Fac Ciencias, Lab Nacl CI3M, San Luis Potosi, San Luis Potosi, Mexico.; Mendez, MO (corresponding author), Univ Autonoma San Luis Potosi, CICSaB, San Luis Potosi, San Luis Potosi, Mexico.
EM mmendez@fc.uaslp.mx; ci3m@me.com; esacristan@ci3m.mx;
   arce@fciencias.uaslp.mx; fac@fc.uaslp.mx; valdemar@fc.uaslp.mx
RI Alba, Alfonso/J-4684-2012
OI Arce-Guevara, Valdemar Emigdio/0000-0001-7973-7758
CR Azpiroz J, 2013, 2013 PAN AM HLTH CAR, P1
   Baglioni S, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036569
   Bonekamp S, 2008, INT J OBESITY, V32, P100, DOI 10.1038/sj.ijo.0803696
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fields DA, 2002, AM J CLIN NUTR, V75, P453, DOI 10.1093/ajcn/75.3.453
   Flegal KM, 2013, JAMA-J AM MED ASSOC, V309, P71, DOI 10.1001/jama.2012.113905
   Florin C, 2007, LECT NOTES COMPUT SC, V4584, P38
   Frederiksen L, 2009, J CLIN ENDOCR METAB, V94, P4010, DOI 10.1210/jc.2009-0980
   Grainger AT, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204071
   Gronemeyer SA, 2000, MAGN RESON IMAGING, V18, P815, DOI 10.1016/S0730-725X(00)00168-5
   Heckel F, 2010, P 2 EUR C VIS COMP B, P9
   HERMAN GT, 1992, IEEE COMPUT GRAPH, V12, P69, DOI 10.1109/38.135915
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Ibrahim MM, 2010, OBES REV, V11, P11, DOI 10.1111/j.1467-789X.2009.00623.x
   Irving BA, 2007, OBESITY, V15, P370, DOI 10.1038/oby.2007.573
   Jin YP, 2003, LECT NOTES COMPUT SC, V2878, P635
   Klein S, 2004, J CLIN INVEST, V113, P1530, DOI 10.1172/JCI200422028
   Kuczmarski RJ, 1996, AM J CLIN NUTR, V64, P453, DOI 10.1093/ajcn/64.3.453S
   Kullberg J, 2007, INT J OBESITY, V31, P1806, DOI 10.1038/sj.ijo.0803671
   Langner T, 2019, MAGN RESON MED, V81, P2736, DOI 10.1002/mrm.27550
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Machann J, 2005, J MAGN RESON IMAGING, V21, P455, DOI 10.1002/jmri.20292
   Ogden CL, 2016, JAMA-J AM MED ASSOC, V315, P2292, DOI 10.1001/jama.2016.6361
   Ogden CL, 2014, JAMA-J AM MED ASSOC, V311, P806, DOI 10.1001/jama.2014.732
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan YS, 2011, COMPUT VIS IMAGE UND, V115, P1375, DOI 10.1016/j.cviu.2011.06.003
   Poon M, 2008, COMPUT MED IMAG GRAP, V32, P639, DOI 10.1016/j.compmedimag.2008.07.004
   Positano V, 2004, J MAGN RESON IMAGING, V20, P684, DOI 10.1002/jmri.20167
   Positano V, 2008, J MAGN RESON IMAGING, V28, P403, DOI 10.1002/jmri.21448
   Preis SR, 2010, OBESITY, V18, P2191, DOI 10.1038/oby.2010.59
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schenk A, 2000, LECT NOTES COMPUT SC, V1935, P186
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Sun JJ, 2016, AM J HUM BIOL, V28, P757, DOI 10.1002/ajhb.22862
   Thörmer G, 2013, J MAGN RESON IMAGING, V37, P1144, DOI 10.1002/jmri.23890
   Thomas EL, 1998, J APPL PHYSIOL, V85, P1778, DOI 10.1152/jappl.1998.85.5.1778
   TOKUNAGA K, 1983, INT J OBESITY, V7, P437
   Wang DF, 2015, MED BIOL ENG COMPUT, V53, P1247, DOI 10.1007/s11517-015-1347-y
   WANG J, 1989, AM J PHYSIOL, V256, pE829, DOI 10.1152/ajpendo.1989.256.6.E829
   Wang YZ, 2017, COMPUT METH PROG BIO, V144, P97, DOI 10.1016/j.cmpb.2017.03.017
   Weston AD, 2019, RADIOLOGY, V290, P669, DOI 10.1148/radiol.2018181432
   Zhou AQ, 2011, J MAGN RESON IMAGING, V34, P852, DOI 10.1002/jmri.22673
NR 44
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1519
EP 1534
DI 10.1007/s11042-019-08360-z
EA NOV 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493973100001
DA 2024-07-18
ER

PT J
AU Termritthikun, C
   Jamtsho, Y
   Muneesawang, P
AF Termritthikun, Chakkrit
   Jamtsho, Yeshi
   Muneesawang, Paisarn
TI An improved residual network model for image recognition using a
   combination of snapshot ensembles and the cutout technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Image recognition; Convolutional neural networks; ResNet;
   Snapshot ensembles; Cutout technique
AB NUF-Net (Naresuan University and Fiber One Public Company Limited Network) is a new and improved Convolutional Neural Network (CNN) model based on the previously developed NU-LiteNet model. Improvements in accuracy were achieved by adding the identity mapping technique of the ResNet model and incorporating Snapshot Ensembles and the Cutout technique into the NU-LiteNet model. We modified the structure of the convolution layers by changing any filters of a size larger than 3 x3, into a 3 x3 filter, thereby significantly reducing processing time and reducing the error rate. To test the effectiveness of our modifications, we developed 10 variations of the NUF-Net-Residual model, one of which, termed NUF-Net-Residual-102, achieved significantly lower error rates than both ResNet and Wide-ResNet when using CIFAR-10, CIFAR-100 and Tiny-ImageNet datasets. The relative error rates were 2.94% for CIFAR-10, 17.57% for CIFAR-100 and 29.57% for Tiny-ImageNet. As well, NUF-Net-Residual-102 achieved a model parameter size of 31.65 million which is a lower value than for Wide-ResNet-32 (46.16 million), although higher than ResNet-1202 (19.42 million).
C1 [Termritthikun, Chakkrit; Jamtsho, Yeshi; Muneesawang, Paisarn] Naresuan Univ, Fac Engn, Dept Elect & Comp Engn, Phitsanulok 65000, Thailand.
C3 Naresuan University
RP Termritthikun, C (corresponding author), Naresuan Univ, Fac Engn, Dept Elect & Comp Engn, Phitsanulok 65000, Thailand.
EM chakkritt60@email.nu.ac.th
RI Jamtsho, Yeshi/HPD-7094-2023; Muneesawang, Paisarn/AFS-0172-2022;
   Termritthikun, Chakkrit/AAI-1448-2020
OI Jamtsho, Yeshi/0009-0006-0975-7458; Termritthikun,
   Chakkrit/0000-0002-1508-3123
FU Thailand Research Fund [PHD/0101/2559]
FX The authors would like to acknowledge the financial support from the
   Thailand Research Fund through the Royal Golden Jubilee Ph.D. Program
   (Grant No. PHD/0101/2559). We would also like to extend our appreciation
   to Mr. Roy I. Morien of the Naresuan University Graduate School for his
   assistance in editing the English grammar and expression in the paper.
CR [Anonymous], 2017, ARXIV170600388
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   DeVries T, 2017, PREPRINT
   El-Rahiem Basma Abd., 2019, INT C ADV MACHINE LE, P23
   Gad R, 2018, FUTURE GENER COMP SY, V89, P178, DOI 10.1016/j.future.2018.06.020
   GOODFELLOW IJ, 2013, ARXIV3024389
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Huang G., 2017, ARXIV170400109
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   KIM Y, 2017, ARXIV170106190
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Li K, 2018, IEEE T GEOSCI REMOTE, V56, P2337, DOI 10.1109/TGRS.2017.2778300
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Loshchilov I., 2017, P INT C LEARN REPR
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Peng JL, 2013, IEICE T INF SYST, VE96D, P1886, DOI 10.1587/transinf.E96.D.1886
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Romero A., 2014, ARXIV14126550
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Srivastava RK, 2015, ARXIV150500387
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   TERMRITTHIKUN C, 2019, ECTI T COMPUTER INFO, V13, P21
   Termritthikun C., 2017, J. Telecommun. Electron. Comput. Eng., V9, P63
   Termritthikun C., 2018, J. Telecommun. Electron. Comput. Eng., V10, P29
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wang N, 2014, MULTIMED TOOLS APPL, V71, P1411, DOI 10.1007/s11042-012-1278-7
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
NR 38
TC 7
Z9 7
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1475
EP 1495
DI 10.1007/s11042-019-08332-3
EA NOV 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000493692500001
DA 2024-07-18
ER

PT J
AU Ma, S
   Zhao, XF
   Liu, YQ
AF Ma, Sai
   Zhao, Xianfeng
   Liu, Yaqi
TI Adaptive spatial steganography based on adversarial examples
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Adversarial attack; Deep learning; Steganalysis
ID IMAGE; STEGANALYSIS
AB Recently, the researchers start to apply adversarial attack to enhance the security of steganographic algorithms. The typical deep learning model is vulnerable to adversarial attack. Such attack is generating special instance via neural network. The generated instance can increase the detection error of the steganalyzer. In this paper, we propose a practical adversarial method to enhance the security of typical distortion-minimizing steganographic algorithms. The proposed method is an adaptation of the Fast Gradient Sign Method in the steganography. We utilize the gradients back-propagated from the deep-learning steganalyzer to control the changing direction of the pixels. This kind of steganaographic modification in the image helps to improve the security towards the steganalysis. The experimental results prove that the proposed method can enhance the security of typical distortion-minimizing steganaographic algorithms.
C1 [Ma, Sai; Zhao, Xianfeng; Liu, Yaqi] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Ma, Sai; Zhao, Xianfeng; Liu, Yaqi] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhao, XF (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Zhao, XF (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM masai@iie.ac.cn; zhaoxianfeng@iie.ac.cn; liuyaqi@iie.ac.cn
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU NSFC [U1736214, U1636102, 61802393, 61872356]; National Key Technology
   RD Program [2016QY15Z2500]; Project of Beijing Municipal Science &
   Technology Commission [Z181100002718001]
FX This work was supported by NSFC under U1736214, U1636102, 61802393 and
   61872356, National Key Technology R&D Program under 2016QY15Z2500, and
   Project of Beijing Municipal Science & Technology Commission under
   Z181100002718001.
CR [Anonymous], 2013, INTRIGUING PROPERTIE
   [Anonymous], 2017, ARXIV170305502
   [Anonymous], P SPIE EL IM SEC FOR
   [Anonymous], 2019, MULTIMED TOOLS APPL
   [Anonymous], 2015, P 3 ACM WORKSH INF H
   [Anonymous], 2012 IEEE INT WORKSH
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Denemark T, 2017, INT CONF ACOUST SPEE, P2117, DOI 10.1109/ICASSP.2017.7952530
   Denemark T, 2017, IEEE T INF FOREN SEC, V12, P2308, DOI 10.1109/TIFS.2017.2705625
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Fridrich J, 2013, INT CONF ACOUST SPEE, P2949, DOI 10.1109/ICASSP.2013.6638198
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goodfellow I.J., 2014, ARXIV 14126572
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li B, 2015, IEEE T INF FOREN SEC, V10, P1905, DOI 10.1109/TIFS.2015.2434600
   Li B, 2014, IEEE T INF FOREN SEC, V9, P1264, DOI 10.1109/TIFS.2014.2326954
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Tan SQ, 2014, ASIAPAC SIGN INFO PR
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Tang WX, 2017, IEEE SIGNAL PROC LET, V24, P1547, DOI 10.1109/LSP.2017.2745572
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
   Yedroudj M, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2092, DOI 10.1109/ICASSP.2018.8461438
   Zhang WM, 2017, IEEE T CIRC SYST VID, V27, P2274, DOI 10.1109/TCSVT.2016.2587388
   Zhang YW, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P67, DOI 10.1145/3206004.3206012
NR 31
TC 15
Z9 18
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32503
EP 32522
DI 10.1007/s11042-019-07994-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000064
DA 2024-07-18
ER

PT J
AU Wang, HB
   Li, HH
   Fu, XP
AF Wang, Huibing
   Li, Haohao
   Fu, Xianping
TI Auto-weighted Mutli-view Sparse Reconstructive Embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view; Sparse representation; Auto-weighted Mutli-view Sparse
   Reconstructive Embedding; Dimension reduction
ID CANONICAL CORRELATION-ANALYSIS; MULTIVIEW
AB With the development of multimedia era, multi-view data is generated in various fields. Contrast with those single-view data, multi-view data brings more useful information and should be carefully excavated. Therefore, it is essential to fully exploit the complementary information embedded in multiple views to enhance the performances of many tasks. Especially for those high-dimensional data, how to develop a multi-view dimension reduction algorithm to obtain the low-dimensional representations is of vital importance but chanllenging. In this paper, we propose a novel multi-view dimensional reduction algorithm named Auto-weighted Mutli-view Sparse Reconstructive Embedding (AMSRE) to deal with this problem. AMSRE fully exploits the sparse reconstructive correlations between features from multiple views. Furthermore, it is equipped with an auto-weighted technique to treat multiple views discriminatively according to their contributions. Various experiments have verified the excellent performances of the proposed AMSRE.
C1 [Wang, Huibing; Fu, Xianping] Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Peoples R China.
   [Li, Haohao] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Peoples R China.
C3 Dalian Maritime University; Dalian University of Technology
RP Fu, XP (corresponding author), Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Peoples R China.
EM huibing.wang@dlmu.edu.cn; haohaoli@mail.dlut.edu.cn; fxp@dlmu.edu.cn
RI Li, Hao Hao/GSN-1035-2022
OI Li, Haohao/0000-0002-0171-1205
FU National Natural Science Foundation of China [61370142, 61272368];
   Fundamental Research Funds for the Central Universities [3132016352];
   Fundamental Research of Ministry of Transport of P.R. China
   [2015329225300]
FX This study was funded by the National Natural Science Foundation of
   China Grant 61370142 and Grant 61272368, by the Fundamental Research
   Funds for the Central Universities Grant 3132016352, by the Fundamental
   Research of Ministry of Transport of P.R. China Grant 2015329225300.
   Huibing Wang, Haohao Li and Xianping Fu declare that they have no
   conflict of interest. Both Huibing Wang and Haohao Li contribute equally
   to this paper. This article does not contain any studies with human
   participants or animals performed by any of the authors.
CR Agarwal M, 2009, WSEAS INT C SENS
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2018, IEEE Trans. Multimedia
   [Anonymous], 2018, ARXIV180710097
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Chunhua Shen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2601, DOI 10.1109/CVPR.2011.5995447
   DENOEUX T, 1995, IEEE T SYST MAN CYB, V25, P804, DOI 10.1109/21.376493
   FANT E, 1994, J AGR ENG RES, V58, P89, DOI 10.1006/jaer.1994.1038
   Feng L., 2018, IEEE T SYSTEMS MAN C
   Feng L, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.5.053002
   Gao XB, 2008, PATTERN RECOGN, V41, P3179, DOI 10.1016/j.patcog.2008.03.025
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Hu QC, 2017, IEEE T INTELL TRANSP, V18, P3147, DOI 10.1109/TITS.2017.2679114
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kumar D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1413
   Liu C, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2788860
   Luo Y, 2015, IEEE T KNOWL DATA EN, V27, P3111, DOI 10.1109/TKDE.2015.2445757
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Wang HB, 2016, NEUROCOMPUTING, V216, P286, DOI 10.1016/j.neucom.2016.07.044
   Wang HB, 2016, IEEE T MULTIMEDIA, V18, P1579, DOI 10.1109/TMM.2016.2569412
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P999, DOI 10.1145/2766462.2767825
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang YP, 2017, J NETW COMPUT APPL, V99, P1, DOI 10.1016/j.jnca.2017.10.009
   Wu L, 2019, IEEE T NEURAL NETWOR
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Zhang W., 2016, P INT JOINT C ART IN, P2153
NR 38
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30959
EP 30973
DI 10.1007/s11042-019-07789-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200071
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yuan, L
   Wang, ML
   Cheng, HJ
AF Yuan, Ling
   Wang, MingLi
   Cheng, HongJu
TI Research of adaptive index based on slide window for spatial-textual
   query
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial-textual object; Index structure; Slide window; Self-adaptive;
   Adaptive cost model
ID SEARCH
AB Aiming at the spatial-textual continuous query with timeliness, we designed an Adaptive Index based on Slide Window, named as SWSA-Tree, which is composed of a slide window to deal with the time factor and a multi-way Self-Adjust Tree (named as SA-Tree) to index queries adaptively by their spatial and textual information. Based on the proposed index structure, we designed a spatial-textual continuous query algorithm. The experiments were conducted to compare the performance among the proposed SWSA-Tree, the index based on the quadtree and Inverted File (named as QIF) and IQ-tree. The comparison results demonstrated that the proposed adaptive index based on the slide window and the spatial-textual continuous query algorithm were with good scalability and low matching cost.
C1 [Yuan, Ling] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Wang, MingLi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Comp Software & Theory, Wuhan 430074, Hubei, Peoples R China.
   [Cheng, HongJu] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Fujian, Peoples R China.
   [Cheng, HongJu] Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou, Fujian, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology; Fuzhou University
RP Cheng, HJ (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350108, Fujian, Peoples R China.; Cheng, HJ (corresponding author), Minist Educ, Key Lab Spatial Data Min & Informat Sharing, Fuzhou, Fujian, Peoples R China.
EM cscheng@fzu.edu.cn
FU National Natural Science Fund of China [61502185, 61370210]; Fundamental
   Research Funds for the Central Universities [2017KFYXJJ071]
FX This work was supported by National Natural Science Fund of China under
   grants 61502185 and 61370210, the Fundamental Research Funds for the
   Central Universities (No: 2017KFYXJJ071).
CR Cary A, 2010, LECT NOTES COMPUT SC, V6187, P87, DOI 10.1007/978-3-642-13818-8_8
   Chen LS, 2013, PROC VLDB ENDOW, V6, P217, DOI 10.14778/2535569.2448955
   Chen SL, 2006, SOHN INTERNATIONAL SYMPOSIUM ADVANCED PROCESSING OF METALS AND MATERIALS, VOL 9, P277
   Cong G., 2013, SIGMOD, P749
   Cong G., 2009, PROC VLDB ENDOW, V2, P337, DOI DOI 10.14778/1687627.1687666
   De Felipe I, 2008, PROC INT CONF DATA, P656, DOI 10.1109/ICDE.2008.4497474
   Hariharan Ramaswamy, 2007, 2007 International Conference on Scientific and Statistical Database Management, DOI 10.1109/SSDBM.2007.22
   He J., 2011, 20 INT C INFORM KNOW, P423
   Khodaei Ali, 2010, Database and Expert Systems Applications. Proceedings 21st International Conference, DEXA 2010, P450, DOI 10.1007/978-3-642-15364-8_37
   Li ZS, 2011, IEEE T KNOWL DATA EN, V23, P585, DOI 10.1109/TKDE.2010.149
   Rocha-Junior Joao B., 2011, Advances in Spatial and Temporal Databases. Proceedings 12th International Symposium (SSTD 2011), P205, DOI 10.1007/978-3-642-22922-0_13
   Swami A, 1989, SIGMOD 89, V18, P367
   Vaid S, 2005, LECT NOTES COMPUT SC, V3633, P218
   Wu DM, 2012, VLDB J, V21, P797, DOI 10.1007/s00778-012-0271-0
   Wu DM, 2012, IEEE T KNOWL DATA EN, V24, P1889, DOI 10.1109/TKDE.2011.172
   Yan TW, 1999, ACM T DATABASE SYST, V24, P529, DOI 10.1145/331983.331992
   Zhou Y., 2005, ACM CIKM, P155
NR 17
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30221
EP 30240
DI 10.1007/s11042-018-6921-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200033
DA 2024-07-18
ER

PT J
AU Abdelfatah, RI
AF Abdelfatah, Roayat Ismail
TI A new fast double-chaotic based Image encryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chebyshev chaotic; Tent chaotic; XOR; Rotations
ID ALGORITHM; PERMUTATION; SYSTEM
AB In this paper, a new scheme for image encryption based on a double chaotic pseudo random generator (DCPG), simple XOR and shift rotations operations is proposed. The DCPG is a combination of both Tent and Chebyshev chaotic and so it needs three values of control parameters which are used as shared secret keys. The encryption consists of two rounds. In the first round, the hash value of the input image is computed using SHA-512. This value also is used as a forth shared secret key and from which, 4 amounts of the shift rotations are extracted. A pseudorandom sequence is generated using the proposed DCPG with the same size of the input image. This sequence and also the input image are divided into blocks of size 1 x 8. Each block of input image is processed with the corresponding block of the pseudorandom sequence using simple shift rotation and XOR operation. To extend the effect of the original image one pixel change to all the pixels of the cipher image, a second round of XOR operation is added. The proposed scheme has many advantages. It is highly secure due to two reasons. Firstly, it uses four secret keys for encryption which provides a large key space to overcome all types of brute force attacks. Secondly, the amounts of shift rotation used are input image dependent which achieves a strong resistance against chosen plaintext attacks. Also, it is more efficient compared to other recently existing schemes as it consists only of two rounds of simple operations. Security analysis of scheme has been provided. Based on the results, our scheme is highly secure with a reduced encryption time and so it can be used for many applications which require real time secure image communications.
C1 [Abdelfatah, Roayat Ismail] Tanta Univ, Fac Engn, Elect, Tanta, Egypt.
   [Abdelfatah, Roayat Ismail] Tanta Univ, Elect Commun Dept, Tanta, Egypt.
C3 Egyptian Knowledge Bank (EKB); Tanta University; Egyptian Knowledge Bank
   (EKB); Tanta University
RP Abdelfatah, RI (corresponding author), Tanta Univ, Fac Engn, Elect, Tanta, Egypt.; Abdelfatah, RI (corresponding author), Tanta Univ, Elect Commun Dept, Tanta, Egypt.
EM royat_esmaeel@f-eng.tanta.edu.eg
RI ismail, roayat/HKN-0154-2023
OI ismail, roayat/0000-0003-0283-8336
CR A Mohammed, 2017, INT J COMPUTER APPL, V167, P12, DOI [10.5120/ijca2017914237, DOI 10.5120/IJCA2017914237]
   Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Advanced Encryption Standard (AES), 2001, FEDERAL INFORM PROCE, V197
   Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P852, DOI 10.1016/j.procs.2015.07.494
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Juaid N, 2018, J INFORM SECURITY CY, V1
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   Alassaf N, 2019, MULTIMED TOOLS APPL, V78, P32633, DOI 10.1007/s11042-018-6801-z
   Almazrooie M, 2018, J KING SAUD U COMPUT
   Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   [Anonymous], 2017, INT J ADV RES COMPUT
   [Anonymous], 2012, INT J EMERG TECHNOL
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   Asghar MN, 2017, J VIS COMMUN IMAGE R, V45, P122, DOI 10.1016/j.jvcir.2017.02.017
   Ayoup A, 2016, MULTIMED TOOLS APPL
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Eom S, 2018, MATHEMATICS-BASEL, V6, DOI 10.3390/math6100202
   Essaid M, 2018, PROCEDIA COMPUT SCI, V127, P539, DOI 10.1016/j.procs.2018.01.153
   Gupta B.B., 2018, COMPUTER CYBER SECUR, P666
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Jiayong Tang, 2017, International Journal of High Performance Computing and Networking, V10, P515
   Jizhong Wang, 2018, International Journal of High Performance Computing and Networking, V12, P111
   Jyoti S, 2015, J EMERG TECHNOL INNO, V2, P1951
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Kong DZ, 2018, IEEE T IND INFORM, V14, P673, DOI 10.1109/TII.2017.2714261
   Kumar Manish, 2016, 2016 International Conference on Computational Techniques in Information and Communication Technologies (ICCTICT). Proceedings, P618, DOI 10.1109/ICCTICT.2016.7514653
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Madhuravani B., 2017, Journal of Theoretical and Applied Information Technology, V95, P661
   Mahmood A, 2013, ADAPTIVE ENCRYPTION
   Murillo-Escobar MA, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0698-3
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Naveenkumar SK, 2013, INT CONF RECENT, P126, DOI 10.1109/ICRTIT.2013.6844192
   Norah A, 2017, J RES ENG APPL SCI J, V2, P50, DOI DOI 10.46565/JREAS.2017.V02I02.002
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Petty T., 2016, Handbook of Research on Professional Development for Quality Teaching and Learning
   Ponuma R, 2018, MULTIMED TOOLS APPL, V77, P19209, DOI 10.1007/s11042-017-5378-2
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Rogaway P, 2004, LECT NOTES COMPUT SC, V3017, P371
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sheela S, 2016, ACCENTS T INFORM SEC, V2, P1, DOI [10.19101/tis.2017.25001, DOI 10.19101/TIS.2017.25001]
   Sufi F, 2011, SECUR COMMUN NETW, V4, P515, DOI 10.1002/sec.226
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Wu Y, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.1.013014
   Xing Y, 2018, 2018 IEEE 3 INT C DA
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2016, SECUR COMMUN NETW, V9, P2015, DOI 10.1002/sec.1458
   Ye GD, 2014, APPL SOFT COMPUT, V22, P351, DOI 10.1016/j.asoc.2014.05.025
   Yoon EJ, 2011, COMMUN NONLINEAR SCI, V16, P2383, DOI 10.1016/j.cnsns.2010.09.021
   Zhang J., 2019, International Journal of High Performance Computing and Networking, V13, P321, DOI 10.1504/IJHPCN.2019.098573
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 62
TC 17
Z9 17
U1 0
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1241
EP 1259
DI 10.1007/s11042-019-08234-4
EA OCT 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492655700001
DA 2024-07-18
ER

PT J
AU Lee, J
   Kim, M
   Kim, J
AF Lee, Jiwon
   Kim, Mingyu
   Kim, Jinmo
TI RoleVR: Multi-experience in immersive virtual reality between co-located
   HMD and non-HMD users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive virtual reality; RoleVR; Multi-experience; Asymmetric virtual
   reality; Co-located users; Presence
ID AUDIO
AB In this study, we present RoleVR, which can provide a similar high level of presence and multi experience for co-located head-mounted display (HMD) and Non-HMD users in an asymmetric virtual reality (VR) environment. The core of RoleVR is distinguishing the difference between the asymmetric environments (in terms of the system and the experience) of HMD and Non-HMD users to design optimized roles for these users. Here, we assign HMD user with spatial role that maximizes the sense of space based on three-dimensional visual information, and we assign Non-HMD user with temporal role in which they take control of communication and action, and understand the overall situation according to the flow of time. We also design an interaction for walking and a hand interface to enhance presence. This is achieved by understanding the user's role, thereby improving the immersion. Finally, we created an asymmetric VR application that considers the interaction between roles and performed survey-based experiments to verify the basic presence and multi-experience of users in RoleVR. Through this process, we confirmed that RoleVR provides satisfactory presence for co-located HMD and Non-HMD users, and a variety of experiences specialized for each role.
C1 [Lee, Jiwon] Korea Adv Inst Sci & Technol, Grad Sch Culture Technol, Daejeon, South Korea.
   [Kim, Mingyu] Korea Univ, Program Visual Informat Proc, Seoul, South Korea.
   [Kim, Jinmo] Hansung Univ, Div Comp Engn, Seoul, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Korea
   University; Hansung University
RP Kim, J (corresponding author), Hansung Univ, Div Comp Engn, Seoul, South Korea.
EM mpm11@kaist.ac.kr; kmg2917@naver.com; jinmo.kim@hansung.ac.kr
RI Kim, Jinmo/AAG-2822-2020
OI Kim, Jinmo/0000-0002-1663-9306
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [NRF-2017R1D1A1B03030286]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education(No. NRF-2017R1D1A1B03030286)).
CR [Anonymous], 2016, TEAM FUTURE BLACK HA
   Bacim F., 2012, IEEE S 3D USER INTER, P187, DOI [DOI 10.1109/3DUI.2012.6184224, 10.1109/3DUI.2012.6184224]
   CARLSSON J, 1993, IEEE AP-S, P394, DOI 10.1109/APS.1993.385323
   Carvalheiro C, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1146, DOI 10.1145/2964284.2964293
   Cheng LP, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P417
   Churchill E. F., 1998, Virtual Reality, V3, P3, DOI 10.1007/BF01409793
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Duval T., 2009, P INT C WEB3D TECHN, P33, DOI [10.1145/1559764.1559769, DOI 10.1145/1559764.1559769]
   Foreign VR, 2016, RUCK RIDG VR PART GA
   Goorts P., 2012, 2012 IEEE S 3D US IN, P177, DOI [10.1109/3DUI.2012.6184219, DOI 10.1109/3DUI.2012.6184219]
   GUGENHEIMER J, 2017, P 2017 CHI C HUM FAC, P369, DOI DOI 10.1145/3027063.3052962
   Gugenheimer J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P4021, DOI 10.1145/3025453.3025683
   Han S, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9020022
   Ibayashi Hikaru, 2015, SIGGRAPH ASIA 2015 E, P8
   IJsselsteijn Wijnand A, 2013, The Game Experience Questionnaire
   Jeong K, 2018, INT J HUM-COMPUT INT, V34, P129, DOI 10.1080/10447318.2017.1331535
   Johansen Robert, 1988, GroupWare: Computer Support for Business Teams
   Kim M, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10040109
   Knibbe J, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174057
   Kokkinara E, 2016, SCI REP-UK, V6, DOI 10.1038/srep28879
   Law ELC, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P257, DOI 10.1145/3242671.3242683
   Lee J, 2017, MAVE MAZE BASED IMME, V28, DOI [10.1002/cav.1756.E1756cav.1756, DOI 10.1002/CAV.1756.E1756CAV.1756]
   Lee J, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9050078
   Li H, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766939
   Oda O, 2015, UIST'15: PROCEEDINGS OF THE 28TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P405, DOI 10.1145/2807442.2807497
   Otto O., 2006, VRCIA 06, P145, DOI DOI 10.1145/1128923.1128947
   Sajjadi P., 2014, P 1 ACM SIGCHI ANN S, P227, DOI [10.1145/2658537.2658690, DOI 10.1145/2658537.2658690]
   Schissler C, 2016, IEEE T VIS COMPUT GR, V22, P1356, DOI 10.1109/TVCG.2016.2518134
   Sidorakis N, 2015, 2015 IEEE 1ST WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P15, DOI 10.1109/WEVR.2015.7151689
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater M, 2014, COMPUTER, V47, P24, DOI 10.1109/MC.2014.198
   Slater Mel, 1995, ACM Transactions on Computer-Human Interaction, V2, P201, DOI DOI 10.1145/210079.210084
   Stafford Aaron, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P165, DOI 10.1109/ISMAR.2006.297809
   Vasylevska K, 2013, 2013 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P39, DOI 10.1109/3DUI.2013.6550194
   Vinayagamoorthy V, 2004, COMPUT GRAPH FORUM, V23, P1, DOI 10.1111/j.1467-8659.2004.00001.x
   Violante MG, 2014, COMPUT APPL ENG EDUC, V22, P708, DOI 10.1002/cae.21564
   Voida A, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1559
   Witmer BG, 2005, PRESENCE-TELEOP VIRT, V14, P298, DOI 10.1162/105474605323384654
   Zhao Wenping, 2012, Proceedings of the ACM SIGGRAPH/eurographics symposium on computer animation. Eurographics Association, P33, DOI [10.2312/SCA/SCA12/033-042, DOI 10.2312/SCA/SCA12/033-042]
   Zheng L, 2013, CANCER METAB, V1, DOI 10.1186/2049-3002-1-12
NR 40
TC 22
Z9 24
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 979
EP 1005
DI 10.1007/s11042-019-08220-w
EA OCT 2019
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492236300001
DA 2024-07-18
ER

PT J
AU Wang, XY
   Xu, MX
   Li, Y
AF Wang, Xingyuan
   Xu, Mingxiao
   Li, Yong
TI Fast encryption scheme for 3D models based on chaos system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos System; 3D models; Scrambling-diffusion; Floating point data
ID SPATIOTEMPORAL CHAOS; MAP LATTICE; IMAGE; ALGORITHM
AB With the development of multimedia applications, the application of 3D models becomes more and more popular, and its security has become an urgent problem to be solved. 3D objects have more complex spatial structures than 1D and 2D objects. Most of the previous work is to encrypt 3D objects directly, and this kind of algorithm is often tedious and the encryption time is long. Therefore, a new fast image encryption scheme based on chaos theory is proposed in this paper. In this scheme, the 3D object is transformed into 2D object (similar to image format), and then encrypted. The encryption process is divided into two stages: confusion stage and diffusion stage. In the confusion phase, we introduce random points. In the diffusion phase, we split the floating-point data, the integer part is encrypted by XOR, and the decimal part is scrambled only. The experimental results show that the scheme can encrypt and decrypt the 3D model correctly. The numerical results in security analysis are close to the ideal value, which shows that the scheme can resist common attacks and has high security.
C1 [Wang, Xingyuan; Xu, Mingxiao; Li, Yong] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, XY; Xu, MX (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
EM xywang@dlmu.edu.cn; 1206512593@qq.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [61672124]; Password Theory
   Project of the 13th Five-Year Plan National Cryptography Development
   Fund [MMJJ20170203]; Liaoning Province Science and Technology Innovation
   Leading Talents Program Project [XLYC1802013]; Key R&D Projects of
   Liaoning Province [2019JH2/10300057]
FX This research is supported by the National Natural Science Foundation of
   China (No: 61672124), the Password Theory Project of the 13th Five-Year
   Plan National Cryptography Development Fund (No: MMJJ20170203), Liaoning
   Province Science and Technology Innovation Leading Talents Program
   Project (No: XLYC1802013), Key R&D Projects of Liaoning Province (No:
   2019JH2/10300057). The authors declare that they have no conflict of
   interest.
CR Alsmirat MA, 2019, MULTIMED TOOLS APPL, V78, P3649, DOI 10.1007/s11042-017-5537-5
   Altaf M, 2018, MULTIMED TOOLS APPL, V77, P27981, DOI 10.1007/s11042-018-6022-5
   Babaei M, 2013, NAT COMPUT, V12, P101, DOI 10.1007/s11047-012-9334-9
   Berman B, 2012, BUS HORIZONS, V55, P155, DOI 10.1016/j.bushor.2011.11.003
   Brown AC, 2013, AFRICON, P694
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta B.B., 2018, Computer and Cyber Security: Principles, Algorithm, Applications, and Perspectives
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Jiayong Tang, 2017, International Journal of High Performance Computing and Networking, V10, P515
   Jin X, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-017-9266-1
   Jizhong Wang, 2018, International Journal of High Performance Computing and Networking, V12, P111
   Jolfaei A, 2014, 3D OBJECT ENCRYPTION, V10, P409
   Kaminsky W, 2014, POWDER DIFFR, V29, pS42, DOI 10.1017/S0885715614001092
   KANEKO K, 1989, PHYSICA D, V34, P1, DOI 10.1016/0167-2789(89)90227-3
   Kusaka M, 2015, TRANSPL P, V47, P596, DOI 10.1016/j.transproceed.2014.12.045
   Li X., 2018, Int. J. Netw. Secur, V20, P110, DOI DOI 10.6633/IJNS.201801
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   del Rey AM, 2015, LECT NOTES ARTIF INT, V9121, P427, DOI 10.1007/978-3-319-19644-2_36
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Parvees MYM., 2018, INT J APPL SYST STUD, V8, P51, DOI [10.1504/IJASS.2018.091847, DOI 10.1504/IJASS.2018.091847]
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Sadkhan SB, 2015, PROCEDIA COMPUT SCI, V65, P314, DOI 10.1016/j.procs.2015.09.089
   Saraf KR, 2014, Int J Em Trends Technol Comp Sci (IJETTCS), V3, P118
   Ventola C Lee, 2014, P T, V39, P704
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang XY, 2018, IEEE ACCESS, V6, P39705, DOI 10.1109/ACCESS.2018.2855726
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2016, NONLINEAR DYNAM, V83, P333, DOI 10.1007/s11071-015-2330-8
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Xu SJ, 2008, CHINESE PHYS B, V17, P4027, DOI 10.1088/1674-1056/17/11/015
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang H, 2017, OPT LASER ENG, V88, P65, DOI 10.1016/j.optlaseng.2016.07.004
   Zhang J, 2019, IEEE T NETW SERV MAN, V16, P321, DOI 10.1109/TNSM.2018.2880222
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
NR 45
TC 16
Z9 16
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33865
EP 33884
DI 10.1007/s11042-019-08171-2
EA OCT 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000489286700001
DA 2024-07-18
ER

PT J
AU Anwar, S
   Meghana, S
AF Anwar, Shamama
   Meghana, Solleti
TI A pixel permutation based image encryption technique using chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Arnold's cat map; SSIM; Correlation coefficient; NPCR
ID ALGORITHM; SCHEME; TRANSFORM; DES
AB In the last decade, with a rapid increase in multimedia productions, image encryption has become a significant part of information security. The inherent image features make image encryption different from text encryption and also makes it difficult to encrypt images using the traditional encryption techniques. This paper presents an overview of the different encryption algorithms in details, analyzing its effect in the field of image cryptography. The paper further discusses the role of chaos theory in the field of image encryption and makes use of the chaos theory to propose an image encryption technique that is based on pixel permutation. Existing image encryption techniques produce encrypted images that resemble a texture or noise like image increasing the chance of attack as it becomes perceivable as an encrypted image. The proposed image encryption technique produces an encrypted image and masquerades it with any general image, hence eluding the attacker. The proposed algorithm is also compared with the Arnold's cat map algorithm visually as well as statistically using the evaluation metrics Structural Similarity Index (SSIM), Correlation coefficient (CC) and Number of changing Pixel Rate (NPCR).
C1 [Anwar, Shamama; Meghana, Solleti] Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Anwar, S (corresponding author), Birla Inst Technol, Dept Comp Sci & Engn, Ranchi 835215, Bihar, India.
EM shamama@bitmesra.ac.in
RI Anwar, Shamama/GWZ-7119-2022
OI Anwar, Shamama/0000-0002-2013-7181
CR Al-Khassaweneh Mahmood, 2013, International Journal of Information and Computer Security, V5, P290
   Aljawarneh S, 2018, MULTIMED TOOLS APPL, V1, P1
   Aljawarneh S, 2017, MULTIMED TOOLS APPL, V76, P22703, DOI 10.1007/s11042-016-4333-y
   [Anonymous], 2009, TENCON 2009 2009 IEE, DOI DOI 10.1109/ICIECS.2009.5364290
   Badve O., 2016, Handbook of Research on Modern Cryptographic Solutions for Computer and Cyber Security, P479, DOI DOI 10.4018/978-1-5225-0105-3.CH020
   Bhanot R, 2015, INT J SECUR APPL, V9, P289, DOI 10.14257/ijsia.2015.9.4.27
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dang PP, 2000, IEEE T CONSUM ELECTR, V46, P395, DOI 10.1109/30.883383
   Davies B., 2018, EXPLORING CHAOS THEO
   Dey S, 2018, PEERJ PREPRINTS
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Huang CK, 2013, TELECOMMUN SYST, V52, P563, DOI 10.1007/s11235-011-9461-0
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Kahate A, 2013, CRYPTOGRAPHY NETWORK, P94
   Khan MF, 2019, IEEE ACCESS, V7, P15999, DOI 10.1109/ACCESS.2019.2893176
   Konikoff J, 2010, CRYPTOLOGIA, V34, P211, DOI 10.1080/01611191003646433
   Krikor L., 2009, EUR J SCI RES, V32, P47
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu ZJ, 2013, OPT LASER ENG, V51, P8, DOI 10.1016/j.optlaseng.2012.08.004
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Nag Amitava, 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P309, DOI 10.1109/ICSCCN.2011.6024565
   Norcen R, 2003, COMPUT BIOL MED, V33, P277, DOI 10.1016/S0010-4825(02)00094-X
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patil P, 2016, PROCEDIA COMPUT SCI, V78, P617, DOI 10.1016/j.procs.2016.02.108
   Reyad O, 2017, 2017 12TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES), P455, DOI 10.1109/ICCES.2017.8275351
   Rijmen Vincent., 2001, P FEDERAL INFORM PRO, P19, DOI DOI 10.1007/978-3-662-04722-4_1
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Schaefer E. F., 1996, Cryptologia, V20, P77, DOI 10.1080/0161-119691884799
   Schneier B., 1993, INT WORKSH FAST SOFT, P191, DOI DOI 10.1007/3-540-58108-1_24
   Selent D., 2010, Rivier Academic Journal, V6, P1
   Singh P, 2017, OPT LASER ENG, V91, P187, DOI 10.1016/j.optlaseng.2016.11.022
   SMID ME, 1988, P IEEE, V76, P550, DOI 10.1109/5.4441
   Tang L., 1997, P 4 ACM INT C MULT, P219
   Vaidyanathan Sundarapandian, 2017, International Journal of Simulation and Process Modelling, V12, P165
   Wahballa Osman, 2017, International Journal of Network Security, V19, P776, DOI 10.6633/IJNS.201709.19(5).15
   Wang J, 2017, ARXIV170801541
   Wang XY, 2018, IEEE ACCESS, V6, P23733, DOI 10.1109/ACCESS.2018.2805847
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang YP, 2009, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2009.5346839
   Zhenxing Qian, 2018, IEEE Transactions on Dependable and Secure Computing, V15, P1055, DOI 10.1109/TDSC.2016.2634161
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 50
TC 37
Z9 37
U1 5
U2 125
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27569
EP 27590
DI 10.1007/s11042-019-07852-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000036
DA 2024-07-18
ER

PT J
AU Cai, B
   Zhao, JH
   Yu, XY
AF Cai, Bo
   Zhao, Jianhui
   Yu, Xiangyu
TI A methodology for 3D geological mapping and implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D geological mapping; Geophysical data interpretation; Data
   visualization; Knowledge extraction
ID AREA
AB Using 3D visualization models to exhibit geological structure has become a trend in geological studies. Compared to 2D geological mapping, 3D geological mapping is dependent on more geological sampling information. Geophysical methods (e.g., gravity, seismic, and electric) thus become the major tools in 3D geological mapping. In traditional works, people must extract the geological information from various data grids acquired through different geophysical methods and subsequently integrate the information to manually construct a 3D geological model. This approach usually causes inconvenience and inefficiencies in practice. Therefore, we propose a methodology of 3D geological mapping. It first constructs visualization models from different geophysical data grids and subsequently integrates these models for interpretation and finally converts to a 3D geological model. Based on this methodology, we implement the corresponding system which can accomplish the above process automatically. As an example, we gave a detail description for constructing the 3D lithological model by the methodology mentioned above with the geological survey data acquired in the western Jungger, Xinjiang of China. The demonstration show us that the methodology can effectively solve the matter of 3D geological modeling in case of enriched in geophysical data but in lack of sufficient geological sampling information.
C1 [Cai, Bo; Zhao, Jianhui] Wuhan Univ, Informat Ctr, Wuhan 430072, Hubei, Peoples R China.
   [Cai, Bo] Wuhan Univ, Sch Comp, Wuhan 430072, Hubei, Peoples R China.
   [Yu, Xiangyu] China Univ Geosci, Inst Geophys & Geomat, Hubei Subsurface Multiscale Imaging Key Lab, Wuhan 430074, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University; China University of Geosciences
RP Yu, XY (corresponding author), China Univ Geosci, Inst Geophys & Geomat, Hubei Subsurface Multiscale Imaging Key Lab, Wuhan 430074, Hubei, Peoples R China.
EM yu_xiangyu@qq.com
OI Cai, Bo/0000-0001-5261-0191
CR Brown CJ, 2008, ESTUAR COAST SHELF S, V78, P203, DOI 10.1016/j.ecss.2007.11.026
   Chalke T, 2012, STRUCTURAL GEOLOGY R, P16
   Dantas E.L., 2003, REV BRAS GEOCIENCIAS, V33, P65
   Gong JY, 2004, COMPUT GEOSCI-UK, V30, P391, DOI 10.1016/j.cageo.2003.06.003
   Huang W, 2010, KSII T INTERNET INF, V4, P575, DOI 10.3837/tiis.2010.08.008
   Jaques A.I., 1997, AGSO J. Aust. Geol. Geophys., V17, P159
   Jessell M, 2001, COMPUT GEOSCI-UK, V27, P455, DOI 10.1016/S0098-3004(00)00142-4
   Lim JS, 2005, J PETROL SCI ENG, V49, P182, DOI 10.1016/j.petrol.2005.05.005
   Malehmir A, 2009, GEOPHYSICS, V74, pB9, DOI 10.1190/1.3008053
   Martelet G, 2004, TECTONOPHYSICS, V382, P117, DOI 10.1016/j.tecto.2003.12.009
   McGaughey J., 2007, Proceedings of exploration, V7, P473
   Ning Fangli, 2009, 2009 INT C COMP INT, P1
   Russell H. A. J., 2013, 3 DIMENSIONAL GEOLOG, V7, P7
   Trampert J, 2005, GEOPHYS MONOGR SER, V160, P47, DOI 10.1029/160GM05
   Wu Q, 2005, COMPUT GEOSCI-UK, V31, P35, DOI 10.1016/j.cageo.2004.09.005
   Yao YY, 2001, INT J INTELL SYST, V16, P87, DOI 10.1002/1098-111X(200101)16:1<87::AID-INT7>3.0.CO;2-S
   Yu X, 2013, IEEE INT C COMP SCI, P1238
   Yu X, 2015, J CHINA UNIV GEOSCI, V40, P419
   Yu XY, 2014, NEAR-SURFACE GEOPHYSICS AND GEOHAZARDS, P224
NR 19
TC 4
Z9 4
U1 4
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28703
EP 28713
DI 10.1007/s11042-018-6379-5
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700020
DA 2024-07-18
ER

PT J
AU Hu, YXN
   Ma, BZ
   Hao, ONW
   Li, LMN
AF Hu, Yuxina
   Ma, Bozhi
   Hao, Honawei
   Li, Lumina
TI Data security: a novel robust regulator design for Portable/implantable
   multimedia models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia models; Portable; implantable device; Voltage regulator;
   Programmable; Data security
ID CUES
AB Portable/implantable multimedia tools have become increasingly popular in recent years, and data transfer's security is so important in models of these tools. To ensure data's stable transfer, a robust voltage regulator is required. Meanwhile, this data transfer usually requires relative complex voltage supplies from limited voltage sources. These specific voltage supplies, which are usually higher than the battery's output voltage, are widely used by multimedia tools to accomplish interactive communication with the human body. This paper describes a novel regulator design to generate higher voltages from a lower voltage supply (e.g. battery's voltage), and the robustness of this regulator could ensure data transfer's security in multimedia models. We first designed a reconfigurable output voltage for compatibility with different multimedia applications. The regulator was made to be highly efficient, fulfilling a critical characteristic for portable/implantable multimedia models. This design also demonstrated reliability and robustness, allowing the highest output voltage to approach to the process tolerance. From simulation, it was indicated that the regulator design had better electrical parameters and more robustness than previous studies, which could ensure the data security for multimedia models.
C1 [Hu, Yuxina; Ma, Bozhi; Hao, Honawei; Li, Lumina] Tsinghua Univ, Sch Aerosp Engn, Beijing, Peoples R China.
C3 Tsinghua University
RP Li, LMN (corresponding author), Tsinghua Univ, Sch Aerosp Engn, Beijing, Peoples R China.
EM thuyuxinghu@gmail.com; mbz@tsinghua.edu.cn; haohw@tsinghua.edu.cn;
   lilm@tsinghua.edu.cn
RI Hu, Yuxing/ISS-8744-2023
FU National Key Technology Research and Development Program [2011BAI12B07];
   National Natural Science Foundation of China [51125028]
FX This study has been supported by National Key Technology Research and
   Development Program (No. 2011BAI12B07) and National Natural Science
   Foundation of China (No. 51125028).
CR [Anonymous], 2016, TOMCCAP, DOI DOI 10.1016/J.YMPEV.2016.12.037
   Geng Y, 2013, IEEE INT S CIRC SYST
   Ghadi M, 2016, MULTIMED TOOLS APPL, V75, P3425, DOI 10.1007/s11042-014-2443-y
   Karime A, 2012, MULTIMED TOOLS APPL, V59, P749, DOI 10.1007/s11042-011-0768-3
   Lee JH, 2016, MULTIMED TOOLS APPL, V75, P15275, DOI 10.1007/s11042-014-2385-4
   Lin HI, 2015, 2015 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY), P1, DOI [10.1109/iFUZZY.2015.7391884, 10.1109/MWSYM.2015.7167041]
   Medina J, 2013, MULTIMED TOOLS APPL, V67, P341, DOI 10.1007/s11042-011-0924-9
   Palumbo G, IEE P CIRCUITS DEVIC, V153, P136
   Palumbo G, 2010, IEEE CIRC SYST MAG, V10, P31, DOI 10.1109/MCAS.2009.935695
   Sarafianos A, 2015, IEEE J SOLID-ST CIRC, V50, P1560, DOI 10.1109/JSSC.2015.2410800
   Tan J, 2011, 2011 SECOND INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATION AND EDUCATION APPLICATION (ICEA 2011), P197, DOI 10.1109/ASSCC.2011.6123636
   Vankeirsbilck B, 2014, MULTIMED TOOLS APPL, V72, P749, DOI 10.1007/s11042-013-1395-y
   Wang W, 2016, IEEE MULTIMEDIA, V23, P80, DOI 10.1109/MMUL.2016.69
   Wikipedia, CHARG PUMP
   Yin YF, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2658981
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2303650
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   ZOU W, 2016, APPL PHYS EXPRESS, V9
NR 21
TC 0
Z9 0
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 26927
EP 26939
DI 10.1007/s11042-017-4451-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000006
DA 2024-07-18
ER

PT J
AU Moon, Y
   Lim, M
AF Moon, Yangchan
   Lim, Mingyu
TI Simulation analysis of prefetching image content for social networking
   service framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content prefetch; Social networking systems; Content access patterns;
   Communication framework; Precision and recall
AB In this paper, we analyze a prefetching mechanism for image content in social networking services (SNS) based on content writers that attract a user's interest. Our prefetching scheme aims to shorten transmission delays and enhance the accessibility to big size images included in SNS content items. The prefetching scheme deals with users of interest instead of the content of interest. Whenever a user downloads new SNS content, his/her client then prefetches the original high-resolution images uploaded by writers of interest to the user. The performance simulations show that the prefetching scheme is well suited if the user's access pattern is highly skewed to a few number of content writers, and that the prefetching scheme gives users high-quality images without significant increase of access delay.
C1 [Moon, Yangchan] Konkuk Univ, Dept Internet & Multimedia Engn, 120 Neungdong Ro, Seoul 05029, South Korea.
   [Lim, Mingyu] Konkuk Univ, Dept Smart ICT Convergence, 120 Neungdong Ro, Seoul 05029, South Korea.
C3 Konkuk University; Konkuk University
RP Lim, M (corresponding author), Konkuk Univ, Dept Smart ICT Convergence, 120 Neungdong Ro, Seoul 05029, South Korea.
EM mlim@konkuk.ac.kr
OI Lim, Mingyu/0000-0002-3749-1902
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF- 2015R1D1A1A01056848]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF- 2015R1D1A1A01056848).
CR Baek J, 2012, 4 INT C UB FUT NETW
   Beaver D, 2010, 9 USENIX C OP SYST D
   Gob A, 2009, IEEE INT C WEB SERV
   Han L, 2012, IEEE 12 INT C PEER T
   Hartmann M, 2007, LERNEN WISSEN ADAPTA
   Hu J, 2013, CHINA COMMUN, V10, P1, DOI 10.1109/CC.2013.6549254
   Kapanipathi P, 2011, 10 INT C SEM WEB BON
   Kubo H, 2011, IEEE INT C COMM WORK
   Lee Y., 2015, INT J ELEC COMP ENG, V5, P586
   Letkowski J, 2012, AC BUS RES I C SAN A
   Li S, 2010, 3 IEEE INT C BROADB
   Lim M, 2017, INFORM INTERDISCIPLI, V20, P631
   Lin K, 2012, 31 ANN IEEE INT C CO
   Mashhadi A, 2009, 10 IEEE INT S WORLD
   Padmanabhan V. N., 1996, Computer Communication Review, V26, P22, DOI 10.1145/235160.235164
   Pietilanen A, 2012, 13 INT S MOB AD HOC
   Said E., 2009, EUROPEAN J SCI RES, V28, P478
   Sulaiman S, 2009, WORLD C NAT BIOL INS
   Thilakarathna K, 2013, 14 ACM INT S MOB AD
   Tramp S, 2011, 8 EXT SEM WEB C HER
   Wang Z, 2012, 20 ACM INT C MULT NA
   Wu B, 2012, IEEE 8 WORLD C SERV
   Zhao Y, 2013, ACM IFIP USENIX INT
NR 23
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28435
EP 28452
DI 10.1007/s11042-017-5492-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700006
DA 2024-07-18
ER

PT J
AU El-Hoseny, HM
   El Kareh, ZZ
   Mohamed, WA
   El Banby, GM
   Mahmoud, KR
   Faragallah, OS
   El-Rabaie, S
   El-Madbouly, E
   Abd El-Samie, FE
AF El-Hoseny, Heba M.
   El Kareh, Zeinab Z.
   Mohamed, Wael A.
   El Banby, Ghada M.
   Mahmoud, Korany R.
   Faragallah, Osama S.
   El-Rabaie, S.
   El-Madbouly, Essam
   Abd El-Samie, Fathi E.
TI An optimal wavelet-based multi-modality medical image fusion approach
   based on modified central force optimization and histogram matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Discrete wavelet transform (DWT); Modified central force
   optimization (MCFO); Histogram matchning
AB This paper introduces an optimal solution for wavelet-based medical image fusion using different wavelet families and Principal Component Ana1ysis (PCA) based on the Modified Central Force Optimization (MCFO) technique. The main motivation of this work is to increase the quality of medical fused images in order to provide correct diagnosis of diseases for the objective of optimal therapy. This can be achieved by fusing medical images of different modalities using an optimization technique based on the MCFO. The MCFO technique gives the optimum gain parameters that achieve the best fused image quality. Histogram matching is applied to improve the overall values of the Peak Signal-to-Noise Ratio (PSNR), entropy, local contrast, and quality of the fused image. A comparative study is performed between the proposed algorithm, the traditional Discrete Wavelet Transform (DWT), and the PCA fusion using maximum fusion rule. The proposed algorithm is evaluated subjectively and objectively with different fusion quality metrics. Simulation results demonstrate that the proposed MCFO optimized wavelet-based fusion algorithm using Haar wavelet and histogram matching achieves a superior performance with the highest image quality and clearest image details in a very short processing time.
C1 [El-Hoseny, Heba M.; Mohamed, Wael A.] Benha Univ, Dept Elect Engn, Fac Engn, Banha, Egypt.
   [El Kareh, Zeinab Z.; El Banby, Ghada M.; El-Madbouly, Essam] Menoufia Univ, Dept Ind Elect & Control Engn, Fac Elect Engn, Menoufia, Egypt.
   [Mahmoud, Korany R.] Helwan Univ, Fac Engn, Dept Elect Commun & Comp, Cairo, Egypt.
   [Faragallah, Osama S.] Menoufia Univ, Dept Comp Sci & Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Faragallah, Osama S.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [El-Rabaie, S.; Abd El-Samie, Fathi E.] Taif Univ, Dept Informat Technol, Coll Comp & Informat Technol, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Benha University; Egyptian Knowledge Bank
   (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Helwan
   University; Egyptian Knowledge Bank (EKB); Menofia University; Egyptian
   Knowledge Bank (EKB); Menofia University; Taif University
RP El Kareh, ZZ (corresponding author), Menoufia Univ, Dept Ind Elect & Control Engn, Fac Elect Engn, Menoufia, Egypt.
EM zeinabelkareh@gmail.com
RI El-Hoseny, Heba/JGC-7081-2023; Faragallah, Osama S./AHB-8031-2022;
   Sayed, Fathi/HRA-4752-2023; Mahmoud, Korany R./F-1455-2019
OI El-Hoseny, Heba/0000-0003-1469-4165; Faragallah, Osama
   S./0000-0003-1982-335X; Sayed, Fathi/0000-0001-8749-9518; Mahmoud,
   Korany R./0000-0002-7113-1310; EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Arunvinodh C, 2015, IEEE INT C INN INF E, P1
   Bick M, 2015, THESIS
   Daniel E, 2017, BIOMED SIGNAL PROCES, V34, P36, DOI 10.1016/j.bspc.2017.01.003
   Deserno TM, 2011, BIOL MED PHYS BIOMED, P1, DOI 10.1007/978-3-642-15816-2_1
   Donia EA, 2016, 2016 FOURTH INTERNATIONAL JAPAN-EGYPT CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND COMPUTERS (JEC-ECC), P111, DOI 10.1109/JEC-ECC.2016.7518980
   I Abdul-Ameer, 2014, INT MULT ENG COMP SC, VI
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Joseph J, 2014, IJEDR, V2
   Kannan K, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P314, DOI 10.1109/ICCIMA.2007.143
   Lee Daniel T. L., 1994, HEWLETT PACKARD J
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2011, COMM COM INF SC, V186, P122
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li M, 2013, 6 INT C IM SIGN PROC, P16
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mahmoud KR, 2016, IET MICROW ANTENNA P, V10, P1011, DOI 10.1049/iet-map.2015.0801
   Mani V., 2013, Journal of Biomedical Engineering and Technology, V1, P8, DOI [10.12691/jbet-1-2-1, DOI 10.12691/JBET-1-2-1, 10.12691/jbet- 1- 2-1]
   Mitchell HB, 2010, IMAGE FUSION: THEORIES, TECHNIQUES AND APPLICATIONS, P1, DOI 10.1007/978-3-642-11216-4
   Nabil A, 2014, THESIS
   Omar Z, 2014, INT C INT SYST MOD S
   Patne G, 2017, REV CT PET IMAGE FUS
   Rajini KC, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P149, DOI 10.1109/WiSPNET.2017.8299737
   Raut G.N., 2013, IJITEE, V2
   Shahdoosti HR, 2015, COMBINING SPECTRAL P
   Song HJ, 2017, PATTERN RECOGN LETT, V94, P15, DOI 10.1016/j.patrec.2017.04.021
   Wang A, 2006, IEEE INT C NETW SENS, P270
   Zhang S, 2012, INT C WAV AN PATT RE
NR 31
TC 15
Z9 16
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26373
EP 26397
DI 10.1007/s11042-019-7552-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700050
DA 2024-07-18
ER

PT J
AU Gao, ZH
   Wang, HQ
   Feng, GS
   Guo, FF
   Lv, HW
   Li, BY
AF Gao, Zihan
   Wang, Huiqiang
   Feng, Guangsheng
   Guo, Fangfang
   Lv, Hongwu
   Li, Bingyang
TI RealPot: an immersive virtual pottery system with handheld haptic
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual pottery; Natural user interfaces; Mesh deformation; Haptic
   feedback
AB We present RealPot, an immersive virtual pottery system with haptic feedback for pottery simulation training using hand-held motion controllers. Our system consists of two major components: an automatic mesh generator and an interactive model editor. The mesh generator can procedurally generate realistic clay meshes by adding Perlin Noise. With the interactive pottery model editor, the user can shape the virtual clay intuitively with a series of bimanual interactions. Based on real-life pottery, a high realism pottery creation workflow was developed and a haptic model was proposed. Our user study investigated how haptic fidelity can impact usability in virtual pottery, and compared our system with a representative work of barehand-based virtual pottery systems. The results of our study reveal that haptic fidelity significantly affects performance and user experience. In addition, the results indicate that our system offers significantly accuracy, presence and usability compared with barehand-based virtual pottery experience.
C1 [Gao, Zihan; Wang, Huiqiang; Feng, Guangsheng; Guo, Fangfang; Lv, Hongwu; Li, Bingyang] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Engineering University
RP Wang, HQ (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM zihan@hrbeu.edu.cn; wanghuiqiang@hrbeu.edu.cn; ica@hrbeu.edu.cn;
   guofangfang@hrbeu.edu.cn; lvhongwu@hrbeu.edu.cn; libingyang@hrbeu.edu.cn
RI Gao, Zihan/GWQ-5679-2022
OI Gao, Zihan/0000-0001-9624-5587; Wang, Huiqiang/0000-0002-1007-5589
FU Natural Science Foundation of China [61872104]; Natural Science
   Foundation of Heilongjiang Province in China [F2016009]; Fundamental
   Research Fund for the Central Universities in China [HEUCF180602,
   HEUCFM180604]; National Science and Technology Major Project
   [2016ZX03001023-005]
FX We thank the reviewers for their valuable feedback and comments. We also
   thank all the people participated in the user studies. This work is
   supported by the Natural Science Foundation of China (No. 61872104), the
   Natural Science Foundation of Heilongjiang Province in China (No.
   F2016009), the Fundamental Research Fund for the Central Universities in
   China (No. HEUCF180602 and HEUCFM180604) and the National Science and
   Technology Major Project (No. 2016ZX03001023-005).
CR Agrawala M., 1995, Proceedings 1995 Symposium on Interactive 3D Graphics, P145, DOI 10.1145/199404.199429
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   [Anonymous], 2001, P 2001 S INT 3D GRAP
   Bastug E, 2017, IEEE COMMUN MAG, V55, P110, DOI 10.1109/MCOM.2017.1601089
   Botsch M., 2010, Polygon Mesh Processing
   CHOUDHARY R, 1995, ECSCW '95 - PROCEEDINGS OF THE FOURTH EUROPEAN CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK, P231
   Cui J, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P41, DOI 10.1109/CW.2016.14
   Gao ZH, 2018, PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON VIRTUAL REALITY (ICVR 2018), P126, DOI 10.1145/3198910.3234659
   Han G, 2007, LECT NOTES COMPUT SC, V4563, P642
   Han YC, 2014, MULTIMED TOOLS APPL, V73, P917, DOI 10.1007/s11042-013-1382-3
   Hinckley K., 1998, ACM Transactions on Computer-Human Interaction, V5, P260, DOI 10.1145/292834.292849
   Jacob RJK, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P201
   Korida K, 1997, INTERNATIONAL CONFERENCE ON VIRTUAL SYSTEMS AND MULTIMEDIA - VSMM'97, PROCEEDINGS, P227, DOI 10.1109/VSMM.1997.622351
   Koutsoudis A, 2009, J CULT HERIT, V10, P281, DOI 10.1016/j.culher.2008.07.012
   Kumar G, 2011, INT J ARTS TECHNOL, V4, P196, DOI 10.1504/IJART.2011.039845
   LaViola Joseph J., 2017, 3D User interfaces: theory and practice
   LaViola JosephJ., 2011, ACM SIGGRAPH 2011 Courses (SIGGRAPH '11), P1
   McMahan RP, 2012, IEEE T VIS COMPUT GR, V18, P626, DOI 10.1109/TVCG.2012.43
   Niehorster DC, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517708205
   OTSUKI M, 2017, VIRTUAL REALITY, P1, DOI DOI 10.5331/BGR.16R02
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Ramani Karthik., 2014, CHI'14 Extended Abstracts on Human Factors in Computing Systems, P371
   Schkolne S., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P261, DOI 10.1145/365024.365114
   Sheng J., 2006, PROC GRAPHITE, V6, P213
   Slater M., 1994, PRESENCE-TELEOP VIRT, V3, P130, DOI DOI 10.1162/PRES.1994.3.2.130
   Vinayak, 2016, COMPUT GRAPH-UK, V55, P143, DOI 10.1016/j.cag.2015.10.012
   Vinayak, 2015, COMPUT AIDED DESIGN, V69, P11, DOI 10.1016/j.cad.2015.06.006
   Vinayak, 2013, J COMPUT INF SCI ENG, V13, DOI 10.1115/1.4023588
   Walter R, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P299, DOI 10.1145/2628363.2628368
   Wang T, 2019, IEEE INTERNET THINGS, V6, P4831, DOI 10.1109/JIOT.2018.2870288
   Wingrave CA, 2010, IEEE COMPUT GRAPH, V30, P71, DOI 10.1109/MCG.2009.109
NR 31
TC 9
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26569
EP 26596
DI 10.1007/s11042-019-07843-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700057
DA 2024-07-18
ER

PT J
AU Gupta, SK
   Ashwin, TS
   Guddeti, RMR
AF Gupta, Sujit Kumar
   Ashwin, T. S.
   Guddeti, Ram Mohana Reddy
TI Students' affective content analysis in smart classroom environment
   using deep learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression; Structure of moods; Mood classification; Affective
   content analysis; Students' engagement; Inception-V3
ID ENGAGEMENT; RECOGNITION; FACES
AB In the era of the smart classroom environment, students' affective content analysis plays a vital role as it helps to foster the affective states that are beneficial to learning. Some techniques target to improve the learning rate using the students' affective content analysis in the classroom. In this paper, a novel max margin face detection based method for students' affective content analysis using their facial expressions is proposed. The affective content analysis includes analyzing four different moods of students', namely: High Positive Affect, Low Positive Affect, High Negative Affect, and Low Negative Affect. Engagement scores have been calculated based upon the four moods of students as predicted by the proposed method. Further, the classroom engagement analysis is performed by considering the entire classroom as one group and the corresponding group engagement score. Expert feedback and analyzed affect content videos are used as feedback to the faculty member to improve the teaching strategy and hence improving the students' learning rate. The proposed smart classroom system was tested for more than 100 students of four different Information Technology courses and the corresponding faculty members at National Institute of Technology Karnataka Surathkal, Mangalore, India. The experimental results demonstrate the train and test accuracy of 90.67% and 87.65%, respectively for mood classification. Furthermore, an analysis was performed over incidence, distribution and temporal dynamics of students' affective states and promising results were obtained.
C1 [Gupta, Sujit Kumar; Ashwin, T. S.; Guddeti, Ram Mohana Reddy] Natl Inst Technol Karnataka Surathkal, Dept Informat Technol, Mangalore, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Ashwin, TS (corresponding author), Natl Inst Technol Karnataka Surathkal, Dept Informat Technol, Mangalore, India.
EM sujitnik16@gmail.com; ashwindixit9@gmail.com; profgrmreddy@nitk.edu.in
RI Guddeti, Ram Mohana Reddy/W-9494-2018; Guddeti, Ram Mohana
   Reddy/ABB-5181-2021; S, ASHWIN T/Z-2285-2019
OI Guddeti, Ram Mohana Reddy/0000-0003-1361-3837; S, ASHWIN
   T/0000-0002-1690-1626
CR Ahlfeldt S., 2005, Higher Education Research & Development, V24, P5, DOI [10.1080/0729436052000318541, DOI 10.1080/0729436052000318541]
   [Anonymous], THESIS
   [Anonymous], IMPROVING TEACHING L
   [Anonymous], IEEE T SYSTEMS MAN C
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bomia L., 1997, The impact of teaching strategies on intrinsic motivation
   Broeckelman-Post MA, 2008, IEEE T EDUC, V51, P206, DOI 10.1109/TE.2007.910428
   Burnik U, 2017, 2017 IEEE FIRST UKRAINE CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (UKRCON), P1229, DOI 10.1109/UKRCON.2017.8100449
   Camelia F, 2017, IEEE T SYST MAN CY-S, V47, P3165, DOI 10.1109/TSMC.2016.2563386
   D'Mello SK., 2010, International Journal of Artificial Intelligence in Education, V20, P361, DOI [DOI 10.3233/JAI-2010-012, 10.3233/JAI-2010-012]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dasari B., 2009, US-China Education Review, V6, P46
   Farhan M, 2018, MULTIMED TOOLS APPL, V77, P4909, DOI 10.1007/s11042-016-4212-6
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Guo P. J., 2014, P 1 ACM C LEARN SCAL, P41, DOI DOI 10.1145/2556325.2566239
   Izenman AJ, 2008, SPRINGER TEXTS STAT, P237, DOI 10.1007/978-0-387-78189-1_8
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Kazmi A., 2010, College Quarterly, V13, P1
   King D.E., 2015, ARXIV150200046
   Langton N., 2013, Fundamentals of organizational behaviour
   Lehman BA, 2018, IEEE T LEARN TECHNOL, V11, P41, DOI 10.1109/TLT.2018.2810878
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Luo J, 2007, INT CONF ACOUST SPEE, P593
   Macal CM, 2005, PROCEEDINGS OF THE 2005 WINTER SIMULATION CONFERENCE, VOLS 1-4, P2, DOI 10.1109/WSC.2005.1574234
   Mann S, 2009, BRIT EDUC RES J, V35, P243, DOI 10.1080/01411920802042911
   Manninen S, 1998, RESPONSES OF PLANT METABOLISM TO AIR POLLUTION AND GLOBAL CHANGE, P371
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Monkaresi H, 2017, IEEE T AFFECT COMPUT, V8, P15, DOI 10.1109/TAFFC.2016.2515084
   Qin JX, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P635, DOI 10.1145/2671188.2749357
   Sagayadevan Vathsala., 2012, J SCHOLARSHIP TEACHI, V12, P1
   Schmidt A, 2007, ADV INTEL SOFT COMPU, V45, P816
   SKINNER EA, 1993, J EDUC PSYCHOL, V85, P571, DOI 10.1037/0022-0663.85.4.571
   Subramainan L, 2016, 2016 2ND INTERNATIONAL SYMPOSIUM ON AGENT, MULTI-AGENT SYSTEMS AND ROBOTICS (ISAMSR), P34, DOI 10.1109/ISAMSR.2016.7809999
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Thomas C, 2017, P 1 ACM SIGCHI INT W, P33, DOI DOI 10.1145/3139513.3139514
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   WALBERG HJ, 1968, J EDUC PSYCHOL, V59, P414, DOI 10.1037/h0026490
   WATSON D, 1988, J PERS SOC PSYCHOL, V54, P1063, DOI 10.1037/0022-3514.54.6.1063
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Wong A., 2016, International Journal of Education and Development Using Information and Communication Technology, V12, P144
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yazzie-Mintz E., 2009, ENGAGING VOICES STUD
   Young M.S., 2009, Active Learning in Higher Education, V10, P41, DOI DOI 10.1177/1469787408100194
NR 43
TC 51
Z9 56
U1 3
U2 129
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25321
EP 25348
DI 10.1007/s11042-019-7651-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700006
DA 2024-07-18
ER

PT J
AU Amani, HR
   Yaghoobi, M
AF Amani, Hamid Reza
   Yaghoobi, Mahdi
TI A New Approach in Adaptive Encryption Algorithm for Color Images Based
   on DNA Sequence Operation and Hyper-Chaotic System
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Encryption; DNA sequence; Hyper Chaotic System; Adaptive
   Encryption
AB The security requirements of digital images led to the development of effective encryption techniques. In this paper, the proposed approach includes the use of the DNA sequence and hyper-chaotic dynamics in adaptive encryption of color images. This method consists of two main steps: In the first step, the pixels logical arrangement is upset by using Arnold's cat map. In the second step, the scrambled image is encrypted by using a combination of three methods, including the Chen's hyper-chaotic system, DNA sequence, and proposed adaptive method, which play a significant role in the complexity of the proposed algorithm. The simulation and experimental results and security analysis indicated that the proposed algorithm not only produces a significant encryption effect, but is also capable of effectively resisting statistical and brute-force attacks.
C1 [Amani, Hamid Reza; Yaghoobi, Mahdi] Islamic Azad Univ, Mashhad Branch, Elect Engn Dept, Mashhad, Razavi Khorasan, Iran.
C3 Islamic Azad University
RP Yaghoobi, M (corresponding author), Islamic Azad Univ, Mashhad Branch, Elect Engn Dept, Mashhad, Razavi Khorasan, Iran.
EM hamidamani70@gmail.com; yaghoobi@mshdiau.ac.ir
OI , mahdi/0000-0003-2263-4859
CR Ailenberg M, 2009, BIOTECHNIQUES, V47, P747, DOI 10.2144/000113218
   [Anonymous], NONLINEAR DYNAMICS
   [Anonymous], 1949, Bell System Technical Journal
   Baum EB, 1996, P 2 DIMACS WORKSH DN, P122
   Boloorchi M, 2017, CAN CON EL COMP EN
   Cell CT, 1999, MICRODOTS NATURE, V399, P533, DOI [10.1038/21092, DOI 10.1038/21092]
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Dong EZ, 2008, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT, INNOVATION MANAGEMENT AND INDUSTRIAL ENGINEERING, VOL 1, P169, DOI 10.1109/ICIII.2008.25
   Fu C, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P3057, DOI 10.1109/ICYCS.2008.522
   Gaborit P, 2005, THEOR COMPUT SCI, P33499
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Gehani A., 2000, DNA -Based Cryptography. DIMACS DNA Based Computers V
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Guesmi R, 2016, NONLINEAR DYNAM, V83, P1123, DOI 10.1007/s11071-015-2392-7
   Hu T, 2016, NONLINEAR DYNAM, DOI [10. 1007/s11071-016-30246, DOI 10.1007/S11071-016-30246]
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Jin X, 2015, CHIN AUTOM CONGR, P1159, DOI 10.1109/CAC.2015.7382673
   King OD, 2007, DISCRETE APPL MATH, V155, P831, DOI 10.1016/j.dam.2005.07.015
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lian SG, 2005, PHYSICA A, V351, P645, DOI 10.1016/j.physa.2005.01.001
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Lian SG, 2009, NEUROCOMPUTING, V72, P1296, DOI 10.1016/j.neucom.2008.11.005
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Peng J, 2008, CONF CYBERN INTELL S, P1219
   Peterson G, 1997, ARNOLDS CAT MAP
   Sabery M, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P585, DOI 10.1109/ICACTE.2008.177
   Saranya MR, 2015, SIGN PROC INF COMM E, P1
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Shyam M, 2007, HIPC2007
   Som S, 2015, SCIENCE, P108
   Wang L, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P22, DOI 10.1109/CISP.2008.129
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang Y, 2009, CHAOS SOLITON FRACT
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei X, 2012, SYST SOFTWARE, P85290
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiao GZ, 2006, CHINESE SCI BULL, V51, P1413, DOI 10.1007/s11434-006-2012-5
   Xue XL, 2010, J COMPUT THEOR NANOS, V7, P397, DOI 10.1166/jctn.2010.1372
   Yanchuk S, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.056235
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang X, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P889, DOI 10.1109/ICALIP.2008.4590187
   Zhang Y, 2015, OPTIK, V126, P223, DOI 10.1016/j.ijleo.2014.08.129
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zheng W, 2017, IEEE INT C SYST MAN
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 54
TC 33
Z9 34
U1 5
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21537
EP 21556
DI 10.1007/s11042-018-6989-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400045
DA 2024-07-18
ER

PT J
AU Lin, C
   Lu, W
   Huang, XC
   Liu, K
   Sun, W
   Lin, HH
AF Lin, Cong
   Lu, Wei
   Huang, Xinchao
   Liu, Ke
   Sun, Wei
   Lin, Hanhui
TI Region duplication detection based on hybrid feature and evaluative
   clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Region duplication detection; Copy-move
   forgery; Harris-Laplace; Hessian-Laplace; Bag of word
ID COPY-MOVE FORGERY; IMAGE SPLICING DETECTION; STEGANALYSIS; DCT;
   TRANSFORM; SCALE; STEP
AB Digital image are easy to be tampered by the photo editing software. Therefore, digital image forensics which aims at validating the authenticity of the digital image are received wide public concern. Region duplication is a commonly used operation in digital image forgeries. The main aims of the region duplication are to overemphasize or conceal some contents by duplicating some regions on the image. Most of the region duplication methods can be categorized into two main classes:block-based and keypoint-based methods. In this paper, a novel region duplication detection scheme is proposed based on hybrid feature and evaluative clustering. The proposed scheme is divided into two stages: the rough matching and the exact matching. In the rough matching, first, hybrid keypoints are extracted from the input image, and those keypoints are described by the unified descriptors. Second, those keypoints are matched by the g2NN strategy. Third, those matched keypoints are grouped by the proposed clustering based on evaluation. Fourth, affine transformations are estimated between these groups, and Bag of Word is used to filter inaccuracy affine transformations to improve the results of pixel level. When no affine transformation is obtained, in the exact matching, each suspicious region is handled separately. Experimental results indicate that the proposed scheme outperforms the state-of-the-art methods under various conditions.
C1 [Lin, Cong; Lu, Wei; Huang, Xinchao] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp,Minist Ed, Guangzhou 510006, Guangdong, Peoples R China.
   [Lin, Cong; Lin, Hanhui] Guangdong Univ Finance & Econ, Ctr Fac Dev & Educ Technol, Guangzhou 510320, Guangdong, Peoples R China.
   [Lu, Wei] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Liu, Ke; Sun, Wei] Sun Yat Sen Univ, Sch Elect & Informat Technol, Key Lab Informat Technol, Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Guangdong University of Finance & Economics;
   Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Key Lab Machine Intelligence & Adv Comp,Minist Ed, Guangzhou 510006, Guangdong, Peoples R China.; Lu, W (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
EM lincong0310@gmail.com; luwei3@mail.sysu.edu.cn
OI lin, cong/0000-0002-5667-5037; Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; National Key
   R&D Program of China [2017YFB0802500]; Natural Science Foundation of
   Guangdong [2016A030313350]; Special Funds for Science and Technology
   Development of Guangdong [2016KZ010103]; Key Project of Scientific
   Research Plan of Guangzhou [201804020068]; Fundamental Research Funds
   for the Central Universities [16lgjc83, 17lgjc45]; Science and
   Technology Planning Project of Guangdong Province [2017A040405051];
   Alibaba Group through Alibaba Innovative Research Program
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the National Key R&D Program of China (No.
   2017YFB0802500), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), the
   Fundamental Research Funds for the Central Universities (No. 16lgjc83
   and No. 17lgjc45), the Science and Technology Planning Project of
   Guangdong Province (No.2017A040405051), the Alibaba Group through
   Alibaba Innovative Research Program.
CR Abd Warif NB, 2017, J VIS COMMUN IMAGE R, V46, P219, DOI 10.1016/j.jvcir.2017.04.004
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], IEEE T CIRCUIT SYST
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2014, IEEE T INFORM FORENS
   [Anonymous], BIOMETRICS
   [Anonymous], INT C DEV ES ENG LIV
   [Anonymous], IEEE T INFORM FORENS
   [Anonymous], 9 IFIP INT C NEW TEC
   [Anonymous], INT WORKSH DIG WAT B
   [Anonymous], 2016, MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2003, PROC DIGIT FORENSIC, DOI DOI 10.1109/PACIIA.2008.240
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen LK, 2012, INT J DIGIT CRIME FO, V4, P49, DOI 10.4018/jdcf.2012010104
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Christlein V, 2010, IEEE INT WORKS INFOR
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Farid H, 2009, ADV COMPUT, V77, P1, DOI 10.1016/S0065-2458(09)01201-7
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Feng BW, 2017, J VIS COMMUN IMAGE R, V46, P119, DOI 10.1016/j.jvcir.2017.01.008
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forssén PE, 2007, IEEE I CONF COMP VIS, P1530
   Harris C., 1988, ALVEY VISION C, P147151
   Hastie T., 2009, ELEMENTS STAT LEARNI
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   HSU YN, 1982, APPL OPTICS, V21, P4012, DOI 10.1364/AO.21.004012
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Lai YC, 2018, MULTIMED TOOLS APPL, V77, P15093, DOI 10.1007/s11042-017-5094-y
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li JH, 2016, ADV SOC SCI EDUC HUM, V76, P1
   Li JX, 2018, MULTIMED TOOLS APPL, V77, P31895, DOI 10.1007/s11042-018-6175-2
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Liu XJ, 2019, MULTIMED TOOLS APPL, V78, P7947, DOI 10.1007/s11042-018-6411-9
   Liu XJ, 2020, IEEE T CIRC SYST VID, V30, P618, DOI 10.1109/TCSVT.2019.2893353
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu W, 2011, ENG APPL ARTIF INTEL, V24, P666, DOI 10.1016/j.engappai.2011.01.002
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma Y, 2019, IEEE T CONTR SYST T, V27, P1788, DOI 10.1109/TCST.2018.2819965
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Muhammad Khan, 2018, Future Generation Computer Systems, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sencar H.T., 2008, OVERVIEW STATE OF TH
   Sharma A, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P1, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.18
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Soni B, 2018, IET IMAGE PROCESS, V12, P2092, DOI 10.1049/iet-ipr.2018.5576
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Xue F, 2017, SIGNAL PROCESS-IMAGE, V57, P76, DOI 10.1016/j.image.2017.05.008
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yang HY, 2018, MULTIMED TOOLS APPL, V77, P13615, DOI 10.1007/s11042-017-4978-1
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
NR 92
TC 13
Z9 15
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20739
EP 20763
DI 10.1007/s11042-019-7342-9
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400009
DA 2024-07-18
ER

PT J
AU Shah, RA
   Asghar, MN
   Abdullah, S
   Fleury, M
   Gohar, N
AF Shah, Rizwan A.
   Asghar, Mamoona N.
   Abdullah, Saima
   Fleury, Martin
   Gohar, Neelam
TI Effectiveness of crypto-transcoding for H.264/AVC and HEVC video
   bit-streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content protection; H; 264; AVC; HEVC; Selective encryption;
   Transcoding; Transrating; Video streaming
ID SELECTIVE ENCRYPTION; QUALITY ASSESSMENT; EFFICIENCY; IMAGE;
   ARCHITECTURES; COMPRESSION; ADAPTATION; SECURITY; DECISION; SYSTEM
AB To avoid delays arising from a need to decrypt a video prior to transcoding and then re-encrypt it afterwards, this paper assesses a selective encryption (SE) content protection scheme. The scheme is suited to both recent standardized codecs, namely H.264/Advanced Video Coding (AVC) and High Efficiency Video Coding (HEVC). Specifically, the paper outlines a joint crypto-transcoding scheme for secure transrating of a video bitstream. That is to say it generates new video bitrates, possibly as part of an HTTP Adaptive Streaming (HAS) content delivery network. The scheme will reduce the bitrate to one or more lower desired bit-rate without consuming time in the encryption/decryption process, which would be the case when full encryption is used. In addition, the decryption key no longer needs to be exposed at intermediate middleboxes, including when transrating is performed in a cloud datacenter. The effectiveness of the scheme is variously evaluated: by examination of the SE generated visual distortion; by the extent of computational and bitrate overheads; and by choice of cipher when encrypting the selected elements within the bitstream. Results indicate that there remains: a content; quantization level (after transrating of an encrypted video); and codec-type dependency to any distortion introduced. A further recommendation is that the Advanced Encryption Standard (AES) is preferred for SE to lightweight XOR encryption, despite it being taken up elsewhere as a real-time encryption method.
C1 [Shah, Rizwan A.; Asghar, Mamoona N.; Abdullah, Saima] Islamia Univ Bahawalpur, Dept Comp Sci & IT, Bahawalpur, Pakistan.
   [Fleury, Martin] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
   [Gohar, Neelam] Shaheed Benazir Bhutto Women Univ, Dept Comp Sci, Peshawar, Pakistan.
C3 Islamia University of Bahawalpur; University of Essex
RP Fleury, M (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
EM fleury.martin55@gmail.com
RI Shah, Rizwan Ali/GRF-0227-2022
OI Abdullah, Dr. Saima/0000-0003-1494-1381; Asghar,
   Mamoona/0000-0001-7460-266X; Ali Shah, Rizwan/0000-0001-7162-6615
CR Adeyemi-Ejeye AO, 2017, J VIS COMMUN IMAGE R, V45, P95, DOI 10.1016/j.jvcir.2017.02.012
   Ahn S, 2015, IEEE T CIRC SYST VID, V25, P422, DOI 10.1109/TCSVT.2014.2360031
   Alanazi H., 2010, J COMPUTING, V2, P152
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   [Anonymous], 2011, HTTP LIVE STREAMING
   Asghar MN, 2015, MULTIMED TOOLS APPL, V74, P10215, DOI 10.1007/s11042-014-2160-6
   Asghar MN, 2014, J VIS COMMUN IMAGE R, V25, P487, DOI 10.1016/j.jvcir.2013.12.015
   Bing B, 2016, VIDEO WIRELESS
   Bjork N, 1998, IEEE T CONSUM ELECTR, V44, P88, DOI 10.1109/30.663734
   Boho A, 2013, IEEE SIGNAL PROC MAG, V30, P97, DOI 10.1109/MSP.2012.2230220
   Boyadjis B, 2017, IEEE T CIRC SYST VID, V27, P892, DOI 10.1109/TCSVT.2015.2511879
   Boyadjis B, 2014, IEEE IMAGE PROC, P3432, DOI 10.1109/ICIP.2014.7025697
   Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Brorsoft Studio, 2017, VID CONV DOC
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Choon L. S., 2004, Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications (IEEE Cat. No.04EX852), P525
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Díaz-Sánchez D, 2016, TELECOMMUN SYST, V61, P59, DOI 10.1007/s11235-014-9952-x
   Dorwin D., 2017, ENCRYPTED MEDIA EXTE
   Eletftheriadis A, 2006, IEEE T MULTIMED, V8, P297, DOI [10.1109/TMM.2005.864346, DOI 10.1109/TMM.2005.864346]
   Eom Sungwook, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1411, DOI 10.1007/s12652-018-0698-2
   Fan QL, 2018, COMPUT ELECTR ENG, V66, P332, DOI 10.1016/j.compeleceng.2017.04.011
   Fang J. T., 2014, P 4 INT C COMP SCI I, V4, P215
   Farajallah M, 2015, IEEE IMAGE PROC, P3096, DOI 10.1109/ICIP.2015.7351373
   Garcia M.-N, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P141, DOI 10.1109/QoMEX.2014.6982310
   Hamidouche W, 2017, SIGNAL PROCESS-IMAGE, V58, P73, DOI 10.1016/j.image.2017.06.007
   Hofbauer Heinz, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1986, DOI 10.1109/ICASSP.2014.6853946
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kim D, 2006, LECT NOTES COMPUT SC, V4319, P1067
   Kim M, 2011, IEEE T CONSUM ELECTR, V57, P1362, DOI 10.1109/TCE.2011.6018895
   Lee J, 2015, IEEE T CIRC SYST VID, V25, P411, DOI 10.1109/TCSVT.2014.2339612
   Lin XY, 2012, IEEE T CONSUM ELECTR, V58, P505, DOI 10.1109/TCE.2012.6227454
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   Liu YN, 2013, IEEE ICC, P3629, DOI 10.1109/ICC.2013.6655116
   Liu YN, 2016, IEEE SENS J, V16, P836, DOI 10.1109/JSEN.2015.2489258
   Lookabaugh T, 2004, IEEE COMMUN MAG, V42, P124, DOI 10.1109/MCOM.2004.1299355
   Van LP, 2016, IEEE T MULTIMEDIA, V18, P364, DOI 10.1109/TMM.2015.2512231
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   Merkle P, 2009, IEEE 3DTV C, P1
   Moiron S., 2007, P C TEL, P449
   MORRISON DG, 1994, P 6 INT WORKSH PACK, P392
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Pande A, 2013, IEEE MULTIMEDIA, V20, P50, DOI 10.1109/MMUL.2012.29
   Peixoto E, 2012, IEEE IMAGE PROC, P737, DOI 10.1109/ICIP.2012.6466965
   Popov A., 2015, 7465 RFC IETF
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Robitza W, 2017, FFMPEG VBR SETTINGS
   Rothke B., 2007, Information Security Management Handbook, Sixth Edition, P1151, DOI DOI 10.1201/9781439833032.CH89
   Safavi-Naini R, 2010, HDB FINANCIAL CRYPTO, P193
   Saleh MA, 2018, J THEOR APPL INFO TE, V96, P6806
   Sallam AI, 2018, MULTIMEDIA SYST, V24, P419, DOI 10.1007/s00530-017-0568-3
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Shen B, 2004, IEEE T MULTIMEDIA, V6, P375, DOI 10.1109/TMM.2003.822791
   Shen LQ, 2014, IEEE T IMAGE PROCESS, V23, P4232, DOI 10.1109/TIP.2014.2341927
   Socek D, 2006, LECT NOTES COMPUT SC, V4141, P547
   Stinson D. R., 2006, Cryptography Theory and Practice, V3rd
   Suehring K., 2018, H 264 MPEG 4 AVC REF
   Suehring K., 2018, HEVC REFERENCE SOFTW
   Sun H., 2005, Digital video transcoding for transmission and storage
   Taleb T, 2016, IEEE NETWORK, V30, P84, DOI 10.1109/MNET.2016.1500244RP
   Tamanna S., 2013, THESIS
   Thomas N, 2010, SIGNAL PROCESS-IMAGE, V25, P196, DOI 10.1016/j.image.2009.12.003
   Thomas NM, 2007, IEEE IMAGE PROC, P1781
   Umbaugh S.E., 2018, Digital Image Processing and Analysis: Applications with Matlab and CVIPtools, V3rd, P873
   Van Wallendael G, 2013, IEEE T CONSUM ELECTR, V59, P634, DOI 10.1109/TCE.2013.6626250
   Venckauskas A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051554
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEE SJ, 2001, ACOUST SPEECH SIG PR, P2049
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Yang MX, 2015, PR IEEE I C PROGR IN, P374, DOI 10.1109/PIC.2015.7489872
   Zhang X, 2018, IEEE ACCESS, V6, P18074, DOI 10.1109/ACCESS.2018.2820724
   Zhou JT, 2014, IEEE T INF FOREN SEC, V9, P39, DOI 10.1109/TIFS.2013.2291625
NR 79
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21455
EP 21484
DI 10.1007/s11042-019-7451-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400042
DA 2024-07-18
ER

PT J
AU Bamal, R
   Kasana, SS
AF Bamal, Roopam
   Kasana, Singara Singh
TI Dual hybrid medical watermarking using walsh-slantlet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Slantlet; SIM; PSNR; ANN; AES
ID INTELLIGENT REVERSIBLE WATERMARKING; IMAGES; INFORMATION; STORAGE;
   EXPANSION; ALGORITHM
AB A hybrid robust lossless data hiding algorithm is proposed in this paper by using the Singular Value Decomposition (SVD) with Fast Walsh Transform (FWT) and Slantlet Transform (SLT) for image authentication. These transforms possess good energy compaction with distinct filtering, which leads to higher embedding capacity from 1.8 bit per pixel (bpp) up to 7.5bpp. In the proposed algorithm, Artificial Neural Network (ANN) is applied for region of interest (ROI) detection and two different watermarks are created. Embedding is done after applying FWH by changing the SVD coefficients and by changing the highest coefficients of SLT subbands. In dual hybrid embedding first watermark is the ROI and another watermark consists of three parts, i.e., patients' personal details, unique biometric ID and the key for encryption. Comparison of the proposed algorithm is done with the existing watermarking techniques for analyzing the performance. Experiments are simulated on the proposed algorithm by casting numerous attacks for testing the visibility, robustness, security, authenticity, integrity and reversibility. The resultant outcome proves that the watermarked image has an improved imperceptibility with a high level of payload, low time complexity and high Peak Signal to Noise Ratio (PSNR) against the existing approaches.
C1 [Bamal, Roopam; Kasana, Singara Singh] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bamal, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM roopambamal@gmail.com; singara@thapar.edu
OI Bamal, Roopam/0000-0002-6321-8133
CR Acharya R, 2004, COMPUT METH PROG BIO, V76, P13, DOI 10.1016/j.cmpb.2004.02.009
   Acharya R, 2003, COMPUT BIOL MED, V33, P303, DOI 10.1016/S0010-4825(02)00083-5
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Alvarez G, 2007, COMPUT BIOL MED, V37, P424, DOI 10.1016/j.compbiomed.2006.04.002
   [Anonymous], 2011, ARXIV11011603
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   BAMAL R, 2017, MULTIMED TOOLS APPL, V77, P1
   Bhatnagar G, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P894, DOI 10.1109/IADCC.2009.4809134
   Biryukov A, 2010, LECT NOTES COMPUT SC, V6110, P299
   Biryukov A, 2009, LECT NOTES COMPUT SC, V5677, P231, DOI 10.1007/978-3-642-03356-8_14
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   da Silva PHF, 2010, SYSTEM CIRCUIT DESIG
   Fakhari P, 2011, DIGIT SIGNAL PROCESS, V21, P433, DOI 10.1016/j.dsp.2011.01.014
   Hykin S., 1999, NEURAL NETWORKS COMP
   Garcia-Hernandez JJ, 2016, COMPUT BIOL MED, V68, P37, DOI 10.1016/j.compbiomed.2015.10.014
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Li MY, 2005, COMPUT MED IMAG GRAP, V29, P367, DOI 10.1016/j.compmedimag.2005.02.003
   Naheed T, 2014, OPTIK, V125, P2515, DOI 10.1016/j.ijleo.2013.10.124
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Selesnick IW, 1999, IEEE T SIGNAL PROCES, V47, P1304, DOI 10.1109/78.757218
   Shih FY, 2016, INFORM SCIENCES, V367, P648, DOI 10.1016/j.ins.2016.07.015
   Shih FY, 2005, INFORM SCIENCES, V175, P200, DOI 10.1016/j.ins.2005.01.013
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tian Y, 2003, PATTERN RECOGN, V36, P649, DOI 10.1016/S0031-3203(02)00105-X
   Wakatani A., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P2043, DOI 10.1109/HICSS.2002.994129
   Wang ZH, 2013, J SYST SOFTWARE, V86, P315, DOI 10.1016/j.jss.2012.08.029
   WEI JC, 1989, INT J PROD RES, V27, P2053, DOI 10.1080/00207548908942674
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 30
TC 22
Z9 23
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17899
EP 17927
DI 10.1007/s11042-018-6820-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200026
DA 2024-07-18
ER

PT J
AU Chen, CC
   Lu, WY
   Chou, CH
AF Chen, Chien-Chang
   Lu, Wei-Yu
   Chou, Chung-Hsuan
TI Rotational copy-move forgery detection using SIFT and region growing
   strategies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forgery duplication; Invariant moment; Keypoints; Region growing
ID ALGORITHM
AB The proposed scheme detects the copy-move forgery regions using SIFT, invariant moments calculation, and the region growing strategy. First, the SIFT-based keypoints are acquired as the significant features of an image. Second, pairs of keypoints with closed scales are examined to identify all possible pair blocks of the copy-move regions. Third, the orientations for each pair of matched keypoints are adjusted to have identical orientation. Lastly, the copy-move regions are acquired using the region growing technique, and invariant moment features are applied to each pair of matched blocks. Experimental results show that the proposed scheme efficiently and effectively detects rotational copy-move duplicated regions. Moreover, the proposed computation time is proportional to the number of keypoints and the size of the copy-move forgery regions.
C1 [Chen, Chien-Chang; Lu, Wei-Yu; Chou, Chung-Hsuan] Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
C3 Tamkang University
RP Chen, CC (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
EM ccchen34@mail.tku.edu.tw
RI Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
FU National Science Council of the Republic of China [MOST
   106-2221-E-032-057]
FX This paper was partially supported by the National Science Council of
   the Republic of China under contract MOST 106-2221-E-032-057.
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2017, Math. Models Methods Appl. Sci., DOI DOI 10.1142/S0218202517500373
   Bi XL, 2018, MULTIMED TOOLS APPL, V77, P363, DOI 10.1007/s11042-016-4276-3
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen CC, 2017, MULTIMED TOOLS APPL, V77, P19327
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cox IJ., 2007, DIGITAL WATERMARKING
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Dixit R, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.2.023007
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Kobayashi M, 2010, IEEE T INF FOREN SEC, V5, P883, DOI 10.1109/TIFS.2010.2074194
   Lai YC, 2018, MULTIMED TOOLS APPL, V77, P15093, DOI 10.1007/s11042-017-5094-y
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lin CS, 2014, DIGIT INVEST, V11, P120, DOI 10.1016/j.diin.2014.03.016
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Exposing digital forgeries by detecting duplicated image regions
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Tu HK, 2015, INT C ADV TECHN COMM
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 34
TC 25
Z9 28
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18293
EP 18308
DI 10.1007/s11042-019-7165-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200043
DA 2024-07-18
ER

PT J
AU Kiranmaye, G
   Tadisetty, S
AF Kiranmaye, G.
   Tadisetty, Srinivasulu
TI A novel ortho normalized multi-stage discrete fast Stockwell transform
   based memory-aware high-speed VLSI implementation for image compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multistage discrete Stockwell transform (MFDST); RTU; CTU; DST
ID WAVELET TRANSFORM; EFFICIENT ARCHITECTURE; HIGH-PERFORMANCE
AB Image Compression is one of the emerging technique of Digital System for storing, retrieving of digital media applications. The main problem of Image Compression is requiring less space for storage and computation speed. In this paper we address this problem and develop a memory-efficient high speed architecture which is implemented based on orthonormalized multi-stage Fast-DST processing unit to perform lifting operation. The proposed multi-stage transform unit performs the split, predict and the update operations by considering the odd samples which are neglected in other lifting transforms. This results in speeding up the process because of the simultaneous execution of both samples. The RTU and CTU are erected with the aid of delay elements and the lifting coefficient, which further tends to attain the optimized processing speed. To address the problem of high cost of memory, multi stage proposed DST unit are combined to build a parallel multi-stage architecture which can perform multistage parallel execution on input image at competitive hardware cost. Finally, the proposed method attains better results when they are compared with existing in terms of memory complexity, low power, low latency.
C1 [Kiranmaye, G.] Jawaharlal Nehru Technol Univ, Very Large Scale Integrated Syst & Architectures, Hyderabad, Telangana, India.
   [Tadisetty, Srinivasulu] Kakatiya Univ, Kakatiya Engn Coll, Warangal, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Hyderabad; Kakatiya
   University
RP Kiranmaye, G (corresponding author), Jawaharlal Nehru Technol Univ, Very Large Scale Integrated Syst & Architectures, Hyderabad, Telangana, India.
EM kirangambala@gmail.com; drstadisetty@gmail.com
RI Tadisetty, Srinivasulu/ADO-3516-2022; Kiranmaye, G/IZE-5547-2023
OI Kiranmaye, G/0000-0002-5054-0342; srinivasulu,
   Tadisetty/0000-0003-0323-1843
CR Aziz SM, 2012, COMPUT ELECTR ENG, V38, P1325, DOI 10.1016/j.compeleceng.2012.05.009
   Cheng C, 2008, IEEE T SIGNAL PROCES, V56, P393, DOI 10.1109/TSP.2007.900754
   Darji A, 2014, IEEE T CIRCUITS-II, V61, P433, DOI 10.1109/TCSII.2014.2319975
   Das A, 2010, IEEE T CIRC SYST VID, V20, P286, DOI 10.1109/TCSVT.2009.2031551
   Haghighi B. B., 2018, ARXIV180302623
   Hashim AT, COLOR IMAGE COMPRESS
   Hsia CH, 2013, IEEE T CIRC SYST VID, V23, P671, DOI 10.1109/TCSVT.2012.2211953
   Hsia CH, 2009, IEEE T CIRC SYST VID, V19, P1202, DOI 10.1109/TCSVT.2009.2020259
   Huang CT, 2005, IEEE T CIRC SYST VID, V15, P910, DOI 10.1109/TCSVT.2005.848307
   Huang H, 2013, IEEE SIGNAL PROC LET, V20, P483, DOI 10.1109/LSP.2013.2252616
   Imgraben S, 2008, J SEA RES, V59, P83, DOI 10.1016/j.seares.2007.06.004
   Kahu S., 2013, International Journal of Advancements in Research & Technology, V2, P244
   Krasikov A, 2010, SOCIOECONOMIC DETERM
   Lai Y-K, IEEE T CONSUMER ELEC, V55, P400
   Lai YK, 2009, IEEE T CONSUM ELECTR, V55, P400, DOI 10.1109/TCE.2009.5174400
   Lee SJ, 2010, IEEE T BIOMED CIRC S, V4, P426, DOI 10.1109/TBCAS.2010.2079330
   Liang DD, 2013, IEEE T BIOMED CIRC S, V7, P24, DOI 10.1109/TBCAS.2012.2194144
   Mohanty BK, 2012, IEEE T CIRCUITS-II, V59, P434, DOI 10.1109/TCSII.2012.2200169
   Mohanty BK, 2013, IEEE T CIRC SYST VID, V23, P258, DOI 10.1109/TCSVT.2012.2203745
   Nian YJ, 2012, SCI CHINA INFORM SCI, P1
   Oweiss KG, 2007, IEEE T CIRCUITS-I, V54, P1266, DOI 10.1109/TCSI.2007.897726
   PramodMeher K, 2011, IEEE T SIGNAL PROCES, V59, P5605, DOI [10.1109/TSP.2011.2162510, DOI 10.1109/TSP.2011.2162510]
   Seo YH, 2010, IEEE T VLSI SYST, V18, P201, DOI 10.1109/TVLSI.2008.2009113
   Tian X, 2011, IEEE T COMPUT, V60, P1207, DOI 10.1109/TC.2010.178
   Wu BF, 2005, IEEE T CIRC SYST VID, V15, P1615, DOI 10.1109/TCSVT.2005.858610
   Xiong C, IEEE T IMAGE PROCESS, V16, P607
   Xiong CY, 2007, IEEE T IMAGE PROCESS, V16, P607, DOI 10.1109/TIP.2007.891069
   Xiong CY, 2006, IEEE T SIGNAL PROCES, V54, P1910, DOI 10.1109/TSP.2006.872538
   Zhang W, 2012, IEEE T CIRCUITS-II, V59, P158, DOI 10.1109/TCSII.2012.2184369
NR 29
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17673
EP 17699
DI 10.1007/s11042-018-7055-5
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200017
DA 2024-07-18
ER

PT J
AU Wu, C
   Li, YQ
   Zhao, ZB
   Liu, B
AF Wu, Chao
   Li, Yaqian
   Zhao, Zhibiao
   Liu, Bin
TI Image classification method rationally utilizing spatial information of
   the image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial pyramid matching; Local position feature; Global contour
   feature; Neural network; Histogram intersection kernel weighted learning
   network
ID EXTREME LEARNING-MACHINE; GLOBAL FEATURES; VISUAL-WORDS; REPRESENTATION;
   KERNEL; FUSION
AB In order to improve the accuracy of image classification problem, this paper proposes a new classification method based on image feature extraction and neural network. The method consists of two stages: image feature extraction and neural network classification. At the stage of feature extraction, spatial pyramid matching (SPM) feature, local position feature and global contour feature are extracted. The utilization of spatial information in SPM feature is effectively improved by combining the above three features. At the stage of neural network classification, a multi-hidden layer feedforward Histogram Intersection Kernel Weighted Learning Network (HWLN) is proposed to take advantage of three features to improve the classification accuracy. In the structure of network, the hidden layer output features are used as the bias of the input features to weight the coefficients of the features. The input layer and the hidden layers are directly connected with the output layer to realize the combination of linear mapping and nonlinear mapping. And the Histogram Intersection Kernel is used instead of random initialization of the input weight matrix. Taking combined features as input information, HWLN can realize the mapping relationship between input information and target category, so as to complete the image classification task. Extensive experiments are performed on Caltech 101, Caltech 256 and MSRC databases respectively. The experimental results show that the proposed method further utilizes the spatial information, and thus improves the accuracy of image classification.
C1 [Wu, Chao; Zhao, Zhibiao; Liu, Bin] Yanshan Univ, Inst Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Li, Yaqian] Yanshan Univ, Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Yanshan University
RP Li, YQ (corresponding author), Yanshan Univ, Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066004, Hebei, Peoples R China.
EM yaqianli@126.com
RI liu, bb/GXA-2527-2022
FU National Natural Science Foundation of China [51641609]; Natural Science
   Foundation of Hebei Province of China [F2015203212]
FX This work is supported by National Natural Science Foundation of China
   (No. 51641609), Natural Science Foundation of Hebei Province of China
   (No. F2015203212).
CR Ahmed KT, 2017, APPL INTELL, V47, P526, DOI 10.1007/s10489-017-0916-1
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Anwar H, 2014, LECT NOTES COMPUT SC, V8753, P443, DOI 10.1007/978-3-319-11752-2_36
   Avila S, 2013, COMPUT VIS IMAGE UND, V117, P453, DOI 10.1016/j.cviu.2012.09.007
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Deng WY, 2016, NEURAL NETWORKS, V76, P29, DOI 10.1016/j.neunet.2015.10.006
   Frome A., 2007, NIPS, V19, P417
   Frome A, 2007, IEEE I CONF COMP VIS, P94
   Goh H, 2014, IEEE T NEUR NET LEAR, V25, P2212, DOI 10.1109/TNNLS.2014.2307532
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Gui J, 2016, IEEE T CYBERNETICS, V46, P1877, DOI 10.1109/TCYB.2015.2457234
   Hu J., 2017, CoRR
   Huang GB, 2004, IEEE IJCNN, P985
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huang Y, 2007, CONTEMPORARY CHINESE LITERATURE: FROM THE CULTURAL REVOLUTION TO THE FUTURE, P1, DOI 10.1057/9780230608757
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Juneja M, 2013, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2013.124
   Khan R, 2015, COMPUT VIS IMAGE UND, V132, P102, DOI 10.1016/j.cviu.2014.09.005
   Koniusz P, 2017, IEEE T PATTERN ANAL, V39, P313, DOI 10.1109/TPAMI.2016.2545667
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li GQ, 2014, NEURAL COMPUT APPL, V24, P1683, DOI 10.1007/s00521-013-1398-7
   Li Q., 2018, IEEE Transactions on Geoscience and Remote Sensing, V99, P1
   Li WS, 2016, NEUROCOMPUTING, V172, P271, DOI 10.1016/j.neucom.2015.01.083
   [李雅倩 Li Yaqian], 2018, [电子学报, Acta Electronica Sinica], V46, P1726
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Mansourian L, 2018, MULTIMED TOOLS APPL, V77, P16131, DOI 10.1007/s11042-017-5192-x
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Perronnin F., 2007, IEEE C COMPUTER VISI
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang S, 2016, PATTERN RECOGN, V57, P179, DOI 10.1016/j.patcog.2016.02.019
   Xiong W, 2017, PATTERN RECOGN, V62, P225, DOI 10.1016/j.patcog.2016.08.006
   Zafar B, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0198175
   Zhu QH, 2017, APPL INTELL, V47, P148, DOI 10.1007/s10489-016-0887-7
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
NR 41
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19181
EP 19199
DI 10.1007/s11042-019-7254-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800012
DA 2024-07-18
ER

PT J
AU Kim, WH
   Nam, SH
   Kang, JH
   Lee, HK
AF Kim, Wook-Hyung
   Nam, Seung-Hun
   Kang, Ji-Hyeon
   Lee, Heung-Kyu
TI Robust watermarking in curvelet domain for preserving cleanness of
   high-quality images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content copyright protection; Digital content watermark; Curvelet
   transform; High-quality content; Blind detection
ID SYSTEM; TRANSFORM
AB Watermarking inserts invisible data into content to protect copyright. The embedded information provides proof of authorship and facilitates the tracking of illegal distribution, etc. Current robust watermarking techniques have been proposed to preserve inserted copyright information from various attacks, such as content modification and watermark removal attacks. However, since the watermark is inserted in the form of noise, there is an inevitable effect of reducing content visual quality. In general, most robust watermarking techniques tend to have a greater effect on quality, and content creators and users are often reluctant to insert watermarks. Thus, there is a demand for a watermark that maintains maximum image quality, even if the watermark performance is slightly inferior. Therefore, we propose a watermarking technique that maximizes invisibility while maintaining sufficient robustness and data capacity to be applied in real situations. The proposed method minimizes watermarking energy by adopting curvelet domain multi-directional decomposition to maximize invisibility and maximizes robustness against signal processing attacks with a watermarking pattern suitable for curvelet transformation. The method is also robust against geometric attacks by employing the watermark detection method utilizing curvelet characteristics. The proposed method showed very good results of a 57.65dB peak signal-to-noise ratio in fidelity tests, and the mean opinion score showed that images treated with the proposed method were hardly distinguishable from the originals. The proposed technique also showed good robustness against signal processing and geometric attacks compared with existing techniques.
C1 [Kim, Wook-Hyung; Nam, Seung-Hun; Kang, Ji-Hyeon; Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejeon 34141, South Korea.
EM whkim@mmc.kaist.ac.kr; shnam@mmc.kaist.ac.kr; jhkang@mmc.kaist.ac.kr;
   heunglee@kaist.ac.kr
RI Nam, Seung-Hun/AAT-8449-2021
OI Nam, Seung-Hun/0000-0002-2576-7342
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT)
CR [Anonymous], METHODS
   [Anonymous], P 2003 I E COMP SOC
   [Anonymous], METH SUBJ ASS QUAL T
   [Anonymous], 2000, CURVES SURFACES
   [Anonymous], IEEE C EVOL COMPUTAT
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Candès EJ, 2002, SIGNAL PROCESS, V82, P1519, DOI 10.1016/S0165-1684(02)00300-6
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Channapragada RSR, 2015, SMART INNOV SYST TEC, V31, P199, DOI 10.1007/978-81-322-2205-7_19
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ., 2007, DIGITAL WATERMARKING
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Kim WH, 2017, ELECTRON LETT, V53, DOI 10.1049/el.2017.0955
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Nayak DR, 2018, MULTIMED TOOLS APPL, V77, P3833, DOI 10.1007/s11042-016-4171-y
   Nayak DR, 2017, EXPERT SYST APPL, V88, P152, DOI 10.1016/j.eswa.2017.06.038
   Nguyen SC, 2015, PROC INT CONF ADV, P445, DOI 10.1109/ATC.2015.7388369
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zhang CE, 2008, IEEE T INF FOREN SEC, V3, P611, DOI 10.1109/TIFS.2008.2004288
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 27
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16887
EP 16906
DI 10.1007/s11042-018-6879-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500051
DA 2024-07-18
ER

PT J
AU Mukherjee, S
   Sanyal, G
AF Mukherjee, Srilekha
   Sanyal, Goutam
TI Edge based image steganography with variable threshold
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Peak signal to noise ratio; Entropy; Cross correlation
ID OPTIMIZATION; CAPACITY; SCHEME; MAP
AB With the rapid escalation of the usage of sensitive data exchange through internet, information security has become a vulnerable realm of concern. Numerous security policies are incorporated, steganography being one of them. In this paper, a new image steganography technique facilitating embedding and extraction mechanisms have been proposed. The classic technique of edge detection is employed in which the threshold is made to vary for every new input test case. Relying on the threshold generation methodology, each edge image is generated in accordance with a distinct key threshold value. This in turn directs the insertion and extraction strategies. By using different performance metrics, like Payload, Mean Squared Error, Peak Signal to Noise Ratio, Structural Similarity Index, Kullback-Leibler Divergence, Cross-correlation, etc., this procedure substantiates better results. It has quite a remarkable embedding capacity (i.e. Payload). Also the values of Peak Signal to Noise Ratio and Structural Similarity Index indicate that the imperceptibility of the stego-image is well-maintained. The statistical results obtained reassure the undetectability of the hidden image. This approach may be used to deliver a status of security to a system which communicates secure data files through any public surveillance medium.
C1 [Mukherjee, Srilekha; Sanyal, Goutam] Natl Inst Technol, CSE, Durgapur, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur
RP Mukherjee, S (corresponding author), Natl Inst Technol, CSE, Durgapur, India.
EM srilekha.mukherjee3@gmail.com; nitgsanyal@gmail.com
RI Mukherjee, Srilekha/ABA-7026-2020; SANYAL, GOUTAM/AAI-6613-2020
CR Abdallah EE, 2007, LECT NOTES COMPUT SC, V4633, P772
   Abdallah EE, 2010, SIGNAL IMAGE VIDEO P, V4, P233, DOI 10.1007/s11760-009-0114-7
   Almohammad A, 2010, STEGO IMAGE QUALITY
   Altaay AAJ, 2012, IEEE INT C ADV COMP
   [Anonymous], INT J COMPUTER INFOR
   [Anonymous], 2004, IEEE INT C IND INF B
   Balitanas, 2011, COMMUN COMPUT PHYS, P151
   Banerjee I, 2015, INT J ELECT SECUR DI, V7
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Bhattacharyya S., 2012, INT J APPL INF SYST, V2, P42
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Dukkipati A, 2012, APPL MATH COMPUT, V218, P11674, DOI 10.1016/j.amc.2012.05.052
   Duncan K, 2012, IEEE IMAGE PROC, P1093, DOI 10.1109/ICIP.2012.6467054
   El-Alfy El-Sayed M., 2011, 2011 9th IEEE/ACS International Conference on Computer Systems and Applications (AICCSA), P144, DOI 10.1109/AICCSA.2011.6126588
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   Feng JH, 2017, MULTIMED TOOLS APPL, V76, P17405, DOI 10.1007/s11042-016-3907-z
   Ferzli R, 2010, IMAGE PROCESSING ALG, P75320
   Gurav J., 2015, INT J RECENT INNOV T, V3, P1836
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Huang P, 2008, J MULTIMED, V3
   Kahn J, 2007, COMB PROBAB COMPUT, V16, P495, DOI 10.1017/S096354830700S474
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Koo HI, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013020
   Kumar V., 2012, International Journal of Emerging Technology and Advanced Engineering, V2, P56, DOI 10.1070/pu1997v040n05abeh000236.www.ijetae.com
   Lan TH, 2000, IEEE IMAGE PROC, P581, DOI 10.1109/ICIP.2000.901025
   Li QH, 2016, J COMPUT SCI TECH-CH, V31, P225, DOI 10.1007/s11390-016-1623-9
   Liu LF, 2017, MULTIMED TOOLS APPL, V76, P16511, DOI 10.1007/s11042-016-3925-x
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mohapatra S, 2012, NEURAL COMPUT APPL, V21, P281, DOI 10.1007/s00521-011-0583-9
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P18985, DOI 10.1007/s11042-017-4420-8
   MUKHERJEE S, 2015, TENCON IEEE REGION, pN1582
   Mukherjee S, 2017, INT J COMPUT APPL, V39
   Mukherjee S, 2015, IEEE C PUBLICATIONS, V201
   Safarpour M, 2016, 160100299 CORRABS
   Sajedi H, 2016, J INF SECUR APPL, V30, P3, DOI 10.1016/j.jisa.2016.04.001
   Sheisi H, 2012, INT J COMPUTER ELECT, V4
   Soleymani SH, 2017, MULTIMED TOOLS APPL, V76, P20847, DOI 10.1007/s11042-016-4009-7
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Sun SL, 2016, INFORM PROCESS LETT, V116, P93, DOI 10.1016/j.ipl.2015.09.016
   Tiwari N, 2014, INT J ADV COMPUT SC, V5, P156
   Wakure MA, 2015, INT J COMPUT APPL, V129
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Yang X, 2016, COMPUT ELECT ENG
   Yevseyeva I, 2016, PROCEDIA COMPUT SCI, V100, P971, DOI 10.1016/j.procs.2016.09.261
NR 44
TC 9
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16363
EP 16388
DI 10.1007/s11042-018-6975-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500029
DA 2024-07-18
ER

PT J
AU Pae, DS
   An, CG
   Kang, TK
   Lim, MT
AF Pae, Dong Sung
   An, Chi Gun
   Kang, Tae Koo
   Lim, Myo Taeg
TI Advanced digital image stabilization using similarity-constrained
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image stabilization; MSURF; K-means
ID VIDEO STABILIZATION; MOTION
AB As many people have portable video devices such as cameras on cell phones and camcorders, image stabilization technique is a crucial and challenging task in computer vision applications, and many image stabilization techniques have been researched over many years. We propose a digital image stabilization method that only uses a software algorithm without additional hardware devices. Furthermore, a novel digital image stabilization method composed of three steps that use similarity-constrained nonlinear optimizer is introduced and applied to many unstabilized videos. First, a feature detection technique called moment-based speeded-up robust features (MSURF) is utilized to obtain the transformation matrix. Second, the k-means clustering algorithm is used to detect and remove some of the outliers that cause residual errors during feature matching. Third, the transformation matrix is optimized using nonlinear optimization algorithms to maintain the similarity of the transformation matrix. The experimental results prove that the proposed algorithm provides accurate image stabilization performance.
C1 [Pae, Dong Sung; Lim, Myo Taeg] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [An, Chi Gun] Samsung Elect Co, Mechatron R&D Ctr, Hwasung Si, South Korea.
   [Kang, Tae Koo] Sangmyung Univ, Dept Human Intelligence & Robot Engn, Cheonan, South Korea.
C3 Korea University; Samsung; Sangmyung University
RP Lim, MT (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.; Kang, TK (corresponding author), Sangmyung Univ, Dept Human Intelligence & Robot Engn, Cheonan, South Korea.
EM paeds915@korea.ac.kr; chigun.an@samsung.com; tkkang@smu.ac.kr;
   mlim@korea.ac.kr
RI Pae, Dong-Sung/AAD-2470-2022
OI Lim, Myo Taeg/0000-0003-2990-8066
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Education [NRF-2016R1D1A1B01016071]; Residential
   Environment Research Program through the Infrastructure and Transport of
   Korean government - Ministry of Land [14RERP-B082204-01]
FX This paper is supported by Basic Science Research Program through the
   National Research Foundation of Korea funded by the Ministry of
   Education under Grant (NRF-2016R1D1A1B01016071), and Residential
   Environment Research Program through the Infrastructure and Transport of
   Korean government funded by Ministry of Land under a
   grant(14RERP-B082204-01).
CR Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bosco A, 2008, IEEE T CONSUM ELECTR, V54, P220, DOI 10.1109/TCE.2008.4560078
   Ertürk S, 2002, REAL-TIME IMAGING, V8, P317, DOI 10.1006/rtim.2001.0278
   Favorskaya MN, 2014, COMPUTER VISION CONT
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Hadawale N, 2018, INT J CURRENT TREDNS, V8, P182
   He J, 2014, IMAGE VISION COMPUT, V32, P800, DOI 10.1016/j.imavis.2014.02.015
   Kang TK, 2015, PATTERN RECOGN, V48, P670, DOI 10.1016/j.patcog.2014.06.022
   Kang TK, 2012, ETRI J, V34, P572, DOI 10.4218/etrij.12.0111.0538
   Kim SK, 2013, IEEE T CONSUM ELECTR, V59, P267, DOI 10.1109/TCE.2013.6490269
   Kim SW, 2014, COMPUT VIS IMAGE UND, V118, P71, DOI 10.1016/j.cviu.2013.09.005
   Kir B, 2015, IEEE SIGNAL PROC LET, V22, P341, DOI 10.1109/LSP.2014.2359981
   Kumar V, 2016, IEEE T IMAGE PROCESS, V25, P5212, DOI 10.1109/TIP.2016.2605919
   Lee TH, 2014, J VIS COMMUN IMAGE R, V25, P943, DOI 10.1016/j.jvcir.2014.02.011
   Li DY, 2017, IEEE T COMPUT IMAG, V3, P749, DOI 10.1109/TCI.2017.2671360
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Ma ZG, 2018, IEEE T NEUR NET LEAR, V29, P2921, DOI 10.1109/TNNLS.2017.2709308
   Okade M, 2014, IETE J RES, V60, P373, DOI 10.1080/03772063.2014.962627
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Puglisi G, 2011, IEEE T CIRC SYST VID, V21, P1390, DOI 10.1109/TCSVT.2011.2162689
   RIENER A, 2016, IEEE INT C CONS EL I, P217
   Wang S, 2016, IEEE T KNOWL DATA EN, V28, P3191, DOI 10.1109/TKDE.2016.2605687
   Xu J, 2012, IEEE T CONSUM ELECTR, V58, P993, DOI 10.1109/TCE.2012.6311347
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
   Yeni AA, 2005, IEEE T CONSUM ELECTR, V51, P917, DOI 10.1109/TCE.2005.1510503
NR 26
TC 3
Z9 3
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16489
EP 16506
DI 10.1007/s11042-018-6932-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500034
DA 2024-07-18
ER

PT J
AU Yahya, AA
   Tan, JQ
   Su, BY
   Liu, K
   Hadi, AN
AF Yahya, Ali Abdullah
   Tan, Jieqing
   Su, Benyu
   Liu, Kui
   Hadi, Ali Naser
TI Image noise reduction based on adaptive thresholding and clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive thresholding; Hard-thresholding; Soft-thresholding; K-means
   clustering; Block matching; Reference-blocks; Candidate-blocks
ID SCALE; REMOVAL
AB In this paper, we present a novel image denoising method based on adaptive thresholding and k-means clustering. In this method, we adopt the adaptive thresholding technique as an alternative to the traditional hard-thresholding of the block-matching and 3D filtering (BM3D) method. This technique has a high capacity to adapt and change according to the amount of the noise. More precisely, in our method the soft-thresholding is applied to the areas with heavy noise, on the contrary the hard-thresholding is applied to the areas with slight noise. Based on the adaptation and stability of the adaptive thresholding, we can achieve optimal noise reduction and maintain the high spatial frequency detail (e.g. sharp edges). Owing to the capacity of k-means clustering in terms of finding the relevant candidate-blocks, we adopt this clustering at the last estimate to partition the denoised image into several regions and identify the boundaries between these regions. Applying k-means clustering will allow us to force the block matching to search within the region of the reference block, which in turn will lead to minimize the risk of finding poor matching. The main reason of applying the K-means clustering method on the denoised image and not on the noised image is specifically due to the flaw of accuracy in detecting edges in the noisy image. Experimental results demonstrate that the new algorithm consistently outperforms other reference methods in terms of visual quality, Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM). Furthermore, in the proposed algorithm the time consumption of the image denoising is less than that in the other reference algorithms.
C1 [Yahya, Ali Abdullah; Su, Benyu; Liu, Kui] Anqing Normal Univ, Sch Comp & Informat, Anqing 246011, Peoples R China.
   [Tan, Jieqing; Hadi, Ali Naser] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Anqing Normal University; Hefei University of Technology
RP Yahya, AA (corresponding author), Anqing Normal Univ, Sch Comp & Informat, Anqing 246011, Peoples R China.
EM aselwey1@hotmail.com
RI Tan, Jie/IVV-5250-2023; Hadi, Ali/JZD-8785-2024
FU ANHUI Province Key Laboratory of Affective Computing & Advanced
   Intelligent Machine [ACAIM180201]
FX This work is supported by ANHUI Province Key Laboratory of Affective
   Computing & Advanced Intelligent Machine, Grant (No. ACAIM180201).
CR [Anonymous], P INT C IM PROC GEN
   Bayram I, 2012, EUR SIGNAL PR CONF, P265
   Beigman Eyal, 2009, P JOINT C 47 ANN M A, P280
   Chatterjee P, 2010, IEEE T IMAGE PROCESS, V19, P895, DOI 10.1109/TIP.2009.2037087
   Chen QA, 2010, SIGNAL PROCESS, V90, P2778, DOI 10.1016/j.sigpro.2010.03.016
   Dabov K., 2008, PROC INT WORKSHOP LO, P1
   Dabov K., 2009, Signal Processing with Adaptive Sparse Structured Representations (SPARS'09)
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Danielyan A, 2012, IEEE T IMAGE PROCESS, V21, P1715, DOI 10.1109/TIP.2011.2176954
   Djurovic I, 2017, SIGNAL IMAGE VIDEO P, V11, P753, DOI 10.1007/s11760-016-1019-x
   Djurovic I, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0113-x
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Frénay B, 2014, IEEE T NEUR NET LEAR, V25, P845, DOI 10.1109/TNNLS.2013.2292894
   Ghael SP, 1997, P SOC PHOTO-OPT INS, V3169, P389, DOI 10.1117/12.292799
   Guleryuz OG, 2003, CONF REC ASILOMAR C, P1992
   Guo Y., 2016, International Joint Conference on Artificial Intelligence, P3382
   Guo YC, 2018, IEEE T IMAGE PROCESS, V27, P949, DOI 10.1109/TIP.2017.2766445
   Guo YC, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P115, DOI 10.1145/2671188.2749317
   Huang Lingli, 2015, J. Comput. Commun, V3, P23, DOI DOI 10.4236/JCC.2015.34003
   Huang XL, 2018, MOBILE NETW APPL, V23, P100, DOI 10.1007/s11036-017-0886-x
   Jitha CR, 2015, INT J SCI ENG RES, V6, P802
   Li Dai, 2013, Information Technology Journal, V12, P1995, DOI 10.3923/itj.2013.1995.2001
   LINDENBAUM M, 1994, PATTERN RECOGN, V27, P1, DOI 10.1016/0031-3203(94)90013-2
   Maggioni M, 2014, IEEE T IMAGE PROCESS, V23, P4282, DOI 10.1109/TIP.2014.2345261
   Maggioni M, 2011, PROC SPIE, V7870, DOI 10.1117/12.872569
   Manjón JV, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0073021
   Manwani N, 2013, IEEE T CYBERNETICS, V43, P1146, DOI 10.1109/TSMCB.2012.2223460
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pizurica A, 2002, IEEE T IMAGE PROCESS, V11, P545, DOI 10.1109/TIP.2002.1006401
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Tae Hwan Lee, 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P128, DOI 10.1109/ISCE.2011.5973798
   Wang X., 2015, INT J SIGNAL PROCESS, V8, P227, DOI DOI 10.14257/ijsip.2015.8.4.20
   Yahya AA, 2017, J ENG-JOE, V2017, P246, DOI 10.1049/joe.2017.0112
   Yahya AA, 2014, MULTIMED TOOLS APPL, V73, P1843, DOI 10.1007/s11042-013-1586-6
   Yang Y., 2005, IEEE workshop on wireless mesh networks (WiMesh), P1
   Zhang L, 2009, IEEE T IMAGE PROCESS, V18, P797, DOI 10.1109/TIP.2008.2011384
NR 38
TC 7
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15545
EP 15573
DI 10.1007/s11042-018-6955-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700061
DA 2024-07-18
ER

PT J
AU Baskar, D
   Jayanthi, VS
   Jayanthi, AN
AF Baskar, D.
   Jayanthi, V. S.
   Jayanthi, A. N.
TI An efficient classification approach for detection of Alzheimer's
   disease from biomedical imaging modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biomedical imaging; Structural MRI; KFCM; BPANN; Hippocampus; Posterior
   cingulate cortex; AAL
ID TEXTURAL FEATURES; BRAIN IMAGES; MRI; ATROPHY; CONVERSION; SCALE; ONSET;
   FOCUS; FMRI; MCI
AB The complex patterns of the neuroimaging data are analyzed successfully with bio-medical imaging applications. The patients with/without AD can be discriminated effectively through several biomedical imaging modalities such as, sMRI, fMRI, PET and so on. In this paper, brain images from structural MRI (sMRI) are used for better categorization of 3 subjects namely, NC (Normal Control), MCI (Mild Cognitive Impairment) and AD (Alzheimer's disease). Moreover, ambiguous training data employed for the discrimination of subjects may mislead the classifier to take incorrect decisions and in turn degrades the classification performance. In order to recover these hurdles, we propose an automated reliable system for the detection of AD affected patients accurately from the brain images of sMRI. The proposed system is a multi-stage system comprising four key phases namely, i) pre-processing, ii) feature extraction, iii) feature selection and iv) detection phase. In the initial phase, ROI regions related to Hippocampus (HC) and Posterior Cingulate Cortex (PCC) from the brain images are extracted using Automated Anatomical Labeling (AAL) method. In the feature extraction stage, important texture and shape features are extracted from HC and PCC involved in three brain planes. Nearly, 19 highly relevant AD related features are selected through a multiple-criterion feature selection method. It should be noted that, the class labels when explored manually consumes more time and turns to be an expensive process. Therefore, it is essential to construct an automatic method to identify irrelevant samples in the training data to enhance the decision-making process. With this in mind, at the detection phase, a novel classification technique is proposed by combining the Kernel fuzzy c-means clustering (i.e. unsupervised learning technique) and Back-propagation artificial neural network (i.e. supervised learning technique) to categorize NC, MCI and AD from the brain images of sMRI. This proposed KFCM based BPANN algorithm can improve the classification performance by removing the suspicious training samples. The proposed frameworks efficiency is evaluated with the ADNI subset and then to the Bordeaux-3 city dataset. The experimental validation of our proposed approach attains an accuracy of 97.63%, 95.4%, 96.4% for the most challenging classification tasks AD vs NC, MCI vs NC and AD vs MCI, respectively.
C1 [Baskar, D.] Hindusthan Coll Engn & Technol, Elect & Commun Engn Dept, Coimbatore, Tamil Nadu, India.
   [Jayanthi, V. S.] Rajagiri Sch Engn & Technol, Elect & Commun Engn Dept, Cochin, Kerala, India.
   [Jayanthi, A. N.] Sri Ramakrishna Inst Technol, Elect & Commun Engn Dept, Coimbatore, Tamil Nadu, India.
C3 Rajagiri School of Engineering & Technology
RP Baskar, D (corresponding author), Hindusthan Coll Engn & Technol, Elect & Commun Engn Dept, Coimbatore, Tamil Nadu, India.
EM dbaskarphd@gmail.com
RI N, J/JOZ-6459-2023; A N, Jayanthi/ADU-3959-2022; Duraisamy,
   Baskar/AAB-2970-2021
OI A N, Jayanthi/0000-0002-6524-4941; 
CR Ahmed MM, 2004, INT J IMAGE PROCESS, V2, P27
   Akgul CeyhunBurak., 2009, Proceedings of the ACM International Conference on Image and Video Retrieval, p34:1, DOI DOI 10.1145/1646396.1646438
   Aksu Y, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0025074
   AMADASUN M, 1989, IEEE T SYST MAN CYB, V19, P1264, DOI 10.1109/21.44046
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], 2013, J COMPUT SCI SYST BI
   Arbabshirani MR, 2017, NEUROIMAGE, V145, P137, DOI 10.1016/j.neuroimage.2016.02.079
   Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Beheshti I, 2015, COMPUT BIOL MED, V64, P208, DOI 10.1016/j.compbiomed.2015.07.006
   Ben Ahmed O, 2015, COMPUT MED IMAG GRAP, V44, P13, DOI 10.1016/j.compmedimag.2015.04.007
   Bezdek James C., 1981, PATTERN RECOGN
   Cabral C, 2015, COMPUT BIOL MED, V58, P101, DOI 10.1016/j.compbiomed.2015.01.003
   Challis E, 2015, NEUROIMAGE, V112, P232, DOI 10.1016/j.neuroimage.2015.02.037
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chen G, 2011, RADIOLOGY, V259, P213, DOI 10.1148/radiol.10100734
   Cheng B, 2015, IEEE T BIO-MED ENG, V62, P1805, DOI 10.1109/TBME.2015.2404809
   Chételat G, 2008, BRAIN, V131, P60, DOI 10.1093/brain/awm288
   Cho Y, 2012, NEUROIMAGE, V59, P2217, DOI 10.1016/j.neuroimage.2011.09.085
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   Cocosco CA, 2003, MED IMAGE ANAL, V7, P513, DOI 10.1016/S1361-8415(03)00037-9
   Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013
   DASARATHY BV, 1991, PATTERN RECOGN LETT, V12, P497, DOI 10.1016/0167-8655(91)80014-2
   Davatzikos C, 2008, NEUROBIOL AGING, V29, P514, DOI 10.1016/j.neurobiolaging.2006.11.010
   DYER CR, 1976, IEEE T SYST MAN CYB, V6, P703
   El-Dahshan ESA, 2010, DIGIT SIGNAL PROCESS, V20, P433, DOI 10.1016/j.dsp.2009.07.002
   El-Sayed A, 2009, HYBRID TECHNIQUE AUT, VLIV
   Falahati F, 2014, J ALZHEIMERS DIS, V41, P685, DOI 10.3233/JAD-131928
   Fiot JB, 2014, NEUROIMAGE-CLIN, V4, P718, DOI 10.1016/j.nicl.2014.02.002
   Fransson P, 2005, HUM BRAIN MAPP, V26, P15, DOI 10.1002/hbm.20113
   Frisoni GB, 2005, J NEUROL NEUROSUR PS, V76, P112, DOI 10.1136/jnnp.2003.029876
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Giraldo DL, 2018, BRAIN BEHAV, V8, DOI 10.1002/brb3.942
   Gonzalez RC, 2010, DIGITAL IMAGE PROCES
   Gutman B, 2009, HIPPOCAMPUS, V19, P572, DOI 10.1002/hipo.20627
   Hagan M.T., 1996, NEURAL NETWORK DESIG
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Herrera LJ, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P846, DOI 10.1109/SocialCom.2013.127
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ishii K, 2005, AM J NEURORADIOL, V26, P333
   Jie B, 2014, IEEE T BIO-MED ENG, V61, P576, DOI 10.1109/TBME.2013.2284195
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Jones BF, 2006, CEREB CORTEX, V16, P1701, DOI 10.1093/cercor/bhj105
   Khazaee A, 2015, CLIN NEUROPHYSIOL, V126, P2132, DOI 10.1016/j.clinph.2015.02.060
   Kim YS, 2016, FEATURE SELECTION DA
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Laws K. I., 1980, Proceedings of the Society of Photo-Optical Instrumentation Engineers, V238, P376
   Li B, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P493, DOI 10.1109/ISCSCT.2008.40
   Liu FY, 2014, IEEE J BIOMED HEALTH, V18, P984, DOI 10.1109/JBHI.2013.2285378
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   McGowan JC, 2008, NEUROIMAG CLIN N AM, V18, P623, DOI 10.1016/j.nic.2008.06.004
   Nir TM, 2015, NEUROBIOL AGING, V36, pS132, DOI 10.1016/j.neurobiolaging.2014.05.037
   Pan YH, 2015, IEEE ENG MED BIO, P699, DOI 10.1109/EMBC.2015.7318458
   Pievani M, 2011, LANCET NEUROL, V10, P829, DOI 10.1016/S1474-4422(11)70158-2
   Ridha BH, 2007, ARCH NEUROL-CHICAGO, V64, P849, DOI 10.1001/archneur.64.6.849
   Rusinek H, 2003, RADIOLOGY, V229, P691, DOI 10.1148/radiol.2293021299
   Sabuncu MR, 2015, NEUROINFORMATICS, V13, P31, DOI 10.1007/s12021-014-9238-1
   Saha S, 2007, IEEE C EVOL COMPUTAT, P4417, DOI 10.1109/CEC.2007.4425049
   Salvatore C, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00307
   Sarraf S., 2016, BIORXIV070441
   Serrano-Pozo A, 2011, CSH PERSPECT MED, V1, DOI 10.1101/cshperspect.a006189
   Shen KK, 2012, NEUROIMAGE, V59, P2155, DOI 10.1016/j.neuroimage.2011.10.014
   Srinivasan G.N., 2008, Engineering and Technology, V36, P1264
   Stoitsis J, 2006, IEEE T INSTRUM MEAS, V55, P1944, DOI 10.1109/TIM.2006.884348
   Sujatha K, 2018, MULTIMED TOOLS APPL, V77, P1735, DOI 10.1007/s11042-016-4312-3
   Sundararaj V., 2016, INT J INTELLIGENT EN, V9, P117, DOI DOI 10.22266/ijies2016.0930.12
   Tang J., 2014, DATA CLASSIFICATION
   Termenon M, 2012, NEURAL PROCESS LETT, V35, P1, DOI 10.1007/s11063-011-9200-2
   Toga AW, 2001, ANAT EMBRYOL, V204, P267, DOI 10.1007/s004290100198
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Weishaupt D., 2003, DOES MRI WORK INTRO
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   WU CM, 1992, CVGIP-GRAPH MODEL IM, V54, P407, DOI 10.1016/1049-9652(92)90025-S
   WU CM, 1992, IEEE T MED IMAGING, V11, P141, DOI 10.1109/42.141636
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
NR 77
TC 18
Z9 20
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 12883
EP 12915
DI 10.1007/s11042-018-6287-8
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900011
DA 2024-07-18
ER

PT J
AU Pak, C
   An, K
   Jang, P
   Kim, J
   Kim, S
AF Pak, Chanil
   An, Kwangil
   Jang, Paeksan
   Kim, Jonggun
   Kim, Sok
TI A novel bit-level color image encryption using improved 1D chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Chaotic system; Image encryption
ID PERMUTATION; TRANSFORM; SYSTEM
AB This paper introduces new simple and effective improved one-dimension(1D) Logistic map and Sine map made by the output sequences of two same existing 1D chaotic maps. The comparison analysis of the proposed improved 1D chaotic map and previous 1D chaotic map confirmed the accuracy of the improved chaotic map. To investigate the applications of the improved chaotic system in image encryption, a novel bit-level image encryption system is proposed. Experiments and analysis prove that the improved chaotic map and the algorithm has an excellent performance in image encryption and various attacks.
C1 [Pak, Chanil; An, Kwangil] Kim Chaek Univ Technol, Informat Ctr, Pyongyang 950003, North Korea.
   [Jang, Paeksan] Kim Chaek Univ Technol, Inst Nano Phys Engn, Pyongyang 950003, North Korea.
   [Kim, Jonggun] Kim Il Sung Univ, Informat Ctr, Pyongyang 950003, North Korea.
   [Kim, Sok] Chongjin Mine Met Univ, Dept Informat Engn, Chongjin 999091, North Korea.
RP Pak, C (corresponding author), Kim Chaek Univ Technol, Informat Ctr, Pyongyang 950003, North Korea.
EM pakchanil@126.com
RI Jang, Paeksan/HJA-8562-2022; Kim, Sok/AAP-9139-2020
OI Kim, Sok/0000-0001-6971-1626; An, Kwangil/0000-0002-9342-6427; Pak,
   Chanil/0000-0003-2344-6438; Jang, Paeksan/0000-0001-9942-1419
CR Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   [Anonymous], IEEE T SYST MAN CY A
   Arroyo D, 2013, SIGNAL PROCESS, V93, P1358, DOI 10.1016/j.sigpro.2012.11.019
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Bhatnagar G, 2012, IEEE T SYST MAN CY A, V42, P262, DOI 10.1109/TSMCA.2011.2147307
   Cao LC, 2015, CHINESE PHYS B, V24, DOI 10.1088/1674-1056/24/10/100501
   Chen TH, 2010, INFORM SCIENCES, V180, P1690, DOI 10.1016/j.ins.2009.12.021
   Diaconu AV, 2015, INF SCI, V000, P1
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Fu C, 2011, OPT COMMUN, V284, P5415, DOI 10.1016/j.optcom.2011.08.013
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Jeng FG, 2015, SIGNAL PROCESS-IMAGE, V34, P45, DOI 10.1016/j.image.2015.03.003
   Kassem A, 2014, DIGIT SIGNAL PROCESS, V25, P266, DOI 10.1016/j.dsp.2013.11.004
   Kumar R. Ranjith, 2014, ICTACT J IMAGE VIDEO, V4, P795, DOI [10.21917/ijivp.2014.0114, DOI 10.21917/IJIVP.2014.0114]
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Nandeesh G.S., 2013, IJCSMC, V2, P145
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Teng L, 2012, OPT COMMUN, V285, P4048, DOI 10.1016/j.optcom.2012.06.004
   Wang W, 2018, COMPUT ELECTR ENG, V65, P282, DOI 10.1016/j.compeleceng.2017.07.026
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Wen WY, 2015, OPT COMMUN, V341, P131, DOI 10.1016/j.optcom.2014.12.026
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P584, DOI 10.1016/j.cnsns.2012.08.010
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
NR 31
TC 94
Z9 96
U1 12
U2 182
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12027
EP 12042
DI 10.1007/s11042-018-6739-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900042
DA 2024-07-18
ER

PT J
AU Wang, B
   Zhong, F
   Qin, XY
AF Wang, Bin
   Zhong, Fan
   Qin, Xueying
TI Robust edge-based 3D object tracking with direction-based pose
   validation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D tracking; Pose optimization; Distance field; Particle filter
ID REGISTRATION
AB In this paper we propose a robust edge-based approach for 3D textureless object tracking. We first introduce an edge-based pose estimation method, which minimizes the holistic distance between the projected object contour and the query image edges, without explicitly searching for 3D-2D correspondences. This method is accurate with a good initialization; however, it is sensitive to occlusion and fast motion, thus often gets lost in real environments. To improve robustness, we exploit consistency of edge direction for validating the correctness of the estimated 3D pose, and further incorporate the validation scheme for robust estimation, non-local searching and failure recovery. The robust estimation adopts point-wise validation to reduce the effect of outlier, resulting in a direction-based robust estimator. The non-local searching is based on particle filter, with the pose validation for a faithful weighting of particles, which is shown to be better than the distance-based weighting. The failure recovery is based on fast 2D detection, and estimates the recovered pose by searching for 3D-2D point correspondences, with the validation scheme to adaptively determine state transition. The effectiveness of our approach is demonstrated using comparative experiments on real image sequences with occlusions, large motions and background clutters.
C1 [Wang, Bin; Zhong, Fan] Shandong Univ, Sch Comp Sci & Technol, Qingdao, Shandong, Peoples R China.
   [Qin, Xueying] Shandong Univ, Sch Software, Jinan, Shandong, Peoples R China.
   [Wang, Bin; Qin, Xueying] Minist Educ China, Engn Res Ctr Digital Media Technol, Jinan, Shandong, Peoples R China.
C3 Shandong University; Shandong University
RP Zhong, F (corresponding author), Shandong Univ, Sch Comp Sci & Technol, Qingdao, Shandong, Peoples R China.
EM binwangsdu@gmail.com; zhongfan@sdu.edu.cn; qxy@sdu.edu.cn
RI Qin, Xueying/AAM-8775-2021
OI Qin, Xueying/0000-0003-0057-295X
FU National Key Research and Development Program of China [2016YFB1001501]
FX The authors gratefully acknowledge the anonymous reviewers for their
   comments to help us to improve our paper, and also thank for their
   enormous help in revising this paper. This work is supported by the
   National Key Research and Development Program of China (No.
   2016YFB1001501).
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Choi CH, 2012, IEEE INT C INT ROBOT, P3877, DOI 10.1109/IROS.2012.6386065
   Choi C, 2012, INT J ROBOT RES, V31, P498, DOI 10.1177/0278364912437213
   Comport AI, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P36, DOI 10.1109/ISMAR.2003.1240686
   Felzenszwalb P.F., 2004, Distance transforms of sampled functions
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hinterstoisser S, 2010, PROC CVPR IEEE, P2257, DOI 10.1109/CVPR.2010.5539908
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Imperoli M, 2015, LECT NOTES COMPUT SC, V9163, P316, DOI 10.1007/978-3-319-20904-3_29
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Klein Georg., 2006, BMVC, P1119
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Liu MY, 2010, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2010.5539837
   Lourakis Manolis, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P83, DOI 10.1007/978-3-642-39402-7_9
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marchand É, 2001, IMAGE VISION COMPUT, V19, P941, DOI 10.1016/S0262-8856(01)00054-3
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Park Y, 2008, INT SYM MIX AUGMENT, P117, DOI 10.1109/ISMAR.2008.4637336
   Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   SEO BK, 2014, TVCG, V20, P99, DOI DOI 10.1109/TVCG.2013.94
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Stennett C., 1990, P BMVC, P1
   Vacchetti L, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P48, DOI 10.1109/ISMAR.2004.24
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Wang B, 2017, CATAL TODAY, V285, P147, DOI 10.1016/j.cattod.2017.01.023
   Wang GF, 2015, VISUAL COMPUT, V31, P979, DOI 10.1007/s00371-015-1098-7
   Wuest H, 2005, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P62
   Youngmin Park, 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P121, DOI 10.1109/ISMAR.2011.6092377
NR 37
TC 17
Z9 20
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12307
EP 12331
DI 10.1007/s11042-018-6727-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900055
DA 2024-07-18
ER

PT J
AU Zhang, R
   Yin, D
   Ding, JW
   Luo, YH
   Liu, W
   Yuan, MY
   Zhu, CF
   Zhou, ZP
AF Zhang, Rui
   Yin, Dong
   Ding, Jinwen
   Luo, Yuhao
   Liu, Wei
   Yuan, Mingyue
   Zhu, Chengfeng
   Zhou, Zhipeng
TI A detection method for low-pixel ratio object
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Object detection; Road garbage detection
ID CONVOLUTIONAL NETWORKS; CLASSIFICATION; RECOGNITION; SCALE
AB Low-pixel object detection is a kind of difficult program. Existing object detection benchmarks and methods mainly focus on standard detection task. However, these way cannot get good performance on low-pixel ratio object detection, which has a few pixel in high resolution images. In order to solve it, we propose a new deep learning framework. This framework improves Faster R-CNN by combining multiple level feature map and optimizing anchor size for bounding box recognition. In order to validate our approach, we collect and annotate a dataset for road garbage detection, which contains 801 images and 966 bounding boxes. Experiments demonstrate that our framework outperforms other state-of-the-art detection methods. What's more, our method can apply on road garbage target.
C1 [Zhang, Rui; Yin, Dong; Ding, Jinwen; Luo, Yuhao; Yuan, Mingyue; Zhu, Chengfeng; Zhou, Zhipeng] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
   [Zhang, Rui; Yin, Dong; Luo, Yuhao; Yuan, Mingyue; Zhu, Chengfeng; Zhou, Zhipeng] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
   [Ding, Jinwen] USTC, Dept Mat Sci & Engn, Hefei 230026, Anhui, Peoples R China.
   [Liu, Wei] Anhui CAS Zhonghuan Def Equipment Technol Co LTD, Hefei 230001, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS
RP Yin, D (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.; Yin, D (corresponding author), Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
EM rzhang13@mail.ustc.edu.cn; yindong@ustc.edu.cn; jwding@ustc.edu.cn;
   lyhbo11@mail.ustc.edu.cn; weillau@163.com; moonuke@mail.ustc.edu.cn;
   zhuchf@mail.ustc.edu.cn; zzp1994@mail.ustc.edu.cn
RI Ding, Jinwen/F-8136-2010
OI Zhou, Zhipeng/0000-0002-1564-5800; liu, wei/0000-0001-7227-7154
FU National Natural Science Foundation of China (NSFC) [61671423, 61271403]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grant No. 61671423 and Grant No. 61271403.
CR [Anonymous], AM J PSYCHOANALYSIS
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gao Y, 2017, IEEE T IMAGE PROCESS, V26, P2545, DOI 10.1109/TIP.2017.2675341
   Gidaris S, 2016, PROC CVPR IEEE, P789, DOI 10.1109/CVPR.2016.92
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R., 2015, IEEE I CONF COMP VIS, DOI [DOI 10.1109/ICCV.2015.169, 10.1109/ICCV.2015.169]
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P1080, DOI 10.1109/ICCV.2015.129
   Guo Z, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P357, DOI 10.1145/2964284.2967242
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Li YS, 2018, PATTERN RECOGN, V77, P113, DOI 10.1016/j.patcog.2017.12.012
   Li YS, 2018, IEEE T GEOSCI REMOTE, V56, P950, DOI 10.1109/TGRS.2017.2756911
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Minaeian S, 2018, IEEE T INTELLIGENT T
   Najibi M, 2016, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2016.260
   Nguyen LD, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351550
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Tian T, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030904
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang F, 2017, AEROSP CONF PROC
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wang XH, 2018, NEUROCOMPUTING, V275, P438, DOI 10.1016/j.neucom.2017.08.063
   Xu D., 2015, arXiv preprint arXiv:1510.01553
   Yabuki N, 2018, LECT NOTES COMPUT SC, V10863, P3, DOI 10.1007/978-3-319-91635-4_1
   Yang Z, 2019, NEURAL COMPUT APPL, V31, P6469, DOI 10.1007/s00521-018-3468-3
   Zhu Y, 2015, PROC CVPR IEEE, P4703, DOI 10.1109/CVPR.2015.7299102
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 42
TC 5
Z9 5
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11655
EP 11674
DI 10.1007/s11042-018-6653-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900025
DA 2024-07-18
ER

PT J
AU Liu, XK
   Tian, H
   Huang, YF
   Lu, J
AF Liu, Xiaokang
   Tian, Hui
   Huang, Yongfeng
   Lu, Jing
TI A novel steganographic method for
   algebraic-code-excited-linear-prediction speech streams based on
   fractional pitch delay search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech steganography; Algebraic code-excited linear prediction; Pitch
   period prediction
ID VOICE
AB Although a large number of steganography algorithms based on algebraic-code-excited-linear-prediction have been proposed, their performance, such as embedding capacity, embedding transparency and capability for resisting detection, can be further enhanced. Therefore, we are motivated to present a new steganographic scheme based on pitch delay search, which can achieve better performance by embedding secret information into the fractional pitch delay parameters while keeping the integer pitch delay parameters unchanged. Specifically, we treat all fractional pitch delays as replaceable cover bits to achieve maximum embedding capacity. Further, the steganographic process is encrypted and guided by m sequences for flexibility and security. The proposed method is evaluated with a large number of adaptive multi-rate speech samples and compared with the existing works. Experimental results show that the proposed method can provide larger embedding capacity than the existing works while achieving excellent embedding transparency. Moreover, we evaluate the performance of the proposed method for resisting the state-of-the-art steganalysis methods. The experimental results demonstrate that the proposed method is highly secure, since the state-of-the-art steganalysis methods cannot detect it efficiently.
C1 [Liu, Xiaokang; Tian, Hui] Natl Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
   [Huang, Yongfeng] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Lu, Jing] Natl Huaqiao Univ, Dept Informat Syst & Management, Xiamen 361021, Peoples R China.
C3 Huaqiao University; Tsinghua University; Huaqiao University
RP Tian, H (corresponding author), Natl Huaqiao Univ, Coll Comp Sci & Technol, Xiamen 361021, Peoples R China.
EM htian@hqu.edu.cn
RI Tian, Hui/AAG-4048-2019
OI Huang, Yongfeng/0000-0003-3825-2230
FU National Natural Science Foundation of China [U1536115, U1405254];
   Natural Science Foundation of Fujian Province of China [2018J01093];
   Program for New Century Excellent Talents in Fujian Province University
   [MJK2016-23]; Program for Outstanding Youth Scientific and Technological
   Talents in Fujian Province University [MJK2015-54]; Promotion Program
   for Young and Middle-aged Teacher in Science & Technology Research of
   Huaqiao University [ZQN-PY115]; Program for Science & Technology
   Innovation Teams and Leading Talents of Huaqiao University [2014KJTD13];
   Opening Project of Shanghai Key Laboratory of Integrated Administration
   Technologies for Information Security [AGK201710]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant Nos. U1536115 and U1405254, Natural Science
   Foundation of Fujian Province of China under Grant No. 2018J01093,
   Program for New Century Excellent Talents in Fujian Province University
   under Grant No. MJK2016-23, Program for Outstanding Youth Scientific and
   Technological Talents in Fujian Province University under Grant No.
   MJK2015-54, Promotion Program for Young and Middle-aged Teacher in
   Science & Technology Research of Huaqiao University under Grant No.
   ZQN-PY115, Program for Science & Technology Innovation Teams and Leading
   Talents of Huaqiao University under Grant No.2014KJTD13, Opening Project
   of Shanghai Key Laboratory of Integrated Administration Technologies for
   Information Security under Grant No. AGK201710.
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2018, MAT SCI TECHNOL
   [Anonymous], 2009, 2009 INT C WIR COMM
   Aoki N., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P534, DOI 10.1109/IIHMSP.2010.136
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Chang PC, 2002, CONF REC ASILOMAR C, P1199
   Dittmann J, 2005, STEGANOGRAPHY STEGAN, P607
   Erchi Xu, 2011, Proceedings of the 2011 14th International Conference on Network-Based Information Systems (NBiS 2011), P612, DOI 10.1109/NBiS.2011.103
   Huang YF, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1512, DOI 10.1109/IIH-MSP.2008.174
   Huang YF, 2012, IEEE T INF FOREN SEC, V7, P1865, DOI 10.1109/TIFS.2012.2218599
   LIN C, 2006, MAN, V3, P2380, DOI DOI 10.1109/ICSMC.2006.385219
   Liu LH, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P406, DOI 10.1109/IIH-MSP.2008.297
   Liu P, 2017, MULTIMED TOOLS APPL, V76, P2837, DOI 10.1007/s11042-016-3257-x
   Miao R, 2011, P 46 IEEE INT C COMM, P1, DOI DOI 10.1109/ICC.2011.5962657
   Mrak M., 2008, ENCY MULTIMEDIA, P771
   Qin J, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND INTERNET COMPUTING (3PGCIC), P462, DOI 10.1109/3PGCIC.2015.65
   RAMACHANDRAN RP, 1989, IEEE T ACOUST SPEECH, V37, P467, DOI 10.1109/29.17527
   Ren YZ, 2018, MULTIMED TOOLS APPL, V77, P12095, DOI 10.1007/s11042-017-4860-1
   Ren YZ, 2017, IEEE T INF FOREN SEC, V12, P1345, DOI 10.1109/TIFS.2016.2636087
   Samphaiboon N, 2011, MULTIMED TOOLS APPL, V52, P569, DOI 10.1007/s11042-009-0432-3
   Su YM, 2006, 2006 IMACS: Multiconference on Computational Engineering in Systems Applications, Vols 1 and 2, P11
   Tian H, 2015, SIGNAL PROCESS, V117, P33, DOI 10.1016/j.sigpro.2015.05.001
   Tian H, 2014, MULTIMEDIA SYST, V20, P143, DOI 10.1007/s00530-013-0302-8
   Tian H, 2011, COMPUT COMMUN, V34, P2236, DOI 10.1016/j.comcom.2011.07.003
   Tian H, 2009, IEEE INT SYMP CIRC S, P2922, DOI 10.1109/ISCAS.2009.5118414
   Wang CY, 2007, IEEE INT SYM MULTIM, P255, DOI 10.1109/ISM.2007.33
   Wang FH, 2007, J NETW COMPUT APPL, V30, P4, DOI 10.1016/j.jnca.2005.08.002
   XIAO B, 2008, IEEE GLOB TEL C GLOB, P1, DOI DOI 10.1109/GLOCOM.2008.ECP.375
   Yan S, 2015, APPL RES COMPUT
   Yan SF, 2015, MULTIMED TOOLS APPL, V74, P11763, DOI 10.1007/s11042-014-2265-y
NR 31
TC 12
Z9 14
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8447
EP 8461
DI 10.1007/s11042-018-6867-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800031
DA 2024-07-18
ER

PT J
AU Rehman, AU
   Xiao, D
   Kulsoom, A
   Hashmi, MA
   Abbas, SA
AF Rehman, Aqeel Ur
   Xiao, Di
   Kulsoom, Ayesha
   Hashmi, Muntazim Abbas
   Abbas, Syed Ali
TI Block mode image encryption technique using two-fold operations based on
   chaos, MD5 and DNA rules
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block mode; Two-fold; Chaotic map; DNA; CBC encryption; Image encryption
ID SEQUENCE OPERATION; CRYPTANALYSIS; TRANSFORM
AB An innovative image encryption scheme named Two-Fold confusion operation is proposed in the block mode. A gray image is permuted using Logistic map and then Most and Least Significant parts of the image are separated known as MSB and LSB. These LSB and MSB parts are transformed into separate 1-Dimensional arrays and are divided into non-overlapped blocks of fixed size. These blocks are then encoded into DNA bases where each block of LSB and MSB gets a different DNA rule selected dynamically using Chen's hyper chaotic sequence. The innovation in this scheme is that each selective part of digital image is confused with different operations in DNA algebraic mode: Exclusive-OR for MSB blocks and addition operation for LSB blocks in the first phase. In 2nd phase of confusion, operations are exchanged for LSB and MSB. At last, confused LSB blocks are combined randomly with confused MSB blocks to form blocks of image pixels. These blocks of pixels are decoded back to digital domain by different DNA rules using chaotic pseudo-random numbers. The secret keys for chaotic maps are made dependent on MD5 digest of plain image to avoid launch of chose-plaintext attack. The simulation results show that NPCR score is >99.60%, UACI score>33.40% and Chi-square is <255, hence proposed system is highly robust against statistical and differential attacks.
C1 [Rehman, Aqeel Ur] COMSATS Univ Islamabad, Dept Comp Sci, Vehari, Pakistan.
   [Xiao, Di] Chongqing Univ, Coll Comp Sci, Chongqing, Peoples R China.
   [Kulsoom, Ayesha] Pakistan Inst Dev Econ, Islamabad, Pakistan.
   [Hashmi, Muntazim Abbas] KFUEIT, Dept Math, Rahim Yar Khan, Pakistan.
   [Abbas, Syed Ali] Univ Azad Jammu & Kashmir, Dept Comp Sci & IT, Muzaffarabad, Pakistan.
C3 COMSATS University Islamabad (CUI); Chongqing University; Pakistan
   Institute of Development Economics; University of Azad Jammu & Kashmir
RP Rehman, AU (corresponding author), COMSATS Univ Islamabad, Dept Comp Sci, Vehari, Pakistan.
EM rehmancqu@gmail.com
RI Rehman, Aqeel ur/R-4559-2018
OI Rehman, Aqeel ur/0000-0002-3083-6066
CR ADLEMAN LM, 1994, SCIENCE, V266, P1021, DOI 10.1126/science.7973651
   Akhavan A, 2017, OPT LASER TECHNOL, V95, P94, DOI 10.1016/j.optlastec.2017.04.022
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Bhatnagar G, 2013, INFORM SCIENCES, V223, P297, DOI 10.1016/j.ins.2012.09.053
   Bhatnagar G, 2012, IEEE T SYST MAN CY A, V42, P262, DOI 10.1109/TSMCA.2011.2147307
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Biham E., 1993, DIFFERENTIAL CRYPTAN, P487
   Blakely G. R., 1979, Computers & Mathematics with Applications, V5, P169, DOI 10.1016/0898-1221(79)90039-7
   Borujeni SE, 2013, TELECOMMUN SYST, V52, P525, DOI 10.1007/s11235-011-9458-8
   Chen TH, 2010, INFORM SCIENCES, V180, P1690, DOI 10.1016/j.ins.2009.12.021
   Cui GZ, 2008, 2008 THIRD INTERNATIONAL CONFERENCE ON BIO-INSPIRED COMPUTING: THEORIES AND APPLICATIONS, P37, DOI 10.1109/BICTA.2008.4656701
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khanzadi H, 2014, ARAB J SCI ENG, V39, P1039, DOI 10.1007/s13369-013-0713-z
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu YS, 2014, OPT LASER TECHNOL, V60, P111, DOI 10.1016/j.optlastec.2014.01.015
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Özkaynak F, 2013, SIG PROCESS COMMUN
   Ozturk I., 2004, INT J INF TECHNOL, V1, P108
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Wang XY, 2014, NONLINEAR DYNAM, V78, P2975, DOI 10.1007/s11071-014-1639-z
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Xu M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0126-y
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang YS, 2018, MULTIDIM SYST SIGN P, V29, P999, DOI 10.1007/s11045-017-0482-z
   Zhang YS, 2014, OPTIK, V125, P1562, DOI 10.1016/j.ijleo.2013.09.018
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
NR 42
TC 29
Z9 32
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9355
EP 9382
DI 10.1007/s11042-018-6516-1
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800077
DA 2024-07-18
ER

PT J
AU Tanwar, VK
   Buckchash, H
   Raman, B
   Bhargava, R
AF Tanwar, Vishesh Kumar
   Buckchash, Himanshu
   Raman, Balasubramanian
   Bhargava, Rama
TI Dense motion analysis of German finger spellings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Finger spelling recognition; Dense trajectories; Sign language
   recognition; Gaussian mixture model
ID SIGN-LANGUAGE RECOGNITION; SUPPORT VECTOR MACHINE; GESTURE RECOGNITION;
   TRAJECTORIES; EXTRACTION; TRACKING; ENTROPY; SYSTEM
AB Finger spellings is a frequent form of sign-language communication used by hearing-impaired people. It is a powerful media for visual communication. Capturing sign-language modalities are often challenging due to quick compact motion of fingers. Other approaches use costly sensors such as leap-motion or specially designed gloves or color segmentation. These are not speaker invariant, and are less speaker-friendly as they do not allow free expression of gesture. This work focuses on the progressive finger motion aspects of the speaker by analyzing the motion of gestures. Hand is segmented with Gaussian Mixture Model. It boosts the calculation of dense trajectories to trace hand movement. A Bag-of-Word (BoW) representation is employed to capture motion features. Experiments are conducted on German finger spelling dataset to evaluate the performance of the proposed technique. The observed performance of the technique indicates the effectiveness of motion as a substantial modality for finger spelling recognition.
C1 [Tanwar, Vishesh Kumar; Bhargava, Rama] Indian Inst Technol Roorkee, Dept Math, Roorkee, Uttarakhand, India.
   [Buckchash, Himanshu; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttarakhand, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Roorkee
RP Tanwar, VK (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee, Uttarakhand, India.
EM vishu.dma2015@iitr.ac.in
RI Buckchash, Himanshu/ABF-8409-2021; Tanwar, Dr. Vishesh
   Kumar/AGI-9932-2022; Tanwar, Dr. Vishesh Kumar/AFJ-6309-2022
OI Buckchash, Himanshu/0000-0003-3679-3498; Tanwar, Dr. Vishesh
   Kumar/0000-0002-4802-7582
CR Abhishek KS, 2016, IEEE C ELEC DEVICES, P334, DOI 10.1109/EDSSC.2016.7785276
   Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Ali S, 2006, APPL SOFT COMPUT, V6, P119, DOI 10.1016/j.asoc.2004.12.002
   Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   [Anonymous], 2013, NATURE STAT LEARNING
   [Anonymous], 2016, PROC IEEE COMPUT VIS
   [Anonymous], KINECT GESTURE RECOG
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, Computer Vision and Pattern Recognition Workshops (CVPRW), 2015 IEEE Conference on
   Aran O, 2009, IEEE MULTIMEDIA, V16, P81, DOI 10.1109/MMUL.2009.17
   Aran O, 2009, PATTERN RECOGN, V42, P812, DOI 10.1016/j.patcog.2008.09.010
   Bauer B, 2002, INT C PATT RECOG, P434, DOI 10.1109/ICPR.2002.1048332
   Bauer B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P440, DOI 10.1109/AFGR.2000.840672
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Corradini A, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P82, DOI 10.1109/RATFG.2001.938914
   Dreuw P., 2006, ECCV WORKSHOP STAT M, P7
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Imran J, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P144, DOI 10.1109/ICACCI.2016.7732038
   Joachims T., 1998, Machine Learning: ECML-98. 10th European Conference on Machine Learning. Proceedings, P137, DOI 10.1007/BFb0026683
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kelly D, 2011, IEEE T SYST MAN CY B, V41, P526, DOI 10.1109/TSMCB.2010.2065802
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Maji S., 2008, IEEE C COMPUTER VISI, P1
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Mehdi SA, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P2204
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Raczko E, 2017, EUR J REMOTE SENS, V50, P144, DOI 10.1080/22797254.2017.1299557
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ronchetti Franco, 2016, 20 2 C ARG CIENC COM
   Shanableh T, 2007, IEEE T SYST MAN CY B, V37, P641, DOI 10.1109/TSMCB.2006.889630
   Shimada M, 2003, SICE 2003 ANNUAL CONFERENCE, VOLS 1-3, P2458
   Starner T., 1997, Motion-Based Recognit, P227
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Wang H, 2016, INT J COMPUT VISION, V119, P219, DOI 10.1007/s11263-015-0846-5
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang SH, 2017, CNS NEUROL DISORD-DR, V16, P116, DOI 10.2174/1871527315666161111123638
   Yang KJ, 2017, IEEE ACCESS, V5, P22504, DOI 10.1109/ACCESS.2017.2760251
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Yang Quan, 2010, 2010 5th IEEE Conference on Industrial Electronics and Applications (ICIEA 2010), P1537, DOI 10.1109/ICIEA.2010.5514688
   Yu D., 2016, AUTOMATIC SPEECH REC, VVolume 1
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 48
TC 1
Z9 1
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9511
EP 9536
DI 10.1007/s11042-018-6533-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400001
DA 2024-07-18
ER

PT J
AU Wahed, MA
   Nyeem, H
AF Wahed, Md Abdul
   Nyeem, Hussain
TI Reversible data hiding with interpolation and adaptive embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive embedding; Interpolation; Reversible embedding; Data hiding;
   Digital watermarking
ID IMAGE WATERMARKING; BINARY IMAGE; AUTHENTICATION; EXPANSION; SCHEME
AB Interpolation based reversible data hiding (IRDH) schemes have recently been studied for better rate-distortion performance. However, most of them do not have any consideration of an effective' capacity management for increasing size of payload. In this paper, we develop and present an IRDH scheme with adaptive embedding, which determines how many bits of an interpolated pixel can be used for the best possible embedded image quality by using a parameter to control the embedding rate. While compared with the prominent IRDH schemes, our scheme demonstrated its efficiency for better embedding rate distortion performance. Being up-sampled, the embedded image would have higher spatial resolution. It also does not require any location map, and thus the total capacity can be effectively used for data embedding. Moreover, it keeps the original pixels untouched and thus, would be useful in military and medical image applications that restrict minimum possible changes in the cover images.
C1 [Wahed, Md Abdul; Nyeem, Hussain] MIST, Dept Elect Elect & Commun Engn, Dhaka 1216, Bangladesh.
RP Wahed, MA (corresponding author), MIST, Dept Elect Elect & Commun Engn, Dhaka 1216, Bangladesh.
EM wahedruet@gmail.com; h.nyeem@eece.mist.ac.bd
RI Wahed, Abdul/AAN-4561-2021; Nyeem, Hussain/G-7075-2014
OI Nyeem, Hussain/0000-0003-4839-5059; Wahed, Md Abdul/0000-0003-4703-0373
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], 2003, Techniques and Applications of Digital Watermarking and Content Protection
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Bender W, 2000, IBM SYST J, V39, P547, DOI 10.1147/sj.393.0547
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chang YT, 2013, J SUPERCOMPUT, V66, P1093, DOI 10.1007/s11227-013-1016-6
   Chen XY, 2015, MULTIMED TOOLS APPL, V74, P5747, DOI 10.1007/s11042-014-1881-x
   Chen XD, 2010, INT CONF ACOUST SPEE, P2382, DOI 10.1109/ICASSP.2010.5496175
   Coatrieux G, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P4691
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Cox IJ, 2008, MKS MULTIMED INFORM, P61, DOI 10.1016/B978-012372585-1.50006-1
   [DWA Digital watermarking alliance (DWA)], 2006, DIG WAT ALL
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P513, DOI 10.1007/s11042-010-0486-2
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kundur D, 1999, P IEEE, V87, P1167, DOI 10.1109/5.771070
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lee Y, 2009, INFORM SCIENCES, V179, P3866, DOI 10.1016/j.ins.2009.07.014
   Liu YC, 2011, MULTIMED TOOLS APPL, V52, P263, DOI 10.1007/s11042-010-0496-0
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Malik A, 2016, MULTIMED TOOLS APPL, V76, P1
   Malik A., 2017, MULTIMEDIA TOOTS APP, V76, P1
   Nyeem H, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-135
   Nyeem H, 2013, J DIGIT IMAGING, V26, P326, DOI 10.1007/s10278-012-9527-x
   Ou B, 2016, J VIS COMMUN IMAGE R, V39, P12, DOI 10.1016/j.jvcir.2016.05.005
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   REY C, 1965, EURASIP J APPL SIG P, V2002, P613
   Rhoads GB, 2000, US Patent, Patent No. [6,122,392, 6122392]
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Tewfik AH, 1997, IEEE SIGNAL PROC MAG, V14, P41, DOI 10.1109/79.598593
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Voyatzis G, 1999, P IEEE, V87, P1197, DOI 10.1109/5.771072
   Wahed M. A., 2016, P ICEEICT 2016, P1
   Wang CT, 2012, MULTIMED TOOLS APPL, V61, P299, DOI 10.1007/s11042-011-0838-6
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Yu HH, 2002, US Patent, Patent No. [6,456,726, 6456726]
   Zhang X, 2017, MULTIMED TOOLS APPL, P1
NR 44
TC 8
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10795
EP 10819
DI 10.1007/s11042-018-6616-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400057
DA 2024-07-18
ER

PT J
AU Yu, J
   Song, W
   Zhou, GZ
   Hou, JJ
AF Yu, Jing
   Song, Wei
   Zhou, Guozhu
   Hou, Jian-jun
TI Violent scene detection algorithm based on kernel extreme learning
   machine and three-dimensional histograms of gradient orientation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Violent scene detection; HOG3D; Bag of visual words; Feature pooling;
   Kernel extreme learning machine
AB Most existing feature descriptors for video have limited representation ability. In order to improve the recognition accuracy of method for detecting the videos that include violent scenes and take advantage of the logical structure of video sequences, a novel feature constructing approach based on three dimensional histograms of gradient orientation (HOG3D), the Bag of Visual Words (BoVW) model, and feature pooling technology is proposed. This approach, combined with kernel extreme learning machine (KELM), can be used to detect violent scene. First, the HOG3D feature is extracted on the block level for video, and then the K-Means clustering algorithm is implemented to generate visual words. Then, the bag of visual words framework is used for the quantization of feature. And the feature pooling technology is operated to generate a feature vector for an entire video segment, and feature vectors of training data and testing data were used separately to train the model and evaluate the performance of the proposed approach. The experimental results showed that the proposed feature descriptor had good representation and generalization abilities. The proposed approach is efficient for violent scene detection, and the accuracy matches the best result on Hockey dataset, and it outperforms state-of-the-art on Movies.
C1 [Yu, Jing; Hou, Jian-jun] Beijing Jiaotong Univ, Sch Elect Informat & Engn, Beijing 100044, Peoples R China.
   [Song, Wei] Minzu Univ China, Sch Informat & Engn, Beijing 100081, Peoples R China.
   [Zhou, Guozhu] Beijing Polytech, Beijing 100176, Peoples R China.
C3 Beijing Jiaotong University; Minzu University of China; Beijing
   Polytechnic
RP Yu, J (corresponding author), Beijing Jiaotong Univ, Sch Elect Informat & Engn, Beijing 100044, Peoples R China.
EM ssoohay@139.com
FU National Natural Science Foundation of China [615034244, 61331013];
   Promotion plan for young teachers' scientific research ability of Minzu
   University of China Project; Promotion Project for teachers' scientific
   research ability of the Beijing Polytechnic Project [YZK2015013
   CJGX2016-SZ-05/008 CJGX2016[18]-SZJC-05/008 02362050301]
FX This work was supported in part by the National Natural Science
   Foundation of China project (615034244,61331013); Promotion plan for
   young teachers' scientific research ability of Minzu University of China
   Project; Promotion Project for teachers' scientific research ability of
   the Beijing Polytechnic Project (YZK2015013 CJGX2016-SZ-05/008
   CJGX2016[18]-SZJC-05/008 02362050301).
CR [Anonymous], 2008, PROC BRIT MACH VIS C
   [Anonymous], 2007, MIR
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bilinski P, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P30, DOI 10.1109/AVSS.2016.7738019
   CHEN MY, 2009, CMU CS 09 161, V161, P1
   Chen XW, 2014, IEEE ACCESS, V2, P514, DOI 10.1109/ACCESS.2014.2325029
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Deniz O, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P478
   Ding CH, 2014, LECT NOTES COMPUT SC, V8888, P551, DOI 10.1007/978-3-319-14364-4_53
   Giannakopoulos T, 2010, LECT NOTES ARTIF INT, V6040, P91, DOI 10.1007/978-3-642-12842-4_13
   Gong Y, 2008, LECT NOTES COMPUT SC, V5353, P317, DOI 10.1007/978-3-540-89796-5_33
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   LAM V, 2017, TOOLS, V76, P7041, DOI DOI 10.1007/s11042-016-3331-4
   Luo MX, 2014, ENG APPL ARTIF INTEL, V27, P228, DOI 10.1016/j.engappai.2013.05.012
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   MOHAMMADI S, 2015, 2015 12TH IEEE INT C, V12, P1
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Shim HM, 2015, J CENT SOUTH UNIV, V22, P1801, DOI 10.1007/s11771-015-2698-0
   Xia LM, 2013, J CENT SOUTH UNIV, V20, P3171, DOI 10.1007/s11771-013-1841-z
   Xu L, 2014, INT CONF ACOUST SPEE
   Zhang T, 2017, MULTIMED TOOLS APPL, V76, P1419, DOI 10.1007/s11042-015-3133-0
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhou PP, 2017, J PHYS CONF SER, V844, DOI 10.1088/1742-6596/844/1/012044
NR 25
TC 17
Z9 18
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8497
EP 8512
DI 10.1007/s11042-018-6923-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800034
OA hybrid
DA 2024-07-18
ER

PT J
AU Al-nasrawi, M
   Deng, G
   Waheed, W
AF Al-nasrawi, Mukhalad
   Deng, Guang
   Waheed, Waseem
TI Structure extraction of images using anisotropic diffusion with
   directional second neighbour derivative operator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structure extraction filter; Second neighbour derivative; Superpixel
   segmentation; Contrast enhancement; Texture transfer
ID TEXTURE DECOMPOSITION
AB The aim of structure extraction is to decompose an image into prominent structures and textures. In this paper, we present a new structure extraction method which has two main steps. First, high-frequency components due to the texture information in the original image are alleviated by a pre-smoothing filter. The result is then processed by a new anisotropic diffusion algorithm which uses a second neighbour derivative (SND) operator instead of the first neighbour derivative operator. We have demonstrated that the SND operator is better suited for applications such as texture smoothing. We have also presented a detailed study of the proposed method including the selection of the pre-smoothing filter, the number of iterations, and the scale parameter in the anisotropic diffusion algorithm. We have conducted experiments to compare the performance of the proposed method with those state-of-the-art structure extraction algorithms in a wide range of image editing applications such as: superpixel segmentation, texture transfer, contrast enhancement, and pencil drawing. We show that while the running speed of the proposed method is the fastest, its performance is competitive to other methods.
C1 [Al-nasrawi, Mukhalad; Deng, Guang; Waheed, Waseem] La Trobe Univ, Dept Engn, Bundoora, Vic 3086, Australia.
   [Al-nasrawi, Mukhalad] Al Furat Al Awsat Tech Univ, Al Musaib Tech Coll, Babylon 51009, Iraq.
C3 La Trobe University; Al-Furat Al-Awsat Technical University
RP Al-nasrawi, M (corresponding author), La Trobe Univ, Dept Engn, Bundoora, Vic 3086, Australia.; Al-nasrawi, M (corresponding author), Al Furat Al Awsat Tech Univ, Al Musaib Tech Coll, Babylon 51009, Iraq.
EM m.al-nasrawi@latrobe.edu.au; d.deng@latrobe.edu.au;
   w.waheed@latrobe.edu.au
RI Waheed, Waseem/L-4026-2019; Al-nasrawi, Mukhalad/AAG-5347-2019
OI Waheed, Waseem/0000-0002-5858-5836; Al-nasrawi,
   Mukhalad/0000-0003-1833-3519
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Al-nasrawi M, 2018, SIGNAL IMAGE VIDEO P, V12, P347, DOI 10.1007/s11760-017-1164-x
   [Anonymous], 2016, P 25 INT JOINT C ART
   Arnheim R., 1956, ART VISUAL PERCEPTIO
   Aujol JF, 2006, INT J COMPUT VISION, V67, P111, DOI 10.1007/s11263-006-4331-z
   Bao LC, 2014, IEEE T IMAGE PROCESS, V23, P555, DOI 10.1109/TIP.2013.2291328
   Buades A, 2010, IEEE T IMAGE PROCESS, V19, P1978, DOI 10.1109/TIP.2010.2046605
   Cho H, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601188
   Deng G, 2016, IEEE T IMAGE PROCESS, V25, P439, DOI 10.1109/TIP.2015.2503699
   Du H, 2016, VISUAL COMPUT, V32, P1537, DOI 10.1007/s00371-015-1138-3
   Farbman Z, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360666
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Ham B, 2015, PROC CVPR IEEE, P4823, DOI 10.1109/CVPR.2015.7299115
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jeon J, 2016, COMPUT GRAPH FORUM, V35, P77, DOI 10.1111/cgf.13005
   Jiang XL, 2017, COMPUT GRAPH-UK, V68, P129, DOI 10.1016/j.cag.2017.07.034
   Karacan L, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508403
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   LAN X, 1937, TIP, V27, P2022, DOI DOI 10.1109/TIP.2017.2777183
   LAN X, 2015, TIP, V24, P5826, DOI DOI 10.1109/TIP.2015.2481325
   Lan XY, 2017, AAAI CONF ARTIF INTE, P4118
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lee H, 2017, COMPUT GRAPH FORUM, V36, P262, DOI 10.1111/cgf.12875
   Li Y, 2014, LECT NOTES COMPUT SC, V8690, P174, DOI 10.1007/978-3-319-10605-2_12
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Lu Cewu., 2012, Proc. NPAR, P65
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Su Z, 2018, J COMPUT APPL MATH, V329, P244, DOI 10.1016/j.cam.2017.05.047
   Su Z, 2013, IEEE T MULTIMEDIA, V15, P535, DOI 10.1109/TMM.2012.2237025
   Subr K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618493
   Thai B, 2017, IET IMAGE PROCESS, V11, P512, DOI 10.1049/iet-ipr.2016.0418
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu H, 2017, MULTIMEDIA TOOLS APP
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yin WT, 2005, LECT NOTES COMPUT SC, V3752, P73
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhou ZQ, 2018, IEEE T MULTIMEDIA, V20, P1392, DOI 10.1109/TMM.2017.2772438
   Zhu LF, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366146
NR 41
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 6385
EP 6407
DI 10.1007/s11042-018-6377-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100064
DA 2024-07-18
ER

PT J
AU Dalal, M
   Juneja, M
AF Dalal, Mukesh
   Juneja, Mamta
TI A robust and imperceptible steganography technique for SD and HD videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; DWT; High definition; Standard definition;
   Imperceptibility; Robustness
ID IMAGE STEGANOGRAPHY; ALGORITHM
AB In this era of internet transfer of information is in digital form using multimedia files such as image, video, audio, etc. which relies on secure communication techniques to convey information safely. Due to the frequent transfer of videos over the internet nowadays they have become a good cover media for secure and covert communication in the form of video steganography. For efficient video steganography, it must fulfill its basic requirements such as capacity, imperceptibility, and robustness. In order to make a balance between imperceptibility and robustness, an efficient video steganography scheme is proposed for Standard Definition (SD) and High Definition (HD) videos. This scheme employs DWT (discrete wavelet transforms) for embedding the secret message inside the video frames utilizing only luminance (Y) component, and the security of the proposed scheme is strengthen by pre-processing the secret message with encryption before embedding. The embedding process is done by utilizing the middle-frequency sub-bands after applying second level 2-D DWT to the video frames to decompose it into 16 sub-bands. The performance of the proposed scheme is tested on different videos with quality metrics including peak signal to noise ratio (PSNR), structural similarity (SSIM) index, bit error rate (BER) and also by applying Gaussian and salt & pepper noise attacks. Moreover, the scheme is tested for the different level of compression on stego-video and also compared with U and V components used while embedding. Experimental results show that for both types of videos (HD and SD) the proposed scheme is able to achieve high imperceptibility. Further, it also provides robustness against different types of noise attacks and different compression levels which makes the proposed scheme evident for secure data transmission.
C1 [Dalal, Mukesh; Juneja, Mamta] Panjab Univ, UIET, Chandigarh, India.
C3 Panjab University
RP Dalal, M (corresponding author), Panjab Univ, UIET, Chandigarh, India.
EM mukeshdalal05@gmail.com; mamtajuneja@pu.ac.in
OI Juneja, Mamta/0000-0002-2611-9005
CR [Anonymous], 2013, RES J INFORM TECHNOL
   [Anonymous], 2003, P ACM C COMP COMM SE, DOI [DOI 10.1145/948109.948120, 10.1145/948109.948120]
   [Anonymous], 2015, 2015 INT C INN INF E, DOI DOI 10.1109/ICIIECS.2015.7192885
   [Anonymous], 2001, INFORM HIDING STEGAN
   [Anonymous], 2014, 1 INT C PHOT VLSI SI
   [Anonymous], INT J INNOVATIVE TEC
   Chantrapornchai C, 2014, INT J MULTIMEDIA UBI, V9, P385
   Dalal Mukesh, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P705, DOI 10.1007/978-981-10-6890-4_67
   Das S, 2018, ADV INTELL SYST, V563, P3, DOI 10.1007/978-981-10-6872-0_1
   Dasgupta K, 2013, PROC TECH, V10, P131, DOI 10.1016/j.protcy.2013.12.345
   Di Laura C, 2016, INT J DIGIT MULTIMED, V2016, DOI 10.1155/2016/6950592
   Ebrahim M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P557, DOI 10.1109/ICCSCE.2013.6720027
   He YL, 2012, AEU-INT J ELECTRON C, V66, P305, DOI 10.1016/j.aeue.2011.08.007
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Idbeaa T, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150732
   Khan Shujaat, 2015, International Journal of Computer Network and Information Security, V7, P60, DOI 10.5815/ijcnis.2015.12.07
   Li G, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/293031
   Mstafa R.J., 2017, IEEE Long Island Systems, Applications and Technology Conference (LISAT), P1, DOI DOI 10.1109/ACCESS.2017.2691581
   Mstafa RJ, 2015, WIREL TELECOMM SYMP
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Patel K, 2013, INT CONF COMM SYST, P497, DOI 10.1109/CSNT.2013.109
   Rabie T, 2018, MULTIMED TOOLS APPL, V77, P23673, DOI 10.1007/s11042-018-5713-2
   RAMALINGAM M, 2014, INDIAN J SCI TECHNOL, V7, P897
   Ramalingam M., 2011, Int J Informat Commun Eng, V5, P170, DOI [10.5281/zenodo.1070343, DOI 10.5281/ZENODO.1070343]
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sharma VK, 2018, IET IMAGE PROCESS, V12, P1065, DOI 10.1049/iet-ipr.2017.0965
   Sikora T, 1997, IEEE SIGNAL PROC MAG, V14, P82, DOI 10.1109/79.618010
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei D, 2002, J COMPUT SCI TECH-CH, V17, P129, DOI 10.1007/BF02962205
NR 34
TC 16
Z9 16
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5769
EP 5789
DI 10.1007/s11042-018-6093-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100038
DA 2024-07-18
ER

PT J
AU Kumar, SH
   Ramakrishnan, KR
AF Kumar, S. Hemanth
   Ramakrishnan, K. R.
TI Depth compression via planar segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth map video; Segmentation; Graph cuts; Data compression; Noisy depth
   sensors; RANSAC
ID PARALLEL FRAMEWORK; 3D; EXTENSIONS; MOTION; VIEW
AB Augmented Reality applications are set to revolutionize the smartphone industry due to the integration of RGB-D sensors into mobile devices. Given the large number of smartphone users, efficient storage and transmission of RGB-D data is of paramount interest to the research community. While there exist Video Coding Standards such as HEVC and H.264/AVC for compression of RGB/texture component, the coding of depth data is still an area of active research. This paper presents a method for coding depth videos, captured from mobile RGB-D sensors, by planar segmentation. The segmentation algorithm is based on Markov Random Field assumptions on depth data and solved using Graph Cuts. While all prior works based on this approach remain restricted to images only and under noise-free conditions, this paper presents an efficient solution to planar segmentation in noisy depth videos. Also presented is a unique method to encode depth based on its segmented planar representation. Experiments on depth captured from a noisy sensor (Microsoft Kinect) shows superior Rate-Distortion performance over the 3D extension of HEVC codec.
C1 [Kumar, S. Hemanth; Ramakrishnan, K. R.] Indian Inst Sci, Dept Elect Engn, Bangalore, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Kumar, SH (corresponding author), Indian Inst Sci, Dept Elect Engn, Bangalore, Karnataka, India.
EM hemanths@iisc.ac.in; krr2504@gmail.com
CR [Anonymous], 2012, P INT C INT ROB SYST
   [Anonymous], LOSSLESS PHOTO COMPR
   [Anonymous], IEEE T CIRCUITS SYST
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, IEEE T CIRCUITS SYST
   [Anonymous], 2005, ADAPTIVE WEIGHING CO
   [Anonymous], THESIS CANKAYA ANKAR
   [Anonymous], 2015, THESIS
   [Anonymous], LOSSLESS IMAGE COMPR
   [Anonymous], RANDOM FIELDS VISION
   [Anonymous], 2014 INT C 3D IM IC3
   [Anonymous], J ELECT IMAGING
   [Anonymous], 2001, VCEGM33 ITU T
   [Anonymous], 1449610 ITUT ISO IEC
   [Anonymous], PAQ DATA COMPRESSION
   [Anonymous], 2011, VISUAL COMMUN-US, DOI DOI 10.1109/VCIP.2011.6115989
   [Anonymous], TIP
   [Anonymous], 2001, IEEE T PATTERN ANAL
   [Anonymous], P 2011 IEEE 13 INT W, DOI DOI 10.1109/MMSP.2011.6093810
   [Anonymous], JTC1SC29WG11 ISOIEC
   [Anonymous], 3DTV C TRUE VIS CAPT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhattacharya U, 2017, INT CONF 3D VISION, P548, DOI 10.1109/3DV.2017.00068
   Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z
   Farid MS, 2015, IEEE T IMAGE PROCESS, V24, P205, DOI 10.1109/TIP.2014.2374533
   Feng C, 2014, IEEE INT CONF ROBOT, P6218, DOI 10.1109/ICRA.2014.6907776
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gallup David, 2008, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2008.4587671
   Hemanth KS, 2014, IEEE DATA COMPR CONF, P424, DOI 10.1109/DCC.2014.34
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7
   Jäger F, 2012, INT CONF 3D IMAG
   Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382
   Lei JJ, 2015, IEEE T CIRC SYST VID, V25, P275, DOI 10.1109/TCSVT.2014.2335471
   Duch MM, 2017, MULTIMED TOOLS APPL, V76, P13761, DOI 10.1007/s11042-016-3727-1
   Milani S, 2011, IEEE INT CON MULTI
   Ozaktas H.M., 2008, Three-Dimensional Television: Capture, Transmission, Display
   Özkalayci BO, 2014, IEEE T IMAGE PROCESS, V23, P5222, DOI 10.1109/TIP.2014.2360452
   Shah S. K., 2014, INT C DIG IM COMP TE, P1, DOI DOI 10.1109/DICTA.2014.7008105
   Shen G., 2010, 2010 28th Picture Coding Symposium (PCS 2010), P566, DOI 10.1109/PCS.2010.5702565
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Tech G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P25, DOI 10.1109/PCS.2012.6213277
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Zou F, 2014, IEEE T CIRC SYST VID, V24, P1696, DOI 10.1109/TCSVT.2014.2313891
NR 47
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6529
EP 6558
DI 10.1007/s11042-018-6327-4
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700006
DA 2024-07-18
ER

PT J
AU Li, DJ
   Chen, CJ
AF Li, Dongnian
   Chen, Chengjun
TI Tracking a hand in interaction with an object based on single depth
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand tracking; Object tracking; Depth image; Particle filtering;
   Gaussian PSO; OSG
ID BODY MOTION
AB Tracking a hand in interaction with an object based on vision is a challenging research topic. The occlusions that occur during the hand-object interaction make it difficult to develop an effective tracking system. To overcome the impacts of occlusions, we build 3D models for both the hand and the manipulated object and propose a model-based tracking method to track the hand and the object simultaneously from single depth images during the hand-object interaction. The most likely hand-object state is searched by an improved particle filtering (PF) tracking algorithm in the high-dimensional hand-object space, which uses Gaussian particle swarm optimization (Gaussian PSO) algorithm to improve the process of particle sampling, moving the particles to the regions with higher likelihood. According to the proposed tracking algorithm, two kinds of hand-object tracking prototype systems are developed by using the graphics rendering engine OSG and off-screen rendering techniques. Experimental results demonstrate that the proposed method can track hand-object motion robustly with few particles.
C1 [Li, Dongnian; Chen, Chengjun] Qingdao Univ Technol, Sch Mech & Automot Engn, Qingdao 266520, Shandong, Peoples R China.
C3 Qingdao University of Technology
RP Chen, CJ (corresponding author), Qingdao Univ Technol, Sch Mech & Automot Engn, Qingdao 266520, Shandong, Peoples R China.
EM chenchengjun79@163.com
FU National Natural Science Foundation of China [51475251, 51705273]
FX This work was funded by the National Natural Science Foundation of China
   (NO. 51475251 and 51705273).
CR [Anonymous], 2013, Consumer Depth Cameras for Computer Vision
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   Bray M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P675, DOI 10.1109/AFGR.2004.1301612
   Cui JS, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P729
   Doliotis P, 2012, LECT NOTES COMPUT SC, V7431, P148, DOI 10.1007/978-3-642-33179-4_15
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Erol A., 2005, P IEEE WORKSH VIS HU, P75, DOI [DOI 10.1109/CVPR.2005.395, 10.1109/CVPR.2005.395]
   Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282
   Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61
   Kjellström H, 2008, LECT NOTES COMPUT SC, V5303, P336, DOI 10.1007/978-3-540-88688-4_25
   Krohling RA, 2004, CONF CYBERN INTELL S, P372
   Kyriazis N, 2013, PROC CVPR IEEE, P9, DOI 10.1109/CVPR.2013.9
   Li Dongnian., 2015, Int J Signal Process Image Process Pattern Recognit, V8, P237
   Liang H, 2013, VISUAL COMPUT, V29, P837, DOI 10.1007/s00371-013-0822-4
   LU G, 2017, TMM, V19, P2117, DOI DOI 10.1109/TMM.2017.2731044
   Do MQ, 2017, MULTIMED TOOLS APPL, V76, P24569, DOI 10.1007/s11042-016-4217-1
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483
   Prisacariu VA, 2012, IMAGE VISION COMPUT, V30, P236, DOI 10.1016/j.imavis.2012.01.003
   Romero Javier, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P87, DOI 10.1109/ICHR.2009.5379596
   Romero J, 2010, IEEE INT CONF ROBOT, P458, DOI 10.1109/ROBOT.2010.5509753
   Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965
   Wang YG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462000
   Zhang Z, 2013, IEEE T MULTIMEDIA, V15, P106, DOI 10.1109/TMM.2012.2225040
NR 25
TC 1
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6745
EP 6762
DI 10.1007/s11042-018-6452-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700015
DA 2024-07-18
ER

PT J
AU Mseddi, WS
   Jmal, M
   Attia, R
AF Mseddi, Wided Souidene
   Jmal, Marwa
   Attia, Rabah
TI Real-time scene background initialization based on spatio-temporal
   neighborhood exploration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background initialization; Online clustering; Spatial exploration; Edge
   matching
AB In this paper, we address the problem of scene background initialization to define a background model free from foreground objects. The complexity of this task resides in the continuous clutter of the scene by moving and stationary objects. To face this challenge, we propose a robust real-time iterative model completion method based on online block-level processing to initialize the background with low computational cost. First, temporal data analysis is conducted to cluster similar blocks. Meanwhile, a two-folded inter-block spatial neighborhood exploration is performed. It aims to capture relationships among neighboring clusters and reduce the number of candidate clusters employed in the next phase. Then, a smoothness analysis between neighboring locations is performed to iteratively reconstruct the background based on a newly proposed edge matching metric and an inter-block color discontinuity. Extensive evaluations of the proposed approach on the public Scene Background Initialization 2015 dataset and on the Scene Background Modeling Contest 2016 dataset revealed a performance superior or comparable to state-of-the-art methods.
C1 [Mseddi, Wided Souidene; Jmal, Marwa; Attia, Rabah] Univ Carthage, Ecole Polytech Tunisie, SERCOM, BP 743, La Marsa 2078, Tunisia.
   [Mseddi, Wided Souidene] Univ Paris 13, Inst Galilee, L2TI, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
   [Jmal, Marwa] Telnet Innovat Labs, Telnet Holding, Ariana, Tunisia.
C3 Universite de Carthage; Universite Paris 13
RP Mseddi, WS (corresponding author), Univ Carthage, Ecole Polytech Tunisie, SERCOM, BP 743, La Marsa 2078, Tunisia.; Mseddi, WS (corresponding author), Univ Paris 13, Inst Galilee, L2TI, 99 Ave Jean Baptiste Clement, F-93430 Villetaneuse, France.
EM wided.mseddi@univ-paris13.fr; marwa.jmal@sercom-lab.com;
   rabah.attia@enit.rnu.tn
RI Mseddi, Wided/AAD-7732-2021
OI Mseddi, Wided/0000-0002-3002-4033
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2016, SMBC2016 ICPR
   [Anonymous], 2015, SMBI2015 ICIAP
   [Anonymous], 2008, COMP VIS PATT REC 20
   [Anonymous], PATTERN RECOGNITION
   Baltieri Davide, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P165, DOI 10.1109/AVSS.2010.43
   Bloisi DD, 2015, LECT NOTES COMPUT SC, V9281, P485, DOI 10.1007/978-3-319-23222-5_59
   Bouwmans T, 2014, COMPUT SCI REV, V11-12, P31, DOI 10.1016/j.cosrev.2014.04.001
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Colombari A, 2010, IEEE T IMAGE PROCESS, V19, P926, DOI 10.1109/TIP.2009.2038652
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Gregorio MD, 2017, PATTERN RECOGNITION
   Halkidi M, 2001, J INTELL INF SYST, V17, P107, DOI 10.1023/A:1012801612483
   Laugraud B, 2016, PATTERN RECOGNITION
   Laugraud B, 2016, INT C PATT RECOG, P107, DOI 10.1109/ICPR.2016.7899617
   Maddalena L., 2012, 2012 IEEE COMP SOC C, P21, DOI [10.1109/CVPRW.2012.6238922, DOI 10.1109/CVPRW.2012.6238922]
   Maddalena L., 2014, BACKGROUND MODELING, P3
   Maddalena L, 2015, LECT NOTES COMPUT SC, V9281, P469, DOI 10.1007/978-3-319-23222-5_57
   Maddalena L, 2014, COMPUT VIS IMAGE UND, V122, P65, DOI 10.1016/j.cviu.2013.11.006
   Ortego D, 2016, COMPUT VIS IMAGE UND, V147, P23, DOI 10.1016/j.cviu.2016.03.012
   Park D, 2013, PATTERN RECOGN, V46, P1985, DOI 10.1016/j.patcog.2012.12.013
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Reddy V, 2011, EURASIP J IMAGE VIDE, DOI 10.1155/2011/164956
   Reddy V, 2009, IEEE IMAGE PROC, P1109, DOI 10.1109/ICIP.2009.5413450
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Wang HZ, 2006, LECT NOTES COMPUT SC, V3851, P328
NR 29
TC 5
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7289
EP 7319
DI 10.1007/s11042-018-6399-1
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700040
DA 2024-07-18
ER

PT J
AU Carrara, F
   Falchi, F
   Caldelli, R
   Amato, G
   Becarelli, R
AF Carrara, Fabio
   Falchi, Fabrizio
   Caldelli, Roberto
   Amato, Giuseppe
   Becarelli, Rudy
TI Adversarial image detection in deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial images detection; Deep convolutional neural network; Machine
   learning security
AB Deep neural networks are more and more pervading many computer vision applications and in particular image classification. Notwithstanding that, recent works have demonstrated that it is quite easy to create adversarial examples, i.e., images malevolently modified to cause deep neural networks to fail. Such images contain changes unnoticeable to the human eye but sufficient to mislead the network. This represents a serious threat for machine learning methods. In this paper, we investigate the robustness of the representations learned by the fooled neural network, analyzing the activations of its hidden layers. Specifically, we tested scoring approaches used for kNN classification, in order to distinguish between correctly classified authentic images and adversarial examples. These scores are obtained searching only between the very same images used for training the network. The results show that hidden layers activations can be used to reveal incorrect classifications caused by adversarial attacks.
C1 [Carrara, Fabio; Falchi, Fabrizio; Amato, Giuseppe] CNR, ISTI, Via G Moruzzi 1, Pisa, Italy.
   [Caldelli, Roberto; Becarelli, Rudy] Univ Florence, CNIT Res Unit, MICC, Viale Morgagni 65, Florence, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR); University
   of Florence
RP Carrara, F (corresponding author), CNR, ISTI, Via G Moruzzi 1, Pisa, Italy.
EM Fabio.Carrara@isti.cnr.it; Fabrizio.Falchi@isti.cnr.it;
   Roberto.Caldelli@unifi.it; Giuseppe.Amato@isti.cnr.it;
   Rudy.Becarelli@unifi.it
RI Amato, Giuseppe/F-2227-2013; Falchi, Fabrizio/J-2920-2012; Carrara,
   Fabio/R-2275-2019; Caldelli, Roberto/AAP-1708-2020
OI Amato, Giuseppe/0000-0003-0171-4315; Falchi,
   Fabrizio/0000-0001-6258-5313; Carrara, Fabio/0000-0001-5014-5089;
   Caldelli, Roberto/0000-0003-3471-1196
FU Smart News, Social sensing for breaking news; Tuscany region under the
   FAR-FAS 2014 program [CUP CIPE D58C15000270008]; Fondazione Cassa di
   Risparmio di Firenze (Italy); NVIDIA Corporation
FX This work was partially supported by Smart News, Social sensing for
   breaking news, co-founded by the Tuscany region under the FAR-FAS 2014
   program, CUP CIPE D58C15000270008, and the project ESPRESS (Smartphone
   identification based on on-board sensors for security applications)
   co-funded by Fondazione Cassa di Risparmio di Firenze (Italy) within the
   Scientific Research and Technological Innovation framework. We
   gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Tesla K40 GPU used for this research.
CR Amato G, 2017, EXPERT SYST APPL, V72, P327, DOI 10.1016/j.eswa.2016.10.055
   Amato G, 2016, LECT NOTES COMPUT SC, V9939, P196, DOI 10.1007/978-3-319-46759-7_15
   Amerini I, 2017, IEEE COMPUT SOC CONF, P1865, DOI 10.1109/CVPRW.2017.233
   [Anonymous], 2016, Adversarial perturbations against deep neural networks for malware classification
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], 2016, ARXIV161109312
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], SING CYB SEC C SG CR
   [Anonymous], ARXIV160607287
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2014, arxiv: 1412. 6572
   [Anonymous], ARXIV150802496
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], NIPS 2017 COMPETITIO
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], J COMPUTING CULTURAL
   [Anonymous], IEEE INT WORKSH INF
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   Bengio S, 2016, ARXIV
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Carrara F., 2017, Proceedings of the 15th International Workshop on Content-Based Multimedia Indexing, P38
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Erhan D, 2013, 2 INT C LEARNING REP
   Frossard P, 2016, ARXIV161008401
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Grosse K., 2017, ARXIV
   Gu S, 2015, 3TH INT C LEARN REPR
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Klarreich E, 2016, COMMUN ACM, V59, P12, DOI 10.1145/2994577
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Metzen J. H., 2017, P INT C LEARN REPR T
   Papernot N., 2016, SOK SCI SECURITY PRI, P1
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Papernot Nicolas, 2017, ARXIV161000768
   Papernot Nicolas, 2016, arXiv preprint arXiv:1602.02697
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tabacof P, 2016, IEEE IJCNN, P426, DOI 10.1109/IJCNN.2016.7727230
NR 47
TC 21
Z9 23
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2815
EP 2835
DI 10.1007/s11042-018-5853-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600010
DA 2024-07-18
ER

PT J
AU Al-Otum, HM
AF Al-Otum, Hazem Munawer
TI Wavelet packets-based watermarking with preserved high color image
   quality and enhanced robustness for copyright protection applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image processing; Wavelet-packets; Robust watermarking; Copyright
   protection and watermarking attacks
ID SCHEME; DOMAIN
AB This paper proposes an effective technique to be implemented for wavelet-packets-based color image watermarking applications. The proposed technique exhibits high imperceptibility and enhanced robustness for copyright protection applications that exploits the significant features between color image components. The RGB layers of the input color host image are extracted and separately applied to the wavelet-packet transform. The obtained transformed components are used to build the so called difference conjoint core trees with coefficients corresponding to various frequency bands of the same spatial location. Next, an updating step is applied by adaptively modifying selected elements in such a manner to provide the selected coefficients with proper energy (amplitude) to preserve the watermark while not highly deteriorating the output image quality. Simulation results have shown high imperceptibility as well as superior robustness against a wide variety of mild-to-severe unintentional and intentional attacks.
C1 [Al-Otum, Hazem Munawer] Jordan Univ Sci & Technol, EE Dept, POB 3030, Irbid 22110, Jordan.
C3 Jordan University of Science & Technology
RP Al-Otum, HM (corresponding author), Jordan Univ Sci & Technol, EE Dept, POB 3030, Irbid 22110, Jordan.
EM hazem-ot@just.edu.jo
OI Al-Otum, Hazem/0000-0002-3628-3191
CR Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Ansari IA, 2017, PATTERN RECOGN LETT, V94, P228, DOI 10.1016/j.patrec.2016.12.010
   Bhatnagar G, 2012, IET IMAGE PROCESS, V6, P386, DOI 10.1049/iet-ipr.2010.0400
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Dewangan Ravi Prakash, 2015, INT J SCI ENG TECHNO, V4, P3531
   Dietl W, 2003, SIGNAL PROCESS, V83, P2095, DOI 10.1016/S0165-1684(03)00170-1
   Dietl WM, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P2043, DOI 10.1109/ICME.2004.1394666
   Frery AC, 2013, INTRO IMAGE PROCESSI
   Ghannam Shereen, 2008, 2008 International Conference on Computer Engineering & Systems (ICCES '08), P83, DOI 10.1109/ICCES.2008.4772971
   Montefusco L, 2014, WAVELETS THEORY ALGO
   Paquet AH, 2003, SIGNAL PROCESS, V83, P2117, DOI 10.1016/S0165-1684(03)00171-3
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Rawat S, 2012, OPT COMMUN, V285, P2563, DOI 10.1016/j.optcom.2012.01.067
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Saliani S, 2003, J FOURIER ANAL APPL, V9, P117, DOI 10.1007/s00041-003-0008-y
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   Song W, 2015, UBIQUITOUS INT J INF, V6, P613
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Tao P., 2006, J Multimed, V1, P36, DOI 10.4304/jmm.1.6.36-45
   Thirugnanam G., 2010, INT J SIGNAL IMAGE P, V1, p80 
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Véhel JL, 2000, INT C PATT RECOG, P413, DOI 10.1109/ICPR.2000.903572
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
NR 27
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2199
EP 2225
DI 10.1007/s11042-018-6328-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700041
DA 2024-07-18
ER

PT J
AU Liu, LT
   Lu, YL
   Yan, XH
AF Liu, Lintao
   Lu, Yuliang
   Yan, Xuehu
TI Polynomial-based extended secret image sharing scheme with reversible
   and unexpanded covers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret sharing; Polynomial-based scheme; Extended secret image sharing;
   Meaningful shares; Reversible cover images
ID TONE VISUAL CRYPTOGRAPHY; STEGANOGRAPHY; IMPROVEMENTS; ALGORITHM
AB In comparison with traditional secret image sharing (SIS), extended secret image sharing (ESIS) can encrypt the secret image into several meaningful shadow images rather than noise-like shares, which both decrease enemies' suspects and make them more manageable for participants. However, a majority of current ESISs are based on a combination between SIS and steganography, which result in the limited performance such as the small capacity of secret information and the large cost for decryption. In this paper, we propose a (k, n) threshold extended polynomial-based ESIS, namely EPSIS, completely based on Shamir's classic PSIS without the help of steganography. Firstly, novel concepts, such as the sharing map and sharing pool, are defined to reconstruct the sharing and recovery phases of PSIS; secondly, the secret image and halftone binary cover images act on the sharing phase to generate meaningful grayscale shares from the novel view of PSIS based on the sharing map; finally, in order to achieve the same effects but without the huge sharing map, a filtering procedure for appropriate shared values is added into the sharing phase of natural PSIS, which aims to make the most significant bit of pixel in each share equal to bit in corresponding binary cover. In comparison with current ESISs, the proposed EPSIS not only has advantages in the traditional properties, such (k, n) threshold, capacity, visual quality and computational cost, but also owns two unique properties about covers, including no restrictive requirements on the selection of covers and reversible recovery of cover with the single related share. These significant properties are beneficial for searchable encryption in the area of cloud storage. Furthermore, the security condition of the proposed EPSIS is discussed in detail, and then simulations are provided to verify the security and effectiveness.
C1 [Liu, Lintao; Lu, Yuliang; Yan, Xuehu] Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
C3 National University of Defense Technology - China
RP Liu, LT (corresponding author), Natl Univ Def Technol, Hefei 230037, Anhui, Peoples R China.
EM liuta1989@163.com; publictiger@126.com
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720; Lu,
   Yuliang/0000-0002-8502-9907
FU National Natural Science Foundation of China [61602491]
FX This project is supported by the National Natural Science Foundation of
   China (Grant No.61602491). Thanks for the anonymous reviewers'
   constructive comments and suggestions.
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Cheng TF, 2017, MULTIMED TOOLS APPL, V76, P9337, DOI 10.1007/s11042-016-3535-7
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   He JH, 2017, MULTIMED TOOLS APPL, V76, P7677, DOI 10.1007/s11042-016-3429-8
   Li P, 2018, J REAL-TIME IMAGE PR, V14, P41, DOI 10.1007/s11554-016-0621-z
   Li P, 2012, J VIS COMMUN IMAGE R, V23, P441, DOI 10.1016/j.jvcir.2012.01.003
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu F., 2014, VISUAL CRYPTOGRAPHY, DOI [10.1007/978-3-319-09644-5, DOI 10.1007/978-3-319-09644-5]
   Liu F, 2011, IEEE T INF FOREN SEC, V6, P307, DOI 10.1109/TIFS.2011.2116782
   Liu X, 2017, MASTERS DISSERTATION, V52, P1
   Liu X, 2018, J REAL-TIME IMAGE PR, V14, P51, DOI 10.1007/s11554-016-0644-5
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Huynh NT, 2015, J VIS COMMUN IMAGE R, V28, P105, DOI 10.1016/j.jvcir.2015.01.011
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Shen G, 2017, DESIGN CODE CRYPTOGR, V85, P15, DOI 10.1007/s10623-016-0285-5
   Shin SH, 2016, MULTIMED TOOLS APPL, V75, P13931, DOI 10.1007/s11042-016-3844-x
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang DS, 2009, PATTERN RECOGN, V42, P3071, DOI 10.1016/j.patcog.2009.02.015
   Wang ZM, 2006, IEEE IMAGE PROC, P109, DOI 10.1109/ICIP.2006.312384
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Weir J, 2009, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2009.5117797
   Wu XT, 2018, SIGNAL PROCESS, V143, P269, DOI 10.1016/j.sigpro.2017.09.017
   Wu XT, 2013, IEEE T INF FOREN SEC, V8, P1541, DOI 10.1109/TIFS.2013.2274955
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yan XH, 2015, DIGIT SIGNAL PROCESS, V38, P53, DOI 10.1016/j.dsp.2014.12.002
   Yan XH, 2015, SIGNAL PROCESS, V109, P317, DOI 10.1016/j.sigpro.2014.12.002
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 33
TC 13
Z9 13
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1265
EP 1287
DI 10.1007/s11042-018-6202-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700003
DA 2024-07-18
ER

PT J
AU Peng, YJ
   Li, QL
   Yan, YY
   Wang, Q
AF Peng, Yanjun
   Li, Qiaoling
   Yan, Yingying
   Wang, Qiong
TI Real-time deformation and cutting simulation of cornea using point based
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Point based method; Real-time interaction; Virtual surgery; Deformation
   simulation
ID SOFT-TISSUE DEFORMATION; MODEL
AB This paper proposed an improved point based method to simulate the deformation and cutting of cornea, realized the real-time interaction between the force feedback device and the model in virtual surgery. We construct a hybrid deformable model, the model consists of two parts: the interior of the cornea consists of some particles, and the boundary consists of some meshes which are formed by surfaces nodes, calculate the stress tensor of particle can simulate corneal deformation. In this process, in order to ensure the stability of the deformation, a volume constraint is added to our model. By sampling on the surface of the model to form some meshes, the model could support the changes of topology. Using a node replication method for surface cutting and subdivide the cutting triangles in the cutting process, so that it can generate relatively smooth incision. Experiments show that the model provides a real and efficient deformation simulation, with good stability and scalability.
C1 [Peng, Yanjun; Li, Qiaoling; Yan, Yingying] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
   [Wang, Qiong] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
C3 Shandong University of Science & Technology; Chinese Academy of
   Sciences; Shenzhen Institute of Advanced Technology, CAS
RP Peng, YJ (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
EM pengyanjuncn@163.com
FU National key research and development project of China [2016YFC0801406];
   Natural Science Foundation of Shandong Province [ZR2015FM013]; National
   Natural Science Foundation of China [61502279]; National key research
   and development project of the Shandong Province [2016GSF120012];
   Special Project Fund of Taishan Scholars of Shandong Province, Leading
   Talent Project of Shandong University of Science and Technology
FX This work is supported by the National key research and development
   project of China under Grant No.2016YFC0801406, the Natural Science
   Foundation of Shandong Province under Grant No. ZR2015FM013, the
   National Natural Science Foundation of China under Grant No. 61502279,
   the National key research and development project of the Shandong
   Province under Grant No. 2016GSF120012, and by Special Project Fund of
   Taishan Scholars of Shandong Province, Leading Talent Project of
   Shandong University of Science and Technology.
CR Bianchi G, 2004, LECT NOTES COMPUT SC, V3217, P293
   Bianchi G, 2004, MED IMAGE COMPUT COM, V2004, P293
   Busaryev O, 2013, ADAPTIVE FRACTURE SI
   Camara M, 2016, INT J COMPUT ASS RAD, V11, P919, DOI 10.1007/s11548-016-1373-8
   Choi KS, 2009, COMPUT BIOL MED, V39, P1020, DOI 10.1016/j.compbiomed.2009.08.003
   Gilles B, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944855
   Guo X, 2010, COMPUT ANIMAT VIRT W, V16, P189
   Hong M, 2006, IEEE COMPUT GRAPH, V26, P83, DOI 10.1109/MCG.2006.104
   Jung H, 2012, REAL TIME CUTTING SI
   Kaufmann P, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531356
   Lim YJ, 2006, COMP MED SY, P635
   Liu YQ, 2008, 2008 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2008), VOLS 1-4, P606, DOI 10.1109/APCCAS.2008.4746096
   Markus B, 2009, NPH 2009
   Müller M, 2007, J VIS COMMUN IMAGE R, V18, P109, DOI 10.1016/j.jvcir.2007.01.005
   Müller M, 2005, ACM T GRAPHIC, V24, P471, DOI 10.1145/1073204.1073216
   Muller M., 2004, P 2004 ACM SIGGRAPHE, P141, DOI [DOI 10.1145/1028523.1028542, 10.1145/1028523.1028542, 10]
   Pauly M, 2005, ACM T GRAPHIC, V24, P957, DOI 10.1145/1073204.1073296
   Peng Y, 2017, MULTIMED TOOLS APPL, P1
   Peng YJ, 2011, COMPUT ANIMAT VIRT W, V22, P277, DOI 10.1002/cav.418
   Selle A, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360663
   Shrivastava P, 2014, IND C COMP VIS GRAPH, P6
   Solenthaler B, 2007, COMPUT ANIMAT VIRT W, V18, P69, DOI 10.1002/cav.162
   Wang YF, 2014, I C VIRTUAL REALITY, P430, DOI 10.1109/ICVRV.2014.58
   Wicke M, 2007, COMPUT GRAPH FORUM, P355
   Zhu B, 2012, COMPUT MED IMAG GRAP, V36, P356, DOI 10.1016/j.compmedimag.2012.03.001
NR 25
TC 3
Z9 3
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2251
EP 2268
DI 10.1007/s11042-018-6343-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700043
DA 2024-07-18
ER

PT J
AU Wang, P
   Ni, C
   Zhang, GY
   Li, KF
AF Wang, Peng
   Ni, Cui
   Zhang, Guangyuan
   Li, Kefeng
TI R-Lambda model based CTU-level rate control for intra frames in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; CTU-level rate control; Motion vector; Bit allocation
ID RATE-CONTROL ALGORITHM; MULTIVIEW VIDEO
AB In High Efficiency Video Coding (HEVC), the coding efficiency of intra frames is much lower than inter frames. If the bits allocated to intra frames are not sufficient to improve their quality, the quality fluctuation between intra frames and their neighboring inter frames will appear. But if too many bits are allocated to intra frames, the other frames may get bits starvation, which will cause quality degradation of some other frames. We propose an R-Lambda model based CTU-level rate control to improve the reconstructed quality of intra frames with fewer bits. CTUs in intra frame are classified into three regions according to their motion vectors and complexity. The bits allocated to CTUs belong to different regions will be adjusted and the R-lambda model will be used to calculate the QPs. Experimental results demonstrate that the proposed rate control can efficiently reduce the bits cost by intra frames and suppress the quality fluctuation between intra frames and others when compared to the rate control by R-lambda model adopted in HM10.0.
C1 [Wang, Peng; Ni, Cui; Zhang, Guangyuan; Li, Kefeng] Shandong Jiao Tong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
C3 Shandong Jiaotong University
RP Wang, P (corresponding author), Shandong Jiao Tong Univ, Sch Informat Sci & Elect Engn, Jinan 250357, Shandong, Peoples R China.
EM knightwp@126.com
FU National Natural Science Funds of China [61502277]; Natural Science
   Funds of Shandong Province [ZR2015FL017]
FX This work was partially supported by the National Natural Science Funds
   of China (Grant No. 61502277) and the Natural Science Funds of Shandong
   Province (Grant No. ZR2015FL017).
CR Boyce JM, 2016, IEEE T CIRC SYST VID, V26, P20, DOI 10.1109/TCSVT.2015.2461951
   Choi H, 2012, RATE CONTROL BASED U
   Hu HM, 2012, IEEE T CIRC SYST VID, V22, P1564, DOI 10.1109/TCSVT.2012.2199398
   Hu HM, 2011, J VIS COMMUN IMAGE R, V22, P504, DOI 10.1016/j.jvcir.2011.05.002
   Hu SD, 2012, IEEE T IMAGE PROCESS, V21, P1911, DOI 10.1109/TIP.2011.2176347
   Kim I, 2012, HM9 HIGH EFFICIENCY
   Kuo CH, 2016, IEEE T CIRC SYST VID, V26, P2069, DOI 10.1109/TCSVT.2015.2501921
   Kwon DK, 2007, IEEE T CIRC SYST VID, V17, P517, DOI 10.1109/TCSVT.2007.894053
   Lei JJ, 2014, MULTIMED TOOLS APPL, V72, P825, DOI 10.1007/s11042-013-1386-z
   Li B., 2012, RATE CONTROL R LAMBD
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li L, 2016, IEEE T MULTIMEDIA, V18, P2023, DOI 10.1109/TMM.2016.2595264
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1533, DOI 10.1109/TCSVT.2010.2077773
   McCann K., 2013, HIGH EFFICIENCY VIDE
   Park S, 2011, REPORT EVALUATION HM
   Sanz-Rodríguez S, 2013, INT CONF ACOUST SPEE, P1719, DOI 10.1109/ICASSP.2013.6637946
   Shao F, 2013, IEEE T MULTIMEDIA, V15, P1843, DOI 10.1109/TMM.2013.2269897
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Si JJ, 2013, PICT COD SYMP, P89, DOI 10.1109/PCS.2013.6737690
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian L, 2014, IEEE INT C COMP NETW
   Tsai WJ, 2010, IEEE T CIRC SYST VID, V20, P1882, DOI 10.1109/TCSVT.2010.2087473
   Wang P, 2013, INT C IM PROC ICIP 2, P9
   Yang J, 2013, MULTIMED TOOLS APPL, V64, P581, DOI 10.1007/s11042-011-0967-y
   Zeng HQ, 2016, MULTIMED TOOLS APPL, V75, P10383, DOI 10.1007/s11042-015-2997-3
   Zhang XG, 2013, IEEE T MULTIMEDIA, V15, P1446, DOI 10.1109/TMM.2013.2247988
   Zhou YM, 2013, IEEE SYMP COMP COMMU
NR 27
TC 6
Z9 6
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 125
EP 139
DI 10.1007/s11042-017-5507-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500007
DA 2024-07-18
ER

PT J
AU Al-Shamayleh, AS
   Ahmad, R
   Abushariah, MAM
   Alam, KA
   Jomhari, N
AF Al-Shamayleh, Ahmad Sami
   Ahmad, Rodina
   Abushariah, Mohammad A. M.
   Alam, Khubaib Amjad
   Jomhari, Nazean
TI A systematic literature review on vision based gesture recognition
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Gesture recognition; Vision-based gesture recognition; Human-computer
   interaction; Computer vision; Systematic literature review
ID HUMAN-COMPUTER INTERACTION; SIGN-LANGUAGE RECOGNITION; DELAY
   NEURAL-NETWORK; HAND-GESTURE; DYNAMIC HAND; DEPTH DATA; ALGORITHM;
   TRACKING; POSTURE
AB Human Computer Interaction (HCI) technologies are rapidly evolving the way we interact with computing devices and adapting to the constantly increasing demands of modern paradigms. One of the most useful tools in this regard is the integration of Human-to-Human Interaction gestures to facilitate communication and expressing ideas. Gesture recognition requires the integration of postures, gestures, face expressions and movements for communicating or conveying certain messages. The aim of this study is to aggregate and synthesize experiences and accumulated knowledge about Vision-Based Recognition (VBR) techniques. The major objective of conducting this Systematic Literature Review (SLR) is to highlight the state-of-the-art in the context of vision-based gesture recognition with specific focus on hand gesture recognition (HGR) techniques and enabling technologies. After a careful systematic selection process, 100 studies relevant to the four research questions were selected. This process was followed by data collection, a detailed analysis, and a synthesis of the selected studies. The results reveal that among the VBR techniques, HGR is a predominant and highly focused area of research. Research focus is also found to be converging towards sign language recognition. Potential applications of HGR techniques include desktop applications, smart environments, entertainment, sign language interpretation, virtual reality and gamification. Although various experimental research efforts have been devoted to gestures recognition, there are still numerous open issues and research challenges in this field. Lastly, considering the results from this SLR, potential future research directions are suggested, including a much needed focus on grammatical interpretation, hybrid approaches, smartphone devices, normalization, and real-life systems.
C1 [Al-Shamayleh, Ahmad Sami; Ahmad, Rodina; Alam, Khubaib Amjad; Jomhari, Nazean] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Software Engn, Kuala Lumpur 50603, Malaysia.
   [Abushariah, Mohammad A. M.] Univ Jordan, Dept Comp Informat Syst, King Abdullah II Sch Informat Technol, Amman 11942, Jordan.
C3 Universiti Malaya; University of Jordan
RP Al-Shamayleh, AS (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Dept Software Engn, Kuala Lumpur 50603, Malaysia.
EM ashamayleh@siswa.um.edu.my; rodina@um.edu.my; m.abushariah@ju.edu.jo;
   khubaibalam@siswa.um.edu.my; nazean@um.edu.my
RI JOMHARI, NAZEAN/B-9213-2010; Ahmad, Rodina/B-9582-2010; Al-Shamayleh,
   Ahmad Sami/IVU-8846-2023; Abushariah, Mohammad/C-2501-2015
OI JOMHARI, NAZEAN/0000-0002-1609-5353; Al-Shamayleh, Dr. Ahmad
   Sami/0000-0002-7222-2433; Abushariah, Mohammad/0000-0002-1676-8765
CR Alam KA, 2015, INFORM SYST, V54, P43, DOI 10.1016/j.is.2015.06.003
   Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   Amin MA, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2218
   [Anonymous], P INT C COMP COMM NE
   [Anonymous], 2006, P GEOMETRIC MODELING, DOI DOI 10.1109/GMAI.2006.18
   [Anonymous], 2011 3DTV C TRUE VIS
   [Anonymous], 2006, THESIS U SOUTHAMPTON
   [Anonymous], INSTR MEAS TECHN C P
   [Anonymous], ROBIO 2008 IEEE INT
   [Anonymous], ADV INTELLIGENT SYST
   [Anonymous], P CHI SPARKS
   [Anonymous], NEURAL NETW
   [Anonymous], GUIDELINES PERFORMIN
   [Anonymous], 0673 IDIAP EPFL
   [Anonymous], 2007, LECT NOTES
   [Anonymous], PRIS
   [Anonymous], P 2015 10 INT C COMP
   [Anonymous], 2010 2 INT C SIGN PR
   [Anonymous], P 19 IAPR IEEE INT C
   [Anonymous], THESIS
   [Anonymous], REV VISION BASED HAN
   [Anonymous], THESIS
   [Anonymous], 1995, IEEE INT WORKSH AUT
   Appenrodt J., 2010, 2010 International Conference of Soft Computing and Pattern Recognition (SoCPaR 2010), P35, DOI 10.1109/SOCPAR.2010.5685854
   Auephanwiriyakul S, 2013, PATTERN RECOGN LETT, V34, P1291, DOI 10.1016/j.patrec.2013.04.017
   Aujeszky T, 2016, MULTIMED TOOLS APPL, V75, P8493, DOI 10.1007/s11042-015-2767-2
   Badi Haitham, 2016, Intelligent Industrial Systems, V2, P179, DOI 10.1007/s40903-016-0046-9
   Bao J, 2011, 2011 INT C ELECT INF, P338
   Baxter J, 2000, J ARTIF INTELL RES, V12, P149, DOI 10.1613/jair.731
   Bellal A, 2011, INT REV RED CROSS, V93, P47, DOI 10.1017/S1816383111000051
   Bilal S, 2013, ARTIF INTELL REV, V40, P495, DOI 10.1007/s10462-011-9292-0
   Binh N., 2005, P INT C GRAPHICS VIS, P19
   Birdal A, 2008, WSCG 2008, COMMUNICATION PAPERS, P1
   Bourke AK, 2007, GAIT POSTURE, V26, P194, DOI 10.1016/j.gaitpost.2006.09.012
   Bretzner L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P423, DOI 10.1109/AFGR.2002.1004190
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chang CC, 2006, J INF SCI ENG, V22, P1047
   Chaudhary A., 2011, Int J Comput Sci Eng Survey, V2, P122, DOI DOI 10.5121/IJCSES.2011.2109
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Chen LC, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND APPLICATIONS (CSA), P313, DOI 10.1109/CSA.2013.79
   Chen Q, 2008, IEEE T INSTRUM MEAS, V57, P1562, DOI 10.1109/TIM.2008.922070
   Cheng H, 2016, PATTERN RECOGN, V55, P137, DOI 10.1016/j.patcog.2016.01.011
   Cheng J, 2012, PATTERN RECOGN LETT, V33, P476, DOI 10.1016/j.patrec.2010.12.009
   Cheok MJ, 2019, INT J MACH LEARN CYB, V10, P131, DOI 10.1007/s13042-017-0705-5
   Choras Ryszard S., 2009, Proceedings of the 2009 IEEE Symposium on Industrial Electronics & Applications (ISIEA 2009), P145, DOI 10.1109/ISIEA.2009.5356486
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Côté M, 2006, I W IMAG SYST TECHNI, P27
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Tran C, 2012, IEEE T IND INFORM, V8, P178, DOI 10.1109/TII.2011.2172450
   D'Orazio T, 2016, IMAGE VISION COMPUT, V52, P56, DOI 10.1016/j.imavis.2016.05.007
   Dabre K, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, SYSTEMS, COMMUNICATION AND INFORMATION TECHNOLOGY APPLICATIONS (CSCITA), P317, DOI 10.1109/CSCITA.2014.6839279
   de Brito DM, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146352
   de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33
   Deng Lawrence Y., 2010, IET International Conference on Frontier Computing. Theory, Technologies and Applications, P436, DOI 10.1049/cp.2010.0602
   Deng-Yuan Huang, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1, DOI 10.1109/IIH-MSP.2009.96
   Derpanis K.G., 2005, Lecture Notes
   Dinh DL, 2016, MULTIMED TOOLS APPL, V75, P1333, DOI 10.1007/s11042-014-2370-y
   Dongjin Huang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P737, DOI 10.1109/ICIG.2011.125
   Elmezain M, 2009, IEEE IMAGE PROC, P3577, DOI 10.1109/ICIP.2009.5414322
   Gameiro J., 2014, Procedia Technology, V17, P384, DOI [DOI 10.1016/J.PROTCY.2014.10.199, 10.1016/j.protcy.2014.10.199]
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Goza S. M., 2004, Proceedings of the 2004 conference on Human factors in computing systems-CHI'04, P623, DOI 10.1145/985692.985771
   Guan-Feng He, 2011, Proceedings 2011 IEEE 2nd International Conference on Software Engineering and Service Science (ICSESS 2011), P187, DOI 10.1109/ICSESS.2011.5982286
   Gupta S, 2012, PROCEDIA ENGINEER, V41, P827, DOI 10.1016/j.proeng.2012.07.250
   Hackenberg G, 2011, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2011.5759431
   Hasan H, 2014, NEURAL COMPUT APPL, V25, P251, DOI 10.1007/s00521-013-1481-0
   Hasan MM., 2012, Int J Mach Learn Comput, V2, P266, DOI [10.7763/IJMLC.2012.V2.128, DOI 10.7763/IJMLC.2012.V2.128]
   Henia O. B., 2011, Proceedings of the 2011 Workshop on Digital Media and Digital Content Management (DMDCM 2011), P72, DOI 10.1109/DMDCM.2011.65
   Ho MF, 2011, PATTERN RECOGN, V44, P443, DOI 10.1016/j.patcog.2010.08.012
   Holzmann GerardJ., 1990, DESIGN VALIDATION CO
   Hongwang Du, 2011, 2011 International Conference on Multimedia Technology, P416
   Hu C, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1560
   Hu M, 2014, IEEE IJCNN, P3108, DOI 10.1109/IJCNN.2014.6889632
   Huang DY, 2011, EXPERT SYST APPL, V38, P6031, DOI 10.1016/j.eswa.2010.11.016
   Ibarguren A, 2010, ENG APPL ARTIF INTEL, V23, P1216, DOI 10.1016/j.engappai.2010.06.001
   Ionescu B, 2005, EURASIP J APPL SIG P, V2005, P2101, DOI 10.1155/ASP.2005.2101
   Ionescu D., 2011, 2011 6th IEEE International Symposium on Applied Computational Intelligence and Informatics (SACI), P159, DOI 10.1109/SACI.2011.5872992
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Ju SX, 1997, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.1997.609386
   Jufeng Yang, 2011, 2011 Seventh International Conference on Natural Computation (ICNC 2011), P1588, DOI 10.1109/ICNC.2011.6022274
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kaoning Hu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3760, DOI 10.1109/ICPR.2010.916
   Kausar S., 2011, Proceedings of the 2011 Frontiers of Information Technology (FIT 2011), P95, DOI 10.1109/FIT.2011.25
   Kevin NYY, 2004, TENCON IEEE REGION, pA571
   Kiliboz NÇ, 2015, J VIS COMMUN IMAGE R, V28, P97, DOI 10.1016/j.jvcir.2015.01.015
   Kim J, 2016, WIRELESS PERS COMMUN, V86, P255, DOI 10.1007/s11277-015-3068-9
   Kitchenham B., 2004, TRSE0401 KEELE U, V33, P28, DOI [10.1.1.122.3308, DOI 10.1.1.122.3308]
   Kitchenham B, 2009, INFORM SOFTWARE TECH, V51, P7, DOI 10.1016/j.infsof.2008.09.009
   Kumar YHS, 2016, ADV INTELL SYST COMP, V404, P611, DOI 10.1007/978-81-322-2695-6_52
   Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224
   Li Q, 2012, PHYSIOL MEAS, V33, P1491, DOI 10.1088/0967-3334/33/9/1491
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu K, 2016, J REAL-TIME IMAGE PR, V11, P201, DOI 10.1007/s11554-013-0333-6
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu Yun, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P72, DOI 10.1109/WCSE.2009.769
   Lu W.-L., 2006, The 3rd Canadian Conference on Computer and Robot Vision (CRV'06), P6
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Luo QS, 2010, MACH VISION APPL, V21, P377, DOI 10.1007/s00138-008-0168-5
   Mahdavi-Hezavehi S, 2013, INFORM SOFTWARE TECH, V55, P320, DOI 10.1016/j.infsof.2012.08.010
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Muñoz-Salinas R, 2008, PATTERN RECOGN LETT, V29, P319, DOI 10.1016/j.patrec.2007.10.011
   Murthy GRS, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P134, DOI 10.1109/IADCC.2010.5423024
   Murthy G.R.S., 2009, International Journal of Information Technology and Knowledge Management, V2, P405
   Myers B.A., 1998, ACM INTERACTIONS, V5, P44, DOI DOI 10.1145/274430.274436
   Noury N, 2003, P ANN INT IEEE EMBS, V25, P3286, DOI 10.1109/IEMBS.2003.1280846
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Parvini Farid, 2007, Int J Bioinform Res Appl, V3, P4, DOI 10.1504/IJBRA.2007.011832
   Paulraj MP, 2008, ICED: 2008 INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN, VOLS 1 AND 2, P5
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Pisharady PK, 2015, COMPUT VIS IMAGE UND, V141, P152, DOI 10.1016/j.cviu.2015.08.004
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Radkowski R., 2012, 5 INT C ADV COMPUTER, P303
   Rautaray SiddharthS., 2012, Int J UbiComp, V3, P21
   Rautaray SS, 2010, P 1 INT C INT INT TE, P292
   Reale MJ, 2011, IEEE T MULTIMEDIA, V13, P474, DOI 10.1109/TMM.2011.2120600
   Reese MG, 2001, COMPUT CHEM, V26, P51, DOI 10.1016/S0097-8485(01)00099-7
   Ren Y, 2009, IEEE I C EMBED SOFTW, P344, DOI 10.1109/ICESS.2009.21
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Sajjawiso T., 2011, Proceedings of the Eighth International Joint Conference on Computer Science and Software Engineering (JCSSE 2011), P177, DOI 10.1109/JCSSE.2011.5930116
   Sangineto E, 2012, IMAGE VISION COMPUT, V30, P26, DOI 10.1016/j.imavis.2011.11.004
   Schlmer T., 2008, Second International Conference on Tangible and Embedded Interaction, P11, DOI [DOI 10.1145/1347390.1347395, 10.1145/1347390.1347395]
   Senin P., 2008, Information and Computer Science Department University of Hawaii at Manoa Honolulu, USA, V855, P40
   Shaily S, 2015, RECENT ADV ENG COMPU, P1
   Sharma R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P964, DOI 10.1109/ICPR.1996.547311
   Smith G.M., 2004, P 17 ANN ACM S USER, P53
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Starner T, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P87, DOI 10.1109/ISWC.2000.888469
   Starner T., 1997, Motion-Based Recognit, P227
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Stotts D., 2004, ACM conference on Hypertext hypermedia, P48, DOI DOI 10.1145/1012807.1012827
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Swapna B, 2011, COMM COM INF SC, V250, P782
   Thirumuruganathan S., 2010, A detailed introduction to k-nearest neighbor (knn) algorithm
   Tong-de Tan, 2011, 2011 IEEE International Symposium on VR Innovation (ISVRI), P311, DOI 10.1109/ISVRI.2011.5759657
   Triesch J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P170, DOI 10.1109/AFGR.1996.557260
   Triesch J, 2001, IEEE T PATTERN ANAL, V23, P1449, DOI 10.1109/34.977568
   Tubaiz N, 2015, IEEE T HUM-MACH SYST, V45, P526, DOI 10.1109/THMS.2015.2406692
   Vafadar M, 2015, MULTIMED TOOLS APPL, V74, P7515, DOI 10.1007/s11042-014-1989-z
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Várkonyi-Kóczy AR, 2011, IEEE T INSTRUM MEAS, V60, P1505, DOI 10.1109/TIM.2011.2108075
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wang G, 2012, ABSTR APPL ANAL, DOI 10.1155/2012/407351
   Webel S., 2008, P ACM S VIRTUAL REAL, P263
   Wöhler C, 1999, IEEE T NEURAL NETWOR, V10, P1531, DOI 10.1109/72.809100
   Wu CH, 2016, MULTIMED TOOLS APPL, V75, P7065, DOI 10.1007/s11042-015-2632-3
   Wu Y, 1999, LECT NOTES ARTIF INT, V1739, P103
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yeo HS, 2015, MULTIMED TOOLS APPL, V74, P2687, DOI 10.1007/s11042-013-1501-1
   Zhang X, 2011, IEEE T SYST MAN CY A, V41, P1064, DOI 10.1109/TSMCA.2011.2116004
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
NR 158
TC 69
Z9 72
U1 15
U2 148
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28121
EP 28184
DI 10.1007/s11042-018-5971-z
PG 64
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500017
DA 2024-07-18
ER

PT J
AU Chu, PM
   Cho, S
   Sim, S
   Kwak, K
   Cho, K
AF Chu, Phuong Minh
   Cho, Seoungjae
   Sim, Sungdae
   Kwak, Kiho
   Cho, Kyungeun
TI Convergent application for trace elimination of dynamic objects from
   accumulated lidar point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convergence; Trace filtering; Ground segmentation; Voxel map;
   Bresenham's line algorithm
ID 3D; CLASSIFICATION
AB In this paper, a convergent multimedia application for filtering traces of dynamic objects from accumulated point cloud data is presented. First, a fast ground segmentation algorithm is designed by dividing each frame data item into small groups. Each group is a vertical line limited by two points. The first point is orthogonally projected from a sensor's position to the ground. The second one is a point in the outermost data circle. Two voxel maps are employed to save information on the previous and current frames. The position and occupancy status of each voxel are considered for detecting the voxels containing past data of moving objects. To increase detection accuracy, the trace data are sought in only the nonground group. Typically, verifying the intersection between the line segment and voxel is repeated numerous times, which is time-consuming. To increase the speed, a method is proposed that relies on the three-dimensional Bresenham's line algorithm. Experiments were conducted, and the results showed the effectiveness of the proposed filtering system. In both static and moving sensors, the system immediately eliminated trace data and maintained other static data, while operating three times faster than the sensor rate.
C1 [Chu, Phuong Minh; Cho, Seoungjae; Cho, Kyungeun] Dongguk Univ Seoul, Dept Multimedia Engn, 30,Pildongro 1 Gil, Seoul 04620, South Korea.
   [Sim, Sungdae; Kwak, Kiho] Agcy Def Dev, POB 35, Yuseong 34186, Daejeon, South Korea.
C3 Dongguk University; Agency of Defense Development (ADD), Republic of
   Korea
RP Cho, K (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, 30,Pildongro 1 Gil, Seoul 04620, South Korea.
EM cke@dongguk.edu
FU Agency for Defense Development [UD150017ID]
FX This work was also supported by a grant from Agency for Defense
   Development, under contract #UD150017ID.
CR Aijazi AK, 2013, REMOTE SENS-BASEL, V5, P3701, DOI 10.3390/rs5083701
   [Anonymous], 2013, ISPRS ANNAL PHOTOGRA
   [Anonymous], SCI WORLD J
   [Anonymous], SCI REP-UK, DOI [DOI 10.1038/s41598-016-0001-8, DOI 10.1038/SREP38294]
   [Anonymous], LINE3D 3D BRESENHAMS
   [Anonymous], P 5 INT C UB COMP AP
   [Anonymous], 2011, ECMR 5 EUR C MOB ROB
   Azim A, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P802, DOI 10.1109/IVS.2012.6232303
   Choe Y, 2013, ADV ROBOTICS, V27, P351, DOI 10.1080/01691864.2013.763724
   Douillard B, 2011, IEEE INT CONF ROBOT
   Hou YY, 2016, J INF PROCESS SYST, V12, P502, DOI 10.3745/JIPS.02.0042
   Jin JH, 2011, EXPERT SYST APPL, V38, P15159, DOI 10.1016/j.eswa.2011.05.088
   Kanatani T, 2013, IEEE IMAGE PROC, P2163, DOI 10.1109/ICIP.2013.6738446
   Litomisky Krystof, 2013, Advances in Depth Image Analysis and Applications. International Workshop, WDIA 2012. Selected and Invited Papers: LNCS 7854, P50, DOI 10.1007/978-3-642-40303-3_6
   Mertz C, 2013, J FIELD ROBOT, V30, P17, DOI 10.1002/rob.21430
   Moosmann F, 2009, IEEE INT VEH SYM, P215, DOI 10.1109/IVS.2009.5164280
   Mu KN, 2016, J INF PROCESS SYST, V12, P183, DOI 10.3745/JIPS.02.0040
   Ryde J, 2013, IEEE INT C INT ROBOT, P3731, DOI 10.1109/IROS.2013.6696889
   Sappa AD, 2012, STUD COMPUT INTELL, V386, P25
   Song W, 2015, MULTIMED TOOLS APPL, V74, P3459, DOI 10.1007/s11042-013-1669-4
   Suzuki T, 2010, IEEE INT C INT ROBOT, P5737, DOI 10.1109/IROS.2010.5652983
   Yungeun Choe, 2011, 2011 Proceedings of IEEE International Symposium on Safety, Security, and Rescue Robotics (SSRR 2011), P110, DOI 10.1109/SSRR.2011.6106760
NR 22
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29991
EP 30009
DI 10.1007/s11042-017-5089-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800047
DA 2024-07-18
ER

PT J
AU Gao, Z
   Han, TT
   Zhang, H
   Xue, YB
   Xu, GP
AF Gao, Zan
   Han, Tao-tao
   Zhang, Hua
   Xue, Yan-bing
   Xu, Guang-ping
TI MMA: a multi-view and multi-modality benchmark dataset for human action
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Benchmark dataset; Multi-view; Multi-modalidy;
   Cross-view; Multi-task; Cross-domain
ID FEATURE-SELECTION
AB Human action recognition is an active research topic in both computer vision and machine learning communities, which has broad applications including surveillance, biometrics and human computer interaction. In the past decades, although some famous action datasets have been released, there still exist limitations, including the limited action categories and samples, camera views and variety of scenarios. Moreover, most of them are designed for a subset of the learning problems, such as single-view learning problem, cross-view learning problem and multi-task learning problem. In this paper, we introduce a multi-view, multi-modality benchmark dataset for human action recognition (abbreviated to MMA). MMA consists of 7080 action samples from 25 action categories, including 15 single-subject actions and 10 double-subject interactive actions in three views of two different scenarios. Further, we systematically benchmark the state-of-the-art approaches on MMA with respective to all three learning problems by different temporal-spatial feature representations. Experimental results demonstrate that MMA is challenging on all three learning problems due to significant intra-class variations, occlusion issues, views and scene variations, and multiple similar action categories. Meanwhile, we provide the baseline for the evaluation of existing state-of-the-art algorithms.
C1 [Gao, Zan; Han, Tao-tao; Zhang, Hua; Xue, Yan-bing; Xu, Guang-ping] Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.
   [Gao, Zan; Han, Tao-tao; Zhang, Hua; Xue, Yan-bing; Xu, Guang-ping] Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
C3 Tianjin University of Technology; Tianjin University of Technology
RP Gao, Z (corresponding author), Tianjin Univ Technol, Key Lab Comp Vis & Syst, Minist Educ, Tianjin 300384, Peoples R China.; Gao, Z (corresponding author), Tianjin Univ Technol, Tianjin Key Lab Intelligence Comp & Novel Softwar, Tianjin 300384, Peoples R China.
EM zangaonsh4522@gmail.com
OI Xu, Guangping/0000-0001-5221-0331
FU National Natural Science Foundation of China [61572357, 61202168];
   Tianjin Municipal Natural Science Foundation [14JCZDJC31700,
   13JCQNJC0040]
FX This work was supported in part by the National Natural Science
   Foundation of China (No.61572357, No.61202168), Tianjin Municipal
   Natural Science Foundation (No.14JCZDJC31700, No.13JCQNJC0040).
CR [Anonymous], 2012, COMPUTER SCI
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IJCV
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], NTU RGB D LARGE SCAL
   [Anonymous], 2014, CVPR
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Chen G, 2015, HUMAN ACTION RECOGNI, P418
   Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Evgeniou T., 2004, P 10 ACM SIGKDD INT, P109, DOI DOI 10.1145/1014052.1014067
   Gao Z, 2017, MULTIMED TOOLS APPL, V76, P20125, DOI 10.1007/s11042-017-4384-8
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2017, J VIS COMMUN IMAGE R
   Gao Z, 2016, NEUROCOMPUTING, V173, P110, DOI 10.1016/j.neucom.2015.07.105
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Han YH, 2012, IEEE T CIRC SYST VID, V22, P1485, DOI 10.1109/TCSVT.2012.2202075
   He XN, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P771, DOI 10.1145/2566486.2567975
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Lin L, 2016, INT J COMPUT VISION, V118, P256, DOI 10.1007/s11263-015-0876-z
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Marszalek M., 2009, IEEE C COMP VIS PATT
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Rahmani H, 2016, PROC CVPR IEEE, P1506, DOI 10.1109/CVPR.2016.167
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Ren TW, 2015, MULTIMEDIA SYST, V21, P189, DOI 10.1007/s00530-014-0384-y
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Soomro K, 2014, ACTION RECOGNITION R, P408
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zheng J, 2016, CROSS VIEW ACTION RE, P2542
   Zhou Q, 2013, IEEE I CONF COMP VIS, P2264, DOI 10.1109/ICCV.2013.281
NR 44
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29383
EP 29404
DI 10.1007/s11042-018-5833-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800011
DA 2024-07-18
ER

PT J
AU Liu, ZB
   Xu, T
   Ma, C
   Gao, CY
   Yang, HH
AF Liu, Zhenbing
   Xu, Tao
   Ma, Chao
   Gao, Chunyang
   Yang, Huihua
TI T-test based Alzheimer's disease diagnosis with multi-feature in MRIs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AD; MCI; MRI; T-test; P-Value; Multi-feature
ID SVM FEATURE-SELECTION; CLASSIFICATION; IMAGES
AB Diagnosing Alzheimer's disease (AD) with magnetic resonance imaging (MRI) has attracted increasing attention. In this paper, we propose a new feature selection method for AD diagnosis by selecting interested structures in brain MRI. In the proposed method, P-Value is used to obtain the independent principal features, and the structures that have large values are selected as interested structures. P-Value for every voxel is calculated by T-test between different image classes, then the average P-Value for every brain tissue is obtained. After these operations, we firstly use Statistical Parametric Mapping (SPM) software to pre-process MRI, secondly select interested structures based on T-test, then extract different texture characteristics as multi-feature, finally classify the images to diagnose AD by collaborative representation based classification (CRC). Extensive experiments were conducted to evaluate the proposed method, and the comparison results indicate that it achieves better performance in contrast with several existing algorithms.
C1 [Liu, Zhenbing; Xu, Tao; Ma, Chao; Gao, Chunyang; Yang, Huihua] Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, 1 Jinji Rd, Qixing Strict 541000, Guilin, Peoples R China.
C3 Guilin University of Electronic Technology
RP Liu, ZB (corresponding author), Guilin Univ Elect Technol, Guangxi Coll & Univ Key Lab Intelligent Proc Comp, 1 Jinji Rd, Qixing Strict 541000, Guilin, Peoples R China.
EM zbliu@guet.edu.cn
RI Yang, Huihua/ABI-3520-2020
OI Yang, Huihua/0000-0001-6334-4044
FU National Natural Science Foundation of China [61562013]; Natural Science
   Foundation of Guangxi Province [2017GXNSFDA198025]; Innovation Project
   of GUET Graduate Education; study abroad program for graduate student of
   Guilin University of Electronic Technology; project of cultivating
   excellent degree papers for graduate students of GUET
FX The authors would like to thank the anonymous reviewers and the
   associate editor for helpful comments and suggestions. Our study was
   funded by the National Natural Science Foundation of China (Grant No.
   61562013), Natural Science Foundation of Guangxi Province (Grant No.
   2017GXNSFDA198025), Innovation Project of GUET Graduate Education, the
   study abroad program for graduate student of Guilin University of
   Electronic Technology, the project of cultivating excellent degree
   papers for graduate students of GUET. Meanwhile, we want to thank the
   help of Huanhuan Ji, Zimin Wang, Qijia He, Rushi Lan on revising
   manuscript.
CR [Anonymous], MED IMAGE ANAL
   Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013
   Fung G, 2007, KNOWL INF SYST, V11, P243, DOI 10.1007/s10115-006-0043-5
   Gray KR, 2013, NEUROIMAGE, V65, P167, DOI 10.1016/j.neuroimage.2012.09.065
   Hinrichs C, 2011, NEUROIMAGE, V55, P574, DOI 10.1016/j.neuroimage.2010.10.081
   [李昕 LI Xin], 2011, [中国医学影像技术, Chinese Journal of Medical Imaging Technology], V27, P1047
   Liu F, 2014, NEUROIMAGE, V84, P466, DOI 10.1016/j.neuroimage.2013.09.015
   Liu J, 2017, IEEE T NANOBIOSCI, V16, P428, DOI 10.1109/TNB.2017.2707139
   Liu MX, 2017, MED IMAGE ANAL, V36, P123, DOI 10.1016/j.media.2016.11.002
   Liu ZB, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P13, DOI 10.1109/FSKD.2017.8392952
   Ma XY, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00243
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   Mesrob L, 2008, LECT NOTES COMPUT SC, V5128, P124, DOI 10.1007/978-3-540-79982-5_14
   Oppedal K, 2017, BIOMED SIGNAL PROCES, V33, P19, DOI 10.1016/j.bspc.2016.10.007
   Shi YH, 2014, PROC CVPR IEEE, P2721, DOI 10.1109/CVPR.2014.354
   Tong YB, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0159327
   Vemuri P, 2008, NEUROIMAGE, V39, P1186, DOI 10.1016/j.neuroimage.2007.09.073
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhu XF, 2017, IEEE T NEUR NET LEAR, V28, P1263, DOI 10.1109/TNNLS.2016.2521602
   Zhu XF, 2016, IEEE T CYBERNETICS, V46, P450, DOI 10.1109/TCYB.2015.2403356
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
   [朱旭艳 Zhu Xuyan], 2013, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V27, P850
NR 22
TC 2
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29687
EP 29703
DI 10.1007/s11042-018-5768-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800028
DA 2024-07-18
ER

PT J
AU Wang, CL
   Ren, JC
   Wang, HW
   Zhang, YY
   Wen, J
AF Wang, Cai-ling
   Ren, Jinchang
   Wang, Hong-wei
   Zhang, Yinyong
   Wen, Jia
TI Spectral-spatial classification of hyperspectral data using
   spectral-domain local binary patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image classification; Spectral-spatial analysis; Local
   binary patterns; Spectrum information diversity; Support vector machine
ID IMAGES; INFORMATION; FEATURES
AB It is of great interest in spectral-spatial features classification for hyperspectral images (HSI) with high spatial resolution. This paper presents a novel Spectral-spatial classification method for improving hyperspectral image classification accuracy. Specifically, a new texture feature extraction algorithm exploits spatial texture feature from spectrum is proposed. It employs local binary patterns (LBPs) in order to extract the image texture feature with respect to spectrum information diversity (SID) to measure the differences of spectrum information. The classifier adopted in this work is support vector machine (SVM) because of its outstanding classification performances. In this paper, two real hyperspectral image datasets are used for testing the performance of the proposed method. Our experimental results from real hyperspectral images indicate that the proposed framework can enhance the classification accuracy compare to traditional alternatives.
C1 [Wang, Cai-ling] Xian Shiyou Univ, Sch Comp Sci, Xian 710065, Shaanxi, Peoples R China.
   [Ren, Jinchang; Zhang, Yinyong] Univ Strathclyde, Dept Elect & Elect Engn, Glasgow, Lanark, Scotland.
   [Wang, Hong-wei] Engn Univ CAPF, Xian 710086, Shaanxi, Peoples R China.
   [Wen, Jia] Tianjin Polytech Univ, Sch Elect Engn, Tianjin 300387, Peoples R China.
C3 Xi'an Shiyou University; University of Strathclyde; Tiangong University
RP Wang, CL (corresponding author), Xian Shiyou Univ, Sch Comp Sci, Xian 710065, Shaanxi, Peoples R China.
EM azering@163.com
OI Ren, Jinchang/0000-0001-6116-3194
FU National Natural Science foundations of China [41301382, 61401439,
   41604113, 41711530128]; foundation of Key lab of spectral imaging, Xi'an
   Institute of Optics and Precision Mechanics of CAS
FX This work was supported in part by National Natural Science foundations
   of China (Grant Nos. 41301382, 61401439, 41604113, 41711530128) and
   foundation of Key lab of spectral imaging, Xi'an Institute of Optics and
   Precision Mechanics of CAS.
CR [Anonymous], TEXTURE BASED CLASSI
   [Anonymous], REMOTE SENSING DIGIT
   [Anonymous], 2015, IEEE T GEOSC REMOTE
   Bandos TV, 2009, IEEE T GEOSCI REMOTE, V47, P862, DOI 10.1109/TGRS.2008.2005729
   Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Chang CI, 2000, IEEE T INFORM THEORY, V46, P1927, DOI 10.1109/18.857802
   Chen C, 2014, IEEE J-STARS, V7, P1047, DOI 10.1109/JSTARS.2013.2295610
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   DIZENZO S, 1987, IEEE T GEOSCI REMOTE, V25, P815, DOI 10.1109/TGRS.1987.289753
   Doshi NP, 2015, IEEE SYS MAN CYBERN, P2283, DOI 10.1109/SMC.2015.399
   Fang LY, 2015, IEEE T GEOSCI REMOTE, V53, P6663, DOI 10.1109/TGRS.2015.2445767
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Gu YF, 2012, IEEE T GEOSCI REMOTE, V50, P2852, DOI 10.1109/TGRS.2011.2176341
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Guo Y, 2017, IEEE INT CONF SOFTW, P1, DOI 10.1109/ICST.2017.8
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P4816, DOI 10.1109/TGRS.2012.2230268
   Li W, 2012, IEEE T GEOSCI REMOTE, V50, P1185, DOI 10.1109/TGRS.2011.2165957
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Ma L, 2010, IEEE T GEOSCI REMOTE, V48, P4099, DOI 10.1109/TGRS.2010.2055876
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Stathakis D, 2006, IEEE T GEOSCI REMOTE, V44, P2305, DOI 10.1109/TGRS.2006.872903
   Tuia D, 2010, IEEE T GEOSCI REMOTE, V48, P3780, DOI 10.1109/TGRS.2010.2049496
   Vijaya Kumarau V., 2015, INT J APPL ENG RES I, V10, P4373
NR 26
TC 4
Z9 4
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29889
EP 29903
DI 10.1007/s11042-018-5928-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800040
DA 2024-07-18
ER

PT J
AU Zhang, XR
   Pan, ZB
   Lu, XQ
   Hu, BL
   Zheng, X
AF Zhang, Xiaorong
   Pan, Zhibin
   Lu, Xiaoqiang
   Hu, Bingliang
   Zheng, Xi
TI Hyperspectral image classification based on joint spectrum of spatial
   space and spectral space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Hyperspectral imagery; Spectral-spatial fusion; Affine
   transform; Feature extraction; Probabilistic fusion
ID FEATURE-EXTRACTION; BAND SELECTION; SALIENCY; KERNEL
AB This paper presents a novel feature extraction model that incorporates local histogram in spatial space and pixel spectrum in spectral space, with the goal of hyperspectral image classification. We named this joint spectrum as 3D spectrum. Moreover, as a preprocessing step, an iterative procedure, which exploits spectral information in such a way that it considers corrupted bands existing in the data cube, is applied to original hyperspectral image. Further, Affine transform is applied to the bands chosen by the aforementioned procedure. The final feature is extracted by affine transform and 3D spectrum model, and as an input of widely used classifier of Support Vector Machine. As a post-processing step, multiple iterative results are fused in the level of probability. Our experimental results indicate that the proposed methodology leads to state-of-the-art classification results when combined with probabilistic classifiers for several widely used hyperspectral data sets, even when very only limited training samples are available.
C1 [Zhang, Xiaorong; Pan, Zhibin] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Zhang, Xiaorong] Univ Chinese Acad Sci, Beijing 100039, Peoples R China.
   [Zhang, Xiaorong; Lu, Xiaoqiang; Hu, Bingliang] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
   [Zheng, Xi] Chinese Acad Sci, Inst Earth Environm, Xian 710016, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS; Chinese Academy of Sciences; Xi'an
   Institute of Optics & Precision Mechanics, CAS; Chinese Academy of
   Sciences; Institute of Earth Environment, CAS
RP Zhang, XR (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.; Zhang, XR (corresponding author), Univ Chinese Acad Sci, Beijing 100039, Peoples R China.; Zhang, XR (corresponding author), Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Shaanxi, Peoples R China.
EM zhangxiaorong@opt.ac.cn; zbpan@xjtu.edu.cn; luxq666666@gmail.com;
   hbl@opt.ac.cn; unique_sissizheng@163.com
RI Pan, Zhibin/I-8212-2012
FU National Natural Science Foundation of China (NSFC) [61501456,
   XAB2016B20]
FX This research has been partially supported by National Natural Science
   Foundation of China (NSFC) (61501456) and "Light of West China"
   (XAB2016B20).
CR Benediktsson JA, 2005, IEEE T GEOSCI REMOTE, V43, P480, DOI 10.1109/TGRS.2004.842478
   Bioucas-Dias JM, 2012, IEEE J-STARS, V5, P354, DOI 10.1109/JSTARS.2012.2194696
   Cahill ND, 2014, SPIE DEFENSE SECURIT, V9088
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Cao XH, 2016, INT J REMOTE SENS, V37, P4501, DOI 10.1080/01431161.2016.1214301
   Chang CI, 2006, HYPERSPECTRAL DATA E, P47
   Chen C, 2014, REMOTE SENS-BASEL, V6, P5795, DOI 10.3390/rs6065795
   Cheng G, 2017, P IEEE, V105, P1865, DOI 10.1109/JPROC.2017.2675998
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Dalla Mura M, 2010, INT J REMOTE SENS, V31, P5975, DOI 10.1080/01431161.2010.512425
   Demirci S, 2015, SPIE SENSING TECHNOL, V9482
   Ding GG, 2016, IEEE T IMAGE PROCESS, V25, P5427, DOI 10.1109/TIP.2016.2607421
   Du B, 2014, IEEE T GEOSCI REMOTE, V52, P6844, DOI 10.1109/TGRS.2014.2303895
   Du B, 2014, PATTERN RECOGN, V47, P344, DOI 10.1016/j.patcog.2013.07.005
   Fauvel M, 2013, PATTERN RECOGN, V46, P845, DOI 10.1016/j.patcog.2012.09.009
   Fauvel M, 2015, IEEE J-STARS, V8, P2824, DOI 10.1109/JSTARS.2015.2441771
   Gharaati E, 2015, NEW BAND SELECTION M, P1
   Ghedass F, 2015, IMPROVED CLASSIFICAT
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Han JW, 2015, IEEE T GEOSCI REMOTE, V53, P3325, DOI 10.1109/TGRS.2014.2374218
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Khodadadzadeh M, 2014, IEEE T GEOSCI REMOTE, V52, P6298, DOI 10.1109/TGRS.2013.2296031
   Kianisarkaleh A, 2016, ISPRS J PHOTOGRAMM, V119, P64, DOI 10.1016/j.isprsjprs.2016.05.009
   Landgrebe D, 2017, AVIRIS NW INDIANAS I
   Li F, 2015, IEEE J-STARS, V8, P2427, DOI 10.1109/JSTARS.2015.2414816
   Li J, 2016, IEEE J-STARS, V9, P625, DOI 10.1109/JSTARS.2015.2470129
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P4816, DOI 10.1109/TGRS.2012.2230268
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Lu XQ, 2017, IEEE T GEOSCI REMOTE, V55, P5148, DOI 10.1109/TGRS.2017.2702596
   Lu XQ, 2015, IEEE T CYBERNETICS, V45, P1967, DOI 10.1109/TCYB.2014.2362959
   Lu XQ, 2013, IEEE T GEOSCI REMOTE, V51, P4009, DOI 10.1109/TGRS.2012.2226730
   Lu XQ, 2013, IEEE T NEUR NET LEAR, V24, P929, DOI 10.1109/TNNLS.2013.2245914
   Prasad S, 2016, CORR
   Sellami A, 2016, SPAT STAT-NETH, V16, P103, DOI 10.1016/j.spasta.2016.02.003
   Soltani-Farani A, 2015, IEEE T GEOSCI REMOTE, V53, P527, DOI 10.1109/TGRS.2014.2325067
   Sun K, 2014, IEEE J-STARS, V7, P2697, DOI 10.1109/JSTARS.2014.2320299
   Xia JS, 2015, IEEE T GEOSCI REMOTE, V53, P2532, DOI 10.1109/TGRS.2014.2361618
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yao XW, 2016, IEEE T GEOSCI REMOTE, V54, P3660, DOI 10.1109/TGRS.2016.2523563
   Yao XW, 2015, NEUROCOMPUTING, V164, P162, DOI 10.1016/j.neucom.2015.02.073
   Yu H, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8030259
   Yuan JY, 2015, IEEE T IMAGE PROCESS, V24, P3488, DOI 10.1109/TIP.2015.2446948
   Zhong P, 2017, IEEE T GEOSCI REMOTE, V55, P3516, DOI 10.1109/TGRS.2017.2675902
NR 43
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29759
EP 29777
DI 10.1007/s11042-017-5552-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800033
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Hu, CH
   Lu, XB
AF Zhang, Yang
   Hu, Changhui
   Lu, Xiaobo
TI Face recognition under varying illumination based on singular value
   decomposition and retina modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Illumination preprocessing; Singular value
   decomposition; Illumination normalization; High-and low-frequency
   features
ID OPTIMIZATION; NORMALIZATION; COMPENSATION; IMAGE; POSE
AB Face recognition under the influence of complex illumination is a challenging problem to be solved. The common treatments for minimizing the affection of illumination variation are illumination preprocessing and illumination insensitive extraction techniques. However, the methods proposed previously present low performances. To realize high-accuracy recognition under varying illumination, this paper proposes a novel illumination processing algorithm called REC&SIG-SVD algorithm. Above all, singular value decomposition (SVD) is utilized to obtain preliminary high-frequency and low-frequency features of the face image in logarithm domain. This study proposes Sigmoid function which satisfies the principle of diminishing marginal utility to normalize singular values, aiming at calculating effective high-frequency features. Furthermore, this paper proposes a novel illumination normalization method to process low-frequency features, which is based on retina modeling cooperate with an advanced contrast limited adaptive histogram equalization (CLAHE). Meanwhile, enhancement on high-frequency features is realized by threshold-value filtering. Last but not least, the normalized high-frequency and enhanced low-frequency features are reassembled to form the normalized face image. The comparative trials based on Yale B and CMU PIE databases are conducted for our algorithm and other similar techniques as well as deep learning methods. The experimental results demonstrate that REC&SIG-SVD algorithm shows outstanding recognition performance.
C1 [Zhang, Yang; Hu, Changhui; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Zhang, Yang; Hu, Changhui; Lu, Xiaobo] Southeast Univ, Key Lab Measurement & Control CSE, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
   [Hu, Changhui] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China; Nanjing
   University of Posts & Telecommunications
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Key Lab Measurement & Control CSE, Minist Educ, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
RI Hu, Chang-Hui/AAD-8822-2020
FU National Natural Science Foundation of China [61374194]; National Key
   Science and Technology Pillar Program of China [2014BAG01DB03]; Key
   Research and Development Program of Jiangsu Province [BE2016739]
FX We would like to thank the National Natural Science Foundation of China
   (No. 61374194), National Key Science and Technology Pillar Program of
   China (No. 2014BAG01DB03) and Key Research and Development Program of
   Jiangsu Province (No. BE2016739) for funding.
CR ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], 2010, COMPUTER KNOWLEDGE T
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], P IEEE INT WORKSH AN
   [Anonymous], NEAREST NEIGHBOR NN
   [Anonymous], LOCAL SUBSPACE CLASS
   [Anonymous], 2012, P 29 INT C MACH LEAR
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], P IEEE INT C WORKSH
   [Anonymous], 2012, P 29 INT COFERENCE I
   [Anonymous], P IEEE C COMP VIS PA
   Cao X, 2012, PATTERN RECOGN, V45, P1299, DOI 10.1016/j.patcog.2011.09.010
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Choi SI, 2007, PATTERN RECOGN, V40, P2118, DOI 10.1016/j.patcog.2006.11.020
   Demirel H, 2008, IEEE SIGNAL PROC LET, V15, P537, DOI 10.1109/LSP.2008.926729
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gonzales R.C., 2002, Digital image processing
   Gu L, 2013, IEEE T IMAGE PROCESS, V22, P3648, DOI 10.1109/TIP.2013.2268970
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu CH, 2015, MULTIMED TOOLS APPL, V74, P10313, DOI 10.1007/s11042-014-2168-y
   Hu CH, 2017, PATTERN RECOGN, V64, P60, DOI 10.1016/j.patcog.2016.10.029
   Kim W, 2014, IEEE SIGNAL PROC LET, V21, P1336, DOI 10.1109/LSP.2014.2334656
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu HD, 2014, IMAGE VISION COMPUT, V32, P335, DOI 10.1016/j.imavis.2014.02.010
   Ochoa-Villegas MA, 2015, IET COMPUT VIS, V9, P978, DOI 10.1049/iet-cvi.2014.0086
   Shah Zainudin M.N., 2012, International Journal of Electrical Computer Sciences, V12, P50
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wang JW, 2011, IEEE SIGNAL PROC LET, V18, P567, DOI 10.1109/LSP.2011.2163798
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang TP, 2009, PATTERN RECOGN, V42, P251, DOI 10.1016/j.patcog.2008.03.017
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhao WY, 2001, INT J COMPUT VISION, V45, P55, DOI 10.1023/A:1012369907247
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhou Y, 2016, J SUPERCOMPUT, V72, P2394, DOI 10.1007/s11227-016-1738-3
NR 43
TC 4
Z9 4
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28355
EP 28374
DI 10.1007/s11042-018-6044-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500025
DA 2024-07-18
ER

PT J
AU Zhao, GP
   Liu, JJ
   Jiang, JC
   Wang, WY
AF Zhao, Guoping
   Liu, Jiajun
   Jiang, Jiacheng
   Wang, Weiying
TI A deep cascade of neural networks for image inpainting, deblurring and
   denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inpainting; Deblurring; Denoising; Wasserstein GAN; Auto-encoder
ID SPARSE; REPRESENTATIONS
AB In recent years, we have witnessed the great success of deep learning on various problems both in low and high-level computer visions. The low-level vision problems, including inpainting, deblurring, denoising, super-resolution, and so on, are highly anticipated to occur in machine vision and image processing. Many deep learning based methods have been proposed to solve low-level vision problems. Most researches treat these problems independently; however, most of the time they appear concurrently. Motivated by the success of generative model in the field of image generation, we develop a deep cascade of neural networks to solve the inpainting, deblurring, denoising problems at the same time. Our model contains two networks: inpainting GAN and deblurring-denoising network. Inpainting GAN generates the coarse patches to fill the lost part in damaged image, and the deblurring-denoising network, stacked by a convolutional auto-encoder, will further refine them. Unlike other methods that handle each problem separately, our method jointly optimizes the two sub-networks. Because GAN training is not only unstable but also difficult, we adopt the Wasserstein distance as the loss function of the inpainting GAN and propose a gradual training strategy. Learning from the idea of residual learning, we utilize skip connections to pass image details from input to reconstruction layer. Experimental results have demonstrated that the proposed model can achieve state-of-the-art performance. Through the experiments, we also demonstrated the effectiveness of the cascade architecture.
C1 [Zhao, Guoping; Liu, Jiajun; Jiang, Jiacheng] Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
   [Wang, Weiying] Miami Univ, Dept Comp Sci & Software Engn, Oxford, OH 45056 USA.
C3 Renmin University of China; University System of Ohio; Miami University
RP Zhao, GP (corresponding author), Renmin Univ China, Sch Informat, Beijing 100872, Peoples R China.
EM guopingzhao@ruc.edu.cn; jiajunliu@ruc.edu.cn; jiachengjiang@ruc.edu.cn;
   wangw17@miamioh.edu
RI liu, jiajia/IUN-0901-2023; liu, jia/HKE-9796-2023; liu,
   jiajia/ISS-0316-2023; liu, peng/JSL-1931-2023; liu, jia/JAC-7852-2023;
   Li, Wenjuan/KDN-8450-2024; liu, jiayu/JCP-0511-2023; Yu,
   Kun/IAP-9807-2023; Liu, Jiayu/JCO-5073-2023; li, jiawei/HOA-5023-2023;
   Li, JW/HNC-1743-2023
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], 2017, CoRR
   [Anonymous], 2016, CVPR
   [Anonymous], 2016, P INT C LEARNING REP
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Beck A, 2009, IEEE T IMAGE PROCESS, V18, P2419, DOI 10.1109/TIP.2009.2028250
   Bengio Y., 2013, ADV NEURAL INFORM PR
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Cai JF, 2009, PROC CVPR IEEE, P104, DOI 10.1109/CVPRW.2009.5206743
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dong Weisheng, 2011, IEEE Trans Image Process, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gharbi M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982399
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Ji H, 2012, IEEE T IMAGE PROCESS, V21, P1624, DOI 10.1109/TIP.2011.2171699
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Le Meur O, 2013, IEEE T IMAGE PROCESS, V22, P3779, DOI 10.1109/TIP.2013.2261308
   Liu D, 2007, IEEE T CIRC SYST VID, V17, P1273, DOI 10.1109/TCSVT.2007.903663
   Liu JJ, 2016, NEUROCOMPUTING, V195, P112, DOI 10.1016/j.neucom.2015.09.119
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shang S, 2016, NEUROCOMPUTING, V213, P147, DOI 10.1016/j.neucom.2016.02.085
   Shang S, 2016, NEUROCOMPUTING, V173, P118, DOI 10.1016/j.neucom.2015.06.086
   Shang S, 2015, NEUROCOMPUTING, V169, P50, DOI 10.1016/j.neucom.2014.08.105
   Shao L, 2014, IEEE T CYBERNETICS, V44, P1001, DOI 10.1109/TCYB.2013.2278548
   Simonyan K., 2014, 14091556 ARXIV
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Vondrick C, 2016, 30 C NEURAL INFORM P, V29
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Yang C., 2017, P IEEE C COMP VIS PA, P6721, DOI DOI 10.1109/CVPR.2017.434
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhu SZ, 2017, NEUROCOMPUTING, V253, P49, DOI 10.1016/j.neucom.2016.08.138
NR 44
TC 11
Z9 14
U1 1
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29589
EP 29604
DI 10.1007/s11042-017-5320-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800022
DA 2024-07-18
ER

PT J
AU Erra, U
   Scanniello, G
   Colonnese, V
AF Erra, Ugo
   Scanniello, Giuseppe
   Colonnese, Valerio
TI Exploring the effectiveness of an augmented reality dressing room
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Human body tracking; Dressing room
ID MODEL
AB In this paper, we describe our experience with the design of an augmented reality dressing room in which 3D models of a dress are overlaid with a color image from a camera to provide the function of a sort of virtual mirror. In such a way, the customer can move around to understand if a dress suits and fits them well. The project is implemented in Unity 4 Pro in combination with the Microsoft Kinect 2 for the tracking process. Design issues and technical implementation as well as the prospects for further development of the techniques are discussed. To assess the validity of our proposal, we have conducted a user study using 47 participants with different levels of experience with video games and devices used to play them. The empirical method used is qualitative. To this end, we used questionnaire-based surveys. The obtained results suggest that our solution represents a viable means to simulate dressing rooms, and participants in the study found the interaction with our 3D models to be natural for understanding if a dress suits and fits them well. Overall, the participants found our application very useful from a practical point of view.
C1 [Erra, Ugo; Scanniello, Giuseppe; Colonnese, Valerio] Univ Basilicata, Dipartimento Matemat Informat & Econ, Potenza, Italy.
C3 University of Basilicata
RP Erra, U (corresponding author), Univ Basilicata, Dipartimento Matemat Informat & Econ, Potenza, Italy.
EM ugo.erra@unibas.it; giuseppe.scanniello@unibas.it;
   valerio.colonnese@unibas.it
RI Erra, Ugo/X-3889-2019
OI Erra, Ugo/0000-0003-2942-7131; Scanniello, Giuseppe/0000-0003-0024-7508
CR Ahn T, 2007, INFORM MANAGE-AMSTER, V44, P263, DOI 10.1016/j.im.2006.12.008
   [Anonymous], 2016, UN GAM ENG
   [Anonymous], 2000, QUESTIONNAIRE DESIGN
   Araki N., 2008, 2008 3 INT C DIG INF, P33
   Berger K, 2013, SENSORS ALGORITHMS A, P257
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Cordero R., 2010, CAN TECHNOLOGY HELP
   Developer W, 2016, TRACKING USERS KINEC
   Developer W, 2016, KINECT SDK 2 0
   Developer W, 2016, KINECT WINDOWS FEATU
   Erra U, 2015, LECT NOTES COMPUT SC, V9254, P467, DOI 10.1007/978-3-319-22888-4_35
   Greuter S., 2014, P 2014 C INT ENT
   Holte MB, 2013, SYST APPL 5 INT C 2, P241
   Holte MB, 2015, LECT NOTES COMPUT SC, V9179, P429, DOI 10.1007/978-3-319-21067-4_44
   Isikdogan F, 2012, REAL TIME VIRTUAL DR
   Juristo N., 2013, BASICS SOFTWARE ENG
   Kitchenham BA, 2002, IEEE T SOFTWARE ENG, V28, P721, DOI 10.1109/TSE.2002.1027796
   Kjaerside K, 2005, CENTR EUR MULT VIRT
   Lin YL, 2016, MULTIMED TOOLS APPL, V75, P7575, DOI 10.1007/s11042-015-2681-7
   Magnenat-Thalmann, 1988, Proceedings of Graphics Interface '88, P26
   Martin C. G., 2012, J SIGNAL INF PROCESS, V3, P481, DOI DOI 10.4236/JSIP.2012.34061
   Michael N, 2017, MULTIMED TOOLS APPL, V76, P14169, DOI 10.1007/s11042-016-3808-1
   Parent R., 2012, Computer animation: algorithms and techniques
   Presle P., 2012, A Virtual Dressing Room based on Depth Data
   Sands Walker., 2015, Reinventing retail: what businesses need to know for 2015 whitepaper
   Shaikh AA., 2014, Int. J. Soft Comput. Eng.(IJSCE), V4, P98
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Szymczyk M, 2011, US Patent App, Patent No. [12/822,168, 12822168]
   Wang RM, 2014, MULTIMED TOOLS APPL, V71, P395, DOI 10.1007/s11042-013-1519-4
   Wohlin C., 2012, Experimentation in Software Engineering
   Zugara, 2009, CAN TECHN HELP FASH
NR 31
TC 13
Z9 17
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25077
EP 25107
DI 10.1007/s11042-018-5758-2
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400022
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kansal, S
   Purwar, S
   Tripathi, RK
AF Kansal, Shubhi
   Purwar, Shikha
   Tripathi, Rajiv Kumar
TI Image contrast enhancement using unsharp masking and histogram
   equalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsharp masking; Sharpening; Clipping
AB Contrast enhancement and Mean brightness conservation are two important parameters of image enhancement. A high contrast image is good in subjective quality assessment but also high contrast may cause over or under enhancement in the enhanced image. In this paper a new unsharp mask filtering technique with the combination of histogram equalization is used for the general-purpose images which maximizes the entropy of the image as well as controls the over and under enhancement by clipping the histogram of the image. After rigorous experimentation on standard data-set, it is observed that the information present in the image is highest in the proposed method i.e. the entropy value is highest and the mean brightness is also comparable with the other histogram based image enhancement methods. Mean opinion score(MOS) result shows that visual quality of the image is also better than existing methods.
C1 [Kansal, Shubhi; Purwar, Shikha; Tripathi, Rajiv Kumar] Natl Inst Technol, Delhi 110040, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi
RP Kansal, S (corresponding author), Natl Inst Technol, Delhi 110040, India.
EM kansalshubhi@yahoo.com
RI tripathi, rajiv/F-1353-2018
OI tripathi, rajiv/0000-0002-1036-046X; purwar, shikha/0000-0001-5362-1669;
   kansal, shubhi/0000-0001-8917-6843
FU Dept. of Electronics and Communication Engineering, NIT Delhi
FX This work was supported by Dept. of Electronics and Communication
   Engineering, NIT Delhi
CR Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Kaur M, 2011, INT J ADV COMPUT SC, V2, P137
   Kim M, 2008, IEEE T CONSUM ELECTR, V54, P1389, DOI 10.1109/TCE.2008.4637632
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Kotera H, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1866147
   Moon T.K., 2000, Mathematical Methods and Algorithms for Signal Processing
   Nithyananda CR, 2016, IEEE INT C DAT MIN A
   Parihar AS, 2016, IET IMAGE PROCESS, V10, P799, DOI 10.1049/iet-ipr.2016.0242
   Ramponi G, 1998, J ELECTRON IMAGING, V7, P333, DOI 10.1117/1.482649
   Ritika Kaur S, 2013, INT J COMPUT APPL, V64, P20
   Sim KS, 2007, PATTERN RECOGN LETT, V28, P1209, DOI 10.1016/j.patrec.2007.02.003
   Singh K, 2015, OPTIK, V126, P2619, DOI 10.1016/j.ijleo.2015.06.060
   Singh K, 2014, OPTIK, V125, P4646, DOI 10.1016/j.ijleo.2014.04.093
   Singh K, 2014, PATTERN RECOGN LETT, V36, P10, DOI 10.1016/j.patrec.2013.08.024
   Spring K, 2016, INTERACTIVE TUTORIAL
   Sridhar S., 2011, Digital Image Processing'
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   ZIMMERMAN JB, 1988, IEEE T MED IMAGING, V7, P304, DOI 10.1109/42.14513
NR 21
TC 47
Z9 50
U1 1
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26919
EP 26938
DI 10.1007/s11042-018-5894-8
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500031
DA 2024-07-18
ER

PT J
AU Talebi, M
   Vafaei, A
   Monadjemi, A
AF Talebi, Mehdi
   Vafaei, Abbas
   Monadjemi, Amirhassan
TI Vision-based entrance detection in outdoor scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entrance detection; Lines extraction; Color; Texture; Image processing
ID APPEARANCE
AB Doors are a significant object for the visually impaired and robots to enter and exit buildings. Although the accuracy of door detection is reported high in indoor scenes, it has become a difficult problem in outdoor scenes in computer vision. The reason may lie in the fact that such properties of a simple ordinary door such as handles, corners, and the gap between the door and the ground may not be visible due to the great variety of doors in outdoor environments. In this paper, we present a vision-based method for detecting building entrances in outdoor images. After extracting the lines and deleting the extra ones, regions between the vertical lines are specified and the features including height, width, location, color, texture and the number of lines inside the regions are obtained. Finally, some additional knowledge such as door existence at the bottom of the image, a reasonable height and width of a door, the difference between color and texture of the doors and those of the neighboring regions, and numerous lines on doors is used to decide on door detection. The method was tested on the eTRIMS dataset, door images from the ImageNet dataset, and our own dataset including doors of houses, apartments, and stores leading to acceptable results. The obtained results show that our approach outperforms comparable state-of-the-art approaches.
C1 [Talebi, Mehdi; Vafaei, Abbas; Monadjemi, Amirhassan] Univ Isfahan, Fac Comp Engn, Esfahan 81746, Iran.
C3 University of Isfahan
RP Vafaei, A (corresponding author), Univ Isfahan, Fac Comp Engn, Esfahan 81746, Iran.
EM mtalebi@eng.ui.ac.ir; abbas_vafaei@eng.ui.ac.ir; monadjemi@eng.ui.ac.ir
RI Talebi, Mehdi/AAR-5282-2021; Talebi, Mehdi/AHD-9942-2022
OI Talebi, Mehdi/0000-0002-3688-4982; Vafaei, Abbas/0000-0001-6535-1272
CR Anguelov D, 2004, IEEE INT CONF ROBOT, P3777, DOI 10.1109/ROBOT.2004.1308857
   [Anonymous], 2009, Technical report
   [Anonymous], 2017, ARXIV 1704 06857
   [Anonymous], P INT C RES ED ROB
   Chen ZC, 2011, ROBOT AUTON SYST, V59, P966, DOI 10.1016/j.robot.2011.06.013
   Cohen A, 2014, PROC CVPR IEEE, P3206, DOI 10.1109/CVPR.2014.410
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gould S, 2014, COMMUN ACM, V57, P68, DOI 10.1145/2629637
   He ZY, 2009, SIGNAL PROCESS, V89, P1501, DOI 10.1016/j.sigpro.2009.01.021
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Kang SJ, 2010, LECT NOTES ARTIF INT, V5990, P251, DOI 10.1007/978-3-642-12145-6_26
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu J., 2014, P 27 IEEE C COMPUTER
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mathias M, 2016, INT J COMPUT VISION, V118, P22, DOI 10.1007/s11263-015-0868-z
   Murillo AC, 2008, ROBOT AUTON SYST, V56, P512, DOI 10.1016/j.robot.2008.03.003
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sekkal R, 2013, IEEE IMAGE PROC, P3929, DOI 10.1109/ICIP.2013.6738809
   Shuai B, 2016, IEEE T IMAGE PROCESS, V25, P2379, DOI 10.1109/TIP.2016.2533862
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Teboul O., 2010, Ecole centrale paris facades database
   Teboul O, 2013, IEEE T PATTERN ANAL, V35, P1744, DOI 10.1109/TPAMI.2012.252
   Tighe J, 2015, INT J COMPUT VISION, V112, P150, DOI 10.1007/s11263-014-0778-5
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Yang MY, 2011, LECT NOTES COMPUT SC, V6952, P209, DOI 10.1007/978-3-642-24393-6_18
   Zhang D, 2009, INT J PATTERN RECOGN, V23, P521, DOI 10.1142/S0218001409007260
NR 32
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26219
EP 26238
DI 10.1007/s11042-018-5846-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500003
DA 2024-07-18
ER

PT J
AU Wang, RG
   Wang, QH
   Yang, J
   Xue, LX
   Hu, M
AF Wang, Ronggui
   Wang, Qinghui
   Yang, Juan
   Xue, Lixia
   Hu, Min
TI Super-resolution via supervised classification and independent
   dictionary training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Independent dictionary training; Decision tree; Mapping function;
   Super-resolution; Sparse coding
ID SINGLE-IMAGE SUPERRESOLUTION; KERNEL REGRESSION; ALGORITHM
AB Super-resolution (SR) reconstruction plays an important role in recovering the image details and improving the visual perception. In this paper, we propose a new and effective method based on the idea of classification reconstruction and independent dictionary training. Firstly, we extract some geometric features of images and design a new supervised classification method, which uses the decision tree to guarantee a better classification result. Secondly, the coefficients of the high-resolution (HR) and low-resolution (LR) patches are not equal strictly in fact, which enlighten us to train the HR and LR dictionaries independently. And then mapping matrices are learned to map LR coefficients into HR coefficients, which can not only help us improve reconstruction quality, but also just perform sparse coding one time in the reconstruction stage. At last, we enforce a global optimization on the initial reconstruction HR image based on the non-local means and the auto-regressive model. The experiments show that the method we proposed works better than other classic state-of-the-art methods.
C1 [Wang, Ronggui; Wang, Qinghui; Yang, Juan; Xue, Lixia; Hu, Min] Hefei Univ Technol, Coll Comp & Informat, Hefei 230009, Anhui, Peoples R China.
C3 Hefei University of Technology
RP Yang, J (corresponding author), Hefei Univ Technol, Coll Comp & Informat, Hefei 230009, Anhui, Peoples R China.
EM wangrgui@foxmail.com; 1649759610@qq.com; yangjuan6985@163.com;
   xlxzzm@163.com; jsjhumin@hfut.edu.cn
RI Hu, Min/HLH-2112-2023; Lin, Kuan-Yu/JXM-6653-2024
FU National Natural Science Foundation of China [61672202]
FX This work is partly supported by the National Natural Science Foundation
   of China under Project code (61672202).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   Ducournau A, 2016, IAPR WORKS PATTERN
   EDELMAN A, 1988, SIAM J MATRIX ANAL A, V9, P543, DOI 10.1137/0609045
   Feng XG, 2003, P 36 AS C SIGN SYST, P478
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Huang J, 2010, NEUROCOMPUTING, V73, P883, DOI 10.1016/j.neucom.2009.09.016
   Jiang HQ, 2015, IEEE T MULTIMEDIA, V17, P3, DOI 10.1109/TMM.2014.2368273
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Jiang JJ, 2016, INFORM SCIENCES, V367, P354, DOI 10.1016/j.ins.2016.05.032
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu H, 2018, NEUROCOMPUTING, V282, P52, DOI 10.1016/j.neucom.2017.12.014
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Rubinstein R, 2008, Tech. rep.
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Uiboupin T, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P437, DOI 10.1109/SIU.2016.7495771
   Wang LZ, 2015, IEEE GEOSCI REMOTE S, V12, P736, DOI 10.1109/LGRS.2014.2360457
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang ZY, 2015, IEEE T IMAGE PROCESS, V24, P4359, DOI 10.1109/TIP.2015.2462113
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xu J, 2014, IEEE IMAGE PROC, P3910, DOI 10.1109/ICIP.2014.7025794
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang S., 2011, Multi-Platform/Multi-Sensor Remote Sensing and Mapping (M2RSM), 2011 International Workshop on, P1, DOI [10.1109/M2RSM.2011.5697375, DOI 10.1109/M2RSM.2011.5697375]
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Yang SY, 2011, NEUROCOMPUTING, V74, P3193, DOI 10.1016/j.neucom.2011.04.014
   Yang W, 2016, IEEE T MULTIMEDIA, V18, P1
   Yang XH, 2016, OXID MED CELL LONGEV, V2016, DOI 10.1155/2016/2968462
   Yuan T, 2014, IEEE INT C AC SPEECH, P5794
   Yun-Heng Wang, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P106, DOI 10.1109/IIH-MSP.2012.31
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2013, IEEE IMAGE PROC, P943, DOI 10.1109/ICIP.2013.6738195
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 50
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27709
EP 27732
DI 10.1007/s11042-018-5950-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500065
DA 2024-07-18
ER

PT J
AU Yang, CG
   Wang, ZR
   He, W
   Li, ZJ
AF Yang, Chenguang
   Wang, Zunran
   He, Wei
   Li, Zhijun
TI Development of a fast transmission method for 3D point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point cloud; Point cloud transmission; Point cloud filter; Point
   cloud compression; Point cloud segmentation; Human face detection; Nose
   tip detection
ID PARALLEL FRAMEWORK; IMAGES
AB In this paper, a transmission method of the 3D point cloud data of the object upper body is proposed. The key idea of the method is to reduce the amount of transmission data in the condition of retaining the necessary information. In our system, the unnecessary information is removed by using filters and the segmentation algorithm. Three P frames (Predicted frame) are inserted between two I frames (Intra frame) to further improve the transmission rate. The I frame of large size includes all the vision information that is related to the object upper body, while the P frame includes only the information of the small change in the current frame, whose size is smaller than the former. In order to acquire the information of the P frame, first, a human face detection algorithm based on the machine learning technology is implemented. Then, a coarse-to-fine approach is used to detect the nose tip which helps to improve the precision of acquiring the human faces information. The experiment result demonstrates that the proposed method is able to reduce the time delay of processing and transmission and to lower the compression ratio with an allowable distortion rate.
C1 [Yang, Chenguang; Wang, Zunran; Li, Zhijun] South China Univ Technol, Coll Automat Sci & Engn, Key Lab Autonomous Syst & Networked Control, Guangzhou, Guangdong, Peoples R China.
   [He, Wei] Univ Sci & Technol Beijing, Sch Automat & Elect Engn, Beijing, Peoples R China.
C3 South China University of Technology; University of Science & Technology
   Beijing
RP Yang, CG (corresponding author), South China Univ Technol, Coll Automat Sci & Engn, Key Lab Autonomous Syst & Networked Control, Guangzhou, Guangdong, Peoples R China.
EM cyang@ieee.org
RI Yang, Chenguang/AAJ-2509-2020
OI Yang, Chenguang/0000-0001-5255-5559
CR [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 2013, Proceedings of High Performance Graphics (HPG)
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], RES INNOVATION SCHOL
   [Anonymous], COMPUTER GRAPHICS FO
   [Anonymous], P 21 ACM INT C MULT
   [Anonymous], INT SOC OPTICS PHOTO
   [Anonymous], 2010, Image Rochester NY
   [Anonymous], 2002, 2002 P INT C IM PROC
   [Anonymous], IEEE INT C ROB AUT I
   Bhimani J, 2017, IEEE HIGH PERF EXTR
   Bhimani J, 2017, IEEE IPCCC
   Brahimi T, 2016, MULTIMED TOOL APPL, P1
   Chum O., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P623
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Han SR, 2007, IEEE T CIRC SYST VID, V17, P1506, DOI 10.1109/TCSVT.2007.903810
   He W, 2017, IEEE T CYBERNETICS, V47, P3452, DOI 10.1109/TCYB.2017.2720801
   He W, 2017, IEEE T SYST MAN CY-S, V47, P45, DOI 10.1109/TSMC.2016.2557227
   Huang HC, 2000, PROC SPIE, V3957, P102, DOI 10.1117/12.384434
   Kim KT, 1998, P SOC PHOTO-OPT INS, V3295, P76, DOI 10.1117/12.307195
   KOST B, 1990, P SOC PHOTO-OPT INS, V1256, P280, DOI 10.1117/12.19916
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Lv TJ, 2017, IEEE ICC
   Menzies RJ, 2016, VIRTUAL REAL-LONDON, V20, P173, DOI 10.1007/s10055-016-0288-6
   Mian A, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P735
   Ohm JR, 1999, PROC SPIE, V3639, P242, DOI 10.1117/12.349385
   Rabie T, 2016, MULTIMED TOOL APPL, P1
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Shi GY, 2017, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE, 2017, VOL 3A
   Siegel M, 1997, P SOC PHOTO-OPT INS, V3012, P227, DOI 10.1117/12.274461
   Strintzis MG, 1999, IEEE SIGNAL PROC MAG, V16, P14, DOI 10.1109/79.768570
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang CG, 2017, IEEE T SYST MAN CY-S, V47, P2125, DOI 10.1109/TSMC.2016.2615061
   Yang CG, 2017, IEEE T SYST MAN CY-S, V47, P2398, DOI 10.1109/TSMC.2017.2676022
   Yu H, 2014, IEEE T HUM-MACH SYST, V44, P386, DOI 10.1109/THMS.2014.2313912
NR 39
TC 15
Z9 17
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25369
EP 25387
DI 10.1007/s11042-018-5789-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400035
DA 2024-07-18
ER

PT J
AU Zia, MS
   Hussain, M
   Jaffar, MA
AF Zia, M. Sultan
   Hussain, Majid
   Jaffar, M. Arfan
TI A novel spontaneous facial expression recognition using dynamically
   weighted majority voting based ensemble classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamically Weighted Majority Voting; Ensemble; Classification;
   Spontaneous; Expression; Incremental Learning
ID SEQUENCES; FEATURES; FUSION; SYSTEM
AB Facial Expression Recognition (FER) is inherently data driven. Spontaneous expressions are substantially different from posed expressions. Spontaneous facial expressions are more challenging and more difficult to recognize. Any facial expression can be represented in many different patterns of muscles movements. Moreover, the facial expressions show discrepancies in different cultures and ethnicities. Therefore, a FER system has to learn a huge problem/feature space. A base classifier trained on a sub-region of feature space, cannot perform equally well in other areas of feature space. Therefore, a base classifier should be assigned higher voting weight in the regions near to its training space and a lower voting weight in the regions far from its training space. In order to maintain high accuracy and robustness of a FER system in space and time, a Dynamic Weight Majority Voting (DWMV) mechanism for base classifiers is introduced. An ensemble system for FER is proposed that has the aptitude of incrementally learning and thus, can learn all possible patterns of expressions that may be generated in feature or in various cultures and ethnicities. Speeded-Up Robust Features (SURF) are used to represent the feature space. Since no work in literature is found on which similarity measure is more appropriate in SURF descriptor domain for facial expression recognition, therefore, different similarity measures are used and the results are compared. A vast range of experimentation is performed on posed and spontaneous databases that demonstrates promising results.
C1 [Zia, M. Sultan; Hussain, Majid] Inst Informat Technol, COMSATS, Dept Comp Sci, Sahiwal, Pakistan.
   [Jaffar, M. Arfan] Gwangju Inst Sci & Technol, Sch Informat & Mechatron, Gwangju, South Korea.
   [Jaffar, M. Arfan] Al Imam Mohammad Ibn Saud Islamic Univ, Riyadh, Saudi Arabia.
C3 COMSATS University Islamabad (CUI); Gwangju Institute of Science &
   Technology (GIST); Imam Mohammad Ibn Saud Islamic University (IMSIU)
RP Zia, MS (corresponding author), Inst Informat Technol, COMSATS, Dept Comp Sci, Sahiwal, Pakistan.
EM ziactn@ciitsahiwal.edu.pk; majidhussain@ciitsahiwal.edu.pk;
   majaffar@imamu.edu.sa
RI Hussain, Majid/JXL-6148-2024; Jaffar, Arfan/GQB-2768-2022
OI Hussain, Majid/0009-0002-5968-0509; 
CR Abboud B, 2004, SIGNAL PROCESS-IMAGE, V19, P723, DOI 10.1016/j.image.2004.05.009
   Aifanti N, 2010, IM AN MULT INT SERV
   Alizadeh S, 2017, CONVOLUTIONAL NEURAL
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2019, UNDERSTANDING FACIAL, DOI DOI 10.1007/978-81-322-1934-7_10
   [Anonymous], 2011, MVA2011 IAPR C MACH
   Bartlett M., 2003, P IEEE C COMP VIS PA
   Bashyal S, 2008, ENG APPL ARTIF INTEL, V21, P1056, DOI 10.1016/j.engappai.2007.11.010
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berretti S, 2011, VISUAL COMPUT, V27, P1021, DOI 10.1007/s00371-011-0611-x
   BETTADAPURA V, 2012, COMPUTER SCI
   Braathen B, 2002, 5 IEEE INT C IEEE
   Bull P, 2001, PSYCHOLOGIST, V14, P644
   Chen P, 2012, INT J PHOTOENERGY, V2012, DOI 10.1155/2012/192380
   Chen XW, 2003, PATTERN RECOGN LETT, V24, P1295, DOI 10.1016/S0167-8655(02)00371-9
   Chin S, 2010, CHIN OPT LETT, V8, P29, DOI 10.3788/COL20100801.0029
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Dubuisson S, 2002, SIGNAL PROCESS-IMAGE, V17, P657, DOI 10.1016/S0923-5965(02)00076-0
   Ekman P., 2009, Telling lies: Clues to deceit in the marketplace, politics, and marriage
   Fang T, 2011, AUT FAC GEST REC WOR
   Fang TH, 2012, IMAGE VISION COMPUT, V30, P738, DOI 10.1016/j.imavis.2012.02.004
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fasel B, 2002, MULTISCALE FACIAL EX
   Filko D, 2013, AUTOMATIKA-UK, V54, P263, DOI 10.7305/automatika.54-2.73
   Gangardiwala A, 2005, NEUR NETW 2005 IJCNN
   Gao YS, 2003, IEEE T SYST MAN CY A, V33, P407, DOI 10.1109/TSMCA.2003.817057
   Guo GD, 2005, IEEE T SYST MAN CY B, V35, P477, DOI 10.1109/TSMCB.2005.846658
   Jabbar S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-32
   Jaimes A., 2006, P 14 ANN ACM INT C M
   Kanade T, 2000, P 4 IEEE INT C IEEE
   Kandemir R, 2013, ISTANB UNIV-J ELECTR, V13, P1667
   Kang B-N., 2014, CONSUMER ELECT ICCE
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lapakko D, 1997, COMMUN EDUC, V46, P63, DOI 10.1080/03634529709379073
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Ma L, 2004, IEEE T SYST MAN CY B, V34, P1588, DOI 10.1109/TSMCB.2004.825930
   Matsugu M, 2003, NEURAL NETWORKS, V16, P555, DOI 10.1016/S0893-6080(03)00115-1
   Mehrabian Albert., 1977, NONVERBAL COMMUNICAT
   Muhlbaier MD, 2009, IEEE T NEURAL NETWOR, V20, P152, DOI 10.1109/TNN.2008.2008326
   Owusu E, 2014, EXPERT SYST APPL, V41, P3383, DOI 10.1016/j.eswa.2013.11.041
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Pramerdorfer C, 2016, ARXIV
   Samad R, 2011, ARTIF LIFE ROBOT, V16, P21, DOI 10.1007/s10015-011-0871-6
   Sangineto E, 2013, IEEE T PATTERN ANAL, V35, P624, DOI 10.1109/TPAMI.2012.87
   Scherer Klaus R., 2010, A Blueprint for Affective Computing: a Sourcebook and Manual
   Strat ST, 2014, MULTIMED TOOLS APPL, V69, P443, DOI 10.1007/s11042-012-1280-0
   Su F, 2009, 6 INT S MULT IM PROC
   Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374
   Valstar Michel F., 2015, INT C WORKSH AUT FAC
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wallhoff F., 2006, Facial Expressions and Emotion Database
   Wallhoff F, 2006, MULT EXP 2006 IE INT
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   Yan H, 2012, IET BIOMETRICS, V1, P160, DOI 10.1049/iet-bmt.2012.0006
   Yan H, 2011, ROB AUT ICRA 2011 IE
   Zavaschi THH, 2013, EXPERT SYST APPL, V40, P646, DOI 10.1016/j.eswa.2012.07.074
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhao XM, 2011, SENSORS-BASEL, V11, P9573, DOI 10.3390/s111009573
   Zia MS, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418560049
   Zia MS, 2015, MULTIMED TOOLS APPL, V74, P3881, DOI 10.1007/s11042-013-1803-3
   Zia MS, 2015, IMAGING SCI J, V63, P160, DOI 10.1179/1743131X14Y.0000000097
NR 64
TC 29
Z9 31
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25537
EP 25567
DI 10.1007/s11042-018-5806-y
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400041
DA 2024-07-18
ER

PT J
AU Anbarjafari, G
   Ozcinar, C
AF Anbarjafari, Gholamreza
   Ozcinar, Cagri
TI Imperceptible non-blind watermarking and robustness against tone mapping
   operation attacks for high dynamic range images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
ID DISCRETE WAVELET TRANSFORM; ENTROPY; MODEL
AB High dynamic range (HDR) imaging has experienced a widespread during the recent years through various technologies, including social network applications, which necessitates robust watermarking schemes to protect the copyright and image authentication. As watermarked high dynamic range images need to be tone mapped for visualization purposes on the traditional low dynamic range displays, the associated tone mapping operators (TMOs) can be deemed inevitable attacks. In this paper, we show that the state-of-the-art non-blind watermarking algorithms are vulnerable to the TMO's attacks. Based on the results of our investigation, we propose an improved non-blind watermarking method and extensively evaluate with state-of-the-art non-blind watermarking schemes using a broad set of TMOs' attacks. The proposed method first divides a given host image into patches, each of which is then decomposed using the discrete wavelet transform (DWT). The high-high sub-band of DWT is then passed through chirp-z transformation, followed by QR decomposition. The proposed solution embeds the watermark into each of value of the upper triangular matrix obtained from QR decomposition. The efficiency of the proposed embedding scheme is evaluated by applying 14 different TMOs on the watermarked image and extracting the embedded watermark. The average of 100 normalized correlation values for each image is then taken into account as a criterion for comparison, which demonstrates the noticeably stronger performance of the proposed watermarking scheme with respect to the state-of-the-art non-blind watermarking alternatives.
C1 [Anbarjafari, Gholamreza] Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
   [Anbarjafari, Gholamreza] Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkey.
   [Ozcinar, Cagri] Trinity Coll Dublin, Sch Comp Sci & Stat, V SENSE, Dublin 2, Ireland.
C3 University of Tartu; Hasan Kalyoncu University; Trinity College Dublin
RP Anbarjafari, G (corresponding author), Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.; Anbarjafari, G (corresponding author), Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkey.
EM shb@icv.tuit.ut.ee; ozcinarc@scss.tcd.ie
RI Anbarjafari, Gholamreza/A-3845-2010
OI Anbarjafari, Gholamreza/0000-0001-8460-5717; Ozcinar,
   Cagri/0000-0003-4915-2251
FU Estonian Information Technology Foundation; Skype Technologies; Estonian
   Research Council [PUT638]; Estonian Centre of Excellence in IT (EXCITE)
   - European Regional Development Fund; European Network on Integrating
   Vision and Language (iV&L Net) ICT COST Action [IC1307]
FX This work has been partially supported by Estonian Information
   Technology Foundation, Skype Technologies, Estonian Research Council
   Grant (PUT638), the Estonian Centre of Excellence in IT (EXCITE) funded
   by the European Regional Development Fund and the European Network on
   Integrating Vision and Language (iV&L Net) ICT COST Action IC1307.
CR Hernandez-Avalos PA, 2012, DIGIT SIGNAL PROCESS, V22, P324, DOI 10.1016/j.dsp.2011.10.012
   Abu-Marie W, 2010, INT J SIGNAL IMAGE P, V1, P1
   Agoyi M, 2015, SIGNAL IMAGE VIDEO P, V9, P735, DOI 10.1007/s11760-014-0624-9
   [Anonymous], ICGST INT J GRAPH VI
   Banterle F, 2011, ADVANCED HIGH DYNAMIC RANGE IMAGING: THEORY AND PRACTICE, P1
   CHIU K, 1993, GRAPH INTER, P245
   Çiftçi S, 2017, IET SIGNAL PROCESS, V11, P1055, DOI 10.1049/iet-spr.2016.0759
   Debevec Paul, 2002, 13 EUR WORKSH REND
   Debevec Paul E, 2008, ACM SIGGRAPH 2008 CL, P1, DOI DOI 10.1145/1401132.1401174
   Drago F, 2003, COMPUT GRAPH FORUM, V22, P419, DOI 10.1111/1467-8659.00689
   Elbasi E, 2010, TURK J ELECTR ENG CO, V18, P159, DOI 10.3906/elk-0906-85
   EMPA Media technology laboratory, 2015, EMPA HDR IMAG DATAB
   Fairchild MD, 2007, FIFTEENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, AND APPLICATIONS, FINAL PROGRAM AND PROCEEDINGS, P233
   Funt B, 2010, COLOR IMAG CONF, P256
   Ghazy Rania A., 2007, 24th Radio National Science Conference (NRSC 2007), P1, DOI 10.1109/NRSC.2007.371376
   Ghouti L, 2012, IET C IM PROC, P1, DOI DOI 10.1049/CP.2012.0456
   Guerrini F, 2011, IEEE T INF FOREN SEC, V6, P283, DOI 10.1109/TIFS.2011.2109383
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2009, 2009 IEEE/ACS INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND APPLICATIONS, VOLS 1 AND 2, P400, DOI 10.1109/AICCSA.2009.5069356
   Hu WC, 2016, MULTIMED TOOLS APPL, V75, P3495, DOI 10.1007/s11042-015-2449-0
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Larijani HH, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P157, DOI 10.1109/ICCCE.2008.4580587
   Laur L, 2015, RADIOENGINEERING, V24, P1025, DOI 10.13164/re.2015.1025
   Lian SG, 2009, MULTIMED TOOLS APPL, V43, P91, DOI 10.1007/s11042-008-0258-4
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mantiuk R, 2005, PROC SPIE, V5666, P204, DOI 10.1117/12.586757
   Mantiuk R., 2006, ACM Transactions on Applied Perception, V3, P286, DOI DOI 10.1145/1166087.1166095
   Mantiuk R. K., 2015, High dynamic range imaging. na
   Megalingam RK, 2010, 2010 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING: ICSAP 2010, PROCEEDINGS, P349, DOI 10.1109/ICSAP.2010.79
   Mitra P., 2012, Proceedings of the 2012 International Conference on Recent Advances in Computing and Software Systems (RACSS), P135, DOI 10.1109/RACSS.2012.6212712
   Ozcinar C, 2016, 2016 DIGITAL MEDIA INDUSTRY AND ACADEMIC FORUM (DMIAF), P43, DOI 10.1109/DMIAF.2016.7574900
   Park H, 2006, LECT NOTES COMPUT SC, V4283, P397
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Reinhard E., 2010, High Dynamic Range Imaging: Acquisition, Display, and Image-Based Lighting
   Sharma P., 2013, C ADV COMM CONTR SYS, P129
   Sheriff SR, 2010, 3 SCI C INF TECHN, V7
   Singh AK, 2012, 2012 2ND IEEE INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P497, DOI 10.1109/PDGC.2012.6449871
   Solachidis V, 2013, IS T SPIE ELECT IMAG
   Solachidis V., 2013, INT C DIG SIGN PROC, P1
   Trick D, 2013, IEEE INT WORKSH MULT, P418, DOI 10.1109/MMSP.2013.6659325
   Xue X, 2011, ASIA PACIFIC SIGNAL
   Yang Q., 2012, P 2012 S PHOTONICS O, P1, DOI [10.1109/SOPO.2012.6270549, DOI 10.1109/SOPO.2012.6270549]
   Zebbiche K, 2014, IET IMAGE PROCESS, V8, P23, DOI 10.1049/iet-ipr.2013.0055
NR 46
TC 10
Z9 10
U1 4
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24521
EP 24535
DI 10.1007/s11042-018-5759-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900064
DA 2024-07-18
ER

PT J
AU Hu, HJ
   Wang, R
   Nie, FP
   Yang, XJ
   Yu, WZ
AF Hu, Haojie
   Wang, Rong
   Nie, Feiping
   Yang, Xiaojun
   Yu, Weizhong
TI Fast unsupervised feature selection with anchor graph and
   <i>l</i><sub>2,1</sub>-norm regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised feature selection; Anchor graph; l(2,1)-norm
ID PRESERVING PROJECTIONS; ROBUST
AB Graph-based unsupervised feature selection has been proven to be effective in dealing with unlabeled and high-dimensional data. However, most existing methods face a number of challenges primarily due to their high computational complexity. In light of the ever-increasing size of data, these approaches tend to be inefficient in dealing with large-scale data sets. We propose a novel approach, called Fast Unsupervised Feature Selection (FUFS), to efficiently tackle this problem. Firstly, an anchor graph is constructed by means of a parameter-free adaptive neighbor assignment strategy. Meanwhile, an approximate nearest neighbor search technique is introduced to speed up the anchor graph construction. The a"" (2,1)-norm regularization is then performed to select more valuable features. Experiments on several large-scale data sets demonstrate the effectiveness and efficiency of the proposed method.
C1 [Hu, Haojie; Wang, Rong] Xian Res Inst Hitech, Xian 710025, Shaanxi, Peoples R China.
   [Wang, Rong; Nie, Feiping] Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
   [Yang, Xiaojun] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Guangdong, Peoples R China.
   [Yu, Weizhong] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Rocket Force University of Engineering; Northwestern Polytechnical
   University; Guangdong University of Technology; Xi'an Jiaotong
   University
RP Wang, R (corresponding author), Xian Res Inst Hitech, Xian 710025, Shaanxi, Peoples R China.; Wang, R (corresponding author), Northwestern Polytech Univ, Ctr OPT IMagery Anal & Learning OPTIMAL, Xian 710072, Shaanxi, Peoples R China.
EM wangrong07@tsinghua.org.cn
RI liu, mengjie/KDN-1890-2024; Nie, Feiping/B-3039-2012; Wang,
   Rong/JQI-7854-2023
OI Wang, Rong/0009-0009-5350-5743; Wang, Rong/0000-0001-9240-6726; Nie,
   Feiping/0000-0002-0871-6519
FU National Natural Science Foundation of China [61401471, 61772427,
   61751202]; China Postdoctoral Science Foundation [2014M562636]
FX This paper is supported in part by the National Natural Science
   Foundation of China under Grant 61401471, Grant 61772427 and Grant
   61751202 and in part by the China Postdoctoral Science Foundation under
   Grant 2014M562636.
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   Cai D., 2010, KDD, P333
   Cheng QA, 2011, IEEE T PATTERN ANAL, V33, P1217, DOI 10.1109/TPAMI.2010.195
   Deng C, 2013, IEEE I CONF COMP VIS, P2600, DOI 10.1109/ICCV.2013.323
   Deng C, 2014, IEEE T MULTIMEDIA, V16, P785, DOI 10.1109/TMM.2014.2298841
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Freeman C, 2013, IEEE T CYBERNETICS, V43, P1990, DOI 10.1109/TSMCB.2012.2237394
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hancock T, 2012, IEEE T NEUR NET LEAR, V23, P1767, DOI 10.1109/TNNLS.2012.2214057
   Hou CP, 2017, IEEE T KNOWL DATA EN, V29, P1998, DOI 10.1109/TKDE.2017.2681670
   Hou CP, 2014, IEEE T CYBERNETICS, V44, P793, DOI 10.1109/TCYB.2013.2272642
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Lai HJ, 2013, IEEE T NEUR NET LEAR, V24, P940, DOI 10.1109/TNNLS.2013.2247628
   Laporte L, 2014, IEEE T NEUR NET LEAR, V25, P1118, DOI 10.1109/TNNLS.2013.2286696
   Li Y, 2015, IEEE T NEUR NET LEAR, V26, P1388, DOI 10.1109/TNNLS.2014.2341627
   Li Z., 2012, P AAAI C ART INT, P1026
   Ling Xing, 2018, Multimedia Tools and Applications, V77, P3029, DOI 10.1007/s11042-017-4970-9
   Ling Xing, 2013, SCI CHINA INFORM SCI, V56, P1
   Liu W., 2010, PROC ICML, P679
   Liu W, 2012, P IEEE, V100, P2624, DOI 10.1109/JPROC.2012.2197809
   Luo MN, 2018, IEEE T CYBERNETICS, V48, P648, DOI 10.1109/TCYB.2017.2647904
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Nie F., 2008, P 23 NATL C ARTIFICI, V2, P671
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1969
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Peng Y, 2017, NEUROCOMPUTING, V261, P242, DOI 10.1016/j.neucom.2016.05.113
   Qian M., 2013, P 23 INT JOINT C ART, P1621
   Romero E, 2008, IEEE T NEURAL NETWOR, V19, P431, DOI 10.1109/TNN.2007.909535
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Wang R, 2017, IEEE T IMAGE PROCESS, V26, P5019, DOI 10.1109/TIP.2017.2726188
   Wang R, 2015, IEEE T CYBERNETICS, V45, P1108, DOI 10.1109/TCYB.2014.2341575
   Xiang SM, 2009, IEEE T KNOWL DATA EN, V21, P1285, DOI 10.1109/TKDE.2008.204
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yu Q, 2016, NEUROCOMPUTING, V171, P57, DOI 10.1016/j.neucom.2015.06.011
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
NR 37
TC 9
Z9 10
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22099
EP 22113
DI 10.1007/s11042-017-5582-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500018
DA 2024-07-18
ER

PT J
AU Hu, QP
   Sun, HQ
   Li, P
   Shen, RM
   Sheng, B
AF Hu, Qiaoping
   Sun, Hanqiu
   Li, Ping
   Shen, Ruimin
   Sheng, Bin
TI Illumination-aware live videos background replacement using antialiasing
   optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illumination-aware; Live video; Background replacement; Antialiasing;
   GPU acceleration
AB We propose a real-time illumination-aware live videos background replacement approach with antialiasing optimization on GPU in this paper. The aim of background replacement for live videos is to substitute the current real-time backgrounds with specially-chosen background images. Here we assume that the camera is stationary and the beginning of the video is only with a pure background scene. We propose the colored locality sensitive histograms (CLSH) considering the influence of other pixels to each pixel in every color channel to improve the performance of background segmentation, which makes the segmentation results robust enough to illumination differences. With the segmentation results, we then introduce a blocked real-time matting approach to enhance the accuracy of the objects' boundary. Finally, to make the video composition more realistic, we propose a local antialiasing method to recover the distortions on edges. Compared with existing background replacement methods, our approach does not require costly blue/green screen or depth camera, but can produce more reliable video composition results. We have applied hardware GPU parallelism to speed up the live background replacement. Our illumination-aware video background replacement runs very efficiently in real-time, which can be applied for various video applications. The experimental results have shown the efficiency and high-quality rendering of our video background replacement in real-time.
C1 [Hu, Qiaoping; Shen, Ruimin; Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
   [Sun, Hanqiu] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   [Li, Ping] Macau Univ Sci & Technol, Fac Informat Technol, Taipa, Macau, Peoples R China.
C3 Shanghai Jiao Tong University; Chinese University of Hong Kong; Macau
   University of Science & Technology
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai, Peoples R China.
EM huqiaoping23@sjtu.edu.cn; hanqiu@cse.cuhk.edu.hk; pli@must.edu.mo;
   rmshen@sjtu.edu.cn; shengbin@sjtu.edu.cn
RI Li, Ping/AAO-2019-2020
OI Li, Ping/0000-0002-1503-0240
FU National Natural Science Foundation of China [61671290]; Key Program for
   International S&T Cooperation Project [2016YFE0129500]; UGC [4055060];
   NSFC [61602183, 61379087]; Research Grants Council of Hong Kong
   [28200215]
FX The authors would like to thank all reviewers for their helpful
   suggestions and constructive comments, and colleagues for their
   participating in program testing and helpful discussions. The work is
   supported by the National Natural Science Foundation of China (No.
   61671290), the Key Program for International S&T Cooperation Project
   (No. 2016YFE0129500), UGC grant for research (no. 4055060), NSFC joint
   projects (No. 61602183, 61379087), and a grant from the Research Grants
   Council of Hong Kong (No. 28200215).
CR [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2014, BACKGROUND MODELING
   [Anonymous], 2016, INT C SYST SIGN IM P
   [Anonymous], 9 WORKSH VIS 0 COMP
   [Anonymous], COMPUT SCI REV
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], COMPUT GRAPH FORUM
   [Anonymous], 2017, IEEE ACCESS
   [Anonymous], P IEEE COMP VIS PATT
   [Anonymous], INT J COMPUT VIS
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 2011, IEEE T IMAGE PROCESS
   [Anonymous], C COMP GRAPH INT TEC
   [Anonymous], INT C INF COMM SIGN
   [Anonymous], IEEE COMPUT GRAPH AP
   [Anonymous], COMPUT VIS MEDIA
   [Anonymous], 2012, AS C COMP VIS
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], 2002, IMPROVED ADAPTIVE BA
   [Anonymous], ACM T GRAPH
   Brainerd W, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925874
   El Baf F., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P187, DOI 10.1109/WIAMIS.2008.9
   Evangelio RH, 2014, IEEE T INF FOREN SEC, V9, P863, DOI 10.1109/TIFS.2014.2313919
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Klose F, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766920
   Lim Y, 2008, OPT ENG, V47, DOI 10.1117/1.2909664
   Lu Y, 2016, PROC CVPR IEEE, P642, DOI 10.1109/CVPR.2016.76
   Niessner M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2077341.2077347
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Qian R. J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P143, DOI 10.1109/ICIP.1999.819566
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   St- Charles PL, 2015, IEEE WINTER C APPL C
   Thaxton S, 2017, AEROSP CONF PROC
   Vergne R, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185590
   Wang J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239460
   Wang L, 2012, INT J COMPUT VISION, V97, P104, DOI 10.1007/s11263-011-0471-x
   Wren C, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P51, DOI 10.1109/AFGR.1996.557243
   Zhang FL, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980243
   Zhang Y, 2015, J COMPUT SCI TECH-CH, V30, P467, DOI 10.1007/s11390-015-1537-y
   Zhong F, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661281
NR 43
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24477
EP 24497
DI 10.1007/s11042-018-5737-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900062
DA 2024-07-18
ER

PT J
AU Jin, X
   Hou, JY
   Nie, RC
   Yao, SW
   Zhou, DM
   Jiang, Q
   He, KJ
AF Jin, Xin
   Hou, Jingyu
   Nie, Rencan
   Yao, Shaowen
   Zhou, Dongming
   Jiang, Qian
   He, Kangjian
TI A lightweight scheme for multi-focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image fusion; Pulse coupled neural networks; Laplacian
   pyramid transform; Spatial frequency
ID MANY-CORE PROCESSORS; WAVELET TRANSFORM; PYRAMID DECOMPOSITION;
   CONTOURLET TRANSFORM; PARALLEL FRAMEWORK; NEURAL-NETWORK; PCNN; LINKING;
   DOMAIN
AB The aim of multi-focus image fusion is to fuse the images taken from the same scene with different focuses so that we can obtain a resultant image with all objects in focus. However, the most existing techniques in many cases cannot gain good fusion performance and acceptable complexity simultaneously. In order to improve image fusion efficiency and performance, we propose a lightweight multi-focus image fusion scheme based on Laplacian pyramid transform (LPT) and adaptive pulse coupled neural networks-local spatial frequency (PCNN-LSF), and it only needs to deal with fewer sub-images than common methods. The proposed scheme employs LPT to decompose a source image into the corresponding constituent sub-images. Spatial frequency (SF) is calculated to adjust the linking strength, beta of PCNN according to the gradient features of the sub-images. Then oscillation frequency graph (OFG) of the sub-images is generated by PCNN model. Local spatial frequency (LSF) of the OFG is calculated as the key step to fuse the sub-images. Incorporating LSF of the OFG into the fusion scheme (LSF of the OFG represents the information of its regional features); it can effectively describe the detailed information of the sub-images. LSF can enhance the features of OFG and makes it easy to extract high quality coefficient of the sub-image. The experiments indicate that the proposed scheme achieves good fusion effect and is more efficient than other commonly used image fusion algorithms.
C1 [Jin, Xin; Nie, Rencan; Zhou, Dongming; Jiang, Qian; He, Kangjian] Yunnan Univ, Sch Informat, Kunming, Yunnan, Peoples R China.
   [Hou, Jingyu] Deakin Univ, Sch Informat Technol, Melbourne, Vic, Australia.
   [Yao, Shaowen] Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.
C3 Yunnan University; Deakin University; Yunnan University
RP Zhou, DM (corresponding author), Yunnan Univ, Sch Informat, Kunming, Yunnan, Peoples R China.; Yao, SW (corresponding author), Yunnan Univ, Sch Software, Kunming, Yunnan, Peoples R China.
EM yaosw@ynu.edu.cn; zhoudm@ynu.edu.cn
RI He, Kangjian/R-6183-2016; jin, xin/GQZ-5811-2022; He,
   Kangjian/CAG-0300-2022; Jin, Xin/S-9172-2017
OI He, Kangjian/0000-0001-6207-9728; Jin, Xin/0000-0003-2211-2006
FU National Natural Science Foundation of China [61365001, 61463052,
   61640306]; Scientific Research Fund of Education Department of Yunnan
   Province [2017YJS108]; Doctoral Candidate Academic Award of Yunnan
   Province
FX The authors thank the editors and the anonymous reviewers for their
   careful works and valuable suggestions for this study. The authors thank
   O. rockinger, G. Easley et al., and da Cunha AL et al. for their kindly
   sharing of program. This study is supported by the National Natural
   Science Foundation of China (No. 61365001, No. 61463052 and No.
   61640306). We thank to the support of Scientific Research Fund of
   Education Department of Yunnan Province (No. 2017YJS108) and Doctoral
   Candidate Academic Award of Yunnan Province. We also thank Dr. Shin-Jye
   Lee for his valuable advises.
CR Adu JH, 2013, INFRARED PHYS TECHN, V61, P94, DOI 10.1016/j.infrared.2013.07.010
   Bavirisetti DP, 2016, INFRARED PHYS TECHN, V76, P52, DOI 10.1016/j.infrared.2016.01.009
   Bhateja V, 2015, IEEE SENS J, V15, P6783, DOI 10.1109/JSEN.2015.2465935
   Bulanon DM, 2009, BIOSYST ENG, V103, P12, DOI 10.1016/j.biosystemseng.2009.02.009
   Cheng J, 2015, ISPRS J PHOTOGRAMM, V104, P158, DOI 10.1016/j.isprsjprs.2015.02.015
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Eckhorn R., 1989, MODELS BRAIN FUNCTIO, P255, DOI DOI 10.1139/W00-039
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Frejlichowski D, 2010, LECT NOTES COMPUT SC, V6112, P151, DOI 10.1007/978-3-642-13775-4_16
   Gao X, 2015, PROC SPIE, V9443, DOI 10.1117/12.2179453
   Geng P., 2016, MULTIMED TOOLS APPL, V75, P1
   Haghighat MBA, 2011, COMPUT ELECTR ENG, V37, P744, DOI 10.1016/j.compeleceng.2011.07.012
   Hong RC, 2014, INFORM SCIENCES, V281, P611, DOI 10.1016/j.ins.2014.03.046
   Ji X, 2015, MULTIMED TOOLS APPL, V76, P17633
   Jin HY, 2015, INFRARED PHYS TECHN, V73, P204, DOI 10.1016/j.infrared.2015.09.018
   Jin X, 2017, INFRARED PHYS TECHN, V85, P478, DOI 10.1016/j.infrared.2017.07.010
   Jin X, 2016, PHYSICA A, V461, P325, DOI 10.1016/j.physa.2016.05.004
   Jin X, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.025023
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Kountchev R, 2015, INT J MULTIMED DATA, V6, P19, DOI 10.4018/ijmdem.2015010102
   Li HH, 2015, PATTERN RECOGN LETT, V51, P23, DOI 10.1016/j.patrec.2014.07.021
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Naidu VPS, 2014, J OPT-INDIA, V43, P48, DOI 10.1007/s12596-013-0148-7
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Qu Xiao-Bo, 2008, Acta Automatica Sinica, V34, P1508, DOI 10.3724/SP.J.1004.2008.01508
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Singh S, 2015, BIOMED SIGNAL PROCES, V18, P91, DOI 10.1016/j.bspc.2014.11.009
   Subashini MM, 2014, EXPERT SYST APPL, V41, P3965, DOI 10.1016/j.eswa.2013.12.027
   Vijayarajan R, 2015, AEU-INT J ELECTRON C, V69, P896, DOI 10.1016/j.aeue.2015.02.007
   Wen DH, 2014, OPT COMMUN, V322, P150, DOI 10.1016/j.optcom.2014.02.034
   Xiang TZ, 2015, INFRARED PHYS TECHN, V69, P53, DOI 10.1016/j.infrared.2015.01.002
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang B, 2007, CHIN OPT LETT, V5, P452
   Yang Y, 2014, SENSORS-BASEL, V14, P22408, DOI 10.3390/s141222408
   Zhang BH, 2015, INFRARED PHYS TECHN, V73, P286, DOI 10.1016/j.infrared.2015.10.004
NR 37
TC 11
Z9 13
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23501
EP 23527
DI 10.1007/s11042-018-5659-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900020
DA 2024-07-18
ER

PT J
AU Karn, NK
   Zhang, HL
   Jiang, F
AF Karn, Nabin Kumar
   Zhang, Hongli
   Jiang, Feng
TI User-perceived quality aware adaptive streaming of 3D multi-view video
   plus depth over the internet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D multi-view video plus depth; Adaptive streaming; QoE; MPEG-DASH;
   Dynamic network environment
ID EFFICIENCY
AB Video streaming is a foremost and growing contributor in the ever increasing Internet traffic. Since last two decades, due to the enhancement in cameras and image processing technology, we have seen a shift towards multi-view plus depth (MVD) technology from traditional 2D and 3D video technology. This growth comes with deep changes in the Internet bandwidth, video coding and network technologies, which smoothed the mode for delivery of MVD content to end-users over the Internet. Since, MVD contains large amounts of data than single view video, it requires more bandwidth. It is a challenging task for network service provider to deliver such views with the best user's Quality of Experience(QoE) in dynamic network condition. Also, Internet is known to be prone to packet loss, bandwidth variation, delay and network congestion, which may prevent video packets from being delivered on time. Besides that, different capabilities of end user's devices in terms of computing power, display, and access link capacity are other challenges. As consequences, the viewing experiences of 3D videos may well degrade, if the quality-aware adaptation techniques are not deployed. In this article, our work concentrates to present a comprehensive analysis of a dynamic network environment for streaming of 3D MVD over Internet (HTTP). We analyzed the effect of different adaptation of decision strategies and formulated a new quality-aware adaptation technique. The proposed technique is promoting from layer based video coding in terms of transmitted views scalability. The results of MVD streaming experiment, using the proposed approach have shown that the video quality of perceptual 3D improves significantly, as an effect of proposed quality aware adaptation even in adverse network conditions.
C1 [Karn, Nabin Kumar; Zhang, Hongli; Jiang, Feng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Karn, NK (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM karnnabin@hit.edu.cn; zhanghongli@hit.edu.cn; fjiang@hit.edu.cn
RI JIANG, Feng/HTP-2862-2023
CR [Anonymous], P 2016 ACM MULT C
   [Anonymous], MPEG2008M15419
   [Anonymous], 2012, TECH REP
   [Anonymous], 2016, MICR SMOOTH STREAM
   Benzie P, 2007, IEEE T CIRC SYST VID, V17, P1647, DOI 10.1109/TCSVT.2007.905377
   Bosc E, 2013, ANN TELECOMMUN, V68, P615, DOI 10.1007/s12243-013-0363-x
   Buchowicz A, 2013, OPTO-ELECTRON REV, V21, P39, DOI 10.2478/s11772-013-0072-z
   Chakareski J, 2013, IEEE COMMUN MAG, V51, P94, DOI 10.1109/MCOM.2013.6515052
   De Simone F, 2013, MULT SIGN PROC MMSP
   Fruanhofer H. -H. -I., 2013, HEVC 3D EXTENSION TE
   Gao Y, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2967502
   ISO/ IEC JTC1/ SC29/ WG11, 2005, MPEG2005N6999 ISOIEC
   Jacobson V., 1988, Computer Communication Review, V18, P314, DOI 10.1145/52325.52356
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Kuschnig R, 2011, P 2 ANN ACM C MULT S
   Li B, 2012, JCTVC ISOIEC ITU T 1
   Miller K, 2012, PACK VID WORKSH PV 2
   (MPEG) IJSW, 2010, W11578 MPEG IJSW
   Müller K, 2013, IEEE T IMAGE PROCESS, V22, P3366, DOI 10.1109/TIP.2013.2264820
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Ozcinar C, 2016, ACOUSTICS SPEECH SIG
   Ozcinar C, 2016, MULTIMED TOOLS APPL, V75, P12431, DOI 10.1007/s11042-016-3475-2
   Oztas B, 2014, COMP NETW COMM ICNC
   Psannis KE, 2006, IEEE T CIRC SYST VID, V16, P280, DOI 10.1109/TCSVT.2005.859933
   Rizzo L., 1997, Computer Communication Review, V27, P31, DOI 10.1145/251007.251012
   Roodaki H, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348823
   Savas SS, 2011, P 2011 ACM WORKSH SO
   Schierl T, 2012, IEEE T CIRC SYST VID, V22, P1871, DOI 10.1109/TCSVT.2012.2223054
   Seufert M, 2015, IEEE COMMUN SURV TUT, V17, P469, DOI 10.1109/COMST.2014.2360940
   Shimizu S, 2007, IEEE T CIRC SYST VID, V17, P1485, DOI 10.1109/TCSVT.2007.903773
   Smolic A, 2008, IM PROC 2008 ICIP 20
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Sripanidkulchai K, 2004, P 4 ACM SIGCOMM C IN
   Stockhammer T., 2011, P 2 ANN ACM C MULTI
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tanimoto M, 2010, INFORMATION OPTICS AND PHOTONICS: ALGORITHMS, SYSTEMS, AND APPLICATIONS, P115, DOI 10.1007/978-1-4419-7380-1_9
   Tanimoto M, 2009, IEEE INT CON MULTI, P1552, DOI 10.1109/ICME.2009.5202803
   Tanimoto Masayuki, 2013, 105 M MPEG
   Toni L., 2014, P 5 ACM MULT SYST C
   Thang TC, 2014, IEEE J SEL AREA COMM, V32, P693, DOI 10.1109/JSAC.2014.140403
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhao S, 2015, P 23 ACM INT C MULT
   Zhao S, 2018, IEEE J BIOMED HEALTH, V22, P1571, DOI 10.1109/JBHI.2017.2776246
   Zhao SC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4669
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhou C, 2012, VISUAL COMMUNICATION
NR 50
TC 5
Z9 5
U1 5
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22965
EP 22983
DI 10.1007/s11042-018-5744-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500064
DA 2024-07-18
ER

PT J
AU Kong, FQ
AF Kong, Fanqiang
TI Comparison of reconstruction algorithm for compressive sensing magnetic
   resonance imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE compressed sensing; magnetic resonance imaging; iterative
   shrinkage/threshold algorithm; exponential wavelet transform
ID DENSITY
AB Compressed sensing can reconstruct the undersampled image. The combination of compressed sensing and magnetic resonance imaging is a potential future fast imaging method in hospitals. This study investigated five state-of-the-art reconstruction approaches: iterative shrinkage/threshold algorithm (ISTA), fast ISTA, subband-adaptive ISTA, exponential wavelet transform ISTA, and exponential wavelet ISTA with random search (EWISTARS). The simulation results compared the five algorithms over hand image and shoulder image. Finally, we can observe the EWISTARS obtains the best result.
C1 [Kong, Fanqiang] Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing 210016, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Kong, FQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Astronaut, Nanjing 210016, Jiangsu, Peoples R China.
EM kongfq@nuaa.edu.cn
FU National Natural Science Foundation of China [61401200]
FX This work has been supported by National Natural Science Foundation of
   China (61401200). Moreover, the authors would also like to thank those
   anonymous reviewers for their helpful comments to improve this paper.
CR [Anonymous], MULTIMED TOOLS APPL
   Bayram I, 2010, IEEE T SIGNAL PROCES, V58, P1131, DOI 10.1109/TSP.2009.2036064
   Bhotto MZA, 2015, SIAM J IMAGING SCI, V8, P1640, DOI 10.1137/140970537
   Bi DJ, 2017, IEEE T INSTRUM MEAS, V66, P777, DOI 10.1109/TIM.2017.2654578
   Bigot J, 2016, IEEE T INFORM THEORY, V62, P2125, DOI 10.1109/TIT.2016.2524628
   Chambolle A, 2015, J OPTIMIZ THEORY APP, V166, P968, DOI 10.1007/s10957-015-0746-4
   Chen Y, 2017, CNS NEUROL DISORD-DR, V16, P5, DOI 10.2174/1871527314666161124115531
   Chen ZZ, 2017, APPL MAGN RESON, V48, P361, DOI 10.1007/s00723-017-0866-0
   Chepuri SP, 2015, IEEE T SIGNAL PROCES, V63, P684, DOI 10.1109/TSP.2014.2379662
   Chu ZG, 2017, APPL ACOUST, V123, P64, DOI 10.1016/j.apacoust.2017.03.010
   Conrad TOF, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1565-4
   Fan CB, 2014, ADV ENG SOFTW, V77, P48, DOI 10.1016/j.advengsoft.2014.08.001
   Feng L, 2017, J MAGN RESON IMAGING, V45, P966, DOI 10.1002/jmri.25547
   Gigliotti D, 2017, MUSCLE NERVE, V55, P715, DOI 10.1002/mus.25388
   Guerquin-Kern M, 2011, IEEE T MED IMAGING, V30, P1649, DOI 10.1109/TMI.2011.2140121
   Horns J, 2015, J EXP BIOL, V218, P3215, DOI 10.1242/jeb.125831
   Jin J, 2017, IEEE T BIO-MED ENG, V64, P274, DOI 10.1109/TBME.2016.2552489
   Kolber MJ, 2017, J STRENGTH COND RES, V31, P1024, DOI 10.1519/JSC.0000000000001554
   Kowalski M, 2014, IEEE IMAGE PROC, P4151, DOI 10.1109/ICIP.2014.7025843
   Lögters T, 2016, CHIRURG, V87, P893, DOI 10.1007/s00104-016-0274-2
   Lu SY, 2017, CNS NEUROL DISORD-DR, V16, P23, DOI 10.2174/1871527315666161019153259
   Okada H, 2017, IEICE T COMMUN, VE100B, P456, DOI 10.1587/transcom.2016EBP3122
   Park B, 2017, MECH SYST SIGNAL PR, V92, P315, DOI 10.1016/j.ymssp.2017.01.035
   Reddy DS, 2011, ADV SPACE RES, V48, P1432, DOI 10.1016/j.asr.2011.06.015
   Tan K, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.015008
   Valvano G, 2016, MAGN RESON MED, V76, P59, DOI 10.1002/mrm.25847
   Wang SH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00106
   Wang SH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060169
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wang YF, 2012, MATH MOD METH APPL S, V22, DOI 10.1142/S0218202511500084
   Yamagishi M, 2011, 2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P697, DOI 10.1109/SSP.2011.5967797
   Yu CX, 2017, GEOPHYS J INT, V208, P1756, DOI 10.1093/gji/ggw484
   Zhang GS, 2015, 2015 12TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P1296, DOI 10.1109/FSKD.2015.7382130
   Zhang YS, 2013, IEEE T IMAGE PROCESS, V22, P1373, DOI 10.1109/TIP.2012.2230010
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/9416435
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, INFORM SCIENCES, V322, P115, DOI 10.1016/j.ins.2015.06.017
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2014, J ELECTROMAGNET WAVE, V28, P2327, DOI 10.1080/09205071.2014.967365
   Zhang YD, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/546814
   Zhang YD, 2013, SENSORS-BASEL, V13, P4029, DOI 10.3390/s130404029
NR 43
TC 4
Z9 4
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22617
EP 22628
DI 10.1007/s11042-017-4985-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500046
DA 2024-07-18
ER

PT J
AU Li, B
   He, MY
   Dai, YC
   Cheng, XL
   Chen, YC
AF Li, Bo
   He, Mingyi
   Dai, Yuchao
   Cheng, Xuelian
   Chen, Yucheng
TI 3D skeleton based action recognition by video-domain translation-scale
   invariant mapping and multi-scale dilated CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D skeleton; CNN; Image mapping; Recognition
ID OBJECT RETRIEVAL
AB In this paper, we present an image classification approach to action recognition with 3D skeleton videos. First, we propose a video domain translation-scale invariant image mapping, which transforms the 3D skeleton videos to color images, namely skeleton images. Second, a multi-scale dilated convolutional neural network (CNN) is designed for the classification of the skeleton images. Our multi-scale dilated CNN model could effectively improve the frequency adaptiveness and exploit the discriminative temporal-spatial cues for the skeleton images. Even though the skeleton images are very different from natural images, we show that the fine-tuning strategy still works well. Furthermore, we propose different kinds of data augmentation strategies to improve the generalization and robustness of our method. Experimental results on popular benchmark datasets such as NTU RGB + D, UTD-MHAD, MSRC-12 and G3D demonstrate the superiority of our approach, which outperforms the state-of-the-art methods by a large margin.
C1 [Li, Bo; He, Mingyi; Dai, Yuchao; Cheng, Xuelian; Chen, Yucheng] Northwestern Polytech Univ, Xian 710129, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP He, MY (corresponding author), Northwestern Polytech Univ, Xian 710129, Shaanxi, Peoples R China.
EM myhe@nwpu.edu.cn
RI Dai, Yuchao/F-7832-2015; Li, bo/IWL-9318-2023; chen,
   yu-cheng/IQT-1648-2023; He, Mingyi/AGX-2464-2022; Chen,
   Yu-Cheng/ISS-5682-2023; Mingyi, HE/IXN-2319-2023; Li, Ye/JBS-2949-2023;
   He, Mingyi/B-4138-2011; cheng, xuelian/D-1414-2017
OI Dai, Yuchao/0000-0002-4432-7406; He, Mingyi/0000-0003-2051-6955; Chen,
   Yu-Cheng/0000-0003-1696-4667; Mingyi, HE/0000-0003-2051-6955; He,
   Mingyi/0000-0003-2051-6955; Li, Bo/0009-0003-4088-1578
FU Natural Science Foundation of China [61420106007, 61671387]; Australian
   Research Council [DE140100180]; Australian Research Council
   [DE140100180] Funding Source: Australian Research Council
FX This work was supported in part by Natural Science Foundation of China
   grants (61420106007, 61671387) and Australian Research Council grants
   (DE140100180).
CR [Anonymous], IEEE T VEHICULAR TEC
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, IEEE CVPR
   [Anonymous], ARXIV170307475
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Bloom V., 2012, 2012 IEEE COMP SOC C, P7, DOI [DOI 10.1109/CVPRW.2012.6239175, 10.1109/CVPRW.2012.6239175]
   Chen C, 2015, IEEE IMAGE PROC, P168, DOI 10.1109/ICIP.2015.7350781
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2016, IEEE T IMAGE PROCESS, V25, P3010, DOI 10.1109/TIP.2016.2552404
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Gao Y, 2014, IEEE T IND ELECTRON, V61, P2088, DOI 10.1109/TIE.2013.2262760
   Gowayyed M.A., 2013, Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence, IJCAI '13, P1351
   Huang Z., 2017, CVPR
   Hussein, 2013, INT JOINT C ART INT
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Li B, 2017, POLYMER NANOCOMPOSITES FOR DIELECTRICS, P1
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lu GL, 2016, MULTIMED TOOLS APPL, V75, P3479, DOI 10.1007/s11042-015-2448-1
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Nie SQ, 2015, COMPUT VIS IMAGE UND, V136, P14, DOI 10.1016/j.cviu.2014.12.005
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Song Y, 2015, IEEE SIGNAL PROC LET, V22, P426, DOI 10.1109/LSP.2014.2361901
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xuanhan Wang, 2017, IEEE Signal Processing Letters, V24, P510, DOI 10.1109/LSP.2016.2611485
   Yang S, 2014, INT C PATT RECOG, P2613, DOI 10.1109/ICPR.2014.451
   Yu FP, 2016, PROCEEDINGS OF 2016 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES, AND DEVICE APPLICATIONS (SPAWDA), P1, DOI 10.1109/SPAWDA.2016.7829944
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zheng Y, 2015, IEEE IMAGE PROC, P576, DOI 10.1109/ICIP.2015.7350864
   Zhou LJ, 2016, IEEE INT CON MULTI
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
   Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697
NR 50
TC 26
Z9 26
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22901
EP 22921
DI 10.1007/s11042-018-5642-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500061
DA 2024-07-18
ER

PT J
AU Li, Q
   Fu, HY
   Kong, XW
   Tian, Q
AF Li, Qiang
   Fu, Haiyan
   Kong, Xiangwei
   Tian, Qi
TI Deep hashing with top similarity preserving for image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Deep hashing; Top similarity preserving
AB Hashing has drawn more and more attention in image retrieval due to its high search speed and low storage cost. Traditional hashing methods project the high-dimensional hand-crafted visual features to compact binary codes by linear or non-linear hashing functions. Deep hashing methods, which integrate image representation learning and hash functions learning into a unified framework, have shown more superior performance. Most of existing supervised deep hashing methods mainly consider the semantic similarities among images by using pair-wise or triplet-wise constraints as supervision information. However, as a kind of crucial information, the rankings of the retrieval results, are neglected. Consequently, the produced hash codes may be suboptimal. In this paper, a new Deep Hashing with Top Similarity Preserving (DHTSP) method is proposed to optimize the quality of hash codes for image retrieval. Specifically, we utilize AlexNet to extract discriminative image representations directly from the raw image pixels and learn hash functions simultaneously. Then a top similarity preserving loss function is designed to preserve the similarity of returned images at the top of the ranking list. Experimental results on three benchmark datasets show that our proposed method outperforms most of state-of-the-art deep hashing methods and traditional hashing methods.
C1 [Li, Qiang; Fu, Haiyan; Kong, Xiangwei] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
   [Tian, Qi] Univ Texas San Antonio, Dept Comp Sci, San Antonio, TX 78249 USA.
C3 Dalian University of Technology; University of Texas System; University
   of Texas at San Antonio (UTSA)
RP Kong, XW (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
EM kongxw@dlut.edu.cn
RI Kong, Xiangwei/IWL-9350-2023
FU Foundation for Innovative Research Groups of the National Natural
   Science Foundation of China (NSFC) [71421001]; National Natural Science
   Foundation of China (NSFC) [61502073, 61429201]; Open Projects Program
   of National Laboratory of Pattern Recognition [201407349]; ARO
   [W911NF-15-1-0290]; NEC Laboratories of America; Blippar
FX This work was supported in part by the Foundation for Innovative
   Research Groups of the National Natural Science Foundation of China
   (NSFC) under Grant 71421001, in part by the National Natural Science
   Foundation of China (NSFC) under Grant 61502073 and Grant 61429201, in
   part by the Open Projects Program of National Laboratory of Pattern
   Recognition under Grant 201407349, and in part to Dr. Qi Tian by ARO
   grants W911NF-15-1-0290 and Faculty Research Gift Awards by NEC
   Laboratories of America and Blippar.
CR [Anonymous], IEEE CVPR
   [Anonymous], IEEE ICCV
   [Anonymous], AAAI
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2016, IJCAI
   [Anonymous], 2014, IEEE CVPR
   [Anonymous], IEEE CVPR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], IEEE CVPR
   [Anonymous], 2015, PROC IEEE C COMPUT V
   [Anonymous], IEEE CVPR
   [Anonymous], 2016, ARXIV160305027
   [Anonymous], IEEE CVPR
   [Anonymous], 2014, IEEE CVPR
   [Anonymous], 2011, ICML
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2012, NIPS
   [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], 2016, AAAI
   [Anonymous], IEEE CVPR
   [Anonymous], 2014, AAAI
   [Anonymous], 2017, IJCAI
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ARXIV150700101
   [Anonymous], 2011, AISTATS
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2467315
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], 1999, P IEEE C COMP VIS FO
   [Anonymous], 2009, ACM CIVR
   [Anonymous], IEEE CVPR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1998, The mnist database of handwritten digits
   [Anonymous], 2006, ACM SIGIR
   [Anonymous], 2014, P 22 ACM INT C MULT
   [Anonymous], IEEE CVPR
   [Anonymous], 2009, NIPS
   [Anonymous], 1999, VLDB
   [Anonymous], 2016, AAAI
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2009, IEEE T PATTERN ANAL, V31, P2143, DOI 10.1109/TPAMI.2009.151
   Liu WF, 2016, IEEE T IND ELECTRON, V63, P5120, DOI 10.1109/TIE.2016.2552147
   Norouzi M., 2012, ADV NEURAL INFORM PR
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
   Zheng L, 2015, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
   Zheng L, 2013, PROC CVPR IEEE, P1626, DOI 10.1109/CVPR.2013.213
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
NR 53
TC 1
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24121
EP 24141
DI 10.1007/s11042-017-5596-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900045
DA 2024-07-18
ER

PT J
AU Nguyen, NT
   Chang, CC
AF Ngoc-Tu Nguyen
   Chang, Chin-Chen
TI A biometric-based authenticated key agreement scheme for session
   initiation protocol in ip-based multimedia networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Session Initial Protocol (SIP); Authenticated key agreement;
   Client-serverm; Client-client; Group communication; Biometric; PalmHash
   code; Smart card
ID SECURE AUTHENTICATION; SMART CARD; ROBUST
AB Session Initial Protocol (SIP) has been widely adopted for signaling and controlling interactive sessions in multimedia communication networks. Despite its various advantages compared to predecessor protocols, the security and privacy of the SIP remain challenges due to the risk of real-world public networks. While most SIP applications utilize end-to-end communications, existing studies mainly focus on client-server protocols. In this study, we propose a novel SIP authenticated key agreement protocol for all user-server, user-user, and group communications. An end user employs a short-term token to communicate with either end-users or multimedia servers without connecting to a trusted server. Our security analyzes show that the scheme not only resists all known attacks, but provides the system with many desirable features, including direct end-to-end communications, preserving biometric template privacy, user access control, smart card revocation, and long-term secret updates. The latency of the authenticated key agreement phase is relatively small, and thus this signaling protocol is appropriate for a wide range of real-time applications.
C1 [Ngoc-Tu Nguyen; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Ngoc-Tu Nguyen] Tay Nguyen Univ, Fac Nat Sci & Technol, 567 Le Duan Rd, Buon Ma Thuot City, Daklak, Vietnam.
C3 Feng Chia University; Tay Nguyen University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM nntu@ttn.edu.vn; alan3c@gmail.com
RI Nguyen, Ngoc-Tu/T-1409-2019; Chang, Ching-Chun/JAN-6210-2023
OI Nguyen, Ngoc-Tu/0000-0002-1355-8885; 
CR [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2016, NIST SPEC PUBL
   [Anonymous], 1999, SIP SESSION INITIATI
   [Anonymous], 2002, SIP SESSION INITIATI
   [Anonymous], INT J COMMUNICATION
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Butcher D, 2007, IEEE T SYST MAN CY C, V37, P1152, DOI 10.1109/TSMCC.2007.905853
   Chaudhry SA, 2017, PEER PEER NETW APPL, V10, P1, DOI 10.1007/s12083-015-0400-9
   Das AK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9969-9
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Eckhoff D, 2018, IEEE COMMUN SURV TUT, V20, P489, DOI 10.1109/COMST.2017.2748998
   Farash MS, 2016, PEER PEER NETW APPL, V9, P82, DOI 10.1007/s12083-014-0315-x
   Farash MS, 2016, MULTIMED TOOLS APPL, V75, P4485, DOI 10.1007/s11042-015-2487-7
   Franks J., 1999, HTTP AUTHENTICATION
   Geneiatakis D, 2006, IEEE COMMUN SURV TUT, V8, P68, DOI 10.1109/COMST.2006.253270
   Irshad A, 2015, MULTIMED TOOLS APPL, V74, P3967, DOI 10.1007/s11042-013-1807-z
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Islam SKH, 2015, INFORM SCIENCES, V312, P104, DOI 10.1016/j.ins.2015.03.050
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jiang Q, 2015, INT J COMMUN SYST, V28, P1340, DOI 10.1002/dac.2767
   Keromytis AD, 2012, IEEE COMMUN SURV TUT, V14, P514, DOI 10.1109/SURV.2011.031611.00112
   Kumari S., 2015, PEERTOPEER NETWORKIN, P1
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Leng L, 2015, MULTIMED TOOLS APPL, V74, P11683, DOI 10.1007/s11042-014-2255-0
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Li YT, 2017, NEURAL COMPUT APPL, V28, P1405, DOI 10.1007/s00521-015-2158-7
   Liao YP, 2010, COMPUT COMMUN, V33, P372, DOI 10.1016/j.comcom.2009.10.005
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu Y., 2015, MATH PROBL ENG, V2015, P1, DOI DOI 10.1109/IEDM.2015.7409770
   Lu YR, 2016, PEER PEER NETW APPL, V9, P449, DOI 10.1007/s12083-015-0363-x
   Meng FL, 2017, ENVIRON SCI TECHNOL, V51, P9876, DOI 10.1021/acs.est.7b01727
   Mishkovski I, 2011, STUD COMPUT INTELL, V354, P27
   Mishra D, 2016, WIRELESS PERS COMMUN, V91, P1361, DOI 10.1007/s11277-016-3533-0
   Mishra D, 2016, PEER PEER NETW APPL, V9, P171, DOI 10.1007/s12083-014-0321-z
   Okamoto T, 2001, LECT NOTES COMPUT SC, V1992, P104
   Schulzrinne H., 2000, IEEE SERVICE PORTABI, P29
   Tu H, 2015, PEER PEER NETW APPL, V8, P903, DOI 10.1007/s12083-014-0248-4
   Wang CH, 2011, J NETW COMPUT APPL, V34, P1545, DOI 10.1016/j.jnca.2010.10.011
   Wu F, 2018, PEER PEER NETW APPL, V11, P1, DOI 10.1007/s12083-016-0485-9
   Wu K, 2013, ROM J INF SCI TECH, V16, P324
   Wu LF, 2009, COMPUT STAND INTER, V31, P286, DOI 10.1016/j.csi.2008.01.002
   Xie Q, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2725-0
   Yang CC, 2005, COMPUT SECUR, V24, P381, DOI 10.1016/j.cose.2004.10.007
   Yeh HL, 2014, COMPUT STAND INTER, V36, P397, DOI 10.1016/j.csi.2013.08.010
   Yoon EJ, 2009, CISIS: 2009 INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT AND SOFTWARE INTENSIVE SYSTEMS, VOLS 1 AND 2, P549, DOI 10.1109/CISIS.2009.93
   Zhang LP, 2016, J NETW COMPUT APPL, V59, P126, DOI 10.1016/j.jnca.2015.06.022
   Zhang LP, 2016, PEER PEER NETW APPL, V9, P108, DOI 10.1007/s12083-014-0317-8
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
   Zhang LP, 2014, IET COMMUN, V8, P83, DOI 10.1049/iet-com.2012.0783
   Zhang ZZ, 2015, MULTIMED TOOLS APPL, V74, P3477, DOI 10.1007/s11042-014-1885-6
NR 55
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23909
EP 23947
DI 10.1007/s11042-018-5708-z
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900036
DA 2024-07-18
ER

PT J
AU Zhang, YD
   Hou, XX
   Chen, Y
   Chen, H
   Yang, M
   Yang, JQ
   Wang, SH
AF Zhang, Yu-Dong
   Hou, Xiao-Xia
   Chen, Yi
   Chen, Hong
   Yang, Ming
   Yang, Jiquan
   Wang, Shui-Hua
TI Voxelwise detection of cerebral microbleed in CADASIL patients by leaky
   rectified linear unit and early stopping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CADASIL; Cerebral microbleed; Magnetic resonance imaging; Susceptibility
   weighted imaging; Class-imbalanced problem; Logistic sigmoid; Leaky
   rectified linear unit
ID COMPUTER-AIDED DETECTION; SUPPORT VECTOR MACHINE; FOLD CROSS-VALIDATION;
   ACUTE ISCHEMIC-STROKE; ACTIVATION FUNCTION; WAVELET-ENTROPY;
   CLASSIFICATION; PREDICTION; IMAGES; RISK
AB It is important to detect cerebral microbleed voxels from the brain image of cerebral autosomal-dominant arteriopathy with subcortical infarcts and Leukoencephalopathy (CADASIL) patients. Traditional manual method suffers from intra-observe and inter-observe variability. In this study, we used the susceptibility weighted imaging (SWI) to scan 10 CADASIL patients and 10 healthy controls. We used slicing neighborhood processing (SNP) to extract "input" and "target" dataset from the 20 brain volumetric images. Afterwards, the undersampling technique was employed to handle the class-imbalanced problem. The single-hidden layer feedforward neural-network with scaled conjugate gradient was used as the classifier. We compared three activation functions: logistic sigmoid (LOSI), rectified linear unit (ReLU), and leaky rectified linear unit (LReLU). Early stopping and K-fold cross validation (CV) was used to avoid overfitting and statistical analysis. In the experiment, we generated 68,847 CMB voxels, and 68,829 non-CMB voxels. We observed that LReLU achieved the best result with a sensitivity of 93.05%, a specificity of 93.06%, and an accuracy of 93.06%. We also observed the effect of early stopping and K-fold CV. We found the optimal number of hidden neuron was 10 by grid searching method. Besides, our method performs better than three state-of-the-art methods. The results show our method is promising. In addition, LReLU is a better activation function that may replace traditional logistic sigmoid function in other applications.
C1 [Zhang, Yu-Dong; Chen, Yi; Yang, Jiquan; Wang, Shui-Hua] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Zhang, Yu-Dong; Chen, Yi] Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
   [Zhang, Yu-Dong; Hou, Xiao-Xia; Chen, Hong] Nanjing Med Univ, Affiliated Hosp 1, Dept Neurol, Nanjing 210029, Jiangsu, Peoples R China.
   [Yang, Ming] Nanjing Med Univ, Nanjing Childrens Hosp, Dept Radiol, Nanjing 210008, Jiangsu, Peoples R China.
   [Wang, Shui-Hua] CUNY, CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
C3 Nanjing Normal University; Nanjing Medical University; Nanjing Medical
   University; City University of New York (CUNY) System; City College of
   New York (CUNY)
RP Wang, SH (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Wang, SH (corresponding author), CUNY, CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
EM wangshuihua@njnu.edu.cn
RI ; Wang, shuihua/G-7326-2016; Zhang, Yudong/I-7633-2013
OI Chen, Yi/0000-0002-8762-4523; Wang, shuihua/0000-0003-4713-2791; Zhang,
   Yudong/0000-0002-4870-1493
FU NSFC [61602250]; Natural Science Foundation of Jiangsu Province
   [BK20150983]; Leading Initiative for Excellent Young Researcher (LEADER)
   of Ministry of Education, Culture, Sports, Science and Technology-Japan
   [16809746]; Program of Natural Science Research of Jiangsu Higher
   Education Institutions [16KJB520025]; Open Research Fund of Hunan
   Provincial Key Laboratory of Network Investigational Technology
   [2016WLZC013]; Open Fund of Fujian Provincial Key Laboratory of Data
   Intensive Computing [BD201607]; Open Program of Jiangsu Key Laboratory
   of 3D Printing Equipment and Manufacturing [3DL201602]
FX This paper was supported by NSFC (61602250), Natural Science Foundation
   of Jiangsu Province (BK20150983), Leading Initiative for Excellent Young
   Researcher (LEADER) of Ministry of Education, Culture, Sports, Science
   and Technology-Japan (16809746), Program of Natural Science Research of
   Jiangsu Higher Education Institutions (16KJB520025), Open Research Fund
   of Hunan Provincial Key Laboratory of Network Investigational Technology
   (2016WLZC013), Open Fund of Fujian Provincial Key Laboratory of Data
   Intensive Computing (BD201607), Open Program of Jiangsu Key Laboratory
   of 3D Printing Equipment and Manufacturing (3DL201602).
CR Aghdam HH, 2016, ADV INTELL SYST COMP, V417, P399, DOI 10.1007/978-3-319-27146-0_31
   Aghdam HH, 2015, PROC SPIE, V9875, DOI 10.1117/12.2228582
   Ali S, 2016, COMPUT BIOL MED, V73, P38, DOI 10.1016/j.compbiomed.2016.04.002
   Ando S, 2016, KNOWL INF SYST, V46, P707, DOI 10.1007/s10115-015-0846-3
   [Anonymous], EXP SYST, DOI DOI 10.1111/EXSY.12146
   [Anonymous], 2016, IEEE POW EN SOC GEN, DOI DOI 10.1109/PESGM.2016.7741781
   Babaie-Kafaki S, 2014, B BELG MATH SOC-SIM, V21, P465, DOI 10.36045/bbms/1407765884
   Barnes SRS, 2011, MAGN RESON IMAGING, V29, P844, DOI 10.1016/j.mri.2011.02.028
   Barrow E, 2015, LECT NOTES COMPUT SC, V9492, P29, DOI 10.1007/978-3-319-26561-2_4
   Bian W, 2013, NEUROIMAGE-CLIN, V2, P282, DOI 10.1016/j.nicl.2013.01.012
   Borkar P, 2016, PROCEDIA COMPUT SCI, V78, P740, DOI 10.1016/j.procs.2016.02.047
   Chen M, 2015, IEEE WIREL COMMUN, V22, P20, DOI 10.1109/MWC.2015.7054715
   Chen Y, 2018, MULTIMED TOOLS APPL, V77, P3775, DOI 10.1007/s11042-016-4087-6
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Esmaeelzadeh SR, 2015, KSCE J CIV ENG, V19, P2298, DOI 10.1007/s12205-014-0105-2
   Famouri M, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415510131
   Fazlollahi A, 2015, COMPUT MED IMAG GRAP, V46, P269, DOI 10.1016/j.compmedimag.2015.10.001
   Gayathri K, 2015, INT J COMPUT INT SYS, V8, P95, DOI 10.1080/18756891.2014.967007
   Goodwin JA, 2015, J NEUROIMAGING, V25, P575, DOI 10.1111/jon.12192
   Greenberg SM, 2009, LANCET NEUROL, V8, P165, DOI 10.1016/S1474-4422(09)70013-4
   Gregoire SM, 2009, NEUROLOGY, V73, P1759, DOI 10.1212/WNL.0b013e3181c34a7d
   Hara K, 2015, INT JOINT C NEUR NET, P144
   Imaizumi T, 2007, J NEUROIMAGING, V17, P204, DOI 10.1111/j.1552-6569.2007.00090.x
   Klein K, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152700
   Klimstra M, 2008, EXP BRAIN RES, V186, P93, DOI 10.1007/s00221-007-1207-6
   Kolus A, 2015, APPL ERGON, V50, P68, DOI 10.1016/j.apergo.2015.03.001
   Kuijf HJ, 2012, NEUROIMAGE, V59, P2266, DOI 10.1016/j.neuroimage.2011.09.061
   Lee JB, 2015, 7 INT C MACH VIS, P3460
   Lee Y, 2014, MAGN RESON MED, V71, P1324, DOI 10.1002/mrm.24776
   Levati E, 2016, SCI REP-UK, V6, DOI 10.1038/srep25165
   Li B, 2013, CHIN CONT DECIS CONF, P2170
   Liao B, 2015, IETE TECH REV, V32, P294, DOI 10.1080/02564602.2015.1015631
   Murray V, 2010, IEEE T IMAGE PROCESS, V19, P1138, DOI 10.1109/TIP.2010.2040446
   Njikam ANS, 2016, APPL INTELL, V45, P75, DOI 10.1007/s10489-015-0744-0
   Osoba O, 2016, FLUCT NOISE LETT, V15, DOI 10.1142/S0219477516500073
   Roy S, 2015, PROC SPIE, V9413, DOI 10.1117/12.2082237
   Rutten JW, 2015, ACTA NEUROPATHOL COM, V3, DOI 10.1186/s40478-015-0268-1
   Seghier ML, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017547
   Sepasian M, 2008, LECT NOTES ENG COMP, P1199
   Shah P, 2016, IEEE T ANTENN PROPAG, V64, P1373, DOI 10.1109/TAP.2016.2529641
   Shao Y, 2011, IEEE GEOSCI REMOTE S, V8, P113, DOI 10.1109/LGRS.2010.2052782
   Tan RYY, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157613
   Tsivgoulis G, 2016, JAMA NEUROL, V73, P675, DOI 10.1001/jamaneurol.2016.0292
   Valmoria MS, 2014, ANN NEUROL, V76, pS88
   Vitali P, 2014, CAN J NEUROL SCI, V41, P661, DOI 10.1017/cjn.2014.29
   Wang SH, 2016, IEEE ACCESS, V4, DOI 10.1109/ACCESS.2016.2620996
   Wang SH, 2016, PROG ELECTROMAGN RES, V156, P105
   Wang SH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6060169
   Wang SH, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/454076
   Wang SH, 2015, ENTROPY-SWITZ, V17, P5711, DOI 10.3390/e17085711
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Wesolowski W, 2015, POL J PATHOL, V66, P323, DOI 10.5114/PJP.2015.54966
   Wu XX, 2009, ICICTA: 2009 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTATION TECHNOLOGY AND AUTOMATION, VOL I, PROCEEDINGS, P15, DOI 10.1109/ICICTA.2009.11
   Wu YW, 2014, LECT NOTES COMPUT SC, V8836, P142, DOI 10.1007/978-3-319-12643-2_18
   Zadeh MR, 2010, WATER RESOUR MANAG, V24, P2673, DOI 10.1007/s11269-009-9573-4
   Zainuddin Z, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P8, DOI 10.1109/ICNC.2015.7377957
   Zhang Y, 2015, MOBILE NETW APPL, V20, P348, DOI 10.1007/s11036-014-0537-4
   Zhang Y, 2014, IEEE NETWORK, V28, P52, DOI 10.1109/MNET.2014.6863132
   Zhang YM, 2016, IEEE ACM T NETWORK, V24, P1632, DOI 10.1109/TNET.2015.2425146
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zhang YD, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3871575
   Zhang YD, 2016, SCI REP-UK, V6, DOI 10.1038/srep21816
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/840491
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhou XX, 2015, LECT N BIOINFORMAT, V9043, P201, DOI 10.1007/978-3-319-16483-0_20
NR 67
TC 43
Z9 45
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 21825
EP 21845
DI 10.1007/s11042-017-4383-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500002
DA 2024-07-18
ER

PT J
AU Zhou, YQ
   Yang, X
   Ling, Y
   Zhang, JZ
AF Zhou, Yongquan
   Yang, Xiao
   Ling, Ying
   Zhang, Jinzhong
TI Meta-heuristic moth swarm algorithm for multilevel thresholding image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Moth swarm algorithm; Image segmentation;
   Metaheuristic; Kapur's entropy
ID DIFFERENTIAL EVOLUTION; ENTROPY; OPTIMIZATION
AB Multilevel thresholding is a very important image processing technique in the field of image segmentation. However, the computational complexity of determining the optimal threshold grows exponentially with increasing thresholds. To overcome this drawback, in this paper, we propose a multi-threshold image segmentation method based on the moth swarm algorithm. The meta-heuristic algorithm uses Kapur's entropy method to optimize the thresholds for eight standard test images. When compared with other state-of-the-art evolutionary algorithms, the proposed method proved to be robust and effective according to numerical experimental results and image segmentation results. This indicates the high performance of the method for the segmentation of digital images.
C1 [Zhou, Yongquan; Yang, Xiao; Ling, Ying; Zhang, Jinzhong] Guangxi Univ Nationalities, Coll Informat Sci & Engn, Nanning 530006, Peoples R China.
   [Zhou, Yongquan; Yang, Xiao; Ling, Ying; Zhang, Jinzhong] Key Labs Guangxi High Sch Complex Syst & Computat, Nanning 530006, Guangxi, Peoples R China.
C3 Guangxi Minzu University
RP Zhou, YQ (corresponding author), Guangxi Univ Nationalities, Coll Informat Sci & Engn, Nanning 530006, Peoples R China.; Zhou, YQ (corresponding author), Key Labs Guangxi High Sch Complex Syst & Computat, Nanning 530006, Guangxi, Peoples R China.
EM yongquanzhou@126.com
RI zhang, jin/GXV-9154-2022; zhang, jin/IXD-9872-2023; Zhou,
   Yongquan/AAI-3982-2021
OI Zhou, Yongquan/0000-0001-6945-4922
FU National Science Foundation of China [61463007]; Project of the Guangxi
   Natural Science Foundation [2016GXNSFAA380264]
FX This work was supported by the National Science Foundation of China
   under Grant No. 61463007 and the Project of the Guangxi Natural Science
   Foundation under Grant No. 2016GXNSFAA380264. We thank Maxine Garcia,
   PhD, from Liwen Bianji, Edanz Group China (www.liwenbianji.cn/ac) for
   editing the English text of a draft of this manuscript.
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Develi I, 2012, INT J INNOV COMPUT I, V8, P7095
   Duraisamy Sathya P., 2010, Journal of Intelligent Learning Systems and Applications, V2, P126, DOI 10.4236/jilsa.2010.23016
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Hollander M., 2014, Nonparametric Statistical Methods, Solutions Manual, Vthird
   Jiang YZ, 2015, SOFT COMPUT, V19, P2605, DOI 10.1007/s00500-014-1425-3
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karaboga D., 2005, Technical Report-TR06
   Kenndy J., 1995, P ICNN 95 INT C NEUR, P1942
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Lai CC., 2004, INT J HYBRID INTELL, V1, P143
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Maltra M, 2008, EXPERT SYST APPL, V34, P1341, DOI 10.1016/j.eswa.2007.01.002
   Mohamed AA, 2017, ELECTR POW SYST RES, V142, P190, DOI 10.1016/j.epsr.2016.09.025
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Sarkar S., 2013, ADV INTELLIGENT SYST, P699, DOI DOI 10.1007/978-3-642-35314-7_
   SHORE JE, 1980, IEEE T INFORM THEORY, V26, P26, DOI 10.1109/TIT.1980.1056144
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Wang R, 2015, BIO-MED MATER ENG, V26, pS1345, DOI 10.3233/BME-151432
   Yang XS, 2013, ENG COMPUT-GERMANY, V29, P175, DOI 10.1007/s00366-012-0254-1
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   YEN JC, 1995, IEEE T IMAGE PROCESS, V4, P370, DOI 10.1109/83.366472
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
NR 30
TC 51
Z9 51
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23699
EP 23727
DI 10.1007/s11042-018-5637-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900028
DA 2024-07-18
ER

PT J
AU Bibiloni, T
   Oliver, A
   del Molino, J
AF Bibiloni, Toni
   Oliver, Antoni
   del Molino, Javier
TI Automatic collection of user behavior in 360° multimedia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-computer interaction; xAPI; 360 degrees video; Visual analytics;
   User behavior
AB The arrival of 360 degrees video to the everyday life creates the necessity of assessing both the audiovisual production and the playback environment offered to the final user. Leveraging the standard Experience API (xAPI), that considers collecting micro-interactions with e-learning content, we propose a platform to automatically collect the users' interaction with applications based on interactive 360 degrees multimedia. To validate the platform, we introduce an example of educational activities based on interactive 360 degrees videos and the tools used to first, annotate these videos and convert them into interactive activities; second, to perform said activity and collect the users' behavior via xAPI statements; and finally, to convert these statements to meaningful information in the form of user metrics and charts, both at individual level and also aggregated by activity, creating the possibility of finding singular and group behavior. This work concludes that the presented platform helps to analyze how users behave with omnidirectional interactive productions, with the aim of validating and improving its usability, ending with the discussion of future work ideas.
C1 [Bibiloni, Toni; Oliver, Antoni; del Molino, Javier] Univ Balearic Isl, LTIM, Dept Math & Comp Sci, Palma De Mallorca, Balearic Island, Spain.
C3 Universitat de les Illes Balears
RP Bibiloni, T (corresponding author), Univ Balearic Isl, LTIM, Dept Math & Comp Sci, Palma De Mallorca, Balearic Island, Spain.
EM toni.bibiloni@uib.es; antoni.oliver@uib.es;
   j.delmolino1@estudiant.uib.es
RI Tomàs, Antoni Oliver/AAD-1216-2019; Bibiloni, Toni/G-3426-2015
OI Tomàs, Antoni Oliver/0000-0002-2495-5245; Bibiloni,
   Toni/0000-0002-7359-8280
FU Universitat de les Illes Balears (UIB)
FX A. Oliver was supported by a predoctoral contract with the Universitat
   de les Illes Balears (UIB).
CR [Anonymous], 2015, ACM International Conference Proceeding Series, DOI DOI 10.1145/2735711.2735785
   Bakharia A, RECIPE SUCCESS LESSO
   Berning Matthias., 2013, P 2013 ACM C PERVASI, P1471
   Bleumers L, 2012, P 10 EUR C INT TV VI, V12, P115
   Chen Q, 2016, IEEE T VIS COMPUT GR, V22, P2315, DOI 10.1109/TVCG.2015.2505305
   Drachen A, 2011, INT J ARTS TECHNOL, V4, P294, DOI 10.1504/IJART.2011.041483
   Duhon R, WHY REPORTING LRS
   Fekete JD, 2008, LECT NOTES COMPUT SC, V4950, P1, DOI 10.1007/978-3-540-70956-5_1
   Giannakos MN, 2015, INT REV RES OPEN DIS, V16, P260
   Kasahara S, 2017, IEEE T VIS COMPUT GR, V23, P1222, DOI 10.1109/TVCG.2016.2642947
   Kavanagh S., 2016, P 28 AUSTR C COMPUTE, P34
   Kitto K., 2015, P 5 INT C LEARNING A, DOI [10.1145/2723576.2723627, DOI 10.1145/2723576.2723627]
   Kuzyakov E., ENHANCING HIGH RESOL
   Mizushina Y., 2015, P 6 AUGM HUM INT C S, P227, DOI [10.1145/2735711.2735778, DOI 10.1145/2735711.2735778]
   Neng Luisa. R., 2010, Proceedings of the 14th International Academic MindTrek Conference on Envisioning Future Media Environments-MindTrek '10, P119, DOI DOI 10.1145/1930488.1930512
   Neumann U., 2000, MULTIMEDIA 00 P 8 AC, P493
   Paterno F, 2016, P INT WORK C ADV VIS, P88, DOI DOI 10.1145/2909132.2909272
   Shi CL, 2015, IEEE PAC VIS SYMP, P159, DOI 10.1109/PACIFICVIS.2015.7156373
   Siemens G, 2011, LAK 11 1 INT C LEARN
   Wachtler J, USING LEARNING ANAL
   Wallner G, 2013, VISUALIZATION BASED
   Williamson JR, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1251, DOI 10.1145/2750858.2807518
   Zoric Goranka, 2013, P 11 EUR C INT TV VI, P153, DOI DOI 10.1145/2465958.2465959
NR 23
TC 4
Z9 6
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20597
EP 20614
DI 10.1007/s11042-017-5510-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300013
DA 2024-07-18
ER

PT J
AU Cheng, YQ
   Fu, ZX
   Yu, B
   Shen, G
AF Cheng, Yuqiao
   Fu, Zhengxin
   Yu, Bin
   Shen, Gang
TI A new two-level QR code with visual cryptography scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR code; Two-level information storage; VCS; Low computational
   complexity; High error correction
AB The Quick Response (QR) code is designed for information storage recognizable by machine vision. With the popularity of QR code applications, the security of QR codes becomes hot issues concerned by many scholars. In this paper, a novel QR code with two-level information storage is designed to protect private messages. In the meantime, the public level can be directly decoded by any standard QR reader. In contrast to other studies, the computational complexity of the proposed scheme is reduced by combining with the theory of visual cryptography scheme (VCS). In addition, an important characteristic of the QR code, error correction capability, is preserved in this paper, guaranteeing the robustness to QR code damage. Experimental results and analysis show that the proposed scheme is both feasible and reasonably secure, further enriching the application fields and outperforming the previous schemes significantly.
C1 [Cheng, Yuqiao; Fu, Zhengxin; Yu, Bin; Shen, Gang] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Cheng, YQ (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
EM xdqiao2015@163.com
RI Fu, Zhengxin/AAD-7881-2019
OI Fu, Zhengxin/0000-0001-8587-0942
FU National Natural Science Foundation of China [61602513]; Outstanding
   Youth Foundation of Zhengzhou Information Science and Technology
   Institute [2016611303]
FX The authors thank the anonymous reviewers for their valuable comments.
   This work was supported in part by the National Natural Science
   Foundation of China under Grant No.61602513 and the Outstanding Youth
   Foundation of Zhengzhou Information Science and Technology Institute
   under Grant No.2016611303.
CR [Anonymous], 2006, 180042006 ISO IEC
   Arumugam S, 2014, DESIGN CODE CRYPTOGR, V71, P153, DOI 10.1007/s10623-012-9722-2
   Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Chen CS, 2017, MOBILE NETW APPL, V22, P383, DOI 10.1007/s11036-016-0772-y
   Chow YW, 2016, LECT NOTES COMPUT SC, V9722, P409, DOI 10.1007/978-3-319-40253-6_25
   Chu HK, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508408
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Krishna MB, 2016, WIRELESS PERS COMMUN, V90, P381, DOI 10.1007/s11277-016-3374-x
   Lin PY, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0155-0
   Lin PY, 2016, IEEE T IND INFORM, V12, P384, DOI 10.1109/TII.2015.2514097
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   [刘莺迎 Liu Yingying], 2016, [计算机应用研究, Application Research of Computers], V33, P3460
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Shyu SJ, 2015, IEEE T CIRC SYST VID, V25, P1557, DOI 10.1109/TCSVT.2015.2389372
   Tkachenko I, 2016, IEEE T INF FOREN SEC, V11, P571, DOI 10.1109/TIFS.2015.2506546
   Tuyls P, 2005, DESIGN CODE CRYPTOGR, V37, P169, DOI 10.1007/s10623-004-3816-4
   Wan S, 2018, J REAL-TIME IMAGE PR, V14, P25, DOI 10.1007/s11554-017-0678-3
   Wang JY, 2016, OPT QUANT ELECTRON, V48, DOI 10.1007/s11082-015-0296-x
   Weir Jonathan, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P196, DOI 10.1007/978-3-642-32205-1_17
   Xie X, 2017, P INT C MICRO EL SYS, DOI [10.1109/MEMSYS.2017.7863532, DOI 10.1109/MEMSYS.2017.7863532]
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2016, PROC IEEE MICR ELECT, P75, DOI 10.1109/MEMSYS.2016.7421561
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Yang CY, 2016, COMPUT STAND INTER, V47, P52, DOI 10.1016/j.csi.2016.03.001
   Yang CN, 2016, DEV VISUAL CRYPTOGRA, DOI [10.1007/978-3-319-44350-8_19, DOI 10.1007/978-3-319-44350-8_19]
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
NR 28
TC 13
Z9 13
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20629
EP 20649
DI 10.1007/s11042-017-5465-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300015
DA 2024-07-18
ER

PT J
AU Lassoued, I
   Zagrouba, E
AF Lassoued, Imen
   Zagrouba, Ezzeddine
TI Human actions recognition: an approach based on stable motion boundary
   fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video sequences; Human action recognition; Motion boundary; Stable
   regions
AB Automatic video action recognition have been a long-standing problem in computer vision. To obtain a scalable solution for actions recognition, it is important to have efficient visual representation of motions. In this paper, we propose a new visual representation for actions based in the body motion boundaries. The first step, a set of optical flow frames highlighting the principal motions in the poses is substracted. Then, the motion boundaries are computed from the previous optical flow frames. Maximum Stable Extremal Regions are then applied to motion boundaries maps in order to obtain Motion Stable Shape (MSS) features. Local descriptors were computed based on each detected MSS to capture motion patterns. To predict the classes of the different human actions, we have represented different descriptors with a bag-of-words (BOW) model and for classification, we use a non-linear support vector machine. We have performed a set of experiments on different datasets: Weizmann, KTH, UCF sport, UCF50 and Hollywood to prove the efficiency of our developed model. The achieved results improve the state-of-the-art on the KTH and Weizmann datasets and are comparable to state-of-the-art for UCF sport and UCF50 datasets.
C1 [Lassoued, Imen; Zagrouba, Ezzeddine] ISI, Limt Lab, Ariana, Tunisia.
C3 Universite de Tunis-El-Manar
RP Lassoued, I (corresponding author), ISI, Limt Lab, Ariana, Tunisia.
EM lassoued.imen@yahoo.fr; e.zagrouba@gmail.com
RI Zagrouba, Ezzeddine/D-7896-2014
OI Zagrouba, Ezzeddine/0000-0002-2574-9080; lassoued,
   imen/0000-0003-4312-6482
CR [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 5 INT C COMP SCI AUT
   [Anonymous], 00514828 NRIA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACM C MULT AUGSB GER
   [Anonymous], CVPR
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587730
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Jones S, 2012, PATTERN RECOGN LETT, V33, P446, DOI 10.1016/j.patrec.2011.05.001
   Kim TK, 2007, PROC CVPR IEEE, P124
   Klaser A., 2010, IEEE EUROPEAN C COMP, V6553, P219
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Lassoued I., 2011, Proceedings of the Seventh International Conference on Signal-Image Technology & Internet-Based Systems (SITIS 2011), P291, DOI 10.1109/SITIS.2011.65
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Nister David, 2006, CVPR
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sun J, 2010, IEEE INT CON MULTI, P322, DOI 10.1109/ICME.2010.5583046
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Thomas S, 2007, P 11 IEEE INT C COMP, P1
   Wang L, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P1
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Xin M, 2016, NEUROCOMPUTING, V178, P87, DOI 10.1016/j.neucom.2015.09.112
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Yuan JS, 2011, IEEE T PATTERN ANAL, V33, P1728, DOI 10.1109/TPAMI.2011.38
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
NR 44
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20715
EP 20729
DI 10.1007/s11042-017-5477-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300019
DA 2024-07-18
ER

PT J
AU Lin, FJ
   Chuang, JH
AF Lin, Fang-Ju
   Chuang, Jen-Hui
TI Image super-resolution by estimating the enhancement weight of self
   example and external missing patches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image super-resolution; Enhancement weight; Patch clustering; External
   superresolution
ID INTERPOLATION
AB Image super-resolution (SR) is the process of generating a high-resolution (HR) image using one or more low-resolution (LR) inputs. Many SR methods have been proposed, but generating the small-scale structure of an SR image remains a challenging task. We hence propose a single-image SR algorithm that combines the benefits of both internal and external SR methods. First, we estimate the enhancement weights of each LR-HR image patch pair. Next, we multiply each patch by the estimated enhancement weight to generate an initial SR patch. We then employ a method to recover the missing information from the high-resolution patches and create that missing information to generate a final SR image. We then employ iterative back-projection to further enhance visual quality. The method is compared qualitatively and quantitatively with several state-of-the-art methods, and the experimental results indicate that the proposed framework provides high contrast and better visual quality, particularly for non-smooth texture areas.
C1 [Lin, Fang-Ju; Chuang, Jen-Hui] Natl Chiao Tung Univ, Comp Sci, 1001 Univ Rd, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, FJ (corresponding author), Natl Chiao Tung Univ, Comp Sci, 1001 Univ Rd, Hsinchu, Taiwan.
EM fiona.cs97g@nctu.edu.tw
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], 2008, ACM T GRAPHIC, DOI DOI 10.1145/1409060.1409106
   Babacan SD, 2011, IEEE T IMAGE PROCESS, V20, P984, DOI 10.1109/TIP.2010.2080278
   Cao FL, 2016, IEEE T NEUR NET LEAR, V27, P1550, DOI 10.1109/TNNLS.2015.2512563
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Farsiu S, 2003, P IEEE INT C IM PROC
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Gong WG, 2015, INFORM SCIENCES, V325, P1, DOI 10.1016/j.ins.2015.07.004
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin FJ, 2015, IEEE IMAGE PROC, P2135, DOI 10.1109/ICIP.2015.7351178
   Nguyen TM, 2010, IEEE T NEURAL NETWOR, V21, P1326, DOI 10.1109/TNN.2010.2054109
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Timofte R, 2014, ADJUSTED ANCHORED NE, DOI [10.1007/978-3-319-16817-3_8, DOI 10.1007/978-3-319-16817-3_8]
   Timofte R, 2016, PROC CVPR IEEE, P1865, DOI 10.1109/CVPR.2016.206
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2012, IEEE T IMAGE PROCESS, V21, P4054, DOI 10.1109/TIP.2012.2199330
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zibetti MVW, 2007, IEEE T CIRC SYST VID, V17, P1288, DOI 10.1109/TCSVT.2007.903801
   Zuo WM, 2014, IEEE T IMAGE PROCESS, V23, P2459, DOI 10.1109/TIP.2014.2316423
NR 29
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19071
EP 19087
DI 10.1007/s11042-017-5350-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500009
DA 2024-07-18
ER

PT J
AU Abkenar, MR
   Ahmad, MO
AF Abkenar, Masoumeh Rezaei
   Ahmad, M. Omair
TI Salient region detection using efficient wavelet-based textural feature
   maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient region detection; Image color feature maps; Wavelet-based
   feature maps; Entropy-based feature map combination
ID OBJECT DETECTION; MODEL; ATTENTION
AB A salient region is part of an image that captures the highest level of attention by the human visual system. In this paper, a new salient region detection method is proposed by linearly combining the feature maps for the L, a and b color channels. Since, the wavelet transform is capable of providing a multi-scale spatial-frequency decomposition of the image, the color feature maps are obtained using this transform. A scheme is proposed whereby the channel feature maps are linearly combined. The weights for the linear combination are determined by making use of the entropy of the channel feature maps and a Gaussian kernel, utilizing the fact that the salient objects are generally clustered and scenecentric. The salient region is further refined by making use of the proximity of the pixels to the centers of gravity in the image feature map. Extensive simulations are conducted in order to evaluate the performance of the proposed saliency detection scheme by applying it to the natural images from several datasets. Experimental results show that the proposed method provides values of precision, recall and F-measure larger than and that of the mean absolute error smaller than those provided by other existing methods. The performance of the proposed salient region detection method is also evaluated on noisy images and it is shown to be robust against noise.
C1 [Abkenar, Masoumeh Rezaei; Ahmad, M. Omair] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Ahmad, MO (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1M8, Canada.
EM omair@ece.concordia.ca
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   Regroupement Strategique en Microelectronique du Quebec (ReSMiQ)
FX This work was supported in part by the Natural Sciences and Engineering
   Research Council (NSERC) of Canada and in part by the Regroupement
   Strategique en Microelectronique du Quebec (ReSMiQ).
CR Abkenar MR, 2016, IEEE INT SYMP CIRC S, P2719, DOI 10.1109/ISCAS.2016.7539154
   Abkenar MR, 2015, 2015 SIGNAL PROCESSING AND INTELLIGENT SYSTEMS CONFERENCE (SPIS), P78, DOI 10.1109/SPIS.2015.7422316
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   Arya R, 2016, MULTIMED TOOLS APPL, V75, P8267, DOI 10.1007/s11042-015-2750-y
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Fugal D.L., 2009, Conceptual Wavelets in Digital Signal Processing: An In-depth, Practical Approach for the Non-mathematician
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ko BC, 2006, J OPT SOC AM A, V23, P2462, DOI 10.1364/JOSAA.23.002462
   Koffka K., 1935, Principles of gestalt psychology
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu SW, 2016, MULTIMED TOOLS APPL, V75, P16699, DOI 10.1007/s11042-016-3903-3
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Merry R.J.E., 2005, Wavelet Theory and Applications: A Literature Study
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Sun L, 2016, MULTIMED TOOLS APPL, V75, P667, DOI 10.1007/s11042-014-2314-6
   Tian Q, 2001, J ELECTRON IMAGING, V10, P835, DOI 10.1117/1.1406945
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xu X, 2016, MULTIMED TOOLS APPL, V75, P2667, DOI 10.1007/s11042-015-2570-0
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yuan YX, 2015, IEEE T MED IMAGING, V34, P2046, DOI 10.1109/TMI.2015.2418534
   Zhang GX, 2009, COMPUT GRAPH FORUM, V28, P1897, DOI 10.1111/j.1467-8659.2009.01568.x
   Zhang L., 2013, Selective visual attention: Computational models and applications
   Zhou CB, 2015, MULTIMED TOOLS APPL, V74, P5623, DOI 10.1007/s11042-014-1871-z
NR 38
TC 2
Z9 2
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16291
EP 16317
DI 10.1007/s11042-017-5199-3
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300014
DA 2024-07-18
ER

PT J
AU Hanilçi, C
AF Hanilci, Cemal
TI Linear prediction residual features for automatic speaker verification
   anti-spoofing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker verification; Anti-spoofing; Countermeasure; Linear prediction
   residual
ID COUNTERMEASURES; BIOMETRICS
AB Automatic speaker verification (ASV) systems are highly vulnerable against spoofing attacks. Anti-spoofing, determining whether a speech signal is natural/genuine or spoofed, is very important for improving the reliability of the ASV systems. Spoofing attacks using the speech signals generated using speech synthesis and voice conversion have recently received great interest due to the 2015 edition of Automatic Speaker Verification Spoofing and Countermeasures Challenge (ASVspoof 2015). In this paper, we propose to use linear prediction (LP) residual based features for anti-spoofing. Three different features extracted from LP residual signal were compared using the ASVspoof 2015 database. Experimental results indicate that LP residual phase cepstral coefficients (LPRPC) and LP residual Hilbert envelope cepstral coefficients (LPRHEC) obtained from the analytic signal of the LP residual yield promising results for anti-spoofing. The proposed features are found to outperform standard Mel-frequency cepstral coefficients (MFCC) and Cosine Phase (CosPhase) features. LPRPC and LPRHEC features give the smallest equal error rates (EER) for eight spoofing methods out of ten spoofing attacks in comparison to MFCC and CosPhase features.
C1 [Hanilci, Cemal] Bursa Tech Univ, Dept Elect & Elect Engn, Bursa, Turkey.
C3 Bursa Technical University
RP Hanilçi, C (corresponding author), Bursa Tech Univ, Dept Elect & Elect Engn, Bursa, Turkey.
EM cemal.hanilci@btu.edu.tr
RI Hanilci, Cemal/S-4967-2016
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [115E916]
FX This work was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK) (project #115E916).
CR [Anonymous], 2015, INT CONF BIOMETR THE
   [Anonymous], 2010, THEORY APPL DIGITAL
   [Anonymous], 2016, SPEAK OD WORKSH
   Bhaysar HN, 2016, INTERSPEECH, P155, DOI 10.21437/Interspeech.2016-1002
   Bonastre J.F., 2007, INTERSPEECH, P2053
   De Leon PL, 2010, INT CONF ACOUST SPEE, P1798, DOI 10.1109/ICASSP.2010.5495413
   Evans N, 2014, ADV COMPUT VIS PATT, P125, DOI 10.1007/978-1-4471-6524-8_7
   Fukada T., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P137, DOI 10.1109/ICASSP.1992.225953
   Hanilçi C, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2057
   Hautamäki RG, 2013, INTERSPEECH, P930
   Hautamäki RG, 2015, SPEECH COMMUN, V72, P13, DOI 10.1016/j.specom.2015.05.002
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Janicki A, 2017, MULTIMED TOOLS APPL, V76, P9017, DOI 10.1007/s11042-016-3508-x
   Janicki A, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2077
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kinnunen T, 2012, INT CONF ACOUST SPEE, P4401, DOI 10.1109/ICASSP.2012.6288895
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Kinnunen T, 2009, PATTERN RECOGN LETT, V30, P341, DOI 10.1016/j.patrec.2008.11.007
   Lavrentyeva G, 2017, COMM COM INF SC, V661, P172, DOI 10.1007/978-3-319-52920-2_17
   Leon PLD, 2010, P OD, P28
   MAKHOUL J, 1975, P IEEE, V63, P561, DOI 10.1109/PROC.1975.9792
   Martin A., 1997, PROC EURO SPEECH 97, V4, P1895
   Murty KR, 2006, IEEE SIGNAL PROC LET, V13, P52, DOI 10.1109/LSP.2005.860538
   Nandi D, 2017, COMPUT SPEECH LANG, V41, P68, DOI 10.1016/j.csl.2016.06.002
   Novoselov S, 2016, INT CONF ACOUST SPEE, P5475, DOI 10.1109/ICASSP.2016.7472724
   Pati D, 2011, INT J SPEECH TECHNOL, V14, P49, DOI 10.1007/s10772-010-9087-8
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Sahidullah M, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2087
   Sanchez J, 2015, IEEE T INF FOREN SEC, V10, P810, DOI 10.1109/TIFS.2015.2398812
   Villalba J, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2067
   Villoria J, 2010, PORTA LINGUARUM, P131
   Wang LB, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2092
   Wu Z., 2012, INTERSPEECH, ISCA, P1700
   Wu ZZ, 2017, IEEE J-STSP, V11, P588, DOI 10.1109/JSTSP.2017.2671435
   Wu ZZ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2037
   Wu ZZ, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.17
   Wu ZZ, 2015, SPEECH COMMUN, V66, P130, DOI 10.1016/j.specom.2014.10.005
   Xiao X, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P2052
NR 39
TC 7
Z9 8
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 16099
EP 16111
DI 10.1007/s11042-017-5181-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300005
DA 2024-07-18
ER

PT J
AU Wu, MY
   Yu, MC
   Leu, JS
   Chen, SK
AF Wu, Min-Ying
   Yu, Min-Chieh
   Leu, Jenq-Shiou
   Chen, Sheng-Kai
TI Enhancing security and privacy of images on cloud by histogram shifting
   and secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud; Invisible digital watermarking; Histogram shifting; Reversible
   data hiding; Secret sharing
AB In contemporary society, people can easily use any smart device at hand to capture images of scenery and upload them to cloud storage. Cloud storage is widely used for storing user generated multimedia content. However, the risk of potential private data leakage exists because cloud storage is normally in a public domain. To protect the privacy information of images on cloud storage, we propose an integrated scheme involving invisible watermarking, masking and secret sharing methods. The histogram modification-based scheme can achieve reversible data hiding to ensure the integrity and confidentiality of image data. Additionally, a secret sharing scheme was used to further improve the security of data access. The evaluation results show that the proposed system may prevent malicious users from accessing private images.
C1 [Wu, Min-Ying; Yu, Min-Chieh; Leu, Jenq-Shiou; Chen, Sheng-Kai] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Leu, JS (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
EM M10202127@mail.ntust.edu.tw; D10002103@mail.ntust.edu.tw;
   jsleu@mail.ntust.edu.tw; M10302147@mail.ntust.edu.tw
OI Leu, Jenq-Shiou/0000-0001-7197-9912
CR Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Gracia-Tinedo R, 2013, IEEE INT CONF CLOUD, P301, DOI 10.1109/CLOUD.2013.25
   Hamzaoui R., 2006, FRACTAL IMAGE COMPRE, P168
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Lee SK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1321, DOI 10.1109/icme.2006.262782
   Liu DY, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P748, DOI 10.1109/ICYCS.2008.61
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang C, 2013, IEEE T EMERG TOP COM, V1, P166, DOI 10.1109/TETC.2013.2273797
   Wang HG, 2014, IEEE COMMUN MAG, V52, P73, DOI 10.1109/MCOM.2014.6766088
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HT, 2015, IEEE SIGNAL PROC LET, V22, P81, DOI 10.1109/LSP.2014.2346989
   Zhang L, 2015, INT CON DISTR COMP S, P308, DOI 10.1109/ICDCS.2015.39
   Zhou L, 2014, IEEE COMMUN MAG, V52, P66, DOI 10.1109/MCOM.2014.6766087
NR 15
TC 3
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17285
EP 17305
DI 10.1007/s11042-017-5306-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300058
DA 2024-07-18
ER

PT J
AU Zhao, HM
   Dai, QY
   Ren, JC
   Wei, WG
   Xiao, YY
   Li, CY
AF Zhao, Huimin
   Dai, Qingyun
   Ren, J. C.
   Wei, Wenguo
   Xiao, Yinyin
   Li, Chunying
TI Robust information hiding in low-resolution videos with quantization
   index modulation in DCT-CS domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video information hiding; Statistical transparency; Compressive sensing;
   Quantization index modulation; Image fusion
ID WATERMARKING
AB Video information hiding and transmission over noisy channels leads to errors on video and degradation of the visual quality notably. In this paper, a video signal fusion scheme is proposed to combine sensed host signal and the hidden signal with quantization index modulation (QIM) technology in the compressive sensing (CS) and discrete cosine transform (DCT) domain. With quantization based signal fusion, a realistic solution is provided to the receiver, which can improve the reconstruction video quality without requiring significant extra channel resource. The extensive experiments have shown that the proposed scheme can effectively achieve the better trade-off between robustness and statistical invisibility for video information hiding communication. This will be extremely important for low-resolution video analytics and protection in big data era.
C1 [Zhao, Huimin; Xiao, Yinyin; Li, Chunying] Guangdong Polytech Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Zhao, Huimin; Dai, Qingyun; Ren, J. C.; Wei, Wenguo; Xiao, Yinyin; Li, Chunying] Guangzhou Key Lab Digital Content Proc & Secur Te, Guangzhou, Guangdong, Peoples R China.
   [Dai, Qingyun; Wei, Wenguo] Guangdong Polytech Normal Univ, Sch Elect & Informat, Guangzhou, Guangdong, Peoples R China.
   [Ren, J. C.] Univ Strathclyde, Dept Elect & Elect Engn, Glasgow, Lanark, Scotland.
C3 Guangdong Polytechnic Normal University; Guangdong Polytechnic Normal
   University; University of Strathclyde
RP Zhao, HM (corresponding author), Guangdong Polytech Normal Univ, Sch Comp Sci, Guangzhou, Guangdong, Peoples R China.; Zhao, HM (corresponding author), Guangzhou Key Lab Digital Content Proc & Secur Te, Guangzhou, Guangdong, Peoples R China.
EM zhaohuimin66@yahoo.com
FU National Natural Science Foundation of China [61672008]; Guangdong
   Provincial Application-oriented Technical Research and Development
   Special fund project [2016B010127006, 2015B010131017]; Natural Science
   Foundation of Guangdong Province [2016A030311013]; Scientific and
   Technological Projects of Guangdong Province [2017A050501039]
FX This work was supported by the National Natural Science Foundation of
   China (61672008), Guangdong Provincial Application-oriented Technical
   Research and Development Special fund project (2016B010127006,
   2015B010131017), the Natural Science Foundation of Guangdong Province
   (2016A030311013), and Scientific and Technological Projects of Guangdong
   Province (2017A050501039).
CR [Anonymous], 2016, IEEE T CYBERNETICS
   Barni M, 2005, IEEE T MULTIMEDIA, V7, P23, DOI 10.1109/TMM.2004.840594
   Biswas S, 2005, IEEE T INSTRUM MEAS, V54, P1853, DOI 10.1109/TIM.2005.855084
   Braci S, 2008, IEEE P MMSP
   Braci S, 2011, SIGNAL PROCESS-IMAGE, V26, P567, DOI 10.1016/j.image.2011.07.006
   Cachin C, 1998, LECT NOTES COMPUT SC, V1525, P306
   Calderbank Robert, 2009, TECHNICAL REPORT
   Candes E. J., 2005, TECHNICAL REPORT
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen WM, 2011, IET IMAGE PROCESS, V5, P349, DOI 10.1049/iet-ipr.2009.0362
   Cox I., 2001, Digital Watermarking
   Davenport MA, 2010, IEEE J-STSP, V4, P445, DOI 10.1109/JSTSP.2009.2039178
   Delpha C, 2014, LECT NOTES COMPUT SC, V8389, P409, DOI 10.1007/978-3-662-43886-2_29
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Eggers JJ, 2003, IEEE T SIGNAL PROCES, V51, P1003, DOI 10.1109/TSP.2003.809366
   Fowler JE, 2011, EUR SIGNAL PR CONF, P564
   Gao P., 2006, COMPUT APPL SOFTW, V23, P134
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P1344, DOI 10.1109/TIP.2017.2652730
   Han J, 2017, EP Patent App, Patent No. [EP20150719863, 20150719863]
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Hou XS, 2014, NEUROCOMPUTING, V133, P358, DOI 10.1016/j.neucom.2013.12.047
   Hsu Daniel J, 2009, Proc. of Neural Information Processing Systems, P772
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Jiang JM, 2011, IEEE T BROADCAST, V57, P646, DOI 10.1109/TBC.2011.2158252
   Komaty A, 2012, IEEE INT C TEL ICT 2
   Le Guelvouit G., 2005, IEEE C AC SPEECH SIG
   Masoum A, 2013, PROCEDIA COMPUT SCI, V21, P207, DOI 10.1016/j.procs.2013.09.028
   Mostefa IB, 2011, SIGNAL PROCESS-IMAGE, V26, P194, DOI 10.1016/j.image.2010.12.003
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Qin C, 2013, INT J INNOV COMPUT I, V9, P599
   Rauhut H, 2008, IEEE T INFORM THEORY, V54, P2210, DOI 10.1109/TIT.2008.920190
   Ren JC, 2014, J VIS COMMUN IMAGE R, V25, P1558, DOI 10.1016/j.jvcir.2014.07.001
   Sheikh M.A., 2007, IEEE INT C IM PROC I
   Tsaig Y, 2006, SIGNAL PROCESS, V86, P533, DOI 10.1016/j.sigpro.2005.05.028
   Voloshynovskiy S, 2011, P SPIE SECURITY WATE, V4134, P23
   Wang Q, 2014, IEEE T IMAGE PROCESS, V23, P1317, DOI 10.1109/TIP.2014.2298980
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Ward R, 2009, IEEE T INFORM THEORY, V55, P5773, DOI 10.1109/TIT.2009.2032712
   Zabalza J, 2014, IEEE T AERO ELEC SYS, V50, P2304, DOI 10.1109/TAES.2014.130082
   Zhang BJ, 2015, SECUR COMMUN NETW, V8, P2416, DOI 10.1002/sec.828
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P1223, DOI 10.1109/TIFS.2011.2159208
   [赵春晖 Zhao Chunhui], 2012, [自动化学报, Acta Automatica Sinica], V38, P609
   Zhao HM, 2016, MULTIDIM SYST SIGN P, V27, P891, DOI 10.1007/s11045-015-0371-2
   [赵慧民 Zhao Huimin], 2013, [电子学报, Acta Electronica Sinica], V41, P1153
   Zhou Y, 2016, COGN COMPUT, V8, P877, DOI 10.1007/s12559-016-9424-6
NR 46
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18827
EP 18847
DI 10.1007/s11042-017-5223-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900063
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jiang, B
   Meng, HQ
   Zhao, J
   Ma, XL
   Jiang, SY
   Wang, L
   Zhou, Y
   Ru, Y
   Ru, C
AF Jiang, Bo
   Meng, Hongqi
   Zhao, Jian
   Ma, Xiaolei
   Jiang, Siyu
   Wang, Lin
   Zhou, Yan
   Ru, Yi
   Ru, Chao
TI Single image fog and haze removal based on self-adaptive guided image
   filter and color channel information of sky region
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fog and haze removal; Color correction; Main boundaries extraction
AB In this paper, we report an effective algorithm for removing both fog and haze from a single image. Existing algorithms based on atmospheric degeneration model generally lead to non-definite solutions for the haze and thick fog images, though they are very efficient for thin fog images. In general, as the algorithms based on vision enhancement cannot automatically adjust weight coefficient for the different structure images, the excessive or inadequate enhancement may emerge. In this paper an original degradation image is primarily segmented into the sky and non-sky regions, and then the main boundaries of non-sky region are extracted using L (0) smoothing filter. So our vision enhancement algorithm automatically adjusts weight coefficient according to various structure images. At the stage of vision enhancement, guided image filter famous for its excellent boundary preservation is adopted. As for haze image, the color channel information scattered by haze particles can be obtained in the sky region to make an effective color correction. Both the subjective and objective evaluations of experimental results demonstrate that the proposed algorithm has more outstanding recovery effect for haze and thick fog images. Moreover, the proposed algorithm can judge fog or haze image, which is a by-product of this research.
C1 [Jiang, Bo; Meng, Hongqi; Zhao, Jian; Wang, Lin; Zhou, Yan; Ru, Yi; Ru, Chao] Northwest Univ, Sch Informat & Technol, Xian 710127, Shaanxi, Peoples R China.
   [Ma, Xiaolei] Emory Univ, Dept Phys, Atlanta, GA 30322 USA.
   [Jiang, Siyu] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Northwest University Xi'an; Emory University; Xi'an Jiaotong University
RP Jiang, B (corresponding author), Northwest Univ, Sch Informat & Technol, Xian 710127, Shaanxi, Peoples R China.
EM jiangbo@nwu.edu.cn
RI Zhao, Jian/GNM-6340-2022; Jiang, siyu/KJK-9483-2024; Zhou,
   Yan/AFN-5099-2022
OI Zhao, Jian/0000-0002-0619-7866; 
FU National Natural Science Foundation of China [41601353, 61503300];
   Foundation of Key Laboratory of Space Active Opto-Electronics Technology
   of Chinese Academy of Sciences [AOE-2016-A02]; Scientific Research
   Program - Shaanxi Provincial Education Department [16JK1765]; Natural
   Science Basic Research Plan in Shaanxi Province of China [2014JQ8327,
   2017JQ4003]; Foundation of State Key Laboratory of Transient Optics and
   Photonics, Chinese Academy of Sciences [SKLST201614]
FX This work was supported by National Natural Science Foundation of China
   (No. 41601353, 61503300), and Foundation of Key Laboratory of Space
   Active Opto-Electronics Technology of Chinese Academy of Sciences (No.
   AOE-2016-A02), and Scientific Research Program Funded by Shaanxi
   Provincial Education Department (No. 16JK1765), and Natural Science
   Basic Research Plan in Shaanxi Province of China (No. 2014JQ8327 and
   2017JQ4003) and Foundation of State Key Laboratory of Transient Optics
   and Photonics, Chinese Academy of Sciences (No. SKLST201614).
CR Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu ZZ, 2015, J SYST ENG ELECTRON, V26, P1070, DOI 10.1109/JSEE.2015.00116
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Jiang B, 2015, ELECTRON LETT, V51, P2105, DOI 10.1049/el.2015.2297
   Jiang B, 2015, INT CONF SOFTW ENG, P280, DOI 10.1109/ICSESS.2015.7339055
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Khan SH, 2016, IEEE T PATTERN ANAL, V38, P431, DOI 10.1109/TPAMI.2015.2462355
   Li B, 2014, IET COMPUT VIS, V8, P131, DOI 10.1049/iet-cvi.2013.0011
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Yu T, 2015, IET IMAGE PROCESS, V9, P725, DOI 10.1049/iet-ipr.2015.0087
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 16
TC 6
Z9 7
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13513
EP 13530
DI 10.1007/s11042-017-4973-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900020
DA 2024-07-18
ER

PT J
AU Kye, H
   Lee, SH
   Lee, J
AF Kye, Heewon
   Lee, Se Hee
   Lee, Jeongjin
TI CPU-based real-time maximim intensity projection via fast matrix
   transposition using parallelization operations with AVX instruction set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Maximum intensity projection; Matrix transposition; Parallelization; AVX
   instruction set; Volume rendering
ID ALGORITHM
AB Rapid visualization is essential for maximum intensity projection (MIP) rendering, since the acquisition of a perceptual depth can require frequent changes of a viewing direction. In this paper, we propose a CPU-based real-time MIP method that uses parallelization operations with the AVX instruction set. We improve shear-warp based MIP rendering by resolving the bottle-neck problems of the previous method of a matrix transposition. We propose a novel matrix transposition method using the AVX instruction set to minimize bottle-neck problems. Experimental results show that the speed of MIP rendering on general CPU is faster than 20 frame-per-second (fps) for a 512 x 512 x 552 volume dataset. Our matrix transposition method can be applied to other image processing algorithms for faster processing.
C1 [Kye, Heewon] Hansung Univ, Div Comp Engn, 116 Samseongyoro 16Gil, Seoul 136792, South Korea.
   [Lee, Se Hee] Hansung Univ, Dept Informat Syst Engn, 116 Samseongyoro 16Gil, Seoul 136792, South Korea.
   [Lee, Jeongjin] Soongsil Univ, Sch Comp Sci & Engn, 369 Sangdo Ro, Seoul 156743, South Korea.
C3 Hansung University; Hansung University; Soongsil University
RP Lee, J (corresponding author), Soongsil Univ, Sch Comp Sci & Engn, 369 Sangdo Ro, Seoul 156743, South Korea.
EM kuei@hansung.ac.kr; twoh25@naver.com; leejeongjin@ssu.ac.kr
OI Lee, Se Hee/0000-0003-4708-8508
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and Future Planning
   [2017R1A2B3011475]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Science, ICT and Future Planning (No. 2017R1A2B3011475).
CR Belina S, 2009, COLLEGIUM ANTROPOL, V33, P43
   Chen KH., 2012, SAE Int., V1, P1, DOI DOI 10.4271/2012-01-0645
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dachille F., 1998, SIGGRAPHEUROGRAPHICS, P69
   Fang LF, 2002, MAGNET RESON MED, V47, P696, DOI 10.1002/mrm.10114
   Kiefer G, 2006, IEEE T INF TECHNOL B, V10, P385, DOI 10.1109/TITB.2005.863871
   Kye Heewon, 2009, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V12, P512
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   Lacroute P, 1995, CSLTR95678
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   McFarlin DanielS., 2011, Proceedings of the international conference on Supercomputing, ICS '11, P265
   Mensmann J, 2010, GRAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS THEORY AND APPLICATIONS, P190
   Mora B, 2005, ACM T GRAPHIC, V24, P1392, DOI 10.1145/1095878.1095886
   Mroz L., 1999, Data Visualization '99. Proceedings of the Joint EUROGRAPHICS and IEEE TCVG Symposium on Visualization, P135
   Mroz L, 2000, COMPUT GRAPH FORUM, V19, pC341, DOI 10.1111/1467-8659.00426
   Pekar D., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P135
   REZK-SALAMA C., 2000, EGSIGGRAPH WORKSHOP, P109, DOI DOI 10.1145/346876.348238
   Sabella P., 1988, Computer Graphics, V22, P51, DOI 10.1145/378456.378476
   SCHREINER S, 1993, IEEE T MED IMAGING, V12, P50, DOI 10.1109/42.222666
   Vollrath JE, 2005, P VIS MOD VIS, P391
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zekri Ahmed Sherif, 2014, International Journal of Computer Science & Information Technology, V6, P67, DOI 10.5121/ijcsit.2014.6305
   Zhao K, 2014, COMM COM INF SC, V474, P228
NR 27
TC 2
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15971
EP 15994
DI 10.1007/s11042-017-5171-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200066
DA 2024-07-18
ER

PT J
AU Ryoo, M
   Kim, N
   Park, K
AF Ryoo, Miohk
   Kim, Namjung
   Park, Kyoungju
TI Visual analysis of soccer players and a team
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soccer data; Visual analysis; Pixel grid visualization; Player
   visualization; Team visualization
ID PERFORMANCE; VISUALIZATION; POSITION
AB Soccer is one of the most entertaining and popular sports around the world, and is also very interesting from a scientific point of view. Most of the scientific research on soccer is related to matches and game play analysis. In this paper, we propose a novel system for team performance analysis and visualization in terms of the structure of a team, and concentrate on cause-and-effect relationships between players and their teams based on player transfer data. Our system visualizes the individual player performance, team characteristics, comparisons between teams, and time varying changes of the team characteristics. The analyzed data are presented in two different ways (1) the system creates a pixel-grid visualization that presents the distinct characteristics of each player in a team. (2) A horizon graph is used to display the changes in team characteristics over time due to player transfers. This approach facilitates understanding the influence of player transfers on team characteristics in a very simple and straightforward manner.
C1 [Ryoo, Miohk; Kim, Namjung] Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Seoul, South Korea.
   [Park, Kyoungju] Chung Ang Univ, Sch Integrat Engn, Seoul, South Korea.
C3 Chung Ang University; Chung Ang University
RP Ryoo, M (corresponding author), Chung Ang Univ, Grad Sch Adv Imaging Sci Multimedia & Film, Seoul, South Korea.
EM vogue901@cau.ac.kr; sogalman@naver.com; kjpark@cau.ac.kr
FU Mid-Career Researcher Program through an NRF grant - MEST
   [NRF-2016R1A2B4016239]
FX This work (NRF-2016R1A2B4016239) was supported by the Mid-Career
   Researcher Program through an NRF grant funded by the MEST.
CR [Anonymous], 2010, TACTFOOT SOCCER COAC
   [Anonymous], 2015, FIFA TMS BIG 5 TRANS
   [Anonymous], 2014, FIFA TMS BIG 5 TRANS
   [Anonymous], 2014, FINANCIAL FAIR PLAY
   [Anonymous], P MIT SLOAN SPORTS A
   Bernard J, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 3, P75, DOI 10.5220/0006116400750087
   Berthold M.R., 2007, KNIME: The Konstanz Information Miner
   Chapman S, 2012, SOCCER COACHING MANU
   Chung DHS, 2016, IEEE COMPUT GRAPH, V36, P72, DOI 10.1109/MCG.2015.25
   Di Salvo V, 2007, INT J SPORTS MED, V28, P222, DOI 10.1055/s-2006-924294
   Duarte R, 2013, J SYST SCI COMPLEX, V26, P62, DOI 10.1007/s11424-013-2290-3
   Fonseca S, 2013, INT J PERF ANAL SPOR, V13, P179, DOI 10.1080/24748668.2013.11868640
   Fujimura A., 2005, Systems and Computers in Japan, V36, P49, DOI 10.1002/scj.20254
   Gudmundsson J., 2012, Proceedings of the 20th International Conference on Advances in Geographic Information Systems pags, P566
   Jacques Bertin, 1983, SEMIOLOGY GRAPHICS D
   Janetzko H, 2014, IEEE CONF VIS ANAL, P13, DOI 10.1109/VAST.2014.7042477
   Kang CH, 2006, ICDM 2006: Sixth IEEE International Conference on Data Mining, Workshops, P377
   Kim S., 2004, Nonlinear Anal Model Control, V9, P233, DOI [DOI 10.15388/NA.2004.9.3.15154, 10.15388/NA.2004.9.3.15154]
   Lago-Peñas C, 2010, J SPORT SCI MED, V9, P288
   Legg PA, 2012, COMPUT GRAPH FORUM, V31, P1255, DOI 10.1111/j.1467-8659.2012.03118.x
   Memmert D, 2017, SPORTS MED, V47, P1, DOI 10.1007/s40279-016-0562-5
   Nakanishi R, 2010, LECT NOTES ARTIF INT, V5949, P228, DOI 10.1007/978-3-642-11876-0_20
   Page M., 2006, CGIV '06, P24, DOI DOI 10.1109/CGIV.2006.85
   Pena J.L., 2012, NETWORK THEORY ANAL
   Perin C, 2013, IEEE T VIS COMPUT GR, V19, P2506, DOI 10.1109/TVCG.2013.192
   Pileggi H, 2012, IEEE T VIS COMPUT GR, V18, P2819, DOI 10.1109/TVCG.2012.263
   Robertson PK, 1994, P SCI VIS OV METH TE, P179
   Rusu A, 2011, IEEE INT CONF INF VI, P194, DOI 10.1109/IV.2011.57
   Spence R, 2001, INFORM VISUALIZATION, P14
   Stein M, 2017, DATA, V2, DOI 10.3390/data2010002
   Taki T, 2000, COMPUTER GRAPHICS INTERNATIONAL 2000, PROCEEDINGS, P227, DOI 10.1109/CGI.2000.852338
   Ward MO, 2010, INF VIS, V1, P194
NR 32
TC 14
Z9 15
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15603
EP 15623
DI 10.1007/s11042-017-5137-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200051
DA 2024-07-18
ER

PT J
AU Geng, WJ
   Zhang, CL
   Wu, GS
AF Geng, Wenjing
   Zhang, Chunlong
   Wu, Gangshan
TI Adaptive video object proposals by a context-aware model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-object proposals; Spatial and temporal windows; Adaptive
   context-aware model; Proposal consistency; Multi-object dataset
ID REPRESENTATION; ACCURATE
AB Most previous works focus on image object proposals while few on video object proposals. Besides, the existing explorations about video object proposals mainly concentrate on localizing the dominant object. In this paper, we aim at exploring a uniform framework for proposing multi-objects in videos no matter they are in the foreground or background. The method is derived from image object proposals, and makes best use of video characteristics. To achieve this task, we propose an adaptive context-aware model for video object proposals. First, spatial candidate windows are generated by the image method for acquiring the adequate bounding box samples. Temporal boxes are calculated by the motion based mapping. Considering the mapping loss, we define a box confidence coefficient contributing to keeping the proposal consistency and restraining the motion blur. The output proposal bounding boxes are ranked based on the scores calculated by the weighted scoring system. The proposed method is separately evaluated on the proposed multi-object dataset and the public dataset. The results compared with several state-of-the-arts show that our method has the most satisfactory overall performance for multi-object proposals in videos.
C1 [Geng, Wenjing; Zhang, Chunlong; Wu, Gangshan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University
RP Wu, GS (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM jenngeng@gmail.com; clzhang.nju@gmail.com; gswu@nju.edu.cn
RI zhang, chunlong/KQU-9361-2024
FU National Science Foundation of China [61321491]; Collaborative
   Innovation Center of Novel Software Technology and Industrialization
FX This work is supported by the National Science Foundation of China under
   Grant No. 61321491, and Collaborative Innovation Center of Novel
   Software Technology and Industrialization.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Bai TX, 2015, IEEE T CYBERNETICS, V45, P663, DOI 10.1109/TCYB.2014.2332279
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chavali N, 2016, P IEEE C COMP VIS PA, P1
   Chen XZ, 2015, PROC CVPR IEEE, P2587, DOI 10.1109/CVPR.2015.7298874
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Cheng ZY, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1069, DOI 10.1145/2911451.2914765
   Cheng ZY, 2016, MULTIMEDIA SYST, V22, P509, DOI 10.1007/s00530-014-0432-7
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Choi MK, 2016, MULTIMED TOOLS APPL, V75, P2453, DOI 10.1007/s11042-015-2876-y
   Chu WT, 2015, IEEE T MULTIMEDIA, V17, P201, DOI 10.1109/TMM.2014.2383616
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Endres I, 2010, LECT NOTES COMPUT SC, V6315, P575, DOI 10.1007/978-3-642-15555-0_42
   Geng WJ, 2016, INT C PAR DISTRIB SY, P1203, DOI [10.1109/ICPADS.2016.158, 10.1109/ICPADS.2016.0160]
   Geng WJ, 2016, IEEE IJCNN, P4154, DOI 10.1109/IJCNN.2016.7727741
   Ghodrati A, 2015, IEEE I CONF COMP VIS, P2578, DOI 10.1109/ICCV.2015.296
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Gygli M, 2015, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2015.7298928
   Hayder Z, 2016, P IEEE C COMP VIS PA, P1
   Heilbron FC, 2016, PROC CVPR IEEE, P1914, DOI 10.1109/CVPR.2016.211
   Hosang Jan, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hu JF, 2016, LECT NOTES COMPUT SC, V9905, P280, DOI 10.1007/978-3-319-46448-0_17
   Hua Y, 2015, IEEE I CONF COMP VIS, P3092, DOI 10.1109/ICCV.2015.354
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jang WD, 2016, PROC CVPR IEEE, P696, DOI 10.1109/CVPR.2016.82
   Jing Liu, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P199, DOI 10.1007/978-3-319-27671-7_17
   Kong T., 2016, Proceedings of Computer Vision and Pattern Recognition (CVPR), P1
   Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liang YC, 2015, I C COMM SOFTW NET, P1, DOI [10.1109/ICCSN.2015.7296116, 10.1109/MWSYM.2015.7166918]
   Liu J, 2016, NEUROCOMPUTING, V236, P134
   Liu JX, 2016, ACSR ADV COMPUT, V68, P1, DOI 10.1145/3185504
   Liu YJ, 2016, J CHEM-NY, V2016, DOI 10.1155/2016/6903524
   Lowry S, 2016, IEEE T ROBOT, V32, P1, DOI 10.1109/TRO.2015.2496823
   Manen S, 2013, IEEE I CONF COMP VIS, P2536, DOI 10.1109/ICCV.2013.315
   Meng JJ, 2016, PROC CVPR IEEE, P1039, DOI 10.1109/CVPR.2016.118
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Oneata D, 2014, LECT NOTES COMPUT SC, V8691, P737, DOI 10.1007/978-3-319-10578-9_48
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Pont-Tuset J, 2016, IEEE T PATTERN ANAL, V38, DOI [10.1109/TPAMI.2015.2481406, 10.1109/TPAMI.2016.2537320]
   Pont-Tuset J, 2015, IEEE I CONF COMP VIS, P1546, DOI 10.1109/ICCV.2015.181
   Rahtu E, 2011, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2011.6126351
   Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310
   Savelonas MA, 2015, MULTIMED TOOLS APPL, V74, P11783, DOI 10.1007/s11042-014-2267-9
   Sharir Gilad., 2012, Proceedings of the IEEE Workshops on Comput. Vision and Pattern Recognition, P9
   Sun DQ, 2014, INT J COMPUT VISION, V106, P115, DOI 10.1007/s11263-013-0644-x
   Sünderhauf N, 2015, ROBOTICS: SCIENCE AND SYSTEMS XI
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Van den Bergh M, 2013, IEEE I CONF COMP VIS, P377, DOI 10.1109/ICCV.2013.54
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P4185, DOI 10.1109/TIP.2015.2460013
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Xiao F., 2016, 2016 IEEE OES CHIN O, P1, DOI [10.1109/COA. 2016.7535797, DOI 10.1109/COA.2016.7535797]
   Xu XL, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/714530
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang HW, 2016, PROC CVPR IEEE, P2809, DOI 10.1109/CVPR.2016.307
   Zhang JG, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0630-4
   Zhang YD, 2016, EXPERT SYST, V33, P239, DOI 10.1111/exsy.12146
   Zhou Y, 2015, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR.2015.7298953
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 68
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10589
EP 10614
DI 10.1007/s11042-017-4561-9
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900013
DA 2024-07-18
ER

PT J
AU Hu, ZG
   Zhang, QQ
AF Hu, Zhiguo
   Zhang, Qiqiang
TI A new approach for packet loss measurement of video streaming and its
   application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Packet loss; Measurement; User_data field; Video quality
ID QUALITY; TRANSMISSION
AB Packet loss is of great importance as a metric that characterizes the network's performance, and is crucial for video applications, congestion control and routing. Most of existing measurement tools can indicate the packet loss of network links instead of the actual packet loss of individual application. On the other hand, because occurrence of packet loss behavior is relatively rare and its duration is short, active measuring methods need to inject a large number of packets and run for a long time for reporting accurate estimates, which would introduce additional intrusiveness to the network and perturb user traffic. In this paper, we present a new packet loss estimation technique by making use of user_data field of video, which is less intrusive since it does not affect video playing and does not need to inject extra probing stream. It can also provide the packet loss detailed information of I,P,B frames. The accuracy of the algorithm has been evaluated with both simulations and experiments over real-world Internet paths. In addition, we analyze the video quality distortion caused by packet loss of different frame types, and a real-time video quality monitoring system is built.
C1 [Hu, Zhiguo] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.
   [Hu, Zhiguo; Zhang, Qiqiang] Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
C3 Shanxi University; Tongji University
RP Hu, ZG (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.; Hu, ZG (corresponding author), Tongji Univ, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
EM huzhiguotj@163.com
CR Akbari B, 2008, MULTIMEDIA SYST, V13, P345, DOI 10.1007/s00530-007-0097-6
   [Anonymous], 1998, 2330 RFC
   [Anonymous], 1996, ITU-T Recommendation
   [Anonymous], 2001, MPEG4
   [Anonymous], THESIS
   [Anonymous], 2005, 3984 RFC IETF
   [Anonymous], 1990, 1191 RFC
   Belyaev E, 2014, IEEE CONF COMPUT, P131, DOI 10.1109/INFCOMW.2014.6849190
   Blanch C, 2005, IST2004004042 BETSY
   Dutta S., 1996, Conference Record of The Twenty-Ninth Asilomar Conference on Signals, Systems and Computers, P1462, DOI 10.1109/ACSSC.1995.540940
   Ellis M, 2012, C LOCAL COMPUT NETW, P220, DOI 10.1109/LCN.2012.6423613
   Gu Y, 2007, IEEE INFOCOM SER, P1037, DOI 10.1109/INFCOM.2007.125
   Hasib M, 2003, LOND COMM S LCS2003
   Hlavacs H, 2005, LECT NOTES COMPUT SC, V3427, P152
   HOFFMAN D, 1998, 2250 RFC
   Hu Z, 2003, J SOFTW, V24, P2182
   Huang C, 2005, IEEE T IMAGE PROCESS, V14, P389, DOI 10.1109/TIP.2004.841197
   Huszak A, 2010, P ISCCSP, V2010, P3
   Joskowicz J., 2010, IEEE INT WORKSH TECH, P1, DOI DOI 10.1109/CQR.2010.5619912
   KIKUCHI Y, 2000, 3016 IETF RFC
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Leopold K, 2003, P SOC PHOTO-OPT INS, V5242, P163, DOI 10.1117/12.511112
   Liang YJ, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P684
   Luo F, 2007, THESIS
   Mahdavi J, 1998, P INET, V14, P110
   MAWI, 2006, WORK GROUP TRAFF ARC
   OpenRTSP, 2010, OPENRTSP IS COMM LIN
   Padmalatha R, 2010, INT J COMPUT APPL, V6, P1
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Planetlab, 2007, OP PLATF DEV DEPL AC
   Sangtae Ha, 2008, Operating Systems Review, V42, P64, DOI 10.1145/1400097.1400105
   Savadatti-Kamath S, 2008, THESIS
   Sommers J, 2008, IEEE ACM T NETWORK, V16, P307, DOI 10.1109/TNET.2007.900412
   Tao S, 2008, IEEE ACM T NETWORK, V16, P1052, DOI 10.1109/TNET.2007.910617
   VANDERMEER J, 2003, 3640 RFC
   Vinel A, 2013, IEEE INT CONF COMM, P505, DOI 10.1109/ICCW.2013.6649286
   Wan Z, 2014, MULTIMED TOOLS APPL, V72, P541, DOI 10.1007/s11042-013-1378-z
   Wang ZJ, 2014, J CHEM-NY, V2014, DOI 10.1155/2014/475389
   Wu M, 2003, IEEE T IMAGE PROCESS, V12, P696, DOI 10.1109/TIP.2003.810589
   Ye D, 2007, IEEE J-STSP, V1, P308, DOI 10.1109/JSTSP.2007.901506
   You FH, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P824, DOI 10.1109/ICIS.2009.24
   Zhang L, 2014, IEEE MULTIMEDIA, V21, P67, DOI 10.1109/MMUL.2014.50
NR 42
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11589
EP 11608
DI 10.1007/s11042-016-3566-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100001
DA 2024-07-18
ER

PT J
AU Manohar, K
   Kieu, TD
AF Manohar, Kris
   Kieu, The Duc
TI An SMVQ-based reversible data hiding technique exploiting side match
   distortion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Steganography; Watermarking; Vector
   quantization; Side match vector quantization; Side match distortion
ID STEGANOGRAPHIC SCHEME; VECTOR QUANTIZATION; COMPRESSION
AB Secure online communication is a necessity in today's digital world. This paper proposes a novel reversible data hiding technique based on side match vector quantization (SMVQ). The proposed scheme classifies SMVQ indices as Case 1 or 2 based on the value of the first state codeword's side match distortion (SMD) and a predefined threshold t. The proposed scheme uses this classification to switch between compression codes designed for Cases 1 and 2 SMVQ indices. The length of these compression codes is controlled by the parameter a"". Thus, with the selection of appropriate a"" and t values, the proposed scheme achieves good compression, creating spaces to embed secret information. The embedding algorithm can embed n secret bits into each SMVQ index, where n = 1, 2, 3, or 4. The experimental results show that the proposed scheme obtains the embedding rates of 1, 2, 3, or 4 bit per index (bpi) at the average bit rates of 0.340, 0.403, 0.465, or 0.528 bit per pixel (bpp) for the codebook size 256. This improves the performance of recent VQ and SMVQ-based data hiding schemes.
C1 [Manohar, Kris; Kieu, The Duc] Univ West Indies, Dept Comp & Informat Technol, Fac Sci & Technol, St Augustine, Trinidad Tobago.
C3 University West Indies Mona Jamaica; University West Indies Saint
   Augustine
RP Kieu, TD (corresponding author), Univ West Indies, Dept Comp & Informat Technol, Fac Sci & Technol, St Augustine, Trinidad Tobago.
EM justkrismanohar@gmail.com; ktduc0323@yahoo.com.au
RI Manohar, Kris/AAR-3335-2020
CR BENTLEY JL, 1986, COMMUN ACM, V29, P320, DOI 10.1145/5684.5688
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Davis R. M., 1978, IEEE Communications Society Magazine, V16, P5, DOI 10.1109/MCOM.1978.1089771
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Kieu TD, 2015, EXPERT SYST APPL, V42, P713, DOI 10.1016/j.eswa.2014.09.001
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee CC, 2009, IET IMAGE PROCESS, V3, P243, DOI 10.1049/iet-ipr.2008.0251
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lin CC, 2015, INFORM SCIENCES, V293, P314, DOI 10.1016/j.ins.2014.08.057
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Pan ZB, 2015, IET IMAGE PROCESS, V9, P22, DOI 10.1049/iet-ipr.2014.0310
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang LF, 2014, J VIS COMMUN IMAGE R, V25, P454, DOI 10.1016/j.jvcir.2013.12.004
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Yang CH, 2011, J SYST SOFTWARE, V84, P388, DOI 10.1016/j.jss.2010.11.924
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
NR 26
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11727
EP 11750
DI 10.1007/s11042-017-4814-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100006
DA 2024-07-18
ER

PT J
AU Shivani, S
   Tiwari, S
   Mishra, KK
   Zheng, ZG
   Sangaiah, AK
AF Shivani, Shivendra
   Tiwari, Shailendra
   Mishra, Krishn K.
   Zheng, Zhigao
   Sangaiah, Arun K.
TI Providing security and privacy to huge and vulnerable songs repository
   using visual cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual cryptography; Big data; Audio security; Meaningful shares; Songs
   repository
ID AUDIO WATERMARKING; WAVELET TRANSFORM; DOMAIN
AB In the today's scenario, the number of online song repositories such as iTunes, Ilungama.com , etc. is increasing day-by-day. The reason for this can be attributed to the exponential growth in the Internet users in the past few years. These song repositories store huge number of songs (mostly in millions) and charge their users for listening and downloading them. With increased number of users requires more enhanced security measures to protect such vulnerable songs repository. Any breach in security of such song repositories would not only cause huge financial loss but also copyright infringement for the owners. Therefore, in this paper we have presented a novel and efficient approach for providing security and privacy to huge and vulnerable songs repository using visual cryptography. Presented approach not only provides confidentiality to the songs but also provides integrity verification with access control to the songs repository. We have also removed various basic security constraints of (2, 2) visual cryptography existed in most of the state of art approaches like meaningless pattern of the shares, explicit codebook requirement, contrast loss, lossy recovery etc which are eliminated in the proposed approach.
C1 [Shivani, Shivendra] Thapar Univ, Patiala, Punjab, India.
   [Tiwari, Shailendra] Thapar Univ, CSE Dept, Patiala, Punjab, India.
   [Mishra, Krishn K.] Univ Missouri, Columbia, MO 65211 USA.
   [Zheng, Zhigao] Huazhong Univ Sci & Technol, Serv Comp Technol & Syst Lab, Big Data Technol & Syst Lab, Cluster & Grid Comp Lab,Sch Comp Sci & Technol, Wuhan, Hubei, Peoples R China.
   [Sangaiah, Arun K.] VIT Univ, Sch Engn & Comp Sci, Vellore, Tamil Nadu, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology; University of Missouri System; University of
   Missouri Columbia; Huazhong University of Science & Technology; Vellore
   Institute of Technology (VIT); VIT Vellore
RP Shivani, S (corresponding author), Thapar Univ, Patiala, Punjab, India.
EM shivendra.shivani@thapar.edu
RI Tiwari, Shailendra/ABF-3873-2021; Shivani, Shivendra/AFN-2368-2022;
   Sangaiah, Arun Kumar/U-6785-2019; Mishra, K.K/AAT-3083-2021
OI Tiwari, Shailendra/0000-0001-7209-0437; Shivani,
   Shivendra/0000-0002-5931-6603; Sangaiah, Arun Kumar/0000-0002-0229-2460;
   mishra, k.k./0000-0001-7557-5288
CR Al-Ayyoub M, 2016, ACCELERATING 3D MED
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Ciptasari R.W., 2014, EURASIP J INFORM SEC, V2014, P1
   Dhar PK, 2015, J INF SECUR APPL, V20, P74, DOI 10.1016/j.jisa.2014.10.007
   Fu MS, 2004, INT C MULT EXP P IEE
   George JT, 2016, INT J APPL ENG RES, V11, P5228
   Hemalatha S, 2016, INT J ELECTRON SECUR, V8, P131, DOI 10.1504/IJESDF.2016.075586
   Hemalatha S, 2015, PROCEDIA COMPUT SCI, V47, P272, DOI 10.1016/j.procs.2015.03.207
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hu HT, 2014, SIGNAL PROCESS, V105, P316, DOI 10.1016/j.sigpro.2014.05.003
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Khalil M, 2014, DIGIT SIGNAL PROCESS, V34, P116, DOI 10.1016/j.dsp.2014.07.009
   Lee CW, 2013, J SYST SOFTWARE, V86, P324, DOI 10.1016/j.jss.2012.08.048
   Li J, 2017, COLOR IMAGE WATERMAR
   Liu HJ, 2016, OPTIK, V127, P7431, DOI 10.1016/j.ijleo.2016.05.073
   Naor M, 1997, LNCS, V1294
   Naor M, 1995, LECT NOTES COMPUTER, V950, P112
   Shivani S, ADV COMPUTER SCI INF, V3
   Shivani S, 2018, PATTERN ANAL APPL, V21, P139, DOI 10.1007/s10044-016-0571-x
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Washio Shinya, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7396, DOI 10.1109/ICASSP.2014.6855037
   Xia ZH, 2016, IEEE T INF FOREN SEC, V11, P2594, DOI 10.1109/TIFS.2016.2590944
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Zarepour-Ahmadabadi J, 2016, INFORM SCIENCES, V369, P467, DOI 10.1016/j.ins.2016.07.001
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 26
TC 10
Z9 10
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11101
EP 11120
DI 10.1007/a11042-017-5240-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900041
DA 2024-07-18
ER

PT J
AU Zhu, JW
   Song, H
   Jiang, Y
   Li, B
AF Zhu, Junwu
   Song, Heng
   Jiang, Yi
   Li, Bin
TI On truthful auction mechanisms for electricity allocation with multiple
   time slots
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electricity market; Resources allocation; Auction mechanism design;
   Fixed and dynamic price; Time-of-use pricing
ID SMART; OPPORTUNITIES; ENHANCEMENT
AB As technology evolves and electricity demand rises, an increasing number of researches have focused on the efficient electricity allocation mechanisms so as to make consumer demand adaptive to the supply of electricity at all times. Considering the respective characteristics of the fixed price and the dynamic price model commonly used in the electricity market, in this paper, we formulate the problem of electricity allocation as a novel combinatorial auction model, and then put forward two directly applicable mechanisms called TAMEA-FP based on fixed price model and TAMEA-DP based on dynamic price model respectively. In addition, it is theoretically proven that both the proposed mechanisms are equipped with the economic properties such as individual rationality, budget balance and truthfulness. Finally, extensive simulation results show that both the proposed mechanisms own the allocation efficiency and computational traceability with the time complexity.
C1 [Zhu, Junwu; Song, Heng; Jiang, Yi; Li, Bin] Yangzhou Univ, Inst Informat Engn, Yangzhou, Jiangsu, Peoples R China.
   [Zhu, Junwu] Guelph Univ, Dept Comp Sci & Engn, Guelph, ON, Canada.
C3 Chinese Academy of Sciences; Yangzhou University; University of Guelph
RP Zhu, JW (corresponding author), Yangzhou Univ, Inst Informat Engn, Yangzhou, Jiangsu, Peoples R China.; Zhu, JW (corresponding author), Guelph Univ, Dept Comp Sci & Engn, Guelph, ON, Canada.
EM kren.junwu.zhu@gmail.com; song_heng@foxmail.com; yj@yzu.edu.cn;
   lb@yzu.edu.cn
RI Zhu, Junwu/H-2641-2015; Song, Heng/U-4120-2019
OI Song, Heng/0000-0001-8495-9582
FU National Nature Science Foundation of China [61170201, 61070133,
   61472344]; Six talent peaks project in Jiangsu Province [2011-DZXX-032];
   Jiangsu Science and Technology Project [BY2015061-06, BY2015061-08];
   Yangzhou Science and Technology Project [SXT20140048, SXT20150014,
   SXT201510013]; Natural Science Foundation of the Jiangsu Higher
   Education Institutions [14KJB520041]
FX Project supported by the National Nature Science Foundation of China
   (Grant No. 61170201, No. 61070133, No. 61472344), Six talent peaks
   project in Jiangsu Province (Grant No. 2011-DZXX-032), Jiangsu Science
   and Technology Project (Grant No. BY2015061-06, BY2015061-08), Yangzhou
   Science and Technology Project (Grant No. SXT20140048, SXT20150014,
   SXT201510013), Natural Science Foundation of the Jiangsu Higher
   Education Institutions (Grant No. 14KJB520041).
CR Akasiadis Charilaos., 2013, Proceedings of the Twenty-seventh AAAI Conference on Artificial Intelligence (AAAI-13), P1263
   [Anonymous], P MOBIHOC 11
   [Anonymous], CONCURRENCY COMPUTAT
   Babaioff M, 2011, J ARTIF INTELL RES, V21, P1
   Chichin S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON SERVICES COMPUTING (SCC 2014), P27, DOI 10.1109/SCC.2014.13
   Fumagalli E, 2007, ENERG POLICY, V35, P6212, DOI 10.1016/j.enpol.2007.07.019
   Güngör VC, 2011, IEEE T IND INFORM, V7, P529, DOI 10.1109/TII.2011.2166794
   Gungor VC, 2010, IEEE T IND ELECTRON, V57, P3557, DOI 10.1109/TIE.2009.2039455
   Huang P, 2002, COMPUT INTELL-US, V18, P596, DOI 10.1111/1467-8640.t01-1-00206
   Ibars C, 2010, INT CONF SMART GRID, P495, DOI 10.1109/SMARTGRID.2010.5622091
   Klemperer P., 1999, J ECON SURV, V13, P227, DOI [DOI 10.1111/1467-6419.00083, 10.1111/1467-6419.00083]
   Li CH, 2010, DECIS SUPPORT SYST, V49, P1, DOI 10.1016/j.dss.2009.12.002
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Lu HP, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/348036
   Lu HM, 2017, IEEE ACCESS, V5, P670, DOI 10.1109/ACCESS.2017.2648845
   Lu HM, 2016, J VIS COMMUN IMAGE R, V38, P504, DOI 10.1016/j.jvcir.2016.03.029
   Lu HM, 2015, J OPT SOC AM A, V32, P886, DOI 10.1364/JOSAA.32.000886
   Medina J, 2010, IEEE T SMART GRID, V1, P193, DOI 10.1109/TSG.2010.2050156
   Mohsenian-Rad AH, 2010, IEEE T SMART GRID, V1, P320, DOI 10.1109/TSG.2010.2089069
   MYERSON RB, 1983, J ECON THEORY, V29, P265, DOI 10.1016/0022-0531(83)90048-0
   Nisan N, 2011, P ACM C EL COMM, P242
   Palensky P, 2011, IEEE T IND INFORM, V7, P381, DOI 10.1109/TII.2011.2158841
   Pillai PS, 2016, IEEE SYST J, V10, P637, DOI 10.1109/JSYST.2014.2314861
   Rothkopf MH, 1998, MANAGE SCI, V44, P1131, DOI 10.1287/mnsc.44.8.1131
   Schülke A, 2010, INT CONF SMART GRID, P437, DOI 10.1109/SMARTGRID.2010.5622081
   Stacke F, 2008, IEEE T POWER SYST, V23, P1601, DOI 10.1109/TPWRS.2008.2002291
   Zaman S., 2010, J PARALLEL DISTRIB C, V73, P495
   Zou XY, 2009, ENERG POLICY, V37, P4231, DOI 10.1016/j.enpol.2009.05.019
NR 28
TC 2
Z9 2
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10753
EP 10772
DI 10.1007/s11042-017-4855-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900022
DA 2024-07-18
ER

PT J
AU Bacharidis, K
   Moirogiorgou, K
   Koukiou, G
   Giakos, G
   Zervakis, M
AF Bacharidis, Konstantinos
   Moirogiorgou, Konstantia
   Koukiou, Georgia
   Giakos, George
   Zervakis, Michalis
TI Stereo System for Remote Monitoring of River Flows
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE River flow monitoring; Remote sensing; Optical flow; StereoVision
ID IMAGE VELOCIMETRY; ACCURACY
AB In this article we present a video-based method for river flow monitoring. The proposed method aims at deriving efficient approximations of the river velocity using natural formations on the river surface. In order to overcome peculiarities of the flow, we propose to uniformly exploit all such structures that appear locally with short temporal duration. Towards this direction we explore the expanded capabilities of a stereoscopic camera layout with the dual observation fields and the potential of reverting projective deformations. By mapping to world coordinates, all spatial locations in the video reflect velocity as a uniform field, except for local flow variations. The velocity estimation is performed by computing the optical flow using a series of video frames, combining the information of the views of both cameras. The novelty of the proposed river flow estimation scheme lies on the fact that the accuracy of motion estimation is increased due to the use of the complementary views, which also enables the transition from a 2-Dimensional image-based velocity estimate to 3-Dimensional estimates. The estimated optical velocity is back-projected to the real world coordinates using the parameters extracted using the stereoscopic layout. The results on simulated and real conditions demonstrate that the proposed method is efficient in the estimation of the surface velocity and robust against locally disappearing formations, since it can compensate for a loss with other formations active in the field of view.
C1 [Bacharidis, Konstantinos; Moirogiorgou, Konstantia; Zervakis, Michalis] Tech Univ Crete, Elect & Comp Engn Sch, Khania, Greece.
   [Koukiou, Georgia] Univ Patras, Elect Lab, Dept Phys, Patras, Greece.
   [Giakos, George] Manhattan Coll, Elect & Comp Engn Sch, Bronx, NY 10471 USA.
C3 Technical University of Crete; University of Patras; Manhattan College
RP Bacharidis, K (corresponding author), Tech Univ Crete, Elect & Comp Engn Sch, Khania, Greece.
EM kbacharidis@isc.tuc.gr; dina@display.tuc.gr; gkoukiou@upatras.gr;
   george.giakos@manhattan.edu; michalis@display.gr
RI Moirogiorgou, Konstantia/AAE-6808-2022
OI Moirogiorgou, Konstantia/0000-0003-4826-6388; Koukiou,
   Georgia/0000-0002-9314-8359; Bacharidis,
   Konstantinos/0000-0002-3867-7119
FU European Union (European Social Fund - ESF); Greek national funds
   through the Operational Program "Education and Lifelong Learning" of the
   National Strategic Reference Framework (NSRF) - Research Funding
   Program: Thales. Investing in knowledge society through the European
   Social fund
FX This work is elaborated through an on-going THALES project (CYBERSENSORS
   High Frequency Monitoring System for Integrated Water Resources
   Management of Rivers). The project has been co-financed by the European
   Union (European Social Fund - ESF) and Greek national funds through the
   Operational Program "Education and Lifelong Learning" of the National
   Strategic Reference Framework (NSRF) - Research Funding Program: Thales.
   Investing in knowledge society through the European Social fund.
CR [Anonymous], 2011, GEOPHYS RES LETT, DOI DOI 10.1029/2011GL050686
   Bacharidis K, 2014, IEEE CONF IMAGING SY, P173, DOI 10.1109/IST.2014.6958468
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bradley AA, 2002, WATER RESOUR RES, V38, DOI 10.1029/2002WR001317
   Chang J., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P91
   Chen X, 2015, EXP FLUIDS, V56, DOI 10.1007/s00348-014-1874-6
   Chorin A.J., 1990, A Mathematical Introduction to Fluid Mechanics
   Creutin JD, 2003, J HYDROL, V277, P182, DOI 10.1016/S0022-1694(03)00081-7
   Fujita I, 1998, J HYDRAUL RES, V36, P397, DOI 10.1080/00221689809498626
   Fujita I, 2004, INT C ADV OPT DIAGN, VV0032
   Fujita I, 2007, INT J RIVER BASIN MA, V5, P105, DOI 10.1080/15715124.2007.9635310
   Gui L, 2002, EXP FLUIDS, V32, P506, DOI 10.1007/s00348-001-0396-1
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hauet A, 2008, J HYDROL ENG, V13, P105, DOI 10.1061/(ASCE)1084-0699(2008)13:2(105)
   Héas P, 2013, IEEE T PATTERN ANAL, V35, P1343, DOI 10.1109/TPAMI.2012.232
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Hoyt WG, 1939, EOS T AM GEOPHYS UN, V20, P166
   Huang HT, 1993, EXP FLUIDS
   Jonkman SN, 2005, NAT HAZARDS, V34, P151, DOI 10.1007/s11069-004-8891-3
   Kääb A, 2014, REMOTE SENS ENVIRON, V154, P164, DOI 10.1016/j.rse.2014.08.015
   Kim Y., 2006, Uncertainty analysis for non-intrusive measurement of river discharge using image velocimetry
   Le Boursicaud R, 2016, HYDROL PROCESS, V30, P90, DOI 10.1002/hyp.10532
   Lecordier B, 2001, MEAS SCI TECHNOL, V12, P1382, DOI 10.1088/0957-0233/12/9/302
   Nakajima Y, 2003, PATTERN RECOGN, V36, P1203, DOI 10.1016/S0031-3203(02)00078-X
   Ralli J, 2011, THESIS
   Saikano H, 2008, COMP VISION PAT RECO
   Sakaino H, 2015, IEEE T IMAGE PROCESS, V24, P3609, DOI 10.1109/TIP.2015.2447738
   Simon Baker, 2007, INT C COMPUT VIS, P1, DOI [10.1109/ICCV.2007.4408903, DOI 10.1109/ICCV.2007.4408903]
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   Tsubaki R, 2011, J HYDRO-ENVIRON RES, V5, P313, DOI 10.1016/j.jher.2010.12.004
   Vescoukis V, 2012, FUTURE GENER COMP SY, V28, P593, DOI 10.1016/j.future.2011.03.010
   Westerweel J, 1997, EXP FLUIDS, V23, P20, DOI 10.1007/s003480050082
   Wildes RP, 2000, COMPUT VIS IMAGE UND, V80, P246, DOI 10.1006/cviu.2000.0874
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 34
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9535
EP 9566
DI 10.1007/s11042-017-5148-1
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200019
DA 2024-07-18
ER

PT J
AU Hatem, Y
   Rady, S
AF Hatem, Yomna
   Rady, Sherine
TI Exploring feature dimensionality reduction methods for enhancing
   automatic sport image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sport images annotation; SVM; Feature extraction and selection;
   Information gain; Chi-Square; LSA
ID RETRIEVAL
AB Nowadays, multimedia information requires the demand to investigate and apply efficient techniques for better annotation and retrieval purposes. In the content-based indexing, low-level features are generally extracted from images to serve as image descriptors. Other than the descriptor poses a computational overhead, the learning model may also tend to overfit, resulting in performance degeneration. This work solves such problems in the sport image domain by proposing feature dimensionality reduction techniques for the retrieval and annotation of image datasets. Different techniques are investigated, such as Information Gain, Gain Ratio, Chi-Square, and Latent Semantic Analysis (LSA), and applied for sport images classification using Support Vector Machine (SVM) classifier. A comparison between the performances of applying SVM alone and when incorporating the different reduction methods is presented. Experimental results show that the SVM classification accuracy is 76.4%; while integrating LSA technique manages to raise the accuracy to 96%, with the other techniques recording 74% accuracy at 50% feature space reduction.
C1 [Hatem, Yomna; Rady, Sherine] Ain Shams Univ, Fac Comp & Informat Sci, Dept Informat Syst, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Ain Shams University
RP Hatem, Y (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Dept Informat Syst, Cairo, Egypt.
EM yomna.abdellatief@cis.asu.edu.eg; srady@cis.asu.edu.eg
RI Hatem, Yomna/N-6351-2018; Rady, Sherine/W-7351-2019
OI Hatem, Yomna/0000-0003-1759-3722; Rady, Sherine/0000-0003-4991-966X
CR Aslam N., 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P414, DOI 10.1109/ISSPIT.2010.5711741
   Assfalg J, 2002, IEEE MULTIMEDIA, V9, P52, DOI 10.1109/93.998060
   Banerjee Minakshi, 2015, Pattern Recognition and Machine Intelligence. 6th International Conference, PReMI 2015. Proceedings: LNCS 9124, P149, DOI 10.1007/978-3-319-19941-2_15
   Barrena M, 2015, MACH VISION APPL, V26, P423, DOI 10.1007/s00138-015-0672-3
   Buathong W., 2013, 9 INT C COMPUTING IN, P125
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Cai X, 2012, LECT NOTES COMPUT SC, V7577, P823, DOI 10.1007/978-3-642-33783-3_59
   CASTELLI V., 2002, Digital Imagery: Fundamentals, P1
   Chen G-B, 2013, ADV INTELLIGENT SYST, V1, P317
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Dongjin Choi, 2012, Multidisciplinary Research and Practice for Information Systems. International Cross-Domain Conference and Workshop on Availability, Reliability and Security (CD-ARES 2012). Proceedings, P479, DOI 10.1007/978-3-642-32498-7_36
   Han J, 2012, MOR KAUF D, P1
   Hatem Y, 2016, INTERNATIONAL CONFERENCE ON INFORMATICS AND SYSTEMS (INFOS 2016), P88, DOI 10.1145/2908446.2908458
   Jaworska T, 2015, ADV INTELL SYST, V314, P25, DOI 10.1007/978-3-319-10383-9_3
   Johnson S, 2010, P BRIT MACH VIS C, V2
   Kesorn K, 2009, LECT NOTES COMPUT SC, V5414, P817, DOI 10.1007/978-3-540-92957-4_71
   KHARKATE S, 2013, INT J INNOVATIVE RES, V1, P1142
   Khemchandani R, 2015, NEUROCOMPUTING, V165, P444, DOI 10.1016/j.neucom.2015.03.074
   Leung CHC, 2011, COMM COM INF SC, V260, P291
   Liu H, 1995, PROC INT C TOOLS ART, P388, DOI 10.1109/TAI.1995.479783
   Lulio L C, 2012, ADV IMAGE SEGMENTATI, P103
   Panakarn P, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415500081
   Prasad Y, 2010, LECT NOTES COMPUT SC, V6146, P307, DOI 10.1007/978-3-642-13498-2_40
   Priyogi B, 2014, P INF COMM TECHN EUR, P179
   Reisert M, 2006, LECT NOTES COMPUT SC, V4141, P661
   Sangeetha M, 2016, INT RES J ENG TECHNO, V3, P1143
   Seng T Y, 2010, P 2 SEM TECHN KNOWL, P74
   Seo KK, 2007, LECT NOTES ARTIF INT, V4632, P594
   Siddiqui A., 2015, INT J COMPUTER APPL, V118, P27, DOI DOI 10.5120/20863-3575
   Tang J., 2014, DATA CLASSIFICATION, P37, DOI DOI 10.1201/B17320
   Wang L., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P435
   Zhang DS, 2013, J VIS COMMUN IMAGE R, V24, P1087, DOI 10.1016/j.jvcir.2013.07.004
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhang SL, 2014, COMPUT VIS IMAGE UND, V118, P16, DOI 10.1016/j.cviu.2013.03.008
   Zheng H, 2014, SIVIP, V10, P55
NR 35
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9171
EP 9188
DI 10.1007/s11042-017-5417-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800062
DA 2024-07-18
ER

PT J
AU Li, J
   Hu, HP
   Liu, RH
AF Li, Jun
   Hu, HanPing
   Liu, Ruihua
TI Data restoration based on Gaussian noisy and motion-blurred snapshots in
   multimedia big data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia big data; Gaussian noisy; Data restoration; Alternating
   iterative optimization; Semantic retrieval
ID INVERSE PROBLEM
AB In the era of big data, the complexity of data analysis and information extraction has grown dramatically. In this paper, we firstly analyze the disadvantages of TV deblurring model and TV-denoising model. Afterwards, we propose an alternating iterative optimization (AIO) algorithm to data restoration based on two noisy and blurred degraded snapshots. Next, we prove theoretically the existence, uniqueness of the minimal solutions and convergence of the AIO algorithm, which are the most important part of the paper. In the end, we show our discrete numerical algorithm and some experimental results. Through these experiments, we can see that the AIO algorithm proposed by us works effectively very well.
C1 [Li, Jun; Hu, HanPing] Huazhong Univ Sci & Technol, Inst Automat, Wuhan 430070, Peoples R China.
   [Li, Jun] Hubei Univ Technol, Wuhan, Hubei, Peoples R China.
   [Liu, Ruihua] Chongqing Univ Technol, Sch Math & Stat, Chongqing 400054, Peoples R China.
C3 Huazhong University of Science & Technology; Hubei University of
   Technology; Chongqing University of Technology
RP Hu, HP (corresponding author), Huazhong Univ Sci & Technol, Inst Automat, Wuhan 430070, Peoples R China.
EM lj_py@126.com; hanp_hu@163.com; lruih@sohu.com
RI Hu, Hanping/H-3942-2015; Liu, Ruihua/GSE-4956-2022
OI Hu, Hanping/0000-0003-3049-1149
FU Provincial education scientific planning project of Hubei Ministry of
   Education of China [D20141403]; Project Foundation of National Science
   Foundation of China [11104365]
FX The work is supported by Provincial education scientific planning
   project of Hubei Ministry of Education of China under Grant D20141403
   and Project Foundation of National Science Foundation of China
   (11104365).
CR [Anonymous], MATH PROBLEMS ENG
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Bredies K, 2015, J MATH IMAGING VIS, V52, P317, DOI 10.1007/s10851-015-0564-1
   Chan RH, 1999, IEEE T IMAGE PROCESS, V8, P1472, DOI 10.1109/83.791976
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Dong Y, 2012, 1223 UCLACAM
   Fu CX, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/381010
   Kirsch A., 1996, INTRO MATH THEORY IN, P29
   Lang RL, 2016, APPL MATH COMPUT, V291, P115, DOI 10.1016/j.amc.2016.06.048
   Lederman C, 2011, 1115 UCLACAM
   [刘瑞华 LIU Rui-hua], 2009, [中国图象图形学报, Journal of Image and Graphics], V14, P2451
   Matin M, 2013, J SCI COMPUT, V54, P269
   Reeves SJ, 2005, IEEE T IMAGE PROCESS, V14, P1448, DOI 10.1109/TIP.2005.854474
   Rossi O, 2014, PUBL MATH-DEBRECEN, V84, P165, DOI 10.5486/PMD.2014.5990
   Rudin L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P103, DOI 10.1007/0-387-21810-6_6
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Senzaki K, 2015, I SYMP CONSUM ELECTR, P633, DOI 10.1109/ICCE.2015.7066558
   Taylor M, 1997, PARTY STATE SOC ELEC, P53
   Wei Q, 2015, IEEE T IMAGE PROCESS, V24, P4109, DOI 10.1109/TIP.2015.2458572
NR 19
TC 0
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9959
EP 9977
DI 10.1007/s11042-017-4515-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200040
DA 2024-07-18
ER

PT J
AU Zhang, G
   Hsu, CHR
   Lai, HD
   Zheng, XH
AF Zhang, Gang
   Hsu, Ching-Hsien Robert
   Lai, Huadong
   Zheng, Xianghan
TI Deep learning based feature representation for automated skin
   histopathological image annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin biopsy histopathological image annotation; Deep learning;
   Convolutional neural network; Multiple-instance multiple-label learning;
   Unsupervised feature learning
AB Automated annotation of skin biopsy histopathological images provides valuable information and supports for diagnosis, especially for the discrimination between malignant and benign lesions. Currently, computer-aid analysis of skin biopsy images mostly relied on some human-designed features, which requires expensive human efforts and experiences in problem domains. In this study, we propose an annotation framework for automated skin biopsy image analysis which makes use of a deep model for image feature representation. A convolutional neural network (CNN) is designed for local regions of skin biopsy images which learns potential high-level features automatically from input raw pixels. The annotation model is constructed in the multiple-instance multiple-label (MIML) learning framework with the features learned through the network. We achieve significant improvement of the model performance on a real world clinical skin biopsy image dataset and a benchmark dataset. Moreover, our study indicates that deep learning based model could achieve better performance than human designed features.
C1 [Zhang, Gang; Lai, Huadong] Guangdong Univ Technol, Sch Automat, Guangzhou, Guangdong, Peoples R China.
   [Hsu, Ching-Hsien Robert] Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu, Taiwan.
   [Zheng, Xianghan] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
C3 Guangdong University of Technology; Chung Hua University; Fuzhou
   University
RP Zheng, XH (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
EM ipx@gdut.edu.cn; chh@chu.edu.tw; 961649205@qq.com;
   xianghan.zheng@fzu.edu.cn
RI Hsu, Ching-Hsien/AAE-6917-2020
FU National Natural Science Foundation of China [61502106, 81373883,
   81573827]; Natural Science Foundation of GuangDong Province
   [2016A030310340]; College Student Career and Innovation Training Plan
   Project of Guangdong Province [xj201511845018, yj201511845038,
   yj201611845074, yj201611845075, yj201611845366]; Special Fund of
   Cultivation of Technology Innovation for University Students
   [pdjh2016b0150]; Research Project of Guangdong Education Evaluation
   Association [G-11]; Fujian Major Project of Regional Industry
   [2014H4015]
FX This work is supported by National Natural Science Foundation of China
   (No. 61502106, 81373883, 81573827), Natural Science Foundation of
   GuangDong Province (No. 2016A030310340), the College Student Career and
   Innovation Training Plan Project of Guangdong Province (xj201511845018,
   yj201511845038, yj201611845074, yj201611845075, yj201611845366), the
   Special Fund of Cultivation of Technology Innovation for University
   Students (pdjh2016b0150), the 2015 Research Project of Guangdong
   Education Evaluation Association (No. G-11) and Fujian Major Project of
   Regional Industry (No. 2014H4015).
CR Ali R, 2013, PHYS MED BIOL, V58, P8007, DOI 10.1088/0031-9155/58/22/8007
   [Anonymous], ACM GEN EV COMP C CO
   Baldi A., 2014, SKIN CANC, P523
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bunte K, 2011, PATTERN RECOGN, V44, P1892, DOI 10.1016/j.patcog.2010.10.024
   Caicedo JC, 2009, LECT NOTES ARTIF INT, V5651, P126, DOI 10.1007/978-3-642-02976-9_17
   Cerroni L, 2010, J AM ACAD DERMATOL, V63, P647, DOI 10.1016/j.jaad.2009.09.009
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Cho Y, 2012, THESIS
   Cruz-Roa A, 2011, ARTIF INTELL MED, V52, P91, DOI 10.1016/j.artmed.2011.04.010
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Dong R., 2011, NAT COMP ICNC 2011 7, V3, P1654
   Ferrara G, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0005375
   Foulds J, 2010, KNOWL ENG REV, V25, P1, DOI 10.1017/S026988890999035X
   Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360
   He JJ, 2012, MACH LEARN, V88, P273, DOI 10.1007/s10994-012-5283-x
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Trinh HP, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2685394
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Jinliang Chen, 2013, 2013 6th International Conference on Information Management, Innovation Management and Industrial Engineering (ICIII), P546, DOI 10.1109/ICIII.2013.6703210
   Li N, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON MANAGEMENT INNOVATION AND PUBLIC POLICY (ICMIPP 2012), VOLS 1-6, P396
   Li YY, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818071
   Lopes N, 2014, PATTERN RECOGN, V47, P114, DOI 10.1016/j.patcog.2013.06.029
   Malik MSA, 2014, DBAS PERSPECTIVE USE
   Marrugo Andres G., 2011, Journal of Physics: Conference Series, V274, DOI 10.1088/1742-6596/274/1/012039
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Ooi BC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P685, DOI 10.1145/2733373.2807410
   Schapire RE, 2000, MACH LEARN, V39, P135, DOI 10.1023/A:1007649029923
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tang Yichuan, 2013, CoRR
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Zhang G, 2012, MULTIINSTANCE LEARNI, P83
   Zhang G, 2014, BIOMED RES INT, V2014, DOI 10.1155/2014/305629
   Zhang Gui-Biao, 2013, Evid Based Complement Alternat Med, V2013, P621423, DOI 10.1155/2013/621423
   Zhang ML, 2009, GEN MULTIINSTANCE LE
   Zhang SG, 2010, PROCEEDINGS OF THE ASME JOINT RAIL CONFERENCE, VOL 2, P501, DOI 10.1145/1873951.1874018
   Zhong R, 2014, IDEAS 15, P226
   Zhou ZH, 2012, ARTIF INTELL, V176, P2291, DOI 10.1016/j.artint.2011.10.002
NR 42
TC 22
Z9 22
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9849
EP 9869
DI 10.1007/s11042-017-4788-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200032
DA 2024-07-18
ER

PT J
AU Zhang, HT
   Yu, J
   Wang, ZF
AF Zhang, Hai-Tao
   Yu, Jun
   Wang, Zeng-Fu
TI Probability contour guided depth map inpainting and superresolution
   using non-local total generalized variation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depth map inpainting; Depth map super-resolution; Non-local generalized
   variation; First-order primal dual algorithm
AB This paper proposes an image-guided depth super-resolution framework to improve the quality of depth map captured by low-cost depth sensors, like the Microsoft Kinect. First, a contour-guided fast marching method is proposed to preprocess the raw depth map for recovering the missing data. Then, by using the non-local total generalized variation (NL-TGV) regularization, a convex optimization model is constructed to up-sample the preprocessed depth map to a high-resolution one. To preserve the sharpness of depth discontinuities, the color image and its multi-level segmentation information are utilized to assign the weights within the NL-TGV through a novel weight combining scheme. The texture energy from color image and local structure coherence around neighbor pixels in low-resolution depth map are applied to adjust the combination weights for further suppressing texture-transfer. Quantitative and qualitative evaluations of the proposed method on the Middlebury datasets and real-sensor datasets show the promising results in quality.
C1 [Zhang, Hai-Tao; Yu, Jun; Wang, Zeng-Fu] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
   [Zhang, Hai-Tao] Southwest Univ Sci & Technol, Sch Informat & Engn, Mianyang 621010, Peoples R China.
   [Wang, Zeng-Fu] Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Southwest University of Science & Technology - China;
   Chinese Academy of Sciences; Hefei Institutes of Physical Science, CAS
RP Wang, ZF (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.; Wang, ZF (corresponding author), Chinese Acad Sci, Inst Intelligent Machines, Hefei 230031, Anhui, Peoples R China.
EM zhtsir@mail.ustc.edu.cn; harryjun@ustc.edu.cn; zfwang@ustc.edu.cn
RI ZHANG, Haitao/ABB-8153-2022
OI ZHANG, Haitao/0000-0003-0513-6241
CR [Anonymous], IMAGE PROCESSING LIN
   [Anonymous], P EUR C COMPUT VIS
   [Anonymous], 2008, P ECCV WORKSH MULT C
   [Anonymous], PROC EUR CONF COMP
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Cui Y, 2010, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2010.5540082
   Diebel J., 2005, P 18 INT C NEUR INF, V18, P291
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Ferstl D, 2015, IEEE I CONF COMP VIS, P513, DOI 10.1109/ICCV.2015.66
   Ferstl D, 2013, IEEE I CONF COMP VIS, P993, DOI 10.1109/ICCV.2013.127
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Hui TW, 2016, LECT NOTES COMPUT SC, V9907, P353, DOI 10.1007/978-3-319-46487-9_22
   Kiechle M, 2013, IEEE I CONF COMP VIS, P1545, DOI 10.1109/ICCV.2013.195
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239453
   Kwon H, 2015, PROC CVPR IEEE, P159, DOI 10.1109/CVPR.2015.7298611
   Li YH, 2016, ADV SOC SCI EDUC HUM, V50, P717
   Liu MY, 2013, PROC CVPR IEEE, P169, DOI 10.1109/CVPR.2013.29
   Liu W, 2015, IEEE SIGNAL PROC LET, V22, DOI 10.1109/LSP.2015.2427376
   Lu JB, 2012, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2012.6247705
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Nair Rahul, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P105, DOI 10.1007/978-3-642-44964-2_6
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   Park J, 2014, IEEE T IMAGE PROCESS, V23, P5559, DOI 10.1109/TIP.2014.2361034
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Pock T, 2011, IEEE I CONF COMP VIS, P1762, DOI 10.1109/ICCV.2011.6126441
   Ranftl R, 2014, LECT NOTES COMPUT SC, V8689, P439, DOI 10.1007/978-3-319-10590-1_29
   Scharstein Daniel, 2007, PROC COMPUT VIS PATT, P1
   Schuon Sebastian, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563171
   Schuon S, 2009, PROC CVPR IEEE, P343, DOI 10.1109/CVPRW.2009.5206804
   Tan X, 2014, PROC CVPR IEEE, P2941, DOI 10.1109/CVPR.2014.376
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Xiaofeng Ren, 2012, NeurIPS, V25, DOI DOI 10.5555/2999134.2999200
   Yang JY, 2014, IEEE T IMAGE PROCESS, V23, P3443, DOI 10.1109/TIP.2014.2329776
   Yang Q., 2007, PROC COMPUT VIS PATT, P1
   Yang QX, 2013, IEEE T IMAGE PROCESS, V22, P4841, DOI 10.1109/TIP.2013.2278917
   Yu LF, 2013, PROC CVPR IEEE, P1415, DOI 10.1109/CVPR.2013.186
   Zhang S, 2015, J SIGNAL PROCESS SYS, V79, P19, DOI 10.1007/s11265-013-0821-8
   Zhu JJ, 2011, IEEE T PATTERN ANAL, V33, P1400, DOI 10.1109/TPAMI.2010.172
NR 41
TC 16
Z9 17
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 9003
EP 9020
DI 10.1007/s11042-017-4791-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800054
DA 2024-07-18
ER

PT J
AU Chaudhry, SA
   Naqvi, H
   Khan, MK
AF Chaudhry, Shehzad Ashraf
   Naqvi, Husnain
   Khan, Muhammad Khurram
TI An enhanced lightweight anonymous biometric based authentication scheme
   for TMIS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Key agreement; Biometrics; Smart card; Smart card stolen
   attack; Anonymity violation; ProVerif; Telemedicine
ID KEY AGREEMENT SCHEME; SMART-CARD; SECURITY; PROTOCOL; NETWORKS
AB In recent past, Mir and Nikooghadam presented an enhanced biometrics based authentication scheme using lightweight symmetric key primitives for telemedicine networks. This scheme was introduced in an anticipation to the former biometrics based authentication system proposed by Yan et al. Mir and Nikooghadam declared that their scheme is invincible against potential attacks while providing user anonymity. Our study and in-depth analysis unveil that Mir and Nikooghadam's authentication scheme is susceptible to smart card stolen attack, moreover anonymity violation is still possible despite the claim of Mir and Nikooghadam. We have utilized the random oracle model in order to perform security analysis. The analysis endorses that the proposed scheme is robust enough to provide protection against all potential attacks specially smart card stolen attack and user anonymity violation attack. Analysis is further substantiated through an automated software application ProVerif. The analysis also shows that proposed scheme is computationally efficient than Mir and Nikooghadam's scheme.
C1 [Chaudhry, Shehzad Ashraf; Naqvi, Husnain] Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
C3 International Islamic University, Pakistan; King Saud University
RP Chaudhry, SA (corresponding author), Int Islamic Univ, Dept Comp Sci & Software Engn, Islamabad, Pakistan.
EM shahzad@iiu.edu.pk; husnain.naqvi@iiu.edu.pk; mkhurram@ksu.edu.sa
RI Nusa, Nuhammad/JXY-5819-2024; Khan, Muhammad/IXN-8470-2023; Chaudhry,
   Shehzad/Y-3430-2019; KHAN, MUHAMMAD KHURRAM/E-4836-2014
OI Chaudhry, Shehzad/0000-0002-9321-6956; KHAN, MUHAMMAD
   KHURRAM/0000-0001-6636-0533
FU King Saud University [PRG-1436-16]
FX Muhammad Khurram Khan extends his sincere appreciations to the Deanship
   of Scientific Research at King Saud University for its funding the
   Prolific Research Group (PRG-1436-16)<SUP>2</SUP>.
CR Anderson GF, 2003, HEALTH AFFAIR, V22, P89, DOI 10.1377/hlthaff.22.3.89
   [Anonymous], 2010, E LEARN INF TECHN S
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], J MED SYST
   [Anonymous], ARXIV07122235
   [Anonymous], 2013, J. Med. Syst.
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Chang YF, 2014, INT J COMMUN SYST, V27, P3430, DOI 10.1002/dac.2552
   Chaudhry SA, 2015, SECUR COMMUN NETW, V8, P3782, DOI 10.1002/sec.1299
   Chaudhry SA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0244-0
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   Das AK, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.2933
   He DB, 2015, IEEE COMMUN MAG, V53, P71, DOI 10.1109/MCOM.2015.7010518
   He DB, 2014, IEEE T CONSUM ELECTR, V60, P30, DOI 10.1109/TCE.2014.6780922
   Irshad A, 2013, MULTIMED TOOLS APPL, P1
   Irshad A, 2014, SECUR COMMUN NETW, V7, P1210, DOI 10.1002/sec.834
   Jin ZP, 2015, IEEE PERVAS COMPUT, V14, P54, DOI 10.1109/MPRV.2015.19
   Khan MK, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/491289
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Leu JS, 2014, IET INFORM SECUR, V8, P104, DOI 10.1049/iet-ifs.2012.0206
   Li CS, 2011, J STAT COMPUT SIM, V81, P1081, DOI 10.1080/00949651003677410
   Li X, 2013, MATH COMPUT MODEL, V58, P85, DOI 10.1016/j.mcm.2012.06.033
   Liu JY, 2008, COMPUT COMMUN, V31, P2205, DOI 10.1016/j.comcom.2008.02.002
   Lu YR, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/635890
   Lu YR, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0221-7
   Mehmood Z., 2012, 2012 Second International Conference on Digital Information Processing and Communications (ICDIPC), P164, DOI 10.1109/ICDIPC.2012.6257295
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mir O, 2015, WIRELESS PERS COMMUN, V83, P2439, DOI 10.1007/s11277-015-2538-4
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Nikooghadam M, 2010, J SYST SOFTWARE, V83, P1917, DOI 10.1016/j.jss.2010.05.072
   Srivastava K, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0153-7
   Wang D, 2015, IEEE T DEPEND SECURE, V12, P428, DOI 10.1109/TDSC.2014.2355850
   Wang D, 2014, COMPUT NETW, V73, P41, DOI 10.1016/j.comnet.2014.07.010
   Witteman M., 2002, Information Security Bulletin, V7, P11
   Xie Q, 2016, INT J COMMUN SYST, V29, P478, DOI 10.1002/dac.2858
   Xu X, 2014, J MED SYST, V38, DOI 10.1007/s10916-013-9994-8
   Yan XP, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9972-1
   Zhang LP, 2014, INT J COMMUN SYST, V27, P2691, DOI 10.1002/dac.2499
   Zhang M, 2015, SECUR COMMUN NETW, V8, P682, DOI 10.1002/sec.1016
   Zuowen Tan, 2013, Przeglad Elektrotechniczny, V89, P200
NR 42
TC 44
Z9 45
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5503
EP 5524
DI 10.1007/s11042-017-4464-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800018
DA 2024-07-18
ER

PT J
AU Hu, ZP
   Zhang, ZB
   Sun, Z
   Zhao, SH
AF Hu, Zhengping
   Zhang, Zhenbin
   Sun, Zhe
   Zhao, Shuhuan
TI Saliency detection based on salient edges and remarkable discriminating
   for superpixel pairs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Image edges; Superpixel pairs; Affinity matrix;
   Isolated superpixel; Seeds
ID REGION DETECTION
AB Saliency detection is an essential pre-processing step for intensifying image objects in many computer vision fields. Other than most bottom-up methods, in this paper, we propose a novel saliency model based on high-level image edges and low-level feature contrast. Edges are inherent features for an image, and it can locate the object via a salient selection. With this theory, an accurate object contour is generated after two salient discriminations for edge-contiguous superpixel couples. After position is confirmed, foreground and background of the image can be divided by the contour. With an ingrowth model, we then obtain a foreground (or background) seeds referencing spatial adjacent relation. According to the seed set, a homologous saliency map is computed via a seed-based saliency approach, which is proposed on the basis of affinity matrix. Compared with some pre-existing algorithms, low-level information is utilized purposefully by salient edges in the presented method, which makes the extracted fore regions more precise.
C1 [Hu, Zhengping; Zhang, Zhenbin; Sun, Zhe; Zhao, Shuhuan] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University
RP Zhang, ZB (corresponding author), Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM zzbysu@163.com
CR Achanta R., 2010, SLIC Superpixels
   Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], IEEE INT
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gao H.-Y., 2014, IEEE INT C IM PROC, DOI [10.1109/icip.2014.7025666, DOI 10.1109/ICIP.2014.7025666]
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Ma XL, 2015, J VIS COMMUN IMAGE R, V32, P95, DOI 10.1016/j.jvcir.2015.08.003
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Murray N., 2011, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2011.5995506., DOI 10.1109/CVPR.2011.5995506]
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sha C, 2013, IEEE INT C IM SIGN P, DOI [10.1109/CISP.2013.6745214, DOI 10.1109/CISP.2013.6745214]
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Sun JG, 2015, IEEE T IMAGE PROCESS, V24, P1639, DOI 10.1109/TIP.2015.2403241
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang YX, 2015, IEEE INT CON MULTI
   Wang Z, 2008, AC SPEECH SIGN PROC, DOI [10.1109/ICASSP.2008.4517772, DOI 10.1109/ICASSP.2008.4517772]
   Xie Y, 2011, IEEE INT C IM PROC, DOI [10.1109/ICIP.2011.6116634, DOI 10.1109/ICIP.2011.6116634]
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Zhang LH, 2015, NEUROCOMPUTING, V155, P1, DOI 10.1016/j.neucom.2014.12.080
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 38
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5949
EP 5968
DI 10.1007/s11042-017-4508-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800037
DA 2024-07-18
ER

PT J
AU Shivani, S
AF Shivani, Shivendra
TI VMVC: Verifiable multi-tone visual cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Verifiable visual cryptography; Multi-toned visual cryptography; Secret
   sharing; Meaningful shares
ID SECRET IMAGES; LEVEL IMAGES; RANDOM GRIDS; SCHEME
AB Traditional k out of n threshold visual cryptography scheme is proposed to hide a secret image into n shares, where only k or more shares can visually reveal the secret image. Most of the previous state of art approaches on visual cryptography are almost restricted in processing of binary images as secret, which are inadequate for many applications like securely transmission of medical images(Store and Forward Telemedicine), forensic images etc. In this paper, a new Verifiable Multi-toned Visual Cryptography (VMVC) scheme is proposed to securely transmit the confidential images on web. Proposed approach also provides cheating prevention, since each pixel of shares contains a self embedding verifiable bit for integrity test of that pixel. Many existing approaches are suffering from many unnecessary encryption constraints like random shares, codebook requirement, contrast loss etc, which all are successfully addressed in proposed approach. Some comparisons with previously proposed methods are also made. Experimental results and analysis are used to prove the efficiency of proposed approach.
C1 [Shivani, Shivendra] Thapar Univ, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Shivani, S (corresponding author), Thapar Univ, Patiala, Punjab, India.
EM shivendra.shivani@thapar.edu
RI Shivani, Shivendra/AFN-2368-2022
OI Shivani, Shivendra/0000-0002-5931-6603
CR Ateniese G, 1996, INFORM COMPUT, V129, P86, DOI 10.1006/inco.1996.0076
   Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Fang Wen-Pinn, 2006, [Pattern Recognition and Image Analysis (Advances in Mathematical Theory and Applications), Pattern Recognition and Image Analysis. (Advances in Mathematical Theory and Applications)], V16, P632
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Feng JB, 2005, J SYST SOFTWARE, V76, P327, DOI 10.1016/j.jss.2004.07.250
   Fu MS, 2004, P IEEE INT C MULT EX
   Hou Y-C, 2014, IEEE T CIRCUITS SYST, V24, P5
   Hou Y-C, 2011, IEEE T CIRCUITS SYST, V21, P11
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   MACPHERSON LA, 2002, THESIS
   Nakajima M, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P303
   Naor M, 1997, LECT NOTES COMPUT SC, V1294, P322
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Taghaddos D, 2014, J INFORM HIDING MULT, V5
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Tso Hao-Kuan, 2013, J ADV MANAGEMENT SCI, V1
   Wang D-S, 2013, IEEE T INFORM FORENS, V8
   Wang Zhi-hui, 2011, J INFORM HIDING MULT
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Yamaguchi Y, 2015, INT J INFORM COMMUNI, V7
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 26
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5169
EP 5188
DI 10.1007/s11042-017-4422-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800004
DA 2024-07-18
ER

PT J
AU Subburam, S
   Selvakumar, S
   Geetha, S
AF Subburam, S.
   Selvakumar, S.
   Geetha, S.
TI High performance reversible data hiding scheme through multilevel
   histogram modification in lifting integer wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Reversible histogram modification; Lifting
   integer wavelet transform; Authentication and security
ID IMAGE; WATERMARKING; DIFFERENCE; QUALITY
AB This paper proposes a digital image reversible data hiding method in integer lifting transform domain. Owing to the characteristics of the natural image statistics, the neighbor pixel values are similar mostly and hence their differences are observed to be close or equal to zero. A histogram constructed out of this difference factor is exploited for reversible data embedding. Further, data is embedded at multiple levels in the integer lifting wavelet transform domain and hence the proposed scheme facilitates higher payload capacity and exceptional perceptual quality than the conventional single level histogram based techniques. The additional information involved for restoring the cover image and the secret payload is also less compared to the conventional schemes, as the proposed method employs a single parameter called "Embedding Level" for both hiding as well as extraction. Extensive experimentation with huge database of images, five existing RDH schemes and against seven steganalysers, shows that the proposed RDH scheme outperforms other schemes and proves to be a high performance RDH scheme in terms of all the desirable features of a reversible data hiding system like high payload, imperceptible, robustness, losslessness and minimal side information.
C1 [Subburam, S.] Prince Shri Venkateshwara Padmavathy Engn Coll, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
   [Selvakumar, S.] GKM Coll Engg, Dept Comp Sci & Engn, Madras, Tamil Nadu, India.
   [Geetha, S.] VIT Univ, Sch Comp Sci & Engn, Chennai Campus,Vandalur Kelambakkam Rd, Madras 600127, Tamil Nadu, India.
C3 Prince Shri Venkateshwara Padmavathy Engineering College; Vellore
   Institute of Technology (VIT); VIT Chennai
RP Geetha, S (corresponding author), VIT Univ, Sch Comp Sci & Engn, Chennai Campus,Vandalur Kelambakkam Rd, Madras 600127, Tamil Nadu, India.
EM geethabaalan@gmail.com
RI Subramanian, Selvakumar/AEO-1935-2022; Kamaraj, N./AAS-2531-2020; ,
   Dr.S.Geetha/ABI-7036-2020
OI Kamaraj, N./0000-0002-0424-5529; SUBASCHANDRABOSE,
   Subburam/0009-0000-4749-1765; S, Geetha/0000-0002-6850-9423; S, Dr.
   Selvakumar/0000-0001-9795-3569
FU All India Council for Technical Education
   [20/AICTE/RIFD/RPS(POLICY-II)65/2012-13]
FX This paper is based upon work supported by the All India Council for
   Technical Education - Research Promotion Scheme under Grant No.
   20/AICTE/RIFD/RPS(POLICY-II)65/2012-13.
CR Abdulrahman H., 2016, 4THACM WORKSHOP INF, P109
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Awranjeb M, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1877523
   COHEN A, 1992, COMMUN PUR APPL MATH, V45, P485, DOI 10.1002/cpa.3160450502
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Hsiao JY, 2009, SIGNAL PROCESS, V89, P556, DOI 10.1016/j.sigpro.2008.10.018
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lee S, 2007, IEEE T INF FOREN SEC, V2, P321, DOI 10.1109/TIFS.2007.905146
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Liu QC, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/383671
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Pei QQ, 2013, J SYST SOFTWARE, V86, P2841, DOI 10.1016/j.jss.2013.06.055
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qiu YQ, 2016, IEEE SIGNAL PROC LET, V23, P130, DOI 10.1109/LSP.2015.2504464
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Tseng HW, 2009, INFORM SCIENCES, V179, P2460, DOI 10.1016/j.ins.2009.03.014
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Weng SW, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P631
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yang B, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P143
   Yang CH, 2010, IET IMAGE PROCESS, V4, P223, DOI 10.1049/iet-ipr.2009.0316
   Yang CY, 2012, ETRI J, V34, P429, DOI [10.4218/etrij.11.0111.0312, 10.4218/etrij.12.0111.0312]
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 40
TC 36
Z9 38
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7071
EP 7095
DI 10.1007/s11042-017-4622-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700030
DA 2024-07-18
ER

PT J
AU Chen, Y
   Yang, M
   Chen, XQ
   Liu, B
   Wang, HN
   Wang, SH
AF Chen, Yi
   Yang, Ming
   Chen, Xianqing
   Liu, Bin
   Wang, Hainan
   Wang, Shuihua
TI Sensorineural hearing loss detection via discrete wavelet transform and
   principal component analysis combined with generalized eigenvalue
   proximal support vector machine and Tikhonov regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Tikhonov regularization; Sensorineural
   hearing loss; Magnetic resonance imaging; Dimensionality reduction
ID MR BRAIN IMAGES; CLASSIFICATION; ENTROPY
AB In the past, scholars used various computer vision and artificial intelligence methods to detect brain diseases via magnetic resonance imaging (MRI). In this paper, we proposed a novel system to detect sensorineural hearing loss (SNHL). First, we used three-level bior4.4 wavelet to decompose original brain image. Second, principal component analysis (PCA) was utilized for dimensionality reduction. Third, the generalized eigenvalue proximal support vector machine (GEPSVM) with Tikhonov regularization was employed as the classifier. The 10 repetitions of five-fold cross validation showed our method achieved an overall accuracy of 95.71 %. Our sensitivities over healthy control, left-sided SNHL, and right-sided SNHL are 96.00 %, 95.33 %, and 95.71 %, respectively. The proposed system is promising and effective in SNHL detection. It gives better performance than four state-of-the-art methods.
C1 [Chen, Yi; Wang, Hainan; Wang, Shuihua] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Chen, Yi] Hunan Policy Acad, Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
   [Chen, Yi; Wang, Hainan] Nanjing Univ Sci & Technol, Key Lab Image & Video Understanding Social Safety, Nanjing 210094, Jiangsu, Peoples R China.
   [Yang, Ming] Nanjing Med Univ, Nanjing Childrens Hosp, Dept Radiol, Nanjing 210008, Peoples R China.
   [Yang, Ming; Wang, Hainan] Quanzhou Normal Univ, Fujian Prov Univ, Key Lab Intelligent Comp & Informat Proc, Quanzhou 362002, Fujian, Peoples R China.
   [Chen, Xianqing] Zhejiang Normal Univ, Dept Elect Engn, Coll Engn, Jinhua 321004, Zhejiang, Peoples R China.
   [Liu, Bin] Southeast Univ, Zhong Da Hosp, Dept Radiol, Nanjing 210009, Peoples R China.
   [Wang, Shuihua] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
C3 Nanjing Normal University; Nanjing University of Science & Technology;
   Nanjing Medical University; Quanzhou Normal University; Fuzhou
   University; Zhejiang Normal University; Southeast University - China;
   City University of New York (CUNY) System; City College of New York
   (CUNY)
RP Wang, SH (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.; Wang, SH (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
EM wangshuihua@njnu.edu.cn
RI xianqing, chen/C-7474-2012; Wang, shuihua/G-7326-2016
OI Wang, shuihua/0000-0003-4713-2791; Chen, Yi/0000-0002-8762-4523
FU NSFC [61602250, 61503188, 61562041]; Natural Science Foundation of
   Jiangsu Province [BK20150983, BK20150982]; Program of Natural Science
   Research of Jiangsu Higher Education Institutions [14KJB520021]; Open
   Research Fund of Hunan Provincial Key Laboratory of Network
   Investigational Technology [2016WLZC013]; Open Fund of Fujian Provincial
   Key Laboratory of Data Intensive Computing [BD201607]; Jiangsu Key
   Laboratory of Image and Video Understanding for Social Safety, Nanjing
   University of Science and Technology [30916014107]
FX This paper was supported by NSFC (61602250, 61503188, 61562041), Natural
   Science Foundation of Jiangsu Province (BK20150983, BK20150982), Program
   of Natural Science Research of Jiangsu Higher Education Institutions
   (14KJB520021), Open Research Fund of Hunan Provincial Key Laboratory of
   Network Investigational Technology (2016WLZC013), Open Fund of Fujian
   Provincial Key Laboratory of Data Intensive Computing (BD201607),
   Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety, Nanjing University of Science and Technology (30916014107).
CR Aharamuthu K, 2013, J MECH SCI TECHNOL, V27, P641, DOI 10.1007/s12206-013-0114-y
   Akbarpour T, 2015, 2015 22ND IRANIAN CONFERENCE ON BIOMEDICAL ENGINEERING (ICBME), P293, DOI 10.1109/ICBME.2015.7404158
   [Anonymous], 2013, SCI WORLD J
   Bai YQ, 2015, J OPER RES SOC CHINA, V3, P1, DOI [10.1007/s40305-014-0068-5, 10.1007/s40305-015-0090-2]
   Baklouti R, 2016, J COMPUT SCI-NETH, V15, P34, DOI 10.1016/j.jocs.2015.11.005
   Chen C, 2016, FUEL, V182, P761, DOI 10.1016/j.fuel.2016.06.020
   Dash R., 2015, INT C COMP COMM SEC, P6
   Davò F, 2016, SOL ENERGY, V134, P327, DOI 10.1016/j.solener.2016.04.049
   Deokar SA, 2013, J SCI IND RES INDIA, V72, P92
   Dufrenois F, 2015, INT JOINT C NEUR NET, P12
   Gunning D, 2016, AI MAG, V37, P5, DOI 10.1609/aimag.v37i2.2624
   Hager WW, 2016, J GLOBAL OPTIM, V65, P657, DOI 10.1007/s10898-016-0402-z
   Hakimi F, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P1074, DOI 10.1109/KBEI.2015.7436195
   Ikawa N, 2013, INT J WAVELETS MULTI, V11, DOI 10.1142/S0219691313600096
   Ikuzawa T, 2016, J PARALLEL DISTR COM, V93-94, P44, DOI 10.1016/j.jpdc.2016.03.010
   Jenkal W, 2015, INT C MICROELECTRON, P39, DOI 10.1109/ICM.2015.7437982
   Karelle S, 2012, B-ENT, V8, P135
   Liu YH, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6050142
   Maldonado S, 2016, APPL INTELL, V45, P265, DOI 10.1007/s10489-016-0764-4
   Mangasarian OL, 2006, IEEE T PATTERN ANAL, V28, P69, DOI 10.1109/TPAMI.2006.17
   Mao Y, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL III, PROCEEDINGS, P737, DOI 10.1109/IITA.2008.502
   Masalski M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2222
   Monzack EL, 2015, CELL DEATH DIFFER, V22, P1995, DOI 10.1038/cdd.2015.48
   Morales JA, 2016, INT J ELEC POWER, V80, P312, DOI 10.1016/j.ijepes.2016.01.043
   Nakagawa T, 2016, AURIS NASUS LARYNX, V43, P489, DOI 10.1016/j.anl.2015.12.004
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Pasadas DJ, 2016, SENSOR ACTUAT A-PHYS, V246, P73, DOI 10.1016/j.sna.2016.05.019
   Rathinavelu A, 2007, LECT NOTES COMPUT SC, V4554, P786
   Saliba I, 2009, INT J PEDIATR OTORHI, V73, P1616, DOI 10.1016/j.ijporl.2009.07.010
   Singh M, 2013, MAPAN-J METROL SOC I, V28, P17, DOI 10.1007/s12647-013-0045-1
   Nguyen VB, 2016, J GLOBAL OPTIM, V64, P399, DOI 10.1007/s10898-015-0315-2
   Vasta R, 2016, CURR ALZHEIMER RES, V13, P566, DOI 10.2174/1567205013666160120151457
   Vaswani R, 2008, SOUTH MED J, V101, P107, DOI 10.1097/SMJ.0b013e31815d3d4d
   Wang SH, 2016, J AM GERIATR SOC, V64, pS350
   Wang SH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00106
   Wang SH, 2016, PEERJ, V4, DOI 10.7717/peerj.2207
   Wang SH, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18050194
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wright GD, 2016, DIFFERENTIATION, V91, P104, DOI 10.1016/j.diff.2016.01.002
   Xiong H, 2011, NEUROSCI LETT, V488, P204, DOI 10.1016/j.neulet.2010.11.030
   Xuan SB, 2016, INT J EARTH SCI, V105, P1591, DOI 10.1007/s00531-015-1272-1
   Yahia K, 2014, ISA T, V53, P603, DOI 10.1016/j.isatra.2013.12.002
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
   Zhang YD, 2015, INT J IMAG SYST TECH, V25, P317, DOI 10.1002/ima.22144
   Zhang YD, 2014, J FOOD ENG, V143, P167, DOI 10.1016/j.jfoodeng.2014.07.001
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
   Zhang YD, 2015, PEERJ, V3, DOI 10.7717/peerj.1251
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhang YD, 2015, ENTROPY-SWITZ, V17, P1795, DOI 10.3390/e17041795
   Zhang YD, 2014, J ELECTROMAGNET WAVE, V28, P2327, DOI 10.1080/09205071.2014.967365
   Zhang YD, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/840491
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
NR 53
TC 34
Z9 34
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3775
EP 3793
DI 10.1007/s11042-016-4087-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600049
DA 2024-07-18
ER

PT J
AU Gardezi, SJS
   Adjed, F
   Faye, I
   Kamel, N
   Eltoukhy, MM
AF Gardezi, Syed Jamal Safdar
   Adjed, Faouzi
   Faye, Ibrahima
   Kamel, Nidal
   Eltoukhy, Mohamed Meselhy
TI Segmentation of pectoral muscle using the adaptive gamma corrections
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Pectoral suppression; Edge detection; Adaptive gamma
   correction; Interpolation
ID COMPUTER-AIDED DETECTION; DENSITY; CLASSIFICATION; MAMMOGRAPHY
AB Accurate segregation of pectoral muscles is very crucial in breast cancer detection. Pectoral segmentation is a challenging task due to heterogeneous tissues densities, neighborhood complexities and breast shape variabilities. This paper presents an adaptive gamma correction method for pectoral suppression in mammograms. The proposed algorithm is adaptive to variations in shape, density of tissues and the curvature of pectoral boundary i.e. straight line or curved pectoral boundary. The method utilizes the morphological information of mammograms to discriminate the breast parenchyma from the rest of breast region. The adaptive gamma corrections enhance the mammograms according to tissues densities and provide a separation boundary between breast region and pectoral parenchymal. The method is tested on three types of tissues densities present in MIAS dataset i.e. Fatty, Fatty-glandular and Dense tissues. The goodness of segmentation is measured using jaccard similarity index between the ground truth and segmented regions. The proposed methods successfully detected 98.45 % of the pectoral regions and have an overall 92.79 % jaccard similarity index with the ground truth. Moreover, evaluation by experts also confirms good performance of the proposed method.
C1 [Gardezi, Syed Jamal Safdar; Adjed, Faouzi; Faye, Ibrahima; Kamel, Nidal] Univ Tecknol PETRONAS, Dept Fundamental & Appl Sci, Ctr Intelligent Signals & Imaging Res, Bandar Seri Iskandar 32610, Malaysia.
   [Adjed, Faouzi] Univ DEvry Val dEssonne, Lab IBISC EA 4526, F-91020 Evry, France.
   [Eltoukhy, Mohamed Meselhy] Suez Canal Univ, Fac Comp, Dept Comp Sci, Informat, Ismailia 41522, Egypt.
C3 Universiti Teknologi Petronas; Universite Paris Saclay; Egyptian
   Knowledge Bank (EKB); Suez Canal University
RP Gardezi, SJS; Faye, I (corresponding author), Univ Tecknol PETRONAS, Dept Fundamental & Appl Sci, Ctr Intelligent Signals & Imaging Res, Bandar Seri Iskandar 32610, Malaysia.
EM jamalgardezi@gmail.com; ibrahima_faye@utp.edu.my
RI safdar, shujaa/ABS-9583-2022; Gardezi, Jamal/AAH-7448-2019; Eltoukhy,
   Mohamed Meselhy/D-3026-2013; Faye, Ibrahima/AAH-5032-2020; Eltoukhy,
   Mohamed Meselhy/E-7504-2010
OI Gardezi, Jamal/0000-0002-1655-2956; Faye, Ibrahima/0000-0001-7777-1119; 
FU URIF [0153AA-B52]
FX The work is supported by URIF grant 0153AA-B52.
CR [Anonymous], 1994, DIGITAL MAMMO, DOI DOI 10.1007/S11999-016-4732-4
   [Anonymous], 2015, Global Cancer Facts Figures, V3rd
   Birdwell RL, 2005, RADIOLOGY, V236, P451, DOI 10.1148/radiol.2362040864
   BOYD NF, 1995, J NATL CANCER I, V87, P670, DOI 10.1093/jnci/87.9.670
   Camilus KS, 2010, J DIGIT IMAGING, V23, P562, DOI 10.1007/s10278-009-9240-6
   Ciatto S, 2003, EUR J RADIOL, V45, P135, DOI 10.1016/S0720-048X(02)00011-6
   Dense B, 2013, AUTODENSITY AUTOMATE
   Doi K, 2007, COMPUT MED IMAG GRAP, V31, P198, DOI 10.1016/j.compmedimag.2007.02.002
   Duarte M, 2012, 23 C BRAS ENG BIOM, V52
   E-Zaart A, 2010, COMPUT BIOL MED, V40, P392, DOI 10.1016/j.compbiomed.2010.02.003
   Fenton JJ, 2007, NEW ENGL J MED, V356, P1399, DOI 10.1056/NEJMoa066099
   Galdran A, 2015, LECT NOTES COMPUT SC, V9117, P587, DOI 10.1007/978-3-319-19390-8_66
   Ganesan K, 2013, COMPUT METH PROG BIO, V110, P48, DOI 10.1016/j.cmpb.2012.10.020
   Ge M, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034503
   Hacking D, MEDIOLATERAL VIEW
   Hacking D, CRANIOCAUDAL VIEW
   He WD, 2015, INT J BREAST CANCER, V2015, DOI 10.1155/2015/276217
   Keller B, 2011, INT C MED IM COMP CO, P562
   Kwok SM, 2004, IEEE T MED IMAGING, V23, P1129, DOI 10.1109/TMI.2004.830529
   Li YF, 2013, PATTERN RECOGN, V46, P681, DOI 10.1016/j.patcog.2012.09.021
   Liberman L, 2002, RADIOL CLIN N AM, V40, P409, DOI 10.1016/S0033-8389(01)00017-3
   Lu LJW, 2007, PHYS MED BIOL, V52, P4905, DOI 10.1088/0031-9155/52/16/013
   Matsubara T, 2001, INT CONGR SER, V1230, P515
   Mustra M, 2013, SIGNAL PROCESS, V93, P2817, DOI 10.1016/j.sigpro.2012.07.026
   Oliver A, 2008, IEEE T INF TECHNOL B, V12, P55, DOI 10.1109/TITB.2007.903514
   Olsen C, 2007, LECT NOTES COMPUT SC, V4522, P679
   Raba D, 2005, LECT NOTES COMPUT SC, V3523, P471
   Sreedevi S, 2015, PROCEDIA COMPUT SCI, V46, P1724, DOI 10.1016/j.procs.2015.02.117
   Wirth M. A., 2006, RECENT ADV BREAST IM, P640
   Zhang YD, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016634243
   Zhang YD, 2015, BIO-MED MATER ENG, V26, pS1283, DOI 10.3233/BME-151426
   Zhou C, 2001, MED PHYS, V28, P1056, DOI 10.1118/1.1376640
NR 32
TC 3
Z9 3
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3919
EP 3940
DI 10.1007/s11042-016-4283-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600057
DA 2024-07-18
ER

PT J
AU Hong, W
   Chen, MJ
   Chen, TS
   Huang, CC
AF Hong, Wien
   Chen, Meijin
   Chen, Tung Shou
   Huang, Chien-Che
TI An efficient authentication method for AMBTC compressed images using
   adaptive pixel pair matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AMBTC; Image authentication; Adaptive pixel pair matching; APPM
ID SCHEME; OPTIMIZATION
AB The existing image authentication methods for absolute moment block truncation coding (AMBTC) modify the bits of quantitation levels or bitmaps to embed the authentication code (AC). However, the modification of the bits in these methods is equivalent to the LSB replacement, which may introduce undesirable distortions. Besides, the modification of bitmap for embedding AC reduces the image quality significantly, especially at image edges. Moreover, the existing methods might not be able to detect some special modifications to the marked image. In this paper, we propose an efficient authentication method for the AMBTC compressed image. AC is obtained from the bitmap and the location information, and is embedded into the quantization levels using the adaptive pixel pair matching (APPM) technique. Since the bitmap is unchanged and the APPM embedment is efficient, a high image quality can be achieved. The experimental results reveal that the proposed method not only significantly reduces the distortion caused by embedding but also provides a better authentication result when compared to the prior state-of-art works.
C1 [Hong, Wien; Chen, Meijin] Sun Yat Sen Univ, Nanfang Coll, Dept Elect Commun & Software Engn, Guangzhou, Guangdong, Peoples R China.
   [Hong, Wien] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing, Jiangsu, Peoples R China.
   [Chen, Tung Shou; Huang, Chien-Che] Natl Taichung Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 Sun Yat Sen University; Nanfang College, Guangzhou; Nanjing University
   of Information Science & Technology; National Taichung University of
   Science & Technology
RP Chen, MJ (corresponding author), Sun Yat Sen Univ, Nanfang Coll, Dept Elect Commun & Software Engn, Guangzhou, Guangdong, Peoples R China.
EM dollar_95@outlook.com
RI Huang, Charles/ABI-3072-2020
OI Huang, Charles/0000-0001-5927-7918
CR [Anonymous], J INTERNET TECHNOLOG
   Chang CC, 2011, J SYST SOFTWARE, V84, P1462, DOI 10.1016/j.jss.2011.02.029
   Chen J, 2005, IMAGING SCI J, V53, P12, DOI 10.1179/136821905X26917
   Chen XY, 2017, J INTERNET TECHNOL, V18, P313, DOI 10.6138/JIT.2017.18.2.20160815
   Chin-Feng Lee, 2011, Journal of Multimedia, V6, P277, DOI 10.4304/jmm.6.3.277-284
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fu ZJ, 2019, IEEE T SERV COMPUT, V12, P813, DOI 10.1109/TSC.2016.2622697
   Fu ZJ, 2016, IEEE T INF FOREN SEC, V11, P2706, DOI 10.1109/TIFS.2016.2596138
   Gu B, 2017, IEEE T NEUR NET LEAR, V28, P1646, DOI 10.1109/TNNLS.2016.2544779
   Gu B, 2015, IEEE T NEUR NET LEAR, V26, P1403, DOI 10.1109/TNNLS.2014.2342533
   Gu B, 2015, NEURAL NETWORKS, V67, P140, DOI 10.1016/j.neunet.2015.03.013
   Hong W, 2015, INFORM SCIENCES, V308, P140, DOI 10.1016/j.ins.2014.03.030
   Hong W, 2013, INFORM SCIENCES, V221, P473, DOI 10.1016/j.ins.2012.09.013
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hu YC, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013012
   Kong Y, 2017, KNOWL-BASED SYST, V115, P123, DOI 10.1016/j.knosys.2016.10.016
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lin CC, 2015, LECT NOTES COMPUT SC, V9023, P433, DOI 10.1007/978-3-319-19321-2_33
   Lin CC, 2014, KSII T INTERNET INF, V8, P4588, DOI 10.3837/tiis.2014.12.020
   Liu Q, 2016, SECUR COMMUN NETW, V9, P4002, DOI 10.1002/sec.1582
   Lou DC, 2000, IEEE T CONSUM ELECTR, V46, P31, DOI 10.1109/30.826378
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH, V1st
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Tian Q, 2017, NEUROCOMPUTING, V238, P286, DOI 10.1016/j.neucom.2017.01.064
   Tsai P, 2005, IMAGING SCI J, V53, P149, DOI 10.1179/136821905X50406
   Wang J, 2016, FOOD BIOPROCESS TECH, P1
   Wu CM., 2014, International Journal of Signal Processing, Image Processing and Pattern Recognition, V7, P13, DOI [10.14257/ijsip.2014.7.5.02, DOI 10.14257/IJSIP.2014.7.5.02]
   Xia ZH, 2016, IEEE T PARALL DISTR, V27, P340, DOI 10.1109/TPDS.2015.2401003
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang YH, 2016, CHINA COMMUN, V13, P16, DOI 10.1109/CC.2016.7559071
   Zhong H, 2016, J INFORM HIDING MULT, V7, P2073
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 38
TC 9
Z9 9
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4677
EP 4695
DI 10.1007/s11042-017-4899-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500035
DA 2024-07-18
ER

PT J
AU Javaid, S
   Fahim, H
   Hamid, Z
   Hussain, FB
AF Javaid, Shumaila
   Fahim, Hamza
   Hamid, Zara
   Hussain, Faisal Bashir
TI Traffic-aware congestion control (TACC) for wireless multimedia sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless multimedia sensor networks; Rate adaptation; Congestion control
ID RELIABLE TRANSPORT; VIDEO; PROTOCOL
AB Wireless multimedia sensor networks (WMSNs) have emerged as a revolutionary technology, that has shifted the focus of low power wireless sensor networks (WSNs). These networks are aimed at gathering and delivering both scalar and multimedia data from the environment. WMSNs inherit the miniature size, low power, low processing and short range wireless communication traits from WSNs. Addition of multimedia content in WMSNs demands fulfillment of various QoS parameters like low end-to-end delay, acceptable jitter rate, low packet loss rate and higher throughput. Over the past few years, considerable research efforts have been directed towards the fulfillment of these QoS requirements; by proposing new traffic-aware medium access and routing algorithms. However, the issues of rate adaptation and congestion control are still largely unexplored. Congestion in wireless networks is a major cause of packet loss resulting in degraded network performance. In WMSNs congestion is a common occurrence, due to the communication of high data rate, bursty video traffic over lossy wireless link. Therefore, it is critical to adjust the sending rate of source nodes based on network conditions. This work investigates the issue of rate adaptation and congestion control in WMSNs. A traffic-aware congestion control protocol (TACC) is proposed that operates on end-to-end principle at the transport layer. The proposed protocol uses burst loss information to detect congestion at the destination and directs source nodes to adjust reporting rate accordingly. The proposed protocol is evaluated using simulation analysis which shows significant improvement in terms of packet losses, end-to-end delay, packet delivery ratio and received picture quality.
C1 [Javaid, Shumaila; Fahim, Hamza; Hamid, Zara] COMSATS Inst Informat Technol, Dept Comp Sci, Pk Rd, Islamabad, Pakistan.
   [Hussain, Faisal Bashir] Bahria Univ, Dept Comp Sci, Islamabad, Pakistan.
C3 COMSATS University Islamabad (CUI)
RP Hamid, Z (corresponding author), COMSATS Inst Informat Technol, Dept Comp Sci, Pk Rd, Islamabad, Pakistan.
EM shumaila.javed@comsats.edu.pk; hamzafahim@comsats.edu.pk;
   zarahamid@comsats.edu.pk; faisalwn@yahoo.com
RI Fahim, Hamza/JHU-4934-2023; Javaid, Shumaila/AAG-9195-2021; Hussain,
   Faisal Bashir/HIK-3794-2022; Fahim, Hamza/AAI-5204-2020
OI Fahim, Hamza/0000-0001-6537-7691; Fahim, Hamza/0000-0001-6537-7691;
   Hamid, Zara/0000-0001-8182-7453; javaid, shumaila/0000-0001-5424-915X
CR Acharya PAK, 2010, IEEE T MOBILE COMPUT, V9, P1535, DOI 10.1109/TMC.2010.108
   Akan ÖB, 2005, IEEE ACM T NETWORK, V13, P1003, DOI 10.1109/TNET.2005.857076
   Akyildiz IF, 2008, P IEEE, V96, P1588, DOI 10.1109/JPROC.2008.928756
   [Anonymous], 2012, 2012 5 INT C NEW TEC
   Apostolopoulos JG, 2001, PROC SPIE, V4310, P392
   Chen X, 2006, COMPUT COMMUN, V29, P3516, DOI 10.1016/j.comcom.2006.01.020
   Deshpande Sachin., 2006, INT C COMMUNICATIONS, P863
   Dunkels A., 2004, DISTRIBUTED TCP CACH
   Fuqiang Liu, 2006, 2006 3rd Annual IEEE Communications Society Conference on Sensor and Ad Hoc Communications and Networks (IEEE Cat. No. 06EX1523), P916
   Hamid Z., 2013, EURASIP J WIREL COMM, V2013, P1
   Hamid Z, 2014, WIRELESS PERS COMMUN, V75, P729, DOI 10.1007/s11277-013-1389-0
   Jaap S, 2004, TECHNICAL REPORT
   Klaue J, 2003, LECT NOTES COMPUT SC, V2794, P255, DOI 10.1007/978-3-540-45232-4_16
   Lee JH, 2010, SENSORS-BASEL, V10, P1486, DOI 10.3390/s100301487
   Liang YJ, 2008, IEEE T CIRC SYST VID, V18, P861, DOI 10.1109/TCSVT.2008.923139
   Lie A, 2008, MULTIMEDIA SYST, V14, P33, DOI 10.1007/s00530-007-0110-0
   Marchi Bruno, 2007, 2007 IEEE Symposium on Computers and Communications, P165, DOI 10.1109/ISCC.2007.4381601
   Perkins CharlesE., 2003, RFC3561
   Rangwala S, 2006, ACM SIGCOMM COMP COM, V36, P63, DOI 10.1145/1151659.1159922
   Rawat P, 2014, J SUPERCOMPUT, V68, P1, DOI 10.1007/s11227-013-1021-9
   Sharif A, 2010, IEEE SENSOR, P793, DOI 10.1109/ICSENS.2010.5690972
   Sharif A, 2009, IEEE INTL CONF IND I, P606, DOI 10.1109/INDIN.2009.5195872
   Talaat Mohammad A., 2011, INT J COMPUTER APPL, V18, P1
   Wan CY, 2011, ACM T SENSOR NETWORK, V7, DOI 10.1145/1921621.1921626
   Wan CY, 2005, IEEE J SEL AREA COMM, V23, P862, DOI 10.1109/JSAC.2005.843554
   Wang C, 2007, IEEE J SEL AREA COMM, V25, P786, DOI 10.1109/JSAC.2007.070514
   Zhuonong Xu, 2010, Proceedings of the 2010 International Conference on Communications and Mobile Computing (CMC 2010), P438, DOI 10.1109/CMC.2010.203
NR 27
TC 14
Z9 16
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4433
EP 4452
DI 10.1007/s11042-016-4224-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500023
DA 2024-07-18
ER

PT J
AU Seal, A
   Bhattacharjee, D
   Nasipuri, M
AF Seal, A.
   Bhattacharjee, D.
   Nasipuri, M.
TI Predictive and probabilistic model for cancer detection using computer
   tomography images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LR; LDA; MLP; GLCMs
AB This paper presents one predictive and two probabilistic models for detecting cancer in human liver using computed tomography image. Two probabilistic models are built using Logistic Regression (LR) and Linear Discriminant Analysis (LDA). Multilayer Perceptron (MLP) is used to make a predictive model. The proposed method consists of three basic steps. Initially, fuzzy c-means (FCM) clustering algorithm is used to segment the lesions from the human liver. Among all the segmented lesions, some of them are marked as abnormal (malignant) and others are marked as normal (benign) by the radiologist. It has been observed experimentally that the marked normal and abnormal lesions are distinguishable by their textures. Gray Level Co-occurrence Matrices (GLCMs) are one of the earliest methods for texture analysis. Thirteen Haralick features are extracted from the GLCMs of abnormal and normal lesions, which are further employed to build two probabilistic models using LR, LDA and a predictive model using MLP to determine the probability that the patient has cancer in his liver or not. A comparative study has been made based on the prediction accuracies of these three models. Moreover, LR and LDA are used to identify some of the features out of those thirteen features which play a statistically significant role in decision making by these probabilistic models. On the other hand, MLP doesn't have the ability to select such significant features. It is proved that logistic regression (96.67%) gives better accuracy as compared to LDA (95%) and MLP (94.4%).
C1 [Seal, A.] PDPM IIITDM Jabalpur, Jabalpur 482005, Madhya Pradesh, India.
   [Bhattacharjee, D.; Nasipuri, M.] Jadavpur Univ, Kolkata 700032, W Bengal, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; Jadavpur University
RP Seal, A (corresponding author), PDPM IIITDM Jabalpur, Jabalpur 482005, Madhya Pradesh, India.
EM ayan.seal@gmail.com
RI Seal, Ayan/AAI-1929-2020; Seal, Ayan/AAZ-9020-2020; Bhattacharjee,
   Debotosh/L-8521-2015; Bhattacharjee, Debotosh/Q-4065-2019
OI Seal, Ayan/0000-0002-9939-2926; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413
CR Al-Kadi OS, 2008, IEEE T BIO-MED ENG, V55, P1822, DOI 10.1109/TBME.2008.919735
   Al-Tarawneh M.S., 2012, Leonardo Electron J Practices And Technol, V11, P147
   [Anonymous], CATEGORICAL DATA ANA
   Bandhita P, 2006, MATHEMATIC STAT THEI
   Bezdek James C., 1981, PATTERN RECOGN
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bhattacharjee D, 2012, COMPUTATIONAL INTELL
   Bryan S, LECT 2 IMAGE PROCESS
   CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248, DOI 10.1109/TPAMI.1986.4767778
   Dunn JC J, 1974, CYBERNETICS, V3
   Foruzan AH, 2009, COMPUT MED IMAG GRAP, V33, P567, DOI 10.1016/j.compmedimag.2009.03.008
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Kuruvilla J, 2014, COMPUT METH PROG BIO, V113, P202, DOI 10.1016/j.cmpb.2013.10.011
   Lee Y, 2001, IEEE T MED IMAGING, V20, P595, DOI 10.1109/42.932744
   Liang XD, 2016, IEEE T MED IMAGING, V35, P713, DOI 10.1109/TMI.2015.2492618
   Lin L, 2015, IEEE T CYBERNETICS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez-Escobar M, 2012, COMPUT BIOL MED, V42, P1170, DOI 10.1016/j.compbiomed.2012.09.008
   Ruspini E.H, 1970, J INFORM SCI, V2
   Sharma D., 2011, INT C COMPUTATIONAL, V17, P872
   Vogel WV, 2004, J NUCL MED, V45, p15S
   Zhang X, 2010, IEEE T BIO-MED ENG, V57, P2622, DOI 10.1109/TBME.2010.2056369
NR 24
TC 6
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3991
EP 4010
DI 10.1007/s11042-017-4405-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600060
DA 2024-07-18
ER

PT J
AU Tian, F
   Shen, XK
   Liu, XM
AF Tian, Feng
   Shen, Xukun
   Liu, Xianmei
TI Multimedia automatic annotation by mining label set correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia annotation; Automatic annotation; Label set correlation
   mining
ID IMAGE TAG REFINEMENT; RELEVANCE; RECOGNITION; COMPLETION; RETRIEVAL
AB Organizing and retrieving multimedia data heavily rely on the relevant textual descriptions. Multimedia automatic annotation, which assigns text labels to multimedia samples, has been widely studied. Among others, search-based annotation methods are well suited for annotation tasks on large-scale datasets and are studied in depth because of their simplicity and scalability. However, classical search based annotation methods address this problem by treating each label independently, which ignores the correlation between different labels in the assigned label set. This paper aims to integrate the relevant information of the label set with respect to the multimedia content and the inner correlated information of the label set into a joint learning framework. We evaluate the performance of the proposed method on MIRFLICKR-25000 and NUS-WIDE datasets. Experimental results show that the proposed annotation method achieves excellent performance.
C1 [Tian, Feng; Liu, Xianmei] Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 163318, Peoples R China.
   [Shen, Xukun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Northeast Petroleum University; Beihang University
RP Tian, F (corresponding author), Northeast Petr Univ, Sch Comp & Informat Technol, Daqing 163318, Peoples R China.
EM tianfeng80@gmail.com; xukunshen11@gmail.com; liuxianmei78@gmail.com
OI Shen, Xukun/0000-0001-8509-9393
FU Natural Science Foundation of China [61502094, 61402099]; Natural
   Science Foundation of Heilongjiang Province of China [F2016002,
   F2015020]
FX Special thanks should go to the collaborators in the Lab for Media
   Search of National University of Singapore, for their instructive advice
   and useful suggestions on this work. This work is supported by the
   Natural Science Foundation of China (No. 61502094,61402099) and Natural
   Science Foundation of Heilongjiang Province of China(No. F2016002,
   F2015020).
CR [Anonymous], 2004, P 12 ANN ACM INT C M, DOI [10.1145/1027527.1027608, DOI 10.1145/1027527.1027608]
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], 2013, P 21 ACM INT C MULT
   [Anonymous], 2008, Proceedings of the 9th International Workshop on Multimedia Data Mining: held in conjunction with the ACM SIGKDD 2008
   [Anonymous], 2010, P ACM MULTIMEDIA
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Chen L, 2012, IEEE T MULTIMEDIA, V14, P1057, DOI 10.1109/TMM.2012.2187435
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Feng ZY, 2014, LECT NOTES COMPUT SC, V8695, P424, DOI 10.1007/978-3-319-10584-0_28
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jin Y., 2005, P 13 ANN ACM INT C M, P706
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Kuo YH, 2012, IEEE T MULTIMEDIA, V14, P1079, DOI 10.1109/TMM.2012.2190386
   Lee S, 2014, MULTIMED TOOLS APPL, V72, P1363, DOI 10.1007/s11042-013-1439-3
   Li XR, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2906152
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li XR, 2014, MULTIMEDIA SYST, V23, P29
   Liu AA, 2017, IEEE T CYBERNETICS, V47, P1781, DOI 10.1109/TCYB.2016.2582918
   Liu AA, 2017, IEEE T PATTERN ANAL, V39, P102, DOI 10.1109/TPAMI.2016.2537337
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu D, 2009, IEEE INT CON MULTI, P350, DOI 10.1109/ICME.2009.5202506
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   Liu J, 2006, SOFT COMPUT, V10, P61, DOI 10.1007/s00500-005-0467-y
   Liu J, 2013, NEUROCOMPUTING, V119, P3, DOI 10.1016/j.neucom.2012.02.052
   Nie L., 2012, P 20 ACM INT C MULTI, P59, DOI DOI 10.1145/2393347.2393363
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie WZ, 2016, MULTIMEDIA SYST, V22, P75, DOI 10.1007/s00530-014-0394-9
   Richter F, 2012, MULTIMED TOOLS APPL, V56, P35, DOI 10.1007/s11042-010-0554-7
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P883, DOI 10.1109/TMM.2012.2188782
   Socher R, 2010, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.2010.5540112
   Tian F, MULTIMEDIA TOOLS APP
   Tian F, MULTIMEDIA SYSTEMS
   Tian F, 2015, CHINESE J ELECTRON, V24, P790, DOI 10.1049/cje.2015.10.021
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Wang H, 2009, IEEE I CONF COMP VIS, P2029, DOI 10.1109/ICCV.2009.5459447
   Wang H, 2010, LECT NOTES COMPUT SC, V6314, P793, DOI 10.1007/978-3-642-15561-1_57
   Wang JD, 2014, COMPUT VIS IMAGE UND, V124, P61, DOI 10.1016/j.cviu.2014.02.011
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wang XJ, 2008, IEEE T PATTERN ANAL, V30, P1919, DOI 10.1109/TPAMI.2008.127
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Xiaojun Chang, 2014, Advances in Knowledge Discovery and Data Mining. 18th Pacific-Asia Conference, PAKDD 2014. Proceedings: LNCS 8444, P74, DOI 10.1007/978-3-319-06605-9_7
   Xu X., 2014, DATE, P349, DOI DOI 10.1080/00207543.2014.937013
   Zbou BL, 2015, PROC CVPR IEEE, P1492, DOI 10.1109/CVPR.2015.7298756
   Zhu XF, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P223, DOI 10.1145/2600428.2609556
NR 52
TC 4
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3473
EP 3491
DI 10.1007/s11042-017-5170-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600031
DA 2024-07-18
ER

PT J
AU Zou, FH
   Tang, XM
   Li, K
   Wang, YF
   Song, JK
   Yang, SY
   Ling, HF
AF Zou, Fuhao
   Tang, Xiaoman
   Li, Kai
   Wang, Yunfei
   Song, Jingkuan
   Yang, Shuangyuan
   Ling, Hefei
TI Hidden semantic hashing for fast retrieval over large scale document
   collection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic hashing; Non-negative matrix factorization; Laplacian graph;
   Multiplicative update rules
ID ALGORITHMS
AB As is well known, the semantics of documents are exposed to us in latent way. However, most existing hashing methods ignore this fact and thus fail to discover the hidden semantic structure. To overcome this issue, we pay more attention to discover its latent semantic structure when hashing for document corpus in this paper. We mainly adopt two measures to discover the hidden structures. On the one hand, the Laplacian graph constructed in semantic space rather than in term-document space is used to capture the semantic structure for document corpus during hashing. On the other hand, motivated by the fact that non-negative matrix factorization (NMF) is an effective algorithm to discover the latent semantic structure for documents, we employ NMF to extract a parts-based representation for document. In addition, to reduce semantic loss when mapping parts-based representation into Hamming space, we impose sparse constraints to make the element of parts-based representation more close to binary values. The experimental results demonstrate that the proposed hashing method is competitive with the state-of-the-art methods in document hashing.
C1 [Zou, Fuhao; Tang, Xiaoman; Li, Kai; Wang, Yunfei; Ling, Hefei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Song, Jingkuan] Columbia Univ, Sch Engn & Appl Sci, New York, NY 10027 USA.
   [Yang, Shuangyuan] Xiamen Univ, Sch Software Engn, Xiamen 361005, Peoples R China.
C3 Huazhong University of Science & Technology; Columbia University; Xiamen
   University
RP Zou, FH (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM fuhao_zou@hust.edu.cn
RI Li, Kaixuan/AAS-9432-2021
OI Li, Kaixuan/0000-0002-4539-0335
FU National Natural Science Foundation of China [61672254, 61300222]; Key
   project of National Natural Science Foundation of China [U1536203];
   Natural Science Foundation of Hubei Province [2015CFB687]; Natural
   Science Foundation of Fujian Province [2015J01288]; Fundamental Research
   Funds for the Central Universities [HUST:2016YXMS088]
FX This work is supported in part by the National Natural Science
   Foundation of China under Grant No. 61672254 and 61300222, Key project
   of National Natural Science Foundation of China Grant No U1536203,
   Natural Science Foundation of Hubei Province Grant No. 2015CFB687 and
   Natural Science Foundation of Fujian Province, Grant No. 2015J01288, the
   Fundamental Research Funds for the Central Universities,
   HUST:2016YXMS088. The authors appreciate the valuable suggestions from
   the anonymous reviewers and the Editors.
CR [Anonymous], 2004, P 20 ACM S COMP
   [Anonymous], TR0502 RIC U DEP COM
   [Anonymous], P INT C MATH INF TEC
   [Anonymous], 2008, Proceedings of the 21st International Conference on Neural Information Processing Systems
   [Anonymous], NIPGS
   [Anonymous], INT J APPROX REAS IE
   [Anonymous], 2007, ADV NEURAL INF PROCE
   BENTLEY JL, 1990, PROCEEDINGS OF THE SIXTH ANNUAL SYMPOSIUM ON COMPUTATIONAL GEOMETRY, P187, DOI 10.1145/98524.98564
   Beygelzimer A., 2006, ICML, DOI DOI 10.1145/1143844.1143857
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chang XJ, 2017, IEEE T NEUR NET LEAR, V28, P2294, DOI 10.1109/TNNLS.2016.2582746
   Chang XJ, 2017, IEEE T IMAGE PROCESS, V26, P3911, DOI 10.1109/TIP.2017.2708506
   Chang XJ, 2017, IEEE T CYBERNETICS, V47, P1180, DOI 10.1109/TCYB.2016.2539546
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Guttman Antonin., 1984, P 1984 ACM SIGMOD C, P47
   Hoyer PO, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P557, DOI 10.1109/NNSP.2002.1030067
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jabeen F, 2016, MULTIMED TOOLS APPL, V75, P573, DOI 10.1007/s11042-014-2309-3
   Jiang QY, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2248
   Jiang X, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON KNOWLEDGE ENGINEERING AND APPLICATIONS (ICKEA 2016), P103, DOI 10.1109/ICKEA.2016.7803001
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Lei Z, 2016, IEEE T CYBERN, VPP, P1
   Li HJ, 2016, MULTIMED TOOLS APPL, V75, P8939, DOI 10.1007/s11042-014-2336-0
   Liang RZ, 2016, INT C PATT RECOG, P2954, DOI 10.1109/ICPR.2016.7900086
   Lin CJ, 2007, IEEE T NEURAL NETWOR, V18, P1589, DOI 10.1109/TNN.2007.895831
   Liu W, 2011, SER INF MANAGE SCI, V10, P1
   Lv Q, 2007, P 33 INT C VER LARG, P950
   Ma ZG, 2017, IEEE T MULTIMEDIA, V19, P1558, DOI 10.1109/TMM.2017.2659221
   Panigrahy R, 2006, PROCEEDINGS OF THE SEVENTHEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1186, DOI 10.1145/1109557.1109688
   Peng, 2006, AAAI, P342
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Tatwawadi K, 2016, BIOINFORMATICS, V32, P479, DOI 10.1093/bioinformatics/btw437
   WACHSMUTH E, 1994, CEREB CORTEX, V4, P509, DOI 10.1093/cercor/4.5.509
   Xie L, 2016, AAAI CONF ARTIF INTE, P294
   Xu JM, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1369
   Yang J, 2017, IEEE T INDUS INFORM, P1
   Zhang D, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P18
   Zhang D, 2010, LECT NOTES COMPUT SC, V5993, P577, DOI 10.1007/978-3-642-12275-0_51
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 44
TC 6
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3677
EP 3697
DI 10.1007/s11042-017-5219-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600042
DA 2024-07-18
ER

PT J
AU Münzer, B
   Schoeffmann, K
   Böszörmenyi, L
AF Muenzer, Bernd
   Schoeffmann, Klaus
   Boeszoermenyi, Laszlo
TI Content-based processing and analysis of endoscopic images and videos: A
   survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging; Endoscopic videos; Content-based video analysis;
   Medical multimedia
ID MINIMALLY INVASIVE SURGERY; WIRELESS CAPSULE ENDOSCOPY; LAPAROSCOPIC
   PARTIAL NEPHRECTOMY; AUGMENTED REALITY VISUALIZATION; SURFACE
   RECONSTRUCTION; DISTORTION CORRECTION; SURGICAL-INSTRUMENTS; FRAME
   CLASSIFICATION; AUTOMATIC DETECTION; RETRIEVAL-SYSTEM
AB In recent years, digital endoscopy has established as key technology for medical screenings and minimally invasive surgery. Since then, various research communities with manifold backgrounds have picked up on the idea of processing and automatically analyzing the inherently available video signal that is produced by the endoscopic camera. Proposed works mainly include image processing techniques, pattern recognition, machine learning methods and Computer Vision algorithms. While most contributions deal with real-time assistance at procedure time, the post-procedural processing of recorded videos is still in its infancy. Many post-processing problems are based on typical Multimedia methods like indexing, retrieval, summarization and video interaction, but have only been sparsely addressed so far for this domain. The goals of this survey are (1) to introduce this research field to a broader audience in the Multimedia community to stimulate further research, (2) to describe domain-specific characteristics of endoscopic videos that need to be addressed in a pre-processing step, and (3) to systematically bring together the very diverse research results for the first time to provide a broader overview of related research that is currently not perceived as belonging together.
C1 [Muenzer, Bernd; Schoeffmann, Klaus; Boeszoermenyi, Laszlo] Klagenfurt Univ, Lakeside Labs, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
C3 University of Klagenfurt
RP Münzer, B (corresponding author), Klagenfurt Univ, Lakeside Labs, Inst Informat Technol, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM bernd@itec.aau.at; ks@itec.aau.at; laszlo@itec.aau.at
FU University of Klagenfurt; Lakeside Labs GmbH, Klagenfurt, Austria;
   European Regional Development Fund; Carinthian Economic Promotion Fund
   (KWF) [KWF-20214 U. 3520/26336/38165]
FX Open access funding provided by University of Klagenfurt. This work was
   supported by Universitat Klagenfurt and Lakeside Labs GmbH, Klagenfurt,
   Austria and funding from the European Regional Development Fund and the
   Carinthian Economic Promotion Fund (KWF) under grant KWF-20214 U.
   3520/26336/38165.
CR Ackerman JD, 2002, PROC SPIE, V4661, P39, DOI 10.1117/12.460179
   Agrawal M, 2008, LECT NOTES COMPUT SC, V5305, P102, DOI 10.1007/978-3-540-88693-8_8
   Ahmadi SA, 2006, LECT NOTES COMPUT SC, V4190, P420
   Alexandre LA, 2008, INT CONF BIOMED, P38, DOI 10.1109/BMEI.2008.246
   Allan M, 2013, IEEE T BIO-MED ENG, V60, P1050, DOI 10.1109/TBME.2012.2229278
   Ameling S., 2009, BILDVERARBEITUNG MED, P346
   Amir-Khalili A, 2013, LECT NOTES COMPUT SC, V8198, P184, DOI 10.1007/978-3-642-41083-3_21
   [Anonymous], SPIE C SERIES
   [Anonymous], SPIE C SERIES
   [Anonymous], MULT EXP WORKSH ICME
   [Anonymous], JOURNAL OF ADVANCED
   [Anonymous], 12 INT WORKSH CONT B
   [Anonymous], SPIE C SERIES
   [Anonymous], IEEE INT C IM PROC 2
   [Anonymous], GYNECOL OBSTET
   [Anonymous], MICCAI
   [Anonymous], INT J COMPUT ASSIST
   [Anonymous], 2014, ABDOMEN THORACIC IMA, DOI DOI 10.1007/978-1-4614-8498-1_14
   [Anonymous], TENCON 2008 2008 IEE
   [Anonymous], 2010, BRIEF BINARY ROBUST
   [Anonymous], SPIE C SERIES
   [Anonymous], RECOVERING TISSUE DE
   [Anonymous], 2011, 17 INT C DIG SIGN PR, DOI DOI 10.1109/ICDSP.2011.6004900
   [Anonymous], LNCS
   [Anonymous], 2012 IEEE INT C ROB
   [Anonymous], P 1 ACM INT WORKSH H
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], LNCS
   [Anonymous], P 9 AS PAC IND ENG M
   [Anonymous], 2015 13 INT WORKSH C
   [Anonymous], INT J ADV COMPUTER S
   [Anonymous], SPIE C SERIES
   [Anonymous], 20 BRIT MACH VIS C B
   [Anonymous], LECT NOTES COMPUT SC
   [Anonymous], THESIS
   [Anonymous], GASTROINTEST ENDOSC
   [Anonymous], BIOMEDICAL ENG ONLIN
   [Anonymous], SPIE SPIE C SERIES
   [Anonymous], IEEE INT S BIOM IM I
   [Anonymous], PROCEDIA TECHNOL
   [Anonymous], IEEE INTL SYMPOSIUM
   [Anonymous], P ACM SIGHIT INT HLH
   Arnold M, 2010, EURASIP J IMAGE VIDE, DOI 10.1155/2010/814319
   Arnold M, 2009, 2009 13TH INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, P47, DOI 10.1109/IMVIP.2009.16
   Asari KV, 1999, IEEE T MED IMAGING, V18, P345, DOI 10.1109/42.768843
   Atasoy S, 2010, LECT NOTES COMPUT SC, V6362, P437
   Barreto JP, 2007, 3DTV CONF, P354
   Bashar MK, 2010, MED IMAGE ANAL, V14, P449, DOI 10.1016/j.media.2009.12.001
   Baumhauer M, 2008, J ENDOUROL, V22, P751, DOI 10.1089/end.2007.9827
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Behrens A, 2011, IEEE ENG MED BIO, P6635, DOI 10.1109/IEMBS.2011.6091636
   Bergen T, 2016, IEEE J BIOMED HEALTH, V20, P304, DOI 10.1109/JBHI.2014.2384134
   Bernal J, 2012, PATTERN RECOGN, V45, P3166, DOI 10.1016/j.patcog.2012.03.002
   Bernal J, 2014, LECT NOTES COMPUT SC, V8899, P1, DOI 10.1007/978-3-319-13410-9_1
   Bernhardt Sylvain, 2013, Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging. Second International MICCAI Workshop, MCV 2012. Revised Selected Papers, P254, DOI 10.1007/978-3-642-36620-8_25
   Bichlmeier C, 2009, IEEE T MED IMAGING, V28, P1498, DOI 10.1109/TMI.2009.2018622
   Bilodeau GA, 2006, COMPUT MED IMAG GRAP, V30, P437, DOI 10.1016/j.compmedimag.2006.07.003
   Blum T, 2010, LECT NOTES COMPUT SC, V6363, P400
   Bouarfa L, 2012, MINIM INVASIV THER, V21, P129, DOI 10.3109/13645706.2011.580764
   Braga J, 2014, ADV INTELL SYST, V275, P239, DOI 10.1007/978-3-319-05951-8_23
   Burschka D, 2005, MED IMAGE ANAL, V9, P413, DOI 10.1016/j.media.2005.05.005
   Burschka D, 2005, ROBOT AUTON SYST, V52, P5, DOI 10.1016/j.robot.2005.03.013
   Cano AM, 2008, LECT NOTES COMPUT SC, V5104, P191, DOI 10.1007/978-3-540-70521-5_21
   Cao Y, 2004, LECT NOTES COMPUT SC, V3115, P160
   Cao Y, 2007, IEEE T BIO-MED ENG, V54, P1268, DOI 10.1109/TBME.2007.890734
   Carlos JR, 2015, 2015 13 INT WORKSH C, P1
   Casals A, 1996, IEEE INT CONF ROBOT, P895, DOI 10.1109/ROBOT.1996.503886
   Chengyu Wu, 2009, Proceedings of the 2009 Sixth International Conference on Fuzzy Systems and Knowledge Discovery (FSKD 2009), P388, DOI 10.1109/FSKD.2009.202
   Chowdhury M, 2015, PERCEPTION AND MACHINE INTELLIGENCE, 2015, P64, DOI 10.1145/2708463.2709046
   Chu XQ, 2010, LECT NOTES COMPUT SC, V6362, P522
   Climent J, 2012, COMPUT BIOL MED, V42, P614, DOI 10.1016/j.compbiomed.2012.02.007
   Collins Toby, 2012, Information Processing in Computer-Assisted Interventions. Proceedings Third International Conference, IPCAI 2012, P11, DOI 10.1007/978-3-642-30618-1_2
   Collins T., 2011, Medical Image Understanding Analysis
   Collins T, 2014, INT SYM MIX AUGMENT, P243, DOI 10.1109/ISMAR.2014.6948434
   Collins T, 2012, LECT NOTES COMPUT SC, V7511, P634, DOI 10.1007/978-3-642-33418-4_78
   Cunha JPS, 2008, IEEE T MED IMAGING, V27, P19, DOI 10.1109/TMI.2007.901430
   Dahyot R, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/139429
   Deguchi D, 2009, MED IMAGE ANAL, V13, P621, DOI 10.1016/j.media.2009.06.001
   del Fabro M, 2014, Multimedia Tools and Applications, P1
   Dhandra BV, 2006, INT C PATT RECOG, P695
   Dickens MM, 1998, 11TH IEEE SYMPOSIUM ON COMPUTER-BASED MEDICAL SYSTEMS, PROCEEDINGS, P246, DOI 10.1109/CBMS.1998.701364
   Dixon BJ, 2013, SURG ENDOSC, V27, P454, DOI 10.1007/s00464-012-2457-3
   Doignon C, 2007, LECT NOTES COMPUT SC, V4358, P314
   Doignon C, 2006, LECT NOTES COMPUT SC, V4190, P527
   Doignon C, 2008, LECT NOTES ELECTR EN, V8, P79
   Duda K, 2008, ICSES 2008 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS, CONFERENCE PROCEEDINGS, P197, DOI 10.1109/ICSES.2008.4673391
   Duplaga M, 2008, LECT NOTES COMPUT SC, V5188, P227, DOI 10.1007/978-3-540-85891-1_25
   El Meslouhi O, 2011, OPEN COMPUT SCI, V1, P341, DOI 10.2478/s13537-011-0020-2
   Elter M, 2006, INT C PATT RECOG, P599
   Forestier G, 2012, J BIOMED INFORM, V45, P255, DOI 10.1016/j.jbi.2011.11.002
   Fuchs H, 1998, LECT NOTES COMPUT SC, V1496, P934, DOI 10.1007/BFb0056282
   Fukuda Norio, 2010, Proceedings of the 2nd International Conference on Software Engineering and Data Mining (SEDM 2010), P684
   Gambadauro P, 2012, SURG INNOV, V19, P76, DOI 10.1177/1553350611415424
   Gaviao W, 2012, MED IMAGE ANAL, V16, P160, DOI 10.1016/j.media.2011.06.008
   Geng JS, 2014, IEEE SENS J, V14, P945, DOI 10.1109/JSEN.2013.2294679
   Giannarou S, 2010, LECT NOTES COMPUT SC, V6326, P314
   Giannarou S, 2009, I S BIOMED IMAGING, P1059, DOI 10.1109/ISBI.2009.5193238
   Giritharan B, 2008, IEEE ENG MED BIO, P4780, DOI 10.1109/IEMBS.2008.4650282
   Grasa Oscar G., 2011, IEEE International Conference on Robotics and Automation, P4816
   Grega M, 2010, ADV INTEL SOFT COMPU, V69, P535
   Groger M., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P53
   Groger M., 2005, Bildverarbeitung fur die Medizin 2005, P242
   Gschwandtner M., 2010, 10th IEEE International Conference on Information Technology and Applications in Biomedicine, P1
   Guthart G. S., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P618, DOI 10.1109/ROBOT.2000.844121
   Häfner M, 2013, COMP MED SY, P185, DOI 10.1109/CBMS.2013.6627786
   Haro BB, 2012, LECT NOTES COMPUT SC, V7510, P34, DOI 10.1007/978-3-642-33415-3_5
   Helferty JP, 2001, IEEE T MED IMAGING, V20, P605, DOI 10.1109/42.932745
   Hernández-Mier Y, 2010, COMPUT MED IMAG GRAP, V34, P579, DOI 10.1016/j.compmedimag.2010.02.002
   Higgins WE, 2008, COMPUT MED IMAG GRAP, V32, P159, DOI 10.1016/j.compmedimag.2007.11.001
   Höller K, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P713
   Hu MX, 2012, MED IMAGE ANAL, V16, P597, DOI 10.1016/j.media.2010.11.002
   Hughes-Hallett A, 2014, UROLOGY, V83, P266, DOI 10.1016/j.urology.2013.08.049
   Hwang S, 2010, INT CONF ACOUST SPEE, P678, DOI 10.1109/ICASSP.2010.5495103
   Hwang S, 2008, IEEE ENG MED BIO, P3004, DOI 10.1109/IEMBS.2008.4649835
   Iakovidis DK, 2010, COMPUT MED IMAG GRAP, V34, P471, DOI 10.1016/j.compmedimag.2009.11.005
   Iakovidis DK, 2005, COMP MED SY, P575, DOI 10.1109/CBMS.2005.6
   Ieiri S, 2012, PEDIATR SURG INT, V28, P341, DOI 10.1007/s00383-011-3034-x
   Jun SK, 2012, P IEEE RAS-EMBS INT, P25, DOI 10.1109/BioRob.2012.6290869
   Kallemeyn Nicole A, 2007, Iowa Orthop J, V27, P52
   Karargyris A, 2010, IEEE ENG MED BIOL, V29, P72, DOI 10.1109/MEMB.2009.935466
   Karkanis SA, 2003, IEEE T INF TECHNOL B, V7, P141, DOI 10.1109/TITB.2003.813794
   Katic Darko, 2014, Information Processing in Computer-Assisted Interventions. 5th International Conference, IPCAI 2014. Proceedings: LNCS 8498, P158, DOI 10.1007/978-3-319-07521-1_17
   Katic D, 2013, COMPUT MED IMAG GRAP, V37, P174, DOI 10.1016/j.compmedimag.2013.03.003
   Kelley WE, 2008, JSLS-J SOC LAPAROEND, V12, P351
   Khatibi Toktam, 2014, J Med Signals Sens, V4, P53
   Klank U, 2008, INT J COMPUT ASS RAD, V3, P331, DOI 10.1007/s11548-008-0223-8
   Ko SY, 2010, INT J CONTROL AUTOM, V8, P782, DOI 10.1007/s12555-010-0410-6
   Koninckx PR, 2008, J MINIM INVAS GYN, V15, P248, DOI 10.1016/j.jmig.2007.12.001
   Koppel D, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P269
   Kranzfelder M, 2013, J SURG RES, V185, P704, DOI 10.1016/j.jss.2013.06.022
   Krupa A, 2003, IEEE T ROBOTIC AUTOM, V19, P842, DOI 10.1109/TRA.2003.817086
   Kumar A, 2013, J DIGIT IMAGING, V26, P1025, DOI 10.1007/s10278-013-9619-2
   Kumar Suren, 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P480, DOI 10.1109/CoASE.2013.6654037
   Kumar S, 2014, IEEE INT CONF ROBOT, P4887, DOI 10.1109/ICRA.2014.6907575
   Lalys F, 2014, INT J COMPUT ASS RAD, V9, P495, DOI 10.1007/s11548-013-0940-5
   Lalys F, 2011, LECT NOTES COMPUT SC, V6533, P54, DOI 10.1007/978-3-642-18421-5_6
   Laranjo I., 2013, Distributed Computing and Artificial Intelligence, V217, P317
   Lau WY, 1997, WORLD J SURG, V21, P444, DOI 10.1007/PL00012268
   Lee J, 2007, APPLIED COMPUTING 2007, VOL 1 AND 2, P1041
   Lee SL, 2010, COMPUT MED IMAG GRAP, V34, P33, DOI 10.1016/j.compmedimag.2009.07.007
   Leong JJH, 2006, LECT NOTES COMPUT SC, V4190, P752
   Leszczuk MI, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-110
   Li BP, 2012, IEEE T INF TECHNOL B, V16, P323, DOI 10.1109/TITB.2012.2185807
   Li BP, 2009, IEEE T BIO-MED ENG, V56, P1032, DOI 10.1109/TBME.2008.2010526
   Liao H, 2009, MINIM INVASIV THER, V18, P332, DOI 10.3109/13645700903201217
   Liao R, 2013, IEEE T MULTIMEDIA, V15, P983, DOI 10.1109/TMM.2013.2244869
   Liedlgruber Michael, 2011, IEEE Rev Biomed Eng, V4, P73, DOI 10.1109/RBME.2011.2175445
   Lin Henry C, 2006, Comput Aided Surg, V11, P220, DOI 10.1080/10929080600989189
   Liu DY, 2007, P ANN INT IEEE EMBS, P3470, DOI 10.1109/IEMBS.2007.4353078
   Liu D, 2007, COMPUT METH PROG BIO, V88, P152, DOI 10.1016/j.cmpb.2007.07.011
   Lo B, 2008, LECT NOTES COMPUT SC, V5242, P104, DOI 10.1007/978-3-540-85990-1_13
   Lokoc Jakub, 2015, MultiMedia Modeling. 21st International Conference, MMM 2015. Proceedings: LNCS 8936, P291, DOI 10.1007/978-3-319-14442-9_31
   Loukas C, 2015, INT J MED ROBOT COMP, V11, P80, DOI 10.1002/rcs.1578
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo XB, 2012, MED IMAGE ANAL, V16, P577, DOI 10.1016/j.media.2010.11.001
   Lux M., 2013, P 4 ACM MULT SYST C, P141
   Lux M, 2010, MULTIMED TOOLS APPL, V46, P521, DOI 10.1007/s11042-009-0353-1
   Mackiewicz M, 2008, IEEE T MED IMAGING, V27, P1769, DOI 10.1109/TMI.2008.926061
   Maier-Hein L, 2013, MED IMAGE ANAL, V17, P974, DOI 10.1016/j.media.2013.04.003
   Makary MA, 2013, JAMA-J AM MED ASSOC, V309, P1591, DOI 10.1001/jama.2013.595
   Malti A, 2014, IEEE T BIO-MED ENG, V61, P1684, DOI 10.1109/TBME.2014.2300237
   Marayong P, 2003, IEEE INT CONF ROBOT, P1954, DOI 10.1109/ROBOT.2003.1241880
   Markelj P, 2012, MED IMAGE ANAL, V16, P642, DOI 10.1016/j.media.2010.03.005
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Miranda-Luna R, 2008, IEEE T BIO-MED ENG, V55, P541, DOI 10.1109/TBME.2007.903520
   Mirota D, 2009, LECT NOTES COMPUT SC, V5761, P91, DOI 10.1007/978-3-642-04268-3_12
   Mirota DJ, 2011, ANNU REV BIOMED ENG, V13, P297, DOI 10.1146/annurev-bioeng-071910-124757
   Moll M, 2009, IFMBE PROC, V22, P966
   Mountney P, 2007, LECT NOTES COMPUT SC, V4792, P34
   Mountney P, 2012, MED IMAGE ANAL, V16, P550, DOI 10.1016/j.media.2011.02.010
   Mountney P, 2010, IEEE SIGNAL PROC MAG, V27, P14, DOI 10.1109/MSP.2010.936728
   Mountney P, 2009, IEEE ENG MED BIO, P1184, DOI 10.1109/IEMBS.2009.5333939
   Moustris GP, 2011, INT J MED ROBOT COMP, V7, P375, DOI 10.1002/rcs.408
   Münzer B, 2016, COMP MED SY, P312, DOI 10.1109/CBMS.2016.28
   Münzer B, 2013, COMP MED SY, P534, DOI 10.1109/CBMS.2013.6627865
   Münzer B, 2014, COMP MED SY, P153, DOI 10.1109/CBMS.2014.58
   Münzer B, 2013, IEEE INT SYM MULTIM, P84, DOI 10.1109/ISM.2013.22
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Nageotte F, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2364, DOI 10.1109/IROS.2006.282647
   Neumuth T, 2011, INT J COMPUT ASS RAD, V6, P59, DOI 10.1007/s11548-010-0475-y
   Nicolau S, 2011, SURG ONCOL, V20, P189, DOI 10.1016/j.suronc.2011.07.002
   Oh J, 2007, MED IMAGE ANAL, V11, P110, DOI 10.1016/j.media.2006.10.003
   Oh J, 2009, 2009 PROCEEDINGS OF 6TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS (ISPA 2009), P724
   Oh J, 2009, IEEE T BIO-MED ENG, V56, P2190, DOI 10.1109/TBME.2008.2006035
   Okatani T, 1997, COMPUT VIS IMAGE UND, V66, P119, DOI 10.1006/cviu.1997.0613
   Oropesa I, 2013, SURG ENDOSC, V27, P1029, DOI 10.1007/s00464-012-2513-z
   Oropesa I, 2011, J SURG RES, V171, pE81, DOI 10.1016/j.jss.2011.06.034
   Padoy N, 2011, IEEE INT CONF ROBOT
   Padoy N, 2012, MED IMAGE ANAL, V16, P632, DOI 10.1016/j.media.2010.10.001
   Parchami M., 2014, Proceedings of the 7th International Conference on PErvasive Technologies Related to Assistive Environments, P25
   Park S., 2001, INT C MEDICAL IMAGE, P1419, DOI DOI 10.1007/3-540-45468-3_
   Parot V, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.7.076017
   Penne J, 2009, LECT NOTES COMPUT SC, V5761, P467, DOI 10.1007/978-3-642-04268-3_58
   Pezzementi Z, 2009, IEEE INT CONF ROBOT, P1225
   Prasath VBS, 2012, IEEE ENG MED BIO, P4014, DOI 10.1109/EMBC.2012.6346847
   Primus MJ, 2016, INT WORK CONTENT MUL
   Primus MJ, 2013, INT WORK CONTENT MUL, P223, DOI 10.1109/CBMI.2013.6576587
   Przelaskowski A, 2008, ADV INTEL SOFT COMPU, V47, P208
   Puerto GA, 2012, LECT NOTES COMPUT SC, V7511, P625, DOI 10.1007/978-3-642-33418-4_77
   Puerto-Souza GA, 2014, LECT NOTES COMPUT SC, V8333, P48, DOI 10.1007/978-3-642-53842-1_5
   Puerto-Souza GA, 2013, IEEE T MED IMAGING, V32, P1201, DOI 10.1109/TMI.2013.2239306
   Rangseekajee N, 2011, COMPUT CARDIOL CONF, V38, P549
   Reeff Mireille., 2006, INFORMATIK 2006 INFO, V2006, P467
   Reiter A, 2014, INT J ROBOT RES, V33, P342, DOI 10.1177/0278364913507796
   Richa R, 2011, MED IMAGE ANAL, V15, P302, DOI 10.1016/j.media.2010.12.002
   Riegler Riegler M. M., P 24 ACM INT C MULT, P968, DOI [10.1145/2964284.2976760, DOI 10.1145/2964284.2976760]
   Röhl S, 2012, MED PHYS, V39, P1632, DOI 10.1118/1.3681017
   Rosen J, 2006, IEEE T BIO-MED ENG, V53, P399, DOI 10.1109/TBME.2005.869771
   Rosen J, 2001, IEEE T BIO-MED ENG, V48, P579, DOI 10.1109/10.918597
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rungseekajee N., 2009, 2009 6th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, V2, P1076
   Rupp S, 2007, P ANN INT IEEE EMBS, P6566
   Sae Hwang, 2005, 13th Annual ACM International Conference on Multimedia, P912, DOI 10.1145/1101149.1101343
   Saint-Pierre CA, 2011, MACH VISION APPL, V22, P171, DOI 10.1007/s00138-007-0099-6
   Sauvée M, 2007, BIOMED SIGNAL PROCES, V2, P199, DOI 10.1016/j.bspc.2007.07.006
   Scharcanski J, 2006, IEEE IMAGE PROC, P129, DOI 10.1109/ICIP.2006.312376
   Selka F, 2015, COMPUT MED IMAG GRAP, V40, P49, DOI 10.1016/j.compmedimag.2014.11.012
   Shen Y, 2012, IEEE T INF TECHNOL B, V16, P98, DOI 10.1109/TITB.2011.2171977
   Sheraizin S, 2005, P ANN INT IEEE EMBS, P6551, DOI 10.1109/IEMBS.2005.1616001
   Shih TK, 2005, THIRD INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P15
   Sielhorst T, 2008, J DISP TECHNOL, V4, P451, DOI 10.1109/JDT.2008.2001575
   Simpfendörfer T, 2011, J ENDOUROL, V25, P1841, DOI 10.1089/end.2010.0724
   Song KT, 2012, IEEE ASME INT C ADV, P39, DOI 10.1109/AIM.2012.6266023
   Soper TD, 2012, IEEE T BIO-MED ENG, V59, P1670, DOI 10.1109/TBME.2012.2191783
   Spyrou E, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON SEMANTIC AND SOCIAL MEDIA ADAPTATION AND PERSONALIZATION (SMAP 2013), P41, DOI 10.1109/SMAP.2013.21
   Stanek SR, 2012, COMPUT METH PROG BIO, V108, P524, DOI 10.1016/j.cmpb.2011.04.003
   Staub C, 2010, P IEEE RAS-EMBS INT, P746, DOI 10.1109/BIOROB.2010.5628075
   Staub C, 2010, IEEE INT CONF ROBOT, P4585, DOI 10.1109/ROBOT.2010.5509601
   Stauder Ralf, 2014, Information Processing in Computer-Assisted Interventions. 5th International Conference, IPCAI 2014. Proceedings: LNCS 8498, P148, DOI 10.1007/978-3-319-07521-1_16
   Stehle T, 2006, ACTA POLYTECH, V46, P32
   Stehle T., 2009, Bildverarbeitung fur die Medizin, P142
   Stoyanov D, 2005, LECT NOTES COMPUT SC, V3750, P139, DOI 10.1007/11566489_18
   Su LM, 2009, UROLOGY, V73, P896, DOI 10.1016/j.urology.2008.11.040
   Sugimoto M, 2010, J HEPATO-BIL-PAN SCI, V17, P629, DOI 10.1007/s00534-009-0199-y
   Sung GT, 2001, UROLOGY, V58, P893, DOI 10.1016/S0090-4295(01)01423-6
   Suwelack S, 2012, COMPUTATIONAL BIOMECHANICS FOR MEDICINE: DEFORMATION AND FLOW, P39, DOI 10.1007/978-1-4614-3172-5_6
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.7017.09.004, 10.1016/j.cmpb.2012.09.004]
   Taylor RH, 2003, IEEE T ROBOTIC AUTOM, V19, P765, DOI 10.1109/TRA.2003.817058
   Taylor RH, 2006, P IEEE, V94, P1652, DOI 10.1109/JPROC.2006.880669
   Teber D, 2009, EUR UROL, V56, P332, DOI 10.1016/j.eururo.2009.05.017
   Tian J, 2011, SIGNAL IMAGE VIDEO P, V5, P329, DOI 10.1007/s11760-010-0204-6
   Tokgozoglu H. N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6239241
   Tonet O, 2007, COMPUT AIDED SURG, V12, P35, DOI 10.1080/10929080701210782
   Totz J, 2012, INT J COMPUT ASS RAD, V7, P423, DOI 10.1007/s11548-011-0631-z
   Totz J, 2011, LECT NOTES COMPUT SC, V6891, P89, DOI 10.1007/978-3-642-23623-5_12
   Tsevas S, 2008, IEEE INT C BIOINF BI, P921
   Twinanda AP, 2014, LECT NOTES COMPUT SC, V8675, P409, DOI 10.1007/978-3-319-10443-0_52
   Ukimura O, 2008, J ENDOUROL, V22, P803, DOI 10.1089/end.2007.9823
   Vilariño F, 2006, INT C PATT RECOG, P719
   Visentini-Scarzanella M, 2009, LECT NOTES COMPUT SC, V5761, P353, DOI 10.1007/978-3-642-04268-3_44
   Vitiello Valentina, 2013, IEEE Rev Biomed Eng, V6, P111, DOI 10.1109/RBME.2012.2236311
   Vogt F, 2003, LECT NOTES COMPUT SC, V2879, P356
   Vogt F, 2002, IEEE IMAGE PROC, P637
   Vogt F, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P352
   Voros S, 2007, INT J ROBOT RES, V26, P1173, DOI 10.1177/0278364907083395
   Voros S, 2010, IEEE-ASME T MECH, V15, P879, DOI 10.1109/TMECH.2010.2080683
   Voros S, 2008, P IEEE RAS-EMBS INT, P562, DOI 10.1109/BIOROB.2008.4762915
   Wang P, 2001, P ANN INT IEEE EMBS, V23, P3691, DOI 10.1109/IEMBS.2001.1019637
   Wang XW, 2010, IEEE T MED IMAGING, V29, P1213, DOI 10.1109/TMI.2009.2028341
   Wang Y, 2015, COMPUT METH PROG BIO, V120, P164, DOI 10.1016/j.cmpb.2015.04.002
   Wang Y, 2013, IEEE J BIOMED HEALTH, V17, P143, DOI 10.1109/TITB.2012.2226595
   Wang Y, 2010, IEEE T BIO-MED ENG, V57, P685, DOI 10.1109/TBME.2009.2034466
   Wei GQ, 1997, IEEE ENG MED BIOL, V16, P40, DOI 10.1109/51.566151
   Wengert Christian., 2006, BILDVERARBEITUNG F R, P419, DOI DOI 10.1007/3-540-32137-3_85
   Wieringa FokkoP., 2014, Journal of Medical Imaging, V15001, P1
   Winter C, 2006, IEEE T BIO-MED ENG, V53, P2035, DOI 10.1109/TBME.2006.877110
   Wolf R, 2011, LECT NOTES COMPUT SC, V6891, P203, DOI 10.1007/978-3-642-23623-5_26
   Wong WK, 2013, IEEE-ASME T MECH, V18, P1472, DOI 10.1109/TMECH.2012.2203919
   Wu CY, 2010, INT J COMPUT VISION, V86, P211, DOI 10.1007/s11263-009-0207-3
   Xia SR, 2005, P ANN INT IEEE EMBS, P1720
   Xia SR, 2003, P SOC PHOTO-OPT INS, V5286, P410, DOI 10.1117/12.538935
   Xiao-Ying T, 2009, INT J INF TECH DECIS, V8, P239, DOI 10.1142/S0219622009003363
   Yamaguchi Tetsuzo, 2004, Comput Aided Surg, V9, P203, DOI 10.3109/10929080500163505
   Yao R, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4, P1, DOI 10.1109/ICACC.2010.5487088
   Yip MC, 2012, IEEE T MED IMAGING, V31, P2169, DOI 10.1109/TMI.2012.2212718
   Zappella L, 2013, MED IMAGE ANAL, V17, P732, DOI 10.1016/j.media.2013.04.007
   Zhang C, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICIP.2000.899441
   Zhang XL, 2002, J ROBOTIC SYST, V19, P315, DOI 10.1002/rob.10043
   Zheng MM, 2005, COMPUT BIOL MED, V35, P259, DOI 10.1016/j.compbiomed.2004.01.002
NR 279
TC 82
Z9 89
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1323
EP 1362
DI 10.1007/s11042-016-4219-z
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400055
OA hybrid
DA 2024-07-18
ER

PT J
AU Khatoonabadi, SH
   Bajic, IV
   Shan, YF
AF Khatoonabadi, Sayed Hossein
   Bajic, Ivan V.
   Shan, Yufeng
TI Compressed-domain visual saliency models: a comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency; Fixation points; Compressed-domain processing; Motion
   vectors
ID QUALITY ASSESSMENT; CAMERA MOTION; ATTENTION; IMAGE; TRACKING;
   MECHANISMS; GAZE
AB Computational modeling of visual saliency has become an important research problem in recent years, with applications in video quality estimation, video compression, object tracking, retargeting, summarization, and so on. While most visual saliency models for dynamic scenes operate on raw video, several models have been developed for use with compressed-domain information such as motion vectors and transform coefficients. This paper presents a comparative study of eleven such models as well as two high-performing pixel-domain saliency models on two eye-tracking datasets using several comparison metrics. The results indicate that highly accurate saliency estimation is possible based only on a partially decoded video bitstream. The strategies that have shown success in compressed-domain saliency modeling are highlighted, and certain challenges are identified as potential avenues for further improvement.
C1 [Khatoonabadi, Sayed Hossein] Simon Fraser Univ, Burnaby, BC, Canada.
   [Bajic, Ivan V.] Simon Fraser Univ, Engn Sci, Burnaby, BC, Canada.
   [Shan, Yufeng] Cisco Syst Boxborough, Boxboro, MA USA.
C3 Simon Fraser University; Simon Fraser University
RP Khatoonabadi, SH (corresponding author), Simon Fraser Univ, Burnaby, BC, Canada.
EM skhatoon@sfu.ca; ibajic@ensc.sfu.ca; yshan@cisco.com
RI ; Bajic, Ivan/I-1241-2013
OI Khatoonabadi, Sayed Hossein/0000-0002-9927-9595; Bajic,
   Ivan/0000-0003-3154-5743
FU Cisco Research Award [573690]; NSERC [RGPIN 327249]
FX This work was supported in part by the Cisco Research Award CG# 573690
   and NSERC Grant RGPIN 327249.
CR Abdollahian G, 2008, IEEE IMAGE PROC, P693, DOI 10.1109/ICIP.2008.4711849
   Agarwal G, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P133
   [Anonymous], 1999, MPEG7 ISO
   [Anonymous], ACM MULT C MULT C
   [Anonymous], 1996, Signal detection theory and ROC analysis in psychology and diagnostics: Collected papers
   [Anonymous], 1996, J ECON LIT
   [Anonymous], 1997, Information theory and statistics
   Baudrier E, 2009, INT CONF ACOUST SPEE, P817, DOI 10.1109/ICASSP.2009.4959709
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Brown CD, 2006, CHEMOMETR INTELL LAB, V80, P24, DOI 10.1016/j.chemolab.2005.05.004
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Carlson N.R., 2010, Psychology the Science of Behaviour, P20
   Culibrk D, 2011, IEEE T IMAGE PROCESS, V20, P948, DOI 10.1109/TIP.2010.2080279
   Dagan I, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P56, DOI 10.3115/979617.979625
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Engelke U, 2011, IEEE SIGNAL PROC MAG, V28, P50, DOI 10.1109/MSP.2011.942473
   Fang YM, 2014, IEEE T CIRC SYST VID, V24, P27, DOI 10.1109/TCSVT.2013.2273613
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Feng X, 2011, IEEE T BROADCAST, V57, P81, DOI 10.1109/TBC.2010.2092150
   Fukuchi K, 2009, IEEE INT CON MULTI, P638, DOI 10.1109/ICME.2009.5202577
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hadizadeh H., 2011, 2011 IEEE International Conference on Multimedia and Expo, P1
   Hadizadeh H., 2013, THESIS
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hadizadeh H, 2012, IEEE T IMAGE PROCESS, V21, P898, DOI 10.1109/TIP.2011.2165292
   Hagiwara Aiko, 2011, P 1 INT WORKSH PERV
   Han S, 2010, VISION RES, V50, P2295, DOI 10.1016/j.visres.2010.05.034
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He ZH, 2005, IEEE T SIGNAL PROCES, V53, P2835, DOI 10.1109/TSP.2005.850355
   Hochberg Yosef, 1987, Multiple comparison procedures
   Itti L, 2005, PROC CVPR IEEE, P631
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   JEFFREYS H, 1946, PROC R SOC LON SER-A, V186, P453, DOI 10.1098/rspa.1946.0056
   Ji QG, 2013, SIGNAL PROCESS-IMAGE, V28, P241, DOI 10.1016/j.image.2012.11.008
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Khatoonabadi S. H., 2014, P 1 INT WORKSH PERC, P3
   Khatoonabadi SH, 2015, MULTIMED TOOLS APPL, V74, P10057, DOI 10.1007/s11042-015-2802-3
   Khatoonabadi SH, 2015, PROC CVPR IEEE, P5501, DOI 10.1109/CVPR.2015.7299189
   Khatoonabadi SH, 2014, IEEE IMAGE PROC, P1081, DOI 10.1109/ICIP.2014.7025215
   Khatoonabadi SH, 2013, IEEE T IMAGE PROCESS, V22, P300, DOI 10.1109/TIP.2012.2214049
   Khatoonabadi SH, SUPPLEMENTARY MAT CO
   Kim C, 2013, J VISION, V13, DOI 10.1167/13.4.5
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Larson EC, 2008, IEEE IMAGE PROC, P2572, DOI 10.1109/ICIP.2008.4712319
   Le Meur O., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3285, DOI 10.1109/ICIP.2011.6116372
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Lin XY, 2012, IEEE T CONSUM ELECTR, V58, P505, DOI 10.1109/TCE.2012.6227454
   Liu HT, 2011, IEEE T CIRC SYST VID, V21, P971, DOI 10.1109/TCSVT.2011.2133770
   Liu Z, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P568, DOI 10.1109/ICIS.2009.165
   Lu TR, 2010, IEEE IMAGE PROC, P1801, DOI 10.1109/ICIP.2010.5651644
   Ma YF, 2002, IEEE IMAGE PROC, P129
   Ma YF, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P426, DOI 10.1109/ICIP.2001.958142
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Mateescu VA, 2012, IEEE GLOBE WORK, P1304, DOI 10.1109/GLOCOMW.2012.6477770
   Mateescu Victor. A., 2013, 2013 IEEE INT C MULT, P1
   MILANESE R, 1995, OPT ENG, V34, P2428, DOI 10.1117/12.205668
   Mishra AK, 2012, IEEE T PATTERN ANAL, V34, P639, DOI 10.1109/TPAMI.2011.171
   Mital PK, 2011, COGN COMPUT, V3, P5, DOI 10.1007/s12559-010-9074-z
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   Muthuswamy K, 2013, IEEE SIGNAL PROC LET, V20, P996, DOI 10.1109/LSP.2013.2277884
   Park JC, 2008, J VISION, V8, DOI 10.1167/8.10.8
   Parkhurst DJ, 2003, SPATIAL VISION, V16, P125, DOI 10.1163/15685680360511645
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Schisterman EF, 2001, AM J EPIDEMIOL, V154, P174, DOI 10.1093/aje/154.2.174
   Sinha A, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P161
   Tatler BW, 2007, J VISION, V7, DOI 10.1167/7.14.4
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Vandewalle P, 2009, IEEE SIGNAL PROC MAG, V26, P37, DOI 10.1109/MSP.2009.932122
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wang Zhou., 2005, Digital Video Image Quality and Perceptual Coding, P431
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Winkler S, 2013, INT WORK QUAL MULTIM, P212, DOI 10.1109/QoMEX.2013.6603239
   Xie R, 2008, OPT ENG, V47, DOI 10.1117/1.2976797
NR 80
TC 7
Z9 7
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26297
EP 26328
DI 10.1007/s11042-016-4124-5
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500036
DA 2024-07-18
ER

PT J
AU Na, IS
   Kim, SH
AF Na, In Seop
   Kim, Soo Hyung
TI Music symbol recognition by a LAG-based combination model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical music recognition; Line adjacency graph; Run length encoding;
   Graph model; Set model
AB Most of optical music recognition (OMR) systems work under the assumption that the input image is scanner-based. However, we propose in this paper, camera based OMR system. Camera based OMR has a challengeable work in un-controlled environment such as a light, perspective, curved, transparency distortions and uneven staff-lines which tend to incur more frequently. In addition, the loss in performance of binarization methods, line thickness variation and space variation between lines are inevitable. In order to solve these problems, we propose a novel and effective staff-line removal method based on following three main ideas. First, a state-of-the-art staff-line detection method, Stable Path, is used to extract staff-line skeletons of the music score. Second, a line adjacency graph (LAG) model is exploited in a different manner over segmentation to cluster pixel runs generated from the run-length encoding (RLE) of an music score image. Third, a two-pass staff-line removal pipeline called filament filtering is applied to remove clusters lying on the staff-line. A music symbol is comprised of several parts so-called primitives, but the combination of these parts to form music symbol is unlimited. It causes difficulty applying the state-of-the-art method for music symbol recognition. To overcome these challenges and deal with primitive parts separately, we proposed a combination model which consists of LAG model, Graph model, and Set model as a framework for music symbol recognition. Our method shows impressive results on music score images captured from cameras, and gives high performance when applied to the ICDAR/GREC 2013 database, and a Gamera synthetic database. We have compared to some commercial software and proved the expediency and efficiency of the proposed method.
C1 [Na, In Seop; Kim, Soo Hyung] Chonnam Natl Univ, Sch Elect & Comp Engn, 77 Yongbong Ro, Gwangju 61186, South Korea.
C3 Chonnam National University
RP Na, IS (corresponding author), Chonnam Natl Univ, Sch Elect & Comp Engn, 77 Yongbong Ro, Gwangju 61186, South Korea.
EM ypencil@hanmail.net
RI Na, In Seop/K-2508-2018
OI Na, In Seop/0000-0001-6471-043X
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2015018993]; Basic Science Research Program through the National
   Research Foundation of Korea (NRF) - Ministry of Science, ICT & Future
   Planning [NRF-2015R1C1A1A02036495]; Korea Institute of Planning and
   Evaluation for Technology in Food, Agriculture, Forestry and
   Fisheries(IPET) through Agriculture, Food and Rural Affairs Research
   Center Support Program - Ministry of Agriculture, Food and Rural
   Affairs(MAFRA) [714002-07]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2015018993) and Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Science, ICT & Future Planning
   (NRF-2015R1C1A1A02036495) and This Research was supported by Korea
   Institute of Planning and Evaluation for Technology in Food,
   Agriculture, Forestry and Fisheries(IPET) through Agriculture, Food and
   Rural Affairs Research Center Support Program(Project No.: 714002-07)
   funded by Ministry of Agriculture, Food and Rural Affairs(MAFRA).
CR [Anonymous], STRUCTURED DOCUMENT
   Bainbridge D, 2001, COMPUT HUMANITIES, V35, P95, DOI 10.1023/A:1002485918032
   Bellini P., 2008, INTERACTIVE MULTIMED, P80
   Bellini P, 2007, COMPUT MUSIC J, V31, P68, DOI 10.1162/comj.2007.31.1.68
   Bui HN, 2014, INT C PATT RECOG, P2787, DOI 10.1109/ICPR.2014.480
   Bui HN, 2014, INT C PATT RECOG, P522, DOI 10.1109/ICPR.2014.100
   Cardoso JD, 2009, IEEE T PATTERN ANAL, V31, P1134, DOI 10.1109/TPAMI.2009.34
   Dalitz C, 2008, IEEE T PATTERN ANAL, V30, P753, DOI [10.1109/TPAMI.2007.70749, 10.1109/TPAM1.2007.70749]
   Fujinaga I., 2004, Visual Perception of Music Notation: On-Line and Off Line Recognition, P1, DOI DOI 10.4018/978-1-59140-298-5.CH001
   Homenda W, 2005, ADV SOFT COMP, P835
   Homenda W, 1995, OPTICAL PATTERN RECO, V2490, P230, DOI 10.1117/12.205779
   Kato H, 1992, STRUCTURED DOCUMENT, P435
   Kim SK, 2007, P INT COMP SOFTW APP, P131
   Modayur B. R., 1993, Machine Vision and Applications, V6, P140, DOI 10.1007/BF01211937
   Ng KC, 1996, IMAGE VISION COMPUT, V14, P39, DOI 10.1016/0262-8856(95)01038-6
   Pavlidis T, 1982, ALGORITHMS GRAPHICS, P99, DOI [10.1007/978-3-642-93208-3_6, DOI 10.1007/978-3-642-93208-3_6]
   Prerau D, 1970, STRUCTURED DOCUMENT, DOI [10.1007/3-540-32390-2_98, DOI 10.1007/3-540-32390-2_98]
   Pruslin D, 1966, STRUCTURED DOCUMENT
   Randriamahefa R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P898, DOI 10.1109/ICDAR.1993.395592
   Rebelo A, 2010, INT J DOC ANAL RECOG, V13, P19, DOI 10.1007/s10032-009-0100-1
NR 20
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25563
EP 25579
DI 10.1007/s11042-016-4170-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500003
DA 2024-07-18
ER

PT J
AU Becattini, F
   Seidenari, L
   Del Bimbo, A
AF Becattini, Federico
   Seidenari, Lorenzo
   Del Bimbo, Alberto
TI Indexing quantized ensembles of exemplar-SVMs with rejecting taxonomies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Media indexing; Object detection; Efficient data structures; Label
   transfer; Exemplar SVM; Vector quantization; Taxonomy learning
AB Ensembles of Exemplar-SVMs have been introduced as a framework for Object Detection but have rapidly found a large interest in a wide variety of computer vision applications such as mid-level feature learning, tracking and segmentation. What makes this technique so attractive is the possibility of associating to instance specific classifiers one or more semantic labels that can be transferred at test time. To guarantee its effectiveness though, a large collection of classifiers has to be used. This directly translates in a high computational footprint, which could make the evaluation step prohibitive. To overcome this issue we organize Exemplar-SVMs into a taxonomy, exploiting the joint distribution of Exemplar scores. This permits to index the classifiers at a logarithmic cost, while maintaining the label transfer capabilities of the method almost unaffected. We propose different formulations of the taxonomy in order to maximize the speed gain. In particular we propose a highly efficient Vector Quantized Rejecting Taxonomy to discard unpromising image regions during evaluation, performing computations in a quantized domain. This allow us to obtain ramarkable speed gains, with an improvement up to more than two orders of magnitude. To verify the robustness of our indexing data structure with reference to a standard Exemplar-SVM ensemble, we experiment with the Pascal VOC 2007 benchmark on the Object Detection competition and on a simple segmentation task.
C1 [Becattini, Federico; Seidenari, Lorenzo; Del Bimbo, Alberto] Univ Florence, Viale Morgagni 65, I-50134 Florence, Italy.
C3 University of Florence
RP Becattini, F (corresponding author), Univ Florence, Viale Morgagni 65, I-50134 Florence, Italy.
EM federico.becattini@unifi.it; lorenzo.seidenari@unifi.it;
   alberto.delbimbo@unifi.it
RI Becattini, Federico/AAE-8554-2021; Seidenari, Lorenzo/AAA-1848-2020
OI Becattini, Federico/0000-0003-2537-2700; Seidenari,
   Lorenzo/0000-0003-4816-0268
FU "THE SOCIAL MUSEUM AND SMART TOURISM", MIUR project
   [CTN01_00034_23154_SMST]
FX Federico Becattini and Lorenzo Seidenari are partially supported by "THE
   SOCIAL MUSEUM AND SMART TOURISM", MIUR project no.
   CTN01_00034_23154_SMST.
CR [Anonymous], P CVPR
   [Anonymous], P CVPR
   [Anonymous], P ECCV
   [Anonymous], P ICCV
   [Anonymous], 2010, PASCAL VISUAL OBJECT
   Aubry M, 2014, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2014.487
   Aytar Y, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.79
   Becattini F, 2016, 2016 14 INT WORKSH C, P1
   Bengio S., 2010, P NIPS
   Chen Y, 2004, P IGARSS
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dean T. L., 2013, P CVPR
   Deng J., 2011, P NIPS
   Deng J., 2014, EUR C COMP VIS, P48
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan JP, 2015, IEEE T IMAGE PROCESS, V24, P4172, DOI 10.1109/TIP.2015.2457337
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gao T., 2011, P ICCV
   Griffin G, 2008, PROC CVPR IEEE, P533
   Gronát P, 2013, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2013.122
   Guillaumin M, 2012, PROC CVPR IEEE, P3202, DOI 10.1109/CVPR.2012.6248055
   Hariharan B, 2012, LECT NOTES COMPUT SC, V7575, P459, DOI 10.1007/978-3-642-33765-9_33
   Jain A., 2013, P CVPR
   Kobayashi T, 2015, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2015.7298893
   Kuettel D, 2012, LECT NOTES COMPUT SC, V7578, P459, DOI 10.1007/978-3-642-33786-4_34
   Liu BY, 2013, PROC CVPR IEEE, P843, DOI 10.1109/CVPR.2013.114
   Malisiewicz T, 2011, IEEE I CONF COMP VIS, P89, DOI 10.1109/ICCV.2011.6126229
   Marszalek M., 2008, P ECCV
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Modolo D, 2015, CONTEXT FOREST OBJEC
   Modolo D, 2015, PROC CVPR IEEE, P3955, DOI 10.1109/CVPR.2015.7299021
   Mrowca D, 2015, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2015.232
   Ng A., 2002, P NIPS
   Ristin M, 2014, PROC CVPR IEEE, P3654, DOI 10.1109/CVPR.2014.467
   Rohrbach M., 2013, Advances in neural information processing systems, P46
   Sadeghi M.A., 2013, NIPS, P2949
   Sadeghi MA, 2014, LECT NOTES COMPUT SC, V8689, P65, DOI 10.1007/978-3-319-10590-1_5
   Spielman DA, 1996, AN S FDN CO, P96, DOI 10.1109/SFCS.1996.548468
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Yao BP, 2011, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR.2011.5995368
   Zepeda J, 2015, PROC CVPR IEEE, P3052, DOI 10.1109/CVPR.2015.7298924
NR 44
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22647
EP 22668
DI 10.1007/s11042-017-4794-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200038
DA 2024-07-18
ER

PT J
AU Shen, J
   Tan, HW
   Zhang, Y
   Sun, XM
   Xiang, Y
AF Shen, Jian
   Tan, Haowen
   Zhang, Yan
   Sun, Xingming
   Xiang, Yang
TI A new lightweight RFID grouping authentication protocol for multiple
   tags in mobile environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RFID; Grouping authentication; Multiple tags; Mobile environment
ID DELAY TOLERANT NETWORKS; SECURITY; PRIVACY
AB Radio Frequency Identification (RFID) is a promising technology in logistics management of mobile environment. Due to the practical prospects of low-cost RFID tags, multiple tags authentication remains an interesting topic. However, because of the resource restriction of low-cost tags, security and privacy risks remain crucial issues. Lots of research findings have been made emphasizing on the arrangement where single object to be verified is combined with only one tag, while the scenario that one object is attached with multiple tags is out of consideration, especially the authentication of large-size objects. In this paper, a new lightweight RFID grouping authentication protocol for multiple tags in mobile environment is proposed. A number of tags are attached to different parts of the large-size object. The proposed protocol can tolerate missing tags. The tags that do not respond will not disturb the entire authentication process, which guarantees that the object can be timely verified. Moreover, the security analysis shows that this protocol can offer sufficient security assurances and resist various attacks. Besides, the proposed protocol has better performance in terms of the execution time compared to previous studies.
C1 [Shen, Jian] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Jiangsu Collaborat Innovat Ctr Atmospher Environm, Jiangsu Engn Ctr Network Monitoring, 219 Ningliu Rd, Nanjing 210044, Jiangsu, Peoples R China.
   [Tan, Haowen; Sun, Xingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhang, Yan] Univ Oslo, Simula Res Lab Norway, Oslo, Norway.
   [Zhang, Yan] Univ Oslo, Dept Informat, Oslo, Norway.
   [Xiang, Yang] Deakin Univ, Ctr Cyber Secur Res, Deakin, Australia.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; University of Oslo;
   University of Oslo; Deakin University
RP Xiang, Y (corresponding author), Deakin Univ, Ctr Cyber Secur Res, Deakin, Australia.
EM s_shenjian@126.com; tan_halloween@foxmail.com; yang.xiang@deakin.edu.au;
   sunnudt@163.com; yang.xiang@deakin.edu.au
RI Sun, Xingming/AAD-1866-2019; Xiang, Yang/M-3527-2019; yang,
   xiang/HKN-0533-2023; Shen, Jian/AFL-0619-2022; Xiang, Yang/D-1280-2009
OI Xiang, Yang/0000-0001-5252-0831; Xiang, Yang/0000-0001-5252-0831; Shen,
   Jian/0000-0003-0519-9058
FU National Science Foundation of China [61300237, U1536206, U1405254,
   61232016, 61402234]; National Basic Research Program 973 [2011CB311808];
   Natural Science Foundation of Jiangsu province [BK2012461]; Jiangsu
   Engineering Center of Network Monitoring in NUIST [KJR1302]; Nanjing
   University of Information Science and Technology [S8113003001]; Nanjing
   Project of Science and Technology Activities for Returning from
   Overseas; Project of six personnel in Jiangsu Province [R2015L06];
   CICAEET fund; PAPD fund
FX This work is supported by the National Science Foundation of China under
   Grant No. 61300237, No. U1536206, No. U1405254, No. 61232016 and No.
   61402234, the National Basic Research Program 973 under Grant No.
   2011CB311808, the Natural Science Foundation of Jiangsu province under
   Grant No. BK2012461, the research fund from Jiangsu Engineering Center
   of Network Monitoring in NUIST under Grant No. KJR1302, the research
   fund from Nanjing University of Information Science and Technology under
   Grant No. S8113003001, the 2013 Nanjing Project of Science and
   Technology Activities for Returning from Overseas, the 2015 Project of
   six personnel in Jiangsu Province under Grant No. R2015L06, the CICAEET
   fund, and the PAPD fund.
CR Bellare M., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P419, DOI 10.1145/276698.276854
   Bolotnyy L, 2006, 2006 3RD ANNUAL INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS SYSTEMS - WORKSHOPS, P1
   Chien HY, 2009, NSWCTC 2009: INTERNATIONAL CONFERENCE ON NETWORKS SECURITY, WIRELESS COMMUNICATIONS AND TRUSTED COMPUTING, VOL 1, PROCEEDINGS, P550, DOI 10.1109/NSWCTC.2009.316
   Cho JS, 2008, 2008 22ND INTERNATIONAL WORKSHOPS ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOLS 1-3, P1591, DOI 10.1109/WAINA.2008.204
   Dhal S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P668, DOI 10.1109/IndiaCom.2014.6828046
   Fan K, 2016, PEER PEER NETW APPL, P1
   Fu ZJ, 2015, IEICE T COMMUN, VE98B, P190, DOI 10.1587/transcom.E98.B.190
   Guo P, 2014, J INTERNET TECHNOL, V15, P929, DOI 10.6138/JIT.2014.15.6.05
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Ha J, 2007, LECT NOTES COMPUT SC, V4412, P80
   Hanguang Luo, 2018, Wireless Networks, V24, P69, DOI 10.1007/s11276-016-1323-y
   He DB, 2015, INFORM SCIENCES, V321, P263, DOI 10.1016/j.ins.2015.02.010
   He DB, 2015, IEEE COMMUN MAG, V53, P71, DOI 10.1109/MCOM.2015.7010518
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   Juels A, 2006, IEEE J SEL AREA COMM, V24, P381, DOI 10.1109/JSAC.2005.861395
   Juels A, 2009, ACM T INFORM SYST SE, V13, DOI 10.1145/1609956.1609963
   Leng XF, 2009, 2009 FIRST ASIAN CONFERENCE ON INTELLIGENT INFORMATION AND DATABASE SYSTEMS, P73, DOI 10.1109/ACIIDS.2009.94
   Lien YH, 2008, ISI 2008: 2008 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS, P128, DOI 10.1109/ISI.2008.4565042
   Lin CC, 2007, LECT NOTES COMPUT SC, V4537, P634
   Liu H, 2013, IEEE T PARALL DISTR, V24, P1321, DOI 10.1109/TPDS.2012.218
   NAOR M, 1990, PROCEEDINGS OF THE TWENTY SECOND ANNUAL ACM SYMPOSIUM ON THEORY OF COMPUTING, P427, DOI 10.1145/100216.100273
   Ouafi K, 2008, LECT NOTES COMPUT SC, V4991, P263
   Piramuthu S, 2006, INTERNATIONAL CONFERENCE ON PERVASIVE SERVICES, PROCEEDINGS, P317
   RACKOFF C, 1992, LECT NOTES COMPUT SC, V576, P433
   Saito J, 2005, AINA 2005: 19th International Conference on Advanced Information Networking and Applications, Vol 2, P621
   Shen J, 2016, J COMMUN NETWORKS
   Shen J, 2015, J COMMUN NETW-S KOR, V17, P453, DOI 10.1109/JCN.2015.000083
   Shen J, 2015, J INTERNET TECHNOL, V16, P171
   Shen J, 2014, J COMMUN NETW-S KOR, V16, P656, DOI 10.1109/JCN.2014.000112
   Shen J, 2010, IEICE T INF SYST, VE93D, P2763, DOI 10.1587/transinf.E93.D.2763
   Shoup Victor., 1999, FORMAL MODELS SECURE
   Sun DZ, 2012, IEEE T CONSUM ELECTR, V58, P1246, DOI 10.1109/TCE.2012.6414992
   Sundaresan S., 2013, 2013 IEEE INT C RFID, P1
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
NR 34
TC 19
Z9 23
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22761
EP 22783
DI 10.1007/s11042-017-4386-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200044
DA 2024-07-18
ER

PT J
AU Allani, O
   Zghal, HB
   Mellouli, N
   Akdag, H
AF Allani, Olfa
   Zghal, Hajer Baazaoui
   Mellouli, Nedra
   Akdag, Herman
TI Pattern graph-based image retrieval system combining semantic and visual
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Image's region; Ontology module; Pattern graph
ID MODEL; ONTOLOGY; FUSION
AB In the literature, several image retrieval approaches that allow mapping between low-level features and high-level semantics have been proposed. Among these one can cite object recognition, ontologies, and relevance feedback. However, their main limitations concern their high dependence on reliable external resources (existing ontologies, learning sets, etc.) and lack of capacity to combine semantic and visual information and provide relevant results. This paper proposes a system aiming to improve image retrieval results. The proposed system is based on a pattern graph combining semantic and visual features. The idea is (1) to automatically build a modular ontology based on a learning step from textual corpus and terminological resource, (2) to organize visual features in a graph-based model where the combined module and graph represent a unique component called "pattern," and (3) to build a pattern graph. To this end our system has been implemented. The obtained experimental results show that the pattern graph that we propose enables an improvement of retrieval task.
C1 [Allani, Olfa; Zghal, Hajer Baazaoui] Univ Manouba, RIADI Lab, ENSI, Manouba, Tunisia.
   [Allani, Olfa; Mellouli, Nedra; Akdag, Herman] Paris 8 Univ, LIASD Lab, St Denis, France.
   [Mellouli, Nedra] Paris 8 Univ, IUT Montreuil, St Denis, France.
C3 Universite de la Manouba
RP Zghal, HB (corresponding author), Univ Manouba, RIADI Lab, ENSI, Manouba, Tunisia.
EM olfa.allani@gmail.com; hajer.baazaouizghal@riadi.rnu.tn;
   n.mellouli@iut.univ-paris8.fr; Herman.Akdag@ai.univ-paris8.fr
RI Mellouli, Nédra/AAB-4820-2020
OI Baazaoui, Hajer/0000-0002-2151-7397
CR Allani O, 2015, INT C COMP VIS THEOR, P2015
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], ARXIV161101872
   [Anonymous], 2013, MULTIMEDIA INFORM RE
   [Anonymous], P ICMR
   [Anonymous], 2007, P CIKM
   Arni T, 2009, LECT NOTES COMPUT SC, V5706, P500
   Hernández-Gracidas CA, 2013, MULTIMED TOOLS APPL, V62, P479, DOI 10.1007/s11042-011-0911-1
   Baker L. D., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P96, DOI 10.1145/290941.290970
   Bannour H, 2014, MULTIMED TOOLS APPL, V72, P2107, DOI 10.1007/s11042-013-1491-z
   Barbu T, 2013, MATH MODELS ENG COMP, P15
   Ben Mustapha Nesrine, 2012, Model and Data Engineering. Proceedings of the 2nd International Conference, MEDI 2012, P79, DOI 10.1007/978-3-642-33609-6_9
   Besbes G, 2014, MULTIMEDIA TOOLS APP, V1-25
   Choi D., 2012, P 11 WSEAS INT C ART, P83
   Crucianu M, 2004, RELEVANCE FEEDBACK I
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   dAquin M., 2006, MODULARIZATION KEY D
   Demir B, 2015, IEEE T GEOSCI REMOTE, V53, P2323, DOI 10.1109/TGRS.2014.2358804
   Fundel K, 2007, BIOINFORMATICS, V23, P365, DOI 10.1093/bioinformatics/btl616
   Hammiche S, 2005, 7 IEEE INT S MULT, P8
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Khalid Y. I. A., 2011, 2011 International Conference on Semantic Technology and Information Retrieval (STAIR 2011), P144, DOI 10.1109/STAIR.2011.5995779
   Lin D., 1998, P 36 ANN M ASS COMP, V2, P768, DOI DOI 10.3115/980432.980696
   Liqiang N, 2012, ACM T INF SYST
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lu Y., 2016, Multimedia Tools and Appl, P1
   Meghini C, 2001, J ACM, V48, P909, DOI 10.1145/502102.502103
   Mezaris V, 2004, EURASIP J APPL SIG P, V2004, P886, DOI 10.1155/S1110865704401188
   Minu R., 2012, INT J COMP UNPUB FEB
   Moehrmann Julia, 2013, Computer Analysis of Images and Patterns. 15th International Conference, CAIP 2013. Proceedings: LNCS 8048, P266, DOI 10.1007/978-3-642-40246-3_33
   Moro A., 2014, Trans. Assoc. Computat. Ling., V2, P231, DOI [10.1162/tacl_a_00179, DOI 10.1162/TACL_A_00179]
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie WZ, 2016, MULTIMED TOOLS APPL, V75, P12521, DOI 10.1007/s11042-014-2339-x
   Nie WZ, 2016, MULTIMEDIA SYST, V22, P75, DOI 10.1007/s00530-014-0394-9
   Pham T., 2007, Proc. ACM International Conference on Information and Knowledge Management, P439
   Poslad S, 2014, INFORM FUSION, V20, P225, DOI 10.1016/j.inffus.2014.02.003
   Raoui Y., 2011, Applied Mathematical Sciences, V5, P2109
   Rokach L, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P321, DOI 10.1007/0-387-25465-X_15
   Salton G, 1986, Introduction to Modern Information Retrieval
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Visco G., 2007, DESCRIPTION LOGICS
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang H, 2016, ACM T MULTIMED COMPU
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 52
TC 2
Z9 2
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 20287
EP 20316
DI 10.1007/s11042-017-4716-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500055
DA 2024-07-18
ER

PT J
AU Guo, YN
   Liu, QJ
   Wang, AH
   Sun, CL
   Tian, WY
   Naik, GR
   Abraham, A
AF Guo, Yina
   Liu, Qijia
   Wang, Anhong
   Sun, Chaoli
   Tian, Wenyan
   Naik, Ganesh R.
   Abraham, Ajith
TI Optimized phase-space reconstruction for accurate musical-instrument
   signal classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Musical-instrument classification; Phase-space reconstruction; Principal
   component analysis; Flexible neural tree
ID MODEL
AB Traditional musical-instrument classification methods mainly use regions in the time or/and frequency characteristics, cepstrum characteristics, and MPEG-7 characteristics, and they often lead to erroneous classification. Therefore, there is need to develop a more suitable method that is more applicable to the nonlinear characteristics of musical-instrument signals and can avoid the abovementioned problems. In this paper, a musical-instrument classification method that couples the optimized phase-space reconstruction (OPSR) with a flexible neural tree (FNT) is proposed. As per nonlinear dynamic theory, a principal component analysis and correlation coefficient are used to optimize the phase-space reconstruction (PSR) method. Multidimensional PSR results for different musical-instrument signals are extracted as the main components, and the dimensionality is reduced by the OPSR method. A probability density function (PDF) is introduced in the feature extraction step to differentiate musical instruments according to the phase-space-reconstructible characteristics. A FNT is adopted as a classifier to tackle the variability in musical-instrument signals and to improve the adaptive ability of various target classification problems. Experimental testing has been conducted to show that the proposed OPSR-PDF-FNT algorithm gives superior performance over other comparable algorithms and can classify 12 musical instruments with an accuracy of 98.2 %.
C1 [Guo, Yina; Liu, Qijia; Wang, Anhong; Sun, Chaoli; Tian, Wenyan] Taiyuan Univ Sci & Technol, Taiyuan 030024, Shanxi, Peoples R China.
   [Naik, Ganesh R.] Univ Technol, CHT, Sydney, NSW 2007, Australia.
   [Abraham, Ajith] Sci Network Innovat & Res Excellence, MIR Labs, POB 2259, Auburn, WA 98071 USA.
C3 Taiyuan University of Science & Technology; University of Technology
   Sydney
RP Guo, YN (corresponding author), Taiyuan Univ Sci & Technol, Taiyuan 030024, Shanxi, Peoples R China.
EM zulibest@163.com
RI Abraham, Ajith/A-1416-2008; Naik, Ganesh/G-5538-2011
OI Abraham, Ajith/0000-0002-0169-6738; Guo, Yina/0000-0002-0998-2448; Naik,
   Ganesh/0000-0003-1790-9838
FU National Natural Science Foundation of China [61301250, 61401298];
   Program for the Outstanding Innovative Teams of Higher Learning
   Institutions of Shanxi [[2015]3]; Shanxi Scholarship Council of China
   [2014-060]; Taiyuan University of Science and Technology [20152003];
   Project for "131" Talented Person Project of Higher Learning
   Institutions of Shanxi
FX Funding for this work was supported by the National Natural Science
   Foundation of China (NO. 61301250, NO. 61401298), Program for the
   Outstanding Innovative Teams of Higher Learning Institutions of Shanxi
   (NO. [2015]3), Project of Shanxi Scholarship Council of China (NO.
   2014-060), Doctoral Program of Taiyuan University of Science and
   Technology (NO. 20152003), and Project for "131" Talented Person Project
   of Higher Learning Institutions of Shanxi (NO. [2016]).
CR Agostini G, 2003, EURASIP J APPL SIG P, V2003, P5, DOI 10.1155/S1110865703210118
   Barbedo JGA, 2011, IEEE T AUDIO SPEECH, V19, P111, DOI 10.1109/TASL.2010.2045186
   Bao WZ, 2014, BIO-MED MATER ENG, V24, P3797, DOI 10.3233/BME-141209
   Benetos E, 2007, 4 SOUND MUS COMP C, V11, P13
   Bhalke DG, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P40, DOI 10.1109/SPIN.2014.6776918
   Bouaziz S, 2013, NEUROCOMPUTING, V117, P107, DOI 10.1016/j.neucom.2013.01.024
   Chen Y, 2009, SCI BUSINESS MEDIA, V2, P39
   Chen YC, 2006, NEUROCOMPUTING, V70, P305, DOI 10.1016/j.neucom.2006.01.022
   Deng JD, 2008, IEEE T SYST MAN CY B, V38, P429, DOI 10.1109/TSMCB.2007.913394
   Eronen A, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P19, DOI 10.1109/ASPAA.2001.969532
   Guo YN, 2014, J VIB CONTROL, V20, P1333, DOI 10.1177/1077546313481001
   Guo YN, 2013, CIRC SYST SIGNAL PR, V32, P2317, DOI 10.1007/s00034-013-9556-9
   Guo YN, 2012, CIRC SYST SIGNAL PR, V31, P2047, DOI 10.1007/s00034-012-9414-1
   Guo YN, 2012, J COMPUT, V7, P1099, DOI 10.4304/jcp.7.5.1099-1103
   Hess S, 2016, MON NOT R ASTRON SOC, V456, P4247, DOI 10.1093/mnras/stv2928
   Hong M, 2016, ENVIRON RES, V148, P560, DOI 10.1016/j.envres.2015.11.024
   Joder C, 2009, IEEE T AUDIO SPEECH, V17, P174, DOI 10.1109/TASL.2008.2007613
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kazi FI, 2014, INT J COMPUT APPL, V107, P17
   Koulaouzidis G, 2015, INT J CARDIOL, V182, P38, DOI 10.1016/j.ijcard.2014.12.067
   MCKAY Cory, 2010, THESIS MCGILL U CANA
   Misron M.M., 2014, Recent Advances on Soft Computing and Data Mining, P539
   Patil K, 2015, EURASIP J AUDIO SPEE, P1, DOI 10.1186/s13636-015-0070-9
   Rui R, 2012, ACTA ELECT SIN, V7
   Stehman SV, 1997, REMOTE SENS ENVIRON, V62, P77, DOI 10.1016/S0034-4257(97)00083-7
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Wang Y, 2015, ENERGY, V91, P556, DOI 10.1016/j.energy.2015.08.039
   Xu BB, 2014, BIOMED SIGNAL PROCES, V13, P313, DOI 10.1016/j.bspc.2014.06.005
   Xu T, 2013, IET IMAGE PROCESS, V7, P751, DOI 10.1049/iet-ipr.2012.0657
   Yang B, 2016, NEUROCOMPUTING, V179, P161, DOI 10.1016/j.neucom.2015.12.001
NR 30
TC 7
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20719
EP 20737
DI 10.1007/s11042-016-4021-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400015
DA 2024-07-18
ER

PT J
AU Kazemivash, B
   Moghaddam, ME
AF Kazemivash, Behnam
   Moghaddam, Mohsen Ebrahimi
TI A robust digital image watermarking technique using lifting wavelet
   transform and firefly algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarkin; Lifting wavelet transform; Firefly algorithm;
   Optimization; Arnold transform
ID SINGULAR-VALUE DECOMPOSITION; OPTIMIZATION
AB In this paper, an optimized and robust digital image watermarking technique based on lifting wavelet transform (LWT) and firefly algorithm is proposed. LWT is newer and faster generation of former wavelet transforms and firefly algorithm is an efficient optimizing algorithms. In current technique, base image decomposed by LWT into 4 sub bands then the first sub band separated into non overlapping blocks. After that blocks are sorted in order of descending based on standard derivation of each block. Selecting suitable blocks for special embedding process seems to be an optimization problem due to existence of a trade-off between imperceptibility and robustness. Firefly algorithm used to solve this trade-off while selecting primary blocks causes high robustness and low imperceptibility and vice versa. For improving security, Arnold transform applied to watermark and achieved scrambled image bits used as condition for embedding process. The proposed technique evaluated by variety of attacks like additive noise, average filter, median filter, sharpening filter and some other geometric and non-geometric attacks and experimental results showed its good imperceptibility and high robustness.
C1 [Kazemivash, Behnam; Moghaddam, Mohsen Ebrahimi] Shahid Beheshti Univ, Fac Comp Sci & Engn, GC, Tehran, Iran.
C3 Shahid Beheshti University
RP Kazemivash, B (corresponding author), Shahid Beheshti Univ, Fac Comp Sci & Engn, GC, Tehran, Iran.
EM be.kazemivash@gmail.com
CR Agoyi M, 2015, SIGNAL IMAGE VIDEO P, V9, P735, DOI 10.1007/s11760-014-0624-9
   Ali ES, 2015, NEURAL COMPUT APPL, V26, P1321, DOI 10.1007/s00521-014-1796-5
   Amiri T, 2016, MULTIMED TOOLS APPL, V75, P8527, DOI 10.1007/s11042-015-2770-7
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   Arora S., 2013, Int. J. Comput. Appl., V69, DOI 10.5120/11826-7528
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Daubechies I, 1998, J FOURIER ANAL APPL, V4, P247, DOI 10.1007/BF02476026
   Elshazly EH, 2015, SIGNAL IMAGE VIDEO P, V9, P89, DOI 10.1007/s11760-014-0684-x
   Fan WB, 2005, LECT NOTES ARTIF INT, V3802, P838
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Hajiramezan S, 2015, KNOWL BAS ENG INN KB, DOI [10.1109/KBEI.2015.7436044, DOI 10.1109/KBEI.2015.7436044]
   Helle C., 2000, Pasadena Houses
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Huang HN, 2015, J SIGNAL PROCESS SYS, V80, P197, DOI 10.1007/s11265-013-0863-y
   Ijyas VPT, 2014, WIRELESS PERS COMMUN, V79, P565, DOI 10.1007/s11277-014-1873-1
   Kaur R, 2015, WIRELESS PERS COMMUN, V80, P1547, DOI 10.1007/s11277-014-2099-y
   Khan M, 2015, NEURAL COMPUT APPL, V26, P845, DOI 10.1007/s00521-014-1747-1
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Mehta R, 2017, INT J MACH LEARN CYB, V8, P379, DOI 10.1007/s13042-015-0331-z
   Mehta R, 2018, INT J MACH LEARN CYB, V9, P145, DOI 10.1007/s13042-015-0329-6
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Miller ML, 2002, IM PROC P 2002 INT C, DOI [10.1109/ICIP.2002.1039904, DOI 10.1109/ICIP.2002.1039904]
   Rahebi J, 2016, MED BIOL ENG COMPUT, V54, P453, DOI 10.1007/s11517-015-1330-7
   Raja NSM, 2013, LECT NOTES COMPUT SC, V8297, P110, DOI 10.1007/978-3-319-03753-0_11
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Soliman MM, 2016, NEURAL COMPUT APPL, V27, P469, DOI 10.1007/s00521-015-1868-1
   Soniwal K, 2016, INT J ELECT ELECT CO, V5
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Walia E, 2014, SIGNAL IMAGE VIDEO P, V8, P859, DOI 10.1007/s11760-012-0312-6
   Wang JW, 2015, MULTIMEDIA SYST, V21, P345, DOI 10.1007/s00530-013-0338-9
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yang XS, 2008, NATURE INSPIRED META, P808
   Zhang SQ, 2006, J PHYS CONF SER, V48, P696, DOI 10.1088/1742-6596/48/1/131
NR 39
TC 28
Z9 28
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20499
EP 20524
DI 10.1007/s11042-016-3962-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400006
DA 2024-07-18
ER

PT J
AU Li, YT
   Shen, D
   Zhou, G
AF Li, Yantao
   Shen, Du
   Zhou, Gang
TI Energy optimization for mobile video streaming via an aggregate model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy optimization; Mobile video streaming; Scheduling algorithm;
   Aggregate model
AB Wireless video streaming on smartphones drains a significantly large fraction of battery energy, which is primarily consumed by wireless network interfaces for downloading unused data and repeatedly switching radio interface. In this paper, we propose an energy-efficient download scheduling algorithm for video streaming based on an aggregate model that utilizes user's video viewing history to predict user behavior when watching a new video, thereby minimizing wasted energy when streaming over wireless network interfaces. The aggregate model is constructed by a personal retention model with users' personal viewing history and the audience retention on crowd-sourced viewing history, which can accurately predict the user behavior of watching videos by balancing "user interest" and "video attractiveness". We evaluate different users streaming multiple videos in various wireless environments and the results illustrate that the aggregate model can help reduce energy waste by 20 % on average. In addition, we also discuss implementation details and extensions, such as dynamically updating personal retention, balancing audience and personal retention, categorizing videos for accurate model.
C1 [Li, Yantao] Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.
   [Li, Yantao; Shen, Du; Zhou, Gang] Coll William & Mary, Dept Comp Sci, Williamsburg, VA 23187 USA.
   [Li, Yantao] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Southwest University - China; William & Mary; Nanjing University
RP Li, YT (corresponding author), Southwest Univ, Coll Comp & Informat Sci, Chongqing 400715, Peoples R China.; Li, YT (corresponding author), Coll William & Mary, Dept Comp Sci, Williamsburg, VA 23187 USA.; Li, YT (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
EM yantaoli@foxmail.com
RI Zhou, Gang/T-7901-2017
OI Zhou, Gang/0000-0002-4425-9837; Li, Yantao/0000-0001-7648-5671
FU National Natural Science Foundation of China [61528206, 61402380];
   Natural Science Foundation of CQ CSTC [cstc2015jcyjA40044]; U.S.
   National Science Foundation [CNS-1253506, CNS-1618300]; Fundamental
   Research Funds for the Central Universities [XDJK2015B030]; State Key
   Laboratory for Novel Software Technology [KFKT2016B13]
FX We would like to thank the anonymous reviewers for their valuable
   comments. This work is supported in part by the National Natural Science
   Foundation of China (Grant nos. 61528206 and 61402380), the Natural
   Science Foundation of CQ CSTC (Grant no. cstc2015jcyjA40044), U.S.
   National Science Foundation (Grant nos. CNS-1253506 (CAREER) and
   CNS-1618300), the Fundamental Research Funds for the Central
   Universities (Grant no. XDJK2015B030), and the Opening Project of State
   Key Laboratory for Novel Software Technology (Grant No. KFKT2016B13).
CR Anand Manish., 2003, MOBICOM 03, P176, DOI [http://doi.acm.org/10.1145/938985.939004, DOI 10.1145/938985.939004]
   [Anonymous], 2013, PROC 5 WORKSHOP MOBI, DOI DOI 10.1145/2457413.2457417
   [Anonymous], 2011, 2011 IEEE INT S WORL
   [Anonymous], 2012, J. Eng. Sci. Technol. Rev.
   [Anonymous], P 19 ANN INT C MOB C
   Atawia R, 2016, IEEE J SEL AREA COMM, V34, P1389, DOI 10.1109/JSAC.2016.2545358
   Athivarapu PK, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P101
   Bagchi S, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1925101.1925106
   Brienza S, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2835374
   Bui DH, 2013, REAL TIM SYST SYMP P, P57, DOI 10.1109/RTSS.2013.14
   Dogar F.R., 2010, P 8 INT C MOBILE SYS, P107, DOI [DOI 10.1145/1814433.1814446, 10.1145/1814433.1814446]
   Feng Qian, 2010, 2010 18th IEEE International Conference on Network Protocols (ICNP 2010), P285, DOI 10.1109/ICNP.2010.5762777
   Finamore A., 2011, ACM IMC, P345, DOI DOI 10.1145/2068816.2068849
   Go Y, 2015, IEEE T MULTIMEDIA, V17, P1646, DOI 10.1109/TMM.2015.2451951
   Guo L., 2006, Proc. ACM SIGCOMM Internet Measurement Conference (IMC), P217
   He J, 2014, IEEE T MULTIMEDIA, V16, P242, DOI 10.1109/TMM.2013.2284894
   Hoque M., 2013, WORLD WIRELESS MOBIL, P1
   Hoque MA, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2840723
   Ishizu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND DATA INTENSIVE SYSTEMS, P318, DOI 10.1109/DSDIS.2015.38
   Kim S, 2015, 2015 INT C BIG DAT S, P9
   Ma D, 2015, IEEE PAC RIM CONF CO, P286, DOI 10.1109/PACRIM.2015.7334849
   Pering Trevor., 2006, P 4 INT C MOBILE SYS, P220, DOI DOI 10.1145/1134680.1134704
   Qi X, 2016, IEEE T MULTIMEDIA, V18, P1640, DOI 10.1109/TMM.2016.2572001
   Qi Xin., 2015, Proceedings of the 6th ACM Multimedia Systems Conference, P1
   Qian Feng, 2011, P 9 INT C MOB SYST A, P321, DOI DOI 10.1145/1999995.2000026
   Schulman A, 2010, MOBICOM 10 & MOBIHOC 10: PROCEEDINGS OF THE 16TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING AND THE 11TH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P85
   Seema A, 2015, IEEE T BROADCAST, V61, P346, DOI 10.1109/TBC.2015.2400816
   Tan E, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P123, DOI 10.1109/ICNP.2007.4375843
   Trestian R, 2012, IEEE IFIP NETW OPER, P444, DOI 10.1109/NOMS.2012.6211929
   Wenjie Hu, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1185, DOI 10.1109/INFOCOM.2015.7218493
   Yoon J, 2012, MOBICOM 12: PROCEEDINGS OF THE 18TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P209
   Zhou L, 2013, IEEE J SEL AREA COMM, V31, P981, DOI 10.1109/JSAC.2013.130516
   Zhu TX, 2012, PROCEEDINGS OF THE 4TH (2012) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, VOLS I AND II, P279
NR 33
TC 7
Z9 8
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20781
EP 20797
DI 10.1007/s11042-016-4002-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400018
DA 2024-07-18
ER

PT J
AU Liu, L
   Wang, L
   Chang, CC
AF Liu, Li
   Wang, Lifang
   Chang, Chin-Chen
TI A semantic compression scheme for digital images based on vector
   quantization and data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic compression; Compact image; PCA; Reversible data hiding
AB A novel semantic compression based on vector quantization (VQ) and data hiding is proposed. A compact version of the original image is generated, and then, VQ encoding is used in both the original image and the compact image to get their indexes of codewords in each block. In this processing, principal components analysis (PCA) is employed to rearrange the codebooks of the original image and the compact image in order to obtain the similar index table. Finally, the difference values of these indexes are calculated and embedded into the compact image using the reversible data hiding scheme to generate a small-sized compressed image that has similar content. And a high-quality reconstructed image with the original size easily can be obtained. Our experimental results have proven the expected merits of the proposed scheme.
C1 [Liu, Li; Wang, Lifang] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.
   [Liu, Li] Taiyuan Univ Sci & Technol, Coll Elect Informat & Engn, Taiyuan 030024, Shanxi, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Northwestern Polytechnical University; Taiyuan University of Science &
   Technology; Feng Chia University
RP Wang, L (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Shaanxi, Peoples R China.; Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
EM wanglf@nwpu.edu.cn; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023
FU National Natural Science Foundation of China [61540009]
FX This work was supported in part by The National Natural Science
   Foundation of China (No.61540009).
CR [Anonymous], P 42 ANN ALL C COMM
   [Anonymous], 2010, PRINCIPAL COMPONENT, DOI DOI 10.1007/B98835
   Ceglarek D, 2010, STUD COMPUT INTELL, V283, P111
   Gang L, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 1, PROCEEDINGS, P464, DOI 10.1109/IFITA.2009.100
   Govind PVS, 2015, PROCEDIA COMPUT SCI, V46, P491, DOI 10.1016/j.procs.2015.02.073
   Hu YC, 2012, OPTO-ELECTRON REV, V20, P187, DOI 10.2478/s11772-012-0016-z
   Jagadish H., 1999, VLDB, V99, P7
   Jagadish HV, 2004, PROC INT CONF DATA, P646, DOI 10.1109/ICDE.2004.1320034
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Lin SD, 2015, INT J COMPUT APPL, P174
   Liu L, 2015, MICROSYST TECHNOL, P1
   Liu ZR, 2002, P SOC PHOTO-OPT INS, V4875, P182, DOI 10.1117/12.477139
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Thangadurai K, 2014, INT CONF COMP COMMUN
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Willems FMJ, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY (ISIT), VOLS 1 AND 2, P214
   Wu YG, 2004, J ELECTRON IMAGING, V13, P324, DOI 10.1117/1.1666877
   Zhang XP, 2015, IET IMAGE PROCESS, V9, P54, DOI 10.1049/iet-ipr.2014.0321
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 22
TC 2
Z9 3
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20833
EP 20846
DI 10.1007/s11042-016-4011-0
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400021
DA 2024-07-18
ER

PT J
AU Liu, YJ
   Chang, CC
AF Liu, Yanjun
   Chang, Chin-Chen
TI A one-card-pass user authentication scheme using image morphing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User authentication; Security; Imagemorphing; De-morphing
ID SMART CARDS
AB A novel smart card user authentication scheme is proposed in this paper. It is the first authentication scheme that can achieve "one-card-pass" functionality, that is, an authorized card user may register with any department in an organization, and then, by just passing the face-to-face authentication but without conducting any extra registration, the card user can use his/her card to gain different services from all authorized departments in this organization. To enhance the security, image morphing and de-morphing techniques are used in our proposed scheme. Both the theoretical analyses and experimental results show that our proposed scheme is secure and very simple to implement.
C1 [Liu, Yanjun; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
C3 Feng Chia University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 407, Taiwan.
EM yjliu104@gmail.com; alan3c@gmail.com
RI liu, yan/HGV-1365-2022; Chang, Ching-Chun/JAN-6210-2023; liu,
   yan/HCI-5542-2022; 刘, 严君/GZL-5764-2022
CR BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Huang XY, 2011, IEEE T PARALL DISTR, V22, P1390, DOI 10.1109/TPDS.2010.206
   Hwang MS, 2000, IEEE T CONSUM ELECTR, V46, P28, DOI 10.1109/30.826377
   Juang WS, 2008, IEEE T IND ELECTRON, V55, P2551, DOI 10.1109/TIE.2008.921677
   Kim DJ, 2010, IEEE T CONSUM ELECTR, V56, P2678, DOI 10.1109/TCE.2010.5681156
   Kim SK, 2009, COMPUT COMMUN, V32, P1018, DOI 10.1016/j.comcom.2008.11.026
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Li CT, 2013, IET INFORM SECUR, V7, P3, DOI 10.1049/iet-ifs.2012.0058
   Li X, 2014, SECUR COMMUN NETW, V7, P1488, DOI 10.1002/sec.767
   Li X, 2013, J NETW COMPUT APPL, V36, P1365, DOI 10.1016/j.jnca.2013.02.034
   Mao Q, 2010, IETE TECH REV, V30, P343
   Mao Q, 2014, COMPUT J, DOI [10.1093/comjnl/bxu094, DOI 10.1093/C0MJNL/BXU094]
   Mao Q, 2015, MULTIMED TOOLS APPL, V74, P3207, DOI 10.1007/s11042-013-1780-6
   Qiangfu Zhao, 2011, Proceedings of the 2011 3rd International Conference on Awareness Science and Technology (iCAST), P117, DOI 10.1109/ICAwST.2011.6163124
   Song RG, 2010, COMPUT STAND INTER, V32, P321, DOI 10.1016/j.csi.2010.03.008
   Sun HM, 2000, IEEE T CONSUM ELECTR, V46, P958, DOI 10.1109/30.920446
   Wolberg G., 1989, Visual Computer, V5, P95, DOI 10.1007/BF01901485
   Yu JS, 2014, IEEE T INF FOREN SEC, V9, P2302, DOI 10.1109/TIFS.2014.2362979
   Yu PL, 2011, IEEE T INF FOREN SEC, V6, P606, DOI 10.1109/TIFS.2011.2134850
   Zhao Q, 2009, TECHNIQUE METHOD SYS
   Zhao QF, 2012, IEEE SYS MAN CYBERN, P364, DOI 10.1109/ICSMC.2012.6377728
   Zhu L, 2007, IEEE T IMAGE PROCESS, V16, P1481, DOI 10.1109/TIP.2007.896637
NR 22
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21247
EP 21264
DI 10.1007/s11042-016-4077-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400042
DA 2024-07-18
ER

PT J
AU Nandy, A
   Chakraborty, P
AF Nandy, Anup
   Chakraborty, Pavan
TI A study on human gait dynamics: modeling and simulations on OpenSim
   platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait dynamics; Musculoskeletal model; Normalized auto correlation;
   Regression analysis; OpenSim software
ID MUSCLE MOMENT ARMS; HUMAN WALKING; KNEE; COORDINATION; BIOMECHANICS;
   RECOGNITION; POSTSTROKE; PARAMETERS; FRAMEWORK; SUPPORT
AB The analysis of human gait dynamics allows an individual to obtain interesting biometric features through which gait disturbances can be observed from normal and abnormal gait patterns. The musculo-skeletal modeling of human movement helps to study the gait dynamics with expected simulations. It encourages the clinicians to identify the pathological gait for proper treatment. We have created a vision-based human locomotion laboratory to capture the healthy and non-healthy gait patterns. A low cost black uniform is taken to capture different person's gait data. This dress is made up with a piece of multiple color ribbon to identify different locations of body joints. It provides an added advantage during separation of different joint locations through color-based segmentation method. The demographic information of each subject helps to understand their gait dynamics. It instigates us to build a musculo-skeletal gait model on OpenSim simulation framework. The Regression Analysis (RA) technique is applied on crouch and healthy gait feature to measure the generalization ability and to uncover the gait profiles which are estimated by different error metrics such as, Root Mean Square Error (RMSE), Standard Deviation of Error (SDE), and Mean Error (ME). A computational method based on Normalized Auto Correlation (NAC) is computed to measure the gait disturbances in training subjects. The performance analysis of regression model on motion captured data has been validated with subject specific musculo-skeletal gait model on OpenSim platform.
C1 [Nandy, Anup] Natl Inst Technol Rourkela, Dept Comp Sci, Rourkela, India.
   [Nandy, Anup; Chakraborty, Pavan] Indian Inst Informat Technol Allahabad, Robot & Artificial Intelligence Lab Jhalwa, Allahabad 211012, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Indian Institute of Information Technology
   Allahabad
RP Nandy, A (corresponding author), Natl Inst Technol Rourkela, Dept Comp Sci, Rourkela, India.; Nandy, A (corresponding author), Indian Inst Informat Technol Allahabad, Robot & Artificial Intelligence Lab Jhalwa, Allahabad 211012, Uttar Pradesh, India.
EM nandy.anup@gmail.com; pavan@iiita.ac.in
RI Chakraborty, Pavan/Y-5495-2019
OI Chakraborty, Pavan/0000-0002-9260-1131
CR [Anonymous], 1992, GAIT ANAL NORMAL PAT
   Aqmar MR, 2014, COMPUT VIS IMAGE UND, V126, P38, DOI 10.1016/j.cviu.2014.05.004
   Arnold A S, 2000, Comput Aided Surg, V5, P108, DOI 10.1002/1097-0150(2000)5:2<108::AID-IGS5>3.0.CO;2-2
   Arnold AS, 2000, GAIT POSTURE, V11, P181, DOI 10.1016/S0966-6362(00)00046-1
   Baratin E, 2015, GAIT POSTURE, V41, P634, DOI 10.1016/j.gaitpost.2015.01.012
   Bruening DA, 2014, GAIT POSTURE, V39, P472, DOI 10.1016/j.gaitpost.2013.08.023
   Chen M, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P517
   Delp SL, 2007, IEEE T BIO-MED ENG, V54, P1940, DOI 10.1109/TBME.2007.901024
   Delp SL, 2000, COMPUT SCI ENG, V2, P46, DOI 10.1109/5992.877394
   DELP SL, 1990, IEEE T BIO-MED ENG, V37, P757, DOI 10.1109/10.102791
   Gage JR, 2004, TREATMENT GAIT PROBL
   Grimpampi E, 2013, GAIT POSTURE, V38, P523, DOI 10.1016/j.gaitpost.2013.01.031
   Higginson JS, 2006, J BIOMECH, V39, P1769, DOI 10.1016/j.jbiomech.2005.05.032
   Hutchinson JR, 2005, PALEOBIOLOGY, V31, P676
   Jonkers I, 2006, GAIT POSTURE, V23, P222, DOI 10.1016/j.gaitpost.2005.02.005
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Makihara Y, 2014, IEEE T SIGNAL PROCES, V62, P2066, DOI 10.1109/TSP.2014.2306174
   Mansouri M, 2012, J BIOMECH, V45, P1517, DOI 10.1016/j.jbiomech.2012.03.016
   Martínez F, 2013, J NEUROENG REHABIL, V10, DOI 10.1186/1743-0003-10-73
   Mondal S., 2012, Journal of Emerging Trends in Computing and Information Sciences, V3, P395
   Mori Atsushi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2194, DOI 10.1109/ICPR.2010.537
   MURRAY MP, 1964, J BONE JOINT SURG AM, V46, P335, DOI 10.2106/00004623-196446020-00009
   MURRAY WM, 1995, J BIOMECH, V28, P513, DOI 10.1016/0021-9290(94)00114-J
   Neptune RR, 2001, J BIOMECH, V34, P1387, DOI 10.1016/S0021-9290(01)00105-1
   Nishino K, 2015, GAIT POSTURE, V42, P127, DOI 10.1016/j.gaitpost.2015.04.018
   Osis ST, 2016, GAIT POSTURE, V46, P86, DOI 10.1016/j.gaitpost.2016.02.021
   Papageorgiou XS, 2015, IEEE INT C INT ROBOT, P6342, DOI 10.1109/IROS.2015.7354283
   Piazza SJ, 1996, J BIOMECH, V29, P723, DOI 10.1016/0021-9290(95)00144-1
   Reinbolt JA, 2011, PROC IUTAM, V2, P186, DOI 10.1016/j.piutam.2011.04.019
   Robertson G., 2004, RES METHODS BIOMECHA
   Sasaki K, 2006, GAIT POSTURE, V23, P383, DOI 10.1016/j.gaitpost.2005.05.002
   Schmid J, 2009, RECENT ADVANCES IN THE 3D PHYSIOLOGICAL HUMAN, P3, DOI 10.1007/978-1-84882-565-9_1
   Schutte L. M., 1993, IEEE Transactions on Rehabilitation Engineering, V1, P109, DOI 10.1109/86.242425
   Seth A, 2011, PROC IUTAM, V2, P212, DOI 10.1016/j.piutam.2011.04.021
   Simon S, 1993, J BONE JOINT SURG, V75
   Thelen DG, 2006, J BIOMECH, V39, P1107, DOI 10.1016/j.jbiomech.2005.02.010
   Trojaniello D, 2015, GAIT POSTURE, V42, P310, DOI 10.1016/j.gaitpost.2015.06.008
   Vasavada AN, 1998, SPINE, V23, P412, DOI 10.1097/00007632-199802150-00002
   Veilleux LN, 2016, GAIT POSTURE, V43, P257, DOI 10.1016/j.gaitpost.2015.10.007
   Winter D., 1990, BIOMECHANICS HUMAN M
   Zajac FE, 2003, GAIT POSTURE, V17, P1, DOI 10.1016/S0966-6362(02)00069-3
   Zajac FE, 2002, GAIT POSTURE, V16, P215, DOI 10.1016/S0966-6362(02)00068-1
   Zhang YJ, 2013, INT CONF SERVICE SCI, P64, DOI 10.1109/ICSS.2013.38
   Zhihan Lv, 2015, COMPARING KINECT2 BA
   Zhihan Lv, 2015, INTUITIVE EVALUATION
NR 45
TC 6
Z9 7
U1 5
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21365
EP 21400
DI 10.1007/s11042-016-4033-7
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400047
DA 2024-07-18
ER

PT J
AU Qu, T
   Zhang, QY
   Sun, SL
AF Qu, Tao
   Zhang, Quanyuan
   Sun, Shilei
TI Vehicle detection from high-resolution aerial images using spatial
   pyramid pooling-based deep convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unmanned aerial vehicle; Vehicle detection; Multi-scale spatial pyramid;
   Deep convolutional neural network
ID CLASSIFICATION; UAV
AB In recent years, vehicle detection from aerial images obtained using unmanned aerial vehicles (UAVs) has become a research focus in image processing as remote sensing platforms on UAVs are rapidly popularised. This study proposes a detection algorithm using a deep convolutional neural network (DCNN) based on multi-scale spatial pyramid pooling (SPP). By using multi-scale SPP models to sample characteristic patterns with different sizes, feature vectors with a fixed length are generated. This avoids the stretching- or cropping-induced deformation of input images of different sizes, thus improving the detection effect. In addition, an imaging pre-processing algorithm based on maximum normed gradient (NG) with multiple thresholds is proposed. By using this algorithm, this research restores the edges of objects disturbed by clutter in the environment. Meanwhile, the raised candidate object extraction algorithm based on the maximum binarized NG entails fewer computations as it generates fewer candidate windows. Experimental results indicate that the multi-scale SPP based DCNN can better adapt to input images of different sizes to learn of the multi-scale characteristics of objects, thus further improving the detection effect.
C1 [Qu, Tao; Sun, Shilei] Wuhan Univ, Int Sch Software, 37 Luoyu Rd, Wuhan 430072, Peoples R China.
   [Zhang, Quanyuan] Shanghai Spaceflight Inst Elect Commun Equipment, 1777 Zhongchun Rd, Shanghai 201100, Peoples R China.
C3 Wuhan University
RP Sun, SL (corresponding author), Wuhan Univ, Int Sch Software, 37 Luoyu Rd, Wuhan 430072, Peoples R China.
EM sunsl@whu.edu.cn
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   Bryson M, 2010, J FIELD ROBOT, V27, P632, DOI 10.1002/rob.20343
   Caltabiano D., 2005, 10th IEEE International Conference on Emerging Technologies and Factory Automation
   Casbeer DW, 2006, INT J SYST SCI, V37, P351, DOI 10.1080/00207720500438480
   Eisenbeiss H., 2006, Proceedings of the ISPRS Commission V Symposium on Image Engineering and Vision Metrology, P90
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Grenzdorffer G.J., 2008, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXXXVII.
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Howard A. G., 2013, Some improvements on deep convolutional neural network based image classification
   Hung C, 2014, REMOTE SENS-BASEL, V6, P12037, DOI 10.3390/rs61212037
   Hung C, 2012, ISPRS J PHOTOGRAMM, V68, P170, DOI 10.1016/j.isprsjprs.2012.01.009
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lambers K, 2007, J ARCHAEOL SCI, V34, P1702, DOI 10.1016/j.jas.2006.12.008
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mathieu Michael, 2013, ARXIV13125851
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sauerbier M, 2010, INT ARCH PHOTOGRAMM, V38, P526
   Spiess T, 2007, METEOROL Z, V16, P159, DOI 10.1127/0941-2948/2007/0195
   Turner D, 2014, REMOTE SENS-BASEL, V6, P4003, DOI 10.3390/rs6054003
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhang NQ, 2002, COMPUT ELECTRON AGR, V36, P113, DOI 10.1016/S0168-1699(02)00096-0
NR 26
TC 47
Z9 53
U1 0
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21651
EP 21663
DI 10.1007/s11042-016-4043-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400059
DA 2024-07-18
ER

PT J
AU Ullah, S
   Thar, K
   Hong, CS
AF Ullah, Saeed
   Thar, Kyi
   Hong, Choong Seon
TI Management of scalable video streaming in information centric networking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information centric networking (ICN); Scalable video streaming;
   Cooperative caching in CCN; Request forwarding
ID CODING EXTENSION; POPULARITY
AB Ability of caching the contents is one of the most important feature of an Information Centric Networking (ICN) node. By managing the cache space intelligently we can improve network's performance and increase users' Quality of Experience (QoE). Moreover, scalable video streaming in ICN is envisioned to be very beneficial as well as a challenging issue. In this paper, we are proposing a mechanism for cache management and request forwarding policies for scalable video streaming in ICN. Our proposed cache decision policy ensures to cache the base layer of a scalable video near to the users, which is mandatory layer for decoding any SVC encoded video and is needed by all the users with any data-rate budget, and consequently cache the higher layers in the upper nodes in the CCN/ICN within a specific RTT range. Furthermore, our intelligent cache decision cover fairness by considering router's cache capacity (inside the RTT range) and at the same time giving more priority to the nodes that are nearer to the users. A limited cooperative request forwarding mechanism, which is the part of our proposal, plays a role to improve users' QoE by providing the popular requested contents quickly. We have intensively simulated our proposed cache management and request forwarding scheme. The simulation results show that our proposed solution outperforms the current cache management schemes and improve the cache utilization. Also our proposed scheme decrease the traffic flowing inside the network by eliminating the request flooding and providing the requested contents from the nearby location to the users. The proposed scheme provides video faster to the users, specially the mandatory base layer is provided very quickly to the users.
C1 [Ullah, Saeed; Thar, Kyi; Hong, Choong Seon] Kyung Hee Univ, Dept Comp Sci & Engn, Yongin, South Korea.
C3 Kyung Hee University
RP Hong, CS (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Yongin, South Korea.
EM saeed@khu.ac.kr; kyithar@khu.ac.kr; cshong@khu.ac.kr
RI Thar, Kyi/AFO-1363-2022; Ullah, Saeed/ABF-3678-2021; Hong, Choong
   Seon/ABF-5527-2020
OI Thar, Kyi/0000-0001-9390-6511; Ullah, Saeed/0000-0001-8946-7640; Hong,
   Choong Seon/0000-0003-3484-7333
FU Institute for Information AMP; communications Technology Promotion(IITP)
   - Korea government(MSIP) [R0126- 16- 1009]
FX This work was supported by Institute for Information & communications
   Technology Promotion(IITP) grant funded by the Korea government(MSIP)
   (R0126- 16- 1009, Development of Smart Mediator for Mashup Service and
   Information Sharing among ICBMS Platform). CS Hong is the corresponding
   author.
CR Ahlgren B, 2012, IEEE COMMUN MAG, V50, P26, DOI 10.1109/MCOM.2012.6231276
   Amadeo M, 2016, IEEE COMMUN MAG, V54, P98, DOI 10.1109/MCOM.2016.7402268
   [Anonymous], 2011, P ACM SIGCOMM WORKSH
   Burke J., 2012, TECH REP
   Carofiglio G., 2011, Proceedings of the 2011 23rd International Teletraffic Congress (ITC 2011), P111
   Chai WK, 2012, LECT NOTES COMPUT SC, V7289, P27, DOI 10.1007/978-3-642-30045-5_3
   Chiocchetti R, 2013, IEEE ICC
   Guo S, 2012, LECT NOTES COMPUT SC, V7289, P41, DOI 10.1007/978-3-642-30045-5_4
   Han L, 2013, IEEE COMMUN LETT, V17, P1292, DOI 10.1109/LCOMM.2013.043013.130326
   Jiang D., 2015, TELECOMMUN SYST, P1
   Jiang DD, 2016, MULTIMED TOOLS APPL, V75, P14281, DOI 10.1007/s11042-016-3402-6
   Laoutaris N, 2004, IEEE IPCCC, P445
   Laoutaris N, 2006, PERFORM EVALUATION, V63, P609, DOI 10.1016/j.peva.2005.05.003
   Lederer S, 2013, IEEE INT CONF COMM, P677, DOI 10.1109/ICCW.2013.6649319
   Lederer Stefan., 2013, MULTIMEDIA EXPO ICME, P1
   Lee J, 2013, KSII T INTERNET INF, V7, P2430, DOI 10.3837/tiis.2013.10.006
   Li W., 2015, Popularity-driven Caching Strategy for Dynamic Adaptive Streaming over Information-Centric Networks
   Li WJ, 2015, IEEE ICC, P5747, DOI 10.1109/ICC.2015.7249238
   Li Z., 2014, J NANOMATER, V2014, P1
   Li ZQ, 2011, INT J POLYM SCI, V2011, DOI 10.1155/2011/803428
   Marpe D, 2006, IEEE COMMUN MAG, V44, P134, DOI 10.1109/MCOM.2006.1678121
   Petrangeli S, 2015, SVC BASED ADAPTIVE S
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Ponnusamy P., 2012, EUROPEAN J SCI RES, V68, P21
   Psaras I., 2012, P 2 ED ICN WORKSH IN, P55, DOI DOI 10.1145/2342488.2342501
   Psaras I, 2013, IEEE T PARALLEL DIST
   Psaras I, 2011, MODELLING EVALUATION, P78
   Saino L., 2013, Proceedings of the 3rd ACM SIGCOMM workshop on Information-centric networking, P27, DOI DOI 10.1145/2491224.2491232
   Schwarz H, 2008, IEEE SIGNAL PROC MAG, V25, P135, DOI 10.1109/MSP.2007.914712
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Sodagar I, 2011, IEEE MULTIMEDIA, V18, P62, DOI 10.1109/MMUL.2011.71
   Sourlas V, 2013, IEEE T NETW SERV MAN
   Suksomboon K, 2013, C LOCAL COMPUT NETW, P236, DOI 10.1109/LCN.2013.6761239
   Wang J.M., 2013, P 3 ACM SIGCOMM WORK, P61
   Wang JM, 2012, IEEE GLOB COMM CONF, P2727, DOI 10.1109/GLOCOM.2012.6503529
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Yi C, 2012, ACM SIGCOMM COMP COM, V42, P62, DOI 10.1145/2317307.2317319
NR 37
TC 19
Z9 20
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21519
EP 21546
DI 10.1007/s11042-016-4008-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400053
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, ZY
   Sun, RR
   Zhao, CW
   Wang, J
   Chang, CK
   Gupta, BB
AF Zhang, Zhiyong
   Sun, Ranran
   Zhao, Changwei
   Wang, Jian
   Chang, Carl K.
   Gupta, Brij B.
TI CyVOD: a novel trinity multimedia social network scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia social network; Security; Digital rights management;
   Recommendation algorithm; Prototype
ID ACCESS-CONTROL; MODEL; RECOMMENDATION; TRUST
AB How to comprehensively explore, improve and deploy multimedia social networks (MSNs) has become a hot topic in the era of emerging pervasive mobile multimedia. More and more MSNs offer a great number of convenient tools, services, and applications for multimedia contents including video and audio that users share willingly and on demand. However, concerns with digital rights management (DRM)-oriented multimedia security, as well as the efficiency of multimedia usage and sharing are meanwhile intensified due to easier distribution and reproduction of multimedia content in a wide range of social networks. The paper proposes a comprehensive framework for multimedia social network, and realized a cross-platform MSN prototype system, named as CyVOD, to support two kinds of DRM modes. The proposed framework effectively protects copyrighted multimedia contents against piracy, and supports a more efficient recommendation system for its better handling of the tradeoff between multimedia security and ease of use.
C1 [Zhang, Zhiyong; Sun, Ranran; Zhao, Changwei; Wang, Jian] Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.
   [Zhang, Zhiyong; Chang, Carl K.] Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
   [Gupta, Brij B.] Natl Inst Technol, Kurukshetra, Haryana, India.
C3 Henan University of Science & Technology; Iowa State University;
   National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Zhang, ZY (corresponding author), Henan Univ Sci & Technol, Informat Engn Coll, Luoyang 471023, Peoples R China.; Zhang, ZY (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM xidianzzy@126.com
RI zhang, ling/JXW-6931-2024; ZHANG, Zhiyong/AAG-3281-2021; Gupta, Brij
   B/E-9813-2011
OI ZHANG, Zhiyong/0000-0003-3061-7768; Gupta, Brij B/0000-0003-4929-4698;
   Sun, Ranran/0000-0001-7048-6331
FU National Natural Science Foundation of China [61370220]; Plan For
   Scientific Innovation Talent of Henan Province [2017JR0011]; Program for
   Innovative Research Team (in Science and Technology) in University of
   Henan Province [15IRTSTHN010]; Program for Henan Province Science and
   Technology [142102210425]; Project of the Cultivation Fund of Science
   and Technology Achievements of Henan University of Science and
   Technology [2015BZCG01]
FX The work was sponsored by National Natural Science Foundation of China
   Grant No. 61370220, Plan For Scientific Innovation Talent of Henan
   Province Grant No. 2017JR0011, Program for Innovative Research Team (in
   Science and Technology) in University of Henan Province Grant No.
   15IRTSTHN010, Program for Henan Province Science and Technology Grant
   No. 142102210425, Project of the Cultivation Fund of Science and
   Technology Achievements of Henan University of Science and Technology
   Grant No. 2015BZCG01. We give thanks to Xiaoxue Wang, Fangyun Liu, Cheng
   Li and Peining Shi for their technical assistance on CyVOD MSN
   prototype, and also would like to thank the reviewers and editor for
   their valuable comments, questions, and suggestions.
CR Alsmirat M. A., 2016, MULTIMED TOOLS APPL, P1
   Alsmirat MA, 2016, J REAL TIME IMAGE PR
   Atawneh Samer, 2016, MULTIMED TOOLS APPL
   Chen SH, 2015, INFORM SCIENCES, V318, P123, DOI 10.1016/j.ins.2014.09.058
   Fatemeh R, 2015, IET INFORM SECUR, V9, P73
   Feng WN, 2016, MULTIMED TOOLS APPL, V75, P13995, DOI 10.1007/s11042-015-2929-2
   Fogues R, 2015, INT J HUM-COMPUT INT, V31, P350, DOI 10.1080/10447318.2014.1001300
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hu HX, 2013, IEEE T KNOWL DATA EN, V25, P1614, DOI 10.1109/TKDE.2012.97
   Huang J, 2013, ACM T KNOWL DISCOV D, V7, DOI 10.1145/2541268.2541270
   Jung YN, 2014, COMPUT SECUR, V41, P19, DOI 10.1016/j.cose.2013.08.004
   Nepal S, 2015, COMPUT INTELL-US, V31, P642, DOI 10.1111/coin.12041
   Pasquale DM, 2015, IEEE T CYBERNETICS, V45, P205
   Santa A, 2015, IEEE INTERNET COMPUT, V19, P26
   Sohn JS, 2013, WIRELESS PERS COMMUN, V73, P1529, DOI 10.1007/s11277-013-1264-z
   Tang JL, 2015, IEEE T KNOWL DATA EN, V27, P1724, DOI 10.1109/TKDE.2014.2382576
   Viejo A, 2015, EXPERT SYST APPL, V42, P9366, DOI 10.1016/j.eswa.2015.08.014
   Xu YH, 2012, DECIS SUPPORT SYST, V54, P564, DOI 10.1016/j.dss.2012.08.003
   Yu SJ, 2012, INFORM SCIENCES, V187, P1, DOI 10.1016/j.ins.2011.10.020
   Zhang Z., 2011, INT J DIGIT CONTENT, V5, P255, DOI DOI 10.4156/JDCTA.VOL5.ISSUE3.26
   Zhang ZY, 2018, FUTURE GENER COMP SY, V86, P914, DOI 10.1016/j.future.2016.10.007
   Zhang ZY, 2015, MULTIMED TOOLS APPL, V74, P6255, DOI [10.1007/s11042-014-2135-7, 10.1007/s11042-015-2619-0]
   Zhang ZY, 2015, COMPUT J, V58, P668, DOI 10.1093/comjnl/bxu035
   Zhang ZY, 2013, SOC NETW ANAL MIN, V3, P969, DOI 10.1007/s13278-012-0078-4
NR 24
TC 50
Z9 54
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18513
EP 18529
DI 10.1007/s11042-016-4162-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800017
DA 2024-07-18
ER

PT J
AU Fotouhi, M
   Fouladi, S
   Kasaei, S
AF Fotouhi, Mehran
   Fouladi, Sadjad
   Kasaei, Shohreh
TI Projection matrix by orthogonal vanishing points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Projection matrix; Perspective transformation; Camera calibration;
   Vanishing points
ID CAMERA CALIBRATION
AB Calculation of camera projection matrix, also called camera calibration, is an essential task in many computer vision and 3D data processing applications. Calculation of projection matrix using vanishing points and vanishing lines is well suited in the literature; where the intersection of parallel lines (in 3D Euclidean space) when projected on the camera image plane (by a perspective transformation) is called vanishing point and the intersection of two vanishing points (in the image plane) is called vanishing line. The aim of this paper is to propose a new formulation for easily computing the projection matrix based on three orthogonal vanishing points. It can also be used to calculate the intrinsic and extrinsic camera parameters. The proposed method reaches to a closed-form solution by considering only two feasible constraints of zero-skewness in the internal camera matrix and having two corresponding points between the world and the image. A nonlinear optimization procedure is proposed to enhance the computed camera parameters, especially when the measurement error of input parameters or the skew factor are not negligible. The proposed method has been run on real and synthetic data for more precise evaluations. The provided experimental results demonstrate the superiority of the proposed method.
C1 [Fotouhi, Mehran; Fouladi, Sadjad; Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM fotouhi@ce.sharif.edu; fouladi@ce.sharif.edu; skasaei@sharif.edu
RI Kasaei, Shohreh/AAD-5618-2019
OI Kasaei, Shohreh/0000-0002-3831-0878
FU Iran National Science Foundation (INSF)
FX The authors would like to thank Mr. Yasin Zamani for providing the
   synthetic 3D-rendered dataset of soccer images. Special thanks to Mr.
   Mostafa Hadian, Mr. Afshin Bozorgpour, and Mrs. Sara Monji-azad for
   their valuable comments and suggestions to improve this work. We also
   would like to thank Prof. Mahmoud Reza Pishvaie for his guidance in
   solving some of the equations. This work has been partly supported by a
   grant from Iran National Science Foundation (INSF).
CR [Anonymous], P BRIT MACH VIS C
   Antunes M, 2013, PROC CVPR IEEE, P1336, DOI 10.1109/CVPR.2013.176
   Babaee-Kashany V., 2010, Proceedings 2010 UKSim 4th European Modelling Symposium on Computer Modelling and Simulation (EMS 2010), P152, DOI 10.1109/EMS.2010.36
   Babaee-Kashany V, 2010, IEEE INT S HAPT AUD, P1
   BEARDSLEY P, 1992, LECT NOTES COMPUT SC, V588, P312
   Beardsley P., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P416
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   Daniilidis K, 1996, PROC CVPR IEEE, P708, DOI 10.1109/CVPR.1996.517150
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Farin D, 2004, ELECT IMAGING, V2003, P80
   Grammatikopoulos L., 2004, INT ARCH PHOTOGRAMM, V35, P99
   Grammatikopoulos L, 2006, INT ARCH PHOTOGRAMM, V5
   Grammatikopoulos L, 2007, ISPRS J PHOTOGRAMM, V62, P64, DOI 10.1016/j.isprsjprs.2007.02.002
   Guillemaut JY, 2005, IEEE T PATTERN ANAL, V27, P265, DOI 10.1109/TPAMI.2005.41
   Guillou E, 2000, VISUAL COMPUT, V16, P396, DOI 10.1007/PL00013394
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   He BW, 2007, I C MECH MACH VIS PR, P44, DOI 10.1109/MMVIP.2007.4430712
   He BW, 2008, OPT LASER TECHNOL, V40, P555, DOI 10.1016/j.optlastec.2007.09.001
   Ito M., 1991, Advanced Robotics, V5, P321, DOI 10.1163/156855391X00232
   KANATANI K, 1992, IEEE T ROBOTIC AUTOM, V8, P767, DOI 10.1109/70.182677
   Kong H, 2013, IEEE T INTELL TRANSP, V14, P408, DOI 10.1109/TITS.2012.2216878
   LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781
   Li B, 2010, LECT NOTES COMPUT SC, V6454, P151, DOI 10.1007/978-3-642-17274-8_15
   Liang DW, 2007, IEEE T CONSUM ELECTR, V53, P1138, DOI 10.1109/TCE.2007.4341597
   Ling-Ling Wang, 1990, Machine Vision and Applications, V3, P129, DOI 10.1007/BF01214426
   Moghadam P, 2012, IEEE T IMAGE PROCESS, V21, P425, DOI 10.1109/TIP.2011.2162422
   Orghidan R, 2012, CAMERA CALIBRATION U
   Pan SJ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P417, DOI 10.1109/CISP.2008.36
   Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1
   Salvi J, 1998, THESIS
   SEETHARAMAN G, 1994, J FRANKLIN I, V331B, P555, DOI 10.1016/0016-0032(94)90037-X
   Shou-Ping Dong, 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5058, P104, DOI 10.1117/12.509513
   STEVENSON DE, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P34
   Sun H, 2016, IMAGING SCI J, V64, P232, DOI 10.1080/13682199.2016.1168143
   Sun J, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P2371, DOI 10.1109/WCICA.2008.4593293
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   WANG LL, 1991, IEEE T PATTERN ANAL, V13, P370, DOI 10.1109/34.88572
   WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901
   Wu YH, 2006, IMAGE VISION COMPUT, V24, P1313, DOI 10.1016/j.imavis.2006.04.010
   Xu XQ, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P931
   Xu YL, 2013, PROC CVPR IEEE, P1376, DOI 10.1109/CVPR.2013.181
   You XH, 2016, NEUROCOMPUTING, V204, P222, DOI 10.1016/j.neucom.2015.09.132
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhu HJ, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, VOL 1, PROCEEDINGS, P321, DOI 10.1109/ITCS.2009.72
NR 45
TC 3
Z9 3
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16189
EP 16223
DI 10.1007/s11042-016-3904-2
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100007
DA 2024-07-18
ER

PT J
AU Zheng, H
   Liu, JF
   Gao, JL
   Lu, QM
AF Zheng, Hao
   Liu, Jian-fang
   Gao, Jing-Li
   Lu, Qingmei
TI Feature detection method for small targets of complex multimedia images
   in cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia image; Small target; Feature detection; Cloud environment
AB During feature detection process of small targets of complex multimedia images in cloud environment, traditional analysis tools are unable to demonstrate the details of the multimedia image due to poor time-frequency localization function, a feature detection method for small target of complex multimedia images in cloud environment based on spatial transformation kernel Fisher is proposed, this method analyzes the principle of wavelet transform applied for signal filtering, also, a filtering method applied for the multimedia image containing small targets is introduced for filtering of complex multimedia image. On the basis of Fisher discriminant analysis method, the feature sample data of small targets is projected into the high-dimensional feature space, and the optimal projection vector set is found in feature space to complete the detection of small targets' feature of the multimedia image. Experimental results show that the proposed method has high detection performance.
C1 [Zheng, Hao; Liu, Jian-fang] Pingdingshan Univ, Software Inst, Pingdingshan 467000, Henan, Peoples R China.
   [Gao, Jing-Li] Zhejiang Univ, Coll Elect Engn, Hangzhou 310058, Zhejiang, Peoples R China.
   [Lu, Qingmei] Wuhan Univ, Int Sch Software, Wuhan 430072, Peoples R China.
C3 Pingdingshan University; Zhejiang University; Wuhan University
RP Zheng, H (corresponding author), Pingdingshan Univ, Software Inst, Pingdingshan 467000, Henan, Peoples R China.
EM zhenghao5486@163.com
FU national natural science fund project [61503206]
FX This work is supported by the The national natural science fund project
   (61503206).
CR Alaybeyoglu A, 2015, J INTELL FUZZY SYST, V28, P1235, DOI 10.3233/IFS-141408
   Bregler C, 2015, P IEEE COMP SOC C CO, V2, P690
   Byong JH, 2013, EURASIP J WIREL COMM, P63
   Chopra P, 2015, COMPLEX INTELL SYST, V1, P25, DOI 10.1007/s40747-015-0004-2
   Demir AK, 2014, WIREL NETW, V20, P655, DOI 10.1007/s11276-013-0628-3
   Gao X, 2015, 33323344 TIP, V6, P23
   Hell B, 2015, IEEE T IMAGE PROCESS, V24, P2633, DOI 10.1109/TIP.2015.2419078
   Ho ATS, 2015, MULTIMEDIA ANAL IMAG
   Hossain M. A., 2014, MAT RENEWABLE SUSTAI, V3, P1
   Luo Y, 2015, IEEE T IMAGE PROCESS, V24, P2355, DOI 10.1109/TIP.2015.2421309
   Reddy PVB, 2014, AEU-INT J ELECTRON C, V68, P637, DOI 10.1016/j.aeue.2014.01.012
   Santos Marc Ericson C, 2016, Res Pract Technol Enhanc Learn, V11, P4, DOI 10.1186/s41039-016-0028-2
   Skodras E, 2013, J IMAG VIDEO PROCESS, V26
   Song CY, 2013, IEICE T COMMUN, VE96B, P859, DOI 10.1587/transcom.E96.B.859
   Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443
   Tie Y, 2012, IEEE INT SYMP CIRC S, P1115
   Tie Y, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-8
   Treviño V, 2015, J MASS SPECTROM, V50, P165, DOI 10.1002/jms.3512
   Vipparthi SK, 2014, EXPERT SYST APPL, V41, P8016, DOI 10.1016/j.eswa.2014.07.001
   Wang WJ, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P387, DOI 10.1109/IIH-MSP.2013.103
   Xu Y, 2015, IEEE T IMAGE PROCESS, V24, P1315, DOI 10.1109/TIP.2015.2397314
   Zhang SC, 2015, IEEE T IMAGE PROCESS, V24, P2466, DOI 10.1109/TIP.2015.2422578
   Zheng XH, 2014, J INTERNET TECHNOL, V15, P1043, DOI 10.6138/JIT.2014.15.6.15
   Zhou JM, 2015, EURASIP J WIREL COMM, DOI 10.1186/s13638-015-0471-6
NR 24
TC 1
Z9 2
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17095
EP 17112
DI 10.1007/s11042-016-3669-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500012
DA 2024-07-18
ER

PT J
AU Wang, WH
   Sun, SL
   Jiang, MX
   Yan, YY
   Chen, XB
AF Wang, Wenhao
   Sun, Shanlin
   Jiang, Mingxin
   Yan, Yunyang
   Chen, Xiaobing
TI Traffic lights detection and recognition based on multi-feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic lights; Color segmentation; Noise removal; Support vector
   machine
AB Many traffic accidents occurred at intersections are caused by drivers who miss or ignore the traffic signals. In this paper, we present a method dealing with automatic detection of traffic lights that integrates both image processing and support vector machine techniques. Firstly, based on the color characteristics of traffic lights, the paper proposes a method of traffic light segmentation in RGB and HSV color space. And then, according to the geometric features and backplane color information of traffic lights, we design an algorithm to remove false targets in images. Moreover, in order to solve traffic lights diffusion problem, we apply a strategy that we first map the candidate regions onto the original image, then using Otsu algorithm re-extract the target region. Finally, HOG features are extracted from the target regions, and recognized by the trained SVM classifier. Experimental results show that the proposed method has relatively high detection rate and recognition accuracy in different natural scenarios, and is able to meet real-time requirements.
C1 [Wang, Wenhao; Jiang, Mingxin; Yan, Yunyang; Chen, Xiaobing] HuaiYin Inst Technol, Fac Comp & Software Engn, 1 East Meicheng Rd, Huaian 223003, Jiangsu, Peoples R China.
   [Sun, Shanlin] Beihang Univ, Beijing 100191, Peoples R China.
C3 Huaiyin Institute of Technology; Beihang University
RP Wang, WH (corresponding author), HuaiYin Inst Technol, Fac Comp & Software Engn, 1 East Meicheng Rd, Huaian 223003, Jiangsu, Peoples R China.
EM wenhaowang2013@sina.com
FU National Natural Science Foundation of China [61403060]; Natural Science
   Foundation of the Jiangsu Higher Education Institutions [15KJA460003]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61403060, and the Natural Science
   Foundation of the Jiangsu Higher Education Institutions under Grant
   15KJA460003. The authors would like to thank the anonymous reviewers and
   the editors for their many helpful suggestions.
CR [Anonymous], 2010, BRIT MACHINE VISION
   Barbu T, 2014, COMPUT ELECTR ENG, V40, P1072, DOI 10.1016/j.compeleceng.2013.12.004
   Chen XJ, 2008, APPL SOFT COMPUT, V8, P1222, DOI 10.1016/j.asoc.2007.02.019
   Chen Z, 2015, IEEE INT VEH SYM, P37, DOI 10.1109/IVS.2015.7225659
   Chiang CC, 2011, INT J INNOV COMPUT I, V7, P6919
   Chunhe YU, 2012, ADV TECHNOLOGY TEACH, P745
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Charette R, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P333, DOI 10.1109/IROS.2009.5353941
   de Charette R, 2009, IEEE INT VEH SYM, P358, DOI 10.1109/IVS.2009.5164304
   Diaz-Cabrera M, 2015, EXPERT SYST APPL, V42, P3911, DOI 10.1016/j.eswa.2014.12.037
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Jang C, 2014, IEEE INT VEH SYM, P1313, DOI 10.1109/IVS.2014.6856541
   Omachi M, 2010, INT CONF SIGN PROCES, P809, DOI 10.1109/ICOSP.2010.5655932
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Sooksatra S., 2014, Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), 2014 11th International Conference on, P1, DOI [DOI 10.1109/ECTICON.2014.6839767, 10.1109/ecticon.2014.6839767]
   Ying J, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P644
NR 16
TC 4
Z9 4
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14829
EP 14846
DI 10.1007/s11042-016-4051-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400016
DA 2024-07-18
ER

PT J
AU Xu, JJ
   Zhang, WM
   Jiang, RQ
   Hu, XC
   Yu, NH
AF Xu, Jiajia
   Zhang, Weiming
   Jiang, Ruiqi
   Hu, Xiaocheng
   Yu, Nenghai
TI Optimal structural similarity constraint for reversible data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Structural similarity; Recursive code
   construction; Convex optimization
ID SCHEME; EXPANSION; IMAGE
AB Until now, most reversible data hiding techniques have been evaluated by peak signal-to-noise ratio(PSNR), which based on mean squared error(MSE). Unfortunately, MSE turns out to be an extremely poor measure when the purpose is to predict perceived signal fidelity or quality. The structural similarity (SSIM) index has gained widespread popularity as an alternative motivating principle for the design of image quality measures. How to utilize the characterize of SSIM to design RDH algorithm is very critical. In this paper, we propose an optimal RDH algorithm under structural similarity constraint. Firstly, we deduce the metric of the structural similarity constraint, and further we prove it does't hold non-crossing-edges property. Secondly, we construct the rate-distortion function of optimal structural similarity constraint, which is equivalent to minimize the average distortion for a given embedding rate, and then we can obtain the optimal transition probability matrix under the structural similarity constraint. Comparing with previous RDH, our method have gained the improvement of SSIM about 1.89 % on average. Experiments show that our proposed method outperforms the state-of-arts performance in SSIM.
C1 [Xu, Jiajia; Zhang, Weiming; Jiang, Ruiqi; Hu, Xiaocheng; Yu, Nenghai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230026, Peoples R China.
EM xujiajia@mail.ustc.edu.cn; zhangwm@ustc.edu.cn;
   rqjiang@mail.ustc.edu.cn; hxc@mail.ustc.edu.cn; ynh@mail.ustc.edu.cn
RI Xu, Jiawen/JEF-5028-2023; xu, jiawen/KGK-4238-2024; xu,
   jia/GSD-6347-2022
FU Natural Science Foundation of China [61170234, 60803155]; Strategic
   Priority Research Program of the Chinese Academy of Sciences
   [XDA06030601]
FX This work was supported in part by the Natural Science Foundation of
   China under Grants 61170234 and 60803155, and by the Strategic Priority
   Research Program of the Chinese Academy of Sciences under Grant
   XDA06030601.
CR [Anonymous], THESIS
   Brunet D, 2012, IEEE T IMAGE PROCESS, V21, P1488, DOI 10.1109/TIP.2011.2173206
   Cohen S., 1999, THESIS
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Hu XC, 2013, IEEE T INF FOREN SEC, V8, P779, DOI 10.1109/TIFS.2013.2256131
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Kalker T, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P71, DOI 10.1109/ICDSP.2002.1027818
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin SJ, 2012, IEEE T INF FOREN SEC, V7, P1155, DOI 10.1109/TIFS.2012.2197614
   Ling H, 2007, IEEE T PATTERN ANAL, V29, P840, DOI 10.1109/TPAMI.2007.1058
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang SQ, 2013, IEEE T IMAGE PROCESS, V22, P1418, DOI 10.1109/TIP.2012.2231090
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2009, IEEE SIGNAL PROCESS, V26
   Weiming Zhang, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P255, DOI 10.1007/978-3-642-24178-9_18
   Xiannian F, 2014, TIGHTENING BOUNDS BA
   Xiannian F, 2014, P 30 ANN C UNC ART I
   Zhang W, 2011, P 13 INF HID C PRAG
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
   Zhang XP, 2013, IEEE T MULTIMEDIA, V15, P316, DOI 10.1109/TMM.2012.2229262
   Zhao Q, 2010, IEEE T PATTERN ANAL, V32, P274, DOI 10.1109/TPAMI.2008.299
NR 30
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15491
EP 15511
DI 10.1007/s11042-016-3850-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900013
DA 2024-07-18
ER

PT J
AU Yang, HJ
   Chang, J
   Geng, N
   Notman, G
   Li, SQ
   Jiang, M
   Wang, ML
   Zhang, JJ
AF Yang, HuiJun
   Chang, Jian
   Geng, Nan
   Notman, Gabriel
   Li, Shuqin
   Jiang, Min
   Wang, MeiLi
   Zhang, JianJun
TI Texture organisation and mapping on <i>Citrus sinensis</i> point cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Citrus sinensis; Texel descriptor; Linearisation code; Texture mapping
AB In light of the current problems including coarseness, visible cracks, difficult data organisation, and the expensive memory requirements of the current texture methods, this paper mainly focuses on efficient organisation, linearised memory compression and seamless texture mapping between scanned Citrus sinensis images and point cloud information. Position and colour gradient based top-down splitting is proposed to simplify and organise the texture as texel descriptors to avoid both over-simplification and under-simplification. A Quadtree Morton and Z-order based linearised coding strategy is presented to compress the memory space of our texel descriptor based texture. A Gaussian Markov random field scheme was designed to smooth the 'cracks' between neighbouring texels. The simulated results on eight Citrus sinensises show that our simplification method reduces the texture memory requirements by 81.3 % over the original image, and 50 % over conventional simplification. The compression scheme also showed a 61.7 % improvement over the ordinary Morton code. Finally, the Gaussian Markov random field scheme makes the texture mapping smoother in comparison with other methods.
C1 [Yang, HuiJun; Geng, Nan; Li, Shuqin; Wang, MeiLi] Northwest A&F Univ, Coll Informat Engn, Yangling, Shaanxi, Peoples R China.
   [Yang, HuiJun; Chang, Jian; Notman, Gabriel; Jiang, Min; Zhang, JianJun] Bournemouth Univ, Natl Ctr Comp Animat, Poole BH12 5BB, Dorset, England.
C3 Northwest A&F University - China; Bournemouth University
RP Li, SQ (corresponding author), Northwest A&F Univ, Coll Informat Engn, Yangling, Shaanxi, Peoples R China.
EM lsq_cie@nwsuaf.edu.cn
RI JIANG, Min/J-8602-2019
OI JIANG, Min/0000-0003-2946-6974; yang, Huijun/0000-0002-4226-2493; Zhang,
   Jian/0000-0002-7069-5771; Chang, Jian/0000-0003-4118-147X
FU Fundamental Research Funds for the Central Universities [2014YB067,
   2452015199, 2452015195]; National High Technology Research and
   Development Program of China (863 Program) [2013AA10230402]; National
   High Technology Research and Development Program of China
   [2013BAD15B02]; Scholarship Council and Scientific Research Foundation
   for Ph. D from Northwest Agriculture & Forest University of China
   [2014BSJJ060]
FX The authors would like to thank the Fundamental Research Funds for the
   Central Universities (No. 2014YB067, 2452015199, 2452015195), the
   National High Technology Research and Development Program of China (863
   Program. 2013AA10230402), the National High Technology Research and
   Development Program of China (2013BAD15B02), the Scholarship Council and
   Scientific Research Foundation for Ph. D from Northwest Agriculture &
   Forest University of China (2014BSJJ060), for financial support
   provided.
CR Adams B, 2004, EUR S POINT BAS GRAP
   Catmull EE, 1974, UTECCSC74133
   Chan RH, 2013, NUMER MATH-THEORY ME, V6, P276, DOI 10.4208/nmtma.2013.mssvm15
   Clarenz U., 2004, EUROGRAPHICS S POINT
   Digne J, 2014, J MATH IMAGING VIS, V48, P369, DOI 10.1007/s10851-013-0414-y
   Gross M., 2011, Point-based graphics
   Kennel P, 2015, PATTERN ANAL APPL, P1
   Koyuncu B, 2010, P 9 WSEAS INT C
   Kraak Menno-Jan., 2011, Cartography: Visualization of Spatial Data, V3rd
   Lensch HP, 2001, IMAGE BASED RECONSTR
   Liu WL, 2011, APPL MECH MATER, V94-96, P86, DOI 10.4028/www.scientific.net/AMM.94-96.86
   LU X-C, 2007, J SYST SIMUL, V7
   Magda S, 2003, ACM SIGGRAPH 2003 SK
   Pan RJ, 2015, GRAPH MODELS, V79, P39, DOI 10.1016/j.gmod.2015.04.002
   Quan YS, 2005, APPL RES COMPUT, V8
   Rabin J, 2012, LECT NOTES COMPUT SC, V6667, P435, DOI 10.1007/978-3-642-24785-9_37
   Raper J, 2009, ANNU REV INFORM SCI, V43, P73
   Soler C, 2002, ACM T GRAPHIC, V21, P673, DOI 10.1145/566570.566635
   Stahlhut O, 2005, GRAPH MODELS, V67, P496, DOI 10.1016/j.gmod.2005.01.006
   ter Haar FB, 2009, GRAPH MODELS, V71, P77, DOI 10.1016/j.gmod.2008.12.003
   Turk G, 2001, P 28 ANN C COMP GRAP
   Wei J, 2013, PROG EXPLOR GEOPHYS, V49, P240
   Xiao Chun-Xia, 2006, Chinese Journal of Computers, V29, P2061
   Xu W, 2015, 9 INT S MULT IM PROC
   Zhang J, 2003, ACM T GRAPHICS TOG
   Zhang Z, 2011, COMPUTER TECHNOLOGY, P10
   [赵煦 ZHAO Xu], 2008, [武汉大学学报. 信息科学版, Geomatics and Information Science of Wuhan University], V33, P684
   Zwicker M, 2003, THESIS
NR 28
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14711
EP 14732
DI 10.1007/s11042-016-3998-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400010
DA 2024-07-18
ER

PT J
AU Yu, J
   Wang, ZF
AF Yu, Jun
   Wang, Zengfu
TI A Video-Based Facial Motion Tracking and Expression Recognition System
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facialmotion tracking; Facial expression recognition; Particle
   filtering; Markov process
ID APPEARANCE MODELS; FACE TRACKING; HEAD; ONLINE
AB We proposed a facial motion tracking and expression recognition system based on video data. By a 3D deformable facial model, the online statistical model (OSM) and cylinder head model (CHM) were combined to track 3D facial motion in the framework of particle filtering. For facial expression recognition, a fast and efficient algorithm and a robust and precise algorithm were developed. With the first, facial animation and facial expression were retrieved sequentially. After that facial animation was obtained, facial expression was recognized by static facial expression knowledge learned from anatomical analysis. With the second, facial animation and facial expression were simultaneously retrieved to increase the reliability and robustness with noisy input data. Facial expression was recognized by fusing static and dynamic facial expression knowledge, the latter of which was learned by training a multi-class expressional Markov process using a video database. The experiments showed that facial motion tracking by OSM+CHM is more pose robust than that by OSM, and the facial expression score of the robust and precise algorithm is higher than those of other state-of-the-art facial expression recognition methods.
C1 [Yu, Jun; Wang, Zengfu] Univ Sci & Technol China, Natl Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China.
   [Yu, Jun; Wang, Zengfu] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Nanjing University
RP Yu, J (corresponding author), Univ Sci & Technol China, Natl Lab Speech & Language Informat Proc, Hefei 230027, Peoples R China.; Yu, J (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM harryjun@ustc.edu.cn; zfwang@ustc.edu.cn
FU National Natural Science Foundation of China [61572450, 61303150]; Open
   Project Program of the State KeyLab of CAD&CG, Zhejiang University
   [A1501]; Fundamental Research Funds for the Central Universities
   [WK2350000002]; Open Funding Project of State Key Laboratory of Virtual
   Reality Technology and Systems, Beihang University [BUAA-VR-16KF-12]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61572450 and No. 61303150), the Open Project Program of the
   State KeyLab of CAD&CG, Zhejiang University (No. A1501), the Fundamental
   Research Funds for the Central Universities (WK2350000002), the Open
   Funding Project of State Key Laboratory of Virtual Reality Technology
   and Systems, Beihang University (No. BUAA-VR-16KF-12).
CR Ahlberg J., 2002, MODEL BASED CODING E
   Anderson K, 2006, IEEE T SYST MAN CY B, V36, P96, DOI 10.1109/TSMCB.2005.854502
   [Anonymous], 2004, Technical Report
   [Anonymous], 2011, International Journal of Wavelets Multiresolution and Information Processing, DOI DOI 10.1142/S021969130400041X
   [Anonymous], ACM TOG
   Bartlett M., 2004, ICSMC, P145
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Blake Andrew., 2000, Active Contours
   Blanz V, 2003, IEEE T PATTERN ANAL, V15, P253
   Chang Y, 2004, PROC CVPR IEEE, P520
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cohn JF, 2004, IEEE SYS MAN CYBERN, P610
   Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7
   Dornaika F, 2006, IEEE T CIRC SYST VID, V16, P1107, DOI 10.1109/TCSVT.2006.881200
   Ekman P., 2002, FACIAL ACTION CODING
   Fang T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P603, DOI 10.1109/FG.2011.5771466
   Fidaleo D, 2005, LECT NOTES COMPUT SC, V3723, P125
   Gokturk SB, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P701, DOI 10.1109/ICCV.2001.937695
   Grassberger P, 1997, PHYS REV E, V56, P3682, DOI 10.1103/PhysRevE.56.3682
   Guo GD, 2005, IEEE T SYST MAN CY B, V35, P477, DOI 10.1109/TSMCB.2005.846658
   Hammal Z, 2007, INT J APPROX REASON, V46, P542, DOI 10.1016/j.ijar.2007.02.003
   Hayat M, 2014, PROC CVPR IEEE, P1915, DOI 10.1109/CVPR.2014.246
   Hu YK, 2006, INT C PATT RECOG, P1147
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Lee C, 2005, IWAMFG, P958
   Liao WK, 2008, PROC CVPR IEEE, P3597
   Liao WK, 2007, LECT NOTES COMPUT SC, V4778, P109
   Littlewort GC, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P15
   Liu SC, 2012, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2012.6247662
   Lucey P., 2010, WORKSH CVPR, P217
   Lucey Simon., 2007, FACE RECOGNITION DEL, P275
   Lui YM, 2010, IEEE T SYST MAN CY A, V40, P437, DOI 10.1109/TSMCA.2010.2041655
   Marks TK, 2010, IEEE T PATTERN ANAL, V32, P348, DOI 10.1109/TPAMI.2008.278
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M., 2007, FACE RECOGNITION, P377
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Schmidt K., 2001, IEEE INT C MULTIMEDI, P728
   Sebe N, 2004, ICAFGR, P701
   Strom J., 2002, MODEL BASED HEAD TRA
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Tang FQ, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P632
   Tao H., 1999, IEEE C COMPUTER VISI, V1, P611
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   Valstar M.F., 2006, International Conference on Multimodal Interfaces, P162, DOI DOI 10.1145/1180995.1181031
   Valstar MF, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P38
   Wang HC, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P958, DOI 10.1109/ICCV.2003.1238452
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wang Q, 2006, IEEE T CIRC SYST VID, V16, P1533, DOI 10.1109/TCSVT.2006.885727
   Wang Y, 2004, ICPR, P307
   Wen Z, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1343, DOI 10.1109/ICCV.2003.1238646
   Whitehill J., 2006, PROC INT C AUTOMATIC, P217
   Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048
   Yin L, 2008, ICAFGR, P958
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yu J, 2014, SCI CHINA INFORM SCI, V57, DOI 10.1007/s11432-013-5023-2
   Yuankui Hu, 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P217
   Zeng Z., 2006, J MULTIMED, V1, P1, DOI DOI 10.4304/jmm.1.5.1-8
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang W, 2008, LECT NOTES COMPUT SC, V5303, P720, DOI 10.1007/978-3-540-88688-4_53
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 69
TC 5
Z9 5
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14653
EP 14672
DI 10.1007/s11042-016-3883-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400007
DA 2024-07-18
ER

PT J
AU Yu, J
   Jiang, C
   Wang, ZF
AF Yu, Jun
   Jiang, Chen
   Wang, Zengfu
TI Creating and simulating a realistic physiological tongue model for
   speech production
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual speech synthesis; Physics-based modeling; Tongue animation
ID SKELETAL-MUSCLE; CONTRACTION; MOVEMENTS
AB Simulation of the tongue has important applications in biomechanics, medical science, linguistics, and graphics. The accuracy of the geometry, intrinsic structure and dynamic simulation of tongue are crucial for these applications. In this paper, we build a 3D anatomically and biomechanically accurate tongue model. For ensuring anatomical accuracy, the tongue mesh model is constructed based on accurate medical data and an interactive muscle marking method for specifying the muscle geometry and fiber arrangement. For ensuring biomechanical accuracy, a nonlinear, quasi-incompressible, isotropic, hyperelastic constitutive model is applied for describing the tongue tissues. Particularly, tongue muscles are additionally endowed with an anisotropic constitutive model, which reflects the active and passive mechanical behavior of muscle fibers. The dynamic simulation results of tongue movements subjected to certain muscle activations are presented and validated with experimental data, indicating the suitability for visual speech synthesis.
C1 [Yu, Jun; Jiang, Chen; Wang, Zengfu] Univ Sci & Technol China, Hefei, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Yu, J (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.
EM harryjun@ustc.edu.cn; zfwang@ustc.edu.cn
RI jiang, chen/HZL-9276-2023
FU National Natural Science Foundation of China [61572450, 61303150]; Open
   Project Program of the State KeyLab of CAD&CG, Zhejiang University
   [A1501]; Fundamental Research Funds for the Central Universities
   [WK2350000002]; Open Funding Project of State Key Laboratory of Virtual
   Reality Technology and Systems, Beihang University [BUAA-VR-16KF-12]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61572450 and No. 61303150), the Open Project Program of the
   State KeyLab of CAD&CG, Zhejiang University (No. A1501), the Fundamental
   Research Funds for the Central Universities (WK2350000002), the Open
   Funding Project of State Key Laboratory of Virtual Reality Technology
   and Systems, Beihang University (No. BUAA-VR-16KF-12).
CR Abd-El-Malek S, 1939, J ANAT, V73, P201
   Ackerman MJ, 1998, P IEEE, V86, P504, DOI 10.1109/5.662875
   Agur AMR, 2012, GRANT GRANTS ATLAS A
   [Anonymous], 2007, INFORM RETRIEVAL MUS
   [Anonymous], ACOUSTICAL SCI TECHN
   [Anonymous], J AM STAT ASS
   Badin P, 2002, J PHONETICS, V30, P533, DOI 10.1006/jpho.2002.0166
   Baer T., 1988, ANN B RILP, V7, P7
   Bourdin X, 2007, TECH REP
   Cohen M. M., 1993, Models and Techniques in Computer Animation, P139
   Dang JW, 2004, J ACOUST SOC AM, V115, P853, DOI 10.1121/1.1639325
   Engwall O, 2003, SPEECH COMMUN, V41, P303, DOI 10.1016/S0167-6393(02)00132-2
   FELDMAN AG, 1986, J MOTOR BEHAV, V18, P17
   Fujita S, 2007, ORAL SCI INT, V4, P97, DOI 10.1016/S1348-8643(07)80004-8
   Fung YC, 1993, BIOMECHANICS MECH PR
   Gerard J.M., 2006, SPEECH PRODUCTION MO, P85
   Hiiemae KM, 2003, CRIT REV ORAL BIOL M, V14, P413, DOI 10.1177/154411130301400604
   Hill AV, 1938, PROC R SOC SER B-BIO, V126, P136, DOI 10.1098/rspb.1938.0050
   HUXLEY AF, 1974, J PHYSIOL-LONDON, V243, P1
   Kajee Y, 2013, INT J NUMER METH BIO, V29, P492, DOI 10.1002/cnm.2531
   King SA, 2001, J VISUAL COMP ANIMAT, V12, P107, DOI 10.1002/vis.249
   Lieber R., 2002, SKELETAL MUSCLE STRU
   Lieber RL, 2000, MUSCLE NERVE, V23, P1647, DOI 10.1002/1097-4598(200011)23:11<1647::AID-MUS1>3.0.CO;2-M
   MACNEILAGE PF, 1964, J SPEECH HEAR RES, V7, P209, DOI 10.1044/jshr.0703.209
   Maurel W., 1998, BIOMECHANICAL MODELS
   Miyawaki K., 1974, Annual Bulletin Research Institute of Logopedics and Phoniatrics, V8, P23
   Pelachaud Catherine, 1994, P IEEE, V94, P40
   Perkell SJ, 1974, PHYSL ORIENTED MODEL
   Perrier P., 2011, FAITS DE LANGUES, V37, P155, DOI 10.1163/19589514-037-01-900000009
   Sanguineti V, 1997, BIOL CYBERN, V77, P11, DOI 10.1007/s004220050362
   Shewchuk J. R., 1998, Proceedings of the Fourteenth Annual Symposium on Computational Geometry, P86, DOI 10.1145/276884.276894
   Sifakis E, 2005, ACM T GRAPHIC, V24, P417, DOI 10.1145/1073204.1073208
   Sifakis E., 2006, ACM SIGGRAPHEUROGRAP, P261
   SIMO JC, 1991, COMPUT METHOD APPL M, V85, P273, DOI 10.1016/0045-7825(91)90100-K
   Takemoto H, 2001, J SPEECH LANG HEAR R, V44, P95, DOI 10.1044/1092-4388(2001/009)
   Tang CY, 2009, J BIOMECH, V42, P865, DOI 10.1016/j.jbiomech.2009.01.021
   Teran J, 2005, IEEE T VIS COMPUT GR, V11, P317, DOI 10.1109/TVCG.2005.42
   Vogt F., 2006, P ISSP 06, P51
   Weiss JA, 1996, COMPUT METHOD APPL M, V135, P107, DOI 10.1016/0045-7825(96)01035-3
   Wilhelms-Tricarico R., 2006, PHYSICS0606148 ARXIV
   WILHELMSTRICARICO R, 1995, J ACOUST SOC AM, V97, P3085, DOI 10.1121/1.411871
   Yu J., 2013, OR COCOSDA HELD JOIN, P1
   ZAJAC FE, 1989, CRIT REV BIOMED ENG, V17, P359
NR 43
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14673
EP 14689
DI 10.1007/s11042-016-3929-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400008
DA 2024-07-18
ER

PT J
AU Ahmed, SA
   Dogra, DP
   Kar, S
   Kim, BG
   Hill, P
   Bhaskar, H
AF Ahmed, Sk. Arif
   Dogra, Debi Prosad
   Kar, Samarjit
   Kim, Byung-Gyu
   Hill, Paul
   Bhaskar, Harish
TI Localization of region of interest in surveillance scene
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trajectory analysis; Scene segmentation; Scene understanding; Object
   tracking; Movement analysis
ID OBJECT DETECTION; CONTEXT
AB In this paper, we present a method for autonomously detecting and extracting region(s)-of-interest (ROI) from surveillance videos using trajectory-based analysis. Our approach, localizes ROI in a stochastic manner using correlated probability density functions that model motion dynamics of multiple moving targets. The motion dynamics model is built by analyzing trajectories of multiple moving targets and associating importance to regions in the scene. The importance of each region is estimated as a function of the total time spent by multiple targets, their instantaneous velocity and direction of movement whilst passing through that region. We systematically validate our model and benchmark our technique against competing baselines through extensive experimentation using public datasets such as CAVIAR, ViSOR, and CUHK as well as a scenario-specific in-house surveillance dataset. Results obtained have demonstrated the superiority of the proposed technique against a few popular existing state-of-the-art techniques.
C1 [Ahmed, Sk. Arif] Haldia Inst Technol, Haldia, India.
   [Dogra, Debi Prosad] Indian Inst Technol, Bhubaneswar, Orissa, India.
   [Kar, Samarjit] Natl Inst Technol, Dept Math, Durgapur, India.
   [Kim, Byung-Gyu] Sookmyung Womens Univ, Seoul, South Korea.
   [Hill, Paul] Univ Bristol, Dept Elect & Elect Engn, Bristol, Avon, England.
   [Bhaskar, Harish] Khalifa Univ, Visual Signal Anal & Proc VSAP Res Ctr, POB 127788, Abu Dhabi, U Arab Emirates.
C3 Haldia Institute of Technology; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Bhubaneswar;
   National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; Sookmyung Women's University; University of
   Bristol; Khalifa University of Science & Technology
RP Dogra, DP (corresponding author), Indian Inst Technol, Bhubaneswar, Orissa, India.
EM arif.1984.in@ieee.org; dpdogra@iitbbs.ac.in; dr.samarjitkar@gmail.com;
   bg.kim@ieee.org; paul.hill@bristol.ac.uk; harish.bhaskar@kustar.ac.ae
RI Sk, Arif Ahmed/U-5120-2019; Kar, Samarjit/R-3128-2019
OI Sk, Arif Ahmed/0000-0003-0706-2565; 
CR [Anonymous], 2008, PROC INT CONF PATTER
   [Anonymous], 2015, COMP INT NEUROSC, DOI DOI 10.1016/J.ATMOSENV.2015.01.039
   Bao X, 2014, IEEE INT C ADV VID S, P1087
   Bharath R, 2013, IEEE INT CONF CON AU, P1503
   Brun L, 2014, IEEE T CIRC SYST VID, V24, P1669, DOI 10.1109/TCSVT.2014.2302521
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Dogra D, 2015, 10 INT C COMP VIS TH, P31
   Dogra D. P., 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P478
   Dogra DP, 2016, MULTIMED TOOLS APPL, V75, P6373, DOI 10.1007/s11042-015-2576-7
   FISHER R, 2001, CAVIAR CONTEXT AWARE
   Colque RVHM, 2015, SIBGRAPI, P126, DOI 10.1109/SIBGRAPI.2015.21
   Javanbakhti S., 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P94, DOI 10.1109/InfoSEEE.2014.6948075
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kapsalas P., 2008, 2008 International Workshop on Content-based Multimedia Indexing - CBMI 2008, P147, DOI 10.1109/CBMI.2008.4564940
   Keum JS, 2012, JOINT INT CONF SOFT, P266, DOI 10.1109/SCIS-ISIS.2012.6505144
   Kim G, 2009, UNSUPERVISED DETECTI, P961
   Lai YH, 2015, IEEE T CIRC SYST VID, V25, P1026, DOI 10.1109/TCSVT.2014.2358022
   Lee WF, 2011, IEEE T IMAGE PROCESS, V20, P3028, DOI 10.1109/TIP.2011.2144610
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Lin WY, 2015, NEUROCOMPUTING, V155, P84, DOI 10.1016/j.neucom.2014.12.044
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Ma X, 2009, IEEE T CIRC SYST VID, V19, P397, DOI 10.1109/TCSVT.2009.2013510
   Manikandan MS, 2012, BIOMED SIGNAL PROCES, V7, P118, DOI 10.1016/j.bspc.2011.03.004
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Mathworks Inc, 2014, AB OBJ DET
   Mitri S, 2005, IEEE INT CONF ROBOT, P125
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Morris Brendan T., 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P154, DOI 10.1109/AVSS.2008.65
   Osberger W, 2001, PROC SPIE, V4299, P361, DOI 10.1117/12.429506
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rokunuzzaman M, 2010, J ROBOT MECHATRON, V22, P65, DOI 10.20965/jrm.2010.p0065
   Saleemi I, 2009, IEEE T PATTERN ANAL, V31, P1472, DOI 10.1109/TPAMI.2008.175
   Shou N, 2012, 2012 5TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P1205, DOI 10.1109/CISP.2012.6469927
   Suzuki S, 2007, IEEE SYS MAN CYBERN, P2980
   Tao Wu, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P1673, DOI 10.1109/ACSSC.2009.5469788
   Uddin Md Reaz, 2011, 2011 12th IEEE International Conference on Mobile Data Management (MDM 2011), P39, DOI 10.1109/MDM.2011.12
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wang JW, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P706, DOI 10.1109/ACPR.2011.6166550
   Wang WY, 2014, LECT NOTES COMPUT SC, V8689, P756, DOI 10.1007/978-3-319-10590-1_49
   Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9
   Xu D, 2013, IEEE IMAGE PROC, P3597, DOI 10.1109/ICIP.2013.6738742
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhou BL, 2012, PROC CVPR IEEE, P2871, DOI 10.1109/CVPR.2012.6248013
   Zhou Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1087
NR 46
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13651
EP 13680
DI 10.1007/s11042-016-3762-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900034
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tian, L
   Fan, CX
   Ming, Y
AF Tian, Lei
   Fan, Chunxiao
   Ming, Yue
TI Learning spherical hashing based binary codes for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Local descriptor; Binary codes; Spherical hashing;
   Supervised spherical hashing
ID APPROXIMATE NEAREST-NEIGHBOR; ITERATIVE QUANTIZATION; PROCRUSTEAN
   APPROACH; PATTERNS; REPRESENTATION; SCALE; ALGORITHMS; HISTOGRAM; SPACE;
   MODEL
AB Local feature descriptor has been widely used in computer vision field due to their excellent discriminative power and strong robustness. However, the forms of such local descriptors are predefined in the hand-crafted way, which requires strong domain knowledge to design them. In this paper, we propose a simple and efficient Spherical Hashing based Binary Codes (SHBC) feature learning method to learn a discriminative and robust binary face descriptor in the data-driven way. Firstly, we extract patch-wise pixel difference vectors (PDVs) by computing the difference between center patch and its neighboring patches. Then, inspired by the fact that hypersphere provide much stronger power in defining a tighter closed region in the original data space than hyperplane, we learn a hypersphere-based hashing function to map these PDVs into low-dimensional binary codes by an efficient iterative optimization process, which achieves both balanced bits partitioning of data points and independence between hashing functions. In order to better capture the semantic information of the dataset, our SHBC also can be used with supervised data embedding method, such as Canonical Correlation Analysis (CCA), namely Supervised-SHBC (S-SHBC). Lastly, we cluster and pool these learned binary codes into a histogram-based feature that describes the co-occurrence of binary codes. And we consider the histogram-based feature as our final feature representation for each face image. We investigate the performance of our SHBC and S-SHBC on FERET, CAS-PEAL-R1, LFW and PaSC databases. Extensive experimental results demonstrate that our SHBC descriptor outperforms other state-of-the-art face descriptors.
C1 [Tian, Lei; Fan, Chunxiao; Ming, Yue] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ming, Y (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing, Peoples R China.
EM tianlei189@sina.com; fcxg100@163.com; myname35875235@126.com
RI tian, lei/HGU-7245-2022
FU National Natural Science Foundation of China [NSFC-61402046,
   NSFC-61170176]; Fund for Beijing University of Posts and
   Telecommunications [2013XZ10, 2013XD-04]; Fund for the Doctoral Program
   of Higher Education of China [20120005110002]
FX The work presented in this paper was supported by the National Natural
   Science Foundation of China (Grants No. NSFC-61402046, NSFC-61170176),
   Fund for Beijing University of Posts and Telecommunications (No.
   2013XZ10, 2013XD-04), Fund for the Doctoral Program of Higher Education
   of China (Grants No. 20120005110002).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   [Anonymous], 2012, NIPS
   [Anonymous], 2009, NEURIPS
   [Anonymous], 2013, P IEEE 6 INT C BIOM
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], ARXIV14053162
   [Anonymous], 2014, ARXIV14043606
   [Anonymous], 2009, NEURIPS
   [Anonymous], BRIT MACH VIS C
   Arashloo ShervinRahimzadeh., 2013, BIOMETRICS THEORY AP, P1, DOI DOI 10.1109/BTAS.2013.6712721
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Draper B, 2014, 2014 IEEE INT JOINT, P1, DOI [10.1109/BTAS.2014.6996258, DOI 10.1109/BTAS.2014.6996258]
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Huang G.B., 2008, PROC WORKSHOP FACES
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Kulis B, 2012, IEEE T PATTERN ANAL, V34, P1092, DOI 10.1109/TPAMI.2011.219
   Lei Z, 2007, LECT NOTES COMPUT SC, V4642, P49
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu WJ, 2011, E-POLYMERS
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P1371, DOI 10.1109/TIFS.2015.2408431
   Lui Y., 2012, Proceed- ings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, CVPR 2012, P9
   Maturana D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P470, DOI 10.1109/FG.2011.5771444
   Maturana D, 2011, LECT NOTES COMPUT SC, V6495, P618, DOI 10.1007/978-3-642-19282-1_49
   Meng X, 2006, INT C PATT RECOG, P536
   Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Phillips P. Jonathon, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P346, DOI 10.1109/FG.2011.5771424
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205
   Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1
   Singh R, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P672, DOI 10.1109/ICIIP.2013.6707679
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tian L, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1039, DOI 10.1109/ICDSP.2015.7252036
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Werghi N, 2015, IEEE T IMAGE PROCESS, V24, P220, DOI 10.1109/TIP.2014.2370253
   Xia Y, 2015, PROC CVPR IEEE, P3332, DOI 10.1109/CVPR.2015.7298954
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016
   Ylioinas J, 2014, INT C PATT RECOG, P4471, DOI 10.1109/ICPR.2014.765
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 57
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13271
EP 13299
DI 10.1007/s11042-016-3708-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900016
DA 2024-07-18
ER

PT J
AU Cai, HM
   Wang, SL
   Liu, EY
   Liu, HX
AF Cai, Huimin
   Wang, Shulong
   Liu, Eryun
   Liu, Hongxia
TI Invariant object recognition based on combination of sparse DBN and SOM
   with temporal trace rule
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DBN; SOM; Hierarchical network; Trace rule; Transformation invariance
ID REPRESENTATION; INFORMATION
AB This paper proposes a trace rule based self-organized map (SOM) model built upon a sparse 2-stage deep belief network (DBN). The combination of SOM and sparse DBN forms a hierarchical network where DBN serves as a V2 features detector while SOM layer learns to extract transformation invariant features guided by trace learning rule during training phase. The performance of our proposed method is evaluated by stimulus specific information (SSI) measuring and comparison with classic algorithms. It is demonstrated that trace rule based SOM model can generate more neurons with high SSI value which is beneficial to convey more useful and discriminative information for further object recognition.
C1 [Cai, Huimin; Wang, Shulong; Liu, Hongxia] Xidian Univ, Sch Microelect, Xian 710071, Shaanxi, Peoples R China.
   [Liu, Eryun] Zhejiang Univ, Coll Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
C3 Xidian University; Zhejiang University
RP Wang, SL (corresponding author), Xidian Univ, Sch Microelect, Xian 710071, Shaanxi, Peoples R China.
EM hmcai1230@163.com; slwang@xidian.edu.cn
FU National Natural Science Foundation of China [61076097, 61473257]
FX This work was supported in part by the Project of National Natural
   Science Foundation of China (Grant Nos. 61076097, 61473257).
CR [Anonymous], 2008, Advances in neural information processing systems
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bengio Yoshua, 2007, ADV NEURAL INFORM PR, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Coates A., 2011, P 14 INT C ART INT S, V15, P215
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Ji NN, 2014, KNOWL-BASED SYST, V63, P82, DOI 10.1016/j.knosys.2014.03.016
   KOHONEN T, 1982, BIOL CYBERN, V43, P59, DOI 10.1007/BF00337288
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Liu MX, 2016, IEEE T CYBERNETICS, V46, P298, DOI 10.1109/TCYB.2015.2401733
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Ng Andrew Y, 2012, P 26 ANN C NEUR PROC, P665, DOI DOI 10.1002/2014GB005021
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Robinson L, 2015, BIOL CYBERN, V109, P505, DOI 10.1007/s00422-015-0658-2
   Rolls ET, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00035
   Rolls ET, 2011, PROG NEUROBIOL, V95, P448, DOI 10.1016/j.pneurobio.2011.08.002
   Rolls ET, 1997, J COMPUT NEUROSCI, V4, P309, DOI 10.1023/A:1008899916425
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Wallis G, 1997, PROG NEUROBIOL, V51, P167, DOI 10.1016/S0301-0082(96)00054-8
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang J, 2015, PATTERN RECOGN LETT, V51, P57, DOI 10.1016/j.patrec.2014.08.002
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhang J, 2013, COMPUT VIS IMAGE UND, V117, P56, DOI 10.1016/j.cviu.2012.10.004
NR 27
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12017
EP 12034
DI 10.1007/s11042-016-3956-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000048
DA 2024-07-18
ER

PT J
AU Feng, T
   Mao, X
AF Feng, Tao
   Mao, Xia
TI Multimodal Data fusion for SRGPS antenna motion error reduction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Antenna motion; SRGPS; Error; Multiple reference station; Weighted
   average; Graph learning
ID OBJECT RETRIEVAL; NAVIGATION; FLEXURE; GPS
AB Antenna motion is a primary fault that degrades the integrity of shipboard relative GPS (SRGPS) systems, so we must investigate how to monitor and mitigate its impacts. Previous work proposed a single-baseline mode, but it had obvious problems, such as large motion errors, error measurement difficulties, and poor reliability. To solve these issues, we propose a multiple reference station architecture that deploys more than one reference station at different positions on ship. The observations are first translated to the ship reference point, and then integrated into a comprehensive measurement that accounts for the overall antenna motion errors. We consider two integrating methods: direct and weighted average methods. The direct average method is simple and intuitive, but the weighted average method more effectively reduced the overall antenna motion error by using the reciprocal standard deviation of historical measurements as weighting factors. All the antennas are mounted on the same ship body, so their correlations should also be considered when determining weighting factors. We used the ranking scores of the antennas derived using a graph-learning algorithm and fused them with the standard deviations to create new weighting factors. Finally, our experimental results demonstrated that the weighting factors based on the standard deviations and ranking scores reduced the overall antenna-motion error variance and improved the system integrity.
C1 [Feng, Tao; Mao, Xia] Beihang Univ, Sch Elect & Informat Engn, 37 XueYuan Rd, Beijing 100191, Peoples R China.
   [Feng, Tao] China Transport Telecommun & Informat Ctr, 1 Anwai Waiguan Houshen, Beijing 100011, Peoples R China.
C3 Beihang University
RP Mao, X (corresponding author), Beihang Univ, Sch Elect & Informat Engn, 37 XueYuan Rd, Beijing 100191, Peoples R China.
EM moukyou@buaa.edu.cn
CR Blanch J, 2011, P INT TECH M I NAVIG, P459
   Deng H., 2009, WSDM, P212
   Dogra S., 2005, Proceedings of the 18th International Technical Meeting of the Satellite Division of the Institute of Navigation (ION GNSS 2005), P2871
   Dutton KE, 2008, Patent, US, Patent No. [US 7411545:B2, 7411545]
   Feng SJ, 2009, GPS SOLUT, V13, P13, DOI 10.1007/s10291-008-0093-0
   Gao Y, 2015, MULTIMEDIA SOCIAL EV, V8935, P269
   Gao Y, 2013, IEEE T IMAGE PROCESS, V22, P363, DOI 10.1109/TIP.2012.2202676
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gebre-Egziabher D, 2010, IEEE T AERO ELEC SYS, V46, P483, DOI 10.1109/TAES.2010.5461636
   He J, 2004, ACM MULTIMED SYS J, V15, P9, DOI [10.1145/1027527.1027531, DOI 10.1145/1027527.1027531]
   Heo MB, 2006, IEEE T AERO ELEC SYS, V42, P670, DOI 10.1109/TAES.2006.1642581
   Khanafseh S, 2008, POS LOC NAVIGAT S IE, V46, P583
   Koenig M, 2010, THESIS
   Li F, 2011, P IEEE INT C IM PROC, P2453
   Offer CR, 2006, I NAVIG SAT DIV INT, P726
   Peterson B.R., 2004, Proc. ION GNSS 2004, P544
   Peterson B.R., 2005, Proc. ION GNSS 2005, P26
   Petovello M., 2005, Proceedings of the 18th International Technical Meeting of the Satellite Division of the Institute of Navigation (ION GNSS 2005), P219
   Petovello MG, 2009, IEEE T AERO ELEC SYS, V45, P523, DOI 10.1109/TAES.2009.5089539
   Psiaki ML, 2007, J GUID CONTROL DYNAM, V30, P1628, DOI 10.2514/1.29534
   Rife J., 2007, P 63 ANN M I NAV CAM, P356
   Rife J, 2008, P IEEE, V96, P1958, DOI 10.1109/JPROC.2008.2006107
   Walter T, 2010, I NAVIG SAT DIV INT, P2031
   Wang M, 2009, IEEE T CIRC SYST VID, V19, P733, DOI 10.1109/TCSVT.2009.2017400
   Yang YH, 2015, NEUROCOMPUTING, V160, P191, DOI 10.1016/j.neucom.2014.12.060
   Zhao SC, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1025, DOI 10.1145/2647868.2655035
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
NR 27
TC 1
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 12035
EP 12050
DI 10.1007/s11042-016-3972-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000049
DA 2024-07-18
ER

PT J
AU Yang, TC
   Lo, NW
   Liaw, HT
   Wu, WC
AF Yang, Ta-Chih
   Lo, Nai-Wei
   Liaw, Horng-Twu
   Wu, Wei Chen
TI A secure smart card authentication and authorization framework using in
   multimedia cloud
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Diffie-Hellman key exchange; User authentication; Smart
   card; RBAC
ID SCHEME
AB Through the rapid evolution of information technology, there are many innovative services and products bring a lot of convenience for people especially "Cloud Computing". The cloud computing provides users more than personal computer's storage resources and calculate ability. Nowadays the most consume hard drive space or calculate resources are belong to multimedia applications, such like HD videos, HD computer games and so on. Because of the reason of the requirement, the cloud computing technology also develop multimedia cloud. The multimedia cloud is evolved from media cloud and multimedia-aware cloud, combine with the highly calculate ability, high quality of service and virtually unlimited storage space. Users can put all the multimedia content or games into the multimedia cloud. But there is still a harassment, the "Information Security". Before users can use multimedia cloud, they must go through an insecure network environment between cloud services and user's equipment. Malicious attackers usually attack this insecure section to capture user's information. Besides the privacy of the user's data in the multimedia cloud is also a fatal reason that why users don't use this convenience and powerful service. In this article, we provide a smart card based secure authentication mechanism and a protect user's data authorization framework. We expect the framework can protect users' privacy and their data.
C1 [Yang, Ta-Chih; Lo, Nai-Wei] Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei, Taiwan.
   [Liaw, Horng-Twu] Shih Hsin Univ, Dept Informat Management, Taipei, Taiwan.
   [Wu, Wei Chen] Hsin Sheng Jr Coll Med Care & Management, Ctr Comp, Taoyuan, Taiwan.
C3 National Taiwan University of Science & Technology; Shih Hsin University
RP Yang, TC (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, Taipei, Taiwan.
EM tcyang@livemail.tw
RI Lo, Nai-Wei/K-8389-2012
OI Wu, Wei-chen/0000-0002-2419-6453
FU Taiwan Information Security Center (TWISC); Academia Sinica; Ministry of
   Science and Technology, Taiwan [MOST 104-2218-E-001-002, MOST
   104-2119-M-011-003, MOST 104-2923-E-011-005-MY3, MOST
   103-2221-E-011-091-MY2]
FX This work was supported in part by Taiwan Information Security Center
   (TWISC), Academia Sinica, and Ministry of Science and Technology,
   Taiwan, under the grant numbers MOST 104-2218-E-001-002, MOST
   104-2119-M-011-003, MOST 104-2923-E-011-005-MY3 and MOST
   103-2221-E-011-091-MY2.
CR [Anonymous], ENG UNIVERSE SCI RES
   [Anonymous], INT C DIG SEC FOR
   [Anonymous], INT C CLOUD COMP
   [Anonymous], 2010, TOP THREATS CLOUD CO
   [Anonymous], COMPUTER
   [Anonymous], STUDY RFID SECURITY
   [Anonymous], P 6 INT AS C IND ENG
   [Anonymous], J INNOVATION MANAGEM
   [Anonymous], 2011 C EL COMM DIG L
   [Anonymous], INT C PAR DISTR COMP
   [Anonymous], NIST DEFINITION CLOU
   Chang CC, 2009, COMPUT COMMUN, V32, P611, DOI 10.1016/j.comcom.2008.11.032
   Chang-Lung Tsai, 2010, Proceedings of the 2010 Sixth International Conference on Networked Computing and Advanced Information Management (NCM 2010), P645
   Chen YM, 2014, MULTIMED TOOLS APPL, V69, P1041, DOI 10.1007/s11042-012-1166-1
   Chunlin Li., 2015, IFS, P1
   Ferraiolo D. F., 2001, ACM Transactions on Information and Systems Security, V4, P224, DOI 10.1145/501978.501980
   Gruschka N., 2010, 2010 IEEE 3rd International Conference on Cloud Computing (CLOUD 2010), P276, DOI 10.1109/CLOUD.2010.23
   He DJ, 2011, COMPUT COMMUN, V34, P367, DOI 10.1016/j.comcom.2010.02.031
   Jasti A, 2010, INT CARN CONF SECU, P35, DOI 10.1109/CCST.2010.5678682
   Le XH, 2012, J BIOMED INFORM, V45, P1084, DOI 10.1016/j.jbi.2012.06.001
   Li X, 2015, WIRELESS PERS COMMUN, V80, P175, DOI 10.1007/s11277-014-2002-x
   Lo NW, 2015, WIRELESS PERS COMMUN, V84, P2119, DOI 10.1007/s11277-015-2515-y
   Oh S, 2003, INFORM SYST, V28, P533, DOI 10.1016/S0306-4379(02)00029-7
   Reid F., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P1318, DOI 10.1109/PASSAT/SocialCom.2011.79
   Sangroya A, 2010, COMM COM INF SC, V54, P255
   Song RG, 2010, COMPUT STAND INTER, V32, P321, DOI 10.1016/j.csi.2010.03.008
   Tripathi A., 2011, IEEE INT C SIGNAL PR, P1
   Tu H, 2015, PEER PEER NETW APPL, V8, P903, DOI 10.1007/s12083-014-0248-4
   Xu J, 2009, COMPUT STAND INTER, V31, P723, DOI 10.1016/j.csi.2008.09.006
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Zhiqiang Wei, 2010, 2010 IEEE International Conference on Software Engineering and Service Sciences (ICSESS 2010), P86, DOI 10.1109/ICSESS.2010.5552297
   Zhu WW, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940269
NR 32
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11715
EP 11737
DI 10.1007/s11042-016-3506-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000033
DA 2024-07-18
ER

PT J
AU Han, AL
   Han, FL
   Hao, J
   Yuan, YH
AF Han, Aili
   Han, Feilin
   Hao, Jing
   Yuan, Yahui
TI An improved saliency detection method based on non-uniform
   quantification and channel-weighted color distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Visual computing; Non-uniform quantification;
   Channel weight
AB We propose a non-uniform quantification method for RGB channels based on the visual sensitivities of human eyes to the red, green and blue colors, and give weights to RGB channels which are used to compute the channel-weighted color distances. Furthermore, we design a saliency detection method using the non-uniform quantification method and the channel-weighted color distances measurement. We first quantify the values in RGB channels in different step-lengths and determine the weights w (r) , w (g) and w (b) based on the visual sensitivities of human eyes to the three-primary colors. And then we convert the quantified image into that in Lab color space, which are segmented into some regions, and compute the channel-weighted color distance using the weights w (L) , w (a) and w (b) , which are computed from the weights w (r) , w (g) and w (b) and the transformation from RGB color space to Lab color space. The saliency of each region is computed using the weighted distances and spatial weights. The proposed non-uniform quantification method and the channel-weighted color distance measurement can be used for the applications based on color features in the field of image processing and computer vision. Experimental results show that our methods can improve the efficiency and performance of saliency detection to some extent.
C1 [Han, Aili; Hao, Jing; Yuan, Yahui] Shandong Univ, Dept Comp Sci & Technol, Weihai 264209, Peoples R China.
   [Han, Feilin] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310007, Zhejiang, Peoples R China.
C3 Shandong University; Zhejiang University
RP Han, AL (corresponding author), Shandong Univ, Dept Comp Sci & Technol, Weihai 264209, Peoples R China.
EM hanal@sdu.edu.cn
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2011, P IEEE MTT S INT MIC
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Lu S, 2014, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2014.357
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Miao QG, 2016, IEEE T NEUR NET LEAR, V27, P2216, DOI 10.1109/TNNLS.2015.2475750
   Miao QG, 2013, IEEE T IMAGE PROCESS, V22, P1546, DOI 10.1109/TIP.2012.2233487
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
NR 16
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 11037
EP 11050
DI 10.1007/s11042-016-3463-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400041
DA 2024-07-18
ER

PT J
AU Huang, JC
   Jeng, FG
   Chen, TH
AF Huang, Jyun-Ci
   Jeng, Fuh-Gwo
   Chen, Tzung-Her
TI A new buyer-seller watermarking protocol without multiple watermarks
   insertion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking protocol; Copyright protection; Digital watermarking;
   Visual cryptography
ID DIGITAL WATERMARKING; ROBUST WATERMARKING
AB Watermarking protocols are designed for tracing illegal distributors when unauthorized copies are found. So far, most of the proposed schemes set up two or more watermarks embedded to a copy by the seller before it was sold. The main potential concerns of multiple watermarking are the image quality would be damaged and any earlier embedded watermarks would be destroyed as well. Thanks to visual cryptography which encodes the secret image into two shares, and recovers the secret by collecting these two shares. Therefore, a new buyer-seller watermarking protocol is proposed in this paper by applying the technique of visual cryptography to Lei et al.'s scheme so as to free from the disadvantages of multiple-watermarking insertion.
C1 [Huang, Jyun-Ci; Chen, Tzung-Her] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
   [Jeng, Fuh-Gwo] Natl Chiayi Univ, Dept Appl Math, Chiayi 60004, Taiwan.
C3 National Chiayi University; National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
EM thchen@mail.ncyu.edu.tw
OI Chen, Tzung-Her/0000-0001-5775-6034
FU National Science Council, Taiwan, R.O.C. [NSC 102-2221-E-415-014, NSC
   102-2221-E-415-007]
FX This work was partially supported National Science Council, Taiwan,
   R.O.C., under contract by NSC 102-2221-E-415-014 and NSC
   102-2221-E-415-007.
CR Chen TH, 2005, J CHIN INST ENG, V28, P535, DOI 10.1080/02533839.2005.9671019
   Cheung SC, 2002, P INT COMP SOFTW APP, P105, DOI 10.1109/CMPSAC.2002.1044539
   Chin-Chen Chang, 2010, ICIC Express Letters, V4, P89
   Horng G, 2003, INT J COMPUT NUMER A, V4, P423
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Lin PY, 2014, J SYST SOFTWARE, V95, P194, DOI 10.1016/j.jss.2014.04.038
   Lin PL, 2001, J SYST SOFTWARE, V55, P261, DOI 10.1016/S0164-1212(00)00075-3
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Pei SC, 2005, IEEE SIGNAL PROC LET, V12, P333, DOI 10.1109/LSP.2004.842295
   Qi XJ, 2007, SIGNAL PROCESS, V87, P1264, DOI 10.1016/j.sigpro.2006.11.002
   Qiao LT, 1998, J VIS COMMUN IMAGE R, V9, P194, DOI 10.1006/jvci.1998.0391
   Qiaolun Gu, 2009, ICIC Express Letters, V3, P397
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2014, IEEE T IMAGE PROCESS, V23, P969, DOI 10.1109/TIP.2013.2260760
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2012, SIGNAL PROCESS, V92, P1137, DOI 10.1016/j.sigpro.2011.11.013
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Wu Y, 2008, ADV MULTIMEDIA 2008, V2008, P1, DOI DOI 10.1155/2008/905065
   Yang CY, 2010, INT J INNOV COMPUT I, V6, P1401
   Zhang J., 2006, IEE Proceedings-Information Security, V153, P15, DOI 10.1049/ip-ifs:20055069
NR 24
TC 3
Z9 3
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9667
EP 9679
DI 10.1007/s11042-016-3573-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300025
DA 2024-07-18
ER

PT J
AU Meng, L
   Miao, CY
   Leung, C
AF Meng, Lei
   Miao, Chunyan
   Leung, Cyril
TI Towards online and personalized daily activity recognition, habit
   modeling, and anomaly detection for the solitary elderly through
   unobtrusive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Healthcare system for the elderly; Online activity recognition;
   Personalized daily habit modeling; Personalized anomaly detection
ID HUMAN FALL DETECTION; FRAMEWORK; HMM
AB Rapid population aging and advances in sensing technologies motivate the development of unobtrusive healthcare systems, designed to unobtrusively collect an elderly's personalized information of daily living and help him actively enjoy a healthy lifestyle. Existing studies towards this goal typically focus on recognition of activities of daily living (ADLs) and abnormal behavior detection. However, the applicability of these approaches is often limited by an offline analysis strategy, complex parameter tuning, obtrusive data collection, and a need for training data. To overcome these shortcomings, this paper presents a novel framework, named the online daily habit modeling and anomaly detection (ODHMAD) model, for the real-time personalized ADL recognition, habit modeling, and anomaly detection for the solitary elderly. In contrast to most existing studies which consider activity recognition and abnormal behavior detection separately, ODHMAD links both in a system. Specifically, ODHMAD performs online recognition of the elderly's daily activities and dynamically models the elderly's daily habit. In this way, ODHMAD recognizes the personalized abnormal behavior of an elderly by detecting anomalies in his learnt daily habit. The developed online activity recognition (OAR) algorithm determines the occurrence of activities by modeling the activation status of sensors. It has advantages of online learning, light parameter tuning, and no training data required. Moreover, OAR is able to obtain details of the detected activities. Experimental results demonstrate the effectiveness of the proposed OAR model for online activity recognition in terms of precision, false alarm rate, and miss detection rate.
C1 [Meng, Lei; Miao, Chunyan; Leung, Cyril] Nanyang Technol Univ, Joint NTU UBC Res Ctr Excellence Act Living Elder, Singapore, Singapore.
   [Miao, Chunyan] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
   [Leung, Cyril] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.
C3 Nanyang Technological University; Nanyang Technological University;
   University of British Columbia
RP Meng, L (corresponding author), Nanyang Technol Univ, Joint NTU UBC Res Ctr Excellence Act Living Elder, Singapore, Singapore.
EM lmeng@ntu.edu.sg; ascymiao@ntu.edu.sg; cleung@ntu.edu.sg
RI Miao, Chunyan/A-3730-2011
OI Miao, Chunyan/0000-0002-0300-3448
FU National Research Foundation Singapore under its Interactive Digital
   Media (IDM) Strategic Research Programme
FX This research is supported by the National Research Foundation Singapore
   under its Interactive Digital Media (IDM) Strategic Research Programme.
CR Aicha AhmedNait., 2013, Proceedings of the ACM conference on Pervasive and ubiquitous computing adjunct publication, P1285
   [Anonymous], 2015, MULTIMED TOOLS APPL
   Avgerinakis K., 2013, PROC 1 ACM INT WORKS, P3, DOI 10.1145/2505323.2505327
   Bogomolov A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P477, DOI 10.1145/2647868.2654933
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chavarriaga R, 2011, IEEE SYS MAN CYBERN, P2761, DOI 10.1109/ICSMC.2011.6084090
   Chen J, 2005, P ANN INT IEEE EMBS, P3551, DOI 10.1109/IEMBS.2005.1617246
   Cheng H, 2014, MULTIMED TOOLS APPL, V70, P177, DOI 10.1007/s11042-012-1162-5
   Cheng J, 2013, IEEE J BIOMED HEALTH, V17, P38, DOI 10.1109/TITB.2012.2226905
   Gayathri KS, 2015, PERS UBIQUIT COMPUT, V19, P271, DOI 10.1007/s00779-014-0827-7
   Hajihashemi Z, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1241, DOI 10.1145/2638728.2638805
   Hevesi P, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P141, DOI 10.1145/2632048.2636084
   Ince N.F., 2007, Proceedings of the 1st ACM SIGMOBILE international workshop on Systems and networking support for healthcare and assisted living environments, P61, DOI [10.1145/1248054.1248071, DOI 10.1145/1248054.1248071]
   Ordóñez FJ, 2015, PERS UBIQUIT COMPUT, V19, P259, DOI 10.1007/s00779-014-0820-1
   Khan SS, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1075
   Lepri B, 2010, PERS UBIQUIT COMPUT, V14, P749, DOI 10.1007/s00779-010-0290-z
   Li H, 2015, P ACM C HUM FACT COM, P43
   Li Q, 2009, SIXTH INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P138, DOI [10.1109/P3644.45, 10.1109/BSN.2009.46]
   Loic CarouxCharles Consel., 2014, P 16 INT ACM SIGACCE, P43, DOI DOI 10.1145/2661334.2661360
   Lotfi A, 2012, J AMB INTEL HUM COMP, V3, P205, DOI 10.1007/s12652-010-0043-x
   Min-Seok Lee, 2009, 2009 ICROS-SICE International Joint Conference. ICCAS-SICE 2009, P134
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   NIE L, 2015, P 23 ANN ACM C MULT, P591, DOI DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Ojetola O, 2014, THESIS
   Ojetola O, 2015, PROC 6 ACM MULTIMEDI, P243, DOI [10.1145/2713168.2713198, DOI 10.1145/2713168.2713198]
   Park K, 2010, P INT C PERV TECHN R
   Piyathilaka L, 2013, C IND ELECT APPL, P567
   Rakhecha Sanjana, 2013, P 8 INT C BOD AR NET, P420, DOI DOI 10.4108/ICSTBODYNETS.2013.253528
   Rashidi P, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508045
   Rashidi P, 2013, IEEE J BIOMED HEALTH, V17, P579, DOI 10.1109/JBHI.2012.2234129
   Sagha H, 2011, IEEE SYS MAN CYBERN, P36, DOI 10.1109/ICSMC.2011.6083628
   Seeger Christian., 2011, Proceedings of the 6th International Confer- ence on Body Area Networks, P1
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Song X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2438653.2438670
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10
   Tong LN, 2013, IEEE SENS J, V13, P1849, DOI 10.1109/JSEN.2013.2245231
   Uddin M., 2015, P 2015 WORKSHOP WEAR, P21
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Yan, 2013, 2013 20th IEEE International Conference on Image Processing (ICIP), P2842, DOI 10.1109/ICIP.2013.6738585
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yin J, 2008, IEEE T KNOWL DATA EN, V20, P1082, DOI 10.1109/TKDE.2007.1042
   Yiping Tang., 2006, SICE-ICASE, 2006, P3850
   Yuan BC, 2014, PERS UBIQUIT COMPUT, V18, P865, DOI 10.1007/s00779-013-0696-5
   Zhang S, 2008, 2008 10TH IEEE INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES, P171, DOI 10.1109/HEALTH.2008.4600131
   Zheng YL, 2014, IEEE T BIO-MED ENG, V61, P1538, DOI 10.1109/TBME.2014.2309951
NR 49
TC 34
Z9 40
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10779
EP 10799
DI 10.1007/s11042-016-3267-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400027
DA 2024-07-18
ER

PT J
AU Noordin, MNMJ
   Isa, NAM
   Lim, WH
AF Noordin, Mohd Naim Mohd Jain
   Isa, Nor Ashidi Mat
   Lim, Wei Hong
TI Saturation avoidance color correction for digital color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saturation avoidance color correction; Color constancy; Image
   post-processing; Pixel distribution
ID MACHINE VISION; CONSTANCY ALGORITHMS; COMPUTER VISION
AB The qualities of color images captured by digital imaging devices are vulnerable to the scene illumination settings of a given environment. The colors of captured objects may not be accurately reproduced when the illumination settings are uncontrollable or not known a priori. This undesirable property can inevitably degrade the qualities of captured images and lead to difficulties in subsequent image-processing stages. Considering that the task of controlling scene illumination is nontrivial, color correction has emerged as a plausible post-processing procedure to efficiently restore the scene chromatics of a given image. In this study, a new color correction technique called the Saturation Avoidance Color Correction (SACC) algorithm is proposed to remove the undesirable effect of scene illuminants. Unlike most well-established color correction algorithms, the proposed SACC comprises a nonlinear pixel adjustment mechanism to avoid the saturation effect during the color manipulation process. A collection of color images including indoor, outdoor, and underwater images are used to verify the capability of SACC. Extensive experimental studies reveal that the proposed algorithm is preferable to some existing techniques because the former has a high capability to mitigate the color saturation issue and is able to produce corrected images with more pleasant visualization.
C1 [Noordin, Mohd Naim Mohd Jain; Isa, Nor Ashidi Mat; Lim, Wei Hong] Univ Sains Malaysia, Imaging & Intelligent Syst Res Team ISRT, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
C3 Universiti Sains Malaysia
RP Isa, NAM (corresponding author), Univ Sains Malaysia, Imaging & Intelligent Syst Res Team ISRT, Sch Elect & Elect Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM ashidi@usm.my
RI Lim, Wei Hong/J-9273-2019; Mat Isa, Nor Ashidi/I-7826-2017
OI Lim, Wei Hong/0000-0003-1673-8088; Mat Isa, Nor
   Ashidi/0000-0002-2675-4914
FU Fundamental Research Grant Scheme ("Formulation of a Robust Framework of
   Image Enhancement for Nonuniform Illumination and Low-Contrast Images")
   of the Ministry of Higher Education of Malaysia
FX The authors would like to express their sincere gratitude to the
   associate editor and all reviewers who made great contributions to the
   improvement of this paper. This research was supported by the
   Fundamental Research Grant Scheme ("Formulation of a Robust Framework of
   Image Enhancement for Nonuniform Illumination and Low-Contrast Images")
   of the Ministry of Higher Education of Malaysia.
CR Agarwal V, 2007, NEURAL NETWORKS, V20, P559, DOI 10.1016/j.neunet.2007.02.004
   [Anonymous], 2009 3 INT S INT INF
   AYACHE N, 1995, IMAGE VISION COMPUT, V13, P295, DOI 10.1016/0262-8856(95)99717-F
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P972, DOI 10.1109/TIP.2002.802531
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529
   Barnard K, 2000, LECT NOTES COMPUT SC, V1842, P375
   Bianco S, 2010, PATTERN RECOGN, V43, P695, DOI 10.1016/j.patcog.2009.08.007
   Bianco S, 2008, LECT NOTES COMPUT SC, V5188, P104, DOI 10.1007/978-3-540-85891-1_14
   Bianconi F, 2014, COMPUT IND, V65, P325, DOI 10.1016/j.compind.2013.12.001
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Cardei V., 2000, THESIS
   Chen CL, 2011, APPL SOFT COMPUT, V11, P523, DOI 10.1016/j.asoc.2009.12.012
   Chen SY, 2008, IEEE T IMAGE PROCESS, V17, P167, DOI 10.1109/TIP.2007.914755
   Cheng Y, 2008, IEEE T AUTOM SCI ENG, V5, P140, DOI 10.1109/TASE.2007.912058
   Doulamis AD, 2000, IEEE T CONSUM ELECTR, V46, P758, DOI 10.1109/30.883444
   Eberhardt M, 2008, COMPUT ELECTR ENG, V34, P111, DOI 10.1016/j.compeleceng.2007.10.006
   Faghih MM, 2014, APPL SOFT COMPUT, V17, P52, DOI 10.1016/j.asoc.2013.11.016
   Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113
   Finlayson G, 2000, IEEE T IMAGE PROCESS, V9, P1774, DOI 10.1109/83.869188
   Finlayson G. D., 2004, 12 COL IM C COL SCI
   Finlayson GD, 2006, INT J COMPUT VISION, V67, P93, DOI 10.1007/s11263-006-4100-z
   Gasparini F, 2004, PATTERN RECOGN, V37, P1201, DOI 10.1016/j.patcog.2003.12.007
   Ghani ASA, 2015, APPL SOFT COMPUT, V37, P332, DOI 10.1016/j.asoc.2015.08.033
   Gijsenij A, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING WORKSHOPS, PROCEEDINGS, P171, DOI 10.1109/ICIAPW.2007.16
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   HUBEL P, 2000, Patent No. 6038339
   Huo JY, 2006, IEEE T CONSUM ELECTR, V52, P541, DOI 10.1109/TCE.2006.1649677
   Kim BK, 2010, IMAGE VISION COMPUT, V28, P952, DOI 10.1016/j.imavis.2009.11.009
   Kurtulmus F, 2014, EXPERT SYST APPL, V41, P7390, DOI 10.1016/j.eswa.2014.06.013
   Kwok NM, 2013, ENG APPL ARTIF INTEL, V26, P2356, DOI 10.1016/j.engappai.2013.07.023
   Kwok N. M., 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P994, DOI 10.1109/CISP.2011.6100336
   Lam EY, 2005, I SYMP CONSUM ELECTR, P134, DOI 10.1109/ISCE.2005.1502356
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee JH, 2006, AUTOMAT CONSTR, V15, P616, DOI 10.1016/j.autcon.2005.06.018
   Montenegro J, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE), P313, DOI 10.1109/ICEEE.2013.6676048
   Nammi S, 2014, OPTIK, V125, P3954, DOI 10.1016/j.ijleo.2014.01.152
   Nashat S, 2014, J FOOD ENG, V120, P233, DOI 10.1016/j.jfoodeng.2013.08.006
   Nikitenko Denis, 2008, Journal of Multimedia, V3, P9, DOI 10.4304/jmm.3.5.9-18
   Quintana J, 2011, COMPUT MED IMAG GRAP, V35, P646, DOI 10.1016/j.compmedimag.2011.03.006
   Rajamani V, 2013, 2013 INTERNATIONAL CONFERENCE ON GREEN COMPUTING, COMMUNICATION AND CONSERVATION OF ENERGY (ICGCE), P100, DOI 10.1109/ICGCE.2013.6823408
   Raju A, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P208, DOI 10.1109/ICIIP.2013.6707584
   Recky Michal, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P356, DOI 10.1109/ICPR.2010.96
   Schechner YY, 2005, IEEE J OCEANIC ENG, V30, P570, DOI 10.1109/JOE.2005.850871
   Stanikunas R, 2004, NEURAL NETWORKS, V17, P327, DOI 10.1016/j.neunet.2003.12.002
   VANDEWEIJER J, 2005, IEEE INT C IM PROC I
   Weng CC, 2005, IEEE INT SYMP CIRC S, P3801
   Wirth Michael, 2010, Proceedings of the 2010 Seventh Canadian Conference on Computer and Robot Vision (CRV 2010), P79, DOI 10.1109/CRV.2010.17
   Zhang J, 2016, OPTIK, V127, P776, DOI 10.1016/j.ijleo.2015.10.120
   Zhuo L, 2016, NEUROCOMPUTING, V174, P815, DOI 10.1016/j.neucom.2015.10.008
   Zhuo L, 2014, NEUROCOMPUTING, V134, P111, DOI 10.1016/j.neucom.2012.12.080
NR 52
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 10279
EP 10312
DI 10.1007/s11042-016-3620-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300054
DA 2024-07-18
ER

PT J
AU Parah, SA
   Sheikh, JA
   Ahad, F
   Loan, NA
   Bhat, GM
AF Parah, Shabir A.
   Sheikh, Javaid A.
   Ahad, Farhana
   Loan, Nazir A.
   Bhat, G. M.
TI Information hiding in medical images: a robust medical image
   watermarking system for E-healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Region of interest; Region of non interest; Discrete cosine transform;
   Robustness
ID DCT
AB Electronic transmission of the medical images is one of the primary requirements in a typical Electronic-Healthcare (E-Healthcare) system. However this transmission could be liable to hackers who may modify the whole medical image or only a part of it during transit. To guarantee the integrity of a medical image, digital watermarking is being used. This paper presents two different watermarking algorithms for medical images in transform domain. In first technique, a digital watermark and Electronic Patients Record (EPR) have been embedded in both regions; Region of Interest (ROI) and Region of Non-Interest (RONI). In second technique, Region of Interest (ROI) is kept untouched for tele-diagnosis purpose and Region of Non-Interest (RONI) is used to hide the digital watermark and EPR. In either algorithm 8 x 8 block based Discrete Cosine Transform (DCT) has been used. In each 8 x 8 block two DCT coefficients are selected and their magnitudes are compared for embedding the watermark/EPR. The selected coefficients are modified by using a threshold for embedding bit a '0' or bit '1' of the watermark/EPR. The proposed techniques have been found robust not only to singular attacks but also to hybrid attacks. Comparison results viz-a - viz payload and robustness show that the proposed techniques perform better than some existing state of art techniques. As such the proposed algorithms could be useful for e-healthcare systems.
C1 [Parah, Shabir A.; Sheikh, Javaid A.; Ahad, Farhana; Loan, Nazir A.; Bhat, G. M.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, Jammu & Kashmir, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar 190006, Jammu & Kashmir, India.
EM shabireltr@gmail.com
RI Parah, Shabir/AAB-7603-2021
OI Parah, Shabir/0000-0001-5983-0912; Sheikh, Javaid A/0000-0003-3113-3802;
   Bhat, Ghulam Mohiuddin/0000-0001-9106-4699
CR Al-Qershi OM, 2009, WORLD ACAD SCI ENG T, P801
   [Anonymous], 2014, ECCV
   [Anonymous], 2014, AM J ENG TECHNOLOGY
   [Anonymous], 2014, ARAB J GEOSCI
   Bhat GM, 2010, MAEJO INT J SCI TECH, V4, P125
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Chen YH, 2011, IEEE T VLSI SYST, V19, P709, DOI 10.1109/TVLSI.2009.2037968
   Coatrieux G, 2007, P ANN INT IEEE EMBS, P5654
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Das S, 2012, J MED SYST, V36, P3339, DOI 10.1007/s10916-012-9827-1
   Fotopoulos V, 2008, IEEE INT C BIOINF BI, P910
   Giakoumaki, 2010, IEEE T INF TECHNOL B, V4, P722
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Liqiang N, 2014, P INT ACM SIGIR C
   Navas KA, 2008, PROC WRLD ACAD SCI E, V28, P292
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Parah SA, 2015, INT J ELECTRON, V102, P1253, DOI 10.1080/00207217.2014.954635
   Priya RL, 2014, J THEOR APPL INF TEC, V65
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Rao NV, 2011, INF SECUR J, V20, P148, DOI 10.1080/19393555.2011.561154
   Raul RC, 2007, IEEE 17 INT C EL COM
   Shabanloui A., 2015, MULTIDIM SYST SIGN P, P1
   Shaoqing R, 2015, COMPUTER VISION PATT
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh R, 2001, MIT TECHNOL REV
   Solanki Neha, 2014, International Journal of Modern Education and Computer Science, V6, P40, DOI 10.5815/ijmecs.2014.10.06
   Soliman MM., 2012, Int J Smart Home, V6, P37
   Subhashini D., 2012, INT J ENG RES TECHNO, V1
   Wakatani Akiyoshi, 2002, P 35 ANN HAW INT C S
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
NR 32
TC 116
Z9 117
U1 1
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10599
EP 10633
DI 10.1007/s11042-015-3127-y
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400018
DA 2024-07-18
ER

PT J
AU Su, YT
   Wang, HY
   Jing, PG
   Xu, CZ
AF Su, Yuting
   Wang, Haiyi
   Jing, Peiguang
   Xu, Chuanzhong
TI A spatial-temporal iterative tensor decomposition technique for action
   and gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Tensor decomposition; Spatial-temporal iterative;
   Video sequences
AB Classification of video sequences is an important task with many applications in video search and action recognition. As opposed to some traditional approaches that transform original video sequences into forms of visual feature vectors, tensor-based methods have been proposed for classifying video sequences with natural representation of original data. However, one obvious limitation of tensor-based methods is that the input video sequences are often required to be preprocessed with a unified length of time. In this paper, we propose a technique for handling classification of video sequences in unequal length of time, namely Spatial-Temporal Iterative Tensor Decomposition (S-TITD) for uniform length. The proposed framework contains two primary steps. We first represent original video sequences as a third-order tensor and perform Tucker-2 decomposition to obtain the reduced-dimension core tensor. Then we encode the third order of core tensor to a uniform length by adaptively selecting the most informative slices. Notably, the above two steps are embedded into a dynamic learning framework to guarantee the proposed method has the ability of updating results over time. We conduct a series of experiments on three public datasets in gesture and action recognition, and the experimental results show that the proposed S-TITD approach achieves better performances than the state-of-the-art algorithms.
C1 [Su, Yuting; Wang, Haiyi; Jing, Peiguang; Xu, Chuanzhong] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Jing, PG (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM ytsu@tju.edu.cn; wanghy890917@163.com; pgjing@tju.edu.cn;
   x18745950142@126.com
CR Phan AH, 2010, IEICE NONLINEAR THEO, V1, P37, DOI 10.1587/nolta.1.37
   [Anonymous], 2014, P INT ACM SIGIR WORK
   [Anonymous], 2006, KDD
   Bellini P, 2012, MULTIMED TOOLS APPL, V58, P41, DOI 10.1007/s11042-010-0684-y
   Cevikalp H, 2010, P IEEE C COMP VIS PA, P13
   Chen X, 2016, MULTIMED TOOLS APPL, V75, P6505, DOI 10.1007/s11042-015-2585-6
   Davis J., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P331
   Flórez F, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P318, DOI 10.1109/AFGR.2002.1004173
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi M. T., 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P433, DOI 10.1109/WACV.2012.6163005
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Hossain MB, 2015, LECT N BIOENG, P1, DOI 10.1007/978-981-287-540-2_1
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352
   Ishihara T, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P583, DOI 10.1109/AFGR.2004.1301596
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Lai ZH, 2013, IEEE T IMAGE PROCESS, V22, P3904, DOI 10.1109/TIP.2013.2264678
   Liu LM, 2009, IEEE T CIRC SYST VID, V19, P453, DOI 10.1109/TCSVT.2009.2017074
   Liu YA, 2009, MULTIMED TOOLS APPL, V41, P93, DOI 10.1007/s11042-008-0220-5
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Lui YM, 2012, IEEE T CIRC SYST VID, V22, P930, DOI 10.1109/TCSVT.2011.2181452
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Manresa C, 2005, ELECT LETT COMPUTER, V74, P2687
   Marcel S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P456, DOI 10.1109/AFGR.2000.840674
   Nie FP, 2009, PATTERN RECOGN, V42, P105, DOI 10.1016/j.patcog.2008.03.012
   Nie LQ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P591, DOI 10.1145/2733373.2806217
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Pan P, 2008, IEEE T CIRC SYST VID, V18, P1268, DOI 10.1109/TCSVT.2008.928889
   Pengyu Hong, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P410, DOI 10.1109/AFGR.2000.840667
   Rajko S., 2007, CVPR, P1
   Saisan P, 2001, PROC CVPR IEEE, P58
   Suk H.I., 2008, 8 IEEE INT C AUTOMAT, P1
   Tao J, 2006, P IEEE INT S CIRC SY
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yan R., 2004, PROC ACM INT C MULTI, P548
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T MULTIMEDIA, V17, P40, DOI 10.1109/TMM.2014.2370257
   Zhang W, 2009, PATTERN RECOGN, V42, P1941, DOI 10.1016/j.patcog.2009.01.010
   Zhang XQ, 2011, NEUROCOMPUTING, V74, P3277, DOI 10.1016/j.neucom.2011.05.006
NR 45
TC 7
Z9 8
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10635
EP 10652
DI 10.1007/s11042-015-3090-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400019
DA 2024-07-18
ER

PT J
AU AlShaikh, M
   Laouamer, L
   Nana, L
   Pascu, AC
AF AlShaikh, Muath
   Laouamer, Lamri
   Nana, Laurent
   Pascu, Anca Chrisitine
TI Efficient and robust encryption and watermarking technique based on a
   new chaotic map approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Chaotic map; OTP; Attacks; Robustness
ID SCHEME; RELIABILITY; IMAGES
AB We present a hybrid and robust encryption and watermarking algorithm based on a new chaotic map key generation method. The chaotic map uses a rule to generate the encryption key using an innovative approach. The main goal is to propose a hybrid scheme by applying a One Time Pad (OTP) encryption algorithm and a semi-blind watermarking approach to the host medical image. The encrypted watermark is embedded in the encrypted host image, directly in the spatial domain. The results obtained show perfect watermark extraction even after applying some attack scenarios. Using this approach, we conclude that our technique has a high robustness and a remarkable resistance against geometric, non-geometric and encryption attacks.
C1 [AlShaikh, Muath; Laouamer, Lamri; Nana, Laurent; Pascu, Anca Chrisitine] Univ Western Brittany, Lab STICC, UMR 6285, CNRS, 20 Ave Victor Le Gorgeu,BP 817 CS 93837, F-29238 Brest, France.
   [Laouamer, Lamri] Qassim Univ, Dept Management Informat Syst, CBE, POB 6633, Buraydah 51452, Saudi Arabia.
   [Pascu, Anca Chrisitine] Univ Western Brittany, Fac Letters, Brest CS 93837, F-29238 Brest, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Bretagne Occidentale; Qassim University; Universite de Bretagne
   Occidentale
RP AlShaikh, M (corresponding author), Univ Western Brittany, Lab STICC, UMR 6285, CNRS, 20 Ave Victor Le Gorgeu,BP 817 CS 93837, F-29238 Brest, France.
EM m_shai5@yahoo.com; laoamr@qu.edu.sa; Laurent.Nana@univ-brest.fr;
   Anca.Pascu@univ-brest.fr
OI AlShaikh, Muath/0000-0001-5550-7659
CR Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Akkas MA, WIREL PER COMMUN, P1
   [Anonymous], 2010, ARXIV PREPRINT ARXIV
   Avants BB, 2008, MED IMAGE ANAL, V12, P26, DOI 10.1016/j.media.2007.06.004
   Benhocine A., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P9
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Bouslimi D, 2012, COMPUT METH PROG BIO, V106, P47, DOI 10.1016/j.cmpb.2011.09.015
   Cao Dong, 2015, Applied Mechanics and Materials, V701-702, P1102, DOI 10.4028/www.scientific.net/AMM.701-702.1102
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Guo JT, 2015, J VIS COMMUN IMAGE R, V30, P125, DOI 10.1016/j.jvcir.2015.03.009
   Harrison Owen., 2007, AES ENCRYPTION IMPLE, P209
   Hina AD, 2015, CHAOS COMPLEXITY LEA, P163
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jingbing Li, 2012, Proceedings of the 2012 IEEE International Conference on Computer Science and Automation Engineering (CSAE 2012), P27, DOI 10.1109/CSAE.2012.6272541
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Laouamer Lamri, 2013, 2013 Science and Information Conference (SAI), P353
   Laouamer L, 2013, Life Science Journal, V10, P2591
   Leone L, 2015, CHEMISTRYOPEN, V9999
   Li J, 2012, ADV INF SCI SERV SCI, V4
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Peijia Zheng, 2013, Information Hiding. 14th International Conference, IH 2012 Revised Selected Papers, P240, DOI 10.1007/978-3-642-36373-3_16
   Petitcolas F., 2012, WATERMARKING STIRMAR
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Puentes J, 1998, IEEE T MED IMAGING, V17, P857, DOI 10.1109/42.746619
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Rubin Frank., 1996, Cryptologia, V20, P359
   Saharan B.S., 2014, Chinese Journal of Biology, V2014, P1, DOI DOI 10.1155/2014/802984
   SCHNEIER B, 1993, DR DOBBS J, V18, P50
   Sneyers R, 1997, ENVIRONMETRICS, V8, P517, DOI 10.1002/(SICI)1099-095X(199709/10)8:5<517::AID-ENV267>3.0.CO;2-L
   Subramanyam AV, 2012, IEEE T MULTIMEDIA, V14, P703, DOI 10.1109/TMM.2011.2181342
   Teh JS, 2015, NONLINEAR DYNAM, P1
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xia W, 2010, LECT NOTES COMPUT SC, V5916, P130, DOI 10.1007/978-3-642-11301-7_16
   Yap WS, 2015, NONLINEAR DYNAM, V80, P1483, DOI 10.1007/s11071-015-1956-x
   Yuen CH, 2011, APPL SOFT COMPUT, V11, P5092, DOI 10.1016/j.asoc.2011.05.050
   ZHAO G, 2010, 2010 2 INT C SIGN PR, V0002, P00002
NR 38
TC 15
Z9 15
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8937
EP 8950
DI 10.1007/s11042-016-3499-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800058
DA 2024-07-18
ER

PT J
AU Chen, Y
   Liu, GZ
   Yao, JC
AF Chen, Ying
   Liu, Guizhong
   Yao, Juncai
TI An improved 3D wavelet-based scalable video coding codec for MC-EZBC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable video coding; Motion-compensated temporal filtering;
   Hierarchical variable size block matching; Rate-distortion optimization;
   Lagrange multiplier; Overlapped block motion compensation
ID MOTION ESTIMATION; FRAMEWORK
AB With the rapid growth of modern multimedia applications, 3D wavelet-based scalable video coding (SVC) codec has received considerable attention lately because of its high coding performance and flexibility in bitstream scalability. It combines the motion-compensated temporal filtering (MCTF) together with the spatial decomposition to produce an embedded bitstream offering various levels of video quality over the heterogeneous networks. However, in the existing 3D wavelet-based SVC schemes, where the block types for block matching algorithms are limited, weighting matrices for block-wise motion compensation are fixed, and variations in activities of temporal subbands are not considered in the selection of the Lagrange multiplier for mode decision. In this paper, our major contribution is to provide some recent extensions to the well-known scalable subband/wavelet video codec Motion-Compensated Embedded Zero Block Coding (MC-EZBC) using three novel and content adaptive algorithms. Firstly, the enhanced hierarchical variable size block matching (Enhanced HVSBM) algorithm is proposed for the variable block size motion estimation. Then, the rate-distortion optimization (RDO) based adaptive Lagrange multiplier selection model for mode decision is presented. Finally, we introduce the adaptive weighting matrices design for overlapped block motion compensation (OBMC). Experimental results show that all the three proposed algorithms significantly improve the overall coding performance of MC-EZBC. Comparisons with other popular wavelet-based SVC codecs demonstrate the effectiveness of our improved codec in terms of both video quality assessment and computational complexity.
C1 [Chen, Ying; Liu, Guizhong; Yao, Juncai] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Liu, GZ (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian, Peoples R China.
EM xachenying@stu.xjtu.edu.cn; liugz@xjtu.edu.cn
FU National Natural Science Foundation of China (NSFC) [61173110, 61301237]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) Projects No.61173110 and No.61301237. The authors would
   like to thank the editors and anonymous reviewers for their constructive
   and insightful comments to this paper. They would also like to thank the
   experts for their valuable contributions toward the successful
   completion of these important video coding standards and fruitful
   discussions. In particular, the authors also appreciate the research
   group at RWTH Aachen University and the CIPR lab at RPI for providing
   the source codes of their latest MC-EZBC coding scheme for academic and
   research usage.
CR Adami N, 2007, IEEE T CIRC SYST VID, V17, P1238, DOI 10.1109/TCSVT.2007.906828
   Amel A. M., 2010, J TELECOMMUN, V2, P54
   Andreopoulos Y, 2005, IEEE T SIGNAL PROCES, V53, P1398, DOI 10.1109/TSP.2005.843707
   [Anonymous], 2005, THESIS
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Ben Fradj B, 2014, MULTIMED TOOLS APPL, V69, P1089, DOI 10.1007/s11042-012-1170-5
   Cai XX, 2012, INT CONF SIGN PROCES, P1047, DOI 10.1109/ICoSP.2012.6491758
   Chen J, 2005, P SPIE VISUAL COMMUN, V5960, P1
   Chen P, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P81
   Chen PS, 2004, IEEE T CIRC SYST VID, V14, P1183, DOI 10.1109/TCSVT.2004.833165
   Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Devore J.L., 2013, APPL STAT ENG SCI
   Dufaux F, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P275, DOI 10.1109/ICIP.2000.899354
   Golwelkar A, 2007, IEEE T CIRC SYST VID, V17, P417, DOI 10.1109/TCSVT.2007.893834
   Hanke K, 2003, P SOC PHOTO-OPT INS, V5022, P933, DOI 10.1117/12.476614
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hsiang ST, 2004, IEEE T IMAGE PROCESS, V13, P1018, DOI 10.1109/TIP.2004.828421
   Hsiang ST, 2001, SIGNAL PROCESS-IMAGE, V16, P705, DOI 10.1016/S0923-5965(01)00002-9
   Hsiang ST, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL III, P662, DOI 10.1109/ISCAS.2000.856147
   Huang TY, 2014, INT SYM COMPUT INTEL, P365, DOI 10.1109/ISCID.2014.77
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Kao MP, 2008, THESIS
   Karlsson G., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1100, DOI 10.1109/ICASSP.1988.196787
   Li X, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P364
   Li X, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P1
   González-de-Suso JL, 2014, IEEE T CIRC SYST VID, V24, P452, DOI 10.1109/TCSVT.2013.2276857
   Marzougui M., 2013, 10 IEEE INT MULT SYS, P1, DOI DOI 10.1109/SSD.2013.6564020
   OHM JR, 1994, IEEE T IMAGE PROCESS, V3, P559, DOI 10.1109/83.334985
   Omidyeganeh M, 2013, MULTIMED TOOLS APPL, V65, P441, DOI 10.1007/s11042-012-1012-5
   ORCHARD MT, 1994, IEEE T IMAGE PROCESS, V3, P693, DOI 10.1109/83.334974
   Peker KA, 2004, J VIS COMMUN IMAGE R, V15, P265, DOI 10.1016/j.jvcir.2004.04.007
   Peker KA, 2001, P SOC PHOTO-OPT INS, V4315, P341, DOI 10.1117/12.410944
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Spiteri T, 2012, IET IMAGE PROCESS, V6, P1319, DOI 10.1049/iet-ipr.2012.0048
   Su JK, 2000, IEEE T IMAGE PROCESS, V9, P1509, DOI 10.1109/83.862628
   TAUBMAN D, 1994, IEEE T IMAGE PROCESS, V3, P572, DOI 10.1109/83.334984
   Tsai SS, 2004, SIGNAL PROCESS-IMAGE, V19, P675, DOI 10.1016/j.image.2004.05.008
   Wan SA, 2009, SIGNAL PROCESS-IMAGE, V24, P730, DOI 10.1016/j.image.2009.05.001
   Wang MS, 2006, IEEE T SIGNAL PROCES, V54, P3505, DOI 10.1109/TSP.2006.879273
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wien M, 2004, ISOIECJTCISC29WG11MP
   Woods JW, 2010, U. S. Patent, Patent No. [7,653,133 B2, 7653133]
   Wu YJ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P129
   Wu YJ, 2008, IEEE T CIRC SYST VID, V18, P1432, DOI 10.1109/TCSVT.2008.927003
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
NR 46
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7595
EP 7632
DI 10.1007/s11042-016-3387-1
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800002
DA 2024-07-18
ER

PT J
AU He, JH
   Lan, WQ
   Tang, SH
AF He, Junhui
   Lan, Weiqiang
   Tang, Shaohua
TI A secure image sharing scheme with high quality stego-images based on
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image sharing; Steganography; LOCO-I compression; Message authentication
   code; Dynamic embedding
ID SECRET; AUTHENTICATION
AB Image sharing can be utilized to protect important commercial, military or private images against a single point of failure. Many existing image sharing schemes may have one or more of the security weaknesses as follows: First, noise-like image shares may easily arouse the attackers' attention; Second, cheating in the recovery of the secret image cannot be prevented effectively; Third, the requisite size of cover images may be very large; Finally, poor quality of the stego-images may lessen camouflage effects. In this paper, a novel secure image sharing scheme with high quality stego-images is proposed. With the use of LOCO-I compression as a preprocessing approach, the statistical correlations between neighboring pixels of a secret image drop significantly, which may greatly enhance the visual security of the proposed scheme. And the necessary size of cover images is reduced. Moreover, the PSNR values of stego-images are much higher than the related works. In order to detect three kinds of deception during secret image reconstruction, the hash-based message authentication codes of an image share, the value of argument x and the identity ID of a participant are embedded into a cover image together with the image share. In addition, the application of dynamic embedding with a random strategy further enhance the security of our scheme.
C1 [He, Junhui; Lan, Weiqiang; Tang, Shaohua] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou Higher Educ Mega Ctr, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology
RP He, JH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou Higher Educ Mega Ctr, Guangzhou 510006, Guangdong, Peoples R China.
EM hejh@scut.edu.cn; lwq@mail.scut.edu.cn; csshtang@scut.edu.cn
OI He, Junhui/0000-0002-1689-0509
FU 973 Program [2014CB360501]; National Natural Science Foundation of China
   [U1135004, 61170080]; Guangdong Provincial Natural Science Foundation
   [2014A030308006]; Guangdong Province Universities and Colleges Pearl
   River Scholar Funded Scheme
FX The authors thank the anonymous reviewers for their insightful comments
   and suggestions. This work was partially supported by the 973 Program
   (No. 2014CB360501), the National Natural Science Foundation of China
   (No. U1135004 and No. 61170080), Guangdong Provincial Natural Science
   Foundation (No. 2014A030308006), and Guangdong Province Universities and
   Colleges Pearl River Scholar Funded Scheme (2011).
CR Alvarez G, 2008, INFORM SCIENCES, V178, P4382, DOI 10.1016/j.ins.2008.07.010
   [Anonymous], 1979, P AFIPS NAT COMP C N
   [Anonymous], 1 INT C PERV COMP SI
   [Anonymous], 2014, J INFORM HIDING MULT
   Chan CS, 2012, INT J INNOV COMPUT I, V8, P375
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Chen C.R. J., 2015, MULTIMED TOOLS APPL, P1
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Hsieh SL, 2011, MULTIMED TOOLS APPL, V52, P597, DOI 10.1007/s11042-010-0520-4
   Islam N, 2011, OPT COMMUN, V284, P4412, DOI 10.1016/j.optcom.2011.05.079
   Jin J, 2012, OPT LASER TECHNOL, V44, P538, DOI 10.1016/j.optlastec.2011.08.023
   Khosravi MJ, 2014, MULTIMEDIA SYST, V20, P215, DOI 10.1007/s00530-013-0341-1
   Lee CW, 2012, IEEE T IMAGE PROCESS, V21, P207, DOI 10.1109/TIP.2011.2159984
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2011, IET INFORM SECUR, V5, P81, DOI 10.1049/iet-ifs.2008.0043
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Ulutas G, 2013, PATTERN RECOGN LETT, V34, P283, DOI 10.1016/j.patrec.2012.10.017
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu CC, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1177, DOI 10.1109/IIH-MSP.2008.317
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yuan HD, 2014, INFORM SCIENCES, V254, P197, DOI 10.1016/j.ins.2013.08.012
NR 28
TC 26
Z9 26
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 7677
EP 7698
DI 10.1007/s11042-016-3429-8
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800005
DA 2024-07-18
ER

PT J
AU Shao, CB
   Song, XN
   Shu, X
   Wu, XJ
AF Shao, Changbin
   Song, Xiaoning
   Shu, Xin
   Wu, Xiao-Jun
TI Converted-face identification: using synthesized images to replace
   original images for recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data uncertainty; Mirror image; Virtual image; Representation-based
   classification; Subspace learning; Face recognition
ID SINGLE TRAINING IMAGE; SPARSE REPRESENTATION; EIGENFACES; SYMMETRY;
   ROBUST
AB The changes in appearance of faces, usually caused by pose, expression and illumination variations, increase data uncertainty in the task of face recognition. Insufficient training samples cannot provide abundant multi-view observations of a face. To address this issue, many pioneering works focus on generating virtual training images for better recognition performance. However, the issue also exists in a test set where a test image only conveys a split-second representation of a face and cannot cover more comprehensive features. In this paper, we propose a new face synthesis method for face recognition. In the proposed pipeline, we synthesize a virtual image using both the original image and its corresponding mirror one. Note that, we apply this technique both to the training and test sets. Then we use the newly generated training and test images to replace the original ones for face recognition. The aim is to increase the similarity between a test image and its corresponding intra-class training images. This proposed method is effective and computationally efficient. In order to verify this, we tested our system using multiple face recognition methods in terms of the recognition accuracy, based on either the synthesized images or original images. The methods used in the paper include statistical subspace learning algorithms and representation-based classification approaches. Experimental results obtained on FERET, ORL, GT, PIE and LFW show that the proposed approach improves the face recognition accuracy, especially on faces with left-right pose variations.
C1 [Shao, Changbin; Shu, Xin] Jiangsu Univ Sci & Technol, Sch Comp Sci & Engn, Zhenjiang 212003, Peoples R China.
   [Song, Xiaoning; Wu, Xiao-Jun] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Peoples R China.
   [Song, Xiaoning] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 Jiangsu University of Science & Technology; Jiangnan University;
   University of Surrey
RP Song, XN (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Peoples R China.; Song, XN (corresponding author), Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
EM xnsong@hotmail.com
FU Natural Science Foundation of China [61373055]; Natural Science
   Foundation of Jiangsu Province [BK2012700, BK20130473]; Foundation of
   Artificial Intelligence Key Laboratory of Sichuan Province [2012RZY02];
   Open Project Program of the State Key Lab of CAD&CG of Zhejiang
   University [A1418]; Fundamental Research Funds for the Central
   Universities [JUSRP115A29, JUSRP51410B]
FX The authors would like to thank the anonymous reviewers for their
   constructive suggestions. This work was supported by the Natural Science
   Foundation of China (Grant no. 61373055), the Natural Science Foundation
   of Jiangsu Province (Grant nos. BK2012700, BK20130473), the Foundation
   of Artificial Intelligence Key Laboratory of Sichuan Province (Grant no.
   2012RZY02), the Open Project Program of the State Key Lab of CAD&CG of
   Zhejiang University (Grant no. A1418) and the Fundamental Research Funds
   for the Central Universities (Grant No. JUSRP115A29, JUSRP51410B).
CR [Anonymous], P ICCV
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BEYMER D, 1995, P 5 INT C COMP VIS
   Deng WH, 2010, PATTERN RECOGN, V43, P1748, DOI 10.1016/j.patcog.2009.12.004
   EKMAN P, 1981, PSYCHOPHYSIOLOGY, V18, P101, DOI 10.1111/j.1469-8986.1981.tb02919.x
   Jian M, 2011, P AS PAC SIGN INF PR
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Meng Y, 2012, IEEE T IMAGE PROCESS
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Saad E-SM, 2006, J COMPUT SCI TECHNOL, V6
   Saber E, 1998, PATTERN RECOGN LETT, V19, P669, DOI 10.1016/S0167-8655(98)00044-0
   Saha S., 2007, P IEEE WIE NAT S EM
   Sharma A, 2010, NEUROCOMPUTING, V73, P1868, DOI 10.1016/j.neucom.2009.10.027
   Sugiyama M, 2007, J MACH LEARN RES, V8, P1027
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tang DY, 2014, NEURAL COMPUT APPL, V24, P513, DOI 10.1007/s00521-012-1252-3
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vetter T, 1998, INT J COMPUT VISION, V28, P103, DOI 10.1023/A:1008058932445
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2006, PATTERN RECOGN, V39, P1026, DOI 10.1016/j.patcog.2005.10.029
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1950, DOI 10.1109/TCYB.2014.2300175
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Xu Y, 2014, NEUROCOMPUTING, V131, P191, DOI 10.1016/j.neucom.2013.10.025
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yong Xu, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.234
   Zhang T, 2014, OPTIK, V125, P5017, DOI 10.1016/j.ijleo.2014.01.171
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 33
TC 7
Z9 7
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6641
EP 6661
DI 10.1007/s11042-016-3349-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400025
DA 2024-07-18
ER

PT J
AU Sun, YX
   Wen, GH
AF Sun, Yaxin
   Wen, Guihua
TI Ensemble softmax regression model for speech emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Softmax regression; Ensemble learning;
   Ensemble Softmax regression
ID CLASSIFICATION; CLASSIFIERS; INFORMATION
AB Automatic emotion recognition from speech signals is one of the important research areas. Most speech emotion recognition methods have been proposed, among which ensemble learning is an effective way. However, they are still confronted with problems, such as the curse of dimensionality and the diversity of the base classifiers hardly ensured. To overcome the problems, this paper proposes an ensemble Softmax regression model for speech emotion recognition (ESSER). It applies the feature extraction methods with much different principles to generate the subspaces for the base classifier, so that the diversity of the base classifiers could be ensured. Furthermore, a feature selection method that selects features according to global structure of the data is used to reduce the dimension of subspaces, which can further increase the diversity of the base classifiers and overcome the curse of dimensionality. As in the case of the diversity of the base classifiers ensured, the performance of ensemble classifier highly depends on the ability of the base classifier, it is reasonable for ESSER to select Softmax as the base classifier as Softmax has shown its superiority in speech emotion recognition. The conducted experiments validate the proposed approach in term of the performance of speech emotion recognition.
C1 [Sun, Yaxin] Jiaxing Univ, Jiaxing 314001, Peoples R China.
   [Wen, Guihua] South China Univ Technol, Guangzhou 510006, Guangdong, Peoples R China.
C3 Jiaxing University; South China University of Technology
RP Sun, YX (corresponding author), Jiaxing Univ, Jiaxing 314001, Peoples R China.
EM sunyaxin2005@163.com; crghwen@scut.edu.cn
FU China National Science Foundation [60973083, 61273363]; State Key
   Laboratory of Brain and Cognitive Science [08B12]
FX This work was supported by China National Science Foundation under
   Grants 60973083, 61273363, State Key Laboratory of Brain and Cognitive
   Science under grants 08B12.
CR [Anonymous], PLP RASTA MATLAB HTT
   [Anonymous], P INTERSPEECH
   [Anonymous], 2001, TECHNICAL REPORT
   [Anonymous], P IEEE INT C MULT EX
   [Anonymous], 2014, P 2014 INT C INFORMA
   [Anonymous], 2013, P IET INT SIGN PROC
   [Anonymous], COMPUT SPEE IN PRESS
   [Anonymous], P INT C AC SPEECH SI
   [Anonymous], P INTERSPEECH
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2009, Automatic Classification of Emotion-Related User States in Spontaneous Children's Speech
   Attabi Y, 2013, IEEE T AFFECT COMPUT, V4, P280, DOI 10.1109/T-AFFC.2013.17
   Brown G, 2012, J MACH LEARN RES, V13, P27
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Cai D., 2010, KDD, P333
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Danisman T, 2008, LECT NOTES ARTIF INT, V5078, P205, DOI 10.1007/978-3-540-69369-7_23
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Haq S., 2009, INT C AUDITORY VISUA, P53
   Hassan A, 2012, SPEECH COMMUN, V54, P903, DOI 10.1016/j.specom.2012.03.003
   Hassan A, 2013, IEEE T AUDIO SPEECH, V21, P1458, DOI 10.1109/TASL.2013.2255278
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hermansky H., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P121, DOI 10.1109/ICASSP.1992.225957
   Huang DY, 2014, COMPUT SPEECH LANG, V28, P392, DOI 10.1016/j.csl.2013.06.002
   Huang Y, 2009, PROC CHINESE C PATTE, P1
   Lee CC, 2011, SPEECH COMMUN, V53, P1162, DOI 10.1016/j.specom.2011.06.004
   Mariooryad S, 2014, SPEECH COMMUN, V57, P1, DOI 10.1016/j.specom.2013.07.011
   Milton A, 2014, COMPUT SPEECH LANG, V28, P727, DOI 10.1016/j.csl.2013.08.004
   Morrison D, 2007, J NETW COMPUT APPL, V30, P1356, DOI 10.1016/j.jnca.2006.09.005
   Morrison D, 2007, SPEECH COMMUN, V49, P98, DOI 10.1016/j.specom.2006.11.004
   NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.1090/S0025-5718-1980-0572855-7
   Ntalampiras S, 2012, IEEE T AFFECT COMPUT, V3, P116, DOI 10.1109/T-AFFC.2011.31
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Park JS, 2009, IEEE T CONSUM ELECTR, V55, P1590, DOI 10.1109/TCE.2009.5278031
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qian Y, 2013, PROCEEDINGS 2012 INTERNATIONAL FEDERATION OF LANDSCAPE ARCHITECTS ASIA-PACIFIC REGION ANNUAL CONFERENCE (IFLA APRC 2012), P1
   Rozgic V., 2012, P 2012 AS PAC SIGN I, P1
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798
   Schuller B, 2010, IEEE T AFFECT COMPUT, V1, P119, DOI 10.1109/T-AFFC.2010.8
   van der Wal CN, 2013, APPL INTELL, V39, P675, DOI 10.1007/s10489-013-0449-1
   Vlasenko B, 2014, COMPUT SPEECH LANG, V28, P483, DOI 10.1016/j.csl.2012.11.003
   Wagner J, 2011, IEEE T AFFECT COMPUT, V2, P206, DOI 10.1109/T-AFFC.2011.12
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Yuanlu Kuang, 2013, 2013 IEEE 4th International Conference on Software Engineering and Service Science (ICSESS), P795, DOI 10.1109/ICSESS.2013.6615425
   Zhao XM, 2014, NEURAL COMPUT APPL, V24, P1539, DOI 10.1007/s00521-013-1377-z
   Zheng WM, 2014, IEEE SIGNAL PROC LET, V21, P569, DOI 10.1109/LSP.2014.2308954
NR 48
TC 31
Z9 32
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8305
EP 8328
DI 10.1007/s11042-016-3487-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800031
DA 2024-07-18
ER

PT J
AU Yuan, HM
   Liu, Y
   Gong, LH
   Wang, J
AF Yuan, Hong-Mei
   Liu, Ye
   Gong, Li-Hua
   Wang, Jun
TI A new image cryptosystem based on 2D hyper-chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Confusion; Diffusion; 2D hyper-chaotic system
ID IMPROVED HYPERCHAOTIC SEQUENCES; FRACTIONAL FOURIER-TRANSFORM;
   ENCRYPTION ALGORITHM; LOGISTIC MAPS; SCHEME
AB An efficient image encryption scheme is designed based on 2D hyper-chaotic system. Different from the traditional chaos-based image encryption schemes, the confusion and the diffusion procedures of the proposed scheme are interacted on each other. In the encryption process, the position of the present pixel is influenced by the last diffused one. Then the corresponding diffused pixel makes a difference in the next pixel. By contrast with the traditional chaos-based image cryptosystems, the proposed cryptosystem with the interacted structure is steadier and harder to decipher. In addition, 2D hyper-chaotic systems are employed in the quicker generation of chaotic sequences in comparison to high-dimensional hyper-chaotic systems. Simulation results verify the security and effectiveness of this scheme.
C1 [Yuan, Hong-Mei; Liu, Ye; Gong, Li-Hua; Wang, Jun] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University
RP Liu, Y (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM liuye@ncu.edu.cn
RI Jiang, Cheng/JHU-0179-2023; Yuan, Hong-Mei/HLQ-0484-2023
OI Yuan, Hong-Mei/0000-0002-5787-0483
FU National Natural Science Foundation of China [61462061, 61262084];
   Foundation for Young Scientists of Jiangxi Province (Jinggang Star)
   [20122BCB23002]; Natural Science Foundation of Jiangxi Province, China
   [20151BAB207002]; Innovation Fund for graduates of Nanchang University
   [cx2015139]
FX This work is supported by the National Natural Science Foundation of
   China (grant nos. 61462061 and 61262084), the Foundation for Young
   Scientists of Jiangxi Province (Jinggang Star) (grant no.
   20122BCB23002), the Natural Science Foundation of Jiangxi Province,
   China (grant no. 20151BAB207002) and the Innovation Fund for graduates
   of Nanchang University (grant no. cx2015139).
CR [Anonymous], 2015, BIOMED RES INT
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2014, NONLINEAR DYNAM, V77, P1191, DOI 10.1007/s11071-014-1370-9
   Eslami Z, 2013, OPT COMMUN, V286, P51, DOI 10.1016/j.optcom.2012.07.052
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hermassi H, 2013, TELECOMMUN SYST, V52, P539, DOI 10.1007/s11235-011-9459-7
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Liu Y, MULTIMED TOOLS APPL, P1
   LIU Y, 2015, J NANOMATER, V2015, P1, DOI DOI 10.1007/S11042-015-2479-7
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Nag Amitava, 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P309, DOI 10.1109/ICSCCN.2011.6024565
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Özkaynak F, 2012, OPT COMMUN, V285, P4946, DOI 10.1016/j.optcom.2012.07.106
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Shen CW, 2014, IEEE T CIRCUITS-I, V61, P2380, DOI 10.1109/TCSI.2014.2304655
   Sui LS, 2015, OPT COMMUN, V343, P140, DOI 10.1016/j.optcom.2015.01.021
   Sui LS, 2014, OPT LASER ENG, V62, P139, DOI 10.1016/j.optlaseng.2014.06.003
   Tong XJ, 2015, OPTIK INT J LIGHT EL
   Wang JZ, 2014, NONLINEAR DYNAM, V78, P2517, DOI 10.1007/s11071-014-1607-7
   Ye GD, 2013, NONLINEAR DYNAM, V71, P259, DOI 10.1007/s11071-012-0658-x
   Ye RS, 2011, OPT COMMUN, V284, P5290, DOI 10.1016/j.optcom.2011.07.070
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
   Zhang XP, 2014, NONLINEAR DYNAM, V78, P359, DOI 10.1007/s11071-014-1445-7
   Zhang XP, 2014, NONLINEAR DYNAM, V75, P319, DOI 10.1007/s11071-013-1068-4
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou NR, 2011, OPT COMMUN, V284, P2789, DOI 10.1016/j.optcom.2011.02.066
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu HG, 2013, SIGNAL PROCESS-IMAGE, V28, P670, DOI 10.1016/j.image.2013.02.004
NR 33
TC 24
Z9 24
U1 1
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8087
EP 8108
DI 10.1007/s11042-016-3454-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800022
DA 2024-07-18
ER

PT J
AU Castrillón-Santana, M
   Lorenzo-Navarro, J
   Ramón-Balmaseda, E
AF Castrillon-Santana, M.
   Lorenzo-Navarro, J.
   Ramon-Balmaseda, E.
TI Multi-scale score level fusion of local descriptors for gender
   classification in the wild
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soft biometrics; Gender classification; Local descriptors; Score level
   fusion; CNN
ID BINARY PATTERNS; RECOGNITION; INFORMATION; FEATURES; REVEAL
AB The 2015 FRVT gender classification (GC) report evidences the problems that current approaches tackle in situations with large variations in pose, illumination, background and facial expression. The report suggests that both commercial and research solutions are hardly able to reach an accuracy over 90 % for The Images of Groups dataset, a proven scenario exhibiting unrestricted or in the wild conditions. In this paper, we focus on this challenging dataset, stepping forward in GC performance by observing: 1) recent literature results combining multiple local descriptors, and 2) the psychophysics evidences of the greater importance of the ocular and mouth areas to solve this task. We therefore make use of holistic and inner facial patches to extract features, that are later combined via a score level fusion strategy. The achieved results support the main information provided by the ocular and the mouth areas. Indeed, the combination of multiscale extracted features increases the overall accuracy to over 94 %, reducing notoriously the classification error if compared with tuned holistic and deep learning approaches.
C1 [Castrillon-Santana, M.; Lorenzo-Navarro, J.; Ramon-Balmaseda, E.] ULPGC, SIANI, Las Palmas Gran Canaria, Spain.
C3 Universidad de Las Palmas de Gran Canaria
RP Castrillón-Santana, M (corresponding author), ULPGC, SIANI, Las Palmas Gran Canaria, Spain.
EM modesto.castrillon@ulpgc.es
RI Castrillón-Santana, Modesto/C-6662-2008; Navarro, Javier
   Lorenzo/L-1972-2014
OI Castrillón-Santana, Modesto/0000-0002-8673-2725; Navarro, Javier
   Lorenzo/0000-0002-2834-2067
FU Spanish Ministry of Economy and Competitiveness [TIN2015 64395-R];
   Institute of Intelligent Systems and Numerical Applications in
   Engineering (SIANI); Computer Science Department at ULPGC
FX Work partially funded by the project TIN2015 64395-R from the Spanish
   Ministry of Economy and Competitiveness, the Institute of Intelligent
   Systems and Numerical Applications in Engineering (SIANI) and the
   Computer Science Department at ULPGC.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   [Anonymous], INT C BIOM ICB
   [Anonymous], IEEE S SERIES COMPUT
   [Anonymous], COMPONENT BASED FRAM
   [Anonymous], INT C IM PROC
   [Anonymous], 2012, Second Generation Biometrics: the Ethical, Legal and Social Context
   [Anonymous], DESCRIPTORS REGIONS
   [Anonymous], 18 INT C IM AN PROC
   [Anonymous], 8052 NIST IR
   [Anonymous], INT C PATT REC ICPR
   Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bekios-Calfa J, 2014, PATTERN RECOGN LETT, V36, P228, DOI 10.1016/j.patrec.2013.04.028
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Castrilln-Santana M., 2013, 18 IB C PATT REC CIA, V8259, P270, DOI DOI 10.1007/978-3-642-41827-3_34
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Castrillón-Santana M, 2015, LECT NOTES COMPUT SC, V9281, P43, DOI 10.1007/978-3-319-23222-5_6
   Chen HZ, 2014, IEEE T PATTERN ANAL, V36, P1860, DOI 10.1109/TPAMI.2014.2302443
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Dago-Casas P., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2152, DOI 10.1109/ICCVW.2011.6130514
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   El Shafey Laurent., 2014, Ieee international joint conference on biometrics (ijcb), P1
   Erdogmus N, 2014, 2014 IEEE 16 INT WOR, P1
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9
   Han H, 2014, AGE GENDER RACE ESTI
   Huang G.B., 2008, PROC WORKSHOP FACES
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jia S, 2015, PATTERN RECOGN LETT, V58, P35, DOI 10.1016/j.patrec.2015.02.006
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Ludwig 0., 2009, 12 INT IEEE C INTELL, P1
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Nixon MS, 2015, PATTERN RECOGN LETT, V68, P218, DOI 10.1016/j.patrec.2015.08.006
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ren HY, 2014, INT C PATT RECOG, P2389, DOI 10.1109/ICPR.2014.414
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   Vapnik V., 1999, NATURE STAT LEARNING
   Zhang H, 2015, COMPUT VIS IMAGE UND, V137, P50, DOI 10.1016/j.cviu.2015.03.003
NR 48
TC 10
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4695
EP 4711
DI 10.1007/s11042-016-3653-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500003
DA 2024-07-18
ER

PT J
AU Kane, L
   Khanna, P
AF Kane, Lalit
   Khanna, Pritee
TI Real-time recognition of medial structures within hand postures through
   Eigen-space and geometric skeletal shape features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeletonization; Hand posture recognition; Principal component vector;
   Polar normalization
ID EXACT MATCH RETRIEVAL; INVARIANT SCHEME; SYMBOLIC IMAGES; POSE;
   REPRESENTATION; TRACKING
AB Skeletons provide landmark points that preserve implicit strokes or medial structure within a shape for compact representation. Though, hand posture shapes are usually recognized by region or contour representations, some applications may only be interested in the recognition of medial structures within the postures rather than their exact outlines and regions. Proposed work identifies several unique medial structures formed by a set of both one and two-handed postures and demonstrates their pure skeletal recognition in real-time. Existing skeleton-based recognition schemes apply the complex segmental processing on underlying skeleton and rely on contour information which is not suitable for fast recognition of medial structures. Presented work applies intuitive Eigen-space based Principal Components of Symbolic Structure (PCSS) and geometric Equi-Polar Signature (EPS) features to accomplish the recognition task. Both PCV and EPS process the skeleton globally without sections without associating contour information. Recognition accuracy up to 94% is obtained on a 22 posture dataset comprising of 10,560 depth frames with 480 samples for each posture. Depth sensor based acquisition is employed to meet the real-time requirements.
C1 [Kane, Lalit; Khanna, Pritee] PDPM Indian Inst Informat Technol Design & Mfg, Discipline Comp Sci & Engn, Jabalpur, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Khanna, P (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Discipline Comp Sci & Engn, Jabalpur, India.
EM pkhanna@iiitdmj.ac.in
RI Khanna, Pritee/V-5418-2019; Kane, Lalit/IRY-9134-2023; Kane,
   Lalit/M-6819-2018
OI Khanna, Pritee/0000-0003-0518-2133; Kane, Lalit/0009-0006-5621-5969;
   Kane, Lalit/0000-0002-7305-1189
CR [Anonymous], INT J COMPUTER VISIO
   [Anonymous], INT J COMPUT APPL
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Barkoky Alaa, 2011, 2011 International Conference on Multimedia Technology, P6548
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bourennane S, 2012, SIGNAL IMAGE VIDEO P, V6, P147, DOI 10.1007/s11760-010-0176-6
   CHANG CC, 1995, PATTERN RECOGN LETT, V16, P465, DOI 10.1016/0167-8655(95)00002-X
   Chen C., 2016, P 25 INT JOINT C ART, P3331
   Cobos Guzman S, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2246, DOI 10.1109/IROS.2008.4651053
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Donggang Yu, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P118, DOI 10.1109/CGIV.2010.26
   El-Khoury S, 2013, ROBOT AUTON SYST, V61, P1335, DOI 10.1016/j.robot.2013.08.002
   Fujimura K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P381
   Goh WB, 2008, COMPUT VIS IMAGE UND, V110, P326, DOI 10.1016/j.cviu.2007.09.013
   Gonzalez RC, 2012, Digital image process- ing
   Guru DS, 2004, PATTERN RECOGN LETT, V25, P73, DOI 10.1016/j.patrec.2003.09.003
   Guru DS, 2003, PATTERN RECOGN LETT, V24, P2397, DOI 10.1016/S0167-8655(03)00069-2
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Jiang M, 2015, SIGNAL PROCESS-IMAGE, V33, P29, DOI 10.1016/j.image.2015.02.004
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   Kirac F, 2014, PATTERN RECOGN LETT, V50, P91, DOI 10.1016/j.patrec.2013.09.003
   Krinidis S, 2014, PATTERN ANAL APPL, V17, P517, DOI 10.1007/s10044-013-0327-9
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Lee AJT, 2003, PATTERN RECOGN LETT, V24, P3015, DOI 10.1016/S0167-8655(03)00162-4
   Liu LW, 2012, INT C PATT RECOG, P565
   Ma J, 2014, COMPUT AIDED DESIGN, V46, P221, DOI 10.1016/j.cad.2013.08.036
   Pedersoli F, 2014, VISUAL COMPUT, V30, P1107, DOI 10.1007/s00371-014-0921-x
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145
   Rempel D, 2014, INT J HUM-COMPUT ST, V72, P728, DOI 10.1016/j.ijhcs.2014.05.003
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Roberts L, 2011, IEEE ENG MED BIO, P2929, DOI 10.1109/IEMBS.2011.6090806
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sebastian TB, 2005, SIGNAL PROCESS, V85, P247, DOI 10.1016/j.sigpro.2004.10.016
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Soffer A., 1999, Database Semantics. Semantic Issues in Multimedia Systems. IFIP TC2/WG2.6 Eighth Working Conference on Database Semantics (DS-8), P435
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Su ZW, 2011, PATTERN ANAL APPL, V14, P77, DOI 10.1007/s10044-009-0166-x
   Suau X, 2014, IMAGE VISION COMPUT, V32, P522, DOI 10.1016/j.imavis.2014.04.015
   Tang DH, 2013, IEEE I CONF COMP VIS, P3224, DOI 10.1109/ICCV.2013.400
   Torsello A, 2003, LECT NOTES COMPUT SC, V2749, P200
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang X, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P99, DOI 10.1109/CISP.2014.7003757
   Wang X, 2013, VISUAL COMPUT, V29, P545, DOI 10.1007/s00371-013-0817-1
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xianghua Li, 2011, 2011 International Conference on Multimedia Technology, P3077
   Xie J, 2008, PATTERN RECOGN, V41, P1756, DOI 10.1016/j.patcog.2007.11.005
   Xie SS, 2012, IEEE IMAGE PROC, P529, DOI 10.1109/ICIP.2012.6466913
   Yu MY, 2016, IEEE T PATTERN ANAL, V38, P1651, DOI 10.1109/TPAMI.2015.2491925
   Zhang BC, 2015, PROC CVPR IEEE, P4557, DOI 10.1109/CVPR.2015.7299086
   ZHANG TY, 1984, COMMUN ACM, V27, P236, DOI 10.1145/357994.358023
NR 53
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4571
EP 4598
DI 10.1007/s11042-016-4173-9
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200067
DA 2024-07-18
ER

PT J
AU Liu, BD
   Gui, LK
   Wang, YT
   Wang, YX
   Shen, B
   Li, X
   Wang, YJ
AF Liu, Bao-Di
   Gui, Liangke
   Wang, Yuting
   Wang, Yu-Xiong
   Shen, Bin
   Li, Xue
   Wang, Yan-Jiang
TI Class specific centralized dictionary learning for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Centralized dictionary learning; Face recognition; Class specific
ID SPARSE REPRESENTATION; IMAGE; EIGENFACES
AB Sparse representation based classification (SRC) and collaborative representation based classification (CRC) have demonstrated impressive performance for visual recognition. SRC and CRC assume that the training samples in each class contribute equally to the dictionary and thus generate the dictionary that consists of the training samples in the corresponding class. This may lead to high residual error and instability, to the detriment of recognition performance. One solution is to use the class specific dictionary learning (CSDL) algorithm, which has greatly improved the classification accuracy. However, the CSDL algorithm fails to consider the constraints to sparse codes. In particular, it cannot guarantee that the sparse codes in the same class will be concentrated based on the learned dictionary for each class. Such concentration is actually beneficial to classification. To address these limitations, in this paper, we propose a class specific centralized dictionary learning (CSCDL) algorithm to simultaneously consider the desired characteristics for both dictionary and sparse codes. The blockwise coordinate descent algorithm and Lagrange multipliers are used to optimize the corresponding objective function. Extensive experimental results on face recognition benchmark datasets demonstrate the superior performance of our CSCDL algorithm compared with conventional approaches.
C1 [Liu, Bao-Di; Wang, Yan-Jiang] China Univ Petr, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
   [Gui, Liangke; Wang, Yu-Xiong] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
   [Shen, Bin] Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
   [Li, Xue] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Wang, Yuting] Karlsruhe Inst Technol, Dept Informat, D-76131 Karlsruhe, Germany.
C3 China University of Petroleum; Carnegie Mellon University; Purdue
   University System; Purdue University; Tsinghua University; Helmholtz
   Association; Karlsruhe Institute of Technology
RP Liu, BD (corresponding author), China Univ Petr, Coll Informat & Control Engn, Qingdao 266580, Peoples R China.
EM thu.liubaodi@gmail.com; liangkeg@cs.cmu.edu; utdyc@student.kit.edu;
   yuxiongw@cs.cmu.edu; bshen@purdue.edu; lixue421@gmail.com;
   yjwang@upc.edu.cn
RI Chen, Zheng/KCY-2338-2024
FU National Natural Science Foundation of China [61402535, 61271407];
   Natural Science Foundation for Youths of Shandong Province, China
   [ZR2014FQ001]; Qingdao Science and Technology Project [14-2-4-111-jch];
   Fundamental Research Funds for the Central Universities, China
   University of Petroleum (East China) [14CX02169A]; National Natural
   Science Foundation of China [61402535, 61271407]; Natural Science
   Foundation for Youths of Shandong Province, China [ZR2014FQ001]; Qingdao
   Science and Technology Project [14-2-4-111-jch]; Fundamental Research
   Funds for the Central Universities, China University of Petroleum (East
   China) [14CX02169A]
FX This paper is supported partly by the National Natural Science
   Foundation of China (Grant No. 61402535, No. 61271407), the Natural
   Science Foundation for Youths of Shandong Province, China (Grant No.
   ZR2014FQ001), Qingdao Science and Technology Project (No.
   14-2-4-111-jch), and the Fundamental Research Funds for the Central
   Universities, China University of Petroleum (East China) (Grant No.
   14CX02169A).
CR [Anonymous], 2006, ADV NEURAL INF PROCE
   [Anonymous], P 30 AAAI
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benavente R, 1998, 24 COMP VIS CTR
   Bertsekas D. P., 1999, NONLINEAR PROGRAMMIN
   Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   DUDA RO, 2001, PATTERN CLASSIFICATI, P373
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gao SH, 2014, IEEE T IMAGE PROCESS, V23, P623, DOI 10.1109/TIP.2013.2290593
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332
   Liu B-D, 2015, PROCEEDINGS OF THE 2
   Liu BD, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P229, DOI 10.1109/SPAC.2014.6982690
   Liu BD, 2014, LECT NOTES COMPUT SC, V8690, P600, DOI 10.1007/978-3-319-10605-2_39
   Liu BD, 2014, INT CONF ACOUST SPEE
   Liu BD, 2013, PATTERN RECOGN, V46, P1879, DOI 10.1016/j.patcog.2012.11.018
   Liu BD, 2012, INT CONF ACOUST SPEE, P2193, DOI 10.1109/ICASSP.2012.6288348
   Mairal J., 2009, ADV NEURAL INFORM PR, P1033
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Sprechmann P, 2010, INT CONF ACOUST SPEE, P2042, DOI 10.1109/ICASSP.2010.5494985
   Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70
   Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Wang HR, 2012, PATTERN RECOGN, V45, P3902, DOI 10.1016/j.patcog.2012.04.024
   Wang YX, 2015, PROC CVPR IEEE, P1619, DOI 10.1109/CVPR.2015.7298770
   Wang YX, 2013, IEEE T KNOWL DATA EN, V25, P1336, DOI 10.1109/TKDE.2012.51
   Wang YX, 2012, INT CONF ACOUST SPEE, P3389, DOI 10.1109/ICASSP.2012.6288643
   Wang YX, 2011, IEEE IMAGE PROC, P3409, DOI 10.1109/ICIP.2011.6116443
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan Y, 2014, PATTERN RECOGN, V47, P3487, DOI 10.1016/j.patcog.2014.05.004
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang Q.Z.Q., 2010, PROC CVPR IEEE, DOI [10.1109/CVPR.2010.5539989, DOI 10.1109/CVPR.2010.5539989]
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
NR 39
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4159
EP 4177
DI 10.1007/s11042-015-3042-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200047
DA 2024-07-18
ER

PT J
AU Prandi, C
   Roccetti, M
   Salomoni, P
   Nisi, V
   Nunes, NJ
AF Prandi, Catia
   Roccetti, Marco
   Salomoni, Paola
   Nisi, Valentina
   Nunes, Nuno Jardim
TI Fighting exclusion: a multimedia mobile app with zombies and maps as a
   medium for civic engagement and design
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Urban accessibility; Crowdsourcing; Social inclusion; Gamification;
   Multimedia mobile app
AB This paper presents a study on urban data crowdsourcing driven by Geo-Zombie, a multimedia mobile application we designed and developed to engage pedestrians in taking note of urban architectural impediments and facilities by documenting them through pictures and multimedia data. Geo-Zombie aims at transforming the civic activity of contributing into a virtual gamified experience where players attempt to escape from horrific situations in which zombies are ready to cannibalize unsuspecting walkers. In some sense, walkers that kill zombies deeply reconnect with the concept of imminent danger which can be fought resorting to appropriate civic actions. To challenge our initial hypotheses we conducted a design process, starting with a concept generation where three different concepts were discussed which gave rise to five different multimedia mobile apps including the one with zombies. Then, focus group, experience prototyping, application design and implementation, and finally field trials were exploited to refine the design and to select the best apps out of the five that better responded to the need of involving common people in collecting urban accessibility data. It is worth noting that the experiences of use with 50 avid walkers have demonstrated that a multimedia mobile app with maps and zombies can be a concrete step towards a social inclusion strategy while inviting new reflections and discussions on the issue of urban data crowdsourcing.
C1 [Prandi, Catia; Roccetti, Marco; Salomoni, Paola] Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, I-40126 Bologna, Italy.
   [Nisi, Valentina; Nunes, Nuno Jardim] Univ Madeira, Madeira Interact Technol Inst, P-9020105 Funchal, Portugal.
C3 University of Bologna; Universidade da Madeira
RP Prandi, C (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Mura Anteo Zamboni 7, I-40126 Bologna, Italy.
EM catia.prandi2@unibo.it
RI Nunes, Nuno/GXH-4259-2022; Prandi, Catia/KIB-1268-2024; Nunes, Nuno
   Jardim/M-4006-2013; Nisi, Valentina/G-8658-2018
OI Prandi, Catia/0000-0002-5566-2269; Nunes, Nuno
   Jardim/0000-0002-2498-0643; ROCCETTI, MARCO/0000-0003-1264-8595; Nisi,
   Valentina/0000-0002-8051-3230
CR [Anonymous], 2014, PROC EXTENDED ABSTR
   [Anonymous], 2014, P 11 WEB ALL C W4A 1, DOI DOI 10.1145/2596695.2596708
   [Anonymous], 2013, Chi -Conference, DOI 10.1145/2470654.2470744
   [Anonymous], 2003, PHILOS HORROR PARADO
   Bantinaki K, 2012, J AESTHET ART CRITIC, V70, P383, DOI 10.1111/j.1540-6245.2012.01530.x
   Bertram Dane, 2015, LIKERT SCALES ARE ME
   Buchenau M., 2000, DIS2000. Designing Interactive Systems Processes, Practices, Methods, and Techniques. Conference Proceedings, P424, DOI 10.1145/347642.347802
   Cabitza F, 2014, J VISUAL LANG COMPUT, V25, P684, DOI 10.1016/j.jvlc.2014.10.014
   Certeau Michelde., 1988, PRACTICE EVERYDAY LI
   Csikszentmihalyi M., 1991, Flow: The Psychology of Optimal Experience, DOI DOI 10.5465/AMR.1991.4279513
   Csikszentmihalyi M., 2002, FLOW PSYCHOL HAPPINE
   Darabont F, 2010, AMC TV CHANNEL
   Deci EL, 1999, PSYCHOL BULL, V125, P627, DOI 10.1037/0033-2909.125.6.627
   Deterding S., 2013, CHI '13 Extended Abstracts on Human Factors in Computing Systems, P3263, DOI [DOI 10.1145/2468356.2479662, 10.1145/2468356.2479662]
   Deterding S., 2011, CHI 2011
   Elden S., 2004, Rhythmanalysis: Space, time and everyday life, DOI DOI 10.5040/9781472547385
   Ferretti S, 2010, COMMUN ACM, V53, P139, DOI 10.1145/1721654.1721692
   Fischer Gerhard, 2011, Interactions, V18, P42, DOI 10.1145/1962438-1962450
   Fischer G, 2010, J ORGAN END USER COM, V22, P52, DOI 10.4018/joeuc.2010101901
   Haensch A, 2013, FLEEING ZOMBIES FLU
   Hamari J, 2014, P ANN HICSS, P3025, DOI 10.1109/HICSS.2014.377
   Hara K., 2014, P 27 ANN ACM S US IN, P189, DOI DOI 10.1145/2642918.2647403
   Hara Kotaro, 2013, P 15 INT ACM SIGACCE, P16
   Hung SY, 2011, INT J HUM-COMPUT ST, V69, P415, DOI 10.1016/j.ijhcs.2011.02.004
   Hunicke R., 2004, Proc. AAAI Wksp. Challenges in Game AI, V4, P1722
   Jisun, 2015, DISABILITY INCLUSION
   Kaiser WardL., 2001, Seeing Through Maps: The Power of Images to Shape our World View
   Keane K, 2014, ADV HUM SOC ASPEC T, P224, DOI 10.4018/978-1-4666-4623-0.ch011
   Latour B., 1992, Shaping technology/building society: Studies in sociotechnical change, P225, DOI DOI 10.2307/2074370
   Mirri S, 2014, 2014 EIGHTH INTERNATIONAL CONFERENCE ON NEXT GENERATION MOBILE APPS, SERVICES AND TECHNOLOGIES (NGMAST), P294, DOI 10.1109/NGMAST.2014.59
   Mirri S, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P833, DOI 10.1109/HPCSim.2014.6903776
   Nunes N.J., 2015, P 11 BIANNUAL C ITAL, P130, DOI DOI 10.1145/2808435.2808443
   Palazzi C.E., 2010, ACM COMPUTERS ENTERT, V8, P4
   Palazzi CE, 2010, IEEE INT CON MULTI, P1707, DOI 10.1109/ICME.2010.5583240
   PhoneGap, 2015, EAS CREAT APPS US WE
   Platts TK, 2013, SOCIOL COMPASS, V7, P547, DOI 10.1111/soc4.12053
   Prandi Catia, 2014, 2014 IEEE 11th Consumer Communications and Networking Conference (CCNC), P591, DOI 10.1109/CCNC.2014.6940491
   Prandi C., 2015, CHItaly, V2015, P126, DOI [10.1145/2808435.2808449, DOI 10.1145/2808435.2808449]
   Quercia D., 2014, P 25 ACM C HYPERTEXT, P116, DOI [DOI 10.1145/2631775.2631799, 10/gfvsn2, 10 .1145/2631775.2631799]
   Roccetti Marco, 2011, Comput. Entertain., V9, DOI [10.1145/1998376.1998381, DOI 10.1145/1998376.1998381]
   Romero G, 2010, WHO SAYS ZOMBIES EAT
   Romero G, 2010, QUESTIONS GEORGE ROM
   Romero George., 2008, Night of the Living Dead
   Rosner D, 2014, COMMUN ACM, V57, P82, DOI 10.1145/2602695.2602701
   Rosner DK, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P397, DOI 10.1145/2702123.2702467
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   SUCHMAN L, 1995, COMMUN ACM, V38, P56, DOI 10.1145/223248.223263
   Sweetser P, 2005, COMPUTERS ENTERTAINM, V3, P3, DOI [10.1145/1077246.1077253, DOI 10.1145/1077246.1077253]
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   von Ahn Luis, 2006, P SIGCHI C HUM FACT, P79, DOI DOI 10.1145/1124772.1124785
   Wiechman BM, 2009, J RES PERS, V43, P716, DOI 10.1016/j.jrp.2009.03.008
   Wohlin C., 2000, EXPT SOFTWARE ENG IN
   Wood M., 1992, Damage analysis of bridge structures using vibrational techniques
NR 53
TC 45
Z9 46
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4951
EP 4979
DI 10.1007/s11042-016-3780-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500014
DA 2024-07-18
ER

PT J
AU Singh, R
   Om, H
AF Singh, Rishav
   Om, Hari
TI (Two-Dimensional)<SUP>2</SUP> whitening reconstruction for newborn
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Illumination; Whitening; Newborn; Principal component
   analysis
ID ONE TRAINING IMAGE; FACE RECOGNITION; ILLUMINATION; PCA; NORMALIZATION;
   EIGENFACES
AB Recently, various feature extraction techniques and its variations have been proposed for computer vision. However, most of these techniques are sensitive to the images acquired in uncontrolled environment. The illumination, expression and occlusion for face images result in random error entries in the 2days matrix representing the face. Techniques such as Principal Component Analysis (PCA) do not handle these entries explicitly. This paper proposes a (Two-dimensional)(2) whitening reconstruction ((TWR)-W-2) pre-processing step to be coupled with the PCA algorithm. This combined method would process illumination & expression variations better than standalone PCA. This technique has been compared with state-of-the-art Two-dimensional whitening reconstruction (TWR) pre-processing method. The final results clearly indicate the reason for better performance of (TWR)-W-2 over TWR. The histograms plotted for both these algorithms show that (TWR)-W-2 makes for a smoother frequency distribution than TWR. The proposed method indicated increased recognition rate and accuracy with increasing number of training images; up to 93.82 % for 2 images, 94.76 % for 4 images and 97.42 % for 6 training images.
C1 [Singh, Rishav] Infosys Ltd, Educ & Res, Chandigarh, India.
   [Om, Hari] Indian Sch Mines, Dept Comp Sci, Dhanbad, Jharkhand, India.
C3 Infosys Limited; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Singh, R (corresponding author), Infosys Ltd, Educ & Res, Chandigarh, India.
EM rishvsingh559@gmail.com; hariom4india@gmail.com
RI singh, rishav/AAB-7472-2020; singh, rishav/AAA-6991-2021; OM,
   HARI/AAY-6011-2021
OI singh, rishav/0000-0003-2947-9046; singh, rishav/0000-0003-2947-9046;
   OM, HARI/0000-0002-9750-2706
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2012, INT J COMPUT APPL, DOI DOI 10.5120/8194-1569
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen SC, 2004, PATTERN RECOGN LETT, V25, P1173, DOI 10.1016/j.patrec.2004.03.012
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   FIELDS C, 1960, OBSTET GYNECOL, V16, P98
   Fitzgibbon A, 2002, LECT NOTES COMPUT SC, V2352, P304
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Li S. Z., 2004, HDB FACE RECOGNITION
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Shi XM, 2015, J NANOMATER, V2015, DOI 10.1155/2015/140716
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tiwari S, 2012, IET BIOMETRICS, V1, P200, DOI 10.1049/iet-bmt.2012.0040
   Tiwari S., 2012, Proceedings of the 2012 1st International Conference on Recent Advances in Information Technology (RAIT 2012), P74, DOI 10.1109/RAIT.2012.6194483
   Tiwari S., 2013, INT J BIOSCIENCE BIO, V5, P89
   Tiwari S., 2012, P INT C COMP SCI ENG, P179, DOI [10.1007/978-3-642-30157-5, DOI 10.1007/978-3-642-30157-5]
   Tiwari S., 2011, INT C IM INF PROC IC
   Tiwari S., 2012, Int J Adv Comput Eng Archit, V2, P201
   Tiwari S, ENCY INFORM SCI TECH, P4347, DOI [10.4018/978-1-4666-5888-2.ch427, DOI 10.4018/978-1-4666-5888-2.CH427]
   Tiwari S, 2015, P IEEE 2 INT C COMP
   Tiwari S, MULT BIOM REC NEWB R
   Tiwari S, 2015, P NATL A SCI INDIA A, V85, P211, DOI 10.1007/s40010-014-0196-7
   Tiwari S, 2012, J INF TECHNOL RES, V5, P15, DOI 10.4018/jitr.2012040102
   Tiwari Shrikant., 2012, Signal and Image Processing: An International Journal, V3, P103
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang HT, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P819
   Wu JX, 2002, PATTERN RECOGN LETT, V23, P1711, DOI 10.1016/S0167-8655(02)00134-4
   Xie XD, 2006, PATTERN RECOGN LETT, V27, P609, DOI 10.1016/j.patrec.2005.09.026
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang DQ, 2006, PATTERN RECOGN, V39, P140, DOI 10.1016/j.patcog.2005.08.002
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhao L, 1999, PATTERN RECOGN, V32, P547, DOI 10.1016/S0031-3203(98)00119-8
NR 39
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3471
EP 3483
DI 10.1007/s11042-016-3731-5
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200015
DA 2024-07-18
ER

PT J
AU Tian, Y
   Wang, RN
   Jiang, YQ
   Ma, YF
AF Tian, Ye
   Wang, Ruonan
   Jiang, Yueqiu
   Ma, Yufeng
TI A novel multiple-channels scheduling algorithm based on timeslot
   optimization in the advanced orbiting systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AOS; Multiple-channels; Scheduling algorithm; Timeslot; Buffer size
ID UAVS
AB Multiple-channels data from satellite and unmanned aerial vehicles images have gained much attention. An advanced approach used in the advanced orbiting systems is to divide the space channels into multiple-channels, called virtual channels (VC), which are scheduled according to a special mechanism achieved through the feature learning of on-satellite models. Considering that the performance of the existing multiple-channels scheduling algorithm is not good enough and the buffer size is rarely considered, a novel multiple-channels scheduling algorithm based on timeslot optimization is presented and its performance under the finite buffer size is also studied. Firstly, an optimized timeslot assignment method is designed based on both the ratio of synchronous frames arrival rate to asynchronous frames arrival rate and the allowable maximum time delay of synchronous VC frames. Secondly, the periodical polling scheduling strategy is adopted to schedule the synchronous VCs at the synchronous timeslots. If there are no corresponding synchronous VC frames in a synchronous timeslot, another synchronous or asynchronous frame will be selected and scheduled according to the scheduling mechanism. Thirdly, a dynamic scheduling strategy based on the transmission urgency of VC is adopted to schedule the asynchronous VCs at the asynchronous timeslots. The research results show that the performance of the proposed algorithm is much better than that of the other scheduling algorithms in terms of the time delay and channel utilization rate. The proposed multiple-channels scheduling algorithm for the finite buffer size is extensively studied and the upper bound of rate of frame-lost timeslots of each asynchronous VC is concluded.
C1 [Tian, Ye; Wang, Ruonan; Jiang, Yueqiu; Ma, Yufeng] Shengyang Ligong Univ, Sch Informat Sci & Engn, Shenyang 110159, Peoples R China.
C3 Shenyang Ligong University
RP Jiang, YQ (corresponding author), Shengyang Ligong Univ, Sch Informat Sci & Engn, Shenyang 110159, Peoples R China.
EM missjiangyueqiu@sina.com
RI Yufeng, Ma/E-1594-2019
FU National Natural Science Foundation of China [61471247, 61101116,
   61501307, 61373159]; Program for Liaoning Excellent Talents University
   [LR2015057]; Liaoning BaiQianWan Talents Program [2014921044]; General
   Project of Department of Education of Liaoning Province [L2014078,
   L2015459]; Open Fund of Key Laboratory of Shenyang Ligong University
   [4771004kfs32]
FX This work is supported by the National Natural Science Foundation of
   China (61471247, 61101116, 61501307, 61373159), Program for Liaoning
   Excellent Talents University (LR2015057), Liaoning BaiQianWan Talents
   Program (2014921044), General Project of Department of Education of
   Liaoning Province (L2014078, L2015459) and the Open Fund of Key
   Laboratory of Shenyang Ligong University (4771004kfs32).
CR [Anonymous], 1992, ADV ORB SYST NETW DA, P1
   [Anonymous], 2003, TM SYNCHR CHANN COD, P1
   [Anonymous], 2001, ADV ORB SYST NETW DA, P1
   [Anonymous], 2003, A000Y8 CCSDS, P1
   Ba Y, 2000, ANAL CCSDS PROTOCOL
   Bai Y-F, 2011, J SPACECRAFT TT C TE, V30, P16
   [别玉霞 Bie Yuxia], 2011, [宇航学报, Journal of Chinese Society of Astronautics], V32, P193
   Chung K.L, 2000, COURSE PROBABILITY T
   Cui P, 2011, METEOROL SCI TECHNOL, V39, P473
   Duan JM, 2015, J GLOBAL OPTIM, V62, P853, DOI 10.1007/s10898-015-0290-7
   Gong X-X, 2006, COMPUT ENG DES, V27, P3634
   Gu Y-Q, 2001, CHINESE SPACE SCI TE, V21, P29
   Li Fang, 2010, Microcomputer Information, P52
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   LIU Lishi, 2014, SCI TECHNOLOGY ENG, V14, P97, DOI [10.3969/j.issn.1671-1815.2014.17.019, DOI 10.3969/J.ISSN.1671-1815.2014.17.019]
   Liu Qing-li, 2013, Journal of System Simulation, V25, P87
   Liu QL, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 1, PROCEEDINGS, P351, DOI 10.1109/ISDA.2008.158
   Ma Y-K, 2002, J TELEMETRY TRACKING, V23, P26
   Mao Y-C, 2006, STOCHASTIC PROCESS
   Riha AP, 2006, P IEEE AER 2006 MONT, P1
   Shao G-Z, 2001, J TELEMETRY TRACKING, V22, P9
   Tan W-C, 2004, SPACE DATE SYSTEM
   Tian Y, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/391493
   [田野 Tian Ye], 2011, [中国空间科学技术, Chinese Space Science and Technology], V31, P50
   [田野 TIAN Ye], 2011, [宇航学报, Journal of Chinese Society of Astronautics], V32, P1171
   Tian Z, 2006, SPACECRAFT ENG, V15, P20
   Wang X.H., 2011, SPACECRAFT ENG, V20, P83
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhang B, 2016, INT J COMPUT VIS
   Zhang BC, 2015, J INTELL ROBOT SYST, V77, P391, DOI 10.1007/s10846-013-9901-z
   Zhang BC, 2014, AUTOMATICA, V50, P809, DOI 10.1016/j.automatica.2013.12.035
   Zhao H-P, 2007, SPACECRAFT ENG, V16, P78
   Zhao Y, 2007, HIGH DATA RATE MULTI
   Zhao Y-T, 2001, FIRE CONTROL COMMAND, V36, P9
   Zhao Yun-tao, 2015, Systems Engineering and Electronics, V37, P417, DOI 10.3969/j.issn.1001-506X.2015.02.30
   Zhao Yun-tao, 2010, ICCSIT, V3, P399
   Zhou J, 2007, STUDY SIMULATION SPA
NR 37
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4523
EP 4551
DI 10.1007/s11042-016-3410-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200065
DA 2024-07-18
ER

PT J
AU Chai, XL
AF Chai, Xiuli
TI An image encryption algorithm based on bit level Brownian motion and new
   chaotic systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brownian motion; Directional diffusion; Row diffusion (RD); Column
   diffusion (CD); High security
ID SCHEME; MAP; EFFICIENT
AB In this paper, a new image encryption algorithm based on Brownian motion and new 1D chaotic system is introduced. Firstly, SHA 256 hash value of the plain image is used to generate the initial values and system parameters of chaotic systems for confusion and diffusion process. Then, 8 bitplanes of the plain image are scrambled based on Brownian motion, respectively, and the position and value of all pixels are changed simultaneously. After the confusion process, a two directional diffusion process is carried out, and it is made up of row diffusion (RD) and column diffusion (CD). The whole process can be repeated many rounds in order to get better encryption effect. Simulation results and security analysis show that our scheme has properties of large key space, high sensitivity to key, strong resisting statistical and differential attack. So, it has high security and important practical application in image transmission and image encryption.
C1 [Chai, Xiuli] Henan Univ, Inst Image Proc & Pattern Recognit, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
C3 Henan University
RP Chai, XL (corresponding author), Henan Univ, Inst Image Proc & Pattern Recognit, Sch Comp & Informat Engn, Kaifeng 475004, Peoples R China.
EM chaixiuli@henu.edu.cn
FU National Natural Science Foundation of China [61203094]; Science and
   Technology Foundation of Henan Province of China [152102210048]; Natural
   Science Foundation of Educational Committee of Henan Province of China
   [14A413015]; Henan Provincial Government [SBGJ090603]; Ministry of
   Education of China [SBGJ090603]; Research Foundation of Henan University
   [xxjc20140006]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61203094), Science and Technology Foundation of Henan
   Province of China (Grant No. 152102210048), Natural Science Foundation
   of Educational Committee of Henan Province of China (Grant No.
   14A413015), the joint funds between Henan Provincial Government and
   Ministry of Education of China (Grant No. SBGJ090603), the Research
   Foundation of Henan University (Grant No. xxjc20140006).
CR Aulí-Llinàs F, 2012, IEEE T IMAGE PROCESS, V21, P1920, DOI 10.1109/TIP.2011.2176953
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen JX, 2014, NONLINEAR DYNAM, V77, P1191, DOI 10.1007/s11071-014-1370-9
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Fu C, 2013, COMPUT BIOL MED, V43, P1000, DOI 10.1016/j.compbiomed.2013.05.005
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Ling C, 1999, IEEE T SIGNAL PROCES, V47, P1424, DOI 10.1109/78.757236
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu Q, 2015, COMMUN NONLINEAR SCI, V20, P506, DOI 10.1016/j.cnsns.2014.06.005
   Liu SB, 2009, J COMPUT, V4, P1091
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Moon D, 2006, ETRI J, V28, P444, DOI 10.4218/etrij.06.0106.0013
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wang XY, 2014, NONLINEAR DYNAM, V75, P345, DOI 10.1007/s11071-013-1070-x
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Xu Y, 2014, COMMUN NONLINEAR SCI, V19, P3735, DOI 10.1016/j.cnsns.2014.02.029
   Ye GD, 2014, NONLINEAR DYNAM, V75, P417, DOI 10.1007/s11071-013-1074-6
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang W, 2013, COMMUN NONLINEAR SCI, V18, P2066, DOI 10.1016/j.cnsns.2012.12.012
   Zhang XP, 2016, MULTIMED TOOLS APPL, V75, P1745, DOI 10.1007/s11042-014-2372-9
   Zhang YQ, 2014, PHYSICA A, V402, P104, DOI 10.1016/j.physa.2014.01.051
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou YC, 2014, SIGNAL PROCESS, V100, P197, DOI 10.1016/j.sigpro.2014.01.020
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhou YC, 2012, OPT COMMUN, V285, P594, DOI 10.1016/j.optcom.2011.11.044
   Zhu CX, 2015, NONLINEAR DYNAM, V79, P1511, DOI 10.1007/s11071-014-1757-7
NR 32
TC 127
Z9 128
U1 0
U2 72
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 1159
EP 1175
DI 10.1007/s11042-015-3088-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000051
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Dhondt, J
   Martens, L
AF De Pessemier, Toon
   Dhondt, Jeroen
   Martens, Luc
TI Hybrid group recommendations for a travel service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommender system; Group recommendations; Travel; Tourism; Hybrid;
   Collaborative filtering; Content-based recommender
ID SYSTEMS
AB Recommendation techniques have proven their usefulness as a tool to cope with the information overload problem in many classical domains such as movies, books, and music. Additional challenges for recommender systems emerge in the domain of tourism such as acquiring metadata and feedback, the sparsity of the rating matrix, user constraints, and the fact that traveling is often a group activity. This paper proposes a recommender system that offers personalized recommendations for travel destinations to individuals and groups. These recommendations are based on the users' rating profile, personal interests, and specific demands for their next destination. The recommendation algorithm is a hybrid approach combining a content-based, collaborative filtering, and knowledge-based solution. For groups of users, such as families or friends, individual recommendations are aggregated into group recommendations, with an additional opportunity for users to give feedback on these group recommendations. A group of test users evaluated the recommender system using a prototype web application. The results prove the usefulness of individual and group recommendations and show that users prefer the hybrid algorithm over each individual technique. This paper demonstrates the added value of various recommendation algorithms in terms of different quality aspects, compared to an unpersonalized list of the most-popular destinations.
C1 [De Pessemier, Toon; Dhondt, Jeroen; Martens, Luc] Univ Ghent, IMinds, B-9050 Ghent, Belgium.
C3 Ghent University; IMEC
RP De Pessemier, T (corresponding author), Univ Ghent, IMinds, G Crommenlaan 8-201, B-9050 Ghent, Belgium.
EM toon.depessemier@ugent.be; jeroen.dhondt@ugent.be; luc1.martens@ugent.be
CR [Anonymous], 2011, DATA MINING ICDM
   Ardissono L, 2002, LECT NOTES COMPUTER, V2266, P228, DOI DOI 10.1007/3-540-45844-1
   Bollen D., 2010, P 4 ACM C RECOMMENDE, P63, DOI [10.1145/1864708.1864724, DOI 10.1145/1864708.1864724]
   Buhalis D, 2008, TOURISM MANAGE, V29, P609, DOI 10.1016/j.tourman.2008.01.005
   Burke R., 2007, The Adaptive Web. Methods and Strategies of Web Personalization, P377
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   De Pessemier T., 2010, P 4 ACM C RECOMMENDE, P281
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2925, DOI 10.1007/s11042-013-1582-x
   De Pessemier T, 2014, MULTIMED TOOLS APPL, V72, P2497, DOI 10.1007/s11042-013-1563-0
   Desrosiers C, 2011, RECOMMENDER SYSTEMS HANDBOOK, P107, DOI 10.1007/978-0-387-85820-3_4
   Ekstrand MichaelD., 2011, P 5 ACM C RECOMMENDE, P349
   Felfernig A., 2008, P 10 INT C ELECT COM, P1, DOI DOI 10.1145/1409540.1409544
   Garcia I, 2011, EXPERT SYST APPL, V38, P7683, DOI 10.1016/j.eswa.2010.12.143
   Gibson H, 2002, ANN TOURISM RES, V29, P358, DOI 10.1016/S0160-7383(01)00037-8
   Jameson Anthony, 2004, P WORK C ADV VIS INT, P48
   Jameson Anthony, 2004, P WORK C ADV VIS INT, P447
   Kay J, 2006, P WORKSH NEW TECHN P
   Liu Q, 2014, IEEE T KNOWL DATA EN, V26, P278, DOI 10.1109/TKDE.2012.233
   Lucas JP, 2013, EXPERT SYST APPL, V40, P3532, DOI 10.1016/j.eswa.2012.12.061
   Manning C. D., 2008, INTRODUCTION TO INFO, V1
   Martínez L, 2009, 2009 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 3, P187
   Masthoff J, 2004, HUM-COMPUT INT-SPRIN, P93
   MCCARTHY J, 2002, P WORKSH MOB ADHOC C
   McCarthy K., 2006, FLAIRS Conference, P86
   Moreno A., 2015, P 9 ACM C REC SYST R, P355, DOI DOI 10.1145/2792838.2798713
   Petrevska B., 2012, Revista de Turism, P11
   Pu Pearl, 2011, P 5 ACM C RECOMMENDE, P157, DOI 10.1145/2043932.2043962
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Ricci F., 2001, Information Technology and Tourism, V4, P215, DOI 10.3727/109830501108751001
   Ricci F, 2002, IEEE INTELL SYST, V17, P55
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Wang Shuliang, 2011, Wuhan University Journal of Natural Sciences, V16, P16, DOI 10.1007/s11859-011-0704-4
   Yu C, 2009, PROC INT CONF DATA, P1299, DOI 10.1109/ICDE.2009.225
   Zanker Markus, 2009, 2009 IEEE Conference on Commerce and Enterprise Computing, P49, DOI 10.1109/CEC.2009.84
NR 34
TC 26
Z9 26
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2787
EP 2811
DI 10.1007/s11042-016-3265-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000053
DA 2024-07-18
ER

PT J
AU Lin, C
   Pun, CM
   Vong, CM
   Adjeroh, D
AF Lin, Cong
   Pun, Chi-Man
   Vong, Chi-Man
   Adjeroh, Don
TI Efficient shape classification using region descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape classification; Region descriptor; Skeleton; Contour; Signature;
   k-ELM
ID EXTREME LEARNING-MACHINE; IMAGE RETRIEVAL; RECOGNITION; REPRESENTATION
AB A novel scheme for efficient shape classification using region descriptors and extreme learning machine with kernels is proposed. The skeleton and boundary of the input shape image are first extracted. Then the boundary is simplified to remove noise and minor variations. Finally, region descriptors for the local skeleton, and the simplified shape signature are constructed to form a hybrid feature vector. Training and classification are then performed using kernel extreme learning machine (k-ELM) for efficient shape classification. Experimental results show that the proposed scheme is very fast and can archive high classification accuracy of 91.43 % on the challenging MPEG-7 dataset, outperforming existing state-of-the-art methods.
C1 [Lin, Cong; Pun, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Taipa, Macau, Peoples R China.
   [Vong, Chi-Man] Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Taipa, Macau, Peoples R China.
   [Adjeroh, Don] West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26508 USA.
C3 University of Macau; University of Macau; West Virginia University
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Taipa, Macau, Peoples R China.
EM yb17403@umac.mo; cmpun@umac.mo; cmvong@umac.mo; adjeroh@csee.wvu.edu
RI Pun, Chi Man/GRJ-3703-2022; VONG, Chi-Man/AAU-5720-2020
OI Vong, Chi-Man/0000-0001-7997-8279; Pun, Chi-Man/0000-0003-1788-3746
FU the Research Committee of the University of Macau [MYRG2015-00011-FST,
   MYRG2015-00012-FST]; Science and Technology Development Fund of Macau
   SAR [008/2013/A1, 093-2014-A2]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions. This research was supported in part
   by the Research Committee of the University of Macau
   (MYRG2015-00011-FST, MYRG2015-00012-FST) and the Science and Technology
   Development Fund of Macau SAR (008/2013/A1, 093-2014-A2).
CR Alajlan N, 2007, PATTERN RECOGN, V40, P1911, DOI 10.1016/j.patcog.2006.12.005
   Antani S, 2003, IEEE IJCNN, P160
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Bai X, 2014, IEEE T IMAGE PROCESS, V23, P3935, DOI 10.1109/TIP.2014.2336542
   Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Belongie S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P454, DOI 10.1109/ICCV.2001.937552
   Bicego M, 2004, IEEE T PATTERN ANAL, V26, P281, DOI 10.1109/TPAMI.2004.1262200
   Chen YW, 2008, IEEE T SIGNAL PROCES, V56, P4762, DOI [10.1109/TSP.2009.926692, 10.1109/TSP.2008.926692]
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   El-Naqa I, 2004, IEEE T MED IMAGING, V23, P1233, DOI 10.1109/TMI.2004.834601
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Grigorishin T, 1998, PATTERN ANAL APPL, V1, P163, DOI 10.1007/BF01259366
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Huet B, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P737, DOI 10.1109/ICIP.2001.958599
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Ko B, 2001, PATTERN ANAL APPL, V4, P174, DOI 10.1007/s100440170015
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Leavers VF, 2000, IEEE T PATTERN ANAL, V22, P1411, DOI 10.1109/34.895975
   Li S, 2009, IEEE T SYST MAN CY A, V39, P227, DOI 10.1109/TSMCA.2008.2007988
   Lin L, 2015, IEEE T PATTERN ANAL, V37, P959, DOI 10.1109/TPAMI.2014.2359888
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Luo P, 2015, IEEE T NEURAL NETWOR, P1
   Ma ZM, 2011, PATTERN ANAL APPL, V14, P9, DOI 10.1007/s10044-009-0171-0
   Ren Z, 2013, IEEE T PATTERN ANAL, V35, P2546, DOI 10.1109/TPAMI.2013.67
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sharvit D, 1998, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES - PROCEEDINGS, P56, DOI 10.1109/IVL.1998.694496
   Sun KB, 2005, PROC CVPR IEEE, P727
   Tomczyk A, 2011, PATTERN ANAL APPL, V14, P425, DOI 10.1007/s10044-011-0200-7
   Van Otterloo P. J., 1991, CONTOUR ORIENTED APP
   Wang S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P209, DOI 10.1109/ICCV.2001.937626
   Wenli Yao, 2009, 2009 International Conference on Information and Automation (ICIA), P1144, DOI 10.1109/ICINFA.2009.5205089
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zheng YF, 2005, IEEE I CONF COMP VIS, P1561
NR 40
TC 5
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 83
EP 102
DI 10.1007/s11042-015-3021-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000005
DA 2024-07-18
ER

PT J
AU Liu, PZ
   Hong, M
   Wang, MH
   Gu, PT
   Huang, DT
AF Liu, Peizhong
   Hong, Ming
   Wang, Minghang
   Gu, Peiting
   Huang, Detian
TI 3D face reconstruction via landmark depth estimation and shape
   deformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face reconstruction; Sparse representation; Weighted l(1) norm
   sparsity; Shape deformation
ID IMAGE; ALIGNMENT
AB Since a human face could be represented by a few landmarks with less redundant information, and calculated by a linear combination of a small number of prototypical faces, we propose a two-step 3D face reconstruction approach including landmark depth estimation and shape deformation. The proposed approach allows us to reconstruct a realistic 3D face from a 2D frontal face image. First, we apply a coupled dictionary learning method based on sparse representation to explore the underlying mappings between pair of 2D and 3D training landmarks. In the method, a weighted l (1) norm sparsity function is introduced to better pursuit the l (0) norm sparsity. Then, the depth of the landmarks could be estimated. Second, we propose a novel shape deformation method to reconstruct the 3D face by combining a small number of most relevant deformed faces which are obtained by the estimated landmarks. The sparsity regulation is also introduced to find the relevant faces in the second step. The proposed approach could explore the distributions of 2D and 3D faces and the underlying mappings between them well, because human faces are represented by low-dimensional landmarks, and their distributions are described by sparse representations. Moreover, it is much more flexible since we can make any change in any step. Extensive experiments are conducted on BJUT_3D database, and the results validate the effectiveness of the proposed approach.
C1 [Liu, Peizhong; Hong, Ming; Wang, Minghang; Gu, Peiting; Huang, Detian] Huaqiao Univ, Coll Engn, Quanzhou, Fujian, Peoples R China.
C3 Huaqiao University
RP Liu, PZ (corresponding author), Huaqiao Univ, Coll Engn, Quanzhou, Fujian, Peoples R China.
EM pzliu@hqu.edu.cn; wangminghang852@163.com; huangdetian@hqu.edu.cn
FU Cloud Computing Platform for Internet of Things-Fujian Scientific
   Research Platform for Innovation by the Foundation of Quanzhou City
   [2014Z103, 2014Z113]; Fundamental Research Funds for the Central
   Universities [JB-ZR1202]; new IT platform construction project in Fujian
   Province [2013H2002]
FX This work was supported by Cloud Computing Platform for Internet of
   Things-Fujian Scientific Research Platform for Innovation by the
   Foundation of Quanzhou City under No. 2014Z103 and No.2014Z113. This
   work was supported in part by the Fundamental Research Funds for the
   Central Universities JB-ZR1202, and by new IT platform construction
   project in Fujian Province 2013H2002. The authors would like to thank
   the reviewers for their valuable suggestions and comments
CR Aharon M., 2005, PROC SPARS, V5, P9, DOI DOI 10.1109/TSP.2006.881199
   [Anonymous], ARXIV14112942 CORR
   [Anonymous], P ACM SIGGRAPH 2006
   [Anonymous], SPARSE MODELING SOFT
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2014, P BRIT MACH VIS C
   Blake A., 1998, Active Shape Models
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Castelan Mario, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563049
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Horn B.K., 1989, Obtaining shape from shading information
   Hu YX, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P843
   Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832
   Lei Z., 2008, IEEE C COMPUTER VISI
   Platt S. M., 1981, Computer Graphics, V15, P245, DOI 10.1145/965161.806812
   Prados E, 2005, PROC CVPR IEEE, P870
   Reiter M, 2006, INT C PATT RECOG, P425
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sánchez-Escobedo D, 2012, IEEE IMAGE PROC, P1801, DOI 10.1109/ICIP.2012.6467231
   Sánchez-Escobedo D, 2013, PATTERN RECOGN LETT, V34, P389, DOI 10.1016/j.patrec.2012.09.007
   Sederberg T. W., 1986, Computer Graphics, V20, P151, DOI 10.1145/15886.15903
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P2887, DOI 10.1109/TIP.2012.2183882
   Terzopoulos D., 1990, Journal of Visualization and Computer Animation, V1, P73, DOI 10.1002/vis.4340010208
   Vetter T, 1997, IEEE T PATTERN ANAL, V19, P733, DOI 10.1109/34.598230
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Xiao Q, 2014, INT C PATT RECOG, P2257, DOI 10.1109/ICPR.2014.392
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
NR 30
TC 1
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2749
EP 2767
DI 10.1007/s11042-016-3259-8
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000051
DA 2024-07-18
ER

PT J
AU Peng, JH
   Tang, SY
   Zhang, LP
   Liu, R
AF Peng, Jinghui
   Tang, Shanyu
   Zhang, Liping
   Liu, Ran
TI Information retrieval of mass encrypted data over multimedia networking
   with N-level vector model-based relevancy ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted data retrieval; N-level vector model; Relevancy ranking;
   Multimedia security
AB With an explosive growth in the deployment of networked applications over the Internet, searching the encrypted information that the user needs becomes increasingly important. However, the information search precision is quite low when using Vector space model for mass information retrieval, because long documents having poor similarity values are poorly represented in the vector space model and the order in which the terms appear in the document is lost in the vector space representation with intuitive weighting. To address the problems, this study proposed an N-level vector model (NVM)-based relevancy ranking scheme with an introduction of a new formula of the term weighting, taking into account the location of the feature term in the document to describe the content of the document properly, investigated into ways of ranking the encrypted documents using the proposed scheme, and conducted realistic simulation of information retrieval of mass encrypted data over multimedia networking. Results indicated that the timing of the index building, the most costing part of the relevancy ranking scheme, increased with the increase in both the document size and the multimedia content of the document being searched, which is in agreement with the expected. Performance evaluation demonstrated that our specially designed NVM-based encrypted information retrieval system is effective in ranking the encrypted documents transmitted over multimedia networks with large recall ratio and great retrieval precision.
C1 [Peng, Jinghui; Tang, Shanyu; Zhang, Liping; Liu, Ran] China Univ Geosci, Sch Comp Sci, 388 Lumo Rd, Wuhan 430074, Hubei Province, Peoples R China.
   [Tang, Shanyu] Univ Salford, Salford M5 4WT, Lancs, England.
C3 China University of Geosciences; University of Salford
RP Tang, SY (corresponding author), China Univ Geosci, Sch Comp Sci, 388 Lumo Rd, Wuhan 430074, Hubei Province, Peoples R China.; Tang, SY (corresponding author), Univ Salford, Salford M5 4WT, Lancs, England.
EM shanyu.tang@gmail.com
RI Shi, Hao/AAH-1224-2021
OI Peng, Jinghui/0000-0003-0656-5494
FU National Natural Science Foundation of China [61272469, 61303237]; Wuhan
   Scientific Research Program [2013010501010144]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61272469 and Grant 61303237, and the
   Wuhan Scientific Research Program under Grant 2013010501010144. The
   authors would like to thank anonymous reviewers for their valuable
   suggestions.
CR Abbadi IM, 2014, CLOUD MANAGEMENT AND SECURITY, P1, DOI 10.1002/9781118817087
   Abdalla M, 2005, LECT NOTES COMPUT SC, V3621, P205
   Agrawal R., 2004, P SIGMOID 04, P563
   [Anonymous], 2015, GEN FRAMEWORK ONE DA
   [Anonymous], SECURE INDEXES EARLY
   [Anonymous], 2010, J PAK PSYCH SOC
   [Anonymous], 2005, APPL CRYPTOGRAPHY NE
   [Anonymous], 2008, INTRO INFORM RETRIEV, DOI DOI 10.1017/CBO9780511809071
   [Anonymous], 1983, INTRO MODERN INFORM
   Baeza-Yates R., 1999, Modern information retrieval, V82
   Baeza-Yates R A, 2011, MODERN INFORM RETRIE
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Brakerski Z, 2011, ANN IEEE SYMP FOUND, P97, DOI 10.1109/FOCS.2011.12
   Buyya R, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P5, DOI 10.1109/HPCC.2008.172
   Gao J., 2001, NIST SPECIAL PUBLICA
   Goldreich O, 1996, J ACM, V43, P431, DOI 10.1145/233551.233553
   Goldwasser S., 2010, Proceedings of the 1st Symposium on Innovations in Computer Science, P230
   Golle P, 2004, LECT NOTES COMPUT SC, V3089, P31, DOI 10.1007/978-3-540-24852-1_3
   Grossman David., 1998, Information retrieval algorithms and heuristics
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Park DJ, 2005, LECT NOTES COMPUT SC, V3325, P73
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   SALTON G, 1971, SMART RETRIEVAL SYST, P115
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Weis J, 2011, IEEE SECUR PRIV, V9, P49, DOI 10.1109/MSP.2011.127
NR 26
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2569
EP 2589
DI 10.1007/s11042-015-3224-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000043
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chen, ZH
   Liu, Y
   Sheng, B
   Liang, JN
   Zhang, J
   Yuan, YB
AF Chen, Zhi-hua
   Liu, Yi
   Sheng, Bin
   Liang, Jian-ning
   Zhang, Jing
   Yuan, Yu-bo
TI Image saliency detection using Gabor texture cues
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Texture features; Image segmentation; Superpixel
AB Image saliency analysis plays an important role in various applications such as object detection, image compression, and image retrieval. Traditional methods for saliency detection ignore texture cues. In this paper, we propose a novel method that combines color and texture cues to robustly detect image saliency. Superpixel segmentation and the mean-shift algorithm are adopted to segment an original image into small regions. Then, based on the responses of a Gabor filter, color and texture features are extracted to produce color and texture sub-saliency maps. Finally, the color and texture sub-saliency maps are combined in a nonlinear manner to obtain the final saliency map for detecting salient objects in the image. Experimental results show that the proposed method outperforms other state-of-the-art algorithms for images with complex textures.
C1 [Chen, Zhi-hua; Liu, Yi; Liang, Jian-ning; Zhang, Jing; Yuan, Yu-bo] East China Univ Sci & Technol, Dept Comp Sci & Engn, Shanghai 200237, Peoples R China.
   [Sheng, Bin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 East China University of Science & Technology; Shanghai Jiao Tong
   University
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
RI yuan, yubo/HSG-3147-2023; Yuan, Yubo/O-7235-2016
OI Yuan, Yubo/0000-0002-7577-3257
FU Nature Science Foundation of China [61370174, 61572316, 61300133,
   61202154]; National High-tech RAMP;D Program of China (863 Program)
   [2015AA011604]; Shanghai Pujiang Program [13PJ1404500]; Science and
   Technology Commission of Shanghai Municipality Program [13511505000];
   Open Project Program of the State Key Lab of CAD and CG [A1401];
   Zhejiang University
FX The authors thank Fangli Ying, Xiao-Long Xiao and Xing-jian Lu for their
   reading the paper carefully and the useful suggestions in the saliency
   detection. This work is supported by the Nature Science Foundation of
   China (Grant No. 61370174, Grant No. 61572316, Grant No. 61300133, and
   Grant No. 61202154), National High-tech R&D Program of China (863
   Program) (Grant No. 2015AA011604), Shanghai Pujiang Program (No.
   13PJ1404500), the Science and Technology Commission of Shanghai
   Municipality Program (No. 13511505000), and the Open Project Program of
   the State Key Lab of CAD and CG (Grant No. A1401), Zhejiang University.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Arróspide J, 2013, IEEE T IMAGE PROCESS, V22, P2286, DOI 10.1109/TIP.2013.2249080
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dolu O, 2009, 2009 24TH INTERNATIONAL SYMPOSIUM ON COMPUTER AND INFORMATION SCIENCES, P99, DOI 10.1109/ISCIS.2009.5291860
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Feichtinger H. G., 1994, Proceedings of the IEEE-SP International Symposium on Time-Frequency and Time-Scale Analysis (Cat. No.94TH8007), P44, DOI 10.1109/TFSA.1994.467367
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jing XY, 2009, THIRD INTERNATIONAL CONFERENCE ON GENETIC AND EVOLUTIONARY COMPUTING, P565, DOI 10.1109/WGEC.2009.132
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Madhu K., 2013, Proceedings of the 2013 International Conference on Pattern Recognition, Informatics and Mobile Engineering (PRIME), P37, DOI 10.1109/ICPRIME.2013.6496444
   Narendra A, 2008, IEEE C COMP VIS PATT, P1
   Nemati RJ, 2008, INT CONF SYST SIGNAL, P363, DOI 10.1109/IWSSIP.2008.4604442
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   QIU S, 1995, INT CONF ACOUST SPEE, P1089, DOI 10.1109/ICASSP.1995.480424
   QIU SG, 1995, IEEE T SIGNAL PROCES, V43, P2258, DOI 10.1109/78.469862
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Wan SH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P172
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Yuanbo Yang, 2010, 2010 Third International Symposium on Electronic Commerce and Security (ISECS 2010), P302, DOI 10.1109/ISECS.2010.73
   Zhen-Hua Guo, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P796, DOI 10.1109/ICMLC.2010.5580580
NR 33
TC 7
Z9 8
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16943
EP 16958
DI 10.1007/s11042-015-2965-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600011
DA 2024-07-18
ER

PT J
AU Hahn, C
   Kwon, H
   Kim, D
   Hur, J
AF Hahn, Changhee
   Kwon, Hyunsoo
   Kim, Daeyoung
   Hur, Junbeom
TI Enhanced authentication for outsourced educational contents through
   provable block possession
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Educational contents; Two-factor authentication; Block aggregation;
   Merkle tree; Usability
ID PASSWORDS; DESIGN
AB In recent years, the volume of educational contents has been explosively increased thanks to the rapid development of multimedia technologies. Furthermore, the development of smart devices has made various educational institutes use them as effective learning tools. Since more and more educational contents become available not only at school zone but at a variety of online learning systems, it becomes increasingly unaffordable for a single educational contents provider to store and process them locally. Therefore, many educational contents providers are likely to outsource the contents to cloud storage for cost saving. These phenomena raise one serious concern: how to authenticate educational contents users in a secure and efficient way? The most widely used password-based authentication suffers from numerous drawbacks in terms of security. Multi-factor authentication protocols based on diverse communication channels such as SMS, biometric, hardware token could enhance security, however they inevitably bring poor usability. To this end, we present a data block-based authentication scheme, which provides provable security and guarantees usability invariant such that users do nothing but entering a password. In addition, the proposed scheme supports efficient user revocation. To the best of our knowledge, our scheme is the first data block-based authentication scheme for outsourced educational contents that is provably secure without usability degradation. The experiment on Amazon EC2 cloud shows that the proposed scheme guarantees nearly constant time for user authentication.
C1 [Hahn, Changhee; Kwon, Hyunsoo; Kim, Daeyoung] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Hur, Junbeom] Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University; Korea University
RP Hur, J (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM Mckinsey@cau.ac.kr; khs910504@cau.ac.kr; rlaeod@cau.ac.kr;
   jbhur@korea.ac.kr
RI Hahn, Changhee/HTR-0677-2023; 권, 현수/HPG-4730-2023
OI Hahn, Changhee/0000-0003-4334-0411; 
FU National Research Foundation of Korea(NRF) - Korea government(MSIP)
   [2013R1A2A2A01005559]; Chung-Ang University Excellent Student
   Scholarship
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIP) (No.
   2013R1A2A2A01005559). This research was also supported by the Chung-Ang
   University Excellent Student Scholarship.
CR Adams A, 1999, COMMUN ACM, V42, P41, DOI 10.1145/322796.322806
   [Anonymous], 2013, USA Today
   Ateniese G, 2007, CCS'07: PROCEEDINGS OF THE 14TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P598
   Barni M, 2012, MMSEC, P2
   Bonneau J, 2012, P IEEE S SECUR PRIV, P553, DOI 10.1109/SP.2012.44
   Chiasson S, 2007, LECT NOTES COMPUT SC, V4734, P359
   Chiasson S, 2012, IEEE T DEPEND SECURE, V9, P222, DOI 10.1109/TDSC.2011.55
   Czeskis Alexei., 2012, ACM CCS
   Dirik AhmetEmir., 2007, Proceedings of the 3rd symposium on Usable privacy and security, P20
   Drimer S, 2009, LECT NOTES COMPUT SC, V5628, P184, DOI 10.1007/978-3-642-03549-4_11
   Evans D, 2011, NDSS, P2653
   Goofit K, 2007, COMPUTER SECURITY ES, P343
   Halevi S, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P491, DOI 10.1145/2046707.2046765
   Jain AK, 2000, IEEE T IMAGE PROCESS, V9, P846, DOI 10.1109/83.841531
   MORRIS R, 1979, COMMUN ACM, V22, P594, DOI 10.1145/359168.359172
   Salehi-Abari A, 2008, ANN COMPUT SECURITY, P111, DOI 10.1109/ACSAC.2008.18
   Stajano F, 2011, LECT NOTES COMPUT SC, V7114, P49, DOI 10.1007/978-3-642-25867-1_6
   Thorpe J, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 16TH USENIX SECURITY SYMPOSIUM, P103
   Wiedenbeck S, 2005, INT J HUM-COMPUT ST, V63, P102, DOI 10.1016/j.ijhcs.2005.04.010
   Yuan J, 2013, P IEEE INFOCOM, P2752
NR 20
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13057
EP 13076
DI 10.1007/s11042-015-2593-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800005
DA 2024-07-18
ER

PT J
AU Jeong, HY
AF Jeong, Hwa-Young
TI UX based adaptive e-learning hypermedia system (U-AEHS): an integrative
   user model approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia based learning; AEHS; UX based learning; User profile;
   Learning style
ID EDUCATIONAL HYPERMEDIA; EXPERIENCE; STYLES; SATISFACTION; MATHEMATICS;
   PERFORMANCE; UZWEBMAT; BEHAVIOR
AB Adaptive E-Learning Hypermedia System (AEHS) has been known as a method to provide the optimized learning for each learner's unique characteristics. To this end, learning system developers configure the general characteristic elements of learners in AEHS and analyze learning functions customized for each feature. After then, they develop system to provide learning contents suitable for each learner through the analyzed data thereof. However, there are various learning functions in learning system. Moreover, each individual learner has a different set of characteristic elements. Therefore, it is very difficult to establish application criteria. In particular, it is imperative to have all profile data of learners in e-learning system in order to provide customized learning for each individual learner. Also, it is required to select and provide adequate learning contents by analyzing accurately necessary elements for learning. However, it is very difficult to analyze and determine what learning is necessary for learners and also which learning process is adequate for learners. In this regard, this study proposed Adaptive E-Learning Hypermedia System (AEHS) that leveraged UX (user experience) to provide optimal learning process customized for learners in e-learning system. The basic data model of UX leveraged user profile based on learning style. Learning style for learning has a large number of elements. Thus, this system defined those elements that could reflect learner characteristics from human factors. After then, this study profiled based on the actual data of learners for each characteristic. In this way, this system analyzed accurately which learning would be necessary for learners. In the end, this system proposed required learning contents for learners when learners selected learning based thereon.
C1 [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul, South Korea.
C3 Kyung Hee University
RP Jeong, HY (corresponding author), Kyung Hee Univ, Humanitas Coll, 1 Hoegi Dong, Seoul, South Korea.
EM hyjeong@khu.ac.kr
OI Jeong, Hwa-Young/0000-0002-5017-934X
CR Ahmad N, 2013, PROCD SOC BEHV, V103, P181, DOI 10.1016/j.sbspro.2013.10.324
   Akbulut Y, 2012, COMPUT EDUC, V58, P835, DOI 10.1016/j.compedu.2011.10.008
   [Anonymous], J CONVERGENCE
   [Anonymous], J CONVERGENCE
   Fagan M, 2015, COMPUT HUM BEHAV, V51, P504, DOI 10.1016/j.chb.2015.04.075
   FELDER RM, 1988, ENG EDUC, V78, P674
   Fraser J, 2015, PROCEDIA MANUF, V3, P626, DOI 10.1016/j.promfg.2015.07.285
   Gerjets P, 2009, COMPUT HUM BEHAV, V25, P360, DOI 10.1016/j.chb.2008.12.015
   Hwang GJ, 2015, COMPUT EDUC, V81, P13, DOI 10.1016/j.compedu.2014.09.006
   Jokinen JPP, 2015, INT J HUM-COMPUT ST, V76, P67, DOI 10.1016/j.ijhcs.2014.12.006
   Kim MJ, 2013, ENERG BUILDINGS, V66, P203, DOI 10.1016/j.enbuild.2013.07.049
   Lasa G, 2015, COMPUT HUM BEHAV, V52, P359, DOI 10.1016/j.chb.2015.06.015
   Law ELC, 2014, INT J HUM-COMPUT ST, V72, P523, DOI 10.1016/j.ijhcs.2014.03.003
   Law ELC, 2014, INT J HUM-COMPUT ST, V72, P526, DOI 10.1016/j.ijhcs.2013.09.006
   Lee LT, 2015, HUM-CENTRIC COMPUT I, V5, DOI 10.1186/s13673-015-0024-3
   Lin KM, 2011, COMPUT EDUC, V56, P515, DOI 10.1016/j.compedu.2010.09.017
   Ma R, 2014, SYSTEM, V43, P101, DOI 10.1016/j.system.2013.12.010
   Mampadi F, 2011, COMPUT EDUC, V56, P1003, DOI 10.1016/j.compedu.2010.11.018
   Mustafa Y.E. A., 2011, INT J LIB INFORM SCI, V3, P15
   Ortigosa A, 2010, COMPUT EDUC, V54, P999, DOI 10.1016/j.compedu.2009.10.003
   Özyurt Ö, 2015, COMPUT HUM BEHAV, V52, P349, DOI 10.1016/j.chb.2015.06.020
   Özyurt Ö, 2013, COMPUT HUM BEHAV, V29, P726, DOI 10.1016/j.chb.2012.11.013
   Özyurt Ö, 2013, EXPERT SYST APPL, V40, P2914, DOI 10.1016/j.eswa.2012.12.008
   Özyurt Ö, 2012, EXPERT SYST APPL, V39, P12092, DOI 10.1016/j.eswa.2012.04.018
   Paechter M, 2010, COMPUT EDUC, V54, P222, DOI 10.1016/j.compedu.2009.08.005
   Park J, 2013, INT J IND ERGONOM, V43, P187, DOI 10.1016/j.ergon.2013.01.005
   Peña-Ayala A, 2014, COMPUT HUM BEHAV, V30, P131, DOI 10.1016/j.chb.2013.07.057
   Cota MP, 2014, PROCEDIA COMPUT SCI, V27, P491, DOI 10.1016/j.procs.2014.02.053
   Shee DY, 2008, COMPUT EDUC, V50, P894, DOI 10.1016/j.compedu.2006.09.005
   Sun PC, 2008, COMPUT EDUC, V50, P1183, DOI 10.1016/j.compedu.2006.11.007
   van Doorn K, 2012, J BEHAV THER EXP PSY, V43, P1039, DOI 10.1016/j.jbtep.2012.05.001
   van Seters JR, 2012, COMPUT EDUC, V58, P942, DOI 10.1016/j.compedu.2011.11.002
NR 32
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13193
EP 13209
DI 10.1007/s11042-016-3292-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800014
DA 2024-07-18
ER

PT J
AU Kim, TY
   Kim, EJ
AF Kim, Tae-Yoon
   Kim, Eui-Jik
TI Multi-hop WBAN configuration approach for wearable machine-to-machine
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-hop; Network configuration; Sensor network; Wearable
   machine-to-machine; Wireless body area network
ID BODY AREA NETWORKS; POWER-CONTROL; HEALTH-CARE; TECHNOLOGIES
AB Machine-to-machine (M2M) technologies for wearable healthcare services are now being considered as a cutting-edge solution to provide care for the aging population that is rapidly growing. M2M systems consist of sensors, actuators, and communications modules that can achieve various purposes. With respect to communications, wireless body area networks (WBANs) are highly suitable communication technologies for wearable M2M. Most existing research for WBANs have mainly focused on a one-hop star network configuration due to their ease of implementation. However, in an environment with a real wearable M2M system, a multi-hop network can be a more suitable solution for communication due to its various advantages, including a low heat generation, low path loss, low inter-network interference, etc., despite the high difficulty in management. Therefore, we propose a multi-hop WBAN configuration approach (MWCA) for wearable M2M systems. MWCA improves network throughput by exploiting multi-channel communications, and it achieves high energy efficiency by reducing the transmission power of each M2M device. We also investigate the performance of MWCA by using an analytical model, which is validated through the use of experimental simulations.
C1 [Kim, Tae-Yoon] Korea Univ, Dept Elect Engn, 145 Anam Ro, Seoul 02855, South Korea.
   [Kim, Eui-Jik] Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
C3 Korea University; Hallym University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
EM ejkim32@hallym.ac.kr
OI Kim, Taeyoon/0000-0002-5623-3941
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2014R1A1A2057641]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2014R1A1A2057641).
CR Abid B, 2015, J SUPERCOMPUT, V71, P1678, DOI 10.1007/s11227-014-1241-7
   [Anonymous], 2012, 154E 2012 IEEE STAND, DOI [DOI 10.1109/IEEESTD.2012.6161600, DOI 10.1109/IEEESTD.2012.6185525]
   Boulis A, 2012, IEEE COMMUN MAG, V50, P100, DOI 10.1109/MCOM.2012.6194389
   Chiarini G, 2013, IEEE J SEL AREA COMM, V31, P6, DOI 10.1109/JSAC.2013.SUP.0513001
   Dohler M, 2014, IEEE COMMUN SURV TUT, V16, P1, DOI 10.1109/SURV.2014.012114.00000
   Dong J, 2014, IEEE ICC, P5676, DOI 10.1109/ICC.2014.6884226
   Hayajneh T, 2014, WIREL NETW, V20, P2165, DOI 10.1007/s11276-014-0736-8
   Kim EJ, 2012, IET COMMUN, V6, P2120, DOI 10.1049/iet-com.2011.0700
   Kim EJ, 2013, J SUPERCOMPUT, V65, P562, DOI 10.1007/s11227-012-0840-4
   Kim M, 2015, MULTIMED TOOLS APPL, V74, P3561, DOI 10.1007/s11042-013-1671-x
   Kwon JH, 2015, MULTIMED TOOLS APPL, V74, P1593, DOI 10.1007/s11042-013-1752-x
   Kyung Sup Kwak, 2009, 2009 9th International Symposium on Communications and Information Technology. ISCIT 2009, P834, DOI 10.1109/ISCIT.2009.5341126
   Latré B, 2011, WIREL NETW, V17, P1, DOI 10.1007/s11276-010-0252-4
   Lee W., 2009, Proceedings of the 5th Annual Workshop on Cyber Security and Information Intelligence Research, V12, P6, DOI DOI 10.1145/1558607.1558652
   Movassaghi S, 2014, IEEE COMMUN SURV TUT, V16, P1658, DOI 10.1109/SURV.2013.121313.00064
   Ohta N, 2013, IEEE J SEL AREA COMM, V31, P1, DOI 10.1109/JSAC.2013.SUP.0513000
   Pandit S, 2015, MULTIMED TOOLS APPL, V74, P5353, DOI 10.1007/s11042-014-1999-x
   Penders Julien, 2008, 2008 5th International Summer School and Symposium on Medical Devices and Biosensors, P94, DOI 10.1109/ISSMDBS.2008.4575026
   Rashwand S, 2011, GLOB TELECOMM CONF
   Smith Dennis B., 2011, Product-Focused Software Process Improvement. Proceedings 12th International Conference, PROFES 2011, DOI 10.1007/978-3-642-21843-9_1
   Xiao S, 2009, IEEE J SEL AREA COMM, V27, P37, DOI 10.1109/JSAC.2009.090105
NR 21
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12859
EP 12878
DI 10.1007/s11042-015-2832-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700033
DA 2024-07-18
ER

PT J
AU Zhang, YZ
   Zhang, M
   Wang, JN
   Zhang, G
AF Zhang, Yunzhou
   Zhang, Mo
   Wang, Jinnian
   Zhang, Gang
TI ICRS: inter-layer compression method combined with generation of a
   spatial image pyramid
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image pyramid; Re-sampling filter pair; Texture filtering; Interlayer
   compression
AB Currently, generating spatial image pyramid data mainly relies on down-sampling filtration, but so far, there is not any way to evaluate the effect of down-sampling. Herein, down-sampling and up-sampling were combined to form a pair of re-sampling filter, called RSFP, serving as an approximation of the current layer of pyramid data, can be used to evaluate the effect of the down-sampling filter. Based on RSFP, a pyramid-generating approach was built up in here, called it as TDFA. Its filtering depends on the texture direction of the pyramid image data. TDFA down-sampling PSNR was higher than the nearest neighbor interpolation, about 4.51-5.70 dB, while the latter was ever known the best down-sampling filter. The traditional JPEG compression method ignored the close correlations among the pyramid interlayer data, its compression process does not depend on the image texture features, which is not conducive to improving the compression ratio. The proposed RSFP and texture filtering method TDFA can effectively remove both correlations of pyramid image data, which respectively are the inter-layer correlations and its intra-layer texture correlations. Based on the re-sampling filter pair RSFP, combing these two means, an inter-layer compress method ICRS was created in this paper. Under the same reconstruction conditions, ICRS was found to increase the compression ratio 6.02 to 19.70 higher than the conventional AVS's I-frame algorithm, and on the whole, its compression ratio is 3 times or more high than that of JPEG algorithm, and there still is considerable room for improvement.
C1 [Zhang, Yunzhou; Zhang, Mo; Zhang, Gang] Taiyuan Univ Technol, Taiyuan 030024, Shanxi, Peoples R China.
   [Wang, Jinnian] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100080, Peoples R China.
C3 Taiyuan University of Technology; Chinese Academy of Sciences; The
   Institute of Remote Sensing & Digital Earth, CAS
RP Zhang, G (corresponding author), Taiyuan Univ Technol, Taiyuan 030024, Shanxi, Peoples R China.
EM tyzhgang@tom.com
FU Natural Science Foundation of Shanxi [2013011017-3]
FX This work was financially supported by Natural Science Foundation of
   Shanxi (Grant No. 2013011017-3).
CR Acharya T, 2005, IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS, P1, DOI 10.1002/0471745790
   Acharya T., 2004, JPEG2000 Standard for Image Compression: Concepts, Algorithms and VLSI Architectures
   Aggarwal HK, 2014, INT GEOSCI REMOTE SE, P2011, DOI 10.1109/IGARSS.2014.6946857
   AGRANOV G, 1995, VISUAL COMPUT, V11, P455, DOI 10.1007/BF02439642
   Baek M, 2014, P WORLD C ENG COMP S
   Bjorke JT, 2003, INT J GEOGR INF SCI, V17, P601, DOI 10.1080/1365881031000135500
   Chang L, 2004, P IEEE INT S CIRC SY, V3, P937
   Chen S., 2013, 3 INT WORKSH CLOUD C
   Dutton G, 1996, INT J GEOGR INF SYST, V10, P253, DOI 10.1080/026937996138034
   FEKETE G, 1990, PROCEEDINGS OF THE FIRST IEEE CONFERENCE ON VISUALIZATION - VISUALIZATION 90, P176
   GOODCHILD MF, 1992, INT J GEOGR INF SYST, V6, P31, DOI 10.1080/02693799208901893
   Guilbert E., 2014, Abstracting Geographic Information in a Data Rich World, P227, DOI 10.1007/978-3-319-00203-3_8
   Hirakawa K, 2005, IEEE T IMAGE PROCESS, V14, P360, DOI 10.1109/TIP.2004.838691
   Huang X, 2014, IEEE COMPUT SOC CONF, P455, DOI 10.1109/CVPRW.2014.73
   Klinger A., 1976, COMPUT VISION GRAPH, V5, P68, DOI [10.1016/S0146-664X(76)80006-8, DOI 10.1016/S0146-664X(76)80006-8]
   Pabi O, 2009, GHANA J GEOGR, V1, P115
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Sahr K., 2003, CARTOGR GEOGR INF SC, V30, P121, DOI [DOI 10.1559/152304003100011090, 10.1559/152304003100011090]
   Shen J, 2014, MULTIMED TOOLS APPL, V1-22
   SUN S, 2005, JVTP013
   Yuan H, 2014, IEEE T CIRC SYST VID, V24, P443, DOI 10.1109/TCSVT.2013.2280071
   Zimmer H, 2014, GEOMETRIC MODELING P, P1
NR 23
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 12077
EP 12099
DI 10.1007/s11042-015-3193-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200028
DA 2024-07-18
ER

PT J
AU Elgendy, F
   Sarhan, AM
   Eltobely, TE
   El-Zoghdy, SF
   El-sayed, HS
   Faragallah, OS
AF Elgendy, Fatma
   Sarhan, Amany M.
   Eltobely, Tarek E.
   El-Zoghdy, S. F.
   El-sayed, Hala S.
   Faragallah, Osama S.
TI Chaos-based model for encryption and decryption of digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Confusion; Diffusion; Security evaluation
ID TRANSFORM DOMAIN; HYPER-CHAOS; ALGORITHM; MAPS; SCHEME; CRYPTANALYSIS;
   SECURITY
AB This paper introduces a secure chaos-based model for ciphering and deciphering of digital images. The proposed approach is composed of successive confusion and diffusion stages. The confusion stage is repeated n rounds using a different key in each round. The output of the confusion stage is subjected to diffusion stage which is repeated m rounds with a different key for each round. The nested iterations in the confusion and diffusion stages with a different key for each round enlarges the key space which enhances the proposed image cryptosystem security level. A security investigation is done on a family of 2D chaotic confusion maps to select the one with highest security level to be used with the proposed image cryptosystem. The results demonstrated that the Standard map has the highest security level among the examined 2D chaotic confusion maps because it is more complicated and it has a large key space. The proposed image cryptosystem is compared to other three recent image cryptosystems using different security analysis factors including statistical tests, key space analysis, information entropy test, maximum deviation analysis, irregular deviation analysis, and avalanche effect differential analysis. The results demonstrated that, the proposed image cryptosystem with Standard map outperforms all of the other examined image encryption techniques from security point of view.
C1 [Elgendy, Fatma; Sarhan, Amany M.; Eltobely, Tarek E.] Fac Engn, Dept Computers & Automat Control Engn, Tanta, Egypt.
   [El-Zoghdy, S. F.] Menoufia Univ, Fac Sci, Dept Math & Comp Sci, Shibin Al Kawm, Egypt.
   [El-sayed, Hala S.] Menoufia Univ, Fac Engn, Dept Elect Engn, Shibin Al Kawm 32511, Egypt.
   [Faragallah, Osama S.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.
   [El-Zoghdy, S. F.; Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Menofia University; Egyptian Knowledge Bank (EKB); Menofia
   University; Taif University
RP Faragallah, OS (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia 32952, Egypt.; Faragallah, OS (corresponding author), Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Al Hawiya 21974, Saudi Arabia.
EM osam_sal@yahoo.com
RI Faragallah, Osama S./AHB-8031-2022; El-Sayed, Hala S./GXG-7641-2022;
   Sarhan, ِAmany/U-6091-2019
OI Faragallah, Osama S./0000-0003-1982-335X; El-Sayed, Hala
   S./0000-0002-2776-783X; Sarhan, ِAmany/0000-0002-0151-9619; El-Zoghdy,
   Said/0000-0002-5248-1067
CR Abuturab MR, 2013, OPT LASER ENG, V51, P317, DOI 10.1016/j.optlaseng.2012.09.008
   Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   Amin M, 2009, CHAOS SOLITON FRACT, V42, P767, DOI 10.1016/j.chaos.2009.02.001
   ASKAR SS, 2015, MATH PROBL ENG, P1, DOI DOI 10.1155/2015/341729
   Asmita Lade S, 2014, IJCSNS INT J COMPUT, V14
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   CRUTCHFIELD JP, 1988, IEEE T CIRCUITS SYST, V35, P770, DOI 10.1109/31.1821
   Elashry IF, J ELECT IMAGING, V18
   Elkamchouchi H., 2005, P 22 NAT RAD SCI C N, pC11
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gai S, 2013, NEUROCOMPUTING, V118, P171, DOI 10.1016/j.neucom.2013.02.029
   Gai S, 2013, AEU-INT J ELECTRON C, V67, P233, DOI 10.1016/j.aeue.2012.08.004
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Gao TG, 2008, PHYS LETT A, V372, P394, DOI 10.1016/j.physleta.2007.07.040
   Gong LH, 2013, J MOD OPTIC, V60, P1074, DOI 10.1080/09500340.2013.831139
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Huang CK, 2007, OPT COMMUN, V280, P300, DOI 10.1016/j.optcom.2007.08.052
   Hwang HE, 2012, OPT COMMUN, V285, P567, DOI 10.1016/j.optcom.2011.11.007
   Khan M, 2014, 3D RES, V5, DOI 10.1007/s13319-014-0029-0
   Kwok HS, 2007, CHAOS SOLITON FRACT, V32, P1518, DOI 10.1016/j.chaos.2005.11.090
   Li C, 2007, 2007339 IACRS CRYPT
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Lian SG, 2009, CHAOS SOLITON FRACT, V40, P2509, DOI 10.1016/j.chaos.2007.10.054
   Luo Y, 2012, J CONVERG INF TECHNO, V7, P3
   Mao Yaobin, 2003, INT J BIFURCATION CH
   Mishra M., 2014, INT J COMPUT SCI ENG, V4, P741
   Nien HH, 2007, CHAOS SOLITON FRACT, V32, P1070, DOI 10.1016/j.chaos.2005.11.057
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pisarchik AN, 2006, CHAOS, V16, DOI 10.1063/1.2242052
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Sathishkumar GA, 2011, COMM COM INF SC, V133, P290
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sun FY, 2008, CHAOS SOLITON FRACT, V38, P631, DOI 10.1016/j.chaos.2008.01.028
   Wang K, 2005, PHYS LETT A, V343, P432, DOI 10.1016/j.physleta.2005.05.040
   Wong KW, 2008, PHYS LETT A, V372, P2645, DOI 10.1016/j.physleta.2007.12.026
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Zhang LH, 2005, CHAOS SOLITON FRACT, V24, P759, DOI 10.1016/j.chaos.2004.09.035
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
   Ziedan I. E., 2003, Proceedings of the Twentieth National Radio Science Conference (NRSC'2003) (IEEE Cat. No.03EX665), pC16, DOI 10.1109/NRSC.2003.1217349
NR 42
TC 21
Z9 21
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 11529
EP 11553
DI 10.1007/s11042-015-2883-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900033
DA 2024-07-18
ER

PT J
AU Liang, MY
   Du, JP
   Li, LH
AF Liang, Meiyu
   Du, Junping
   Li, Linghui
TI Video super-resolution reconstruction based on correlation learning and
   spatio-temporal nonlocal similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video super-resolution; Semi-coupled dictionary learning;
   Spatio-temporal nonlocal similarity; Visual saliency; Pseudo-Zernike
   moment
ID IMAGE SUPERRESOLUTION
AB A novel video super-resolution reconstruction algorithm based on correlation learning and spatio-temporal nonlocal similarity is proposed in this paper. Objective high-resolution (HR) estimates of low-resolution (LR) video frames can be obtained by learning LR-HR correlation mapping and fusing the spatio-temporal nonlocal similarity information between video frames. First, the LR-HR correlation mapping between LR and HR patches is established based on semi-coupled dictionary learning. With the aim of improving algorithm efficiency while guaranteeing super-resolution quality, LR-HR correlation mapping is performed only for the salient object region, and then an improved visual saliency-based nonlocal fuzzy registration scheme using the pseudo-Zernike moment feature and structural similarity is proposed for spatio-temporal similarity matching and fusion. Visual saliency and self-adaptive regional correlation evaluation strategies are used in spatio-temporal similarity matching to improve algorithm efficiency further. Experimental results demonstrate that the proposed algorithm achieves competitive super-resolution quality compared to other state-of-the-art algorithms in terms of both subjective and objective evaluations.
C1 [Liang, Meiyu; Du, Junping; Li, Linghui] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Du, JP (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing Key Lab Intelligent Telecommun Software &, Beijing 100876, Peoples R China.
EM junpingdu@126.com
FU National Basic Research Program of China (973 Program) [2012CB821200,
   2012CB821206]; National Natural Science Foundation of China
   [61320106006, 61532006, 61502042]
FX This work was supported by National Basic Research Program of China (973
   Program) 2012CB821200 (2012CB821206) and the National Natural Science
   Foundation of China (No. 61320106006, No. 61532006, No. 61502042).
CR Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen J, 2012, IEEE SIGNAL PROC LET, V19, P63, DOI 10.1109/LSP.2011.2178595
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1382, DOI 10.1109/TIP.2012.2231086
   Dowson N, 2011, IEEE T PATTERN ANAL, V33, P485, DOI 10.1109/TPAMI.2010.114
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Gao XB, 2011, IEEE T IMAGE PROCESS, V20, P2738, DOI 10.1109/TIP.2011.2134859
   Giachetti A, 2012, IEEE T IMAGE PROCESS, V21, P2361, DOI 10.1109/TIP.2012.2186739
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   Jiang JJ, 2014, MULTIMED TOOLS APPL, V72, P2573, DOI 10.1007/s11042-013-1567-9
   Lin DH, 2005, IEEE I CONF COMP VIS, P1699
   Liu C, 2014, IEEE T PATTERN ANAL, V36, P346, DOI 10.1109/TPAMI.2013.127
   Maalouf A, 2012, IET IMAGE PROCESS, V6, P168, DOI 10.1049/iet-ipr.2010.0275
   Mudenagudi U, 2011, IEEE T PATTERN ANAL, V33, P995, DOI 10.1109/TPAMI.2010.167
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Salvador J, 2013, SIGNAL PROCESS-IMAGE, V28, P483, DOI 10.1016/j.image.2013.02.002
   Su H, 2012, IEEE T IMAGE PROCESS, V21, P1031, DOI 10.1109/TIP.2011.2166971
   Su KL, 2005, 2005 IEEE International Workshop on Safety, Security and Rescue Robots, P1
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang JC, 2013, PROC CVPR IEEE, P1059, DOI 10.1109/CVPR.2013.141
   Yang JC, 2012, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2012.6247948
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhou F, 2012, IEEE T CONSUM ELECTR, V58, P891, DOI 10.1109/TCE.2012.6311333
   Zhou L, 2014, MULTIMED TOOLS APPL, V71, P1879, DOI 10.1007/s11042-012-1311-x
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zhu Y, 2014, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR.2014.373
NR 32
TC 5
Z9 5
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10241
EP 10269
DI 10.1007/s11042-015-2952-3
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800008
DA 2024-07-18
ER

PT J
AU Sakamoto, M
   Alexandrova, T
   Nakajima, T
AF Sakamoto, Mizuki
   Alexandrova, Todorka
   Nakajima, Tatsuo
TI Analyzing the influence of virtuality on playful social interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ambient intelligence; Virtuality; Realness; Social interaction;
   Gamefullness; Game design; Tangibility; Persuasive affordance
AB Ambient intelligence technologies are making our daily life increasingly virtual, and the boundary between the real world and the virtual world is gradually disappearing. Computer games are often played on the Internet, which allows people to enjoy games with others, even when they are not at the same location. This paper analyzes the Trading Card Game (TCG), which has two versions. One version is played with paper-based cards, whereas the other is played on a computer. The computer-based TCG supports remote play and has a number of enhancements, such as providing special fictional effects on virtual cards. The two different versions are useful to analyze the influence of virtuality in making future social interaction more playful. First, we investigate potential pitfalls to introduce virtuality in TCG through the scenario-based analysis, which adopts a player's personality to exploit potential difficulties. For investigating further insights on the influence of virtuality in TCG, we analyze some experiments with Augmented Trading Card Game, where a real opponent player is replaced with a fictional player. Our findings from the analyses show that the feeling of realness is essential to make incorporated virtuality successful. Recently some games' concepts can be adopted in order to augment our real world. It is essential to investigate the influence of virtuality introduced with the games. The future social interaction will incorporate virtuality based on a variety of game-like features to make the interaction more playful. Therefore, the insights described in this paper will be useful to help the design of future playful social interaction.
C1 [Sakamoto, Mizuki; Alexandrova, Todorka; Nakajima, Tatsuo] Waseda Univ, Dept Comp Sci & Engn, Tokyo, Japan.
C3 Waseda University
RP Nakajima, T (corresponding author), Waseda Univ, Dept Comp Sci & Engn, Tokyo, Japan.
EM mizuki@dcl.cs.waseda.ac.jp; toty@dcl.cs.waseda.ac.jp;
   tatsuo@dcl.cs.waseda.ac.jp
OI Alexandrova, Todorka/0000-0001-5765-8581
CR [Anonymous], 2005, P HUM 2005 WORKSH VI
   [Anonymous], 2014, INT J SMART HOME
   [Anonymous], METAPRODUCTS BUILDIN
   [Anonymous], P ACM C COMP SUPP CO
   Antikainen Maria J., 2010, International Journal of Entrepreneurship and Innovation Management, V11, P440, DOI 10.1504/IJEIM.2010.032267
   Bandai Character Research Center, 2001, 2 BAND CHAR RES CTR
   Bartle Richard., 2003, Virtual Worlds: Why People Play. Designing Virtual Worlds
   Baskinger M, 2010, TANGIBLE INTERACTION
   Baudrillard Jean., 1998, CONSUMER SOC MYTHS S
   Beyer Hugh., 1999, CONTEXTUAL DESIGN
   Bogost I., 2007, Persuasive game: the expressive power of videogames
   Cooper A., 2007, FACE 3 ESSENTIALS IN
   Deci EL, 2000, PSYCHOL INQ, V11, P227, DOI 10.1207/S15327965PLI1104_01
   Deterding S., 2011, P 15 INT AC MINDTREK, P9, DOI [10.1145/2181037.2181040, DOI 10.1145/2181037.2181040]
   Ducatel K., 2001, SCENARIOS AMBIENT IN
   Horney K., 1994, SELF ANAL
   Iwata T, 2011, P 17 IEEE C EMB REAL
   Jordan P.W., 2002, Designing pleasurable products: An introduction to the new human factors
   Lehdonvirta V, 2009, PUBLICATIONS TURKU A
   Magerkurth C, 2005, ACM COMPUT ENTERTAIN, V3
   Marzano S., 2003, The new everyday view on ambient intelligence
   Messaris P., 1997, Visual Persuasion: The Role of Images in Advertising
   Nakajima T, 2013, PERS UBIQUIT COMPUT, V17, P107, DOI 10.1007/s00779-011-0469-y
   Nettle D., 2009, PERSONALITY WHAT MAK
   Ruth M., 2007, PRODUCT EXPERIENCE
   RYAN FL, 1979, J EXP EDUC, V47, P215, DOI 10.1080/00220973.1979.11011684
   Sakamoto M, 2014, P INT C INT POL POL
   Sakamoto M, 2015, 2015001 WAS U DCL
   Sakamoto M., 2015, P 4 INT C DES US EXP
   Sakamoto M., 2013, P 6 INT C ADV COMP H
   Sakamoto M, 2014, INT J HYBRID TECHNOL, V7
   Sakamoto M., 2015, P 9 INT C DES SEM FO
   Sakamoto M, 2015, MULTIMED TOOLS APPL, V74, P11537, DOI 10.1007/s11042-014-2250-5
   Stark Lizzie., 2012, Leaving Mundania: Inside the Transformative World of Live Action Role- Playing Games
   Suri J.F., 2005, THOUGHTLESS ACTS
   Turner P, 2005, INTERACT COMPUT, V17, P787, DOI 10.1016/j.intcom.2005.04.003
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
   Zappen JP, 2005, TECH COMMUN Q, V14, P319, DOI 10.1207/s15427625tcq1403_10
   Zichermann G., 2011, GAMIFICATION DESIGN
NR 39
TC 7
Z9 7
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8289
EP 8317
DI 10.1007/s11042-015-2751-x
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300008
DA 2024-07-18
ER

PT J
AU Mohanty, M
   Ooi, WT
   Atrey, PK
AF Mohanty, Manoranjan
   Ooi, Wei Tsang
   Atrey, Pradeep K.
TI Secret sharing approach for securing cloud-based pre-classification
   volume ray-casting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Shamir's secret sharing; Cloud-based imaging;
   Volume ray-casting
AB With the evolution in cloud computing, cloud-based volume rendering, which outsources data rendering tasks to cloud datacenters, is attracting interest. Although this new rendering technique has many advantages, allowing third-party access to potentially sensitive volume data raises security and privacy concerns. In this paper, we address these concerns for cloud-based pre-classification volume ray-casting by using Shamir's (k, n) secret sharing and its variant (l, k, n) ramp secret sharing, which are homomorphic to addition and scalar multiplication operations, to hide color information of volume data/images in datacenters. To address the incompatibility issue of the modular prime operation used in secret sharing technique with the floating point operations of ray-casting, we consider excluding modular prime operation from secret sharing or converting the floating number operations of ray-casting to fixed point operations - the earlier technique degrades security and the later degrades image quality. Both these techniques, however, result in significant data overhead. To lessen the overhead at the cost of high security, we propose a modified ramp secret sharing scheme that uses the three color components in one secret sharing polynomial and replaces the shares in floating point with smaller integers.
C1 [Mohanty, Manoranjan] SICS Swedish ICT, Secur Lab, Kista, Sweden.
   [Ooi, Wei Tsang] Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
   [Atrey, Pradeep K.] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA.
C3 RISE Research Institutes of Sweden; National University of Singapore;
   State University of New York (SUNY) System; State University of New York
   (SUNY) Albany
RP Mohanty, M (corresponding author), SICS Swedish ICT, Secur Lab, Kista, Sweden.
EM manoranjan.jnu@gmail.com; ooiwt@comp.nus.edu.sg; patrey@albany.edu
RI Moahnty, Manoranjan/ABG-3544-2020; Ooi, Wei Tsang/HLW-5142-2023; Ooi,
   Wei Tsang/AAE-7810-2019
OI Moahnty, Manoranjan/0000-0002-0258-4586; Ooi, Wei
   Tsang/0000-0001-8994-1736; Ooi, Wei Tsang/0000-0001-8994-1736
FU Singapore Ministry of Education [T 1251RES1213]; NSERC Canada [371714];
   University at Albany [640075]
FX This research was supported by Singapore Ministry of Education Academic
   Research Fund Tier 1 No: T 1251RES1213 (Secure and Efficient Remote 3D
   Rendering). Majority of this work was done when the first author,
   Manoranjan Mohanty, was a PhD student in Department of Computer Science,
   School of Computing, National University of Singapore. Dr. Atrey's
   contribution was supported in parts by the NSERC Canada discovery grant
   number 371714 and the University at Albany grant number 640075.
CR AlZain M. A., 2012, 2012 45th Hawaii International Conference on System Sciences (HICSS), P5490, DOI 10.1109/HICSS.2012.153
   [Anonymous], THESIS
   [Anonymous], 2009, Cloud security and privacy: an enterprise perspective on risks and compliance
   Benaloh JC, 1987, P ADV CRYPT SAN BARB, P31
   Catrina O, 2010, LECT NOTES COMPUT SC, V6052, P35, DOI 10.1007/978-3-642-14577-3_6
   Chor B., 1993, Journal of Cryptology, V6, P87, DOI 10.1007/BF02620136
   Cooper J.A., 1994, Bulletin of the ICA, V12, P33
   Dorn K, 2011, EUROMICRO CONF PROC, P155, DOI 10.1109/SEAA.2011.31
   Fellgiebel A, 2005, NEUROBIOL AGING, V26, P1193, DOI 10.1016/j.neurobiolaging.2004.11.006
   Finamore T, 2012, THESIS
   Harn L, 2010, IEEE T COMPUT, V59, P842, DOI 10.1109/TC.2010.40
   Kamara S, 2010, LECT NOTES COMPUT SC, V6054, P136, DOI 10.1007/978-3-642-14992-4_13
   KDDI Inc, 2012, MED REAL TIM 3D IM S
   Lathey A, 2013, IEEE INT C SEMANT CO, P310, DOI 10.1109/ICSC.2013.60
   Lauter K, 2011, PROCEEDINGS OF THE 3RD ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'11), P113
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Mohanty M., 2013, THESIS
   Mohanty M, 2013, P IEEE INT C CLOUD C
   Mohanty M., 2012, Proceedings of the 20th ACM international conference on Multimedia, P1105
   NICE, 2011, DESKT CLOUD VIS
   NVIDIA, 2009, REAL 3 0 WHIT PAP
   Parsonson L., 2012, Cloud Computing and Services Science, P207
   SaghaianNejadEsfahani SM, 2012, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2012.6466843
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Sinha System, 2012, CLOUD BAS MED IM MAN
   Smelyanskiy M, 2009, IEEE T VIS COMPUT GR, V15, P1563, DOI 10.1109/TVCG.2009.164
   Tharaud Jeremie, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P510, DOI 10.1109/IIHMSP.2010.130
   Vazhenin D., 2012, P JOINT INT C HUM CT, P240
   Zissis D, 2012, FUTURE GENER COMP SY, V28, P583, DOI 10.1016/j.future.2010.12.006
NR 29
TC 9
Z9 9
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6207
EP 6235
DI 10.1007/s11042-015-2567-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700009
DA 2024-07-18
ER

PT J
AU Yang, Y
   Sheng, B
   Wu, W
   Cheng, ZH
   Shen, RM
AF Yang, Yi
   Sheng, Bin
   Wu, Wen
   Cheng, Zezhou
   Shen, Ruimin
TI Image saliency detection based on rectangular-wave spectrum analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Rectangular wave; Spectrum analysis; Response
   matrix.
ID VISUAL-ATTENTION; COLOR
AB Saliency detection is widely used in the fields of computer graphics and multimedia processing. Many computer graphics tasks, such as image segmentation, image labeling, and tracking, rely on the accurate generation of saliency maps. However, most current methods lack the ability to generate a fine boundary between the foreground and background while also providing a high recall rate. The saliency detection algorithm proposed in this paper is based on rectangular-wave spectrum analysis. In this method, we divide a given image into several regions, which are then convoluted using a pre-set rectangular-wave template. We determine the final saliency value by calculating the difference between a region and its adjacent regions, and its uniqueness compared with the entire image. Repeated tests using different data sets produced a high accuracy-recall rate. Moreover, the boundary in our saliency map is clear and fine.
C1 [Yang, Yi; Sheng, Bin; Cheng, Zezhou; Shen, Ruimin] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
   [Wu, Wen] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 Shanghai Jiao Tong University; University of Macau
RP Sheng, B (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM shengbin@cs.sjtu.edu.cn
FU National Natural Science Foundation of China [61202154, 61133009];
   National Key Technology RD Program [2012BAH55F02]; National Basic
   Research Project of China [2011CB302203]; Shanghai Pujiang Program
   [13PJ1404500]; Science and Technology Commission of Shanghai
   Municipality Program [13511505000]; Open Projects Program of National
   Laboratory of Pattern Recognition; Open Project Program of the State Key
   Lab of CADAMP;CG, Zhejiang University [A1401]
FX The authors would like to thank all reviewers for their helpful
   suggestions and constructive comments. The work is supported by the
   National Natural Science Foundation of China (No. 61202154, 61133009),
   National Key Technology R&D Program (No. 2012BAH55F02), the National
   Basic Research Project of China (No. 2011CB302203), Shanghai Pujiang
   Program (No. 13PJ1404500), the Science and Technology Commission of
   Shanghai Municipality Program (No. 13511505000), the Open Projects
   Program of National Laboratory of Pattern Recognition, and the Open
   Project Program of the State Key Lab of CAD&CG (Grant No. A1401),
   Zhejiang University.
CR Achanta R, 2009, CVPR, P409
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2005, Advances in neural information processing systems, DOI DOI 10.5555/2976248.2976268
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2008, CVPR
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Judd T, 2009, ICCV, V3, P9
   Kennedy R, 2011, CVPR
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang QR, 2010, J COMPUT, V5, P1011, DOI 10.4304/jcp.5.7.1011-1018
   Zhao H, 2014, MMSJ
NR 22
TC 1
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2016
VL 75
IS 11
BP 6173
EP 6187
DI 10.1007/s11042-015-2565-x
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DP5QZ
UT WOS:000378553700007
DA 2024-07-18
ER

PT J
AU Battiato, S
   Farinella, GM
   Giudice, O
   Puglisi, G
AF Battiato, Sebastiano
   Farinella, Giovanni Maria
   Giudice, Oliver
   Puglisi, Giovanni
TI Aligning shapes for symbol classification and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shape recognition; Shape retrieval; Symbol classification; Alignment
ID REPRESENTATION; RECOGNITION; IMAGE
AB This paper proposes a method able to exploit peculiarities of both, local and global shape descriptors, to be employed for shape classification and retrieval. In the proposed framework, the silhouettes of symbols are firstly described through Bags of Shape Contexts. The shape signature is then used to solve the correspondence problem between points of two shapes. The obtained correspondences are employed to recover the geometric transformations between the shape to be classified/retrieved and the ones belonging to the training dataset. The alignment is based on a voting procedure in the parameter space of the model considered to recover the geometric transformation. The aligned shapes are finally described with the Blurred Shape Model descriptor for classification and retrieval purposes. Experimental results demonstrate the effectiveness of the proposed solution on two classic benchmark shape datasets, as well as on a large scale set of hand sketches composed by 20,000 examples distributed over 250 object categories.
C1 [Battiato, Sebastiano; Farinella, Giovanni Maria; Giudice, Oliver] Univ Catania, Dept Math & Comp Sci, Image Proc Lab, Catania, Italy.
   [Puglisi, Giovanni] Univ Cagliari, Dipartimento Matemat & Informat, Cagliari, Italy.
C3 University of Catania; University of Cagliari
RP Giudice, O (corresponding author), Univ Catania, Dept Math & Comp Sci, Image Proc Lab, Catania, Italy.
EM battiato@dmi.unict.it; gfarinella@dmi.unict.it; giudice@dmi.unict.it;
   puglisi@unica.it
RI Battiato, Sebastiano/O-7799-2019; Giudice, Oliver/V-7713-2019; Battiato,
   Sebastiano/ABI-1584-2020; FARINELLA, Giovanni Maria/L-8555-2015
OI Giudice, Oliver/0000-0002-8343-2049; Battiato,
   Sebastiano/0000-0001-6127-2470; FARINELLA, Giovanni
   Maria/0000-0002-6034-0432
CR [Anonymous], C COMP VIS PATT REC
   [Anonymous], ACM SIGGRAPH
   Azzaro G, 2011, J DAIRY SCI, V94, P2126, DOI 10.3168/jds.2010-3467
   Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188
   Battiato S, 2012, INT C PATT RECOG, P1598
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Costa LD, 2009, IMAGE PROCESS SER, P1
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Escalera S, 2011, IEEE T SYST MAN CY B, V41, P497, DOI 10.1109/TSMCB.2010.2060481
   Farinella GM, 2006, LECT NOTES COMPUT SC, V4190, P776
   Jia Q, 2014, PATTERN RECOGN LETT, V40, P128, DOI 10.1016/j.patrec.2013.11.003
   Kart-Leong Lim, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P115, DOI 10.1109/PSIVT.2010.26
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Marr D., 1982, Visual perception
   Mcneill G., 2006, IEEE COMPUTER SOC C, V1, P885
   Munder S, 2008, IEEE T INTELL TRANSP, V9, P333, DOI 10.1109/TITS.2008.922943
   Puglisi G, 2011, IEEE T CIRC SYST VID, V21, P1390, DOI 10.1109/TCSVT.2011.2162689
   Qi GJ, 2011, PROC CVPR IEEE, P841, DOI 10.1109/CVPR.2011.5995378
   Tirkaz C, 2012, PATTERN RECOGN, V45, P3926, DOI 10.1016/j.patcog.2012.04.026
   Velasco-Forero Santiago, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3537, DOI 10.1109/ICPR.2010.863
   Wang B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P983, DOI 10.1109/ICPR.2010.246
   Wang JW, 2012, PATTERN RECOGN LETT, V33, P134, DOI 10.1016/j.patrec.2011.09.042
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
NR 25
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5513
EP 5531
DI 10.1007/s11042-015-2523-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600008
DA 2024-07-18
ER

PT J
AU Boato, G
   Dang-Nguyen, DT
   Muratov, O
   Alajlan, N
   De Natale, FGB
AF Boato, Giulia
   Duc-Tien Dang-Nguyen
   Muratov, Oleg
   Alajlan, Naif
   De Natale, Francesco G. B.
TI Exploiting visual saliency for increasing diversity of image retrieval
   results
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual saliency; Content-based image retrieval; Diversity
ID SEARCH
AB Diversification of search results allows for better and faster search, gaining knowledge about different perspectives and viewpoints on retrieved information sources. Recently various methods for diversification of image retrieval results have been proposed, mainly using textual information or techniques imported from the natural language processing domain. However, images contain much more information than their textual descriptions and the use of visual features deserves special attention in this context. Visual saliency provides information about parts of the image perceived as most important, which are instinctively targeted by humans when shooting a photo or looking at a picture. For this reason we propose to exploit such information to improve diversification of search results. To this purpose, we introduce a saliency-based method to re-rank the results of a query and we show that it can achieve significantly better performances as compared to the baseline approach. Experimental validation conducted on a number of queries applied to various datasets demonstrates the potential of the use of saliency information for the diversification of image retrieval results.
C1 [Boato, Giulia; Duc-Tien Dang-Nguyen; Muratov, Oleg; De Natale, Francesco G. B.] Univ Trento, Dept Informat Engn & Comp Sci, Via Sommarive 9, Trento, Italy.
   [Alajlan, Naif] King Saud Univ, Coll Comp & Informat Sci, Riyadh 11543, Saudi Arabia.
C3 University of Trento; King Saud University
RP Boato, G (corresponding author), Univ Trento, Dept Informat Engn & Comp Sci, Via Sommarive 9, Trento, Italy.
EM boato@disi.unitn.it
RI Alajlan, Naif/A-3904-2008
OI Alajlan, Naif/0000-0003-1846-1131
FU Deanship of Scientific Research of the King Saud University [IRG14-20]
FX This work was supported by the Deanship of Scientific Research of the
   King Saud University through the International Research Group under
   Project IRG14-20.
CR [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   [Anonymous], MEDIAEVAL BENCHMARKI
   Carbonell J, 1998, ACM SIGIR C RES DEV
   Clarke C, 2011, ACM INT C WEB SEARCH
   Dang-Nguyen DT, 2014, MEDIAEVAL BENCHMARKI
   Deselaers T, 2009, ACM INT C IM VID RET
   Gelasca E, 2005, INT WORKSH VID PROC
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hoiem D, 2005, IEEE I CONF COMP VIS, P654
   Huang J, 2011, IEEE T MULTIMEDIA, V13, P653, DOI 10.1109/TMM.2011.2127463
   Kennedy LS, 2008, ACM INT C WORLD WID
   Koehler K, 2014, J VISION, V14, DOI 10.1167/14.3.14
   Leung T., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1010, DOI 10.1109/ICCV.1999.790379
   Li H, 2008, ACM INT C MULT
   Li J, 2012, INT C MACH LEARN CYB
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Muratov O, 2011, IEEE INT C AC SPEECH
   Paramita ML, 2009, INT C CROSS LANG EV
   Ramanathan S, 2010, EUR C COMP VIS
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Rudinac S, 2013, IEEE T MULTIMEDIA, V15, P921, DOI 10.1109/TMM.2013.2237896
   Sanderson M, 2009, EUR C INF RETR
   Shi R, 2012, IEEE SIGNAL PROC LET, V19, P215, DOI 10.1109/LSP.2012.2188388
   Song K, 2006, ACM INT C MULT
   Subramanian Ramanathan., 2011, Proceedings of the 19th ACM International Conference on Multimedia, P33
   Tollari S, 2009, WORKSH CROSS LANG EV
   van Leuken RH, 2009, ACM INT C WORLD WID
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Yu ZQ, 2014, IEEE T VIS COMPUT GR, V20, P182, DOI 10.1109/TVCG.2013.106
   Zontone P, 2010, P 2010 WORKSH SUPP A, P88
   Zontone P, 2009, LIV WEB WORKSH
   Zwol RV, 2008, ACM INT C MULT INF R
NR 32
TC 10
Z9 11
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5581
EP 5602
DI 10.1007/s11042-015-2526-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600011
DA 2024-07-18
ER

PT J
AU Hong, CP
AF Hong, Chung-Pyo
TI A locality-aware resource management scheme for the hierarchical P2P
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DHT; Locality; Mobile; Peer-to-peer; Resource management; Ubiquitous
   computing
AB In distributed, ubiquitous computing environments, peer-to-peer (p2p) systems have been studied. Distributed hash table (DHT)-based p2p systems can improve load-balancing even though locality utilization and user mobility are not guaranteed. We propose a mobile locality-based hierarchical p2p overlay network (MLH-Net) to address locality problems without any other services. MLH-Net utilizes mobility features in a mobile environment. MLH-Net is constructed as two layers, an upper layer formed with super-nodes and a lower layer formed with normal-nodes. Because super-nodes can share advertisements, we can guarantee physical locality utilization between a requestor and a target during any discovery process. The simulation results demonstrate that the proposed scheme can reduce the discovery routing distance by 21 %, and 45 % compared with JXTA depending on the given number of max-hop.
C1 [Hong, Chung-Pyo] Yonsei Univ, Sch Engn, Dept Comp Sci, C532,Shinchon Dong 134, Seoul 120749, South Korea.
C3 Yonsei University
RP Hong, CP (corresponding author), Yonsei Univ, Sch Engn, Dept Comp Sci, C532,Shinchon Dong 134, Seoul 120749, South Korea.
EM hulkboy@yonsei.ac.kr
CR [Anonymous], JAV PROGR GUID
   Halepovic E, 2003, THIRD INTERNATIONAL CONFERENCE ON PEER-TO-PEER COMPUTING (P2P2003), PROCEEDINGS, P160, DOI 10.1109/PTP.2003.1231516
   Halepovic E, 2003, 2003 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS, AND SIGNAL PROCESSING, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P149
   Harvey NJA, 2003, USENIX ASSOCIATION PROCEEDINGS OF THE 4TH USENIX SYMPOSIUM ON INTERNET TECHNOLOGIES AND SYSTEMS (USITS'03), P113
   Hsiao R, 2004, 24TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, PROCEEDINGS, P534, DOI 10.1109/ICDCSW.2004.1284084
   Ratnasamy S, 2001, ACM SIGCOMM COMP COM, V31, P161, DOI 10.1145/964723.383072
   Rowstron A., 2001, Proceedings of the Middleware 2001, P329, DOI DOI 10.1007/3-540-45518-3_18
   Shin K, 2002, INT CONF PARA PROC, P159, DOI 10.1109/ICPPW.2002.1039726
   Stoica I, 2001, ACM SIGCOMM COMP COM, V31, P149, DOI 10.1145/964723.383071
   Torkestani JA, 2013, APPL ARTIF INTELL, V27, P575, DOI 10.1080/08839514.2013.813181
   Zhao BY, 2004, IEEE J SEL AREA COMM, V22, P41, DOI 10.1109/JSAC.2003.818784
   Zhao BY, 2002, LECT NOTES COMPUT SC, V2429, P34
   Zhou H, 2013, LECT NOTE ELECT ENG, V210, P441
NR 13
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5013
EP 5027
DI 10.1007/s11042-014-1854-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700011
DA 2024-07-18
ER

PT J
AU Ren, B
   Wang, LB
   Lu, L
   Ueda, Y
   Kai, A
AF Ren, Bo
   Wang, Longbiao
   Lu, Liang
   Ueda, Yuma
   Kai, Atsuhiko
TI Combination of bottleneck feature extraction and dereverberation for
   distant-talking speech recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distant-talking speech recognition; Denoising autoencoder; Bottleneck
   feature; Dereverberation
ID NEURAL-NETWORKS; NECK FEATURES; IDENTIFICATION
AB The performance of speech recognition in distant-talking environments is severely degraded by the reverberation that can occur in enclosed spaces (e.g., meeting rooms). To mitigate this degradation, dereverberation techniques such as network structure-based denoising autoencoders and multi-step linear prediction are used to improve the recognition accuracy of reverberant speech. Regardless of the reverberant conditions, a novel discriminative bottleneck feature extraction approach has been demonstrated to be effective for speech recognition under a range of conditions. As bottleneck feature extraction is not primarily designed for dereverberation, we are interested in whether it can compensate for other carefully designed dereverberation approaches. In this paper, we propose three schemes covering both front-end processing (cascaded combination and parallel combination) and back-end processing (system combination). Each of these schemes integrates bottleneck feature extraction with dereverberation. The effectiveness of these schemes is evaluated via a series of experiments using the REVERB challenge dataset.
C1 [Ren, Bo; Wang, Longbiao] Nagaoka Univ Technol, 1603-1 Kamitomioka, Nagaoka, Niigata 9402188, Japan.
   [Lu, Liang] Univ Edinburgh, Ctr Speech Technol Res, Edinburgh, Midlothian, Scotland.
   [Ueda, Yuma; Kai, Atsuhiko] Shizuoka Univ, Naka Ku, 3-5-1 Johoku, Hamamatsu, Shizuoka 4328561, Japan.
C3 Nagaoka University of Technology; University of Edinburgh; Shizuoka
   University
RP Wang, LB (corresponding author), Nagaoka Univ Technol, 1603-1 Kamitomioka, Nagaoka, Niigata 9402188, Japan.
EM wang@vos.nagaokaut.ac.jp; liang.lu@ed.ac.uk; kai@sys.eng.shizuoka.ac.jp
RI ren, bo/IST-0814-2023
FU JSPS KANKENHI [15K16020]; Grants-in-Aid for Scientific Research
   [15K16020] Funding Source: KAKEN
FX This work was supported by JSPS KANKENHI Grant Number 15K16020.
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   [Anonymous], J SIGNAL PROCESS SYS
   [Anonymous], 2011, P INT C FLOR IT 27 3, DOI DOI 10.5555/3042573.3042574
   [Anonymous], 2000, P SPEECH TRANSCR WOR
   FURUI S, 1981, IEEE T ACOUST SPEECH, V29, P254, DOI 10.1109/TASSP.1981.1163530
   Gesbert D, 1997, INT CONF ACOUST SPEE, P3621, DOI 10.1109/ICASSP.1997.604650
   Grézl F, 2008, INT CONF ACOUST SPEE, P4729, DOI 10.1109/ICASSP.2008.4518713
   Grézl F, 2007, INT CONF ACOUST SPEE, P757
   Hermansky H, 2000, INT CONF ACOUST SPEE, P1635, DOI 10.1109/ICASSP.2000.862024
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Ishii T., 2013, INTERSPEECH, P3512
   Kinoshita K, 2009, IEEE T AUDIO SPEECH, V17, P1, DOI 10.1109/TASL.2008.2009015
   Kinoshita T, 2013, 2013 9TH INTERNATIONAL WORKSHOP ON ELECTROMAGNETIC COMPATIBILITY OF INTEGRATED CIRCUITS (EMC COMPO 2013), P1, DOI 10.1109/EMCCompo.2013.6735162
   Lal P, 2013, IEEE T AUDIO SPEECH, V21, P2506, DOI 10.1109/TASL.2013.2277932
   Liang L, 2014, P ANN C INT SPEECH C
   Liu F-H, 1993, P WORK HUM LANG TECH
   Ney H., 2012, P ANN C INT SPEECH C
   Quoc Bao Nguyen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5607, DOI 10.1109/ICASSP.2014.6854676
   Sainath TN, 2012, INT CONF ACOUST SPEE, P4153, DOI 10.1109/ICASSP.2012.6288833
   Sak H., 2014, ARXIV14021128CSSTAT
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang L, 2012, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2012-115
   Wang LB, 2011, IEICE T INF SYST, VE94D, P659, DOI 10.1587/transinf.E94.D.659
   Wang Longbiao, 2014, APSIPA ASC
   Yamada T, 2013, INTERSPEECH, P3628
   Yu D, 2010, NIPS WORK DEEP LEARN
   Yu D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P244
   Zhang XJ, 2014, INTERSPEECH, P1386
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
   Zhang ZF, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-15
NR 32
TC 9
Z9 9
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5093
EP 5108
DI 10.1007/s11042-015-2849-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700016
DA 2024-07-18
ER

PT J
AU Xiong, LZ
   Xu, ZQ
   Xu, YY
AF Xiong, Lizhi
   Xu, Zhengquan
   Xu, Yanyan
TI A multiple watermarking scheme based on orthogonal decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple watermarking; Orthogonal decomposition; Security; Multimedia
   distribution
AB This paper proposes a novel multiple watermarking scheme based on orthogonal decomposition (MWOD). In the first phase, based on orthogonal decomposition, the host data selected from multimedia data are divided into mutually independent multiple domains. Then multiple watermarks without need for considering the special correlation among them can respectively be embedded into these different domains even using different embedding algorithms. There is no mutual interference among watermarked domains so that multiple watermarks can be flexibly embedded in the distribution of the multimedia cover. Through theoretical analysis, the security of multiple watermarking operands is validated, which means that MWOD can ensure the security of watermarking operation domains. Therefore, media providers and service providers can embed their unique information step-by-step into digital multimedia using their own operation domain keys in MWOD, which can be used to identify media content's ownership or trace the illegal redistributors. Experimental results and analysis demonstrate the feasibility and robustness of MWOD.
C1 [Xiong, Lizhi; Xu, Zhengquan; Xu, Yanyan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
C3 Wuhan University
RP Xu, ZQ (corresponding author), Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, 129 Luoyu Rd, Wuhan 430079, Peoples R China.
EM xlzwhucs@gmail.com; xuzq@whu.edu.cn; xuyy@whu.edu.cn
RI Xiong, Lizhi/KCK-1464-2024
FU National Basic Research Program of China (973 Program) [2011CB302306,
   2011CB302204]; National Natural Science Foundation of China [41371402,
   41101416]; Research Fund for Doctoral Program of Higher Education of
   China [20110141110056]
FX This work was supported by the National Basic Research Program of China
   (973 Program) under Grant 2011CB302306, 2011CB302204, the National
   Natural Science Foundation of China under Grant 41371402, 41101416 and
   the Research Fund for Doctoral Program of Higher Education of China
   under Grant 20110141110056.
CR Badran E.F., 2009, RAD SCI C NRSC NAT, P1
   Cai LJ, 2012, J CENT SOUTH UNIV, V19, P2866, DOI 10.1007/s11771-012-1353-2
   Chamlawi R, 2010, COMPUT ELECTR ENG, V36, P578, DOI 10.1016/j.compeleceng.2009.12.003
   Chen WY, 2008, APPL MATH COMPUT, V197, P243, DOI 10.1016/j.amc.2007.07.078
   Cheng Q, 2009, IEEE T CIRC SYST VID, V19, P978, DOI 10.1109/TCSVT.2009.2020255
   Courtois N., 2002, Public Key Cryptography. 4th International Workshop on Practice and Theory in Public Key Cryptosystems, PKC 2002. Proceedings (Lecture Notes in Computer Science Vol.2274), P211
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Lie WN, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL I, P228, DOI 10.1109/ISCAS.2000.857069
   Lu CS, 2007, IEEE T CIRC SYST VID, V17, P454, DOI 10.1109/TCSVT.2006.888837
   Mairgiotis AK, 2008, IEEE T INF FOREN SEC, V3, P29, DOI 10.1109/TIFS.2007.916290
   Pérez-González F, 2008, IEEE T INF FOREN SEC, V3, P137, DOI 10.1109/TIFS.2008.922057
   Petitcolas F, 2002, STIRMARK BENCHMARK
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Stankovic S, 2001, IEEE T IMAGE PROCESS, V10, P650, DOI 10.1109/83.913599
   Takahashi A, 2005, IEEE T SIGNAL PROCES, V53, P806, DOI 10.1109/TSP.2004.839901
   Wang JW, 2012, SIGNAL PROCESS, V92, P893, DOI 10.1016/j.sigpro.2011.09.029
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P813, DOI 10.1109/TCSVT.2003.815948
   Xiao J, 2009, LECT NOTES COMPUT SC, V5450, P379, DOI 10.1007/978-3-642-04438-0_32
   Zhang Y., 2005, J INF COMMUN ENG, V1, P337
NR 19
TC 4
Z9 4
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5377
EP 5395
DI 10.1007/s11042-015-2504-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600001
DA 2024-07-18
ER

PT J
AU Quax, P
   Liesenborgs, J
   Barzan, A
   Croonen, M
   Lamotte, W
   Vankeirsbilck, B
   Dhoedt, B
   Kimpe, T
   Pattyn, K
   McLin, M
AF Quax, Peter
   Liesenborgs, Jori
   Barzan, Arno
   Croonen, Martijn
   Lamotte, Wim
   Vankeirsbilck, Bert
   Dhoedt, Bart
   Kimpe, Tom
   Pattyn, Kurt
   McLin, Matthew
TI Remote rendering solutions using web technologies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote rendering; Web technology; Scalability
AB Remote rendering is a well-known solution to the issue of running high-performance applications requiring complex visualizations on less capable hardware/software platforms or when client access to the data source for visualization is undesired or prohibitive in terms of required bandwidth. Visualizing the output of these remote rendering applications is typically achieved through native applications or, when considering a browser environment, through plug-ins. In this paper, several solutions are presented that enable deployment of these applications on standard web browsers, even those from the pre-HTML5 era. The focus in this paper is on two specific use case scenarios, taking into account that the proposed solutions are generic enough to be applied to a range of similar applications. The technologies presented cover the entire range of sub-processes contained in a complete remote rendering solution, such as the establishment of interaction feedback channels and delivery of images as part of the rendering pipeline. Depending on factors such as application requirements, developer preferences, feature availability in the web browser or raw performance figures, a custom solution can be composed from the options discussed in this paper. This is illustrated by applying them to the two aforementioned use cases, each with specific requirements and challenges, and benchmarking these example setups in terms of performance. A comparison of advantages and disadvantages is presented to guide developers in applying the technologies under real-life conditions.
C1 [Quax, Peter; Liesenborgs, Jori; Barzan, Arno; Croonen, Martijn; Lamotte, Wim] Univ Hasselt, iMinds, Expertise Ctr Digital Media, tUL, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
   [Vankeirsbilck, Bert; Dhoedt, Bart] Ghent Univ iMinds, Internet Based Commun Networks & Serv IBCN, Dept Informat Technol, Gaston Crommenlaan 8 Bus 201, B-9050 Ghent, Belgium.
   [Kimpe, Tom; Pattyn, Kurt] Barco NV, President Kennedypk 35, B-8500 Kortrijk, Belgium.
   [McLin, Matthew] Barco Inc, 9125 SW Gemini Dr, Beaverton, OR 97008 USA.
C3 Hasselt University; IMEC; IMEC; Ghent University
RP Quax, P (corresponding author), Univ Hasselt, iMinds, Expertise Ctr Digital Media, tUL, Wetenschapspk 2, B-3590 Diepenbeek, Belgium.
EM peter.quax@uhasselt.be
RI Quax, Paul/W-8520-2019; Lamotte, Wim/F-1796-2017
OI Liesenborgs, Jori/0000-0002-3648-8031; QUAX, Peter/0000-0003-4811-0578;
   Lamotte, Wim/0000-0003-1888-6383; Vankeirsbilck,
   Bert/0000-0001-9489-8306
FU IWT of Flanders through the R&D project CIRRUS
FX Part of this work is funded by IWT of Flanders through the R&D project
   CIRRUS.
CR [Anonymous], P NETGAMES VEN IT NO
   [Anonymous], 2014, ER RES
   Beznosyk A., 2012, P 10 AS PAC C COMP H, P11, DOI [10.1145/2350046.2350051, DOI 10.1145/2350046.2350051]
   Boukerche A., 2006, ACM Multimedia, P691, DOI DOI 10.1145/1180639.1180785
   Evans A, 2014, COMPUT GRAPH-UK, V41, P43, DOI 10.1016/j.cag.2014.02.002
   Glander T, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P147
   Jacinto H, 2012, WEB3D 2012, P51
   Jourdain S, 2010, IADIS INT C WEB VIRT
   Kapetanakis K., 2013, 17th Panhellenic Conference on Informatics, P33, DOI [10.1145/2491845.2491888, DOI 10.1145/2491845.2491888]
   Marion C, 2013, WEB3D 2013: 18TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, P117
   Narayanan A., 2013, WEBRTC 1 0 REAL TIME
   Quax Peter, 2012, P 22 INT WORKSH NETW, P45, DOI 10.1145/2229087.2229100
   Shi S, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348825
   Steed A, 2010, NETWORKED GRAPHICS: BUILDING NETWORKED GAMES AND VIRTUAL ENVIRONMENTS, P1
   Wessels A., 2011, Proceedings of the 2011 Eighth International Conference on Information Technology: New Generations (ITNG), P1050, DOI 10.1109/ITNG.2011.182
   Yoon I, 2000, THESIS U SO CALIFORN
   Zorrilla M, 2014, MULTIMED TOOLS APPL, V71, P533, DOI 10.1007/s11042-013-1516-7
NR 17
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4383
EP 4410
DI 10.1007/s11042-015-2481-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700011
OA Green Published
DA 2024-07-18
ER

PT J
AU Ryu, HS
   Park, H
AF Ryu, Ho-Sub
   Park, Hanhoon
TI A system for supporting paper-based augmented reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Paper-based augmented reality; Page marker; Text marker; Binary pattern
   identification
ID RECOGNITION; DOCUMENT
AB In this paper, we aim to implement augmented reality (AR) on distant text documents or books. For this purpose, we propose a new paper-based AR system that can detect text documents in real scenes, markerize and identify them, estimate their relative 3D poses to the camera, and augment them with virtual contents. Unlike the previous paper-based AR systems (applicable to only close documents), the proposed system not only requires no detection of words or characters, but allows partial occlusions like the previous systems. In our experiments, the proposed system worked at 24 fps and could consistently achieve high identification rates for both occluded and unoccluded pages.
C1 [Ryu, Ho-Sub; Park, Hanhoon] Pukyong Natl Univ, Dept Elect Engn, 45 Yongso Ro, Busan 608737, South Korea.
C3 Pukyong National University
RP Park, H (corresponding author), Pukyong Natl Univ, Dept Elect Engn, 45 Yongso Ro, Busan 608737, South Korea.
EM hanhoon_park@pknu.ac.kr
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2011, P 2011 IEEE WORKSH A, DOI DOI 10.1109/WACV.2011.5711545
   [Anonymous], 2000, Dare 2000, DOI DOI 10.1145/354666.354667
   Back M., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P23, DOI 10.1145/365024.365031
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Billinghurst M, 2001, IEEE COMPUT GRAPH, V21, P6, DOI 10.1109/38.920621
   Billinghurst M, 2012, COMPUTER, V45, P56, DOI 10.1109/MC.2012.111
   Clark A., 2012, 2012 IEEE Symposium on 3D User Interfaces (3DUI), P7, DOI 10.1109/3DUI.2012.6184168
   Clark P., 2002, International Journal on Document Analysis and Recognition, V4, P243, DOI 10.1007/s10032-001-0072-2
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fiala M, 2005, PROC CVPR IEEE, P590
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Gómez L, 2013, PROC INT CONF DOC, P467, DOI 10.1109/ICDAR.2013.100
   Grasset Raphael., 2007, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems Extended Abstracts (CHI EA'07), P1953, DOI DOI 10.1145/1240866.1240931
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hull JJ, 2007, 17TH INTERNATIONAL CONFERENCE ON ARTIFICIAL REALITY AND TELEXISTENCE, ICAT 2007, PROCEEDINGS, P205, DOI 10.1109/ICAT.2007.49
   Kato H, 2003, IEEE INTERNATIONAL AUGMENTED REALITY TOOLKIT WORKSHOP, P77, DOI 10.1109/ART.2003.1320435
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kim K, 2010, VISUAL COMPUT, V26, P1145, DOI 10.1007/s00371-010-0490-6
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li N, 1993, IMPLEMENTATION OCR S
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nakai T, 2007, P CBDAR
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Park H, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P272, DOI 10.1109/ISMAR.2004.37
   Park J, 2012, T EDUTAINMENT, V8, P24
   Peng HC, 2003, IEEE T PATTERN ANAL, V25, P1188, DOI 10.1109/TPAMI.2003.1227996
   Petter M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P48, DOI 10.1109/ICCVW.2011.6130221
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Saso TI, 2003, P SIGGRAPH
   Scherrer C, 2008, INT SYM MIX AUGMENT, P163, DOI 10.1109/ISMAR.2008.4637347
   Signer B., 2005, P ACM S DOC ENG, P187
   Uchiyama H, 2009, INT SYM MIX AUGMENT, P95, DOI 10.1109/ISMAR.2009.5336491
   Wagner D, 2008, INT SYM MIX AUGMENT, P121, DOI 10.1109/ISMAR.2008.4637337
   Wagner D, 2008, INT SYM MIX AUGMENT, P125, DOI 10.1109/ISMAR.2008.4637338
   Willis K.D. D., 2013, Proceedings of the 7th International Conference on Tangible, Embedded and Embodied Interaction, P331, DOI DOI 10.1145/2460625.2460682
   Zhang S., 2014, P CVPR
NR 40
TC 6
Z9 7
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3375
EP 3390
DI 10.1007/s11042-014-2439-7
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600021
DA 2024-07-18
ER

PT J
AU Wang, PF
   Wei, ZH
   Xiao, L
AF Wang, Pengfei
   Wei, Zhihui
   Xiao, Liang
TI Pure spatial rich model features for digital image steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Content adaptive steganography; Pure SRM features;
   Neighboring noise residual sample selection; Multi-order statistical
   features
AB The SRM (Spatial Rich Model) is a very effective steganalysis method. It uses statistics of neighboring noise residual samples as features to capture the dependency changes caused by embedding. Because the noise residuals are the high-frequency components of image and closely tied to image content, the residuals of different types of image regions have different statistical properties and effectiveness for steganalysis. In this paper, the effectiveness of the residuals is investigated. Then the effectiveness of the statistics collected from different types of neighboring residual samples is investigated from the FLD (Fisher Linear Discriminant) viewpoint, and ineffective, effective and high-effective neighboring residual samples are defined. The ineffective neighboring residual samples are not likely to change during embedding, and if they are counted in statistics, they may mix the features with noise and make the features impure. Pure SRM features are extracted based on neighboring noise residual sample selection strategy. Furthermore, multi-order statistical features are proposed to increase the statistical diversity. Steganalysis performances of the statistical features collected from different types of neighboring residual samples are investigated on three content adaptive steganographic algorithms. Experimental results demonstrate that the proposed method can achieve a more accurate detection than SRM.
C1 [Wang, Pengfei; Wei, Zhihui; Xiao, Liang] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Wang, Pengfei] Anhui Univ Technol, Sch Comp Sci & Technol, Maanshan 243002, Peoples R China.
C3 Nanjing University of Science & Technology; Anhui University of
   Technology
RP Wang, PF (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM pengfeiw@163.com
RI Wang, Pengfei/ABC-9076-2021; xiao, liang/G-2968-2010
OI xiao, liang/0000-0003-0178-9384
FU Natural Science Foundation of China [61302178, 61402009]; Excellent
   Youth Foundation of Anhui University of Technology (AHUT) [QZ201014]
FX This work was supported by the Natural Science Foundation of China (No.
   61302178 and 61402009), and the Excellent Youth Foundation of Anhui
   University of Technology (AHUT) (No. QZ201014). The authors would like
   to thank the Network Center of Anhui University of Technology (AHUT) for
   providing cloud services to support this work.
CR [Anonymous], 1 ACM IH MMSEC WORKS
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], 2012, IEEE WORKSH INF FOR
   Avcibas I, 2001, PROC SPIE, V4314, P523, DOI 10.1117/12.435436
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bohme R., 2010, Advanced Statistical Steganalysis
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Denemark T., 2014, P SPIE EL IM MED WAT, V9028, P2
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Filler T, 2011, IEEE T INF FOREN SEC, V6, P920, DOI 10.1109/TIFS.2011.2134094
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Holub V, 2013, IEEE T INF FOREN SEC, V8, P1996, DOI 10.1109/TIFS.2013.2286682
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Zou DK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1365, DOI 10.1109/ICME.2006.262792
NR 18
TC 10
Z9 10
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2897
EP 2912
DI 10.1007/s11042-015-2521-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000030
DA 2024-07-18
ER

PT J
AU Barri, I
   Roig, C
   Giné, F
AF Barri, Ignasi
   Roig, Concepcio
   Gine, Francesc
TI Distributing game instances in a hybrid client-server/P2P system to
   support MMORPG playability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMORPG; Hybrid system; P2P; Load balancing
AB MMORPG (Massively Multiplayer Online Role Playing Games) is the most popular genre among network gamers, and now attract millions of users, who play simultaneously in an evolving virtual world. This huge number of concurrent players requires the availability of high performance computation servers. Additionally, gaming aware distribution mechanisms are needed to distribute game instances among servers to avoid load imbalances that affect performance negatively. In this work, we tackle the problem of game distribution and scalability by means of a hybrid Client-Server/P2P architecture that can scale dynamically according to the demand. To manage peak loads that occur during the game, we distribute game computation across the system according to the behavior of MMORPGs. We distinguish between the computation associated with the Main Game, that affects all players, and the computation of Auxiliary Games that affects only a few players and acts in isolation from the execution of the Main Game. Taking this distinction into account, we propose a mechanism that is focused in the distribution of Auxiliary Games, as an entity, across the pool of servers and peers of the underlying hybrid architecture. We evaluate the performance of the balancing mechanism taking the criteria of latency and reliability into account, and we compare the effectiveness of the mechanism with a classic approach that applies load balancing to individually players in a Client-Server system. We show that the balancing mechanism based on the latency criteria provides lower latency than the classical proposal, while in relation to reliability, we obtain a failure probability of under 0.9 % in the worst case, which is amply compensated by the scalability provided by the use of the P2P area.
C1 [Barri, Ignasi; Roig, Concepcio; Gine, Francesc] Univ Lleida, Dept Comp Sci, Lleida, Spain.
C3 Universitat de Lleida
RP Giné, F (corresponding author), Univ Lleida, Dept Comp Sci, Lleida, Spain.
EM ignasibarri@diei.udl.cat; roig@diei.udl.cat; sisco@diei.udl.cat
RI Gine, Francesc/I-5446-2012; Roig, Concepcio/J-8425-2014
OI Roig, Concepcio/0000-0003-3029-3820
FU MEyC-Spain [TIN2011-28689-C02-02]; CUR of DIUE of GENCAT; European
   Social Fund
FX This work was supported by the MEyC-Spain under contract
   TIN2011-28689-C02-02 and the CUR of DIUE of GENCAT and the European
   Social Fund.
CR Ahmed DT, 2008, DS RT 08
   [Anonymous], INFOCOM
   Assiotis M, 2006, P  5 ACM SIGCOMM WOR
   Atomic Blue Corporation, HOM PLANESHIFT OP SO
   Atomic Blue Corporation, LINK PLANESHIFT SERV
   Bauer D., 2002, PROC 1 WORKSHOP NETW, P36
   Bezerra C, 2009, MULTIMED TOOLS APPL, P45
   Boulanger J.S., 2006, P 5 ACM SIGCOMM WORK
   Buyukkaya E, 2008, CONSUM COMM NETWORK, P1050, DOI 10.1109/ccnc08.2007.239
   Castro M, 2002, IEEE J SEL AREA COMM, V20, P1489, DOI 10.1109/JSAC.2002.803069
   chang Feng W, 2002, INT MEAS WORKSH
   Chen J., 2005, P 10 ACM SIGPLAN S P
   De Vleeschauwer B, 2005, P 4 ACM SIGCOMM WORK
   Douglas S, 2005, P IEEE INT C INF AUT
   El Rhalibi A, 2006, CONSUM COMM NETWORK, P1188
   Eugene TS, 2001, INFOCOM
   Fan L, 2010, INT J ADV MEDIA COMM, P4
   Feng WC, 2002, IMW 2002: PROCEEDINGS OF THE SECOND INTERNET MEASUREMENT WORKSHOP, P151, DOI 10.1145/637201.637223
   Fengyun L, 2006, P 5 ACM SIGCOMM WORK
   Frozesand, HOM URB TERR OP SOUR
   Guan-Yu Huang, 2008, International Journal of Advanced Media and Communication, V2, P380, DOI 10.1504/IJAMC.2008.022222
   Hampel T., 2006, P 5 ACM SIGCOMM WORK
   Hanzich M, 2011, J COMPUT SCI TECH-CH, V26, P99, DOI 10.1007/s11390-011-9418-5
   IBM Developers Works, 2002, CHARM PYTH SIMPY SIM
   Keller J, 2003, PDPTA
   Lee YT, 2010, P IEEE INT C CLOUD C
   Liu H, 2008, CCGRID
   Liu H-I, 2008, P 2008 8 IEEE INT S
   Matsumoto N, 2004, GLOB TELECOMM CONF, P529
   Research in China, 2008, CHIN ONL GAM MARK RE
   Siu Fung Y, 2006, P 5 ACM SIGCOMM WORK
   Storey K, 2004, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P140, DOI 10.1109/CGI.2004.1309204
   Suznjevic M, 2009, MULTIMED TOOLS APPL, V45, P191, DOI 10.1007/s11042-009-0300-1
   Swamynathan G, 2008, CONCURR COMP-PRACT E, V20, P155, DOI 10.1002/cpe.1186
   Tarng P, 2008, NETGAMES
   Ye M, 2006, IBM SYST J, V45, P45, DOI 10.1147/sj.451.0045
   Yu AP, 2005, MOPAR MOBILE PEER TO
NR 37
TC 5
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 2005
EP 2029
DI 10.1007/s11042-014-2389-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000013
OA hybrid
DA 2024-07-18
ER

PT J
AU Sun, YQ
   Sudo, K
   Taniguchi, Y
AF Sun, Yongqing
   Sudo, Kyoko
   Taniguchi, Yukinobu
TI Visual concept detection of web images based on group sparse ensemble
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ensemble learning; Visual concept detection; Semantic indexing; Web
   image mining; Sparse representation; Dictionary learning
ID ONLINE
AB Due to the huge intra-class variations for visual concept detection, it is necessary for concept learning to collect large scale training data to cover a wide variety of samples as much as possible. But it presents great challenges on both how to collect and how to train the large scale data. In this paper, we propose a novel web image sampling approach and a novel group sparse ensemble learning approach to tackle these two challenging problems respectively. For data collection, in order to alleviate manual labeling efforts, we propose a web image sampling approach based on dictionary coherence to select coherent positive samples from web images. We propose to measure the coherence in terms of how dictionary atoms are shared because shared atoms represent common features with regard to a given concept and are robust to occlusion and corruption. For efficient training of large scale data, in order to exploit the hidden group structures of data, we propose a novel group sparse ensemble learning approach based on Automatic Group Sparse Coding (AutoGSC). After AutoGSC, we present an algorithm to use the reconstruction errors of data instances to calculate the ensemble gating function for ensemble construction and fusion. Experiments show that our proposed methods can achieve promising results and outperforms existing approaches.
C1 [Sun, Yongqing; Sudo, Kyoko; Taniguchi, Yukinobu] NTT Media Intelligence Labs, 1-1 Hikarinooka, Yokosuka, Kanagawa 2390847, Japan.
RP Sun, YQ (corresponding author), NTT Media Intelligence Labs, 1-1 Hikarinooka, Yokosuka, Kanagawa 2390847, Japan.
EM yongqing.sun@lab.ntt.co.jp; sudo.kyoko@lab.ntt.co.jp;
   taniguchi.yukinobu@lab.ntt.co.jp
CR Amir A, 2003, NIST TRECVID WORKSH
   [Anonymous], 2010, PROC ACM SIGMM INT C
   [Anonymous], P CIVR
   [Anonymous], MM
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bengio DSS, 2009, NEURAL INFORM PROCES
   Bordes A, 2005, J MACH LEARN RES, V6, P1579
   Borth D, 2011, ACM MULTIMEDIA 2011, P1453
   Cao J, 2006, NIST TRECVID WORKSH
   Domingos P, 2012, COMMUN ACM, V55, P78, DOI 10.1145/2347736.2347755
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Li HJ, 2013, MULTIMEDIA SYST, V19, P37, DOI 10.1007/s00530-012-0265-1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Munder S, 2006, IEEE T PATTERN ANAL, V28, P1863, DOI 10.1109/TPAMI.2006.217
   Over P, 2008, NIST TRECVID WORKSH
   Pytlik B, 2005, NIST TRECVID WORKSH
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Song Y, 2011, IEEE T CIRC SYST VID, V21, P1193, DOI 10.1109/TCSVT.2011.2130230
   SUN YONGQING., 2008, ACM Multimedia, P635
   Tang S, 2008, NIST TRECVID WORKSH
   Tang S., 2012, MULTIMEDIA MULTIDISC, P175
   Tang S, 2009, ACM MULTIMEDIA 2009
   Tang S, 2012, IEEE T MULTIMEDIA, V14, P43, DOI 10.1109/TMM.2011.2168198
   Wang F, 2011, 25 AAAI C ART INT AU
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
NR 29
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1409
EP 1425
DI 10.1007/s11042-014-2179-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600004
DA 2024-07-18
ER

PT J
AU Wu, ZP
   Aizawa, K
AF Wu, Zhipeng
   Aizawa, Kiyoharu
TI Very fast generation of content-preserved photo collage under canvas
   size constraint
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Very fast photo collage; Content-preserved; Rainbow collage
AB Photo collage, which constructs a compact and visually appealing representation from a collection of input images, can offer a most convenient and impressive user experience. Most previous approaches to collage construction have utilized saliency detection and visibility optimization. However, such methods are computationally expensive and not feasible for real-time applications such as online image retrieval or interactive photo browsing. Moreover, the effectiveness of automatic saliency detection may be questionable. Even if the main regions of interest are retained accurately, some visually not salient but semantically important items such as logos, captions, and copyright information located at the margins and corners may be missed. In our alternative approach, we address the issue of content-preserved collage, which avoids content-harmful processes such as cropping or changes to aspect ratio and orientation. Based on a full balanced binary layout tree, our algorithm can pack all the input images tightly onto the collage canvas while keeping their visual information unchanged. The proposed algorithm is fast, requiring less than 0.5 ms to generate a 100-image collage. We also present several extensions and applications oriented to a variety of usage contexts and device platforms.
C1 [Wu, Zhipeng; Aizawa, Kiyoharu] Univ Tokyo, Dept Informat & Commun Engn, Tokyo, Tokyo, Japan.
C3 University of Tokyo
RP Wu, ZP (corresponding author), Univ Tokyo, Dept Informat & Commun Engn, Tokyo, Tokyo, Japan.
EM zhipengwu@hal.t.u-tokyo.ac.jp; aizawa@hal.t.u-tokyo.ac.jp
CR Allison W., 2002, P 2 INT S NONPHOTORE, P21
   Atkins C.B., 2008, P 16 ACM INT C MULTI, P821
   Checconi F., 2012, HINDAWI MATH PROBL E, V21, P802
   Chu WT, 2007, IEEE MULTIMEDIA, V14, P36, DOI 10.1109/MMUL.2007.66
   Diakopoulos Nicholas., 2005, P 18 ANN ACM S USER, P183
   Fan J, 2012, IEEE INT CONF MULTI, P308, DOI 10.1109/ICMEW.2012.59
   Gal R, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P7
   Geigel J, 2003, IEEE MULTIMEDIA, V10, P16, DOI 10.1109/MMUL.2003.1237547
   Goferman S, 2010, COMPUT GRAPH FORUM, V29, P459, DOI 10.1111/j.1467-8659.2009.01615.x
   Huang H, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024189
   Kang H.-W., 2006, P IEEE C COMP VIS PA, P1331, DOI [DOI 10.1109/CVPR.2006.284, 10.1109/cvpr.2006.2842, DOI 10.1109/CVPR.2006.2842, 10.1109/cvpr.2006.284]
   Kim J, 2002, ACM T GRAPHIC, V21, P657
   Kong X, 2007, COGN SYST RES, V8, P192, DOI 10.1016/j.cogsys.2007.06.002
   Kong XH, 2010, COGNITIVE SCI, V34, P322, DOI 10.1111/j.1551-6709.2009.01075.x
   Liu T, 2009, IEEE T MULTIMEDIA, V11, P1225, DOI 10.1109/TMM.2009.2030741
   Mei T, 2009, VISUAL COMPUT, V25, P39, DOI 10.1007/s00371-008-0282-4
   Rother C, 2006, ACM T GRAPHIC, V25, P847, DOI 10.1145/1141911.1141965
   Tian A., 2011, P 19 ACM INT C MULTI, P1549
   Wang T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1479
   Wei Y., 2009, MSRTR-2009-59
   Wong D. F., 1986, 23rd ACM/IEEE Design Automation Conference. Proceedings 1986 (Cat. No.86CH2288-9), P101, DOI 10.1145/318013.318030
   Wu Z, 2013, P 2013 APSIPA ANN SU
   Xiao J., 2008, PROC ACM INT C MULTI, P509
   Xiao J., 2010, P INT C MULT, P1551
   Xu QQ, 2010, PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON LOGISTICS SYSTEMS AND INTELLIGENT MANAGEMENT, VOLS 1-3, P927, DOI 10.1109/ICLSIM.2010.5461047
   Yan Q., 2013, HIERARCHICAL SALIENC
   Yang B, 2008, LECT NOTES COMPUT SC, V4903, P175
   Yang YZ, 2009, VISUAL COMPUT, V25, P431, DOI 10.1007/s00371-009-0346-0
   Zhipeng Wu, 2014, Journal of Multimedia, V9, P4, DOI 10.4304/jmm.9.1.4-13
NR 29
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1813
EP 1841
DI 10.1007/s11042-014-2375-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000004
DA 2024-07-18
ER

PT J
AU Yang, JM
   Huang, TQ
   Su, LC
AF Yang, Jianmei
   Huang, Tianqiang
   Su, Lichao
TI Using similarity analysis to detect frame duplication forgery in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video forgery; Video forensics; Frame duplication; Similarity
AB Duplication of selected frames from a video to another location in the same video is one of the most common methods of video forgery. However, few algorithms have been suggested for detecting this tampering operation. This paper proposes an effective similarity-analysis-based method for frame duplication detection that is implemented in two stages. In the first stage, the features of each frame are obtained via SVD (Singular Value Decomposition). Next, the Euclidean distance is calculated between features of each frame and the reference frame. After dividing the video sequence into overlapping sub-sequences, the similarities between the sub-sequences are calculated, and then our algorithm identifies those video sequences with high similarity as candidate duplications. In the second stage, the candidate duplications are confirmed through random block matching. The experimental results show that our algorithm provides detection accuracy that is higher than the previous algorithms, and it has an outstanding performance in terms of time efficiency.
C1 [Yang, Jianmei; Huang, Tianqiang; Su, Lichao] Fujian Normal Univ, Sch Math & Comp Sci, Fuzhou, Peoples R China.
C3 Fujian Normal University
RP Huang, TQ (corresponding author), Fujian Normal Univ, Sch Math & Comp Sci, Fuzhou, Peoples R China.
EM fjnu510@163.com
FU Industry-University Cooperation Major Projects in Fujian Province
   [2012H6006]; Program for New Century Excellent Talents in University in
   Fujian Province [JAI1038]; University Services HaiXi Major Project in
   Fujian Province [2008HX200941-4-5]; Science and Technology Department of
   Fujian province K-class Foundation Project [JA10064]; Education
   Department of Fujian Province A-class Foundation Project [JA10064]
FX This work was supported by the Industry-University Cooperation Major
   Projects in Fujian Province (Grant No. 2012H6006), the Program for New
   Century Excellent Talents in University in Fujian Province (Grant No.
   JAI1038), the University Services HaiXi Major Project in Fujian Province
   (Grant No. 2008HX200941-4-5), the Science and Technology Department of
   Fujian province K-class Foundation Project (Grant No. JA10064), and The
   Education Department of Fujian Province A-class Foundation Project
   (Grant No. JA10064).
CR [Anonymous], 2006, P 8 WORKSHOP MULTIME, DOI DOI 10.1145/1161366.1161375
   [Anonymous], SIG PROCESS MAG IEEE
   Feng JZ, 2009, IEEE IMAGE PROC, P2149, DOI 10.1109/ICIP.2009.5414328
   Hsu CC, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P170, DOI 10.1109/MMSP.2008.4665069
   Hyun D-K, 2012, ERA INTERACTIVE MEDI, P25, DOI DOI 10.1007/978-1-4614-3501-3_3
   Kobayashi M, 2009, LECT NOTES COMPUT SC, V5414, P306, DOI 10.1007/978-3-540-92957-4_27
   Li L., 2013, Detecting removed object from video with stationary background Digital Forensics and Watermaking, P242
   Lin C-S., 2013, 2 INT C CYB SEC CYB, P107
   Lin GS, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412500176
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Qin Y, 2009, J COMPUTER RES DEV S, P227
   Sencar HT, 2009, STAT SCI INTERDISC R, V3, P325
   Subramanyam AV, 2013, INT CONF ACOUST SPEE, P3038, DOI 10.1109/ICASSP.2013.6638216
   Subramanyam AV, 2012, IEEE INT WORKSH MULT, P89, DOI 10.1109/MMSP.2012.6343421
   Sun TF, 2012, INT CONF ACOUST SPEE, P1389, DOI 10.1109/ICASSP.2012.6288150
   Wang W, 2007, P 9 WORKSH MULT SEC
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Wang WH, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P35
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 20
TC 55
Z9 57
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1793
EP 1811
DI 10.1007/s11042-014-2374-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000003
DA 2024-07-18
ER

PT J
AU Zhao, H
   Zheng, QH
   Zhang, WZ
   Li, HF
AF Zhao, Hui
   Zheng, Qinghua
   Zhang, Weizhan
   Li, Haifei
TI MSC: a multi-version shared caching for multi-bitrate VoD services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-bitrate; Video-on-demand; Multi-version videos; Shared caching
ID TRANSCODING PROXY; VIDEO; REPLACEMENT; ALGORITHMS; OBJECTS
AB Recently, many Video-on-Demand (VoD) service providers try to attract as many users as possible by offering multi-bitrate video streaming services with differentiated qualities. Many researches focus on video layered coding (e.g., scalable video coding, SVC). However, SVC is not widely used in VoD industry. Another solution, multi-version videos, can be classified into online transcoding and pre-stored multi-version videos. Online transcoding is a CPU-intensive and costly task, so it is not suitable for large-scale VoD applications. In this paper, we study how to improve caching efficiency based on pre-stored multi-version videos. We leverage the sharing probability among different versions of the same video and propose a multi-version shared caching (MSC) method to maximize the benefit of caching proxy. If the desired version is not in the cache while the higher neighbor version is in, MSC transmits the higher version streaming to user temporarily. In this case, MSC can make full use of the caching resources to improve the cache hit ratio and decrease users' average waiting time. Simulation results show that MSC outperforms the others in the cache hit ratio and the average waiting time.
C1 [Zhao, Hui; Zheng, Qinghua; Zhang, Weizhan] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, MOEKLINNS Lab, Xian 710049, Peoples R China.
   [Li, Haifei] Union Univ, Dept Comp Sci, Germantown, TN 38305 USA.
C3 Xi'an Jiaotong University; Union University
RP Zhang, WZ (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, MOEKLINNS Lab, Xian 710049, Peoples R China.
EM huizhao@stu.xjtu.edu.cn; qhzheng@mail.xjtu.edu.cn;
   zhangwzh@mail.xjtu.edu.cn; hli@uu.edu
FU National Science Foundation of China [61103239, 61221063, 91118005,
   91218301]; National High Technology Research and Development Program 863
   of China [2012AA011003]; Cheung Kong Scholar's Program; Ministry of
   Education Innovation Research Team [IRT13035]; Ministry of Education of
   China Humanities and Social Sciences Project [12YJC880117]; Key Projects
   in the National Science and Technology Pillar Program [2012BAH16F02]
FX The research was supported in part by National Science Foundation of
   China under Grant Nos. 61103239, 61221063, 91118005, 91218301; National
   High Technology Research and Development Program 863 of China under
   Grant No. 2012AA011003; Cheung Kong Scholar's Program; The Ministry of
   Education Innovation Research Team No. IRT13035; Ministry of Education
   of China Humanities and Social Sciences Project under Grant No.
   12YJC880117; Key Projects in the National Science and Technology Pillar
   Program under Grant No. 2012BAH16F02.
CR [Anonymous], P 15 INT PAR DISTR P
   Cha M, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P1
   Chang CY, 2003, IEEE T PARALL DISTR, V14, P611, DOI 10.1109/TPDS.2003.1206507
   Chang KC, 2007, J SYST ARCHITECT, V53, P833, DOI 10.1016/j.sysarc.2007.02.003
   Chen SQ, 2005, IEEE MULTIMEDIA, V12, P59, DOI 10.1109/MMUL.2005.56
   Cheng X, 2008, INT WORKSH QUAL SERV, P249
   Cong X, 2014, PEER PEER NETW APPL, V7, P175, DOI 10.1007/s12083-012-0193-z
   Conklin GJ, 2001, IEEE T CIRC SYST VID, V11, P269, DOI 10.1109/76.911155
   DAN A, 1993, 19347 IBM RC
   Gill P, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P15
   Guo H, 2007, J NETW COMPUT APPL, V30, P265, DOI 10.1016/j.jnca.2005.08.008
   Hartanto F, 2006, MULTIMED TOOLS APPL, V31, P221, DOI 10.1007/s11042-006-0037-z
   Ho KM, 2007, IEEE T BROADCAST, V53, P763, DOI 10.1109/TBC.2007.908326
   Hsu TH, 2011, EXPERT SYST APPL, V38, P3467, DOI 10.1016/j.eswa.2010.08.134
   Kangasharju J, 2002, IEEE T COMPUT, V51, P622, DOI 10.1109/TC.2002.1009148
   Kao CF, 2007, IEEE T MULTIMEDIA, V9, P221, DOI 10.1109/TMM.2006.886259
   Kim KT, 2003, ELECTRON LETT, V39, P1555, DOI 10.1049/el:20030965
   Kim T, 2005, LECT NOTES COMPUT SC, V3768, P1
   Krishnan R. K., 2012, P INT MEAS C, P211
   Kwon O, 2008, 2008 IEEE 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P555, DOI 10.1109/CIT.2008.4594735
   Lee H, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P863, DOI 10.1109/CCNC.2013.6488569
   Lee H, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P247
   Li B, 2013, IEICE T COMMUN, VE96B, P749, DOI 10.1587/transcom.E96.B.749
   Li KQ, 2005, 2005 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, PROCEEDINGS, P500
   Li ZG, 2012, PLANT SCI, V185, P185, DOI 10.1016/j.plantsci.2011.10.006
   Miao ZR, 2002, IEEE J SEL AREA COMM, V20, P1315, DOI 10.1109/JSAC.2002.802061
   Na Sun, 2013, Cross-Cultural Design. Cultural Differences in Everyday Life. 5th International Conference, CCD 2013. Held as Part of HCI International 2013. Proceedings: LNCS 8024, P468, DOI 10.1007/978-3-642-39137-8_52
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shen B, 2004, IEEE T MULTIMEDIA, V6, P375, DOI 10.1109/TMM.2003.822791
   Sun Y, 2013, IEEE NETWORK, V27, P22, DOI 10.1109/MNET.2013.6485092
   Tang XY, 2002, PROC INT CONF PARAL, P287, DOI 10.1109/ICPP.2002.1040884
   Tewari R., 1998, P SPIE ACM C MULT CO, P191
   Wien M, 2007, IEEE T CIRC SYST VID, V17, P1194, DOI 10.1109/TCSVT.2007.905530
   Wu Kun-Lung., 2001, P 10 INT C WORLD WID, P36
   Zhang W, 2013, MULTIMED TOOLS APPL, P1
   Zhang WZ, 2011, MULTIMED TOOLS APPL, V53, P97, DOI 10.1007/s11042-010-0492-4
   Zheng Qingji., 2012, CODASPY '12: ACM conference on Data and Application Security and Privacy, P1
   [No title captured]
NR 38
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1923
EP 1945
DI 10.1007/s11042-014-2380-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000009
DA 2024-07-18
ER

PT J
AU Ionescu, B
   Popescu, A
   Radu, AL
   Müller, H
AF Ionescu, Bogdan
   Popescu, Adrian
   Radu, Anca-Livia
   Mueller, Henning
TI Result diversification in social image retrieval: a benchmarking
   framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social photo retrieval; Result diversification; Image content
   description; Re-ranking; Crowdsourcing
ID AGREEMENT
AB This article addresses the diversification of image retrieval results in the context of image retrieval from social media. It proposes a benchmarking framework together with an annotated dataset and discusses the results achieved during the related task run in the MediaEval 2013 benchmark. 38 multimedia diversification systems, varying from graph-based representations, re-ranking, optimization approaches, data clustering to hybrid approaches that included a human in the loop, and their results are described and analyzed in this text. A comparison of the use of expert vs. crowdsourcing annotations shows that crowdsourcing results have a slightly lower inter-rater agreement but results are comparable at a much lower cost than expert annotators. Multimodal approaches have best results in terms of cluster recall. Manual approaches can lead to high precision but often lower diversity. With this detailed results analysis we give future insights into diversity in image retrieval and also for preparing new evaluation campaigns in related areas.
C1 [Ionescu, Bogdan; Radu, Anca-Livia] Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
   [Popescu, Adrian] CEA LIST, Ctr Saclay NanoInnov, Paris, France.
   [Radu, Anca-Livia] Univ Trento, DISI, I-38123 Povo, Italy.
   [Mueller, Henning] Univ Appl Sci Western Switzerland HES SO, Sierre, Switzerland.
C3 National University of Science & Technology POLITEHNICA Bucharest; CEA;
   University of Trento; University of Applied Sciences & Arts Western
   Switzerland
RP Ionescu, B (corresponding author), Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
EM bionescu@alpha.imag.pub.ro; adrian.popescu@cea.fr;
   ancalivia.radu@unitn.it; henning.mueller@hevs.ch
RI Ionescu, Bogdan/IWU-7778-2023
OI Muller, Henning/0000-0001-6800-9878
FU CUbRIK; PROMISE; MUCKE
FX This work was supported by the following projects: CUbRIK
   (http://www.cubrikproject.eu/), PROMISE (http://www.promise-noe.eu/) and
   MUCKE (http://ifs.tuwien.ac.at/similar to mucke/). We acknowledge also
   the MediaEval Benchmarking Initiative for Multimedia Evaluation
   (http://www.multimediaeval.org/).
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2013, P TRECVID 2013 NIST
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], 2005, JOENS LEARN INSTR S
   [Anonymous], 2012, PASCAL VISUAL OBJECT
   Ballan L, 2015, MULTIMED TOOLS APPL, V74, P1443, DOI 10.1007/s11042-014-1976-4
   Cheng XQ, 2013, IEEE T KNOWL DATA EN, V25, P177, DOI 10.1109/TKDE.2011.190
   COHEN J, 1968, PSYCHOL BULL, V70, P213, DOI 10.1037/h0026256
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dang V, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P65, DOI 10.1145/2348283.2348296
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Deselaers T, 2009, ACM INT C IM VID RET
   Huang Z, 2010, ACM T INFORM SYST, V28, DOI 10.1145/1852102.1852108
   Ionescu B, 2013, WORK NOT P MEDIAEVAL, V1043
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Lehman A., 2005, JMP BASIC UNIVARIATE
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   McGinty L, 2003, LECT NOTES ARTIF INT, V2689, P276
   Radu Anca-Livia, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P25, DOI 10.1007/978-3-319-04114-8_3
   Rudinac S, 2013, IEEE T MULTIMEDIA, V15, P921, DOI 10.1109/TMM.2013.2237896
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Taneva Bilyana., 2010, Proceedings of the third ACM international conference on Web search and data mining, P431
   Tsikrika T, 2012, IEEE MULTIMEDIA, V19, P24, DOI 10.1109/MMUL.2012.17
   Tsikrika T, 2011, LECT NOTES COMPUT SC, V6941, P95, DOI 10.1007/978-3-642-23708-9_12
   Van Leuken Reinier H, 2009, P 18 INT C WORLD WID, P341, DOI 10.1145/1526709.1526756
   Vee E, 2008, PROC INT CONF DATA, P228, DOI 10.1109/ICDE.2008.4497431
   Vieira MR, 2011, PROC INT CONF DATA, P1163, DOI 10.1109/ICDE.2011.5767846
   Wilkie D., 1980, TEACH STAT, V2, P76
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 48
TC 21
Z9 21
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 1301
EP 1331
DI 10.1007/s11042-014-2369-4
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700028
OA Green Published
DA 2024-07-18
ER

PT J
AU Chen, X
   Gao, YF
   Huang, ZH
AF Chen, Xin
   Gao, Yuefang
   Huang, Zhonghong
TI CUDA-accelerated fast Sauvola's method on Kepler architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sauvola's method; GPGPU; CUDA; Integral image
AB Sauvola's method is one of the top binarization methods for degraded document images. High computational complexity, however, restricts it to non-time-sensitive applications. In this paper, we present a parallel implementation of Sauvola's method with integral image optimization, called fast Sauvola's method, on Nvidia Kepler architecture GPUs using CUDA 5.0. Our implementation is evaluated on a GTX 650 graphic card (384 cores) and exhibits an average speedup of about 38 compared to a sequential implementation on a fast CPU, and computational complex of our implementation is constant for any size of local windows.
C1 [Chen, Xin] Hermes Microvis Inc, San Jose, CA 95131 USA.
   [Gao, Yuefang] South China Agr Univ, Guangzhou, Guangdong, Peoples R China.
   [Huang, Zhonghong] Sun Yat Sen Univ, Guangzhou 510275, Guangdong, Peoples R China.
C3 South China Agricultural University; Sun Yat Sen University
RP Chen, X (corresponding author), Hermes Microvis Inc, San Jose, CA 95131 USA.
EM xinchen.hawaii@outlook.com; gaoyuefang@scau.edu.cn;
   zhonghonghuang623@gmail.com
CR [Anonymous], 2011, INT J COMPUT APPL
   Badekas E, 2005, AUTOMATIC EVALUATION
   Bilgic B., 2010, EFFICIENT INTEGRAL I
   Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Breuel TB, 2008, P ISTSPIE 20 ANN S
   Crow F. C., 1984, Computers & Graphics, V18, P207
   CUDA, 2013, CUDA C PROGR GUID 5
   Gatos B, 2011, INT J DOC ANAL RECOG, V14, P35, DOI 10.1007/s10032-010-0115-7
   Hwu W.W., 2011, APPL GPU COMPUTING S
   Messom C, 2008, HIGH PRECISINO GPU B
   Niblack W., 1986, An Introduction to Digital Image Processing
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Palumbo P, 1986, SPIE
   Porikli F, 2006, FAST CONSTRUCTION CO
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shafait F, 2008, PROC SPIE, V6815, DOI 10.1117/12.767755
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang Z., 2008, PARALLEL IMAGE PROCE
   Zheng Z., 2011, 3 WORKSHOP HIGH PERF, P52
NR 22
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11809
EP 11820
DI 10.1007/s11042-014-2269-7
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600037
DA 2024-07-18
ER

PT J
AU Yang, SH
   Chang, CW
   Chan, CC
AF Yang, Shih-Hsuan
   Chang, Chi-Wen
   Chan, Chih-Chieh
TI An object-based error concealment technique for H.264 coded video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Error concealment; Motion estimation; Object segmentation; H.264/AVC
ID ALGORITHM
AB The H.264 video coding standard has become popular owing to its excellent compression efficiency. However, the H.264-coded video is very vulnerable to data loss. Conventional error concealment techniques interpolate the lost data in units of rectangular blocks, which limit the performance because a visual object is not equivalent to an image block. In this paper, we propose a new error concealment technique that uses visual objects as concealment units. The H.264 error-resilience tool FMO (Flexible Macroblock Ordering) is also incorporated at the encoder side for utilizing the spatial correlation. A lost region is concealed at the decoder side in three steps, namely object segmentation, object matching, and region-based patching. Objects are formed in the reference pictures based on color similarity, and adjacent objects of small area or the same motion are grouped as a unity. Motion estimation is performed on detected objects to find the associated motion vector. A lost region is concealed by the object in the reference picture with the best boundary-matching score. The proposed method provides considerably higher PSNR (peak signal-to-noise ratio) than conventional block-based approaches, especially for traditionally difficult cases and high-quality videos.
C1 [Yang, Shih-Hsuan; Chang, Chi-Wen; Chan, Chih-Chieh] Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, Taipei 10608, Taiwan.
C3 National Taipei University of Technology
RP Yang, SH (corresponding author), Natl Taipei Univ Technol, Dept Comp Sci & Informat Engn, 1,Sec 3,Zhong Xiao E Rd, Taipei 10608, Taiwan.
EM shyang@ntut.edu.tw
FU National Science Council, Taiwan [NSC 101-2219-E-027-002, NSC
   102-2219-E-027-002]
FX This research is supported in part by the National Science Council,
   Taiwan, under the Grants NSC 101-2219-E-027-002 and NSC
   102-2219-E-027-002.
CR [Anonymous], 2002, 6 M AW ISL JAP DEC
   [Anonymous], 2010, The H.264 Advanced Video Compression Standard
   Hsiao HH, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-12
   *ISO IEC, 2000, 144962 ISOIEC
   Li H, 2013, MULTIMED TOOLS APPL, V65, P297, DOI 10.1007/s11042-011-0811-4
   Wang L, 2007, INT S INT SIGN PROC
   Wang YK, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P729
   Wu GL, 2010, IEEE T CIRC SYST VID, V20, P1409, DOI 10.1109/TCSVT.2010.2077471
   Yan B, 2010, IEEE T IMAGE PROCESS, V19, P98, DOI 10.1109/TIP.2009.2032311
   Yang SX, 2011, IEEE T SYST MAN CY C, V41, P93, DOI 10.1109/TSMCC.2010.2049200
   Zhang J, 2000, IEEE T CIRC SYST VID, V10, P659, DOI 10.1109/76.845011
NR 11
TC 4
Z9 4
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10785
EP 10800
DI 10.1007/s11042-014-2206-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700029
DA 2024-07-18
ER

PT J
AU Kim, KS
   Song, IS
   Lee, YS
   Choi, SB
AF Kim, Kyeong-seob
   Song, In-seong
   Lee, Yun-sub
   Choi, Sang-bang
TI The implementation of start stop system with the OBD-II interface in the
   automotive smart key system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Start stop system; Smart key system; Vehicle network; OBD-II; ECU
AB Along with the growing needs for the low energy consumption technology and the strengthening vehicle environmental regulations, the researches on the start stop system, which stops the engine on idle, have been briskly carried out around the automobile makers before the appearance of the alternative energy. In addition, the automobile makers are trying to popularize the start stop system by combining the system to the generalized smart key system to not only arouse purchasing but also provide the convenience and reduce the energy consumption as well. In this paper, we designed and implemented the start stop system algorithm for the aftermarket smart key system which uses the OBD-II interface. The implemented start stop system is capable of controlling two independent systems, both an eco-friendly start stop system and a convenient smart key system, on a single ECU. Furthermore, the implemented start sop system standardizes the interface with the vehicles to reduce the time required for installing the start stop system to the various vehicles, and satisfies every standard response time limit for the vehicle status request signals.
C1 [Kim, Kyeong-seob; Song, In-seong; Lee, Yun-sub; Choi, Sang-bang] Inha Univ, Sch Elect Engn, Inchon 402751, South Korea.
C3 Inha University
RP Kim, KS (corresponding author), Inha Univ, Sch Elect Engn, Yonghyeon 4 Dong, Inchon 402751, South Korea.
EM kskim7817@gmail.com; nicvirus@inha.edu; skua1204@inha.edu;
   sangbang@inha.ac.kr
FU Inha University
FX This research was supported by an Inha University Research Grant.
CR [Anonymous], AUTOMOT ENG
   Bishop J, 2007011777 SAE
   Bishop J, 2007011777 SAE
   Bosch, 1991, CAN SPEC VERS 2 0
   Hai-bo L, 2008, CHIN INTERN COMBUST, V29, P15
   Huang D, 2010, 2010 INT C COMP CONT
   International Organization for Standardization, 1999, ROAD VEH DIAGN SYST
   Kazuma O, 2006011501 SAE
   Lijun Z, 2009, AUTOMOB TECHNOL, P28
   Moritaka M, 2004011896 SAE
   Navet N, 2005, P IEEE, V93, P1204, DOI 10.1109/JPROC.2005.849725
   Prucka MJ, 200501006 SAE
   *SAE, 1993, J20561 SAE
   Santoro L, 2005010806 SAE
NR 14
TC 2
Z9 2
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8993
EP 9005
DI 10.1007/s11042-013-1485-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600021
DA 2024-07-18
ER

PT J
AU Liu, WJ
   Wang, AH
   Chang, CC
   Li, ZH
   Liu, L
AF Liu, Wenjie
   Wang, Anhong
   Chang, Chin-Chen
   Li, Zhihong
   Liu, Li
TI A grouped-scalable secret image sharing scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grouped-management; Scalable; Secret sharing; Threshold scheme;
   Steganography
ID EFFICIENT
AB This paper addresses the problem of sharing the secret image among several groups with different priorities, resulting in a scheme of grouped-scalable secret image sharing. Our scheme is based on the concepts of bit-plane decomposition and Shamir's (k, n)-threshold scheme: first, the secret image is decomposed into several subimages of different quality; second, each subimage is shared to generate shadows which are then embedded into the corresponding cover image by steganography, generating a group of stego images. The stego images in the same group are distributed to some specified participants with the same priority. At the receiver side, each subimage can be reconstructed only if more than k different shadows of the same group are provided, while the cooperation of fewer than k participants in each group or more than k participants from different groups cannot obtain anything about the subimage. Scalable recovering of the secret image is achieved when different groups offer their restored subimages. The lossless restoration of the secret image and cover images can be achieved when all of the subimages are available. The experimental results show the superiority of our scheme for grouped-management applications of secret images.
C1 [Liu, Wenjie; Wang, Anhong; Li, Zhihong; Liu, Li] Taiyuan Univ Sci & Technol, Inst Digital Media & Commun, Taiyuan, Peoples R China.
   [Chang, Chin-Chen] Feng Chia Univ, Taichung 407, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichuang 413, Taiwan.
C3 Taiyuan University of Science & Technology; Feng Chia University; Asia
   University Taiwan
RP Wang, AH (corresponding author), Taiyuan Univ Sci & Technol, Inst Digital Media & Commun, Taiyuan, Peoples R China.
EM liuwenjie0712@163.com; wah_ty@163.com; alan3c@gmail.com
RI Chang, Ching-Chun/JAN-6210-2023; Wang, Anhong/HJP-9040-2023
FU NSFC [61272262]; Shanxi NSF [2012011014-3]; Youth Science and Technology
   Research Foundation of TYUST [20123004]
FX This work was supported in part by NSFC (No. 61272262), Shanxi NSF (No.
   2012011014-3), Youth Science and Technology Research Foundation of TYUST
   (No.20123004).
CR Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chen SK, 2005, PATTERN RECOGN, V38, P2466, DOI 10.1016/j.patcog.2005.04.002
   Chen TH, 2011, SIGNAL PROCESS, V91, P90, DOI 10.1016/j.sigpro.2010.06.012
   Cheng Guo, 2011, Journal of Multimedia, V6, P341, DOI 10.4304/jmm.6.4.341-348
   Chin-Chen Chang, 2011, Journal of Electronic Science and Technology, V9, P325, DOI 10.3969/j.issn.1674-862X.2011.04.008
   Dastanian R, 2011, INT PROC COMPUT SCI, V6, P171
   Dehkordi MH, 2008, INFORM SCIENCES, V178, P2262, DOI 10.1016/j.ins.2007.11.031
   Fang WP, 2007, ELE COM ENG, P108
   Fang WP, 2008, PATTERN RECOGN, V41, P1410, DOI 10.1016/j.patcog.2007.09.004
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Huang CP, 2010, J SYST SOFTWARE, V83, P517, DOI 10.1016/j.jss.2009.10.012
   Kong J, 2007, LECT NOTES COMPUT SC, V4688, P736
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Lin TL, 2010, EXPERT SYST APPL, V37, P7858, DOI 10.1016/j.eswa.2010.04.051
   Lukac R, 2005, PATTERN RECOGN, V38, P767, DOI 10.1016/j.patcog.2004.11.010
   Naor M, 1995, Advances in cryptographyEurocrypt'94. Vis lecture notes in computer science, V950, P1, DOI [DOI 10.1007/BFB0053419, 10.1007/BFb0053419, DOI 10.1007/978-1-4939-9484-7_1]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
NR 23
TC 4
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7095
EP 7109
DI 10.1007/s11042-014-1953-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800023
DA 2024-07-18
ER

PT J
AU Tan, SY
   Yau, WC
   Lim, BH
AF Tan, Syh-Yuan
   Yau, Wei-Chuen
   Lim, Boon-Hock
TI An implementation of enhanced public key infrastructure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PKI; Identity-based; Cryptography; EJBCA
AB In this paper, we present the implementation of an enhanced public key infrastructure (PKI) which supports not only conventional public key cryptography (PKC) but also identity-based cryptography (IBC). In addition, we discuss the possible way of placing together IBC and PKI as well as solving the problems of user secret key revocation of PKI and IBC. As a proof of concept, an IBC framework is incorporated into Enterprise Java Bean Certified Authority (EJBCA) and the performance is reported.
C1 [Tan, Syh-Yuan; Lim, Boon-Hock] Multimedia Univ, Fac Informat Sci & Technol, Melaka, Malaysia.
   [Yau, Wei-Chuen] Multimedia Univ, Fac Engn, Cyberjaya, Malaysia.
C3 Multimedia University; Multimedia University
RP Tan, SY (corresponding author), Multimedia Univ, Fac Informat Sci & Technol, Melaka, Malaysia.
EM sytan@mmu.edu.my; boonhock0204@gmail.com; wcyau@mmu.edu.my
RI Tan, Syh-Yuan/P-6811-2019
OI Tan, Syh-Yuan/0000-0003-1182-1210
FU FRGS Grant [FRGS/1/2012/TK06/MMU/03/9]; TM RD Grant [RDTC/130827]
FX This research is partially supported by FRGS Grant
   (FRGS/1/2012/TK06/MMU/03/9) and TM R&D Grant (RDTC/130827).
CR [Anonymous], 2009, FIPS PUB, P186
   [Anonymous], LNCS
   [Anonymous], INT C AV REL SEC
   ANSI, 2005, X962 ANSI
   Carlisle Adams SL, 1999, UNDERSTANDING PUBLIC
   Chen L, 2002, LECT NOTES COMPUT SC, V2433, P322
   Chen Q, 2007, IFIP INT C NETW PARA, P140, DOI 10.1109/NPC.2007.30
   Dalton C.R., 2003, Information Security Technical Report, V8, P73
   Eslami Z, 2014, MULTIMED TOOLS APPL, V72, P2723, DOI 10.1007/s11042-013-1555-0
   Galindo D, LNCS, V5580, P135
   Kiltz E, P CISS 08, V2, P31
   Krishnamurthy S, 2008, NIST ID BAS ENCR WOR
   Price G, 2005, LECT NOTES COMPUT SC, V3545, P73, DOI 10.1007/11533733_5
   Rong R, 2007, IEEE INT WORKSH ANT
   Shamir A., 1984, WORKSH THEOR APPL CR, P47, DOI DOI 10.1007/3-540-39568-7
   Stoianov N, 2015, MULTIMED TOOLS APPL, V74, P4453, DOI 10.1007/s11042-013-1532-7
   Yi X, 2013, MULTIMEDIA TOOLS APP
NR 17
TC 3
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6481
EP 6495
DI 10.1007/s11042-014-2119-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700025
DA 2024-07-18
ER

PT J
AU Miao, J
   Chu, J
   Zhang, GM
AF Miao, Jun
   Chu, Jun
   Zhang, Guimei
TI Detection of saliency maximally stable color regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Maximally stable extremal region; Color; Saliency
ID ATTRIBUTES
AB In this study, we propose to detect regions of interest based on salient information in images. The maximally stable color region (MSCR) approach is extended by incorporating color salient information into the stable region detection design. Salient regions with a color similar to that of their vicinity are detected successively through agglomerative clustering. The algorithm introduces novel methods used in color saliency enhancement into the context of local feature detection. The color saliency enhancement approach is evaluated by detecting salient objects. Experimental results demonstrate that our algorithm yields high precision and recall rates, and focuses on the interesting color structure of the image. The proposed detector is also evaluated by using an image matching test. The experimental results show that this detector outperforms intensity- and color-based detectors in terms of match correspondence.
C1 [Miao, Jun] Nanchang Hangkong Univ, Sch Mechatron Engn, Nanchang, Peoples R China.
   [Miao, Jun; Chu, Jun; Zhang, Guimei] Nanchang Hangkong Univ, Inst Comp Vis, Nanchang, Peoples R China.
C3 Nanchang Hangkong University; Nanchang Hangkong University
RP Chu, J (corresponding author), Nanchang Hangkong Univ, Inst Comp Vis, Nanchang, Peoples R China.
EM miaojun@nchu.edu.cn; chuj@nchu.edu.cn; guimeizhang@nchu.edu.cn
FU National Natural Science Foundation of China [61263046, 61063030];
   Aviation Science Foundation of China [2010ZC56005]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61263046, 61063030), Aviation Science Foundation of China
   (No. 2010ZC56005).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2006, ECCV
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Forssen P.-E., 2007, IEEE International Conference on Computer Vision (ICCV), P1, DOI DOI 10.1109/CVPR.2007.383120
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heiler M, 2005, INT J COMPUT VISION, V63, P5, DOI 10.1007/s11263-005-4944-7
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Khan FS, 2012, PROC CVPR IEEE, P3306, DOI 10.1109/CVPR.2012.6248068
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Penas M, 2009, LECT NOTES COMPUT SC, V5716, P965, DOI 10.1007/978-3-642-04146-4_103
   Pouli T, 2011, COMPUT GRAPH FORUM, V30, P1761, DOI 10.1111/j.1467-8659.2011.01900.x
   Qu YY, 2014, MULTIMED TOOLS APPL, V70, P605, DOI 10.1007/s11042-012-1107-z
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Unnikrishnan R, 2006, P BRIT MACH VIS C ED
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Vigo DR, 2010, P IS TS 5 EUR C COL, P228
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
NR 25
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5845
EP 5860
DI 10.1007/s11042-014-1893-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100023
DA 2024-07-18
ER

PT J
AU Wang, R
   Xu, MK
   Ping, XJ
   Zhang, T
AF Wang, Ran
   Xu, Mankun
   Ping, Xijian
   Zhang, Tao
TI Steganalysis of JPEG images by block texture based segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; JPEG steganography; Image texture; Image segmentation
ID STEGANOGRAPHY
AB The current JPEG steganalysis systems have attained outstanding achievements. A considerable variety of strategies for feature extraction are developed. However, a common shortcoming in the traditional image steganalysis techniques is that they are conducted on the entire image and do not take advantage of the content diversity. In this paper, a new steganalysis algorithm based on image segmentation is proposed to enable us to utilize the content characteristics of JPEG images. The images are segmented into several sub-images according to the texture complexity. The steganalysis features of each type of sub-images with the same or close texture complexity are extracted separately to build a classifier. The steganalysis results of the entire image are determined through a weighted fusing process. Experimental results demonstrate that the proposed method exhibits excellent performance and significantly improves the detection accuracy.
C1 [Wang, Ran; Xu, Mankun; Ping, Xijian; Zhang, Tao] Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
C3 PLA Information Engineering University
RP Wang, R (corresponding author), Zhengzhou Informat Sci & Technol Inst, Zhengzhou 450002, Henan, Peoples R China.
EM wangran721@gmail.com
CR Amirkhani H, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3554413
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   Böhme R, 2004, LECT NOTES COMPUT SC, V3193, P125
   Cancelli G, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P795, DOI 10.1109/MMSP.2008.4665182
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CH, 2008, IEEE INT SYMP CIRC S, P3029, DOI 10.1109/ISCAS.2008.4542096
   Cho SH, 2010, IEEE INT SYMP CIRC S, P1679, DOI 10.1109/ISCAS.2010.5537499
   Davidson J, 2010, LECT NOTES COMPUT SC, V6387, P118, DOI 10.1007/978-3-642-16435-4_10
   Fridrich J, 2005, MULTIMEDIA SYST, V11, P98, DOI 10.1007/s00530-005-0194-3
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich J, 2003, LECT NOTES COMPUT SC, V2578, P310
   Fridrich J., 2002, PROC ACM WORKSHOP MU, P3
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Fu DD, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P310, DOI 10.1109/MMSP.2006.285320
   Goljan M, 2006, PROC SPIE, V6072, DOI 10.1117/12.643254
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kodovsky J, 2011, PROC SPIE, V7880, DOI 10.1117/12.872279
   Kodovsky J, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P63
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Lafferty P, 2004, PROC SPIE, V5561, P145, DOI 10.1117/12.559896
   Li B, 2009, IEEE T INF FOREN SEC, V4, P369, DOI 10.1109/TIFS.2009.2025841
   Liu QZ, 2008, PATTERN RECOGN, V41, P56, DOI 10.1016/j.patcog.2007.06.005
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Sachnev V, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P131
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Schaefer G., 2003, UCID AN UNCOMPRESSED
   Shi YQ, 2007, LECT NOTES COMPUT SC, V4437, P249
   Solanki K, 2007, LECT NOTES COMPUT SC, V4567, P16
NR 30
TC 10
Z9 15
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5725
EP 5746
DI 10.1007/s11042-014-1880-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100017
DA 2024-07-18
ER

PT J
AU Zaid, AO
   Hachani, M
   Puech, W
AF Zaid, A. Ouled
   Hachani, M.
   Puech, W.
TI Wavelet-based high-capacity watermarking of 3-D irregular meshes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Three-dimensional meshes; Watermarking; Wavelet transform; Quantization
   index modulation
ID MULTIRESOLUTION ANALYSIS; DIGITAL WATERMARKING; SCHEME
AB Digital watermarking can be used as data hiding technique to interleave cover content with auxiliary information before transmitting and storing applications. While image and video watermarking has been widely studied, much less attention has been paid to its application in 3D mesh models. This is principally due to their intrinsic irregular sampling nature. This paper proposes a high-capacity watermarking scheme for the purpose of inserting meta-data into 3D triangle meshes. Our proposal can be applied to meshes with arbitrary topology by using irregular wavelet-based analysis. The watermark is embedded in an appropriate resolution level by quantizing the norms of wavelet coefficient vectors. To ensure robustness to similarity transformation, a robust synchronization (indexing) mechanism is performed on the 3D model after irregular wavelet analysis. Experimental results show that our watermarking framework is robust to common geometric attacks and can provide relatively high data embedding rate whereas keep a relative lower distortion.
C1 [Zaid, A. Ouled; Hachani, M.] Univ Tunis El Manar, Natl Engn Sch Tunis, SysCom Lab, Tunis 1002, Tunisia.
   [Puech, W.] CNRS, UMR 5506, LIRMM Lab, F-34095 Montpellier 5, France.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier
RP Zaid, AO (corresponding author), Univ Tunis El Manar, Natl Engn Sch Tunis, SysCom Lab, BP 37, Tunis 1002, Tunisia.
EM azza.ouledzaid@isi.rnu.tn; meha.hachani@gmail.com;
   william.puech@lirmm.fr
OI Puech, William/0000-0001-9383-2401; Ouled Zaid, Azza/0000-0002-3264-5933
CR Ai QS, 2009, SIGNAL PROCESS, V89, P2159, DOI 10.1016/j.sigpro.2009.04.031
   Alface RP, 2007, LNCS T DATA HIDING M, V2, P99
   Aspert N., 2002, MESH MEASURING ERROR
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Bors AG, 2006, IEEE T IMAGE PROCESS, V15, P687, DOI 10.1109/TIP.2005.863116
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Chen LP, 2011, EURASIP J ADV SIG PR, DOI 10.1155/2011/216783
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Chung IL, 2011, INT J INNOV COMPUT I, V7, P3419
   COSTA MHM, 1983, IEEE T INFORM THEORY, V29, P439, DOI 10.1109/TIT.1983.1056659
   Cox IJ., 2007, DIGITAL WATERMARKING
   Gao X, 2012, ACM T MULTIMED COMPU, V8
   KANAI S, 1998, P 6 IFIP WG 5 2 GEO, P296
   Kim MS, 2005, LECT NOTES COMPUT SC, V3710, P313
   Lavoue G, 2006, P SPIE ELECT IMAGING, V6312
   Lee H, 2012, APPL MATH COMPUT, V27, P781
   Lin CH, 2013, INT J INNOV COMPUT I, V9, P1321
   Lounsbery M, 1997, ACM T GRAPHIC, V16, P34, DOI 10.1145/237748.237750
   Maret Y, 2004, P MULT SEC WORKSH, P68
   Shanchao Yang, 2010, Journal of Software, V5, P437, DOI 10.4304/jsw.5.4.437-446
   Sweldens W, 1998, SIAM J MATH ANAL, V29, P511, DOI 10.1137/S0036141095289051
   Uccheddu F., 2004, PROC ACM MULTIMEDIA, P143
   Valette S, 2004, IEEE T VIS COMPUT GR, V10, P113, DOI 10.1109/TVCG.2004.1260763
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang K, 2008, IEEE T INF FOREN SEC, V3, P620, DOI 10.1109/TIFS.2008.2007229
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 28
TC 17
Z9 19
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5897
EP 5915
DI 10.1007/s11042-014-1896-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100026
DA 2024-07-18
ER

PT J
AU Cichowski, J
   Czyzewski, A
   Kostek, B
AF Cichowski, Janusz
   Czyzewski, Andrzej
   Kostek, Bozena
TI Analysis of impact of audio modifications on the robustness of watermark
   for non-blind architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-blind audio watermarking; Discrete wavelet transform; Lossy
   compression; Quality
ID SPREAD-SPECTRUM
AB The aim of this paper is to assess the robustness of the non-blind audio content watermarking scheme proposed by the authors. The authors present the architecture of the designed system along with the employed workflows for embedding and extracting the watermark followed by the implementation phase description and the analysis of the experimental results. Some possible attack simulations on the embedded watermarks are reviewed, and the robustness of the proposed approach is evaluated in the context of the influence of lossy compression on the watermark degradation. Subjective and objective analyses are performed for the algorithm proposed by the authors and compared with the Audio Watermarking Tools (AWT) encoder. Finally, the advantages and drawbacks of the proposed approach are debated followed by the conclusion section outlining possible improvements to the proposed method.
C1 [Cichowski, Janusz; Czyzewski, Andrzej] Gdansk Univ Technol, Multimedia Syst Dept, PL-80233 Gdansk, Poland.
   [Kostek, Bozena] Lab Audio Acoust, PL-80233 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Cichowski, J (corresponding author), Gdansk Univ Technol, Multimedia Syst Dept, Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM jay@sound.eti.pg.gda.pl; andcz@sound.eti.pg.gda.pl;
   bokostek@audioacoustics.org
RI Czyzewski, Andrzej/JXN-0946-2024
OI Czyzewski, Andrzej/0000-0001-9159-8658; Kostek,
   Bozena/0000-0001-6288-2908
FU National Centre for Research and Development (NCBiR, Poland)
   [SP/I/1/77065/10]
FX The research was founded within the project No. SP/I/1/77065/10
   entitled: "Creation of universal, open, repository platform for hosting
   and communication of networked resources of knowledge for science,
   education and open society of knowledge", being a part of Strategic
   Research Program "Interdisciplinary system of interactive scientific and
   technical information" supported by The National Centre for Research and
   Development (NCBiR, Poland).
CR Al-Haj AM, 2012, ADV TECHNIQUES MULTI
   [Anonymous], Janus Patent - U.S. Patent, Patent No. [7,010,808, 7010808]
   [Anonymous], 1969, 20 RFC
   [Anonymous], U.S. Patent, Patent No. [8,116,514, 8116514]
   Bhatnagar G, 2012, IET IMAGE PROCESS, V6, P386, DOI 10.1049/iet-ipr.2010.0400
   Bhatnagar G, 2013, MULTIMED TOOLS APPL, V66, P179, DOI 10.1007/s11042-011-0788-z
   Bloom J.A., 2008, DIGITAL WATERMARKING
   Ciarkowski A, 2010, SMART INNOV SYST TEC, V6, P69
   Cichowski J, 2013, INTELL TOOLS BUILD S, DOI [10.1007/978-3-642-35647-6_27, DOI 10.1007/978-3-642-35647-6_27]
   Czyzyk P, 2012, COMM COM INF SC, V287, P36
   Dutta MK, 2009, 7 INT C INF COMM SIG, V1, P55, DOI [10.1109/ICICS.2009.5397484, DOI 10.1109/ICICS.2009.5397484]
   Foo SW, 2010, WORLD ACAD SCI ENG T, V37, P680
   Furht B., 2006, MULTIMEDIA ENCRYPTIO
   Kondo K, 2011, J AUDIO ENG SOC, V59, P379
   Lang A., 2005, P 7 WORKSHOP MULTIME, P39
   Maha C, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1138, DOI 10.1109/ISCCSP.2008.4537396
   Pérez-Freire L, 2006, LECT NOTES COMPUT SC, V4300, P41
   Pérez-Freire L, 2009, IEEE T INF FOREN SEC, V4, P2, DOI 10.1109/TIFS.2008.2009603
   Petitcolas FAP, 1998, LECT NOTES COMPUT SC, V1525, P218
   Samaali I, 2012, J AUDIO ENG SOC, V60, P431
   Singh J, 2014, MULTIMED TOOLS APPL, V71, P1431, DOI 10.1007/s11042-012-1282-y
   Subramanyam AV, 2014, MULTIMED TOOLS APPL, V71, P1311, DOI 10.1007/s11042-012-1272-0
   Szwoch G, 2009, J AUDIO ENG SOC, V57, P916
   Taneja N, 2013, MULTIMED TOOLS APPL, V67, P593, DOI 10.1007/s11042-012-1037-9
   Tang ZJ, 2011, MULTIMED TOOLS APPL, V52, P325, DOI 10.1007/s11042-009-0437-y
   Venkataramu R., 2007, Analysis and enhancement of Apple's Fairplay Digital Rights Management
   Wassermann J, 2013, COMM COM INF SC, V368, P298
NR 27
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4415
EP 4435
DI 10.1007/s11042-013-1636-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600014
OA hybrid
DA 2024-07-18
ER

PT J
AU Hu, ZZ
   Matsuyama, T
   Nobuhara, S
AF Hu, Zhaozheng
   Matsuyama, Takashi
   Nobuhara, Shohei
TI Cell-based visual surveillance with active cameras for 3D human gaze
   computation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cell-based surveillance; Active cameras; Camera layout; Cell partition;
   Cell-based calibration
AB Capturing fine resolution and well-calibrated video images with good object visual coverage in a wide space is a tough task for visual surveillance. Although the use of active cameras is an emerging method, it suffers from the problems of online camera calibration difficulty, mechanical delay handling, image blurring from motions, and algorithm un-friendly due to dynamic backgrounds, etc. This paper proposes a cell-based visual surveillance system by using N (N a parts per thousand yenaEuro parts per thousand 2) active cameras. We propose the camera scan speed map (CSSM) to deal with the practical mechanical delay problem for active camera system design. We formulate the three mutually-coupled problems of camera layout, surveillance space partition with cell sequence, and camera parameter control, into an optimization problem by maximizing the object resolution while meeting various constraints such as system mechanical delay, full visual coverage, minimum object resolution, etc. The optimization problem is solved by using a full searching approach. The cell-based calibration method is proposed to compute both the intrinsic and exterior parameters of active cameras for different cells. With the proposed system, the foreground object is detected based on motion and appearance features and tracked by dynamically switching the two groups of cameras across different cells. The proposed algorithms and system have been validated by an in-door surveillance experiment, where the surveillance space was partitioned into four cells. We used two active cameras with one camera in one group. The active cameras were configured with the optimized pan, tilt, and zooming parameters for different cells. Each camera was calibrated with the cell-based calibration method for each configured pan, tilt, and zooming parameters. The algorithms and system were applied to monitor freely moving peoples within the space. The system can capture good resolution, well-calibrated, and good visual coverage video images with static background in support of automatic object detection and tracking. The proposed system performed better than traditional single or multiple fixed camera system in term of image resolution, surveillance space, etc. We further demonstrated that advanced 3D features, such as 3D gazes, were successfully computed from the captured good-quality images for intelligent surveillance.
C1 [Hu, Zhaozheng] Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Peoples R China.
   [Hu, Zhaozheng; Matsuyama, Takashi; Nobuhara, Shohei] Kyoto Univ, Grad Sch Informat, Sakyo Ku, Kyoto 6068501, Japan.
C3 Wuhan University of Technology; Kyoto University
RP Hu, ZZ (corresponding author), Wuhan Univ Technol, ITS Res Ctr, Wuhan 430063, Peoples R China.
EM zhaozheng.hu@gmail.com
RI Hu, Zhaozheng/AGC-2475-2022; Nobuhara, Shohei/HWS-3289-2023
OI Nobuhara, Shohei/0000-0002-3204-8696; Hu, Zhaozheng/0000-0002-7204-2459
FU National Natural Science Foundation of China (NSFC) [51208168]; Tianjin
   Natural Science Foundation [13JCYBJC37700]; Youth Top-Notch Talent Plan
   of Hebei Province, China; Japan Society for the Promotion of Science
   (JSPS) [10049]
FX The work presented in this paper was sponsored by grants from National
   Natural Science Foundation of China (NSFC) (No. 51208168), Tianjin
   Natural Science Foundation (No. 13JCYBJC37700), the Youth Top-Notch
   Talent Plan of Hebei Province, China, and the Grant-in-Aid for
   Scientific Research Program (No. 10049) from the Japan Society for the
   Promotion of Science (JSPS).
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Bellotto N, 2012, COMPUT VIS IMAGE UND, V116, P457, DOI 10.1016/j.cviu.2011.09.011
   Bradski GaryR., 1998, Computer vision face tracking for use in a perceptual user interface
   Chen KW, 2011, IEEE T MULTIMEDIA, V13, P1256, DOI 10.1109/TMM.2011.2165055
   De D, 2005, LECT NOTES COMPUT SC, V3776, P413
   Erdem UM, 2006, COMPUT VIS IMAGE UND, V103, P156, DOI 10.1016/j.cviu.2006.06.005
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Loy CC, 2011, PATTERN RECOGN, V44, P117, DOI 10.1016/j.patcog.2010.07.023
   Matsuyama T, 2002, P IEEE, V90, P1136, DOI 10.1109/JPROC.2002.801442
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Qun Shi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P149, DOI 10.2197/ipsjtcva.4.149
   Saini M., 2012, MULTIMEDIA TOOLS APP
   Sankaranarayanan K., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3433, DOI 10.1109/CVPR.2011.5995398
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Yamaguchi Tatsuhisa, 2010, IPSJ Transactions on Computer Vision and Applications, V2, P169, DOI 10.2197/ipsjtcva.2.169
   Yamaguchi T, 2010, GEOM COMPUT, V5, P171, DOI 10.1007/978-3-642-12392-4_8
   Yonetani Ryo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P101, DOI 10.1109/ICPR.2010.33
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 21
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 4161
EP 4185
DI 10.1007/s11042-013-1816-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800025
DA 2024-07-18
ER

PT J
AU Zhong, CC
   Miao, ZJ
AF Zhong, Cencen
   Miao, Zhenjiang
TI Multi-label audio concept detection using correlated-aspect Gaussian
   Mixture Model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aspect Gaussian Mixture Model; Probabilistic latent semantic analysis;
   Audio concept detection; Concept correlation; Multi-label classification
AB As an essentially multi-label classification problem, audio concept detection is normally solved by treating concepts independently. Since in this process the original useful concept correlation information is missing, this paper proposes a new model named Correlated-Aspect Gaussian Mixture Model (C-AGMM) to take advantage of such a clue for enhancing multi-label audio concept detection. Originating from Aspect Gaussian Mixture Model (AGMM) which improves GMM by incorporating it into probabilistic Latent Semantic Analysis (pLSA), C-AGMM still learns a probabilistic model of the whole audio clip by regarding concepts as its component elements. However, different from AGMM that assumes concepts independent with each other, C-AGMM considers their distribution on a sub-manifold embedded in the ambient space. With an assumption that if two concepts are close in the intrinsic geometry of this distribution then their conditional probability distributions are likely to show similarity, a graph regularizer is exploited to model the correlation between these concepts. Following the Maximum Likelihood Estimate principle, model parameters of C-AGMM encoding the concept correlation clue are derived and used directly as the detection criterion. Experiments on two datasets show the effectiveness of our proposed model.
C1 [Zhong, Cencen; Miao, Zhenjiang] Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
C3 Beijing Jiaotong University
RP Zhong, CC (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
EM 07112072@bjtu.edu.cn; zjmiao@bjtu.edu.cn
FU National Science Foundation of China [61273274, 4123104]; National 973
   Key Research Program of China [2011CB302203]; Ph.D. Programs Foundation
   of Ministry of Education of China [20100009110004]; National Key
   Technology R&D Program of China [2012BAH01F03]; Tsinghua-Tencent Joint
   Lab for IIT
FX This work is supported by the National Science Foundation of China
   (61273274, 4123104), National 973 Key Research Program of China
   (2011CB302203), Ph.D. Programs Foundation of Ministry of Education of
   China (20100009110004), National Key Technology R&D Program of China
   (2012BAH01F03) and Tsinghua-Tencent Joint Lab for IIT.
CR Ahrendt P, 2005, MACHINE LEARN SIGN P, P247, DOI 10.1109/MLSP.2005.1532908
   [Anonymous], 2007, P ASS COMP MACH MULT
   [Anonymous], 2008, Proceedings of the 17th ACM Conference on Information and Knowledge Management, CIKM '08
   [Anonymous], 2007, P CIKM
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Bertin-Mahieux T, 2008, J NEW MUSIC RES, V37, P115, DOI 10.1080/09298210802479250
   Chu S., 2006, AAAI FALL S AUR INF, P16
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ellis DPW, 2011, INT CONF ACOUST SPEE, P5880
   Eronen AJ, 2006, IEEE T AUDIO SPEECH, V14, P321, DOI 10.1109/TSA.2005.854103
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jiang YG, 2009, IEEE I CONF COMP VIS, P1420, DOI 10.1109/ICCV.2009.5459295
   JUANG BH, 1991, TECHNOMETRICS, V33, P251, DOI 10.2307/1268779
   Lee K, 2010, INT CONF ACOUST SPEE, P2278, DOI 10.1109/ICASSP.2010.5495915
   Lee K, 2010, IEEE T AUDIO SPEECH, V18, P1406, DOI 10.1109/TASL.2009.2034776
   Li YN, 2010, IEEE T MULTIMEDIA, V12, P814, DOI 10.1109/TMM.2010.2066960
   Liu JL, 2010, AAAI CONF ARTIF INTE, P512
   Ma L., 2006, ACM Trans. Speech Lang. Process, V3, P1, DOI [DOI 10.1145/1149290.1149292, 10.1145/1149290.1149292]
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Tan ChunChet., 2011, ACM MM, P655
   Wang C., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383221
   Wang Z., 2013, Foaming properties of whey protein isolate and lambda-carrageenan mixed systems, P1
   Zhang T, 2001, IEEE T SPEECH AUDI P, V9, P441, DOI 10.1109/89.917689
NR 24
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4817
EP 4832
DI 10.1007/s11042-013-1842-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400017
DA 2024-07-18
ER

PT J
AU Chiang, CC
   Yang, HF
AF Chiang, Cheng-Chieh
   Yang, Huei-Fang
TI Quick browsing and retrieval for surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance video; Video browsing and retrieval; Compact video; Moving
   objects
AB Searching for specific targets from surveillance videos requires huge workforce due to a surveillance system usually generates great amounts of video data. To alleviate the effort of human analysis, a system that helps users quickly look for targets of interest is highly demanded. In this paper, we propose a browsing and retrieval system for users to quickly locate desired targets in surveillance videos. Our basic idea is to collect all moving objects, which carry the most significant information in surveillance videos, to construct a corresponding compact video. The temporal coordinates of the moving objects in the compact video are rearranged, therefore increasing the compactness of the video. However, the appearing order of the moving objects is kept to preserve the essential activities involved in the original surveillance video. Using our system, users will spend only several minutes watching the compact video instead of hours monitoring a long surveillance video. We conducted experiments to demonstrate that the proposed system can help users quickly look for specific targets in surveillance videos.
C1 [Chiang, Cheng-Chieh] Takming Univ Sci & Technol, Dept Informat Technol, Taipei 114, Taiwan.
   [Yang, Huei-Fang] MORPHEME INRIA CNRS UNSA, F-06903 Sophia Antipolis, France.
C3 Takming University Science & Technology
RP Chiang, CC (corresponding author), Takming Univ Sci & Technol, Dept Informat Technol, 56,Sec 1,Huan Shan Rd, Taipei 114, Taiwan.
EM kevin@csie.ntnu.edu.tw; hueifang@gmail.com
CR Chang S-F, 2007, P 6 ACM INT C IM VID
   Chen BW, 2009, IEEE T MULTIMEDIA, V11, P295, DOI 10.1109/TMM.2008.2009703
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   de Rooij O, 2010, IEEE T MULTIMEDIA, V12, P121, DOI 10.1109/TMM.2009.2037388
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Hampapur A, 2007, P IEEE C ADV VID SIG
   Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Jiang P, 2010, IEEE MULTIMEDIA, V17, P64, DOI 10.1109/MMUL.2009.65
   Le T-L, 2010, P INT C COMM EL ICCE
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu TC, 2007, MULTIMEDIA SYST, V12, P289, DOI 10.1007/s00530-006-0053-x
   Philip D., 2010, P ACM INT C MULT, P371, DOI [10.1145/1873951.1874002, DOI 10.1145/1873951.1874002]
   Pongnumkul S, 2010, P ACM S US INT SOFTW, P139
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Pritch Y, 2008, IEEE T PATTERN ANAL, V30, P1971, DOI 10.1109/TPAMI.2008.29
   Rav-Acha A, 2007, IEEE T PATTERN ANAL, V29, P1789, DOI 10.1109/TPAMI.2007.1091
   Ren K, 2010, MULTIMED TOOLS APPL, V49, P513, DOI 10.1007/s11042-009-0445-y
   Schffmann K, 2010, SPIE REV, V1
   Schonert-Reichl KA., 2012, SCH MENT HEALTH, V4, P1
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Yong S-P, 2010, P 25 INT C IM VIS CO
   Yu X-D, 2004, P 10 INT MULT MOD C
   Yuan J, 2012, LECT NOTES COMPUT SC, V7131, P642
NR 25
TC 11
Z9 12
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 9
BP 2861
EP 2877
DI 10.1007/s11042-013-1750-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CF7NI
UT WOS:000352742800001
DA 2024-07-18
ER

PT J
AU Tseng, FH
   Chen, XJ
   Chou, LD
   Chao, HC
   Chen, SP
AF Tseng, Fan-Hsun
   Chen, Xiaojiao
   Chou, Li-Der
   Chao, Han-Chieh
   Chen, Shiping
TI Support vector machine approach for virtual machine migration in cloud
   data center
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media service; Load balance; Support vector machine; Mixed
   integer linear programming; Cloud data center
ID ALGORITHM; SYSTEM; MANAGEMENT
AB The social media services are popular with Internet services today, such as Facebook, YouTube, Plurk and Twitter. However, the enormous interactions among human beings also result in highly computational costs. The requested resources and demands of some specific social media services are changing severely, and the virtual machines (VMs) exhaust the computing resource of physical machine (PM). Thus this will lead to VM migration. Many researchers investigate how to stabilize the average utilization of virtual machines and physical machines in cloud data center. In this paper, we formulated the VM migration problem in cloud data center based on mixed integer linear programming (MILP). Then, the VM allocation algorithm was proposed to allocate the VMs among the PMs, which is based on the Support Vector Machine (SVM). According to the training process during a specific time, the minimum numbers of VM migration and maximum resource utilization of PMs were accomplished. As the allocation case and simulation results showed, we achieved the stable and low-cost for social media services in cloud data center.
C1 [Tseng, Fan-Hsun; Chou, Li-Der] Natl Cent Univ, Dept Comp Sci & Informat Engn, Jhongli 32001, Taoyuan County, Taiwan.
   [Chen, Xiaojiao; Chen, Shiping] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
   [Chao, Han-Chieh] Natl Ilan Univ, Dept Elect Engn, Ilan 26047, Taiwan.
   [Chao, Han-Chieh] Natl Ilan Univ, Dept Comp Sci & Informat Engn, Ilan 26047, Taiwan.
   [Chao, Han-Chieh] Natl Dong Hwa Univ, Dept Elect Engn, Shoufeng 97401, Hualien, Taiwan.
   [Chen, Shiping] Univ Shanghai Sci & Technol, Network Ctr, Shanghai 200093, Peoples R China.
C3 National Central University; University of Shanghai for Science &
   Technology; National Ilan University; National Ilan University; National
   Dong Hwa University; University of Shanghai for Science & Technology
RP Chao, HC (corresponding author), Natl Ilan Univ, Dept Elect Engn, 1,Sec 1,Shen Lung Rd, Ilan 26047, Taiwan.
EM fhtseng@ieee.org; clkjh1210@163.com; cld@csie.ncu.edu.tw;
   hcc@niu.edu.tw; chensp@usst.edu.cn
OI Tseng, Fan-Hsun/0000-0003-2461-8377
FU National Science Council (NSC) of the Taiwan [NSC 101-2221-
   E-197-008-MY]; National Natural Science Foundation of China (NSFC)
   [61170277]; Innovation Program of Shanghai Municipal Education
   Commission [12zz137]; First-class Discipline Construction Project of
   Shanghai [S1201YLXK]; Innovation Fund Project for Graduate Student of
   Shanghai [JWCXSL1202]
FX This research was supported by the National Science Council (NSC) of the
   Taiwan under grants NSC 101-2221- E-197-008-MY. This research was also
   partly funded by the National Natural Science Foundation of China (NSFC)
   under Grant 61170277, the Innovation Program of Shanghai Municipal
   Education Commission under Grant 12zz137, the First-class Discipline
   Construction Project of Shanghai under Grant S1201YLXK, and the
   Innovation Fund Project for Graduate Student of Shanghai under Grant
   JWCXSL1202.
CR [Anonymous], J CONVERGENCE
   [Anonymous], P 1 INT C CLOUD COMP
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Boser BE, 1992, P ACM 5 ANN WORKSH C
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CY, 2011, IEEE T INF FOREN SEC, V6, P152, DOI 10.1109/TIFS.2010.2095845
   Cheng RS, 2010, INT J INTERNET PROTO, V5, P202, DOI 10.1504/IJIPT.2010.039231
   Chou LD, 2011, J INTERNET TECHNOL, V12, P139
   Chung H-Y, 2012, P IEEE INT C CLUST C
   Chung WC, 2012, INT J AD HOC UBIQ CO, V10, P74, DOI 10.1504/IJAHUC.2012.048259
   Clark C, 2005, P 2 USENIX C NETW SY
   Feng ZQ, 2012, J INTERNET TECHNOL, V13, P667
   Hsu HH, 2012, J INTERNET TECHNOL, V13, P963
   Hu J, 2010, P 3 INT S PAR ARCH A
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Khiyaita A., 2012, IEEE Computer, V21, P106
   Kim HS, 2012, INT J AD HOC UBIQ CO, V10, P63, DOI 10.1504/IJAHUC.2012.048258
   König B, 2012, IET COMMUN, V6, P1306, DOI 10.1049/iet-com.2011.0200
   Lai YX, 2013, INFORM SCIENCES, V230, P39, DOI 10.1016/j.ins.2012.10.002
   Lai YX, 2011, INT J COMMUN SYST, V24, P1375, DOI 10.1002/dac.1254
   LIBSVM, LIB SUPP VECT MACH
   Ma F, 2012, P IEEE 3 INT C SOFTW
   Mahajan K, 2013, J INF PROCESS SYST, V9, P379, DOI 10.3745/JIPS.2013.9.3.379
   Randles M., 2010, P IEEE 24 INT C ADV
   Strunk A, 2012, P IEEE 8 WORLD C SER
   Wang LZ, 2012, INT J AD HOC UBIQ CO, V10, P96, DOI 10.1504/IJAHUC.2012.048261
   Wang S-C, 2010, P IEEE 3 INT C COMP
   Wood T., 2007, P 4 USENIX C NETW SY
   Xie X, 2012, METIS PROFILING TOOL
   Zhu K, 2011, P IEEE AS PAC SERV C
NR 30
TC 15
Z9 17
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3419
EP 3440
DI 10.1007/s11042-014-2086-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000013
DA 2024-07-18
ER

PT J
AU Lee, YH
   Kim, Y
AF Lee, Yong-Hwan
   Kim, Youngseop
TI Efficient image retrieval using advanced SURF and DCD on mobile platform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image Retrieval; Mobile Image Search; ASURF (Advanced Speed-Up Robust
   Feature); DCD (Dominant Color Descriptor)
AB As the amount of digital image continues to grow in usage, users are experiencing increased difficulty in finding specific images in the image collection. This paper proposes a novel image searching scheme that extracts the image feature using combination of ASURF (Advanced Speed-Up Robust Feature) and DCD (Dominant Color Descriptor). The system for mobile image searches runs in real-time on iPhone, and can be easily used to find a natural color image. To evaluate the proposed scheme, we assessed the performance of simulation in term of average precision and F-score on two image database, which is commonly used in the field of image retrieval. The experimental results revealed that the proposed algorithm exhibited a significant improvement of over 14.4 % in retrieval effectiveness, compared to open source OpenSURF. The main contribution of this paper is that the proposed approach achieves high accuracy and stability by using ASURF and DCD in searching for natural image on mobile platform.
C1 [Lee, Yong-Hwan] Far East Univ, Dept Smart Mobile, Eumseong 369700, Chungbuk, South Korea.
   [Kim, Youngseop] Dankook Univ, Cheonan Si 330714, Chungnam, South Korea.
C3 Dankook University
RP Kim, Y (corresponding author), Dankook Univ, 119 Dandae Ro, Cheonan Si 330714, Chungnam, South Korea.
EM hwany1458@empal.com; wangcho@dankook.ac.kr
FU Dankook University
FX This work was supported by Dankook University project 2012 for funding.
CR [Anonymous], JTC1SC29WG11N7808 IS
   [Anonymous], IEEE T CIRC SYST VID
   [Anonymous], MULTIMED TOOLS APPL
   Apple Inc, 2014, INSTR US GUID
   Baeza-Yates R A, 2011, MODERN INFORM RETRIE
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Da Silva Torres R, 2006, RITA, V13, P165
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Evans C., 2009, NOTES OPENSURF LIB
   Han Y-J, 2009, INT C IND ENG ENG MA
   Hui H.W., 2010, INT J IMAGE PROCESS, V4, P192
   International Organization for Standards, 2005, 248001 ISOIEC JTC1 S
   Kumar A, 2011, THESIS THAPAR U
   Kumar VV, 2009, INT J FUTUR GENER CO, V2, P39
   Lakdashti A, 2008, 10TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS I-III, P969, DOI 10.1109/ICACT.2008.4493928
   Lee Y-H, 2013, IMPLEMENTATION IMAGE
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Ranathunga L, 2010, MALAYS J COMPUT SCI, V23, P68, DOI 10.22452/mjcs.vol23no2.1
   Surajpal DR, 2007, INDEPENDENT EVALUATI
   Thomee B., 2010, P INT C MULTIMEDIA M, P1473
   Velmurugan K, 2011, GLOBAL J COMPUT SCI, V10, P11
   Wong KM, 2004, THESIS CITY U HONG K
NR 22
TC 21
Z9 21
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2289
EP 2299
DI 10.1007/s11042-014-2129-5
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200007
DA 2024-07-18
ER

PT J
AU Park, JH
AF Park, Je-Ho
TI Low-cost image indexing for massive database
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image database; Identification; Indexing; Feature extraction
ID RETRIEVAL; VIDEO
AB According to the trend in the modern society that utilizes various image related services and products, the amount of images created by diverse personal and industrial devices is immeasurably voluminous. The adoption of very uncommon or unique identifiers or index attributes with admissible storage requirement and adequate data representation enables massive image databases to process demanded operations effectively and efficiently. For the last decades, various content-based image retrieval techniques have been studied and contributed to support indexing in large digital image databases. However, the complexity, high processing cost of the content-based image retrieval techniques might create inefficiency regarding the configuration of a high-performance image database even though satisfying their own objectives. Moreover the indexing methods with the property of low cardinality might need additional indexing in order to provide strong uniqueness. In this paper, we present identifier generation methods for indexing which are efficient and effective in the perspective of cost and indexing performance as well. The proposed methods exploit the distribution of line segments and luminance areas in an image in order to compose identifiers with high cardinality. From the experimental evaluation, we've learned that our approaches are effective and efficient regarding processing time, storage requirement and indexing performance.
C1 Dankook Univ, Comp Sci & Engn Dept, Yongin 330714, Gyeonggi Do, South Korea.
C3 Dankook University
RP Park, JH (corresponding author), Dankook Univ, Comp Sci & Engn Dept, 119 Dandae Ro, Yongin 330714, Gyeonggi Do, South Korea.
EM dk_jhpark@dankook.ac.kr
FU Dankook University
FX The present research was conducted by the research fund of Dankook
   University in 1012.
CR [Anonymous], 2012, 1593882002 ISOIEC
   [Anonymous], 2010, 1593832002 ISOIEC
   [Anonymous], 2008, LEARNING OPENCV COMP
   [Anonymous], MACH INTELL
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Bach J. R., 1996, STORAGE RETRIEVAL ST, V2670, P76
   Bransnett P, 2007, P VIS INF ENG C VIE, P25
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Danish M., 2013, IMAGE, V3, P839
   Döller M, 2013, IEEE MULTIMEDIA, V20, P38, DOI 10.1109/MMUL.2012.60
   Idris F, 1997, J VIS COMMUN IMAGE R, V8, P146, DOI 10.1006/jvci.1997.0355
   Kaushai M., 2010, INT J ENG SCI TECHNO, V2, P2077
   KIRYATI N, 1991, PATTERN RECOGN, V24, P303, DOI 10.1016/0031-3203(91)90073-E
   Kobayashi T, 2009, 2009 SYMPOSIUM ON BIO-INSPIRED LEARNING AND INTELLIGENT SYSTEMS FOR SECURITY (BLISS 2009), P58, DOI 10.1109/BLISS.2009.31
   Lananiere R., 2011, OPENCV 2 COMPUTER VI
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Nixon Mark S, 2012, FEATURE EXTRACTION I, DOI DOI 10.1016/B978-0-12-396549-3.00007-0
   Obeid M., 2001, Proceedings of the ninth ACM international conference on Multimedia, P531
   Pabboju S, 2009, INT J COMPUT SCI NET, V9, P119
   Paschalakis S, 2012, IEEE T CIRC SYST VID, V22, P1050, DOI 10.1109/TCSVT.2012.2189791
   POWELL G, 2005, BEGINNING DATABASE D
   Prewitt JMS, 1970, PICTURE PROGRAMMING
   Raoui Y., 2011, Applied Mathematical Sciences, V5, P2109
   Salomon D., 1991, COMPUTER GRAPHICS GE
   Schettini R, 2002, SURVEY METHODS COLOU
   Vega J., 2008, REV SCI INSTRUM, V79
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
NR 28
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2237
EP 2255
DI 10.1007/s11042-014-2026-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200004
DA 2024-07-18
ER

PT J
AU Han, K
   Shon, T
AF Han, Kyusuk
   Shon, Taeshik
TI Authentication of mobile applications through various local distributors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Authentication; Availability
AB Trends in software distribution indicate a rapid change in an online application market. Current smartphones enable users to easily install various applications that are purchased from the online market using their phone. In addition, the openness of the Android system even allows users to choose from various online markets. Because such openness also invokes critical threats such as malware and illegal use, several online markets employ strong authentication techniques. However, such methods can also inconvenience valid users. In this paper, we discuss such problems and propose the concept of an authentication model that makes purchased applications available in most cases.
C1 [Han, Kyusuk] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Shon, Taeshik] Ajou Univ, Div Informat & Comp Engn, Coll Informat Technol, Suwon 443749, South Korea.
C3 University of Michigan System; University of Michigan; Ajou University
RP Shon, T (corresponding author), Ajou Univ, Div Informat & Comp Engn, Coll Informat Technol, San 5, Suwon 443749, South Korea.
EM hankyusuk@gmail.com; taeshik.shon@gmail.com
RI Han, Kyusuk/AGK-2122-2022
OI Han, Kyusuk/0000-0002-8734-3107
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012R1A1A1010667]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (No. 2012R1A1A1010667).
CR Albano P., 2011, 2011 International Conference on Broadband, Wireless Computing, Communication and Applications, P380, DOI 10.1109/BWCCA.2011.62
   [Anonymous], 2010, INT WORKSHOP COMPUTA, DOI [10.1007/978-3-642-19376-7_12, DOI 10.1007/978-3-642-19376-7_12]
   [Anonymous], 2012, P 2 ACM C DATA APPL, DOI DOI 10.1145/2133601.2133640
   Backes M, 2011, NOVEL ATTACK ANDROID
   Cluley G, 2012, ANDROID MALWARE POSE
   Enck William, 2011, USENIX SEC S 2011
   Rashid FY, 2012, SCMAGAZINE      0726
NR 7
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1541
EP 1555
DI 10.1007/s11042-013-1520-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900002
DA 2024-07-18
ER

PT J
AU Wang, SX
   Pan, P
   Lu, YS
   Xie, L
AF Wang, Shixun
   Pan, Peng
   Lu, Yansheng
   Xie, Liang
TI Improving cross-modal and multi-modal retrieval combining content and
   semantics similarities with probabilistic model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-modal retrieval; Multi-modal retrieval; Content similarity;
   Semantics similarity; Probabilistic model
ID IMAGE; ANNOTATION
AB With the ongoing development of the internet, a large number of multimedia documents containing images and texts have appeared in the daily life of people. Therefore, how to effectively and efficiently conduct cross-modal and multi-modal retrieval is being an important issue. Although some methods have been proposed to deal with the issue, their retrieval processes are confined to a single information source of multimedia documents, such as the representations of images and texts at a semantic level. In this paper, we propose a novel probabilistic model, namely CCSS, which not only combines low-level content and high-level semantics similarities through a first-order Markov chain, but also provides heterogeneous similarity measures for different unimedia types. The ranked list for a query is obtained by highlighting an optimal path across the chain. Content similarity focuses on the internal structure of each modality, while semantics similarity focuses on the semantic correlation between different modalities. Both of them are significant and their combination can be complementary to each other. Multi-class logistic regression and random forests are used to map the original features of each unimedia into a semantic space. According to the query-by-example scenario, the experiments on the Wikipedia dataset show that the performance of our model significantly outperforms those of state-of-the-art approaches for cross-modal retrieval. Additionally, the proposed multi-modal method is also shown to outperform previous systems on image retrieval task.
C1 [Wang, Shixun; Pan, Peng; Lu, Yansheng; Xie, Liang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Pan, P (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM wsxun@hust.edu.cn; panpeng@mail.hust.edu.cn; lys@mail.hust.edu.cn;
   whutxl@hotmail.com
RI Pan, Feng/IXN-2297-2023
OI Wang, Shixun/0000-0002-5127-8403
CR [Anonymous], ICCV
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Clinchant S., 2011, ACM INT C MULT RETR
   Coviello E, 2012, IEEE INT C COMP VIS
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   Haubold A, 2006, IEEE INT C MULT EXP
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Li D., 2003, P ACM INT C MULT
   Lmura J, 2011, ACM INT C MULT
   Logan B., 2001, IEEE INT C MULT EXP
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Miotto R, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180870
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125
   VIA J, 2005, P 13 EUR SIGN PROC C
   Vinokourov A, 2003, INT S IND COMP AN BL
   Westerveld T, 2003, EURASIP J APPL SIG P, V2003, P186, DOI 10.1155/S111086570321101X
   Xie L, 2013, ACM INT C MULT RETR
   Yang Y, 2009, ACM INT C MULT
   Zhai X, 2012, INT C MULTIMED MOD M
   Zhai X, 2012, P ICASSP
   Zhai XH, 2013, MULTIMEDIA SYST, V19, P395, DOI 10.1007/s00530-012-0297-6
   Zhen Y, 2012, P ACM KDD
   Zhen Y, 2012, ADV NEURAL INF PROCE
   Zhen Y, 2013, DATA MIN KNOWL DISC, V26, P255, DOI 10.1007/s10618-012-0249-y
NR 37
TC 9
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 6
BP 2009
EP 2032
DI 10.1007/s11042-013-1737-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CD9CN
UT WOS:000351394500015
DA 2024-07-18
ER

PT J
AU Casanovas, AL
   Cavallaro, A
AF Casanovas, Anna Llagostera
   Cavallaro, Andrea
TI Audio-visual events for multi-camera synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio-visual processing; Multiple cameras; Synchronization; Event
   detection
ID ALIGNMENT; SPEECH
AB We present a multimodal method for the automatic synchronization of audio-visual recordings captured with a set of independent cameras. The proposed method jointly processes data from audio and video channels to estimate inter-camera delays that are used to temporally align the recordings. Our approach is composed of three main steps. First we extract from each recording temporally sharp audio-visual events. These audio-visual events are short and characterized by an audio onset happening jointly to a well-localized spatio-temporal change in the video data. Then, we estimate the inter-camera delays by assessing the co-occurrence of the events in the various recordings. Finally, we use a cross-validation procedure that combines the results for all camera pairs and aligns the recordings in a global timeline. An important feature of the proposed method is the estimation of the confidence level on the results that allows us to automatically reject recordings that are not reliable for the alignment. Results show that our method outperforms state-of-the-art approaches based on audio-only or video-only analysis with both fixed and hand-held moving cameras.
C1 [Casanovas, Anna Llagostera] SwissQual AG, Zuchwil, Switzerland.
   [Cavallaro, Andrea] Queen Mary Univ London, Ctr Intelligent Sensing, London, England.
C3 University of London; Queen Mary University London
RP Casanovas, AL (corresponding author), SwissQual AG, Zuchwil, Switzerland.
EM anna.llagostera@swissqual.com; andrea.cavallaro@eecs.qmul.ac.uk
FU Swiss National Science Foundation [PBELP2-137724]; UK Engineering and
   Physical Sciences Research Council (EPSRC) [EP/K007491/1]; Swiss
   National Science Foundation (SNF) [PBELP2_137724] Funding Source: Swiss
   National Science Foundation (SNF); EPSRC [EP/K007491/1] Funding Source:
   UKRI
FX A. Llagostera Casanovas contributed to this work while at Queen Mary
   University of London, UK. She was supported by the Swiss National
   Science Foundation under the prospective researcher fellowship
   PBELP2-137724. A. Cavallaro acknowledges the support of the UK
   Engineering and Physical Sciences Research Council (EPSRC), under grant
   EP/K007491/1.
CR [Anonymous], 2005, ICCV
   [Anonymous], 1998, Recommendation ITU-R
   [Anonymous], P ADV CONC INT VIS S
   Casanovas AL, 2010, IEEE T MULTIMEDIA, V12, P358, DOI 10.1109/TMM.2010.2050650
   Caspi Y, 2002, IEEE T PATTERN ANAL, V24, P1409, DOI 10.1109/TPAMI.2002.1046148
   Cremer M, 2009, P SPIE IS T ELECT IM, V7254
   Daniyal F, 2010, MULTIMED TOOLS APPL, V46, P235, DOI 10.1007/s11042-009-0355-z
   EU, EP7 PROJ APIDIS ICT
   Fritsch J, 2004, INT C INT AUT SYST
   GUGGENBERGER M, 2012, INT S MULT, P382
   Jiang W, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823748
   Kennedy LS, 2009, P ACM WWW
   Kidron E, 2007, IEEE T SIGNAL PROCES, V55, P1390, DOI 10.1109/TSP.2006.888095
   Lei C, 2006, IEEE T IMAGE PROCESS, V15, P2473, DOI 10.1109/TIP.2006.877438
   Pádua FLC, 2010, IEEE T PATTERN ANAL, V32, P304, DOI 10.1109/TPAMI.2008.301
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Shrestha P, 2010, IEEE T MULTIMEDIA, V12, P79, DOI 10.1109/TMM.2009.2036285
   Sodoyer D, 2004, SPEECH COMMUN, V44, P113, DOI 10.1016/j.specom.2004.10.002
   Stein G, 1999, CVPR
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Summerfield Q., 1987, Hearing by eye: The psychology of lipreading, P3
   Ukrainitz Y., 2006, ECCV
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wedge D., 2007, P IAPR C MACH VIS AP
   WHITEHEAD A, 2005, P IEEE WORKSH MOT VI
NR 25
TC 6
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1317
EP 1340
DI 10.1007/s11042-014-1872-y
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300009
DA 2024-07-18
ER

PT J
AU Ickin, S
   Fiedler, M
   Wac, K
   Arlos, P
   Temiz, C
   Mkocha, K
AF Ickin, Selim
   Fiedler, Markus
   Wac, Katarzyna
   Arlos, Patrik
   Temiz, Canberk
   Mkocha, Khadija
TI VLQoE: Video QoE instrumentation on the smartphone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QoE (Quality of Experience); QoS (Quality of Service); Smartphone;
   Video; User interface; Human Computer Interaction (HCI)
ID QUALITY; EXPERIENCE
AB The usage of network-demanding applications is growing rapidly such as video streaming on mobile terminals. However, network and/or service providers might not guarantee the perceived quality for video streaming that demands high packet transmission rate. In order to satisfy the user expectations and to minimize user churn, it is important for network operators to infer the end-user perceived quality in video streaming. Today, the most reliable method to obtain end-user perceived quality is through subjective tests, and the preferred location is the user interface as it is the closest point of application to the end-user. The end-user perceived quality on video streaming is highly influenced by occasional freezes; technically the extraordinary time gaps between two consecutive pictures that are displayed to the user, i.e., high inter-picture time. In this paper, we present a QoE instrumentation for video streaming, VLQoE. We added functionality to the VLC player to record a set of metrics from the user interface, application-level, network-level, and from the available sensors of the device. To the best of our knowledge, VLQoE is the first tool of its kind that can be used in user experiments for video streaming. By using the tool, we present a two state model based on the inter-picture time, for the HTTP-and RTSP-based video streaming via 3.5G. Next, we studied the influence of inter-picture time on the user perceived quality through out a user study. We investigated the minimum user perceived inter-picture time, and the user response time.
C1 [Ickin, Selim; Fiedler, Markus; Arlos, Patrik] Blekinge Inst Technol, Sch Comp, Blekinge, Sweden.
   [Wac, Katarzyna] Univ Geneva, Inst Serv Sci, Geneva, Switzerland.
   [Temiz, Canberk] Blekinge Inst Technol, Blekinge, Sweden.
   [Mkocha, Khadija] Univ Dar Es Salaam, Dept Elect & Telecommun Engn, Dar Es Salaam, Tanzania.
C3 Blekinge Institute Technology; University of Geneva; Blekinge Institute
   Technology; University of Dar es Salaam
RP Ickin, S (corresponding author), Blekinge Inst Technol, Sch Comp, Blekinge, Sweden.
EM Selim.Ickin@bth.se; Markus.Fiedler@bth.se; katarzyna.wac@unige.ch;
   Patrik.Arlos@bth.se; canberk.tmz@gmail.com; pocadicci@yahoo.com
RI Wac, Katarzyna/C-7856-2013; Ickin, Selim/G-2939-2014; Mkocha,
   Khadija/ABB-3008-2020
OI Wac, Katarzyna/0000-0002-8060-399X; Ickin, Selim/0000-0002-7594-2663;
   Mkocha, Khadija/0000-0002-7432-4804
FU AAL-MyGuardian project; WayFIS project
FX The work of Katarzyna Wac has been supported by AAL-MyGuardian and
   WayFIS projects. We would like to thank anonymous reviewers for the
   valuable comments and suggestions to improve our paper.
CR [Anonymous], 2009, WHIT PAP
   [Anonymous], 1996, Rec. ITU-T P.800
   [Anonymous], 2013, TIME BRAIN YOU ARE A
   [Anonymous], 2013, VLC MEDIA PLAYER AND
   [Anonymous], P INT C CONS EL LAS
   [Anonymous], IEEE INT WORKSH MULT
   Barakovic S, 2013, J COMPUT NETW COMMUN, V2013, DOI 10.1155/2013/165146
   Bonald T, 2012, ACM SIGCOMM COMP COM, V42, P24, DOI 10.1145/2096149.2096153
   Cherif W., 2011, MULTIMEDIA EXPO ICME, P1, DOI [DOI 10.1109/ICME.2011.6011993, 10.1109/ICME.2011.6011993]
   Dalal A. C., 2012, IEEE International Conference on Communications (ICC 2012), P1165, DOI 10.1109/ICC.2012.6364073
   De la Cruz Ramos P, 2010, 5 INT C DIG TEL ICDT
   EGGER S, 2012, P 4 INT WORKSH QUAL
   Exarchakos G, 2011, J MOBILE MULTIMEDIA, V7, P151
   Fenimore C, 2013, PERCEPTUAL EFFECTS N
   Fiedler M, 2011, P 23 INT TEL C SAN F
   French H., 2011, PROC 30 INT PERFORMA, P1
   Gardlo B., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P222, DOI 10.1109/ISM.2011.43
   Grondin S, 2010, ATTEN PERCEPT PSYCHO, V72, P561, DOI 10.3758/APP.72.3.561
   Hossfeld Tobias, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P264, DOI 10.1007/978-3-642-36784-7_11
   Hossfeld T, 2011, INT WORK QUAL MULTIM, P131, DOI 10.1109/QoMEX.2011.6065690
   Huang Junxian., 2010, MobiSys, P165, DOI [10.1145/1814433.1814452, DOI 10.1145/1814433.1814452]
   Huynh-Thu Q, 2008, IEEE T BROADCAST, V54, P641, DOI 10.1109/TBC.2008.2001246
   Ickin S, 2012, 4 INT WORKSH QUAL MU, P164
   Ickin S, 2013, IDENTIFICATION INFLU
   Ickin S, 2012, IEEE COMMUN MAG, V50, P48, DOI 10.1109/MCOM.2012.6178833
   Intille S, 2002, P HUM FACT COMP SYST
   Janowski L., 2011, MULTIMED TOOLS APPL, P1
   Juluri P., 2011, Proceedings of the 2011 23rd International Teletraffic Congress (ITC 2011), P304
   Katabi D, 2002, ACM SIGCOMM COMP COM, V32, P89, DOI 10.1145/964725.633035
   Khan A, 2010, IET COMMUN, V4, P1337, DOI 10.1049/iet-com.2009.0422
   Laghari KUR, 2012, IEEE COMMUN MAG, V50, P58, DOI 10.1109/MCOM.2012.6178834
   Latré S, 2012, IEEE IFIP NETW OPER, P872, DOI 10.1109/NOMS.2012.6212002
   Le Callet P., 2013, Qualinet White Paper on Definitions of Quality of Experience
   Li M, 2005, P NOSSDAV STEV WASH
   Menkovski V, 2013, QOE MOBILE STREAMING
   MIGLIORINI D, 2010, 8 INT C WIR WIR INT
   Minhas T.N., 2012, THESIS BTH
   Myung IJ, 2003, J MATH PSYCHOL, V47, P90, DOI 10.1016/S0022-2496(02)00028-7
   Oliver E., 2010, P 2 ACM INT WORKSHOP, P5
   Qiao Z, 2011, 15 INT C INT NEXT GE
   Recommendations of the ITU ( Telecommunication Standardization Sector), 2013, REC ITU TEL STAND SE
   Schatz Raimund, 2013, Data Traffic Monitoring and Analysis. From Measurement, Classification, and Anomaly Detection to Quality of Experience, P219, DOI 10.1007/978-3-642-36784-7_10
   Seow SC, 2008, DESIDNING ENG TIME P
   Singh KD, 2012, CONSUM COMM NETWORK, P127, DOI 10.1109/CCNC.2012.6181070
   Staehle B, 2010, P EUROITV WORKSH QOE
   Staelens N, 2010, IEEE T BROADCAST, V56, P458, DOI 10.1109/TBC.2010.2067710
   Van Kester S., 2011, P SPIE, V7865
   Venkataraman M, 2009, IEEE GLOBECOM
   Vidal RP, HUMAN VIS ELECT IMAG, Vvol 5292
   VideoLAN, VIDEOLAN
   Vishwanath A, 2010, ACM SIGMOBILE MOBILE, V13, P15
   Vuppala A, 2011, THESIS BLEKINGE I TE
   Wang B, 2008, ACM T MULTIM COMPUT, V4, DOI 10.1145/1352012.1352020
   WANG Y, 2005, KLUWER MULTIMEDIA TO, V27
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Yang KC, 2007, IEEE T MULTIMEDIA, V9, P1528, DOI 10.1109/TMM.2007.906576
   Zinner T., 2010, 21 ITC SPEC SEM MULT
   Zupernick H, 2008, P 18 ITC SPEC SEM QU
NR 59
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 381
EP 411
DI 10.1007/s11042-014-1919-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300005
DA 2024-07-18
ER

PT J
AU Al-Haj, A
AF Al-Haj, Ali
TI A dual transform audio watermarking algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Copyright protection; Discrete wavelet transform;
   Singular value decomposition; Imperceptibility; Robustness; Data payload
ID SPREAD-SPECTRUM WATERMARKING; SINGULAR-VALUE DECOMPOSITION; ROBUST;
   SCHEME; FREQUENCY; TIME; DWT
AB In this paper, a non-blind digital audio watermarking algorithm that satisfies the minimum requirements of optimal audio watermarking set by the International Federation of Photographic Industry (IFPI), is proposed. The algorithm does not degrade perception of audio, offers an SNR value of more than 44 dB, offers around 1387 bps data payload, and it is robust against common audio processing operations such as Gaussian noise addition, MP3 compression, re-quantization, re-sampling, echo, low-pass, high-pass, and band-pass filtering. The IFPI requirements were met by the proposed algorithm as it exploits the attractive properties of two powerful mathematical transforms; the Discrete Wavelet Transform (DWT), and the Singular Value Decomposition (SVD). DWT is applied to achieve robustness as it decomposes the original audio signal in such a way to scatter watermark bits throughout the signal. SVD provides imperceptibility to the proposed algorithm by embedding watermark bits onto the diagonal singular values of the S matrix produced by SVD. The effectiveness of the algorithm is demonstrated by a set of experiments using pop, instrumental, and speech audio scripts.
C1 Princess Sumaya Univ Technol, Dept Comp Engn, Coll Engn, Amman 11941, Jordan.
C3 Princess Sumaya University for Technology
RP Al-Haj, A (corresponding author), Princess Sumaya Univ Technol, Dept Comp Engn, Coll Engn, POB 1438, Amman 11941, Jordan.
EM ali@psut.edu.jo
CR Abd El-Samie FE, 2009, INT J SPEECH TECHNOL, V12, P27, DOI 10.1007/s10772-009-9056-2
   Acevedo A, 2003, DIGITAL WATERMARKING, P75
   Akhaee MA, 2009, IEEE T MULTIMEDIA, V11, P834, DOI 10.1109/TMM.2009.2012923
   Al-Haj Ali, 2010, 2010 Fifth International Conference on Digital Information Management (ICDIM 2010), P525, DOI 10.1109/ICDIM.2010.5664651
   Ali A.-H., 2010, EUR J SCI RES, V39, P6
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   [Anonymous], 2005, P ACM MMSEC
   [Anonymous], 2000, Digital Watermarking
   Arnold M., 2003, PSYCHOACOUSTICS FACT
   Bao P., 2004, Proceedings of 2004 International Symposium on Intelligent Signal Processing And Communication Systems ISPACS 2004 (IEEE Cat. No.04EX910), P266, DOI 10.1109/ISPACS.2004.1439057
   Basso A, 2009, ALGORITHMS, V2, P46, DOI 10.3390/a2010046
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bhat KV, 2011, CIRC SYST SIGNAL PR, V30, P915, DOI 10.1007/s00034-010-9255-8
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Cheng S, 2002, INT CONF ACOUST SPEE, P3728
   Chang CY, 2006, IEEE SYS MAN CYBERN, P1214, DOI 10.1109/ICSMC.2006.384880
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cvejic N, 2004, SIGNAL PROCESS, V84, P207, DOI 10.1016/j.sigpro.2003.10.016
   Dutta MK, 2010, LECT NOTES COMPUT SC, V6340, P131, DOI 10.1007/978-3-642-17499-5_6
   Dutta MK, 2010, COMM COM INF SC, V94, P84, DOI 10.1007/978-3-642-14834-7_9
   Erçelebi E, 2009, DIGIT SIGNAL PROCESS, V19, P265, DOI 10.1016/j.dsp.2008.11.007
   Fallahpour M, 2011, MULTIMED TOOLS APPL, V52, P485, DOI 10.1007/s11042-010-0495-1
   Fallahpour M, 2009, IEICE ELECTRON EXPR, V6, P1057, DOI 10.1587/elex.6.1057
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   Gordy JD, 2000, PROCEEDINGS OF THE 43RD IEEE MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS I-III, P456, DOI 10.1109/MWSCAS.2000.951682
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Kalantari NK, 2009, IEEE T AUDIO SPEECH, V17, P1133, DOI 10.1109/TASL.2009.2019259
   Kardamis J., 2007, THESIS ROCHESTER I T
   Kim HJ, 2003, IEEE T CIRC SYST VID, V13, P885, DOI 10.1109/TCSVT.2003.815950
   Kirovski D, 2003, IEEE T SIGNAL PROCES, V51, P1020, DOI 10.1109/TSP.2003.809384
   Ko BS, 2005, IEEE T MULTIMEDIA, V7, P212, DOI 10.1109/TMM.2005.843366
   Lalitha N.V., 2011, International Journal of Scientific Engineering Research, V2, P1
   Lerch A., 2002, ZPLANE DEV EAQUAL EV
   Li W, 2003, COMPUT MUSIC J, V27, P58, DOI 10.1162/014892603322730505
   Li XY, 2003, 2003 INTERNATIONAL CONFERENCE ON NATURAL LANGUAGE PROCESSING AND KNOWLEDGE ENGINEERING, PROCEEDINGS, P287
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Malik H, 2008, IET INFORM SECUR, V2, P129, DOI 10.1049/iet-ifs:20070145
   Mohammad AA, 2008, SIGNAL PROCESS, V88, P2158, DOI 10.1016/j.sigpro.2008.02.015
   Neubauer C, 2000, P AUD ENG SOC CONV
   Peng H, 2011, MULTIMED TOOLS APPL, V3, P1
   Sehirli M, 2004, LECT NOTES COMPUT SC, V3261, P430
   Strang G., 1996, Wavelets and Filter Banks
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Vongpraphip S, 2009, PROCEEDINGS OF THE 2009 WRI GLOBAL CONGRESS ON INTELLIGENT SYSTEMS, VOL III, P150, DOI 10.1109/GCIS.2009.367
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wu CP, 2000, PROC SPIE, V3971, P382, DOI 10.1117/12.384992
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Wu Y, 2006, INT C SENS NETW UB T
   Xiang SJ, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-3
   Xin Li, 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P74, DOI 10.1109/ITCC.2000.844186
   Xu CS, 1999, J AUDIO ENG SOC, V47, P805
   Yeo IK, 2003, IEEE T SPEECH AUDI P, V11, P381, DOI 10.1109/TSA.2003.812145
NR 54
TC 16
Z9 16
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1897
EP 1912
DI 10.1007/s11042-013-1645-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200036
DA 2024-07-18
ER

PT J
AU Xiang, ZJ
   Chen, QR
   Liu, YC
AF Xiang, Zong Jie
   Chen, Qiren
   Liu, Yuncai
TI Feature correspondence in a non-overlapping camera network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Re-identification; Camera network; Topology; Feature correspondence
AB Person re-identification across multiple cameras is difficult due to viewpoint and illumination variations. Most traditional research focuses on developing invariant features that are unaffected by these variations. However, thus far, there has been no feature developed that is completely invariant, and it is possible that a fully invariant feature may not exist. Therefore, we do not seek to develop these ideal features in this paper. We instead propose a framework for learning a gallery of persons who appear in the camera network frequently. The gallery contains appearance models of these persons from each camera and viewpoint. Given the camera identity, viewpoint identity, person identity, the model is decided. Since these appearance models are specific to each camera and viewpoint, the problems of viewpoint variations and illumination variations between cameras are explicitly solved, and re-identification becomes a ranking problem. Experiments demonstrate that our framework provides significant improvement in addressing the re-identification problem.
C1 [Xiang, Zong Jie; Chen, Qiren] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.
   [Liu, Yuncai] Shanghai Jiao Tong Univ, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Xiang, ZJ (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.
EM zongzong_1984_111@hotmail.com; chenqiren1234@gmail.com;
   whomliu@sjtu.edu.cn
FU China NSFC [60833009, 60975012]; China National 973 Program
   [2011CB302203]
FX This work is supported by China NSFC Key Program Grant No. 60833009,
   China NSFC Program under Grant NO. 60975012, and China National 973
   Program Grant No. 2011CB302203.
CR Alahi A, 2010, COMPUT VIS IMAGE UND, V114, P624, DOI 10.1016/j.cviu.2010.01.004
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen KW, 2008, PROC CVPR IEEE, P1261
   D'Angelo A, 2011, P ELECT IMAGING 2011
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray Douglas, 2007, P IEEE INT WORKSH PE, V3, P1
   Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140
   Havasi L, 2005, IEEE IMAGE PROC, P3273
   Huang J, 1999, INT J COMPUT VISION, V35, P245, DOI 10.1023/A:1008108327226
   Javed O, 2005, PROC CVPR IEEE, P26
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Makris D, 2004, PROC CVPR IEEE, P205
   Makris D, 2003, IEEE INT C ADV VID S
   Oliveira I, 2009, IEEE INT C DEP AUT S
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Zong Jie X, 2012, MULTIMED TO IN PRESS
NR 17
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1129
EP 1145
DI 10.1007/s11042-013-1600-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200004
DA 2024-07-18
ER

PT J
AU Lama, RK
   Han, SJ
   Kwon, GR
AF Lama, Ramesh Kumar
   Han, Seung-Jo
   Kwon, Goo-Rak
TI SVD based improved secret fragment visible mosaic image generation for
   information hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information hiding; Mosaic image; Secret image; Target image
AB This paper proposes a new method for information hiding based on secret fragment visible mosaic image. This algorithm incorporates the application of color transfer for the mosaic image generation to hide the secret information. Since the RGB color space has strong correlation between three color channels, the modification process of any color is complicated in this color space. The large size of bit stream of recovery information of secret image block sequence creates an additional problem. We present a new way to solve these problems using the color transfer technique in correlated color space. The pixel value is considered as a three dimensional stochastic variable and image as a set of samples. Color transformation is achieved by the geometrical transformations such as translation, scaling and rotation. The correlation between the color spaces is measured and further used for the color transfer process by exploring the covariance. In order to get the robust encryption and lower bit rate requirement, the combination of logistic map and Chebyshev map is used to generate the encryption sequence of the secret image.
C1 [Lama, Ramesh Kumar; Han, Seung-Jo; Kwon, Goo-Rak] Chosun Univ, Dept Informat & Commun Engn, Kwangju 501759, South Korea.
C3 Chosun University
RP Kwon, GR (corresponding author), Chosun Univ, Dept Informat & Commun Engn, 375 Seosuk Dong, Kwangju 501759, South Korea.
EM grkwon@chosun.ac.kr
FU Chosun University
FX This study was supported by research funds from Chosun University, 2012.
CR Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chen Y-S, 2008, P WORLD C ENG, P1
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   Cox IJ, 2008, MKS MULTIMED INFORM, P1
   Feng J.B., 2006, IJ Network Security, V2, P161
   Huang FJ, 2005, CHAOS SOLITON FRACT, V23, P851, DOI 10.1016/j.chaos.2004.05.026
   Katzenbeisser SC, 2000, ART H COMP SCI LIBR, P17
   Kiel L.D., 1997, CHAOS THEORY SOCIAL
   Lai I-J, 2011, IEEE T INFORM FORENS, V6
   Lee GJ, 2008, INTERNATIONAL SYMPOSIUM ON UBIQUITOUS MULTIMEDIA COMPUTING, PROCEEDINGS, P130, DOI 10.1109/UMC.2008.33
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Muller N, 2004, SIAM REV, V46, P518, DOI [10.1137/S0036144501387517, 10.1137/s0036144501387517]
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Reinhard E, 2001, COMPUT GRAPH APPL, V21
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Xiao Xuezhong, 2006, PACM INT C VIRT REAL, P305, DOI DOI 10.1145/1128923.1128974
   Ya-Lin Li, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P64, DOI 10.1007/978-3-642-24031-7_7
   Yang GB, 2011, AEU-INT J ELECTRON C, V65, P331, DOI 10.1016/j.aeue.2010.03.011
NR 18
TC 10
Z9 10
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 873
EP 886
DI 10.1007/s11042-013-1381-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700015
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Dooms, S
   Martens, L
AF De Pessemier, Toon
   Dooms, Simon
   Martens, Luc
TI Context-aware recommendations through context and activity recognition
   in a mobile environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context-aware; Recommender system; Activity recognition; Mobile
ID INFORMATION
AB The mobile Internet introduces new opportunities to gain insight in the user's environment, behavior, and activity. This contextual information can be used as an additional information source to improve traditional recommendation algorithms. This paper describes a framework to detect the current context and activity of the user by analyzing data retrieved from different sensors available on mobile devices. The framework can easily be extended to detect custom activities and is built in a generic way to ensure easy integration with other applications. On top of this framework, a recommender system is built to provide users a personalized content offer, consisting of relevant information such as points-of-interest, train schedules, and touristic info, based on the user's current context. An evaluation of the recommender system and the underlying context recognition framework shows that power consumption and data traffic is still within an acceptable range. Users who tested the recommender system via the mobile application confirmed the usability and liked to use it. The recommendations are assessed as effective and help them to discover new places and interesting information.
C1 [De Pessemier, Toon; Dooms, Simon; Martens, Luc] IMinds Ghent Univ, Wica, B-9050 Ghent, Belgium.
C3 Ghent University; IMEC
RP De Pessemier, T (corresponding author), IMinds Ghent Univ, Wica, G Crommenlaan 8 Box 201, B-9050 Ghent, Belgium.
EM toon.depessemier@ugent.be; simon.dooms@gent.be; luc1.martens@ugent.be
CR Adomavicius G, 2005, ACM T INFORM SYST, V23, P103, DOI 10.1145/1055709.1055714
   [Anonymous], P WORLD C ENG COMP S
   Antoniou J, 2010, MOBILE NETW APPL, V15, P831, DOI 10.1007/s11036-010-0235-9
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Biegel G, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P361, DOI 10.1109/PERCOM.2004.1276875
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Brown PJ, 1997, IEEE PERS COMMUN, V4, P58, DOI 10.1109/98.626984
   CultuurNet-Vlaanderen, 2012, UITD DEV TOOLS
   Debaty P, 2005, MOBILE NETW APPL, V10, P385, DOI 10.1007/s11036-005-1552-2
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   El-Geneidy A.M., 2008, ACCESS DESTINATIONS
   Gellersen HW, 2002, MOBILE NETW APPL, V7, P341, DOI 10.1023/A:1016587515822
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Herlocker JL, 2004, ACM T INFORM SYST, V22, P5, DOI 10.1145/963770.963772
   HLN, 2012, RSS NEWS FEED
   Inc S, 2012, HUM TEMP SENS MOB DE
   Kenteris M., 2010, 2010 IEEE Symposium on Computers and Communications (ISCC), P840, DOI 10.1109/ISCC.2010.5546758
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Mysore P., 2005, AAAI, V5, P1541
   Oh JM, 2012, MULTIMED TOOLS APPL, V57, P295, DOI 10.1007/s11042-011-0737-x
   Oku K., 2006, Proceedings of the 7th International Conference on Mobile Data Management, P109, DOI 10.1109/MDM.2006.56
   Ricci F., 2010, Information Technology and Tourism, V12, P205, DOI 10.3727/109830511X12978702284390
   SCHILIT BN, 1994, IEEE NETWORK, V8, P22, DOI 10.1109/65.313011
   Schiller J., 2004, Location-Based Services
   Seon-Woo Lee, 2002, IEEE Pervasive Computing, V1, P24, DOI 10.1109/MPRV.2002.1037719
   Tiete Y, 2012, COLPAERT P IRAIL API
   Wagner J., 2011, P 2011 WORKSH CONT A, P47
NR 27
TC 41
Z9 46
U1 0
U2 46
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2925
EP 2948
DI 10.1007/s11042-013-1582-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300036
OA Green Published
DA 2024-07-18
ER

PT J
AU Dehshibi, MM
   Fazlali, M
   Shanbehzadeh, J
AF Dehshibi, Mohammad Mahdi
   Fazlali, Mahmood
   Shanbehzadeh, Jamshid
TI Linear principal transformation: toward locating features in
   N-dimensional image space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character recognition; Facial feature extraction; Image space; Linear
   principal transformation; Projection function
ID FACE-RECOGNITION ALGORITHMS
AB Projection Functions have been widely used for facial feature extraction and optical/handwritten character recognition due to their simplicity and efficiency. Because these transformations are not one-to-one, they may result in mapping distinct points into one point, and consequently losing detailed information. Here, we solve this problem by defining an N-dimensional space to represent a single image. Then, we propose a one-to-one transformation in this new image space. The proposed method, which we referred to as Linear Principal Transformation (LPT), utilizes Eigen analysis to extract the vector with the highest Eigenvalue. Afterwards, extrema in this vector were analyzed to extract the features of interest. In order to evaluate the proposed method, we performed two sets of experiments on facial feature extraction and optical character recognition in three different data sets. The results show that the proposed algorithm outperforms the observed algorithms in the paper and achieves accuracy from 1.4 % up to 14 %, while it has a comparable time complexity and efficiency.
C1 [Dehshibi, Mohammad Mahdi] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Fazlali, Mahmood] Shahid Beheshti Univ, GC, Dept Comp Sci, Tehran, Iran.
   [Shanbehzadeh, Jamshid] Kharazmi Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
C3 Islamic Azad University; Shahid Beheshti University; Kharazmi University
RP Dehshibi, MM (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
EM mohammad.dehshibi@piau.ac.ir; fazlali@sbu.ac.ir; jamshid@tmu.ac.ir
RI Dehshibi, Mohammad Mahdi/S-9946-2017; Fazlali, Mahmood/JCP-3157-2023
OI Dehshibi, Mohammad Mahdi/0000-0001-8112-5419; Fazlali,
   Mahmood/0000-0002-1701-5562
CR [Anonymous], 2005, Elementary Linear Algebra
   [Anonymous], ICGST INT J GRAPHICS
   [Anonymous], 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119
   Baek G, 2009, LECT NOTES ARTIF INT, V5755, P85, DOI 10.1007/978-3-642-04020-7_10
   Bastanfard A, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P50
   Bledsoe W.W., 1966, Panoramic Research Inc. Palo Alto CA Rep. PRl, V15, P2
   Cristinacce D, 15 BRIT MACH VIS C
   Das MT, 2009, ENG APPL ARTIF INTEL, V22, P688, DOI 10.1016/j.engappai.2009.02.005
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Dehshibi Mohammad Mahdi, 2012, INT J ELECT COMPUT E, V4, P355, DOI 10.7763/IJCEE.2012.V4.511
   Duffner S, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P316, DOI 10.1109/ISPA.2005.195430
   Eckhardt M, 2009, INT J PATTERN RECOGN, V23, P379, DOI 10.1142/S0218001409007247
   Franc V, 2005, LECT NOTES COMPUT SC, V3663, P385
   Geng X, 2004, J SOFTW, P1394
   Jesorsky O, 3 INT C AUD VID BAS
   Kanade T., 1973, Picture processing by computer complex and recognition of human faces
   Karungaru S, 2007, INT J INNOV COMPUT I, V3, P247
   Kaufman L., 1977, ACM Transactions on Mathematical Software, V3, P65, DOI 10.1145/355719.355725
   Kim HY, PAC RIM S IM VID TEC
   Kim KI, INT WORKSH PATT REC
   Kroon B., 2008, P 2008 INT C CONT BA, P379
   Lee PH, INT C MACH VIS APPL
   Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150
   MARQUES F, 2002, P EUSIPCO 2002 F SEP, P33
   MOLER CB, 1973, SIAM J NUMER ANAL, V10, P241, DOI 10.1137/0710024
   Nguyen MH, INT C AUT FAC GEST R
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Takahashi Y., 2007, Systems and Computers in Japan, V38, P49, DOI 10.1002/scj.20342
   Thode H. C., 2002, Testing for Normality, DOI 10.1201/9780203910894
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang J, C IM SIGN PROC
   Yilmaz A, 2002, 5 AS C COMP VIS MELB, V289
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
NR 34
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2249
EP 2273
DI 10.1007/s11042-013-1505-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300010
DA 2024-07-18
ER

PT J
AU Guo, C
   Chang, CC
   Qin, C
AF Guo, Cheng
   Chang, Chin-Chen
   Qin, Chuan
TI A novel (<i>n</i>, <i>t</i>, <i>n</i>) secret image sharing scheme
   without a trusted third party
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE (n, t, n) secret sharing; Modulo operator; Additive homomorphism; Secret
   image sharing; Trusted third party
ID SMALLER SHADOW IMAGES; CELLULAR-AUTOMATA; STEGANOGRAPHY; AUTHENTICATION
AB Secret image sharing is a technique to share a secret image among a set of n participants. A trusted third party embeds the secret image into the cover image to generate shadow images such that at least t or more shadow images can reconstruct the secret image. In this paper, we consider an extreme and real-world situation, in which there is no one who is trusted by anyone else. In the proposed scheme, the participants can act as a dealer and communicate with each other in a secret channel. Each participant can generate her/his own shadow image independently, according to the cover image and the secret image. Experimental results are provided to show that the shadow images have satisfactory quality. In addition, our scheme has a large embedding capacity, and the secret image can be reconstructed losslessly.
C1 [Guo, Cheng] Dalian Univ Technol, Sch Software, Dalian 116620, Peoples R China.
   [Chang, Chin-Chen; Qin, Chuan] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   [Chang, Chin-Chen] Chinese Med Univ, Dept Biomed Imaging & Radiol Sci, Taichung 40402, Taiwan.
C3 Dalian University of Technology; Feng Chia University; China Medical
   University Taiwan
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM guo8016@gmail.com; alan3c@gmail.com; qin@usst.edu.cn
RI Qin, Chuan/C-1106-2017; Chang, Ching-Chun/JAN-6210-2023
OI Qin, Chuan/0000-0002-0370-4623; 
FU Fundamental Research Funds for the Central Universities [DUT12RC(3)80]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities under grants DUT12RC(3)80.
CR [Anonymous], 1979, P AFIPS NAT COMP C N
   Chang CC, 2009, PATTERN RECOGN, V42, P3097, DOI 10.1016/j.patcog.2009.04.012
   Eslami Z, 2011, J SYST SOFTWARE, V84, P803, DOI 10.1016/j.jss.2011.01.002
   Eslami Z, 2010, PATTERN RECOGN, V43, P397, DOI 10.1016/j.patcog.2009.06.007
   Guo C, 2012, PATTERN RECOGN LETT, V33, P1594, DOI 10.1016/j.patrec.2012.04.010
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   HARN L, 1995, IEE P-COMPUT DIG T, V142, P237, DOI 10.1049/ip-cdt:19951874
   Harn L, 2010, INFORM SCIENCES, V180, P3059, DOI 10.1016/j.ins.2010.04.016
   Hwang RJ, 1998, COMPUT COMMUN, V21, P1170, DOI 10.1016/S0140-3664(98)00191-1
   INGEMARSSON I, 1991, LECT NOTES COMPUT SC, V473, P266
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin PY, 2010, PATTERN RECOGN LETT, V31, P1887, DOI 10.1016/j.patrec.2010.01.019
   Lin PY, 2009, PATTERN RECOGN, V42, P886, DOI 10.1016/j.patcog.2008.09.014
   Lin YY, 2010, IEEE SIGNAL PROC LET, V17, P316, DOI 10.1109/LSP.2009.2038113
   Noar N, 1995, ADV CRYPT EUR 94, P1
   Pedersen T. P., 1991, Advances in Cryptology - EUROCRYPT '91. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P522
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wu XT, 2012, J SYST SOFTWARE, V85, P1852, DOI 10.1016/j.jss.2012.02.046
   Yang CC, 2004, APPL MATH COMPUT, V151, P483, DOI 10.1016/S0096-3003(03)00355-2
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
   Zhao JJ, 2007, COMPUT STAND INTER, V29, P138, DOI 10.1016/j.csi.2006.02.004
NR 25
TC 7
Z9 7
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2195
EP 2209
DI 10.1007/s11042-013-1510-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300007
DA 2024-07-18
ER

PT J
AU Sajjad, M
   Ejaz, N
   Baik, SW
AF Sajjad, Muhammad
   Ejaz, Naveed
   Baik, Sung Wook
TI Multi-kernel based adaptive interpolation for image super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Stencil; Geometrical regularity; Kernel; Edge-directed
ID ZOOMING ALGORITHM
AB This paper proposes a cost-effective and edge-directed image super-resolution scheme. Image super-resolution (image magnification) is an enthusiastic research area and is desired in a variety of applications. The basic idea of the proposed scheme is based on the concept of multi-kernel approach. Various stencils have been defined on the basis of geometrical regularities. This set of stencils is associated with the set of kernels. The value of a re-sampling pixel is obtained by calculating the weighted average of the pixels in the selected kernel. The time complexity of the proposed scheme is as low as that of classical linear interpolation techniques, but the visual quality is more appealing because of the edge-orientation property. The experimental results and analysis show that proposed scheme provides a good combination of visual quality and time complexity.
C1 [Sajjad, Muhammad; Ejaz, Naveed; Baik, Sung Wook] Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
C3 Sejong University
RP Baik, SW (corresponding author), Sejong Univ, Coll Elect & Informat Engn, Seoul, South Korea.
EM sajjad@sju.ac.kr; naveed@sju.ac.kr; sbaik@sejong.ac.kr
RI Ejaz, Naveed/HZL-7415-2023; Ejaz, Naveed/I-2891-2012; Ejaz,
   Naveed/HZJ-6101-2023; Sajjad, Muhammad/GZL-4962-2022; Baik, Sung
   Wook/AAR-8236-2020; Sajjad, Muhammad/L-5269-2016
OI Ejaz, Naveed/0000-0003-1295-4787; Ejaz, Naveed/0000-0003-1295-4787;
   Sajjad, Muhammad/0000-0003-0006-1156; Sajjad,
   Muhammad/0000-0001-5646-0338; Baik, Sung Wook/0000-0002-6678-7788
FU Industrial Strategic technology development program - Ministry of
   Knowledge Economy (MKE, Korea) [10041772]
FX This research is supported by the Industrial Strategic technology
   development program, 10041772, (The Development of an Adaptive
   Mixed-Reality Space based on Interactive Architecture) funded by the
   Ministry of Knowledge Economy (MKE, Korea).
CR Acharya Tinku, 2007, ACM UBIQUITY, V8
   Amanatiadis A, 2009, MEAS SCI TECHNOL, V20, DOI 10.1088/0957-0233/20/10/104015
   [Anonymous], 2002, Numerical Recipes in C++: The Art of Scientific Computing
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], 2008, ACM T GRAPHICS SIGGR
   Arcelli C, 2011, SIGNAL PROCESS, V91, P61, DOI 10.1016/j.sigpro.2010.06.007
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Battiato S, 2002, IMAGE VISION COMPUT, V20, P805, DOI 10.1016/S0262-8856(02)00089-6
   Chang CC, 2005, IMAGE VISION COMPUT, V23, P1214, DOI 10.1016/j.imavis.2005.07.020
   Chen HY, 2010, SIGNAL PROCESS, V90, P1676, DOI 10.1016/j.sigpro.2009.11.019
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Ejaz N, 2012, MULTIMEDIA SYST, V18, P483, DOI 10.1007/s00530-012-0263-3
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Gajjar PP, 2010, IEEE T IMAGE PROCESS, V19, P1201, DOI 10.1109/TIP.2010.2041408
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Hung K.W., 2009, ICIP
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   Jurio A, 2011, IEEE T IMAGE PROCESS, V20, P3112, DOI 10.1109/TIP.2011.2158227
   Kim C, 2010, IEEE T IMAGE PROCESS, V19, P2682
   Kim H, 2011, IEEE T IMAGE PROCESS, V20, P1895, DOI 10.1109/TIP.2011.2107523
   KIM K, 2008, 173 M PLANCK I
   Lee YJ, 2010, IEEE T IMAGE PROCESS, V19, P2682, DOI 10.1109/TIP.2010.2050108
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Mallat S, 2010, IEEE T IMAGE PROCESS, V19, P2889, DOI 10.1109/TIP.2010.2049927
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Sun J, 2003, PROC CVPR IEEE, P729
   Tam WS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3358372
   Tipping M. E., 2003, ADV NEURAL INFORM PR, P1303
   Willmott CJ, 2005, CLIMATE RES, V30, P79, DOI 10.3354/cr030079
   Wittman T., 2005, Mathematical techniques for image interpolation
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P2017, DOI 10.1109/TIP.2010.2045707
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yi-Chun Lin, 2010, 2010 28th Picture Coding Symposium (PCS 2010), P254, DOI 10.1109/PCS.2010.5702479
NR 35
TC 13
Z9 17
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2063
EP 2085
DI 10.1007/s11042-012-1325-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300001
DA 2024-07-18
ER

PT J
AU Chandy, DA
   Johnson, JS
   Selvan, SE
AF Chandy, D. Abraham
   Johnson, J. Stanly
   Selvan, S. Easter
TI Texture feature extraction using gray level statistical matrix for
   content-based mammogram retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Mammogram; Texture; Gray level
   statistical matrix; Precision
ID IMAGE RETRIEVAL
AB Texture is one of the visual contents of an image used in content-based image retrieval (CBIR) to represent and index the image. Statistical textural representation methods characterize texture by the statistical distribution of the image intensity. This paper proposes a gray level statistical matrix from which four statistical texture features are estimated for the retrieval of mammograms from mammographic image analysis society (MIAS) database. The mammograms comprising architectural distortion, asymmetry, calcification, circumscribed, ill-defined, spiculated and normal classes are used in the experimentation. Precision, recall, retrieval rate, normalized average rank, average matching fraction, storage requirement and retrieval time are the performance measures used for the evaluation of retrieval performance. Using the proposed method, the highest mean precision rate obtained is 85.1 %. The results show that the proposed method outperforms the state-of-the-art texture feature extraction methods in mammogram retrieval problem.
C1 [Chandy, D. Abraham] Karunya Univ, Coimbatore, Tamil Nadu, India.
   [Johnson, J. Stanly] Control Syst & Instrumentat, Saudi Kayan, Saudi Arabia.
   [Selvan, S. Easter] Catholic Univ Louvain, Louvain La Neuve, Belgium.
C3 Karunya Institute of Technology & Sciences; Universite Catholique
   Louvain
RP Chandy, DA (corresponding author), Karunya Univ, Coimbatore, Tamil Nadu, India.
EM abrahamdchandy@gmail.com; drstanly_johnson@yahoo.com;
   easterselvans@gmail.com
RI Suviseshamuthu, Easter Selvan/AAP-8276-2020
OI Suviseshamuthu, Easter Selvan/0000-0002-8584-5947
CR [Anonymous], 2010, INT J COMPUT COMMUN
   [Anonymous], 2006, DATABASEMODELING IND, DOI DOI 10.4018/978-1-59140-684-6.CH009
   Chen C.H., 1998, Handbook of Pattern Recognition and Computer Vision, V2nd, P207
   Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006
   Choras Ryszard S., 2008, International Journal of Medical Engineering and Informatics, V1, P50, DOI 10.1504/IJMEI.2008.019469
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Eisa M, 2009, ICGST GVIP J, V9, P21
   El-Naqa I, 2004, IEEE T MED IMAGING, V23, P1233, DOI 10.1109/TMI.2004.834601
   Felipe J. C., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P250, DOI 10.1145/1141277.1141333
   Greenspan H, 2007, IEEE T INF TECHNOL B, V11, P190, DOI 10.1109/TITB.2006.874191
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Korn PF, 1998, IEEE T KNOWL DATA EN, V10, P889, DOI 10.1109/69.738356
   Kwitt R, 2011, IEEE T IMAGE PROCESS, V20, P2063, DOI 10.1109/TIP.2011.2108663
   Larnard M, 2007, P ANN INT IEEE EMBS, P4532
   Lu S., 2003, P 2003 APRS WORKSH D, P15
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mudigonda NR, 2000, IEEE T MED IMAGING, V19, P1032, DOI 10.1109/42.887618
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Pandey Dilkeshwar, 2011, Journal of Theoretical and Applied Information Technology, V32, P160
   Qin XJ, 2004, PROC CVPR IEEE, P326
   Quellec G, 2010, MED IMAGE ANAL, V14, P227, DOI 10.1016/j.media.2009.11.004
   Schnorrenberg F, 2000, Technol Health Care, V8, P291
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Srinivasan G.N., 2008, Engineering and Technology, V36, P1264
   Suckling J., 1994, INT WORITSHOP DIG MA, P211
   Sun JD, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, VOLS 1 AND 2, PROCEEDINGS, P190, DOI 10.1109/CIS.2008.118
   Tourassi GD, 1999, RADIOLOGY, V213, P317, DOI 10.1148/radiology.213.2.r99nv49317
   Tourassi GD, 2007, MED PHYS, V34, P140, DOI 10.1118/1.2401667
   Wei CH, 2005, PROC SPIE, V5748, P134, DOI 10.1117/12.594929
NR 31
TC 23
Z9 24
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 2011
EP 2024
DI 10.1007/s11042-013-1511-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300043
DA 2024-07-18
ER

PT J
AU Kim, SC
   Kwon, DS
AF Kim, Seung-Chan
   Kwon, Dong-Soo
TI Haptic interaction with objects in a picture based on pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptic interaction; Haptic augmentation; Object geometry; Image
   understanding; Force feedback
ID TACTILE; PERCEPTION; DISPLAY; FORCE; MOUSE; SHAPE
AB In pictures, every object is displayed in 2D space. Seeing the 2D image, people can perceptually reconstruct and understand information regarding the scene. To enable users to haptically interact with an object that appears in the image, the present study proposes a geometry-based haptic rendering method. More specifically, our approach is intended to estimate haptic information from the object's structure contained in an image while preserving the two-dimensional visual information. Of the many types of objects that can be seen in everyday pictures, this paper mainly deals with polyhedron figures or objects composed of rectangular faces, some of which might be shown in a slanted configuration in the picture. To obtain the geometric layout of the object being viewed from the image plane, we first estimate homographic information that describes a mapping from the object coordinate to the target image coordinate. Then, we transform the surface normals of the object face using the extrinsic part of homography that locates the face of the object we are viewing. Because the transformed normals are utilized for calculating the force in the image space, we call this process normal vector perturbation in the 2D image space. To physically represent the estimated normal vector without distorting the visual information, we employed a lateral haptic rendering scheme in that it fits with our interaction styles on 2D images. The active force value at a given position on the slanted faces is calculated during the interaction phase. To evaluate our approach, we conducted an experiment with different stimulus conditions, in which it was found that participants could reliably estimate the geometric layout that appears in the picture. We conclude with explorations of applications and a discussion of future work.
C1 [Kim, Seung-Chan; Kwon, Dong-Soo] Korea Adv Inst Sci & Technol, Dept Mech Engn, Telerobot & Control Lab, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Kwon, DS (corresponding author), Korea Adv Inst Sci & Technol, Dept Mech Engn, Telerobot & Control Lab, 335 Gwahangno, Taejon 305701, South Korea.
EM kimsc@robot.kaist.ac.kr; kwonds@kaist.ac.kr
RI Kwon, Dong-Soo/C-1540-2011
OI Kim, Seung-Chan/0000-0001-7292-5166
FU MKE/KEIT [2009-S-035-01]
FX This work was supported by the IT R&D program of MKE/KEIT,
   [2009-S-035-01, Contact-free Multipoint Realistic Interaction Technology
   Development].
CR AKAMATSU M, 1994, INT J HUM-COMPUT ST, V40, P443, DOI 10.1006/ijhc.1994.1020
   [Anonymous], 2007, Proc. CVWW '07
   BACH P, 1969, NATURE, V221, P963, DOI 10.1038/221963a0
   Bau O., 2010, P 23 ANN ACM S US IN, P283, DOI DOI 10.1145/1866029.1866074
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   BRITTON EG, 1978, SIGGRAPH COMPUT GRAP, V12, P222, DOI DOI 10.1145/965139.807394
   Byung-Kil Han, 2012, 2012 IEEE Haptics Symposium (HAPTICS), P571, DOI 10.1109/HAPTIC.2012.6183849
   Carmigniani J, 2011, MULTIMED TOOLS APPL, V51, P341, DOI 10.1007/s11042-010-0660-6
   Cha J, 2008, LECT NOTES COMPUT SC, V5024, P640
   Cha J, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596993
   CONCOLATO C, 2002, WORKSH EXH MPEG 4 WE
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Fritz JP, 1996, P SOC PHOTO-OPT INS, V2901, P34, DOI 10.1117/12.263011
   Hart S. G., 1990, Manprint, P257
   Hartley R., 2000, MULTIPLE VIEW GEOMET, V2
   Hinckley K., 1999, 99 UIST. Proceedings of the 12th Annual ACM Symposium on User Interface Software and Technology, P103, DOI 10.1145/320719.322591
   Ho CH, 1999, PRESENCE-VIRTUAL AUG, V8, P477, DOI 10.1162/105474699566413
   Ikei Y, 1997, P IEEE VIRT REAL ANN, P199, DOI 10.1109/VRAIS.1997.583071
   Israr A., 2012, P 2012 ACM ANN C EXT, P1571, DOI DOI 10.1145/2212776.2223674
   Jones LynetteA., 2000, Human and Machine Haptics
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kim S.S., 2010, ICIC EXPRESS LETT B, V1, P39, DOI DOI 10.1145/1900354.1900397
   KIM SC, 2011, P 5 INT C UB INF MAN, DOI DOI 10.1145/1968613.1968675
   Kim Y, 2010, IEEE MULTIMEDIA, V17, P34, DOI 10.1109/MMUL.2010.5692181
   Kyung KU, 2007, IEEE-ASME T MECH, V12, P356, DOI 10.1109/TMECH.2007.897283
   Lederman SJ, 2009, ATTEN PERCEPT PSYCHO, V71, P1439, DOI 10.3758/APP.71.7.1439
   LEDERMAN SJ, 1987, COGNITIVE PSYCHOL, V19, P342, DOI 10.1016/0010-0285(87)90008-9
   Lederman SJ, 1999, PRESENCE-TELEOP VIRT, V8, P86, DOI 10.1162/105474699566062
   Minsky M., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P421
   Minsky M., 1990, Computer Graphics, V24, P235, DOI 10.1145/91394.91451
   Morgenbesser H. B., 1996, Proceedings of the ASME Dynamic Systems and Control Division, P407
   Nack F, 1999, IEEE MULTIMEDIA, V6, P65, DOI 10.1109/93.790612
   Oakley I., 2000, Proceedings of the SIGCHI on Human factors in computing systems, P415
   Rekimoto J, 1998, 3RD ASIA PACIFIC COMPUTER HUMAN INTERACTION, PROCEEDINGS, P63, DOI 10.1109/APCHI.1998.704151
   Robles-De-La-Torre G, 2001, NATURE, V412, P445, DOI 10.1038/35086588
   Ruspini D. C., 1997, ANN C COMP GRAPH INT, P345, DOI DOI 10.1145/258734.258878
   Saga S., 2012, 2012 IEEE Haptics Symposium (HAPTICS), P15, DOI 10.1109/HAPTIC.2012.6183764
   SHERRICK CE, 1986, HDB PERCEPTION HUMAN, V1, P1
   Shimojo M, 1999, IEEE T SYST MAN CY A, V29, P637, DOI 10.1109/3468.798067
   Srinivasa SS, 2010, AUTON ROBOT, V28, P5, DOI 10.1007/s10514-009-9160-9
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Vasudevan H, 2008, SYMPOSIUM ON HAPTICS INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS 2008, PROCEEDINGS, P357
   Willis K.D.D., 2011, Proc. UIST'11, P431, DOI DOI 10.1145/2047196.2047254
   Willis KDD, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1031
   Winfield L, 2007, WORLD HAPTICS 2007: SECOND JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P421
   Xu C., 2011, CHI'11 Extended Abstracts on Human Factors in Computing Systems, P317, DOI [10.1145/1979742.1979705, DOI 10.1145/1979742.1979705]
   YANO H, 2012, HAPT S HAPTICS 2012, P349, DOI DOI 10.1109/HAPTIC.2012.6183813
   Yano H, 2009, WORLD HAPTICS 2009: THIRD JOINT EUROHAPTICS CONFERENCE AND SYMPOSIUM ON HAPTIC INTERFACES FOR VIRTUAL ENVIRONMENT AND TELEOPERATOR SYSTEMS, PROCEEDINGS, P196, DOI 10.1109/WHC.2009.4810889
   ZILLES CB, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 3, P146, DOI 10.1109/IROS.1995.525876
NR 50
TC 3
Z9 4
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 2041
EP 2062
DI 10.1007/s11042-013-1471-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300045
DA 2024-07-18
ER

PT J
AU Leu, JS
   Su, KW
   Chen, CT
AF Leu, Jenq-Shiou
   Su, Kuan-Wu
   Chen, Cheng-Tsung
TI Ambient mesoscale weather forecasting system featuring mobile augmented
   reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weather forecasting; Ambient intelligence; Mesoscale weather; Augmented
   reality
ID MIXED REALITY; INTELLIGENCE
AB With rapid development of mobile technologies, people can easily obtain surrounding information through their mobile devices. Meanwhile, weather forecasting information is important for many people in the daily life. Most of current weather information systems only illustrate the basic weather information, such as the temperature and the precipitation probability, by a simple text-based or graphic-based presentation without involving too much environmental information. To integrate weather information with ambient intelligence, this paper aims at showing our implementation experience about how to realize our ambient mesoscale weather forecasting system (AMWFS). With an augmented reality presentation in the system, a more intuitive navigation interface provides users a new way of accessing weather information.
C1 [Leu, Jenq-Shiou; Su, Kuan-Wu; Chen, Cheng-Tsung] Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology
RP Leu, JS (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect & Comp Engn, Taipei, Taiwan.
EM jsleu@mail.ntust.edu.tw; D10102107@mail.ntust.edu.tw;
   M9902131@mail.ntust.edu.tw
CR Aarts E, 2004, IEEE MULTIMEDIA, V11, P12, DOI 10.1109/MMUL.2004.1261101
   Behringer R, 2007, LECT NOTES COMPUT SC, V4799, P255
   Ibáñez MB, 2011, IEEE INTERNET COMPUT, V15, P44, DOI 10.1109/MIC.2011.78
   Chen CT, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P566, DOI 10.1109/ICCE.2012.6161975
   Christian J, 2007, UNIVERSAL ACCESS IN HUMAN-COMPUTER INTERACTION: APPLICATIONS AND SERVICES, PT 3, PROCEEDINGS, P520
   Christodoulou CI, 2004, IEEE IJCNN, P1393
   de Sa M, 2012, MOBILEHCI '12: COMPANION PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON HUMAN COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES, P225
   Fujita T.T., 1986, Mesoscale Meteorology and Forecasting, P18
   Gliet J., 2008, WORKING C ADV VISUAL, P287
   He J, 2008, 2008 INTERNATIONAL CONFERENCE ON EMBEDDED SOFTWARE AND SYSTEMS SYMPOSIA, PROCEEDINGS, P253, DOI 10.1109/ICESS.Symposia.2008.64
   Holzinger A, 2005, COMMUN ACM, V48, P71, DOI 10.1145/1039539.1039541
   Holzinger A, 2011, J BIOMED INFORM, V44, P968, DOI 10.1016/j.jbi.2011.07.003
   Holzinger K., 2011, INT JOINT C EBUSINES, P131
   Lee JS, 2010, J CHIN INST ENG, V33, P669, DOI 10.1080/02533839.2010.9671656
   Casas DM, 2009, LECT NOTES COMPUT SC, V5518, P487, DOI 10.1007/978-3-642-02481-8_70
   Montopoli M, 2007, IEEE T GEOSCI REMOTE, V45, P2403, DOI 10.1109/TGRS.2007.896551
   Nielsen Jakob., 1994, COST JUSTIFYING USAB, P245
   Novák P, 2009, ATMOS RES, V93, P328, DOI 10.1016/j.atmosres.2008.10.014
   Remagnino P, 2005, IEEE T SYST MAN CY A, V35, P1, DOI 10.1109/TSMCA.2004.838456
   Rosenblum L.J., 2012, EXPANDING FRONTIERS, P431, DOI DOI 10.1007/978-1-4471-2804-5_24
   Tamura H, 2001, IEEE COMPUT GRAPH, V21, P64, DOI 10.1109/38.963462
   Wang Y, 2011, IEEE T POWER SYST, V26, P500, DOI 10.1109/TPWRS.2010.2052638
   Wynne B, 2010, THEOR CULT SOC, V27, P289, DOI 10.1177/0263276410361499
   Zhou ZY, 2007, IEEE T SYST MAN CY A, V37, P262, DOI 10.1109/TSMCA.2006.886376
NR 24
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1585
EP 1609
DI 10.1007/s11042-013-1462-4
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300025
DA 2024-07-18
ER

PT J
AU Tsai, MH
   Liao, YK
   Lin, IC
AF Tsai, Ming-Han
   Liao, Yen-Kai
   Lin, I-Chen
TI Human face aging with guided prediction and detail synthesis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face aging; Image generation; Pattern analysis
ID HUMAN AGE ESTIMATION; IMAGE
AB In this paper, we present an example-based method to estimate the aging process of a human face. To tackle the difficulty of collecting considerable chronological photos of individuals, we utilize a two-layer strategy. Based on a sparse aging database, an EM-PCA-based algorithm with the personal guidance vector is first applied to conjecture the temporal variations of a target face. Since the subspace-based prediction may not preserve detailed creases, we propose synthesizing facial details with a separate texture dataset. Besides automatic simulation, the proposed framework can also include further guidance, e.g., parents' impact vector or users' indication of wrinkles. Our estimated results can improve feature point positions and user evaluation demonstrates that the two-layer approach provides more reasonable aging prediction.
C1 [Tsai, Ming-Han; Liao, Yen-Kai; Lin, I-Chen] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30010, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lin, IC (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 30010, Taiwan.
EM ichenlin@cs.nctu.edu.tw
OI Lin, I-Chen/0000-0001-9924-4723
FU National Science Council, Taiwan [NSC 100-2221-E-009-148]
FX Authors would like to appreciate Hui-Ping Liu for her initial trials on
   face aging, and thank the volunteers that participated in our
   experiments. Ming-Han Tsai and Yen-Kai Liao are the co-first authors and
   I-Chen Lin is the corresponding author. This paper was partially
   supported by the National Science Council, Taiwan under grant no. NSC
   100-2221-E-009-148.
CR [Anonymous], FG NET AGING DATABAS
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   BURT DM, 1995, P ROY SOC B-BIOL SCI, V259, P137, DOI 10.1098/rspb.1995.0021
   Chou JK, 2013, MULTIMED TOOLS APPL, V63, P729, DOI 10.1007/s11042-011-0891-1
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Hubball D, 2008, COMPUT GRAPH FORUM, V27, P607, DOI 10.1111/j.1467-8659.2008.01158.x
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Li W, 2012, IEEE T SYST MAN CY A, V42, P443, DOI 10.1109/TSMCA.2011.2164066
   Lin IC, 2010, COMPUT ANIMAT VIRT W, V21, P55, DOI 10.1002/cav.332
   Liu ZC, 2001, COMP GRAPH, P271
   Mohammed U, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531363
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Ramanathan N, 2009, J VISUAL LANG COMPUT, V20, P131, DOI 10.1016/j.jvlc.2009.01.011
   Scherbaum K, 2007, COMPUT GRAPH FORUM, V26, P285, DOI 10.1111/j.1467-8659.2007.01050.x
   Seitz S. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P21, DOI 10.1145/237170.237196
   Shaw RB, 2010, PLAST RECONSTR SURG, V125, P332, DOI 10.1097/PRS.0b013e3181c2a685
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Wang CC, 2009, IEEE INT CON MULTI, P282, DOI 10.1109/ICME.2009.5202490
   Zimbler M S, 2001, Facial Plast Surg Clin North Am, V9, P179
NR 23
TC 14
Z9 17
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 801
EP 824
DI 10.1007/s11042-013-1399-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800036
DA 2024-07-18
ER

PT J
AU Xiong, TS
   Yi, Z
   Zhang, L
AF Xiong, Taisong
   Yi, Zhang
   Zhang, Lei
TI Grayscale image segmentation by spatially variant mixture model with
   student's t-distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatially variant finite mixture model; Student's t-distribution; Image
   segmentation; Gradient descent
ID EXPECTATION-MAXIMIZATION
AB A spatially variant finite mixture model with Student's t-distribution component function is proposed for grayscale image segmentation. This model employs a new weight function which contains the information along the different spatial directions indicating the relationship of the pixels in the neighborhood. The label probability proportions are explicitly represented as probability vectors in the model. Gradient descend method is used to update the unknown parameters. The proposed model contains fewer parameters and it is easy to be implemented compare with the Markov random field (MRF) models. Comprehensive experiments on synthetic and natural images are carried out to demonstrate that the proposed model outperforms some other related ones.
C1 [Xiong, Taisong] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 610054, Peoples R China.
   [Yi, Zhang; Zhang, Lei] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
C3 University of Electronic Science & Technology of China; Sichuan
   University
RP Yi, Z (corresponding author), Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
EM xiongtaisong@gmail.com; zhangyi@scu.edu.cn; leizhang@scu.edu.cn
FU National Basic Research Program of China (973 Program) [2011CB302201];
   National Nature Science Foundation of China [60931160441, 61003042]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions, which greatly helped to improve both
   the technical content and the presentation quality of the paper. This
   work was supported by National Basic Research Program of China (973
   Program) under Grant 2011CB302201, and National Nature Science
   Foundation of China under grant No. 60931160441 and No. 61003042.
CR Ben Ayed I, 2008, IEEE T IMAGE PROCESS, V17, P2301, DOI 10.1109/TIP.2008.2006425
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chatzis SP, 2008, IEEE T SIGNAL PROCES, V56, P949, DOI 10.1109/TSP.2007.907912
   Chatzis SP, 2011, PATTERN RECOGN, V44, P295, DOI 10.1016/j.patcog.2010.09.001
   Chatzis SP, 2009, IEEE T PATTERN ANAL, V31, P1657, DOI 10.1109/TPAMI.2008.215
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Li S. Z., 2009, Markov random field modeling in image analysis
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Nguyen TM, 2010, IEEE T NEURAL NETWOR, V21, P1326, DOI 10.1109/TNN.2010.2054109
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Rivera M, 2012, COMPUT J, V55, P313, DOI 10.1093/comjnl/bxr032
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   Sfikas G, 2010, J MATH IMAGING VIS, V36, P91, DOI 10.1007/s10851-009-0174-x
   Svensén M, 2005, NEUROCOMPUTING, V64, P235, DOI 10.1016/j.neucom.2004.11.018
   Nguyen TM, 2012, IEEE T SYST MAN CY B, V42, P193, DOI 10.1109/TSMCB.2011.2161284
   Titterington D. M., 1985, Statistical Analysis of Finite Mixture Distributions, V198
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Woolrich MW, 2006, IEEE T MED IMAGING, V25, P1380, DOI 10.1109/TMI.2006.880682
   Woolrich MW, 2005, IEEE T MED IMAGING, V24, P1, DOI 10.1109/TMI.2004.836545
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 29
TC 6
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 167
EP 189
DI 10.1007/s11042-012-1336-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800009
DA 2024-07-18
ER

PT J
AU Chen, HY
   Zhu, YS
AF Chen, Hongyuan
   Zhu, Yuesheng
TI A robust video watermarking algorithm based on singular value
   decomposition and slope-based embedding technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermarking; Singular value decomposition; Slope-based embedding;
   Copyright protection
ID DIGITAL WATERMARKING; SCHEME
AB In this work, we propose a robust watermarking algorithm for video copyright protection. The proposed algorithm is characterized by four key features. First, a robust feature obtained by singular value decomposition is selected to embed the watermark. Second, a novel slope-based embedding technique is developed to embed a 1-bit watermark into several successive blocks in the temporal direction, thus enhancing the robustness against global attacks. Third, an embedding location selection method is used to give priority to blocks with small variations that can enhance the visual quality of the watermarked video. Fourth, a temporal synchronization method is introduced to effectively withstand temporal synchronization attacks. The experimental results demonstrate that our scheme has good imperceptibility and is robust against various attacks, such as noise addition, filtering, gamma correction, lossy compression, scaling, frame dropping, frame insertion, and frame averaging. Furthermore, the watermark can be extracted using only some side information rather than the original video, which makes the scheme more practical.
C1 [Chen, Hongyuan; Zhu, Yuesheng] Peking Univ, Shenzhen Grad Sch, Commun & Informat Secur Lab, Shenzhen 518055, Peoples R China.
C3 Peking University
RP Zhu, YS (corresponding author), Peking Univ, Shenzhen Grad Sch, Commun & Informat Secur Lab, Shenzhen 518055, Peoples R China.
EM chenhy08826@gmail.com; zhuys@pkusz.edu.cn
FU "Shuang Bai Project" of Shenzhen Research Program; 973 Program, China
   [2012CB315904]
FX This work was supported by the "Shuang Bai Project" of Shenzhen Research
   Program, and 973 Program #2012CB315904, China.
CR Abdallah HA, 2009, 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND SYSTEMS (ICCES 2009), P455, DOI 10.1109/ICCES.2009.5383220
   Al-Taweel FAP., 2009, TENCON IEEE REGION 1, P1
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Campisi P, 2005, IEEE IMAGE PROC, P941
   Chan PW, 2003, LECT NOTES COMPUT SC, V2836, P202
   Chandramouli R, 2002, ENCY IMAGING SCI TEC, P226
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cheveau L, 2001, EBU TECHNICAL REV, P1
   Esen E, 2011, IEEE T CIRC SYST VID, V21, P1130, DOI 10.1109/TCSVT.2011.2134770
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   Fung C. W. H., 2011, 2011 Third International Conference on Computational Intelligence, Modelling and Simulation, P233, DOI 10.1109/CIMSim.2011.48
   Ge QM, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2876, DOI 10.1109/ICMLC.2003.1260050
   Huang HY, 2010, IEEE T INF FOREN SEC, V5, P625, DOI 10.1109/TIFS.2010.2080675
   Ke Niu, 2010, 2010 IEEE International Conference on Software Engineering and Service Sciences (ICSESS 2010), P588, DOI 10.1109/ICSESS.2010.5552286
   Lee YY, 2003, PROCEEDINGS OF THE 46TH IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS & SYSTEMS, VOLS 1-3, P1579
   Li W, 2006, IEEE T MULTIMEDIA, V8, P60, DOI 10.1109/TMM.2005.861291
   Li Y, 2003, ICCIMA 2003: FIFTH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, PROCEEDINGS, P260
   Lin Shinfeng D., 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P340, DOI 10.1109/IIH-MSP.2009.150
   Ling HF, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3565193
   Ling HF, 2011, SIGNAL PROCESS, V91, P1863, DOI 10.1016/j.sigpro.2011.02.009
   Liu LS, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5176
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Mansouri A, 2010, IEEE T INF FOREN SEC, V5, P649, DOI 10.1109/TIFS.2010.2076280
   Osama SF, 2011, OPT ENG, V50
   Preda RO, 2007, TELSIKS 2007: 8TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS IN MODERN SATELLITE, CABLE AND BROADCASTING SERVICES, VOLS 1 AND 2, P465
   Preda RO, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3558734
   Preda RO, 2010, MEASUREMENT, V43, P1720, DOI 10.1016/j.measurement.2010.07.009
   Rajab Lama, 2008, IIT 2008 International Conference on Innovations in Information Technology, P588, DOI 10.1109/INNOVATIONS.2008.4781696
   Sun TF, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL I, P179, DOI 10.1109/ISECS.2009.223
   Wu D, 2009, SOFT COMPUT, V13, P375, DOI 10.1007/s00500-008-0328-6
   Xu DW, 2009, LECT NOTES COMPUT SC, V5703, P96, DOI 10.1007/978-3-642-03688-0_11
NR 31
TC 9
Z9 10
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 991
EP 1012
DI 10.1007/s11042-012-1238-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000002
DA 2024-07-18
ER

PT J
AU Wei, C
   Jing, G
   Tian, ZJ
   Chen, WC
   Liu, ZY
AF Wei, Chen
   Jing, Gao
   Tian Zijian
   Chen Wenchao
   Liu, Zhiyong
TI Block-mode discriminant analysis and its application to face and antenna
   signal recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subspace learning; Linear discriminant analysis; Multi-linear
   discriminant analysis; Recognition; Antenna
ID DIELECTRIC-RESONATOR-ANTENNA; BAND; PATTERN; PCA
AB In this paper we present a multi-linear algebra based approach for feature extraction and signal recognition. We call this method Block-Mode Discriminant Analysis (BMDA). Experimentations are carried out on the CMU-PIE benchmark database for the task of face recognition, and we further utilized our method for the application of the signal recognition of underground UWB dielectric resonator antennas. Experiments show that our proposed BMDA is more effective and fast than its predecessors.
C1 [Wei, Chen; Jing, Gao] China Univ Min & Technol, Coll Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Tian Zijian; Chen Wenchao; Liu, Zhiyong] China Univ Min & Technol, State Key Lab Coal Resources & Safe Min, Beijing 100083, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Wei, C (corresponding author), China Univ Min & Technol, Coll Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM davior.chen@gmail.com
RI Wei, Chen/HOH-9991-2023
OI Wei, Chen/0000-0001-5028-2278
FU National Natural Science Foundation of China [51104157]; Ph.D. Programs
   Foundation of Ministry of Education of China [20110095120008]; China
   Postdoctoral Science Foundation [20100481181]; Fundamental Research
   Funds for the Central Universities [2011QNA30]; Jiangsu Overseas
   Research & Training Program for University Prominent Young & Middle-aged
   Teachers and Presidents
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 51104157), the Ph.D. Programs Foundation of Ministry of
   Education of China (Grant No. 20110095120008), the China Postdoctoral
   Science Foundation (Grant No. 20100481181), the Fundamental Research
   Funds for the Central Universities (Grant No. 2011QNA30), and Jiangsu
   Overseas Research & Training Program for University Prominent Young &
   Middle-aged Teachers and Presidents.
CR Ahmed OMH, 2011, ELECTRON LETT, V47, P7, DOI 10.1049/el.2010.7337
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Chair R, 2007, IET MICROW ANTENNA P, V1, P299, DOI 10.1049/iet-map:20060029
   Denidni TA, 2005, IEEE ANTENN WIREL PR, V4, P453, DOI 10.1109/LAWP.2005.860198
   Dissanayake T, 2007, IEEE T ANTENN PROPAG, V55, P3320, DOI 10.1109/TAP.2007.908792
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   HASTIE T, 1995, ANN STAT, V23, P73, DOI 10.1214/aos/1176324456
   Jin QY, 2013, ARTIF INTELL REV, V39, P285, DOI 10.1007/s10462-011-9273-3
   Jin QY, 2012, PATTERN RECOGN LETT, V33, P381, DOI 10.1016/j.patrec.2011.09.001
   Kishk AA, 2003, IEEE T ANTENN PROPAG, V51, P2913, DOI 10.1109/TAP.2003.816300
   Kishk AA, 2002, IEEE T ANTENN PROPAG, V50, P469, DOI 10.1109/TAP.2002.1003382
   Kofidis E, 2002, SIAM J MATRIX ANAL A, V23, P863, DOI 10.1137/S0895479801387413
   Liang XL, 2008, IEEE ANTENN WIREL PR, V7, P163, DOI 10.1109/LAWP.2008.922051
   Liang XL, 2009, IEEE T ANTENN PROPAG, V57, P271, DOI 10.1109/TAP.2008.2009783
   Liu WC, 2007, MICROW OPT TECHN LET, V49, P1536, DOI 10.1002/mop.22495
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Rao QJ, 2006, IEEE MICROW WIREL CO, V16, P7, DOI 10.1109/LMWC.2005.861360
   Ryu KS, 2011, IEEE T ANTENN PROPAG, V59, P1403, DOI 10.1109/TAP.2011.2109676
   Ryu KS, 2010, IEEE T ANTENN PROPAG, V58, P1047, DOI 10.1109/TAP.2010.2041160
   Ryu KS, 2009, IEEE T ANTENN PROPAG, V57, P3942, DOI 10.1109/TAP.2009.2027727
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   [孙继平 Sun Jiping], 2010, [煤炭学报, Journal of China Coal Society], V35, P2121
   Thamae LZ, 2010, IEEE T ANTENN PROPAG, V58, P3707, DOI 10.1109/TAP.2010.2071332
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Walsh AG, 2006, IEEE ANTENN WIREL PR, V5, P130, DOI 10.1109/LAWP.2006.873935
   Wang HC, 2008, INT J COMPUT VISION, V76, P217, DOI 10.1007/s11263-007-0053-0
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   [杨维 YANG Wei], 2008, [煤炭学报, Journal of China Coal Society], V33, P467
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhang LN, 2008, ELECTRON LETT, V44, P947, DOI 10.1049/el:20081253
   Zheng WS, 2008, PATTERN RECOGN, V41, P2156, DOI 10.1016/j.patcog.2007.11.025
NR 33
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1599
EP 1613
DI 10.1007/s11042-012-1295-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000028
DA 2024-07-18
ER

PT J
AU Song, CW
   Lee, D
   Chung, KY
   Rim, KW
   Lee, JH
AF Song, Chang-Woo
   Lee, Daesung
   Chung, Kyung-Yong
   Rim, Kee-Wook
   Lee, Jung-Hyun
TI Interactive middleware architecture for lifelog based context awareness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Context Awareness; Distributed System; Middleware; Ubiquitous Computing
AB Due to the development of IT convergence, a wide variety of information is being produced and distributed rapidly in digital form. Lifelog based context awareness is a technology that provides a service automatically based on perceived situational information in ubiquitous environments. To offer customized services to users, the technology of acquiring lifelog based context information in real time is the most important consideration. We propose the interactive middleware architecture for lifelog based context awareness in distributed and ubiquitous environments. Conventional middleware to support ubiquitous environments stores and manages the situational information and service content acquired by centralized storage or a DBMS. Centralized situational information and service content management may impede the autonomy of mobile nodes and the interoperation between different middle software. The proposed method designs a system that can distribute and manage situational information in mobile nodes using mobile devices in distributed and ubiquitous environments and share the service content between interactive middleware through publication. The application system designed in this study was used in a scenario providing situational perception based mobile service and proved to be useful.
C1 [Song, Chang-Woo; Lee, Jung-Hyun] Inha Univ, Dept Comp & Informat Engn, Inchon, South Korea.
   [Lee, Daesung] Catholic Univ Pusan, Dept Comp Engn, Pusan, South Korea.
   [Chung, Kyung-Yong] Sangji Univ, Dept Comp Informat Engn, Wonju, South Korea.
   [Rim, Kee-Wook] Sunmoon Univ, Dept Comp Sci & Engn, Asan, South Korea.
C3 Inha University; Catholic University Pusan; Sangji University; Sun Moon
   University
RP Lee, D (corresponding author), Catholic Univ Pusan, Dept Comp Engn, Pusan, South Korea.
EM ph.d.scw@gmail.com; dslee@cup.ac.kr; dragonhci@hanmail.net;
   rim@sunmoon.ac.kr; jhlee@inha.ac.kr
RI Lee, Daesung/P-7946-2018; Chung, Kyungyong/JAC-2276-2023
OI Lee, Daesung/0000-0002-2435-6867; 
FU Basic Science Research Program through the National Research Foundation
   of Korea - Ministry of Education, Science and Technology [2012-0004478]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea funded by the Ministry of
   Education, Science and Technology (No. 2012-0004478).
CR [Anonymous], P 6 ANN IEEE CONS CO
   Beamon Bridget, 2010, 2010 8th IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOM Workshops), P30, DOI 10.1109/PERCOMW.2010.5470599
   Broll Gregor, 2007, 16th IST Mobile and Wireless Communications Summit, 2007, P1
   Choi JH, 2008, IEEE IPCCC, P491, DOI 10.1109/PCCC.2008.4745089
   Craig A., 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P364, DOI 10.1109/WI-IAT.2011.231
   Gorodetsky V., 2008, Second International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies 2008, P422, DOI 10.1109/UBICOMM.2008.82
   Jain P, 2011, COMM COM INF SC, V141, P340
   Jung YG, 2011, INFORMATION-TOKYO, V14, P3791
   Kanter T., 2009, 4 INT C COMM NETW CH, P1, DOI DOI 10.1109/CHINACOM.2009.5339728
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P873, DOI 10.1007/s11042-011-0919-6
   Kim J, 2014, MULTIMED TOOLS APPL, V71, P855, DOI 10.1007/s11042-011-0920-0
   Ming Li, 2011, 2011 10th IEEE International Conference on Cognitive Informatics & Cognitive Computing (ICCI-CC 2011), P278, DOI 10.1109/COGINF.2011.6016153
   Mowafi Yaser, 2010, 2010 Third International Conference on Advances in Human-Oriented and Personalized Mechanisms, Technologies, and Services (CENTRIC 2010), P46, DOI 10.1109/CENTRIC.2010.22
   Rizou S, 2010, SIXTH INTERNATIONAL CONFERENCE ON AUTONOMIC AND AUTONOMOUS SYSTEMS: ICAS 2010, PROCEEDINGS, P84, DOI 10.1109/ICAS.2010.21
   Seyong L, 2008, P IEEE INT S PAR DIS, P1
   Song C, 2011, INFORMATION-TOKYO, V14, P3591
   Sousa JP, 2009, 2009 FOURTH INTERNATIONAL CONFERENCE ON INTERNET AND WEB APPLICATIONS AND SERVICES, P357, DOI 10.1109/ICIW.2009.59
   Sousa JP, 2008, SEVENTH WORKING IEEE/IFIP CONFERENCE ON SOFTWARE ARCHITECTURE, PROCEEDINGS, P71, DOI 10.1109/WICSA.2008.46
   Wei Liu, 2011, 2011 International Conference on Computer Science and Service System (CSSS), P144
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   Ying L, 2007, P INT C PERV COMP AP, P154
NR 21
TC 24
Z9 24
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 813
EP 826
DI 10.1007/s11042-013-1362-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400026
DA 2024-07-18
ER

PT J
AU Charfeddine, M
   El'arbi, M
   Ben Amar, C
AF Charfeddine, Maha
   El'arbi, Maher
   Ben Amar, Chokri
TI A new DCT audio watermarking scheme based on preliminary MP3 study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Discrete Cosine transform; Back propagation neural
   networks; MP3 compression; Video watermarking; MPEG Compression
ID FREQUENCY; ROBUST; TIME
AB In this paper, a new audio watermarking scheme operating in the frequency domain and based on neural network architecture is described. The watermark is hidden into the middle frequency band after performing a Discrete Cosine transform (DCT). Embedding and extraction of the watermark are based on the use of a back-propagation neural network (BPNN) architecture. In addition, the selection of frequencies and the block hiding the watermark are based on a preliminary study of the effect of MP3 compression at several rates on the signal. Experimental results show that the proposed technique presents good robustness and perceptual quality results. We also investigate the application of the proposed technique in video watermarking. Traditional techniques have used audio channel as supplementary embedding space and adopt state-of-the art techniques that resist to MP3 compression attack. In these techniques, the MPEG compression attack is only evaluated on the video part and the audio part is kept unaffected. In this paper, we adapt the preliminary MP3 study to video watermarking technique but with a preliminary study of the MPEG compression applied to the audio channel. Here again, we notice that the application of the preliminary MPEG study to the audio channel improves the robustness of the video watermarking scheme though keeping high-quality watermarked video sequences.
C1 [Charfeddine, Maha; El'arbi, Maher; Ben Amar, Chokri] Univ Sfax, Res Grp Intelligent Machines, ENIS, Sfax 3038, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS)
RP Charfeddine, M (corresponding author), Univ Sfax, Res Grp Intelligent Machines, ENIS, BP 1173, Sfax 3038, Tunisia.
EM charfeddine.maha@ieee.org; maher.elarbi@gmail.com;
   chokri.benamar@ieee.org
RI charfeddine, maha/AAC-7422-2021; Chokri, BEN AMAR/K-5237-2012
OI charfeddine, maha/0000-0003-2996-4113; 
FU General Direction of Scientific Research (DGRST), Tunisia under the ARUB
   program
FX The authors would like to acknowledge the financial support of this work
   by grants from General Direction of Scientific Research (DGRST),
   Tunisia, under the ARUB program.
CR Ali A.-H., 2010, EUR J SCI RES, V39, P6
   [Anonymous], 2005, P ACM MMSEC
   Barnett R, 1999, ELECTRON COMMUN ENG, V11, P173, DOI 10.1049/ecej:19990401
   Ben Hamida A, 2011, IEEE S SER COMP INT, P108
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   BHAT V, 2010, DIGIT SIGNAL PROCESS, V20, P426
   Bhat V, 2008, LECT NOTES COMPUT SC, V5352, P235, DOI 10.1007/978-3-540-89862-7_20
   Chaabane F., 2011, 2011 3rd International Conference on Next Generation Networks and Services (NGNS), P90, DOI 10.1109/NGNS.2011.6142556
   Chan PW, 2003, LECT NOTES COMPUT SC, V2836, P202
   CHEVEAU L, 2001, EBU TECHNICAL RE MAR, P8
   Christian N, 1998, P 105 AES CONV
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cox IJ, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P225, DOI 10.1109/MMSP.2001.962738
   Craver S, 1998, IEEE J SEL AREA COMM, V16, P573, DOI 10.1109/49.668979
   El'Arbi M., 2011, proceeding of the third IEEE Symposium Series in computational intelligence CICS, P164
   El'arbi M, 2010, IJCIIS, V1, P34
   El'arbi M, 2005, P 2 INT S COMP INT I, P135
   El'Arbi M, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1577, DOI 10.1109/ICME.2006.262846
   El'Arbi M, 2011, MULTIMED TOOLS APPL, V55, P579, DOI 10.1007/s11042-010-0580-5
   Foo S-W, 2010, WORLD ACAD SCI ENG T, P680
   Gaorong Zeng, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P2193, DOI 10.1109/ICOSP.2008.4697583
   Gosavi CS, 2010, IJCSIS, V8, P64
   Haykin S., 1998, NEURAL NETWORKS COMP
   Koubaa M, 2007, ICSPC: 2007 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATIONS, VOLS 1-3, PROCEEDINGS, P1143
   Koubaa M, 2010, INT J MULTIMEDIA TOO, V56, P281
   Laftsidis Tefas, 2003, P IEEE INT S CIRC SY, P933
   Lee CH, 2000, P SOC PHOTO-OPT INS, V3971, P209, DOI 10.1117/12.384975
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Liu HY, 2008, C IND ELECT APPL, P843, DOI 10.1109/ICIEA.2008.4582634
   Maha C, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P1138, DOI 10.1109/ISCCSP.2008.4537396
   Maha C, 2010, SIGMAP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATION, P139
   Martinez-Noriega Raul, 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P135, DOI 10.1109/IIHMSP.2010.41
   Martinez-Noriega R, 2006, P MEX C INF SEC
   Masmoudi S, 2010, P 2 IEEE INT WORKSH
   Moon Todd K., 2005, Error correction coding, mathematical methods and algorithms
   Nikmehr  H., 2010, 1 INT C COMM ENG, P1
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Salma M., 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P326, DOI 10.1109/ISSPIT.2010.5711803
   Sehirli M, 2004, LECT NOTES COMPUT SC, V3261, P430
   Sun ZW, 2009, NEURAL COMPUT APPL, V18, P507, DOI 10.1007/s00521-009-0253-3
   Swanson MD, 1998, SIGNAL PROCESS, V66, P337, DOI 10.1016/S0165-1684(98)00014-0
   Uludag U., 2001, AUDIO WATERMARKING U, P1
   Wang J, 2011, SIGNAL PROCESS, V91, P1693, DOI 10.1016/j.sigpro.2011.01.014
   Wang LX, 2007, ICEMI 2007: PROCEEDINGS OF 2007 8TH INTERNATIONAL CONFERENCE ON ELECTRONIC MEASUREMENT & INSTRUMENTS, VOL II, P423
   Wu SQ, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P712
   Xu XJ, 2007, LECT NOTES ARTIF INT, V4578, P136
NR 46
TC 25
Z9 27
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1521
EP 1557
DI 10.1007/s11042-012-1167-0
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500008
DA 2024-07-18
ER

PT J
AU Tsai, DS
   Chen, YC
AF Tsai, Du-Shiau
   Chen, Yu-Chi
TI Visibility bounds for visual secret sharing based on JND theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Human vision system; Just noticeable difference
ID CRYPTOGRAPHY SCHEMES; CHEATING PREVENTION; CONTRAST
AB Visual secret sharing (VSS) is a noteworthy variant of secret sharing. One special property of VSS is that the security of VSS is achieved by loosing the contrast and the resolution of the secret image. Generally, the reconstructed secrets of these schemes are considered to be visible if and only if the contrast is greater than 0. However, VSS is based on the human vision system (HVS), thus the visibility is not only dependent on the contract. In this paper, we discuss the limit of human vision for VSS (LHV-VSS), because HVS is actually complicated. We take several human vision parameters into consideration, and propose a profile to analyze the upper bound of n for k-out-of-n VSS schemes based on the just noticeable difference (JND) profile. We conclude some cases of VSS schemes are invisible practically according to the analyses. Finally, we give a definition for VSS, visibility condition.
C1 [Tsai, Du-Shiau] Hsiuping Univ Sci & Technol, Dept Informat & Networking Technol, Taichung 412, Taiwan.
   [Chen, Yu-Chi] Natl Chung Hsing Univ, Dept Comp Sci & Engn, Taichung 402, Taiwan.
C3 National Chung Hsing University
RP Tsai, DS (corresponding author), Hsiuping Univ Sci & Technol, Dept Informat & Networking Technol, 11 Gongye Rd, Taichung 412, Taiwan.
EM dstsai@hust.edu.tw; wycchen@ieee.org
OI Chen, Yu-Chi/0000-0002-5577-0016
FU National Science Council, Taiwan, R.O.C. [NSC100-2221-E-164-010]
FX This work was partially supported by the National Science Council,
   Taiwan, R.O.C., under contract No. NSC100-2221-E-164-010.
CR Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blundo C, 1999, J CRYPTOL, V12, P261, DOI 10.1007/s001459900057
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   Blundo C, 2003, SIAM J DISCRETE MATH, V16, P224, DOI 10.1137/S0895480198336683
   Chen YC, 2011, VISUAL CRYPTOGRAPHY
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   De Prisco R, 2010, COMPUT J, V53, P1485, DOI 10.1093/comjnl/bxp068
   Droste S., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P401
   Hofmeister T, 2000, THEOR COMPUT SCI, V240, P471, DOI 10.1016/S0304-3975(99)00243-1
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hu CM, 2007, IEEE T IMAGE PROCESS, V16, P36, DOI 10.1109/TIP.2006.884916
   Jayant N, 1992, IEEE J SEL AREA COMM, V10, P314
   Lu S, 2011, J COMB OPTIM, V21, P47, DOI 10.1007/s10878-009-9241-x
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Yang CN, 2010, OPT COMMUN, V283, P4949, DOI 10.1016/j.optcom.2010.07.051
   Zhou Z, 2006, IEEE T IMAGE PROCESS, V15, P2441, DOI 10.1109/TIP.2006.875249
NR 19
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1825
EP 1836
DI 10.1007/s11042-012-1206-x
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500021
DA 2024-07-18
ER

PT J
AU Yang, HJ
   Quehl, B
   Sack, H
AF Yang, Haojin
   Quehl, Bernhard
   Sack, Harald
TI A framework for improved video text detection and recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video OCR; Video indexing; Multimedia retrieval
ID IMAGES; LOCALIZATION; CLASSIFICATION; TRACKING
AB Text displayed in a video is an essential part for the high-level semantic information of the video content. Therefore, video text can be used as a valuable source for automated video indexing in digital video libraries. In this paper, we propose a workflow for video text detection and recognition. In the text detection stage, we have developed a fast localization-verification scheme, in which an edge-based multi-scale text detector first identifies potential text candidates with high recall rate. Then, detected candidate text lines are refined by using an image entropy-based filter. Finally, Stroke Width Transform (SWT)- and Support Vector Machine (SVM)-based verification procedures are applied to eliminate the false alarms. For text recognition, we have developed a novel skeleton-based binarization method in order to separate text from complex backgrounds to make it processible for standard OCR (Optical Character Recognition) software. Operability and accuracy of proposed text detection and binarization methods have been evaluated by using publicly available test data sets.
C1 [Yang, Haojin; Quehl, Bernhard; Sack, Harald] Univ Potsdam, Hasso Plattner Inst IT Syst Engn, D-14467 Potsdam, Germany.
C3 University of Potsdam
RP Yang, HJ (corresponding author), Univ Potsdam, Hasso Plattner Inst IT Syst Engn, Prof Dr Helmert Str 2-4, D-14467 Potsdam, Germany.
EM haojin.yang@hpi.uni-potsdam.de; Bernhard.Quehl@hpi.uni-potsdam.de;
   Harald.Sack@hpi.uni-potsdam.de
OI Sack, Harald/0000-0001-7069-9804
FU Mediaglobe project; German Federal Ministry of Economics and Technology
   on the basis of a decision by the German Bundestag [FKZ: 01MQ09031]
FX This work has been supported by the Mediaglobe project. Mediaglobe is a
   SME project of the THESEUS research program, supported by the German
   Federal Ministry of Economics and Technology on the basis of a decision
   by the German Bundestag (FKZ: 01MQ09031).
CR [Anonymous], 1982, IMAGE ANAL MATH MORP
   Anthimopoulos M, 2010, IMAGE VISION COMPUT, V28, P1413, DOI 10.1016/j.imavis.2010.03.004
   Bhaskar H., 2010, P 13 C INF FUS FUSIO, P1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Chengbin Zeng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2069, DOI 10.1109/ICPR.2010.509
   Deza E., 2009, Encyclopedia of Distances
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Gavata J, 2006, IEEE INT SYM MULTIM, P283
   Gllavata J, 2004, INT C PATT RECOG, P425, DOI 10.1109/ICPR.2004.1334146
   Hanif Shehzad Muhammad, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1, DOI 10.1109/ICDAR.2009.172
   Haojin Yang, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P111, DOI 10.1109/ISM.2011.26
   Hua X.-S., 2001, P 2001 ACM WORKSH MU, P24
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Karatzas D, 2011, PROC INT CONF DOC, P1485, DOI 10.1109/ICDAR.2011.295
   Keysers D., 2006, COMP COMBINATION STA
   Kim HH, 2011, J AM SOC INF SCI TEC, V62, P478, DOI 10.1002/asi.21482
   Kim KI, 2001, PATTERN RECOGN, V34, P527, DOI 10.1016/S0031-3203(00)00095-9
   LI H, 1999, P SPIE DOC REC 4, P1
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Niblack W., 1986, An Introduction to Digital Image Processing
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan YF, 2008, PROCEEDINGS OF THE 8TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, P35, DOI 10.1109/DAS.2008.42
   Qian XM, 2007, SIGNAL PROCESS-IMAGE, V22, P752, DOI 10.1016/j.image.2007.06.005
   Sato T, 1999, MULTIMEDIA SYST, V7, P385, DOI 10.1007/s005300050140
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Shivakumara P, 2009, P 2009 INT C MULT EX, P1
   Sobel I., 1990, An Isotropic 3x3 Image Gradient Operator, P376, DOI [10.13140/RG.2.1.1912.4965, DOI 10.13140/RG.2.1.1912.4965]
   Sobottka K., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P57, DOI 10.1109/ICDAR.1999.791724
   Sonnenburg S, 2010, J MACH LEARN RES, V11, P1799
   Thillou CM, 2007, COMPUT VIS IMAGE UND, V107, P1
   Wolf C, 2002, INT C PATT RECOG, P1037, DOI 10.1109/ICPR.2002.1048482
   Zhao M, 2010, IMAGE VISION COMPUT, V28, P1590, DOI 10.1016/j.imavis.2010.04.002
   Zhiwei Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P133, DOI 10.1109/ICPR.2010.41
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
NR 38
TC 26
Z9 27
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2014
VL 69
IS 1
BP 217
EP 245
DI 10.1007/s11042-012-1250-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AB3UH
UT WOS:000331715200011
DA 2024-07-18
ER

PT J
AU Urueña, M
   Muñoz, A
   Larrabeiti, D
AF Uruena, Manuel
   Munoz, Alfonso
   Larrabeiti, David
TI Analysis of privacy vulnerabilities in single sign-on mechanisms for
   multimedia websites
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenID; Facebook connect; Google connect; Single sign-on(SSO); Privacy;
   Security
AB This paper studies the privacy risks for the users of two popular single sign-on platforms for web-based content access: OpenID and Facebook Connect. In particular we describe in detail a privacy vulnerability of the OpenID Authentication Protocol that leads to the exposure of the OpenID user identifier to third parties. We illustrate how OpenID agents leak the (potentially unique) OpenID identifiers of their users to third parties, like advertisement and traffic analysis corporations. This vulnerability is a real and widespread privacy risk for OpenID users. This paper also analyzes the privacy of Facebook Connect --the proprietary single sign-on platform that is gaining a lot of popularity recently-- and, we conclude that it is not affected by the same vulnerability but other important privacy issues remain. Finally, this paper studies the solution space of these problems and defines a number of possible countermeasures. In the case of the OpenID vulnerability, we propose three solutions to this problem: one for the long term to avoid the root cause of the vulnerability, and another two short-term mitigations.
C1 [Uruena, Manuel; Munoz, Alfonso; Larrabeiti, David] Univ Carlos III Madrid, Leganes 28911, Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP Urueña, M (corresponding author), Univ Carlos III Madrid, Avda Univ 30, Leganes 28911, Madrid, Spain.
EM muruenya@it.uc3m.es; ammunoz@it.uc3m.es; dlarra@it.uc3m.es
RI Urueña, Manuel/J-3189-2012; LARRABEITI, DAVID/F-4934-2016
OI Urueña, Manuel/0000-0001-7834-5998; LARRABEITI,
   DAVID/0000-0003-4983-0243
FU INDECT project of the 7th EU Framework Programme [218086]
FX The work presented in this paper has been funded by the INDECT project
   (Ref 218086) of the 7th EU Framework Programme.
CR [Anonymous], P WORKSH WEB 2 0 SEC
   Escola R, 1999, 2631 IETF RFC
   Fielding R., 1999, 2616 RFC
   Hammer-Lahav E., 2011, OAUTH 2 0 A IN PRESS
   Miculan M, 2011, 37 C CURR TRENDS THE
   Recordon D., 2006, Openid authentication 1.1
   Sovis P, 2010, P INF SEC SOL EUR IS
   The OpenID Foundation, 2007, OPENID AUTH 2 0 FIN
NR 8
TC 8
Z9 9
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2014
VL 68
IS 1
BP 159
EP 176
DI 10.1007/s11042-012-1155-4
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 283JZ
UT WOS:000329243600010
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Porto, M
   Cristani, C
   Dall'Oglio, P
   Grellert, M
   Mattos, J
   Bampi, S
   Agostini, L
AF Porto, Marcelo
   Cristani, Cassio
   Dall'Oglio, Pargles
   Grellert, Mateus
   Mattos, Julio
   Bampi, Sergio
   Agostini, Luciano
TI Iterative random search: a new local minima resistant algorithm for
   motion estimation in high-definition videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Fast Search Algorithm; High-definition Videos
ID HARDWARE
AB Motion estimation (ME) is the most important component of current video encoders, however, it presents a very high computational complexity. To deal with this complexity, fast ME search algorithms are widely used, since they can greatly speed up this process. Fast search algorithms are vulnerable to choose local minima, producing quality losses, and these losses are more significant when high-definition videos are considered. This work presents a new fast search algorithm for motion estimation, focusing on high-definition videos, named Iterative Random Search (IRS). The IRS algorithm randomly chooses candidate blocks from the reference frame, and, for the best candidates, an iterative refinement is done. The central position is also evaluated through an iterative process. By using this combination of strategies, the IRS becomes less susceptible to local minima falls. Achieved results show that, for 1080p sequences, IRS generates the highest quality results when compared to well known fast algorithms, such as Diamond Search, Four Step Search and Three Step Search. The quality gains can be higher than 4 dB, while the number of evaluated candidate blocks may increase, at most, 2.6 times. Additionally, the average quality loss against Full Search is 1.45 dB, while the number of evaluated candidate blocks can achieve a reduction higher than 200 times.
C1 [Porto, Marcelo; Bampi, Sergio] Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.
   [Porto, Marcelo; Cristani, Cassio; Dall'Oglio, Pargles; Grellert, Mateus; Mattos, Julio; Agostini, Luciano] Univ Fed Pelotas, Grp Architectures & Integrated Circuits, Pelotas, Brazil.
   [Agostini, Luciano] Univ Fed Pelotas, Ctr Technol Dev CDTEC, Pelotas, Brazil.
C3 Universidade Federal do Rio Grande do Sul; Universidade Federal de
   Pelotas; Universidade Federal de Pelotas
RP Porto, M (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, Porto Alegre, RS, Brazil.
EM msporto@inf.ufrgs.br; crcristani@inf.ufpel.edu.br;
   pwdalloglio@inf.ufpel.edu.br; mgdsilva@inf.ufpel.edu.br;
   julius@inf.ufpel.edu.br; bampi@inf.ufrgs.br; agostini@inf.ufpel.edu.br
RI Agostini, Luciano/N-1102-2019; Grellert, Mateus/AFU-3610-2022; Bampi,
   Sergio/P-6696-2018; Agostini, Luciano/G-8626-2011
OI Grellert, Mateus/0000-0003-0600-7054; Bampi, Sergio/0000-0002-9018-6309;
   Agostini, Luciano/0000-0002-3421-5830
CR [Anonymous], J CONVERGENCE
   [Anonymous], 2003, Standard Codecs: Image Compression to Advanced Video Coding
   Byun J, 2010, IEEE T CONSUM ELECTR, V56, P1911, DOI 10.1109/TCE.2010.5606346
   CHONG RM, 2010, J CONVERGENCE, V1, P49
   International Organization For Standardization, 1999, 144962 ISOIEC
   JCT-VC, 2011, JCT VC M GEN
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   Kuhn P., 1999, Algorithms, complexity analysis and VLSI architectures for MPEG-4 motion estimation
   Kuo CM, 2009, IEEE T CIRC SYST VID, V19, P893, DOI 10.1109/TCSVT.2009.2017420
   Lin YK, 2008, IEEE T CIRCUITS-I, V55, P1526, DOI 10.1109/TCSI.2008.916681
   Ndili O, 2010, IEEE IMAGE PROC, P749, DOI 10.1109/ICIP.2010.5652065
   Po LM, 2009, IEEE T CIRC SYST VID, V19, P1189, DOI 10.1109/TCSVT.2009.2020320
   Porto M, 2007, ACM BRAZ S MULT WEB, P111
   Puri A, 2004, SIGNAL PROCESS-IMAGE, V19, P793, DOI 10.1016/j.image.2004.06.003
   Schiavon Porto Marcelo, 2011, International Journal of Information Technology, Communications and Convergence, V1, P410, DOI 10.1504/IJITCC.2011.044643
   Tasdizen Ozgur, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2354, DOI 10.1109/ICPR.2010.576
   Tasdizen O, 2009, IEEE T CONSUM ELECTR, V55, P1645, DOI 10.1109/TCE.2009.5278038
   Trojahn Tiago Henrique, 2011, International Journal of Information Technology, Communications and Convergence, V1, P391, DOI 10.1504/IJITCC.2011.044642
   Urban F, 2008, IEEE T CIRC SYST VID, V18, P1781, DOI 10.1109/TCSVT.2008.2004927
   Wei S, 2008, INT C CIRC SYST ICCC, P689
   WIEGAND T, 2003, JVTG050R1
   Xie Lifen, 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P483, DOI 10.1109/ICCRD.2011.5764063
   Xiph.org, 2011, TEST MED
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 24
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 1
BP 107
EP 127
DI 10.1007/s11042-012-1033-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105KY
UT WOS:000316069400008
DA 2024-07-18
ER

PT J
AU Sharma, N
   Zhu, JD
   Zheng, YF
   Balster, EJ
AF Sharma, Naresh
   Zhu, Junda
   Zheng, Yuan F.
   Balster, Eric J.
TI Arbitrarily shaped virtual-object based video compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arbitrarily shaped virtual-object; Shape adaptive wavelet transform; 3D
   wavelet compression
ID WAVELET TRANSFORM; IMAGE; SHRINKAGE; ALGORITHM
AB Object based compression techniques are widely believed to have the potential to give the best compression results for a given signal quality. However, true object tracking and extraction are difficult and computationally expensive. In this paper, an arbitrarily shaped virtual-object compression method is developed. The method is similar to the object based compression methods in that it separates the changing portion of the video from the stationary portion, and encodes them independently. The changing portion of the video is grouped as a 3D arbitrarily shaped virtual-object whereas the unchanged portion of the video is grouped as background. The arbitrarily shaped virtual object is coded using 3D wavelet compression whereas stationary background is coded as a single frame using 2D wavelet compression. Experimental results demonstrate that the newly developed method has comparable performance with the state-of-the-art compression methods and significantly outperforms rectangular virtual-object compression.
C1 [Sharma, Naresh; Zhu, Junda; Zheng, Yuan F.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
   [Balster, Eric J.] Univ Dayton, Dept Elect & Comp Engn, Dayton, OH 45469 USA.
C3 University System of Ohio; Ohio State University; University System of
   Ohio; University of Dayton
RP Balster, EJ (corresponding author), Univ Dayton, Dept Elect & Comp Engn, Dayton, OH 45469 USA.
EM sharman@ece.osu.edu; zhuj@ece.osu.edu; zheng@ece.osu.edu;
   balsteej@notes.udayton.edu
RI zheng, yuan/JCN-7781-2023
CR Abu-Hajar A, 2002, PROCEEDINGS OF THE 2002 IEEE 10TH DIGITAL SIGNAL PROCESSING WORKSHOP & 2ND SIGNAL PROCESSING EDUCATION WORKSHOP, P94, DOI 10.1109/DSPWS.2002.1231083
   Adhami R, 1996, 1996 IEEE AEROSPACE APPLICATIONS CONFERENCE, PROCEEDINGS, VOL 4, P449, DOI 10.1109/AERO.1996.499679
   [Anonymous], 1995, 138182 ISOIEC
   Avaro O, 2000, MPEG 4 SYSTEMS OVERV
   Balster E. J., 2005, 2005 48th IEEE International Midwest Symposium on Circuits and Systems (IEEE Cat. No. 05CH37691), P1700
   Balster EJ, 2006, IEEE T CIRC SYST VID, V16, P220, DOI 10.1109/TCSVT.2005.857816
   Balster EJ, 2005, IEEE T IMAGE PROCESS, V14, P2024, DOI 10.1109/TIP.2005.859385
   BALSTER EJ, 2004, THESIS OHIO STATE U
   BBC Research, 2010, DIR OV
   Bindulal T. S., 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P325
   Chunlei Jiang, 2010, 2010 International Conference on Computer Application and System Modeling (ICCASM 2010), P275, DOI 10.1109/ICCASM.2010.5622621
   Crave O, 2010, IEEE T CIRC SYST VID, V20, P769, DOI 10.1109/TCSVT.2010.2045805
   Fowler JE, 2000, P SPIE, V4115
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Guo HT, 1997, INT CONF ACOUST SPEE, P1973, DOI 10.1109/ICASSP.1997.599273
   He C, 2003, IEEE T CIRC SYST VID, V13, P961, DOI 10.1109/TCSVT.2003.816514
   He C, 2002, IEEE T MULTIMEDIA, V4, P528, DOI 10.1109/TMM.2002.806534
   Hwang YT, 2001, SIPS 2001: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS: DESIGN AND IMPLEMENTATION, P225, DOI 10.1109/SIPS.2001.957351
   ISO, 2004, 1449610 ISOIEC
   *ISO IEC, 1993, 111722 ISOIEC
   ISO/IEC, 1998, 1449610 ISOIEC
   Jozawa H., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P649, DOI 10.1109/ICASSP.1992.226314
   Kao MP, 2010, IEEE T IMAGE PROCESS, V19, P1214, DOI 10.1109/TIP.2009.2039373
   Karlsson G., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1100, DOI 10.1109/ICASSP.1988.196787
   Li J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P683, DOI 10.1109/ICIP.1998.727352
   Li SP, 2000, IEEE T CIRC SYST VID, V10, P725, DOI 10.1109/76.856450
   Lin CJ, 2000, IEEE T CIRC SYST VID, V10, P1496, DOI 10.1109/76.889059
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P888, DOI 10.1109/TCSVT.2008.920969
   Martucci SA, 1997, IEEE T CIRC SYST VID, V7, P109, DOI 10.1109/76.554422
   MSU Graphics and Media Lab (Video Group), 2011, MSU VID QUAL MEAS TO
   Oktiawati UY, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P775
   Polzer A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P436, DOI 10.1109/ICIP.1997.632149
   Shen ZL, 2008, IEEE T CIRC SYST VID, V18, P845, DOI 10.1109/TCSVT.2008.919086
   Shuxin Yin, 2010, Proceedings 2010 International Conference on Optoelectronics and Image Processing (ICOIP 2010), P376, DOI 10.1109/ICOIP.2010.345
   SIKORA T, 1995, IEEE T CIRC SYST VID, V5, P59, DOI 10.1109/76.350781
   Strat TM, 2002, PROCEEDINGS OF WORKSHOP AND EXHIBITION ON MPEG-4, P53, DOI 10.1109/MPEG.2001.996447
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Tan W, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P17, DOI 10.1109/ICIP.1996.559422
   Tham JY, 1998, IEEE J SEL AREA COMM, V16, P12, DOI 10.1109/49.650917
   Tsai MJ, 1996, IEEE T CIRC SYST VID, V6, P519, DOI 10.1109/76.538934
   van der Laan WJ, 2011, IEEE T PARALL DISTR, V22, P132, DOI 10.1109/TPDS.2010.143
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xing GW, 2001, IEEE T CIRC SYST VID, V11, P1135, DOI 10.1109/76.954500
   Zhou LL, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P585
   Zixing Xiong, 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P273, DOI 10.1109/ISCAS.1998.698813
NR 46
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 659
EP 680
DI 10.1007/s11042-011-0869-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500006
DA 2024-07-18
ER

PT J
AU Suárez-Figueroa, MC
   Atemezing, GA
   Corcho, O
AF Carmen Suarez-Figueroa, Mari
   Auguste Atemezing, Ghislain
   Corcho, Oscar
TI The landscape of multimedia ontologies in the last decade
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ontology; Multimedia; RDF(S); OWL; Comparative Framework
ID INTEROPERABILITY; RETRIEVAL
AB Many efforts have been made in the area of multimedia to bridge the so-called "semantic-gap" with the implementation of ontologies from 2001 to the present. In this paper, we provide a comparative study of the most well-known ontologies related to multimedia aspects. This comparative study has been done based on a framework proposed in this paper and called FRAMECOMMON. This framework takes into account process-oriented dimension, such as the methodological one, and outcome-oriented dimensions, like multimedia aspects, understandability, and evaluation criteria. Finally, we derive some conclusions concerning this one decade state-of-art in multimedia ontologies.
C1 [Carmen Suarez-Figueroa, Mari; Corcho, Oscar] Univ Politecn Madrid, Fac Informat, OEG, Artificial Intelligence Dept,Sch Comp Sci, Madrid, Spain.
   [Auguste Atemezing, Ghislain] Eurecom, MM Dept, Sophia Antipolis, France.
   [Auguste Atemezing, Ghislain] Eurecom, Multimedia Dept, Sophia Antipolis, France.
C3 Universidad Politecnica de Madrid; IMT - Institut Mines-Telecom;
   EURECOM; IMT - Institut Mines-Telecom; EURECOM
RP Suárez-Figueroa, MC (corresponding author), Univ Politecn Madrid, Fac Informat, OEG, Artificial Intelligence Dept,Sch Comp Sci, Madrid, Spain.
EM mcsuarez@fi.upm.es; ghislain.atemezing@gmail.com; ocorcho@fi.upm.es
RI Corcho, Oscar/C-4000-2011; Suárez-Figueroa, Mari Carmen/J-6277-2012
OI Corcho, Oscar/0000-0002-9260-0753; SUAREZ DE FIGUEROA BAONZA, M.
   CARMEN/0000-0003-3807-5019; Atemezing, Ghislain/0000-0003-1562-6922
FU Spanish project BUSCAME-DIA, a CENIT-E project [CEN-2009-1026]; Centre
   for the Development of Industrial Technology (CDTI)
FX This work has been developed in the framework of the Spanish project
   BUSCAME-DIA (www.cenitbuscamedia.es), a CENIT-E project with reference
   number CEN-2009-1026 and funded by the Centre for the Development of
   Industrial Technology (CDTI). We would like to thank our partners in the
   project for their help.
CR ALBERTONI A, 2006, P 1 INT WORKSH SHAP
   [Anonymous], 2001, 15938 ISOIEC
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 2007, SAMT 2007 2 INT C SE
   [Anonymous], P 13 INT C KNOWL ENG
   ARNDT R, 2007, 6 INT SEM WEB C ISWC
   Arndt R., 2009, HDB ONTOLOGIES, P403, DOI DOI 10.1007/9783-54092673-3_18
   BLOEHDORN S, 2005, 2 EUR SEM WEB C ESWC
   Bloehdorn S., 2004, P EUR WORKSH INT KNO
   Celma O, 2006, SEMANTIC WEB CHALLEN
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V46, P331, DOI 10.1007/s11042-009-0387-4
   Digital Imaging Group (DIG), 2000, DIG35 SPEC MET DIG I
   Garcia R., 2005, Proceedings of the ISWC 2005 Workshop on Knowledge Markup and Semantic Annotation (Semannot'2005). Volume, V185, P69
   HALASCHEKWIENER C, 2006, INT PROV ANN WORKSH
   HUNTER J, 2001, INT SEM WEB WORK S S
   Moscato V., 2010, P 1 IT INF RETR WORK, P89
   NACK F, 1999, IEEE MULTIMEDIA, V6
   Pinto H. S., 2001, Proceedings of the First International Conference on Knowledge Capture, P131, DOI 10.1145/500737.500759
   Poveda-Villalon M., 2010, WORKSH ONT QUAL ONTO
   Poveda-Villalon M, 2010, CURRENT TOPICS ARTIF
   Raimond Y., 2010, MUSIC ONTOLOGY SPECI
   Raphael Troncy, 2007, INT WORKSH MULT ANN, P2
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   SIMOU N, 2005, P WORKSH IM AN MULT
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Suarez-Figueroa M.D.C., 2010, THESIS U POLITECNICA
   Troncy R, 2006, LECT NOTES COMPUT SC, V4306, P41
   Tsinaraki C, 2004, LECT NOTES COMPUT SC, V3115, P582
   Visual Resources Association Data Standards Committee et al, 2002, VRA COR CAT VERS 3 0
NR 30
TC 9
Z9 9
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2013
VL 62
IS 2
BP 377
EP 399
DI 10.1007/s11042-011-0905-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 076OM
UT WOS:000313965900005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ahmed, DT
   Shirmohammadi, S
AF Ahmed, Dewan Tanvir
   Shirmohammadi, Shervin
TI Improving online gaming experience using location awareness and
   interaction details
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Networked games; Client-server; Latency; Lag compensation;
   Synchronization; Performance
AB Latency is a key element for online game quality and user experience. The client-server approach is a widely used system supporting hundreds of thousands of players on a regular basis. However, if latency among players via an intermediate server is large, timely interaction for them could be difficult. In this article, we present a procedure to share game states for a group of players within their area of interaction so that players can comply with stringent time-constraint and improve their game experience. As players move around in a game space, so do their virtual positions. In addition, the relative orientation of players within an area of interaction is unpredictable which indeed changes quite frequently. Because of these facts, we cannot make a predefined rule set for message exchange among players. So a message exchange plan currently working well might have low efficiency after a while due to dynamic changes. In our procedure, considering the importance of interaction, relative orientation, and virtual and geographical locations, we devise a message exchange plan that works alone in each client machine with the local information available. Significant performance improvements are noticed through simulations, validating our approach.
C1 [Ahmed, Dewan Tanvir; Shirmohammadi, Shervin] Univ Ottawa, Sch Informat Technol & Engn, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
C3 University of Ottawa
RP Ahmed, DT (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Distributed & Collaborat Virtual Environm Res Lab, Ottawa, ON, Canada.
EM dahmed@discover.uottawa.ca; shervin@discover.uottawa.ca
RI Shirmohammadi, Shervin/E-6945-2012
OI Shirmohammadi, Shervin/0000-0002-3973-4445
CR Ahmed DT, 2006, IEEE INT WORKSH HAPT, P165
   Ahmed DT, 2010, INT C EMB MULT COMP
   Assiotis M., 2006, P 5 ACM SIGCOMM WORK, P4
   Chambers C., 2005, P 5 ACM SIGCOMM C IN, P1
   Claypool M, 2006, COMMUN ACM, V49, P40, DOI 10.1145/1167838.1167860
   Dick M., 2005, NetGames'05, P1
   El-Sayed A, 2003, IEEE NETWORK, V17, P46, DOI 10.1109/MNET.2003.1174177
   Feng WC, 2005, IEEE ACM T NETWORK, V13, P488, DOI 10.1109/TNET.2005.850221
   Fritsch Tobias., 2005, NETGAMES 05, P1
   Hampel T., 2006, PROC 5 ACM SIGCOMM W, P48, DOI [10.1145/1230040.1230058, DOI 10.1145/1230040.1230058]
   Hosseini M, 2007, IEEE COMMUN SURV TUT, V9, P58, DOI 10.1109/COMST.2007.4317616
   *IEEE, 1998, IEEE STAND DISTR INT
   Kaune S, 2009, EUROMICRO WORKSHOP P, P301, DOI [10.1109/.43, 10.1109/PDP.2009.44]
   Miller JL, 2010, P INT WORKSH NETW SY
   Pullen J. M., 1999, Proceedings 3rd IEEE International Workshop on Distributed Interactive Simulation and Real-Time Applications, P59, DOI 10.1109/DISRTA.1999.807726
   Ratti S, 2010, IEEE INTERNET COMPUT, V14, P60, DOI 10.1109/MIC.2010.57
   Schiele G, 2007, CCGRID 2007: SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, P773
   Shirmohammadi S, 2001, COMPUT NETW, V35, P351, DOI 10.1016/S1389-1286(00)00186-9
   SINGHAL S, 1999, SIGGRAPH SERIES
NR 19
TC 1
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 163
EP 180
DI 10.1007/s11042-010-0703-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000010
DA 2024-07-18
ER

PT J
AU Glowacz, A
   Grega, M
   Leszczuk, M
   Papir, Z
   Romaniak, P
   Fornalski, P
   Lutwin, M
   Enge, J
   Lurk, T
   Simko, V
AF Glowacz, Andrzej
   Grega, Michal
   Leszczuk, Mikolaj
   Papir, Zdzislaw
   Romaniak, Piotr
   Fornalski, Pawel
   Lutwin, Michal
   Enge, Juergen
   Lurk, Tabea
   Simko, Viliam
TI Open internet gateways to archives of media art
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Storage/repositories; Libraries/information repositories/publishing;
   Feature measurement; Intelligent web services and semantic web; Arts
ID RECOGNITION; EIGENFACES; SYSTEM
AB The EU-projects OASIS Archive and GAMA aimed to develop systems for the common presentation of distributed Media Art works, independent of their location. The paper presents the technical solutions implemented during projects, and contextualise the work in the related media art scene. In order to ensure the preservation and availability (sustainability) of cultural heritage, the metadata systems of all participating institutions were interlinked and they can now be accessed by individual users (both researchers and general public) through an on-line interface. The developed multimedia archive servers enable the exchange of metadata within a distributed system and enable various play-out sources and media. The decentralised architecture, where data can remain at their physical location and are linked at the metadata level, is the key concept of the presented system.
C1 [Glowacz, Andrzej; Grega, Michal; Leszczuk, Mikolaj; Papir, Zdzislaw; Romaniak, Piotr; Fornalski, Pawel; Lutwin, Michal] AGH Univ Sci & Technol, Dept Telecommun, PL-30059 Krakow, Poland.
   [Enge, Juergen; Lurk, Tabea] Karlsruhe Univ Arts & Design, D-76135 Karlsruhe, Germany.
   [Simko, Viliam] CIANT Int Ctr Art & New Technol, Prague 14300 4, Czech Republic.
C3 AGH University of Krakow
RP Glowacz, A (corresponding author), AGH Univ Sci & Technol, Dept Telecommun, Al Mickiewicza 30, PL-30059 Krakow, Poland.
EM aglowacz@agh.edu.pl; grega@kt.agh.edu.pl; leszczuk@kt.agh.edu.pl;
   papir@kt.agh.edu.pl; romaniak@kt.agh.edu.pl; pfornalski@pu.kielce.pl;
   lutwin@pu.kielce.pl; juergen@hfg-karlsruhe.de; tabea@info-age.net;
   viliam.simko@matfyz.cz
RI Romaniak, Piotr/C-7763-2011; Glowacz, Andrzej/H-6728-2012; Leszczuk,
   Mikołaj I/C-4857-2011; Grega, Michal/C-3704-2011
OI Leszczuk, Mikołaj I/0000-0001-9123-1039; Grega,
   Michal/0000-0001-7633-8663
FU EC Culture 2000 programme; EC eContentplus programme
FX The authors would like to acknowledge the EC Culture 2000 programme for
   funding the OASIS Archive project as well as the EC eContentplus
   programme for funding the GAMA project.
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bolme DS, 2003, LECT NOTES COMPUT SC, V2626, P304
   *DCMI, 2006, DUBL COR MET EL SET
   Enge Jurgen, ARCHITECTURE ARCH
   Heydegger Volker, ARCH 2008 FINAL PROG, P50
   Knuth D. E., 1973, ART COMPUTER PROGRAM, V3, P391
   Lee KH, 2002, J RES NATL INST STAN, V107, P93, DOI 10.6028/jres.107.010
   MPEG, 2002, 1593832002 ISOIEC JT
   Paal Stefan, 2001, CAST 01 LIVING MIXED, P121
   PAYETTE S, 1998, FEDORA FLEXIBLE EXTE
   Staples T., 2003, D LIB MAGAZINE, V9
   Tansley R, 2005, LECT NOTES COMPUT SC, V3652, P242, DOI 10.1007/11551362_22
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   van der Meulen E, 2007, INTERLEND DOC SUPPLY, V35, P154, DOI 10.1108/02641610710780827
NR 14
TC 0
Z9 0
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 897
EP 920
DI 10.1007/s11042-011-0784-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900008
DA 2024-07-18
ER

PT J
AU Yang, R
   van der Mei, RD
   Roubos, D
   Seinstra, FJ
   Bal, HE
AF Yang, Ran
   van der Mei, Robert D.
   Roubos, Dennis
   Seinstra, Frank J.
   Bal, Henri E.
TI Resource optimization in distributed real-time multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia content analysis; Distributed computing; Resource
   optimization
AB The research area of multimedia content analysis (MMCA) considers all aspects of the automated extraction of knowledge from multimedia archives and data streams. To adhere to strict time constraints, large-scale multimedia applications typically are being executed on distributed systems consisting of large collections of compute clusters. In a distributed scenario, it is first essential to determine the optimal number of compute nodes used by each cluster, properly balancing the complex tradeoff between computation and communication. This issue is referred as the "resource utilization" (RU) problem. Next, it is important to tune the transmission of newly generated data sent to each cluster, so as to obtain the highest service utilization, while minimizing the need for buffering. This latter issue is referred as the problem of "just-in-time" (JIT) communication. In this paper, we first present a simple and easy-to-implement method for the RU problem, which is based on the classical binary search method. Second, we address the JIT problem by introducing a smart adaptive control method that properly reacts to the continuously changing circumstances in distributed systems. Extensive experimental validation of the two approaches on a real distributed system shows that our optimization approaches are indeed highly effective.
C1 [Yang, Ran; van der Mei, Robert D.; Roubos, Dennis] Vrije Univ Amsterdam, Fac Sci, Dept Math, NL-1081 HV Amsterdam, Netherlands.
   [Yang, Ran; van der Mei, Robert D.] Ctr Math & Comp Sci, NL-1098 XG Amsterdam, Netherlands.
   [Seinstra, Frank J.; Bal, Henri E.] Vrije Univ Amsterdam, Dept Comp Sci, Fac Sci, NL-1081 HV Amsterdam, Netherlands.
C3 Vrije Universiteit Amsterdam; Vrije Universiteit Amsterdam
RP Yang, R (corresponding author), Vrije Univ Amsterdam, Fac Sci, Dept Math, De Boelelaan 1081A, NL-1081 HV Amsterdam, Netherlands.
EM ryang@few.vu.nl; mei@few.vu.nl; droubos@few.vu.nl; fjseins@cs.vu.nl;
   bal@cs.vu.nl
OI Bal, H.E./0000-0001-9827-4461
FU Netherlands Organisation for Scientific Research (NWO), GLANCE
   [643.000.602]
FX This work is supported by the Netherlands Organisation for Scientific
   Research (NWO), GLANCE project 643.000.602: "JADE-MM: Adaptive
   High-Performance Multimedia Computing".
CR [Anonymous], 1998, The art of computer programming: Sorting and searching
   [Anonymous], 2006, SPRINGER TEXTS STAT
   [Anonymous], 1991, The Art of Computer Systems Performance Analysis: Techniques for Experimental Design, Measurement, Simulation, and Modeling
   Berman F, 2003, IEEE T PARALL DISTR, V14, P369, DOI 10.1109/TPDS.2003.1195409
   Brown R.G., 1963, Smoothing, Forecasting and Prediction of Discrete Time Series
   Brown R.G., 1959, Statistical forecasting for inventory control
   Cascaval C., 2000, Languages and Compilers for Parallel Computing. 12th International Workshop, LCPC'99. Proceedings (Lecture Notes in Computer Science Vol.1863), P365
   CURNOW HJ, 1976, COMPUT J, V19, P43, DOI 10.1093/comjnl/19.1.43
   Dobber M, 2007, PERFORM EVALUATION, V64, P755, DOI 10.1016/j.peva.2007.01.001
   DONGARRA J, 1987, IEEE SPECTRUM, V24, P38, DOI 10.1109/MSPEC.1987.6448963
   FARMER JD, 1987, PHYS REV LETT, V59, P845, DOI 10.1103/PhysRevLett.59.845
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Guim Francesc, 2006, P 7 IEEE ACM INT C G
   HarcholBalter M, 1997, ACM T COMPUT SYST, V15, P253, DOI 10.1145/263326.263344
   HAUPTMANN AG, 2003, P TRECVID
   Holt C.E., 1957, ONR Memorandum, V52
   Kushner Harold J.., 2003, Stochastic Approximation and Recursive Algorithms and Applications, V35
   Lee JW, 2006, PROCEEDINGS OF THE 12TH IEEE REAL-TIME AND EMBEDDED TECHNOLOGY AND APPLICATIONS SYMPOSIUM, P135
   Maggs B. M., 1995, Proceedings of the Twenty-Eighth Hawaii International Conference on System Sciences, P61, DOI 10.1109/HICSS.1995.375476
   Moore MS, 1997, P SOC PHOTO-OPT INS, V3166, P31, DOI 10.1117/12.279633
   SAAVEDRABARRERA RH, 1989, IEEE T COMPUT, V38, P1659, DOI 10.1109/12.40845
   Schutte K, 1997, SIGNAL PROCESS, V59, P113, DOI 10.1016/S0165-1684(97)00041-8
   SEINSTRA F, 2005, P INT PAR DISTR PROC
   Seinstra FJ, 2002, PARALLEL COMPUT, V28, P967, DOI 10.1016/S0167-8191(02)00103-5
   Seinstra FJ, 2007, IEEE MULTIMEDIA, V14, P64, DOI 10.1109/MMUL.2007.74
   Smith W, 2004, J PARALLEL DISTR COM, V64, P1007, DOI 10.1016/j.jpdc.2004.06.008
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   Veeravalli B, 2006, MULTIMED TOOLS APPL, V28, P89, DOI 10.1007/s11042-006-5116-7
   WEICKER RP, 1984, COMMUN ACM, V27, P1013, DOI 10.1145/358274.358283
   WINTERS PR, 1960, MANAGE SCI, V6, P324, DOI 10.1287/mnsc.6.3.324
   Wolski R, 1997, SIXTH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, PROCEEDINGS, P316, DOI 10.1109/HPDC.1997.626437
   Wolski R, 1999, FUTURE GENER COMP SY, V15, P757, DOI 10.1016/S0167-739X(99)00025-4
   Xu ZC, 1996, J PARALLEL DISTR COM, V39, P14, DOI 10.1006/jpdc.1996.0151
   Zhang Y, 2008, FUTURE GENER COMP SY, V24, P489, DOI 10.1016/j.future.2007.07.003
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 48
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2012
VL 59
IS 3
BP 941
EP 971
DI 10.1007/s11042-011-0782-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 950AF
UT WOS:000304619900010
OA hybrid
DA 2024-07-18
ER

PT J
AU Fiems, D
   Steyaert, B
   Bruneel, H
AF Fiems, Dieter
   Steyaert, Bart
   Bruneel, Herwig
TI A genetic approach to Markovian characterisation of H.264 scalable video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/SVC; Traffic characterisation; Markovian arrival process
ID ATM NETWORKS; TRAFFIC CHARACTERIZATION; VBR VIDEO; MPEG-4; TUTORIAL;
   MODELS
AB We propose an algorithm for multivariate Markovian characterisation of H.264/SVC scalable video traces at the sub-GoP (Group of Pictures) level. A genetic algorithm yields Markov models with limited state space that accurately capture temporal and inter-layer correlation. Key to our approach is the covariance-based fitness function. In comparison with the classical Expectation Maximisation algorithm, ours is capable of matching the second order statistics more accurately at the cost of less accuracy in matching the histograms of the trace. Moreover, a simulation study shows that our approach outperforms Expectation Maximisation in predicting performance of video streaming in various networking scenarios.
C1 [Fiems, Dieter; Steyaert, Bart; Bruneel, Herwig] Univ Ghent, Dept Telecommun & Informat Proc, SMACS Res Grp, B-9000 Ghent, Belgium.
C3 Ghent University
RP Fiems, D (corresponding author), Univ Ghent, Dept Telecommun & Informat Proc, SMACS Res Grp, St Pietersniewstr 41, B-9000 Ghent, Belgium.
EM df@telin.UGent.be; bs@telin.UGent.be; hb@telin.UGent.be
RI Fiems, Dieter/J-4442-2013
FU Flemish Institute for the Promotion of Scientific and Technological
   Research in the Industry (IWT)
FX This work has been carried out in the framework of the Q-MATCH project
   sponsored by the Flemish Institute for the Promotion of Scientific and
   Technological Research in the Industry (IWT). The first author is a
   Postdoctoral Fellow with the Research Foundation, Flanders
   (F.W.O.-Vlaanderen), Belgium. A preliminary version of this paper was
   presented at the 15th International Conference on Analytical and
   Stochastic Modelling Techniques and Applications, Nicosia, Cyprus, 3-6
   June 2008.
CR Alheraish AA, 2004, COMPUT COMMUN, V27, P81, DOI 10.1016/j.comcom.2003.08.002
   [Anonymous], 1999, SERIES STAT APPL PRO
   [Anonymous], 1996, INTRO GENETIC ALGORI
   Ansari N, 2002, IEEE T BROADCAST, V48, P337, DOI 10.1109/TBC.2002.806794
   Baey S, 2004, P SPECTS 2004
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   BLONDIA C, 1992, PERFORM EVALUATION, V16, P5, DOI 10.1016/0166-5316(92)90064-N
   Conti M, 1996, IEEE J SEL AREA COMM, V14, P1455, DOI 10.1109/49.536491
   Conti M, 2001, MULTIMED TOOLS APPL, V13, P127, DOI 10.1023/A:1009633409397
   DEMPSTER AP, 1976, J ROY STAT SOC B MET, V39, P1
   Hasslinger G, 1997, TELECOMMUN SYST, V7, P281, DOI 10.1023/A:1019180514145
   Huang XD, 2004, IEEE T BROADCAST, V50, P323, DOI 10.1109/TBC.2004.834013
   Izquierdo MR, 1999, MULTIMEDIA SYST, V7, P199, DOI 10.1007/s005300050122
   Kempken S, 2007, LECT NOTES COMPUTER
   Kim HS, 2001, IEEE ACM T NETWORK, V9, P755, DOI 10.1109/90.974529
   Koza JR, 1995, P WESC 1995
   Lazaris A, 2006, LECT NOTES COMPUT SC, V4003, P46
   Liebeherr J, 1998, MULTIMEDIA SYST, V6, P271, DOI 10.1007/s005300050093
   Liew CH, 2005, IEE P-COMMUN, V152, P749, DOI 10.1049/ip-com:20045014
   LIPORACE LA, 1982, IEEE T INFORM THEORY, V28, P729, DOI 10.1109/TIT.1982.1056544
   Lombardo A, 1998, IEEE INFOCOM SER, P217, DOI 10.1109/INFCOM.1998.659657
   Macfadyen NW, 2002, BT TECHNOL J, V20, P14, DOI 10.1023/A:1020843525812
   MOLTCHANOV D, 2003, P ICACT 2003, P57
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Radha H, 1999, SIGNAL PROCESS-IMAGE, V15, P95, DOI 10.1016/S0923-5965(99)00026-0
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Seeling P, 2004, IEEE COMMUN SURV TUT, V6, P58, DOI 10.1109/COMST.2004.5342293
   Sen P. K., 1996, WILEY SERIES PROBABI
   Sivanandam S., 2008, INTRO GENETIC ALGORI, P15
   Welch LR, 2003, IEEE INF THEORY SOC, V53, p[1, 10]
   Won Y, 2005, MULTIMEDIA SYST, V10, P359, DOI 10.1007/s00530-005-0166-7
   Zhang QT, 1999, IEEE T CIRC SYST VID, V9, P1130, DOI 10.1109/76.795063
   Zhao J, 2003, PACKET VIDEO 2003
NR 33
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 125
EP 146
DI 10.1007/s11042-010-0713-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600006
OA Green Published
DA 2024-07-18
ER

PT J
AU Scherp, A
   Franz, T
   Saathoff, C
   Staab, S
AF Scherp, Ansgar
   Franz, Thomas
   Saathoff, Carsten
   Staab, Steffen
TI A core ontology on events for representing occurrences in the real world
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Events; Models; Principles; Pattern-oriented ontology design; Core
   ontologies
ID WEB
AB Events are central aspect of many semantic ambient media applications such as surveillance, smart homes, automobiles, and others. Existing models for events typically do not follow a systematic development approach, are conceptually narrow with respect to event features, and their semantics is often ambiguous. This makes the communication between and integration of different event-based components and event-based semantic ambient media applications a challenging task. In this paper, we present the Event-Model-F, a formal model of events based on the foundational ontology DOLCE+DnS Ultralite (DUL). The Event-Model-F provides comprehensive support to represent time and space, objects and persons, mereological, causal, and correlative relationships between events, and different interpretations of the same event. It is developed following a pattern-oriented ontology design approach and can be easily extended by domain specific ontologies. We introduce the design and implementation of an application programming interface that allows for easy integration of the Event-Model-F in arbitrary applications. The use of the Event-Model-F is demonstrated at the example of a socio-technical system of emergency response and implemented in the SemaPlorer++ application for creating and sharing event descriptions.
C1 [Scherp, Ansgar; Franz, Thomas; Saathoff, Carsten; Staab, Steffen] Univ Koblenz Landau, D-56070 Koblenz, Germany.
C3 University of Koblenz & Landau
RP Scherp, A (corresponding author), Univ Koblenz Landau, Univ Str 1, D-56070 Koblenz, Germany.
EM scherp@uni-koblenz.de; franz@uni-koblenz.de; saathoff@uni-koblenz.de;
   staab@uni-koblenz.de
RI Scherp, Ansgar/Q-2315-2016
OI Scherp, Ansgar/0000-0002-2653-9245
FU EU [026978, 215453]
FX This research has been co-funded by the EU in FP6 in the X-Media project
   (026978) and FP7 in the WeKnowIt project (215453). We kindly thank Peter
   Whitwam and Keith Bradley from the Emergency Planning Team of the City
   Council of Sheffield, UK for the discussions on emergency planning and
   emergency response and the requirements and feedback on the SemaPlorer++
   application. We thank our student Daniel Schmeiss for his support in
   implementing the Event-Model-F API and SemaPlorer++ application.
CR [Anonymous], DISTRIBUTION ELEMENT
   [Anonymous], 2003, WONDERWEB DELIVERABL
   [Anonymous], WORLD WID WEB C BEIJ
   [Anonymous], 2009, 5 INT C KNOWLEDGE CA, DOI DOI 10.1145/1597735.1597760
   [Anonymous], USH CROWDS CRIS INF
   [Anonymous], 2003, P WORKSH ONT AG SYST
   [Anonymous], 911 GOV NAT 911 OFF
   [Anonymous], 911 GOV COMM RESP GR
   [Anonymous], 2002, CAUSE CORRELATION BI, DOI DOI 10.1017/CBO9780511605949
   [Anonymous], SOUPA ONTOLOGY PERVA
   [Anonymous], SEMANTIC WEB ANNOTAT
   [Anonymous], DISTRIBUTED EVENT BA
   [Anonymous], EVENTS
   [Anonymous], SPIE
   [Anonymous], INT SEM WEB C SPRING
   [Anonymous], SEMANTIC AMBIENT MED
   [Anonymous], D5 2 1 PROTOTYPICAL
   [Anonymous], KNOWLEDGE INTENSIVE
   [Anonymous], COMPLEX EVENT PROCES
   [Anonymous], COMMUNITY RESPONSE G
   [Anonymous], D2 1 2 INTELLIGENT M
   [Anonymous], AIMS ATL INC MAN SYS
   [Anonymous], SAH HOM FREE OP SOUR
   [Anonymous], EUR C ART INT WIL NE
   [Anonymous], NAT PLAN MIGR IP ENA
   [Anonymous], 2009, HDB ONTOLOGIES
   [Anonymous], CAUSALITY LINGUISTIC
   [Anonymous], EM COMM SYST
   [Anonymous], SAMT DEMO POSTER SES
   [Anonymous], COMPUT INTELL
   [Anonymous], EVENTML
   [Anonymous], 2006, J APPL ONTOLOGY
   Auer S, 2009, LECT NOTES COMPUT SC, V5823, P731, DOI 10.1007/978-3-642-04930-9_46
   Baader F., 2003, DESCRIPTION LOGIC HD
   Baumgartner N, 2006, PROCEEDINGS OF THE FOURTH IASTED INTERNATIONAL CONFERENCE ON KNOWLEDGE SHARING AND COLLABORATIVE ENGINEERING, P1
   Baumgartner N, 2008, APPLIED COMPUTING 2008, VOLS 1-3, P2326
   Bizer C, 2009, J WEB SEMANT, V7, P154, DOI 10.1016/j.websem.2009.07.002
   Broda K, 2009, LECT NOTES COMPUT SC, V5859, P112, DOI 10.1007/978-3-642-05408-2_14
   Doerr M., 2007, ER 07, P51, DOI DOI 10.13140/2.1.1420.6400
   Ekin A, 2004, IEEE T MULTIMEDIA, V6, P839, DOI 10.1109/TMM.2004.837238
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Franz T, 2007, K-CAP'07: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P143
   Gangemi A, 2003, LECT NOTES COMPUT SC, V2888, P689
   Gangemi A, 2002, LECT NOTES ARTIF INT, V2473, P166
   Gangemi A, 2008, AUTON AGENT MULTI-AG, V17, P70, DOI 10.1007/s10458-008-9038-9
   Kokar MM, 2009, INFORM FUSION, V10, P83, DOI 10.1016/j.inffus.2007.01.004
   Lin FZ, 2008, FOUND ARTIF INTELL, P649, DOI 10.1016/S1574-6526(07)03016-7
   Lin FZ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P670
   Lombard L.B., 1986, Events: A metaphysical study
   Matheus CJ, 2005, LECT NOTES COMPUT SC, V3791, P130, DOI 10.1007/11580072_11
   Matheus CJ, 2005, LECT NOTES COMPUT SC, V3729, P944, DOI 10.1007/11574620_67
   Matheus CJ, 2005, PROC SPIE, V5813, P75, DOI 10.1117/12.604120
   Matheus CJ, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P545
   Mueller ET, 2008, FOUND ARTIF INTELL, P671, DOI 10.1016/S1574-6526(07)03017-9
   Muhl G, 2006, Distributed Event-Based Systems
   Nevatia R., 2004, Computer Vision and Pattern Recognition Workshop, P119
   Oberle D., 2006, Semantic management of Middleware, V1
   Oberle D, 2007, J WEB SEMANT, V5, P156, DOI 10.1016/j.websem.2007.06.002
   Patel-Schneider P.F., 2004, OWL Web Ontology Lan-guage semantics and abstract syntax
   Pease A., 2002, Ontologies and the semantic web
   QUINTON A, 1979, MIND, V88, P197
   Raimond Yves, 2007, The Event Ontology
   Saathoff C, 2010, P 19 INT C WORLD WID, P831, DOI [10.1145/1772690.1772775, DOI 10.1145/1772690.1772775]
   Schenk S, 2009, J WEB SEMANT, V7, P298, DOI 10.1016/j.websem.2009.09.006
   Storf H, 2009, LECT NOTES COMPUT SC, V5859, P123, DOI 10.1007/978-3-642-05408-2_16
   Strang T., 2004, Advanced context modelling, reasoning and management
   Wang XH, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P18
   Wang XJ, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P95, DOI 10.1109/ICSC.2007.70
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
NR 70
TC 21
Z9 24
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 293
EP 331
DI 10.1007/s11042-010-0667-z
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500002
DA 2024-07-18
ER

PT J
AU Fu, ZY
   Lu, HT
   Li, WB
AF Fu, Zhenyong
   Lu, Hongtao
   Li, Wenbin
TI Incremental visual objects clustering with the growing vocabulary tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual clustering; Bag-of-words; Incremental pLSA
AB With the bag-of-visual-words image representation, we can use the text analysis methods, such as pLSA and LDA, to solve the visual objects clustering and classification problems. However the previous works only used a fixed visual vocabulary, which is formed by vector quantizing SIFT like region descriptors, and so the learned visual topic models are also only based on the fixed vocabulary. This paper presents a novel approach to cluster visual objects in an incremental manner. Given a new batch of images, we firstly expand the visual vocabulary to include the new visual words, and then adjust the objects clustering model to absorb these new words, and finally give the clustering result. We achieve our goal by adapting to the visual domain of the incremental pLSA model previously used for text analysis. Experimental results demonstrate the feasibility and stability of the growing vocabulary tree and the clustering performance using the images from seven categories in a dynamic environment.
C1 [Fu, Zhenyong; Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
   [Li, Wenbin] Shanghai Jiao Tong Univ, Dept Diagnost & Intervent Radiol, Affiliated Peoples Hosp 6, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Fu, ZY (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200030, Peoples R China.
EM zhyfu@sjtu.edu.cn; lu-ht@cs.sjtu.edu.cn; liwenbin@sh163.net
FU National High Technology Research and Development Program of China
   [2008AA02Z310]; Shanghai Committee of Science and Technology
   [08411951200, 08JG05002]; NLPR [09-4-1];  [973 (2009CB320901)]
FX This work was supported by the National High Technology Research and
   Development Program of China (No. 2008AA02Z310), Shanghai Committee of
   Science and Technology (No. 08411951200, No. 08JG05002), 973
   (2009CB320901) and NLPR (09-4-1).
CR [Anonymous], P SIGIR
   [Anonymous], 2005, P ICCV
   [Anonymous], 2006, IEEE COMP SOC C COMP
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], 2005, P CVPR
   [Anonymous], ACM MULT
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chakrabarti D, 2006, P ACM SIGKDD
   Chou TC, 2008, IEEE T KNOWL DATA EN, V20, P289, DOI 10.1109/TKDE.2007.190702
   Gao B, 2005, ACM MULT
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   LI L.-J., 2007, P CVPR
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moosmann F, 2008, IEEE T PATTERN ANAL, V30, P1632, DOI 10.1109/TPAMI.2007.70822
   Reddy K., 2009, ICCV
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Slobodan I, 2008, ICPR
   Yeh T, 2007, P ICCV
   Yeh T., 2008, CVPR
   Zheng X, 2004, ACM MULT
NR 24
TC 2
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 535
EP 552
DI 10.1007/s11042-010-0616-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700007
DA 2024-07-18
ER

PT J
AU Lee, Y
   Kim, J
   Hong, S
AF Lee, Yuseop
   Kim, Jongsung
   Hong, Seokhie
TI Side-channel attacks on HIGHT with reduced masked rounds suitable for
   the protection of multimedia computing system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Side-channel attacks; HIGHT; Impossible collision
ID CRYPTANALYSIS
AB At CHES 2007, Biryukov and Knovratovich introduced a concept of side-channel attacks based on impossible collisions, and applied it to AES with reduced masked rounds. In this paper, we propose side-channel attacks on HIGHT (HIGh security and light weigHT) with the first 11, 12, 13 reduced masked rounds using impossible collision. Our best attacks on HIGHT with the first 11, 12 and 13 reduced masked rounds need 2(17), 2(32) and 2(40) chosen plaintexts and 2(23.6), 2(56.6) and 2(80.6) curve comparisons, respectively. They are the first known side-channel attacks on HIGHT with reduced masked rounds.
C1 [Lee, Yuseop; Hong, Seokhie] Korea Univ, Grad Sch Informat Management, Seoul 136075, South Korea.
   [Lee, Yuseop; Kim, Jongsung; Hong, Seokhie] Korea Univ, CIST, Seoul 136075, South Korea.
   [Kim, Jongsung] Kyungnam Univ, Dept E Business, Chang Won, South Korea.
C3 Korea University; Korea University; Kyungnam University
RP Kim, J (corresponding author), 449 Woryeong Dong, Masan 631701, Gyeongnam, South Korea.
EM yusubi@cist.korea.ac.kr; jongsungk@kyungnam.ac.kr; hsh@cist.korea.ac.kr
FU Kyungnam University Foundation
FX This work is supported by Kyungnam University Foundation Grant, 2010.
CR Akkar ML, 2004, LECT NOTES COMPUT SC, V3017, P332
   Akkar ML, 2003, LECT NOTES COMPUT SC, V2887, P192
   Biham E, 2003, LECT NOTES COMPUT SC, V2887, P9
   Biham E, 2001, LECT NOTES COMPUT SC, V2045, P340
   Biham E., 1990, J CRYPTOL, V4, P3
   Biryukov A, 2007, LECT NOTES COMPUT SC, V4727, P195
   Courtois NT, 2006, LECT NOTES COMPUT SC, V3935, P199
   Handschuh H, 2007, LECT NOTES COMPUT SC, V4356, P163
   Hong D, 2006, LECT NOTES COMPUT SC, V4249, P46, DOI 10.1007/11894063_4
   Knudsen L. R., 1995, Fast Software Encryption. Second International Workshop. Proceedings, P196
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kocher PC, 1993, CRYPTO 1996, P104
   Matsui M., 1994, Advances in Cryptology - EUROCRYPT '93. Workshop on the Theory and Application of Cryptographic Techniques Proceedings, P386, DOI 10.1007/3-540-48285-7_33
NR 13
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 267
EP 280
DI 10.1007/s11042-010-0590-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100003
DA 2024-07-18
ER

PT J
AU Ciobanu, L
   Côrte-Real, L
AF Ciobanu, Lucian
   Corte-Real, Luis
TI Iterative filtering of SIFT keypoint matches for multi-view registration
   in Distributed Video Coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view registration (MVR); Side information; Distributed Video
   Coding (DVC); Scale-invariant feature transform (SIFT); Hough transform;
   Block matching (BM); Mean Squared Error (MSE)
AB Multi-view registration is an essential step in order to generate the side information for multi-view Distributed Video Coding. As stated in our previous work (Ciobanu and Crte-Real, Multimed Tools Appl 48(3):411-436, 2010) it can be achieved by SIFT (scale-invariant feature transform) generated keypoint matches. The registration accuracy is vital for the adequate generation of side information and it directly depends on the reliable match of possibly all the available point to point correlations between two complete-overlapped views. We propose a solution to this problem based on iterative filtering of SIFT-generated keypoint matches, using the Hough transform and block matching. It aims the generic, real-life and constraint-free scenarios having an arbitrarily close angle between the two views. Practical results show an overall significant reduction of the outliers while maintaining a high rate of correct matches.
C1 [Ciobanu, Lucian; Corte-Real, Luis] Univ Porto, INESC Porto, Fac Engn, P-4100 Oporto, Portugal.
C3 Universidade do Porto; INESC TEC
RP Ciobanu, L (corresponding author), Univ Porto, INESC Porto, Fac Engn, Rua Campo Alegre 823, P-4100 Oporto, Portugal.
EM lciobanu@inescporto.pt; lreal@inescporto.pt
RI Corte-Real, Luís/I-4852-2012
OI Ciobanu, Lucian/0000-0003-1102-8589; Corte-Real,
   Luis/0000-0003-2116-7056
FU Fundacao para a Ciencia e a Tecnologia, Portugal
FX The first author acknowledges the Fundacao para a Ciencia e a
   Tecnologia, Portugal, for the financial support.
CR Benedek C, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P439
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   BROWN M, 2003, P IEEE INT C COMP VI
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Ciobanu L, 2010, MULTIMED TOOLS APPL, V48, P411, DOI 10.1007/s11042-009-0315-7
   FIALA M, 2006, IEEE INT WORKSH HAPT, P118
   FORSSEN PE, 2007, INT C COMP VIS ICCV
   Gao K, 2008, 7TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE IN CONJUNCTION WITH 2ND IEEE/ACIS INTERNATIONAL WORKSHOP ON E-ACTIVITY, PROCEEDINGS, P191, DOI 10.1109/ICIS.2008.24
   GARCIA FL, 2008, ICPR08, P1
   Gordon I, 2006, LECT NOTES COMPUT SC, V4170, P67
   Izquierdo E, 2003, IEEE T MULTIMEDIA, V5, P293, DOI 10.1109/TMM.2003.814910
   Ke Y, 2004, PROC CVPR IEEE, P506
   LEDWICH L, 2004, AUSTR C ROB AUT
   Li Y, 2008, INTENS CARE MED, V34, P568, DOI 10.1007/s00134-007-0921-7
   LOUI A, 2008, MATCHING COMPLEX SCE
   LOWE D, SCALE INVARIANT FEAT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J, 2007, INT CONF ACOUST SPEE, P593
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Osada K, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P245, DOI 10.1109/SMI.2008.4547989
   PARK U, 2008, SPIE, V6944
   Shuai X., 2008, Proc. 19th ICPR, P1
   Szlávik Z, 2007, ISPRS J PHOTOGRAMM, V61, P298, DOI 10.1016/j.isprsjprs.2006.09.014
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 25
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2011
VL 55
IS 3
BP 557
EP 578
DI 10.1007/s11042-010-0565-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 815CV
UT WOS:000294504600009
DA 2024-07-18
ER

PT J
AU Xuan, KF
   Zhao, G
   Taniar, D
   Safar, M
   Srinivasan, B
AF Xuan, Kefeng
   Zhao, Geng
   Taniar, David
   Safar, Maytham
   Srinivasan, Bala
TI Voronoi-based multi-level range search in mobile navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Conference on Advances in Mobile Computing and Multimedia
CY NOV 24-26, 2008
CL Linz, AUSTRIA
SP ACM SIGMM
DE Mobile databases; Voronoi diagram; Range queries; Mobile navigation
ID QUERIES
AB Due to the universality and importance of range search queries processing in mobile and spatial databases as well as in geographic information system (GIS), numerous approaches on range search algorithms have been proposed in recent years. But ordinary range search queries focus only on a specific type of point objects. For queries which require to retrieve objects of interest locating in a particular region, ordinary range search could not get the expected results. In addition, most existing range search methods need to perform a searching on each road segments within the pre-defined range, which decreases the performance of range search. In this paper, we design a weighted network Voronoi diagram and propose a high-performance multilevel range search query processing that retrieves a set of objects locating in some specified region within the searching range. The experimental results show that our proposed algorithm runs very efficiently and outperforms its main competitor.
C1 [Xuan, Kefeng; Zhao, Geng; Taniar, David; Srinivasan, Bala] Monash Univ, Clayton Sch Informat Technol, Melbourne, Vic 3004, Australia.
   [Safar, Maytham] Kuwait Univ, Dept Comp Engn, Kuwait, Kuwait.
C3 Monash University; Kuwait University
RP Xuan, KF (corresponding author), Monash Univ, Clayton Sch Informat Technol, Melbourne, Vic 3004, Australia.
EM Kefeng.Xuan@infotech.monash.edu.au; Geng.Zhao@infotech.monash.edu.au;
   David.Taniar@infotech.monash.edu.au; Maytham.Safar@ku.edu.kw;
   Bala.Srinivasan@infotech.monash.edu.au
RI Safar, Maytham H/E-9238-2010
OI Taniar, David/0000-0002-8862-3960; Safar, Maytham/0000-0002-0007-3141
CR Aleksy M, 2008, MOB INF SYST, V4, P105, DOI 10.1155/2008/142986
   [Anonymous], 2003, PROC VLDB C
   ASH PF, 2004, GEOMETRIAE DEDICATA, V20, P209
   Bayer R, 1997, LECT NOTES COMPUT SC, V1274, P198
   BECKLEY D, 1985, P INT C ACM SIGMOD, P291
   Cantone D, 2005, IEEE T KNOWL DATA EN, V17, P535, DOI 10.1109/TKDE.2005.53
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   GOH J, 2004, P 8 KNOWL BAS INT IN, P795
   Goh J, 2005, INT J BUS DATA COMMU, V1, P50, DOI 10.4018/jbdcn.2005010104
   Goh JY, 2004, LECT NOTES COMPUT SC, V3177, P225
   Gulliver SR, 2007, MOB INF SYST, V3, P71, DOI 10.1155/2007/975892
   Guttman A., 1984, ACM SIGMOD INT C MAN, P47, DOI DOI 10.1145/602259.602266
   Jayaputera J, 2005, MOB INF SYST, V1, P91, DOI 10.1155/2005/917236
   Kolahdouzan MR, 2005, GEOINFORMATICA, V9, P321, DOI 10.1007/s10707-005-4575-8
   MUHAMMAD RB, 2009, MOB INF SYST, V5, P53
   Okabe A., 2000, Spatial tessellations: concepts and applications of Voronoi diagrams, V43
   Safar M, 2005, MOB INF SYST, V1, P207, DOI 10.1155/2005/692568
   Safar M, 2006, INT J INF TECHNOL WE, V1, P1, DOI 10.4018/jitwe.2006100101
   Shahabi, 2004, VLDB, V30, P840, DOI DOI 10.1016/B978-012088469-8.50074-7
   Sharifzadeh M, 2008, GEOINFORMATICA, V12, P411, DOI 10.1007/s10707-007-0034-z
   Taniar D, 2004, INFORM SCIENCES, V165, P103, DOI 10.1016/j.ins.2003.09.019
   Taniar D, 2002, DISTRIB PARALLEL DAT, V12, P73, DOI 10.1023/A:1015682215394
   Taniar D, 2007, INT J DISTRIB SENS N, V3, P69, DOI 10.1080/15501320601069499
   Tran Quoc Thai, 2009, LARGE SCALE T DATA K, V1, P353
   Waluyo AB, 2005, COMPUT SYST SCI ENG, V20, P79
   Waluyo AB, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1 (LONG PAPERS), PROCEEDINGS, P213
   Waluyo AB, 2003, LECT NOTES COMPUT SC, V2834, P655
   Waluyo AB, 2009, J NETW COMPUT APPL, V32, P434, DOI 10.1016/j.jnca.2008.02.014
   Xuan KF, 2009, INT J GRID UTIL COMP, V1, P328, DOI 10.1504/IJGUC.2009.027922
   Xuan KF, 2009, INT CON ADV INFO NET, P741, DOI 10.1109/AINA.2009.82
NR 30
TC 37
Z9 40
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2011
VL 53
IS 2
BP 459
EP 479
DI 10.1007/s11042-010-0498-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 753BS
UT WOS:000289739800006
DA 2024-07-18
ER

PT J
AU Hsu, TH
   Lee, CH
   Chen, LH
AF Hsu, Tzu-Hsiang
   Lee, Chang-Hsing
   Chen, Ling-Hwei
TI An interactive flower image recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flower image recognition; Image segmentation
AB In this paper, we present an interactive system for recognizing flower images taken by digital cameras. The proposed system provides an interactive interface allowing each user to draw an appropriate bounding window that contains the interested flower region. Then, a flower boundary tracing method is developed to extract the flower region as accurately as possible. In addition to the color and shape features of the whole flower region, the color and shape features of the pistil/stamen area will also be used to represent the flower characteristics more precisely. Experiments conducted on two distinct databases consisting of 24 species and 102 species have shown that our proposed system outperforms other approaches in terms of the recognition rate.
C1 [Hsu, Tzu-Hsiang; Chen, Ling-Hwei] Natl Chiao Tung Univ, Inst Multimedia & Engn, Hsinchu 300, Taiwan.
   [Lee, Chang-Hsing] Chung Hua Univ, Dept Comp Sci & Informat Engn, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University; Chung Hua University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Inst Multimedia & Engn, 1001 Univ Rd, Hsinchu 300, Taiwan.
EM lhchen@cc.nctu.edu.tw
OI Lee, Chang-Hsing/0000-0002-5761-421X
FU National Science Council of R.O.C. [NSC-97-2221-E-009-137]
FX This research was supported in part by the National Science Council of
   R.O.C. under contract NSC-97-2221-E-009-137.
CR [Anonymous], 2008, P INT WORKSH NONL CI
   [Anonymous], 1995, SIGGRAPH
   Boykov Y., 2001, International Conference on Computer Vision, V1, P105, DOI DOI 10.1109/ICCV.2001.937505
   Cho SY, 2005, IEEE T KNOWL DATA EN, V17, P216, DOI 10.1109/TKDE.2005.28
   Das M, 1999, IEEE INTELL SYST APP, V14, P24, DOI 10.1109/5254.796084
   Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hong An-Xiang, 2004, J Zhejiang Univ Sci, V5, P764, DOI 10.1631/jzus.2004.0764
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Saitoh T, 2004, INT C PATT RECOG, P27, DOI 10.1109/ICPR.2004.1333997
   Saitoh T, 2000, INT C PATT RECOG, P507, DOI 10.1109/ICPR.2000.906123
   SAITOH T, 2003, P SCAND C IM AN, P1130
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Zou J, 2004, INT C PATT RECOG, P311, DOI 10.1109/ICPR.2004.1334185
NR 16
TC 29
Z9 35
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 53
EP 73
DI 10.1007/s11042-010-0490-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700003
DA 2024-07-18
ER

PT J
AU Leu, JS
   Hsieh, HC
   Chen, YC
AF Leu, Jenq-Shiou
   Hsieh, Hui-Ching
   Chen, Yen-Chiu
TI Inexpensive high availability solutions for the SIP-based VoIP service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice over IP; SIP; P2P; High availability; Domain name relay daemon
AB In the era of IP-based service, people expect a simple, cheap, and competent Voice over IP (VoIP) service as an alternative of the traditional voice over PSTN. The introduction of the SIP protocol realizes the expectation. Following the cost saving spirit of VoIP, we focus on studying inexpensive high availability solutions for the SIP-based VoIP Service. In this paper, Peer-to-Peer (P2P) based and DN-LB based schemes are mainly compared in the paper. A P2P-based scheme enables an inexpensive high availability solution to the VoIP service by the shared computation resources form P2P nodes. Such a P2P-based solution may be appropriate for an individual VoIP user. However, a caller may take a large volume of messages to find out a callee via the proxy nodes in the P2P network. This inherent property of a P2P network may induce the message overhead and long call setup delay. Based on above, another inexpensive scheme, which is a probing-based name resolution solution, is proposed to achieve high availability and load balancing for the VoIP service. We tag the probing mechanism onto the open source project Domain Name Relay Daemon (DNRD) to become a domain name resolution based load balancer (DN-LB). With DN-LB, all request messages from clients can be fairly distributed to all failure-proof proxy servers in the server farm without using any additional costly intermediate network device and changing the standard SIP architecture. Such a DN-LB based solution may be a good choice for a VoIP service provider.
C1 [Leu, Jenq-Shiou] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
   [Hsieh, Hui-Ching; Chen, Yen-Chiu] Natl Tsing Hua Univ, Dept Comp Sci, Hsingchu, Taiwan.
C3 National Taiwan University of Science & Technology; National Tsing Hua
   University
RP Leu, JS (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM jsleu@mail.ntust.edu.tw; eva@rtlab.cs.nthu.edu.tw;
   yenchiu@rtlab.cs.nthu.edu.tw
RI Chen, Yen-chiu/AAF-4574-2021
OI Chen, Yen-chiu/0000-0001-8587-461X
FU National Science Council, Taiwan [NSC-97-2221-E-011-085]
FX The authors gratefully acknowledge the support by the National Science
   Council, Taiwan, under grants NSC-97-2221-E-011-085.
CR CHEN S, 2008, COMPUTER COMMUNI FEB
   Gkantsidis C, 2004, IEEE INFOCOM SER, P120
   *ITU T, 1998, H323 ITUT
   JIANG S, 2008, IEEE T PARLLEL D MAY
   Ma HY, 2007, INT CONF NEXT GEN, P130
   MATIC V, 2006, SOFTWARE TELECOMMUNI, P2006
   ROSENBERG J, 2002, 3261 RFC IETF
   SINGH K, 2005, INT S PERF EV COMP T
   STEVENS W. R., UNIX NETWORK PROGRAM, V1
   Venkitaraman N, 2008, CONSUM COMM NETWORK, P1166, DOI 10.1109/ccnc08.2007.261
   ZOU H, 2000, COMM TECHN P WCC ICC
NR 11
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2011
VL 53
IS 1
BP 285
EP 301
DI 10.1007/s11042-010-0512-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 746AZ
UT WOS:000289214700013
DA 2024-07-18
ER

PT J
AU Ballan, L
   Bertini, M
   Del Bimbo, A
   Seidenari, L
   Serra, G
AF Ballan, Lamberto
   Bertini, Marco
   Del Bimbo, Alberto
   Seidenari, Lorenzo
   Serra, Giuseppe
TI Event detection and recognition for semantic annotation of video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video annotation; Event classification; Action classification; Survey
ID ONTOLOGY; CLASSIFICATION; FEATURES; SCALE
AB Research on methods for detection and recognition of events and actions in videos is receiving an increasing attention from the scientific community, because of its relevance for many applications, from semantic video indexing to intelligent video surveillance systems and advanced human-computer interaction interfaces. Event detection and recognition requires to consider the temporal aspect of video, either at the low-level with appropriate features, or at a higher-level with models and classifiers than can represent time. In this paper we survey the field of event recognition, from interest point detectors and descriptors, to event modelling techniques and knowledge management technologies. We provide an overview of the methods, categorising them according to video production methods and video domains, and according to types of events and actions that are typical of these domains.
C1 [Ballan, Lamberto; Bertini, Marco; Del Bimbo, Alberto; Seidenari, Lorenzo; Serra, Giuseppe] Univ Florence, Media Integrat & Commun Ctr, Florence, Italy.
C3 University of Florence
RP Bertini, M (corresponding author), Univ Florence, Media Integrat & Commun Ctr, Florence, Italy.
EM ballan@dsi.unifi.it; bertini@dsi.unifi.it; delbimbo@dsi.unifi.it;
   seidenari@dsi.unifi.it; serra@dsi.unifi.it
RI Bertini, Marco/X-1325-2019; Ballan, Lamberto/B-3450-2008; Seidenari,
   Lorenzo/AAA-1848-2020; Seidenari, Lorenzo/H-4240-2013; Serra,
   Giuseppe/M-3572-2015
OI Bertini, Marco/0000-0002-1364-218X; Ballan,
   Lamberto/0000-0003-0819-851X; Seidenari, Lorenzo/0000-0003-4816-0268;
   DEL BIMBO, ALBERTO/0000-0002-1052-8322; Serra,
   Giuseppe/0000-0002-4269-4501
FU EU [FP7-222267]
FX This work is partially supported by the EU IST IM3I Project (Contract
   FP7-222267).
CR Akdemir U, 2008, P ACM MULT
   [Anonymous], 2001, 2017 INT C ENERGY CO
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], P INT C COMP VIS ICC
   [Anonymous], P INT C PATT REC ICP
   [Anonymous], 2008, SEMANTIC MULTIMEDIA
   [Anonymous], 2007, P INT C COMP VIS ICC
   [Anonymous], 2008, P BRIT MACH VIS C BM
   [Anonymous], P INT C COMP VIS PAT
   [Anonymous], P INT C COMP VIS PAT
   [Anonymous], P EUR C COMP VIS ECC
   Arndt R, 2007, P INT SEM WEB C
   Artikis A, 2010, P ACM INT WORKSH EV
   Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   Assfalg J, 2002, P INT C MULT EXP ICM
   Bai L, 2007, P INT WORKSH IM AN M
   Bai L, 2007, P INT MACH VIS IM PR
   Ballan L, 2009, P INT C IM PROC ICIP
   Ballan L, 2010, IEEE MULTIMEDIA, DOI [10.1109/MMUL.2004.4, DOI 10.1109/MMUL.2004.4]
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P313, DOI 10.1007/s11042-009-0342-4
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Basharat A, 2008, COMPUT VIS IMAGE UND, V110, P360, DOI 10.1016/j.cviu.2007.09.016
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bertini M, 2005, MULTIMED TOOLS APPL, V27, P215, DOI 10.1007/s11042-005-2575-1
   Bertini M, 2007, P ACM INT WORKSH MAN
   Bertini M, 2008, P ACM INT WORKSH MAN
   Bloehdorn S, 2005, P EUR SEM WEB C
   Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Chao C, 2005, P INT C AC SPEECH SI
   Chen D, 2004, P INT WORKSH MULT IN
   Chen M, 2009, P TRECVID WORKSH
   Dasiopoulou S, 2005, IEEE T CIRC SYST VID, V15, P1210, DOI 10.1109/TCSVT.2005.854238
   Dollar P, 2005, P INT WORKSH VIS SUR
   Dousson C, 2007, P INT JOINT C ART IN
   Ebadollahi S, 2006, P INT C MULT EXP ICM
   Fathi A, 2008, P INT C COMP VIS PAT
   Fellbaum C, 1998, WORDNET ELECT LEXICA
   Fergus R, 2003, P INT C COMP VIS PAT
   Fihl P, 2007, P INT WORKSH GEST HU
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   Garcia R, 2005, P KNOWL MARK SEM ANN
   Georis B, 2004, P INT DISTR SURV SYS
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Hakeem A, 2004, P INT C PATT REC ICP
   Harte N, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/924287
   Haubold A, 2007, P ACM INT C IM VID R, P178
   Hollink L, 2005, P INT C KNOWL CAPT
   Jhuang H, 2010, NATURE COMMUNICATION, DOI [10.1038/ncomms.1064, DOI 10.1038/NCOMMS.1064]
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kennedy L, 2006, 22120067 COL U
   Kienzle W, 2007, P 29 ANN S GERM ASS
   Ko T, 2008, IEEE APP IMG PAT, P84
   Kompatsiaris Y., 2008, SEMANTIC MULTIMEDIA
   KOWALSKI R, 1986, NEW GENERAT COMPUT, V4, P67, DOI 10.1007/BF03037383
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, P INT C COMP VIS PAT
   Lavee G, 2007, LECT NOTES COMPUT SC, V4841, P442
   Lavee G, 2009, IEEE T SYST MAN CY C, V39, P489, DOI 10.1109/TSMCC.2009.2023380
   Lazebnik S, 2006, P INT C COMP VIS PAT
   Leslie L, 2007, P ACM MULT MM
   Liu J, 2009, P INT C COMP VIS PAT
   Liu J, 2008, P INT C COMP VIS PAT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo M, 2003, P ICICS PCM
   Mahadevan V, 2010, P INT C COMP VIS PAT
   Maillot NE, 2008, IMAGE VISION COMPUT, V26, P102, DOI 10.1016/j.imavis.2005.07.027
   Marszalek M, 2009, P INT C COMP VIS PAT
   Mehran R, 2010, P EUR C COMP VIS ECC
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2008, P INT C COMP VIS PAT
   Miller JA, 2005, P WINT SIM C WSC
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   Neumann B, 2006, LECT NOTES COMPUT SC, V3948, P247, DOI 10.1007/11414353_15
   Nevatia R, 2004, P C COMP VIS PATT RE
   Niebles J, 2007, P INT C COMP VIS PAT
   Nister D, 2006, P INT C COMP VIS PAT
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Over P, 2009, P TRECVID WORKSH GAI
   Paschke A, 2008, DECIS SUPPORT SYST, V46, P187, DOI 10.1016/j.dss.2008.06.008
   Pattanasri N., 2006, Advances in Multimedia Modeling. 13th International Multimedia Modeling Conference, MMM 2007. Proceedings (Lecture Notes in Computer Science Vol.4351), P535
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   San Miguel J, 2009, P INT C ADV VID SIGN
   Savarese S, 2006, P INT C COMP VIS PAT
   Savarese S, 2008, P WORKSH MOT VID COM
   Scherp A, 2009, P INT C KNOWL CAPT K
   Scovanner P, 2007, P ACM MULT MM
   Seidenari L, 2010, P ACM MULT MM
   Shet V, 2005, P IEEE INT C ADV VID
   Smeaton AF, 2006, P INT WORKSH MULT IN
   Snidaro L, 2007, P INT C INF FUS
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Tran SD, 2008, P EUR C COMP VIS ECC
   Tsinaraki C, 2005, MULTIMED TOOLS APPL, V26, P299, DOI 10.1007/s11042-005-0894-x
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Wang F, 2008, P ACM MULT MM
   Wong SF, 2007, P INT C COMP VIS ICC
   Wong SF, 2007, P INT C COMP VIS PAT
   Xj Wang, 2007, P INT C SEM COMP ICS
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Xu G, 2003, P IEEE INT C IM PROC
   Xu P, 2001, P INT C MULT EXP ICM
   Yang J, 2007, P INT WORKSH MULT IN
   Yang J, 2006, P INT WORKSH MULT IN
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
NR 111
TC 97
Z9 125
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 279
EP 302
DI 10.1007/s11042-010-0643-7
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800011
DA 2024-07-18
ER

PT J
AU Moorthy, AK
   Bovik, AC
AF Moorthy, Anush Krishna
   Bovik, Alan Conrad
TI Visual quality assessment algorithms: what does the future hold?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quality assessment; Objective quality assessment; Subjective quality
   assessment; Perceived quality
ID VIDEO QUALITY; IMAGE SHARPNESS; AUDIO QUALITY; STATISTICS; AESTHETICS;
   VISIBILITY; BLUR
C1 [Moorthy, Anush Krishna; Bovik, Alan Conrad] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
C3 University of Texas System; University of Texas Austin
RP Moorthy, AK (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM anushmoorthy@gmail.com
RI Bovik, Alan/B-6717-2012
OI Bovik, Alan/0000-0001-6067-710X
FU Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [0854904] Funding Source: National Science Foundation;
   Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [1116656] Funding Source: National Science Foundation
CR Alexandre B., 2009, EURASIP J IMAGE VIDE
   AMATRIAIN X, 2009, P INT C UMAP 09
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], P 15 EUR SIGN PROC C
   [Anonymous], P SPIE
   Barkowsky M, 2009, IEEE J-STSP, V3, P266, DOI 10.1109/JSTSP.2009.2015375
   Barland R., 2006, P 2 INT WORKSH VID P
   Beerends JG, 1999, J AUDIO ENG SOC, V47, P355
   Campisi P, 2003, IEEE T SIGNAL PROCES, V51, P996, DOI 10.1109/TSP.2003.809381
   Cermak GW, 2009, IEEE J-STSP, V3, P336, DOI 10.1109/JSTSP.2009.2014495
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Channappayya SS, 2008, IEEE T IMAGE PROCESS, V17, P857, DOI 10.1109/TIP.2008.921328
   Channappayya SS, 2006, IEEE IMAGE PROC, P2637, DOI 10.1109/ICIP.2006.313051
   Chen GH, 2006, IEEE IMAGE PROC, P2929, DOI 10.1109/ICIP.2006.313132
   CHEN MJ, 2010, IEEE INT C AC SPEECH
   CHEN MJ, 2009, 1 INT WORKSH QUAL MU
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   DIGNAN L, 2010, TIERED MOBILE DATA P
   Ebert Roger, 2010, NEWSWEEK
   Farias MCQ, 2004, PROC SPIE, V5292, P109, DOI 10.1117/12.527222
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Girod Bernd, 1993, P207
   Goldmann L., 2010, ELECT IMAGING EI 3D
   Gorley P., 2008, P SPIE STEREOSCOPIC, V6803
   Hekstra AP, 2002, SIGNAL PROCESS-IMAGE, V17, P781, DOI 10.1016/S0923-5965(02)00056-5
   Kandadai S, 2008, INT CONF ACOUST SPEE, P221, DOI 10.1109/ICASSP.2008.4517586
   Kanumuri S, 2006, IEEE T MULTIMEDIA, V8, P341, DOI 10.1109/TMM.2005.864343
   Kayargadde V, 1996, J OPT SOC AM A, V13, P1178, DOI 10.1364/JOSAA.13.001178
   KE Y, 2006, IEEE C COMP VIS PAT, V1
   KEIMEL C, 2009, P INT C IM PROC SAN
   Kortum P., 2010, HUMAN FACTORS J HUMA
   LECALLET P, 2007, 2 INT WORKSH IM MED, V83, P10
   Li CC, 2009, IEEE J-STSP, V3, P236, DOI 10.1109/JSTSP.2009.2015077
   Li Q, 2009, IEEE J-STSP, V3, P202, DOI 10.1109/JSTSP.2009.2014497
   *LIVE, 2010, QUAL ASS RES LIVE
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Meesters L, 2002, SIGNAL PROCESS, V82, P369, DOI 10.1016/S0165-1684(01)00177-3
   Meesters LMJ, 2004, IEEE T CIRC SYST VID, V14, P381, DOI 10.1109/TCSVT.2004.823398
   Miyata K, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P116
   Moorthy A. K., 2010, 5 INT WORKSH VID PRO
   MOORTHY AK, 2010, EUR C COMP VIS ECCV
   MOORTHY AK, 2009, DIGITAL VIDEO QUALIT
   MOORTHY AK, 2009, P IEEE AS C SIGN SYS
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Moorthy AK, 2009, IEEE J-STSP, V3, P193, DOI 10.1109/JSTSP.2009.2015374
   NACCARI M, 2008, P INT C IM PROC SAN
   Narvekar N., 2009, 1 INT WORKSH QUAL MU
   NINASSI A, 2006, 14 EUR SIGN PROC C
   Ninassi A, 2009, IEEE J-STSP, V3, P253, DOI 10.1109/JSTSP.2009.2014806
   *NINT, 2010, NINT INTR GLASS FREE
   ONG EP, 2003, INT C MULT EXP, V1, P6
   Ponomarenko N., 2008, Tampere image database
   Rouse DM, 2008, IEEE IMAGE PROC, P1188, DOI 10.1109/ICIP.2008.4711973
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Saad MA, 2009, INT WORK QUAL MULTIM, P163, DOI 10.1109/QOMEX.2009.5246957
   Sadaka NG, 2008, IEEE IMAGE PROC, P369, DOI 10.1109/ICIP.2008.4711768
   SAVAKIS AE, 2000, SPIE P HUMAN VIS ELE, P111
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Sazzad Z.P., 2007, IEEE P INT C IM PROC, V3, P517
   SESHADRINATHAN K, 2009, VIDEO QUALITY ASSESS, pCH14
   SESHADRINATHAN K, 2009, IMAGE QUALITY ASSESS, pCH20
   Seshadrinathan K., 2008, THESIS U TEXAS AUSTI
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P109
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Sheskin David, 2011, Handbook of Parametric and Nonparametric Statistical Procedures
   SHNAYDERMAN A, 2003, MULTIDIMENSIONAL IMA, V5294, P82
   Sugimoto O., 2000, Proceedings of the SPIE - The International Society for Optical Engineering, V4310, P932, DOI 10.1117/12.411876
   Suthaharan S, 2003, ELECTRON LETT, V39, P431, DOI 10.1049/el:20030308
   Varghese G, 2010, IEEE T CIRC SYST VID, V20, P1032, DOI 10.1109/TCSVT.2010.2051366
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Vu CT, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P73, DOI 10.1109/SSIAI.2008.4512288
   Vuori T, 2006, P SOC PHOTO-OPT INS, V6059, P5903, DOI 10.1117/12.641158
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   WANG Z, 2006, MODERN IMAGE QUALITY, V2
   Wang Z, 2007, J OPT SOC AM A, V24, pB61, DOI 10.1364/JOSAA.24.000B61
   Wang Z, 2006, IEEE T IMAGE PROCESS, V15, P1680, DOI 10.1109/TIP.2005.864165
   Wang Z, 2008, J VISION, V8, DOI 10.1167/8.12.8
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Winkler S, 2003, PROC SPIE, V5150, P593, DOI 10.1117/12.509910
   Winkler S., 2001, P INT S WIRELESS PER, P547
   Yang KC, 2007, IEEE T MULTIMEDIA, V9, P1528, DOI 10.1109/TMM.2007.906576
   Yarbus A. L., 1967, Eye Movements and Vision
   Zhu X., 2009, 1 INT WORKSH QUAL MU
   TOYAMA IMAGE DATABAS
NR 92
TC 83
Z9 88
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 675
EP 696
DI 10.1007/s11042-010-0640-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300011
DA 2024-07-18
ER

PT J
AU Gondra, I
   Xu, T
AF Gondra, Iker
   Xu, Tao
TI A multiple instance learning based framework for semantic image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multiple instance learning; Content-based image
   retrieval; Relevance feedback; Mean shift; Semantic gap; Adaptive
   segmentation; Segmentation parameters; Diverse density; Clustering
ID MEAN-SHIFT; RETRIEVAL
AB Most image segmentation algorithms extract regions satisfying visual uniformity criteria. Unfortunately, because of the semantic gap between low-level features and high-level semantics, such regions usually do not correspond to meaningful parts. This has motivated researchers to develop methods that, by introducing high-level knowledge into the segmentation process, can break through the performance ceiling imposed by the semantic gap. The main disadvantage of those methods is their lack of flexibility due to the assumption that such knowledge is provided in advance. In content-based image retrieval (CBIR), relevance feedback (RF) learning has been successfully applied as a technique aimed at reducing the semantic gap. Inspired by this, we present a RF-based CBIR framework that uses multiple instance learning to perform a semantically-guided context adaptation of segmentation parameters. A partial instantiation of this framework that uses mean shift-based segmentation is presented. Experiments show the effectiveness and flexibility of the proposed framework on real images.
C1 [Gondra, Iker; Xu, Tao] St Francis Xavier Univ, Dept Math Stat & Comp Sci, Antigonish, NS B2G 1C0, Canada.
C3 Saint Francis Xavier University - Canada
RP Gondra, I (corresponding author), St Francis Xavier Univ, Dept Math Stat & Comp Sci, Antigonish, NS B2G 1C0, Canada.
EM igondra@stfx.ca; x2006opl@stfx.ca
CR [Anonymous], PATTERN CLASSIFICATI
   BHANU B, 1995, IEEE T AERO ELEC SYS, V31, P1268, DOI 10.1109/7.464350
   BHANU B, 1995, IEEE T SYST MAN CYB, V25, P1543, DOI 10.1109/21.478442
   Borenstein E, 2004, LECT NOTES COMPUT SC, V3023, P315
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P281, DOI 10.1109/TPAMI.2003.1177159
   Datta AK, 2008, OPT LASER TECHNOL, V40, P1, DOI 10.1016/j.optlastec.2007.04.006
   Dietterich TG, 1997, ARTIF INTELL, V89, P31, DOI 10.1016/S0004-3702(96)00034-3
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   GONDRA I, 2008, P IEEE INT C DIG INF, P716
   Gu IYH, 2001, IEEE IMAGE PROC, P726, DOI 10.1109/ICIP.2001.959148
   Guy G, 1996, INT J COMPUT VISION, V20, P113, DOI 10.1007/BF00144119
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Maron O, 1998, ADV NEUR IN, V10, P570
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pearl J., 1988, PROBABILISTIC REASON
   Peng J, 1998, IEEE T PATTERN ANAL, V20, P139, DOI 10.1109/34.659932
   SCHNITMAN Y, 2006, AS C COMP VIS, P384
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   Wang YZ, 2006, PATTERN RECOGN LETT, V27, P386, DOI 10.1016/j.patrec.2005.09.014
   XU T, 2009, P C3S2E C ACM NEW YO, P197
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 27
TC 9
Z9 13
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2010
VL 48
IS 2
BP 339
EP 365
DI 10.1007/s11042-009-0347-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 584AY
UT WOS:000276723600006
DA 2024-07-18
ER

PT J
AU Xiao, J
   Zhuang, YT
   Wu, F
   Guo, TQ
   Liang, Z
AF Xiao, Jun
   Zhuang, Yueting
   Wu, Fei
   Guo, Tongqiang
   Liang, Zhang
TI A group of novel approaches and a toolkit for motion capture data
   reusing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion capture data; Bone angle; Interactive segmentation; Key-frame
   extraction; Motion retrieval
ID RETRIEVAL; EXTRACTION; ANIMATION
AB Now more and more motion capture (MoCap) systems are used to acquire realistic and highly detailed motion data which are widely used for producing animations of human-like characters in a variety of applications, such as simulations, video games and animation films. And recently large MoCap databases are available. As a kind of emerging multimedia data, 3D human motion has its own specific data form and standard format. But to the best of our knowledge, only a few approaches have been explored for 3D MoCap data feature representation and reusing. This paper proposes a group of novel approaches for posture feature representation, motion sequence segmentation, key-frame extraction and content-based motion retrieval, which are all very important for MoCap data reusing and benefit to the efficient animation production. To validate these approaches, we set up a MoCap database and implemented a prototype toolkit. The experiments show that the proposed algorithms could achieve the approvable results.
C1 [Xiao, Jun; Zhuang, Yueting; Wu, Fei; Guo, Tongqiang; Liang, Zhang] Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Xiao, J (corresponding author), Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Peoples R China.
EM junx@cs.zju.edu.cn; yzhuang@cs.zju.edu.cn; wufei@cs.zju.edu.cn;
   guotq@cs.zju.edu.cn; liangzhang@cs.zju.edu.cn
FU National Natural Science Foundation of China [60525108]; National Key
   Technology R&D Program of China [2007BAH11B00]; Program for Changjiang
   Scholars and Innovative Research Team in University [IRT0652]; National
   Science Foundation for Post-doctoral Scientists of China [20080431327]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 60525108; the National Key Technology R&D Program
   of China under Grant No. 2007BAH11B00; the Program for Changjiang
   Scholars and Innovative Research Team in University under grant No.
   IRT0652; the National Science Foundation for Post-doctoral Scientists of
   China under Grant No. 20080431327.
CR [Anonymous], 2004, P INT C VERY LARGE D
   [Anonymous], 2005, P ACM SIGGRAPH EUR S
   [Anonymous], P 22 ANN C COMP GRAP
   Arikan O, 2003, ACM T GRAPHIC, V22, P402, DOI 10.1145/882262.882284
   Arikan O, 2006, ACM T GRAPHIC, V25, P890, DOI 10.1145/1141911.1141971
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Bruderlin Armin., 1995, Proceedings of the 22nd Annual Conference on Computer Graphics and Interactive Techniques, SIGGRAPH '95, P97, DOI DOI 10.1145/218380.218421
   Chiu CY, 2004, J VIS COMMUN IMAGE R, V15, P446, DOI 10.1016/j.jvcir.2004.04.004
   CHOI KJ, 1999, P INT PAC GRAPH, P32
   Demuth B, 2006, LECT NOTES COMPUT SC, V3936, P373
   Fod A, 2002, AUTON ROBOT, V12, P39, DOI 10.1023/A:1013254724861
   FRITSCH FN, 1980, SIAM J NUMER ANAL, V17, P238, DOI 10.1137/0717021
   Geng WD, 2003, LECT NOTES COMPUT SC, V2669, P620
   Gleicher M, 2001, GRAPH MODELS, V63, P107, DOI 10.1006/gmod.2001.0549
   GLEICHER M, 2001, S INT 3D GRAPH
   Hsieh MK, 2005, INT C COMP AID DES C, P457
   Huang KS, 2005, VISUAL COMPUT, V21, P532, DOI 10.1007/s00371-005-0316-0
   Kahol K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P883, DOI 10.1109/AFGR.2004.1301645
   KAHOL K, GESTURE SEGMENTATION, V2, P105
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   Kovar L, 2004, ACM T GRAPHIC, V23, P559, DOI 10.1145/1015706.1015760
   Lee Jehee., 2002, Proceedings of the 29th annual conference on Computer graphics and interactive techniques, P491, DOI DOI 10.1145/566570.566607
   LI C, MULTIMEDIA TOOLS APP
   Lim IS, 2001, P ANN INT IEEE EMBS, V23, P1167
   Liu CK, 2002, ACM T GRAPHIC, V21, P408, DOI 10.1145/566570.566596
   Liu F, 2003, COMPUT VIS IMAGE UND, V92, P265, DOI 10.1016/j.cviu.2003.06.001
   LIU G, 2006, P 2006 ACM IN PRESS
   Liu G., 2005, P 2005 ACM SIGMOD IN, P924
   Lu CM, 2004, IEEE T PATTERN ANAL, V26, P258, DOI 10.1109/TPAMI.2004.1262196
   MAJKOWSKA A, P 2007 ACM SIGGRAPH, P35
   MUELLER M, 2005, P ACM SIGGRAPH 2005, V24, P677
   Mukai T, 2005, ACM T GRAPHIC, V24, P1062, DOI 10.1145/1073204.1073313
   Park MJ, 2004, COMPUT ANIMAT VIRT W, V15, P245, DOI 10.1002/cav.27
   Park SI, 2004, COMPUT ANIMAT VIRT W, V15, P125, DOI 10.1002/cav.15
   Pickering MJ, 2003, COMPUT VIS IMAGE UND, V92, P217, DOI 10.1016/j.cviu.2003.06.002
   Pomplun M., 2000, P 1 IEEE RAS INT C H
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SAKAMOTO Y, 2004, P 2004 ACM SIGGRAPH, P259
   Shin HJ, 2006, COMPUT ANIMAT VIRT W, V17, P219, DOI 10.1002/cav.125
   Sung M, 2004, COMPUT GRAPH FORUM, V23, P519, DOI 10.1111/j.1467-8659.2004.00783.x
   SUNG M., 2005, SCA 05, P291
   Tang JKT, 2008, COMPUT ANIMAT VIRT W, V19, P211, DOI 10.1002/cav.260
   WANG J, 2004, 2004 ACM SIGGRAPH EU, P337
   Wang TS, 2001, LECT NOTES COMPUT SC, V2195, P174
   Wen Gaojin., 2006, VRST 06, P165
   XIAO J, 2007, THESIS ZHEJIANG U
   ZHUANG Y, 2002, WEB BASED MULTIMEDIA
   Zhuang Yueting., 1998, Adaptive key frame extraction using unsupervised clustering
NR 48
TC 7
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2010
VL 47
IS 3
SI SI
BP 379
EP 408
DI 10.1007/s11042-009-0329-1
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 572BC
UT WOS:000275800200003
DA 2024-07-18
ER

PT J
AU Zhu, ZY
   Lin, T
AF Zhu, Ziyuan
   Lin, Tao
TI Idempotent H.264 intraframe compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; Multi-generation; Idempotent
ID TRANSFORM; JPEG
AB This paper studies H.264 intraframe multi-generation characteristics and presents four mechanisms that contribute to the generation degradation. We analyze the H.264 transform and quantization and reveal that for some quantization parameters there always exists at least one clipping compensation matrix to make the H.264 intraframe multi-generation coding idempotent as long as the same prediction mode and the same quantization parameter are selected for each coding generation. In addition, an idempotent H.264 intraframe multi-generation coding procedure is presented. The procedure has three additional steps to achieve idempotence: Prediction Mode and QP Restriction, Prediction Mode and QP Identification, and Clipping Compensation. Experiment results show that the proposed idempotent coding produces no generation PSNR loss and the rate-distortion efficiency is almost same as that of traditional H.264.
C1 [Zhu, Ziyuan; Lin, Tao] Tongji Univ, VLSI Lab, Shanghai 200092, Peoples R China.
C3 Tongji University
RP Zhu, ZY (corresponding author), Tongji Univ, VLSI Lab, Shanghai 200092, Peoples R China.
EM zzy@hotmail.it; lintao@tongji.edu.cn
CR DONG PY, IET IMAGE P IN PRESS
   ERDEM AT, 1994, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.1994.413492
   HAUPT RL, 2004, HAUPT SE PRACTICAL G
   Hewitt C, 2008, IEEE INTERNET COMPUT, V12, P96, DOI 10.1109/MIC.2008.107
   Horne C, 1996, IEEE T CIRC SYST VID, V6, P251, DOI 10.1109/76.499835
   Hurd LP, 2000, P SOC PHOTO-OPT INS, V3974, P685, DOI 10.1117/12.383004
   Joshi RL, 2000, P SOC PHOTO-OPT INS, V4115, P492, DOI 10.1117/12.411570
   *JVT, 2005, JVTN011
   Krishnamoorthy R, 2007, CONSUM COMM NETWORK, P395, DOI 10.1109/CCNC.2007.84
   LIN T, 2008, IEEE INT C SIGN CIRC, P1
   Lin T, 2009, IEEE SIGNAL PROC LET, V16, P323, DOI 10.1109/LSP.2009.2014285
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   Sorial HZ, 1997, P SOC PHOTO-OPT INS, V3024, P1394, DOI 10.1117/12.263219
   *W W COMM WIR HDMI, NEXT FRONT HD HOM EN
   *WHDI, WHDI TECHN OV
   Yi Yan, 2004, Journal of Shanghai Jiaotong University, V38, P616
   ZHU ZY, IEEE INT C AC SPEECH, P1033
NR 17
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 1
BP 25
EP 45
DI 10.1007/s11042-009-0306-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 537DQ
UT WOS:000273093600002
DA 2024-07-18
ER

PT J
AU Rakkolainen, I
   Höllerer, T
   DiVerdi, S
   Olwal, A
AF Rakkolainen, Ismo
   Hollerer, Tobias
   DiVerdi, Stephen
   Olwal, Alex
TI Mid-air display experiments to create novel user interfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
CT 1st ACM International Workshop on Semantic Ambient Media Experience
CY OCT 31, 2008
CL Vancouver, CANADA
SP ACM
DE FogScreen; Display; Interaction; Ambient media
AB Displays are the most visible part of most computer applications. Novel display technologies strongly influence and inspire new forms of computer use and interaction. We are particularly interested in the interplay of novel displays and interaction for ubiquitous computing or ambient media environments, as emerging display technologies may become game-changers in how we define and use computers, possibly changing the context of computing fundamentally.
   We present some of our experiments and lessons learnt with a new category of displays, the "immaterial" FogScreen. It can be described as a novel media platform, exhibiting some fundamental differences to and advantages over other displays. It also enables novel kinds of user interfaces and experiences. In this paper we give insights about the special properties and strengths of the FogScreen by looking at a set of successfully demonstrated interfaces and applications. We also discuss its future potential for user interface design.
C1 [Rakkolainen, Ismo; Hollerer, Tobias; DiVerdi, Stephen; Olwal, Alex] Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
   [Rakkolainen, Ismo] Tampere Univ Technol, FIN-33101 Tampere, Finland.
   [DiVerdi, Stephen] Adobe Syst Inc, San Jose, CA 95110 USA.
   [Olwal, Alex] Royal Inst Technol, Stockholm, Sweden.
C3 University of California System; University of California Santa Barbara;
   Tampere University; Adobe Systems Inc.; Royal Institute of Technology
RP Rakkolainen, I (corresponding author), Univ Calif Santa Barbara, Santa Barbara, CA 93106 USA.
EM ismo.rakkolainen@tut.fi
CR [Anonymous], 1997, The coming age of calm technolgy. pages, DOI DOI 10.1007/978-1-4612-0685-9_6
   Benzie P, 2007, IEEE T CIRC SYST VID, V17, P1647, DOI 10.1109/TCSVT.2007.905377
   Bowman Doug, 2004, 3D user interfaces: Theory and practice
   Breisinger M., 2006, Proc. of World Conference on Educational Multimedia, P2282
   DIVERDI S, 2006, SPIE ELECT IMAGING S, V6055, P1
   DIVERDI S, 2007, 3 DIMENSIONAL TELEVI, P505
   *FOGSCREEN INC, 2009, FOGSCREEN DISPL
   Grossman Tovi., 2004, P 17 ANN ACM S USER, P61
   Iwamoto Takayuki., 2008, AIRBORNE ULTRASOUND
   Jumisko-Pyykko Satu, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P377, DOI 10.1109/3DTV.2008.4547887
   Just P.C., 1899, U.S. Patent, Patent No. [No. 620592, 620592]
   Lee C., 2007, ACM S VIRT REAL SOFT
   OLWAL A, 2008, 2 INT C INTELLIGENT
   Rakkolainen Ismo, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P37, DOI 10.1109/3DTV.2008.4547802
   RAKKOLAINEN I, 2002, IS T SPIE EL IM 2002, P17
   RAKKOLAINEN I, 2007, ACM C ADV COMP ENT T, P95
   RAKKOLAINEN I, 2007, IEEE 3DTV C KOS GREE
   RAKKOLAINEN I, 2006, ACM MULT 2006, P185
   Rakkolainen I, 2007, IEEE INT CONF INF VI, P935
   WEISER M, 1991, SCI AM, V265, P94, DOI 10.1038/scientificamerican0991-94
   *WORLDVIZ, 2009, WORLDVIZ PPT PREC PO
NR 21
TC 9
Z9 15
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2009
VL 44
IS 3
BP 389
EP 405
DI 10.1007/s11042-009-0280-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 474WB
UT WOS:000268313900004
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Chu, WT
   Wu, JL
AF Chu, Wei-Ta
   Wu, Ja-Ling
TI Explicit semantic events detection and development of realistic
   applications for broadcasting baseball videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE explicit event detection; semantics; sports video; game summarization;
   highlight extraction
ID SOCCER VIDEO; RECOGNITION
AB This paper presents a framework that explicitly detects events in broadcasting baseball videos and facilitates the development of many practical applications. Three phases of contributions are included in this work: reliable shot classification, explicit event detection, and elaborate applications. At the shot classification stage, color and geometric information are utilized to classify video shots into several canonical views. To explicitly detect semantic events, rule-based decision and model-based decision methods are developed. We emphasize that this system efficiently and exactly identifies what happened in baseball games rather than roughly finding some interesting parts. On the basis of explicit event detection, many accurate and practical applications such as automatic box score generation and game summarization could be built. The reported results show the effectiveness of the proposed framework and demonstrate some research opportunities about bridging the semantic gap for sports videos.
C1 [Chu, Wei-Ta; Wu, Ja-Ling] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
   [Wu, Ja-Ling] Natl Taiwan Univ, Grad Inst Networking & Multimedia, Taipei 10764, Taiwan.
C3 National Taiwan University; National Taiwan University
RP Chu, WT (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei 10764, Taiwan.
EM wtchu@cmlab.csie.ntu.edu.tw; wjl@csie.ntu.edu.tw
RI Chu, Wei-Ta/AAE-8471-2022
OI Chu, Wei-Ta/0000-0001-5722-7239; WU, JA-LING/0000-0002-3631-1551
CR [Anonymous], 2004, P ACM SIGMM INT WORK
   ARIKI Y, 2003, P ACM INT WORKSH MUL, P209
   Babaguchi N, 2004, IEEE T MULTIMEDIA, V6, P575, DOI [10.1109/TMM.2004.830811, 10.1109/tmm.2004.830811]
   Bertini M, 2005, PATTERN ANAL APPL, V7, P411, DOI 10.1007/s10044-004-0234-1
   DORAI C, 2002, MEDIA COMPUTING COMP
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Han M., 2002, Proc. ACM Multimedia, P347, DOI [DOI 10.1145/641007.641081, 10.1145/641007.641081]
   Hua W, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P821, DOI 10.1109/ICME.2002.1035908
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Lee HY, 2003, IEEE T MULTIMEDIA, V5, P358, DOI 10.1109/TMM.2003.814792
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Li BX, 2004, J VIS COMMUN IMAGE R, V15, P393, DOI 10.1016/j.jvcir.2004.04.006
   Nepal S., 2001, ACM Multimedia, P261
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Rui Y., 2000, Proceedings ACM Multimedia 2000, P105, DOI 10.1145/354384.354443
   SHIH HC, 2003, P ICASSP, V5, P820
   Tjondronegoro D, 2004, IEEE MULTIMEDIA, V11, P22, DOI 10.1109/MMUL.2004.28
   Wang J., 2004, P 12 ANN ACM INT C M, P32
   Wang L., 2004, Proceedings of the 6th ACM SIGMM international workshop on Multimedia information retrieval, P259
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Xiong ZY, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P632
   XU G, 2003, P ICIP, V1, P25
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu XG, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P526
   Zhang D., 2002, ACM Multimedia, P315
   Zhong D, 2004, J VIS COMMUN IMAGE R, V15, P330, DOI 10.1016/j.jvcir.2004.04.009
NR 26
TC 18
Z9 19
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 38
IS 1
BP 27
EP 50
DI 10.1007/s11042-007-0145-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 280DL
UT WOS:000254405000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ghini, V
   Lodi, G
   Panzieri, F
AF Ghini, V.
   Lodi, G.
   Panzieri, F.
TI Mobile E-Witness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia data; codec; intermittent communication; multi-homing;
   wireless networks
ID ALWAYS
AB This paper describes the design, implementation and experimental evaluation of a system prototype, named Mobile E-Witness (MEW), which enables the acquisition and remote storage of multimedia (i.e., audio and video) data streams. In essence, MEW consists of a mobile device, incorporating a camera and a microphone, which can be "worn" (i.e., it can be carried without causing any impediment) by public officers, such as policemen and health care operators, in order to record the events these officers witness while on duty. MEW transmits the audio and video data recordings it takes to a remote storage service which maintains these recordings for future replay. Thus, for example, an event recording can be used as an impartial testimony to resolve disputes concerning the relative responsibilities of those participating to the recorded event, including the officers themselves (hence the name Mobile E-Witness). The infrastructure MEW uses for communications with the remote storage service consists of the wired and wireless communication infrastructures publicly available in metropolitan areas, including the Internet. MEW utilizes these infrastructures in order to (1) ensure that sufficient bandwidth for multimedia data transmission is available, (2) guarantee highly available communications, (3) limit the power consumption for the multimedia transmission and, finally, (4) limit the electromagnetic radiation emanation of the device worn by the public officers. We have carried out an experimental evaluation of a MEW prototype in the city of Bologna. The results of this evaluation, reported in this paper, confirm the potential of our system.
C1 [Ghini, V.; Lodi, G.; Panzieri, F.] Univ Bologna, Dept Comp Sci, I-40127 Bologna, Italy.
C3 University of Bologna
RP Ghini, V (corresponding author), Univ Bologna, Dept Comp Sci, Mura A Zamboni 7, I-40127 Bologna, Italy.
EM ghini@cs.unibo.it; lodig@cs.unibo.it; panzieri@cs.unibo.it
OI LODI, GIORGIA/0009-0000-9032-4831
CR ABOBA B, 2004, 3748 RFC INT SOC
   [Anonymous], 2001, 80211B1999 IEEE
   [Anonymous], 2000, 2960 RFC
   [Anonymous], 2004, 80211I2004 IEEE
   BEXLEY C, 2002, THESIS U S FLORIDA T
   *FIATECH CORP, 2007, FUT FIATECH
   FREIER AO, 1996, SSL PROT VERS 3 0
   Ghini V, 2005, IEEE COMMUN MAG, V43, P69, DOI 10.1109/MCOM.2005.1453425
   Gustafsson E, 2003, IEEE WIREL COMMUN, V10, P49, DOI 10.1109/MWC.2003.1182111
   IEEE, 1985, 80231985 IEEE
   IEEE, 2003, 80211G2003 IEEE
   *IEEE, 2001, 8021X2001 IEEE
   *INT ORG STAND, 2002, JTC1SC29WG11 ISO IEC
   *INT ORG STAND INT, 2005, 14496102005 ISO IEC
   *INT SOC, 2003, 3579 RFC
   *INT STREAM MED AL, ISMA 2 0 SPEC
   Johnson D., 2004, RFC 3775
   LI ST, 2002, P IEEE WORKSH KNOWL
   Malek Sam, 2003, SOFTWARE ARCHITECTUR
   MEGURO J, 2005, P IEEE INT C ROB AUT
   Meltzer S., 2006, MPEG 4 HE AAC V2 AUD
   Perkins C., 2002, RFC 3344
   RIEGEL M, 2006, MOBILE SCTP
   RIGOLE P, 2004, P 3N IEEE HAW INT C
NR 24
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 37
IS 3
BP 293
EP 318
DI 10.1007/s11042-007-0164-1
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 274BI
UT WOS:000253976400003
DA 2024-07-18
ER

PT J
AU Lee, HY
   Lee, CH
   Lee, HK
AF Lee, Hae-Yeoun
   Lee, Choong-Hoon
   Lee, Heung-Kyu
TI Geometrically invariant watermarking: synchronization through circular
   Hough transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE geometrically invariant watermarking; watermark synchronization;
   circular Hough transform
AB This paper addresses a geometrically invariant watermarking method for digital images. Most previous watermarking algorithms perform weakly against geometric distortions, which desynchronize the location for the inserted watermark. Watermark synchronization, which is a process for finding the location for watermark insertion and detection, is crucial for robust watermarking. In this paper, we propose a watermarking method that is robust to geometric distortions. In order to synchronize the location for watermark insertion and detection, we use circular Hough transform, which extracts circular features that are invariant to geometric distortions. The circular features are then watermarked using additive way on the spatial domain. Our method belongs to the category of blind watermarking techniques, because we do not need the original image during detection. Experimental results support the contention that our method is useful and considerably robust against both geometric distortion attacks and signal processing attacks as listed in Stirmark 3.1.
C1 Cornell Univ, Weill Med Coll, New York, NY 10022 USA.
   SAMSUNG Elect Co LTD, Digital Media R&D Ctr, Suwon, Gyeonggi Do, South Korea.
   Korea Adv Inst Sci & Technol, Dept EECS, Taejon 305701, South Korea.
C3 Cornell University; Weill Cornell Medicine; Samsung; Samsung
   Electronics; Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, HY (corresponding author), Cornell Univ, Weill Med Coll, 575 Lexington Av,3F, New York, NY 10022 USA.
EM hytoiy@casaturn.kaist.ac.kr
RI Lee, Heung Kyu/C-1941-2011
CR ARGHONIEMY M, 2004, IEEE T IMAGE PROCESS, V13, P145
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   COX IJ, 2002, DIGITAL WATERMARKING, pCH5
   Kutter M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P320, DOI 10.1109/ICIP.1999.821622
   Kutter M., 1998, Proceedings of SPIE, V3628, P423
   Lin CY, 2001, IEEE T IMAGE PROCESS, V10, P767, DOI 10.1109/83.918569
   Lin ET, 2004, PROC SPIE, V5306, P536, DOI 10.1117/12.531946
   Nikolaidis A, 2001, IEEE T IMAGE PROCESS, V10, P1726, DOI 10.1109/83.967400
   O'Ruanaidh J., 1998, Signal Processing, V66, P303, DOI DOI 10.1016/S0165-1684(98)00012-7
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Simitopoulos D, 2003, IEEE T CIRC SYST VID, V13, P732, DOI 10.1109/TCSVT.2003.815947
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   VOLOSHYNOVSKIY S, 1999, P INT WORKSH INF HID, P212
NR 14
TC 17
Z9 22
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2007
VL 34
IS 3
BP 337
EP 353
DI 10.1007/s11042-007-0112-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 189SJ
UT WOS:000248008500004
DA 2024-07-18
ER

PT J
AU Greenberg, S
AF Greenberg, Saul
TI Toolkits and interface creativity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 9th International Workshop on Groupware
CY SEP 28-OCT 02, 2003
CL AUTRANS, FRANCE
SP CNRS, Inst Informat & Math Appl Grenoble, Conseil Reg Rhone Alpes, Mairie Grenoble, Conseil Gen Savoie, Inst Natl Polytech Grenoble, Univ Savoie, Univ Joseph Fourier, CINVESTAV IPAN, CICESE
DE rapid prototyping; interface toolkits; creativity; innovative
   interfaces; groupware
AB Interface toolkits in ordinary application areas let average programmers rapidly develop software resembling other standard applications. In contrast, toolkits for novel and perhaps unfamiliar application areas enhance the creativity of these programmers. By removing low-level implementation burdens and supplying appropriate building blocks, toolkits give people a 'language' to think about these new interfaces, which in turn allows them to concentrate on creative designs. This is important, for it means that programmers can rapidly generate and test new ideas, replicate and refine ideas, and create demonstrations for others to try. To illustrate this important link between toolkits and creativity, I describe example groupware toolkits we have built and how people have leveraged them to create innovative interfaces.
C1 Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
C3 University of Calgary
RP Greenberg, S (corresponding author), Univ Calgary, Dept Comp Sci, Calgary, AB T2N 1N4, Canada.
EM saul@cpsc.ucalgary.ca
CR BEDERSON B, 1999, 9908 HCIL
   BIER B, 1991, P ACM UIST, P79
   BOYLE M, 2005, P 11 INT C DISTR MUL
   Cox D., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P289, DOI 10.1145/358916.359000
   De Bono Edward., 1973, LATERAL THINKING CRE
   DIAZMARINO RA, 2003, COMP P ACM UIST
   Engelbart D.C., 1968, P DECEMBER 9 11 1968, P395
   FOSTER G, 1986, UCBCSD87326 EECS
   Gaines B., 1999, INF SCI, V57, P13
   Greenberg S, 2003, LECT NOTES COMPUT SC, V2806, P1
   GREENBERG S, 1992, INTERACT COMPUT, V4, P364, DOI 10.1016/0953-5438(92)90023-9
   GREENBERG S, 1996, PEOPLE COMPUTERS, V11, P299
   GREENBERG S, 2000, PERSONAL TECHNOLOGIE, V4
   GREENBERG S, 2004, ADV INFORM TECHNOLOG
   Greenberg S., 2001, P ACM C HUMAN FACTOR, P515
   GREENBERG S, 1997, HUMAN FACTORS WEB DE, P241
   Greenberg S., 2001, PROC ACM UIST, P209
   GREENBERG S, 1999, TRENDS SOFTWARE, V7, P135
   Greenberg S, 2003, SHARING EXPERTISE: BEYOND KNOWLEDGE MANAGEMENT, P203
   Gutwin C., 1996, People and Computers XI. Proceedings of HCI '96, P281
   Gutwin C., 2004, TEAM COGNITION, P177, DOI DOI 10.1037/10690-009
   MYERS B, 1995, READINGS HUMAN COMPU, P323
   SARIN S, 1984, MITLCSTR330
   Shneiderman B., 2000, ACM Transactions on Computer-Human Interaction, V7, P114, DOI 10.1145/344949.345077
   Stewart J., 1999, P CHI 99, P286, DOI [10.1145/302979.303064, DOI 10.1145/302979.303064]
   TANG A, 2003, CRPIT C RES PRACTICE, V28, P73
   TANG JC, 1991, INT J MAN MACH STUD, V34, P143, DOI 10.1016/0020-7373(91)90039-A
   Tse E., 2004, Computer Supported Cooperative Work Conference Proceedings, P252, DOI 10.1145/1031607.1031647
   TSE E, 2004, CRPIT C RES PRACTICE, V28, P101
   ZANELLA A, 2001, P ECSCW
NR 30
TC 39
Z9 45
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2007
VL 32
IS 2
BP 139
EP 159
DI 10.1007/s11042-006-0062-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 129ZR
UT WOS:000243769100002
DA 2024-07-18
ER

PT J
AU Bertini, M
   Cucchiara, R
   Del Bimbo, A
   Prati, A
AF Bertini, M
   Cucchiara, R
   Del Bimbo, A
   Prati, A
TI An integrated framework for semantic annotation and adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE semantic annotation; semantic adaptation; semantic transcoding; video
   adaptation; event detection; motion segmentation; performance evaluation
ID VIDEO; EXTRACTION
AB Tools for the interpretation of significant events from video and video clip adaptation can effectively support automatic extraction and distribution of relevant content from video streams. In fact, adaptation can adjust meaningful content, previously detected and extracted, to the user/client capabilities and requirements. The integration of these two functions is increasingly important, due to the growing demand of multimedia data from remote clients with limited resources (PDAs, HCCs, Smart phones). In this paper we propose an unified framework for event-based and object-based semantic extraction from video and semantic on-line adaptation. Two cases of application, highlight detection and recognition from soccer videos and people behavior detection in domotic* applications, are analyzed and discussed.
C1 Univ Florence, DSI, I-50121 Florence, Italy.
   Univ Modena & Reggio Emilia, DII, Modena, Italy.
C3 University of Florence; Universita di Modena e Reggio Emilia
RP Univ Florence, DSI, I-50121 Florence, Italy.
EM bertini@dsi.unifi.it; cucchiara.rita@unimore.it; delbimbo@dsi.unifi.it;
   prati.andrea@unimore.it
RI Prati, Andrea/B-7440-2014; Bertini, Marco/X-1325-2019; Cucchiara,
   Rita/L-3006-2015
OI Prati, Andrea/0000-0002-1211-529X; Bertini, Marco/0000-0002-1364-218X;
   DEL BIMBO, ALBERTO/0000-0002-1052-8322; Cucchiara,
   Rita/0000-0002-2239-283X
CR Assfalg E, 2003, COMPUT VIS IMAGE UND, V92, P285, DOI 10.1016/j.cviu.2003.06.004
   ASSFALG J, 2003, P ACM S APPL COMP MA, P769
   BREMOND F, 2003, IEEE P IDSS S INT DI
   BREMOND F, 2000, P IEEE C COMP VIS PA
   CUCCHIARA R, 2003, INT J IMAGE GRAPHICS, V3, P145
   CUCCHIARA R, 2003, IN PRESS IEEE T PATT
   Cucchiara R., 2002, P 10 ACM INT C MULTI, P223
   EKIN A, 2003, IN PRESS IEEE T IMAG
   FARIN D, 2002, 23 S INF THEOR BEN M
   GONG Y, 1995, P IEEE INT C MULT CO, P15
   Gonzales CA, 1991, IEEE T CIRC SYST VID, V1, P374, DOI 10.1109/76.120778
   Hashemi M. R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P276, DOI 10.1109/ICIP.1999.819594
   Huang KL, 2002, IEEE T CONSUM ELECTR, V48, P522, DOI 10.1109/TCE.2002.1037037
   Hwang JN, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P616, DOI 10.1109/MMSP.1998.739049
   Keesman G, 1996, SIGNAL PROCESS-IMAGE, V8, P481, DOI 10.1016/0923-5965(95)00067-4
   KIM JG, 2003, P IEEE INT C MULT CO
   Leonardi R, 2002, IEEE MULTIMEDIA, V9, P44, DOI 10.1109/93.998057
   Liang YQ, 2001, IEEE IMAGE PROC, P429, DOI 10.1109/ICIP.2001.959045
   Madabhushi A, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P25, DOI 10.1109/VS.1999.780265
   Mohan R, 1999, IEEE T MULTIMEDIA, V1, P104, DOI 10.1109/6046.748175
   Nagao K., 2001, IEEE Multimedia, V8, P69, DOI 10.1109/93.917973
   Nepal S., 2001, ACM Multimedia, P261
   ORTEGA A, 1995, SPIE DIG VID COMPR F
   RAMCHANDRAN K, 1994, IEEE T IMAGE PROCESS, V3, P700, DOI 10.1109/83.334973
   Shanableh T, 2000, IEEE T MULTIMEDIA, V2, P101, DOI 10.1109/6046.845014
   Smith JR, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P7, DOI 10.1109/ICIP.1998.998987
   Song J, 1999, IEEE T CIRC SYST VID, V9, P1100, DOI 10.1109/76.795061
   SUDHIR G, 1998, P INT WORKSH CONT BA
   Sun HF, 1997, IEEE T CONSUM ELECTR, V43, P517
   Vetro A, 2003, IEEE SIGNAL PROC MAG, V20, P18, DOI 10.1109/MSP.2003.1184336
   Vetro A, 2001, IEEE T CIRC SYST VID, V11, P387, DOI 10.1109/76.911163
   VETRO A, 2001, P INT S CIRC SYST MA
   Werner O, 1999, IEEE T IMAGE PROCESS, V8, P179, DOI 10.1109/83.743853
   Westerink PH, 1999, IBM J RES DEV, V43, P471, DOI 10.1147/rd.434.0471
   Yim CH, 1999, IEEE T CIRC SYST VID, V9, P696, DOI 10.1109/76.780359
   YOO Y, 1995, 29 AS C SIGN SYST CO
   YU Y, 2000, P WIR COMM NETW C WC, V3, P1396
NR 37
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2005
VL 26
IS 3
BP 345
EP 363
DI 10.1007/s11042-005-0893-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 942YO
UT WOS:000230319000006
DA 2024-07-18
ER

PT J
AU Emilda, S
   Jacob, L
   Daescu, O
   Prabhakaran, B
AF Emilda, S
   Jacob, L
   Daescu, O
   Prabhakaran, B
TI Flexible strategies for disk scheduling in multimedia presentation
   servers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia servers; flexible disk scheduling; digital libraries; min-max
   skip round algorithm
AB Multimedia presentations (e.g., lectures, digital libraries) normally include discrete media objects such as text and images along with continuous media objects such as video and audio. Objects composing a multimedia presentation need to be delivered based on the temporal relationships specified by the author(s). Hence, even discrete media objects (that do not normally have any real-time characteristics) have temporal constraints on their presentations. Composition of multimedia presentations may be light (without any accompanying video or large multimedia data) or heavy (accompanied by video for the entire presentation duration). The varying nature of the composition of multimedia presentations provides some flexibility for scheduling their retrieval. In this paper, we present a min-max skip round disk scheduling strategy that can admit multimedia presentations in a flexible manner depending on their composition. We also outline strategies for storage of multimedia presentations on an array of disks as well as on multi-zone recording disks.
C1 Natl Univ Singapore, Sch Comp, Singapore 119260, Singapore.
   Univ Texas, Dept Comp Sci, Richardson, TX 75083 USA.
C3 National University of Singapore; University of Texas System; University
   of Texas Dallas
RP Natl Univ Singapore, Sch Comp, Singapore 119260, Singapore.
EM emildasi@comp.nus.edu.sg; jacobl@comp.nus.edu.sg; daescu@utdallas.edu;
   praba@utdallas.edu
CR Feng WC, 1999, IEEE T MULTIMEDIA, V1, P302, DOI 10.1109/6046.784468
   Nerjes G, 2000, MULTIMED TOOLS APPL, V11, P9, DOI 10.1023/A:1009669215773
   Rompogiannakis Y., 1998, Proceedings ACM Multimedia 98, P297, DOI 10.1145/290747.290785
   SALEHI J, 1996, P ACM SIGMETRICS 96, P222
   Shenoy PJ, 1997, PROCEEDINGS OF THE IEEE 7TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEM SUPPORT FOR DIGITAL AUDIO AND VIDEO, P25, DOI 10.1109/NOSDAV.1997.629332
   SUNDARAM V, 2001, P ACM MULT 2001 OTT, P291
   WIJAYARATNE R, 2001, P ACM MULT 2001 OTT, P270
NR 7
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2005
VL 26
IS 1
BP 81
EP 99
DI 10.1007/s11042-005-6850-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 915EU
UT WOS:000228281600004
DA 2024-07-18
ER

PT J
AU Fayzullin, M
   Subrahmanian, VS
AF Fayzullin, M
   Subrahmanian, VS
TI An algebra for PowerPoint sources
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT Workshop on Multimedia Information Systems
CY 2003
CL Ischia, ITALY
DE multimedia; databases; powerpoint; presentation; algebra
AB There are now millions of PowerPoint documents available within corporate intranets and/or over the Internet. In this paper, we develop a formal model of PowerPoint databases. We propose a relational style algebra called pptA ( PowerPoint Algebra) to query PowerPoint databases. The algebra contains some newoperators ( such as the APPLY operator that changes properties of objects, slides and presentations) as well as interesting twists on relational operators ( e. g. join and cartesian product allow different entities being joined together to share attributes whose values may be merged). We prove a set of equivalence results within this algebra. We have implemented a version of pptA - the paper provides a cost model and experimental results on the conditions under which these equivalences are useful.
C1 Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Univ Maryland, Dept Comp Sci, AV Williams Bldg, College Pk, MD 20742 USA.
EM fms@cs.umd.edu; vs@cs.umd.edu
RI Subrahmanian, Venkatramanan/ABA-7399-2021
CR Adali S, 2000, MULTIMEDIA SYST, V8, P212, DOI 10.1007/s005300000046
   LITTLE TDC, 1990, IEEE J SEL AREA COMM, V8, P413, DOI 10.1109/49.53017
   OZSU MT, 1995, MULTIMEDIA SYST, V3, P182, DOI 10.1007/BF01832136
   [No title captured]
   [No title captured]
   [No title captured]
NR 6
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2004
VL 24
IS 3
BP 273
EP 301
DI 10.1023/B:MTAP.0000039422.87260.52
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 849CL
UT WOS:000223516200006
DA 2024-07-18
ER

PT J
AU Shabaninia, E
   Nezamabadi-pour, H
   Shafizadegan, F
AF Shabaninia, Elham
   Nezamabadi-pour, Hossein
   Shafizadegan, Fatemeh
TI Multimodal action recognition: a comprehensive survey on temporal
   modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Temporal modeling; Action recognition; Deep learning; Transformer
ID NEURAL-NETWORKS; ATTENTION; LSTM; VISION; FUSION; CLASSIFICATION
AB In action recognition that relies on visual information, activities are recognized through spatio-temporal features from different modalities. The challenge of temporal modeling has been a long-standing issue in this field. There are a limited number of methods, such as pre-computed motion features, three-dimensional (3D) filters, and recurrent neural networks (RNNs), that are used in deep-based approaches to model motion information. However, the success of transformers in modeling long-range dependencies in natural language processing tasks has recently caught the attention of other domains, including speech, image, and video, as they can rely entirely on self-attention without using sequence-aligned RNNs or convolutions. Although the application of transformers to action recognition is relatively new, the amount of research proposed on this topic in the last few years is impressive. This paper aims to review recent progress in deep learning methods for modeling temporal variations in multimodal human action recognition. Specifically, it focuses on methods that use transformers for temporal modeling, highlighting their key features and the modalities they employ, while also identifying opportunities and challenges for future research.
C1 [Shabaninia, Elham] Grad Univ Adv Technol, Fac Sci & Modern Technol, Dept Appl Math, Kerman 7631818356, Iran.
   [Shabaninia, Elham; Nezamabadi-pour, Hossein] Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman 76169133, Iran.
   [Shafizadegan, Fatemeh] Univ Isfahan, Dept Comp Engn, Esfahan 8174673441, Iran.
C3 Graduate University of Advanced Technology; Shahid Bahonar University of
   Kerman (SBUK); University of Isfahan
RP Shabaninia, E (corresponding author), Grad Univ Adv Technol, Fac Sci & Modern Technol, Dept Appl Math, Kerman 7631818356, Iran.; Shabaninia, E (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, Kerman 76169133, Iran.
EM e.shabaninia@kgut.ac.ir; nezam@uk.ac.ir;
   fatemeh.shafizadegan.1990@eng.ui.ac.ir
RI Nezamabadi-pour, Hossein/I-9578-2014
OI Shabaninia, Elham/0000-0002-1357-8288
FU Iran National Science Foundation
FX No Statement Available
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ahad MdAtiqurRahman, 2019, P IEEE C COMP VIS PA, P1
   Ahn D, 2023, IEEE WINT CONF APPL, P3319, DOI 10.1109/WACV56688.2023.00333
   Al-Faris M, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060046
   Al-Faris M, 2020, PATTERN ANAL APPL, V23, P1587, DOI 10.1007/s10044-020-00886-5
   Arif S, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11020042
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF COMP V, P3179, DOI 10.1109/ICCVW.2017.376
   Asadi-Aghbolaghi M, 2017, IEEE INT CONF AUTOMA, P476, DOI 10.1109/FG.2017.150
   Bai RW, 2022, Arxiv, DOI arXiv:2109.02860
   Baradel F, 2018, BMVC 2018 29 BRIT MA, P1
   Baradel F, 2017, IEEE INT CONF COMP V, P604, DOI 10.1109/ICCVW.2017.77
   Beddiar DR, 2020, MULTIMED TOOLS APPL, V79, P30509, DOI 10.1007/s11042-020-09004-3
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Bruce XB, 2022, PAMI
   Caetano C, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909840
   Caetano C, 2019, SIBGRAPI, P16, DOI 10.1109/SIBGRAPI.2019.00011
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cardenas EE, 2018, SIBGRAPI, P95, DOI 10.1109/SIBGRAPI.2018.00019
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Carreira J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1808.01340
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Casagrande FD, 2019, COMP MED SY, P156, DOI 10.1109/CBMS.2019.00041
   Chai XJ, 2016, INT C PATT RECOG, P31, DOI 10.1109/ICPR.2016.7899603
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Chen JW, 2021, Arxiv, DOI arXiv:2108.09322
   Chen KX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447744
   Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Chen Z, 2021, AAAI CONF ARTIF INTE, V35, P1113, DOI 10.1145/3474085.3475574
   Cheng J, 2021, IEEE Transactions on Circuits and Systems for Video Technology
   Cheng Y.-B., 2021, 2021 IEEE INT C MULT
   Cheng YB, 2021, P 2 ACM INT C MULT A, P1
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Das Dawn D, 2016, VISUAL COMPUT, V32, P289, DOI 10.1007/s00371-015-1066-2
   Das Srijan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P72, DOI 10.1007/978-3-030-58545-7_5
   Das S, 2021, IEEE T PATTERN ANAL
   Das S, 2019, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2019.00092
   Das S, 2019, IEEE WINT CONF APPL, P71, DOI 10.1109/WACV.2019.00015
   Davoodikakhki Mahdi, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P291, DOI 10.1007/978-3-030-64556-4_23
   De Boissiere AM, 2020, IEEE ACCESS, V8, P168297, DOI 10.1109/ACCESS.2020.3023599
   Debnath B, 2021, INT C PATT RECOG, P5897, DOI 10.1109/ICPR48806.2021.9412487
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Diba A, 2017, PROC CVPR IEEE, P1541, DOI 10.1109/CVPR.2017.168
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan H., 2022, CVPR, P2969, DOI DOI 10.1109/CVPR52688.2022.00298
   Duan JL, 2016, Arxiv, DOI [arXiv:1611.06689, 10.48550/arXiv.1611.06689, DOI 10.48550/ARXIV.1611.06689]
   Elboushaki A, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112829
   Elmadany NE, 2018, IEEE T IMAGE PROCESS, V27, P5275, DOI 10.1109/TIP.2018.2855438
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Estevam V, 2021, NEUROCOMPUTING, V439, P159, DOI 10.1016/j.neucom.2021.01.036
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Fang YX, 2022, Arxiv, DOI arXiv:2211.07636
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Gaglio S, 2015, IEEE T HUM-MACH SYST, V45, P586, DOI 10.1109/THMS.2014.2377111
   Garcia NC, 2018, LECT NOTES COMPUT SC, V11212, P106, DOI 10.1007/978-3-030-01237-3_7
   Ge HW, 2019, MULTIMED TOOLS APPL, V78, P20533, DOI 10.1007/s11042-019-7404-z
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Girdhar R, 2017, ADV NEUR IN, V30
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   Guo GD, 2014, PATTERN RECOGN, V47, P3343, DOI 10.1016/j.patcog.2014.04.018
   Han K, 2023, IEEE T PATTERN ANAL, V45, P87, DOI 10.1109/TPAMI.2022.3152247
   He JY, 2018, IEEE GLOB CONF SIG, P439, DOI 10.1109/GlobalSIP.2018.8646404
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou YH, 2018, IEEE T CIRC SYST VID, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Hu G, 2019, IEEE INT CON MULTI, P1216, DOI 10.1109/ICME.2019.00212
   Hu JF, 2018, LECT NOTES COMPUT SC, V11211, P346, DOI 10.1007/978-3-030-01234-2_21
   Hu YC, 2019, MACH VISION APPL, V30, P851, DOI 10.1007/s00138-018-0994-z
   Huang LJ, 2019, PATTERN RECOGN, V92, P165, DOI 10.1016/j.patcog.2019.03.010
   Hussain Z, 2020, J NETW COMPUT APPL, V167, DOI 10.1016/j.jnca.2020.102738
   Pham HH, 2018, COMPUT VIS IMAGE UND, V170, P51, DOI 10.1016/j.cviu.2018.03.003
   Imran J, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P144, DOI 10.1109/ICACCI.2016.7732038
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jaegle A, 2022, Arxiv, DOI arXiv:2107.14795
   Jaegle A, 2021, PR MACH LEARN RES, V139
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jang J, 2020, IEEE INT C INT ROBOT, P10990, DOI 10.1109/IROS45743.2020.9341160
   Jegham I, 2020, FORENS SCI INT-DIGIT, V32, DOI 10.1016/j.fsidi.2019.200901
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang B, 2021, IEEE IMAGE PROC, P1089, DOI 10.1109/ICIP42928.2021.9506453
   Jianglong He, 2021, 2021 2nd Information Communication Technologies Conference (ICTC), P47, DOI 10.1109/ICTC51749.2021.9441568
   Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351
   Kalfaoglu M. Esat, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P731, DOI 10.1007/978-3-030-68238-5_48
   Kamel A, 2019, IEEE T SYST MAN CY-S, V49, P1806, DOI 10.1109/TSMC.2018.2850149
   Kangaspunta J, 2021, IEEE COMPUT SOC CONF, P1602, DOI 10.1109/CVPRW53098.2021.00176
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Ke QH, 2016, LECT NOTES COMPUT SC, V9914, P403, DOI 10.1007/978-3-319-48881-3_28
   Khaire Pushpajit, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 703), P409, DOI 10.1007/978-981-10-7895-8_32
   Khan NS, 2021, WIRELESS PERS COMMUN, V120, P1593, DOI 10.1007/s11277-021-08525-w
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kim S, 2023, Arxiv, DOI arXiv:2212.05638
   Klaser A., 2008, BMVC 2008 19 BRIT MA, P1
   Kong Y, 2022, INT J COMPUT VISION, V130, P1366, DOI 10.1007/s11263-022-01594-9
   Koot R, 2021, arXiv
   Koppula Hema, 2013, P ICML, P792
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Kozlov A, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P2074, DOI 10.1145/3341105.3373906
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai K, 2018, INT C PATT RECOG, P3451, DOI 10.1109/ICPR.2018.8545718
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li BN, 2022, AAAI CONF ARTIF INTE, P1263
   Li CK, 2017, IEEE INT CONF MULTI
   Li CK, 2017, IEEE SIGNAL PROC LET, V24, P624, DOI 10.1109/LSP.2017.2678539
   Li KC, 2024, Arxiv, DOI arXiv:2303.16058
   Li KC, 2022, Arxiv, DOI [arXiv:2211.09552, DOI 10.48550/ARXIV.2211.09552]
   Li Q, 2023, Neural Networks
   Li QM, 2020, INFORM FUSION, V63, P121, DOI 10.1016/j.inffus.2020.06.004
   Li S, 2020, Arxiv, DOI arXiv:1910.06251
   Li X., 2021, IEEE Trans Cogn Develop Syst, P1
   Li Y., 2021, arXiv
   Li YW, 2018, LECT NOTES COMPUT SC, V11210, P520, DOI 10.1007/978-3-030-01231-1_32
   Li YN, 2019, MACH VISION APPL, V30, P875, DOI 10.1007/s00138-018-0996-x
   Li YN, 2016, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2016.7899602
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Li ZF, 2019, MULTIMED TOOLS APPL, V78, P19587, DOI 10.1007/s11042-019-7356-3
   Liu BL, 2019, PATTERN RECOGN, V94, P1, DOI 10.1016/j.patcog.2019.05.020
   Liu H, 2023, IEEE Transactions on Circuits and Systems for Video Technology
   Liu H, 2017, Arxiv, DOI arXiv:1705.08106
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Liu XP, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418500337
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Liu Z., 2021, arXiv
   Liu Z, 2023, Pattern Recognit Lett
   Liu Z, 2022, PROC CVPR IEEE, P11999, DOI 10.1109/CVPR52688.2022.01170
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Ma CY, 2019, SIGNAL PROCESS-IMAGE, V71, P76, DOI 10.1016/j.image.2018.09.003
   Mahasseni B, 2016, PROC CVPR IEEE, P3054, DOI 10.1109/CVPR.2016.333
   Mahmoodi J, 2022, MULTIMED TOOLS APPL, V81, P20945, DOI 10.1007/s11042-022-12532-9
   Mahmoodi J, 2019, EXPERT SYST APPL, V127, P121, DOI 10.1016/j.eswa.2019.02.032
   Mahmud H, 2021, Arxiv, DOI [arXiv:2107.02543, 10.48550/arXiv.2107.02543, DOI 10.48550/ARXIV.2107.02543]
   Majumder S, 2021, PROC SPIE, V11736, DOI 10.1117/12.2585680
   Majumder S, 2021, IEEE SENS J, V21, P2454, DOI 10.1109/JSEN.2020.3022326
   Mazzia V, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108487
   Miao QG, 2017, IEEE INT CONF COMP V, P3047, DOI 10.1109/ICCVW.2017.360
   Michel P, 2019, ADV NEUR IN, V32
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Moutik O, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020734
   Mukherjee S, 2020, MULTIMED TOOLS APPL, V79, P19787, DOI 10.1007/s11042-020-08747-3
   Nag S, 2023, P IEEE CVF WINT C AP, P6243
   Neimark D, 2021, IEEE INT CONF COMP V, P3156, DOI [arXiv:2102.00719, 10.1109/ICCVW54120.2021.00355]
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nguyen B., 2021, Mach Learn App, V5
   Nie WZ, 2019, IEEE ACCESS, V7, P132161, DOI 10.1109/ACCESS.2019.2940281
   Obinata Y, 2021, INT C PATT RECOG, P534, DOI 10.1109/ICPR48806.2021.9412113
   Ohnishi K., 2016, P 24 ACM INT C MULT, P257, DOI DOI 10.1145/2964284.2967222
   Ott M, 2018, Arxiv, DOI arXiv:1806.00187
   Papadopoulos K, 2021, INT C PATT RECOG, P452, DOI 10.1109/ICPR48806.2021.9413189
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Piergiovanni AJ, 2021, PROC CVPR IEEE, P4122, DOI 10.1109/CVPR46437.2021.00411
   Piergiovanni AJ, 2022, arXiv
   Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7
   Plizzari Chiara, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12663), P694, DOI 10.1007/978-3-030-68796-0_50
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Prati A, 2019, J AMB INTEL SMART EN, V11, P5, DOI 10.3233/AIS-180510
   Qi CR, 2017, ADV NEUR IN, V30
   Qin XL, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P731, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00159
   Qin XL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Raffel C, 2023, Arxiv, DOI [arXiv:1910.10683, 10.48550/arXiv.1910.10683]
   Rajput AS, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113349
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Rangasamy K., 2020, Telecommun. Comput. Electron. Control, V18, P1926
   Rangrej SB, 2023, IEEE WINT CONF APPL, P3402, DOI 10.1109/WACV56688.2023.00341
   Ray A., 2023, Int J Inf Manag Data Insights, V3
   Ren B, 2024, Arxiv, DOI arXiv:2002.05907
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren ZL, 2021, NEUROCOMPUTING, V433, P142, DOI 10.1016/j.neucom.2020.12.020
   Ren ZL, 2021, MULTIMED TOOLS APPL, V80, P16185, DOI 10.1007/s11042-019-08576-z
   Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985
   Roitberg A, 2019, IEEE COMPUT SOC CONF, P198, DOI 10.1109/CVPRW.2019.00029
   Romaissa BD, 2021, INT C PATT RECOG, P5859, DOI 10.1109/ICPR48806.2021.9412863
   Ryoo Michael S., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P654, DOI 10.1007/978-3-030-58565-5_39
   Ryoo MSS, 2022, Arxiv, DOI [arXiv:2106.11297, 10.48550/arXiv.2106.11297]
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sanchez-Caballero A, 2020, Arxiv, DOI arXiv:2006.07744
   Sánchez-Caballero A, 2022, MULTIMED TOOLS APPL, V81, P24119, DOI 10.1007/s11042-022-12091-z
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shabaninia E, 2018, Multidimensional Systems and Signal Processing, P1
   Shabaninia E, 2019, MULTIMED TOOLS APPL, V78, P31319, DOI 10.1007/s11042-019-7740-z
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Sharma S, 2016, Arxiv, DOI arXiv:1511.04119
   Shen S, 2020, AAAI CONF ARTIF INTE, V34, P8815
   Shi F, 2021, Arxiv, DOI [arXiv:2107.07089, DOI 10.48550/ARXIV.2107.07089]
   Shi J, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13042058
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi ZY, 2017, PROC CVPR IEEE, P4684, DOI 10.1109/CVPR.2017.498
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A, 2021, PROC CVPR IEEE, P10384, DOI 10.1109/CVPR46437.2021.01025
   Singh R, 2020, Multimed Syst, P1
   Singh Tej, 2019, Advances in Signal Processing and Communication. Select Proceedings of ICSC 2018. Lecture Notes in Electrical Engineering (LNEE 526), P247, DOI 10.1007/978-981-13-2553-3_24
   Singh T, 2021, Multimed Tools Appl, P1
   Singh T, 2019, ARTIF INTELL REV, V52, P1107, DOI 10.1007/s10462-018-9651-1
   Smaira L., 2020, arXiv, DOI DOI 10.48550/ARXIV.2010.10864
   Song S, 2018, 2018 IEEE INT C MULT, P1
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Song XL, 2021, PROC CVPR IEEE, P9782, DOI 10.1109/CVPR46437.2021.00966
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Stergiou A, 2019, Arxiv, DOI arXiv:1909.13474
   Sudhakaran S, 2021, Arxiv, DOI arXiv:2110.02902
   Sun Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165339
   Sun ZH, 2023, IEEE T PATTERN ANAL, V45, P3200, DOI 10.1109/TPAMI.2022.3183112
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang YS, 2019, IEEE T CIRC SYST VID, V29, P3001, DOI 10.1109/TCSVT.2018.2875441
   Truong TD, 2022, PROC CVPR IEEE, P19998, DOI 10.1109/CVPR52688.2022.01940
   Tomas A, 2017, 2017 IEEE 2ND INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P41, DOI 10.1109/SIPROCESS.2017.8124502
   Tong Z, 2022, Arxiv, DOI arXiv:2203.12602
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tu J., 2018, P IEEE INT C MULT EX, V2018, DOI 10.1109/ICME.2018.8486566
   Twinanda AP, 2016, P M2CAI WORKSH MICCA, P1
   Ulhaq A, 2022, Arxiv, DOI arXiv:2209.05700
   Ullah A, 2021, NEUROCOMPUTING, V435, P321, DOI 10.1016/j.neucom.2019.12.151
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Vaswani A, 2017, ADV NEUR IN, V30
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Verma P, 2020, MULTIMEDIA SYST, V26, P671, DOI 10.1007/s00530-020-00677-2
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wang D., 2020, P IEEECVF C COMPUTER, P12695, DOI DOI 10.1109/CVPR42600.2020.01271
   Wang HS, 2017, PROC CVPR IEEE, P3633, DOI 10.1109/CVPR.2017.387
   Wang HG, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20113305
   Wang L, 2019, Arxiv, DOI arXiv:1906.09955
   Wang LM, 2023, Arxiv, DOI arXiv:2303.16727
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2013, IEEE I CONF COMP VIS, P2680, DOI 10.1109/ICCV.2013.333
   Wang LM, 2014, LECT NOTES COMPUT SC, V8693, P565, DOI 10.1007/978-3-319-10602-1_37
   Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345
   Wang PC, 2018, AAAI CONF ARTIF INTE, P7404
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   Wang PC, 2018, KNOWL-BASED SYST, V158, P43, DOI 10.1016/j.knosys.2018.05.029
   Wang PC, 2018, IEEE T MULTIMEDIA, V20, P1051, DOI 10.1109/TMM.2018.2818329
   Wang PC, 2017, IEEE INT CONF COMP V, P1005, DOI 10.1109/ICCVW.2017.123
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YC, 2020, PROC CVPR IEEE, P508, DOI 10.1109/CVPR42600.2020.00059
   Wang Y, 2022, Arxiv, DOI arXiv:2212.03191
   Wang YL, 2016, Arxiv, DOI arXiv:1607.06416
   Wang YQ, 2021, PROC CVPR IEEE, P8737, DOI 10.1109/CVPR46437.2021.00863
   Wei C, 2022, PROC CVPR IEEE, P14648, DOI 10.1109/CVPR52688.2022.01426
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu D, 2016, IEEE T PATTERN ANAL, V38, P1583, DOI 10.1109/TPAMI.2016.2537340
   Wu HB, 2021, IEEE T CIRCUITS SYST
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xiao Y, 2019, INFORM SCIENCES, V480, P287, DOI 10.1016/j.ins.2018.12.050
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xin W, 2023, Neurocomputing
   Xu CW, 2020, Arxiv, DOI arXiv:2002.02925
   Xu ZY, 2020, IEEE ACCESS, V8, P213038, DOI 10.1109/ACCESS.2020.3038235
   Yadav SK, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.106970
   Yan S, 2022, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR52688.2022.00333
   Yan SJ, 2018, Arxiv, DOI [arXiv:1801.07455, DOI 10.1609/AAAI.V32I1.12328, 10.48550/ARXIV.1801.07455]
   Yang D., 2021, Unik: A unified framework for real-world skeleton-based action recognition
   Yang D, 2020, Arxiv, DOI arXiv:2003.03007
   Yang JW, 2022, PROC CVPR IEEE, P14043, DOI 10.1109/CVPR52688.2022.01367
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Ye FF, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P55, DOI 10.1145/3394171.3413941
   Yu X, 2020, Complexity 2020
   Yuan L., 2021, arXiv
   Yuanyuan S., 2021, Virt Real Intell Hardw, V3, P183, DOI [DOI 10.1016/J.VRIH.2021.05.001, 10.1016/j.vrih.2021.05.001]
   Yurur O, 2014, IEEE COMMUN MAG, V52, P24, DOI 10.1109/MCOM.2014.6829941
   Zellers R, 2022, PROC CVPR IEEE, P16354, DOI 10.1109/CVPR52688.2022.01589
   Zhang B, 2021, arXiv
   Zhang HK, 2018, Arxiv, DOI [arXiv:1811.09908, 10.48550/arXiv.1811.09908, DOI 10.48550/ARXIV.1811.09908]
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang J, 2016, PATTERN RECOGN, V60, P86, DOI 10.1016/j.patcog.2016.05.019
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhang SY, 2018, IEEE T MULTIMEDIA, V20, P2330, DOI 10.1109/TMM.2018.2802648
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
   Zhang YH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3229, DOI 10.1145/3474085.3475473
   Zhao BT, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062217
   Zhao C, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040716
   Zheng W, 2019, IEEE INT CON MULTI, P826, DOI 10.1109/ICME.2019.00147
   Zhou B., 2021, Virt Real Intell Hardw, V3, P235
   Zhou BJ, 2021, Arxiv, DOI arXiv:2102.05348
   Zhu F, 2016, Image Vis Comput
   Zhu GM, 2016, INT C PATT RECOG, P19, DOI 10.1109/ICPR.2016.7899601
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
   Zhu JG, 2018, Arxiv, DOI arXiv:1812.05770
   Zhu J, 2013, IEEE I CONF COMP VIS, P3559, DOI 10.1109/ICCV.2013.442
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
   Zhu Y, 2020, Arxiv, DOI [arXiv:2012.06567, 10.48550/arXiv.2012.06567]
NR 309
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17345-y
EA DEC 2023
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000011
DA 2024-07-18
ER

PT J
AU Tyagi, S
   Szénási, S
AF Tyagi, Suryakant
   Szenasi, Sandor
TI Semantic speech analysis using machine learning and deep learning
   techniques: a comprehensive review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Emotion extraction; Speech; Machine learning; Data analysis; Artificial
   neural networks; Long-short term memory; Convolutional neural networks
ID EMOTION RECOGNITION; NEURAL-NETWORKS; FEATURES; CLASSIFICATION;
   DATABASES; MODELS; MFCC
AB Human cognitive functions such as perception, attention, learning, memory, reasoning, and problem-solving are all significantly influenced by emotion. Emotion has a particularly potent impact on attention, modifying its selectivity in particular and influencing behavior and action motivation. Artificial Emotional Intelligence (AEI) technologies enable computers to understand a user's emotional state and respond appropriately. These systems enable a realistic dialogue between people and machines. The current generation of adaptive user interference technologies is built on techniques from data analytics and machine learning (ML), namely deep learning (DL) artificial neural networks (ANN) from multimodal data, such as videos of facial expressions, stance, and gesture, voice, and bio-physiological data (such as eye movement, ECG, respiration, EEG, FMRT, EMG, eye tracking). In this study, we reviewed existing literature based on ML and data analytics techniques being used to detect emotions in speech. The efficacy of data analytics and ML techniques in this unique area of multimodal data processing and extracting emotions from speech. This study analyzes how emotional chatbots, facial expressions, images, and social media texts can be effective in detecting emotions. PRISMA methodology is used to review the existing survey. Support Vector Machines (SVM), Naive Bayes (NB), Random Forests (RF), Recurrent Neural Networks (RNN), Logistic Regression (LR), etc., are commonly used ML techniques for emotion extraction purposes. This study provides a new taxonomy about the application of ML in SER. The result shows that Long-Short Term Memory (LSTM) and Convolutional Neural Networks (CNN) are found to be the most useful methodology for this purpose.
C1 [Tyagi, Suryakant; Szenasi, Sandor] Obuda Univ, Doctoral Sch Appl Informat & Appl Math, H-1034 Budapest, Hungary.
   [Szenasi, Sandor] Obuda Univ, John von Neumann Fac Informat, H-1034 Budapest, Hungary.
   [Szenasi, Sandor] J Selye Univ, Fac Econ & Informat, Komarno 94501, Slovakia.
C3 Obuda University; Obuda University; J. Selye University
RP Tyagi, S (corresponding author), Obuda Univ, Doctoral Sch Appl Informat & Appl Math, H-1034 Budapest, Hungary.
EM suryatyagi10000@gmail.com; szenasi.sandor@nik.uni-obuda.hu
FU buda University
FX No Statement Available
CR Akçay MB, 2020, SPEECH COMMUN, V116, P56, DOI 10.1016/j.specom.2019.12.001
   Al Dabel M, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/3732442
   Al-Makhadmeh Z, 2020, COMPUTING, V102, P501, DOI 10.1007/s00607-019-00745-0
   Al-onazi BB, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12189188
   Alim S. A., 2018, IntechOpen
   Aljarah I, 2021, J INF SCI, V47, P483, DOI 10.1177/0165551520917651
   Alnuaim AA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/7463091
   Alnuaim AA, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/6005446
   Anagnostou M, 2022, ETHICS INF TECHNOL, V24, DOI 10.1007/s10676-022-09634-1
   [Anonymous], 2011, P ICML
   Araque O, 2022, COGN COMPUT, V14, P48, DOI 10.1007/s12559-021-09845-6
   Azman Noramira Fatehah., 2022, Proceedings, V82, P29
   Barros P, 2016, IEEE IJCNN, P921, DOI 10.1109/IJCNN.2016.7727297
   Basel D, 2022, BEHAV THER, V53, P182, DOI 10.1016/j.beth.2021.07.001
   Batliner A, 2011, COGN TECHNOL, P71, DOI 10.1007/978-3-642-15184-2_6
   Bee N., 2010, International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction, P1
   Nguyen TB, 2019, Arxiv, DOI arXiv:1910.05608
   Bodnar T, 2014, IEEE INT CONF BIG DA, P636, DOI 10.1109/BigData.2014.7004286
   Boyd RL, 2021, J LANG SOC PSYCHOL, V40, P21, DOI [10.1177/0261927x20967028, 10.1177/0261927X20967028]
   Butt S., 2021, Iberian languages evaluation forum, P381
   Chen M, 2022, ACM T INTERNET TECHN, V22, DOI 10.1145/3471902
   Chen M, 2017, IEEE ACCESS, V5, P326, DOI 10.1109/ACCESS.2016.2641480
   Chourasia Mayank, 2021, Intelligent Data Communication Technologies and Internet of Things. Proceedings of ICICI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 57), P471, DOI 10.1007/978-981-15-9509-7_39
   Corazza M, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3377323
   Costanzi Marco, 2019, Front Psychol, V10, P2587, DOI 10.3389/fpsyg.2019.02587
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   CUMMINS J, 1979, REV EDUC RES, V49, P222, DOI 10.2307/1169960
   Cummins N, 2015, SPEECH COMMUN, V75, P27, DOI 10.1016/j.specom.2015.09.003
   Das AK, 2021, J INTELL SYST, V30, P578, DOI 10.1515/jisys-2020-0060
   Del Vigna F., 2017, P 1 IT C CYB ITASEC1, P86
   Demircan S., 2014, Journal of Advances in Computer Networks, V2, P34, DOI 10.7763/JACN.2014.V2.76
   Deng L., 2014, FOND T SIGN PROC, V7, P197, DOI [10.1561/2000000039, DOI 10.1561/2000000039, 10.1561/]
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Dhawan M., 2020, Int Res J Eng Technol, V7, P3905
   Dong BW, 2021, NANO ENERGY, V79, DOI 10.1016/j.nanoen.2020.105414
   Dubey H, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON CONNECTED HEALTH: APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P78, DOI 10.1109/CHASE.2016.46
   Le D, 2017, INTERSPEECH, P1108, DOI 10.21437/Interspeech.2017-94
   Dybala MPP., P LING COGN APPR DIA
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Emerich S, 2013, DIGIT SIGNAL PROCESS, V23, P928, DOI 10.1016/j.dsp.2012.11.003
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Fu LQ, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P61, DOI 10.1109/ICALIP.2008.4590144
   Ganapathy A., 2016, ABC J ADV RES, V5, P113, DOI [10.18034/abcjar.v5i2.550, DOI 10.18034/ABCJAR.V5I2.550]
   Garcia-Garcia J.M., 2017, ACM INT C P SER OCT, P1, DOI [10.1145/3123818.3123852, DOI 10.1145/3123818.3123852, 10.1145/3123818, DOI 10.1145/3123818]
   Gaydhani A, 2018, Arxiv, DOI arXiv:1809.08651
   Gharavian D, 2012, NEURAL COMPUT APPL, V21, P2115, DOI 10.1007/s00521-011-0643-1
   Gitari N. D., 2015, INT J MULTIMEDIA UBI, V10, P215, DOI DOI 10.14257/IJMUE.2015.10.4.21
   Gnanamanickam J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21217025
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Han J, 2017, INT CONF ACOUST SPEE, P5005, DOI 10.1109/ICASSP.2017.7953109
   Hansen JHL, 2012, FORENSIC SPEAKER RECOGNITION: LAW ENFORCEMENT AND COUNTER-TERRORISM, P103, DOI 10.1007/978-1-4614-0263-3_5
   Hemanth Kumar H. S., 2021, Proceedings of the Third International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV 2020), P1332, DOI 10.1109/ICICV50876.2021.9388522
   Higgins JPT., 2019, COCHRANE HDB SYSTEMA, P143, DOI DOI 10.1002/9781119536604.CH6
   Huang C., 2014, Math Probl Eng, V2014, P1
   Ingale AB., 2012, Int J Adv Eng Res Stud, V1, P316
   Jackson P., 2014, Surrey audio-visual expressed emotion (savee) database
   Jahangir R, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-022-01294-x
   Javed Nazura, 2022, Proceedings of the 2nd International Conference on Recent Trends in Machine Learning, IoT, Smart Cities and Applications: ICMISC 2021. Lecture Notes in Networks and Systems (237), P133, DOI 10.1007/978-981-16-6407-6_13
   Jin Q., 2007, IEEE Transact Audio, Speech, Lang Process, V15, P1737, DOI [10.1109/TASL.2007.902159, DOI 10.1109/TASL.2007.902159]
   Jokinen E, 2014, COMPUT SPEECH LANG, V28, P619, DOI 10.1016/j.csl.2013.03.005
   Joshi J, 2013, J MULTIMODAL USER IN, V7, P217, DOI 10.1007/s12193-013-0123-2
   Jougleux P., 2022, Facebook and the (EU) law, P183, DOI [10.1007/978-3-031-06596-5_7, DOI 10.1007/978-3-031-06596-5_7]
   Kamble VV, 2015, ADV INTELL SYST, V328, P335, DOI 10.1007/978-3-319-12012-6_37
   Kandali AB, 2009, INT J SPEECH TECHNOL, V12, P1, DOI 10.1007/s10772-009-9046-4
   Kapoor S, 2023, MULTIMED TOOLS APPL, V82, P9413, DOI 10.1007/s11042-022-13731-0
   Karadayi J., 2021, arXiv
   Kaur AP, 2023, MULTIMED TOOLS APPL, V82, P13307, DOI 10.1007/s11042-022-13645-x
   Khalil RA, 2019, IEEE ACCESS, V7, P117327, DOI 10.1109/ACCESS.2019.2936124
   Khan S, 2022, IEEE ACCESS, V10, P7881, DOI 10.1109/ACCESS.2022.3143799
   Kishore KVK, 2013, IEEE INT ADV COMPUT, P842
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P99, DOI 10.1007/s10772-011-9125-1
   Kumar K., 2022, Cyber Security and Digital Forensics, P295
   Kumar GSS, 2022, COMPUTERS, V11, DOI 10.3390/computers11100152
   Kwon OW., 2003, Emotion recognition by speech signals, DOI [10.21437/Eurospeech.2003-80, DOI 10.21437/EUROSPEECH.2003-80]
   Latif S, 2018, Arxiv, DOI [arXiv:1811.11402, 10.48550/arXiv.1811.11402]
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee CM, 2005, IEEE T SPEECH AUDI P, V13, P293, DOI 10.1109/TSA.2004.838534
   Lee ERS, 2022, IEEE ACCESS, V10, P9717, DOI 10.1109/ACCESS.2022.3144266
   Li Wern Chew, 2011, 2011 Third International Conference on Computational Intelligence, Modelling and Simulation, P210, DOI 10.1109/CIMSim.2011.44
   Li Y., 2021, Dual-attention generative adversarial network and flame and smoke analysis. PhD diss
   Lin SY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.102872
   Liqin Fu, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P140, DOI 10.1109/PACIIA.2008.355
   Lugovic S, 2016, 2016 39TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1278, DOI 10.1109/MIPRO.2016.7522336
   Lutsiv N, 2022, CMC-COMPUT MATER CON, V70, P413, DOI 10.32604/cmc.2022.018773
   Mahdhaoui A, 2011, SPEECH COMMUN, V53, P1149, DOI 10.1016/j.specom.2011.05.005
   Malik Pranav, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1254, DOI 10.1109/ICCMC51019.2021.9418395
   Mao QR, 2016, INT CONF ACOUST SPEE, P2608, DOI 10.1109/ICASSP.2016.7472149
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Mariz J.L.V., 2022, Adv. Anal. Min. Eng. Leverage Adv. Anal. Min. Ind. to Make Better Bus. Decis., P363, DOI [10.1007/978-3-030-91589-613, DOI 10.1007/978-3-030-91589-613]
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Matveev Y, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10142373
   Mohammed MA, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113723
   Mohanty Ajit., 2019, The Multilingual Reality: Living with Languages
   Morgan N, 2012, IEEE T AUDIO SPEECH, V20, P7, DOI 10.1109/TASL.2011.2116010
   Mower E, 2011, IEEE T AUDIO SPEECH, V19, P1057, DOI 10.1109/TASL.2010.2076804
   Mutanga RT, 2022, INT J ADV COMPUT SC, V13, P331
   Nalini NJ, 2016, EGYPT INFORM J, V17, P1, DOI 10.1016/j.eij.2015.05.004
   Narayanan SS, 2017, arXiv
   Nassif AB, 2022, INFORMATION, V13, DOI 10.3390/info13100456
   Negenborn RR, 2009, NETW HETEROG MEDIA, V4, P359, DOI 10.3934/nhm.2009.4.359
   Nevendra M, 2021, ACTA POLYTECH HUNG, V18, P173
   Noroozi F, 2017, SIG PROCESS COMMUN
   Ozdamli F, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su142013230
   Pan Yixiong, 2012, International Journal of Smart Home, V6, P101, DOI DOI 10.5120/431-636
   Patel N, 2022, J AMB INTEL HUM COMP, V13, P867, DOI 10.1007/s12652-021-02979-3
   Patel P, 2017, IRA-International J Technol Eng, V7, P56, DOI 10.21013/jte.ICSESD201706
   Petsatodis T, 2011, IEEE T AUDIO SPEECH, V19, P2314, DOI 10.1109/TASL.2011.2131131
   Picard Rosalind W., 1995, Affective Computing
   Pierre-Yves O, 2003, INT J HUM-COMPUT ST, V59, P157, DOI 10.1016/S1071-5819(03)00141-6
   Rajput K, 2020, ALGO INTELL SY, P159, DOI 10.1007/978-981-15-1216-2_7
   Rani S, 2022, Expert Syst Appl
   Riya KS., 2022, INT C ADV COMP TECHN, P10
   Rodrigues AP, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5211949
   Rong J, 2009, INFORM PROCESS MANAG, V45, P315, DOI 10.1016/j.ipm.2008.09.003
   Roy PK, 2022, COMPUT SPEECH LANG, V75, DOI 10.1016/j.csl.2022.101386
   Rudramurthy MS, 2014, J INTELL SYST, V23, P359, DOI 10.1515/jisys-2013-0085
   Rui Cao, 2020, WebSci '20: 12th ACM Conference on Web Science, P11, DOI 10.1145/3394231.3397890
   Sai Siva, 2022, SN Computer Science, V3, P1, DOI DOI 10.1007/S42979-021-01007-7
   Sajjad Muhammad, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P251, DOI 10.1109/ICAEM.2019.8853762
   Salovey P., 2007, Feelings and emotions: the Amsterdam symposium, P321
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Selvan AK., 2022, Int J Inform Technol, V15, P1
   Sezgin M., 2012, EURASIP J Audio, Speech, Music Process, V1, P1
   Singh C, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12083709
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Steidl S., 2005, IEEE INT C ACOUSTICS, P1
   Stoll S, 2020, INT J COMPUT VISION, V128, P891, DOI 10.1007/s11263-019-01281-2
   Stuhlsatz A, 2011, INT CONF ACOUST SPEE, P5688
   Sun SL, 2017, INFORM FUSION, V36, P10, DOI 10.1016/j.inffus.2016.10.004
   Sztahó D, 2014, INTELL DECIS TECHNOL, V8, P315, DOI 10.3233/IDT-140199
   Tolksdorf NF, 2021, INT J SOC ROBOT, V13, P129, DOI 10.1007/s12369-020-00622-3
   Toraman C., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2203.01111, 10.48550/arXiv.2203.01111]
   Vázquez-Romero A, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22060688
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Vogt T, 2010, Real-time automatic emotion recognition from speech
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wang Y, 2022, INFORM FUSION, V83, P19, DOI 10.1016/j.inffus.2022.03.009
   Wani TM, 2021, IEEE ACCESS, V9, P47795, DOI 10.1109/ACCESS.2021.3068045
   Wen GH, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/1945630
   Yadav Jainath, 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045735
   Yan LM, 2016, LECT NOTES COMPUT SC, V10040, P623, DOI 10.1007/978-3-319-48674-1_55
   Yanase J, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.112821
   Zeighami M, 2023, SEX RES SOC POLICY, V20, P575, DOI 10.1007/s13178-022-00688-w
   Zhang L, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1253
   Zhang S, 2015, P 29 PAC AS C LANG I, P73, DOI DOI 10.18653/V1/P16-2034
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhang YC, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104157
   Zhang Y, 2017, INT CONF ACOUST SPEE, P4990, DOI 10.1109/ICASSP.2017.7953106
   Zhu Q, 2022, ALGORITHMS, V15, DOI 10.3390/a15020068
   Zhu X, 2022, KNOWL-BASED SYST, V235, DOI 10.1016/j.knosys.2021.107436
   Zimmerman S, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P2546
NR 153
TC 0
Z9 0
U1 26
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 19
PY 2023
DI 10.1007/s11042-023-17769-6
EA DEC 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7T2
UT WOS:001126521200015
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, XW
   Jiang, X
   Guo, SH
   Lin, JC
   Liao, MH
   Fan, HL
   Zhang, YW
   Luo, GL
AF Chen, Xiaowei
   Jiang, Xiao
   Guo, Shihui
   Lin, Juncong
   Liao, Minghong
   Fan, Hongli
   Zhang, Yiwen
   Luo, Guoliang
TI RehabFAB: design investigation and needs assessment of
   displacement-orientated fabric wearable sensors for rehabilitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Soft sensors; Fabric sensors; Motion tracking; Rehabilitation; Motor
   impairment
ID STROKE PATIENTS; STRAIN SENSORS; SYSTEM
AB Patients with motor impairments (e.g., stroke, bone fracture, Parkinson's) are sensitive to the wearing experience of rehabilitation devices, and they often have difficulty accurately positioning them at an accurate position. While solutions involving optical systems or IMUs could potentially help alleviate the issue, they often introduce other challenges such as privacy concerns or discomforting experiences. With the emergence of wearable soft sensors during the last few decades, researchers widely apply soft sensors in rehabilitation to improve the wearing experience. However, these approaches have primarily focused on analyzing the sensor readings to improve accuracy rather than addressing the needs of patients and healthcare providers, and there is a lack of comprehensive design investigation and need assessment based on soft sensor-based rehabilitation systems for motor-impaired patients and their doctors. In this study, we developed an application, RehabFAB, utilizing fabric sensors for rehabilitation purposes. Besides, we evaluated our application and device and investigated the needs of patients and doctors for potential home rehabilitation applications. The investigation was conducted through thematic analysis, correlation analysis and System Usability Scale. The experimental results validated the efficacy, reliability and usability of our approach, with a SUS score of 81.75. In addition, the RehabFAB meets the expectations of motor-impaired patients and medical professionals as a home rehabilitation tool. Our core contributions lie in a thorough evaluation of the needs of motor-impaired patients in order to design a stable and reliable motion-tracking device based on soft sensors for their recovery.
C1 [Chen, Xiaowei; Jiang, Xiao; Guo, Shihui; Lin, Juncong; Liao, Minghong] Xiamen Univ, Sch Informat, 422 Siming South Rd, Xiamen 361005, Fujian, Peoples R China.
   [Fan, Hongli] Xiamen Haicang Hosp, Dept Rehabil Med, 89 Haiyu Rd, Xiamen 361026, Fujian, Peoples R China.
   [Zhang, Yiwen] Xiamen Med Coll, Dept Neurol, Affiliated Hosp 2, 566 Shengguang Rd, Xiamen 361021, Fujian, Peoples R China.
   [Luo, Guoliang] East China Jiao Tong Univ, Virtual Real & Interact Technol Inst, 808 Shuanggang Rd, Nanchang 330013, Jiangxi, Peoples R China.
C3 Xiamen University; Xiamen Medical College; East China Jiaotong
   University
RP Lin, JC (corresponding author), Xiamen Univ, Sch Informat, 422 Siming South Rd, Xiamen 361005, Fujian, Peoples R China.
EM jclin@xmu.edu.cn
FU National Natural Science Foundation of China [62072383, 61702433,
   62077039, 61962021]; National Natural Science Foundation of China
   [20720210044, 20720190006]; Fundamental Research Funds for the Central
   Universities [20223BBE51039, 20232BBE50020]; Research and Development
   Program of Jiangxi Province [20232ACB212007]; Science Fund for
   Distinguished Young Scholars of Jiangxi Province [2022D022]; Leading
   Project of Fujian Provincial Science and Technology Department
FX This work was supported by National Natural Science Foundation of China
   (62072383, 61702433, 62077039, 61962021), the Fundamental Research Funds
   for the Central Universities (20720210044, 20720190006), Research and
   Development Program of Jiangxi Province (20223BBE51039,
   20232BBE50020),Science Fund for Distinguished Young Scholars of Jiangxi
   Province (20232ACB212007) and Leading Project of Fujian Provincial
   Science and Technology Department (project name: Application of Flexible
   Sensor Based Motion Capture Clothing in Stroke Rehabilitation; grant
   number: 2022D022).
CR Adans-Dester C, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00328-w
   Al-Qazzaz NK, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104799
   Alvarez JT, 2022, IEEE T NEUR SYS REH, V30, P2198, DOI 10.1109/TNSRE.2022.3196501
   Bader P, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3310275
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Bartlett NW, 2015, J MED DEVICES, V9, DOI 10.1115/1.4030554
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brooke John., 1996, Usability evaluation in industry, V189, P4, DOI DOI 10.1201/9781498710411
   Capela NA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124414
   Chen XS, 2021, IEEE T IND INFORM, V17, P943, DOI 10.1109/TII.2020.3010369
   Chen XW, 2023, PROC ACM INTERACT MO, V7, DOI 10.1145/3580832
   Chen YL, 2020, IEEE J TRANSL ENG HE, V8, DOI 10.1109/JTEHM.2020.2981926
   Chossat JB, 2015, IEEE INT CONF ROBOT, P2568, DOI 10.1109/ICRA.2015.7139544
   Chu CY, 2018, J NEUROENG REHABIL, V15, DOI 10.1186/s12984-018-0350-6
   Ciesla N., 2011, J VIS EXP, V50, pe2632
   Dai YC, 2023, ACM T SENSOR NETWORK, V19, DOI 10.1145/3522739
   Dash A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00228
   de Lucena DS, 2017, INT C REHAB ROBOT, P1603, DOI 10.1109/ICORR.2017.8009477
   De Vito L, 2014, IEEE INSTRU MEAS MAG, V17, P30, DOI 10.1109/MIM.2014.6825386
   Dovat L, 2008, IEEE T NEUR SYS REH, V16, P582, DOI 10.1109/TNSRE.2008.2010347
   Fang CM, 2020, BIOSENSORS-BASEL, V10, DOI 10.3390/bios10080085
   Fang J, 2020, SOFT ROBOT, V7, P95, DOI 10.1089/soro.2018.0155
   Ferraris C, 2014, P 9 INT C BODY AREA, P76
   Foundation P, 2023, Understanding parkinson's
   Gao JF, 2019, CHEM ENG J, V373, P298, DOI 10.1016/j.cej.2019.05.045
   Gash MC, 2022, StatPearls
   Glauser O, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322957
   Healthline, 2022, Periarthritis
   Kaku A, 2020, PR MACH LEARN RES, V126, P143
   Kantak SS, 2022, PHYS THER, V102, DOI 10.1093/ptj/pzab289
   Khan MA, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/ac36aa
   Khokhlova L, 2021, INT C WEARABLES HEAL, P70
   Kumar V., 2014, Robbins & Cotran Pathologic Basis of Disease
   Kytö M, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300612
   Lang CE, 2017, JOVE-J VIS EXP, DOI 10.3791/55673
   Lee SI, 2018, IEEE J TRANSL ENG HE, V6, DOI 10.1109/JTEHM.2018.2829208
   Leuenberger K, 2017, MED BIOL ENG COMPUT, V55, P141, DOI 10.1007/s11517-016-1496-7
   Li FG, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8010083
   Maceira-Elvira P, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0612-y
   Mayer T., 2003, SPINE J, V3, P28
   Meng Q, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1166-z
   Michielsen ME, 2012, ARCH PHYS MED REHAB, V93, P1975, DOI 10.1016/j.apmr.2012.03.016
   Mohebbi A., 2020, Curr. Robot. Rep., V1, P131, DOI [10.1007/s43154-020-00015-4, DOI 10.1007/S43154-020-00015-4]
   Monoli C, 2021, IEEE SENS J, V21, P11192, DOI 10.1109/JSEN.2021.3061623
   Oguntosin V, 2015, INT C REHAB ROBOT, P747, DOI 10.1109/ICORR.2015.7281291
   Park YL, 2014, BIOINSPIR BIOMIM, V9, DOI 10.1088/1748-3182/9/1/016007
   Pastor I, 2012, IEEE ENG MED BIO, P1286, DOI 10.1109/EMBC.2012.6346173
   Patel S, 2012, J NEUROENG REHABIL, V9, DOI 10.1186/1743-0003-9-21
   physio.co.uk, 2023, Arthrolysis
   Qassim HM, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10196976
   Reinkensmeyer DJ., 1996, TECHNOL DISABIL, V5, P205
   Roberts JC, 2016, IEEE T VIS COMPUT GR, V22, P419, DOI 10.1109/TVCG.2015.2467271
   Ruibo Liu, 2019, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V3, DOI 10.1145/3314406
   Ruiz a.F., 2006, Proc. First IEEE/RAS-EMBS Int. Conf. Biomed. Robot. Biomechatronics, 2006, V2006, P601
   Tinazzi M, 2021, EUR J NEUROL, V28, P1752, DOI 10.1111/ene.14674
   Tognetti A, 2014, J NEUROENG REHABIL, V11, DOI 10.1186/1743-0003-11-56
   Van Meulen FB, 2016, FRONT BIOENG BIOTECH, V3, DOI 10.3389/fbioe.2015.00210
   Vu CC., 2020, Sens Actuator A Phys, V314, P029
   Waller SM, 2008, NEUROREHABILITATION, V23, P29
   WIKIPEDIA, 2023, Wikipedia
   WIKIPEDIA, 2022, Cerebral infarction
   WIKIPEDIA, 2022, Dorland's medical reference works
   WIKIPEDIA, 2023, Hemiparesis
   WIKIPEDIA, 2022, Spasm
   WIKIPEDIA, 2022, Thrombosis
   Xsens, 2023, Xsens, the leading innovator in 3d motion tracking technology
   Yu M, 2021, IEEE SENS J, V21, P25400, DOI 10.1109/JSEN.2021.3087005
   Zhang T, 2019, ADV MATER TECHNOL-US, V4, DOI 10.1002/admt.201900679
   Zhao YF, 2021, IEEE SENS J, V21, P26311, DOI 10.1109/JSEN.2021.3058429
   Zheng MD, 2022, IEEE SENS J, V22, P9198, DOI 10.1109/JSEN.2022.3165988
   Zhu ZG, 2021, IEEE SENS J, V21, P22976, DOI 10.1109/JSEN.2021.3091004
NR 71
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17726-3
EA DEC 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L6
UT WOS:001155145800006
DA 2024-07-18
ER

PT J
AU Raghuvanshi, A
   Budhia, M
   Patro, KAK
   Acharya, B
AF Raghuvanshi, Ankita
   Budhia, Muskan
   Patro, K. Abhimanyu Kumar
   Acharya, Bibhudendra
TI FSR-SPD: an efficient chaotic multi-image encryption system based on
   flip-shift-rotate synchronous-permutation-diffusion operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Security; Multiple image encryption; Flip-shift-rotate;
   Synchronous-permutation-diffusion; Hash algorithm; 1D chaotic maps
ID MULTIPLE-IMAGE ENCRYPTION; WAVELET TRANSFORM; ALGORITHM
AB Images are a crucial component in contemporary data transmission. Numerous images are transmitted daily through the open-source network. This paper presents a multi-image encryption scheme that utilises flip-shift-rotate synchronous-permutation-diffusion (FSR-SPD) processes to ensure the security of multiple images in a single encryption operation. The proposed encryption technique distinguishes itself from current multi-image encryption methods by utilising SPD operation and rapid FSR-based pixel-shuffling and diffusion operation. The SPD is a cryptographic technique that involves the simultaneous application of permutation and diffusion methods. The FSR-based process involves the manipulation of pixels through three different operations, namely flipping, shifting, and rotating. In the process of encryption, the image components of red, green, and blue colours are merged into a single composite image. The large image is partitioned into non-overlapping blocks of uniform size. The SPD technique is employed to tackle each specific block. The encryption method is efficient and expeditious as it exhibits high performance with both FSR and SPD procedures. The method employs a single, fixed-type, one-dimensional, piecewise linear chaotic map (PWLCM) for both the permutation and diffusion phases, resulting in high efficiency in both software and hardware. The proposed method is assessed using key space, histogram variance, neighbouring pixel correlation, information entropy, and computational complexity. The proposed method has a much bigger key space than the comparative method. Compared to comparison approaches, the suggested solution reduces encrypted picture histogram variance by 6.22% and neighbouring pixel correlations by 77.78%. Compared to the comparison technique, the proposed scheme has a slightly higher information entropy of 0.0025%. Other multiple-color image encryption methods are more computationally intensive than the suggested method. Computer simulations, security analysis, and comparison analysis evaluated the proposed methodology. The results show it outperforms multiple images encrypting methods.
C1 [Raghuvanshi, Ankita; Budhia, Muskan; Acharya, Bibhudendra] Natl Inst Technol Raipur, Dept Elect & Commun Engn, Raipur 492010, Chhattisgarh, India.
   [Patro, K. Abhimanyu Kumar] Manipal Acad Higher Educ, Manipal Inst Technol, Dept Mechatron, Manipal 576104, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; Manipal Academy of Higher Education (MAHE)
RP Patro, KAK (corresponding author), Manipal Acad Higher Educ, Manipal Inst Technol, Dept Mechatron, Manipal 576104, Karnataka, India.
EM ankitaraghu98@gmail.com; muskanbudhia1704@gmail.com;
   abhimanyu.patro@manipal.edu; bacharya.etc@nitrr.ac.in
OI Patro, K Abhimanyu Kumar/0000-0001-7807-7874; Acharya,
   Bibhudendra/0000-0001-7233-7591
FU Manipal Academy of Higher Education, Manipal
FX No Statement Available
CR Abdelfatah RI, 2020, MULTIMED TOOLS APPL, V79, P1241, DOI 10.1007/s11042-019-08234-4
   Al-Zubaidie M, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/3263902
   [Anonymous], 1977, USC SIPI IMAGE DATAB
   Ansari N, 2016, PROCEDIA COMPUT SCI, V78, P125, DOI 10.1016/j.procs.2016.02.021
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Arora S, 2009, COMPUTATIONAL COMPLEXITY: A MODERN APPROACH, P1, DOI 10.1017/CBO9780511804090
   Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Chen X., 2017, Biomed Res, V28, P9001
   Chen Z., 2022, Journal of Computational and Cognitive Engineering, V1, P103, DOI [10.47852/bonviewJCCE149145205514, DOI 10.47852/BON, DOI 10.47852/BONVIEWJCCE149145205514]
   COOPERSMITH D, 1994, IBM J RES DEV, V38, P243, DOI 10.1147/rd.383.0243
   Das S, 2023, IEEE T IND INFORM, V19, P821, DOI 10.1109/TII.2022.3167842
   El-Latif AAA, 2012, SENS IMAGING, V13, P67, DOI 10.1007/s11220-012-0071-z
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   Hassan FS, 2022, CAAI T INTELL TECHNO, V7, P56, DOI 10.1049/cit2.12053
   IEEE Computer Society Standards Committee, 1985, IEEE standard for binary floating-point arithmetic, V754
   Inoue K, 2021, J VIS COMMUN IMAGE R, V79, DOI 10.1016/j.jvcir.2021.103251
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Kong DZ, 2013, APPL OPTICS, V52, P2619, DOI 10.1364/AO.52.002619
   Kumar P, 2023, MOBILE NETW APPL, DOI 10.1007/s11036-023-02158-y
   Lai Q, 2023, APPL MATH COMPUT, V442, DOI 10.1016/j.amc.2022.127738
   Lai Q, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118845
   Li CL, 2018, OPTIK, V171, P277, DOI 10.1016/j.ijleo.2018.06.029
   Li DH, 2023, NONLINEAR DYNAM, V111, P2917, DOI 10.1007/s11071-022-07949-8
   Li HM, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102844
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LD, 2021, J INF SECUR APPL, V60, DOI 10.1016/j.jisa.2021.102854
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Lu Q, 2020, IEEE ACCESS, V8, P25664, DOI 10.1109/ACCESS.2020.2970806
   Namasudra S, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.108048
   Nkandeu YPK, 2019, MULTIMED TOOLS APPL, V78, P10013, DOI 10.1007/s11042-018-6612-2
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Patro K. Abhimanyu Kumar, 2020, Advances in Data and Information Sciences. Proceedings of ICDIS 2019. Lecture Notes in Networks and Systems (LNNS 94), P67, DOI 10.1007/978-981-15-0694-9_8
   Patro KAK, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102470
   Patro KAK, 2019, MICROSYST TECHNOL, V25, P4593, DOI 10.1007/s00542-019-04395-2
   Patro KAK, 2020, MICROSYST TECHNOL, V26, P1437, DOI 10.1007/s00542-019-04676-w
   Patro KAK, 2020, IETE TECH REV, V37, P223, DOI 10.1080/02564602.2019.1595751
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   Pub N.F., 2001, Federal inf. process. standards publication, V197, P311
   Samiullah M, 2020, IEEE ACCESS, V8, P25650, DOI 10.1109/ACCESS.2020.2970981
   Sarkar S., 2015, SSRG INT J COMPUT SC, V2, P18, DOI DOI 10.14445/23488387/IJCSE-V2I8P104
   Singh N, 2010, OPT LASER TECHNOL, V42, P724, DOI 10.1016/j.optlastec.2009.11.016
   Sneha PS, 2020, J AMB INTEL HUM COMP, V11, P1289, DOI 10.1007/s12652-019-01385-0
   Tang ZJ, 2016, OPT LASER ENG, V80, P1, DOI 10.1016/j.optlaseng.2015.12.004
   Tiejun Zhang, 2014, Advanced Materials Research, V981, P327, DOI 10.4028/www.scientific.net/AMR.981.327
   Verma R., 2022, Journal of Computational and Cognitive Engineering, P1
   Wang J, 2021, MULTIMED TOOLS APPL, V80, P16087, DOI 10.1007/s11042-020-10413-7
   Wang T, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106355
   Wang X, 2020, Arxiv, DOI [arXiv:2002.07920, DOI 10.47852/BONVIEWJCCE2202320]
   Wang XY, 2012, INT J MOD PHYS B, V26, DOI 10.1142/S0217979212502086
   Wang XY, 2017, INF SECUR J, V26, P7, DOI 10.1080/19393555.2016.1272725
   Wani A, 2021, CAAI T INTELL TECHNO, V6, P281, DOI 10.1049/cit2.12003
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Yavuz E, 2021, J INF SECUR APPL, V63, DOI 10.1016/j.jisa.2021.103056
   Zhang XQ, 2019, MULTIMED TOOLS APPL, V78, P7841, DOI 10.1007/s11042-018-6496-1
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
NR 59
TC 0
Z9 0
U1 8
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 15
PY 2023
DI 10.1007/s11042-023-17700-z
EA DEC 2023
PG 47
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU3L6
UT WOS:001155145800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Karabila, I
   Darraz, N
   EL-Ansari, A
   Alami, N
   EL Mallahi, M
AF Karabila, Ikram
   Darraz, Nossayba
   EL-Ansari, Anas
   Alami, Nabil
   EL Mallahi, Mostafa
TI BERT-enhanced sentiment analysis for personalized e-commerce
   recommendations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE BERT; Collaborative filtering; Recommendation system; Sentiment
   analysis; Ensemble learning
AB Recommendation systems (RS) play a crucial role in enhancing conversion rates in e-commerce by offering personalized product recommendations based on customer preferences. However, traditional RS heavily rely on numerical ratings, which might not fully capture the subtle nuances of user preferences. To overcome this limitation, the integration of textual data, such as reviews using sentiment analysis (SA), has gained considerable significance. Nevertheless, effectively analyzing and comprehending unstructured review data presents its own set of challenges. In this work, we propose a novel RS that synergizes collaborative filtering with sentiment analysis to deliver precise and individualized recommendations. Our approach encompasses three main steps: (1) Developing a BERT fine-tuned model for accurate sentiment classification, (2) Creating a hybrid collaborative filtering-based Recommendation Model, and (3) Improving the product selection process in the RS using BERT insights for enhanced recommendation accuracy in the e-commerce domain. Notably, our SA model exhibits remarkable accuracy, achieving 91%, and outperforming state-of-the-art models on a benchmark dataset. Through extensive experimentation and evaluation, we demonstrate that our method significantly improves the accuracy and personalization of the RS, thereby providing customers with a tailored and reliable recommendation service in the e-commerce domain.
C1 [Karabila, Ikram; Darraz, Nossayba; EL Mallahi, Mostafa] Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Dept Math & Comp Sci, IPI Lab, Fes, Morocco.
   [EL-Ansari, Anas] Mohammed First Univ, Polydisciplinary Fac, Comp Sci Dept, MASI Lab, Nador, Morocco.
   [Alami, Nabil] Mohammed First Univ, Higher Sch Technol, MASI Lab, Nador, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed First University
   of Oujda; Mohammed First University of Oujda
RP Karabila, I (corresponding author), Sidi Mohamed Ben Abdellah Univ, High Normal Sch, Dept Math & Comp Sci, IPI Lab, Fes, Morocco.
EM ikram.karabila@usmba.ac.ma; nossayba.darraz@usmba.ac.ma;
   anas.elansari@gmail.com; n.alami@ump.ac.ma;
   mostafa.elmallahi@usmba.ac.ma
RI EL ANSARI, ANAS/HMD-7829-2023
OI EL ANSARI, ANAS/0000-0003-2166-1492; Alami, Nabil/0000-0002-5602-2562;
   Karabila, ikram/0009-0002-7467-3972
CR Abbasi F, 2019, Journal of Information Technology Management, V11
   Abhishek Dubey, 2018, INT C APPL COMPUTING
   Aggarwal CC., 2016, Content-based recommender systems, P139
   Arbane M, 2023, EXPERT SYST APPL, V212, DOI 10.1016/j.eswa.2022.118710
   Bhavitha BK, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P216, DOI 10.1109/ICICCT.2017.7975191
   Birjali M, 2021, KNOWL-BASED SYST, V226, DOI 10.1016/j.knosys.2021.107134
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Chen L, 2012, USER MODEL USER-ADAP, V22, P125, DOI [10.1007/s11257-011-9115-7, 10.1007/s11257-011-9108-6]
   Contratres Felipe G., 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 746), P122, DOI 10.1007/978-3-319-77712-2_12
   Salas-Zárate MD, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/5140631
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Ebadi A., 2016, International Journal of Computer and Information Engineering, V10, P1377, DOI DOI 10.5281/ZENODO.1125867
   El-Ansari A, 2023, WIRELESS PERS COMMUN, V129, P1623, DOI 10.1007/s11277-023-10199-5
   Elmurngi E.I., 2018, J. Comput. Sci., V14, P714, DOI 10.3844/jcssp.2018.714.726
   Gao ZJ, 2019, IEEE ACCESS, V7, P154290, DOI 10.1109/ACCESS.2019.2946594
   Geetha G, 2018, J PHYS CONF SER, V1000, DOI 10.1088/1742-6596/1000/1/012101
   Hameed Z, 2020, IEEE ACCESS, V8, P73992, DOI 10.1109/ACCESS.2020.2988550
   Isinkaye FO, 2015, EGYPT INFORM J, V16, P261, DOI 10.1016/j.eij.2015.06.005
   Jain A., 2016, Advanced Computational Intelligence, V3, P25
   jmcauley, Amazon Musical Instruments
   Kumar S, 2020, IEEE T COMPUT SOC SY, V7, P915, DOI 10.1109/TCSS.2020.2993585
   Lee SW, 2021, MULTIMED TOOLS APPL, V80, P34625, DOI 10.1007/s11042-020-08820-x
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Munikar Manish, 2019, 2019 ARTIFICIAL INTE, V1, P1, DOI DOI 10.1109/AITB48515.2019.8947435
   Nabil S, 2018, 2018 IEEE 5TH INTERNATIONAL CONGRESS ON INFORMATION SCIENCE AND TECHNOLOGY (IEEE CIST'18), P155, DOI 10.1109/CIST.2018.8596418
   Nilashi M, 2018, EXPERT SYST APPL, V92, P507, DOI 10.1016/j.eswa.2017.09.058
   Nilashi M, 2014, EXPERT SYST APPL, V41, P3879, DOI 10.1016/j.eswa.2013.12.023
   Nouh RM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020431
   Osman NA., 2019, International Journal of Machine Learning and Computing, V9, P425, DOI DOI 10.18178/IJMLC.2019.9.4.821
   Pan YX, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P1983, DOI [10.1109/ITNEC48623.2020.9084784, 10.1109/itnec48623.2020.9084784]
   Patel B, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Rahali A, 2023, AI-BASEL, V4, P54, DOI 10.3390/ai4010004
   Sachin S., 2020, SN Comput. Sci, DOI [10.1007/s42979-020-0076-y, DOI 10.1007/S42979-020-0076-Y]
   Sallam R., 2022, International Journal of Electrical and Computer Engineering, V12, P1744, DOI 10.11591/ijece.v12i2.pp1744-1753
   Sanchez-Moreno D, INTRENDS CYBER PHYS, P206
   Sharma D., 2021, Advances in Communication and Computational Technology: Select Proceedings of ICACCT, V2019, P333, DOI [10.1007/978-981-15-5341-7_27, DOI 10.1007/978-981-15-5341-7_27]
   Thakker U, 2021, MULTIMED TOOLS APPL, V80, P28647, DOI 10.1007/s11042-021-10965-2
   Tilloo Pallavi, 2021, Sentiment analysis for amazon musical instruments user reviews
   Zhang XY, 2016, INT SYMP PARA DISTR, P230, DOI 10.1109/ISPDC.2016.39
   Zhao W, 2018, IEEE T KNOWL DATA EN, V30, P185, DOI 10.1109/TKDE.2017.2756658
   Ziani Amel, 2017, 2 INT C AUT CONTR TE
NR 43
TC 0
Z9 0
U1 10
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17689-5
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200011
DA 2024-07-18
ER

PT J
AU Ray, P
   Giri, D
   Meng, WZ
   Hore, S
AF Ray, Palash
   Giri, Debasis
   Meng, Weizhi
   Hore, Soumyadeep
TI GPOD: An Efficient and Secure Graphical Password Authentication System
   by Fast Object Detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Graphical passwords; Shoulder surfing attack; Authentication;
   Encryption; YOLOv3
ID DESIGN; SCHEME; ATTACK
AB Nowadays, the graphical password has gained significant recognition and has become a subject of extensive investigation within the research community. The proliferation of Internet usage has resulted in individuals accessing various web applications from any location worldwide, utilizing personal computers, mobile phones, and other touch-enabled devices. However, individuals frequently employ passwords that are weak and commonly used due to their inability to recall complex passwords. This renders the systems susceptible to various forms of attacks. Hence, there is a requirement for an authentication scheme that possesses qualities such as resilience, ease of memorability, and security. Graphical passwords are significantly more effective than text-based passwords in terms of memorability. Nevertheless, numerous schemes are susceptible to various forms of attacks, such as shoulder surfing attacks, man-in-the-middle attacks, database attacks, random guess attacks, and so forth. Moreover, the compromise between security and usability concerns is evident in different graphical authentication schemes. Therefore, we present a novel graphical authentication scheme that ensures both security and usability. This scheme incorporates random graphical objects blended with a background image, resulting in the generation of a distinct graphical challenge. The objects that have been chosen must undergo verification through the utilization of an object detection algorithm known as YOLOv3. In order to strengthen the security of GPOD (Graphical password with object detection), user data is subjected to encryption and subsequently stored on the server, thereby mitigating the risk of potential database attacks. Additionally, the user data undergoes encryption prior to its transmission to the server in order to alleviate the risk of man-in-the-middle attacks. The proposed GPOD scheme is a straightforward, usable, resilient, shoulder-surf-resistant, and secure graphical authentication scheme. The scheme exhibits excellent performance, with an accuracy rate of up to 94.80% and a login time ranging from 9.61 to 14.56 seconds in two scenarios, respectively.
C1 [Ray, Palash; Hore, Soumyadeep] Haldia Inst Technol, Haldia, West Bengal, India.
   [Giri, Debasis] Maulana Abul Kalam Azad Univ Technol, Nadia, West Bengal, India.
   [Meng, Weizhi] Tech Univ Denmark DTU, Lyngby, Denmark.
C3 Haldia Institute of Technology; Maulana Abul Kalam Azad University of
   Technology; Technical University of Denmark
RP Ray, P (corresponding author), Haldia Inst Technol, Haldia, West Bengal, India.
EM palash.ray@gmail.com; debasis_giri@hotmail.com; weme@dtu.dk;
   soumyadeephore9@gmail.com
RI Giri, Debasis/ABF-6428-2022; Meng, Weizhi/N-9638-2019
OI Giri, Debasis/0000-0003-3033-3036; Meng, Weizhi/0000-0003-4384-5786;
   Ray, Palash/0000-0001-5741-7630
CR Alia Mohammad Ahmad, 2018, ICIC Express Letters, V12, P775, DOI 10.24507/icicel.12.08.775
   Alsaiari H, 2016, P 8 SAUD STUD C UK W, P359
   Alsuhibany SA, 2020, J AMB INTEL HUM COMP, V11, P1645, DOI 10.1007/s12652-019-01269-3
   Amin R, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5989151
   Amin R, 2017, IEEE T CONSUM ELECTR, V63, P53, DOI 10.1109/TCE.2017.014735
   Aviv A. J., 2010, 4 USENIX WORKSH OFF, P1
   Bahumik Jaydeb, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P663, DOI 10.1007/978-981-10-6890-4_64
   Bera A, 2018, ADV INTELL SYST, V666, P3, DOI 10.1007/978-981-10-8180-4_1
   Bicakci Kemal, 2009, 2009 33rd Annual IEEE International Computer Software and Applications Conference (COMPSAC 2009), P318, DOI 10.1109/COMPSAC.2009.153
   Biddle R, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333114
   Blonder GE, 1996, Graphical Password U.S. Patent, Patent No. [5559961, US 5559961]
   Bostan H, 2023, MULTIMED TOOLS APPL, V82, P43517, DOI 10.1007/s11042-023-15227-x
   Braz C, 2006, P 18 C INT HOMM MACH, ppp199
   Brostoff S, 2000, BCS CONFERENCE S, P405
   Callegati F, 2009, IEEE SECUR PRIV, V7, P78, DOI 10.1109/MSP.2009.12
   Chiasson S, 2007, LECT NOTES COMPUT SC, V4734, P359
   Chuen Y. S., 2020, J. Crit. Rev., V7, P102
   Davis D, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE 13TH USENIX SECURITY SYMPOSIUM, P151
   De Angeli A, 2005, INT J HUM-COMPUT ST, V63, P128, DOI 10.1016/j.ijhcs.2005.04.020
   De S, 2022, MULTIMED TOOLS APPL, V81, P5485, DOI 10.1007/s11042-021-11696-0
   Dhamija R, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE NINTH USENIX SECURITY SYMPOSIUM, P45
   Eljetlawi AM, 2008, THIRD 2008 INTERNATIONAL CONFERENCE ON CONVERGENCE AND HYBRID INFORMATION TECHNOLOGY, VOL 2, PROCEEDINGS, P1137, DOI 10.1109/ICCIT.2008.20
   Foley D, 2018, AICS, ppp350
   Forouzan B.A., 2015, Cryptography and Network Security, V12
   Gao HC, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P194, DOI 10.1109/CW.2010.34
   Gao HC, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P722, DOI 10.1109/ICIG.2009.62
   Giri D, 2015, IEEE T CONSUM ELECTR, V61, P491, DOI 10.1109/TCE.2015.7389804
   Gokhale AS, 2016, PROCEDIA COMPUT SCI, V79, P490, DOI 10.1016/j.procs.2016.03.063
   Haichang Gao, 2013, Journal of Software, V8, P1678, DOI 10.4304/jsw.8.7.1678-1698
   Haque M.A., 2014, INT J COMPUT ELECT A, V8, P320
   Hayashi Eiji., 2008, Proceedings of the 4th symposium on Usable privacy and security, P35, DOI DOI 10.1145/1408664.1408670
   Hub M., 2011, Int J Comput Commun, V5, P1
   Izadeen G. Y., 2021, Asian J Res Comput Sci, P59, DOI DOI 10.9734/AJRCOS/2021/V9I230220
   Jansen W., 2003, PICTURE PASSWORD VIS
   Jermyn I, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE EIGHTH USENIX SECURITY SYMPOSIUM (SECURITY '99), P1
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kaka Jiya Gloria, 2021, Proceedings of the 2020 IEEE 2nd International Conference on Cyberspace (CYBER NIGERIA), P44, DOI 10.1109/CYBERNIGERIA51635.2021.9428801
   Khedr WI, 2018, J INF SECUR APPL, V39, P41, DOI 10.1016/j.jisa.2018.02.003
   Khodadadi T, 2016, Int J Electrical Comput Eng, V6
   KIRKPATRICK E.A., 1894, PSYCHOL REV, V1, P602, DOI [10.1037/h0068244, DOI 10.1037/H0068244]
   Knudsen L.R., 2011, The block cipher companion, V978-3-642-17342-4, P95, DOI [10.1007/978-3-642-17342-45, DOI 10.1007/978-3-642-17342-45, DOI 10.1007/978-3-642-17342-4_5]
   Komanduri S., 2008, Proceedings of Graphics Interface 2008, P115
   Kostromina S, 2016, PROCD SOC BEHV, V217, P34, DOI 10.1016/j.sbspro.2016.02.016
   Kumar B. Vinoth, 2019, IOP Conference Series: Materials Science and Engineering, V590, DOI 10.1088/1757-899X/590/1/012062
   Kuppusamy K, 2019, J Ambient Intell Human Comput, P1
   Li X, 2012, J NETW COMPUT APPL, V35, P763, DOI 10.1016/j.jnca.2011.11.009
   Lin D, 2018, COMPUT SECUR, V77, P627, DOI 10.1016/j.cose.2017.09.016
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CL, 2015, J NETW COMPUT APPL, V53, P128, DOI 10.1016/j.jnca.2015.03.006
   Luo JN, 2016, MULTIMED TOOLS APPL, V75, P14075, DOI 10.1007/s11042-015-3129-9
   Madigan S, 1983, Image memory. Imagery, Memory, and Cognition: Essays in Honor of Allan Paivio
   Maitra T, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102915
   Maity M, 2016, COMM COM INF SC, V625, P283, DOI 10.1007/978-981-10-2738-3_24
   Meng WZ, 2019, FUTURE GENER COMP SY, V101, P1018, DOI 10.1016/j.future.2019.07.038
   Meng WZ, 2017, LECT NOTES COMPUT SC, V10343, P301, DOI 10.1007/978-3-319-59870-3_17
   Meng WZ, 2017, COMPUT SECUR, V65, P213, DOI 10.1016/j.cose.2016.11.010
   Merhav N, 2020, IEEE T INFORM THEORY, V66, P114, DOI 10.1109/TIT.2019.2920538
   MORRIS R, 1979, COMMUN ACM, V22, P594, DOI 10.1145/359168.359172
   Nizamani SZ, 2021, IEEE ACCESS, V9, P51294, DOI 10.1109/ACCESS.2021.3069164
   Orozco Mauricio., 2006, P VIRTUAL CONCEPT, V56, P1
   Panda S, 2018, LECT NOTES COMPUT SC, V11281, P129, DOI 10.1007/978-3-030-05171-6_7
   Patra K, 2016, PROCEDIA COMPUT SCI, V79, P561, DOI 10.1016/j.procs.2016.03.071
   Pering T, 2003, IEEE PERVAS COMPUT, V2, P30, DOI 10.1109/MPRV.2003.1186723
   Por LY, 2017, FRONT COMPUT SCI-CHI, V11, P1098, DOI 10.1007/s11704-016-5472-z
   Ray P, 2022, INT C FRONT COMP SYS, P231
   Ray P, 2023, MULTIMEDIA SYST, V29, P1865, DOI 10.1007/s00530-023-01075-0
   Ray P, 2020, STUD COMPUT INTELL, V863, P218, DOI 10.1007/978-3-030-34152-7_17
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rogez G, 2017, PROC CVPR IEEE, P1216, DOI 10.1109/CVPR.2017.134
   Salehifar H, 2019, MULTIMED TOOLS APPL, V78, P16861, DOI 10.1007/s11042-018-7043-9
   Sasmal M., 2020, Turkish J Comput Math Educ (TURCOMAT), V11, P508
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schumacher HJ, 1997, J NETW COMPUT APPL, V20, P305, DOI 10.1006/jnca.1997.0058
   Shammee TI., 2020, J Comput Sci Eng, V14, P163, DOI [10.5626/JCSE.2020.14.4.163, DOI 10.5626/JCSE.2020.14.4.163]
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Still JD, 2018, J INF SECUR APPL, V40, P1, DOI 10.1016/j.jisa.2018.02.006
   Sun HM, 2018, IEEE T DEPEND SECURE, V15, P180, DOI 10.1109/TDSC.2016.2539942
   Syukri A. F., 1998, Information Security and Privacy. Third Australasian Conference, ACISP'98. Proceedings, P403, DOI 10.1007/BFb0053751
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Tang S, 2015, INT C IEEE 2016
   Tullis T.S., 2011, CHI'11 Extended Abstracts on Human Factors in Computing Systems, P1789, DOI [10.1145/1979742.1979945, DOI 10.1145/1979742.1979945]
   Van Eekelen WA, 2013, CHI 13 EXTENDED ABST, ppp1857
   van Oorschot PC, 2009, LECT NOTES BUS INF P, V26, P233
   Varenhorst C, 2004, Res Sci Instit
   Wazid M, 2013, 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2013), P433, DOI 10.1109/ISCO.2013.6481194
   Weiss R., 2008, Proceedings of the 5th Nordic Conference on Human-Computer Interaction Building Bridges - NordiCHI'08, P383
   Wiedenbeck S, 2005, INT J HUM-COMPUT ST, V63, P102, DOI 10.1016/j.ijhcs.2005.04.010
   Wiedenbeck S., 2006, Proceedings of the working conference on Advanced visual interfaces (AVI '06), P177
   Wolf F, 2018, J INF SECUR APPL, V41, P28, DOI 10.1016/j.jisa.2018.05.004
   Wu TS, 2014, INT J INF SECUR, V13, P245, DOI 10.1007/s10207-013-0216-7
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiyang Liu, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P949, DOI 10.1109/ICIG.2011.16
   Yu XJ, 2017, COMPUT SECUR, V70, P179, DOI 10.1016/j.cose.2017.05.006
   Yuxin Meng, 2012, 2012 IEEE 7th International Conference on Networking, Architecture, and Storage (NAS), P39, DOI 10.1109/NAS.2012.9
   Zhao HY, 2007, 21ST INTERNATIONAL CONFERENCE ON ADVANCED NETWORKING AND APPLICATIONS WORKSHOPS/SYMPOSIA, VOL 2, PROCEEDINGS, P467
NR 96
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 12
PY 2023
DI 10.1007/s11042-023-17571-4
EA DEC 2023
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CG2W2
UT WOS:001124043200003
DA 2024-07-18
ER

PT J
AU Verma, N
   Valluru, SK
AF Verma, Neelam
   Valluru, Sudarshan K.
TI ANN Based ANFIS controller Design Using Hybrid Meta-Heuristic Tuning
   Approach for Cart Inverted Pendulum System
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ANFIS controller; Ant Colony Optimization; Artificial Neural Network;
   Cart Inverted Pendulum Model; Particle Swarm Optimization
ID SUBSTITUTION BOX; S-BOXES; IMAGE ENCRYPTION; ELLIPTIC CURVE;
   CONSTRUCTION; CRYPTOGRAPHY
AB The control system of the Inverted Pendulum System (IPS) has turned to be a common engineering issue for investigators because of its importance in the implementation in real life. The controller model is usually employed to stabilize the position and the angle of the IPS. In the present study, a cart IPS is designed using Artificial Neural Network (ANN) based Adaptive Neuro-Fuzzy Inference system (ANFIS) controller. To enhance the stability of the closed loop system, a hybrid meta-heuristic optimization algorithm is used to tune the hyper-parameters. The best position of the cart is determined using a hybrid approach (i.e. Ant-colony optimization and Particle Swarm Optimization Algorithms). The model is designed with 10 hidden layers and adopted 25 fuzzy logic rules. The proposed model is evaluated based on the settling time, rise time. The simulation results of the proposal model is performed using SIMULINK in MATLAB. It is found that the proposed model has attained low settling and rise time and low Integrated Squared of Errors (ISE) and Steady State Error rates (SSE). Thus, with these significant features, the proposed model can be practically implemented to acquire an efficient IPS that is optimally stable. To confirm the efficacy of the proposed system, comparison is undertaken with regard to Mean Square Error (MSE) for exposing the better performance of the proposed system.
C1 [Verma, Neelam; Valluru, Sudarshan K.] Delhi Technol Univ, Dept Elect Engn, Control Dynam Syst & Computat Lab, Delhi, India.
C3 Delhi Technological University
RP Verma, N (corresponding author), Delhi Technol Univ, Dept Elect Engn, Control Dynam Syst & Computat Lab, Delhi, India.
EM neelamverma11@gmail.com
RI Valluru, Sudarshan K./G-3682-2019
OI Valluru, Sudarshan K./0000-0002-8348-0016
CR Açikkapi MS, 2019, IEEE ACCESS, V7, P79030, DOI 10.1109/ACCESS.2019.2921708
   Ahmed HA, 2019, NEURAL COMPUT APPL, V31, P7201, DOI 10.1007/s00521-018-3557-3
   Akgüller O, 2020, APPL MATH NONLIN SCI, V5, P349, DOI 10.2478/AMNS.2020.1.00033
   Alhadawi HS, 2021, MULTIMED TOOLS APPL, V80, P7333, DOI 10.1007/s11042-020-10048-8
   Alzaidi AA, 2018, COMPLEXITY, DOI 10.1155/2018/9389065
   Arshad B, 2022, WIRELESS PERS COMMUN, V124, P3527, DOI 10.1007/s11277-022-09524-1
   Azam NA, 2019, FRONT INFORM TECH EL, V20, P1378, DOI 10.1631/FITEE.1800434
   Begum M, 2020, INFORMATION, V11, DOI 10.3390/info11020110
   Ben Farah MA, 2020, MULTIMED TOOLS APPL, V79, P19129, DOI 10.1007/s11042-020-08718-8
   Bhatti UA, 2021, MULTIMED TOOLS APPL, V80, P13367, DOI 10.1007/s11042-020-10257-1
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Bozduman HC, 2020, APPL MATH NONLIN SCI, V5, P479, DOI 10.2478/AMNS.2020.1.00046
   El-Borhamy M, 2020, APPL MATH NONLIN SCI, V5, P93, DOI 10.2478/AMNS.2020.1.00010
   Farhan AK, 2020, INT J INNOV COMPUT I, V16, P331, DOI 10.24507/ijicic.16.01.331
   Farhan AK, 2019, IEEE ACCESS, V7, P124914, DOI 10.1109/ACCESS.2019.2938513
   FEISTEL H, 1973, SCI AM, V228, P15, DOI 10.1038/scientificamerican0573-15
   Gallian J., 2017, Cengage Learning, P1
   Gao W, 2020, IEEE ACCESS, V8, P136736, DOI 10.1109/ACCESS.2020.3010615
   Günerhan H, 2020, APPL MATH NONLIN SCI, V5, P109, DOI 10.2478/AMNS.2020.1.00011
   Hayat U, 2018, WIRELESS PERS COMMUN, V101, P439, DOI 10.1007/s11277-018-5698-1
   Hussain I, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030351
   Idrees B, 2020, MULTIMED TOOLS APPL, V79, P6135, DOI 10.1007/s11042-019-08282-w
   Jahangir S, 2020, MULTIMED TOOLS APPL, V79, P26885, DOI 10.1007/s11042-020-08995-3
   Jamal SS, 2019, CHINESE J PHYS, V60, P564, DOI 10.1016/j.cjph.2019.05.038
   KAM JB, 1979, IEEE T COMPUT, V28, P747, DOI 10.1109/TC.1979.1675242
   Khan M, 2013, NONLINEAR DYNAM, V73, P1795, DOI 10.1007/s11071-013-0904-x
   Lambic D, 2013, PUBL I MATH-BEOGRAD, V93, P109, DOI 10.2298/PIM1307109L
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   MEIER W, 1990, LECT NOTES COMPUT SC, V434, P549
   Nardo LG, 2021, CHAOS, V31, DOI 10.1063/5.0061639
   NYBERG K, 1991, LECT NOTES COMPUT SC, V547, P378
   Parida P, 2021, IEEE ACCESS, V9, P76191, DOI 10.1109/ACCESS.2021.3072075
   PIEPRZYK J, 1988, IEE PROC-E, V135, P325, DOI 10.1049/ip-e.1988.0044
   Qiu YH, 2021, APPL MATH NONLIN SCI, V6, P129, DOI 10.2478/AMNS.2021.1.00015
   Rafiq A, 2019, MULTIMED TOOLS APPL, V78, P15527, DOI 10.1007/s11042-018-6953-x
   Razaq A, 2021, WIRELESS PERS COMMUN, V116, P3165, DOI 10.1007/s11277-020-07841-x
   Razaq A, 2020, WIRELESS PERS COMMUN, V111, P2091, DOI 10.1007/s11277-019-06973-z
   Razaq A, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/5101934
   Seberry J., 1993, P 1 ACM C COMPUTER C, P171
   Sever M, 2021, APPL MATH NONLIN SCI, V6, P499, DOI 10.2478/AMNS.2020.2.00041
   Shah T., 2011, STAT ANAL S BOX IMAG, V6, P4110
   Shah T, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3020013
   Shah T, 2019, MULTIMED TOOLS APPL, V78, P1219, DOI 10.1007/s11042-018-6250-8
   Shah T, 2017, COMPUT APPL MATH, V36, P843, DOI 10.1007/s40314-015-0265-9
   Shah T, 2013, Z NATURFORSCH A, V68, P567, DOI 10.5560/ZNA.2013-0021
   Shahzad I, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/2847801
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Siddiqui N, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241890
   Subramanian N, 2021, IEEE ACCESS, V9, P23409, DOI 10.1109/ACCESS.2021.3053998
   Sun ZJ, 2020, APPL MATH NONLIN SCI, V5, P483, DOI 10.2478/AMNS.2020.2.00024
   Wang Y, 2012, PHYS LETT A, V376, P827, DOI 10.1016/j.physleta.2012.01.009
   WEBSTER AF, 1986, LECT NOTES COMPUT SC, V218, P523
   Wilson R. A., 2009, FINITE SIMPLE GROUPS
   Wu W-l, 2009, Design and analysis of block cipher
   Yousaf MA, 2020, IEEE ACCESS, V8, P39781, DOI 10.1109/ACCESS.2020.2975880
   Zahid AH, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030245
   Zahid AH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030437
NR 58
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17699-3
EA DEC 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800015
DA 2024-07-18
ER

PT J
AU Dutta, K
   Sarkhel, R
   Kundu, M
   Nasipuri, M
   Das, N
AF Dutta, Kalpita
   Sarkhel, Ritesh
   Kundu, Mahantapas
   Nasipuri, Mita
   Das, Nibaran
TI Natural scene text localization and detection using MSER and its
   variants: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text localization; Text recognition; MSER; Stroke width; Enhanced MSER;
   Multilevel MSER; MSER survey
ID NEURAL-NETWORK; IMAGES; RECOGNITION; VIDEO; SEGMENTATION; ALGORITHM;
   CONTEXT; MODEL
AB Text localization and detection within natural scene images have generated significant interest among researchers due to their inherent complexity and various real-life applications. In the last few decades, various methodologies have been developed for localization and detection of wild scene text regions. Among them, Maximally Stable Extremal Regions (MSER) based techniques have achieved remarkable success in a significant variety of text localization tasks over the last decade. MSER is a well-known blob detection method, which has been applied with some modifications in many scene text-related researches. In this paper, we have reviewed and evaluated the concept of MSER methods which are combined with traditional machine learning-based methods using hand-crafted features or deep learning-based methods using automatic feature learning for scene text localization. Different MSER methods, such as standard MSER, MSER with stroke width transform, eMSER, enhanced MSER, multi-level MSER, MSER with CNN features, component splitting with MSER tree, MSER with CNN and CRF, CE-MSER have been described in this study. Finally, we have compared and evaluated the performances of those different types of MSER methods on five publicly available standard scene text datasets, like ICDAR 2003, ICDAR 2013, ICDAR 2015, KAIST, and SVT and provided the insights of appropriate selection of MSER method along with its pros and cons.
C1 [Dutta, Kalpita; Kundu, Mahantapas; Nasipuri, Mita; Das, Nibaran] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Sarkhel, Ritesh] Ohio State Univ, Dept Comp Sci & Engn, Columbus, OH 43210 USA.
C3 Jadavpur University; University System of Ohio; Ohio State University
RP Das, N (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM dutta.kalpita@gmail.com; sarkhel.5@osu.edu; mahantapas@gmail.com;
   mitanasipuri@gmail.com; nibaran.das@jadavpuruniversity.in
FU SERB (DST) [EEQ/2018/000-963]; Jadavpur University, Kolkata
FX This work is partially supported by SERB (DST), Govt. of India (Ref. no.
   EEQ/2018/000-963) and done at CMATER Laboratory, Dept. of CSE, Jadavpur
   University, Kolkata.
CR Ajay BN, 2019, STUD COMPUT INTELL, V771, P669, DOI 10.1007/978-981-10-8797-4_68
   Akoushideh A, 2022, MULTIMED TOOLS APPL, V81, P34047, DOI 10.1007/s11042-022-13179-2
   Ali H, 2022, Arxiv, DOI arXiv:2209.14022
   [Anonymous], 2020, Vishnoitanuj
   Awoke A., 2021, Zede J, V39, P71
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bartz C, 2018, AAAI CONF ARTIF INTE, P6674
   Busta M, 2017, IEEE I CONF COMP VIS, P2223, DOI 10.1109/ICCV.2017.242
   Chaitra YL., 2022, 5 INT C INF COMM TEC, V248, P563, DOI DOI 10.1007/978-981-16-4177-0_55
   Chen H., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2609, DOI 10.1109/ICIP.2011.6116200
   Chen XX, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3440756
   Cho H, 2016, PROC CVPR IEEE, P3566, DOI 10.1109/CVPR.2016.388
   Choudhary S, 2018, 2018 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Cormen T. H., 2001, MIT ELECT ENG COMPUT
   Das Shiplu, 2022, Proceedings of 2nd International Conference on Mathematical Modeling and Computational Science: ICMMCS 2021. Advances in Intelligent Systems and Computing (1422), P401, DOI 10.1007/978-981-19-0182-9_40
   Diaz-Escobar J, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/7067251
   ElAbbadi NK etal, 2023, Al-Salam J Eng Technol, V2, P13, DOI [10.55145/ajest.2023.01.01.002, DOI 10.55145/AJEST.2023.01.01.002]
   Ghosh J, 2024, MULTIMED TOOLS APPL, V83, P6651, DOI 10.1007/s11042-023-15696-0
   Goud DS, 2022, 2022 INT C AUT COMP, P1153, DOI [10.1109/ICACRS55517.2022.10029220, DOI 10.1109/ICACRS55517.2022.10029220]
   Gupta N, 2019, MULTIMED TOOLS APPL, V78, P10821, DOI 10.1007/s11042-018-6613-1
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   He MH, 2021, PROC CVPR IEEE, P8809, DOI 10.1109/CVPR46437.2021.00870
   He T, 2016, IEEE T IMAGE PROCESS, V25, P2529, DOI 10.1109/TIP.2016.2547588
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Islam MR, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P15, DOI 10.1109/ICIEV.2016.7760054
   Islam R, 2020, INT ARAB J INF TECHN, V17, P375, DOI 10.34028/iajit/17/3/11
   Jiang YY, 2017, Arxiv, DOI [arXiv:1706.09579, DOI 10.48550/ARXIV.1706.09579]
   Jung J, 2011, ETRI J, V33, P78, DOI 10.4218/etrij.11.1510.0029
   Jung K, 2004, PATTERN RECOGN, V37, P977, DOI 10.1016/j.patcog.2003.10.012
   Karaoglu S., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P635, DOI 10.1109/DICTA.2010.115
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Khare V, 2016, PATTERN RECOGN, V54, P128, DOI 10.1016/j.patcog.2016.01.008
   L1kw1d, 2013, Borndigitaltext
   Larbi G, 2023, MULTIMED TOOLS APPL, V82, P10595, DOI 10.1007/s11042-022-13690-6
   Lee CY, 2019, PROC INT CONF DOC, P14, DOI 10.1109/ICDARW.2019.60125
   Li RK, 2023, J DATABASE MANAGE, V34, DOI 10.4018/JDM.322086
   Li Y, 2013, IEEE IMAGE PROC, P2264, DOI 10.1109/ICIP.2013.6738467
   Li Y, 2012, INT C PATT RECOG, P681
   Li Y, 2014, IEEE T IMAGE PROCESS, V23, P1666, DOI 10.1109/TIP.2014.2302896
   Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z
   Liao MH, 2021, IEEE T PATTERN ANAL, V43, P532, DOI 10.1109/TPAMI.2019.2937086
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Liu YL, 2019, PROC CVPR IEEE, P9604, DOI 10.1109/CVPR.2019.00984
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Long SB, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01369-0
   Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3
   Lundgren A, 2019, PROC INT CONF DOC, P37, DOI 10.1109/ICDARW.2019.30062
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Mansouri S, 2021, I C COMP SYST APPLIC, DOI 10.1109/AICCSA53542.2021.9686930
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Meetei LS, 2019, LECT NOTES COMPUT SC, V11941, P405, DOI 10.1007/978-3-030-34869-4_44
   Naiemi F, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114549
   Naiemi F, 2020, MULTIMED TOOLS APPL, V79, P27137, DOI 10.1007/s11042-020-09318-2
   Nayef Nibal, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1582, DOI 10.1109/ICDAR.2019.00254
   Nayef N, 2017, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2017.237
   Panda Souvik, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P999, DOI 10.1007/978-981-13-9042-5_86
   Qin LF, 2016, INT C PATT RECOG, P3886, DOI 10.1109/ICPR.2016.7900241
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shi CZ, 2014, PATTERN RECOGN, V47, P2853, DOI 10.1016/j.patcog.2014.03.023
   Shivakumara P, 2012, IEEE T CIRC SYST VID, V22, P1227, DOI 10.1109/TCSVT.2012.2198129
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Soni R, 2017, 2017 4 INT C IMAGE I, P1, DOI [10.1109/ICIIP.2017.8313739, DOI 10.1109/ICIIP.2017.8313739]
   Tabassum A, 2015, INT CONF COMM SYST, P568, DOI 10.1109/CSNT.2015.154
   Thilagavathy A, 2019, CLUSTER COMPUT, V22, P11681, DOI 10.1007/s10586-017-1448-5
   Tian SX, 2015, IEEE I CONF COMP VIS, P4651, DOI 10.1109/ICCV.2015.528
   Tian SX, 2014, INT C PATT RECOG, P2703, DOI 10.1109/ICPR.2014.467
   Tong GX, 2022, KNOWL-BASED SYST, V250, DOI 10.1016/j.knosys.2022.109040
   Turki H, 2017, PROC INT CONF DOC, P949, DOI 10.1109/ICDAR.2017.159
   Turki H, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268993
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang T, 2012, INT C PATT RECOG, P3304
   Wang XB, 2017, MULTIMED TOOLS APPL, V76, P26201, DOI 10.1007/s11042-016-4099-2
   Wang YN, 2018, NEUROCOMPUTING, V295, P46, DOI 10.1016/j.neucom.2017.12.058
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Xie EZ, 2019, AAAI CONF ARTIF INTE, P9038
   Yan Wan, 2019, Recent Developments in Intelligent Computing, Communication and Devices. Proceedings of International Conference on Intelligent Computing, Communication and Devices (ICCD 2017). Advances in Intelligent Systems and Computing (AISC 752), P387, DOI 10.1007/978-981-10-8944-2_45
   Yao C, 2016, Arxiv, DOI arXiv:1606.09002
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
   Yuxin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11750, DOI 10.1109/CVPR42600.2020.01177
   Zhan FN, 2019, IEEE I CONF COMP VIS, P9104, DOI 10.1109/ICCV.2019.00920
   Zhang Shi-Xue, 2020, IEEE C COMPUTER VISI, P9699
   Zhang XN, 2018, NEUROCOMPUTING, V307, P61, DOI 10.1016/j.neucom.2018.03.070
   Zhang Y, 2021, MULTIMED TOOLS APPL, V80, P29005, DOI 10.1007/s11042-021-11101-w
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
   Zhu W, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182227
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
   Zuo LQ, 2019, IEEE ACCESS, V7, P62616, DOI 10.1109/ACCESS.2019.2916616
NR 94
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17671-1
EA NOV 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700009
DA 2024-07-18
ER

PT J
AU Sassi, MSH
   Fourati, LC
AF Sassi, Mohamed Saifeddine Hadj
   Fourati, Lamia Chaari
TI Design cognitive IoT architecture framework for immersive visual
   technologies of air quality monitoring systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Framework; Internet of things; Air quality; Design architecture;
   Immersive visual technologies
ID SCIENCE
AB Industry experts anticipate that Internet of Things (IoT)-based Immersive Visual Technologies (IVT) will revolutionize air quality applications. However, the enormous variety of IoT and IVT poses a significant challenge, impeding widespread adoption in both domains. To fully harness the potential of IoT and IVT in air quality applications, we must confront the complexity arising from their diverse integration. Overcoming this challenge requires an innovative architectural framework that facilitates seamless coexistence and integration. In this paper, we present a New Air Quality Architecture (NAQA) framework designed to model IoT-based immersive technologies for air quality applications. The framework comprises a cohesive collection of architectural perspectives, serving as a guideline to describe specific IoT-based immersive systems with precision. To validate our proposed architecture, we conduct a comprehensive evaluation, including critical case studies like gas leakage and Coronavirus-based air quality monitoring. Comparing NAQA's performance to expert assessments reveals higher precision in detecting errors and recommending solutions. Our framework's versatility and efficacy are demonstrated across various use cases, fostering collaboration and knowledge reuse for accelerated progress in the field.
C1 [Sassi, Mohamed Saifeddine Hadj; Fourati, Lamia Chaari] Univ Sfax, Digital Res Ctr Sfax CRNS, Lab Signals Syst Artificial Intelligence & Networ, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS); Centre
   de Recherche en Numerique de Sfax (CRNS)
RP Sassi, MSH (corresponding author), Univ Sfax, Digital Res Ctr Sfax CRNS, Lab Signals Syst Artificial Intelligence & Networ, Sfax, Tunisia.
EM mohamed-saifeddine.hadjsassi@enis.tn; lamiachaari1@gmail.com
OI HADJ SASSI, MOHAMED SAIFEDDINE/0000-0002-6147-6921
CR Avola D, 2018, MULTIMED TOOLS APPL, V77, P24955, DOI 10.1007/s11042-018-5730-1
   BENBASAT I, 1987, MIS QUART, V11, P369, DOI 10.2307/248684
   Clements P, 2003, PROC INT CONF SOFTW, P740, DOI 10.1109/ICSE.2003.1201264
   Fernández-Caramés TM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061798
   Franchini M, 2009, SEMIN THROMB HEMOST, V35, P665, DOI 10.1055/s-0029-1242720
   Gorski T, 2019, INT C COMP AID SYST
   Gudas S, 2021, INFORMATICA-LITHUAN, V32, P247, DOI 10.15388/21-INFOR446
   Hadj Sassi Mohamed Saifeddine, 2020, Advanced Information Networking and Applications. Proceedings of the 34th International Conference on Advanced Information Networking and Applications (AINA-2020). Advances in Intelligent Systems and Computing (AISC 1151), P405, DOI 10.1007/978-3-030-44041-1_37
   Hadj Sassi MS, 2019, INT WIREL COMMUN, P1403
   HadjSassi MS, 2019, 15 INT WIR COMM MOB
   Henshaw M, 2019, Systems of systems (sos)
   Hevner AR, 2004, MIS QUART, V28, P75, DOI 10.2307/25148625
   Hoppenstedt B, 2019, P 16 INT C MOB SYST
   Irwansyah FS, 2018, IOP CONF SER-MAT SCI, V288, DOI 10.1088/1757-899X/288/1/012068
   Josey A, 2018, An introduction to the togaf standard, version 9.2. W182
   KRUCHTEN PB, 1995, IEEE SOFTWARE, V12, P42, DOI 10.1109/52.469759
   Maier M., 1998, SYST ENG, V1, P267, DOI [DOI 10.1002/(SICI)1520-6858(1998)1:43.0.CO;2-D, 10.1002/(SICI)1520-6858(1998)1:4lt;267::AID-SYS3gt;3.0.CO;2-D, DOI 10.1002/(SICI)1520-6858(1998)1:4LT;267::AID-SYS3GT;3.0.CO;2-D, DOI 10.1002/(SICI)1520-6858(1998)1:4<267::AID-SYS3>3.0.CO;2-D]
   March ST, 2008, MIS QUART, V32, P725
   Nielsen CB, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2794381
   Oltra C, 2021, Isa, 2010. ansi/isa-95.00.02-2010 (iec 62264-2 mod) enterprise-control system integration-part 2: Object model attributes. Enterprise-control system integration
   Pradibta Hendra, 2018, International Journal of Interactive Mobile Technologies, V12, P151, DOI 10.3991/ijim.v12i1.7269
   Rashid Z, 2017, FUTURE GENER COMP SY, V76, P248, DOI 10.1016/j.future.2016.11.030
   Riva G, 2021, CYBERPSYCH BEH SOC N, V24, P851, DOI 10.1089/cyber.2021.29231.ceu
   Sassi MSH, 2021, 2021 INT S NETW COMP
   Tekinerdogan B, 2021, Architecting Software Model Management and Analytics Framework, P61
   Teng C.-C., 2018, P 2 INT C MED HLTH I, P143
   Verdouw C, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104939
   Vermesan O, 2011, RIVER PUBL SER COMM, P9
   Yin R. K., 2008, CASE STUDY RES DESIG, DOI DOI 10.1097/FCH.0B013E31822DDA9E
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17249-x
EA NOV 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900003
DA 2024-07-18
ER

PT J
AU Jiao, N
AF Jiao, Na
TI An efficient disease prediction framework based on optimized machine
   learning models for a smart healthcare application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Healthcare; Firefly algorithm (FA); Optimization; Machine learning;
   Human diagnosis; Artificial intelligence (AI); Internet of Things (IoT)
ID COVID-19
AB In recent times, Artificial Intelligence (AI) and Internet of Things (IoT) approaches are becoming the key driver for many healthcare applications. Healthcare applications are considered a significant tool that can generate a huge dataset for human diagnosis in real-time scenarios for critical cases with the support of powerful Artificial Intelligence (AI). Moreover, the effectiveness of AI model is the backbone of human diagnosis under critical conditions. Therefore, this study presents an intelligent and efficient AI-based human diagnosis framework using new hybrid optimization and machine learning models for human datasets under critical symptoms such as COVID-19 and heart diseases. The proposed hybrid framework utilizes a combination of optimization algorithms such as Firefly Algorithm (FA), Genetic Algorithm (GA), Particle Swarm Algorithm (PSO), Bat Algorithm (BA), Flower Pollination Algorithm (FPA), Jaya Algorithm (JA), and Cuckoo Search (CS), and Machine Learning (ML) such as LR, LDA, NB, KNN, and SVM. The proposed hybrid framework is verified according to two different human datasets which are Coswara-Dataset which depends on the cough sounds for COVID-19 diagnosis and The Cleveland HD dataset for heart diseases. From the experimental results, the hybrid FA-ML within the proposed framework gives acceptable results in selecting the most relevant subset of features from the two employed datasets for human diagnosis by raising the accuracy rates of the original set of features with 99.4% and 91.7% for COVID-19 and heart diseases datasets, respectively. Consequently, the results achieve superior and accurate performance compared to the other existing models for disease diagnosis in real-time based on an IoT-cloud framework. Data will be collected and analyzed via a smartphone application for more scalability and immediate assessment.
C1 [Jiao, Na] East China Univ Polit Sci & Law, Dept Informat Sci & Technol, Shanghai, Peoples R China.
C3 East China University Political Science & Law
RP Jiao, N (corresponding author), East China Univ Polit Sci & Law, Dept Informat Sci & Technol, Shanghai, Peoples R China.
EM zdx.jn@163.com
RI Jiao, Na/GRE-8588-2022
CR Abu Khurma R, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10030464
   Andreu-Perez J, 2022, IEEE T SERV COMPUT, V15, P1220, DOI 10.1109/TSC.2021.3061402
   Ansarullah SI, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/9882288
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Arora S., 2013, Int. J. Comput. Appl., V69, DOI 10.5120/11826-7528
   Booma PM, 2014, SCI WORLD J, DOI 10.1155/2014/357873
   Brown C, 2021, Arxiv, DOI arXiv:2006.05919
   Choi DJ, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0261-3
   Das H, 2022, J KING SAUD UNIV-COM, V34, P3851, DOI 10.1016/j.jksuci.2020.05.002
   Debjit K, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12051023
   Faezipour M, 2020, TELEMED E-HEALTH, V26, P1202, DOI 10.1089/tmj.2020.0114
   Farahani SM., 2011, INT J MACH LEARN COM, V1, P448, DOI [10.7763/ijmlc.2011.v1.67, DOI 10.7763/IJMLC.2011.V1.67, 10.7763/IJMLC.2011.V1.67]
   Felman A, 2020, Everything you need to know about heart disease. Heart disease: Types, Causes, And Treatments
   Goel T., 2020, Appl Intell, V10, P1
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Grant Drew, 2021, 2021 IEEE EMBS International Conference on Biomedical and Health Informatics (BHI), DOI 10.1109/BHI50953.2021.9508482
   Hemdan EE, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03732-0
   Htun HH, 2023, FINANC INNOV, V9, DOI 10.1186/s40854-022-00441-7
   Imran Ali, 2020, Inform Med Unlocked, V20, P100378, DOI 10.1016/j.imu.2020.100378
   Jackins V, 2021, J SUPERCOMPUT, V77, P5198, DOI 10.1007/s11227-020-03481-x
   Jia WK, 2022, COMPLEX INTELL SYST, V8, P2663, DOI 10.1007/s40747-021-00637-x
   Kaur S, 2023, ARCH COMPUT METHOD E, V30, P1863, DOI 10.1007/s11831-022-09853-1
   Khan MA, 2023, CMC-COMPUT MATER CON, V74, P1393, DOI 10.32604/cmc.2023.032064
   Khourdifi Youness., 2019, International Journal of Intelligent Engineering Systems, V12, P242
   Laguarta J, 2020, IEEE OPEN J ENG MED, V1, P275, DOI 10.1109/OJEMB.2020.3026928
   Lalmuanawma S, 2020, CHAOS SOLITON FRACT, V139, DOI 10.1016/j.chaos.2020.110059
   Latha C. Beulah Christalin, 2019, Informatics in Medicine Unlocked, V16, DOI 10.1016/j.imu.2019.100203
   Li L., 2020, Radiology, V296, DOI 10.1148/radiol.2020200905
   Magnetic Resonance Imaging (MRI), ABOUT US
   Malhotra A., 2021, Pattern Recognit, V10, P243
   Mayo Clinic, 2020, Heart disease-symptoms and causes
   Manshouri NM, 2022, COGN NEURODYNAMICS, V16, P239, DOI 10.1007/s11571-021-09695-w
   Mohammadi B, 2023, HYDROLOGY-BASEL, V10, DOI 10.3390/hydrology10030058
   Mohammed MA, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/1307944
   Özdas MB, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13030433
   Pahar M, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104572
   Peter T. J., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P514
   Sahoo KK, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-022-27192-w
   Sallam NM, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122110760
   Sarra R. R., 2022, Designs, V6, P87
   Shami TM, 2022, IEEE ACCESS, V10, P10031, DOI 10.1109/ACCESS.2022.3142859
   Sharanyaa S., 2020, Int. J. Adv. Eng. Res. Sci, V7, P44, DOI [10.22161/ijaers.73.7, DOI 10.22161/IJAERS.73.7]
   Sharma DK, 2022, MATER TODAY-PROC, V56, P2058, DOI 10.1016/j.matpr.2021.11.388
   Sharma N, 2020, Arxiv, DOI arXiv:2005.10548
   Shehab M, 2023, ARCH COMPUT METHOD E, V30, P765, DOI 10.1007/s11831-022-09817-5
   Swapna G., 2018, Procedia Computer Science, V132, P1192, DOI 10.1016/j.procs.2018.05.034
   Thomford NE, 2020, OMICS, V24, P264, DOI 10.1089/omi.2019.0142
   Trivedy S, 2020, IEEE T INSTRUM MEAS, V69, P7125, DOI 10.1109/TIM.2020.2977793
   Vennemann B, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222983
   Verde L, 2021, IEEE ACCESS, V9, P65750, DOI 10.1109/ACCESS.2021.3075571
   walzter, 2020, ABOUT US
   Wankhede JP., 2021, Adv Parallel Comput, V39, P370, DOI [10.3233/APC210160, DOI 10.3233/APC210160]
   Yang X.S., 2008, Nature-Inspired Metaheuristic Algorithms, P81
   Yang XS, 2013, PROCEDIA COMPUT SCI, V18, P861, DOI 10.1016/j.procs.2013.05.251
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yaqoob A, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11051081
   Zafar A, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23073714
   Zayed SM, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00241-6
NR 58
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17613-x
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600017
DA 2024-07-18
ER

PT J
AU Wu, BC
   Wo, Y
AF Wu, Bicheng
   Wo, Yan
TI Incorporating semantic consistency for improved semi-supervised image
   captioning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semi-supervised image captioning; Pseudo-label filter; Self-training;
   Adversarial training
AB The high labor cost of image captioning datasets limits the application scenarios of image captioning methods. Therefore, the semi-supervised image captioning research that utilizes partially labeled datasets and a large amount of unlabeled data has gained widespread attention in recent years. The key issue of current semi-supervised image captioning research is how to obtain pseudo-labels that well match unlabeled images, providing valuable training samples for semi-supervised model training. To this end, we propose a semi-supervised image captioning method improved by incorporating semantic consistency (Semi-SC), which adopts both self-training and adversarial training for Teacher and Student models. Semi-SC constructs a semantic consistency discriminator to evaluate data of two modalities with global and local semantic similarity, which helps to filter out high-quality paired pseudo-samples from Teacher model to optimize the training of for Student model. To improve the semantic consistency between the generated captions and original images, a semantic confidence loss is designed to inject important semantic information of images into the generated captions with the global semantic content. Extensive experiments on the MSCOCO dataset and Unlabeled-COCO dataset verify the effectiveness of Semi-SC, which shows significant advantages in CIDEr and SPICE metrics, achieving 78.1% and 15.8% in the Scarcely-paired COCO setting and outperforming other existing semi-supervised image captioning methods.
C1 [Wu, Bicheng; Wo, Yan] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Peoples R China.
C3 South China University of Technology
RP Wo, Y (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510641, Peoples R China.
EM woyan@scut.edu.cn
OI Wo, Yan/0000-0003-1001-4425
FU National Natural Science Foundation of Guangdong [2021A1515012020];
   Guangzhou Science and Technology Plan Project [202206030007]
FX This work is supported by National Natural Science Foundation of
   Guangdong [Grant No.2021A1515012020] and Guangzhou Science and
   Technology Plan Project [Grant No.202206030007].
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Banerjee S., 2005, P WORKSHOP INTRINSIC, P65
   Ben HX, 2022, IEEE T MULTIMEDIA, V24, P904, DOI 10.1109/TMM.2021.3060948
   Chen XY, 2021, IEEE WINT CONF APPL, P545, DOI 10.1109/WACV48630.2021.00059
   Feng Y, 2019, PROC CVPR IEEE, P4120, DOI 10.1109/CVPR.2019.00425
   Gu JX, 2019, IEEE I CONF COMP VIS, P10322, DOI 10.1109/ICCV.2019.01042
   Hu X., 2022, IEEE C COMP VIS PATT, P17980
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jain A., 2021, IJCAI, P758
   Jia X, 2022, MULTIMED TOOLS APPL, V81, P21349, DOI 10.1007/s11042-022-12776-5
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim DJ, 2019, arXiv
   Kim DJ, 2023, Arxiv, DOI arXiv:2301.11174
   Kingma D. P., 2014, arXiv
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Laina I, 2019, IEEE I CONF COMP VIS, P7413, DOI 10.1109/ICCV.2019.00751
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Li WH, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2020.102432
   Li Yehao, 2022, P IEEE CVF C COMPUTE, P17990
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XH, 2018, LECT NOTES COMPUT SC, V11219, P353, DOI 10.1007/978-3-030-01267-0_21
   Lopez A, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1380584.1380586
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Qizhe Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10684, DOI 10.1109/CVPR42600.2020.01070
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shao Z, 2023, IEEE T MULTIMEDIA
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Song PP, 2023, IEEE T CYBERNETICS, V53, P4388, DOI 10.1109/TCYB.2022.3175012
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhu P, 2023, IEEE Transactions on Multimedia
   Zohourianshahzadi Z, 2022, ARTIF INTELL REV, V55, P3833, DOI 10.1007/s10462-021-10092-2
NR 38
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 4
PY 2023
DI 10.1007/s11042-023-17577-y
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X3ZW2
UT WOS:001097880200015
DA 2024-07-18
ER

PT J
AU Shankar, A
   Perumal, P
   Subramanian, M
   Ramu, N
   Natesan, D
   Kulkarni, VR
   Stephan, T
AF Shankar, Achyut
   Perumal, Pandiaraja
   Subramanian, Murali
   Ramu, Naresh
   Natesan, Deepa
   Kulkarni, Vaishali R.
   Stephan, Thompson
TI An intelligent recommendation system in e-commerce using ensemble
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Ensemble learning; Recommendation system; E-commerce
   reviews; Natural language processing
ID SENTIMENT ANALYSIS; PRODUCT; REVIEWS; SALES; MODEL
AB In today's world, recommendation systems play a vital role in customer analysis on social media, online businesses, e-commerce, etc. There are multiple sources of information on the Internet giving people a large set of suggestions and advice. This may create confusion for the accurate decision to the user and he/she may get lost in the competitive and growing market. A recommendation system is an essential part of e-commerce to supply the filtered relevant information asked by the customer. The major pitfalls of the existing recommendation system are flooding unnecessary recommendations and unpredictability about new products. Most of the recommendation systems rely on the purchase history of the customer and give suggestions for new products. Along with the history of the user's purchase, it is crucial to analyze various other activities such as browsing history, wish lists, reviews, ratings, and previously ordered items. An intelligent recommendation system using ensemble learning is presented in this paper to reduce duplicate and irrelevant recommendations for the customer. The experimental results indicate that there has been a significant improvement in the precision and recall of the recommendation system in comparison with the other conventional techniques.
C1 [Shankar, Achyut] Univ Warwick, Dept Cyber Syst Engn, WMG, Coventry CV74AL, England.
   [Shankar, Achyut] Lovely Profess Univ, Sch Comp Sci Engn, Phagwara 144411, Punjab, India.
   [Perumal, Pandiaraja] MKumarasamy Coll Engn, Dept Comp Sci & Engn, Karur 639113, Tamil Nadu, India.
   [Subramanian, Murali] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore 632014, Tamil Nadu, India.
   [Ramu, Naresh; Natesan, Deepa] SRM Inst Sci & Technol, Dept Networking & Commun, Chennai 603203, Tamil Nadu, India.
   [Kulkarni, Vaishali R.; Stephan, Thompson] Grap Era Univ, Dept Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
C3 University of Warwick; Lovely Professional University; M.Kumarasamy
   College of Engineering; Vellore Institute of Technology (VIT); VIT
   Vellore; SRM Institute of Science & Technology Chennai; Graphic Era
   University
RP Perumal, P (corresponding author), MKumarasamy Coll Engn, Dept Comp Sci & Engn, Karur 639113, Tamil Nadu, India.
EM ashankar2711@gmail.com; sppandiaraja@gmail.com; murali.s@vit.ac.in;
   nareshr@srmist.edu.in; deepan3@srmist.edu.in; vaishali@ieee.org;
   thompsoncse@gmail.com
RI N, Deepa/AHB-4252-2022; R, Naresh/ABD-6834-2021
OI N, Deepa/0000-0001-7551-4987; R, Naresh/0000-0001-6970-5322; P,
   PANDIARAJA/0000-0003-1733-7163; N, Deepa/0009-0003-4097-5822
CR [Anonymous], 2009, Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing
   Bai ST, 2012, Arxiv, DOI arXiv:1204.4809
   de Albornoz JC, 2011, LECT NOTES COMPUT SC, V6611, P55, DOI 10.1007/978-3-642-20161-5_8
   Che DS, 2011, ADV EXP MED BIOL, V696, P191, DOI 10.1007/978-1-4419-7046-6_19
   Chen R, 2018, IEEE ACCESS, V6, P64301, DOI 10.1109/ACCESS.2018.2877208
   Ding J, 2018, 2018 IEEE/ACM 3RD INTERNATIONAL WORKSHOP ON EMOTION AWARENESS IN SOFTWARE ENGINEERING (SEMOTION), P7, DOI [10.1145/3194932.3194935, 10.1109/GLOCOM.2018.8647613]
   Dong XB, 2020, FRONT COMPUT SCI-CHI, V14, P241, DOI 10.1007/s11704-019-8208-z
   Fan ZP, 2017, J BUS RES, V74, P90, DOI 10.1016/j.jbusres.2017.01.010
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Floyd K, 2014, J RETAILING, V90, P217, DOI 10.1016/j.jretai.2014.04.004
   Gen Li, 2020, 2020 IEEE 3rd International Conference on Automation, Electronics and Electrical Engineering (AUTEEE), P366, DOI 10.1109/AUTEEE50969.2020.9315668
   Ghose A., 2006, P 16 ANN WORKSHOP IN, P303
   Go A., 2009, Twitter sentiment classification using distant supervision, V150, DOI DOI 10.1016/J.SEDGEO.2006.07.004
   Gunasekar M., 2019, Int J Recent Technol Eng, V8, P272
   Jindal N., 2008, WSDM 08, P219, DOI [DOI 10.1145/1341531.1341560, 10.1145/1341531.1341560]
   Kanna PR, 2019, PROCEDIA COMPUT SCI, V165, P356, DOI 10.1016/j.procs.2020.01.038
   Khelloufi A, 2021, IEEE INTERNET THINGS, V8, P1859, DOI 10.1109/JIOT.2020.3016659
   Kim S., 2004, P 20 INT C COMP LING, DOI DOI 10.3115/1220355.1220555
   Liu B., 2005, Proceedings of 14th International Conference of World Wide Web, P342
   Liu B, 2011, DATA CENTRIC SYST AP, P459, DOI 10.1007/978-3-642-19460-3_11
   Ma BZ, 2013, J ELECTRON COMMER RE, V14, P304
   Maia M, 2018, IEEE INT C SEMANT CO, P318, DOI 10.1109/ICSC.2018.00065
   Mukherjee A, 2012, P 21 INT C WORLD WID, P191
   Ning HS, 2019, IEEE T COMPUT SOC SY, V6, P394, DOI 10.1109/TCSS.2019.2903857
   Ramírez-Gallego S, 2017, NEUROCOMPUTING, V239, P39, DOI 10.1016/j.neucom.2017.01.078
   Romero C, 2014, A survey on pre-processing educational data, DOI [10.1007/978-3-319-02738-8_2, DOI 10.1007/978-3-319-02738-8_2]
   Shivaprasad TK, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P298, DOI 10.1109/ICICCT.2017.7975207
   Tan LKW, 2011, ICADL 2011, Lecture Notes in Computer Science, V7008, DOI [10.1007/978-3-642-24826-9_13, DOI 10.1007/978-3-642-24826-9_13]
   Thorat PB., 2015, INT J COMPUTER APPL, V110, P31, DOI DOI 10.5120/19308-0760
   Vanaja S., 2018, 2018 INT C INV RES C, P1275
   Woldemariam Y, 2016, 2016 IEEE INT C BIG, P1
   Yeung C.-m.A., 2011, Proceedings of The Fourth ACM International Conference on Web Search and Data Mining, P495
   Yu H, 2003, PROCEEDINGS OF THE 2003 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P129
   Zhang Y, 2013, PAKDD 2013, Lecture Notes in Computer Science, V7867, DOI [10.1007/978-3-642-40319-4_11, DOI 10.1007/978-3-642-40319-4_11]
   Zhang Z, 2021, WORLD WIDE WEB, V24, P1957, DOI 10.1007/s11280-021-00955-7
   Zhou SS, 2013, NEUROCOMPUTING, V120, P536, DOI 10.1016/j.neucom.2013.04.017
NR 36
TC 0
Z9 0
U1 12
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17415-1
EA NOV 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500019
DA 2024-07-18
ER

PT J
AU Singh, MK
AF Singh, Mahesh K.
TI A text independent speaker identification system using ANN, RNN, and CNN
   classification technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE ANN; CNN; Feature Extraction; RNN; Speaker identification
ID FEATURE FUSION; RECOGNITION; NETWORK; VOICE
AB Convolutional Neural network (CNN) has eclipsed end-to-end speaker identification (SI) systems in recent years. The enormous training data sets, high computational expenses, and memory usage all contribute to the lengthy time it takes to train a CNN. With fewer parameters but adequate accuracy, this study introduces an improved CNN for text-independent SI. Additional methods for reducing network training time and memory costs include offline feature extraction utilizing short segments of each audio sample and online data augmentation. On Voxceleb1, the proposed system appears to be more accurate than current speaker identification (SI) methods. Consequently, the suggested CNN enhances accuracy while lowering training time. Three feature extraction methods are employed in this work. Mel- frequency cepstrum coefficients (MFCC), Power-Normalized Cepstral Coefficients (PNCC), and Gammatone frequency cepstral coefficients (GFCC) are the abbreviations for these procedures. Classifier performance and speed are boosted even more with the application of principal component analysis (PCA), a feature reduction approach. Both methodologies make use of artificial neural networks (ANN) that have been trained using a variety of methods. Classification accuracy is improved by the sequential weight/bias training approach and the PNCC feature extraction technique. Our proposed technique calls for lowering the number of neurons that contribute to optimal performance and processing time. Here selected seven speech sample neurons those are white, pink, Volvo, clean, babble, factor, and destroyer for experimental purposes. This speech sample extracted the features using MFCC, GFCC, and PNCC techniques for experimental works. It is the maximum identification rate using MFCC feature extraction in comparison to the GFCC and PNCC feature extraction techniques. By using the proposed technique find out the maximum 96.90% SI using the MFCC feature extraction technique. The number of concealed units appears to be connected to the conversation's total number of participants. Here trained the RNN with 42-60 hidden units for 20 voices. More covert units increased the acceptance ratio by more than 90%.
C1 [Singh, Mahesh K.] Aditya Engn Coll, Dept ECE, Surampalem, India.
C3 Aditya Engineering College, Surampalem
RP Singh, MK (corresponding author), Aditya Engn Coll, Dept ECE, Surampalem, India.
EM mahesh.092002.ece@gmail.com
CR Abu-Hantash AM, 2010, Text-independent speaker identification system
   Almaadeed N, 2016, J SIGNAL PROCESS SYS, V82, P345, DOI 10.1007/s11265-015-1005-5
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   BIMBOT F, 1995, SPEECH COMMUN, V17, P177, DOI 10.1016/0167-6393(95)00013-E
   Cordella LP, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P632, DOI 10.1109/ICIAP.2003.1234121
   Espy-Wilson CY, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1475
   Jahangir R, 2020, IEEE ACCESS, V8, P32187, DOI 10.1109/ACCESS.2020.2973541
   Jalil Ali Muayad, 2019, 2019 First International Conference of Computer and Applied Sciences (CAS), P57, DOI 10.1109/CAS47993.2019.9075461
   Ji RF, 2018, INTERSPEECH, P3628, DOI 10.21437/Interspeech.2018-1058
   Li DM, 2019, INFORM SCIENCES, V479, P432, DOI 10.1016/j.ins.2018.02.060
   Liu JC, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4255
   Murthy HA, 1999, IEEE T SPEECH AUDI P, V7, P554, DOI 10.1109/89.784108
   Pareek K, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.300357
   Purnama J, 2019, INT J SOFTW SCI COMP, V11, P1, DOI 10.4018/IJSSCI.2019010101
   Rashed A, 2013, INT J COMPUT SCI NET, V13, P8
   Reynolds DA, 1992, A Gaussian mixture modeling approach to text-independent speaker identification
   ROSE RC, 1990, INT CONF ACOUST SPEE, P293, DOI 10.1109/ICASSP.1990.115638
   Shi Y, 2019, arXiv, DOI [10.48550/arXiv.1909.11200, DOI 10.48550/ARXIV.1909.11200]
   Singh Mahesh K., 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P317
   Singh MK, 2020, MULTIMED TOOLS APPL, V79, P35537, DOI 10.1007/s11042-019-08329-y
   Singh MK, 2019, MULTIMED TOOLS APPL, V78, P29395, DOI 10.1007/s11042-018-6718-6
   Singh MK, 2019, TRAIT SIGNAL, V36, P455, DOI 10.18280/ts.360511
   Singh MK, 2018, Int. J. Eng. Technol. (UAE), DOI [10.14419/ijet.v7i2,16, DOI 10.14419/IJET.V7I2,16]
   Singh MK., 2018, Int J Pure Appl Math, V11, P241
NR 25
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17573-2
EA NOV 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900002
DA 2024-07-18
ER

PT J
AU Cao, YL
   Xu, HQ
   Zhou, ZH
   Yue, WL
   Zhuge, S
   Li, F
AF Cao, Yinglie
   Xu, Haoqi
   Zhou, Zhiheng
   Yue, Wanlin
   Zhuge, Shang
   Li, Fei
TI Super-resolution reconstructed video coding scheme based on inter-frame
   information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video coding scheme; Super-resolution; Inter-frame correlation; HEVC
AB In recent years, the explosive growth of video data has posed a challenge to the performance of traditional video coding frameworks. The industry is thus faced with the pressing issue of how to transmit high-quality videos under limited bandwidth conditions. To address this challenge, a super-resolution reconstruction video coding scheme has been proposed, which combines traditional coding frameworks with deep learning-based super-resolution technology. By reducing the data coding volume through pre-coding downsampling and reconstructing videos through post-decoding upsampling, this scheme shows great potential in solving the aforementioned problems. However, previous super-resolution reconstruction video coding schemes have failed to effectively utilize the inter-frame correlation of video sequences, which limits the coding efficiency of the scheme. To overcome this limitation, this paper proposes an upsampling reconstruction network based on inter-frame information exploration. Experimental results show that, compared with the HEVC standard, the proposed scheme achieves a reduction of 11.05%, 11.3%, and 8.84% in the BD-BR index under the All-Intra, Low Delay P, and Random Access coding configurations, respectively, demonstrating higher coding efficiency than the previous human-designed scheme.
C1 [Cao, Yinglie] Guangzhou City Univ Technol, Dept, Guangzhou 510030, Peoples R China.
   [Xu, Haoqi; Zhou, Zhiheng; Yue, Wanlin; Zhuge, Shang] South China Univ Technol, Dept, Guangzhou 510641, Peoples R China.
   [Li, Fei] Pengcheng lab, Dept, Shenzhen 518055, Peoples R China.
C3 South China University of Technology
RP Cao, YL (corresponding author), Guangzhou City Univ Technol, Dept, Guangzhou 510030, Peoples R China.
EM caoyl@gcu.edu.cn; jiacinker@163.com; zhouzh@scut.edu.cn;
   202121014322@mail.scut.edu.cn; 202221013537@mail.scut.edu.cn;
   lifei21@mails.ucas.ac.cn
FU The work is supported by the National Key Research and Development
   Program of China(2022YFF0607000), National Natural Science Foundation of
   China (61871188), Guangdong Basic and Applied Basic Research Foundation
   (2023A1515010993), Guangdong Provincial Key [2022YFF0607000]; National
   Key Research and Development Program of China [61871188]; National
   Natural Science Foundation of China [2023A1515010993]; Guangdong Basic
   and Applied Basic Research Foundation [2022B1212010004]; Guangdong
   Provincial Key Laboratory of Human Digital Twin [2023B01J0011];
   Guangzhou City Science and Technology Research Projects
FX The work is supported by the National Key Research and Development
   Program of China(2022YFF0607000), National Natural Science Foundation of
   China (61871188), Guangdong Basic and Applied Basic Research Foundation
   (2023A1515010993), Guangdong Provincial Key Laboratory of Human Digital
   Twin (2022B1212010004), Guangzhou City Science and Technology Research
   Projects (2023B01J0011).
CR Bjontegaard G, 2001, ITU SG16 Doc. VCEG-M33
   Bross B, 2021, IEEE T CIRC SYST VID, V31, P3736, DOI 10.1109/TCSVT.2021.3101953
   Chan KCK, 2021, PROC CVPR IEEE, P4945, DOI 10.1109/CVPR46437.2021.00491
   Chen Y, 2018, PICT COD SYMP, P41, DOI 10.1109/PCS.2018.8456249
   Cisco U., 2021, white paper, P1
   Ho MM, 2021, IEEE T IMAGE PROCESS, V30, P1702, DOI 10.1109/TIP.2020.3046872
   Ho MM, 2020, LECT NOTES COMPUT SC, V11961, P99, DOI 10.1007/978-3-030-37731-1_9
   Huang Y, 2018, IEEE T PATTERN ANAL, V40, P1015, DOI 10.1109/TPAMI.2017.2701380
   Lin CY, 2021, IEEE I C VI COM I PR, DOI 10.1109/VCIP53242.2021.9675417
   LIOU M, 1991, COMMUN ACM, V34, P59, DOI 10.1145/103085.103091
   Montgomery C., 1994, Xiph. org video test media (derf's collection)
   Rijkse K, 1996, IEEE COMMUN MAG, V34, P42, DOI 10.1109/35.556485
   Shen MM, 2011, IEEE T CIRC SYST VID, V21, P755, DOI 10.1109/TCSVT.2011.2130390
   SHLIEN S, 1994, IEEE T BROADCAST, V40, P206, DOI 10.1109/11.362938
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian YP, 2020, PROC CVPR IEEE, P3357, DOI 10.1109/CVPR42600.2020.00342
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 18
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 31
PY 2023
DI 10.1007/s11042-023-17441-z
EA OCT 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XH9
UT WOS:001090305500001
DA 2024-07-18
ER

PT J
AU Yuan, FN
   Zhang, L
   Xia, X
AF Yuan, Feiniu
   Zhang, Lin
   Xia, Xue
TI Smoke semantic segmentation with multi-scale residual paths and weighted
   middle surveillances
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Convolutional neural network; Multiple prediction; Multi-prediction
   loss; Multi-scale residual module; Smoke semantic segmentation
ID FULLY CONVOLUTIONAL NETWORKS; FEATURES
AB Visual smoke segmentation is widely used for fire detection, simulation, human evacuation and pollution monitoring. However, it is challenging to accurately separate smoke from a single image due to highly complicated appearance of smoke, such as blurriness, semi-transparency and varying shapes. We design several multi-resolution convolutional paths to generate multi-scale feature maps for obtaining scale invariance. To capture the feature representation of blurriness and semi-transparency features, we present a Multi-scale Residual Module (MRM) by significantly increasing the width and depth of residual paths. Combining learnable de-convolution and bilinear interpolation has the advantage of generating multi-scale features that are helpful to progressively produce up-sampled and middle predictions for training surveillances. By designing a monotonically decreasing function with respect to the independent pre-training error of each prediction, we implement an automatic regulation of relative importance for accelerating the training. Experimental results show that our method achieves the best results of 79.03%, 78.30% and 78.65% on the three virtual smoke data sets among state-of-the-art methods. In addition, another superiority of our method is the proposed multi-prediction loss making the training of our network to converge faster and more stably.
C1 [Yuan, Feiniu] Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai 201418, Peoples R China.
   [Yuan, Feiniu] Shanghai Normal Univ, Key Innovat Grp Digital Humanities Resource & Res, Shanghai 200234, Peoples R China.
   [Zhang, Lin] Jiangxi Sci & Technol Normal Univ, Sch Math & Comp Sci, Nanchang 330038, Jiangxi, Peoples R China.
   [Xia, Xue] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang 330032, Jiangxi, Peoples R China.
C3 Shanghai Normal University; Shanghai Normal University; Jiangxi Science
   & Technology Normal University; Jiangxi University of Finance &
   Economics
RP Yuan, FN (corresponding author), Shanghai Normal Univ, Coll Informat Mech & Elect Engn, Shanghai 201418, Peoples R China.; Yuan, FN (corresponding author), Shanghai Normal Univ, Key Innovat Grp Digital Humanities Resource & Res, Shanghai 200234, Peoples R China.
EM yfn@ustc.edu
FU This work was partially supported by the National Natural Science
   Foundation of China (62272308) and the Capacity Construction Project of
   Shanghai Local Colleges (23010504100). [62272308]; National Natural
   Science Foundation of China [23010504100]; Capacity Construction Project
   of Shanghai Local Colleges
FX This work was partially supported by the National Natural Science
   Foundation of China (62272308) and the Capacity Construction Project of
   Shanghai Local Colleges (23010504100).
CR Islam MA, 2017, Arxiv, DOI [arXiv:1703.00551, DOI 10.48550/ARXIV.1703.00551]
   Andrearczyk V, 2018, PATTERN RECOGN, V76, P36, DOI 10.1016/j.patcog.2017.10.030
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bilinski P, 2018, PROC CVPR IEEE, P6596, DOI 10.1109/CVPR.2018.00690
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Chen J, 2013, IEEE T IMAGE PROCESS, V22, P326, DOI 10.1109/TIP.2012.2210234
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen X, 2018, LECT NOTES COMPUT SC, V11217, P674, DOI 10.1007/978-3-030-01261-8_40
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dimitropoulos K, 2017, IEEE T CIRC SYST VID, V27, P1143, DOI 10.1109/TCSVT.2016.2527340
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Durand T, 2017, PROC CVPR IEEE, P5957, DOI 10.1109/CVPR.2017.631
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Filonenko A, 2018, IEEE T IND INFORM, V14, P725, DOI 10.1109/TII.2017.2757457
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu Yan, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P1138
   Jain SD, 2017, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2017.228
   Jia Yang, 2016, Computer Engineering, V42, P206, DOI 10.3969/j.issn.1000-3428.2016.02.037
   Jiao LC, 2017, IEEE T GEOSCI REMOTE, V55, P5585, DOI 10.1109/TGRS.2017.2710079
   Jun TJ, 2020, NEURAL NETWORKS, V128, P216, DOI 10.1016/j.neunet.2020.05.002
   Kaabi R., 2018, International Conference on Advanced Technologies for Signal and Image Processing, P1, DOI 10.1109/ATSIP.2018.8364446
   Karen S, 2014, P ICLR
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li XQ, 2020, IEEE T CIRC SYST VID, V30, P89, DOI 10.1109/TCSVT.2018.2889193
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin ZJ, 2019, IEEE T IND ELECTRON, V66, P606, DOI 10.1109/TIE.2018.2823658
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo P, 2017, IEEE I CONF COMP VIS, P2737, DOI 10.1109/ICCV.2017.296
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Mou LC, 2018, IEEE T GEOSCI REMOTE, V56, P391, DOI 10.1109/TGRS.2017.2748160
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sagar A., 2018, Int Res J Eng Technol, V5, P3843
   Salehi SSM, 2017, IEEE T MED IMAGING, V36, P2319, DOI 10.1109/TMI.2017.2721362
   Signatone, About us
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yuan FN, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2022.109289
   Yuan FN, 2023, DIGIT SIGNAL PROCESS, V134, DOI 10.1016/j.dsp.2023.103924
   Yuan FN, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108902
   Yuan FN, 2020, IEEE T IMAGE PROCESS, V29, P2301, DOI 10.1109/TIP.2019.2946126
   Yuan FN, 2019, NEUROCOMPUTING, V357, P248, DOI 10.1016/j.neucom.2019.05.011
   Yuan FN, 2019, MACH VISION APPL, V30, P345, DOI 10.1007/s00138-018-0990-3
   Yuan FN, 2019, IET COMPUT VIS, V13, P178, DOI 10.1049/iet-cvi.2018.5164
   Yuan FN, 2016, INFORM SCIENCES, V372, P225, DOI 10.1016/j.ins.2016.08.040
   Yuan FN, 2012, PATTERN RECOGN, V45, P4326, DOI 10.1016/j.patcog.2012.06.008
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zhang N., 2015, J FRONT COMPUT SCI T, V11, P1296
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang Z, 2016, PROC CVPR IEEE, P4159, DOI 10.1109/CVPR.2016.451
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao Y., 2015, J Electr Comput Eng, V2015, P1
NR 69
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-17260-2
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500010
DA 2024-07-18
ER

PT J
AU Rajakani, M
   Kavitha, RJ
AF Rajakani, M.
   Kavitha, R. J.
TI Invasive weed optimization with deep transfer learning for multispectral
   image classification model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mulitspectral images; Image classification; Deep learning;
   Meta-heuristics; Capsule network
AB Multispectral image classification is a field of static learning with non-stationary input data assumptions. The evolution of Industry 4.0 has resulted in the development of multispectral images in several application areas. The classification of multispectral images is a tedious process due to its complex characteristics of including spectral as well as spatial features. The recent developments of machine learning (ML) and deep learning (DL) paves a way for the design of effectual computer vision tasks such as object recognition, classification, etc. With this motivation, this paper presents an Invasive Weed Optimization with Capsule Network for Multispectral Image Classification (IWOCN-MSIC) technique. The major intention of the IWOCN-MSIC technique incorporates multilevel discrete wavelet transform (DWT) based image decomposition technique, which decomposes the input image into distinct subbands. Besides, IWO algorithm with Capsule Network (CapsNet) model is applied to derive a useful subset of feature vectors. The complex computation in Capsule Networks(CapsNet) requires hyper-parameters to achieve high classification outputs, which requires more computational time and effort. To overcome this difficulty, a bio-inspired meta-heuristic strategy based Invasive Weed optimization is proposed in this research paper. It allows one to automatically search for and select the appropriate values of CapsNet hyper-parameters. Finally, Deep Denoising Auto-Encoder (DDAE) model is employed for the detection and classification of multispectral images. The experimental result analysis of the IWOCN-MSIC technique reported the better performance of the IWOCN-MSIC technique over the recent state of art approaches.
C1 [Rajakani, M.] SRM Inst Sci & Technol, Fac Engn & Technol, Sch Comp, Dept Data Sci & Business Syst, SRM Nagar, Chennai, India.
   [Kavitha, R. J.] Univ Coll Engn, Dept Elect & Commun Engn, Panruti 607106, India.
C3 SRM Institute of Science & Technology Chennai
RP Rajakani, M (corresponding author), SRM Inst Sci & Technol, Fac Engn & Technol, Sch Comp, Dept Data Sci & Business Syst, SRM Nagar, Chennai, India.
EM rajakanijes@gmail.com; drrjk@ucep.edu.in
RI Manoharan, Rajakani/JTU-5106-2023
OI , M.Rajakani/0000-0003-0666-7255; , Dr R J Kavitha/0009-0000-1450-980X
CR Alhassan V, 2020, NEURAL COMPUT APPL, V32, P8529, DOI 10.1007/s00521-019-04349-9
   Chebbi I, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5020021
   Fu G, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9050498
   Garnot VS, 2019, INT GEOSCI REMOTE SE, P6247, DOI [10.1109/IGARSS.2019.8900517, 10.1109/igarss.2019.8900517]
   Gómez P, 2021, IEEE J-STARS, V14, P11643, DOI 10.1109/JSTARS.2021.3126082
   He TD, 2021, J SUPERCOMPUT, V77, P2829, DOI 10.1007/s11227-020-03377-w
   Imamoglu N, 2018, PROCEDIA COMPUT SCI, V140, P162, DOI 10.1016/j.procs.2018.10.325
   Jameel SM, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8361989
   Kumar Deepak, 2023, International Journal of Information Technology, P379, DOI 10.1007/s41870-022-01075-9
   Abdelkader EM, 2021, TRANSPORT RES REC, V2675, P167, DOI 10.1177/0361198120967943
   Muralimohanbabu Y., 2021, International Journal of Bioinformatics Research and Applications, V17, P250, DOI 10.1504/IJBRA.2021.117169
   Nasiri V, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14061453
   Navarro PJ, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040729
   Nisia TG, 2022, EUR J REMOTE SENS, V55, P326, DOI 10.1080/22797254.2022.2075794
   Piao J, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21060570
   Prathap G, 2018, 2018 9TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P461, DOI 10.1109/IS.2018.8710471
   Ren JS, 2023, APPL INTELL, V53, P14162, DOI 10.1007/s10489-022-04232-6
   Saad OM, 2020, GEOPHYSICS, V85, pV367, DOI [10.1190/GEO2019-0468.1, 10.1190/geo2019-0468.1]
   Saralioglu E, 2022, GEOCARTO INT, V37, P657, DOI 10.1080/10106049.2020.1734871
   Senecal JJ, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851840
   Shi ML, 2023, MULTIMED TOOLS APPL, V82, P40473, DOI 10.1007/s11042-023-15017-5
   Singh M, 2021, REMOTE SENS APPL, V24, DOI 10.1016/j.rsase.2021.100645
   Vali A, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12152495
   Yu YT, 2021, INT J APPL EARTH OBS, V104, DOI 10.1016/j.jag.2021.102548
NR 24
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17429-9
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000006
DA 2024-07-18
ER

PT J
AU Kumar, A
AF Kumar, Arun
TI A low complex PTS-SLM-Companding technique for PAPR reduction in 5G NOMA
   waveform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE PAPR; FPTS-SLM; 5G; BER; PSD
ID SCHEME; SYSTEM
AB Non-Orthogonal Multiple Access (NOMA) has emerged as a promising technology to enhance spectrum efficiency and accommodate the ever-increasing demand for higher data rates and improved connectivity. However, one of the critical challenges associated with NOMA is the high Peak to Average Power Ratio (PAPR) of transmitted signals, which can lead to signal distortion and reduced power efficiency of the framework. This paper presents a novel and efficient approach for PAPR reduction in 5G NOMA waveforms, utilizing a low-complexity Partial transmission Selection based Selective Mapping (PTS-SLM-Companding) technique. The proposed PTS-SLM technique leverages the advantages of both precoding and transform domain techniques to efficiently reduce PAPR. In the precoding stage, the transmitted signals are adaptively precoded to manipulate their amplitudes, followed by a selection process that identifies the optimal precoding scheme for each symbol. Subsequently, the selected precoding schemes are combined with a transform domain technique, namely selective mapping (SLM), which further reduces PAPR by generating alternative signal sequences with lower peak amplitudes. Simulation results demonstrate that the proposed low-complexity PTS-SLM technique effectively reduces PAPR in 5G NOMA waveforms, surpassing the performance of existing PAPR reduction methods while maintaining low computational overhead. The trade-off between PAPR reduction and computational complexity is systematically evaluated, revealing that the proposed technique achieves a favorable balance for practical implementation. It should be noted that the hybrid techniques increase gain and power efficiency to 4.34 dB and 34%, respectively, while lowering the PAPR to 3.1 dB. Further, it is noted that the bit error rate (BER) of the framework is retained while optimizing the PAPR and power spectral density performance.
C1 [Kumar, Arun] New Horizon Coll Engn, Dept Elect & Commun Engn, Bengaluru, India.
RP Kumar, A (corresponding author), New Horizon Coll Engn, Dept Elect & Commun Engn, Bengaluru, India.
EM arun.kumar1986@live.com
RI kumar, Arun/AIB-1377-2022
OI kumar, Arun/0000-0001-7640-8975
CR Afrasiabi-Gorgani S., 2016, "A Versatile PAPR Reduction Algorithm for 5G Waveforms with Guaranteed Performance," WSA 2016; 20th International ITG Workshop on Smart Antennas, P1
   Baig I, 2017, IEEE ACCESS, V5, P19233, DOI 10.1109/ACCESS.2017.2752804
   Chen JC, 2017, IEEE COMMUN LETT, V21, P945, DOI 10.1109/LCOMM.2017.2650218
   Chen YM, 2022, IEEE T VEH TECHNOL, V71, P11936, DOI 10.1109/TVT.2022.3194254
   Cheng X, 2020, IEEE T BROADCAST, V66, P656, DOI 10.1109/TBC.2020.2977548
   Chore Nitin M., 2019, 2019 2nd International Conference on Intelligent Computing, Instrumentation and Control Technologies (ICICICT), P243, DOI 10.1109/ICICICT46008.2019.8993230
   Deng Y., 2022, Journal of Artificial Intelligence and Technology, V2, P55, DOI [/10.37965/jait.2022.0066, DOI 10.37965/JAIT.2022.0066]
   Gerzaguet R, 2017, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0792-0
   Ghafoor U, 2022, J NETW COMPUT APPL, V204, DOI 10.1016/j.jnca.2022.103413
   Gopi S, 2020, IEEE WIREL COMMUN LE, V9, P967, DOI 10.1109/LWC.2020.2976935
   Gupta P, 2022, INT J ELECTRON, V109, P1252, DOI 10.1080/00207217.2021.1966671
   Hao LL, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9050852
   Hassan M, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12040815
   Hu C, 2020, IEEE INT CONF ELECTR, P61, DOI 10.1109/iceiec49280.2020.9152350
   Hu F, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS AND MICROSYSTEMS (ICICM 2019), P204, DOI [10.1109/icicm48536.2019.8977168, 10.1109/ICICM48536.2019.8977168]
   Jin C, 2022, CAAI T INTELL TECHNO, V7, P369, DOI 10.1049/cit2.12065
   Kaba R. R., 2021, Social Netw. Comput. Sci., V2, P262
   Karthika J, 2021, MATER TODAY-PROC, V37, P2563, DOI 10.1016/j.matpr.2020.08.498
   Kumar Arun, 2019, Radioelectronics and Communications Systems, V62, P416, DOI 10.3103/S0735272719080053
   Kumar A, 2023, OPT QUANT ELECTRON, V55, DOI 10.1007/s11082-023-05148-2
   Kumar A, 2023, INT J COMMUN SYST, V36, DOI 10.1002/dac.5412
   Kumar A, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14159631
   Kumar A, 2020, SOFT COMPUT, V24, P11893, DOI 10.1007/s00500-020-05086-1
   Kumar A, 2018, ALEX ENG J, V57, P1125, DOI 10.1016/j.aej.2017.01.043
   Kumari S, 2021, COMPUT COMMUN, V178, P161, DOI 10.1016/j.comcom.2021.07.023
   Kumari S, 2021, COMPUT COMMUN, V171, P10, DOI 10.1016/j.comcom.2021.02.004
   Lin P, 2019, LECT NOTES COMPUT SC, V11513, P161, DOI 10.1007/978-3-030-23502-4_12
   Liu Z., 2021, 2021 13 INT C WIR CO, P1, DOI [10.1109/WCSP52459.2021.9613351, DOI 10.1109/WCSP52459.2021.9613351]
   Mohammady S, 2020, INFORMATION, V11, DOI 10.3390/info11010020
   Namasudra S, 2014, 2014 INTERNATIONAL CONFERENCE ON GREEN COMPUTING COMMUNICATION AND ELECTRICAL ENGINEERING (ICGCCEE)
   Rateb AM, 2019, IEEE ACCESS, V7, P16406, DOI 10.1109/ACCESS.2019.2895415
   Sahin MM, 2021, IEEE OPEN J COMM SOC, V2, P67, DOI 10.1109/OJCOMS.2020.3044680
   Sanadhya Gayatri, 2018, 2018 2nd International Conference on Micro-Electronics and Telecommunication Engineering (ICMETE), P168, DOI 10.1109/ICMETE.2018.00046
   Sayyari R, 2022, IEEE WCNC, P1719, DOI 10.1109/WCNC51071.2022.9771812
   Sharma H., 2023, COMPUT SYST SCI ENG, V45, P1199, DOI [10.32604/csse.2023.030909, DOI 10.32604/CSSE.2023.030909]
   Sharma MK, 2021, CMC-COMPUT MATER CON, V69, P1391, DOI 10.32604/cmc.2021.017666
   Shiying Zeng, 2021, 2021 International Wireless Communications and Mobile Computing (IWCMC), P1259, DOI 10.1109/IWCMC51323.2021.9498918
   Sravanti Thota, 2014, International Conference on Computing and Communication Technologies (ICCCT). Proceedings, P1, DOI 10.1109/ICCCT2.2014.7066735
   van der Neut N, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-172
   Vangala S, 2016, PROCEDIA COMPUT SCI, V93, P632, DOI 10.1016/j.procs.2016.07.251
   Wang H, 2018, INFORMATION, V9, DOI 10.3390/info9100246
   Wang M., 2022, J. Artif. Intell. Technol., DOI [10.37965/jait.2022.0120, DOI 10.37965/JAIT.2022.0120]
   Zhang TH, 2023, IEEE PHOTONIC TECH L, V35, P418, DOI 10.1109/LPT.2022.3233076
   Zheng Q., 2017, 2017 32 GEN ASS SCI, P1, DOI [10.23919/URSIGASS.2017.8105377, DOI 10.23919/URSIGASS.2017.8105377]
NR 44
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17223-7
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6NT6
UT WOS:001085957900005
DA 2024-07-18
ER

PT J
AU Saroja, S
   Madavan, R
   Revathi, T
   Hu, YC
AF Saroja, S.
   Madavan, R.
   Revathi, T.
   Hu, Yu-Chen
TI QoS aware productive and resourceful service allocation in fog for
   multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Resource allocation; Makespan; Fog computing; League championship
   algorithm; QoS
ID ALGORITHM; CLOUD
AB Fog computing is a computer architecture consisting of fog nodes, a collection of near-user edge devices. These fog nodes collaborate to perform computational services like data retrieval, processing, storage, etc. Resource allocation is one of the most critical and challenging problems in the fog environment for industrial applications. The significant aspects to consider while allocating resources are response time, throughput, and energy consumption. The proposed work formulated the resource allocation problem as a bi-objective minimization problem. The main aim of the work is to reduce energy consumption and makespan while allocating service requests to virtual machines. The proposed technique uses the league championship algorithm to select an efficient resource for productive and resourceful service allocation of tasks in fog computing. The proposed algorithm's performance is assessed by comparing it to three well-known metaheuristic algorithms. Finally, the simulation results show that the proposed algorithm is superior in terms of makespan and energy consumption.
C1 [Saroja, S.] Natl Inst Technol, Dept Comp Applicat, Trichy, India.
   [Madavan, R.] K Ramakrishnan Coll Technol Autonomous, Dept Elect & Elect Engn, Trichy, Tamil Nadu, India.
   [Revathi, T.] Mepco Schlenk Engn Coll, Dept Informat Technol, Sivakasi, India.
   [Hu, Yu-Chen] TungHai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd, Taichung 407224, Taiwan.
   [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; Mepco Schlenk Engineering College; Tunghai
   University; Providence University - Taiwan
RP Hu, YC (corresponding author), TungHai Univ, Dept Comp Sci, 1727,Sec 4,Taiwan Blvd, Taichung 407224, Taiwan.; Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, 200,Sec 7,Taiwan Blvd, Taichung 43301, Taiwan.
EM saroja@nitt.edu; srmadavan@gmail.com; trevathi@mepcoeng.ac.in;
   ychu@thu.edu.tw
RI Thiagarajan, REVATHI/T-2901-2019
OI Thiagarajan, REVATHI/0000-0002-2024-9933; Hu,
   Yu-Chen/0000-0002-5055-3645
CR Abdulhamid SM, 2017, APPL SOFT COMPUT, V61, P670, DOI 10.1016/j.asoc.2017.08.048
   Abouaomar A, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9014146
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alizadeh N, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105657
   Souza VB, 2016, IEEE GLOB COMM CONF
   Barbulescu M, 2013, ROEDUNET INT C NETW, DOI [10.1109/RoEduNet.2013.6714197, DOI 10.1109/ROEDUNET.2013.6714197]
   Ben Lahmar I, 2020, 2020 FIFTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P86, DOI [10.1109/FMEC49853.2020.9144705, 10.1109/fmec49853.2020.9144705]
   Bergmann N., 2013, Modern Applied Science, V7, P59, DOI [10.5539/mas.v7n6p59, DOI 10.5539/MAS.V7N6P59]
   da Silva RAC, 2018, IEEE ICC
   Deng RL, 2016, IEEE INTERNET THINGS, V3, P1171, DOI 10.1109/JIOT.2016.2565516
   Divya V, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6268
   K.S, 2014, A League Championship Algorithm for Travelling Salesman Problem
   Kashan AH, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P43, DOI 10.1109/SoCPaR.2009.21
   Kashan AH, 2014, APPL SOFT COMPUT, V16, P171, DOI 10.1016/j.asoc.2013.12.005
   Kashyap V, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172668
   Kaul S, 2022, MULTIMED TOOLS APPL, V81, P26779, DOI 10.1007/s11042-021-11011-x
   Lenin K., 2013, International Journal of Computer and Information Technology, V1, P1
   Lizheng Guo, 2012, Journal of Networks, V7, P547, DOI 10.4304/jnw.7.3.547-553
   Mishra SK, 2018, IEEE T IND INFORM, V14, P4497, DOI 10.1109/TII.2018.2791619
   Nassar A, 2019, IEEE ACCESS, V7, P128014, DOI 10.1109/ACCESS.2019.2939735
   Pawar CS, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P311, DOI 10.1109/ISSP.2013.6526925
   Raghavan S, 2015, 2015 INTERNATIONAL CONFERENCE ON ELECTRONIC DESIGN, COMPUTER NETWORKS & AUTOMATED VERIFICATION (EDCAV), P139, DOI 10.1109/EDCAV.2015.7060555
   Sebastian AR, 2014, Scheduling To Job Shop Configuration Minimizing The Makespan Using Champions League Algorithm
   Sofla MS, 2022, MULTIMED TOOLS APPL, V81, P1997, DOI 10.1007/s11042-021-11423-9
   Subbaraj S, 2020, NEURAL COMPUT APPL, V32, P5093, DOI 10.1007/s00521-018-3950-y
   Talaat FM, 2022, MULTIMED TOOLS APPL, V81, P8235, DOI 10.1007/s11042-022-12223-5
   Tsai CW, 2014, IEEE SYST J, V8, P279, DOI 10.1109/JSYST.2013.2256731
   Ul Islam MS, 2021, J NETW COMPUT APPL, V180, DOI 10.1016/j.jnca.2021.103008
   Xu XL, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/6421607
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P7126, DOI 10.1109/TNNLS.2021.3084250
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yin LX, 2018, IEEE T IND INFORM, V14, P4712, DOI 10.1109/TII.2018.2851241
   Zhan ZH, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788397
   Zigkolis C, 2014, MULTIMED TOOLS APPL, V70, P89, DOI 10.1007/s11042-012-1154-5
   Zuo LY, 2018, IEEE SYST J, V12, P1518, DOI 10.1109/JSYST.2016.2542251
NR 39
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17387-2
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600003
DA 2024-07-18
ER

PT J
AU Pingle, YP
   Ragha, LK
AF Pingle, Yogesh Prabhakar
   Ragha, Lakshmappa K.
TI An in-depth analysis of music structure and its effects on human body
   for music therapy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Music therapy; Emotions; Classification; Artificial intelligence;
   Recommendation
ID DEMENTIA; CHILDREN; ANXIETY; STROKE; MEDICINE
AB Music therapy is a therapeutic strategy that uses the natural mood enhancing feature of music to help patients improve their mental health. The music therapist employs a variety of therapies, which can be grouped into two main groups: active interventions and passive interventions. Passive music therapy strategies allow the patient to listen live or recorded music, while active methods engage the patient to sing, compose, or play an instrument. Natural sounds, classical music, or Western music can help patients feel less anxious by lowering cortisol levels, blood pressure, and heart rate. The frequency and length of each music therapy session might vary greatly depending on the desired result, the patient's preferences, and the environment in which the therapy is provided. This paper provides the frequencies for swaras of both classical music and western music to carefully study the frequency difference between the music. Also, it studies the Indian Classical Ragas Structure and its Influence on Human Body for Music Therapy. This investigation has explicitly demonstrated that different ragas can generate different emotions and examined the significance of various music for metabolic syndrome. Finally, it identifies the need for AI to provide valuable information and recommendations for patients. This study can be used to increase the understanding ability of researchers regarding music therapy and its effects related to different diseases.
C1 [Pingle, Yogesh Prabhakar; Ragha, Lakshmappa K.] Terna Engn Coll, Dept Comp Engn, Mumbai 400706, India.
RP Pingle, YP (corresponding author), Terna Engn Coll, Dept Comp Engn, Mumbai 400706, India.
EM yogeshpingle1977@gmail.com
RI Pingle, Yogesh/AAT-2283-2020
OI Pingle, Yogesh/0000-0003-2124-885X
CR Achar A., 2021, MAMC J Med Sci, V7, P251
   Algoodkar S, 2019, Depression, V5
   Alrihaili A, 2019, I C DEV ESYST ENG, P1014, DOI 10.1109/DeSE.2019.00188
   Atiwannapat P, 2016, COMPLEMENT THER MED, V26, P141, DOI 10.1016/j.ctim.2016.03.015
   Balkrishna A, 2018, J Yoga Physiother, P2476
   Banerjee S, 2017, ADV INTELL SYST, V458, P467, DOI 10.1007/978-981-10-2035-3_48
   Bardekar AA, 2016, PROCEEDINGS OF THE 2016 2ND INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P119, DOI 10.1109/ICATCCT.2016.7911976
   Bhardwaj N, 2018, Sangeet Galaxy, V7
   Bhatkhande V.N., 1974, A short historical survey of the music of upper India
   Broder-Fingert S, 2017, JAMA-J AM MED ASSOC, V318, P523, DOI 10.1001/jama.2017.9477
   Bunte K, 2021, EUR J ORAL SCI, V129, DOI 10.1111/eos.12776
   Calamassi D, 2019, EXPLORE-NY, V15, P283, DOI 10.1016/j.explore.2019.04.001
   Chahal JK, 2021, CLIN EPIDEMIOL GLOB, V11, DOI 10.1016/j.cegh.2021.100716
   Chakraborty S., 2021, Hindustani classical music: a historical and computational study
   Chatterjee S, 2020, J Sci Res, V64
   Datta AK, 2017, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-981-10-3959-1
   de Witte M, 2022, HEALTH PSYCHOL REV, V16, P134, DOI 10.1080/17437199.2020.1846580
   Deka S, 2022, MATER TODAY-PROC, V57, P2152, DOI 10.1016/j.matpr.2021.12.181
   Devendran K, 2021, EDP Sciences, V37
   Fogg-Rogers L, 2016, DISABIL REHABIL, V38, P952, DOI 10.3109/09638288.2015.1068875
   Fusar-Poli L, 2018, AGING MENT HEALTH, V22, P1097, DOI 10.1080/13607863.2017.1348474
   He CX, 2015, NUTR RES, V35, P361, DOI 10.1016/j.nutres.2015.03.002
   Kar SK, 2015, J ANAESTH CRIT CARE, V2, P47
   Kruthika G., 2021, Intelligent Data Communication Technologies and Internet of Things. Proceedings of ICICI 2020. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 57), P345, DOI 10.1007/978-981-15-9509-7_30
   Kumar A., 2019, Artizein: Arts Teach J, V4, P9
   Kumar TS, 2014, INDIAN J SURG, V76, P363, DOI 10.1007/s12262-012-0705-3
   Laksmidewi Anak Agung Ayu Putri, 2019, Open Access Maced J Med Sci, V7, P553, DOI 10.3889/oamjms.2019.116
   Leonardi S, 2018, INT J NEUROSCI, V128, P90, DOI 10.1080/00207454.2017.1353981
   Li HC, 2015, J AM MED DIR ASSOC, V16, P71, DOI 10.1016/j.jamda.2014.10.004
   Lin FC, 2017, J TRADIT CHIN MED, V37, P675
   Liu Y, 2015, IEEE T AFFECT COMPUT, V6, P247, DOI 10.1109/TAFFC.2015.2396151
   Lokhande P, 2016, International Journal of Innovations in Engineering and Technology (IJIET), V7
   Magee WL, 2015, ANN NY ACAD SCI, V1337, P256, DOI 10.1111/nyas.12633
   Mandel SE, 2013, DIABETES EDUCATOR, V39, P568, DOI 10.1177/0145721713492216
   Marquez-Garcia AV, 2022, REV J AUTISM DEV DIS, V9, P91, DOI 10.1007/s40489-021-00246-x
   Mathur A, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00513
   Matthews S, 2015, BIOETHICS, V29, P573, DOI 10.1111/bioe.12148
   Modise JM, 2023, RELIGIONS, V14, DOI 10.3390/rel14010045
   Modran HA, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020986
   Mofredj A, 2016, J CRIT CARE, V35, P195, DOI 10.1016/j.jcrc.2016.05.021
   Mössler K, 2019, J AUTISM DEV DISORD, V49, P2795, DOI 10.1007/s10803-017-3306-y
   Norman A.W., 1997, HORMONES, V2nd
   Palmer JB, 2015, J CLIN ONCOL, V33, P3162, DOI 10.1200/JCO.2014.59.6049
   Panwar S, 2019, J SUPERCOMPUT, V75, P2986, DOI 10.1007/s11227-018-2499-y
   Patel L., 2022, Applications of Machine Learning and Artificial Intelligence in Education, P73
   Phumdoung S., 2005, Songklanagarind Med J, V23, P185
   Pingle YP, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P347
   Ragho A, 2020, COMPUT METH PROG BIO, V185, DOI 10.1016/j.cmpb.2019.105160
   Raglio A, 2017, NEUROL SCI, V38, P893, DOI 10.1007/s10072-017-2827-7
   Raglio A, 2016, INT J NEUROSCI, V126, P235, DOI 10.3109/00207454.2015.1010647
   Raglio A, 2015, J AM GERIATR SOC, V63, P1534, DOI 10.1111/jgs.13558
   Raman R, 2016, MUSIC PERCEPT, V33, P367, DOI 10.1525/mp.2016.33.3.367
   Ravi M, 2021, International. J Altern Complement Med, P01
   Rickson DJ, 2016, ART PSYCHOTHER, V50, P119, DOI 10.1016/j.aip.2016.07.002
   Rolvsjord R, 2015, NORD J MUSIC THER, V24, P44, DOI 10.1080/08098131.2013.861502
   Sanker SV, 2022, Edge-of-Things in Personalized Healthcare Support Systems, P217
   Sarkar J., 2015, International Journal of Humanities and Social Science Research, V1, P40
   Sharma M., 2011, J Bangladesh Soc Physiol, V6, P108, DOI [10.3329/jbsp.v6i2.9760, DOI 10.3329/JBSP.V6I2.9760]
   Sharma S, 2021, EXPLORE-NY, V17, P115, DOI 10.1016/j.explore.2020.02.013
   Shetty Surendra, 2009, International Journal of Recent Trends in Engineering, V1, P362
   Stegemann Thomas, 2019, Medicines (Basel), V6, DOI 10.3390/medicines6010025
   Sundar SUMATHY., 2015, International perspectives in music therapy education and training: adapting to a changing world, P202
   Supnet C, 2016, CRIT CARE NURSE, V36, pE1, DOI 10.4037/ccn2016413
   Tanaka Y, 2012, INT J GERONTOL, V6, P247, DOI 10.1016/j.ijge.2012.01.026
   Tiple B., 2017, Ijrcct, V6, P181
   Tiple B, 2022, MULTIMED TOOLS APPL, V81, P8853, DOI 10.1007/s11042-022-11975-4
   Tsoi KKF, 2018, J AM MED DIR ASSOC, V19, P568, DOI 10.1016/j.jamda.2017.12.009
   Ugras GA, 2018, COMPLEMENT THER CLIN, V31, P158, DOI 10.1016/j.ctcp.2018.02.012
   Valla JM, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02115
   Weidong Xu, 2021, 2021 2nd International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT), P57, DOI 10.1109/AINIT54228.2021.00020
   Wong HHL, 2006, J AUTISM DEV DISORD, V36, P901, DOI 10.1007/s10803-006-0131-0
   Zanini C, 2018, J HYPERTENS, V36, pE260
NR 72
TC 0
Z9 0
U1 14
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17290-w
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400013
DA 2024-07-18
ER

PT J
AU Chen, Y
   Long, J
AF Chen, Yu
   Long, Jun
TI CA-GAN: A Method to Narrow Down Domain Differences of Retinal Fundus
   Images Caused by Camera Brands
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Diabetic retinopathy; Domain difference; Domain adaptation; Disentangled
   representation
AB There is a significant body of research that focuses on utilizing deep learning to automatically detect diabetic retinopathy (DR). However, applying these models to real-world DR detection results in a decrease in performance. This degradation is primarily because the fundus camera brands used to capture the training images are different from those used in the real world. To address the domain differences resulting from various camera brands, we propose the Camera Adaptation Generative Adversarial Network (CA-GAN). CA-GAN has two main modules: the image-to-image (I2I) translation module and the pathological descriptor extraction module. The I2I translation module utilizes a disentangled representation framework to separate the structure and style information of fundus images. Then, CA-GAN performs style transfer by exchanging the style information between source domain and target domain images. The pathological descriptor extraction module obtains the pathological descriptor by mapping the most critical feature activations of the DR classification network. This module then employs feature alignment to incorporate the pathological descriptor into the translated retinal fundus image of the original image. Through the combined efforts of the I2I translation module and the pathological descriptor extraction module, CA-GAN can perform style transfer while preserving the structure and lesion information of retinal fundus images. The experimental results show that CA-GAN outperforms Residual-CycleGAN, a state-of-the-art model, in mitigating the domain differences caused by different camera brands.
C1 [Chen, Yu] Northeast Forestry Univ, Coll Comp & Control Engn, 26 Hexing Rd, Harbin 150040, Heilongjiang, Peoples R China.
   [Long, Jun] Northeast Forestry Univ, Coll Mech & Elect Engn, 26 Hexing Rd, Harbin 150040, Heilongjiang, Peoples R China.
C3 Northeast Forestry University - China; Northeast Forestry University -
   China
RP Long, J (corresponding author), Northeast Forestry Univ, Coll Mech & Elect Engn, 26 Hexing Rd, Harbin 150040, Heilongjiang, Peoples R China.
EM nefu_dragonj@nefu.edu.cn
FU National Natural Science Foundation of China [61300098]; Natural Science
   Foundation of Heilongjiang Province [F201347]; Fundamental Research
   Funds for the Central Universities [2572015DY07]; Harbin Science and
   Technology Bureau Manufacturing Innovation Talent Project
   [CXRC20221110393]; Heilongjiang Science and Technology Department
   Provincial Key RAMP;D Program Applied Research Project
   [SC2022ZX06C0025]; Heilongjiang Science and Technology Department
   Provincial Key RAMP;D Program Guidance Project [GZ20220088]
FX This work was supported by the National Natural Science Foundation of
   China [61300098], the Natural Science Foundation of Heilongjiang
   Province [F201347], the Fundamental Research Funds for the Central
   Universities [2572015DY07], the Harbin Science and Technology Bureau
   Manufacturing Innovation Talent Project (CXRC20221110393), the
   Heilongjiang Science and Technology Department Provincial Key R&D
   Program Applied Research Project (SC2022ZX06C0025), the Heilongjiang
   Science and Technology Department Provincial Key R&D Program Guidance
   Project (GZ20220088).
CR Yang TJ, 2020, J DIGIT IMAGING, V33, P946, DOI 10.1007/s10278-020-00339-9
NR 1
TC 0
Z9 0
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17032-y
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200018
DA 2024-07-18
ER

PT J
AU Ouyang, JL
   Huang, JT
   Wen, XZ
AF Ouyang, Junlin
   Huang, Jingtao
   Wen, Xingzi
TI A semi-fragile reversible watermarking method based on qdft and tamper
   ranking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Semi-fragile reversible watermarking; Quaternion discrete Fourier
   transform; Tamper localization; Image forensics
AB The traditional semi-fragile watermarking can effectively protect the integrity of the host image, but the permanent distortion caused by watermark embedding makes the application in high-fidelity images limited. Hence, we propose a novel semi-fragile reversible watermarking scheme for tampering localization. The motivation of this research is to solve the problem that the original carrier cannot be recovered in semi-fragile watermarking method and to improve the accuracy of tampered image detection and location. The proposed scheme embeds the semi-fragile watermark into the mid-frequency quaternion discrete Fourier transform (QDFT) coefficients to provide semi-fragility and reversibly embeds the compensation information into the watermarked image to achieve cover-lossless. First, to reduce the amount of compensation information, the watermarked image is pre-recovered using the neighborhood coefficients of the semi-fragile watermark embedding position. Then, the difference between the pre-recovered image and the original image is represented by the frequency domain error and the spatial domain error. Secondly, the performance of tampering localization is improved by optimizing the graph structure and weight matrix in the manifold ranking (MR) model. Specifically, a new approximate k-regular graph is constituted by introducing spatial relations of neighbors, that must be linked and must not be linked, which are integrated into the original graph structure. Then, a new weight matrix is constructed by combining multi-view features, to enhance the shape performance of the localized regions. The experimental results show that the proposed method can effectively resist content retention attacks, and accurately locate tampered regions. In the event of a non-attack, the original image can be recovered losslessly.
C1 [Ouyang, Junlin; Huang, Jingtao] Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.
   [Ouyang, Junlin; Huang, Jingtao; Wen, Xingzi] Hunan Key Lab Serv Comp & Novel Software Technol, Xiangtan 411201, Peoples R China.
   [Ouyang, Junlin] Hunan Software Vocat & Tech Univ, Xiangtan 411100, Peoples R China.
C3 Hunan University of Science & Technology
RP Ouyang, JL (corresponding author), Hunan Univ Sci & Technol, Sch Comp Sci & Engn, Xiangtan 411201, Peoples R China.; Ouyang, JL (corresponding author), Hunan Key Lab Serv Comp & Novel Software Technol, Xiangtan 411201, Peoples R China.; Ouyang, JL (corresponding author), Hunan Software Vocat & Tech Univ, Xiangtan 411100, Peoples R China.
EM yangjunlin0732@163.com
OI Ouyang, Junlin/0000-0001-7155-2732
FU The authors would like to thank the anonymous reviewers for their valued
   comments and suggestions. This work was supported by the natural science
   foundation of Hunan province under Grants 2021JJ30277, 2019JJ50168, by
   the project of Hunan province education [2021JJ30277, 2019JJ50168];
   natural science foundation of Hunan province [19K035, 19B202]; project
   of Hunan province education department [20YJCZH179]; Ministry of
   Education humanities social sciences the youth fund project [21BXW077];
   projects of national social science foundation of China
FX The authors would like to thank the anonymous reviewers for their valued
   comments and suggestions. This work was supported by the natural science
   foundation of Hunan province under Grants 2021JJ30277, 2019JJ50168, by
   the project of Hunan province education department under Grants 19K035,
   19B202, by the Ministry of Education humanities social sciences the
   youth fund project under Grants 20YJCZH179, and by the projects of
   national social science foundation of China under Grant 21BXW077.
NR 0
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-16963-w
EA OCT 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ4S3
UT WOS:001142752200010
DA 2024-07-18
ER

PT J
AU Wen, H
   Lu, ZM
   Cui, JL
   Li, HL
AF Wen, Hao
   Lu, Zhe-Ming
   Cui, Jia-Lin
   Li, Hao-Lai
TI A novel feature for action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Action recognition; Fourier transform; Multimodality; Representation
   learning
AB In this paper, we focus on how to better represent video data in the field of action recognition. We propose a new image feature named phase spectrum reconstruction map to facilitate action recognition, which extracts the contour features of RGB frame images from a video clip beneficial for action recognition. We demonstrate the effectiveness of such a feature with ablation experiments using the channel-based feature fusion method and two-stream method. Also, we verify that the reconstructed map does contain motion-related features and can be learned by convolutional neural networks only using the reconstructed map as input features. Our method is trained and evaluated using the benchmark datasets HMDB-51 and UCF-101, and both show significant improvements over other methods without adding the reconstructed map features.
C1 [Wen, Hao; Lu, Zhe-Ming] Zhejiang Univ, Sch Aeronaut & Astronaut, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
   [Cui, Jia-Lin] NingboTech Univ, Sch Informat Sci & Engn, Ningbo 315100, Zhejiang, Peoples R China.
   [Li, Hao-Lai] EFORT Intelligent Equipment Co Ltd, Shanghai 201600, Peoples R China.
C3 Zhejiang University; NingboTech University
RP Lu, ZM (corresponding author), Zhejiang Univ, Sch Aeronaut & Astronaut, 38 Zheda Rd, Hangzhou 310027, Zhejiang, Peoples R China.
EM 22024066@zju.edu.cn; zheminglu@zju.edu.cn; cuijl_jx@163.com;
   lihaolai@efort.com.cn
RI Liu, Yu/KFS-0769-2024; han, yang/KHX-8947-2024; Zhang,
   jin/KFT-0762-2024; Liu, Yining/KHC-6217-2024; li, guo/KHU-1749-2024;
   Chen, YiJun/KFS-9282-2024
OI Liu, Yining/0000-0002-2218-2349; 
FU National Key Research and Development Program of China [2020AAA0140004];
   National Key Research and Development Program of China
FX This research is supported in part by the National Key Research and
   Development Program of China under Grant No.2020AAA0140004.
CR Bertasius G, 2021, PR MACH LEARN RES, V139
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen YP, 2018, LECT NOTES COMPUT SC, V11205, P364, DOI 10.1007/978-3-030-01246-5_22
   Contributors M, 2020, OpenMMLab's Next generation video understanding toolbox and benchmark
   Diba A, 2016, arXiv
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   GOODALE MA, 1992, TRENDS NEUROSCI, V15, P20, DOI 10.1016/0166-2236(92)90344-8
   Guo WZ, 2019, IEEE ACCESS, V7, P63373, DOI 10.1109/ACCESS.2019.2916887
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang GX, 2020, INT CONF ACOUST SPEE, P2103, DOI 10.1109/icassp40776.2020.9054200
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lin J., 2019, arXiv
   Liu ZY, 2021, Arxiv, DOI arXiv:2005.06803
   Liu ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13688, DOI 10.1109/ICCV48922.2021.01345
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Ng JYH, 2018, IEEE WINT CONF APPL, P1577, DOI 10.1109/WACV.2018.00176
   Simonyan K, 2014, ADV NEUR IN, V27
   Singla N, 2014, International Journal of Information & Computation Technology, V4, P1559
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stroud JC, 2020, IEEE WINT CONF APPL, P614, DOI 10.1109/wacv45572.2020.9093274
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wu ZX, 2019, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2019.00137
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhang C, 2020, Arxiv, DOI arXiv:2008.03462
   Zhang YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13557, DOI [10.1109/iccv48922.2021.01332, 10.1109/ICCV48922.2021.01332]
   Zhu Y, 2019, LECT NOTES COMPUT SC, V11363, P363, DOI 10.1007/978-3-030-20893-6_23
NR 33
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17251-3
EA OCT 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6C6
UT WOS:001155215300005
DA 2024-07-18
ER

PT J
AU Patel, S
   Vaish, A
AF Patel, Saumya
   Vaish, Ankita
TI DNA coding and chaos based image encryption using compressive sensing in
   MSVD domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Compressive sensing; MSVD; Image encryption; Chaotic map; Discrete
   wavelet transform
ID ALGORITHM; SYSTEM
AB This paper introduces a novel image encryption technique using Compressive Sensing (CS) and DNA encoding. At first, the plain image is decomposed into the low and high-frequency sub-bands through Multi-Resolution Singular Value Decomposition (MSVD). The core idea behind the use of MSVD is to decompose the whole information into significant and less significant information. Significant information contains the information which can best represent the signal, so the low-frequency sub-band values are encrypted through the confusion and diffusion process. Here first diffusion is applied through DNA XOR operation; after that, Arnold scrambling is used to permute the encrypted information. Next, simultaneous compression encryption is employed on less significant information as high-frequency sub-bands through CS. At last, all sub-bands are concatenated to form a single encrypted image. Finally, the proposed algorithm is tested against statistical, differential, clipping, and noise attacks. Simulation results illustrate that the given algorithm is secure and robust against attacks.
C1 [Patel, Saumya; Vaish, Ankita] Banaras Hindu Univ, Comp Sci, Varanasi 221005, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU)
RP Patel, S (corresponding author), Banaras Hindu Univ, Comp Sci, Varanasi 221005, Uttar Pradesh, India.
EM saumyapatel5@gmail.com; av21lko@gmail.com
RI PATEL, SAUMYA/KQU-8641-2024
OI PATEL, SAUMYA/0000-0002-8692-7194
CR Abhishek, 2013, 2013 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P48, DOI 10.1109/RAICS.2013.6745445
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bao WJ, 2022, MULTIMED TOOLS APPL, V81, P15977, DOI 10.1007/s11042-022-12623-7
   Brahim AH, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106489
   Candès EJ, 2011, APPL COMPUT HARMON A, V31, P59, DOI 10.1016/j.acha.2010.10.002
   Chai XL, 2022, NONLINEAR DYNAM, V108, P2671, DOI 10.1007/s11071-022-07328-3
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Cheng GF, 2020, MULTIMED TOOLS APPL, V79, P29243, DOI 10.1007/s11042-020-09542-w
   Davenport MA, 2010, IEEE T INFORM THEORY, V56, P4395, DOI 10.1109/TIT.2010.2054653
   Do TT, 2008, CONF REC ASILOMAR C, P581, DOI 10.1109/ACSSC.2008.5074472
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   Harte J, 2014, TRENDS ECOL EVOL, V29, P384, DOI 10.1016/j.tree.2014.04.009
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang S, 2022, IET IMAGE P
   Huo DM, 2020, APPL PHYS B-LASERS O, V126, DOI 10.1007/s00340-020-7397-3
   Karahanoglu NB, 2012, DIGIT SIGNAL PROCESS, V22, P555, DOI 10.1016/j.dsp.2012.03.003
   Khan JS, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102711
   Kim Y, 2012, IEEE T IMAGE PROCESS, V21, P3102, DOI 10.1109/TIP.2012.2188807
   Kuske D, 2004, LECT NOTES COMPUT SC, V3340, P272
   Lawnik Marcin, 2018, Journal of Physics: Conference Series, V1141, DOI 10.1088/1742-6596/1141/1/012132
   Linfeng Du, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P783, DOI 10.1109/ICALIP.2012.6376720
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Patel S, 2023, Multimed Tools Appl, P1
   Patel S., 2020, J Sci Res, V64, P291
   Patel S, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170341
   Russo F, 2003, IEEE T INSTRUM MEAS, V52, P1148, DOI 10.1109/TIM.2003.815989
   Vaish A, 2022, OPTIK, V266, DOI 10.1016/j.ijleo.2022.169606
   Vaish A, 2022, J KING SAUD UNIV-COM, V34, P6165, DOI 10.1016/j.jksuci.2022.02.002
   Wang XY, 2015, OPT LASER ENG, V68, P126, DOI 10.1016/j.optlaseng.2014.12.025
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wei DY, 2021, OPTIK, V238, DOI 10.1016/j.ijleo.2021.166748
   Wu GC, 2014, NONLINEAR DYNAM, V75, P283, DOI 10.1007/s11071-013-1065-7
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu QY, 2020, OPT LASER ENG, V134, DOI 10.1016/j.optlaseng.2020.106178
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Zhu LY, 2022, SIGNAL PROCESS, V195, DOI 10.1016/j.sigpro.2022.108489
NR 43
TC 0
Z9 0
U1 9
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-17271-z
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100008
DA 2024-07-18
ER

PT J
AU Varanasi, S
   Malathi, K
AF Varanasi, Srinivas
   Malathi, K.
TI Self-improved COOT optimization-based LSTM for patient waiting time
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Waiting Time; Data acquisition; LSTM Network; RMSE; CCR-COOptimization
AB Longer lines and increased demand for medical treatment result from population expansion. When it comes to major illnesses like cancer, the situation is much awful. Instead of a shortage of resources, poor patient management is the main issue. Moreover, waiting Time could affect patient contentment and supremacy in urgent situations. This work suggests a novel model predict the waiting Time of patients. At first, data acquisition and data cleaning are done to pre-process the data. Further, raw features, statistical features, improved Renyi entropy features, and correlation-based features are extracted and then subjected to prediction using an optimized Long Term Short Memory (LSTM) classifier. The weights of LSTM are chosen using the new Cubic Chaotic Randomized Coot Optimization (CCR-CO) model. Finally, investigations are made to scrutinize the adopted model regarding varied error metrics such as RMSE, MAE, MAPE, MDAE, MEAE, MSE, and MSLE. When LP = 90, the RMSE attained by LSTM + CCR-CO is (similar to 0.38). Thus, LSTM + CCR-CO is established to predict the waiting Time of patients better over traditional models.
C1 [Varanasi, Srinivas; Malathi, K.] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering
RP Varanasi, S (corresponding author), Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM srinivassai1549@gmail.com; malathi.learning@gmail.com
CR Aaqib SM, 2021, Mater Today: Proc
   Almeida R, 2021, HEALTHINF: PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES - VOL. 5: HEALTHINF, P328, DOI 10.5220/0010221903280336
   Amelio A, 2023, EXPERT SYST APPL, V215, DOI 10.1016/j.eswa.2022.119391
   [Anonymous], 2008, US
   [Anonymous], About us
   [Anonymous], 2019, U.S
   Ataman MG, 2021, AM J EMERG MED, V46, P45, DOI 10.1016/j.ajem.2021.02.061
   Bentayeb D, 2019, HEALTH CARE MANAG SC, V22, P768, DOI 10.1007/s10729-018-9459-1
   Brenkman HJF, 2017, ANN SURG ONCOL, V24, P1761, DOI 10.1245/s10434-017-5820-8
   Calimeri F, 2021, THEOR PRACT LOG PROG, V21, P80, DOI 10.1017/S1471068419000449
   Chen JJ, 2020, ANN INTENSIVE CARE, V10, DOI 10.1186/s13613-020-0641-5
   Eiset AH, 2019, BMC MED RES METHODOL, V19, DOI 10.1186/s12874-019-0710-3
   Elleuch MA, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107643
   Fan XZ, 2021, J COMB OPTIM, V42, P677, DOI 10.1007/s10878-019-00487-x
   Feng DF, 2021, CCF T PERVAS COMPUT, V3, P40, DOI 10.1007/s42486-020-00052-0
   Hijry H., 2021, INT J IND ENG OPERAT, V3, P33, DOI [10.46254/j.ieom.20210103, DOI 10.46254/J.IEOM.20210103]
   Hosseinzadeh M, 2021, MULTIMED TOOLS APPL, V80, P16933, DOI 10.1007/s11042-020-09049-4
   Jadhav A. N., 2019, Multimedia Research, V2, P1, DOI DOI 10.46253/J.MR.V2I3.A1
   javascript, US
   Jizba P, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026128
   Jizba P, 2004, ANN PHYS-NEW YORK, V312, P17, DOI 10.1016/j.aop.2004.01.002
   Johannes J, 2015, CURR PULMONOL REP, V4, P71, DOI 10.1007/s13665-015-0111-y
   Joseph A, 2017, 2017 16 IEEE INT C M
   Kuo YH, 2020, INT J MED INFORM, V139, DOI 10.1016/j.ijmedinf.2020.104143
   Leccisotti L, 2023, J CANCER RES CLIN, V149, P2783, DOI 10.1007/s00432-022-04138-3
   Lee S, 2021, HEALTH CARE MANAG SC, V24, P72, DOI 10.1007/s10729-020-09517-1
   Li N, 2022, FLEX SERV MANUF J, V34, P879, DOI 10.1007/s10696-021-09414-x
   Li XQ, 2021, BMC HEALTH SERV RES, V21, DOI [10.1186/s12913-021-06248-z, 10.1186/s12870-021-02911-z, 10.1186/s12903-021-01614-z, 10.1186/s12890-021-01546-y]
   Luo L, 2019, HEALTH CARE MANAG SC, V22, P68, DOI 10.1007/s10729-017-9421-7
   Meng FW, 2015, HEALTH CARE MANAG SC, V18, P267, DOI 10.1007/s10729-014-9308-9
   Mtonga K, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11110236
   Naruei I, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115352
   Pak A, 2021, INT J MED INFORM, V145, DOI 10.1016/j.ijmedinf.2020.104303
   Patil P, 2019, 2019 2 INT C ISS CHA
   Schachter ME, 2013, BMC NEPHROL, V14, DOI 10.1186/1471-2369-14-182
   Sun Y, 2012, ANN EMERG MED, V60, P299, DOI 10.1016/j.annemergmed.2012.03.011
   Tavakoli M, 2022, MED BIOL ENG COMPUT, V60, P969, DOI 10.1007/s11517-022-02525-z
   Zhou X, 2019, Neuro Computing
NR 38
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-17045-7
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600001
DA 2024-07-18
ER

PT J
AU Barua, PD
   Kirik, S
   Dogan, S
   Koc, C
   Ozkaynak, F
   Baygin, M
   Tuncer, T
   Tan, RS
   Acharya, UR
AF Barua, Prabal Datta
   Kirik, Serkan
   Dogan, Sengul
   Koc, Canan
   Ozkaynak, Fatih
   Baygin, Mehmet
   Tuncer, Turker
   Tan, Ru-San
   Acharya, U. Rajendra
TI ExDarkLBP: a hybrid deep feature generation-based genetic malformation
   detection using facial images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Genetic malformation; ExDarkLBP; Feature engineering; Machine learning
ID RECOGNITION
AB Body malformations, including those affecting the face, can arise as a result of genetic disorders. The diagnosis of such changes may often require specialist expertise, which is scarce. In this study, we have presented a computer vision model capable of accurately classifying malformed vs. non-malformed face images using automated classification techniques. Our model, which we refer to as ExDarkLBP (exemplar/patch-based feature extraction deploying pretrained DarkNet and local binary pattern), is based on exemplar hybrid feature engineering and incorporates two primary feature extraction methods: (i) textural feature generation using local binary pattern (LBP) and (ii) deep feature creation deploying pretrained DarkNet53. The most informative 500 textural and 500 deep features were first selected using the neighborhood component analysis (NCA) feature selection function and then merged to form a 1000 feature vector. This vector was subsequently fed to iterative NCA to choose the most valuable features. By combining this optimal feature vector with a support vector machine, we achieved an accuracy of 99.22% using a ten-fold cross-validation strategy. Our proposed ExDarkLBP model is highly accurate and may be potentially applied for the screening of facial malformations associated with genetic disorders using face images.
C1 [Barua, Prabal Datta] Univ Southern Queensland, Sch Business Informat Syst, Toowoomba, Australia.
   [Kirik, Serkan] Firat Univ, Pediat Neurol, Sch Med, Elazig, Turkiye.
   [Dogan, Sengul; Tuncer, Turker] Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
   [Koc, Canan; Ozkaynak, Fatih] Firat Univ, Technol Fac, Dept Software Engn, Elazig, Turkiye.
   [Baygin, Mehmet] Erzurum Tech Univ, Coll Engn, Dept Comp Engn, Erzurum, Turkiye.
   [Tan, Ru-San] Natl Heart Ctr Singapore, Dept Cardiol, Singapore, Singapore.
   [Tan, Ru-San] Duke NUS Med Sch, Singapore, Singapore.
   [Acharya, U. Rajendra] Univ Southern Queensland, Sch Math Phys & Comp, Springfield, Australia.
C3 University of Southern Queensland; Firat University; Firat University;
   Firat University; Erzurum Technical University; National Heart Centre
   Singapore; National University of Singapore; University of Southern
   Queensland
RP Dogan, S (corresponding author), Firat Univ, Technol Fac, Dept Digital Forens Engn, Elazig, Turkiye.
EM Prabal.Barua@usq.edu.au; skirik@firat.edu.tr; sdogan@firat.edu.tr;
   canannkc@hotmail.com; ozkaynak@firat.edu.tr;
   mehmet.baygin@erzurum.edu.tr; turkertuncer@firat.edu.tr;
   tanrsnhc@gmail.com; Rajendra.Acharya@usq.edu.au
RI Koç, Canan/AGC-5935-2022; Kirik, SERKAN/ADX-1582-2022; DOGAN,
   Sengul/W-4854-2018
OI Koç, Canan/0000-0002-2651-9471; Kirik, SERKAN/0000-0002-8658-2448;
   DOGAN, Sengul/0000-0001-9677-5684
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Barua PD, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-21380-4
   Basel-Vanagaite L, 2016, CLIN GENET, V89, P557, DOI 10.1111/cge.12716
   Bawack RE, 2019, 25TH AMERICAS CONFERENCE ON INFORMATION SYSTEMS (AMCIS 2019)
   Baygin M, 2022, ARTIF INTELL MED, V127, DOI 10.1016/j.artmed.2022.102274
   Cornejo JYR., 2018, Iberoamerican Congress on Pattern Recognition, P665
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Ferry Q, 2014, ELIFE, V3, DOI 10.7554/eLife.02020
   Geremek M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196595
   Goldberger J., 2004, Advances in Neural Information Processing Systems, V17
   Gurovich Y, 2019, NAT MED, V25, P60, DOI 10.1038/s41591-018-0279-0
   Jones KL, 2021, Smith's Recognizable patterns of human malformation-E-book, V7, P7
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kaplan E, 2022, COMPUT METH PROG BIO, V224, DOI 10.1016/j.cmpb.2022.107030
   Klitzman RL, 2010, J GENET COUNS, V19, P430, DOI 10.1007/s10897-010-9307-z
   Kobat SG, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12081975
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LIPPMAN A, 1991, AM J LAW MED, V17, P15
   McAllister M, 2007, AM J MED GENET A, V143A, P2651, DOI 10.1002/ajmg.a.32013
   Mohamed MM, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108361
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Piosenka G., 2021, Detect Autism from a Facial Image
   Poyraz AK, 2022, BIOMED SIGNAL PROCES, V73, DOI 10.1016/j.bspc.2021.103448
   Raju K., 2022, A Fusion Artif. Intell. Internet Things Emerg. Cyber Syst., V6, P203, DOI [10.1007/978-3-030-76653-5, DOI 10.1007/978-3-030-76653-5]
   Rohatgi S, 2010, AM J MED GENET A, V152A, P1641, DOI 10.1002/ajmg.a.33441
   Ropers HH, 2007, AM J HUM GENET, V81, P199, DOI 10.1086/520679
   Singh A, 2018, PROCEEDINGS OF THE 2018 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2018), P26, DOI 10.1109/ISED.2018.8703997
   Singhal Prateek, 2022, Proceedings of Second Doctoral Symposium on Computational Intelligence: DoSCI 2021. Advances in Intelligent Systems and Computing (1374), P103, DOI 10.1007/978-981-16-3346-1_9
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Tuncer T, 2020, IEEE ACCESS, V8, P84532, DOI 10.1109/ACCESS.2020.2992641
   Vapnik V, 1998, NONLINEAR MODELING, P55
   Vapnik V., 1999, NATURE STAT LEARNING
   Wilkie AOM, 2001, NAT REV GENET, V2, P458, DOI 10.1038/35076601
   Winter RM, 1996, NAT GENET, V12, P124, DOI 10.1038/ng0296-124
NR 34
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-17057-3
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900014
DA 2024-07-18
ER

PT J
AU Misgar, MM
   Bhatia, M
AF Misgar, Muzafar Mehraj
   Bhatia, Mps
TI Utilizing deep convolutional neural architecture with attention
   mechanism for objective diagnosis of schizophrenia using wearable IoMT
   devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Schizophrenia; IoMT; Deep Learning; Machine Learning; Motor Activity
ID CLASSIFICATION; MODELS
AB Mental health diagnosis often relies on subjective evaluations, which can be intrusive and lack objectivity. With the current global situation brought about by the COVID-19 pandemic, the need for real-time, on-demand healthcare services has become more apparent than ever. Fortunately, wearable Internet of Medical Things (IoMT) devices, such as wrist actigraphs and smartphones, offer a promising solution by generating objective data that can aid in early-stage mental health diagnosis. This paper presents a novel Deep Convolutional Neural Architecture (CNN) with a split attention mechanism, that outperforms the traditional methods of analyzing motor activity data in diagnosing schizophrenia. To address the unique characteristics of motor activity, the proposed method includes a novel imputation method, a sampling technique based on a sliding window for sample expansion, and the Synthetic Minority Over-sampling Technique (SMOTE) technique for class balancing. The results demonstrate the highest accuracy of 94% using 24-h actigraphy data. Overall, the application of this methodology can greatly contribute to the development of pervasive healthcare systems, providing non-invasive, objective, and real-time mental healthcare services.
C1 [Misgar, Muzafar Mehraj; Bhatia, Mps] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, New Delhi, India.
C3 Netaji Subhas University of Technology
RP Misgar, MM (corresponding author), Netaji Subhas Univ Technol, Dept Comp Sci & Engn, New Delhi, India.
EM muzafarm.co20@nsut.ac.in; mpsbhatia@nsut.ac.in
OI Misgar, Muzafar Mehraj/0000-0002-1980-9278
CR Adamczyk J, 2021, COMPUT INFORM, V40, P850, DOI 10.31577/cai_2021_4_850
   Akhtar MM, 2023, MULTIMED TOOLS APPL, V82, P17353, DOI 10.1007/s11042-022-13934-5
   AKISKAL HS, 1975, ARCH GEN PSYCHIAT, V32, P285
   Andreasen NC, 1997, SCHIZOPHR RES, V28, P105, DOI 10.1016/S0920-9964(97)00112-6
   Armitage R, 2004, J AM ACAD CHILD PSY, V43, P761, DOI 10.1097/01.chi.0000122731.72597.4e
   Arora A, 2022, ARAB J SCI ENG, V47, P1999, DOI 10.1007/s13369-021-06078-5
   Arora A, 2020, ARAB J SCI ENG, V45, P10793, DOI 10.1007/s13369-020-04877-w
   Ashraf A, 2020, PROCEEDING OF 2020 6TH INTERNATIONAL CONFERENCE ON WIRELESS AND TELEMATICS (ICWT), DOI 10.1109/icwt50448.2020.9243625
   Aydemir E, 2021, APPL INTELL, V51, P6449, DOI 10.1007/s10489-021-02426-y
   Bonato Paolo, 2005, J Neuroeng Rehabil, V2, P2, DOI 10.1186/1743-0003-2-2
   Bondugula RK, 2023, APPL INTELL, V53, P14400, DOI 10.1007/s10489-022-04250-4
   Cheniaux E, 2018, REV BRAS PSIQUIATR, V40, P233, DOI 10.1590/1516-4446-2017-2301
   Cooper MA, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00372
   Feng Changyong, 2014, Shanghai Arch Psychiatry, V26, P105, DOI 10.3969/j.issn.1002-0829.2014.02.009
   Garcia-Ceja E, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P472, DOI 10.1145/3204949.3208125
   Garcia-Ceja E, 2018, COMP MED SY, P316, DOI 10.1109/CBMS.2018.00062
   García-Magariño I, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6247094
   Granholm E, 2020, SCHIZOPHRENIA BULL, V46, P242, DOI 10.1093/schbul/sbz070
   Haag A, 2004, LECT NOTES COMPUT SC, V3068, P36
   Jakobsen P, 2020, 2020 IEEE 33 INT S C, DOI [10.31219/osf.io/e2tzf, DOI 10.31219/OSF.IO/E2TZF]
   Jakobsen P, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0231995
   Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719
   Krishnan PT, 2020, BIOCYBERN BIOMED ENG, V40, P1124, DOI 10.1016/j.bbe.2020.05.008
   Kumar A, 2022, APPL SOFT COMPUT, V122, DOI 10.1016/j.asoc.2022.108863
   Kumari Suneeta, 2017, J Addict Res Ther, V8, DOI 10.4172/2155-6105.1000324
   Laursen TM, 2014, ANNU REV CLIN PSYCHO, V10, P425, DOI 10.1146/annurev-clinpsy-032813-153657
   Lee S, 2021, FRONT PSYCHIATRY, V12, DOI 10.3389/fpsyt.2021.672347
   Liu J, 2018, MULTIMED TOOLS APPL, V77, P29651, DOI 10.1007/s11042-017-5470-7
   Liu Y., 2015, Int. J. Hybrid Inform. Technol., V8, P367
   Marco EM, 2016, CURR TOP BEHAV NEURO, V29, P155, DOI 10.1007/7854_2015_419
   Martin JL, 2011, CHEST, V139, P1514, DOI 10.1378/chest.10-1872
   Nguyen DK, 2022, HEALTH INFORM J, V28, DOI 10.1177/14604582221137537
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Pacheco-Gonzalez S.I., 2019, Res. Comput. Sci., V148, P129
   Rodriguez-Ruiz JG, 2019, 2019 7TH INTERNATIONAL CONFERENCE IN SOFTWARE ENGINEERING RESEARCH AND INNOVATION (CONISOFT 2019), P207, DOI 10.1109/CONISOFT.2019.00037
   Sadeghi D, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105554
   Saeb S, 2015, INT CONF PER COMP, P229, DOI 10.4108/icst.pervasivehealth.2015.259034
   Seal A, 2023, APPL INTELL, V53, P12666, DOI 10.1007/s10489-022-04159-y
   Strous RD, 2009, J NERV MENT DIS, V197, P585, DOI 10.1097/NMD.0b013e3181b09068
   Teicher MH, 1997, ARCH GEN PSYCHIAT, V54, P124
   Tyagi A, 2023, MULTIMED TOOLS APPL, V82, P20343, DOI 10.1007/s11042-022-13809-9
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang R, 2020, INT CONF PERVAS COMP, DOI 10.1109/percom45495.2020.9127365
   Wang ZM, 2022, APPL INTELL, V52, P12064, DOI 10.1007/s10489-021-03070-2
   Wiem MB, 2017, INT J ADV COMPUT SC, V8, P318
   Zanella-Calzada LA, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9010008
   Zanello A, 2013, PSYCHIAT RES, V210, P626, DOI 10.1016/j.psychres.2013.07.001
NR 47
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-17119-6
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500012
DA 2024-07-18
ER

PT J
AU Fan, C
   Chen, ZX
   Lin, H
   Wang, X
AF Fan, Chao
   Chen, Zhixiang
   Lin, Hao
   Wang, Xiao
TI TCGFusion: a network for PET-MRI fusion based on GAN and transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image fusion; GAN; Grid-former; Patch-SSIM
ID IMAGE FUSION; MULTI-FOCUS; PERFORMANCE
AB Modern clinical diagnosis relies heavily on medical imaging. Unimodal images contain limited information, whereas image fusion techniques can combine functional and structural information of images, thus speeding up the diagnostic and therapeutic process. However, existing methods lack global dependency and incomplete retention of image information. Therefore, we provide an end-to-end unsupervised training model called TCGFusion: a network for PET-MRI fusion based on GAN and transformer. We set the generator to a dual-path layout to ensure the gathering of both global semantic and detailed image information. The T-Path guarantees the coarse scale picture extraction and prevents the high computational cost. The C-Path's multi-cascade structure captures image details well. Additionally, we create a dual discriminator to determine the distribution of structural similarity between the fused result and the source image and use patch-SSIM to reinforce the semantic constraints between them and promote the image details. Through thorough investigation using public datasets, our TCGFusion possesses the capability to effectively combine the structural and functional information of an image, thus guaranteeing the integrity of the fused image. On objective measures, our method is about 3% higher overall than EMFusion. QG reached 0.7862 and SSIM reached 0.901.
C1 [Fan, Chao] Henan Univ Technol, Sch Artificial Intelligence & Big Data, Zhengzhou, Henan, Peoples R China.
   [Fan, Chao] Minist Educ, Key Lab Grain Informat Proc & Control, Zhengzhou, Henan, Peoples R China.
   [Chen, Zhixiang; Lin, Hao; Wang, Xiao] Henan Univ Technol, Sch Informat Sci & Engn, Zhengzhou, Henan, Peoples R China.
C3 Henan University of Technology; Henan University of Technology
RP Chen, ZX (corresponding author), Henan Univ Technol, Sch Informat Sci & Engn, Zhengzhou, Henan, Peoples R China.
EM 845082220@stu.haut.edu.cn
FU This work is supported by the Henan science and technology research
   project(No.222102210309); the National Natural Science Foundation of
   China (Nos. 6210606762106068); the Natural Science Project of Henan
   Education Department, China (No.21A520010); and the [222102210309];
   Henan science and technology research project [6210606762106068];
   National Natural Science Foundation of China [21A520010]; Natural
   Science Project of Henan Education Department, China [2021ZKCJ14];
   Innovative Funds Plan of Henan University of Technology
FX This work is supported by the Henan science and technology research
   project(No.222102210309); the National Natural Science Foundation of
   China (Nos. 6210606762106068); the Natural Science Project of Henan
   Education Department, China (No.21A520010); and the Innovative Funds
   Plan of Henan University of Technology (2021ZKCJ14).
CR Ambati L. S., 2021, AMCIS
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Cheng CY, 2023, INFORM FUSION, V92, P80, DOI 10.1016/j.inffus.2022.11.010
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Haghighat M, 2014, I C APPL INF COMM TE, P424
   Hu P, 2019, INFRARED PHYS TECHN, V102, DOI 10.1016/j.infrared.2019.102977
   Huang J, 2020, IEEE ACCESS, V8, P55145, DOI 10.1109/ACCESS.2020.2982016
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li Z, 2021, IEEE T MULTIMEDIA, V23, P306, DOI 10.1109/TMM.2020.2978640
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Ma JY, 2020, IEEE T IMAGE PROCESS, V29, P4980, DOI 10.1109/TIP.2020.2977573
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Nie RC, 2022, IEEE T MULTIMEDIA, V24, P1460, DOI 10.1109/TMM.2021.3065496
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Rao D., 2023, IEEE Trans. Image Process.
   Tang LF, 2022, INFORM FUSION, V82, P28, DOI 10.1016/j.inffus.2021.12.004
   Tang W, 2021, IEEE T COMPUT IMAG, V7, P584, DOI 10.1109/TCI.2021.3083965
   Wang L.-T., 1987, 24th ACM/IEEE Design Automation Conference Proceedings 1987, P2, DOI 10.1145/37888.37889
   Wang ZS, 2015, OPTIK, V126, P4184, DOI 10.1016/j.ijleo.2015.08.118
   Wang ZS, 2020, OPTIK, V201, DOI 10.1016/j.ijleo.2019.163497
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Xu H, 2021, INFORM FUSION, V76, P177, DOI 10.1016/j.inffus.2021.06.001
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Xydeas C, 2000, P SOC PHOTO-OPT INS, V4051, P89, DOI 10.1117/12.381668
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zamzami IF, 2022, INT J INTELL SYST, V37, P11742, DOI 10.1002/int.23061
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang SD, 2020, VISUAL COMPUT, V36, P1797, DOI 10.1007/s00371-019-01774-8
   Zhang Y, information Fusion, V54, DOI [10.1016/j.infus.2019.07.011, DOI 10.1016/J.INFUS.2019.07.011]
NR 31
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 30
PY 2023
DI 10.1007/s11042-023-16978-3
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T4DY8
UT WOS:001077522300008
DA 2024-07-18
ER

PT J
AU Mate, P
   Apte, N
   Parate, M
   Sharma, S
AF Mate, Prajwal
   Apte, Ninad
   Parate, Manish
   Sharma, Sanjeev
TI Detection of driver drowsiness using transfer learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Driver drowsiness; Road mishaps; Transfer learning; Deep learning
   models; Deep learning
ID CONVOLUTIONAL NEURAL-NETWORK
AB Major traffic accidents are often caused by driver drowsiness. Modern lifestyles reduce the amount of sleep an individual gets. Hence, this paper proposes to use Deep Learning to detect such scenarios and prevent mishaps. In the proposed experiment, 7 different deep learning models based on transfer learning are trained and tested for the driver drowsiness problem. The models include VGG19, ResNet50V2, MobileNetV2, Xception, InceptionV3, DenseNet169, and InceptionResNetV2. All of the experiments are conducted on the NTHU-DDD2 dataset. Evaluation and comparison of each model's performance are conducted. We identify the best-performing model and compare it with previous literature in the same field. The best-performing model came out to be VGG19. It achieved an accuracy of 96.51%, precision of 98.14%, recall of 95.36%, and f1 score of 96.73%.
C1 [Mate, Prajwal; Apte, Ninad; Parate, Manish; Sharma, Sanjeev] Indian Inst Informat Technol, Pune, India.
RP Mate, P (corresponding author), Indian Inst Informat Technol, Pune, India.
EM prajwalvmate37@gmail.com; ninad.s.apte@gmail.com;
   manish.dparate@gmail.com; drsanjeev.sharma22@gmail.com
OI sharma, Dr. Sanjeev/0000-0001-9598-242X
CR Amidei A, 2022, 2022 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR AUTOMOTIVE (IEEE METROAUTOMOTIVE 2022), P94, DOI 10.1109/MetroAutomotive54295.2022.9854871
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bhupendra, 2022, COMPUT ELECTRON AGR, V195, DOI 10.1016/j.compag.2022.106811
   Cdcnewsroom, 2016, about us
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P20547, DOI 10.1007/s11042-021-10753-y
   Chand HV, 2022, Intell Autom Soft Comput, DOI [10.32604/iasc, DOI 10.32604/IASC]
   Chen YF, 2022, COMPUT METH PROG BIO, V225, DOI 10.1016/j.cmpb.2022.107053
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cui J, 2022, METHODS, V202, P173, DOI 10.1016/j.ymeth.2021.04.017
   Deng WH, 2019, IEEE ACCESS, V7, P118727, DOI 10.1109/ACCESS.2019.2936663
   Dua M, 2021, NEURAL COMPUT APPL, V33, P3155, DOI 10.1007/s00521-020-05209-7
   Elaraby A, 2022, CMC-COMPUT MATER CON, V71, P4019, DOI 10.32604/cmc.2022.022161
   Ferreira CA, 2018, LECT NOTES COMPUT SC, V10882, P763, DOI 10.1007/978-3-319-93000-8_86
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Goyal V, 2023, MULTIMED TOOLS APPL, V82, P24841, DOI 10.1007/s11042-022-14276-y
   Gundluru N, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/8512469
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Houshmand S, 2022, J MED SIGNALS SENS, V12, P294, DOI 10.4103/jmss.jmss_124_21
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jabbar Rateb, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P237, DOI 10.1109/ICIoT48696.2020.9089484
   Jabbar R, 2018, PROCEDIA COMPUT SCI, V130, P400, DOI 10.1016/j.procs.2018.04.060
   Jamshidi S, 2021, MULTIMED TOOLS APPL, V80, P16045, DOI 10.1007/s11042-021-10542-7
   Jiang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214587
   kaggle, 2022, Nthu-ddd2
   Kaur Taranjit, 2019, 2019 International Conference on Information Technology (ICIT), P94, DOI 10.1109/ICIT48102.2019.00023
   Kumar V, 2023, EVOL INTELL, V16, P1907, DOI 10.1007/s12065-022-00743-w
   Lo WW, 2019, INT CONF NEW TECHNOL, DOI 10.1109/ntms.2019.8763852
   Magán E, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12031145
   Manikandakumar M, 2023, COMPUT SYST SCI ENG, V44, P913, DOI 10.32604/csse.2023.025434
   Muthukumaran N., 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P386, DOI 10.1109/I-SMAC47947.2019.9032698
   Paul A, 2022, NEURAL COMPUT APPL, V34, P10409, DOI 10.1007/s00521-021-06629-9
   Quddus A, 2021, ACCIDENT ANAL PREV, V156, DOI 10.1016/j.aap.2021.106107
   Rajamohana SP, 2021, MATER TODAY-PROC, V45, P2897, DOI 10.1016/j.matpr.2020.11.898
   Rasley J, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P3505, DOI 10.1145/3394486.3406703
   Reddy A. Sai Bharadwaj, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0945, DOI 10.1109/ICCSP.2019.8697909
   Shahi TB, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264586
   Shi CP, 2020, IEEE ACCESS, V8, P154436, DOI 10.1109/ACCESS.2020.3016116
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh R, 2017, MULTIMED TOOLS APPL, V76, P19005, DOI 10.1007/s11042-016-4342-x
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tamilarasi R, 2021, Journal of Physics: Conference Series, V1964
   Tashakori M, 2022, P I MECH ENG H, V236, P43, DOI 10.1177/09544119211044232
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xiang Q, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2019), DOI 10.1145/3331453.3361658
   Yurttakal AH, 2020, MULTIMED TOOLS APPL, V79, P15555, DOI 10.1007/s11042-019-7479-6
   Zheng Z, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS AND COMPUTER ENGINEERING (ICCECE), P325, DOI 10.1109/ICCECE51280.2021.9342346
   Zhong Z, 2020, J Phys Conf Ser, V1651
NR 48
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16952-z
EA SEP 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600027
DA 2024-07-18
ER

PT J
AU Mahato, GK
   Chakraborty, SK
AF Mahato, Ganesh Kumar
   Chakraborty, Swarnendu Kumar
TI Securing edge computing using cryptographic schemes: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Attribute based encryption; Cryptography; Edge computing; Internet of
   things; Homomorphic encryption; Identity based encryption; Searchable
   encryption
ID SEARCHABLE ENCRYPTION; INTERNET; THINGS; IOT
AB The exponential growth and wide-area applications of the Internet of Things have garnered a lot of interest from academics and industries, thus becoming one of the most actively studied research paradigms in recent years. Internet of Things is a concept that builds an inter-connected environment where physical devices collect data from the surroundings and customize it to our requirements. It is known for its fast processing and quick response. Edge computing is a platform that performs the computations on the data supplied by the Internet of Thing devices at the network edge that leads to real-time processing. Despite its advantages, privacy protection and security challenges remain a critical concern that must be addressed. This paper aims to give a comprehensive review on cryptographic schemes used for securing edge computing. In particular, we first present a concept of edge computing in the context of IoT including architecture and advantages over cloud computing. We have explored various encryption techniques like identity-based encryption, attribute-based encryption, searchable encryption, and homomorphic encryption that secure the sensitive data before processing it at the network edge. Various parameters of each encryption technique, such as the length of the public key, private key, and ciphetext, are compared. Computational complexity of encryption and decryption is also included in our comparative study. Although many review papers focused on authentication and authorization challenges, this review on encryption techniques in context of edge security was highly needed. We have also looked at some of the other review papers and compared them to our survey to show how important it is.
C1 [Mahato, Ganesh Kumar; Chakraborty, Swarnendu Kumar] Natl Inst Technol, Comp Sci & Engn, Papum Pare 791113, Arunachal Prade, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Arunachal Pradesh
RP Mahato, GK (corresponding author), Natl Inst Technol, Comp Sci & Engn, Papum Pare 791113, Arunachal Prade, India.
EM mahato.ganesh88@gmail.com; swarnendu@nitap.ac.in
OI MAHATO, GANESH KUMAR/0000-0002-2925-7438
CR Aazam M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P518, DOI 10.1109/PERCOMW.2015.7134091
   Abdalla M, 2007, LECT NOTES COMPUT SC, V4450, P361
   Adil M, 2023, IEEE T NETW SCI ENG, V10, P2719, DOI 10.1109/TNSE.2022.3159526
   Adil M, 2021, SUSTAIN CITIES SOC, V75, DOI 10.1016/j.scs.2021.103311
   Ai Y, 2018, DIGIT COMMUN NETW, V4, P77, DOI 10.1016/j.dcan.2017.07.001
   Al-Dahhan RR, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071695
   Alrawais A, 2017, IEEE ACCESS, V5, P9131, DOI 10.1109/ACCESS.2017.2705076
   Alwarafy A, 2021, IEEE INTERNET THINGS, V8, P4004, DOI 10.1109/JIOT.2020.3015432
   Bhat SA, 2020, IEEE ACCESS, V8, P205340, DOI 10.1109/ACCESS.2020.3037108
   Blaze M, 1998, LECT NOTES COMPUT SC, V1403, P127, DOI 10.1007/BFb0054122
   Boneh D, 2004, LECT NOTES COMPUT SC, V3027, P506
   Boneh D, 2007, LECT NOTES COMPUT SC, V4392, P535
   Cao N, 2014, IEEE T PARALL DISTR, V25, P222, DOI 10.1109/TPDS.2013.45
   Caprolu M, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON EDGE COMPUTING (IEEE EDGE), P116, DOI 10.1109/EDGE.2019.00035
   Chang ZQ, 2021, IEEE INTERNET THINGS, V8, P13849, DOI 10.1109/JIOT.2021.3088875
   Chen Q, 2020, COMPUT COMMUN, V164, P31, DOI 10.1016/j.comcom.2020.09.012
   Chen YC, 2019, FUTURE GENER COMP SY, V100, P715, DOI 10.1016/j.future.2019.05.038
   Cirani S, 2013, ALGORITHMS, V6, P197, DOI 10.3390/a6020197
   Damgård I, 2001, LECT NOTES COMPUT SC, V1992, P119
   Delerablée C, 2007, LECT NOTES COMPUT SC, V4833, P200
   Dyer J, 2019, INT J INF SECUR, V18, P549, DOI 10.1007/s10207-019-00427-0
   Faisal M, 2020, Establishment of trust in internet of things by integrating trusted platform module: to counter cybersecurity challenges complexity
   Farjana N., 2020, Studies in Computational Intelligence, VVolume 669, P215, DOI [10.1007/978-981-13-7564-419, DOI 10.1007/978-981-13-7564-419]
   Farooq M. U., 2015, Int J Comput Appl, V113, P1, DOI DOI 10.5120/19787-1571
   Fun TS, 2017, INT C COMP SCI TECHN, P99, DOI [10.1007/978-981-10-8276-4_10, DOI 10.1007/978-981-10-8276-4_10]
   Gaikwad SS., 2016, Int Res J Eng Tech (IRJET), V3, P105
   Galbraith SD, 2002, J CRYPTOL, V15, P129, DOI 10.1007/s00145-001-0015-6
   Gong CQ, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/8142102
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Gupta S, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2021.102768
   Hagen MVD, 2021, arXiv: 2103.06743, P1
   Hartmann M, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3710
   Husain B. H., 2021, International Journal of Science and Business, V5, P52
   Jianchang Lai, 2016, Information Security and Privacy. 21st Australasian Conference, ACISP 2016. Proceedings: LNCS 9723, P223, DOI 10.1007/978-3-319-40367-0_14
   Jiang YH, 2018, FUTURE GENER COMP SY, V78, P720, DOI 10.1016/j.future.2017.01.026
   Jiang YH, 2016, LECT NOTES COMPUT SC, V9722, P477, DOI 10.1007/978-3-319-40253-6_29
   Kars BN., 2021, J Emerging Comput Technol, V1, P14
   Kawachi A, 2007, LECT NOTES COMPUT SC, V4450, P315
   Khan A, 2016, P 3 INT C REC TRENDS, V10
   Kim J, 2019, PROCEEDINGS OF THE 2019 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS '19), P55, DOI 10.1145/3321705.3329825
   Li H, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/1019767
   Li J, 2012, INT CONF CLOUD COMPU, P214, DOI 10.1109/CCIS.2012.6664399
   Li JG, 2017, IEEE T SERV COMPUT, V10, P715, DOI 10.1109/TSC.2016.2542813
   Liu B, 2022, IEEE Access
   Liu ZY, 2021, J INF SECUR APPL, V58, DOI 10.1016/j.jisa.2020.102709
   Mannanuddin K, 2020, IOP conference series: materials science and engineering
   Miao YB, 2019, IEEE T IND INFORM, V15, P3206, DOI 10.1109/TII.2018.2877146
   Mukherjee M, 2020, IEEE COMMUN MAG, V58, P26, DOI 10.1109/MCOM.001.2000297
   Murugesan A, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3990
   Nain G, 2022, J MANUF SYST, V62, P588, DOI 10.1016/j.jmsy.2022.01.010
   Naucke J, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL WORKSHOP ON CHALLENGES IN ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING FOR INTERNET OF THINGS (AICHALLENGEIOT '19), P32, DOI 10.1145/3363347.3363361
   Nikravan M, 2022, J NETW COMPUT APPL, V204, DOI 10.1016/j.jnca.2022.103402
   Okamoto T, 1998, LECT NOTES COMPUT SC, V1403, P308, DOI 10.1007/BFb0054135
   Oladunni T., 2019, 28th International Conference on Software Engineeringand Data Engineering, V64, P129
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Peralta G, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080827
   Ranaweera P, 2021, IEEE COMMUN SURV TUT, V23, P1078, DOI 10.1109/COMST.2021.3062546
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Sakai J., 2007, IACR CRYPTOL EPRINT, V2007, P217
   Satyanarayanan M, 2017, COMPUTER, V50, P30, DOI 10.1109/MC.2017.9
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Shi YF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0116325
   Singh S, 2022, IEEE INTERNET THINGS, V9, P236, DOI 10.1109/JIOT.2021.3098051
   Sookhak M, 2017, FUTURE GENER COMP SY, V72, P273, DOI 10.1016/j.future.2016.08.018
   Steinwandt R, 2002, IEEE T INFORM THEORY, V48, P2990, DOI 10.1109/TIT.2002.804112
   Sun WH, 2016, IEEE T PARALL DISTR, V27, P1187, DOI 10.1109/TPDS.2014.2355202
   TANAKA H, 1988, LECT NOTES COMPUT SC, V293, P340
   Triantafyllou A, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/5349894
   TSUJII S, 1989, IEEE J SEL AREA COMM, V7, P467, DOI 10.1109/49.17709
   van Dijk M, 2010, LECT NOTES COMPUT SC, V6110, P24
   Wang Yunling., 2016, J COMMUNICATIONS INF, V1, P52, DOI [10.1007/BF03391580, DOI 10.1007/BF03391580]
   Xiao M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061423
   Xiao Y, 2019, 2019 IEEE CONFERENCE ON DEPENDABLE AND SECURE COMPUTING (DSC), P203, DOI [10.1109/JPROC.2019.2918437, 10.1109/dsc47296.2019.8937659]
   Yan XY, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8832341
   Yang YJ, 2016, PERVASIVE MOB COMPUT, V28, P122, DOI 10.1016/j.pmcj.2015.06.017
   Yi SH, 2015, LECT NOTES COMPUT SC, V9204, P685, DOI 10.1007/978-3-319-21837-3_67
   Zhang S, 2020, WIRELESS PERS COMMUN, V114, P2783, DOI 10.1007/s11277-020-07503-y
NR 78
TC 1
Z9 1
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-15592-7
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000009
DA 2024-07-18
ER

PT J
AU Shihabudeen, H
   Rajeesh, J
AF Shihabudeen, H.
   Rajeesh, J.
TI An autoencoder deep residual network model for multi focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep Learning; Deep CNN; Image fusion; Decoder; Multifocus; Depth of
   field
AB Image fusion technology consolidates data from various source images of a similar objective and performs extremely effective data complementation, which is commonly used in the transportation, medication, and surveillance fields. Because of the imaging instrument's depth of field limitations, it is very hard to catch all the details of the scene and miss some important features. To solve this problem, this study provides a competent multi-focus image fusing technique based on deep learning. The algorithm collect features from the source input and feed these feature vectors into the convolutional neural network (CNN) to create feature maps. As a result, the focus map collects critical data for the image fusion. Focusmaps collected by the encoder is combined by using L2 norm and nuclear norm methods. Combined focusmaps are then given to Deep CNN to have the source images transformed effectively to the focus image. The proposed nuclear norm-based fusion model provides good evaluation metrics for Entropy, Mutual Information, normalized MI, Q(abf), and Structural Similarity Index Measure with values 7.6855, 8.7312, 1.1168, 0.7579, and 0.8669, respectively. The L2 norm strategy also provides good computational and experimental efficiency over other approaches. According to the experimental analysis of different approaches, the proposed research outperforms many other existing systems on a variety of performance parameters.
C1 [Shihabudeen, H.] APJ Abdul Kalam Technol Univ, Coll Engn Thalassery, Thalassery 670107, Kerala, India.
   [Rajeesh, J.] Coll Engn Kidangoor, Dept Elect, Kottayam 686583, Kerala, India.
RP Shihabudeen, H (corresponding author), APJ Abdul Kalam Technol Univ, Coll Engn Thalassery, Thalassery 670107, Kerala, India.
EM shihab2009@gmail.com; rajeesh26071969@gmail.com
RI H, shihabudeen/HIK-3431-2022
FU H. Shihabudeen would like to thank the College of Engineering
   Thalassery, College of Engineering Kidangoor, and APJ Abdul Kalam
   Technological University, Kerala, for giving support for carrying out
   the research work. He also thank his supervisor, who has p
FX H. Shihabudeen would like to thank the College of Engineering
   Thalassery, College of Engineering Kidangoor, and APJ Abdul Kalam
   Technological University, Kerala, for giving support for carrying out
   the research work. He also thank his supervisor, who has provided many
   directions in conducting this research.
CR Aishwarya N, 2021, J INTELL FUZZY SYST, V41, P903, DOI 10.3233/JIFS-202803
   Amin-Naji M., 2018, J AI DATA MINING, V6, P233, DOI DOI 10.22044/JADM.2017.5169.1624
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Aslantas V, 2014, OPT COMMUN, V332, P350, DOI 10.1016/j.optcom.2014.07.044
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Chen YB, 2018, IEEE T IMAGE PROCESS, V27, P1526, DOI 10.1109/TIP.2017.2779274
   Cvejic N, 2006, Int J Signal Process
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Du CB, 2019, OPTIK, V176, P567, DOI 10.1016/j.ijleo.2018.09.089
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292
   Jin X, 2023, IET IMAGE PROCESS, V17, P733, DOI 10.1049/ipr2.12668
   Jin X, 2020, IEEE T INSTRUM MEAS, V69, P5900, DOI 10.1109/TIM.2019.2962849
   Kou L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191085
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Ma BY, 2021, NEURAL COMPUT APPL, V33, P5793, DOI 10.1007/s00521-020-05358-9
   Ma HY, 2019, IEEE INT CON MULTI, P1150, DOI 10.1109/ICME.2019.00201
   Ma JY, 2021, IEEE T COMPUT IMAG, V7, P309, DOI 10.1109/TCI.2021.3063872
   Ma JL, 2019, NEUROCOMPUTING, V335, P9, DOI 10.1016/j.neucom.2019.01.048
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Mustafa HT, 2019, IMAGE VISION COMPUT, V85, P26, DOI 10.1016/j.imavis.2019.03.001
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Paninski L, 2003, NEURAL COMPUT, V15, P1191, DOI 10.1162/089976603321780272
   Piella G, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P173
   Qiu XH, 2019, SIGNAL PROCESS-IMAGE, V72, P35, DOI 10.1016/j.image.2018.12.004
   Quan TM, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.613981
   Prabhakar KR, 2017, Arxiv, DOI [arXiv:1712.07384, 10.48550/arXiv.1712.07384, DOI 10.48550/ARXIV.1712.07384]
   Savic S., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P604
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Shihabudeen H, 2022, IEEE ACCESS, V10, P36884, DOI 10.1109/ACCESS.2022.3164426
   Shihabudeen H, 2021, 2021 2 INT C ADV COM, P222, DOI [10.1109/ACCESS51619.2021.9563338, DOI 10.1109/ACCESS51619.2021.9563338]
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Song X, 2019, LECT NOTES ARTIF INT, V11377, P1, DOI 10.1007/978-3-030-20984-1_1
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Tian B, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-29584-y
   Wang C, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106253
   Xu H, 2020, IEEE ACCESS, V8, P26316, DOI 10.1109/ACCESS.2020.2971137
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yang Y, 2015, IEEE SENS J, V15, P2824, DOI 10.1109/JSEN.2014.2380153
   Yang ZQ, 2018, IEEE ACCESS, V6, P38544, DOI 10.1109/ACCESS.2018.2853100
   Zha ZY, 2019, Arxiv, DOI [arXiv:1608.04517, 10.48550/arXiv.1608.04517, DOI 10.48550/ARXIV.1608.04517]
   Zhai H, 2020, APPL OPTICS, V59, P1684, DOI 10.1364/AO.381082
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang Q, 2018, PATTERN RECOGN, V83, P299, DOI 10.1016/j.patcog.2018.06.003
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
NR 55
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
AR s11042-023-16991-6
DI 10.1007/s11042-023-16991-6
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000001
DA 2024-07-18
ER

PT J
AU Farooq, U
   Singh, P
   Khurana, SS
   Kumar, M
AF Farooq, Umar
   Singh, Parvinder
   Khurana, Surinder Singh
   Kumar, Munish
TI Detection of content-based cybercrime in Roman Kashmiri using ensemble
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kashmiri language; Koshur; Cyberbullying; Ensemble learning; XGBM; LGBM;
   n-gram; Lexical features
AB The official language of Kashmir, Kashmiri language or Koshur, is spoken by more than 7 million people, yet its content-based cybercrime detection remains unexplored in theoretical and experimental research. Furthermore, the absence of programming libraries for sentimental analysis and a benchmark corpus has impeded advancements in this field. Challenges persist in working with diverse scripts of Kashmiri, including Perso-Arabic, Sharada, Devanagari, and Roman. Detecting cybercrime in this language is challenging due to its complex morphological nature, lack of resources, scarcity of annotated datasets, and varied linguistic characteristics, emphasizing the importance of overcoming these obstacles to develop effective detection systems. This paper attempts to detect content-based cybercrime in Roman Kashmiri script, extensively utilized on online platforms like social media, chat rooms, emails, etc., by the Kashmiri community. A well-balanced and meaningful dataset, the first of its kind in this context, is compiled, incorporating positive and negative comments, and three strategies were employed for analysis. The findings reveal that the Tf-Idf Vectorizer outperforms other tokenization methods (Count Vectorizer and Tf-Idf Transformer), bi-gram notation exhibits superior performance compared to one and tri-gram notations, and the XGBM proves to be the most effective in terms of evaluation metrics. Leveraging these strategies, Python applications were developed for text classification, successfully distinguishing cyberbullying (unsafe) from non-cyberbullying (safe) instances, with the XGBM exhibiting exceptional accuracy using the Tf-Idf Vectorizer with bi-gram, a Bag of Words, and lexical features. This pioneering research underscores the urgent need for content-based cybercrime detection advancements in the Kashmiri language, paving the way for effective detection systems to address language-specific challenges and promote a safer online environment for the Kashmiri community. Furthermore, this research opens new avenues for further advancements in detecting and preventing cybercrime in Kashmiri and potentially in other languages lacking robust cybercrime detection methodologies.
C1 [Farooq, Umar; Singh, Parvinder; Khurana, Surinder Singh] Cent Univ Punjab, Bathinda, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Bathinda, India.
C3 Central University of Punjab
RP Singh, P (corresponding author), Cent Univ Punjab, Bathinda, India.
EM parvinder.singh@cup.edu.in
RI Kumar, Munish/P-7756-2018; Singh, Parvinder/AAM-5012-2021
OI Kumar, Munish/0000-0003-0115-1620; Singh, Parvinder/0000-0001-7258-7769;
   Farooq, Umar/0000-0002-3786-2574
CR Abbas G., 2023, SN Comput Sci, V4, P1
   Abdhullah-Al-Mamun, 2018, 2018 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P385, DOI 10.1109/ICECE.2018.8636797
   [Anonymous], 2011, Abstract of speakers' strength of languages and mother tongues-2011, Census OF India 2011, Language India, States and Union Territories (Table C-16), P1
   [Anonymous], 2009, P CONT AN WEB 2 0 WO
   [Anonymous], 2019, ABOUT US
   Bastanfard A, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349583
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Bauman S., 2015, Cyberbullying, P53, DOI DOI 10.1002/9781119221685.CH4
   Bilal M, 2016, J KING SAUD UNIV-COM, V28, P330, DOI 10.1016/j.jksuci.2015.11.003
   Britannica TEE, 2018, Encyclopedia Britannica
   Chang FC, 2013, J SCHOOL HEALTH, V83, P454, DOI 10.1111/josh.12050
   Chavan VS, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2354, DOI 10.1109/ICACCI.2015.7275970
   Cooke M, 2008, INT J MARKET RES, V50, P267, DOI 10.1177/147078530805000208
   Dadvar M, 2012, P 12 DTSCH BELG INF
   Dinakar K, 2011, P IEEE INT 5 INT AAA
   Emon EA, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON SMART COMPUTING & COMMUNICATIONS (ICSCC), P108
   Farooq U., 2020, Int J Eng Res Technol (IJERT), V9, P359
   Farooq U, 2021, TEH GLAS, V15, P112, DOI 10.31803/tg-20210205101347
   Grierson GA, 1968, Motilal Banarsidass, P1
   Gupta NV, 2012, P 3 WORKSH S SE AS N
   Haidar B, 2016, EUR MOD S EMS
   Heidemann J, 2012, COMPUT NETW, V56, P3866, DOI 10.1016/j.comnet.2012.08.009
   Hinduja S, 2010, ARCH SUICIDE RES, V14, P206, DOI 10.1080/13811118.2010.494133
   Hussain MG, 2018, 2018 INTERNATIONAL CONFERENCE ON INNOVATION IN ENGINEERING AND TECHNOLOGY (ICIET)
   Jun-Ming X, 2012, P 2012 C N AM CHAPT
   Kanth I, 2013, POLIT RELIG IDEOL, V14, P589, DOI 10.1080/21567689.2013.838477
   Khatana DR, Gujari language and identity in Jammu and Kashmir
   Khodaei A., 2022, Deep emotion detection sentiment analysis of Persian literary text, DOI DOI 10.21203/RS.3.RS-1796157/V1
   Kiani K, 2018, About us
   Kontostathis A., 2009, P TEXT MIN WORKSH 20
   Kumar Mandal A., 2014, International Journal of Artificial Intelligence Applications, V5, DOI [DOI 10.5121/IJAIA.2014.5508, https://doi.org/10.5121/ijaia.2014.5508]
   López V, 2013, KNOWL-BASED SYST, V38, P85, DOI 10.1016/j.knosys.2012.08.025
   Mahdavi R, 2020, 2020 25 INT COMP C C
   McGhee I, 2011, INT J ELECTRON COMM, V15, P103, DOI 10.2753/JEC1086-4415150305
   Mehmood K, 2015, 2015 NATIONAL SOFTWARE ENGINEERING CONFERENCE (NSEC), P42, DOI 10.1109/NSEC.2015.7396343
   Mesleh AM, 2008, ADVANCES IN COMPUTER AND INFORMATIOM SCIENCES AND ENGINEERING, P11, DOI 10.1007/978-1-4020-8741-7_3
   Minoofam SAH, 2012, J CELL AUTOM, V7, P321
   Mouheb D, 2019, INT CONF NEW TECHNOL, DOI 10.1109/ntms.2019.8763808
   Mouheb D, 2018, IEEE INT CONF INNOV, P24, DOI 10.1109/INNOVATIONS.2018.8606030
   Nandhini BS, 2015, PROCEDIA COMPUT SCI, V45, P485, DOI 10.1016/j.procs.2015.03.085
   Omnivision, 2021, about us
   Parey FH, 2017, Int J Sci Res Publ, V7, P228
   Pawar R, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ELECTRO INFORMATION TECHNOLOGY (EIT), P40, DOI [10.1109/eit.2019.8833846, 10.1109/EIT.2019.8833846]
   Perera A, 2021, PROCEDIA COMPUT SCI, V181, P605, DOI 10.1016/j.procs.2021.01.207
   Rafae A, 2015, P 2015 C EMP METH NA
   Raina MK, 2006, How to read and write Kashmiri in Devanagari?
   Reynolds K, 2011, P 2011 10 C MACH LEA
   Savargiv M, 2015 7 C INF KNOWL T
   Savargiv M, 2013, 2013 INTERNATIONAL CONFERENCE ON FUZZY THEORY AND ITS APPLICATIONS (IFUZZY 2013), P380, DOI 10.1109/iFuzzy.2013.6825469
   Selin H, 2008, Soc Sci Law, DOI [10.1007/978-1-4020-4425-0, DOI 10.1007/978-1-4020-4425-0]
   Shakil M, 2012, Languages of Erstwhile State of Jammu Kashmir
   Sheikh AM., 2011, An ethnosemantic analysis of the cultural Lexicon of Kashmiri language
   Shih Y.E., 2007, International Review of Research in Open and Distance Learning, V8, P1, DOI https://doi.org/10.19173/irrodl.v8i2.361
   Singh A, 2020, ARAB J SCI ENG, V45, P2705, DOI 10.1007/s13369-019-04125-w
   Singh P, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-14954-5
   Singh Upinder., 2008, HIST ANCIENT EARLY M
   Sood SO, 2012, J AM SOC INF SCI TEC, V63, P270, DOI 10.1002/asi.21690
   Sourander A, 2010, ARCH GEN PSYCHIAT, V67, P720, DOI 10.1001/archgenpsychiatry.2010.79
   Squicciarini A, 2015, PROCEEDINGS OF THE 2015 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2015), P280, DOI 10.1145/2808797.2809398
   Sticca F, 2013, J YOUTH ADOLESCENCE, V42, P739, DOI 10.1007/s10964-012-9867-3
   Talpur K., 2020, J Crit Rev, V7, P834
   Taylor I., 1883, History of the Alphabet
   Taylor Isaac, 1883, The Alphabet
   Uribe-Villegas O., 1977, Issues in sociolinguistics, DOI [10.1515/9783110806687, DOI 10.1515/9783110806687]
   Veisi H., 2021, J Signal Data Process, V17, P67, DOI [10.29252/jsdp.17.4.67, DOI 10.29252/JSDP.17.4.67]
   Wahbeh AH., 2012, Abhath Al-Yarmouk: Basic Sci Eng, V21, P15
   Wall D., 2004, Crim Justice Matters, V58, P20, DOI [DOI 10.1080/09627250408553239, 10.1080/09627250408553239]
   Walrave M, 2011, CHILD SOC, V25, P59, DOI 10.1111/j.1099-0860.2009.00260.x
   Warikoo K, 2021, Language and politics in Jammu and Kashmir: Issues and perspectives, Jammu, Kashmir and Ladakh: Linguistic predicament
   Wikipedia, 2021, About us
   Yin D, 2019, CAW2.0 2009, April 21, 2009
   Zribi I, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2355
NR 72
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33071
EP 33105
DI 10.1007/s11042-023-16678-y
EA SEP 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400020
DA 2024-07-18
ER

PT J
AU Naveen, P
AF Naveen, Palanichamy
TI Occlusion-aware facial expression recognition: A deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; Occlusion; Deep belief network;
   Persistent contrastive divergence; Densenet
ID NEURAL-NETWORK
AB Facial expression recognition plays a crucial role in computer vision and human-computer interaction, with applications ranging from emotion analysis to social robotics. However, accurate recognition becomes challenging in the presence of occlusions, such as facial hair, glasses, and self-occlusion. This study addresses the problem of facial expression recognition despite occlusions and proposes a novel approach to overcome this challenge. The aim of this research is to develop a robust facial expression recognition framework that effectively handles occlusions and improves recognition accuracy. To achieve this, Hopfield networks, Deep Belief Networks (DBN), and Lanczos interpolation are integrated into the proposed method. Lanczos interpolation helps preserve image quality and reduces during resizing. The Hopfield network is utilized for feature extraction, capturing facial expression features even in the presence of occlusions. The DBN is employed for representation learning, fine-tuning the network using DenseNet to adapt to occluded facial expressions. To evaluate the proposed approach, extensive experiments were conducted on various datasets, including the Static Facial Expressions in the Wild (SFEW) dataset, AffectNet dataset, Real-world Affective Faces Database (RAF-DB), MMI Facial Expression Database, Oulu-CASIA NIR&VIS Facial Expression Database, and Extended Cohn-Kanade (CK +) dataset. The results demonstrate the superiority of our method in handling occlusions and achieving improved facial expression recognition accuracy compared to existing approaches. The contributions of this work are twofold: First, a novel framework is proposed that integrates Lanczos interpolation, Hopfield networks, DBN, and to effectively address the challenge of occlusions in facial expression recognition. Second, extensive experimental validation is provided on diverse datasets, highlighting the superior performance of our approach in handling occlusions and achieving accurate recognition. In conclusion, the proposed approach demonstrates its efficacy in improving facial expression recognition under occlusions. By effectively handling occlusions and capturing relevant features, our method opens up possibilities for enhanced emotion analysis, human-computer interaction, and social robotics applications.
C1 [Naveen, Palanichamy] KPR Inst Engn & Technol, Dept ECE, Coimbatore 641407, Tamil Nadu, India.
RP Naveen, P (corresponding author), KPR Inst Engn & Technol, Dept ECE, Coimbatore 641407, Tamil Nadu, India.
EM naveenamp88@gmail.com
RI Naveen, P/ABF-6323-2020
OI Naveen, P/0000-0002-5202-2557
FU Not Applicable.
FX Not Applicable.
CR Alphonse AS, 2021, J AMB INTEL HUM COMP, V12, P3447, DOI 10.1007/s12652-020-02517-7
   Azazi A, 2015, EXPERT SYST APPL, V42, P3056, DOI 10.1016/j.eswa.2014.10.042
   Danelakis A, 2016, PATTERN RECOGN, V52, P174, DOI 10.1016/j.patcog.2015.10.012
   Devi DAS, 2021, MULTIMED TOOLS APPL, V80, P17543, DOI 10.1007/s11042-021-10547-2
   Dhall A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2106, DOI 10.1109/ICCVW.2011.6130508
   Du Y, 2020, ARXIV200909941
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Hariri W, 2017, ENG APPL ARTIF INTEL, V64, P25, DOI 10.1016/j.engappai.2017.05.009
   Hwooi SKW, 2022, IEEE ACCESS, V10, P96053, DOI 10.1109/ACCESS.2022.3205018
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Kumar MP, 2019, APPL INTELL, V49, P4150, DOI 10.1007/s10489-019-01500-w
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Li B, 2022, MULTICHAOS FRACTAL M, P263, DOI [10.1016/B978-0-323-90032-4.00019-5, DOI 10.1016/B978-0-323-90032-4.00019-5]
   Li J, 2020, NEUROCOMPUTING, V411, P340, DOI 10.1016/j.neucom.2020.06.014
   Li K, 2020, VISUAL COMPUT, V36, P391, DOI 10.1007/s00371-019-01627-4
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2019, INT J COMPUT VISION, V127, P884, DOI 10.1007/s11263-018-1131-1
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liao HB, 2021, MULTIMED TOOLS APPL, V80, P28627, DOI 10.1007/s11042-021-10951-8
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mikhaylenko VS, 2020, AUTOM CONTROL COMPUT, V54, P249, DOI 10.3103/S0146411620030037
   Mollahosseini A, 2017, ARXIV
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shao J, 2019, NEUROCOMPUTING, V355, P82, DOI 10.1016/j.neucom.2019.05.005
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Ting Wu, 2012, Advances in Brain Inspired Cognitive Systems. Proceedings 5th International Conference, BICS 2012, P392, DOI 10.1007/978-3-642-31561-9_44
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Zhang HF, 2021, IEEE T COGN DEV SYST, V13, P898, DOI 10.1109/TCDS.2020.3034807
   Zhang ML, 2015, IEEE T PATTERN ANAL, V37, P107, DOI 10.1109/TPAMI.2014.2339815
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhou S, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0157-2
NR 32
TC 2
Z9 2
U1 14
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32895
EP 32921
DI 10.1007/s11042-023-17013-1
EA SEP 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400013
DA 2024-07-18
ER

PT J
AU Ali, S
   Agrawal, J
AF Ali, Sana
   Agrawal, Jitendra
TI Automated segmentation of brain tumour images using deep learning-based
   model VGG19 and ResNet 101
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Machine learning; Deep learning; Classifiers; Bayesian
ID CLASSIFICATION
AB A life-threatening neurological illness known as a brain tumour is brought on by the uncontrolled growth of cells inside the brain or the skull. Brain tumours may be fatal. A life-threatening brain tumour is caused by uncontrolled cell growth in the brain or skull, which may lead to death. The massive quantity of data that an MRI generates makes it impossible to manually segment the data in a reasonable length of time, which limits the use of accurate quantitative measures in clinical practice. The success of a treatment plan for brain cancer is highly dependent on the level of training and expertise of the attending physician. As a result of this, the utilization of an automated tumour detection system is of the utmost importance in order to assist radiologists and physicians in the detection of brain tumors. Hence, Methods of reliable and automatic segmentation are necessary. However, due to the high amount of spatial and anatomical diversity that exists across brain tumours, automatic segmentation presents a difficult challenge. In this article, we proposed a hybrid model for the automatic segmentation of images that are based on the VGG 19 stack using convolutional neural networks (CNN) with ResNet101. The optimization of a classifier is performed by Bayesian and then cross-validation is used to choose the best parameters for optimized classifiers. During the course of the studies, a number of different transfer learning models were evaluated to, ultimately, decide which model is the most effective for identifying brain alignancies on the basis of neural networks. The suggested stacked classifier model, which makes use of the most recent and cutting-edge technology, outperforms all previous models with regard to precision, recall, and F1 scores.
C1 [Ali, Sana; Agrawal, Jitendra] Rajiv Gandhi Proudyogiki Vishwavidyalaya, Sch Informat Technol, Bhopal, Madhya Pradesh, India.
C3 Rajiv Gandhi Technological University
RP Ali, S (corresponding author), Rajiv Gandhi Proudyogiki Vishwavidyalaya, Sch Informat Technol, Bhopal, Madhya Pradesh, India.
EM sanaalividisha@gmail.com; jitendra@rgtu.net
CR Abdou MA, 2022, NEURAL COMPUT APPL, V34, P5791, DOI 10.1007/s00521-022-06960-9
   Abdullah N., 2011, 2011 Proceedings of IEEE International Conference on Imaging Systems and Techniques (IST 2011), P242, DOI 10.1109/IST.2011.5962185
   [Anonymous], 2016, MICCAI
   Ari A, 2018, TURK J ELECTR ENG CO, V26, P2275, DOI 10.3906/elk-1801-8
   Ayadi W, 2021, NEURAL PROCESS LETT, V53, P671, DOI 10.1007/s11063-020-10398-2
   Bankman IN, 2009, HANDBOOK OF MEDICAL IMAGE PROCESSING AND ANALYSIS, 2ND EDITION, P1
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Chanu MM, 2021, J AMB INTEL HUM COMP, V12, P6911, DOI 10.1007/s12652-020-02336-w
   Charbuty B., 2021, J APPL SCI TECHNOL T, VVol. 2, P20, DOI [10.38094/jastt20165, DOI 10.38094/JASTT20165]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dua S., 2014, MACHINE LEARNING HEA
   Elsayed MS, 2020, I S WORLD WIREL MOBI, P391, DOI 10.1109/WoWMoM49955.2020.00072
   Ghosal P., 2019, P 2019 2 INT C ADV C, P1, DOI [DOI 10.1109/ICACCP.2019.8882973, 10.1109/ICACCP.2019.8882973]
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu A, 2021, INT J IMAG SYST TECH, V31, P657, DOI 10.1002/ima.22495
   Hussain L, 2019, CURR MED IMAGING, V15, P595, DOI 10.2174/1573405614666180718123533
   Khairandish MO, 2022, IRBM, V43, P290, DOI 10.1016/j.irbm.2021.06.003
   Louis DN, 2007, ACTA NEUROPATHOL, V114, P547, DOI 10.1007/s00401-007-0278-6
   Majib MS, 2021, IEEE ACCESS, V9, P116942, DOI 10.1109/ACCESS.2021.3105874
   Mohsen Heba, 2018, Future Computing and Informatics Journal, V3, P68, DOI 10.1016/j.fcij.2017.12.001
   Navamani TM, 2019, DEEP LEARNING AND PARALLEL COMPUTING ENVIRONMENT FOR BIOENGINEERING SYSTEMS, P123, DOI 10.1016/B978-0-12-816718-2.00014-2
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Pinto A, 2015, IEEE ENG MED BIO, P3037, DOI 10.1109/EMBC.2015.7319032
   Rao CS, 2021, MULTIMED TOOLS APPL, V80, P17611, DOI 10.1007/s11042-020-10443-1
   Rao V., 2015, MICCAI Multimodal Brain Tumor Segmentation Challenge (BraTS), P56
   Raza A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071146
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Sapci AH, 2020, JMIR MED EDUC, V6, DOI 10.2196/19285
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro TA, 2023, IEEE REV BIOMED ENG, V16, P70, DOI 10.1109/RBME.2022.3185292
   Srivastava S, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1665, DOI 10.1109/ICACCI.2017.8126082
   Sudharsan K., 2022, 2022 International Conference on Futuristic Technologies (INCOFT), P1, DOI 10.1109/INCOFT55651.2022.10094541
   Zacharaki EI, 2009, MAGN RESON MED, V62, P1609, DOI 10.1002/mrm.22147
NR 35
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33351
EP 33370
DI 10.1007/s11042-023-16828-2
EA SEP 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200004
DA 2024-07-18
ER

PT J
AU Zhuo, X
   Yang, CB
   Gao, YM
   Wang, ZH
   Chen, Y
   Wu, K
AF Zhuo, Xu
   Yang, Chenbin
   Gao, Yuming
   Wang, Zhihua
   Chen, Yang
   Wu, Ke
TI Real-time endoscopy haze removal: a synthetical method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video dehazing; Endoscopy haze removal; Refined Dark Channel prior;
   Markov random field; Color attenuation prior
AB In endoscopic surgeries, the smoke and haze generated by temperature difference and electrosurgical knife usage degrades the surgical view. While many researches on natural single image haze removal being proposed, few works are done for video haze removal of endoscopy view. In this paper, we proposed a synthetical method for endoscopy haze removal combining a Refined Dark Channel Prior (RDCP), Spatial-Temporal Markov Random Field (STMRF), Color Attenuation Prior (CAP) and parameter self-adaption. Qualitative and quantitative experiment results outperformed some traditional and deep learning based methods. Our proposed method is an effective and practical one.
C1 [Zhuo, Xu; Chen, Yang] Southeast Univ, Sch Comp Sci & Engn, Lab Image Sci & Technol, Nanjing, Peoples R China.
   [Yang, Chenbin; Wu, Ke] Tuge Med Technol Co Ltd, Nanjing, Peoples R China.
   [Gao, Yuming; Wang, Zhihua] Southeast Univ, Sch Comp Sci & Engn, Nanjing, Peoples R China.
   [Chen, Yang] Jiangsu Prov Joint Int Res Lab Med Informat Proc, Nanjing, Peoples R China.
   [Chen, Yang] Southeast Univ, Minist Educ, Key Lab New Generat Artificial Intelligence Tech, Nanjing, Peoples R China.
C3 Southeast University - China; Southeast University - China; Southeast
   University - China
RP Chen, Y (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Lab Image Sci & Technol, Nanjing, Peoples R China.; Chen, Y (corresponding author), Jiangsu Prov Joint Int Res Lab Med Informat Proc, Nanjing, Peoples R China.; Chen, Y (corresponding author), Southeast Univ, Minist Educ, Key Lab New Generat Artificial Intelligence Tech, Nanjing, Peoples R China.
EM zhuoxu@seu.edu.cn; ycb199312@gmail.com; 213172447@seu.edu.cn;
   213172208@seu.edu.cn; chenyang.list@seu.edu.cn; wuke0615@126.com
RI Jing, Jing/JSK-6237-2023; Li, Xinyue/JVN-4601-2024; yang,
   zhou/KBB-6972-2024; li, jiaxin/JNT-5073-2023; LI, LI/KCJ-5600-2024;
   Zhang, Bo/JVD-9890-2024; Liu, qi/JZT-5038-2024; feng,
   feng/KBR-1814-2024; chen, gang/JRX-1197-2023; LI, YUN/JTV-7108-2023; li,
   mengyang/JWO-9551-2024; yang, le/KFB-5420-2024; Liu, Zhe/KEJ-5299-2024;
   chen, xu/JNT-3068-2023; wang, xi/JNT-5162-2023; Zhihua,
   Wang/AFO-5263-2022; li, rui/JVM-8999-2024; Wang, Zejun/KBB-8454-2024;
   Lin, Lin/JTU-1595-2023; Zhang, yuxuan/JXM-9935-2024; Li,
   Fan/KBB-8931-2024; wang, wang/JQW-3034-2023; Chen, Xiao/KBD-1464-2024;
   ZHENG, YI/KAM-6536-2024; xiao, wei/KCK-6954-2024; liu,
   feng/KCL-0778-2024; wang, jing/GRS-7509-2022
FU Student Research Training Program
FX The authors would like to thank Prof. Guangquan Zhou from Southeast
   University for his help in revisiting the manuscript.
CR Cai B., 2016, Lecture notes in computer science, DOI [10.1007/978-3-319-48896-7, DOI 10.1007/978-3-319-48896-7]
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Jalal Nour Aldeen, 2017, Current Directions in Biomedical Engineering, V3, P521, DOI 10.1515/cdbme-2017-0110
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Lee S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0104-y
   Leibetseder A, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P296, DOI 10.1145/3126686.3126690
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Luo XB, 2017, IEEE T MED IMAGING, V36, P2021, DOI 10.1109/TMI.2017.2701861
   Sidorov O, 2019, arXiv
   Tchaka K, 2017, PROC SPIE, V10133, DOI 10.1117/12.2254622
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang CC, 2018, Arxiv, DOI arXiv:1803.08410
   Xu K, 2019, Arxiv, DOI arXiv:1904.02363
   Zhang JW, 2011, VISUAL COMPUT, V27, P749, DOI 10.1007/s00371-011-0569-8
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 17
TC 0
Z9 0
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31195
EP 31209
DI 10.1007/s11042-023-16375-w
EA SEP 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001067934200001
DA 2024-07-18
ER

PT J
AU Kumar, C
   Singh, S
AF Kumar, Chandan
   Singh, Shailendra
TI Security standards for real time video surveillance and moving object
   tracking challenges, limitations, and future: a case study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video surveillance; Entropy learning; Video encryption; Object tracking;
   Background subtraction; Kalman filter
ID ALGORITHM; SYSTEM; RECOGNITION; ROBUST
AB Uses of video surveillance (VS) have exponentially increased using the internet as a platform. Therefore, security issues in such real time videos need to be addressed. Video may have multiple moving objects in a frame and different features in video lengths. Hence, designing content-based video encryption standards and lightweight crypto-encryption standards are needed to serve the real-time requirement for securing surveillance videos. This paper presents a survey and case study of various encryption standards of VS, which secures video data and used for object tracking (OT). In the first part, a fast and secure modified AES method is proposed. The performance is compared using NCPR and UACI measures with state-of-the-art encryption standards. Modified AES is lightweight and offers nearly 99% NCPR value and offers the fastest elapsed time. In the second part, the paper has proposed an entropy adaptive object learning model for only securing frames containing moving objects in the scene. Percentage frame adaption is achieved by the entropy threshold. The proposed entropy learning model based on content adaptive security standards has proven to save memory requirements by encrypting the desired frames only. In third part, weight average background subtraction (BS) approaches are used for evaluation which performs better for multi OT. The paper has designed learning and adapting the best RGB space to apply tracking. The qualitative expected outcomes are presented for real-time captured videos with different object motions. The performance comparison of the entropy and crypto weights is compared for selected light weight ciphers under the consideration of multiple object motion of various real time videos. The paper finally addresses various challenges, open issues and future scopes of VS systems.
C1 [Kumar, Chandan] RGPV, Comp Sci & Engn, Bhopal, India.
   [Singh, Shailendra] NITTTR, Comp Sci & Engn, Bhopal, India.
C3 Rajiv Gandhi Technological University; National Institute of Technical
   Teachers Training & Research, Bhopal
RP Kumar, C (corresponding author), RGPV, Comp Sci & Engn, Bhopal, India.
EM mckv.chandan@gmail.com
RI Singh, Shailendra/HOH-4339-2023
OI Singh, Shailendra/0000-0002-3964-5100; KUMAR,
   CHANDAN/0000-0001-9485-2375
CR Abbas Q, 2018, MULTIMED TOOLS APPL, V77, P20415, DOI 10.1007/s11042-017-5438-7
   Ahmed E, 2014, 2014 FIRST INTERNATIONAL IMAGE PROCESSING, APPLICATIONS AND SYSTEMS CONFERENCE (IPAS)
   Ahmed SA, 2019, IEEE T CIRC SYST VID, V29, P1985, DOI 10.1109/TCSVT.2018.2857489
   Aïssa B, 2012, INT J ADV COMPUT SC, V3, P150
   Al-Kadei FHMS, 2020, INT CONF ADVAN COMPU, P1302, DOI [10.1109/ICACCS48705.2020.9074430, 10.1109/icaccs48705.2020.9074430]
   Ali F.M.S., 2014, International Journal of Computer Applications, V100, P1
   Alsaffar D. M., 2020, 2020 3 INT C COMP AP, P1, DOI [10.1109/ICCAIS48893.2020.9096809, DOI 10.1109/ICCAIS48893.2020.9096809]
   Alsaif KI., 2018, INT J COMPUTER APPL, V179, P10
   Ambata LU, 2019, IEEE 11 INT C HUM NA, P1
   Angelo KM, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2018), P1055, DOI 10.1109/ICCMC.2018.8487514
   [Anonymous], 2001, Cryptographic Hardware and Embedded SystemsCHES 2001: Third International Workshop Paris, France, May 14-16, 2001 Proceedings 3
   Arjun SV, 2015, NOVATEUR PUBLICATION
   Arreola L, 2022, INT C CONTROL DECISI, P45, DOI [10.1109/CODIT55151.2022.9803981, 10.1109/CoDIT55151.2022.9803981]
   Asghar MN, 2019, IEEE ACCESS, V7, P111709, DOI 10.1109/ACCESS.2019.2934226
   Asl AM, 2021, INT J NONLINEAR ANAL, V12, P903, DOI 10.22075/IJNAA.2021.5520
   Asvadi A, 2012, P 4 C INF KNOWL TECH
   Atrey PK, 2013, INTELLIGENT MULTIMED, P1, DOI [10.1007/978-3-642-41512-8_1, DOI 10.1007/978-3-642-41512-8_1]
   Barreto PSLM., 2007, 25 BRAZ S COMP NETW, V1, P61
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   Beaulieu R, 2013, P 52 ANN DES AUT C D, P1
   Bremond F, 2013, OBJECT TRACKING VIDE, P1
   Busnel Y, 2008, LECT NOTES COMPUT SC, V5067, P46, DOI 10.1007/978-3-540-69170-9_4
   Chen YF, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P754, DOI 10.1109/ICNC.2015.7378085
   Cheng F, 2010, ACM S APPL COMP LAUS
   Dang PP, 2000, P SOC PHOTO-OPT INS, V4122, P1, DOI 10.1117/12.409238
   De S, 2022, MULTIMED TOOLS APPL, V81, P5485, DOI 10.1007/s11042-021-11696-0
   Dena A., 2018, J THEORETICAL APPL I, V96, P7065
   Desai S, 2015, INT J ELECT ELECT EN, V07
   Deshmukh A., 2013, IJES, V2, P38
   Dinu D, 2016, LECT NOTES COMPUT SC, V10031, P484, DOI 10.1007/978-3-662-53887-6_18
   Enzeng Dong, 2020, 2020 IEEE International Conference on Mechatronics and Automation (ICMA), P1140, DOI 10.1109/ICMA49215.2020.9233627
   Etem T, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.122750
   Ezzat MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093222
   Fedorov A, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0234-z
   Gautam Aayushi, 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P729, DOI 10.1109/I-SMAC47947.2019.9032529
   Guo J, 2011, LECT NOTES COMPUT SC, V6917, P326, DOI 10.1007/978-3-642-23951-9_22
   Hafsa A, 2021, MULTIMED TOOLS APPL, V80, P19769, DOI 10.1007/s11042-021-10700-x
   Hao Wang, 2007, 2007 International Conference on Wireless Networks (ICWN'07), P180
   Heikkilä J, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P74, DOI 10.1109/VS.1999.780271
   Indrani, 2016, INT J INNOV SCI ENG, V3, P266
   Islam MZ., 2009, INT J SIGNAL PROCESS, V2, P119
   Iswanto IA, 2019, PROCEDIA COMPUT SCI, V157, P521, DOI 10.1016/j.procs.2019.09.009
   Jaswanth PV., 2020, INT J RF MICROW C E, V9, P547, DOI [10.35940/ijeat.E9648.069520, DOI 10.35940/IJEAT.E9648.069520]
   Jin C, 2016, ADV INTELL SYST, V466, P3, DOI 10.1007/978-3-319-33389-2_1
   Kalbo N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174806
   Kamate S, 2015, PROCEDIA COMPUT SCI, V61, P436, DOI 10.1016/j.procs.2015.09.183
   Kawle P., 2014, MODIFIED ADV ENCRYPT, V4, P21
   Khan J, 2020, IEEE ACCESS, V8, P15747, DOI 10.1109/ACCESS.2020.2966656
   Khelifi F, 2019, MOBILE NETW APPL, V24, P761, DOI 10.1007/s11036-018-1090-3
   Kumar C, 2021, IEEE 8 UTT PRAD SECT, P1, DOI [10.1109/UPCON52273.2021.9667591, DOI 10.1109/UPCON52273.2021.9667591]
   Kumar C, 2022, IMAGING SCI J, V70, P439, DOI 10.1080/13682199.2023.2171550
   Kumar S., 2016, Perspect. Sci., V8, P317
   Kumar BJS, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P501, DOI 10.1109/ICCSP.2017.8286408
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Li HS, 2018, INT J THEOR PHYS, V57, P3745, DOI 10.1007/s10773-018-3887-z
   Li H, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134419
   Liu K, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/680623
   Miranto Afit, 2019, 2019 International Conference on Information and Communications Technology (ICOIACT), P153
   Mishra PK, 2016, 3 INT C COMP SUST GL
   Mrithu AS, 2016, IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGICAL TRENDS IN COMPUTING, COMMUNICATIONS AND ELECTRICAL ENGINEERING (ICETT)
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Naga Srinivasu P, 2021, BIOINSPIRED NEUROCOM, V903, DOI [10.1007/978-981-15-5495-7_1, DOI 10.1007/978-981-15-5495-7_1]
   Noor MBM, 2019, COMPUT NETW, V148, P283, DOI 10.1016/j.comnet.2018.11.025
   Pal SK., 2013, INT J ENG RES TECHNO, V2, P193
   Patel AS, 2019, 2019 IEEE C INFORM C, P1, DOI [10.1109/CICT48419.2019.9066256, DOI 10.1109/CICT48419.2019.9066256]
   Patel AS, 2022, MULTIMED TOOLS APPL, V81, P6849, DOI 10.1007/s11042-021-11722-1
   Patil N, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P344, DOI 10.1109/ICCSP.2017.8286374
   Phap DN, 2020, IEEE ACCESS, V8, P108158, DOI 10.1109/ACCESS.2020.3000316
   Potestad-Ordóñez FE, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236909
   Puvvadi ULN, 2015, IEEE T IND INFORM, V11, P1457, DOI 10.1109/TII.2015.2491259
   Rajavel R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03157-1
   Rajpurohit J., 2014, PROCEDIA COMPUT SCI, V91, P10
   Ratnadewi, 2018, J PHYS CONF SER, V954, DOI 10.1088/1742-6596/954/1/012009
   Rawat P., 2013, INT J SIGNAL PROCESS, V6, P17
   Rawat P., 2011, INT J SIGNAL IMAGE P, V2, P159, DOI DOI 10.5121/sipij.2011.2213
   Rego A, 2018, IEEE ACCESS, V6, P31580, DOI 10.1109/ACCESS.2018.2842034
   Ren Gaofeng, 2013, Video Engineering, V37, P79
   Sadkhan SB, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCE IN SUSTAINABLE ENGINEERING AND ITS APPLICATION (ICASEA), P105, DOI 10.1109/ICASEA.2018.8370965
   Sadura P, 2021, 2021 SIGNAL PROCESSING SYMPOSIUM (SPSYMPO), P248, DOI 10.1109/SPSYMPO51155.2020.9593340
   Sajjad M, 2019, IEEE T
   Sediq Faten H. Mohammed, 2020, 6 INT C ADV COMP COM
   Sekaran KC., 2014, INT J COMPUT SCI NET, V11, P77
   Sharma A., 2019, INT J ENG ADV TECHNO, V8, P5139
   Shifa A, 2020, IEEE ACCESS, V8, P177131, DOI 10.1109/ACCESS.2020.3024926
   Simpson A, 2023, J MENT HEALTH, V32, P369, DOI 10.1080/09638237.2023.2194988
   Singh S, 2020, SMART INNOVATION SYS, V141, DOI [10.1007/978-981-13-8406-6_63, DOI 10.1007/978-981-13-8406-6_63]
   Singhi Vandita., 2017, IJIRCCE, V5, P1111
   Singla BS., 2020, INT J ADV SCI TECHNO, V29, P8838
   Soeleman MA, 2012, TENCON IEEE REGION
   Sowjanya PL., 2016, INT J ENG SCI RES TE, V5, P379
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Srinivasu PN, 2020, INT J INF SYST MODEL, V11, P74, DOI 10.4018/IJISMD.2020010105
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Supreeth HSG, 2018, SIGNAL IMAGE VIDEO P, V12, P1097, DOI 10.1007/s11760-018-1259-z
   Suresh S., 2015, INT J IMAG ROBOT, V15, P117
   Susanto A., 2018, INT J PR ENG MAN-GT, V7, P62, DOI [10.14419/ijet.v7i2.2.12734, DOI 10.14419/IJET.V7I2.2.12734]
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   TAH A, 2017, INDIAN J SCI TECHNOL, V10, pNIL82, DOI DOI 10.17485/ijst/2017/v10i19/95427
   Techmer A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P648, DOI 10.1109/ICIP.2001.958202
   Usman M, 2017, INT J ADV COMPUT SC, V8, P402
   Martínez YV, 2019, IEEE ACCESS, V7, P98507, DOI 10.1109/ACCESS.2019.2930401
   Wesonga S, 2022, INT C CONTR AUTOMAT, P333, DOI 10.23919/ICCAS55662.2022.10003872
   Woeber Wilfried, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P357
   Wu CW, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/592960
   Yasser I, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/9597619
   Ye Y, 2013, IEEE ACCESS, V1, P646, DOI 10.1109/ACCESS.2013.2282613
   Zang Q, 2003, LECT NOTES COMPUT SC, V2756, P198
   Zenga H, 2018, 8 INT C INF COMM TEC
   Zhang X, 2019, J IEEE ACCESS, V4
   Zhang XQ, 2021, INT J AUTOM COMPUT, V18, P311, DOI 10.1007/s11633-020-1274-8
   Zhang YS, 2017, IEEE INTERNET THINGS, V4, P1380, DOI 10.1109/JIOT.2017.2732357
   Zulkifley MA, 2012, SENSORS-BASEL, V12, P15638, DOI 10.3390/s121115638
NR 112
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30113
EP 30144
DI 10.1007/s11042-023-16629-7
EA SEP 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000006
DA 2024-07-18
ER

PT J
AU Yadav, SP
   Jindal, M
   Rani, P
   de Albuquerque, VHC
   Nascimento, CD
   Kumar, M
AF Yadav, Satya Prakash
   Jindal, Muskan
   Rani, Preeti
   de Albuquerque, Victor Hugo C.
   Nascimento, Caio dos Santos
   Kumar, Manoj
TI An improved deep learning-based optimal object detection system from
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object Detection; Chess Piece Identification; You Only Look Once (YOLO);
   Single Stage Detector (SSD); Faster Region-Based Convolutional Neural
   Networks (R-CNN)
ID CHESS
AB Computer vision technology for detecting objects in a complex environment often includes other key technologies, including pattern recognition, artificial intelligence, and digital image processing. It has been shown that Fast Convolutional Neural Networks (CNNs) with You Only Look Once (YOLO) is optimal for differentiating similar objects, constant motion, and low image quality. The proposed study aims to resolve these issues by implementing three different object detection algorithms-You Only Look Once (YOLO), Single Stage Detector (SSD), and Faster Region-Based Convolutional Neural Networks (R-CNN). This paper compares three different deep-learning object detection methods to find the best possible combination of feature and accuracy. The R-CNN object detection techniques are performed better than single-stage detectors like Yolo (You Only Look Once) and Single Shot Detector (SSD) in term of accuracy, recall, precision and loss.
C1 [Yadav, Satya Prakash] GL Bajaj Inst Technol & Management GLBITM, Dept Comp Sci & Engn, Greater Noida 201306, India.
   [Yadav, Satya Prakash] Fed Inst Educ Sci & Technol Ceara IFCE, Grad Program Telecommun Engn PPGET, Fortaleza, CE, Brazil.
   [Jindal, Muskan] Amity Univ, Dept Comp Sci & Engn, Noida 201313, India.
   [Rani, Preeti] SRM Inst Sci & Technol, Dept Elect & Commun Engn, Delhi NCR Campus,Delhi Meerut Rd, Ghaziabad, Uttar Pradesh, India.
   [de Albuquerque, Victor Hugo C.; Nascimento, Caio dos Santos] Univ Fed Ceara, Dept Teleinformat Engn, Fortaleza, CE, Brazil.
   [Kumar, Manoj] Univ Wollongong Dubai, Sch Comp Sceince, FEIS, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 Instituto Federal do Ceara (IFCE); Amity University Noida; SRM Institute
   of Science & Technology Delhi NCR (Ghaziabad); Universidade Federal do
   Ceara; University of Wollongong; Middle East University
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Sch Comp Sceince, FEIS, Dubai Knowledge Pk, Dubai, U Arab Emirates.; Kumar, M (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM prakashyadav.satya@gmail.com; muskanjindal2790@gmail.com;
   preetiresearcher1@gmail.com; victor.albuquerque@ieee.org;
   caio.santos@alu.ufc.br; wss.manojkumar@gmail.com
RI de Albuquerque, Victor Hugo C./C-3677-2016; YADAV, SATYA/X-8396-2018;
   Kumar, Manoj/AFS-0700-2022
OI de Albuquerque, Victor Hugo C./0000-0003-3886-4309; YADAV,
   SATYA/0000-0002-2634-5600; Kumar, Manoj/0000-0001-9598-0280
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   Agyemang I.O., 2021, 2021 18 INT COMP C W, P175, DOI [10.1109/ICCWAMTIP53232.2021.9674153, DOI 10.1109/ICCWAMTIP53232.2021.9674153]
   Ahmed I, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107226
   Ansari Ghazala, 2023, Proceedings of International Conference on Recent Trends in Computing: ICRTC 2022. Lecture Notes in Networks and Systems (600), P641, DOI 10.1007/978-981-19-8825-7_55
   Atrish A, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2017), P103, DOI 10.1145/3177404.3177432
   Bennett S, 2014, COMPUT VIS IMAGE UND, V118, P197, DOI 10.1016/j.cviu.2013.10.008
   Cai YF, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3065438
   Conghao Li, 2020, Recent Trends in Intelligent Computing, Communication and Devices. Proceedings of ICCD 2018. Advances in Intelligent Systems and Computing (AISC 1031), P467, DOI 10.1007/978-981-13-9406-5_57
   Czyzewski MA, 2020, FOUND COMPUT DECIS S, V45, P257, DOI 10.2478/fcds-2020-0014
   Ding LH, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102949
   Fernandez A, 2008, PATTERN RECOGNIT LET, V29
   Halim Z, 2021, MULTIMED TOOLS APPL, V80, P33377, DOI 10.1007/s11042-021-11419-5
   Hou Qibin., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P3203
   Hu JY, 2021, KNOWL INF SYST, V63, P717, DOI 10.1007/s10115-020-01538-0
   Jang Y, 2019, COMPUT VIS IMAGE UND, V182, P17, DOI 10.1016/j.cviu.2019.01.006
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Koppanati RK, 2021, IEEE CONSUM ELECTR M, V10, P41, DOI 10.1109/MCE.2020.3003127
   Kumar Ashwani, 2020, Procedia Computer Science, V171, P2610, DOI 10.1016/j.procs.2020.04.283
   Kumar A., 2017, 2016 IEEE Annual India Conference, P1, DOI DOI 10.1109/ICISC.2017.8068696
   Kumar K, 2021, MULTIMED TOOLS APPL, V80, P11079, DOI 10.1007/s11042-020-10157-4
   Kumar K, 2019, ADV INTELL SYST, V748, P453, DOI 10.1007/978-981-13-0923-6_39
   Kumar K, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P100, DOI 10.1145/3154979.3154998
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P7383, DOI 10.1007/s11042-017-4642-9
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li YD, 2020, CHINESE J AERONAUT, V33, P1747, DOI 10.1016/j.cja.2020.02.024
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Pan HD, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115987
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Preeti R, 2022, INT C SIGN PROC INT
   Rani P, 2022, INT J E-HEALTH MED C, V13, DOI 10.4018/IJEHMC.309436
   Rani P, 2023, COMPUT ELECTR ENG, V105, DOI 10.1016/j.compeleceng.2022.108543
   Rani P, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/3365392
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sakai Y, 2019, FUTURE GENER COMP SY, V92, P157, DOI 10.1016/j.future.2018.09.068
   Sharma S, 2017, 2017 IEEE 7TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE IEEE CCWC-2017
   Sharma S, 2021, MULTIMED TOOLS APPL, V80, P26319, DOI 10.1007/s11042-021-10768-5
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Srivastava G, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01065-6
   Villafaina S, 2019, PHYSIOL BEHAV, V198, P140, DOI 10.1016/j.physbeh.2018.10.017
   Wang Q, 2023, INFORM SCIENCES, V626, P694, DOI 10.1016/j.ins.2023.01.004
   Wang XL, 2017, PROC CVPR IEEE, P3039, DOI 10.1109/CVPR.2017.324
   Yi C, 2022, LECT NOTES COMPUT SC, V13262, P3, DOI 10.1007/978-3-031-11488-5_1
   Yi JR, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102827
   Yuan J, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107131
NR 46
TC 4
Z9 4
U1 16
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30045
EP 30072
DI 10.1007/s11042-023-16736-5
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066067700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Shaban, WM
AF Shaban, Warda M.
TI Early diagnosis of liver disease using improved binary butterfly
   optimization and machine learning algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Liver Disease; Feature selection; Butterfly Optimization Algorithm;
   Classification
ID PREDICTION
AB Liver disease in patients is on the rise due to environmental factors like toxic gas exposure, contaminated food, drug interactions, and excessive alcohol use. Therefore, diagnosing liver disease is crucial for saving lives and managing the condition effectively. In this paper, a new method called Liver Patients Detection Strategy (LPDS) is proposed for diagnosing liver disease in patients from laboratory data alone. The three main parts of LPDS are data preprocessing, feature selection, and detection. The data from the patient is processed, and any anomalies are removed during this stage. Then, during feature selection phase, the most helpful features are chosen. A novel method is proposed to choose the most relevant features during the feature selection stage. The formal name for this method is IB(2)OA, which stands for Improved Binary Butterfly Optimization Algorithm. There are two steps to IB(2)OA, which are; Primary Selection (PS) step and Final Selection (FS) step. This paper presents two enhancements. The first is Information Gain (IG) approach, which is used for initial feature reduction. The second is implementing BOA's initialization with Optimization Based on Opposition (OBO). Finally, five different classifiers, which are Support Vector Machine (SVM), K-Nearest Neighbor (KNN), Naive Bayes (NB), Decision Tree (DT), and Random Forest (RF) are used to identify patients with liver disease during the detection phase. Results from a battery of experiments show that the proposed IB(2)OA outperforms the state-of-the-art methods in terms of precision, accuracy, recall, and F-score. In addition, when compared to the state-of-the-art, the proposed model's average selected features score is 4.425. In addition, among all classifiers considered, KNN classifier achieved the highest classification accuracy on the test dataset.
C1 [Shaban, Warda M.] Nile Higher Inst Engn & Technol, Mansoura, Egypt.
RP Shaban, WM (corresponding author), Nile Higher Inst Engn & Technol, Mansoura, Egypt.
EM warda_mohammed@nilehi.edu.eg
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB)
CR Acharjya DP, 2022, MULTIMED TOOLS APPL, V81, P13489, DOI 10.1007/s11042-021-11495-7
   Adamu A, 2021, MACH LEARN APPL, V6, DOI 10.1016/j.mlwa.2021.100108
   Alweshah M, 2022, NEURAL COMPUT APPL, V34, P11267, DOI 10.1007/s00521-020-05210-0
   Amin Ruhul, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.101155
   Nguyen BH, 2020, SWARM EVOL COMPUT, V54, DOI 10.1016/j.swevo.2020.100663
   Bharti R, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8387680
   Brezocnik L, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8091521
   EL-Hasnony IM, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12786
   Gaber A, 2022, APPL SCI MDPI, V12, P1
   Gholami J, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106402
   Gumbs AA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134918
   Hectors SJ, 2021, EUR RADIOL, V31, P3805, DOI 10.1007/s00330-020-07475-4
   Heigl M, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10131534
   Houssein EH, 2023, NEURAL COMPUT APPL, V35, P5251, DOI 10.1007/s00521-022-07916-9
   Hsu C, 2019, CLIN GASTROENTEROL H, V17, P630, DOI 10.1016/j.cgh.2018.05.059
   Hu P, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105746
   Hussien AG, 2022, INT J MACH LEARN CYB, V13, P309, DOI 10.1007/s13042-021-01326-4
   Hydes T, 2021, BMJ OPEN, V11, DOI 10.1136/bmjopen-2020-044952
   Karim MA, 2023, CLIN GASTROENTEROL H, V21, P670, DOI 10.1016/j.cgh.2022.03.010
   Kicska G, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5030036
   Long W, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107146
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Meng CZ, 2022, SPECTROSC LETT, V55, P79, DOI 10.1080/00387010.2022.2027988
   Richard M, 2023, J HEPATOL, V79, P461, DOI 10.1016/j.jhep.2023.04.021
   Pashaei E, 2022, NEURAL COMPUT APPL, V34, P6427, DOI 10.1007/s00521-021-06775-0
   Pramanik R, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119643
   Rajathi GI, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010033
   Sadeghian Z, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104079
   Sathiyabhama B, 2021, NEURAL COMPUT APPL, V33, P14583, DOI 10.1007/s00521-021-06099-z
   Shaban WM, 2023, NEURAL COMPUT APPL, V35, P6831, DOI 10.1007/s00521-022-08062-y
   Shaban WM, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108110
   Shaban WM, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106906
   Shaban WM, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106270
   Singh J, 2020, PROCEDIA COMPUT SCI, V167, P1970, DOI 10.1016/j.procs.2020.03.226
   Singh N, 2021, CHEMOMETR INTELL LAB, V217, DOI 10.1016/j.chemolab.2021.104396
   Sun L, 2022, APPL INTELL, V52, P17264, DOI 10.1007/s10489-021-03142-3
   Tang J, 2023, ARTIF INTELL REV, V56, P4295, DOI 10.1007/s10462-022-10281-7
   Tang J, 2021, IEEE-CAA J AUTOMATIC, V8, P1627, DOI 10.1109/JAS.2021.1004129
   Thawkar S, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104968
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Tubishat M, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.113873
   Wu CC, 2019, COMPUT METH PROG BIO, V170, P23, DOI 10.1016/j.cmpb.2018.12.032
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Zhang G, 2020, INTERDISCIP SCI, V12, P288, DOI 10.1007/s12539-020-00372-w
   Zhang S, 2022, NAT RESOUR RES, V31, P1981, DOI 10.1007/s11053-021-09872-y
NR 45
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30867
EP 30895
DI 10.1007/s11042-023-16686-y
EA SEP 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900010
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhou, QF
   Guo, YQ
   Zhao, WL
   Xu, KJ
   Wang, K
   Wu, ZL
   Sun, H
AF Zhou, Qifan
   Guo, Yingqing
   Zhao, Wanli
   Xu, Kejie
   Wang, Kun
   Wu, Zhenglong
   Sun, Hao
TI Research on fault diagnosis technology of simulated altitude test
   facility based on multi-optimization strategy, real-time data transfer,
   and the M-H attention-RF algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Simulated altitude test facility; Data extraction and transfer
   techniques; Multi-optimization strategies; Granularity improvement
   schemes; Fault diagnosis algorithms
AB The simulated altitude test facility, as an important means to verify the performance, characteristics, and evaluation result criteria of aero-engines, has a pivotal engineering significance in the process of aero-engine development and promotion of application. In order to cope with the drawbacks of traditional techniques for experimental processes, this paper proposes the real-time data extraction and transfer techniques with multiple optimization strategies and the fault diagnosis technology of simulated altitude test facility with an improved optimization algorithm is propose, Firstly, the optimization strategy based on peak shaving + peak fast processing and token bucket instructions with multi-threaded parallel processing flow allocation call logic is used to realize the test data for fast extraction and migration demand, and then the overall data transfer function is optimized in granularity improvement schemes by using the abstraction optimization strategy mechanism based on Direct Routing mode to maximise real-time targets while ensuring correspondence and completeness of test data. Finally, the random forest algorithm with Multi-Head Attention optimization is used to implement the diagnostic technology research of the simulated altitude test facility under two scenarios under the data-driven mode, and the analytical comparison and validation results with the unimproved and optimized Random Forest algorithm are given. The results indicate that the amount of test data synchronization reaches 300 + lines per second, the accuracy of fault diagnosis identification is increased by 30% at the highest degree, and the proposed improvement research has a very high degree of application value and innovativeness.
C1 [Zhou, Qifan; Guo, Yingqing; Zhao, Wanli; Xu, Kejie; Wang, Kun; Wu, Zhenglong] Northwestern Polytech Univ, Xian 710000, Peoples R China.
   [Sun, Hao] Xian Inst Modern Control Technol, Xian 710054, Peoples R China.
C3 Northwestern Polytechnical University
RP Zhou, QF (corresponding author), Northwestern Polytech Univ, Xian 710000, Peoples R China.
EM george13@mail.nwpu.edu.cn
RI Zhao, Wanli/AAY-1931-2021
CR Addad RA, 2020, IEEE NETWORK, V34, P92, DOI 10.1109/MNET.001.1800289
   Afkhami S, 2023, AEROSP SCI TECHNOL, V133, DOI 10.1016/j.ast.2023.108111
   Ahmadi K, 2023, ECOL MODEL, V475, DOI 10.1016/j.ecolmodel.2022.110190
   [Anonymous], 2017, Patents; Patent Application Titled, Patent No. [USPTO20170116206, 20170116206]
   Bansal N, 2022, LECT NOTES COMPUT SC, V13167, P159, DOI 10.1007/978-3-030-96600-3_12
   [曹建国 Cao Jianguo], 2018, [推进技术, Journal of Propulsion Technology], V39, P961
   [陈磊 Chen Lei], 2022, [计算机科学, Computer Science], V49, P27
   Chen T., 2021, SCI TECHNOL B, V37, P57, DOI [10.13774/j.cnki.kjtb.2021.04.011, DOI 10.13774/J.CNKI.KJTB.2021.04.011]
   Chen Yidan., 2022, AUTOM TECHNOL APPL, V41, P60, DOI [10.20033/j.1003-7241.(2022)10-0060-05, DOI 10.20033/J.1003-7241.(2022)10-0060-05]
   Chengnan Wu., 2021, POWER ENERGY, V42, P527
   Gao R, 2022, RADIO ENG, P1
   Guangniu Su., 2022, CHINA SME, V06, P67
   Guo J, 2010, INT NETW INT SYST IN
   Hossam M., 2022, ELECTRONICS, V11, P3610, DOI [10.3390/ELECTRONICS11213610, DOI 10.3390/ELECTRONICS11213610]
   Hou M., 2012, AVIAT SCI TECHNOL, V03, P1
   Huang D, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3062104
   Klingerman S, 2020, DATABASE TRENDS APPL, V34
   Lehman TJ., 2020, COMPUT NETW, V35, P24
   Li Z., 2022, SHIP SCI TECHNOL, V44, P119
   Liu J., 2022, PROPULSION TECHNOLOG, V10, P383
   [马徐瀚 Ma Xuhan], 2016, [微电子学与计算机, Microelectronics & Computer], V33, P84
   Ouafiq El Mehdi, 2022, Human Centred Intelligent Systems: Proceedings of KES-HCIS 2022 Conference. Smart Innovation, Systems and Technologies (310), P191, DOI 10.1007/978-981-19-3455-1_15
   Pant A, 2022, GEOTEXT GEOMEMBRANES, V50, P1188, DOI 10.1016/j.geotexmem.2022.08.003
   Pei X., 2016, GAS TURBINE TESTING, V29, P5
   Peres RS, 2020, IEEE ACCESS, V8, P220121, DOI 10.1109/ACCESS.2020.3042874
   Prasath N., 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P1674, DOI 10.1109/ICACCS51430.2021.9441898
   Schmid M, 2021, IEEE T POWER ELECTR, V36, P2584, DOI 10.1109/TPEL.2020.3012964
   Shen Zhang, 2020, IEEE Access, V8, P29857, DOI 10.1109/ACCESS.2020.2972859
   Sun H., 2022, Autom. Technol. Appl, V41, P73
   Tamilselvan P, 2013, RELIAB ENG SYST SAFE, V115, P124, DOI 10.1016/j.ress.2013.02.022
   Wang J., 2021, SHIP ELECT ENG, V41, P25
   Wang Y., 2023, CONTROL ENG, P1, DOI DOI 10.14107/J.CNKI.KZGC.20220513
   Wang YB, 2022, RENEW ENERG, V201, P889, DOI 10.1016/j.renene.2022.11.016
   Wei YP, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22207994
   Zhang J, 2021, AUTOM APPL, P74, DOI [10.19769/j.zdhy.2021.05.020, DOI 10.19769/J.ZDHY.2021.05.020]
   [章琪 Zhang Qi], 2023, [计算机科学, Computer Science], V50, P115
   Zhang Xiaodong., 2023, COMPUT SYST APPL, V32, P95, DOI [10.15888/j.cnki.csa.008958, DOI 10.15888/J.CNKI.CSA.008958]
   Zheng YF, 2022, INT J FOUND COMPUT S, V33, P717, DOI 10.1142/S0129054122420114
   Zhou Q, 2023, RES ALTITUDE TABLE D, DOI [10.21203/rs.3.rs-2555451/v1, DOI 10.21203/RS.3.RS-2555451/V1]
NR 39
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 28729
EP 28760
DI 10.1007/s11042-023-16738-3
EA SEP 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001060763900007
DA 2024-07-18
ER

PT J
AU Dhal, P
   Azad, C
AF Dhal, Pradip
   Azad, Chandrashekhar
TI Hybrid momentum accelerated bat algorithm with GWO based optimization
   approach for spam classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spam detection; Feature selection; Bat algorithm; Grey wolf optimization
ID NEGATIVE SELECTION ALGORITHM; PARTICLE SWARM OPTIMIZATION; GREY WOLF
   OPTIMIZER; DETECTION MODEL; LEVY FLIGHT; NEURAL-NETWORKS; EMAIL; SYSTEM
AB Spam emails have become more prevalent, necessitating the development of more effective and reliable anti-spam filters. Internet users face security threats, and youngsters are exposed to inappropriate content while receiving spam emails. The gigantic data flow between billions of people and the tremendous number of features (attributes) makes the task more tiresome and complex. Feature Selection (FS) technique is essential for overwhelming accuracy, time and spatial complexity when we have high dimensional data (i.e., the number of features is very large). Spam emails have been successfully filtered and detected using Machine Learning (ML) methods by various researchers nowadays. This work proposes a hybrid binary Metaheuristic Algorithm (MA) based Feature Selection (FS) approach for classifying email spam. The proposed FS approach is based upon two MA, i.e., Bat Algorithm (BA) with Grey Wolf Optimization(GWO). A novel concept of bat momentum has been introduced here, replacing the previous bat velocity. Two quantity, i.e., velocity and momentum, has an entirely different effect on the particle (i.e. bats). But they always follow the exact directions for both of them. To provide the best possible set of features for the FS process, the proposed approach uses an amalgamation technique to reach both the global and local optimum solution. To get the global optimum solution, a new momentum-based equation has been added to the BA, substituting the velocity equation from the prior BA. The GWO property has been added to the momentum-based equation mentioned above to improve the FS process search capabilities. Here a novel concept convergence timer has been introduced, which can eliminate the convergence issue in the iterative algorithm if it arises. A novel GWO based levy flight update has been introduced here to produce the local optimum solution. We have evaluated our proposed method on two benchmark spam corpora (Spambase, SpamAssassin) having different significant properties. The proposed FS approach has been tested on various classification and clustering algorithms to check the robustness and how the model will behave on unknown data. After comparing multiple state-of-the-art and existing approaches, the proposed method is superior in boosting classification accuracy while minimizing the features in the feature set for misclassifying legitimate emails as spam.
C1 [Dhal, Pradip; Azad, Chandrashekhar] Natl Inst Technol, ITER, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.
   [Dhal, Pradip] Siksha O Anusandhan Deemed Be Univ, Dept Comp Sci & Engn, Bhubaneswar 751030, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur; Siksha 'O' Anusandhan University
RP Dhal, P (corresponding author), Natl Inst Technol, ITER, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.; Dhal, P (corresponding author), Siksha O Anusandhan Deemed Be Univ, Dept Comp Sci & Engn, Bhubaneswar 751030, Odisha, India.
EM pradip1780@gmail.com; csazad.cse@nitjsr.ac.in
RI Azad, Dr. Chandrashekhar/U-2277-2019; DHAL, PRADIP/GLV-1614-2022
OI Azad, Dr. Chandrashekhar/0000-0003-2101-8114; DHAL,
   PRADIP/0000-0003-2097-6601
CR Abdulhamid Shafi'i Muhammad, 2018, International Journal of Computer Network and Information Security, V10, P60, DOI 10.5815/ijcnis.2018.01.07
   Abdulwahab HA, 2019, IEEE ACCESS, V7, P142085, DOI 10.1109/ACCESS.2019.2937021
   Agrahari S, 2022, ARAB J SCI ENG, V47, P10605, DOI 10.1007/s13369-022-06653-4
   Al-Rawashdeh G, 2019, IEEE ACCESS, V7, P143721, DOI 10.1109/ACCESS.2019.2944089
   Amjad S, 2019, A novel hybrid approach for email spam detection based on scatter search algorithm and k-nearest neighbors
   Aslam N, 2022, J VIS COMMUN IMAGE R, V87, DOI 10.1016/j.jvcir.2022.103598
   Aslam N, 2022, MULTIMED TOOLS APPL, V81, P42457, DOI 10.1007/s11042-022-13496-6
   Aslantas P, 2020, J Soft Comput Data Mining, P44, DOI [10.30880/jscdm.2020.01.02.005, DOI 10.30880/JSCDM.2020.01.02.005]
   Awad W. A., 2011, International Journal of Computer Science & Information Technology, V3, P173, DOI 10.5121/ijcsit.2011.3112
   Bahassine S, 2020, J KING SAUD UNIV-COM, V32, P225, DOI 10.1016/j.jksuci.2018.05.010
   Chikh R, 2019, J AMB INTEL HUM COMP, V10, P143, DOI 10.1007/s12652-017-0621-2
   Dada EG, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e01802
   Davino D, 2021, Spam Detection by Machine Learning-Based Content Analysis, P415, DOI [10.1007/978-981-15-5093-5_37, DOI 10.1007/978-981-15-5093-5_37]
   Dhal Pradip, 2023, Journal of Ambient Intelligence and Humanized Computing, P12345, DOI 10.1007/s12652-022-04335-5
   Dinkar SK, 2018, J COMPUT SCI-NETH, V29, P119, DOI 10.1016/j.jocs.2018.10.002
   Dorigo M., 1997, IEEE Transactions on Evolutionary Computation, V1, P53, DOI 10.1109/4235.585892
   Ebadati OME, 2019, J INF KNOWL MANAG, V18, DOI 10.1142/S0219649219500084
   ElGayyar M, 2018, ADV INTELL SYST COMP, V723, P3, DOI 10.1007/978-3-319-74690-6_1
   Elssied N. O. F., 2014, Research Journal of Applied Sciences, Engineering and Technology, V7, P625, DOI [10.19026/rjaset.7.299, DOI 10.19026/RJASET.7.299]
   Fagbola T., 2012, Comput. Eng. Intelli. Syst, V3, P17
   Faris H., 2015, 2015 IEEE JORD C APP, P1, DOI DOI 10.1109/AEECT.2015.7360576
   Faris H, 2019, INFORM FUSION, V48, P67, DOI 10.1016/j.inffus.2018.08.002
   Faris H, 2016, LECT NOTES ARTIF INT, V9875, P498, DOI 10.1007/978-3-319-45243-2_46
   Feng GZ, 2012, INFORM PROCESS MANAG, V48, P283, DOI 10.1016/j.ipm.2011.08.002
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Ghaleb SAA, 2022, IEEE ACCESS, V10, P98475, DOI 10.1109/ACCESS.2022.3204593
   Ghaleb SAA, 2021, IEEE ACCESS, V9, P116768, DOI 10.1109/ACCESS.2021.3105914
   Gibson S, 2020, IEEE ACCESS, V8, P187914, DOI 10.1109/ACCESS.2020.3030751
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Huang XW, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/3235720
   Idris I, 2015, ENG APPL ARTIF INTEL, V39, P33, DOI 10.1016/j.engappai.2014.11.001
   Idris I, 2014, APPL SOFT COMPUT, V22, P11, DOI 10.1016/j.asoc.2014.05.002
   Idris I, 2014, ENG APPL ARTIF INTEL, V28, P97, DOI 10.1016/j.engappai.2013.12.001
   Igawa K, 2009, APPL SOFT COMPUT, V9, P431, DOI 10.1016/j.asoc.2008.05.003
   Islam MR, 2005, Spam filtering using ml algorithms
   Jensi R, 2016, APPL SOFT COMPUT, V43, P248, DOI 10.1016/j.asoc.2016.02.018
   Kabir MM, 2011, NEUROCOMPUTING, V74, P2914, DOI 10.1016/j.neucom.2011.03.034
   Kamalova A, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142931
   Karaboga D., 2005, IDEA BASED HONEY BEE
   Karim A, 2019, IEEE ACCESS, V7, P168261, DOI 10.1109/ACCESS.2019.2954791
   Kashef S, 2015, NEUROCOMPUTING, V147, P271, DOI 10.1016/j.neucom.2014.06.067
   Kaya Y, 2016, SECUR COMMUN NETW, V9, P1216, DOI 10.1002/sec.1412
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li Y, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070925
   Liu F, 2020, IEEE ACCESS, V8, P4244, DOI 10.1109/ACCESS.2019.2963084
   Liu H., 1998, FEATURE SELECTION KN, DOI [DOI 10.1007/978-1-4615-5689-3, 10.1007/978-1-4615-5689-3]
   Liu M, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105954
   Lopes C, 2011, EXPERT SYST APPL, V38, P9365, DOI 10.1016/j.eswa.2011.01.174
   Ma XX, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/3847951
   MANTEGNA RN, 1994, PHYS REV E, V49, P4677, DOI 10.1103/PhysRevE.49.4677
   Marie-Sainte SL, 2020, J KING SAUD UNIV-COM, V32, P320, DOI 10.1016/j.jksuci.2018.06.004
   Mashaleh A. S., 2022, Procedia Computer Science, V201, P659, DOI [10.1016/j.procs.2022.03.087, DOI 10.1016/J.PROCS.2022.03.087]
   Mirjalili S, 2016, EXPERT SYST APPL, V47, P106, DOI 10.1016/j.eswa.2015.10.039
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mitchell M., 1999, INTRO GENETIC ALGORI, DOI DOI 10.1016/S0898-1221(96)90227-8
   Nakamura RYM, 2013, ELSEV INSIGHT, P225, DOI 10.1016/B978-0-12-405163-8.00009-0
   Mohammad R.M.A., 2020, IAENG Int. J. Comput. Sci., V47, P187
   Mohammadzadeh H, 2021, COMPUT INTELL-US, V37, P176, DOI 10.1111/coin.12397
   Niu T, 2018, RENEW ENERG, V118, P213, DOI 10.1016/j.renene.2017.10.075
   Olatunji SO, 2019, NEURAL COMPUT APPL, V31, P691, DOI 10.1007/s00521-017-3100-y
   Oludare O., 2014, Int J Sci Technol Res, V3, P7
   Ozkan H, 2022, Analysis of adversarial attacks against traditional spam filters
   Pare S, 2018, COMPUT ELECTR ENG, V70, P476, DOI 10.1016/j.compeleceng.2017.08.008
   Pramanik R, 2023, EXPERT SYST APPL, V219, DOI 10.1016/j.eswa.2023.119643
   Rafat KF, 2022, MATH BIOSCI ENG, V19, P1926, DOI 10.3934/mbe.2022091
   Rocca P, 2011, IEEE ANTENN PROPAG M, V53, P38, DOI 10.1109/MAP.2011.5773566
   Rodrigues D, 2014, EXPERT SYST APPL, V41, P2250, DOI 10.1016/j.eswa.2013.09.023
   Sahoo A, 2017, APPL SOFT COMPUT, V52, P64, DOI 10.1016/j.asoc.2016.12.022
   Saji Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114639
   Shahin I, 2023, APPL ACOUST, V205, DOI 10.1016/j.apacoust.2023.109279
   Shan X, 2016, SCI PROGRAMMING-NETH, V2016, DOI 10.1155/2016/8031560
   Shuaib M, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0394-7
   Singh Narinder, 2017, Journal of Applied Mathematics, V2017, DOI 10.1155/2017/2030489
   SoleimanianGharehchopogh F, 2019, A new feature selection in email spam detection by particle swarm optimization and fruit fly optimization algorithms, P2, DOI [10.22067/cke.v2i2.81750, DOI 10.22067/CKE.V2I2.81750]
   Tang XC, 2019, EXPERT SYST APPL, V120, P207, DOI 10.1016/j.eswa.2018.11.018
   Taylor O., 2020, Int J Comput Sci Math Theo, V6, P1
   Verma AK, 2020, INT J MACH LEARN CYB, V11, P2439, DOI 10.1007/s13042-020-01128-0
   Vidyadhari C, 2020, INT J MODEL SIMUL SC, V11, DOI 10.1142/S1793962320500324
   Wang SG, 2011, EXPERT SYST APPL, V38, P8696, DOI 10.1016/j.eswa.2011.01.077
   Xie XJ, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104938
   Yang X-S, 2021, NATURE INSPIRED OPTI, P123, DOI [10.1016/B978-0-12-821986-7.00016-0, DOI 10.1016/B978-0-12-821986-7.00016-0]
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Zamir A, 2020, ELECTRON LIBR, V38, P633, DOI 10.1108/EL-07-2019-0181
NR 83
TC 3
Z9 3
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26929
EP 26969
DI 10.1007/s11042-023-16448-w
EA SEP 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059026300010
DA 2024-07-18
ER

PT J
AU Lian, SY
   Guan, LX
   Pei, JH
   Zeng, G
   Li, MS
AF Lian, Suyun
   Guan, Lixin
   Pei, Jihong
   Zeng, Gui
   Li, Mengshan
TI Identification of apple leaf diseases using C-Grabcut algorithm and
   improved transfer learning base on low shot learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apple leaf diseases; C-Grabcut; Transfer learning; Segmentation
ID CLASSIFICATION; PLANTS; YIELD
AB Plant disease control is an indispensable research topic in the field of agriculture. Different apple leaf diseases may have similar manifestations, and it is time-consuming and laborious to rely on manual means. In this paper, we propose an apple leaf disease classification algorithm for a small number of samples, which is based on the C-Grabcut image segmentation algorithm proposed in this paper and the improved EfficientNetB4 transfer learning algorithm. Firstly, data augmentation is used to expand the samples, which effectively solves the problems of insufficient samples and unbalanced sample categories. Then the leaves are extracted from the images using the C-Grabcut algorithm to reduce the interference brought by the background. Finally, the improved Vgg16, ResNet50, EfficientNetB0, EfficientNetB4 and EfficientNetB7 transfer learning algorithms are used to classify leaves into four categories: rust, scab, multiply and healthy. The experimental results show that the improved EfficientB4 algorithm works best with an average accuracy of 98% and the Kappa value of 0.98. In addition, the C-Grabcut algorithm reduces the training time from 153 to 73 s during an epoch, allowing the proposed algorithms to be deployed on devices with lower computing power and memory.
C1 [Lian, Suyun; Guan, Lixin; Zeng, Gui; Li, Mengshan] Gannan Normal Univ, Sch Phys & Elect Informat, Ganzhou 341000, Peoples R China.
   [Lian, Suyun; Pei, Jihong] Shenzhen Univ, Elect Engn Dept, CIE, Shenzhen 518000, Peoples R China.
C3 Gannan Normal University; Shenzhen University
RP Guan, LX (corresponding author), Gannan Normal Univ, Sch Phys & Elect Informat, Ganzhou 341000, Peoples R China.
EM lxguan@gnnu.edu.cn
RI wei, wang/KHY-7669-2024; Sun, Yuchen/JZD-1692-2024
OI lian, suyun/0000-0002-4455-3227
FU National Natural Science Foundation of China [42061067, 52063002];
   Science and technology projects of Jiangxi Provincial Department of
   Education [190745]
FX This work was supported in part by the National Natural Science
   Foundation of China [grant numbers 42061067, 52063002]; the~Science and
   technology projects of Jiangxi Provincial Department of Education [grant
   numbers 190745].
CR Bhange M, 2015, PROCEDIA COMPUT SCI, V58, P280, DOI 10.1016/j.procs.2015.08.022
   Braunack MV, 2012, SOIL TILL RES, V120, P85, DOI 10.1016/j.still.2011.11.002
   Cao ZY, 2019, IEEE ACCESS, V7, P166109, DOI 10.1109/ACCESS.2019.2953465
   Chao XF, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12071065
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng MM, 2015, COMPUT GRAPH FORUM, V34, P193, DOI 10.1111/cgf.12758
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong HZ, 2006, CROP PROT, V25, P324, DOI 10.1016/j.cropro.2005.05.003
   Douillard A, 2021, PROC CVPR IEEE, P4039, DOI 10.1109/CVPR46437.2021.00403
   Fang SS, 2017, LECT NOTES COMPUT SC, V10666, P545, DOI 10.1007/978-3-319-71607-7_48
   Fu RG, 2016, IET IMAGE PROCESS, V10, P937, DOI 10.1049/iet-ipr.2016.0009
   Gao HH, 2024, IEEE T NEUR NET LEAR, V35, P4826, DOI 10.1109/TNNLS.2022.3155486
   Gregory PJ, 2009, J EXP BOT, V60, P2827, DOI 10.1093/jxb/erp080
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Jaisakthi SM, 2019, 2019 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS 2019), DOI 10.1109/iccids.2019.8862084
   Kaur P, 2017, INT J ADV APPL SCI, V4, P79, DOI 10.21833/ijaas.2017.08.012
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Kranth GPR., 2018, INT J COMPUT APPL, V18, P0975, DOI DOI 10.5120/IJCA2018918049
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Nandhini SA, 2018, WIRELESS PERS COMMUN, V102, P725, DOI 10.1007/s11277-017-5092-4
   Odegard IYR, 2014, ECOL ECON, V97, P51, DOI 10.1016/j.ecolecon.2013.10.005
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panchal SS., 2016, IJECS, V5, P16815
   PD S.A, 2019, WORLD POPULATION PRO
   Qi F, 2022, NEURAL PROCESS LETT, V54, P5317, DOI 10.1007/s11063-022-10863-0
   Rakelly K, 2018, CONDITIONAL NETWORKS
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sabrol H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1242, DOI 10.1109/ICCSP.2016.7754351
   Shrivastava VK, 2021, J PLANT PATHOL, V103, P17, DOI 10.1007/s42161-020-00683-3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang M, 2013, IEEE I CONF COMP VIS, P1769, DOI 10.1109/ICCV.2013.222
   Xiong YH, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105712
   Yan Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123535
   Zhou MM, 2019, THESIS NW A F U YANG
NR 38
TC 0
Z9 0
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27411
EP 27433
DI 10.1007/s11042-023-16602-4
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001059921400004
DA 2024-07-18
ER

PT J
AU Xiong, M
   Cao, WM
   Zhao, ZN
AF Xiong, Min
   Cao, Wenming
   Zhao, Zhineng
TI Dual-model Collaborative Learning with Knowledge Clustering for Few-shot
   Image Classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Dual-model; Correlation; GNN
ID ALGEBRA
AB Few-shot learning (FSL) refers to adapt model to novel classes with few annotations. Existing methods generally utilize a single model's information directly extracted from samples. Extra information are helpful to enhance the generation of the model. This paper focuses on designing a dual-model structure to learn the correlation between two models and introduce the center loss to cluster the same sort of samples and enhance the representation of samples. The center loss is to improve the generalization of the active branch. Moreover, we combine meta-learning. The meta-training has multiple tasks, and each task has two stages in our work, which firstly trains one model with soft labels from another fixed model and center loss. The optimal predictions of the active model are close to the soft and actual labels. Meanwhile, the same samples will gather together, attempting to minimize the intra-class differences. It could enhance the generalization and robustness of the model. We conduct experiments on miniImageNet, tieredImageNet and CUB. The results show the excellence of our proposed method.
C1 [Xiong, Min; Cao, Wenming; Zhao, Zhineng] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
   [Xiong, Min; Cao, Wenming; Zhao, Zhineng] Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.
   [Cao, Wenming] Shenzhen Univ, State Key Lab Radio Frequency Heterogeneous Integ, Shenzhen, Peoples R China.
C3 Shenzhen University; Shenzhen University; Shenzhen University
RP Cao, WM (corresponding author), Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.; Cao, WM (corresponding author), Shenzhen Univ, Shenzhen Key Lab Media Secur, Shenzhen, Peoples R China.; Cao, WM (corresponding author), Shenzhen Univ, State Key Lab Radio Frequency Heterogeneous Integ, Shenzhen, Peoples R China.
EM xiongtnin2020@email.szu.edu.cn; wmcao@szu.edu.cn;
   zhaozhinen2020@email.szu.edu.cn
RI cao, wenming/Y-5293-2019
OI cao, wenming/0000-0002-8174-6167
FU National Natural Science Foundation of China [61771322]; Fundamental
   Research Foundation of Shenzhen [JCYJ20220531100814033]
FX This work is supported by National Natural Science Foundation of China
   under grant 61771322, and the Fundamental Research Foundation of
   Shenzhen under Grant JCYJ20220531100814033.
CR Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Bateni Peyman, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14481, DOI 10.1109/CVPR42600.2020.01450
   Bhatti Uzair Aslam, 2022, Proceedings of International Conference on Information Technology and Applications: ICITA 2021. Lecture Notes in Networks and Systems (350), P75, DOI 10.1007/978-981-16-7618-5_7
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, P1
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535, DOI DOI 10.1145/1150402.1150464
   Chen CF, 2021, PROC CVPR IEEE, P6592, DOI 10.1109/CVPR46437.2021.00653
   Chen W., 2020, PROC INT C LEARN REP
   Chen Y., 2020, ARXIV200304390
   Chen Y, 2021, INT J EXTREME MANUF, V3, DOI 10.1088/2631-7990/abe0d0
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Das R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9010, DOI 10.1109/ICCV48922.2021.00890
   Finn C, 2017, PR MACH LEARN RES, V70
   Garcia V, 2017, ARXIV
   GORI M, 2005, IEEE IJCNN, P729, DOI DOI 10.1109/IJCNN.2005.1555942
   Grant E, 2018, ARXIV
   Hu S. X., 2020, ARXIV
   Jiang X., 2018, INT C LEARN REPR
   Kang D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8802, DOI 10.1109/ICCV48922.2021.00870
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar V, 2019, ARXIV
   Lee Y, 2018, PR MACH LEARN RES, V80
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Lin Y, 2022, IEEE T PATTERNA MACH
   Ling Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13387, DOI 10.1109/CVPR42600.2020.01340
   Liu G, 2021, IEEE WINT CONF APPL, P586, DOI [10.1109/WACV48630.2021.00063, 10.1109/Radar53847.2021.10027960]
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Ma J, 2021, P IEEE CVF INT C COM, P10573
   Mahajan K, 2020, IEEE COMPUT SOC CONF, P3142, DOI 10.1109/CVPRW50498.2020.00373
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Nichol A, 2018, ARXIV
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Qiushan Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11017, DOI 10.1109/CVPR42600.2020.01103
   Ravi S, 2016, PROC INT C LEARN REP
   Ren M, 2018, ARXIV
   Requeima J, 2019, ADV NEUR IN, V32
   Romero A, 2014, ARXIV
   Rusu AA, 2018, ARXIV
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tang SX, 2021, PROC CVPR IEEE, P2329, DOI 10.1109/CVPR46437.2021.00236
   Tseng H-Y, 2020, ARXIV
   Van Horn G, 2018, PROC CVPR IEEE, P8769, DOI 10.1109/CVPR.2018.00914
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang X, 2018, ADV NEUR INFORM PROC, V31
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wertheimer D, 2021, PROC CVPR IEEE, P8008, DOI 10.1109/CVPR46437.2021.00792
   Widhianingsih TDA, 2022, APPL INTELL, V52, P7037, DOI 10.1007/s10489-021-02744-1
   Wonpyo Park, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P709, DOI 10.1007/978-3-030-66415-2_49
   Wu Y, 2017, IEEE INT CONF COMP V, P1933, DOI 10.1109/ICCVW.2017.228
   Xie JT, 2022, PROC CVPR IEEE, P7962, DOI 10.1109/CVPR52688.2022.00781
   Yan XQ, 2022, INFORM SCIENCES, V593, P1, DOI 10.1016/j.ins.2022.01.065
   Yan XQ, 2020, IEEE T IND INFORM, V16, P3974, DOI 10.1109/TII.2019.2939278
   Yan XQ, 2020, INFORM FUSION, V56, P15, DOI 10.1016/j.inffus.2019.10.006
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Yoon SW, 2019, PR MACH LEARN RES, V97
   Yue Z., 2020, P 34 C NEUR INF PROC, P2734
   Zhang RX, 2018, ADV NEUR IN, V31
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhao Y, 2023, IEEE T IMAGE P
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou ZQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8382, DOI 10.1109/ICCV48922.2021.00829
   Ziko I., 2020, ICML, P11660
NR 74
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26527
EP 26546
DI 10.1007/s11042-023-16551-y
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300001
DA 2024-07-18
ER

PT J
AU Rani, KV
   Prince, ME
   Therese, PS
   Shermila, PJ
   Devi, EA
AF Rani, K. Vijila
   Prince, M. Eugine
   Therese, P. Sujatha
   Shermila, P. Josephin
   Devi, E. Anna
TI Content-based medical image retrieval using fractional Hartley transform
   with hybrid features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBMIR; MWBMMBO; Fractional Hartley Transform; Multi class SVM; Hybrid
   Feature Extraction
ID CLASSIFICATION; ALGORITHM; SELECTION
AB Content-Based Medical Image Retrieval is used to extract meaningful information from a large number of medical images. To extract image texture characteristics, a novel medical image retrieval technique is presented. Images from Computed Tomography scans are used as input images. At first, the respective image is affected by some noise disturbance. To mitigate this and to improve the contrast of the pixels in the source image, and then a fractional Hartley transform is applied to eradicate the noise variation as well as reduce the image distortion. About this, a better-filtered output is determined. Then the hybrid feature extraction technique is utilized to extract the desirable features. After this Modified Weight-Brownian Motion Monarch Butterfly Optimization approach is exploited to alleviate the unwanted features from the huge amount of features and select certain desirable features. Finally, the similarity between the selected features is measured to detect and classify the medical images. The proposed technique has been more advantageous to increase the accuracy level as well as gradually minimizing the error rate. The proposed algorithms are implemented using the image processing toolbox in MATLAB 2019 platform. The performances are analyzed by the proposed method in terms of precision (99%), recall (83%), F-measure (90%), and accuracy (98.85%).
C1 [Rani, K. Vijila] Udaya Sch Engn, Dept ECE, Nagercoil, Tamil Nadu, India.
   [Prince, M. Eugine] ST Hindu Coll, Dept Phys, Nagercoil, Tamil Nadu, India.
   [Therese, P. Sujatha] Noorul Islam Ctr Higher Educ, Dept EEE, Kumaracoil, Tamil Nadu, India.
   [Shermila, P. Josephin] RMK Coll Engn & Technol, Dept Artificial Intelligence & Data Sci, Chennai, Tamil Nadu, India.
   [Devi, E. Anna] Sathyabama Inst Sci & Technol, Dept ECE, Chennai, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology
RP Rani, KV (corresponding author), Udaya Sch Engn, Dept ECE, Nagercoil, Tamil Nadu, India.
EM vijilaranijournal@gmail.com; eugineprince2015@gmail.com;
   sujathatherese@niuniv.com; josephinshermilaads@rmkcet.ac.in;
   annadevimit@gmail.com
RI Easwaralingam, E.ANNA DEVI/AAQ-5320-2020; Therese,
   P.Sujatha/AAT-6732-2020; K, VIJILA RANI/ABI-1263-2020
OI Easwaralingam, E.ANNA DEVI/0000-0002-6049-313X; K, VIJILA
   RANI/0000-0002-5007-1507
FU Udaya School of Engineering
FX First of all, the writers are thankful for the continuing encouragement
   and support from the management of the Udaya School of Engineering for
   their study. The writers are also noting the vital role of the National
   Cancer Institute Kanyakumari and the Foundation for the National
   Institutes of Health for their critical role in the creation of the
   In-house clinical database & free, public available database used in
   this study. Finally, we want to thank the anonymous reviewers for their
   help with this article's improvement.
CR Abe S, 2010, ADV PATTERN RECOGNIT, P331, DOI 10.1007/978-1-84996-098-4_7
   Agrawal Shubham, 2022, Int J Inf Technol, V14, P3619, DOI 10.1007/s41870-022-01007-7
   Akgül CB, 2011, J DIGIT IMAGING, V24, P208, DOI 10.1007/s10278-010-9290-9
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Baig F, 2020, IJST-T ELECTR ENG, V44, P99, DOI 10.1007/s40998-019-00237-z
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bugatti PH, 2008, COMP MED SY, P272, DOI 10.1109/CBMS.2008.82
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chen YG, 2022, IEEE J BIOMED HEALTH, V26, P3342, DOI 10.1109/JBHI.2022.3157592
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Demir B, 2015, IEEE T GEOSCI REMOTE, V53, P2323, DOI 10.1109/TGRS.2014.2358804
   El-Naqa I, 2004, IEEE T MED IMAGING, V23, P1233, DOI 10.1109/TMI.2004.834601
   Feng YH, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114418
   Gali R., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P243, DOI 10.1109/CICSyN.2012.52
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Hameed IM, 2021, COGENT ENG, V8, DOI 10.1080/23311916.2021.1927469
   Haq NF, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101847
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hiremath PS., 2007, Int Confer Adv Comput Commun, DOI [10.1109/ADCOM.2007.2, DOI 10.1109/ADCOM.2007.2]
   Jeon JH, 2013, EXPERT SYST APPL, V40, P450, DOI 10.1016/j.eswa.2012.07.053
   John M, 1999, P DARPA BROADC NEWS
   Kobayashi K, 2023, Arxiv, DOI arXiv:2303.03633
   Ledwich L., 2004, AUSTR C ROB AUT, V322, P3
   Liu CH, 2019, INT SYMPOS COMPUT NE, P45, DOI 10.1109/CANDAR.2019.00014
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   Mojsilovic A, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P145, DOI 10.1109/ICIP.2002.1038925
   Mortazavi A, 2021, KNOWL-BASED SYST, V228, DOI 10.1016/j.knosys.2021.107291
   Mudigonda NR, 2001, IEEE T MED IMAGING, V20, P1215, DOI 10.1109/42.974917
   Nain K, 2020, Digital Signal Processing
   Nair LR, 2021, J AMB INTEL HUM COMP, V12, P5917, DOI 10.1007/s12652-020-02139-z
   Natsev A, 2004, IEEE T KNOWL DATA EN, V16, P301, DOI 10.1109/TKDE.2003.1262183
   Öztürk S, 2023, INFORM SCIENCES, V637, DOI 10.1016/j.ins.2023.118938
   Rani KV, 2023, MULTIMED TOOLS APPL, V82, P47477, DOI 10.1007/s11042-023-15716-z
   Rao RV, 2021, MULTIMED TOOLS APPL, V80, P11815, DOI 10.1007/s11042-020-10415-5
   Rashad M, 2023, J DIGIT IMAGING, V36, P1248, DOI 10.1007/s10278-022-00769-7
   Ribeiro MX, 2008, IEEE T MULTIMEDIA, V10, P277, DOI 10.1109/TMM.2007.911837
   Silva W, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-25027-2
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Sotomayor CG, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081470
   Syam B, 2013, INT ARAB J INF TECHN, V10, P143
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Rani KV, 2021, IETE J RES, V67, P514, DOI 10.1080/03772063.2018.1557086
   Vishraj R, 2022, COMPUT ELECTR ENG, V104, DOI 10.1016/j.compeleceng.2022.108450
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Xie WH, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/5560465
   Zhang Y, 2012, PROG ELECTROMAGN RES, V130, P369, DOI 10.2528/PIER12061410
NR 51
TC 2
Z9 2
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27217
EP 27242
DI 10.1007/s11042-023-16462-y
EA AUG 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062026900007
DA 2024-07-18
ER

PT J
AU Ghosh, D
   Chowdhury, K
   Muhuri, S
AF Ghosh, Debabrata
   Chowdhury, Kuntal
   Muhuri, Samya
TI Finding correlation between diabetic retinopathy and diabetes during
   pregnancy based on computer-aided diagnosis: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Diabetic retinopathy; Diabetes during pregnancy; Computer-aided
   diagnosis; Fundus data set; Correlation
ID MACULAR EDEMA; INFLAMMATORY MARKERS; AUTOMATIC DETECTION; DATA
   AUGMENTATION; RETINAL IMAGES; BLOOD-VESSELS; PROGRESSION;
   CLASSIFICATION; SEGMENTATION; ASSOCIATION
AB Diabetic retinopathy (DR) is a condition that damages the retina in people with diabetes and can lead to vision loss. It can be detected by observing the morphological changes in the fundus image. DR manifests in several types, including, mild non-proliferative DR (MilNPDR), moderate non-proliferative DR (ModNPDR), severe non-proliferative DR (SevNPDR), proliferative DR (PDR), and Severe proliferative DR (SPDR). Diagnosing DR manually is a time-consuming process and requires significant human resources. Computational-based diagnostic framework, on the other hand, may facilitate early detection and timely treatments. Diabetes during pregnancy can lead to a future development of DR in the mother as well as the fetus. The effect of pregnancy on DR is a significant health concern, however, it is unexplored due to the limited number of screening and treatment options. This manuscript aims to give a comprehensive review of DR and its correlation with diabetes during pregnancy. Moreover, it presents the available resources of fundus data sets for DR research and depicts the advanced methodologies for computational aided DR detection. It also highlights the research gaps in DR detection and its classification and therefore opens the possibility of future research on DR during pregnancy.
C1 [Ghosh, Debabrata] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala 147004, Punjab, India.
   [Chowdhury, Kuntal; Muhuri, Samya] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Muhuri, S (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM samya.muhuri@thapar.edu
OI Ghosh, Debabrata/0000-0002-4603-1238; MUHURI, SAMYA/0000-0003-3426-3741
CR Abbas Q, 2017, MED BIOL ENG COMPUT, V55, P1959, DOI 10.1007/s11517-017-1638-6
   Abràmoff MD, 2010, OPHTHALMOLOGY, V117, P1147, DOI 10.1016/j.ophtha.2010.03.046
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Adal KM, 2018, IEEE T BIO-MED ENG, V65, P1382, DOI 10.1109/TBME.2017.2752701
   Adzura S, 2011, INT J OPHTHALMOL-CHI, V4, P69, DOI 10.3980/j.issn.2222-3959.2011.01.16
   Afzal S, 2019, IEEE ACCESS, V7, P115528, DOI 10.1109/ACCESS.2019.2932786
   Akram MU, 2013, PATTERN RECOGN, V46, P107, DOI 10.1016/j.patcog.2012.07.002
   Alasil T, 2010, OPHTHALMOLOGY, V117, P2379, DOI 10.1016/j.ophtha.2010.03.051
   Ali-Gombe A, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851953
   Alyoubi W. L., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Amel F., 2012, INT J IMAGE GRAPH SI, V4, P19, DOI [10.5815/ijigsp.2012.04.03, DOI 10.5815/ijigsp.2012.04.03, DOI 10.5815/IJIGSP.2012.04.03]
   American Diabetes Association, 2020, Diabetes Care, V43, pS183, DOI 10.2337/dc20-S014
   Arun CS, 2008, DIABETOLOGIA, V51, P1041, DOI 10.1007/s00125-008-0994-z
   Arunkumar R, 2017, NEURAL COMPUT APPL, V28, P329, DOI 10.1007/s00521-015-2059-9
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Atwany Mohammad Z, 2022, IEEE Access
   AxerSiegel R, 1996, OPHTHALMOLOGY, V103, P1815, DOI 10.1016/S0161-6420(96)30421-1
   Bain SC, 2019, DIABETES OBES METAB, V21, P454, DOI 10.1111/dom.13538
   Bandara AMRR, 2017, P IEEE INT C IND INF, P1, DOI [10.1109/ICIINFS.2017.8300426, DOI 10.1109/ICIINFS.2017.8300426]
   Basha SS, 2008, INT J COMPUT SCI NET, V8, P211
   Behboudi-Gandevani S, 2019, DIABETOL METAB SYNDR, V11, DOI 10.1186/s13098-019-0406-1
   Bellemo V, 2019, LANCET DIGIT HEALTH, V1, pE35, DOI 10.1016/S2589-7500(19)30004-4
   Bernardes R, 2009, OPHTHALMOLOGICA, V223, P284, DOI 10.1159/000213638
   Best RM, 1999, EYE, V13, P179, DOI 10.1038/eye.1999.47
   Best RM, 1997, BRIT J OPHTHALMOL, V81, P249, DOI 10.1136/bjo.81.3.249
   Boeldt DS, 2017, J ENDOCRINOL, V232, pR27, DOI 10.1530/JOE-16-0340
   Bohman L., 2011, SURG DECISION MAKING
   BOONE MI, 1989, OPHTHALMOLOGY, V96, P251
   Bourry J, 2021, DIABETES CARE, V44, P181, DOI 10.2337/dc20-0904
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Bui T, 2017, 2017 IEEE 10TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA), P203, DOI 10.1109/IWCIA.2017.8203585
   Chakrabarty S, 2019, EUR SIGNAL PR CONF, DOI 10.23919/eusipco.2019.8903176
   Chandrasekaran PR, 2021, INDIAN J OPHTHALMOL, V69, P3015, DOI 10.4103/ijo.IJO_1377_21
   Chu AA, 2020, J OPHTHALMOL, V2020, DOI 10.1155/2020/8841927
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Das UN, 2013, NUTRITION, V29, P1, DOI 10.1016/j.nut.2012.02.003
   Davoudi S, 2016, RETINA-J RET VIT DIS, V36, P1622, DOI 10.1097/IAE.0000000000001022
   De Fauw Jeffrey, 2016, F1000Res, V5, P1573
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   DIBBLE CM, 1982, OBSTET GYNECOL, V59, P699
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Egan AM, 2015, J DIABETES RES, V2015, DOI 10.1155/2015/310239
   El Annan Jaafar, 2014, Int Ophthalmol Clin, V54, P141, DOI 10.1097/IIO.0000000000000027
   Errera MH, 2013, SURV OPHTHALMOL, V58, P127, DOI 10.1016/j.survophthal.2012.08.001
   Fan Z, 2019, IEEE T IMAGE PROCESS, V28, P2367, DOI 10.1109/TIP.2018.2885495
   Farnell DJJ, 2008, J FRANKLIN I, V345, P748, DOI 10.1016/j.jfranklin.2008.04.009
   FERRIS FL, 1984, SURV OPHTHALMOL, V28, P452, DOI 10.1016/0039-6257(84)90227-3
   Fink W, 2015, INVEST OPHTH VIS SCI, V56
   Flaxel CJ, 2010, RETINA-J RET VIT DIS, V30, P1488, DOI 10.1097/IAE.0b013e3181e7974f
   Fraz MM, 2012, IEEE T BIO-MED ENG, V59, P2538, DOI 10.1109/TBME.2012.2205687
   Ganesan K, 2014, MED BIOL ENG COMPUT, V52, P663, DOI 10.1007/s11517-014-1167-5
   Gao ZT, 2019, IEEE ACCESS, V7, P3360, DOI 10.1109/ACCESS.2018.2888639
   Gegundez-Arias ME, 2017, COMPUT BIOL MED, V88, P100, DOI 10.1016/j.compbiomed.2017.07.007
   Gouliopoulos NS, 2018, EUR REV MED PHARMACO, V22, P7113, DOI 10.26355/eurrev_201811_16243
   Govind D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67880-z
   Grossniklaus HE, 2004, AM J OPHTHALMOL, V137, P496, DOI 10.1016/j.ajo.2003.09.042
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo YF, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-0412-7
   Haddock LJ, 2013, J OPHTHALMOL, V2013, DOI 10.1155/2013/518479
   He AL, 2021, IEEE T MED IMAGING, V40, P143, DOI 10.1109/TMI.2020.3023463
   Hemanth DJ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1111-6
   Holmberg OG, 2020, NAT MACH INTELL, V2, P719, DOI 10.1038/s42256-020-00247-1
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hossain NI, 2017, INT CONF ADV ELECTR, P123, DOI 10.1109/ICAEE.2017.8255339
   Hua CH, 2019, IEEE ENG MED BIO, P36, DOI [10.1109/embc.2019.8856552, 10.1109/EMBC.2019.8856552]
   Huang S, 2022, J MED IMAG RADIAT ON, V66, P592, DOI 10.1111/1754-9485.13415
   Immonen IJ, 2004, INVEST OPHTH VIS SCI, V45, pU378
   Ioannides A, 2011, CLIN OPHTHALMOL, V5, P1431, DOI 10.2147/OPTH.S16272
   Ishtiaq U, 2020, MULTIMED TOOLS APPL, V79, P15209, DOI 10.1007/s11042-018-7044-8
   Kaggle, 2019, APTOS 2019 BLINDN DE
   Kaggle, 2015, EYEPACS 2015 DIAB RE
   Kamran SA, 2021, INT C PATT RECOG, P9122, DOI 10.1109/ICPR48806.2021.9412428
   Kamran Sharif Amit, 2021, P IEEECVF INT C COMP, P3235
   Kauppi T., 2006, Machine Vision and Pattern Recognition Research Group, V73, P1
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Khalaf Nervana, 2017, Electron Physician, V9, P5031, DOI 10.19082/5031
   Kitzmiller JL, 2008, DIABETES CARE, V31, P1060, DOI 10.2337/dc08-9020
   KLEIN BEK, 1990, DIABETES CARE, V13, P34, DOI 10.2337/diacare.13.1.34
   Krause J, 2018, OPHTHALMOLOGY, V125, P1264, DOI 10.1016/j.ophtha.2018.01.034
   Kumaran K, 2021, Proceedings of the 2021 International Symposium on Intelligent Signal Processing and Communication Systems (ISPACS), P1
   Kusakunniran W, 2018, COMPUT METH PROG BIO, V158, P173, DOI 10.1016/j.cmpb.2018.02.011
   Lauszus F, 2000, ACTA OBSTET GYN SCAN, V79, P367, DOI 10.1034/j.1600-0412.2000.079005367.x
   Lee J, 2022, PROC SPIE, V12102, DOI 10.1117/12.2632901
   Leopold HA, 2019, J IMAGING, V5, DOI 10.3390/jimaging5020026
   Levin AV, 2010, PEDIATRICS, V126, P961, DOI 10.1542/peds.2010-1220
   Li LJ, 2017, BMC OPHTHALMOL, V17, DOI 10.1186/s12886-016-0398-7
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li XM, 2020, IEEE T MED IMAGING, V39, P1483, DOI 10.1109/TMI.2019.2951844
   Li XC, 2019, NEUROCOMPUTING, V369, P134, DOI 10.1016/j.neucom.2019.08.079
   Li Zhijian, 2012, Conn Med, V76, P85
   Lin JK, 2021, IEEE SIGNAL PROC LET, V28, P454, DOI 10.1109/LSP.2021.3057548
   Liu YP, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.002
   Lord RK, 2010, OPHTHALMOLOGY, V117, P1274, DOI 10.1016/j.ophtha.2010.01.001
   Loukovaara S, 2003, DIABETES CARE, V26, P1193, DOI 10.2337/diacare.26.4.1193
   Loukovaara S, 2005, EYE, V19, P422, DOI 10.1038/sj.eye.6701499
   Loukovaara S, 2007, ACTA OPHTHALMOL SCAN, V85, P46, DOI 10.1111/j.1600-0420.2006.00766.x
   Lu CD, 2014, BIOMED OPT EXPRESS, V5, P293, DOI 10.1364/BOE.5.000293
   Luo YG, 2020, IEEE ACCESS, V8, P92352, DOI 10.1109/ACCESS.2020.2994047
   Makwana T, 2018, INDIAN J OPHTHALMOL, V66, P541, DOI 10.4103/ijo.IJO_1062_17
   Mallika Ps, 2010, Malays Fam Physician, V5, P2
   Mane Vijay M., 2015, 2015 IEEE International Advanced Computing Conference (IACC). Proceedings, P56, DOI 10.1109/IADCC.2015.7154668
   Micheletti J Morgan, 2016, J Diabetes Sci Technol, V10, P295, DOI 10.1177/1932296816629158
   Mo J, 2017, INT J COMPUT ASS RAD, V12, P2181, DOI 10.1007/s11548-017-1619-0
   Morrison JL, 2016, CLIN EXP OPHTHALMOL, V44, P321, DOI 10.1111/ceo.12760
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Nijalingappa P, 2015, PROCEEDINGS OF THE 2015 INTERNATIONAL CONFERENCE ON APPLIED AND THEORETICAL COMPUTING AND COMMUNICATION TECHNOLOGY (ICATCCT), P653, DOI 10.1109/ICATCCT.2015.7456965
   Oke JL, 2016, DIABETIC MED, V33, P896, DOI 10.1111/dme.13053
   Pao SI, 2020, J OPHTHALMOL, V2020, DOI 10.1155/2020/9139713
   Papadopoulos A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93632-8
   Pappot N, 2022, DIABETIC MED, V39, DOI 10.1111/dme.14819
   Pasquel FJ., 2015, J DIABETES SCI TECHN, V10, P301, DOI [DOI 10.1177/1932296815624109, 10.1177/1932296815624109]
   Patterson C etal, 2013, SAHMRI
   Patwari MB, 2016, IEEES INT C CONVERGE, P1
   Prentasic P, 2014, IEEE ENG MED BIO, P138, DOI 10.1109/EMBC.2014.6943548
   Prentasic P, 2013, INT SYMP IMAGE SIG, P711
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Raman P., 2018, Journal of Clinical Gynecology and Obstetrics, V7, P72, DOI DOI 10.14740/JCGO487W
   Ramos JMA, 2022, ARXIV
   Rasmussen KL, 2010, DIABETOLOGIA, V53, P1076, DOI 10.1007/s00125-010-1697-9
   Referral system for hard exudates in eye fundus, 2015, COMPUT BIOL MED, V64, P217
   Rochac JFR, 2019, INT CONF INFO SCI, P362, DOI 10.1109/icist.2019.8836913
   ROSENN B, 1992, AM J OBSTET GYNECOL, V166, P1214, DOI 10.1016/S0002-9378(11)90608-5
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Sixt L, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00066
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Srinivasan V, 2021, ARXIV
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Sugimoto M, 2022, J CLIN MED, V11, DOI 10.3390/jcm11010165
   Sun R, 2021, PROC CVPR IEEE, P10933, DOI 10.1109/CVPR46437.2021.01079
   Sun YL, 2019, IEEE ACCESS, V7, P69657, DOI 10.1109/ACCESS.2019.2916922
   Taherkhani A, 2020, NEUROCOMPUTING, V404, P351, DOI 10.1016/j.neucom.2020.03.064
   Takahashi H, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0179790
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Temple RC, 2001, DIABETIC MED, V18, P573, DOI 10.1046/j.1464-5491.2001.00535.x
   Ting DSW, 2017, JAMA-J AM MED ASSOC, V318, P2211, DOI 10.1001/jama.2017.18152
   Tjandrasa H, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2013), P376, DOI 10.1109/ICCSCE.2013.6719993
   Tranos PG, 2004, SURV OPHTHALMOL, V49, P470, DOI 10.1016/j.survophthal.2004.06.002
   Tymchenko B, 2020, ARXIV
   Vestgaard M, 2010, DIABETIC MED, V27, P431, DOI 10.1111/j.1464-5491.2010.02958.x
   Wang YL, 2021, DIABETES-METAB RES, V37, DOI 10.1002/dmrr.3445
   Wilkinson CP, 2003, OPHTHALMOLOGY, V110, P1677, DOI 10.1016/S0161-6420(03)00475-5
   Wu JF, 2021, MED PHYS, V48, P7850, DOI 10.1002/mp.15312
   Wu L, 2013, WORLD J DIABETES, V4, P290, DOI 10.4239/wjd.v4.i6.290
   Xiaotong Li, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092112
   Yu S, 2021, LECT NOTES COMPUT SC, V12908, P45, DOI 10.1007/978-3-030-87237-3_5
   Yu SX, 2021, MATH BIOSCI ENG, V18, P1740, DOI 10.3934/mbe.2021090
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zeghlache R, 2022, ARXIV
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhang W, 2019, KNOWL-BASED SYST, V175, P12, DOI 10.1016/j.knosys.2019.03.016
   Zhang XH, 2005, IEEE IJCNN, P2435
   Zhou Y, 2019, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2019.00218
NR 154
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 27037
EP 27065
DI 10.1007/s11042-023-16449-9
EA AUG 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001064537600003
DA 2024-07-18
ER

PT J
AU Benkrama, A
   Mokhtari, B
   Melkemi, KE
   Foufou, S
   Boudraa, O
   Michelucci, D
AF Benkrama, Abdelhakim
   Mokhtari, Bilal
   Melkemi, Kamal Eddine
   Foufou, Sebti
   Boudraa, Omar
   Michelucci, Dominique
TI QPert: Query Perturbation to improve shape retrieval algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D shape retrieval; Shape descriptors; Shapes dissimilarity measures;
   Perturbation; Noise-enhanced shape retrieval; Genetic algorithms;
   Multiagent system
ID OF-THE-ART; MULTIAGENT SYSTEMS; GENETIC ALGORITHMS; DESCRIPTOR; FUSION;
   FRAMEWORK
AB Although there is a wide range of shape descriptors available in the literature, most of them are restricted to a specific class of shapes and no one can achieve satisfactory shape retrieval results when used with different classes of shapes. Introducing new descriptors, improving, or merging existing descriptors are potential strategies for enhancing shape retrieval algorithms. In this paper, we propose a Query Perturbation-based (QPert) method for shape retrieval. QPert perturbs the query shape to create copies or clones that are closer than the query itself to the database shapes. Clones are created by adding a small noise to the coordinates of a randomly selected subset of mesh vertices or applying genetic operators between existing clones. A Genetic Algorithm (GA) gradually develops a population of clones so that the fittest clones get closer and closer to their most similar shapes in the database. The GA is implemented as a multiagent system (MAS) that enables any number of shape descriptors, classical or modern, to cooperate without the need for synchronization or direct communication between agents. Experimental results and comparisons demonstrate the advantages of this approach, regardless of the shape descriptors used.
C1 [Benkrama, Abdelhakim; Melkemi, Kamal Eddine] Univ Batna 2, Dept informat, 53 Route Constantine, Batna 05078, Algeria.
   [Mokhtari, Bilal] Biskra Univ, Comp Sci Dept, BP 145 RP, Biskra 07000, Algeria.
   [Foufou, Sebti] Univ Sharjah, Comp Sci Dept, Sharjah, U Arab Emirates.
   [Foufou, Sebti] Univ Bourgogne, ICB UMR 6303, F-21000 Dijon, France.
   [Boudraa, Omar] Ecole Super Informat, Esi, Algiers 16309, Algeria.
   [Michelucci, Dominique] Univ Bourgogne, LIB, Lab Informat Bourgogne, F-21000 Dijon, France.
C3 University of Batna 2; Universite Mohamed Khider Biskra; University of
   Sharjah; Centre National de la Recherche Scientifique (CNRS); CNRS -
   Institute of Physics (INP); Universite de Bourgogne; Universite de
   Technologie de Belfort-Montbeliard (UTBM); Universite de Bourgogne
RP Mokhtari, B (corresponding author), Biskra Univ, Comp Sci Dept, BP 145 RP, Biskra 07000, Algeria.
EM bilal.mokhtari@univ-biskra.dz
CR Akgul CB, 2008, P 1 EUR C 3D OBJ RET, P41
   Aparna K., 2013, INT J ENG RES APPL I, V3, P1486
   Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P271
   Audhkhasi K, 2016, NEURAL NETWORKS, V78, P15, DOI 10.1016/j.neunet.2015.09.014
   Belongie S, 2001, ADV NEUR IN, V13, P831
   Berg M., 2008, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-3-540-77974-2
   Biasotti S, 2012, SHREC 12 TRACK STABI, P101
   Bickel S, 2023, COMPUT AIDED DESIGN, V154, DOI 10.1016/j.cad.2022.103417
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Bu SH, 2017, NEUROCOMPUTING, V259, P183, DOI 10.1016/j.neucom.2016.06.088
   Burmeister B., 1997, IEE Proceedings-Software Engineering, V144, P51, DOI 10.1049/ip-sen:19971023
   Busoniu L, 2008, IEEE T SYST MAN CY C, V38, P156, DOI 10.1109/TSMCC.2007.913919
   Cantu-Paz E., 1992, Calc. Paralleles, V10, P141
   Chahooki MAZ, 2012, IET IMAGE PROCESS, V6, P327, DOI 10.1049/iet-ipr.2010.0548
   Chapeau-Blondeau F, 2009, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2009/01/P01003
   Chen B, 2010, IEEE T INTELL TRANSP, V11, P485, DOI 10.1109/TITS.2010.2048313
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Daras P, 2009, INT WORK CONTENT MUL, P115, DOI 10.1109/CBMI.2009.15
   David Yuk-Ming Chan, 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P557
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Delanoue N, 2016, COMPUT OPTIM APPL, V63, P855, DOI 10.1007/s10589-015-9794-9
   Dorri A, 2018, IEEE ACCESS, V6, P28573, DOI 10.1109/ACCESS.2018.2831228
   EMIRIS IZ, 1995, SIAM J COMPUT, V24, P650, DOI 10.1137/S0097539792235918
   Fan WG, 2004, INFORM PROCESS MANAG, V40, P587, DOI 10.1016/j.ipm.2003.08.001
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Ferber J, 1999, Multi-agent systems: An introduction to distributed artificial intelligence, V1
   Florea AM, 1998, INTRO MULTIAGENT SYS, P1
   Gal R, 2007, IEEE T VIS COMPUT GR, V13, P261, DOI 10.1109/TVCG.2007.45
   Goldber D. E., 1988, Machine Learning, V3, P95, DOI 10.1023/A:1022602019183
   Goodfellow I. J., 2014, ARXIV
   Gordon VS, 1992, DATAFLOW PARALLELISM
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Jayanti S, 2006, COMPUT AIDED DESIGN, V38, P939, DOI 10.1016/j.cad.2006.06.007
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Koutaki G, 2022, INT J COMPUT VISION, V130, P2286, DOI 10.1007/s11263-022-01630-8
   LAMPORT L, 1982, ACM T PROGR LANG SYS, V4, P382, DOI 10.1145/357172.357176
   Lardeux F, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108000
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Levine D., 1996, ANL9518, V9700, P8703941
   Lew M, 2001, PRINCIPLES VISUAL IN, V1, P356
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li B, 2014, MULTIMED TOOLS APPL, V72, P1531, DOI 10.1007/s11042-013-1464-2
   Li Bo., 2012, Proceedings of EuroGraphics 3DOR, P119, DOI 10.2312/3DOR/3DOR12/119-126
   Lin S.C., 1994, 6 IEEE SPDP, P28, DOI DOI 10.1109/SPDP.1994.346184
   Ling HB, 2005, PROC CVPR IEEE, P719
   Liu ZH, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108774
   Luciano L, 2019, COMPUT GRAPH-UK, V79, P14, DOI 10.1016/j.cag.2018.12.003
   Mahmoud AM, 2020, MULTIMED TOOLS APPL, V79, P20281, DOI 10.1007/s11042-020-08825-6
   McDonald K, 2005, LECT NOTES COMPUT SC, V3568, P61
   Melkemi KE, 2006, PATTERN RECOGN LETT, V27, P1230, DOI 10.1016/j.patrec.2005.07.021
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   MIRANDA V, 1994, IEEE T POWER SYST, V9, P1927, DOI 10.1109/59.331452
   Mokhtari Bilal, 2020, Mathematical Aspects of Computer and Information Sciences. 8th International Conference, MACIS 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 11989), P422, DOI 10.1007/978-3-030-43120-4_33
   Mokhtari B, 2017, PATTERN RECOGN LETT, V98, P46, DOI 10.1016/j.patrec.2017.07.012
   Murali K, 2010, AIP CONF PROC, V1339, P67, DOI 10.1063/1.3574845
   Oh KK, 2015, AUTOMATICA, V53, P424, DOI 10.1016/j.automatica.2014.10.022
   Park YS, 2009, IEEE T CONSUM ELECTR, V55, P240, DOI 10.1109/TCE.2009.4814441
   Radwan AAA, 2007, 3 INT C INT COMP INF, P83
   Romero-González C, 2022, MULTIMED TOOLS APPL, V81, P3577, DOI 10.1007/s11042-021-11586-5
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Sabater J., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P475
   Sayar A, 2015, INT J COMPUT APPL, V119
   Sayar A, 2015, FRONT INFORM TECH EL, V16, P98, DOI 10.1631/FITEE.1400165
   Shen JH, 2009, SIAM REV, V51, P567, DOI 10.1137/060653317
   Stanford Graphics Lab, 2006, STANF DIG FORMS URB
   Stanford Graphics Lab, 2003, DIG MICH PROJ ARCH 3
   Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Syam B, 2013, INT ARAB J INFORM TE, V10
   Tang J, 2004, I C CONT AUTOMAT ROB, P2286
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Thada V., 2013, Int. J. Innov. Eng. Technol, V2, P202
   Vas P., 1999, ARTIF INTELL, V45
   Veltkamp RC, 2001, ADV PTRN RECOGNIT, P87
   VIGNES J, 1993, MATH COMPUT SIMULAT, V35, P233, DOI 10.1016/0378-4754(93)90003-D
   Vranic DV, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P757
   Wang XB, 2019, GEOFLUIDS, DOI 10.1155/2019/1985216
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiang C, 2019, PROC CVPR IEEE, P9128, DOI 10.1109/CVPR.2019.00935
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Yang XW, 2008, LECT NOTES COMPUT SC, V5305, P788, DOI 10.1007/978-3-540-88693-8_58
   Zeng H, 2018, J INF PROCESS SYST, V14, P176, DOI 10.3745/JIPS.04.0058
   Zhao Y, 2022, J VIS COMMUN IMAGE R, V89, DOI 10.1016/j.jvcir.2022.103668
   Zhou CS, 2002, PHYS REV LETT, V89, DOI 10.1103/PhysRevLett.89.014101
   Zhou Y, 2019, LECT NOTES COMPUT SC, V11901, P566, DOI 10.1007/978-3-030-34120-6_46
NR 88
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25461
EP 25485
DI 10.1007/s11042-023-16376-9
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001051861800006
DA 2024-07-18
ER

PT J
AU Bhavani, KD
   Ukrit, MF
AF Bhavani, K. Durga
   Ukrit, M. Ferni
TI Design of inception with deep convolutional neural network based fall
   detection and classification model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fall detection; Computer vision; Transfer learning; Convolution neural
   network; Inception v3
AB Falling is the most serious health problem for elderly population resulting in serious injuries, if not treated quickly. As the world population gets increased, the number of serious falls and succeeding financial burdens rise accordingly. It is important to detect falls timely to initiate appropriate medical responses to decrease considerable physical, social, and financial losses. Earlier detection of fall events can helps to provide timely medical services and reduce severe injuries. Different techniques have been developed for fall detection process among elderly population. Recently, the development of Internet of Things (IoT) and artificial intelligence (AI) technologies involving deep learning (DL) and machine learning (ML) approaches can be employed in the field of healthcare for automating the diagnosis procedure of diseased and abnormal cases. This study designs a new Inception with deep convolutional neural network-based fall detection and classification (INDCNN-FDC) model. The presented INDCNN-FDC model intends to categorize the events into two class labels namely fall and not fall. To accomplish this, the INDCNN-FDC model carries out two stages of data pre-processing: Gaussian filter (GF) based image sharpening and Guided Filter (GIF) based image smoothing. In addition, the presented INDCNN-FDC model applies deep transfer learning-based Inception v3 model for generating a helpful group of feature vectors. Finally, DCNN approach receives the feature vectors as input and performs fall detection process. The experimental validation of the INDCNN-FDC approach is performed on benchmark dataset. The comparative study reported the supremacy of the INDCNN-FDC model over state-of-the-art.
C1 [Bhavani, K. Durga; Ukrit, M. Ferni] SRM Inst Sci & Technol, Dept Computat Intelligence, Chennai 603203, India.
C3 SRM Institute of Science & Technology Chennai
RP Ukrit, MF (corresponding author), SRM Inst Sci & Technol, Dept Computat Intelligence, Chennai 603203, India.
EM kb6456@srmist.edu.in; ferniukm@srmist.edu.in
CR Adhikari K, 2019, INT J COMPUT SYST EN, V13, P251
   Albatayneh O, 2020, J INFRASTRUCT SYST, V26, DOI 10.1061/(ASCE)IS.1943-555X.0000545
   Cai X, 2021, IEEE ACCESS, V9, P18318, DOI 10.1109/ACCESS.2021.3054469
   Chen WM, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12050744
   Chen Z, 2021, MED BIOL ENG COMPUT, V59, P607, DOI 10.1007/s11517-020-02312-8
   Dong N, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106311
   Espinosa R, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103520
   Han Q, 2020, IEEE ACCESS, V8, P17556, DOI 10.1109/ACCESS.2019.2962778
   Harrou F, 2019, IEEE ACCESS, V7, P114966, DOI 10.1109/ACCESS.2019.2936320
   Hemamalini V, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/5262294
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Islam MM, 2020, IEEE ACCESS, V8, P166117, DOI 10.1109/ACCESS.2020.3021943
   Jeyakumar M., 2019, SENSORS-BASEL, V19, P1306
   Karar ME, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073276
   Khraief C, 2020, MULTIMED TOOLS APPL, V79, P19537, DOI 10.1007/s11042-020-08812-x
   Li W., 2014, IEEE ACCESS, V8, P22219
   Mauldin TR, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103363
   Mehta S, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P1293, DOI [10.1109/ICCS45141.2019.9065537, 10.1109/iccs45141.2019.9065537]
   Mubashir M., 2018, APPL SCI, V8, P1415
   Musci M, 2021, IEEE T EMERG TOP COM, V9, P1276, DOI 10.1109/TETC.2020.3027454
   Nogas J, 2020, J HEALTHC INFORM RES, V4, P50, DOI 10.1007/s41666-019-00061-4
   Ramachandran A, 2020, BIOMED RES INT-UK, V2020, DOI 10.1155/2020/2167160
   Ren L, 2021, INFRARED PHYS TECHN, V114, DOI 10.1016/j.infrared.2021.103662
   Sangeethaa SN, 2023, BIOMED SIGNAL PROCES, V81, DOI 10.1016/j.bspc.2022.104347
   Santos GL, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071644
   Sarabia-Jácome D, 2020, INTERNET THINGS-NETH, V11, DOI 10.1016/j.iot.2020.100185
   Sengül G, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103242
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sultana A, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23030328
   Szczesny K., 2019, ELECTRONICS, V8, P574
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tanwar R, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10010172
   Thakur N, 2021, J SENS ACTUAT NETW, V10, DOI 10.3390/jsan10030039
   Tsai TH, 2019, IEEE ACCESS, V7, P153049, DOI 10.1109/ACCESS.2019.2947518
   Vaiyapuri T, 2021, IEEE ACCESS, V9, P113879, DOI 10.1109/ACCESS.2021.3094243
   Waheed M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062006
   Wang XY, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00071
   Wu J, 2018, IN 2018 IEEE INT C M, P1
   Wu XD, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103355
   Xin MY, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0417-8
   Yacchirema D, 2019, PERS UBIQUIT COMPUT, V23, P801, DOI 10.1007/s00779-018-01196-8
   Yadav SS, 2019, J BIG DATA-GER, V6, DOI [10.12921/jas.v6i1.14911, 10.1186/s40537-019-0276-2]
   Zeng Y., 2020, IEEE ACCESS, V8, P24429
NR 43
TC 1
Z9 1
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 18
PY 2023
DI 10.1007/s11042-023-16476-6
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P4RX5
UT WOS:001050545900001
DA 2024-07-18
ER

PT J
AU Idrissi, N
   Zellou, A
   Bakkoury, Z
AF Idrissi, Nouhaila
   Zellou, Ahmed
   Bakkoury, Zohra
TI KFDBN: Kernelized Finetuned Deep Belief Network for recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recommender systems; Collaborative filtering; Sparsity; Deep Belief
   Network; Kernel methods; Matrix factorization
ID MATRIX FACTORIZATION
AB In today's technologically evolved world, users have become accustomed to personalized tools that provide accurate and precise recommendations that consider their needs and interests, leading to a perceived reduction in information overload in a fiercely competitive marketplace. However, sparsity issues render the effective prediction infeasible and hamper the performance of the recommendation, as users typically only rate a small proportion of the offered items. To solve these problems, we propose, in this paper, a novel hybrid model named Kernelized Finetuned Deep Belief Network (KFDBN) for accurate rating prediction and efficient Top-k recommendation. First, we learn a deep generative model using a Deep Belief Network (DBN) to capture higher-level latent feature representations of users and items to effectively predict missing entries in the rating matrix. Next, we present the practical KFDBN approach to seamlessly incorporate features extracted by the generative model into kernel-based feature extraction. Subsequently, KFDBN is leveraged to learn reliable hidden features that improve the performance of sparse recommendations. Finally, we introduce the KFDBN-based imputation technique to create a denser user-item interaction matrix for a relevant item ranking in the Top-k recommendation. Experimental evaluations on six datasets in various domains reveal that the proposed generative model enhances the accuracy of rating prediction and outperforms the state-of-the-art methods by 21.32% and 16.35% in RMSE and MAE, respectively, averaging on all used datasets. Moreover, the KFDBN exceeds baseline approaches and enhances the Top-k recommendation performance by 5.2% and 8.1% in HR@10 and NDCG@10, respectively, averaging on the six datasets.
C1 [Idrissi, Nouhaila; Bakkoury, Zohra] Mohammed V Univ, AMIPS Res Team, EMI, Rabat, Morocco.
   [Zellou, Ahmed] Mohammed V Univ, SPM Res Team, ENSIAS, Rabat, Morocco.
C3 Mohammed V University in Rabat; Mohammed V University in Rabat
RP Idrissi, N (corresponding author), Mohammed V Univ, AMIPS Res Team, EMI, Rabat, Morocco.
EM nouhaila_idrissi@um5.ac.ma; ahmed.zellou@um5.ac.ma; z.bakoury@um5.ac.ma
RI Idrissi, Nouhaila/AAQ-1364-2020
OI Idrissi, Nouhaila/0000-0003-4449-7381
CR Ahmadian S, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115849
   Amari S, 1997, IEEE T NEURAL NETWOR, V8, P985, DOI 10.1109/72.623200
   [Anonymous], 2003, NEURAL COMPUT, DOI DOI 10.1111/J.1945-1474.2005.TB00541.X
   Bathla G, 2020, MULTIMED TOOLS APPL, V79, P20845, DOI 10.1007/s11042-020-08932-4
   Bell RobertM., 2010, Chance, V23, P24, DOI [DOI 10.1080/09332480.2010.10739787, 10.1080/09332480.2010.10739787]
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Chae DK, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2616, DOI 10.1145/3308558.3313413
   Chen ZL, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114436
   Deng ZH, 2019, AAAI CONF ARTIF INTE, P61
   Ding R, 2020, PROCEEDINGS OF THE 2020 SIAM INTERNATIONAL CONFERENCE ON DATA MINING (SDM), P82, DOI 10.1137/1.9781611976236.10
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Hernando A, 2016, KNOWL-BASED SYST, V97, P188, DOI 10.1016/j.knosys.2015.12.018
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huang JD, 2022, ENG COMPUT-GERMANY, V38, P3151, DOI 10.1007/s00366-021-01305-x
   Idrissi N, 2019, P 2019 11 INT C INFO, P10, DOI [10.1145/3373744.3373746, DOI 10.1145/3373744.3373746]
   Idrissi N, 2019, INT C SMART APPL COM, P1, DOI [10.1109/SmartNets48225.2019.9069801, DOI 10.1109/SMARTNETS48225.2019.9069801]
   Idrissi N, 2019, 2019 1 INT C SMART S, P1, DOI [10.1109/ICSSD47982.2019.9003149, DOI 10.1109/ICSSD47982.2019.9003149]
   Idrissi N, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-0626-2
   Iqbal M, 2019, IEEE ACCESS, V7, P24719, DOI 10.1109/ACCESS.2019.2897003
   Katarya R, 2020, MULTIMED TOOLS APPL, V79, P35927, DOI 10.1007/s11042-020-09199-5
   Khan ZY, 2021, ARTIF INTELL REV, V54, P95, DOI 10.1007/s10462-020-09892-9
   Kiran R, 2020, EXPERT SYST APPL, V144, DOI 10.1016/j.eswa.2019.113054
   Knerr S., 1990, Neurocomputing, Algorithms, Architectures and Applications. Proceedings of the NATO Advanced Research Workshop, P41
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Kumar SG, 2022, MULTIMED TOOLS APPL, V81, P9091, DOI 10.1007/s11042-021-11452-4
   Liu JX, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105255
   Lu SY, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/8314105
   Manogaran G, 2018, MULTIMED TOOLS APPL, V77, P4379, DOI 10.1007/s11042-017-5515-y
   Mohammadpour T., 2023, INT J NONLINEAR ANAL, V14, P785
   Ravanifard R, 2021, APPL INTELL, V51, P3353, DOI 10.1007/s10489-020-01945-4
   Rendle S., 2009, P 25 C UNCERTAINTY A, P452
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sharaf M, 2022, MULTIMED TOOLS APPL, V81, P16761, DOI 10.1007/s11042-022-12564-1
   Tahmasbi H, 2021, J AMB INTEL HUM COMP, V12, P9693, DOI 10.1007/s12652-020-02714-4
   Tosh Christopher, 2021, Algorithmic Learning Theory, P1179
   Verma S, 2021, IEEE ACCESS, V9, P57757, DOI 10.1109/ACCESS.2021.3070634
   Wang JY, 2020, INT J COMPUT SCI MAT, V12, P1
   Wang X, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P165, DOI 10.1145/3331184.3331267
   Wang ZM, 2021, NEUROCOMPUTING, V425, P181, DOI 10.1016/j.neucom.2020.04.033
   Wen XL, 2021, SOFT COMPUT, V25, P3087, DOI 10.1007/s00500-020-05364-y
   Wilson AG, 2016, JMLR WORKSH CONF PRO, V51, P370
   Xiwei Wang, 2012, Proceedings of the World Congress on Engineering (WCE 2012), P377
   Xue HJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3203
   Yaxiong Wu, 2020, ICTIR '20. Proceedings of the 2020 SIGIR on International Conference on Theory of Information Retrieval, P89, DOI 10.1145/3409256.3409835
   Zhang HY, 2021, IEEE ACCESS, V9, P65266, DOI 10.1109/ACCESS.2021.3074365
NR 48
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-15208-0
EA AUG 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600012
DA 2024-07-18
ER

PT J
AU Das, R
   Singh, TD
AF Das, Ringki
   Singh, Thoudam Doren
TI A hybrid fusion-based machine learning framework to improve sentiment
   prediction of assamese in low resource setting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentiment analysis; Low resource assamese language; Machine learning
   classifier; Feature-level fusion; Decision-level fusion
AB In recent times, sentiment analysis works are dedicated to unimodal data and less effort has been paid to multimodal data. Due to the growth of multimedia, multimodal sentiment analysis is growing as one of the forefront research areas in natural language processing. However, the presence of multimodal information helps us to get a clearer understanding of the sentiment. However, multimodal sentiment analysis in a low-resource setting is yet to be explored for several resource-poor languages like Assamese. In this paper, we propose a hybrid fusion-based multimodal sentiment analysis framework for the Assamese news domain. We concentrate on the lexical features and the specific image objects to develop two individual semantic and visual models and predict the sentiment separately. Next, we combine the image and the text features by employing feature-level fusion to introduce a multimodal for joint sentiment classification. Finally, a decision/late fusion scheme is applied to three models, i.e., textual, visual, and multimodal systems, for final sentiment prediction. The hybrid fusion multimodal framework improves sentiment prediction performance over a single modality and feature-level multimodality of the Assamese news domain.
C1 [Das, Ringki; Singh, Thoudam Doren] Natl Inst Technol Silchar, Comp Sci & Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Das, R (corresponding author), Natl Inst Technol Silchar, Comp Sci & Engn, Silchar 788010, Assam, India.
EM ringkidas@gmail.com; thoudam.doren@gmail.com
CR [Anonymous], 2017, P INT SYST DES APPL
   [Anonymous], 2015, P 2015 C EMP METH NA, DOI [10.18653/v1/d15-1303, 10.18653/v1/D15-1303]
   Baroi S J, 2020, NITS HINGLISH SENTIM
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Cambria E, 2018, LECT NOTES COMPUT SC, V10762, P166, DOI 10.1007/978-3-319-77116-8_13
   Campos V, 2017, IMAGE VISION COMPUT, V65, P15, DOI 10.1016/j.imavis.2017.01.011
   Cao DL, 2016, MULTIMED TOOLS APPL, V75, P8955, DOI 10.1007/s11042-014-2337-z
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen XY, 2017, IEEE IMAGE PROC, P1557, DOI 10.1109/ICIP.2017.8296543
   Das A., 2010, Int. J. Comput. Linguistics Appl., V1, P169
   Das A., 2010, INT C COMP PROC OR L, P169
   Das Ringki, 2021, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2020, NEHU. Lecture Notes in Networks and Systems (LNNS 170), P15, DOI 10.1007/978-981-33-4084-8_2
   Das R, 2022, EXPERT SYST APPL
   Das R, 2022, MULTIMED TOOLS APPL, V81, P10051, DOI 10.1007/s11042-022-12042-8
   Ghosal D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3454
   Hazarika D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1122, DOI 10.1145/3394171.3413678
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jindal S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P447, DOI 10.1109/INFOP.2015.7489424
   LeCun Y., 1988, FEATURE GROUPING, V66, P233
   Meetei LS, 2021, LANG RESOUR EVAL, V55, P947, DOI 10.1007/s10579-021-09541-9
   Ortis A, 2021, MULTIMED TOOLS APPL, V80, P22323, DOI 10.1007/s11042-019-08312-7
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Pereira Moises Henrique Ramos, 2016, 10 INT AAAI C WEB SO
   Poria S, 2017, IEEE DATA MINING, P1033, DOI 10.1109/ICDM.2017.134
   Poria S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P873, DOI 10.18653/v1/P17-1081
   Poria S, 2012, INT CONF SIGN PROCES, P1251, DOI 10.1109/ICoSP.2012.6491803
   Sarkar K, 2017, 2017 IEEE CALCUTTA CONFERENCE (CALCON), P31, DOI 10.1109/CALCON.2017.8280690
   Sharma A., 2012, P 2012 ACM RES APPL, P1, DOI DOI 10.1145/2401603.2401605
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Siersdorfer S., 2010, ACM MM, P715
   Singh Thoudam Doren, 2021, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2020, NEHU. Lecture Notes in Networks and Systems (LNNS 170), P45, DOI 10.1007/978-981-33-4084-8_5
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Song KK, 2018, NEUROCOMPUTING, V312, P218, DOI 10.1016/j.neucom.2018.05.104
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang Jingwen., 2016, IJCAI, P3484
   Wei Han, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P6, DOI 10.1145/3462244.3479919
   You QZ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1071, DOI 10.1145/2733373.2806284
   You QZ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1008, DOI 10.1145/2964284.2964288
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yuan J., 2013, P 2 INT WORKSH ISS S, P1
   Zhang YW, 2015, LECT NOTES ARTIF INT, V9078, P52, DOI 10.1007/978-3-319-18032-8_5
   Zhao ZY, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102097
NR 43
TC 2
Z9 2
U1 7
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 16
PY 2023
DI 10.1007/s11042-023-15356-3
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P2QW4
UT WOS:001049147100001
DA 2024-07-18
ER

PT J
AU Amiri, Z
   Heidari, A
   Navimipour, NJ
   Unal, M
   Mousavi, A
AF Amiri, Zahra
   Heidari, Arash
   Navimipour, Nima Jafari
   Unal, Mehmet
   Mousavi, Ali
TI Adventures in data analysis: a systematic review of Deep Learning
   techniques for pattern recognition in cyber-physical-social systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Deep Learning; Machine Learning; Pattern Recognition; Big Data;
   Autonomous System
ID PERFORMANCE; INTERNET; NETWORK; CNN
AB Machine Learning (ML) and Deep Learning (DL) have achieved high success in many textual, auditory, medical imaging, and visual recognition patterns. Concerning the importance of ML/DL in recognizing patterns due to its high accuracy, many researchers argued for many solutions for improving pattern recognition performance using ML/DL methods. Due to the importance of the required intelligent pattern recognition of machines needed in image processing and the outstanding role of big data in generating state-of-the-art modern and classical approaches to pattern recognition, we conducted a thorough Systematic Literature Review (SLR) about DL approaches for big data pattern recognition. Therefore, we have discussed different research issues and possible paths in which the abovementioned techniques might help materialize the pattern recognition notion. Similarly, we have classified 60 of the most cutting-edge articles put forward pattern recognition issues into ten categories based on the DL/ML method used: Convolutional Neural Network (CNN), Recurrent Neural Network (RNN), Generative Adversarial Network (GAN), Autoencoder (AE), Ensemble Learning (EL), Reinforcement Learning (RL), Random Forest (RF), Multilayer Perception (MLP), Long-Short Term Memory (LSTM), and hybrid methods. SLR method has been used to investigate each one in terms of influential properties such as the main idea, advantages, disadvantages, strategies, simulation environment, datasets, and security issues. The results indicate most of the articles were published in 2021. Moreover, some important parameters such as accuracy, adaptability, fault tolerance, security, scalability, and flexibility were involved in these investigations.
C1 [Amiri, Zahra; Heidari, Arash] Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.
   [Heidari, Arash] Halic Univ, Dept Software Engn, TR-34060 Istanbul, Turkiye.
   [Navimipour, Nima Jafari] Kadir Has Univ, Dept Comp Engn, Istanbul, Turkiye.
   [Navimipour, Nima Jafari] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Touliu 64002, Taiwan.
   [Unal, Mehmet] Nisantasi Univ, Dept Comp Engn, Istanbul, Turkiye.
   [Mousavi, Ali] Islamic Azad Univ, Sanandaj Branch, Sanandaj, Iran.
C3 Islamic Azad University; Halic University; Kadir Has University;
   National Yunlin University Science & Technology; Istanbul Nisantasi
   University; Islamic Azad University
RP Heidari, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Tabriz Branch, Tabriz, Iran.; Heidari, A (corresponding author), Halic Univ, Dept Software Engn, TR-34060 Istanbul, Turkiye.; Navimipour, NJ (corresponding author), Kadir Has Univ, Dept Comp Engn, Istanbul, Turkiye.; Navimipour, NJ (corresponding author), Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, Touliu 64002, Taiwan.
EM zahraamiriii1398@gmail.com; arash_heidari@ieee.org;
   nima.navimipour@khas.edu.tr
RI Heidari, Arash/AAK-9761-2021; Mousavi, Ali/KOD-6511-2024; Jafari
   Navimipour, Nima/AAF-5662-2021; Amiri, Zahra/KHU-7955-2024; Ünal,
   Mehmet/AAO-6590-2021
OI Heidari, Arash/0000-0003-4279-8551; Jafari Navimipour,
   Nima/0000-0002-5514-5536; Ünal, Mehmet/0000-0003-4927-649X; Mousavi,
   Ali/0009-0002-6835-4836
CR Abbasi A, 2021, IEEE ACCESS, V9, P66408, DOI 10.1109/ACCESS.2021.3076264
   Aghakhani S, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12102263
   Akhavan J, 2024, J INTELL MANUF, V35, P1389, DOI 10.1007/s10845-023-02121-4
   Amiri Z, 2023, CLUSTER COMPUT, V26, P1565, DOI 10.1007/s10586-022-03738-5
   Awan MJ, 2022, INT J COMPUT APPL T, V68, P215, DOI [10.1504/IJCAT.2022.124942, 10.1504/IJCAT.2022.10049746]
   Awan MJ, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph181910147
   Bagheri M., 2020, OFFSHORE TECHNOLOGY
   Bai X, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108102
   Ben Atitallah S, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100303
   Benhamou E, 2021, INT C PATT RECOG, P10050, DOI 10.1109/ICPR48806.2021.9412958
   Bhamare D, 2018, FUZZY INF ENG, V10, P362, DOI 10.1080/16168658.2019.1611030
   Butt H, 2021, FORECASTING-BASEL, V3, P520, DOI 10.3390/forecast3030033
   Chancan M, 2020, arXiv
   Chen DY, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107969
   Chen JJ, 2021, DIGIT COMMUN NETW, V7, P453, DOI 10.1016/j.dcan.2020.11.001
   Chen P, 2022, COMPUT J, V65, P2909, DOI 10.1093/comjnl/bxac085
   Chen SF, 2022, Arxiv, DOI arXiv:2107.10224
   Chen Y., 2021, Complexity, V2021, P1
   Chen YL, 2022, UNDERGR SPACE, V7, P748, DOI 10.1016/j.undsp.2021.12.006
   Cheng L, 2022, IEEE SIGNAL PROC MAG, V39, P18, DOI 10.1109/MSP.2022.3198201
   Darbandi M., 2017, HCTL International Journal of Technology Innovations and Research, V23, P10, DOI DOI 10.5281/ZENODO.345288
   Darbandi M., 2017, Published by HCTL, Int. J. Technol. Innov. Res, V24, P1, DOI DOI 10.5281/ZENODO.1034475
   de Arruda HF, 2021, Arxiv, DOI arXiv:2107.08512
   Deng Y, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3258413
   Du Simon, 2019, INT C MACH LEARN, P1665
   Fang Han., 2020, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPR), P804
   Gammulle H, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107039
   Gao LQ, 2021, NEUROCOMPUTING, V434, P45, DOI 10.1016/j.neucom.2020.12.006
   Gao XJ, 2020, IEEE INT CONF ROBOT, P8440, DOI [10.1109/ICRA40945.2020.9196674, 10.1109/icra40945.2020.9196674]
   Gong JH, 2023, MULTIMED TOOLS APPL, V82, P25585, DOI 10.1007/s11042-023-14349-6
   Gowda SN, 2021, arXiv
   Hafeez Sadaf, 2021, 2021 International Conference on Communication Technologies (ComTech), P91, DOI 10.1109/ComTech52583.2021.9616668
   Hajipour Khire Masjidi B, 2022, Computational Intelligence and Neuroscience, V2022
   Han C., 2023, Frontiers in Business, Economics and Management, V8, P51, DOI [10.54097/fbem.v8i2.6616, DOI 10.54097/FBEM.V8I2.6616]
   Hasan MM, 2020, INT J COMPUT SCI INF, V18
   Heidari A, 2023, SUSTAIN COMPUT-INFOR, V39, DOI 10.1016/j.suscom.2023.100899
   Heidari A, 2023, IEEE INTERNET THINGS, V10, P8445, DOI 10.1109/JIOT.2023.3237661
   Heidari A, 2023, ARTIF INTELL MED, V141, DOI 10.1016/j.artmed.2023.102572
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Hou QB, 2023, IEEE T PATTERN ANAL, V45, P1328, DOI 10.1109/TPAMI.2022.3145427
   Hou XY, 2023, NANO ENERGY, V105, DOI 10.1016/j.nanoen.2022.108013
   Huang CQ, 2024, IEEE T NEUR NET LEAR, V35, P4813, DOI 10.1109/TNNLS.2022.3162301
   Jafari BM., 2022, J. Softw. Eng. Appl, V15, P325, DOI [10.4236/jsea.2022.159019, DOI 10.4236/JSEA.2022.159019]
   Jafari BM, 2023, INT FLAIRS C P, V36
   Jiao SH, 2021, J TRANSL MED, V19, DOI 10.1186/s12967-021-03084-x
   Jun K, 2020, IEEE ACCESS, V8, P19196, DOI 10.1109/ACCESS.2020.2967845
   Khairy RS., 2021, Int. J. Intell. Eng. and Syst, V14, P326
   Kim J, 2021, INT C MACHINE LEARNI, V139
   Kosarirad H, 2022, J SENSORS, V2022, DOI 10.1155/2022/9620555
   Langroodi AK, 2021, AUTOMAT CONSTR, V122, DOI 10.1016/j.autcon.2020.103465
   Lee K, 2021, PR MACH LEARN RES, V139
   Li B, 2023, MULTIMED TOOLS APPL, V82, P21641, DOI 10.1007/s11042-023-14675-9
   Li B, 2022, IEEE T WIREL COMMUN, V21, P4579, DOI 10.1109/TWC.2021.3131384
   Li B, 2022, IEEE T AUTOMAT CONTR, V67, P5762, DOI 10.1109/TAC.2021.3124750
   Li JB, 2022, COMPUT GEOTECH, V148, DOI 10.1016/j.compgeo.2022.104835
   Li P, 2018, IEEE T IND INFORM, V14, P790, DOI 10.1109/TII.2017.2739340
   Li QK, 2020, IEEE T SYST MAN CY-S, V50, P4905, DOI 10.1109/TSMC.2018.2884510
   Li W, 2021, MOBILE NETW APPL, V26, P234, DOI 10.1007/s11036-020-01700-6
   Li XT, 2021, NEURAL COMPUT APPL, V33, P8227, DOI 10.1007/s00521-020-04958-9
   Li XT, 2020, NEURAL COMPUT APPL, V32, P1765, DOI 10.1007/s00521-019-04566-2
   Lin J, 2019, ENG APPL ARTIF INTEL, V77, P186, DOI 10.1016/j.engappai.2018.10.008
   Liu Q, 2023, PROCESSES, V11, DOI 10.3390/pr11041162
   Liu ZB, 2020, NEURAL COMPUT APPL, V32, P14593, DOI 10.1007/s00521-020-05144-7
   Lu SY, 2023, INT J COMPUT INT SYS, V16, DOI 10.1007/s44196-023-00233-6
   Luo MD, 2021, IEEE T INF FOREN SEC, V16, P2341, DOI 10.1109/TIFS.2021.3053460
   Lv ZH, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3468506
   Lv ZH, 2021, IEEE INTERNET THINGS, V8, P9531, DOI 10.1109/JIOT.2020.3007130
   Ma YS, 2021, ACM T INTERNET THING, V2, DOI 10.1145/3424739
   Mao C, 2021, IEEE ACCESS, V9, P39608, DOI 10.1109/ACCESS.2021.3064362
   Marins MA, 2021, J PETROL SCI ENG, V197, DOI 10.1016/j.petrol.2020.107879
   Men YF, 2020, PROC CVPR IEEE, P5083, DOI 10.1109/CVPR42600.2020.00513
   Mohammed EA, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95042-2
   Morteza A, 2023, ENERG BUILDINGS, V289, DOI 10.1016/j.enbuild.2023.113036
   Morteza A, 2023, IET RENEW POWER GEN, V17, P1092, DOI 10.1049/rpg2.12663
   Mousavi A., 2023, INT J ROBOT CONTROL, V3, P221, DOI [10.31763/ijrcs.v3i2.939, DOI 10.31763/IJRCS.V3I2.939]
   Moussa M., 2021, INT J ELECT COMPUT E, V11, P892
   Abirami RN, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/5541134
   Ni HBA, 2020, INFORM-INT J COMPUT, V44, P491, DOI 10.31449/inf.v44i4.3390
   Ni QF, 2022, IEEE T NETW SCI ENG, V9, P1187, DOI 10.1109/TNSE.2021.3137353
   Niknam T, 2015, J INTELL FUZZY SYST, V29, P791, DOI 10.3233/IFS-141579
   Pan SP, 2022, IEEE INTERNET THINGS, V9, P8838, DOI 10.1109/JIOT.2021.3116158
   Paolanti M, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100276
   Parmar G, 2021, PROC CVPR IEEE, P823, DOI 10.1109/CVPR46437.2021.00088
   Peivandizadeh A, 2023, Compatible Authentication and Key Agreement Protocol for Low Power and Lossy Network in Iot Environment
   Peng Y, 2023, INFORM SCIENCES, V621, P672, DOI 10.1016/j.ins.2022.11.101
   Qu ZG, 2023, IEEE T INTELL TRANSP, V24, P8677, DOI 10.1109/TITS.2022.3203791
   Rao HC, 2021, INFORM SCIENCES, V569, P90, DOI 10.1016/j.ins.2021.04.023
   Rui Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P266, DOI 10.1007/978-3-030-58523-5_16
   Sadi M, 2022, 2022 IEEE 40 VLSI TE, P1
   Saeed RH, 2022, FOOD CONTROL, V137, DOI 10.1016/j.foodcont.2022.108902
   Safarzadeh VM, 2020, 2020 25 INT COMP C C, P1, DOI DOI 10.1109/CSICC49403.2020.9050073
   Salehi S, 2024, IEEE T ENG MANAGE, V71, P4761, DOI 10.1109/TEM.2023.3235718
   Sarbaz M, 2022, 2022 8 INT C CONTROL, P1
   Sarbaz M, 2021, INT CONF INSTRUM, P41, DOI 10.1109/ICCIA52082.2021.9403609
   Sevik A, 2018, 2018 INTERNATIONAL CONGRESS ON BIG DATA, DEEP LEARNING AND FIGHTING CYBER TERRORISM (IBIGDELFT), P61, DOI 10.1109/IBIGDELFT.2018.8625333
   Shahidi S, 2022, J FAM MED PRIM CARE, V11, P6183, DOI 10.4103/jfmpc.jfmpc_231_22
   Shen G., 2017, Eksploatacja i Niezawodnosc, V19
   Shen GX, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012112
   Shi ZW, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-021-04073-z
   Simpson T, 2021, J ENG MECH, V147, DOI 10.1061/(ASCE)EM.1943-7889.0001971
   Sohangir S, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0111-6
   Song FZ, 2022, IEEE T IND ELECTRON, V69, P13428, DOI 10.1109/TIE.2022.3142428
   Song YJ, 2023, FUTURE GENER COMP SY, V145, P77, DOI 10.1016/j.future.2023.03.020
   Subhashini PS, DNN RBF AHHO SPEAKER
   Tian J, 2023, COMPLEX INTELL SYST, V9, P3887, DOI 10.1007/s40747-022-00910-7
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Utkin Lev, 2021, 2021 Proceedings of the 28th Conference of Open Innovations Association (FRUCT), P489, DOI 10.23919/FRUCT50888.2021.9347612
   Vahdat S, 2022, EUR REV MED PHARMACO, V26, P2188, DOI 10.26355/eurrev_202203_28367
   Vahdat S., 2021, TOB REGUL SCI, V7, P6764
   Vahdat S, 2022, IJC HEART VASC, V41, DOI 10.1016/j.ijcha.2022.101068
   Vahdat S, 2022, KYBERNETES, V51, P2065, DOI 10.1108/K-04-2021-0333
   Vandat S, 2022, J PHARM NEGAT RESULT, V13, P235, DOI 10.47750/pnr.2022.13.S03.038
   Wang, 2020, P IEEE CVF C COMP VI, P9319, DOI DOI 10.1109/CVPR42600.2020.00934
   Wang B, 2023, IEEE T AERO ELEC SYS, V59, P4559, DOI [10.1109/IECON51785.2023.10312630, 10.1109/TAES.2023.3243580]
   Wang B, 2023, INT J ROBUST NONLIN, V33, P10182, DOI 10.1002/rnc.6631
   Wang H, 2023, IEEE T KNOWL DATA EN, V35, P10981, DOI [10.1109/TKDE.2022.3233481, 10.1109/ICASSP49357.2023.10096626]
   Wang H, 2022, COMPUT J, V65, P1189, DOI 10.1093/comjnl/bxaa168
   Wang YX, 2022, HIGH VOLT, V7, P452, DOI 10.1049/hve2.12135
   Wang YJ, 2020, PROC CVPR IEEE, P6957, DOI 10.1109/CVPR42600.2020.00699
   Xia K, 2020, IEEE ACCESS, V8, P56855, DOI 10.1109/ACCESS.2020.2982225
   Xiong ZG, 2023, J SIGNAL PROCESS SYS, V95, P1371, DOI 10.1007/s11265-023-01868-6
   Xiong ZG, 2022, J SIGNAL PROCESS SYS, V94, P1253, DOI 10.1007/s11265-022-01790-3
   Xu JW, 2022, IEEE T INTELL VEHICL, V7, P908, DOI 10.1109/TIV.2022.3200592
   Xu JW, 2023, IEEE T INTELL TRANSP, V24, P3383, DOI 10.1109/TITS.2022.3225782
   Xu RY, 2020, COMPUTING, V102, P765, DOI 10.1007/s00607-019-00722-7
   Xu W, 2021, IEEE ACCESS, V9, P140136, DOI 10.1109/ACCESS.2021.3116612
   Yan A, 2022, IEEE T COMPUT AIDED
   Yang M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/2836064
   Yumusak S, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.538
   Zerdoumi S, 2018, MULTIMED TOOLS APPL, V77, P10091, DOI 10.1007/s11042-017-5045-7
   Zhang DJ, 2022, Arxiv, DOI [arXiv:2111.12527, 10.48550/arXiv.2111.12527]
   Zhang JN, 2023, IEEE SYST J, V17, P4371, DOI 10.1109/JSYST.2023.3263865
   Zhang JZ, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115561
   Zhang X, 2023, CAAI T INTELL TECHNO, V8, P1480, DOI [10.1049/cit2.12174, 10.7633/j.issn.1003-6202.2023.06.001]
   Zhang X, 2024, COMPUT J, V67, P236, DOI 10.1093/comjnl/bxac171
   Zhang YW, 2021, IEEE ACCESS, V9, P18538, DOI 10.1109/ACCESS.2021.3051215
   Zhang ZY, 2021, ADV MATER, V33, DOI 10.1002/adma.202005112
   Zhao H, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA 2020), P108, DOI 10.1109/ICCIA49625.2020.00028
   Zheng WF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12084059
   Zheng WF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12073416
   Zhou GQ, 2021, IEEE ACCESS, V9, P27140, DOI 10.1109/ACCESS.2021.3057719
   Zhou L, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3105567
   Zong CJ, 2022, BRODOGRADNJA, V73, P23, DOI 10.21278/brod73102
   Zong CJ, 2022, COMPUT ELECTR ENG, V98, DOI 10.1016/j.compeleceng.2022.107685
NR 144
TC 26
Z9 26
U1 9
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16382-x
EA AUG 2023
PG 65
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400004
DA 2024-07-18
ER

PT J
AU Basak, S
   Suresh, S
AF Basak, Suvramalya
   Suresh, S.
TI Vehicle detection and type classification in low resolution congested
   traffic scenes using image super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Vehicle detection; Vehicle classification; Image super resolution;
   Convolution Neural Network; Deep learning
AB Vehicle detection and classification in real world highly congested traffic scenario is an important yet difficult task, especially because surveillance footage is captured in low resolution. Most available datasets contain high quality images and the models developed based on them do not perform well in real world scenario. In this paper, we present a Convolution Neural Network (CNN) based approach for vehicle type classification in congested vehicle traffic scenario with low resolution surveillance images. We have used highly congested low resolution CityCam dataset. To improve the classification performance of the proposed model, image super resolution technique is adopted to enhance essential details needed for differentiating classes. The experimental results demonstrate that the proposed CNN model performs better on the dataset compared with other existing state of art deep learning models. The proposed model achieved higher accuracy of 87.56% over the state of art models VGG16 and Inceptionv3 which achieves 84.62% and 84.87% respectively. Further, by enhancing the dataset with Residual Dense Network based image super resolution technique, the classification accuracy has increased around 1.73% to 89.29%.
C1 [Basak, Suvramalya; Suresh, S.] Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi 221005, India.
C3 Banaras Hindu University (BHU)
RP Suresh, S (corresponding author), Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi 221005, India.
EM suresh.selvam@bhu.ac.in
RI Basak, Suvramalya/KPY-7075-2024; S, Suresh/AAL-5541-2021
OI S, Suresh/0000-0003-1933-8872
FU Institute of Eminence - Seed Grant by Banaras Hindu University, Varanasi
FX The authors would like to acknowledge the financial support of Institute
   of Eminence - Seed Grant by Banaras Hindu University, Varanasi.
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Alam F, 2023, MOBILE NETW APPL, V28, P636, DOI 10.1007/s11036-019-01319-2
   Alshareef A, 2020, IJCSNS INT J COMPUTE, V20
   [Anonymous], 2017, arXiv
   Awang Suryanti, 2018, Journal of Physics: Conference Series, V1061, DOI 10.1088/1742-6596/1061/1/012009
   Banerjee S, 2019, TENCON IEEE REGION, P931, DOI [10.1109/TENCON.2019.8929357, 10.1109/tencon.2019.8929357]
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai DD, 2019, PATTERN RECOGN LETT, V119, P166, DOI 10.1016/j.patrec.2017.10.020
   Cardinale Francesco, 2018, ISR
   Chang JL, 2018, IEEE INTEL TRANSP SY, V10, P80, DOI 10.1109/MITS.2018.2806619
   Cheng Z, 2020, INFORM SYST RES, V31, P653, DOI 10.1287/isre.2019.0894
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong Z, 2014, INT C PATT RECOG, P172, DOI 10.1109/ICPR.2014.39
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hakim bin Che Mansor Muhammad Akmal, 2021, 2021 IEEE International Conference on Automatic Control & Intelligent Systems (I2CACIS), P126, DOI 10.1109/I2CACIS52118.2021.9495899
   Han YF, 2018, ADV MULTIMED, V2018, DOI 10.1155/2018/3138278
   Hurtik P, 2020, arXiv
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jolicoeur-Martineau A, 2018, Arxiv, DOI arXiv:1807.00734
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Rahman Minhajur, 2022, 2022 International Conference on Innovations in Science, Engineering and Technology (ICISET)., P421, DOI 10.1109/ICISET54810.2022.9775889
   Rahman Md Sazedur, 2022, 2022 4th International Conference on Sustainable Technologies for Industry 4.0 (STI), P1, DOI 10.1109/STI56238.2022.10103325
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roecker MN, 2018, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2018.8439406
   Sheng ML, 2018, PROCEEDINGS OF 2018 IEEE 7TH DATA DRIVEN CONTROL AND LEARNING SYSTEMS CONFERENCE (DDCLS), P581, DOI 10.1109/DDCLS.2018.8516099
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tabassum S, 2020, IEEE REGION 10 SYMP, P40
   Ullah FUM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112472
   Vest A, 2017, VERY LOW RESOLUTION
   Waleed A, 2017, GITHUB REPOSITORY
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wen J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164601
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Yamamoto K, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112557
   Zhang SH, 2017, PROC CVPR IEEE, P4264, DOI 10.1109/CVPR.2017.454
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou LG, 2021, INT C PATT RECOG, P1972, DOI 10.1109/ICPR48806.2021.9412876
   Zhou YR, 2016, Arxiv, DOI arXiv:1601.01145
   Zhou YR, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P276, DOI 10.1109/ICDSP.2016.7868561
NR 55
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16337-2
EA AUG 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700016
DA 2024-07-18
ER

PT J
AU Bastanfard, A
   Shahabipour, M
   Amirkhani, D
AF Bastanfard, Azam
   Shahabipour, Mohammad
   Amirkhani, Dariush
TI Crowdsourcing of labeling image objects: an online gamification
   application for data collection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data collection; Gamification; Image labeling; Deceptive behavior;
   Crowdsourcing
ID RECOMMENDATION SYSTEM; ALGORITHMS
AB This study aimed to improve the labeling of objects inside images in the crowdsourcing process. Images are one of the most widely used types of data on the internet. Controlling and refining images through the crowdsourcing process is time-consuming and tedious because of their quality and nature. Gamification of data collection was presented as a solution to review, categorize images, and motivate people. Because participant motivation might influence the quality of the output data, we used gamification elements to manage user interaction in this study. The proposed method has a great effect on improving the quality of output data by considering various challenges such as motivation, financial costs, and delays. The proposed algorithm calculates the average of the points specified by each user and then compares it with the average of the total correct answers. In the end, the proposed algorithm uses this comparison to decide whether to accept or reject the answer. In this research, the LabelMe, Flickr, and VOC2012 datasets were used. Implementing the proposed method in a real context showed that the proposed design improved the image labeling accuracy, which was increased by 11.3% compared to the previous methods. In this experiment, the people who interacted the most generated the most accurate data.
C1 [Bastanfard, Azam; Shahabipour, Mohammad] Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
   [Amirkhani, Dariush] Univ Quebec Outaouais, Dept Comp Sci & Engn, Gatineau, PQ, Canada.
C3 Islamic Azad University; University of Quebec; University Quebec
   Outaouais
RP Bastanfard, A (corresponding author), Islamic Azad Univ, Dept Comp Engn, Karaj Branch, Karaj, Iran.
EM Bastanfard@kiau.ac.ir; muh.shahabipour@gmail.com; amid01@uqo.ca
CR ADELSMAN RM, 1977, J ECON THEORY, V15, P145, DOI 10.1016/0022-0531(77)90073-4
   Allahverdi R., 2012, 2012 16th CSI International Symposium on Artificial Intelligence and Signal Processing (AISP), P278, DOI 10.1109/AISP.2012.6313758
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   [Anonymous], 2010, P 8 INT C MOBILE SYS, DOI DOI 10.1145/1814433.1814443
   [Anonymous], 2013, Proceedings of the 16th International Conference on Database Theory, DOI DOI 10.1145/2448496.2448524
   [Anonymous], 2012, SIGMOD
   Antin J., 2012, Interactions, V19, P14
   Bagley K.S., 2012, Conceptual mile markers to improve time-to-value for exploratory search sessions
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Bastanfard A, 2021, IRAN CONF ELECTR ENG, P493, DOI 10.1109/ICEE52715.2021.9544273
   Bastanfard A, 2009, LECT NOTES COMPUT SC, V5879, P1080, DOI 10.1007/978-3-642-10467-1_104
   Bastian A, 2019, 2019 2ND INTERNATIONAL CONFERENCE OF COMPUTER AND INFORMATICS ENGINEERING (IC2IE 2019), P1, DOI 10.1109/ic2ie47452.2019.8940861
   Berengueres J, 2013, ACMIEEE INT CONF HUM, P83, DOI 10.1109/HRI.2013.6483512
   Bhatti SS, 2020, J SYST SOFTWARE, V167, DOI 10.1016/j.jss.2020.110611
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2022, ENVIRON SCI POLLUT R, V29, P14780, DOI 10.1007/s11356-021-16627-y
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Bista S. K., 2012, 2012 IEEE 11th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom), P1405, DOI 10.1109/TrustCom.2012.145
   Bista SK, 2012, COLLABORATECOM, P611, DOI 10.4108/icst.collaboratecom.2012.250526
   Blohm I. J.M., 2013, LEIMEISTER DESIGN IT
   Börzsönyi S, 2001, PROC INT CONF DATA, P421, DOI 10.1109/ICDE.2001.914855
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Busa-Fekete R., 2013, ICML
   Cramer H., 2011, P 13 INT C HUMAN COM, P57, DOI DOI 10.1145/2037373.2037384
   Csikszentmihalyi M., 1990, Flow: The psychology of optimal experience
   Das Sarma A, 2014, PROC INT CONF DATA, P964, DOI 10.1109/ICDE.2014.6816715
   Deci EL, 1999, PSYCHOL BULL, V125, P627, DOI 10.1037/0033-2909.125.6.627
   Demartini G., 2012, P 21 INT C WORLD WID, P469
   Deterding S., 2011, GAMIFICATION USING G
   Downes-Le Guin T, 2012, INT J MARKET RES, V54, P613, DOI 10.2501/IJMR-54-5-613-633
   Elo A. E., 1978, The Rating of Chessplayers, Past and Present
   Eriksson B., 2013, ARTIF INTELL, P265
   Fan J, 2014, PROC INT CONF DATA, P976, DOI 10.1109/ICDE.2014.6816716
   Fang Y., 2016, INT C DAT SYST ADV A
   FEIGE U, 1994, SIAM J COMPUT, V23, P1001, DOI 10.1137/S0097539791195877
   Aparicio AF, 2012, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON INTERACCION PERSONA-ORDENADOR (INTERACCION'12), DOI 10.1145/2379636.2379653
   Frith J.H., 2012, CONSTRUCTING LOCATIO
   Gasland MM, 2011, THESIS I DATATEKNIKK
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Ghallab M., 2004, AUTOMATED PLANNING T
   Gnauk B., 2012, Proceedings of the 2012 Joint EDBT/ICDT Workshops, P103, DOI DOI 10.1145/2320765.2320799
   Gokhale C, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P601
   Grote A, 2019, IEEE T MED IMAGING, V38, P1284, DOI 10.1109/TMI.2018.2883237
   Groz B, 2015, PODS'15: PROCEEDINGS OF THE 33RD ACM SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P185, DOI 10.1145/2745754.2745775
   Gruenheid A., 2012, CROWDSOURCING ENTITY, P785
   Guo S., 2012, P 2012 ACM SIGMOD IN, DOI DOI 10.1145/2213836.2213880
   Hajarian M, 2019, MULTIMED TOOLS APPL, V78, P33457, DOI 10.1007/s11042-019-08057-3
   Hajarian M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0589-3
   Haksu Lee, 2012, 2012 International Symposium on Ubiquitous Virtual Reality (ISUVR), P34, DOI 10.1109/ISUVR.2012.21
   Heikinheimo H., 2013, P AAAI C HUMAN COMPU, P69
   Herbrich R., 2006, P 19 INT C NEUR INF, P569
   Hu L, 2019, IEEE T SUST COMPUT, V4, P168, DOI 10.1109/TSUSC.2017.2705181
   Jeffery ShawnR., 2008, P 2008 ACM SIGMOD IN, P847
   Jiang XY, 2011, MATH PROGRAM, V127, P203, DOI 10.1007/s10107-010-0419-x
   Kaplan H, 2013, PROC VLDB ENDOW, V6, P697, DOI 10.14778/2536360.2536369
   Khan AR., 2014, HYBRID STRATEGIES FI
   Li G, 2011, ARXIV
   Li GL, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1711, DOI 10.1145/3035918.3054776
   Liu Y., 2011, Proceedings of the 2011 International ACM Workshop on Ubiquitous Meta User Interfaces, Ubi-MUI '11, P7, DOI [DOI 10.1145/2072652.2072655, 10.1145/2072652.2072655]
   Lofi C., 2013, INT C CONC MOD
   Lofi Christoph., 2013, P 16 INT C EXTENDING, P465, DOI DOI 10.1145/2452376.2452431
   Malone T.W., 1982, P 1982 C HUM FACT CO, P63, DOI DOI 10.1145/800049.801756
   MALONE TW, 1981, COGNITIVE SCI, V5, P333, DOI 10.1207/s15516709cog0504_2
   Marcus A, 2011, ARXIV
   Marcus A, 2012, PROC VLDB ENDOW, V6, P109, DOI 10.14778/2535568.2448944
   Mason AD., 2012, 2012 6 IEEE INT C DI
   Massung E., 2013, Proceedings of CHI '13, P371, DOI [DOI 10.1145/2470654.2470708, 10.1145/2470654.2470708]
   McDaniel R, 2012, IEEE INT PROF COMMUN
   McGonical Jane., 2011, REALITY IS BROKEN WH
   Mekler ED., 2013, Gamification'13 - First International Conference on Gameful Design, Research, and Applications, P66, DOI [10.1145/2583008.2583017, DOI 10.1145/2583008.2583017]
   Minoofam SAH, 2010, LECT NOTES COMPUT SC, V6350, P79
   MirMashhouri A, 2022, MULTIMED TOOLS APPL, V81, P18935, DOI 10.1007/s11042-022-11966-5
   Morneau RA, 2012, SPE INTELLIGENT ENER
   Movahedi Z, 2021, MULTIMED TOOLS APPL, V80, P26773, DOI 10.1007/s11042-021-10968-z
   Mozafari B, 2014, PROC VLDB ENDOW, V8, P125, DOI 10.14778/2735471.2735474
   Negahban S., 2012, Advances in neural information processing systems, V25, P2474
   Hung NQV, 2014, PROC INT CONF DATA, P220, DOI 10.1109/ICDE.2014.6816653
   Nicholson S., 2012, Games-Learning-Society
   Parameswaran A, 2011, ARXIV
   Parameswaran A.G., 2012, SIGMOD C, P361, DOI 10.1145/2213836.2213878
   Park H, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P577, DOI 10.1145/2588555.2610503
   Passos EB., 2011, 2011 BRAZILIAN S GAM
   Pfei_er Thomas., 2012, Proceedings of the National Conference on Arti_cial Intelligence (AAAI), P122
   Pomerol J.-C., 2012, Multicriterion Decision in Management: Principles and Practice
   Rahm E, 2001, VLDB J, V10, P334, DOI 10.1007/s007780100057
   Rice JW, 2012, INT J GAMING COMPUT-, V4, P81, DOI 10.4018/jgcms.2012100106
   Rudinac S, 2013, IEEE T MULTIMEDIA, V15, P1231, DOI 10.1109/TMM.2013.2261481
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Sakamoto Mizuki, 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P421, DOI 10.1007/978-3-642-33542-6_43
   Sarawagi Sunita, 2002, P 8 ACM SIGKDD INT C, P269, DOI DOI 10.1145/775047.775087
   Sarma AD., 2015, JELLYBEAN CROWD POWE
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Shi F, 2013, 2013 INTERNATIONAL CONFERENCE ON MANAGEMENT AND INFORMATION TECHNOLOGY, P299
   Skinner B.F., 1953, SCI HUMAN BEHAV
   Takbiri Y, 2023, MULTIMED TOOLS APPL, V82, P20683, DOI 10.1007/s11042-023-14356-7
   Thom J., 2012, Incentives, P1067, DOI DOI 10.1145/2145204.2145362
   Trushkowsky B, 2013, PROC INT CONF DATA, P673, DOI 10.1109/ICDE.2013.6544865
   Tseng WY, 2019, MULTIMED TOOLS APPL, V78, P18137, DOI 10.1007/s11042-018-6944-y
   Venetis P., 2012, WWW, P989
   Verroios V, 2015, PROC INT CONF DATA, P219, DOI 10.1109/ICDE.2015.7113286
   Vesdapunt N, 2014, PROC VLDB ENDOW, V7, P1071, DOI 10.14778/2732977.2732982
   Wang J, 2012, ARXIV
   Wang SB, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1263, DOI 10.1145/2723372.2723739
   Wauthier F., 2013, INT C MACH LEARN, P109
   Whang SE., 2012, COMP ME MAYBE CROWD
   Whang SE, 2013, PROC VLDB ENDOW, V6, P349, DOI 10.14778/2536336.2536337
   Witt Maximilian., 2011, Informatik schafft Communities, P192
   Zhang CJ, 2013, PROC VLDB ENDOW, V6, P757, DOI 10.14778/2536360.2536374
   Zhang XH, 2016, PROC VLDB ENDOW, V9, P612, DOI 10.14778/2921558.2921559
   Zichermann G., 2011, GAMIFICATION DESIGN
NR 113
TC 0
Z9 0
U1 5
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20827
EP 20860
DI 10.1007/s11042-023-16325-6
EA AUG 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042010700001
DA 2024-07-18
ER

PT J
AU Yan, CP
   Wei, HJ
   Lan, Z
   Li, H
AF Yan, Caiping
   Wei, Huajian
   Lan, Zhi
   Li, Hong
TI MSA-Net: Multi-scale attention network for image splicing localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Spatial-channel relationships; Multi-scale;
   Self-attention; Image splicing localization
ID FORGERY
AB In this paper, we introduce the novel Multi-Scale Attention Network (MSA-Net) to address the challenge of locating diverse types and sizes of splicing forgery objects. Previous methods neglect crucial characteristics of global dependencies and size, resulting in imprecise localization on background tampering and small target tampering. To overcome this, we integrate a multi-scale self-attention mechanism to capture global dependencies and fully understand the relationships between spliced objects and untampered areas. Our approach involves inserting multi-scale attention modules that combine the position attention and channel attention modules between convolution layers for feature extraction. The position attention module emphasizes spatial interdependencies, capturing relationships between feature positions. Similarly, the channel attention module captures relationships between channel features. This allows for the preservation of intrinsic details while capturing long-range semantic dependencies, which is beneficial to the detection of splicing forgery objects. Meanwhile, by dividing the feature maps into multiple sub-regions or sub-channels, our attention modules can better preserve the details while capturing long-range semantic information dependencies. Experimental results show that the proposed MSA-Net outperforms several state-of-the-art algorithms with an F1-score of 60.5% and an IOU value of 58.8% on the CASIA dataset.
C1 [Yan, Caiping; Wei, Huajian; Lan, Zhi] Hangzhou Normal Univ, Dept Comp Sci, Hangzhou 311121, Peoples R China.
   [Li, Hong] Hangzhou InsVis Technol Co Ltd, Hangzhou 311121, Peoples R China.
C3 Hangzhou Normal University
RP Li, H (corresponding author), Hangzhou InsVis Technol Co Ltd, Hangzhou 311121, Peoples R China.
EM yancp@hznu.edu.cn; 2020111011002@stu.hznu.edu.cn;
   2020111011009@stu.hznu.edu.cn; hong.li.leon@connect.um.edu.mo
FU National Natural Science Foundation of China [61902102]; Natural Science
   Foundation of Zhejiang Province [LQ19F020004]
FX This work was supported by National Natural Science Foundation of China
   (61902102) and Natural Science Foundation of Zhejiang Province
   (LQ19F020004).
CR Bhartiya G, 2017, MULTIMED TOOLS APPL, V76, P20799, DOI 10.1007/s11042-016-3964-3
   Bi XL, 2019, IEEE COMPUT SOC CONF, P30, DOI 10.1109/CVPRW.2019.00010
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Charpe Jayshri, 2015, Proceedings of 2015 Global Conference on Communication Technologies (GCCT), P723, DOI 10.1109/GCCT.2015.7342759
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Cozza D., 2015, 2015 IEEE 42nd Photovoltaic Specialist Conference (PVSC). Proceedings, P1, DOI 10.1109/PVSC.2015.7355795
   Cozzolino D, 2020, IEEE T INF FOREN SEC, V15, P144, DOI 10.1109/TIFS.2019.2916364
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Goularas Dionysis, 2019, 2019 International Conference on Deep Learning and Machine Learning in Emerging Applications (Deep-ML). Proceedings, P12, DOI 10.1109/Deep-ML.2019.00011
   Guo JiaDong, 2022, 2022 International Conference on Machine Learning and Knowledge Engineering (MLKE), P59, DOI 10.1109/MLKE55170.2022.00017
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Korus P, 2017, IEEE T INF FOREN SEC, V12, P809, DOI 10.1109/TIFS.2016.2636089
   Krawetz Neal, 2007, Hacker Factor Solut., V6, P2
   Li CT, 2012, IEEE T CIRC SYST VID, V22, P260, DOI 10.1109/TCSVT.2011.2160750
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu B, 2020, INFORM SCIENCES, V526, P133, DOI 10.1016/j.ins.2020.03.099
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P480, DOI 10.1109/TIFS.2010.2051426
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Marra F, 2020, IEEE ACCESS, V8, P133488, DOI 10.1109/ACCESS.2020.3009877
   Meena KB, 2023, MULTIMED TOOLS APPL, V82, P13181, DOI 10.1007/s11042-021-11483-x
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salloum R, 2018, J VIS COMMUN IMAGE R, V51, P201, DOI 10.1016/j.jvcir.2018.01.010
   Springenberg J. T., 2015, ARXIV PREPRINT ARXIV
   Wang JW, 2020, IEEE T CIRC SYST VID, V30, P2736, DOI 10.1109/TCSVT.2019.2922309
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Y, 2019, PROC CVPR IEEE, P9535, DOI 10.1109/CVPR.2019.00977
   Xiao B, 2020, INFORM SCIENCES, V511, P172, DOI 10.1016/j.ins.2019.09.038
   Yang JQ, 2021, IEEE T CIRC SYST VID, V31, P1661, DOI 10.1109/TCSVT.2020.3003653
   Yang JQ, 2014, IEEE T INF FOREN SEC, V9, P1933, DOI 10.1109/TIFS.2014.2359368
   YILDIRIM EO, 2018, 2018 INT C ARTIFICIA, P1, DOI DOI 10.1109/IDAP.2018.8620870
   Zhang RY, 2020, INT CONF ACOUST SPEE, P2982, DOI [10.1109/icassp40776.2020.9054068, 10.1109/ICASSP40776.2020.9054068]
   Zhang Y, 2016, CRYPTOL INF SEC SER, V14, P1, DOI 10.3233/978-1-61499-617-0-1
   Zhang YL, 2022, IEEE T CIRC SYST VID, V32, P4828, DOI 10.1109/TCSVT.2021.3123829
   Zhang Z, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040478
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhuang PY, 2021, IEEE T INF FOREN SEC, V16, P2986, DOI 10.1109/TIFS.2021.3070444
NR 41
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20587
EP 20604
DI 10.1007/s11042-023-16131-0
EA AUG 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042601200007
DA 2024-07-18
ER

PT J
AU Hosseini, SA
   Farahmand, P
AF Hosseini, S. Abolfazl
   Farahmand, Parya
TI An attack resistant hybrid blind image watermarking scheme based on
   combination of DWT, DCT and PCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image watermarking; Discrete Wavelet Transform (DWT); Discrete
   Cosine Transform (DCT); Principal component analysis (PCA); Arnold cat
   map; Watermarking attacks
ID DISCRETE WAVELET TRANSFORM; MULTI-WATERMARKING; ROBUST; SVD; SECURE
AB A blind digital image watermarking method based on combination of Discrete Wavelet Transform (DWT), Discrete Cosine Transform (DCT) and Principal component analysis (PCA) is presented. First, the original image is decomposed by 3-level DWT, and HL/LH sub-band coefficients are divided into 4 x 4 non-overlapping blocks. Then, DCT is applied on each block. The high-frequency coefficients of each of four adjacent blocks are placed in a data matrix. After that, the PCA is applied to them. A binary watermarked image is scrambled by Arnold cat map and the PN-sequences of scrambled watermark bits are embedded into the first component of PCs. In the extraction procedure, the watermarked image is pre-filtered by combination of spatial sharpening and LoG filters to determine distinction between the original image and the watermarked information. Subsequently, the same method as the embedding process is used to extract the first principal component. Finally, correlation between the extracted components and the PN-sequences is calculated to decide whether the embedded bit is 0 or 1. The innovation of the proposed method is participation of PCA and frequency domain transforms for blind image watermarking purpose to improve the resistance of process against attacks, and increase the PSNR and NC even in the absence of attack. Comparing to some other methods, experimental results show high imperceptibility and the proposed method is achieved significantly higher robustness against general image processing attacks.
C1 [Hosseini, S. Abolfazl; Farahmand, Parya] Islamic Azad Univ, Res Ctr Developing Adv Technol Elect & Elect Ind, Dept Commun, Shahre Rey Branch,Yadegar E Imam Khomeini RAH, Tehran, Iran.
C3 Islamic Azad University
RP Hosseini, SA (corresponding author), Islamic Azad Univ, Res Ctr Developing Adv Technol Elect & Elect Ind, Dept Commun, Shahre Rey Branch,Yadegar E Imam Khomeini RAH, Tehran, Iran.
EM abolfazl.hosseini@modares.ac.ir
OI Hosseini, S. Abolfazl/0000-0002-9023-6222
CR Al-Haj Ali, 2007, Journal of Computer Sciences, V3, P740, DOI 10.3844/jcssp.2007.740.746
   Amirgholipour SK., 2009, JDCTA, V3, P42, DOI DOI 10.4156/JDCTA.VOL3.ISSUE2.AMIRGHOLIPOUR
   Bal SN, 2021, J KING SAUD UNIV-COM, V33, P552, DOI 10.1016/j.jksuci.2018.04.006
   Beitollahi M, 2022, EARTH SCI INFORM, V15, P1215, DOI 10.1007/s12145-022-00796-6
   Bors AG, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P231, DOI 10.1109/ICIP.1996.560426
   Chaughule SS, 2021, IEEE INT CONF COMP, DOI 10.1109/CIVEMSA52099.2021.9493672
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Cheng Mingzhi, 2012, Journal of Multimedia, V8, P299, DOI 10.4304/jmm.8.3.299-305
   Cox I. J., 2002, Digital Watermarking
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Gao YC, 2019, J REAL-TIME IMAGE PR, V16, P565, DOI 10.1007/s11554-018-0812-x
   Ghosh Ananya, 2019, Recent Trends in Signal and Image Processing. Proceedings of ISSIP 2018. Advances in Intelligent Systems and Computing (AISC 922), P103, DOI 10.1007/978-981-13-6783-0_10
   Giri KJ, 2020, MULTIMED TOOLS APPL, V79, P32881, DOI 10.1007/s11042-020-09716-6
   Hosseini S. A., 2010, 2010 International Conference on Computer Applications and Industrial Electronics (ICCAIE), P521, DOI 10.1109/ICCAIE.2010.5735136
   Hosseini SA, 2016, REMOTE SENS LETT, V7, P101, DOI 10.1080/2150704X.2015.1101180
   Hosseini SA, 2015, COMP COMM SEC ICCCS, P1, DOI DOI 10.1177/1464420715588218
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kaur Gurpreet Rekha Agarwal, 2020, 2020 IEEE 17 IND COU, P1, DOI [10.1109/INDICON49873.2020.9342560, DOI 10.1109/INDICON49873.2020.9342560]
   Kumar B., 2011, J INF SECUR, V2, P91, DOI DOI 10.4236/JIS.2011.22009
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Li XH, 2018, LECT NOTES COMPUT SC, V11166, P793, DOI 10.1007/978-3-030-00764-5_73
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Liu Q, 2006, WCICA 2006: SIXTH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-12, CONFERENCE PROCEEDINGS, P2878
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Nguyen TS, 2016, AEU-INT J ELECTRON C, V70, P1055, DOI 10.1016/j.aeue.2016.05.003
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Priya E, 2021, SIGNAL IMAGE PROCESS, DOI [10.1007/978-981-15-6141-2, DOI 10.1007/978-981-15-6141-2]
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Rathi S., 2012, INT J HLTH INF, V1, P27, DOI DOI 10.5281/zenodo.1240669
   Razafindradina Bruno H, 2013, ARXIV
   Rodarmel C., 2002, Surveying and Land Information Science, V62, P115, DOI DOI 10.1109/IGARSS.2001.976068
   Roy R, 2018, VIS INFORM, V2, P125, DOI 10.1016/j.visinf.2018.03.001
   Roy S, 2017, MULTIMED TOOLS APPL, V76, P3577, DOI 10.1007/s11042-016-3902-4
   Saboori A, 2016, P 2016 10 INT S COMM, P1
   Saboori A, 2015, IRAN CONF ELECTR ENG, P308, DOI 10.1109/IranianCEE.2015.7146230
   Saboori A, 2014, 2014 22ND TELECOMMUNICATIONS FORUM TELFOR (TELFOR), P521, DOI 10.1109/TELFOR.2014.7034461
   Sangeetha N, 2018, COMPLEX INTELL SYST, V4, P181, DOI 10.1007/s40747-017-0065-5
   Shaamala A., 2011, International Journal of Computer Science Issues, V8, P220
   Shahhosseini S., 2010, 2010 International Conference on Computer Applications and Industrial Electronics (ICCAIE), P537, DOI 10.1109/ICCAIE.2010.5735139
   Sharma A, 2017, WIRELESS PERS COMMUN, V92, P1611, DOI 10.1007/s11277-016-3625-x
   Shih FY, 2003, PATTERN RECOGN, V36, P969, DOI 10.1016/S0031-3203(02)00122-X
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh OP, 2021, MULTIMED TOOLS APPL, V80, P30367, DOI 10.1007/s11042-020-09606-x
   Singh R., 2020, INTELLIGENT WAVELET, DOI [10.1007/978-3-030-31873-4, DOI 10.1007/978-3-030-31873-4]
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Sneha S., 2016, INT J ENG MANAG RES, V6, P472
   Soni Mukesh, 2020, 2020 12th International Conference on Computational Intelligence and Communication Networks (CICN), P403, DOI 10.1109/CICN49253.2020.9242626
   Suryavanshi H. E., 2013, IAES International Journal of Electrical and Computer Engineering, V3, P1
   Thanki R, 2019, J INF SECUR APPL, V46, P231, DOI 10.1016/j.jisa.2019.03.017
   Wang JW, 2017, MULTIDIM SYST SIGN P, V28, P617, DOI 10.1007/s11045-015-0363-2
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
   Yi-lin Bei, 2011, 2011 IEEE International Conference on Computer Science and Automation Engineering (CSAE), P305, DOI 10.1109/CSAE.2011.5952856
   Zhang Y, 2019, IEEE INT CONF ELECTR, P41, DOI [10.1109/ICEIEC.2019.8784574, 10.1109/iceiec.2019.8784574]
NR 58
TC 0
Z9 0
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18829
EP 18852
DI 10.1007/s11042-023-16202-2
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001041470800001
DA 2024-07-18
ER

PT J
AU Rajasekaran, AS
   Azees, M
   Dash, CS
   Nayyar, A
AF Rajasekaran, Arun Sekar
   Azees, M.
   Dash, Chandra Sekhar
   Nayyar, Anand
TI Content addressable memory (CAM) based robust anonymous authentication
   and integrity preservation scheme for wireless body area networks (WBAN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless body area networks (WBAN); Authentication; Integrity; Privacy;
   Security; Cygwin; Cadence tool
ID KEY AGREEMENT SCHEME; PRIVACY-PRESERVING AUTHENTICATION; EFFICIENT USER
   AUTHENTICATION; SENSOR NETWORKS; PROTOCOL; INTERNET
AB Health plays a foremost role for every individual. To preserve the health, continuous monitoring of health is essential. Wireless Body Area Network (WBAN) is a type of wireless network used to monitor the health and fitness-related parameters of the human body. It is a short-range wireless network that connects wearable and implanted devices to each other and to a centralized server for data collection and analysis. As the advancement in the medical field increases, the security threats to health-related medical data also increases. The medical data of each individual (patient) is highly confidential. So, the privacy and security of this confidential information are of prior importance. Though several schemes have been proposed in the previous years, the anonymity and integrity preservation with lightweight is not addressed effectively. The proposed idea is to develop an anonymous integrity-preserved authenticated lightweight scheme based on Elliptic curve cryptography (ECC). The performance investigation of this scheme proves to be more efficient in terms of computational cost i.e., only 3.8 ms (27.53% less) is required for performing the authentication. Moreover, communicational cost at the doctor's side requires 960 bits (41.17% less) when compared to related schemes. In addition, the suggested scheme can serve up to a maximum of 6250 users in one minute. The analysis is simulated using the Cygwin software tool and its reports are analysed and proved to be noteworthy. Further, a health monitoring system is designed using Verilog Hardware description language (HDL). Finally, hardware implementation is done in - EDGE ZYNQ 7000 SoC FPGA Development board and synthesized using the Cadence tool using CMOS GPDK 90 nm technology.
C1 [Rajasekaran, Arun Sekar] SR Univ, Dept ECE, Warangal, Telangana, India.
   [Azees, M.] VIT AP Univ, Sch Comp Sci & Engn, Amaravati 522237, Andhra Prades, India.
   [Dash, Chandra Sekhar] Centurion Univ Technol & Management, Dept ECE, Sitapur, Odisha, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
C3 VIT-AP University; Centurion University of Technology & Management; Duy
   Tan University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang 550000, Vietnam.
EM rarunsekar007@gmail.com; azeesmm@gmail.com; Chandu0071@gmail.com;
   anandnayyar@duytan.edu.vn
RI Nayyar, Anand/F-3732-2015; Rajasekaran, Arun Sekar/AFG-2549-2022
OI Nayyar, Anand/0000-0002-9821-6146; Rajasekaran, Arun
   Sekar/0000-0002-3531-1904
CR Far HAN, 2021, WIREL NETW, V27, P1389, DOI 10.1007/s11276-020-02523-9
   Al-Janabi S, 2017, EGYPT INFORM J, V18, P113, DOI 10.1016/j.eij.2016.11.001
   Alzahrani BA, 2021, WIRELESS PERS COMMUN, V117, P47, DOI 10.1007/s11277-020-07237-x
   [Anonymous], 2017, CONCURR COMP PRACT E, DOI DOI 10.1002/CPE.3870
   Ara A, 2017, IEEE ACCESS, V5, P12601, DOI 10.1109/ACCESS.2017.2716439
   Arshad H, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0585-3
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Chang CC, 2016, WIRELESS PERS COMMUN, V89, P447, DOI 10.1007/s11277-016-3281-1
   Chatterjee K, 2022, INT J INF SECUR PRIV, V16, DOI 10.4018/IJISP.2022010111
   Chatterjee K, 2020, WIRELESS PERS COMMUN, V111, P2605, DOI 10.1007/s11277-019-07005-6
   CHEN Y, 2017, WIRELESS COMMUNICATI, V2017, P1
   Chen YY, 2018, J OPHTHALMOL, V2018, DOI 10.1155/2018/8629429
   Cygwin, LIN ENV EM WIND
   Das AK, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0218-2
   Farash MS, 2016, AD HOC NETW, V36, P152, DOI 10.1016/j.adhoc.2015.05.014
   He DB, 2018, IEEE SYST J, V12, P64, DOI 10.1109/JSYST.2015.2428620
   He DB, 2012, INFORM FUSION, V13, P223, DOI 10.1016/j.inffus.2011.01.001
   Hsu CL, 2020, IEEE ACCESS, V8, P196553, DOI 10.1109/ACCESS.2020.3035076
   Ivanov S, 2012, IEEE T BIO-MED ENG, V59, P3238, DOI 10.1109/TBME.2012.2208110
   Jangirala S, 2016, LECT NOTES COMPUT SC, V10063, P45, DOI 10.1007/978-3-319-49806-5_3
   Ji S, 2018, IEEE ACCESS, V6, P69603, DOI 10.1109/ACCESS.2018.2880898
   Jiang Q, 2016, J SUPERCOMPUT, V72, P3826, DOI 10.1007/s11227-015-1610-x
   Jiang Q, 2018, J AMB INTEL HUM COMP, V9, P1061, DOI 10.1007/s12652-017-0516-2
   Julien-Vergonjanne A, 2016, SIGNALS COMMUN TECHN, P569, DOI 10.1007/978-3-319-30201-0_26
   Kasyoka Philemon, 2020, Journal of Medical Engineering & Technology, V44, P12, DOI 10.1080/03091902.2019.1707890
   Koya AM, 2018, COMPUT NETW, V140, P138, DOI 10.1016/j.comnet.2018.05.006
   Kumar M, 2021, IEEE SYST J, V15, P2779, DOI 10.1109/JSYST.2020.2990749
   Lara E, 2021, IEEE ACCESS, V9, P79196, DOI 10.1109/ACCESS.2021.3084135
   Latré B, 2011, WIREL NETW, V17, P1, DOI 10.1007/s11276-010-0252-4
   Li X, 2017, COMPUT ELECTR ENG, V61, P238, DOI 10.1016/j.compeleceng.2017.02.011
   LIU J, 2016, SENSORS BASEL, V16
   Liu WZ, 2019, IEEE ACCESS, V7, P137770, DOI 10.1109/ACCESS.2019.2942987
   Liu XY, 2014, KSII T INTERNET INF, V8, P4643, DOI 10.3837/tiis.2014.12.023
   Lu YR, 2017, WIRELESS PERS COMMUN, V96, P813, DOI 10.1007/s11277-017-4203-6
   Ma LM, 2014, WIRELESS PERS COMMUN, V77, P1077, DOI 10.1007/s11277-013-1555-4
   Masdari M, 2016, SECUR COMMUN NETW, V9, P4777, DOI 10.1002/sec.1642
   Mo JQ, 2019, SECUR COMMUN NETW, V2019, DOI 10.1155/2019/2136506
   Narwal B, 2021, ARAB J SCI ENG, V46, P9197, DOI 10.1007/s13369-021-05707-3
   Odelu V, 2019, COMPUT SECUR, V83, P300, DOI 10.1016/j.cose.2019.03.002
   Ostad-Sharif A, 2019, INT J COMMUN SYST, V32, DOI 10.1002/dac.3974
   Pu C, 2022, IEEE INTERNET THINGS, V9, P21136, DOI 10.1109/JIOT.2022.3175756
   Rangwani D, 2021, CLOUD SECUR, P76, DOI [10.1201/9780367821555-6, DOI 10.1201/9780367821555-6]
   Ren J, 2013, IEEE T WIREL COMMUN, V12, P1018, DOI 10.1109/TWC.2012.12.112120
   Renuka K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19214625
   Ryu H, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9091114
   Saeed MES, 2018, IEEE INTERNET THINGS, V5, P4926, DOI 10.1109/JIOT.2018.2876133
   Sahoo SS, 2021, J AMB INTEL HUM COMP, V12, P1419, DOI 10.1007/s12652-020-02213-6
   Seulgi Shin, 2016, International Journal of Computer and Communication Engineering, V5, P50, DOI 10.17706/ijcce.2016.5.1.50-60
   Shen J, 2018, J NETW COMPUT APPL, V106, P117, DOI 10.1016/j.jnca.2018.01.003
   Shen J, 2018, FUTURE GENER COMP SY, V78, P956, DOI 10.1016/j.future.2016.11.033
   Shin S, 2020, IEEE ACCESS, V8, P67555, DOI 10.1109/ACCESS.2020.2985719
   Shuai MX, 2020, IET INFORM SECUR, V14, P380, DOI 10.1049/iet-ifs.2019.0491
   Shuai MX, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102499
   Singh A, 2017, WIRELESS PERS COMMUN, V94, P1881, DOI 10.1007/s11277-016-3717-7
   Son S, 2020, IEEE ACCESS, V8, P192177, DOI 10.1109/ACCESS.2020.3032680
   Soni M, 2022, WIRELESS PERS COMMUN, V127, P1067, DOI 10.1007/s11277-021-08565-2
   Subramani J, 2022, IEEE T IND INFORM, V18, P3484, DOI 10.1109/TII.2021.3097759
   Tan ZW, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0016-2
   Turkanovic M, 2014, AD HOC NETW, V20, P96, DOI 10.1016/j.adhoc.2014.03.009
   Vandana T. Santhi, 2021, International Journal of Cloud Computing, V10, P319, DOI 10.1504/IJCC.2021.119194
   Vijayakumar P, 2020, IEEE T IND INFORM, V16, P2603, DOI 10.1109/TII.2019.2925071
   Wang YB, 2021, IEEE ACCESS, V9, P105101, DOI 10.1109/ACCESS.2021.3099299
   Wang YF, 2023, PROBIOTICS ANTIMICRO, V15, P694, DOI [10.1007/s12602-021-09905-1, 10.1109/MWP54208.2022.9997737]
   Wu F, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9958-z
   Wu TY, 2010, COMPUT NETW, V54, P1520, DOI 10.1016/j.comnet.2009.12.008
   Xie Y, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/5860286
   Xie Y, 2019, IEEE ACCESS, V7, P15170, DOI 10.1109/ACCESS.2019.2894895
   Xiong H, 2015, IEEE T INF FOREN SEC, V10, P1442, DOI 10.1109/TIFS.2015.2414399
   Xu DQ, 2019, J AMB INTEL HUM COMP, V10, P611, DOI 10.1007/s12652-018-0710-x
   Xu DQ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1047-x
   Yang HM, 2015, PEER PEER NETW APPL, V8, P1059, DOI 10.1007/s12083-014-0299-6
   Young Lee J., 2018, INT J ENG TECHNOL, V7, P58, DOI [10.14419/ijet.v7i2.12.11036, DOI 10.14419/IJET.V7I2.12.11036]
   Yu S, 2022, IEEE ACCESS, V10, P60534, DOI 10.1109/ACCESS.2022.3181182
   Yuce M., 2011, WIREL BODY AREA NETW, DOI [10.1201/b11522-2, DOI 10.1201/B11522-2]
   Zhang AQ, 2017, IEEE T INF FOREN SEC, V12, P662, DOI 10.1109/TIFS.2016.2631950
   Zhang JW, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/1651560
   Zhang LP, 2017, IEEE J BIOMED HEALTH, V21, P465, DOI 10.1109/JBHI.2016.2517146
NR 77
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20429
EP 20455
DI 10.1007/s11042-023-16257-1
EA AUG 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400011
DA 2024-07-18
ER

PT J
AU Zhang, M
   Wang, HD
   Guo, YA
AF Zhang, Meng
   Wang, Haidong
   Guo, Yina
TI YUVDR: A residual network for image deblurring in YUV color space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deblurring; Color space; Residual network; Motion blur; YUV
ID NEURAL-NETWORK
AB Motion blur removal caused by camera shake and object motion in 3D space has long been a challenge in computer vision. Although RGB images are commonly used as input data for CNN-based image deblurring, their inherent issues of color overlap and high dimensionality can limit performance. To address these problems, we propose YUVDR, a residual network based on YUV color space, for image deblurring. By using YUV images, we mitigate the issues of color overlap and mutual influence. We introduce novel loss functions and conduct experiments on three datasets, namely GoPro, DVD and NFS, which offer a wide range of image quality levels, scene complexities, and types of motion blur. Our proposed method outperforms state-of-the-art algorithms, yielding a 3-5 dB improvement in the PSNR of test results. In addition, utilizing the YUV color space as the input data can greatly reduce the number of training parameters and model size, by approximately 15 times. This optimization of GPU memory not only improves training efficiency, but also reduces testing time for practical applications.
C1 [Zhang, Meng; Wang, Haidong; Guo, Yina] Taiyuan Univ Sci & Technol, Sch Elect & Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
C3 Taiyuan University of Science & Technology
RP Guo, YA (corresponding author), Taiyuan Univ Sci & Technol, Sch Elect & Informat Engn, Taiyuan 030024, Shanxi, Peoples R China.
EM 876239595@qq.com; 398520364@qq.com; zulibest@tyust.edu.cn
OI Zhang, Meng/0000-0002-8894-2507
CR Amirkhani D, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066140
   Ansari M, 2022, RECENT ADV COMPUTER, V15, P946
   Bahat Y, 2017, IEEE I CONF COMP VIS, P3306, DOI 10.1109/ICCV.2017.356
   Bastanfard A, 2022, MULTIMED TOOLS APPL, V81, P23473, DOI 10.1007/s11042-022-12584-x
   Bloomfield P., 1983, Least Absolute Deviations: Theory, Applications, and Algorithms
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Cai CT, 2018, IEEE ACCESS, V6, P58710, DOI 10.1109/ACCESS.2018.2874980
   Fahad M, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS (INIS), P1, DOI [10.1109/iNIS.2016.60, 10.1109/iNIS.2016.013]
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Ghimire D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060945
   Han K, 2014, IEEE-ACM T AUDIO SPE, V22, P2158, DOI 10.1109/TASLP.2014.2363410
   Hao RQ, 2022, MICROSC MICROANAL, V28, P732, DOI 10.1017/S1431927622000265
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HRADI M, 2015, BRIT MACH VIS C
   Instruments N, 2013, PEAK SIGN NOIS RAT I
   Jiang WB, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5605846
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Le Ngan, 2022, ARTIF INTELL REV, P1
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li Ming, 2010, Journal of Shanghai Jiaotong University (English Edition), V15, P31, DOI 10.1007/s12204-010-9740-z
   Li SY, 2019, PROC CVPR IEEE, P3833, DOI 10.1109/CVPR.2019.00396
   Liu RW, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033026
   Mark S., 2005, CS542B PROJECT REPOR, V504, P195
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Nah S, 2017, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2017.35
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Park KB, 2022, J COMPUT DES ENG, V9, P616, DOI 10.1093/jcde/qwac018
   Park S, 2022, APPL INTELL, V1-10
   Pergoloni S, 2016, 2016 6 INT C IM PROC, P1
   Podpora M., 2014, FEDCSIS POSITION PAP, P29, DOI DOI 10.15439/2014F206
   Premachandra C, 2019, IEEE INT C NETW SENS, P369, DOI [10.1109/icnsc.2019.8743319, 10.1109/ICNSC.2019.8743319]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Satish P, 2020, TRAIT SIGNAL, V37, P527, DOI 10.18280/ts.370321
   Sehar U, 2022, MULTIMED TOOLS APPL, V81, P30519, DOI 10.1007/s11042-022-12821-3
   Shaochen Li, 2022, 2022 14th International Conference on Measuring Technology and Mechatronics Automation (ICMTMA), P286, DOI 10.1109/ICMTMA54903.2022.00062
   Su JW, 2022, NEUROCOMPUTING, V487, P46, DOI 10.1016/j.neucom.2022.02.046
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Subashini P., 2011, WORLD COMP SCI INF T, V1, P277
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Wang KJ, 2021, J INTELL MANUF, V32, P1129, DOI 10.1007/s10845-020-01606-w
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2011, IEEE I CONF COMP VIS, P1100, DOI 10.1109/ICCV.2011.6126357
   Yang HH, 2022, APPL ACOUST, V190, DOI 10.1016/j.apacoust.2022.108644
   Zhang KH, 2020, PROC CVPR IEEE, P2734, DOI 10.1109/CVPR42600.2020.00281
   Zhao H., 2015, arXiv
   Zhongshui Qu, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P3546, DOI 10.1109/ICNC.2010.5584134
NR 53
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19541
EP 19561
DI 10.1007/s11042-023-16284-y
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800009
DA 2024-07-18
ER

PT J
AU Jiang, W
   Yang, K
   Qiu, CR
   Xie, LM
AF Jiang, Wan
   Yang, Kai
   Qiu, Chunrong
   Xie, Liming
TI Memory enhancement method based on Skip-GANomaly for anomaly detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Anomaly detection; Deep learning; Generative
   Adversarial Networks; Skip-GANomaly; Memory Enhancement
AB Unsupervised anomaly detection methods based on the Generative Adversarial Network have solved the problem of supervised anomaly detection methods relying on the training of known anomaly samples. However, the encoder is so powerful as to reconstruct the abnormal samples well, eventually resulting in missed detection. To address this problem, this paper proposes a memory enhancement method based on Skip-GANomaly for anomaly detection to optimize the generator. During the training process, the number of skip-connection layers is adjusted to reduce the generator overfitting. The coded information is used as query in the memory enhancement module attention to retrieve the most relevant items in the module memory and the memory content can be updated and frozen, so as to improve the reliability of the coding information, increase the error of anomaly reconstruction, finally to improve the detection accuracy. The average AUC values of this method tested on the public datasets MNIST and CIFAR-10 reach 0.905 and 0.851, improved by 15.0% and 12.0%, respectively. It fully indicates the versatility and effectiveness of the method described in this paper.
C1 [Jiang, Wan; Yang, Kai; Qiu, Chunrong; Xie, Liming] Southwest Jiaotong Univ, Inst Optoelect Engn, Sch Phys Sci & Technol, Chengdu 610031, Peoples R China.
C3 Southwest Jiaotong University
RP Jiang, W (corresponding author), Southwest Jiaotong Univ, Inst Optoelect Engn, Sch Phys Sci & Technol, Chengdu 610031, Peoples R China.
EM jiangwan9924@163.com
RI Xie, Liming/AAL-9554-2020
FU National Natural Science Foundation of China [61960206010]
FX National Natural Science Foundation of China(61960206010).
CR Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chalapathy R, 2019, arXiv
   Cheng Z, 2021, INT J INTELL SYST, V36, P7103, DOI 10.1002/int.22582
   Erfani SM, 2017, AAAI CONF ARTIF INTE, P1854
   Görnitz N, 2013, J ARTIF INTELL RES, V46, P235, DOI 10.1613/jair.3623
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A., 2014, ARXIV
   Hou JL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8771, DOI 10.1109/ICCV48922.2021.00867
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Javaid A., 2016, EAI ENDORSED T SECUR, P21, DOI DOI 10.4108/EAI.3-12-2015.2262516
   Jumutc V, 2014, IEEE T PATTERN ANAL, V36, P2510, DOI 10.1109/TPAMI.2014.2327984
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2014, AUTOENCODING VARIATI, P3581
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lai CH, 2019, ARXIV
   Li Deng, 2012, IEEE Signal Processing Magazine, V29, P141, DOI [10.1109/MSP.2012.2211477, DOI 10.1109/MSP.2012.2211477]
   Ling C.X., 2003, IJCAI International Joint Conference on Artificial Intelligence, V3, P519, DOI DOI 10.5555/1630659.1630736
   Liu GL, 2021, IEEE IMAGE PROC, P2468, DOI 10.1109/ICIP42928.2021.9506332
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Maas AL, 2013, PROC INT C MACH LEAR
   Meng QX, 2017, IEEE IJCNN, P364, DOI 10.1109/IJCNN.2017.7965877
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Radford A., 2015, ARXIV
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruff L, 2018, PR MACH LEARN RES, V80
   Schlegl T, 2017, LECT NOTES COMPUT SC, V10265, P146, DOI 10.1007/978-3-319-59050-9_12
   Shilton A, 2013, 2013 IEEE EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSORS, SENSOR NETWORKS AND INFORMATION PROCESSING, P491, DOI 10.1109/ISSNIP.2013.6529839
   Skvara V, 2018, ARXIV
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Xu HW, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P187, DOI 10.1145/3178876.3185996
   Ye F, 2022, IEEE T MULTIMEDIA, V24, P116, DOI 10.1109/TMM.2020.3046884
   Zenati H, 2018, ARXIV
NR 38
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19501
EP 19516
DI 10.1007/s11042-023-16317-6
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900011
DA 2024-07-18
ER

PT J
AU Roselinkiruba, R
   Bhuvaneshwari, G
AF Roselinkiruba, R.
   Bhuvaneshwari, G.
TI Feature extraction based pixel segmentation techniques data hiding and
   data encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Feature extraction; Object detection; Segmentation
ID SEMI-TENSOR PRODUCT; IMAGE ENCRYPTION; ALGORITHM; WATERMARKING;
   REGRESSION; NETWORKS
AB Data hiding along with the security plays a vital role in the wireless network. In recent years, object detection, Feature Extraction (FE) and correlation based technique are developed to predict the pixels that is suitable for embedding. However, traditional data hiding method still suffered in the selection of less distortion pixels. To overcome these shortcomings, this method proposes (i) Moving Object (MO) detection, (ii) FE, (iii) data hiding, and (iv) data encryption. Initially, the MO in the video are detected using optical flow and tracking the weight of MO. Next, data hiding features are extracted using Optimization Fruit fly Algorithm (OFA) with Differential Evolution (DE) and Opposition Based Learning (OBL) algorithm. Then, a modified data hiding techniques based on correlation, regression and pixel segmentation with Prediction Error (PE) techniques are used for improving the performance. Finally, the hidden data is encrypted using Binary Tree Structure (BTS) to provide additional layer of security. Experimental result shows the proposed method is superior to other state-of-the-art methods in terms of Peak-Signal-to-Noise Ratio (PSNR), embedding capacity and security analysis.
C1 [Roselinkiruba, R.; Bhuvaneshwari, G.] Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci & T, Dept SOC, Chennai, India.
C3 Vel Tech Rangarajan Dr Sagunthala R&D Institute of Science & Technology
RP Roselinkiruba, R (corresponding author), Vel Tech Rangarajan Dr Sagunthala R&D Inst Sci & T, Dept SOC, Chennai, India.
EM kirubaroselin@gmail.com; bhuvini146@gmail.com
RI R, RoselinKiruba/HOH-2068-2023
CR Ahmad M, 2022, INFORM SCIENCES, V592, P1, DOI 10.1016/j.ins.2022.01.042
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P1090, DOI 10.1109/TIP.2019.2934350
   Chen CLZ, 2016, PATTERN RECOGN, V52, P410, DOI 10.1016/j.patcog.2015.09.033
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Girod Bernd, 1993, P207
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Kumar M, 2022, ARTIF INTELL REV, V55, P2997, DOI 10.1007/s10462-021-10070-8
   Li Q, 2021, CHINESE PHYS B, V30, DOI 10.1088/1674-1056/abfa01
   Li Q, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107618
   Li Q, 2021, NEURAL PROCESS LETT, V53, P4037, DOI 10.1007/s11063-021-10582-y
   Li YX, 2021, IEEE T CIRC SYST VID, V31, P2315, DOI 10.1109/TCSVT.2020.3023080
   Ma B, 2019, J REAL-TIME IMAGE PR, V16, P821, DOI 10.1007/s11554-019-00891-w
   Ponuma R, 2019, MULTIMED TOOLS APPL, V78, P25707, DOI 10.1007/s11042-019-07808-6
   Roselinkiruba R, 2023, MULTIMED TOOLS APPL, V82, P35757, DOI 10.1007/s11042-023-14651-3
   RoselinKiruba R, 2023, VISUAL COMPUT, V39, P59, DOI 10.1007/s00371-021-02312-1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Singh LD, 2018, ARAB J SCI ENG, V43, P7397, DOI 10.1007/s13369-018-3104-7
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Tao JY, 2019, IEEE T CIRC SYST VID, V29, P594, DOI 10.1109/TCSVT.2018.2881118
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang HJ, 2022, CIRC SYST SIGNAL PR, V41, P6844, DOI 10.1007/s00034-022-02076-6
   Wang JX, 2019, SIGNAL PROCESS, V159, P193, DOI 10.1016/j.sigpro.2019.02.013
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2020, INFORM SCIENCES, V539, P195, DOI 10.1016/j.ins.2020.06.030
   Wang XY, 2020, INFORM SCIENCES, V507, P16, DOI 10.1016/j.ins.2019.08.041
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Willems F., 2004, 42 ANN ALL C COMM CO
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
NR 30
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19259
EP 19276
DI 10.1007/s11042-023-16338-1
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037130000002
DA 2024-07-18
ER

PT J
AU Altay, A
   Gumus, A
AF Altay, Ayse
   Gumus, Abdurrahman
TI Real-time superficial vein imaging system for observing abnormalities on
   vascular structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical imaging system; Superficial vein imaging; Computer vision;
   Real-time video processing; Microcomputer
ID FACILITATE BLOOD WITHDRAWAL; NEAR-INFRARED LIGHT; FOOT; ANGIOGRAPHY;
   ARTERIES; KINKING
AB Circulatory system abnormalities might be an indicator of diseases or tissue damage. Early detection of vascular abnormalities might have an important role during treatment and also raise the patient's awareness. Current detection methods for vascular imaging are high-cost, invasive, and mostly radiation-based. In this study, a low-cost and portable microcomputer-based tool has been developed as a Near-Infrared (NIR) superficial vascular imaging device. The device uses NIR Light-Emitting Diode (LED) light at 850 nm along with other electronic and optical components. It operates as a non-contact and safe infrared (IR) imaging method in real-time. Image and video analysis are carried out using OpenCV (Open-Source Computer Vision), a library of programming functions mainly used in computer vision. Various tests were carried out to optimize the imaging system and set up a suitable external environment. To test the performance of the device, the images taken from three diabetic volunteers, who are expected to have abnormalities in the vascular structure due to the possibility of deformation caused by high glucose levels in the blood, were compared with the images taken from two non-diabetic volunteers. As a result, tortuosity was observed successfully in the superficial vascular structures, where the results need to be interpreted by the medical experts in the field to understand the underlying reasons. Although this study is an engineering study and does not have an intention to diagnose any diseases, the developed system here might assist healthcare personnel in early diagnosis and treatment follow-up for vascular structures and may enable further opportunities.
C1 [Altay, Ayse; Gumus, Abdurrahman] Izmir Inst Technol, Dept Elect & Elect Engn, Izmir, Turkiye.
C3 Izmir Institute of Technology
RP Gumus, A (corresponding author), Izmir Inst Technol, Dept Elect & Elect Engn, Izmir, Turkiye.
EM aysealtayy@gmail.com; abdurrahmangumus@iyte.edu.tr
RI Gumus, Abdurrahman/KGL-2848-2024; Gumus, Abdurrahman/KGL-4306-2024
OI Gumus, Abdurrahman/0000-0003-2993-5769; 
FU Izmir Institute of Technology by Scientific Research Projects
   Coordination Unit (BAP) [2020IYTE0112]
FX We would like to thank Assoc. Prof. Dr. Sevket Gumustekin for laboratory
   resources during 3D modeling of the device. We also would like to thank
   you to Izmir Institute of Technology for their support in this project
   by Scientific Research Projects Coordination Unit (BAP) 2020IYTE0112.
CR Ai DN, 2016, BIOMED OPT EXPRESS, V7, P2565, DOI 10.1364/BOE.7.002565
   ALMER LO, 1975, THROMB RES, V6, P177, DOI 10.1016/0049-3848(75)90022-5
   [Anonymous], HOYA FILTERS
   Apelqvist J, 2000, DIABETES-METAB RES, V16, pS75, DOI 10.1002/1520-7560(200009/10)16:1+<::AID-DMRR139>3.0.CO;2-8
   Barolet D, 2016, J PHOTOCH PHOTOBIO B, V155, P78, DOI 10.1016/j.jphotobiol.2015.12.014
   Beckert S, 2006, DIABETES CARE, V29, P988, DOI 10.2337/dc05-2431
   Brandt HGS, 2016, DAN MED J, V63
   Cuper NJ, 2013, MED ENG PHYS, V35, P433, DOI 10.1016/j.medengphy.2012.06.007
   Cuper NJ, 2011, CLIN PEDIATR, V50, P508, DOI 10.1177/0009922810395932
   D'Alessandro B, 2012, IEEE T BIO-MED ENG, V59, P2660, DOI 10.1109/TBME.2012.2209647
   Desmet KD, 2006, PHOTOMED LASER SURG, V24, P121, DOI 10.1089/pho.2006.24.121
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Goyen M, 2000, EUR J RADIOL, V34, P247, DOI 10.1016/S0720-048X(00)00203-5
   Gupta S., 2018, INT J COMPUT APPL, V182, P19, DOI DOI 10.5120/IJCA2018917554
   Hashimoto J., 2006, S VLSI CIRC, P5, DOI DOI 10.1109/VLSIC.2006.1705285
   Helisch A, 2003, MICROCIRCULATION, V10, P83, DOI 10.1038/sj.mn.7800173
   Huang D, 2017, IMAGE VISION COMPUT, V58, P266, DOI 10.1016/j.imavis.2016.07.001
   Johnstone DM, 2016, FRONT NEUROSCI-SWITZ, V9, DOI [10.3389/fninc.2015.00500, 10.3389/fnins.2015.00500]
   Kato T, 2012, INT SYM MICRO-NANOM, P501, DOI 10.1109/MHS.2012.6492503
   Kramer CM, 2007, J AM COLL CARDIOL, V50, P1097, DOI 10.1016/j.jacc.2007.07.006
   Marshall SM, 2006, BMJ-BRIT MED J, V333, P475, DOI 10.1136/bmj.38922.650521.80
   Mela CA, 2019, INT J COMPUT ASS RAD, V14, P203, DOI 10.1007/s11548-018-1865-9
   Norris JW, 2004, STROKE, V35, P370, DOI 10.1161/01.STR.0000115295.63866.E0
   Nvidia, Nvidia Jetson Nano Developer Kit
   Raspovic KM, 2014, J FOOT ANKLE SURG, V53, P716, DOI 10.1053/j.jfas.2014.06.011
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Schaper NC, 2012, DIABETES-METAB RES, V28, P218, DOI 10.1002/dmrr.2255
   Schep G, 2001, PHYSIOL MEAS, V22, P475, DOI 10.1088/0967-3334/22/3/306
   Schiffer F, 2009, BEHAV BRAIN FUNCT, V5, DOI 10.1186/1744-9081-5-46
   Seker K, 2017, J INNOV OPT HEAL SCI, V10, DOI 10.1142/S1793545816500516
   Sowa MG, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.9.091304
   van Hamersvelt Robbert W, 2018, Int J Cardiovasc Imaging, V34, P1265, DOI 10.1007/s10554-018-1329-x
   Wan ZQ, 2020, THERANOSTICS, V10, P11837, DOI 10.7150/thno.49784
   WEIBEL J, 1965, NEUROLOGY, V15, P7, DOI 10.1212/WNL.15.1.7
   WorldHealth Organization, 2020, WHO GUID US FERR CON
   Yildiz MZ, 2019, INFRARED PHYS TECHN, V98, P27, DOI 10.1016/j.infrared.2019.02.010
   Zhao JM, 2006, 2006 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY, PROCEEDINGS, P52, DOI 10.1109/IAT.2006.54
   Zharov VP, 2004, LASER SURG MED, V34, P56, DOI 10.1002/lsm.10248
NR 38
TC 0
Z9 0
U1 11
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21045
EP 21064
DI 10.1007/s11042-023-16251-7
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001043237000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zabihzadeh, D
   Alitbi, Z
   Mousavirad, SJ
AF Zabihzadeh, Davood
   Alitbi, Zahraa
   Mousavirad, Seyed Jalaleddin
TI Ensemble of loss functions to improve generalizability of deep metric
   learning methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep metric learning; Semantic embedding; Similarity embedding; Ensemble
   of Loss function; Combining Losses; Zero Shot Learning
AB The success of a Deep metric learning (DML) algorithm greatly depends on its loss function. However, no loss function is perfect and deals only with some aspects of an optimal similarity embedding. Besides, they omit the generalizability of the DML on unseen categories. To address these challenges, we propose novel approaches to combine different losses built on top of a shared deep network. The proposed ensemble of losses enforces the model to extract compatible features with all losses. Since the selected losses are diverse and emphasize different aspects of an optimal embedding, our effective combining method yields a considerable improvement over any individual loss and generalize well on unseen classes. It can optimize each loss function and its weight without imposing an additional hyper-parameter. We evaluate our methods on some popular datasets in a Zero-Shot-Learning setting. The results are very encouraging and show that our methods outperform all baseline losses by a large margin in all datasets. Specifically, the proposed method surpasses the best individual loss on the Cars-196 dataset by 10.37% and 9.54% in terms of Recall@1 and kNN accuracy respectively. Moreover, we develop a novel distance-based compression method that compresses the coefficient and embedding of losses into a single embedding vector. The size of the resulting embedding is identical to each baseline learner. Thus, it is fast as each baseline DML in the evaluation stage. Meanwhile, it outperforms the best individual loss on the Cars-196 dataset by 8.28% and 7.76% in terms of Recall@1 and kNN accuracy respectively.
C1 [Zabihzadeh, Davood; Mousavirad, Seyed Jalaleddin] Hakim Sabzevari Univ, Comp Engn Dept, Sabzevar, Iran.
   [Alitbi, Zahraa] Ferdowsi Univ Mashhad FUM, Engn Fac, Comp Engn Dept, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Zabihzadeh, D (corresponding author), Hakim Sabzevari Univ, Comp Engn Dept, Sabzevar, Iran.
EM d.zabihzadeh@hsu.ac.ir
RI Mousavirad, Seyed Jalaleddin/O-3254-2019
OI Mousavirad, Seyed Jalaleddin/0000-0001-8661-7578
CR Al-Kaabi K, 2023, APPL INTELL, V53, P8693, DOI 10.1007/s10489-022-03959-6
   Chen BH, 2019, AAAI CONF ARTIF INTE, P8134
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Elezi I, 2023, IEEE T PATTERN ANAL, V45, P2505, DOI 10.1109/TPAMI.2022.3163846
   Ge WF, 2018, LECT NOTES COMPUT SC, V11210, P272, DOI 10.1007/978-3-030-01231-1_17
   Gonzalez-Zapata J, 2022, IEEE COMPUT SOC CONF, P1480, DOI 10.1109/CVPRW56347.2022.00154
   Gu G, 2021, P AAAI C ART INT VAN, P1
   Hajiabadi H, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106624
   Hajiabadi H, 2019, APPL INTELL, V49, P1437, DOI 10.1007/s10489-018-1341-9
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Jian Wang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2612, DOI 10.1109/ICCV.2017.283
   Jiang W, 2021, IEEE T CIRC SYST VID, V31, P1091, DOI 10.1109/TCSVT.2020.2995754
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066
   Kim S, 2020, PROC CVPR IEEE, P5163, DOI 10.1109/CVPR42600.2020.00521
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li XM, 2020, NEUROCOMPUTING, V406, P49, DOI 10.1016/j.neucom.2020.04.040
   Milbich T., 2021, ADV NEURAL INF PROCE, V34, P25006
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Ni JZ, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1189, DOI 10.1145/3132847.3133022
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Opitz M, 2020, IEEE T PATTERN ANAL, V42, P276, DOI 10.1109/TPAMI.2018.2848925
   Qian Q, 2019, IEEE I CONF COMP VIS, P6459, DOI 10.1109/ICCV.2019.00655
   Rippel O, 2015, ARXIV
   Salman H, 2023, MULTIMED TOOLS APPL, V82, P33937, DOI 10.1007/s11042-023-14761-y
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Ustinova E, 2016, ADV NEUR IN, V29
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Yao XX, 2021, IEEE T MULTIMEDIA, V23, P1640, DOI 10.1109/TMM.2020.3001527
   Yuan TT, 2019, PROC CVPR IEEE, P4810, DOI 10.1109/CVPR.2019.00495
   Zhang H., 2017, ARXIV
NR 33
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 21525
EP 21549
DI 10.1007/s11042-023-16160-9
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001035725700014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Saraswat, S
   Singh, P
   Kumar, M
   Agarwal, J
AF Saraswat, Shipra
   Singh, Pooja
   Kumar, Manoj
   Agarwal, Jyoti
TI Advanced detection of fungi-bacterial diseases in plants using modified
   deep neural network and DSURF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fungi-Bacterial diseases; Machine Learning; Data Fusion; Modified neural
   network models; Dynamic SURF method; Image space detection
ID FOOD; QUALITY; CNN
AB Food is indispensable for humans as their growth and survival depend on it. But nowadays, crop is getting spoiled due to fungi and bacteria as soil temperature are changes very rapidly according to sudden climate changes. Due to fungi-bacterial crop, the quality of food is declining day by day and this is really not good for human health. The goal of this research paper is the advanced detection of fungi-bacterial diseases in plants using modified deep neural network approach and DSURF method in order to enhance the detection process. Proposed approach of this research is to use the artificial intelligence techniques like neural network model and dynamic SURF method in order to identify and classify the plant diseases for fungus and bacteria. Additionally, support dynamic feature extraction DSURF & classifier combinations for creating image clusters with the help of Clustering. Deep learning model is employed for training and testing the classifier. The quantitative experimental results of this research work are claimed that authors have achieved the 99.5% overall accuracy by implementing DNNM and DSURF which is much higher than other previous proposed methods in this field. This proposed work is a step towards finding the best practices to detect plant diseases from any bacterial and fungal infection so that humans can get healthy food.
C1 [Saraswat, Shipra] AKTU Lucknow, ABES Inst Technol, Dept Comp Sci & Engn, Ghaziabad, UP, India.
   [Singh, Pooja] Chandigarh Univ, Univ Inst Engn Comp Sci & Engn, Mohali, Punjab, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Sch Comp Sci, FEIS, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Agarwal, Jyoti] Graph Era Deemed Be Univ, Dept Comp Sci & Engn, Dehra Dun, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Chandigarh
   University; University of Wollongong; Middle East University; Graphic
   Era University
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Sch Comp Sci, FEIS, Dubai Knowledge Pk, Dubai, U Arab Emirates.; Kumar, M (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM sshipra1510@gmail.com; Pooja17ps@gmail.com; wss.manojkumar@gmail.com;
   itsjyotiagarwal1@gmail.com
RI Kumar, Manoj/AFS-0700-2022
OI Kumar, Manoj/0000-0001-9598-0280; Singh, Dr. Pooja/0000-0002-8649-1060
FU CAUL and its Member Institutions
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Adeel A, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12569
   Agarwal Mayank, 2023, 2023 IEEE International Students' Conference on Electrical, Electronics and Computer Science (SCEECS), P1, DOI 10.1109/SCEECS57921.2023.10063036
   Al-bayati JSH, 2020, INT J COMPUT INT SYS, V13, P12, DOI 10.2991/ijcis.d.200108.001
   Alfian G, 2020, FOOD CONTROL, V110, DOI 10.1016/j.foodcont.2019.107016
   Almadhor A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113830
   Annabel L. Sherly Puspha, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0538, DOI 10.1109/ICCSP.2019.8698004
   Arshaghi A, 2023, MULTIMED TOOLS APPL, V82, P5725, DOI 10.1007/s11042-022-13390-1
   Arun RA, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118905
   Banús N, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-01254-x
   Bhole Varsha, 2020, SIGITE '20: Proceedings of the 21st Annual Conference on Information Technology Education, P180, DOI 10.1145/3368308.3415370
   Bonkra Anupam, 2023, Int J Environ Res Public Health, V20, DOI 10.3390/ijerph20043222
   Bouguettaya A, 2023, CLUSTER COMPUT, V26, P1297, DOI 10.1007/s10586-022-03627-x
   Brooks S, 2022, CURR MICROBIOL, V79, DOI 10.1007/s00284-022-02803-x
   Chakrabarti S. K., 2022, Sustainable management of potato pests and diseases, P1, DOI 10.1007/978-981-16-7695-6_1
   Choudhary RC, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0266675
   Chowdhury MEH, 2021, AGRIENGINEERING, V3, P294, DOI 10.3390/agriengineering3020020
   Debauche O., 2020, Procedia Comput. Sci, V177, P40, DOI [10.1016/j.procs.2020.10.009, DOI 10.1016/J.PROCS.2020.10.009]
   Fekri-Ershad S, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113509
   Gobalakrishnan N., 2020, 2020 Proceedings of the International Conference on Communication and Signal Processing (ICCSP), P0465, DOI 10.1109/ICCSP48568.2020.9182046
   Selvaraj MG, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0475-z
   Guine R. P. F., 2019, Int. J. Food Eng, V5, P15, DOI [DOI 10.18178/IJFE.5.1.15-21, 10.18178/ijfe.5.1.15-21]
   Gungor VC, 2010, IEEE T IND ELECTRON, V57, P3557, DOI 10.1109/TIE.2009.2039455
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Haq Zeeshan Ali, 2021, Proceedings of the 2021 8th International Conference on Computing for Sustainable Global Development (INDIACom), P227, DOI 10.1109/INDIACom51348.2021.00040
   Hasan RI, 2020, PLANTS-BASEL, V9, DOI 10.3390/plants9101302
   Huang XB, 2023, MULTIMED TOOLS APPL, V82, P2121, DOI 10.1007/s11042-021-11790-3
   Hussain N, 2022, CMC-COMPUT MATER CON, V70, P3281, DOI 10.32604/cmc.2022.019036
   Jadhav S.B., 2019, IAES Int J Artif Intell Educ, V8, P328
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Khan RU, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5541859
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Lam MB, 2020, IEEE ACCESS, V8, P88360, DOI 10.1109/ACCESS.2020.2993053
   Liu SY, 2020, IT PROF, V22, P14, DOI 10.1109/MITP.2020.2986121
   Liu Y, 2021, TRENDS FOOD SCI TECH, V113, P193, DOI 10.1016/j.tifs.2021.04.042
   Loey M., 2020, INT J SERV SCI MANAG, V11, P41
   Medus LD, 2021, FOOD CONTROL, V125, DOI 10.1016/j.foodcont.2021.107962
   Meng WB, 2013, PANCREATOLOGY, V13, P201, DOI 10.1016/j.pan.2013.02.003
   Misra NN, 2022, IEEE INTERNET THINGS, V9, P6305, DOI 10.1109/JIOT.2020.2998584
   Nachtigall LG, 2016, PROC INT C TOOLS ART, P472, DOI [10.1109/ICTAI.2016.75, 10.1109/ICTAI.2016.0078]
   Nayak J, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100297
   Ozdemir A., 2020, J I ELECT COMPUT, V2, P39, DOI [DOI 10.33969/JIEC.2020.21004, 10.33969/JIEC.2020.21004]
   Raja SP, 2022, IEEE ACCESS, V10, P23625, DOI 10.1109/ACCESS.2022.3154350
   Said L. B., 2019, Industrial Biotechnology, V15, P138, DOI 10.1089/ind.2019.29175.lbs
   Salim Nareen O. M., 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1963/1/012014
   Shoaib M, 2023, FRONT PLANT SCI, V14, DOI 10.3389/fpls.2023.1158933
   Sinha A, 2020, IET IMAGE PROCESS, V14, P1427, DOI 10.1049/iet-ipr.2018.6210
   Stangierski J, 2019, EUR FOOD RES TECHNOL, V245, P2539, DOI 10.1007/s00217-019-03369-y
   Verma S, 2023, COMPUT ELECTRON AGR, V207, DOI 10.1016/j.compag.2023.107708
   Xie WJ, 2021, BIOSYST ENG, V208, P287, DOI 10.1016/j.biosystemseng.2021.06.008
   Xing TT, 2022, J INTEGR AGR, V21, P1488, DOI 10.1016/S2095-3119(21)63673-0
   Yan Z., 2022, J SUSTAIN AGR ENV, V1, P73, DOI [DOI 10.1002/SAE2.12007, 10.1002/sae2.12007]
   Yu L, 2003, P 20 INT C MACH LEAR, P856, DOI DOI 10.5555/3041838.3041946
   Zhang XL, 2021, TRENDS FOOD SCI TECH, V112, P431, DOI 10.1016/j.tifs.2021.04.008
   Zhou L, 2019, COMPR REV FOOD SCI F, V18, P1793, DOI 10.1111/1541-4337.12492
   Zhu LL, 2021, CURR RES FOOD SCI, V4, P233, DOI 10.1016/j.crfs.2021.03.009
NR 55
TC 4
Z9 4
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16711
EP 16733
DI 10.1007/s11042-023-16281-1
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100009
OA hybrid
DA 2024-07-18
ER

PT J
AU Wu, GK
   Xu, J
   Zhang, YD
   Zhang, BP
AF Wu, Geng-Kun
   Xu, Jie
   Zhang, Yi-Dan
   Zhang, Bei-Ping
TI Underwater enhancement computing of ocean HABs based on cyclic color
   compensation and multi-scale fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Harmful algal blooms; Enhancement computing; Cyclic color compensation;
   Multi-scale fusion
ID IMAGE-ENHANCEMENT
AB The clarity of algal images is crucial for solving problems such as harmful algal blooms (HABs) classification and red tide warning. However, the original underwater microscopic images of HABs often produce color distortion and blurred details due to the effects of seawater quality, illumination and image extraction techniques. To deal with the above problems, an enhancement computing method based on cyclic color compensation and three-image Multi-scale fusion is proposed in this paper. In this method, first, we propose a novel cyclic color compensation method to correct the color of the microscopic images of HABs. Then, with the input of three images derived from the color compensation versions of the original images of the algae, the correlation weight maps of the three inputs are redefined to facilitate the transfer of texture features and color contrast to the output images. Finally, to avoid image artifacts in the low-frequency components of the output image after the weight map transformation, a novel image Multi-scale fusion strategy is used in this paper. Qualitative and quantitative experimental results show that the underwater microscopic images of HABs enhanced with the method proposed in this paper have the best texture clarity and global contrast, and the method significantly improves the accuracy of transmission map estimation, edge detection and key point matching in processing algal images.
C1 [Wu, Geng-Kun; Xu, Jie; Zhang, Yi-Dan; Zhang, Bei-Ping] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Wu, Geng-Kun] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Technol, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Wu, GK (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.; Wu, GK (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Technol, Qingdao 266590, Peoples R China.
EM wugengkun@sdust.edu.cn
OI , Gengkun/0000-0002-8074-3431
FU Shandong Natural Science Foundation of China [ZR2021MD063]
FX AcknowledgmentsThe authors are grateful for the collaborative funding
   support from the Shandong Natural Science Foundation of China
   (ZR2021MD063).
CR Aggarwal A.K., 2022, Int J Biol Biomed, V7
   Aguirre-Castro OA, 2022, NEUROCOMPUTING, V494, P148, DOI 10.1016/j.neucom.2022.04.074
   Agusa Y., 2021, PROGR IMAGE PROCESSI, P339
   Akkaynak D, 2019, PROC CVPR IEEE, P1682, DOI 10.1109/CVPR.2019.00178
   Ancuti CO, 2018, IEEE T IMAGE PROCESS, V27, P379, DOI 10.1109/TIP.2017.2759252
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Azmi KZM, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105810
   Emberton S, 2018, COMPUT VIS IMAGE UND, V168, P145, DOI 10.1016/j.cviu.2017.08.003
   Finlayson GD, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P37
   Galdran A, 2015, J VIS COMMUN IMAGE R, V26, P132, DOI 10.1016/j.jvcir.2014.11.006
   Gao SB, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919947
   He JZ, 2019, PROC CVPR IEEE, P3823, DOI 10.1109/CVPR.2019.00395
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Huang RY, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.09.003
   Huo FS, 2021, IEEE INT CONF COMP V, P1944, DOI 10.1109/ICCVW54120.2021.00221
   Hussain MA, 2016, I C DEV ESYST ENG, P289, DOI 10.1109/DeSE.2016.45
   Kareem Hana H., 2019, IOP Conference Series: Materials Science and Engineering, V571, DOI 10.1088/1757-899X/571/1/012125
   Kumari Taruna, 2021, 2021INTERNATIONAL C, P1, DOI [10.1109/CCGE50943.2021.9776407, DOI 10.1109/CCGE50943.2021.9776407]
   Lee MS, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13020298
   Lee MS, 2020, INT J REMOTE SENS, V41, P5838, DOI 10.1080/01431161.2019.1706011
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Li YJ, 2019, OPT LASER TECHNOL, V110, P2, DOI 10.1016/j.optlastec.2017.09.017
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liu YB, 2020, IEEE ACCESS, V8, P91116, DOI 10.1109/ACCESS.2020.2994614
   Lu HM, 2017, MOBILE NETW APPL, V22, P1204, DOI 10.1007/s11036-017-0863-4
   Lu JY, 2019, OPT LASER TECHNOL, V110, P105, DOI 10.1016/j.optlastec.2018.05.048
   Luchman S, 2021, LECT NOTES COMPUT SC, V13055, P316, DOI 10.1007/978-3-030-89691-1_31
   Ma XM, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.5.053033
   Malik S, 2016, COMMUNICATIONS APPL
   Matos F, 2020, NUCL FUSION, V60, DOI 10.1088/1741-4326/ab6c7a
   Muniraj M, 2021, NEUROCOMPUTING, V460, P211, DOI 10.1016/j.neucom.2021.07.003
   Raveendran S, 2021, ARTIF INTELL REV, V54, P5413, DOI 10.1007/s10462-021-10025-z
   Saleh A., 2022, ARXIV
   Shi DX, 2021, LECT NOTES COMPUT SC, V13021, P29, DOI 10.1007/978-3-030-88010-1_3
   Sonali, 2019, OPT LASER TECHNOL, V110, P87, DOI 10.1016/j.optlastec.2018.06.061
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Soria X, 2020, IEEE WINT CONF APPL, P1912, DOI 10.1109/WACV45572.2020.9093290
   Thukral R, 2022, P INT C REC TRENDS C, P827, DOI DOI 10.1007/978-981-16-7118-0_70
   Thukral R, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT COMMUNICATION AND COMPUTATIONAL TECHNIQUES (ICCT), P161, DOI [10.1109/icct46177.2019.8969036, 10.1109/ICCT46177.2019.8969036]
   Yang M, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115723
NR 41
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16657
EP 16681
DI 10.1007/s11042-023-16258-0
EA JUL 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001030882700002
DA 2024-07-18
ER

PT J
AU Yang, L
   Shen, ZX
   Zeng, JJ
   Luo, X
   Lin, HF
AF Yang, Liang
   Shen, Zhexu
   Zeng, Jingjie
   Luo, Xi
   Lin, Hongfei
TI COSMIC: Music emotion recognition combining structure analysis and modal
   interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music emotion recognition; Musical structure analysis; Cross modal
   interaction
AB As a common multi-modal information carrier, music is frequently used to deliver emotions with lyrics and melodies. Besides lyrics (text) and melodies (audio), the structure of a song is another indicator of emotions creating a strong resonance for listeners. Typically, a pop song is composed of verses and choruses. To improve the performance of existing music emotion recognition models, we first propose a hierarchical model to analyze music structure. Then, a cross-modal interaction method is developed to extract and interact emotions from different modalities. Finally, we perform music emotion recognition by combining music structure analysis and cross-modal interaction. Adequate experiments are conducted on a dataset crawled from Netease Cloud Music, and results demonstrate the effectiveness of music structure analysis and cross-modal interaction. The proposed model COSMIC achieves state-of-the-art performance on music emotion recognition tasks.
C1 [Yang, Liang; Shen, Zhexu; Zeng, Jingjie; Luo, Xi; Lin, Hongfei] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Yang, L (corresponding author), Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
EM liang@dlut.edu.cn; szx@mail.dlut.edu.cn; jjwind@mail.dlut.edu.cn;
   luoxi@mail.dlut.edu.cn; hflin@dlut.edu.cn
CR Agrawal Yudhik, 2021, Advances in Information Retrieval. 43rd European Conference on IR Research, ECIR 2021. Proceedings. Lecture Notes in Computer Science (LNCS 12657), P167, DOI 10.1007/978-3-030-72240-1_12
   Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   [Anonymous], 2005, Deeper Than Reason: Emotion and Its Role in Literature, Music, and Art, DOI DOI 10.1093/0199263655.001.0001
   Baccianella S, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION
   Benward B, 1997, MUSIC THEORY PRACTIC, V7
   Bertin-Mahieux T., 2011, ISMIR, P591
   Bhattacharya, 2018, ARXIV
   Carr D., 2004, The Journal of Aesthetics and Art Criticism, V62, P225, DOI [10.1111/j.0021-8529.2004.00155.x, DOI 10.1111/JAAC.2004.62.ISSUE-3]
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Delbouys Remi., 2018, P 19 INT SOC MUS INF, P370
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dhariwal Prafulla, 2020, ARXIV
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Ferreira Lucas, 2019, Proceedings of the 20th International Society for Music Information Retrieval Conference (Delft, The Netherlands), P384, DOI [DOI 10.5281/ZENODO.3527824, 10 . 5281 / zenodo.3527824]
   Finnegan R, 2012, CULTURAL STUDY MUSIC, P375
   Garg A, 2022, MULTIMED TOOLS APPL, V81, P5137, DOI 10.1007/s11042-021-11650-0
   Han BJ, 2010, MULTIMED TOOLS APPL, V47, P433, DOI 10.1007/s11042-009-0332-6
   Hennequin R., 2020, J OPEN SOURCE SOFTW, V5, DOI [10.21105/joss.02154, DOI 10.21105/JOSS.02154]
   Hizlisoy S, 2021, ENG SCI TECHNOL, V24, P760, DOI 10.1016/j.jestch.2020.10.009
   Hung H., 2021, PROC 22 INT SOC MUSI, P318
   Jazi SY, 2021, MULTIMED TOOLS APPL, V80, P13559, DOI 10.1007/s11042-020-10386-7
   Jianchao Zhou, 2019, Proceedings of the 6th Conference on Sound and Music Technology (CSMT). Revised Selected Papers: Lecture Notes in Electrical Engineering (LNEE 568), P27, DOI 10.1007/978-981-13-8707-4_3
   Kumar V, 2013, INT CONF COMP COMMUN
   Laurier C, 2008, SEVENTH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS, PROCEEDINGS, P688, DOI 10.1109/ICMLA.2008.96
   Mo SS, 2019, IEEE T AFFECT COMPUT, V10, P313, DOI 10.1109/TAFFC.2017.2724515
   Panagakis Y, 2013, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2013-13
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Parisi L, 2019, ARXIV
   Rahman JS, 2021, J ARTIF INTELL SOFT, V11, P5, DOI 10.2478/jaiscr-2021-0001
   Shen Y., 2019, 7 INT C LEARNING REP
   Silva Panda RenatoEduardo., 2013, 10th International Symposium on Computer Music Multidisciplinary Research (CMMR 2013), P570, DOI DOI 10.1162/NECO.1997.9.8.1735
   Stein Deborah., 2005, Engaging Music: Essays in Music Analysis
   Won M, 2021, P 22 INT SOC MUSIC I, P777
   Won M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P591, DOI 10.1109/ICASSP39728.2021.9413514
   Xiong Y, 2017, IEEE INT CON MULTI, P961, DOI 10.1109/ICME.2017.8019341
   Xu M, 2015, CEUR WORKSHOP P, V1436
   Zhang KJ, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P135, DOI 10.1145/3206025.3206037
   Zhang M, 2023, MICROB BIOTECHNOL, V16, P448, DOI 10.1111/1751-7915.14100
   Zhang Y, 2022, P 23 INT SOC MUS INF, P19
   Zhao J, 2022, IEEE INT C MULT EXP, P1
NR 41
TC 1
Z9 1
U1 13
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12519
EP 12534
DI 10.1007/s11042-023-15376-z
EA JUL 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001025717900005
DA 2024-07-18
ER

PT J
AU Mundody, S
   Guddeti, RMR
AF Mundody, Sona
   Guddeti, Ram Mohana Reddy
TI A framework for low cost, ubiquitous and interactive smart refrigerator
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart Refrigerator; Night Vision; IR images; Natural Language
AB Internet of Things (IoT) and Artificial Intelligence (AI)-enabled technologies are essential in developing innovative environments and intelligent applications. IoT and AI-enabled appliances are entering our kitchens, adding more comfort and usability. However, these appliances are not economical and are beyond the reach of a commoner with a moderate income. An intelligent fridge is one such appliance. This paper proposes a design for developing a cost-effective, ubiquitous, and intelligent refrigerator. Unlike existing approaches, the proposed method identifies and predicts the fridge items based on Night Vision images and provides minimal natural language interaction with the fridge. The proposed design aims to convert any standard refrigerator into its more intelligent counterpart with minimal hardware and software requirements. The design allows users to view fridge contents on the go using a mobile application and interact with it using natural language. The transfer learning technique enables us to use a YOLOv5n model for object detection. As there are no publicly available Night Vision image datasets of fridge items, we created a custom dataset of Night Vision images to train and validate the object recognition model. Our model for object detection achieved a mAP of 97.1% compared to the YOLOv3-tiny and YOLOv4-tiny models, whose mAP are 94.8% and 96.3%, respectively. The overall cost of the refrigerator after deployment of the module is less than $300, making it an affordable option. The proposed framework meets most of the requirements of a low-cost, ubiquitous, interactive smart refrigerator.
C1 [Mundody, Sona; Guddeti, Ram Mohana Reddy] Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Mundody, S (corresponding author), Natl Inst Technol Karnataka, Dept Informat Technol, Mangalore, India.
EM sona.mndy@gmail.com; profgrmreddy@nitk.edu.in
OI Mundody, Sona/0000-0003-2724-6679
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Abid Y, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON ENERGY CONSERVATION AND EFFICIENCY (ICECE), P1
   Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/icaccs48705.2020.9074315, 10.1109/ICACCS48705.2020.9074315]
   Al-Sarawi S, 2020, PROCEEDINGS OF THE 2020 FOURTH WORLD CONFERENCE ON SMART TRENDS IN SYSTEMS, SECURITY AND SUSTAINABILITY (WORLDS4 2020), P449, DOI 10.1109/WorldS450073.2020.9210375
   Anand Gaurav, 2018, 2018 3rd International Conference on Contemporary Computing and Informatics (IC3I), P268, DOI 10.1109/IC3I44769.2018.9007271
   [Anonymous], 2021, ANDR PROF
   [Anonymous], 2022, INSTAVIEW DOOR IN DO
   [Anonymous], 2015, J MULTIDISCIP ENG SC
   Bansal T, 2021, 2021 8 INT C FUTURE, P163, DOI DOI 10.1109/FICLOUD49777.2021.00031
   Bayya M, 2019, TENCON IEEE REGION, P1702, DOI [10.1109/TENCON.2019.8929291, 10.1109/tencon.2019.8929291]
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cappelletti F, 2022, PROCEDIA COMPUT SCI, V200, P887, DOI 10.1016/j.procs.2022.01.286
   Fangbo Zhou, 2021, Proceedings of the 2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA), P6, DOI 10.1109/ICPECA51329.2021.9362711
   Ferrero R, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON RFID TECHNOLOGY AND APPLICATIONS (IEEE RFID-TA 2019), DOI [10.1109/rfid-ta.2019.8892025, 10.1109/RFID-TA.2019.8892025]
   Floarea AD, 2016, INT C ELECT COMPUT
   Gao X., 2019, P 2019 INT C ARTIFIC
   Gupta Shreya, 2021, 2021 International Conference on Advance Computing and Innovative Technologies in Engineering (ICACITE), P436, DOI 10.1109/ICACITE51222.2021.9404612
   Hossain S, 2018, 2ND INTERNATIONAL CONFERENCE ON SMART DIGITAL ENVIRONMENT (ICSDE'18), P15, DOI 10.1145/3289100.3289103
   Jain Pulkit, 2021, 2021 Second International Conference on Electronics and Sustainable Communication Systems (ICESC), P1852, DOI 10.1109/ICESC51422.2021.9532833
   Jiang Z., 2020, arXiv
   Kang J, 2022, MULTIMED TOOLS APPL, V81, P22355, DOI 10.1007/s11042-021-11282-4
   Kim I., 2016, TRANSPORTATION, V1, P3
   Krishnamoorthy R, 2021, MATER TODAY-PROC, V45, P2777, DOI 10.1016/j.matpr.2020.11.741
   Laker B., 2021, MIT Sloan Management Review
   Lakhan A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22165937
   Lakhan A, 2023, IEEE J BIOMED HEALTH, V27, P664, DOI 10.1109/JBHI.2022.3165945
   Lakhan A, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107839
   Lakhan A, 2023, J KING SAUD UNIV-COM, V35, P1, DOI 10.1016/j.jksuci.2021.11.009
   Lee TE, 2021, INT RELIAB PHY SYM, DOI 10.1109/IRPS46558.2021.9405189
   Li Y, 2020, CHI'20: EXTENDED ABSTRACTS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3334480.3375147
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mallikarjun B.C., 2020, 2020 INT C EM TECHN
   Mohammad I, 2020, P INT C COMPUTING AD, P1
   Nasir Haidawati, 2018, 2018 2nd International Conference on Smart Sensors and Application (ICSSA), P48, DOI 10.1109/ICSSA.2018.8535867
   Olivas E.S., 2009, Handbook of Research on Machine Learning Applications and Trends: Algorithms, Methods, and Techniques, DOI 10.4018/978-1-6056-6766-9&BUYLINK=TRUE
   Paszke A, 2019, ADV NEUR IN, V32
   Programme UE, 2021, UNEP FOOD WAST IND R
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Saha D, 2020, P 3 INT C ADV SCI TE
   Samsung, 2022, FAM HUB
   Song L, 2022, J SHANGHAI JIAOTONG, DOI [10.1007/s12204-022-2504-8, DOI 10.1007/S12204-022-2504-8]
   Stojkoska BLR, 2017, J CLEAN PROD, V140, P1454, DOI 10.1016/j.jclepro.2016.10.006
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   tensorflow, 2022, TENS LIT
   Tusor B, 2020, AUGMENTED SMART REFR, DOI [10.1007/978-3-030-36841-8_17, DOI 10.1007/978-3-030-36841-8_17]
   Tzutalin, 2015, LabelImg Free Software: MIT License
   Wang AL, 2018, FOOD RES INT, V114, P1, DOI 10.1016/j.foodres.2018.07.053
   Wang K, 2019, EKOLOJI, V28, P4873
   Wang XH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06965-3
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Yuting Zhou, 2021, 2021 International Conference on Signal Processing and Machine Learning (CONF-SPML), P290, DOI 10.1109/CONF-SPML54095.2021.00063
   Zhang WS, 2018, COMPUT IND, V95, P15, DOI 10.1016/j.compind.2017.09.001
   Zhongxu Dong, 2020, CNIOT2020: Proceedings of the 2020 International Conference on Computing, Networks and Internet of Things, P65, DOI 10.1145/3398329.3398338
   Zhuang FZ, 2021, P IEEE, V109, P43, DOI 10.1109/JPROC.2020.3004555
NR 55
TC 0
Z9 0
U1 6
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13337
EP 13368
DI 10.1007/s11042-023-15544-1
EA JUL 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700009
DA 2024-07-18
ER

PT J
AU Ohri, K
   Kumar, M
AF Ohri, Kriti
   Kumar, Mukesh
TI Supervised fine-tuned approach for automated detection of diabetic
   retinopathy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Supervised learning; Diabetic retinopathy; Supervised pre-training;
   Transfer learning; Fine-tuning; Convolutional neural network; Medical
   imaging; Visual interpretability
ID NEURAL-NETWORK
AB The factors that concern the current AI medical models are the lack of generalizing capability when they are subjected to clinical data and also the scarcity of labeled medical data from which they can learn. This paper studies the role of transfer learning by fine-tuning the network when different fractions of medical data are available at the downstream task of diabetic retinopathy (DR) severity detection. The experimental results signify that supervised pre-training on ImageNet, followed by fine-tuning on labeled domain-specific fundus images significantly improves the efficacy of the medical image classifier when trained on full training data thereby suggesting transfer learning works. But what is less known is how the fine-tuning performance is affected when subjected to different fractions of data and if the learning is label efficient. Hence, we investigate the performance of the model under different fractions of labeled data (20 %, 40 %, 60 %, and 80 % of the entire data) on DR classification task, the results suggest that supervised fine-tuning underperforms when model is trained under low data regime. The proposed model achieves test accuracy of 0.8010, AUC of 0.86, F1 score of 0.6477, and cohen kappa score of 0.7007 when trained on full training data but underperforms when subjected to low data regime. Thereby suggesting the limits of supervised learning when the model is trained using limited annotated data. Hence our work opens door to further research in achieving good performance at low data regimes.
C1 [Ohri, Kriti; Kumar, Mukesh] Natl Inst Technol Patna, Dept CSE, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ohri, K; Kumar, M (corresponding author), Natl Inst Technol Patna, Dept CSE, Patna 800005, Bihar, India.
EM kriti.ohri@gmail.com; mukesh.kumar@nitp.ac.in
RI Kumar, Mukesh/GNW-5893-2022
OI Kumar, Mukesh/0000-0001-5668-3419; Ohri, Kriti/0000-0002-6279-4147
CR Adak C, 2023, ARXIV
   Alyoubi W. L., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Alzubaidi L, 2021, CANCERS, V13, DOI 10.3390/cancers13071590
   Alzubaidi L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134523
   Azizi S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3458, DOI 10.1109/ICCV48922.2021.00346
   Bianco S, 2018, IEEE ACCESS, V6, P64270, DOI 10.1109/ACCESS.2018.2877890
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Castro DC, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17478-w
   Cavan D, 2017, DIABETES RES CLIN PR, V129, P16, DOI 10.1016/j.diabres.2017.03.023
   Chaudhary A., 2020, ILLUSTRATED SELF SUP
   Chen YP, 2017, ADV NEUR IN, V30
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Gabruseva T, 2020, IEEE COMPUT SOC CONF, P1436, DOI 10.1109/CVPRW50498.2020.00183
   Gifani P, 2021, INT J COMPUT ASS RAD, V16, P115, DOI 10.1007/s11548-020-02286-w
   Graziani M., 2019, IRISH MACHINE VISION
   Gu J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11151817
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Hagos MT, 2019, ARXIV
   Harangi B, 2019, IEEE ENG MED BIO, P2699, DOI [10.1109/embc.2019.8857073, 10.1109/EMBC.2019.8857073]
   Hart B., 2022, J OPEN SOURCE ED, V5
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang SQ, 2022, IEEE T MED IMAGING, V41, P1596, DOI 10.1109/TMI.2022.3143833
   Huynh BQ, 2016, J MED IMAGING, V3, DOI 10.1117/1.JMI.3.3.034501
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jampol LM, 2021, RETINA-J RET VIT DIS, V41, P459, DOI 10.1097/IAE.0000000000003070
   Jampol LM, 2020, NEW ENGL J MED, V382, P1629, DOI 10.1056/NEJMra1909637
   Jiwani N., 2022, PROC IEEE 11 INT C C, P357
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lam C., 2018, AMIA JT SUMMITS TRAN, V2017, P147
   Li F, 2022, EYE, V36, P1433, DOI 10.1038/s41433-021-01552-8
   Lin JK, 2021, IEEE SIGNAL PROC LET, V28, P454, DOI 10.1109/LSP.2021.3057548
   Liu Y, 2020, NAT MED, V26, P900, DOI 10.1038/s41591-020-0842-3
   Lones M.A., 2021, ARXIV
   McKinney SM, 2020, NATURE, V577, P89, DOI 10.1038/s41586-019-1799-6
   Ohri K, 2021, KNOWL-BASED SYST, V224, DOI 10.1016/j.knosys.2021.107090
   Porwal P, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101561
   Raghu M, 2019, ADV NEUR IN, V32
   Raschka S, 2020, METHODS, V180, P89, DOI 10.1016/j.ymeth.2020.06.016
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Selvachandran G, 2023, ARTIF INTELL REV, V56, P915, DOI 10.1007/s10462-022-10185-6
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shi Xu, 2021, arXiv
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Shurrab S., 2021, ARXIV
   Sikder N, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13040670
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stitt AW, 2016, PROG RETIN EYE RES, V51, P156, DOI 10.1016/j.preteyeres.2015.08.001
   Sun R, 2021, PROC CVPR IEEE, P10933, DOI 10.1109/CVPR46437.2021.01079
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tammina S, 2019, Int. J. Sci. Res. Publ, V9, P143, DOI DOI 10.29322/IJSRP.9.10.2019.P9420
   Tobin Josh., 2019, Troubleshooting Deep Neural Networks: A Field Guide to Fixing Your Model
   Truong Tuan, 2021, Proc Machine Learning Research, P54
   Tymchenko B, 2020, ARXIV
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang SL, 2015, NEUROCOMPUTING, V149, P708, DOI 10.1016/j.neucom.2014.07.059
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wang Z., 2018, WORKSH 32 AAAI C ART
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yehui Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P533, DOI 10.1007/978-3-319-66179-7_61
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 63
TC 5
Z9 5
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14259
EP 14280
DI 10.1007/s11042-023-16049-7
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023897700012
DA 2024-07-18
ER

PT J
AU Singh, SK
   Sinha, A
   Singh, H
   Mahanti, A
   Patel, A
   Mahajan, S
   Pandit, AK
   Varadarajan, V
AF Singh, Sanjay Kumar
   Sinha, Amit
   Singh, Harikesh
   Mahanti, Aniket
   Patel, Abhishek
   Mahajan, Shubham
   Pandit, Amit Kant
   Varadarajan, Vijayakumar
TI A novel deep learning-based technique for detecting prostate cancer in
   MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prostate cancer (PC); Magnetic resonance imaging (MRI);
   Prostate-specific antigen (PSA); Cancer grading; Targeted biopsy (TB);
   Deep learning
ID SEGMENTATION
AB In the western world,the prostate cancer is major cause of death in males. Magnetic Resonance Imaging (MRI) is widely used for the detection of prostate cancer due to which it is an open area of research. The proposed method uses deep learning framework for the detection of prostate cancer using the concept of Gleason grading of the historical images. A3D convolutional neural network has been used to observe the affected region and predicting the affected region with the help of Epithelial and the Gleason grading network. The proposed model has performed the state-of-art while detecting epithelial and the Gleason score simultaneously. The performance has been measured by considering all the slices of MRI, volumes of MRI with the test fold, and segmenting prostate cancer with help of Endorectal Coil for collecting the images of MRI of the prostate 3D CNN network. Experimentally, it was observed that the proposed deep learning approach has achieved overall specificity of 85% with an accuracy of 87% and sensitivity 89% over the patient-level for the different targeted MRI images of the challenge of the SPIE-AAPM-NCI Prostate dataset.
C1 [Singh, Sanjay Kumar] Guru Gobind Singh Indraprastha Univ, Univ Sch Automat & Robot, East Delhi Campus, Delhi, India.
   [Sinha, Amit] ABES Engn Coll, Dept Informat Technol, Ghaziabad, India.
   [Singh, Harikesh] JSS Acad Tech Educ, Dept Comp Sci & Engn, Noida, India.
   [Mahanti, Aniket] Univ Auckland, Sch Comp Sci, Auckland, New Zealand.
   [Patel, Abhishek] Finnove Technol, Kathmandu, Bagmati, Nepal.
   [Mahajan, Shubham; Pandit, Amit Kant] Shri Mata Vaishno Devi Univ, Katra, India.
   [Varadarajan, Vijayakumar] Univ New South Wales, Sydney, NSW, Australia.
C3 GGS Indraprastha University; University of Auckland; Shri Mata Vaishno
   Devi University; University of New South Wales Sydney
RP Mahanti, A (corresponding author), Univ Auckland, Sch Comp Sci, Auckland, New Zealand.
EM sanjayksingh.012@gmail.com; amit.sinha@abes.ac.in;
   harikeshsingh@yahoo.co.in; a.mahanti@auckland.ac.nz;
   abhishekpatelnp53@gmail.com; mahajanshubham2232579@gmail.com;
   amitkantpandit@gmail.com; v.varadarajan@unsw.edu.au
RI MAHAJAN, SHUBHAM/AAY-6389-2020; varadarajan, vijayakumar/K-8007-2017;
   Singh, Dr. Sanjay Kumar/I-7663-2016; Singh, Harikesh/ABB-9826-2020
OI MAHAJAN, SHUBHAM/0000-0003-0385-3933; Singh, Dr. Sanjay
   Kumar/0000-0002-7101-4341; Singh, Harikesh/0000-0003-2203-0828
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions
CR Artan Y, 2012, IEEE T INF TECHNOL B, V16, P1313, DOI 10.1109/TITB.2012.2201731
   Azizi S, 2018, IEEE T MED IMAGING, V37, P2695, DOI 10.1109/TMI.2018.2849959
   Brunese L, 2019, IEEE ACCESS, V7, P186236, DOI 10.1109/ACCESS.2019.2961754
   Cao RM, 2019, IEEE T MED IMAGING, V38, P2496, DOI 10.1109/TMI.2019.2901928
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng RD, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.4.041302
   Cheng RD, 2016, PROC SPIE, V9784, DOI 10.1117/12.2216286
   Clark K, 2013, J DIGIT IMAGING, V26, P1045, DOI 10.1007/s10278-013-9622-7
   Dai ZZ, 2020, ADV RADIAT ONCOL, V5, P473, DOI 10.1016/j.adro.2020.01.005
   Feng YJ, 2019, IEEE ACM T COMPUT BI, V16, P1794, DOI 10.1109/TCBB.2018.2835444
   Gorelick L, 2013, IEEE T MED IMAGING, V32, P1804, DOI 10.1109/TMI.2013.2265334
   Hamoen EHJ, 2015, EUR UROL, V67, P1112, DOI 10.1016/j.eururo.2014.10.033
   Hassanzadeh T, 2019, IEEE ACCESS, V7, P36748, DOI 10.1109/ACCESS.2019.2903284
   Hussain L, 2018, CANCER BIOMARK, V21, P393, DOI 10.3233/CBM-170643
   Ingale K., 2023, ICDSMLA 2021 P 3 RD
   Jansen BHE, 2021, EUR UROL ONCOL, V4, P821, DOI 10.1016/j.euo.2020.01.002
   Kasivisvanathan V, 2019, EUR UROL, V76, P284, DOI 10.1016/j.eururo.2019.04.043
   Kwak JT, 2017, PROC SPIE, V10140, DOI 10.1117/12.2253513
   Li WY, 2019, IEEE T MED IMAGING, V38, P945, DOI 10.1109/TMI.2018.2875868
   Litjens G, 2014, IEEE T MED IMAGING, V33, P1083, DOI 10.1109/TMI.2014.2303821
   Moradi M, 2009, IEEE T BIO-MED ENG, V56, P2214, DOI 10.1109/TBME.2008.2009766
   Schalk SG, 2017, IEEE T BIO-MED ENG, V64, P661, DOI 10.1109/TBME.2016.2571624
   Singh SK, 2020, IMAGING SCI J, V68, P41, DOI 10.1080/13682199.2020.1734306
   Singh SK, 2020, INT J HEALTHC INF SY, V15, P1, DOI 10.4018/IJHISI.2020040101
   Yan K, 2016, IEEE ENG MED BIO, P635, DOI 10.1109/EMBC.2016.7590782
   Yang MJ, 2013, IEEE T BIO-MED ENG, V60, P479, DOI 10.1109/TBME.2012.2228644
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang GK, 2019, IEEE ACCESS, V7, P131448, DOI 10.1109/ACCESS.2019.2939389
NR 29
TC 1
Z9 1
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14173
EP 14187
DI 10.1007/s11042-023-15793-0
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022083300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Dinç, B
   Kaya, Y
AF Dinc, Baris
   Kaya, Yasin
TI HBDFA: An intelligent nature-inspired computing with high-dimensional
   data analytics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary dragonfly algorithm; COVID-19; Text mining; Nature inspired
   algorithms; Feature selection
ID ARTIFICIAL BEE COLONY; FEATURE-SELECTION; OPTIMIZATION ALGORITHM
AB The rapid development of data science has led to the emergence of high-dimensional datasets in machine learning. The curse of dimensionality is a significant problem caused by high-dimensional data with a small sample size. This paper proposes a novel hybrid binary dragonfly algorithm (HBDFA) in which a distance-based similarity evaluation algorithm is embedded before the dragonfly algorithm (DA) searching behavior to select the most discriminating features. The two-step feature selection mechanism of HBDFA enables the method to explore the feature space reduced by the distance-based similarity evaluation algorithm. The model was evaluated on two datasets. The first dataset contained 200 reports from 4 evenly distributed categories of Daily Mail Online: COVID-19, economy, science, and sports. The second dataset was the publicly available Spam dataset. The proposed model is compared with binary versions of four popular metaheuristic algorithms. The model achieved an accuracy rate of 96.75% by reducing 66.5% of the top 100 features determined on the first dataset. Results on the Spam dataset reveal that HBDFA gives the best classification results with over 95% accuracy. The experimental results show the superiority of HBDFA in searching high-dimensional data, improving classification results, and reducing the number of selected features.
C1 [Dinc, Baris] Adana Alparslan Turkes Sci & Technol Univ, Dept Comp Engn, TR-01250 Adana, Turkiye.
   [Kaya, Yasin] Adana Alparslan Turkes Sci & Technol Univ, Dept Artificial Intelligence Engn, TR-01250 Adana, Turkiye.
C3 Adana Alparslan Turkes Science & Technology University; Adana Alparslan
   Turkes Science & Technology University
RP Kaya, Y (corresponding author), Adana Alparslan Turkes Sci & Technol Univ, Dept Artificial Intelligence Engn, TR-01250 Adana, Turkiye.
EM bdinc@atu.edu.tr; ykaya@atu.edu.tr
RI KAYA, Yasin/E-8858-2018
OI KAYA, Yasin/0000-0002-9074-0189
CR Abd El Aziz M, 2018, NEURAL COMPUT APPL, V29, P925, DOI 10.1007/s00521-016-2473-7
   Abdel-Basset M, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112824
   Abualigah L, 2021, INT J MACH LEARN CYB, V12, P783, DOI 10.1007/s13042-020-01202-7
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Abukhodair F, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9202627
   Akila S, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115828
   Alia A., 2016, Int J Innov Res Comput Commun Eng, V3, P7
   Almeida TA, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P259
   Arora S, 2019, EXPERT SYST APPL, V116, P147, DOI 10.1016/j.eswa.2018.08.051
   Arora S, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P220, DOI 10.1109/ISPCC.2015.7375029
   Asgarnezhad R, 2021, J SUPERCOMPUT, V77, P5806, DOI 10.1007/s11227-020-03490-w
   Bai XH, 2018, IEEE C EVOL COMPUTAT, P989, DOI 10.1109/CEC.2018.8477773
   Bolón-Canedo V, 2014, INFORM SCIENCES, V282, P111, DOI 10.1016/j.ins.2014.05.042
   Chantar Hamouda, 2021, SN Comput Sci, V2, P295, DOI 10.1007/s42979-021-00687-5
   Chatterjee S, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105027
   Chohra A, 2022, COMPUT SECUR, V117, DOI 10.1016/j.cose.2022.102684
   Cunningham S.J., 1997, APPL MACHINE LEARNIN
   Debie E, 2019, PATTERN ANAL APPL, V22, P519, DOI 10.1007/s10044-017-0649-0
   Do T.Hui., 2006, International Journal of Information Technology, V12, P59
   Emary E, 2016, NEUROCOMPUTING, V213, P54, DOI 10.1016/j.neucom.2016.03.101
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Esfandiari A, 2022, J AMB INTEL HUM COMP, P1
   Ewees AA, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9182321
   Gharehchopogh FS, 2022, EVOL INTELL, V15, P1777, DOI 10.1007/s12065-021-00590-1
   Gokalp O, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113176
   Hammouri AI, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106131
   Holland J. H., 1992, Scientific American (International Edition), V267, P44, DOI 10.1038/scientificamerican0792-66
   Hossny AH, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00658-3
   Hu P, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105746
   Hull DA, 1996, J AM SOC INFORM SCI, V47, P70, DOI 10.1002/(SICI)1097-4571(199601)47:1<70::AID-ASI7>3.0.CO;2-#
   Jain DK, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2021.102758
   Ji B, 2020, IEEE ACCESS, V8, P85989, DOI 10.1109/ACCESS.2020.2992752
   Jing LP, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P944, DOI 10.1109/ICMLC.2002.1174522
   kaggle, SPAM TEXT MESS CLASS
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaya Y, 2018, SIG PROCESS COMMUN
   Khan Aurangzeb, 2010, Journal of Advances in Information Technology, V1, P4, DOI 10.4304/jait.1.1.4-20
   Kiliç F, 2021, KNOWL-BASED SYST, V219, DOI 10.1016/j.knosys.2021.106894
   Kononenko I., 1994, EUR C MACH LEARN, V94, P171, DOI DOI 10.1007/3-540-57868-4_57
   Kumar Nikhil, 2020, Proceedings of Second International Conference on Inventive Research in Computing Applications (ICIRCA 2020), P108, DOI 10.1109/ICIRCA48905.2020.9183098
   Li JD, 2017, IEEE INTELL SYST, V32, P9, DOI 10.1109/MIS.2017.38
   Liu S, 2023, INFORM SCIENCES, V619, P679, DOI 10.1016/j.ins.2022.11.076
   Liu Z, 2022, 2022 IEEE INT C SYST, P2471, DOI [10.1109/SMC53654.2022.9945264, DOI 10.1109/SMC53654.2022.9945264]
   Long W, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107146
   LOVINS JB, 1968, MECH TRANSL, V11, P22
   Mafarja M, 2018, KNOWL-BASED SYST, V145, P25, DOI 10.1016/j.knosys.2017.12.037
   Mafarja MM, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P12, DOI 10.1109/ICTCS.2017.43
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Paice C., 2005, LANCASTER STEMMER
   Pan XY, 2023, LECT NOTE DATA ENG, V153, P475, DOI 10.1007/978-3-031-20738-9_54
   Pawlak Z, 2004, LECT NOTES COMPUT SC, V3100, P1
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Purushothaman R, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106651
   Rajammal RR, 2022, KNOWL-BASED SYST, V246, DOI 10.1016/j.knosys.2022.108701
   Rao H, 2019, APPL SOFT COMPUT, V74, P634, DOI 10.1016/j.asoc.2018.10.036
   Rodrigues D, 2013, IEEE INT SYMP CIRC S, P465, DOI 10.1109/ISCAS.2013.6571881
   Sadeghian Z, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104079
   Sakri SB, 2018, IEEE ACCESS, V6, P29637, DOI 10.1109/ACCESS.2018.2843443
   Sathiyabhama B, 2021, NEURAL COMPUT APPL, V33, P14583, DOI 10.1007/s00521-021-06099-z
   Sun LC, 2022, ENERGIES, V15, DOI 10.3390/en15103485
   Tubishat M, 2020, IEEE ACCESS, V8, P194303, DOI 10.1109/ACCESS.2020.3033757
   Tutkan M, 2016, INFORM PROCESS MANAG, V52, P885, DOI 10.1016/j.ipm.2016.03.007
   Uzer MS, 2013, SCI WORLD J, DOI 10.1155/2013/419187
   Wang J, 2022, SOFT COMPUT, V26, P9665, DOI 10.1007/s00500-022-06826-1
   WILBUR WJ, 1992, J INF SCI, V18, P45, DOI 10.1177/016555159201800106
   Wu JW, 2014, INTEGR COMPUT-AID E, V21, P35, DOI 10.3233/ICA-130446
   Xue Y, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106031
   Zhong CT, 2023, COMPUT BIOL MED, V153, DOI 10.1016/j.compbiomed.2022.106520
   Zorarpaci E, 2016, EXPERT SYST APPL, V62, P91, DOI 10.1016/j.eswa.2016.06.004
NR 69
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11573
EP 11592
DI 10.1007/s11042-023-16039-9
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100014
DA 2024-07-18
ER

PT J
AU Florindo, JB
   Abreu, E
AF Florindo, Joao B.
   Abreu, Eduardo
TI A pseudo-parabolic diffusion model to enhance deep neural texture
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture recognition; Partial Differential Equation (PDE); Convolutional
   neural networks; Image descriptors; PDE image; texture process
ID CLASSIFICATION; EQUATION; NETWORK; SCALE
AB In this work, we propose a methodology for texture recognition. The combination of deep learning with texture encoding techniques has demonstrated to be a powerful strategy to solve this problem. However, one of such encoding classically used in texture images, which are PDE operators, has not been explored in deep learning frameworks. Based on that, here we introduce a pseudo-parabolic diffusion operator to the pipeline of a convolutional neural network (CNN). The method is divided into 4 major stages: 1) application of the pseudo-parabolic operator to the image; 2) use of the resulting image as input to a pre-trained CNN; 3) extraction of local features from the last convolutional layer and pooling by Fisher vectors; 4) classification of the pooled features. Our approach is compared in a texture classification task and outperforms, in terms of classification accuracy, several state-of-the-art solutions. For example, in the challenging benchmark datasets KTH2b and FMD, the proposed method achieves classification accuracy of 79% and 81.8%, respectively. From the numerical viewpoint, we also highlight the key approximation and algorithmic aspects of our computational pseudo-parabolic diffusion modeling into the pipeline of a CNN to enhance deep neural texture features. In particular, the advantage over the plain CNN architecture is substantial. Such interesting performance can be justified by the capacity of the pseudo-parabolic operator to remove spurious noise while preserving important discontinuity information on the texture. The results also suggest the potential of our approach in real-world application, as attested on a practical application to the identification of plant species. In this specific task, our method achieves an accuracy of 94% and outperforms the state-of-the-art results. This is especially the case when we do not have access to a large amount of data for training and when the computational resources are limited, as our method do not involve any fine tuning.
C1 [Florindo, Joao B.; Abreu, Eduardo] Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque Holanda 651,Cidade Univ Zeferin, BR-13083859 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Florindo, JB (corresponding author), Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque Holanda 651,Cidade Univ Zeferin, BR-13083859 Campinas, SP, Brazil.
EM florindo@unicamp.br; eabreu@unicamp.br
OI Florindo, Joao/0000-0002-0071-0227; Abreu, Eduardo/0000-0003-1979-3082
FU Sao Paulo Research Foundation (FAPESP) [2020/01984-8, 2020/09838-0];
   National Council for Scientific and Technological Development, Brazil
   (CNPq) [306030/2019-5, 423292/2018-8]; National Council for Scientific
   and Technological Development - Brazil (CNPq) [306385/2019-8]
FX J. B. Florindo gratefully acknowledges the financial support of Sao
   Paulo Research Foundation (FAPESP) (Grants #2020/01984-8 and
   #2020/09838-0) and from National Council for Scientific and
   Technological Development, Brazil (CNPq) (Grants #306030/2019-5 and
   #423292/2018-8). E. Abreu gratefully acknowledges the financial support
   from National Council for Scientific and Technological Development -
   Brazil (CNPq) (Grant 306385/2019-8).
CR Abreu E, 2021, COMPUT MATH APPL, V102, P15, DOI 10.1016/j.camwa.2021.10.001
   Abreu E, 2020, J COMPUT PHYS, V411, DOI 10.1016/j.jcp.2020.109395
   Abreu E, 2017, MATH COMPUT SIMULAT, V137, P29, DOI 10.1016/j.matcom.2016.10.006
   Akiva P., 2022, P IEEE CVF C COMP VI, P8203
   Alkhatib M, 2019, IEEE T IMAGE PROCESS, V28, P5407, DOI 10.1109/TIP.2019.2916742
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Boudra S, 2022, APPL SOFT COMPUT, V118, DOI 10.1016/j.asoc.2022.108473
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Bu XY, 2019, PATTERN RECOGN, V91, P34, DOI 10.1016/j.patcog.2019.02.003
   Casanova D, 2009, INT J IMAG SYST TECH, V19, P236, DOI 10.1002/ima.20201
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Csurka G, 2011, COMM COM INF SC, V229, P28
   Deepalakshmi P, 2021, INT J INF SYST MODEL, V12, P1, DOI 10.4018/IJISMD.2021010101
   Donahue J, 2014, PR MACH LEARN RES, V32
   Düll WP, 2006, COMMUN PART DIFF EQ, V31, P1117, DOI 10.1080/03605300600781568
   Florindo Joao B., 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12743), P386, DOI 10.1007/978-3-030-77964-1_30
   Florindo JB, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115027
   Florindo JB, 2021, INFORM SCIENCES, V543, P296, DOI 10.1016/j.ins.2020.07.050
   Florindo JB, 2020, INFORM SCIENCES, V507, P356, DOI 10.1016/j.ins.2019.08.049
   Geron A., 2019, Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, V2
   Gonçalves WN, 2016, INFORM SCIENCES, V364, P51, DOI 10.1016/j.ins.2016.04.052
   Guidotti P, 2015, ADV STU P M, V67, P131
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Hazgui M, 2022, VISUAL COMPUT, V38, P457, DOI 10.1007/s00371-020-02028-8
   Kannala J, 2012, INT C PATT RECOG, P1363
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Kuznetsov I, 2022, NONLINEAR ANAL-REAL, V65, DOI 10.1016/j.nonrwa.2022.103509
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   LeVeque RJ, 2007, OTHER TITL APPL MATH, V98, P1, DOI 10.1137/1.9780898717839
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Mao SB, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2021.107817
   Mikelic A, 2010, J DIFFER EQUATIONS, V248, P1561, DOI 10.1016/j.jde.2009.11.022
   Neiva MB, 2018, INT J MOD PHYS C, V29, DOI 10.1142/S0129183118500717
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan ZB, 2019, EXPERT SYST APPL, V120, P319, DOI 10.1016/j.eswa.2018.11.041
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ranganath A, 2022, COMP M BIO BIO E-IV, V10, P145, DOI 10.1080/21681163.2021.1998925
   Saad Yousef., 2003, Iterative Methods for Sparse Linear Systems
   Seam N, 2011, NONLINEAR ANAL-REAL, V12, P2625, DOI 10.1016/j.nonrwa.2011.03.010
   Sharan L., 2009, J VISION, V9, P784, DOI 10.1167/9.8.784
   SHOWALTE.RE, 1969, STUD APPL MATH, P51
   Showalter R.E., 1970, SIAM J MATH ANAL, V1, P214, DOI DOI 10.1137/0501020
   SHOWALTER RE, 1975, J MATH ANAL APPL, V50, P183, DOI 10.1016/0022-247X(75)90047-5
   Showalter RE, 2010, HILBERT SPACE METHOD
   Shu X, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108843
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Song TC, 2021, INT C PATT RECOG, P1306, DOI 10.1109/ICPR48806.2021.9412962
   Song TC, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2019.113167
   Song TC, 2018, IEEE SIGNAL PROC LET, V25, P625, DOI 10.1109/LSP.2018.2809607
   Song TC, 2018, IEEE T CIRC SYST VID, V28, P1565, DOI 10.1109/TCSVT.2017.2671899
   Song Y, 2017, IEEE I CONF COMP VIS, P4922, DOI 10.1109/ICCV.2017.526
   Srinivasu PN, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/3169927
   Van Duijn CJ, 2007, SIAM J MATH ANAL, V39, P507, DOI 10.1137/05064518X
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Vieira J, 2022, MULTIMED TOOLS APPL, P1
   Wang G, 2022, REMOTE SENS-BASEL, V14
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Xiao B, 2019, IEEE T CIRC SYST VID, V29, P2796, DOI 10.1109/TCSVT.2018.2869841
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Xue J, 2018, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2018.00065
   Yang ZJ, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118223
   Zhai W, 2019, IEEE I CONF COMP VIS, P3612, DOI 10.1109/ICCV.2019.00371
   Zhang H, 2017, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR.2017.309
   Zhou YM, 2022, IEEE T INTELL TRANSP, V23, P16072, DOI 10.1109/TITS.2022.3147924
NR 70
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11507
EP 11528
DI 10.1007/s11042-023-15886-w
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100009
DA 2024-07-18
ER

PT J
AU Gu, XY
   Chen, JG
   Wu, GQ
   Wang, K
   Wang, JX
AF Gu, Xiangyuan
   Chen, Jianguo
   Wu, Guoqiang
   Wang, Kun
   Wang, Jiaxing
TI Feature subset selection algorithm based on symmetric uncertainty and
   interaction factor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature subset selection; Symmetric uncertainty; Interaction factor;
   Feature selection; Graph representation
ID MUTUAL INFORMATION; OPTIMIZATION; RELEVANCE
AB Since either only one metric is employed or two metrics are adopted and each of them is compared separately to measure redundant features, several existing feature subset selection algorithms cannot obtain the desired performance. To address the problem, a feature subset selection algorithm named symmetric uncertainty and interaction factor (SUIF) is presented. SUIF first exploits symmetric uncertainty to evaluate relevant features and removes irrelevant features. Then, it uses a graph theoretic representation to process these relevant features and removes some edges whose weights are some smaller values. Following that, it adopts Louvain community detection algorithm to cluster features into several clusters. Finally, it utilizes two metrics, symmetric uncertainty and interaction factor, and the method of equal interval division and ranking to evaluate features in each cluster, and removes redundant features. For validating the performance of SUIF, FCBF, INTERACT, FAST, SAOLA, NFCBF and EID-TII are exploited for comparison. Experimental results indicate that SUIF can obtain better feature selection performance.
C1 [Gu, Xiangyuan; Chen, Jianguo; Wu, Guoqiang; Wang, Kun; Wang, Jiaxing] Aerosp Times FeiHong Technol Co Ltd, Beijing 100094, Peoples R China.
RP Chen, JG (corresponding author), Aerosp Times FeiHong Technol Co Ltd, Beijing 100094, Peoples R China.
EM gxiangyuan@126.com
CR Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bolón-Canedo V, 2015, KNOWL-BASED SYST, V86, P33, DOI 10.1016/j.knosys.2015.05.014
   Bolón-Canedo V, 2013, KNOWL INF SYST, V34, P483, DOI 10.1007/s10115-012-0487-8
   Brown G, 2012, J MACH LEARN RES, V13, P27
   Dua D, 2019, UCI MACHINE LEARNING
   Ershadi MM, 2022, APPL SOFT COMPUT, V126, DOI 10.1016/j.asoc.2022.109293
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Fleuret F, 2004, J MACH LEARN RES, V5, P1531
   Gao WF, 2018, PATTERN RECOGN, V79, P328, DOI 10.1016/j.patcog.2018.02.020
   Grag M, 2022, EXPERT SYST APPL, V195
   Gu XY, 2022, NEURAL PROCESS LETT, V54, P2079, DOI 10.1007/s11063-021-10720-6
   Gu XY, 2022, APPL INTELL, V52, P1436, DOI 10.1007/s10489-021-02412-4
   Gu XY, 2021, SOFT COMPUT, V25, P8785, DOI 10.1007/s00500-021-05800-7
   [顾翔元 Gu Xiangyuan], 2021, [天津大学学报. 自然科学与工程技术版, Journal of Tianjin University], V54, P214
   Gu XY, 2021, APPL INTELL, V51, P2672, DOI 10.1007/s10489-020-01936-5
   Gu XY, 2020, SOFT COMPUT, V24, P333, DOI 10.1007/s00500-019-03910-x
   Gu XY, 2020, NEURAL PROCESS LETT, V51, P1237, DOI 10.1007/s11063-019-10144-3
   Gu X, 2019, MULTIMED TOOLS APPL, V78, P19681, DOI 10.1007/s11042-019-7285-1
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Maldonado J, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116822
   Moradi P, 2015, KNOWL-BASED SYST, V84, P144, DOI 10.1016/j.knosys.2015.04.007
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Piho L, 2020, IEEE T AFFECT COMPUT, V11, P722, DOI 10.1109/TAFFC.2018.2840973
   Preeti, 2022, EXPERT SYST APPL, V206, DOI 10.1016/j.eswa.2022.117864
   Song QB, 2013, IEEE T KNOWL DATA EN, V25, P1, DOI 10.1109/TKDE.2011.181
   Thirumoorthy K, 2021, PATTERN RECOGN LETT, V147, P63, DOI 10.1016/j.patrec.2021.03.034
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Wang LX, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115365
   Wang ZC, 2015, INFORM SCIENCES, V307, P73, DOI 10.1016/j.ins.2015.02.031
   Yin KX, 2023, APPL INTELL, V53, P8910, DOI 10.1007/s10489-022-03922-5
   Yu K, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2976744
   Yu K, 2014, IEEE DATA MINING, P660, DOI 10.1109/ICDM.2014.63
   Yu L, 2004, J MACH LEARN RES, V5, P1205
   [张俐 Zhang Li], 2018, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V41, P86
   Zhang YS, 2014, KNOWL-BASED SYST, V64, P70, DOI 10.1016/j.knosys.2014.03.022
   Zhao Z, 2009, INTELL DATA ANAL, V13, P207, DOI 10.3233/IDA-2009-0364
NR 38
TC 0
Z9 0
U1 6
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11247
EP 11260
DI 10.1007/s11042-023-15821-z
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900008
DA 2024-07-18
ER

PT J
AU Liu, ZH
   Cao, Y
   Lin, KJ
AF Liu, Zhenghui
   Cao, Yi
   Lin, Kejia
TI A watermarking-based authentication and recovery scheme for encrypted
   audio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermark; Encrypted audio; Content authentication; Tamper
   recovery
ID ROBUST; ALGORITHM; BLIND
AB To protect the audio stored on third-party servers, a novel authentication and recovery watermarking scheme for encrypted audio is proposed. We define the relative energy (RE) feature and analyze the characteristic of the feature. At the embedding stage, the host audio is encrypted firstly. Then the encrypted audio is divided into frames. We embed watermark bits into each frame by quantifying the RE feature. At the decoding stage, the receivers locate the attacked frames based on the watermark extraction and substitute the attacked frames using 0 amplitude signals, which are scattered over different segments after anti-scrambling transformation and do not influence the expressed meaning of watermarked signal. Experimental evaluation results demonstrate that the scheme improves the security of audio signals stored on third-party servers.
C1 [Liu, Zhenghui; Cao, Yi] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
   [Liu, Zhenghui] Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui] Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.
   [Liu, Zhenghui] Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510275, Peoples R China.
   [Lin, Kejia] Xinyang Normal Univ Lib, Xinyang 464000, Peoples R China.
C3 Xinyang Normal University
RP Liu, ZH (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.; Liu, ZH (corresponding author), Guangdong Key Lab Intelligent Informat Proc, Shenzhen 518060, Peoples R China.; Liu, ZH (corresponding author), Shenzhen Key Lab Media Secur, Shenzhen 518060, Peoples R China.; Liu, ZH (corresponding author), Guangdong Prov Key Lab Informat Secur Technol, Guangzhou 510275, Peoples R China.
EM zhenghui.liu@163.com
OI Liu, zhenghui/0000-0001-9460-8890
FU Science and Technology Research key Project of the Education Department
   of Henan Province [23A510002]; National Natural Science Foundation of
   Henan Province [232300420424]; Science and Technology Department of
   Henan Province [222102210265]; Opening Project of Guangdong Provincial
   Key Laboratory of Information Security Technology
FX AcknowledgmentsThis paper is supported by Science and Technology
   Research key Project of the Education Department of Henan Province(No.
   23A510002), National Natural Science Foundation of Henan Province (No.
   232300420424), Science and Technology Department of Henan Province (No.
   222102210265), and the Opening Project of Guangdong Provincial Key
   Laboratory of Information Security Technology (No.2020B1212060078-1). We
   would like to thank the anonymous reviewers for their constructive
   suggestions.
CR Bhat KV, 2011, CIRC SYST SIGNAL PR, V30, P915, DOI 10.1007/s00034-010-9255-8
   Jiang WZ, 2019, SIGNAL PROCESS, V162, P153, DOI 10.1016/j.sigpro.2019.04.017
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Li JX, 2022, SIGNAL PROCESS, V198, DOI 10.1016/j.sigpro.2022.108561
   Liang XY, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107584
   Liu ZH, 2017, MULTIMED TOOLS APPL, V76, P9297, DOI 10.1007/s11042-016-3533-9
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Liu ZH, 2014, DIGIT SIGNAL PROCESS, V24, P197, DOI 10.1016/j.dsp.2013.09.007
   Natgunanathan I, 2017, IEEE-ACM T AUDIO SPE, V25, P2176, DOI 10.1109/TASLP.2017.2749001
   Pun CM, 2013, IEEE T AUDIO SPEECH, V21, P2412, DOI 10.1109/TASL.2013.2279312
   Wang C, 2013, IEEE T COMPUT, V62, P362, DOI 10.1109/TC.2011.245
   Wang C, 2012, IEEE T SERV COMPUT, V5, P220, DOI 10.1109/TSC.2011.24
   Wang XY, 2016, AEU-INT J ELECTRON C, V70, P416, DOI 10.1016/j.aeue.2016.01.002
   Wang XY, 2011, COMPUT ELECTR ENG, V37, P425, DOI 10.1016/j.compeleceng.2011.05.011
   Wang Y., 2010, J ADV SIGNAL PROCESS, V2010, P1, DOI DOI 10.1016/J.PEPTIDES.2010.12.001
   Xiang SJ, 2017, ADV MULTIMED, V2017, DOI 10.1155/2017/8492672
   Zeng XT, 2010, PATTERN RECOGN, V43, P1656, DOI 10.1016/j.patcog.2009.09.016
   Zheng HC, 2019, SIGNAL PROCESS, V164, P74, DOI 10.1016/j.sigpro.2019.05.035
NR 18
TC 0
Z9 0
U1 6
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10969
EP 10987
DI 10.1007/s11042-023-16032-2
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800006
DA 2024-07-18
ER

PT J
AU Goncalves, VPM
   Silva, LP
   Nunes, FLS
   Ferreira, JE
   Araújo, LV
AF Goncalves, Vinicius P. M.
   Silva, Lourival P.
   Nunes, Fatima L. S.
   Ferreira, Joao E.
   Araujo, Luciano V.
TI Concept drift adaptation in video surveillance: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concept drift; Change detection; Surveillance; Video; Adaptation
ID DATA STREAMS; RECOGNITION
AB The world we live in is dynamic by nature. Frequently, the environment changes in ways we cannot predict. In machine learning, the phenomenon that occurs when a model has its prediction effectiveness degraded due to unforeseen changes is known as concept drift. Applications of smart video surveillance tend to suffer from concept drift due to changes in illumination, weather, and scene structure. This work differs from previous ones as it brings focus to the problem of concept drift from a surveillance video perspective which presents additional challenges compared to other sources of data, such as high dimensionality, spatial and temporal relations between data, and real-time constraints. The approaches and algorithms used to cope with concept drift are compared and discussed. We also present datasets and metrics used to evaluate the effectiveness of the algorithms.As contributions, we present a new classification of concept drift adaptation methods, delineate the characteristics and limitations of techniques that deal with concept drift, and analyze practical aspects, such as real-time processing and memory constraints. Moreover, we conclude that informed concept drift adaptation methods have been employed 90% less than continuous adaptation ones.Research directions include using established concept drift detection techniques applied to surveillance video data, exploring datasets for concept drift in surveillance, strategies to deal with the high dimensionality and volume of surveillance video data when adapting existing models, and the creation of frameworks to manage drift adaptation while applying computer vision tasks.
C1 [Goncalves, Vinicius P. M.; Silva, Lourival P.; Nunes, Fatima L. S.; Araujo, Luciano V.] Univ Sao Paulo, Sch Arts Sci & Humanities, Rua Arlindo Bettio 1000, BR-03828000 Sao Paulo, SP, Brazil.
   [Ferreira, Joao E.] Univ Sao Paulo, Inst Math & Stat, Rua Matao 1010, BR-05508090 Sao Paulo, SP, Brazil.
C3 Universidade de Sao Paulo; Universidade de Sao Paulo
RP Goncalves, VPM (corresponding author), Univ Sao Paulo, Sch Arts Sci & Humanities, Rua Arlindo Bettio 1000, BR-03828000 Sao Paulo, SP, Brazil.
EM viniciuspires.go@usp.br
RI Ferreira, Joao E/C-6025-2012; Ferreira, João E/L-1287-2016; ferreira,
   joao/JJE-8433-2023; Nunes, Fatima L S/C-4126-2012
CR Alahakoon D, 2000, IEEE T NEURAL NETWOR, V11, P601, DOI 10.1109/72.846732
   Alcantara MF, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013020
   Ali S, 2020, 2020 IEEE INT C IM P, P10
   [Anonymous], 2010, 2010 INT JOINT C NEU
   Anoopa S, 2022, KUWAIT J SCI, V6
   Baena-Garcia M, 2017, 4 ECML PKDD INT WORK, V6
   Bakliwal P, 2017, VISIGRAPP 2017 P 12, V6
   Baltieri D, 2011, MM 11 P 2011 ACM MUL
   Barddal JP, 2017, J SYST SOFTWARE, V127, P278, DOI 10.1016/j.jss.2016.07.005
   Barekatain M, 2017, IEEE COMPUT SOC CONF, P2153, DOI 10.1109/CVPRW.2017.267
   BARROW HG, 1981, P IEEE, V69, P572, DOI 10.1109/PROC.1981.12026
   Bastani V, 2016, IEEE T IMAGE PROCESS, V25, P2089, DOI 10.1109/TIP.2016.2540813
   Bialkowski A, 2012, 2012 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING TECHNIQUES AND APPLICATIONS (DICTA)
   Bifet A, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P443
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Campo D, 2020, P INT C IM PROC PROC
   Cao W, 2017, MEMET COMPUT, V9, P23, DOI 10.1007/s12293-016-0196-z
   Cao ZW, 2022, MULTIMED TOOLS APPL, V81, P42433, DOI 10.1007/s11042-022-13491-x
   Chaovalit P., 2005, HAWAII INT C SYSTEM, V4, p112c, DOI DOI 10.1109/HICSS.2005.445
   Chen H, 2016, 2016 12 WORLD CON IN, P6
   COCO Consortium, 2019, COC DET EV METR
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dalal N, 2005, P 2005 IEEE COMP SOC
   Ding SF, 2012, ARTIF INTELL REV, V37, P169, DOI 10.1007/s10462-011-9225-y
   Disabato S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851731
   Ditzler G, 2015, IEEE COMPUT INTELL M, V10, P12, DOI 10.1109/MCI.2015.2471196
   Dongre Priyanka B., 2014, 2014 IEEE International Advance Computing Conference (IACC), P533, DOI 10.1109/IAdCC.2014.6779381
   Doshi K, 2022, P 2022 IEEE CVF WINT, P1, DOI DOI 10.1109/IJCNN55064.2022.9891913
   Doshi K, 2022, IEEE COMPUT SOC CONF, P3888, DOI 10.1109/CVPRW56347.2022.00434
   Doshi K, 2020, IEEE COMPUT SOC CONF, P1025, DOI 10.1109/CVPRW50498.2020.00135
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang SC, 1995, PROCEEDINGS 1995 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, P170, DOI 10.1109/ISIT.1995.531519
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Fisher R, 2007, CAVIAR CONTEXT AWARE
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gama J., 2004, Lecture Notes in Computer Science, V3171
   Gama J, 2006, INTELL DATA ANAL, V10, P23, DOI 10.3233/IDA-2006-10103
   Gama J, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2523813
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gepperth A., 2016, EUROPEAN S ARTIFICIA
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goller C, 1996, IEEE IJCNN, P347, DOI 10.1109/ICNN.1996.548916
   Gonzalez J, 2021, EUR SIGNAL PR CONF, P781, DOI 10.23919/EUSIPCO54536.2021.9616296
   Goodfellow IJ, 2014, ADV NEURAL INFORM PR, V3
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Gozuack A, 2020, ARTIF INTELL REV
   Gray D, 2007, P IEEE INT WORKSH PE, P3
   Grimmeisen B, 2020, ACM INT C P
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   Hamdoun O, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P140
   Hampapur A, 2003, ICICS-PCM 2003, VOLS 1-3, PROCEEDINGS, P1133
   Hasan M, 2020, IEEE T PATTERN ANAL, V42, P554, DOI 10.1109/TPAMI.2018.2878696
   Hilsenbeck B, 2017, P 2016 IEEE INT S MU
   Hirzer M, 2011, LECT NOTES COMPUTER, V6688
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoogs A, 2008, PROC NATL CONF ARTIF, V3
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Hu B, 2019, J NANJING U AERONAUT, V51
   Huang XY, 2018, INT C PATT RECOG, P1683, DOI 10.1109/ICPR.2018.8546301
   Huang ZW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2493448
   Ismail MH, 2009, GEOGRAFIA-MALAYSIA, V01
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Joy F, 2021, IND J COMPUT SCI ENG, V12
   Khamassi I, 2018, EVOL SYST-GER, V9, P1, DOI 10.1007/s12530-016-9168-2
   Khan A., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P357, DOI 10.1109/DICTA.2010.67
   Kharabe SR, 2016, P 10 INDIACOM 2016 3
   Khoshrou S, 2015, MACH LEARN, V100, P609, DOI 10.1007/s10994-015-5515-y
   Kim W, 2021, LECT NOTES COMPUTER, V12667
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumari P, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P54, DOI 10.1109/BigMM50055.2020.00018
   Kwon B, 2022, IEEE ACCESS, V10, P89732, DOI 10.1109/ACCESS.2022.3201139
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li TY, 2020, INFORM FUSION, V60, P41, DOI 10.1016/j.inffus.2020.02.001
   Li W, 2014, IEEE IPCCC
   Lim C. P., 1995, Fourth International Conference on `Artificial Neural Networks' (Conf. Publ. No.409), P148, DOI 10.1049/cp:19950545
   Lin H., 2016, Proc. ACM MM, P536
   Lin HH, 2015, IEEE IMAGE PROC, P2434, DOI 10.1109/ICIP.2015.7351239
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lopez-Lopez E, 2021, 2020 25 INT C PATT R, P1
   Lopez-Lopez E, 2021, EXPERT SYST APPL, V174, DOI 10.1016/j.eswa.2021.114734
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu J, 2019, IEEE T KNOWL DATA EN, V31, P2346, DOI 10.1109/TKDE.2018.2876857
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Mahadevan V, 2010, PROC CVPR IEEE, P1975, DOI 10.1109/CVPR.2010.5539872
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Manoj krishna M., 2018, INT J ENG TECHNOL, P614, DOI DOI 10.14419/IJET.V7I2.7.10892
   Martinez Torres D., 2006, IMAGE VISION COMPUT, V89, P1, DOI [10.1007/BFb0053993, DOI 10.1007/BFB0053993]
   Martos G, 2013, PROGR PATTERN RECOGN, P125, DOI DOI 10.1007/978-3-642-41822-8_16
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]
   McCulloch W.S., 1988, LOGICAL CALCULUS IDE, P15
   Mehran R, 2011, UMN DATASET
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Nallaperuma D, 2019, IEEE T INTELL TRANSP, V20, P4679, DOI 10.1109/TITS.2019.2924883
   Nawaratne R, 2020, IEEE T IND INFORM, V16, P393, DOI 10.1109/TII.2019.2938527
   Nawaratne R, 2017, IEEE IND ELEC, P4790, DOI 10.1109/IECON.2017.8216826
   Nguyen DB, 2016, LECT NOTES I COMPUTE, V165
   Nguyen-Meidine L, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108771
   Norman TL, 2017, EFFECTIVE PHYS SECUR, p95 137, DOI DOI 10.1016/B978-0-12-804462-9.00006-3
   Oh S, 2011, IEEE IC COMP COM NET
   Pagano C., 2015, 4th International Conference on Pattern Recognition Applications and Methods (ICPRAM 2015). Proceedings, P45
   PAGE ES, 1954, BIOMETRIKA, V41, P100, DOI 10.1093/biomet/41.1-2.100
   Patino L, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P355, DOI 10.1109/AVSS.2014.6918694
   Patron-Perez A, 2010, BRIT MACHINE VISION
   Pérez-Sánchez B, 2018, ARTIF INTELL REV, V49, P281, DOI 10.1007/s10462-016-9526-2
   Pillai GV, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3072191
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raj SS, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103956
   Ramchandran A, 2020, MULTIMED TOOLS APPL, V79, P35275, DOI 10.1007/s11042-019-7702-5
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S, 2022, J AMBIENT INTELL HUM, V7
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Rodríguez-Moreno I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143160
   Rohrbach M, 2012, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2012.6247801
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Saito T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118432
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Saunier N, 2010, 93 ANN M TRANSP RES, P1
   Schlimmer J. C., 1986, Machine Learning, V1, P317, DOI 10.1023/A:1022810614389
   Schuldt C, 2017, PATT REC 2994 ICPR 2, V3
   Settles Burr, 2011, JMLR WORKSHOP C P, P1
   Shin DK, 2018, IEEE ACCESS, V6, P61748, DOI 10.1109/ACCESS.2018.2875720
   Shobha B. S., 2018, 2018 3rd International Conference on Computational Systems and Information Technology for Sustainable Solutions (CSITSS), P183, DOI 10.1109/CSITSS.2018.8768743
   Silverman BW., 1951, INT STAT REV REV INT, V57, P1989
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Soomro K., 2014, COMPUTER VISION SPOR, V71, P181, DOI [DOI 10.1007/978-3-319-09396-3_9, DOI 10.1007/978-3-319-09396-39]
   Soomro K, 2019, IEEE T PATTERN ANAL, V41, P459, DOI 10.1109/TPAMI.2018.2797266
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Staffs Keele, 2007, Tech. Rep.
   Stein S, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P729, DOI 10.1145/2493432.2493482
   Sugianto N, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909828
   Suprem A, 2020, PROC VLDB ENDOW, V13, P2453, DOI 10.14778/3407790.3407837
   Teng E, 2018, IEEE APP IMG PAT
   Thirde David., 2006, PROC 9 IEEE INT WORK, P47
   Tsoi AC, 1998, LECT NOTES ARTIF INT, V1387, P1, DOI 10.1007/BFb0053993
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   UCF University of Central Florida, 2011, UCF AER DAT
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Wang HY, 2017, PATTERN RECOGN, V67, P340, DOI 10.1016/j.patcog.2017.01.033
   Wang X, 2018, ICME, P1
   Wei LW, 2018, IEEE ICC
   Wei XS, 2013, IEEE SYMP COMP COMMU
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Widmer G, 1996, MACH LEARN, V23, P69, DOI 10.1023/A:1018046501280
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xie Y, 2011, IEEE INT CON MULTI
   Yang P, 2020, IEEE ACCESS, V8, P131723, DOI 10.1109/ACCESS.2020.3009876
   Yu F., 2018, ARXIV
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zheng L, 2017, IEEE INT C COMPUTER
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 167
TC 1
Z9 1
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9997
EP 10037
DI 10.1007/s11042-023-15855-3
EA JUN 2023
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400014
DA 2024-07-18
ER

PT J
AU Jain, MK
   Gopalani, D
   Meena, YK
AF Jain, Mayank Kumar
   Gopalani, Dinesh
   Meena, Yogesh Kumar
TI ConFake: fake news identification using content based features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Machine learning; Fake news; Linguistic features; Word
   embedding
ID DETECTING DECEPTION; WORDS; CUES
AB The majority of users were available on the Internet and created a number of social networking accounts during India's COVID-19-caused lockdown, which lasted from March to June 2020. A massive amount of information is currently being disseminated on the Internet via various social networking accounts. Some false or fake information in the form of "government letters or resolutions, religious comments, hate speech, and so on" has spread like wildfire. As a result, there are major social issues affecting areas such as unemployment, politics, healthcare, poverty, religious cleavages, etc. Due to the vast availability of similar datasets comprising these types of information, manual detection of fake news or false information is challenging. This issue requires immediate attention in terms of automatically finding false news. With this motivation, we present a novel 'ConFake' algorithm. This algorithm includes an eighty content-based feature set for identifying fake news. Content-based and word vector features extracted from the textual content of news stories were used in the experiment. These characteristics were combined and input into machine learning classifiers. To validate the experimental findings, we ran all of the experiments on five publicly available datasets and one synthetically generated ConFake dataset that combined five datasets, namely: Kaggle, McIntire, Reuter, BuzzFeed, and PolitiFact. The proposed model achieved the highest accuracy of 97.31% when compared to other cutting-edge models.
C1 [Jain, Mayank Kumar; Gopalani, Dinesh; Meena, Yogesh Kumar] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Jain, MK (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
EM mayank261288@gmail.com; dgopalani.cse@mnit.ac.in; ymeena.cse@mnit.ac.in
RI Jain, Mayank Kumar/AAQ-7677-2021
OI Jain, Mayank Kumar/0000-0002-5451-5339
CR Ahmed H, 2017, THESIS U VICTORIA
   Ahmed H, 2017, LECT NOTES COMPUT SC, V10618, P127, DOI 10.1007/978-3-319-69155-8_9
   Ajao O, 2018, SMSOCIETY'18: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON SOCIAL MEDIA AND SOCIETY, P226, DOI 10.1145/3217804.3217917
   Allcott H, 2017, J ECON PERSPECT, V31, P211, DOI 10.1257/jep.31.2.211
   [Anonymous], FAKE NEWS KAGGLE DAT
   [Anonymous], POLITIFACT NEWS DATA
   [Anonymous], ?About us"
   [Anonymous], VISWAS NEWS
   [Anonymous], MCINTIRE DATASET
   Faustini PHA, 2020, EXPERT SYST APPL, V158, DOI 10.1016/j.eswa.2020.113503
   Bezerra JFR, 2021, J INFORM TELECOMMUN, V5, P499, DOI 10.1080/24751839.2021.1963912
   Brasoveanu AMP, 2019, LECT NOTES COMPUT SC, V11506, P656, DOI 10.1007/978-3-030-20521-8_54
   Burgoon JK, 2003, LECT NOTES COMPUT SC, V2665, P91
   Choudhary A, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114171
   Del Vicario M, 2019, ACM T WEB, V13, DOI 10.1145/3316809
   Ghanem B, 2020, ACM T INTERNET TECHN, V20, DOI 10.1145/3381750
   Gilda S, 2017, IEEE ST CONF RES DEV, P110, DOI 10.1109/SCORED.2017.8305411
   Gogate M, 2017 IEEE S SERIES C, P1
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Horne B.D., 2017, 11 INT AAAI C WEB SO, P759, DOI DOI 10.1609/ICWSM.V11I1.14976
   Huang YF, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113584
   Jain Mayank Kumar, 2022, Emerging Technologies in Computer Engineering: Cognitive Computing and Intelligent IoT: 5th International Conference, ICETCE 2022, Revised Selected Papers. Communications in Computer and Information Science (1591), P395, DOI 10.1007/978-3-031-07012-9_34
   Jin ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P795, DOI 10.1145/3123266.3123454
   Jin ZW, 2017, IEEE T MULTIMEDIA, V19, P598, DOI 10.1109/TMM.2016.2617078
   Kaliyar RK, 2020, COGN SYST RES, V61, P32, DOI 10.1016/j.cogsys.2019.12.005
   Kaliyar RK, 2019, INT CONF ADV COMPU, P103, DOI [10.1109/IACC48062.2019.8971579, 10.1109/iacc48062.2019.8971579]
   Kaur S, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113350
   Khan JY, 2021, MACH LEARN APPL, V4, DOI 10.1016/j.mlwa.2021.100032
   Khattar D, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2915, DOI 10.1145/3308558.3313552
   Kumar Mahendra, 2020, 2020 IEEE 7th Uttar Pradesh Section International Conference on Electrical, Electronics and Computer Engineering (UPCON), DOI 10.1109/UPCON50219.2020.9376574
   Maan Manita, 2022, Emerging Technologies in Computer Engineering: Cognitive Computing and Intelligent IoT: 5th International Conference, ICETCE 2022, Revised Selected Papers. Communications in Computer and Information Science (1591), P259, DOI 10.1007/978-3-031-07012-9_23
   Meel P, 2020, EXPERT SYST APPL, V153, DOI 10.1016/j.eswa.2019.112986
   Newman ML, 2003, PERS SOC PSYCHOL B, V29, P665, DOI 10.1177/0146167203029005010
   Perez-Rosas V., 2017, ARXIV
   Qi P, 2019, IEEE DATA MINING, P518, DOI 10.1109/ICDM.2019.00062
   Ratner B., 2009, J. Target. Meas. Anal. Mark, V17, P139, DOI [10.1057/jt.2009.5, DOI 10.1057/JT.2009.5]
   Ravi K, 2017, KNOWL-BASED SYST, V120, P15, DOI 10.1016/j.knosys.2016.12.018
   Reddy H, 2020, INT J AUTOM COMPUT, V17, P210, DOI 10.1007/s11633-019-1216-5
   Reis JCS, 2019, PROCEEDINGS OF THE 11TH ACM CONFERENCE ON WEB SCIENCE (WEBSCI'19), P17, DOI 10.1145/3292522.3326027
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Ruchansky N, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P797, DOI 10.1145/3132847.3132877
   Saquete E, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112943
   Schwarz N., 2016, Behav Sci Policy, V2, P85, DOI [DOI 10.1177/237946151600200110, DOI 10.1353/BSP.2016.0009]
   Shah P, 2020, IEEE C EVOL COMPUTAT
   Sharma K, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3305260
   Shu K, 2020, BIG DATA, V8, P171, DOI 10.1089/big.2020.0062
   Shu K, 2019, PROCEEDINGS OF THE TWELFTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'19), P312, DOI 10.1145/3289600.3290994
   Shu K, 2019, COMPUT MATH ORGAN TH, V25, P60, DOI 10.1007/s10588-018-09280-3
   Silva RM, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2020.113199
   Singh Bali Arvinder Pal., 2019, International conference on advances in computing and data sciences, P420, DOI 10.1007/978-981-13-9942-8_40
   Singh V. K., 2017, INT C SOCIAL COMPUTI, P1, DOI [10.13140/RG.2.2.16825.67687, DOI 10.13140/RG.2.2.16825.67687]
   Singhal S, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P39, DOI [10.1109/BigMM.2019.00-44, 10.1109/BigMM.2019.00018]
   Tausczik YR, 2010, J LANG SOC PSYCHOL, V29, P24, DOI 10.1177/0261927X09351676
   Verma PK, 2021, IEEE T COMPUT SOC SY, V8, P881, DOI 10.1109/TCSS.2021.3068519
   Vishwakarma DK, 2019, COGN SYST RES, V58, P217, DOI 10.1016/j.cogsys.2019.07.004
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang YQ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P849, DOI 10.1145/3219819.3219903
   Wu YH, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106525
   Wynne HE, 2019, IIWAS2019: THE 21ST INTERNATIONAL CONFERENCE ON INFORMATION INTEGRATION AND WEB-BASED APPLICATIONS & SERVICES, P669, DOI 10.1145/3366030.3366116
   Yang YF, 2018, REPRESENTATION LEARNING FOR NLP, P164
   Zhou L, 2004, GROUP DECIS NEGOT, V13, P81, DOI 10.1023/B:GRUP.0000011944.62889.6f
   Zhou X., 2020, DIGITAL THREATS RES, V1, P1
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zhou XY, 2020, LECT NOTES ARTIF INT, V12085, P354, DOI 10.1007/978-3-030-47436-2_27
NR 65
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8729
EP 8755
DI 10.1007/s11042-023-15792-1
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000004
DA 2024-07-18
ER

PT J
AU Joshi, AB
   Kumar, D
   Kumar, S
   Singh, S
AF Joshi, Anand B.
   Kumar, Dhanesh
   Kumar, Sachin
   Singh, Sonali
TI A novel method of digital image encryption using graph theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image security; Graph theory; Image encryption; Decryption
AB This paper proposes a new technique for image data security using the concepts from graph theory. The proposed technique considers the pixels of the digital image as vertices of a graph and defines edges between vertices with some real weight to each edge. Using the minimal spanning tree (MST) and weighted adjacency matrix of MST, the encryption and decryption algorithm for the color digital image are proposed. The experimental results and the security analysis of the proposed technique are given to validate the feasibility and robustness of the proposed method. Statistical analysis like histogram, correlation, and entropy confirm the robustness of the proposed method against statistical attacks. The experimental results also show that the proposed technique is resistant to brute force and occlusion attacks.
C1 [Joshi, Anand B.; Kumar, Dhanesh; Singh, Sonali] Univ Lucknow, Dept Math & Astron, Lucknow 226007, UP, India.
   [Kumar, Sachin] Block 3,Old JNU Campus, New Delhi 110067, India.
C3 Lucknow University
RP Joshi, AB (corresponding author), Univ Lucknow, Dept Math & Astron, Lucknow 226007, UP, India.
EM anandiitd.joshi@gmail.com; dhaneshkumar.lu@gmail.com;
   skiitd09@gmail.com; singhsonali09192@gmail.com
RI Kumar, Dhanesh/JFA-1971-2023
OI Joshi, Anand Ballabh/0000-0003-0227-4032; KUMAR,
   DHANESH/0000-0002-6725-4772
CR Acharya B., 2007, INT J SECURITY, V1, P14
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Chen H, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106901
   Etaiwi WMA., 2014, J SCI RES REP, V3, P2519
   Faridnia S., 2010, IMAGE ENCRYPTION USI, P352
   Goel N, 2014, ADV MULTIMED, V2014, DOI 10.1155/2014/910106
   Guleria V, 2021, FRACTALS, V29, DOI 10.1142/S0218348X21501516
   Joshi AB, 2021, INT J IMAGE GRAPH, V21, DOI 10.1142/S0219467821500066
   Joshi AB, 2020, J MOD OPTIC, V67, P933, DOI 10.1080/09500340.2020.1789233
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Priyadarsini PLK, 2015, J DISCRET MATH SCI C, V18, P209, DOI 10.1080/09720529.2013.878819
   Rajput SK, 2017, OPT COMMUN, V388, P38, DOI 10.1016/j.optcom.2016.11.002
   Shafique A, 2020, WIRELESS PERS COMMUN, V115, P2243, DOI 10.1007/s11277-020-07680-w
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Sui LS, 2019, OPT LASER ENG, V122, P113, DOI 10.1016/j.optlaseng.2019.06.005
   Sun XN, 2021, MULTIMED TOOLS APPL, V80, P15825, DOI 10.1007/s11042-021-10550-7
   Taneja N, 2012, MULTIMED TOOLS APPL, V59, P775, DOI 10.1007/s11042-011-0775-4
   Taneja N, 2011, INT J WAVELETS MULTI, V9, P317, DOI 10.1142/S0219691311004092
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Tokareva N., 2014, CONNECTIONS GRAPH TH, P23
   Tokareva N, 2014, GRAPHS GROUPS CYCLES, P23
   Rehman AU, 2021, MULTIMED TOOLS APPL, V80, P21979, DOI 10.1007/s11042-021-10692-8
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yamuna M., 2015, INT J ADV RES SCI EN, V4, P128
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang W, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22010073
NR 29
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6803
EP 6828
DI 10.1007/s11042-023-15698-y
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010496600001
DA 2024-07-18
ER

PT J
AU Jindal, A
   Ghosh, R
AF Jindal, Amar
   Ghosh, Rajib
TI A hybrid deep learning model to recognize handwritten characters in
   ancient documents in Devanagari and Maithili scripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Character recognition; Ancient handwritten documents; Devanagari script;
   Maithili script; Hybrid deep learning model
AB Any optical character recognition (OCR) system recognizes each and every character present in any document image. But, the task of performing OCR in ancient handwritten document images is challenging due to the existence of faded text and dark spots in the ancient document images. The presence of intrinsic patterns of characters and large number of character classes in most of the Indian scripts make this task even more challenging. This research article proposes a novel hybrid deep learning based OCR method to recognize each character present in ancient handwritten document image written in two different Indian scripts, Devanagari and Maithili. Various discriminating features have been extracted from each character present in the document using several convolutional layers and each extracted feature vector has been classified into a proper character class using hybrid deep learning model. The hybrid deep learning model consists of one dense layer and several recurrently connected hidden layers. Both long-short-term-memory (LSTM) and Bidirectional-long-short-term-memory (Bi-LSTM) variants of recurrent neural network (RNN) have been employed in the portion of recurrently connected hidden layers of hybrid deep learning model. The performance of the proposed OCR method has been evaluated on two self-generated datasets of ancient handwritten document images in Devanagari and Maithili scripts. The proposed method has achieved the character recognition accuracy of 96.97 percent and 95.83 percent in Devanagari and Maithili scripts respectively. The experimental results demonstrate that the proposed OCR method outperforms the state-of-the-art methods in this regard.
C1 [Jindal, Amar; Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017; Jindal, Amar/IZP-7693-2023
OI GHOSH, RAJIB/0000-0002-8553-8656; Jindal, Amar/0000-0002-5442-6811
CR Arun M, 2022, NEURAL COMPUT APPL, V34, P12223, DOI 10.1007/s00521-022-07110-x
   Avadesh M, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P447, DOI 10.1109/DAS.2018.50
   Balaha HM, 2021, NEURAL COMPUT APPL, V33, P6325, DOI 10.1007/s00521-020-05397-2
   Cascianelli S, 2022, INT J DOC ANAL RECOG, DOI 10.1007/s10032-022-00401-y
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Coquenet D, 2023, IEEE T PATTERN ANAL, V45, P508, DOI 10.1109/TPAMI.2022.3144899
   Demilew FA, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1340-4
   fadhilAlsaffar M, MESOPOTAMIA ENV J
   Fekri-Ershad S, 2021, MULTIMED TOOLS APPL, V80, P12103, DOI 10.1007/s11042-020-10321-w
   Ghosh R, 2024, MULTIMED TOOLS APPL, V83, P7135, DOI 10.1007/s11042-023-15633-1
   Ghosh R, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117730
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P38643, DOI 10.1007/s11042-022-13068-8
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Granell E, 2020, NEUROCOMPUTING, V390, P12, DOI 10.1016/j.neucom.2020.01.081
   Granell E, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010015
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Jindal Amar, 2023, International Journal of Information Technology, P1975, DOI 10.1007/s41870-023-01247-1
   Jindal A, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120127
   Jindal A, 2023, MULTIMED TOOLS APPL, V82, P10703, DOI 10.1007/s11042-022-13709-y
   Kang L, 2022, PATTERN RECOGN, V129, DOI 10.1016/j.patcog.2022.108766
   Katsouros V, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P346, DOI 10.1109/DAS.2016.60
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Lakshmi TRV, 2017, ENG SCI TECHNOL, V20, P143, DOI 10.1016/j.jestch.2016.06.006
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Liu X, 2021, COMPUT INTEL NEUROSC
   Ly NT, 2020, PATTERN RECOGN LETT, V136, P134, DOI 10.1016/j.patrec.2020.05.026
   Ma LL, 2020, IEEE ACCESS, V8, P52641, DOI 10.1109/ACCESS.2020.2975023
   Markou K., 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12667), P249, DOI 10.1007/978-3-030-68787-8_18
   Mondal R, 2022, MULTIMED TOOLS APPL, V81, P975, DOI 10.1007/s11042-021-11425-7
   Mushtaq F, 2021, NEURAL COMPUT APPL, V33, P15229, DOI 10.1007/s00521-021-06144-x
   Narang S, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1126-9
   Narang SR, 2021, MULTIMED TOOLS APPL, V80, P20671, DOI 10.1007/s11042-021-10775-6
   Narang SR, 2020, SOFT COMPUT, V24, P17279, DOI 10.1007/s00500-020-05018-z
   Narang SR, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P215, DOI 10.1109/PDGC.2018.8745903
   Simistira F, 2015, PROC INT CONF DOC, P766, DOI 10.1109/ICDAR.2015.7333865
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek J, 2015, PR MACH LEARN RES, V37, P2171
   Suganya TS, 2020, SOFT COMPUT, V24, P10933, DOI 10.1007/s00500-019-04596-x
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Weldegebriel HT, 2020, IEEE ACCESS, V8, P17804, DOI 10.1109/ACCESS.2019.2960161
   Yousefi MR, 2015, PROC INT CONF DOC, P1121, DOI 10.1109/ICDAR.2015.7333935
NR 41
TC 2
Z9 2
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8389
EP 8412
DI 10.1007/s11042-023-15826-8
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012579700004
DA 2024-07-18
ER

PT J
AU Gedeon, KK
   Liu, Z
AF Gedeon, Kashala Kabe
   Liu, Zhe
TI Classification of liver lesions in CT images based on LivlesioNet,
   modified Multi-Scale CNN with bridge Scale method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural networks CNN; Multi-Scale; Liver
   lesion classification; Computed tomography (CT)
AB Liver cancer is one of main origins of death worldwide, and it is the second frequent cause of cancer-related deaths from men and the sixth from women. Deep learning techniques, and in particular convolutional neural networks (CNN) has led to very good performance on a variety of problems, such as image classification, speech recognition, and visual recognition with large-scale annotated datasets. However, collecting medical dataset is difficult and expensive task requires the collaboration of medical experts and researchers. In this paper, we propose a new method for classifying liver lesions based on small dataset. Our proposed method is demonstrated on a small liver lesions dataset of computed tomography (CT) images of 120 patients (30 Hepatocellular carcinoma, 23 metastases, 26 hemangiomas and 41 Healthy). We first use LivlesioNet based on DenseNet to extract feature from the input, in which the model produces the effective feature maps at each stage. Secondly, we propose the modified multi scale convolutional layer (MMS), which extract scale-invariant patterns with a dynamic selection of the convolutional kernels. Based on efforts from LivlesioNet and the modified multi scale convolutional layer, the number of parameters is decreased, and training with small dataset becomes realizable. Then, in order to improve the accuracy, a bridge scale (BS) is proposed to integrate multi-scale spatial features with the aim of removing the redundant features, and adjust weights of the features maps. In addition, after concatenate layer, a fully-connected layer and a SoftMax classifier are connected for further classification. The results indicate that the proposed method provides good results with 97.7% accuracy. It is also indicated that our proposed model achieves the best result in ternary classification.
C1 [Gedeon, Kashala Kabe; Liu, Zhe] Jiangsu Univ, Sch Comp & Commun Engn, Zhenjiang 212013, Peoples R China.
C3 Jiangsu University
RP Gedeon, KK (corresponding author), Jiangsu Univ, Sch Comp & Commun Engn, Zhenjiang 212013, Peoples R China.
EM gedeonkashala26@gmail.com; 1000004088@ujs.edu.cn
FU National Natural Science Foundation of China [61402204, 61572239,
   61772242]; Research Fund for Advanced Talents of Jiangsu University
   [14JDG141]; Qing Lan Project; China Postdoctoral Science Foundation
   [2017~M611737]; Zhenjiang social development project [SH2016029]
FX This work was supported by the National Natural Science Foundation of
   China (NO.61402204, 61572239 and 61772242) Research Fund for Advanced
   Talents of Jiangsu University (14JDG141); Qing Lan Project; China
   Postdoctoral Science Foundation (NO. 2017 & nbsp;M611737) Zhenjiang
   social development project (SH2016029).
CR Chang YH, 2017, IEEE ENG MED BIO, P672, DOI 10.1109/EMBC.2017.8036914
   Che H, 2021, INT J COMPUT ASS RAD, V16, P1537, DOI 10.1007/s11548-021-02414-0
   Cheema MN, 2019, IEEE T BIO-MED ENG, V66, P2641, DOI 10.1109/TBME.2019.2894123
   Chen YH, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105919
   Cheng NT, 2021, BIOSENS BIOELECTRON, V186, DOI 10.1016/j.bios.2021.113246
   Das B, 2022, BIOMED SIGNAL PROCES, V72, DOI 10.1016/j.bspc.2021.103317
   Feng XF, 2022, COMPUT METH PROG BIO, V215, DOI 10.1016/j.cmpb.2021.106598
   Gurian E, 2021, ANAL BIOANAL CHEM, V413, P1303, DOI 10.1007/s00216-020-03093-7
   Hashimoto N, 2020, PROC CVPR IEEE, P3851, DOI 10.1109/CVPR42600.2020.00391
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kabe GK, 2021, 5TH INTERNATIONAL CONFERENCE ON ALGORITHMS, COMPUTING AND SYSTEMS, ICACS 2021, P127, DOI 10.1145/3490700.3490721
   Kabe GK, 2022, MULTIMED TOOLS APPL, V81, P1607, DOI 10.1007/s11042-021-11411-z
   Kabe GK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081237
   Lee H, 2021, MED PHYS, V48, P5029, DOI 10.1002/mp.15118
   Li SH, 2019, LECT NOTES COMPUT SC, V11767, P531, DOI 10.1007/978-3-030-32251-9_58
   Li Y., 2019, ARXIV
   Lim G, 2020, PROC INT C TOOLS ART, P1096, DOI 10.1109/ICTAI50040.2020.00167
   Liu RN, 2020, IEEE T IND INFORM, V16, P3797, DOI 10.1109/TII.2019.2941868
   [刘晓虹 Liu Xiaohong], 2019, [计算机科学, Computer Science], V46, P125
   Lotter W, 2017, LECT NOTES COMPUT SC, V10553, P169, DOI 10.1007/978-3-319-67558-9_20
   marsbigdata.com, SEED PUBLIC COMPETIT
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Novak J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82214-3
   Romero FP, 2019, I S BIOMED IMAGING, P1243, DOI 10.1109/isbi.2019.8759257
   Xiang L, 2017, NEUROCOMPUTING, V267, P406, DOI 10.1016/j.neucom.2017.06.048
   Xie H, 2022, APPL SOFT COMPUT, V114, DOI 10.1016/j.asoc.2021.108156
   Xie LZ, 2020, KNOWL-BASED SYST, V208, DOI 10.1016/j.knosys.2020.106465
   Xu XY, 2020, KNOWL-BASED SYST, V189, DOI 10.1016/j.knosys.2019.105128
   Xu YJ, 2021, NEUROCOMPUTING, V443, P96, DOI 10.1016/j.neucom.2021.03.034
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Zhang S, 2023, ISA T, V133, P369, DOI 10.1016/j.isatra.2022.06.035
   Zhang YD, 2011, EXPERT SYST APPL, V38, P10049, DOI 10.1016/j.eswa.2011.02.012
   Zhen SH, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00680
   Zhou JR, 2021, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.581210
NR 37
TC 1
Z9 1
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8911
EP 8929
DI 10.1007/s11042-023-15966-x
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012326000008
DA 2024-07-18
ER

PT J
AU Shi, Y
   Jin, SS
   Zhao, L
   Wang, F
   Li, H
AF Shi, Yi
   Jin, Shanshan
   Zhao, Long
   Wang, Fei
   Li, Hui
TI Simulation of apple tree branch growth using an improved
   point-cloud-boundary-constraint model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Apple tree; Point cloud; Boundary constraint; Semi-Markov model; Branch
   growth simulation
AB The apple is a valuable commercial crop. Morphological information on and visual simulation of the apple plant are critical for precise and scientific field management during its growth period. However, the complex morphological structure of apple trees make it difficult to simulate the growth process. According to the pipeline model theory, branches play a key role in the growth process of apple trees. In this study, an improved semi-Markov-based point cloud boundary constraint is proposed to simulate the growth process of apple tree branches. To improve simulation accuracy, the point cloud data of the dormant, bud, strip-pulling, and leaf curtain stable stages of the apple tree were continuously collected, and the point cloud boundaries of various growing stages were extracted to obtain constrains for the growth process of branches. The results revealed that the improved semi-Markov-based point cloud boundary constraint model can achieve highly accurate simulation of the growth process of apple tree branches, with an average branch reconstruction rate of test samples in various growth periods and an average skeleton point coincidence rate of 93.0% and 90.8%, respectively.
C1 [Shi, Yi; Jin, Shanshan; Zhao, Long; Wang, Fei; Li, Hui] Henan Univ Sci & Technol, Coll Agr Equipment Engn, Luoyang, Peoples R China.
C3 Henan University of Science & Technology
RP Zhao, L (corresponding author), Henan Univ Sci & Technol, Coll Agr Equipment Engn, Luoyang, Peoples R China.
EM hkdzhaolong@163.com
RI Jin, Shanshan/AAB-7200-2019
FU Key Scientific Research Projects of Colleges and Universities in Henan
   Province [22B416002]; Key R&D and Promotion Projects in Henan Province
   (Science and Technology Development) [222102110452, 232102110264];
   Experimental Technology Development Fund Project of Henan University of
   Science and Technology [SY2021008]; PhD research startup foundation of
   Henan University of Science and Technology [13480033, 13480025]
FX AcknowledgementsThis study is supported by Key Scientific Research
   Projects of Colleges and Universities in Henan Province(Grand No.
   22B416002), Key R&D and Promotion Projects in Henan Province (Science
   and Technology Development) (Grand No. 222102110452 and Grand No.
   232102110264), Experimental Technology Development Fund Project of Henan
   University of Science and Technology(Grand No. SY2021008) and PhD
   research startup foundation of Henan University of Science and
   Technology (Grand No. 13480033 and Grand No. 13480025).
CR Bucksch A, 2008, ISPRS J PHOTOGRAMM, V63, P115, DOI 10.1016/j.isprsjprs.2007.10.004
   Chang C., 2019, COMPUT ENG DES, V40, P1349
   Costes E, 2003, ANN BOT-LONDON, V91, P91, DOI 10.1093/aob/mcg010
   Durand JB, 2005, NEW PHYTOL, V166, P813, DOI 10.1111/j.1469-8137.2005.01405.x
   HOLTON M, 1994, COMPUT GRAPH FORUM, V13, P57, DOI 10.1111/1467-8659.1310057
   HONDA H, 1971, J THEOR BIOL, V31, P331, DOI 10.1016/0022-5193(71)90191-3
   Jiang Z, 2009, STUDY SIMULATING VIR
   LINDENMAYER A, 1968, J THEOR BIOL, V18, P300, DOI 10.1016/0022-5193(68)90080-5
   Lintermann B, 1999, IEEE COMPUT GRAPH, V19, P56, DOI 10.1109/38.736469
   Liu Gang Liu Gang, 2014, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V45, P38
   Livny Y, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964948
   Prusinkiewicz P., 1990, The algorithmic beauty of plants, DOI [10.1007/978-1-4613-8476-2, DOI 10.1007/978-1-4613-8476-2]
   Quan L, 2006, ACM T GRAPHIC, V25, P599, DOI 10.1145/1141911.1141929
   Shinozaki K., 1964, JAPANESE J ECOL, V14, P133, DOI DOI 10.18960/SEITAI.14.4_133
   Shlyakhter I, 2001, IEEE COMPUT GRAPH, V21, P53, DOI 10.1109/38.920627
   Tan P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239538
   Wang D., 2016, J AGR MECH RES, V10, P187
   Wang K., 2018, MOD ELECT TECH, V41, P139
   Wang YT, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1761
   Xia YongJie Xia YongJie, 2019, Scientia Silvae Sinicae, V55, P108
   Xiong Y., 2009, J AGR MECH RES, V31, P70
   Zeng J, 2006, INT C INT SYST DES A
   [张建 Zhang Jian], 2013, [华中农业大学学报, Journal of Huazhong Agricultural University], V32, P126
   Zhang X., 2013, METEOROL SCI TECHNOL, V41, P1122
   [赵春江 Zhao Chunjiang], 2015, [中国农业科学, Scientia Agricultura Sinica], V48, P3415
NR 25
TC 0
Z9 0
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7417
EP 7432
DI 10.1007/s11042-023-15943-4
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001002295400001
DA 2024-07-18
ER

PT J
AU Ghosh, R
AF Ghosh, Rajib
TI Product identification in retail stores by combining faster r-cnn and
   recurrent neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shopping mall product identification; Text block detection; Text
   recognition; Faster R-CNN; Several RPNs; RNN
ID RECOGNITION; SYSTEM
AB Identifying various products on the racks of supermarkets is a very easy task for human beings. But, when the same identification task is given to a computer vision based system, it poses a huge challenge for it. This article proposes a method to identify various products on the racks of supermarkets by detecting the text blocks in product labels using Faster R-CNN with more than one region proposal networks (RPNs) and then recognizing the text using Recurrent Neural Network (RNN) classifier. To detect the varying sized text blocks in product labels, several diverse sized RPNs have been proposed in this investigation. The traditional Faster R-CNN creates regions-of-interest (ROIs) using a sole RPN and so remains unable to detect the labels with diverse sized text blocks accurately. The novelty of this work lies in proposing more than one diverse sized RPNs in the traditional Faster R-CNN to detect the text blocks in the product labels and recognizing the text using RNN classifier. Three different public datasets, namely GroZi-120, Grocery Products, and Grocery Dataset have been used to assess the performance of this work and it outperforms state-of-the-art results on text block detection. The proposed system has provided the text recognition accuracies of 99.18%, 99.21%, and 99.12% for GroZi-120, Grocery Products, and Grocery Dataset respectively.
C1 [Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna 800005, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017
OI GHOSH, RAJIB/0000-0002-8553-8656
CR [Anonymous], 2010, 2010 IEEE COMP SOC C
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Cleveland J, 2017, IEEE T AUTOM SCI ENG, V14, P820, DOI 10.1109/TASE.2016.2631085
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Franco A, 2017, EXPERT SYST APPL, V81, P163, DOI 10.1016/j.eswa.2017.02.050
   Fritz M, 2005, IEEE I CONF COMP VIS, P1363
   George M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P546, DOI 10.1109/ICCVW.2015.77
   George M, 2014, LECT NOTES COMPUT SC, V8690, P440, DOI 10.1007/978-3-319-10605-2_29
   Ghosh R, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117730
   Ghosh R, 2021, MULTIMED TOOLS APPL, V80, P25985, DOI 10.1007/s11042-021-10954-5
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hu B, 2020, IEEE ACCESS, V8, P19336, DOI 10.1109/ACCESS.2020.2967090
   Karlinsky L, 2017, PROC CVPR IEEE, P965, DOI 10.1109/CVPR.2017.109
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liu S, 2015, IEEE INT SYM MULTIM, P27, DOI 10.1109/ISM.2015.72
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marder M, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2394513
   Merler M, 2007, PROC CVPR IEEE, P3634
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saran A, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P576, DOI 10.1109/MVA.2015.7153257
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tonioni A, 2017, LECT NOTES COMPUT SC, V10484, P682, DOI 10.1007/978-3-319-68560-1_61
   Umer S, 2021, MULTIMED TOOLS APPL, V80, P34997, DOI 10.1007/s11042-020-09079-y
   Varol G, 2015, PROC SPIE, V9443, DOI 10.1117/12.2179127
   Varol G, 2014, SIG PROCESS COMMUN, P1031, DOI 10.1109/SIU.2014.6830408
   Yörük E, 2016, INT C PATT RECOG, P1352, DOI 10.1109/ICPR.2016.7899825
   Zhang Q, 2016, J SENSORS, V2016, DOI 10.1155/2016/6937852
   Zientara P, 2017, IEEE CONSUM ELECTR M, V6, P73, DOI 10.1109/MCE.2016.2614422
NR 31
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7135
EP 7158
DI 10.1007/s11042-023-15633-1
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003562600006
DA 2024-07-18
ER

PT J
AU Al-Karawi, KA
AF Al-Karawi, Khamis A.
TI Face mask effects on speaker verification performance in the presence of
   noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Background noise; Face mask; Speaker verification; MFCC; i-vector
ID RECOGNITION
AB Due to its spread via physical contact and the regulations on wearing face masks, COVID-19 has resulted in tough challenges for speaker recognition. Masks may aid in preventing COVID-19 transmission, although the implications of the mask on system performance in a clean environment and with varying levels of background noise are unclear. The face mask has an impact on speech output. The task of comprehending speech while wearing a face mask is made more difficult by the mask's frequency response and radiation qualities, which is vary depending on the material and design of the mask. In this study, we recorded speech while wearing a face mask to see how different masks affected a state-of-the-art text-independent speaker verification system using an i-vector speaker identification system. This research investigates the influence of facial coverings on speaker verification. To address this, we investigated the effect of fabric masks on speaker identification in a cafeteria setting. These results present preliminary speaker recognition rates as well as mask verification trials. The result shows that masks had little to no effect in low background noise, with an EER of 2.4-2.5% in 20 dB SNR for both masks compared to no mask at the same level. In noisy conditions, accuracy was 12.7-13.0% lowers than without a mask with a 5 dB SNR, indicating that while different masks perform similarly in low background noise levels, they become more noticeable in high noise levels.
C1 [Al-Karawi, Khamis A.] Diyala Univ, Baqubah, Diyala, Iraq.
C3 University of Diyala
RP Al-Karawi, KA (corresponding author), Diyala Univ, Baqubah, Diyala, Iraq.
EM Alkasi_68@yahoo.com
RI AL-KARAWI, Khamis A./AGB-6700-2022
OI AL-KARAWI, Khamis A./0000-0001-9275-6902
CR Al-Karawi K, 2018, ROBUST SPEAKER RECOG
   Al-Karawi Khamis A., 2015, International Journal of Information and Electronics Engineering, V5, P423, DOI 10.7763/IJIEE.2015.V5.571
   Al-Karawi KA, 2020, INT J SPEECH TECHNOL, P1
   Al-Karawi KA, 2021, MULTIMED TOOLS APPL, P1
   Al-karawi KA, 2021, MULTIMED TOOLS APPL, V80, P22231, DOI 10.1007/s11042-021-10767-6
   Al-Karawi KA, 2019, INT J SPEECH TECHNOL, V22, P1077, DOI 10.1007/s10772-019-09648-z
   Al-Karawi KA, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P52, DOI 10.1109/INTECH.2017.8102427
   Alenizi Abdulrahman S., 2022, Proceedings of Sixth International Congress on Information and Communication Technology: ICICT 2021. Lecture Notes in Networks and Systems (216), P149, DOI 10.1007/978-981-16-1781-2_15
   [Anonymous], 2000, HTK BOOK HTK VERSION
   [Anonymous], 2001, 2001 SPEAK OD THE SP
   [Anonymous], 2013, Msr identity toolbox
   Boles A, 2017, 2017 12TH SYSTEM OF SYSTEMS ENGINEERING CONFERENCE (SOSE)
   Chen YW, 2006, STUD FUZZ SOFT COMP, V207, P315
   Chu DK, 2020, LANCET, V395, P1973, DOI 10.1016/S0140-6736(20)31142-9
   Das RK, 2020, ASIAPAC SIGN INFO PR, P747
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1527
   Doddington GR, 2000, SPEECH COMMUN, V31, P225, DOI 10.1016/S0167-6393(99)00080-1
   Nguyen DD, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85130-8
   Fecher N, 2014, EFFECTS FORENSICALLY
   Ghitza O, 1994, IEEE T SPEECH AUDI P, V2, P115, DOI 10.1109/89.260357
   Llamas Carmen, 2009, EFFECTS DIFFERENT TY
   Logan B., 2000, ISMIR, V270, P11
   Malone V., SPEAKER RECOGNITION
   Mendel LL, 2008, J AM ACAD AUDIOL, V19, P686, DOI 10.3766/jaaa.19.9.4
   Mohamed MM, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108361
   Mohammed D. Y., 2021, Bulletin of Electrical Engineering and Informatics, V10, P2310
   Mohammed DY, 2020, 2 INT C PERS TECHN, P95
   NUTE ME, 1973, J TEXT I, V64, P652, DOI 10.1080/00405007308630315
   Pelecanos J., 2001, Proc. Speaker Odyssey, V13, P1
   Qi J, 2013, INTERSPEECH, P1750
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Saeidi R, 2015, SPEAKER RECOGNITION
   Saeidi R, 2016, INTERSPEECH, P1800, DOI 10.21437/Interspeech.2016-518
   Shao Y, 2006, INT CONF ACOUST SPEE, P645
   Toscano JC, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0246842
   van Doremalen N, 2020, NEW ENGL J MED, V382, P1564, DOI [10.1056/NEJMc2004973, 10.1101/2020.03.09.20033217]
   VanDam M, 2014, J ACOUST SOC AM, V136, pEL263, DOI 10.1121/1.4895015
   Wittum K.J., 2013, Proc. Mtgs. Acoust, V19, P060125, DOI DOI 10.1121/1.4800719
   Wu PS, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104341
   Zhang CL, 2008, FORENSIC SCI INT, V175, P118, DOI 10.1016/j.forsciint.2007.05.019
NR 42
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 29
PY 2023
DI 10.1007/s11042-023-15824-w
EA MAY 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H8LP5
UT WOS:000998414300009
PM 37362700
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Yuan, YL
   Yang, JZ
   Sun, Q
   Huang, Y
   Ma, S
AF Yuan, Yuliang
   Yang, JinZhu
   Sun, Qi
   Huang, Yan
   Ma, Shuang
TI Cinematic volume rendering algorithm based on multiple lights photon
   mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cinematic rendering; Photon mapping; Volume rendering; Monte Carlo
AB Cinematic volume rendering, which can obtain highly realistic rendering results, is considered to be the next-generation volume rendering technology. Cinematic volume rendering generally uses ray tracing algorithms to build a global illumination model for rendering. In the rendering process, the convergence speed of ray tracing is slow, and the physically-based global illumination model is computationally expensive. Moreover, when the rendered sampling interval is not very large, there are problems such as random noise in the rendered image. This paper proposes a Cinematic volume rendering algorithm based on photon mapping. Using the illumination model defined by the algorithm, the rendering quality can be guaranteed, and there is no random noise. The algorithm can support multi-light illumination while under the influence of multiple lights. It can effectively enhance the depth and shape of the region of interest perception. We have implemented a fast photon mapping system for medical imaging. We test the algorithm under GPU, the multi-light rendering results are realistic, and the interaction reaches the level of interactive frames.
C1 [Yuan, Yuliang; Yang, JinZhu; Sun, Qi; Huang, Yan; Ma, Shuang] Northeastern Univ, Sch Comp Sci & Engn, Shenyang, Liaoning, Peoples R China.
C3 Northeastern University - China
RP Yang, JZ (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang, Liaoning, Peoples R China.
EM yangjinzhu@cse.neu.edu.cn
CR Avro J, 1990, SIGGRAPH 90 P 17 C C, P63, DOI [10.1145/97879.97886, DOI 10.1145/97879.97886]
   Christensen P, 2008, 0801 PIX
   Comaniciu D, 2016, SHAPING FUTURE INNOV, DOI [10.1016/j.media.2016.06.016, DOI 10.1016/J.MEDIA.2016.06.016]
   Dappa E, 2016, INSIGHTS IMAGING, V7, P849, DOI 10.1007/s13244-016-0518-1
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Hachisuka T., 2008, ACM T GRAPHIC, V27, P1, DOI [DOI 10.1145/1457515.1409083, DOI 10.1145/1360612.1360632]
   Iglesias-Guitian JA, 2022, IEEE T VIS COMPUT GR, V28, P2734, DOI 10.1109/TVCG.2020.3037680
   Jensen HW, 1995, SPRING COMP SCI, P326, DOI 10.1007/978-3-7091-9430-0_31
   Khalil Azira, 2017, 2017 International Conference on Applied System Innovation (ICASI). Proceedings, P629, DOI 10.1109/ICASI.2017.7988504
   Kroes T, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0038586
   Kwon K, 2020, COMPUT BIOL MED, V117, DOI 10.1016/j.compbiomed.2020.103608
   Lafortune EP, 1993, BIDIRECTIONAL PATH T, DOI [10.1007/978-4-431-68057-4_21, DOI 10.1007/978-4-431-68057-4_21]
   Mukunoki D, 2014, LECT NOTES COMPUT SC, V8384, P632, DOI 10.1007/978-3-642-55224-3_59
   Salama CR, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P411, DOI 10.1109/PG.2007.27
   Veach E., 1995, Photorealistic Rendering Techniques, P145
   Zhang YB, 2013, IEEE T VIS COMPUT GR, V19, P2946, DOI 10.1109/TVCG.2013.172
NR 16
TC 1
Z9 1
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15075-9
EA MAY 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3NP9
UT WOS:000995070900008
DA 2024-07-18
ER

PT J
AU Wu, XC
   Zeng, XQ
   Lu, XX
   Zhang, KM
AF Wu, XiangChen
   Zeng, Xiaoqin
   Lu, Xiaoxiang
   Zhang, Keman
TI Step detection in complex walking environments based on continuous
   wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Step detection; Wavelet transform; Pedestrian dead reckoning; Inertial
   measurement unit
ID GAIT RECOGNITION; SENSORS
AB The existing algorithms for step detection have rarely been designed for walking in complex scenes. Complex scenes often bring about more complicated changes in walking states that could cause ordinary detection algorithms less effective. In this paper, an observation is made that there are gatherings of low-frequency signals, called clusters, in the spectrogram generated from the walking signal in a particular situation through wavelet transform. The clusters would exhibit prominent features when some specific basis function is chosen for the wavelet transform, which can precisely characterize the strides in walking. Then, the criteria for choosing the basis function of wavelet transform are established and verified experimentally. Based on the spectral features, an efficient and accurate step detection algorithm named frequency domain extension detection (FDED) is proposed and its time/space complexity will be no more than the constant times of its input size, O(n). FDED consists of three phases. First, the Kalman filter is adopted to denoise the raw data. Then, a continuous wavelet transform is applied to the filtered data to attain the obvious gait pattern in the time spectrum. Finally, a robust detection algorithm is proposed to implement step counting and single-stride segmentation. The experiments are conducted on two datasets, Diecui, a self-established dataset with diverse walking patterns in complex scenes, and a public dataset, ZJU-gaitacc. The experimental results show that FDED achieves an average accuracy of 99.1% for step counting on Diecui, and outperforms several representative detection algorithms on ZJU-gaitacc, which suggests that the proposed algorithm possesses strong adaptability in complex scenes with diverse personnel.
C1 [Wu, XiangChen; Zeng, Xiaoqin; Lu, Xiaoxiang; Zhang, Keman] Hohai Univ, Sch Comp & Informat, Inst Intelligence Sci & Technol, Nanjing 211100, Peoples R China.
C3 Hohai University
RP Wu, XC (corresponding author), Hohai Univ, Sch Comp & Informat, Inst Intelligence Sci & Technol, Nanjing 211100, Peoples R China.
EM wxc@hhu.edu.cn; xzeng@hhu.edu.cn; luxx0824@hhu.edu.cn
RI sun, chen/JCP-0396-2023; li, tao/JVO-9006-2024; Zhang,
   Yun/JCN-7026-2023; Li, siqi/KDN-4520-2024; wang, jun/JPY-3635-2023;
   Wang, Jing/JRW-1512-2023; Li, Yan/JUU-5189-2023; li, yuan/KBQ-4200-2024;
   you, li/KHW-2201-2024; Li, Wen/JQI-4757-2023; zhao, yan/JNT-6961-2023;
   Zhou, Yue/JHS-8791-2023; Liu, Jie/JCP-1070-2023; Wang,
   Yitong/KBA-1959-2024; wei, wang/KHY-7669-2024; Wang, yl/JNR-4963-2023;
   yang, rui/JHI-3328-2023; wang, zhe/JNE-3510-2023; Zhang,
   Youyou/KCY-0810-2024; Wang, Xin/JVE-0200-2024; zhang,
   zheng/KHY-8870-2024; wang, Xiaoming/KBB-8854-2024; wang,
   xin/JWA-3772-2024; Li, Wenjuan/KDN-8450-2024; Wang, Jin/KAM-5595-2024;
   wang, xi/JNT-5162-2023; zhang, xiao/JCN-8822-2023; yang,
   liu/JXX-5043-2024; liu, yuhao/JWP-0475-2024; zheng, yan/JKJ-3632-2023;
   Yang, Fan/JVO-8611-2024; Zhang, Kai/KBD-3312-2024; Lu, Yi/KEJ-2560-2024;
   liu, yang/JMB-9083-2023; Liu, Shaobo/JUU-5767-2023; lin,
   yuan/JXL-9592-2024; Wang, Bo/KEH-0105-2024; li, Li/JPA-0218-2023; wang,
   yi/JYO-8193-2024; wang, xiaoxuan/JMP-6531-2023; chang, yu/KFB-2822-2024;
   li, chunlin/KFS-0761-2024; Liu, Yang/JVD-6777-2023; li,
   lan/KCJ-5061-2024; Li, Yao/JJC-2927-2023; wang, wenjing/KEH-0575-2024;
   liu, jingwen/JQW-9270-2023; Liu, Xiaohan/KBB-4246-2024; zhang,
   xinyu/JKI-8403-2023; yang, yunfeng/KHT-9566-2024; Yu,
   Xiaohan/KCK-5462-2024; zhang, ying/JQX-1479-2023; luo,
   Jing/KFT-0288-2024; zhao, lin/JJF-0406-2023; ZHANG, JING/KHY-1073-2024;
   yan, xu/KCY-8174-2024; Ma, Wei/JXY-5019-2024; liu, feng/KCL-0778-2024;
   yang, xiao/JLL-7721-2023; li, yifan/JHU-9272-2023; Zhang,
   Bo/JVD-9890-2024; LI, WEI/JUE-9796-2023; zhang, wen/JXN-0191-2024; Li,
   Kexin/KAO-2519-2024; Cheng, Lin/KFQ-3111-2024; Wang, Yue/JRY-8962-2023;
   Wang, Xuechun/JRX-6509-2023; Shen, Yan/KEJ-4617-2024; Li,
   Yan/JRW-0176-2023; Wang, Jiawei/KHC-8971-2024; LI, HAO/KBD-0866-2024;
   YANG, DAN/KCL-5217-2024; Zhang, Tianxi/KEH-5921-2024; Wang,
   Fei/KEH-6292-2024; Liu, Zhihao/JUF-7651-2023; zhou, chen/KBC-4023-2024;
   yuanyuan, Li/JEZ-6497-2023; Zhang, Wenkai/JWO-2030-2024; Wen,
   Jing/KCL-6614-2024; Jing, Jing/JSK-6237-2023; yu, hui/KDO-3946-2024; YI,
   J/JJE-7713-2023; WANG, YING/JLM-9219-2023; PENG, CHENG/KCL-2506-2024;
   Li, YU/JQV-2716-2023; Chen, Zheng/KCY-2338-2024; Liu,
   Yining/KHC-6217-2024; Zhang, Lijuan/KAM-0174-2024; Yuan,
   Ye/KBC-9835-2024; Zhang, Wei/JKI-3565-2023; zhang, lu/KGL-6144-2024;
   Wang, Yibin/KEZ-9645-2024; Li, Wei/JLL-4365-2023; li,
   xinyi/KEI-6391-2024; xiang, wei/JXL-3308-2024; liu, xiao/JLL-2119-2023;
   wang, wei/JYP-7819-2024; lin, lin/KCZ-0185-2024; Zhang,
   Yuan/JUF-7293-2023; su, hang/KEH-2976-2024; Zhang, Yunyi/JHS-3626-2023;
   Wang, Junzhe/KCK-4991-2024; Li, Lei/JPE-6543-2023; chen,
   xiao/KFQ-6812-2024; Ling, Li/JYO-7043-2024; song, yu/KCZ-2003-2024; lu,
   Li/KBA-2603-2024; LI, LI/KCJ-5600-2024; Yang, Fan/JMA-9594-2023; li,
   li/JVP-2971-2024; ZHOU, YUE/KCJ-8790-2024; Li, J N/JXL-5833-2024; Li,
   Bo/KHX-7246-2024; Liu, Xiong/JWO-1231-2024; wang,
   xiaoqiang/JMT-2783-2023; Qi, Ling/KHE-3068-2024
OI Liu, Xiaohan/0009-0009-5291-2494; Ma, Wei/0000-0002-7344-998X; Wang,
   Yue/0000-0001-8673-6358; Liu, Yining/0000-0002-2218-2349; Yuan,
   Ye/0009-0008-1640-7047; Liu, Xiong/0000-0001-9021-3031; 
CR Abadleh A, 2021, WIREL NETW, V27, P2337, DOI 10.1007/s11276-021-02588-0
   Addison PS, 2002, J SOUND VIB, V254, P733, DOI 10.1006/jsvi.2001.4119
   Anwary AR, 2018, IEEE SENS J, V18, P2555, DOI 10.1109/JSEN.2017.2786587
   Ates HC, 2022, NAT REV MATER, V7, P887, DOI 10.1038/s41578-022-00460-x
   Avci A., 2010, 23 INT C ARCH COMP S, P1
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Barralon Pierre, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P1711
   Barth J, 2015, SENSORS-BASEL, V15, P6419, DOI 10.3390/s150306419
   De Marsico M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3340293
   De Marsico M, 2017, MULTIMED TOOLS APPL, V76, P4713, DOI 10.1007/s11042-016-3654-1
   Dehzangi O, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122735
   EBP US Inc., 2021, IMP COVID 19 PAND PU
   Feng Lin, 2015, 2015 IEEE Signal Processing in Medicine and Biology Symposium (SPMB). Proceedings, P1, DOI 10.1109/SPMB.2015.7405425
   Fortino G, 2015, INFORM FUSION, V22, P50, DOI 10.1016/j.inffus.2014.03.005
   Genovese V, 2017, IEEE ACCESS, V5, P13028, DOI 10.1109/ACCESS.2017.2702066
   Giorgi Giacomo, 2017, Computer Safety, Reliability and Security, SAFECOMP 2017: Workshops ASSURE, DECSoS, SASSUR, TELERISE and TIPS. Proceedings: LNCS 10489, P384, DOI 10.1007/978-3-319-66284-8_32
   Harle R, 2013, IEEE COMMUN SURV TUT, V15, P1281, DOI 10.1109/SURV.2012.121912.00075
   Heikenfeld J, 2018, LAB CHIP, V18, P217, DOI 10.1039/c7lc00914c
   Hölzke F, 2020, INT CONF SIGN PROCES, P626, DOI 10.1109/ICSP48669.2020.9321077
   KADABA MP, 1990, J ORTHOP RES, V8, P383, DOI 10.1002/jor.1100080310
   Kang J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093149
   Ladetto Q., 2000, Proceedings of the 13th International Technical Meeting of the Satellite Division of The Institute of Navigation (ION GPS), Salt Lake City, UT, USA, 19-22 September 2000, P1735
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   Mallat S., 1998, WAVELET TOUR SIGNAL
   Mukhopadhyay SC, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145137
   Nadeem T, 2019, IEEE GLOB COMM CONF, P1
   Nyan MN, 2006, J BIOMECH, V39, P2647, DOI 10.1016/j.jbiomech.2005.08.014
   Perc M, 2005, EUR J PHYS, V26, P525, DOI 10.1088/0143-0807/26/3/017
   Pino-Ortega J, 2021, GAIT POSTURE, V87, P6, DOI 10.1016/j.gaitpost.2021.04.015
   Qian JC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113803
   Sekine M, 2000, METHOD INFORM MED, V39, P183
   SHUKLA PD, 2003, THESIS U STRATHCLYDE
   Soaz C, 2016, IEEE T BIO-MED ENG, V63, P933, DOI 10.1109/TBME.2015.2480296
   Steinmetzer T, 2020, NEURAL COMPUT APPL, V32, P17857, DOI 10.1007/s00521-019-04384-6
   Suksuganjana W, 2021, INT CONF KNOWL SMART, P55, DOI 10.1109/KST51265.2021.9415857
   Taborri J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010066
   Tanigawa A, 2018, GAIT POSTURE, V65, P176, DOI 10.1016/j.gaitpost.2018.07.165
   Tarnita D, 2016, ROM J MORPHOL EMBRYO, V57, P373
   Wang JH, 2012, 2012 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P591, DOI 10.1109/APCCAS.2012.6419104
   Wang ZL, 2017, INFORM FUSION, V37, P1, DOI 10.1016/j.inffus.2017.01.004
   Wu JN, 2015, BIOMED RES INT, V2015, DOI 10.1155/2015/528971
   Yao YB, 2020, IEEE SENS J, V20, P9685, DOI 10.1109/JSEN.2020.2989865
   [张华 ZHANG Hua], 2011, [高分子通报, Polymer Bulletin], P1
   Zhang YT, 2015, IEEE T CYBERNETICS, V45, P1864, DOI 10.1109/TCYB.2014.2361287
   Zhao H, 2022, NANOSCALE, V14, P1653, DOI 10.1039/d1nr06244a
   Zhao HY, 2019, INFORM FUSION, V52, P157, DOI 10.1016/j.inffus.2019.03.002
NR 46
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15426-6
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400021
DA 2024-07-18
ER

PT J
AU Wu, YH
   Liu, F
AF Wu, Yahong
   Liu, Feng
TI Zero-shot contrast enhancement and denoising network for low-light
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Low-light image enhancement; Zero-shot learning; Contrast enhancement;
   Denoisng; Hierarchical features
ID CONVOLUTIONAL NEURAL-NETWORK; ILLUMINATION
AB Low-light image enhancement has wide applications. However, contrast improvement and denoising are easily overlooked in existing low-light image enhancement algorithms. Inspired by the technique of zero-shot learning, a zero-shot contrast enhancement and denoising network is proposed to remedy the above disadvantages. First, different hierarchical features are extracted by a multi-scale dense network, where the features in the previous layers can be fully used. This step can obtain richer features from the observed low-light image. Second, a hierarchical feature distillation block, including channel shuffle, contrast attention mechanism and noise attention mechanism, is designed to refine the extracted features. This step contributes to contrast enhancement and denoising. Finally, a mapping network is employed to adjust the brightness, which can map the refined features to the enhanced image in pixel-wise way. The proposed network does not require any reference samples during the training phase, and non-reference loss functions are designed to improve the performance. Subjective and objective experiments demonstrate the superiority of the proposed method in contrast improvement, denoising, brightness enhancement and naturalness preservation.
C1 [Wu, Yahong] Nanjing Vocat Univ Ind Technol, 1 North Yangshan Rd, Nanjing 210023, Peoples R China.
   [Wu, Yahong; Liu, Feng] Nanjing Univ Posts & Telecommun, 66 Xin Mofan RD, Nanjing 210003, Peoples R China.
C3 Nanjing Vocational University of Industry Technology; Nanjing University
   of Posts & Telecommunications
RP Wu, YH (corresponding author), Nanjing Vocat Univ Ind Technol, 1 North Yangshan Rd, Nanjing 210023, Peoples R China.; Wu, YH (corresponding author), Nanjing Univ Posts & Telecommun, 66 Xin Mofan RD, Nanjing 210003, Peoples R China.
EM wuyahonghaha@163.com; liuf@njupt.edu.cn
FU National Natural Science Foundation of China [61702278]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 61702278 and in part by Priority Academic Program
   Development of Jiangsu Higher Education Institutions.
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dong X, 2011, IEEE INT CON MULTI
   Fan MH, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2317, DOI 10.1145/3394171.3413757
   Feng XM, 2021, APPL INTELL, V51, P5111, DOI 10.1007/s10489-020-02119-y
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   Hu J., 2018, PROC IEEECVF C COMPU, P7132, DOI DOI 10.1109/CVPR.2018.00745
   Hui Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2024, DOI 10.1145/3343031.3351084
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Kingma D, 2014, C LEARNING REPRESENT, P12
   Ko S, 2017, SIGNAL PROCESS-IMAGE, V58, P99, DOI 10.1016/j.image.2017.06.016
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2012, IEEE IMAGE PROC, P965, DOI 10.1109/ICIP.2012.6467022
   Li C, 2020, APPL INTELL, V1
   Li CY, 2022, IEEE T PATTERN ANAL, V44, P4225, DOI 10.1109/TPAMI.2021.3063604
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Li L, 2015, IEEE IMAGE PROC, P3730, DOI 10.1109/ICIP.2015.7351501
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lu K, 2021, IEEE T MULTIMEDIA, V23, P4093, DOI 10.1109/TMM.2020.3037526
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nakai K, 2013, I S INTELL SIG PROC, P445, DOI 10.1109/ISPACS.2013.6704591
   Qian SY, 2022, APPL INTELL, V52, P1770, DOI 10.1007/s10489-021-02466-4
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   Ronneberger O., 2017, BILDVERARBEITUNG MED
   Wang HR, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P1, DOI 10.1145/3489517.3530400
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang RX, 2019, PROC CVPR IEEE, P6842, DOI 10.1109/CVPR.2019.00701
   Wang SH, 2018, IEEE T IMAGE PROCESS, V27, P938, DOI 10.1109/TIP.2017.2771449
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wei C., 2018, BRIT MACHINE VISION
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P3461, DOI 10.1109/TIP.2021.3062184
   Yuan Y, 2019, UG 2 TRACK 2 COLLECT
   Zhang L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1623, DOI 10.1145/3343031.3351069
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
   Zhao ZP, 2021, IET RENEW POWER GEN, V15, P1178, DOI 10.1049/rpg2.12098
   Zhu A, 2020, 2020 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR INDUSTRIES (AI4I 2020), P1, DOI 10.1109/AI4I49448.2020.00007
   Zhu MF, 2020, AAAI CONF ARTIF INTE, V34, P13106
NR 57
TC 0
Z9 0
U1 9
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15233-z
EA MAY 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400003
DA 2024-07-18
ER

PT J
AU El-Rashidy, MA
   Mohamed, RG
   El-Fishawy, NA
   Shouman, MA
AF El-Rashidy, Mohamed A. A.
   Mohamed, Ramy G. G.
   El-Fishawy, Nawal A. A.
   Shouman, Marwa A. A.
TI An effective text plagiarism detection system based on feature selection
   and SVM techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Text plagiarism; Natural language processing; Classification; Feature
   Selection
ID SIMILARITY; DATABASE
AB Text plagiarism has greatly spread in the recent years, it becomes a common problem in several fields such as research manuscripts, textbooks, patents, academic circles, etc. There are many sentence similarity features were used to detect plagiarism, but each of them is not discriminative to differentiate the similarity cases. This causes the discovery of lexical, syntactic and semantic text plagiarism types to be a challenging problem. Therefore, a new plagiarism detection system is proposed to extract the most effective sentence similarity features and construct hyperplane equation of the selected features to distinguish the similarity cases with the highest accuracy. It consists of three phases; the first phase is used to preprocess the documents. The second phase is depended on two paths, the first path is based on traditional paragraph level comparison, and the second path is based on the computed hyperplane equation using Support Vector Machine (SVM) and Chi-square techniques. The third phase is used to extract the best plagiarized segment. The proposed system is evaluated on several benchmark datasets. The experimental results showed that the proposed system obtained a significant superiority in the performance compared to the systems with a higher ranking in the recent years. The proposed system achieved the best values 89.12% and 92.91% of the Plagdet scores, 89.34% and 92.95% of the F-measure scores on the complete test corpus of PAN 2013 and PAN 2014 datasets, respectively.
C1 [El-Rashidy, Mohamed A. A.; Mohamed, Ramy G. G.; El-Fishawy, Nawal A. A.; Shouman, Marwa A. A.] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Shibin Al Kawm, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Shouman, MA (corresponding author), Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Shibin Al Kawm, Egypt.
EM mohamed.elrashedy@el-eng.menofia.edu.eg;
   ramygamalawad23@el-eng.menofia.edu.eg;
   nawal.elfishawy@el-eng.menofia.edu.eg;
   marwa.shouman@el-eng.menofia.edu.eg
OI Elrashidy, Mohamed/0000-0002-4699-4077
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB)
CR Abnar S, 2014, CLEF WORKING NOTES, V1180, P928
   Ahuja L, 2020, ARAB J SCI ENG, V45, P9939, DOI 10.1007/s13369-020-04565-9
   Altheneyan AS, 2020, PATTERN ANAL APPL, V23, P1627, DOI 10.1007/s10044-020-00882-9
   Alvi F, 2014, CLEF WORKING NOTES, V1180, P939
   Alvi F, 2021, INT J EDUC TECHNOL H, V18, DOI 10.1186/s41239-021-00277-8
   [Anonymous], 1997, P 10 RES COMP LING I
   Bochkarev VV, 2015, SOC EVOL HIST, V14, P153
   Chang CY, 2021, INFORM RETRIEVAL J, V24, P298, DOI 10.1007/s10791-021-09394-4
   Chong D, 2011, IEEE POTENTIALS, V30, P3
   Daud A, 2018, INT J SEMANT WEB INF, V14, P53, DOI 10.4018/IJSWIS.2018070103
   Eissen SMZ, 2006, LECT NOTES COMPUT SC, V3936, P565
   Ekbal A, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P366, DOI 10.1109/HIS.2012.6421362
   Ghanem B, 2018, LECT NOTES COMPUT SC, V10859, P315, DOI 10.1007/978-3-319-91947-8_33
   Gharavi E, 2020, NEURAL COMPUT APPL, V32, P10593, DOI 10.1007/s00521-019-04594-y
   Gillam L, 2014, CLEF, V1180, P951
   Glinos DG, 2014, CLEF WORKING NOTES, V1180, P958
   Gross P, 2014, CLEF WORKING NOTES, V1182, P966
   Gupta D, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2694, DOI 10.1109/ICACCI.2014.6968314
   Harris MA, 2004, NUCLEIC ACIDS RES, V32, pD258, DOI 10.1093/nar/gkh036
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Jayapal A, 2013, CLEF
   Kauffman Y, 2015, COMPUT EDUC, V83, P44, DOI 10.1016/j.compedu.2014.12.016
   Kong L, 2014, CLEF WORKING NOTES, V1180, P973
   Kong L, 2012, CLEF WORKING NOTES
   Kuppers R, 2012, CLEF WORKING NOTES
   Leacock C, 1998, LANG SPEECH & COMMUN, P265
   Lee G, 2013, CLEF WORKING NOTES
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Lin D., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P296
   Lyon C, 2001, PROCEEDINGS OF THE 2001 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P118
   Margaret Larock, 1980, MASTERING EFFECTIVE
   Mariani J, 2018, INT J DIGIT LIBRARIE, V19, P113, DOI 10.1007/s00799-017-0211-0
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mingxing W, 2013, C LABS EV FOR WORKSH
   Nourian A, 2013, 5 INT COMP PLAG DET
   Oberreuter G, 2014, 6 INT COMP PLAG DET
   Oberreuter G, 2012, 4 INT COMP PLAG DET
   Palkovskii Y, 2012, CLEF
   Palkovskii Y, 2013, CLEF WORKING NOTES
   Palkovskii Y, 2014, C LABS EVALUATION FO, V1180, P984
   Pearson K, 1900, PHILOS MAG, V50, P157, DOI 10.1080/14786440009463897
   Pedersen T, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P1024
   Phyllis A, 2016, ENCY GIS, P1, DOI [10.1007/978-3-319-23519-6_1259-2, DOI 10.1007/978-3-319-23519-6_1259-2]
   Potthast M., 2013, CLEF C MULT MULT INF, P301
   Potthast M, 2012, 4 INT COMP PLAG DET
   Potthast M., 2010, An evaluation framework for plagiarism detection, P997
   Potthast M., 2014, CLEF 2014 evaluation labs and Workshop-working notes papers. CEUR Workshop proceedings, P845
   Reshamwala A., 2013, IRACST Engineering Science and Technology: An International Journal (ESTIJ), V3, P113
   Resnik P, 1995, INT JOINT CONF ARTIF, P448
   Rodriguez Torrejon D, 2014, CLEF WORKING NOTES, V1180, P997
   Rodriguez Torrejon DA, 2013, CLEF WORKING NOTES
   Roostaee M, 2020, EXPERT SYST APPL, V160, DOI 10.1016/j.eswa.2020.113718
   Sahi M, 2017, COGN COMPUT, V9, P852, DOI 10.1007/s12559-017-9502-4
   Sanchez-Perez M, 2014, CLEF 2014 EVALUATION, V1180, P1004
   Sanchez-Vega F, 2012, CLEF
   Saremi M, 2013, 5 INT COMP PLAG DET
   Shahmohammadi H, 2021, MULTIMED TOOLS APPL, V80, P6479, DOI 10.1007/s11042-020-09996-y
   Shrestha P, 2014, CEUR WORKSHOP PROC, V1180, P1012
   Shrestha P, 2013, NOTEBOOK PAN CLEF 20
   Suchomel S, 2012, CLEF WORKING NOTES
   Suchomel S, 2013, CLEF
   Tomasic A., 1993, VLDB. J, V2, P243, DOI [10.1007/BF01228671, DOI 10.1007/BF01228671]
   Torrejon DA, 2012, CLEF
   Ullah F, 2020, MULTIMED TOOLS APPL, V79, P8581, DOI 10.1007/s11042-018-5827-6
   Vani K, 2018, INFORM PROCESS MANAG, V54, P408, DOI 10.1016/j.ipm.2018.01.008
   Vani K, 2017, EXPERT SYST APPL, V73, P11, DOI 10.1016/j.eswa.2016.12.022
   Vani K, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1578, DOI 10.1109/ICACCI.2015.7275838
   Vani K, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P1268, DOI 10.1109/IC3I.2014.7019659
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Zobel J., 1998, SIGIR Forum, V32, P18, DOI 10.1145/281250.281256
NR 70
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15703-4
EA MAY 2023
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100006
OA hybrid
DA 2024-07-18
ER

PT J
AU Vasanthi, P
   Mohan, L
AF Vasanthi, Ponduri
   Mohan, Laavanya
TI Multi-Head-Self-Attention based YOLOv5X-transformer for multi-scale
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object recognition; YOLOv5; Multi-Head-Self-Attention; Spatial Pyramid
   Pooling-Faster
ID FASTER
AB The state-of-the-art deep learning models mostly depend upon the region proposal and grid methods in detecting the objects with localization has been in practice for a long time but still, it has got scope for further improvement. There exists a visual challenge of small-scale object detection. To solve this issue, some methods are used for creating and enhancing shallow features and feature fusion concepts. However, the progressive enhancement of shallow features reduces the quality of the image, and feature fusion causes the aliasing effect. To ensure and solve this aliasing effect in small-scale object detection, this paper introduces the YOLOv5X- transformer. In this model, Multi-Head-Self-Attention (MHSA) module extracts in-depth information from the feature maps based on the query, key, and value parameters. Afterward, these feature maps are pooled together at five different scales by using Spatial Pyramid Pooling-Faster (SPPF) to improve the quality of the feature maps. To save spatial information and locate the pixels correctly Path-Aggregated Network (PANet) is used as a neck model. This model is experimentally verified on the PASCAL dataset. This model has achieved 87.7% mAP, 85.2% Precision, and 81.4% Recall. These tested results show that the proposed model performs better than existing models in detecting small objects.
C1 [Vasanthi, Ponduri; Mohan, Laavanya] Vignans Fdn Sci Technol & Res, Guntur, Andhra Prades, India.
C3 Vignan's Foundation for Science, Technology & Research (VFSTR)
RP Vasanthi, P (corresponding author), Vignans Fdn Sci Technol & Res, Guntur, Andhra Prades, India.
EM Vasanthi457@gmail.com; laavanvijay@gmail.com
RI Mohan, Laavanya/Z-1413-2018
OI Mohan, Laavanya/0000-0001-7656-2913; ponduri,
   vasanthi/0000-0002-9769-5202
CR Ahmed I, 2020, IEEE INTERNET THINGS, V7, P5737, DOI 10.1109/JIOT.2019.2951365
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bharati Puja, 2020, Computational Intelligence in Pattern Recognition. Proceedings of CIPR 2019. Advances in Intelligent Systems and Computing (AISC 999), P657, DOI 10.1007/978-981-13-9042-5_56
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   Chen ZG, 2019, IEEE ACCESS, V7, P80622, DOI 10.1109/ACCESS.2019.2923016
   Dai JF, 2016, ADV NEUR IN, V29
   De Menezes R.S.T., 2019, Recent Trends in Artificial Neural Networks-from Training to Prediction. IntechOpen
   Du C, 2020, PATTERN RECOGN LETT, V129, P108, DOI 10.1016/j.patrec.2019.11.015
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fu C.-Y., 2017, arXiv
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hui Jonathan., 2018, SSD object detection: Single Shot Multi-Box Detector for real-time processing
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Khan A, 2020, ARTIF INTELL REV, V53, P5455, DOI 10.1007/s10462-020-09825-6
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Kumar Ashwani, 2020, Procedia Computer Science, V171, P2610, DOI 10.1016/j.procs.2020.04.283
   Li HL, 2017, IEEE ACCESS, V5, P13665, DOI 10.1109/ACCESS.2017.2729943
   Li W, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-67529-x
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Liu B, 2022, IEEE T CYBERNETICS
   Liu DW, 2021, INT J COMPUT APPL T, V65, P25, DOI 10.1504/IJCAT.2021.113643
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo HL, 2021, IEEE SENS J, V21, P21839, DOI 10.1109/JSEN.2021.3103612
   Ma WC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107149
   Mittal N., 2019, INT J SCI RES ENG TR, V5, P562
   Neethirajan S, 2022, MEASUREMENT, V191, DOI 10.1016/j.measurement.2022.110819
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sharma K.U., 2017, International Journal of Computational Vision and Robotics, V7, P196, DOI [10.1504/IJCVR.2017.081234, DOI 10.1504/IJCVR.2017.081234]
   Sharma P., 2018, STEP BY STEP INTRO 1
   Shen ZQ, 2020, IEEE T PATTERN ANAL, V42, P398, DOI 10.1109/TPAMI.2019.2922181
   Tan YS, 2021, NEURAL COMPUT APPL, V33, P5339, DOI 10.1007/s00521-020-05337-0
   Wang Hao, 2020, Journal of Physics: Conference Series, V1684, DOI 10.1088/1742-6596/1684/1/012094
   Wang K, 2020, IEEE ACCESS, V8, P193168, DOI 10.1109/ACCESS.2020.3032981
   Yi JR, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102827
   Yin YH, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102756
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhong QY, 2020, NEUROCOMPUTING, V395, P170, DOI 10.1016/j.neucom.2017.12.070
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
NR 42
TC 3
Z9 3
U1 7
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15773-4
EA MAY 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G5FI8
UT WOS:000989408100005
DA 2024-07-18
ER

PT J
AU Rani, S
   Jain, A
AF Rani, Somiya
   Jain, Amita
TI Optimizing healthcare system by amalgamation of text processing and deep
   learning: a systematic review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Deep learning; Healthcare system; Natural language processing; Text
   processing
ID RECURRENT NEURAL-NETWORK; REPRESENTATIONS; IDENTIFICATION
AB The explosion of clinical textual data has drawn the attention of researchers. Owing to the abundance of clinical data, it is becoming difficult for healthcare professionals to take real-time measures. The tools and methods are lacking when compared to the amount of clinical data generated every day. This review aims to survey the text processing pipeline with deep learning methods such as CNN, RNN, LSTM, and GRU in the healthcare domain and discuss various applications such as clinical concept detection and extraction, medically aware dialogue systems, sentiment analysis of drug reviews shared online, clinical trial matching, and pharmacovigilance. In addition, we highlighted the major challenges in deploying text processing with deep learning to clinical textual data and identified the scope of research in this domain. Furthermore, we have discussed various resources that can be used in the future to optimize the healthcare domain by amalgamating text processing and deep learning.
C1 [Rani, Somiya] Guru Gobind Singh Indraprastha Univ, Dept Comp Sci & Engn, NSUT East Campus erstwhile AIACTR, Delhi, India.
   [Jain, Amita] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Delhi, India.
C3 GGS Indraprastha University; Netaji Subhas University of Technology
RP Jain, A (corresponding author), Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Delhi, India.
EM somiya1093@gmail.com; amitajain@aiactr.ac.in
OI Rani, Somiya/0000-0002-6345-4013
CR Ahltorp M, 2016, J BIOMED SEMANT, V7, DOI 10.1186/s13326-016-0093-x
   Akbik A, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE DEMONSTRATIONS SESSION, P54
   Akhtyamova L, 2020, IEEE ACCESS, V8, P164717, DOI 10.1109/ACCESS.2020.3018688
   Al-Aiad A., 2018, 2018 IEEE/ACS 15th International Conference on Computer Systems and Applications (AICCSA), P1
   Alambo A, 2019, IEEE INT C SEMANT CO, P468, DOI [10.1109/ICSC.2019.00090, 10.1109/ICOSC.2019.8665525]
   [Anonymous], 2018, P 2018 C N AM CHAPTE
   Antonatos S, 2018, PROC INT CONF DATA, P1531, DOI 10.1109/ICDE.2018.00171
   Asada M, 2017, In BioNLP, V2017, P9
   Basiri ME, 2020, KNOWL-BASED SYST, V198, DOI 10.1016/j.knosys.2020.105949
   Baumel T., 2017, ARXIV
   Baytas IM, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P65, DOI 10.1145/3097983.3097997
   Beck JT, 2020, JCO CLIN CANCER INFO, V4, P50, DOI 10.1200/CCI.19.00079
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Boon-Itt S, 2020, JMIR PUBLIC HLTH SUR, V6, P245, DOI 10.2196/21978
   Braghin S, 2019, STUD HEALTH TECHNOL, V264, P1140, DOI 10.3233/SHTI190404
   Brown T., 2020, P ADV NEUR INF PROC, V33, P1877
   Campillos-Llanos L, 2019, SIGBIOMED WORKSHOP ON BIOMEDICAL NATURAL LANGUAGE PROCESSING (BIONLP 2019), P152
   Chao Che, 2017, P 2017 SIAM INT C DA, P198, DOI DOI 10.1137/1.9781611974973.23
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   Choi E, 2017, J AM MED INFORM ASSN, V24, P361, DOI 10.1093/jamia/ocw112
   Choi Edward, 2016, JMLR Workshop Conf Proc, V56, P301
   Colón-Ruiz C, 2020, J BIOMED INFORM, V110, DOI 10.1016/j.jbi.2020.103539
   Dandala B, 2019, DRUG SAFETY, V42, P135, DOI 10.1007/s40264-018-0764-x
   data.world, 2021, US
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dinov ID, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0157077
   Divya S., 2018, J WEB DEV WEB DESIGN, V3, P1, DOI DOI 10.1007/978-981-15-6707-0_57
   Dreisbach C, 2019, INT J MED INFORM, V125, P37, DOI 10.1016/j.ijmedinf.2019.02.008
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, 10.48550/arXiv.1802.05365]
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Fan B, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102131
   Ghojogh B, 2020, Attention mechanism, transformers, BERT, and GPT: tutorial and survey, DOI [10.31219/osf.io/m6gcn, DOI 10.31219/OSF.IO/M6GCN]
   Grasser F, 2018, DH '18: PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON DIGITAL HEALTH, P121, DOI 10.1145/3194658.3194677
   Guan MJ, 2019, JAMIA OPEN, V2, P139, DOI 10.1093/jamiaopen/ooy061
   Gurdin Gabrielle, 2020, AMIA Jt Summits Transl Sci Proc, V2020, P201
   Han Y, 2020, IEEE ACCESS, V8, P21314, DOI 10.1109/ACCESS.2020.2969473
   Hassanzadeh H, 2020, J BIOMED INFORM, V105, DOI 10.1016/j.jbi.2020.103406
   healthdata, 2021, US
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang JM, 2019, COMPUT METH PROG BIO, V177, P141, DOI 10.1016/j.cmpb.2019.05.024
   Iroju Olaronke G., 2015, International Journal of Information Technology and Computer Science, V7, P44, DOI 10.5815/ijitcs.2015.08.07
   Jelodar H, 2020, IEEE J BIOMED HEALTH, V24, P2733, DOI 10.1109/JBHI.2020.3001216
   Jian Z, 2017, J BIOMED INFORM, V73, P76, DOI 10.1016/j.jbi.2017.07.017
   Joopudi V, 2018, J BIOMED INFORM, V86, P71, DOI 10.1016/j.jbi.2018.07.025
   Kam HJ, 2017, COMPUT BIOL MED, V89, P248, DOI 10.1016/j.compbiomed.2017.08.015
   kdnuggets, 2021, US
   Kieuvongngam V, 2020, Arxiv, DOI arXiv:2006.01997
   Kocaman Veysel, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P635, DOI 10.1007/978-3-030-68763-2_48
   Koleck TA, 2019, J AM MED INFORM ASSN, V26, P364, DOI 10.1093/jamia/ocy173
   Kong J, 2021, J BIOMED INFORM, V116, DOI 10.1016/j.jbi.2021.103737
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Lee K, 2019, STUD HEALTH TECHNOL, V264, P218, DOI 10.3233/SHTI190215
   Lee K, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI), P462, DOI 10.1109/ICHI.2017.59
   Li JQ, 2020, J SUPERCOMPUT, V76, P1450, DOI 10.1007/s11227-017-2229-x
   Li LT, 2020, NEUROCOMPUTING, V414, P182, DOI 10.1016/j.neucom.2020.07.027
   Li XY, 2020, J BIOMED INFORM, V107, DOI 10.1016/j.jbi.2020.103422
   Liu WE, 2022, Arxiv, DOI arXiv:2010.07497
   Liu ZJ, 2017, J BIOMED INFORM, V75, pS34, DOI 10.1016/j.jbi.2017.05.023
   Luo Y, 2018, J AM MED INFORM ASSN, V25, P93, DOI 10.1093/jamia/ocx090
   Luo Y, 2017, DRUG SAFETY, V40, P1075, DOI 10.1007/s40264-017-0558-6
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Mardini MT, 2022, INFORM SYST FRONT, V24, P133, DOI 10.1007/s10796-020-10058-9
   Marek K, 2011, PROG NEUROBIOL, V95, P629, DOI 10.1016/j.pneurobio.2011.09.005
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   mimic.physionet, 2021, US
   Molenaar S, 2020, LECT NOTES BUS INF P, V382, P76, DOI 10.1007/978-3-030-49165-9_7
   Moradi M, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105117
   Moradi M, 2018, ARTIF INTELL MED, V84, P101, DOI 10.1016/j.artmed.2017.11.004
   Naseem U, 2021, IEEE T COMPUT SOC SY, V8, P1003, DOI 10.1109/TCSS.2021.3051189
   Neveol A, 2015, Yearb Med Inform, V10, P194, DOI 10.15265/IY-2015-035
   Neveol A, 2015, YB MED INF, V25, P234
   Névéol A, 2018, J BIOMED SEMANT, V9, DOI 10.1186/s13326-018-0179-8
   Ni YZ, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/s12911-015-0149-3
   Ningthoujam D, 2019, Arxiv, DOI arXiv:1903.09941
   Nuthakki S, 2019, Arxiv, DOI arXiv:1912.12397
   Oniani D., 2020, P 11 ACM INT C BIOIN, P1
   Pattisapu N, 2019, PR MACH LEARN RES, V116, P246
   portal.dbmi.hms.harvard, 2021, US
   Radford A, Improving language understanding by generative pre-training
   Radford A., 2019, LANGUAGE MODELS ARE
   re3data, 2021, US
   Richter-Pechanski P, 2019, STUD HEALTH TECHNOL, V267, P101, DOI 10.3233/SHTI190813
   Sahu SK, 2018, J BIOMED INFORM, V86, P15, DOI 10.1016/j.jbi.2018.08.005
   Shamshirband S, 2021, J BIOMED INFORM, V113, DOI 10.1016/j.jbi.2020.103627
   Shi JY, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0411-5
   Shickel B, 2018, IEEE J BIOMED HEALTH, V22, P1589, DOI 10.1109/JBHI.2017.2767063
   Si YQ, 2019, J AM MED INFORM ASSN, V26, P1297, DOI 10.1093/jamia/ocz096
   Siva Nayanah, 2008, Nat Biotechnol, V26, P256, DOI 10.1038/nbt0308-256b
   Skreta M, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25578-4
   Sorin V, 2020, J AM COLL RADIOL, V17, P639, DOI 10.1016/j.jacr.2019.12.026
   Steiner Claudia, 2002, Eff Clin Pract, V5, P143
   Tang BZ, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0787-y
   Topaz M, 2020, GERONTOL GERIATR MED, V6, DOI 10.1177/2333721420959861
   Uroshlev LA, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-65406-1
   Vaswani A, 2017, ADV NEUR IN, V30
   Vatian A, 2019, LECT NOTES COMPUT SC, V11871, P175, DOI 10.1007/978-3-030-33607-3_20
   Velupillai S, 2018, J BIOMED INFORM, V88, P11, DOI 10.1016/j.jbi.2018.10.005
   Viani N, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80457-0
   Viani N, 2019, J BIOMED INFORM, V95, DOI 10.1016/j.jbi.2019.103219
   Wanstreet T, 2021, INT J PEDIATR OTORHI, V142, DOI 10.1016/j.ijporl.2020.110559
   Wu S, 2020, J AM MED INFORM ASSN, V27, P457, DOI 10.1093/jamia/ocz200
   Wu Yonghui, 2018, AMIA Annu Symp Proc, V2018, P1110
   Wulff A, 2020, METHOD INFORM MED, V59, pe64, DOI 10.1055/s-0040-1716403
   Xiao C, 2018, J AM MED INFORM ASSN, V25, P1419, DOI 10.1093/jamia/ocy068
   Xie F., 2017, J PATHOL INF, V2017, P8
   Xu J, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0937-2
   Xue J., 2020, PLOS ONE, V15
   Yamamoto N, 2020, GENE, V758, DOI 10.1016/j.gene.2020.144944
   Yang X, 2020, J AM MED INFORM ASSN, V27, P1935, DOI 10.1093/jamia/ocaa189
   Yu XY, 2020, IEEE ACM T COMPUT BI, V17, P2029, DOI 10.1109/TCBB.2019.2916346
   Zand A, 2020, J MED INTERNET RES, V22, DOI 10.2196/15589
   Zhang TX, 2021, APPL SOFT COMPUT, V106, DOI 10.1016/j.asoc.2021.107358
   Zhang XH, 2019, INT J MED INFORM, V132, DOI 10.1016/j.ijmedinf.2019.103985
   Zhang XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1029, DOI 10.1145/3366423.3380181
   Zhang YL, 2020, IEEE ACCESS, V8, P95947, DOI 10.1109/ACCESS.2020.2995739
   Zhao S, 2019, J BIOMED INFORM, V99, DOI 10.1016/j.jbi.2019.103290
   Zheng T, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0880-2
   Zhou XK, 2021, IEEE ACM T COMPUT BI, V18, P912, DOI 10.1109/TCBB.2020.2994780
NR 119
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15539-y
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3MC7
UT WOS:000988228200003
PM 37362695
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kririm, S
   Zouhri, A
   Mallahi, ME
   Hmamed, A
AF Kririm, Said
   Zouhri, Amal
   Mallahi, Mostafa El
   Hmamed, Abdelaziz
TI New robust state estimation of 2D embedded descriptor systems in Roesser
   form with bounded disturbance using strict LMI approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D Descriptor systems; H-8 performance; 2D observer; Time-invariant
   uncertainties
ID DISCRETE-SYSTEMS; DELAYED SYSTEMS; 2-D; STABILIZATION; STABILITY;
   OBSERVERS; ALGORITHM
AB This paper is concerned with the problems of robust H-8 observer-based filtering for 2 dimensional (2D) embedded descriptor systems described by Roesser model with matrices that depend on time-invariant bounded uncertain parameters. By using the strict linear matrix inequalities (SLMI) approach and projection lemma,sufficient condition is established under which the 2D error embedded descriptor system is asymptotically sable and satisfies a predefined H-8 performance index for time-invariant bounded uncertain parameters. The observer design is given in terms of strict linear matrix inequalities (SLMI). Numerical examples illustrate the effectiveness of the proposed filter design methods.
C1 [Kririm, Said] Ibn Zohr Univ, Higher Sch Technol, Elect & Energy Engn Dept, Guelmim, Morocco.
   [Zouhri, Amal] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, Phys Dept, LISAC Lab, St,BP 1796 Fez-Atlas, Fez Atlas, Morocco.
   [Mallahi, Mostafa El] Sidi Mohamed Ben Abdellah Univ, Higher Normal Sch, Math & Comp Sci Dept, BP 5206, Fes, Morocco.
   [Hmamed, Abdelaziz] Private Univ Fez, Phys Dept, Fes 30040, Morocco.
C3 Ibn Zohr University of Agadir; Sidi Mohamed Ben Abdellah University of
   Fez; Sidi Mohamed Ben Abdellah University of Fez
RP Kririm, S (corresponding author), Ibn Zohr Univ, Higher Sch Technol, Elect & Energy Engn Dept, Guelmim, Morocco.
EM saidkririm@yahoo.fr; amal.zouhri@usmba.ac.ma;
   mostafa.elmallahi@usmba.ac.ma; hmamed@upf.ac.ma
CR Benhayoun M, 2013, CIRC SYST SIGNAL PR, V32, P2723, DOI 10.1007/s00034-013-9585-4
   Benzaouia A, 2016, STUD SYST DECIS CONT, V28, P1, DOI 10.1007/978-3-319-20116-0
   Boukili B, 2022, PATTERN ANAL APPL, V25, P63, DOI 10.1007/s10044-021-01030-7
   Boukili B, 2021, OPTIM CONTR APPL MET, V42, P1337, DOI 10.1002/oca.2730
   Boyd S., 1994, LINEAR MATRIX INEQUA, V1st
   Cai CX, 2004, MULTIDIM SYST SIGN P, V15, P197, DOI 10.1023/B:MULT.0000017025.77423.7f
   Cheng S. K., 1985, Proceedings of the 24th IEEE Conference on Decision and Control (Cat. No.85CH2245-9), P585
   de Souza CE, 2010, AUTOMATICA, V46, P673, DOI 10.1016/j.automatica.2010.01.017
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Ding DW, 2020, SYST CONTROL LETT, V82, DOI [10.1007/s11045-014-0279-2, DOI 10.1007/S11045-014-0279-2]
   Du CL, 2000, IEEE T SIGNAL PROCES, V48, P1760, DOI 10.1109/78.845933
   El Mallahi Mostafa, 2021, Multimedia Tools and Applications, P25965, DOI 10.1007/s11042-021-10845-9
   FORNASINI E, 1978, MATH SYST THEORY, V12, P59, DOI 10.1007/BF01776566
   Gao CY, 2008, INT J AUTOM COMPUT, V5, P413, DOI 10.1007/s11633-008-0413-4
   HINAMOTO T, 1982, INT J SYST SCI, V13, P177, DOI 10.1080/00207728208926339
   Hmamed A, 2016, INT J SYST SCI, V47, P3004, DOI 10.1080/00207721.2015.1063172
   Hmamed A, 2009, MED C CONTR AUTOMAT, P1, DOI 10.1109/MED.2009.5164505
   Hmamed A, 2010, MULTIDIM SYST SIGN P, V21, P277, DOI 10.1007/s11045-010-0107-2
   KACZOREK T, 1993, IEEE T AUTOMAT CONTR, V38, P1391, DOI 10.1109/9.237652
   Kaczorek T, 2001, IEEE T AUTOMAT CONTR, V46, P1671, DOI 10.1109/9.956070
   Kaczorek T., 1985, TOW DIMENSIONEL LINE
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kawaji S., 1984, IFAC P VOLUMES, V17, P383, DOI [10.1016/S1474-6670(17)61000-0, DOI 10.1016/S1474-6670(17)61000-0]
   Kririm S, 2019, 8 INT C SYSTEMS CONT
   Kririm S, 2021, NEURAL COMPUT APPL, V33, P16865, DOI 10.1007/s00521-021-06533-2
   Kririm S, 2017, INT J AUTOM CONTROL, V11, P207
   Kririm S, 2016, INT CONF SYST CONTRO, P319, DOI 10.1109/ICoSC.2016.7507035
   Kririm S, 2016, CIRC SYST SIGNAL PR, V35, P1579, DOI 10.1007/s00034-015-0139-9
   Kririm S, 2015, CIRC SYST SIGNAL PR, V34, P2213, DOI 10.1007/s00034-015-9967-x
   Kumar R., 2021, Int. J. Modern Res, V1, P1, DOI DOI 10.1109/ICMLC.2007.4370325
   Hien LV, 2018, SYST CONTROL LETT, V112, P42, DOI 10.1016/j.sysconle.2017.12.003
   Peng D, 2009, MULTIDIM SYST SIGN P, V20, P265, DOI 10.1007/s11045-008-0064-1
   PETERSEN IR, 1987, SYST CONTROL LETT, V8, P351, DOI 10.1016/0167-6911(87)90102-2
   ROESSER RP, 1975, IEEE T AUTOMAT CONTR, VAC20, P1, DOI 10.1109/TAC.1975.1100844
   Sajewski L, 2009, KYBERNETES, V38, P1079, DOI 10.1108/03684920910976835
   Wang L, 2013, INT J CONTROL AUTOM, V11, P911, DOI 10.1007/s12555-012-9422-8
   Wang ZH, 2015, MULTIDIM SYST SIGN P, V26, P753, DOI 10.1007/s11045-014-0279-2
   Wu LG, 2007, SIGNAL PROCESS, V87, P2213, DOI 10.1016/j.sigpro.2007.03.002
   Xu HL, 2005, MULTIDIM SYST SIGN P, V16, P285, DOI 10.1007/s11045-005-1678-1
   Xu HL, 2005, SYST CONTROL LETT, V54, P339, DOI 10.1016/j.sysconle.2004.09.005
   Xu Hui-Ling, 2006, Acta Automatica Sinica, V32, P213
   Xu Hui-Ling, 2006, Control Theory & Applications, V23, P703
   Xu HL, 2011, INT J SYST SCI, V42, P609, DOI 10.1080/00207720902974728
   Xu HL, 2010, MULTIDIM SYST SIGN P, V21, P255, DOI 10.1007/s11045-010-0104-5
   Xu SY, 2005, IEEE T SIGNAL PROCES, V53, P1731, DOI 10.1109/TSP.2005.845464
   Yang R, 2006, AUTOMATICA, V42, P1507, DOI 10.1016/j.automatica.2006.04.002
   Zou Y, 2000, MULTIDIM SYST SIGN P, V11, P321
   Zou Y., 2007, J CONTROL THEORY APP, V5, P37
   Zou Y, 2008, MULTIDIM SYST SIGN P, V19, P139, DOI 10.1007/s11045-007-0035-y
NR 51
TC 1
Z9 1
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47425
EP 47439
DI 10.1007/s11042-023-14719-0
EA MAY 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000986851800008
DA 2024-07-18
ER

PT J
AU Agarwal, P
   Kumar, S
AF Agarwal, Prabhakar
   Kumar, Sandeep
TI EEG-based imagined words classification using Hilbert transform and deep
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain-computer interface; Convolutional neural network;
   Electroencephalography; Hilbert transform; Imagined speech
   classification
ID EMPIRICAL MODE DECOMPOSITION; COVERT SPEECH
AB The completely paralyzed and quadriplegic patients cannot communicate with others. However, the imagined thoughts of these patients can be used to drive assistive devices by brain-computer interfacing (BCI), the success of which relies on better classification accuracies. In this paper, we have performed an experiment for the classification of imagined words, which can provide an alternative neural path of speech communication for deprived people. A 32-channel industry-standard physiological signal system is used to measure imagined electroencephalogram (EEG) signals of five words (sos, stop, medicine, washroom, comehere) from 13 subjects. We have used the Hilbert transform to calculate time and joint time-frequency features from the imagined EEG signals. The above features are extracted individually in electrodes corresponding to nine brain regions. Each region of the brain is further analyzed in seven EEG frequency bands. The imagined speech features from each of the 63 combinations of brain region and frequency band are classified by the proposed deep architectures like long short term memory (LSTM), gated recurrent unit, and convolutional neural network (CNN). Some combinations are also classified by six traditional machine learning classifiers for performance comparison. In a five-class classification framework, we achieved the average and maximum accuracy of 71.75% and 94.29%. CNN gave high accuracy, but LSTM gave less network prediction time. Our results show that the alpha band can classify imagined speech better than other frequency bands. We have implemented subject-independent BCI, and the results are better than the state-of-the-art methods present in the literature.
C1 [Agarwal, Prabhakar; Kumar, Sandeep] Natl Inst Technol Delhi, Elect & Commun Engn, Plot FA7,Zone P1,GT Karnal Rd, Delhi 110036, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi
RP Kumar, S (corresponding author), Natl Inst Technol Delhi, Elect & Commun Engn, Plot FA7,Zone P1,GT Karnal Rd, Delhi 110036, India.
EM prabhakar@nitdelhi.ac.in; sandeep@nitdelhi.ac.in
RI Kumar, Sandeep/V-7151-2019
OI Kumar, Sandeep/0000-0001-9922-2663; Agarwal,
   Prabhakar/0000-0003-4818-9351
CR Agarwal P, 2022, INT J IMAG SYST TECH, V32, P111, DOI 10.1002/ima.22655
   Agarwal P, 2021, INDIAN J PURE AP PHY, V59, P180
   Attoh-Okine NO, 2005, HILBERT-HUANG TRANSFORM IN ENGINEERING, P281, DOI 10.1201/9781420027532.ch13
   Bakhshali MA, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101899
   Bejestani MRA, 2022, BIOMED RES INT, V2022, DOI 10.1155/2022/8333084
   Cho KYHY, 2014, Arxiv, DOI [arXiv:1406.1078, DOI 10.3115/V1/D14-1179, 10.48550/ARXIV.1406.1078, DOI 10.48550/ARXIV.1406.1078]
   D'Zmura M, 2009, LECT NOTES COMPUT SC, V5610, P40, DOI 10.1007/978-3-642-02574-7_5
   DaSalla CS, 2009, NEURAL NETWORKS, V22, P1334, DOI 10.1016/j.neunet.2009.05.008
   Deng SY, 2010, J NEURAL ENG, V7, DOI 10.1088/1741-2560/7/4/046006
   DEWAN EM, 1967, NATURE, V214, P975, DOI 10.1038/214975a0
   Esfahani ET, 2012, COMPUT AIDED DESIGN, V44, P1011, DOI 10.1016/j.cad.2011.04.008
   Fujimaki N., 1994, Brain Topography, V6, P259, DOI 10.1007/BF01211171
   Glorot Xavier, 2010, P 13 INT C ART INT S, P249
   Hahn SL, 1996, HILBERT TRANSFORMS S, V2
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang N. E., 2014, Hilbert-Huang Transform and Its Applications, V16
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Kaushik P, 2019, IEEE SENS J, V19, P2634, DOI 10.1109/JSEN.2018.2885582
   Khademi S, 2022, Artificial IntelligenceBased Brain-Computer Interface, P23, DOI DOI 10.1016/B978-0-323-91197-9.00004-7
   Kingma D. P., 2014, arXiv
   Klem G H, 1999, Electroencephalogr Clin Neurophysiol Suppl, V52, P3
   Kristensen AB, 2020, IEEE T NEUR SYS REH, V28, P1750, DOI 10.1109/TNSRE.2020.3004924
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar P, 2018, PERS UBIQUIT COMPUT, V22, P185, DOI 10.1007/s00779-017-1083-4
   LaVaque T., 1999, Journal of Neurotherapy, V3, P1, DOI DOI 10.1300/J184V03N02_01
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Saxe AM, 2014, Arxiv, DOI arXiv:1312.6120
   Martin S, 2016, SCI REP-UK, V6, DOI 10.1038/srep25803
   Nguyen CH, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aa8235
   Nie K, 2006, EAR HEARING, V27, P208, DOI 10.1097/01.aud.0000202312.31837.25
   Panachakel JT, 2019, ANNU IEEE IND CONF, DOI 10.1109/indicon47234.2019.9028925
   Porbadnigk A, 2009, BIOSIGNALS 2009: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON BIO-INSPIRED SYSTEMS AND SIGNAL PROCESSING, P376
   Qureshi MNI, 2018, IEEE T BIO-MED ENG, V65, P2168, DOI 10.1109/TBME.2017.2786251
   Ramadan RA, 2017, NEUROCOMPUTING, V223, P26, DOI 10.1016/j.neucom.2016.10.024
   Recio-Spinoso A, 2011, IEEE T BIO-MED ENG, V58, P1456, DOI 10.1109/TBME.2010.2052254
   Roy AM, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103496
   Roy Y, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab260c
   Sereshkeh AR, 2017, IEEE-ACM T AUDIO SPE, V25, P2292, DOI 10.1109/TASLP.2017.2758164
   Sereshkeh AR, 2017, INT J NEURAL SYST, V27, DOI 10.1142/S0129065717500332
   Sreeja SR, 2020, MULTIMED TOOLS APPL, V79, P13775, DOI 10.1007/s11042-019-08602-0
   Torres-García AA, 2016, EXPERT SYST APPL, V59, P1, DOI 10.1016/j.eswa.2016.04.011
   Wang L, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.070
   Xu FZ, 2022, COMPUT METH PROG BIO, V218, DOI 10.1016/j.cmpb.2022.106692
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P26697, DOI 10.1007/s11042-018-5885-9
   Zhao SN, 2015, INT CONF ACOUST SPEE, P992, DOI 10.1109/ICASSP.2015.7178118
NR 45
TC 1
Z9 1
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15664-8
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9HG1
UT WOS:000985378600006
DA 2024-07-18
ER

PT J
AU Lu, YZ
   Lu, F
AF Lu, Yangze
   Lu, Fei
TI Adaptive integration method of transformer state big data based on deep
   hash algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep hash algorithm; CNN network; Loss function; Big data of transformer
   status; Metadata; Adaptive integration of big data; Sol wrapper
AB To solve the problem of data omission and low storage efficiency of big data, an adaptive integration method of transformer state big data based on deep hash algorithm is designed. Quantitatively evaluate the fluctuation degree of big data, judge the fluctuation degree of big data of transformer status, and formulate a stress transformer status big data acquisition scheme. Design a semantic retrieval algorithm based on the deep hash algorithm, configure the CNN network, design the loss function, train the CNN network through the loss function and the input semantic data, and realize the semantic retrieval of transformer status big data. Transform the retrieved isomerization semantics into metadata to solve the problem of data isomerization in big data integration. The adaptive integration model of transformer state big data is designed to realize multi-source adaptive integration of big data. The test results show that when the heterogeneous semantic data accounts for 30% and 60%, respectively, the data operation and processing time under the proposed method is 3589 ms and 5068 ms. The adaptive integration error of this method is low, fluctuating around 0.10%. The big data storage efficiency is higher than 95%, which has certain significance for transformer maintenance.
C1 [Lu, Yangze; Lu, Fei] State Grid Hubei Elect Power Corp Ltd, Elect Power Res Inst, Wuhan 430077, Hubei, Peoples R China.
RP Lu, YZ (corresponding author), State Grid Hubei Elect Power Corp Ltd, Elect Power Res Inst, Wuhan 430077, Hubei, Peoples R China.
EM lu26715865@163.com
FU Science and Technology Project of State Grid Hubei Electric Power
   Company [B3153221001J]
FX The study was supported by "Science and Technology Project of State Grid
   Hubei Electric Power Company (Project No. B3153221001J)".
CR Chandran LR, 2021, MATER TODAY-PROC, V46, P4659, DOI 10.1016/j.matpr.2020.10.290
   Chen L, 2020, WATER RESOUR POWER, V38, P177
   Cui JB., 2021, SCI TECHNOL ENG, V21, P8481
   [杜江 Du Jiang], 2020, [电工技术学报, Transactions of China Electrotechnical Society], V35, P4306
   [韩笑 Han Xiao], 2021, [电网技术, Power System Technology], V45, P107
   Huang L., 2021, ELECT DRIVE, V51, P62
   Kolesnikov IE, 2020, 2020 GLOBAL SMART INDUSTRY CONFERENCE (GLOSIC), P315, DOI [10.1109/glosic50886.2020.9267867, 10.1109/GloSIC50886.2020.9267867]
   [刘林青 Liu Linqing], 2020, [高压电器, High Voltage Apparatus], V56, P11
   Liu YL, 2022, J MANUF SYST, V64, P288, DOI 10.1016/j.jmsy.2022.07.004
   Ma H., 2020, ELECT MEAS INSTRUM, V57, P99
   Xu QC., 2021, TRANSFORMER, V58, P25
   [禹洪波 Yu Hongbo], 2021, [电网技术, Power System Technology], V45, P3706
   [袁婉玲 Yuan Wanling], 2022, [电力建设, Electric Power  Construction], V43, P50
   [张寒 Zhang Han], 2022, [高压电器, High Voltage Apparatus], V58, P103
   Zhang T., 2020, WATER RESOUR POWER, V38, P181
   Zhao LH., 2020, ELECT MEAS INSTRUM, V57, P45
NR 16
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2023
VL 82
IS 30
BP 47313
EP 47325
DI 10.1007/s11042-023-15578-5
EA MAY 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z9FI2
UT WOS:000985452800007
DA 2024-07-18
ER

PT J
AU Ahmed, S
   Islam, S
AF Ahmed, Sajjad
   Islam, Saiful
TI Methods in detection of median filtering in digital images: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image forensics; operator detection; Median Filter;
   Median filter forensics; Operator detection; testing framework; machine
   learning
ID TRACES; IDENTIFICATION; ALGORITHM; FORENSICS; MODEL
AB When it comes to reducing impulsive noise from digital photos, the Median Filter (MF) is a nonlinear filter that can be employed effectively. This nonlinear filter is used to erase traces left by other linear filters due to the fact that they are nonlinear in nature. The application of a median filter on an image raises questions about the image's genuineness when it is discovered. For the detection of median filtering, a slew of approaches has been developed. The main purpose of this paper is to explain different parts of median filter forensics, look at some new and existing techniques in median filter forensics, and compare the pros and cons of each technique. We also developed a taxonomy to broadly classify various methods proposed for median filter forensics. In addition, we also discussed and describe the popular testing procedure that researchers in the field are using to evaluate the median filtering detection methods and may be employed as a testing framework for future studies, for other operator detection as well as for general purpose image forensics.
C1 [Ahmed, Sajjad] VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal Indore Highway, Sehore 466114, Madhya Pradesh, India.
   [Islam, Saiful] Aligarh Muslim Univ, Dept Comp Engn, ZHCET, Aligarh, India.
C3 VIT Bhopal University; Zakir Husain College Of Engineering & Technology;
   Aligarh Muslim University
RP Ahmed, S (corresponding author), VIT Bhopal Univ, Sch Comp Sci & Engn, Bhopal Indore Highway, Sehore 466114, Madhya Pradesh, India.
EM sajjadahmed@vitbhopal.ac.in; saifulislam@zhcet.ac.in
OI Ahmed, Sajjad/0000-0003-1300-0272
CR Agarwal S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11093749
   Agarwal S, 2016, SECUR COMMUN NETW, V9, P4089, DOI 10.1002/sec.1590
   Ahmed S, 2018, DIGIT INVEST, V26, P100, DOI 10.1016/j.diin.2018.08.002
   [Anonymous], 2014, ASIA PACIFIC SIGNAL
   [Anonymous], 1981, Median filtering: statistical properties, DOI DOI 10.1007/BFB0057597
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bas P, 2007, BOWS 2 BREAK OUR WAT
   Bas P, 2016, 1 IEEE IFS TC IMAGE
   Bayar B, 2018, IEEE T INF FOREN SEC, V13, P2691, DOI 10.1109/TIFS.2018.2825953
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   Cao G, 2010, IEEE INT CON MULTI, P89, DOI 10.1109/ICME.2010.5583869
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chenglong Chen, 2012, Digital-Forensics and Watermarking 10th International Workshop, IWDW 2011. Revised Selected Papers, P361, DOI 10.1007/978-3-642-32205-1_29
   Chuang WH, 2009, INT CONF ACOUST SPEE, P1517, DOI 10.1109/ICASSP.2009.4959884
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Farid H., 2006, Significance, V3, P162, DOI [DOI 10.1111/J.1740-9713.2006.00197.X, 10.1111/j.1740-9713.2006.00197.x]
   GALLAGHER NC, 1981, IEEE T ACOUST SPEECH, V29, P1136, DOI 10.1109/TASSP.1981.1163708
   Gao H, 2020, MULTIMED TOOLS APPL, V79, P12551, DOI 10.1007/s11042-019-08340-3
   Gao H, 2019, SIGNAL PROCESS-IMAGE, V72, P126, DOI 10.1016/j.image.2018.12.014
   Gloe T., 2010, ACM S APPL COMP, P1584, DOI DOI 10.1080/15567281.2010.531500
   Górecki T, 2013, INT J AP MAT COM-POL, V23, P463, DOI 10.2478/amcs-2013-0035
   Gupta A, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3176650
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jain H, 2017, 2017 IEEE INT C IDEN, P1, DOI [10.1109/ISBA.2017.7947704, DOI 10.1109/ISBA.2017.7947704]
   Jin X, 2018, IEEE ACCESS, V6, P50459, DOI 10.1109/ACCESS.2018.2867370
   Kang X, 2012, P 2012 ASIA PACIFIC, P1
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Ke Y., 2015, INT J HYBRID INF TEC, V8, P181
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kirchner M, 2008, IEEE T INF FOREN SEC, V3, P582, DOI 10.1109/TIFS.2008.2008214
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li WJ, 2019, MULTIMED TOOLS APPL, V78, P8363, DOI 10.1007/s11042-018-6831-6
   LIAO GY, 1985, IEEE T ACOUST SPEECH, V33, P1280, DOI 10.1109/TASSP.1985.1164676
   Lisha Yang, 2020, Advances in Intelligent Information Hiding and Multimedia Signal Processing. Proceedings of the 15th International Conference on IIH-MSP in conjunction with the 12th International Conference on FITAT. Smart Innovation, Systems and Technologies (SIST 157), P361, DOI 10.1007/978-981-13-9710-3_38
   Liu AN, 2017, MULTIMED TOOLS APPL, V76, P22119, DOI 10.1007/s11042-017-4845-0
   Mazumdar A, 2018, Arxiv, DOI arXiv:1808.06323
   Ng T.T., 2004, ADVENT Technical Report
   Niu YK, 2017, SIGNAL PROCESS-IMAGE, V53, P65, DOI 10.1016/j.image.2017.01.008
   Nodes T, 1984, ICASSP 84 IEEE INT C, V9, P255
   NRCS U, 2014, NAT RES CONS SERV PH
   Pasquini C, 2016, IEEE T INF FOREN SEC, V11, P1425, DOI 10.1109/TIFS.2016.2530636
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Piva A., 2013, Int. Scholarly Res. Notices, V2013
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   RABINER LR, 1975, IEEE T ACOUST SPEECH, V23, P552, DOI 10.1109/TASSP.1975.1162749
   Rhee KH, 2019, IEEE ACCESS, V7, P77524, DOI 10.1109/ACCESS.2019.2921573
   Rhee KH, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053039
   Rhee KH, 2015, 2015 IEEE 5TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN), P103, DOI 10.1109/ICCE-Berlin.2015.7391206
   Rhee RH, 2019, IEEE ACCESS, V7, P92586, DOI 10.1109/ACCESS.2019.2927540
   Ruoyu Wu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P1933, DOI 10.1109/ICIP.2011.6115849
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Swaminathan A, 2008, IEEE T INF FOREN SEC, V3, P101, DOI 10.1109/TIFS.2007.916010
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang HS, 2018, J VIS COMMUN IMAGE R, V51, P162, DOI 10.1016/j.jvcir.2018.01.011
   Tukey J. M., 1971, EXPLORATORY DATA ANA
   Tyan S., 1981, 2 DIMENSIONAL DIGITA, V43, P197
   Wang DP, 2018, MULTIMED TOOLS APPL, V77, P23411, DOI 10.1007/s11042-018-5651-z
   Wang JW, 2020, CMC-COMPUT MATER CON, V65, P929, DOI 10.32604/cmc.2020.06569
   Yang JQ, 2018, MULTIMED TOOLS APPL, V77, P7931, DOI 10.1007/s11042-017-4691-0
   Yu L, 2019, IEEE ACCESS, V7, P120594, DOI 10.1109/ACCESS.2019.2932810
   Yuan HD, 2011, IEEE T INF FOREN SEC, V6, P1335, DOI 10.1109/TIFS.2011.2161761
   Zhang J, 2020, IEEE SIGNAL PROC LET, V27, P276, DOI 10.1109/LSP.2020.2966888
   Zhang YJ, 2014, IEEE SIGNAL PROC LET, V21, P275, DOI 10.1109/LSP.2013.2295858
   Zhu BB, 2004, IEEE SIGNAL PROC MAG, V21, P40, DOI 10.1109/MSP.2004.1276112
   Zhu Tao, 2022, Proceedings of the 11th International Conference on Computer Engineering and Networks. Lecture Notes in Electrical Engineering (808), P258, DOI 10.1007/978-981-16-6554-7_30
NR 70
TC 4
Z9 4
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43945
EP 43965
DI 10.1007/s11042-023-14835-x
EA APR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000976820400001
DA 2024-07-18
ER

PT J
AU Ghosh, C
   Majumdar, D
   Mondal, B
AF Ghosh, Chanchal
   Majumdar, Dipankar
   Mondal, Bikromadittya
TI Detection of changes in synthetic aperture radar images using Modified
   Gauss-Log ratio and Fuzzy Local Information C-Means clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Change detection SAR; CNN; Fuzzy Local Information C Means; SRAD;
   Speckle Reducing Anisotropic Diffusion
ID UNSUPERVISED CHANGE DETECTION; AUTOMATIC CHANGE DETECTION
AB Change detection in SAR is currently known to be a happening field of research in the domain of computer vision and remote sensing. There are numerous approaches and techniques available to detect the change in varied types of images captured in various areas. In this paper, we present a technique for detecting changes in SAR images, which generally happen to be poor contrast and poor brightness grayscale images. Consequently, they are complicated to change detection. We developed a change detection strategy in this study that employs a Convolution Neural Network (CNN) as a classification model. Further, we have used the Fuzzy Local Information C-Means approach to find out interesting pixels which have a high possibility of being changed or unchanged. By integrating the CNN classification result with the pre-classification result, the final change map is created. In this paper, we have tried to generate some virtual samples to supplement the lack of training samples. The efficiency and robustness of the planned approach have been ascertained with investigational results on four real SAR image data sets compared to several existing methodologies.
C1 [Ghosh, Chanchal] Calcutta Inst Technol, Dept MCA, Howrah 711316, India.
   [Majumdar, Dipankar] RCC Inst Informat Technol, Dept CSE, Kolkata 15, India.
   [Mondal, Bikromadittya] BP Poddar Inst Management & Technol, Dept CSE, Kolkata 52, India.
C3 RCC Institute of Information Technology (RCCIIT); B. P. Poddar Institute
   of Management & Technology
RP Ghosh, C (corresponding author), Calcutta Inst Technol, Dept MCA, Howrah 711316, India.
EM chanchalghosh80@hotmail.com
RI Ghosh, Chanchal/AFG-4671-2022
OI Ghosh, Chanchal/0000-0002-8611-9584
CR Bazi Y, 2005, IEEE T GEOSCI REMOTE, V43, P874, DOI 10.1109/TGRS.2004.842441
   Bazi Y, 2006, IEEE GEOSCI REMOTE S, V3, P349, DOI 10.1109/LGRS.2006.869973
   Bazi Y, 2010, IEEE T GEOSCI REMOTE, V48, P3178, DOI 10.1109/TGRS.2010.2045506
   Bazi Y, 2009, INT J REMOTE SENS, V30, P6591, DOI 10.1080/01431160902882538
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P1658, DOI 10.1109/TGRS.2007.895835
   Celik T, 2009, IEEE GEOSCI REMOTE S, V6, P772, DOI 10.1109/LGRS.2009.2025059
   Feng Gao X, 2019, IEEE GEOSCI REMOTE S, V16
   Forkuo E.K., 2012, International Journal of Remote Sensing Applications, V2, P82
   Gao F, 2016, J APPL REMOTE SENS, V10, DOI 10.1117/1.JRS.10.046019
   Gao F, 2016, IEEE GEOSCI REMOTE S, V13, P1792, DOI 10.1109/LGRS.2016.2611001
   Gao YH, 2021, IEEE GEOSCI REMOTE S, V18, P484, DOI 10.1109/LGRS.2020.2977838
   Gong MG, 2017, ISPRS J PHOTOGRAMM, V129, P212, DOI 10.1016/j.isprsjprs.2017.05.001
   Gong MG, 2014, IEEE T FUZZY SYST, V22, P98, DOI 10.1109/TFUZZ.2013.2249072
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Jenerowicz M, 2011, SAR IMAGERY CHANGE D, DOI [10.1109/Multi-Temp.2011.6005086, DOI 10.1109/MULTI-TEMP.2011.6005086]
   Jia L, 2015, IEEE T GEOSCI REMOTE, V53, P3960, DOI 10.1109/TGRS.2015.2388495
   Kumar S, 2012, 2012 INTERNATIONAL CONFERENCE ON RADAR, COMMUNICATION AND COMPUTING (ICRCC), P54, DOI 10.1109/ICRCC.2012.6450547
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Liu SC, 2017, IEEE J-STARS, V10, P4124, DOI 10.1109/JSTARS.2017.2712119
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   Nefeslioglu HA, 2003, 2ND GRSS/ISPRS JOINT WORKSHOP ON REMOTE SENSING AND DATA FUSION OVER URBAN AREAS, P177, DOI 10.1109/DFUA.2003.1219982
   Wang Q, 2019, IEEE T GEOSCI REMOTE, V57, P3, DOI 10.1109/TGRS.2018.2849692
NR 22
TC 0
Z9 0
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42661
EP 42678
DI 10.1007/s11042-023-15187-2
EA APR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000970713300001
DA 2024-07-18
ER

PT J
AU Tripathi, G
   Singh, VK
   Chaurasia, BK
AF Tripathi, Gaurav
   Singh, Vishal Krishna
   Chaurasia, Brijesh Kumar
TI An energy-efficient heterogeneous data gathering for sensor-based
   internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed sensing; In-network transmission; Internet of things; Load
   distribution; Machine learning
ID NETWORKS
AB Data gathering in the Sensor-Based Internet of Things is done in the midst of many constraints such as high in-network transmissions, uneven load distribution, high energy depletion, and data heterogeneity. Interestingly, compressed sensing based solutions for heterogeneous data gathering have been widely used to resolve these issues but remain unexplored for Sensor Based Internet of Things. Therefore, with the aim of optimizing the in-network transmissions and achieving uniform load distribution in the network, this work presents a novel compressed sensing based algorithm for heterogeneous data gathering in sensor-based Internet of Things. A random markov model is used to obtain co-relation-based segregation of the region of interest, followed by a novel compressed sensing based sampling and data gathering scheme. Simulation results are obtained for two different scenarios by varying the sink position with respect to the region of interest. Comparative analysis, with state of the art methods, proves the efficacy of the proposed scheme over existing methods where the proposed scheme achieves an improved performance of 81% and 44% for network lifetime and average energy consumption respectively.
C1 [Tripathi, Gaurav; Singh, Vishal Krishna] Indian Inst Informat Technol, Dept Comp Sci, Wireless Commun & Analyt Res Lab, Lucknow 226002, Uttar Pradesh, India.
   [Chaurasia, Brijesh Kumar] Pranveer Singh Insitute Technol, Dept Comp Sci, Kanpur 209305, Uttar Pradesh, India.
RP Tripathi, G (corresponding author), Indian Inst Informat Technol, Dept Comp Sci, Wireless Commun & Analyt Res Lab, Lucknow 226002, Uttar Pradesh, India.
EM gt50@live.in; vashukrishna@gmail.com; brijeshchaurasia@ieee.org
RI Singh, Vishal Krishna/ACZ-1600-2022
OI Singh, Vishal Krishna/0000-0002-5438-579X
CR Al-Hourani A, 2014, IEEE WIREL COMMUN LE, V3, P569, DOI 10.1109/LWC.2014.2342736
   Bhattacharjee D, 2021, IEEE T GREEN COMMUN, V5, P1165, DOI 10.1109/TGCN.2021.3092765
   Dong S, 2021, IEEE SYST J, V15, P289, DOI 10.1109/JSYST.2020.2983002
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Kashani MH, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4340
   Hülsmann J, 2020, PROC VLDB ENDOW, V13, P2801, DOI 10.14778/3415478.3415479
   Jain N, 2019, IEEE SENS J, V19, P1040, DOI 10.1109/JSEN.2018.2878788
   Kashani MH, 2023, IEEE T SERV COMPUT, V16, P1505, DOI 10.1109/TSC.2022.3174475
   Kashani MH, 2021, J NETW COMPUT APPL, V192, DOI 10.1016/j.jnca.2021.103164
   Kathuria M, 2021, MULTIMED TOOLS APPL, V80, P10533, DOI 10.1007/s11042-020-10144-9
   Kovtun V, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11193-w
   Kovtun V, 2022, ALEX ENG J, V61, P7941, DOI 10.1016/j.aej.2022.01.054
   Kovtun V, 2022, IEEE ACCESS, V10, P31494, DOI 10.1109/ACCESS.2022.3160837
   Liu RS, 2020, COMPUT NETW, V167, DOI 10.1016/j.comnet.2019.107025
   Mehta D, 2022, MULTIMED TOOLS APPL, V81, P35083, DOI 10.1007/s11042-020-09633-8
   Nayyar A, 2020, MULTIMED TOOLS APPL, V79, P35221, DOI 10.1007/s11042-019-7627-z
   Ren DD, 2021, PEER PEER NETW APPL, V14, P3959, DOI 10.1007/s12083-021-01154-x
   Salim A, 2022, J NETW COMPUT APPL, V202, DOI 10.1016/j.jnca.2022.103353
   Shivhare A, 2020, IEEE SYST J, V14, P4854, DOI 10.1109/JSYST.2020.2967838
   Singh VK, 2020, IEEE T PARALL DISTR, V31, P1066, DOI 10.1109/TPDS.2019.2954902
   Singh VK, 2019, IEEE SYST J, V13, P248, DOI 10.1109/JSYST.2017.2783353
   Singh VK, 2018, WIRELESS PERS COMMUN, V99, P185, DOI 10.1007/s11277-017-5047-9
   Suman J., 2021, IMPROVING NETWORK LI, P1
   Tan HO, 2011, IEEE T PARALL DISTR, V22, P489, DOI 10.1109/TPDS.2010.68
   Tomar MS, 2019, MULTIMED TOOLS APPL, V78, P27849, DOI 10.1007/s11042-019-07844-2
   Tommasi F, 2021, MULTIMED TOOLS APPL, V80, P20929, DOI 10.1007/s11042-020-10198-9
   VELPULA P, 2021, P 2014 INT C ISSUES, P1
   Zheng HF, 2018, IEEE T SYST MAN CY-S, V48, P2315, DOI 10.1109/TSMC.2017.2734886
   Zheng HF, 2015, IEEE T PARALL DISTR, V26, P35, DOI 10.1109/TPDS.2014.2308212
NR 29
TC 1
Z9 1
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42593
EP 42616
DI 10.1007/s11042-023-15161-y
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000970495100001
DA 2024-07-18
ER

PT J
AU Kapoor, R
   Singh, N
   Kapoor, A
AF Kapoor, Rajiv
   Singh, Nikhil
   Kapoor, Aarchishya
TI Multi-sensor based object tracking using enhanced particle swarm
   optimized multi-cue granular fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Granular fusion; Multi-sensor Tracking; Particle filter; Enhanced
   Particle swarm optimization
ID VISUAL TRACKING; ADAPTIVE FUSION; FILTER; ALGORITHM; NETWORKS
AB In the discipline of computer vision, object tracking is one of the progressive and prominent areas of research with its application in the field of medical imaging, vehicle navigation, surveillance etc. Many of the proposed object tracking algorithms has shown success in the recent years. In this manuscript, we introduced a novel approach for object tracking that can develop an efficient framework of various features from different sensors. If we contemplate a RGB (red-green-blue) image it has better distinction of colors from human eye standpoint but is degraded by shadows and noise caused by illumination. Unlike RGB images thermal images are less receptive to such type of noise factors yet environmental condition can alter its distinction. To overcome this distinction issue of the two sensors a fusion of these two modalities is introduced, considering their interdependent advantages. This proposed technique is focused at enhancing the information collected from the fusion of visible imaging and thermal imaging sensors. It can also be implemented if the number of sensor are increased which in turn increases the number of features. With the use of features from two different sensors the proposed scheme utilizes the six information cues for the estimation of single output. The EPSO (enhanced particle swarm optimization) based particle filtering was adjusted with the concept of using multi-cue granular computing to weigh the particles and estimate the ultimate tracking result. After conducting attribute weight adaptation, the same approach is expanded to produce source-level fusion. The experimental performance of the method has been demonstrated on publicly available standard video sequences. After comparing it against state-of-the-art approaches, the findings show that it outperforms the trackers mentioned in the literature.
C1 [Kapoor, Rajiv; Singh, Nikhil] DTU, Dept ECE, New Delhi, India.
   [Singh, Nikhil; Kapoor, Aarchishya] Thapar Inst Engn & Technol, Dept CSE, Patiala, Punjab, India.
C3 Delhi Technological University; Thapar Institute of Engineering &
   Technology
RP Kapoor, R (corresponding author), DTU, Dept ECE, New Delhi, India.
EM rajivkapoor.dtu@gmail.com
RI Kapoor, Rajiv/AAA-2011-2022
OI Kapoor, Rajiv/0000-0003-3020-1455
FU DRDO [ERIP/ER/202205001/M/01/1811]
FX DRDO has funded this project (Approval No: ERIP/ER/202205001/M/01/1811.
   Authors acknowledge and admire the research grant provided by DRDO.
CR [Anonymous], 2021, VID AN DAT
   [Anonymous], 2019, BRIST ED PROJ MULT D
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bebis G, 2006, IMAGE VISION COMPUT, V24, P727, DOI 10.1016/j.imavis.2006.01.017
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Brasnett P, 2007, IMAGE VISION COMPUT, V25, P1217, DOI 10.1016/j.imavis.2006.07.017
   Cielniak Grzegorz, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3436, DOI 10.1109/IROS.2007.4399507
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Hanif M., 2006, Information Fusion, 2006 9th International Conference on, P1
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Heo J., 2004, Computer Vision and Pattern Recognition Workshop, page, P122, DOI DOI 10.1109/CVPR.2004.35
   Hsu C., 2012, World Academy of Science, Engineering and Technology, V68, P41, DOI DOI 10.5281/ZENODO.1075523
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   John V, 2017, SIGNAL IMAGE VIDEO P, V11, P517, DOI 10.1007/s11760-016-0989-z
   Kapoor R, 2012, IET COMPUT VIS, V6, P111, DOI 10.1049/iet-cvi.2008.0070
   Kapoor R, 2015, INT J ELECTRON, V102, P1560, DOI 10.1080/00207217.2014.984351
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kennedy J, 2006, P 2003 IEEE SWARM IN
   Kong SG, 2007, INT J COMPUT VISION, V71, P215, DOI 10.1007/s11263-006-6655-0
   Kumar A, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113711
   Kumar DA, 2019, SOFT COMPUT, V23, P4051, DOI 10.1007/s00500-018-3052-x
   Li CL, 2018, NEUROCOMPUTING, V281, P78, DOI 10.1016/j.neucom.2017.11.068
   Li TC, 2015, IEEE SIGNAL PROC MAG, V32, P70, DOI 10.1109/MSP.2014.2330626
   Liu M, 2019, IET COMPUT VIS, V13, P312, DOI 10.1049/iet-cvi.2018.5499
   Ning Y, 2019, APPL INTELL, V49, P335, DOI 10.1007/s10489-018-1258-3
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Palmerini GB, 2014, I C CONT AUTOMAT ROB, P383, DOI 10.1109/ICARCV.2014.7064336
   Pedrycz W, 2002, IEEE T SYST MAN CY A, V32, P605, DOI 10.1109/TSMCA.2002.804790
   Pedrycz W, 2002, IEEE T SYST MAN CY B, V32, P212, DOI 10.1109/3477.990878
   Qian XY, 2018, SIGNAL PROCESS-IMAGE, V60, P183, DOI 10.1016/j.image.2017.09.001
   Qian YH, 2017, INFORM SCIENCES, V382, P150, DOI 10.1016/j.ins.2016.11.024
   Qian YH, 2011, IEEE T FUZZY SYST, V19, P253, DOI 10.1109/TFUZZ.2010.2095461
   Qian YH, 2009, INT J APPROX REASON, V50, P174, DOI 10.1016/j.ijar.2008.08.004
   Rohilla R, 2017, IET COMPUT VIS, V11, P207, DOI 10.1049/iet-cvi.2016.0201
   Sardari F, 2017, APPL SOFT COMPUT, V50, P280, DOI 10.1016/j.asoc.2016.11.028
   Singh S., 2018, HDB RES ADV CONCEPTS, P105
   Singh S., 2019, INT J IMAGE GRAPH SI, V9, P39, DOI [10.5815/ijigsp.2019.07.03, DOI 10.5815/IJIGSP.2019.07.03]
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   St-Laurent L, 2010, QUANT INFRARED THERM
   Talha M, 2014, IEEE SENS J, V14, P159, DOI 10.1109/JSEN.2013.2271561
   Tong Y, 2016, SIGNAL PROCESS, V126, P149, DOI 10.1016/j.sigpro.2015.07.005
   Ursine W, 2012, 11 INT C QUANT INFR, P1, DOI DOI 10.21611/QIRT.2012.261
   Vidas S, 2012, IEEE T INSTRUM MEAS, V61, P1625, DOI 10.1109/TIM.2012.2182851
   Walia GS, 2020, PATTERN ANAL APPL, V23, P1439, DOI 10.1007/s10044-019-00847-7
   Walia GS, 2018, INT J ARTIF INTELL T, V27, DOI 10.1142/S0218213018500239
   Walia GS, 2016, MULTIMED TOOLS APPL, V75, P15821, DOI 10.1007/s11042-015-2890-0
   Walia GS, 2016, ARTIF INTELL REV, V46, P1, DOI 10.1007/s10462-015-9454-6
   Walia GS, 2014, EXPERT SYST APPL, V41, P6315, DOI 10.1016/j.eswa.2014.03.012
   Wang YD, 2007, J VLSI SIG PROC SYST, V49, P363, DOI 10.1007/s11265-007-0090-5
   Wilhelm T, 2004, ROBOT AUTON SYST, V48, P31, DOI 10.1016/j.robot.2004.05.004
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xiao G., 2016, Int. J. Dyn. Control, V4, P40
   Xiao JJ, 2018, IEEE T CYBERNETICS, V48, P2485, DOI 10.1109/TCYB.2017.2740952
   Xiao JJ, 2016, IEEE SENS J, V16, P2639, DOI 10.1109/JSEN.2016.2514704
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904
   Zheng Y, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P23, DOI 10.1109/CISDA.2007.368130
   Zhu P, 2011, APPL MATH LETT, V24, P1548, DOI 10.1016/j.aml.2011.03.044
   Zhu XY, 2022, IEEE T CIRC SYST VID, V32, P1273, DOI 10.1109/TCSVT.2021.3078436
   Zhu Xiangyuan, 2021, IEEE Transactions on Multimedia
NR 62
TC 0
Z9 0
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42417
EP 42438
DI 10.1007/s11042-023-15164-9
EA APR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200002
DA 2024-07-18
ER

PT J
AU Riza, LS
   Firdaus, Y
   Sukamto, RA
   Wahyudin
   Fariza, KA
AF Riza, Lala Septem
   Firdaus, Yahya
   Sukamto, Rosa Ariani
   Wahyudin
   Fariza, Khyrina Airin
TI Automatic generation of short-answer questions in reading comprehension
   using NLP and KNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic Question Generation; Natural Language Processing; K-Nearest
   Neighbor; Text Processing; Machine Learning
AB In general, making evaluations requires a lot of time, especially in thinking about the questions and answers. Therefore, research on automatic question generation is carried out in the hope that it can be used as a tool to generate question and answer sentences, so as to save time in thinking about questions and answers. This research focuses on automatically generating short answer questions in the reading comprehension section using Natural Language Processing (NLP) and K-Nearest Neighborhood (KNN). The questions generated use article sources from news with reliable grammar. To maintain the quality of the questions produced, machine learning methods are also used, namely by conducting training on existing questions. The stages of this research in outline are simple sentence extraction, problem classification, generating question sentences, and finally comparing candidate questions with training data to determine eligibility. The results of the experiment carried out were for the Grammatical Correctness parameter to produce a percentage of 59.52%, for the Answer Existence parameter it yielded 95.24%, while for the Difficulty Index parameter it produced a percentage of 34.92%. So that the resulting average is 63.23%. So, this software deserves to be used as an alternative to automatically create reading comprehension questions.
C1 [Riza, Lala Septem; Firdaus, Yahya; Sukamto, Rosa Ariani; Wahyudin] Univ Pendidikan Indonesia, Dept Comp Sci Educ, Bandung, Indonesia.
   [Fariza, Khyrina Airin] Univ Teknol MARA UiTM, Coll Comp Informat & Media, Melaka Branch, Melaka, Malaysia.
C3 Universitas Pendidikan Indonesia; Universiti Teknologi MARA
RP Riza, LS (corresponding author), Univ Pendidikan Indonesia, Dept Comp Sci Educ, Bandung, Indonesia.
EM lala.s.riza@upi.edu
CR Aithal SG, 2021, APPL INTELL, V51, P8484, DOI 10.1007/s10489-021-02348-9
   Ali Husam, 2010, Proceedings of QG2010: The Third Workshop on Question Generation. pages, P58
   Alsubait T, 2012, RES LEARN TECHNOL, V20, P95, DOI 10.3402/rlt.v20i0.19198
   [Anonymous], 2001, IELTS READING TESTS
   Blsták M, 2022, NAT LANG ENG, V28, P487, DOI 10.1017/S1351324921000139
   Bourne P., 2005, HIGH IMPACT IELTS WO
   Cambridge University, 1996, CAMBR PRACT TESTS IE
   Cambridge University, 2003, CAMBR IELTS 3
   Chali Y., 2012, Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012), P475
   Cotton K., 1988, Classroom questioning, V5, P1
   Cruz Roberto Ruiz, 2021, Advances in Information and Communication. Proceedings of the 2021 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 1364), P244, DOI 10.1007/978-3-030-73103-8_16
   Das B, 2022, COGN SYST RES, V72, P14, DOI 10.1016/j.cogsys.2021.11.002
   Fung Y. C., 2020, PROC INT C TECHNOL E, P136
   Gnanasekaran D., 2021, RECENT ADV COMPUT SC, V14, P1477
   Goto T, 2010, KNOWL MANAG E-LEARN, V2, P210
   Harrison R., 2013, HEADWAY ACAD SKILLS
   Heilman M., 2007, P SLATE WORKSHOP SPE, P65
   Huang Y. T., 2012, 20 INT C COMP ED ICC
   Jakeman V., 2008, NEW INSIGHT IELTS ST
   Jerome B., 2021, P 8 ACM C LEARNING S, P365, DOI DOI 10.1145/3430895.3460878
   Kalady S., 2010, P QG2010 3 WORKSH QU, P1
   Kim MK, 2008, NCM 2008: 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 2, PROCEEDINGS, P365, DOI 10.1109/NCM.2008.236
   Kumar G., 2015, P 10 WORKSH INN US N, P154, DOI DOI 10.3115/V1/W15-0618
   Kusuma SF, 2022, KNOWL-BASED SYST, V249, DOI 10.1016/j.knosys.2022.108906
   Liu M., 2012, DIALOGUE DISCOURSE S, V3, P101, DOI [10.5087/dad.2012.205, DOI 10.5087/DAD.2012.205, DOI 10.5087/dad.2012.205]
   Lougheed L., 2013, BARRONS IELTS PRACTI
   Lougheed L., 2016, BARRONS ED SERIES
   Majumder M, 2014, KNOWL MANAG E-LEARN, V6, P377
   Mazidi K, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P321
   Mazidi Karen., 2016, 9 INT NATURAL LANGUA, P51, DOI DOI 10.18653/V1/W16-6609
   McDowell C., 1996, CAMBRIDGE PRACTICE T
   Mokhtar M., 2021, INT J INTELL COMPUT, V21, P110
   Murugan S, 2022, ENG SCI TECHNOL, V26, DOI 10.1016/j.jestch.2021.04.012
   Nguyen HA, 2022, LECT NOTES COMPUT SC, V13450, P272, DOI 10.1007/978-3-031-16290-9_20
   Patrick H., 2001, MASTER IELTS 6 IELTS
   Riza L.S., 2019, INDONESIAN J SCI TEC, V4, P294, DOI [DOI 10.17509/IJOST.V4I2.18202, 10.17509/ijost.v4i2.18202]
   Riza LS., 2020, J COMPUT SOC, V1, P1
   Shuai P., 2022, APPL INTELL, P1
   Susanti Y, 2020, RES PRACT TECH ENHAN, V15, DOI 10.1186/s41039-020-00132-w
   Tsumori S., 2006, CONCURRENT ENG-RES A, V14, P151
   Van Geyte E., 2011, READING IELTS
   Vasic D, 2021, TEH VJESN, V28, P739, DOI 10.17559/TV-TV-20200402175619
   Yuan X., 2017, ARXIV
   Zhang X., 2021, J COM COMM, V9, P9, DOI [10.4236/jcc.2021.99013, DOI 10.4236/JCC.2021.99013]
NR 44
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41913
EP 41940
DI 10.1007/s11042-023-15191-6
EA APR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000968176200008
PM 37362718
OA Bronze, Green Accepted
DA 2024-07-18
ER

PT J
AU Chithambarathanu, M
   Jeyakumar, MK
AF Chithambarathanu, M.
   Jeyakumar, M. K.
TI Survey on crop pest detection using deep learning and machine learning
   approaches
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Agriculture; Pest identification for citrus; Identification of rice
   pests; Pesticide identification for cotton; Deep learning; Machine
   learning
ID CITRUS DISEASES; RECOGNITION; CLASSIFICATION; IDENTIFICATION; SYSTEM;
   SEGMENTATION; ALGORITHM; SELECTION; LEAVES
AB The most important elements in the realm of commercial food standards are effective pest management and control. Crop pests can make a huge impact on crop quality and productivity. It is critical to seek and develop new tools to diagnose the pest disease before it caused major crop loss. Crop abnormalities, pests, or dietetic deficiencies have usually been diagnosed by human experts. Anyhow, this was both costly and time-consuming. To resolve these issues, some approaches for crop pest detection have to be focused on. A clear overview of recent research in the area of crop pests and pathogens identification using techniques in Machine Learning Techniques like Random Forest (RF), Support Vector Machine (SVM), and Decision Tree (DT), Naive Bayes (NB), and also some Deep Learning methods like Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM), Deep convolutional neural network (DCNN), Deep Belief Network (DBN) was presented. The outlined strategy increases crop productivity while providing the highest level of crop protection. By offering the greatest amount of crop protection, the described strategy improves crop efficiency. This survey provides knowledge of some modern approaches for keeping an eye on agricultural fields for pest detection and contains a definition of plant pest detection to identify and categorise citrus plant pests, rice, and cotton as well as numerous ways of detecting them. These methods enable automatic monitoring of vast domains, therefore lowering human error and effort.
C1 [Chithambarathanu, M.] Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Kumaracoil, Tamilnadu, India.
   [Jeyakumar, M. K.] Noorul Islam Ctr Higher Educ, Dept Comp Applicat, Kumaracoil, Tamilnadu, India.
RP Chithambarathanu, M (corresponding author), Noorul Islam Ctr Higher Educ, Dept Comp Sci & Engn, Kumaracoil, Tamilnadu, India.
EM chithambaramthanu@gmail.com
RI Jeyakumar, MK/KIA-5250-2024
OI Jeyakumar, MK/0000-0001-9703-4685
CR Ahmad M, 2021, IEEE ACCESS, V9, P140565, DOI 10.1109/ACCESS.2021.3119655
   Ai Y, 2020, IEEE ACCESS, V8, P171686, DOI 10.1109/ACCESS.2020.3025325
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Amirruddin AD, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105221
   Barbedo JGA, 2019, BIOSYST ENG, V180, P96, DOI 10.1016/j.biosystemseng.2019.02.002
   Ayan E, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105809
   Barman U, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105661
   Chen CJ, 2020, IEEE ACCESS, V8, P180750, DOI 10.1109/ACCESS.2020.3024891
   Chen DM, 2018, COMPUT ELECTRON AGR, V152, P109, DOI 10.1016/j.compag.2018.07.002
   Chen P, 2020, COMPUT ELECTRON AGR, V176, DOI 10.1016/j.compag.2020.105612
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   Cristin R, 2020, ARTIF INTELL REV, V53, P4993, DOI 10.1007/s10462-020-09813-w
   Deng LM, 2018, BIOSYST ENG, V169, P139, DOI 10.1016/j.biosystemseng.2018.02.008
   Deng XL, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105006
   Dhingra G, 2019, MEASUREMENT, V135, P782, DOI 10.1016/j.measurement.2018.12.027
   Dong MX, 2016, IEEE INTERNET THINGS, V3, P511, DOI 10.1109/JIOT.2016.2517405
   Ebrahimi MA, 2017, COMPUT ELECTRON AGR, V137, P52, DOI 10.1016/j.compag.2017.03.016
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gao JF, 2018, BIOSYST ENG, V170, P39, DOI 10.1016/j.biosystemseng.2018.03.006
   Hassan SM, 2022, IEEE ACCESS, V10, P5390, DOI 10.1109/ACCESS.2022.3141371
   Hou CJ, 2021, J AGR FOOD RES, V5, DOI 10.1016/j.jafr.2021.100154
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Janarthan S, 2020, IEEE ACCESS, V8, P162588, DOI 10.1109/ACCESS.2020.3021487
   Jiang F, 2020, COMPUT ELECTRON AGR, V179, DOI [10.1016/j.compeg.2020.105824, 10.1016/j.compag.2020.105824]
   Johnson LK, 2019, AGR SYST, V176, DOI 10.1016/j.agsy.2019.102672
   Karar ME, 2021, ALEX ENG J, V60, P4423, DOI 10.1016/j.aej.2021.03.009
   Kaur S, 2018, 2018 6TH EDITION OF INTERNATIONAL CONFERENCE ON WIRELESS NETWORKS & EMBEDDED SYSTEMS (WECON), P1, DOI 10.1109/WECON.2018.8782058
   Khaled AY, 2018, COMPUT ELECTRON AGR, V144, P297, DOI 10.1016/j.compag.2017.11.012
   Khanramaki M, 2021, COMPUT ELECTRON AGR, V186, DOI 10.1016/j.compag.2021.106192
   Krishnamoorthy N, 2021, ENVIRON RES, V198, DOI 10.1016/j.envres.2021.111275
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Li R, 2019, IEEE ACCESS, V7, P160274, DOI 10.1109/ACCESS.2019.2949852
   Li YF, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105174
   Li Y, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105803
   Li Y, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105240
   Liu XD, 2021, IEEE T IMAGE PROCESS, V30, P2003, DOI 10.1109/TIP.2021.3049334
   Lv MJ, 2020, IEEE ACCESS, V8, P57952, DOI 10.1109/ACCESS.2020.2982443
   Miranda JR, 2020, INT J APPL EARTH OBS, V85, DOI 10.1016/j.jag.2019.101983
   Mondal D, 2017, COMPUT ELECTRON AGR, V142, P485, DOI 10.1016/j.compag.2017.11.024
   Mustafa MS, 2020, NEURAL COMPUT APPL, V32, P11419, DOI 10.1007/s00521-019-04634-7
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Negi A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P595, DOI 10.1109/ICCCIS51004.2021.9397196
   Nigam A, 2020, MATER TODAY-PROC, V33, P4856, DOI 10.1016/j.matpr.2020.08.397
   Pan WY, 2019, IEEE ACCESS, V7, P87534, DOI 10.1109/ACCESS.2019.2924973
   Rady A, 2017, POSTHARVEST BIOL TEC, V129, P37, DOI 10.1016/j.postharvbio.2017.03.007
   Rajendran D, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-021-01652-x
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Shi ZC, 2020, IEEE ACCESS, V8, P163703, DOI 10.1109/ACCESS.2020.3021830
   Shiba T, 2018, FIELD CROP RES, V217, P211, DOI 10.1016/j.fcr.2017.12.002
   Shuaibu M, 2018, COMPUT ELECTRON AGR, V148, P45, DOI 10.1016/j.compag.2017.09.038
   Su JY, 2018, COMPUT ELECTRON AGR, V155, P157, DOI 10.1016/j.compag.2018.10.017
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   Tian L, 2021, REMOTE SENS ENVIRON, V257, DOI 10.1016/j.rse.2021.112350
   Turkoglu M, 2019, J AMB INTEL HUM COMP, DOI 10.1007/s12652-019-01591-w
   Vaishnnave MP, 2020, SOFT COMPUT, V24, P16347, DOI 10.1007/s00500-020-04946-0
   Van de Vijver R, 2020, COMPUT ELECTRON AGR, V168, DOI 10.1016/j.compag.2019.105106
   Vishnoi VK, 2021, J PLANT DIS PROTECT, V128, P19, DOI 10.1007/s41348-020-00368-0
   Wang FY, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106268
   Wang J, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105834
   Wang Q, 2018, ARTHROPOD-PLANT INTE, V12, P567, DOI 10.1007/s11829-018-9604-2
   WANG T, 2021, COMPUT ELECTRON AGR, V193, P2022, DOI [10.13031/aim.202000219, DOI 10.13031/AIM.202000219]
   Wei CY, 2020, BIOCHEM BIOPH RES CO, V524, P392, DOI 10.1016/j.bbrc.2020.01.126
   Wu Y, 2022, IEEE ACCESS, V10, P41087, DOI 10.1109/ACCESS.2022.3167513
   Xiao MH, 2018, COMPUT ELECTRON AGR, V154, P482, DOI 10.1016/j.compag.2018.08.028
   Xu ZH, 2020, J FORESTRY RES, V31, P107, DOI 10.1007/s11676-018-0832-1
   Yadav Anupama, 2021, Innovations in Computer Science and Engineering. Proceedings of 8th ICICSE. Lecture Notes in Networks and Systems (LNNS 171), P651, DOI 10.1007/978-981-33-4543-0_69
   Yao Q, 2020, J INTEGR AGR, V19, P2500, DOI 10.1016/S2095-3119(20)63168-9
   Zhang DY, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105588
   Zhang DY, 2020, IEEE ACCESS, V8, P109876, DOI 10.1109/ACCESS.2020.3001652
   Zhang JH, 2018, J INTEGR AGR, V17, P1800, DOI 10.1016/S2095-3119(18)61915-X
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zhou GX, 2019, IEEE ACCESS, V7, P143190, DOI 10.1109/ACCESS.2019.2943454
NR 79
TC 9
Z9 9
U1 43
U2 103
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42277
EP 42310
DI 10.1007/s11042-023-15221-3
EA APR 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000967980300002
PM 37362671
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Daliya, VK
   Ramesh, TK
AF Daliya, V. K.
   Ramesh, T. K.
TI Optimized stacking ensemble models for the prediction of diabetic
   progression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Data analysis; Diabetes management; Ensemble learning;
   Machine learning; Regression; Stacking
ID RISK
AB The influence of applied machine learning in our day-to-day life has seen significant improvement over the last few years. The use of machine learning in Artificial Intelligence to predict various aspects of human life has helped industries in knowledge discovery, to draw inferences and to ultimately increase the business aspects. In healthcare industry, when different machines which monitor various health parameters are increasingly getting connected, it is important to process the information and draw inferences which could be very helpful and easy for the doctors to prescribe medicines and to give advice on lifestyle changes. In this paper, disease progression of Diabetes Mellitus of 442 patients is analyzed in terms of various health parameters along with six related blood serum measurements. Here, optimized stacking method is used to perform both regression and classification. In regression, the quantitative measurement of disease progression is predicted where as in classification, the disease progression is classified into high progression or low progression category. In both cases, certain base models are chosen and the accuracy score of these base models are compared with the score of optimized stacking based ensemble model.Optimized Stacking has shown promising results in comparison with the individual methods. The method is also tested on standard datasets. The result validation is performed using a large dataset with 22 features and 70,692 records, which is used to predict the diabetic information of patients. It was found that the technique has performed well with all the datasets.This method can be used as a data analysis backbone of healthcare based IoT systems for predicting diabetic progression as well as for any other related applications.
C1 [Daliya, V. K.; Ramesh, T. K.] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept ECE, Bengaluru, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Bengaluru
RP Daliya, VK (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Dept ECE, Bengaluru, India.
EM daliyavk1@gmail.com; tk.ramesh@blr.amrita.edu
OI V K, Daliya/0000-0002-4508-2922
CR Abdollahi J, 2021, ARXIV
   Akula R, 2017, SUPERVISED MACHINE L
   Alama F, 2016, INT WORKSH DAT MIN I
   Alehegn M, 2019, INT J SCI TECHNOL RE, V8
   Ang Q, 2010, 2 IEEE INT C INF MAN
   [Anonymous], 2000, REPORT EXPERT COMMIT
   Christoph F, 2020, BMC RES NOTES
   Ribeiro MHD, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105837
   Daliya VK, 2021, IEEE ACCESS
   Daliya VK, 2020, 2 PHD C ETH DRIV INN
   Daskalaki Elena, 2013, J Diabetes Sci Technol, V7, P689
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Ge ZQ, 2017, IEEE ACCESS, V5, P20590, DOI 10.1109/ACCESS.2017.2756872
   Hamdi T, 2018, BIOCYBERN BIOMED ENG
   He YQ, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18030456
   Heureux AL, 2017, IEEE ACCESS
   Hu XD, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10114016
   Jangam E, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104608
   Kalaiyarasi P, 2020, INT J PSYCH REHAB, V24
   Kumari S., 2021, INT J COGN COMPUT EN, V2, P40, DOI [10.1016/j.ijcce.2021.01.001, DOI 10.1016/J.IJCCE.2021.01.001]
   Liu JM, 2020, LIBR HI TECH, V38, P835, DOI 10.1108/LHT-08-2019-0171
   Liu YJ, 2019, RISK MANAG HEALTHC P, V12, P189, DOI 10.2147/RMHP.S225762
   Mahdavinejad MS, 2018, DIGIT COMMUN NETW, V4, P161, DOI 10.1016/j.dcan.2017.10.002
   Nai-arun N, 2015, PROCEDIA COMPUT SCI, V69, P132, DOI 10.1016/j.procs.2015.10.014
   Nai-aruna N, 2014, EGYPT INFORM J
   Shailaja K., 2018, 2018 2 INT C ELECT C, P910
   Shanthamallu US, 2017, 8 INT C INFORM INTEL
   Singh N, 2020, BIOCYBERN BIOMED ENG, V40, P1, DOI 10.1016/j.bbe.2019.10.001
   Somannavar S, 2009, DIABETES CARE, V32, P641, DOI 10.2337/dc08-0403
   Susairaj Priscilla, 2019, J Diabetes Clin Res, V1, P53, DOI 10.33696/diabetes.1.009
   Tama BA, 2019, ARTIF INTELL REV, V51, P355, DOI 10.1007/s10462-017-9565-3
   Wang Youqing, 2013, Diabetes Technol Ther, V15, P792, DOI 10.1089/dia.2013.0104
   Woldaregaya AZ, 2019, J ARTIF INTELL MED
NR 34
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42901
EP 42925
DI 10.1007/s11042-023-14858-4
EA APR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000967652700005
DA 2024-07-18
ER

PT J
AU Zhang, J
   Qi, QY
   Zhang, HL
   Du, QF
   Wang, FX
   Shi, XP
AF Zhang, Jie
   Qi, Qiye
   Zhang, Huanlong
   Du, Qifan
   Wang, Fengxian
   Shi, Xiaoping
TI Residual attention mechanism and weighted feature fusion for multi-scale
   object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Object detection; Residual attention mechanism; Weighted
   feature fusion
AB Object detection is one of the critical problems in computer vision research, which is also an essential basis for understanding high-level semantic information of images. To improve object detection performance, an improved YOLOv3 multi-scale object detection method is proposed in this article. Firstly, a residual attention module is introduced into the neck of YOLOv3, which includes the channel attention module, spatial attention module, and skip connection. The residual attention module is applied to the three layers of features obtained from the backbone, making the output feature focus on the channels and regions related to the object. Secondly, an additional weight is proposed to add to each input feature in the top-down feature fusion stage of YOLOv3, the size of which is determined by the degree of contribution of each input feature to the output features. The experimental results on KITTI, PASCAL VOC, and bird's nest datasets fully verify the effectiveness of the proposed method in object detection. The proposed method has significant value in electric power inspection and self-driving automobiles.
C1 [Zhang, Jie; Qi, Qiye; Zhang, Huanlong; Du, Qifan; Wang, Fengxian] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
   [Shi, Xiaoping] Harbin Inst Technol, Harbin, Peoples R China.
C3 Zhengzhou University of Light Industry; Harbin Institute of Technology
RP Qi, QY (corresponding author), Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, Dongfeng Rd, Zhengzhou 450002, Henan, Peoples R China.
EM 2018007@zzuli.edu.cn; 319195921@qq.com; zhl_lit@163.com;
   2807134091@qq.com; 2019031@zzuli.edu.cn; sxp@hit.edu.cn
OI Qi, Qiye/0000-0002-6325-5364
FU National Science Foundation of China [62102373, 61873246, 62006213];
   Science and Technology Research Project of Henan Province
   [212102310053]; Henan University Science and Technology Innovation
   Talents Program [21HASTIT028]
FX AcknowledgmentsThis work is supported by the grants from National
   Science Foundation of China (No.62102373, 61873246, 62006213), The
   Science and Technology Research Project of Henan Province
   (No.212102310053) and Henan University Science and Technology Innovation
   Talents Program (No.21HASTIT028).
CR Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen SH, 2020, IEEE T CYBERNETICS, V50, P2050, DOI 10.1109/TCYB.2018.2879859
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Dai JF, 2016, ADV NEUR IN, V29
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Feng D, 2022, IEEE T INTELL TRANSP, V23, P9961, DOI 10.1109/TITS.2021.3096854
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong F., 2020, IEEE ACCESS, VPP, P1
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   I Jie JL, 2020, COMPUT SYST APPL, P202
   Ju MR, 2021, NEURAL COMPUT APPL, V33, P2769, DOI 10.1007/s00521-020-05150-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li C, 2021, IEEE J BIOMED HEALTH, V25, P1429, DOI 10.1109/JBHI.2020.3037031
   Li WQ, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00641-y
   Li Y., 2019, ARXIV
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma WC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107149
   Mao JY, 2017, PROC CVPR IEEE, P6034, DOI 10.1109/CVPR.2017.639
   Park J., 2018, ARXIV
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pouyanfar S, 2019, IEEE COMPUT SOC CONF, P1267, DOI 10.1109/CVPRW.2019.00166
   Qian R., 2021, ARXIV
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Singh S, 2021, MULTIMED TOOLS APPL, P1
   Uçar A, 2017, SIMUL-T SOC MOD SIM, V93, P759, DOI 10.1177/0037549717709932
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang L, 2017, LECT NOTES COMPUT SC, V10132, P576, DOI 10.1007/978-3-319-51811-4_47
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yu CG, 2020, OPT MEMORY NEURAL, V29, P69, DOI 10.3103/S1060992X2002006X
   Yya B, 2020, Dig Signal Process, V102
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
   Zhou X., 2019, arXiv
NR 46
TC 0
Z9 0
U1 6
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40873
EP 40889
DI 10.1007/s11042-023-14997-8
EA APR 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983404900014
DA 2024-07-18
ER

PT J
AU Tanko, D
   Demir, FB
   Dogan, S
   Sahin, SE
   Tuncer, T
AF Tanko, Dahiru
   Demir, Fahrettin Burak
   Dogan, Sengul
   Sahin, Sakir Engin
   Tuncer, Turker
TI Automated speech emotion polarization for a distance education system
   based on orbital local binary pattern and an appropriate sub-band
   selection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion polarization; Speech emotion recognition; Distance
   education; 1D-OLBP; NCA; SVM
ID FEATURES
AB The distance education system was widely adopted during the Covid-19 pandemic by many institutions of learning. To measure the effectiveness of this system, it is essential to evaluate the performance of the lecturers. To this end, an automated speech emotion recognition model is a solution. This research aims to develop an accurate speech emotion recognition model that will check the lecturers/instructors' emotional state during lecture presentations. A new speech emotion dataset is collected, and an automated speech emotion recognition (SER) model is proposed to achieve this aim. The presented SER model contains three main phases, which are (i) feature extraction using multi-level discrete wavelet transform (DWT) and one-dimensional orbital local binary pattern (1D-OLBP), (ii) feature selection using neighborhood component analysis (NCA), (iii) classification using support vector machine (SVM) with ten-fold cross-validation. The proposed 1D-OLBP and NCA-based model is tested on the collected dataset, containing three emotional states with 7101 sound segments. The presented 1D-OLBP and NCA-based technique achieved a 93.40% classification accuracy using the proposed model on the new dataset. Moreover, the proposed architecture has been tested on the three publicly available speech emotion recognition datasets to highlight the general classification ability of this self-organized model. We reached over 70% classification accuracies for all three public datasets, and these results demonstrated the success of this model.
C1 [Tanko, Dahiru; Dogan, Sengul; Tuncer, Turker] Firat Univ, Coll Technol, Dept Digital Forens Engn, Elazig, Turkiye.
   [Demir, Fahrettin Burak] Bandirma Onyedi Eylul Univ, Fac Engn & Nat Sci, Deparment Software Engn, Bandirma, Turkiye.
   [Sahin, Sakir Engin] Malatya Turgut Ozal Univ, Arapgir Vocat Sch, Dept Comp Technol, Malatya, Turkiye.
C3 Firat University; Bandirma Onyedi Eylul University; Malatya Turgut Ozal
   University
RP Dogan, S (corresponding author), Firat Univ, Coll Technol, Dept Digital Forens Engn, Elazig, Turkiye.
EM 212144203@firat.edu.tr; fdemir@bandirma.edu.tr; sdogan@firat.edu.tr;
   engin.sahin@ozal.edu.tr; turkertuncer@firat.edu.tr
RI ŞAHİN, ŞAKİR ENGİN/JRY-6918-2023; DOGAN, Sengul/W-4854-2018
OI DOGAN, Sengul/0000-0001-9677-5684; Tanko, Dahiru/0000-0001-7376-3306
CR Agarwal G, 2021, MULTIMED TOOLS APPL, V80, P9961, DOI 10.1007/s11042-020-10118-x
   Aini Q., 2020, Jurnal Sistem Informasi, V16, P57
   Ancilin J, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108046
   Bandela SR, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107645
   Bastanfard A, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P592, DOI 10.1109/KBEI.2019.8735005
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cahyadi A., 2020, Dinamika Ilmu, V20, P255, DOI 10.21093/di.v20i2.2545
   Chauhan Krishna, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P1176, DOI 10.1109/ICAIS50930.2021.9395844
   Costantini G, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3501
   Dupuis Kate, 2011, Canadian Acoustics, V39, P182
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Fonnegra RD, 2018, LECT NOTES COMPUT SC, V10901, P385, DOI 10.1007/978-3-319-91238-7_31
   Goldberger J., 2004, P 17 INT C NEUR INF, P513
   Haq S., 2010, Machine Audition: Principles, Algorithms and Systems, P398, DOI DOI 10.4018/978-1-61520-919-4
   Ilyas O, 2021, BIOMED SIGNAL PROCES, V66
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jing SL, 2018, DIGIT SIGNAL PROCESS, V72, P216, DOI 10.1016/j.dsp.2017.10.016
   Kalhor E, 2021, MULTIMED TOOLS APPL, V80, P8127, DOI 10.1007/s11042-020-10119-w
   Kambalimath SS, 2021, ENVIRON EARTH SCI, V80, DOI 10.1007/s12665-021-09394-z
   Latif S, 2018, INT CONF FRONT INFO, P88, DOI 10.1109/FIT.2018.00023
   Li M., 2021, ARXIV
   Liu ZT, 2021, INFORM SCIENCES, V563, P309, DOI 10.1016/j.ins.2021.02.016
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Martin O., 2006, 22 INT C DATA ENG WO, P8, DOI [DOI 10.1109/ICDEW.2006.145, 10.1109/ICDEW.2006.145]
   Meyer P, 2021, IEEE W SP LANG TECH, P365, DOI 10.1109/SLT48900.2021.9383513
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Mustaqeem, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114177
   Nezami OM, 2019, LANG RESOUR EVAL, V53, P1, DOI 10.1007/s10579-018-9427-x
   Pan Yixiong, 2012, International Journal of Smart Home, V6, P101, DOI DOI 10.5120/431-636
   Pawar MD, 2021, MULTIMED TOOLS APPL, V80, P15563, DOI 10.1007/s11042-020-10329-2
   Pham HH, 2020, HIGH EDUC RES DEV, V39, P1327, DOI 10.1080/07294360.2020.1823945
   Ramakrishnan S, 2013, TELECOMMUN SYST, V52, P1467, DOI 10.1007/s11235-011-9624-z
   Savargiv M., 2014, Journal of Computer & Robotics, V7, P19
   Savargiv M, 2016, 2016 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P72, DOI 10.1109/RIOS.2016.7529493
   Seo J, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14071428
   Sun PF, 2020, J MED VIROL, V92, P548, DOI 10.1002/jmv.25722
   Torrence C, 1998, B AM METEOROL SOC, V79, P61, DOI 10.1175/1520-0477(1998)079<0061:APGTWA>2.0.CO;2
   Triyason T., 2020, IAIT 20 P 11 INT C A, DOI DOI 10.1145/3406601.3406635
   Tuncer T, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106547
   Tzirakis P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5089, DOI 10.1109/ICASSP.2018.8462677
   Vapnik V, 1998, NONLINEAR MODELING, P55
   Vapnik V., 2013, The nature of statistical learning theory
   Wani TM, 2021, IEEE ACCESS, V9, P47795, DOI 10.1109/ACCESS.2021.3068045
   Yildirim S, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107721
   Zhang H, 2021, Front Physiol, V12
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
NR 48
TC 3
Z9 3
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40839
EP 40856
DI 10.1007/s11042-023-14648-y
EA APR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000961838200001
PM 37362680
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Singh, S
   Mittal, N
   Singh, H
   Oliva, D
AF Singh, Simrandeep
   Mittal, Nitin
   Singh, Harbinder
   Oliva, Diego
TI Improving the segmentation of digital images by using a modified Otsu's
   between-class variance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Multi-level thresholding; Metaheuristics; Otsu;
   Kapur's entropy
ID ALGORITHM; ENTROPY
AB Image segmentation is a critical stage in the analysis and pre-processing of images. It comprises dividing the pixels according to threshold values into several segments depending on their intensity levels. Selecting the best threshold values is the most challenging task in segmentation. Because of their simplicity, resilience, reduced convergence time, and accuracy, standard multi-level thresholding (MT) approaches are more effective than bi-level thresholding methods. With increasing thresholds, computer complexity grows exponentially. A considerable number of metaheuristics were used to optimize these problems. One of the best image segmentation methods is Otsu's between-class variance. It maximizes the between-class variance to determine image threshold values. In this manuscript, a new modified Otsu function is proposed that hybridizes the concept of Otsu's between class variance and Kapur's entropy. For Kapur's entropy, a threshold value of an image is selected by maximizing the entropy of the object and background pixels. The proposed modified Otsu technique combines the ability to find an optimal threshold that maximizes the overall entropy from Kapur's and the maximum variance value of the different classes from Otsu. The novelty of the proposal is the merging of two methodologies. Clearly, Otsu's variance could be improved since the entropy (Kapur) is a method used to verify the uncertainty of a set of information. This paper applies the proposed technique over a set of images with diverse histograms, which are taken from Berkeley Segmentation Data Set 500 (BSDS500). For the search capability of the segmentation methodology, the Arithmetic Optimization algorithm (AOA), the Hybrid Dragonfly algorithm, and Firefly Algorithm (HDAFA) are employed. The proposed approach is compared with the existing state-of-art objective function of Otsu and Kapur. Qualitative experimental outcomes demonstrate that modified Otsu is highly efficient in terms of performance metrics such as PSNR, mean, threshold values, number of iterations taken to converge, and image segmentation quality.
C1 [Singh, Simrandeep] IIT Ropar, AWaDH, Dept Comp Sci & Engn, Rupnagar 140001, India.
   [Singh, Simrandeep] Chandigarh Univ, Dept Elect & Commun Engn, UCRD, Gharuan, Punjab, India.
   [Mittal, Nitin] Shri Vishwakarma Skill Univ, Fac Sci & Technol, Dept Skill, Palwal 121102, Haryana, India.
   [Singh, Harbinder] Chandigarh Engn Coll, Dept Elect & Commun Engn, Landran, Punjab, India.
   [Oliva, Diego] Univ Guadalajara, Dept Innovac Basada Informac & Conocimiento, CUCEI, Guadalajara, Jal, Mexico.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Ropar; Chandigarh University; Universidad de
   Guadalajara
RP Singh, H (corresponding author), Chandigarh Engn Coll, Dept Elect & Commun Engn, Landran, Punjab, India.
EM staff.simrandeep.singh@iitrpr.ac.in; harbinder.ece@gmail.com;
   diego.oliva@cucei.udg.mx
RI Oliva, Diego/A-3271-2016; Singh, Dr. Harbinder/I-2870-2018
OI Oliva, Diego/0000-0001-8781-7993; Singh, Dr.
   Harbinder/0000-0002-9713-6048
FU DST, Government of India
FX This work was supported by DST, Government of India, for the Technology
   Innovation Hub at the IIT Ropar in the National Mission on
   Interdisciplinary Cyber-Physical Systems framework.
CR Abak AT, 1997, PROC INT CONF DOC, P697, DOI 10.1109/ICDAR.1997.620597
   Abd Elaziz M, 2019, EXPERT SYST APPL, V125, P305, DOI 10.1016/j.eswa.2019.01.075
   Abdel-Khalek S, 2017, OPTIK, V131, P414, DOI 10.1016/j.ijleo.2016.11.039
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Aranguren I, 2022, MULTIMED TOOLS APPL, V81, P10023, DOI 10.1007/s11042-022-11959-4
   Bandyopadhyay R, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107468
   Bhandari AK, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105570
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Bohat VK, 2019, EXPERT SYST APPL, V117, P176, DOI 10.1016/j.eswa.2018.08.045
   Brest J, 2006, IEEE C EVOL COMPUTAT, P215, DOI 10.1109/CEC.2006.1688311
   Chaves AS, 1998, PHYS LETT A, V239, P13, DOI 10.1016/S0375-9601(97)00947-X
   Gandomi AH, 2013, COMMUN NONLINEAR SCI, V18, P89, DOI 10.1016/j.cnsns.2012.06.009
   Garg A., 2020, NAT COMPUT, V29, P1701
   Hashim FA, 2021, APPL INTELL, V51, P1531, DOI 10.1007/s10489-020-01893-z
   He LF, 2017, NEUROCOMPUTING, V240, P152, DOI 10.1016/j.neucom.2017.02.040
   Hemeida AM, 2019, INT J INTERACT MULTI, V5, P102, DOI 10.9781/ijimai.2018.09.001
   Hinojosa S, 2019, Metaheuristic Algorithms for image Segmentation: Theory and Applications, P59
   Horng MH, 2010, APPL MATH COMPUT, V215, P3302, DOI 10.1016/j.amc.2009.10.018
   Hosny KM, 2022, COMPUT BIOL MED, V150, DOI 10.1016/j.compbiomed.2022.106003
   Houssein EH, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114159
   Huo FC, 2020, MULTIMED TOOLS APPL, V79, P2447, DOI 10.1007/s11042-019-08231-7
   Ji WQ, 2021, MATH BIOSCI ENG, V18, P7110, DOI 10.3934/mbe.2021353
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kaur R, 2016, PROCEEDINGS ON 2016 2ND INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P450, DOI 10.1109/NGCT.2016.7877458
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kumar A, 2019, IEEE C EVOL COMPUTAT, P34, DOI [10.1109/CEC.2019.8789907, 10.1109/cec.2019.8789907]
   Lei B, 2020, SOFT COMPUT, V24, P7305, DOI 10.1007/s00500-019-04351-2
   Li K, 2014, CHIN INT CONF ELECTR
   Liang HN, 2019, IEEE ACCESS, V7, P11258, DOI 10.1109/ACCESS.2019.2891673
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liao WH, 2011, EXPERT SYST APPL, V38, P12180, DOI 10.1016/j.eswa.2011.03.053
   Nadimi-Shahraki MH, 2022, J COMPUT SCI-NETH, V61, DOI 10.1016/j.jocs.2022.101636
   Oliva D, 2021, EXPERT SYST APPL, V184, DOI 10.1016/j.eswa.2021.115481
   Ouyang HB, 2016, INFORM SCIENCES, V346, P318, DOI 10.1016/j.ins.2016.02.007
   Qi AL, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105810
   Ren LL, 2022, COMPUT BIOL MED, V148, DOI 10.1016/j.compbiomed.2022.105910
   Rodríguez-Esparza E, 2020, EXPERT SYST APPL, V155, DOI 10.1016/j.eswa.2020.113428
   Singh S, 2022, IETE J RES, V68, P2476, DOI 10.1080/03772063.2019.1711205
   Singh S, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118272
   Singh S, 2022, NEURAL COMPUT APPL, V34, P8137, DOI 10.1007/s00521-022-06900-7
   Singh S, 2021, SOFT COMPUT, V25, P10677, DOI 10.1007/s00500-021-05956-2
   Singh S, 2022, ARCH COMPUT METHOD E, V29, P1415, DOI 10.1007/s11831-021-09619-1
   Singh S, 2020, NEURAL COMPUT APPL, V32, P16681, DOI 10.1007/s00521-020-04989-2
   Sreeja P, 2018, BIOCYBERN BIOMED ENG, V38, P611, DOI 10.1016/j.bbe.2018.03.004
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Zamani H, 2022, COMPUT METHOD APPL M, V392, DOI 10.1016/j.cma.2022.114616
   Zamani H, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104314
   Zamani H, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105583
NR 48
TC 7
Z9 7
U1 14
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40701
EP 40743
DI 10.1007/s11042-023-15129-y
EA MAR 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT6E9
UT WOS:000960874500001
PM 37362708
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Yilmaz, AG
   Turhal, U
   Nabiyev, V
AF Yilmaz, Asuman Gunay
   Turhal, Ugur
   Nabiyev, Vasif
TI Face presentation attack detection performances of facial regions with
   multi-block LBP features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face presentation attack detection; LBP; Face regions; Texture analysis
ID LIVENESS DETECTION; SPOOFING DETECTION; TEXTURE; ROBUST; RECOGNITION;
   IMAGE
AB Biometric recognition systems are frequently used in daily life although they are vulnerable to attacks. Today, especially the increasing use of face authentication systems has made these systems the target of face presentation attacks (FPA). This has increased the need for sensitive systems detecting the FPAs. Recently surgical masks, frequently used due to the pandemic, directly affect the performance of face recognition systems. Researchers design face recognition systems only from the eye region. This motivated us to evaluate the FPA detection performance of the eye region. Based on this, in cases where the whole face is not visible, the FPA detection performance of other parts of the face has also been examined. Therefore, in this study, FPA detection performances of facial regions of wide face, cropped face, eyes, nose, and mouth was investigated. For this purpose, the facial regions were determined and normalized, and texture features were extracted using powerful texture descriptor local binary patterns (LBP) due to its easy computability and low processing complexity. Multi-block LBP features are used to obtain more detailed texture information. Generally uniform LBP patterns are used for feature extraction in the literature. In this study, the FPA detection performances of both uniform LBP patterns and all LBP patterns were investigated. The size of feature vector is reduced by principal component analysis, and real/fake classification is performed with support vector machines. Experimental results on NUAA, CASIA, REPLAY-ATTACK and OULU-NPU datasets show that the use of all patterns increased the performance of FPA detection.
C1 [Yilmaz, Asuman Gunay; Nabiyev, Vasif] Karadeniz Tech Univ, Trabzon, Turkiye.
   [Turhal, Ugur] Bayburt Univ, Bayburt, Turkiye.
C3 Karadeniz Technical University; Bayburt University
RP Yilmaz, AG (corresponding author), Karadeniz Tech Univ, Trabzon, Turkiye.
EM gunaya@ktu.edu.tr
RI Günay Yılmaz, Asuman/AAR-5221-2020; TURHAL, Uğur/ABC-7688-2020
OI Günay Yılmaz, Asuman/0000-0003-3960-5085; TURHAL,
   UGUR/0000-0002-5627-1833
CR Agarwal A, 2016, INT CONF BIOMETR THE
   Alotaibi A, 2017, SIGNAL IMAGE VIDEO P, V11, P713, DOI 10.1007/s11760-016-1014-2
   Alpaydin E, 2014, ADAPT COMPUT MACH LE, P1
   Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Arashloo SR, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P80, DOI 10.1109/BTAS.2017.8272685
   Bekhouche SE, 2015, AUTOMATIC AGE ESTIMA
   Boulkenafet Z, 2018, IMAGE VISION COMPUT, V77, P1, DOI 10.1016/j.imavis.2018.04.007
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Chingovska I., 2012, 2012 BIOSIG P INT C, P1
   Croux C, 2013, TECHNOMETRICS, V55, P202, DOI 10.1080/00401706.2012.727746
   Curtis S, 2013, STUD HEALTH TECHNOL
   de Luis-García R, 2003, SIGNAL PROCESS, V83, P2539, DOI 10.1016/j.sigpro.2003.08.001
   de Souza GB, 2017, IEEE T CIRCUITS-II, V64, P1397, DOI 10.1109/TCSII.2017.2764460
   Erdogmus N, 2014, IEEE T INF FOREN SEC, V9, P1084, DOI 10.1109/TIFS.2014.2322255
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gunay A., 2017, T RKIYE BILI IM VAKF, V9, P1
   Gunay Yilmaz A., 2020, EFFECT FEATURE SELEC, V5, P48
   Kavzoglu T., 2010, DESTEK VEKTOR MAKINE, P73
   Khurshid A, 2019, LECT NOTES COMPUT SC, V11786, P484, DOI 10.1007/978-3-030-30033-3_37
   Kim I, 2016, IEEE SYS MAN CYBERN, P4299, DOI 10.1109/SMC.2016.7844907
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Komulainen J, 2013, INT CONF BIOMETR
   Luqman M. M., 2020, SURVEY ANTISPOOFING
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Maatta J, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117510
   Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Raja Rohit, 2018, International Journal of Information and Computer Security, V10, P303
   Shu X, 2021, MULTIMEDIA SYST, V27, P161, DOI 10.1007/s00530-020-00719-9
   Souza L, 2018, ENG APPL ARTIF INTEL, V72, P368, DOI 10.1016/j.engappai.2018.04.013
   Sthevanie F, 2018, J PHYS CONF SER, V971, DOI 10.1088/1742-6596/971/1/012014
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tian Y, 2017, LECT NOTES COMPUT SC, V10082, P16, DOI 10.1007/978-3-319-53465-7_2
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Yang JW, 2015, IEEE T INF FOREN SEC, V10, P797, DOI 10.1109/TIFS.2015.2403306
   Yang JS, 2013, IEEE GLOB COMM CONF, P1, DOI 10.1109/GLOCOM.2013.6831038
   Zhang WL, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115990
   Zhang Z., 2012, P 2012 5 IAPR INT C, P2
   Zhao Q, 2021, MULTIMED TOOLS APPL, V80, P27279, DOI 10.1007/s11042-021-10996-9
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
NR 46
TC 3
Z9 4
U1 4
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40039
EP 40063
DI 10.1007/s11042-023-14453-7
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000983783100013
PM 37362728
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Kadian, G
   Kumar, R
AF Kadian, Garima
   Kumar, Rajiv
TI Analysis and selection of haze-relevant features for haze detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haze relevant features; Feature selection; SVM; Random forest; Machine
   learning
AB Due to smog, haze, fog, etc., the visibility of outdoor images degrades significantly. Limited visibility leads to the failure of many computer vision applications like tracking an object, intelligent transportation, etc. Many image dehazing methods have been developed to resolve this problem. But, most of the existing dehazing techniques are applied directly to the image regardless of the presence or absence of haze, which results in image deterioration. For real-world applications, it is vital to know whether the obtained image needs to be processed by dehazing methods. Hence, haze detection plays an essential role. Most of the existing techniques of haze detection used multiple features without considering their need. Thus, the proposed method presents a study analyzing different haze-relevant features. The main contributions of the proposed approach include: (i) by using haze-relevant features on RESIDE and NH-Haze datasets, a proposed dataset is prepared. (ii) analysis of features is done using multiple feature selection methods(iii) mapping between selected features and classification models. The results demonstrate that a set of features performs better when compared with another set of features.
C1 [Kadian, Garima; Kumar, Rajiv] TIET, CSED, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kadian, G (corresponding author), TIET, CSED, Patiala 147004, Punjab, India.
EM garima@thapar.edu; rkumar@thapar.edu
CR Akhtar F, 2019, INT C FRONTIER COMPU, P63
   Ancuti Codruta O., 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P501, DOI 10.1007/978-3-642-19309-5_39
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Chen BH, 2016, J DISP TECHNOL, V12, P753, DOI 10.1109/JDT.2016.2518646
   FARGE M, 1992, ANNU REV FLUID MECH, V24, P395, DOI 10.1146/annurev.fl.24.010192.002143
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   Hasler D, 2003, P SOC PHOTO-OPT INS, V5007, P87, DOI 10.1117/12.477378
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hung-Yu Yang, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P17, DOI 10.1109/IBICA.2011.9
   Jiang YT, 2017, IEEE T IMAGE PROCESS, V26, P3397, DOI 10.1109/TIP.2017.2700720
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Koschmieder H., 1924, Beitraege Phys. Atmosp., P33
   Kursa MB, 2010, J STAT SOFTW, V36, P1, DOI 10.18637/jss.v036.i11
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li Ke, 2018, Electronics Optics & Control, V25, P37, DOI 10.3969/j.issn.1671-637X.2018.03.009
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pan XX, 2015, IEEE SIGNAL PROC LET, V22, P1806, DOI 10.1109/LSP.2015.2432466
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Shi H., 2016, REV FACULTAD INGENIE, V31, P211
   Sun W, 2013, OPTIK, V124, P4770, DOI 10.1016/j.ijleo.2013.01.097
   Tripathi AK, 2012, IET IMAGE PROCESS, V6, P966, DOI 10.1049/iet-ipr.2011.0472
   Varga D, 2021, J IMAGING, V7, DOI 10.3390/jimaging7020029
   Voicu LI, 1997, J ELECTRON IMAGING, V6, P108, DOI 10.1117/12.251157
   Xiaoliang Yu, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P286, DOI 10.1109/ICIG.2011.22
   Zhang YY, 2013, CONF PROC INT SYMP C, P142, DOI 10.1109/ICPC.2013.6613842
   Zhao Z, 2013, MACH LEARN, V92, P195, DOI 10.1007/s10994-013-5373-4
   Zhou CF, 2018, LECT NOTES GEOINF CA, P71, DOI 10.1007/978-3-319-71470-7_4
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 34
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39057
EP 39076
DI 10.1007/s11042-023-14771-w
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600005
DA 2024-07-18
ER

PT J
AU Sekhar, CH
   Rao, KV
   Prasad, MHMK
AF Sekhar, C. H.
   Rao, K. Venkata
   Prasad, M. H. M. Krishna
TI Classification performance improvement by enhancing the detection
   accuracy of DDOS attacks over flash crowd using CROSS GAN (XGAN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network security; Distributed denial of service; Flash crowd; Intrusion
   detection systems; Generative Adversarial Network (GAN); Information
   gain
ID ANOMALY DETECTION; FRAMEWORK; NETWORKS; MODEL
AB Due to the rapid development of network technology in recent years, network security has drawn a lot of attention. Intrusion detection systems are crucial in preventing unwanted traffic from entering networks and computer systems. For network security, it is essential to increase the detection accuracy of network attacks using a range of strategies. However, to increase the detection accuracy of DDoS attacks, the existing model uses a Support vector machine (SVM) and K-Nearest Neighbors (KNN), which does not address the misclassification of data during transmission. Hence, a novel DDoS attack Over Flash Crowd Using Cross GAN (XGAN) has been proposed to classify the performance by enhancing the detection of DDoS attacks in the network which utilizes the information gain, chi-square, and gain ratio to determine the features first using a wrapper-based feature selection ensemble. There is no data collection available right now that has both flash crowd and DDoS sample data. To achieve more accurate categorizations using any classification model, a Generative Adversarial Network (GAN) technique is used to mimic both in the same data set. Then, a Cross Generative Adversarial Network (XGAN), a mixture of two sets of GANs that construct and classify even the imitation damaging attacks with high accuracy, has been provided to improve the detection performance of the model by minimizing the imbalance of attack records. Hence the proposed methodology enhanced the DDoS detection with high accuracy.
C1 [Sekhar, C. H.; Prasad, M. H. M. Krishna] JNT Univ, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
   [Rao, K. Venkata] Guru Nanak Inst Tech Campus, Dept Comp Sci & Engn, Ibrahimpatnam, Telangana, India.
C3 Jawaharlal Nehru Technological University - Kakinada; Guru Nanak
   Institutions Technical Campus
RP Sekhar, CH (corresponding author), JNT Univ, Dept Comp Sci & Engn, Kakinada, Andhra Pradesh, India.
EM sekhar1203@gmail.com; vrkoduganti@gmail.com; krishnaprasad.mhm@gmail.com
RI Chipurupalli, SEKHAR/AAU-1651-2020; Krishna Prasad, Munaga H
   M/ISB-1394-2023
OI Chipurupalli, SEKHAR/0000-0001-5603-1453; 
CR Agarwal A, 2022, WIRELESS PERS COMMUN, V127, P419, DOI 10.1007/s11277-021-08271-z
   Chauhan R., 2020, P 2020 INT S NETWORK, P1, DOI DOI 10.1109/ISNCC49221.2020.9297264
   Chen J.I.Z., 2020, Journal of Information Technology, V2, P108
   Chouhan N, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105612
   Das S, 2019, 2019 COMPANION OF THE 19TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY (QRS-C 2019), P471, DOI 10.1109/QRS-C.2019.00090
   de Araujo PF, 2021, IEEE INTERNET THINGS, V8, P6247, DOI 10.1109/JIOT.2020.3024800
   Dixit P, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100317
   Erhan L, 2021, INFORM FUSION, V67, P64, DOI 10.1016/j.inffus.2020.10.001
   Frost CM, 2019, TRENDS ECOL EVOL, V34, P831, DOI 10.1016/j.tree.2019.04.012
   Gurung S., 2019, International Journal of Computer Network and Information Security, V11, P8, DOI [DOI 10.5815/IJCNIS.2019.03.02, 10.5815/ijcnis.2019.03.02]
   Haider S, 2020, IEEE ACCESS, V8, P53972, DOI 10.1109/ACCESS.2020.2976908
   Hajj S, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4240
   Ibitoye O., 2019, arXiv
   Kirtas M, 2022, 2022 IEEE 14TH IMAGE, VIDEO, AND MULTIDIMENSIONAL SIGNAL PROCESSING WORKSHOP (IVMSP), DOI 10.1109/IVMSP54334.2022.9816178
   Lee J, 2021, PERS UBIQUIT COMPUT, V25, P121, DOI 10.1007/s00779-019-01332-y
   Lin T, 2020, IEEE IPCCC, DOI 10.1109/IPCCC50635.2020.9391558
   Liu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204396
   Vu L, 2023, IEEE T CYBERNETICS, V53, P565, DOI 10.1109/TCYB.2022.3163811
   Mazini M, 2019, J KING SAUD UNIV-COM, V31, P541, DOI 10.1016/j.jksuci.2018.03.011
   Monteiro R, 2020, FEATURE EXTRACTION U, P1, DOI [10.21528/CBIC2019-7, DOI 10.21528/CBIC2019-7]
   Najafimehr M, 2022, J SUPERCOMPUT, V78, P8106, DOI 10.1007/s11227-021-04253-x
   Nandakumar K, 2019, IEEE COMPUT SOC CONF, P40, DOI 10.1109/CVPRW.2019.00011
   Rezvy S, 2019, 2019 53RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI [10.1109/ciss.2019.8693059, 10.1109/CLEOE-EQEC.2019.8871857]
   Roopak M, 2019, 2019 IEEE 9TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P452, DOI 10.1109/CCWC.2019.8666588
   Sabry F, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/4653923
   Sasikumar S., 2021, TURKISH J COMPUT MAT, V12, P404
   Sharafaldin I, 2019, INT CARN CONF SECU
   Staar B, 2019, PROC CIRP, V79, P484, DOI 10.1016/j.procir.2019.02.123
   Tan L, 2020, IEEE ACCESS, V8, P161908, DOI 10.1109/ACCESS.2020.3021435
   Tang Y, 2019, J INTELL FUZZY SYST, V37, P3197, DOI 10.3233/JIFS-179121
   Ullah I, 2021, IEEE ACCESS, V9, P103906, DOI 10.1109/ACCESS.2021.3094024
   Usama M, 2019, INT WIREL COMMUN, P78, DOI 10.1109/iwcmc.2019.8766353
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Yan XD, 2021, IEEE ACM T COMPUT BI, V18, P871, DOI 10.1109/TCBB.2019.2940583
   Yu Y, 2017, LECT NOTES ARTIF INT, V10571, P144, DOI 10.1007/978-3-319-67422-3_13
NR 35
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38693
EP 38714
DI 10.1007/s11042-023-15151-0
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956328600006
DA 2024-07-18
ER

PT J
AU Li, W
   Ye, PP
   Yu, K
   Min, X
   Xie, WD
AF Li, Wei
   Ye, Panpan
   Yu, Kun
   Min, Xin
   Xie, Weidong
TI An abnormal surgical record recognition model with keywords combination
   patterns based on TextRank for medical insurance fraud detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical insurance; Fraud detection; TextRank; Keyword combination
   pattern; Rule filtering
AB Increasing insurance fraud has resulted in the loss of large amounts of money, making it difficult to expand insurance coverage and scale. This phenomenon is particularly acute in the field of health insurance. Medical insurance fraud is the falsification of medical records to obtain medical insurance funds or medical insurance benefits. Therefore, effective detection of health insurance fraud is of great importance for the rational use of health insurance funds. To address the frequent violations and frauds in health insurance, this paper proposes a keyword combination-based approach for health insurance fraud detection. First, a medical dictionary is built by TextRank to segment the surgical procedure text and extract the surgical keywords, then, the synonyms corresponding to each keyword are extracted from the electronic medical record data to form a keyword combination pattern as the final detection rule, and finally, a medical insurance fraud detection model is built on this basis. In this paper, data on acute myocardial infarction and unstable angina were selected for examination, with 1371 and 1787 cases, respectively. The performance of the model was evaluated by the coverage rate and compared experimentally with the TF-IDF and LDA algorithms. The experiments also prove the efficiency and advancedness of the algorithm in this paper. In the case of acute myocardial infarction, the method in this paper improved the coverage rate by 23.77% and 9.4% compared with the TF-IDF and LDA methods respectively. In the case of unstable angina, the coverage of the method in this paper was improved by 20.21% compared to both TF-IDF and LDA methods.
C1 [Li, Wei] Northeastern Univ, Key Lab Intelligent Comp Med Image MIIC, Minist Educ, Shenyang, Peoples R China.
   [Ye, Panpan; Min, Xin; Xie, Weidong] Northeastern Univ, Sch Comp Sci & Engn, Shenyang, Peoples R China.
   [Yu, Kun] Northeastern Univ, Biomed & Informat Engn Sch, Shenyang, Peoples R China.
C3 Northeastern University - China; Northeastern University - China;
   Northeastern University - China
RP Min, X (corresponding author), Northeastern Univ, Sch Comp Sci & Engn, Shenyang, Peoples R China.
EM 1810622@stu.neu.edu.cn
OI Xie, Weidong/0000-0003-1930-4509; Min, Xin/0000-0002-1996-7241
FU Fundamental Research Funds for the Central Universities [N2016006];
   National Key R&D Program of China [2018YFC0830701]; Shenyang Medical
   Imaging Processing Engineering Technology Research Center [17-134-8-00]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (N2016006), National Key R&D Program of China
   (2018YFC0830701), Shenyang Medical Imaging Processing Engineering
   Technology Research Center (17-134-8-00).
CR [陈列蕾 Chen Lielei], 2018, [南京大学学报. 自然科学版, Journal of Nanjing University. Natural Sciences], V54, P604
   Chiu CC, 2004, 2004 IEEE INTERNATIONAL CONFERNECE ON E-TECHNOLOGY, E-COMMERE AND E-SERVICE, PROCEEDINGS, P177
   [冯永 FENG Yong], 2010, [计算机科学, Computer Science], V37, P251
   Jiang Xiao-ping, 2011, Journal of Computer Applications, V31, P2551, DOI 10.3724/SP.J.1087.2011.02551
   Li WG, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P683, DOI 10.1109/ICISCE.2016.151
   Liu J, 2015, AAAI CONF ARTIF INTE, P3912
   [刘竹辰 Liu Zhuchen], 2018, [数据分析与知识发现, Data Analysis and Knowledge Discovery], V2, P74
   Lloyd Jean L., 2015, Journal of Nutrition in Gerontology and Geriatrics, V34, P90, DOI 10.1080/21551197.2015.1031592
   Lu Wei, 2007, Journal of Hunan University, V34, P67
   Matloob I, 2019, INT C ELECT COMPUT, DOI 10.1109/ecai46879.2019.9042126
   Mihalcea R., 2004, P 2004 C EMPIRICAL M, P404, DOI DOI 10.3115/1219044.1219064
   Pandey P, 2018, ANAL DET HLTH INS FR
   Rosen-Zvi M., 2004, Pro- ceedings of the 20th conference on Uncertainty in artificial intelligence, UAI '04, P487, DOI DOI 10.5555/1036843.1036902
   Shamsi S, 2020, PARASITOL RES, V119, P1729, DOI 10.1007/s00436-020-06672-w
   Soleymani MH, 2018, DARU, V26, P209, DOI 10.1007/s40199-018-0227-z
   [王景中 Wang Jingzhong], 2015, [计算机应用, Journal of Computer Applications], V35, P2901
   [谢玮 Xie Wei], 2016, [计算机应用研究, Application Research of Computers], V33, P798
   Ye Xuemei, 2019, Computer Engineering and Applications, V55, P104, DOI 10.3778/j.issn.1002-8331.1805-0071
   Yuan L., 2010, INSURANCE STUD, V12, P115
   Yuan L, 2011, THESIS JILIN U
   Zhang HX, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON MATHEMATICS AND ARTIFICIAL INTELLIGENCE (ICMAI 2018), P85, DOI 10.1145/3208788.3208803
NR 21
TC 1
Z9 1
U1 12
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30949
EP 30963
DI 10.1007/s11042-023-14529-4
EA MAR 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000955293100005
DA 2024-07-18
ER

PT J
AU Cheres, I
   Groza, A
AF Cheres, Ioana
   Groza, Adrian
TI The profile: unleashing your deepfake self
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AI ethics; AI and art; Full body puppetry
ID IMAGE
AB From the way we perceive society to the way we perceive ourselves, the virtual environment is changing the fundamental mechanisms of living. There is a significant gap in understanding the impact of current AI technologies on society. For instance, deepfake creates realistic forgeries that make people unable to distinguish reality from fiction, while filtering algorithms distort the perception by amplifying the interests of the user. The speed and scale of the virtual world and its hazy moral context put pressure on regulators to build the groundwork of ethical codes and regulatory frameworks. The multifaceted nature of such regulatory frameworks - legal, technological, societal, political, ethical - make it a challenging task, in which the public perception remains a key issue.The study presents a multimedia art installation - "The Profile"- based on deepfake technologies, in which the users movements are gradually learned and an alter ego is generated. The user becomes confused when this alter ego starts to deviate from its initial mirroring behaviour. "The Profile" artwork aims to raise awareness of the main threats of current online technologies and dark patterns employed online. The users experience ethical dilemmas regarding the impact of the latest technologies in a metaphoric approach. The interaction is structured in three parts that match the steps of creating an online identity: (i) filling personal data, (ii) agreeing to terms and conditions, and (iii) receiving personalised content. Our work extends the current state-of-the-art by using the decomposition of the frame along with the image simplification, real time rendering and the combination of ethics and art for human-centred technology. We also discuss some of the risks of AI, along with the proposal of art as a way to approach technology ethics. With the "The Profile", we aim to raise awareness about the power of deepfakes, build new technology, understand human behaviour, and present a fresh perspective on intertwining art and AI.
C1 [Cheres, Ioana; Groza, Adrian] Tech Univ Cluj Napoca, Dept Comp Sci, Cluj Napoca, Romania.
C3 Technical University of Cluj Napoca
RP Groza, A (corresponding author), Tech Univ Cluj Napoca, Dept Comp Sci, Cluj Napoca, Romania.
EM cheresioana@gmail.com; Adrian.Groza@cs.utcluj.ro
RI Groza, Adrian/D-6401-2011
OI Groza, Adrian/0000-0003-0143-5631
FU European Union [951962]; H2020 - Industrial Leadership [951962] Funding
   Source: H2020 - Industrial Leadership
FX AcknowledgementsAuthors would like to thank the anonymous reviewers for
   their valuable comments and suggestions. The project was improved and
   further developed during the
   https://www.youtube.com/watch?v=h9g2lTc5lAoMindBugs project. TheProfile
   @ MindBugs is part of the https://mediafutures.eu/MediaFutures project.
   This project has received funding from the European Union's framework
   Horizon 2020 for research and innovation programme under grant agreement
   No 951962.
CR Arcas BAY, 2017, ARTS, V6, DOI 10.3390/arts6040018
   Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Alighieri D, 1472, DIVINE COMEDY, V1
   Baudrillard Jean., 1994, SIMULACRA SIMULATION
   Baumann F, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.048301
   Bregler C., 1997, P 24 ANN C COMP GRAP, V31, P353, DOI DOI 10.1145/258734.258880
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Caporusso Nicholas, 2021, Advances in Artificial Intelligence, Software and Systems Engineering, P235
   Carter S., 2017, Distill, DOI DOI 10.23915/DISTILL.00009
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Chomanski B, 2021, MIND MACH, V31, P257, DOI 10.1007/s11023-021-09562-x
   Commission E, 2021, PROP REG LAYING HARM
   Danesi M., 2018, CIGARETTES HIGH HEEL
   DeepfakesWeb.com, 2018, WEBS CREAT DEEPF AN
   Dobber T, 2021, INT J PRESS/POLIT, V26, P69, DOI 10.1177/1940161220944364
   Elgammal A, 2017, arXiv
   Festinger L, 1954, HUM RELAT, V7, P117, DOI 10.1177/001872675400700202
   Fido D, 2020, PSYARXIV
   Floridi L, 2018, MIND MACH, V28, P689, DOI 10.1007/s11023-018-9482-5
   Giles P, 2019, J CULT ECON-UK, V12, P612, DOI 10.1080/17530350.2019.1639068
   Giorgio Patrini Henry Ajder FC, 2019, STATE DEEPFAKES LAND
   Goethe JW, 2020, PROJECT GUTENBERG
   Goodfellow I. J., 2014, ARXIV
   Groh MMR, 2019, THESIS MIT
   GUNTHER AC, 1993, JOURNALISM QUART, V70, P58, DOI 10.1177/107769909307000107
   Holland G, 2016, BODY IMAGE, V17, P100, DOI 10.1016/j.bodyim.2016.02.008
   Hong JW, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3326337
   Ioana C, 2021, VIDEO PRESENTATION P
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kang D, 2017, IEEE INT C CL COMP, P301, DOI 10.1109/CLUSTER.2017.17
   Kapur A, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P43, DOI 10.1145/3172944.3172977
   Kietzmann J, 2020, BUS HORIZONS, V63, P135, DOI 10.1016/j.bushor.2019.11.006
   Lee M, 2021, COMPUT HUM BEHAV, V114, DOI 10.1016/j.chb.2020.106579
   Li YT, 2019, PROC CVPR IEEE, P6322, DOI 10.1109/CVPR.2019.00649
   Lupton Deborah., 2016, The quantified self
   Manago AM, 2015, SEX ROLES, V72, P1, DOI 10.1007/s11199-014-0441-1
   Mazzone M, 2019, ARTS, V8, DOI 10.3390/arts8010026
   Mmasked.com, 2020, WEBS CREAT DEEPF AN
   Mordvintsev A., 2014, OpenCV-Python Tutorials
   Schneider Tim., 2018, Artnet News
   Shearer E., 2020, NEWS USE SOCIAL MEDI
   Sreckovic S, 2022, MIND MACH, V32, P159, DOI 10.1007/s11023-021-09575-6
   Tulyakov S, 2018, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR.2018.00165
   Unit SF, 2021, TACKL DEEPF EUR POL
   van Den Berg P, 2007, BODY IMAGE, V4, P257, DOI 10.1016/j.bodyim.2007.04.003
   Wang T., 2018, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Zadka M., 2019, DevOps in Python: Infrastructure as Python, P111, DOI [10.1007/978-1-4842-4433-3_9, DOI 10.1007/978-1-4842-4433-3_9]
   Zakharov E, 2019, IEEE I CONF COMP VIS, P9458, DOI 10.1109/ICCV.2019.00955
NR 50
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31839
EP 31854
DI 10.1007/s11042-023-14568-x
EA MAR 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000984224700011
DA 2024-07-18
ER

PT J
AU Khanna, M
   Singh, LK
   Thawkar, S
   Goyal, M
AF Khanna, Munish
   Singh, Law Kumar
   Thawkar, Shankar
   Goyal, Mayur
TI Deep learning based computer-aided automatic prediction and grading
   system for diabetic retinopathy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Deep learning; Convolutional neural networks;
   Multi class classification; Ensemble model; LSTM-CNN
ID CONVOLUTIONAL NEURAL-NETWORKS; IDENTIFICATION; DIAGNOSIS; ALGORITHM
AB Diabetic Retinopathy (DR) is a consequence of diabetes mellitus that results in damage to the retina's blood vessel networks. It is now the major cause of irreversible blindness among diabetics. It is more prevalent in those with a history of diabetes mellitus. A high blood glucose level results in the loss of blood and other fluids from the retina's blood vessels. The importance of early detection and treatment of this illness cannot be overstated. In medical image processing, reliably detecting diabetic retinopathy from digital fundus pictures is considered an open challenge that requires the exploration of innovative approaches. An automated computerized system accomplishes this goal via a series of processes, including the identification and classification of lesions in fundus images. We are motivated by the researchers who chose to use deep learning for the detection of many diseases, like glaucoma, due to its recent breakthroughs and significant success over typical machine learning techniques in a variety of applications. The goal of this article is to develop reformed networks for detecting and categorizing diabetic retinopathy into five classes. Through this work, three novel Convolutional Neural Networks(CNNs) based on deep learning have been proposed for the prediction of diabetic retinopathy. The first proposed network is built from scratch, the second network is the ensemble of five best-performing networks, and the last one is the Convolutional Neural Network-Long Short Term Memory (CNN-LSTM) model. The performance of three proposed networks is compared with twenty-one well-accepted image nets. The effectiveness of the proposed reformed networks is validated using multiple performance indicators on seven experiments of three Kaggle datasets (separately and in combination of these). The presented work achieves the maximum accuracy of 0.9545 (highest average-wise 0.9368), a maximum F1 score of 0.9685 (highest average-wise 0.9374), the maximum sensitivity of 0.9566 (highest average-wise 0.9420),and a maximum AUC score of 0.9769 (highest average-wise 0.9395). The results of the experiments showed that the provided model outperforms the many current models in terms of classification. So, the results of the calculations show that with the proposed networks, retinal problems in diabetic patients can be effectively found so that they can get a better diagnosis and avoid losing their sight.
C1 [Khanna, Munish; Goyal, Mayur] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
   [Singh, Law Kumar] GLA Univ, Dept Comp Engn & Applicat, Mathura 281406, India.
   [Thawkar, Shankar] Hindustan Coll Sci & Technol, Dept Informat Technol, Mathura 281122, India.
C3 GLA University
RP Khanna, M (corresponding author), Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura 281122, India.
EM munishkhanna.official@rocketmail.com; lawkumarcs@gmail.com;
   Shankar.thawkar@gmail.com; mayurg6832@gmail.com
RI Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852; Thawkar,
   Shankar/0000-0002-0118-9605
CR Ahmadi-Khatir Ali, 2014, 2014 IEEE PES General Meeting: Conference & Exposition, DOI 10.1109/PESGM.2014.6939252
   Alyoubi W. L., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Amalia R., 2021, Journal of Physics: Conference Series, V1722, P12010, DOI [DOI 10.1088/1742-6596/1722/1/012010, 10.1088/1742-6596/1722/1/012010]
   [Anonymous], 2016, Int J Eng Res Technol
   [Anonymous], Diabetes in india
   Atre S, 2019, LANCET GLOB HEALTH, V7, pE418, DOI 10.1016/S2214-109X(18)30556-4
   Atre S, 2015, PERSPECT PUBLIC HEAL, V135, P257, DOI 10.1177/1757913914565197
   Ayan E, 2022, ARAB J SCI ENG, V47, P2123, DOI 10.1007/s13369-021-06127-z
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Bodapati JD, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060914
   Butt M. M., 2019, Procedia Comput. Sci., V163, P283, DOI [10.1016/j.procs.2019.12.110, DOI 10.1016/J.PROCS.2019.12.110]
   Casanova R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098587
   Chang K, 2018, J AM MED INFORM ASSN, V25, P945, DOI 10.1093/jamia/ocy017
   Chen H., 2018, 2018 IEEE 23 INT C D, P1, DOI [DOI 10.1109/ICDSP.2018.8631882, 10.1109/ICDSP.2018.8631882]
   Colas E, 2016, ACTA OPHTHALMOL, V94, DOI 10.1111/j.1755-3768.2016.0635
   Dal Canto E, 2019, EUR J PREV CARDIOL, V26, P25, DOI 10.1177/2047487319878371
   Das Sraddha, 2021, Biomedical Signal Processing and Control, V68, P303, DOI 10.1016/j.bspc.2021.102600
   Das S, 2022, MULTIMED TOOLS APPL, V81, P8007, DOI 10.1007/s11042-021-11824-w
   Dow C, 2018, EUR J EPIDEMIOL, V33, P141, DOI 10.1007/s10654-017-0338-8
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   Esfahani MT, 2018, Leonardo Electron J Pract Technol, V17, P233
   Esteva A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-020-00376-2
   Fenner BJ, 2018, OPHTHALMOL THER, V7, P333, DOI 10.1007/s40123-018-0153-7
   García G, 2017, LECT NOTES COMPUT SC, V10614, P635, DOI 10.1007/978-3-319-68612-7_72
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Goel N, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103624
   Goel N, 2022, SOFT COMPUT, V26, P1231, DOI 10.1007/s00500-021-06546-y
   Gondal WM, 2017, IEEE IMAGE PROC, P2069, DOI 10.1109/ICIP.2017.8296646
   Graham B., 2015, Diabetic Retinopathy Detection
   Gräsbeck TC, 2016, AM J OPHTHALMOL, V169, P227, DOI 10.1016/j.ajo.2016.06.037
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Gupta G, 2017, COMPUT MED IMAG GRAP, V55, P124, DOI 10.1016/j.compmedimag.2016.08.005
   Harangi B, 2019, IEEE ENG MED BIO, P2699, DOI [10.1109/embc.2019.8857073, 10.1109/EMBC.2019.8857073]
   Hemanth DJ, 2020, NEURAL COMPUT APPL, V32, P707, DOI 10.1007/s00521-018-03974-0
   Islam MM, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105320
   Jaafar HF, 2011, EUR SIGNAL PR CONF, P66
   Janakiramaiah B, 2021, EVOL INTELL, V14, P635, DOI 10.1007/s12065-020-00353-4
   Janakiramaiah B., 2021, TRENDS DEEP LEARNING, P157, DOI [10.1016/B978-0-12-822226-3.00007-6, DOI 10.1016/B978-0-12-822226-3.00007-6]
   Kalyani G, 2023, COMPLEX INTELL SYST, V9, P2651, DOI 10.1007/s40747-021-00318-9
   Karim T, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ROBOTICS, ELECTRICAL AND SIGNAL PROCESSING TECHNIQUES (ICREST), P606, DOI [10.1109/ICREST.2019.8644439, 10.1109/icrest.2019.8644439]
   Khan MA, 2021, ADV CIV ENG, V2021, DOI 10.1155/2021/6618407
   Khan Z, 2021, IEEE ACCESS, V9, P61408, DOI 10.1109/ACCESS.2021.3074422
   Kumar S, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105815
   Li F, 2022, EYE, V36, P1433, DOI 10.1038/s41433-021-01552-8
   Lin XL, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71908-9
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Mary AR, 2021, MATER TODAY-PROC
   Mateen M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/5801870
   Math L, 2021, MULTIMED TOOLS APPL, V80, P5173, DOI 10.1007/s11042-020-09793-7
   Ministry of Health & Family Welfare (MoHFW India) & Directorate General of Health Services (DGHS), 2020, NATL PROGR PREV CONT
   Mushtaq Gazala, 2021, IOP Conference Series: Materials Science and Engineering, V1070, DOI 10.1088/1757-899X/1070/1/012049
   Najrabi D., 2018, 2018 6th Iranian Joint Congress on Fuzzy and Intelligent Systems (CFIS), P152, DOI 10.1109/CFIS.2018.8336661
   Pires R, 2019, ARTIF INTELL MED, V96, P93, DOI 10.1016/j.artmed.2019.03.009
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Qiao LF, 2020, IEEE ACCESS, V8, P104292, DOI 10.1109/ACCESS.2020.2993937
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Qummar S, 2019, IEEE ACCESS, V7, P150530, DOI 10.1109/ACCESS.2019.2947484
   Qureshi I, 2021, MULTIMED TOOLS APPL, V80, P11691, DOI 10.1007/s11042-020-10238-4
   Raju M, 2017, STUD HEALTH TECHNOL, V245, P559, DOI 10.3233/978-1-61499-830-3-559
   Reddy SS, 2020, MAT TODAY P
   Renukadevi NT, 2021, IOP C SERIES MAT SCI, V1055
   Safi H, 2018, SURV OPHTHALMOL, V63, P601, DOI 10.1016/j.survophthal.2018.04.003
   Sajid S, 2019, ARAB J SCI ENG, V44, P9249, DOI 10.1007/s13369-019-03967-8
   Salamat N, 2019, ARTIF INTELL MED, V97, P168, DOI 10.1016/j.artmed.2018.10.009
   Samanta A, 2020, PATTERN RECOGN LETT, V135, P293, DOI 10.1016/j.patrec.2020.04.026
   Saxena G., 2020, Intell.-Based Med., V3, DOI [10.1016/j.ibmed.2020.100022, DOI 10.1016/J.IBMED.2020.100022]
   Schaal KB, 2019, RETINA-J RET VIT DIS, V39, P79, DOI 10.1097/IAE.0000000000001938
   Seth S, 2018, J STAT MANAG SYST, V21, P569, DOI 10.1080/09720510.2018.1466965
   Shahin EM, 2012, 2012 8TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO): TODAY INFORMATION SOCIETY WHAT'S NEXT?, P20, DOI 10.1109/ICENCO.2012.6487084
   Shaikh T. A., 2020, Informatics in Medicine Unlocked, V21, P100408, DOI [10.1016/j.imu.2020.100408, DOI 10.1016/J.IMU.2020.100408]
   Shaikh TA, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01058-5
   Sharma NC, 2019, LIVEMINT
   Soleymanifard M, 2022, MULTIMED TOOLS APPL, V81, P8451, DOI 10.1007/s11042-022-12326-z
   Tandon N, 2018, LANCET GLOB HEALTH, VGlob
   Vives-Boix V, 2021, COMPUT METH PROG BIO, V206, DOI 10.1016/j.cmpb.2021.106094
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang XL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P465, DOI 10.1109/IRI.2018.00074
   Weilong Mo, 2019, Journal of Physics: Conference Series, V1237, DOI 10.1088/1742-6596/1237/2/022026
   Xu KL, 2017, MOLECULES, V22, DOI 10.3390/molecules22122054
   Yehui Yang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P533, DOI 10.1007/978-3-319-66179-7_61
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
NR 83
TC 6
Z9 6
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39255
EP 39302
DI 10.1007/s11042-023-14970-5
EA MAR 2023
PG 48
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000984224700009
DA 2024-07-18
ER

PT J
AU Hussan, M
   Gull, S
   Parah, SA
   Qureshi, GJ
AF Hussan, Muzamil
   Gull, Solihah
   Parah, Shabir A.
   Qureshi, G. J.
TI An efficient encoding based watermarking technique for tamper detection
   and localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Tamper detection; Tamper localization; DNA encoding; Huffman encoding
ID FRAGILE WATERMARKING; IMAGES
AB In the present era of preposterous melioration, the security of the image data has got prioritized. Although a large number of methods have been developed for security and authenticity verification of the images, still the prevalent data breaches raise the concern of the development of novel methods for such a purpose. Digital image watermarking is viewed as a potential approach for ensuring the integrity and authenticity of image data. To address the important authentication issue, this research proposes an efficient encoding-based watermarking scheme for tamper detection and localization. Firstly, the cover image is divided into 4 x 4 non-overlapping blocks and the Arithmetic Average (AA) of each block is computed. This value is represented by an 8-bit Vector (BV). This BV is enhanced to a 16-bit vector by appending 8-bits of an encrypted watermark. The resultant Enhanced Bit Vector (EBV) is embedded into 4 x 4 blocks of the image. For better imperceptibility, Huffman encoding is applied to the watermark while the security of the watermark is taken care of using DNA encryption. The EBV serves the purpose of tamper detection while BV serves to localize the tamper. The experimental results reveal that the proposed technique has a lower computing complexity in addition to tamper detection and localization capability. Furthermore, the suggested approach provides an average PSNR of 51.41 dB, revealing that the watermarked images exhibit high visual quality for a payload of 512,416 bits i.e., 1.95 bpp.
C1 [Hussan, Muzamil; Gull, Solihah; Parah, Shabir A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
   [Qureshi, G. J.] J&K, Higher Educ Dept, Srinagar, India.
C3 University of Kashmir
RP Parah, SA (corresponding author), Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
EM shabireltr@gmail.com
OI Parah, Shabir/0000-0001-5983-0912
FU Department of Science and Technology, Government of India
   [DST/TDT/SHRI-33/2018]
FX AcknowledgementsThe authors would like to express gratitude to the
   Department of Science and Technology, Government of India, for
   supporting this work under SHRI, scheme under Grant number:
   DST/TDT/SHRI-33/2018.
CR Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Feng B, 2020, MOBILE NETW APPL, V25, P82, DOI 10.1007/s11036-018-1186-9
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Gull S, 2021, MULTIMED TOOLS APPL, V80, P29939, DOI 10.1007/s11042-021-11170-x
   Gull S, 2020, COMPUT COMMUN, V163, P134, DOI 10.1016/j.comcom.2020.08.023
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Hussan M, 2022, MULTIMED TOOLS APPL, V81, P18563, DOI 10.1007/s11042-022-12545-4
   Hussan M, 2022, HEALTH TECHNOL-GER, V12, P385, DOI 10.1007/s12553-021-00632-9
   Hussan M, 2021, ARAB J SCI ENG, V46, P3465, DOI 10.1007/s13369-020-05135-9
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Mohsin AH, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1264-y
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Rajput V, 2020, MULTIMED TOOLS APPL, V79, P35519, DOI 10.1007/s11042-019-07971-w
   Sahu AK, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03365-9
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Selvam P, 2017, OPTIK, V145, P655, DOI 10.1016/j.ijleo.2017.07.060
   Su GD, 2021, MULTIMED TOOLS APPL, V80, P12881, DOI 10.1007/s11042-020-10451-1
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
NR 27
TC 2
Z9 2
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 18
PY 2023
DI 10.1007/s11042-023-15039-z
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA A0QJ4
UT WOS:000952258900006
DA 2024-07-18
ER

PT J
AU Manmadhan, S
   Kovoor, BC
AF Manmadhan, Sruthy
   Kovoor, Binsu C.
TI Parallel multi-head attention and term-weighted question embedding for
   medical visual question answering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-head attention; Denoising autoencoder; Radiology images;
   Supervised term weighting; Visual question answering; VQA-RAD
AB The goal of medical visual question answering (Med-VQA) is to correctly answer a clinical question posed by a medical image. Medical images are fundamentally different from images in the general domain. As a result, using general domain Visual Question Answering (VQA) models to the medical domain is impossible. Furthermore, the large-scale data required by VQA models is rarely available in the medical arena. Existing approaches of medical visual question answering often rely on transfer learning with external data to generate good image feature representation and use cross-modal fusion of visual and language features to acclimate to the lack of labelled data. This research provides a new parallel multi-head attention framework (MaMVQA) for dealing with Med-VQA without the use of external data. The proposed framework addresses image feature extraction using the unsupervised Denoising Auto-Encoder (DAE) and language feature extraction using term-weighted question embedding. In addition, we present qf-MI, a unique supervised term-weighting (STW) scheme based on the concept of mutual information (MI) between the word and the corresponding class label. Extensive experimental findings on the VQA-RAD public medical VQA benchmark show that the proposed methodology outperforms previous state-of-the-art methods in terms of accuracy while requiring no external data to train the model. Remarkably, the presented MaMVQA model achieved significantly increased accuracy in predicting answers to both close-ended (78.68%) and open-ended (55.31%) questions. Also, an extensive set of ablations are studied to demonstrate the significance of individual components of the system.
C1 [Manmadhan, Sruthy; Kovoor, Binsu C.] Cochin Univ Sci & Technol, Div Informat Technol, Kochi 682022, Kerala, India.
   [Manmadhan, Sruthy] NSS Coll Engn, Dept Comp Sci & Engn, Palakkad 678008, Kerala, India.
C3 Cochin University Science & Technology; NSS College of Engineering
   Palakkad
RP Manmadhan, S (corresponding author), Cochin Univ Sci & Technol, Div Informat Technol, Kochi 682022, Kerala, India.; Manmadhan, S (corresponding author), NSS Coll Engn, Dept Comp Sci & Engn, Palakkad 678008, Kerala, India.
EM sruthym.88@gmail.com; binsukovoor@gmail.com
OI Kovoor, Binsu/0000-0002-1566-4454; Manmadhan, Sruthy/0000-0001-6465-6883
CR Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Chen K, 2015, ARXIV
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Debole F, 2004, STUD FUZZ SOFT COMP, V138, P81
   Do T, 2021, ARXIV
   Dong JF, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3006, DOI 10.1109/ICASSP.2018.8462085
   Finn C, 2017, PR MACH LEARN RES, V70
   Fukui A, 2016, ARXIV
   Gasmi K, 2022, J SUPERCOMPUT, V78, P15042, DOI 10.1007/s11227-022-04474-8
   Gondara L, 2016, INT CONF DAT MIN WOR, P241, DOI [10.1109/ICDMW.2016.102, 10.1109/ICDMW.2016.0041]
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Guo WY, 2021, IEEE T IMAGE PROCESS, V30, P6730, DOI 10.1109/TIP.2021.3097180
   Gupta Deepak, 2021, Expert Systems with Applications, V164, P465, DOI 10.1016/j.eswa.2020.113993
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44
   Khan AU, 2020, ARXIV
   Kim JH, 2016, ADV NEUR IN, V29
   Kim J, 2018, TENCON IEEE REGION, P0090, DOI 10.1109/TENCON.2018.8650166
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lan M, 2009, IEEE T PATTERN ANAL, V31, P721, DOI 10.1109/TPAMI.2008.110
   Lao MR, 2018, IEEE ACCESS, V6, P31516, DOI 10.1109/ACCESS.2018.2844789
   Lau JJ, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.251
   Lee D, 2018, NUCL INSTRUM METH A, V884, P97, DOI 10.1016/j.nima.2017.12.050
   Lee J, 2020, BIOINFORMATICS, V36, P1234, DOI 10.1093/bioinformatics/btz682
   Li Y, 2021, WORKING NOTES CLEF, P1295
   Liu B, 2021, LECT NOTES COMPUT SC, V12902, P210, DOI 10.1007/978-3-030-87196-3_20
   Liu SY, 2022, BMC MED IMAGING, V22, DOI 10.1186/s12880-022-00800-x
   Lu JS, 2016, ADV NEUR IN, V29
   Luo QM, 2011, EXPERT SYST APPL, V38, P12708, DOI 10.1016/j.eswa.2011.04.058
   Malinowski M, 2017, INT J COMPUT VISION, V125, P110, DOI 10.1007/s11263-017-1038-2
   Matsuo R, 2018, EXPERT SYST APPL, V114, P543, DOI 10.1016/j.eswa.2018.08.028
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Nguyen BD, 2019, LECT NOTES COMPUT SC, V11767, P522, DOI 10.1007/978-3-030-32251-9_57
   Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Quan XJ, 2011, IEEE T PATTERN ANAL, V33, P1009, DOI 10.1109/TPAMI.2010.154
   Raghu M, 2019, ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross BC, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0087357
   Sharma D, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-98390-1
   Shi Y, 2018, LECT NOTES COMPUT SC, V11208, P158, DOI 10.1007/978-3-030-01225-0_10
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sitara NMS, 2021, CLEF WORKING NOTES, P1329
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tommasi T, 2016, ARXIV
   Vaswani A, 2017, ADV NEUR IN, V30
   Wei B, 2011, LECT NOTES ELECT ENG, P87, DOI DOI 10.1007/978-94-007-2105-0_11
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542
NR 55
TC 2
Z9 2
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34937
EP 34958
DI 10.1007/s11042-023-14981-2
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000947594500009
PM 37362667
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, T
   An, T
   Geng, YZ
   Liu, ZZ
   Zhao, X
   Li, S
AF Zhang, Tao
   An, Tong
   Geng, Yanzhang
   Liu, Zhongzheng
   Zhao, Xin
   Li, Shuang
TI Dual-mode active noise control system with on-line identification of
   secondary path
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Active noise control; Online identification; Mode switching;
   Self-adjusting
ID VARIABLE STEP-SIZE; OPTIMIZATION ALGORITHM
AB Active Noise Control (ANC) has achieved good performance in noise reduction, and the handling of the secondary path is vital in ANC. Systems that do not handle secondary path cannot reflect the practice situation of the system and thus fail to guide the realization of ANC. Systems that identify secondary path in off-line way cannot update the parameters to adapt to the variations of the secondary path and have higher complexity of equipment in practical applications. On-line systems can track changes of environment, but still have limited convergence due to the influence of error signals and algorithm complexity. In this paper, we present a new method from the perspective of system design rather than an improvement of algorithm, which can be further used in combination with different algorithms. We divide the system into two modes and propose a dual-mode ANC system with online identification of the secondary path. The system can run between the I-on mode and I-off mode, which can be switched automatically in real time to adapt to the changes of the secondary path in different environments. This method can handle environmental changes more efficiently, and has better noise reduction overall.
C1 [Zhang, Tao; An, Tong; Geng, Yanzhang; Liu, Zhongzheng; Zhao, Xin; Li, Shuang] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Geng, YZ (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM gregory@tju.edu.cn
RI Liu, Zhongzheng/AFI-1287-2022
OI Liu, Zhongzheng/0009-0006-6105-1639
FU National Natural Science Fund of China [62001323]
FX FundingThis research was supported by the National Natural Science Fund
   of China (No. 62001323)
CR Ahmed S, 2021, IEEE-ACM T AUDIO SPE, V29, P187, DOI 10.1109/TASLP.2020.3039607
   ALBERT A.E., 1967, STOCHASTIC APPROXIMA
   Aslam MS, 2019, IEEE T CIRCUITS-I, V66, P3955, DOI 10.1109/TCSI.2019.2910290
   Aslam MS, 2019, IEEE T CIRCUITS-I, V66, P782, DOI 10.1109/TCSI.2018.2868662
   Aslam MS, 2015, SIGNAL PROCESS, V107, P433, DOI 10.1016/j.sigpro.2014.04.012
   BOSA, BOSA BINARY ORIENTAT
   Carini A, 2008, IEEE T AUDIO SPEECH, V16, P1383, DOI 10.1109/TASL.2008.2002757
   Chatterjee I., 2021, Int. J. Mod. Res, V1, P15
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, P286, DOI [10.22266/ijies2020.1031.26, DOI 10.22266/IJIES2020.1031.26]
   Dehghani M., 2020, Int. J. Intell. Eng. Syst, V13, DOI DOI 10.22266/IJIES2020.1231.32
   Dehghani M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186173
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Dhiman G, 2021, J AMB INTEL HUM COMP, V12, P8457, DOI 10.1007/s12652-020-02580-0
   Dhiman G, 2021, ENG COMPUT-GERMANY, V37, P323, DOI 10.1007/s00366-019-00826-w
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   ERIKSSON LJ, 1989, J ACOUST SOC AM, V85, P797, DOI 10.1121/1.397552
   Feihong Gu., 2020, RES NOISE CONTROL SY
   Furlong TS, 2021, APPL ACOUST, V176, DOI 10.1016/j.apacoust.2020.107902
   Gomathi K, 2016, PROC TECH, V25, P420, DOI 10.1016/j.protcy.2016.08.127
   Jiang Y, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107816
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Kumar R., 2021, Int. J. Modern Res, V1, P1, DOI DOI 10.1109/ICMLC.2007.4370325
   Kuo SM, 1999, P IEEE, V87, P943, DOI 10.1109/5.763310
   Lee HM, 2021, APPL ACOUST, V17
   Lopes PAC, 2015, IEEE SIGNAL PROC LET, V22, P1590, DOI 10.1109/LSP.2015.2415875
   Lu L, 2021, SIGNAL PROCESS, V181, DOI 10.1016/j.sigpro.2020.107929
   Luo L, 2021, MECH SYST SIGNAL PR, V158, DOI 10.1016/j.ymssp.2021.107675
   Ma YP, 2017, IEEE-ACM T AUDIO SPE, V25, P420, DOI 10.1109/TASLP.2016.2633799
   Michalczyk M, 2016, 2016 21ST INTERNATIONAL CONFERENCE ON METHODS AND MODELS IN AUTOMATION AND ROBOTICS (MMAR), P420, DOI 10.1109/MMAR.2016.7575172
   MORGAN DR, 1980, IEEE T ACOUST SPEECH, V28, P454, DOI 10.1109/TASSP.1980.1163430
   NAGUMO JI, 1967, IEEE T AUTOMAT CONTR, VAC12, P282, DOI 10.1109/TAC.1967.1098599
   Thai N, 2017, APPL ACOUST, V116, P337, DOI 10.1016/j.apacoust.2016.09.022
   OLSON HF, 1953, J ACOUST SOC AM, V25, P1130, DOI 10.1121/1.1907249
   ROSS CF, 1982, J SOUND VIB, V80, P373, DOI 10.1016/0022-460X(82)90278-4
   Ross CF, 1980, THESIS U CAMBRIDGE
   Shen XY, 2021, APPL ACOUST, V173, DOI 10.1016/j.apacoust.2020.107712
   Shi C, 2019, ASIAPAC SIGN INFO PR, P1833, DOI 10.1109/APSIPAASC47483.2019.9023193
   SNYDER SD, 1994, IEEE T SIGNAL PROCES, V42, P950, DOI 10.1109/78.285659
   Tapia Javier, 1990, Proceedings of the IEEE International Conference on Systems Engineering, P280
   Vaishnav P.K., 2021, Int. J. Mod. Res, V1, P22, DOI DOI 10.31838/IJPR/2021.13.01.268
   Wahbi A, 2013, J COMMUN, VComput10
   Wang L, 2021, IEEJ T ELECTR ELECTR, V16, P436, DOI 10.1002/tee.23314
   [玉昊昕 Yu Haoxin], 2015, [噪声与振动控制, Noise and Vibration Control], V35, P152
   Zhang M, 2001, IEEE T SPEECH AUDI P, V9, P598, DOI 10.1109/89.928924
NR 47
TC 0
Z9 0
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33889
EP 33910
DI 10.1007/s11042-023-14477-z
EA MAR 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000946494700009
DA 2024-07-18
ER

PT J
AU Jindal, H
   Bharti, M
   Kasana, SS
   Saxena, S
AF Jindal, Himanshu
   Bharti, Monika
   Kasana, Singara Singh
   Saxena, Sharad
TI An ensemble mosaicing and ridgelet based fusion technique for underwater
   panoramic image reconstruction and its refinement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mosaicing; Frames; Reconstruction; Image refinement; Ridgelet; Fusion;
   Panoramic; Discrete; Intensity
ID RESTORATION; ENHANCEMENT; SCATTERING; TRANSFORM; LIGHT
AB Water is an integral part of the reproduction of flora and fauna and covers almost 71.4% of the Earth's surface area. It undergoes various chemical, thermal and physical changes due to man-made and natural hazard which deteriorate the quality of water. In order to monitor the quality of water, a consistent monitoring methodology is required. For this reason, Underwater Acoustic Sensor Network (UWASN) came into existence that targets to gather data through the sensors as a wired or wireless network. UWASN is used to capture underwater images for getting information and it indicates that the photographs have valuable evidence for research. However, during transmission, the lifetime of sensor network is rapidly reduced due to limited battery, storage capacity and computational power constraints. Also, the extraction does not provide complete information as the data loss occur due to Doppler spread, path loss and propagation delay, during transmission. Thus, obtaining quality panoramic images using conventional methods, is an eminent challenge due to hostile environment of underwater, that gives rise to issues like poor visibility, distortion, light scattering, noise and wavelength attenuation. Even, the erred pixels and less information in images hinders the analyzing processes used for research, industry and other economic purposes. In order to overcome the limitations, the paper proposes an ensemble technique that refines panoramic images using Mosaicing, Ridgelet and helps to retain the information along with contours by smoothening its edges. It maps line singularities into points via Radon Transform and reconstructs robust periodic images against noise. The proposed solution is validated on underwater images taken from Bubble Vision Dataset. The proposed technique through the computation of Ridglet based Fusion Technique (RBFT), refines panoramic images and combines the pixels of two or more images. The performance of RBFT is measured and compared with state-of-the-art techniques on various parameters like Mean Squared Error (MSE), Peak Signal to Noise Ratio (PSNR), Structural Similarity Index Metrics (SSIM) and Entropy. It is found that RBFT provides approximately 18.5 % less MSE, as an average. This implies that produced images has less erred pixels. As far as PSNR is concerned, RBFT provides high quality resultant panoramic images which is upto an average of 10.8 %. It is observed that RBFT generates approximately 14.3 % higher average SSIM for resultant panoramic images, suggesting that images have higher intensity values. It is found that RBFT provide upto 10.1 % average higher entropy values for resultant panoramic images. It suggests that the images are enriched with content information. Thus, the obtained results support the efficiency of the proposed ensemble technique in terms of quality and visibility of the panoramic images.
C1 [Jindal, Himanshu; Bharti, Monika] Jaypee Univ Informat Technol, Comp Sci & Engn Dept, Solan 173234, Himachal Prades, India.
   [Kasana, Singara Singh; Saxena, Sharad] Thapar Univ, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Jaypee University of Information Technology; Thapar Institute of
   Engineering & Technology
RP Jindal, H (corresponding author), Jaypee Univ Informat Technol, Comp Sci & Engn Dept, Solan 173234, Himachal Prades, India.
EM himanshu19j@gmail.com; mbharti1@gmail.com; singara@thapar.edu;
   sharad.saxena@thapar.edu
RI Jindal, Himanshu/AAM-5809-2020; Bharti, Dr. Monika/HSH-3410-2023
OI Jindal, Himanshu/0000-0002-5595-5539; Bharti, Dr.
   Monika/0000-0003-1175-7386
CR Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   Ancuti C., 2012, PROC CVPR IEEE, P81, DOI DOI 10.1109/CVPR.2012.6247661
   Andreopoulos Y, 2008, IEEE T SIGNAL PROCES, V56, P140, DOI 10.1109/TSP.2007.906727
   Ansar M. K., 2014, International Journal of Image, Graphics and Signal Processing, V6, P65, DOI 10.5815/ijigsp.2014.12.09
   Arif M, 2020, SOFT COMPUT, V24, P1815, DOI 10.1007/s00500-019-04011-5
   Bhavana V, 2015, PROCEDIA COMPUT SCI, V70, P625, DOI 10.1016/j.procs.2015.10.057
   Block M., 2017, STUD DIGIT HERIT, V1, P566, DOI [10.14434/sdh.v1i2.23214, DOI 10.14434/SDH.V1I2.23214]
   Borkar S, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Cai MX, 2020, IEEE T AUTOM SCI ENG, V17, P1443, DOI 10.1109/TASE.2019.2957782
   Candes E.J., 1998, Ridgelets: theory and applications
   Cao KM, 2018, IEEE SW SYMP IMAG, P1, DOI 10.1109/SSIAI.2018.8470347
   Chang HH, 2019, IEEE J OCEANIC ENG, V44, P1130, DOI 10.1109/JOE.2018.2865045
   Cheema AM, 2020, IEEE ACCESS, V8, P169525, DOI 10.1109/ACCESS.2020.3024181
   Chen G, 2021, PHYS ENG SCI MED, V44, P535, DOI 10.1007/s13246-021-01003-4
   Chen T, 2005, INT GEOSCI REMOTE SE, P1150
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Do MN, 2003, IEEE T IMAGE PROCESS, V12, P16, DOI 10.1109/TIP.2002.806252
   Do MN., 2002, TECH REP
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Geng N., 2012, TELKOMNIKA Indonesian Journal of Electrical Engineering, V10, P2183, DOI [DOI 10.11591/TELKOMNIKA.V10I8.1658, 10.11591/telkomnika.v10i8.1658]
   Guo QW, 2017, J OCEAN U CHINA, V16, P757, DOI 10.1007/s11802-017-3242-7
   He CT, 2010, PROCEDIA ENGINEER, V7, P280, DOI 10.1016/j.proeng.2010.11.045
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hope N, 2001, BUBBLE VISION UNDERW
   Hou W, 2007, INT GEOSCI REMOTE SE, P1889, DOI 10.1109/IGARSS.2007.4423193
   Huang IC., 2019, INT J SIGNAL PROCESS, V7, P20, DOI [10.18178/ijsps.7.1.20-25, DOI 10.18178/IJSPS.7.1.20-25]
   Iqbal Kashif, 2007, IAENG International Journal of Computer Science, V34, P239
   Ivasic-Kos M, 2015, P INT C IMAGE PROCES, P284
   Kumar N, 2020, IEEE T SUSTAIN ENERG, V11, P371, DOI 10.1109/TSTE.2019.2891558
   Lebart K, 2003, IEEE J OCEANIC ENG, V28, P673, DOI 10.1109/JOE.2003.819314
   Lei Yang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P846, DOI 10.1109/CISP.2011.6100279
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li YJ, 2016, COMPUT ELECTR ENG, V54, P68, DOI 10.1016/j.compeleceng.2016.08.008
   Liang Pei, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P978, DOI 10.1109/CISP.2010.5646931
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   Lv XQ, 2019, LECT NOTES COMPUT SC, V11901, P418, DOI 10.1007/978-3-030-34120-6_34
   Mangeruga M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101652
   Mitchell HB, 2010, IMAGE FUSION: THEORIES, TECHNIQUES AND APPLICATIONS, P1, DOI 10.1007/978-3-642-11216-4
   Naidu VPS, 2010, DEFENCE SCI J, V60, P48, DOI 10.14429/dsj.60.105
   Ouyang B, 2012, PROC SPIE, V8372, DOI 10.1117/12.920710
   Pan PW, 2018, J MAR SCI TECH-TAIW, V26, P531, DOI 10.6119/JMST.201808_26(4).0006
   Park D, 2017, IEICE T INF SYST, VE100D, P1475, DOI 10.1587/transinf.2016EDP7486
   Peng YT, 2015, IEEE IMAGE PROC, P4952, DOI 10.1109/ICIP.2015.7351749
   Qing CM, 2016, MULTIDIM SYST SIGN P, V27, P909, DOI 10.1007/s11045-016-0407-2
   Sahu V., 2014, GLOBAL J COMPUT SCI, V14, P21
   Sathya R., 2015, INT J INNOV RES COMP, V3, P1829
   Schechner YY, 2007, IEEE T PATTERN ANAL, V29, P1655, DOI 10.1109/TPAMI.2007.1141
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Sharma S., 2015, INT J COMPUT APPL, V122, P4
   Song Y, 2019, ITERATIVE REFINEMENT, V42
   Srividhya K, 2017, MULTIMED TOOLS APPL, V76, P25679, DOI 10.1007/s11042-017-4459-6
   Subhedar Mansi, 2022, Proceedings of the International e-Conference on Intelligent Systems and Signal Processing: e-ISSP 2020. Advances in Intelligent Systems and Computing (1370), P81, DOI 10.1007/978-981-16-2123-9_6
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   Treibitz T, 2012, IEEE T IMAGE PROCESS, V21, P4662, DOI 10.1109/TIP.2012.2208978
   Uemura T., 2020, 2 EAI INT C ROBOTIC, P53
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wencheng Wang, 2011, Journal of Computers, V6, P2559, DOI 10.4304/jcp.6.12.2559-2566
   Yadav G, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2392, DOI 10.1109/ICACCI.2014.6968381
   Yamashita A, 2007, IEEE INT CONF ROBOT, P4570, DOI 10.1109/ROBOT.2007.364183
   Yang X, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417738100
   Yang Y, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/579341
   Zhang MH, 2018, IEEE ACCESS, V6, P58634, DOI 10.1109/ACCESS.2018.2875344
   Zhu JL, 2022, FORENSIC SCI INT, V330, DOI 10.1016/j.forsciint.2021.111089
   Zoran LF, 2009, UNIV POLIT BUCHAR S, V71, P37
NR 67
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33719
EP 33771
DI 10.1007/s11042-023-14594-9
EA MAR 2023
PG 53
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945792800003
DA 2024-07-18
ER

PT J
AU Puttagunta, MK
   Ravi, S
   Babu, CNK
AF Puttagunta, Murali Krishna
   Ravi, S.
   Babu, C. Nelson Kennedy
TI Adversarial examples: attacks and defences on medical deep learning
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial attack; Adversarial defence; Adversarial example; Deep
   neural networks; Deep learning
ID RECOGNITION
AB In recent years, significant progress has been achieved using deep neural networks (DNNs) in obtaining human-level performance on various long-standing tasks. With the increased use of DNNs in various applications, public concern over DNNs' trustworthiness has grown. Studies conducted in the last several years have proven that deep learning models are vulnerable to small adversarial perturbations. Adversarial examples are generated from clean images by adding imperceptible perturbations. Adversarial examples are necessary for practical reasons, as they can be physically constructed, implying that DNNs are unsuitable for some image classification applications in their current state. This paper aims to provide an in-depth overview of the numerous adversarial attack strategies and defence methods. The theoretical principles, methods, and applications of adversarial attack strategies are first discussed. After that, a few research attempts on defence techniques covering the field's broad boundary are outlined. Afterwards, this study reviews recently proposed adversarial attack methods to medical deep learning systems and defence techniques against these attacks. The vulnerability of the DL model is evaluated for different medical image modalities using an adversarial attack and defence method. Some unresolved issues and obstacles are highlighted to ignite additional research efforts in this crucial area.
C1 [Puttagunta, Murali Krishna; Ravi, S.] Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Pondicherry, India.
   [Babu, C. Nelson Kennedy] Saveetha Inst Med & Tech Sci, Saveetha Sch Engn, Dept Comp Sci & Engn, Chennai 602105, India.
C3 Pondicherry University; Saveetha Institute of Medical & Technical
   Science; Saveetha School of Engineering
RP Puttagunta, MK; Ravi, S (corresponding author), Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Pondicherry, India.
EM murali93940@gmail.com; sravicite@gmail.com; cnkbabu63@gmail.com
RI Chindanur, Narendra Babu/AAF-5898-2019
OI Chindanur, Narendra Babu/0000-0002-2358-3443; Puttagunta,
   MuraliKrishna/0000-0002-2544-7832; Subban, Ravi/0000-0001-7267-9233;
   Kennedy Babu, Nelson/0000-0002-3382-4415
CR Agarwal A, 2021, IEEE T DEPEND SECURE, V18, P2106, DOI 10.1109/TDSC.2020.3027183
   Agarwal A, 2021, PATTERN RECOGN LETT, V146, P244, DOI 10.1016/j.patrec.2021.01.032
   Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   Allyn J, 2020, MEDICINE, V99, DOI 10.1097/MD.0000000000023568
   Anand D, 2020, I S BIOMED IMAGING, P1159, DOI [10.1109/ISBI45749.2020.9098369, 10.1109/isbi45749.2020.9098369]
   [Anonymous], 2016, Adversarial perturbations against deep neural networks for malware classification
   [Anonymous], 2017, ACM WORKSHOP ARTIFIC
   Athalye A, 2018, PR MACH LEARN RES, V80
   Baluja S, 2018, AAAI CONF ARTIF INTE, P2687
   Baluja Shumeet, 2017, ARXIV170309387
   Bengio S, 2016, ARXIV
   Biggio B., 2012, ARXIV12066389, P1467
   Biggio B, 2015, IEEE SIGNAL PROC MAG, V32, P31, DOI 10.1109/MSP.2015.2426728
   Brendel W, 2017, ARXIV171204248
   Buckman J., 2018, INT C LEARN REPR
   Byra M, 2020, IEEE INT ULTRA SYM, P9
   Carlini N., 2017, P 10 ACM WORKSH ART, P3, DOI DOI 10.1145/3128572.3140444
   Carlini N, 2016, DEFENSIVE DISTILLATI, V0, P1
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chakraborty A, 2021, CAAI T INTELL TECHNO, V6, P25, DOI 10.1049/cit2.12028
   Chen CF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P347, DOI 10.1109/ICCV48922.2021.00041
   Chen JY, 2021, COMPUT SECUR, V104, DOI 10.1016/j.cose.2021.102220
   Chen PY, 2018, AAAI CONF ARTIF INTE, P10
   Chen PY, 2017, P 10 ACM WORKSH ART, P15, DOI [10.1145/3128572.3140448, DOI 10.1145/3128572.3140448]
   Chen RX, 2022, INFORM SCIENCES, V600, P118, DOI 10.1016/j.ins.2022.03.056
   Chen T, 2019, CYBERSECURITY, V2, DOI 10.1186/s42400-019-0027-x
   Cheng KY, 2020, PR MACH LEARN RES, V121, P121
   Chugh T, 2018, IEEE T INF FOREN SEC, V13, P2190, DOI 10.1109/TIFS.2018.2812193
   Deldjoo Y, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439729
   Dhillon G. S., 2018, ARXIV
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Duan Ruian, 2020, arXiv
   Eberz S, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23408
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Fawaz HI., 2019, ARXIV
   Fei JW, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-0490-z
   Feinman R., 2017, arXiv
   Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399
   Finlayson SG, 2018, ARXIV
   Fischer V, 2019, ARXIV
   Gao J, 2019, ARXIV, P1
   Goodfellow I.J., 2015, PROC 3 INT C LEARN R
   Grigorescu S, 2020, ARXIV
   Grosse K., 2017, ARXIV
   Gu S, 2015, 3TH INT C LEARN REPR
   Han KJ, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108303
   Han XT, 2020, NAT MED, V26, P360, DOI 10.1038/s41591-020-0791-x
   He W, 2017, P 11 USENIX C OFF TE, P15
   He X, 2019, AAAI CONF ARTIF INTE, P8417, DOI 10.1609/aaai.v33i01.33018417
   He ZY, 2022, COMPUT SECUR, V118, DOI 10.1016/j.cose.2022.102720
   Hinton Geoffrey, 2014, NIPS DEEP LEARN WORK
   Hirano H, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00530-y
   Huang S., 2017, ARXIV
   Huang XW, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100270
   Ilahi Inaam, 2022, IEEE Transactions on Artificial Intelligence, V3, P90, DOI 10.1109/TAI.2021.3111139
   Jin GQ, 2019, INT CONF ACOUST SPEE, P3842, DOI [10.1109/ICASSP.2019.8683044, 10.1109/icassp.2019.8683044]
   Joel MZ, 2022, JCO CLIN CANCER INFO, V6, DOI 10.1200/CCI.21.00170
   Kannan H., 2018, ARXIV
   Karimian Nima, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P257, DOI 10.1109/TBIOM.2020.2992274
   Karimian N, 2019, PROC SPIE, V11009, DOI 10.1117/12.2518828
   Kaviani S, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116815
   Kingma D. P., 2014, arXiv
   Kurakin Alexey, 2017, INT C LEARN REPR
   Lal S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113922
   Lan JH, 2022, J SYST ARCHITECT, V127, DOI 10.1016/j.sysarc.2022.102526
   Li HL, 2021, INFORM FUSION, V76, P55, DOI 10.1016/j.inffus.2021.05.005
   Li J, 2020, IEEE INTERNET THINGS, V7, P5103, DOI 10.1109/JIOT.2020.2975654
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Li X, 2020, I S BIOMED IMAGING, P1154, DOI [10.1109/ISBI45749.2020.9098628, 10.1109/isbi45749.2020.9098628]
   Li YQ, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103037
   Li ZW, 2022, DISPLAYS, V73, DOI 10.1016/j.displa.2021.102143
   Liang Q, 2022, SIGNAL PROCESS-IMAGE, V103, DOI 10.1016/j.image.2022.116659
   Liao FZ, 2018, PROC CVPR IEEE, P1778, DOI 10.1109/CVPR.2018.00191
   Lin YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3756
   Liu S, 2021, IEEE T MED IMAGING
   Liu Y., 2017, INT J CONTROL, V2017, P2210
   Liu ZH, 2021, J NEURAL ENG, V18, DOI 10.1088/1741-2552/ac0f4c
   Lu JJ, 2017, IEEE I CONF COMP VIS, P446, DOI 10.1109/ICCV.2017.56
   Ma XJ, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107332
   Maiorana E., 2013, 2013 IEEE 6 INT C BI, P1
   Martins N, 2020, IEEE ACCESS, V8, P35403, DOI 10.1109/ACCESS.2020.2974752
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Metzen JH, 2017, IEEE I CONF COMP VIS, P2774, DOI 10.1109/ICCV.2017.300
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Newaz AKMI, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9322472
   Ozbulak U, 2019, LECT NOTES COMPUT SC, V11765, P300, DOI 10.1007/978-3-030-32245-8_34
   Papernot N., 2016, CORR
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Paschali M, 2018, ARXIV
   Paul R, 2020, I S BIOMED IMAGING, P1517, DOI [10.1109/ISBI45749.2020.9098740, 10.1109/isbi45749.2020.9098740]
   Pitropakis N, 2019, COMPUT SCI REV, V34, DOI 10.1016/j.cosrev.2019.100199
   Puttagunta M, 2021, MULTIMED TOOLS APPL, V80, P24365, DOI 10.1007/s11042-021-10707-4
   Qayyum A, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.587139
   Qayyum A, 2021, IEEE REV BIOMED ENG, V14, P156, DOI 10.1109/RBME.2020.3013489
   Qayyum A, 2020, IEEE COMMUN SURV TUT, V22, P998, DOI 10.1109/COMST.2020.2975048
   Qiu SL, 2022, NEUROCOMPUTING, V492, P278, DOI 10.1016/j.neucom.2022.04.020
   Rahman MA, 2021, IEEE INTERNET THINGS, V8, P9603, DOI 10.1109/JIOT.2020.3013710
   Rao C, 2020, THOROUGH COMP STUDY
   Rasool RU, 2022, J NETW COMPUT APPL, V201, DOI 10.1016/j.jnca.2022.103332
   Ros AS, 2018, AAAI CONF ARTIF INTE, P1660
   Rozsa A, 2016, IEEE COMPUT SOC CONF, P410, DOI 10.1109/CVPRW.2016.58
   Sadeghi K, 2020, IEEE T EM TOP COMP I, V4, P450, DOI [10.1109/TETCI.2020.2968933, 10.1109/tetci.2020.2968933]
   Samangouei P., 2018, 6 INT C LEARN REPR I
   Santhanam GK, 2018, ARXIV
   Sarkar S, 2017, ABS170701159 CORR
   Shao MW, 2021, INFORM SCIENCES, V554, P33, DOI 10.1016/j.ins.2020.12.013
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Song Y., 2017, ARXIV
   Srinivasan V, 2021, NEURAL NETWORKS, V137, P1, DOI 10.1016/j.neunet.2020.12.024
   Su JW, 2019, IEEE T EVOLUT COMPUT, V23, P828, DOI 10.1109/TEVC.2019.2890858
   Sun MY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P793, DOI 10.1145/3219819.3219909
   Sun XL, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104085
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taghanaki Saeid Asgari, 2018, Understanding and Interpreting Machine Learning in Medical Image Computing Applications. First International Workshops MLCN 2018, DLF 2018, and iMIMIC 2018. Held in Conjunction with MICCAI 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11038), P87, DOI 10.1007/978-3-030-02628-8_10
   Tang S., 2021, arXiv
   Tramer F, 2017, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.48550/ARXIV.1705.07204
   Tu J, 2020, P IEEE CVF C COMP VI, P13716
   Vakhshiteh F, 2021, IEEE ACCESS, V9, P92735, DOI 10.1109/ACCESS.2021.3092646
   Vladu Adrian, 2018, PROC 6 INT C LEARN R
   Wang L, 2019, ARXIV, DOI [10.48550/arXiv.1908.06281, DOI 10.48550/ARXIV.1908.06281]
   Wang L, 2022, PDAAA PROGRESSIVE DE, P879
   Wang X, 2021, EXPERT SYST APPL, Vabs/2103.1
   Wu D, 2021, ADVERSARIAL ATTACKS, P1
   Xiao CW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3905
   Xiao Chaowei, 2018, 6 INT C LEARN REPR I
   Xie CH, 2019, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2019.00059
   Xie CH, 2017, IEEE I CONF COMP VIS, P1378, DOI 10.1109/ICCV.2017.153
   Xu H, 2020, INT J AUTOM COMPUT, V17, P151, DOI 10.1007/s11633-019-1211-x
   Xu MT, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101977
   Xu W., 2017, arXiv
   Yefet N, 2020, P ACM PROGRAM LANG, V4, DOI 10.1145/3428230
   Yin SL, 2022, NEUROCOMPUTING, V478, P1, DOI 10.1016/j.neucom.2021.12.080
   Zhang JL, 2020, IEEE T NEUR NET LEAR, V31, P2578, DOI 10.1109/TNNLS.2019.2933524
   Zhang WE, 2020, ACM T INTEL SYST TEC, V11, DOI 10.1145/3374217
   Zhang X, 2021, NATL SCI REV, V8, DOI 10.1093/nsr/nwaa233
   Zhang X, 2019, IEEE T NEUR SYS REH, V27, P814, DOI 10.1109/TNSRE.2019.2908955
   ZHAO Z, 2017, ARXIV171011342
NR 140
TC 5
Z9 5
U1 6
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 33773
EP 33809
DI 10.1007/s11042-023-14702-9
EA MAR 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945311800003
DA 2024-07-18
ER

PT J
AU Chakroun, R
   Frikha, M
AF Chakroun, Rania
   Frikha, Mondher
TI A deep learning approach for text-independent speaker recognition with
   short utterances
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; i-vector; PLDA; Short utterances; Deep learning;
   DNN; CNN; LSTM; RNN
ID VERIFICATION; ROBUSTNESS; FREQUENCY; ATTENTION; SYSTEMS; GMM
AB Recently, the speaker recognition techniques have been widely attractive for their extensive use in many fields, such as speech communications, domestic services, security and access control and smart terminals. Today's interactive devices like smart-phone assistants and smart speakers need to deal with short duration speech segments. However, existing speaker recognition applications perform poorly when short utterances are available and require relatively long speech to perform well. Aiming at solving this problem, we introduce in this paper, a novel method to enhance the speaker recognition capability with short utterance speaker recognition applications. For this purpose, we considered new deep neural network architectures based on convolutional neural network (CNN) and recurrent neural network (RNN). The proposed method is evaluated with the standard i-vector based on Probabilistic Linear discriminant analysis (PLDA) approach. The experimental results show that our model could outperform the i-vector -PLDA baseline system and enhance the speaker recognition capability when significant and short utterance duration are used.
C1 [Chakroun, Rania; Frikha, Mondher] Adv Technol Image & Signal Proc ATISP Res Unit, Sfax, Tunisia.
   [Chakroun, Rania] Natl Sch Engn sfax, Sfax, Tunisia.
   [Frikha, Mondher] Natl Sch Elect & Telecommun Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax
RP Chakroun, R (corresponding author), Adv Technol Image & Signal Proc ATISP Res Unit, Sfax, Tunisia.; Chakroun, R (corresponding author), Natl Sch Engn sfax, Sfax, Tunisia.
EM chakrounrania@yahoo.fr; mondher@yahoo.fr
RI FRIKHA, Mondher/IAN-7365-2023
OI FRIKHA, Mondher/0000-0003-2584-5141
CR Abd El-Moneim S, 2020, MULTIMED TOOLS APPL, V79, P24013, DOI 10.1007/s11042-019-08293-7
   Al-karawi KA, 2021, MULTIMED TOOLS APPL, V80, P22231, DOI 10.1007/s11042-021-10767-6
   Alam MJ, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P249
   [Anonymous], 2016, Odyssey 2016, DOI [10.21437/Odyssey.2016-51, DOI 10.21437/ODYSSEY.2016-51]
   Bahmaninezhad F, 2021, SPEECH COMMUN, V129, P7, DOI 10.1016/j.specom.2021.01.001
   Bai ZX, 2021, NEURAL NETWORKS, V140, P65, DOI 10.1016/j.neunet.2021.03.004
   Bhattacharya G, 2016, IEEE W SP LANG TECH, P192, DOI 10.1109/SLT.2016.7846264
   Chakroun R, 2020, NEURAL COMPUT APPL, V32, P13863, DOI 10.1007/s00521-020-04793-y
   Chakroun R, 2020, MULTIMED TOOLS APPL, V79, P21279, DOI 10.1007/s11042-020-08824-7
   Chakroun R, 2018, IET SIGNAL PROCESS, V12, P873, DOI 10.1049/iet-spr.2016.0572
   Chiu CC, 2017, ARXIV
   Chung JS, 2018, ARXIV
   Dahl GE, 2012, IEEE T AUDIO SPEECH, V20, P30, DOI 10.1109/TASL.2011.2134090
   Das RK, 2018, IETE TECH REV, V35, P599, DOI 10.1080/02564602.2017.1357507
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INT CONF ACOUST SPEE, P4237, DOI 10.1109/ICASSP.2009.4960564
   Devi KJ, 2023, COMPUT INTELL-US, V39, P170, DOI 10.1111/coin.12278
   Drozdowski P, 2019, IET BIOMETRICS, V8, P351, DOI 10.1049/iet-bmt.2019.0076
   Dua M, 2022, J AMB INTEL HUM COMP, V13, P1985, DOI 10.1007/s12652-021-02960-0
   Tran DT, 2022, J SUPERCOMPUT, V78, P11051, DOI 10.1007/s11227-021-04275-5
   Fatima N., 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P1746, DOI 10.1109/ICSAI.2012.6223381
   Fei Zang, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P16, DOI 10.1109/MINES.2011.123
   Gelly G, 2016, INTERSPEECH, P3231, DOI 10.21437/Interspeech.2016-180
   Ghahabi Omid, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1700, DOI 10.1109/ICASSP.2014.6853888
   Ghosh Soumi, 2019, International Journal of Advanced Intelligence Paradigms, V12, P370
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Hajavi A, 2019, ARXIV
   Hatch AO, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1471
   Ho T, 2021, J INF PROCESS SYST, V17, P163, DOI 10.3745/JIPS.04.0206
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong QY, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1037
   Huh JH, 2019, IEEE ACCESS, V7, P164229, DOI 10.1109/ACCESS.2019.2945338
   Ing-Jr Ding, 2015, Applied Mechanics and Materials, V764-765, P891, DOI 10.4028/www.scientific.net/AMM.764-765.891
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jansen W., 2004, DATA SECURITY
   Jati A, 2018, INTERSPEECH, P1131
   Jayanna HS, 2009, IET SIGNAL PROCESS, V3, P189, DOI 10.1049/iet-spr.2008.0211
   Jia YJ, 2021, COMPLEX INTELL SYST, V7, P1749, DOI 10.1007/s40747-020-00172-1
   Kabir MM., 2021, IEEE ACCESS
   Kanagasundaram A, 2019, INTERSPEECH, P2943, DOI 10.21437/Interspeech.2019-1891
   Kanagasundaram Ahilan, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1665, DOI 10.1109/ICASSP.2014.6853881
   Kanagasundaram A, 2016, ARXIV
   Kanagasundaram A, 2014, INT CONF ACOUST SPEE
   Kanagasundaram A, 2017, INT J SPEECH TECHNOL, V20, P247, DOI 10.1007/s10772-017-9402-8
   Khosravani A, 2018, COMPUT SPEECH LANG, V52, P105, DOI 10.1016/j.csl.2017.12.009
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Krishnamoorthy P, 2011, EXPERT SYST APPL, V38, P13487, DOI 10.1016/j.eswa.2011.04.069
   Laskar MA, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115281
   Laskar MA, 2021, CIRC SYST SIGNAL PR, V40, P5127, DOI 10.1007/s00034-021-01713-w
   Li DD, 2022, CIRC SYST SIGNAL PR, V41, P3931, DOI 10.1007/s00034-022-01964-1
   Li KP., 1982, J ACOUST SOC AM, V72, pS29, DOI [10.1121/1.2019810, DOI 10.1121/1.2019810]
   Li LT, 2016, IEEE-ACM T AUDIO SPE, V24, P1129, DOI 10.1109/TASLP.2016.2544660
   Li ZY, 2015, MULTIMED TOOLS APPL, V74, P937, DOI 10.1007/s11042-013-1705-4
   Liu ZL, 2018, IEEE T IND INFORM, V14, P3244, DOI 10.1109/TII.2018.2799928
   Mak M-W., 2006, INT CONF ACOUST SPEE, pI
   MARR D, 1977, ARTIF INTELL, V9, P37, DOI 10.1016/0004-3702(77)90013-3
   Matsui T, 1994, IEEE T SPEECH AUDI P, V2, P456, DOI 10.1109/89.294363
   Meghanani A, 2021, IEEE W SP LANG TECH, P670, DOI 10.1109/SLT48900.2021.9383491
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   NAINAN S, 2020, INT J SPEECH, P1
   National Institute Of Standards and Technology NIST, 2010, SPEAK REC EV PLAN
   Novoselov S, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P214
   Pal M, 2015, APPL SOFT COMPUT, V30, P214, DOI 10.1016/j.asoc.2015.01.036
   Poddar A, 2018, IET BIOMETRICS, V7, P91, DOI 10.1049/iet-bmt.2017.0065
   Ranzato M, 2007, PROC CVPR IEEE, P1429
   Rao K, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P193, DOI 10.1109/ASRU.2017.8268935
   Reynolds D.A., 2008, HDB SPEECH PROCESSIN, P763, DOI DOI 10.1007/978-3-540-49127-9_38
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Rohdin J, 2020, COMPUT SPEECH LANG, V59, P22, DOI 10.1016/j.csl.2019.06.002
   Rohdin J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4874, DOI 10.1109/ICASSP.2018.8461958
   Sak H., 2014, ARXIV
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shaheed K, 2021, ARCH COMPUT METHOD E, V28, P4917, DOI 10.1007/s11831-021-09560-3
   Snyder D, 2016, IEEE W SP LANG TECH, P165, DOI 10.1109/SLT.2016.7846260
   Soldi G., 2014, SHORT DURATION SPEAK, DOI [10.21437/Odyssey.2014-32, DOI 10.21437/ODYSSEY.2014-32]
   Song ZJ, 2020, COMPUTING, V102, P663, DOI 10.1007/s00607-019-00753-0
   Suvarna Kumar G., 2010, International Journal of Engineering Science and Technology, V2, P2428
   Togneri R, 2011, IEEE CIRC SYST MAG, V11, P23, DOI 10.1109/MCAS.2011.941079
   Vogt R, 2010, IEEE T AUDIO SPEECH, V18, P1182, DOI 10.1109/TASL.2009.2031505
   Wang JX, 2019, INT CONF ACOUST SPEE, P3652, DOI 10.1109/ICASSP.2019.8683393
   Wen-kai Lu, 2009, IEEE Signal Processing Letters, V16, P576, DOI 10.1109/LSP.2009.2020887
   Xu CL, 2021, IEEE-ACM T AUDIO SPE, V29, P2696, DOI 10.1109/TASLP.2021.3100682
   Yadav S, 2020, INT CONF ACOUST SPEE, P6794, DOI [10.1109/ICASSP40776.2020.9054440, 10.1109/icassp40776.2020.9054440]
   Yamada T, 2013, INTERSPEECH, P3628
   Yun Lei, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1695, DOI 10.1109/ICASSP.2014.6853887
   Zhang XY, 2019, IEEE ACCESS, V7, P27874, DOI 10.1109/ACCESS.2019.2901812
NR 88
TC 2
Z9 2
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33111
EP 33133
DI 10.1007/s11042-023-14942-9
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200011
DA 2024-07-18
ER

PT J
AU Manishdavi, A
   Rafie, M
AF Manishdavi, Alireza
   Rafie, Mahnaz
TI Automatic diagnosis of ischemic heart disease using combined classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiovascular disease; Data mining; Combined learning; Decision tree;
   RIPPER algorithm; Bayesian learning
ID CLASSIFICATION; RISK
AB The cardiovascular disease risk in modern industrial societies and living with sedentary lifestyles, high-calorie meals, and mental stress is on the rise. Methods of diagnosing the disease, which is based on clinical examinations and tests, are time-consuming and costly, and can also involve human error. Therefore, data mining methods have been used in recent years, each of which has its advantages and disadvantages. Due to the variety of features related to patient data, the use of a classifier alone cannot cover all the hidden sides of the problem. Thus, in the proposed method, a combined cascading learning model is used, which consists of two levels. In the first level, the Bayesian classifier is used, which adds two characteristics of the possibility of being sick or not to the data. In the second level, the decision tree and RIPPER classifiers are used in parallel. The model is based on the heart data set. The evaluation results based on the accuracy, recall, and precision parameters show that the proposed method compared to Miao and Yakala methods based on the accuracy parameter has improved performance by 9% and 2%, respectively.
C1 [Manishdavi, Alireza] Univ Arvandan khoramshahr, Dept Comp Engn, Khoramshahr, Iran.
   [Rafie, Mahnaz] Islamic Azad Univ, Dept Comp Engn, Ramhormoz Branch, Ramhormoz, Iran.
C3 Islamic Azad University
RP Rafie, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Ramhormoz Branch, Ramhormoz, Iran.
EM m.rafie@srbiau.ac.ir
OI Rafie, Mahnaz/0000-0003-2546-826X
CR Alizadehsani R, 2012, INT CONF DAT MIN WOR, P9, DOI 10.1109/ICDMW.2012.29
   Cormack J, 2015, J BIOMED INFORM, V58, pS120, DOI 10.1016/j.jbi.2015.06.030
   Demuth HB, 2014, NEURAL NETWORK DESIG, P93
   Dolatabadi AD, 2017, COMPUT METH PROG BIO, V138, P117, DOI 10.1016/j.cmpb.2016.10.011
   Eggers KM, 2015, CLIN CHIM ACTA, V445, P19, DOI 10.1016/j.cca.2015.03.002
   Gilani M, 2016, IEEE ENG MED BIO, P3461, DOI 10.1109/EMBC.2016.7591473
   Giri D, 2013, KNOWL-BASED SYST, V37, P274, DOI 10.1016/j.knosys.2012.08.011
   Ilayaraja M, 2015, PROCEDIA COMPUT SCI, V70, P586, DOI 10.1016/j.procs.2015.10.040
   Kazemi M, 2017, Journal of Ilam University of Medical Sciences, V25, P20, DOI [10.29252/sjimu.25.1.20, DOI 10.29252/SJIMU.25.1.20]
   Khan SN., 2019, INT J INFORM VISUALI, V1, P227
   Kim JK, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/2780501
   Kurt I, 2008, EXPERT SYST APPL, V34, P366, DOI 10.1016/j.eswa.2006.09.004
   Li JP, 2020, IEEE ACCESS, V8, P107562, DOI 10.1109/ACCESS.2020.3001149
   Mastoi QU, 2018, CARDIOL RES PRACT, V2018, DOI 10.1155/2018/2016282
   Miao KH, 2016, INT J ADV COMPUT SC, V7, P30
   Miao KH, 2018, INT J ADV COMPUT SC, V9
   Mohammadpour RA., 2015, COMPUT MATH METHOD M, V45, P267
   Patidar S, 2015, KNOWL-BASED SYST, V82, P1, DOI 10.1016/j.knosys.2015.02.011
   Rajkumar M., 2010, Global Journal of Computer Science and Technology, V10, P38
   Rubini P.E., 2021, Int. J. Eng. Adv. Technol., V8, P904
   Shafique U., 2015, INT J INNOV APPL STU, V10, P2028
   Shah D., 2020, Heart Disease Prediction Using Machine Learning Techniques
   Singh Archana, 2020, 2020 International Conference on Electrical and Electronics Engineering (ICE3), P452, DOI 10.1109/ICE348803.2020.9122958
   Subhadra K., 2019, International Journal of Innovative Technology and Exploring Engineering (IJITEE), V8, P484
   Suchithra C., 2014, INT J COMPUT SCI MOB, V3, P21
   Tarawneh M, 2019, LECT NOTE DATA ENG, V29, P447, DOI 10.1007/978-3-030-12839-5_41
   Yekkala I, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON SMART TECHNOLOGIES FOR SMART NATION (SMARTTECHCON), P691, DOI 10.1109/SmartTechCon.2017.8358460
NR 27
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33135
EP 33159
DI 10.1007/s11042-023-14834-y
EA MAR 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943970200020
DA 2024-07-18
ER

PT J
AU Abdelaziz, M
   Zhang, ZP
AF Abdelaziz, Mounir
   Zhang, Zuping
TI Learn to aggregate global and local representations for few-shot
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Few-shot learning; Metric learning; Deep nearest neighbors; Class
   prototypes; Euclidean distance; Cosine similarity
AB Few-shot learning aims to train recognition models to learn new object categories from limited training examples. Recent metric-learning based methods have made significant progress. Most of these methods rely on a single similarity metric at a global or local level. However, classifying samples using multiple similarity metrics at different levels simultaneously can produce a better similarity measure and more discriminative feature maps. Therefore, in this paper, a novel method called Learn to Aggregate Global and Local Representations for Few-shot Learning is introduced. Our proposed method embeds the support images and the query images. Then, it calculates four distinct similarity metrics between representations at global and local levels. Finally, the calculated similarities are combined and fed to a fusion module to obtain a final similarity score. Extensive experiments demonstrate that our method achieves state-of-the-art results on popular benchmarks. Particularly, AGLRs outperforms DN4 with a margin of approximate to 3 - 4% on the miniImageNet dataset.
C1 [Abdelaziz, Mounir; Zhang, Zuping] Cent South Univ, Sch Comp Sci & Engn, 932 South Lushan Rd, Changsha 410083, Hunan, Peoples R China.
C3 Central South University
RP Zhang, ZP (corresponding author), Cent South Univ, Sch Comp Sci & Engn, 932 South Lushan Rd, Changsha 410083, Hunan, Peoples R China.
EM mouniraziz@csu.edu.cn; zpzhang@csu.edu.cn
CR Abdelaziz M, 2022, MULTIMED TOOLS APPL, P1
   Abdelaziz M, 2021, MULTIMED TOOLS APPL, V80, P10491, DOI 10.1007/s11042-020-09875-6
   Baik S, 2020, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR42600.2020.00245
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chen H, 2020, ARXIV
   Chen H., 2021, arXiv
   Chen ZT, 2019, PROC CVPR IEEE, P8672, DOI 10.1109/CVPR.2019.00888
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Chu WH, 2019, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR.2019.00641
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dong CAQ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P716
   Finn C, 2017, PR MACH LEARN RES, V70
   Flennerhag S., 2020, INT C LEARN REPR
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Hao FS, 2019, IEEE I CONF COMP VIS, P8459, DOI 10.1109/ICCV.2019.00855
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Kingma D. P., 2014, arXiv
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake B., 2011, P ANN M COGNITIVE SC, P1
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li W., 2020, ARXIV
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Mishra N., 2017, ICLR
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Oh J., 2021, ICLR
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Paszke A, 2019, ADV NEUR IN, V32
   Ravi S., 2016, INT C LEARNING REPRE
   Ren M, 2018, ARXIV
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santoro A., 2016, INT C MACH LEARN, P1842, DOI DOI 10.5555/3045390.3045585
   Satorras V.G., 2018, P INT C LEARN REPR V
   Schwartz E., 2019, ARXIV
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tao A., 2020, Arxiv
   Thrun S, 1998, LEARNING TO LEARN, P3
   Vilalta R, 2002, ARTIF INTELL REV, V18, P77, DOI 10.1023/A:1019956318069
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Xing C., 2019, P ADV NEUR INF PROC, V32, P4848
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
NR 54
TC 2
Z9 2
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32991
EP 33014
DI 10.1007/s11042-023-14413-1
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943638900017
DA 2024-07-18
ER

PT J
AU Bonny, T
   Al Nassan, W
   Vaidyanathan, S
   Sambas, A
AF Bonny, Talal
   Al Nassan, Wafaa
   Vaidyanathan, Sundarapandian
   Sambas, Aceng
TI Highly-secured chaos-based communication system using cascaded masking
   technique and adaptive synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cascaded chaotic system; Chaotic oscillators; Hyperchaotic oscillators;
   Adaptive control synchronization; Security analysis; Chaos-based
   communication system
ID PROJECTIVE SYNCHRONIZATION; HYPERCHAOTIC SYSTEMS; NEURAL-NETWORKS;
   TIME-DELAY; OBSERVER; IMAGE
AB Over the past years, many chaos-based secure communication system algorithms have been published for the encryption of different types of data. The problem with these algorithms is either the high complexity that makes them difficult to be implemented or the lack of the high security that prevents them from being applicable in real applications. In this paper, we propose a new highly-secured chaos-based communication system that is based on adaptive control synchronization. The implementation process of the proposed system is detailed including the oscillator dynamic equations, the control laws derivation, the numerical solutions, and the Matlab/Simulink representation. To show the efficiency of the proposed system, its security is analyzed using different security measures. This proofs that the carrier signal is unpredictable by the intruder in both time and frequency domains. The experimental results and the show that the proposed system outperforms the different related and recent work in addition to its stability and robustness to the variation of initial conditions. Finally, we introduce an application on voice encryption to demonstrate the effectiveness of our system. Then We compare the security results of our system with different implementations of recent and related work.
C1 [Bonny, Talal; Al Nassan, Wafaa] Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
   [Vaidyanathan, Sundarapandian] Vel Tech Univ, Sch Elect & Commun Engn, Avadi, Tamil Nadu, India.
   [Sambas, Aceng] Univ Muhammadiyah Tasikmalaya, Dept Mech Engn, Tasikmalaya, Indonesia.
C3 University of Sharjah; Vel Tech Rangarajan Dr Sagunthala R&D Institute
   of Science & Technology; Universitas Muhammadiyah Tasikmalaya
RP Bonny, T (corresponding author), Univ Sharjah, Dept Comp Engn, Sharjah, U Arab Emirates.
EM tbonny@sharjah.ac.ae; walnassan@sharjah.ac.ae; sundar@veltech.edu.in;
   acengs@umtas.ac.id
RI Vaidyanathan, Sundarapandian/A-4618-2013; Sambas, Aceng/AAF-3737-2019
OI Sambas, Aceng/0000-0002-1623-0770; Bonny, Talal/0000-0003-1111-0304
CR Abd MH, 2017, NONLINEAR DYNAM, V90, P2583, DOI 10.1007/s11071-017-3825-2
   Abdelfatah RI, 2020, IEEE ACCESS, V8, P69894, DOI 10.1109/ACCESS.2020.2987197
   Abid DB, 2019, INT J COMPUT APPL T, V59, P130, DOI 10.1504/IJCAT.2019.098033
   Ahmad I, 2018, IEEE ACCESS, V6, P35449, DOI 10.1109/ACCESS.2018.2850371
   AlMutairi F, 2019, 2019 INT C ELECT COM, ppp1
   [Anonymous], 2017, FRACTIONAL ORDER CON
   [Anonymous], 1979, ANN NY ACAD SCI
   Bao HM, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P1487, DOI 10.1109/ICCIAS.2006.295307
   Bonny T, 2021, CIRC SYST SIGNAL PR, V40, P1061, DOI 10.1007/s00034-020-01521-8
   Bonny T, 2019, NONLINEAR DYNAM, V96, P2087, DOI 10.1007/s11071-019-04907-9
   Bonny T, 2019, CIRC SYST SIGNAL PR, V38, P1342, DOI 10.1007/s00034-018-0905-6
   Bonny T, 2018, NONLINEAR DYNAM, V93, P819, DOI 10.1007/s11071-018-4229-7
   Cao JD, 2013, ABSTR APPL ANAL, DOI 10.1155/2013/940573
   Chang WD, 2009, CHAOS SOLITON FRACT, V39, P910, DOI 10.1016/j.chaos.2007.01.064
   Chen GR, 2004, INT J BIFURCAT CHAOS, V14, P2229, DOI 10.1142/S0218127404010655
   Çiçek S, 2016, OPTIK, V127, P4024, DOI 10.1016/j.ijleo.2016.01.069
   Feng GZ, 2013, ADV DIFFER EQU-NY, DOI 10.1186/1687-1847-2013-24
   Grassi G, 2007, INT J BIFURCAT CHAOS, V17, P1337, DOI 10.1142/S0218127407017835
   Jahanshahi H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21020156
   Jian H, 2008, PHYS LETT A, V372, P4799, DOI 10.1016/j.physleta.2008.05.025
   Jiang GP, 2006, IEEE T CIRCUITS-I, V53, P2739, DOI 10.1109/TCSI.2006.883876
   Kharel R, 2008, PROC 9 ANN POSTGRADU, P295
   Kharel Rupak., 2011, Design and Implementation of Secure Chaotic Communication Systems
   Khorashadizadeh S, 2018, FRONT INFORM TECH EL, V19, P1180, DOI 10.1631/FITEE.1601814
   Khorashadizadeh S, 2017, AEU-INT J ELECTRON C, V82, P37, DOI 10.1016/j.aeue.2017.07.032
   Kordov K, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8050530
   Kumar M., 2020, Multimedia Security Using Chaotic Maps: Principles and Methodologies, P1
   LAKSHMANAN M, 1994, CURR SCI INDIA, V67, P989
   Li CH, 2017, FRONT INFORM TECH EL, V18, P1305, DOI 10.1631/FITEE.1601253
   Li GH, 2006, CHAOS SOLITON FRACT, V29, P490, DOI 10.1016/j.chaos.2005.08.029
   Li SY, 2019, INFORM SCIENCES, V481, P604, DOI 10.1016/j.ins.2018.12.066
   Liu ZY, 2008, INT J BIFURCAT CHAOS, V18, P3731, DOI 10.1142/S0218127408022688
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Mani P, 2019, INFORM SCIENCES, V491, P74, DOI 10.1016/j.ins.2019.04.007
   Marwan M, 2020, SOFT COMPUT, V24, P4333, DOI 10.1007/s00500-019-04197-8
   Mobayen S, 2019, IJST-T ELECTR ENG, V43, P1, DOI 10.1007/s40998-018-0094-0
   Mobayen S, 2018, CHAOS SOLITON FRACT, V114, P46, DOI 10.1016/j.chaos.2018.06.020
   Mofid O, 2019, INT J ADAPT CONTROL, V33, P462, DOI 10.1002/acs.2965
   MURALI K, 1994, PHYS REV E, V49, P4882, DOI 10.1103/PhysRevE.49.4882
   Muthukumar P, 2017, MULTIMED TOOLS APPL, V76, P23517, DOI 10.1007/s11042-016-4052-4
   Muthuswamy B, 2010, INT J BIFURCAT CHAOS, V20, P1335, DOI 10.1142/S0218127410026514
   Nakamura Y, 2001, IEEE T ROBOTIC AUTOM, V17, P898, DOI 10.1109/70.976022
   Park JH, 2005, CHAOS SOLITON FRACT, V26, P959, DOI 10.1016/j.chaos.2005.02.002
   Parlitz U, 1992, INT J BIFURCAT CHAOS, V2, P973, DOI 10.1142/S0218127492000823
   PECORA LM, 1990, PHYS REV LETT, V64, P821, DOI 10.1103/PhysRevLett.64.821
   Plata C, 2020, MATH COMPUT APPL, V25, DOI 10.3390/mca25010016
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Quan L, 2020, HYPERCHAOTIC SYNCHRO, P660
   Rafikov M, 2008, COMMUN NONLINEAR SCI, V13, P1246, DOI 10.1016/j.cnsns.2006.12.011
   Rajagopal K, 2018, AEU-INT J ELECTRON C, V94, P55, DOI 10.1016/j.aeue.2018.06.043
   Rigatos G, 2019, PROC IEEE INT SYMP, P670, DOI 10.1109/ISIE.2019.8781178
   Sambas A., 2020, IAENG INT J APPL MAT, V50, P1
   Sambas A., 2019, INT J ELECT COMPUT E, V9, P2365
   Sambas A, 2019, IEEE ACCESS, V7, P115454, DOI 10.1109/ACCESS.2019.2933456
   Samimi M, 2020, AEU-INT J ELECTRON C, V127, DOI 10.1016/j.aeue.2020.153424
   Sathiyamurthi P, 2017, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-017-0118-0
   Sheela SJ, 2017, J COMPUT NETW COMMUN, V2017, DOI 10.1155/2017/2721910
   Singh PP, 2018, IEEE INT CONF INDUST, P322, DOI 10.1109/ICIT.2018.8352197
   Tian K, 2020, IEEE ACCESS, V8, P72570, DOI 10.1109/ACCESS.2020.2986786
   Vaidyanathan S., 2015, INT J PHARMTECH RES, V8, P156
   Vaidyanathan S., 2015, COORDINATES, V1, P3
   Vaidyanathan S, 2016, STUD FUZZ SOFT COMP, V337, P155, DOI 10.1007/978-3-319-30340-6_7
   Vaidyanathan S, 2012, INT J AUTOM COMPUT, V9, P274, DOI 10.1007/s11633-012-0644-2
   Vaidyanathan Sundarapandian., 2013, J. Cont. Eng. Tech, V3, P69
   Vaseghi B, 2018, T I MEAS CONTROL, V40, P3788, DOI 10.1177/0142331217731617
   Vaseghi B, 2017, NONLINEAR DYNAM, V89, P1689, DOI 10.1007/s11071-017-3543-9
   Wang SJ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030271
   Wu CW, 1996, INT J BIFURCAT CHAOS, V6, P455, DOI 10.1142/S0218127496000187
   Yau HT, 2008, MECH SYST SIGNAL PR, V22, P408, DOI 10.1016/j.ymssp.2007.08.007
NR 69
TC 4
Z9 4
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34229
EP 34258
DI 10.1007/s11042-023-14643-3
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000943009100005
DA 2024-07-18
ER

PT J
AU Suresh, M
   Sam, IS
AF Suresh, Meenu
   Sam, I. Shatheesh
TI Optimized interesting region identification for video steganography
   using multi-objective cost function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video steganography; Optimization; Fractional Calculus; Lifting wavelet
   transform; Optimal region selection
ID IMAGE STEGANOGRAPHY; TRANSFORM; ALGORITHM; SCHEME; SECURE; CODE
AB This paper presents an optimal data hiding in videos using optimization based on multi-objective constraints such as, the energy of wavelet, intensity, edge details, and energy of Local Binary Patterns (LBP). The Fractional-Cat swarm optimization (Fractional-CSO) is modelled with the inclusion of fractional calculus in Cat swarm optimization (CSO). Initially, an input video is selected from which frames are generated. The key frames are extracted from those frames using the Contourlet Transform (CT) and Structural Similarity Index (SSIM). Regions are formed on the selected key frames with the help of grid lines. Finally, the optimal region for embedding is interpreted using the proposed optimization algorithm along with multi-objective cost functions to embed the secret message. The secret data is hidden in the optimal region using the Lifting Wavelet Transform (LWT). Then the embedded video is subsequently sent across the network to its intended recipient. The experimental analysis is done using two videos which reveal the effectiveness of the proposed video steganography. The comparative analysis based on the MSE (Mean-Square Error), Peak Signal to Noise Ratio (PSNR) and correlation measure reveals the effectiveness of the method. With MSE of 0.0001, maximal PSNR of 82.273 dB and correlation of 0.9529 respectively shows increase in security of the data with a better quality embedded image. For noise free image, the correlation acquired using the proposed video steganography is 0.9934.
C1 [Suresh, Meenu] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
   [Sam, I. Shatheesh] Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept PG Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Suresh, M (corresponding author), Manonmaniam Sundaranar Univ, Nesamony Mem Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
EM meenupillai1988@gmail.com; shatheeshsam@yahoo.com
CR Abdulla AA., 2014, LECT NOTES COMPUTER, DOI [10.1007/978-3-319-14054-4_10, DOI 10.1007/978-3-319-14054-4_10]
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   AlZain MA., 2018, INT J APPL ENG RES, V13, P6380
   [Anonymous], VID WAT US DWT FIL E
   Balu S, 2019, CLUSTER COMPUT, V22, pS4057, DOI 10.1007/s10586-018-2639-4
   Bhaladhare PR, 2018, INT J INF SECUR PRIV, V2, P587, DOI [10.4018/978-1-5225-7113-1.ch031, DOI 10.4018/978-1-5225-7113-1.CH031]
   Dalal M, 2020, INF SECUR J, V29, P40, DOI 10.1080/19393555.2020.1714822
   Nguyen DC, 2019, MULTIMED TOOLS APPL, V78, P16033, DOI 10.1007/s11042-018-6976-3
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Ghamsarian N, 2020, MULTIMED TOOLS APPL, V79, P18909, DOI 10.1007/s11042-020-08617-y
   Gurunathan K, 2020, MULTIMED TOOLS APPL, V79, P3893, DOI 10.1007/s11042-019-7471-1
   Hashemzadeh M, 2018, COMPUT ELECTR ENG, V68, P14, DOI 10.1016/j.compeleceng.2018.03.046
   Jackson ES, 2006, 2006 ASAE ANN M
   Jain M, 2017, INT J MACH LEARN CYB, V8, P1695, DOI 10.1007/s13042-016-0542-y
   Jain Mamta, 2017, Brain Inform, V4, P95, DOI 10.1007/s40708-016-0057-z
   Kakde Y, 2015, 2015 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Kaur R, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P867, DOI 10.1109/WiSPNET.2016.7566255
   Khare R, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P898, DOI 10.1109/CICN.2014.189
   Khupse S, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON ISSUES AND CHALLENGES IN INTELLIGENT COMPUTING TECHNIQUES (ICICT), P811, DOI 10.1109/ICICICT.2014.6781384
   Lima R., 2017, INT J COMPUT APPL, V164, P1, DOI 10.5120/ijca2017913686
   Mahdi Bahrami OB-H., 2018, STUD COMPUT INTELL, V720, P143, DOI [10.1007/978-981-10-5221-7, DOI 10.1007/978-981-10-5221-7]
   Mallick P., 2017, 2017 INT C INTELLIGE, DOI [10.1109/intelcct.2017.8324020, DOI 10.1109/INTELCCT.2017.8324020]
   Miri A, 2017, OPTIK, V145, P158, DOI 10.1016/j.ijleo.2017.07.043
   Montes de Oca MA, 2009, IEEE T EVOLUT COMPUT, V13, P1120, DOI 10.1109/TEVC.2009.2021465
   Mstafa RJ, 2020, IEEE ACCESS, V8, P161825, DOI 10.1109/ACCESS.2020.3021356
   Mstafa RJ, 2017, 2017 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Mstafa RJ, 2017, IEEE ACCESS, V5, P5354, DOI 10.1109/ACCESS.2017.2691581
   Nyo HL., 2019, INT J COMPUTER NETWO, V9, P45, DOI DOI 10.5815/IJCNIS.2019.06.06
   Pezzella F, 2008, COMPUT OPER RES, V35, P3202, DOI 10.1016/j.cor.2007.02.014
   Pradhan PM, 2012, EXPERT SYST APPL, V39, P2956, DOI 10.1016/j.eswa.2011.08.157
   Rajalakshmi K, 2018, MULTIMED TOOLS APPL, V77, P27427, DOI 10.1007/s11042-018-5930-8
   Rajpreetha C, 2015, REGISTER METHOD, V1, P56
   Raju R, 2018, INT J ENVIRON HEAL R, V5
   Ramalingam Mritha, 2020, Procedia Computer Science, V171, P1147, DOI 10.1016/j.procs.2020.04.123
   Rana S, 2020, MULTIMED TOOLS APPL, V79, P5881, DOI 10.1007/s11042-019-08525-w
   Kiruba RR, 2021, MULTIDIM SYST SIGN P, V32, P405, DOI 10.1007/s11045-019-00697-w
   Sadek MM, 2017, MULTIMED TOOLS APPL, V76, P3065, DOI 10.1007/s11042-015-3170-8
   Sethy PK, 2016, 2016 INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND DYNAMIC OPTIMIZATION TECHNIQUES (ICACDOT), P618, DOI 10.1109/ICACDOT.2016.7877660
   Shanableh T, 2012, IEEE T INF FOREN SEC, V7, P455, DOI 10.1109/TIFS.2011.2177087
   Sushmitha MC, 2017, IEEE ICCE, P72, DOI 10.1109/ICCE-ASIA.2017.8307831
   Thakur V, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P150, DOI 10.1109/ISSP.2013.6526892
   Wagdarikar AMU, 2019, J INTELL SYST, V28, P873, DOI 10.1515/jisys-2017-0264
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang WH, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P39
   Xiph.org, DERFS TEST MED COLL
   Yao YZ, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102986
   Zhang YN, 2017, TSINGHUA SCI TECHNOL, V22, P198
NR 48
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 31373
EP 31396
DI 10.1007/s11042-023-14821-3
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000941913300004
DA 2024-07-18
ER

PT J
AU Zhang, WJ
   Hu, MN
   Tan, QE
   Zhou, QL
   Wang, R
AF Zhang, Wenjing
   Hu, Mengnan
   Tan, Quange
   Zhou, Qianli
   Wang, Rong
TI Cross-modal attention guided visual reasoning for referring image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Referring image segmentation; Multi-scales features; Cross-modal
   attention mechanism; Graph convolution
AB The goal of referring image segmentation (RIS) is to generate the foreground mask of the object described by a natural language expression. The key of RIS is to learn the valid multimodal features between visual and linguistic modalities to identify the referred object accurately. In this paper, a cross-modal attention-guided visual reasoning model for referring segmentation is proposed. First, the multi-scale detailed information is captured by a pyramidal convolution module to enhance visual representation. Then, the entity words of the referring expression and relevant image regions are aligned by a cross-modal attention mechanism. Based on this, all the entities described by the expression can be identified. Finally, a fully connected multimodal graph is constructed with multimodal features and relationship cues of expressions. Visual reasoning is performed stepwisely on the graph to highlight the correct entity whiling suppressing other irrelevant ones. The experiment results on four benchmark datasets show that the proposed method achieves performance improvement (e.g., +1.13% on UNC, +3.06% on UNC+, +2.1% on G-Ref, and 1.11% on ReferIt). Also, the effectiveness and feasibility of each component of our method are verified by extensive ablation studies.
C1 [Zhang, Wenjing; Hu, Mengnan; Tan, Quange; Zhou, Qianli; Wang, Rong] Peoples Publ Secur Univ China, Sch Informat & Cyber Secur, Beijing 434020, Peoples R China.
   [Hu, Mengnan] Shandong Police Coll, Police Technol & Equipment Innovat Res Ctr, Jinan 250200, Peoples R China.
   [Wang, Rong] Minist Publ Secur, Key Lab Secur Prevent Technol & Risk Assessment, Beijing 434020, Peoples R China.
C3 People's Public Security University of China; Shandong Police College;
   Ministry of Public Security (China)
RP Wang, R (corresponding author), Peoples Publ Secur Univ China, Sch Informat & Cyber Secur, Beijing 434020, Peoples R China.; Wang, R (corresponding author), Minist Publ Secur, Key Lab Secur Prevent Technol & Risk Assessment, Beijing 434020, Peoples R China.
EM 2248853762@qq.com; 361868422@qq.com; tanquange@126.com;
   13331112522@189.cn; dbdxwangrong@163.com
RI zhang, wenjing/AAE-7146-2019
FU National Natural Science Foundation of China [62076246]; Fundamental
   Research Funds for the Central Universities [2019JKF426]
FX AcknowledgementsThis work was supported by the National Natural Science
   Foundation of China (Grant 62076246), Fundamental Research Funds for the
   Central Universities (No. 2019JKF426).
CR Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Burks Arthur W, 1954, Math Comput, V8, P53
   Chandra S, 2017, IEEE I CONF COMP VIS, P5113, DOI 10.1109/ICCV.2017.546
   Chen DJ, 2019, IEEE I CONF COMP VIS, P7453, DOI 10.1109/ICCV.2019.00755
   Chen L-C., 2015, ARXIV
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Yi-Wen, 2019, ARXIV191004748
   Chen YP, 2019, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2019.00052
   Deng CR, 2018, PROC CVPR IEEE, P7746, DOI 10.1109/CVPR.2018.00808
   Duta I. C., 2020, ARXIV
   Feng G, 2021, PROC CVPR IEEE, P15501, DOI 10.1109/CVPR46437.2021.01525
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu RH, 2017, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2017.470
   Hu RH, 2016, PROC CVPR IEEE, P4555, DOI 10.1109/CVPR.2016.493
   Hu RH, 2016, LECT NOTES COMPUT SC, V9905, P108, DOI 10.1007/978-3-319-46448-0_7
   Hu ZW, 2020, PROC CVPR IEEE, P4423, DOI 10.1109/CVPR42600.2020.00448
   Huang S., 2020, 2020 IEEE CVF C COMP, P10485, DOI [DOI 10.1109/CVPR42600.2020.01050, 10.1109/CVPR42600.2020.01050]
   Hui T, 2020, ARXIV
   Escalante HJ, 2010, COMPUT VIS IMAGE UND, V114, P419, DOI 10.1016/j.cviu.2009.03.008
   Jing Y, 2021, PROC CVPR IEEE, P9853, DOI 10.1109/CVPR46437.2021.00973
   Kazemzadeh S., 2014, EMNLP, P787, DOI DOI 10.3115/V1/D14-1086
   Kingma D. P., 2014, arXiv
   Li RY, 2018, PROC CVPR IEEE, P5745, DOI 10.1109/CVPR.2018.00602
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu CX, 2017, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2017.143
   Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730
   Mao JH, 2016, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2016.9
   Margffoy-Tuay E, 2018, ARXIV
   Peng B, 2020, MULTIMED TOOLS APPL, V79, P32833, DOI 10.1007/s11042-020-09346-y
   Qiu S, 2020, IEEE T MULTIMEDIA, V22, P1333, DOI 10.1109/TMM.2019.2942480
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezaei M, 2020, MULTIMED TOOLS APPL, V79, P15329, DOI 10.1007/s11042-019-7305-1
   Rohrbach A, 2016, ARXIV
   Sadhu A, 2019, IEEE I CONF COMP VIS, P4693, DOI 10.1109/ICCV.2019.00479
   Shi HC, 2018, LECT NOTES COMPUT SC, V11210, P38, DOI 10.1007/978-3-030-01231-1_3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao A., 2020, Arxiv
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Yang SB, 2019, IEEE I CONF COMP VIS, P4643, DOI 10.1109/ICCV.2019.00474
   Yang SB, 2019, PROC CVPR IEEE, P4140, DOI 10.1109/CVPR.2019.00427
   Yang ZY, 2019, IEEE I CONF COMP VIS, P4682, DOI 10.1109/ICCV.2019.00478
   Ye LW, 2019, PROC CVPR IEEE, P10494, DOI 10.1109/CVPR.2019.01075
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zhang H, 2022, IEEE COMPUT SOC CONF, P2735, DOI 10.1109/CVPRW56347.2022.00309
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang HW, 2018, PROC CVPR IEEE, P4158, DOI 10.1109/CVPR.2018.00437
   Zhuang BH, 2018, PROC CVPR IEEE, P4252, DOI 10.1109/CVPR.2018.00447
NR 50
TC 0
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28853
EP 28872
DI 10.1007/s11042-023-14586-9
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941926100008
DA 2024-07-18
ER

PT J
AU Tan, Z
   Teng, ZF
AF Tan, Zhi
   Teng, Zhaofei
TI Improving generalization of image recognition with multi-branch
   generation network and contrastive learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image recognition; Domain generalization; Image generation; Contrastive
   learning; Adversarial training
AB Aiming at the phenomenon that the recognition performance of the Image Recognition model trained by the source domain dataset decreases significantly after it is transplanted to the target domain dataset with different distribution, a domain generalization model based on multi-branch generation network and contrastive learning (MGNDG) is proposed, by generating data different from the source domain to simulate the target domain. Firstly, a multi-branch generation network is constructed, and the multi-scale feature maps of different fields of view are obtained by convolution encoder; Secondly, the feature diversification is realized through the self attention regularization layer, and then the images with different distributions are synthesized by the decoder, so that the effect of simulating the data distribution in the target domain can be achieved. Then contrastive learning and two-way content consistency strategies are introduced to ensure the effectiveness of the generated image. At the same time, the strategies strengthen information interaction and learn the invariant representation between samples and improve the ability of model identification. Finally, the adversarial training multi-branch generation network and backbone network continuously improve the generalization performance of the image recognition domain of the model. Compared with traditional methods, the average recognition accuracy of the proposed model in five classical digital recognition datasets is improved by nearly 3%. The accuracy of classification on CIFAR 10-C dataset is improved by at least 2.2% The experimental results show the feasibility of this model and significantly improve the performance of the domain generalization model of image recognition affected by domain shift.
C1 [Tan, Zhi; Teng, Zhaofei] Beijing Univ Civil Engn & Architecture, Sch Elect & Informat Engn, Beijing, Peoples R China.
C3 Beijing University of Civil Engineering & Architecture
RP Teng, ZF (corresponding author), Beijing Univ Civil Engn & Architecture, Sch Elect & Informat Engn, Beijing, Peoples R China.
EM tanzhi@bucea.edu.cn; tengzf20162020@163.com
CR Aman S, 2018, INT C LEARNING REPRE
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Cha J., 2021, IEEE ELECTR DEVICE L, V27, p22,405
   Chen GY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P448, DOI 10.1109/ICCV48922.2021.00051
   Csurka G., 2017, ARXIV
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Fengchun Qiao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12553, DOI 10.1109/CVPR42600.2020.01257
   Galstyan T, 2022, P IEEE C COMPUTER VI
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2017, IEEE T PATTERN ANAL, V39, P1414, DOI 10.1109/TPAMI.2016.2599532
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Hendrycks Dan, 2019, ARXIV190312261
   Hou Z, 2022, PROC CVPR IEEE, P7246, DOI 10.1109/CVPR52688.2022.00711
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jia Y., 2020, P IEEECVF C COMPUTER, P8484, DOI DOI 10.1109/CVPR42600.2020.00851
   Kaiyang Zhou, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P561, DOI 10.1007/978-3-030-58517-4_33
   Koltchinskii V, 2011, LECT NOTES MATH, V2033, P1, DOI 10.1007/978-3-642-22147-7_1
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BY, 2021, PROC CVPR IEEE, P12378, DOI 10.1109/CVPR46437.2021.01220
   Li JC, 2021, PROC CVPR IEEE, P2505, DOI 10.1109/CVPR46437.2021.00253
   Li L, 2021, PROC CVPR IEEE, P224, DOI [10.1109/CVPR46437.2021.00029, 10.1109/ICPECA51329.2021.9362616]
   Motiian S, 2017, IEEE I CONF COMP VIS, P5716, DOI 10.1109/ICCV.2017.609
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Prabhu V, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8485, DOI 10.1109/ICCV48922.2021.00839
   Saito K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8980, DOI 10.1109/ICCV48922.2021.00887
   Van A., 2018, ARXIV
   Volpi R, 2018, GEN UNSEEN DOMAINS V, P5334
   Wang Q, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8495, DOI 10.1109/ICCV48922.2021.00840
   Wang ZJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P814, DOI 10.1109/ICCV48922.2021.00087
   Xu QW, 2021, PROC CVPR IEEE, P14378, DOI 10.1109/CVPR46437.2021.01415
   Xu X, 2019, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2019.00260
   Xu Zhenlin, 2020, INT C LEARNING REPRE
   Yingjun Du, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P200, DOI 10.1007/978-3-030-58607-2_12
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang CY, 2021, COMMUN ACM, V64, P107, DOI 10.1145/3446776
   Zhang YB, 2022, PROC CVPR IEEE, P8025, DOI 10.1109/CVPR52688.2022.00787
   Zhou K, 2015, P AAAI C ARTIFICIAL
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 41
TC 0
Z9 0
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 28367
EP 28387
DI 10.1007/s11042-023-14397-y
EA FEB 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000940065100001
DA 2024-07-18
ER

PT J
AU Moutakki, Z
   Ouloul, IM
   Amghar, A
   Motahhir, S
   Afdel, K
AF Moutakki, Zakaria
   Ouloul, Imad Mohamed
   Amghar, Abdellah
   Motahhir, Saad
   Afdel, Karim
TI Embedded and real time vehicle classification system with occlusion
   handling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle classification; Traffic congestion; Embedded AI; Real-time
   requirement; Occlusion handling; Raspberry PI
AB The idea of applying AI in embedded systems is growing in all sectors, from airplanes to drones, cars, cell phones and robots. The challenge for this type of embedded systems is to ensure real-time functioning, with accurate results under a robust system. In this paper, we propose an embedded and real-time road traffic classification system based on AI techniques. The software part includes the different blocks dedicated to vehicle counting and classification, which is performed by using background subtraction, Histograms of Oriented Gradients and Support Vector Machine. The proposed method also includes a set of linear and non-linear filtering techniques for noise removal. The occlusion handling is applied during classification process by training the model on classes containing occlusion images. The hardware part of the system consists of Raspberry Pi board with an operating system installed for flexibility purposes. The implemented algorithm has been improved to guarantee a real time operation and a minimal storage in the memory. The proposed system achieved a counting accuracy of 96.34%, and a processing speed around 4.55 FPS, which is adequate with all the performance and real time criteria.
C1 [Moutakki, Zakaria] Sidi Mohamed Ben Abdellah Univ, Higher Sch Technol, Ind Technol & Serv Lab, Fes 30000, Morocco.
   [Ouloul, Imad Mohamed; Amghar, Abdellah] Ibnou Zohr Univ, Metrol & Informat Proc Lab, Agadir 80000, Morocco.
   [Motahhir, Saad] Sidi Mohamed Ben Abdellah Univ, ENSA, Fes 30000, Morocco.
   [Afdel, Karim] Ibnou Zohr Univ, Comp Syst & Vis Lab, Agadir 80000, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Ibn Zohr University of
   Agadir; Sidi Mohamed Ben Abdellah University of Fez; Ibn Zohr University
   of Agadir
RP Motahhir, S (corresponding author), Sidi Mohamed Ben Abdellah Univ, ENSA, Fes 30000, Morocco.
EM zakaria.moutakki@usmba.ac.ma; md1.ouloul@gmail.com;
   amghar_abdellah@hotmail.com; saad.motahhir@usmba.ac.ma;
   k.afdel@uiz.ac.ma
RI Motahhir, Saad/J-3585-2016; Karim, AFDEL/AAC-7992-2019
OI Motahhir, Saad/0000-0002-6846-8908; Karim, AFDEL/0000-0002-0828-2116;
   Ouloul, Imad M./0000-0002-9865-1308
CR Aggarwal S., 2014, Flask Framework Cookbook
   Alphonse AS, 2019, MULTIMED TOOLS APPL, V78, P23369, DOI 10.1007/s11042-019-7646-9
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang JL, 2018, IEEE INTEL TRANSP SY, V10, P80, DOI 10.1109/MITS.2018.2806619
   Comer ML, 1999, J ELECTRON IMAGING, V8, P279, DOI 10.1117/1.482677
   Dai Z, 2019, IEEE ACCESS, V7, P64460, DOI 10.1109/ACCESS.2019.2914254
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Derrouz H, 2019, IEEE ACCESS, V7, P72528, DOI 10.1109/ACCESS.2019.2920740
   Ding LJ, 2001, PATTERN RECOGN, V34, P721, DOI 10.1016/S0031-3203(00)00023-6
   Dziri A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.041005
   Espejel-García D, 2017, CIV ENG J-TEHRAN, V3, P1029, DOI 10.28991/cej-030935
   Garcia-Garcia B, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100204
   Ghosh A, 2019, IEEE REGION 10 SYMP, P541, DOI [10.1109/TENSYMP46218.2019.8971196, 10.1109/tensymp46218.2019.8971196]
   Greenhalgh P., 2011, white paper
   Guerrero-Gomez-Olmedo Ricardo, 2013, Natural and Artificial Computation in Engineering and Medical Applications. 5th International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2013. Proceedings: LNCS 7931, P306, DOI 10.1007/978-3-642-38622-0_32
   Huang D-Y, 2016, J INFORM HIDING MULT, V7, P101
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Kim K, 2005, LECT NOTES COMPUT SC, V3804, P337
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Maddalena L, 2018, J IMAGING, V4, DOI 10.3390/jimaging4050071
   Moutakki Z, 2018, TRANSP TELECOMMUN J, V19, P93, DOI 10.2478/ttj-2018-0008
   Moutakki Z, 2017, TRANSP TELECOMMUN J, V18, P297, DOI 10.1515/ttj-2017-0027
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Raspberry Pi Ltd, BCM2711 ARM PER
   Raspberry Pi Ltd, 2019, RASP PI 4 MOD B
   Shanableh T, 2021, MULTIMED TOOLS APPL, V80, P27047, DOI 10.1007/s11042-020-09826-1
   Soleh Muhamad., 2018, Jurnal Ilmu Komputer dan Informasi, V11, P17
   Srijongkon K, 2017, PROCEEDINGS OF THE 2017 IEEE REGIONAL SYMPOSIUM ON MICRO AND NANOELECTRONICS (RSM), P235, DOI 10.1109/RSM.2017.8069172
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun W, 2021, MULTIMED TOOLS APPL, V80, P30803, DOI 10.1007/s11042-020-09171-3
   Tapp C, 2009, SAE INT J PASSENG CA, V1, P265, DOI 10.4271/2008-01-0664
   Velazquez-Pupo R, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020374
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xu Y, 2021, MEASUREMENT, V169, DOI 10.1016/j.measurement.2020.108502
   Yang B, 2017, IET INTELL TRANSP SY, V11, P76, DOI [10.1049/iet-its.2017.0047, 10.1049/iet-its.2016.0084]
   Zhao N, 2016, J VIS COMMUN IMAGE R, V37, P25, DOI 10.1016/j.jvcir.2015.04.011
NR 36
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24407
EP 24423
DI 10.1007/s11042-023-14852-w
EA FEB 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000939106800005
DA 2024-07-18
ER

PT J
AU Priyamvada, B
   Singhal, S
   Nayyar, A
   Jain, R
   Goel, P
   Rani, M
   Srivastava, M
AF Priyamvada, Bhavini
   Singhal, Shruti
   Nayyar, Anand
   Jain, Rachna
   Goel, Priya
   Rani, Mehar
   Srivastava, Muskan
TI Stacked CNN-LSTM approach for prediction of suicidal ideation on social
   media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Early suicide detection; Suicide ideation; Word embeddings; Machine
   learning; Deep learning; Twitter
ID RECTIFIED LINEAR UNITS; CLASSIFICATION
AB The growing use of social media forums to express suicidal ideation creates an immense requirement for automatic recognition of suicidal posts. Individuals use social forums to discuss their problems or access information on similar topics. This study aims to work on the automatic recognition and flagging of suicidal posts. It presents an approach that analyses social media platform Twitter to identify suicide warning signs for individuals. The primary purpose of the mentioned approach is the automatic identification of abnormal changes in online behaviour of the user. The challenges faced in suicide prevention is the understanding and detection of complex risk factors or warning signs that may lead to the event. To achieve this task, numerous natural language processing (NLP) techniques are employed to quantify linguistic and textual changes and pass through a novel framework which can be applied at large. The preliminary detection of suicidal ideation is achieved through deep learning and machine learning-based classification models applied to tweets on Twitter social media. For both classifiers initially we executed data pre-processing, feature extraction subsequently machine learning and deep learning classifiers respectively. For this purpose, we employ a Stacked CNN - 2 Layer LSTM model to evaluate and compare with other classification models. The study shows that the Stacked CNN - 2 Layer LSTM architecture with word embedding techniques achieves 93.92% classification accuracy as compared to previous previous CNN - LSTM approaches.
C1 [Priyamvada, Bhavini; Singhal, Shruti; Goel, Priya; Rani, Mehar; Srivastava, Muskan] Bharati Vidyapeeths Coll Engn, Comp Sci Dept, New Delhi, India.
   [Nayyar, Anand] Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
   [Jain, Rachna] Bhagwan Parshuram Inst Technol, Informat Technol Dept, New Delhi, India.
C3 Duy Tan University; Duy Tan University; Bhagwan Parshuram Institute of
   Technology
RP Nayyar, A (corresponding author), Duy Tan Univ, Grad Sch, Da Nang 550000, Vietnam.; Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Da Nang 550000, Vietnam.
EM bhavinipriyamvada8@gmail.com; shruti.singhal.2608@gmail.com;
   anandnayyar@duytan.edu.vn; rachnajain@bpitindia.com;
   priyagoel99@gmail.com; mehar212228@gmail.com;
   muskan.srivastava1904@gmail.com
RI Nayyar, Anand/F-3732-2015
OI Nayyar, Anand/0000-0002-9821-6146
CR Ahmad S, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0185-6
   Basu T., 2012, Proceedings of the International Conference on Advanced Data Mining and Applications, ADMA'12, V7713, P296, DOI DOI 10.1007/978-3-642-35527-1_25
   BECK AT, 1975, JAMA-J AM MED ASSOC, V234, P1146, DOI 10.1001/jama.234.11.1146
   Bhat H. S., 2017, ARXIV
   Bird S., 2009, NATURAL LANGUAGE PRO
   Chadha A, 2019, COMPUT J
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Choi SB, 2018, J AFFECT DISORDERS, V231, P8, DOI 10.1016/j.jad.2018.01.019
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   De Choudhury M, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P2098, DOI 10.1145/2858036.2858207
   Du JC, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0632-8
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Gehrmann S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0192360
   github, about us
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gupta SF, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ADVANCED NETWORKS AND TELECOMMUNICATIONS SYSTEMS (ANTS)
   He H., 2016, P 2016 C N AM CHAPT, P937, DOI [10.18653/v1/N16-1108, DOI 10.18653/V1/N16-1108]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ji SX, 2019, LECT NOTES COMPUT SC, V11448, P225, DOI 10.1007/978-3-030-18590-9_17
   Ji SX, 2018, COMPLEXITY, DOI 10.1155/2018/6157249
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Klonsky ED, 2014, SUICIDE LIFE-THREAT, V44, P1, DOI 10.1111/sltb.12068
   Kumar ER, 2020, J INTERDISCIP MATH, V23, P117, DOI 10.1080/09720502.2020.1721674
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li JC, 2021, JMIR MED INF, V9, DOI 10.2196/28227
   Lin GM, 2020, IEEE J BIOMED HEALTH, V24, P1907, DOI 10.1109/JBHI.2020.2988393
   Marks M., 2019, ARTIF INTELL
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Morales Michelle., 2019, Proceedings of the Sixth Workshop on Computational Linguistics and Clinical Psychology, P177, DOI DOI 10.18653/V1/W19-3023
   Munikar Manish, 2019, 2019 ARTIFICIAL INTE, V1, P1, DOI DOI 10.1109/AITB48515.2019.8947435
   Nordin N, 2021, HEALTH INFORM J, V27, DOI 10.1177/1460458221989395
   Onan A, 2019, ADV INTELL SYST COMP, V984, P293, DOI 10.1007/978-3-030-19807-7_29
   Pestian J, 2008, P WORKSH CURR TRENDS, P96
   Pompili M, 2014, SUICIDE LIFE-THREAT, V44, P34, DOI 10.1111/sltb.12051
   Sawhney Ramit., 2018, P ACL 2018 STUDENT R, P91, DOI [DOI 10.18653/V1/P18-3013, 10.18653/v1/p18-3013]
   Sawhney Ramit., 2018, P 9 WORKSHOP COMPUTA, P167, DOI [DOI 10.18653/V1/W18-6223, 10.18653/v1/w18-6223]
   Schapire R. E., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P215, DOI 10.1145/290941.290996
   SILVER MA, 1971, ARCH GEN PSYCHIAT, V25, P573
   Sinha PP, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P941, DOI 10.1145/3357384.3358060
   Sosa P. M., 2017, TWITTER SENTIMENT AN, P1
   Sun C, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P380
   Tadesse MM, 2020, ALGORITHMS, V13, DOI 10.3390/a13010007
   Weng JC, 2020, J CLIN MED, V9, DOI 10.3390/jcm9030658
   World Health Organization, 2018, NAT SUIC PREV STRAT
   Xu B., 2015, ARXIV
   Yang YF, 2018, REPRESENTATION LEARNING FOR NLP, P164
   Yin W., 2016, ARXIV
   Zeiler MD, 2013, INT CONF ACOUST SPEE, P3517, DOI 10.1109/ICASSP.2013.6638312
   Zhang JR, 2018, PROCEEDINGS OF 2018 IEEE 3RD ADVANCED INFORMATION TECHNOLOGY, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (IAEAC 2018), P1675, DOI 10.1109/IAEAC.2018.8577620
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang Y., 2015, arXiv
   Zhu H, 2020, J PSYCHIATR RES, V124, P123, DOI 10.1016/j.jpsychires.2020.02.019
   Ziqiang Wang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P674, DOI 10.1109/CSSE.2008.571
NR 55
TC 2
Z9 2
U1 7
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27883
EP 27904
DI 10.1007/s11042-023-14431-z
EA FEB 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000939106800006
DA 2024-07-18
ER

PT J
AU Naseri, H
   Mehrdad, V
AF Naseri, HamidReza
   Mehrdad, Vahid
TI Novel CNN with investigation on accuracy by modifying stride, padding,
   kernel size and filter numbers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Convolutional neural network; Deep learning; Variable
   kernel size; Variable numbers filter
ID FACE-RECOGNITION; CLASSIFIER; SVM
AB Face recognition is most important knowledge whom many researchers are working on. The challenges with the existing approaches can allude to upscale input data from 48 x 48 to 64 x 64 which can increase load of processor. Another challenges could be using PCA and LDA to find most important data. It can be elapsed more time. Therefore, we proposed a network to solve this challenges. Proposed network constitutes 4 convolutional Layers with 1 and 3 Max-pooling and Average-pooling respectively. Second, we apply ADAM optimizer to enhance network accuracy. After designing our network, we investigate impact of the dimension of kernel size and number of filters with different padding and stride on accuracy which was led to find optimal kernel size and number of filter. Eventually we discuss about convergences of each kernel size and number of filter. Dataset used for training and testing is going to be Faces96 with 150 classes.
C1 [Naseri, HamidReza; Mehrdad, Vahid] Lorestan Univ, Fac Engn, Dept Elect Engn, Khorramabad, Iran.
C3 Lorestan University
RP Mehrdad, V (corresponding author), Lorestan Univ, Fac Engn, Dept Elect Engn, Khorramabad, Iran.
EM HamidRezaNaseri76@gmail.com; mehrdad.v@lu.ac.ir
CR Abebe HB, 2019, IET CYBER PHYS SYST, V4, P189, DOI 10.1049/iet-cps.2018.5045
   Aghazadeh A, 2020, ARXIV
   Agrawal A, 2020, VISUAL COMPUT, V36, P405, DOI 10.1007/s00371-019-01630-9
   Agrawal AK, 2017, MULTIMED TOOLS APPL, V76, P3751, DOI 10.1007/s11042-016-3976-z
   Aiquan Yuan, 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P125, DOI 10.1109/DAS.2012.61
   Albdairi A., 2020, SCI PROGRAMMING-NETH, V2020, P1
   Bharadwaj Rahul R., 2019, Procedia Computer Science, V152, P74, DOI 10.1016/j.procs.2019.05.029
   Boughrara H, 2012, INT CONF MULTIMED, P233, DOI 10.1109/ICMCS.2012.6320263
   Chater A., 2020, TELKOMNIKA, V18, P695, DOI [10.12928/TELKOMNIKA.v18i2.13726, DOI 10.12928/TELKOMNIKA.V18I2.13726, 10.12928/telkomnika.v18i2.13726]
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Elleuch M, 2016, PROCEDIA COMPUT SCI, V80, P1712, DOI 10.1016/j.procs.2016.05.512
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Keerthi SS, 2002, MACH LEARN, V46, P351, DOI 10.1023/A:1012431217818
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar R, 2015, IEEE T IND APPL, V51, P1249, DOI 10.1109/TIA.2014.2356639
   Li S., 2020, IEEE T AFFECT COMPUT
   Melnyk P., 2019, SOFT COMPUT, V24, P1
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Schwarz CG, 2019, NEW ENGL J MED, V381, P1684, DOI 10.1056/NEJMc1908881
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shu Chang, 2011, Tsinghua Science and Technology, V16, P216, DOI 10.1016/S1007-0214(11)70032-3
   Sun Y, 2015, ARXIV
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tieleman Tijmen, 2012, LECT 6 5 RMSPROP COU
   Vinay A, 2019, INT C RECENT TRENDS
   Wang H, 2019, SIGNAL IMAGE VIDEO P, V13, P985, DOI 10.1007/s11760-019-01436-1
   Wani M.A., 2020, Advances in Deep Learning, P95
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   William I., 2019, 2019 4 INT C INF COM, P1
   Yasunami S, APPL CNNS EARLY MODE
   Yu DJ, 2014, LECT NOTES ARTIF INT, V8818, P364, DOI 10.1007/978-3-319-11740-9_34
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zheng T., 2018, Tech. Rep., V5
   Zheng T., 2017, ARXIV
NR 42
TC 3
Z9 3
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23673
EP 23691
DI 10.1007/s11042-023-14603-x
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000937854600006
DA 2024-07-18
ER

PT J
AU Garg, S
   Singh, P
AF Garg, Shankey
   Singh, Pradeep
TI An aggregated loss function based lightweight few shot model for plant
   leaf disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Lightweight models; Few-shot classification; Loss
   function
ID AGRICULTURE
AB In India, a significant portion of the annual crop is lost due to plant diseases. It is required to monitor agriculture's growth and health status of plants to help farmers take prompt actions regarding any plant disease. An automatic plant disease classification algorithm is necessary to identify and prevent plant diseases at an early stage. This paper aims to classify plant diseases using a lightweight transfer learning model using only a few samples. Few-shot classification aims to identify unseen classes while training with small labeled data. The proposed work uses an aggregated loss function formed by the combination of triplet loss and cross-entropy loss with MobileNetV2 as a base model for the effective classification of plant disease using small samples. Two publicly available datasets (PlantVillage having 54,303 leaf samples and Plantdoc having 2598 Leaf samples) were considered for the evaluation of the proposed work. Different domain splits were considered to divide the dataset into the source, and target domains, and a large quantum of experimentation is conducted on the target dataset considering various sample sizes. For the analysis of plantvillage dataset, four domain splits were considered, and it is found that an average improvement in accuracy, when compared with recent work, is 1.49% for split-1, 16.25% for split-2, 2.9% for split-3, and 2.1%for split-4 using the proposed aggregated loss and the lightweight transfer learning model for the target domain data (K-ways, N-shot). Two domain splits were considered for the plantdoc dataset, and it gives an accuracy of around 81% using 30 samples and more than 40% using only 1 sample. The proposed work is compared with several state-of-the-art works using different evaluation metrics like, loss functions, execution time, model size, and model parameters.
C1 [Garg, Shankey; Singh, Pradeep] Natl Inst Technol, Dept Comp Sci & Engn, Raipur 492010, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Singh, P (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Raipur 492010, Chhattisgarh, India.
EM sgarg.phd2019.cse@nitrr.ac.in; psingh.cs@nitrr.ac.in
CR [Anonymous], 2015, ARXIV PREPR ARXIV151
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Chen W., 2020, PROC INT C LEARN REP
   Chen Y., 2020, arXiv
   Dhillon G. S., 2020, INT C LEARN REPR
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   LeCun S, 1997, APPL FACE VERIFICATI, V40, P91, DOI [10.1007/BF02407565, DOI 10.1007/BF02407565]
   Li XM, 2020, NEUROCOMPUTING, V406, P49, DOI 10.1016/j.neucom.2020.04.040
   Li XX, 2019, IEEE T VEH TECHNOL, V68, P4204, DOI 10.1109/TVT.2019.2895651
   Li Y, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00770-1
   Li Y, 2021, COMPUT ELECTRON AGR, V182, DOI 10.1016/j.compag.2021.106055
   Liu XJ, 2022, MULTIMED TOOLS APPL, V81, P4979, DOI 10.1007/s11042-021-11472-0
   Nuthalapati SV, 2021, IEEE INT CONF COMP V, P1399, DOI 10.1109/ICCVW54120.2021.00161
   Parnami A., 2022, ARXIV
   Paszke A., 2017, ADV NEURAL INF PROCE, V9, P1, DOI DOI 10.1017/CB09781107707221.009
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Raman S, 2022, MULTIMED TOOLS APPL, V81, P22323, DOI 10.1007/s11042-021-11866-0
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Singh D, 2020, ACM INT CONF PR SER, P249, DOI 10.1145/3371158.3371196
   Thakur PS, 2023, MULTIMED TOOLS APPL, V82, P497, DOI 10.1007/s11042-022-13144-z
   Wang B, 2019, IEEE ACCESS, V7, P151754, DOI 10.1109/ACCESS.2019.2947510
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang YT, 2021, IEEE INT C BIOINF BI, DOI 10.1109/BIBE52308.2021.9635575
   Yang JC, 2022, PLANT METHODS, V18, DOI 10.1186/s13007-022-00866-2
   Zhang CJ, 2020, IEEE T CIRC SYST VID, V30, P2867, DOI 10.1109/TCSVT.2019.2920783
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
   Zhou Y, 2020, PROCEEDINGS OF 2020 IEEE 5TH INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC 2020), P1713, DOI [10.1109/ITOEC49072.2020.9141847, 10.1109/itoec49072.2020.9141847]
NR 31
TC 3
Z9 3
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23797
EP 23815
DI 10.1007/s11042-023-14372-7
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000933104800005
DA 2024-07-18
ER

PT J
AU Cui, YM
   Lu, SC
   Liu, SY
AF Cui, Yuming
   Lu, Shuochen
   Liu, Songyong
TI Real-time detection of wood defects based on SPP-improved YOLO algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; Wood defects detection; Real-time detection; Full
   convolutional neural network
ID INTELLIGENCE; INSPECTION; NETWORKS
AB Wood processing is one of the most widely used in agriculture and industry. Low precision and high time delay of machine learning in wood defect detection are currently the main factors restricting the production efficiency and product quality of the wood processing industry. An SPP-improved deep learning method was proposed to detect wood defects based on the basic framework of the YOLO V3 network to improve accuracy and real-time performance. The extended dataset was firstly established by image data enhancement and preprocessing based on the limited samples of the wood defect dataset. Anchor box scale re-clustering of the wood defect dataset was carried out according to the defect features. The spatial pyramid pooling (SPP) network was applied to improve the feature pyramid (FP) network in YOLO V3. The validity and real-time performance of the proposed algorithm were verified by a randomly selected test set. The results show that the overall detection accuracy rate on the wood defect test dataset reaches 93.23% while the detection time for each image is within 13 ms.
C1 [Cui, Yuming] Jiangsu Normal Univ, Sch Mechatron Engn, Xuzhou 221116, Peoples R China.
   [Lu, Shuochen; Liu, Songyong] China Univ Min & Technol, Sch Mechatron Engn, Xuzhou 221116, Peoples R China.
C3 Jiangsu Normal University; China University of Mining & Technology
RP Lu, SC (corresponding author), China Univ Min & Technol, Sch Mechatron Engn, Xuzhou 221116, Peoples R China.
EM 295002408@qq.com
OI , Yuming Cui/0000-0001-5648-1825
FU National Key R&D Program of China [2018YFB1308303]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2018YFB1308303, and in part by the Priority Academic Program
   Development of Jiangsu Higher Education Institutions.
CR Baesler F, 2014, INT J ADV MANUF TECH, V74, P757, DOI 10.1007/s00170-014-5957-6
   Dawei Qi, 2008, 2008 IEEE Conference on Cybernetics and Intelligent Systems, P951, DOI 10.1109/ICCIS.2008.4670955
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Funck JW, 2003, COMPUT ELECTRON AGR, V41, P157, DOI 10.1016/S0168-1699(03)00049-8
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He T, 2019, IEEE ACCESS, V7, P123453, DOI 10.1109/ACCESS.2019.2937461
   Hendarto B, 2006, INT J ADV MANUF TECH, V28, P775, DOI 10.1007/s00170-004-2414-y
   Hittawe MM, 2015, IEEE IMAGE PROC, P427, DOI 10.1109/ICIP.2015.7350834
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee S, 2011, J WOOD SCI, V57, P387, DOI 10.1007/s10086-011-1186-x
   Lemley J, 2017, IEEE CONSUM ELECTR M, V6, P48, DOI 10.1109/MCE.2016.2640698
   Lihai W., 2002, FORESTRY SCI TECHNOL, V27, P35
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   [罗会兰 Luo Huilan], 2020, [电子学报, Acta Electronica Sinica], V48, P1230
   Packianather MS, 2015, 2015 10th System of Systems Engineering Conference (SoSE), P498, DOI 10.1109/SYSOSE.2015.7151902
   Packianather MS, 2000, INT J ADV MANUF TECH, V16, P424, DOI 10.1007/s001700050174
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Robertson S, 2008, P 31 ANN INT ACM SIG, P689, DOI DOI 10.1145/1390334.1390453
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ruz GA, 2009, INT J SYST SCI, V40, P163, DOI 10.1080/00207720802630685
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silvén I, 2003, MACH VISION APPL, V13, P275, DOI 10.1007/s00138-002-0084-z
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tang C, 2020, AQUACULT ENG, V91, DOI 10.1016/j.aquaeng.2020.102115
   van Dyk DA, 2001, J COMPUT GRAPH STAT, V10, P1, DOI 10.1198/10618600152418584
   Wu D, 2010, 2010 CHINESE C PATTE, P1
   Zhang R., 2021, AI EDAM, V35, P77
   Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Zhang YZ, 2016, WOOD SCI TECHNOL, V50, P297, DOI 10.1007/s00226-015-0776-y
   Zhang YZ, 2015, J FORESTRY RES, V26, P745, DOI 10.1007/s11676-015-0066-4
   Zhou LM, 2020, PROCEEDINGS OF 2020 IEEE 4TH INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2020), P468, DOI [10.1109/itnec48623.2020.9084975, 10.1109/ITNEC48623.2020.9084975]
NR 37
TC 5
Z9 5
U1 32
U2 87
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21031
EP 21044
DI 10.1007/s11042-023-14588-7
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000931751400001
DA 2024-07-18
ER

PT J
AU Li, GX
   Zheng, ZZ
   Shao, YY
   Shen, JY
   Zhang, Y
AF Li, Guangxu
   Zheng, Zhouzhou
   Shao, Yuyi
   Shen, Jinyue
   Zhang, Yan
TI Automated Tire visual inspection based on low rank matrix recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automated visual inspection; Low rank matrix recovery; Semantic texture
   segmentation
ID DEFECT INSPECTION; ALGORITHM
AB Visual inspection is a challenging and widely employed process in industries. In this work, an automated tire visual inspection system is proposed based on low rank matrix recovery. Deep Network is employed to perform texture segmentation which benefits low rank decomposition in both quality and computational efficiency. We propose a dual optimization method to improve convergence speed and matrix sparsity by incorporating the improvement of the soft-threshold shrinkage operator by the weight matrix M. We investigated how incremental multiplier affects the decomposition accuracy and the convergence speed of the algorithm. On this basis, image blocks were decomposed into low-rank matrix and sparse matrix in which defects were separated. Comparative experiments have been performed on our dataset. Experimental results validate the theoretical analysis. The method is promising in false alarm, robustness and running time based on multi-core processor distributed computing. It can be extended to other real-time industrial applications.
C1 [Li, Guangxu; Shao, Yuyi; Shen, Jinyue; Zhang, Yan] Qingdao Univ Sci & Technol, Coll Mech & Elect Engn, Qingdao 266061, Peoples R China.
   [Zheng, Zhouzhou] Northwest A&F Univ, Coll Mech & Elect Engn, Xianyang 712100, Peoples R China.
C3 Qingdao University of Science & Technology; Northwest A&F University -
   China
RP Zhang, Y (corresponding author), Qingdao Univ Sci & Technol, Coll Mech & Elect Engn, Qingdao 266061, Peoples R China.
EM zy@qust.edu.cn
RI Zheng, Zhouzhou/AAU-4761-2021
OI Zheng, Zhouzhou/0000-0002-0822-1436
FU Natural Science Foundation of Shandong Province [ZR2019MEE066,
   ZR2018MC007]
FX AcknowledgementsThis work was supported by the Natural Science
   Foundation of Shandong Province No. ZR2019MEE066 and partly by No.
   ZR2018MC007.
CR Al Arif SMMR, 2018, COMPUT METH PROG BIO, V157, P95, DOI 10.1016/j.cmpb.2018.01.006
   [Anonymous], 2009, ADV NEUR INF PROC SY
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Biao Y, 2015, OPTIK, V126, P4586, DOI 10.1016/j.ijleo.2015.08.064
   Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061
   Cao FL, 2017, NEURAL COMPUT APPL, V28, pS503, DOI 10.1007/s00521-016-2391-8
   Cen YG, 2015, NEUROCOMPUTING, V149, P1206, DOI 10.1016/j.neucom.2014.09.007
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chu W, 2021, STUDIES EFFECTS WIRI
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Guo Q, 2016, J SENSORS, V2016, DOI 10.1155/2016/4140175
   Jia YT, 2021, IEEE ACCESS, V9, P44107, DOI 10.1109/ACCESS.2021.3066445
   Jin B, 2020, IEEE ACCESS, V8, P123649, DOI 10.1109/ACCESS.2020.3005687
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P2180, DOI 10.1109/TIP.2021.3050643
   Ju MY, 2020, IEEE T IMAGE PROCESS, V29, P3104, DOI 10.1109/TIP.2019.2957852
   Li FY, 2011, ADV MATER RES-SWITZ, V317-319, P968, DOI 10.4028/www.scientific.net/AMR.317-319.968
   Li P, 2019, MULTIMED TOOLS APPL, V78, P99, DOI 10.1007/s11042-017-5263-z
   Lin Z, 2013, ARXIV
   Lin Z, SIAM J OPTIM
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Mo DM, 2021, IEEE T AUTOM SCI ENG, V18, P1170, DOI 10.1109/TASE.2020.2997718
   Ren RX, 2018, IEEE T CYBERNETICS, V48, P929, DOI 10.1109/TCYB.2017.2668395
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sun J, 2019, IEEE T IND INFORM, V15, P6322, DOI 10.1109/TII.2019.2896357
   Tang G., 2011, P ANN C INF SCI SYST, P1, DOI DOI 10.1109/CISS.2011.5766144
   Tao M, 2011, SIAM J OPTIMIZ, V21, P57, DOI 10.1137/100781894
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang Q, 2020, I C NETWORK PROTOCOL, DOI 10.1109/icnp49622.2020.9259369
   Xiang YY, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (ICIA), P519, DOI 10.1109/ICInfA.2014.6932710
   Yin XF, 2020, AUTOMAT CONSTR, V109, DOI 10.1016/j.autcon.2019.102967
   Zhang JW, 2020, COMPUT IND, V122, DOI 10.1016/j.compind.2020.103231
   Zhang XQ, 2021, IEEE T IMAGE PROCESS, V30, P5211, DOI 10.1109/TIP.2021.3078319
   Zhang XQ, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103003
   Zhang Y., 2013, CHINESE PHYS LETT, V8, P256
   Zhang Y, 2018, INT J COMPUT INT SYS, V11, P1056, DOI 10.2991/ijcis.11.1.80
   Zhang Y, 2017, IEEE T AUTOM SCI ENG, V14, P1378, DOI 10.1109/TASE.2015.2469594
   Zhang Y, 2013, OPT LASER TECHNOL, V47, P64, DOI 10.1016/j.optlastec.2012.08.023
   Zhao G, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082524
   Zhao M, 2021, ARXIV
   Zhao MY, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102048
   Zheng ZZ, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/ac13f8
   Zheng ZZ, 2021, MEAS SCI TECHNOL, V32, DOI 10.1088/1361-6501/abddf3
   Zheng ZZ, 2020, IEEE ACCESS, V8, P112674, DOI 10.1109/ACCESS.2020.3003089
   Zhou ZH, 2010, IEEE INT SYMP INFO, P1518, DOI 10.1109/ISIT.2010.5513535
   Zhu JZ, 2018, IEEE T IND INFORM, V14, P5658, DOI 10.1109/TII.2018.2866443
NR 48
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24227
EP 24246
DI 10.1007/s11042-023-14467-1
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000931751400002
DA 2024-07-18
ER

PT J
AU Mughaid, A
   Obeidat, I
   AlZu'bi, S
   Elsoud, EA
   Alnajjar, A
   Alsoud, AR
   Abualigah, L
AF Mughaid, Ala
   Obeidat, Ibrahim
   AlZu'bi, Shadi
   Elsoud, Esraa Abu
   Alnajjar, Asma
   Alsoud, Anas Ratib
   Abualigah, Laith
TI A novel machine learning and face recognition technique for fake
   accounts detection system on cyber social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social media; Cyber attacks; Social media privacy; Computer vision in
   social media; Social media security; Face recognition
ID ONLINE; THREATS
AB Online Social Networks (OSN) such as Facebook, Instagram, Twitter, and others have seen rapid growth in recent years. Such applications provide attractive online social networks and communications with the opportunity to connect with relatives and acquaintances, meet new people, enter communities, talk, exchange photos, organize events, and network with others who are close to real-life; unfortunately, on the other hand, they also raise privacy and security issues. We identified OSN threats in this paper and recommended a digital face-processing authentication method as a double-factor authentication after entering the password using Matlab. After applying deep learning classification by attending to a real dataset from the live webcam to train the model, we achieved the best accuracy rate of 95%. However, such methods have yet to be deployed to all social networks, so we also mentioned the problem of fake accounts, which is one of the most significant problems in OSN. These are effective tools for executing spam campaigns and spreading malware and phishing attacks. Fake accounts could lead to the loss of money for businesses, loss of reputation, stealing information for malicious purposes, and much more. This study is related to detecting fake and legitimate profiles on OSN. For this purpose, we chose two datasets that contain fake and legitimate accounts on Facebook and Instagram. Each contains different features after applying machine learning using Naive Bayes, Logistic Regression, Support Vector Machines, K-Nearest Neighbour, Boosted Tree, Neural Networks, SVM Kernal, and Logistec Regression Kernal. SVM achieved the highest classification accuracy for the Fake Profiles detection datasets with 97.1%.
C1 [Mughaid, Ala; Obeidat, Ibrahim; Elsoud, Esraa Abu; Alnajjar, Asma] Hashemite Univ, Fac Prince Al Hussien bin Abdullah IT, Dept Informat Technol, POB 330127, Zarqa, Jordan.
   [AlZu'bi, Shadi] Al Zaytoonah Univ Jordan, Fac Sci & IT, Amman, Jordan.
   [Alsoud, Anas Ratib; Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Ho Chi Minh City Open Univ, Ctr Engn Applicat & Technol Solut, Ho Chi Minh, Vietnam.
   [Abualigah, Laith] Al AlBayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.
   [Abualigah, Laith] Middle East Univ, Fac Informat Technol, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Pulau Pinang, Malaysia.
C3 Hashemite University; Al-Zaytoonah University of Jordan; Al-Ahliyya
   Amman University; Ho Chi Minh City Open University; Al al-Bayt
   University; Middle East University; Universiti Sains Malaysia
RP Abualigah, L (corresponding author), Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.; Abualigah, L (corresponding author), Ho Chi Minh City Open Univ, Ctr Engn Applicat & Technol Solut, Ho Chi Minh, Vietnam.; Abualigah, L (corresponding author), Al AlBayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.; Abualigah, L (corresponding author), Middle East Univ, Fac Informat Technol, Amman 11831, Jordan.; Abualigah, L (corresponding author), Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.; Abualigah, L (corresponding author), Univ Sains Malaysia, Sch Comp Sci, George Town 11800, Pulau Pinang, Malaysia.
EM Aligah.2020@gmail.com
RI Abualigah, Laith/ABC-9695-2020; ALSOUD, ANAS RATIB/AAM-7546-2021
OI Abualigah, Laith/0000-0002-2203-4549; ALSOUD, ANAS
   RATIB/0000-0002-1410-8843; Abu Elsoud, Esraa/0009-0000-0796-8522;
   Mughaid, Ala/0000-0002-1298-6933
CR Abualigah Laith, 2023, Journal of Ambient Intelligence and Humanized Computing, P13931, DOI 10.1007/s12652-022-04103-5
   Abualigah L, 2021, DEEP LEARNING APPROA, P1
   Abushanap Samia A., 2021, 2021 International Conference on Information Technology (ICIT), P571, DOI 10.1109/ICIT52682.2021.9491678
   Abusukhon A, 2020, 2020 SEVENTH INTERNATIONAL CONFERENCE ON SOFTWARE DEFINED SYSTEMS (SDS), P235, DOI 10.1109/SDS49854.2020.9143891
   Al Hasib A, 2009, INT J COMPUT SCI NET, V9, P288
   Al-Zoubi AM, 2017, INT CONF INFORM COMM, P130, DOI 10.1109/IACS.2017.7921959
   Al-Zu'bi S, 2021, MULTIMED TOOLS APPL, V80, P16887, DOI 10.1007/s11042-020-09160-6
   Albayati M., 2019, INT J SIMULATION SYS, V20, P1
   Albayati MB, 2019, J ICT RES APPL, V13, P107, DOI 10.5614/itbj.ict.res.appl.2019.13.2.2
   Alfar HE, 2020, Recent Advances in NLP: The Case of Arabic Language, P129, DOI DOI 10.1007/978-3-030-34614-0_7
   Alghamdi B, 2016, 2016 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WIW 2016), P5, DOI [10.1109/WIW.2016.014, 10.1109/WIW.2016.41]
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Alia MA, 2011, ARXIV
   Alia MA, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), P234, DOI 10.1109/JEEIT.2019.8717368
   Alkhatib A.A. A., 2021, Advances in Science, Technology and Engineering Systems Journal, V6, P860
   Alkhatib AAA, 2022, IET SMART CITIES, V4, P143, DOI 10.1049/smc2.12032
   AlZu'bi S, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11182964
   Alzu'bi S, 2019, INT RENEW SUST ENERG, P922, DOI 10.1109/irsec48032.2019.9078166
   AlZu'bi S, 2022, CLUSTER COMPUT, V25, P3617, DOI 10.1007/s10586-022-03594-3
   AlZu'bi S, 2020, 2020 FIFTH INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P306, DOI [10.1109/FMEC49853.2020.9144916, 10.1109/fmec49853.2020.9144916]
   AlZu'bi S, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P555, DOI [10.1109/SNAMS.2019.8931816, 10.1109/snams.2019.8931816]
   AlZu'bi S, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P494, DOI [10.1109/snams.2019.8931856, 10.1109/SNAMS.2019.8931856]
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   AlZu'bi S, 2020, PATTERN RECOGN LETT, V130, P312, DOI 10.1016/j.patrec.2018.07.026
   AlZu'bi S, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P323, DOI 10.1109/SNAMS.2018.8554909
   Alzubi S, 2020, INT CONF INFORM COMM, P191, DOI 10.1109/ICICS49469.2020.239519
   [Anonymous], 2011, PROC INTERNET MEASUR, DOI 10.1145/2068816.2068823
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI DOI 10.1145/1526709.1526784
   Aqel D, 2022, CLUSTER COMPUT, V25, P2007, DOI 10.1007/s10586-021-03397-y
   Avidan S, 2006, LECT NOTES COMPUT SC, V3953, P1, DOI 10.1007/11744078_1
   Aydin I, 2022, 2018 INT C ARTIFICIA, P1
   Aydin I, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA PROCESSING (IDAP)
   Elbes M, 2022, INT J ADV SOFT COMPU, V14
   Fire M., 2012, HUMAN J, V1, P26
   Fire M, 2014, IEEE COMMUN SURV TUT, V16, P2019, DOI 10.1109/COMST.2014.2321628
   Gross R., 2007, Biometrics: Theory, Applications, and Systems, P1
   Humphreys L, 2007, J COMPUT-MEDIAT COMM, V13, P341, DOI 10.1111/j.1083-6101.2007.00399.x
   Hussein F, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11193075
   Ilia P, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P781, DOI 10.1145/2810103.2813603
   Jia JY, 2017, I C DEPEND SYS NETWO, P273, DOI 10.1109/DSN.2017.55
   Mislove A., 2010, P 3 ACM INT C WEB SE, P251, DOI [DOI 10.1145/1718487.1718519, 10.1145/1718487.1718519]
   Mughaid Ala, 2021, 2021 International Conference on Information Technology (ICIT), P691, DOI 10.1109/ICIT52682.2021.9491709
   Mughaid A, 2023, MULTIMED TOOLS APPL, V82, P13973, DOI 10.1007/s11042-022-13914-9
   Mughaid A, 2022, SOFT COMPUT, V26, P5577, DOI 10.1007/s00500-022-07080-1
   Muhairat M, 2020, J UNIVERS COMPUT SCI, V26, P33
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Obeidat I, 2016, INT J INTERACTIVE MO
   OLeary J, 2013, GETT START LOG VER
   Otair M, 2022, WIREL NETW, V28, P721, DOI 10.1007/s11276-021-02866-x
   Pallis G, 2011, STUD COMPUT INTELL, V331, P213
   Ramadan R, 2019, 2019 SIXTH INTERNATIONAL CONFERENCE ON SOCIAL NETWORKS ANALYSIS, MANAGEMENT AND SECURITY (SNAMS), P561, DOI [10.1109/snams.2019.8931832, 10.1109/SNAMS.2019.8931832]
   Raturi R., 2018, INT J PURE APPL MATH, V118, P4785
   Reddy V, 2021, J COMPUT VIROL HACKI, V17, P333, DOI 10.1007/s11416-021-00387-x
   Safaldin M, 2021, J AMB INTEL HUM COMP, V12, P1559, DOI 10.1007/s12652-020-02228-z
   Sahoo SR, 2019, ENTERP INF SYST-UK, V13, P832, DOI 10.1080/17517575.2019.1605542
   Siddiqui S, 2016, IWSPA'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL WORKSHOP ON SECURITY AND PRIVACY ANALYTICS, P64, DOI 10.1145/2875475.2875484
   Song Andrew., 2011, Introducing login approvals
   Stein T., 2011, P 4 WORKSH SOC NETW, P1
   Sushama C., 2021, Materials Today: Proceedings, DOI [DOI 10.1016/J.MATPR.2020.11.105, 10.1016/j.matpr.2020.11.105]
   Williams EJ, 2018, INT J HUM-COMPUT ST, V120, P1, DOI 10.1016/j.ijhcs.2018.06.004
   Zhang ZY, 2018, FUTURE GENER COMP SY, V86, P914, DOI 10.1016/j.future.2016.10.007
NR 64
TC 5
Z9 5
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26353
EP 26378
DI 10.1007/s11042-023-14347-8
EA JAN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000922310300005
DA 2024-07-18
ER

PT J
AU Gao, ML
   Zhou, YN
   Zhai, WZ
   Zeng, S
   Li, QL
AF Gao, Mingliang
   Zhou, Yi'nan
   Zhai, Wenzhe
   Zeng, Shuai
   Li, Qilei
TI SaReGAN: a salient regional generative adversarial network for visible
   and infrared image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Smart city; Image fusion; Visible and infrared image; Generative
   adversarial network; Salient region
ID PERFORMANCE
AB Multispectral image fusion plays a crucial role in smart city environment safety. In the domain of visible and infrared image fusion, object vanishment after fusion is a key problem which restricts the fusion performance. To address this problem, a novel Salient Regional Generative Adversarial Network GAN (SaReGAN) is presented for infrared and VIS image fusion. The SaReGAN consists of three parts. In the first part, the salient regions of infrared image are extracted by visual saliency map and the information of these regions is preserved. In the second part, the VIS image, infrared image and salient information are merged thoroughly in the generator to gain a pre-fused image. In the third part, the discriminator attempts to differentiate the pre-fused image and VIS image, in order to learn details from VIS image based on the adversarial mechanism. Experimental results verify that the SaReGAN outperforms other state-of-the-art methods in quantitative and qualitative evaluations.
C1 [Gao, Mingliang; Zhai, Wenzhe] Shandong Univ Technol, Coll Elect & Elect Engn, Zibo 255000, Shandong, Peoples R China.
   [Zhou, Yi'nan] Genesis AI Lab, Futong Technol, Chengdu 610054, Peoples R China.
   [Zeng, Shuai] Sichuan Univ, West China Univ Hosp 2, Dept Obstet & Gynaecol, Chengdu, Sichuan, Peoples R China.
   [Li, Qilei] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
C3 Shandong University of Technology; Sichuan University; University of
   London; Queen Mary University London
RP Zhou, YN (corresponding author), Genesis AI Lab, Futong Technol, Chengdu 610054, Peoples R China.
EM littlemuji@163.com
RI Zhai, Wenzhe/KEE-6745-2024; li, xiaomin/KCX-9845-2024; ,
   李启磊/K-7546-2019; WANG, SHIHAO/KHC-8263-2024
OI Zhai, Wenzhe/0000-0003-0996-6832; , 李启磊/0000-0002-9675-9016; 
FU National Natural Science Foundation of Shandong Province [ZR2021QD041,
   ZR2020MF127]
FX This work is supported in part by the National Natural Science
   Foundation of Shandong Province (Nos. ZR2021QD041 and ZR2020MF127).
CR Chen JY, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2020.100172
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Gao ML, 2019, IEEE ACCESS, V7, P43110, DOI 10.1109/ACCESS.2019.2907071
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Li B., 2021, Journal of Computer and Communications, V9, P73, DOI 10.4236/jcc.2021.96005
   Li H, 2022, Arxiv, DOI arXiv:1804.08992
   Li QL, 2020, J INTELL TRANSPORT S, V24, P254, DOI 10.1080/15472450.2019.1643725
   Li QL, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5074
   Liu FQ, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5632
   Liu S., 2020, ACM Trans. on Intelligent Systems and Technology, V12, P1
   Ma JY, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103016
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Pan T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143901
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Reynolds JH, 2003, NEURON, V37, P853, DOI 10.1016/S0896-6273(03)00097-7
   Roberts JW, 2008, J APPL REMOTE SENS, V2, DOI 10.1117/1.2945910
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shreyamsha Kumar BK, 2015, SIGNAL IMAGE VIDEO P, V9, P1193, DOI 10.1007/s11760-013-0556-9
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Toet A, 2014, figshare, DOI 10.6084/m9.figshare.1008029.v1
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yu F., 2015, ARXIV
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang H, 2021, INFORM FUSION, V76, P323, DOI 10.1016/j.inffus.2021.06.008
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao JF, 2013, OPT COMMUN, V287, P45, DOI 10.1016/j.optcom.2012.08.070
   Zhou T, 2023, INFORM FUSION, V91, P134, DOI 10.1016/j.inffus.2022.10.017
NR 31
TC 0
Z9 0
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 25
PY 2023
DI 10.1007/s11042-023-14393-2
EA JAN 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8G8VR
UT WOS:000920621000001
DA 2024-07-18
ER

PT J
AU Vivekananda, GN
   Jarwar, MA
   Jaber, MM
   Prakash, C
   Buddhi, D
   Gnanasigamani, LJ
   Sanz-Prieto, I
AF Vivekananda, G. N.
   Jarwar, Muhammad Aslam
   Jaber, Mustafa Musa
   Prakash, Chander
   Buddhi, Dharam
   Gnanasigamani, Lydia J.
   Sanz-Prieto, Ivan
TI Effective two-tier tokenization for intelligent transportation supply
   chain systems using hybrid optimized query expansion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brent's algorithm; Cloud resources scheduling; Intelligent
   transportation; Query expansion; Smart contracts; Supply chain systems
ID VEHICLES; MODEL
AB Intelligent Transportation Supply Chain Systems has continued to metamorphose forward-looking supply chain management (SCM). Using data from the Intelligent Transportation Systems and Supply Chain Management Systems on real-time information Transportation services is critical to survival. The new protocol proposes to fulfill this deficiency gap in Intelligent Transportation Systems and Supply Chain Management. This research suggested the two-tier Tokenization for Intelligent Transportation Supply Chain Systems Using a Hybrid optimized query expansion strategy and Smart Contracts to automatically handle the Intelligent Transportation Supply Chain Systems vehicle alignment on live driving. This helps to enhance the vehicle conditions and traffic to enhance overall transportation systems. This Proposed System has three modules to improve the Intelligent Transportation Supply Chain Systems. Firstly, the Intelligent Transportation Supply Chain Systems for cloud resources scheduling of semantic driving with vehicle alignment. It Shows the Intelligent Transportation activities and Supply Chain Systems management based on "Brent's algorithm. " This encourages the two-tier tokenization. Broadly, the two-tier Tokenization Enabled Smart Contracts show process verification. The formation of Tier 1 is Fungible Tokens based process verification, and Tier 2 is Non-Fungible Tokens based process verification. Also, the Smart Contracts are adaptable to Security concerns in the Intelligent Transportation Supply Chain Systems. It is Forming the "Hybrid Optimized Query Expansion Strategy " for Intelligent Transportation ranking. The simulation result of effective two-tier tokenization for intelligent transportation supply chain systems using hybrid optimized query expansion strategy and smart contracts improves the supply chain management system in planning at 34.5%, optimization at 56.8%, the level of system management at 60.23%, also the analysis 72.3% and finally at the execution stage by 75%.
C1 [Vivekananda, G. N.] Madanapalle Inst Technol & Sci, Dept Comp Sci & Engn, Madanapalle, India.
   [Jarwar, Muhammad Aslam] Sheffield Hallam Univ, Dept Comp, Sheffield, England.
   [Jaber, Mustafa Musa] Al Turath Univ Coll, Dept Med Instruments Engn Tech, 10021, Baghdad, Iraq.
   [Prakash, Chander] Lovly Profess Univ, Sch Mech Engn, Phagwara, India.
   [Buddhi, Dharam] Uttaranchal Univ, Div Res & Innovat, Dehra Dun 248007, Uttarakhand, India.
   [Gnanasigamani, Lydia J.] Vellore Inst Technol, Sch Comp Sci & Engn, Vellore, India.
   [Sanz-Prieto, Ivan] Univ Int La Rioja UNIR, Engn & Technol Sch, Logrono, Spain.
C3 Madanapalle Institute of Technology & Science; Sheffield Hallam
   University; Uttaranchal University; Vellore Institute of Technology
   (VIT); VIT Vellore; Universidad Internacional de La Rioja (UNIR)
RP Vivekananda, GN (corresponding author), Madanapalle Inst Technol & Sci, Dept Comp Sci & Engn, Madanapalle, India.
EM vivekanandagn@gmail.com
RI Prakash, Chander/T-4766-2018; Buddhi, Dharam/Q-1593-2015; G N,
   Vivekananda/L-5335-2014; Jarwar, Aslam/GQH-8677-2022
OI Prakash, Chander/0000-0003-0856-9712; G N,
   Vivekananda/0000-0001-7292-7436; Jarwar, Aslam/0000-0002-5332-1698
CR Adigopula VK, 2022, INNOV INFRASTRUCT SO, V7, DOI 10.1007/s41062-021-00622-w
   Ahmed DR, 2023, ENERGY SYST, V14, P229, DOI 10.1007/s12667-021-00472-6
   Akbari M, 2021, BENCHMARKING, V28, P2977, DOI 10.1108/BIJ-10-2020-0514
   Assbeihat JM, 2021, ACAD STRATEG MANAG J, V20, P1
   Chen Z, 2022, SUSTAIN ENERGY TECHN, V49, DOI 10.1016/j.seta.2021.101724
   Das D, 2022, CLUSTER COMPUT, V25, P1899, DOI 10.1007/s10586-022-03536-z
   Iyer LS., 2021, Transportation Engineering, V5, P100083, DOI [DOI 10.1016/J.TRENG.2021.100083, 10.1016/j.treng.2021.100083]
   Karandikar N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113822
   Khan PW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154252
   Kim H, 2021, ASIAN J CONTROL, V23, P2185, DOI 10.1002/asjc.2449
   Kim K, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.113861
   Kumar PM, 2023, IEEE T INTELL TRANSP, V24, P980, DOI 10.1109/TITS.2022.3191757
   Kumar PM, 2018, COMPUT NETW, V144, P154, DOI 10.1016/j.comnet.2018.07.001
   Liu CC, 2023, J CONTROL DECIS, V10, P174, DOI 10.1080/23307706.2021.2024460
   Liu J, 2021, J PHYS C SER, V2074
   Liu Y, 2023, ANN OPER RES, V326, P81, DOI 10.1007/s10479-021-04383-8
   Ma LX, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103932
   Manogaran G, 2021, IEEE SENS J, V21, P15564, DOI 10.1109/JSEN.2020.3017384
   Micka P, THESIS
   Montoya-Torres JR, 2021, IFAC PAPERSONLINE, V54, P216, DOI 10.1016/j.ifacol.2021.06.025
   Nguyen TN, 2022, IEEE T GREEN COMMUN, V6, P1355, DOI 10.1109/TGCN.2022.3171511
   Prakash V, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111320
   Sohet B, 2021, IEEE T SMART GRID, V12, P5146, DOI 10.1109/TSG.2021.3107896
   Tsakam B, 2021, PREPRINT
   Tyagi A.K., 2021, Int. J. Intell. Networks, V2, P83
   Vanderschuren M, INTELLIGENT TRANSPOR
   Varnaseri A, 2021, INT J KNOWL PROCESS, V1, P3
   Younus AM, 2021, EUR J RES DEV SUSTAI, V2, P99
   Zingla MA, 2018, INFORM RETRIEVAL J, V21, P337, DOI 10.1007/s10791-017-9326-6
NR 29
TC 0
Z9 0
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 21
PY 2022
DI 10.1007/s11042-022-14317-6
EA DEC 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7F2PJ
UT WOS:000901695800002
DA 2024-07-18
ER

PT J
AU Goyal, V
   Sharma, S
AF Goyal, Vinat
   Sharma, Sanjeev
TI Texture classification for visual data using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture classification; Computer vision; Transfer learning; MobileNetV3;
   InceptionV3; Deep learning
ID FEATURES; DESCRIPTORS
AB The texture is the most fundamental aspect of a picture that contributes to its recognition. Computer vision challenges such as picture identification and segmentation are built on the foundation of texture analysis. Various images of satellite, forestry, medical etc. have been identifiable because of textures. This work aims to offer texture classification models that will outperform previously presented methods. In this work, transfer learning was applied to attain this goal. MobileNetV3 and InceptionV3 are the two pre-trained models employed. Brodatz, Kylberg, and Outex texture datasets were used to evaluate the models. The models achieved excellent results and achieved the objective in most cases. Classification accuracy obtained for the Kylberg dataset were 100% and 99.89%. For the Brodatz dataset, the classification accuracy obtained was 99.83% and 99.94%. For the Outex datasets, the classification accuracy obtained was 99.48% and 99.48%. The model outputs the corresponding label of the texture of the image.
C1 [Goyal, Vinat; Sharma, Sanjeev] Indian Inst Informat Technol, Pune, India.
RP Goyal, V (corresponding author), Indian Inst Informat Technol, Pune, India.
EM vinatgoyal19@cse.iiitp.ac.in; sanjeevsharma@iiitp.ac.in
OI Goyal, Vinat/0000-0002-3859-9034
CR Ahmadvand A, 2016, IMAGE VISION COMPUT, V45, P1, DOI 10.1016/j.imavis.2015.10.002
   Andrearczyk V, 2016, PATTERN RECOGN LETT, V84, P63, DOI 10.1016/j.patrec.2016.08.016
   Arora V, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104575
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Sa JJD, 2016, PATTERN RECOGN, V51, P395, DOI 10.1016/j.patcog.2015.09.014
   Di Ruberto C, 2017, IET IMAGE PROCESS, V11, P760, DOI 10.1049/iet-ipr.2016.1077
   Dixit U, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-0678-y
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   El Khadiri I, 2018, INFORM SCIENCES, V467, P634, DOI 10.1016/j.ins.2018.02.009
   Feng JW, 2017, IET IMAGE PROCESS, V11, P118, DOI 10.1049/iet-ipr.2016.0495
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermann KM, 2015, ADV NEURAL INFORM PR, V28, P1693
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Jain A, 2022, MULTIMED TOOLS APPL, V81, P6451, DOI 10.1007/s11042-021-11823-x
   Kalita DJ, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114139
   Kaya Y, 2015, APPL SOFT COMPUT, V34, P728, DOI 10.1016/j.asoc.2015.06.009
   Kazi A, 2022, MULTIMED TOOLS APPL, V81, P7611, DOI 10.1007/s11042-022-12150-5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundu R, 2022, MULTIMED TOOLS APPL, V81, P31, DOI 10.1007/s11042-021-11319-8
   Kylberg G., 2011, KYLBERG TEXTURE DATA
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Liu XJ, 2022, MULTIMED TOOLS APPL, V81, P4979, DOI 10.1007/s11042-021-11472-0
   Lu SY, 2020, PATTERN RECOGN LETT, V140, P252, DOI 10.1016/j.patrec.2020.10.017
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Nadeem Z, 2022, MULTIMED TOOLS APPL, V81, P8429, DOI 10.1007/s11042-022-12177-8
   Nasirzadeh M, 2010, 2010 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE, COMMUNICATION SYSTEMS AND NETWORKS (CICSYN), P308, DOI 10.1109/CICSyN.2010.27
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Picard R. W., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P638, DOI 10.1109/CVPR.1993.341050
   Pritt M, 2017, IEEE APP IMG PAT
   Ramola A, 2020, ENG REP, V2, DOI 10.1002/eng2.12149
   Sana JK, 2018, IET IMAGE PROCESS, V12, P2065, DOI 10.1049/iet-ipr.2018.5604
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shallu, 2018, ICT EXPRESS, V4, P247, DOI 10.1016/j.icte.2018.10.007
   Simon Philomina, 2020, Procedia Computer Science, V171, P1680, DOI 10.1016/j.procs.2020.04.180
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh VP, 2018, MULTIMED TOOLS APPL, V77, P14435, DOI 10.1007/s11042-017-5036-8
   SMITH JR, 1994, IEEE IMAGE PROC, P407, DOI 10.1109/ICIP.1994.413817
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Xu P, 2011, P 2 INT C INT MULT C, P147, DOI [10.1145/1937728.1937763, DOI 10.1145/1937728.1937763]
   Yuan XJ, 2006, 2006 28TH ANNUAL INTERNATIONAL CONFERENCE OF THE IEEE ENGINEERING IN MEDICINE AND BIOLOGY SOCIETY, VOLS 1-15, P3301
   Zheng Y, 2014, VISUAL TEXTURE PERCE, DOI [10.1007/978-3-662-45646-041, DOI 10.1007/978-3-662-45646-041]
NR 43
TC 6
Z9 6
U1 3
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24841
EP 24864
DI 10.1007/s11042-022-14276-y
EA DEC 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000897363800001
PM 36532597
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Termritthikun, C
   Jamtsho, Y
   Muneesawang, P
   Zhao, J
   Lee, I
AF Termritthikun, Chakkrit
   Jamtsho, Yeshi
   Muneesawang, Paisarn
   Zhao, Jia
   Lee, Ivan
TI Evolutionary neural architecture search based on efficient CNN models
   population for image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Neural architecture search; Multi-objective evolutionary
   algorithms; Image classification
AB The aim of this work is to search for a Convolutional Neural Network (CNN) architecture that performs optimally across all factors, including accuracy, memory footprint, and computing time, suitable for mobile devices. Although deep learning has evolved for use on devices with minimal resources, its implementation is hampered by that these devices are not designed to tackle complex tasks, such as CNN architectures. To address this limitation, a Network Architecture Search (NAS) strategy is considered, which employs a Multi-Objective Evolutionary Algorithm (MOEA) to create an efficient and robust CNN architecture by focusing on three objectives: fast processing times, reduced storage, and high accuracy. Furthermore, we proposed a new Efficient CNN Population Initialization (ECNN-PI) method that utilizes a combination of random and selected strong models to generate the first-generation population. To validate the proposed method, CNN models are trained using CIFAR-10, CIFAR-100, ImageNet, STL-10, FOOD-101, THFOOD-50, FGVC Aircraft, DTD, and Oxford-IIIT Pets benchmark datasets. The MOEA-Net algorithm outperformed other models on CIFAR-10, whereas MOEANet with the ECNN-PI method outperformed other models on CIFAR-10 and CIFAR-100. Furthermore, both the MOEA-Net algorithm and MOEA-Net with the ECNN-PI method outperformed DARTS, P-DARTS, and Relative-NAS for small-scale multi-class and fine-grained datasets.
C1 [Termritthikun, Chakkrit] Naresuan Univ, Sch Renewable Energy & Smart Grid Technol SGtech, Phitsanulok 65000, Thailand.
   [Jamtsho, Yeshi] Royal Univ Bhutan, Coll Sci & Technol, Phuentsholing 21101, Bhutan.
   [Muneesawang, Paisarn] Naresuan Univ, Fac Engn, Dept Elect & Comp Engn, Phitsanulok 65000, Thailand.
   [Zhao, Jia] Nanchang Inst Technol, Sch Informat Engn, Nanchang 330099, Jiangxi, Peoples R China.
   [Lee, Ivan] Univ South Australia, STEM, Adelaide, SA 5095, Australia.
C3 Naresuan University; Naresuan University; Nanchang Institute Technology;
   University of South Australia
RP Termritthikun, C (corresponding author), Naresuan Univ, Sch Renewable Energy & Smart Grid Technol SGtech, Phitsanulok 65000, Thailand.
EM chakkritt@nu.ac.th
RI Jamtsho, Yeshi/HPD-7094-2023; Lee, Ivan/F-4131-2013; Muneesawang,
   Paisarn/AFS-0172-2022; Termritthikun, Chakkrit/AAI-1448-2020
OI Jamtsho, Yeshi/0009-0006-0975-7458; Termritthikun,
   Chakkrit/0000-0002-1508-3123
FU Thailand Research Fund through the Royal Golden Jubilee PhD. Program
   [PHD/0101/2559]
FX The authors would like to acknowledge the financial support from the
   Thailand Research Fund through the Royal Golden Jubilee PhD. Program
   (Grant No. PHD/0101/2559). The study utilizes Australia's National
   Computational Infrastructure (NCI) under the National Computational
   Merit Allocation Scheme (NCMAS). We would like to extend our
   appreciation to Mr. Roy I. Morien of the Naresuan University Graduate
   School for his assistance in editing the English grammar and expression
   in the paper. Finally, we would like to thank Mr. Ayaz Umer and Ms.
   Suwichaya Suwanwimolkul for their unwavering support, without which the
   research would not have been successful.
CR Baldominos A, 2018, NEUROCOMPUTING, V283, P38, DOI 10.1016/j.neucom.2017.12.049
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen X, 2019, IEEE I CONF COMP VIS, P1294, DOI 10.1109/ICCV.2019.00138
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Coates A., 2011, P 14 INT C ART INT S, P215
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Darlow Luke N, 2018, arXiv
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Dong HB, 2020, KNOWL-BASED SYST, V208, DOI 10.1016/j.knosys.2020.106456
   He C, 2020, P IEEE CVF C COMP VI, P11990, DOI 10.1109/CVPR42600.2020.01201
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hornakova A, 2020, PR MACH LEARN RES, V119
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hutter F., 2018, INT C LEARNING REPRE
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu HaiJing Liu HaiJing, 2018, The Proceedings of the Fifteenth Congress of China Sheep Industry Development Sponsored by the China Animal Husbandry Association in 2018, Henan, China, 10-11 October, 2018, P13
   Lu ZC, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P419, DOI 10.1145/3321707.3321729
   Maji Subhransu, 2013, ARXIV
   Moyano JM, 2020, KNOWL-BASED SYST, V196, DOI 10.1016/j.knosys.2020.105770
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   PARKHI OM, 2012, PROC CVPR IEEE, P3498, DOI [DOI 10.1109/CVPR.2012.6248092, 10.1109/CVPR.2012.6248092]
   Paszke A, 2019, ADV NEUR IN, V32
   Pham H, 2018, PR MACH LEARN RES, V80
   Real E, 2017, PR MACH LEARN RES, V70
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan H, 2023, IEEE T NEUR NET LEAR, V34, P475, DOI 10.1109/TNNLS.2021.3096658
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   TERMRITTHIKUN C, 2019, ECTI T COMPUTER INFO, V13, P21
   Termritthikun C, 2017, INT ELECT ENG CONGR
   Termritthikun C, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104397
   Termritthikun C, 2020, MULTIMED TOOLS APPL, V79, P1475, DOI 10.1007/s11042-019-08332-3
   Termritthikun C, 2019, ENG APPL ARTIF INTEL, V85, P579, DOI 10.1016/j.engappai.2019.07.018
   Umer A, 2022, IEEE T IND INFORM, V18, P6317, DOI 10.1109/TII.2022.3153365
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Xie LX, 2017, IEEE I CONF COMP VIS, P1388, DOI 10.1109/ICCV.2017.154
   Xu Y, 2020, IEEE IC COMP COM NET
   Yan MJ, 2019, IEEE INT CONF COMP V, P2647, DOI 10.1109/ICCVW.2019.00323
   Yang ZH, 2020, PROC CVPR IEEE, P1826, DOI 10.1109/CVPR42600.2020.00190
   Yu Hsiang-Fu, 2020, ARXIV
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhong Z., 2020, P IEEE CVF C COMP VI, P13065, DOI DOI 10.1109/CVPR42600.2020.01308
   Zhu H, 2019, IEEE INT CONF COMP V, P1891, DOI 10.1109/ICCVW.2019.00238
   Zoph B., 2016, INT C LEARN REPR
NR 57
TC 2
Z9 2
U1 5
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 23917
EP 23943
DI 10.1007/s11042-022-14187-y
EA NOV 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000888710400001
DA 2024-07-18
ER

PT J
AU Rastegar, H
   Giveki, D
AF Rastegar, Homayoun
   Giveki, Davar
TI Designing a new deep convolutional neural network for skin lesion
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skin cancer; Deep learning; Convolutional neural network
ID DERMOSCOPY IMAGES; CLASSIFICATION; SEGMENTATION; FEATURES; CANCER
AB In recent decades, many people have died because of cancer. Like many diseases, early detection of the disease can greatly help the healing process of the sick people. One of the most common types of cancer is the skin cancer. Skin lesions can lead to a kind of malignant cancer. Hence, it is important to diagnose the type of the skin lesion. Mostly, the skin lesion diagnosis needs to be done by an expert dermatologist. But a dermatologist's examination can be time consuming and inaccurate. Therefore, using modern computer aided diagnosis methods can help to increase the speed and accuracy of the diagnosis of this disease. This paper proposes a new approach for skin lesion recognition using a new Convolutional Neural Network (CNN) with 69 layers. The proposed method has been tested on three benchmark datasets of skin lesions including PH2, ISIC 2016, and ISIC 2017. The experimental results illustrate that the proposed method performs better compared to the state-of-the-art in the field. Our method reached to 97.2%, 96.3%, and 99.4% of accuracy on PH2, ISIC2016, and ISIC2017 datasets, respectively.
C1 [Rastegar, Homayoun; Giveki, Davar] Malayer Univ, Dept Comp Engn, POB 65719-95863, Malayer, Iran.
RP Giveki, D (corresponding author), Malayer Univ, Dept Comp Engn, POB 65719-95863, Malayer, Iran.
EM rhomayon@gmail.com; davood.giveki@gmail.com
CR Abbas Q, 2010, BRIT J BIOMED SCI, V67, P177, DOI 10.1080/09674845.2010.11730316
   Al-masni MA, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105351
   Al-Masni MA, 2018, COMPUT METH PROG BIO, V162, P221, DOI 10.1016/j.cmpb.2018.05.027
   Albelwi S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060242
   Balch CM, 2009, J CLIN ONCOL, V27, P6199, DOI 10.1200/JCO.2009.23.4799
   Benyahia S, 2022, TISSUE CELL, V74, DOI 10.1016/j.tice.2021.101701
   Bi L, 2016, I S BIOMED IMAGING, P1055, DOI 10.1109/ISBI.2016.7493447
   BINDER M, 1995, ARCH DERMATOL, V131, P286, DOI 10.1001/archderm.131.3.286
   Celebi ME, 2014, IEEE SYST J, V8, P980, DOI 10.1109/JSYST.2014.2313671
   Ching T, 2018, J R SOC INTERFACE, V15, DOI 10.1098/rsif.2017.0387
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Gómez DD, 2008, IEEE T BIO-MED ENG, V55, P157, DOI 10.1109/TBME.2007.910651
   Hosny KM, 2020, MULTIMED TOOLS APPL, V79, P24029, DOI 10.1007/s11042-020-09067-2
   Hosny KM, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0217293
   Jafari MH, 2017, INT J COMPUT ASS RAD, V12, P1021, DOI 10.1007/s11548-017-1567-8
   Jerant AF, 2000, AM FAM PHYSICIAN, V62, P357
   Khan MA, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCES (ICCIS), P63, DOI 10.1109/iccisci.2019.8716400
   Khouloud S, 2022, APPL INTELL, V52, P3976, DOI 10.1007/s10489-021-02652-4
   Korotkov K, 2012, ARTIF INTELL MED, V56, P69, DOI 10.1016/j.artmed.2012.08.002
   Li Z, 2019, INT J IMAG SYST TECH, V29, P577, DOI 10.1002/ima.22337
   Liu Z, 2015, PHYS MED BIOL, V60, P3415, DOI 10.1088/0031-9155/60/9/3415
   Mahbod A, 2019, COMPUT MED IMAG GRAP, V71, P19, DOI 10.1016/j.compmedimag.2018.10.007
   Marques JS, 2012, IEEE ENG MED BIO, P4402, DOI 10.1109/EMBC.2012.6346942
   Nasir M, 2018, MICROSC RES TECHNIQ, V81, P528, DOI 10.1002/jemt.23009
   Nasiri S, 2018, ARXIV
   Pratiwi RA., 2019, COMPUT ENG APPL J, V8, P203
   Reboucas PP, 2018, COMPUT MED IMAG GRAP, V68, P40, DOI 10.1016/j.compmedimag.2018.05.004
   Rizzi M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093045
   Rogers HW, 2015, JAMA DERMATOL, V151, P1081, DOI 10.1001/jamadermatol.2015.1187
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1413-3
   Satheesha TY, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2648797
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Singh L, 2020, PROCEDIA COMPUT SCI, V167, P2172, DOI 10.1016/j.procs.2020.03.267
   Sultana NN, 2018, IET COMPUT VIS, V12, P1096, DOI 10.1049/iet-cvi.2018.5238
   Pham TC, 2018, LECT NOTES ARTIF INT, V10752, P573, DOI 10.1007/978-3-319-75420-8_54
   Tschandl P, 2019, COMPUT BIOL MED, V104, P111, DOI 10.1016/j.compbiomed.2018.11.010
   Waheed Z, 2017, PROCEEDINGS OF 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P316, DOI 10.1109/C-CODE.2017.7918949
   Yousaf K, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/7151475
   Yousefzadeh A, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351562
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yuan Y, 2017, ARXIV170305165
   Zanddizari H, 2021, MED BIOL ENG COMPUT, V59, P1123, DOI 10.1007/s11517-021-02355-5
NR 43
TC 3
Z9 3
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18907
EP 18923
DI 10.1007/s11042-022-14181-4
EA NOV 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000884953400001
DA 2024-07-18
ER

PT J
AU Cao, C
   Qiu, Y
   Wang, Z
   Ou, JR
   Wang, JJ
   Hounye, AH
   Hou, MZ
   Zhou, QH
   Zhang, JL
AF Cao, Cong
   Qiu, Yue
   Wang, Zheng
   Ou, Jiarui
   Wang, Jiaoju
   Hounye, Alphonse Houssou
   Hou, Muzhou
   Zhou, Qiuhong
   Zhang, Jianglin
TI Nested segmentation and multi-level classification of diabetic foot
   ulcer based on mask R-CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic foot ulcer (DFU); Nested-structure; Wound; Multi-level
   classification; Mask Region based convolutional neural networks (mask
   R-CNN)
AB A diabetic foot ulcer(DFU) is a common chronic complication of diabetes because of the dysfunction of islets or receptors of insulin, and it has a high disability and mortality rate. Measuring diabetic foot ulcers is also one of the popular application areas where computer vision combines with deep learning techniques. However, some remaining defects in these studies prevent them from accurately visualizing the wound of different severity. Based on this, we used a multi-classification model to mark the wounds into five grades according to the Wagner diabetic foot grading method. It segmented the different grades in each different level wound using colorfully nested ring shapes to reflect the gradual change of wound grades. We collected 1426 DFU images, of which 967 had nested labels and 459 were single-level labels, with images marked with colored rings to show different degrees of wounds. And then, we constructed a deep learning model of diabetes foot ulcer wounds for semantic segmentation based on Mask Region-based convolutional neural networks (Mask R-CNN), and obtain different levels of diabetes nested segmentation results to reflect the different severity in one wound. Finally, we test and evaluate the performance data of the model. Compared with the state-of- the-art results concerning segmentation and classification and diagnosis of diabetic foot wounds, our model has achieved better performance data (specificity = 99.50%, sensitivity = 70.62%, precision = 84.56%, Mean Average Precision = 85.70%). It shows the effectiveness of our nested segmentation and multi-level classification method. It provides some suggestions and directions for the subsequent evaluation and diagnosis and treatment of diabetic foot ulcers.
C1 [Cao, Cong; Wang, Zheng; Wang, Jiaoju; Hounye, Alphonse Houssou; Hou, Muzhou] Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.
   [Qiu, Yue; Ou, Jiarui] Cent South Univ, Dept Dermatol, Xiangya Hosp, Changsha 410008, Peoples R China.
   [Wang, Zheng] Hunan First Normal Univ, Sci & Engn Sch, Changsha 410205, Peoples R China.
   [Zhou, Qiuhong] Cent South Univ, Teaching & Res Sect Clin Nursing, Xiangya Hosp, Changsha 410008, Peoples R China.
   [Zhang, Jianglin] Southern Univ Sci & Technol, Jinan Univ, Shenzhen Peoples Hosp, Dept Detmatol,Affiliated Hosp 1,Clin Med Coll 2, Shenzhen 518020, Guangdong, Peoples R China.
C3 Central South University; Central South University; Hunan First Normal
   University; Central South University; Jinan University; Southern
   University of Science & Technology
RP Hou, MZ (corresponding author), Cent South Univ, Sch Math & Stat, Changsha 410083, Peoples R China.; Zhou, QH (corresponding author), Cent South Univ, Teaching & Res Sect Clin Nursing, Xiangya Hosp, Changsha 410008, Peoples R China.; Zhang, JL (corresponding author), Southern Univ Sci & Technol, Jinan Univ, Shenzhen Peoples Hosp, Dept Detmatol,Affiliated Hosp 1,Clin Med Coll 2, Shenzhen 518020, Guangdong, Peoples R China.
EM houmuzhou@sina.com; zhouqiuhong_xy@csu.edu.cn;
   zhang.jianglin@szhospital.com
RI Cao, Cong/GSD-8213-2022; , houmuzhou/N-2357-2019; Wang,
   Zheng/GXA-0956-2022; Ou, Jiarui/GVS-0848-2022; Jiang-lin,
   Zhang/ABC-3073-2020
OI Cao, Cong/0000-0002-6853-6421; , houmuzhou/0000-0001-6658-2187; Ou,
   Jiarui/0000-0002-8879-3281; Wang, Zheng/0000-0002-1343-5199
FU Hunan Province Natural Science Foundation [2022JJ30673]; Scientific
   Research Fund of Hunan Provincial Education Department [20C0402]; Hunan
   First Normal University [XYS16N03]; Projects of the National Natural
   Science Foundation of China [82073018]; Shenzhen Science and Technology
   Innovation Commission (Natural Science Foundation of Shenzhen)
   [JCYJ20210324113001005]; Management Research Fund of Xiangya Hospital of
   Central South University [2021GL11]
FX We are grateful to all patients involved in all trials and investigators
   for their previous work that enabled the present study. This study was
   supported by the Hunan Province Natural Science Foundation (grant number
   2022JJ30673), Scientific Research Fund of Hunan Provincial Education
   Department (grant number 20C0402), Hunan First Normal University (grant
   number XYS16N03), the Projects of the National Natural Science
   Foundation of China (grant number 82073018), the Shenzhen Science and
   Technology Innovation Commission (Natural Science Foundation of
   Shenzhen, grant number JCYJ20210324113001005), Management Research Fund
   of Xiangya Hospital of Central South University (grant number 2021GL11).
CR Abdissa D, 2020, J DIABETES RES, V2020, DOI 10.1155/2020/4106383
   Al-Rubeaan K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188097
   Alsabek MB, 2022, INT WOUND J, V19, P531, DOI 10.1111/iwj.13651
   Cassidy Bill, 2021, touchREV Endocrinol, V17, P5, DOI 10.17925/EE.2021.17.1.5
   Chiao JY, 2019, MEDICINE, V98, DOI 10.1097/MD.0000000000015200
   Cui C, 2019, IEEE ENG MED BIO, P1002, DOI [10.1109/EMBC.2019.8856665, 10.1109/embc.2019.8856665]
   Dmitriyeva M, 2022, CURR DIABETES REV, V18, DOI 10.2174/1573399817666210928144706
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gourishetti K, 2020, INT J NANOMED, V15, P9265, DOI 10.2147/IJN.S268941
   Goyal M, 2020, COMPUT BIOL MED, V117, DOI 10.1016/j.compbiomed.2020.103616
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Goyal M, 2019, IEEE J BIOMED HEALTH, V23, P1730, DOI 10.1109/JBHI.2018.2868656
   Goyal M, 2017, IEEE SYS MAN CYBERN, P618, DOI 10.1109/SMC.2017.8122675
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Joulin Armand, 2017, P ICML, P1302
   Kingma D. P., 2014, arXiv
   Lavery L A, 1996, J Foot Ankle Surg, V35, P528
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lu CH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-71831-z
   Mabeku LBK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69208-3
   Malerbi FK, 2022, J MED SYST, V46, DOI 10.1007/s10916-021-01795-8
   Ohura N, 2019, J WOUND CARE, V28, pS13, DOI 10.12968/jowc.2019.28.Sup10.S13
   Rastogi A, 2020, DIABETES RES CLIN PR, V162, DOI 10.1016/j.diabres.2020.108113
   Reardon R, 2020, AUST J GEN PRACT, V49, P250, DOI 10.31128/AJGP-11-19-5161
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rumenapf G, 2021, GEBIETE OPERATIVEN M, V92, P81
   Syed MH, 2020, VASCULAR, V28, P520, DOI 10.1177/1708538120923420
   Wagner F W Jr, 1981, Foot Ankle, V2, P64
   Wang P, 2017, INTERDISCIP SCI, V9, P419, DOI 10.1007/s12539-016-0196-1
   Wang T, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.03.135
   Woldemariam GT, 2020, DIABET METAB SYND OB, V13, P3739, DOI 10.2147/DMSO.S265988
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yap M.H., 2021, 2021 IEEE EMBS INT C, P1
   Yap MH, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104596
NR 39
TC 6
Z9 6
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18887
EP 18906
DI 10.1007/s11042-022-14101-6
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000884646000001
DA 2024-07-18
ER

PT J
AU Patel, R
   Thakar, V
   Joshi, R
AF Patel, Rutul
   Thakar, Vishvjit
   Joshi, Rutvij
TI Dictionary learning-based image super-resolution for multimedia devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super-resolution; Dictionary learning; Sparse representation; Multimedia
   devices
ID REMOTELY-SENSED IMAGES; RESOLUTION; INTERPOLATION; REGISTRATION;
   ALGORITHM
AB In multimedia devices such as mobile phones, surveillance cameras, and web cameras, image sensors have limited spatial resolution. As a result, the image captured from these devices misses high-frequency content and exhibits visual artifacts. Image super-resolution (SR) algorithms can minimize these artifacts by reconstructing missing high-frequency textures. Image SR algorithm estimates a high resolution (HR) image from a given low-resolution (LR) image. Given a single LR image, reconstructing an HR image makes SR be an extremely ill-posed problem. Over the past decade, dictionary learning-based methods have shown promising results in SR reconstruction. These methods extract numerous patches from external images for training dictionaries via sparse representation. However, these methods do not involve any patch selection mechanism that enhances the learning process. This paper proposes a dictionary learning-based SR algorithm that extracts selective patches from an input LR image based on the iScore criterion. Results show that patch selection criteria keep only 36% of all extracted patches for training while improving the peak signal-to-noise ratio (PSNR). Furthermore, we have proposed a method to initialize dictionaries to achieve better convergence that enhances PSNR.
C1 [Patel, Rutul] Nirma Univ, Elect & Commun Engn, Ahmadabad 382481, Gujarat, India.
   [Thakar, Vishvjit] Gujarat Technol Univ, Noble Grp Inst, Junagadh Bhesan Rd, Junagadh 362310, Gujarat, India.
   [Joshi, Rutvij] Parul Univ, Elect & Commun Engn, Vadodara 391760, Gujarat, India.
C3 Nirma University; Gujarat Technological University; Parul University
RP Patel, R (corresponding author), Nirma Univ, Elect & Commun Engn, Ahmadabad 382481, Gujarat, India.
EM rutul.patel@nirmauni.ac.in; vishvjitkthakar@gmail.com;
   RUTVIJ.JOSHI19624@paruluniversity.ac.in
RI Joshi, Rutvij/JKJ-4805-2023
OI Joshi, Rutvij/0000-0002-0562-8521
CR Alam MS, 2000, IEEE T INSTRUM MEAS, V49, P915, DOI 10.1109/19.872908
   Amiri M, 2019, SIGNAL PROCESS-IMAGE, V70, P259, DOI 10.1016/j.image.2018.10.008
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Cha Y, 2007, IEEE T IMAGE PROCESS, V16, P1496, DOI 10.1109/TIP.2007.896645
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Choi JS, 2017, IEEE T IMAGE PROCESS, V26, P1300, DOI 10.1109/TIP.2017.2651411
   Christensen-Jeffries K, 2020, ULTRASOUND MED BIOL, V46, P865, DOI 10.1016/j.ultrasmedbio.2019.11.013
   Dai W, 2012, IEEE T SIGNAL PROCES, V60, P6340, DOI 10.1109/TSP.2012.2215026
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P1, DOI 10.1007/978-1-4419-7011-4
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Elad M, 2010, P IEEE, V98, P972, DOI 10.1109/JPROC.2009.2037655
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Irani M., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P115, DOI 10.1109/ICPR.1990.119340
   Jiang CD, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24536-3
   Jiang K, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107475
   Jiang K, 2019, IEEE T GEOSCI REMOTE, V57, P5799, DOI 10.1109/TGRS.2019.2902431
   Joshi M, 2010, IEEE T GEOSCI REMOTE, V48, P1245, DOI 10.1109/TGRS.2009.2030323
   Keren D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P742, DOI 10.1109/CVPR.1988.196317
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li M, 2008, IEEE T IMAGE PROCESS, V17, P1121, DOI 10.1109/TIP.2008.924289
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Li XL, 2010, SIGNAL PROCESS, V90, P405, DOI 10.1016/j.sigpro.2009.05.028
   Li XS, 2020, SIGNAL PROCESS-IMAGE, V83, DOI 10.1016/j.image.2020.115805
   Ning Q, 2013, IEEE SIGNAL PROC LET, V20, P399, DOI 10.1109/LSP.2013.2242198
   Patel R, 2020, TECHNOLOGIES SUSTAIN, P161
   Patel R, 2020, INT J ELECTRON TELEC, V66, P347, DOI 10.24425/ijet.2020.131884
   Peleg T, 2014, IEEE T IMAGE PROCESS, V23, P2569, DOI 10.1109/TIP.2014.2305844
   Perez-Pellitero E, 2015, I SYMP CONSUM ELECTR, P317, DOI 10.1109/ICCE.2015.7066429
   Starck J.-L., 2010, Sparse image and signal processing: wavelets, curvelets, morphological diversity, DOI DOI 10.1017/CBO9780511730344
   Sun J, 2003, PROC CVPR IEEE, P729
   Merino MT, 2007, IEEE T GEOSCI REMOTE, V45, P1446, DOI 10.1109/TGRS.2007.893271
   Thévenaz P, 2000, BIOMED EN S, P393
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Tipping M., 2002, Advances in neural information processing systems, V15
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
   Van Reeth E, 2012, CONCEPT MAGN RESON A, V40A, P306, DOI 10.1002/cmr.a.21249
   Wang Q, 2005, IEEE I CONF COMP VIS, P709
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang ZY, 2019, IEEE T IMAGE PROCESS, V28, P2530, DOI 10.1109/TIP.2018.2887017
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WM, 2017, IEEE T SYST MAN CY-S, V47, P2478, DOI 10.1109/TSMC.2016.2523947
   Yedidia JS, 2001, ADV NEUR IN, V13, P689
   Yi P, 2022, IEEE T PATTERN ANAL, V44, P2264, DOI 10.1109/TPAMI.2020.3042298
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
NR 55
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 17243
EP 17262
DI 10.1007/s11042-022-14076-4
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000883287200003
DA 2024-07-18
ER

PT J
AU Sharma, G
   Vidalis, S
   Menon, C
   Anand, N
AF Sharma, Gaurav
   Vidalis, Stilianos
   Menon, Catherine
   Anand, Niharika
TI Analysis and implementation of semi-automatic model for vulnerability
   exploitations of threat agents in NIST databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE NIST database; CVSS; Security management; Threat agent vectors;
   Vulnerability
AB Proactive security plays a vital role in preventing the attack before entering active mode. In the modern information environment, it depends on the vulnerability management practitioners of an organization in which the critical factor is the prioritization of threats. The existing models and methodology follow the traditional approaches of a Common Vulnerability Scoring System (CVSS) to prioritize threats and vulnerabilities. The CVSS is not able to provide effectiveness to the security of the business of an organization. In contrast, the vulnerability analysis needs a model which can give significance to the prioritization policies. The model depends on the CVSS score of threats and compares various features of vulnerability like threat vectors, inputs, environments used by threat agent's groups, and potential outputs of threat agents. Therefore, the research aims to design a semi-automatic model for vulnerability analysis of threats for the National Institute of Standards and Technology (NIST) database of cyber-crime. We have developed a semi-automatic model that simulates the CVE (Common Vulnerabilities and Exposures) list of the NIST database between 1999 and 2021, concerning the resources used by the threat agents, pre-requisites input, attack vectors, and dormant results. The semi-automatic approach of the model to perform the vulnerability analysis of threat agent groups identified in a network makes the model more efficient and effective to addresses the profiling of threat agents and evaluating the CTI (Critical Threat intelligence feed). Our experimental results imply that the semi-automatic model implements the vulnerability prioritization based on the CVSS score and uses the comparative analysis based on the threat agent's vectors identified. It also provides potency and optimized complexity to an organization's business to mitigate the vulnerability identified in a network.
C1 [Sharma, Gaurav] Univ Hertfordshire, Cybersecur Res Grp, Hatfield, Herts, England.
   [Vidalis, Stilianos; Menon, Catherine] Univ Hertfordshire, Hatfield, Herts, England.
   [Anand, Niharika] Indian Inst Informat Technol Lucknow IIITL, Lucknow, Uttar Pradesh, India.
C3 University of Hertfordshire; University of Hertfordshire
RP Sharma, G (corresponding author), Univ Hertfordshire, Cybersecur Res Grp, Hatfield, Herts, England.
EM g.gaurav@herts.ac.uk; s.vidalis@herts.ac.uk; c.menon@herts.ac.uk;
   niharika@iiitl.ac.in
RI sharma, gaurav/JXX-2424-2024
OI sharma, gaurav/0000-0003-2523-1297; Menon, Catherine/0000-0003-2072-5845
CR Addison, 2002, INTRO SECURITY RISK
   Alberts C.J., 2001, OCTAVE catalog of practices version 2.0
   Alfadel M, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ANALYSIS, EVOLUTION AND REENGINEERING (SANER 2021), P446, DOI 10.1109/SANER50967.2021.00048
   Allodi L, 2018, ARXIV
   Allodi L, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1483, DOI 10.1145/3133956.3133960
   Allodi L, 2017, LECT NOTES COMPUT SC, V10646, P23, DOI 10.1007/978-3-319-70004-5_2
   Alomar N, 2020, PROCEEDINGS OF THE SIXTEENTH SYMPOSIUM ON USABLE PRIVACY AND SECURITY (SOUPS 2020), P319
   [Anonymous], 1995, Nist special database 19 handprinted forms and characters database
   Aufner P, 2020, INT J INF SECUR, V19, P3, DOI 10.1007/s10207-019-00445-y
   Bagstad Kenneth J., 2011, ARIES Artificial Intelligence for Ecosystem Services: A guide to models and data
   Berhe S, 2021, RES ANTHOLOGY RECENT, P916
   Boban, 2010, E SOC J RES APPL, V1, P1
   Cisar P., 2016, Annals of the Faculty of Engineering Hunedoara - International Journal of Engineering, V14, P207
   de Ruiter MC, 2017, NAT HAZARD EARTH SYS, V17, P1231, DOI 10.5194/nhess-17-1231-2017
   Engebretson P., 2013, BASICS HACKING PENET
   Feutrill A, 2018, INT SYMPOS COMPUT NE, P1, DOI 10.1109/CANDAR.2018.00009
   Franklin J, 2014, NISTIR7946
   Geerts E, 2017, BOOK REV VULNERABLE
   Haber MJ., 2018, ASSET ATTACK VECTORS, DOI [10.1007/978-1-4842-3627-7, DOI 10.1007/978-1-4842-3627-7]
   Humayun M, SECURITY THREAT VULN
   Humayun M, 2020, ARAB J SCI ENG, V45, P3171, DOI 10.1007/s13369-019-04319-2
   Ingoldsby TR, 2010, ATTACK TREE BASED TH, P3
   Jing Y., 2014, P 4 ACM C DATA APPL, P99, DOI DOI 10.1145/2557547.2557549
   Joh H, 2014, QUAL RELIAB ENG INT, V30, P1445, DOI 10.1002/qre.1567
   Jones Andrew., 2002, IDENTIFICATION METHO
   Mahmud SMH, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P71, DOI 10.1109/ICAIBD.2018.8396169
   Martell A., 2004, CRITICALLY SELECTED
   Munaiah Nuthan., 2016, P 2 INT WORKSHOP SOF, P8, DOI DOI 10.1145/2989238.2989239
   Pendleton Marcus, 2017, ACM Computing Surveys, V49, DOI 10.1145/3005714
   Pfleeger C.P., 2009, SECURITY COMPUTING, VFourth
   Ralchenko Y, 2008, NIST ATOMIC SPECTRA
   Ruohonen J, 2018, INFORM SOFTWARE TECH, V103, P239, DOI 10.1016/j.infsof.2018.06.005
   Samuel J, 2020, IEEE INT CONF TRUST, P442, DOI 10.1109/TrustCom50675.2020.00067
   Sgandurra D, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2856126
   Sharma G, 2021, 2021 IEEE BOMBAY SEC, P1, DOI DOI 10.1109/ISCON52037.2021.9702452
   Sharma G, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151849
   Strom B. E., 2018, MITRE ATT&CK: design and Philosophy
   Summers R., 1997, SECURE COMPUTING THR
   Tavenard R, 2020, J MACH LEARN RES, V21
   Teixeira A, 2015, IEEE CONTR SYST MAG, V35, P24, DOI 10.1109/MCS.2014.2364709
   Tevis J.-E.J., 2006, Proceedings of the 44th annual southeast regional conference on - ACM-SE, V44, P560
   Ullah F, 2018, J NETW COMPUT APPL, V101, P18, DOI 10.1016/j.jnca.2017.10.016
   van Royen Martin E., 2008, V464, P363, DOI 10.1007/978-1-60327-461-6_20
   Vidalis S, 2003, CS032
   Xu H, 2011, DECIS SUPPORT SYST, V51, P42, DOI 10.1016/j.dss.2010.11.017
NR 45
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16951
EP 16971
DI 10.1007/s11042-022-14036-y
EA NOV 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000877437000001
PM 36339055
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Kalita, I
   Singh, GP
   Roy, M
AF Kalita, Indrajit
   Singh, Gyan Prakash
   Roy, Moumita
TI Crop classification using aerial images by analyzing an ensemble of
   DCNNs under multi-filter & multi-scale framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Agriculture monitoring; Aerial image; Crop classification; Deep
   convolutional neural network; Ensemble approach
ID CONVOLUTIONAL NEURAL-NETWORKS; LAND-COVER; DEEP; IDENTIFICATION; FUSION;
   FRUIT
AB The rapid collection and development of multimedia data and devices allows agricultural monitoring to be automated. Crop classification using aerial images is the challenge of identifying the appropriate crop type planted on a certain area of land. These approaches, however, have several drawbacks that may inhibit the performance owing to a lack of appropriate data and the lack sufficient investigation of automatic feature extraction techniques. To deal with this, an ensemble approach has been investigated using two different deep convolutional neural networks (DCNN), namely Multi-Filter Multi-Scale deep convolutional neural network (MFMS-DCNN) and a pre-trained Inception V3 architecture, for crop classification using aerial images. At the onset, the MFMS-DCNN is constructed using Convolution- batchnormalization-activation units along with max and average pooling layers. Here, input images have been down-sampled using the max- pooling operation instead of traditional image processing approaches which facilitates to extract the important features in multiple levels, and the feature maps are concatenated by embedding a step-by-step fusion approach. The pre-trained Inception V3 model is initially fine-tuned using the three datasets under consideration (publicly available Plant seedling, and two new aerial image datasets obtained from two regions across India.). Finally, two combiners (Mean rule and Product rule) are enforced to ensemble the outputs of MFMS-DCNN and pre-trained Inception V3, to give the final prediction. To validate the feasibility of the proposed method, experimentations have been performed on the considered datasets and with state-of-the-art techniques. The findings derived from these image datasets produce superior performance for the proposed schemes as compared to the state-of-the-art techniques. Apart from that, with average accuracy approximate to 9% to approximate to 99% for all datasets, the ensemble methods with both combiners are proven to be more efficient than the two individual proposed schemes (MFMS-DCNN and fine-tuned Inception V3).
C1 [Kalita, Indrajit; Singh, Gyan Prakash; Roy, Moumita] Indian Inst Informat Technol Guwahati, Comp Sci & Engn, Gauhati 781015, Assam, India.
RP Roy, M (corresponding author), Indian Inst Informat Technol Guwahati, Comp Sci & Engn, Gauhati 781015, Assam, India.
EM indrakalita09@gmail.com; singhprakashjnv@gmail.com;
   moumita2009.roy@gmail.com
RI kalita, Indrajit/HGB-6863-2022; Roy, Moumita/HHS-6708-2022
FU Science and Engineering Research Board, Department of Science and
   Technology, Government of India [ECR/2016/001227]
FX This work is supported by a project-grant (with file number:
   ECR/2016/001227) from Science and Engineering Research Board, Department
   of Science and Technology, Government of India.
CR Alimboyong CR, 2019, 2019 IEEE 15TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2019), P217, DOI [10.1109/cspa.2019.8696009, 10.1109/CSPA.2019.8696009]
   Amara J., 2017, Lecture Notes in Informatics (LNI), Gesellschaft fur Informatik, P79
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Biradar CM, 2011, INT J REMOTE SENS, V32, P367, DOI 10.1080/01431160903464179
   Chen SW, 2017, IEEE ROBOT AUTOM LET, V2, P781, DOI 10.1109/LRA.2017.2651944
   Cheng G, 2016, INT GEOSCI REMOTE SE, P767, DOI 10.1109/IGARSS.2016.7729193
   Chew R, 2020, DRONES-BASEL, V4, DOI 10.3390/drones4010007
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Dyrmann M., 2017, Advances in Animal Biosciences, V8, P842, DOI [DOI 10.1017/S2040470017000206, 10.1017/S2040470017000206]
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Giselsson TM., 2017, ARXIV
   Grinblat GL, 2016, COMPUT ELECTRON AGR, V127, P418, DOI 10.1016/j.compag.2016.07.003
   Hall D, 2015, IEEE WINT CONF APPL, P797, DOI 10.1109/WACV.2015.111
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, IEEE SIGNAL PROC LET, V25, P853, DOI 10.1109/LSP.2018.2809688
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Imani M, 2015, IEEE GEOSCI REMOTE S, V12, P1387, DOI 10.1109/LGRS.2015.2402167
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jia Yangqing, 2014, ARXIV14085093, DOI [10.1145/2647868.2654889, DOI 10.1145/2647868.2654889]
   Kalita Indrajit, 2020, IEEE Transactions on Artificial Intelligence, V1, P167, DOI 10.1109/TAI.2020.3043724
   Kalita Indrajit, 2019, 2019 International Conference on Information Technology (ICIT), P505, DOI 10.1109/ICIT48102.2019.00095
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kung HY, 2016, SUSTAINABILITY-BASEL, V8, DOI 10.3390/su8080735
   Kussul N, 2017, IEEE GEOSCI REMOTE S, V14, P778, DOI 10.1109/LGRS.2017.2681128
   Kuwata K, 2015, INT GEOSCI REMOTE SE, P858, DOI 10.1109/IGARSS.2015.7325900
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Liang P, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010016
   Lv Q, 2015, J SENSORS, V2015, DOI 10.1155/2015/538063
   Mandianpari M, 2018, INT GEOSCI REMOTE SE, P9249, DOI 10.1109/IGARSS.2018.8517919
   McCool C, 2017, IEEE ROBOT AUTOM LET, V2, P1344, DOI 10.1109/LRA.2017.2667039
   Milioto A, 2017, ISPRS ANN PHOTO REM, V4-2, P41, DOI 10.5194/isprs-annals-IV-2-W3-41-2017
   Mohanty S. P., 2016, Frontiers in Plant Science, V7, P1419
   Monika, 2021, Applications of Artificial Intelligence and Machine Learning: Select Proceedings of ICAAAIML 2020. Lecture Notes in Electrical Engineering (778), P289, DOI 10.1007/978-981-16-3067-5_22
   Monika, 2021, Computational Methods and Data Engineering. Proceedings of ICMDE 2020. Advances in Intelligent Systems and Computing (AISC 1227), P207, DOI 10.1007/978-981-15-6876-3_16
   Mortensen A. K., 2016, CIGR-AgEng Conference, 26-29 June 2016, Aarhus, Denmark. Abstracts and Full papers, P1
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A., 2021, Data Science and Its Applications, P63
   Niculescu S., 2018, ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VXLII-3, P1311, DOI [DOI 10.5194/ISPRS-ARCHIVES-XLII-3-1311-2018, 10.5194/isprs-archives-XLII-3-1311-2018]
   Pantazi XE, 2016, COMPUT ELECTRON AGR, V121, P57, DOI 10.1016/j.compag.2015.11.018
   Penatti Otavio A. B., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P44, DOI 10.1109/CVPRW.2015.7301382
   Postadjian T, 2018, INT GEOSCI REMOTE SE, P3623, DOI 10.1109/IGARSS.2018.8518799
   Potena C, 2017, ADV INTELL SYST COMP, V531, P105, DOI 10.1007/978-3-319-48036-7_9
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Ramos PJ, 2017, COMPUT ELECTRON AGR, V137, P9, DOI 10.1016/j.compag.2017.03.010
   Reyes A. K., 2015, CLEF (Working Notes), V1391, P467
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sameen MI, 2018, J SENSORS, V2018, DOI 10.1155/2018/7195432
   Satizabal H. F., ESANN, P515
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P1638, DOI 10.1109/LGRS.2017.2722988
   Sengupta S, 2014, BIOSYST ENG, V117, P51, DOI 10.1016/j.biosystemseng.2013.07.007
   Senthilnath J, 2016, BIOSYST ENG, V146, P16, DOI 10.1016/j.biosystemseng.2015.12.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Srensen RA, 2017, 2017 EF WCCA C, P161
   Su YX, 2017, SAUDI J BIOL SCI, V24, P537, DOI 10.1016/j.sjbs.2017.01.024
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tran TT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081601
   Wang XS, 2015, ASIAPAC SIGN INFO PR, P408
NR 69
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18409
EP 18433
DI 10.1007/s11042-022-13946-1
EA OCT 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000874060400003
DA 2024-07-18
ER

PT J
AU Khan, ZA
   Dardouri, T
   Kaaniche, M
   Dauphin, G
AF Khan, Zohaib Amjad
   Dardouri, Tassnim
   Kaaniche, Mounir
   Dauphin, Gabriel
TI NNCD-IQA: A new neural networks based compressed database for image
   quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Neural networks; Quality assessment; Subjective
   scores; Learning based metrics
ID NATURAL SCENE STATISTICS
AB Objective and subjective quality assessment is still a challenging problem in various image processing tasks. For instance, in the context of image compression, most of the conducted studies have focused on image datasets encoded using standard algorithms such as JPEG and JPEG2000. In this paper, we propose to further investigate the quality assessment issue in the presence of neural networks-based compressed images. More precisely, a new database of compressed images has been firstly built using JPEG2000 standard as well as four recent neural networks based coding schemes. Then, subjective experiments are performed to obtain the mean opinion scores of the generated distorted images. Finally, an extensive evaluation and analysis of objective image quality assessment metrics is achieved. For instance, in addition to conventional and machine learning metrics, we have considered different deep learning based models, which have been trained on our database. The new subjective database with its associated mean opinion scores as well as the learned models are publicly available at https://github.com/zakopz/NNCD-IQA-Database. The obtained results show the interest of deep learning based metrics in the context of neural networks-based compressed images.
C1 [Khan, Zohaib Amjad] Univ Paris Saclay, CentraleSupelec, L2S, F-91190 Gif Sur Yvette, France.
   [Dardouri, Tassnim; Kaaniche, Mounir; Dauphin, Gabriel] Univ Sorbonne Paris Nord, L2TI, UR 3043, F-93430 Villetaneuse, France.
C3 Universite Paris Cite; Universite Paris Saclay
RP Dardouri, T (corresponding author), Univ Sorbonne Paris Nord, L2TI, UR 3043, F-93430 Villetaneuse, France.
EM zohaib.khan@centralesupelec.fr; tasnim.dardouri@edu.univ-paris13.fr;
   mounir.kaaniche@univ-paris13.fr; gabriel.dauphin@univ-paris13.fr
OI Dardouri, Tassnim/0000-0001-5100-4747; Dauphin,
   Gabriel/0000-0002-0677-6702
CR Agustsson E, 2019, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2019.00031
   Ahanonu E, 2018, IEEE DATA COMPR CONF, P395, DOI 10.1109/DCC.2018.00048
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   [Anonymous], 2012, ITURBT50013
   Balle J, 2018, ICLR
   Balle J, 2017, 5 INT C LEARN REPR I
   Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Cheng ZX, 2019, IEEE IMAGE PROC, P719, DOI [10.1109/icip.2019.8803824, 10.1109/ICIP.2019.8803824]
   Corchs S, 2014, DIGIT SIGNAL PROCESS, V30, P86, DOI 10.1016/j.dsp.2014.04.003
   Dardouri T, 2020, IEEE IMAGE PROC, P3329, DOI 10.1109/ICIP40778.2020.9191292
   Dardouri T, 2022, IEEE T IMAGE PROCESS, V31, P569, DOI 10.1109/TIP.2021.3132825
   Ding KY, 2022, IEEE T PATTERN ANAL, V44, P2567, DOI 10.1109/TPAMI.2020.3045810
   Dumas T, 2020, IEEE T IMAGE PROCESS, V29, P679, DOI 10.1109/TIP.2019.2934565
   García-Lucas D, 2020, MULTIMED TOOLS APPL, V79, P29621, DOI 10.1007/s11042-020-09453-w
   Hajihashemi V, 2021, MULTIMED TOOLS APPL, V80, P31953, DOI 10.1007/s11042-021-11232-0
   Hammou D, 2021, IEEE COMPUT SOC CONF, P541, DOI 10.1109/CVPRW53098.2021.00066
   Jin L., 2016, Electronic Imaging, V2016, P1
   Kaaniche M, 2011, SIGNAL PROCESS, V91, P2767, DOI 10.1016/j.sigpro.2011.01.003
   Kim J, 2017, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2017.213
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Korshunov P, 2015, INT WORK QUAL MULTIM
   Laparra V, 2016, ELECT IMAG, V2016, P1
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee, 2019, INT C LEARN REPR
   Li JH, 2018, IEEE T IMAGE PROCESS, V27, P3236, DOI 10.1109/TIP.2018.2817044
   Li MH, 2018, PROC CVPR IEEE, P6644, DOI 10.1109/CVPR.2018.00695
   Liu D, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3368405
   Liu D, 2018, LECT NOTES COMPUT SC, V10705, P61, DOI 10.1007/978-3-319-73600-6_6
   Ma HC, 2020, IEEE T MULTIMEDIA, V22, P1667, DOI 10.1109/TMM.2019.2957990
   Ma SW, 2020, IEEE T CIRC SYST VID, V30, P1683, DOI 10.1109/TCSVT.2019.2910119
   Minnen D, 2017, IEEE IMAGE PROC, P2796, DOI 10.1109/ICIP.2017.8296792
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Ni ZK, 2018, IEEE T IMAGE PROCESS, V27, P4516, DOI 10.1109/TIP.2018.2839890
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Prashnani E, 2018, PROC CVPR IEEE, P1808, DOI 10.1109/CVPR.2018.00194
   Rippel O, 2017, PR MACH LEARN RES, V70
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Schiopu I, 2018, IEEE IMAGE PROC, P445, DOI 10.1109/ICIP.2018.8451731
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P1918, DOI 10.1109/TIP.2005.854492
   Shi SW, 2021, IEEE COMPUT SOC CONF, P324, DOI 10.1109/CVPRW53098.2021.00042
   Sun HM, 2020, IEEE IMAGE PROC, P3359, DOI [10.1109/icip40778.2020.9190805, 10.1109/ICIP40778.2020.9190805]
   Sun W, 2017, PATTERN RECOGN, V61, P153, DOI 10.1016/j.patcog.2016.07.033
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Testolina M, 2021, 13 INT C QUAL MULT E, P1
   Theis L., 2017, ICLR
   Todeschini G, 2017, INVENTIONS-BASEL, V2, DOI 10.3390/inventions2030014
   Valenzise G, 2018, IEEE INT WORKSH MULT
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z, 2012, ASIA PACIFIC SIGNAL, P1
   Zhang C, 2019, IEEE T IMAGE PROCESS, V28, P1732, DOI 10.1109/TIP.2018.2878326
   Zhang XF, 2019, IEEE T IMAGE PROCESS, V28, P1163, DOI 10.1109/TIP.2018.2874283
   Zhengxue Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7936, DOI 10.1109/CVPR42600.2020.00796
NR 60
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13951
EP 13971
DI 10.1007/s11042-022-13842-8
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416900001
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Shahsavani, F
   Nasiripour, R
   Shakeri, R
   Gholamrezaee, A
AF Shahsavani, Fatemeh
   Nasiripour, Reza
   Shakeri, Reza
   Gholamrezaee, Alireza
TI Arrhythmia detection based on the reduced features with K-SVD sparse
   coding algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse code; ECG; K-SVD; Feature extraction; Back propagation neural
   network
ID HEARTBEAT CLASSIFICATION; ECG; NETWORK
AB Arrhythmia is a subnormal heartbeat that causes Tachycardia or Bradycardia. ECG signal is extensively used for the analysis of heart diseases. The ECG is used to measure the rate and regularity of heartbeats. With the help of the study of the ECG signal, the presence of any damage to the heart can be identified. Arrhythmia classification is an important part of the research of medical images and signal processing. This paper aims to apply the K-SVD technique so that both the best features selected, and the accuracy of arrhythmia classification are improved. Additionally, the required space for storage has been reduced. For each ECG, we extracted 100 features of each ECG signal. Afterward, we applied statistical descriptors for extracted features which include Mean, Energy, Variance, Covariance, and Standard Deviation (S.D). The next step is the training process. We applied MLP neural networks. We have used two kinds of datasets in our research paper, UCI Machine Learning Repository and the MIT-BIH dataset. The accuracy rate of the proposed method is 98.90% and 99.14% for the UCI and MIT-BIH Dataset, respectively.
C1 [Shahsavani, Fatemeh] Payam & Noor Univ Mashhad, Dept Elect & Comp Engn, Mashhad, Razavi Khorasan, Iran.
   [Nasiripour, Reza; Gholamrezaee, Alireza] Univ Birjand, Dept Elect & Comp Engn, Birjand, Iran.
   [Shakeri, Reza] Khorasan Univ Mashhad, Dept Elect & Comp Engn, Mashhad, Razavi Khorasan, Iran.
C3 University of Birjand
RP Nasiripour, R (corresponding author), Univ Birjand, Dept Elect & Comp Engn, Birjand, Iran.
EM reza.nasiripour@birjand.ac.ir
CR Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   [Anonymous], 2011, Signal Process., Int. J.
   Aphale SS, 2021, MIDWEST SYMP CIRCUIT, P453, DOI 10.1109/MWSCAS47672.2021.9531841
   Appathurai A, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.02.040
   Arrais Junior Ernano, 2018, Res. Biomed. Eng., V34, P187, DOI 10.1590/2446-4740.01618
   Asuncion A., 2007, Uci machine learning repository
   Beritelli F, 2018, NEURAL NETWORKS, V108, P331, DOI 10.1016/j.neunet.2018.08.023
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   de Oliveira LSC, 2016, IEEE LAT AM T, V14, P1103, DOI 10.1109/TLA.2016.7459585
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Izci E, 2019, 2019 MEDICAL TECHNOLOGIES CONGRESS (TIPTEKNO), P121, DOI 10.1109/tiptekno.2019.8895011
   Jambukia SH, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P714, DOI 10.1109/ICACEA.2015.7164783
   Karimui RY, 2017, BIOCYBERN BIOMED ENG, V37, P690, DOI 10.1016/j.bbe.2017.08.005
   Khazaee A, 2014, FRONT COMPUT SCI-CHI, V8, P217, DOI 10.1007/s11704-014-2398-1
   Li PF, 2017, IEEE T BIO-MED ENG, V64, P78, DOI 10.1109/TBME.2016.2539421
   Li TY, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080285
   Liu WH, 2018, IEEE J BIOMED HEALTH, V22, P1434, DOI 10.1109/JBHI.2017.2771768
   Luz EJD, 2016, COMPUT METH PROG BIO, V127, P144, DOI 10.1016/j.cmpb.2015.12.008
   Massachusetts Institute of Technology, 2011, MIT BIH ECGDATABASE
   Mathunjwa BM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041660
   Mitra M, 2013, PROC TECH, V10, P76, DOI 10.1016/j.protcy.2013.12.339
   Nasiripour R., 2020, J SOFT COMPUT INF TE, V9, P93
   Nasiripour R, 2019, IET IMAGE PROCESS, V13, P2436, DOI 10.1049/iet-ipr.2018.6613
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Rajagopal R, 2017, BIOMED SIGNAL PROCES, V34, P1, DOI 10.1016/j.bspc.2016.12.017
   rana amrita, 2020, [Journal of Sensor Science and Technology, 센서학회지], V29, P19
   Sahoo S, 2020, INT J AUTOM COMPUT, V17, P551, DOI 10.1007/s11633-019-1219-2
   Savalia Shalin, 2018, Bioengineering (Basel), V5, DOI 10.3390/bioengineering5020035
   Sayantan G, 2018, MED BIOL ENG COMPUT, V56, P1887, DOI 10.1007/s11517-018-1815-2
   Thomas M, 2015, AEU-INT J ELECTRON C, V69, P715, DOI 10.1016/j.aeue.2014.12.013
   Tjolleng A, 2017, APPL ERGON, V59, P326, DOI 10.1016/j.apergo.2016.09.013
   Vishwanath B, 2021, J KING SAUD UNIV-COM, V33, P54, DOI 10.1016/j.jksuci.2018.02.005
   Wan MH, 2022, IEEE T CIRC SYST VID, V32, P1917, DOI 10.1109/TCSVT.2021.3090420
   Wan MH, 2021, INFORM SCIENCES, V563, P1, DOI 10.1016/j.ins.2021.02.006
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wang LD, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071502
   Xu XY, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/2102918
   Zhu WL, 2019, IEEE ACM T COMPUT BI, V16, P131, DOI 10.1109/TCBB.2018.2846611
NR 39
TC 1
Z9 1
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12337
EP 12350
DI 10.1007/s11042-022-13894-w
EA SEP 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000860416900005
DA 2024-07-18
ER

PT J
AU Ahmed, K
   Saini, M
AF Ahmed, Khalil
   Saini, Munish
TI Fog cloud-assisted IoT-based human identification in construction sites
   from gait sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait; Fog cloud computing; Human identity; Construction sites; CNN;
   SURF; SVM
ID SAFETY; RECOGNITION
AB Human identification on construction sites is critical for minimizing safety mishaps. Existing approaches have shortcomings such as a low recognition rate, workplace locating errors, and alarming latency. These challenges are addressed in this study by developing a Fog Cloud Computing, Internet of Things (IoT)-based Human Identification system based on Gait Sequences. Gait recognition, as a prospective biometric identification approach, has several advantages, including the ability to identify humans at a great distance, without any interaction, and the difficulty of imitating. However, due to the complexity of the external components involved in the collection and sampling of gait data and changes in the clothing style of an individual to be recognized, this recognition technology continues to confront several obstacles in real-time applications. In this study, the purpose is to offer a unique method for gait feature extraction and classification at construction sites. The feature vectors derived from Speeded Up Robust Features (SURF) and Convolutional Neural Networks (CNN) are integrated. The classification is performed by applying a Support Vector Machine (SVM) to increase the recognition rate at the Fog layer. The decision-making, record storage, and monitoring processing are performed in the cloud layer. On comparative analysis, experimental results demonstrate that our proposed model outperforms the existing methods and attained the highest accuracy of 97.19%.
C1 [Ahmed, Khalil; Saini, Munish] Guru Nanak Dev Univ, Dept Comp Engn & Technol, Amritsar, Punjab, India.
C3 Guru Nanak Dev University
RP Ahmed, K (corresponding author), Guru Nanak Dev Univ, Dept Comp Engn & Technol, Amritsar, Punjab, India.
EM khalilahmed@bgsbu.ac.in
RI Saini, Munish/J-4196-2016
OI Saini, Munish/0000-0003-4129-2591; Ahmed, Khalil/0000-0002-4774-5582
CR [Anonymous], 2009, UND CAUS CONSTR FAT
   [Anonymous], 2004, ADV NEURAL INFORM PR
   [Anonymous], 2017, FAT OCC INJ COUNTS R
   Anshu AK, 2020, IEEE 15 INT C IND IN, DOI [10.1109/ICIIS51140.2020.9342689, DOI 10.1109/ICIIS51140.2020.9342689]
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Batool S, 2020, IEEE ACCESS, V8, P101784, DOI 10.1109/ACCESS.2020.2998412
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boulgouris NV, 2013, IEEE T IMAGE PROCESS, V22, P3636, DOI 10.1109/TIP.2013.2266578
   Buciu I, 2016, INT J COMPUT COMMUN, V11, P315, DOI 10.15837/ijccc.2016.3.2556
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Cohen A., 1998, ASSESSING OCCUPATION
   Davis J, 2007, 24 INT C MACHINE LEA
   Elharrouss O, 2021, J SUPERCOMPUT, V77, P3653, DOI 10.1007/s11227-020-03409-5
   Fardhosseini MS, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: SAFETY, WORKFORCE, AND EDUCATION, P453, DOI 10.1061/9780784482872.049
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Heng L, 2016, SAFETY SCI, V84, P97, DOI 10.1016/j.ssci.2015.12.004
   Hussain M, 2019, ADV INTELL SYST, V840, P191, DOI 10.1007/978-3-319-97982-3_16
   Jannadi OA, 2002, BUILD ENVIRON, V37, P539, DOI 10.1016/S0360-1323(01)00056-7
   Jayanthia N., 2021, TURK J COMPUT MATH E, V12, P1723
   Jayapriya K, 2020, MULTIMED TOOLS APPL, V79, P29399, DOI 10.1007/s11042-020-09528-8
   Jin R, 2020, AUTOMAT CONSTR, V118, DOI 10.1016/j.autcon.2020.103278
   Khamsemanan N, 2018, IEEE T INF FOREN SEC, V13, P119, DOI 10.1109/TIFS.2017.2738611
   Labati Ruggero Donida, 2016, ACM Computing Surveys, V49, DOI 10.1145/2933241
   Langford D., 2000, ENG CONSTR, V7, P133, DOI DOI 10.1108/EB021138
   Liu TC, 2018, CHIN AUTOM CONGR, P3477, DOI 10.1109/CAC.2018.8623118
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Mary NAB, 2018, MULTIMED TOOLS APPL, V77, P31545, DOI 10.1007/s11042-018-6148-5
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   McCann M, 2003, AM J IND MED, V43, P398, DOI 10.1002/ajim.10198
   Nandyala C., 2016, Internation Journal of Smart Homes, V10, P187, DOI [DOI 10.14257/IJSH.2016.10.2.18, 10.14257/ijsh.2016.10.2.18]
   Ng H, 2011, COMM COM INF SC, V179, P623
   Pedersen JT, 2011, STUD GROUP SURF FEAT
   Pradhan N, 2020, MACHINE LEARNING COG, P1
   Rida I, 2019, IET BIOMETRICS, V8, P14, DOI 10.1049/iet-bmt.2018.5063
   Saleem F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21227584
   Seifert AK, 2019, IEEE T BIO-MED ENG, V66, P2629, DOI 10.1109/TBME.2019.2893528
   Shapira A, 2012, J CONSTR ENG M, V138, P1281, DOI 10.1061/(ASCE)CO.1943-7862.0000537
   Sharma S, 2020, MACHINE LEARNING ENH, P95
   Son H, 2019, AUTOMAT CONSTR, V99, P27, DOI 10.1016/j.autcon.2018.11.033
   Törner M, 2009, J SAFETY RES, V40, P399, DOI 10.1016/j.jsr.2009.09.005
   Umeokafor N., 2014, Developing Country Studies, V4, P119
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Zhou ZP, 2012, J CONSTR ENG M ASCE, V138, P1169, DOI 10.1061/(ASCE)CO.1943-7862.0000518
NR 44
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14265
EP 14285
DI 10.1007/s11042-022-13785-0
EA SEP 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000857279500002
DA 2024-07-18
ER

PT J
AU Yan, YP
   Zhang, HJ
   Du, SL
   Ma, YD
AF Yan, Yaping
   Zhang, Hongjuan
   Du, Songlin
   Ma, Yide
TI Bi-SCM: bidirectional spiking cortical model with adaptive unsharp
   masking for mammography image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital mammography; Image enhancement; Unsharp masking; Bidirectional
   spiking cortical model (Bi-SCM); Image fusion
ID HISTOGRAM EQUALIZATION; FUSION; PERFORMANCE; WAVELET
AB Mammography technique is commonly used for diagnosing breast cancer, but mammography images usually show low contrast which cause difficulties to clinical diagnosis. Therefore, improving the visual quality of mammography images is an important issue. This is a challenging problem, because every mammography image consists of rich textures, including bright areas, dark areas, and textural details. Inspired by bio-inspired neural network, this paper proposes a Bidirectional Spiking Cortical Model (Bi-SCM) from the perspective of neural information fusion to enhance the contrast of bright areas and dark areas adequately, as well as textural details. This goal is achieved by utilizing the Bi-SCM to first enhance a mammography image and its inverse separately. The enhanced results are fused by a new fusion algorithm based on non-subsampled contourlet transform (NSCT) to ensure that both of the contrast of bright areas and dark areas are adequately improved. The textual details are then enhanced by an unsharp masking method which consists of cubic filter and log-ratio operation. Sufficient experiments on mammography images are conducted to evaluate the proposed approach. Experimental results show that the proposed method outperforms state-of-the-art methods on both enhancing contrast and details. Besides, over-enhancement and noise sensitivity are also significantly suppressed.
C1 [Yan, Yaping] Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China.
   [Zhang, Hongjuan; Ma, Yide] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Peoples R China.
   [Du, Songlin] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
   [Du, Songlin] Hubei Key Lab Adv Control & Intelligent Automat C, Wuhan 430074, Peoples R China.
   [Du, Songlin] Minist Educ, Engn Res Ctr Intelligent Geodetect Technol, Wuhan 430074, Peoples R China.
C3 Southeast University - China; Lanzhou University; Southeast University -
   China
RP Yan, YP (corresponding author), Southeast Univ, Sch Comp Sci & Engn, Nanjing 210096, Peoples R China.
EM yan@seu.edu.cn
RI zhang, hui/GXH-6098-2022
FU National Natural Science Foundation of China [62001110]; Natural Science
   Foundation of Jiangsu Province [BK20200353]; 111 Project [B17040]
FX This work was jointly supported by the National Natural Science
   Foundation of China under grant 62001110, the Natural Science Foundation
   of Jiangsu Province under grant BK20200353, andthe 111 Project under
   grant B17040.
CR Agaian SS, 2001, IEEE T IMAGE PROCESS, V10, P367, DOI 10.1109/83.908502
   Bhatnagar G, 2013, IEEE T MULTIMEDIA, V15, P1014, DOI 10.1109/TMM.2013.2244870
   Celik T, 2012, IEEE T IMAGE PROCESS, V21, P145, DOI 10.1109/TIP.2011.2162419
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Diwakar Manoj, 2020, International Journal of Information and Computer Security, V12, P234
   Diwakar M, 2019, SOFT COMPUTING THEOR, V742
   Diwakar M, 2019, HDB MULTIMEDIA INFOR, P501, DOI [10.1007/978-3-030-15887-3_24, DOI 10.1007/978-3-030-15887-3_24]
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Diwakar M, 2015, PROCEEDING OF THE THIRD INTERNATIONAL SYMPOSIUM ON WOMEN IN COMPUTING AND INFORMATICS (WCI-2015), P297, DOI 10.1145/2791405.2791430
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Eltoukhy MM, 2010, COMPUT BIOL MED, V40, P384, DOI 10.1016/j.compbiomed.2010.02.002
   Fechner G. T., 1860, Elemente der Psychophysik
   Gao XB, 2010, IEEE T INF TECHNOL B, V14, P266, DOI 10.1109/TITB.2009.2036167
   Ghita O, 2013, IEEE T IMAGE PROCESS, V22, P3133, DOI 10.1109/TIP.2013.2259839
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   Heath M, 2001, IWDM 2000: 5TH INTERNATIONAL WORKSHOP ON DIGITAL MAMMOGRAPHY, P212
   Hu K, 2011, IEEE T INSTRUM MEAS, V60, P462, DOI 10.1109/TIM.2010.2051060
   Jung SW, 2014, IEEE SIGNAL PROC LET, V21, P382, DOI 10.1109/LSP.2014.2303157
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lakshmanan R, 2012, 2012 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC), P14, DOI 10.1109/ICACC.2012.4
   Lu Z, 2007, PROC SPIE, V6534, DOI 10.1117/12.741340
   Ma Yi-de, 2012, Journal of Beijing University of Posts and Telecommunications, V35, P70
   Mai C. L. D. A., 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P646, DOI 10.1109/CISP.2011.6100322
   Panetta K, 2011, IEEE T INF TECHNOL B, V15, P918, DOI 10.1109/TITB.2011.2164259
   Petrovic V, 2007, INFORM FUSION, V8, P208, DOI 10.1016/j.inffus.2005.05.001
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Qu GH, 2001, OPT EXPRESS, V9, P184, DOI 10.1364/OE.9.000184
   Qu Xiao-bo, 2009, Optics and Precision Engineering, V17, P1203
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Ramponi G, 1998, SIGNAL PROCESS, V67, P211, DOI 10.1016/S0165-1684(98)00038-3
   Ramponi G, 1998, J ELECTRON IMAGING, V7, P333, DOI 10.1117/1.482649
   Ranganath H. S., 1995, Proceedings IEEE Southeastcon '95. Visualize the Future (Cat. No.95CH35793), P37, DOI 10.1109/SECON.1995.513053
   Sheet D, 2010, IEEE T CONSUM ELECTR, V56, P2475, DOI 10.1109/TCE.2010.5681130
   Stewart DE, 2001, PSYCHO-ONCOLOGY, V10, P179, DOI 10.1002/pon.497
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Sun XD, 2013, C IND ELECT APPL, P1610
   TOET A, 1989, OPT ENG, V28, P789, DOI 10.1117/12.7977034
   Wang ZB, 2008, INFORM FUSION, V9, P176, DOI 10.1016/j.inffus.2007.04.003
   Xiaoling Xiao, 2010, 2010 2nd International Conference on Industrial Mechatronics and Automation (ICIMA 2010), P349, DOI 10.1109/ICINDMA.2010.5538297
   Xing S-X, 2010, INT C SIGN PROC SYST, pV1
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhan K, 2009, IEEE T NEURAL NETWOR, V20, P1980, DOI 10.1109/TNN.2009.2030585
NR 47
TC 1
Z9 1
U1 5
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12081
EP 12098
DI 10.1007/s11042-022-13766-3
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000858393000008
DA 2024-07-18
ER

PT J
AU Kapoor, S
   Kumar, T
AF Kapoor, Shalini
   Kumar, Tarun
TI A novel approach to detect instant emotion change through spectral
   variation in single frequency filtering spectrogram of each pitch cycle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion change detection; Single-frequency filtering; glottal signal;
   SFF spectrogram; Glottal closure instant; Convolutional neural network
ID FUNDAMENTAL-FREQUENCY; SPEECH; FEATURES; EXTRACTION
AB The intelligent human-computer interface should not only provide automatic emotion inference, but it should also provide information about emotion change. The former has generated promising results, whilst the latter is currently being researched. Emotional transformation, or a quick change in one's emotional state, is a normal part of life that can be triggered by mental stress, ongoing situations, or people we connect with. To better control these emotions, it's vital to recognize triggers and early warning signs of imminent emotional swings. The Single frequency filtering (SFF) spectrogram is a visual representation of voice that captures both temporal and frequency resolutions at the same time. In this study, convolutional neural network (CNN) EfficientNetB0 is used to study patterns in SFF spectrogram for localizing the instants of emotion change. The process used in detecting the instant of emotion change detection could be broken into two stages. First stage deals with the construction of SFF spectrograms from speech samples belonging to each pitch cycle. Second stage deals with predicting the time when emotional changes occur. The performance of the proposed method is evaluated using parameters binary accuracy (BAC), binary cross-entropy loss (BECL), binary error (BError), and F1-Score. The proposed method obtains an accuracy of 0.95 and 0.952 on the datasets used. The experimental results obtained using the proposed method on Interactive emotional dyadic motion capture(IEMOCAP) and Ryerson Audio-Visual Database of Emotional Speech and Song (RAVDESS) datasets establish the supremacy of the proposed method on existing methods and other CNN architectures.
C1 [Kapoor, Shalini] Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.
   [Kapoor, Shalini] KIET Grp Inst, Dept CSE, Ghaziabad, India.
   [Kumar, Tarun] Dewan VS Grp Inst, Dept Comp Sci, Meerut, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); KIET Group of
   Institutions
RP Kapoor, S (corresponding author), Dr APJ Abdul Kalam Tech Univ, Lucknow, Uttar Pradesh, India.; Kapoor, S (corresponding author), KIET Grp Inst, Dept CSE, Ghaziabad, India.
EM shalini_kapoor311@rediffmail.com
RI Kumar, Tarun/T-8152-2018
OI Kumar, Tarun/0000-0001-6011-8498; Kumar, Tarun/0000-0001-5033-5544
CR Abbaschian BJ, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041249
   Alisamir S, 2021, IEEE SIGNAL PROC MAG, V38, P12, DOI 10.1109/MSP.2021.3106890
   Altun H, 2009, EXPERT SYST APPL, V36, P8197, DOI 10.1016/j.eswa.2008.10.005
   Aneeja G, 2017, IEEE-ACM T AUDIO SPE, V25, P829, DOI 10.1109/TASLP.2017.2666425
   Aneeja G, 2015, IEEE-ACM T AUDIO SPE, V23, P705, DOI 10.1109/TASLP.2015.2404035
   Badshah AM, 2019, MULTIMED TOOLS APPL, V78, P5571, DOI 10.1007/s11042-017-5292-7
   Bakhshi A, 2022, SPEECH COMMUN, V139, P62, DOI 10.1016/j.specom.2022.02.007
   Ben-Ze'ev A, 2003, COMPUT HUM BEHAV, V19, P451, DOI 10.1016/S0747-5632(02)00078-X
   Busso C, 2009, IEEE T AUDIO SPEECH, V17, P582, DOI 10.1109/TASL.2008.2009578
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cowie R, 2003, SPEECH COMMUN, V40, P5, DOI 10.1016/S0167-6393(02)00071-7
   Davidson RJ, 1998, COGNITION EMOTION, V12, P307, DOI 10.1080/026999398379628
   Fredrickson BL, 2000, MOTIV EMOTION, V24, P237, DOI 10.1023/A:1010796329158
   Gupta S, 2020, MULTIMED TOOLS APPL, V79, P23347, DOI 10.1007/s11042-020-09068-1
   Huang ZC, 2015, INT CONF AFFECT, P733, DOI 10.1109/ACII.2015.7344650
   Huang ZW, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P801, DOI 10.1145/2647868.2654984
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jiang W, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19122730
   Kadiri SR, 2019, J ACOUST SOC AM, V146, P4446, DOI 10.1121/1.5139225
   Kadiri SR, 2017, SPEECH COMMUN, V86, P52, DOI 10.1016/j.specom.2016.11.005
   Kim Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P92, DOI 10.1145/2993148.2993151
   Krishnan PT, 2021, COMPLEX INTELL SYST, V7, P1919, DOI 10.1007/s40747-021-00295-z
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Meng H, 2019, IEEE ACCESS, V7, P125868, DOI 10.1109/ACCESS.2019.2938007
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Nam Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134399
   Sezgin MC, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-16
   Suveg C, 2009, J CLIN CHILD ADOLESC, V38, P390, DOI 10.1080/15374410902851721
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wani TM, 2021, IEEE ACCESS, V9, P47795, DOI 10.1109/ACCESS.2021.3068045
   Zhang J, 2018, J PSYCHIATR RES, V98, P59, DOI 10.1016/j.jpsychires.2017.12.012
   Zhao JF, 2019, BIOMED SIGNAL PROCES, V47, P312, DOI 10.1016/j.bspc.2018.08.035
   Zheng WQ, 2015, INT CONF AFFECT, P827, DOI 10.1109/ACII.2015.7344669
   Zhu J, 2002, PHILOS PSYCHOL, V15, P19, DOI 10.1080/09515080120109397
NR 35
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9413
EP 9429
DI 10.1007/s11042-022-13731-0
EA SEP 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000852138100002
DA 2024-07-18
ER

PT J
AU Kaur, AP
   Singh, A
   Sachdeva, R
   Kukreja, V
AF Kaur, Amrit Preet
   Singh, Amitoj
   Sachdeva, Rohit
   Kukreja, Vinay
TI Automatic speech recognition systems: A survey of discriminative
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech recognition; Acoustic modeling; Feature extraction; Deep
   learning; Speech processing
ID CONVOLUTIONAL NEURAL-NETWORKS; ACOUSTIC MODELS; SPEAKER; HINDI;
   ARCHITECTURE; LANGUAGES; ACCURATE; FEATURES
AB In the subject of pattern recognition, speech recognition is an important study topic. The authors give a detailed assessment of voice recognition strategies for several majority languages in this study. Over the last several decades, many researchers have contributed to the field of voice processing and recognition. Although there are several frameworks for speech processing and recognition, there are only a few ASR systems available for language recognition throughout the world. However, the data gathered for this research reveals that the bulk of the effort has been done to construct ASR systems for majority languages, whereas minority languages suffer from a lack of standard speech corpus. We also looked at some of the key issues for voice recognition in various languages in this research. We have explored various kinds of hybrid acoustic modeling methods required for efficient results. Because the success of a classifier is dependent on the removal of information during the feature separation phase, it is critical to carefully pick the value extraction techniques and classifiers.
C1 [Kaur, Amrit Preet] Punjabi Univ, Patiala, Punjab, India.
   [Singh, Amitoj] Jagat Guru Nanak Dev Punjab State Open Univ, Patiala, Punjab, India.
   [Sachdeva, Rohit] Multani Mal Modi Coll, Patiala, Punjab, India.
   [Kukreja, Vinay] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Punjabi University; Chitkara University, Punjab
RP Singh, A (corresponding author), Jagat Guru Nanak Dev Punjab State Open Univ, Patiala, Punjab, India.
EM amitoj.pb@gmail.com; onlyvinaykukreja@gmail.com
RI Kukreja, Vinay/AAT-7893-2021; SACHDEVA, ROHIT/ABT-0297-2022
OI Kukreja, Vinay/0000-0002-9760-0824; SACHDEVA, ROHIT/0000-0003-4309-5284;
   Singh, amitoj/0000-0002-5884-3145
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Abushariah M. A. M., 2010, Computer and Communication Engineering (ICCCE), 2010 International Conference on, P1
   Al Mojaly M, 2014, I C COMP SYST APPLIC, P571, DOI 10.1109/AICCSA.2014.7073250
   Ali A., 2021, arXiv
   Ali A, 2014, IEEE W SP LANG TECH, P525, DOI 10.1109/SLT.2014.7078629
   Amodei D, 2016, PR MACH LEARN RES, V48
   Amrous AI, 2011, INT J SPEECH TECHNOL, V14, P351, DOI 10.1007/s10772-011-9113-5
   [Anonymous], 2011, P INT C FLOR IT 27 3, DOI DOI 10.5555/3042573.3042574
   [Anonymous], 2006, Multilingual speech processing
   Ardila R., 2019, arXiv
   Baccouche Moez, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5422, DOI 10.1109/ICASSP.2014.6854639
   Badino L, 2016, COMPUT SPEECH LANG, V36, P173, DOI 10.1016/j.csl.2015.05.005
   Bahl L. R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P49
   Baker JM, 2009, IEEE SIGNAL PROC MAG, V26, P75, DOI 10.1109/MSP.2009.932166
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Beck E, 2018, INTERSPEECH, P766, DOI 10.21437/Interspeech.2018-1212
   Benzeghiba M, 2007, SPEECH COMMUN, V49, P763, DOI 10.1016/j.specom.2007.02.006
   Berard A, 2016, ARXIV
   Bhuriyakorn P, 2008, PROCEEDINGS OF NINTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING, P475, DOI 10.1109/SNPD.2008.73
   Biagetti G, 2018, SMART INNOV SYST TEC, V73, P43, DOI 10.1007/978-3-319-59424-8_5
   Botros R, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1443
   Bouchakour L, 2018, INT J CIRCUITS SYSTE, V12, P1
   Bourlard H., 2012, Connectionist speech recognition: a hybrid approach, V247
   Boyer F, 2019, ARXIV
   Burget L, 2010, INT CONF ACOUST SPEE, P4334, DOI 10.1109/ICASSP.2010.5495646
   Cai M, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P291, DOI 10.1109/ASRU.2013.6707745
   Chaloupka Josef, 2015, 2015 38th International Conference on Telecommunications and Signal Processing (TSP), P1, DOI 10.1109/TSP.2015.7296399
   Chao Weng, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5532, DOI 10.1109/ICASSP.2014.6854661
   Chen NF, 2016, SPEECH COMMUN, V84, P46, DOI 10.1016/j.specom.2016.07.005
   Chen W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P319, DOI 10.1109/CISP.2008.492
   Cheng H, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P2772
   Chien JT, 2006, IEEE T AUDIO SPEECH, V14, P797, DOI 10.1109/TSA.2005.860847
   Choopanya P, 2016, 2016 INTERNATIONAL CONFERENCE ON POWER, ENERGY ENGINEERING AND MANAGEMENT (PEEM 2016), P232, DOI 10.1109/ICSDA.2016.7919017
   Das T., 2016, INDIAN J SCI TECHNOL, V9
   Deemagarn A, 2004, P INT C SPEECH COMP, P731
   Desai N., 2013, Int J Emerg Technol Adv Eng, V3, P367
   Dey A, 2018, INTERSPEECH, P1036
   Dey A, 2017, 2017 IEEE 7TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP)
   Dhonde SB, 2016, INT J COMPUT APPL, V134
   Djemili R., 2012, 2012 International Conference on Multimedia Computing and Systems (ICMCS), P184, DOI 10.1109/ICMCS.2012.6320122
   Draman M, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOIC7), DOI 10.1109/ICoICT.2017.8074675
   Dua M., 2012, INT J COMPUT SCI ISS, V9, P359
   Dua M., 2012, 4 INT C ADV REC TECH, P206, DOI DOI 10.1049/CP.2012.2528
   Dua M, 2019, NEURAL COMPUT APPL, V31, P6747, DOI 10.1007/s00521-018-3499-9
   Dua M, 2019, J AMB INTEL HUM COMP, V10, P2301, DOI 10.1007/s12652-018-0828-x
   Emami A, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, VOLS 1 AND 2, P147, DOI 10.1109/ASRU.2007.4430100
   Enarvi S, 2017, IEEE-ACM T AUDIO SPE, V25, P2085, DOI 10.1109/TASLP.2017.2743344
   Fantaye TG, 2020, COMPUTERS, V9, DOI 10.3390/computers9020036
   Fauziya F., 2014, INT J COMPUTER APPL, V98, P12, DOI [10.5120/17186-7366, DOI 10.5120/17186-7366]
   Fook C. Y., 2012, 2012 International Conference on Biomedical Engineering (ICoBE), P479, DOI 10.1109/ICoBE.2012.6179063
   Furui S, 2012, IEICE T INF SYST, VE95D, P1182, DOI 10.1587/transinf.E95.D.1182
   Gales MJF, 1998, COMPUT SPEECH LANG, V12, P75, DOI 10.1006/csla.1998.0043
   Gawali BW, 2011, ACEEE INT J INFORM T, V1, P21
   Gehring J, 2017, PR MACH LEARN RES, V70
   Georgescu A, 2017, 2017 INT C SPEECH TE, P1
   Georgescu AL, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6606
   Gergen S., 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P154, DOI 10.1109/ICSPCC.2012.6335733
   Gevaert W., 2010, Journal of Automatic Control, V20, P1, DOI 10.2298/jac1001001g
   Gonzalez-Dominguez J, 2015, IEEE J-STSP, V9, P749, DOI 10.1109/JSTSP.2014.2364559
   Gupta A, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P170, DOI 10.1109/ISSP.2013.6526896
   Hammami N, 2010, INT CONF COMP SCI, P521, DOI 10.1109/ICCSIT.2010.5563892
   Hanani A, 2013, COMPUT SPEECH LANG, V27, P59, DOI 10.1016/j.csl.2012.01.003
   Hoffineister B, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING, VOLS 1 AND 2, P455, DOI 10.1109/ASRU.2007.4430155
   Hori T, 2017, COMPUT SPEECH LANG, V46, P401, DOI 10.1016/j.csl.2017.01.013
   Hu Xianbiao., 2014, Transportation Research Board 93rd Annual Meeting Compendium of Papers, P1
   Huang H.Y., 2017, ARXIV
   Huang H, 2017, J ACOUST SOC AM, V142, P3165, DOI 10.1121/1.5011159
   Huang YM, 2019, J AMB INTEL HUM COMP, V10, P1787, DOI 10.1007/s12652-017-0644-8
   Huet S, 2010, COMPUT SPEECH LANG, V24, P663, DOI 10.1016/j.csl.2009.10.001
   Hwang MY, 2009, IEEE T AUDIO SPEECH, V17, P1253, DOI 10.1109/TASL.2009.2014263
   Ircing P., 2001, 7 EUR C SPEECH COMM
   Jamal N, 2017, AIP CONF PROC, V1883, DOI 10.1063/1.5002046
   Joshi R, 2021, ACM INT CONF PR SER, P107, DOI 10.1145/3503162.3503173
   Kadyan V, 2018, IETE J RES, V64, P673, DOI 10.1080/03772063.2017.1369370
   Kantithammakorn P, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22041583
   Karafiat Martin, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P5622, DOI 10.1109/ICASSP.2014.6854679
   Karpov Alexey, 2013, Universal Access in Human-Computer Interaction. Design Methods, Tools, and Interaction Techniques for eInclusion. 7th International Conference, UAHCI 2013 Held as Part of HCI International 2013. Proceedings. LNCS 8009, P520, DOI 10.1007/978-3-642-39188-0_56
   Karpov A, 2014, SPEECH COMMUN, V56, P213, DOI 10.1016/j.specom.2013.07.004
   Karpov A, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P3168
   Kaur J, 2021, ARCH COMPUT METHOD E, V28, P1039, DOI 10.1007/s11831-020-09414-4
   Khelifa MOM, 2017, INT J SPEECH TECHNOL, V20, P937, DOI 10.1007/s10772-017-9456-7
   Kipyatkova I, 2012, FED CONF COMPUT SCI, P719
   Kitchenham BA, 2007, IEEE T SOFTWARE ENG, V33, P316, DOI 10.1109/TSE.2007.1101
   Kothapalli V, 2018, 2018 15 IEEE INDIA C, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo H-K J., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P208, DOI 10.1109/ASRU.2011.6163932
   Kurian Cini, 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), P1475, DOI 10.1109/NABIC.2009.5393692
   Larson M., 2003, P EUROSPEECH 2003, P1217
   Le H, 2021, INT C ONSPOKEN LANGU
   Lee SC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072068
   Lei X, 2016, GOOGLE PATENTS
   Li JY, 2012, IEEE W SP LANG TECH, P131, DOI 10.1109/SLT.2012.6424210
   Li XG, 2015, NEUROCOMPUTING, V170, P251, DOI 10.1016/j.neucom.2014.07.087
   Li XG, 2015, INT CONF ACOUST SPEE, P4520, DOI 10.1109/ICASSP.2015.7178826
   Liang S, 2022, MULTIMED TOOLS APPL
   Liao J., 2020, ARXIV
   Liu G, 2010, EUR SIGNAL PR CONF, P2003
   Liu Y, 2006, LECT NOTES COMPUT SC, V4274, P724
   Ljubesic N, 2012, P 8 INFORM SOC LANGU, P117
   Ljubesic N., 2015, INFORMATICA, V39
   Lopez-Moreno I, 2016, COMPUT SPEECH LANG, V40, P46, DOI 10.1016/j.csl.2016.03.001
   Maas AL, 2017, COMPUT SPEECH LANG, V41, P195, DOI 10.1016/j.csl.2016.06.007
   Maekawa K., 2003, ISCA IEEE WORKSH SPO, P7
   Maseri M, 2019, LECT NOTES ELECTR EN, V481, P205, DOI 10.1007/978-981-13-2622-6_21
   Maurya A, 2018, PROCEDIA COMPUT SCI, V125, P880, DOI 10.1016/j.procs.2017.12.112
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Milde B., 2018, SPEECH COMMUN, P1
   Mohan B. Jagan, 2014, Proceedings of the IEEE 27th Canadian Conference on Electrical and Computer Engineering (CCECE), P1
   Moncy Ashana Mariam, 2020, 2020 IEEE Recent Advances in Intelligent Computational Systems (RAICS), P170, DOI 10.1109/RAICS51191.2020.9332493
   Moore AH, 2017, COMPUT SPEECH LANG, V46, P574, DOI 10.1016/j.csl.2016.11.003
   Mukhamadiyev A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103683
   Najkar N, 2010, MATH COMPUT MODEL, V52, P1910, DOI 10.1016/j.mcm.2010.03.041
   Nakamura S, 2006, IEEE T AUDIO SPEECH, V14, P365, DOI 10.1109/TSA.2005.860774
   Nguyen BA, 2019, ARXIV
   Noda K, 2014, INTERSPEECH, P1149
   Normandin Y, 1994, IEEE T SPEECH AUDI P, V2, P299, DOI 10.1109/89.279279
   Nouza J, 2013, RADIOENGINEERING, V22, P866
   Nouza J, 2010, LECT NOTES COMPUT SC, V5967, P225
   Ouisaadane A., 2020, TELKOMNIKA, V18, P2193, DOI [10.12928/telkomnika.v18i4.14215, DOI 10.12928/TELKOMNIKA.V18I4.14215]
   Pan J, 2012, 2012 8TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING, P301, DOI 10.1109/ISCSLP.2012.6423452
   Patil UG, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTING, ANALYTICS AND SECURITY TRENDS (CAST), P433, DOI 10.1109/CAST.2016.7915008
   Paul AK, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P171, DOI 10.1109/ICAPR.2009.80
   Peddinti V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3214
   Hung PD, 2019, INT J ADV COMPUT SC, V10, P194
   Plahl C., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P371, DOI 10.1109/ASRU.2011.6163960
   Plahl C, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2426
   Quang Trung Nguyen, 2016, Vietnam Journal of Computer Science, V3, P247, DOI 10.1007/s40595-016-0071-3
   Radeck-Arneth S, 2015, LECT NOTES ARTIF INT, V9302, P480, DOI 10.1007/978-3-319-24033-6_54
   Rahman FD, 2014, 2014 THIRD ICT INTERNATIONAL STUDENT PROJECT CONFERENCE (ICT-ISPC), P79, DOI 10.1109/ICT-ISPC.2014.6923222
   Razavi M, 2016, SPEECH COMMUN, V80, P1, DOI 10.1016/j.specom.2016.03.003
   Richardson F, 2015, IEEE SIGNAL PROC LET, V22, P1671, DOI 10.1109/LSP.2015.2420092
   Rosdi F, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING, VOLS 1-3, P721, DOI 10.1109/ICCCE.2008.4580699
   Sailor HB, 2016, IEEE-ACM T AUDIO SPE, V24, P2341, DOI 10.1109/TASLP.2016.2607341
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Sainath TN, 2015, 2008 INT C COMPUTER, P721
   Sak H, 2012, IEEE T AUDIO SPEECH, V20, P2341, DOI 10.1109/TASL.2012.2201477
   Salam MSH, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P731, DOI 10.1109/ISSPA.2001.950252
   Saon G, 2012, IEEE T AUDIO SPEECH, V20, P43, DOI 10.1109/TASL.2011.2129911
   Saon G, 2010, INT CONF ACOUST SPEE, P4378, DOI 10.1109/ICASSP.2010.5495640
   Schiopu D, 2014, 2014 INTERNATIONAL CONFERENCE ON DEVELOPMENT AND APPLICATION SYSTEMS (DAS), P165, DOI 10.1109/DAAS.2014.6842448
   Seltzer ML, 2013, INT CONF ACOUST SPEE, P7398, DOI 10.1109/ICASSP.2013.6639100
   Seman Noraini, 2010, Proceedings of 2010 International Symposium on Information Technology (ITSim 2010), P1628, DOI 10.1109/ITSIM.2010.5561618
   Seman N, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P59, DOI 10.1109/ICACTE.2008.150
   Sertsi P, 2021, 2021 18 INT JOINT C, P1
   Siivola V, 2001, INTERSPEECH, P737
   Siniscalchi SM, 2009, SPEECH COMMUN, V51, P1139, DOI 10.1016/j.specom.2009.05.004
   Skowronski MD, 2003, P 2003 INT S CIRCUIT, V4, pIV
   Smit P, 2017, INTERSPEECH, P2551, DOI 10.21437/Interspeech.2017-103
   SODANIL M, 2010, P 10 INT C INN INT C, P247
   Spille C, 2018, COMPUT SPEECH LANG, V48, P51, DOI 10.1016/j.csl.2017.10.004
   Sukvichai K, 2021, 2021 SECOND INTERNATIONAL SYMPOSIUM ON INSTRUMENTATION, CONTROL, ARTIFICIAL INTELLIGENCE, AND ROBOTICS (ICA-SYMP), P108, DOI 10.1109/ICA-SYMP50206.2021.9358451
   Swietojanski P, 2014, IEEE SIGNAL PROC LET, V21, P1120, DOI 10.1109/LSP.2014.2325781
   Theera-Umpon N, 2011, EXPERT SYST APPL, V38, P13254, DOI 10.1016/j.eswa.2011.04.142
   Tong SB, 2016, INT CONF ACOUST SPEE, P5695, DOI 10.1109/ICASSP.2016.7472768
   Valente F, 2010, INTERSPEECH
   Vazhenina D., 2011, 2011 7th International Conference on Natural Language Processing and Knowledge Engineering (NLPKE), P475, DOI 10.1109/NLPKE.2011.6138246
   Vegesna Vishnu Vidyadhara Raju, 2017, Mining Intelligence and Knowledge Exploration. 5th International Conference, MIKE 2017. Proceedings: LNAI 10682, P189, DOI 10.1007/978-3-319-71928-3_19
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Vesely K, 2012, IEEE W SP LANG TECH, P336, DOI 10.1109/SLT.2012.6424246
   Wahyuni ES, 2017, 2017 2ND INTERNATIONAL CONFERENCES ON INFORMATION TECHNOLOGY, INFORMATION SYSTEMS AND ELECTRICAL ENGINEERING (ICITISEE), P22, DOI 10.1109/ICITISEE.2017.8285499
   Wang D, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11081018
   Wang YQ, 2020, INT CONF ACOUST SPEE, P6874, DOI [10.1109/ICASSP40776.2020.9054345, 10.1109/icassp40776.2020.9054345]
   Watanabe S, 2017, IEEE J-STSP, V11, P1240, DOI 10.1109/JSTSP.2017.2763455
   Wei Zou, 2018, 2018 11th International Symposium on Chinese Spoken Language Processing (ISCSLP). Proceedings, P369, DOI 10.1109/ISCSLP.2018.8706661
   Weninger F, 2014, ARXIV
   Yang D, 2012, COMPUT SPEECH LANG, V26, P321, DOI 10.1016/j.csl.2011.12.002
   Ying WY, 2020, FRONT COMPUT SCI-CHI, V14, P378, DOI 10.1007/s11704-018-8030-z
   Zerari N, 2019, OPEN COMPUT SCI, V9, P92, DOI 10.1515/comp-2019-0004
   Zhai L., 2004, P HLT NAACL, P37
   Zhang XH, 2021, IEEE W SP LANG TECH, P46, DOI 10.1109/SLT48900.2021.9383623
   Zhang Y., 2017, ARXIV
   Zhao F, 2000, 6 INT C SPOKEN LANGU
   Ziehe S., 2021, P 1 WORKSHOP LANGUAG, P132
NR 173
TC 4
Z9 4
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13307
EP 13339
DI 10.1007/s11042-022-13645-x
EA SEP 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000852127600006
DA 2024-07-18
ER

PT J
AU Luo, S
   Li, XF
   Zhang, XL
AF Luo, Shi
   Li, Xiongfei
   Zhang, Xiaoli
TI Wide aspect ratio matching for robust face detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Anchor matching; Feature enhancement; Deep learning;
   Convolutional neural network
AB Recently, anchor-based methods have achieved great progress in face detection. They adopt standard anchor matching strategy to sample positive anchors according to predefined IoU threshold. However, the max IoUs of extreme aspect ratio faces are still lower than fixed positive threshold, leading to the sampling failure from these faces. To construct a more robust detection model, more positive anchors from extreme aspect ratio faces need to be sampled and participate in the training phase. The goal of the present research is to improve the detection performance by reasonably extending sampling range of face aspect ratio. In this paper, we firstly explore the factors that affect the max IoU of each face in theory. Then, anchor matching simulation is performed to evaluate the sampling range of face aspect ratio. Finally, we propose a Wide Aspect Ratio Matching (WARM) strategy to collect more representative positive anchors from ground-truth faces across a wide range of aspect ratios. Besides, we present a novel feature enhancement module, named Receptive Field Diversity (RFD) module, to provide diverse receptive field corresponding to different aspect ratios. Extensive experiments have been conducted on popular benchmarks to show the effectiveness of our method, which can help detectors better capture extreme aspect ratio faces. Our method achieves promising APs on WIDER FACE validation dataset (easy: 0.965, medium: 0.955, hard: 0.904) and impressive generalization capability on FDDB dataset.
C1 [Luo, Shi; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Luo, Shi; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Zhang, XL (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.; Zhang, XL (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM zhangxiaoli@jlu.edu.cn
RI Zhang, Xiaoli/ABC-2210-2021
OI Luo, Shi/0000-0001-5334-0453
FU National Natural Science Foundation of China [61801190]; National Key
   Research and Development Project of China [2019YFC0409105]; Nature
   Science Foundation of Jilin Province [20180101055JC]; Industrial
   Technology Research and Development Funds of Jilin Province
   [2019C054-3]; "Thirteenth Five-Year Pla" Scientific Research Planning
   Project of Education Department of Jilin Province [JKH20200678KJ,
   JJKH20200997KJ]; Fundamental Research Funds for the Central
   Universities, JLU
FX The work was supported in part by the National Natural Science
   Foundation of China under Grant 61801190, in part by the National Key
   Research and Development Project of China under Grant 2019YFC0409105, in
   part by the Nature Science Foundation of Jilin Province under Grant
   20180101055JC, in part by the Industrial Technology Research and
   Development Funds of Jilin Province under Grant 2019C054-3, in part by
   the "Thirteenth Five-Year Pla" Scientific Research Planning Project of
   Education Department of Jilin Province (JKH20200678KJ,JJKH20200997KJ),
   and in part by the Fundamental Research Funds for the Central
   Universities, JLU.
CR Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen Tianqi, 2015, ARXIV
   Chi C, 2019, AAAI CONF ARTIF INTE, P8231
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding XH, 2019, IEEE I CONF COMP VIS, P1911, DOI 10.1109/ICCV.2019.00200
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Li J, 2019, PROC CVPR IEEE, P5055, DOI 10.1109/CVPR.2019.00520
   Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26
   Liao SC, 2016, IEEE T PATTERN ANAL, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu Y., 2020, P IEEE CVF C COMPUTE, P13568
   Liu Y, 2017, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2017.69
   Ming X, 2019, PROC CVPR IEEE, P3441, DOI 10.1109/CVPR.2019.00356
   Najibi M, 2019, PROC CVPR IEEE, P7715, DOI 10.1109/CVPR.2019.00791
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Ohn-Bar E, 2016, INT C PATT RECOG, P3350, DOI 10.1109/ICPR.2016.7900151
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2021, MULTIMED TOOLS APPL, V80, P19753, DOI 10.1007/s11042-021-10711-8
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang X, 2018, LECT NOTES COMPUT SC, V11213, P812, DOI 10.1007/978-3-030-01240-3_49
   Triantafyllidou D, 2018, BIG DATA RES, V11, P65, DOI 10.1016/j.bdr.2017.06.002
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227
   Xu DZ, 2021, MULTIMED TOOLS APPL, V80, P34153, DOI 10.1007/s11042-020-09143-7
   Yang B., 2014, IEEE INT JOINT C BIO, P1
   Yang Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13043, DOI 10.1109/CVPR42600.2020.01306
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Zhang JL, 2020, NEUROCOMPUTING, V380, P180, DOI 10.1016/j.neucom.2019.10.087
   Zhang KP, 2017, IEEE I CONF COMP VIS, P3190, DOI 10.1109/ICCV.2017.344
   Zhang SF, 2021, IEEE T PATTERN ANAL, V43, P4008, DOI 10.1109/TPAMI.2020.2997456
   Zhang SF, 2019, INT J COMPUT VISION, V127, P537, DOI 10.1007/s11263-019-01159-3
   Zhang SF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P1, DOI 10.1109/BTAS.2017.8272675
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhu CC, 2018, PROC CVPR IEEE, P5127, DOI 10.1109/CVPR.2018.00538
   Zhu CC, 2017, ADV COMPUT VIS PATT, P57, DOI 10.1007/978-3-319-61657-5_3
NR 55
TC 2
Z9 2
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10535
EP 10552
DI 10.1007/s11042-022-13667-5
EA SEP 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000850418800001
PM 36090154
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Shin, J
   Lee, K
AF Shin, Jongkyu
   Lee, Kyogu
TI Incorporating real-world object into virtual reality: using mobile
   device input with augmented virtuality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality; Augmented virtuality; Human computer interaction; User
   interfaces
AB Interactive virtual reality (VR) experience has become more common and widespread these days. The interaction is enabled by capturing inputs from users usually by mechanical hand-held controllers. Mainstream head-mounted display (HMD) based VR platforms come with these trackable multi-DOF controllers with a high level of versatility. This enables a tremendous diversity in input types and forms to provide more interactive and immersive VR experience. However, these devices lack in cross-platform compatibility as the protocols are non-standardized. Thus, it leads to a steep learning curve. The trouble in learning these devices results in non-intuitiveness and confusion to users. Also, the VR isolation may cause problems since the platforms are not designed to reflect any real environment around the user. In this paper, we investigate an alternate input method for virtual reality by incorporating a real-world object with augmented virtuality. We set a mobile phone as the real-world object for this phase of the study. We import a mobile phone from the real world and evaluate the possibility of utilizing it as an input device. The objective of this method is to give VR users more flexibility in input methods for VR and to reduce the physical barrier between the reality and virtual environment by using augmented virtuality. We propose a method for VR that overlays both real texture of a mobile phone and user's hand onto a virtual scene in real-time by utilizing external cameras attached on the HMD. While being immersed in virtual environment with the HMD, users can manipulate the device naturally for entering inputs to alter the virtual environment without removing the headset. We implement our prototype in two phases to explore its possibilities as a new input technique for VR. The evaluation was conducted by setting up different kinds of conditions and tasks in virtual environment. The effectiveness of the proposed method is verified experimentally in specific given tasks in comparison with conventional controllers. Furthermore, we address and improve important points for accurate real image display in the virtual environment which we have found in the process of the implementation and the experiment. The outcome of the study indicates that our approach based on augmented virtuality, which is a relatively new approach for mixed reality, could lead to a path for an effective and natural input method for VR.
C1 [Shin, Jongkyu; Lee, Kyogu] Seoul Natl Univ, Mus & Audio Res Grp, 1 Gwanak Ro, Seoul 151742, South Korea.
C3 Seoul National University (SNU)
RP Lee, K (corresponding author), Seoul Natl Univ, Mus & Audio Res Grp, 1 Gwanak Ro, Seoul 151742, South Korea.
EM jqshin@snu.ac.kr; kglee@snu.ac.kr
CR Abrash Michael, 2014, STEAM DEV DAYS
   Alaee G., 2018, IEEE VRS 4 WORKSH EV, P10
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   [Anonymous], 2014, CHI 14 EXTENDED ABST, DOI [DOI 10.1145/2559206.2574827, 10.1145/2559206.2574827]
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bhowmick S, 2018, REPORT STATE ART SEM
   Blumel E., 2009, East European Conference on Advances in Databases and Information Systems, P1, DOI DOI 10.1007/978-3-642-12082-4_4
   Brook J., 1996, Usability evaluation in industry
   Burdea G. C., 2003, Virtual reality technology
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   CALVIN J, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P450, DOI 10.1109/VRAIS.1993.380745
   Carruth DW, 2019, USING HMD IMMERSIVE
   Caserman P, 2019, VIRTUAL REAL-LONDON, V23, P155, DOI 10.1007/s10055-018-0374-z
   Casterson S., 2016, HTC VIVE GUIDE BEGIN
   Desai AP, 2017, 2017 14TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2017), P217, DOI 10.1109/CRV.2017.16
   Desai K, 2017, IEEE INT SYM MULTIM, P130, DOI 10.1109/ISM.2017.27
   Dong Wei, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P279, DOI 10.1109/ISMAR.2010.5643606
   Fisher S. S., 1987, Proceedings of the 1986 Workshop on Interactive 3D Graphics, P77, DOI 10.1145/319120.319127
   Friston S, 2014, IEEE T VIS COMPUT GR, V20, P616, DOI 10.1109/TVCG.2014.30
   Hou Ming., 2001, Proceedings of the 2001 conference of the Centre for Advanced Studies on Collaborative research, P6
   Hudson C, 2017, 2017 15TH IEEE INTERNATIONAL CONFERENCE ON EMERGING ELEARNING TECHNOLOGIES AND APPLICATIONS (ICETA 2017), P167
   Jerald Jason, 2015, The VR Book: Human-Centered Design for Virtual Reality, DOI [DOI 10.1145/2792790, 10.1145/2792790]
   Jiang F, 2016, PROCEEDINGS VRCAI 2016: 15TH ACM SIGGRAPH CONFERENCE ON VIRTUAL-REALITY CONTINUUM AND ITS APPLICATIONS IN INDUSTRY, P309, DOI 10.1145/3013971.3013987
   Kasahara S, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P6438, DOI 10.1145/3025453.3025962
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Koike H., 2001, ACM Transactions on Computer-Human Interaction, V8, P307, DOI 10.1145/504704.504706
   Latoschik ME, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P317, DOI 10.1145/2993369.2996308
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MAGGIONI C, 1993, IEEE VIRTUAL REALITY ANNUAL INTERNATIONAL SYMPOSIUM, P118, DOI 10.1109/VRAIS.1993.380789
   McGill M, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P2143, DOI 10.1145/2702123.2702382
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Piumsomboon T, 2017, IEEE SYMP 3D USER, P36, DOI 10.1109/3DUI.2017.7893315
   Poupyrev I., 1996, P 9 ANN ACM S USER I, P79, DOI [DOI 10.1145/237091.237102, 10.1145/237091.237102]
   Ren Z, 2011, PROC FL STATE HORTIC, V124, P1
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Satyavolu S, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P149, DOI 10.1109/VR.2012.6180925
   Stanney K.M., 2002, Handbook of virtual environments: design, implementation and applications
   Steed A., 2008, P 2008 ACM S VIRT RE, P123, DOI [10.1145/1450579.1450606, DOI 10.1145/1450579.1450606]
   Tecchia Franco., 2014, Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology, P73, DOI DOI 10.1145/2671015.2671123
   Vertanen K., 2011, P 13 INT C HUM COMP, DOI DOI 10.1145/2037373.2037418
   Villamor C., 2010, Touch Gesture Reference Guide
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Xiao R, 2018, IEEE T VIS COMPUT GR, V24, P1653, DOI 10.1109/TVCG.2018.2794222
   Zhou F, 2008, INT SYM MIX AUGMENT, P193, DOI 10.1109/ISMAR.2008.4637362
NR 45
TC 1
Z9 1
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 AUG 30
PY 2022
DI 10.1007/s11042-022-13637-x
EA AUG 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4E1YW
UT WOS:000847629600003
DA 2024-07-18
ER

PT J
AU Yang, YG
   Wang, BP
   Zhou, YH
   Shi, WM
   Liao, X
AF Yang, Yu-Guang
   Wang, Bao-Pu
   Zhou, Yi-Hua
   Shi, Wei-Min
   Liao, Xin
TI Efficient color image encryption by color-grayscale conversion based on
   steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Color image encryption; Steganography; Chaotic system;
   YCbCr
ID CHAOTIC SYSTEM; ALGORITHM; DECOMPOSITION; COMPRESSION
AB Traditional image encryption algorithms usually aim to encrypt the RGB channels of color plain images separately. In this paper, a novel dimension reduction method is proposed for color image encryption, where a color plain image is first converted into a grayscale image by using steganography technique followed by an encryption operation on the resultant grayscale image thereby reducing the dimension of the encryption. And the color information can be restored back without losing any details. More specifically, a color plain image is first converted into the YCbCr channels, where the Y channel is used as the steganography carrier and to hide the other two channels that are down-sampled by a bicubic interpolation. Our algorithm can compress and encrypt the color plain image to generate a grayscale cipher image so as to reduce the repeatability of encryption. Furthermore, only the used pixel values are encrypted, where a bridge is built between binary image encryption and traditional grayscale image encryption. The security and performance of the proposed image encryption algorithm are analyzed, and the unification between binary image encryption and grayscale image encryption is achieved.
C1 [Yang, Yu-Guang; Wang, Bao-Pu; Zhou, Yi-Hua; Shi, Wei-Min] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Yang, Yu-Guang] Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
   [Liao, Xin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
C3 Beijing University of Technology; Hunan University
RP Yang, YG (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.; Yang, YG (corresponding author), Beijing Key Lab Trusted Comp, Beijing 100124, Peoples R China.
EM yangyang7357@bjut.edu.cn
OI Yang, Yuguang/0000-0002-4040-2448
FU National Natural Science Foundation of China [62071015, 61972142,
   62171264]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 62071015, 61972142, 62171264).
CR Athira V, 2013, 2013 IEEE INTERNATIONAL MULTI CONFERENCE ON AUTOMATION, COMPUTING, COMMUNICATION, CONTROL AND COMPRESSED SENSING (IMAC4S), P271, DOI 10.1109/iMac4s.2013.6526421
   Bao L, 2015, INFORM SCIENCES, V324, P197, DOI 10.1016/j.ins.2015.06.049
   Bao WJ, 2022, MULTIMED TOOLS APPL, V81, P15977, DOI 10.1007/s11042-022-12623-7
   Calderbank AR, 1998, APPL COMPUT HARMON A, V5, P332, DOI 10.1006/acha.1997.0238
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chai XL, 2018, SIGNAL PROCESS, V148, P124, DOI 10.1016/j.sigpro.2018.02.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chen E, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417500468
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen XY, 2021, MATH BIOSCI ENG, V18, P1722, DOI 10.3934/mbe.2021089
   Deng J, 2017, MULTIMED TOOLS APPL, V76, P10097, DOI 10.1007/s11042-016-3600-2
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Duan CF, 2022, OPT LASER ENG, V150, DOI 10.1016/j.optlaseng.2021.106881
   Eftekhari A, 2011, SIGNAL PROCESS, V91, P1589, DOI 10.1016/j.sigpro.2011.01.002
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Han Bao, 2021, IEEE Transactions on Circuits and Systems I: Regular Papers, V68, P4534, DOI 10.1109/TCSI.2021.3082895
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2022, IEEE T SYST MAN CY-S, V52, P4402, DOI 10.1109/TSMC.2021.3096967
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Huo DM, 2021, OPT COMMUN, V492, DOI 10.1016/j.optcom.2021.126976
   Huo DM, 2020, APPL PHYS B-LASERS O, V126, DOI 10.1007/s00340-020-7397-3
   Iqbal N, 2021, MULTIMED TOOLS APPL, V80, P36305, DOI 10.1007/s11042-021-11386-x
   Jiang DH, 2021, SIGNAL PROCESS, V188, DOI 10.1016/j.sigpro.2021.108220
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Lin HR, 2022, IEEE T IND INFORM, V18, P8839, DOI 10.1109/TII.2022.3155599
   Liu S, 2014, OPT LASER TECHNOL, V57, P327, DOI 10.1016/j.optlastec.2013.05.023
   Loukhaoukha K, 2018, MULTIMED TOOLS APPL, V77, P9325, DOI 10.1007/s11042-017-4938-9
   Loukhaoukha K, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON SYSTEMS, SIGNAL PROCESSING AND THEIR APPLICATIONS (WOSSPA), P267, DOI 10.1109/WoSSPA.2013.6602374
   Miri A, 2018, MULTIMED TOOLS APPL, V77, P13133, DOI 10.1007/s11042-017-4935-z
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Ping P, 2019, IEEE ACCESS, V7, P170168, DOI 10.1109/ACCESS.2019.2955570
   Rani N, 2022, NONLINEAR DYNAM, V108, P1773, DOI 10.1007/s11071-022-07276-y
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Rehman AU, 2021, MULTIMED TOOLS APPL, V80, P21979, DOI 10.1007/s11042-021-10692-8
   Wang H, 2019, SIGNAL PROCESS, V155, P218, DOI 10.1016/j.sigpro.2018.10.001
   Wang SM, 2022, OPT LASER TECHNOL, V148, DOI 10.1016/j.optlastec.2021.107753
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Wu Y, 2010, PROC SPIE, V7708, DOI 10.1117/12.853197
   Xian YJ, 2022, INFORM SCIENCES, V596, P304, DOI 10.1016/j.ins.2022.03.025
   Yang Y, 2007, IEEE T CONSUM ELECTR, V53, P1490, DOI 10.1109/TCE.2007.4429242
   Yang YG, 2023, MULTIMED TOOLS APPL, V82, P22033, DOI 10.1007/s11042-021-11656-8
   Yang YG, 2021, INFORM SCIENCES, V580, P174, DOI 10.1016/j.ins.2021.08.073
   Yang YG, 2021, INFORM SCIENCES, V562, P304, DOI 10.1016/j.ins.2021.01.041
   Yang YG, 2021, MULTIMED TOOLS APPL, V80, P9055, DOI 10.1007/s11042-020-10149-4
   Yang YG, 2020, OPTIK, V213, DOI 10.1016/j.ijleo.2020.164422
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Yang YG, 2018, INFORM SCIENCES, V429, P102, DOI 10.1016/j.ins.2017.11.009
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Zhang XP, 2011, IEEE T INF FOREN SEC, V6, P53, DOI 10.1109/TIFS.2010.2099114
   Zhong HY, 2022, MULTIMED TOOLS APPL, V81, P24757, DOI 10.1007/s11042-022-12479-x
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhu LY, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107629
   Zhu LY, 2019, IEEE ACCESS, V7, P22161, DOI 10.1109/ACCESS.2019.2897721
NR 63
TC 10
Z9 10
U1 38
U2 168
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 10835
EP 10866
DI 10.1007/s11042-022-13689-z
EA AUG 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000844934900001
DA 2024-07-18
ER

PT J
AU Mahapatra, S
   Jena, UR
   Dash, S
AF Mahapatra, Sakambhari
   Jena, U. R.
   Dash, Sonali
TI Mean global based on hysteresis thresholding for retinal blood vessel
   segmentation using enhanced homomorphic filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal vessel segmentation; Homomorphic filtering; Laplacian operator;
   Mean global based on hysteresis thresholding
ID RETINOPATHY
AB Retinal images are playing a very significant role in medical imaging technology. The variation in blood vessel attributes like tortuosity, focal length, branching angle, deformations like haemorrhage, lesions, etc. are good indicators of many diseases. Therefore, identifying these changes and distortions precisely can assist the ophthalmologists to detect and diagnose many diseases like diabetes, hypertension, glaucoma, stroke, etc. even in the early stage. Segmenting the vessel network is the preliminary step in the automation of the disease diagnosis process. The computerization of this segmentation process reduces the time, cost, and inconsistency due to manual segmentation. Here we present an automatic vessel segmentation technique. The proposed approach enhances the image contrast and highlights the edges using a novel cascaded pre-processing stage. In addition to this, a novel thresholding method named Mean Global Based on Hysteresis (MGBH) is introduced for segmentation. The efficiency of the suggested scheme is evaluated on the DRIVE database. The results are compared with state-of-the-art methods. The proposed method achieves better performance parameter values. The advantages of the proposed method include fast processing and high segmentation accuracy with simplified implementation. Moreover, this work can be extended to segment noisy and diseased fundus images.
C1 [Mahapatra, Sakambhari; Jena, U. R.] VSSUT, Dept Elect & Telecommun Engn, Burla 768018, India.
   [Dash, Sonali] Chandigarh Univ, Dept Comp Sci & Engn, Mohali 140413, India.
C3 Veer Surendra Sai University of Technology; Chandigarh University
RP Mahapatra, S (corresponding author), VSSUT, Dept Elect & Telecommun Engn, Burla 768018, India.
EM mahapatra.shakambhari@gmail.com; urjena@rediffmail.com;
   sonali.isan@gmail.com
CR [Anonymous], 1983, Finding Edges and Lines in Images
   Aslani S, 2016, BIOMED SIGNAL PROCES, V30, P1, DOI 10.1016/j.bspc.2016.05.006
   Bandara AMRR, 2017, INT CONF IND INF SYS, P535
   Chu K., 1999, Emerg Med, V11, P175, DOI DOI 10.1046/J.1442-2026.1999.00041.X
   Dash Jyotiprava, 2019, Soft Computing and Signal Processing. Proceedings of ICSCSP 2018. Advances in Intelligent Systems and Computing (AISC 900), P603, DOI 10.1007/978-981-13-3600-3_57
   Dash Jyotiprava, 2017, Future Computing and Informatics Journal, V2, P103, DOI 10.1016/j.fcij.2017.10.001
   Dash J, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P933, DOI 10.1109/ICISC.2018.8398938
   Dash S, 2021, INT J IMAG SYST TECH, V31, P351, DOI 10.1002/ima.22461
   Davies ER., 1990, MACHINE VISION THEOR
   GeethaRamani R, 2016, BIOCYBERN BIOMED ENG, V36, P102, DOI 10.1016/j.bbe.2015.06.004
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Heneghan C, 2002, MED IMAGE ANAL, V6, P407, DOI 10.1016/S1361-8415(02)00058-0
   Imani E, 2015, COMPUT METH PROG BIO, V118, P263, DOI 10.1016/j.cmpb.2015.01.004
   Imran A, 2019, IEEE ACCESS, V7, DOI 10.1109/ACCESS.2019.2935912
   isi, 2021, DATABASES DRIVE
   Khan MAU, 2019, PATTERN ANAL APPL, V22, P583, DOI 10.1007/s10044-017-0661-4
   Liao M, 2014, OPT LASER TECHNOL, V58, P56, DOI 10.1016/j.optlastec.2013.10.018
   Memari N, 2019, J MED BIOL ENG, V39, P713, DOI 10.1007/s40846-018-0454-2
   Mohsen Saleh SamiAbdulla., 2012, Proceedings of the International Conference on Information and Knowledge Management, P74
   Neto LC, 2017, EXPERT SYST APPL, V78, P182, DOI 10.1016/j.eswa.2017.02.015
   Nguyen UTV, 2013, PATTERN RECOGN, V46, P703, DOI 10.1016/j.patcog.2012.08.009
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal S, 2019, MULTIDIM SYST SIGN P, V30, P373, DOI 10.1007/s11045-018-0561-9
   Roychowdhury S, 2015, IEEE J BIOMED HEALTH, V19, P1118, DOI 10.1109/JBHI.2014.2335617
   Sathya N, 2017, INT J BIOMED ENG TEC, V25, P105, DOI 10.1504/IJBET.2017.087710
   Zhou C, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105231
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 27
TC 2
Z9 2
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41911
EP 41928
DI 10.1007/s11042-022-13517-4
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000842923900001
DA 2024-07-18
ER

PT J
AU Gupta, A
AF Gupta, Abhishek
TI A lightweight deep neural network implemented on MATLAB without using
   GPU for the automatic monitoring of the plants
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution neural network; Deep learning; Plant's leaf segmentation;
   Semantic segmentation; Lightweight training-based system
AB Plants and trees are essential for the human kind which must be preserved and well taken care for the growth of any country. Plants require intensive care which involves monitoring of their size, growth, health, and yield. Manually monitoring of these factors is time consuming. In this regard, computer vision approaches are evolving to monitor the plants for developing better yields. Deep learning convolution neural network is the most promising and currently trending tool which can solve the complex problems in the field of image processing and computer vision. However, often these deep learning models are computationally expensive and time-consuming which makes them unsuitable to be used in the real world scenarios. Thus, a lightweight deep learning convolutional neural network was designed and proposed to automatically segment the plant's leaves so that the monitoring of the plants can be done with high speed. Benchmark datasets in four different categories with total of 810 images were collected to train and test the proposed model. Many challenges were associated with those categories under the mentioned dataset for the segmentation of leaves. The proposed light-weight deep learning model was implemented on MATLAB platform tool and trained on a local system without using any GPU (Graphical Processing Unit). The training was completed within 13 minutes and 25 sec and provided segmentation accuracy on testing set as 98.26% which is satisfactory for such kind of monitoring applications.
C1 [Gupta, Abhishek] Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
C3 Shri Mata Vaishno Devi University
RP Gupta, A (corresponding author), Shri Mata Vaishno Devi Univ, Sch Comp Sci & Engn, Katra 182320, Jammu & Kashmir, India.
EM abhishekgupta10@yahoo.co.in
RI Gupta, Abhishek/O-3016-2019
OI Gupta, Abhishek/0000-0002-8592-9964
FU UGC (University Grants Commission), India [RP-103, F.30-436/2018(BSR)]
FX The study was supported by grant No. F.30-436/2018(BSR) and RP-103
   received from UGC (University Grants Commission), India.
CR Al-Shakarji NM, 2017, 2017 IEEE APPL IMAG
   Alguliyev R, 2021, SOFT COMPUT, V25, P13229, DOI 10.1007/s00500-021-06176-4
   [Anonymous], 2021, SEMANTIC SEGMENTATIO
   Ashok M, 2021, P INT C ARTIFICIAL I
   Ashok M, 2021, ARCH COMPUT METHOD E, V28, P3245, DOI 10.1007/s11831-020-09497-z
   Bao WX, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-06181-z
   Bell J, 2019, ARXIV
   Boulent J, 2019, FRONT PLANT SCI, V10, DOI 10.3389/fpls.2019.00941
   Brindha GJ, 2021, ECOL INFORM, V63, DOI 10.1016/j.ecoinf.2021.101323
   Cap HQ, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P118, DOI 10.1109/CSPA.2018.8368697
   Dellen B, 2015, IEEE ACM T COMPUT BI, V12, P1470, DOI 10.1109/TCBB.2015.2404810
   Gai JY, 2020, J FIELD ROBOT, V37, P35, DOI 10.1002/rob.21897
   Gao LW, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104924
   Gupta A., 2020, J CRIT REV, V7, P2398
   Gupta A, 2019, COMPUT SCI-AGH, V20, P389, DOI 10.7494/csci.2019.20.4.3163
   Gupta RK, 2021, INT J UNCERTAIN FUZZ, V29, P921, DOI 10.1142/S0218488521500410
   Huang WJ, 2014, IEEE J-STARS, V7, P2516, DOI 10.1109/JSTARS.2013.2294961
   Jadhav S.B., 2019, IAES Int J Artif Intell Educ, V8, P328
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946
   Kolhar S, 2021, ECOL INFORM, V64, DOI 10.1016/j.ecoinf.2021.101373
   Kumar J. P., 2019, Information Processing in Agriculture, V6, P233, DOI 10.1016/j.inpa.2018.09.005
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Minervini M, 2014, ECOL INFORM, V23, P35, DOI 10.1016/j.ecoinf.2013.07.004
   Ozturk S., 2017, ELECTRONICS, P1
   Pandey M, 2021, BIOCYBERN BIOMED ENG, V41, P1601, DOI 10.1016/j.bbe.2021.10.006
   Patil BM, 2022, MULTIMED TOOLS APPL, V81, P15419, DOI 10.1007/s11042-022-12436-8
   Raina Sakshi, 2021, Proceedings of the 2021 International Conference on Artificial Intelligence and Smart Systems (ICAIS), P900, DOI 10.1109/ICAIS50930.2021.9396023
   Raza SEA, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0123262
   Rzanny M, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0462-4
   Scharr H., 2014, FZJ201403837, P1
   Sharma S., 2020, INT J INTELLIGENCE S, V1, P101
   Triki A, 2021, PATTERN RECOGN LETT, V150, P76, DOI 10.1016/j.patrec.2021.07.003
   Trivedi M., 2021, INT J APPL SCI ENG, V18, P1, DOI [DOI 10.6703/IJASE.202106_18(2).003, 10.6703/IJASE.202106_18(2).003]
   Trivedi M, 2022, MULTIMED TOOLS APPL, V81, P5515, DOI 10.1007/s11042-021-11807-x
   Viaud G, 2017, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.02057
   Waldchen J, 2018, PLOS COMPUT BIOL, V14, DOI 10.1371/journal.pcbi.1005993
   Xie XY, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.00751
   Yang KL, 2020, AGRONOMY-BASEL, V10, DOI 10.3390/agronomy10111721
   Yin X, 2018, IEEE T PATTERN ANAL, V40, P1411, DOI 10.1109/TPAMI.2017.2728065
NR 39
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7343
EP 7359
DI 10.1007/s11042-022-13678-2
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000847198600001
DA 2024-07-18
ER

PT J
AU Ashiba, HI
AF Ashiba, H., I
TI Presented cancelable face recognition system using graph theory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Graph theory; Face recognition; Image encryption; Cancelable
   biometric
AB This paper suggests novel proposed cancellable biometric realization technique recognition and template protection. This algorithm is based on encrypt data securely with the benefits of graph theory properties. The new symmetric encryption algorithm utilizes the concepts of bipartite graph to generate a complex cipher text using a shared key. In this paper, the Graph First Decomposition Mask (GFH) encoding algorithm is utilized for cancelable face system. In the suggested scheme, the GFH algorithm is applied on the face images. The resultant map is encrypted, in order to the second GFH utilized in production from the picture. This scheme can be used to develop a frequency domain procedure for making this system for biometric template protection. Simulation results using evaluation metrics False Positive Rate (FPR), False Negative Rate (FNR), Equal Error Rate (EER), Receiver Operating Characteristic (ROC) and Area under ROC (AROC) prove that the proposed cancelable biometric technique is the best performance with comparing the other techniques.The obtained results clear that the suggested technique has sucesseded in cancelable face biometric.
C1 [Ashiba, H., I] Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Bilbis, Sharqia, Egypt.
RP Ashiba, HI (corresponding author), Bilbis Higher Inst Engn, Dept Elect & Elect Commun Engn, Bilbis, Sharqia, Egypt.
EM eng_h_2006@yahoo.com
CR Akl SG, 2019, PARALLEL EMERGENT CO, P18
   Amudha P., 2018, International Journal of Pure and Applied Mathematics, V119, P375
   [Anonymous], TECHNICAL DOCUMENT F
   Ashiba HI, 2021, MULTIMED TOOLS APPL, V80, P13677, DOI 10.1007/s11042-020-10291-z
   Ashiba HI, 2020, MULTIMED TOOLS APPL, V79, P30813, DOI 10.1007/s11042-020-09529-7
   Ben Tarif E, 2018, MULTIMED TOOLS APPL, V77, P2485, DOI 10.1007/s11042-016-4280-7
   Bordel B, 2020, INTEGR COMPUT-AID E, V27, P37, DOI 10.3233/ICA-190604
   Cheung KH, 2005, CISST '05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY: COMPUTER GRAPHICS, P40
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   Falah N., 2019, J ENG APPL SCI, Vl, P219
   Gaddam S. V. K., 2010, INT J NETW SECURITY, V11, P57
   Kumar P, 2011, APPL OPTICS, V50, P1805, DOI 10.1364/AO.50.001805
   Lumini A, 2007, PATTERN RECOGN, V40, P1057, DOI 10.1016/j.patcog.2006.05.030
   Ni BZ, 2021, J MATH-UK, V2021, DOI 10.1155/2021/6614172
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Qi X, 2013, IEEE REAL TIME, P163, DOI 10.1109/RTAS.2013.6531089
   Qi X, 2012, REAL TIM SYST SYMP P, P95, DOI 10.1109/RTSS.2012.62
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Sreekumar S., 2016, PROC IEEE INT C COMP, P1
   The impact of social identity and empathy on helping behavior: the moderator role of empathy, 2019, INT J SCI TECHNOL RE, V5, P12, DOI 10.7176/JSTR/5-12-35
   Dang TK, 2016, IET BIOMETRICS, V5, P229, DOI 10.1049/iet-bmt.2015.0029
   Walia GS, 2020, IEEE T DEPENDABLE SE, V19
   Walia GS, 2020, IEEE T INF FOREN SEC, V15, P1945, DOI 10.1109/TIFS.2019.2954779
NR 24
TC 0
Z9 0
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 5
BP 7159
EP 7180
DI 10.1007/s11042-022-13656-8
EA AUG 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K4QK
UT WOS:000842591000001
DA 2024-07-18
ER

PT J
AU Abdallah, B
   Belghith, F
   Ben Ayed, MA
   Masmoudi, N
AF Abdallah, Bouthaina
   Belghith, Fatma
   Ben Ayed, Mohamed Ali
   Masmoudi, Nouri
TI Fast QTMT decision tree for Versatile Video Coding based on deep neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Versatile Video Coding (VVC); Encoding complexity; Quadtree with nested
   multi-type tree (QTMT); Convolution Neural Network (CNN)
AB Versatile Video Coding (VVC), the emerging video coding standard, outperforms the coding efficiency of the previous standard named High Efficiency Video Coding (HEVC) at the cost of an encoding complexity increase. In fact, VVC proposes a new partitioning block structure called quadtree with nested multi-type tree (QTMT) that introduces a more flexible partition shape compared to the previous splitting algorithms namely quadtree plus binary tree (QTBT) and quadtree (QT) structures adopted in HEVC. However, QTMT increases the encoding time due to the rate-distortion cost (RDcost) process. In order to overcome this issue, this paper proposes a fast intra partitioning algorithm based on a Deep Learning (DL) approach using a Convolution Neural Network (CNN). First, a fast QTMT partition algorithm based on a CNN-binary tree horizontal (CNN-BTH) network is developed to predict the BTH mode decision at 32x32 Coding Units (CUs). The BTV decision tree algorithm is also predicted at this level by a CNN-binary tree vertical (CNN-BTV). Then, two algorithms are combined to suggest a new fast intra QTMT decision tree algorithm. Compared to the VVC reference software VTM-3.0, the proposed overall intra QTMT partition approach reaches a significant complexity reduction down to 37% compared to the original software VTM-3.0, and an average of 31% in terms of encoding time saving with a slight loss in coding performance.
C1 [Abdallah, Bouthaina; Belghith, Fatma; Masmoudi, Nouri] Univ Sfax, Natl Engn Sch Sfax, Elect & Informat Technol Lab, Sfax 3035, Tunisia.
   [Ben Ayed, Mohamed Ali] Univ Sfax, Sfax Natl Sch Elect & Commun ENETCOM, New Technol & Telecom Syst Lab NTSCOM, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax
RP Abdallah, B (corresponding author), Univ Sfax, Natl Engn Sch Sfax, Elect & Informat Technol Lab, Sfax 3035, Tunisia.
EM Boutheina.abdallah@enis.tn
RI Abdallah, Bouthaina/HCI-9949-2022
CR Abdallah B, 2021, SIGNAL IMAGE VIDEO P, V15, P1153, DOI 10.1007/s11760-020-01843-9
   Amestoy T, 2020, IEEE T IMAGE PROCESS, V29, P1313, DOI 10.1109/TIP.2019.2938670
   Bjontegaard G, 2001, VCEGM33
   Bossen F., 2018, JOINT VIDEO EXPERTS
   Cao J, 2020, LECT NOTES COMPUT SC, V11961, P739, DOI 10.1007/978-3-030-37731-1_60
   Chang CY, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010045
   Fan YB, 2020, IEEE ACCESS, V8, P107900, DOI 10.1109/ACCESS.2020.3000565
   Fu T, 2019, IEEE INT CON MULTI, P55, DOI 10.1109/ICME.2019.00018
   Jin ZP, 2018, IEEE ACCESS, V6, P54660, DOI 10.1109/ACCESS.2018.2872492
   JVET, 2018, VVC TEST MOD VTM VES
   Kibeya H, 2016, IET IMAGE PROCESS, V10, P371, DOI 10.1049/iet-ipr.2015.0381
   Kibeya H, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013028
   Kim S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091094
   Li T., 2020, ARXIV
   Liu XG, 2019, IEEE T CIRC SYST VID, V29, P144, DOI 10.1109/TCSVT.2017.2777903
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   Park SH, 2019, IEEE ACCESS, V7, P172597, DOI 10.1109/ACCESS.2019.2956196
   Sidaty N, 2017, INT WORK QUAL MULTIM
   Tang G., 2019, P IEEE VIS COMM IM P, P1
   Wang Z, 2018, IEEE IMAGE PROC, P2550, DOI 10.1109/ICIP.2018.8451258
   Wang Z, 2017, IEEE DATA COMPR CONF, P23, DOI 10.1109/DCC.2017.70
   Yang H, 2020, IEEE T CIRC SYST VID, V30, P1668, DOI 10.1109/TCSVT.2019.2904198
   Yang Hao, 2019, IEEE T CIRCUITS SYST
   Zhong GY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020132
NR 24
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42731
EP 42747
DI 10.1007/s11042-022-13479-7
EA AUG 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000840140800001
DA 2024-07-18
ER

PT J
AU Kar, T
   Kanungo, P
AF Kar, T.
   Kanungo, P.
TI A gradient based dual detection model for shot boundary detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Abrupt transition; Gradual transition; Gradient
   orientation; Gradient magnitude; Joint histogram; Golay filter
ID FEATURE VECTOR; SEGMENTATION; TRANSFORM; SCHEME; SVD
AB An efficient video shot boundary detection is highly desirable for subsequent semantic video content analysis and retrieval applications. The major challenge of shot boundary detection problem is an appropriate choice of features to handle the illumination variation and motion artifacts of frames while finding the boundary in a shot. In this paper, to improve the efficacy of shot boundary detection in presence of the aforementioned challenges, the strength of the gradient feature is explored to develop a dual detection framework for automatic shot boundary detection. In the first phase, abrupt transition (AT) detection is addressed in presence of illumination variation and motion in the frames of a shot by generating an combined feature through joint histogram of gradient magnitude and gradient orientation features frame. In the second phase, gradual transition detection (GT) detection is applied only on the frames within two AT frames satisfying specific frame distance criteria. Handling both AT and GT by the proposed simple gradient-based framework is the uniqueness of this work. Moreover, the proposed method is fully ubiquitous, independent of the video content and free from any training process. Exhaustive simulations are carried out on different databases to validate the proposed approach. The performance of the proposed feature-based shot boundary framework, in terms of average F1 measure, is 94% for AT detection, 84% for GT detection and 90.01% for overall detection.
C1 [Kar, T.] KIIT Deemed Univ, Sch Elect Engn, Bhubaneswar, Odisha, India.
   [Kanungo, P.] CV Raman Global Univ, Dept Elect & Telecommun Engn, Bhubaneswar, Odisha, India.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Kar, T (corresponding author), KIIT Deemed Univ, Sch Elect Engn, Bhubaneswar, Odisha, India.
EM tkarfet@kiit.ac.in; pkanungo@gmail.com
CR Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   Birinci M, 2014, SIGNAL PROCESS-IMAGE, V29, P410, DOI 10.1016/j.image.2013.12.003
   Chakraborty Dipanita, 2021, 2021 18th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P272, DOI 10.1109/ECTI-CON51831.2021.9454775
   Chakraborty S, 2022, VISUAL COMPUT, V38, P445, DOI 10.1007/s00371-020-02027-9
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P4007, DOI 10.1007/s11042-020-09857-8
   Chakraborty S, 2021, MULTIMED TOOLS APPL, V80, P3071, DOI 10.1007/s11042-020-09683-y
   Chasanis VT, 2009, IEEE T MULTIMEDIA, V11, P89, DOI 10.1109/TMM.2008.2008924
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhiman S, 2019, MULTIMED TOOLS APPL, V78, P34707, DOI 10.1007/s11042-019-08170-3
   Fan JY, 2017, MULTIMED TOOLS APPL, V76, P10169, DOI 10.1007/s11042-016-3604-y
   Giveki D, 2017, OPTIK, V131, P242, DOI 10.1016/j.ijleo.2016.11.046
   Gygli M, 2018, INT WORK CONTENT MUL
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   Hassanien A, 2017, ARXIV
   Huang M, 2015, OPTIK, V126, P2144, DOI 10.1016/j.ijleo.2015.05.095
   Jian MW, 2020, MULTIMED TOOLS APPL, V79, P33467, DOI 10.1007/s11042-019-07842-4
   Jian MW, 2018, J VIS COMMUN IMAGE R, V57, P1, DOI 10.1016/j.jvcir.2018.10.008
   Jian MW, 2018, J VIS COMMUN IMAGE R, V53, P31, DOI 10.1016/j.jvcir.2018.03.008
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jiang XH, 2013, NEUROCOMPUTING, V116, P102, DOI 10.1016/j.neucom.2011.11.037
   Kar T, 2015, 2015 IEEE POWER, COMMUNICATION AND INFORMATION TECHNOLOGY CONFERENCE (PCITC-2015), P72, DOI 10.1109/PCITC.2015.7438097
   Kavitha J, 2017, INT J IMAGE GRAPH, V17, DOI 10.1142/S0219467817500024
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Liang R, 2017, IEEE INT SYM MULTIM, P489, DOI 10.1109/ISM.2017.97
   Lu ZM, 2013, IEEE T IMAGE PROCESS, V22, P5136, DOI 10.1109/TIP.2013.2282081
   Mohanta PP, 2012, IEEE T MULTIMEDIA, V14, P223, DOI 10.1109/TMM.2011.2170963
   Montazer GA, 2015, OPTIK, V126, P1695, DOI 10.1016/j.ijleo.2015.05.002
   Murthy ASD, 2020, MATER TODAY-PROC, V33, P4323, DOI 10.1016/j.matpr.2020.07.447
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   open-video, VIDEO DATASET
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Rashmi BS, 2021, MULTIMED TOOLS APPL, V80, P641, DOI 10.1007/s11042-020-09697-6
   Sasithradevi A, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293392
   Sasithradevi A, 2020, J VIS COMMUN IMAGE R, V67, DOI 10.1016/j.jvcir.2020.102754
   Singh A, 2020, SIGNAL IMAGE VIDEO P, V14, P645, DOI 10.1007/s11760-019-01593-3
   Soucek T, 2019, ARXIV
   Tippaya S, 2017, IEEE ACCESS, V5, P12563, DOI 10.1109/ACCESS.2017.2717998
   Warhade KK, 2011, SIGNAL IMAGE VIDEO P, V5, P507, DOI 10.1007/s11760-010-0163-y
   Yoo HW, 2006, MULTIMED TOOLS APPL, V28, P283, DOI 10.1007/s11042-006-7715-8
   Youssef B, 2017, COMPUT VIS IMAGE UND, V161, P20, DOI 10.1016/j.cviu.2017.06.003
   Zhou SB, 2021, SIGNAL IMAGE VIDEO P, V15, P627, DOI 10.1007/s11760-020-01785-2
NR 42
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8489
EP 8506
DI 10.1007/s11042-022-13547-y
EA AUG 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000837590100004
DA 2024-07-18
ER

PT J
AU Mishra, AK
   Roy, P
   Bandyopadhyay, S
   Das, SK
AF Mishra, Arnab Kumar
   Roy, Pinki
   Bandyopadhyay, Sivaji
   Das, Sujit Kumar
TI Feature fusion based machine learning pipeline to improve breast cancer
   prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radiomics; Deep convolutional neural networks; Feature fusion; ML
   pipeline; Breast cancer
ID INTEROBSERVER VARIABILITY; DIAGNOSIS; LESIONS; SMOTE
AB Early detection of malignant breast cancer can significantly improve the survival chances of the involved patients. Analysis of a non-invasive and non-radioactive modality like ultrasound imaging with the help of Machine Learning(ML) and Artificial Intelligence(AI) techniques can be crucial for achieving such effective early-stage detection of the disease. A feature fusion based approach is proposed in this work, in conjunction with an ML pipeline that systematically deals with various problems like high dimensionality, class imbalance, and hyperparameter tuning, so that efficient benign vs. malignant classification can be performed. Experimental evaluation on two publicly available datasets reveals that the proposed approach is able to outperform state-of-the-art techniques on the classification task with an overall performance of above 95% for all the evaluation metrics under consideration and an AUC of similar to 0.99. More specifically, an overall improvement of (1-4)%, (2-10)% and (2-7)% over the current state-of-the-art approaches could be obtained for the Accuracy, AUC and Sensitivity metrics respectively, on both the datasets. Such an efficient approach can provide the necessary real-time decision support to the involved radiologists, making better cancer patient care possible.
C1 [Mishra, Arnab Kumar; Roy, Pinki; Bandyopadhyay, Sivaji] Natl Inst Technol Silchar, Dept CSE, Silchar, India.
   [Das, Sujit Kumar] Bennett Univ, Dept CSE, Greater Noida, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Mishra, AK (corresponding author), Natl Inst Technol Silchar, Dept CSE, Silchar, India.
EM arnab.mishra.1992@gmail.com; pinki@cse.nits.ac.in;
   sivaji.cse.ju@gmail.com; sujit.das@bennett.edu.in
OI Das, Dr. Sujit Kumar/0000-0002-7807-1461; Mishra,
   Arnab/0000-0001-8323-3122
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   [Anonymous], 2012, BAYESIAN APPROACH GL
   Asraf Amanullah, 2020, SN Comput Sci, V1, P363, DOI 10.1007/s42979-020-00383-w
   Ayon SI, 2022, IETE J RES, V68, P2488, DOI 10.1080/03772063.2020.1713916
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Byra M, 2019, MED PHYS, V46, P746, DOI 10.1002/mp.13361
   Cai LY, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/s12938-015-0022-8
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Coelho, 2012, ARXIV
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daoud MI, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236838
   Das Arijit, 2021, P INT C COMP COMM NE, P1, DOI DOI 10.1109/ICCCNT51525.2021.9580160
   Das S, 2018, P INT C COMP INT IOT
   Das SK, 2021, DEEP LEARNING TECHNI, P295
   Das SK, 2021, DFU SPNET STACKED PA
   Das SK, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6741
   Das SK, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6690
   Das SK, 2022, INT J IMAG SYST TECH, V32, P192, DOI 10.1002/ima.22598
   Elreedy D, 2019, INFORM SCIENCES, V505, P32, DOI 10.1016/j.ins.2019.07.070
   Feurer M, 2019, SPRING SER CHALLENGE, P3, DOI 10.1007/978-3-030-05318-5_1
   Goodfellow I. J., 2014, ARXIV
   Haque M E., 2018, Proceedings of 2018 21st International Conference of Computer and Information Technology (ICCIT'18), P21, DOI [DOI 10.1109/ICCITECHN.2018.8631957, 10.1109/IC4ME2.2018.8465658, DOI 10.1109/IC4ME2.2018.8465658]
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Hasan MK, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS AND VISION (ICIEV), P574, DOI 10.1109/ICIEV.2016.7760068
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Islam Ayon S., 2019, Int J Inf Eng Electronic Business, V11, P21, DOI DOI 10.5815/IJIEEB.2019.02.03
   Islam MM, 2021, IEEE ACCESS, V9, P30551, DOI 10.1109/ACCESS.2021.3058537
   Islam Md Milon, 2020, SN Comput Sci, V1, P274, DOI 10.1007/s42979-020-00300-1
   Islam MM, 2017, IEEE REG 10 HUMANIT, P226, DOI 10.1109/R10-HTC.2017.8288944
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jain Deepali, 2021, Proceedings of International Conference on Artificial Intelligence and Applications. ICAIA 2020. Advances in Intelligent Systems and Computing (AISC 1164), P351, DOI 10.1007/978-981-15-4992-2_33
   Jain D, 2020, ACM INT CONF PR SER, P41, DOI 10.1145/3441501.3441502
   Jia Wu, 2019, Journal of Electronic Science and Technology, V17, P26, DOI 10.11989/JEST.1674-862X.80904120
   Kim SH, 2013, KOREAN J RADIOL, V14, P154, DOI 10.3348/kjr.2013.14.2.154
   Kingma D. P., 2014, arXiv
   Lazarus E, 2006, RADIOLOGY, V239, P385, DOI 10.1148/radiol.2392042127
   Li H., 2017, ARXIV
   Lo CM, 2015, IFMBE PROC, V47, P124, DOI 10.1007/978-3-319-12262-5_35
   Löfstedt T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212110
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mishra Arnab Kumar, 2021, Proceedings of International Conference on Artificial Intelligence and Applications. ICAIA 2020. Advances in Intelligent Systems and Computing (AISC 1164), P373, DOI 10.1007/978-981-15-4992-2_35
   Mishra A.K., 2019, P SAI INTELLIGENT SY, P724
   Mishra AK, 2021, EXPERT SYST, V38, DOI 10.1111/exsy.12713
   Mishra AK, 2020, J HEALTHC ENG, V2020, DOI 10.1155/2020/8843664
   Moon WK, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105361
   Moura DC, 2013, INT J COMPUT ASS RAD, V8, P561, DOI 10.1007/s11548-013-0838-2
   Muhammad L J, 2020, SN Comput Sci, V1, P206, DOI 10.1007/s42979-020-00216-w
   Park CS, 2015, BREAST CANCER-TOKYO, V22, P153, DOI 10.1007/s12282-013-0465-3
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rahman Mohammad Marufur, 2021, SN Comput Sci, V2, P384, DOI 10.1007/s42979-021-00774-7
   Rodríguez-Cristerna A, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE)
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sadad T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061900
   Sadoughi F, 2018, BREAST CANCER-TARGET, V10, P219, DOI 10.2147/BCTT.S175311
   Saha Prottoy, 2021, Inform Med Unlocked, V22, P100505, DOI 10.1016/j.imu.2020.100505
   Shi XJ, 2010, DIGIT SIGNAL PROCESS, V20, P824, DOI 10.1016/j.dsp.2009.10.010
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Verma K, 2015, STUD COMPUT INTELL, V598, P23, DOI 10.1007/978-3-319-16211-9_3
   Victoria AH, 2021, EVOL SYST-GER, V12, P217, DOI 10.1007/s12530-020-09345-2
   WCRF, 2020, Breast cancer statistics
   Wu T, 2019, BREAST CANCER RES TR, V173, P365, DOI 10.1007/s10549-018-4984-7
   Xiao T, 2018, BIOMED RES INT, V2018, DOI 10.1155/2018/4605191
   Xie J, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/abc5c7
   Yang MC, 2013, IEEE T MED IMAGING, V32, P2262, DOI 10.1109/TMI.2013.2279938
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Zhang EL, 2019, IEEE ENG MED BIO, P947, DOI [10.1109/EMBC.2019.8856539, 10.1109/embc.2019.8856539]
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
NR 71
TC 4
Z9 4
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37627
EP 37655
DI 10.1007/s11042-022-13498-4
EA AUG 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000837590100007
DA 2024-07-18
ER

PT J
AU Anshula
   Singh, H
AF Anshula
   Singh, Hukum
TI Ensuring security of cryptosystems with DVFM-, modified equal modulus
   decomposition in the domain of gyrator wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gyrator wavelet transform; Equal modulus decomposition; Devil vortex
   Fresnel mask
ID STRUCTURED PHASE MASKS; VORTEX FRESNEL LENS; OPTICAL ENCRYPTION;
   COHERENT SUPERPOSITION; CANONICAL TRANSFORMS; PLAINTEXT ATTACK;
   REALIZATION; GENERATION
AB This paper analyses the security of a nonlinear optical cryptosystem based on double random phase encoding (DRPE). This article is upgraded through an interference-based asymmetric optical image encryption technique, equal modulus decomposition (EMD) and deploying of the devil's vortex Fresnel Mask (DVFM). DVFM is designed by the phase values of the Devils Mask (DM),Vortex Mask(VM) and Fresnel Mask(FM). The key space of the cryptographic system increases with the use of DVFM phase keys and hybrid gyrator wavelet transform (GWT). A system's efficiency is measured by the difference between the input image and the retrieved image. The capabilities of the proposed algorithm are accomplished in terms of histograms, noise attacks and correlation coefficients. The results show that the proposed optical image encryption system based on hybrid transformation is time-efficient and provides a high degree of information security without affecting its noise immunity. In addition to offering a large number of security phase keys, it has a robust resistance to a variety of potential attacks.
C1 [Anshula] NorthCap Univ, Dept Comp Sci & Engn, Gurugram, India.
   [Singh, Hukum] NorthCap Univ, Dept Appl Sci, Gurugram, India.
C3 The Northcap University; The Northcap University
RP Singh, H (corresponding author), NorthCap Univ, Dept Appl Sci, Gurugram, India.
EM hukumsingh.dhs@gmail.com
CR Abuturab MR, 2015, J OPT SOC AM A, V32, P1811, DOI 10.1364/JOSAA.32.001811
   Abuturab MR, 2012, OPT LASER ENG, V50, P1383, DOI 10.1016/j.optlaseng.2012.04.011
   Alfalou A, 2009, ADV OPT PHOTONICS, V1, P589, DOI 10.1364/AOP.1.000589
   Anshula, 2021, OPT REV, V28, P596, DOI 10.1007/s10043-021-00705-0
   Anshula, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02854-7
   Barrera JF, 2005, OPT COMMUN, V248, P35, DOI 10.1016/j.optcom.2004.11.086
   Cai JJ, 2017, OPT LASER TECHNOL, V95, P105, DOI 10.1016/j.optlastec.2017.04.018
   Cai JJ, 2015, OPT LETT, V40, P475, DOI 10.1364/OL.40.000475
   Calabuig A, 2013, APPL OPTICS, V52, P5822, DOI 10.1364/AO.52.005822
   Calatayud A, 2012, APPL PHYS B-LASERS O, V106, P915, DOI 10.1007/s00340-012-4913-0
   Carnicer A, 2005, OPT LETT, V30, P1644, DOI 10.1364/OL.30.001644
   Chen H, 2017, OPT LASER ENG, V93, P1, DOI 10.1016/j.optlaseng.2017.01.005
   Chen LF, 2005, OPT COMMUN, V254, P361, DOI 10.1016/j.optcom.2005.05.052
   Fatima A, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/8/085701
   Girija R, 2021, OPTIK, V244, DOI 10.1016/j.ijleo.2021.167568
   Girija R, 2020, MULTIMED TOOLS APPL, V79, P34717, DOI 10.1007/s11042-019-7733-y
   Girija R, 2019, OPTIK, V187, P238, DOI 10.1016/j.ijleo.2019.04.090
   Javidi B, 2016, J OPTICS-UK, V18, DOI 10.1088/2040-8978/18/8/083001
   Khurana M., 2019, RECENT PATENTS COMPU, V12, P80, DOI [10.2174/2213275911666181030111102, DOI 10.2174/2213275911666181030111102]
   Kong DZ, 2014, OPT LASER TECHNOL, V57, P343, DOI 10.1016/j.optlastec.2013.08.013
   Kumar P, 2016, SPRINGER SER OPT SCI, V198, P367, DOI 10.1007/978-1-4939-3028-9_13
   Kumar R, 2018, J OPTICS-UK, V20, DOI 10.1088/2040-8986/aa9943
   Matoba O, 2009, P IEEE, V97, P1128, DOI 10.1109/JPROC.2009.2018367
   Mehra I, 2018, IET IMAGE PROCESS, V12, P432, DOI 10.1049/iet-ipr.2017.0666
   Mehra I, 2015, OPT COMMUN, V354, P344, DOI 10.1016/j.optcom.2015.06.015
   MENDLOVIC D, 1993, APPL OPTICS, V32, P6542, DOI 10.1364/AO.32.006542
   Millan M. S., 2011, OPTICAL DIGITAL IMAG, P739, DOI DOI 10.1002/9783527635245.CH33
   Mitry M, 2012, APPL OPTICS, V51, P4103, DOI 10.1364/AO.51.004103
   Peng X, 2006, OPT LETT, V31, P1044, DOI 10.1364/OL.31.001044
   Peng X, 2006, OPT LETT, V31, P3261, DOI 10.1364/OL.31.003261
   Pu JX, 2015, OPT EXPRESS, V23, P8190, DOI 10.1364/OE.23.008190
   Qin W, 2010, OPT LETT, V35, P118, DOI 10.1364/OL.35.000118
   Rajput SK, 2012, APPL OPTICS, V51, P5377, DOI 10.1364/AO.51.005377
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Rodrigo JA, 2007, OPT EXPRESS, V15, P2190, DOI 10.1364/OE.15.002190
   Sangwan A, 2021, INT J OPT, V2021, DOI 10.1155/2021/5510125
   Singh H, 2016, OPT LASER ENG, V81, P125, DOI 10.1016/j.optlaseng.2016.01.014
   Singh H, 2014, APPL OPTICS, V53, P6472, DOI 10.1364/AO.53.006472
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Sui LS, 2016, OPT EXPRESS, V24, P499, DOI 10.1364/OE.24.000499
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Vilardy Juan M., 2011, Journal of Physics: Conference Series, V274, DOI 10.1088/1742-6596/274/1/012047
   Wang Y, 2016, APPL OPTICS, V55, P679, DOI 10.1364/AO.55.000679
   Yadav AK, 2015, SPRINGER PROC PHYS, V166, P25, DOI 10.1007/978-81-322-2367-2_5
   Yadav S., 2021, Recent Adv. Computer Sci. Commun, V14, P1987, DOI [10.2174/2666255813666191223112920, DOI 10.2174/2666255813666191223112920]
   Yadav S., 2021, RECENT ADV COMPUT SC, V14, P2691, DOI [10.2174/2666255813999200708134844, DOI 10.2174/2666255813999200708134844]
   Yadav S, 2022, MULTIDIM SYST SIGN P, V33, P99, DOI 10.1007/s11045-021-00788-7
   Zamrani W, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.10.103108
   Zhou NR, 2011, OPT COMMUN, V284, P3234, DOI 10.1016/j.optcom.2011.02.065
NR 49
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5965
EP 5985
DI 10.1007/s11042-022-13584-7
EA AUG 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000834736500008
DA 2024-07-18
ER

PT J
AU Ahmed, U
   Lin, JCW
   Srivastava, G
AF Ahmed, Usman
   Lin, Jerry Chun-Wei
   Srivastava, Gautam
TI Mitigating adversarial evasion attacks by deep active learning for
   medical image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adversarial attack; IoMT; Medical image analysis; Deep learning
AB In the Internet of Medical Things (IoMT), collaboration among institutes can help complex medical and clinical analysis of disease. Deep neural networks (DNN) require training models on large, diverse patients to achieve expert clinician-level performance. Clinical studies do not contain diverse patient populations for analysis due to limited availability and scale. DNN models trained on limited datasets are thereby constraining their clinical performance upon deployment at a new hospital. Therefore, there is significant value in increasing the availability of diverse training data. This research proposes institutional data collaboration alongside an adversarial evasion method to keep the data secure. The model uses a federated learning approach to share model weights and gradients. The local model first studies the unlabeled samples classifying them as adversarial or normal. The method then uses a centroid-based clustering technique to cluster the sample images. After that, the model predicts the output of the selected images, and active learning methods are implemented to choose the sub-sample of the human annotation task. The expert within the domain takes the input and confidence score and validates the samples for the model's training. The model re-trains on the new samples and sends the updated weights across the network for collaboration purposes. We use the InceptionV3 and VGG16 model under fabricated inputs for simulating Fast Gradient Signed Method (FGSM) attacks. The model was able to evade attacks and achieve a high accuracy rating of 95%.
C1 [Ahmed, Usman; Lin, Jerry Chun-Wei] Western Norway Univ Appl Sci, Dept Comp Sci Elect Engn & Math Sci, N-5063 Bergen, Norway.
   [Srivastava, Gautam] Brandon Univ, Dept Math & Comp Sci, Brandon, MB, Canada.
   [Srivastava, Gautam] China Med Univ, Res Ctr Interneural Comp, Taichung, Taiwan.
C3 Western Norway University of Applied Sciences; Brandon University; China
   Medical University Taiwan
RP Lin, JCW (corresponding author), Western Norway Univ Appl Sci, Dept Comp Sci Elect Engn & Math Sci, N-5063 Bergen, Norway.
EM usman.ahmed@hvl.no; jerrylin@ieee.org; srivastavag@brandonu.ca
RI Ahmed, Usman/AAG-5727-2020; Srivastava, Gautam/N-5668-2019
OI Ahmed, Usman/0000-0002-3933-4273; Srivastava,
   Gautam/0000-0001-9851-4103; Lin, Jerry Chun-Wei/0000-0001-8768-9709
FU Western Norway University Of Applied Sciences
FX Open access funding provided by Western Norway University Of Applied
   Sciences.
CR Ahmed U., 2021, IEEE CONSUM ELECTR M
   Aldape K, 2018, NEURO-ONCOLOGY, V20, P873, DOI 10.1093/neuonc/noy020
   Amich A, 2021, ARXIV 210615820
   Bai X, 2018, PATTERN RECOGN, V75, P136, DOI 10.1016/j.patcog.2017.03.020
   Bonawitz Keith, 2019, ARXIV 190201046
   Borovec J, 2020, IEEE T MED IMAGING, V39, P3042, DOI 10.1109/TMI.2020.2986331
   Chang K, 2018, J AM MED INFORM ASSN, V25, P945, DOI 10.1093/jamia/ocy017
   Chen M, 2020, IEEE T CLOUD COMPUT, V8, P1274, DOI 10.1109/TCC.2016.2617382
   Cheng YH, 2018, LECT NOTES COMPUT SC, V11218, P105, DOI 10.1007/978-3-030-01264-9_7
   Davatzikos C, 2020, NEURO-ONCOLOGY, V22, P886, DOI 10.1093/neuonc/noaa045
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding XY, 2021, IEEE INTERNET THINGS, V8, P802, DOI 10.1109/JIOT.2020.3008232
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Finlayson SG, 2019, SCIENCE, V363, P1287, DOI 10.1126/science.aaw4399
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Kermany Daniel, 2018, Mendeley Data, V3
   Lin JCW, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106548
   Lin JCW, 2019, ENG APPL ARTIF INTEL, V85, P175, DOI 10.1016/j.engappai.2019.06.005
   Lyu ZL, 2021, FRONT BIOENG BIOTECH, V9, DOI 10.3389/fbioe.2021.687426
   Maarouf R, 2021, ARXIV 210514564
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Niu YH, 2019, AAAI CONF ARTIF INTE, P1093
   Paranjape Jay N., 2020, 2020 International Conference on Computing and Data Science (CDS), P114, DOI 10.1109/CDS49703.2020.00029
   Paschali M, 2018, LECT NOTES COMPUT SC, V11070, P493, DOI 10.1007/978-3-030-00928-1_56
   Pien HH, 2005, DRUG DISCOV TODAY, V10, P259, DOI 10.1016/S1359-6446(04)03334-3
   Ravi V., 2021, IEEE T ENG MANAGE, DOI [DOI 10.1109/TEM.2021.3059664, 10.1109/tem.2021.3059664]
   Roth HR, 2020, LECT NOTES COMPUT SC, V12444, P181, DOI 10.1007/978-3-030-60548-3_18
   Roth HR, 2015, PROC SPIE, V9413, DOI 10.1117/12.2081420
   Sheller MJ, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69250-1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stapor K, 2021, APPL SOFT COMPUT, V104, DOI 10.1016/j.asoc.2021.107219
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang C, 2019, IEEE GEOSCI REMOTE S, V16, P310, DOI 10.1109/LGRS.2018.2872355
   Wang Z, 2020, ON THE CONSTITUTIONALITY OF COMPILING A CIVIL CODE OF CHINA: A PROCESS MAP FOR LEGISLATION BORN OUT OF PRAGMATISM, P1, DOI 10.1007/978-981-13-7900-0
   Yu ZF, 2020, 2020 12TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P628, DOI [10.1109/icaci49185.2020.9177527, 10.1109/ICACI49185.2020.9177527]
   Zech JR, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002683
NR 38
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41899
EP 41910
DI 10.1007/s11042-021-11473-z
EA JUL 2022
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700027
OA hybrid
DA 2024-07-18
ER

PT J
AU Viswanath, K
   Anilkumar, B
   Gunasundari, R
AF Viswanath, K.
   Anilkumar, Budati
   Gunasundari, R.
TI Design of deep learning reaction-diffusion level set segmentation
   approach for health care related to automatic kidney stone detection
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kidney stone recognition; Deep learning technique; Level set
   segmentation; Multilayer perceptron (MLP) and Back propagation (BP);
   FPGA; Advanced decomposition wavelet transform; RoI and RDLSS
ID IMAGE; TOMOGRAPHY; NETWORKS
AB The current study of kidney stones made by the National Health and Nutrition Examination Survey (NHANES) describes that over the last eighty years the number of stones present in the kidney is significantly enhanced by approximately 70% (2015). According to Malaysian Dialysis and information of Transplant Registry, there is a constant increase in the number of patients who are registering newly, and the increase from 2002 to 2010 is 2375, 5153 from 2011 to 2014, and from 2015 to 2016 it is 5201. A standardized data system in the United States (2008-2009). In the United States Renal Data System which captures, evaluates, and generates reports that are based on end-stage renal disease and diseases of the kidney. Some of the pathological changes of the kidney are the formation of stones, variations in the state of its position, and inflammation of the kidney. It is very essential to recognize the precise and correct position of stone in the kidney for interventional procedures. For further analysis, the ultrasound images are considered as a challenging task because of its significantly low intensity and additive sound. Therefore, to eliminate the additive noise present in the image, preprocessing of the US is performed. The preprocessed US image by using Plain Intensity Filter is fed to feature extraction technique extracted by deep learning-based advanced Symlets, Daubechies, and Biorthogonal wavelet sub-bands filters to extract kidney image and stones. These features are subjected to segmentation using a Novel Deep and Machine learning Reaction-Diffusion (RD) level set segmentation (LSS). It employs a two-step division process to recursively solve the equation of RD-LSS such as reaction and diffusion. The reaction is to minimize the numerical errors and the diffusion is employed to normalize the set function level for better stability. The RD-LSS also eliminates the anti-leakages on image boundary without requiring any expensive re-initialization. Wavelet sub-bands are used to obtain energy and mean levels and the average levels provide a sign of the absence or existence of stones. These levels of energy are accomplished through Machine learning algorithms with the help of Back Propagation, Multilayer Perceptron, and Support Vector Machine ANN (Verma et al. in Pattern Recognit Image Anal 27:574-580, 35). After successfully training by Machine learning algorithms, the proposed system can identify the single and multiple stones with an accuracy of 98.9% in terms of detection of stone in US images compared with the existing detection techniques that give 92.1% accuracy.
C1 [Viswanath, K.] RL Jalappa Inst Technol, Dept ECE, Bangalore, Karnataka, India.
   [Gunasundari, R.] GRIET, Dept ECE, Hyderabad, India.
   [Anilkumar, Budati] Pondicherry Engn Coll, Dept ECE, Pondicherry, India.
C3 Gokaraju Rangaraju Institute of Engineering & Technology; Pondicherry
   Engineering College
RP Viswanath, K (corresponding author), RL Jalappa Inst Technol, Dept ECE, Bangalore, Karnataka, India.
EM vishwanathk@rljit.in; anilbudati@gmail.com; gunasundari@pec.edu
RI Budati, Anil Kumar/U-4960-2018
OI Budati, Anil Kumar/0000-0002-5118-2284; ,
   Dr.R.Gunasundari/0000-0001-9149-3354
CR Abou El-Ghar ME, 2012, ARAB J UROL, V10, P279, DOI 10.1016/j.aju.2012.02.007
   Al-Asad JF, 2010, INT CONF BIOINFORM
   Andersson T, 2013, IEEE T IMAGE PROCESS, V22, P621, DOI 10.1109/TIP.2012.2220148
   [Anonymous], USRDS SYSTEM ANN DAT
   [Anonymous], 21 REPORT MALAYSIAN
   Anushalin PS., 2014, INT J BIOSCIENCE ENG, V1, P39
   Bagley DH, 2012, ARAB J UROL, V10, P296, DOI 10.1016/j.aju.2012.05.005
   Bharath R., 2016, J IMAGING, DOI [10.3390/jimaging101019, DOI 10.3390/JIMAGING101019]
   Bommanna Raja K, 2007, P INT C COMPUTING TH
   Bommanna Raja K, 2007, P INT C COMP THEOR A
   Dheepa N., 2012, 2012 International Conference on Advances in Engineering, Science and Management (ICAESM), P601
   Gladis Pushpa Rathi V. P., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P274, DOI 10.1109/ICECTECH.2011.5942097
   Goel R, 2020, ADV DATA INFORM SCI, V94, DOI [10.1007/978.981.15.0694.9_58, DOI 10.1007/978.981.15.0694.9_58]
   Hafizah W. M., 2012, 2012 6th Asia Modelling Symposium (AMS 2012), P115, DOI 10.1109/AMS.2012.47
   Hossain S, 2019, INT CONF ACOUST SPEE, P1348, DOI 10.1109/ICASSP.2019.8683802
   Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4
   Krishna KD, 2016, IRBM, V37, P189, DOI 10.1016/j.irbm.2016.05.001
   Law MWK, 2013, IEEE T IMAGE PROCESS, V22, P845, DOI 10.1109/TIP.2012.2216274
   Law YN, 2008, IEEE T IMAGE PROCESS, V17, P2289, DOI 10.1109/TIP.2008.2005823
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu LY, 2019, IEEE ACCESS, V7, P43970, DOI 10.1109/ACCESS.2019.2908282
   Lu SJ, 2010, IEEE T BIO-MED ENG, V57, P2605, DOI 10.1109/TBME.2010.2055057
   Marsousi M, 2014, IEEE ENG MED BIO, P2890, DOI 10.1109/EMBC.2014.6944227
   Martinez-carballido J, 2010, 2010 ELECT ROBOTICS
   Ngo LY, 2011, ALL RENAL REPLACEMEN
   Park H, 2001, IEEE T CIRC SYST VID, V11, P252, DOI 10.1109/76.905991
   Rahman T, 2013, SPECKLE NOISE REDUCT
   Raja R.A., 2013, INT J COMPUT APPL, V975, P8887
   Rajaei A., 2011, INT J ENG SCI, V4, P131
   Robertson WG, 2012, ARAB J UROL, V10, P250, DOI 10.1016/j.aju.2012.03.006
   Shehata M, 2019, IEEE T BIO-MED ENG, V66, P539, DOI 10.1109/TBME.2018.2849987
   Shen DG, 2017, ANNU REV BIOMED ENG, V19, P221, DOI [10.1146/annurev-bioeng-071516044442, 10.1146/annurev-bioeng-071516-044442]
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Vaish P., 2016, 2016 IEEE 18 INT C E, P1
   Verma Jyoti, 2017, Pattern Recognition and Image Analysis, V27, P574, DOI 10.1134/S1054661817030294
   Viswanath K, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P407, DOI 10.1109/ICACCI.2014.6968485
   Viswanath K, 2014, P INT C OCMM COM IMC, P38
   Viswanath K., 2017, MED IMAGING, DOI [10.4018/978-1-5225-0571-6.ch027, DOI 10.4018/978-1-5225-0571-6.CH027]
   Viswanath K, 2015, VLSI DES, DOI 10.1155/2015/581961
   Xie Y, 2018, KIDNEY INT, V94, P567, DOI 10.1016/j.kint.2018.04.011
   Yan K, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.036501
   Zhang H, 2019, IEEE ACCESS, V7, P83001, DOI 10.1109/ACCESS.2019.2924207
   Zhang L, 2018, IEEE T MED IMAGING, V37, P638, DOI 10.1109/TMI.2017.2774044
   Zhang WD, 2013, IEEE T MED IMAGING, V32, P2006, DOI 10.1109/TMI.2013.2271487
NR 44
TC 4
Z9 4
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 41807
EP 41849
DI 10.1007/s11042-021-11263-7
EA JUL 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000823376700014
DA 2024-07-18
ER

PT J
AU Vieira, J
   Abreu, E
   Florindo, JB
AF Vieira, Jardel
   Abreu, Eduardo
   Florindo, Joao B.
TI Texture image classification based on a pseudo-parabolic diffusion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pseudo-parabolic equation; Texture recognition; Image classification;
   Numerical approximation methods for PDEs
ID DISCRETE SCHROEDINGER TRANSFORM; LOCAL BINARY PATTERN;
   CAPILLARY-PRESSURE; EDGE-DETECTION; SCALE; REPRESENTATION; EQUATION
AB This work proposes a novel method based on a pseudo-parabolic diffusion process to be employed for texture recognition. The proposed operator is applied over a range of time scales giving rise to a family of images transformed by nonlinear filters. Therefore each of those images are encoded by a local descriptor (we use local binary patterns for that purpose) and they are summarized by a simple histogram, yielding in this way the image feature vector. Three main novelties are presented in this manuscript: (1) The introduction of a pseudo-parabolic model associated with the signal component of binary patterns to the process of texture recognition and a real-world application to the problem of identifying plant species based on the leaf surface image. (2) We also introduce a simple and efficient discrete pseudo-parabolic differential operator based on finite differences as texture descriptors. While the work in [26] uses complete local binary patterns, here we use the original version of the local binary pattern operator. (3) We also discuss, in more general terms, the possibilities of exploring pseudo-parabolic models for image analysis as they balance two types of processing that are fundamental for pattern recognition, i.e., they smooth undesirable details (possibly noise) at the same time that highlight relevant borders and discontinuities anisotropically. Besides the practical application, the proposed approach is also tested on the classification of well established benchmark texture databases. In both cases, it is compared with several state-of-the-art methodologies employed for texture recognition. Our proposal outperforms those methods in terms of classification accuracy, confirming its competitiveness. The good performance can be justified to a large extent by the ability of the pseudo-parabolic operator to smooth possibly noisy details inside homogeneous regions of the image at the same time that it preserves discontinuities that convey critical information for the object description. Such results also confirm that model-based approaches like the proposed one can still be competitive with the omnipresent learning-based approaches, especially when the user does not have access to a powerful computational structure and a large amount of labeled data for training.
C1 [Vieira, Jardel] Univ Fed Goias, Unidade Acad Especial Matemat & Tecnol, Av Dr Lamartine Pinto Avelar 1120, BR-75704020 Catalao, Go, Brazil.
   [Abreu, Eduardo; Florindo, Joao B.] Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque Holanda 651, BR-13083859 Campinas, SP, Brazil.
C3 Universidade Federal de Goias; Universidade Estadual de Campinas
RP Florindo, JB (corresponding author), Univ Estadual Campinas, Inst Math Stat & Sci Comp, Rua Sergio Buarque Holanda 651, BR-13083859 Campinas, SP, Brazil.
EM jardelvieira@ufg.br; eabreu@unicamp.br; florindo@unicamp.br
OI Florindo, Joao/0000-0002-0071-0227
FU SAo Paulo Research Foundation (FAPESP) [2019/20991-8]; National Council
   for Scientific and Technological Development, Brazil (CNPq)
   [301480/2016-8, 423292/2018-8]; National Council for Scientific and
   Technological Development - Brazil (CNPq) [2 306385/2019-8]; PETROBRAS -
   Brazil [2015/00398-0]
FX J. B. Florindo gratefully acknowledges the financial support of SAo
   Paulo Research Foundation (FAPESP) (Grant #2016/16060-0) and from
   National Council for Scientific and Technological Development, Brazil
   (CNPq) (Grants #301480/2016-8 and #423292/2018-8). E. Abreu gratefully
   acknowledges the financial support of SAo Paulo Research Foundation
   (FAPESP) (Grant #2019/20991-8), from National Council for Scientific and
   Technological Development - Brazil (CNPq) (Grant #2 306385/2019-8) and
   PETROBRAS - Brazil (Grant #2015/00398-0). E. Abreu and J. B. Florindo
   also gratefully acknowledge the financial support of Red Iberoamericana
   de Investigadores en Matematicas Aplicadas a Datos (MathData).
CR Abreu Eduardo, 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12743), P398, DOI 10.1007/978-3-030-77964-1_31
   Abreu E, 2020, J COMPUT PHYS, V411, DOI 10.1016/j.jcp.2020.109395
   Abreu E, 2017, MATH COMPUT SIMULAT, V137, P29, DOI 10.1016/j.matcom.2016.10.006
   Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   Bounik Z, 2020, MULTIMED TOOLS APPL, V79, P7121, DOI 10.1007/s11042-019-08532-x
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Brunton SL, 2020, ANNU REV FLUID MECH, V52, P477, DOI 10.1146/annurev-fluid-010719-060214
   Casanova D, 2009, INT J IMAG SYST TECH, V19, P236, DOI 10.1002/ima.20201
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chatterjee AN, 2021, CHAOS SOLITON FRACT, V147, DOI 10.1016/j.chaos.2021.110952
   CHAVENT G, 1991, ADV WATER RESOUR, V14, P329, DOI 10.1016/0309-1708(91)90020-O
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Condori RHM, 2021, INFORM SCIENCES, V555, P260, DOI 10.1016/j.ins.2020.09.058
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COTTET GH, 1993, MATH COMPUT, V61, P659, DOI 10.1090/S0025-5718-1993-1195422-2
   Cuesta C, 2003, NONLINEAR ANAL-THEOR, V52, P1199, DOI 10.1016/S0362-546X(02)00160-8
   Cuesta CM, 2009, J COMPUT APPL MATH, V224, P269, DOI 10.1016/j.cam.2008.05.001
   Dai XY, 2017, PROC CVPR IEEE, P6100, DOI 10.1109/CVPR.2017.646
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dong XH, 2020, IEEE T IMAGE PROCESS, V29, P8776, DOI 10.1109/TIP.2020.3019185
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Florindo Joao B., 2021, Computational Science - ICCS 2021. 21st International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12743), P386, DOI 10.1007/978-3-030-77964-1_30
   Florindo JB, 2020, INFORM SCIENCES, V507, P356, DOI 10.1016/j.ins.2019.08.049
   Florindo JB, 2016, PATTERN RECOGN LETT, V78, P22, DOI 10.1016/j.patrec.2016.03.025
   Florindo JB, 2017, INFORM SCIENCES, V415, P142, DOI 10.1016/j.ins.2017.06.022
   Ghazouani H, 2020, EXPERT SYST APPL, V161, DOI 10.1016/j.eswa.2020.113667
   Gonçalves WN, 2016, INFORM SCIENCES, V364, P51, DOI 10.1016/j.ins.2016.04.052
   Guidotti P, 2013, SIAM J IMAGING SCI, V6, P1416, DOI 10.1137/120882895
   Guidotti P, 2009, J DIFFER EQUATIONS, V246, P4731, DOI 10.1016/j.jde.2009.03.017
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HASSANIZADEH SM, 1993, WATER RESOUR RES, V29, P3389, DOI 10.1029/93WR01495
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Jasionowska M, 2019, PATTERN ANAL APPL, V22, P1399, DOI 10.1007/s10044-018-0698-z
   Kannala J, 2012, INT C PATT RECOG, P1363
   Karch G, 1997, MATH METHOD APPL SCI, V20, P271
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P2663, DOI 10.1007/s11042-020-09745-1
   Kollem S, 2021, MULTIMED TOOLS APPL, V80, P409, DOI 10.1007/s11042-020-09675-y
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Li DM, 2021, NEURAL COMPUT APPL, V33, P8157, DOI 10.1007/s00521-020-04930-7
   Liu L, 2019, INT J COMPUT VISION, V127, P74, DOI 10.1007/s11263-018-1125-z
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu L, 2021, SIAM REV, V63, P208, DOI 10.1137/19M1274067
   Naik DL, 2019, ENG FRACT MECH, V219, DOI 10.1016/j.engfracmech.2019.106618
   Neiva MB, 2018, INT J MOD PHYS C, V29, DOI 10.1142/S0129183118500717
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Safdar A, 2019, MICROSC RES TECHNIQ, V82, P1542, DOI 10.1002/jemt.23320
   SHOWALTE.RE, 1969, STUD APPL MATH, P51
   SHOWALTER RE, 1969, PAC J MATH, V31, P787
   SHOWALTER RE, 1975, J MATH ANAL APPL, V50, P183, DOI 10.1016/0022-247X(75)90047-5
   Song TC, 2018, IEEE T CIRC SYST VID, V28, P1565, DOI 10.1109/TCSVT.2017.2671899
   Song Y, 2017, IEEE I CONF COMP VIS, P4922, DOI 10.1109/ICCV.2017.526
   STECHER M, 1977, J MATH ANAL APPL, V57, P110, DOI 10.1016/0022-247X(77)90289-X
   Tao ZY, 2021, IEEE SIGNAL PROC LET, V28, P1215, DOI 10.1109/LSP.2021.3088052
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   TING TW, 1969, J MATH SOC JPN, V21, P440
   Tu B, 2019, INT J REMOTE SENS, V40, P9484, DOI 10.1080/01431161.2019.1633699
   Van Duijn CJ, 2007, SIAM J MATH ANAL, V39, P507, DOI 10.1137/05064518X
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Vieira J, 2018, THESIS U CAMPIANS CA
   Wang S, 2022, VISUAL COMPUT, V38, P2539, DOI 10.1007/s00371-021-02129-y
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   Weickert J., 1996, ANISOTROPIC DIFFUSIO
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Xu XC, 2021, DIGIT SIGNAL PROCESS, V114, DOI 10.1016/j.dsp.2021.103081
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Xue J, 2018, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2018.00065
   You LH, 2020, MULTIMED TOOLS APPL, V79, P23161, DOI 10.1007/s11042-020-09060-9
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
   Zhai W, 2019, IEEE I CONF COMP VIS, P3612, DOI 10.1109/ICCV.2019.00371
   Zhang H, 2017, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR.2017.309
NR 80
TC 3
Z9 3
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3581
EP 3604
DI 10.1007/s11042-022-12048-2
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000823376500004
PM 35855773
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Li, YL
   Zhang, TS
   Bi, JY
   Wang, JM
AF Li, Yuelong
   Zhang, Tongshun
   Bi, Junyu
   Wang, Jianming
TI DD-GAN: pedestrian image inpainting with simultaneous tone correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image reconstruction; Image inpainting; Tone correction; Pedestrian
   inpainting
AB Accompanied by the rapid popularization of camera surveillance devices, tremendous pedestrian images can be acquired. Since a huge part of surveillance cameras are deployed out-of-door, many obtained images may contain some kinds of flaws, such as content defection and tone disorder. In this paper, a newly designed adversarial framework, namely DD-GAN, is proposed which could simultaneously recover both mentioned image damages. DD-GAN consists of three parts: generator, tone discriminator and inpainting discriminator. DD-GAN emphasizes the fusion of image inpainting and tone correction through the GAN network. In this way, we construct two generative adversarial losses, for two completely different functions, achieving the efficient combination of tone correction and image inpainting. Extensive experiments are conducted to verified the effectiveness of the proposed approach.
C1 [Li, Yuelong; Zhang, Tongshun; Bi, Junyu; Wang, Jianming] Tiangong Univ, Tianjin Key Lab Independent Intelligent Technol &, Tianjin 300387, Peoples R China.
   [Li, Yuelong; Zhang, Tongshun; Bi, Junyu; Wang, Jianming] Tiangong Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
C3 Tiangong University; Tiangong University
RP Wang, JM (corresponding author), Tiangong Univ, Tianjin Key Lab Independent Intelligent Technol &, Tianjin 300387, Peoples R China.; Wang, JM (corresponding author), Tiangong Univ, Sch Comp Sci & Technol, Tianjin 300387, Peoples R China.
EM liyuelong@pku.edu.cn; 1831125478@tiangong.edu.cn; bijunyu315@163.com;
   wangjianming@tiangong.edu.cn
RI Li, Yuelong/H-5707-2013
FU National Natural Science Foundation of China [61771340, 62072335,
   61902280]; Tianjin Natural Science Foundation [18JCYBJC15300,
   19JCYBJC15600]; Program for Innovative Research Team in University of
   Tianjin [TD13-5032]; Tianjin Science and Technology Program
   [19PTZWHZ00020, 20YDTPJC00870]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61771340, 62072335, and 61902280), the Tianjin Natural
   Science Foundation (No. 18JCYBJC15300 and 19JCYBJC15600), the Program
   for Innovative Research Team in University of Tianjin (No. TD13-5032),
   and the Tianjin Science and Technology Program (19PTZWHZ00020 and
   20YDTPJC00870).
CR Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Deng Y, 2015, ARXIV PREPRINT ARXIV
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   IIZUKA S, 2016, ACM T GRAPHIC, V35, P1, DOI DOI 10.1145/2897824.2925974
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   [刘威辰 Liu Weichen], 2017, [空军工程大学学报. 自然科学版, Journal of Air Force Engineering University. Natural Science Edition], V18, P1
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Nazeri K., 2019, ARXIV190100212
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shin YG, 2021, IEEE T NEUR NET LEAR, V32, P252, DOI 10.1109/TNNLS.2020.2978501
   Wang HD, 2019, PROCEDIA COMPUT SCI, V147, P254, DOI 10.1016/j.procs.2019.01.250
   Wang X, 2017, PROC CVPR IEEE, P7178, DOI 10.1109/CVPR.2017.759
   Xiao J, 2019, AAAI CONF ARTIF INTE, P354
   Yu JH, 2018, PROC CVPR IEEE, P5505, DOI 10.1109/CVPR.2018.00577
   Zeng YH, 2019, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2019.00158
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang J, 2019, MACH VISION APPL, V30, P987, DOI 10.1007/s00138-018-0970-7
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang W, 2017, IEEE T IMAGE PROCESS, V26, P2042, DOI 10.1109/TIP.2017.2672440
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 30
TC 0
Z9 0
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2503
EP 2516
DI 10.1007/s11042-022-12342-z
EA JUN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000817041500002
DA 2024-07-18
ER

PT J
AU Luo, YH
   Cao, X
   Zhang, JT
   Cheng, P
   Wang, TJ
   Feng, Q
AF Luo, Yihao
   Cao, Xiang
   Zhang, Juntao
   Cheng, Peng
   Wang, Tianjiang
   Feng, Qi
TI Dynamic multi-scale loss optimization for object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Multi-scale imbalance; Reinforcement learning;
   Multi-task
AB With the continuous improvement of deep object detectors via advanced model architectures, imbalance problems in the training process have received more attention. It is a common paradigm in object detection frameworks to perform multi-scale detection. However, each scale is treated equally during training. In this paper, we carefully study the objective imbalance of multi-scale detector training. We argue that the loss in each scale level is neither equally important nor independent. Different from the existing solutions of setting multi-task weights, we dynamically optimize the loss weight of each scale level in the training process. Specifically, we propose an Adaptive Variance Weighting (AVW) to balance multi-scale loss according to the statistical variance. Then we develop a novel Reinforcement Learning Optimization (RLO) to decide the weighting scheme probabilistically during training. It makes better utilization of multi-scale training loss without extra computational complexity and learnable parameters for backpropagation. Without bells and whistles, the proposed method improves ATSS by 0.9 AP on the MS COCO benchmark. And it achieves 82.1 mAP on Pascal VOC 2007 test set, which outperforms other reinforcement-learning-based methods.
C1 [Luo, Yihao; Cao, Xiang; Zhang, Juntao; Wang, Tianjiang; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Cheng, Peng] Coolanyp Ltd Liabil Co, Kirkland, WA USA.
C3 Huazhong University of Science & Technology
RP Feng, Q (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM luoyihao@hust.edu.cn; caoxiang112@hust.edu.cn; zhangjt0902@hust.edu.cn;
   pengc@coolanyptech.com; tjwang@hust.edu.cn; fengqi@hust.edu.cn
RI Cao, Xiang/ACT-7733-2022
OI Cao, Xiang/0000-0002-8813-9669
FU National Natural Science Foundation of China [61572214]; Seed Foundation
   of Huazhong University of Science and Technology [2020kfyXGYJ114]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61572214, and Seed Foundation of
   Huazhong University of Science and Technology (2020kfyXGYJ114).
CR Caicedo JC, 2015, IEEE I CONF COMP VIS, P2488, DOI 10.1109/ICCV.2015.286
   Cao J, 2020, ARXIV 200511475
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chen K, 2019, ARXIV 190607155
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Guo M, 2018, LECT NOTES COMPUT SC, V11220, P282, DOI 10.1007/978-3-030-01270-0_17
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Jie ZQ, 2016, ADV NEUR IN, V29
   Joya C, 2019, ARXIV 190904868
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kim S, 2020, AAAI CONF ARTIF INTE, V34, P11270
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Kong XY, 2017, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR.2017.748
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2020, IEEE T NEUR NET LEAR, V31, P2544, DOI 10.1109/TNNLS.2019.2933451
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo Y, 2021, ARXIV 210310643
   Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pirinen A, 2018, PROC CVPR IEEE, P6945, DOI 10.1109/CVPR.2018.00726
   Qi Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14161, DOI 10.1109/CVPR42600.2020.01418
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yi Wei, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11212), P274, DOI 10.1007/978-3-030-01237-3_17
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Yuan CH, 2019, MULTIMED TOOLS APPL, V78, P21145, DOI 10.1007/s11042-019-7446-2
   Yuhang Cao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11580, DOI 10.1109/CVPR42600.2020.01160
   Zhang H., 2020, P EUR C COMP VIS, P260, DOI DOI 10.1007/978-3-030-58555-6_16
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhang T, 2021, IEEE INT C MULTIMEDI
   Zhang ZJ, 2022, IEEE T NEUR NET LEAR, V33, P6856, DOI 10.1109/TNNLS.2021.3083710
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
NR 46
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2349
EP 2367
DI 10.1007/s11042-022-13164-9
EA JUN 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814956100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Garg, P
   Jain, A
AF Garg, Payal
   Jain, Ajit
TI A robust technique for biometric image authentication using invisible
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Biometric; SVD; DWT; Identity management; Chaotic
   encryption
AB In the present digital era, the number of ways to misuse multimedia data increases day by day. The availability of high image editing tools can change the image so it becomes challenging to predict the data. Watermarking is one of the techniques which can protect the identity of users. This is a highly secured method to protect digital images. In the presented paper, we suggested a more robust image watermarking approach using DWT-SVD with Chaotic encryption. This work mainly focuses on the protection of biometric images. The entropy map (blocks of 4 x 4) is estimated to apply for 2D discrete wavelet transformation (DWT). The LL band is considered for the watermark embedding process because of holding more information about the original image. Further, an orthogonal matrix is obtained using (Singular value decomposition) SVD and edge entropy-based thresholding is used. The chaotic encryption is performed over a watermark image. The encrypted form of copyright image is used to embed into that orthogonal matrix for performing watermarking. The results evaluated using fingerprints and gait biometrics datasets show the robustness of the proposed approach. The performance of the technique is evaluated using BER, PSNR and NC. The watermark is less fragile after testing under various noise and geometrical attacks. The technique's performance is also compared with recent techniques in this domain, where the proposed method outperforms.
C1 [Garg, Payal; Jain, Ajit] Banasthali Vidyapeeth, Dept Comp Sci, Tonk, Rajasthan, India.
   [Garg, Payal] GL Bajaj Inst Technol & Management, Dept Comp Sci & Engn, Greater Noida, India.
C3 Banasthali Vidyapith
RP Garg, P (corresponding author), Banasthali Vidyapeeth, Dept Comp Sci, Tonk, Rajasthan, India.; Garg, P (corresponding author), GL Bajaj Inst Technol & Management, Dept Comp Sci & Engn, Greater Noida, India.
EM payalgarg.cs@gmail.com; ajitjain_2k@yahoo.co.in
RI Jain, Ajit Kumar/GXG-9895-2022
OI Jain, Ajit Kumar/0000-0001-7953-3157; Garg, Payal/0000-0002-5347-722X
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Aggarwal A, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6157
   Aggarwal A, 2021, MULTIMED TOOLS APPL, V80, P1289, DOI 10.1007/s11042-020-09520-2
   Ahmadi M, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113157
   Alshoura WH, 2020, NEW CHAOTIC IMAGE WA
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Arora M, 2020, SECURE IMAGE ENCRYPT
   Arumugham S, 2019, TAMPER RESISTANT SEC
   Asikuzzaman M, 2016, IEEE T MULTIMEDIA, V18, P1733, DOI 10.1109/TMM.2016.2589208
   Ben Tarif E, 2018, MULTIMED TOOLS APPL, V77, P2485, DOI 10.1007/s11042-016-4280-7
   Cedillo-Hernandez M, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101695
   Chinese Academy of Sciences Institute of Automation, DAT CASIA FING V5
   Das S, 2020, IEEE ACCESS, V8, P69072, DOI 10.1109/ACCESS.2020.2986134
   Ernawan, BLOCK BASED RDWT SVD
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Hemdan EE, 2021, MULTIMED TOOLS APPL, V80, P1749, DOI 10.1007/s11042-020-09769-7
   Hosny KM, 2018, PARALLEL MULTICORE C
   Hurrah NN, 2019, SECURE MED IMAGE WAT
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Khare P, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3918
   Kumar M, 2013, 24 IET IR SIGN SYST
   Kumar M., 2016, INT J SIGNAL PROCESS, V9, P395, DOI 10.14257/ijsip.2016.9.10.35
   Linchundan, 2019, 1000 FUND IM 39 CAT
   Loan NA, 2018, SECURE ROBUST DIGITA
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Malik S, 2018, HISTOGRAM ENTROPY BA
   Nasrullah N, 2019, REVERSIBLE DATA HIDI
   Parah SA, 2015, INFORM HIDING MED IM
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Sabbane F, 2019, MED IMAGE WATERMARKI
   Saha, 2019, INT C ELECT COMPUTER
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh S, 2017, SVD DCT BASED MED IM
   Su Q, 2017, ROBUST COLOR IMAGE W
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Thakkar FN, 2016, BLIND MED IMAGE WATE
   Thakur S, 2020, MULTIMED TOOLS APPL, V79, P4263, DOI 10.1007/s11042-018-6691-0
   Thanki R, 2017, ENG SCI TECHNOL, V20, P1366, DOI 10.1016/j.jestch.2017.06.001
   Velazquez-Garcia L, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116593
   Vo PH, 2020, SECURE ROBUST WATERM
   Wang B, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON NETWORK INFRASTRUCTURE AND DIGITAL CONTENT, PROCEEDINGS, P1034, DOI 10.1109/ICNIDC.2009.5360866
   Wang YX, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10121465
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xiong LZ, 2019, J INF SECUR APPL, V47, P78, DOI 10.1016/j.jisa.2019.04.005
   Ye GD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/8402578
NR 45
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 2237
EP 2253
DI 10.1007/s11042-022-13314-z
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000814042700002
DA 2024-07-18
ER

PT J
AU Chennamma, HR
   Madhushree, B
AF Chennamma, H. R.
   Madhushree, B.
TI A comprehensive survey on image authentication for tamper detection with
   localization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital signature; Digital watermarking; Explicit authentication; Image
   authentication; Implicit authentication; Tamper localization
ID COPY-MOVE FORGERY; EXPOSING DIGITAL FORGERIES; REGION-DUPLICATION
   FORGERY; SEMI-FRAGILE WATERMARKING; ROBUST-DETECTION; DCT COEFFICIENT;
   JPEG IMAGES; WAVELET; HASH; COMPRESSION
AB The data that is stored or transmitted in digital form is susceptible to be attacked. Digital images are particularly vulnerable to unauthorized access and illicit alterations. As a result, image credibility verification approaches are constantly gaining popularity due to their importance in a variety of social concerns, including the government, military, forensics, and electronic commerce, among others. Even a minor attack could have disastrous consequences. Therefore, protecting images from tampering has become increasingly crucial. Many approaches have been developed in the literature to ensure the authenticity and integrity of digital images. These methodologies can be grouped into active and passive approaches for image authentication and tampering detection. Active image authentication has a general solution based on watermarking, signature and hybrid techniques. Passive authentication, on the other hand, relies on the image's inherent natural characteristics to provide implicit authentication. Digital image forensic tools have been utilized for identifying the signs of digital tampering. We have found from the literature of the past three decades that image credibility verification approaches have achieved promising results. However, accurate image tamper localization remains an unsolved problem and a fairly difficult task too, if it is performed carefully with expertise. This motivated us to present a comprehensive review of image authentication techniques, which enables not only image tamper detection but also localize the manipulated region. We also discussed the future work.
C1 [Chennamma, H. R.; Madhushree, B.] JSS Sci & Technol Univ, Dept Comp Applicat, Mysuru, India.
C3 JSS Science & Technology University
RP Chennamma, HR (corresponding author), JSS Sci & Technol Univ, Dept Comp Applicat, Mysuru, India.
EM anuamruthesh@gmail.com
RI H.R, Chennamma/V-1767-2019
OI H.R, Chennamma/0000-0002-3858-7834; , Madhushree B/0000-0002-6117-9468
CR Abbas SQ, 2016, INT C ULTRA MOD TELE, P401, DOI 10.1109/ICUMT.2016.7765393
   Abdalla Y, 2019, INFORMATION, V10, DOI 10.3390/info10090286
   Abdelhakim A, 2019, MULTIMED TOOLS APPL, V78, P32523, DOI 10.1007/s11042-019-07986-3
   Abidin ABZ, 2019, INT CONF RES INNOV, DOI [10.1109/icriis48246.2019.9073569, 10.1109/giots.2019.8766376]
   Adams J, 1998, IEEE MICRO, V18, P20, DOI 10.1109/40.743681
   Ahmed B, 2020, SIGNAL IMAGE VIDEO P, V14, P1035, DOI 10.1007/s11760-020-01636-0
   Ahmed F, 2007, LECT NOTES COMPUT SC, V4352, P51
   Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   Al Azrak FM, 2020, MULTIMED TOOLS APPL, V79, P18221, DOI 10.1007/s11042-019-08162-3
   Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Anbu T, 2021, MULTIMED TOOLS APPL, V80, P2713, DOI 10.1007/s11042-020-09585-z
   [Anonymous], 2011, WORLD ACAD SCI ENG T
   [Anonymous], 2011, 2011 4 INT C IM SIGN
   [Anonymous], 2010, J COMPUT INFORM SYST
   Vega EAA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103372
   Asghar K, 2017, AUST J FORENSIC SCI, V49, P281, DOI 10.1080/00450618.2016.1153711
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Babu B, 2015, INT J SCI TECHNOL MA, V04
   Barad ZJ, 2020, INT CONF ADVAN COMPU, P571, DOI [10.1109/ICACCS48705.2020.9074408, 10.1109/icaccs48705.2020.9074408]
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Battiato S, 2011, IEEE INT CON MULTI
   Battiato S, 2012, IEEE T INF FOREN SEC, V7, P1105, DOI 10.1109/TIFS.2012.2194285
   Bayram S, 2005, IEEE IMAGE PROC, P2793
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bilal M, 2020, ARAB J SCI ENG, V45, P2975, DOI 10.1007/s13369-019-04238-2
   Bunk J, 2017, IEEE COMPUT SOC CONF, P1881, DOI 10.1109/CVPRW.2017.235
   Byun SW, 2019, IEEE ACCESS, V7, P100706, DOI 10.1109/ACCESS.2019.2931039
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P439, DOI 10.1016/j.patrec.2005.09.006
   Chen W, 2007, PROC SPIE, V6505, DOI 10.1117/12.704321
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Chennamma HR, 2011, INT J COMPUT SCI ISS, V2010
   Cheung YM, 2007, IEEE T CIRC SYST VID, V17, P1007, DOI 10.1109/TCSVT.2007.903553
   Choi KS, 2006, PROC SPIE, V6069, DOI 10.1117/12.649775
   Ciptasari RW, 2013, DIGIT INVEST, V10, P246, DOI 10.1016/j.diin.2013.06.014
   Davarzani R., 2015, J AI DATA MINING, V3, P21
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Ding WJ, 2019, MULTIMED TOOLS APPL, V78, P5305, DOI 10.1007/s11042-018-5732-z
   Dirik AE, 2007, 2007 IEEE WORKSHOP ON SIGNAL PROCESSING APPLICATIONS FOR PUBLIC SECURITY AND FORENSICS, P1
   Doegar A, 2020, J U SHANGHAI SCI TEC
   Fan W, 2012, EUR SIGNAL PR CONF, P1777
   Farid H., 2006, Digital image ballistics from JPEG quantization
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Farinella GM, 2015, LECT NOTES COMPUT SC, V9386, P464, DOI 10.1007/978-3-319-25903-1_40
   Fridrich J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P536, DOI 10.1109/MMCS.1999.778542
   Fridrich J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P404, DOI 10.1109/ICIP.1998.723401
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Fu DD, 2006, LECT NOTES COMPUT SC, V4283, P177
   Ghorbani M, 2011, 2011 18 INT C SYST S, P14
   Gill NK, 2017, INT CONF COMPUT
   Gong D., 2020, INT J ADV TRENDS COM, V9, P2861, DOI [DOI 10.30534/IJATCSE/2020/58932020, 10.30534/ijatcse/2020/58932020]
   Gopi ES, 2006, CAN CON EL COMP EN, P52
   Guo XC, 2007, LECT NOTES COMPUT SC, V4810, P755
   Guorui F, 2020, P 2020 12 INT C MACH, P266270
   Haghighi BB, 2020, COGN COMPUT, V12, P863, DOI 10.1007/s12559-019-09700-9
   Haipeng Chen, 2010, Proceedings of the 2010 Fifth International Conference on Frontier of Computer Science and Technology (FCST 2010), P131, DOI 10.1109/FCST.2010.90
   Hassanien AE, 2014, INTEL SYST REF LIBR, V70, P115, DOI 10.1007/978-3-662-43616-5_5
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   He ZW, 2011, PATTERN RECOGN LETT, V32, P1591, DOI 10.1016/j.patrec.2011.05.013
   Hosseini S, 2021, ARXIV PREPRINT ARXIV
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Hwei-Jen Lin, 2009, WSEAS Transactions on Signal Processing, V5, P188
   Johnson Micah K., 2007, Digital Watermarking. Proceedings 6th International Workshop, IWDW 2007, P19
   Johnson M.K., 2005, Proceedings of the 7th Workshop on Multimedia and Security, P1
   Johnson MK, 2007, LECT NOTES COMPUT SC, V4567, P311, DOI 10.1007/978-3-540-77370-2_21
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Kee E, 2010, IEEE INT WORKS INFOR
   Kharrazi M, 2004, IEEE IMAGE PROC, P709
   Kharrazi M, 2005, IEEE INT C IMAGE PRO, P6972
   Kim C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11031146
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Kundur D, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P409, DOI 10.1109/ICIP.1998.723403
   Langille A, 2006, 3 CAN C COMP ROB VIS, P6464
   Laouamer Lamri, 2015, Journal of Innovation in Digital Ecosystems, V2, P1, DOI 10.1016/j.jides.2015.10.001
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li HD, 2019, IEEE I CONF COMP VIS, P8300, DOI 10.1109/ICCV.2019.00839
   Li Weng, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P380, DOI 10.1109/ICME.2012.163
   Li X, 2010, 2010 IEEE INT C INF
   Lin CY, 2000, PROC SPIE, V3971, P140, DOI 10.1117/12.384968
   Lin HJ, 2009, ELE COM ENG, P250
   Lin HYS, 2005, IEEE T MULTIMEDIA, V7, P997, DOI 10.1109/TMM.2005.858412
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu B, 2018, P ECCV WORKSH, P0
   Liu GJ, 2011, J NETW COMPUT APPL, V34, P1557, DOI 10.1016/j.jnca.2010.09.001
   Liu Q, 2009, P 1 ACM WORKSH MULT, P43, DOI [10.1145/1631081.1631092, DOI 10.1145/1631081.1631092]
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Liu XL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122029
   Long YJ, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P419, DOI 10.1109/MMSP.2006.285343
   Lou DC, 2000, IEEE T CONSUM ELECTR, V46, P31, DOI 10.1109/30.826378
   Lourembam A, 2021, MALAYA J MAT, P2330
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Lu WJ, 2010, IEEE IMAGE PROC, P989, DOI 10.1109/ICIP.2010.5650613
   Lu W, 2010, PROC SPIE, V7541, DOI 10.1117/12.838745
   Luk J, 2003, P DIG FOR RES WORKSH, P58
   Luo WQ, 2006, INT C PATT RECOG, P746
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Lv YD, 2011, J SUPERCOMPUT, V58, P50, DOI 10.1007/s11227-010-0531-y
   Lynch G, 2013, INFORM SCIENCES, V239, P253, DOI 10.1016/j.ins.2013.03.028
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Mazaheri Ghazal, 2019, IEEE C COMP VIS PATT
   Mohammed TM., 2018, ELECT IMAGING, V2018, P118
   Molina-Garcia J, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115725
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Muzaffer G, 2019, 2019 SCIENTIFIC MEETING ON ELECTRICAL-ELECTRONICS & BIOMEDICAL ENGINEERING AND COMPUTER SCIENCE (EBBT), DOI 10.1109/ebbt.2019.8741657
   Myna AN, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P371, DOI 10.1109/ICCIMA.2007.271
   Ng TT, 2009, IEEE INT WORKS INFOR, P161, DOI 10.1109/WIFS.2009.5386461
   Ng TT, 2009, IEEE INT WORKS INFOR, P156, DOI 10.1109/WIFS.2009.5386464
   Ng TT, 2004, IEEE IMAGE PROC, P1169
   Ng TT, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P688
   Ng TT, 2005, P 13 ANN ACM INT C M
   Nguyen T.N., 2019, ARXIV PREPRINT ARXIV
   ORuanaidh JJK, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P536, DOI 10.1109/ICIP.1997.647968
   Pal P, 2021, WIRELESS PERS COMMUN, V121, P939, DOI 10.1007/s11277-021-08666-y
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Paquet AH, 2002, IEEE CCEC 2002: CANADIAN CONFERENCE ON ELECTRCIAL AND COMPUTER ENGINEERING, VOLS 1-3, CONFERENCE PROCEEDINGS, P879, DOI 10.1109/CCECE.2002.1013058
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Pickett J., 2000, AM HERITAGE DICT, V4th
   Popescu A, 2004, COMPUTER SCI TECHNIC
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Prasad S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1325, DOI 10.1109/ICME.2006.262783
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Pun CM, 2018, MULTIMED TOOLS APPL, V77, P11609, DOI 10.1007/s11042-017-4809-4
   Qu ZH, 2009, LECT NOTES COMPUT SC, V5806, P247
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Rao MP, 2014, IEEE T INF FOREN SEC, V9, P583, DOI 10.1109/TIFS.2014.2302895
   Rao Y, 2016, IEEE INT WORKS INFOR
   Roy S, 2007, IEEE IMAGE PROC, P2913
   Sadeghi S, 2018, PATTERN ANAL APPL, V21, P291, DOI 10.1007/s10044-017-0678-8
   Sameer VU, 2018, LECT NOTES COMPUT SC, V11281, P291, DOI 10.1007/978-3-030-05171-6_15
   Sameer VU, 2018, IET IMAGE PROCESS, V12, P1204, DOI 10.1049/iet-ipr.2017.1142
   Sekeh MA, 2013, DIGIT INVEST, V10, P73, DOI 10.1016/j.diin.2013.02.007
   Shao H, 2012, FORENSIC SCI INT, V222, P71, DOI 10.1016/j.forsciint.2012.05.002
   Shin J, 2014, IEEE IMAGE PROC, P5292, DOI 10.1109/ICIP.2014.7026071
   Singh OP, 2021, MULTIMED TOOLS APPL, V80, P30367, DOI 10.1007/s11042-020-09606-x
   Sumalatha L., 2012, INT J COMPUT APPL, V49, P24
   Sutthiwan P, 2010, IEEE INT CON MULTI, P1463, DOI 10.1109/ICME.2010.5583264
   Tagliasacchi M, 2009, IEEE T IMAGE PROCESS, V18, P2491, DOI 10.1109/TIP.2009.2028251
   Tang S, 2005, LECT NOTES COMPUT SC, V3481, P547
   Tao Chen, 2001, 2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479), P78, DOI 10.1109/ICII.2001.983498
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Vinolin V, 2021, COMPUT J, V64, P1692, DOI 10.1093/comjnl/bxz148
   Wang H, 2011, PROTECTING PRIVACY IN CHINA: A RESEARCH ON CHINAS PRIVACY STANDARDS AND THE POSSIBILITY OF ESTABLISHING THE RIGHT TO PRIVACY AND THE INFORMATION PRIVACY PROTECTION LEGISLATION IN MODERN CHINA, P1, DOI 10.1007/978-3-642-21750-0_1
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang W, 2014, IEEE T INF FOREN SEC, V9, P1653, DOI 10.1109/TIFS.2014.2345479
   Wang XF, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115642
   Wang XF, 2015, IEEE T INF FOREN SEC, V10, P1336, DOI 10.1109/TIFS.2015.2407698
   Wang XF, 2012, J VIS COMMUN IMAGE R, V23, P782, DOI 10.1016/j.jvcir.2012.03.005
   Wang XF, 2012, COMPUT J, V55, P686, DOI 10.1093/comjnl/bxr108
   Wang XY, 2019, MATH BIOSCI ENG, V16, P4581, DOI 10.3934/mbe.2019229
   Wolfgang RB, 1999, P SOC PHOTO-OPT INS, V3657, P204, DOI 10.1117/12.344670
   Wolfgang RB, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P219, DOI 10.1109/ICIP.1996.560423
   Wong PW, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P374
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wu HC, 2022, MULTIMED TOOLS APPL, V81, P19351, DOI 10.1007/s11042-021-11018-4
   Wu M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P437, DOI 10.1109/ICIP.1998.723413
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Xuemin Wu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P600, DOI 10.1109/MINES.2011.135
   Yan CP, 2016, IEEE T INF FOREN SEC, V11, P2664, DOI 10.1109/TIFS.2016.2594136
   Yan CP, 2016, SIGNAL PROCESS, V121, P1, DOI 10.1016/j.sigpro.2015.10.027
   Yeo BL, 1999, IEEE COMPUT GRAPH, V19, P36, DOI 10.1109/38.736467
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Yeung MM, 1997, P INT C IMAGE PROCES, V2, P680683
   Ying QC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3565, DOI 10.1145/3474085.3475520
   Zhang H, 2017, J INF PROCESS SYST, V13, P385, DOI 10.3745/JIPS.03.0070
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang J, 2008, 2008 11TH IEEE SINGAPORE INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS (ICCS), VOLS 1-3, P362, DOI 10.1109/ICCS.2008.4737205
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
   Zhang Z, 2008, 2008 INT C COMPUTER, V1, P10351039
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhao X, 2011, STUD COMPUT INTELL, V346, P139
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
   Zhen Fang, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P923, DOI 10.1109/MINES.2010.196
NR 182
TC 4
Z9 4
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1873
EP 1904
DI 10.1007/s11042-022-13312-1
EA JUN 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000810329200001
DA 2024-07-18
ER

PT J
AU Jawahar, M
   Anbarasi, LJ
   Geetha, S
AF Jawahar, Malathy
   Anbarasi, L. Jani
   Geetha, S.
TI Vision based leather defect detection: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leather defect detection; Vision based approach; Image capture; Stages
   in leather processing; Leather quality classification
ID REFERENCE-STANDARD; NEURAL-NETWORK; CLASSIFICATION; IDENTIFICATION
AB Increasing consumer quality awareness and increase in consumer wealth drives the market demand for high quality leather and leather products. Reliable and effective detection and classification of leather surface defects is of profound significance to tanneries and industries where leather is a major raw material for leather accessories and leather parts manufacturers. This paper presents a methodical and a detailed review of the leather surface defects detection methods starting from leather image acquisition, leather image processing, feature extraction and classification for defect detection. Firstly, we introduce the fundamentals of leather image acquisition and various related image processing methods, feature extraction and classification for the defect inspection. Next, the existing datasets and summary of the recent methodologies used in this field are discussed. Finally, the challenges and suggested improvements to further the development of the application of advanced Machine Learning and Deep Learning in this field are discussed. Deep learning algorithms are shown to have a great potential for leather surface defect detection and can help prepare a robust system that would greatly guarantee quality leather and provide monetary wealth from such leather products. Finally, research guidelines are presented to fellow researchers regarding data augmentation, leather defect detection models which need to be investigated in the future to make progress in this crucial area of research.
C1 [Jawahar, Malathy] CSIR Cent Leather Res Inst, Leather Proc Technol Div, Chennai 600020, Tamil Nadu, India.
   [Anbarasi, L. Jani; Geetha, S.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
C3 Council of Scientific & Industrial Research (CSIR) - India; CSIR -
   Central Leather Research Institute (CLRI); Vellore Institute of
   Technology (VIT); VIT Chennai
RP Geetha, S (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
EM malathy.jawahar@gmail.com; janianbarasi.l@vit.ac.in;
   geethabaalan@gmail.com
RI l, j/JVZ-8480-2024; Jawahar, Dr. Malathy/AGF-0084-2022; L,
   J/JEF-9564-2023; S, Geetha/IYJ-9136-2023
OI Jawahar, Dr. Malathy/0000-0001-6865-2097; L, JANI
   ANBARASI/0000-0002-8904-2236
FU Ministry of Electronics and Information Technology (MeitY), Goverenment
   of India; CSIR-CLRI [A/2020/LPT/GAP1811/1374]
FX The authors gratefully acknowledge the Ministry of Electronics and
   Information Technology (MeitY), Goverenment of India for funding this
   research and Director, CSIR-CLRI for his support during the project.
   (A/2020/LPT/GAP1811/1374).
CR AHUJA N, 1981, IEEE T PATTERN ANAL, V3, P1, DOI 10.1109/TPAMI.1981.4767045
   Amorim, 2009, EMBRAPA PECURIA SUDE
   Amorim W. P., 2010, Proceedings of the 23rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2010), P353, DOI 10.1109/SIBGRAPI.2010.54
   [Anonymous], 1998, FAIR PROJ IMPR HID S
   Aslam M, 2019, IEEE ACCESS, V7, P176065, DOI 10.1109/ACCESS.2019.2957427
   Bowman CC, 1996, P SOC PHOTO-OPT INS, V2908, P33, DOI 10.1117/12.257274
   Branca A., 1997, Computer Analysis of Images and Patterns. 7th International Conference, CAIP '97. Proceedings, P223, DOI 10.1007/3-540-63460-6_121
   Branca A., 1997, Image Analysis and Processing. 9th International Conference, ICIAP '97 Proceedings, P584
   Branca A, 1996, P SOC PHOTO-OPT INS, V2908, P97, DOI 10.1117/12.257252
   Casey P, 2010, J SOC LEATH TECH CH, V94, P144
   CHETVERIKOV D, 1990, PATTERN RECOGN LETT, V11, P743, DOI 10.1016/0167-8655(90)90093-H
   DARWISH AM, 1988, IEEE T PATTERN ANAL, V10, P56, DOI 10.1109/34.3867
   Gonzalez R.C., 1978, SYNTACTIC PATTERN RE
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   He FQ, 2006, KEY ENG MATER, V326-328, P469, DOI 10.4028/www.scientific.net/KEM.326-328.469
   He Fuqiang, 2006, TECHNOLOGY INNOVATIO, P2024
   Ho CC, 2013, ADV MECH ENG, DOI 10.1155/2013/347921
   Hoang K, 1997, COMPUT IND, V34, P43, DOI 10.1016/S0166-3615(97)00019-5
   Bong HQ, 2018, PROCEEDINGS OF 2018 5TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS 2018), P300, DOI 10.1109/NICS.2018.8606836
   Jang-Woo Kwon, 2004, TENCON 2004. 2004 IEEE Region 10 Conference (IEEE Cat. No. 04CH37582), P327
   Jawahar M, 2021, MULTIMED TOOLS APPL, V80, P4203, DOI 10.1007/s11042-020-09727-3
   Jawahar M, 2016, IEEE I C COMP INT CO, P933
   Jian L., 2010, P 2010 INT C COMP DE, V2, pV2, DOI DOI 10.1109/ICCDA.2010.5541405
   Kasi M.K., 2014, 2014 International Conference on High Performance Computing and Applications (ICHPCA), P1
   Krastev K, 2006, P INT C COMP SYST TE
   Krastev K, 2005, P INT C COMP SYST TE
   Krastev K., 2004, Energy, V2, P1
   Kumar A, 2001, IEEE IND APPLIC SOC, P247, DOI 10.1109/IAS.2001.955418
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Kwak C, 2000, J INTELL MANUF, V11, P485, DOI 10.1023/A:1008974314490
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Lerch A., 1991, Engineering Applications of Artificial Intelligence, V4, P433, DOI 10.1016/0952-1976(91)90032-2
   Limas Serafim A. F., 1992, Proceedings of the 1992 International Conference on Industrial Electronics, Control, Instrumentation, and Automation. Power Electronics and Motion Control (Cat. No.92CH3137-7), P716, DOI 10.1109/IECON.1992.254544
   LIMASSERAFIM AF, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1357, DOI 10.1109/IECON.1993.339265
   Liong ST, 2020, INT J COMPUT INTEG M, V33, P1105, DOI 10.1080/0951192X.2020.1795928
   Lovergine FP, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P669, DOI 10.1109/ICIP.1997.638584
   Neto, 2004, INT C INF TECHN BAL
   Peters Stefanie, 2007, 7th International Conference on Hybrid Intelligent Systems, HIS 2007, P326
   Pistori H, 2007, PROC MONOGR ENG WATE, P355
   POLZLEITNER W, 1994, P SOC PHOTO-OPT INS, V2347, P50, DOI 10.1117/12.188759
   Qingyuan Wang, 1992, Proceedings of the IEEE International Symposium on Industrial Electronics (Cat. No.92TH0371-5), P304, DOI 10.1109/ISIE.1992.279565
   Rao A.R., 2012, TAXONOMY TEXTURE DES
   SERAFIM AFL, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P41, DOI 10.1109/ICPR.1992.201923
   SERAFIM AFL, 1991, IECON 91, VOLS 1-3, P1842
   Sobral, 2005, IB C PATT REC IM AN
   Tafuri M, 1996, P SOC PHOTO-OPT INS, V2665, P108, DOI 10.1117/12.232232
   Tofang-Sazi K, 2001, Intell. Data Anal., V5, P355
   Tuceryan M., 1993, Handbook of Pattern Recognition and Computer Vision, P235, DOI [DOI 10.1142/9789814343138_0010, 10.1142/97898143431380010, DOI 10.1142/97898143431380010]
   Viana, 2007, PAC RIM S IM VID TEC
   Villar, 2011, IB C PATT REC BERL H
   Wang L, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1765
   Winiarti S, 2018, INT J ADV COMPUT SC, V9, P212
   Yeh C, 2005, INT J ADV MANUF TECH, V25, P1197, DOI 10.1007/s00170-003-1945-y
   Yeh C, 2001, INT J ADV MANUF TECH, V18, P731, DOI 10.1007/s001700170016
   ZHANG YXF, 1995, TEXT RES J, V65, P1, DOI 10.1177/004051759506500101
NR 58
TC 2
Z9 2
U1 11
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 989
EP 1015
DI 10.1007/s11042-022-13308-x
EA JUN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000809534700005
DA 2024-07-18
ER

PT J
AU Feng, ZN
   González, VA
   Mutch, C
   Amor, R
   Cabrera-Guerrero, G
AF Feng, Zhenan
   Gonzalez, Vicente A.
   Mutch, Carol
   Amor, Robert
   Cabrera-Guerrero, Guillermo
TI Exploring spiral narratives with immediate feedback in immersive virtual
   reality serious games for earthquake emergency training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Immersive Virtual Reality; Serious Games; Earthquake training;
   Problem-based gaming; Narrative
ID PREPAREDNESS; PERFORMANCE; WORK; VS.
AB Various attempts and approaches have been made to teach individuals about the knowledge of best practice for earthquake emergencies. Among them, Immersive Virtual Reality Serious Games (IVR SGs) have been suggested as an effective tool for emergency training. The notion of IVR SGs is consistent with the concept of problem-based gaming (PBG), where trainees interact with games in a loop of forming a playing strategy, applying the strategy, observing consequences, and making reflection. PBG triggers reflection-on-action, enabling trainees to reform perceptions and establish knowledge after making a response to a scenario. However, in the literature of PBG, little effort has been made for trainees to reflect while they are making a response (i.e., reflection-in-action) in a scenario. In addition, trainees do not have the possibility to adjust their responses and reshape their behaviors according to their reflection-in-action. In order to overcome these limitations, this study proposes a game mechanism, which integrates spiral narratives with immediate feedback, to underpin reflection-in-action and reflective redo in PBG. An IVR SG training system suited to earthquake emergency training was developed, incorporating the proposed game mechanism. A controlled experiment with 99 university students and staff was conducted. Participants were divided into three groups, with three interventions tested: a spiral narrated IVR SG, a linear narrated IVR SG, and a leaflet. Both narrated IVR SGs were effective in terms of immediate knowledge gain and self-efficacy improvement. However, challenges and opportunities for future research have been suggested.
C1 [Feng, Zhenan; Gonzalez, Vicente A.] Univ Auckland, Dept Civil & Environm Engn, Auckland, New Zealand.
   [Feng, Zhenan] Massey Univ, Sch Built Environm, Auckland, New Zealand.
   [Mutch, Carol] Univ Auckland, Dept Crit Studies Educ, Auckland, New Zealand.
   [Amor, Robert] Univ Auckland, Dept Comp Sci, Auckland, New Zealand.
   [Cabrera-Guerrero, Guillermo] Pontificia Univ Catolica Valparaiso, Escuela Ingn Informat, Valparaiso, Chile.
C3 University of Auckland; Massey University; University of Auckland;
   University of Auckland; Pontificia Universidad Catolica de Valparaiso
RP Feng, ZN (corresponding author), Univ Auckland, Dept Civil & Environm Engn, Auckland, New Zealand.; Feng, ZN (corresponding author), Massey Univ, Sch Built Environm, Auckland, New Zealand.
EM z.feng1@massey.ac.nz; v.gonzalez@auckland.ac.nz; c.mutch@auckland.ac.nz;
   trebor@cs.auckland.ac.nz; guillermo.cabrera@pucv.cl
RI Amor, Robert/L-9611-2019; Feng, Zhenan/N-1336-2018
OI Amor, Robert/0000-0002-4329-9044; Feng, Zhenan/0000-0001-7513-8942
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Admiraal W, 2011, COMPUT HUM BEHAV, V27, P1185, DOI 10.1016/j.chb.2010.12.013
   [Anonymous], 2018, Understanding Virtual Reality: Interface Application, and Design
   Asgari M., 2004, Relationships among computer games, fantasy, and learning
   Baird L, 1999, ORGAN DYN, V27, P19, DOI 10.1016/S0090-2616(99)90027-X
   Bandura A., 2010, Self-efficacy. The Corsini encyclopedia of psychology
   BECK LA, 1992, J LEISURE RES, V24, P93, DOI 10.1080/00222216.1992.11969876
   Bemardini G, 2016, SAFETY SCI, V86, P273, DOI 10.1016/j.ssci.2016.03.010
   Boud D, 2013, Reflection: Turning experience into learning
   Bransford J.D., 1990, COGNITION ED MULTIME
   Brown AL., 1980, THEORETICAL ISSUES R
   Brown AS, 1999, J EDUC PSYCHOL, V91, P756, DOI 10.1037/0022-0663.91.4.756
   Burigat S, 2016, INT J HUM-COMPUT ST, V87, P92, DOI 10.1016/j.ijhcs.2015.11.004
   Butler AC, 2008, MEM COGNITION, V36, P604, DOI 10.3758/MC.36.3.604
   Chatman Seymour, 1978, STORY DISCOURS NARRA
   Chittaro L, 2015, COMPUT HUM BEHAV, V50, P508, DOI 10.1016/j.chb.2015.03.074
   Chittaro L, 2015, IEEE T VIS COMPUT GR, V21, P529, DOI 10.1109/TVCG.2015.2391853
   Cohen B.H., 2001, EXPLAINING PSYCHOL S, V2nd
   Daniel C, 2020, DICT MEDIA COMMUNICA
   Engle RA, 2012, EDUC PSYCHOL-US, V47, P215, DOI 10.1080/00461520.2012.695678
   Feng Z, 2018, 18 INT C CONSTR APPL
   Feng ZA, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101134
   Feng ZN, 2021, J COMPUT ASSIST LEAR, V37, P542, DOI 10.1111/jcal.12507
   Feng ZA, 2020, ADV ENG INFORM, V45, DOI 10.1016/j.aei.2020.101118
   Feng ZN, 2020, SAFETY SCI, V129, DOI 10.1016/j.ssci.2020.104837
   Feng ZA, 2018, COMPUT EDUC, V127, P252, DOI 10.1016/j.compedu.2018.09.002
   Ferguson C, 2020, COMPUT EDUC, V143, DOI 10.1016/j.compedu.2019.103671
   Finn B, 2011, PSYCHOL SCI, V22, P781, DOI 10.1177/0956797611407932
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   GeoNet, 2019, EARTHQUAKE INTENSITY
   Gobel S, 2010, LECT NOTES COMPUT SC, V6249, P438, DOI 10.1007/978-3-642-14533-9_45
   GREENWOOD J, 1993, J ADV NURS, V18, P1183, DOI 10.1046/j.1365-2648.1993.18081183.x
   Hahgood MPJ, 2005, SIMULAT GAMING, V36, P483, DOI 10.1177/1046878105282276
   Iuppa Nick., 2012, Story and simulations for serious games: Tales from the trenches
   Johnson CI, 2014, FEEDBACK PRINCIPLE M
   Kensinger EA, 2009, EMOT REV, V1, P99, DOI 10.1177/1754073908100432
   Khan KS, 2001, MED TEACH, V23, P158
   Kiili K, 2007, BRIT J EDUC TECHNOL, V38, P394, DOI 10.1111/j.1467-8535.2007.00704.x
   Krathwohl D.R., 2009, A taxonomy for learning, teaching, and assessing: A revision of Bloom's taxonomy of educational objectives
   Li CY, 2017, IEEE T VIS COMPUT GR, V23, P1388, DOI 10.1109/TVCG.2017.2656958
   Lim T, 2014, LECT NOTES COMPUT SC, V8395, P23, DOI 10.1007/978-3-319-05972-3_4
   Lin J, 2019, ADV ENG INFORM, V39, P53, DOI 10.1016/j.aei.2018.11.007
   Lovreglio R, 2018, ADV ENG INFORM, V38, P670, DOI 10.1016/j.aei.2018.08.018
   Moon J.A., 2013, Reflection in learning and professional development: Theory and practice
   Nakamura J., 2002, Handbook of Positive Psychology, DOI DOI 10.1007/978-94-017-9088-8_16
   National Research Council, 2000, PEOPLE LEARN BRAIN M
   New Zealand Ministry of Civil Defence & Emergency Management, 2015, WORK SAM PAG CONS B
   Padilla-Zea N, 2014, COMPUT HUM BEHAV, V31, P461, DOI 10.1016/j.chb.2013.04.020
   Ragavan S. Veera, 2011, 2011 IEEE Recent Advances in Intelligent Computational Systems (RAICS 2011), P756, DOI 10.1109/RAICS.2011.6069411
   Regan C., 1995, VIRTUAL REAL-LONDON, V1, P17, DOI DOI 10.1007/BF02009710
   Romano DM, 2001, CYBERPSYCHOL BEHAV, V4, P265, DOI 10.1089/109493101300117947
   Schon D.A, 1984, The reflective practitioner: How professionals think in action, V5126
   Schulteis MT., 2003, ETHICAL ISSUES CLIN
   Schwarzer R., 2010, Anxiety Stress Coping, V12, P329, DOI DOI 10.1037/T18916-000
   Scoresby J, 2014, SIMULAT GAMING, V45, P666, DOI 10.1177/1046878114549426
   Sharot T, 2004, NAT NEUROSCI, V7, P1376, DOI 10.1038/nn1353
   Sharples S, 2008, DISPLAYS, V29, P58, DOI 10.1016/j.displa.2007.09.005
   Smith S, 2009, VIRTUAL REAL-LONDON, V13, P87, DOI 10.1007/s10055-009-0113-6
   Stajkovic AD, 1998, PSYCHOL BULL, V124, P240, DOI 10.1037/0033-2909.124.2.240
   Starks Katryna, 2014, Front Psychol, V5, P28, DOI 10.3389/fpsyg.2014.00028
   Stauffert JP, 2020, FRONT VIRTUAL REAL, V1, DOI 10.3389/frvir.2020.582204
   Stein D., 1998, ERIC DIGEST
   United States Geological Survey, 2018, EARTHQ FACTS
NR 62
TC 8
Z9 8
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 125
EP 147
DI 10.1007/s11042-022-13306-z
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000805749700002
OA hybrid
DA 2024-07-18
ER

PT J
AU Lu, SZ
   Wang, SS
   Wang, GY
AF Lu, Shuzhen
   Wang, Shengsheng
   Wang, Guangyao
TI Automated universal fractures detection in X-ray images based on deep
   learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fracture detection CAD system; ResNeSt; Bidirectional feature pyramid;
   Cascade R-CNN
AB At present, bone fracture is a common clinical disease, while the missed diagnosis or misdiagnosis of fracture is harmful to the recovery of patients. Fracture diagnosis often needs the X-ray image as an assistive tool and many fracture detection CAD systems on X-ray images have been explored. However, the majority of existing works mainly focus on detecting fractures in a specific human body part. It's desirable and feasible to propose a more practical system that can detect various anatomical region fractures ideally due to their similar general fracture characteristics. In this paper, a universal fracture detection CAD system has been developed by us on X-ray images based on the deep learning method. Firstly, we design an image preprocessing method to improve the poor quality of these X-ray images and employ several data augmentation strategies to enlarge the used dataset. Secondly, based on our modified Ada-ResNeSt backbone network and the AC-BiFPN detection method, we propose our automatic fracture detection system. Finally, we establish a private universal fracture detection dataset MURA-D based on the public dataset MURA. As demonstrated by our comprehensive experiments, compared with other popular detectors, our method achieved a higher detection AP of 68.4% with an acceptable inference speed of 122 ms per image on the MURA-D test set, achieving promising results among the state-of-the-art detectors.
C1 [Lu, Shuzhen; Wang, Shengsheng; Wang, Guangyao] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Lu, Shuzhen; Wang, Shengsheng; Wang, Guangyao] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University
RP Wang, SS (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.; Wang, SS (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
EM lusz19@mails.jlu.edu.cn; wss@jlu.edu.cn; wanggy15@mails.jlu.edu.cn
FU Innovation Capacity Construction Project of Jilin Province Development
   and Reform Commission [2021FGWCXNLJSSZ10]; National Key Research and
   Development Program of China [2020YFA0714103]; Science & Technology
   Development Project of Jilin Province, China [20190302117GX];
   Fundamental Research Funds for the Central Universities
FX This work is supported by the Innovation Capacity Construction Project
   of Jilin Province Development and Reform
   Commission(2021FGWCXNLJSSZ10),the National Key Research and Development
   Program of China (No. 2020YFA0714103) and the Science & Technology
   Development Project of Jilin Province, China (20190302117GX),the
   Fundamental Research Funds for the Central Universities, JLU.
CR Adams M, 2019, J MED IMAG RADIAT ON, V63, P27, DOI 10.1111/1754-9485.12828
   Al-Ayyoub M., 2013, JMPT, V4, P155
   Beyaz S, 2020, JOINT DIS RELAT SURG, V31, P175, DOI 10.5606/ehc.2020.72163
   Bhalke JS., 2014, INT J COMPUTER APPL, V89, P47, DOI [10.5120/15534-4444, DOI 10.5120/15534-4444]
   Cao J, 2020, P IEEE C COMPUTER VI
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   Chung SW, 2018, ACTA ORTHOP, V89, P468, DOI 10.1080/17453674.2018.1453714
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Donnelley M, 2008, LECT NOTES COMPUT SC, V5099, P153, DOI 10.1007/978-3-540-69905-7_18
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gale W., 2017, ARXIV PREPRINT ARXIV
   Gan KF, 2019, ACTA ORTHOP, V90, P394, DOI 10.1080/17453674.2019.1600125
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Guan B, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106530
   Guan B, 2019, PATTERN RECOGN LETT, V125, P521, DOI 10.1016/j.patrec.2019.06.015
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Kim DH, 2018, CLIN RADIOL, V73, P439, DOI 10.1016/j.crad.2017.11.015
   Le QV, 2019, Learning data augmentation strategies for object detection
   Lim S.E., 2004, P 2 INT C ADV MED SI, VVolume 65
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lindsey R, 2018, P NATL ACAD SCI USA, V115, P11591, DOI 10.1073/pnas.1806905115
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mahendran SK., 2012, INT J ENG TECHNOLOGY, V4, P7, DOI [10.7763/IJET.2012.V4.310, DOI 10.7763/IJET.2012.V4.310]
   Mayne R, 2013, IDENTIFY FRACTURE TY
   Myint WW, 2018, MACH LEARN RES, V3, P49, DOI [10.11648/j.mlr.20180303.11, DOI 10.11648/J.MLR.20180303.11]
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pranata YD, 2019, COMPUT METH PROG BIO, V171, P27, DOI 10.1016/j.cmpb.2019.02.006
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao QB, 2019, LECT NOTES COMPUT SC, V11769, P301, DOI 10.1007/978-3-030-32226-7_34
   Tan M., 2019, ARXIV190709595
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tomita N, 2018, COMPUT BIOL MED, V98, P8, DOI 10.1016/j.compbiomed.2018.05.011
   Urakawa T, 2019, SKELETAL RADIOL, V48, P239, DOI 10.1007/s00256-018-3016-3
   Vishnu V, 2015, INT J APPL ENG RES, V10
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan K, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.3.036501
   Yang, 2019, ARXIV PREPRINT ARXIV
   Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968
   Zhang H, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP), P1541
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zlocha M, 2019, LECT NOTES COMPUT SC, V11769, P402, DOI 10.1007/978-3-030-32226-7_45
NR 45
TC 5
Z9 5
U1 2
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44487
EP 44503
DI 10.1007/s11042-022-13287-z
EA JUN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805908000001
DA 2024-07-18
ER

PT J
AU Diwan, T
   Tembhurne, JV
AF Diwan, Tausif
   Tembhurne, Jitendra V.
TI Sentiment analysis: a convolutional neural networks perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; Emotion detection; Convolutional neural network;
   Deep learning; Social network analysis
ID LEXICON; MODEL; CLASSIFICATION; ALGORITHMS
AB With the dramatic growth of various social media platforms, sentiment analysis (SA) of and emotion detection (ED) in various social network posts, blogs, and conversations are very useful and effective for mining the true opinions on different issues, entities, or aspects. During the last decade, many statistical and probabilistic models based on lexical and machine learning approaches have been employed for these tasks. Majority of the relevant literature has emphasized on improving the contemporary SA determination and emotion extraction techniques. With the recent advancements in deep neural networks, various deep learning models have been heavily used to enhance the accuracy of SA. Convolutional neural networks (CNN), a deep neural network model formerly adopted for visual data processing only, has recently gained acceptance for textual inputs as well. As the inputs for SA may be textual, visual, or any combination of these, CNN seems to be a powerful tool. Capturing spatial and contextual information in an incremental fashion respectively from visual and textual inputs proves CNN as an effective model for SA. In this paper, we present an extensive survey that covers the applicability, challenges, and issues for textual, visual, and multimodal SA using CNNs. A detailed discussion and analysis for SA using a CNN model is summarized. For both of the unimodal inputs i.e., textual and visual, we present an optimized algorithmic approach for SA determination using CNN.
C1 [Diwan, Tausif; Tembhurne, Jitendra V.] Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
RP Diwan, T (corresponding author), Indian Inst Informat Technol, Dept Comp Sci & Engn, Nagpur, India.
EM tausif.diwan@cse.iiitn.ac.in; jitendra.tembhurne@cse.iiitn.ac.in
RI Diwan, Tausif/AFN-9746-2022; Tembhurne, Jitendra/AGI-1097-2022
OI Tembhurne, Jitendra/0000-0002-1389-3456
CR Albelwi S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060242
   [Anonymous], 2016, ARXIV161008815
   [Anonymous], IMDBCOM TRAFFIC DEMO
   [Anonymous], 2016, P 26 INT C COMP LING
   [Anonymous], WISSNER GROSS DATASE
   Arora M, 2019, SOC NETW ANAL MIN, V9, DOI 10.1007/s13278-019-0557-y
   Bai X, 2011, DECIS SUPPORT SYST, V50, P732, DOI 10.1016/j.dss.2010.08.024
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P452
   Balamurali AR., 2011, P 2 WORKSH COMP APPR, P132
   Balaprakash P, 2018, INT C HIGH PERFORM, P42, DOI 10.1109/HiPC.2018.00014
   Bamman David, 2015, P INT AAAI C WEB SOC, V9
   Beel J, 2016, INT J DIGIT LIBRARIE, V17, P305, DOI 10.1007/s00799-015-0156-0
   Bengio Y., 2012, ABS12065538 CORR, V1, P5538
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Cambria Erik., 2015, Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), P647
   CHEN PC, 1979, COMPUT VISION GRAPH, V10, P172, DOI 10.1016/0146-664X(79)90049-2
   Chen T, 2014, ARXIV PREPRINT ARXIV
   Chen T, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P367, DOI 10.1145/2647868.2654935
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Dahou A, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/2537689
   Deng L, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/atsip.2013.9
   Deriu J, 2016, P 10 INT WORKSH SEM, P1124, DOI DOI 10.18653/V1/S16-1173
   Dermouche M, 2014, IEEE DATA MINING, P773, DOI 10.1109/ICDM.2014.82
   Devaraj M, 2016, IETE TECH REV, V33, P332, DOI 10.1080/02564602.2015.1073572
   Dos Santos C., 2014, Coling, P69
   Fang X, 2015, Journal of Big Data, V2, P5, DOI 10.1186/s40537-015-0015-2
   Fink CR, 2011, J HOPKINS APL TECH D, V30, P22
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Gan CQ, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.06.035
   Go Alec., 2009, CS224N project report 1.12
   Hagenau M, 2013, DECIS SUPPORT SYST, V55, P685, DOI 10.1016/j.dss.2013.02.006
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Hao YB, 2020, IEEE T KNOWL DATA EN, V32, P1909, DOI 10.1109/TKDE.2019.2913379
   He YL, 2011, INFORM PROCESS MANAG, V47, P606, DOI 10.1016/j.ipm.2010.11.003
   Heerschop B., 2011, Proceedings of the 20th ACM International Conference on Information and Knowledge Management CIKM, P1061, DOI [10.1145/2063576.2063730, DOI 10.1145/2063576.2063730]
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu Y, 2011, COMPUT SPEECH LANG, V25, P386, DOI 10.1016/j.csl.2010.07.004
   Huang M., 2020, IEEE Transactions on Affective Computing
   Huang MH, 2020, INFORM SCIENCES, V520, P389, DOI 10.1016/j.ins.2020.02.026
   Hussein Doaa Mohey El-Din Mohamed, 2018, Journal of King Saud University - Engineering Sciences, V30, P330, DOI 10.1016/j.jksues.2016.04.002
   images, About us
   Jin RZ, 2019, COMPUT INTELL-US, V35, P599, DOI 10.1111/coin.12225
   Kang H, 2012, EXPERT SYST APPL, V39, P6000, DOI 10.1016/j.eswa.2011.11.107
   Karpathy Andrej, 2011, Lessons Learned From Manually Classi- fying CIFAR-10
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JS, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P793, DOI 10.1145/2733373.2807966
   Liao SY, 2017, PROCEDIA COMPUT SCI, V111, P376, DOI 10.1016/j.procs.2017.06.037
   Liu B, 2010, CH CRC MACH LEARN PA, P627
   Liu M, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2355
   Maks I, 2012, DECIS SUPPORT SYST, V53, P680, DOI 10.1016/j.dss.2012.05.025
   Markoff J., 2012, NEW YORK TIMES
   McAuley J., 2013, P 7 ACM C REC SYST, P165, DOI DOI 10.1145/2507157.2507163
   Medhat W, 2014, AIN SHAMS ENG J, V5, P1093, DOI 10.1016/j.asej.2014.04.011
   Mikolov Tomas, 2013, EFFICIENT ESTIMATION
   Moreo A, 2012, EXPERT SYST APPL, V39, P9166, DOI 10.1016/j.eswa.2012.02.057
   Neviarouskaya A, 2010, P 23 INT C COMPUTATI, P80681
   Ning Y, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1095, DOI 10.1145/2939672.2939802
   Ortigosa A, 2014, COMPUT HUM BEHAV, V31, P527, DOI 10.1016/j.chb.2013.05.024
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Plutchik, US
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2016, IEEE DATA MINING, P439, DOI [10.1109/ICDM.2016.178, 10.1109/ICDM.2016.0055]
   Poria S, 2016, KNOWL-BASED SYST, V108, P42, DOI 10.1016/j.knosys.2016.06.009
   Poursepanj H., 2013, Second Joint Conference on Lexical and Computational Semantics, P380
   Rakhlin A, 2016, Convolutional Neural Networks for Sentence Classification
   Rao TR, 2019, NEUROCOMPUTING, V333, P429, DOI 10.1016/j.neucom.2018.12.053
   Ren YF, 2016, AAAI CONF ARTIF INTE, P215
   Rojas-Barahona LM, 2016, LANG LINGUIST COMPAS, V10, P701, DOI 10.1111/lnc3.12228
   Rong X, 2014, ARXIV PREPRINT ARXIV
   Sarkar K, 2019, J INTELL SYST, V28, P377, DOI 10.1515/jisys-2017-0418
   Severyn A, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P959, DOI 10.1145/2766462.2767830
   Shu XB, 2017, NEUROCOMPUTING, V236, P153, DOI 10.1016/j.neucom.2016.09.110
   Soleymani M, 2017, IMAGE VISION COMPUT, V65, P3, DOI 10.1016/j.imavis.2017.08.003
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tang DY, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1014
   Tang DY, 2015, WSDM'15: PROCEEDINGS OF THE EIGHTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P447, DOI 10.1145/2684822.2697035
   Tang DY, 2015, WIRES DATA MIN KNOWL, V5, P292, DOI 10.1002/widm.1171
   Tang DY, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1555
   Tang Duyu., 2014, International Workshop on Semantic Evaluation, P208
   Vinodhini G, 2012, International Journal, V2, P282
   Wang Jingwen., 2016, IJCAI, P3484
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xiangbo Shu, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P114, DOI 10.1007/978-3-319-27671-7_10
   Xu C, 2014, ARXIV PREPRINT ARXIV
   Xu JG, 2015, IETE TECH REV, V32, P131, DOI 10.1080/02564602.2014.987328
   Yadav A, 2020, ARTIF INTELL REV, V53, P4335, DOI 10.1007/s10462-019-09794-5
   Yang ZM, 2016, ALGORITHMS, V9, DOI 10.3390/a9010009
   You QZ, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P13, DOI 10.1145/2835776.2835779
   You QZ, 2015, AAAI CONF ARTIF INTE, P381
   Yu LC, 2013, KNOWL-BASED SYST, V41, P89, DOI 10.1016/j.knosys.2013.01.001
   Zhang X, 2015, ADV NEUR IN, V28
   Zhao JQ, 2018, IEEE ACCESS, V6, P23253, DOI 10.1109/ACCESS.2017.2776930
NR 93
TC 5
Z9 5
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44405
EP 44429
DI 10.1007/s11042-021-11759-2
EA JUN 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805749900003
DA 2024-07-18
ER

PT J
AU Bhavsar, SA
   Patil, VH
   Patil, AH
AF Bhavsar, Swati A.
   Patil, Varsha H.
   Patil, Aboli H.
TI Graph partitioning and visualization in graph mining: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph mining; Graph classification; Graph partitioning; Graph datasets
ID MATRIX-VECTOR MULTIPLICATION; SPECTRAL-ANALYSIS; NORMALIZED CUTS;
   INFORMATION; CLASSIFICATION; EIGENVECTORS; ALGORITHMS; SUBGRAPHS;
   NUMBER; MODEL
AB Graph mining is a process of obtaining one or more sub-graphs and has been a very attractive research topic over the last two decades. It has found many practical applications dealing with real world problems in variety of domains like Social Network Analysis, Designing of Computer Networks, Study of Chemical Reactions, Bio Informatics, Program Flow Structures, Image Processing, Enterprise data, Sparse Matrix ordering and many more. For these applications, many graph classification and Graph Clustering algorithms are evolved. This paper presents a comprehensive survey of published work in Graph Mining by grouping them in a broad taxonomy. For each of these groups in the taxonomy, the basic concepts of the algorithms are covered in detail by mentioning the contributions of various authors to the basic concepts of each group. Furthermore, common issues in graph mining algorithms, such as clustering, partitioning, visualization of graphs, are also elaborated. Standard datasets available for graph mining are stated as well.
C1 [Bhavsar, Swati A.; Patil, Varsha H.; Patil, Aboli H.] SavitribaiPhule Pune Univ, MCERC, Res Ctr, Dept Comp Engn, Nasik, India.
RP Bhavsar, SA (corresponding author), SavitribaiPhule Pune Univ, MCERC, Res Ctr, Dept Comp Engn, Nasik, India.
EM bhavsar.swati4@gmail.com; varsha.patil@gmail.com;
   aboleee.patil@gmail.com
RI Patil, Varsha H/HPF-0651-2023; BHavsar, Swati/IUQ-5609-2023; Patil,
   Varsha H/AAD-8491-2020
OI Patil, Varsha H/0000-0002-4267-616X; Patil, Varsha H/0000-0002-4267-616X
CR Abello J, 2006, IEEE T VIS COMPUT GR, V12, P669, DOI 10.1109/TVCG.2006.120
   Abnar A, 2014, 2014 PROCEEDINGS OF THE IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2014), P289, DOI 10.1109/ASONAM.2014.6921599
   Aggarwal CC, 2010, ADV DATABASE SYST, V40, P1, DOI 10.1007/978-1-4419-6045-0
   Aggarwal CC, 2010, ADV DATABASE SYST, V40, P275, DOI 10.1007/978-1-4419-6045-0_9
   Alwahaishi S, 2011, ANAL DBLP PUBLICATIO
   Andreev K, 2006, THEOR COMPUT SYST, V39, P929, DOI 10.1007/s00224-006-1350-7
   [Anonymous], G-Store
   [Anonymous], 2014, THESIS LEIDEN U
   [Anonymous], 1988, P PAP 25 YEARS EL DE
   [Anonymous], DEKORTE
   [Anonymous], 1993, Technical Report SAND93-1301
   [Anonymous], FILAMENT
   [Anonymous], HORTON
   [Anonymous], 2013, P 25 INT C SCI STAT, DOI DOI 10.1145/2484838.2484843
   [Anonymous], CloudGraph
   [Anonymous], ALLEGROGRAPH
   [Anonymous], 1995, METIS UNSTRUCTURED G
   [Anonymous], 2004, P 10 ACM SIGKDD INT, DOI 10.1145/1014052.1014068
   [Anonymous], Giraph
   Auber D, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P75, DOI 10.1109/infvis.2003.1249011
   Ayati Marzieh, 2015, EURASIP J Bioinform Syst Biol, V2015, P7, DOI 10.1186/s13637-015-0025-6
   Baecker R., 1990, ART HUMAN COMPUTER I, P251
   Bansal N, 2004, MACH LEARN, V56, P89, DOI 10.1023/B:MACH.0000033116.57574.95
   Bapodra M, 2009, CO3120 COMPUTER SCI
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   BARNARD ST, 1994, CONCURRENCY-PRACT EX, V6, P101, DOI 10.1002/cpe.4330060203
   Batagelj V, 2011, IEEE T VIS COMPUT GR, V17, P1587, DOI 10.1109/TVCG.2010.265
   Benkö G, 2003, J CHEM INF COMP SCI, V43, P1085, DOI 10.1021/ci0200570
   Berlingerio M., 2009, GRAPH NETWORK DATA M
   Beucher Serge., 1979, INT WORKSHOP IMAGE P, P132
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   Borgatti SP, 2009, SCIENCE, V323, P892, DOI 10.1126/science.1165821
   Brath R, GRAPH ANAL VISUALIZA
   BUI TN, 1993, PROCEEDINGS OF THE SIXTH SIAM CONFERENCE ON PARALLEL PROCESSING FOR SCIENTIFIC COMPUTING, VOLS 1 AND 2, P445
   Bulò SR, 2013, IEEE T PATTERN ANAL, V35, P1312, DOI 10.1109/TPAMI.2012.226
   Callut J, 2008, **DATA OBJECT**, V5211
   Callut J, 2008, LECT NOTES ARTIF INT, V5211, P162, DOI 10.1007/978-3-540-87479-9_29
   Camps-Valls G., 2009, Kernel methods for remote sensing data analysis
   Chartrand G, 1993, Applied and Algorithmic Graph Theory
   CHENG CK, 1991, IEEE T COMPUT AID D, V10, P1502, DOI 10.1109/43.103500
   Clique BD, 2008, MATRICES STAT GRAPH, P2633
   Delest M, 2006, SYNASC 8 TH INT C
   Deo N., 2017, Graph theory with applications to engineering and computer science
   Dey S, GRAPH THEORY APPL
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Di Fatta G, 2005, LECT NOTES COMPUT SC, V3726, P866
   Diane Cook J, MINING GRAPH DATA
   Dias CR, 2003, IEEE C EVOL COMPUTAT, P983
   Dias CR, 2003, EFFICIENT EVOLUTIONA, P983
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Eades P., 2000, Journal of Graph Algorithms and Applications, V4, DOI 10.7155/jgaa.00029
   Eades P., 1997, Graph Drawing. Symposium on Graph Drawing, GD '96. Proceedings, P101
   Ellis G, 2007, IEEE T VIS COMPUT GR, V13, P1216, DOI 10.1109/TVCG.2007.70535
   Elmacioglu E, 2005, SIGMOD REC, V34, P33, DOI 10.1145/1083784.1083791
   Eppstein D, 2007, CONFLUENT LAYERED DR, V47
   Estrada E., 2013, CHEM GRAPH THEORY
   Faloutsos M, 1999, COMP COMM R, V29, P251, DOI 10.1145/316194.316229
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Feng QW, 1995, LECT NOTES COMPUT SC, V959, P21, DOI 10.1007/BFb0030816
   Finocchi I, 2002, THESIS U STUDI ROMA
   Fonseca F., 2003, P WORKSH SEM WEB TEC
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gao S, 2014, APPL MECH MATER, V443, P402, DOI 10.4028/www.scientific.net/AMM.443.402
   Garbers J., 1990, 1990 IEEE International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.90CH2924-9), P520, DOI 10.1109/ICCAD.1990.129970
   GAREY MR, 1983, SIAM J ALGEBRA DISCR, V4, P312, DOI 10.1137/0604033
   Gentilini R, 2003, SIAM PROC S, P573
   Golub G. H., 1983, MATRIX COMPUTATIONS
   Gomez Rodriguez M., 2010, SIGKDD, P1019
   Grzegorz R., 1997, Handbook Of Graph Grammars And Computing By Graph Transformation, Vol, V1
   Guo G, KNN MODEL BASED APPR, V112
   Guo P, 2014, IEEE T PARALL DISTR, V25, P1112, DOI 10.1109/TPDS.2013.123
   Hagen L., 1992, 1992 IEEE/ACM International Conference on Computer-Aided Design. Digest of Technical Papers (Cat. No.92CH03183-1), P422, DOI 10.1109/ICCAD.1992.279334
   Han J, 2006, P 12 TH ACM C KNOWLE
   Hans Othmer G., 1981, GRAPH THEORETIC ANAL, V84112, P1
   Haq A, 2015, APPLYING GRAPH MININ
   Harchaoui Z, IMAGE CLASSIFICATION, P16
   HAREL D, 1987, SCI COMPUT PROGRAM, V8, P231, DOI 10.1016/0167-6423(87)90035-9
   Heath MT, 1994, IN PRESS
   Hendrickson B, 1995, SUPERCOMP PROC, P626
   Ho J, 2006, DRAWING CLUSTERED GR
   Holten D, 2006, IEEE T VIS COMPUT GR, V12, P741, DOI 10.1109/TVCG.2006.147
   Horak Z., 2011, 2011 International Conference on Computational Aspects of Social Networks (CASoN 2011), P261, DOI 10.1109/CASON.2011.6085955
   Horak Z, 2011, INT C COMPUTATIONAL
   HUANG DJH, 1995, EUR CONF DESIG AUTOM, P60, DOI 10.1109/EDTC.1995.470419
   Huang ML, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P920, DOI 10.1109/ICIG.2007.10
   Jalali M, 2010, EXPERT SYST APPL, V37, P6201, DOI 10.1016/j.eswa.2010.02.105
   Jr Rodrigues., 2006, Proceedings of the 32Nd International Conference on Very Large Data Bases. VLDB '06. VLDB Endowment, P1195
   Kang U, 2014, IEEE T KNOWL DATA EN, V26, P350, DOI 10.1109/TKDE.2012.244
   Kannan R, 2004, J ACM, V51, P497, DOI 10.1145/990308.990313
   Kappes Jorg Hendrik, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P31, DOI 10.1007/978-3-642-23094-3_3
   Karypis G, 1998, SUP 1998 SC98 IEEE A
   Karypis G., 1995, P 1995 INT C PARALLE, P113
   Kashima H., 2002, ICDM WORKSH ACT MIN
   Kazimianec Michail, 2013, International Journal of Knowledge-Based Organizations, V3, P84, DOI 10.4018/ijkbo.2013100105
   Kernighan B. W., 1970, Bell System Technical Journal, V49, P291
   Ketkar N.S., 2009, EMPIRICAL COMP GRAPH
   Khuller S, 2009, LECT NOTES COMPUT SC, V5555, P597, DOI 10.1007/978-3-642-02927-1_50
   Kim S, 2003, COMPUTATIONAL BIOL G, P81116
   Kramer S., 2001, ICML, P258
   Kraus J. M., 2007, ROBUSTNESS SEMISUPER
   Krishnamurthy V, 2005, LECT NOTES COMPUT SC, V3462, P328
   Kudelka M., 2010, Proceedings of the 2010 International Conference on Computational Aspects of Social Networks (CASoN 2010), P509, DOI 10.1109/CASoN.2010.120
   Kudelka M, 2010, INT C COMPUTATIONAL
   Kulis B., 2005, P 11 ACM SIGKDD INT, P629634, DOI [DOI 10.1145/1081870.1081948, 10.1145/1081870.1081948]
   Laukens K, 2015, PROTEOMICS, V15, P981, DOI 10.1002/pmic.201400296
   Le TV, 2008, INT C PATT RECOG, P26
   Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387
   Leskovec Jure, 2006, P ACM SIGKDD INT C K, P631
   Ley M, 2009, PROC VLDB ENDOW, V2, P1493, DOI 10.14778/1687553.1687577
   Lin Frank, 2010, ICML
   Liu W, 2021, IEEE T IND INFORM
   Lombaert H, 2005, IEEE I CONF COMP VIS, P259
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma YL, 2021, IEEE INTERNET THINGS, V8, P5822, DOI 10.1109/JIOT.2020.3034221
   Macskassy SA, 2007, J MACH LEARN RES, V8, P935
   Malcolm J, 2007, IEEE IMAGE PROC, P2061
   Mancoridis S., 1999, Proceedings IEEE International Conference on Software Maintenance - 1999 (ICSM'99). `Software Maintenance for Business Change' (Cat. No.99CB36360), P50, DOI 10.1109/ICSM.1999.792498
   Mansurul Bhuiyan A, 2013, T KNOWL DATA ENG
   MarziehAyati SE, 2015, J BIOINF SYSTEMS BIO
   Meysman P, 2016, T COMPUT BIOBIOINF
   Meysman P, 2019, IEEE ACM T COMPUT BI, V16, P1496, DOI 10.1109/TCBB.2016.2576440
   Meysman P, 2013, MOL BIOL EVOL, V30, P1302, DOI 10.1093/molbev/mst029
   Milenkovic T, 2008, CANCER INFORM, V6, P257
   Motoda H, 2006, LECT NOTES COMPUT SC, V4304, P1
   NEWBERY FJ, 1989, ACM SIGSOFT, V17, P76, DOI 10.1145/73337.73350
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Newman MEJ, 2005, SOC NETWORKS, V27, P39, DOI 10.1016/j.socnet.2004.11.009
   Ng AY, 2002, ADV NEUR IN, V14, P849
   NOUROMID B, 1986, AM SOC MECH ENG, P291
   Ou CW, 1997, IEEE T PARALL DISTR, V8, P884, DOI 10.1109/71.605773
   Ozaki T, 2008, LECT NOTES ARTIF INT, V5012, P272, DOI 10.1007/978-3-540-68125-0_25
   Papadimitriou C.H., 1998, COMBINATORIAL OPTIMI
   Phan D, 2005, INFOVIS 05: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION, PROCEEDINGS, P219, DOI 10.1109/INFVIS.2005.1532150
   Ponnusamy R., 1993, INT C SUPERCOMPUTING
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   POTHEN A, 1990, SIAM J MATRIX ANAL A, V11, P430, DOI 10.1137/0611030
   Preciado VM, 2013, IEEE ACM T NETWORK, V21, P373, DOI 10.1109/TNET.2012.2217152
   Przulj N, 2007, BIOINFORMATICS, V23, pE177, DOI 10.1093/bioinformatics/btl301
   Quick L, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P457, DOI 10.1109/ASONAM.2012.254
   Rahman M, 2014, IEEE T KNOWL DATA EN, V26, P2466, DOI 10.1109/TKDE.2013.2297929
   Ramon J, GRAPH MINING DECLARA
   Rehman S. U., 2012, 2012 Seventh International Conference on Digital Information Management (ICDIM 2012), P88, DOI 10.1109/ICDIM.2012.6360146
   Risch JS., 2006, INT J HUM COMPUT STU, V53, P695
   Rodrigues JF, 2013, IEEE T KNOWL DATA EN, V25, P106, DOI 10.1109/TKDE.2011.199
   Rosselló F, 2005, ELECTRON NOTES THEOR, V127, P157, DOI 10.1016/j.entcs.2004.12.033
   Saha B, 2010, LECT N BIOINFORMAT, V6044, P456, DOI 10.1007/978-3-642-12683-3_30
   Sangwon Seo, 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P721, DOI 10.1109/CloudCom.2010.17
   Schaeffer SE, 2007, COMPUT SCI REV, V1, P27, DOI 10.1016/j.cosrev.2007.05.001
   Schenker A, 2003, PROC INT CONF DOC, P240
   Shao Bin, 2013, SIGMOD, P505, DOI [DOI 10.1145/2463676.2467799, 10.1145/2463676.2467799]
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407
   Shiy J, NORMALIZED CUTS IMAG
   Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839
   Sougata Mukherjea, 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P331
   SUGIYAMA K, 1991, IEEE T SYST MAN CYB, V21, P876, DOI 10.1109/21.108304
   Tony Chan F, 1994, GEOMETRIC SPECTRAL P
   van Ham F, 2004, IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2004, PROCEEDINGS, P199, DOI 10.1109/INFVIS.2004.43
   Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34
   Vitter JS, 2001, ACM COMPUT SURV, V33, P209, DOI 10.1145/384192.384193
   Wang L, 2006, IJCSNS INT J COMPUT, V6
   Wang S, 2006, IEEE EMBEDDED SYSTEM, V14
   Wattenberg M., 2006, Conference on Human Factors in Computing Systems. CHI2006, P811, DOI 10.1145/1124772.1124891
   Watts D. J., 2004, Small Worlds: The Dynamics of Networks between Order and Randomness
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Wernicke S, 2006, BIOINFORMATICS, V22, P1152, DOI 10.1093/bioinformatics/btl038
   Wernicke S, 2006, FANMOD TOOL FAST NET, V22
   Westbrook JD, FORMAT MMCIF FORMATS
   Wong N, 2003, INFOVIS 2002: IEEE SYMPOSIUM ON INFORMATION VISUALIZATION 2003, PROCEEDINGS, P51, DOI 10.1109/INFVIS.2003.1249008
   Wu MQY, 2015, IEEE ACM INT C ADV S
   Wu X, 2008, C IMAGE SIGNAL PROCE
   Xiao Z, 2016, 978150904093316 IEEE
   Xuan JY, 2015, IEEE T CYBERNETICS, V45, P2792, DOI 10.1109/TCYB.2014.2386282
   Yang XT, 2011, PROC VLDB ENDOW, V4, P231, DOI 10.14778/1938545.1938548
   Yi F, 2012, 2012 INT C SYSTEMS I
   Yi JS, 2007, IEEE T VIS COMPUT GR, V13, P1224, DOI 10.1109/TVCG.2007.70515
   Yu ZY, 2011, IEEE ENG MED BIO, P5714, DOI 10.1109/IEMBS.2011.6091383
   Zass R, 2008, PROC CVPR IEEE, P1221
   Zhao PX, 2007, LECT NOTES COMPUT SC, V4443, P91
   Zhou D., 2006, NIPS, V19
NR 181
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 43315
EP 43356
DI 10.1007/s11042-022-13017-5
EA MAY 2022
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000800967800003
DA 2024-07-18
ER

PT J
AU Chowdhury, R
   Sen, S
   Roy, A
   Saha, B
AF Chowdhury, Ratul
   Sen, Shibaprasad
   Roy, Arindam
   Saha, Banani
TI An optimal feature based network intrusion detection system using
   bagging ensemble method for real-time traffic analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intrusion detection system; NSL-KDD dataset; Moth-flame optimization;
   Bagging ensemble method; Real-time test-bed
ID MOTH-FLAME OPTIMIZATION; ALGORITHM
AB The enormous growth of cyber threats has become a calamitous issue in today's technically advanced world where data and information play a crucial role in identifying patterns and automatic predictive analysis. Network packet analysis is a pivotal technique in cybersecurity to protect our network and computer from unauthorized access. A network intrusion detection system (NIDS) is a network packet monitoring tool that intently inspects all the incoming and outgoing packets passing through a network and recognizes malicious incidents. This paper proposes a novel NIDS using the decision tree-based Bagging ensemble method, where the NSL-KDD dataset has been used for experimental purposes. The optimal features from the mentioned dataset have been filtered through the application of the wrapper-based Moth Flame optimization (MFO) technique and the effectiveness of the selected features has been evaluated using various machine learning, deep learning, and ensemble learning frameworks. All the experiments have been conducted in accordance with both binary and multiclass categories. Exhaustive performance evaluation confirms that the proposed MFO-ENSEMBLE method achieves an 87.43% detection rate and incurs minimal time overhead amongst all classification techniques. Practical implementation of the proposed methodology in a custom-built real-time test-bed confirms both the novelty as well as the feasibility of this work.
C1 [Chowdhury, Ratul] Future Inst Engn & Management, Kolkata, India.
   [Sen, Shibaprasad] Univ Engn & Management, Kolkata, India.
   [Roy, Arindam; Saha, Banani] Univ Calcutta, Kolkata, India.
C3 University of Calcutta
RP Sen, S (corresponding author), Univ Engn & Management, Kolkata, India.
EM ratul.cse87@gmail.com; shibubiet@gmail.com; rarindam68@gmail.com;
   bsaha_29@yahoo.com
RI Chowdhury, Ratul/JAC-0555-2023; Saha, Banani/HDL-8898-2022
OI sen, shibaprasad/0000-0003-4815-6621
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Aburomman AA, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRICAL, ELECTRONIC AND SYSTEMS ENGINEERING (ICAEES), P362, DOI 10.1109/ICAEES.2016.7888070
   Akinbo R.S., 2021, Machine Learning-Algorithms, Models and Applications
   Bajaj K., 2013, International Journal of Computer Applications, V76, P5, DOI [DOI 10.5120/13209-0587, 10.5120/13209-0587]
   Bhlmann P., 2012, HDB COMPUTATIONAL ST
   Buczak AL, 2016, IEEE COMMUN SURV TUT, V18, P1153, DOI 10.1109/COMST.2015.2494502
   Chen CM, 2010, COMPUT COMMUN, V33, P477, DOI 10.1016/j.comcom.2009.10.010
   Chowdhury R, 2021, DATA DRIVEN APPROACH, P337
   Esmaily J, 2015, 2015 7TH CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT)
   Farahnakian F, 2018, INT CONF ADV COMMUN, P178, DOI 10.23919/ICACT.2018.8323688
   Ferreira PJG, 2020, THESIS
   Gaikwad DP, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P291, DOI 10.1109/ICCUBEA.2015.61
   Gandhi G. Meera, 2010, International Journal of Advanced Networking and Applications, V2, P686
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Ingre B, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P92, DOI 10.1109/SPACES.2015.7058223
   Ioulianou P.P., 2018, A Signature based Intrusion Detection System for the Internet of Things
   Jha J., 2013, International Journal of Applied Information Systems (IJAIS), V3, P25
   Khalaf M, 2020, IEEE ACCESS, V8, P70375, DOI 10.1109/ACCESS.2020.2986090
   Lakhina S., 2010, FEATURE REDUCTION US
   Lashkari AH, 2017, ICISSP: PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P253, DOI 10.5220/0006105602530262
   Li ZP, 2017, LECT NOTES COMPUT SC, V10638, P858, DOI 10.1007/978-3-319-70139-4_87
   Mahfouz A, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12110180
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Moustafa N, 2019, IEEE INTERNET THINGS, V6, P4815, DOI 10.1109/JIOT.2018.2871719
   Neethu B., 2012, International Journal of Electronics and Computer Science Engineering, V1, P1044
   Patro S, 2015, ARXIV 150306462
   Rai Kajal, 2016, International Journal of Advanced Networking and Applications, V7, P2828
   Sanders C., 2013, Applied network security monitoring: Collection, detection, and analysis
   Shehab M, 2020, NEURAL COMPUT APPL, V32, P9859, DOI 10.1007/s00521-019-04570-6
   Shi JY, 2019, J POWER ELECTRON, V19, P1248, DOI 10.6113/JPE.2019.19.5.1248
   Sommer Robin., 2007, The bro network intrusion detection system
   Su TT, 2020, IEEE ACCESS, V8, P29575, DOI 10.1109/ACCESS.2020.2972627
   Tavallaee M, 2009, 2009 IEEE S COMP INT, P1, DOI DOI 10.1109/CISDA.2009.5356528
   Trivedi IN, 2016, 2016 INTERNATIONAL CONFERENCE ON ENERGY EFFICIENT TECHNOLOGIES FOR SUSTAINABILITY (ICEETS), P442, DOI 10.1109/ICEETS.2016.7583795
   Vinayakumar R, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1222, DOI 10.1109/ICACCI.2017.8126009
   Yin CL, 2017, IEEE ACCESS, V5, P21954, DOI 10.1109/ACCESS.2017.2762418
   Zawbaa HM, 2016, IEEE C EVOL COMPUTAT, P4612, DOI 10.1109/CEC.2016.7744378
NR 37
TC 6
Z9 7
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41225
EP 41247
DI 10.1007/s11042-022-12330-3
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000797788600002
DA 2024-07-18
ER

PT J
AU Wu, YH
   Zheng, JY
   Song, WR
   Liu, F
AF Wu, Yahong
   Zheng, Jieying
   Song, Wanru
   Liu, Feng
TI Perceptive low-light image enhancement via multi-layer illumination
   decomposition model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light image enhancement; Perceptive contrast; Multi-layer
   illumination decomposition; Naturalness preservation; Human visual
   perception
ID HISTOGRAM EQUALIZATION; RETINEX
AB The images captured under low light conditions generally have less than satisfactory visual quality. To address this issue, many low-light image enhancement methods have been studied. However, these existing algorithms mostly suffer from unnaturalness, over-enhancement and artifacts. In this paper, a perceptive low-light image enhancement via multi-layer illumination decomposition model is proposed, to preserve the naturalness and improve the contrast for low-light images. First, the contrast of the target image is defined from global, local and the effect of noise aspects. Then, inspired by the human visual system, the perceptive contrast is designed by combining the defined contrast with just-noticeable-difference transformation. Last and most importantly, the target image is decomposed in a multi-layer way based on the multi-scale adaptive filter, which utilizes the perceptive contrast to decide the variance adaptively. This step can effectively obtain multiple illumination and reflectance layers. Combining these reflectance with adjusted illumination components can generate the final enhanced result. The proposed method has better no-reference quantitative measurement results than other compared methods. Experimental results on several public challenging low-light image datasets demonstrate that the proposed method can achieve great performance in balancing the contrast, brightness and naturalness.
C1 [Wu, Yahong; Zheng, Jieying; Song, Wanru; Liu, Feng] Nanjing Univ Posts & Telecommun, 66 Xin Mofan RD, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Liu, F (corresponding author), Nanjing Univ Posts & Telecommun, 66 Xin Mofan RD, Nanjing 210003, Peoples R China.
EM wuyahonghaha@163.com; liuf@njupt.edu.cn
FU National Natural Science Foundation of China [61702278]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions;
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX18_0902]
FX This work was supported in part by National Natural Science Foundation
   of China under Grant 61702278, in part by Priority Academic Program
   Development of Jiangsu Higher Education Institutions and in part by
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   KYCX18_0902.
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Cheng H, 2020, MULTIMED TOOLS APPL, P1
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dicarlo JM., 2006, PROC SPIE, V3956, P392
   Dong X, 2011, 2011 IEEE INT C MULT, P16
   Eilertsen G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818092
   Fattal R, 2002, GRADIENT DOMAIN HIGH, V21
   Feng XM, 2020, MULTIMED TOOLS APPL, V79, P32973, DOI 10.1007/s11042-020-09562-6
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Fu XY, 2016, SIGNAL PROCESS, V129, P82, DOI 10.1016/j.sigpro.2016.05.031
   Fu XY, 2015, IEEE T IMAGE PROCESS, V24, P4965, DOI 10.1109/TIP.2015.2474701
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   Guo C, 2020, 2020 IEEECVF C COMPU
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2020, IEEE T MULTIMEDIA, V22, P3025, DOI 10.1109/TMM.2020.2969790
   JAYANT N, 1992, IEEE J SEL AREA COMM, V10, P796, DOI 10.1109/49.138986
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kimmel R, 2003, INT J COMPUT VIS SOB
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee C, 2012, 2012 IEEE INT C IMAG
   Li L, 2015, 2015 IEEE INT C IMAG
   Li MD, 2018, IEEE T IMAGE PROCESS, V27, P2828, DOI 10.1109/TIP.2018.2810539
   Liao S, 2015, 2015 IEEE C COMPUTER
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Ma K, 2015, IEEE T IMAGE PROCESS, V24, P3345, DOI 10.1109/TIP.2015.2442920
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Panetta KA, 2008, IEEE T SYST MAN CY B, V38, P174, DOI 10.1109/TSMCB.2007.909440
   Pisano ED, 1998, J DIGIT IMAGING, V11, P193, DOI 10.1007/BF03178082
   Provenzi E, 2005, J OPT SOC AM A, V22, P2613, DOI 10.1364/JOSAA.22.002613
   Qiao, 2020, 2020 IEEE CVF C COMP
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478
   Steyer S, 2020, IEEE T INTELL TRANSP, V21, P2874, DOI 10.1109/TITS.2019.2921248
   Wang C, 2005, IEEE T CONSUM ELECTR, V51, P1326, DOI 10.1109/TCE.2005.1561863
   Wang D, 2014, 2014 IEEE INT C SECU
   Wang LW, 2020, IEEE T IMAGE PROCESS, V29, P7984, DOI 10.1109/TIP.2020.3008396
   Wang R, 2019, 2019 IEEECVF C COMPU
   Wang SH, 2018, IEEE T IMAGE PROCESS, V27, P938, DOI 10.1109/TIP.2017.2771449
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wu YH, 2021, SIGNAL PROCESS-IMAGE, V93, DOI 10.1016/j.image.2021.116141
   Xu J, 2020, IEEE T IMAGE PROCESS, V29, P5022, DOI 10.1109/TIP.2020.2974060
   Xu K, 2020, PROC CVPR IEEE, P2278, DOI 10.1109/CVPR42600.2020.00235
   Xu XL, 2020, IEEE IMAGE PROC, P2011, DOI [10.1109/icip40778.2020.9190896, 10.1109/ICIP40778.2020.9190896]
   Yang W, 2020, 2020 IEEECVF C COMPU
   Yu L, 2018, IEEE ACCESS, V6, P36132, DOI 10.1109/ACCESS.2018.2848671
   Zhang, 2020, ARXIV 200509829
   Zhang X, 2012, 2012 IEEE INT C PATT
   Zhang Y, 2019, ARXIV 190504161
   Zhu M, 2020, AAAI C ARTIFICIAL IN, V34
NR 54
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40905
EP 40929
DI 10.1007/s11042-022-13139-w
EA MAY 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795639800002
DA 2024-07-18
ER

PT J
AU Sengupta, A
   Singh, A
   Kumar, P
   Dhar, T
AF Sengupta, Aritro
   Singh, Amit
   Kumar, Pankaj
   Dhar, Tapobrata
TI A secure and improved two factor authentication scheme using elliptic
   curve and bilinear pairing for cyber physical systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cyber physical system; Two factor authentication; Smart card; Elliptic
   curve; Bilinear pairing; Security analysis; Session key; ECDLP (Ellitpic
   Curve Discrete Logarithmic Problem); Client-server authentication
ID XEDNI CALCULUS; EFFICIENT
AB In order to equip the technical fraternity with smart technologies, the past few years have witnessed increasing usage of Cyber-Physical Systems (CPS) in different critical infrastructures. The abrupt surge in the advancement of CPS has brought in several cybersecurity issues. To address the issue of cybersecurity and to protect the CPS from attackers, authentication schemes have been designed and implemented. One such authentication scheme is two-factor authentication (2FA) which is considered to be a straightforward and coherent authentication mechanism that ensures secure communication in an unprotected network environment. Over the past few decades, several 2FA schemes using smart card have been proposed by Wang et al., Wang et al., WenLis et al., Chou et al., Ans et al., and Chang et al. with each scheme trying to overcome the shortcomings of the previous schemes. Subsequently, S.Kumari et al. pointed out the various loopholes of the previous schemes and proposed a new scheme on 2FA that was asserted to be both secure and efficient. In this article, we have explained how the different 2FA schemes as proposed in the previous papers are susceptible to various security attacks. Later on, an effective and user-friendly 2FA scheme is proposed in this article which can be implemented on CPS. The proposed scheme works on the principles of bilinear pairing and can overcome the loopholes of the previously proposed schemes. As a proof of our claim, the security analysis of the proposed scheme against all the common attacks has also been done in detail. The comparison of the security analysis and performance of the proposed scheme with the previous schemes has also been carried out in this paper.
C1 [Sengupta, Aritro; Singh, Amit; Kumar, Pankaj] Govt India, Minist Elect & IT, New Delhi, India.
   [Dhar, Tapobrata] Indian Inst Engn Sci & Technol, Sibpur, W Bengal, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Sengupta, A (corresponding author), Govt India, Minist Elect & IT, New Delhi, India.
EM asg.ju2012@gmail.com; singhamit1320@gmail.com; pankaj260294@gmail.com;
   tapobrata.dhar91@gmail.com
CR An YH, 2013, 15 INT C ADV COMMUNI
   Barreto Paulo SLM, 2005, ADV CRYPTOLOGY ASIAC, V3788
   Chang YF, 2014, INT J COMMUN SYST, V27, P3430, DOI 10.1002/dac.2552
   Chou JS, 2013, EFFICIENT 2 PASS ANO
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Jacobson MJ, 2000, DESIGN CODE CRYPTOGR, V20, P41, DOI 10.1023/A:1008312401197
   Jing Q, 2014, WIREL NETW, V20, P2481, DOI 10.1007/s11276-014-0761-7
   Joye M., 2005, SIDE CHANNEL ANAL EN, P571, DOI [10.1007/0-387-23483-7_394, DOI 10.1007/0-387-23483-7_394]
   KOBLITZ N, 1987, MATH COMPUT, V48, P203, DOI 10.1090/S0025-5718-1987-0866109-5
   Kocher Paul, 1999, LECT NOTES COMPUTER, P388, DOI [DOI 10.1007/3-540-48405-1_25, 10.1007/3-540-48405-1_25]
   Kumari S, 2014, COMPUT ELECTR ENG, V40, P1997, DOI 10.1016/j.compeleceng.2014.05.007
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   Li X, 2013, J NETW COMPUT APPL, V36, P1365, DOI 10.1016/j.jnca.2013.02.034
   Lynn, PBC LIB MANUAL 0 5 1
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   MILLER VS, 1986, LECT NOTES COMPUT SC, V218, P417, DOI 10.1007/3-540-39799-x_31
   NIST, 2012, CYB PHYS SYST SIT AN
   Odlyzko A, 2000, DESIGN CODE CRYPTOGR, V19, P129, DOI 10.1023/A:1008350005447
   Odlyzko AM., 1985, ADV CRYPTOLOGY P EUR, V224, P314
   Pateriya RK, 2011, IEEE 2011 INT C COMM
   Silverman JH, 2000, DESIGN CODE CRYPTOGR, V20, P5, DOI 10.1023/A:1008319518035
   Wang XM, 2007, COMPUT STAND INTER, V29, P507, DOI 10.1016/j.csi.2006.11.005
   Wang Y, 2017, SECURE COMMUNICATION
   Wang YY, 2009, COMPUT COMMUN, V32, P583, DOI 10.1016/j.comcom.2008.11.008
   Wen FT, 2012, COMPUT ELECTR ENG, V38, P381, DOI 10.1016/j.compeleceng.2011.11.010
   Yanga Jen-Ho, ID BASED REMOTE MUTU
NR 27
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22425
EP 22448
DI 10.1007/s11042-022-12227-1
EA MAY 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000791638100002
DA 2024-07-18
ER

PT J
AU Mishra, R
   Malviya, S
   Singh, S
   Singh, V
   Tiwary, US
AF Mishra, Rohit
   Malviya, Shrikant
   Singh, Sumit
   Singh, Varsha
   Tiwary, Uma Shanker
TI Multi-attribute decision making application using hybridly modelled
   Gaussian Interval Type-2 Fuzzy sets with uncertain mean
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interval type-2 fuzzy sets; Multiple attribute decision-making;
   Computing with words; Perceptual computing; Membership functions
ID LINGUISTIC SUMMARIES; WORDS
AB Perceptual computing (Per-C) is a branch of CWW (Computing with words) that assist people in making subjective decisions. Their applications take linguistic inputs (i.e., words) from the user and return a linguistic output (i.e., word). The perception of these linguistic inputs suffers from uncertainties, for which IT2FSs (Interval Type-2 Fuzzy Sets) are considered better than T1FSs (Type-1 Fuzzy Sets) to capture it. In these applications, the IT2FSs are constructed either by application developers or by consulting experts. Due to the manual introduction of biases, these methods cannot capture uncertainties appropriately, so constructing IT2FS using data intervals is a better approach. The Trapezoidal IT2FS is the only available through this approach, but it has a linear membership function. In real life, the distribution observed is primarily non-linear. The paper presents an experimental method to construct the GIT2FSUM (Gaussian IT2FSs with Uncertain Mean) following statistical (i.e. pruning) and heuristical (i.e. selection of underlying T1FS) steps on data intervals. In order to show its capability in capturing uncertainties, a MADM (Multi-attribute decision making) application following the Per-C framework is developed. The application recommends the suitability of the Online Study Platforms (OSP) to a student. LWA (Linguistic weighted average) operation is performed to obtain OWR (Output Word Representation) for selecting the recommendation word corresponding to an OSP. In this experiment, we compare our GIT2FSUM with the existing Trapezoidal IT2FS (i.e., also formed using data-interval). The average Jaccard similarity between OWR (using GIT2FSUM) and recommendation word is (0.67 +/- 0.12), while for OWR (using Trapezoidal IT2FS) is (0.55 +/- 0.11). It indicates that the GIT2FSUM is much better than Trapezoidal IT2FS in capturing uncertainties present in the perception of words. In addition, the number of parameters to model GIT2FSUM is comparatively less than Trapezoidal IT2FS.
C1 [Mishra, Rohit; Malviya, Shrikant; Singh, Sumit; Singh, Varsha; Tiwary, Uma Shanker] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Mishra, R (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
EM rohit129iiita@gmail.com; s.kant.malviya@gmail.com; sumitrsch@gmail.com;
   varshagaur@gmail.com; ust@iiita.ac.in
RI Singh, Varsha/JJC-3364-2023; Malviya, Shrikant/AGW-5616-2022
OI Singh, Varsha/0000-0003-4777-1278; Malviya,
   Shrikant/0000-0002-7539-3721; MISHRA, ROHIT/0000-0002-8461-4223
CR Alonso JM, 2019, LECT NOTES ARTIF INT, V11291, P244, DOI 10.1007/978-3-030-12544-8_21
   [Anonymous], 1999, PROC 3 INT ICSC S FU
   Azar F., 2000, MULTIATTRIBUTE DECIS
   Chen SM, 2014, IEEE T SYST MAN CY-S, V44, P1665, DOI 10.1109/TSMC.2014.2314724
   DONG WM, 1987, FUZZY SET SYST, V21, P183, DOI 10.1016/0165-0114(87)90163-1
   Dongrui Wu, 2008, IEEE Transactions on Fuzzy Systems, V16, P1664, DOI 10.1109/TFUZZ.2008.2005941
   Gao Y, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103276
   Gupta PK, 2019, GRANULAR COMPUT, V4, P167, DOI 10.1007/s41066-018-0109-2
   Kacprzyk J, 2001, INT J GEN SYST, V30, P133, DOI 10.1080/03081070108960702
   Kazmier, 2019, THEORY PROBLEMS BUSI
   Kim S, 2007, INT SYM PERFORM ANAL, P1
   Liang DC, 2013, INT J APPROX REASON, V54, P1087, DOI 10.1016/j.ijar.2013.03.014
   Liu F, 2008, IEEE T FUZZY SYST, V16, P1503, DOI 10.1109/TFUZZ.2008.2005002
   Lyon A, 2014, BRIT J PHILOS SCI, V65, P621, DOI 10.1093/bjps/axs046
   Majumder D, 2017, ADV INTELL SYST COMP, V517, P679, DOI 10.1007/978-981-10-3174-8_57
   Manna S, 2019, GRANULAR COMPUT, V4, P585, DOI 10.1007/s41066-018-0119-0
   Mendel J.M., 2010, PERCEPTUAL COMPUTING, DOI [10.1002/9780470599655, DOI 10.1002/9780470599655]
   Mendel JM, 2007, IEEE T FUZZY SYST, V15, P301, DOI 10.1109/TFUZZ.2006.881447
   Mendel JM, 2007, INFORM SCIENCES, V177, P988, DOI 10.1016/j.ins.2006.06.008
   Mendel JM, 2006, IEEE T FUZZY SYST, V14, P808, DOI 10.1109/TFUZZ.2006.879986
   Mendel JM, 2008, IEEE T FUZZY SYST, V16, P1550, DOI 10.1109/TFUZZ.2008.2005691
   Mendel JM, 2003, IEEE INT CONF FUZZY, P37
   Mendel JM., 2018, INFORM SPEKTRUM, V41, P15, DOI [10.1007/s00287-018-1088-z, DOI 10.1007/S00287-018-1088-Z]
   Mishra R, 2019, INT C INT HUM COMP I, P112, DOI DOI 10.1007/978-3-030-44689-5
   Nguyen H. T., 2018, A First Course in Fuzzy Logic
   Niewiadomski A, 2006, CONTROL CYBERN, V35, P415
   OHagan A., 2006, Uncertain judgements: Eliciting experts' probabilities
   Rao RV, 2007, SPRINGER SER ADV MAN, P27
   Runkler T, 2017, INT J APPROX REASON, V80, P217, DOI 10.1016/j.ijar.2016.09.007
   Schreier, 2016, COMPUTING NUMBERS CO, P9
   Tan WW., 2007, introduction and new directions, V2, P72, DOI DOI 10.1109/MCI.2007.357196
   Vinogradova I, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7100915
   WALLSTEN TS, 1995, KNOWL ENG REV, V10, P43, DOI 10.1017/S0269888900007256
   Walpole R. E., 2007, Probability & Statistics for Engineers and Scientists
   Wu D, 2012, IEEE INT CONF COMMUN, P43, DOI 10.1109/ICCCW.2012.6316472
   Wu D, 2008, INFORM SCIENCES, V178, P381, DOI 10.1016/j.ins.2007.04.014
   Wu DR, 2007, IEEE T FUZZY SYST, V15, P1145, DOI 10.1109/TFUZZ.2007.896325
   Wu DR, 2006, IEEE INT CONF FUZZY, P566
   Wu DR, 2007, INFORM SCIENCES, V177, P5378, DOI 10.1016/j.ins.2007.07.012
   Wu DR, 2019, ENG APPL ARTIF INTEL, V85, P182, DOI 10.1016/j.engappai.2019.06.012
   Wu DR, 2019, IEEE T FUZZY SYST, V27, P515, DOI 10.1109/TFUZZ.2018.2862869
   Wu DR, 2009, IEEE T FUZZY SYST, V17, P923, DOI 10.1109/TFUZZ.2008.924329
   Wu DR, 2009, INFORM SCIENCES, V179, P1169, DOI 10.1016/j.ins.2008.12.010
   Wu HW, 2002, IEEE T FUZZY SYST, V10, P622, DOI 10.1109/TFUZZ.2002.803496
   YAGER RR, 1982, INFORM SCIENCES, V28, P69, DOI 10.1016/0020-0255(82)90033-0
   Yang YY, 2020, INT J FUZZY SYST, V22, P293, DOI 10.1007/s40815-019-00777-w
   Zadeh LA, 2001, AI MAG, V22, P73
   ZADEH LA, 1988, COMPUTER, V21, P83, DOI 10.1109/2.53
   Zadeh LA, 1999, IEEE T CIRCUITS-I, V46, P105, DOI 10.1109/81.739259
   Zadeh LA, 2008, IEEE COMPUT INTELL M, V3, P11, DOI 10.1109/MCI.2008.926583
   Zadeh Lotfi A., 1999, COMPUTING WORDS INFO, P3, DOI DOI 10.1007/978-3-7908-1873-4_1
   Zhang Q, 2004, DECIS SUPPORT SYST, V38, P247, DOI 10.1016/s0167-9236(03)00094-0
   Zimmermann H.-J., 2001, Fuzzy Set Theory-and Its Applications, V4th
NR 53
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 4913
EP 4940
DI 10.1007/s11042-022-12172-z
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000788980000007
DA 2024-07-18
ER

PT J
AU Diniesh, VC
   Murugesan, G
AF Diniesh, V. C.
   Murugesan, G.
TI Review on mobility aware MAC protocol using Mobile internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Wireless sensor networks; Medium access control; Internet of things;
   Mobility; Performance analysis; Internet of thing
ID MEDIUM ACCESS-CONTROL; WIRELESS SENSOR NETWORKS; IOT
AB Modern boom and understanding of our growing needs, applications based on the Mobile Internet of Things (MIoT) are becoming important for future internet technologies. MIoT will force to connect billions of intelligent devices such as sensors connected with the internet. This increase in a mobile application for long-lasting high throughput network sensor coordination plays a crucial role in the design of energy-efficient protocols, specifically in the Medium Access Control (MAC) layer. In this survey, we first propose a taxonomy for classifying mobility-aware MAC protocols in MWSNs. Then we classify the Mobility MAC protocols into the synchronous and asynchronous-based mechanism. For each category, relevant protocols are thoroughly reviewed with the design, and the selected mobility MAC is evaluated under different mobility models. Finally, we discuss open issues associated with the design of mobility MAC protocols gives a start-up for the design of mobile MAC solutions for future large-scale Mobile IoT applications.
C1 [Diniesh, V. C.; Murugesan, G.] Kongu Engn Coll, Dept Elect & Commun Engn, Perundurai 638060, Tamil Nadu, India.
C3 Kongu Engineering College
RP Diniesh, VC (corresponding author), Kongu Engn Coll, Dept Elect & Commun Engn, Perundurai 638060, Tamil Nadu, India.
EM dinieshece@gmail.com; murugesanece@gmail.com
RI Diniesh, V.C/GVT-0061-2022
OI Diniesh, V.C/0000-0001-8377-7015
CR Ahmed N, 2018, IEEE INTERNET THINGS, V5, P4890, DOI 10.1109/JIOT.2018.2879579
   Al-Fuqaha A, 2015, IEEE COMMUN SURV TUT, V17, P2347, DOI 10.1109/COMST.2015.2444095
   Ali M, 2005, IEEE IPCCC, P401
   Anastasi G, 2009, AD HOC NETW, V7, P537, DOI 10.1016/j.adhoc.2008.06.003
   [Anonymous], 2020, IOT MARK SIZ WORLDW
   [Anonymous], 2016, MOBILITY NODES COOJA
   [Anonymous], 2011, CISCO VISUAL NETWORK
   Aschenbruck N., 2010, PROC 3 INT ICST C SI, P51, DOI DOI 10.4108/ICST.SIMUTOOLS2010.8684
   Ba PD, 2014, TELECOMMUN SYST, V55, P271, DOI 10.1007/s11235-013-9780-4
   Baccelli E, 2013, RESEARCHGATE, P1
   Buettner M., 2006, SenSys ?06, P307, DOI [DOI 10.1145/1182807.1182838, 10.1145/1182807.1182838]
   Domingo MC, 2012, J NETW COMPUT APPL, V35, P1879, DOI 10.1016/j.jnca.2012.07.012
   Choi SC, 2008, IEEE VTS VEH TECHNOL, P168
   Dam T., 2003, the 1st International Conference on Embedded Networked Sensor Systems, P171, DOI DOI 10.1145/958491.958512
   Dong Q, 2013, IEEE COMMUN SURV TUT, V15, P88, DOI 10.1109/SURV.2012.013012.00051
   Dunkels, 2011, 111 SWED I COMP SCI
   Dunkels A, 2011, T20110414 SICS
   EL-HOIYDI A., 2003, P ACM SENSYS, P302
   Fafoutis X, 2011, PE-WASUN 11: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON PERFORMANCE EVALUATION OF WIRELESS AD HOC, SENSOR, AND UBIQUITOUS NETWORKS, P49
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hameed S.A., 2009, IEEE ULTR TEL WORKSH, P1, DOI DOI 10.1109/ICUMT.2009.5345591
   IoT, 2020, NUMB CONN DEV WORLDW
   Karl H, 2005, PROTOCOLS AND ARCHITECTURES FOR WIRELESS SENSOR NETWORKS, P1
   Kazmi SWA, 2017, INT CONF UBIQ FUTUR, P159
   Khan JA, 2015, COMPUT ELECTR ENG, V41, P159, DOI 10.1016/j.compeleceng.2014.06.009
   Khanna A, 2019, COMPUT ELECTRON AGR, V157, P218, DOI 10.1016/j.compag.2018.12.039
   Legendre F, 2006, IEEE NETWORK, V20, P4, DOI 10.1109/MNET.2006.273114
   Lin P, 2004, IEEE WCNC, P1534, DOI 10.1109/WCNC.2004.1311671
   López P, 2013, 2013 IEEE 27TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P1349, DOI 10.1109/WAINA.2013.255
   Maitra T, 2016, COMPUT SCI REV, V22, P107, DOI 10.1016/j.cosrev.2016.09.004
   Moss D, 2008, Rep. TR-2008, V64, P120
   Österlind F, 2006, C LOCAL COMPUT NETW, P641
   Papadopoulos Georgios Z., 2014, IEEE Sensors 2014. Proceedings, P257, DOI 10.1109/ICSENS.2014.6984982
   Papadopoulos GZ, 2016, IEEE GLOB COMM CONF
   Papadopoulos GZ, 2016, AD HOC NETW, V48, P66, DOI 10.1016/j.adhoc.2016.05.011
   Papadopoulos GZ, 2015, 2015 IEEE 2ND WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P210, DOI 10.1109/WF-IoT.2015.7389054
   Papadopoulos GZ, 2015, MOBILE NETW APPL, V20, P649, DOI 10.1007/s11036-015-0608-1
   Peng F, 2015, WIRELESS PERS COMMUN, V81, P489, DOI 10.1007/s11277-014-2140-1
   Pham H., 2004, 2004 IEEE International Conference on Mobile Ad-hoc and Sensor Systems (IEEE Cat. No.04EX975), P558, DOI 10.1109/MAHSS.2004.1392207
   Polastre J., 2004, SenSys '04, P95, DOI [DOI 10.1145/1031495.1031508, 10.1145/1031495.1031508]
   Roy RR, 2011, HANDBOOK OF MOBILE AD HOC NETWORKS FOR MOBILITY MODELS, P1, DOI 10.1007/978-1-4419-6050-4
   Silva R, 2014, COMPUT COMMUN, V52, P1, DOI 10.1016/j.comcom.2014.05.008
   Tang ZY, 2010, IEEE GLOBE WORK, P109, DOI 10.1109/GLOCOMW.2010.5700105
   Yang DL, 2010, ADV INTEL SYS RES, V14, P358
   Ye W, 2002, IEEE INFOCOM SER, P1567, DOI 10.1109/INFCOM.2002.1019408
   Yick J, 2008, COMPUT NETW, V52, P2292, DOI 10.1016/j.comnet.2008.04.002
   Youssef W, 2006, IEEE ICC, P3396
   Zareei M, 2018, J NETW COMPUT APPL, V104, P21, DOI 10.1016/j.jnca.2017.12.009
   Zareei M, 2014, AEU-INT J ELECTRON C, V68, P1000, DOI 10.1016/j.aeue.2014.05.014
   Zhu H., 2015, J INFORM HIDING MULT, V6, P444
NR 50
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38705
EP 38734
DI 10.1007/s11042-022-13131-4
EA APR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500007
DA 2024-07-18
ER

PT J
AU Anand, S
   Rahul
   Mallik, A
   Kumar, S
AF Anand, Sameer
   Rahul
   Mallik, Abhishek
   Kumar, Sanjay
TI Integrating node centralities, similarity measures, and machine learning
   classifiers for link prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network (ANN); Complex networks; Link prediction; Node
   centrality; Random forest; Similarity measures
ID COMPLEX NETWORKS; SOCIAL NETWORKS; SPREADERS
AB Link prediction is a widely studied topic in graph data analytics and finds numerous applications like friend recommendations in social networks and product recommendations in e-commerce. It refers to predicting new connections or edges that may arise in the near future amongst the nodes of the network. There exist various methods of link prediction generally based on either local, semi-local, or global features of networks and usually suffers from the problems of consistency in their performances over different and large size networks. In this paper, we intend to propose a generic and improved method of link prediction named as NSMLLP by integrating Node centralities, Similarity measures, and Machine Learning classifiers. We calculate popularity measures for every node and evaluate similarity measures for every pair of nodes in the network. The combined popularity and similarity measures form the features for every node pair in the network. The combined features of the nodes at the end of the edges, along with the positive or negative edge label, form a well-defined dataset for the task of link prediction. This dataset is then fed into machine learning classifiers like Random Forest classifier, AdaBoost classifier, and an ANN based classifier. The results obtained from these classifiers are then combined to make the final link prediction. We provide an information gain study aiming to quantify the improvement brought on by our proposed method. A feature importance study is also provided to comprehend better the relative importance of the various popularity and similarity measures used by us. The experimental results obtained on multiple real-life networks demonstrate that the proposed technique outperforms many existing popular methods of link predication based on several evaluation criteria.
C1 [Anand, Sameer] Delhi Univ, Shaheed Sukhdev Coll Business Studies SSCBS, Dr KN Katju Marg, New Delhi 110089, India.
   [Rahul; Mallik, Abhishek; Kumar, Sanjay] Delhi Technol Univ, Dept Comp Sci & Engn, Main Bawana Rd, New Delhi 110042, India.
C3 University of Delhi; Delhi Technological University
RP Kumar, S (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Main Bawana Rd, New Delhi 110042, India.
EM sameeranand@sscbsdu.ac.in; rahulv0530@gmail.com;
   abhishekmallik265@gmail.com; sanjay.kumar@dtu.ac.in
OI Kumar, Dr. Sanjay/0000-0002-8951-5996
CR Abdel-Nasser M, 2020, ALEX ENG J, V59, P3531, DOI 10.1016/j.aej.2020.05.037
   Adamic LA, 2003, SOC NETWORKS, V25, P211, DOI 10.1016/S0378-8733(03)00009-1
   Adamic N., 2005, INT WORKSHOP LINK DI, P36, DOI DOI 10.1145/1134271.1134277
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Aziz F, 2020, PHYSICA A, V557, DOI 10.1016/j.physa.2020.124980
   Bae J, 2014, PHYSICA A, V395, P549, DOI 10.1016/j.physa.2013.10.047
   Batagelj V., 2006, Pajek datasets
   Behera DK, 2022, WIRELESS PERS COMMUN, V127, P695, DOI 10.1007/s11277-021-08399-y
   Berahmand K, 2021, COMPUTING, V103, P2227, DOI 10.1007/s00607-021-00982-2
   Berahmand Kamal, 2021, J KING SAUD UNIV-COM
   Biswas A, 2017, MULTIMED TOOLS APPL, V76, P18619, DOI 10.1007/s11042-016-4270-9
   Bonchi F, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961194
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chebotarev P, 2006, ARXIV MATH0602070
   Das D, 2018, WIRELESS PERS COMMUN, V102, P2183, DOI 10.1007/s11277-018-5499-6
   DILLON M, 1983, INFORM PROCESS MANAG, V19, P402, DOI 10.1016/0306-4573(83)90062-6
   Firth JA, 2015, P ROY SOC B-BIOL SCI, V282, DOI 10.1098/rspb.2014.2350
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Gao M, 2018, APPL INTELL, V48, P4531, DOI 10.1007/s10489-018-1220-4
   Ghorbanzadeh H, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113896
   Gu SS, 2019, APPL INTELL, V49, P703, DOI 10.1007/s10489-018-1284-1
   Haghani S, 2019, ARTIF INTELL REV, V52, P1961, DOI 10.1007/s10462-017-9590-2
   Ibrahim NMA, 2015, APPL INTELL, V42, P738, DOI 10.1007/s10489-014-0631-0
   Kaya B, 2020, MULTIMED TOOLS APPL, V79, P1745, DOI 10.1007/s11042-019-08270-0
   Kim J, 2019, SCIENTOMETRICS, V119, P687, DOI 10.1007/s11192-019-03055-6
   Kumar A, 2019, APPL INTELL, V49, P2762, DOI 10.1007/s10489-019-01413-8
   Kumar S, 2021, APPL INTELL, P1
   Kumar S, 2021, APPL INTELL, V51, P7647, DOI 10.1007/s10489-021-02266-w
   Kumar S, 2021, J INTELL INF SYST, V57, P51, DOI 10.1007/s10844-020-00625-6
   Kumar S, 2020, PHYSICA A, V553, DOI 10.1016/j.physa.2020.124215
   Kumar S, 2023, J THERMOPLAST COMPOS, V36, P794, DOI [10.1177/0892705720970629, 10.1007/s10844-020-00623-8]
   Leicht EA, 2006, PHYS REV E, V73, DOI 10.1103/PhysRevE.73.026120
   Leskovec J., 2007, ACM Transactions on Knowledge Discovery from Data, V1
   Li KY, 2020, COMPUT NETW, V166, DOI 10.1016/j.comnet.2019.106978
   Liu WP, 2010, EPL-EUROPHYS LETT, V89, DOI 10.1209/0295-5075/89/58007
   Martínez V, 2017, ACM COMPUT SURV, V49, DOI 10.1145/3012704
   Mistele T, 2019, SCIENTOMETRICS, V120, P87, DOI 10.1007/s11192-019-03110-2
   Monteserin A, 2019, INFORM RETRIEVAL J, V22, P32, DOI 10.1007/s10791-018-9335-0
   Mutlu EC, 2019, ARXIV190103425
   Nasiri E, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111230
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Richardson M, 2003, LECT NOTES COMPUT SC, V2870, P351
   Rozemberczki B, 2019, PROCEEDINGS OF THE 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM 2019), P65, DOI 10.1145/3341161.3342890
   Salavati C, 2019, NEUROCOMPUTING, V336, P36, DOI 10.1016/j.neucom.2018.04.086
   Stam Cornelis J, 2007, Nonlinear Biomed Phys, V1, P3, DOI 10.1186/1753-4631-1-3
   Sun ZB, 2015, J SYST SOFTWARE, V99, P109, DOI 10.1016/j.jss.2014.09.019
   Tripathi Shashi Prakash, 2019, Computational Intelligence: Theories, Applications and Future DirectionsVolume II. ICCI-2017. Advances in Intelligent Systems and Computing (AISC 799), P107, DOI 10.1007/978-981-13-1135-2_9
   Wahid-Ul-Ashraf A, 2019, PHYSICA A, V523, P1110, DOI 10.1016/j.physa.2019.04.246
   Wang GH, 2021, J COMPUT SCI-NETH, V53, DOI 10.1016/j.jocs.2021.101358
   Wang WT, 2019, INFORMATION, V10, DOI 10.3390/info10050172
   Wang ZQ, 2018, KNOWL-BASED SYST, V159, P72, DOI 10.1016/j.knosys.2018.06.005
   Wen T, 2020, INFORM SCIENCES, V512, P549, DOI 10.1016/j.ins.2019.10.003
   WHITE JG, 1986, PHILOS T R SOC B, V314, P1, DOI 10.1098/rstb.1986.0056
   Wu JH, 2019, PHYSICA A, V523, P996, DOI 10.1016/j.physa.2019.04.205
   Wu XM, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105740
   Yadav RK, 2020, J INTELL INF SYST, V55, P183, DOI 10.1007/s10844-020-00603-y
   Yao L, 2016, PROCEDIA COMPUT SCI, V83, P82, DOI 10.1016/j.procs.2016.04.102
   Zeng A, 2013, PHYS LETT A, V377, P1031, DOI 10.1016/j.physleta.2013.02.039
   Zhang LL, 2020, MULTIMED TOOLS APPL, V79, P13197, DOI 10.1007/s11042-019-08451-x
   Zhou W, 2018, SCIENTOMETRICS, V117, P381, DOI 10.1007/s11192-018-2867-7
NR 63
TC 9
Z9 9
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38593
EP 38621
DI 10.1007/s11042-022-12854-8
EA APR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000786569700001
DA 2024-07-18
ER

PT J
AU Salama, WM
   Shokry, A
   Aly, MH
AF Salama, Wessam M.
   Shokry, Ahmed
   Aly, Moustafa H.
TI A generalized framework for lung Cancer classification based on deep
   generative models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung cancer; Computer aided diagnosis; ResNet50; Convolutional neural
   network; Variational auto-encoders
ID AUTOMATED CLASSIFICATION; FEATURES
AB A new generalized framework for lung cancer detection and classification are introduced in this paper. Specifically, two types of deep models are presented. The first model is a generative model to capture the distribution of the important features in a set of small class-unbalanced collected CXR images. This generative model can be utilized to synthesize any number of CXR images for each class. For example, our generative model can generate images with tumors with different sizes and positions in the lung. Hence, the system can automatically convert the small unbalanced collected dataset to a larger balanced one. The second model is the ResNet50 that is trained using the large balanced dataset for cancer classification into benign and malignant. The proposed framework acquires 98.91% overall detection accuracy, 98.85% area under curve (AUC), 98.46% sensitivity, 97.72% precision, 97.89% F1 score. The classifier takes 1.2334 s on average to classify a single image using a machine with 13GB RAM.
C1 [Salama, Wessam M.] Pharos Univ, Dept Basic Sci, Fac Engn, Alexandria, Egypt.
   [Shokry, Ahmed] Alexandria Univ, Comp & Syst Engn, Alexandria, Egypt.
   [Aly, Moustafa H.] Arab Acad Sci Technol & Maritime Transport, Dept Elect & Commun Engn, Coll Engn & Technol, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Pharos University in Alexandria; Egyptian
   Knowledge Bank (EKB); Alexandria University; Egyptian Knowledge Bank
   (EKB); Arab Academy for Science, Technology & Maritime Transport
RP Salama, WM (corresponding author), Pharos Univ, Dept Basic Sci, Fac Engn, Alexandria, Egypt.
EM wessam.salama@pua.edu.eg; ahmed.shokry@alexu.edu.eg; mosaly@aast.edu
RI Aly, Moustafa H./I-9205-2018
OI Aly, Moustafa H./0000-0003-1966-3755; Shokry, Ahmed/0000-0003-3753-8886
FU Science, Technology & Innovation Funding Authority (STDF); The Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Afzali A, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1058-7
   Bagci U, 2012, COMPUT MED IMAG GRAP, V36, P72, DOI 10.1016/j.compmedimag.2011.06.002
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   Bilwaj G, 2016, MED IMAGING COMPUTER
   Cha MJ, 2019, J THORAC IMAG, V34, P86, DOI 10.1097/RTI.0000000000000388
   Fang TT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION ENGINEERING TECHNOLOGY (CCET), P286, DOI 10.1109/CCET.2018.8542189
   Han GH, 2018, MED BIOL ENG COMPUT, V56, P2201, DOI 10.1007/s11517-018-1850-z
   He KM, 2019, IEEE I CONF COMP VIS, P4917, DOI 10.1109/ICCV.2019.00502
   Joo W, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107514
   Lakhani P, 2017, RADIOLOGY, V284, P574, DOI 10.1148/radiol.2017162326
   Li XH, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107049
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lo SCB, 1995, NEURAL NETWORKS, V8, P1201, DOI 10.1016/0893-6080(95)00061-5
   Lopez R., 2018, ADV NEURAL INFORM PR, P6114
   Masafumi Y, 2019, ARXIV PREPRINT ARXIV
   Masataro A, 2018, ARXIV PREPRINT ARXIV
   Matthews AGD, 2016, JMLR WORKSH CONF PRO, V51, P231
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Paul R, 2016, TOMOGRAPHY, V2, P388, DOI 10.18383/j.tom.2016.00211
   Pehrson LM, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9010029
   Ping G, 2019, COMPUT IND, V109, P72, DOI 10.1016/j.compind.2019.04.013
   Ramachandran SS, 2018, PROC SPIE, V10575, DOI 10.1117/12.2293699
   Saba T, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1455-6
   Saito T, 2017, BIOINFORMATICS, V33, P145, DOI 10.1093/bioinformatics/btw570
   Salehinejad H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P990, DOI 10.1109/ICASSP.2018.8461430
   Shaukat F, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.2.020901
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Tripathi P, 2019, PATTERN RECOGN IMAGE, V29, P167, DOI 10.1134/S105466181901019X
   Wang X., 2017, PROC CVPR IEEE, P2097, DOI [DOI 10.1109/CVPR.2017.369, 10.1109/CVPR.2017.369]
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xie YT, 2018, INFORM FUSION, V42, P102, DOI 10.1016/j.inffus.2017.10.005
   Xu YW, 2019, CLIN CANCER RES, V25, P3266, DOI 10.1158/1078-0432.CCR-18-2495
   Zhang T., International Journal of Performability Engineering, DOI [DOI 10.23940/IJPE.17.08.P17.13581370, 10.23940/ijpe.17.08.p17.13581370]
NR 33
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 23
BP 32705
EP 32722
DI 10.1007/s11042-022-13005-9
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3Y8HJ
UT WOS:000782544600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Huang, WJ
   Yang, W
   Zhang, ZY
   Xi, CP
   Wang, ZH
   Li, YJ
AF Huang, Weijia
   Yang, Wei
   Zhang, Zhengyan
   Xi, Caiping
   Wang, Zehui
   Li, Yuanjiang
TI Liver function classification based on local direction number and
   non-local binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Liver function classification; Gabor filters; Local direction number;
   Non-local binary pattern; CT image
ID TEXTURE; HISTOGRAM; CIRRHOSIS; FACE
AB Liver function can be used to track secretion, excretion, synthesis, and reserve function. This research proposes a new method based on CT images to address the problem of current methods of liver function measurement being invasive and insufficiently. To begin, Gabor filters are employed to extract the multiscale texture features of the region of interest in CT image, and the principal directions of each scale are encoded in a compact numerical mode in order to extract more discriminative features. Second, to achieve a wide range of pixel relationships, the non-local binary mode is used. Finally, the support vector machine is used to classify features. Extensive experiments have shown that evaluating liver function using a CT image is both feasible and effective. The relationship between liver function grades and CT image is examined using the model for end stage liver disease (MELD) score. It provides non-invasive and more efficient image-based auxiliary diagnosis for liver function evaluation.
C1 [Huang, Weijia; Zhang, Zhengyan; Xi, Caiping; Wang, Zehui; Li, Yuanjiang] Jiangsu Univ Sci & Technol, Ocean Coll, Zhenjiang 212003, Jiangsu, Peoples R China.
   [Yang, Wei] Jiangsu Prov Hosp, Dept Intervent, Nanjing 210029, Peoples R China.
   [Yang, Wei] Nanjing Med Univ, Affiliated Hosp 1, Nanjing 210029, Peoples R China.
C3 Jiangsu University of Science & Technology; Nanjing Medical University;
   Nanjing Medical University
RP Zhang, ZY (corresponding author), Jiangsu Univ Sci & Technol, Ocean Coll, Zhenjiang 212003, Jiangsu, Peoples R China.
EM zhangzhengyan@just.edu.cn
RI zhengyan, zhang/D-2029-2012; Xi, Caiping/JMP-5817-2023
FU National Natural Science Foundation of China [61901195]
FX This work was part of a project funded by "The National Natural Science
   Foundation of China" (Grant No. 61901195).
CR Bourkache N., 2020, P 2020 INT MULT ORG, DOI [10.1109/OCTA49274.2020.9151681, DOI 10.1109/OCTA49274.2020.9151681]
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Devi RM, 2020, SOFT COMPUT, V24, P18591, DOI 10.1007/s00500-020-05094-1
   Duan J, 2016, MED PHYS, V43, P3378, DOI 10.1118/1.4955795
   El Idrissi A, 2020, IET BIOMETRICS, V9, P143, DOI 10.1049/iet-bmt.2019.0103
   Elkilany A, 2021, ABDOM RADIOL, V46, P979, DOI 10.1007/s00261-020-02731-z
   Geetha R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1402-6
   Hosny KM, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5567489
   Hosny KM, 2021, MULTIMED TOOLS APPL, V80, P13179, DOI 10.1007/s11042-020-10444-0
   Kamath PS, 2007, HEPATOLOGY, V45, P797, DOI 10.1002/hep.21563
   Karanwal S, 2021, DIGIT SIGNAL PROCESS, V110, DOI 10.1016/j.dsp.2020.102948
   Kim WR, 2016, J HEPATOL, V64, P773, DOI 10.1016/j.jhep.2015.11.012
   Lee H, 2021, MED PHYS, V48, P5029, DOI 10.1002/mp.15118
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li ZJ, 2017, BMC MED IMAGING, V17, DOI 10.1186/s12880-017-0212-x
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu Xiaohong Z., 2019, COMPUT SCI, V46, P125
   Lu L, 2012, 2012 25 IEEE CAN C E
   Mao B, 2021, EUR RADIOL, V31, P4576, DOI 10.1007/s00330-020-07562-6
   Palmieri C, 2021, ESMO OPEN, V6, DOI 10.1016/j.esmoop.2021.100162
   Porebski A, 2020, J IMAGING, V6, DOI 10.3390/jimaging6060053
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Shankar K, 2020, J SUPERCOMPUT, V76, P1128, DOI 10.1007/s11227-018-2469-4
   Sharma S., 2019, International Journal of Image, Graphics and Signal Processing, V11, P35, DOI [DOI 10.5815/IJIGSP.2019.03.05, 10.5815/ijigsp.2019.03.05]
   Siddiqi AA, 2020, MEHRAN UNIV RES J EN, V39, P751, DOI 10.22581/muet1982.2004.07
   Song T., 2020, IEEE T CIRCUITS SYST, V99, P1
   Uddin MP, 2021, IETE TECH REV, V38, P377, DOI 10.1080/02564602.2020.1740615
   Wang MY, 2021, BRIT J CANCER, V125, P1111, DOI 10.1038/s41416-021-01511-w
   Yang BQ, 2016, MULTIMED TOOLS APPL, V75, P6979, DOI 10.1007/s11042-015-2623-4
   Yang H, 2021, IEEE T IMAGE PROCESS, V30, P3858, DOI 10.1109/TIP.2021.3065843
   Yip SSF, 2016, PHYS MED BIOL, V61, pR150, DOI 10.1088/0031-9155/61/13/R150
   Zaydfudim VM, 2020, AM J SURG, V220, P682, DOI 10.1016/j.amjsurg.2020.01.022
   Zhang S, 2012, INT C WAV AN PATT RE
   Zhao H, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107272
   Zhou E, 2005, IEEE WCNC, P18
   Zollanvari A, 2021, PATTERN RECOGN LETT, V151, P41, DOI 10.1016/j.patrec.2021.07.026
NR 36
TC 0
Z9 0
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32305
EP 32322
DI 10.1007/s11042-022-12986-x
EA APR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000781941300001
DA 2024-07-18
ER

PT J
AU Wu, CL
   Yang, CK
   Lin, YL
AF Wu, Chia-Lin
   Yang, Chuan-Kai
   Lin, Yi-Ling
TI Privacy protection and beautification of cornea images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Corneal reflection; Iris localization; Image super-resolution; Object
   recognition; Image privacy
AB Thanks to the technological advances, social media has become more popular year by year, especially when it is common to upload selfies to the Internet where anyone from anywhere can have access to them, thus leading to some privacy issue. More specifically, when a selfie photo is relatively clear and bright, there could be a high probability of revealing a person's locations and/or some associated information. In this paper, a framework is designed to automatically obtain the cornea information. First, the Haar Cascade algorithm is applied on the captured eye area and a find-tuned YOLO object detector is then used for iris localization. Next, an image calibration is performed to get a more accurate identification. Furthermore, image super resolution and denoising are applied to boost the image quality. Finally, Google Vision API is used for object detection. Experimental results indicate that certain privacy information could be obtained from a photo via aforementioned processes, especially when some person information can be identified. More specifically, for certain phones when the image capturing distance is around 50 cm, the probability to identify a person (from Google Vision API) can be as high as 60%. Although lowering image quality could help reduce the risk of privacy exposure, it could make the photo undesirably blur. To address these issues, a novel method is proposed to remove sensitive privacy information while at the same time being able to produce eye-stunning images.
C1 [Wu, Chia-Lin; Yang, Chuan-Kai; Lin, Yi-Ling] Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
C3 National Taiwan University of Science & Technology
RP Yang, CK (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Informat Management, 43,Sec 4,Keelung Rd, Taipei 106, Taiwan.
EM cruisewu98@gmail.com; ckyang@cs.ntust.edu.tw; elina10920@gmail.com
FU Ministry of Science and Technology of Taiwan [MOST 109-2221-E-011-133,
   MOST 109-2228-E-011-007]
FX This work was supported in part by the Ministry of Science and
   Technology of Taiwan under the grants MOST 109-2221-E-011-133 and MOST
   109-2228-E-011-007.
CR [Anonymous], AMAZON RING LIGHT PR
   Boyle M., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P1, DOI 10.1145/358916.358935
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Gafni O, 2019, IEEE I CONF COMP VIS, P9377, DOI 10.1109/ICCV.2019.00947
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Gross Ralph, 2009, FACE DEIDENTIFICATIO, P129
   Grotta SW, 2012, IEEE SPECTRUM, V49, P22, DOI 10.1109/MSPEC.2012.6189568
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Jaehan Koh, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2852, DOI 10.1109/ICPR.2010.699
   Jenkins R, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083325
   Kaufman P L, J NEUROOPHTHALMOL, V24, P348
   Kelby S, 2010, DIGITAL PHOTOGRAPHY, V3
   Kerr D.A., 2007, APEX THE ADDITIVE SY
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim J, 2016, IEEE CONF COMPUT
   Kumar V, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMPUTING AND CONTROL (ISPCC), P277, DOI 10.1109/ISPCC.2015.7375040
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lin JC, 2021, NEURAL NETWORKS, V133, P132, DOI 10.1016/j.neunet.2020.09.001
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Meng L, 2017, IET SIGNAL PROCESS, V11, P1039, DOI 10.1049/iet-spr.2016.0761
   Meng LL, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1234, DOI 10.1109/MIPRO.2014.6859756
   Menon S, 2020, PROC CVPR IEEE, P2434, DOI 10.1109/CVPR42600.2020.00251
   Mundhenk TN, 2000, P SOC PHOTO-OPT INS, V4197, P181, DOI 10.1117/12.403762
   Pech-Pacheco JL, 2000, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2000.903548
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Redmon J, 2020, DARKNET
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ribaric S, 2015, IEEE INT CONF AUTOMA
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang Xiang-de, 2011, Journal of Northeastern University (Natural Science), V32, P1550
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
NR 41
TC 0
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32421
EP 32448
DI 10.1007/s11042-022-12530-x
EA APR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600007
DA 2024-07-18
ER

PT J
AU Das, KN
   Dutta, S
   Raju, MSS
   Roy, PD
AF Das, Kedar Nath
   Dutta, Saykat
   Raju, M. Sri Srinivasa
   Roy, Pradip Deb
TI A robust environmental selection strategy in decomposition based
   many-objective optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Evolutionary algorithm; Many-objective optimization; Convergence;
   Diversity; Decomposition; Selection
ID NONDOMINATED SORTING APPROACH; MULTIOBJECTIVE OPTIMIZATION; EVOLUTIONARY
   ALGORITHM; INDICATOR
AB Many researchers witness the efficiency of decomposition-based evolutionary multi- and many-objective optimization algorithms in finding quality solutions on problems with regular Pareto front. These decomposition-based evolutionary approaches profoundly depend on aggregation methods and weight vectors. Such algorithms fail to guarantee the diversity in the population, especially when dealing with irregular Pareto front, because some of the weight vectors become ineffective during simulation. Efforts are being made over time to frequently adopt the position of weight vectors at the rate of increased computation burden, in order to achieve improved solutions. Hence an alternative mechanism has been suggested in this paper. Instead of changing the weight vector, a better treatment on environmental selection is proposed that could effectively balance both convergence and diversity in solving both multi- and many-objective optimization problems. The higher rate of performance of the proposed algorithm has been validated over the comparative permanence with six popular state-of-the-art algorithms in terms of hypervolume, complemented with winning ratio using t-test. It is concluded in the latter part of this paper that the proposed method performs better while solving test suite problems with irregular Pareto fronts. Moreover, it is more prone towards better solutions with an increase in the number of objective functions in MaOPs.
C1 [Das, Kedar Nath; Dutta, Saykat; Raju, M. Sri Srinivasa; Roy, Pradip Deb] Natl Inst Technol Silchar, Silchar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Dutta, S (corresponding author), Natl Inst Technol Silchar, Silchar, India.
EM saykat_rs@math.nits.ac.in
RI dutta, saykat/ABE-3044-2021; M, Sri Srinivasa Raju/GNH-4935-2022
OI dutta, saykat/0000-0002-0691-7237; 
CR Al-Dujaili A, 2018, INFORM SCIENCES, V424, P159, DOI 10.1016/j.ins.2017.09.066
   Bejinariu SI, 2017, E-HEALTH BIOENG CONF, P442, DOI 10.1109/EHB.2017.7995456
   Cheng R, 2016, IEEE T EVOLUT COMPUT, V20, P773, DOI 10.1109/TEVC.2016.2519378
   Das I, 1998, SIAM J OPTIMIZ, V8, P631, DOI 10.1137/S1052623496307510
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deb K., 1995, Complex Systems, V9, P115
   Deb K., 2005, Evolutionary Multiobjective Optimization: Theoretical Advances and Applications, DOI DOI 10.1007/1-84628-137-7_6
   Deb K, 2014, IEEE T EVOLUT COMPUT, V18, P577, DOI 10.1109/TEVC.2013.2281535
   Donoso Y., 2007, Multi-Objective Optimization in Computer Networks Using Metaheuristics
   Dutta S, 2019, ADV INTELL SYST COMP, V817, P807, DOI 10.1007/978-981-13-1595-4_64
   Elarbi M, 2020, IEEE T EVOLUT COMPUT, V24, P809, DOI 10.1109/TEVC.2019.2958921
   Elarbi M, 2017, ADAPT LEARN OPTIM, V20, P1, DOI 10.1007/978-3-319-42978-6_1
   Ishibuchi H, 2017, IEEE T EVOLUT COMPUT, V21, P169, DOI 10.1109/TEVC.2016.2587749
   Ishibuchi H, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P861, DOI 10.1109/SSCI.2015.127
   Jain H, 2014, IEEE T EVOLUT COMPUT, V18, P602, DOI 10.1109/TEVC.2013.2281534
   Kamila NK, 2016, CLUSTER COMPUT, V19, P1723, DOI 10.1007/s10586-016-0643-0
   Lezcano C, 2020, HELIYON, V6, DOI 10.1016/j.heliyon.2020.e03670
   Li K, 2015, IEEE T EVOLUT COMPUT, V19, P694, DOI 10.1109/TEVC.2014.2373386
   Liagkouras K., 2013, ICCCN P INT C COMP C, DOI 10.1109/ICCCN.2013.6614105
   Liu QQ, 2019, IEEE C EVOL COMPUTAT, P1726, DOI [10.1109/CEC.2019.8790214, 10.1109/cec.2019.8790214]
   Nakib A, 2008, PATTERN RECOGN LETT, V29, P161, DOI 10.1016/j.patrec.2007.09.008
   Nakib A, 2010, ENG APPL ARTIF INTEL, V23, P313, DOI 10.1016/j.engappai.2009.09.002
   Pamulapati Trinadh, 2019, IEEE Transactions on Evolutionary Computation, V23, P346, DOI 10.1109/TEVC.2018.2848921
   Sato H, 2014, GECCO'14: PROCEEDINGS OF THE 2014 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P645, DOI 10.1145/2576768.2598297
   Shang K, 2021, IEEE T EVOLUT COMPUT, V25, P1, DOI 10.1109/TEVC.2020.3013290
   Trivedi A, 2017, IEEE T EVOLUT COMPUT, V21, P440, DOI 10.1109/TEVC.2016.2608507
   While L, 2006, IEEE T EVOLUT COMPUT, V10, P29, DOI 10.1109/TEVC.2005.851275
   Yuan Y, 2016, IEEE T EVOLUT COMPUT, V20, P16, DOI 10.1109/TEVC.2015.2420112
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
   Zhang XY, 2015, IEEE T EVOLUT COMPUT, V19, P761, DOI 10.1109/TEVC.2014.2378512
   Zhou YR, 2019, IEEE T CYBERNETICS, V49, P2073, DOI 10.1109/TCYB.2018.2819360
   Zitzler E, 2004, LECT NOTES COMPUT SC, V3242, P832
   Zitzler E, 1998, LECT NOTES COMPUT SC, V1498, P292, DOI 10.1007/BFb0056872
NR 33
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 7971
EP 7989
DI 10.1007/s11042-022-12974-1
EA APR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000781124000003
DA 2024-07-18
ER

PT J
AU Tora, H
   Gokcay, E
   Turan, M
   Buker, M
AF Tora, Hakan
   Gokcay, Erhan
   Turan, Mehmet
   Buker, Mohamed
TI A generalized Arnold's Cat Map transformation for image scrambling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image scrambling; Arnold's Cat Map; Information security; Transformation
   matrix; Chaotic maps
AB This study presents a new approach to generate the transformation matrix for Arnold's Cat Map (ACM). Matrices of standard and modified ACM are well known by many users. Since the structure of the possible matrices is known, one can easily select one of them and use it to recover the image with several trials. However, the proposed method generates a larger set of transform matrices. Thus, one will have difficulty in estimating the transform matrix used for scrambling. There is no fixed structure for our matrix as in standard or modified ACM, making it much harder for the transform matrix to be discovered. It is possible to use different type, order and number of operations to generate the transform matrix. The quality of the shuffling process and the strength against brute-force attacks of the proposed method is tested on several benchmark images.
C1 [Tora, Hakan] Atilim Univ, Dept Elect & Elect Engn, Ankara, Turkey.
   [Gokcay, Erhan] Atilim Univ, Dept Software Engn, Ankara, Turkey.
   [Turan, Mehmet] Atilim Univ, Dept Math, Ankara, Turkey.
   [Buker, Mohamed] Atilim Univ, Grad Sch Nat & Appl Sci, Ankara, Turkey.
C3 Atilim University; Atilim University; Atilim University; Atilim
   University
RP Tora, H (corresponding author), Atilim Univ, Dept Elect & Elect Engn, Ankara, Turkey.
EM hakan.tora@atilim.edu.tr; erhan.gokcay@atilim.edu.tr;
   mehmet.turan@atilim.edu.tr; bouker65@yahoo.com
RI Turan, Mehmet/JYQ-4459-2024; Gokcay, Erhan/JOK-0734-2023
OI Gokcay, Erhan/0000-0002-4220-199X; Turan, Mehmet/0000-0002-1718-3902;
   Tora, Hakan/0000-0002-0427-483X
CR Abood May H., 2017, 2017 Annual Conference on New Trends in Information & Communications Technology Applications (NTICT), P86, DOI 10.1109/NTICT.2017.7976154
   Anwar S, 2019, MULTIMED TOOLS APPL, V78, P27569, DOI 10.1007/s11042-019-07852-2
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Gupta Kamlesh., 2011, Journal of Information Security, V2, P139, DOI DOI 10.4236/JIS.2011.24014
   Huan Zhang, 2010, 2010 International Conference on Intelligent Computing and Integrated Systems (ICISS 2010), P113, DOI 10.1109/ICISS.2010.5656735
   Kumar Tarun, 2018, International Journal of Computer Network and Information Security, V10, P60, DOI 10.5815/ijcnis.2018.03.07
   Lin KT, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P84, DOI 10.1109/IIH-MSP.2013.30
   Mohamed NA, 2016, INT J ADV COMPUT SC, V7, P208
   Musanna F, 2018, P 2 INT C COMP VIS I, P365
   Qi DX, 2000, SCI CHINA SER E, V43, P304, DOI 10.1007/BF02916835
   Shalaby MAW, 2020, 2020 2 NOV INT LEAD
   Shang ZW, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P2942, DOI 10.1109/ICYCS.2008.99
   Sinha RK, 2018, 2018 INT C CURR TREN
   Souza CEC, 2021, IEEE T CIRCUITS-II, V68, P491, DOI 10.1109/TCSII.2020.3010477
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Weigang Zou, 2010, 2010 International Symposium on Information Science and Engineering (ISISE 2010), P415, DOI 10.1109/ISISE.2010.98
   Zhang L, 2020, MULTIMED TOOLS APPL, V79, P20753, DOI 10.1007/s11042-020-08835-4
   Zou JC, 2003, 2003 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS, AND SIGNAL PROCESSING, VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P708
NR 19
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31349
EP 31362
DI 10.1007/s11042-022-11985-2
EA APR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700004
DA 2024-07-18
ER

PT J
AU Hu, YW
   Zhan, JL
   Zhou, GX
   Chen, AB
   Li, JY
AF Hu, Yaowen
   Zhan, Jialei
   Zhou, Guoxiong
   Chen, Aibin
   Li, Jiayong
TI Pulmonary nodules recognition based on parallel cross-convolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung cancer recognition; Parallel cross-convolution neural network;
   Segmentation of lung parenchyma; Low dose CT image
ID FALSE-POSITIVE REDUCTION; COMPUTER-AIDED DETECTION; AUTOMATIC DETECTION;
   LUNG
AB Lung cancer is the highest incidence rate and mortality rate in human beings. Pulmonary nodules are the early manifestation of lung cancer. The accurate identification of pulmonary nodules is of great significance for the treatment and response of early lung cancer, and can effectively improve the life expectancy of lung cancer patients. In order to improve the recognition rate of lung cancer, this paper proposes a lung cancer recognition method based on parallel cross convolution neural network, which aims to solve the problems of gray scale classification, image edge blur, local body effect, artifact and noise in low-dose CT images. Firstly, the low-dose CT images are preprocessed. Then, the parallel cross convolution neural network model is used to classify pulmonary nodules. The model uses two data streams with different steps to extract image features, and is optimized by improved excitation function and batch regularization method. The experimental results show that the accuracy of pccnn proposed in this paper for pulmonary nodules or lung cancer is 97.78%. This shows that the combination of lung parenchyma cutting and parallel cross convolution neural network model can extract image features more deeply and improve the accuracy of lung cancer recognition.
C1 [Hu, Yaowen; Zhan, Jialei; Zhou, Guoxiong; Chen, Aibin; Li, Jiayong] Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
C3 Central South University of Forestry & Technology
RP Zhou, GX (corresponding author), Cent South Univ Forestry & Technol, Coll Comp & Informat Engn, Changsha 410004, Peoples R China.
EM 294736058@qq.com; 522987225@qq.com; zhougx01@163.com; 5708111@qq.com;
   2320368245@qq.com
OI Hu, Yaowen/0000-0003-2081-9358; Zhou, Guoxiong/0000-0002-5142-4845;
   Zhan, Jialei/0000-0001-8826-8279
FU National Natural Science Foundation in China [61703441]
FX This work was supported by the National Natural Science Foundation in
   China (Grant No. 61703441).
CR Bar Y, 2015, I S BIOMED IMAGING, P294, DOI 10.1109/ISBI.2015.7163871
   Choi WJ, 2014, COMPUT METH PROG BIO, V113, P37, DOI 10.1016/j.cmpb.2013.08.015
   de Carvalho AO, 2017, MED BIOL ENG COMPUT, V55, P1199, DOI 10.1007/s11517-016-1582-x
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   He, 2017, RES LOW DOSE CT IMAG
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jacobs C, 2014, MED IMAGE ANAL, V18, P374, DOI 10.1016/j.media.2013.12.001
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Khodatars M, 2021, COMPUT BIOL MED, V139, DOI 10.1016/j.compbiomed.2021.104949
   Krishnamurthy S, 2016, INT C REC TRENDS IM, P343
   Li F, 2002, RADIOLOGY, V225, P673, DOI 10.1148/radiol.2253011375
   Li Q, 2021, INT IMMUNOPHARMACOL, V96, DOI 10.1016/j.intimp.2021.107764
   Li Yong, 2015, Optics and Precision Engineering, V23, P550, DOI 10.3788/OPE.20152302.0550
   Liang Y., 2021, IEEE INT C COMPUTATI, P1
   Mei J, 2022, IEEE T PATTERN ANAL, V44, P4374, DOI 10.1109/TPAMI.2021.3065086
   Meng FQ, 2021, MOL MICROBIOL, V116, P298, DOI 10.1111/mmi.14709
   Messay T, 2010, MED IMAGE ANAL, V14, P390, DOI 10.1016/j.media.2010.02.004
   Oudkerk M, 2021, NAT REV CLIN ONCOL, V18, P135, DOI 10.1038/s41571-020-00432-6
   Ravi V., 2021, IEEE Transactions on Engineering Management
   Ravi V., 2021, ADV ARTIFICIAL INTEL, P227, DOI [10.1007/978-3-030-69951-2_9, DOI 10.1007/978-3-030-69951-2_9]
   Ravi V, 2022, MULTIMEDIA SYST, V28, P1401, DOI 10.1007/s00530-021-00826-1
   Roth HR, 2016, IEEE T MED IMAGING, V35, P1170, DOI 10.1109/TMI.2015.2482920
   Saood A, 2021, BMC MED IMAGING, V21, DOI 10.1186/s12880-020-00529-5
   Setio AAA, 2015, MED PHYS, V42, P5642, DOI 10.1118/1.4929562
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shoeibi A, 2020, ARXIV PREPRINT ARXIV
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Sone S, 1998, LANCET, V351, P1242, DOI 10.1016/S0140-6736(97)08229-9
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tajbakhsh N, 2017, PATTERN RECOGN, V63, P476, DOI 10.1016/j.patcog.2016.09.029
   Tan M, 2011, MED PHYS, V38, P5630, DOI 10.1118/1.3633941
   Tao, 2015, COMPUTER SCI EXPLORA, V9, P234
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Yang J L, 2016, Sci. Technol. Eng, V16, P69
   Ye XJ, 2009, IEEE T BIO-MED ENG, V56, P1810, DOI 10.1109/TBME.2009.2017027
   Zhang, 2015, STUDY IMAGE QUALITY
NR 37
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29137
EP 29158
DI 10.1007/s11042-022-12908-x
EA APR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777384900002
DA 2024-07-18
ER

PT J
AU Jiang, N
   Zhuang, Y
   Hu, H
   Chiu, DKW
AF Jiang, Nan
   Zhuang, Yi
   Hu, Hua
   Chiu, Dickson K. W.
TI Local-privacy-preserving-based and partition-based batch transmission of
   sectional medical image sequences in recourse-constraint mobile
   telemedicine systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sectional medical image; Multi-resolution; Mobile telemedicine system;
   Batch transmission; Privacy preserving
ID EFFICIENT; RETRIEVAL; SCHEME
AB As sectional medical image(SMI) sequence(e.g., computed tomography(CT) and magnetic resonance imaging(MRI)) usually consists of a several neighboring and visually similar medical images with temporal information. In the state-of- the-art SMI transmission methods, multiple neighboring SMIs are usually transmitted one by one which is very inefficient. The paper proposes an effective and efficient local-privacy-preserving-based and partition-based batch transmission scheme for the SMI sequences called the Btsi method via analyzing the visual content of the neighboring SMIs in the sequence based on the characteristics of a recourse-constraint mobile telemedicine system(MTS) and the SMIs. Three enabling techniques, i.e., 1) local privacy preserving(LPP) scheme, 2) sequence partition scheme, 3) partition-based RIB replicas selection are devised to better facilitate the Btsi processing. To the best of our knowledge, this is the first study on the sectional medical image sequence transmission from the perspective of image batching. The experimental results show that our approach is more efficient than the state-of-the-art methods, significantly minimizing the response time by decreasing the network communication cost while improving the transmission throughput.
C1 [Jiang, Nan] Zhejiang Univ, Sch Med, Affiliated Hangzhou Peoples Hosp 1, Hangzhou, Peoples R China.
   [Zhuang, Yi] Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Apart 1701,Unit 1,Blg 8, Hangzhou, Peoples R China.
   [Hu, Hua] Hangzhou Normal Univ, Hangzhou, Peoples R China.
   [Chiu, Dickson K. W.] Univ Hong Kong, Fac Educ, Hong Kong, Peoples R China.
C3 Zhejiang University; Zhejiang Gongshang University; Hangzhou Normal
   University; University of Hong Kong
RP Zhuang, Y (corresponding author), Zhejiang Gongshang Univ, Coll Comp & Informat Engn, Apart 1701,Unit 1,Blg 8, Hangzhou, Peoples R China.
EM zhuang@mail.zjgsu.edu.cn
RI Chiu, Dickson K. W./B-9630-2017
OI Chiu, Dickson K. W./0000-0002-7926-9568
FU Zhejiang Provincial Natural Science Foundation of China [Y22F021788];
   Zhejiang Public Welfare Technology Application Research Project
   [GF22H185665]; Zhejiang Medical and Health Research Project [2019RC070]
FX The authors would like to thank the editors and anonymous reviewers for
   their helpful comments. This work is partially supported by Zhejiang
   Provincial Natural Science Foundation of China under Grant
   No.Y22F021788; the Zhejiang Public Welfare Technology Application
   Research Project under grant No.GF22H185665; the Zhejiang Medical and
   Health Research Project under grant No. 2019RC070.
CR Al-Haj A, 2015, IET INFORM SECUR, V9, P365, DOI 10.1049/iet-ifs.2014.0245
   Allcock B, 2002, PARALLEL COMPUT, V28, P749, DOI 10.1016/S0167-8191(02)00094-7
   [Anonymous], 2010, ANDROID PLATFORM
   Arslan SS, 2012, IEEE T IMAGE PROCESS, V21, P3586, DOI 10.1109/TIP.2012.2195668
   Aziz SM, 2013, IEEE COMMUN LETT, V17, P1084, DOI 10.1109/LCOMM.2013.050313.121933
   Boluk PS, 2011, MOBILE NETW APPL, V16, P149, DOI 10.1007/s11036-010-0282-2
   Chang CC, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1774
   Chang CC, 2003, VISUAL COMPUT, V19, P342, DOI 10.1007/s00371-002-0186-7
   Chang RC, 2008, J INF SCI ENG, V24, P691
   Chin-Chen Chang, 1999, Fifth Asia-Pacific Conference on Communications and Fourth Optoelectronics and Communications Conference. APCC/OECC'99. Proceedings. Conference - Vitality to the New Century (IEEE Cat. No.99EX379), P892, DOI 10.1109/APCC.1999.820406
   DANSKIN JM, 1995, ACM MULTIMEDIA
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gao DH, 2010, LECT NOTES ARTIF INT, V6216, P334
   Hashimoto M, 1999, GLOBECOM'99: SEAMLESS INTERCONNECTION FOR UNIVERSAL SERVICES, VOL 1-5, P2208, DOI 10.1109/GLOCOM.1999.827596
   Hemalatha R, 2015, COMPUT ELECTR ENG, V44, P67, DOI 10.1016/j.compeleceng.2015.01.011
   Jiang N, 2017, COMPUT METH PROG BIO, V145, P103, DOI 10.1016/j.cmpb.2017.04.002
   Kim JH, 1996, IEE P-VIS IMAGE SIGN, V143, P132, DOI 10.1049/ip-vis:19960254
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Maani R, 2012, J DIGIT IMAGING, V25, P101, DOI 10.1007/s10278-011-9387-9
   Manimurugan S, 2015, INT J DIGIT CRIME FO, V7, P26, DOI [10.4018/ijdcf.2015010102, 10.4018/IJDCF.2015010102]
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Qureshi A, 2005, P ANN INT IEEE EMBS, P3942, DOI 10.1109/IEMBS.2005.1615324
   Raman S, 2000, 2000 INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, PROCEEDINGS, P209, DOI 10.1109/ICNP.2000.896305
   Rostami M, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104210
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Rostami M, 2020, GENOMICS, V112, P4370, DOI 10.1016/j.ygeno.2020.07.027
   Ruiz V., 2001, P 19 IASTED INT C AP, P519
   Sun Y, 2006, IEEE T MOBILE COMPUT, V5, P1016, DOI 10.1109/TMC.2006.120
   Turner C. J., 1992, Computer Communication Review, V22, P258, DOI 10.1145/144191.144296
   TZOU KH, 1987, OPT ENG, V26, P581, DOI 10.1117/12.7974121
   Xu HS, 2015, DIGIT COMMUN NETW, V1, P213, DOI 10.1016/j.dcan.2015.05.002
   Yaghmai V, 2004, ACAD RADIOL, V11, P1291, DOI 10.1016/j.acra.2004.07.020
   Zhuang Y, 2016, MULTIMED TOOLS APPL, V75, P2931, DOI 10.1007/s11042-014-2413-4
   Zhuang Y, 2014, INFORM SCIENCES, V263, P60, DOI 10.1016/j.ins.2013.10.013
NR 35
TC 2
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 29093
EP 29118
DI 10.1007/s11042-022-12663-z
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777241700001
DA 2024-07-18
ER

PT J
AU Kukreja, V
   Sakshi
AF Kukreja, Vinay
   Sakshi
TI Machine learning models for mathematical symbol recognition: A stem to
   stern literature analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Handwritten mathematical symbol
   recognition; Machine learning; Mathematical symbol recognition; Optical
   character recognition; Support vector machine; Segmentation
ID HANDWRITTEN; ONLINE; MATH; SYSTEM
AB Given the ubiquity of handwriting and mathematical content in human transactions, machine recognition of handwritten mathematical text and symbols has become a domain of great practical scope and significance. Recognition of mathematical expression (ME) has remained a challenging and emerging research domain, with mathematical symbol recognition (MSR) as a requisite step in the entire recognition process. Many variations in writing styles and existing dissimilarities among the wide range of symbols and recurring characters make the recognition tasks strenuous even for Optical Character Recognition. The past decade has witnessed the emergence of recognition techniques and the peaking interest of several researchers in this evolving domain. In light of the current research status associated with recognizing handwritten math symbols, a systematic review of the literature seems timely. This article seeks to provide a complete systematic analysis of recognition techniques, models, datasets, sub-stages, accuracy metrics, and accuracy details in an extracted form as described in the literature. A systematic literature review conducted in this study includes pragmatic studies until the year 2021, and the analysis reveals Support Vector Machine (SVM) to be the most dominating recognition technique and symbol recognition rate to be most frequently deployed accuracy measure and other interesting results in terms of segmentation, feature extraction and datasets involved are vividly represented. The statistics of mathematical symbols-related papers are shown, and open problems are identified for more advanced research. Our study focused on the key points of earlier research, present work, and the future direction of MSR.
C1 [Kukreja, Vinay; Sakshi] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Sakshi (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
EM onlyvinaykukreja@gmail.com; asakshi541@gmail.com
RI Kukreja, Vinay/AAT-7893-2021
OI Kukreja, Vinay/0000-0002-9760-0824
CR Ali I, 2018, INT ARAB J INF TECHN, V15, P565
   Alvaro F., 2010, P 2010 20 INT C PATT, P1953
   Alvaro F, 2014, INT C PATT RECOG, P2944, DOI 10.1109/ICPR.2014.507
   Alvaro F, 2013, PROC INT CONF DOC, P1012, DOI 10.1109/ICDAR.2013.203
   Baker J.B., 2010, The Ninth IAPR International Workshop on Document Analysis Systems, DAS 2010, June 9-11, 2010, Boston, Massachusetts, USA, P485, DOI [DOI 10.1145/1815330.1815393, 10.1145/1815330.1815393]
   Bouvett E, 2012, IEEE MEDITERR ELECT, P653, DOI 10.1109/MELCON.2012.6196516
   Cao XY, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM DESIGN AND ENGINEERING APPLICATIONS (ISDEA), P803, DOI 10.1109/ISDEA.2012.191
   Chajri Y, 2016, I C COMP GRAPH IM VI, P448, DOI 10.1109/CGiV.2016.92
   Chan KF, 2001, PROC INT CONF DOC, P774, DOI 10.1109/ICDAR.2001.953893
   Chan KF, 2001, PATTERN RECOGN, V34, P1671, DOI 10.1016/S0031-3203(00)00102-3
   Char BW, 2007, PROC INT CONF DOC, P1198
   Chen Y, 2001, INT J PATTERN RECOGN, V15, P967, DOI 10.1142/S021800140100126X
   Clark R, 2013, 2013 IEEE EUROCON, P2029, DOI 10.1109/EUROCON.2013.6625259
   Davila K, 2018, INT CONF FRONT HAND, P50, DOI 10.1109/ICFHR-2018.2018.00018
   Davila K, 2014, INT CONF FRONT HAND, P323, DOI 10.1109/ICFHR.2014.61
   DIMITRIADIS YA, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P944, DOI 10.1109/ICNN.1993.298684
   Drsouza L., 2018, INT C INF COMM ENG T, P1, DOI [10. 1109/ICICET.2018.8533789, DOI 10.1109/ICICET.2018.8533789]
   Fang DB, 2020, IEEE ACCESS, V8, P48101, DOI 10.1109/ACCESS.2020.2979346
   Fang DB, 2019, IEEE INT CONF ELECTR, P226, DOI [10.1109/ICEIEC.2019.8784656, 10.1109/iceiec.2019.8784656]
   Farulla GA, 2016, LECT NOTES COMPUT SC, V9758, P7, DOI 10.1007/978-3-319-41264-1_1
   Firdaus SA, 2020, ADV DECISION SCI IMA, P658, DOI [10.1007/978-3-030-24318-0_75, DOI 10.1007/978-3-030-24318-0_75]
   Garain U, 2004, INT C PATT RECOG, P380, DOI 10.1109/ICPR.2004.1334131
   Tran GS, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON CONTROL, ROBOTICS AND CYBERNETICS (CRC), P15, DOI 10.1109/CRC.2018.00012
   Golubitsky O, 2010, INT J DOC ANAL RECOG, V13, P133, DOI 10.1007/s10032-009-0107-7
   Golubitsky O, 2009, LECT NOTES COMPUT SC, V5625, P460, DOI 10.1007/978-3-642-02614-0_36
   Green BN, 2001, J SPORT CHIROPR REH, V15, P5, DOI 10.1016/S0899-3467(07)60142-6
   Nguyen HD, 2016, IEICE T INF SYST, VE99D, P3110, DOI 10.1587/transinf.2016EDP7102
   Hu L, 2012, INT C PATT RECOG, P326
   Hu L, 2011, PROC INT CONF DOC, P457, DOI 10.1109/ICDAR.2011.98
   Hu R, 2014, INT SYMP SYMB NUMERI, P61, DOI 10.1109/SYNASC.2013.15
   Jakjoud W, 2011, INT C MULTIMEDIA COM, P1, DOI [10.1109/ICMCS.2011.5945634, DOI 10.1109/ICMCS.2011.5945634]
   Jakjoud W, 2009, INT CONF RES CHAL, P427, DOI 10.1109/RCIS.2009.5089307
   Jimenez ND, 2013, RECOGNITION HANDWRIT
   Julca-Aguilar F, 2014, INT CONF FRONT HAND, P500, DOI 10.1109/ICFHR.2014.90
   Kacem A., 2001, International Journal on Document Analysis and Recognition, V4, P97, DOI 10.1007/s100320100064
   Kam-Fai Chan, 2000, International Journal on Document Analysis and Recognition, V3, P3, DOI 10.1007/PL00013549
   Kanahori T, 2000, LECT NOTES COMPUT SC, V1948, P394
   Keshari B, 2008, P MATH US INT WORK
   Keshari B, 2007, PROC INT CONF DOC, P859
   Kitchenham B., 2004, PROCEDURES PERFORMIN, V33, P1
   KURTZBERG JM, 1987, IBM J RES DEV, V31, P91, DOI 10.1147/rd.311.0091
   LEE HJ, 1994, PATTERN RECOGN, V27, P447, DOI 10.1016/0031-3203(94)90121-X
   Li LH, 2009, HIS 2009: 2009 NINTH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS, VOL 3, PROCEEDINGS, P433, DOI 10.1109/HIS.2009.301
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   Luo ZX, 2008, INT CONF ACOUST SPEE, P1953
   MacLean S, 2015, PATTERN RECOGN, V48, P2433, DOI 10.1016/j.patcog.2015.02.017
   MacLean S, 2013, INT J DOC ANAL RECOG, V16, P139, DOI 10.1007/s10032-012-0184-x
   Mahdavi Mahshad, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P647, DOI 10.1109/ICDAR.2019.00109
   Malon C, 2008, PATTERN RECOGN LETT, V29, P1326, DOI 10.1016/j.patrec.2008.02.005
   Malon C, 2006, LECT NOTES COMPUT SC, V4109, P136
   Marinai S, 2011, PROC INT CONF DOC, P1309, DOI 10.1109/ICDAR.2011.263
   Medjkoune S, 2011, PROC INT CONF DOC, P379, DOI 10.1109/ICDAR.2011.84
   Mohamed Shaffril H.A., 2021, QUAL QUANT, V55, P1319, DOI DOI 10.1007/S11135-020-01059-6
   Nazemi A., 2019, arXiv preprint arXiv:1910.07395
   Nguyen HD, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P121, DOI 10.1109/ACPR.2015.7486478
   Okamoto M., 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P121, DOI 10.1109/ICDAR.2001.953767
   Page MJ, 2021, BMJ-BRIT MED J, V372, DOI [10.1136/bmj.n71, 10.1016/j.ijsu.2021.105906, 10.1136/bmj.n160]
   Pathak A, 2019, 2019 2 INT C ADV COM, P1, DOI DOI 10.1109/ICACCP.2019.8882887
   Pillay A, 2014, Intelligent combination of structural analysis algorithms: Application to mathematical expression recognition
   Prusa D, 2007, PROC INT CONF DOC, P849
   Ramadhan I, 2016, 2016 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT)
   Ramirez-Pina C., 2018, IBEROAMERICAN C PATT, V1, P893, DOI [10.1007/ 978-3-030-13469-3, DOI 10.1007/978-3-030-13469-3]
   Sabeghi Saroui B, 2015, PROC INT CONF DOC, P1051, DOI 10.1109/ICDAR.2015.7333922
   Sakshi, 2021, ENG APPL ARTIF INTEL, V103, DOI 10.1016/j.engappai.2021.104292
   Sui Kun Guan, 2019, 2019 International Conference on High Performance Computing & Simulation (HPCS), P185, DOI 10.1109/HPCS48598.2019.9188180
   Takiguchi Y, 2005, PROC INT CONF DOC, P745, DOI 10.1109/ICDAR.2005.10
   Tapia E, 2003, PROC INT CONF DOC, P980
   Tian XD, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1678
   Tian XD, 2006, ICICIC 2006: FIRST INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING, INFORMATION AND CONTROL, VOL 3, PROCEEDINGS, P357
   Toyozumi K, 2004, P 17 INT C PATT REC, V2, P2
   Wang CC, 2016, INT CONF FRONT HAND, P252, DOI [10.1109/ICFHR.2016.0056, 10.1109/ICFHR.2016.51]
   Wang HY, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P461, DOI 10.1109/ISCIT.2016.7751674
   Wang J., 2020, Pattern Recogn, V119, P1
   Watt SM, 2005, PROC INT CONF DOC, P740, DOI 10.1109/ICDAR.2005.195
   Watt SM, 2005, PROTOTYPE PRUNING FE
   Shi Y, 2007, PROC INT CONF DOC, P854
   Zanibbi R, 2001, PROC INT CONF DOC, P768, DOI 10.1109/ICDAR.2001.953892
   Zanibbi R, 2002, IEEE T PATTERN ANAL, V24, P1455, DOI 10.1109/TPAMI.2002.1046157
   Zanibbi R, 2012, INT J DOC ANAL RECOG, V15, P331, DOI 10.1007/s10032-011-0174-4
   Zhang DY, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P251, DOI 10.1109/ICACC.2010.5486679
   Zhao W, 2021, HANDWRITTEN MATH EXP
   Zhao XJ, 1997, PROC INT CONF DOC, P645, DOI 10.1109/ICDAR.1997.620585
   Zhu BL, 2011, PROC INT CONF DOC, P603, DOI 10.1109/ICDAR.2011.127
NR 83
TC 10
Z9 10
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28651
EP 28687
DI 10.1007/s11042-022-12644-2
EA MAR 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000777375900003
DA 2024-07-18
ER

PT J
AU Labinghisa, BA
   Lee, DM
AF Labinghisa, Boney A.
   Lee, Dong Myung
TI Indoor localization system using deep learning based scene recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor localization; Wi-Fi fingerprinting; RSSI; Scene recognition; Deep
   learning
AB One of the major problems of indoor positioning using Wi-Fi is the unstable wireless signal in a large area inside the building. In some buildings, signal path loss occurs due to the partition separating the space. In this case, since it is difficult to identify a specific partition when indoor positioning is performed using only received signal strength indicator (RSSI), a partitioning or segmentation algorithm is required to solve this problem. The proposed system in this paper consists of a scene recognition algorithm suitable for a given environment, an image-based indoor location awareness algorithm (IILAA), and a clustering algorithm that connects these modules to identify not only the exact spatial location but also the scene cluster of the user. The system is composed of a scene recognition module which identifies an image taken by the user. A convolutional neural network trained on resnet50 architecture will identify the scene and forward the classified scene result to another module name mapping algorithm module where KNN is used to process the RSSI received by the user mobile device. As a result of the experiment, first, it was confirmed that the proposed system can recognize an average of 93.07% of a given indoor environment. In addition, it was confirmed that the average error distance of the proposed system is 1.31 m, which is about 6.2 times more accurate than 8.15 m, which is the average error distance of fingerprinting using RSSI. The main factor of this performance result is that the proposed system appropriately selects the classified cluster for each scene in the indoor space. Second, it was confirmed that the proposed IILAA's error distance performance was 1.75 m in an environment in which both clustering/non-clustering fingerprint maps were combined, which is about 3.90 times more accurate than the 6.90 m average error distance of conventional fingerprinting. Finally, the trained model was used on MIT67 dataset to compare its 87. 6% accuracy with other approaches.
C1 [Labinghisa, Boney A.; Lee, Dong Myung] Tongmyong Univ, Busan 48520, South Korea.
C3 Tongmyong University
RP Lee, DM (corresponding author), Tongmyong Univ, Busan 48520, South Korea.
EM blabinghisa@yahoo.com; dmlee@tu.ac.kr
OI Lee, Dong Myung/0000-0002-1314-8763
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2019R1F1A1062670]; Busan Metropolitan City and Busan Institute for
   Talent & Lifelong Education (BIT)
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2019R1F1A1062670). This research was supported by the BB21plus funded by
   Busan Metropolitan City and Busan Institute for Talent & Lifelong
   Education (BIT).
CR Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Cheng XJ, 2018, PATTERN RECOGN, V74, P474, DOI 10.1016/j.patcog.2017.09.025
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Guo YM, 2018, IEEE T MULTIMEDIA, V20, P1525, DOI 10.1109/TMM.2017.2766842
   Güzel MS, 2013, ADV MECH ENG, DOI 10.1155/2013/234747
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Labinghisa BA, 2018, THESIS GRADUATE SCH, P1
   Labinghisa BA, 2020, THESIS GRADUATE SCH, P1
   Labinghisa BA, 2021, J SUPERCOMPUT, V77, P638, DOI 10.1007/s11227-020-03272-4
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Liu H, 2007, IEEE T SYST MAN CY C, V37, P1067, DOI 10.1109/TSMCC.2007.905750
   Machaj J, 2010, PROCEEDINGS OF THE 20TH INTERNATIONAL CONFERENCE, RADIOELETRONIKA 2010, P83, DOI 10.1109/RADIOELEK.2010.5478585
   Matei A, 2020, ARXIVABS200701806
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tang PJ, 2017, NEUROCOMPUTING, V225, P188, DOI 10.1016/j.neucom.2016.11.023
   Tsotsos JK, 2019, IEEE INT C ROB AUT I
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Walther D, 2002, LECT NOTES COMPUT SC, V2525, P472
   Wang Z, 2017, IEEE T IMAGE PROCESS, V26, P2028, DOI 10.1109/TIP.2017.2666739
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 29
TC 10
Z9 10
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28405
EP 28429
DI 10.1007/s11042-022-12481-3
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000775769200007
DA 2024-07-18
ER

PT J
AU Ladi, SK
   Panda, GK
   Dash, R
   Ladi, PK
   Dhupar, R
AF Ladi, Sandeep Kumar
   Panda, G. K.
   Dash, Ratnakar
   Ladi, Pradeep Kumar
   Dhupar, Rohan
TI A Novel Grey Wolf Optimisation based CNN Classifier for Hyperspectral
   Image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Stationary Wavelet Transform (SWT); Principal
   Component Analysis (PCA); Hyperspectral Image classification; Deep
   Learning (DL); Convolutional Neural Network (CNN); Grey Wolf Optimizer
   (GWO); Optimal Hyper-parameters
ID PARTICLE SWARM OPTIMIZATION; FEATURE-EXTRACTION; NETWORKS
AB Hyperspectral image (HI) analysis is becoming popular in remote sensing applications due to its high spectral resolution along with high spatial resolution compared to a Multispectral image. Classification of pixel vectors in a hyperspectral image (HI) to their respective classes is challenging. HI classification is an elementary task for land cover mapping, mineral exploitation, precision agriculture, etc. Optimal parameters are required to reduce the losses in the Convolutional Neural Networks (CNNs) and provide the most accurate results possible. Studies in this regard, so far have been made with manual selection of optimal parameters using traditional trial-and-error methods like the selection of loss function, a number of convolution filters, optimizer function, etc., and found to be strenuous and time-consuming. To alleviate these challenges of selecting the hyperparameters and observing the accuracy until a competitive value is reached, this paper uses a novel mechanism to classify Hyperspectral Images using Convolutional Neural Network (CNN) where the 6-hyperparameters of CNN are optimized with Grey Wolf Optimizer (GWO). The proposed GWO-based-CNN-HI model exhibits better classification accuracy (99.95%, 99.96%, and 99.99%) on three benchmark HI datasets in comparison to traditional models. Thus the novel GWO-based-CNN-HI model finds its suitability in applications of land cover classification, crop stage detection, specially in remote applications with limited computing power.
C1 [Ladi, Sandeep Kumar] GITAM Deemed Univ Visakhapatnam, Visakhapatnam, Andhra Pradesh, India.
   [Panda, G. K.] MITS Bhubaneswar, Bhubaneswar, Odisha, India.
   [Dash, Ratnakar] NIT Rourkela, Rourkela, Odisha, India.
   [Ladi, Pradeep Kumar] GIET Univ Gunupur, Gunupur, Odisha, India.
   [Dhupar, Rohan] Bharti Airtel, Gurugram, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; GIET University
RP Ladi, SK (corresponding author), GITAM Deemed Univ Visakhapatnam, Visakhapatnam, Andhra Pradesh, India.
EM sandeepkmriacr@gmail.com; drgkpmail@gmail.com; ratnakar.dash@gmail.com;
   ladi.pradeep@giet.edu; rohandhupar18@gmail.com
RI Pradeep Kumar, Ladi/HZM-0363-2023; Dash, Ratnakar/F-1498-2018
OI Pradeep Kumar, Ladi/0000-0003-2277-0252; PANDA, GOURI
   KUMAR/0000-0001-6161-7854; Sandeep Kumar, Ladi/0000-0002-3545-2459
CR Antoniadis A., 2013, LECT NOTES STAT
   Beirami BA, 2020, IEEE GEOSCI REMOTE S, V17, P1953, DOI 10.1109/LGRS.2019.2958833
   Back T., 1996, EVOLUTIONARY ALGORIT
   Ben-Dor E, 2002, INT J REMOTE SENS, V23, P1043, DOI 10.1080/01431160010006962
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CI, 2002, IEEE T GEOSCI REMOTE, V40, P375, DOI 10.1109/36.992799
   Chen C, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P454, DOI 10.1109/ACPR.2015.7486544
   Chen YS, 2016, IEEE T GEOSCI REMOTE, V54, P6232, DOI 10.1109/TGRS.2016.2584107
   Chen YS, 2015, IEEE J-STARS, V8, P2381, DOI 10.1109/JSTARS.2015.2388577
   Coifman R. R., 1995, LECT NOTES STAT, V103, P125, DOI [DOI 10.1007/978-1-4612-2544-7_9, 10.1002/cpa.3160410705, DOI 10.1002/CPA.3160410705]
   Dasarathy B. V., 1991, Nearest neighbor (NN) norms, V317
   del Valle Y, 2008, IEEE T EVOLUT COMPUT, V12, P171, DOI 10.1109/TEVC.2007.896686
   Dicker DT, 2006, CANCER BIOL THER, V5, P1033, DOI 10.4161/cbt.5.8.3261
   Ding XH, 2020, IEEE ACCESS, V8, P25789, DOI 10.1109/ACCESS.2020.2971327
   Feng YZ, 2012, CRIT REV FOOD SCI, V52, P1039, DOI 10.1080/10408398.2011.651542
   Fu Y, 2019, DYNAMICALLY DIMENSIO
   Ghamisi P, 2017, IEEE GEOSC REM SEN M, V5, P37, DOI 10.1109/MGRS.2017.2762087
   Gharaati E, 2015, NEW BAND SELECTION M
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Gowen AA, 2007, TRENDS FOOD SCI TECH, V18, P590, DOI 10.1016/j.tifs.2007.06.001
   He K., 2015, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2015.7299173, DOI 10.1109/CVPR.2015.7299173]
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Izonin I, 2019, MULTIPLE LINEAR REGR
   Jia S, 2018, IEEE T GEOSCI REMOTE, V56, P749, DOI 10.1109/TGRS.2017.2754511
   Jia Wu, 2019, Journal of Electronic Science and Technology, V17, P26, DOI 10.11989/JEST.1674-862X.80904120
   Jonnadula H, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP)
   Ladi Sandeep Kumar, 2019, 2019 International Conference on Information Technology (ICIT), P172, DOI 10.1109/ICIT48102.2019.00037
   Lee G.R., 2019, Journal of Open Source Software, V4, P1237, DOI [10.21105/joss.01237, DOI 10.21105/JOSS.01237]
   Letalick D., 2009, Multi-Optical Mine detection System (MOMS) final report
   Li R, 2020, IEEE T GEOSCI REMOTE, V58, P3136, DOI 10.1109/TGRS.2019.2948865
   Li T, 2014, IEEE IMAGE PROC, P5132, DOI 10.1109/ICIP.2014.7026039
   Li Y, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9010067
   Liao WZ, 2019, INT GEOSCI REMOTE SE, P3697, DOI [10.1109/igarss.2019.8899087, 10.1109/IGARSS.2019.8899087]
   Lillesand T.M., 2000, REMOTE SENSING IMAGE, V4th
   Liu B, 2018, IEEE T GEOSCI REMOTE, V56, P1909, DOI 10.1109/TGRS.2017.2769673
   Mercier G, 2003, INT GEOSCI REMOTE SE, P288
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Nakamura RYM, 2014, IEEE T GEOSCI REMOTE, V52, P2126, DOI 10.1109/TGRS.2013.2258351
   Nason G.P., 1995, The Stationary Wavelet Transform and Some Statistical Applications, V103
   Niu PF, 2019, KNOWL-BASED SYST, V171, P37, DOI 10.1016/j.knosys.2019.01.018
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rathod M, 2017, PROCEEDINGS OF 2017 11TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND CONTROL (ISCO 2017), P287, DOI 10.1109/ISCO.2017.7856000
   Rodarmel C, 2002, PRINCIPAL COMPONENT, V62
   Romay D.M.G., HYPERSPECTRAL REMOTE
   Shaheen F, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P638
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Su YC, 2019, IEEE T GEOSCI REMOTE, V57, P4309, DOI 10.1109/TGRS.2018.2890633
   Tao C, 2015, IEEE GEOSCI REMOTE S, V12, P2438, DOI 10.1109/LGRS.2015.2482520
   Tarabalka Y, 2010, INT GEOSCI REMOTE SE, P1410, DOI 10.1109/IGARSS.2010.5649222
   Tarabalka Y, 2009, IEEE T GEOSCI REMOTE, V47, P2973, DOI 10.1109/TGRS.2009.2016214
   Tarek E, 2015, ARXIV PREPRINT ARXIV
   Thomas AM, 2010, IEEE T GEOSCI REMOTE, V48, P3465, DOI 10.1109/TGRS.2010.2046740
   Tkachenko R, 2019, IMBALANCE DATA CLASS
   Tkachenko R, 2019, MODEL PRINCIPLES IMP
   Tkachenko R, 2018, STUD COMPUT INTELL, V730, P537, DOI 10.1007/978-3-319-63754-9_25
   Vaddi R, 2020, INFRARED PHYS TECHN, V107, DOI 10.1016/j.infrared.2020.103296
   Vrbancic G, 2018, J OPEN SOURCE SOFTWA, P3
   Wang YH, 2014, INT C WAVEL ANAL PAT, P104, DOI 10.1109/ICWAPR.2014.6961299
   Wirsing K., 2021, Wavelet Theory, DOI [10.5772/intechopen.94521, DOI 10.5772/INTECHOPEN.94521]
   Xia HY, 2020, IET IMAGE PROCESS, V14, P2013, DOI 10.1049/iet-ipr.2019.1386
   Xu YH, 2018, ISPRS J PHOTOGRAMM, V142, P344, DOI 10.1016/j.isprsjprs.2018.05.014
   Xu YH, 2018, IEEE T GEOSCI REMOTE, V56, P5893, DOI 10.1109/TGRS.2018.2827407
   Yang H, 2012, IEEE J-STARS, V5, P544, DOI 10.1109/JSTARS.2012.2185822
   Yang XS, 2020, J COMPUT SCI-NETH, V46, DOI 10.1016/j.jocs.2020.101104
   Yang XS, 2013, ENG COMPUT-GERMANY, V29, P175, DOI 10.1007/s00366-012-0254-1
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yu CY, 2020, IEEE J-STARS, V13, P2485, DOI 10.1109/JSTARS.2020.2983224
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zhang LP, 2016, IEEE GEOSC REM SEN M, V4, P22, DOI 10.1109/MGRS.2016.2540798
   Zhang TT, 2012, PROCEEDINGS OF 2012 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2012), P103, DOI 10.1109/ICCSNT.2012.6525900
   Zhao WZ, 2016, IEEE T GEOSCI REMOTE, V54, P4544, DOI 10.1109/TGRS.2016.2543748
   Zhong ZL, 2018, IEEE T GEOSCI REMOTE, V56, P847, DOI 10.1109/TGRS.2017.2755542
   ZHOU F, 2018, NEUROCOMPUTING, V328
   Zortea M, 2007, IEEE GEOSCI REMOTE S, V4, P107, DOI 10.1109/LGRS.2006.886429
   2009, STUD COMPUT INTELL, V191, P1
NR 77
TC 8
Z9 8
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 20
BP 28207
EP 28230
DI 10.1007/s11042-022-12628-2
EA MAR 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3E6IF
UT WOS:000774644000004
DA 2024-07-18
ER

PT J
AU Shukla, S
   Banka, H
AF Shukla, Shipra
   Banka, Haider
TI Monophonic music composition using genetic algorithm and Bresenham's
   line algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer music; Genetic algorithm; Bresenham's line algorithm; Melody;
   Rhythm; Music composition
AB Music composition is one of the oldest artistic pursuits. The role of machine in automatic generation of creative artworks, like music, is still an explorable area. In this paper, a new approach for music composition is proposed that differs from previous methods of generating music with predefined musical parameters. The proposed method gives flexibility to change the musical parameters, namely time signature, range and scale. Moreover, the user can also input any desired motif (a short piece of melody) and generate a melody that includes the motif. The type of music composed in this work is monophonic, which includes melody and rhythm. To create a proper sequence of notes, we used genetic algorithm with suitably formulated crossover and mutation operators. The rhythm is generated using Bresenham's line drawing algorithm, which has been modified to adapt different time signature with changing beats. PySynth, a simple music synthesizer, is chosen to convert music into wave file format. In the end, a comparative analysis is conducted to show the efficacy of the proposed model. Results show that the proposed algorithm performs better than conventional genetic algorithm.
C1 [Shukla, Shipra; Banka, Haider] IIT ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Shukla, S (corresponding author), IIT ISM Dhanbad, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM shiprashukla.iit@gmail.com
OI Shukla, Shipra/0000-0002-3532-5214
CR Acampora G, 2011, IEEE INT CONF FUZZY, P202
   Agarwala N., 2017, Music Composition using Recurrent Neural Networks
   [Anonymous], 2017, ARXIV171204371
   [Anonymous], 2016, ARXIV160607251
   [Anonymous], 1994, ICMC
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   Cao XZ, 2015, MULTIMED TOOLS APPL, V74, P9097, DOI 10.1007/s11042-014-2057-4
   Cohen H, 2002, LEONARDO, V35, P59, DOI 10.1162/002409402753689335
   Cope David., 1996, EXPT MUSICAL INTELLI, V12
   Costa EO, 2006, PROC INT C TOOLS ART, P10
   Fernández JD, 2013, J ARTIF INTELL RES, V48, P513, DOI 10.1613/jair.3908
   Davis L., 1991, Handbook of Genetic Algorithms
   Delgado M, 2011, EXPERT SYST APPL, V38, P155, DOI 10.1016/j.eswa.2010.06.033
   Delgado M, 2009, EXPERT SYST APPL, V36, P4574, DOI 10.1016/j.eswa.2008.05.028
   Douglas Eck, 2002, Istituto Dalle Molle Di Studi Sull'Intelligenza Artificiale, V103, P48
   Gartland-Jones A., 2003, CONTEMP MUSIC REV, V22, P43, DOI [DOI 10.1080/0749446032000150870, 10.1080/0749446032000150870]
   Guedes C, 2018, P 15 SOUND MUS COMP
   Hewitt M., 2008, MUSIC THEORY COMPUTE
   Jarrett S., 2008, Music composition for dummies
   Jeong JH, 2015, PROCEEDINGS OF THE 18TH ASIA PACIFIC SYMPOSIUM ON INTELLIGENT AND EVOLUTIONARY SYSTEMS, VOL 2, P105, DOI 10.1007/978-3-319-13356-0_9
   Jeong J, 2017, EXPERT SYST APPL, V90, P50, DOI 10.1016/j.eswa.2017.08.014
   Johanson B., 1998, GP-Music: An Interactive Genetic Programming System for Music Generation with Automated Fitness Raters
   Kikuchi M, 2014, WOR CONG NAT BIOL, P190, DOI 10.1109/NaBIC.2014.6921876
   Kirke AJ, 2019, INT J UNCONV COMPUT, V14, P349
   Loughran R, 2020, GENET PROGRAM EVOL M, V21, P55, DOI 10.1007/s10710-020-09380-7
   Mao HH, 2018, IEEE INT C SEMANT CO, P377, DOI 10.1109/ICSC.2018.00077
   Matic Dragan., 2010, YUGOSLAV J OPERATION, V20, P157
   Miranda E. R., 2007, EVOLUTIONARY COMPUTE
   Navarro M, 2015, LECT NOTES COMPUT SC, V9027, P175, DOI 10.1007/978-3-319-16498-4_16
   Navarro-Cáceres M, 2019, SWARM EVOL COMPUT, V50, DOI 10.1016/j.swevo.2019.05.012
   Ortega de la Puente A., 2002, APL Quote Quad, V32, P148, DOI 10.1145/604444.602249
   Papadopoulos G., 1998, P STEP 98, V98
   Reese KristopherWayne., 2011, COMPUTATIONALLY GENE
   Roig C, 2014, KNOWL-BASED SYST, V71, P419, DOI 10.1016/j.knosys.2014.08.018
   Scirea M, 2016, LECT NOTES COMPUT SC, V9596, P202, DOI 10.1007/978-3-319-31008-4_14
   Shan MK, 2010, MULTIMED TOOLS APPL, V46, P1, DOI 10.1007/s11042-009-0303-y
   Ting CK, 2017, IEEE SYST J, V11, P1284, DOI 10.1109/JSYST.2015.2482602
   Tokui N., 2000, Proceedings of the 3rd international conference on generative art, V17, P215
   Toussaint Godfried, 2005, Proceedings of BRIDGES: Mathematical Connections in Art, Music, and Science, P47
   Yimaz AE, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P670, DOI 10.1109/FUZZY.2009.5277385
NR 40
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 26483
EP 26503
DI 10.1007/s11042-022-12185-8
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000774644100001
DA 2024-07-18
ER

PT J
AU Wadhera, A
   Agarwal, M
AF Wadhera, Ankita
   Agarwal, Megha
TI Low dimensional multi-block neighborhood combination pattern for
   biomedical image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture feature; Biomedical image retrieval; Local binary pattern;
   Dimensionality reduction
ID TERNARY COOCCURRENCE PATTERNS; LINEAR DISCRIMINANT-ANALYSIS; FEATURE
   DESCRIPTOR; TEXTURE; FACE; EFFICIENT; EIGENFACES; SCALE; MRI
AB Content based image retrieval (CBIR) has been a thrust area of research to retrieve relevant images quickly from a huge image database. In this pursuit, a low dimensional multi-block neighborhood combination pattern (MNCP) is proposed for biomedical image retrieval. Traditional local binary pattern (LBP) failed to capture the macro-structures present in the image. A multi-block technique is applied here to design a feature insensitive to noise. Further, MNCP computes the modified Weber's ratio by encoding three different combinations of change in intensities among pixels to obtain unique patterns. This process considers sign and magnitude both of intensity changes and hence, the direction of intensity changes is also incorporated. In order to make the feature robust, these three combination patterns are concatenated. The most significant features of MNCP are selected to provide maximum inter class separability and variance using principal component analysis (PCA) and linear discriminant analysis (LDA) algorithms. Experiments are conducted on four very distinct and popular medical image datasets namely: OASIS MRI, VIA/I-ELCAP CT, Emphysema CT and MESSIDOR retinal database to examine the ability of the proposed method. Results of the proposed approach proves its superiority by outperforming the existing handcrafted as well as deep learning techniques in terms of average retrieval precision (ARP), average retrieval rate (ARR) and mean average precision (MAP). The proposed CBIR system takes very less time in retrieving the relevant images hence, it is suitable for real time applications as well.
C1 [Wadhera, Ankita; Agarwal, Megha] Jaypee Inst Informat Technol, Dept Elect & Commun Engn, Noida, India.
C3 Jaypee Institute of Information Technology (JIIT)
RP Agarwal, M (corresponding author), Jaypee Inst Informat Technol, Dept Elect & Commun Engn, Noida, India.
EM ankita.wadhera@gmail.com; drmegha.iit@gmail.com
OI Agarwal, Megha/0000-0003-3434-6555
CR Agarwal M, 2020, IJST-T ELECTR ENG, V44, P495, DOI 10.1007/s40998-019-00219-1
   Agarwal M, 2019, PATTERN ANAL APPL, V22, P1585, DOI 10.1007/s10044-019-00787-2
   Agarwal M, 2018, NEUROCOMPUTING, V313, P333, DOI 10.1016/j.neucom.2018.06.027
   Aggarwal A, 2019, BIOMED SIGNAL PROCES, V50, P10, DOI 10.1016/j.bspc.2019.01.009
   Baby CG, 2013, INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, IMAGE PROCESSING AND PATTERN RECOGNITION (ICSIPR 2013), P195, DOI 10.1109/ICSIPR.2013.6497987
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cai YH, 2019, IEEE ACCESS, V7, P51877, DOI 10.1109/ACCESS.2019.2911630
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   DAS P, 2020, IRBM
   Deep G, 2018, COMP M BIO BIO E-IV, V6, P687, DOI 10.1080/21681163.2017.1344933
   Deep G, 2016, ENG SCI TECHNOL, V19, P1895, DOI 10.1016/j.jestch.2016.05.006
   Di Ruberto C, 2017, IET IMAGE PROCESS, V11, P760, DOI 10.1049/iet-ipr.2016.1077
   Dubey SR, 2020, NEURAL COMPUT APPL, V32, P7539, DOI 10.1007/s00521-019-04279-6
   Dubey SR, 2016, ELECTRON LETT, V52, P1290, DOI 10.1049/el.2016.1206
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Galshetwar GM, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102615
   Galshetwar GM, 2018, INT J MULTIMED INF R, V7, P231, DOI 10.1007/s13735-018-0156-0
   Galshetwar GM, 2017, PROCEDIA COMPUT SCI, V115, P440, DOI 10.1016/j.procs.2017.09.103
   Ghosal SK, 2021, MULTIMEDIA SYST, V27, P73, DOI 10.1007/s00530-020-00703-3
   Gonde AB, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P170
   Hassan G, 2020, IEEE ACCESS, V8, P175669, DOI 10.1109/ACCESS.2020.3026452
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang Y., 2006, BMVC, P879
   Hussain CA, 2020, EVOL INTELL, P1
   Kasban H, 2019, MULTIMED TOOLS APPL, V78, P35211, DOI 10.1007/s11042-019-08100-3
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar Y, 2018, BIOMED SIGNAL PROCES, V39, P459, DOI 10.1016/j.bspc.2017.08.018
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mandal M, 2019, IET COMPUT VIS, V13, P31, DOI 10.1049/iet-cvi.2018.5206
   Mohite N, 2019, INT J MULTIMED INF R, V8, P115, DOI 10.1007/s13735-019-00170-1
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Murala S, 2015, NEUROCOMPUTING, V149, P1502, DOI 10.1016/j.neucom.2014.08.042
   Murala S, 2014, SIGNAL PROCESS-IMAGE, V29, P400, DOI 10.1016/j.image.2013.12.002
   Murala S, 2013, NEUROCOMPUTING, V119, P399, DOI 10.1016/j.neucom.2013.03.018
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pinapatruni R, 2020, SIGNAL IMAGE VIDEO P, V14, P1319, DOI 10.1007/s11760-020-01670-y
   Shinde A, 2019, BIOMED ENG LETT, V9, P387, DOI 10.1007/s13534-019-00112-0
   Shivashankar S, 2011, LECT NOTES ARTIF INT, V7080, P193, DOI 10.1007/978-3-642-25725-4_17
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singhal A, 2020, MULTIMED TOOLS APPL
   Song W, 2018, EXPERT SYST APPL, V96, P347, DOI 10.1016/j.eswa.2017.12.006
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Srivastava P, 2018, MULTIMED TOOLS APPL, V77, P12377, DOI 10.1007/s11042-017-4894-4
   Sucharitha G, 2020, MULTIMED TOOLS APPL, V79, P1847, DOI 10.1007/s11042-019-08215-7
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Verma M, 2015, J VIS COMMUN IMAGE R, V32, P224, DOI 10.1016/j.jvcir.2015.08.015
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CZ, 2021, MULTIMED TOOLS APPL, V80, P9687, DOI 10.1007/s11042-020-10137-8
   Wang XY, 2009, FRACTALS, V17, P441, DOI 10.1142/S0218348X09004557
   Wang XY, 2014, PATTERN RECOGN, V47, P3293, DOI 10.1016/j.patcog.2014.04.020
   Wang XY, 2013, J VIS COMMUN IMAGE R, V24, P63, DOI 10.1016/j.jvcir.2012.10.003
   Xu Y, 2017, IEEE ACCESS, V5, P8502, DOI 10.1109/ACCESS.2017.2695239
   Yan LY, 2019, MULTIMED TOOLS APPL, V78, P15101, DOI 10.1007/s11042-018-6855-y
   Yang J, 2004, PATTERN RECOGN, V37, P2097, DOI 10.1016/j.patcog.2003.10.015
   Yang WK, 2020, NEUROCOMPUTING, V373, P109, DOI 10.1016/j.neucom.2019.09.102
NR 62
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27853
EP 27877
DI 10.1007/s11042-022-12089-7
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000774644100013
DA 2024-07-18
ER

PT J
AU Sharma, S
   Gupta, V
AF Sharma, Saurabh
   Gupta, Vishal
TI Role of twitter user profile features in retweet prediction for big data
   streams
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Twitter; Social media analysis; Retweet prediction; User behavior; User
   profiling; Big data analysis
ID MODEL; INFORMATION; ACCOUNTS; WEB
AB To study the various factors influencing the process of information sharing on Twitter is a very active research area. This paper aims to explore the impact of numerical features extracted from user profiles in retweet prediction from the real-time raw feed of tweets. The originality of this work comes from the fact that the proposed model is based on simple numerical features with the least computational complexity, which is a scalable solution for big data analysis. This research work proposes three new features from the tweet author profile to capture the unique behavioral pattern of the user, namely "Author total activity", "Author total activity per year", and "Author tweets per year". The features set is tested on a dataset of 100 million random tweets collected through Twitter API. The binary labels regression gave an accuracy of 0.98 for user-profile features and gave an accuracy of 0.99 when combined with tweet content features. The regression analysis to predict the retweet count gave an R-squared value of 0.98 with combined features. The multi-label classification gave an accuracy of 0.9 for combined features and 0.89 for user-profile features. The user profile features performed better than tweet content features and performed even better when combined. This model is suitable for near real-time analysis of live streaming data coming through Twitter API and provides a baseline pattern of user behavior based on numerical features available from user profiles only.
C1 [Sharma, Saurabh; Gupta, Vishal] Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
C3 Panjab University
RP Gupta, V (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh, India.
EM saurabhsharma381@gmail.com; vishal@pu.ac.in
RI Sharma, Saurabh/JFK-3974-2023
OI sharma, saurabh/0000-0002-3213-8819
CR Adewole KS, 2019, MULTIMED TOOLS APPL, V78, P3925, DOI 10.1007/s11042-017-5018-x
   Aggarwal A, 2012, ECRIM RES SUM
   Alsaleh M, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P463, DOI 10.1109/ICMLA.2014.81
   Antonakaki D, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114006
   Arpaci I, 2020, CMC-COMPUT MATER CON, V65, P193, DOI 10.32604/cmc.2020.011489
   Bhowmick AK, 2019, IEEE T COMPUT SOC SY, V6, P441, DOI 10.1109/TCSS.2019.2907553
   Chen GD, 2019, NEUROCOMPUTING, V333, P221, DOI 10.1016/j.neucom.2018.12.039
   Chen L, 2020, IEEE ACCESS, V8
   Chen S, 2020, IEEE T VIS COMPUT GR, V26, P1204, DOI 10.1109/TVCG.2019.2934263
   Chen SJ, 2020, TELEMAT INFORM, V47, DOI 10.1016/j.tele.2019.101326
   Chu Z, 2012, IEEE T DEPEND SECURE, V9, P811, DOI 10.1109/TDSC.2012.75
   Chung WY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS (ISI), P68, DOI [10.1109/isi.2019.8823399, 10.1109/ISI.2019.8823399]
   Daga I, 2020, PROCEDIA COMPUT SCI, V168, P123, DOI 10.1016/j.procs.2020.02.273
   Dinh Ly, 2020, Proc Assoc Inf Sci Technol, V57, pe252, DOI 10.1002/pra2.252
   Duan MX, 2018, IEEE T NEUR NET LEAR, V29, P2337, DOI 10.1109/TNNLS.2017.2654357
   Dutta HS, 2020, IEEE T INF FOREN SEC, V15, P2667, DOI 10.1109/TIFS.2020.2970601
   Fan C, 2020, INT J DISAST RISK RE, V46, DOI 10.1016/j.ijdrr.2020.101498
   Firdaus Syeda Nadia, 2018, Online Social Networks and Media, V6, P26, DOI 10.1016/j.osnem.2018.04.001
   Firdaus SN, 2019, INT J MACH LEARN CYB, V10, P2071, DOI 10.1007/s13042-018-0798-5
   Gao X, 2019, IEEE T KNOWL DATA EN, V1
   Hemphill L, 2021, J ASSOC INF SCI TECH, V72, P97, DOI 10.1002/asi.24368
   Hemsley J, 2019, POLICY INTERNET, V11, P280, DOI 10.1002/poi3.202
   Jain Deepak Kumar, 2020, Future Generation Computer Systems, V112, P996, DOI 10.1016/j.future.2020.04.001
   Jalali NY, 2019, INT J RES MARK, V36, P647, DOI 10.1016/j.ijresmar.2019.05.001
   Jung AK, 2020, BIG DATA SOC, V7, DOI 10.1177/2053951720980127
   Lee J, 2018, PUBLIC RELAT REV, V44, P201, DOI 10.1016/j.pubrev.2017.10.002
   Lee S, 2014, COMPUT COMMUN, V54, P48, DOI 10.1016/j.comcom.2014.08.006
   Lymperopoulos IN, 2021, EXPERT SYST APPL, V163, DOI 10.1016/j.eswa.2020.113785
   Miller Z, 2014, INFORM SCIENCES, V260, P64, DOI 10.1016/j.ins.2013.11.016
   Murshed BAH, 2020, COMPUT SYST SCI ENG, V35, P495
   Nesi P, 2018, MULTIMED TOOLS APPL, V77, P26371, DOI 10.1007/s11042-018-5865-0
   Rousidis D, 2020, MULTIMED TOOLS APPL, V79, P6279, DOI 10.1007/s11042-019-08291-9
   Safari RM, 2019, MULTIMED TOOLS APPL, V78, P33747, DOI 10.1007/s11042-019-08046-6
   Savyan PV, 2020, MULTIMED TOOLS APPL, V79, P19349, DOI 10.1007/s11042-020-08721-z
   Scott Jason, 2012, ARCHIVETEAM TWITTER
   Sequiera R, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1225, DOI 10.1145/3077136.3080667
   Shyni C E., 2016, Asian Journal of Information Technology, V15, P1253
   Singh SK, 2021, COMPUT SCI INF SYST, V18, P597, DOI 10.2298/CSIS200330012S
   Son J, 2020, INT J INFORM MANAGE, V54, DOI 10.1016/j.ijinfomgt.2020.102176
   Son J, 2019, INT J INFORM MANAGE, V45, P56, DOI 10.1016/j.ijinfomgt.2018.10.012
   Tardelli Serena, 2020, Social Computing and Social Media. Design, Ethics, User Behavior, and Social Network Analysis. 12th International Conference, SCSM 2020 Held as Part of the 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12194), P376, DOI 10.1007/978-3-030-49570-1_26
   Tian Y, 2020, IEEE ACCESS, V8, P87121, DOI 10.1109/ACCESS.2020.2989180
   Wang SQ, 2020, INFORM SCIENCES, V515, P218, DOI 10.1016/j.ins.2019.12.017
   Yang C, 2013, IEEE T INF FOREN SEC, V8, P1280, DOI 10.1109/TIFS.2013.2267732
   Zheng XH, 2015, NEUROCOMPUTING, V159, P27, DOI 10.1016/j.neucom.2015.02.047
   Zhou F, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3433000
   Zola P, 2019, DECIS SUPPORT SYST, V120, P50, DOI 10.1016/j.dss.2019.03.006
   Zubiaga A, 2018, J ASSOC INF SCI TECH, V69, P974, DOI 10.1002/asi.24026
   Zubiaga A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3161603
NR 49
TC 7
Z9 7
U1 5
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 27309
EP 27338
DI 10.1007/s11042-022-12815-1
EA MAR 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000780464900006
PM 35368857
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, MY
   Zhou, ZH
   Deng, M
AF Zhang, Mingyue
   Zhou, Zhiheng
   Deng, Ming
TI Cascaded hierarchical CNN for 2D hand pose estimation from a single
   color image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Body pose estimation; Hand pose estimation; Hand mask segmentation;
   Hierarchical estimation
AB Due to severe articulation, self-occlusion, various scales, and high dexterity of the hand, hand pose estimation is more challenging than body pose estimation. Recently-developed body pose estimation algorithms are not suitable for addressing the unique challenges of hand pose estimation because they are trained without explicitly modeling structural relationships between keypoints. In this paper, we propose a novel cascaded hierarchical CNN(CH-HandNet) for 2D hand pose estimation from a single color image. The CH-HandNet includes three modules, hand mask segmentation, preliminary 2D hand pose estimation, and hierarchical estimation. The first module obtains a hand mask by hand mask segmentation network. The second module connects the hand mask and the intermediate image features to estimate the 2D hand heatmaps. The last module connects hand heatmaps with the intermediate image features and hand mask to estimate finger and palm heatmaps hierarchically. Finally, the extracted Finger(pinky,ring,middle,index) and Palm(thumb and palm) feature information are fused to estimate 2D hand pose. Experimental results on three datasets - OneHand 10k, Panoptic, and Eric.Lee, consistently shows that our proposed CH-HandNet outperforms previous state-of-the-art hand pose estimation methods.
C1 [Zhang, Mingyue; Zhou, Zhiheng; Deng, Ming] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
C3 South China University of Technology
RP Zhou, ZH (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Peoples R China.
EM zhouzh@scut.edu.cn
RI Zhou, zhiheng/HNC-4591-2023
FU National Key R&D Program of China [2018YFC0309400]; National Natural
   Science Foundation of China [61871188]; Guangzhou city science and
   technology research projects [201902020008]
FX The work is supported by National Key R&D Program of China
   (2018YFC0309400), National Natural Science Foundation of China
   (61871188), Guangzhou city science and technology research
   projects(201902020008).
CR Cai YJ, 2018, LECT NOTES COMPUT SC, V11210, P678, DOI 10.1007/978-3-030-01231-1_41
   Chen XH, 2020, NEUROCOMPUTING, V395, P138, DOI 10.1016/j.neucom.2018.06.097
   Chen YF, 2020, IEEE WINT CONF APPL, P370, DOI [10.1109/WACV45572.2020.9093271, 10.1109/wacv45572.2020.9093271]
   Chen Z, 2020, SIGNAL PROCESS-IMAGE, V87, DOI 10.1016/j.image.2020.115909
   Clark E, 2006, MULTICAMERA SYSTEM G
   Dai SM, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/8432840
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elboushaki A, 2020, MULTIMED TOOLS APPL, V79, P28925, DOI 10.1007/s11042-020-09370-y
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Fan LL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21020649
   Gomez-Donoso F, 2019, IMAGE VISION COMPUT, V81, P25, DOI 10.1016/j.imavis.2018.12.001
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang X, 2020, IEEE T SUSTAIN ENERG, V11, P477, DOI [10.1109/TSTE.2019.2895601, 10.1109/ieee-iws.2019.8804089]
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Kingma D. P., 2014, arXiv
   Kourbane I, 2021, ARXIV210510904
   Kulon D, 2020, PROC CVPR IEEE, P4989, DOI 10.1109/CVPR42600.2020.00504
   Kuo Du, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9888, DOI 10.1109/CVPR.2019.01013
   Madadi M., 2017, ARXIV170509606
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Panteleris P, 2018, IEEE WINT CONF APPL, P436, DOI 10.1109/WACV.2018.00054
   Rosa-Pujazón A, 2016, MULTIMED TOOLS APPL, V75, P8137, DOI 10.1007/s11042-015-2729-8
   Ruder S, 2017, arXiv preprint arXiv:1706.05098
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun X, 2015, PROC CVPR IEEE, P824, DOI 10.1109/CVPR.2015.7298683
   Tang DH, 2014, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2014.490
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Wan CD, 2016, LECT NOTES COMPUT SC, V9907, P554, DOI 10.1007/978-3-319-46487-9_34
   Wan JX, 2021, J INDIAN SOC REMOTE, V49, P2019, DOI 10.1007/s12524-020-01255-9
   Wang YG, 2020, IEEE T IMAGE PROCESS, V29, P2977, DOI 10.1109/TIP.2019.2955280
   Wang YG, 2019, IEEE T CIRC SYST VID, V29, P3258, DOI 10.1109/TCSVT.2018.2879980
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Yang Y, 2013, IEEE T PATTERN ANAL, V35, P2878, DOI 10.1109/TPAMI.2012.261
   Zhou YM, 2016, PATTERN RECOGN, V49, P102, DOI 10.1016/j.patcog.2015.07.014
   Zimmermann C, 2019, IEEE I CONF COMP VIS, P813, DOI 10.1109/ICCV.2019.00090
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 38
TC 4
Z9 5
U1 8
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25745
EP 25763
DI 10.1007/s11042-022-12780-9
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288100001
DA 2024-07-18
ER

PT J
AU Mi, JX
   Fu, CQ
   Chen, T
   Gou, TT
AF Mi, Jian-Xun
   Fu, Chang-Qing
   Chen, Tao
   Gou, Tingting
TI Deep cross-view autoencoder network for multi-view learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view learning; Cross-view reconstruction; Common representation;
   Cross-view classification; Encoding consistency
ID DISCRIMINANT-ANALYSIS
AB In many real-world applications, an increasing number of objects can be collected at varying viewpoints or by different sensors, which brings in the urgent demand for recognizing objects from distinct heterogeneous views. Although significant progress has been achieved recently, heterogeneous recognition (cross-view recognition) in multi-view learning is still challenging due to the complex correlations among views. Multi-view subspace learning is an effective solution, which attempts to obtain a common representation from downstream computations. Most previous methods are based on the idea of maximal correlation after feature extraction to establish the relationship among different views in a two-step manner, thus leading to performance deterioration. To overcome this drawback, in this paper, we propose a deep cross-view autoencoder network (DCVAE) that extracts the features of different views and establishes the correlation between views in one step to simultaneously handle view-specific, view-correlation, and consistency in a joint manner. Specifically, DCVAE contains self-reconstruction, newly designed cross-view reconstruction, and consistency constraint modules. Self-reconstruction ensures the view-specific, cross-view reconstruction transfers the information from one view to another view, and consistency constraint makes the representation of different views more consistent. The proposed model suffices to discover the complex correlation embedded in multi-view data and to integrate heterogeneous views into a latent common representation subspace. Furthermore, the 2D embeddings of the learned common representation subspace demonstrate the consistency constraint is valid and cross-view classification experiments verify the superior performance of DCVAE in the two-view scenario.
C1 [Mi, Jian-Xun; Fu, Chang-Qing] Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing, Peoples R China.
   [Mi, Jian-Xun; Chen, Tao] State Grid Chongqing Elect Power Res Inst, Chongqing, Peoples R China.
   [Gou, Tingting] Chongqing Chem Ind Vocat Coll, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing Electric
   Power Corp
RP Mi, JX (corresponding author), Chongqing Univ Posts & Telecommun, Sch Comp Sci & Technol, Chongqing, Peoples R China.; Mi, JX (corresponding author), State Grid Chongqing Elect Power Res Inst, Chongqing, Peoples R China.
EM mijianxun@gmail.com; s180201082@stu.cqupt.edu.cn; ydwh@163.com;
   12415992@qq.com
RI Mi, Jianxun/J-9670-2014; Mi, Jianxun/U-3642-2019
OI Mi, Jianxun/0000-0002-7531-4341; 
FU Scientific and Technological Research Program of Chongqing Municipal
   Education Commission [KJQN202100638]; Natural Science Foundation of
   Chongqing [cstc2018jcyjAX0532]
FX This work was sponsored by Scientific and Technological Research Program
   of Chongqing Municipal Education Commission (Grant No. KJQN202100638)
   and Natural Science Foundation of Chongqing (Grant No.
   cstc2018jcyjAX0532).
CR Akaho Shotaro, 2006, ARXIV
   Andrew G., 2013, ICML, P1247
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247923
   Bajorski, 2011, ENCY STAT BEHAV SCI, P241, DOI [10.1002/9781118121955.ch8, DOI 10.1002/9781118121955.CH8]
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Cao GQ, 2018, IEEE T CYBERNETICS, V48, P2542, DOI 10.1109/TCYB.2017.2742705
   Deng SY, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107633
   Ding ZM, 2018, IEEE T NEUR NET LEAR, V29, P1986, DOI 10.1109/TNNLS.2017.2690970
   Guo YY, 2021, MULTIMED TOOLS APPL, V80, P23009, DOI 10.1007/s11042-020-08713-z
   Hu P, 2019, IEEE T IMAGE PROCESS, V28, P5352, DOI 10.1109/TIP.2019.2913511
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   King DB, 2015, ACS SYM SER, V1214, P1
   Kuehlkamp A, 2019, IEEE T INF FOREN SEC, V14, P1419, DOI 10.1109/TIFS.2018.2878542
   Li SZ, 2009, PROC CVPR IEEE, P267, DOI 10.1109/FSKD.2009.137
   Li YM, 2019, IEEE T KNOWL DATA EN, V31, P1863, DOI 10.1109/TKDE.2018.2872063
   Liu HY, 2017, AAAI CONF ARTIF INTE, P2231
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Nie FP, 2018, IEEE T IMAGE PROCESS, V27, P1501, DOI 10.1109/TIP.2017.2754939
   Rupnik J, 2016, C DAT MIN DAT WAR SI
   Shang RH, 2019, PATTERN RECOGN, V92, P219, DOI 10.1016/j.patcog.2019.03.026
   Van der Maaten L., 2009, Tilburg Univ, P2
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang QQ, 2018, IEEE DATA MINING, P1290, DOI 10.1109/ICDM.2018.00174
   Wang WR, 2015, PR MACH LEARN RES, V37, P1083
   Wen J, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3230
   Yang SS, 2022, IEEE T NEUR NET LEAR, V33, P4861, DOI 10.1109/TNNLS.2021.3061630
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P4398, DOI [10.1109/TNNLS.2021.3057070, 10.4018/IJCINI.20211001.oa2]
   Yang SM, 2019, IEEE T CYBERNETICS, V49, P2490, DOI 10.1109/TCYB.2018.2823730
   Yoshida K, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1543-x
   You XG, 2019, PATTERN RECOGN, V92, P37, DOI 10.1016/j.patcog.2019.03.008
   Zhang C, 2019, PROC CVPR IEEE, P9444, DOI 10.1109/CVPR.2019.00968
   Zhang Y, 2018, LECT NOTES COMPUT SC, V11205, P707, DOI 10.1007/978-3-030-01246-5_42
   Zhang Z, 2018, 2017 IEEE VISUAL COM, P1, DOI [10.1109/VCIP.2017.8305137, DOI 10.1109/VCIP.2017.8305137]
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
   Zhao YR, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND COMMUNICATION ENGINEERING (ICTCE 2018), P154, DOI [10.1145/3291842.3291895, 10.1016/j.patcog.2018.01.012]
NR 36
TC 0
Z9 0
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24645
EP 24664
DI 10.1007/s11042-022-12636-2
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000771380200007
DA 2024-07-18
ER

PT J
AU Yang, WJ
   Su, JN
   Qiu, K
   Zhang, ZP
AF Yang, Wenjin
   Su, Jianning
   Qiu, Kai
   Zhang, Zhipeng
TI Supporting computer-aided product form design research with a cognitive
   model of the creative process
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Design cognition; Creative generation; Computer-aided design; Parametric
   generation model; Inspiration stimulus
ID STIMULATION; STRESS
AB Companies need to innovate quickly to adapt to the current rapidly changing market environment. Therefore, methods to support the computer-aided creative design process have become a hot research topic, and a variety of methods to support research on creative systems have been derived on the basis of the designer's cognition. This study establishes a general parametric design cognitive model to support the computer-aided creative process of directed design. First, this model divides a large amount of stimulus knowledge into corresponding levels through considers multiple dimensions of inspiration and stimulus factors. Second, this model develops and validates a form-generating design technology to replace a designer's hand-drawn sketches. This technology can quickly obtain many effective product 3D models to further increase the speed of creative realization. Finally, this study verifies the model through a case study. Through the analysis of the case output results, we found that the model can quickly generate a three-dimensional sketch plan that meets the desired goals. In turn, the generated results can stimulate the designer to generate broader inspiration. Therefore, the computer-supported creative generation model established by this research has a certain degree of scientificity and feasibility. Its novelty lies in the method can liberate the designer's labor to a certain extent and replace the designer in completing the directed creative generation process and the plan sketch process. And the verification process reflects certain cognitive mechanisms of the human brain, Therefore, this method can be applied to some specific design propositions.
C1 [Yang, Wenjin; Su, Jianning] Lanzhou Univ Technol, Sch Design Art, Lanzhou 730050, Peoples R China.
   [Su, Jianning; Qiu, Kai; Zhang, Zhipeng] Lanzhou Univ Technol, Sch Mech & Elect Engn, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University of Technology
RP Su, JN (corresponding author), Lanzhou Univ Technol, Sch Design Art, Lanzhou 730050, Peoples R China.; Su, JN (corresponding author), Lanzhou Univ Technol, Sch Mech & Elect Engn, Lanzhou 730050, Peoples R China.
EM 171080203016@lut.cn; sujn@lut.cn; 191080203003@lut.cn;
   Japadesign@163.com
FU National Natural Science Foundation of China [51705226]
FX The project is sponsored by the National Natural Science Foundation of
   China (52165033) and the National Natural Science Foundation of China
   (51705226).
CR Akin, 2013, CREATIVITY PUZZLES I
   Alcaide-Marzal J, 2020, DESIGN STUD, V66, P144, DOI 10.1016/j.destud.2019.11.003
   Althuizen N, 2016, J MANAGE INFORM SYST, V33, P11, DOI 10.1080/07421222.2016.1172439
   Althuizen N, 2014, J MANAGE INFORM SYST, V31, P309, DOI 10.2753/MIS0742-1222310112
   Appio FP, 2017, TECHNOL ANAL STRATEG, V29, P775, DOI 10.1080/09537325.2016.1236190
   Baldussu Alessandro, 2015, Procedia Engineering, V131, P3, DOI 10.1016/j.proeng.2015.12.342
   Becattini N, 2012, COMPUT AIDED DESIGN, V44, P961, DOI 10.1016/j.cad.2011.02.013
   Benami Oren., 2002, PROC ASME DETC, P1
   Bernal M, 2015, DESIGN STUD, V41, P163, DOI 10.1016/j.destud.2015.08.001
   Bin Aqeel A, 2015, PROC TECH, V20, P170, DOI 10.1016/j.protcy.2015.07.028
   Chen XY, 2019, B ENG GEOL ENVIRON, V78, P4451, DOI 10.1007/s10064-018-1413-4
   Daniel M., 2021, ISM DSM TOOLS DESIGN, V5, P31
   Delhaye E, 2019, EXP AGING RES, V45, P469, DOI 10.1080/0361073X.2019.1664442
   Goldschmidt G., 1994, DESIGN STUDIES, V15, P158, DOI [https://doi.org/10.1016/0142-694X(94)90022-1, DOI 10.1016/0142-694X(94)90022-1]
   Goldschmidt G, 2011, J CREATIVE BEHAV, V45, P92, DOI 10.1002/j.2162-6057.2011.tb01088.x
   Goucher-Lambert K, 2019, DESIGN STUD, V61, P1, DOI 10.1016/j.destud.2019.01.001
   Guo J, 2014, CREATIVITY RES J, V26, P361, DOI 10.1080/10400419.2014.929433
   Han J, 2019, P I MECH ENG C-J MEC, V233, P373, DOI 10.1177/0954406217750189
   Hatchuel A., 2003, INT C ENG DES STOCKH, P15
   Hender JM., 2002, P 34 ANN HAW INT C S
   Howard TJ, 2008, DESIGN STUD, V29, P160, DOI 10.1016/j.destud.2008.01.001
   Hu Z, 2019, CLUSTER COMPUT, V22, pS10145, DOI 10.1007/s10586-017-1190-z
   Jin Y, 2010, AI EDAM, V24, P191, DOI 10.1017/S0890060410000053
   Julian F., 2016, INT TECHN ED DEV C
   Kennedy B, 2015, INTEGR STEM EDU CONF, P88, DOI 10.1109/ISECon.2015.7119952
   Keshwani S, 2017, J ENG DESIGN, V28, P654, DOI 10.1080/09544828.2017.1393504
   Kielarova Somlak Wannarumon, 2015, Advances in Swarm and Computational Intelligence - 6th International Conference, ICSI 2015, held in conjunction with the Second BRICS Congress, CCI 2015. Proceedings: LNCS 9140, P302, DOI 10.1007/978-3-319-20466-6_33
   Li Z, 2012, COMPUT AIDED DESIGN, V44, P987, DOI 10.1016/j.cad.2011.12.006
   Martins JM., 2018, NEED DEV CORPORATE C
   Mckay MCAH., 2006, COMBINING EVOLUTIONA
   Nagai Y., 2002, P 4 C CREAT COGN OCT, P118
   Narraway CL, 2020, ENVIRON PLAN B-URBAN, V47, P268, DOI 10.1177/2399808319882730
   Peleg, 2007, LECT NOTES COMPUT SC, V4840, P150
   Salgueiredo CF, 2016, AI EDAM, V30, P159, DOI 10.1017/S0890060416000044
   Santanen EL, 2004, J MANAGE INFORM SYST, V20, P167, DOI 10.1080/07421222.2004.11045783
   Sartori J, 2010, AI EDAM, V24, P483, DOI 10.1017/S0890060410000351
   Schmitt R, 2014, J SENS SENS SYST, V3, P315, DOI 10.5194/jsss-3-315-2014
   Shen ZF, 2020, INT J IND ERGONOM, V79, DOI 10.1016/j.ergon.2020.102990
   Stones C, 2010, DESIGN STUD, V31, P439, DOI 10.1016/j.destud.2010.05.003
   Nguyen TA, 2017, J INTELL MANUF, V28, P1609, DOI 10.1007/s10845-016-1196-z
   Nguyen TA, 2012, J INTEGR DES PROCESS, V16, P65, DOI 10.3233/jid-2012-0007
   Troiano L, 2014, INFORM SCIENCES, V259, P433, DOI 10.1016/j.ins.2012.01.006
   Turrin M, 2011, ADV ENG INFORM, V25, P656, DOI 10.1016/j.aei.2011.07.009
   Visser W, 2006, HUM-COMPUT INTERACT, V21, P103, DOI 10.1207/s15327051hci2101_4
   Wang K, 2019, J MANAGE INFORM SYST, V36, P1284, DOI 10.1080/07421222.2019.1661095
   Wissam, 2021, MODERN MECH ENG, V11, P27
   Yang, 2015, P I MECH ENG C-MECH, P230
NR 47
TC 1
Z9 1
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21619
EP 21639
DI 10.1007/s11042-022-12119-4
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000769836800010
DA 2024-07-18
ER

PT J
AU Kapoor, R
   Goel, R
   Sharma, A
AF Kapoor, Rajiv
   Goel, Rohini
   Sharma, Avinash
TI An intelligent railway surveillance framework based on recognition of
   object and railway track using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thermal imaging; Singular spectrum analysis; Singular value
   decomposition (SVD); Region proposals; Faster R-CNN
ID EMPIRICAL MODE DECOMPOSITION; SINGULAR SPECTRUM ANALYSIS
AB In high speed railways, the intelligent railway safety system is necessary to avoid the accidents due to collision between trains and obstacles on the railway track. The unceasing research work is being performed to reinforce the railway safety and to diminish the accident rates. The rapid development in the field of deep learning has prompted new research opportunities in this area. In this paper, a novel and efficient approach is proposed to recognize the objects (obstacles) on the railway track ahead the train using deep classifier network. The 2-D Singular Spectrum Analysis (SSA) is utilized as decomposition tool that decomposes the image in useful components. That component is further applied to the deep classifier network. The obstacle recognition performance is enhanced by the combination of 2D-SSA and deep network. This method also presents a novel measure to identify the railway tracks. In addition, the performance of this approach is analyzed under different illumination conditions using OSU thermal pedestrian benchmark database. This system can be a tremendous support to curtail rail accidental rate and monetary loads. The results of proposed approach present good accuracy as well as can effectively recognize the objects (obstacles) on the railway track which helps to the railway safety. It also achieves a better performance with 85.2% accuracy, 84.5% precision and 88.6% recall.
C1 [Kapoor, Rajiv] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi 110042, India.
   [Goel, Rohini; Sharma, Avinash] Maharishi Markandeshwar Deemed Univ, Comp Sci & Engn Dept, Ambala, Haryana, India.
C3 Delhi Technological University
RP Kapoor, R (corresponding author), Delhi Technol Univ, Dept Elect & Commun Engn, Delhi 110042, India.
EM rajivkapoor.dtu@gmail.com
RI Kapoor, Rajiv/AAA-2011-2022; Sharma, Dr. Avinash/IAN-3189-2023; Goel,
   Rohini/AHE-4057-2022
OI Kapoor, Rajiv/0000-0003-3020-1455; Goel, Rohini/0000-0002-9297-4691
FU Delhi Technological University
FX Authors are grateful to Delhi Technological University and specially Sh
   Anand Vardhan, CEO of MM Logic soft P Ltd for sponsoring the project.
CR Aakash DB, 2019, IOP C SERIES MAT SCI, V691, P3
   Amaral V, 2016, J SENSORS, V2016, DOI 10.1155/2016/1719230
   Barney D., 2001, Proceedings of the 6th Australian workshop on Safety critical systems and software, Brisbane, V3, P23, DOI DOI 10.5555/563780.563784
   Berg Amanda, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P492, DOI 10.1007/978-3-319-19665-7_42
   Chaudhary PK, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104454
   Chaudhary PK, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102237
   Chen Y, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109809
   Daubechies I, 2011, APPL COMPUT HARMON A, V30, P243, DOI 10.1016/j.acha.2010.08.002
   Davis JW, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P364
   Demir B, 2008, 6 EUR SIGN PROC C EU
   Demir B, 2010, IEEE T GEOSCI REMOTE, V48, P4071, DOI 10.1109/TGRS.2010.2070510
   García-Guerrero M, 2020, INT J SCI EDUC PART, V10, P133, DOI 10.1080/21548455.2020.1719293
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Golyandina N., 2001, Analysis of time Series Structure: SSA and related techniques
   Golyandina N, 2009, P 6 ST PET WORKSH SI, P308
   Golyandina N. E., 2010, Matrix methods: Theory, algorithms and applications: Dedicated to the memory of gene golub, P449, DOI DOI 10.1142/9789812836021_0029
   Golyandina N, 2010, STAT INTERFACE, V3, P259
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Kapoor R., 2020, J. Comput. Theor. Nanosci, V17, P5062, DOI [10.1166/jctn.2020.9342, DOI 10.1166/JCTN.2020.9342]
   Karaduman M, 2017, 2017 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P899
   Kristo M, 2020, IEEE ACCESS, V8, P125459, DOI 10.1109/ACCESS.2020.3007481
   Krummenacher G, 2018, IEEE T INTELL TRANSP, V19, P1176, DOI 10.1109/TITS.2017.2720721
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Madhavan S, 2020, IEEE SENS J, V20, P3078, DOI 10.1109/JSEN.2019.2956072
   Malta A, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11114758
   Mangale Supriya, 2017, ICTACT Journal on Image and Video Processing, V8, P1566, DOI 10.21917/ijivp.2017.0221
   Manikandan R, 2017, Int. J. Pure Appl. Math., V116, P567
   Manolakis D.G., 2005, Statistical and adaptive signal processing : spectral estimation, signal modeling, adaptive filtering, and array processing
   Mittal S, 2017, COMPUT SCI
   Murthy CB, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093280
   Nayak SR, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102365
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodríguez-Aragón LJ, 2010, STAT INTERFACE, V3, P419
   Sabnis Omkar Vivek, 2019, 2019 Fifth International Conference on Science Technology Engineering and Mathematics (ICONSTEM), P149, DOI 10.1109/ICONSTEM.2019.8918786
   Shangsheng Z, 1827, J PHYS C SERIES
   Sharma R, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2020.101867
   Sinha D, 2016, IEEE SENS J, V16, P642, DOI 10.1109/JSEN.2015.2490247
   Stewart G., 1973, INTRO MATRIX COMPUTA
   Sudha D, 2020, SOFT COMPUT, V24, P17417, DOI 10.1007/s00500-020-05042-z
   Vázquez J, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P872
   Wang Q, 2019, IEEE T IMAGE PROCESS, V28, P4376, DOI 10.1109/TIP.2019.2910667
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Wu YY, 2017, IEEE T CIRC SYST VID, V27, P236, DOI 10.1109/TCSVT.2015.2493499
   Zabalza J, 2015, IEEE T GEOSCI REMOTE, V53, P4418, DOI 10.1109/TGRS.2015.2398468
   Zhang M, 2018, 5 C FRONT OPT IM TEC, P10832
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 49
TC 6
Z9 6
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21083
EP 21109
DI 10.1007/s11042-022-12059-z
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500011
PM 35310890
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Moon, SK
AF Moon, Sunil K.
TI Software and hardware-based audio-video crypto steganalysis model for
   enhancing robustness and imperceptibility of secured data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio-video steganalysis; Information security; Authentication;
   Forensics detection; APBMDET; Attacks; FPGA; LabVIEW
ID PERFORMANCE ANALYSIS; IMAGE STEGANOGRAPHY; WATERMARKING; DESIGN
AB Nowadays for the privacy and security of secret data, information like audio, signature, thumb, voice, and fingerprints are the most emerging parameters and hence its authentication has received more attention due to its need for different applications. This paper develops innovative and efficient forensic software and hardware-based audio-video crypto -steganalysis model to enhance robustness and imperceptibility. All the existing diamond encoding (DE) approaches are always used to conceal one secret bit to create a diamond shape with objectionable manipulation error and hence, it is not a perfect solution for the security of hidden secret data, embedding capacity (EC), imperceptibility, and robustness. To overcome these limits, the proposed approach integrates all kinds of secret data such as Text, Image, Mp3, .Wav, Voice with many bits vertically and horizontally using the Adaptive Pixel Block Mapping Diamond Encoding Technique (APBMDET). It is used to generate a New Diamond Characteristic Value (NDCV) function which is equal to log(2)(4s(2) + 4s + 5) - ary notations. Moreover, to enhance the security of hidden data, robustness, and imperceptibility, the forensic authentication technique and various types of attacks are applied to stego video. It is observed that original and stego audio-video does not deviate from each other. The obtained theoretical analysis and experimental results through LabVIEW and Field Programmable Gate Array (FPGA) show the effectiveness of the proposed novel technique which is used to maintain a very good recovery of both original and secret data without any distortion with larger data conceal capacity as compared to any existing techniques.
C1 [Moon, Sunil K.] SCTRs Pune Inst Comp Technol, Dept Elect & Telecommun, PICT, Pune, Maharashtra, India.
RP Moon, SK (corresponding author), SCTRs Pune Inst Comp Technol, Dept Elect & Telecommun, PICT, Pune, Maharashtra, India.
EM skmoon@pict.edu
RI Moon, Sunil/HHN-2680-2022
OI moon, sunil/0000-0002-8828-6300
CR Abed S, 2019, J CIRCUIT SYST COMP, V28, DOI 10.1142/S021812661950083X
   Anderson JH, 2010, ASIA S PACIF DES AUT, P1, DOI 10.1109/ASPDAC.2010.5419927
   [Anonymous], 2003, INT J DIG EVID
   [Anonymous], 2015, UBIQUITOUS INT J INF
   [Anonymous], 2017, INT J COMPUTER SCI I
   Aos AZ, 2009, IACSIT-SC 2009: INTERNATIONAL ASSOCIATION OF COMPUTER SCIENCE AND INFORMATION TECHNOLOGY - SPRING CONFERENCE, P437, DOI 10.1109/IACSIT-SC.2009.103
   Arab F, 2016, MULTIMED TOOLS APPL, V75, P10855, DOI 10.1007/s11042-015-2800-5
   ATAWNEH S, 2016, SPRINGER J MULTIMEDI
   Bossuet L, 2013, ACM COMPUT SURV, V45, DOI 10.1145/2501654.2501655
   Chao RM, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/658047
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Dalal M, 2019, MULTIMED TOOLS APPL, V78, P5769, DOI 10.1007/s11042-018-6093-3
   El Hadedy ME, 2006, THESIS MANSOURA U
   ElAraby WS, 2010, INT C MICROELECTRON, P463, DOI 10.1109/ICM.2010.5696189
   Elshazly EA, 2018, NAT RADIO SCI CO, P258, DOI 10.1109/NRSC.2018.8354371
   Elshazly E. A., 2016, INT J COMPUTER APPL, V145, P43, DOI DOI 10.5120/IJCA2016910796
   Farouk HA, 2004, ASIA S PACIF DES AUT, P577, DOI 10.1109/ASPDAC.2004.1337657
   Filler T, 2011, IS T SPIE ELECT IMAG, V7880
   Haque MM, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P583, DOI 10.1109/ECACE.2017.7912972
   Ho LH, 2012, OPTO-ELECTRON REV, V20, P367, DOI 10.2478/s11772-012-0046-6
   Holub V., 2013, P 1 ACM WORKSH INF H, P59, DOI DOI 10.1145/2482513.2482514
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   HUANG CW, 2018, HINDAWI MATH PROBLEM
   Jain A.K., 2003, PROC GREAT LAKES S V, P147
   Jeong YJ, 2009, 2009 INTERNATIONAL SYMPOSIUM ON INTELLIGENT SIGNAL PROCESSING AND COMMUNICATION SYSTEMS (ISPACS 2009), P603, DOI 10.1109/ISPACS.2009.5383768
   Garcia-Hernandez JJ, 2011, J SIGNAL PROCESS SYS, V64, P457, DOI 10.1007/s11265-010-0503-8
   Kasana G, 2017, J INF PROCESS SYST, V13, P1331, DOI 10.3745/JIPS.03.0042
   Kim C, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155336
   Kim C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040644
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kodovsky J, 2010, PROC SPIE, V7541, DOI 10.1117/12.838768
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Lande PU., 2009, ICGST PDCS J, V9, P17
   Leung HY, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P279
   Mohd B.J., 2012, International Conference on Computer, Information and Telecommunication Systems (CITS), P1, DOI DOI 10.1109/CITS.2012.6220393
   Mohd BJ, 2016, INT J ELECTRON SECUR, V8, P164, DOI 10.1504/IJESDF.2016.075589
   Moon Sunil K., 2018, International Journal of Information and Computer Security, V10, P374
   Moon SK, 2019, MULTIMED TOOLS APPL, V78, P22045, DOI 10.1007/s11042-019-7503-x
   Moon SK, 2015, INT J ELECTRON SECUR, V7, P305
   Moon SK, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P660, DOI 10.1109/ICIIP.2013.6707677
   Mstafa RJ, 2017, MULTIMED TOOLS APPL, V76, P21749, DOI 10.1007/s11042-016-4055-1
   Nagaraj V, 2013, IERI PROC, V4, P17, DOI 10.1016/j.ieri.2013.11.004
   Naji AW, 2009, IACSIT-SC 2009: INTERNATIONAL ASSOCIATION OF COMPUTER SCIENCE AND INFORMATION TECHNOLOGY - SPRING CONFERENCE, P405, DOI 10.1109/IACSIT-SC.2009.105
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Powar PV., 2013, INT J ELECT ELECT CO, V1, P99
   Rajagopalan S, 2012, PROCEDIA ENGINEER, V30, P806, DOI 10.1016/j.proeng.2012.01.931
   Riyas M., 2014, IOSR J ELECT ELECTRO, V9, P99
   Sadek MM, 2015, MULTIMED TOOLS APPL, V74, P7063, DOI 10.1007/s11042-014-1952-z
   Sakthivel SM, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P1124, DOI 10.1109/ECS.2015.7124758
   Shanthamma K, 2017, INT J ADV RES IDEAS, V3, P341
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Sun HM, 2011, IEEE J SEL AREA COMM, V29, P1392, DOI 10.1109/JSAC.2011.110806
   Tewari Aakanksha, 2017, International Journal of Advanced Intelligence Paradigms, V9, P111
   Verma P. K., 2016, CSI Transactions on ICT, V4, P65, DOI 10.1007/s40012-016-0122-z
   Yao Y., 2014, MULTIMED TOOLS APPL, V74, P1
   Zaidan A. A., 2009, International Journal of Computer and Network Security, V1, P71
   Zaidan AA, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING AND APPLICATIONS, P482
   Zaidan BB, 2017, J CIRCUIT SYST COMP, V26, DOI 10.1142/S021812661750116X
   Zaidan B. B., 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P343
   Zaidan BB, 2009, INT J COMPUTER ELECT, V1
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Ziener D, 2008, J SIGNAL PROCESS SYS, V51, P123, DOI 10.1007/s11265-007-0136-8
NR 62
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 15
BP 21047
EP 21081
DI 10.1007/s11042-022-12353-w
EA MAR 2022
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1U7IV
UT WOS:000770061500006
DA 2024-07-18
ER

PT J
AU Rathi, S
   Kaur, B
   Agrawal, RK
AF Rathi, Swati
   Kaur, Baljeet
   Agrawal, R. K.
TI Selection of Relevant Visual Feature Sets for Enhanced Depression
   Detection using Incremental Linear Discriminant Analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Depression classification; Video processing; Visual Cues; Texture
   Features; Feature selection; Wrapper method; Incremental Linear
   Discriminant Analysis
ID TEXTURE CLASSIFICATION; FACIAL APPEARANCE; DIAGNOSIS
AB Presently, while automated depression diagnosis has made great progress, most of the recent works have focused on combining multiple modalities rather than strengthening a single one. In this research work, we present a unimodal framework for depression detection based on facial expressions and facial motion analysis. We investigate a wide set of visual features extracted from different facial regions. Due to high dimensionality of the obtained feature sets, identification of informative and discriminative features is a challenge. This paper suggests a hybrid dimensionality reduction approach which leverages the advantages of the filter and wrapper methods. First, we use a univariate filter method, Fisher Discriminant Ratio, to initially reduce the size of each feature set. Subsequently, we propose an Incremental Linear Discriminant Analysis (ILDA) approach to find an optimal combination of complementary and relevant feature sets. We compare the performance of the proposed ILDA with the batch-mode LDA and also the Composite Kernel based Support Vector Machine (CKSVM) method. The experiments conducted on the Distress Analysis Interview Corpus Wizard-of-Oz (DAIC-WOZ) dataset demonstrate that the best depression classification performance is obtained by using different feature extraction methods in combination rather than individually. ILDA generates better depression classification results in comparison to the CKSVM. Moreover, ILDA based wrapper feature selection incurs lower computational cost in comparison to the CKSVM and the batch-mode LDA methods. The proposed framework significantly improves the depression classification performance, with an F1 Score of 0.805, which is better than all the video based depression detection models suggested in literature, for the DAIC-WOZ dataset. Salient facial regions and well performing visual feature extraction methods are also identified.
C1 [Rathi, Swati; Agrawal, R. K.] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi, India.
   [Kaur, Baljeet] Univ Delhi, Hansraj Coll, Delhi, India.
C3 Jawaharlal Nehru University, New Delhi; University of Delhi
RP Rathi, S (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, Delhi, India.
EM swatirathi362@gmail.com; baljeetkaur26@hotmail.com; rkajnu@gmail.com
RI kaur, baljeet/JEF-0422-2023
OI Agrawal, Ramesh kumar/0000-0003-3122-5096; Kaur,
   Baljeet/0000-0003-2821-2219; Rathi, Swati/0000-0003-4385-0120
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Al Jazaery M, 2021, IEEE T AFFECT COMPUT, V12, P262, DOI 10.1109/TAFFC.2018.2870884
   Alghowinem S, 2018, IEEE T AFFECT COMPUT, V9, P478, DOI 10.1109/TAFFC.2016.2634527
   [Anonymous], 2013, AVEC 13, DOI DOI 10.1145/2512530.2512533
   APA, 2013, DIAGNOSTIC STAT MANU, V5th ed.
   Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Beck AT, 1996, Psychol Assess, DOI [10.1037/t00742-000, DOI 10.1037/T00742-000]
   Bellantonio Marco., 2016, Video Analytics. Face and Facial Expression Recognition and Audience Measurement, P151
   Buyukdura JS, 2011, PROG NEURO-PSYCHOPH, V35, P395, DOI 10.1016/j.pnpbp.2010.10.019
   Castro E, 2011, NEUROIMAGE, V58, P526, DOI 10.1016/j.neuroimage.2011.06.044
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Cohen Ira., 2000, Neural Information Processing Systems
   Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260
   Cummins N., 2013, P 3 ACM INT WORKSH A, P11
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Melo WC, 2019, COMBINING GLOBAL LOC, P1
   Dibeklioglu H, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P307, DOI 10.1145/2818346.2820776
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Giannakakis G, 2017, BIOMED SIGNAL PROCES, V31, P89, DOI 10.1016/j.bspc.2016.06.020
   Girard JM, 2013, IEEE INT CONF AUTOMA
   Gong Y., 2017, Proceedings of the 7th Annual Workshop on Audio/Visual Emotion Challenge, P69, DOI DOI 10.1145/3133944.3133945
   Gratch J, 2014, LREC 2014 - NINTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3123
   Gupta R., 2014, P 4 INT WORKSH AUD V, P33, DOI [DOI 10.1145/2661806.2661810, 10.1145/2661806.2661810]
   Haque A., 2018, ARXIV PREPRINT ARXIV
   Hawton K, 2013, J AFFECT DISORDERS, V147, P17, DOI 10.1016/j.jad.2013.01.004
   He L, 2019, IEEE T MULTIMEDIA, V21, P1476, DOI 10.1109/TMM.2018.2877129
   He S, 2009, IEEE T BIO-MED ENG, V56, P1864, DOI 10.1109/TBME.2009.2017508
   HILL D, 1974, BRIT J PSYCHIAT, V124, P221, DOI 10.1192/bjp.124.3.221
   Nhat HTM, 2019, 2019 26TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), P371, DOI [10.1109/ict.2019.8798816, 10.1109/ICT.2019.8798816]
   Jain V., 2014, 2014 ACM INT WORKSH, P87
   Jan A, 2018, IEEE T COGN DEV SYST, V10, P668, DOI 10.1109/TCDS.2017.2721552
   Jan Asim., 2014, Proceedings of the ACM 4th International Workshop on Audio/Visual Emotion Challenge, P73, DOI DOI 10.1145/2661806.2661812
   Joshi J, 2013, J MULTIMODAL USER IN, V7, P217, DOI 10.1007/s12193-013-0123-2
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Manfredonia J, 2019, J AUTISM DEV DISORD, V49, P279, DOI 10.1007/s10803-018-3757-9
   MARSAGLIA G, 1974, SANKHYA SER A, V36, P437
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Meng H., 2009, EMBEDDED COMPUTER VI, P139, DOI DOI 10.1007/978-1-84800-304-0_7
   Meng H., 2013, P 3 ACM INT WORKSH A, P21, DOI [10.1145/2512530.2512532., DOI 10.1145/2512530.2512532]
   Nasir M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P43, DOI 10.1145/2988257.2988261
   Neumann D, 2017, IEEE INT VEH SYM, P773, DOI 10.1109/IVS.2017.7995810
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   OUELLETTE DV, 1981, LINEAR ALGEBRA APPL, V36, P187, DOI 10.1016/0024-3795(81)90232-9
   Pampouchidou A, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P27, DOI 10.1145/2988257.2988266
   Ringeval Fabien, 2017, P 7 ANN WORKSHOP AUD, P3, DOI DOI 10.1145/3133944.3133953
   Roberts N. L., 2018, Lancet, V392, P1789, DOI [10.1016/S0140-6736(18)32279-7, DOI 10.1016/S0140-6736(18)32279-7]
   Senoussaoui M., 2014, P 4 INT WORKSH AUD V, P57
   Shao L., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, P477
   Song SY, 2018, IEEE INT CONF AUTOMA, P158, DOI 10.1109/FG.2018.00032
   Stratou G, 2015, J MULTIMODAL USER IN, V9, P17, DOI 10.1007/s12193-014-0161-4
   Sun B., 2017, P 7 ANN WORKSHOP AUD, P61, DOI [DOI 10.1145/3133944.3133951, 10.1145/3133944.3133951]
   Syed Z. S., 2017, P 7 ANN WORKSH AUD V, P37, DOI DOI 10.1145/3133944.3133947
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Valstar M., 2014, P 4 INT WORKSH AUD V, P3, DOI 10.1145/2661806.2661807
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Wang YF, 2020, I S BIOMED IMAGING, P1933, DOI [10.1109/isbi45749.2020.9098396, 10.1109/ISBI45749.2020.9098396]
   Wen LY, 2015, IEEE T INF FOREN SEC, V10, P1432, DOI 10.1109/TIFS.2015.2414392
   Who.int, 2020, DEPRESSION
   WILLIAMS JBW, 1988, ARCH GEN PSYCHIAT, V45, P742
   Williamson J.R., 2013, AVEC 2013 P 3 ACM IN, P41, DOI [DOI 10.1145/2512530.2512531, 10.1145/2512530.2512531]
   Williamson J.R, 2014, 2014 ACM INT WORKSH, P65
   Williamson JR, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P11, DOI 10.1145/2988257.2988263
   Yang BQ, 2016, MULTIMED TOOLS APPL, V75, P6979, DOI 10.1007/s11042-015-2623-4
   Yang L, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P89, DOI 10.1145/2988257.2988269
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Zheng WY, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9348207
   Zhou XZ, 2020, IEEE T AFFECT COMPUT, V11, P542, DOI 10.1109/TAFFC.2018.2828819
   Zhu Y, 2018, IEEE T AFFECT COMPUT, V9, P578, DOI 10.1109/TAFFC.2017.2650899
NR 71
TC 4
Z9 4
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17703
EP 17727
DI 10.1007/s11042-022-12420-2
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900020
DA 2024-07-18
ER

PT J
AU Mandal, SK
   Naskar, MNB
AF Mandal, Sumanta Kumar
   Naskar, M. Nazma Bj
TI Meta heuristic assisted automated channel selection model for motor
   imagery brain computer interface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MI EEG signal; CSP based feature extraction; Channel and sample
   selection; BLDA
ID COMPONENT ANALYSIS; CLASSIFICATION; PERFORMANCE; OPTIMIZATION; ALGORITHM
AB Recently, the practical Motor Imaginary Brain-computer interface (MIBCI) are being largely developed. In general, these systems adopt high-density ElectroEncephaloGraphy (EEG) channels with lack of channel optimization. The data processing complexity increases due to the artifacts and noise in the several channels and this tends to lessen the classification performance. Hence to address this problem, a novel channel selection approach will be developed. In this work, the most appropriate channel will be selected by a new hybrid optimization approach Geometric Mean based Moth flame hybridized with Fire fly Update (GM-MFU) model. This is the hybridized form of standard "Moth-Flame Optimization (MFO) algorithm and Firefly (FF) optimization algorithm". In addition to this, the appropriate samples corresponding to the channels are also selected with the proposed GM-MFU model. An objective model is developed for congruent selection of the optimal channels and solution samplesThe selected channels as well as features extracted from the original signal with "Common Spatial Pattern(CSP)" are subjected for classification via Bayesian Linear Discriminate Analysis (BLDA). The final resultant from Bayesian Linear Discriminate Analysis (BLDA) provides the classified Motor Imagery (MI) EEG signal. The proposed channels election approach with hybridized meta-heuristic optimization is evaluated over the state of the art models in terms of positive, negative measures and Kappa coefficient as well.
C1 [Mandal, Sumanta Kumar; Naskar, M. Nazma Bj] Kalinga Inst Ind Technol KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar, Odisha, India.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Mandal, SK (corresponding author), Kalinga Inst Ind Technol KIIT Deemed Univ, Sch Comp Engn, Bhubaneswar, Odisha, India.
EM skumarjp555@gmail.com
CR Aggarwal S, 2019, ARRAY-NY, V1-2, DOI 10.1016/j.array.2019.100003
   Basha TSG, 2012, IET MICROW ANTENNA P, V6, P773, DOI 10.1049/iet-map.2011.0356
   Chang HL, 2019, IEEE ACCESS, V7, P154180, DOI 10.1109/ACCESS.2019.2944938
   Chaudhary S, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2020.105325
   Fadda E., 2019, 14 IEEE INT C AUT SC
   Fadda E, 2021, Recent advances in computational optimization. Springer studies in computational intelligence, V920, P71
   Fadda E, 2021, TRANSPORT RES E-LOG, V145, DOI 10.1016/j.tre.2020.102174
   Fister I, 2013, SWARM EVOL COMPUT, V13, P34, DOI 10.1016/j.swevo.2013.06.001
   Handiru VS, 2016, IEEE T HUM-MACH SYST, V46, P777, DOI 10.1109/THMS.2016.2573827
   Jin J, 2019, NEURAL NETWORKS, V118, P262, DOI 10.1016/j.neunet.2019.07.008
   Kirar JS, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105519
   Kirar JS, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0931-8
   Luo J, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105464
   Luo J, 2019, J NEUROSCI METH, V323, P98, DOI 10.1016/j.jneumeth.2019.05.011
   Malan NS, 2019, COMPUT BIOL MED, V107, P118, DOI 10.1016/j.compbiomed.2019.02.009
   Miao MM, 2018, NEURAL COMPUT APPL, V30, P3677, DOI 10.1007/s00521-017-2950-7
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Olivas-Padilla BE, 2019, APPL SOFT COMPUT, V75, P461, DOI 10.1016/j.asoc.2018.11.031
   Qiu ZY, 2016, NEUROCOMPUTING, V207, P519, DOI 10.1016/j.neucom.2016.05.035
   Rajakumar BR, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATIONS AND NETWORKING TECHNOLOGIES (ICCCNT)
   Rajakumar BR, 2013, AASRI PROC, V4, P288, DOI 10.1016/j.aasri.2013.10.043
   Rajakumar BR, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P2116, DOI 10.1109/CEC.2014.6900561
   Ruan J, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1106-3
   Sadiq MT, 2019, IEEE ACCESS, V7, P171431, DOI 10.1109/ACCESS.2019.2956018
   Talukdar U, 2020, BIOMED SIGNAL PROCES, V58, DOI 10.1016/j.bspc.2019.101829
   Tan P, 2020, SWARM EVOL COMPUT, V52, DOI 10.1016/j.swevo.2019.100597
   Tang XL, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113285
   Togha MM, 2019, BIOMED SIGNAL PROCES, V50, P52, DOI 10.1016/j.bspc.2019.01.008
   Wang J, 2018, BIOMED SIGNAL PROCES, V46, P10, DOI 10.1016/j.bspc.2018.06.008
   Wang L, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.070
   Yang Y, 2017, BIOMED SIGNAL PROCES, V38, P302, DOI 10.1016/j.bspc.2017.06.016
   Yilmaz BH, 2020, MED BIOL ENG COMPUT, V58, P443, DOI 10.1007/s11517-019-02075-x
   Zahid SZ., 2019, ONLINE CLASSIFICATIO
   Zhou BY, 2019, BIOMED SIGNAL PROCES, V50, P103, DOI 10.1016/j.bspc.2019.01.017
NR 34
TC 3
Z9 3
U1 6
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17111
EP 17130
DI 10.1007/s11042-022-12327-y
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200005
DA 2024-07-18
ER

PT J
AU Sameer, M
   Gupta, B
AF Sameer, Mustafa
   Gupta, Bharat
TI CNN based framework for detection of epileptic seizures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EEG; CNN; Deep learning; Epilepsy; Classification; Seizures
ID NEURAL-NETWORK; CLASSIFICATION; SIGNAL
AB Epilepsy is a common neurological disease that uses electroencephalogram (EEG) data for its detection purpose. Neurologists make the diagnosis by visual inspection of EEG reports. As it is time-consuming and due to the shortage of specialists worldwide, researchers have proposed automated systems to detect the disease. In the past decade, most of the systems were designed using hand-engineered features. However, identifying appropriate features is always a challenging task in the development of a seizure detector system. Deep learning networks eliminate the problem of selecting the best features but suffer from long training time, generally days or weeks. To overcome this problem, the authors have proposed a new 1D convolutional neural network (CNN) that automatically extracts features at an average of seven epochs, only followed by traditional machine learning (ML) classifier. 1D CNN architectures are intrinsically suitable for the processing of EEG time-series data. The proposed model doesn't require any preprocessing of EEG signal and results in approximately 94% reduced training time than end-to-end deep learning models. Different ML techniques have been applied to extracted features to check the robustness of the proposed 1D CNN. Maximum accuracy of 99.83% has been achieved by most of the classifiers to detect between healthy and seizure patients. The reduced number of processing steps and epochs makes it suitable for real-time clinical applications.
C1 [Sameer, Mustafa; Gupta, Bharat] Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Sameer, M (corresponding author), Natl Inst Technol Patna, Dept Elect & Commun Engn, Patna 800005, Bihar, India.
EM mustafa.ec17@nitp.ac.in; bharat@nitp.ac.in
RI Sameer, Mustafa/AAW-2704-2020
OI Sameer, Mustafa/0000-0003-3819-7825
CR Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   Akyol K, 2020, EXPERT SYST APPL, V148, DOI 10.1016/j.eswa.2020.113239
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   Ansari AH, 2019, INT J NEURAL SYST, V29, DOI 10.1142/S0129065718500119
   ASIF U, 2019, SEIZURENET DEEP CONV
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Dash DP, 2020, J BIOMED RES, V34, P170, DOI 10.7555/JBR.34.20190006
   Diaz-Pinto A, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0649-y
   Diykh M, 2017, EXPERT SYST APPL, V90, P87, DOI 10.1016/j.eswa.2017.08.012
   Dong YX, 2017, 2017 IEEE/ACM SECOND INTERNATIONAL CONFERENCE ON CONNECTED HEALTH - APPLICATIONS, SYSTEMS AND ENGINEERING TECHNOLOGIES (CHASE), P51, DOI 10.1109/CHASE.2017.59
   Emami A, 2019, NEUROIMAGE-CLIN, V22, DOI 10.1016/j.nicl.2019.101684
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   GOTMAN J, 1990, ELECTROEN CLIN NEURO, V76, P317, DOI 10.1016/0013-4694(90)90032-F
   Hassan AR, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105333
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   He KM, 2015, PROC CVPR IEEE, P5353, DOI 10.1109/CVPR.2015.7299173
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaiswal AK, 2017, BIO-MED MATER ENG, V28, P141, DOI 10.3233/BME-171663
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Kumar SP, 2010, EXPERT SYST APPL, V37, P3284, DOI 10.1016/j.eswa.2009.09.051
   Li Y, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S0129065720500197
   Liu Y, 2020, IEEE ACCESS, V8, P37495, DOI 10.1109/ACCESS.2020.2976156
   Marsland, 2014, MACHINE LEARNING ALG, DOI DOI 10.1201/B17476
   Muhammad G, 2018, IEEE ACCESS, V6, P45372, DOI 10.1109/ACCESS.2018.2859267
   Namazi H, 2016, ONCOTARGET, V7, P342, DOI 10.18632/oncotarget.6341
   Ocak H, 2009, EXPERT SYST APPL, V36, P2027, DOI 10.1016/j.eswa.2007.12.065
   Quan Q, 2021, VISUAL COMPUT, V37, P245, DOI 10.1007/s00371-020-01796-7
   Raghu S, 2020, NEURAL NETWORKS, V124, P202, DOI 10.1016/j.neunet.2020.01.017
   Raghu S, 2019, EXPERT SYST APPL, V127, P323, DOI 10.1016/j.eswa.2019.03.021
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sameer M, 2020, NATL CONF COMMUN, DOI 10.1109/ncc48643.2020.9056027
   Sameer M, 2019, INT SYMP WIREL, DOI 10.1109/wpmc48795.2019.9096119
   Sameer M, 2020, WIRELESS PERS COMMUN, V115, P909, DOI 10.1007/s11277-020-07542-5
   Samiee K, 2015, IEEE T BIO-MED ENG, V62, P541, DOI 10.1109/TBME.2014.2360101
   San-Segundo R, 2019, COMPUT BIOL MED, V109, P148, DOI 10.1016/j.compbiomed.2019.04.031
   Sharmila A, 2020, HEALTH TECHNOL-GER, V10, P711, DOI 10.1007/s12553-019-00363-y
   Siuly S, 2019, IET SCI MEAS TECHNOL, V13, P35, DOI 10.1049/iet-smt.2018.5358
   Tzallas AT, 2009, IEEE T INF TECHNOL B, V13, P703, DOI 10.1109/TITB.2009.2017939
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   Wang GJ, 2017, NEUROCOMPUTING, V228, P283, DOI 10.1016/j.neucom.2016.09.080
   Widman G, 2000, PHYS REV E, V62, P4898, DOI 10.1103/PhysRevE.62.4898
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Zhang SD, 2020, NEUROCOMPUTING, V410, P363, DOI 10.1016/j.neucom.2020.06.041
   Zhou MN, 2018, FRONT NEUROINFORM, V12, DOI 10.3389/fninf.2018.00095
   Zhu GH, 2014, COMPUT METH PROG BIO, V115, P64, DOI 10.1016/j.cmpb.2014.04.001
NR 45
TC 7
Z9 8
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17057
EP 17070
DI 10.1007/s11042-022-12702-9
EA MAR 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200012
DA 2024-07-18
ER

PT J
AU Yu, JT
   Jia, RS
   Li, YC
   Sun, HM
AF Yu, Jin-Tao
   Jia, Rui-Sheng
   Li, Yong-Chao
   Sun, Hong-Mei
TI Automatic fish counting via a multi-scale dense residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fish counting; Multi-scale attention mechanism; Dense residual network;
   Density map
AB The existing fish counting methods count the number of fish through target detection or regression, and these methods are difficult to process the image of fish with serious occlusion and small target. In response to this problem, using the idea of density regression, this paper proposes a fish counting method based on a multi-scale dense residual network, and designs a multi-scale attention mechanism to improve the network's ability to extract features of fish of different sizes. The weight is used to discriminate the size of the fish scale, which solves the problem of large changes in the fish scale. In order to generate a higher definition fish density map, a dense residual module is constructed to fuse the shallow and deep features of the image, which ensures that the density map generated by this method can truly reflect the distribution of fish. Experimental results show that the peak signal to noise ratio (PSNR) and structural similarity of the density map generated by the proposed method are within a reasonable range. Compared with the existing methods, our method improves the mean absolute error by 21.8% and the mean square error by 22.8% under high density, and our method also achieves good results in real scenes.
C1 [Yu, Jin-Tao; Jia, Rui-Sheng; Li, Yong-Chao; Sun, Hong-Mei] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Jia, Rui-Sheng; Sun, Hong-Mei] Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Techno, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Jia, RS; Sun, HM (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.; Jia, RS; Sun, HM (corresponding author), Shandong Univ Sci & Technol, Shandong Prov Key Lab Wisdom Mine Informat Techno, Qingdao 266590, Peoples R China.
EM jrs716@163.com; shm0221@163.com
RI Jia, Rui-Sheng/D-4460-2015
OI Jia, Rui-Sheng/0000-0003-1612-4764
FU Humanity and Social Science Foundation of Ministry of Education, China
   [21YJAZH077]
FX The authors are grateful for collaborative funding support from the
   Humanity and Social Science Foundation of Ministry of Education, China
   (21YJAZH077).
CR Achanta SDM, 2019, INT J INTELL UNMANNE, V8, P43, DOI 10.1108/IJIUS-01-2019-0005
   Achanta SDM, 2019, SOFT COMPUT, V23, P8359, DOI 10.1007/s00500-019-04108-x
   Al-Saaidah B, 2018, INT CONF INFORM COMM, P107, DOI 10.1109/IACS.2018.8355450
   Albuquerque PLF, 2019, COMPUT ELECTRON AGR, V167, DOI 10.1016/j.compag.2019.105015
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   del Río J, 2013, SENSORS-BASEL, V13, P14740, DOI 10.3390/s131114740
   Fabic JN, 2013, IEEE UNDERWATER TECH
   Fan LZ, 2013, AQUACULTURE, V380, P91, DOI 10.1016/j.aquaculture.2012.10.016
   Follana-Berná G, 2020, J EXP MAR BIOL ECOL, V527, DOI 10.1016/j.jembe.2020.151376
   French G., 2015, P MACH VIS AN THEIR
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Hernández-Ontiveros JM, 2018, COMPUT ELECTRON AGR, V145, P53, DOI 10.1016/j.compag.2017.12.023
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Islam MJ, 2020, IEEE ROBOT AUTOM LET, V5, P3227, DOI 10.1109/LRA.2020.2974710
   Lainez SMD, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION SYSTEMS (ICCCS 2019), P67, DOI [10.1109/ccoms.2019.8821746, 10.1109/CCOMS.2019.8821746]
   Le J., 2017, 2016 INT FOR MECH CO, P358, DOI [DOI 10.2991/IFMCA-16.2017.56, 10.2991/ifmca-16.2017.56]
   Lempitsky V., 2010, Advances in Neural Information Processing Systems, V23
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Li YS, 2017, NEUROCOMPUTING, V266, P29, DOI 10.1016/j.neucom.2017.05.024
   Liu YB, 2020, J ELECTRON IMAGING, V29, DOI 10.1117/1.JEI.29.3.033010
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   NEWBURY PF, 1995, AQUACULTURE, V133, P45, DOI 10.1016/0044-8486(95)00003-K
   Sharif MH, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P347, DOI 10.1109/ICCITechn.2015.7488094
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Westling F., 2014, 2014 INT C DIG IM CO, P1, DOI [DOI 10.1109/DICTA.2014.7008086, 10.1109/dicta.2014.7008086]
   Zeng LK, 2017, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2017.8296324
   Zhang L, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105844
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang YL, 2021, IEEE T PATTERN ANAL, V43, P2480, DOI 10.1109/TPAMI.2020.2968521
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng X, 2010, INT CONF COMP SCI, P247, DOI 10.1109/ICCSIT.2010.5564597
   Zhu C, 2009, FISHERY MODERNIZATIO, V36, P25
NR 36
TC 9
Z9 12
U1 10
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17223
EP 17243
DI 10.1007/s11042-022-12672-y
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200007
DA 2024-07-18
ER

PT J
AU Zhang, B
   Liu, JZ
   Wu, JH
AF Zhang, Bing
   Liu, Jizhong
   Wu, Jianhua
TI Label consistent non-negative representation of ECG signals for
   automated recognition of cardiac arrhythmias
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiogram signal; Nonnegative representation; Dictionary
   learning; Sparse representation
ID SPARSE REPRESENTATION; HEARTBEAT CLASSIFICATION; DICTIONARY; PCA
AB Electrocardiogram (ECG) is a common and powerful tool for studying heart function and diagnosing several abnormal arrhythmias. This paper aims to propose a novel robust ECG biometric method, named the Label Consistent Non-negative Representation (LCNR), for ECG classification. We propose an objective function consists of the reconstruction error, classification error and discriminative sparse-code error with the non-negative regularization term on the coding coefficients. The coding vector was restricted to be non-negative using a non-negative constrained least squares model, and a blockwise coordinate descent algorithm was used to simultaneously learn a compact discriminative dictionary and a multiclass linear classifier. The experiments are carried out for the proposed methods using benchmark MIT-BIH data and evaluated under standard scheme and category-based scheme. The evaluation and experimental results show that our proposed LCNR algorithm achieves state-of-the-art performance, specifically surpassing the label consistent KSVD algorithm in terms of classification accuracy. By means of the dictionary learning algorithm, we can improve the efficiency for a large-size training database with a significantly faster execution time (more than 5 times) than NRC.
C1 [Zhang, Bing; Liu, Jizhong] Nanchang Univ, Sch Mechatron Engn, Nanchang Key Lab Med & Technol Res, Nanchang 330031, Jiangxi, Peoples R China.
   [Wu, Jianhua] Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
C3 Nanchang University; Nanchang University
RP Liu, JZ (corresponding author), Nanchang Univ, Sch Mechatron Engn, Nanchang Key Lab Med & Technol Res, Nanchang 330031, Jiangxi, Peoples R China.; Wu, JH (corresponding author), Nanchang Univ, Sch Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM 15070899683@163.com; liujizhong@ncu.edu.cn; jhwu@ncu.edu.cn
RI Wu, Jianhua/AFL-8480-2022
OI Wu, Jianhua/0000-0002-4505-0568
FU National Natural Science Foundation of China [61863027]; Key Research
   and Development Plan of Jiangxi Province [20202BBGL73057]; Natural
   Science Foundation of Jiangxi Province [20171BAB201013]; Project of
   Nanchang Key Laboratory of Medical and Technology Research
   [2018-NCZDSY-002]
FX This work is supported by the National Natural Science Foundation of
   China (Grant no. 61863027), the Key Research and Development Plan of
   Jiangxi Province (Grant no. 20202BBGL73057), the Natural Science
   Foundation of Jiangxi Province (Grant no. 20171BAB201013) and the
   Project of Nanchang Key Laboratory of Medical and Technology Research
   (Grant no. 2018-NCZDSY-002).
CR Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cui GS, 2018, NEUROCOMPUTING, V292, P38, DOI 10.1016/j.neucom.2018.02.067
   Desai U, 2015, ANNU IEEE IND CONF
   Elhaj FA, 2016, COMPUT METH PROG BIO, V127, P52, DOI 10.1016/j.cmpb.2015.12.024
   Hua J, 2020, J SYST ARCHITECT, V104, DOI 10.1016/j.sysarc.2019.101687
   Hua J, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618500883
   Huang HF, 2012, J MED SYST, V36, P1235, DOI 10.1007/s10916-010-9585-x
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li NY, 2017, 2017 17TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT 2017), P1537, DOI 10.1109/ICCT.2017.8359889
   Li R, 2020, PATTERN RECOGN LETT, V129, P70, DOI 10.1016/j.patrec.2019.11.005
   Liu HW, 2013, DATA MIN KNOWL DISC, V26, P435, DOI 10.1007/s10618-012-0265-y
   Mar T, 2011, IEEE T BIO-MED ENG, V58, DOI 10.1109/TBME.2011.2113395
   Marinho LB, 2019, FUTURE GENER COMP SY, V97, P564, DOI 10.1016/j.future.2019.03.025
   Martis RJ, 2009, ANNU IEEE IND CONF, P422
   Martis RJ, 2014, COMPUT BIOL MED, V48, P133, DOI 10.1016/j.compbiomed.2014.02.012
   Martis RJ, 2013, BIOMED SIGNAL PROCES, V8, P437, DOI 10.1016/j.bspc.2013.01.005
   Martis RJ, 2012, EXPERT SYST APPL, V39, P11792, DOI 10.1016/j.eswa.2012.04.072
   Mathews Sherin M., 2015, 2015 41st Annual Northeast Biomedical Engineering Conference (NEBEC). Proceedings, P1, DOI 10.1109/NEBEC.2015.7117118
   Mondéjar-Guerra V, 2019, BIOMED SIGNAL PROCES, V47, P41, DOI 10.1016/j.bspc.2018.08.007
   Plawiak P, 2018, EXPERT SYST APPL, V92, P334, DOI 10.1016/j.eswa.2017.09.022
   Raj S, 2018, EXPERT SYST APPL, V105, P49, DOI 10.1016/j.eswa.2018.03.038
   Raj S, 2016, COMPUT METH PROG BIO, V136, P163, DOI 10.1016/j.cmpb.2016.08.016
   Romdhane TF, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103866
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Singh BN, 2006, DIGIT SIGNAL PROCESS, V16, P275, DOI 10.1016/j.dsp.2005.12.003
   Standard A. E, 1998, EC571998 ANSIAAMI
   Wan MH, 2021, INFORM SCIENCES, V563, P1, DOI 10.1016/j.ins.2021.02.006
   Wan MH, 2019, MULTIMED TOOLS APPL, V78, P22109, DOI 10.1007/s11042-019-7454-2
   Wan MH, 2017, FUZZY SET SYST, V318, P120, DOI 10.1016/j.fss.2016.06.001
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu JX, 2020, PATTERN RECOGN LETT, V135, P44, DOI 10.1016/j.patrec.2020.04.022
   Xu J, 2019, PATTERN RECOGN, V88, P679, DOI 10.1016/j.patcog.2018.12.023
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao W, 2019, IEEE ENG MED BIO, P1500, DOI [10.1109/EMBC.2019.8856650, 10.1109/embc.2019.8856650]
   Zhou JH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112609
   Zhu WL, 2019, IEEE ACM T COMPUT BI, V16, P131, DOI 10.1109/TCBB.2018.2846611
NR 40
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 16047
EP 16065
DI 10.1007/s11042-022-12614-8
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902100002
DA 2024-07-18
ER

PT J
AU Alshayeji, MH
   Al-Roomi, SA
   Abed, S
AF Alshayeji, Mohammad H.
   Al-Roomi, Suood Abdulaziz
   Abed, Sa'ed
TI Efficient hand vein recognition using local keypoint descriptors and
   directional gradients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Palm and wrist vein biometric; Image processing; Scale-invariant feature
   transform (SIFT); Speeded-up robust features (SURF)
ID IDENTIFICATION
AB This paper proposes a computationally efficient palm and wrist vein biometric system through finely tuning computer-vision algorithms. In particular, a comprehensive analysis of the scale-invariant feature transform (SIFT) and speeded-up robust features (SURF) keypoint descriptors was conducted along with a novel idea of a score-based fusion of directional image derivatives to achieve outstanding recognition results. The work demonstrates that appropriate vein image processing, keypoint extraction, optimal matching metrics, and combination of classification scores from a group of directional gradients lead to robust and stable vein recognition. It was shown through experimental analysis that the developed biometric system outperforms all state-of-the-art results other than deep learning methods on the two public hand vein databases (VERA and PUT). Moreover, an absolute 100% recognition for the PUT palm dataset was achieved without using deep learning. The proposed method is more suitable for embedded implementation compared to deep learning algorithms, with only a slight penalty in performance compared to deep learning architectures.
C1 [Alshayeji, Mohammad H.; Al-Roomi, Suood Abdulaziz; Abed, Sa'ed] Kuwait Univ, Comp Engn Dept, Kuwait, Kuwait.
C3 Kuwait University
RP Alshayeji, MH (corresponding author), Kuwait Univ, Comp Engn Dept, Kuwait, Kuwait.
EM m.alshayeji@ku.edu.kw
RI Alshayeji, Mohammad/HIZ-5938-2022
CR Ahmed MA., 2015, EGYPTIAN COMPUTER SC, V39, P1
   Ananthi G, 2022, VISUAL COMPUT, V38, P1901, DOI 10.1007/s00371-021-02253-9
   [Anonymous], 2008, PATTERN RECOGN
   Arakala A., 2015, INT C INFORM SYSTEMS, P56
   Babalola FO, 2021, SIGNAL IMAGE VIDEO P, V15, P459, DOI 10.1007/s11760-020-01765-6
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bouzida N, 2010, J MOD OPTIC, V57, P1731, DOI 10.1080/09500341003725763
   Bradski G., 2008, LEARNING OPENCV
   Chen YY, 2021, IEEE ACCESS, V9, P149796, DOI 10.1109/ACCESS.2021.3124631
   Cho S., 2021, PALM VEIN VERIFICATI
   COETZEE L, 1993, PATTERN RECOGN, V26, P1441, DOI 10.1016/0031-3203(93)90151-L
   Das Abhijit, 2014, 2014 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM). Proceedings, P68, DOI 10.1109/CIBIM.2014.7015445
   Du G., 2009, SPIE 7496 MIPPR 2009, P749628
   Hartung D., 2011, BIOM IJCB 2011 INT J, P1
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P302, DOI 10.1109/34.587996
   Jain A.K., 2006, Biometrics: Personal Identification in Networked Society
   Jhong S-Y., 2020, PROC INT C ADV ROBOT, P1, DOI DOI 10.1109/ARIS50834.2020
   Kabacinski R, 2011, ELECTRON LETT, V47, P1127, DOI 10.1049/el.2011.1441
   Kang WX, 2014, IEEE T INF FOREN SEC, V9, P1974, DOI 10.1109/TIFS.2014.2361020
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Kumar R., 2021, Adv. in Intell. Sys. and Comp., V1165, P1087, DOI DOI 10.1007/978-981-15-5113-0_92
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma X, 2017, IET BIOMETRICS, V6, P325, DOI 10.1049/iet-bmt.2016.0085
   Mirmohamadsadeghi L, 2014, IET BIOMETRICS, V3, P198, DOI 10.1049/iet-bmt.2013.0041
   Nivas S., 2014, INT J ENG RES GEN SC, V2, P580
   Olsen MA, 2010, COMM COM INF SC, V93, P425
   Pan M, 2011, LECT NOTES COMPUT SC, V7098, P116, DOI 10.1007/978-3-642-25449-9_15
   Pedersen J.T., 2011, Study group: Surf - feature detection and description
   Raghavendra R., 2015, 2015 IEEE 7th international conference on biometrics theory, applications and systems (BTAS), P1
   Sangeetha NM., 2014, INT J EMERGING TECHN, V4, P9
   Tome P., 2015, 2015 INT C BIOM SPEC, P1
   Wang GQ, 2017, COMPUT MATH METHOD M, V2017, DOI 10.1155/2017/2373818
   Wang KJ, 2006, IEEE ICMA 2006: PROCEEDING OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-3, PROCEEDINGS, P1790
   Wang YD, 2014, IET BIOMETRICS, V3, P234, DOI 10.1049/iet-bmt.2013.0042
   Wang Y, 2011, INT CONF ACOUST SPEE, P1, DOI 10.1109/PLASMA.2011.5993071
   Wu W, 2020, IET BIOMETRICS, V9, P1, DOI 10.1049/iet-bmt.2019.0034
   Zhou YB, 2011, IEEE T INF FOREN SEC, V6, P1259, DOI 10.1109/TIFS.2011.2158423
NR 39
TC 6
Z9 6
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15687
EP 15705
DI 10.1007/s11042-022-12608-6
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600024
DA 2024-07-18
ER

PT J
AU Bansal, M
   Mishra, A
   Sharma, A
AF Bansal, Megha
   Mishra, Anurag
   Sharma, Arpita
TI Multiple scaling Fuzzy-PSO watermarking scheme for gray-scale and
   colored images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete cosine transform; Fuzzy logic; Normalized cross-correlation;
   Human visual system
ID SVD; SECURE; OPTIMIZATION
AB Digital watermarking has become the core of digital security paradigm for ownership rights and copyright protection. The advance research in digital watermarking domain is focused on developments of techniques and algorithms which produce optimum results balancing two most relevant watermarking parameters, visual quality and robustness. This paper proposes a novel watermarking scheme which is a hybrid of fuzzy logic with particle swarm optimization (PSO), and is applied over eight standard grayscale and colored images each, to analyze the effectiveness of the proposed watermarking scheme. Three human visual system (HVS) features i.e. luminance, edge sensitivity, and contrast sensitivity, are extracted from each host image in the discrete cosine transform (DCT) domain, which are used as fuzzy attributes. These features are fed as input into fuzzy inference system which is based on 27 inference rules. Nine different image processing attacks are applied over signed images to examine the robustness of the proposed algorithm. Multiple scaling factors have been used for the embedding strength (proportional to) in the proposed scheme. The quality of the signed and attacked images is assessed using computed peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) values. The similarity between the extracted and the original watermark is assessed by computing normalized cross-correlation (NC) values depicting the robustness of our proposed scheme. The obtained results are compared with other state-of-the-art schemes available in this domain. The proposed Fuzzy-PSO watermarking scheme is found to outperform all of them.
C1 [Bansal, Megha] Univ Delhi, Dept Comp Sci, New Delhi, India.
   [Mishra, Anurag; Sharma, Arpita] Univ Delhi, Deen Dayal Upadhyaya Coll, New Delhi, India.
C3 University of Delhi; Deen Dayal Upadhyaya College; University of Delhi
RP Bansal, M (corresponding author), Univ Delhi, Dept Comp Sci, New Delhi, India.
EM megha.cs.du@gmail.com; anurag_cse2003@yahoo.com; asharma@ddu.du.ac.in
CR Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Abdelhakim AM, 2018, EXPERT SYST APPL, V100, P197, DOI 10.1016/j.eswa.2018.02.002
   Abraham A, 2005, STUD FUZZ SOFT COMP, V173, P159
   Agarwal C, 2015, EGYPT INFORM J, V16, P83, DOI 10.1016/j.eij.2015.01.002
   Agarwal C, 2013, J VIS COMMUN IMAGE R, V24, P1135, DOI 10.1016/j.jvcir.2013.07.007
   Akter A, 2014, 2014 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV)
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Alonso S.K., eMathTeacher: Mamdani's Fuzzy Inference Method
   Ansari IA, 2014, 2014 IEEE S COMPUTAT, P1
   Bansal M, 2021, 10 INT C SOFT COMPUT, P125
   Bansal M, 2020, LECT NOTES COMPUT SC, V12254, P862, DOI 10.1007/978-3-030-58817-5_61
   Benoraira A, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0239-5
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chen WN, 2013, IEEE T EVOLUT COMPUT, V17, P241, DOI 10.1109/TEVC.2011.2173577
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Dey N, 2013, INT J BIO-INSPIR COM, V5, P315, DOI 10.1504/IJBIC.2013.057193
   Fazlali HR, 2017, MULTIMED TOOLS APPL, V76, P3105, DOI 10.1007/s11042-015-3200-6
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gupta R, 2019, INT J INF SYST MODEL, V10, P51, DOI 10.4018/IJISMD.2019100103
   Gupta R, 2018, MULTIMED TOOLS APPL, V77, P19235, DOI 10.1007/s11042-017-5351-0
   Huang HC., 2010, J INF HIDING MULTIME, V1, P51
   Ishtiaq M., 2010, ICIC Express Lett, V4, P1
   Jacobsen HA., 2001, STUD FUZZ SOFT COMP, V1, P145, DOI 10.1007/978-3-7908-1837-6_7
   Jagadeesh B, 2016, SOFT COMPUT, V20, P3679, DOI 10.1007/s00500-015-1729-y
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khanna AK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1140, DOI 10.1109/CCAA.2016.7813888
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Liu J., 2005, P 1 INT C INF COMM T, P337
   Liu JC, 2001, IMAGE VISION COMPUT, V19, P1083, DOI 10.1016/S0262-8856(01)00068-3
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Loukhaoukha K, 2014, OPTO-ELECTRON REV, V22, P45, DOI 10.2478/s11772-014-0177-z
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Mehta R., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P123, DOI 10.1109/IIHMSP.2010.38
   Mehta R, 2016, J SIGNAL PROCESS SYS, V84, P265, DOI 10.1007/s11265-015-1055-8
   Melin P, 2007, NAFIPS 2007 - 2007 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, P582, DOI 10.1109/NAFIPS.2007.383905
   Mishra A, 2016, BIO-INSPIRED COMPUTATION AND APPLICATIONS IN IMAGE PROCESSING, P131, DOI 10.1016/B978-0-12-804536-7.00007-7
   Mishra A, 2012, IEEE IJCNN
   Mishra A, 2019, MULTIMED TOOLS APPL, V78, P22127, DOI 10.1007/s11042-019-7452-4
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Mohanty S. P., 1999, P 7 ACM INT C MUL OC, P49
   Motwani Mukesh, 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P321
   Motwani MC, 2009, IEEE IMAGE PROC, P4261, DOI 10.1109/ICIP.2009.5413682
   Negnevitsky Michael, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P533, DOI 10.1109/CSIE.2009.623
   Oueslati S., 2010, Int J Image Process, V4, P218
   Pan JS, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104049
   Rajpal A., 2016, 2016 IEEE Int Conf Signal Process, Commun and Comput (ICSPCC), P1
   Rajpal A, 2019, APPL SOFT COMPUT, V74, P603, DOI 10.1016/j.asoc.2018.10.043
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Takore Tamirat Tagesse, 2018, International Journal of Intelligent Systems and Applications, V10, P50, DOI 10.5815/ijisa.2018.11.06
   Taneja N, 2013, MULTIMED TOOLS APPL, V67, P593, DOI 10.1007/s11042-012-1037-9
   Taneja N, 2011, AEU-INT J ELECTRON C, V65, P338, DOI 10.1016/j.aeue.2010.04.011
   Tsai HH, 2012, APPL SOFT COMPUT, V12, P2442, DOI 10.1016/j.asoc.2012.02.021
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Vishwakarma Virendra P., 2018, Procedia Computer Science, V132, P1012, DOI 10.1016/j.procs.2018.05.017
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
NR 55
TC 5
Z9 5
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15219
EP 15248
DI 10.1007/s11042-022-12526-7
EA FEB 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600025
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Bai, J
   Xu, FJ
AF Zhang, Qiu-yu
   Bai, Jian
   Xu, Fu-jiu
TI A retrieval method for encrypted speech based on improved power
   normalized cepstrum coefficients and perceptual hashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Perceptual hashing; Speech feature
   extraction; Henon chaotic mapping; Power normalized cepstrum
   coefficients (PNCC)
ID ALGORITHM
AB In order to improve the impact of noise on the robustness and discrimination of the speech perceptual hashing scheme, improve retrieval efficiency and retrieval accuracy, and protect the privacy of the cloud speech data, a retrieval method for encrypted speech based on improved power normalized cepstrum coefficients (PNCC) and perceptual hashing was proposed in the paper. Firstly, the original speech was encrypted by Henon chaotic map inter-frame scrambling encryption algorithm before uploading to the encrypted speech library in cloud server. Secondly, the discrete wavelet transform (DWT) and first-order difference coefficient were used to improve the PNCC feature extraction algorithm to extract speech features, and the principal component analysis (PCA) was used to reduce high-dimensional audio features to one dimension to form frame features that can represent the speech segment. Finally, the frame features are constructed as binary hashing sequences using hash functions and upload it to the system hashing index table in the cloud. When the user retrieves, the hashing sequence of query speech is extracted and matched with the encrypted speech features by normalized hamming distance in the cloud system hashing index table to obtain the retrieval result. Experimental results show that compared with the existing methods, the proposed method has good robustness and discrimination, and improves retrieval efficiency and retrieval accuracy, the security of cloud speech data is improved. In addition, the proposed method has good recognition ability under simulated real noise environment.
C1 [Zhang, Qiu-yu; Bai, Jian; Xu, Fu-jiu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Lanzhou University of Technology
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM zhanggylz@163.com; baijian0213@163.com; xufujiu1@163.com
RI zhang, qiu/GXG-5600-2022; zhang, qiuyu/V-9223-2019
OI zhang, qiuyu/0000-0003-1488-388X
FU National Natural Science Foundation of China [61862041, 61363078]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61862041, 61363078). The authors also gratefully acknowledge
   the helpful comments and suggestions of the reviewers, which have
   improved the presentation.
CR Abdullah RSAR, 2019, J ENG-JOE, V2019, P6935, DOI 10.1049/joe.2019.0535
   Alassi A., 2019, 2019 IEEE INT C EL C, P1, DOI [10.1109/SGRE46976.2019.9020679, DOI 10.1109/ICECCT.2019.8869154]
   Ali Z, 2018, IEEE ACCESS, V6, P15494, DOI 10.1109/ACCESS.2018.2805845
   [白静 Bai Jing], 2019, [西安电子科技大学学报, Journal of Xidian University], V46, P86
   Dua M, 2019, J AMB INTEL HUM COMP, V10, P2301, DOI 10.1007/s12652-018-0828-x
   Elzaher MFA, 2016, INTERNATIONAL CONFERENCE ON INFORMATICS AND SYSTEMS (INFOS 2016), P329, DOI 10.1145/2908446.2908508
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Kim C, 2016, IEEE-ACM T AUDIO SPE, V24, P1315, DOI 10.1109/TASLP.2016.2545928
   Kowsigan M, 2019, CLUSTER COMPUT, V22, P12411, DOI 10.1007/s10586-017-1640-7
   Lee SC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072068
   Li WJ, 2014, THESIS XIDIAN U XIAN
   Nair UR., 2016, SECURE AUDIO WATERMA, V3, P1, DOI [10.1109/INVENTIVE.2016.7830133, DOI 10.1109/INVENTIVE.2016.7830133]
   Nayyar RK, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P30, DOI 10.1109/BID.2017.8336569
   Waldekar S, 2020, MULTIMED TOOLS APPL, V79, P7911, DOI 10.1007/s11042-019-08279-5
   Wang D., 2015, ARXIV PREPRINT ARXIV
   Wang H. X., 2015, China Patent, Patent No. [CN104835499A, 104835499]
   [王晓华 Wang Xiaohua], 2020, [西安电子科技大学学报, Journal of Xidian University], V47, P16
   Wu JF, 2018, IEICE T INF SYST, VE101D, P556, DOI 10.1587/transinf.2017EDL8162
   Zhang HM., 2017, J HANGZHOU DIANZI U, V37, P5, DOI [10.13954/j.cnki.hdu.2017.02.002, DOI 10.13954/J.CNKI.HDU.2017.02.002]
   Zhang KJ, 2016, 2016 INTERNATIONAL CONFERENCE ON NETWORK AND INFORMATION SYSTEMS FOR COMPUTERS (ICNISC), P274, DOI 10.1109/ICNISC.2016.66
   Zhang Q.Y., 2018, J INF HIDING MULTIME, V9, P1452
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P6337, DOI 10.1007/s11042-019-08450-y
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   [张秋余 Zhang Qiuyu], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P77
   Zhang ZT, 2018, THESIS CHONGQING U C
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
   Zhong SM., 2019, J S CHINE NORMAL NAT, V51, P118, DOI [10.6054/j.jscnun.2019111, DOI 10.6054/J.JSCNUN.2019111]
NR 28
TC 4
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15127
EP 15151
DI 10.1007/s11042-022-12560-5
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000769532100001
DA 2024-07-18
ER

PT J
AU Nira
   Kumar, H
AF Nira
   Kumar, Harekrishna
TI Epidemiological Mucormycosis treatment and diagnosis challenges using
   the adaptive properties of computer vision techniques based approach: a
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Mucormycosis; Computer vision; Black fungus; Artificial intelligence;
   Deep learning
ID X-RAY; SEGMENTATION; SYSTEM; REGISTRATION; COVID-19
AB As everyone knows that in today's time Artificial Intelligence, Machine Learning and Deep Learning are being used extensively and generally researchers are thinking of using them everywhere. At the same time, we are also seeing that the second wave of corona has wreaked havoc in India. More than 4 lakh cases are coming in 24 h. In the meantime, news came that a new deadly fungus has come, which doctors have named Mucormycosis (Black fungus). This fungus also spread rapidly in many states, due to which states have declared this disease as an epidemic. It has become very important to find a cure for this life-threatening fungus by taking the help of our today's devices and technology such as artificial intelligence, data learning. It was found that the CT-Scan has much more adequate information and delivers greater evaluation validity than the chest X-Ray. After that the steps of Image processing such as pre-processing, segmentation, all these were surveyed in which it was found that accuracy score for the deep features retrieved from the ResNet50 model and SVM classifier using the Linear kernel function was 94.7%, which was the highest of all the findings. Also studied about Deep Belief Network (DBN) that how easy it can be to diagnose a life-threatening infection like fungus. Then a survey explained how computer vision helped in the corona era, in the same way it would help in epidemics like Mucormycosis.
C1 [Nira; Kumar, Harekrishna] GLA Univ, Dept Elect & Commun, Mathura 281406, India.
C3 GLA University
RP Kumar, H (corresponding author), GLA Univ, Dept Elect & Commun, Mathura 281406, India.
EM harekrishnabgp@gmail.com
OI kumar, Harekrishna/0000-0002-2098-4196
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abd Elaziz M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0244416
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Acharjya P.P., 2012, Global Journal of Computer Science and Technology
   Adil A., 2021, Over 28,200 'Black Fungus' Cases Recorded in India
   Akbari Y, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11178039
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Al-Tawfiq JA, 2021, INFECTION, V49, P833, DOI 10.1007/s15010-021-01670-1
   Alekseyev Kirill, 2021, J Med Cases, V12, P85, DOI 10.14740/jmc3637
   Andreu-Perez J, 2021, IEEE Transactions on Services Computing
   Asnaoui K. E., 2003, ARXIV PREPRINT ARXIV, P14363
   Barstugan M, 2020, ARXIV200309424
   Bhargava A, 2021, MULTIMED TOOLS APPL, V80, P19931, DOI 10.1007/s11042-021-10714-5
   Blank R, 2016, IEEE SENS J, V16, P5596, DOI 10.1109/JSEN.2016.2567538
   Cao JW, 2021, IEEE IMAGE PROC, P205, DOI 10.1109/ICIP42928.2021.9506553
   Castiglione A, 2021, IEEE T IND INFORM, V17, P6480, DOI 10.1109/TII.2021.3057524
   Chakraborty S, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102800
   Chang VC, 2021, IEEE T IND INFORM, V17, P6476, DOI 10.1109/TII.2021.3067670
   Chen G, 2019, IEEE T MED IMAGING, V38, P1736, DOI 10.1109/TMI.2018.2890510
   Chen JH, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-70879-1
   Chen R, 2020, CAN J ANESTH, V67, P754, DOI 10.1007/s12630-020-01625-4
   Chen T, 2014, LECT NOTES COMPUT SC, V8679, P17, DOI 10.1007/978-3-319-10581-9_3
   Chuanqi Tan, 2018, Artificial Neural Networks and Machine Learning - ICANN 2018. 27th International Conference on Artificial Neural Networks. Proceedings: Lecture Notes in Computer Science (LNCS 11141), P270, DOI 10.1007/978-3-030-01424-7_27
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cosic I, 2015, IEEE T NANOBIOSCI, V14, P491, DOI 10.1109/TNB.2014.2365851
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Dai X., 2020, MATH PROBL ENG, V2020, P1
   Dantas KC, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-83587-1
   Dev Chethan, 2019, Ambient Communications and Computer Systems. RACCCS-2018. Advances in Intelligent Systems and Computing (AISC 904), P161, DOI 10.1007/978-981-13-5934-7_15
   Elbossaty W.F., 2021, CLIN ONCO, V5, P1
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Ghoshal B., 2020, ARXIV200310769
   Gozes O., 2020, RAPID AI DEV CYCLE C
   Gupta Brij Mohan, 2021, International Journal of Medicine and Public Health, V11, P133, DOI 10.5530/ijmedph.2021.3.24
   Han C, 2019, INT CONF 3D VISION, P729, DOI 10.1109/3DV.2019.00085
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Imteaj A, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, COMPUTER AND COMMUNICATION ENGINEERING (ECCE), P899, DOI 10.1109/ECACE.2017.7913031
   Ismael AM, 2021, EXPERT SYST APPL, V164, DOI 10.1016/j.eswa.2020.114054
   Jian Z, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 5, P264, DOI 10.1109/ICACC.2010.5487242
   Jin S., 2020, medRxiv
   Kassani SH, 2021, BIOCYBERN BIOMED ENG, V41, P867, DOI 10.1016/j.bbe.2021.05.013
   Khan ZU, 2000, J CLIN MICROBIOL, V38, P2010, DOI 10.1128/JCM.38.5.2010-2014.2000
   Kim W, 2013, IEEE T IMAGE PROCESS, V22, P1665, DOI 10.1109/TIP.2012.2231689
   Koley Subha, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P671, DOI 10.1109/ISVLSI.2017.122
   Kumar H, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621501061
   Kuo JW, 2016, IEEE T MED IMAGING, V35, P427, DOI 10.1109/TMI.2015.2477395
   Lessmann N, 2018, IEEE T MED IMAGING, V37, P615, DOI 10.1109/TMI.2017.2769839
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahalaxmi I, 2021, ENVIRON RES, V201, DOI 10.1016/j.envres.2021.111643
   Mahalaxmi I, 2021, J CELL PHYSIOL, V236, P763, DOI 10.1002/jcp.29937
   Maini A, 2021, INT J SURG CASE REP, V82, DOI 10.1016/j.ijscr.2021.105957
   Medeiros AG, 2019, MEASUREMENT, V148, DOI 10.1016/j.measurement.2019.05.078
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   O'Connor P, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00178
   Pardeshi V, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIVE MECHANISMS FOR INDUSTRY APPLICATIONS (ICIMIA), P134, DOI 10.1109/ICIMIA.2017.7975587
   Pauraj T, 2019, INT J IMAG SYST TECH, V29, P374, DOI 10.1002/ima.22340
   Prakash H, 2021, J FUNGI, V7, DOI 10.3390/jof7080616
   Pujari J.D., 2013, International Journal of Signal Processing, Image Processing and Pattern Recognition, V6, P321
   Raza AF, 2021, EUR ARCH OTO-RHINO-L, P1
   Ribbens A, 2014, IEEE T MED IMAGING, V33, P201, DOI 10.1109/TMI.2013.2270114
   Shakeel PM, 2019, MEASUREMENT, V145, P702, DOI 10.1016/j.measurement.2019.05.027
   Shariati A, 2020, INFECT DRUG RESIST, V13, P2329, DOI 10.2147/IDR.S254478
   Sharma S, 2021, J LARYNGOL OTOL, V135, P442, DOI 10.1017/S0022215121000992
   Shi F, 2021, IEEE REV BIOMED ENG, V14, P4, DOI 10.1109/RBME.2020.2987975
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shrestha A, 2019, IEEE ACCESS, V7, P53040, DOI 10.1109/ACCESS.2019.2912200
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh AK, 2021, DIABETES METAB SYND, V15, DOI 10.1016/j.dsx.2021.05.019
   Slavin M., 2021, BBC
   Song Y, 2020, GUT, V69, P1143, DOI 10.1136/gutjnl-2020-320891
   Song Y, 2021, IEEE ACM T COMPUT BI, V18, P2775, DOI 10.1109/TCBB.2021.3065361
   Song YY, 2014, IEEE ENG MED BIO, P2903, DOI 10.1109/EMBC.2014.6944230
   Swierczynski P, 2018, COMPUT MED IMAG GRAP, V65, P58, DOI 10.1016/j.compmedimag.2017.06.003
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tahir MW, 2017, IEEE SENS J, V17, P5341, DOI 10.1109/JSEN.2017.2723052
   Tang SJ, 2021, IEEE T IND INFORM, V17, P6539, DOI 10.1109/TII.2021.3057683
   Tang ZY, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abbf9e
   Vellingiri B, 2020, SCI TOTAL ENVIRON, V725, DOI 10.1016/j.scitotenv.2020.138277
   Vishnupriya M, 2021, EUR REV MED PHARMACO, V25, P2748, DOI 10.26355/eurrev_202103_25438
   Wang EK, 2020, FUTURE GENER COMP SY, V108, P135, DOI 10.1016/j.future.2020.02.054
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Xie WD, 2018, COMP M BIO BIO E-IV, V6, P283, DOI 10.1080/21681163.2016.1149104
   Xu XW, 2020, ENGINEERING-PRC, V6, P1122, DOI 10.1016/j.eng.2020.04.010
   Yao QS, 2021, IEEE T MED IMAGING, V40, P2808, DOI 10.1109/TMI.2021.3066161
   Ye CQ, 2019, IEEE ACCESS, V7, P23421, DOI 10.1109/ACCESS.2019.2899635
   Zhang JQ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2831, DOI 10.1145/3394486.3403334
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zheng CM, 2021, IEEE T MULTIMEDIA, V23, P2520, DOI 10.1109/TMM.2020.3013398
NR 94
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14217
EP 14245
DI 10.1007/s11042-022-12450-w
EA FEB 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761886300001
PM 35233180
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Huang, YB
   Wang, Y
   Li, H
   Zhang, Y
   Zhang, QY
AF Huang, Yi-bo
   Wang, Yong
   Li, Hao
   Zhang, Yuan
   Zhang, Qiu-yu
TI Encrypted speech retrieval based on long sequence Biohashing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Biometric template; Long sequence;
   Biohashing; Improved SHA256; Content preservation operation
ID PHASE RETRIEVAL; ALGORITHM; AUDIO; TRANSFORM; RECOVERY
AB This paper proposes a Encrypted speech retrieval based on long sequence Biohashing to solve the problem of plaintext data leakage in the existing speech retrieval system, and improve the efficiency and accuracy of speech retrieval, the diversity and revocability of biometric template. According to speech feature classification, a biometric template with a single mapping key is established, and then the feature vector is used to generate speech feature index, and the speech file is encrypted by the improved SHA256 algorithm, and finally, feature index and encrypted speech are sent to the cloud. For the input speech, the feature vector is generated at the mobile, and then the cloud will retrieve the feature vector table according to the feature vector to obtain the feature index of the speech, and finally, the feature index only matches the feature index related to the speech in the feature index table. Experimental results show that this algorithm can not only effectively prevent the leakage of plaintext, but also has good diversity and revocability of biometric template. At the same time, the algorithm not only has good efficiency and accuracy, but also solves the problem of speech retrieval after content preservation operation.
C1 [Huang, Yi-bo; Wang, Yong; Li, Hao; Zhang, Yuan] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
   [Zhang, Qiu-yu] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
C3 Northwest Normal University - China; Lanzhou University of Technology
RP Huang, YB (corresponding author), Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
EM huang_yibo@foxmail.com; 15737315638@163.com; lhnwnu@163.com;
   1243169384@qq.com; zhangqylz@163.com
RI Yong, Wang/AAW-8984-2020; zhang, qiu/GXG-5600-2022
OI Yong, Wang/0000-0002-8326-2924; /0000-0003-1667-3114
FU National Natural Science Foundation of China [61862041]; Science and
   Technology Program of Gansu Province [21JR7RA120]
FX This work is supported by the National Natural Science Foundation of
   China(No.61862041), Science and Technology Program of Gansu Province
   (No. 21JR7RA120).
CR Banawan K, 2018, IEEE T INFORM THEORY, V64, P1945, DOI 10.1109/TIT.2018.2791994
   Chai XL, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107525
   Chen L, 2017, IEEE T INTELL TRANSP, V18, P3303, DOI 10.1109/TITS.2017.2683641
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Descloux A, 2018, NAT PHOTONICS, V12, P165, DOI 10.1038/s41566-018-0109-4
   Du L, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115713
   Elizalde B, 2019, INT CONF ACOUST SPEE, P4095, DOI 10.1109/ICASSP.2019.8682632
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Hu PF, 2014, PATTERN RECOGN, V47, P1138, DOI 10.1016/j.patcog.2013.06.010
   Jaganathan K, 2017, IEEE T SIGNAL PROCES, V65, P2402, DOI 10.1109/TSP.2017.2656844
   Jati A, 2020, INT CONF ACOUST SPEE, P4497, DOI [10.1109/ICASSP40776.2020.9053766, 10.1109/icassp40776.2020.9053766]
   Jiang Q, 2018, J AMB INTEL HUM COMP, V9, P1061, DOI 10.1007/s12652-017-0516-2
   Karst SM, 2018, NAT BIOTECHNOL, V36, P190, DOI 10.1038/nbt.4045
   Krivokuca V, 2020, ADV COMPUT VIS PATT, P465, DOI 10.1007/978-3-030-27731-4_15
   Li D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-017-18566-6
   Li L, 2017, IEEE SIGNAL PROC LET, V24, P372, DOI 10.1109/LSP.2017.2663668
   Myers CJ, 2015, NAT NANOTECHNOL, V10, P886, DOI [10.1038/NNANO.2015.173, 10.1038/nnano.2015.173]
   Pancoast S, 2016, INTERSPEECH, P3071, DOI 10.21437/Interspeech.2016-1589
   Pedarsani R, 2017, IEEE T INFORM THEORY, V63, P3663, DOI 10.1109/TIT.2017.2693287
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Shen Q, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107244
   Tasaki H, 2017, INTERSPEECH, P2894, DOI 10.21437/Interspeech.2017-893
   Waldspurger I, 2017, IEEE T INFORM THEORY, V63, P2993, DOI 10.1109/TIT.2017.2672727
   Wallnöfer J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-36543-5
   Wang HX, 2013, LNCS, P423, DOI DOI 10.1007/978-3-662-43886-2_3
   [毋立芳 Wu Lifang], 2016, [仪器仪表学报, Chinese Journal of Scientific Instrument], V37, P2407
   Yang YG, 2016, SCI REP-UK, V6, DOI 10.1038/srep19788
   Yao SS, 2015, IEEE T MULTIMEDIA, V17, P1450, DOI 10.1109/TMM.2015.2460121
   Yibo Huang, 2019, 2019 3rd International Conference on Electronic Information Technology and Computer Engineering (EITCE). Proceedings, P243, DOI 10.1109/EITCE47263.2019.9094822
   Yu Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3281746
   Zhang FC, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13367
   Zhang Q.Y., 2018, J INF HIDING MULTIME, V9, P1452
   Zhang QY, 2020, MULTIMED TOOLS APPL, V79, P6337, DOI 10.1007/s11042-019-08450-y
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   Zhang QY, 2019, TURK J ELECTR ENG CO, V27, P1719, DOI 10.3906/elk-1808-161
   Zhang XM, 2018, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: IOT AND SMART CITY (ICIT 2018), P110, DOI 10.1145/3301551.3301600
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
NR 37
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 13065
EP 13085
DI 10.1007/s11042-022-12371-8
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000760059700006
DA 2024-07-18
ER

PT J
AU Niu, YH
   Shen, SY
AF Niu, Yuhang
   Shen, Shuyuan
TI A novel pixel value ordering reversible data hiding based on dual-image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Pixel-value-ordering; Dual-image; High capacity
ID SCHEME; WATERMARKING
AB Recently, reversible data hiding (RDH) based on pixel value order (PVO) has been an important research direction in the field of information security due to its high-fidelity characteristics. However, PVO-based schemes have low embedding capacities (EC) because the pixels whose prediction-error greater than 1 or less than -1 on the histogram just shifted but not selected for embedding data. Dual-image techniques have often been used in recent years. In this paper, we use dual-image to design a new shift strategy that allows secret data to be embedded in those pixels only shifted in PVO-based schemes previously to improve the EC. The number of secret message bits for each embedding is fixed in most dual-image RDH methods, which leads to image redundancy not be fully exploited. In the proposed method, the number of embedded bits changes dynamically according to the prediction-error so that the visual quality of the stego images is better. Experimental results verify that the proposed method is superior to some other state-of-the-art PVO-based and dual-image RDH methods.
C1 [Niu, Yuhang; Shen, Shuyuan] South China Normal Univ, Sch Software, Foshan 528225, Peoples R China.
C3 South China Normal University
RP Shen, SY (corresponding author), South China Normal Univ, Sch Software, Foshan 528225, Peoples R China.
EM connerniu@m.scnu.edu.cn; ssyuan16@m.scnu.edu.cn
FU Fund of Basic and Applied Basic Research [2020B1515120089,
   2021A1515011171]
FX This work was supported by the Fund of Basic and Applied Basic Research
   (Grant No.2020B1515120089 and 2021A1515011171) of Guangdong Province.
CR Chang T. Duc, 2007, P IEEE REG 10 C NOV, P1, DOI [10.1109/TENCON.2007.4483783, DOI 10.1109/TENCON.2007.4483783]
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Chowdhuri P, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102420
   Dong L, 2020, IEEE T CIRCUITS-II, V67, P951, DOI 10.1109/TCSII.2020.2981550
   Fridrich J, 2001, P SOC PHOTO-OPT INS, V4314, P197, DOI 10.1117/12.435400
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kim PH, 2020, INT J DISTRIB SENS N, V16, DOI 10.1177/1550147720911006
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Lin JY, 2019, MULTIMED TOOLS APPL, V78, P25855, DOI 10.1007/s11042-019-07783-y
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2014, SIGNAL PROCESS-IMAGE, V29, P760, DOI 10.1016/j.image.2014.05.003
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2016, SIGNAL PROCESS, V129, P48, DOI 10.1016/j.sigpro.2016.05.032
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qu X, 2015, SIGNAL PROCESS, V111, P249, DOI 10.1016/j.sigpro.2015.01.002
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Sun YX, 2020, MULTIMED TOOLS APPL, V79, P27659, DOI 10.1007/s11042-020-08626-x
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wan WB, 2020, IEEE ACCESS, V8, P164504, DOI 10.1109/ACCESS.2020.3022652
   Wan WB, 2020, PATTERN RECOGN LETT, V130, P157, DOI 10.1016/j.patrec.2018.08.009
   Wang X, 2015, INFORM SCIENCES, V310, P16, DOI 10.1016/j.ins.2015.03.022
   Wang YG, 2021, IEEE T CIRC SYST VID, V31, P76, DOI 10.1109/TCSVT.2020.2971590
   Wang YG, 2018, IEEE T IMAGE PROCESS, V27, P2063, DOI 10.1109/TIP.2018.2795745
   Wu HR, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107264
   Xiang LY, 2019, INT J COMPUT SCI ENG, V19, P132
   Xiang LY, 2018, CMC-COMPUT MATER CON, V55, P541, DOI 10.3970/cmc.2018.03510
   Yang ZL, 2021, IEEE T INF FOREN SEC, V16, P880, DOI 10.1109/TIFS.2020.3023279
   Yao H, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0281-y
   Yu H, 2020, IEEE ACCESS, V8, P162271, DOI 10.1109/ACCESS.2020.3015851
   Zhang XY, 2020, IEEE ACCESS, V8, P61754, DOI 10.1109/ACCESS.2020.2983869
NR 34
TC 2
Z9 2
U1 4
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13751
EP 13771
DI 10.1007/s11042-022-12149-y
EA FEB 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000760059700002
DA 2024-07-18
ER

PT J
AU Xie, SP
   Song, ZR
AF Xie, Shipeng
   Song, Zhenrong
TI Metal artifact correction in head computed tomography based on a
   homographic adaptation convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Metal artifact; Convolution network; Data misalignment; Contextual loss
ID REDUCTION; CT; RECONSTRUCTION; SEGMENTATION
AB In dental treatment, an increasing number of patients choose metal-implant surgery to treat oral conditions. Computed tomography (CT) images of patients with implanted foreign bodies such as dentures and metal clips are difficult to interpret correctly owing to the presence of high-density metal artifacts. In severe cases, these artifacts may even lead to misdiagnosis, potentially affecting subsequent treatment. Therefore, metal artifact reduction remains an important concern. We propose a novel homographic adaptation convolutional neural network (HACNN) algorithm to solve the problem of metal artifacts in the mouth in head CT. In an experiment, we use a 17-layer CNN as a framework for deep learning, in conjunction with the VGG19 network, to extract the features of CT images, including the original CT, reference CT, and CT images processed by the CNN network. Then, to solve the problem of data misalignment, the improved contextual loss is used as the loss function in the network, and the parameters are adjusted to produce the best results. In contrast to the results of similar experiments, the metal artifacts were removed, details of the CT image were well conserved, and generation of new artifacts was avoided without introducing image blurring.
C1 [Xie, Shipeng; Song, Zhenrong] Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Xie, SP (corresponding author), Nanjing Univ Posts & Telecommun, Coll Telecommun & Informat Engn, Nanjing 210003, Jiangsu, Peoples R China.
EM xie@njupt.edu.cn
FU University Natural Science Research Project of Jiangsu Province
   [17KJB510038]; Primary Research & Development Plan of Jiangsu Province
   [BE217616]; NUPTSF [NY219043]
FX The authors are very grateful to the anonymous reviewers for their
   constructive comments and unique evaluations, which have considerably
   improved the way our research is presented. We will also endeavor to
   make the work available to everyone. We also thank those who have helped
   and supported us, in particular Jay K. Udupa and Yubing Tong, who
   provided data and advice. This work was supported by the University
   Natural Science Research Project of Jiangsu Province (Grant No.
   17KJB510038), the Primary Research & Development Plan of Jiangsu
   Province (Grant No. BE217616), and NUPTSF (Grant No. NY219043).
CR Antholzer S, 2019, INVERSE PROBL SCI EN, V27, P987, DOI 10.1080/17415977.2018.1518444
   Bamberg F, 2011, EUR RADIOL, V21, P1424, DOI 10.1007/s00330-011-2062-1
   Boas FE, 2011, RADIOLOGY, V259, P894, DOI 10.1148/radiol.11101782
   Chen ZQ, 2013, PHYS MED BIOL, V58, P2119, DOI 10.1088/0031-9155/58/7/2119
   De Man B, 1999, IEEE T NUCL SCI, V46, P691, DOI 10.1109/23.775600
   Dehmeshki J, 2007, IEEE T MED IMAGING, V26, P273, DOI 10.1109/TMI.2007.893344
   Geraily G, 2014, INT J RADIAT RES, V12, P249
   Ghani MU, 2020, IEEE T COMPUT IMAG, V6, P181, DOI 10.1109/TCI.2019.2937221
   Gjesteby L, 2017, PROC SPIE, V10391, DOI 10.1117/12.2274427
   Gjesteby L, 2017, PROC SPIE, V10132, DOI 10.1117/12.2254091
   Gjesteby Lars., 2017, The 14th International Meeting on Fully Three-Dimensional Image Reconstruction in Radiology and Nuclear Medicine, P611
   Goodfellow I, 2014, NEURIPS, V2014, P2672
   Han Y, 2018, IEEE T MED IMAGING, V37, P1418, DOI 10.1109/TMI.2018.2823768
   Han YS, 2016, ARXIVCORRABS16110639
   Hongli G, 2015, J CLIN RADIOL, V34, P706
   Huang X, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0609-y
   JENNINGS RJ, 1988, MED PHYS, V15, P588, DOI 10.1118/1.596210
   KALENDER WA, 1987, RADIOLOGY, V164, P576, DOI 10.1148/radiology.164.2.3602406
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Lee H, 2019, IEEE T RADIAT PLASMA, V3, P109, DOI 10.1109/TRPMS.2018.2867611
   Lell MM, 2013, EUR RADIOL, V23, P2137, DOI 10.1007/s00330-013-2809-y
   Liao HF, 2020, IEEE T MED IMAGING, V39, P634, DOI 10.1109/TMI.2019.2933425
   Mechrez R, 2018, LECT NOTES COMPUT SC, V11218, P800, DOI 10.1007/978-3-030-01264-9_47
   Mechrez Roey, 2018, ARXIV PREPRINT ARXIV
   Mehranian A, 2013, IEEE T MED IMAGING, V32, P1707, DOI 10.1109/TMI.2013.2265136
   Meinhardt T, 2017, IEEE I CONF COMP VIS, P1799, DOI 10.1109/ICCV.2017.198
   Meyer E, 2012, MED PHYS, V39, P1904, DOI 10.1118/1.3691902
   Meyer E, 2010, MED PHYS, V37, P5482, DOI 10.1118/1.3484090
   Park HS, 2018, MED PHYS, V45, P5376, DOI 10.1002/mp.13199
   Park HS, 2016, IEEE T MED IMAGING, V35, P480, DOI 10.1109/TMI.2015.2478905
   Roeske John C, 2003, Brachytherapy, V2, P207, DOI 10.1016/j.brachy.2003.08.001
   Sakamoto M, 2019, ARXIV190611484
   Schmidt Bernhard, 2003, Z Med Phys, V13, P30
   Schüller S, 2015, MED PHYS, V42, P794, DOI 10.1118/1.4903281
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stayman JW, 2012, IEEE T MED IMAGING, V31, P1837, DOI 10.1109/TMI.2012.2199763
   Stille M, 2016, IEEE T MED IMAGING, V35, P158, DOI 10.1109/TMI.2015.2459764
   Veldkamp WJH, 2010, MED PHYS, V37, P620, DOI 10.1118/1.3276777
   Wang JN, 2018, LECT NOTES COMPUT SC, V11070, P3, DOI 10.1007/978-3-030-00928-1_1
   Xie SP, 2018, IEEE ACCESS, V6, P78031, DOI 10.1109/ACCESS.2018.2884704
   Xu S, 2018, PROGR BIOMEDICAL OPT, V10573
   Yasaka K, 2016, JPN J RADIOL, V34, P625, DOI 10.1007/s11604-016-0566-y
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang XM, 2011, MED PHYS, V38, P701, DOI 10.1118/1.3533711
   Zhang YB, 2018, IEEE T MED IMAGING, V37, P1370, DOI 10.1109/TMI.2018.2823083
NR 46
TC 0
Z9 1
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 13045
EP 13064
DI 10.1007/s11042-022-12194-7
EA FEB 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000760059700010
DA 2024-07-18
ER

PT J
AU Liang, C
   Lao, H
   Wei, T
   Zhang, XJ
AF Liang, Chan
   Lao, Huan
   Wei, Tao
   Zhang, Xuejun
TI Alzheimer's disease classification from hippocampal atrophy based on
   PCANet-BLS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease (AD); Hippocampal atrophy; Magnetic resonance
   images; PCANet; Broad learning system (BLS); Computer-aided diagnosis
ID MILD COGNITIVE IMPAIRMENT
AB Alzheimer's Disease (AD) is a neurodegenerative disease of unknown etiology that progresses progressively and is currently incurable. It is more common in the elderly that seriously affects the physical and mental health of patients, thus early detection is very important for the prevention of AD progression. By using PCANet and Broad Learning System (BLS), we propose a novel method to identify Alzheimer's patients according to the clinical symptom of hippocampal atrophy, which is the most important indicator of AD. T1-weighted magnetic resonance images (MRIs) are used in this study, containing 207 patients with AD, 209 patients with mild cognitive impairment (MCI) and 109 cognitively normal (CN) cohorts from ADNI dataset. The left and right hippocampus are segmented from MRI at the first step, then the PACNet is applied to extract features from these images, finally the BLS is used to distinguish the different types of patients. Compared with the traditional machine learning methods, PCANet is able to extract the most informative features inside pictures effectively, while BLS can reach over 95% accuracy rate with lower time consuming. Experimental results have revealed that our method improves the performance of computer-aided diagnosis of Alzheimer's disease in both accuracy and speed of classification task.
C1 [Liang, Chan; Wei, Tao; Zhang, Xuejun] Guangxi Univ, Sch Comp & Elect Informat, Nanning, Guangxi, Peoples R China.
   [Lao, Huan; Zhang, Xuejun] Guangxi Univ, Coll Med, Nanning, Guangxi, Peoples R China.
   [Zhang, Xuejun] Guangxi Key Lab Multimedia Commun & Network Techn, Nanning, Guangxi, Peoples R China.
C3 Guangxi University; Guangxi University
RP Zhang, XJ (corresponding author), Guangxi Univ, Sch Comp & Elect Informat, Nanning, Guangxi, Peoples R China.; Zhang, XJ (corresponding author), Guangxi Univ, Coll Med, Nanning, Guangxi, Peoples R China.; Zhang, XJ (corresponding author), Guangxi Key Lab Multimedia Commun & Network Techn, Nanning, Guangxi, Peoples R China.
EM xjzhang@gxu.edu.cn
RI Lao, Huan/KHU-2758-2024; tao, wei/GXN-4445-2022
FU Science and Technology Key Projects of Guangxi Province [2020AA21077007,
   2021JJYGD170060]; Innovation Project of Guangxi Graduate Education
   [YCSW2020064]
FX This work was supported by the Science and Technology Key Projects of
   Guangxi Province (Grant No.2020AA21077007 and 2021JJYGD170060); and the
   Innovation Project of Guangxi Graduate Education (Grant No.
   YCSW2020064).
CR Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   Aly S, 2019, IEEE ACCESS, V7, P52024, DOI 10.1109/ACCESS.2019.2911851
   Andres O, 2017, CURR ALZHMER RES, V14
   Balthazar MLF, 2009, EUR J NEUROL, V16, P468, DOI 10.1111/j.1468-1331.2008.02408.x
   Ben Ahmed O, 2015, MULTIMED TOOLS APPL, V74, P1249, DOI 10.1007/s11042-014-2123-y
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen CLP, 2018, IEEE T NEUR NET LEAR, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Chetelat G, 2003, NEUROIMAGE, V18, P525, DOI 10.1016/S1053-8119(02)00026-5
   Chételat G, 2002, NEUROREPORT, V13, P1939
   Ebrahim D, 2020, 2020 15 INT C COMP E
   Farooq A, 2017, IEEE CONF IMAGING SY, P111
   Feng W, 2020, INT J NEURAL SYST, V30, DOI 10.1142/S012906572050032X
   Frings L, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090814
   Gao XHW, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P28, DOI 10.1109/SAI.2016.7555958
   Grabner G, 2006, LECT NOTES COMPUT SC, V4191, P58
   Huang J, 2015, EFFECTS MECH ELECT S
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Karow DS, 2010, RADIOLOGY, V256, P932, DOI 10.1148/radiol.10091402
   Longhe Z., 2020, ALZHEIMERS DEMENT, V16
   Lu DH, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-22871-z
   Migliaccio Raffaella, 2012, Alzheimers Dement, V8, pS78, DOI 10.1016/j.jalz.2012.04.010
   Morabito FC, 2016, 2016 IEEE 2ND INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGIES FOR SOCIETY AND INDUSTRY LEVERAGING A BETTER TOMORROW (RTSI), P162
   Morris JC, 2001, ARCH NEUROL-CHICAGO, V58, P397, DOI 10.1001/archneur.58.3.397
   O'Hanlon E, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00755
   Raza M, 2019, EXPERT SYST APPL, V136, P353, DOI 10.1016/j.eswa.2019.06.038
   Sarraf S.Tofighi., 2016, Classification of alzheimer's disease using fmri data and deep learning convolutional neural networks
   Shi J, 2017, IEEE J BIOMED HEALTH, V21, P1327, DOI 10.1109/JBHI.2016.2602823
   Tripoliti EE, 2008, ARGYROPOULOU M SUPER
   Tzourio-Mazoyer N, 2002, NEUROIMAGE, V15, P273, DOI 10.1006/nimg.2001.0978
   Ward A, 2013, DEMENT GER COGN D EX, V3, P320, DOI 10.1159/000354370
   Wilson RS, 2012, PSYCHOL AGING, V27, P1008, DOI 10.1037/a0029857
NR 31
TC 4
Z9 4
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11187
EP 11203
DI 10.1007/s11042-022-12228-0
EA FEB 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400002
DA 2024-07-18
ER

PT J
AU Shukla, A
   Singh, D
   Sajwan, M
   Kumar, M
   Kumari, D
   Kumar, A
   Panthi, M
AF Shukla, Anurag
   Singh, Deepak
   Sajwan, Mohit
   Kumar, Malay
   Kumari, Divya
   Kumar, Ajit
   Panthi, Manikant
TI SLP-RRFPR: a source location privacy protection scheme based on random
   ring and limited hop fake packet routing for wireless sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network; Source location privacy (SLP); Source location
   protection protocol based on dynamic routing (SLPDR); Animal monitoring;
   Border surveillance; Source node; Event packet; SLP-RRFPR
ID ENERGY-EFFICIENT; WSNS; ALGORITHM; INTERNET
AB In recent times, the wireless sensor network (WSN) has become an integral part of daily life. WSN forms the necessary foundation for several important applications such as animal monitoring, border surveillance, asset monitoring, etc. These applications help maintain the confidentiality of the location of the occurring event from the attacker. The properties of the sensor nodes such as limited energy source, communication capability, memory, and network deployment at a large scale make it challenging to maintain the location privacy of a source node. To secure the source node location, this paper presents a source location privacy protection scheme that is based on random rings and a limited hop fake packet routing scheme (SLP-RRFPR). In the proposed scheme, an event packet is forwarded away from the base station by the random routing with confounding transmission to change the attacker's backtracking process. Afterward, it follows the random routing, where the phantom node forwards the fake packet to other randomly selected nodes. In the last phase, a real packet is transmitted at the base station by ring routing. The simulation results of the proposed SLP-RRFPR are compared with phantom, baseline, probabilistic, source location privacy protection scheme based on ring-loop routing (SLPRR), and source location protection protocol based on dynamic routing (SLPDR). The simulation results show that the proposed SLP-RRFPR performs better than the compared protocol for various performance metrics, such as safety time, transmission delay, network lifetime, and randomness in the packet path.
C1 [Shukla, Anurag] Bliss Connect India Pvt Ltd, New Delhi 110032, India.
   [Singh, Deepak] NIT Raipur, Dept Comp Sci, GE Rd, Raipur 492010, Madhya Pradesh, India.
   [Sajwan, Mohit] Bennett Univ, Dept Comp Sci, Greater Noida 201310, India.
   [Kumar, Malay] IIIT Dharwad, Dept Comp Sci, Dharwad 580029, Karnataka, India.
   [Kumari, Divya] Kalinga Inst Ind Technol, Sch Comp Engn, Bhubaneswar 751024, India.
   [Kumar, Ajit] Soongsil Univ, Dept Comp Engn & Applicat, Seoul, South Korea.
   [Panthi, Manikant] NIT Raipur, Dept Comp Applicat, GE Rd, Raipur 492010, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; Kalinga Institute of Industrial Technology (KIIT);
   Soongsil University; National Institute of Technology (NIT System);
   National Institute of Technology Raipur
RP Shukla, A (corresponding author), Bliss Connect India Pvt Ltd, New Delhi 110032, India.
EM anurag672@yahoo.com; dsingh.cs@nitrr.ac.in; mohit.sajwan@gmail.com;
   malay.kumar@iiitdwd.ac.in; divya.nov30@gmail.com; kumar@ssu.ac.kr;
   mani.panthi97@gmail.com
RI Kumar, Malay/KIJ-9427-2024; Shukla, Anurag/AAR-9723-2021
OI Kumar, Malay/0000-0002-9537-8991; Kumari, Divya/0000-0002-7379-2606;
   SAJWAN, MOHIT/0000-0002-3072-6617
CR Adil M, 2022, IEEE INTERNET THINGS, V9, P22173, DOI [10.1109/JIOT.2021.3083731, 10.1109/jiot.2021.3083731]
   Bagree R, 2010, LECT NOTES COMPUT SC, V6511, P13, DOI 10.1007/978-3-642-17520-6_2
   Chen J, 2015, SENSORS-BASEL, V15, P29129, DOI 10.3390/s151129129
   Deng J, 2006, PERVASIVE MOB COMPUT, V2, P159, DOI 10.1016/j.pmcj.2005.12.003
   Dou K, 2019, MULTIMED TOOLS APPL, V78, P26907, DOI 10.1007/s11042-017-4352-3
   Florian M, 2016, AD HOC NETW, V37, P110, DOI 10.1016/j.adhoc.2015.07.015
   Gupta N, 2021, MULTIMED TOOLS APPL, V80, P22301, DOI 10.1007/s11042-021-10820-4
   Han GJ, 2018, IEEE WIREL COMMUN, V25, P84, DOI 10.1109/MWC.2017.1800061
   Han GJ, 2018, FUTURE GENER COMP SY, V82, P689, DOI 10.1016/j.future.2017.08.044
   Hong Z, 2019, IEEE T INF FOREN SEC, V14, P1337, DOI 10.1109/TIFS.2018.2876839
   Jain S, 2021, IEEE INTERNET THINGS, V8, P4882, DOI 10.1109/JIOT.2020.3030120
   Jain S, 2019, J NETW COMPUT APPL, V147, DOI 10.1016/j.jnca.2019.102430
   Jan MA, 2021, IEEE T GREEN COMMUN, V5, P1202, DOI [10.1109/tgcn.2021.3077318, 10.1109/TGCN.2021.3077318]
   Kamat, 2005, ENHANCING SOURCE LOC, P1
   Long J, 2015, J PARALLEL DISTR COM, V81-82, P47, DOI 10.1016/j.jpdc.2015.04.003
   Luo HW, 2021, MULTIMED TOOLS APPL, V80, P21823, DOI 10.1007/s11042-021-10789-0
   Manjula R, 2018, PERVASIVE MOB COMPUT, V44, P58, DOI 10.1016/j.pmcj.2018.01.006
   Misra S, 2010, MULTIMED TOOLS APPL, V47, P121, DOI 10.1007/s11042-009-0410-9
   Mutalemwa LC, 2019, IEEE ACCESS, V7, P140169, DOI 10.1109/ACCESS.2019.2943710
   Mutalemwa LC, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051037
   Mutalemwa LC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072291
   Nadian-Ghomsheh A, 2021, MULTIMED TOOLS APPL, V80, P31357, DOI 10.1007/s11042-021-10563-2
   Naumowicz T, 2010, C LOCAL COMPUT NETW, P882, DOI 10.1109/LCN.2010.5735827
   Ozturk C, 2004, SECOND IEEE WORKSHOP ON SOFTWARE TECHNOLOGIES FOR FUTURE EMBEDDED AND UBIQUITOUS SYSTEMS, PROCEEDINGS, P68, DOI 10.1109/WSTFES.2004.1300417
   Ozturk C., 2004, P 2 ACM WORKSHOP SEC, P88, DOI [10.1145/1029102.1029117, DOI 10.1145/1029102.1029117]
   Raja M, 2018, IETE J RES, V64, P764, DOI 10.1080/03772063.2017.1371652
   Rashwan AM, 2014, IEEE INTERNET THINGS, V1, P399, DOI 10.1109/JIOT.2014.2360217
   Sajwan M, 2018, COMPUT ELECTR ENG, V67, P96, DOI 10.1016/j.compeleceng.2018.03.018
   Sheu JP, 2008, IEEE ICC, P2728, DOI 10.1109/ICC.2008.515
   Shukla A, 2020, WIREL NETW, V26, P3471, DOI 10.1007/s11276-020-02277-4
   Shukla A, 2020, WIRELESS PERS COMMUN, V112, P2611, DOI 10.1007/s11277-020-07167-8
   Shukla A, 2018, J INTELL FUZZY SYST, V35, P1301, DOI 10.3233/JIFS-169674
   Singh A, 2020, AD HOC NETW, V107, DOI 10.1016/j.adhoc.2020.102182
   Sun Z, 2011, AD HOC NETW, V9, P468, DOI 10.1016/j.adhoc.2010.09.008
   Thirukrishna JT, 2018, FUTURE GENER COMP SY, V81, P331, DOI 10.1016/j.future.2017.11.042
   Wang H, 2019, COMPUT NETW, V148, P142, DOI 10.1016/j.comnet.2018.11.005
   Wang J, 2020, CMC-COMPUT MATER CON, V62, P695, DOI 10.32604/cmc.2020.08674
   Wang J, 2019, HUM-CENTRIC COMPUT I, V9, DOI 10.1186/s13673-019-0179-4
   Wang J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071494
   Wang J, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/9472075
   Wang J, 2018, CMC-COMPUT MATER CON, V56, P433, DOI 10.3970/cmc.2018.04132
   Xu WT, 2020, AD HOC NETW, V102, DOI 10.1016/j.adhoc.2020.102115
NR 42
TC 6
Z9 6
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11145
EP 11185
DI 10.1007/s11042-022-12157-y
EA FEB 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000757168400005
DA 2024-07-18
ER

PT J
AU Maalej, R
   Kherallah, M
AF Maalej, Rania
   Kherallah, Monji
TI New MDLSTM-based designs with data augmentation for offline Arabic
   handwriting recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data augmentation; MDLSTM; Dropout; ReLU; Maxout; Offline arabic
   handwriting recognition
ID NEURAL-NETWORKS; DROPOUT
AB Although deep learning techniques have achieved promising results in several fields including healthcare, monitoring, and smart cities, their application in handwriting recognition shows limited results, especially for the offline Arabic handwritten script. Therefore, there is a need to enhance existing deep learning architectures. Moreover, the Multi-Dimensional Long Short-Term Memory (MDLSTM) leverages the LSTM model by replacing the single recurring connection with as many connections as there are spatiotemporal dimensions in the data. These connections allow the network to create a flexible internal context representation that is robust to local distortions. In this context, MDLSTM based architecture has been explored and three new architectures with Dropout, ReLU, and Maxout are proposed for offline Arabic handwriting recognition. Moreover, data augmentation approach has been applied to validate the proposed models. Indeed, a new dataset is developed by some morphological operations applied to the existing dataset "IFN/ENIT". The experimental results show that our models outperform existing ones and the best accuracy of 92.59% was recorded with the MDLSTM-CTC-Maxout model trained with the original IFN/ENIT dataset. Moreover, data augmentation improves the MDLSTM-CTC-Maxout proposed model's accuracy to reach 93.46%.
C1 [Maalej, Rania] Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
   [Kherallah, Monji] Univ Sfax, Fac Sci, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Faculty of Sciences Sfax
RP Maalej, R (corresponding author), Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
EM rania.mlj@gmail.com; monji.kherallah@fss.usf.tn
RI MAALEJ, Rania/AAF-6695-2019
OI MAALEJ, Rania/0000-0003-1657-3324
CR Ahmad R, 2016, INT CONF FRONT HAND, P453, DOI [10.1109/ICFHR.2016.70, 10.1109/ICFHR.2016.0090]
   Altwaijry N, 2021, NEURAL COMPUT APPL, V33, P2249, DOI 10.1007/s00521-020-05070-8
   Amrouch M, 2018, LECT NOTES COMPUT SC, V10884, P265, DOI 10.1007/978-3-319-94211-7_29
   [Anonymous], 2013, ICML
   [Anonymous], 2012, Guide to OCR for Arabic Scripts
   [Anonymous], 2002, PRIK CIFED
   [Anonymous], 2017, PROC INT C ADV INF S
   Bluche T, 2017, PROC INT CONF DOC, P1050, DOI 10.1109/ICDAR.2017.174
   Cai M, 2016, SPEECH COMMUN, V77, P53, DOI 10.1016/j.specom.2015.12.003
   Cheng GF, 2017, INTERSPEECH, P1586, DOI 10.21437/Interspeech.2017-129
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   El Abed H, 2011, INT J DOC ANAL RECOG, V14, P3, DOI 10.1007/s10032-010-0117-5
   Elleuch M, 2019, INT J MULTIMED DATA, V10, P26, DOI 10.4018/IJMDEM.2019100102
   Elleuch M, 2015, 2015 IEEE 12TH INTERNATIONAL MULTI-CONFERENCE ON SYSTEMS, SIGNALS & DEVICES (SSD)
   Elleuch M, 2016, PROCEDIA COMPUT SCI, V80, P1712, DOI 10.1016/j.procs.2016.05.512
   Ghanim TM, 2020, IEEE ACCESS, V8, P95465, DOI 10.1109/ACCESS.2020.2994290
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Graves A, 2005, LECT NOTES COMPUT SC, V3697, P799
   Graves A., 2008, ADV NEURAL INFORM PR, V20, P1
   Graves A., 2013, RNNLIB: A recurrent neural network library for sequence learning problems
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jemni SK, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420520072
   Khémiri A, 2019, ARAB J SCI ENG, V44, P9301, DOI 10.1007/s13369-019-03939-y
   Kong QQ, 2019, IEEE-ACM T AUDIO SPE, V27, P777, DOI 10.1109/TASLP.2019.2895254
   Li XG, 2015, INT CONF ACOUST SPEE, P4600, DOI 10.1109/ICASSP.2015.7178842
   Lipton Z. C., 2015, ARXIV
   Liwicki M, 2007, PROC INT CONF DOC, P367
   Lorigo LM, 2006, IEEE T PATTERN ANAL, V28, P712, DOI 10.1109/TPAMI.2006.102
   Maalej R., 2021, RELU ENHANCE MDLSTM, P386
   Maalej R., 2019, MAXOUT MDLSTM OFFLIN, P534
   Maalej R, 2020, MULTIMED TOOLS APPL, V79, P17969, DOI 10.1007/s11042-020-08740-w
   Maalej R, 2018, INT ARAB CONF INF TE, P267
   Maalej R, 2016, LECT NOTES COMPUT SC, V9887, P431, DOI 10.1007/978-3-319-44781-0_51
   Maalej R, 2016, LECT NOTES COMPUT SC, V9730, P746, DOI 10.1007/978-3-319-41501-7_83
   Maalej R, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P417, DOI 10.1109/DAS.2016.49
   Miao YJ, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P398, DOI 10.1109/ASRU.2013.6707763
   Rabi M, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418600078
   Swietojanski P, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6855088
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   Xiaohui Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P215, DOI 10.1109/ICASSP.2014.6853589
   Yan RJ, 2017, PROC INT CONF DOC, P1031, DOI 10.1109/ICDAR.2017.171
   Zhang T, 2015, ON LINE HANDWRITTEN
NR 45
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 10243
EP 10260
DI 10.1007/s11042-022-12339-8
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800008
DA 2024-07-18
ER

PT J
AU Tsai, CY
   Su, YK
AF Tsai, Chi-Yi
   Su, Yu-Kai
TI MobileNet-JDE: a lightweight multi-object tracking model for embedded
   systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Multi-object tracking; MobileNet; One-shot
   tracking-by-detection; Joint detection and embedding; Data association
ID MULTIPLE OBJECT TRACKING; MULTITARGET
AB Multi-object tracking (MOT) is one of the most challenging tasks in the field of computer vision. Although many MOT methods have been proposed in the literature, most of them cannot achieve real-time processing performance, especially those running on embedded platforms with limited computing resources. In this paper, we propose a real-time lightweight MOT method based on MobileNet to effectively improve the MOT processing speed. The proposed tracking method consists of a lightweight MOT model and a post-processing module. In the design of the lightweight MOT model, we have enhanced the lightweight object detection model proposed in our previous work by adding an appearance embedding layer. Moreover, we have also proposed a new anchor box design and a novel feature pyramid network (FPN) to improve the tracking accuracy of the proposed method. In the post-processing module, we have proposed a simple filtering method to replace the Kalman filter used in data association processing to accelerate the processing speed. Experimental results show that the proposed MOT method can reach to high processing speeds of 50.5 Frame-Per-Second (FPS) and 12.6 FPS when running on a desktop computer and an embedded platform, respectively. Moreover, the proposed MOT method also provides a competitive tracking performance when compared with the existing MOT methods. These advantages make the proposed method suitable for many applications running on embedded platforms, such as visual surveillance, visual tracking control of mobile robots, human-robot interaction, etc.
C1 [Tsai, Chi-Yi; Su, Yu-Kai] Tamkang Univ, Dept Elect & Comp Engn, 151 Yingzhuan Rd, New Taipei 251, Taiwan.
C3 Tamkang University
RP Tsai, CY (corresponding author), Tamkang Univ, Dept Elect & Comp Engn, 151 Yingzhuan Rd, New Taipei 251, Taiwan.
EM chiyi_tsai@mail.tku.edu.tw
RI Tsai, Chi-Yi/AFJ-8560-2022
OI Tsai, Chi-Yi/0000-0001-9872-4338
FU Ministry of Science and Technology of Taiwan [MOST 1102221-E-032-047,
   MOST 109-2221-E-032-039]
FX The authors sincerely thank Professor Humaira Nisar from the Department
   of Electronics Engineering of Universiti Tunku Abdul Rahman, Malaysia,
   for participating in the revision of the manuscript. This research was
   supported by the Ministry of Science and Technology of Taiwan under
   Grant MOST 1102221-E-032-047 and Grant MOST 109-2221-E-032-039.
CR Ahmed S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9112335
   [Anonymous], 2021, FRAME RATE GUIDE VID
   [Anonymous], 2016, ARXIV160300831V2
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A., 2016, ALEXTRAC AFFINITY LE
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Chen LJ, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS), P1, DOI [10.1109/ICSRS.2018.8688869, 10.1109/ICSRS.2018.00009]
   Chiu Y C, 2020, 2020 INT C SYSTEM SC, P1, DOI DOI 10.1109/ICSSE50014.2020.9219319
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Ess A, 2008, PROC CVPR IEEE, P1857
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang K, 2018, IEEE WINT CONF APPL, P466, DOI 10.1109/WACV.2018.00057
   Girdhar R, 2018, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2018.00044
   Gómez-Huélamo C, 2020, IEEE INT C INTELL TR
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosang J., 2017, ARXIV170502950V2
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Kalake L, 2021, IEEE ACCESS, V9, P32650, DOI 10.1109/ACCESS.2021.3060821
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lee J, 2020, IEEE ACCESS, V8, P182828, DOI 10.1109/ACCESS.2020.3028770
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Redmon J., 2018, COMPUTER VISION PATT
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wan XY, 2018, IEEE IMAGE PROC, P788, DOI 10.1109/ICIP.2018.8451174
   Wang Q, 2018, COMP VISION PATT REC
   Wang Z, 2019, ARXIV190912605V1
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Yang B, 2012, LECT NOTES COMPUT SC, V7572, P484, DOI 10.1007/978-3-642-33718-5_35
   Yang M, 2007, IEEE I CONF COMP VIS, P897
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Yu FW, 2016, LECT NOTES COMPUT SC, V9914, P36, DOI 10.1007/978-3-319-48881-3_3
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhang S., 2017, ARXIV170205693V1
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang Y, 2020, PROC CVPR IEEE, P6193, DOI 10.1109/CVPR42600.2020.00623
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zhou ZW, 2018, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2018.8545450
   Zhu J, 2018, LECT NOTES COMPUT SC, V11209, P379, DOI 10.1007/978-3-030-01228-1_23
NR 59
TC 8
Z9 8
U1 5
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9915
EP 9937
DI 10.1007/s11042-022-12095-9
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800018
DA 2024-07-18
ER

PT J
AU Hazra, T
   Anjaria, K
AF Hazra, Tanmoy
   Anjaria, Kushal
TI Applications of game theory in deep learning: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial neural network; Deep learning; GAN; Game theory; Artificial
   intelligence; CNN; Reinforcement learning
ID RECEPTIVE-FIELDS; NEURAL-NETWORKS; MECHANISM; MODEL
AB This paper provides a comprehensive overview of the applications of game theory in deep learning. Today, deep learning is a fast-evolving area for research in the domain of artificial intelligence. Alternatively, game theory has been showing its multi-dimensional applications in the last few decades. The application of game theory to deep learning includes another dimension in research. Game theory helps to model or solve various deep learning-based problems. Existing research contributions demonstrate that game theory is a potential approach to improve results in deep learning models. The design of deep learning models often involves a game-theoretic approach. Most of the classification problems which popularly employ a deep learning approach can be seen as a Stackelberg game. Generative Adversarial Network (GAN) is a deep learning architecture that has gained popularity in solving complex computer vision problems. GANs have their roots in game theory. The training of the generators and discriminators in GANs is essentially a two-player zero-sum game that allows the model to learn complex functions. This paper will give researchers an extensive account of significant contributions which have taken place in deep learning using game-theoretic concepts thus, giving a clear insight, challenges, and future directions. The current study also details various real-time applications of existing literature, valuable datasets in the field, and the popularity of this research area in recent years of publications and citations.
C1 [Hazra, Tanmoy] Indian Inst Informat Technol Pune, Dept Comp Sci & Engn, Pune, Maharashtra, India.
   [Anjaria, Kushal] Inst Rural Management Anand IRMA, Post Box 60, Anand 388001, Gujarat, India.
C3 Institute of Rural Management Anand
RP Hazra, T (corresponding author), Indian Inst Informat Technol Pune, Dept Comp Sci & Engn, Pune, Maharashtra, India.
EM tanmoyhazra316@gmail.com; kushal.anjaria@gmail.com
CR Abraham I., 2006, P ACM PODC 2006, P53, DOI [10.1145/1146381.1146393, 10.1145/1146381.1146411.8,31, DOI 10.1145/1146381.1146411.8,31]
   Agrawal A, 1981, MACHINE LEARNING MEE
   Alafif T, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18031117
   Andersen PA, 2018, IEEE CONF COMPU INTE, P149
   [Anonymous], 2017, P ADV NEUR INF PROC
   Arora S, 2017, PR MACH LEARN RES, V70
   Aslan S, 2020, PATTERN RECOGN LETT, V131, P158, DOI 10.1016/j.patrec.2019.12.007
   Balliet D, 2011, PSYCHOL BULL, V137, P594, DOI 10.1037/a0023489
   Baum E. B., 1988, Journal of Complexity, V4, P193, DOI 10.1016/0885-064X(88)90020-9
   Berthelot David, 2017, CoRR
   Brams, 2003, NEGOTIATION GAMES AP, V2
   Caicedo JC, 2019, CYTOM PART A, V95, P952, DOI 10.1002/cyto.a.23863
   Carse J.P., 1986, Finite and infinite games
   Carter E, 2019, DEEP LEARNING ROBUST
   Chavdarova T, 2018, PROC CVPR IEEE, P9407, DOI 10.1109/CVPR.2018.00980
   Chen JZ, 2016, PROCEEDINGS OF 2016 12TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P551, DOI [10.1109/CIS.2016.133, 10.1109/CIS.2016.0134]
   Chivukula AS, 2019, IEEE T KNOWL DATA EN, V31, P1066, DOI 10.1109/TKDE.2018.2851247
   Chivukula AS, 2017, IEEE IJCNN, P2758, DOI 10.1109/IJCNN.2017.7966196
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Darwish A, 2020, ARTIF INTELL REV, V53, P1767, DOI 10.1007/s10462-019-09719-2
   Dasgupta P, 2019, ARXIV PREPRINT ARXIV
   David B., 2016, FRONT ROBOT AI, V2, P39
   DAVIS M, 1965, NAV RES LOGIST Q, V12, P223, DOI 10.1002/nav.3800120303
   Devon Hjelm R., 2017, Boundary-seeking generative adversarial networks
   Ding M, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P913, DOI 10.1145/3269206.3271768
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Durugkar I., 2016, ARXIV PREPRINT ARXIV
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Fedus W., 2017, ARXIV171008446
   Fei F., 2019, P 28 INT JOINT C ART
   Foerster J, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P122
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gadirov H, 2018, CAPSULE ARCHITECTURE
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goodfellow I., 2016, NIPS 2016 TUTORIAL G
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Granmo O.-C., 2018, ARXIV PREPRINT ARXIV
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guo X, 2016, ARXIV PREPRINT ARXIV
   Gupta S., 2018, 2018 INT HIGH PERF E
   Gurram P, 2014, INT GEOSCI REMOTE SE, P3446, DOI 10.1109/IGARSS.2014.6947223
   Halpern JY, 2008, NEW PALGRAVE DICT EC, V1-8, P984
   Hang S., 2018, 2018 IEEE INT C DAT, P2018
   Hartmann Stefan, 2017, Streetgan: Towards road network synthesis with generative adversarial networks
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Heinrich J., 2016, ARXIV160301121
   Hinton G. E., 2012, 12070580 ARXIV
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hitawala Saifuddin, 2018, ARXIV180104271
   Ho J, 2016, ADV NEUR IN, V29
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Holmgard Christoffer, 2014, Generative Agents for Player Decision Modeling in Games
   Hsieh YP, 2018, ARXIV PREPRINT ARXIV
   Huang C.W., 2018, Advances in neural information processing systems, P9701
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Jiequn H, 2016, ARXIV PREPRINT ARXIV
   Johnson ND, 2011, J ECON PSYCHOL, V32, P865, DOI 10.1016/j.joep.2011.05.007
   Kingma D. P., 2014, arXiv
   Kohonen T, 1997, 1997 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-4, pPL1, DOI 10.1109/ICNN.1997.611622
   Kossaifi J, 2018, PROC CVPR IEEE, P878, DOI 10.1109/CVPR.2018.00098
   Lamba A., 2013, INT J ADV MANAG TECH, V3
   Lanctot M., 2017, Advances in Neural Information Processing Systems
   Larichev OI., 2013, VERBAL DECISION ANAL, P51
   Leckie C., 2018, DECISION GAME THEORY
   Li CX, 2017, ADV NEUR IN, V30
   Li Jiwei, 2017, P 2017 C EMP METH NA, P2157, DOI DOI 10.18653/V1/D17-1230
   Li XX, 2019, LECT NOTES COMPUT SC, V11492, P718, DOI 10.1007/978-3-030-20351-1_56
   Liang XN, 2013, IEEE COMMUN SURV TUT, V15, P472, DOI 10.1109/SURV.2012.062612.00056
   Lippi M, 2016, IEEE T COMP INTEL AI, V8, P412, DOI 10.1109/TCIAIG.2015.2490279
   Liu JL, 2021, NEURAL COMPUT APPL, V33, P19, DOI 10.1007/s00521-020-05383-8
   Lu Y, 2020, LECT NOTES ARTIF INT, V12164, P185, DOI 10.1007/978-3-030-52240-7_34
   Luce R. D., 1957, Games and decisions: Introduction and critical survey
   Lucic M, 2018, ADV NEUR IN, V31
   Malherbe C, 2018, NEUROPSYCHOLOGIA, V115, P142, DOI 10.1016/j.neuropsychologia.2017.10.013
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marchiori D, 2019, HEURISTICS THINKING
   Marsland, 2014, MACHINE LEARNING ALG, DOI DOI 10.1201/B17476
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moran N, 2018, 2018 CONFERENCE ON ARTIFICIAL LIFE (ALIFE 2018), P39
   Murugan R, 2021, J AMB INTEL HUM COMP, V12, P8887, DOI 10.1007/s12652-020-02688-3
   Mycielski J., 1992, Handbook of Game Theory with Economic Applications, Volume 1, V1, P41, DOI [DOI 10.1016/S1574-0005(05)80006-2, 10.1016/S1574-0005(05)80006-2]
   Myerson R. B., 2013, Game theory
   Narahari Y., 2014, Game theory and mechanism design
   NASH J, 1951, ANN MATH, V54, P286, DOI 10.2307/1969529
   NASH JF, 1950, P NATL ACAD SCI USA, V36, P48, DOI 10.1073/pnas.36.1.48
   Nguyen T., 2017, NIPS, P2670
   Oliehoek F.A., 2018, ARXIV PREPRINT ARXIV
   Oliehoek FA, 2017, ARXIV PREPRINT ARXIV
   Osborne M.J., 2004, An introduction to game theory, V3
   Osborne Martin J, 1994, COURSE GAME THEORY
   Paola U, 2018, THESIS U CAFOSCARIVE
   Paszke A, 2019, ADV NEUR IN, V32
   Pfau David, 2016, CoRR
   Pinto L., 2017, 2017 IEEE INT C ROB, P2017
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Rabinowitz NC, 2018, PR MACH LEARN RES, V80
   Ren K, 2020, ENGINEERING-PRC, V6, P346, DOI 10.1016/j.eng.2019.12.012
   Rudrapal D., 2020, DEEP LEARNING APPROA, P93
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Salimans T, 2016, ADV NEUR IN, V29
   Saxe AM, 2019, J STAT MECH-THEORY E, V2019, DOI 10.1088/1742-5468/ab3985
   Schuster A., 2010, Advances in Artificial Intelligence
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Schuurmans D., 2016, ADV NEURAL INFORM PR, P1678
   Schwenker F, 2001, NEURAL NETWORKS, V14, P439, DOI 10.1016/S0893-6080(01)00027-2
   Sengupta, 2021, INFORM GENERATION IN
   Shapley Lloyd S, 1953, Contributions to the Theory of Games (AM-28), V2, P307, DOI DOI 10.1515/9781400881970-018
   SHAPLEY LS, 1953, P NATL ACAD SCI USA, V39, P1095, DOI 10.1073/pnas.39.10.1095
   Shermila, 2017, ARXIV PREPRINT ARXIV
   Shin M, 2019, IEEE T VEH TECHNOL, V68, P4235, DOI 10.1109/TVT.2019.2903144
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Srivastava R. K., 2015, ADV NEURAL INFORM PR, P2377, DOI DOI 10.48550/ARXIV.1505.00387
   Stier J, 2018, PROCEDIA COMPUT SCI, V126, P234, DOI 10.1016/j.procs.2018.07.257
   Tembine H, 2020, IEEE T CYBERNETICS, V50, P1132, DOI 10.1109/TCYB.2018.2886238
   Tennenholtz M, 2002, LECT NOTES ARTIF INT, V2403, P49, DOI 10.1007/3-540-45634-1_4
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Von Neumann John, 1959, Contributions to the Theory of Games, V4, P13
   Vos N, 2011, COMPUT EDUC, V56, P127, DOI 10.1016/j.compedu.2010.08.013
   Wakatsuki M., 2020, DECISION MAKING METH, P317
   Wang, 2018, DEEP LEARNING DEEP D
   Wang BN, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4123
   Wang EK, 2020, FUTURE GENER COMP SY, V102, P14, DOI 10.1016/j.future.2019.07.034
   Wang HQ, 2018, 2018 14TH IEEE/ASME INTERNATIONAL CONFERENCE ON MECHATRONIC AND EMBEDDED SYSTEMS AND APPLICATIONS (MESA), DOI 10.1145/3204493.3204584
   Wang J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P515, DOI 10.1145/3077136.3080786
   Wang KF, 2017, IEEE-CAA J AUTOMATIC, V4, P588, DOI 10.1109/JAS.2017.7510583
   Wang RZ, 2019, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2019.00315
   Wang Y, DISCRIMINATIVE ADVER
   Wiering M, 2012, ADAPT LEARN OPTIM, V12, P1, DOI 10.1007/978-3-642-27645-3
   Woo TH, 2019, ANN NUCL ENERGY, V125, P12, DOI 10.1016/j.anucene.2018.10.041
   Wu TY, 2014, J NETW COMPUT APPL, V41, P47, DOI 10.1016/j.jnca.2013.10.006
   Xiao L, 2018, IEEE T INF FOREN SEC, V13, P35, DOI 10.1109/TIFS.2017.2737968
   Yang L.-C., 2017, ARXIV PREPRINT ARXIV, P324
   Yegnanarayana B., 2009, ARTIFICIAL NEURAL NE
   Yoon Jin-Hyun, 2021, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V26, P77, DOI 10.9708/jksci.2021.26.01.077
   Yoshida W, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000254
   Yu, 2018, WORKSH 32 AAAI C ART
   Zhang L, 2019, ARXIV190309569V2
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou C, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P665, DOI 10.1145/3097983.3098052
   Zhou Y, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1259
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou J, 2019, NAT GENET, V51, P12, DOI 10.1038/s41588-018-0295-5
   Zurada J.M., 1992, INTRO ARTIFICIAL NEU
   2007, ALG GAM THEOR, P1, DOI DOI 10.1017/CBO9780511800481
NR 149
TC 20
Z9 20
U1 27
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8963
EP 8994
DI 10.1007/s11042-022-12153-2
EA FEB 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000753241100002
PM 35496996
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Revathi, A
   Nagakrishnan, R
   Sasikaladevi, N
AF Revathi, A.
   Nagakrishnan, R.
   Sasikaladevi, N.
TI Robust HI and dysarthric speaker recognition - perceptual features and
   models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HI speaker recognition; Dysarthric speaker identification; Vector
   quantization; Perceptual features
ID SPATIAL SPEECH RECOGNITION; CONSONANT RECOGNITION; HEARING; NOISE;
   IDENTIFICATION; LISTENERS; ALGORITHM
AB This paper explores the necessity of having hearing impaired (HI) and dysarthric speakers be part of the person authentication system and it is considered to be imperative. Automated system on identifying speakers is evaluated by having the perceptual features with critical band analysis done in various non-linear frequency scales and vector quantization (VQ) & Fuzzy C means (FCM) based iterative clustering templates and multi-variant hidden Markov (MHMM) models as representative of HI or dysarthric speakers. For developing a training system, perceptual features are extracted from the speeches of HI or dysarthric speakers after the initial pre-processing techniques namely voice activity detection, pre-emphasis, frame blocking, and windowing contemplated on the speech utterances, and VQ & FCM clustering models and MHMM models are created for each speaker and the study is done on varying cluster and mixture size. The testing phase emphasizes the extraction of features from the test utterances, application of features to the templates, and classification is done based on minimum distance criterion for clustering technique and maximum log-likelihood criterion for MHMM technique. This algorithm gives the overall accuracy of 100% when the decision level fusion classification is done for the perceptual features with critical band analysis done in MEL, BARK, and ERB scales for all the clusters with variations in cluster size for both hearing impaired and dysarthric speaker recognition. Decision level fusion classification using FCM and MHMM technique provides low overall accuracy as compared to the VQ technique.
C1 [Revathi, A.; Nagakrishnan, R.] SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
   [Sasikaladevi, N.] SASTRA Deemed Univ, Dept CSE SoC, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Revathi, A (corresponding author), SASTRA Deemed Univ, Dept ECE SEEE, Thanjavur, India.
EM revathi@ece.sastra.edu
CR Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Chin YH, 2017, MULTIMED TOOLS APPL, V76, P13881, DOI 10.1007/s11042-016-3764-9
   Dargan S, 2020, SOFT COMPUT, V24, P10111, DOI 10.1007/s00500-019-04525-y
   Dargan S, 2020, EXPERT SYST APPL, V143, DOI 10.1016/j.eswa.2019.113114
   de Andrade AN, 2016, BRAZ J OTORHINOLAR, V82, P334, DOI 10.1016/j.bjorl.2015.10.002
   Farhadipour A, 2018, ETRI J, V40, P643, DOI 10.4218/etrij.2017-0260
   Fink N, 2012, J ACOUST SOC AM, V132, P1718, DOI 10.1121/1.4739441
   Gadekallu TR, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020274
   Ghezaiel W, 2017, MULTIMED TOOLS APPL, V76, P20973, DOI 10.1007/s11042-016-4044-4
   Healy EW, 2019, J ACOUST SOC AM, V145, pEL581, DOI 10.1121/1.5112828
   Healy EW, 2014, J ACOUST SOC AM, V136, P3325, DOI 10.1121/1.4901712
   Healy EW, 2013, J ACOUST SOC AM, V134, P3029, DOI 10.1121/1.4820893
   Hermansky H., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P1971
   HERMANSKY H, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P800, DOI 10.1109/ACSSC.1991.186557
   Hermansky H, 1994, IEEE T SPEECH AUDI P, V2, P578, DOI 10.1109/89.326616
   Jürgens T, 2014, J ACOUST SOC AM, V135, P1506, DOI 10.1121/1.4864293
   Kadi KL, 2016, BIOCYBERN BIOMED ENG, V36, P233, DOI 10.1016/j.bbe.2015.11.004
   Khare N, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040692
   Kumar M, 2021, J VIS COMMUN IMAGE R, V75, DOI 10.1016/j.jvcir.2021.103052
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Kumar M, 2018, NATL ACAD SCI LETT, V41, P29, DOI 10.1007/s40009-017-0606-x
   Li B, 2017, NEURAL PLAST, V2017, DOI 10.1155/2017/8941537
   Li ZY, 2015, MULTIMED TOOLS APPL, V74, P937, DOI 10.1007/s11042-013-1705-4
   Li ZQ, 2016, MULTIMED TOOLS APPL, V75, P7391, DOI 10.1007/s11042-015-2660-z
   Luque-Suárez F, 2019, MULTIMED TOOLS APPL, V78, P16803, DOI 10.1007/s11042-018-7035-9
   Moro-Velázquez L, 2018, APPL SOFT COMPUT, V62, P649, DOI 10.1016/j.asoc.2017.11.001
   Neher T, 2012, J ACOUST SOC AM, V131, P2561, DOI 10.1121/1.3689850
   Neher T, 2011, J ACOUST SOC AM, V130, P1542, DOI 10.1121/1.3608122
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Revathi A, 2008, PROC INT C SIGNAL PR, DOI [10.1109/ICSPCS.2008.4813764, DOI 10.1109/ICSPCS.2008.4813764]
   Revathi A, 2009, INT C COMP SCI INF E, DOI [10.1109/CSIE.2009.926, DOI 10.1109/CSIE.2009.926]
   Singh A, 2020, ARTIF INTELL REV, V53, P3673, DOI 10.1007/s10462-019-09775-8
   Tiwari V, 2020, MULTIMED TOOLS APPL, V79, P5243, DOI 10.1007/s11042-018-6358-x
NR 34
TC 0
Z9 0
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8215
EP 8233
DI 10.1007/s11042-022-12184-9
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749966800002
DA 2024-07-18
ER

PT J
AU Baig, MA
   Moinuddin, AA
   Khan, E
   Ghanbari, M
AF Baig, Md Amir
   Moinuddin, Athar A.
   Khan, E.
   Ghanbari, M.
TI DFT-based no-reference quality assessment of blurred images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sharpness; Blurrines; DFT; Image quality assessment; Distortion specific
ID SHARPNESS ASSESSMENT; VISUAL-SYSTEM
AB In this paper, blind image quality assessment (IQA) of Gaussian blurred images based on Discrete Fourier Transform (DFT) is proposed. The proposed work is based on the fact that if a positive constant is added to the magnitude of every AC coefficient of an image, then the average value of ratio of AC coefficient magnitude before and after the constant, gives an indication of degree of blurriness in the image. This ratio is likely to be smaller for blurred images and larger for sharper images. Further, it has been observed that the above-mentioned ratio measures the blurriness more precisely when the DFT is applied on the derivative of image instead of image itself. Therefore, in the proposed approach, the image derivative is calculated first and then block-based DFT is computed. The ratios of each AC coefficient (before and after adding a fixed positive constant) within the block are averaged at block level and then it is pooled to obtain a quality metric estimating the perceptual quality of the overall image. The proposed method is very fast and highly correlated with the subjective image quality rating and hence is suitable for real-time blurriness estimation applications.
C1 [Baig, Md Amir; Moinuddin, Athar A.; Khan, E.] Aligarh Muslim Univ, ZH Coll Engn, Dept Elect Engn, Aligarh, Uttar Pradesh, India.
   [Ghanbari, M.] Univ Essex, Sch Comp Sci & Elect Engn, Colchester, Essex, England.
C3 Zakir Husain College Of Engineering & Technology; Aligarh Muslim
   University; University of Essex
RP Baig, MA (corresponding author), Aligarh Muslim Univ, ZH Coll Engn, Dept Elect Engn, Aligarh, Uttar Pradesh, India.
EM amir.jvwu@gmail.com; atharamoin@gmail.com; ekhan67@gmail.com;
   ghan@essex.ac.uk
RI BAIG, MD AMIR/V-2291-2019
OI BAIG, MD AMIR/0000-0002-4607-3286
FU Ministry of Electronics and Information Technology, Government of India
   under Visvesvaraya PhD Scheme [MEITY-PHD-562]
FX "Md Amir Baig acknowledges the financial support for this work from the
   Ministry of Electronics and Information Technology, Government of India
   under Visvesvaraya PhD Scheme (Unique Awardee Number is MEITY-PHD-562)
   for Electronics and IT".
CR Athar S, 2019, IEEE ACCESS, V7, P140030, DOI 10.1109/ACCESS.2019.2943319
   Bahrami K, 2014, IEEE SIGNAL PROC LET, V21, P751, DOI 10.1109/LSP.2014.2314487
   Batten C. F., 2000, Autofocusing and astigmatism correction in the scanning electron microscope
   Bong DBL, 2015, MULTIMED TOOLS APPL, V74, P7355, DOI 10.1007/s11042-014-1983-5
   Caviedes J, 2004, SIGNAL PROCESS-IMAGE, V19, P147, DOI 10.1016/j.image.2003.08.002
   Deng CW, 2020, IEEE T CYBERNETICS, V50, P1146, DOI 10.1109/TCYB.2018.2889376
   DEPALMA JJ, 1962, J OPT SOC AM, V52, P328, DOI 10.1364/JOSA.52.000328
   ERASMUS SJ, 1982, J MICROSC-OXFORD, V127, P185, DOI 10.1111/j.1365-2818.1982.tb00412.x
   Fang RG, 2017, IEEE T CIRC SYST VID, V27, P1381, DOI 10.1109/TCSVT.2016.2539658
   Ferzli R, 2005, IEEE IMAGE PROC, P1157
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   FIRESTONE L, 1991, CYTOMETRY, V12, P195, DOI 10.1002/cyto.990120302
   Golestaneh S. Alireza, 2014, IEEE Signal Processing Letters, V21, P155, DOI 10.1109/LSP.2013.2296038
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gvozden G, 2018, J VIS COMMUN IMAGE R, V50, P145, DOI 10.1016/j.jvcir.2017.11.017
   Hassen R, 2013, IEEE T IMAGE PROCESS, V22, P2798, DOI 10.1109/TIP.2013.2251643
   Hong YZ, 2016, MULTIMED TOOLS APPL, V75, P10807, DOI 10.1007/s11042-015-2792-1
   Hosseini MS, 2019, IEEE T IMAGE PROCESS, V28, P4510, DOI 10.1109/TIP.2019.2906582
   Joshi P, 2018, IEEE ACCESS, V6, P33871, DOI 10.1109/ACCESS.2018.2846585
   Joshi P, 2017, MULTIMED TOOLS APPL, V76, P18871, DOI 10.1007/s11042-017-4418-2
   Larrabee R. D., 2003, TECH REP
   Larson E C, 2009, Categorical Image Quality (CSIQ) database [EB/OL]
   Li LD, 2016, IEEE T MULTIMEDIA, V18, P1085, DOI 10.1109/TMM.2016.2545398
   Li QH, 2016, J COMPUT SCI TECH-CH, V31, P225, DOI 10.1007/s11390-016-1623-9
   Lim CL, 2016, J FRANKLIN I, V353, P4715, DOI 10.1016/j.jfranklin.2016.08.012
   Marichal X., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P386, DOI 10.1109/ICIP.1999.822923
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nakhaei AA, 2018, IET IMAGE PROCESS, V12, DOI 10.1049/iet-ipr.2017.0916
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ng KC, 2001, IEEE INT CONF ROBOT, P2791, DOI 10.1109/ROBOT.2001.933045
   NILL NB, 1992, OPT ENG, V31, P813, DOI 10.1117/12.56114
   Ong EP, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P469, DOI 10.1109/ISSPA.2003.1224741
   Ponomarenko N., 2008, Tampere image database
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   SAGHRI JA, 1989, OPT ENG, V28, P813, DOI 10.1117/12.7977038
   Saha A, 2015, IEEE T IMAGE PROCESS, V24, P1879, DOI 10.1109/TIP.2015.2411436
   Shaked D, 2005, IEEE IMAGE PROC, P841
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sheikh HR, 2005, LIVE IMAGE QUALITY A, DOI DOI 10.1109/CVPR.2015.7298594
   Tan KT, 2000, IEEE SIGNAL PROC LET, V7, P213, DOI 10.1109/97.855443
   Tang LJ, 2018, MULTIMED TOOLS APPL, V77, P5637, DOI 10.1007/s11042-017-4477-4
   Venkatanath N, 2015, NATL CONF COMMUN
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Vu PV, 2012, IEEE SIGNAL PROC LET, V19, P423, DOI 10.1109/LSP.2012.2199980
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z, 2006, IEEE IMAGE PROC, P2945, DOI 10.1109/ICIP.2006.313136
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Zaric A, 2012, AUTOMATIKA, V53, P344, DOI 10.7305/automatika.53-4.241
   Zhai GT, 2015, APSIPA TRANS SIGNAL, V4, DOI 10.1017/ATSIP.2015.8
   Zhan YB, 2017, IEEE SIGNAL PROC LET, V24, P760, DOI 10.1109/LSP.2017.2688371
NR 53
TC 7
Z9 7
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7895
EP 7916
DI 10.1007/s11042-022-11992-3
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000750865500002
DA 2024-07-18
ER

PT J
AU Zhang, QQ
   Zhu, ZJ
   Bai, YQ
   Liao, GL
   Liu, TN
AF Zhang, Qingqing
   Zhu, Zhongjie
   Bai, Yongqiang
   Liao, Guanglong
   Liu, Tingna
TI Distracted driving detection based on the improved CenterNet with
   attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target detection; Distracted driving; CenterNet; Attention mechanism
ID NETWORK
AB Distracted driving detection has many significant application scenarios in intelligent transportation, driver assistance, and other fields. However, these distracted behaviors are difficult to be recognized due to the variable background and different scale targets. To solve these problems, a distracted driving detection scheme is proposed based on the improved CenterNet with attention mechanism in this paper. Given the complexity of driving environments, an image classification method was first designed to divide the images into person and unmanned areas, which can reduce the interference in unmanned situations. And then a novel attention mechanism module was introduced into CenterNet to improve its detection ability for small targets. Numerous experiments were conducted with a public dataset and newly built targeted dataset that included three categories of distracted driving behaviors with 6481 pictures. The results demonstrated that, the proposed scheme can detect distracted behaviors in real time while driving with a mean average precision (mAP) of 97.0%, which outperforms some representative detection methods, such as CornerNet, YOLO v3 and YOLO v4.
C1 [Zhang, Qingqing; Zhu, Zhongjie; Bai, Yongqiang; Liao, Guanglong; Liu, Tingna] Zhejiang Wanli Univ, Ningbo Key Lab Digital Signal Proc, Ningbo 315100, Peoples R China.
C3 Zhejiang Wanli University
RP Zhu, ZJ; Bai, YQ (corresponding author), Zhejiang Wanli Univ, Ningbo Key Lab Digital Signal Proc, Ningbo 315100, Peoples R China.
EM zhongjiezhu@hotmail.com; byq-163@163.com
RI Zhang, Qing/HTT-5047-2023; Zhang, Qing/IZQ-5273-2023
FU National Natural Science Foundation of China [61671412]; Zhejiang
   Provincial Natural Science Foundation of China [LY19F010002,
   LY21F010014]; Natural Science Foundation of Ningbo, China [2018A610053,
   202003N4323]; Ningbo Municipal Projects for Leading and Top Talents
   [NBLJ201801006]; General Scientific Research Project of Zhejiang
   Education Department [Y201941122]; School level scientific research and
   innovation team project; Fundamental Research Funds for Zhejiang
   Provincial Colleges and Universities
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61671412), Zhejiang Provincial Natural
   Science Foundation of China (Grant No. LY19F010002, LY21F010014),
   Natural Science Foundation of Ningbo, China (Grant No. 2018A610053,
   202003N4323), Ningbo Municipal Projects for Leading and Top Talents
   (Grant No. NBLJ201801006), General Scientific Research Project of
   Zhejiang Education Department (Grant No. Y201941122), School level
   scientific research and innovation team project, and Fundamental
   Research Funds for Zhejiang Provincial Colleges and Universities.
CR Alexey B, 2020, COMPUTER VISION PATT
   Alotaibi M, 2020, SIGNAL IMAGE VIDEO P, V14, P617, DOI 10.1007/s11760-019-01589-z
   CAI Z, 2016, EUR C COMP VIS, P354, DOI DOI 10.1007/978-3-319-46493-0_22
   Cui ZY, 2021, IEEE T GEOSCI REMOTE, V59, P379, DOI 10.1109/TGRS.2020.2997200
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Tran D, 2018, IET INTELL TRANSP SY, V12, P1210, DOI 10.1049/iet-its.2018.5172
   Eraqi HM, 2019, J ADV TRANSPORT, DOI 10.1155/2019/4125865
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Koesdwiady A, 2017, LECT NOTES COMPUT SC, V10317, P11, DOI 10.1007/978-3-319-59876-5_2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Law Hei, 2019, ARXIV190408900
   Li QN, 2021, IEEE ACCESS, V9, P51550, DOI 10.1109/ACCESS.2021.3068899
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Yehya A, 2018, ARXIV170609498V3
   Yi P, 2022, IEEE T PATTERN ANAL, V44, P2264, DOI 10.1109/TPAMI.2020.3042298
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhou X, 2019, PSYCHOL HEALTH, V34, P811, DOI 10.1080/08870446.2019.1574348
NR 28
TC 5
Z9 5
U1 6
U2 93
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7993
EP 8005
DI 10.1007/s11042-022-12128-3
EA JAN 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749055500003
DA 2024-07-18
ER

PT J
AU Agarwal, S
   Jung, KH
AF Agarwal, Saurabh
   Jung, Ki-Hyun
TI Median filtering forensics based on optimum thresholding for
   low-resolution compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forgery detection; Image forensics; Median filtering detection;
   Markov model
AB Image dependence is increasing for information sharing. In image forensics, the detection of median filtering is challenging on low-resolution and highly compressed images. In this paper, a robust median filtering detection technique is proposed to give promising results on low-resolution and highly compressed images. The proposed technique is based on optimal thresholding process on difference arrays. The optimal thresholding provides additional intrinsic features by utilizing a full range of difference array values. As a result, the optimized thresholding difference arrays give better statistical information that can improve a performance. Further, experimental results show that a choice of padding in median filtering process has a considerable effect on median filtering detection accuracy. Both zero padding and symmetric padding types are considered to highlight effect of padding in performance evaluation. Experimental analysis is performed on multiple datasets using SVM and LDA classifier. The proposed technique proves robustness even against the averaging and Gaussian filter post processing. The proposed technique achieved better accuracy in comparison with state of the art techniques in most of the cases.
C1 [Agarwal, Saurabh] Amity Univ Uttar Pradesh, Amity Sch Engn Technol, Noida, India.
   [Agarwal, Saurabh; Jung, Ki-Hyun] Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil,, Gyongsan 38428, Gyeongbuk, South Korea.
C3 Amity University Noida; Kyungil University
RP Jung, KH (corresponding author), Kyungil Univ, Dept Cyber Secur, 50 Gamasil Gil,, Gyongsan 38428, Gyeongbuk, South Korea.
EM saurabhnsit2510@gmail.com; khanny.jung@gmail.com
RI Agarwal, Saurabh/AAC-5460-2020
OI Agarwal, Saurabh/0000-0003-3836-2595; Jung, Ki-Hyun/0000-0002-0662-8355
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2018R1D1A1A09081842,
   2021R1I1A3049788]; Brain Pool program - Ministry of Science and ICT
   through the National Research Foundation of Korea [2019H1D3A1A01101687]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2018R1D1A1A09081842, 2021R1I1A3049788) and Brain Pool
   program funded by the Ministry of Science and ICT through the National
   Research Foundation of Korea (2019H1D3A1A01101687).
CR Bas P., 2008, BREAK OUR WATERMARKI
   Bhanot K, 2018, INT J SYST ASSUR ENG, V9, P12, DOI 10.1007/s13198-015-0398-7
   Chen CL, 2013, IEEE T IMAGE PROCESS, V22, P4699, DOI 10.1109/TIP.2013.2277814
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P1849, DOI 10.1109/LSP.2015.2438008
   Chen ZP, 2019, IEEE T INF FOREN SEC, V14, P2454, DOI 10.1109/TIFS.2019.2901826
   Ferreira A, 2014, LECT NOTES COMPUT SC, V8827, P302, DOI 10.1007/978-3-319-12568-8_37
   Gao H, 2019, SIGNAL PROCESS-IMAGE, V72, P126, DOI 10.1016/j.image.2018.12.014
   Gupta A, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3321508
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Kanwal N, 2020, MULTIMED TOOLS APPL, V79, P12829, DOI 10.1007/s11042-020-08621-2
   Kirchner M, 2010, PROC SPIE, V7541, DOI 10.1117/12.839100
   Kumar R, 2019, J INF SECUR APPL, V47, P94, DOI 10.1016/j.jisa.2019.04.007
   Li WJ, 2019, MULTIMED TOOLS APPL, V78, P8363, DOI 10.1007/s11042-018-6831-6
   Matern F, 2020, IEEE T INF FOREN SEC, V15, P1303, DOI 10.1109/TIFS.2019.2935913
   Nam SH, 2019, IEEE IMAGE PROC, P106, DOI [10.1109/icip.2019.8802946, 10.1109/ICIP.2019.8802946]
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Peng AJ, 2019, IEEE ACCESS, V7, P28525, DOI 10.1109/ACCESS.2019.2897761
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Rhee RH, 2019, IEEE ACCESS, V7, P92586, DOI 10.1109/ACCESS.2019.2927540
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Shan WY, 2019, IEEE ACCESS, V7, P17174, DOI 10.1109/ACCESS.2019.2894981
   Shan WY, 2019, SIGNAL PROCESS-IMAGE, V71, P138, DOI 10.1016/j.image.2018.11.011
   Tang HS, 2018, J VIS COMMUN IMAGE R, V51, P162, DOI 10.1016/j.jvcir.2018.01.011
   Yu L, 2019, IEEE ACCESS, V7, P120594, DOI 10.1109/ACCESS.2019.2932810
   Zhang WW, 2019, MULTIMED TOOLS APPL, V78, P20113, DOI 10.1007/s11042-019-7288-y
NR 26
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7047
EP 7062
DI 10.1007/s11042-022-11945-w
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746354000005
DA 2024-07-18
ER

PT J
AU Wang, Q
   Li, YZ
   Wang, Y
   Ren, JD
AF Wang, Qian
   Li, Yazhou
   Wang, Yan
   Ren, Jiadong
TI An automatic algorithm for software vulnerability classification based
   on CNN and GRU
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Software security; Vulnerability classification
AB In order to improve the management efficiency of software vulnerability classification, reduce the risk of system being attacked and destroyed, and save the cost for vulnerability repair, this paper proposes an automatic algorithm for Software Vulnerability Classification based on convolutional neural network (CNN) and gate recurrent unit neural network (GRU), called SVC-CG. It has conducted a fusion between the models of CNN and GRU according to their advantages (CNN is good at extracting local vector features of vulnerability text and GRU is good at extracting global features related to the context of vulnerability text). The merger of the features extracted by the complementary models can represent the semantic and grammatical information more accurately. Firstly, the Skip-gram language model based on Word2Vec is used to train and generate the word vector, and the words in each vulnerability text are mapped into the space with limited dimensions to represent the semantic information. Then the CNN is used to extract the local features of the text vector, and the GRU is used to extract the global features related to the text context. We combine two complementary models to construct a SVC-CG neural network algorithm, which can represent semantic and grammatical information more accurately to realize automatic classification of vulnerabilities. The experiment uses the vulnerability data from the national vulnerability database (NVD) to train and evaluate the SVC-CG algorithm. Through experimental comparison and analysis, the SVC-CG algorithm proposed in this paper has a good performance on Macro recall rate, Macro precision rate and Macro F1-score.
C1 [Wang, Qian; Ren, Jiadong] Yanshan Univ, Coll Informat Sci & Engn, Comp Virtual Technol & Syst Integrat Lab Hebei Pr, Qinhuangdao 066000, Hebei, Peoples R China.
   [Li, Yazhou] China Mobile Xiongan Informat & Commun Technol Co, Xiongan 071700, Hebei, Peoples R China.
   [Wang, Yan] Northeastern Univ Qinhuangdao, Ctr Comp, Qinhuangdao, Hebei, Peoples R China.
C3 Yanshan University; Northeastern University - China
RP Wang, Q (corresponding author), Yanshan Univ, Coll Informat Sci & Engn, Comp Virtual Technol & Syst Integrat Lab Hebei Pr, Qinhuangdao 066000, Hebei, Peoples R China.
EM wangqianysu@163.com
FU National Natural Science Foundation of China [61807028, 61802332,
   61772449]; Youth Foundation of Hebei Educational Committee of China
   [QN2021145]; Natural Science Foundation of Hebei Province of China
   [F2019203120]; Fundamental Research Funds for the Central Universities
FX This work is supported by the National Natural Science Foundation of
   China under Grant Nos. 61807028, 61802332, and 61772449, the Youth
   Foundation of Hebei Educational Committee of China under Grant No.
   QN2021145, the Natural Science Foundation of Hebei Province of China
   under Grant No. F2019203120. The Fundamental Research Funds for the
   Central Universities under Grant No.N182303036.The authors are grateful
   to valuable comments and suggestions of the reviewers.
CR Aota M, 2020, IEEE SYMP COMP COMMU, P26, DOI 10.1109/iscc50000.2020.9219568
   Bhuiyan FA, 2021, IEEE ACCESS, V9, P28471, DOI 10.1109/ACCESS.2021.3058067
   Chiu CC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4774, DOI 10.1109/ICASSP.2018.8462105
   Chung Junyoung, 2014, ARXIV14123555
   Davari M, 2017, PROCEEDINGS 2017 INTERNATIONAL CONFERENCE ON SOFTWARE SECURITY AND ASSURANCE (ICSSA), P44, DOI 10.1109/ICSSA.2017.27
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Gardner M, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P1
   Gawron M, 2018, LECT NOTES COMPUT SC, V10694, P3, DOI 10.1007/978-3-319-76687-4_1
   Harer JA, ABS180304497 CORR
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hovsepyan A., 2012, P 4 INT WORKSH SEC M, P7
   Huang GY, 2019, IEEE ACCESS, V7, P28291, DOI 10.1109/ACCESS.2019.2900462
   Kalchbrenner N, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P655, DOI 10.3115/v1/p14-1062
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li ZS, 2018, TRANS DISTRIB CONF
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Na S, 2017, LECT NOTE DATA ENG, V2, P657, DOI 10.1007/978-3-319-49106-6_65
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Siewruk G, 2021, IEEE ACCESS, V9, P88852, DOI 10.1109/ACCESS.2021.3075385
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Wang AQ, 2016, INT CONF GEOINFORM
   Wijayasekara D, 2014, IEEE IND ELEC, P3612, DOI 10.1109/IECON.2014.7049035
   Wu F, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P1298, DOI 10.1109/CompComm.2017.8322752
   Xiong W, 2017, IEEE-ACM T AUDIO SPE, V25, P2410, DOI 10.1109/TASLP.2017.2756440
   Yih Wen-tau, 2011, P 15 C COMPUTATIONAL, P247
   Zhang Y, 2015, ARXIV PREPRINT ARXIV
NR 28
TC 9
Z9 9
U1 7
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 7103
EP 7124
DI 10.1007/s11042-022-12049-1
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000746354000008
DA 2024-07-18
ER

PT J
AU Wang, R
   Li, L
   Wang, PP
   Tao, XH
   Liu, PY
AF Wang, Ru
   Li, Lin
   Wang, Peipei
   Tao, Xiaohui
   Liu, Peiyu
TI Deep boundary-aware clustering by jointly optimizing unsupervised
   representation learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised representation learning; Deep clustering; Variational
   bounds
AB Deep clustering obtains feature representation generally and then performs clustering for high dimension real-world data. However, conventional solutions are two-stage embedding learning-based methods and these two processes are separate and independent, which often leads to clustering results cannot feedback to optimize the representation learning and reduces the performance of deep clustering. In this paper, we aim to propose a deep boundary-aware clustering by jointly optimizing unsupervised representation learning. More specifically, we joint boundary-aware variational auto-encoder and deep regularized clustering for deep regularized clustering for unsupervised learning, named Boundary-aware DEep Clustering (BaDEC). BaDEC is able to learn feature representation and clustering simultaneously, and it introduces deep regularized clustering to reduce the unreliability of the similarity measures. In particular, we present a boundary-aware variational auto-encoder that tunes variable evidence lower bounds flexibly to assist feature representation learning better for more accurate clustering. Extensive experiments on various datasets from multiple domains demonstrate that the proposed method outperforms several popular comparison baseline methods.
C1 [Wang, Ru; Liu, Peiyu] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
   [Li, Lin; Wang, Peipei] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Tao, Xiaohui] Univ Southern Queensland, Sch Sci, Toowoomba, Qld, Australia.
C3 Shandong Normal University; Wuhan University of Technology; University
   of Southern Queensland
RP Liu, PY (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.; Li, L (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
EM cathylilin@whut.edu.cn; ppwang07@whut.edu.cn; Xiaohui.Tao@usq.edu.au;
   liupy@sdnu.edu.cn
RI tao, xiaohui/KCK-2677-2024; Li, Li/AEM-3636-2022; li, li/HII-4157-2022;
   Tao, Xiaohui/JKI-2330-2023; Liu, peiyu/AAE-3641-2021
OI Tao, Xiaohui/0000-0002-0020-077X
FU National Natural Science Foundation of China [61602353, 61373148]; Hubei
   Provincial Natural Science Foundation of China [2017CFA012]; National
   Social Science Foundation [19BYY076]; Key R & D project of Shandong
   Province [2019JZZY010129]; Shandong Provincial Social Science Planning
   Project [18CXWJ01, 18BJYJ04, 19BJCJ51]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61602353 and 61373148), Hubei Provincial Natural
   Science Foundation of China (Grant No. 2017CFA012), the National Social
   Science Foundation under Award (Grant No. 19BYY076), in part Key R & D
   project of Shandong Province (Grant No. 2019JZZY010129), and Shandong
   Provincial Social Science Planning Project (Grant No. 18CXWJ01, 18BJYJ04
   and 19BJCJ51).
CR [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2009, NEURIPS
   Chen XK, 2017, AER ADV ENG RES, V100, P1
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Dizaji KG, 2017, IEEE I CONF COMP VIS, P5747, DOI 10.1109/ICCV.2017.612
   Fu YP, 2020, PROC CVPR IEEE, P5949, DOI 10.1109/CVPR42600.2020.00599
   Gregor K, 2016, ADV NEUR IN, V29
   Guo XF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1753
   Huang C.-W., 2019, INT C MACHINE LEARNI, P2869
   Ji P, 2017, ADV NEUR IN, V30
   Jiang B, 2020, IEEE T IMAGE PROCESS, V29, P5079, DOI 10.1109/TIP.2020.2978583
   Jiang ZX, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1965
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu, 2020, P IEEE CVF C COMP VI, P8136, DOI DOI 10.1109/CVPR42600.2020.00816
   Martínez-Trinidad JF, 2001, PATTERN RECOGN, V34, P783, DOI 10.1016/S0031-3203(00)00030-3
   Mukherjee S, 2019, AAAI CONF ARTIF INTE, P4610
   Ng AY, 2002, ADV NEUR IN, V14, P849
   RAINFORTH T., 2018, INT C MACHINE LEARNI
   Ren YZ, 2019, NEUROCOMPUTING, V325, P121, DOI 10.1016/j.neucom.2018.10.016
   Solorio-Fernández S, 2017, PATTERN RECOGN, V72, P314, DOI 10.1016/j.patcog.2017.07.020
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Xiang SM, 2008, PATTERN RECOGN, V41, P3600, DOI 10.1016/j.patcog.2008.05.018
   Xiao H., 2017, ARXIV170807747
   Xie JY, 2016, PR MACH LEARN RES, V48
   Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556
   Ye J., 2008, P ADV NEUR INF PROC, P1649
   Yu J, 2012, INT J COMPUT COMMUN, V7, P784
   Zhang R, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1181, DOI 10.1145/3357384.3357985
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 30
TC 3
Z9 3
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34309
EP 34324
DI 10.1007/s11042-021-11597-2
EA JAN 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000746354000007
DA 2024-07-18
ER

PT J
AU Patel, AS
   Vyas, R
   Vyas, OP
   Ojha, M
AF Patel, Ashish Singh
   Vyas, Ranjana
   Vyas, O. P.
   Ojha, Muneendra
TI A study on video semantics; overview, challenges, and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video; Intelligent surveillance systems; Deep learning; Video semantics
ID ABNORMAL EVENT DETECTION; REAL-TIME; STRUCTURAL DESCRIPTION; CONCEPT
   ONTOLOGY; IMAGE; RETRIEVAL; RECOGNITION; REPRESENTATION; FRAMEWORK;
   FEATURES
AB Due to the increase in surveillance systems, there is a massive increase in surveillance data. As of now, the key challenge for video surveillance systems is analyzing these large video clips. It, therefore, has an enormous demand for intelligent video analysis systems capable of identifying activities and events. Since many researchers have emphasized the role of contextual knowledge and how the performance of video content analysis has improved in several ways, we have looked at different approaches in this study that can extract semantic information to human-level perception in the video. We also addressed open problems in semantics that come from event detection and irregular activity detection. Most methods/models are too coarse to accurately extract a complete set of information. Thus, we need to use a machine-readable format to view, process, store and extract meaningful information from the video data. In this paper, we discussed the methods/approaches for extracting low-level features, mid-level features, and high-level video features and their representation using Semantic Technologies. A taxonomy of hierarchical feature generation approaches is also provided. Some evaluation metrics for evaluating video activity and measuring the performance of the extraction features are explored. Community-approved benchmark datasets are also thoroughly surveyed and presented. The paper provides a complete framework of video research to develop an intelligent surveillance system.
C1 [Patel, Ashish Singh; Ojha, Muneendra] Int Inst Informat Technol Naya Raipur, Dept Comp Sci & Engn, Atal Nagar, India.
   [Vyas, Ranjana; Vyas, O. P.] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Patel, AS (corresponding author), Int Inst Informat Technol Naya Raipur, Dept Comp Sci & Engn, Atal Nagar, India.
EM ashish@iiitnr.edu.in; ranjana@iiita.ac.in; dropvyas@gmail.com;
   muneendra@iiitnr.edu.in
RI Patel, Ashish Singh/HIU-0959-2022; Ojha, Muneendra/GQZ-0811-2022
OI Patel, Ashish Singh/0000-0002-2963-1039; Ojha,
   Muneendra/0000-0002-3913-1185
CR Aafaq N, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3355390
   Ahmed SA, 2019, IEEE T CIRC SYST VID, V29, P1985, DOI 10.1109/TCSVT.2018.2857489
   Ahsan U, 2017, IEEE WINT CONF APPL, P669, DOI 10.1109/WACV.2017.80
   Akdemir U., 2008, Proc. ACMMM, P709, DOI DOI 10.1145/1459359.1459466
   Ali H, 2020, ARTIF INTELL REV, V53, P2635, DOI 10.1007/s10462-019-09743-2
   Aljaloud AS, 2021, IEEE ACCESS, V9, P73327, DOI 10.1109/ACCESS.2021.3081050
   Anjulan A, 2009, IEEE T CIRC SYST VID, V19, P63, DOI 10.1109/TCSVT.2008.2005801
   [Anonymous], 2018, ABS18010
   [Anonymous], 2011, 2011 NAT C COMM NCC
   [Anonymous], CISCO PUBLIC WHITE P, P2016
   [Anonymous], 2019, CVPR
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2011, TRECVID MULTIMEDIA E
   AR Z, 2012, UCF101 DATASET 101 H
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Arroyo R, 2015, EXPERT SYST APPL, V42, P7991, DOI 10.1016/j.eswa.2015.06.016
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bai L, 2007, IMVIP 2007: INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P117, DOI 10.1109/IMVIP.2007.13
   Baradel F, 2018, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2018.00056
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bellamine Insaf, 2014, Journal of Computer Science, V10, P828, DOI 10.3844/jcssp.2014.828.839
   BELLAMINE I, 2015, INTELL COMPUT VISION, P2015
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Ben Mabrouk A, 2017, PATTERN RECOGN LETT, V92, P62, DOI 10.1016/j.patrec.2017.04.015
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhattacharya S, 2014, PROC CVPR IEEE, P2243, DOI 10.1109/CVPR.2014.287
   Bizer C, 2009, INT J SEMANT WEB INF, V5, P1, DOI 10.4018/jswis.2009081901
   Bottazzi E., 2009, International Journal of Business Process Integration and Management, V4, P225, DOI 10.1504/IJBPIM.2009.032280
   Bouindour Samir, 2017, 8th International Conference on Imaging for Crime Detection and Prevention (ICDP 2017), P1
   Burl MC, 2004, SIAM PROC S, P532
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   SanMiguel JC, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P220, DOI 10.1109/AVSS.2009.28
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Caruccio L, 2019, EXPERT SYST APPL, V131, P190, DOI 10.1016/j.eswa.2019.04.031
   Cavaliere D, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P115, DOI 10.1109/AVSS.2016.7738062
   Chen K., 2021, ACM COMPUT SURV CSUR, V54, P1
   Chen LM, 2009, INT J WEB INF SYST, V5, P410, DOI 10.1108/17440080911006199
   Choudhary A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P344, DOI 10.1109/ICVGIP.2008.76
   Cong Y, 2013, PATTERN RECOGN, V46, P1851, DOI 10.1016/j.patcog.2012.11.021
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Crowley JL, 2005, CAVIAR CONTEXT AWARE
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dendorfer P., 2020, Mot20: A benchmark for multi object tracking in crowded scenes
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Du M, 2021, J VISUAL-JAPAN, V24, P47, DOI 10.1007/s12650-020-00687-2
   Elleuch N, 2011, P ELEV INT WORK MULT, P1
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan J, 2007, IEEE T MULTIMEDIA, V9, P939, DOI 10.1109/TMM.2007.900143
   Fan JP, 2002, MULTIMED TOOLS APPL, V17, P97, DOI 10.1023/A:1014635823052
   Ferryman J, 2006, CONJUNCTION IEEE C C
   Fiaz M., 2018, ARXIV180203098
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu CJ, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P1524
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   García A, 2008, LECT NOTES COMPUT SC, V5259, P322, DOI 10.1007/978-3-540-88458-3_29
   Garcia-Garcia A, 2018, APPL SOFT COMPUT, V70, P41, DOI 10.1016/j.asoc.2018.05.018
   Geczy P, 2008, MEDICAL APPL E COMME, V5077
   Girshick R., 2012, Rich feature hierarchies for accurate object detection and semantic segmentation, P2
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gómez-Romero J, 2011, EXPERT SYST APPL, V38, P7494, DOI 10.1016/j.eswa.2010.12.118
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grassi M, 2012, COGN COMPUT, V4, P497, DOI 10.1007/s12559-012-9172-1
   Greco L, 2016, IEEE COMPUT SOC CONF, P1297, DOI 10.1109/CVPRW.2016.164
   Greco L, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P194, DOI 10.1109/AVSS.2016.7738025
   Gruber TR, 1995, INT J HUM-COMPUT ST, V43, P907, DOI 10.1006/ijhc.1995.1081
   Guntuboina C., 2021, ELECT LETT COMPUT VI, V20, P99, DOI DOI 10.5565/REV/ELCVIA.1286
   Hamid R, 2007, IEEE I CONF COMP VIS, P520
   Hassan MM, 2021, J SUPERCOMPUT, V77, P2237, DOI 10.1007/s11227-020-03361-4
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   He D., 2018, ARXIV PREPRINT ARXIV
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hongeng S, 2000, PROC CVPR IEEE, P818, DOI 10.1109/CVPR.2000.855905
   Huang J., 2021, ARXIV PREPRINT ARXIV
   Huang JF, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P565, DOI 10.1109/FSKD.2014.6980896
   Hunter J., 2001, First International Semantic Web Working Symposium (SWWS'01), P261
   Hussain T, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107567
   J Z, 2019, P TRECVID 2019
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Ji XF, 2015, LECT NOTES ARTIF INT, V9244, P487, DOI 10.1007/978-3-319-22879-2_45
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joao Carreira AZ, 2019, SHORT NOTE KINETICS
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kavukcuoglu K., 2010, Learning convolutional feature hierarchies for visual recognition
   Kavukcuoglu K, 2009, PROC CVPR IEEE, P1605, DOI 10.1109/CVPRW.2009.5206545
   Kliper-Gross O, 2012, IEEE T PATTERN ANAL, V34, P615, DOI 10.1109/TPAMI.2011.209
   Kompatsiaris I, 2005, MULTIMEDIA CONTENT AND THE SEMANTIC WEB: METHODS, STANDARDS AND TOOLS, P339, DOI 10.1002/0470012617.ch13
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Kotsiantis S., 2004, MULTIMEDIA MINING WS, V3, P3263
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2012, HINTON GE 2012 ALEXN
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2013, HIGH PERFORMANCE COMPUTING IN SCIENCE AND ENGINEERING '12: TRANSACTIONS OF THE HIGH PERFORMANCE COMPUTING CENTER, STUTTGART (HLRS) 2012, P571, DOI 10.1007/978-3-642-33374-3_41
   Kuo WC, 2015, IEEE I CONF COMP VIS, P2479, DOI 10.1109/ICCV.2015.285
   Leach MJV, 2014, IEEE COMPUT SOC CONF, P467, DOI 10.1109/CVPRW.2014.75
   Leal-Taixe L., 2015, MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
   Lee SC, 2014, MACH VISION APPL, V25, P133, DOI 10.1007/s00138-013-0516-y
   Leo M, 2019, LECT NOTES COMPUT SC, V11134, P3, DOI 10.1007/978-3-030-11024-6_1
   Li C, 2013, NEUROCOMPUTING, V119, P94, DOI 10.1016/j.neucom.2012.03.040
   Li T, 2021, NEUROCOMPUTING, V439, P256, DOI 10.1016/j.neucom.2021.01.097
   Li XL, 2017, IEEE T IMAGE PROCESS, V26, P3652, DOI 10.1109/TIP.2017.2695887
   Liao W., 2017, ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, VIV-1-W1, P19, DOI [10.5194/isprs-annals-IV-1-W1-19-2017, DOI 10.5194/ISPRS-ANNALS-IV-1-W1-19-2017]
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood K, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P431, DOI 10.1109/GCCE.2015.7398708
   Markowska-Kaczmar U, 2018, INTEL SYST REF LIBR, V145, P123, DOI 10.1007/978-3-319-73891-8_7
   Meditskos G, 2017, PERVASIVE MOB COMPUT, V40, P17, DOI 10.1016/j.pmcj.2017.05.003
   Meditskos G, 2013, INT CONF PERVAS COMP, P25
   Miao YY, 2014, PROCEEDINGS OF 2014 IEEE WORKSHOP ON ADVANCED RESEARCH AND TECHNOLOGY IN INDUSTRY APPLICATIONS (WARTIA), P1379, DOI 10.1109/WARTIA.2014.6976540
   Milan A., 2016, ARXIV160300831
   Mitra S, 2003, DATA MINING CONCEPTS
   Nabati M, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102302
   Najibi M, 2016, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2016.260
   Nallaivarothayan H, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P343, DOI 10.1109/AVSS.2014.6918692
   Naphade M, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.63
   NEVATIA R, 2004, IEEE COMPUT SOC C CO
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   OM P, JAWAHAR OXFORD IIIT
   Oquab M, 2015, HAL ID HAL 01015140
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Pan J.-Y., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P405, DOI 10.1145/584792.584859
   Pantoja C., 2015, 6th International Conference on Imaging for Crime Prevention and Detection (ICDP-15)
   Papadopoulos GT, 2007, P ONT DRIV SEM VID A, P56
   Pareek P, 2021, ARTIF INTELL REV, V54, P2259, DOI 10.1007/s10462-020-09904-8
   Patel AS, 2021, SEMANT WEB, V12, P467, DOI 10.3233/SW-200393
   Patino L, 2016, IEEE COMPUT SOC CONF, P1240, DOI 10.1109/CVPRW.2016.157
   Patino L, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P355, DOI 10.1109/AVSS.2014.6918694
   Petrucci G, 2016, LECT NOTES COMPUT SC, V10024, P480, DOI 10.1007/978-3-319-49004-5_31
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Quack T, 2006, LECT NOTES COMPUT SC, V4071, P360
   Rai H, 2015, ADV INTELL SYST, V366, P789, DOI 10.1007/978-3-319-08422-0_114
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Ryoo MS, 2013, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2013.352
   Saini R, 2018, P 2 INT C COMP VIS I, V703, P261
   SanMiguel JC, 2013, MACH VISION APPL, V24, P493, DOI 10.1007/s00138-011-0397-x
   SanMiguel JC, 2012, COMPUT VIS IMAGE UND, V116, P937, DOI 10.1016/j.cviu.2012.04.005
   Saravanan D., 2010, 2010 Recent Advances in Space Technology Services and Climate Change (RSTSCC), P167, DOI 10.1109/RSTSCC.2010.5712827
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Shen JL, 2016, MULTIMEDIA SYST, V22, P99, DOI 10.1007/s00530-014-0399-4
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Si ZZ, 2011, IEEE I CONF COMP VIS, P41, DOI 10.1109/ICCV.2011.6126223
   Sigari MH, 2016, IMAGE VISION COMPUT, V53, P20, DOI 10.1016/j.imavis.2015.07.004
   Sikos L., 2017, Description Logics in Multimedia Reasoning
   Sikos L. F., 2015, P 8 WORKSH EXPL SEM, P35, DOI 10.1145/2810133.2810141
   Sikos LF, 2016, LECT NOTES ARTIF INT, V9621, P3, DOI 10.1007/978-3-662-49381-6_1
   Sikos LF, 2018, J INFORM TELECOMMUN, P1
   Sivic J, 2004, PROC CVPR IEEE, P488
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snidaro L, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P493, DOI 10.1109/AVSS.2007.4425360
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P975, DOI 10.1109/TMM.2007.900156
   Sobhani F, ARXIV PREPRINT ARXIV
   Son J, 2017, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2017.403
   Sreeja MU, 2021, COMPUT ELECTR ENG, V92, DOI 10.1016/j.compeleceng.2021.107161
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Stavropoulos TG, PERVASIVE MOBILE COM, V34, P126
   Suresh V, 2005, 2005 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, PROCEEDINGS, P187
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tani MYK, 2017, INT J MULTIMED INF R, V6, P295, DOI 10.1007/s13735-017-0133-z
   Tani MYK, 2015, LECT NOTES COMPUT SC, V8926, P299, DOI 10.1007/978-3-319-16181-5_21
   Tasnim N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062675
   Town C, 2006, MACH VISION APPL, V17, P94, DOI 10.1007/s00138-006-0017-3
   Duong TH, 2015, EXPERT SYST APPL, V42, P246, DOI 10.1016/j.eswa.2014.07.046
   Turaga PK, 2007, PROC CVPR IEEE, P1529
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   ul Hassan M, 2018, Neurohive
   Ullah A, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107102
   Vallet D, 2007, IEEE T CIRC SYST VID, V17, P336, DOI 10.1109/TCSVT.2007.890633
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vijayakumar V, 2012, INT J MULTIMED INF R, V1, P153, DOI 10.1007/s13735-012-0016-2
   WADLEY FM, 1952, PROBIT ANAL STAT TRE
   Wang B, 2011, IEEE IMAGE PROC
   Wang H., 2015, Semantic Deep Learning, P1
   Wang H, 2016, LECT NOTES COMPUT SC, V9827, P431, DOI 10.1007/978-3-319-44403-1_27
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang M, 2012, IEEE T MULTIMEDIA, V14, P975, DOI 10.1109/TMM.2012.2185041
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang XY, 2015, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2015.7299071
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu GC, 2017, PROC CVPR IEEE, P1638, DOI 10.1109/CVPR.2017.178
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Xie LX, 2008, P IEEE, V96, P623, DOI 10.1109/JPROC.2008.916362
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Xu Z, 2013, IEEE INT C COMPUT, P802, DOI 10.1109/CSE.2013.122
   Xu Z, 2015, J SYST SOFTWARE, V102, P217, DOI 10.1016/j.jss.2014.07.024
   Xuan Wang HC, 2017, OPTIK STUTTG, V11, P29
   Xue J, 2013, INTERSPEECH, P2364
   Yao BZ, 2010, P IEEE, V98, P1485, DOI 10.1109/JPROC.2010.2050411
   Yoo D, 2015, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2015.305
   Yu J, 2022, IEEE T NEUR NET LEAR, V33, P3572, DOI 10.1109/TNNLS.2021.3053563
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zablocki M., 2014, Journal of Theoretical and Applied Computer Science, V8, P13
   Zaidenberg S, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P136, DOI 10.1109/AVSS.2012.1
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang T, 2017, MULTIMED TOOLS APPL, V76, P1419, DOI 10.1007/s11042-015-3133-0
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhang X, 2018, QINIU SUBMISSION ACT
   Zhang YH, 2014, IEEE INT CON MULTI
   Zhang YT, 2015, PROC CVPR IEEE, P249, DOI 10.1109/CVPR.2015.7298621
   Zhao Y, 2015, LECT NOTES COMPUT SC, V9492, P410, DOI 10.1007/978-3-319-26561-2_49
   Zhao ZQ, 2015, LECT NOTES COMPUT SC, V9004, P348, DOI 10.1007/978-3-319-16808-1_24
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou K, 2016, DESTECH TRANS COMP
   Zhu XQ, 2005, IEEE T KNOWL DATA EN, V17, P665, DOI 10.1109/TKDE.2005.83
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 231
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6849
EP 6897
DI 10.1007/s11042-021-11722-1
EA JAN 2022
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000744378900002
DA 2024-07-18
ER

PT J
AU Geng, KK
   Dong, G
   Huang, WH
AF Geng, Keke
   Dong, Ge
   Huang, Wenhan
TI Robust dual-modal image quality assessment aware deep learning network
   for traffic targets detection of autonomous vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous driving; Deep neural network; Image quality assessment;
   Multi-spectral image
ID CAMERA; FUSION; LIDAR
AB The multi-spectral image pairs composed of LIDAR and RGB images demonstrates more effective detection performance in complex traffic environments, such as low illumination, motion blur and strong noise, etc. However, there is still a lack of relevant research on how to better fuse the two modalities to improve the robustness and detection accuracy of the perception system for autonomous vehicles under the condition of low visible light image quality. In this paper, we proposed a dual-modal image quality aware deep neural network (DMIQADNN). We comprehensively compared and analyzed the adaptions of fusion architectures in the early, middle, late, and score stages. By comprehensively considering the detection accuracy and detection speed, the fusion architecture in the middle stage was selected. Besides, we developed an image quality assessment network (IQAN) to evaluate the image quality score for RGB images. The corresponding fusion weights for RGB sub-network and LIDAR sub-network were adaptively assigned by using the proposed fusion weight assignment function. Then based on the calculated fusion weights, the RGB and LIDAR sub-networks were adaptively merged via a data fusion sub-network. The RGB images in the KITTI dataset were processed by reducing illumination and adding motion blur and Gaussian noises to produce a modified dataset containing 7481 RBG-LIDAR image pairs, and the DNIQADNN was trained and tested by semi-automatic annotation. The experimental results on modified KITTI Benchmark and dataset collected by using our own developed autonomous vehicle validate the robustness and effectiveness of proposed method. The ultimate FPS and AP values of the DNIQADNN reach 27 and 39.1, which are superior to those of the state-of-the-art instance segmentation networks.
C1 [Geng, Keke; Huang, Wenhan] Southeast Univ, Sch Mech Engn, Nanjing 211189, Peoples R China.
   [Dong, Ge] Tsinghua Univ, Inst Aeronaut & Astronaut, Beijing 100084, Peoples R China.
C3 Southeast University - China; Tsinghua University
RP Geng, KK (corresponding author), Southeast Univ, Sch Mech Engn, Nanjing 211189, Peoples R China.
EM jsgengke@seu.edu.cn
RI Dong, Ge/N-7866-2017
OI Dong, Ge/0000-0003-3950-222X
FU National Natural Science Foundation of China [51905095]; National
   Natural Science Foundation of Jiangsu Province [BK20180401]
FX This study is supported by the National Natural Science Foundation of
   China (Grant No. 51905095), and National Natural Science Foundation of
   Jiangsu Province (Grant No. BK20180401).
CR Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   Antico M, 2020, IEEE T ULTRASON FERR, V67, P2543, DOI 10.1109/TUFFC.2020.2965291
   Bi HB, 2021, NEUROCOMPUTING, V439, P63, DOI 10.1016/j.neucom.2020.12.125
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Bu F, 2020, IEEE ROBOT AUTOM LET, V5, P1626, DOI 10.1109/LRA.2019.2962358
   Chen, 2020, ARXIV201211525V1
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Cheng G, 2019, IEEE T IMAGE PROCESS, V28, P265, DOI 10.1109/TIP.2018.2867198
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Dolson J, 2010, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2010.5540086
   Dou J, 2019, IEEE INT CONF ROBOT, P4362, DOI [10.1109/ICRA.2019.8793492, 10.1109/icra.2019.8793492]
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Fourati E, 2020, MULTIMED TOOLS APPL, V79, P865, DOI 10.1007/s11042-019-08115-w
   Fu C.-Y., 2019, ARXIV190103353
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geng KK, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12203274
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2018, IEEE T NEUR NET LEAR, V29, P1301, DOI 10.1109/TNNLS.2017.2649101
   Gu K, 2017, IEEE T CYBERNETICS, V47, P4559, DOI 10.1109/TCYB.2016.2575544
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Gu K, 2015, IEEE T MULTIMEDIA, V17, P50, DOI 10.1109/TMM.2014.2373812
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Jiang Y, 2021, J SUPERCOMPUT, V77, P6904, DOI 10.1007/s11227-020-03537-y
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Li CN, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-85072-1
   Li F, 2021, NEUROCOMPUTING, V465, P141, DOI 10.1016/j.neucom.2021.08.116
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lv C, 2017, IEEE T IND ELECTRON, V64, P7984, DOI 10.1109/TIE.2017.2694414
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Pan BY, 2021, MULTIMED TOOLS APPL, V80, P19179, DOI 10.1007/s11042-021-10662-0
   Pang S, 2020, IEEE INT C INT ROBOT, P10386, DOI 10.1109/IROS45743.2020.9341791
   Premebida C, 2014, IEEE INT C INT ROBOT, P4112, DOI 10.1109/IROS.2014.6943141
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Rezaei M, 2019, IRAN CONF ELECTR ENG, P1589, DOI [10.1109/iraniancee.2019.8786526, 10.1109/IranianCEE.2019.8786526]
   Rödönyi G, 2021, IFAC PAPERSONLINE, V54, P20, DOI 10.1016/j.ifaco1.2021.08.575
   Rövid A, 2020, AT-AUTOM, V68, P337, DOI 10.1515/auto-2019-0086
   Schlosser J, 2016, IEEE INT CONF ROBOT, P2198, DOI 10.1109/ICRA.2016.7487370
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sun J, 2017, LECT NOTES COMPUT SC, V10554, P126, DOI 10.1007/978-3-319-67561-9_14
   Tang ZS, 2019, IEEE T BROADCAST, V65, P138, DOI 10.1109/TBC.2018.2871376
   Wang YH, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.107006
   Wang Z., 2016, ARXIV016551604
   Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI [10.1109/IROS40897.2019.8968513, 10.1109/iros40897.2019.8968513]
   Yoo JH, 2020, SELECTED PAPERS FROM THE NINETEENTH BIENNIAL IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (IEEE CEFC 2020), DOI [10.1109/CEFC46938.2020.9451336, 10.1007/978-3-030-58583-9_43]
   Zamanakos G, 2021, COMPUT GRAPH-UK, V99, P153, DOI 10.1016/j.cag.2021.07.003
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   Zhao XM, 2020, IEEE SENS J, V20, P4901, DOI 10.1109/JSEN.2020.2966034
   Zhong HZ, 2021, PROCEDIA COMPUT SCI, V183, P579, DOI 10.1016/j.procs.2021.02.100
NR 49
TC 10
Z9 10
U1 4
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6801
EP 6826
DI 10.1007/s11042-022-11924-1
EA JAN 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000743891900004
DA 2024-07-18
ER

PT J
AU Pérez-Gil, O
   Barea, R
   López-Guillén, E
   Bergasa, LM
   Gómez-Huélamo, C
   Gutiérrez, R
   Díaz-Díaz, A
AF Perez-Gil, Oscar
   Barea, Rafael
   Lopez-Guillen, Elena
   Bergasa, Luis M.
   Gomez-Huelamo, Carlos
   Gutierrez, Rodrigo
   Diaz-Diaz, Alejandro
TI Deep reinforcement learning based control for Autonomous Vehicles in
   CARLA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous Vehicles; Deep Reinforcement Learning; DQN; DDPG; CARLA
   Simulator
ID DESIGN
AB Nowadays, Artificial Intelligence (AI) is growing by leaps and bounds in almost all fields of technology, and Autonomous Vehicles (AV) research is one more of them. This paper proposes the using of algorithms based on Deep Learning (DL) in the control layer of an autonomous vehicle. More specifically, Deep Reinforcement Learning (DRL) algorithms such as Deep Q-Network (DQN) and Deep Deterministic Policy Gradient (DDPG) are implemented in order to compare results between them. The aim of this work is to obtain a trained model, applying a DRL algorithm, able of sending control commands to the vehicle to navigate properly and efficiently following a determined route. In addition, for each of the algorithms, several agents are presented as a solution, so that each of these agents uses different data sources to achieve the vehicle control commands. For this purpose, an open-source simulator such as CARLA is used, providing to the system with the ability to perform a multitude of tests without any risk into an hyper-realistic urban simulation environment, something that is unthinkable in the real world. The results obtained show that both DQN and DDPG reach the goal, but DDPG obtains a better performance. DDPG perfoms trajectories very similar to classic controller as LQR. In both cases RMSE is lower than 0.1m following trajectories with a range 180-700m. To conclude, some conclusions and future works are commented.
C1 [Perez-Gil, Oscar; Barea, Rafael; Lopez-Guillen, Elena; Bergasa, Luis M.; Gomez-Huelamo, Carlos; Gutierrez, Rodrigo; Diaz-Diaz, Alejandro] Univ Alcala, Elect Dept, Alcala De Henares, Spain.
C3 Universidad de Alcala
RP Pérez-Gil, O (corresponding author), Univ Alcala, Elect Dept, Alcala De Henares, Spain.
EM o.perezg@edu.uah.es; rafael.barea@uah.es; elena.lopezg@uah.es;
   luism.bergasa@uah.es; carlos.gomez@edu.uah.es;
   rodrigo.gutierrez@edu.uah.es; alejando.diazd@edu.uah.es
RI Diaz-Diaz, Alejandro/AFI-1982-2022; Bergasa, Luis M./H-9810-2013; Barea,
   Rafael/R-5760-2016; Diaz-Diaz, Alejandro/AAF-3672-2022
OI Diaz-Diaz, Alejandro/0000-0002-7232-3197; Bergasa, Luis
   M./0000-0002-0087-3077; Diaz-Diaz, Alejandro/0000-0002-7232-3197
FU Spanish MICINN/FEDER [RTI2018-099263-B-C21, RoboCity2030-DIH-CM,
   P2018/NMT-4331]; Programas de actividades I+D (CAM); EU Structural
   Funds; CRUE-CSIC; Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work has been funded in part from the Spanish
   MICINN/FEDER through the Techs4AgeCar project (RTI2018-099263-B-C21) and
   from the RoboCity2030-DIH-CM project (P2018/NMT-4331), funded by
   Programas de actividades I+D (CAM) and cofunded by EU Structural Funds.
CR Arango JF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216121
   Barea R, 2018, IEEE INT C INTELL TR, P3481, DOI 10.1109/ITSC.2018.8569962
   Bemporad A, 2002, AUTOMATICA, V38, P3, DOI 10.1016/S0005-1098(01)00174-1
   BYRNE RH, 1995, MATH COMPUT MODEL, V22, P343, DOI 10.1016/0895-7177(95)00143-P
   Charalel A, 2016, DEEP REINFORCEMENT L
   Cheein F., 2010, International Journal of Advanced Robotic Systems, V7, P155
   Chen Jiaqi, 2019, ARXIV PREPRINT ARXIV
   Chen L, 2022, IEEE T INTELL TRANSP, V23, P2966, DOI 10.1109/TITS.2020.3025671
   Ching-Yao Chan, 2017, International Journal of Transportation Science and Technology, V6, P208, DOI 10.1016/j.ijtst.2017.07.008
   Choomuang R., 2005, International Journal of Advanced Robotic Systems, V2, P197
   Codevilla F, 2018, IEEE INT CONF ROBOT, P4693
   Coulter R. C, 1992, CMURITR9201
   de Bruin T., 2015, DEEP REINFORCEMENT L
   del Egido J, 2018, WORKSH PHYS AG, P31
   Dosovitskiy A., 2017, P 1 ANN C ROB LEARN, P1, DOI DOI 10.48550/ARXIV.1711.03938
   Duan Y, 2016, PR MACH LEARN RES, V48
   Dupuis M., 2010, P DRIV SIM C EUR, P231
   Fan J., 2020, LEARNING DYNAMICS CO, P486, DOI DOI 10.48550/ARXIV.1901.00137
   Geiger A., 2012, CVPR
   Gutiérrez R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20144062
   HESSBURG T, 1994, IEEE CONTR SYST MAG, V14, P55, DOI 10.1109/37.295971
   Hou YN, 2017, IEEE SYS MAN CYBERN, P316, DOI 10.1109/SMC.2017.8122622
   Kendall A, 2019, IEEE INT CONF ROBOT, P8248, DOI [10.1109/ICRA.2019.8793742, 10.1109/icra.2019.8793742]
   Le-Anh T, 2006, EUR J OPER RES, V171, P1, DOI 10.1016/j.ejor.2005.01.036
   Lenain R, 2005, IEEE INT CONF ROBOT, P885
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liang XD, 2018, LECT NOTES COMPUT SC, V11211, P604, DOI 10.1007/978-3-030-01234-2_36
   Lillicrap, 2015, ARXIV150902971, P1
   Lin L.-J., 1993, Reinforcement learning for robots using neural networks
   Luo Y, 2009, AUTOMATICA, V45, P2446, DOI 10.1016/j.automatica.2009.06.022
   Mao HZ, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '16), P50, DOI 10.1145/3005745.3005750
   Martin UI etal, 2018, THESIS U POLITECNICA
   Matt V, 2017, DEEP REINFORCEMENT L
   Mnih V, 2013, ARXIV
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258
   Perez-Gil O, 2020, WORKSH PHYS AG, P60
   Raimondi FA, 2005, ROBOT AUTON SYST, V52, P115, DOI 10.1016/j.robot.2005.04.006
   Sáez A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030503
   Sanders A., 2016, INTRO UNREAL ENGINE
   Sasaki H, 2017, 2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P799, DOI 10.23919/SICE.2017.8105597
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Urmson C, 2008, J FIELD ROBOT, V25, P425, DOI 10.1002/rob.20255
   Wang F., 2017, P 2 WORKSHOP SYSTEM, P1, DOI DOI 10.23919/ITU-WT.2017.8246841
   Wang S., 2018, DEEP REINFORCEMENT L
   Wang W, 2008, INT J ADV ROBOT SYST, V5, P235
   Xiong X, 2016, ARXIV PREPRINT ARXIV
   Ye F, 2021, ARXIV PREPRINT ARXIV
   Yurtsever E, 2020, ARXIV PREPRINT ARXIV
   Zhang FJ, 2020, NEUROCOMPUTING, V411, P206, DOI 10.1016/j.neucom.2020.05.097
   Zhao JQ, 2018, IEEE INT C INTELL TR, P1303, DOI 10.1109/ITSC.2018.8569629
   Zhuang De-jun, 2007, Journal of Shanghai Jiaotong University, V41, P278
NR 52
TC 36
Z9 38
U1 10
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3553
EP 3576
DI 10.1007/s11042-021-11437-3
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000742319000007
OA hybrid
DA 2024-07-18
ER

PT J
AU Garg, A
   Chaturvedi, V
   Kaur, AB
   Varshney, V
   Parashar, A
AF Garg, Anupam
   Chaturvedi, Vybhav
   Kaur, Arman Beer
   Varshney, Vedansh
   Parashar, Anshu
TI Machine learning model for mapping of music mood and human emotion based
   on physiological signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human emotions; Music mood; Physiological signal; Multimedia; Audio
   signals; Machine learning
ID RECOGNITION SYSTEM; CLASSIFICATION; ACTIVATION
AB Emotion is considered a physiological state that appears whenever a transformation is observed by an individual in their environment or body. While studying the literature, it has been observed that combining the electrical activity of the brain, along with other physiological signals for the accurate analysis of human emotions is yet to be explored in greater depth. On the basis of physiological signals, this work has proposed a model using machine learning approaches for the calibration of music mood and human emotion. The proposed model consists of three phases (a) prediction of the mood of the song based on audio signals, (b) prediction of the emotion of the human-based on physiological signals using EEG, GSR, ECG, Pulse Detector, and finally, (c) the mapping has been done between the music mood and the human emotion and classifies them in real-time. Extensive experimentations have been conducted on the different music mood datasets and human emotion for influential feature extraction, training, testing and performance evaluation. An effort has been made to observe and measure the human emotions up to a certain degree of accuracy and efficiency by recording a person's bio- signals in response to music. Further, to test the applicability of the proposed work, playlists are generated based on the user's real-time emotion determined using features generated from different physiological sensors and mood depicted by musical excerpts. This work could prove to be helpful for improving mental and physical health by scientifically analyzing the physiological signals.
C1 [Garg, Anupam; Chaturvedi, Vybhav; Kaur, Arman Beer; Varshney, Vedansh; Parashar, Anshu] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Parashar, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM aparashar@thapar.edu
CR Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   Aljanaki A, 2016, INFORM PROCESS MANAG, V52, P115, DOI 10.1016/j.ipm.2015.03.004
   [Anonymous], 2010, 11 INT SOC MUS INF R
   Bagherzadeh Y, 2020, NEURON, V105, P577, DOI 10.1016/j.neuron.2019.11.001
   Bahl A, 2019, NANOIMPACT, V15, DOI 10.1016/j.impact.2019.100179
   Bashashati A, 2003, P ANN INT IEEE EMBS, V25, P2220, DOI 10.1109/IEMBS.2003.1280200
   Bengio Y., 2006, J MACH LEARN RES, V3, P1155, DOI DOI 10.5555/944919.9449661061.68157
   Bhat AS, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P359, DOI 10.1109/ICSIP.2014.63
   Bhattarai B, 2019, INT J FUZZY LOG INTE, V19, P88, DOI 10.5391/IJFIS.2019.19.2.88
   Bigo Louis, 2012, Sound and Music Computing
   Cao, 2009, THINKITS SUBMISSIONS
   Cernian A, 2017, 2017 21ST INTERNATIONAL CONFERENCE ON CONTROL SYSTEMS AND COMPUTER SCIENCE (CSCS), P213, DOI 10.1109/CSCS.2017.36
   Chanel G, 2007, IEEE SYS MAN CYBERN, P375
   Chaturvedi V, 2022, MULTIMEDIA SYST, V28, P21, DOI 10.1007/s00530-021-00786-6
   Cowie R., 2000, PROC ISCA WORKSHOP S, P19
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Drucker H., 2003, SUPPORT VECTOR REGRE, P155
   Edla Damodar Reddy, 2018, Procedia Computer Science, V132, P1523, DOI 10.1016/j.procs.2018.05.116
   Giannakopoulos T, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0144610
   Gilda S, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P154, DOI 10.1109/WiSPNET.2017.8299738
   Han B.-j., 2009, ISMIR, P651
   Harmon-Jones E, 2001, J PERS SOC PSYCHOL, V80, P797, DOI 10.1037/0022-3514.80.5.797
   Hosseini SA, 2010, J BIOL SYST, V18, P101, DOI 10.1142/S0218339010003640
   Hu X., 2008, Proceedings of the International Society for Music Information Retrieval Conference, P462
   IBM Corp. Released, 2021, IBM SPSS STAT WINDOW
   Juslin PN, 2004, J NEW MUSIC RES, V33, P217, DOI 10.1080/0929821042000317813
   Khanchandani KB, 2009, J SCI IND RES INDIA, V68, P367
   Kim KH, 2004, MED BIOL ENG COMPUT, V42, P419, DOI 10.1007/BF02344719
   King DB, 2015, ACS SYM SER, V1214, P1
   Landauer Thomas K., 2007, Handbook of latent semantic analysis
   Leaver AM, 2009, J NEUROSCI, V29, P2477, DOI 10.1523/JNEUROSCI.4921-08.2009
   Lehmburg L.J., 2010, MUSIC ED RES INT, V4, P19
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Malheiro R., 2016, P WORKSH MUS MACH LE, DOI 10.5220/0006037400450055
   McCraty R, 1998, ALTERN THER HEALTH M, V4, P75
   Naji M, 2015, SIGNAL IMAGE VIDEO P, V9, P1365, DOI 10.1007/s11760-013-0591-6
   Naji M, 2014, COGN COMPUT, V6, P241, DOI 10.1007/s12559-013-9239-7
   North AC., 2014, P NATL ACAD SCI USA, V111, P646, DOI [10.1073/pnas.1321664111, DOI 10.1073/PNAS.1321664111]
   Nummenmaa L, 2014, P NATL ACAD SCI USA, V111, P646, DOI 10.1073/pnas.1321664111
   Oliphant T., 2006, Guide to NumPy
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Patil T. R., 2013, International Journal Of Computer Science And Applications, V6, P256
   Pedregosa F., 2012, J MACH LEARN RES, V12
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Ramanathan R., 2017, P INT C COMP SYST IN, DOI 10.1109/CSITSS.2017.8447743
   Reynolds D, 2015, ENCY BIOMETRICS, P827, DOI [10.1007/978-0-387-73003-5%20196, DOI 10.1007/978-0-387-73003-5196, DOI 10.1007/978-1-4899-7488-4_196]
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Santos J.R.Q., 1999, Journal of Extension, V37, DOI [DOI 10.4135/9781483381411.N492, DOI 10.1080/09500690802187025]
   Schacter D.L., 2010, Psychology, V2nd
   Schmidt E.M., 2010, Proceedings of the international conference on Multimedia information retrieval, P267, DOI 10.1145/1743384.1743431
   Selvaraj J, 2013, BIOMED ENG ONLINE, V12, DOI 10.1186/1475-925X-12-44
   Silverman M.J., 2015, International Journal of Music and Performing Arts, V3, P1, DOI DOI 10.15640/IJMPA.V3N1A1
   Takahashi K, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P95, DOI 10.1109/ROMAN.2004.1374736
   Taktak A., 2019, Clinical engineering: a handbook for clinical and biomedical engineers
   Tan KR., 2019, P IOP C SERIES, V482, P012
   Thaut MichaelH., 2005, Rhythm, Music, and the Brain: Scientific Foundations and Clinical Applications
   Thayer Robert E., 1990, The Biopsychology of Mood and Arousal
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   van der Zwaag MD, 2012, ERGONOMICS, V55, P12, DOI 10.1080/00140139.2011.638403
   Vijayan AE, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P587, DOI 10.1109/CICT.2015.24
   Weninger  F., 2014, P IEEE INT C AC SPEE
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   YILDIRIM O, 2018, NEURAL COMPUT APPL
   Zhang KJ, 2018, ICMR '18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P135, DOI 10.1145/3206025.3206037
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zong C, 2009, IEEE INT SYMP SIGNAL, P334, DOI 10.1109/ISSPIT.2009.5407547
NR 66
TC 15
Z9 15
U1 7
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5137
EP 5177
DI 10.1007/s11042-021-11650-0
EA JAN 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700010
DA 2024-07-18
ER

PT J
AU Yang, XC
   Wang, TS
   Ji, GL
AF Yang, Xichen
   Wang, Tianshu
   Ji, Genlin
TI Image quality assessment via multiple features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No reference; Structural information; Natural sense statistic; Image
   quality assessment; Support vector regression
ID STATISTICS
AB Multimedia devices are indispensable in the information society. And, image quality highly impacts user experience of multimedia equipment. Therefore, measuring image quality accurately has great application value. The existing image quality assessment (IQA) methods have demonstrated the natural sense statistics and image structural information can measure the degradation of image. However, the generalization ability of individual IQA method is limited. In this paper, we propose a novel no-reference IQA method which is based on multiple features. For each image, we first extract natural sense statistic feature, global structural feature and local structural feature, respectively. Second, we train the quality prediction model via different features, and obtain different quality prediction scores by the models. Third, the prediction scores are collected and transformed to feature vectors. Subsequently, the IQA model is trained by support vector regression, and the input variables are the obtained feature vectors and subjective scores. The experimental results on the public databases demonstrate the proposed method can accurately predict the quality of both natural image and screen content image, and the performance is competitive with prevalent methods.
C1 [Yang, Xichen; Ji, Genlin] Nanjing Normal Univ, Sch Artificial Intelligence, Sch Comp & Elect Informat, 1 Wenyuan Rd, Nanjing, Peoples R China.
   [Wang, Tianshu] Nanjing Univ Chinese Med, Sch Artificial Intelligence & Informat Technol, 138 Xianlin Rd Qixia Dist, Nanjing, Peoples R China.
C3 Nanjing Normal University; Nanjing University of Chinese Medicine
RP Yang, XC (corresponding author), Nanjing Normal Univ, Sch Artificial Intelligence, Sch Comp & Elect Informat, 1 Wenyuan Rd, Nanjing, Peoples R China.
EM xichen_yang@njnu.edu.cn
OI Yang, Xichen/0000-0002-9949-4818
FU Natural Science Foundation of the Jiangsu Higher Education Institutions
   of China [20KJB510021]; National Natural Science Foundation of China
   [41971343]
FX This paper is supported by the Natural Science Foundation of the Jiangsu
   Higher Education Institutions of China (Grant No. 20KJB510021), the
   National Natural Science Foundation of China (Grant No. 62101268) and
   the National Natural Science Foundation of China (Grant No. 41971343).
CR Arora M, 2021, MULTIMED TOOLS APPL, V80, P3039, DOI 10.1007/s11042-020-09726-4
   Bansal M, 2021, SOFT COMPUT, V25, P4423, DOI 10.1007/s00500-020-05453-y
   Bansal M, 2021, ARCH COMPUT METHOD E, V28, P1147, DOI 10.1007/s11831-020-09409-1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Dargan S, 2020, ARCH COMPUT METHOD E, V27, P1071, DOI 10.1007/s11831-019-09344-w
   Ding L, 2017, IEEE T IMAGE PROCESS, V26, P1799, DOI 10.1109/TIP.2017.2665972
   Fang YM, 2018, IEEE T IMAGE PROCESS, V27, P1600, DOI 10.1109/TIP.2017.2781307
   Garg D, 2018, MULTIMED TOOLS APPL, V77, P26545, DOI 10.1007/s11042-018-5878-8
   Ghadiyaram D, 2016, IEEE T IMAGE PROCESS, V25, P372, DOI 10.1109/TIP.2015.2500021
   Gu K, 2020, IEEE T BROADCAST, V66, P127, DOI 10.1109/TBC.2019.2906768
   Gu K, 2018, IEEE T VIS COMPUT GR, V24, P2689, DOI 10.1109/TVCG.2017.2771284
   Gu K, 2017, IEEE T IMAGE PROCESS, V26, P4005, DOI 10.1109/TIP.2017.2711279
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2016, NEUROCOMPUTING, V196, P140, DOI 10.1016/j.neucom.2015.11.101
   Gupta S, 2021, ARCH COMPUT METHOD E, V28, P2209, DOI 10.1007/s11831-020-09452-y
   Hu B, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115839
   Hui J., 2008, 2008 IEEE C COMPUTER, P1
   Jabar F, 2020, IEEE J-STSP, V14, P49, DOI 10.1109/JSTSP.2019.2962970
   Karaali A, 2018, IEEE T IMAGE PROCESS, V27, P1126, DOI 10.1109/TIP.2017.2771563
   Ko H, 2020, IEEE T IMAGE PROCESS, V29, P5964, DOI 10.1109/TIP.2020.2987180
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kumar M, 2020, INT C COMP METH DAT
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P21557, DOI 10.1007/s11042-017-5587-8
   Lee D, 2016, IEEE T IMAGE PROCESS, V25, P3875, DOI 10.1109/TIP.2016.2579308
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu LX, 2019, IEEE T MULTIMEDIA, V21, P2305, DOI 10.1109/TMM.2019.2900941
   Liu Y, 2020, NEUROCOMPUTING, V405, P126, DOI 10.1016/j.neucom.2020.04.049
   Liu YT, 2020, IEEE T CIRC SYST VID, V30, P929, DOI 10.1109/TCSVT.2019.2900472
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Qin M, 2017, IET IMAGE PROCESS, V11, P443, DOI 10.1049/iet-ipr.2016.0411
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Sinno Z, 2018, IEEE T IMAGE PROCESS, V27, P3194, DOI 10.1109/TIP.2018.2817740
   Tang LJ, 2016, J VIS COMMUN IMAGE R, V40, P335, DOI 10.1016/j.jvcir.2016.07.007
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Wan ZL, 2020, IEEE T MULTIMEDIA, V22, P2024, DOI 10.1109/TMM.2019.2950533
   Wang SQ, 2016, IEEE J EM SEL TOP C, V6, P532, DOI 10.1109/JETCAS.2016.2598756
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu JJ, 2019, INFORM SCIENCES, V504, P487, DOI 10.1016/j.ins.2019.07.061
   Yan B, 2019, IEEE T MULTIMEDIA, V21, P2603, DOI 10.1109/TMM.2019.2904879
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   Yang XC, 2020, MULTIMED TOOLS APPL, V79, P22797, DOI 10.1007/s11042-020-09022-1
   Yang XC, 2020, IET IMAGE PROCESS, V14, P384, DOI 10.1049/iet-ipr.2019.0750
   Yue GH, 2019, IEEE T IND ELECTRON, V66, P3784, DOI 10.1109/TIE.2018.2851984
   Yue GH, 2018, IEEE T MULTIMEDIA, V20, P2722, DOI 10.1109/TMM.2018.2807589
   Zhan YB, 2017, IEEE T MULTIMEDIA, V19, P1837, DOI 10.1109/TMM.2017.2689923
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Y, 2018, IEEE T IMAGE PROCESS, V27, P5433, DOI 10.1109/TIP.2018.2857413
   Zhou ZX, 2020, IEEE T BIO-MED ENG, V67, P298, DOI 10.1109/TBME.2019.2912986
NR 58
TC 1
Z9 1
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5459
EP 5483
DI 10.1007/s11042-021-11788-x
EA DEC 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000733870800002
DA 2024-07-18
ER

PT J
AU Kuo, LW
   Chang, T
   Lai, CC
AF Kuo, Lungwen
   Chang, Tsuiyueh
   Lai, Chih-Chun
TI Application of visual colors in dynamic web page design through
   affective cognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HTML5; Design; Vision; Web; Color
ID ATTRACTIVENESS; ENHANCE
AB The visual language of a web page reflects its quality and emotion. Compared with static web page designs, dynamic web page designs enable easier reading and is more effective in attracting the attention of users. In this study, web pages were created using programs that applied three dynamic web page creation languages, namely HTML5, JavaScript, and CSS3. Moreover, the most suitable type of dynamic web page design was determined through experiments and analyses on diverse psychological feelings for web page composition and colors. Such experiments and analyses allow web page designers to understand users' psychological factors more easily for developing the most suitable visual design for dynamic web pages. This study involved three parts: (1) understanding the status of current dynamic web page design, collecting HTML5 dynamic home pages of websites, and conducting experiments and analyses on web page contents; (2) exploring feelings regarding the use of websites and identifying optimized styles of dynamic web page design according to the compositions and dynamic representations of web images; and (3) developing superior color schemes for dynamic web page design and providing a reference for applying colors to dynamic web page design. The research results indicated that the design covered entirely with carousel images when the home page remained static had the best visual effect, followed by the design containing carousel images and 1/10th area of blank space to the left and right sides of the images when the home page remained static. The affective adjective pair with the best fit in the experiments was difficult-convenient, followed by trivial-simple and annoying-favorite. The most popular color for dynamic web pages was dark royal blue (L46.8, A17.8, and B-66.7), followed by dark cyan (L36.2, A-39.9, and B40.8). The results obtained through experiments on dynamic web pages in this study serve as a reference for web designers and researchers to configure the composition and colors of dynamic web page design.
C1 [Kuo, Lungwen] Sanming Univ, Dept Prod Design, Sanming, Fujian, Peoples R China.
   [Chang, Tsuiyueh] Tzu Chi Acad, Dept Educ, Cupertino, CA 95014 USA.
   [Lai, Chih-Chun] Tatung Univ, Dept Ind Design, Taipei, Taiwan.
C3 Sanming University; Tatung University
RP Chang, T (corresponding author), Tzu Chi Acad, Dept Educ, Cupertino, CA 95014 USA.
EM yueh5031162@yahoo.com.tw
RI Kuo, Lungwen/AAV-1958-2021; lai, chih chun/AAE-6772-2021
OI Kuo, Lungwen/0000-0001-9894-2706; Lai, Chih-Chun/0000-0003-4261-6228
FU Sanming University; Fujian Province Science [FJ2021B190]; Research
   Foundation for Advanced Talents [21YG02S]
FX Sanming University. Research Foundation for Advanced Talents, Grant
   Number: 21YG02S. Supported by Fujian Province Science, Grant Number:
   FJ2021B190.
CR Azman Shahrul Azmeer, 2020, J ART DES REKA, V2, P17
   Berlyne DE., 1971, INFORM UNCERTAINTY R
   Birnbaum M.H., 2000, Psychological Experiments on the Internet, P3
   Bodrunova Svetlana S., 2017, Design, User Experience and Usability: Theory, Methodology and Management. 6th International Conference, DUXU 2017, held as part of HCI International 2017. Proceedings: LNCS 10288, P219, DOI 10.1007/978-3-319-58634-2_17
   Bonnardel N, 2011, DISPLAYS, V32, P69, DOI 10.1016/j.displa.2010.12.002
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Carrion B, 2019, MULTIMED TOOLS APPL, V78, P32919, DOI 10.1007/s11042-019-07880-y
   Cazenave F, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P43
   Cho Y., 2000, DESIGN PSYCHOL USER
   Demir Ü, 2020, COLOR RES APPL, V45, P871, DOI 10.1002/col.22522
   Deng, 2006, USABILITY AFFECT WEB
   DEREFELDT G, 1995, DISPLAYS, V16, P69, DOI 10.1016/0141-9382(95)91176-3
   Dianat I, 2019, APPL ERGON, V81, DOI 10.1016/j.apergo.2019.102892
   Eroglu SA, 2003, PSYCHOL MARKET, V20, P139, DOI 10.1002/mar.10064
   Furche Tim, 2012, WWW, P267
   Gasparini F, 2020, MULTIMED TOOLS APPL, V79, P35845, DOI 10.1007/s11042-020-09114-y
   Guan S.-S., 2002, J DES, V7, P59, DOI [10.6381/JD.200206.0059, DOI 10.6381/JD.200206.0059]
   Hashemi M, 2020, MULTIMED TOOLS APPL, V79, P11921, DOI 10.1007/s11042-019-08373-8
   Hu R, 2020, WORLD WIDE WEB, V23, P1441, DOI 10.1007/s11280-019-00746-1
   Jennings M., 2000, Proceedings of the 2000 ACM SIGCPR Conference, P77, DOI 10.1145/333334.333358
   Jeong SH., 2005, J Korean Soc Des Sci, V18, P69
   Johnson JA, 2019, CHI 19 P 2019 CHI C, V528, P1
   Kallio T, 2003, P 2003 INT C DES PLE
   Kang J, 2008, NCM 2008: 4TH INTERNATIONAL CONFERENCE ON NETWORKED COMPUTING AND ADVANCED INFORMATION MANAGEMENT, VOL 2, PROCEEDINGS, P290, DOI 10.1109/NCM.2008.170
   Kirschenbaum M, 2004, P 3 ANN WORKSH HCI R, P1
   Kovac A., 2019, Journal of Graphic Engineering and Design, V10, P13, DOI [10.24867/JGED-2019-1-013, DOI 10.24867/JGED-2019-1-013]
   Kravchenko A, 2019, WORLD WIDE WEB, V22, P1999, DOI 10.1007/s11280-018-0634-6
   Krishnan A, 2018, WORLD WIDE WEB, V21, P1041, DOI 10.1007/s11280-017-0468-7
   Kuo LW, 2021, COLOR RES APPL, V46, P1321, DOI 10.1002/col.22662
   Lin HY, 2014, DISPLAYS, V35, P202, DOI 10.1016/j.displa.2014.05.009
   Liu YL, 2003, ERGONOMICS, V46, P1293, DOI 10.1080/00140130310001610838
   Majumdar Arjun, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P259, DOI 10.1007/978-3-030-58539-6_16
   Mikkonen T, 2008, SERA 2008: 6TH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS, PROCEEDINGS, P319, DOI 10.1109/SERA.2008.16
   Musial K, 2013, WORLD WIDE WEB, V16, P31, DOI 10.1007/s11280-011-0155-z
   Nielsen J, 1993, USABILITY ENG, P224
   Oliva A, 2004, PROCEEDINGS OF THE TWENTY-SIXTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P1041
   Pak A., 2010, COMPUTER, P19, DOI DOI 10.17148/IJARCCE.2016.51274
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pollet TV, 2019, DISPLAYS, V56, P23, DOI 10.1016/j.displa.2018.10.008
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Rinaldi AM, 2021, MULTIMED TOOLS APPL, V80, P3885, DOI 10.1007/s11042-020-09761-1
   Rodriguez-Gil L, 2018, MULTIMED TOOLS APPL, V77, P6471, DOI 10.1007/s11042-017-4556-6
   RUBENS PM, 1986, J TECH WRIT COMMUN, V16, P73, DOI 10.2190/JQX6-EUB3-V1WA-JW74
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   Schubert TW, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0067769
   Shoumy NJ, 2020, J NETW COMPUT APPL, V149, DOI 10.1016/j.jnca.2019.102447
   Speriosu M., 2011, WORKSH UNS LEARN NLP, P53
   Sutcliffe A., 2003, HUM FAC ER, P245
   Theben A, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17061991
   Tractinsky N, 2006, INT J HUM-COMPUT ST, V64, P1071, DOI 10.1016/j.ijhcs.2006.06.009
   Tsou MH, 2017, LECT NOTES GEOINF CA, P85, DOI 10.1007/978-3-319-57336-6_7
   Vuorimaa P, 2016, WORLD WIDE WEB, V19, P519, DOI 10.1007/s11280-015-0339-z
   Wischenbart M, 2021, MULTIMED TOOLS APPL, V80, P6785, DOI 10.1007/s11042-020-09803-8
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Yue Ma, 2020, 2020 2nd International Conference on Information Technology and Computer Application (ITCA), P125, DOI 10.1109/ITCA52113.2020.00033
NR 56
TC 3
Z9 3
U1 9
U2 69
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4435
EP 4454
DI 10.1007/s11042-021-11732-z
EA DEC 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000728243800001
DA 2024-07-18
ER

PT J
AU Cheng, FM
   Yu, SH
   Chu, JJ
   Fan, JS
   Hu, YK
AF Cheng, Fangmin
   Yu, Suihuai
   Chu, Jianjie
   Fan, Jiashuang
   Hu, Yukun
TI Customer satisfaction-oriented product configuration approach based on
   online product reviews
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Product configuration; Customer satisfaction; Online product reviews;
   Quantified Kano model; Voice of customer
ID DESIGN; MODEL; REQUIREMENTS
AB Improving customer satisfaction (CS) is one of the core objectives of product configuration. Therefore, accurately analyzing customer opinions and generating appropriate product configuration schemes according to customer opinions are crucial to the success of product configuration. Online product review is a excellent and reliable customer opinion source. Therefore, this paper proposes a customer satisfaction-oriented product configuration approach based on online product reviews. First, this approach identifies critical requirements and quantifies CS degree by extracting and quantifying key elements in online product reviews. Then, the CS degree of the new component scheme is predicted based on the quantitative Kano model and the CS degree of the existing component schemes. Lastly, the single objective programming model is built to generate the product configuration scheme. The product configuration of a desktop 3D printer is taken as an example to verify the feasibility and effectiveness of the proposed approach. Compared with two approaches of customer data acquisition and customer collaboration, it is proved that this approach can effectively improve the CS degree of product configuration scheme, and significantly save the labor, time and cost of product configuration. This approach provides a novel product configuration approach for enterprises to improve CS and extends the application scope for online product review.
C1 [Cheng, Fangmin; Yu, Suihuai; Chu, Jianjie; Fan, Jiashuang; Hu, Yukun] Northwestern Polytech Univ, Shaanxi Engn Lab Ind Design, Xian, Peoples R China.
C3 Northwestern Polytechnical University
RP Cheng, FM (corresponding author), Northwestern Polytech Univ, Shaanxi Engn Lab Ind Design, Xian, Peoples R China.
EM chengfm1991@163.com
FU National Key Research and Development Program of China [2017YFB1104205]
FX The authors really appreciate the experts, designers and users who offer
   great help. This research was supported by the National Key Research and
   Development Program of China (No. 2017YFB1104205).
CR Carulli M, 2013, J INTELL MANUF, V24, P887, DOI 10.1007/s10845-012-0662-5
   Chen CB, 2008, J INTELL MANUF, V19, P577, DOI 10.1007/s10845-008-0131-3
   Cheng FM, 2021, J INTELL FUZZY SYST, V41, P1791, DOI 10.3233/JIFS-210564
   DESPONTIN M, 1984, EUR J OPER RES, V18, P277, DOI 10.1016/0377-2217(84)90196-6
   Dou RL, 2017, INT J PROD RES, V55, P3886, DOI 10.1080/00207543.2017.1316020
   Globocnik D, 2021, TECHNOVATION, V100, DOI 10.1016/j.technovation.2020.102187
   He LN, 2017, P I MECH ENG B-J ENG, V231, P699, DOI 10.1177/0954405415598894
   Jeong B, 2019, INT J INFORM MANAGE, V48, P280, DOI 10.1016/j.ijinfomgt.2017.09.009
   Jiao Y, 2019, J INTELL MANUF, V30, P2473, DOI 10.1007/s10845-018-1406-y
   Jiao Y, 2019, J INTELL MANUF, V30, P1291, DOI 10.1007/s10845-017-1324-4
   Jin J, 2016, ENG APPL ARTIF INTEL, V49, P61, DOI 10.1016/j.engappai.2015.12.005
   Jin J, 2016, ENG APPL ARTIF INTEL, V47, P38, DOI 10.1016/j.engappai.2015.05.006
   Lee J, 2020, MANAGE SCI, V66, P2120, DOI 10.1287/mnsc.2019.3306
   Lee YC, 2009, EXPERT SYST APPL, V36, P4479, DOI 10.1016/j.eswa.2008.05.034
   Li Z, 2020, INT J COMPUT INTEG M, V33, P670, DOI 10.1080/0951192X.2019.1571240
   Li Z, 2018, J ENG DESIGN, V29, P358, DOI 10.1080/09544828.2018.1471671
   Liu HF, 2014, KNOWL-BASED SYST, V56, P156, DOI 10.1016/j.knosys.2013.11.006
   Liu Y, 2019, DECIS SUPPORT SYST, V123, DOI 10.1016/j.dss.2019.113079
   Ostrosi E, 2010, INT J ADV MANUF TECH, V49, P13, DOI 10.1007/s00170-009-2397-9
   Qi JY, 2016, INFORM MANAGE-AMSTER, V53, P951, DOI 10.1016/j.im.2016.06.002
   Risdiyono, 2013, J INTELL MANUF, V24, P295, DOI 10.1007/s10845-011-0587-4
   Schweisfurth TG, 2019, RES POLICY, V48, P289, DOI 10.1016/j.respol.2018.08.018
   Shi YL, 2021, ADV ENG INFORM, V49, DOI 10.1016/j.aei.2021.101340
   Subramanian R, 2013, PROD OPER MANAG, V22, P36, DOI 10.1111/j.1937-5956.2012.01350.x
   Tan LB, 2019, INT J COMPUT INTEG M, V32, P253, DOI 10.1080/0951192X.2019.1571233
   Trentin A, 2012, INT J PROD ECON, V135, P850, DOI 10.1016/j.ijpe.2011.10.023
   Wang T, 2010, INT J QUAL RELIAB MA, V27, P173, DOI 10.1108/02656711011014294
   Wang Y, 2021, IEEE T IND INFORM, V17, P6192, DOI 10.1109/TII.2020.3043315
   Zhan JM, 2009, EXPERT SYST APPL, V36, P2107, DOI 10.1016/j.eswa.2007.12.039
   Zhang LL, 2014, INT J PROD RES, V52, P6381, DOI 10.1080/00207543.2014.942012
   Zhang LL, 2013, INT J PROD RES, V51, P465, DOI 10.1080/00207543.2011.652745
   Zhao SY, 2020, J INTELL MANUF, V31, P597, DOI 10.1007/s10845-019-01467-y
   Zheng P, 2017, J MANUF SYST, V43, P422, DOI 10.1016/j.jmsy.2017.03.010
   Zhou F, 2013, J INTELL MANUF, V24, P1047, DOI 10.1007/s10845-012-0673-2
NR 34
TC 6
Z9 6
U1 22
U2 161
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4413
EP 4433
DI 10.1007/s11042-021-11774-3
EA DEC 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000728243900001
DA 2024-07-18
ER

PT J
AU Xie, XX
   Wang, XC
   Wu, ZK
AF Xie, Xiaoxiao
   Wang, Xingce
   Wu, Zhongke
TI 3D face dense reconstruction based on sparse points using probabilistic
   principal component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D face reconstruction; Landmarks; Probabilistic principal component
   analysis; Learning-based method
AB Reconstructing 3D face from sparse points is an ill-posed problem. While there already exits available solutions addressing this problem, to our knowledge, we propose a better-performed approach which can robustly reconstruct fine 3D face shape. Our method includes two modules: face model establishment based on probabilistic principal component analysis (PPCA) trained in an unsupervised manner to learn transformation between landmarks and point cloud in their low-dimensional representation, and 3D face reconstruction based on learned relation between them to reconstruct fine face shape. Overall, our method considers the probability of face shape and learns more useful information of 3D face shape. We compare our method with 3 typical and state-of-the-art methods on 2 datasets and the effectiveness of our method is demonstrated generally. Further experiments on datasets with noise of different intensities show the stability of our method.
C1 [Xie, Xiaoxiao; Wang, Xingce; Wu, Zhongke] Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Xie, Xiaoxiao; Wang, Xingce; Wu, Zhongke] Beijing Normal Univ, Engn Res Ctr Virtual Real & Applicat, Beijing Key Lab Digital Preservat & Virtual Real, Minist Educ, Beijing 100875, Peoples R China.
C3 Beijing Normal University; Beijing Normal University
RP Wu, ZK (corresponding author), Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.; Wu, ZK (corresponding author), Beijing Normal Univ, Engn Res Ctr Virtual Real & Applicat, Beijing Key Lab Digital Preservat & Virtual Real, Minist Educ, Beijing 100875, Peoples R China.
EM zwu@bnu.edu.cn
FU National Natural Science Foundation of China [61972041, 62072045]; BRICS
   of China [2017YFE0100500]; National Key R&D Program of China
   [2017YFB1002604, 2017YFB1402105]
FX This work is partially supported by National Natural Science Foundation
   of China (No.61972041, No.62072045), the National Key Cooperation
   between the BRICS of China (No.2017YFE0100500), National Key R&D Program
   of China (No.2017YFB1002604, No.2017YFB1402105).
CR Aji OP, 2019, 2019 INT C COMP ENG, P1
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Chen YJ, 2020, IEEE T IMAGE PROCESS, V29, P8696, DOI 10.1109/TIP.2020.3017347
   Deng QQ, 2011, FORENSIC SCI INT, V208, P95, DOI 10.1016/j.forsciint.2010.11.011
   Duan FQ, 2015, NEUROCOMPUTING, V151, P674, DOI [10.1016/j.neucom.2014.04.989, 10.1016/j.neucom.2014.04.089]
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Ferrari Claudio, 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P320, DOI 10.1007/978-3-030-04375-9_27
   Geraci M, 2016, J ROY STAT SOC C, V65, P51, DOI 10.1111/rssc.12105
   Gruszczynski M, 2018, PURE APPL GEOPHYS, V175, P1841, DOI 10.1007/s00024-018-1856-3
   Gu Mengyang, 2020, J MACH LEARN RES, V21, P1
   Guo X, 2019, ARXIV190210859, DOI [10.48550/arXiv.1902.10859, DOI 10.48550/ARXIV.1902.10859]
   Hu XP, 2016, INT CONF ACOUST SPEE, P1651, DOI 10.1109/ICASSP.2016.7471957
   Hubert M, 2005, TECHNOMETRICS, V47, P64, DOI 10.1198/004017004000000563
   Jhanani R, 2020, MOBILE APPL HUMAN FA, P16
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Knothe R, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P637
   Liu F, 2016, LECT NOTES COMPUT SC, V9909, P545, DOI 10.1007/978-3-319-46454-1_33
   Liu P, 2020, P AS C COMP VIS
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Mredhula L, 2016, J MED IMAG HEALTH IN, V6, P194, DOI 10.1166/jmihi.2016.1602
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Shah SMS, 2017, PHYSICA A, V482, P796, DOI 10.1016/j.physa.2017.04.113
   Tekalp AM, 2000, SIGNAL PROCESS-IMAGE, V15, P387, DOI 10.1016/S0923-5965(99)00055-7
   Thomas D, 2020, ARXIV200410557
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Vaddi Radhesyam, 2020, Intelligent Systems Design and Applications. 18th International Conference on Intelligent Systems Design and Applications (ISDA 2018). Advances in Intelligent Systems and Computing (AISC 941), P863, DOI 10.1007/978-3-030-16660-1_84
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   WU CFJ, 1983, ANN STAT, V11, P95, DOI 10.1214/aos/1176346060
   Xiao Q, 2014, INT C PATT RECOG, P2257, DOI 10.1109/ICPR.2014.392
   Yi HW, 2019, PROC CVPR IEEE, P7655, DOI 10.1109/CVPR.2019.00785
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhong YC, 2020, IEEE INT CONF AUTOMA, P117, DOI 10.1109/FG47880.2020.00005
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 38
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2937
EP 2957
DI 10.1007/s11042-021-11707-0
EA NOV 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000716240000003
DA 2024-07-18
ER

PT J
AU Amna, M
   Imen, W
   Soulef, B
   Ezahra, SF
AF Amna, Maraoui
   Imen, Werda
   Soulef, Bouaafia
   Ezahra, Sayadi Fatma
TI Machine Learning-Based approaches to reduce HEVC intra coding unit
   partition decision complexity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Deep CNN; Online FSVM; Complexity reduction
ID VIDEO
AB The use of machine learning techniques to reduce recent video coding standards complexity such as High Efficiency Video Coding (HEVC) has received prominent attention. In fact, the fascinating HEVC standard coding efficiency gap is performed at the expense of dramatically increasing coding complexity. HEVC adopts a similar block-based hybrid video coding framework its predecessor H.264 Advanced Video Coding (H.264/AVC), but it provides a highly flexible hierarchy of unit representation, which includes three units: coding unit (CU), prediction unit (PU) and transform unit (TU). The recursive splitting of CU is content adaptive, which is one of the biggest differences compared to H.264/AVC. Adopting a large variety of coding unit (CU) sizes, the quadtree partition takes the lion's share of the HEVC encoding complexity, making it ever more challenging to use rigid traditional inference models to predict the efficient coding decisions. In this context, this paper investigates the resulting implications on both coding efficiency and encoding complexity, when using Fuzzy Support Vector Machine (FSVM) and convolutional Neural Network (CNN) models for partitioning in the HEVC intra-prediction. The first approach is an online FSVM-based algorithm designed to predict efficiently the CU partition module. The second one is a deep CNN method founded on a large-scale database of substantial CU partition training. Experimental results reveal that the proposed deep CNN approach, with 66.04% complexity reduction, outperforms the proposed online FSVM approach that achieves 45.33%. However, the FSVM with only 0.067% loss in coding efficiency compared to 1.69% engendered with the CNN, is considered as the approach that performs the best tradeoff between the compression efficiency and the complexity reduction when optimizing the HEVC complexity at all Intra configuration.
C1 [Amna, Maraoui; Soulef, Bouaafia] Fac Sci Monastir, Elect & Microelect Lab, Environm St, Monastir 5019, Tunisia.
   [Imen, Werda] Univ Sfax, Elect & Informat Technol Lab, Sfax, Tunisia.
   [Ezahra, Sayadi Fatma] Univ Sousse, Networked Objects Control & Commun Syst Lab, Sousse, Tunisia.
C3 Universite de Monastir; Universite de Sfax; Ecole Nationale dIngenieurs
   de Sfax (ENIS); Universite de Sousse
RP Amna, M (corresponding author), Fac Sci Monastir, Elect & Microelect Lab, Environm St, Monastir 5019, Tunisia.
EM maraouiamna@gmail.com
RI sayadi, fatma/AHC-0214-2022; Maraoui, Amna/AFS-0573-2022; Werda,
   Imen/AHB-9833-2022
OI Maraoui, Amna/0000-0002-0448-4378; Bouaafia, Soulef/0000-0003-0657-6900
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Amna M, 2021, 2020 10TH INTERNATIONAL SYMPOSIUM ON SIGNAL, IMAGE, VIDEO AND COMMUNICATIONS (ISIVC), DOI 10.1109/ISIVC49222.2021.9487529
   [Anonymous], 2012, P 2012 VISUAL COMMUN
   [Anonymous], 2012, JCTVCI0408
   Bjontegaard G, 2001, VCEGM33
   Bouaafia S, 2020, J REAL-TIME IMAGE PR, V17, P185, DOI 10.1007/s11554-019-00936-0
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Corrêa G, 2012, IEEE T CIRC SYST VID, V22, P1899, DOI 10.1109/TCSVT.2012.2223411
   Fernández DG, 2017, PROC SPIE, V10223, DOI 10.1117/12.2262604
   Fini MR, 2016, MULTIMED TOOLS APPL, V75, P7541, DOI 10.1007/s11042-015-2675-5
   Grellert M, 2019, IEEE T CIRC SYST VID, V29, P1741, DOI 10.1109/TCSVT.2018.2849941
   Hassan M, 2019, MULTIMED TOOLS APPL, V78, P32735, DOI 10.1007/s11042-018-6882-8
   Hosseini E, 2019, MULTIMED TOOLS APPL, V78, P11607, DOI 10.1007/s11042-018-6713-y
   JCT-VC, 2019, HM SOFTW
   Kuanar S, 2018, IEEE INT CONF MULTI
   Li TY, 2017, IEEE INT CON MULTI, P1255, DOI 10.1109/ICME.2017.8019316
   Lin CJ, 2002, IEEE T NEURAL NETWOR, V13, P1045, DOI 10.1109/TNN.2002.1031937
   Liu XG, 2019, IEEE T CIRC SYST VID, V29, P144, DOI 10.1109/TCSVT.2017.2777903
   Liu ZY, 2016, IEEE T IMAGE PROCESS, V25, P5088, DOI 10.1109/TIP.2016.2601264
   MALLIKARACHCHI T, 2014, IEEE INT CON MULTI, DOI DOI 10.1109/ICME.2014.6890319
   Moraes D, 2016, J VIS COMMUN IMAGE R, V38, P340, DOI 10.1016/j.jvcir.2016.03.007
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tsai AC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1587
   Wang C., 2018, ARXIV180703100
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiong J, 2014, IEEE T MULTIMEDIA, V16, P559, DOI 10.1109/TMM.2013.2291958
   Xiph.org, 2019, XIPH ORG VID TEST ME
   Xu M, 2018, IEEE T IMAGE PROCESS, V27, P5044, DOI 10.1109/TIP.2018.2847035
   Yin J, 2018, PROCEEDINGS OF 2018 THE 2ND INTERNATIONAL CONFERENCE ON VIDEO AND IMAGE PROCESSING (ICVIP 2018), P176, DOI 10.1145/3301506.3301527
   Zhang T, 2017, IEEE T CIRC SYST VID, V27, P1714, DOI 10.1109/TCSVT.2016.2556518
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhu LW, 2017, IEEE T BROADCAST, V63, P547, DOI 10.1109/TBC.2017.2711142
NR 35
TC 4
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2777
EP 2802
DI 10.1007/s11042-021-11678-2
EA NOV 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000714884800004
DA 2024-07-18
ER

PT J
AU Zhao, ZH
   Zhang, HG
AF Zhao, Zihao
   Zhang, Haigang
TI A localization method for stagnant water in city road traffic image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Road stagnant water; Weekly supervised localization; Grad CAM plus plus;
   ResNet
AB Stagnant water on roads has always been a major cause of traffic jams and accidents. Traditional urban waterlogging monitoring and warning system is mainly based on a large amount of historical data and predictive network, which has low accuracy and weak generalization ability. Considering the deep neural network algorithms have demonstrated strong capabilities in computer vision tasks such as object detection, we aim to apply them to road stagnant water detection. In this paper, a novel automatic stagnant water localization method under weak supervision based on visual image is proposed. First, the template matching method is applied to extract road information from the traffic image. Then, due to the complexity of data annotation, we locate stagnant water in image based on Class Activation Maps (CAM) mechanism, which is a weakly supervised method. The detection model consists of the ResNet-18 and the Grad-CAM++ mechanism. Finally, based on the heat map and template, we set a suitable threshold to segment stagnant water area in image. In the experiments, the precision and recall for road stagnant water classification by the proposed model are 99.39% and 99.60%, while the Intersection over Union (IoU) for stagnant water area segmentation is up to 63%. These show that our method is effective for road stagnant water localization.
C1 [Zhao, Zihao; Zhang, Haigang] Shenzhen Polytech, Guangdong Hong Kong Macao Greater Bay Area, Inst Appl Artificial Intelligence, Shenzhen, Guangdong, Peoples R China.
C3 Shenzhen Polytechnic University; Southern Medical University - China
RP Zhang, HG (corresponding author), Shenzhen Polytech, Guangdong Hong Kong Macao Greater Bay Area, Inst Appl Artificial Intelligence, Shenzhen, Guangdong, Peoples R China.
EM zih_zhao@163.com; zhg2018@sina.com
RI Zhao, ZiHao/KHT-4413-2024; Zhao, Zihao/GRF-5493-2022
FU National Natural Science Foundation of China [61806208, 62076166];
   General Higher Education Project of Guangdong Provincial Education
   Department [2020ZDZX3082]; Guangdong Provincial Rural Science and
   Technology Specialists Project [KPT20200220]; Shenzhen Science and
   Technology Program [RCBS20200714114940262]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61806208, 62076166), in part by the
   General Higher Education Project of Guangdong Provincial Education
   Department (Grant No. 2020ZDZX3082), in part by the Guangdong Provincial
   Rural Science and Technology Specialists Project (Grant No.
   KPT20200220), in part by the Shenzhen Science and Technology Program
   (Grand No. RCBS20200714114940262).
CR Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Chattopadhay Aditya, 2018, 2018 IEEE Winter Conference on Applications of Computer Vision (WACV). Proceedings, P839, DOI 10.1109/WACV.2018.00097
   Choudhury AD, 2012, INT CONF INTELL SYST, P274, DOI 10.1109/ISDA.2012.6416550
   Fan Q, 2020, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR42600.2020.00407
   Gupta A, 2017, 2017 19TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS (HPCC) / 2017 15TH IEEE INTERNATIONAL CONFERENCE ON SMART CITY (SMARTCITY) / 2017 3RD IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (DSS), P42, DOI 10.1109/HPCC-SmartCity-DSS.2017.6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang KX, 2019, 2019 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P182, DOI 10.1109/dicta47822.2019.8946068
   Janos V, 2018, 2018 SMART CITY SYMPOSIUM PRAGUE (SCSP)
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Krizhevsky A, 2012, C WORKSH NEUR INF PR, P1106
   Minghao Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12352, DOI 10.1109/CVPR42600.2020.01237
   Sandler Mark, 2018, IEEE C COMP VIS PATT, DOI [10.1109/CVPR.2018.00474, DOI 10.1109/CVPR.2018.00474]
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tagaris T, 2019, IEEE IMAGE PROC, P4514, DOI [10.1109/ICIP.2019.8803474, 10.1109/icip.2019.8803474]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HJ, 2020, Cambria Sinophone Wo, P111, DOI 10.1109/CVPRW50498.2020.00020
   Wang YY, 2016, I COMP CONF WAVELET, P171, DOI 10.1109/ICCWAMTIP.2016.8079831
   Xia JA, 2019, COMPUT ELECTRON AGR, V159, P59, DOI 10.1016/j.compag.2019.02.022
   Yang JF, 2019, IEEE ACCESS, V7, P28894, DOI 10.1109/ACCESS.2019.2902121
   Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x
   Zhang TY, 2019, IEEE T MULTIMEDIA, V21, P2930, DOI 10.1109/TMM.2019.2914870
   Zhang WT, 2016, 2016 INTERNATIONAL CONFERENCE ON SMART CITY AND SYSTEMS ENGINEERING (ICSCSE), P394, DOI [10.1109/ICSCSE.2016.0110, 10.1109/ICSCSE.2016.28]
   Zhang ZS, 2018, IEEE T VEH TECHNOL, V67, P10378, DOI [10.1109/TIE.2018.2835378, 10.1109/TVT.2018.2866828]
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 28
TC 2
Z9 2
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2453
EP 2466
DI 10.1007/s11042-021-11638-w
EA OCT 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000712714400001
DA 2024-07-18
ER

PT J
AU Kabe, GK
   Song, YQ
   Liu, Z
AF Kabe, Gedeon Kashala
   Song, Yuqing
   Liu, Zhe
TI FireNet-MLstm for classifying liver lesions by using deep features in CT
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Classification of liver lesions; Computed tomography
   (CT); Convolutional neural networks; Long short-term memory networks
   (LSTMs)
ID CLASSIFICATION
AB Nowadays working in the medical imaging domain remains a big challenge, since the collecting such datasets is so complex, deep learning techniques have accomplished great success in a diversity of applications across many disciplines. In current work, we have combined two novel neural networks for classifying liver lesions of Hepatocellular carcinoma, Metastases, Hemangiomas, and Healthy tissues. On the first model called FireNet, we have introduced fire modules to reduce the model size and the number of parameters for quick classification. The first part will be in charge of extracting spatial feature information. The second model called Modified Long Short-Term Memory (MLstm), the features extracted by the FireNet are then used for temporal information and prediction with a new loss function called G-loss. In order to improve the proposed FireNet-MLstm model, a new bias was added through the forget gate. The activation function and the hyperbolic tangent were also added, which increased prediction accuracy. The dataset used in this study was collected by searching for the medical records with HCC, MET, HEM, and Healthy tissues in Jiangbin Hospital, the affiliated hospital of Jiangsu University from 2015 to 2018, with 120 patients, 30 patients with one or multiple Hcc, 26 patients with one or multiple Hem, 23 patients with one or multiple Met and 41 Healthy with non-lesion. The final classification accuracy of the proposed FireNet-MLstm model was 91.2%.
C1 [Kabe, Gedeon Kashala; Song, Yuqing; Liu, Zhe] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University
RP Kabe, GK (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
EM gedeonkashala26@gmail.com; yqsong@ujs.edu.com; lzhe@ujs.edu.cn
OI Kashala Kabe, gedeon/0000-0002-5120-4105
FU National Nature Science Foundation of China [61976106, 61772242,
   61572239]; China Postdoctoral Science Foundation [2017M611737]; Six
   talent peaks project in Jiangsu Province [DZXX-122]; Key special
   projects of health and family planning science and technology in
   Zhenjiang City [SHW2017019]
FX This work was supported by the National Nature Science Foundation of
   China (61976106, 61772242, 61572239); China Postdoctoral Science
   Foundation (2017M611737); Six talent peaks project in Jiangsu Province
   (DZXX-122); Key special projects of health and family planning science
   and technology in Zhenjiang City (SHW2017019).
CR Alahmer H, 2016, PROCEDIA COMPUT SCI, V90, P80, DOI 10.1016/j.procs.2016.07.027
   [Anonymous], 2010, NESUG
   [Anonymous], 2017, DETECTION AIDED LIVE
   [Anonymous], 2019, The liver tumor segmentation benchmark (lits)
   Ben-Cohen A, 2016, LECT NOTES COMPUT SC, V10008, P77, DOI 10.1007/978-3-319-46976-8_9
   Chang YH, 2017, IEEE ENG MED BIO, P672, DOI 10.1109/EMBC.2017.8036914
   Chlebus G, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33860-7
   Christ Patrick Ferdinand, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P415, DOI 10.1007/978-3-319-46723-8_48
   Dai SZ, 2019, IEEE ACCESS, V7, P38287, DOI 10.1109/ACCESS.2019.2907000
   Diamant I, 2016, IEEE J BIOMED HEALTH, V20, P1585, DOI 10.1109/JBHI.2015.2478255
   Frid-Adar M, 2018, NEUROCOMPUTING, V321, P321, DOI 10.1016/j.neucom.2018.09.013
   Guo YM, 2018, MULTIMED TOOLS APPL, V77, P10251, DOI 10.1007/s11042-017-5443-x
   Han X., 2017, AUTOMATIC LIVER LESI, V44, P1408, DOI 10.1002/mp.12155
   Ho Y, 2020, IEEE ACCESS, V8, P4806, DOI 10.1109/ACCESS.2019.2962617
   Hoogi A, 2017, IEEE T MED IMAGING, V36, P781, DOI 10.1109/TMI.2016.2628084
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Janocha Katarzyna, 2017, Theor Found Mach Learn, DOI [DOI 10.4467/20838476SI.16.004.6185, 10.4467/20838476SI.16. 004.6185]
   Kabe GK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081237
   Li W., 2015, J COMPUT COMMUN, V3, P146, DOI DOI 10.4236/JCC.2015.311023
   Li XM, 2018, IEEE T MED IMAGING, V37, P2663, DOI 10.1109/TMI.2018.2845918
   Li ZF, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202167
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Miao S, 2016, IEEE T MED IMAGING, V35, P1352, DOI 10.1109/TMI.2016.2521800
   Novak J, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82214-3
   Organization WH., 2018, WORLD CANC REPORT
   Özyurt F, 2019, ARAB J SCI ENG, V44, P3173, DOI 10.1007/s13369-018-3454-1
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Ryerson AB, 2016, CANCER-AM CANCER SOC, V122, P1312, DOI 10.1002/cncr.29936
   Shahzadi I, 2018, IEEE EMBS CONF BIO, P633, DOI 10.1109/IECBES.2018.8626704
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Smagulova K, 2019, EUR PHYS J-SPEC TOP, V228, P2313, DOI 10.1140/epjst/e2019-900046-x
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang WB, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON DIGITAL MEDICINE AND IMAGE PROCESSING (DMIP 2018), P56, DOI 10.1145/3299852.3299860
   Wu KZ, 2014, OPTIK, V125, P4057, DOI 10.1016/j.ijleo.2014.01.114
   Wu ZX, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P461, DOI 10.1145/2733373.2806222
   Yasaka K, 2018, RADIOLOGY, V286, P899, DOI 10.1148/radiol.2017170706
NR 36
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1607
EP 1623
DI 10.1007/s11042-021-11411-z
EA OCT 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000704942000001
DA 2024-07-18
ER

PT J
AU Juang, LH
AF Juang, Li-Hong
TI Humanoid robots play chess using visual control
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Humanoid robot; Image processing; Kinematics; Playing chess
ID WALKING; DESIGN
AB This paper mainly considers the humanoid robot vision system and the type of its joint structure, and designs a set of effective planning strategies for the robots grabbing the chess pieces from the chess board and places them into the designated positions and ensures their success in the chess game. The core content of this paper is the design of the humanoid robot performing the operation of chess. The main procedure of the humanoid robot performing the operation of the next chess game is as follows: firstly, the image is acquired by the vision system mounted on the camera of the humanoid robot; secondly, the pixel position of the checkerboard corner point is obtained through the image processing; furthermore, a target position is set for the humanoid robot and then the improvement is performed to let it become more efficiencies. The monocular distance ranging algorithm is used to obtain the actual position of the corner point of the checkerboard. Finally, the robot kinematics accurately controls the humanoid robot to perform an operation of grabbing the chess to place the chess to the specified position successfully. The superiority of the proposed work is that it can be for various complex conditions. In the three-dimensional environment, the visual system of the NAO robot was firstly used to perceive its surrounding environment, and then the image processing technology was used to identify the chess position. The first general remark is that this work can be conceived as a good technological/engineering achievement.
C1 [Juang, Li-Hong] Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
RP Juang, LH (corresponding author), Lunghwa Univ Sci & Technol, Dept Elect Engn, 300,Sec 1,Wanshou Rd, Taoyuan 333326, Taiwan.
EM lipuu@qq.com
CR Chen ATY, 2016, PROCEEDINGS OF 2016 THE 2ND INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS, P11, DOI 10.1109/ICCAR.2016.7486689
   Christie Dennis Aprilla, 2017, INF COMP ICIC 2017 2
   Espiau B., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3996, DOI 10.1109/ROBOT.2000.845354
   Hu Y, 2016, ROBOT AUTON SYST, V85, P37, DOI 10.1016/j.robot.2016.08.013
   Kajita S., 2014, Introduction to humanoid robotics
   Kajita S, 2009, ADV ROBOTICS, V23, P1527, DOI 10.1163/016918609X12469692711804
   Kim JY, 2005, IEEE INT CONF ROBOT, P1431
   Lim, 2014, J I CONTROL, V20
   Massah BA, 2012, PROCEDIA ENGINEER, V41, P296, DOI 10.1016/j.proeng.2012.07.176
   Nefti-Meziani S, 2015, ROBOT AUTON SYST, V68, P129, DOI 10.1016/j.robot.2014.12.016
   Omarsdóttir FY, 2016, PROC CIRP, V53, P231, DOI 10.1016/j.procir.2016.07.002
   Park, 2005, MECH DESIGN HUMANOID
   Rofer, 2012, ROBOCUP ROBOT SOCCER, V107, P93
   Sajó L, 2011, INT J HUM-COMPUT ST, V69, P483, DOI 10.1016/j.ijhcs.2011.04.001
   Sakagami, 2015, HCI INT 2015, V2015, P645
   Shamsuddin S, 2012, PROCEDIA ENGINEER, V41, P1533, DOI 10.1016/j.proeng.2012.07.346
   Shamsuddin S, 2012, PROCEDIA ENGINEER, V41, P1448, DOI 10.1016/j.proeng.2012.07.334
   Singh AK, 2016, ROBOT AUTON SYST, V79, P108, DOI 10.1016/j.robot.2016.01.009
   Tong GF, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P984, DOI 10.1109/IROS.2009.5354813
NR 19
TC 3
Z9 3
U1 5
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1545
EP 1566
DI 10.1007/s11042-021-11636-y
EA OCT 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000703870700001
DA 2024-07-18
ER

PT J
AU Qiao, NZ
   Di, LM
AF Qiao, Nianzu
   Di, Lamei
TI An improved method of linear spectral clustering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subsampled; Accelerate; Superpixel segmentation; Manhattan distance;
   Non-convex images
ID SUPERPIXEL; SEGMENTATION; SHIFT; CUTS
AB Superpixel segmentation is a popular image preprocessing technology in image processing. Among the various methods used to calculate uniform superpixel, the performance of linear spectral clustering (LSC) is better than the state-of-the-art superpixel segmentation algorithms. However, this method is slow on images and has low accuracy on non-convex images. In order to improve this problem, we propose a subsampled clustering method that can accelerate LSC. Meanwhile, this paper presents an improved distance measurement method based on non-convex image features and Manhattan distance, which can achieve high accuracy on non-convex images. The proposed method is evaluated on the BSDS500 dataset. The experimental results confirmed that this method runs faster than LSC, and at the same time produces almost the same superpixel segmentation accuracy on the images. In addition, the proposed method improves the accuracy of superpixel segmentation on non-convex images.
C1 [Qiao, Nianzu] Tongji Univ, Coll Elect & Informat Engn, Shanghai, Peoples R China.
   [Di, Lamei] Xi An Jiao Tong Univ, Xian, Peoples R China.
C3 Tongji University; Xi'an Jiaotong University
RP Qiao, NZ (corresponding author), Tongji Univ, Coll Elect & Informat Engn, Shanghai, Peoples R China.
EM 504023705@qq.com
CR Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alexandre EB, 2015, SIBGRAPI, P337, DOI 10.1109/SIBGRAPI.2015.20
   [Anonymous], 2007, P IEEE COMP VIS PATT
   [Anonymous], 2008, IEEE INT C COMPUTER
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Belém FC, 2020, IEEE SIGNAL PROC LET, V27, P1440, DOI 10.1109/LSP.2020.3015433
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dhillon IS, 2007, IEEE T PATTERN ANAL, V29, P1944, DOI 10.1109/TP'AMI.2007.1115
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Feng HW, 2017, COMM COM INF SC, V771, P539, DOI 10.1007/978-981-10-7299-4_45
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Lakshmi, 2016, INT J ADV RES COMPUT, DOI 10.17148/IJARCCE.2016.51009
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P4199, DOI 10.1109/TIP.2016.2588329
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Qian X, 2019, VISUAL COMPUT, V35, P985, DOI 10.1007/s00371-019-01682-x
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tian ZQ, 2014, IET COMPUT VIS, V8, P16, DOI 10.1049/iet-cvi.2012.0189
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Wang H, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9030031
   Zhengqin L., 2015, PROC CVPR IEEE, P1356, DOI DOI 10.1109/CVPR.2015.7298741
   Zhu Lei, 2018, ASI C COMPUT VIS ACC, P540
NR 27
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1287
EP 1311
DI 10.1007/s11042-021-11459-x
EA SEP 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000701004000001
DA 2024-07-18
ER

PT J
AU Shrinivasa, SR
   Prabhakar, CJ
AF Shrinivasa, S. R.
   Prabhakar, C. J.
TI Scene image classification based on visual words concatenation of local
   and global features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene image classification; Speed up robust feature; Directional Binary
   Code; Image understanding; Similarity measure; Support Vector Machine
ID LATENT DIRICHLET ALLOCATION; TEXTURE; REPRESENTATION; SHAPE
AB In this paper, we present a novel framework for scene image classification, which depends on corresponding visual words concatenation of speeded up robust features (SURF) and Directional binary code (DBC) feature descriptor. Firstly, we use SURF feature descriptor as a local feature descriptor. The local feature descriptor captures very close visual appearance (distinct structure) among their visual contents representation of an image. Secondly, the DBC feature descriptor captures global features, where color-texture features are extracted from entire image. Then, visual words of local and global descriptors are build separately. The concatenated visual words are used to represent the training images and query image. The SVM classifier is used to classify training samples and a query image is classified based on the similarity between histograms of training samples and query image. We carried out experiments using the challenging scene datasets such as MIT scene, UIUC sports event, and MIT indoor scene datasets. The experimental results demonstrate that the proposed method outperforms compared to the existing scene image classification methods.
C1 [Shrinivasa, S. R.; Prabhakar, C. J.] Kuvempu Univ, Dept PG Studies & Res Comp Sci, Shimoga 577451, Karnataka, India.
C3 Kuvempu University
RP Prabhakar, CJ (corresponding author), Kuvempu Univ, Dept PG Studies & Res Comp Sci, Shimoga 577451, Karnataka, India.
EM srinivasa1991sri@gmail.com; psajjan@yahoo.com
RI Prabhakar, C. J./N-1058-2013
OI S R, Shrinivasa/0000-0002-0536-6699
CR Baig F, 2020, IJST-T ELECTR ENG, V44, P99, DOI 10.1007/s40998-019-00237-z
   Banerji S, 2013, NEUROCOMPUTING, V117, P173, DOI 10.1016/j.neucom.2013.02.014
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   FEIFEI L, 2010, COMPUTER VISION, V285
   HASSABALLAH M, 2010, IMAGE FEATURES DETEC
   He NJ, 2018, INT GEOSCI REMOTE SE, P3587, DOI 10.1109/IGARSS.2018.8517914
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hiremath PS, 2007, ADCOM 2007: PROCEEDINGS OF THE 15TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P780, DOI 10.1109/ADCOM.2007.21
   Jalab H. A., 2011, 2011 IEEE Conference on Open Systems, P32, DOI 10.1109/ICOS.2011.6079266
   Kabbai L, 2019, VISUAL COMPUT, V35, P679, DOI 10.1007/s00371-018-1503-0
   Kabbai L, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P151, DOI 10.1109/ATSIP.2016.7523086
   Kaljahi MA, 2019, MULTIMED TOOLS APPL, V78, P5791, DOI 10.1007/s11042-018-6151-x
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Lin L., 2009, IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI [DOI 10.1177/0040517509349789, DOI 10.1109/ICMSS.2009.5301348]
   Liu Shengzhong, 2019, J Cell Physiol, DOI 10.1002/jcp.28556
   MA J, 2014, COMPUT MATH METHODS
   Nagaraja, 2015, COMPUTER APPL INT J, V2, P13
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Qin JZ, 2010, PATTERN RECOGN, V43, P1874, DOI 10.1016/j.patcog.2009.11.009
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rahman MM, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0178-1
   Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69
   Shawe-Taylor, 2009, LECT NOTES
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sleit A, 2011, KSII T INTERNET INF, V5, P211, DOI 10.3837/tiis.2011.01.012
   Thontadari C, 2017, INT J COMPUT SCI INF, DOI 10.5121/ijcsit.2017.9406
   Tsai, 2012, BAG OF WORDS REPRESE
   Vaduva C, 2013, IEEE T GEOSCI REMOTE, V51, P2770, DOI 10.1109/TGRS.2012.2219314
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   van de Sande KEA, 2011, IEEE T MULTIMEDIA, V13, P60, DOI 10.1109/TMM.2010.2091400
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zhong YF, 2015, IEEE T GEOSCI REMOTE, V53, P6207, DOI 10.1109/TGRS.2015.2435801
   Zou JY, 2016, INFORM SCIENCES, V348, P209, DOI 10.1016/j.ins.2016.02.021
NR 35
TC 10
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1237
EP 1256
DI 10.1007/s11042-021-11354-5
EA SEP 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000701004100001
DA 2024-07-18
ER

PT J
AU Srinivasan, K
   Rathee, G
   Raja, MR
   Jaglan, N
   Mahendiran, TV
   Palaniswamy, T
AF Srinivasan, K.
   Rathee, Geetanjali
   Raja, M. Ramkumar
   Jaglan, Naveen
   Mahendiran, T., V
   Palaniswamy, Thangam
TI Secure multimedia data processing scheme in medical applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia process; Healthcare security; Record storage; Trusted
   frameworks; Security schemes
ID PRIVACY
AB People communicate in a variety of ways via multimedia through the propagation of various techniques. Nowadays, variety of multimedia frameworks or techniques is used in various applications such as industries, software processing, vehicles and medical systems. The usage of multimedia frameworks in healthcare systems makes it possible to process, record and store huge amount of information generated by various medical records. However, the processing and management of huge records of every individual lead to overload the security risk and human efforts. The aim of this paper is to propose a secure and efficient technique that helps the medical organizations to process every record of individuals in a secure and efficient way. The proposed mechanism is validated against various security and processing metrics over conventional mechanisms such as Response Time, Message Alteration Record, Trusted Classification Accuracy and Record Accuracy. The analyzed results claim the significant improvement of proposed mechanism as compare to other schemes.
C1 [Srinivasan, K.] Sri Krishna Coll Technol, Dept ECE, Coimbatore, Tamil Nadu, India.
   [Rathee, Geetanjali] Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Dwarka Sect 3, New Delhi 110078, India.
   [Raja, M. Ramkumar] King Khalid Univ, Dept Elect Engn, Abha, Saudi Arabia.
   [Jaglan, Naveen] Jaypee Univ Informat Technol, Dept Elect & Commun Engn, Solan 173234, HP, India.
   [Mahendiran, T., V; Palaniswamy, Thangam] King Abdulaziz Univ, Fac Engn, Dept Elect & Comp Engn, Jeddah, Saudi Arabia.
C3 Netaji Subhas University of Technology; King Khalid University; Jaypee
   University of Information Technology; King Abdulaziz University
RP Rathee, G (corresponding author), Netaji Subhas Univ Technol, Dept Comp Sci & Engn, Dwarka Sect 3, New Delhi 110078, India.
EM k.srinivasan@skct.edu.in; geetanjali.rathee123@gmail.com;
   rmanoharan@kku.edu.sa; naveenjaglan1@gmail.com; mvellingiri@kau.edu.sa;
   tswamy@kau.edu
RI K, SRINIVASAN/T-6808-2019; Vellingiri, mahendiran/AAP-5803-2020; raja,
   ramkumar/AAU-2234-2021; m, ramkumarraja/GRO-5996-2022; Palaniswamy,
   Thangam/B-8547-2016; Rathee, Geetanjali/C-8186-2018; Jaglan,
   Naveen/C-5822-2018
OI Vellingiri, mahendiran/0000-0001-9347-6881; raja,
   ramkumar/0000-0001-9528-3207; Palaniswamy, Thangam/0000-0002-8642-5266;
   Rathee, Geetanjali/0000-0002-4761-1912; Jaglan,
   Naveen/0000-0003-3521-671X
CR Al-Muhtadi J, 2019, HEALTH INFORM J, V25, P315, DOI 10.1177/1460458217706184
   Bourbakis N, 2009, 2009 16 INT C DIG SI, P1
   Coatrieux G, 2006, 1ST TRANSDISCIPLINARY CONFERENCE ON DISTRIBUTED DIAGNOSIS AND HOME HEALTHCARE, CONFERENCE PROCEEDINGS, P156, DOI 10.1109/DDHH.2006.1624820
   Coventry L, 2018, MATURITAS, V113, P48, DOI 10.1016/j.maturitas.2018.04.008
   Dimoulas CA, 2016, IEEE T MULTIMEDIA, V18, P1969, DOI 10.1109/TMM.2016.2594148
   Hassan MM, 2017, FUTURE GENER COMP SY, V66, P48, DOI 10.1016/j.future.2015.12.016
   Hathaliya JJ, 2020, COMPUT COMMUN, V153, P311, DOI 10.1016/j.comcom.2020.02.018
   Jalali MS, 2019, J MED INTERNET RES, V21, DOI 10.2196/12644
   Khan FA, 2020, SUSTAIN CITIES SOC, V55, DOI 10.1016/j.scs.2020.102018
   Kundur D, 2008, P IEEE, V96, P112, DOI 10.1109/JPROC.2007.909914
   Liu W, 2017, AIP CONF PROC, V1794, DOI 10.1063/1.4971938
   Magana AJ, 2014, COMPUT EDUC, V72, P367, DOI 10.1016/j.compedu.2013.11.012
   Manogaran G, 2018, FUTURE GENER COMP SY, V82, P375, DOI 10.1016/j.future.2017.10.045
   Mansfield-Devine Steve, 2017, Network Security, V2017, P14, DOI 10.1016/S1353-4858(17)30062-4
   Marwan M, 2016, INT CONF MULTIMED, P366, DOI 10.1109/ICMCS.2016.7905649
   Muzammal SM, 2018, IEEE ACCESS, V6, P20722, DOI 10.1109/ACCESS.2018.2826225
   Rathee G, 2021, IEEE T IND INFORM, V17, P4270, DOI 10.1109/TII.2020.3005252
   Rathee G, 2021, J AMB INTEL HUM COMP, V12, P533, DOI 10.1007/s12652-020-02017-8
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Raveendran VR, 2015, U.S. Patent, Patent No. [9,197,912, 9197912]
   Sudha G, 2013, 2013 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P433, DOI 10.1109/iccsp.2013.6577090
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Valtolina S, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P214, DOI 10.1109/MMMC.2005.36
   Walker-Roberts S, 2018, IEEE ACCESS, V6, P25167, DOI 10.1109/ACCESS.2018.2817560
NR 24
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9079
EP 9090
DI 10.1007/s11042-021-11481-z
EA SEP 2021
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000695787100001
DA 2024-07-18
ER

PT J
AU Sanket, S
   Sarobin, MVR
   Anbarasi, LJ
   Thakor, J
   Singh, U
   Narayanan, S
AF Sanket, Shashwat
   Sarobin, M. Vergin Raja
   Anbarasi, L. Jani
   Thakor, Jayraj
   Singh, Urmila
   Narayanan, Sathiya
TI Detection of novel coronavirus from chest X-rays using deep
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deep-CNN; COVID-19 detection; X-rays
ID COVID-19
AB With over 172 Million people infected with the novel coronavirus (COVID-19) globally and with the numbers increasing exponentially, the dire need of a fast diagnostic system keeps on surging. With shortage of kits, and deadly underlying disease due to its vastly mutating and contagious properties, the tired physicians need a fast diagnostic method to cater the requirements of the soaring number of infected patients. Laboratory testing has turned out to be an arduous, cost-ineffective and requiring a well-equipped laboratory for analysis. This paper proposes a convolutional neural network (CNN) based model for analysis/detection of COVID-19, dubbed as CovCNN, which uses the patient's chest X-ray images for the diagnosis of COVID-19 with an aim to assist the medical practitioners to expedite the diagnostic process amongst high workload conditions. In the proposed CovCNN model, a novel deep-CNN based architecture has been incorporated with multiple folds of CNN. These models utilize depth wise convolution with varying dilation rates for efficiently extracting diversified features from chest X-rays. 657 chest X-rays of which 219 were X-ray images of patients infected from COVID-19 and the remaining were the images of non-COVID-19 (i.e. normal or COVID-19 negative) patients. Further, performance evaluation on the dataset using different pre-trained models has been analyzed based on the loss and accuracy curve. The experimental results show that the highest classification accuracy (98.4%) is achieved using the proposed CovCNN model.
C1 [Sanket, Shashwat; Sarobin, M. Vergin Raja; Anbarasi, L. Jani; Thakor, Jayraj; Singh, Urmila] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Narayanan, Sathiya] Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Vellore Institute of
   Technology (VIT); VIT Chennai
RP Narayanan, S (corresponding author), Vellore Inst Technol, Sch Elect Engn, Chennai, Tamil Nadu, India.
EM sathiyanarayanan.s@vit.ac.in
RI l, j/JVZ-8480-2024; L, J/JEF-9564-2023
OI L, JANI ANBARASI/0000-0002-8904-2236; Sekar, Sathiya
   Narayanan/0000-0001-8064-7442
CR Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Apostolopoulos ID, 2020, J MED BIOL ENG, V40, P462, DOI 10.1007/s40846-020-00529-4
   Ardakani AA, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103795
   Balas ValentinaEmilia., 2020, Recent Trends and Advances in Artificial Intelligence and Internet of Things
   Bi QF, 2020, LANCET INFECT DIS, V20, P911, DOI 10.1016/S1473-3099(20)30287-5
   Fang YC, 2020, RADIOLOGY, V295, P208, DOI [10.1148/2020200280, 10.1148/radiol.2020200280]
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Fukushima K., 2007, Scholarpedia, V2, P1717, DOI DOI 10.4249/SCHOLARPEDIA.1717
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   HUBEL DH, 1970, J PHYSIOL-LONDON, V206, P419, DOI 10.1113/jphysiol.1970.sp009022
   Kaburlasos VG, 2000, NEURAL NETWORKS, V13, P1145, DOI 10.1016/S0893-6080(00)00074-5
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Li L, 2020, RADIOLOGY, V296, pE65, DOI 10.1148/radiol.2020200905
   Liu KC, 2020, EUR J RADIOL, V126, DOI 10.1016/j.ejrad.2020.108941
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Narin A, 2021, PATTERN ANAL APPL, V24, P1207, DOI 10.1007/s10044-021-00984-y
   Ohata EF, 2021, IEEE-CAA J AUTOMATIC, V8, P239, DOI 10.1109/JAS.2020.1003393
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Panwar H, 2020, CHAOS SOLITON FRACT, V138, DOI 10.1016/j.chaos.2020.109944
   Sethy PK, 2020, INT J MATH ENG MANAG, V5, P643, DOI 10.33889/IJMEMS.2020.5.4.052
   Singh D, 2020, EUR J CLIN MICROBIOL, V39, P1379, DOI 10.1007/s10096-020-03901-z
   Song Y, 2020, GUT, V69, P1143, DOI 10.1136/gutjnl-2020-320891
   Song YZ, 2022, IEEE T INTELL TRANSP, V23, P12287, DOI 10.1109/TITS.2021.3112458
   Sousa RT, 2013, PROCEDIA COMPUT SCI, V18, P2579, DOI 10.1016/j.procs.2013.05.444
   Tuncer T, 2020, CHEMOMETR INTELL LAB, V203, DOI 10.1016/j.chemolab.2020.104054
   Venkatesan R., 2017, Convolutional neural networks in visual computing: a concise guide, DOI DOI 10.4324/9781315154282
   Wang JZ, 2018, PEER PEER NETW APPL, V11, P679, DOI 10.1007/s12083-017-0556-6
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang S, 2021, EUR RADIOL, V31, P6096, DOI [10.1080/1064119X.2021.1966557, 10.1079/9781789246070.0001, 10.1007/s00330-021-07715-1]
   Wang SH, 2021, INFORM FUSION, V68, P131, DOI 10.1016/j.inffus.2020.11.005
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zou LR, 2020, NEW ENGL J MED, V382, P1177, DOI [10.1056/NEJMc2001737, 10.1148/radiol.2020200463]
NR 33
TC 9
Z9 9
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22263
EP 22288
DI 10.1007/s11042-021-11257-5
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000695537100003
PM 34512112
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Martínez-Colón, A
   Viciana-Abad, R
   Perez-Lorenzo, JM
   Evers, C
   Naylor, PA
AF Martinez-Colon, Antonio
   Viciana-Abad, Raquel
   Perez-Lorenzo, Jose Manuel
   Evers, Christine
   Naylor, Patrick A.
TI An audio enhancement system to improve intelligibility for
   social-awareness in HRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Beamforming; ASR; Array; Masking; Intelligibility
ID MOVING SOUND SOURCES; LOCALIZATION; SEPARATION; SPEECH
AB Improving the ability to interact through voice with a robot is still a challenge especially in real environments where multiple speakers coexist. This work has evaluated a proposal based on improving the intelligibility of the voice information that feeds an existing ASR service in the network and in conditions similar to those that could occur in a care centre for the elderly. The results indicate the feasibility and improvement of a proposal based on the use of an embedded microphone array and the use of a simple beamforming and masking technique. The system has been evaluated with 12 people and results obtained for time responsiveness indicate that the system would allow natural interaction with voice. It is shown to be necessary to incorporate a system to properly employ the masking algorithm, through the intelligent and stable estimation of the interfering signals. In addition, this approach allows to fix as sources of interest other speakers not located in the vicinity of the robot.
C1 [Martinez-Colon, Antonio; Viciana-Abad, Raquel; Perez-Lorenzo, Jose Manuel] Univ Jaen, Jaen, Spain.
   [Evers, Christine] Univ Southampton, Southampton, Hants, England.
   [Naylor, Patrick A.] Imperial Coll London, London, England.
C3 Universidad de Jaen; University of Southampton; Imperial College London
RP Viciana-Abad, R (corresponding author), Univ Jaen, Jaen, Spain.
EM amcolon@ujaen.es; rviciana@ujaen.es; jmperez@ujaen.es;
   c.evers@soton.ac.uk; p.naylor@imperial.ac.uk
RI Perez Lorenzo, Jose Manuel/H-1694-2015; Viciana Abad, Raquel/A-3258-2013
OI Perez Lorenzo, Jose Manuel/0000-0002-5286-8026; Evers,
   Christine/0000-0003-0757-5504; Naylor, Patrick/0000-0001-8546-8013;
   Viciana Abad, Raquel/0000-0003-2545-7229
FU Spanish Ministry of Science, Innovation and University; 
   [TEST-RTI2018-099522-A-C44];  [AT17-5509-UMA]
FX This work has been funded by the National Research Project
   TEST-RTI2018-099522-A-C44': "Test-beds for the Evaluation of Social
   Awareness in Assistance Robotics" and thanks to the collaboration with
   CSP group at Imperial College London, funded by the Spanish Ministry of
   Science, Innovation and University through the lectures mobility program
   (Jose Castillejo's 2018 grant). Most of the information about the
   typical life in a retirement house and Felipe's robot name have been
   gathered from the experiences during the work developed in Vitalia
   Teatinos and supported by the Regional Project AT17-5509-UMA 'ROSI'.
CR Becker E., 2009, P 2 INT C PERVSIVE T, P1, DOI DOI 10.1145/1579114.1579131
   Biocca F, 1997, SECOND INTERNATIONAL CONFERENCE ON COGNITIVE TECHNOLOGY, PROCEEDINGS, P12, DOI 10.1109/CT.1997.617676
   Chakrabarty S, 2019, IEEE J-STSP, V13, P8, DOI 10.1109/JSTSP.2019.2901664
   Chang XK, 2019, 2019 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU 2019), P237, DOI [10.1109/asru46091.2019.9003986, 10.1109/ASRU46091.2019.9003986]
   DiBiase J. H., 2001, MICROPHONE ARRAYS SI
   Evers C, 2018, IEEE-ACM T AUDIO SPE, V26, P1484, DOI 10.1109/TASLP.2018.2828321
   Evers C, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1206, DOI 10.1109/ICDSP.2015.7252071
   Garnerin Mahault, 2019, 1 INT WORKSHOP AI SM, P3
   GRIFFITHS LJ, 1982, IEEE T ANTENN PROPAG, V30, P27, DOI 10.1109/TAP.1982.1142739
   Kennedy J, 2017, ACMIEEE INT CONF HUM, P82, DOI 10.1145/2909824.3020229
   Kriegel Johannes, 2019, Stud Health Technol Inform, V260, P178
   Lazzeri N, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8020302
   Lim H, 2015, IEEE T CONSUM ELECTR, V61, P112, DOI 10.1109/TCE.2015.7064118
   Lin R., 2020, IMPROVED ROBUST ASR
   Martínez J, 2018, IEEE ROMAN, P820, DOI 10.1109/ROMAN.2018.8525818
   Martinez-Colon Antonio, 2021, Advances in Physical Agents. Proceedings of the 21st International Workshop of Physical Agents (WAF 2020). Advances in Intelligent Systems and Computing (AISC 1285), P151, DOI 10.1007/978-3-030-62579-5_11
   Matamoros M, 2019, LECT NOTES ARTIF INT, V11374, P217, DOI 10.1007/978-3-030-27544-0_18
   MILLER GA, 1947, PSYCHOL BULL, V44, P105, DOI 10.1037/h0055960
   Morgan JP., 2017, TIME FREQUENCY MASKI
   Nikunen J, 2018, IEEE-ACM T AUDIO SPE, V26, P281, DOI 10.1109/TASLP.2017.2774925
   Okuno HG, 2011, SPRINGER TRAC ADV RO, V70, P227
   Pavlidi D, 2012, INT CONF ACOUST SPEE, P2625, DOI 10.1109/ICASSP.2012.6288455
   Rascon C, 2017, ROBOT AUTON SYST, V96, P184, DOI 10.1016/j.robot.2017.07.011
   Rascon C, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0055-8
   Reche-Lopez P, 2018, ENG APPL ARTIF INTEL, V69, P137, DOI 10.1016/j.engappai.2017.12.013
   Reche-Lopez P., 2018, P 19 INT WORKSH PHYS, DOI [10.1007/978-3-319-99885-5_12, DOI 10.1007/978-3-319-99885-5_12]
   Takeda R, 2016, IEEE W SP LANG TECH, P603, DOI 10.1109/SLT.2016.7846325
   Valin JM, 2007, IEEE T ROBOT, V23, P742, DOI 10.1109/TRO.2007.900612
   Valin JM, 2004, IEEE INT CONF ROBOT, P1033, DOI 10.1109/ROBOT.2004.1307286
   Wang C., 2009, P 2009 IEEE RSJ INT
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Zhuo DB, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11010445
NR 32
TC 1
Z9 1
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3327
EP 3350
DI 10.1007/s11042-021-11291-3
EA AUG 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000690714100001
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Kang, J
   Gwak, J
AF Kang, Jaeyong
   Gwak, Jeonghwan
TI Ensemble of multi-task deep convolutional neural networks using transfer
   learning for fruit freshness classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Ensemble learning; Fruit freshness classification;
   Machine learning; Multi-task learning; Transfer learning
ID SENTIMENT ANALYSIS; SPEECH EMOTION; FEATURES; VISION; FUSION
AB Automatic classification of fruit freshness plays an important role in the agriculture industry. In this work, we propose an ensemble model that combines the bottleneck features of two multi-task deep convolutional neural networks with different architectures (ResNet-50 and ResNet-101). In our proposed multi-tasking framework, there are two classification branches: a binary classifier to distinguish between fresh and rotten fruits, and a multi-class label classifier to identify the kind of fruit. Since the features (e.g., color, texture, and shape) of rotten fruits are different from each other depending on the kind of fruit, the input of the first branch is combined with the kind of fruit information from the second branch to classify the fruit freshness more accurately. Transfer learning technique has been applied during the model training since transfer learning has been shown to be effective transfer learning has been shown to be effective in many applications in which training data for the target problem are limited. To evaluate our proposed model, we use simple images from the existing dataset and real-world images crawled from the web, both representing fresh and rotten fruits for different fruit categories as our dataset. Our proposed model achieved average accuracies of 98.50% and 97.43% for freshness classification and fruit classification, respectively, demonstrating that our transfer learning-based ensemble model outperforms other transfer learning-based models.
C1 [Kang, Jaeyong; Gwak, Jeonghwan] Korea Natl Univ Transportat, Dept Software, Chungju 27469, South Korea.
   [Gwak, Jeonghwan] Korea Natl Univ Transportat, Dept AI Robot Engn, Chungju 27469, South Korea.
   [Gwak, Jeonghwan] Korea Natl Univ Transportat, Dept Biomed Engn, Chungju 27469, South Korea.
   [Gwak, Jeonghwan] Korea Natl Univ Transportat, Dept IT Energy Convergence BK21 FOUR, Chungju 27469, South Korea.
C3 Korea National University of Transportation; Korea National University
   of Transportation; Korea National University of Transportation; Korea
   National University of Transportation
RP Gwak, J (corresponding author), Korea Natl Univ Transportat, Dept Software, Chungju 27469, South Korea.; Gwak, J (corresponding author), Korea Natl Univ Transportat, Dept AI Robot Engn, Chungju 27469, South Korea.; Gwak, J (corresponding author), Korea Natl Univ Transportat, Dept Biomed Engn, Chungju 27469, South Korea.; Gwak, J (corresponding author), Korea Natl Univ Transportat, Dept IT Energy Convergence BK21 FOUR, Chungju 27469, South Korea.
EM kjysmu@gmail.com; jgwak@ut.ac.kr
OI Gwak, Jeonghwan/0000-0002-6237-0141; Kang, Jaeyong/0000-0003-1211-2678
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2020R1I1A3074141]; NRF - Ministry of Science, ICT and Future
   Planning [NRF-2019M3C7A1020406]; NRF - Ministry of Education
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (Grant No. NRF-2020R1I1A3074141), the Brain Research
   Program through the NRF funded by the Ministry of Science, ICT and
   Future Planning (Grant No. NRF-2019M3C7A1020406), and Regional
   Innovation Strategy (RIS) through the NRF funded by the Ministry of
   Education.
CR Akçay S, 2016, IEEE IMAGE PROC, P1057, DOI 10.1109/ICIP.2016.7532519
   Akhtar MS, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P370
   Al-Twairesh N, 2019, IEEE ACCESS, V7, P84122, DOI 10.1109/ACCESS.2019.2924314
   Albawi S, 2017, I C ENG TECHNOL
   Altaheri H, 2019, IEEE ACCESS, V7, P117115, DOI 10.1109/ACCESS.2019.2936536
   Ananthanarayana T., 2020, ELECT IMAGING, V12, P172, DOI DOI 10.2352/ISSN.2470-1173.2020.12.FAIS-172
   Baltruschat IM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-42294-8
   Calisto MGB, 2021, PROC SPIE, V11313, DOI 10.1117/12.2543810
   Calisto MB, NEURAL NETWORK
   Caruana R, 1997, MACH LEARN, V28, P41, DOI 10.1023/A:1007379606734
   Christodoulidis S, 2017, IEEE J BIOMED HEALTH, V21, P76, DOI 10.1109/JBHI.2016.2636929
   Corchs S, 2019, INT J MACH LEARN CYB, V10, P2057, DOI 10.1007/s13042-017-0734-0
   Devlin J., 2018, BERT PRE TRAINING DE
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   Gómez-Sanchis J, 2012, EXPERT SYST APPL, V39, P780, DOI 10.1016/j.eswa.2011.07.073
   Goyal M, 2019, ARXIV PREPRINT ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Phan HT, 2020, IEEE ACCESS, V8, P14630, DOI 10.1109/ACCESS.2019.2963702
   Jimenez-Moreno, 2018, INT J APPL ENG RES, P12846
   Kang J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062222
   Kang J, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8101652
   Kang J, 2019, IEEE ACCESS, V7, P26440, DOI 10.1109/ACCESS.2019.2900672
   Kang J, 2019, J INTELL INF SYST, V52, P191, DOI 10.1007/s10844-018-0534-3
   Khoong W.H., 2020, ARXIV PREPRINT ARXIV
   Krizhevsky A., 2014, ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee HY, 2013, INTERSPEECH, P215
   López M, 2019, INFORM SCIENCES, V480, P273, DOI 10.1016/j.ins.2018.12.038
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Majumder N, 2019, IEEE INTELL SYST, V34, P38, DOI 10.1109/MIS.2019.2904691
   Minaee S., 2019, Deep-emotion: Facial expression recognition using attentional convolutional network
   Nguyen H.H., 2019, ARXIV PREPRINT ARXIV
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Prasomphan S, 2017, INT C BIG DAT TECHN, P66
   Ren Y, 2016, IEEE COMPUT INTELL M, V11, P41, DOI 10.1109/MCI.2015.2471235
   Rocha A, 2010, COMPUT ELECTRON AGR, V70, P96, DOI 10.1016/j.compag.2009.09.002
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Semary NA, 2015, ADV INTELL SYST, V323, P401, DOI 10.1007/978-3-319-11310-4_35
   Sifre Laurent, 2014, ARXIV14031687, P1, DOI [10.48550/arXiv.1403.1687, DOI 10.48550/ARXIV.1403.1687]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Shiksha, 2019, Recent Trends in Communication, Computing, and Electronics. Select Proceedings of IC3E 2018. Lecture Notes in Electrical Engineering (LNEE 524), P377, DOI 10.1007/978-981-13-2685-1_36
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   TAO F, 2018, 2018 1 AS C AFF, pNIL49
   Turkan M, 2020, P 2019 INN INT SYST, P1
   Wang LJ, 2014, 2014 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES, AND DEVICE APPLICATIONS (SPAWDA), P44, DOI 10.1109/SPAWDA.2014.6998522
   Wen GH, 2017, COGN COMPUT, V9, P597, DOI 10.1007/s12559-017-9472-6
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang H, 2018, IEEE T SEMICONDUCT M, V31, P116, DOI 10.1109/TSM.2017.2777499
   Yu J, 2015, INT CONF CONTR AUTO, P113, DOI 10.1109/ICCAIS.2015.7338643
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhang YD, 2012, SENSORS-BASEL, V12, P12489, DOI 10.3390/s120912489
   Zvarevashe K, 2020, ALGORITHMS, V13, DOI 10.3390/a13030070
NR 60
TC 26
Z9 26
U1 8
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22355
EP 22377
DI 10.1007/s11042-021-11282-4
EA AUG 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000687926200006
DA 2024-07-18
ER

PT J
AU Karimi, M
   Nejati, M
   Khadivi, P
   Karimi, N
   Samavi, S
AF Karimi, Maryam
   Nejati, Mansour
   Khadivi, Pejman
   Karimi, Nader
   Samavi, Shadrokh
TI No-reference stereo image quality assessment based on discriminative
   sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image quality assessment; Discriminative dictionary learning;
   No-reference quality assessment; Sparse representation; Stereo image
   quality assessment
ID K-SVD; DICTIONARY; COMBINATION; SIMILARITY; FEATURES
AB The quality of images could be degraded through processing, compression, and transmission. This has created a fundamental need for perceptual quality assessment methods in multimedia services. The use of 3D stereo imaging is rapidly increasing. The quality assessment of stereo images is different from their 2D counterparts. Various algorithms have been devised in this field, mainly based on feature extraction. However, the objective quality scores are not sufficiently correlated with human judgments, or they are not fast enough because of using stereo matching and fusion techniques. In this paper, a fast-efficient algorithm is proposed for blind quality assessment of stereoscopic images. A supervised dictionary learning approach for discriminative sparse representation is applied as an automatic feature discovery framework. Based on this framework, discriminative distortion-specific bases are learned on structural features from stereoscopic images based upon discriminative dictionary learning. The over-complete bases are suitable for sparse representation of samples from the same distortion class. Given these features, an SVR is trained for the no-reference quality assessment of stereoscopic images. The experimental results show that the proposed method has achieved an overall correlation of 97% with subjective scores on common datasets so that its superiority compared to the state-of-the-art methods is up to 2%. Furthermore, our method is computationally efficient and evaluates the quality of stereo images much faster than the competing methods making it qualified for real-time applications.
C1 [Karimi, Maryam] Shahrekord Univ, Dept Comp Sci, Shahrekord 8818634141, Iran.
   [Nejati, Mansour; Karimi, Nader] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Khadivi, Pejman] Seattle Univ, Dept Comp Sci, Seattle, WA 98122 USA.
   [Samavi, Shadrokh] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Samavi, Shadrokh] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON L8S 4L8, Canada.
C3 Shahrekord University; Isfahan University of Technology; Seattle
   University; Isfahan University of Technology; McMaster University
RP Karimi, M (corresponding author), Shahrekord Univ, Dept Comp Sci, Shahrekord 8818634141, Iran.
EM ma.karimi@sku.ac.ir; mansour.nejati@ec.iut.ac.ir; khadivip@seattleu.edu;
   nader.karimi@cc.iut.ac.ir; samavi@mcmaster.ca
RI karimi, maryam/AAZ-9303-2021; nejati, mansour/HJP-0888-2023; Karimi,
   Nader/HWP-4206-2023
OI Karimi, Nader/0000-0001-8904-1607; karimi, maryam/0000-0002-7597-0680
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akhter R, 2010, PROC SPIE, V7524, DOI 10.1117/12.838775
   Appina B, 2016, SIGNAL PROCESS-IMAGE, V43, P1, DOI 10.1016/j.image.2016.02.001
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Bensalma R, 2010, IEEE IMAGE PROC, P4037, DOI 10.1109/ICIP.2010.5649390
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Hachicha W, 2017, SIGNAL PROCESS-IMAGE, V54, P107, DOI 10.1016/j.image.2017.03.005
   Jiang GY, 2017, J VIS COMMUN IMAGE R, V46, P269, DOI 10.1016/j.jvcir.2017.04.010
   Jiang QP, 2019, IEEE T IMAGE PROCESS, V28, P1866, DOI 10.1109/TIP.2018.2881828
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Karimi M, 2019, DIGIT SIGNAL PROCESS, V91, P91, DOI 10.1016/j.dsp.2019.03.004
   Karimi M, 2018, MULTIMED TOOLS APPL, V77, P13799, DOI 10.1007/s11042-017-4994-1
   Karimi M, 2017, IEEE T MULTIMEDIA, V19, P2475, DOI 10.1109/TMM.2017.2699082
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Lin YC, 2017, IEEE J-STSP, V11, P89, DOI 10.1109/JSTSP.2016.2632422
   Lin YH, 2014, IEEE T IMAGE PROCESS, V23, P1527, DOI 10.1109/TIP.2014.2302686
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu LX, 2017, SIGNAL PROCESS-IMAGE, V58, P287, DOI 10.1016/j.image.2017.08.011
   Liu TJ, 2019, IEEE ACCESS, V7, P8058, DOI 10.1109/ACCESS.2018.2890304
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma J, 2018, IEEE ACCESS, V6, P2768, DOI 10.1109/ACCESS.2017.2785282
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Messai O, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115772
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy A, 2013, LIVE 3D IMAGE QUALIT
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Nejati M, 2016, IEEE T IMAGE PROCESS, V25, P4900, DOI 10.1109/TIP.2016.2598483
   Nejati M, 2016, J VIS COMMUN IMAGE R, V36, P28, DOI 10.1016/j.jvcir.2016.01.004
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Saad MA, 2010, IEEE SIGNAL PROC LET, V17, P583, DOI 10.1109/LSP.2010.2045550
   Shao F, 2016, IEEE T MULTIMEDIA, V18, P2104, DOI 10.1109/TMM.2016.2594142
   Shao F, 2015, IEEE T IMAGE PROCESS, V24, P2971, DOI 10.1109/TIP.2015.2436332
   Shao F, 2015, IEEE SIGNAL PROC LET, V22, P1548, DOI 10.1109/LSP.2015.2413946
   Shao F, 2013, IEEE T IMAGE PROCESS, V22, P1940, DOI 10.1109/TIP.2013.2240003
   Shi YQ, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107168
   Su CC, 2015, IEEE T IMAGE PROCESS, V24, P1685, DOI 10.1109/TIP.2015.2409558
   Wan ZL, 2020, IEEE T MULTIMEDIA, V22, P2024, DOI 10.1109/TMM.2019.2950533
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang JC, 2015, J VIS COMMUN IMAGE R, V31, P138, DOI 10.1016/j.jvcir.2015.06.002
   Zhou WJ, 2017, IEEE T BROADCAST, V63, P404, DOI 10.1109/TBC.2016.2638620
   Zhou WJ, 2017, NEUROCOMPUTING, V224, P128, DOI 10.1016/j.neucom.2016.10.046
   Zhou WJ, 2016, IEEE T MULTIMEDIA, V18, P1077, DOI 10.1109/TMM.2016.2542580
NR 46
TC 0
Z9 0
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 33033
EP 33053
DI 10.1007/s11042-021-11322-z
EA AUG 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000684489300001
DA 2024-07-18
ER

PT J
AU Kayhan, N
   Fekri-Ershad, S
AF Kayhan, Nasim
   Fekri-Ershad, Shervan
TI Content based image retrieval based on weighted fusion of texture and
   color features derived from modified local binary patterns and local
   neighborhood difference patterns
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content based image retrieval; Feature extraction; Texture analysis;
   Local binary patterns; Local neighborhood difference patterns; Weighted
   combination
ID FEATURE DESCRIPTOR
AB Today, large amount of data are stored in image format. Content based image retrieval from bulk databases has become an interesting research topic in last decade. Most of the recent approaches use joint of texture and color information. In most cases, the color and texture features are concatenated together and equal importance is given to each one. The human visual system, usually pays more attention to the textural properties of objects to recognize. In this paper a new approach is proposed for content based image retrieval based on weighted combination of color and texture features. Firstly, to achieve discriminant features, texture features are extracted using modified local binary patterns (MLBP) and local neighborhood differences patterns (LNDP) and filtered gray level co-occurrence matrix (GLCM). Also, quantization color histogram is used to extract color features. Next, the similarity matching is performed based on canbera distance in color and texture features separatly. Finally, a weighted decision is performed to retrieve most similar database images to the user query. The performance of the proposed approach is evaluated on Corel 1 K and Corel 10k datasets. Results show that proposed approach provide better performance than state-of-the-art methods in terms of precision and recall rate.
C1 [Kayhan, Nasim] Shahid Ashrafi Esfahani Univ, Fac Engn, Dept Comp Engn, Esfahan, Iran.
   [Fekri-Ershad, Shervan] Islamic Azad Univ, Fac Comp Engn, Najafabad Branch, Najafabad, Iran.
   [Fekri-Ershad, Shervan] Islamic Azad Univ, Big Data Res Ctr, Najafabad Branch, Najafabad, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Fac Comp Engn, Najafabad Branch, Najafabad, Iran.; Fekri-Ershad, S (corresponding author), Islamic Azad Univ, Big Data Res Ctr, Najafabad Branch, Najafabad, Iran.
EM fekriershad@pco.iaun.ac.ir
RI Fekri-Ershad, Shervan/J-7600-2019
OI Fekri-Ershad, Shervan/0000-0003-1226-7610
CR Afifi A.J., 2012, Int. Sch. Res. Not, V2012, DOI [10.5402/2012/248285, DOI 10.5402/2012/248285]
   Alrahhal Maher, 2020, International Journal of Computer Vision and Image Processing, V10, P1, DOI 10.4018/IJCVIP.2020010101
   An J, 2014, IEEE IMAGE PROC, P3042, DOI 10.1109/ICIP.2014.7025615
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Boukerma R, 2019, 2019 INT C THEOR APP, P1
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   DHINGRA S, 2018, ICST T SCALABLE INF
   Du AY, 2019, AUTOMATIKA, V60, P491, DOI 10.1080/00051144.2019.1645977
   Dubey SR, 2015, IET IMAGE PROCESS, V9, P578, DOI 10.1049/iet-ipr.2014.0769
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hua JZ, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S021800141940010X
   Huang WQ, 2017, CURRENT TRENDS IN COMPUTER SCIENCE AND MECHANICAL AUTOMATION, VOL 1, P304
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Liu HL, 2017, PROCEDIA COMPUT SCI, V107, P749, DOI 10.1016/j.procs.2017.03.159
   Mistry Yogita, 2018, Journal of Electrical Systems and Information Technology, V5, P874, DOI 10.1016/j.jesit.2016.12.009
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Mustikasari M., 2014, Int. J. Eng.Res., V3, P507
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qazanfari H., 2019, International Journal of Computer and Information Engineering, V13, P537, DOI [10.5281/zenodo.3566277, DOI 10.5281/ZENODO.3566277]
   Raju USN, 2020, INT J WAVELETS MULTI, V18, DOI 10.1142/S0219691319410017
   Raza A, 2018, IEEE ACCESS, V6, P46595, DOI 10.1109/ACCESS.2018.2866091
   SATHIAMOORTHY S, 2020, SN APPL SCI, V2
   Shih JL, 2002, IEE P-VIS IMAGE SIGN, V149, P370, DOI 10.1049/ip-vis:20020614
   Shikha B, 2020, INT J INTERACT MULTI, V6, P15, DOI 10.9781/ijimai.2020.01.002
   Singh C, 2018, PATTERN RECOGN, V76, P50, DOI 10.1016/j.patcog.2017.10.021
   Srivastava P, 2014, INT CONF CONTR AUTO, P159, DOI 10.1109/ICCAIS.2014.7020550
   Varga D, 2016, IEEE SYS MAN CYBERN, P2636, DOI 10.1109/SMC.2016.7844637
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Xie GY, 2020, J SENSORS, V2020, DOI 10.1155/2020/6068759
   Zhang F, 2016, IMAGE RETRIEVAL BASE
NR 32
TC 45
Z9 46
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32763
EP 32790
DI 10.1007/s11042-021-11217-z
EA AUG 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000682496300003
DA 2024-07-18
ER

PT J
AU Gull, S
   Mansour, RF
   Aljehane, NO
   Parah, SA
AF Gull, Solihah
   Mansour, Romany F.
   Aljehane, Nojood O.
   Parah, Shabir A.
TI A self-embedding technique for tamper detection and localization of
   medical images for smart-health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; Tamper localization; Chaotic encryption; Smart-health;
   Steganography
ID FRAGILE WATERMARKING SCHEME; AUTHENTICATION; SECURE; PROTECTION
AB With the prodigious headway of the Internet of Things (IoT), cloud computing, Artificial Intelligence (AI), and big data, smart healthcare is expected to provide potential and competent healthcare services. Smart healthcare is changing the traditional healthcare system by making it more convenient, more expedient, more effective, and more personalized. The rampant health sector data breaches worldwide, however, testify to the need of ensuring the integrity and authenticity of data shared over insecure networks. In this paper, a secure self-embedding fragile watermarking scheme capable of authenticating the medical images and precisely localizing the tampered regions is presented. Two watermarks generated from the cover image called authentication watermark and localization watermark, are used for authentication and localization of the tampered region at the receiver. For watermark generation, the cover image is divided into 4 x 4 non-overlapping blocks. Each block is permuted using chaotic encryption before the watermark generation. The authentication watermark is a function of the 4-Most Significant Bits (MSBs) of each pixel of a block. Deoxyribonucleic Acid (DNA) encoding is used to ensure the security of the authentication watermark before its embedding. The localization watermark utilizes the arithmetic mean of a selected block and the Maximum Pixel Intensity (MPI) in that block. The DNA arithmetic is applied to generate the final authentication of watermark data. The tamper detection and localization results obtained for the proposed work are found to perform better compared to the state-of-art techniques. The proposed algorithm maintains better visual quality despite higher embedding capacity as indicated by an average Peak Signal to Noise (PSNR) value of 51.94 dB for an embedding capacity of 262,144 bits. The average value for the Structural Similarity Index Metric (SSIM) for the proposed scheme is found to be 0.9962 which is higher when compared to the techniques under comparison. The average False Positive Rate (F-PR) for the proposed algorithm is found to be 3.9916 for tampering rates varied from 5 to 50%. The scheme outperforms the various state-of-the-art techniques making it an efficient candidate for tamper detection and localization in smart health applications.
C1 [Gull, Solihah; Parah, Shabir A.] Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, JK, India.
   [Mansour, Romany F.] New Valley Univ, Fac Sci, El Kharja 72511, Egypt.
   [Aljehane, Nojood O.] Tabuk Univ, Comp Sci & Informat Dept, Tabuk, Saudi Arabia.
C3 University of Kashmir; University of Tabuk
RP Parah, SA (corresponding author), Univ Kashmir, Post Grad Dept Elect & Instrumentat Technol, Srinagar 190006, JK, India.
EM shabireltr@gmail.com
RI Mansour, Romany F./AAB-6085-2021; Aljehane, Nojood/ABG-8816-2021
OI Mansour, Romany F./0000-0001-5857-8495; Parah,
   Shabir/0000-0001-5983-0912; O Aljehane, Nojood/0000-0001-9877-7456
FU Department of Science and Technology (DST), Government of India under
   the DST Inspire Fellowship Scheme
FX The authors would like to thank Department of Science and Technology
   (DST), Government of India for supporting this work under the DST
   Inspire Fellowship Scheme.
CR Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Anwer AA., 2015, THESIS U BUCKINGHAM
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Azeroual A, 2017, AEU-INT J ELECTRON C, V79, P207, DOI 10.1016/j.aeue.2017.06.001
   Barani MJ, 2019, OPTIK, V187, P205, DOI 10.1016/j.ijleo.2019.04.074
   Bhalerao S, 2021, J AMB INTEL HUM COMP, V12, P1057, DOI 10.1007/s12652-020-02135-3
   Cao F, 2017, DISPLAYS, V46, P52, DOI 10.1016/j.displa.2017.01.001
   Dorgham O, 2018, INT J CLOUD APPL COM, V8, P154, DOI 10.4018/IJCAC.2018010108
   Fan MQ, 2018, SIGNAL PROCESS-IMAGE, V66, P19, DOI 10.1016/j.image.2018.04.003
   Feng B, 2020, MOBILE NETW APPL, V25, P82, DOI 10.1007/s11036-018-1186-9
   Gao ZF, 2018, IEEE T MED IMAGING, V37, P273, DOI 10.1109/TMI.2017.2746879
   Golea Nour El-Houda, 2019, International Journal of High Performance Computing and Networking, V13, P199
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Haghighi BB, 2018, J VIS COMMUN IMAGE R, V50, P49, DOI 10.1016/j.jvcir.2017.09.017
   Hurrah NN, 2020, MULTIMED TOOLS APPL, V79, P21441, DOI 10.1007/s11042-020-08988-2
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Liu Y, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107293
   Mshali H, 2018, INT J IND ERGONOM, V66, P26, DOI 10.1016/j.ergon.2018.02.002
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Qin C, 2016, INFORM SCIENCES, V373, P233, DOI 10.1016/j.ins.2016.09.001
   Ranade SK., 2017, INT J ADV RES COMPUT, V6, P1058
   Sarkar D, 2020, MULTIMED TOOLS APPL, V79, P17761, DOI 10.1007/s11042-020-08669-0
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shen YC, 2020, TECHNOL FORECAST SOC, V160, DOI 10.1016/j.techfore.2020.120225
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Sivasubramanian N, 2020, COMPUTING, V102, P1365, DOI 10.1007/s00607-020-00797-7
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tai WL, 2018, SIGNAL PROCESS-IMAGE, V65, P11, DOI 10.1016/j.image.2018.03.011
   Tiwari A, 2017, AEU-INT J ELECTRON C, V78, P114, DOI 10.1016/j.aeue.2017.05.027
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   Wang LC, 2019, IEEE INTERNET THINGS, V6, P1402, DOI 10.1109/JIOT.2018.2844727
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Xiang YP, 2019, SIGNAL PROCESS, V162, P282, DOI 10.1016/j.sigpro.2019.04.022
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zhang H, 2017, ALGORITHMS, V10, DOI 10.3390/a10010027
   Zhang Y, 2018, J NETW COMPUT APPL, V123, P89, DOI 10.1016/j.jnca.2018.09.005
   Zhewei Y, 2019, GLOB HLTH J, V3
NR 43
TC 13
Z9 13
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29939
EP 29964
DI 10.1007/s11042-021-11170-x
EA JUL 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000673928000002
DA 2024-07-18
ER

PT J
AU Ocaña, M
   Chapela-Campa, D
   Alvarez, P
   Hernández, N
   Mucientes, M
   Fabra, J
   Llamazares, A
   Lama, M
   Revenga, PA
   Bugarín, A
   García-Garrido, MA
   Alonso, JM
AF Ocana, Manuel
   Chapela-Campa, David
   Alvarez, Pedro
   Hernandez, Noelia
   Mucientes, Manuel
   Fabra, Javier
   Llamazares, Angel
   Lama, Manuel
   Revenga, Pedro A.
   Bugarin, Alberto
   Garcia-Garrido, Miguel A.
   Alonso, Jose M.
TI Automatic linguistic reporting of customer activity patterns in open
   malls
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social workflows; Localization; Data mining techniques; Parallelization
   strategies; Automatic linguistic reporting
ID NATURAL-LANGUAGE GENERATION; OF-THE-ART; REAL
AB In this work, we present a complete system to produce an automatic linguistic reporting about the customer activity patterns inside open malls, a mixed distribution of classical malls joined with the shops on the street. These reports can assist to design marketing campaigns by means of identifying the best places to catch the attention of customers. Activity patterns are estimated with process mining techniques and the key information of localization. Localization is obtained with a parallelized solution based on WiFi fingerprint system to speed up the solution. In agreement with the best practices for human evaluation of natural language generation systems, the linguistic quality of the generated report was evaluated by 41 experts who filled in an online questionnaire. Results are encouraging, since the average global score of the linguistic quality dimension is 6.17 (0.76 of standard deviation) in a 7-point Likert scale. This expresses a high degree of satisfaction of the generated reports and validates the adequacy of automatic natural language textual reports as a complementary tool to process model visualization.
C1 [Ocana, Manuel; Hernandez, Noelia; Llamazares, Angel; Revenga, Pedro A.; Garcia-Garrido, Miguel A.] Univ Alcala, Madrid, Spain.
   [Chapela-Campa, David; Mucientes, Manuel; Lama, Manuel; Bugarin, Alberto; Alonso, Jose M.] Univ Santiago de Compostela, Ctr Singular Invest Tecnoloxias Intelixentes CiTI, Santiago De Compostela, Spain.
   [Alvarez, Pedro; Fabra, Javier] Univ Zaragoza, Zaragoza, Spain.
C3 Universidad de Alcala; Universidade de Santiago de Compostela;
   University of Zaragoza
RP Ocaña, M (corresponding author), Univ Alcala, Madrid, Spain.
EM mocana@depeca.uah.es
RI Ocaña, Manuel/AAU-2650-2021; Revenga, Pedro/K-9174-2014; García-Garrido,
   Miguel Ángel/ABF-5670-2021; Lama, Manuel/AAE-6880-2019; Llamazares,
   Angel/AAQ-6732-2021; Hernandez, Noelia/K-8485-2014; Alonso Moral, Jose
   Maria/A-4374-2017; Mucientes, Manuel/L-7100-2014
OI Ocaña, Manuel/0000-0002-8875-1866; Revenga, Pedro/0000-0003-2550-5972;
   García-Garrido, Miguel Ángel/0000-0002-4348-6018; Lama,
   Manuel/0000-0001-7195-6155; Llamazares, Angel/0000-0001-8273-5163;
   Chapela-Campa, David/0000-0002-4711-9653; Hernandez,
   Noelia/0000-0002-6644-9498; Alonso Moral, Jose
   Maria/0000-0003-3673-421X; Mucientes, Manuel/0000-0003-1735-3585
FU Spanish Ministry of Science Innovation and Universities; European
   Regional Development Fund (ERDF/FEDER) [RTI2018-099646-B-I00,
   TIN2017-84796-C2-1-R, TIN2017-90773-REDT, RED2018-102641-T,
   RYC-2016-19802]; Galician Ministry of Education, University and
   Professional Training; ERDF/FEDER [ED431F2018/02, ED431C2018/29,
   ED431G2019/04]
FX This work has been partially supported by the Spanish Ministry of
   Science Innovation and Universities and the European Regional
   Development Fund (ERDF/FEDER) Grants RTI2018-099646-B-I00,
   TIN2017-84796-C2-1-R, TIN2017-90773-REDT, RED2018-102641-T and
   RYC-2016-19802 (Ramon y Cajal program, Jose M. Alonso). Also by the
   Galician Ministry of Education, University and Professional Training and
   the ERDF/FEDER program (ED431F2018/02, ED431C2018/29, ED431G2019/04
   grants).
CR [Anonymous], 2000, BUILDING NATURAL LAN, DOI DOI 10.1017/CBO9780511519857
   [Anonymous], 1996, Pattern oriented software architecture: a system of patters
   [Anonymous], 2018, P DOCT CONS PAP 30 I
   Chapela-Campa D, 2019, INFORM SCIENCES, V472, P235, DOI 10.1016/j.ins.2018.09.011
   Conde-Clemente P, 2017, EXPERT SYST APPL, V85, P46, DOI 10.1016/j.eswa.2017.05.031
   DALE R, 1995, COGNITIVE SCI, V19, P233, DOI 10.1207/s15516709cog1902_3
   Dijkman R, 2017, INFORM SYST, V67, P114, DOI 10.1016/j.is.2017.03.009
   Dusek O, 2020, COMPUT SPEECH LANG, V59, P123, DOI 10.1016/j.csl.2019.06.009
   EU High Level Expert Group on AI, 2019, TECH REP, DOI [10.2759/002360, DOI 10.2759/002360]
   EU High Level Expert Group on AI, 2019, TECH REP, DOI [10.2759/346720, DOI 10.2759/346720]
   Ferreira TC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P552
   Fontenla-Seco Yago, 2021, Trustworthy AI - Integrating Learning, Optimization and Reasoning. First International Workshop, TAILOR 2020. Revised Selected Papers. Lecture Notes in Artificial Intelligence, Subseries of Lecture Notes in Computer Science (LNAI 12641), P212, DOI 10.1007/978-3-030-73959-1_19
   Gatt A, 2018, J ARTIF INTELL RES, V61, P65, DOI 10.1613/jair.5477
   Görg S, 2015, INFORM SYST, V50, P1, DOI 10.1016/j.is.2014.12.007
   Grice H. P., 1975, SYNTAX SEMANTICS, V3, P41, DOI DOI 10.1163/9789004368811_003
   Hernández N, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010147
   Law Anna S, 2005, J Clin Monit Comput, V19, P183, DOI 10.1007/s10877-005-0879-3
   Leopold H, 2014, IEEE T SOFTWARE ENG, V40, P818, DOI 10.1109/TSE.2014.2327044
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Mannhardt F., 2018, BPM (Dissertation/Demos/Industry), P41
   Ocana Manuel, 2021, Advances in Physical Agents. Proceedings of the 21st International Workshop of Physical Agents (WAF 2020). Advances in Intelligent Systems and Computing (AISC 1285), P30, DOI 10.1007/978-3-030-62579-5_3
   Ottensooser A, 2012, J SYST SOFTWARE, V85, P596, DOI 10.1016/j.jss.2011.09.023
   PETRE M, 1995, COMMUN ACM, V38, P33, DOI 10.1145/203241.203251
   Ramos-Soto A, 2016, PROG ARTIF INTELL, V5, P261, DOI 10.1007/s13748-016-0097-x
   Ramos-Soto A, 2016, FUZZY SET SYST, V285, P31, DOI 10.1016/j.fss.2015.06.019
   Ramos-Soto A, 2015, IEEE T FUZZY SYST, V23, P44, DOI 10.1109/TFUZZ.2014.2328011
   Reiter E, 2007, P 11 EUROPEAN WORKSH, DOI DOI 10.1017/CB09781107415324.004
   Reiter Ehud., 2016, NLG VS TEMPLATES LEV
   Sànchez-Ferreres J, 2019, LECT NOTES COMPUT SC, V11675, P86, DOI 10.1007/978-3-030-26619-6_8
   Sànchez-Ferreres J, 2017, LECT NOTES COMPUT SC, V10253, P413, DOI 10.1007/978-3-319-59536-8_26
   van Deemter K, 2005, COMPUT LINGUIST, V31, P15, DOI 10.1162/0891201053630291
   van der Aa H., 2018, P 27 INT C COMP LING, P2791
   van der Aa H, 2015, LECT NOTES COMPUT SC, V9253, P90, DOI 10.1007/978-3-319-23063-4_6
   van der Aalst W., 2016, Process Mining: Data Science in Action, DOI DOI 10.1007/978-3-662-49851-4
   van der Aalst W, 2012, LECT NOTES BUS INF P, V99, P169
   van der Aalst WMP, 2011, PROCESS MINING: DISCOVERY, CONFORMANCE AND ENHANCEMENT OF BUSINESS PROCESSES, P1, DOI 10.1007/978-3-642-19345-3
   van der Lee C, 2021, COMPUT SPEECH LANG, V67, DOI 10.1016/j.csl.2020.101151
   Vazquez-Barreiros B, 2015, INFORM SCIENCES, V294, P315, DOI 10.1016/j.ins.2014.09.057
NR 38
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3369
EP 3395
DI 10.1007/s11042-021-11186-3
EA JUL 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000670850000002
OA hybrid
DA 2024-07-18
ER

PT J
AU Chang, CC
   Wang, X
   Lin, CC
AF Chang, Chin-Chen
   Wang, Xu
   Lin, Chia-Chen
TI An efficient dual prediction-based reversible data hiding and reduced
   code method for AMBTC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Dual prediction; Reduced code; AMBTC
ID SCHEME; IMAGE
AB Due to the popularity of smartphones, laptops and wireless communication technologies, compressed images have become widely used for such applications, because a smaller storage space is needed. Protecting the security of information transmission over the Internet while reducing file size (also called the size of the final coding stream) has become a critical issue. Three related works have proposed using the reversible data hiding (RDH) method on AMBTC-compressed images to reduce the final stego-coding stream. However, these approaches still have room for improvement. To further optimize the performance of the related works, in this paper, we present an efficient dual prediction-based reversible data hiding and reduced code method for AMBTC-compressed images that uses three significant techniques: the dual prediction strategy (DP), the reversible standardized parameters (RSP) and the improved error division technique (IED). We can thus embed more secret data while effectively reducing the length of the final coding stream. Experimental results show that the proposed method has both the lowest true bitrate and the highest embedding efficiency in broader usage scenarios when compared to other related methods.
C1 [Chang, Chin-Chen; Wang, Xu] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Natl Chin Yi Univ Technol, Dept Comp Sci & Informat Engn, Taichung 411030, Taiwan.
C3 Feng Chia University; National Chin-Yi University of Technology
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM alan3c@gmail.com; wx1990555@gmail.com; ally.cclin@ncut.edu.tw
RI 王, 旭/JAX-6722-2023; 王, 旭/GPX-0697-2022; Chang, Ching-Chun/JAN-6210-2023
OI Lin, Chia-Chen/0000-0003-4480-7351
CR Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Ben Farah MA, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105777
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2018, MULTIMED TOOLS APPL, V77, P9039, DOI 10.1007/s11042-017-4800-0
   Chang CC, 2016, MULTIMED TOOLS APPL, V75, P145, DOI 10.1007/s11042-014-2279-5
   Chang CC, 2015, INFORM SCIENCES, V300, P85, DOI 10.1016/j.ins.2014.12.028
   Chen Y, 2019, J BUS ETHICS, V159, P587, DOI 10.1007/s10551-018-3847-9
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   GOLDWASSER S, 1988, SIAM J COMPUT, V17, P281, DOI 10.1137/0217017
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Hong WE, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10070254
   Hong W, 2017, MULTIMED TOOLS APPL, V76, P5441, DOI 10.1007/s11042-016-4032-8
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lin CC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P8, DOI 10.1109/CISP.2008.64
   Liu XL, 2016, IMAGING SCI J, V64, P364, DOI 10.1080/13682199.2016.1213983
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Huynh NT, 2018, MULTIMED TOOLS APPL, V77, P5767, DOI 10.1007/s11042-017-4487-2
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Sun W, 2013, SIGNAL IMAGE VIDEO P, V7, P297, DOI 10.1007/s11760-011-0238-4
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
NR 35
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 24
BP 33157
EP 33176
DI 10.1007/s11042-021-11048-y
EA JUL 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WJ3HO
UT WOS:000669777200001
DA 2024-07-18
ER

PT J
AU Rana, S
   Mishra, D
   Mukhopadhyay, S
AF Rana, Saurabh
   Mishra, Dheerendra
   Mukhopadhyay, Sourav
TI Blockchain-based multimedia content distribution with the assured system
   update mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Blockchain; Revocation; Access control; Authentication;
   Security
ID SCHEME; MANAGEMENT; TRANSFORM
AB Advancement in Internet technology is providing the exponential growth to the multimedia industry, which handles digital content broadcast and distribution over the internet. It also faces several series of challenges such as the transgression of copyrights, multimedia content security, efficient communication, user privacy, secure and authorized communication, etc. In general, centralize authority works to address security and privacy. Thus, the existing mechanism will not work if the decentralized and heterogeneous system occurs. To attain an effective solution for content distribution, blockchain-based content distribution framework is provided to ensure authenticated and efficient access. The proposed protocol gives the method of blockchain-based access control with user revocation, which provides an alternative solution to handle the decentralization and revocation issues. This multimedia content distribution framework ensures security against malicious users. The proposed scheme security is proved in the widely recognized random oracle model. The comparative analysis of the proposed scheme with relevant schemes shows the enhancement in term of efficiency.
C1 [Rana, Saurabh] Chandigarh Univ, Dept Math, Chandigarh, India.
   [Mishra, Dheerendra] Maulana Azad Natl Inst Technol, Dept Math, Bhopal, India.
   [Mukhopadhyay, Sourav] Indian Inst Technol, Dept Math, Kharagpur, W Bengal, India.
C3 Chandigarh University; National Institute of Technology (NIT System);
   Maulana Azad National Institute of Technology Bhopal; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Kharagpur
RP Mishra, D (corresponding author), Maulana Azad Natl Inst Technol, Dept Math, Bhopal, India.
EM dheerendra.m@gmail.com
RI Mishra, Dheerendra/C-4208-2017
OI Mishra, Dheerendra/0000-0001-8115-6397; Mukhopadhyay,
   Sourav/0000-0002-4015-1386
CR Bethencourt J, 2007, P IEEE S SECUR PRIV, P321, DOI 10.1109/sp.2007.11
   bt Abd Halim N. S., 2017, INT C REL INF COMM T, P739
   Chen HB, 2018, MULTIMED TOOLS APPL, V77, P23099, DOI 10.1007/s11042-018-5614-4
   De SJ, 2020, IEEE T CLOUD COMPUT, V8, P124, DOI 10.1109/TCC.2017.2754255
   DOLEV D, 1983, IEEE T INFORM THEORY, V29, P198, DOI 10.1109/TIT.1983.1056650
   Ghosal SK, 2019, J INF SECUR APPL, V46, P320, DOI 10.1016/j.jisa.2018.04.003
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Ghosal SK, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.3984
   Goyal V., 2006, P 13 ACM C COMP COMM, P89, DOI DOI 10.1145/1180405.1180418
   Guo R, 2019, IEEE ACCESS, V7, P88012, DOI 10.1109/ACCESS.2019.2925625
   Hari A, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '16), P204, DOI 10.1145/3005745.3005771
   JUNG J, 2017, PLOS ONE, V12
   Katz J, 2008, LECT NOTES COMPUT SC, V4965, P146
   King S., 2012, Ppcoin: Peer-to-peer crypto-currency with proof-of-stake, P1
   Lee CC, 2018, INF TECHNOL CONTROL, V47, P262, DOI 10.5755/j01.itc.47.2.18506
   Lee CC, 2018, J INF SECUR APPL, V39, P19, DOI 10.1016/j.jisa.2018.02.001
   Li M, 2013, IEEE T PARALL DISTR, V24, P131, DOI 10.1109/TPDS.2012.97
   Liang X., 2011, GLOB TELECOMM CONF, P1
   Luo K, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY AND SECURITY COMPANION (QRS-C), P139, DOI 10.1109/QRS-C.2018.00037
   Malik Nisha, 2018, 2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE). Proceedings, P674, DOI 10.1109/TrustCom/BigDataSE.2018.00099
   Mistry I, 2020, MECH SYST SIGNAL PR, V135, DOI 10.1016/j.ymssp.2019.106382
   Nakamoto S., 2008, DECENTRAL BUS REV
   Wang GJ, 2011, COMPUT SECUR, V30, P320, DOI 10.1016/j.cose.2011.05.006
   Xu XL, 2020, MULTIMED TOOLS APPL, V79, P9819, DOI 10.1007/s11042-019-07900-x
   Yang K, 2014, IEEE T PARALL DISTR, V25, P1735, DOI 10.1109/TPDS.2013.253
   Yang K, 2013, IEEE T INF FOREN SEC, V8, P1790, DOI 10.1109/TIFS.2013.2279531
   Zhang YH, 2017, PERS UBIQUIT COMPUT, V21, P815, DOI 10.1007/s00779-017-1047-8
NR 27
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29423
EP 29436
DI 10.1007/s11042-021-10948-3
EA JUN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000667012200002
DA 2024-07-18
ER

PT J
AU Marques, T
   Vairinhos, M
   Almeida, P
AF Marques, Tiffany
   Vairinhos, Mario
   Almeida, Pedro
TI VR 360o and its impact on the immersion of viewers of suspense AV
   content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual Reality; 360o; Immersion; Audio-visual; Suspense; Audio-visual
   production
ID AROUSAL
AB With the development of new technologies, audio-visual (AV) content creators are looking for more immersive experiences, so a greater involvement of the viewer with the action and the narrative occur. Based on this vision, virtual reality (VR) is increasingly considered a tempting option for the world of entertainment. VR 360o AV content is beginning to emerge, allowing greater immersion for the spectator. In the cinematic genre of suspense, VR 360o has high potential to provide a more impacting experience for the spectators. However, it is necessary to confirm whether this potential is true. In this sense, the study focused on the production of an AV content of suspense and its adaptation to three different formats (2D, 360o and VR 360o), with the objective of understanding the impact on the immersion of the spectators when they watch VR 360o, in comparison with the other formats. Three tests were performed in the laboratory, with sample of 36 participants in total. In order to understand the immersive differences, each test consisted of 12 participants, in which they all watched the same suspense content, an adaptation of The Tell-Tale Heart by Edgar Allen Poe, but in different formats. The results showed that the VR 360o format intensifies perceptual immersion but decreases narrative immersion, when compared to 2D and 360o formats. Also is shown that the fact that narrative immersion has decreased in this format is a consequence of the user being allowed a 360o stereoscopic view with the Head-Mounted Display (HMD).
C1 [Marques, Tiffany; Vairinhos, Mario; Almeida, Pedro] Univ Aveiro, Dept Commun & Art, DigiMedia, Aveiro, Portugal.
C3 Universidade de Aveiro
RP Marques, T (corresponding author), Univ Aveiro, Dept Commun & Art, DigiMedia, Aveiro, Portugal.
EM tiffanymarques@ua.pt; mariov@ua.pt; almeida@ua.pt
RI Almeida, Pedro/K-9055-2018; Vairinhos, Mário/ABI-8209-2020
OI Almeida, Pedro/0000-0001-5878-3317; Vairinhos,
   Mário/0000-0002-4483-8126; Marques, Tiffany/0000-0001-6662-7998
CR Anderson-Moore, 2016, ENTER NEW WORLD NARR
   Aylett R., 2003, Virtual Reality, V7, P2, DOI 10.1007/s10055-003-0114-9
   Bindman SW, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174031
   Codispoti M, 2007, PSYCHOPHYSIOLOGY, V44, P680, DOI 10.1111/j.1469-8986.2007.00545.x
   Diemer J, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.00026
   Fonseca D., 2016, Proceedings of the 20th International Mindtrek Conference, P287, DOI [DOI 10.1145/2994310.2994334, 10.1145/2994310.2994334, 10.1145/2994310.2994334,96]
   Gödde M, 2018, LECT NOTES COMPUT SC, V10910, P184, DOI 10.1007/978-3-319-91584-5_15
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Huang M P, 1999, Cyberpsychol Behav, V2, P15, DOI 10.1089/cpb.1999.2.15
   Kim A, 2018, 25TH 2018 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P601, DOI 10.1109/VR.2018.8446046
   Kraakman N., 2017, Cinematic VR crash course
   Kurbatov V, 2017, DRAW SKETCHES VIRTUA
   Li BJ, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.02116
   MacQuarrie A, 2017, P IEEE VIRT REAL ANN, P45, DOI 10.1109/VR.2017.7892230
   Marques TE, 2019, TVX 2019: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON INTERACTIVE EXPERIENCES FOR TV AND ONLINE VIDEO, P239, DOI 10.1145/3317697.3325120
   Milk Chris., 2015, Ted Talk
   Nogueira Luis., 2010, Manuais de Cinema II - Generos Cinematograficos
   Passmore Peter J., 2016, Proceedings of the 26th International Conference on Artificial Reality and Telexistence and the 21st Eurographics Symposium on Virtual Environments, ICAT-EGVE'16, P9
   Paul B, 2017, VIRTUAL REALITY ENTE
   Roth Christian., 2016, Proceedings of the 1st International Workshop on Multimedia Alternate Realities. AltMM'16, P31, DOI DOI 10.1145/2983298.2983302
   Slater MD, 2014, J COMMUN, V64, P439, DOI 10.1111/jcom.12100
   Swant M., 2016, How virtual reality is inspiring donors to dig deep for charitable causes
   Tse A., 2017, P 2017 CHI C HUM FAC, P2967, DOI DOI 10.1145/3027063.3053225
   Visch VT, 2010, COGNITION EMOTION, V24, P1439, DOI 10.1080/02699930903498186
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 25
TC 4
Z9 4
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31021
EP 31038
DI 10.1007/s11042-021-11067-9
EA JUN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000667012400003
DA 2024-07-18
ER

PT J
AU Cao, Y
   Liu, C
   Huang, ZL
   Sheng, YJ
   Ju, YJ
AF Cao, Yi
   Liu, Chen
   Huang, Zilong
   Sheng, Yongjian
   Ju, Yongjian
TI Skeleton-based action recognition with temporal action graph and
   temporal adaptive graph convolution structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton-based action recognition; GCN; Temporal action graph; Temporal
   adaptive graph convolution structure; Spatia-temporal adaptive graph
   convolution network
ID NETWORKS
AB Skeleton-based action recognition has recently achieved much attention since they can robustly convey the action information. Recently, many studies have shown that graph convolutional networks (GCNs), which generalize CNNs to more generic non-Euclidean structures, are more exactly extracts spatial feature. Nevertheless, how to effectively extract global temporal features is still a challenge. In this work, firstly, a unique feature named temporal action graph is designed. It first attempts to express timing relationship with the form of graph. Secondly, temporal adaptive graph convolution structure (T-AGCN) are proposed. Through generating global adjacency matrix for temporal action graph, it can flexibly extract global temporal features in temporal dynamics. Thirdly, we further propose a novel model named spatial-temporal adaptive graph convolutional network (ST-AGCN) for skeletons-based action recognition to extract spatial-temporal feature and improve action recognition accuracy. ST-AGCN combines T-AGCN with spatial graph convolution to make up for the shortage of T-AGCN for spatial structure. Besides, ST-AGCN uses dual features to form a two-stream network which is able to further improve action recognition accuracy for hard-to-recognition sample. Finally, comparsive experiments on the two skeleton-based action recognition datasets, NTU-RGBD and SBU, demonstrate that T-AGCN and temporal action graph can effective explore global temporal information and ST-AGCN achieves certain improvement of recognition accuracy on both datasets.
C1 [Cao, Yi; Liu, Chen; Huang, Zilong; Sheng, Yongjian; Ju, Yongjian] Jiangnan Univ, Sch Mech Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Cao, Yi; Liu, Chen; Huang, Zilong; Sheng, Yongjian; Ju, Yongjian] Jiangsu Key Lab Adv Food Mfg Equipment & Technol, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Cao, Y (corresponding author), Jiangnan Univ, Sch Mech Engn, Wuxi 214122, Jiangsu, Peoples R China.; Cao, Y (corresponding author), Jiangsu Key Lab Adv Food Mfg Equipment & Technol, Wuxi 214122, Jiangsu, Peoples R China.
EM caoyi@jiangnan.edu.cn
OI CAO, Yi/0000-0003-3255-6575
FU National Natural Science Foundation of China [51375209]; Six Talent
   Peaks Project in Jiangsu Province [ZBZZ-012]; Excellent Science and
   Technology Innovation Team Fund Jiangsu Province [:2019SK07];
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX20_1928, KYCX20 0760]
FX This work is supported by National Natural Science Foundation of China
   (Grant No: 51375209), the Six Talent Peaks Project in Jiangsu
   Province(Grant No:ZBZZ-012), Excellent Science and Technology Innovation
   Team Fund Jiangsu Province(Grant No:2019SK07) and partially supported by
   the Postgraduate Research & Practice Innovation Program of Jiangsu
   Province (Grant No:KYCX20_1928 and KYCX20 0760).
CR [Anonymous], 2014, Asian Conference on Computer Vision
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   Diao ZL, 2019, AAAI CONF ARTIF INTE, P890
   Ding WW, 2016, SIGNAL PROCESS-IMAGE, V42, P109, DOI 10.1016/j.image.2016.01.010
   Dong XW, 2019, IEEE SIGNAL PROC MAG, V36, P44, DOI 10.1109/MSP.2018.2887284
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Feng JG, 2019, MULTIMED TOOLS APPL, V78, P591, DOI 10.1007/s11042-017-5290-9
   Garcia-Hernando G, 2017, PROC CVPR IEEE, P407, DOI 10.1109/CVPR.2017.51
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kay W., 2017, ARXIV170506950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li B, 2018, MULTIMED TOOLS APPL, V77, P22901, DOI 10.1007/s11042-018-5642-0
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li JN, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107356
   Lie WN, 2018, PROC INT WORKSH ADV
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Mihai T., 2019, SENSORS-BASEL, V19, P423, DOI [10.3390/s19020423, DOI 10.3390/S19020423]
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Salah AA, 2011, LECT NOTES COMPUT SC, V7040, P376
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Song SJ, 2018, IEEE T IMAGE PROCESS, V27, P3459, DOI 10.1109/TIP.2018.2818328
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tang YS, 2018, PROC CVPR IEEE, P5323, DOI 10.1109/CVPR.2018.00558
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Weng JW, 2018, LECT NOTES COMPUT SC, V11211, P142, DOI 10.1007/978-3-030-01234-2_9
   Xu M, 2017, IEEE INT CON MULTI, P517, DOI 10.1109/ICME.2017.8019351
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zhang P, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P6475
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhou Jie, 2018, arXiv preprint arXiv:1812.08434
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
NR 45
TC 12
Z9 13
U1 2
U2 50
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29139
EP 29162
DI 10.1007/s11042-021-11136-z
EA JUN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000663494600002
DA 2024-07-18
ER

PT J
AU Dey, R
   Balabantaray, RC
   Mohanty, S
AF Dey, Raghunath
   Balabantaray, Rakesh Chandra
   Mohanty, Sanghamitra
TI Sliding window based off-line handwritten text recognition using edit
   distance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Off-line handwritten text recognition; Sliding window; Edit distance;
   Machine learning algorithms; Edge detection; Feature extraction
ID CHARACTER-RECOGNITION; NEURAL-NETWORK
AB A significant issue in the domain of optical character recognition is handwritten text recognition. Here, two novel feature extraction techniques are proposed using a fixed-size sliding window, and also an edit distance-based architecture is suggested to recognize the off-line characters. These feature extraction techniques are designed for text recognition from the text images. It's an off-line approach, that is why data from scanned documents or natural scenes are taken as input. In this paper, the freely available datasets, known as Chars74k and MNIST for English alphabets and digits are used. The proposed feature extraction technique for the off-line text images of characters as well as numbers generates the features successfully. The impact of the proposed method on text recognition accuracy is computed using several state-of-the-art machine learning algorithms. After that, these are again compared with the proposed Edit distance based text recognition system with the help of different conducted experiments. The proposed model has reached an accuracy of more than 96% for the MNIST dataset.
C1 [Dey, Raghunath; Balabantaray, Rakesh Chandra] Int Inst Informat Technol, Bhubaneswar, India.
   [Mohanty, Sanghamitra] North Orissa Univ, Baripada, India.
C3 International Institute of Information Technology, Bhubaneswar
RP Dey, R (corresponding author), Int Inst Informat Technol, Bhubaneswar, India.
EM c118003@iiit-bh.ac.in; rakesh@iiit-bh.ac.in; sangham1@rediffmail.com
OI Dey, Raghunath/0000-0002-0295-8189
CR Ali M, 2016, IEEE IMAGE PROC, P2891, DOI 10.1109/ICIP.2016.7532888
   Arica N, 2002, IEEE T PATTERN ANAL, V24, P801, DOI 10.1109/TPAMI.2002.1008386
   BARUCH O, 1988, PATTERN RECOGN LETT, V8, P271, DOI 10.1016/0167-8655(88)90034-7
   Beigi HS, 1993, P 1 ANN C TECHN ADV, P30
   Ben S, 2017, REAL TIME IMAGE VIDE, V10223, P1
   Bengio E., 2016, RUAN
   Bu YJ, 2013, 2013 IEEE 11TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC), P304, DOI 10.1109/DASC.2013.79
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Choudhary A, 2013, PROCEDIA COMPUT SCI, V17, P88, DOI 10.1016/j.procs.2013.05.013
   Das D, 2019, MULTIMED TOOLS APPL, V78, P19495, DOI 10.1007/s11042-019-7330-0
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Dey Raghunath, 2019, 2019 International Conference on Information Technology (ICIT), P178, DOI 10.1109/ICIT48102.2019.00038
   Dey S, 2019, INT J DOC ANAL RECOG, V22, P361, DOI 10.1007/s10032-019-00338-9
   Dutt Anuj., 2017, INT J OF ADV RES IN, V6, P990
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Fenu G, 2018, PATTERN RECOGN LETT, V113, P83, DOI 10.1016/j.patrec.2017.03.027
   Fenu G, 2017, LECT NOTES COMPUT SC, V10590, P331, DOI 10.1007/978-3-319-70742-6_31
   Ghosh SK, 2015, LECT NOTES COMPUT SC, V9117, P652, DOI 10.1007/978-3-319-19390-8_73
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   GRIMSDALE RL, 1959, P I ELEC ENG       B, V106, P210
   Hambal AbdallaMohamed., 2017, International Journal of Science and Research, V6, P2033, DOI DOI 10.21275/25031706
   Hochuli AG, 2018, PATTERN RECOGN, V78, P1, DOI 10.1016/j.patcog.2018.01.004
   Ignat A, 2016, INT SYMP SYMB NUMERI, P303, DOI 10.1109/SYNASC.2016.48
   Ilmi N, 2016, 2016 4TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOICT)
   Islam MM, 2019, INT C ENG RES ED
   Islam N., 2017, ARXIV171005703
   Kandaswamy Chetak, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P265, DOI 10.1007/978-3-319-11179-7_34
   Kaur RP, 2020, MULTIMED TOOLS APPL, V79, P7435, DOI 10.1007/s11042-019-08365-8
   Kavallieratou E, 2018, J IMAGING, V4, DOI 10.3390/jimaging4060080
   Kowsalya S, 2019, MULTIMED TOOLS APPL, V78, P25043, DOI 10.1007/s11042-019-7624-2
   Krishnan P, 2018, 2018 13TH IAPR INTERNATIONAL WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS (DAS), P1, DOI 10.1109/DAS.2018.70
   Krishnan P, 2016, LECT NOTES COMPUT SC, V9905, P766, DOI 10.1007/978-3-319-46448-0_46
   Kusetogullari H, 2020, NEURAL COMPUT APPL, V32, P16505, DOI 10.1007/s00521-019-04163-3
   LAM SW, 1995, P SOC PHOTO-OPT INS, V2422, P38, DOI 10.1117/12.205839
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li HZ, 2019, MULTIMED TOOLS APPL, V78, P22249, DOI 10.1007/s11042-019-7410-1
   Lu Q, 2019, MULTIMED TOOLS APPL, V78, P15665, DOI 10.1007/s11042-018-6889-1
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panwar NNS., 2012, J COMPUT INFORM TECH, V2, P95
   Priya A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P967, DOI 10.1109/ICCSP.2016.7754291
   Rath TM, 2007, INT J DOC ANAL RECOG, V9, P139, DOI 10.1007/s10032-006-0027-8
   Saha S, 2015, MULTIMED TOOLS APPL, V74, P10621, DOI 10.1007/s11042-014-2196-7
   Sahu N, 2016, ADV VISION COMPUTING, V3
   Sudholt S, 2016, INT CONF FRONT HAND, P277, DOI [10.1109/ICFHR.2016.0060, 10.1109/ICFHR.2016.55]
   Sun CM, 1997, PROC INT CONF DOC, P142, DOI 10.1109/ICDAR.1997.619830
   Sundaresan V, 1998, RECOGNIZING HANDWRIT
   Supardi J, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P149, DOI 10.1109/IC3INA.2014.7042618
   TALREJA S, 2016, J ELECT COMMUNICATIO
   Tay YH, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P1190
   Viklund A, 2017, CHARACTER RECOGNITIO
   Wang J, 2018, MULTIMED TOOLS APPL, V77, P1679, DOI 10.1007/s11042-017-4356-z
   Wibowo GH, 2016, 2016 INTERNATIONAL ELECTRONICS SYMPOSIUM (IES), P471, DOI 10.1109/ELECSYM.2016.7861052
NR 52
TC 4
Z9 5
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22761
EP 22788
DI 10.1007/s11042-021-10988-9
EA MAY 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000655960200002
DA 2024-07-18
ER

EF