FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Anisetti, M
   Ardagna, CA
   Bellandi, V
   Damiani, E
   Döller, M
   Stegmaier, F
   Rabl, T
   Kosch, H
   Brunie, L
AF Anisetti, Marco
   Ardagna, Claudio A.
   Bellandi, Valerio
   Damiani, Ernesto
   Doeller, Mario
   Stegmaier, Florian
   Rabl, Tilmann
   Kosch, Harald
   Brunie, Lionel
TI Landmark-assisted location and tracking in outdoor mobile network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Landmark; Geolocation; Wireless network
ID VEHICLE LOCATION; MPEG-7; STANDARD
AB Modern mobile devices integrating sensors, like accelerometers and cameras, are paving the way to the definition of high-quality and accurate geolocation solutions based on the informations acquired by these sensors, and data collected and managed by GSM/3G networks. In this paper, we present a technique that provides geolocation and mobility prediction of mobile devices, mixing the location information acquired with the GSM/3G infrastructure and the results of a landmark matching achieved thanks to the camera integrated on the mobile devices. Our geolocation approach is based on an advanced Time-Forwarding algorithm and on database correlation technique over Received Signal Strength Indication (RSSI) data, and integrates information produced by a landmark recognition infrastructure, to enhance algorithm performances in those areas with poor signal and low accurate geolocation. Performances of the algorithm are evaluated on real data from a complex urban environment.
C1 [Anisetti, Marco; Ardagna, Claudio A.; Bellandi, Valerio; Damiani, Ernesto] Univ Milan, Dipartimento Tecnol Informaz, Milan, Italy.
   [Doeller, Mario; Stegmaier, Florian; Rabl, Tilmann; Kosch, Harald] Univ Passau, Dept Distributed Informat Syst, Passau, Germany.
   [Brunie, Lionel] INSA Lyon, Lyon, France.
C3 University of Milan; University of Passau; Institut National des
   Sciences Appliquees de Lyon - INSA Lyon
RP Anisetti, M (corresponding author), Univ Milan, Dipartimento Tecnol Informaz, Milan, Italy.
EM marco.anisetti@unimi.it; claudio.ardagna@unimi.it;
   valerio.bellandi@unimi.it; ernesto.damiani@unimi.it;
   mario.doller@uni-passau.de; florian.stegmaier@uni-passau.de;
   tilmann.rabl@uni-passau.de; harald.kosch@uni-passau.de;
   lionel.brunie@insa-lyon.fr
RI damiani, ernesto/J-6060-2012; bellandi, valerio/M-7582-2019; damiani,
   ernesto/AAI-5709-2020; Anisetti, Marco/AAC-9656-2021; ARDAGNA, CLAUDIO
   AGOSTINO/A-3283-2016
OI bellandi, valerio/0000-0003-4473-6258; damiani,
   ernesto/0000-0002-9557-6496; Anisetti, Marco/0000-0002-5438-9467;
   Doller, Mario/0000-0002-9716-564X; ARDAGNA, CLAUDIO
   AGOSTINO/0000-0001-7426-4795; Kosch, Harald/0000-0002-7090-1133
CR Anisetti Marco, 2008, International Journal of Communications, Networks and System Sciences, V1, P95, DOI 10.4236/ijcns.2008.11013
   Anisetti M, 2007, European patent, Patent No. [EP1765031, 1765031]
   ANISETTI M, 2005, P INT S TEL SHIR IR
   Bahl P., 2000, P IEEE INFOCOM 2000
   Broumandan A, 2008, P IEEE 68 VEH TECHN
   Brown B, 2005, P 9 C EUR C COMP SUP
   Bruns E, 2007, IEEE MULTIMEDIA, V14, P16, DOI 10.1109/MMUL.2007.33
   DAMOSSO E, 1999, COST 231 DIGITAL MOB
   Djuknic GM, 2001, COMPUTER, V34, P123, DOI 10.1109/2.901174
   Döller M, 2008, J SYST SOFTWARE, V81, P1559, DOI 10.1016/j.jss.2006.03.051
   Doller M, 2009, P IEEE INT C MULT CO
   FIGEL WG, 1969, IEEE T VEH TECHNOL, VVT18, P105, DOI 10.1109/T-VT.1969.23415
   Gustafsson F, 2005, IEEE SIGNAL PROC MAG, V22, P41, DOI 10.1109/MSP.2005.1458284
   Laitinen H, 2001, P IEEE VTS 53 VEH TE
   Li Y., 2002, P 16 INT C PATT REC
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Martínez JM, 2002, IEEE MULTIMEDIA, V9, P78, DOI 10.1109/93.998074
   Mihaylova L, 2007, IEEE T WIREL COMMUN, V6, P3589, DOI 10.1109/TWC.2007.05912
   Munoz D, 2009, POSITION LOCATION TECHNIQUES AND APPLICATIONS, P1
   Okumura Y, 1995, P5292 ITUR
   Retscher G., 2007, J. Glob. Position. Syst, V6, P56
   Sieskul BT, 2009, P 2009 IEEE C WIR CO
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Simon D, 2002, IEEE T AERO ELEC SYS, V38, P128, DOI 10.1109/7.993234
   SONG HL, 1994, IEEE T VEH TECHNOL, V43, P902, DOI 10.1109/25.330153
   WOLFLE G, 1999, P 10 IEEE INT S PERS
   WOLFLE G, 2004, P 11 COST 273 DUISB
   Wu ZL, 2007, IEEE T MOBILE COMPUT, V6, P311, DOI 10.1109/TMC.2007.42
   Yang Z, 2002, P 21 ANN JOINT COMP
   Zaidi ZR, 2005, IEEE T MOBILE COMPUT, V4, P195, DOI 10.1109/TMC.2005.29
   Zendjebil IM, 2008, P 2008 ACM S VIRT RE
   Zhang M, 2008, P IEEE VEH C VTC2008
   Zimmermann D, 2004, P 60 IEEE VEH TECHN
NR 33
TC 6
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 1
BP 89
EP 111
DI 10.1007/s11042-010-0721-x
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 940DI
UT WOS:000303869800006
DA 2024-07-18
ER

PT J
AU Nam, Y
   Rho, S
   Park, JH
AF Nam, Yunyoung
   Rho, Seungmin
   Park, Jong Hyuk
TI Intelligent video surveillance system: 3-tier context-aware surveillance
   system with metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object identification; Object localization; Object tracking; CCTV;
   Surveillance; PTZ camera; Metadata
ID MOTION
AB This paper presents an intelligent video surveillance system with the metadata rule for the exchange of analyzed information. We define the metadata rule for the exchange of analyzed information between intelligent video surveillance systems that automatically analyzes video data acquired from cameras. The metadata rule is to effectively index very large video surveillance databases and to unify searches and management between distributed or heterogeneous surveillance systems more efficiently. The system consists of low-level context-aware, high-level context-aware and intelligent services to generate metadata for the surveillance systems. Various contexts are acquired from physical sensors in monitoring areas for the low-level context-aware system. The situation is recognized in the high-level context-aware system by analyzing the context data collected in the low-level system. The system provides intelligent services to track moving objects in Fields Of View (FOVs) and to recognize human activities. Furthermore, the system supports real-time moving objects tracking with Panning, Tilting and Zooming (PTZ) cameras in overlapping and non-overlapping FOVs.
C1 [Rho, Seungmin] Korea Univ, Sch Elect Engn, Seoul, South Korea.
   [Rho, Seungmin] Carnegie Mellon Univ, Comp Mus Lab, Sch Comp Sci, Pittsburgh, PA 15213 USA.
   [Nam, Yunyoung] Ajou Univ, Ctr Excellence Ubiquitous Syst, Suwon 441749, South Korea.
   [Nam, Yunyoung] SUNY Stony Brook, Stony Brook, NY USA.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, Seoul, South Korea.
   [Park, Jong Hyuk] Kyungnam Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Korea University; Carnegie Mellon University; Ajou University; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; Seoul National University of Science & Technology;
   Kyungnam University
RP Rho, S (corresponding author), Korea Univ, Sch Elect Engn, Seoul, South Korea.
EM young022@gmail.com; smrho@korea.ac.kr; jhpark1@seoultech.ac.kr
RI Rho, Seungmin/HTP-6683-2023; Nam, Yunyoung/AAI-4536-2020
OI Nam, Yunyoung/0000-0002-3318-9394
FU MKE(The Ministry of Knowledge Economy), Korea
   [NIPA-2010-C1090-1031-0004]; Ubiquitous Computing and Network (UCN);
   Ministry of Knowledge Economy (MKE); Korean government [10C2-T3-10M]
FX "This research was supported by the MKE(The Ministry of Knowledge
   Economy), Korea, under the ITRC(Information Technology Research Center)
   support program supervised by the NIPA (National IT Industry Promotion
   Agency)" (NIPA-2010-C1090-1031-0004) and this research is also supported
   by the Ubiquitous Computing and Network (UCN) Project, Knowledge and
   Economy Frontier R&D Program of the Ministry of Knowledge Economy (MKE),
   the Korean government, as a result of UCN's subproject 10C2-T3-10M.
CR Ali A, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P28, DOI 10.1109/EVENT.2001.938863
   [Anonymous], OPENCV OPEN COMPUTER
   [Anonymous], GOOGL EARTH API
   Ayers D, 2001, IMAGE VISION COMPUT, V19, P833, DOI 10.1016/S0262-8856(01)00047-6
   Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796
   Chae YN, 2009, P INT C VIRT REAL CO, P357
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Duong TV, 2005, PROC CVPR IEEE, P838
   Huang CL, 2001, IEEE T CIRC SYST VID, V11, P1281, DOI 10.1109/76.974682
   Huang T, 1997, INT JOINT CONF ARTIF, P1276
   Kelly P., 1995, PROC 3 ACE INT C MUL, P201
   Kettnaker V, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P267, DOI 10.1109/MMCS.1999.778358
   Lv F, 2004, PETS04
   Nam J, 2005, IEEE T MULTIMEDIA, V7, P667, DOI 10.1109/TMM.2005.843362
   Nam Y, 2007, WORLD ACAD SCI ENG T, V4, P254
   Petrushin VA, 2005, MACHINE LEARN SIGN P, P349, DOI 10.1109/MLSP.2005.1532927
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ribeiro P.C., 2005, Proceedings of International Workshop on Human Activity Recognition and Modelling, P61
   Ribnick Evan, 2006, VID SIGN BAS SURV 20
   Serby D, 2004, INT C PATT RECOG, P184, DOI 10.1109/ICPR.2004.1334091
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
   Zhang D, 2005, PROC CVPR IEEE, P611
   Zhao W, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P752, DOI 10.1109/MMCS.1999.778579
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 28
TC 31
Z9 34
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2012
VL 57
IS 2
BP 315
EP 334
DI 10.1007/s11042-010-0677-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 904HQ
UT WOS:000301185700005
DA 2024-07-18
ER

PT J
AU Sam, IS
   Devaraj, P
   Bhuvaneswaran, RS
AF Sam, I. Shatheesh
   Devaraj, P.
   Bhuvaneswaran, Raghuvel S.
TI A novel image cipher based on mixed transformed logistic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed logistic map; Image encryption; Zig-Zag diffusion
AB In this paper, a novel secure cryptosystem is proposed for direct encryption of color images, based on transformed logistic maps. The proposed cipher provides good confusion and diffusion properties that ensures extremely high security due to the mixing of colors pixels. The encryption scheme makes use of six odd secret keys and chaotic keys for each operation. The operations include initial permutation of all pixels with six odd keys, nonlinear diffusion using first chaotic key, xoring the second chaotic key with resultant values and zig-zag diffusion with third chaotic key. The proposed scheme supports key sizes ranging from 192 to 400 bits. The security and performance of the proposed image encryption technique have been analysed thoroughly using statistical analysis, key sensitivity analysis, differential analysis, key space analysis, entropy analysis and performance analysis. Results of the various types of analyses are showing that the proposed image encryption technique is more secure and fast and hence suitable for the real-time applications.
C1 [Sam, I. Shatheesh; Bhuvaneswaran, Raghuvel S.] Anna Univ Chennai, Coll Engn, Ramanujan Comp Ctr, Madras, Tamil Nadu, India.
   [Devaraj, P.] Anna Univ Chennai, Dept Math, Coll Engn, Madras, Tamil Nadu, India.
C3 Anna University; Anna University Chennai; Anna University; Anna
   University Chennai
RP Sam, IS (corresponding author), Anna Univ Chennai, Coll Engn, Ramanujan Comp Ctr, Madras, Tamil Nadu, India.
EM shatheeshsam@yahoo.com; devaraj@annauniv.edu; bhuvan@annauniv.edu
OI PONNAIAN, DEVARAJ/0000-0001-6613-1925
FU All India Council for Technical Education, New Delhi, India
FX This research is partially supported by the All India Council for
   Technical Education, New Delhi, India.
CR Alvarez G, 2009, COMMUN NONLINEAR SCI, V14, P3743, DOI 10.1016/j.cnsns.2009.02.033
   [Anonymous], 2016, HDB APPL CRYPTOGRAPH
   Baptista MS, 1998, PHYS LETT A, V240, P50, DOI 10.1016/S0375-9601(98)00086-3
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Gao TG, 2008, CHAOS SOLITON FRACT, V38, P213, DOI 10.1016/j.chaos.2006.11.009
   Jun H, 2009, IEEE INT C NETW SEC, P365
   Liu Shubo, 2008, IEEE INT WORKSH ED T, P803
   Liu S, 2009, SCI CHINA SER G, V52, P177, DOI 10.1007/s11433-009-0032-2
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Sabery M, 2008, 2008 INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER THEORY AND ENGINEERING, P585, DOI 10.1109/ICACTE.2008.177
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Xiao HP, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2707
   Xie JQ, 2009, NSWCTC 2009: INTERNATIONAL CONFERENCE ON NETWORKS SECURITY, WIRELESS COMMUNICATIONS AND TRUSTED COMPUTING, VOL 2, PROCEEDINGS, P111, DOI 10.1109/NSWCTC.2009.201
   Xu SJ, 2008, INT CONF SIGN PROCES, P1014, DOI 10.1109/ICOSP.2008.4697300
   Zhang YW, 2007, SCI CHINA SER F, V50, P334, DOI 10.1007/s11432-007-0026-5
NR 18
TC 60
Z9 61
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2012
VL 56
IS 2
SI SI
BP 315
EP 330
DI 10.1007/s11042-010-0652-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AR
UT WOS:000300189100006
DA 2024-07-18
ER

PT J
AU Cerqueira, E
   Zeadally, S
   Leszczuk, M
   Curado, M
   Mauthe, A
AF Cerqueira, Eduardo
   Zeadally, Sherali
   Leszczuk, Mikolaj
   Curado, Marilia
   Mauthe, Andreas
TI Recent advances in multimedia networking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Quality of service; Quality of experience; Content
   distribution; Networking; Mobile multimedia
ID TRANSMISSION
AB In recent years, the ubiquity of multimedia services along with the proliferation of mobile devices and the demand for new audio and video applications are changing the life style of users. User demands for multimedia access anywhere, anytime from any device are creating new challenges for research communities from both academia and industry. It is expected that video-based services alone will account for 50 percent of all consumer network traffic in 2012 and we will continue to witness the explosive growth in users sharing multimedia content over the Internet. In this context, new network, application, and user-based approaches must be created to deal with such complex multimedia systems. This paper presents some of the recent advances in multimedia networking focusing primarily on areas that have been receiving attention recently and are expected to continue to generate further interests in coming years. These areas include Quality of Experience (QoE) and various related standardization issues, Content Distribution Networks (CDNs), multimedia communications, mobile Multimedia. This paper also briefly highlights some of the major challenges that still need to be addressed to enable the support and delivery of multimedia services anywhere, anytime over highly heterogeneous infrastructures and user terminal devices.
C1 [Cerqueira, Eduardo] Fed Univ Para, BR-66075110 Belem, Para, Brazil.
   [Zeadally, Sherali] Univ Dist Columbia, Washington, DC 20008 USA.
   [Leszczuk, Mikolaj] AGH Univ Sci & Technol, PL-30059 Krakow, Poland.
   [Curado, Marilia] Univ Coimbra, P-3030290 Coimbra, Portugal.
   [Mauthe, Andreas] Univ Lancaster, Lancaster LA1 4WA, England.
C3 Universidade Federal do Para; University of the District of Columbia;
   AGH University of Krakow; Universidade de Coimbra; Lancaster University
RP Cerqueira, E (corresponding author), Fed Univ Para, Rua Augusto Correa 01, BR-66075110 Belem, Para, Brazil.
EM cerqueira@ufpa.br; szeadally@udc.edu; leszczuk@agh.edu.pl;
   marilia@dei.uc.pt; andreas@comp.lancs.ac.uk
RI Leszczuk, Mikołaj I/C-4857-2011; Cerqueira, Eduardo/HPC-8703-2023;
   Zeadally, Sherali/AAY-9504-2020; Monteiro, Edmundo/N-1341-2013; Curado,
   Marilia/F-2341-2018
OI Leszczuk, Mikołaj I/0000-0001-9123-1039; Cerqueira,
   Eduardo/0000-0003-2162-6523; Monteiro, Edmundo/0000-0003-1615-2925;
   Curado, Marilia/0000-0001-6760-4675
FU CNPq [476202/2009-4]; PROPESP UFPA; FAPESPA [5183.UNI319.4107.07072009 -
   5467.UNI317.1279.31082009]; European Community's Seventh Framework
   Program FP7/2007-2013 [218086]; Ministry of Science and Higher Education
   of the Republic of Poland [PBZ-MNiSW-02/II/2007,
   POIG.01.01.02-00-045/09-00]; European Regional Development Fund, Future
   Internet Engineering [5467.UNI317.1279.31082009]; NSF [0911969];
   District of Columbia NASA Space; FCT UBIQUIMESH
   [PTDC/EEATEL/105472/2008]; Division Of Graduate Education; Direct For
   Education and Human Resources [0911969] Funding Source: National Science
   Foundation
FX Eduardo Cerqueira was supported by CNPq 476202/2009-4, PROPESP UFPA and
   FAPESPA 5183.UNI319.4107.07072009 - 5467.UNI317.1279.31082009. Mikolaj
   Leszczuk has received funding from the European Community's Seventh
   Framework Program (FP7/2007-2013) under grant agreement n degrees 218086
   and from the Ministry of Science and Higher Education of the Republic of
   Poland, under the projects n degrees PBZ-MNiSW-02/II/2007 and
   POIG.01.01.02-00-045/09-00 (European Regional Development Fund, Future
   Internet Engineering) - 5467.UNI317.1279.31082009. Sherali Zeadally was
   supported by an NSF award (No. 0911969) and a grant from the District of
   Columbia NASA Space Grant Consortium during this work. Marilia Curado
   was supported by FCT UBIQUIMESH project (PTDC/EEATEL/105472/2008).
CR ANDI W, 2008, P 2008 2 INT C MOB U
   [Anonymous], 2005, RFC 4080
   [Anonymous], 2009, 802212008 IEEE
   BELLAVISTA P, 2009, IEEE T NETWORKS SERV, V6
   BERNARDO V, 2009, P IEEE WORKSH MULT A
   BLESS R, 2009, P 8 INT IFIP TC 6 NE
   BOURAS C, 2008, P WWRF 21 M WG3 FUT
   Chilamkurti N, 2010, MULTIMED TOOLS APPL, V47, P189, DOI 10.1007/s11042-009-0413-6
   Díaz A, 2010, COMPUT COMMUN, V33, P322, DOI 10.1016/j.comcom.2009.09.007
   Exposito E, 2008, COMPUT NETW, V52, P1125, DOI 10.1016/j.comnet.2007.12.008
   FORD C, 2010, IEEE C MULT COMM SER
   HUANG C, 2008, P 8 ACM SIGCOMM C IN
   JACOBSON V, 2009, P 5 INT C EM NETW EX
   Kofler I, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P3, DOI 10.1109/SMAP.2007.34
   Koponen T., 2007, SIGCOMM Computer Communications Rev, V37
   Latré S, 2009, COMPUT NETW, V53, P1587, DOI 10.1016/j.comnet.2008.11.004
   LAZAR I, 2001, IT PROFESSIONAL, V3
   Lee DB, 2010, J VIS COMMUN IMAGE R, V21, P245, DOI 10.1016/j.jvcir.2010.01.002
   Liang C, 2009, IEEE INFOCOM SER, P2741, DOI 10.1109/INFCOM.2009.5062223
   MANNER J, 2008, NSLP QUALIT IN PRESS
   MATOS R, 2009, P 5 IEEE INT C WIR M
   Milani S, 2009, IEEE T MULTIMEDIA, V11, P810, DOI 10.1109/TMM.2009.2021791
   Mu Mu, 2009, International Journal of Internet Protocol Technology, V4, P54, DOI 10.1504/IJIPT.2009.024170
   Plagemann T, 2006, COMPUT COMMUN, V29, P551, DOI 10.1016/j.comcom.2005.06.006
   REY J, 2008, P 45 ACM IEEE DES AU
   ROMANIAK P, 2008, P 18 ITC SPEC SEM QU, P242
   SOUSA B, 2008, P 7 INT C MOB UB MUL
   STOICA I, 2002, P 2002 C APPL TECHN
   Takahashi A, 2008, IEEE COMMUN MAG, V46, P78, DOI 10.1109/MCOM.2008.4473087
   Tong W, 2008, IEEE MICROW MAG, V9, P64, DOI 10.1109/MMM.2008.924968
   TYSON G, 2009, P 16 ACM SPIE MULT C
   TYSON G, 2008, P 5 INT WORKSH NEXT
   *US DEP COMM, 2010, PUBL SAF COMM RES PR
   van der Schaar M, 2003, IEEE J SEL AREA COMM, V21, P1752, DOI 10.1109/JSAC.2003.815231
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Verma D., 2002, CONTENT DISTRIBUTION
   *VQEG, 2010, HDTV
   *VQEG, 2010, VQEG TEST PLAN EV VI
   2001, NEW WAY LOOK NETWORK
NR 39
TC 11
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2011
VL 54
IS 3
SI SI
BP 635
EP 647
DI 10.1007/s11042-010-0578-z
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 790CH
UT WOS:000292565600006
OA hybrid
DA 2024-07-18
ER

PT J
AU Mehmood, R
   Alturki, R
AF Mehmood, Rashid
   Alturki, Raad
TI A scalable multimedia QoS architecture for ad hoc networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Quality of service; Ad hoc networks; Provisioning; Routing
   protocols; QoS architecture
AB Communication demands have grown from separate data and voice to integrated multimedia, paving the way to converging fixed, mobile and IP networks. Supporting Multimedia is a challenging task for wireless ad hoc network designers. Multimedia forms high data rate traffic with stringent Quality of Service (QoS) requirements. Wireless ad hoc networks are characterized by frequent topology changes, unreliable wireless channel, network congestion and resource contention. Providing scalable QoS is the most important challenge for multimedia delivery over ad hoc networks. We introduce here a provisioning and routing architecture for ad hoc networks which scales well while provisioning QoS. The proposed architecture is analysed using a mix of HTTP, voice and video streaming applications over 54 Mbps 802.11 g-based ad hoc networks. The architecture is simulated and compared to well-known routing protocols using the OPNET Modeller. The results show that our architecture scales well with increase in the network size, and outperforms well-known routing protocols.
C1 [Mehmood, Rashid; Alturki, Raad] Swansea Univ, Sch Engn, Swansea SA2 8PP, W Glam, Wales.
C3 Swansea University
RP Mehmood, R (corresponding author), Swansea Univ, Sch Engn, Swansea SA2 8PP, W Glam, Wales.
EM R.Mehmood@swansea.ac.uk
RI Mehmood, Rashid/AFV-3953-2022
OI Mehmood, Rashid/0000-0002-4997-5322
CR [Anonymous], 2004, AD HOC NETW, DOI DOI 10.1016/S1570-8705(03)00043-X
   Broch J., 1998, MobiCom'98. Proceedings of Fourth Annual ACM/IEEE International Conference on Mobile Computing and Networking, P85, DOI 10.1145/288235.288256
   Chao HL, 2003, IEEE J SEL AREA COMM, V21, P1642, DOI 10.1109/JSAC.2003.815232
   ELHADEF M, 2006, P 9 ACM INT S MOD AN, P165
   GERLA M, 2000, P IEEE GLOBECOM 2000
   Goldsmith AJ, 2002, IEEE WIREL COMMUN, V9, P8, DOI 10.1109/MWC.2002.1028874
   Jain R, 2004, IEEE MULTIMEDIA, V11, P96, DOI 10.1109/MMUL.2004.1261114
   Jönsson U, 2000, MOBIHOC: 2000 FIRST ANNUAL WORKSHOP ON MOBILE AND AD HOC NETWORKING AND COMPUTING, P75, DOI 10.1109/MOBHOC.2000.869215
   Li BC, 2003, IEEE J SEL AREA COMM, V21, P1627, DOI 10.1109/JSAC.2003.815964
   Mao SW, 2003, IEEE J SEL AREA COMM, V21, P1721, DOI 10.1109/JSAC.2003.815965
   MEHMOOD R, 2005, P 6 IEEE ACM INT WOR
   MEHMOOD R, 2004, THESIS U BIRMINGHAM
   Mehmood R, 2005, UCAMCLTR650
   Ramanathan R, 2002, IEEE COMMUN MAG, P20
   *SCAL NETW TECHN, QUALNET NETW SIM
   Tyan J, 2005, MOBILE NETW APPL, V10, P423, DOI 10.1007/s11036-005-1555-z
   XU K, 2002, P IEEE ICC 02
   Xu KX, 2003, IEEE MILIT COMMUN C, P1018
NR 18
TC 10
Z9 10
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2011
VL 54
IS 3
SI SI
BP 551
EP 568
DI 10.1007/s11042-010-0569-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 790CH
UT WOS:000292565600002
DA 2024-07-18
ER

PT J
AU Samphaiboon, N
AF Samphaiboon, Natthawut
TI Steganography via running short text messages
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Text steganography; Covert communication; Information
   hiding; Information security
ID WATERMARKING
AB Steganography, or covert communication between two parties through public channels, has been received a lot of attention, since the mere existence of encrypted message might cause suspicion and could even provide useful information to eavesdroppers. In some cases, secret information needs to be covertly broadcast to receivers in multiple locations at the same time. In this paper, we propose a novel steganographic scheme, which covertly sends secret message to multiple receivers via a stream of running short text messages displayed on a media output screen, assuming appropriate optical character recognition (OCR) functionality at the decoder. We use Thai language short text messages as a case study. We analyze the characteristics of Thai short text messages and introduce some effective message-to-bit transformation methods. We find that one Thai short text message can be transformed into multiple secret bits. In principle, the proposed transformation methods can be applied to short text messages in any language. We use a provably secure construction that guarantees covertness, privacy, and authenticity of the secret data against active attacks. In an experimental evaluation, we show that four secret message bits can be embedded in each short text message. In addition, we find that the embedded bits can be retrieved correctly and easily by human observers without OCR functionality at the decoder. Thus, the scheme is practical and effective for covert communication from one sender to multiple receivers over public channels.
C1 Asian Inst Technol, Klongluang 12120, Pathumthani, Thailand.
C3 Asian Institute of Technology
RP Samphaiboon, N (corresponding author), Asian Inst Technol, POB 4, Klongluang 12120, Pathumthani, Thailand.
EM nata@cs.ait.ac.th
FU Royal Thai Government
FX Supported in part by a graduate fellowship from the Royal Thai
   Government.
CR Amano T., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P91, DOI 10.1109/ICDAR.1999.791732
   Brassil JT, 1999, P IEEE, V87, P1181, DOI 10.1109/5.771071
   Cvejic N, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P533, DOI 10.1109/ITCC.2004.1286709
   DAILEY M, 2009, DO EMBEDDING STEGANO
   Huang D, 2001, IEEE T CIRC SYST VID, V11, P1237, DOI 10.1109/76.974678
   KAROONBOONYANAN T, 1999, STANDARDIZATION IMPL
   Kim YW, 2004, PATTERN RECOGN LETT, V25, P1243, DOI 10.1016/j.patrec.2004.04.002
   Kim YW, 2003, PROC INT CONF DOC, P775
   Koanantakool T, 1991, INFORM PROCESSING I
   Liu YL, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2094
   Lou DC, 2002, COMPUT SECUR, V21, P449, DOI 10.1016/S0167-4048(02)00515-1
   Muhammad HZ, 2009, 2009 CONFERENCE ON INNOVATIVE TECHNOLOGIES IN INTELLIGENT SYSTEMS AND INDUSTRIAL APPLICATIONS, P423, DOI 10.1109/CITISIA.2009.5224169
   Rogaway P., 2003, ACM Transactions on Information and Systems Security, V6, P365, DOI 10.1145/937527.937529
   SAMPHAIBOON N, 2008, P ECTI CON 2008 KRAB
   SHIRALISHAHREZA M, 2007, INT C CONV INF TECHN, P2260
   SHIRALISHAHREZA MH, 2006, P 5 IEEE ACIS INT C, P310
   Su JK, 1998, COMPUT GRAPH-UK, V22, P687, DOI 10.1016/S0097-8493(98)00089-2
   Sun Xingming., 2004, INFOS TERNATIONAL C, P76
   TOPKARA M, 2005, P SPIE IS T EL IM 20
   ZHANG W, 2006, 2 INF COMM TEXHN ICT, V1, P1850
NR 20
TC 4
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 569
EP 596
DI 10.1007/s11042-009-0432-3
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000019
DA 2024-07-18
ER

PT J
AU Han, J
   de With, PHN
AF Han, Jungong
   de With, Peter H. N.
TI Real-time multiple people tracking for automatic group-behavior
   evaluation in delivery simulation training
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multiple people tracking; MRF; Automatic assessment; Group behavior
   analysis; Real time
ID IMAGE SEQUENCES
AB This paper aims at generating an automated way to evaluate the team-behavior of trainees in a delivery simulation course using video-processing techniques with emphasis on multiple people tracking. The paper is composed of two interacting, but clearly separated stages: moving people segmentation and multiple people tracking. At people segmentation stage, the combination of the Gaussian Mixture Model (GMM) and the Dynamic Markov Random Fields (DMRF) technique helps to extract the foreground pixels. For a better extraction of the human silhouettes, the energy function of DMRF is extended with texture information. At multiple people tracking stage, we concentrate on solving human-occlusion problem caused by interacting persons based on silhouette data and a non-linear regression model. Our model effectively transfers the person location problem during the occlusion into the finding of the local maximum points on a smooth curve, so that visual persons in the partial or complete occlusion can still be precisely captured. We have compared our algorithm with two other popular tracking algorithms: mean-shift and particle-filter. Experimental results reveal that the correctness of our method is much higher than the mean-shift algorithm and slightly lower than a particle-filter, however, with the major benefit of being a factor of 10-15 faster in computing.
C1 [Han, Jungong; de With, Peter H. N.] Eindhoven Univ Technol, Fac Elect Engn, NL-5600 MB Eindhoven, Netherlands.
C3 Eindhoven University of Technology
RP Han, J (corresponding author), Eindhoven Univ Technol, Fac Elect Engn, POB 513, NL-5600 MB Eindhoven, Netherlands.
EM jungonghan@hotmail.com
RI Han, Jungong/ABE-6812-2020
CR AACH T, 1995, SIGNAL PROCESS-IMAGE, V7, P147, DOI 10.1016/0923-5965(95)00003-F
   Antonakaki P, 2009, SIGNAL PROCESS, V89, P1723, DOI 10.1016/j.sigpro.2009.03.016
   Chen DT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198308
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cutler R, 1998, INT C PATT RECOG, P495, DOI 10.1109/ICPR.1998.711189
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   HAN J, 2008, P C ICME, V1, P305
   Han JG, 2008, IEEE T CIRC SYST VID, V18, P1628, DOI 10.1109/TCSVT.2008.2005611
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Hazelhoff L, 2008, LECT NOTES COMPUT SC, V5259, P298, DOI 10.1007/978-3-540-88458-3_27
   JAIN R, 1979, IEEE T PATTERN ANAL, V1, P206, DOI 10.1109/TPAMI.1979.4766907
   Kohli P, 2007, IEEE T PATTERN ANAL, V29, P2079, DOI 10.1109/TPAMI.2007.1128
   Koile K, 2003, LECT NOTES COMPUT SC, V2864, P90
   LAO W, 2007, P SPIE INT C MULT MO, V2, P405
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   TSAIG Y, 2000, P INT C COMP VIS PAT, P889
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhou Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1079, DOI 10.1109/ICCV.2003.1238469
   Zhou ZN, 2008, IEEE T CIRC SYST VID, V18, P1489, DOI 10.1109/TCSVT.2008.2005612
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 22
TC 11
Z9 11
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2011
VL 51
IS 3
BP 913
EP 933
DI 10.1007/s11042-009-0423-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 717XL
UT WOS:000287081100004
OA hybrid
DA 2024-07-18
ER

PT J
AU Böszörmenyi, L
   del Fabro, M
   Kogler, M
   Lux, M
   Marques, O
   Sobe, A
AF Boeszoermenyi, Laszlo
   del Fabro, Manfred
   Kogler, Marian
   Lux, Mathias
   Marques, Oge
   Sobe, Anita
TI Innovative directions in self-organized distributed multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed multimedia systems; Self-organized multimedia applications;
   Video delivery; Video streaming; User experience; Social multimedia
   systems
AB The way by which multimedia contents are produced, delivered across networks, and consumed by intended users have shifted significantly during the past 10 years. In this paper we postulate that, in the near future, flexible and self-organizing facilities will play a dominating role in distributed multimedia systems. We discuss how such systems can be designed, using a three-layer (sensor, distribution, and user layer) architecture, SOMA (Self Organizing Multimedia Architecture), as an example. We also present innovative directions in three main aspects of self-organized multimedia systems: (i) the self-organizing aspects of multimedia user communities, e.g., the wisdom, intentions, and needs of users; (ii) a fresh look at video streams that treat them as a collection of units that can be composed taking user and network aspects into account; and (iii) new delivery paradigms and how self-organization and multimedia delivery can be combined.
C1 [Marques, Oge] Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, Boca Raton, FL 33431 USA.
   [Boeszoermenyi, Laszlo; del Fabro, Manfred; Kogler, Marian; Lux, Mathias; Sobe, Anita] Klagenfurt Univ, Inst Informat Technol, A-9020 Klagenfurt, Austria.
C3 State University System of Florida; Florida Atlantic University;
   University of Klagenfurt
RP Marques, O (corresponding author), Florida Atlantic Univ, Dept Comp & Elect Engn & Comp Sci, 777 Glades Rd, Boca Raton, FL 33431 USA.
EM laszlo@itec.uni-klu.ac.at; manfred@itec.uni-klu.ac.at;
   mkogler@itec.uni-klu.ac.at; mlux@itec.uni-klu.ac.at; omarques@fau.edu;
   anita.sobe@itec.uni-klu.ac.at
RI ; Marques, Oge/I-4933-2014
OI Lux, Mathias/0000-0002-8688-6388; Marques, Oge/0000-0003-4321-2719
FU Lakeside Labs Research and Technology Center, Klagenfurt; Klagenfurt
   University, Austria
FX The SOMA project has been funded by the Lakeside Labs Research and
   Technology Center, Klagenfurt and by the Klagenfurt University, Austria.
   Further thanks go to Wilfried Elmenreich, Christoph Kofler, Arthur
   Pitman, Felix Pletzer, Bernhard Rinner, Klaus Schoffmann, Markus
   Strohmaier, Roland Tusch and Stefan Wieser for their ongoing work on the
   topic and their help.
CR Androutsellis-Theotokis S, 2004, ACM COMPUT SURV, V36, P335, DOI 10.1145/1041680.1041681
   [Anonymous], 2007, MIR
   [Anonymous], CIVR 07
   Babaoglu O, 2006, ACM T AUTON ADAP SYS, V1, P26, DOI 10.1145/1152934.1152937
   Brinkschulte U, 2007, LECT NOTES COMPUT SC, V4761, P339
   Broder A., 2002, SIGIR Forum, V36, P3, DOI 10.1145/792550.792552
   CAPOVILLA N, 2010, P 2 INT C MULT MMEDI
   CATTUTO C, 2007, AI COMMUNICATIONS SP
   Choe Y.R., 2007, MULTIMEDIA 07 P 15 I, P117
   COHEN B, 2008, BEP0003 BITTORRENT P
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Elmenreich W, 2009, LECT NOTES COMPUT SC, V5918, P37, DOI 10.1007/978-3-642-10865-5_4
   Elmenreich W, 2008, LECT NOTES COMPUT SC, V5343, P1, DOI 10.1007/978-3-540-92157-8_1
   Gershenson C, 2003, LECT NOTES ARTIF INT, V2801, P606
   Herrmann K, 2007, FIRST IEEE INTERNATIONAL CONFERENCE ON SELF-ADAPTIVE AND SELF-ORGANIZING SYSTEMS, P13, DOI 10.1109/SASO.2007.54
   Heylighen F, 2003, IEEE INTELL SYST, V18, P72, DOI 10.1109/MIS.2003.1217631
   HEYLIGHEN F, 2003, SCI SELF ORG ADAPTIV, P184
   Hotho A, 2006, LECT NOTES COMPUT SC, V4011, P411
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   JANSEN BJ, 2007, WWW 2007, P1149
   Khan S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P503, DOI 10.1109/ICME.2004.1394239
   KOFLER C, 2009, I KNOW 09, P208
   KOFLER C, 2009, P 17 ACM INT C MULT, P1117
   KOGLER M, 2010, P KDD2010 IN PRESS
   LI X, 2008, SIGIR, P339
   Li XR, 2009, INT CONF ACOUST SPEE, P3717, DOI 10.1109/ICASSP.2009.4960434
   LUX M, 2008, INT WORKSH KNOWL ACQ
   LUX M, 2007, 4 INT WORKSH TEXT IN, P283
   LUX M, 2010, INT WORKSH SOC AD PE
   LUX M, 2010, P ACM CHI 2010 ATL G
   Lux M, 2010, MULTIMED TOOLS APPL, V46, P521, DOI 10.1007/s11042-009-0353-1
   Makadia A, 2008, LECT NOTES COMPUT SC, V5304, P316, DOI 10.1007/978-3-540-88690-7_24
   Mamei M, 2006, J SYST ARCHITECT, V52, P443, DOI 10.1016/j.sysarc.2006.02.002
   Padmanabhan V.N., 2002, P 12 INT WORKSHOP NE, P177
   PLETZER F, 2010, SEISMYC 2010
   Prehofer C, 2005, IEEE COMMUN MAG, V43, P78, DOI 10.1109/MCOM.2005.1470824
   Rose D.E., 2004, P 13 INT C WORLD WID, P13, DOI [DOI 10.1145/988672.988675, 10.1145/988672.988675]
   Snoek C.G.M., 2008, TRECVID
   SOBE A, 2009, SINGLE SIGN ON IMS B
   SOBE A, 2010, SAPMIA 2010
   Sobe A., 2010, IARIA INT J ADV SOFT, V3, P19
   Spielvogel C, 2007, SECOND INTERNATIONAL WORKSHOP ON SEMANTIC MEDIA ADAPTATION AND PERSONALIZATION, PROCEEDINGS, P21, DOI 10.1109/SMAP.2007.17
   Spielvogel C, 2007, PROCEEDINGS OF THE IASTED INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING AND NETWORKS, P303
   Uijlings J. R., 2009, P ACM INT C IMAGE VI, P1
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   Verbeek J., 2010, Proc. ACM Multimedia Information Retrieval, P537
   Vlavianos Aggelos., 2006, Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications, P1
   WIESER S, 2010, MMEDIA 2010, P119
NR 48
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 525
EP 553
DI 10.1007/s11042-010-0622-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300006
DA 2024-07-18
ER

PT J
AU Konstantinou, N
   Solidakis, E
   Zafeiropoulos, A
   Stathopoulos, P
   Mitrou, N
AF Konstantinou, Nikolaos
   Solidakis, Emmanuel
   Zafeiropoulos, Anastasios
   Stathopoulos, Panagiotis
   Mitrou, Nikolas
TI A context-aware middleware for real-time semantic enrichment of
   distributed multimedia metadata
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic; Middleware; Rule-based; Real-time; Context-aware; Annotation
ID WEB; RECOGNITION; EIGENFACES; FRAMEWORK
AB This paper investigates the problem of the real-time integration and processing of multimedia metadata collected by a distributed sensor network. The discussed practical problem is the efficiency of the technologies used in creating a Knowledge Base in real-time. Specifically, an approach is proposed for the real-time, rule-based semantic enrichment of lower level context features with higher-level semantics. The distinguishing characteristic is the provision of an intelligent middleware-based architecture on which low level components such as sensors, feature extraction algorithms, data sources, and high level components such as application-specific ontologies can be plugged. Throughout the paper, Priamos, a middleware architecture based on Semantic Web technologies is presented, together with a stress-test of the system's operation under two test case scenarios: A smart security surveillance application and a smart meeting room application. Performance measurements are conducted and corresponding results are exposed.
C1 [Konstantinou, Nikolaos; Solidakis, Emmanuel; Zafeiropoulos, Anastasios; Stathopoulos, Panagiotis; Mitrou, Nikolas] Natl Tech Univ Athens, Athens 15773, Greece.
C3 National Technical University of Athens
RP Konstantinou, N (corresponding author), Natl Tech Univ Athens, Heroon Polytech Str, Athens 15773, Greece.
EM nkons@cn.ntua.gr
RI Zafeiropoulos, Anastasios/T-6478-2019; Konstantinou,
   Nikolaos/J-4676-2014
OI Zafeiropoulos, Anastasios/0000-0003-0078-8697; Konstantinou,
   Nikolaos/0000-0003-3742-9276
CR ALLEN BD, 2001, TRACKING 15 MINUTES
   [Anonymous], 2008, W3C RECOMMENDATION
   [Anonymous], WORKSH SEM WEB DAT
   [Anonymous], 2004, W3C recommendation
   [Anonymous], HPL2003146
   Baader F., 2002, Basic Description Logics, P47
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   BECHHOFER S, 2006, DIG 2 0 DIG DESCRIPT
   BECHHOFER S, 2004, RECOWLREF20040210 WO
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BLACK W, 2003, TRU4 UMIST
   Bradski GR, 1998, INTEL TECHNOL J
   BUITELAAR P, 2004, 1 EUR SEM WEB S ESWS
   Cardoso J, 2007, IEEE INTELL SYST, V22, P84, DOI 10.1109/MIS.2007.4338499
   Chakravarthy A., 2006, P 1 SEM WEB AUTH ANN
   Chen H, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P277, DOI 10.1109/PERCOM.2004.1276865
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Dey AK, 2000, MANAGING INTERACTIONS IN SMART ENVIRONMENTS, P114
   Dey AK, 2001, PERS UBIQUIT COMPUT, V5, P4, DOI 10.1007/s007790170019
   DOU D, 2006, P 2 INT WORKSH SCAL, P129
   DOUGHERTY E, 1995, WHAT IS REAL TIME PR, P1
   Etzioni O, 2005, ARTIF INTELL, V165, P91, DOI 10.1016/j.artint.2005.03.001
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   GOASDOUE F, 1999, LECT NOTES ARTIF INT, V1621, P121
   Hirtle D., 2006, SCHEMA SPECIFICATION
   Horrocks I.R., 1998, KR, P636
   Horrocks Ian., 2003, Journal of Web Semantics, V1, P7, DOI [DOI 10.1016/J.WEBSEM.2003.07.001, https://doi.org/10.1016/j.websem.2003.07.001]
   Vazquez JI, 2006, LECT NOTES COMPUT SC, V3983, P108, DOI 10.1007/11751632_12
   IRIA J, 2004, P EKAW WORKSH APPL L
   KAGAL L, 2003, P IEEE 4 INT WORKSH
   KARAME G, 2007, ADV VID SIGN BAS SUR, P371
   Kaykova O., 2005, International Journal on Semantic Web and Information Systems, V1, P31, DOI 10.4018/jswis.2005070102
   KONSTANTINOU N, 2007, IET INT C INT ENV IE, P96
   Lassila O, 2005, PROCEEDINGS OF MOBIQUITOUS 2005, P183
   Lien CC, 2007, J VIS COMMUN IMAGE R, V18, P1, DOI 10.1016/j.jvcir.2006.09.002
   Liu S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/32135
   MASUOKA R, 2003, 2 INT SEM WEB C ISWC
   May W, 2005, LECT NOTES COMPUT SC, V3791, P30, DOI 10.1007/11580072_4
   Motik B, 2006, LECT NOTES ARTIF INT, V4246, P227, DOI 10.1007/11916277_16
   PANDIS I, 2005, P 2 INT C EMB SOFTW
   Patel-Schneider P.F., 2004, OWL Web Ontology Lan-guage semantics and abstract syntax
   PETRIDIS K, 2006, ENG APPL SEM WEB SES
   Roman M., 2002, SIGMOBILE MOBILE COM, P65
   Schroeter R, 2006, P 2 IEEE INT C E SCI, P41
   Seaborne A., 2008, W3C Member Submission, V15
   Shankar Vembu, 2006, P 1 INT WORKSH SEM W
   Sirin E, 2007, J WEB SEMANT, V5, P51, DOI 10.1016/j.websem.2007.03.004
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   Stamou G, 2006, IEEE MULTIMEDIA, V13, P86, DOI 10.1109/MMUL.2006.15
   Stergiou A, 2007, LECT NOTES COMPUT SC, V4122, P223
   Toninelli A, 2006, LECT NOTES COMPUT SC, V4273, P473
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Uren V, 2006, J WEB SEMANT, V4, P14, DOI 10.1016/j.websem.2005.10.002
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   VU VT, 2003, P 18 INT JOINT C ART, P1295
   Zafeiropoulos Anastasios, 2008, Second International Conference on Mobile Ubiquitous Computing, Systems, Services and Technologies 2008, P116, DOI 10.1109/UBICOMM.2008.67
   Zhang D., 2002, ACM Multimedia, P315
NR 57
TC 2
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 425
EP 461
DI 10.1007/s11042-009-0361-1
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300012
DA 2024-07-18
ER

PT J
AU Shi, XB
   Wang, X
   Bi, J
   Liu, F
   Yang, D
   Liu, XY
AF Shi, Xiang-Bin
   Wang, Xue
   Bi, Jing
   Liu, Fang
   Yang, Dan
   Liu, Xian-Yan
TI A DR algorithm based on artificial potential field method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MMOG; Dead reckoning algorithm; Artificial potential field; Q-Learning
AB Considering player entity's motion regularity into DR (Dead Reckoning) algorithm can improve its prediction accuracy in MMOG (Massively Multiplayer Online Games), a novel DR algorithm was proposed to solve this problem in this paper. First the artificial potential field model of player entities is created, and then the acceleration of player entities is weighted with the acceleration produced by the potential field force and the acceleration reckoned by the traditional DR algorithm. In order to calculate the weight, Q-Learning algorithm is used. The experiments show that the method can improve prediction accuracy and reduce the network traffic.
C1 [Shi, Xiang-Bin; Bi, Jing; Liu, Fang] Shenyang Inst Aeronaut Engn, Dept Comp, Shenyang 110136, Peoples R China.
   [Shi, Xiang-Bin; Wang, Xue; Yang, Dan; Liu, Xian-Yan] Liaoning Univ, Sch Informat Sci & Technol, Shenyang 110036, Peoples R China.
C3 Shenyang Aerospace University; Liaoning University
RP Shi, XB (corresponding author), Shenyang Inst Aeronaut Engn, Dept Comp, Shenyang 110136, Peoples R China.
EM sxb@syiae.edu.cn
RI liu, xy/JEP-3175-2023
FU Natural Science Foundation of Liaoning Province of China [20052007];
   Foundation of Liaoning Educational Committee [2004D116]
FX This paper was supported by a grant from the Natural Science Foundation
   of Liaoning Province of China (20052007) and Foundation of Liaoning
   Educational Committee (2004D116). Special thanks to colleagues in our
   lab helped us in experimental design.
CR Bridle J., 1989, P 2 INT C NEURAL INF, V2, P211
   DELANEY D, 2005, NOVEL CONVERGENCE AL, P118
   DELANEY D, 2003, REDUCING UPDATE PACK, P417
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Kim HG, 2005, LECT NOTES COMPUT SC, V3768, P676
   MADDEN D, 2004, EXPLORING SPATIAL DE, P210
   MADDEN D, 2004, VISIBILITY PATH FIND, P91
   MARSHALL D, 2004, REALISTIC DISTRIBUTE, P83
   MCCOY A, 2006, MACH LEARN SIGNAL PR, P295, DOI DOI 10.1109/MLSP.2006.275564
   MCCOY A, 2004, STAT CLIENT PREDICTI, P144
   McCoy A, 2007, ACM T MODEL COMPUT S, V17, DOI 10.1145/1276927.1276929
   SINGHAL SK, 1995, PRESENCE-TELEOP VIRT, V4, P169, DOI 10.1162/pres.1995.4.2.169
   Sutton R., 1998, Reinforcement Learning: An Introduction
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   YANG HY, 2000, J COMPUT RES DEV, V37, P954
   Yang Ming, 2000, Journal of System Simulation, V12, P439
NR 16
TC 1
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2009
VL 45
IS 1-3
SI SI
BP 247
EP 261
DI 10.1007/s11042-009-0296-6
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 490VE
UT WOS:000269534900011
DA 2024-07-18
ER

PT J
AU Yu, HF
   Yang, HC
   Wang, YT
   Fan, PL
   Chien, CY
AF Yu, Hsiang-Fu
   Yang, Hung-Chang
   Wang, Yao-Tien
   Fan, Ping-Lin
   Chien, Chu-Yi
TI Broadcasting scheme with low client buffers and bandwidths for
   video-on-demand applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periodic broadcasting; Video-on-demand (VOD); Buffer; Cable TV
ID SEAMLESS CHANNEL TRANSITION
AB Efficient data broadcasting is independent of request arrivals, and is thus highly promising when transmitting popular videos. A conventionally adopted broadcasting method is periodic broadcasting, which divides a popular video into segments, which are then simultaneously broadcast on different data channels. Once clients want to watch the video, they download the segments from these channels. The skyscraper broadcasting (SkB) scheme supports clients with small bandwidths. An SkB client requires only two-channel bandwidths to receive video segments. This work proposes a reverse SkB (RSkB) scheme, which extends SkB by reducing buffering spaces. The RSkB is mathematically shown to achieve on-time video delivery and two-channel client bandwidths. A formula for determining the maximum number of segments buffered by an RSkB client is presented. Finally, an analysis of RSkB reveals that its client buffer requirements are usually 25-37% lower than SkB. Extensive simulations of RSkB further demonstrate that RSkB yields lower client buffer demand than other proposed systems.
C1 [Yu, Hsiang-Fu; Chien, Chu-Yi] Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
   [Yang, Hung-Chang] Natl Cent Univ, Dept Comp Sci & Informat Engn, Tao Yuan, Taiwan.
   [Wang, Yao-Tien] Kainan Univ, Dept Informat Management, Tao Yuan, Taiwan.
   [Fan, Ping-Lin] Natl Taipei Univ Educ, Grad Sch Toy & Game Design, Taipei, Taiwan.
C3 National Taipei University of Education; National Central University;
   Nan Kai University Technology; National Taipei University of Education
RP Yu, HF (corresponding author), Natl Taipei Univ Educ, Dept Comp Sci, Taipei, Taiwan.
EM yu@dslab.csie.ncu.edu.tw
CR Bar-Noy A, 2003, SIAM J COMPUT, V32, P1091, DOI 10.1137/S009753970240447X
   Chien WD, 2005, IEEE T BROADCAST, V51, P360, DOI 10.1109/TBC.2005.852251
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Gao LX, 2002, MULTIMEDIA SYST, V8, P284, DOI 10.1007/s005300100049
   Guo Y, 2004, IEEE T MULTIMEDIA, V6, P387, DOI 10.1109/TMM.2003.822786
   HUA KA, 1997, SKYSCRAPER BROADCAST
   Juhn LS, 1998, IEEE T BROADCAST, V44, P182, DOI 10.1109/11.713070
   Juhn LS, 1998, IEEE T BROADCAST, V44, P100, DOI 10.1109/11.713059
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   Kwon JB, 2002, IEEE T CONSUM ELECTR, V48, P41, DOI 10.1109/TCE.2002.1010090
   Leung YW, 2003, IEEE T MULTIMEDIA, V5, P130, DOI 10.1109/TMM.2003.808818
   Nikolaus B, 2005, IEEE T BROADCAST, V51, P354, DOI 10.1109/TBC.2005.852252
   Paris J.-F., 1999, Proceedings Eight International Conference on Computer Communications and Networks (Cat. No.99EX370), P118, DOI 10.1109/ICCCN.1999.805505
   Pâris JF, 1998, IEEE IC COMP COM NET, P690, DOI 10.1109/ICCCN.1998.998831
   Paris JF, 1998, SIXTH INTERNATIONAL SYMPOSIUM ON MODELING, ANALYSIS AND SIMULATION OF COMPUTER AND TELECOMMUNICATION SYSTEMS, PROCEEDINGS, P127, DOI 10.1109/MASCOT.1998.693685
   Pâris JF, 2001, IEEE IPCCC, P347, DOI 10.1109/IPCCC.2001.918672
   Saparilla D, 1999, IEEE INFOCOM SER, P464, DOI 10.1109/INFCOM.1999.751379
   Sheu JP, 2004, IEEE T BROADCAST, V50, P120, DOI 10.1109/TBC.2004.828754
   Tantaoui MA, 2004, IEEE T BROADCAST, V50, P289, DOI 10.1109/TBC.2004.834202
   TANTAOUI MA, 2002, P 10 ACM INT C MULT, P29
   Tseng YC, 2004, IEEE ACM T NETWORK, V12, P559, DOI 10.1109/TNET.2004.828965
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Tseng YC, 2001, IEEE T COMMUN, V49, P863, DOI 10.1109/26.923810
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   WENG SZ, 2001, P NATL COMP S, P115
   Yang ZY, 1999, IEEE T BROADCAST, V45, P318, DOI 10.1109/11.796274
   Yu HF, 2005, COMPUT COMMUN, V28, P1903, DOI 10.1016/j.comcom.2005.02.016
   Yu HF, 2004, LECT NOTES COMPUT SC, V2957, P272
   Yu HF, 2007, IEEE T BROADCAST, V53, P103, DOI 10.1109/TBC.2006.888917
   Yu HF, 2006, COMPUT COMMUN, V29, P2904, DOI 10.1016/j.comcom.2006.04.003
NR 30
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2009
VL 42
IS 3
BP 295
EP 316
DI 10.1007/s11042-008-0245-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 423HN
UT WOS:000264487500002
DA 2024-07-18
ER

PT J
AU Zhu, SH
   Liu, YC
AF Zhu, Songhao
   Liu, Yuncai
TI Video scene segmentation and semantic representation using a novel
   scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video content analysis; Shot segmentation; Scene clustering; Semantic
   representation
ID EXTRACTION
AB Grouping video content into semantic segments and classifying semantic scenes into different types are the crucial processes to content-based video organization, management and retrieval. In this paper, a novel approach to automatically segment scenes and semantically represent scenes is proposed. Firstly, video shots are detected using a rough-to-fine algorithm. Secondly, key-frames within each shot are selected adaptively with hybrid features, and redundant key-frames are removed by template matching. Thirdly, spatio-temporal coherent shots are clustered into the same scene based on the temporal constraint of video content and visual similarity between shot activities. Finally, under the full analysis of typical characters on continuously recorded videos, scene content is semantically represented to satisfy human demand on video retrieval. The proposed algorithm has been performed on various genres of films and TV program. Promising experimental results show that the proposed method makes sense to efficient retrieval of interesting video content.
C1 [Zhu, Songhao; Liu, Yuncai] Shanghai Jiao Tong Univ, Sch Elect & Elect Engn, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Zhu, SH (corresponding author), Shanghai Jiao Tong Univ, Sch Elect & Elect Engn, Inst Image Proc & Pattern Recognit, 800 Don Chuan Rd, Shanghai 200240, Peoples R China.
EM playtree@sjtu.edu.cn; whomliu@sjtu.edu.cn
FU National High-Tech Research and development Plan of China
   [2006CB303103]; National Natural Science Foundation of China [60833009]
FX This work is supported by the National High-Tech Research and
   development Plan of China ( 973) under Grant No. 2006CB303103, and also
   supported by the National Natural Science Foundation of China under
   Grant No. 60833009.
CR Adams B, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P641, DOI 10.1109/ICME.2000.871444
   Aner A, 2002, LECT NOTES COMPUT SC, V2353, P388
   [Anonymous], 1995, PROC ICJAI, DOI DOI 10.1145/217279.215068
   [Anonymous], 2000, P 2000 ACM WORKSH MU, DOI DOI 10.1145/357744.357942
   ARIKI Y, 2003, P ACM INT WORKSH MUL, P209
   Avrithis YS, 1999, COMPUT VIS IMAGE UND, V75, P3, DOI 10.1006/cviu.1999.0761
   Bordwell D., 1997, FILM ART INTRO
   Bouthemy P., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P245
   Cerneková Z, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P301
   Chaisorn L, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P73, DOI 10.1109/ICME.2002.1035721
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   HOASHI K, 2004, SHOT BOUNDARY DETERM
   HSU W, 2004, IEEE P INT C MULT EX, P656
   Huang JC, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P526, DOI 10.1109/ICIP.1998.727252
   Kender JR, 1998, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.1998.698632
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   LI Y, 2003, MOVIE CONTENT ANAL I, pCH5
   Lienhart R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P685, DOI 10.1109/MMCS.1999.779282
   LIN T, 2001, INT J IMAGE GRAPH, V1, P507, DOI DOI 10.1142/S0219467801000293
   Ngo CW, 2002, INT J COMPUT VISION, V50, P127, DOI 10.1023/A:1020341931699
   Qi Y, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P689
   Rasheed Z, 2005, IEEE T MULTIMEDIA, V7, P1097, DOI 10.1109/TMM.2005.858392
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Rui Y, 1999, MULTIMEDIA SYST, V7, P359, DOI 10.1007/s005300050138
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Sundaram H, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1145, DOI 10.1109/ICME.2000.871563
   Tavanapong W, 2004, IEEE T MULTIMEDIA, V6, P517, DOI 10.1109/tmm.2004.830810
   Truong BT, 2003, IEEE T CIRC SYST VID, V13, P5, DOI 10.1109/TCSVT.2002.808084
   Wolf W, 1996, INT CONF ACOUST SPEE, P1228, DOI 10.1109/ICASSP.1996.543588
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Yoshitaka A, 1997, IEEE VISLANG, P310, DOI 10.1109/VL.1997.626599
   Yuan JH, 2005, LECT NOTES ARTIF INT, V3518, P758
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zhai Y, 2006, IEEE T MULTIMEDIA, V8, P686, DOI 10.1109/TMM.2006.876299
   ZHAO YJ, 2007, IEEE P COMP VIS PATT, P343
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 37
TC 17
Z9 18
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2009
VL 42
IS 2
BP 183
EP 205
DI 10.1007/s11042-008-0233-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 415EY
UT WOS:000263918300003
DA 2024-07-18
ER

PT J
AU Spyrou, E
   Tolias, G
   Mylonas, P
   Avrithis, Y
AF Spyrou, Evaggelos
   Tolias, Giorgos
   Mylonas, Phivos
   Avrithis, Yannis
TI Concept detection and keyframe extraction using a visual thesaurus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Concept detection; Keyframe extraction; Visual thesaurus; Region types
ID IMAGE RETRIEVAL
AB This paper presents a video analysis approach based on concept detection and keyframe extraction employing a visual thesaurus representation. Color and texture descriptors are extracted from coarse regions of each frame and a visual thesaurus is constructed after clustering regions. The clusters, called region types, are used as basis for representing local material information through the construction of a model vector for each frame, which reflects the composition of the image in terms of region types. Model vector representation is used for keyframe selection either in each video shot or across an entire sequence. The selection process ensures that all region types are represented. A number of high-level concept detectors is then trained using global annotation and Latent Semantic Analysis is applied. To enhance detection performance per shot, detection is employed on the selected keyframes of each shot, and a framework is proposed for working on very large data sets.
C1 [Spyrou, Evaggelos; Tolias, Giorgos; Mylonas, Phivos; Avrithis, Yannis] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece.
C3 National Technical University of Athens
RP Spyrou, E (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Iroon Politech 9 Str,Zographou Campus, GR-15773 Athens, Greece.
EM espyrou@image.ntua.gr; gtolias@image.ntua.gr; fmylonas@image.ntua.gr;
   iavr@image.ntua.gr
RI Mylonas, Phivos/AAF-2497-2019; Tolias, Giorgos/O-9939-2017
OI Mylonas, Phivos/0000-0002-6916-3129; Tolias, Giorgos/0000-0002-9570-3870
FU European Commission [FP7-215453];  [FP6-027026 K-Space];  [FP6-027685
   MESH]
FX This work was partially supported by the European Commission under
   contracts FP7-215453 We Know It, FP6-027026 K-Space and FP6-027685 MESH.
CR [Anonymous], FUZZY INFORM ENG GUI
   [Anonymous], 2004, ECCV INT WORKSH STAT
   [Anonymous], 2002, P 10 ACM INT C MULT
   [Anonymous], 2005, NII2005014E
   [Anonymous], CBMI 2005
   [Anonymous], 2007, COLUMBIA U BASELINE
   Avrithis YS, 1999, COMPUT VIS IMAGE UND, V75, P3, DOI 10.1006/cviu.1999.0761
   AYACHE S, 2007, TRECVID 2007 WORKSH
   BOUJEMAA N, 2004, IS T SPIE C STOR RET
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   COOPER M, 2005, P IEEE INT C MULT EX
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Everingham M., 2007, The PASCAL Visual Object Classes Chal- lenge (VOC) Results, DOI 10.1007/s11263-009-0275-4
   GOKALP D, 2007, IEEE C COMP VIS PATT
   Haykin S, 1998, Neural Networks: A Comprehensive Foundation
   *IBM, 2005, MARVEL MULT AN RETR
   Klir G. J., 1995, Fuzzy Sets and Fuzzy Logic: Theory and Applications
   Laaksonen J, 2002, IEEE T NEURAL NETWOR, V13, P841, DOI 10.1109/TNN.2002.1021885
   Lazebnik S, 2006, LECT NOTES COMPUT SC, V4170, P423
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MERIALDO B, 2002, INT THYRR WORKSH DIG
   Mitchell M., 1999, INTRO GENETIC ALGORI, DOI DOI 10.1016/S0898-1221(96)90227-8
   MOLINA J, 2007, 2 INT C SEM DIG MED
   MORRIS OJ, 1986, IEE PROC-F, V133, P146, DOI 10.1049/ip-f-1.1986.0025
   Naphade M.R., 2005, A light scale concept ontology for multimedia understanding for trecvid 2005
   NATSEV A, 2003, INT C COMM TECHN PRO
   OPELT A, 2006, IEEE COMP SOC C COMP
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   SAUX BL, 2004, INT C COMP VIS GRAPH
   SMEATON AF, 2006, MIR 06
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SNOEK CGM, 2003, P 9 ANN C ADV SCH CO
   SPYROU E, 2005, INT C ART NEUR NETW
   SPYROU E, 2007, 2 INT C SEM DIG MED
   SPYROU E, 2007, 2 INT WORKSH SEM MED
   SPYROU E, 2008, INT WORKSH IM AN MUL
   VOISINE N, 2005, 6 INT WORKSH IM AN M
   YAMADA A, 2001, MPEG 7 VISUAL PART E
   YUAN J, 2007, 5 TRECVID WORKSH GAI
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
   ZHUANG Y, 1998, P INT C OH IM PROC I
NR 45
TC 21
Z9 24
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2009
VL 41
IS 3
SI SI
BP 337
EP 373
DI 10.1007/s11042-008-0237-9
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 395EL
UT WOS:000262506300002
DA 2024-07-18
ER

PT J
AU Thomasian, A
   Li, Y
   Zhang, LJ
AF Thomasian, Alexander
   Li, Yue
   Zhang, Lijuan
TI Optimal subspace dimensionality for k-nearest-neighbor queries on
   clustered and dimensionality reduced datasets with SVD
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia databases; content-based retrieval; dimensionality reduction;
   singular value decomposition; clustering; high dimensional data; nearest
   neighbor search
ID ALGORITHM
AB Content based image retrieval represents images as N- dimensional feature vectors. The k images most similar to a target image, i.e., those closest to its feature vector, are determined by applying a k-nearest-neighbor (k-NN) query. A sequential scan of the feature vectors for k-NN queries is costly for a large number of images when N is high. The search space can be reduced by indexing the data, but the effectiveness of multidimensional indices is poor for high dimensional data. Building indices on dimensionality reduced data is one method to improve indexing efficiency. We utilize the Singular Value Decomposition (SVD) method to attain dimensionality reduction (DR) with minimum information loss for static data. Clustered SVD (CSVD) combines clustering with SVD to attain a lower normalized mean square error (NMSE) by taking advantage of the fact that most real-world datasets exhibit local rather than global correlations. The Local Dimensionality Reduction (LDR) method differs from CSVD in that it uses an SVD-friendly clustering method, rather than the k-means clustering method. We propose a hybrid method which combines the clustering method of LDR with the DR method of CSVD, so that the vector of the number of retained dimensions of the clusters is determined by varying the NMSE. We build SR-tree indices based on the vectors in the clusters to determine the number of accessed pages for exact k-NN queries (Thomasian et al., Inf Process Lett - IPL 94(6):247-252, 2005) (see Section A.3 versus the NMSE. Varying the NMSE a minimum cost can be found, because the lower cost of accessing a smaller index is offset with the higher postprocessing cost resulting from lower retrieval accuracy. Experimenting with one synthetic and three real-world datasets leads to the conclusion that the lowest cost is attained at NMSE approximate to 0.03 and between 1/3 and 1/2 of the number of dimensions are retained. In one case doubling the number of dimensions cuts the number of accessed pages by one half. The Appendix provides the requisite background information for reading this paper.
C1 [Thomasian, Alexander] Thomasian & Associates, Pleasantville, NY 10570 USA.
   [Li, Yue] AIG Software, Jersey City, NJ USA.
   [Zhang, Lijuan] Amicas Inc, Boston, MA 02135 USA.
RP Thomasian, A (corresponding author), Thomasian & Associates, 17 Meadowbrook Rd, Pleasantville, NY 10570 USA.
EM alexthomasian@gmail.com; yue@cs.njit.edu; catherine_zh@hotmail.com
RI Zhang, Lijuan/L-9988-2014
CR [Anonymous], 1995, P 1995 ACM SIGMOD IN, DOI DOI 10.1145/223784.223794
   BARBARA W, 1997, DATA ENG B, V20, P3
   BECKMANN N, 1990, SIGMOD REC, V19, P322, DOI 10.1145/93605.98741
   BERGER MM, 2000, WASH U J L POLY, V3, P99
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Böhm C, 2000, ACM T DATABASE SYST, V25, P129, DOI 10.1145/357775.357776
   Castelli V, 2003, IEEE T KNOWL DATA EN, V15, P671, DOI 10.1109/TKDE.2003.1198398
   Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Castelli Vittorio., 2002, Image Databases: Search and Retrieval of Digital Imagery, P373
   Chakrabarti K, 1999, PROC INT CONF DATA, P440, DOI 10.1109/ICDE.1999.754960
   Chakrabarti K., 2000, Proceedings of the 6th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P89
   Faloutsos C., 1994, Proceedings of the Thirteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1994, P4, DOI 10.1145/182591.182593
   Faloutsos C., 1996, SEARCHING MULTIMEDIA
   Farnstrom F., 2000, ACM SIGKDD Explorations Newsletter, V2, P51, DOI DOI 10.1145/360402.360419
   Gaede V, 1998, ACM COMPUT SURV, V30, P170, DOI 10.1145/280277.280279
   GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5
   Han J., 2006, DATA MINING CONCEPTS, DOI 10.1016/C2009-0-61819-5
   Hjaltason GR, 1995, LECT NOTES COMPUT SC, V951, P83
   Jin H, 2003, PROC INT CONF DATA, P87, DOI 10.1109/ICDE.2003.1260784
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Katayama N., 1997, P ACM SIGMOD, P369
   KIM BS, 1986, IEEE T PATTERN ANAL, V8, P761, DOI 10.1109/TPAMI.1986.4767859
   Korn F, 1996, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P215
   Korn F, 2001, IEEE T KNOWL DATA EN, V13, P96, DOI 10.1109/69.908983
   KORN F, 1997, P ACM SIGMOD INT C M, P289, DOI DOI 10.1145/253260.253332
   Korn PF, 1998, IEEE T KNOWL DATA EN, V10, P889, DOI 10.1109/69.738356
   LI Y, 2004, THESIS NEW JERSEY I
   McCallum A., 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P169, DOI 10.1145/347090.347123
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Parsons L., 2004, ACM SIGKDD EXPLOR NE, V6, P90, DOI DOI 10.1145/1007730.1007731
   Prabhakar S, 1998, PROC INT CONF DATA, P94, DOI 10.1109/ICDE.1998.655763
   SAMET H, 2007, FUNDAMENTALS MULTIDI
   SINGH AK, 2001, P ACM SIGMOD INT C M, P389
   Theodoridis Y., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, P161, DOI 10.1145/237661.237705
   Thomasian A, 2005, INFORM PROCESS LETT, V94, P247, DOI 10.1016/j.ipl.2005.03.003
   Thomasian A., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P201, DOI 10.1145/288627.288658
   THOMASIAN A, 2003, ISL200301 NEW JERS I
   Thomasian A, 2006, COMPUT J, V49, P670, DOI 10.1093/comjnl/bx1035
   White DA, 1996, P SOC PHOTO-OPT INS, V2670, P62, DOI 10.1117/12.234810
   Yi B K., 2000, Proceedings of the 26st International Conference on Very Large Databases, P385
   ZHANG L, 2005, THESIS NEW JERSEY I
NR 41
TC 3
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2008
VL 40
IS 2
BP 241
EP 259
DI 10.1007/s11042-008-0206-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 349CU
UT WOS:000259257200004
DA 2024-07-18
ER

PT J
AU Leng, B
   Qin, Z
AF Leng, Biao
   Qin, Zheng
TI A powerful relevance feedback mechanism for content-based 3D model
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based 3D model retrieval; relevance feedback; feature vector
ID SEARCH
AB The technique of relevance feedback has been introduced to content-based 3D model retrieval, however, two essential issues which affect the retrieval performance have not been addressed. In this paper, a novel relevance feedback mechanism is presented, which effectively makes use of strengths of different feature vectors and perfectly solves the problem of small sample and asymmetry. During the retrieval process, the proposed method takes the user's feedback details as the relevant information of query model, and then dynamically updates two important parameters of each feature vector, narrowing the gap between high-level semantic knowledge and low-level object representation. The experiments, based on the publicly available 3D model database Princeton Shape Benchmark (PSB), show that the proposed approach not only precisely captures the user's semantic knowledge, but also significantly improves the retrieval performance of 3D model retrieval. Compared with three state-of-the-art query refinement schemes for 3D model retrieval, it provides superior retrieval effectiveness only with a few rounds of relevance feedback based on several standard measures.
C1 [Leng, Biao] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   [Qin, Zheng] Tsinghua Univ, Sch Software, Beijing 100084, Peoples R China.
C3 Tsinghua University; Tsinghua University
RP Leng, B (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM lengb04@mails.tsinghua.edu.cn
CR [Anonymous], THESIS U LEIPZIG LEI
   Atmosukarto I, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P334, DOI 10.1109/MMMC.2005.39
   Bang HY, 2002, IEEE IMAGE PROC, P968
   Bustos B., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P514
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Elad M., 2001, PROC EG MULTIMEDIA, P97, DOI DOI 10.2312/EGMM/EGMM01/107-118
   Funkhouser T, 2005, COMMUN ACM, V48, P58, DOI 10.1145/1064830.1064859
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Kazhdan M, 2004, ACM T GRAPHIC, V23, P623, DOI 10.1145/1015706.1015770
   Kazhdan M, 2004, ALGORITHMICA, V38, P201, DOI 10.1007/s00453-003-1050-5
   Leifman G, 2005, VISUAL COMPUT, V21, P865, DOI 10.1007/s00371-005-0341-z
   NOVOTNI M, 2005, P 4 INT WORKSH CONT
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Pu JT, 2006, COMPUT AIDED DESIGN, V38, P249, DOI 10.1016/j.cad.2005.10.009
   Regli WC, 2000, COMPUT AIDED DESIGN, V32, P119, DOI 10.1016/S0010-4485(99)00095-0
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Vranic DV, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P963
   Vranic DV, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P757
   Yeh JS, 2005, BIOINFORMATICS, V21, P3056, DOI 10.1093/bioinformatics/bti458
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 24
TC 24
Z9 24
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2008
VL 40
IS 1
BP 135
EP 150
DI 10.1007/s11042-007-0188-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 339KO
UT WOS:000258576700007
DA 2024-07-18
ER

PT J
AU Martinet, J
   Satoh, S
   Chiaramella, Y
   Mulhem, P
AF Martinet, Jean
   Satoh, Shin'ichi
   Chiaramella, Yves
   Mulhem, Philippe
TI Media objects for user-centered similarity matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE image and video indexing; similarity matching; human perception;
   weighting scheme; evaluation
ID IMAGE; CLASSIFICATION; RETRIEVAL; MODEL
AB The increase of digital image and video acquisition devices, combined with the growth of the World Wide Web, requires the definition of user-relevant similarity matching methods providing meaningful access to documents searched by users among large amounts of data. The aim of our work is to define media objects for document description suited to images and videos, integrating a user-centered definition of importance for similarity matching. The importance is defined according to criteria and hypotheses, which have been experimentally validated. This leads to a definition of a weighting scheme for media objects (based on objects size, position, and scene homogeneity), which has also been validated with users in a second experiment. This model allows for meaningful similarity matching between document pairs and between users' queries and documents.
C1 [Martinet, Jean; Satoh, Shin'ichi] Natl Inst Informat, Tokyo, Japan.
   [Chiaramella, Yves; Mulhem, Philippe] MRIM CLIPS IMAG, Grenoble, France.
C3 Research Organization of Information & Systems (ROIS); National
   Institute of Informatics (NII) - Japan
RP Martinet, J (corresponding author), Natl Inst Informat, Tokyo, Japan.
EM jean@nii.ac.jp; satoh@nii.ac.jp; Yves.Chiaramella@imag.fr;
   Philippe.Mulhem@imag.fr
CR [Anonymous], 1994, Human-Computer Interaction
   [Anonymous], 1983, INTRO MODERN INFORM
   [Anonymous], 10TH INT C PATT REC
   [Anonymous], 2003, Front-End Vision and Multi-Scale Image Analysis
   Ayache S, 2007, LECT NOTES COMPUT SC, V4425, P494
   Baeza-Yates Ricardo, 1999, MODERN INFORM RETRIE, V463
   BAILLARGEON G, 1998, PROBABILITIES STAT T
   Bastan M., 2006, P CIVR 2006 PHOEN AZ
   CARSON C, 1999, INT C VIS INF INF SY
   Hollink L, 2004, INT J HUM-COMPUT ST, V61, P601, DOI 10.1016/j.ijhcs.2004.03.002
   Horster E., 2007, CIVR 07 P 2007 ACM I, P17, DOI DOI 10.1145/1282280.1282283
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Lee JH, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P267, DOI 10.1145/258525.258587
   Lim JH, 2003, IEEE MULTIMEDIA, V10, P28, DOI 10.1109/MMUL.2003.1237548
   Lim JH, 2001, PATTERN ANAL APPL, V4, P125, DOI 10.1007/PL00014574
   Lim JH, 2000, NEW GENERAT COMPUT, V18, P147, DOI 10.1007/BF03037593
   LOTHAR KH, 2001, HIERARCHY INTERACTIO
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LU Y, 1999, INT C IM AN PROC, P933
   Martin P., 1986, MEASURING BEHAV
   Martinet J., 2003, P CBMI 03, P335
   Martinet J., 2005, ACM CIKM, P760
   MARTINET J, 2007, ECIR 07
   MITRA M, 1998, RES DEV INFROM RETRI, P206
   Mulhem P., 2003, MULTIMEDIA SYSTEMS C
   Osberger W., 1998, ICPR
   OUNIS I, 1998, P IEEE KNOWL DAT ENG, P50
   QIU Y, 1993, SIGIR 1993, P160
   QUELHAS P, 2006, CIVR 2006
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Rodden K., 1999, P 25 BCS IRSG C IR
   RODDEN K, 2003, ACM C HUM FACT COMP, P409
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Salton G., 1971, SMART RETRIEVAL SYST
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   STENTIFORD FWM, 2003, P SPIE STOR RETR MED, V5021
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Vapnik V., 1999, NATURE STAT LEARNING
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Wang J. Z., 2001, ICIAP, P380
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Yahiaoui I, 2003, EURASIP J APPL SIG P, V2003, P48, DOI 10.1155/S1110865703210052
   ZHENG QF, 2006, ACM MULTIMEDIA 2006
NR 49
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 2
BP 263
EP 291
DI 10.1007/s11042-008-0200-9
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 322NA
UT WOS:000257381400007
DA 2024-07-18
ER

PT J
AU Wang, JS
   Patel, N
   Grosky, W
   Fotouhi, F
AF Wang, Jinsong
   Patel, Nilesh
   Grosky, William
   Fotouhi, Farshad
TI Video frame rate up conversion under inconsistent camera motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE frame rate conversion; compressed domain; generalized affine motion
   model; temporal tracking; bilinear interpolation
ID COMPRESSED VIDEO; INTERPOLATION
AB In this paper, we address the problem of video frame rate up-conversion (FRC) in the compressed domain. FRC is often recognized as video temporal interpolation. This problem is very challenging when targeted for video sequences with inconsistent camera and object motion, such as sports videos. A novel compressed domain motion compensation scheme is presented and applied in this paper, aiming at up-sampling frame rates in sports videos. MPEG-2 encoded motion vectors (MVs) are utilized as inputs in the proposed algorithm. The decoded MVs undergo a cumulative spatiotemporal interpolation. An iterative rejection scheme based on the dense motion vector field (MVF) and the generalized affine motion model is exploited to detect global camera motion. Subsequently, the foreground object separation is performed by additionally examining the temporal consistency of the output of iterative rejections. This consistency check process helps coalesce the resulting foreground blocks and weed out the unqualified blocks. Finally, different compensation strategies for the camera and object motions are applied to interpolate the new frames. Illustrative examples are provided to demonstrate the efficacy of the proposed approach. Experimental results are compared with the popular block and non-block based frame interpolation approaches.
C1 [Wang, Jinsong; Fotouhi, Farshad] Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA.
   [Patel, Nilesh; Grosky, William] Univ Michigan, Dept Comp & Informat Syst, Dearborn, MI 48128 USA.
C3 Wayne State University; University of Michigan System; University of
   Michigan
RP Wang, JS (corresponding author), Wayne State Univ, Dept Comp Sci, Detroit, MI 48202 USA.
EM kennyw@wayne.edu
RI Wang, Jiaqiang/HHN-9059-2022
OI Wang, Jiaqiang/0000-0003-0202-2046
CR [Anonymous], 2001, MPEG 4 VID VER MOD V
   [Anonymous], 1992, NUMERICAL RECIPES C
   ASCENSO J, 2005, P 2005 EUR ASS SIGN
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Favalli L, 2000, IEEE T CIRC SYST VID, V10, P427, DOI 10.1109/76.836288
   Ishwar P, 2000, IEEE T CIRC SYST VID, V10, P980, DOI 10.1109/76.867937
   *ISO IEC, 1996, 13 818 ISOIEC
   Jeon BW, 2003, IEEE T CONSUM ELECTR, V49, P499, DOI 10.1109/TCE.2003.1233761
   Lee SH, 2002, IEEE T CONSUM ELECTR, V48, P444, DOI 10.1109/TCE.2002.1037026
   Li DG, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P445, DOI 10.1109/MMCS.1999.779243
   Liu S, 2001, PROC SPIE, V4209, P251, DOI 10.1117/12.420826
   MUSMANN HG, 1985, P IEEE, V73, P523, DOI 10.1109/PROC.1985.13183
   Pelagotti A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P375, DOI 10.1109/ICIP.2001.958506
   SCHUTTEN RJ, 1994, IEEE T CONSUM ELECTR, V4, P930
   SEKIGUCHI S, 2005, P 2005 IEEE INT C IM, P974
   Shen B, 2005, IEEE T CIRC SYST VID, V15, P1291, DOI 10.1109/TCSVT.2005.854216
   Shen B, 1999, IEEE T CIRC SYST VID, V9, P929, DOI 10.1109/76.785730
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   TAN YP, 1995, P IEEE INT C IM PROC, V1, P406
   Tekalp A.M., 1995, DIGITAL VIDEO PROCES
   WANG J, 2004, P 2004 IEEE REG 4 EL
   WANG J, 2004, 38 AS C SIGN COMP, P1740
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 23
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 3
BP 329
EP 351
DI 10.1007/s11042-007-0162-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 328BF
UT WOS:000257771600002
DA 2024-07-18
ER

PT J
AU Ryu, ES
   Yoo, C
AF Ryu, Eun-Seok
   Yoo, Chuck
TI Towards building large scale live media streaming framework for a U-city
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE U-City; multimedia streaming; SLiM; media framework
AB This paper proposes camera and media stream management techniques at the middleware level for implementing a U-City (ubiquitous city). The study focuses on overcoming the difficulties associated with developing middleware capable of processing and streaming multimedia data from a large number of cameras by expanding the traditional media processing technology. The content of the study can be classified into two main categories: One is a camera array management technique that involves the middleware-level framework and protocol for managing the camera array. The other is the media stream management technique for effective delivery management and processing of the multimedia streams from the camera array.
C1 [Ryu, Eun-Seok; Yoo, Chuck] Korea Univ, Dept Comp Sci & Engn, Seoul 136701, South Korea.
C3 Korea University
RP Ryu, ES (corresponding author), Korea Univ, Dept Comp Sci & Engn, Seoul 136701, South Korea.
EM esryu@os.korea.ac.kr; hxy@os.korea.ac.kr
RI Ryu, Eun-Seok/AAA-3536-2021
CR BERKVENS W, 2005, IEEE P C PERV COMP C
   DESUMONT S, 2004, P SPIE REAL TIME IMA, V5297
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Esteve M, 2006, IEEE MULTIMEDIA, V13, P78, DOI 10.1109/MMUL.2006.1
   Garlan D., 2002, IEEE Pervasive Computing, V1, P22, DOI 10.1109/MPRV.2002.1012334
   HESS CK, 2002, INT C PERV COMP PERV, P16
   MARTI S, 2002, CARMEN DYNAMIC SERVI
   Roman M., 2002, IEEE Pervasive Computing, V1, P74, DOI 10.1109/MPRV.2002.1158281
   Ryu ES, 2005, LECT NOTES COMPUT SC, V3744, P161
   RYU ES, 2004, P 12 ACM INT C MULT
   Trivedi MM, 2000, 2000 IEEE INTELLIGENT TRANSPORTATION SYSTEMS PROCEEDINGS, P155, DOI 10.1109/ITSC.2000.881042
   YANG Z, 2005, P 15 INT WORKSH NETW
   ZHAO W, 2002, 3421 IETF RFC
NR 13
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 37
IS 3
BP 319
EP 338
DI 10.1007/s11042-007-0166-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 274BI
UT WOS:000253976400004
DA 2024-07-18
ER

PT J
AU Jin, SH
   Cho, JH
   Ro, YM
AF Jin, Sung Ho
   Cho, Jun Ho
   Ro, Yong Man
TI Real-time content filtering for live broadcasts in TV terminals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content filtering; real-Time processing; filtering requirements; queue
   model
ID SCENE CHANGE DETECTION; VIDEO; SYSTEM
AB In this paper, we propose a new real-time content filtering framework for live broadcasts in TV terminals. Content filtering in TV terminals is a necessary provision of personalized broadcasting services in that it enables a TV viewer to obtain desired scenes from multiple channel broadcasts. In this paper, a stable and reliable filtering structure and an algorithm for multiple inputs are proposed. Moreover, real-time filtering requirements such as frame sampling rate per channel, number of input channels, and buffer condition are analyzed to achieve real-time processing in terminals with limited computing power. Based on queueing theory, we model the system and resolve the filtering requirements. To verify the proposed system and analysis, a filtering algorithm for soccer videos is applied which is modified for real-time processing. Through analysis of visual features (e.g., dominant color and edge components) and detection of spatial objects (e.g., a score board), it recognizes a temporal pattern between successive video frames and filters desired scenes. Experiments on soccer videos have been performed and the results validate the effectiveness of the proposed approach and system.
C1 [Jin, Sung Ho; Cho, Jun Ho; Ro, Yong Man] Informat & Commun Univ, Dept Engn, Taejon 305732, South Korea.
RP Ro, YM (corresponding author), Informat & Commun Univ, Dept Engn, 119 Munjiro, Taejon 305732, South Korea.
EM wh966@icu.ac.kr; chojunho@icu.ac.kr; yro@icu.ac.kr
RI Ro, Yong Man/ABF-6817-2020; Ro, Yong Man/C-1731-2011
OI Ro, Yong Man/0000-0001-5306-6853; 
CR Bais M, 2002, IEEE T BROADCAST, V48, P151, DOI 10.1109/TBC.2002.1021281
   Choi JS, 2004, IEEE T CONSUM ELECTR, V50, P991, DOI 10.1109/TCE.2004.1362489
   Dimitrova N., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P214, DOI 10.1109/ITCC.2000.844213
   Dimitrova N, 1999, IEEE MULTIMEDIA, V6, P14, DOI 10.1109/93.771369
   Dimitrova N, 1998, IEEE T KNOWL DATA EN, V10, P988, DOI 10.1109/69.738361
   Dimitrova N, 2002, IEEE MULTIMEDIA, V9, P42, DOI 10.1109/MMUL.2002.1022858
   ECKBERG AE, 1979, IEEE T COMMUN, V27, P556, DOI 10.1109/TCOM.1979.1094425
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   EKIN A, 2003, P IEEE INT C MULT EX, P27
   Fu Y, 2002, IEEE T IMAGE PROCESS, V11, P135, DOI 10.1109/83.982821
   Gauch JM, 1999, INFORM PROCESS MANAG, V35, P381, DOI 10.1016/S0306-4573(98)00067-3
   Gross D., 1998, FUNDAMENTALS QUEUEIN
   Jin SH, 2004, CISST '04: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, P613
   Kim JR, 2003, IEEE T CONSUM ELECTR, V49, P683, DOI 10.1109/TCE.2003.1233802
   Kleinrock L., 1975, Queueing System
   Kumano M, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P277, DOI 10.1109/ICME.2004.1394179
   Lee JH, 2003, IEEE T CONSUM ELECTR, V49, P742, DOI 10.1109/TCE.2003.1233813
   LEE KS, 1994, ETRI J, V15, P35
   Leonardi R, 2004, IEEE T CIRC SYST VID, V14, P634, DOI 10.1109/TCSVT.2004.826751
   Li HL, 2004, IEEE T MULTIMEDIA, V6, P624, DOI [10.1109/TMM.2004.830812, 10.1109/tmm.2004.830812]
   Li Y, 2004, IEEE T CIRC SYST VID, V14, P1073, DOI 10.1109/TCSVT.2004.831968
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Moon JC, 1999, IEEE T CONSUM ELECTR, V45, P488, DOI 10.1109/30.793531
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Otsuka I, 2005, IEEE T CONSUM ELECTR, V51, P112, DOI 10.1109/TCE.2005.1405707
   Pekowsky S, 1998, IEEE T CONSUM ELECTR, V44, P833, DOI 10.1109/30.713202
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   *TVAF, 2005, SP001V20, P9
   Wolf C, 2002, INT C PATT RECOG, P1037, DOI 10.1109/ICPR.2002.1048482
   Zhong D, 2004, J VIS COMMUN IMAGE R, V15, P330, DOI 10.1016/j.jvcir.2004.04.009
   Zhu XQ, 2003, MULTIMEDIA SYST, V9, P31, DOI 10.1007/s00530-003-0076-5
NR 31
TC 1
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2008
VL 36
IS 3
BP 285
EP 301
DI 10.1007/s11042-007-0148-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 249TV
UT WOS:000252253600006
DA 2024-07-18
ER

PT J
AU Delest, M
   Don, A
   Benois-Pineau, J
AF Delest, Maylis
   Don, Anthony
   Benois-Pineau, Jenny
TI DAG-based visual interfaces for navigation in indexed video content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video indexing; color descriptors; graph clustering; navigation
AB Indexing and segmenting of video content by motion, color and texture has been intensively explored leading to a commonly used representation in a storyboard. In this paper, a novel method of visualization of video content is proposed. First of all, the content is segmented into shots, and then a spatio-temporal color signature of shots, based on color distribution in the frames, is proposed. This spatio-temporal color signature serves as a basis for graph clustering and graph visualization tools. Those, integrated in a platform for visualization of huge graphs, Tulip, supply an exciting graph-based navigation interface for multimedia content. The results obtained on feature documentaries are promising.
C1 Univ Bordeaux 1, LaBRI, CNRS, UMR 5800, Bordeaux, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS)
RP Delest, M (corresponding author), Univ Bordeaux 1, LaBRI, CNRS, UMR 5800, Bordeaux, France.
EM maylis.delest@labri.fr; don@labri.fr; jenny.benois@labri.fr
RI Benois-Pineau, Jenny/ABG-6325-2020
OI Benois-Pineau, Jenny/0000-0003-0659-8894
CR ADAMI N, 2000, P ICCASP 2000 IST TU, V4, P2023
   Auber D, 2004, IEEE INFOR VIS, P44, DOI 10.1109/IV.2004.1320123
   AUBER D, 2002, INT C COMP VIS GRAPH, P56
   AUBER D, SPRINGER MATH VISUAL, P105
   Barbieri M., 2001, IEEE INT C MULT EXP, P627
   BENOISPINEAU J, 2001, EUSFLAT 2001 DAT MIN, P385
   Coudert F, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P679, DOI 10.1109/MMCS.1999.779281
   DELEST M, 2003, P CBMI 03 RENN FRANC, P49
   ERSHOV AP, 1958, COM ACM, V8, P3
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   *ISO IEC, 2000, MPEG 7 MULT DESCR SC
   JOly P, 1996, SIGNAL PROCESS-IMAGE, V8, P295, DOI 10.1016/0923-5965(95)00054-2
   Manerba F, 2004, PROC SPIE, V5307, P50
   Meiers T, 2002, P SOC PHOTO-OPT INS, V4676, P324
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   STRAHLER AN, 1952, GEOL SOC AM BULL, V63, P1117, DOI 10.1130/0016-7606(1952)63[1117:HAAOET]2.0.CO;2
   TONOMURA Y, 1993, P INTERCHI 93, P131
   Yeung M., 1996, P 13 INT C PATT REC, V3, P375
   [No title captured]
NR 19
TC 3
Z9 3
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2006
VL 31
IS 1
BP 51
EP 72
DI 10.1007/s11042-006-0032-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 092QK
UT WOS:000241112200003
DA 2024-07-18
ER

PT J
AU Jiang, J
   Guo, BF
   Ipson, S
AF Jiang, J.
   Guo, B. F.
   Ipson, S.
TI Shape-based image retrieval for JPEG-2000 compressed image databases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE shape-based image retrieval; invariant moment extraction; pattern
   recognition
ID WAVELETS
AB As JPEG-2000 is primarily based on wavelet transforms, we propose a moment-based algorithm to extract shape features out of wavelet coefficients to facilitate image retrieval from compressed image databases. Motivated by the observation that isolated significant points in the wavelet coefficients domain cannot accurately represent the shapes of regions, a range of ideas are investigated in this paper to construct shape descriptors in the wavelet domain using several morphological operators. Based on the fact that certain moments are invariant to rotation, a more compact and effective moment representation method is also proposed to integrate shape information in various directional wavelet sub-bands. Extensive experiments have been carried out using JPEG-2000 compressed image databases, and the results show that the proposed algorithm outperforms a representative existing shape-based image retrieval method in the wavelet domain.
C1 Univ Bradford, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Bradford
RP Jiang, J (corresponding author), Univ Bradford, Bradford BD7 1DP, W Yorkshire, England.
EM j.jiang1@bradford.ac.uk
CR Battista S, 1999, IEEE MULTIMEDIA, V6, P74, DOI 10.1109/93.809236
   CANNY J, 1986, IEEE T PATTERN ANAL, V36, P961
   Courant R., 1989, Methods of Mathematical Physics, VII
   Courant R., 1989, Methods of mathematical physics, V1
   HEARN B, 1997, COMPUTER GRAPHCIS C
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   JACOBS CE, 1995, P SIGGRAPH COMP GRAP, P278
   Liang KC, 1999, IEEE T IMAGE PROCESS, V8, P1619, DOI 10.1109/83.799889
   Mallat S, 1996, P IEEE, V84, P604, DOI 10.1109/5.488702
   Mandal MK, 1996, IEEE T CONSUM ELECTR, V42, P557, DOI 10.1109/30.536156
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Nene S.A., CUCS00696 COL U DEP
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Serra J., 1983, IMAGE ANAL MATH MORP
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Sonka M., 1996, IMAGE PROCESSING ANA
   Usevitch BE, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.952803
   Zhou XS, 2001, PATTERN RECOGN LETT, V22, P457, DOI 10.1016/S0167-8655(00)00124-0
NR 18
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2006
VL 29
IS 2
BP 93
EP 108
DI 10.1007/s11042-006-0001-y
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 071KE
UT WOS:000239600300001
DA 2024-07-18
ER

PT J
AU Asaduzzaman, A
   Mahgoub, I
AF Asaduzzaman, Abu
   Mahgoub, Imad
TI Cache modeling and optimization for portable devices running MPEG-4
   video decoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE cache modeling; cache optimization; portable devices; MPEG-4; video
   decoder
AB There are increasing demands on portable communication devices to run multimedia applications. ISO (an International Organization for Standardization) standard MPEG-4 is an important and demanding multimedia application. To satisfy the growing consumer demands, more functions are added to support MPEG-4 video applications. With improved CPU speed, memory sub-system deficiency is the major barrier to improving the system performance. Studies show that there is Sufficient reuse of values for caching that significantly reduce the memory bandwidth requirement for video data. Software decoding of MPEG-4 video data generates Much more cache-memory traffic than required. Proper understanding of the decoding algorithm and the composition of its data set is obvious to improve the performance of such a system. The focus of this paper is cache modeling and optimization for portable Communication devices running MPEG-4 video decoding algorithm. The architecture we Simulate includes a digital signal processor (DSP) for running the MPEG-4 decoding algorithm and a memory system with two levels of caches. We use VisualSim and Cachegrind Simulation tools to optimize cache sizes, levels of associativity, and cache levels for a portable device decoding MPEG-4 video.
C1 Florida Atlantic Univ, Dept Comp Sci & Engn, Boca Raton, FL 33431 USA.
C3 State University System of Florida; Florida Atlantic University
RP Asaduzzaman, A (corresponding author), Florida Atlantic Univ, Dept Comp Sci & Engn, 777 Glades Rd, Boca Raton, FL 33431 USA.
EM aasaduzz@fau.edu; imad@cse.fau.edu
OI Mahgoub, Imad/0000-0002-4461-7307
CR *ARM LTD, 2003, 0032F ARM LTD DAI
   Asaduzzaman A., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P499
   ASADUZZAMAN A, 2004, P 2004 S PERF EV COM, P751
   AVRITZER A, 2002, WOSP 02 JUL 24 26 20
   CHASE JG, 2002, TECHONLINE PUBLICATI
   ELY SR, 1995, EBU TECHNICAL RE WIN
   Kulkarni C, 1998, LECT NOTES COMPUT SC, V1470, P923, DOI 10.1007/BFb0057949
   MAXIAGUINE A, WORKLOAD CHARACTERIZ
   *MIR DES INC, VISUALSIM SYST LEV S
   Molnos A.M., 2003, Proceedings of the 14th Annual Workshop on Circuits, Systems and Signal Processing (ProRISC'03), P529
   Schaphorst R., 1999, Videoconferencing and Videotelephony, V2nd
   Slingerland NT, 2002, MULTIMEDIA SYST, V8, P315, DOI 10.1007/s005300200052
   SLINGERLAND NT, CACHE PERFORMANCE MU
   SODERQUIST P, 1997, ACM MULT 97 EL P SEA
   Stallings William., 2003, Computer organization and architecture: designing for performance
   FFMPEG VERY FAST VID
   CACHEGRIND CACHE PRO
NR 17
TC 6
Z9 6
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2006
VL 28
IS 2
BP 239
EP 256
DI 10.1007/s11042-006-6145-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 042MH
UT WOS:000237531600009
DA 2024-07-18
ER

PT J
AU Ou, SC
   Chung, HY
   Sung, WT
AF Ou, SC
   Chung, HY
   Sung, WT
TI Improving the compression and encryption of images using FPGA-based
   cryptosystems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE discrete wavelet transform (DWT); significance-linked connected
   component analysis (SLCCA); advance encryption standard (AES); image
   compression encryption scheme (ICES)
AB Compression and encryption technologies are important to the efficient solving of network bandwidth and security issues. A novel scheme, called the Image Compression Encryption Scheme (ICES), is presented. It combines the Haar Discrete Wavelet Transform (DWT), Significance-Linked Connected Component Analysis (SLCCA), and the Advance Encryption Standard (AES). Because of above reason the ICES efficiently reduce the overall processing time. This study develops a novel hardware system to compress and encrypt an image in real-time using an image compression encryption scheme. The proposed system exploits parallel processing to increase the throughout of the cryptosystem for Internet multimedia applications to implement the ICES. Using hardware acceleration for encryption and decryption, the FPGA implementation of DWT, SLCCA and the AES algorithm can be used. Using a pipeline structure, a very high data throughput of 330 Mbit/s at a clock frequency of 40 MHz was obtained. Therefore, the ICES is secure, fast and suited to high speed network protocols such as ATM (Asynchronous Transfer Mode), FDDI (Fiber Distributed Data Interface) or Internet multimedia applications.
C1 Leader Univ, Dept Informat Commun, Tainan, Taiwan.
   Natl Cent Univ, Dept Elect Engn, Chungli 32054, Taiwan.
C3 National Central University
RP 4F,NO 184-1,Kee Kin 1st Rd,An Lo Dist, Chilung 204, Taiwan.
EM songchen@ms10.hinet.net
RI Chung, Hung-Yuan/L-7402-2019; Chung, Hung-Yuan/H-8055-2012
OI Sung, Wen-Tsai/0000-0001-9045-9090
CR Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   CROCKATT C, JAVA SERVLET IMPLEME
   Daemen Joan, 1999, AES Proposal
   Dang PP, 2000, IEEE T CONSUM ELECTR, V46, P395, DOI 10.1109/30.883383
   GAJ K, 2000, IMPLEMENTATIONS AES
   LEPERCHEY B, 2000, FPGA IMPLEMENTATION
   Li XB, 1997, PATTERN RECOGN LETT, V18, P1253, DOI 10.1016/S0167-8655(97)00099-8
   MRCOZKOWSKI P, IMPLEMENTATION BLOCK
   Munteanu A, 1999, IEEE Trans Inf Technol Biomed, V3, P176, DOI 10.1109/4233.788579
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SERVETTO SD, 1995, INT C IM PROC 1995 P, V1, P530
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Zhong JM, 1999, IEE P-VIS IMAGE SIGN, V146, P206, DOI 10.1049/ip-vis:19990556
   [No title captured]
NR 17
TC 16
Z9 19
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2006
VL 28
IS 1
BP 5
EP 22
DI 10.1007/s11042-006-5117-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 011ZR
UT WOS:000235308500001
DA 2024-07-18
ER

PT J
AU Zhou, Q
   Ma, LM
   Celenk, M
   Chelberg, D
AF Zhou, Q
   Ma, LM
   Celenk, M
   Chelberg, D
TI Content-based image retrieval based on ROI detection and relevance
   feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE content-based image retrieval (CBIR); region of interest (ROI);
   relevance feedback; color and wavelet saliencies; normalized
   projections; similarity measure
ID SEGMENTATION; REGIONS
AB Content-based image retrieval is an important research topic in computer vision. We present a new method that combines region of interest (ROI) detection and relevance feedback. The ROI based approach is more accurate in describing the image content than using global features, and the relevance feedback makes the system to be adaptive to subjective human perception. The feedback information is utilized to discover the subjective ROI perception of a particular user, and it is further employed to recompute the features associated with ROIs with the updated personalized ROI preference. A fast computation technique is proposed to avoid repeating the ROI detection for images in the database. It directly estimates the features of the ROIs, which makes the query process fast and efficient. For illustration of the overall approach, we use the color saliency and wavelet feature saliency to determine the ROIs. Normalized projections are selected to represent the shape features associated with the ROIs. Experimental results show that the proposed system has better performance than the global features based approaches and region based techniques without feedback.
C1 Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
C3 University System of Ohio; Ohio University
RP Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
EM celenk@bobcat.ent.ohiou.edu
OI Celenk, Mehmet/0000-0001-7104-5861
CR ARDIZZONI S, 1999, P 1 WORKSH SIM SEARC
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Celenk M, 2003, PROC SPIE, V5014, P86, DOI 10.1117/12.477747
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Furht B., 1995, Video and Image Processing in Multimedia Systems
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GESU VD, 1997, PATTERN RECOGN, V18, P1077, DOI DOI 10.1016/S0167-8655(97)00084-6
   HARALICK HM, 1992, COMPUTER ROBOT VISIO, V1
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   JING F, 2002, P IEEE INT S CIRC SY
   Lau HF, 2002, PATTERN RECOGN, V35, P2323, DOI 10.1016/S0031-3203(01)00230-8
   LEE C, 1998, INFORMATION EMBEDDIN
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Lu Y, 2000, ACM MULTIMEDIA, P31
   Ma WY, 1999, MULTIMEDIA SYST, V7, P184, DOI 10.1007/s005300050121
   Marchette DJ, 1998, PATTERN RECOGN, V31, P2103, DOI 10.1016/S0031-3203(98)00025-9
   Moghaddam B, 2001, MULTIMED TOOLS APPL, V14, P201, DOI 10.1023/A:1011355417880
   Nakazato M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P201, DOI 10.1109/ICME.2002.1035753
   OGLE CCA, 1996, IEEE COMPUTER SOC B, V9, P19
   Pauwels EJ, 1999, COMPUT VIS IMAGE UND, V75, P73, DOI 10.1006/cviu.1999.0763
   PENTLAND A, 1996, BASED MANIPULATION I, P43
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y., 1999, P 7 ACM INT C MULTIM, P67, DOI DOI 10.1145/319878.319896
   Salembier P, 1999, IEEE T CIRC SYST VID, V9, P1147, DOI 10.1109/76.809153
   Shao Y, 2001, PATTERN RECOGN, V34, P2097, DOI 10.1016/S0031-3203(00)00148-5
   SRIDHAR V, 2002, P 2002 VIS INF SYST, P61
   Tian Q, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P746, DOI 10.1109/ICIP.2000.899562
   Veltkamp R., 2002, MU SYS APPL, P47
   VU K, 2003, IEEE T KNOWL DATA EN, P1045
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   ZHOU XS, 2001, ACM MULTIMEDIA, P137
NR 32
TC 21
Z9 26
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2005
VL 27
IS 2
BP 251
EP 281
DI 10.1007/s11042-005-2577-z
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 961OP
UT WOS:000231672000005
DA 2024-07-18
ER

PT J
AU Bilasco, I
   Gensel, J
   Villanova-Oliver, M
AF Bilasco, I
   Gensel, J
   Villanova-Oliver, M
TI STAMP: A model for generating adaptable multimedia presentations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multimedia presentation; adaptation; dynamic generation; variable
   content; compensation techniques
AB The STAMP model addresses the dynamic generation of multimedia presentations in the domain of Multimedia Web-based Information Systems. STAMP allows the presentation of multimedia data obtained from XML compatible data sources by means of query. Assuming that the size and the nature of the elements of information provided by a data source is not known a priori, STAMP proposes templates which describe the spatial, temporal, navigational structuration of multimedia presentations whose content varies. The instantiation of a template is done with respect to the set of spatial and temporal constraints associated with the delivery context. A set of adaptations preserving the initial intention of the presentation is proposed.
C1 IMAG, Lab LSR, F-38402 St Martin Dheres, France.
RP IMAG, Lab LSR, BP 72, F-38402 St Martin Dheres, France.
EM bilasco@imag.fr; gensel@imag.fr; villanova@imag.fr
RI VILLANOVA-OLIVER, Marlène/AAE-9943-2019; Gensel, Jérôme/AAD-8090-2022;
   Gensel, Jérôme/G-1026-2015
OI Gensel, Jérôme/0000-0003-1398-7118; BILASCO, Ioan
   Marius/0000-0001-7254-8727
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Bertino E, 2000, IEEE T KNOWL DATA EN, V12, P1, DOI 10.1109/TKDE.2000.842245
   BILASCO M, 2003, MODELES PRESENTATION
   Bray Tim., 1998, EXTENSIBLE MARKUP LA
   BRUSILOVSKY P, 1997, LECT NOTES COMPUTER, V1326, P12
   Ceri S., 2000, P 9 INT WORLD WID WE
   CLARK J, 1999, XSL TRANSFORMATIO
   HOUBEN GJ, 2000, P 3 INT WORKSH ENG F, P81
   Isakowitz T, 1998, COMMUN ACM, V41, P78, DOI 10.1145/278476.278490
   KLYNE G, 2001, COMPOSITE CAPABILITY
   Layaida N, 1996, P SOC PHOTO-OPT INS, V2667, P124, DOI 10.1117/12.235866
   RUTLEDGE L, 2000, P 11 ACM C HYP HYP, P19
   VAZIRGIANNIS M, 1996, P INT WORKSH MULT SO
   VILLANOVAOLIVER M, 2002, THESIS U J FOURIER G
   *W3C REC, 2000, XML SCHEM XML SCH 1
NR 15
TC 12
Z9 12
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2005
VL 25
IS 3
BP 361
EP 375
DI 10.1007/s11042-005-6540-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 913SM
UT WOS:000228173400004
DA 2024-07-18
ER

PT J
AU Vishwakarma, G
   Nandanwar, AK
   Thakur, GS
AF Vishwakarma, Gagan
   Nandanwar, Amit Kumar
   Thakur, Ghanshyam Singh
TI Optimized vision transformer encoder with cnn for automatic psoriasis
   disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNN; Vision transformer; AROA; Psoriasis
AB Psoriasis is a skin disorder that results in swollen skin cells and red, itchy areas on the skin. 40% of the world's population is currently affected by psoriasis. Nowadays, using skin image analysis technology is the main way for detecting psoriasis. Additionally, a number of academics have identified potential machine learning methods for categorising the psoriasis illness. However, the accuracy and computational efficiency of the model still need to be improved. Thus, in this paper, we present an optimized vision transformer for autonomous psoriasis disease detection. Following pre-processing, feature optimized image is attained using convolutional neural network (CNN) which embeds full image and concatenates to each vision transformer encoder layer. It leads the network to always "retain" the full image at the end of each transformer block output. In parallel, the pre-processed images are cropped into patches and these patches along with its positional encoded information are given as input to the optimized transformer encoder. To enhance the performance of transformer, the hyper-parameters of it are optimized using adaptive rabbit optimization algorithm (AROA). Results of this article confirm that the proposed optimized vision transformer model achieved better classification accuracy of 97.7% and F-Score of 96.5%.
C1 [Vishwakarma, Gagan] Indian Inst Informat Technol, Comp Sci & Engn, Bhopal, Madhya Pradesh, India.
   [Nandanwar, Amit Kumar] Maulana Azad Natl Inst Technol, Comp Sci Engn, Bhopal, MP, India.
   [Thakur, Ghanshyam Singh] Maulana Azad Natl Inst Technol, Dept Comp Applicat, Bhopal, MP, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal; National Institute of Technology (NIT
   System); Maulana Azad National Institute of Technology Bhopal
RP Nandanwar, AK (corresponding author), Maulana Azad Natl Inst Technol, Comp Sci Engn, Bhopal, MP, India.
EM amitdataset@gmail.com
RI Nandanwar, Amit Kumar/HJG-6264-2022; Vishwakarma, Gagan/AAK-9768-2021
OI Nandanwar, Amit Kumar/0000-0003-1168-0032; Vishwakarma,
   Gagan/0000-0002-3308-8438
CR Ahammed M., 2022, Healthc. Anal., V2, DOI [10.1016/j.health.2022.100122, DOI 10.1016/J.HEALTH.2022.100122, 10.1016/J.HEALTH.2022.100122]
   Aijaz SF, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/7541583
   Balaji VR, 2020, MEASUREMENT, V163, DOI 10.1016/j.measurement.2020.107922
   Dash M, 2020, COMPUT BIOL CHEM, V86, DOI 10.1016/j.compbiolchem.2020.107247
   Dash M, 2019, BIOMED SIGNAL PROCES, V52, P226, DOI 10.1016/j.bspc.2019.04.002
   ElMallah R, 2020, EGYPT RHEUMATOL, V42, P319, DOI 10.1016/j.ejr.2020.07.003
   Erfan R, 2023, NON-CODING RNA RES, V8, P340, DOI 10.1016/j.ncrna.2023.04.002
   Geale K, 2017, HEALTH QUAL LIFE OUT, V15, DOI 10.1186/s12955-017-0721-x
   George Y, 2016, IEEE ENG MED BIO, P1352, DOI 10.1109/EMBC.2016.7590958
   Hussein SA, 2021, EGYPT RHEUMATOL, V43, P153, DOI 10.1016/j.ejr.2021.01.004
   Ibrahim R.B, 2020, IAES INT J ARTIF INT, V9, P349, DOI DOI 10.11591/IJAI.V9.I2
   Kumar VB, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Li P, 2021, Digit Chin Med, V4, P92, DOI 10.1016/j.dcmed.2021.06.003
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Monga V, 2021, IEEE SIGNAL PROC MAG, V38, P18, DOI 10.1109/MSP.2020.3016905
   Negrei C, 2017, Psoriasis: An Interdisciplinary Approach, V211
   Pasch MC, 2016, DRUGS, V76, P675, DOI 10.1007/s40265-016-0564-5
   Raina A, 2016, SKIN RES TECHNOL, V22, P375, DOI 10.1111/srt.12276
   Raj R, 2020, IEEE INT C BIOINFORM, P723, DOI 10.1109/BIBM49941.2020.9313356
   Rezaee M, 2018, IEEE J-STARS, V11, P3030, DOI 10.1109/JSTARS.2018.2846178
   Sadik R., 2023, Healthcare Analytics, V3, P100143, DOI [10.1016/j.health.2023.100143, DOI 10.1016/J.HEALTH.2023.100143]
   Shtanko Alexander, 2022, Procedia Computer Science, P250, DOI 10.1016/j.procs.2022.11.063
   Tizhoosh HR, 2006, INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING, CONTROL & AUTOMATION JOINTLY WITH INTERNATIONAL CONFERENCE ON INTELLIGENT AGENTS, WEB TECHNOLOGIES & INTERNET COMMERCE, VOL 1, PROCEEDINGS, P695, DOI 10.1109/cimca.2005.1631345
   Wang LY, 2022, ENG APPL ARTIF INTEL, V114, DOI 10.1016/j.engappai.2022.105082
   Yang C, 2019, IEEE ACCESS, V7, P155304, DOI 10.1109/ACCESS.2019.2949287
NR 25
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-16871-z
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500012
DA 2024-07-18
ER

PT J
AU Theerthagiri, P
   Siddalingaiah, SD
AF Theerthagiri, Prasannavenkatesan
   Siddalingaiah, Sahana Devarayapattana
TI RG-SVM: Recursive gaussian support vector machine based feature
   selection algorithm for liver disease classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Recursive Feature selection; Feature ranking, RG-SVM, decision tree;
   Liver disease Prediction
AB Health is an essential concern for everyone, so it is necessary to facilitate medical services that are easily accessible to everyone. The primary goal of this work is to predict liver diseases using a machine-learning strategy that makes use of feature selection and classification techniques. This work proposes the recursive Gaussian support vector machine-based feature selection (RG-SVM) algorithm. It uses the Gaussian kernel of support vector machine and recursive feature selection algorithm for the prediction of liver disease. The proposed RG-SVM algorithm has been evaluated on the Indian liver patient records dataset. Various classification algorithms such as logistic regression, decision tree, k-nearest neighbour, and Naive Bayes are implemented and compared in order to assess the accuracy, confusion matrix and area under curve. The proposed RG-SVM has been compared with other existing algorithms such as logistic regression (LR), decision tree (DT), k-nearest neighbour (KNN), Naive Bayes (NB), and proposed RG-SVM algorithms. The algorithms LR, DT, KNN, NB, and proposed RG-SVM have accuracy values of 73, 80, 81, 54, and 93%, respectively. It clearly shows that the proposed RG-SVM with the support of a recursive feature selection algorithm, outperformed other existing algorithms with an improved accuracy of 14 - 39% 12- 20% of reduced MSE error over other compared algorithms. Similarly, the sensitivity and specificity of RG-SVM algorithm produced 5-26% and 34-72% improved results over the existing algorithms. The results of the proposed algorithm will be useful for physicians to make better decisions for liver disease patients.
C1 [Theerthagiri, Prasannavenkatesan; Siddalingaiah, Sahana Devarayapattana] GITAM Univ Bengaluru, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, India.
C3 Gandhi Institute of Technology & Management (GITAM)
RP Theerthagiri, P (corresponding author), GITAM Univ Bengaluru, GITAM Sch Technol, Dept Comp Sci & Engn, Bengaluru, India.
EM prasannait91@gmail.com
CR Abdalrada AS, 2019, PERIODICALS ENG NATU, V7, P1255, DOI [10.21533/pen.v7i3.667, DOI 10.21533/PEN.V7I3.667]
   Abdar M, 2017, EXPERT SYST APPL, V67, P239, DOI 10.1016/j.eswa.2016.08.065
   Abdullah D.M., 2021, Qubahan Academic Journal, V1, P81, DOI DOI 10.48161/QAJ.V1N2A50
   Ambesange Sateesh, 2020, 2020 IEEE International Conference on Cloud Computing in Emerging Markets (CCEM), P98, DOI 10.1109/CCEM50674.2020.00030
   Amin Ruhul, 2023, Informatics in Medicine Unlocked, DOI 10.1016/j.imu.2022.101155
   [Anonymous], 2011, AdvApplSci Res
   Assegie T. A., 2022, B ELECT ENG INFORM, V11, P1650, DOI [10.11591/eei.v11i3.3787, DOI 10.11591/EEI.V11I3.3787]
   Assegie T. A., 2023, International Journal of Electrical and Computer Engineering, V13, P3359, DOI [10.11591/ijece.v13i3.pp3359-3366, DOI 10.11591/IJECE.V13I3.PP3359-3366]
   Assegie TA, 2021, Support Vector Machine And K-Nearest Neighbor Based Liver Disease Classification Model, DOI [10.35882/ijeeemi.v3i1.2, DOI 10.35882/IJEEEMI.V3I1.2]
   Botchkarev A, 2018, Arxiv, DOI [arXiv:1809.03006, 10.48550/arXiv.1809.03006, DOI 10.48550/ARXIV.1809.03006]
   Bukhari SNH, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-11731-6
   Butkiewicz M, 2013, MOLECULES, V18, P735, DOI 10.3390/molecules18010735
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chicco D, 2021, BIODATA MIN, V14, DOI 10.1186/s13040-021-00244-z
   Deshmukh S, 2022, International Journal of Scientific Research in Engineering & Management, V06
   Dong RZ, 2019, J CELL MOL MED, V23, P3369, DOI 10.1111/jcmm.14231
   Dritsas E, 2023, COMPUTERS, V12, DOI 10.3390/computers12010019
   Farokhzad M.R., 2016, Int. J. Acad. Res. Comput. Eng, V1, P61
   Ghazal T. M., 2022, P 2022 INT C BUS AN, DOI [10.1109/ICBATS54253.2022.9758929, DOI 10.1109/ICBATS54253.2022.9758929]
   Hassan A., 2013, Int J Comput Sci Inf Technol Secur, V3, P185
   Hayashi Yoichi, 2016, Informatics in Medicine Unlocked, V5, P26, DOI 10.1016/j.imu.2016.10.001
   Ismail WN, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13152501
   Jain S, 2019, COGENT ENG, V6, DOI 10.1080/23311916.2019.1599537
   kaggle, US
   Khan M. A. R., 2023, Iran Journal of Computer Science, V6, P277, DOI [10.1007/S42044-023-00138-9, DOI 10.1007/S42044-023-00138-9]
   Krause J, 2018, OPHTHALMOLOGY, V125, P1264, DOI 10.1016/j.ophtha.2018.01.034
   Krisnabayu RY, 2021, PROCEEDINGS OF 2021 INTERNATIONAL CONFERENCE ON SUSTAINABLE INFORMATION ENGINEERING AND TECHNOLOGY, SIET 2021, P151, DOI 10.1145/3479645.3479668
   Kumar P, 2021, MULTIMED TOOLS APPL, V80, P16515, DOI 10.1007/s11042-019-07978-3
   Lanjewar MG, 2023, CLUSTER COMPUT, V26, P3657, DOI 10.1007/s10586-022-03752-7
   Lazar C, 2012, IEEE ACM T COMPUT BI, V9, P1106, DOI 10.1109/TCBB.2012.33
   Lin XH, 2018, MOLECULES, V23, DOI 10.3390/molecules23010052
   Liu YX, 2021, HEPATOB PANCREAT DIS, V20, P409, DOI 10.1016/j.hbpd.2021.08.004
   Marwa IM., 2016, Int J Comput Appl, V140, P1, DOI [10.5120/ijca2016909402, DOI 10.5120/IJCA2016909402]
   Mehmood M, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/7816200
   Murugesan S, 2021, COMPUT MATH METHOD M, V2021, DOI 10.1155/2021/6662420
   Obayya Marwa I M., 2016, Int J Comput Appl, V140, P1
   Orooji A., 2021, Frontiers in Health Informatics, V10, P57, DOI [10.30699/fhi.v10i1.259, DOI 10.30699/FHI.V10I1.259]
   Padmakala S, 2021, INT J NUMER METH BIO, V37, DOI 10.1002/cnm.3525
   Praveen A. Durga, 2021, Intelligent Computing in Control and Communication. Proceeding of the First International Conference on Intelligent Computing in Control and Communication (ICCC 2020). Lecture Notes in Electrical Engineering (LNEE 702), P609, DOI 10.1007/978-981-15-8439-8_50
   Rubia Y, 2023, Design of Novel Feature Union for Prediction of Liver Disease Patients: A Machine Learning Approach, DOI [10.1007/978-981-19-8032-9_36, DOI 10.1007/978-981-19-8032-9_36]
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Sanz H, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2451-4
   Sepanlou SG, 2020, LANCET GASTROENTEROL, V5, P245, DOI 10.1016/S2468-1253(19)30349-8
   Sharma N, 2021, NEW GENERAT COMPUT, V39, P701, DOI 10.1007/s00354-020-00119-7
   Shobana G., 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1223, DOI 10.1109/ICCMC51019.2021.9418333
   Sontakke S, 2017, 2017 INTERNATIONAL CONFERENCE ON EMERGING TRENDS & INNOVATION IN ICT (ICEI), P129, DOI 10.1109/ETIICT.2017.7977023
   STEWART W., 2014, World cancer report 2014
   Sun CL, 2020, IEEE J BIOMED HEALTH, V24, P1643, DOI 10.1109/JBHI.2019.2949837
   Suthaharan S, 2016, INTEGR SER INFORM SY, V36, P207
   Theerthagiri P., 2022, Intell Syst Appl, V16
   Theerthagiri P, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13064
   Theerthagiri P, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.13048
   Tokala S., 2023, International Journal of Advanced Computer Science and Applications, V14, DOI [10.14569/ijacsa.2023.0140299, DOI 10.14569/IJACSA.2023.0140299]
   Wang XD, 2019, IEEE ACCESS, V7, P42639, DOI 10.1109/ACCESS.2019.2907043
   Zaheer MM, 2022, CARDIOMETRY, P1038, DOI 10.18137/cardiometry.2022.25/10381046
NR 55
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17825-1
EA DEC 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000006
DA 2024-07-18
ER

PT J
AU Sun, XL
   Li, WZ
   Liu, HT
   Fang, J
   Wen, Z
   Wen, CY
AF Sun, Xiulan
   Li, Wenzao
   Liu, Hantao
   Fang, Jie
   Wen, Zhan
   Wen, Chengyu
TI A task offloading strategy based on sequential waiting model in MEC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mobile edge computing; Latency; Offloading reliability; Task offloading;
   Niching genetic algorithm
ID RESOURCE-ALLOCATION; EDGE; OPTIMIZATION
AB In the field of mobile edge computing (MEC) research, many studies under common research scenarios focus on the optimization of energy consumption and processing delay. Meanwhile, some researchers only discussed the task offloading of terminals to a single server, without considering the collaborative execution of task offloading by multiple servers. Motivated by their observations, this paper conducted research in the scenario of offloading tasks from a single terminal to multiple edge servers. We formulated the multi-objective optimization problem of latency and offloading reliability, and proposed an intensive task offloading strategy based on the Sequential Waiting Model(SWM). The scheme allocates tasks according to the wireless channel environment and the computing power of the server. Besides, this approach minimized the combined cost consisting of latency and offloading failure probability. Since this kind of optimization problem has been proved to be an NP-hard problem. And we designed a Niching Preservation Genetic Algorithm (NPGA), which is based on Niching Genetic Algorithm (NGA). Besides, to obtain better system performance, we simulated the influence of different computing factors on the proposed algorithm NPGA and analyzed the convergence of the NPGA. Finally, the simulation results illustrated the proposed algorithm NPGA can effectively reduce the total latency of task completion and the probability of task offloading failure. Compared with the most advanced algorithms in the previous literature, the cost function value of the combined latency and offloading failure probability reduces 2%-16%. At the same time, we conducted simulation experiments using real base station locations, and also verified that the NPGA algorithm can achieve lower cost values under multiple edge server counts.
C1 [Sun, Xiulan; Li, Wenzao; Fang, Jie; Wen, Zhan; Wen, Chengyu] Chengdu Univ Informat Technol, Coll Commun Engn, Chengdu, Peoples R China.
   [Li, Wenzao; Liu, Hantao] Educ Informationizat & Big Data Ctr, Educ Dept Sichuan Prov, Chengdu, Peoples R China.
   [Li, Wenzao] Univ Elect Sci & Technol China, Network & Data Secur Key Lab Sichuan Pro, Chengdu, Peoples R China.
C3 Chengdu University of Information Technology; University of Electronic
   Science & Technology of China
RP Li, WZ (corresponding author), Chengdu Univ Informat Technol, Coll Commun Engn, Chengdu, Peoples R China.; Li, WZ (corresponding author), Educ Informationizat & Big Data Ctr, Educ Dept Sichuan Prov, Chengdu, Peoples R China.; Li, WZ (corresponding author), Univ Elect Sci & Technol China, Network & Data Secur Key Lab Sichuan Pro, Chengdu, Peoples R China.
EM lwz@cuit.edu.cn
FU the Network and Data Security Key Laboratory of Sichuan Province
   [NDS2021-7]; Network and Data Security Key Laboratory of Sichuan
   Province, UESTC [2019514]; Sichuan Province General Education Scientific
   Research [ZNZL2023A04, CXHCL202201]; Open Project of National
   Intelligent Society Governance Testing Area
FX We thank all the reviewers and editors who have contributed to the
   quality of this paper. At the same time, we also appreciate the support
   by the fund from the Network and Data Security Key Laboratory of Sichuan
   Province, UESTC (NO. NDS2021-7), Sichuan Province General Education
   Scientific Research (NO.2019514), Open Project of National Intelligent
   Society Governance Testing Area(ZNZL2023A04), Research on Intelligent
   Access Control Technology(CXHCL202201).
CR Al-Abiad MS, 2021, Arxiv, DOI arXiv:2104.11801
   Al-Habob AA, 2020, IEEE COMMUN LETT, V24, P71, DOI 10.1109/LCOMM.2019.2948179
   Ali R, 2021, IEEE ACCESS, V9, P67064, DOI 10.1109/ACCESS.2021.3073806
   Azimi SM, 2016, 2016 ANNUAL CONFERENCE ON INFORMATION SCIENCE AND SYSTEMS (CISS)
   Chen W, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093135
   conformancespecification Radio UEU, 2011, 3rd generation partnership project; technical specification group radio access network; evolved universal terrestrial radio access (e-utra); user equipment (ue) conformance specification radio transmission and reception
   Deng ZZ, 2020, IEEE ACCESS, V8, P53062, DOI 10.1109/ACCESS.2020.2981501
   Guo SY, 2021, COMPUT COMMUN, V170, P144, DOI 10.1016/j.comcom.2021.01.020
   Huang T, 2020, IEEE T INTELL TRANSP, V21, P4225, DOI 10.1109/TITS.2019.2939224
   Katoch S, 2021, MULTIMED TOOLS APPL, V80, P8091, DOI 10.1007/s11042-020-10139-6
   Li SY, 2018, WIREL COMMUN MOB COM, DOI 10.1155/2018/4181626
   Liu CF, 2017, IEEE GLOBE WORK
   Liu FG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051105
   Liu JH, 2019, IEEE ACCESS, V7, P11222, DOI 10.1109/ACCESS.2019.2891113
   Liu JH, 2018, IEEE ACCESS, V6, P12825, DOI 10.1109/ACCESS.2018.2800032
   Liu J, 2016, IEEE INT SYMP INFO, P1451, DOI 10.1109/ISIT.2016.7541539
   Mehrabi M., 2021, Network, V1, P191, DOI DOI 10.3390/NETWORK1020012
   Muñoz O, 2015, IEEE T VEH TECHNOL, V64, P4738, DOI 10.1109/TVT.2014.2372852
   Muoz A., 2021, J Comput Sci, V53, P101388
   Nyathi T, 2018, Expert Syst Appl
   Peng SY, 2019, ARAB J GEOSCI, V12, DOI 10.1007/s12517-019-4514-x
   Sacco A, 2022, IEEE T VEH TECHNOL, V71, P4301, DOI 10.1109/TVT.2022.3144654
   Sacco A, 2021, IEEE T GREEN COMMUN, V5, P1114, DOI 10.1109/TGCN.2021.3091812
   Saleem U, 2021, IEEE T WIREL COMMUN, V20, P360, DOI 10.1109/TWC.2020.3024538
   Sardellitti S, 2015, IEEE T SIGNAL INF PR, V1, P89, DOI 10.1109/TSIPN.2015.2448520
   Shahidinejad A, 2022, IEEE CONSUM ELECTR M, V11, P57, DOI 10.1109/MCE.2021.3053543
   Shahryari OK, 2021, PERVASIVE MOB COMPUT, V74, DOI 10.1016/j.pmcj.2021.101395
   Shakarami A, 2020, J GRID COMPUT, V18, P639, DOI 10.1007/s10723-020-09530-2
   Shuang Z, 2017, Research on key technologies of amc for lte uplink
   Souri A, 2020, CLUSTER COMPUT, V23, P2453, DOI 10.1007/s10586-019-03018-9
   Tang Q, 2020, NEURAL COMPUT APPL, V32, P15383, DOI 10.1007/s00521-019-04401-8
   Dinh TQ, 2017, IEEE T COMMUN, V65, P3571, DOI 10.1109/TCOMM.2017.2699660
   Wang YT, 2016, IEEE T COMMUN, V64, P4268, DOI 10.1109/TCOMM.2016.2599530
   Wu CR, 2019, INT SYMPOS COMPUT NE, P204, DOI 10.1109/CANDAR.2019.00034
   Xiao S, 2020, Future Gen Comput Syst
   Xu XL, 2019, J NETW COMPUT APPL, V133, P75, DOI 10.1016/j.jnca.2019.02.008
   Zhang K, 2016, IEEE ACCESS, V4, P5896, DOI 10.1109/ACCESS.2016.2597169
   Zhou JS, 2019, IEEE SIGNAL PROC LET, V26, P104, DOI 10.1109/LSP.2018.2880081
   Zhou SC, 2021, COMPUTING, V103, P2839, DOI 10.1007/s00607-021-00931-z
NR 39
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 5
PY 2023
DI 10.1007/s11042-023-17578-x
EA DEC 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8R0
UT WOS:001121582900005
DA 2024-07-18
ER

PT J
AU Zhang, SY
   Wang, CP
   Sun, YR
   Yang, J
   Gao, SQ
AF Zhang, Si-yu
   Wang, Chun-peng
   Sun, Yao-ru
   Yang, Jun
   Gao, Shi-qing
TI Locally optimum watermark decoder based on fast quaternion generic polar
   complex exponential transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Watermarking; Fast quaternion generic polar complex exponential
   transform; Maximum likelihood decoder; Cauchy-Rayleigh distribution
ID HARMONIC FOURIER MOMENTS; IMAGE WATERMARKING; DETECTOR
AB Digital image watermarking, as an important image content security protection technology, has higher research value. It is well-known that imperceptibility, robustness, and watermark payload are three paramount factors to evaluate model performance. Recent methods based on statistical modeling strategy effectively trade-off between imperceptibility and robustness. However, capacity and time complexity are not allowed to ignore. Furthermore, how to select robust modeling objects, appropriate statistical models, and decision rules is one of the major issues in statistical watermark detection. To this end, we propose a color image watermark detector in robust fast quaternion generic polar complex exponential transform (FQGPCET) magnitudes domain, which fully considers the human visual system (HVS) and the statistical properties of image signals. Specifically, we adopt the Cauchy-Rayleigh distribution to model the probability density function of the FQGPCET magnitudes. Then, local high entropy image blocks are used as a new embedding domain for watermark messages due to their strong robustness. Furthermore, we develop a novel optimum multibit watermark decoder based on maximum likelihood theory. Experimental results are evaluated employing a set of standard color images in terms of watermark capacity, imperceptibility, and robustness. The proposed scheme provides better performance against all types of attacks in comparison with other existing methods.
C1 [Zhang, Si-yu; Sun, Yao-ru; Yang, Jun; Gao, Shi-qing] Tongji Univ, Sch Elect & Informat Engn, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
   [Wang, Chun-peng] Qilu Univ Technol, Shandong Acad Sci, Sch Cyber Secur, Shandong Prov Key Lab Comp Networks, Jinan 250353, Peoples R China.
C3 Tongji University; Qilu University of Technology
RP Sun, YR (corresponding author), Tongji Univ, Sch Elect & Informat Engn, Dept Comp Sci & Technol, Shanghai 201804, Peoples R China.
EM yaoru@tongji.edu.cn
FU National Natural Science Foundation of China [2019YFC1906201]; National
   Key R &D Program of China [91748122]; National Natural Science
   Foundation of China
FX This work was supported by the National Key R &D Program of China under
   Grant No. 2019YFC1906201, National Natural Science Foundation of China
   under Grant No. 91748122.
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Ahmadi SBB, 2021, APPL INTELL, V51, P1701, DOI 10.1007/s10489-020-01903-0
   Alghamedi A., 2020, ANN DATA SCI, V7, P139, DOI [10.1007/s40745-020-00240-w, DOI 10.1007/S40745-020-00240-W]
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amirmazlaghani M, 2017, LECT NOTES COMPUT SC, V10485, P547, DOI 10.1007/978-3-319-68548-9_50
   Barazandeh M, 2016, P 2 IEEE INT C SIGN, P1
   Bibalan MH, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0148-z
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Dong L, 2017, MULTIMED TOOLS APPL, V76, P1983, DOI 10.1007/s11042-015-3115-2
   Etemad S, 2018, PATTERN RECOGN, V77, P99, DOI 10.1016/j.patcog.2017.12.006
   Ganji M, 2016, J Math Sci, V218
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hernández JR, 1999, P IEEE, V87, P1142, DOI 10.1109/5.771069
   Hoang TV, 2014, IMAGE VISION COMPUT, V32, P497, DOI 10.1016/j.imavis.2014.04.016
   Hoang TV, 2014, IEEE T IMAGE PROCESS, V23, P2961, DOI 10.1109/TIP.2014.2322933
   Hoang TV, 2011, IEEE IMAGE PROC, P829, DOI 10.1109/ICIP.2011.6116685
   Hosny KM, 2020, ASTRON COMPUT, V31, DOI 10.1016/j.ascom.2020.100383
   Li YN, 2013, IEEE SIGNAL PROC LET, V20, P803, DOI 10.1109/LSP.2013.2267775
   Liu YN, 2020, PATTERN ANAL APPL, V23, P1551, DOI 10.1007/s10044-020-00877-6
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Niu PP, 2020, MULTIMED TOOLS APPL, V79, P33071, DOI 10.1007/s11042-020-09621-y
   Niu PP, 2020, MULTIMED TOOLS APPL, V79, P13351, DOI 10.1007/s11042-019-08504-1
   Ouyang JL, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2978572
   Rabizadeh M, 2016, J VIS COMMUN IMAGE R, V40, P324, DOI 10.1016/j.jvcir.2016.07.001
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Sharman K. C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P2716, DOI 10.1109/ICASSP.1989.267029
   ugr, ABOUT US
   usenix, ABOUT US
   Wang CP, 2016, J VIS COMMUN IMAGE R, V41, P247, DOI 10.1016/j.jvcir.2016.10.004
   Wang CP, 2022, IEEE T CIRC SYST VID, V32, P1998, DOI 10.1109/TCSVT.2021.3094882
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2018, INFORM SCIENCES, V450, P141, DOI 10.1016/j.ins.2018.03.040
   Wang KS, 2022, MULTIMED TOOLS APPL, V81, P6159, DOI 10.1007/s11042-021-11725-y
   Wang WB, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6615678
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P27717, DOI 10.1007/s11042-021-11056-y
   Wang XY, 2020, INFORM SCIENCES, V535, P81, DOI 10.1016/j.ins.2020.05.034
   Wang XY, 2019, J VIS COMMUN IMAGE R, V62, P309, DOI 10.1016/j.jvcir.2019.05.012
   Wang XY, 2016, INFORM SCIENCES, V372, P634, DOI 10.1016/j.ins.2016.08.076
   Wang XY, 2015, OPT LASER TECHNOL, V66, P78, DOI 10.1016/j.optlastec.2014.07.020
   Wang XY, 2023, J VIS COMMUN IMAGE R, V91, DOI 10.1016/j.jvcir.2023.103779
   Wang XY, 2022, MULTIMED TOOLS APPL, V81, P43037, DOI 10.1007/s11042-022-13229-9
   Xia ZQ, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2020.106568
   Yang HY, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115747
   Yao YZ, 2019, SIGNAL PROCESS, V164, P386, DOI 10.1016/j.sigpro.2019.06.034
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
   Zhong X, 2020, IEEE Trans Multimed, P201
NR 49
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 2
PY 2023
DI 10.1007/s11042-023-17682-y
EA DEC 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AV0F5
UT WOS:001121103400003
DA 2024-07-18
ER

PT J
AU Li, N
   Wang, ML
   Yang, GC
   Li, B
   Yuan, BH
   Xu, SK
AF Li, Ning
   Wang, Mingliang
   Yang, Gaochao
   Li, Bo
   Yuan, Baohua
   Xu, Shoukun
TI DENS-YOLOv6: a small object detection model for garbage detection on
   water surface
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Small object detection; Water surface garbage detection; YOLOv6; Detail
   information enhancement; Adaptive noise suppression
AB The study of garbage detection onwater surface is of great significance for the development of water surface garbage monitoring and automated water surface garbage salvage. However, in water surface garbage scenes, the proportion of water background is relatively large, while the proportion of detection objects is relatively small. Moreover, the objects are easily affected by noise interference such as lighting, water waves, and reflections, which makes it difficult to extract object features and affects detection accuracy. In this paper, we propose a Detail Enhancement Noise Suppression YOLOv6 (DENS-YOLOv6) detection algorithm based on YOLOv6. Firstly, to better capture the detailed feature information of small objects, we design a Detail Information Enhancement Module (DIEM) based on atrous convolution. Secondly, to suppress noise interference on small objects, we develop an Adaptive Noise Suppression Module (ANSM). Finally, in order to improve the stability and convergence speed of the model training, we employ a regression loss function based on the Normalized Wasserstein Distance(NWD) metric. Experiments were conducted on the Flow+ dataset with a large number of small objects and the publicly available Pascal VOC2007 dataset. The mAPS indicators reached 40.6% and 11.4%, respectively. Compared with other models, DENS-YOLOv6 achieved the highest small object detection accuracy
C1 [Li, Ning; Wang, Mingliang; Yang, Gaochao; Li, Bo; Yuan, Baohua; Xu, Shoukun] Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Aliyun Sch Big Data, Sch Software, Changzhou 213164, Peoples R China.
   [Li, Ning] Hohai Univ, Sch Comp & Informat Engn, Nanjing 210098, Peoples R China.
   [Li, Bo] Changzhou Univ, Jiangsu Petrochem Proc Key Equipment Digital Twin, Changzhou 213164, Peoples R China.
C3 Changzhou University; Hohai University; Changzhou University
RP Xu, SK (corresponding author), Changzhou Univ, Sch Comp Sci & Artificial Intelligence, Aliyun Sch Big Data, Sch Software, Changzhou 213164, Peoples R China.
EM xsk@cczu.edu.cn
OI Yuan, Baohua/0000-0001-9694-9250
FU Jiangsu Petrochemical Process Key Equipment Digital Twin Technology
   Engineering Research Center Open Project;  [DTEC202103]
FX This work was supported by Jiangsu Petrochemical Process Key Equipment
   Digital Twin Technology Engineering Research Center Open Project
   (DTEC202103).
CR Antonelli S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3519022
   Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Cheng YW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10933, DOI 10.1109/ICCV48922.2021.01077
   Chu FC, 2022, LECT NOTES COMPUT SC, V13604, P343, DOI 10.1007/978-3-031-20497-5_28
   Ding XH, 2021, PROC CVPR IEEE, P13728, DOI 10.1109/CVPR46437.2021.01352
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gao A, 2022, IEEE Trans Circ Syst Vid Technol
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Gevorgyan Z, 2022, Arxiv, DOI [arXiv:2205.12740, 10.48550/arXiv.2205.12740]
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta A, 2022, PROC CVPR IEEE, P9225, DOI 10.1109/CVPR52688.2022.00902
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jiang Z, 2023, J Comput Appl 0
   Li CY, 2022, Arxiv, DOI [arXiv:2209.02976, 10.48550/arXiv.2209.02976]
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2023, Neurocomputing
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P6719, DOI 10.1109/TIP.2022.3215887
   Liu Y, 2021, IEEE T INF FOREN SEC, V16, P5154, DOI 10.1109/TIFS.2021.3124734
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Ma Long, 2023, 2023 5th International Conference on Communications, Information System and Computer Engineering (CISCE), P391, DOI 10.1109/CISCE58541.2023.10142409
   Noh J, 2019, IEEE I CONF COMP VIS, P9724, DOI 10.1109/ICCV.2019.00982
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shao Z., 2023, IEEE T MULTIMED
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang JB, 2023, Arxiv, DOI arXiv:2302.04607
   Wang JW, 2022, Arxiv, DOI arXiv:2110.13389
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HW, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01369-6
   Xu C, 2021, IEEE COMPUT SOC CONF, P1192, DOI 10.1109/CVPRW53098.2021.00130
   Xu SK, 2023, NEUROCOMPUTING, V525, P29, DOI 10.1016/j.neucom.2023.01.055
   Yang LX, 2021, PR MACH LEARN RES, V139
   Yang XS, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10224366
   Zhang H, 2022, Arxiv, DOI arXiv:2203.03605
   Zhang LL, 2021, IEEE ACCESS, V9, P81147, DOI 10.1109/ACCESS.2021.3085348
   Zhang QL, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2235, DOI 10.1109/ICASSP39728.2021.9414568
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 55
TC 2
Z9 2
U1 16
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17679-7
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700003
DA 2024-07-18
ER

PT J
AU Mulla, S
   Shaikh, NF
AF Mulla, Samina
   Shaikh, Nuzhat F.
TI Effective Elytron Vespid-B rank BiLSTM classifier for Multi-Document
   Summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi documents; Elytron Vespid-B optimization algorithm; BiLSTM
   classifier; Summarized document; Complexity
AB Multi-Document Summarization is the progression of extracting the pertinent information from a group of documents and weeding out the irrelevant information to create a concise text representation of the documents. This summarization initiates comprehensive information and a coherent flow of the summary, which reduces the effort and time of the individuals. In this research, the document summarization is performed using the Elytron Vespid-B rank-based Bidirectional Long Short-Term Memory (BiLSTM) classifier, which reduces the multi documents into a summarized document. The main contribution of the research depends on the proposed Elytron Vespid Beetle (Elytron Vespid-B) optimization algorithm that effectively enhanced the interactive and individual behavior of the Elytron-B that reduced the computational complexity of the classifier by optimally tuning the hyperparameters. The proposed Elytron vespid-B rank BiLSTM classifier achieved the values of 0.61, 0.35, and 0.61, for the metrics f1 measure for the varied rouges 1, 2, and l, which are believed to be more efficient than the existing approaches, and used to reveal the effectiveness of the research.
C1 [Mulla, Samina] STESs Smt Kashibai Navale Coll Engn, Res Ctr, Dept Comp Engn, Pune 411041, Maharastra, India.
   [Shaikh, Nuzhat F.] Modern Educ Soc Coll Engn MESCOE Pune, Dept Comp Engn, 19 Bund Garden Rd,Wadia Coll Campus, Pune 411001, Maharashtra, India.
RP Mulla, S (corresponding author), STESs Smt Kashibai Navale Coll Engn, Res Ctr, Dept Comp Engn, Pune 411041, Maharastra, India.
EM samina.mulla27@gmail.com
RI Mulla, Samina/JCO-0358-2023
CR Alguliev RM, 2011, SWARM EVOL COMPUT, V1, P213, DOI 10.1016/j.swevo.2011.06.006
   Baralis E, 2013, INFORM SCIENCES, V249, P96, DOI 10.1016/j.ins.2013.06.046
   Cao SS, 2016, AAAI CONF ARTIF INTE, P1145
   ieee-dataport, DUC 2002 dataset
   Liu Yang, 2019, ARXIV
   Lloret E, 2012, ARTIF INTELL REV, V37, P1, DOI 10.1007/s10462-011-9216-z
   Mojrian M, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2020.114555
   paperswithcode, DUC 2004 dataset
   paperswithcode, Daily mail dataset
   Pinto P, 2005, SPRING COMP SCI, P264, DOI 10.1007/3-211-27389-1_63
   Ribeiro LFR, 2020, T ASSOC COMPUT LING, V8, P589, DOI 10.1162/tacl_a_00332
   Rostami M, 2023, IEEE ACCESS, V11, P30247, DOI 10.1109/ACCESS.2023.3260652
   Roul RK, 2021, SOFT COMPUT, V25, P1113, DOI 10.1007/s00500-020-05207-w
   Sanchez-Gomez JM, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106231
   Sanchez-Gomez JM, 2018, KNOWL-BASED SYST, V159, P1, DOI 10.1016/j.knosys.2017.11.029
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Srivastava AK, 2021, MULTIMED TOOLS APPL, V80, P11273, DOI 10.1007/s11042-020-10176-1
   Tomer M, 2022, J KING SAUD UNIV-COM, V34, P6057, DOI 10.1016/j.jksuci.2021.04.004
   Uçkan T, 2020, EGYPT INFORM J, V21, P145, DOI 10.1016/j.eij.2019.12.002
   Wang DQ, 2020, Arxiv, DOI [arXiv:2004.12393, DOI 10.48550/ARXIV.2004.12393]
   Wang TT, 2020, Arxiv, DOI arXiv:1808.00206
   Xu JC, 2020, Arxiv, DOI arXiv:1910.14142
   Yasunaga M, 2017, Arxiv, DOI arXiv:1706.06681
NR 23
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 30
PY 2023
DI 10.1007/s11042-023-17544-7
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Z2YV8
UT WOS:001110791700007
DA 2024-07-18
ER

PT J
AU Bodzin, AM
   Fu, Q
   Araujo-Junior, RM
   Hammond, T
   Anastasio, D
   Schwartz, C
AF Bodzin, Alec M.
   Fu, Qiong
   Araujo-Junior, Robson M.
   Hammond, Thomas
   Anastasio, David
   Schwartz, Chad
TI Implementation of a desktop virtual reality field trip in public
   outreach settings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual Reality field trip; Desktop Virtual Reality; Engagement; Public
   outreach; Environmental education
ID ENGAGEMENT; EDUCATION; STATE; MODEL
AB This study investigated how the VR experience (immersion and presence) and design features (narrative, guidance, and feedback) were related to participants' engagement and perceptions of learning with a desktop Virtual Reality field trip (dVFT) in public outreach settings as used by environmental education centers. Data was collected from 139 participants at three different types of public outreach settings. The results found that immersion, presence, engagement, learning about local environment, VR design features, and affective learning were perceived favorably by the majority of the study's participants. Design features, engagement, learning about the local environment, and affective learning were significantly lower for young participants (<= 18 years old) compared to adults. Environmental education center festival participants had higher favorable mean responses for each subscale followed by Web location participants, followed by Homework Club participants. Results from the path analysis highlighted the importance of presence and the design features for engagement and perceived learning. Our findings support that learning about one's local environment with a dVFT can have a positive impact on engagement and learning, particularly in public outreach learning environments.
C1 [Bodzin, Alec M.; Fu, Qiong; Araujo-Junior, Robson M.; Hammond, Thomas] Lehigh Univ, Dept Educ & Human Serv, Bethlehem, PA 18015 USA.
   [Anastasio, David] Lehigh Univ, Dept Earth & Environm Sci, Bethlehem, PA USA.
   [Schwartz, Chad] Lehigh Gap Nat Ctr, Slatington, PA USA.
C3 Lehigh University; Lehigh University
RP Bodzin, AM (corresponding author), Lehigh Univ, Dept Educ & Human Serv, Bethlehem, PA 18015 USA.
EM amb4@lehigh.edu
OI Fu, Qiong/0000-0002-2282-7653; Bodzin, Alec/0000-0002-5045-1681
FU Lehigh University; Office of Creative Inquiry at Lehigh University;
   Lehigh Gap Nature Center, Nurture Nature Center; D&L National Heritage
   Corridor
FX We thank Sarah Kiel, Tyler Hogue, Austin Lordi, Brad DeMassa, Challen
   Adu, Kanaruj Chanthongdee, Yolanda Liu, Max Louissaint, Anthony Blakely,
   and Brantley Balsamo for their development work with us on the dVFT. The
   authors are grateful for the Office of Creative Inquiry at Lehigh
   University and its continued support. Special thanks to the Lehigh RiVR
   Immersive Learning lab members. In addition, the authors appreciate the
   collaboration from Lehigh Gap Nature Center, Nurture Nature Center,
   Jacobsburg Environmental Education Center, and D&L National Heritage
   Corridor.
CR Allen S., 2007, Secrets of circles summative evaluation report. Report prepared for the Children's Discovery Museum of San Jose
   Alon NL, 2015, INT J SCI EDUC, V37, P1279, DOI 10.1080/09500693.2015.1034797
   Andersen MS, 2023, J COMPUT ASSIST LEAR, V39, P369, DOI 10.1111/jcal.12749
   [Anonymous], 2005, The Journal of Environmental Education, DOI [10.3200/JOEE.36.3.39-50, DOI 10.3200/JOEE.36.3.39-50]
   Azevedo R., 2010, INT HDB METACOGNITIO
   Bibic L, 2019, J CHEM EDUC, V96, P1486, DOI 10.1021/acs.jchemed.8b00905
   Bleiwas DonaldI., 2010, US GEOLOGICAL SURVEY
   Bodzin A, 2022, Inno Sci Teac Edu, V7
   Bodzin A, 2021, J SCI EDUC TECHNOL, V30, P347, DOI 10.1007/s10956-020-09870-4
   Bodzin AM, 2008, J ENVIRON EDUC, V39, P47, DOI 10.3200/JOEE.39.2.47-58
   Borun M., 2003, Space Command summative evaluation
   Carini RM, 2006, RES HIGH EDUC, V47, P1, DOI 10.1007/s11162-005-8150-9
   Cheng KH, 2022, J RES TECHNOL EDUC, V54, P438, DOI 10.1080/15391523.2021.1876576
   Cheng KH, 2019, COMPUT EDUC, V140, DOI 10.1016/j.compedu.2019.103600
   Chung J., 2016, MEASURES TECHNICAL B
   Clary R.M., 2010, Journal of College Science Teaching, V39, P50
   Cummings JJ, 2022, NEW MEDIA SOC, V24, P2003, DOI 10.1177/1461444820986816
   Cummings JJ, 2016, MEDIA PSYCHOL, V19, P272, DOI 10.1080/15213269.2015.1015740
   Dale RG, 2020, ENVIRON EDUC RES, V26, P613, DOI 10.1080/13504622.2020.1738346
   de Jong T., 2005, CAMBRIDGE HDB MULTIM, P215, DOI [10.1017/CBO9780511816819.015, DOI 10.1017/CBO9780511816819.015]
   Dolphin G., 2019, J GEOSCIENCE ED, V67, P114, DOI [DOI 10.1080/10899995.2018.1547034, 10.1080/10899995.2018, DOI 10.1080/10899995.2018]
   Dorph R., 2016, The Electronic Journal for Research in Science Mathematics Education, V20, P49
   Finn JD., 1995, J Res Sci Teac, V40, P163
   Fredricks J., 2011, ISSUES ANSWERS REL 2
   Fredricks JA, 2004, REV EDUC RES, V74, P59, DOI 10.3102/00346543074001059
   Freina L, 2015, ELEARN SOFTW EDUC, P133, DOI 10.12753/2066-026X-15-020
   Fritz MS, 2012, MULTIVAR BEHAV RES, V47, P61, DOI 10.1080/00273171.2012.640596
   Fung FM, 2019, J CHEM EDUC, V96, P382, DOI 10.1021/acs.jchemed.8b00728
   Goldowsky N, 2002, Dissertation
   Hahgood MPJ, 2005, SIMULAT GAMING, V36, P483, DOI 10.1177/1046878105282276
   Han IS, 2020, BRIT J EDUC TECHNOL, V51, P420, DOI 10.1111/bjet.12842
   Hidi S, 2006, EDUC PSYCHOL-US, V41, P111, DOI 10.1207/s15326985ep4102_4
   [Honey MargaretA. National Research Council National Research Council], 2011, LEARNING SCI COMPUTE
   Huang XX, 2023, COMPUT EDUC OPEN, V4, DOI 10.1016/j.caeo.2023.100124
   Jenkins H., 2002, 1 PERSON
   Jennett C, 2008, INT J HUM-COMPUT ST, V66, P641, DOI 10.1016/j.ijhcs.2008.04.004
   Jensen L, 2018, EDUC INF TECHNOL, V23, P1515, DOI 10.1007/s10639-017-9676-0
   Johnson-Glenberg MC, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01819
   Kersting M, 2021, INT J SCI EDUC PART, V11, P17, DOI 10.1080/21548455.2020.1857458
   Klippel A, 2020, VIRTUAL REAL-LONDON, V24, P753, DOI 10.1007/s10055-019-00418-5
   Langran E., 2020, Navigating placed-based learning, DOI [10.1007/978-3-030-55673-0, DOI 10.1007/978-3-030-55673-0]
   Leung GYS, 2022, J ENVIRON PSYCHOL, V83, DOI 10.1016/j.jenvp.2022.101863
   Litherland K, 2012, TECHNOL PEDAGOG EDUC, V21, P213, DOI 10.1080/1475939X.2012.697773
   Makransky G, 2019, LEARN INSTR, V60, P225, DOI 10.1016/j.learninstruc.2017.12.007
   Markowitz DM, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.02364
   McLean K., 1993, Planning for people in museum exhibitions
   Mead C., 2019, Journal of Geoscience Education, V67, P131, DOI [10.1080/10899995.2019.1565285, DOI 10.1080/10899995.2019.1565285]
   Muthen LK., 1998, MPLUS USERS GUIDE
   Nasir NS, 2006, CAMB HANDB PSYCHOL, P489
   Natl Res Council, 2009, LEARNING SCIENCE IN INFORMAL ENVIRONMENTS: PEOPLE, PLACES, AND PURSUITS, P1
   Novak E, 2015, ETR&D-EDUC TECH RES, V63, P431, DOI 10.1007/s11423-015-9372-y
   Petersen GB, 2020, BRIT J EDUC TECHNOL, V51, P2098, DOI 10.1111/bjet.12991
   Pirker J., 2016, Handbook of Research on Engaging Digital Natives in Higher Education Settings, P416, DOI [10.4018/978-1-5225-0039-1.ch020, DOI 10.4018/978-1-5225-0039-1.CH020]
   Pituch K.A., 2016, APPL MULTIVARIATE ST, V6th
   Reeve J, 2013, J EDUC PSYCHOL, V105, P579, DOI 10.1037/a0032690
   Reeve J, 2011, CONTEMP EDUC PSYCHOL, V36, P257, DOI 10.1016/j.cedpsych.2011.05.002
   Renne JL, 2021, J TRANSP GEOGR, V93, DOI 10.1016/j.jtrangeo.2021.103077
   Rogoff B., 2003, CULTURAL NATURE HUMA
   Sanchez-Vives MV, 2005, NAT REV NEUROSCI, V6, P332, DOI 10.1038/nrn1651
   Semken S., 2017, J GEOSCIENCE ED, V65, P542, DOI [DOI 10.5408/17-276.1, 10.5408/17-276.1]
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Sobel D., 2004, Place-based Education: Connecting Classrooms Communities
   Southgate Erica, 2019, International Journal of Child-Computer Interaction, V19, P19, DOI 10.1016/j.ijcci.2018.10.002
   Tabachnick B.G., 2001, Using Multivariate Statistics
   Vander Ark T., 2020, POWER PLACE AUTHENTI
   Wirth W, 2007, MEDIA PSYCHOL, V9, P493, DOI 10.1080/15213260701283079
   Zhao JY, 2020, 2020 IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR 2020), P893, DOI [10.1109/VR46266.2020.00114, 10.1109/VR46266.2020.1581091793502]
NR 67
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 28
PY 2023
DI 10.1007/s11042-023-17729-0
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW6F2
UT WOS:001155742800001
DA 2024-07-18
ER

PT J
AU Wang, JH
   Wang, L
   Yang, ZX
   Tan, WC
   Luo, M
   Liu, YB
AF Wang, Jinhua
   Wang, Liang
   Yang, Zhongxian
   Tan, Wanchang
   Luo, Min
   Liu, Yubao
TI Multifractal analysis of MRI. images from breast cancer patients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE MRI; Breast cancer; Multifractal analysis; Chemotherapy; Blood supply;
   Lacunarity
ID FRACTAL ANALYSIS; LACUNARITY; DIMENSION; LESIONS; TRENDS; CHINA
AB The present study aims to evaluate the effectiveness of the multifractal analysis in classifying benign and malignant tumor cells on MRI (Magnetic Resonance Imaging) images from patients diagnosed with breast cancer. In this study, the three-dimensional multifractal analysis method was adapted to comprehensively analyze MRI breast images and evaluate chemotherapy in terms of effectiveness. Twenty-four Chinese patients (Guangdong, Shenzhen, People's Republic of China (PRC)) between the ages of 18 and 60 were included in the study. All patients were divided in two groups. Group 1 included 10 women whose MRI breast images were used to estimate the multifractal scaling exponents, with lacunarity taken as a multifractal measure. Group 2 included 14 patients whose MRI breast images underwent multifractal analysis to evaluate chemotherapy in terms of effectiveness. The MRI images were taken before and after chemotherapy. The combined multifractal analysis is effective for classifying malignant and benign neoplasms. Based on the results of the study, the multifractal spectrum width has proven an informative parameter in quantitative analysis of cancer treatment effectiveness. It correlates with the rate of blood supply to malignant tumors. The baseline Hurst exponent was below 0.4, indicating a low long-term correlation in the original data. However, after chemotherapy treatment, the exponent significantly increased to a range of 0.7-0.9, suggesting enhanced long-term correlation and a potential association with the effectiveness of chemotherapy in the context of breast cancer. Receiver operating characteristic (ROC) curve analysis for fractal dimension and lacunarity showed 70.8% sensitivity and 65.9% specificity and 72.4% sensitivity and 89.3% specificity, respectively. Therefore, lacunarity is more effective as a parameter in neoplastic cell identification. The present findings provide prediction capability for breast cancer at various stages. The multifractal method exhibited high efficiency of tumor classification in MRI.
C1 [Wang, Jinhua; Yang, Zhongxian; Luo, Min; Liu, Yubao] Southern Med Univ, Shenzhen Hosp, Shenzhen, Peoples R China.
   [Wang, Jinhua; Yang, Zhongxian; Luo, Min; Liu, Yubao] Southern Med Univ, Clin Med 3, Shenzhen, Peoples R China.
   [Wang, Liang] Univ Hong Kong, Shenzhen Hosp, Shenzhen, Peoples R China.
   [Tan, Wanchang] South China Univ Technol, Affiliated Hosp 6, Sch Med, Foshan, Peoples R China.
C3 Southern Medical University - China; Southern Medical University -
   China; University of Hong Kong; South China University of Technology
RP Liu, YB (corresponding author), Southern Med Univ, Shenzhen Hosp, Shenzhen, Peoples R China.; Liu, YB (corresponding author), Southern Med Univ, Clin Med 3, Shenzhen, Peoples R China.
EM ybliu28@163.com
FU Shenzhen Science and Technology Program [JCYJ20210324125403011]; Open
   Fund Program of National Innovation Center for Advanced Medical Devices
   [NMED2021MS-01-003]; Shenzhen Bao'an District Science and Technology
   Plan Basic Research Project [2021JD041]; Guangdong Provincial College
   Students Innovation training Program Project [S202112121097]
FX This study was funded by the Shenzhen Science and Technology Program
   (Grant Number: JCYJ20210324125403011), Open Fund Program of National
   Innovation Center for Advanced Medical Devices (NMED2021MS-01-003),
   Shenzhen Bao'an District Science and Technology Plan Basic Research
   Project (Number:2021JD041) and Guangdong Provincial College Students
   Innovation training Program Project(S202112121097).
CR [Anonymous], 2001, Image Anal. Stereol.
   Ballerini L., 2003, WSEAS Transactions on Circuits and Systems, V2, P270
   Bayrak E.A., 2022, System Analysis Intelligent Computing: Theory and Applications, P377, DOI [10.1007/978-3-030-94910-5_19, DOI 10.1007/978-3-030-94910-5_19]
   Chan A, 2016, ROY SOC OPEN SCI, V3, DOI 10.1098/rsos.160558
   Chen W, 2007, MAGN RESON MED, V58, P562, DOI 10.1002/mrm.21347
   da Silva Lucas Glaucio, 2021, Appl Microsc, V51, P6
   Dokukin ME, 2011, PHYS REV LETT, V107, DOI 10.1103/PhysRevLett.107.028101
   Elkington L., 2022, Biophysica, V2, P59, DOI [10.3390/biophysica2010005, DOI 10.3390/BIOPHYSICA2010005]
   Gil'deeva GN, 2018, PHARM CHEM J+, V52, P550, DOI 10.1007/s11094-018-1858-6
   Gould DJ, 2011, MICROCIRCULATION, V18, P136, DOI 10.1111/j.1549-8719.2010.00075.x
   Hakim Aayesha, 2022, IOT with Smart Systems: Proceedings of ICTIS 2021. Smart Innovation, Systems and Technologies (251), P393, DOI 10.1007/978-981-16-3945-6_38
   Ivanov PC, 1996, NATURE, V383, P323, DOI 10.1038/383323a0
   Ivanov PC, 1999, NATURE, V399, P461, DOI 10.1038/20924
   Joseph AJ, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111301
   Kisan S., 2017, IRJET, V4, P1102
   Lemaître G, 2015, COMPUT BIOL MED, V60, P8, DOI 10.1016/j.compbiomed.2015.02.009
   Li HP, 2021, J IMAGING, V7, DOI 10.3390/jimaging7100205
   Li L, 2014, BIO-MED MATER ENG, V24, P163, DOI 10.3233/BME-130796
   Lopes R, 2011, PATTERN RECOGN, V44, P1690, DOI 10.1016/j.patcog.2011.02.017
   Maipas S, 2018, CUREUS J MED SCIENCE, V10, DOI 10.7759/cureus.3630
   Mani DR, 2022, NAT REV CANCER, V22, P298, DOI 10.1038/s41568-022-00446-5
   Marrone A, 1999, PHYS REV E, V60, P1088, DOI 10.1103/PhysRevE.60.1088
   Maryenko N., 2021, Inter Collegas, V8, P290, DOI [10.35339/ic.8.4.290-297, DOI 10.35339/IC.8.4.290-297]
   Pavlov AN, 2005, CHAOS SOLITON FRACT, V24, P57, DOI 10.1016/j.chaos.2004.09.025
   Rangayyan RM, 2007, J DIGIT IMAGING, V20, P223, DOI 10.1007/s10278-006-0860-9
   Rao AA, 2016, RADIOGRAPHICS, V36, P623, DOI 10.1148/rg.2016150178
   Revel'skii IA, 2009, J ANAL CHEM+, V64, P926, DOI 10.1134/S1061934809090093
   Roy A, 2014, FRACTALS, V22, DOI 10.1142/S0218348X14400039
   Schleicher D, 2007, AM MATH MON, V114, P509, DOI 10.1080/00029890.2007.11920440
   Sedivy R, 1997, CANCER INVEST, V15, P601, DOI 10.3109/07357909709047603
   Sharma S, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.20752
   Sim AJ, 2020, CLIN TRANSL RAD ONCO, V24, P16, DOI 10.1016/j.ctro.2020.06.002
   Smirnova IG, 2012, MOSC UNIV CHEM BULL, V67, P95, DOI 10.3103/S002713141203008X
   Smitha KA, 2015, PHYS MED BIOL, V60, P6937, DOI 10.1088/0031-9155/60/17/6937
   Soares F, 2013, IEEE T IMAGE PROCESS, V22, P4422, DOI 10.1109/TIP.2013.2273669
   Soares F, 2009, 2009 IEEE PACIFIC RIM CONFERENCE ON COMMUNICATIONS, COMPUTERS AND SIGNAL PROCESSING, VOLS 1 AND 2, P677, DOI 10.1109/PACRIM.2009.5291288
   Song SE, 2015, CANCER IMAGING, V15, DOI 10.1186/s40644-015-0036-2
   Sun DQ, 2020, CHINESE J CANCER RES, V32, P129, DOI 10.21147/j.issn.1000-9604.2020.02.01
   Thurner S, 1998, PHYS REV LETT, V80, P1544, DOI 10.1103/PhysRevLett.80.1544
   Vasiljevic J., 2016, Comp Sci Inform Tech, V6, P61
   Velanovich V, 1996, AM J MED SCI, V311, P211, DOI 10.1097/00000441-199605000-00003
   WHO, 2020, BREAST CANCER-TOKYO
   Xia CF, 2022, CHINESE MED J-PEKING, V135, P584, DOI 10.1097/CM9.0000000000002108
   Ye DM, 2020, TECHNOL CANCER RES T, V19, DOI 10.1177/1533033820916191
   Yoshioka H, 2021, ACTA CYTOL, V65, P4, DOI 10.1159/000509668
NR 45
TC 0
Z9 0
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 27
PY 2023
DI 10.1007/s11042-023-17380-9
EA NOV 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8T3
UT WOS:001121585200005
DA 2024-07-18
ER

PT J
AU Singh, A
   Chandra, H
   Rana, S
   Chhikara, D
AF Singh, Akanksha
   Chandra, Harish
   Rana, Saurabh
   Chhikara, Deepak
TI Blockchain based authentication and access control protocol for IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE IoT; Authentication; Key agreement; Blockchain; Security; Access control
ID INTERNET; SYSTEM
AB The integration of various advancements, ongoing management, intellectual capacity, item sensors, and incorporated frameworks have all contributed to idea behind the internet of things. Due to the energy limitations of the majority of Internet of Things (IoT) devices, more and more developers are choosing to create IoT systems based on group communication. A safe and reliable authenticated group secret key is essential for complete group communication in these applications. As the resource-constrained character and widespread use of the Internet of Things (IoT) provide a significant problem for IoT application security. In this paper, using elliptic curve and bi-linear paring, we provide a Blockchain based lightweight authenticated key agreement and access control protocol for group communication. We also proved the secrecy of the protocol in the random-oracle paradigm and give a thorough heuristic security assessment to verify that our protocol is safe from all possible threats and offers the required security features. Furthermore, functional implementation using NS-3 simulation expose that presented protocol is applicable for real-life IoT environments.
C1 [Singh, Akanksha; Chandra, Harish] Madan Mohan Malaviya Univ Technol, Dept Math & Sci Comp, Gorakhpur 273010, Uttar Pradesh, India.
   [Rana, Saurabh] Bennett Univ, Dept Math SCSET, Greater Noida 201310, Uttar Pradesh, India.
   [Chhikara, Deepak] Chandigarh Univ, Dept Math, Mohali 140413, India.
C3 Madan Mohan Malaviya University of Technology; Chandigarh University
RP Chandra, H (corresponding author), Madan Mohan Malaviya Univ Technol, Dept Math & Sci Comp, Gorakhpur 273010, Uttar Pradesh, India.; Rana, S (corresponding author), Bennett Univ, Dept Math SCSET, Greater Noida 201310, Uttar Pradesh, India.
EM hcmsc@mmmut.ac.in; saurabhranapsm@gmail.com
RI Chandra, Harish/IUO-7178-2023
OI Chandra, Harish/0000-0001-5232-6043
CR [Anonymous], 2016, P ACM IOT PRIV TRUST
   Chen J. N., 2021, J. Netw. Intell, V6, P1
   Cheng HJ, 2022, IEEE INTERNET THINGS, V9, P7904, DOI 10.1109/JIOT.2021.3114438
   Chhikara D, 2022, J SYST ARCHITECT, V131, DOI 10.1016/j.sysarc.2022.102714
   Dharminder D, 2023, MULTIMED TOOLS APPL, V82, P26937, DOI 10.1007/s11042-023-14836-w
   Dorri Ali, 2017, 2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI), P173, DOI 10.1145/3054977.3055003
   Dorri A, 2019, J PARALLEL DISTR COM, V134, P180, DOI 10.1016/j.jpdc.2019.08.005
   Dwivedi SK, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102554
   Egala BS, 2021, IEEE INTERNET THINGS, V8, P11717, DOI 10.1109/JIOT.2021.3058946
   Florea BC, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12103984
   Goswami A, 2023, TELECOMMUN SYST, V83, P241, DOI 10.1007/s11235-023-01016-2
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Gupta Sarthak, 2020, Advances in Data and Information Sciences. Proceedings of ICDIS 2019. Lecture Notes in Networks and Systems (LNNS 94), P47, DOI 10.1007/978-981-15-0694-9_6
   Hammi MT, 2018, COMPUT SECUR, V78, P126, DOI 10.1016/j.cose.2018.06.004
   Huh S, 2017, INT CONF ADV COMMUN, P464, DOI 10.23919/ICACT.2017.7890132
   Irshad A, 2020, IEEE T IND APPL, V56, P4425, DOI 10.1109/TIA.2020.2966160
   Jia XY, 2020, IEEE SYST J, V14, P560, DOI 10.1109/JSYST.2019.2896064
   Jiang YM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092042
   Kumar S, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0268-2
   Lee JY, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23115173
   Li CT, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0260-0
   Li CT, 2013, NONLINEAR DYNAM, V74, P1133, DOI 10.1007/s11071-013-1029-y
   Lin C, 2018, J NETW COMPUT APPL, V116, P42, DOI 10.1016/j.jnca.2018.05.005
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Nikravan M, 2020, WIRELESS PERS COMMUN, V111, P463, DOI 10.1007/s11277-019-06869-y
   Ouaddah A, 2016, SECUR COMMUN NETW, V9, P5943, DOI 10.1002/sec.1748
   Puthal D, 2019, I SYMP CONSUM ELECTR, DOI 10.1109/ICCE.2019.8662009
   Qu C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092784
   Rajasekaran AS, 2022, DRONES-BASEL, V6, DOI 10.3390/drones6010014
   Rana S, 2021, MULTIMED TOOLS APPL, V80, P25255, DOI 10.1007/s11042-021-10813-3
   Rathee G, 2021, J AMB INTEL HUM COMP, V12, P533, DOI 10.1007/s12652-020-02017-8
   Satamraju KP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20051389
   Sharma PK, 2020, IEEE NETWORK, V34, P263, DOI 10.1109/MNET.001.1900526
   Yu GS, 2020, IEEE T ENG MANAGE, V67, P1213, DOI 10.1109/TEM.2020.2966643
NR 34
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17607-9
EA NOV 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900012
DA 2024-07-18
ER

PT J
AU Ozdemir, C
   Dogan, Y
   Kaya, Y
AF Ozdemir, Cuneyt
   Dogan, Yahya
   Kaya, Yilmaz
TI A new local pooling approach for convolutional neural network: local
   binary pattern
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pooling methods; Convolutional neural network; Local binary pattern
AB The pooling layer used in CNN models aims to reduce the resolution of image/feature maps while retaining their distinctive information, reducing computation time and enabling deeper models. Max and average pooling methods are frequently used in CNN models due to their computational efficiency; however, these methods discard the position information of the pixels. In this study, we proposed an LBP-based pooling method that generates a neighborhood-based output for any pixel, reflecting the correlation between pixels in the local area. Our proposed method reduces information loss since it considers the neighborhood and size of the pixels in the pooling region. Experimental studies were performed on four public datasets to assess the effectiveness of the LBP pooling method. In experimental studies, a toy CNN model and various transfer learning models were utilized in conducting test operations. The proposed method provided improvements of 1.56% for Fashion MNIST, 0.22% for MNIST, 3.95% for CIFAR10, and 5% for CIFAR100 dataset using the toy model. In the experimental studies conducted using the transfer learning model, performance improvements of 6.99(-/+)(0.74) and 8.3(-/+)(0.1) were achieved for CIFAR10 and CIFAR100, respectively. We observed that the proposed method outperforms the commonly used pooling layers in CNN models. Code for this paper can be publicly accessed at: https://github.com/cuneytozdemir/lbppooling
C1 [Ozdemir, Cuneyt; Dogan, Yahya] Siirt Univ, Comp Engn Dept, TR-56100 Siirt, Turkiye.
   [Kaya, Yilmaz] Batman Univ, Comp Engn Dept, TR-72000 Batman, Turkiye.
C3 Siirt University; Batman University
RP Ozdemir, C (corresponding author), Siirt Univ, Comp Engn Dept, TR-56100 Siirt, Turkiye.
EM cozdemir@siirt.edu.tr; yahyadogan@siirt.edu.tr;
   yilmaz.kaya@batman.edu.tr
RI Ozdemir, Cuneyt/HTT-1812-2023; dogan, yahya/AAR-3259-2020
OI dogan, yahya/0000-0003-1529-6118; OZDEMIR, Cuneyt/0000-0002-9252-5888
CR Abdel-Salam R, 2022, NEURAL COMPUT APPL, V34, P6085, DOI 10.1007/s00521-021-06762-5
   Akhtar N, 2020, NEURAL COMPUT APPL, V32, P879, DOI 10.1007/s00521-019-04296-5
   [Anonymous], 2011, International Journal of Computer Applications
   Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555
   Cui Y, 2017, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR.2017.325
   Fan XL, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2022.102150
   Fei J, 2018, P 10 INT C INT MULT, P1
   Fradi M, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103123
   Güner A, 2019, MEASUREMENT, V145, P214, DOI 10.1016/j.measurement.2019.05.061
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Kou QQ, 2019, OPTIK, V193, DOI 10.1016/j.ijleo.2019.162999
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kumar A, 2018, Arxiv, DOI [arXiv:1804.02702, 10.48550/arXiv.1804.02702]
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LECUN Y, 1989, CONNECTIONISM IN PERSPECTIVE, P143
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee CY, 2016, JMLR WORKSH CONF PRO, V51, P464
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Mercioni MA, 2020, 2020 15TH INTERNATIONAL CONFERENCE ON DEVELOPMENT AND APPLICATION SYSTEMS (DAS), P141, DOI [10.1109/das49615.2020.9108942, 10.1109/DAS49615.2020.9108942]
   Patel H, 2022, MULTIMED TOOLS APPL, V81, P695, DOI 10.1007/s11042-021-11422-w
   Rampun A, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103842
   Rippel O, 2015, ADV NEUR IN, V28
   Saeedan F, 2018, PROC CVPR IEEE, P9108, DOI 10.1109/CVPR.2018.00949
   Sainath TN, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P315, DOI 10.1109/ASRU.2013.6707749
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Shah Ashita, 2022, Soft Computing and Signal Processing: Proceedings of 3rd ICSCSP 2020. Advances in Intelligent Systems and Computing, P553, DOI 10.1007/978-981-16-1249-7_52
   Shahriari A, 2017, Arxiv, DOI [arXiv:1710.07435, 10.48550/arXiv.1710.07435]
   Shang RH, 2022, APPL SOFT COMPUT, V123, DOI 10.1016/j.asoc.2022.108922
   Sharma S, 2019, FOUND COMPUT DECIS S, V44, P303, DOI 10.2478/fcds-2019-0016
   Shu X, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116392
   Song ZH, 2018, NEURAL NETWORKS, V105, P340, DOI 10.1016/j.neunet.2018.05.015
   Sun ML, 2017, NEUROCOMPUTING, V224, P96, DOI 10.1016/j.neucom.2016.10.049
   Tekin R, 2020, MULTIMED TOOLS APPL, V79, P32541, DOI 10.1007/s11042-020-09698-5
   Tong ZQ, 2016, LECT NOTES COMPUT SC, V9948, P454, DOI 10.1007/978-3-319-46672-9_51
   Wang F, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717748899
   Wang ZL, 2016, ADV INTEL SYS RES, V133, P203
   Williams T, 2018, INT C LEARN REPR
   Wu HB, 2015, LECT NOTES COMPUT SC, V9489, P46, DOI 10.1007/978-3-319-26532-2_6
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Yin HG, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.106983
   Yu DJ, 2014, LECT NOTES ARTIF INT, V8818, P364, DOI 10.1007/978-3-319-11740-9_34
NR 42
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17540-x
EA NOV 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700002
DA 2024-07-18
ER

PT J
AU Tank, M
   Thakkar, P
AF Tank, Meenaxi
   Thakkar, Priyank
TI Abstractive text summarization using adversarial learning and deep
   neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Abstractive text summarization; Deep neural networks; Generative
   adversarial networks; Adversarial learning; Natural language processing
AB A long-term objective of artificial intelligence is to design an abstractive text summarization (ATS) system that can produce condensed, adequate, and realistic summaries for the source documents. Deep learning approaches have contributed significantly to recent advancements in ATS, taking the state-of-the-art to new heights. Despite the considerable success of earlier approaches, producing high-quality and more human-like abstractive summaries continues to be a challenging task in reality. In this paper, we present an adversarial framework for abstractive text summarization, in which a generative model G and a proposed deep discriminative model D are trained in an adversarial manner. The goal of the generator is to generate summaries that are hard to differentiate from real summaries, whereas the discriminator's role is to estimate the probability that a summary came from the training data rather than the generator to direct the generative model's training. Experimental results on a benchmark CNN/Daily Mail dataset demonstrate that the proposed model achieves Rouge-1 and Rouge-L scores of 41.58 and 38.96 respectively which are better than the ones reported by various other methods (e.g. the base paper [1] achieved Rouge-1 and Rouge-L score of 39.92 and 36.71, while one of the recent works ACGT [2] achieved Rouge-1 score of 40.49 and Rouge-L score of 37.41). The manuscript's unique characteristic is qualitative evaluation, which, along with quantitative evaluation, shows that the proposed model is superior.
C1 [Tank, Meenaxi; Thakkar, Priyank] Inst Technol Nirma Univ, Dept Comp Sci, Sarkhej Gandhinagar Highway, Ahmadabad 382481, Gujarat, India.
C3 Nirma University
RP Thakkar, P (corresponding author), Inst Technol Nirma Univ, Dept Comp Sci, Sarkhej Gandhinagar Highway, Ahmadabad 382481, Gujarat, India.
EM 19ftphde33@nirmauni.ac.in; priyank.thakkar@nirmauni.ac.in
OI Thakkar, priyank/0000-0001-8241-0617
CR Ahmed U, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107903
   [Anonymous], 2015, BRIT MACH VIS C
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Cao Z., 2018, Retrieve, rerank and rewrite: Soft template based neural summarization
   Cao ZQ, 2018, AAAI CONF ARTIF INTE, P4784
   Celikyilmaz A, 2018, Arxiv, DOI arXiv:1803.10357
   Chen YC, 2018, Arxiv, DOI arXiv:1805.11080
   Chopra Sumit, 2016, P 2016 C N AM CHAPT, P93, DOI DOI 10.18653/V1/N16-1012
   Chu E, 2019, PR MACH LEARN RES, V97
   Conneau A, 2017, 15TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (EACL 2017), VOL 1: LONG PAPERS, P1107
   Denton E, 2015, Arxiv, DOI arXiv:1506.05751
   Duan ZL, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122010378
   Farahani M, 2021, 2021 26TH INTERNATIONAL COMPUTER CONFERENCE, COMPUTER SOCIETY OF IRAN (CSICC), DOI 10.1109/CSICC52343.2021.9420563
   Gehring J, 2017, PR MACH LEARN RES, V70
   Gehrmann S, 2018, Arxiv, DOI arXiv:1808.10792
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Guo ZW, 2022, IEEE T NETW SCI ENG, V9, P1067, DOI 10.1109/TNSE.2021.3049262
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang YC, 2018, Arxiv, DOI arXiv:1809.04585
   Kalchbrenner N, 2017, Arxiv, DOI [arXiv:1610.10099, DOI 10.48550/ARXIV.1610.10099]
   Klein G, 2017, Arxiv, DOI arXiv:1701.02810
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li ZX, 2020, IEEE ACCESS, V8, P11279, DOI 10.1109/ACCESS.2020.2965575
   Lin JY, 2018, Arxiv, DOI arXiv:1805.03989
   Liu L, 2018, Proceedings of the AAAI Conference on Artificial Intelligence, V32
   Luong MT, 2015, Arxiv, DOI arXiv:1508.04025
   Rush AM, 2015, Arxiv, DOI [arXiv:1509.00685, 10.18653/v1/d15-1044, DOI 10.18653/V1/D15-1044]
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Nallapati R, 2016, Arxiv, DOI [arXiv:1602.06023, DOI 10.48550/ARXIV.1602.06023]
   Pasunuru R, 2018, Arxiv, DOI arXiv:1804.06451
   Pasunuru R, 2021, AAAI CONF ARTIF INTE, V35, P13666
   Paulus R, 2017, Arxiv, DOI [arXiv:1705.04304, 10.48550/arXiv.1705.04304, DOI 10.3389/FPSYG.2017.01779]
   Bowman SR, 2016, Arxiv, DOI [arXiv:1511.06349, 10.48550/ARXIV.1511.06349, DOI 10.48550/ARXIV.1511.06349]
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Rothe S, 2020, T ASSOC COMPUT LING, V8, P264, DOI [10.1162/tacl_a_.00313, 10.1162/tacl_a_00313]
   See Abigail, 2017, GET POINT SUMMARIZAT
   Shao YA, 2023, IEEE T NEUR NET LEAR, V34, P2133, DOI 10.1109/TNNLS.2021.3105937
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh RK, 2021, NEURAL COMPUT APPL, V33, P3251, DOI 10.1007/s00521-020-05188-9
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Vallathan G, 2021, J SUPERCOMPUT, V77, P3242, DOI 10.1007/s11227-020-03387-8
   Wu YH, 2016, Arxiv, DOI [arXiv:1609.08144, DOI 10.48550/ARXIV.1609.08144]
   Xu H, 2018, PROC INT C TOOLS ART, P242, DOI 10.1109/ICTAI.2018.00045
   Xu WR, 2020, EURASIP J ADV SIG PR, V2020, DOI 10.1186/s13634-020-00674-7
   Yang M, 2020, IEEE Transactions on Neural Networks and Learning Systems
   Yang M, 2019, AAAI CONF ARTIF INTE, P7362
   You Jingyi, 2021, P INT C REC ADV NAT, P1586
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X, 2015, ADV NEUR IN, V28
   Zhao Z, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3455, DOI 10.1145/3308558.3313619
NR 56
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 8
PY 2023
DI 10.1007/s11042-023-17478-0
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X8TR3
UT WOS:001101114600012
DA 2024-07-18
ER

PT J
AU Mohammed, AG
   El-Khamy, SE
AF Mohammed, Amira G.
   El-Khamy, Said E.
TI Innovative chaotic dragon fractal (ChDrFr) shapes for efficient
   encryption applications: a new highly secure image encryption algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Dragon fractals; Chaotic maps; Image encryption; Performance analysis
ID TRANSFORMATION; SCHEME
AB In this paper, the generation of new dragon fractal shapes with chaotic iteration parameters is introduced as the main component of a new efficient approach for different cryptographic applications. This process involves applying a chaotic map, which is considered the initiator pattern, to generate different chaotic dragon fractal (ChDrFr) shapes in lieu of lines (which are classically used to generate dragon fractals). This is the new concept of this paper. The used chaotic maps are sensitive to their initial conditions and are characterized by randomness; hence, the resulting scheme is highly secure. As the resulting ChDrFr shapes have sparse structures, the spaces are packed with random values generated from another 5D hyper chaotic map. For encryption applications based on the substitution approach, one of the five generated ChFrDr shapes can be used to construct a chaotic fractal (ChFr) S-Box, while the other four ChDrFr shapes can be used for diffusion purposes. As an application to these new ChDrFr shapes and the ChFr S-Box, we introduce in this paper a new highly secure image encryption algorithm. A Henon chaotic map is used as the initiator of the ChDrFr shapes. The integer wavelet transform (IWT) is used to generate an approximation and three detail sub-bands for the original image. As the approximation sub-band contains a considerable amount of information about the original image, the above-described ChFr S-Box is used as a replacement for each pixel's value in this sub-band. Then, the resultant substituted image is diffused with one of the generated ChFrDr shapes. The other three ChDrFr shapes are XORed with the details sub-images. Numerical simulation is applied to ensure the efficacy of encrypted images against different attacks. In particular, the correlation coefficient between the initial and the generated images is shown to be nearly zero. Moreover, tests reveal that the information entropy of the encrypted images and UACI were close to their optimum values. The properties of the newly proposed ChDrFr-based encryption algorithm are compared to the ones obtained by other encryption algorithms, and the results prove the superiority of this newly proposed algorithm to other types of encryption methods.
C1 [Mohammed, Amira G.] Alexandria Higher Inst Engn & Technol AIET, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
   [El-Khamy, Said E.] Alexandria Univ, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
C3 Egyptian Knowledge Bank (EKB); Alexandria University
RP Mohammed, AG (corresponding author), Alexandria Higher Inst Engn & Technol AIET, Dept Elect & Elect Commun Engn, Alexandria, Egypt.
EM eng_amira90@yahoo.com; said.elkhamy@alexu.edu.eg
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Agarwal S., 2019, Int J Comput Netw Inf Secur, V11, P1
   Agarwal S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4010017
   Aouissaoui I, 2021, IET IMAGE PROCESS, V15, P2770, DOI 10.1049/ipr2.12261
   Ayubi P, 2020, J INF SECUR APPL, V52, DOI 10.1016/j.jisa.2020.102472
   Barani MJ, 2020, J INF SECUR APPL, V53, DOI 10.1016/j.jisa.2020.102509
   Bhowmik A, 2020, Arxiv, DOI arXiv:2008.12645
   El-Khamy SE, 2021, MULTIMED TOOLS APPL, V80, P23319, DOI 10.1007/s11042-021-10527-6
   Firdous A, 2021, IEEE ACCESS, V9, P11675, DOI 10.1109/ACCESS.2021.3049791
   Firdous A, 2019, MULTIMED TOOLS APPL, V78, P24809, DOI 10.1007/s11042-019-7623-3
   Gao WJ, 2019, OPTIK, V185, P917, DOI 10.1016/j.ijleo.2019.02.007
   Gong LH, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6627005
   Hasanzadeh E, 2020, MULTIMED TOOLS APPL, V79, P7279, DOI 10.1007/s11042-019-08342-1
   He PC, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6679288
   Hosny KM, 2022, MULTIMED TOOLS APPL, V81, P505, DOI 10.1007/s11042-021-11384-z
   Iqbal N, 2022, MULTIMED TOOLS APPL, V81, P8107, DOI 10.1007/s11042-022-11912-5
   Iqbal N, 2021, IEEE ACCESS, V9, P118253, DOI 10.1109/ACCESS.2021.3106028
   Jithin KC, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102428
   Karmakar J, 2021, DIGIT SIGNAL PROCESS, V117, DOI 10.1016/j.dsp.2021.103143
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Kumar V, 2021, MULTIMED TOOLS APPL, V80, P3749, DOI 10.1007/s11042-020-09854-x
   Lai Q, 2022, APPL INTELL, V52, P11448, DOI 10.1007/s10489-021-03071-1
   Lambic D, 2020, NONLINEAR DYNAM, V100, P699, DOI 10.1007/s11071-020-05503-y
   Lee HH, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105555
   Li H., 2021, J Inf Secur Appl, V61
   Li T, 2020, IEEE ACCESS, V8, P13792, DOI 10.1109/ACCESS.2020.2966264
   Lin RG, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/5586959
   Louzzani N, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111315
   Man ZL, 2021, CHAOS SOLITON FRACT, V152, DOI 10.1016/j.chaos.2021.111318
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Mohamed AG, 2021, IEEE ACCESS, V9, P14284, DOI 10.1109/ACCESS.2021.3052161
   Muthu JS, 2021, OPTIK, V242, DOI 10.1016/j.ijleo.2021.167300
   Ning X, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109216
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Kari AP, 2021, MULTIMED TOOLS APPL, V80, P2753, DOI 10.1007/s11042-020-09648-1
   Qayyum A, 2020, IEEE ACCESS, V8, P140876, DOI 10.1109/ACCESS.2020.3012912
   Ramakrishnan B, 2022, MULTIMED TOOLS APPL, V81, P23819, DOI 10.1007/s11042-022-12400-6
   Rathore V, 2021, MULTIMED TOOLS APPL, V80, P22275, DOI 10.1007/s11042-021-10719-0
   Sha YW, 2021, IEEE ACCESS, V9, P96321, DOI 10.1109/ACCESS.2021.3094563
   Shah DW, 2020, MULTIMEDIA SYST, V26, P235, DOI 10.1007/s00530-019-00640-w
   Sun JL, 2021, IEEE ACCESS, V9, P59313, DOI 10.1109/ACCESS.2021.3070350
   Sun JY, 2023, NONLINEAR DYNAM, V111, P3851, DOI 10.1007/s11071-022-07993-4
   Wang CS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3170493
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang XY, 2022, NONLINEAR DYNAM, V107, P1277, DOI 10.1007/s11071-021-07017-7
   Wang XY, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106837
   Yan DW, 2021, CHAOS SOLITON FRACT, V146, DOI 10.1016/j.chaos.2021.110773
   Yang Y, 2021, OPT LASER TECHNOL, V133, DOI 10.1016/j.optlastec.2020.106553
   Yu F, 2021, EUR PHYS J-SPEC TOP, V230, P1763, DOI 10.1140/epjs/s11734-021-00132-x
   Zeng J, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6675565
   Zhang H., 2022, Comput Intell Neurosci, V2022, P1
   Zhang JW, 2023, PHYSICA A, V610, DOI 10.1016/j.physa.2022.128397
   Zhang LP, 2022, IEEE SENS J, V22, P785, DOI 10.1109/JSEN.2021.3130951
   Zhang SJ, 2021, MATH COMPUT SIMULAT, V190, P723, DOI 10.1016/j.matcom.2021.06.012
   Zhang XQ, 2022, MULTIMED TOOLS APPL, V81, P20021, DOI 10.1007/s11042-022-12554-3
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhang Y, 2021, INFORM SCIENCES, V547, P307, DOI 10.1016/j.ins.2020.07.058
   Zhao HX, 2021, OPTIK, V230, DOI 10.1016/j.ijleo.2021.166307
   Zhao Y., 2019, Chaos Solitons Fractals, V4, DOI 10.1016/j.csfx.2020.100023
   Zhou SH, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107359
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 60
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17183-y
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500007
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, S
   Liu, CS
AF Li, Shuang
   Liu, Chunsheng
TI Transfer and supplement AdaBoost for extracting region proposals of CNN
   in transfer-learning application
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Transfer learning; Supplement learning; AdaBoost; Traffic sign detection
   (TSD); Region proposals extraction; CNN
ID TRAFFIC SIGN DETECTION; PEDESTRIAN DETECTION; FACE DETECTION; FRAMEWORK;
   CASCADE; NETWORK; OBJECTS
AB As a common way to extract region proposals for CNN based detection, Region Proposal Network often requires very large amount of training samples and relative large computation requirements, which makes it hard to transfer to different real-time applications. To overcome these difficulties, a transfer and supplement AdaBoost learning method (TS-AdaBoost) is proposed to retrain the off-line trained AdaBoost detector to adapt to the new data with small amount of samples, which can extract region proposals when combining with CNN. The TS-AdaBoost includes a transfer learning process and a supplement learning process. The transfer learning process is designed to replace the features in the off-line trained detector with some new features, resulting a transfer learned new detector with better adaptive capacity to the new data. The supplement learning process is designed to lengthen the transfer learned detector achieving higher detection rates and lower false alarm rates. This method allows users to utilize the new labeled data to retrain the off-line trained detector, and do not need to discard all old labeled data and the old trained detector. Two transfer learning problems for traffic sign detection (TSD) are taken to show our method. Experiments show that the proposed TS-AdaBoost learning method can adapt to the new data from different application scenes independently or combined with CNN-based methods.
C1 [Li, Shuang] Qilu Univ Technol, Shandong Acad Sci, Sch Informat & Automat Engn, Jinan 250353, Shandong, Peoples R China.
   [Liu, Chunsheng] Shandong Univ, Sch Control Sci & Engn, Jinan 250061, Shandong, Peoples R China.
C3 Qilu University of Technology; Shandong University
RP Li, S (corresponding author), Qilu Univ Technol, Shandong Acad Sci, Sch Informat & Automat Engn, Jinan 250353, Shandong, Peoples R China.
EM lishuang@qlu.edu.cn; liuchunsheng@sdu.edu.cn
FU National Nature Science Foundation of China [62203242, 62176138,
   62176136, U22A2058]; Peiyou Fund of Qilu University of Technology
   (Shandong Academy of Sciences) [2023PY006]; Shandong Outstanding Youth
   Funding [ZR2023YQ054]
FX This work was supported by the National Nature Science Foundation of
   China (62203242, 62176138, 62176136, U22A2058), and the Peiyou Fund of
   Qilu University of Technology (Shandong Academy of Sciences)
   (2023PY006), and the Shandong Outstanding Youth Funding (ZR2023YQ054).
CR Alfarizi M., 2023, An extreme gradient boosting aided fault diagnosis approach: A case study of fuse test bench, DOI [10.1109/TAI.2022.3165137, DOI 10.1109/TAI.2022.3165137]
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Berkaya SK, 2016, EXPERT SYST APPL, V48, P67, DOI 10.1016/j.eswa.2015.11.018
   Chen T, 2016, IEEE T VEH TECHNOL, V65, P4006, DOI 10.1109/TVT.2015.2500275
   Chen YT, 2008, IEEE T IMAGE PROCESS, V17, P1452, DOI 10.1109/TIP.2008.926152
   Dai W, 2007, C MACH LEARN, P1
   Dai Wenyuan, 2007, P 24 INT C MACHINE L, P193
   Djenouri Y, 2022, PATTERN RECOGN LETT, V158, P42, DOI 10.1016/j.patrec.2022.04.012
   Djenouri Y, 2022, IEEE T INTELL TRANSP, V23, P25335, DOI 10.1109/TITS.2022.3165156
   Djenouri Y, 2021, IEEE T IND INFORM, V17, P2947, DOI 10.1109/TII.2020.3001493
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dong MQ, 2023, IEEE T SERV COMPUT, V16, P330, DOI 10.1109/TSC.2021.3133673
   Eaton E, 2009, INT CONF DAT MIN WOR, P422, DOI 10.1109/ICDMW.2009.97
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Guo L, 2012, EXPERT SYST APPL, V39, P4274, DOI 10.1016/j.eswa.2011.09.106
   Han JM, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3062048
   Hu QC, 2016, IEEE T INTELL TRANSP, V17, P1002, DOI 10.1109/TITS.2015.2496795
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Javed O, 2005, PROC CVPR IEEE, P696
   Jocher Glenn, 2020, Zenodo
   Khalyasmaa AI, 2021, IEEE T POWER DELIVER, V36, P2154, DOI 10.1109/TPWRD.2020.3021702
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Larsson F, 2011, LECT NOTES COMPUT SC, V6688, P238, DOI 10.1007/978-3-642-21227-7_23
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li QM, 2017, IEEE T INTELL TRANSP, V18, P1549, DOI 10.1109/TITS.2016.2612705
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   Li WT, 2022, PROC CVPR IEEE, P1819, DOI 10.1109/CVPR52688.2022.00187
   Li YP, 2022, IEEE SIGNAL PROC LET, V29, P1367, DOI 10.1109/LSP.2022.3180680
   Liang ZW, 2020, NEURAL COMPUT APPL, V32, P6533, DOI 10.1007/s00521-019-04086-z
   Liu CS, 2022, IEEE T INTELL TRANSP, V23, P19246, DOI 10.1109/TITS.2022.3165175
   Liu CS, 2022, IEEE T INTELL TRANSP, V23, P12518, DOI 10.1109/TITS.2021.3115123
   Liu CS, 2019, IEEE T INTELL TRANSP, V20, P2122, DOI 10.1109/TITS.2018.2859348
   Liu CS, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072386
   Liu CS, 2016, IEEE T INTELL TRANSP, V17, P79, DOI 10.1109/TITS.2015.2459594
   Liu CS, 2014, IEEE T INTELL TRANSP, V15, P2394, DOI 10.1109/TITS.2014.2314711
   Mathias Markus, 2013, The 2013 International Joint Conference on Neural Networks (IJCNN), DOI 10.1109/IJCNN.2013.6707049
   Mogelmose A, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2433019
   Nam W., 2014, P 27 INT C NEURAL IN, V27
   Oza Nikunj C, 2001, INT WORKSH ART INT S, P229
   Paisitkriangkcrai S, 2008, IEEE T CIRC SYST VID, V18, P1140, DOI 10.1109/TCSVT.2008.928213
   Qian RQ, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION (ICNC), P791, DOI 10.1109/ICNC.2015.7378092
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saadna Y, 2019, NEURAL COMPUT APPL, V31, P5005, DOI 10.1007/s00521-018-03994-w
   Seo H, 2020, IEEE ACCESS, V8, P64992, DOI 10.1109/ACCESS.2020.2985414
   Vezhnevets A., 2005, The Graphicon-2005
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang DX, 2022, IEEE T IND ELECTRON, V69, P11611, DOI 10.1109/TIE.2021.3120474
   Wang P, 2012, IEEE T NEUR NET LEAR, V23, P33, DOI 10.1109/TNNLS.2011.2178324
   Wu JMT, 2021, SOFTWARE PRACT EXPER, V51, P628, DOI 10.1002/spe.2915
   Wu YH, 2013, IEEE IJCNN
   Yamamoto F, 2022, IEEE ACCESS, V10, P43954, DOI 10.1109/ACCESS.2022.3169502
   Yang TT, 2018, COMPUT NETW, V136, P95, DOI 10.1016/j.comnet.2018.02.026
   Yang X, 2021, AAAI CONF ARTIF INTE, V35, P3163
   Yang Xue, 2021, ADV NEURAL INFORM PR, V34
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P1918, DOI 10.1109/TITS.2016.2614548
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhang ZW, 2012, IEEE SIGNAL PROC LET, V19, P131, DOI 10.1109/LSP.2011.2171949
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu YY, 2016, NEUROCOMPUTING, V214, P758, DOI 10.1016/j.neucom.2016.07.009
   Zou WB, 2021, IEEE T IMAGE PROCESS, V30, P4084, DOI 10.1109/TIP.2021.3069547
NR 63
TC 0
Z9 0
U1 8
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-16604-2
EA NOV 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900013
DA 2024-07-18
ER

PT J
AU Ye, Y
   Park, H
AF Ye, Yuning
   Park, Hanhoon
TI Focal segmentation for robust 6D object pose estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object pose estimation; Focal segmentation; Keypoint detection; Severe
   occlusion; Deep learning
ID ACCURATE; NETWORK
AB In the field of augmented reality, 6D pose estimation of rigid objects poses limitations and challenges. Most of the previous 6D pose estimation methods have trained deep neural networks to directly regress poses from input images or predict the 2D locations of 3D keypoints for pose estimation; thus, they are vulnerable to large occlusion. This study addresses the challenge of 6D pose estimation from a single RGB image under severe occlusion. A novel method is proposed that is based on PVNet but improves its performance. Similar to PVNet, our method regresses target object segments and pixel-wise direction vectors from an RGB image. Subsequently, the 2D locations of 3D keypoints are computed using the direction vectors of object pixels, and the 6D object pose is obtained using a PnP algorithm. However, accurate segmentation of object pixels is difficult, particularly under severe occlusion. To this end, a focal segmentation mechanism is proposed that ensures accurate complete segmentation of occluded objects. Extensive experiments on LINEMOD, LINEMOD-Occlusion datasets validate the effectiveness and superiority of our method. Our method improves the accuracy of PVNet by 1.09 and 5.14 on average in terms of the 2D reprojection error and ADD metric, respectively, without increasing the computational time.
C1 [Ye, Yuning; Park, Hanhoon] Pukyong Natl Univ, Grad Sch, Dept Artificial Intelligence Convergence, Pusan 48513, South Korea.
   [Park, Hanhoon] Pukyong Natl Univ, Div Elect & Commun Engn, Pusan 48513, South Korea.
C3 Pukyong National University; Pukyong National University
RP Park, H (corresponding author), Pukyong Natl Univ, Grad Sch, Dept Artificial Intelligence Convergence, Pusan 48513, South Korea.; Park, H (corresponding author), Pukyong Natl Univ, Div Elect & Commun Engn, Pusan 48513, South Korea.
EM yeyuning12@gmail.com; hanhoon.park@pknu.ac.kr
OI Park, Hanhoon/0000-0002-6968-4565
FU This work was supported by the National Research Foundation of Korea
   (NRF) Grant by the Korean Government through the MSIT under Grant
   2021R1F1A1045749. [2021R1F1A1045749]; National Research Foundation of
   Korea (NRF) Grant by the Korean Government through the MSIT
FX This work was supported by the National Research Foundation of Korea
   (NRF) Grant by the Korean Government through the MSIT under Grant
   2021R1F1A1045749.
CR Brachmann E, 2016, PROC CVPR IEEE, P3364, DOI 10.1109/CVPR.2016.366
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Do TT, 2018, Arxiv, DOI [arXiv:1802.10367, 10.48550/ARXIV.1802.10367, DOI 10.48550/ARXIV.1802.10367]
   Doumanoglou A, 2016, PROC CVPR IEEE, P3583, DOI 10.1109/CVPR.2016.390
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   github, about us
   Gu RS, 2019, 2019 2ND IEEE CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2019), P163, DOI 10.1109/MIPR.2019.00036
   Hachiuma R, 2016, 2016 IEEE 2ND WORKSHOP ON EVERYDAY VIRTUAL REALITY (WEVR), P32, DOI 10.1109/WEVR.2016.7859541
   Haugaard RL, 2022, PROC CVPR IEEE, P6739, DOI 10.1109/CVPR52688.2022.00663
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinterstoisser S, 2016, LECT NOTES COMPUT SC, V9907, P834, DOI 10.1007/978-3-319-46487-9_51
   Hinterstoisser S, 2012, IEEE T PATTERN ANAL, V34, P876, DOI 10.1109/TPAMI.2011.206
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kothari N, 2017, 2017 INDIAN CONTROL CONFERENCE (ICC), P424, DOI 10.1109/INDIANCC.2017.7846512
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Li XY, 2020, IEEE ROBOT AUTOM LET, V5, P1453, DOI 10.1109/LRA.2020.2967688
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lu YW, 2019, IEEE GLOB CONF SIG, DOI 10.1109/globalsip45357.2019.8969201
   Malyavej V., 2009, Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, V1, P395, DOI [10.1109/ECTICON.2009.5137033, DOI 10.1109/ECTICON.2009.5137033]
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Park K, 2019, IEEE I CONF COMP VIS, P7667, DOI 10.1109/ICCV.2019.00776
   Pavlakos G., 2017, P IEEE C COMPUTER VI, P2011, DOI DOI 10.1109/CVPR.2017.139
   Peng SD, 2022, IEEE T PATTERN ANAL, V44, P3212, DOI 10.1109/TPAMI.2020.3047388
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ruan XG, 2019, CHIN CONTR CONF, P8827, DOI [10.23919/ChiCC.2019.8870974, 10.23919/chicc.2019.8870974]
   Song C, 2020, PROC CVPR IEEE, P428, DOI 10.1109/CVPR42600.2020.00051
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang G, 2021, PROC CVPR IEEE, P16606, DOI 10.1109/CVPR46437.2021.01634
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiao ZH, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P678, DOI 10.1109/ICInfA.2017.8078992
   Zakharov S, 2019, IEEE I CONF COMP VIS, P1941, DOI 10.1109/ICCV.2019.00203
   Zhang S, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P237, DOI 10.1109/ISMAR-Adjunct.2019.00-39
   Zhao ZL, 2018, Arxiv, DOI arXiv:1812.01387
NR 39
TC 0
Z9 0
U1 9
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-16937-y
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300010
DA 2024-07-18
ER

PT J
AU Dixit, M
   Yadav, RN
AF Dixit, Monika
   Yadav, Ram Narayan
TI U-SRN: Convolutional Neural network for single image super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Single Image Super Resolution (SISR); Medical imaging; Hyper spectral
   imaging; Convolutional Neural Network (CNN); Perceptual loss
AB Single Image Super Resolution (SISR) aims to recover high-frequency details of an image from its low-resolution form. It is a highly challenging problem since low-resolution image is blur and contains noise. The application of SISR can be found in various fields, such as microscopic image analysis, medical imaging, security and surveillance imaging, biometric image identification, hyper spectral imaging and text image super-resolution. Convolutional Neural Networks (CNNs) are the most widely used technique for SISR. Most of the previous CNN-based SISR methods blindly increase the network depth to achieve good performance, leading to increased computational cost. They train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. U-SRN model is proposed for single-image super-resolution, consisting of a contracting path to capture context and a symmetric expanding path that enables precise localization. Per-pixel loss is replaced with perceptual loss, which gives visually pleasing results. Extensive experiments show that the U-SRN model performs excellently and can perform multi-scale tasks. The model is trained on the DIV2K dataset. It is a benchmark dataset in the field of super-resolution, which consists of 1,000 high-quality images. Set 5, Set 14, Urban 100, and BSD 100 are the benchmark super-resolution datasets used for testing. For the upscaling factor of 4, the average gains on PSNR, SSIM and IFC achieved by U-SRN using Urban 100 dataset are 0.24 dB, 0.0037 and 0.025 higher than the next best approach. The results indicate that U-SRN performs better as compared to other state-of-art methods in terms of PSNR, SSIM and IFC on all datasets. The other performance analysis criterion, such as PI (4.12), FSIM (0.971), and SRQC (0.954), indicate the superiority of the model. The network has limited number of parameters and performs fast execution.
C1 [Dixit, Monika; Yadav, Ram Narayan] Maulana Azad Natl Inst Technol, Dept Elect & Commun Engn, Bhopal, MP, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Dixit, M (corresponding author), Maulana Azad Natl Inst Technol, Dept Elect & Commun Engn, Bhopal, MP, India.
EM monikadixitec@gmail.com; rnyadav@gmail.com
RI Yadav, R N/B-1694-2017; Dixit, Monika/HSF-3006-2023
OI Yadav, R N/0000-0002-3635-5925; Dixit, Monika/0000-0002-1533-0323
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bisen D, 2022, MULTIMED TOOLS APPL, V81, P18011, DOI 10.1007/s11042-022-12775-6
   Chen YT, 2021, MULTIMED TOOLS APPL, V80, P30839, DOI 10.1007/s11042-020-09969-1
   Cheng Y., 2023, Multimed Tools Appl, V8, P1136
   Cheng YD, 2023, MULTIMED TOOLS APPL, V82, P22705, DOI 10.1007/s11042-023-14474-2
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Greeshma MS, 2020, MULTIMED TOOLS APPL, V79, P35125, DOI 10.1007/s11042-020-09352-0
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang JC, 2020, MULTIMED TOOLS APPL, V79, P29639, DOI 10.1007/s11042-020-09524-y
   Iqbal M, 2021, MULTIMED TOOLS APPL, V80, P10361, DOI 10.1007/s11042-020-09762-0
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2018, P COMP VIS PATT REC, P886
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lan R., 2020, IEEE Trans. on Cybernetics, V9, P4587
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Ma C, 2017, COMPUT VIS IMAGE UND, V158, P1, DOI 10.1016/j.cviu.2016.12.009
   Mao XJ, 2016, ADV NEUR IN, V29
   Mishra J, 2022, MULTIMED TOOLS APPL, V81, P18915, DOI 10.1007/s11042-022-12531-w
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Naga Srinivasu P, 2021, BIOINSPIRED NEUROCOM, V903, DOI [10.1007/978-981-15-5495-7_1, DOI 10.1007/978-981-15-5495-7_1]
   Peng YH, 2020, MULTIMED TOOLS APPL, V79, P9351, DOI 10.1007/s11042-019-7544-1
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Senalp FM, 2023, MULTIMED TOOLS APPL, V82, P18483, DOI 10.1007/s11042-022-14169-0
   Shen PY, 2021, MULTIMED TOOLS APPL, V80, P28087, DOI 10.1007/s11042-021-10888-y
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song ZY, 2021, MULTIMED TOOLS APPL, V80, P9765, DOI 10.1007/s11042-020-10152-9
   Srinivas G., 2018, Smart Comput Inform Smart Innov, Syst Technol, V78, P143, DOI [10.1007/978-981-10-5547-8_14, DOI 10.1007/978-981-10-5547-8_14]
   Srinivasu PN, 2022, MOB INF SYST, V2022, DOI 10.1155/2022/3169927
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Xia TE, 2023, MULTIMED TOOLS APPL, V82, P2839, DOI 10.1007/s11042-022-13395-w
   Yin J., 2023, Multimed Tools Appl, V12, P4165
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
NR 48
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17379-2
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700013
DA 2024-07-18
ER

PT J
AU Qin, XJ
   Mao, W
   Hu, ZT
   Zheng, HB
   Xu, XG
AF Qin, Xujia
   Mao, Wei
   Hu, Zhongtian
   Zheng, Hongbo
   Xu, Xiaogang
TI Procedural modeling and layout method for a generic ancient Chinese city
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Procedural modeling; L-System; Ancient Chinese city; Layout of the city;
   Ancient building
ID 'YINGZAO-FASHI'
AB This paper mainly proposes a city layout method based on the L-System method generated for an ancient Chinese cities. This method is improved by adding local constraints improvements, adding a symmetric factor, and introducing a distance constraint to guide the layout generation, so that the improved SE L-System can generate a symmetric urban layout and the degree of symmetry of the city can be globally controlled by the user. A building level control function is proposed to realize the mapping from building location to building level and then to specific building parameters. Based on the parameters, ancient building complexes with different appearances and layouts that conform to the layout rules of ancient Chinese cities can be generated. Buildings are generated based on the L-System, and trees are generated at arbitrary positions according to the probability density of generated trees determined by the building density. Based on the convex hull and intersection of rays, the city walls and watch tower of the ancient city are generated, and the procedural modeling generation of a complete ancient Chinese city is realized. The experimental results show that the square and symmetrical structure of the ancient city layout generated by SE L-System is closer to a real ancient Chinese city layout.
C1 [Qin, Xujia; Mao, Wei; Hu, Zhongtian; Zheng, Hongbo] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
   [Xu, Xiaogang] Zhejiang Gongshang Univ, Coll Informat & Comp Engn, Hangzhou 310018, Peoples R China.
   [Xu, Xiaogang] Inst Artificial Intelligence, Zhejiang Lab, Hangzhou 311121, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang Gongshang University;
   Zhejiang Laboratory
RP Zheng, HB (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Peoples R China.
EM zhb@zjut.edu.cn
FU This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61672462, 61702455) and the Natural
   Science Foundation of Zhejiang province, China (Grant No. LY20F020025).
   [61672462, 61702455]; National Natural Science Foundation of China
   [LY20F020025]; Natural Science Foundation of Zhejiang province, China
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61672462, 61702455) and the Natural
   Science Foundation of Zhejiang province, China (Grant No. LY20F020025).
CR Buyukdemircioglu M, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7090339
   Chen GN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360702
   Demir I, 2018, COMPUT GRAPH-UK, V74, P257, DOI 10.1016/j.cag.2018.05.013
   Edelsbrunner J, 2017, COMPUT GRAPH-UK, V64, P14, DOI 10.1016/j.cag.2017.01.004
   Gdawiec K, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12062923
   Gieseke L, 2021, COMPUT GRAPH FORUM, V40, P585, DOI 10.1111/cgf.142658
   Glahn Else., 1984, Chinese Traditional Architecture, P47
   Greuter S., 2003, P 1 INT C COMPUTER G, P87, DOI [DOI 10.1145/604487.604490, DOI 10.1145/604471.604490]
   Guo QH, 1998, ARCHIT HIST, V41, P1, DOI 10.2307/1568644
   Hu ZT, 2021, MULTIMED TOOLS APPL, V80, P5773, DOI 10.1007/s11042-020-09744-2
   Huang C, 2015, Revised Selected Papers, V13, P16, DOI [10.1007/978-3-319-53838-92, DOI 10.1007/978-3-319-53838-92]
   Jesus Diego., 2012, Proceedings of PCG 2012 - Workshop on Procedural Content Generation for Games, co-located with the Foundations of Digital Games, V2012, P1, DOI DOI 10.1145/2538528.2538533
   Kim H, 2018, MULTIMED TOOLS APPL, V77, P27387, DOI 10.1007/s11042-018-5926-4
   Kim S, 2020, VISUAL COMPUT, V36, P911, DOI 10.1007/s00371-019-01701-x
   Lechner T, 2003, 1 MIDW GRAPH C MAND, V4, P1
   Lechner T, 2006, ACM SIGGRAPH 2006 RE, DOI [10.1016/j.trpro.2017.05.194, DOI 10.1016/J.TRPRO.2017.05.194]
   Li ML, 2016, COMPUT GRAPH-UK, V54, P84, DOI 10.1016/j.cag.2015.07.004
   Li S, 2003, J SOC ARCHIT HIST, V62, P470
   Lipp M, 2011, COMPUT GRAPH FORUM, V30, P345, DOI 10.1111/j.1467-8659.2011.01865.x
   Liu J, 2018, INT J ARCHIT HERIT, V12, P280, DOI 10.1080/15583058.2017.1410253
   Martin I, 2019, COMPUT GRAPH-UK, V84, P93, DOI 10.1016/j.cag.2019.08.003
   Müller P, 2006, ACM T GRAPHIC, V25, P614, DOI 10.1145/1141911.1141931
   Nishida G, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925951
   Ouyang PC, 2014, IEEE COMPUT GRAPH, V34, P68, DOI 10.1109/MCG.2014.6
   Parish YIH, 2001, COMP GRAPH, P301, DOI 10.1145/383259.383292
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   Ren P, 2017, PRESENCE-VIRTUAL AUG, V26, P389, DOI 10.1162/PRES_a_00304
   Richards-Rissetto H, 2015, 2015 DIGITAL HERITAGE INTERNATIONAL CONGRESS, VOL 2: ANALYSIS & INTERPRETATION THEORY, METHODOLOGIES, PRESERVATION & STANDARDS DIGITAL HERITAGE PROJECTS & APPLICATIONS, P85, DOI 10.1109/DigitalHeritage.2015.7419458
   Schubiger-Banz S, 2014, IOP C SER EARTH ENV, V18, DOI 10.1088/1755-1315/18/1/012169
   Schwarz M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766956
   Sharma SA, 2016, J INDIAN SOC REMOTE, V44, P187, DOI 10.1007/s12524-015-0478-9
   Sun J., 2002, P ACM S VIRTUAL REAL, P33, DOI [DOI 10.1145/585740.585747, 10 . 1145 / 585740 . 585747]
   Wu FZ, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601162
NR 33
TC 0
Z9 0
U1 5
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-16942-1
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700016
DA 2024-07-18
ER

PT J
AU Sachdeva, S
   Singh, H
   Bhatia, S
   Goswami, P
AF Sachdeva, Shelly
   Singh, Hitendra
   Bhatia, Shailee
   Goswami, Puneet
TI An integrated framework for predicting air quality index using pollutant
   concentration and meteorological data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Pollutants; Prediction; Machine Learning; Air Quality Index; Artificial
   Neural Networks
ID MODEL
AB Everyone wishes to lead a healthy life, but the tremendous increase in air pollution affects our lives. The current tools can give updates on the Air Quality Index (AQI), but we can get further insights into air pollution by applying knowledge discovery and analytics techniques. Our research proposes a novel and integrated framework to predict AQI using pollutant concentration data and meteorological data. The framework comprises four modules for insights into air pollution. The first module (AQIfp) computes air quality by forecasting pollutant concentrations of particulate matter and harmful gases. The second module (AQIp) predicts air quality using pollutant data and historical air quality index data. The third module (AQIm) predicts AQI using meteorological features (temperature, surface pressure, cloud cover, humidity, wind speed, wind direction, and precipitation) and extra features (month, year, time, day of month, day of week). The fourth module (AQIc) computes AQI by combining the results of AQIp and AQIm. Various methods are used for forecasting pollutants and predicting AQI, viz artificial neural networks (ANN), random forest regression, XGradientboost, long-short term memory, vector autoregression, auto-regressive integrated moving average (ARIMA), decision tree regression, support vector regression, multiple linear regression, and K-nearest neighbour. The results show that different methods are best suited for various pollutants. However, ARIMA and ANN successfully predict almost all the pollutants. The results are promising, with Mean Absolute Error to predict AQI being 7.09 only when combining AQIp and AQIm. AQI can be predicted best with both pollutant and meteorological data. Since the modules are independent and if one data is missing, any module can be utilized to obtain an approximation of the AQI with minimal error. The framework will assist in providing decisions at the individual and administration levels to mitigate air pollution.
C1 [Sachdeva, Shelly; Singh, Hitendra] Natl Inst Technol, Dept Comp Sci & Engn, Plot FA7,ZoneP1,GT Karnal Rd, Delhi 110036, India.
   [Bhatia, Shailee; Goswami, Puneet] SRM Univ, Dept Comp Sci & Engn, 39 Rajiv Gandhi Educ City, Sonipat 131029, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Delhi; SRM University Haryana
RP Sachdeva, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Plot FA7,ZoneP1,GT Karnal Rd, Delhi 110036, India.
EM shellysachdeva@nitdelhi.ac.in; 171210028@nitdelhi.ac.in;
   shaileebhatia@gmail.com; goswamipuneet@srmuniversity.ac.in
RI Sachdeva, Shelly/AAB-8719-2022
OI Sachdeva, Shelly/0000-0003-4088-1271; khare, Mayank
   Deep/0000-0002-0726-2711
FU The authors thank CPCB, New Delhi, for providing us with the website to
   get the air quality data.; CPCB, New Delhi
FX The authors thank CPCB, New Delhi, for providing us with the website to
   get the air quality data.
CR Agrawal R, 2020, Big data, IoT, and machine learning: Tools and applications
   AirVisual, 2020, Airvisual Earth-3D Real-Time Air Pollution Map
   Ameer S, 2019, IEEE ACCESS, V7, P128325, DOI 10.1109/ACCESS.2019.2925082
   [Anonymous], World's Air Pollution: Real-Time Air Quality Index
   Aqi.in, 2020, AQI India: Real-Time Air Quality Index | Air Pollution Level
   Beelen R, 2014, LANCET, V383, P785, DOI 10.1016/S0140-6736(13)62158-3
   Bhalgat P., 2019, Int J Comput Appl Technol Res, V8, P367, DOI DOI 10.7753/IJCATR0809.1006
   Bhatia S, 2022, J STAT MANAG SYST, V25, P1553, DOI 10.1080/09720510.2022.2130568
   Breezometer.com, 2020, Live Air Quality & Forecast Pollution-Breezometer
   Castelli M, 2020, COMPLEXITY, V2020, DOI 10.1155/2020/8049504
   CCR, 2020, Central Control Room for Air Quality Management, National Air Quality Index
   Chang YS, 2020, ATMOS POLLUT RES, V11, P1451, DOI 10.1016/j.apr.2020.05.015
   Chen J., 2023, Appl. Intell., P1
   Copernicus Climate Change Service Information, 2020, ERA5: Fifth generation of ECMWF atmospheric reanalyses of the global climate
   Cpcb, 2020, Central Pollution Control Board. Comprehensive Environmental Pollution Abate-ment Action Plan Byrnihat Industrial Cluster-Assam
   Docs.python.org, 2020, The Python Language Reference-Python 3.8.6Rc1 Documentation
   Dutta J, 2021, MULTIMED TOOLS APPL, V80, P19989, DOI 10.1007/s11042-021-10666-w
   EVC, 2019, Air Quality & How to Measure It: The Air Quality Index
   Ganesh S. Sankar, 2017, 2017 International Conference on Trends in Electronics and Informatics (ICEI). Proceedings, P248, DOI 10.1109/ICOEI.2017.8300926
   Gispub.epa.gov, 2020, Airnow Interactive Map
   Google.com, 2020, Air Quality
   Gu K, 2018, IEEE T IND INFORM, V14, P3946, DOI 10.1109/TII.2018.2793950
   Hajek P, 2015, AEROSOL AIR QUAL RES, V15, P544, DOI 10.4209/aaqr.2014.08.0154
   He HN, 2020, IOP C SER EARTH ENV, V446, DOI 10.1088/1755-1315/446/3/032113
   Huang Y, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14094889
   Kotsiantis SB, 2006, PROC WRLD ACAD SCI E, V12, P278
   Kumar A, 2011, SCI TOTAL ENVIRON, V409, P5517, DOI 10.1016/j.scitotenv.2011.08.069
   Liu HX, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9194069
   Mahanta S, 2019, TENCON IEEE REGION, P1118, DOI [10.1109/TENCON.2019.8929517, 10.1109/tencon.2019.8929517]
   Méndez M, 2023, ARTIF INTELL REV, V56, P10031, DOI 10.1007/s10462-023-10424-4
   MODIS, 2020, NASA, Moderate Resolution Imaging Spectroradiometer
   Ojagh S, 2021, COMPUT ELECTR ENG, V96, DOI 10.1016/j.compeleceng.2021.107572
   Pollution.org, 2020, Global Pollution Map
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   project T., 2020, World Air Pollution Forecast
   Safar.tropmet.res.in, 2020, SAFAR-India
   Shaban KB, 2016, IEEE SENS J, V16, P2598, DOI 10.1109/JSEN.2016.2514378
   Sharma E, 2020, IEEE ACCESS, V8, P209503, DOI 10.1109/ACCESS.2020.3039002
   Singh M, 2021, arXiv
   Soh PW, 2018, IEEE ACCESS, V6, P38186, DOI 10.1109/ACCESS.2018.2849820
   Suganya S, 2023, MULTIMED TOOLS APPL, DOI 10.1007/s11042-023-15046-0
   Suganya S, 2020, International Journal of Scientific & Technology Research, V9, P1
   Tao Q, 2019, IEEE ACCESS, V7, P76690, DOI 10.1109/ACCESS.2019.2921578
   Team K., 2020, Keras Documentation: Keras API Reference
   TensorFlow, 2020, API Documentation | Tensorflow Core V2.3.0
   US EPA, 2020, United States Environmental Protection Agency, Air Data Basic Information.
   Xayasouk T, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062570
   Xu XH, 2021, IEEE T CYBERNETICS, V51, P2577, DOI 10.1109/TCYB.2019.2945999
   Ye Z., Air Pollutants Prediction in Shenzhen Based on ARIMA and Prophet Method, DOI [10.1051/e3sconf/20191360, DOI 10.1051/E3SCONF/20191360]
   Zhang Y, 2019, IEEE ACCESS, V7, P30732, DOI 10.1109/ACCESS.2019.2897754
   Zhou YC, 2018, IEEE ACCESS, V6, P77996, DOI 10.1109/ACCESS.2018.2884647
NR 51
TC 0
Z9 0
U1 14
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17432-0
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700006
DA 2024-07-18
ER

PT J
AU Shinde, SA
   Pawar, RR
   Jagtap, AA
   Tambewagh, PA
   Rajput, PU
   Mali, MK
   Kale, SD
   Mulik, SV
AF Shinde, Sandeep A.
   Pawar, Ranjeet R.
   Jagtap, Asmita A.
   Tambewagh, Pratibha A.
   Rajput, Punam U.
   Mali, Mohan K.
   Kale, Satish D.
   Mulik, Sameer V.
TI Deceptive opinion spam detection using bidirectional long short-term
   memory with capsule neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deceptive opinion; Spam detection; Social media; Bidirectional long
   short-term memory; Capsule neural network; Borderline-SMOTE; Extra tree
   classifier
AB Product reviews are becoming a more popular tool for businesses and individuals when making judgements about purchases. Spammers create synthesized reviews to either promote certain items or denigrate those of rivals to make money. As a result, in recent years, both the business and research sectors have paid close attention to the detection of false opinion spam. Customers' decision-making is severely harmed by false opinion spam in service or product evaluations. It's becoming difficult to identify false opinion spam. Accordingly, the article proposed to detect deceptive opinion spam based on a hybrid deep learning technique. Initially, the model was tested using deceptive reviews gathered from several online forums. To identify deceptive reviews, many researchers at the moment create models based on a single text attribute. On the contrary, deceptive reviewers will decisively copy the wording style of legitimate evaluations while submitting reviews. These text-feature-based techniques may or may not be successful. As a result, the research suggested an ensemble multiple-feature selection technique of the Extra tree classifier to extract information based on a variety of features, including text, behaviour, and deceptive scoring features. In addition, a data resampling approach is used that integrates the Borderline-SMOTE algorithm to reduce the effects of the high dimensional imbalanced class category distribution. For detecting deceptive reviews, the article developed a hybrid technique of Bidirectional Long Short-Term Memory (Bi-LSTM) with a Capsule Neural Network to detect the positive and negative false opinions spam. The model optimizes the dynamic routing algorithm and changes the structure of the conventional capsule network without sacrificing classification performance, leading to high model accuracy. The model performance is evaluated using Python software. The study assesses the suggested model using data from two distinct domains (hotel and restaurant) as a standard benchmark. The experimental results demonstrate the advantage of neural models with higher accuracy of 99% respectively, showing that the suggested neural model greatly outperforms the state-of-the-art techniques.
C1 [Shinde, Sandeep A.; Pawar, Ranjeet R.; Jagtap, Asmita A.; Tambewagh, Pratibha A.; Rajput, Punam U.; Mali, Mohan K.; Kale, Satish D.; Mulik, Sameer V.] Bharati Vidyapeeth Inst Technol, Navi Mumbai, India.
RP Shinde, SA (corresponding author), Bharati Vidyapeeth Inst Technol, Navi Mumbai, India.
EM Sandeep.Shinde@bharatividyapeeth.edu;
   Ranjeet.Pawar@bharatividyapeeth.edu;
   Asmita.Jagtap@bharatividyapeeth.edu;
   Pratibha.Tambewagh@bharatividyapeeth.edu;
   Poonam.Rajput@bharatividyapeeth.edu; Mohan.Mali@bharatividyapeeth.edu;
   Satish.Kale@bharatividyapeeth.edu; Sameer.Mulik@bharatividyapeeth.edu
CR Al-Zoubi AM, 2023, IEEE ACCESS, V11, P72250, DOI 10.1109/ACCESS.2023.3293641
   Amin I, 2022, MATER TODAY-PROC, V62, P4779, DOI 10.1016/j.matpr.2022.03.342
   Cao N, 2022, EXPERT SYST APPL, V187, DOI 10.1016/j.eswa.2021.115977
   Cao N, 2020, EXPERT SYST APPL, V156, DOI 10.1016/j.eswa.2020.113465
   Catelli R, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118290
   Ceballos Delgado AA, 2021, P 54 HAW INT C SYST, P7122, DOI [10.24251/hicss.2021.857, DOI 10.24251/HICSS.2021.857]
   Dangi D, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.119849
   Dangi D, 2022, MULTIMED TOOLS APPL, V81, P42261, DOI 10.1007/s11042-022-13492-w
   Deepika DS, 2021, INT C IM PROC CAPS N, P581, DOI [10.1007/978-3-030-84760-9_49, DOI 10.1007/978-3-030-84760-9_49]
   Dixit DK, 2023, CONCURR COMP-PRACT E, V35, DOI 10.1002/cpe.7382
   Du XD, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534008
   Duma RA, 2023, SOFT COMPUT, V27, P6281, DOI 10.1007/s00500-023-07897-4
   Fahfouh A, 2024, IEEE T NEUR NET LEAR, V35, P1228, DOI 10.1109/TNNLS.2022.3183037
   Fahfouh A, 2020, EXPERT SYST APPL, V157, DOI 10.1016/j.eswa.2020.113517
   Jacob Minu Susan, 2022, Mobile Radio Communications and 5G Networks: Proceedings of Second MRCN 2021. Lecture Notes in Networks and Systems (339), P57, DOI 10.1007/978-981-16-7018-3_4
   Jayathunga Dinooshi Poornima, 2021, Computational Intelligence in Information Systems. Proceedings of the Computational Intelligence in Information Systems Conference (CIIS 2020). Advances in Intelligent Systems and Computing (AISC 1321), P97, DOI 10.1007/978-3-030-68133-3_10
   Khan W, 2021, EXPERT SYST APPL, V169, DOI 10.1016/j.eswa.2020.114341
   Kotriwal Sparsh, 2022, Data Engineering for Smart Systems: Proceedings of SSIC 2021. Lecture Notes in Networks and Systems (238), P489, DOI 10.1007/978-981-16-2641-8_47
   Liu YX, 2022, INFORM SYST, V103, DOI 10.1016/j.is.2021.101865
   Mewada Arvind, 2021, Materials Today: Proceedings, DOI [10.1016/j.matpr.2020.12.1126, DOI 10.1016/J.MATPR.2020.12.1126]
   Parte SA, 2023, ACM transactions on knowledge discovery from data
   Rao SJ, 2023, EXPERT SYST APPL, V217, DOI 10.1016/j.eswa.2023.119594
   Ren YF, 2022, INFORM SCIENCES, V604, P1, DOI 10.1016/j.ins.2022.05.011
   Rout JK, 2023, IEEE T COMPUT SOC SY, DOI 10.1109/TCSS.2023.3243139
   Sharmila MG, 2023, A Journal for New Zealand Herpetology, V12
   Soldner F, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0277869
   Sultana N., 2020, Int J Inf Eng Electron Bus, V12, P1, DOI DOI 10.5815/IJIEEB.2020.01.01
   Tamimi M., 2023, P 28 INT COMP C COMP, P1, DOI DOI 10.1109/CSICC58665.2023.10105368
   Toplu A, 2021, IN C IND ENG ENG MAN, P1442, DOI 10.1109/IEEM50564.2021.9672994
   Velutharambath A, 2023, Arxiv, DOI arXiv:2306.02827
   Vidanagama D, 2021, 2021 5 SLAAI INT C A, P1, DOI [10.1109/SLAAI-ICAI54477.2021.9664748, DOI 10.1109/SLAAI-ICAI54477.2021.9664748]
   Zaki N, 2023, Node embedding approach for accurate detection of fake reviews: a graph-based machine learning approach with explainable AI, DOI [10.21203/rs.3.rs-2841712/v1, DOI 10.21203/RS.3.RS-2841712/V1]
   Zhong MJ, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/7475022
   Zhong MJ, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/9923374
NR 34
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 20
PY 2023
DI 10.1007/s11042-023-17348-9
EA OCT 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NY9
UT WOS:001088014100004
DA 2024-07-18
ER

PT J
AU Cao, F
   Chen, J
   Li, FY
AF Cao, Fang
   Chen, Jing
   Li, Fengyong
TI Texture driven adaptive multi-level block selection based reversible
   data hiding in encrypted image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Reversible data hiding; Image encryption; Image recovery; Block
   selection embedding
AB For reversible data hiding in encrypted image (RDHEI), it is an important problem to resolve the contradiction between embedding capacity and image visual quality. However, existing schemes do not maintain a good balance between them. Accordingly, we propose a multi-level block selection embedding mechanism to solve this problem. Our scheme firstly divides original image into muliple non-overlapping blocks with identical size. The most significant bit (MSB) planes of all pixels in the block are predicted from their neighboring pixels to generate a corresponding prediction error map for each block. Subsequently, the pixels are divided into eight bit planes, and the adjacent bit planes are implemented XOR operation to vacate room. Furthermore, by simulating data embedding in each block, PSNR values of each image block are sequentially generated. After encrypting the image using stream ciphers, the optimal blocks with maximum PSNR value can be selected to embed data according to the secret data capacity. Since our proposed scheme usually selects the image block with maximum PSNR value to embed secret data, it can naturally improve the image visual quality. Extensive experiments demonstrate that our scheme is effective and efficient, and outperforms existing state-of-the art methods with better visual quality and higher security performance under the given embedding capacity.
C1 [Cao, Fang; Chen, Jing] Shanghai Maritime Univ, Coll Informat Engn, Shanghai 201306, Peoples R China.
   [Li, Fengyong] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Li, Fengyong] Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
C3 Shanghai Maritime University; Guangxi Normal University; Shanghai
   University of Electric Power
RP Li, FY (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Li, FY (corresponding author), Shanghai Univ Elect Power, Coll Comp Sci & Technol, Shanghai 201306, Peoples R China.
EM fyli@shiep.edu.cn
FU The authors would like to thank the editors and anonymous reviewers for
   their valuable suggestions and comments.
FX The authors would like to thank the editors and anonymous reviewers for
   their valuable suggestions and comments.
CR [Anonymous], 2021, BOWS2 database
   [Anonymous], 2020, BOSSbase v1.01
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Cao F, 2022, SECUR COMMUN NETW, V2022, DOI 10.1155/2022/1227926
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen KM, 2019, MULTIMED TOOLS APPL, V78, P31441, DOI 10.1007/s11042-019-07946-x
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   Hong CQ, 2019, IEEE T IND INFORM, V15, P3952, DOI 10.1109/TII.2018.2884211
   Huang DL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115632
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kong P, 2021, MULTIMEDIA SYST, V27, P303, DOI 10.1007/s00530-020-00739-5
   Li FY, 2022, IEEE T CIRC SYST VID, V32, P8849, DOI 10.1109/TCSVT.2022.3192553
   Li FY, 2023, MULTIMED TOOLS APPL, V82, P6013, DOI 10.1007/s11042-022-13406-w
   Li FY, 2022, INFORM SCIENCES, V595, P142, DOI 10.1016/j.ins.2022.02.040
   Li FY, 2021, MULTIMED TOOLS APPL, V80, P2141, DOI 10.1007/s11042-020-09805-6
   Li Q, 2018, MULTIMED TOOLS APPL, V77, P30749, DOI 10.1007/s11042-018-6187-y
   Ma GY, 2019, SIGNAL PROCESS-IMAGE, V75, P55, DOI 10.1016/j.image.2019.03.013
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mahasree M., 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P732, DOI 10.1109/ICOEI51242.2021.9452956
   Malik A, 2020, MULTIMED TOOLS APPL, V79, P11591, DOI 10.1007/s11042-019-08460-w
   Mohammadi A, 2020, IEEE T CIRC SYST VID, V30, P2366, DOI 10.1109/TCSVT.2020.2990952
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Puteaux P, 2018, IEEE T INF FOREN SEC, V13, P1670, DOI 10.1109/TIFS.2018.2799381
   Qin C, 2022, IEEE T CIRC SYST VID, V32, P1928, DOI 10.1109/TCSVT.2021.3091319
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tang ZJ, 2019, MULTIMED TOOLS APPL, V78, P9691, DOI 10.1007/s11042-018-6567-3
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang X, 2022, J VIS COMMUN IMAGE R, V82, DOI 10.1016/j.jvcir.2021.103421
   Wang YM, 2022, IEEE T MULTIMEDIA, V24, P1288, DOI 10.1109/TMM.2021.3062699
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu HB, 2019, MULTIMED TOOLS APPL, V78, P25349, DOI 10.1007/s11042-019-07769-w
   Xu SY, 2021, MULTIMED TOOLS APPL, V80, P20307, DOI 10.1007/s11042-021-10698-2
   Yi S, 2018, SIGNAL PROCESS-IMAGE, V64, P78, DOI 10.1016/j.image.2018.03.001
   Yu CY, 2021, ACTA HORTIC, V1313, P1, DOI [10.17660/ActaHortic.2021.1313.1, 10.1109/TCSVT.2021.3062947]
   Yu CQ, 2022, INFORM SCIENCES, V584, P89, DOI 10.1016/j.ins.2021.10.050
   Yu J, 2022, IEEE T PATTERN ANAL, V44, P563, DOI 10.1109/TPAMI.2019.2932058
   Yu MJ, 2022, IEEE T CIRC SYST VID, V32, P7241, DOI 10.1109/TCSVT.2022.3172226
   Yu MJ, 2022, SIGNAL PROCESS-IMAGE, V105, DOI 10.1016/j.image.2022.116696
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhou TF, 2022, IEEE T IMAGE PROCESS, V31, P799, DOI 10.1109/TIP.2021.3132834
   Zhou TF, 2021, PROC CVPR IEEE, P5774, DOI 10.1109/CVPR46437.2021.00572
NR 44
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 19
PY 2023
DI 10.1007/s11042-023-17173-0
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6OE7
UT WOS:001085969000013
DA 2024-07-18
ER

PT J
AU Fukusato, T
   Maejima, A
   Igarashi, T
   Yotsukura, T
AF Fukusato, Tsukasa
   Maejima, Akinobu
   Igarashi, Takeo
   Yotsukura, Tatsuo
TI Exploring inbetween charts with trajectory-guided sliders for cutout
   animation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Inbetween chart; Cutout animation; Motion trajectory
ID TOOL
AB We introduce an interactive tool to intuitively make inbetween charts for cutout character movements (i.e., transitioning from one image to another), inspired by cartoon animators' techniques. Given several keyframes, this system constructs trajectory-guided sliders that enable users to directly adjust inbetween values on a screen. In addition, these sliders can visualize simple inbetween timings to provide guidance on cartoon-like motions, such as animating "on twos" and "slow-in/out" in the background of the slider. Thus, the users can intuitively explore inbetween charts until they are satisfied. This method is simple enough to easily implement in existing animation-authoring tools. We conduct a user study with novice and amateur users and confirm that the proposed slider (including the guidance function) is effective for manually constructing the inbetween charts envisioned by the users.
C1 [Fukusato, Tsukasa] Waseda Univ, Dept Intermedia Art & Sci, 3-4-1 Okubo, Tokyo, Tokyo 1698555, Japan.
   [Maejima, Akinobu; Yotsukura, Tatsuo] OLM Digital Inc, 1-18-10 Wakabayashi, Tokyo, Tokyo 1540023, Japan.
   [Maejima, Akinobu; Yotsukura, Tatsuo] IMAGICA GRP Inc, 1-14-2 Kaigan, Minato, Tokyo 1050022, Japan.
   [Igarashi, Takeo] Univ Tokyo, Dept Creat Informat, 7-3-1 Hongo,Bunkyo, Tokyo 1138656, Japan.
C3 Waseda University; University of Tokyo
RP Fukusato, T (corresponding author), Waseda Univ, Dept Intermedia Art & Sci, 3-4-1 Okubo, Tokyo, Tokyo 1698555, Japan.
EM tsukasafukusato@waseda.jp; akinobu.maejima@olm.co.jp; takeo@acm.org;
   yotsukura@olm.co.jp
OI Maejima, Akinobu/0000-0002-8005-9218; Fukusato,
   Tsukasa/0000-0002-5090-1443; Yotsukura, Tatsuo/0000-0002-4091-5905
FU This research was supported by Waseda University Grant for Special
   Research Projects (Project number: 2023Q-009). [2023Q-009]; Waseda
   University Grant for Special Research Projects
FX This research was supported by Waseda University Grant for Special
   Research Projects (Project number: 2023Q-009).
CR Alexa M, 2000, COMP GRAPH, P157, DOI 10.1145/344779.344859
   Barnes C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409077
   Baxter W., 2008, NPAR'08 Proceedings of the 6th international symposium on Non-photorealistic animation and rendering, P59, DOI [http://doi.acm.org/10.1145/1377980.1377993. endereco, DOI 10.1145/1377980.1377993.ENDERE]
   Baxter W, 2006, COMPUT GRAPH FORUM, V25, P477, DOI 10.1111/j.1467-8659.2006.00967.x
   Baxter W, 2009, COMPUT ANIMAT VIRT W, V20, P79, DOI 10.1002/cav.310
   Bregler C, 2002, ACM T GRAPHIC, V21, P399, DOI 10.1145/566570.566595
   Carvalho L, 2017, COMPUT GRAPH-UK, V65, P31, DOI 10.1016/j.cag.2017.04.001
   Chen R, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461983
   Choi B, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925970
   Choi MG, 2012, COMPUT GRAPH FORUM, V31, P2057, DOI 10.1111/j.1467-8659.2012.03198.x
   Ciccone L, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322938
   Davis RC, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P413
   Dragicevic P, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P237
   Dunbar D, 2006, ACM T GRAPHIC, V25, P503, DOI 10.1145/1141911.1141915
   Fukusato T, 2022, IEEE COMPUT GRAPH, V42, P66, DOI 10.1109/MCG.2022.3174202
   Fukusato Tsukasa, 2016, Mathematical Progress in Expressive Image Synthesis, VIII, P45, DOI [10.1007/978-981-10-1076-7_6, DOI 10.1007/978-981-10-1076-7_6]
   Furukawa S, 2018, LECT NOTES COMPUT SC, V10714, P153, DOI 10.1007/978-3-319-76270-8_12
   Guay M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766893
   Hornung A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1186644.1186645
   Iarussi E., 2013, P 26 ANN ACM S USER, DOI [DOI 10.1145/2501988.2501997, 10.1145/2501988.2501997]
   Igarashi T, 2005, ACM T GRAPHIC, V24, P1134, DOI 10.1145/1073204.1073323
   Kaji S, 2012, P ACM SIGGRAPH EUR S, P71
   Kawamoto S, 2008, COMPUT ANIMAT VIRT W, V19, P247, DOI 10.1002/cav.250
   Kazi RH, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P4599, DOI 10.1145/2858036.2858386
   Kitamura M, 2013, P INT WORKSH ADV IM, P148
   Koyama Y, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173735
   Levi Z, 2015, IEEE T VIS COMPUT GR, V21, P264, DOI 10.1109/TVCG.2014.2359463
   Maejima A, 2021, PROCEEDINGS OF SIGGRAPH ASIA 2021 TECHNICAL COMMUNICATIONS, DOI 10.1145/3478512.3488604
   Morimoto Y., 2019, Int J Asia Digit Art Des, V23, P16, DOI [10.20668/adada.23.2_16, DOI 10.20668/ADADA.23.2_16]
   Morishima S, 2007, ACM SIGGRAPH 2007 SK, P76, DOI [10.1145/1278780.1278872, DOI 10.1145/1278780.1278872]
   Pantoja T, 2016, The art of inbetweening: Timing charts
   Rivers A, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778796
   Roberts R, 2019, COMPUT VIS MEDIA, V5, P171, DOI 10.1007/s41095-019-0138-z
   Sorkine O, 2007, S GEOM PROC, V4, P109, DOI [10.1145/1073204.1073323, DOI 10.1145/1073204.1073323]
   Su QK, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3174236
   Sykora D, 2009, COMPUT GRAPH FORUM, V28, P599, DOI 10.1111/j.1467-8659.2009.01400.x
   Sykora Daniel, 2009, P 7 INT S NONPHOTORE, P25, DOI DOI 10.1145/1572614.1572619.3,7
   Thorne M, 2004, ACM T GRAPHIC, V23, P424, DOI 10.1145/1015706.1015740
   Wang J, 2006, ACM T GRAPHIC, V25, P1169, DOI 10.1145/1141911.1142010
   Whited B, 2010, COMPUT GRAPH FORUM, V29, P605, DOI 10.1111/j.1467-8659.2009.01630.x
   Willett NS, 2020, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, IUI 2020, P88, DOI 10.1145/3377325.3377505
   Willett NS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P85, DOI 10.1145/3126594.3126596
   Willett NS, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P97, DOI 10.1145/3126594.3126641
   Xing J, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P755, DOI 10.1145/2984511.2984585
   Xing J, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818079
   Yichen Peng, 2021, 2021 Nicograph International (NicoInt), P42, DOI 10.1109/NICOINT52941.2021.00015
NR 46
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17354-x
EA OCT 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600004
DA 2024-07-18
ER

PT J
AU Yin, SL
   Li, H
   Teng, L
   Laghari, AA
   Estrela, VV
AF Yin, Shoulin
   Li, Hang
   Teng, Lin
   Laghari, Asif Ali
   Estrela, Vania Vieira
TI Attribute-based multiparty searchable encryption model for privacy
   protection of text data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud storage; Hidden access structure; Attribute-enabled searchable
   Re-Encryption model; Proxy Re-Encryption; Medical data; IoMT
AB The problems of data storage and sharing have been well solved with cloud storage. However, the disadvantage is that users' messages are stored in the cloud without encryption protection. Cloud storage managers can access or even obtain user data, which brings significant security risks to data owners. Therefore, some cloud storage centers adopt ciphertext storage, which can protect them from the risk of user privacy disclosure. However, there are also problems, that is, how to find the desired data achieved in the cloud server search and how to ensure information integrity in the search process. Moreover, the encryption operation destroys the value and size relation of the original plaintext data. It does not have semantic and statistical characteristics when retrieving. Combining the hidden access structure in an attribute-based file searchable encryption model with proxy Re-Encryption technology, we propose an attribute-based file retrieval model with a partially hidden access structure supporting Proxy Re-Encryption. The model solves the above problems effectively and supports keyword updating. Finally, the security of the model is proved based on the hypothesis of D-linear and decisional q-parallel bilinear Diffie-Hellman exponent under the random oracle model.
C1 [Yin, Shoulin; Li, Hang; Teng, Lin; Laghari, Asif Ali] Shenyang Normal Univ, Software Coll, Shenyang 110034, Peoples R China.
   [Estrela, Vania Vieira] Fed Fluminense Univ UFF, Niteroi, RJ, Brazil.
C3 Shenyang Normal University; Universidade Federal Fluminense
RP Li, H; Teng, L; Laghari, AA (corresponding author), Shenyang Normal Univ, Software Coll, Shenyang 110034, Peoples R China.
EM yslinhit@163.com; lihangsoft@163.com; 1532554069@qq.com;
   asif.laghari@smiu.edu.pk; vania.estrela.phd@ieee.org
RI Laghari, Asif Ali/AAF-5893-2020; Yin, Shoulin/AAQ-6430-2021; Yin,
   Shoulin/IZE-4876-2023; Estrela, Vania V./I-7599-2012
OI Laghari, Asif Ali/0000-0001-5831-5943; Yin, Shoulin/0000-0002-5367-1372;
   Estrela, Vania V./0000-0002-4465-7691; Teng, Lin/0000-0002-3437-2123;
   Li, Hang/0000-0002-1230-4007
CR Agrawal Shweta, 2023, Advances in Cryptology - EUROCRYPT 2023: 42nd Annual International Conference on the Theory and Applications of Cryptographic Techniques, Proceedings. Lecture Notes in Computer Science (14004), P581, DOI 10.1007/978-3-031-30545-0_20
   Ferrag MA, 2017, TELECOMMUN SYST, V66, P481, DOI 10.1007/s11235-017-0299-y
   Ateniese G., 2006, ACM Transactions on Information and Systems Security, V9, P1, DOI 10.1145/1127345.1127346
   Belguith S., 2019, Secur Priv, DOI [10.1002/spy2.85, DOI 10.1002/SPY2.85]
   Bhuarya P, 2021, INT J COMMUN SYST, V34, DOI 10.1002/dac.4834
   Deverajan GG, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.4202
   Dewangan NK, 2023, IEEE T COMPUT SOC SY, V10, P3109, DOI 10.1109/TCSS.2022.3194872
   Hhan Minki, 2023, Advances in Cryptology - EUROCRYPT 2023: 42nd Annual International Conference on the Theory and Applications of Cryptographic Techniques, Proceedings. Lecture Notes in Computer Science (14004), P639, DOI 10.1007/978-3-031-30545-0_22
   Kaushik K, 2013, 2013 IEEE 14TH INTERNATIONAL CONFERENCE ON MOBILE DATA MANAGEMENT (MDM 2013), VOL 2, P200, DOI 10.1109/MDM.2013.94
   Kuzuno H., 2013, IEICE Trans Commun, V87, P404
   Li Hang, 2017, J Inf Hiding Multimed Signal Process, V8, P218
   Li JG, 2017, IEEE T SERV COMPUT, V10, P715, DOI 10.1109/TSC.2016.2542813
   Li P, 2018, IEEE T IND INFORM, V14, P790, DOI 10.1109/TII.2017.2739340
   [李双 Li Shuang], 2014, [计算机学报, Chinese Journal of Computers], V37, P1017
   Liu Jie, 2017, J Inf Hiding Multimed Signal Process, V8, P12
   Liu LX, 2016, SECUR COMMUN NETW, V9, P4897, DOI 10.1002/sec.1663
   Nguyen TT, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060891
   Padhya M, 2014, LECT NOTES COMPUT SC, V8880, P167, DOI 10.1007/978-3-319-13841-1_10
   Shao J, 2010, INFORM SCIENCES, V180, P2576, DOI 10.1016/j.ins.2010.03.026
   Shen XY, 2022, INFORM SCIENCES, V605, P202, DOI 10.1016/j.ins.2022.05.001
   Song DXD, 2000, P IEEE S SECUR PRIV, P44, DOI 10.1109/SECPRI.2000.848445
   Sowjanya K, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102559
   Sun Y., 2019, Int J Netw Secur, V21, P843
   Tang YL, 2022, CLUSTER COMPUT, V25, P2305, DOI 10.1007/s10586-021-03488-w
   Teng L., 2019, J Comput (Taiwan), V30, P59
   Teng W, 2017, IEEE T CLOUD COMPUT, V5, P617, DOI 10.1109/TCC.2015.2440247
   Ya-Ling Z, 2015, 2014 10 INT C COMP I
   Yin H, 2019, IEEE ACCESS, V7, P5682, DOI 10.1109/ACCESS.2018.2889754
   Zhang MW, 2018, IEEE ACCESS, V6, P33859, DOI 10.1109/ACCESS.2018.2842713
   Zhang QC, 2021, IEEE ACM T COMPUT BI, V18, P882, DOI 10.1109/TCBB.2019.2914447
   Zhao M, 2023, J INF SECUR APPL, V73, DOI 10.1016/j.jisa.2023.103441
   Zheng QJ, 2014, IEEE INFOCOM SER, P522, DOI 10.1109/INFOCOM.2014.6847976
NR 32
TC 1
Z9 1
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-16818-4
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600015
DA 2024-07-18
ER

PT J
AU Bingu, R
   Jothilakshmi, S
AF Bingu, Rajesh
   Jothilakshmi, S.
TI Cloud auditing and authentication scheme for establishing privacy
   preservation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cloud storage; Auditing; Authentication; Duplication; Data integrity
ID PROTOCOL; ACCESS
AB Data outsourcing to cloud servers is increased with the development of cloud storage. While increasing the amount of cloud storage, it leads to data duplication. But the unique copy of the original data is stored in the cloud server, and it causes data loss in terms of corruption or missing. It is essential to maintain the duplicate copy of the file and integrity auditing in the field of academic and industrial. The file over the cloud is maintained in a secure or protected manner. This paper proposes cloud auditing with secure file maintenance to retain the duplicate copy of the encrypted file. During the process of public auditing, integrity is maintained for each copy with reduced storage. Secure Authentication with User Anonymity (SAUS) is established with cloud auditing and confidentiality during the process of duplication, and auditing integrity is maintained with encryption approaches. The duplication process is invoked with Multi-Failure Resilient Replication (MRR) procedure in which the data loss is reduced. In order to deal with the multiple auditing strategy for outsourced data, data integrity is maintained with each data owner and delegating third party auditing (TPA) independently. The proposed work is implemented in MATLAB environment with better security and improved performance. The performance of the proposed work is compared with the existing approaches, which shows a better trade-off in contrast to prevailing approaches.
C1 [Bingu, Rajesh] Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram 522302, Andhra Pradesh, India.
   [Jothilakshmi, S.] Annamalai Univ, Dept Informat Technol, Chidambaram 608002, Tamil Nadu, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University);
   Annamalai University
RP Bingu, R (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept CSE, Vaddeswaram 522302, Andhra Pradesh, India.
EM govindajeeyardasan@gmail.com; jothi.sekar@gmail.com
RI S, Jothilakshmi/W-7968-2019; BINGU, RAJESH/HRE-3679-2023
OI BINGU, RAJESH/0000-0003-1635-579X
CR Armknecht F, 2021, IEEE T CLOUD COMPUT, V9, P286, DOI 10.1109/TCC.2018.2865554
   Chen RN, 2020, IEEE INTERNET THINGS, V7, P4143, DOI 10.1109/JIOT.2019.2963789
   Cheng HB, 2018, IEEE ACCESS, V6, P37869, DOI 10.1109/ACCESS.2018.2851599
   Devika K. N., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0370, DOI 10.1109/ICCSP.2019.8698069
   Fan YK, 2019, FUTURE GENER COMP SY, V101, P127, DOI 10.1016/j.future.2019.04.046
   Garg N, 2020, FUTURE GENER COMP SY, V109, P306, DOI 10.1016/j.future.2020.03.032
   Hiremath S, 2020, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS 2020), P1017, DOI [10.1109/ICICCS48265.2020.9120974, 10.1109/iciccs48265.2020.9120974]
   Hou HY, 2019, J NETW COMPUT APPL, V134, P26, DOI 10.1016/j.jnca.2019.02.015
   Huang P, 2020, IEEE ACCESS, V8, P94780, DOI 10.1109/ACCESS.2020.2993606
   Jegadeesan S, 2019, SUSTAIN CITIES SOC, V49, DOI 10.1016/j.scs.2019.101522
   Kundalwal MK, 2019, ICT EXPRESS, V5, P167
   Li JG, 2021, IEEE SYST J, V15, P577, DOI 10.1109/JSYST.2020.2978146
   Li JW, 2016, IEEE T COMPUT, V65, P2386, DOI 10.1109/TC.2015.2389960
   Li X, 2020, IEEE T INF FOREN SEC, V15, P2881, DOI 10.1109/TIFS.2020.2978592
   Liu JW, 2021, IEEE ACM T NETWORK, V29, P1436, DOI 10.1109/TNET.2020.3027814
   Liu XF, 2017, IEEE T SERV COMPUT, V10, P826, DOI 10.1109/TSC.2016.2531665
   Miao MX, 2021, INT J INTELL SYST, V36, P2753, DOI 10.1002/int.22400
   Polu SK, 2018, Int J Innov Res Sci Technol Researchgate.net, V5, P18
   Prabha KM, 2020, COMPUT COMMUN, V158, P85, DOI 10.1016/j.comcom.2020.04.057
   Qiu MK, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4278
   Sahinidis NV, 2019, OPTIM ENG, V20, P301, DOI 10.1007/s11081-019-09438-1
   Taneja Harsh, 2022, Proceedings of Data Analytics and Management: ICDAM 2021. Lecture Notes on Data Engineering and Communications Technologies (91), P789, DOI 10.1007/978-981-16-6285-0_61
   Tchernykh A, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2016.11.011
   Thokchom S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102427
   Tian H, 2017, IEEE T SERV COMPUT, V10, P701, DOI 10.1109/TSC.2015.2512589
   Tian H, 2017, SOFT COMPUT, V21, P2175, DOI 10.1007/s00500-016-2311-y
   Walker I., 2022, SN Comput Sci Springer, V3, P1
   Wang F, 2020, IEEE ACCESS, V8, P2258, DOI 10.1109/ACCESS.2019.2960853
   Wazid M, 2019, FUTURE GENER COMP SY, V91, P475, DOI 10.1016/j.future.2018.09.017
   Xu Y, 2021, IEEE T EMERG TOP COM, V9, P1421, DOI 10.1109/TETC.2020.3005610
   Xue KP, 2018, IEEE NETWORK, V32, P7, DOI 10.1109/MNET.2018.1700341
   Yang Z, 2017, IEEE ICC
   Youn TY., 2017, Res Briefs Inf Commun Technol Evol (ReBICTE), V3, P1
   Young M, 2019, FAT*'19: PROCEEDINGS OF THE 2019 CONFERENCE ON FAIRNESS, ACCOUNTABILITY, AND TRANSPARENCY, P191, DOI 10.1145/3287560.3287577
   Zhou YK, 2018, FUTURE GENER COMP SY, V84, P177, DOI 10.1016/j.future.2017.10.014
NR 35
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17170-3
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400012
DA 2024-07-18
ER

PT J
AU Gao, XY
   Yan, SK
   Zhang, CX
AF Gao, Xueyao
   Yan, Shaokang
   Zhang, Chunxiang
TI 3D Model classification based on regnet design space and voting
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 3D model classification; Semantic feature; RegNet design space; Voting
   algorithm; Shape features
AB 3D models are widely used in industrial manufacturing, virtual reality, medical diagnosis and so on. At present, view-based 3D model classification has become an important research topic. However, single view feature can not describe the overall shape of 3D model. When multiple views are fused to describe 3D model, useful information is confused. It causes certain interference to determine 3D model's category. To solve these problems, a novel method of 3D model classification based on RegNet design space and voting algorithm is proposed. Firstly, 2D views of 3D model are input into RegNet design space with attention mechanism to extract high-level semantic feature(HSF). Secondly, HSF and the corresponding low-level shape features (LSF) of view are fused, including D1, D2, D3, Fourier descriptor, and Zernike moment. Thirdly, LSTM is combined with softmax function to extract more representative features from the fused feature. Finally, based on discriminative features, improved voting algorithm based on shannon entropy is constructed to determine 3D model's category. Experimental results show that average accuracy of the proposed method on ModelNet10 reaches 94.93%, and the classification performance is outstanding.
C1 [Gao, Xueyao; Yan, Shaokang; Zhang, Chunxiang] Harbin Univ Sci & Technol, Sch Comp Sci & Technol, 52 Xuefu Rd, Harbin 150080, Heilongjiang, Peoples R China.
C3 Harbin University of Science & Technology
RP Gao, XY (corresponding author), Harbin Univ Sci & Technol, Sch Comp Sci & Technol, 52 Xuefu Rd, Harbin 150080, Heilongjiang, Peoples R China.
EM xueyao_gao@163.com; ysk_18463912040@163.com; z6c6x666@163.com
FU Heilongjiang Provincial Natural Science Foundation of China [LH2022F030]
FX This research was supported by Heilongjiang Provincial Natural Science
   Foundation of China (Grant No. LH2022F030).
CR Armi L, 2019, MULTIMED TOOLS APPL, V78, P18995, DOI 10.1007/s11042-019-7207-2
   [白静 Bai Jing], 2019, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V31, P303
   Boukerma R, 2019, 2019 INT C THEOR APP, V1, P1
   Cai WW, 2021, DISPLAYS, V69, DOI 10.1016/j.displa.2021.102076
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gao YB, 2023, IEEE T INTELL TRANSP, V24, P2158, DOI 10.1109/TITS.2022.3140355
   Han L, 2021, MULTIMED TOOLS APPL, V80, P973, DOI 10.1007/s11042-020-09764-y
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P3986, DOI 10.1109/TIP.2019.2904460
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YQ, 2021, NEUROCOMPUTING, V459, P201, DOI 10.1016/j.neucom.2021.06.046
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iyer N, 2005, COMPUT AIDED DESIGN, V37, P509, DOI 10.1016/j.cad.2004.07.002
   Jin X, 2022, COMPUT AIDED DESIGN, V150, DOI 10.1016/j.cad.2022.103279
   Kayhan N, 2021, MULTIMED TOOLS APPL, V80, P32763, DOI 10.1007/s11042-021-11217-z
   Kim S, 2021, COMPUT AIDED DESIGN, V130, DOI 10.1016/j.cad.2020.102932
   Le T, 2017, COMPUT GRAPH-UK, V66, P103, DOI 10.1016/j.cag.2017.05.011
   Liu AA, 2021, INFORM SCIENCES, V547, P984, DOI 10.1016/j.ins.2020.09.057
   Ma ZP, 2022, MULTIMED TOOLS APPL, V81, P32519, DOI 10.1007/s11042-022-12041-9
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   Qi C. R., 2017, P IEEE C COMP VIS PA, P652
   Qin FW, 2014, J ZHEJIANG U-SCI C, V15, P91, DOI 10.1631/jzus.C1300185
   Radosavovic Ilija, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10425, DOI 10.1109/CVPR42600.2020.01044
   Rao TYS, 2018, MULTIMED TOOLS APPL, V77, P32041, DOI 10.1007/s11042-018-6224-x
   Romanengo C, 2023, COMPUT AIDED DESIGN, V157, DOI 10.1016/j.cad.2023.103479
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Song Y, 2022, Comput Aided Des, V146, P1
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang HF, 2022, PATTERN RECOGN, V121, DOI 10.1016/j.patcog.2021.108251
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Xu X, 2016, INT C PATT RECOG, P3506, DOI 10.1109/ICPR.2016.7900177
   Zhou F, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13106098
   Zhu F, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104405
NR 36
TC 0
Z9 0
U1 9
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17291-9
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400011
DA 2024-07-18
ER

PT J
AU Imani, M
AF Imani, Maryam
TI Modified PCA, LDA and LPP feature extraction methods for PolSAR image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE PCA; LDA; LPP; PolSAR; Classification
ID NETWORK
AB Three well-known feature extraction methods are modified for PolSAR image classification in this work. The polarimetric scattering characteristics of the PolSAR image containing randomness degree and scattering mechanism information are utilized to define a scattering coefficient. The defined coefficient is used to modify the principal component analysis (PCA), linear discriminant analysis (LDA) and locality preserving projection (LPP). The simple defined scattering coefficient, without any free parameter or any requirement to training samples, involves the scattering information into the PCA, LDA and LPP transforms. New projection models are developed according to the scattering coefficient. Finally, an edge preserving filter with the first principal component as the guidance image is suggested for importing the spatial characteristics and cleaning the speckle noise. The experimental results show superior performance of the modified feature extraction methods compared to the conventional methods and some state-of-the-art methods.
C1 [Imani, Maryam] Tarbiat Modares Univ, Fac Elect & Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Imani, M (corresponding author), Tarbiat Modares Univ, Fac Elect & Comp Engn, Tehran, Iran.
EM maryam.imani@modares.ac.ir
RI Imani, Maryam/AAA-8782-2022
OI Imani, Maryam/0000-0002-1924-9776
CR Abdeen MM, 2018, EGYPT J REMOTE SENS, V21, pS55, DOI 10.1016/j.ejrs.2017.12.001
   Ahishali M, 2021, GISCI REMOTE SENS, V58, P28, DOI 10.1080/15481603.2020.1853948
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Dalmiya CP, 2019, EGYPT J REMOTE SENS, V22, P183, DOI 10.1016/j.ejrs.2018.03.005
   Duan YP, 2016, IEEE GEOSCI REMOTE S, V13, P1686, DOI 10.1109/LGRS.2016.2604256
   Ferguson JE, 2022, REMOTE SENS ENVIRON, V280, DOI 10.1016/j.rse.2022.113176
   Fini RM, 2022, MULTIMED TOOLS APPL, V81, P38375, DOI 10.1007/s11042-022-13167-6
   Gadhiya T, 2020, IEEE T GEOSCI REMOTE, V58, P97, DOI 10.1109/TGRS.2019.2933483
   Horch A, 2019, IET IMAGE PROCESS, V13, P2866, DOI 10.1049/iet-ipr.2019.0122
   Hu RY, 2017, NEUROCOMPUTING, V220, P130, DOI 10.1016/j.neucom.2016.05.081
   Hua WQ, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15082025
   Imani M, 2021, INT J REMOTE SENS, V42, P4946, DOI 10.1080/01431161.2021.1906984
   Imani M, 2019, IET IMAGE PROCESS, V13, P270, DOI 10.1049/iet-ipr.2017.1431
   Imani M, 2014, 2014 IRANIAN CONFERENCE ON INTELLIGENT SYSTEMS (ICIS)
   Imani M, 2015, ISPRS J PHOTOGRAMM, V102, P1, DOI 10.1016/j.isprsjprs.2014.12.024
   Imani M, 2015, IEEE GEOSCI REMOTE S, V12, P1387, DOI 10.1109/LGRS.2015.2402167
   Kuo BC, 2004, IEEE T GEOSCI REMOTE, V42, P1096, DOI 10.1109/TGRS.2004.825578
   Lin LP, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3121166
   Liu F, 2016, PATTERN RECOGN, V59, P325, DOI 10.1016/j.patcog.2016.02.020
   Liu M, 2018, IEEE J-STARS, V11, P2134, DOI 10.1109/JSTARS.2018.2830103
   Liu QS, 2021, ISPRS J PHOTOGRAMM, V180, P151, DOI 10.1016/j.isprsjprs.2021.08.008
   Liu Y, 2021, MULTIMED TOOLS APPL, V80, P30261, DOI 10.1007/s11042-020-09135-7
   Ma Y., 2019, Prog. Electromagn. Res. B, V83, P111, DOI [10.2528/PIERB18112104, DOI 10.2528/PIERB18112104]
   Mullissa AG, 2021, IEEE Geosci Remote Sens Lett
   Nie XL, 2019, IEEE J-STARS, V12, P302, DOI 10.1109/JSTARS.2018.2886821
   Park SE, 2007, IEEE T GEOSCI REMOTE, V45, P2652, DOI 10.1109/TGRS.2007.897691
   Samat A, 2021, IEEE J-STARS, V14, P9334, DOI 10.1109/JSTARS.2021.3110994
   Shao Qiqi, 2023, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2456/1/012003
   Shi HT, 2021, REMOTE SENS ENVIRON, V261, DOI 10.1016/j.rse.2021.112485
   Tian T, 2018, MULTIMED TOOLS APPL, V77, P18637, DOI 10.1007/s11042-017-5331-4
   Wang CZ, 2021, MULTIMED TOOLS APPL, V80, P9687, DOI 10.1007/s11042-020-10137-8
   Wu Q, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030459
   Xiao DL, 2020, Arxiv, DOI [arXiv:1909.10783, 10.48550/ARXIV.1909.10783]
   Xie W, 2016, IEEE GEOSCI REMOTE S, V13, P227, DOI 10.1109/LGRS.2015.2506718
   Zhang LM, 2019, Arxiv, DOI arXiv:1903.09917
   Zhang LM, 2018, INT GEOSCI REMOTE SE, P4551, DOI 10.1109/IGARSS.2018.8519557
   Zhang L, 2019, NEUROCOMPUTING, V351, P167, DOI 10.1016/j.neucom.2019.03.024
   Zhang WC, 2008, IET IMAGE PROCESS, V2, P194, DOI 10.1049/iet-ipr:20070194
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
   Zhao JP, 2019, IEEE T GEOSCI REMOTE, V57, P10116, DOI 10.1109/TGRS.2019.2931620
   Zhu YH, 2018, PATTERN RECOGN LETT, V109, P89, DOI 10.1016/j.patrec.2017.08.018
NR 41
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17269-7
EA OCT 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800023
DA 2024-07-18
ER

PT J
AU Shastry, KA
   Sanjay, HA
AF Shastry, K. Aditya
   Sanjay, H. A.
TI Artificial Intelligence Techniques for the effective diagnosis of
   Alzheimer's Disease: A Review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Artificial Intelligence; Alzheimer's Disease; Machine Learning;
   Applications
ID MILD COGNITIVE IMPAIRMENT; ASSOCIATION WORKGROUPS; NATIONAL INSTITUTE;
   PREDICTING CONVERSION; BRAIN IMAGES; CLASSIFICATION; RECOMMENDATIONS;
   GUIDELINES; SELECTION; DEMENTIA
AB Alzheimer's disease (AD) is a progressive and irreversible neurological disorder that leads to memory loss and cognitive decline. It is a prevalent form of dementia among individuals aged 65 and above. Accurate and early diagnosis of AD is of utmost importance. Diagnostic neuroimaging and software techniques have emerged as crucial tools for assessing early-stage dementia. The aim of this study is to provide a comprehensive review of recent research that employs deep learning (DL) techniques for the assessment of dementia, particularly the early stages of AD. The objective is to analyze the current state of research and explore the future directions of this field. The study involves a systematic review of literature that focuses on the utilization of DL techniques in the assessment of dementia and early AD diagnosis. Various datasets commonly used for AD prediction are examined. The study encompasses the discussion of different applications of contemporary AI algorithms in AD detection, as well as their merits, limitations, and performance. The review reveals that DL techniques have shown promise in the detection and diagnosis of AD. The use of DL, particularly in image classification and natural language processing, has demonstrated significant advancements in the field of AI. The study also highlights the potential of AI in AD genetic studies, providing valuable insights into the broad scope of this research..
C1 [Shastry, K. Aditya] Nitte Meenakshi Inst Technol, Bangalore 560064, Karnataka, India.
   [Sanjay, H. A.] M S Ramaiah Inst Technol, Dept Biotechnol, Bangalore 560054, Karnataka, India.
C3 Nitte Meenakshi Institute of Technology; Ramaiah Institute of Technology
RP Shastry, KA (corresponding author), Nitte Meenakshi Inst Technol, Bangalore 560064, Karnataka, India.
EM adityashastry.k@nmit.ac.in
OI HA, Dr.Sanjay/0000-0002-7492-5263; Shastry, Aditya/0000-0003-3920-576X
FU This work was carried out as part of a funded project from Vision Group
   on Science and Technology (VGST), India with GRD number: 880.; Vision
   Group on Science and Technology (VGST), India
FX This work was carried out as part of a funded project from Vision Group
   on Science and Technology (VGST), India with GRD number: 880.
CR Aderghal K, 2018, COMP MED SY, P345, DOI 10.1109/CBMS.2018.00067
   Albert MS, 2011, ALZHEIMERS DEMENT, V7, P270, DOI 10.1016/j.jalz.2011.03.008
   Albright J, 2019, ALZH DEMENT-TRCI, V5, P483, DOI 10.1016/j.trci.2019.07.001
   Amin-Naji Mostafa, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P75, DOI 10.1109/PRIA.2019.8786031
   Tran BX, 2019, J CLIN MED, V8, DOI 10.3390/jcm8030360
   Bae J, 2021, NEUROBIOL AGING, V99, P53, DOI 10.1016/j.neurobiolaging.2020.12.005
   Ballard C, 2011, LANCET, V377, P1019, DOI 10.1016/S0140-6736(10)61349-9
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   BECKER JT, 1994, ARCH NEUROL-CHICAGO, V51, P585, DOI 10.1001/archneur.1994.00540180063015
   Beekly DL, 2007, ALZ DIS ASSOC DIS, V21, P249, DOI 10.1097/WAD.0b013e318142774e
   Bi XW, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/8198552
   Binaco R, 2020, J INT NEUROPSYCH SOC, V26, P690, DOI 10.1017/S1355617720000144
   Cabral C, 2015, COMPUT BIOL MED, V58, P101, DOI 10.1016/j.compbiomed.2015.01.003
   Cheng B, 2015, IEEE T BIO-MED ENG, V62, P1805, DOI 10.1109/TBME.2015.2404809
   Chitradevi D, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105857
   Choi JY, 2020, IEEE SIGNAL PROC LET, V27, P206, DOI 10.1109/LSP.2020.2964161
   COX DR, 1972, J R STAT SOC B, V34, P187
   Cox DR., 1984, Analysis of Survival Data
   Crigger E, 2022, J MED SYST, V46, DOI 10.1007/s10916-021-01790-z
   Cui ZY, 2019, IEEE INT C BIOINFORM, P2324, DOI [10.1109/bibm47256.2019.8983046, 10.1109/BIBM47256.2019.8983046]
   Cuingnet R, 2011, NEUROIMAGE, V56, P766, DOI 10.1016/j.neuroimage.2010.06.013
   Davatzikos C, 2011, NEUROBIOL AGING, V32, DOI 10.1016/j.neurobiolaging.2010.05.023
   De Simone MS, 2020, J NEUROL, V267, P113, DOI 10.1007/s00415-019-09559-8
   De Simone MS, 2019, J NEUROL, V266, P102, DOI 10.1007/s00415-018-9108-0
   De Simone MS, 2017, J NEUROL, V264, P2258, DOI 10.1007/s00415-017-8623-8
   Di Lorenzo F, 2020, BRAIN STIMUL, V13, P1175, DOI 10.1016/j.brs.2020.05.013
   Ding Y, 2019, RADIOLOGY, V290, P456, DOI 10.1148/radiol.2018180958
   Dunham I, 2012, NATURE, V489, P57, DOI 10.1038/nature11247
   Ebrahimi-Ghahnavieh A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, ARTIFICIAL INTELLIGENCE, AND COMMUNICATIONS TECHNOLOGY (IAICT), P133, DOI [10.1109/iciaict.2019.8784845, 10.1109/ICIAICT.2019.8784845]
   Edgar R, 2002, NUCLEIC ACIDS RES, V30, P207, DOI 10.1093/nar/30.1.207
   El-Sappagh S, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8439655
   El-Sappagh S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82098-3
   Engedal K, 2020, DEMENT GERIATR COGN, V49, P38, DOI 10.1159/000508392
   Fabrizio C, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11081473
   Fang XS, 2020, IET IMAGE PROCESS, V14, P318, DOI 10.1049/iet-ipr.2019.0617
   Fedorov A, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), DOI 10.1109/bhi.2019.8834630
   Fenoglio C, 2018, J ALZHEIMERS DIS, V62, P913, DOI 10.3233/JAD-170702
   Fisher CK, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-49656-2
   Forloni G, 2020, BMJ NEUROL OPEN, V2, DOI 10.1136/bmjno-2020-000079
   Fouladvand S, 2019, IEEE INT C BIOINFORM, P799, DOI [10.1109/bibm47256.2019.8982955, 10.1109/BIBM47256.2019.8982955]
   Franzmeier N, 2020, ALZHEIMERS DEMENT, V16, P501, DOI 10.1002/alz.12032
   Frazer KA, 2009, NAT REV GENET, V10, P241, DOI 10.1038/nrg2554
   Gamberger D, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-06624-y
   Gamberger D, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-016-0183-0
   Ganasegeran K, 2021, Handbook of decision support systems for neurological disorders, P71
   Gao J, 2020, NEURAL COMPUT, V32, P829, DOI 10.1162/neco_a_01273
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   Gatz M, 2006, ARCH GEN PSYCHIAT, V63, P168, DOI 10.1001/archpsyc.63.2.168
   Giorgio J, 2020, NEUROIMAGE-CLIN, V26, DOI 10.1016/j.nicl.2020.102199
   Giulietti G, 2018, J MAGN RESON IMAGING, V48, P767, DOI 10.1002/jmri.25947
   Gorriz JM, 2008, IEEE NUCL SCI S MED, P4392, DOI DOI 10.1109/NSSMIC.2008.4774255
   Grassi M, 2019, FRONT NEUROL, V10, DOI 10.3389/fneur.2019.00756
   Grundman M, 2004, ARCH NEUROL-CHICAGO, V61, P59, DOI 10.1001/archneur.61.1.59
   Gu K, 2020, IEEE T INSTRUM MEAS, V69, P660, DOI 10.1109/TIM.2019.2905904
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   Guo JM, 2019, IEEE INT CONF BIG DA, P5359
   Haider F, 2020, IEEE J-STSP, V14, P272, DOI 10.1109/JSTSP.2019.2955022
   Hampel H, 2021, AGEING RES REV, V69, DOI 10.1016/j.arr.2021.101346
   Hampel H, 2019, J ALZHEIMERS DIS, V68, P1, DOI 10.3233/JAD-181121
   Hao XK, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101625
   Harrer S, 2019, TRENDS PHARMACOL SCI, V40, P577, DOI 10.1016/j.tips.2019.05.005
   He JX, 2019, NAT MED, V25, P30, DOI 10.1038/s41591-018-0307-0
   Hjelm R.D., 2019, P 7 INT C LEARNING R
   Jabason E, 2019, MIDWEST SYMP CIRCUIT, P481, DOI 10.1109/MWSCAS.2019.8884939
   Jack CR, 2018, ALZHEIMERS DEMENT, V14, P535, DOI 10.1016/j.jalz.2018.02.018
   Jarrett D, 2020, IEEE J BIOMED HEALTH, V24, P424, DOI 10.1109/JBHI.2019.2929264
   Kavitha M, 2019, 2019 IEEE 11TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA 2019), P89, DOI [10.1109/IWCIA47330.2019.8955006, 10.1109/iwcia47330.2019.8955006]
   Khan NM, 2019, IEEE ACCESS, V7, P72726, DOI 10.1109/ACCESS.2019.2920448
   Kohannim O, 2010, NEUROBIOL AGING, V31, P1429, DOI 10.1016/j.neurobiolaging.2010.04.022
   Ku CS, 2010, J HUM GENET, V55, P403, DOI 10.1038/jhg.2010.55
   Kumar S, 2017, BMC NEUROSCI, V18, DOI 10.1186/s12868-017-0394-8
   Langa KM, 2014, JAMA-J AM MED ASSOC, V312, P2551, DOI 10.1001/jama.2014.13806
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee E, 2019, NEUROIMAGE, V202, DOI 10.1016/j.neuroimage.2019.116113
   Lee G, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37769-z
   Lee Y, 2018, J AFFECT DISORDERS, V241, P519, DOI 10.1016/j.jad.2018.08.073
   Li F, 2018, COMPUT MED IMAG GRAP, V70, P101, DOI 10.1016/j.compmedimag.2018.09.009
   Li HM, 2019, I S BIOMED IMAGING, P368, DOI 10.1109/ISBI.2019.8759397
   Li HM, 2019, ALZHEIMERS DEMENT, V15, P1059, DOI 10.1016/j.jalz.2019.02.007
   Li Shanshan, 2013, Am J Alzheimers Dis (Columbia), V2, P12
   Lin WM, 2020, FRONT AGING NEUROSCI, V12, DOI 10.3389/fnagi.2020.00077
   Liu K, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00033
   Liu MX, 2020, IEEE T CYBERNETICS, V50, P3381, DOI 10.1109/TCYB.2019.2904186
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Liu SQ, 2015, IEEE T BIO-MED ENG, V62, P1132, DOI 10.1109/TBME.2014.2372011
   Lulu Yue, 2018, 2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P228, DOI 10.1109/FSKD.2018.8687207
   Marcus DS, 2007, J COGNITIVE NEUROSCI, V19, P1498, DOI 10.1162/jocn.2007.19.9.1498
   Martinez-Murcia FJ, 2020, IEEE J BIOMED HEALTH, V24, P17, DOI 10.1109/JBHI.2019.2914970
   Maston GA, 2006, ANNU REV GENOM HUM G, V7, P29, DOI 10.1146/annurev.genom.7.080505.115623
   Mazzocchi F, 2008, EMBO REP, V9, P10, DOI 10.1038/sj.embor.7401147
   McKhann GM, 2011, ALZHEIMERS DEMENT, V7, P263, DOI 10.1016/j.jalz.2011.03.005
   Mishra R, 2020, AGING DIS, V11, P1567, DOI 10.14336/AD.2020.0312
   Mitchell T.M., 1997, Machine Learning, P432, DOI DOI 10.5555/541177
   Mitelpunkt A, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-57785-2
   Moradi E, 2015, NEUROIMAGE, V104, P398, DOI 10.1016/j.neuroimage.2014.10.002
   Neff RA, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abb5398
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan D, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00259
   Petersen RC, 2018, NEUROLOGY, V91, P395, DOI 10.1212/WNL.0000000000006088
   Platero C, 2021, BRAIN IMAGING BEHAV, V15, P1728, DOI 10.1007/s11682-020-00366-8
   Popescu SG, 2020, Alzheimer's disease neuroimaging initiative nonlinear biomarker interactions in conversion from mild cognitive impairment to Alzheimer's disease Hum Brain Mapp
   Pusil S, 2019, NEUROIMAGE-CLIN, V24, DOI 10.1016/j.nicl.2019.101972
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Rathore S, 2017, NEUROIMAGE, V155, P530, DOI 10.1016/j.neuroimage.2017.03.057
   Rosenberg PB, 2008, WORLD PSYCHIATRY, V7, P72
   Salas-Gonzalez D, 2009, LECT NOTES COMPUT SC, V5507, P418, DOI 10.1007/978-3-642-03040-6_51
   Schneider G, 2018, NAT REV DRUG DISCOV, V17, P97, DOI 10.1038/nrd.2017.232
   Senanayake U, 2018, I S BIOMED IMAGING, P1394, DOI 10.1109/ISBI.2018.8363832
   Spalletta G, 2014, CORTEX, V61, P183, DOI 10.1016/j.cortex.2014.10.010
   Spasov S, 2019, NEUROIMAGE, V189, P276, DOI 10.1016/j.neuroimage.2019.01.031
   Sperling RA, 2011, ALZHEIMERS DEMENT, V7, P280, DOI 10.1016/j.jalz.2011.03.003
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Subetha T., 2020, Int Conference Computational Intell Smart Power System SustainEnergy (CISPSSE), V2020, P1, DOI [10.1109/CISPSSE49931.2020.9212240, DOI 10.1109/CISPSSE49931.2020.9212240]
   Sudlow C, 2015, PLOS MED, V12, DOI 10.1371/journal.pmed.1001779
   Taqi AM, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P140, DOI 10.1109/MIPR.2018.00032
   Telenti A, 2018, HUM MOL GENET, V27, pR63, DOI 10.1093/hmg/ddy115
   Termine A, 2021, J PERS MED, V11, DOI 10.3390/jpm11040280
   Thung KH, 2018, MED IMAGE ANAL, V45, P68, DOI 10.1016/j.media.2018.01.002
   Tibshirani R, 1997, STAT MED, V16, P385, DOI 10.1002/(SICI)1097-0258(19970228)16:4<385::AID-SIM380>3.0.CO;2-3
   Tolar M, 2021, INT J MOL SCI, V22, DOI 10.3390/ijms22126355
   Tong T, 2017, IEEE T BIO-MED ENG, V64, P155, DOI 10.1109/TBME.2016.2549363
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
   Vougas K, 2019, PHARMACOL THERAPEUT, V203, DOI 10.1016/j.pharmthera.2019.107395
   Walhovd KB, 2010, AM J NEURORADIOL, V31, P347, DOI 10.3174/ajnr.A1809
   Waring J, 2020, ARTIF INTELL MED, V104, DOI 10.1016/j.artmed.2020.101822
   Webb S, 2018, NATURE, V554, P555, DOI 10.1038/d41586-018-02174-z
   Westman E, 2012, NEUROIMAGE, V62, P229, DOI 10.1016/j.neuroimage.2012.04.056
   Williamson J, 2009, NEUROLOGIST, V15, P80, DOI 10.1097/NRL.0b013e318187e76b
   Wirth R., 2000, Proceedings of the Fourth International Conference on the Practical Application of Knowledge Discovery and Data Mining, P29
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xu Y, 2021, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.617537
   Yan Y, 2019, NUCL MED COMMUN, V40, P242, DOI 10.1097/MNM.0000000000000953
   Young AL, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-05892-0
   Zhang M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0168812
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhao X, 2019, I S BIOMED IMAGING, P1598, DOI [10.1109/isbi.2019.8759256, 10.1109/ISBI.2019.8759256]
   Zitnik M, 2019, INFORM FUSION, V50, P71, DOI 10.1016/j.inffus.2018.09.012
NR 138
TC 2
Z9 2
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 7
PY 2023
DI 10.1007/s11042-023-16928-z
EA OCT 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2OY9
UT WOS:001096913600014
DA 2024-07-18
ER

PT J
AU El Jurdi, R
   Sekkat, AR
   Dupuis, Y
   Vasseur, P
   Honeine, P
AF El Jurdi, Rosana
   Sekkat, Ahmed Rida
   Dupuis, Yohan
   Vasseur, Pascal
   Honeine, Paul
TI Fully residual Unet-based semantic segmentation of automotive fisheye
   images: a comparison of rectangular and deformable convolutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fisheye image segmentation; Multi-view data augmentation; Deformable
   convolutions; Deep convolutional neural networks
AB Semantic image segmentation is an essential task for autonomous vehicles and self-driving cars where a complete and real-time perception of the surroundings is mandatory. Convolutional Neural Network approaches for semantic segmentation standout over other state-of-the-art solutions due to their powerful generalization ability over unknown data and end-to-end training. Fisheye images are important due to their large field of view and ability to reveal information from broader surroundings. Nevertheless, they pose unique challenges for CNNs, due to object distortion resulting from the Fisheye lens and object position. In addition, large annotated Fisheye datasets required for CNN training is rather limited. In this paper, we investigate the use of Deformable convolutions in accommodating distortions within Fisheye image segmentation for fully residual U-net by learning unknown geometric transformations via variable shaped and sized filters. The proposed models and integration strategies are exploited within two main paradigms: single(front)-view and multi-view Fisheye images segmentation. The validation of the proposed methods is conducted on synthetic and real Fisheye images from the WoodScape and the SynWoodScape datasets. The results validate the significance of the Deformable fully residual U-Net structure in learning unknown geometric distortions in both paradigms, demonstrate the possibility in learning view-agnostic distortion properties when trained on the multi-view data and shed light on the role of surround-view images in increasing segmentation performance relative to the single view. Finally, our experiements suggests that Deformable convolutions are a powerful tool that can increase the efficiency of fully residual U-Nets for semantic segmentation of automotive fisheye images.
C1 [El Jurdi, Rosana; Sekkat, Ahmed Rida; Honeine, Paul] Univ Rouen Normandy, LITIS, Rouen, France.
   [El Jurdi, Rosana] Sorbonne Univ, Inst Cerveau, Paris Brain Inst, Paris, France.
   [Sekkat, Ahmed Rida] IAV GmbH, Berlin, Germany.
   [Dupuis, Yohan] CESI LINEACT, CESI, St etienne du rouvray, France.
   [Vasseur, Pascal] Univ Picardie Jules Verne, MIS, Amiens, France.
C3 Universite de Rouen Normandie; Sorbonne Universite; IAV GmbH; Universite
   de Picardie Jules Verne (UPJV)
RP El Jurdi, R (corresponding author), Univ Rouen Normandy, LITIS, Rouen, France.; El Jurdi, R (corresponding author), Sorbonne Univ, Inst Cerveau, Paris Brain Inst, Paris, France.
EM rosana.eljurdi@icm-institute.org; ahmed.rida.sekkat@iav.de;
   ydupuis@cesi.fr; pascal.vasseur@u-picardie.fr;
   paul.honeine@univ-rouen.fr
OI El Jurdi, Rosana/0000-0003-0509-9620; SEKKAT, Ahmed
   Rida/0000-0002-8075-0383
FU The authors would like to acknowledge the ANR (Project APi, grant
   ANR-18-CE23-0014) for funding this project and the CRIANN for providing
   computational resources. This work was funded in part by the French
   government under management of Agence Nationale de [ANR-18-CE23-0014];
   ANR [ANR-19-P3IA-0001, ANR-10-IAIHU-06]; French government under
   management of Agence Nationale de la Recherche as part of the
   "Investissements d'avenir" program
FX The authors would like to acknowledge the ANR (Project APi, grant
   ANR-18-CE23-0014) for funding this project and the CRIANN for providing
   computational resources. This work was funded in part by the French
   government under management of Agence Nationale de la Recherche as part
   of the "Investissements d'avenir" program, reference ANR-19-P3IA-0001
   (PRAIRIE 3IA Institute) and ANR-10-IAIHU-06.
CR Ahmad O, 2022, AAAI CONF ARTIF INTE, P5968
   Blott G, 2019, LECT NOTES COMPUT SC, V11129, P181, DOI 10.1007/978-3-030-11009-3_10
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Cheng ZY, 2022, LECT NOTES COMPUT SC, V13698, P514, DOI 10.1007/978-3-031-19839-7_30
   Cohen TS, 2016, PR MACH LEARN RES, V48
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng LY, 2020, IEEE T INTELL TRANSP, V21, P4350, DOI 10.1109/TITS.2019.2939832
   Deng LY, 2017, IEEE INT VEH SYM, P231, DOI 10.1109/IVS.2017.7995725
   Eder M, 2020, P IEEECVF C COMPUTER, P12426
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Hu X, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3139710
   Huang Y, 2020, COMPANION OF THE 2020 IEEE 20TH INTERNATIONAL CONFERENCE ON SOFTWARE QUALITY, RELIABILITY, AND SECURITY (QRS-C 2020), P221, DOI 10.1109/QRS-C51114.2020.00045
   Jeon YH, 2017, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2017.200
   Jiang C. M., 2019, ARXIV190102039
   Kervadec H, 2019, PR MACH LEARN RES, V102, P285
   Kumar VR, 2023, Arxiv, DOI arXiv:2102.07448
   Liang JM, 2023, Arxiv, DOI arXiv:2305.02187
   Liu D, 2021, arXiv, DOI DOI 10.48550/ARXIV.2103.10284
   Playout C, 2021, arXiv
   Quan TM, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.613981
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sáez A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030503
   Sáez A, 2018, IEEE INT VEH SYM, P1039, DOI 10.1109/IVS.2018.8500456
   Salahuddin Z, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105111
   Sekkat AR, 2022, IEEE ROBOT AUTOM LET, V7, P8502, DOI 10.1109/LRA.2022.3188106
   Sekkat AR, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-08466-9
   Sekkat AR, 2020, IEEE INT CONF ROBOT, P1603, DOI [10.1109/ICRA40945.2020.9197144, 10.1109/icra40945.2020.9197144]
   Wang W., 2023, 11 INT C LEARN REPR
   Wang W., 2022, Advances in Neural Information Processing Systems
   Xie EZ, 2021, ADV NEUR IN, V34
   Yin XQ, 2018, LECT NOTES COMPUT SC, V11214, P475, DOI 10.1007/978-3-030-01249-6_29
   Yogamani S, 2019, IEEE I CONF COMP VIS, P9307, DOI 10.1109/ICCV.2019.00940
NR 35
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16627-9
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Seetha, J
   Ramanathan, R
   Goyal, V
   Tholkapiyan, M
   Karthikeyan, C
   Kumar, R
AF Seetha, J.
   Ramanathan, Ramakrishnan
   Goyal, Vishal
   Tholkapiyan, M.
   Karthikeyan, C.
   Kumar, Ravi
TI Mango leaf disease classification using hybrid Coyote-Grey Wolf
   optimization tuned neural network model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mango leaf; Disease; Neural network; Optimization; Classification
AB The identification of diseases in plants contributes an important role in captivating disease control methods for the improvement of quality and quantity of crop yield. Mango trees are affected by different diseases and the identification of diseases is a tedious task till now when those diseases are manually detected. This paper proposes the novel hybrid Coyote Grey Wolf optimization (CO-GWO) algorithm for the classification of mango leaves as normal or diseased. The classification process is done through the extraction of significant features from the segmented image. The Neural network (NN) classifier performs the classification task, with the weights being adjusted using the proposed algorithm that acts a major role in the enhancement of the classification accuracy. The effectiveness of the proposed model is evaluated concerning the evaluation metrics, namely accuracy, precision, recall, and F1 measure, and is attained to be 96.7111%, 97.5712%, 97.1504%, and 96.4792%, respectively. This shows the superiority of the proposed technique in the effective classification of mango leaf classification as compared with the existing techniques.
C1 [Seetha, J.] SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 600089, India.
   [Ramanathan, Ramakrishnan] Deemed Be Univ Vadlamudi, Vignans Fdn Sci, Dept IT Technol & Res, Guntur 522213, Andhra Pradesh, India.
   [Goyal, Vishal] GLA Univ, Dept ECE, Mathura, Uttar Pradesh, India.
   [Tholkapiyan, M.] Saveetha Inst Med & Tech Sci SIMATS, Saveetha Sch Engn, Dept Civil Engn, Chennai 602105, Tamil Nadu, India.
   [Karthikeyan, C.] Deemed to Be Univ, Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Guntur 522502, Andhra Pradesh, India.
   [Kumar, Ravi] Jaypee Univ Engn & Technol, Dept ECE, Guna 473226, India.
C3 SRM Institute of Science & Technology Chennai; GLA University; Saveetha
   Institute of Medical & Technical Science; Saveetha School of
   Engineering; Koneru Lakshmaiah Education Foundation (K L Deemed to be
   University)
RP Seetha, J (corresponding author), SRM Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 600089, India.
EM seetha.vital@gmail.com
RI KUMAR, RAVI/J-5961-2013; C, Karthikeyan Dr./M-5711-2018; Ramanathan,
   Ramakrishnan/HTL-2655-2023
OI KUMAR, RAVI/0000-0001-9922-9064; Ramanathan,
   Ramakrishnan/0000-0002-2995-9309
CR Arivazhagan S., 2018, INT J PURE APPL MATH, V120, P11067
   Bhadra S, 2022, Handbook of health and well-being: challenges, strategies and future trends, P637
   Chakma S, 2022, Agro-biodiversity and Agri-ecosystem Management, P217
   Chakraborti T, 2018, IEEE SIGNAL PROC LET, V25, P635, DOI 10.1109/LSP.2018.2817176
   Chouhan SS, 2020, WIRELESS PERS COMMUN, V113, P1279, DOI 10.1007/s11277-020-07279-1
   Deeba K, 2020, Microprocess Microsyst, Patent No. 103364
   Faris H, 2018, NEURAL COMPUT APPL, V30, P413, DOI 10.1007/s00521-017-3272-5
   Garg R, 2023, INT C DISR TECHN ICD
   Gining RAJM., 2021, IJEECS, V23, P378, DOI [10.11591/ijeecs.v23.i1.pp378-386, DOI 10.11591/IJEECS.V23.I1.PP378-386]
   Gurumita NG, 2022, IEEE INT C DAT SCI I
   Indriani OR, 2017, 2017 INT C INN CREAT, P1
   Jabid T, 2010, IEEE ICCE
   Jain S., 2023, INT C POW INSTR EN C, P1
   Jhuria M, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P521, DOI 10.1109/ICIIP.2013.6707647
   Kandegama W. M. Wishwajith W., 2022, Food security and climate-smart food systems: building resilience for the Global South, P67, DOI 10.1007/978-3-030-92738-7_5
   Kour VP, 2019, IEEE ACCESS, V7, P29374, DOI 10.1109/ACCESS.2019.2901900
   Kumar P., 2023, Agroforestry for Sustainable Intensification of Agriculture in Asia and Africa, P429, DOI [10.1007/978-981-19-4602-8_14, DOI 10.1007/978-981-19-4602-8_14]
   Kumar SR, 2016, International Journal of Advanced Research in Electrical, Electronics and Instrumentation, VEngineering5, P4556
   Kumari S, 2022, 11 INT C SYST MOD AD
   Ma YW, 2022, IT PROF, V24, P74, DOI 10.1109/MITP.2022.3205707
   Mahbub NI, 2023, INT C EL COMP COMM E
   Mia MR., 2020, IRAN J COMPUTER SCI, V3, P185, DOI DOI 10.1007/S42044-020-00057-Z
   Mohapatra M, 2022, COMPUTERS, V11, DOI 10.3390/computers11050082
   Mohapatra Madhumini, 2022, INT C ADV SMART SEC
   Molina-Cárdenas L, 2023, PLANT DIS, V107, P581, DOI 10.1094/PDIS-05-22-1213-PDN
   Mutengwa CS, 2023, SUSTAINABILITY-BASEL, V15, DOI 10.3390/su15042882
   Pierezan J, 2018, IEEE C EVOL COMPUTAT, P2633, DOI 10.1109/CEC.2018.8477769
   Prasetyo E, 2018, 2018 INTERNATIONAL SEMINAR ON INTELLIGENT TECHNOLOGY AND ITS APPLICATIONS (ISITIA 2018), P317, DOI 10.1109/ISITIA.2018.8711115
   Rahaman M., 2023, Int. J. Comput. Dig. Syst, V13, P1
   Rajbongshi A., 2021, Indones. J. Electr. Eng. Comput. Sci., V23, P1681
   Rao PRK., 2020, PalArch's Journal of Archaeology of Egypt/Egyptology, V17, P10567
   Sanath Rao U., 2021, GLOBAL TRANSITIONS P, V2, P535, DOI [10.1016/j.gltp.2021.08.002, DOI 10.1016/J.GLTP.2021.08.002]
   Saravanan TM, 2023, 2023 INT C COMP COMM
   Selvakumar A, 2024, IMAGING SCI J, V72, P285, DOI 10.1080/13682199.2023.2204036
   Sharma A, 2023, IEEE 12 INT C COMM S
   Vinay Gautam, 2023, Multimed Tools Appl1-27
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16964-9
EA OCT 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U0GP6
UT WOS:001081680200017
DA 2024-07-18
ER

PT J
AU Chakraborty, T
   Bhattacharyya, R
   Das, N
   Basu, S
   Nasipuri, M
AF Chakraborty, Tapas
   Bhattacharyya, Rudrajit
   Das, Nibaran
   Basu, Subhadip
   Nasipuri, Mita
TI MAuD: a multivariate audio database of samples collected from benchmark
   conferencing platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Voice calling platforms; Audio conferencing; Deep learning; CNN; ResNet;
   DenseNet; Signal processing
ID SPEAKER; RECOGNITION; MACHINES
AB This paper presents an unique audio database, we named it Multivariate Audio Database (MAuD), where audio data has been collected in real life scenarios. MAuD contains 229 audio files, each of duration approx 5 minutes, collected across different conferencing apps, spoken languages, background noises and discussion topics. Various audio conferencing applications have been used for collecting these data e.g. Mobile conference calls, Zoom, Google Meet, Skype and Hangout. During this collection, speakers of different age, sex spoke in several languages and on various topics. Audio was recorded using devices of one of the speakers. Background noises were then introduced synthetically. Researchers may find this database useful as it can be used for several signal processing experiments e.g. conference app identification, background noise identification, speaker identification, identification of who speaks when. We have explored classification of some of the above mentioned mismatch cases (conference app and background noise). Pre-trained deep learning models (ResNet18 and DenseNet201) has been used for these purposes. We have achieved more than 98% accuracy in both the experiments that confirms MAuD contains high quality audio specific properties.
C1 [Chakraborty, Tapas; Bhattacharyya, Rudrajit; Das, Nibaran; Basu, Subhadip; Nasipuri, Mita] Jadavpur Univ, Kolkata 700032, India.
C3 Jadavpur University
RP Chakraborty, T (corresponding author), Jadavpur Univ, Kolkata 700032, India.
EM tapasc.cse.rs@jadavpuruniversity.in; rudrajitb24@gmail.com;
   nibaran.das@jadavpuruniversity.in; subhadip.basu@jadavpuruniversity.in;
   mita.nasipuri@jadavpuruniversity.in
OI CHAKRABORTY, TAPAS/0000-0003-0026-6426
FU CMATER laboratory of the Computer Science and Engineering Department,
   Jadavpur University, India
FX This project is partially supported by the CMATER laboratory of the
   Computer Science and Engineering Department, Jadavpur University, India.
   We acknowledge the contribution of Ms Adrita Chakrabarti for assisting
   in the data collection process.
CR Aronowitz H, 2010, INT CONF ACOUST SPEE, P4402, DOI 10.1109/ICASSP.2010.5495629
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Barai B, 2022, INT J SPEECH TECHNOL, V25, P173, DOI 10.1007/s10772-021-09899-9
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Canavan A., 1997, CALLHOME AM ENGLISH, DOI 10.35111/exq3-x930
   Chakraborty Tapas, 2021, Figshare, DOI 10.6084/m9.figshare.14731629.v1
   Chakraborty T, 2020, ADV INTELL SYST COMP, V1034, P291, DOI 10.1007/978-981-15-1084-7_28
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Esmaeilpour M, 2022, APPL ACOUST, V195, DOI 10.1016/j.apacoust.2022.108817
   Fujihara H, 2006, 9 INT C SPOK LANG PR
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Ghahabi O, 2018, COMPUT SPEECH LANG, V47, P16, DOI 10.1016/j.csl.2017.06.007
   Godfrey J., 1993, Switchboard-1 release 2
   Haris B, 2011, COMM NCC 2011 NAT C, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey S., 2017, arXiv
   Jumelle M, 2018, Arxiv, DOI arXiv:1803.08276
   Madikeri S, 2015, INT CONF ACOUST SPEE, P4435, DOI 10.1109/ICASSP.2015.7178809
   McFee B., 2015, P 14 PYTH SCI C, P18, DOI [DOI 10.25080/MAJORA-7B98E3ED-003, 10.25080/Majora-7b98e3ed-003]
   Mesaros A, 2016, EUR SIGNAL PR CONF, P1128, DOI 10.1109/EUSIPCO.2016.7760424
   Piczak Karol J., 2015, ESC: Dataset for Environmental Sound Classification, DOI DOI 10.7910/DVN/YDEPUT
   Rao KS, 2014, SPRBRIEF ELECT, P1, DOI 10.1007/978-3-319-07130-5
   Ren J, 2016, AAAI CONF ARTIF INTE, P3581
   Robotham T, 2022, 2022 14 INT C QUAL M, P1
   Rose P, 2006, COMPUT SPEECH LANG, V20, P159, DOI 10.1016/j.csl.2005.07.003
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Singh N, 2012, PROCEDIA ENGINEER, V38, P3122, DOI 10.1016/j.proeng.2012.06.363
   Yamada T, 2013, INTERSPEECH, P3628
   Zheng J, 2022, Discrete Dynamics in Nature and Society
NR 29
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16879-5
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900013
DA 2024-07-18
ER

PT J
AU Wang, HC
   Putra, CD
   Wu, CY
AF Wang, Hei -Chia
   Putra, Cendra Devayana
   Wu, Chia-Ying
TI A recurrent stick breaking topic model for argument stance detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Argument Mining; Neural Topic Model; Stance Detection
AB Debate websites are valuable social media platforms for discussing controversial issues and gaining insights into diverse perspectives. However, with thousands of arguments on popular topics, browsing through entire discussions can be too time-consuming to extract a summary of the main viewpoints. To address this challenge, natural language processing techniques have been proposed to automatically identify argument structures and determine a user's stance on an issue. In addition to detecting stances, identifying topics that remain contentious between factions is especially important for policy-makers. However, the topics discussed by users with the same stance may vary in importance. To extract potential text topics, models based on probability and neural topic models have been proposed, with the latter being more effective due to improved computational cost and the ability to extract more consistent topics. This research proposes a two-stage stance detection model, which combines a neural topic model based on variational autoencoder and a recurrent neural network to learn the characteristics of an argument and enhance the model with subtopic features. The experimental results show that the model can obtain more coherent subtopics with a coherence of 0.42, and achieve an accuracy of nearly 70% in stance detection, demonstrating the effectiveness of the subtopic feature detection process.
C1 [Wang, Hei -Chia; Putra, Cendra Devayana; Wu, Chia-Ying] Natl Cheng Kung Univ, Inst Informat Management, Tainan 701, Taiwan.
   [Wang, Hei -Chia] Natl Cheng Kung Univ, Ctr Innovat FinTech Business Models, Tainan 701, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University
RP Wang, HC (corresponding author), Natl Cheng Kung Univ, Inst Informat Management, Tainan 701, Taiwan.; Wang, HC (corresponding author), Natl Cheng Kung Univ, Ctr Innovat FinTech Business Models, Tainan 701, Taiwan.
EM hcwang@mail.ncku.edu.tw; r78117012@gs.ncku.edu.tw; ying33119@gmail.com
OI Putra, Cendra Devayana/0000-0002-5692-9762
FU Taiwan Ministry of Science and Technology [MOST 107-2410-H-006 040-MY3,
   MOST 108-2511-H-0 06-009]; "Higher Education SPROUT Project" and "Center
   for Innovative Fin-Tech Business Models" of National Cheng Kung
   University (NCKU); Ministry of Education, Taiwan
FX The research is based on work supported by Taiwan Ministry of Science
   and Technology under Grant No. MOST 107-2410-H-006 040-MY3 and MOST
   108-2511-H-0 06-009. We would like to thank partially research grant
   supported by "Higher Education SPROUT Project" and "Center for
   Innovative Fin-Tech Business Models" of National Cheng Kung University
   (NCKU), sponsored by the Ministry of Education, Taiwan
CR Abbott R, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P4445
   ALDayel A, 2021, INFORM PROCESS MANAG, V58, DOI 10.1016/j.ipm.2021.102597
   [Anonymous], 2022, Multimedia Tools and Applications, P1
   [Anonymous], 2016, Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers
   Augenstein I., 2016, P 2016 C EMP METH NA, P876
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang  J., 2009, ADV NEURAL INFORM PR, P288, DOI DOI 10.5555/2984093.2984126
   Ding R, 2018, Arxiv, DOI arXiv:1809.02687
   Du JC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3988
   Ebrahimi J, 2016, P COLING 2016 26 INT, P1250
   Feng JC, 2020, Arxiv, DOI arXiv:2008.04545
   Ghannay S, 2016, LREC 2016 - TENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P300
   Hamad O, 2022, BIG DATA COGN COMPUT, V6, DOI 10.3390/bdcc6030088
   He RD, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P388, DOI 10.18653/v1/P17-1036
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jain PK, 2022, J Ambient Intell Human Comput, P10429
   Jain PK, 2023, EXPERT SYST, V40, DOI 10.1111/exsy.13247
   Jain PK, 2022, MULTIMED TOOLS APPL, V81, P6979, DOI 10.1007/s11042-022-11972-7
   Jain PK, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107397
   Jelodar H, 2021, MULTIMED TOOLS APPL, V80, P4155, DOI 10.1007/s11042-020-09755-z
   Justo R, 2014, KNOWL-BASED SYST, V69, P124, DOI 10.1016/j.knosys.2014.05.021
   Kumaran P, 2023, MULTIMED TOOLS APPL, V82, P8943, DOI 10.1007/s11042-021-11855-3
   Miao YS, 2018, Arxiv, DOI arXiv:1706.00359
   Miao YS, 2016, PR MACH LEARN RES, V48
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Ng LHX, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.103070
   Norouzi R, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/6536908
   O Jin, 2011, P 20 ACM INT C INF K
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rezende DJ, 2014, INT C MACH LEARN BEI, P1401
   Rostami M, 2023, IEEE ACCESS, V11, P30247, DOI 10.1109/ACCESS.2023.3260652
   Sasaki Akira, 2018, P 27 INT C COMP LING, P3381
   Seok M., 2016, INT J STW ENG APPL, V10, P93, DOI [DOI 10.14257/ijseia.2016.10.2.08, DOI 10.14257/IJSEIA.2016.10.2.08]
   SETHURAMAN J, 1994, STAT SINICA, V4, P639
   Sheikhpour R, 2023, KNOWL-BASED SYST, V269, DOI 10.1016/j.knosys.2023.110521
   Srivastava A, 2017, Arxiv, DOI arXiv:1703.01488
   Sun QY, 2016, LECT NOTES COMPUT SC, V10102, P840, DOI 10.1007/978-3-319-50496-4_76
   Thonet T, 2016, EUR C INF RETR, P9626
   Vilares David., 2017, P 2017 C EMPIRICAL M, P1573
   Wang ZQ, 2020, IEEE-ACM T AUDIO SPE, V28, P635, DOI 10.1109/TASLP.2020.2963954
   Wei W., 2016, P 10 INT WORKSH SEM, P384, DOI 10.18653/v1/S16-1062
   Xu C, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P778
   Zhao YY, 2016, MULTIMED TOOLS APPL, V75, P8843, DOI 10.1007/s11042-014-2184-y
   Zhu QL, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4663
   Zulqarnain M, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-13339-4
NR 46
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 4
PY 2023
DI 10.1007/s11042-023-16829-1
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2UQ2
UT WOS:001076590000001
DA 2024-07-18
ER

PT J
AU Kumar, V
AF Kumar, Vijay
TI Advancements in arithmetic optimization algorithm: theoretical
   foundations, variants, and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Arithmetic optimization algorithm; Metaheuristic; Population;
   Exploration; Exploitation
ID POWER POINT TRACKING; FREQUENCY STABILITY; SEARCH; IDENTIFICATION;
   PARAMETERS; ENSEMBLE; MACHINE; SYSTEMS
AB Arithmetic optimization algorithm (AOA) is a population-based metaheuristic algorithm that mimics the properties of primitive arithmetic operators. Researchers were attracted to AOA after its development in 2021. It has been extensively applied across several research domains. This study presents a thorough analysis of the AOA. The mathematical modelling of AOA and its inspiration are discussed. The variants of AOA namely improved, binary, chaotic, hybrid, and multi-objective are investigated in detail. The applications of AOA and its variants in numerous research domain are discussed. The possible research directions for AOA are examined. The young researchers will be assisted by this study in comprehending the fundamental ideas of AOA and in applying this knowledge to their own research issues.
C1 [Kumar, Vijay] Dr B R Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar
RP Kumar, V (corresponding author), Dr B R Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, India.
EM vijaykumarchahar@gmail.com
RI Chahar, Vijay Kumar/A-2782-2015
OI Chahar, Vijay Kumar/0000-0002-3460-6989
CR Abbassi A, 2022, OPTIK, V253, DOI 10.1016/j.ijleo.2022.168600
   Abd Elaziz M, 2022, COGN COMPUT, V14, P2274, DOI 10.1007/s12559-022-10022-6
   Abd Elaziz M, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/9114113
   Abdel-mawgoud H, 2022, IRAN CONF RENEW ENER, DOI 10.1109/ICREDG54199.2022.9804522
   Abdel-Mawgoud H, 2022, J ENERGY STORAGE, V49, DOI 10.1016/j.est.2022.104154
   Abdulsalami AO., 2023, International Conference on Artificial Intelligence Science and Applications (CAISA), P81, DOI [10.1007/978-3-031-28106-8_6, DOI 10.1007/978-3-031-28106-8_6]
   Abualigah L., 2022, Handbook of Moth-Flame Optimization Algorithm, P209, DOI [10.1201/9781003205326-14, DOI 10.1201/9781003205326-14]
   Abualigah L, 2022, J Ambient Intell Humaniz Comput, P1
   Abualigah L, 2023, J INTELL MANUF, V34, P3523, DOI 10.1007/s10845-022-02016-w
   Abualigah L, 2022, NEURAL COMPUT APPL, V34, P20939, DOI 10.1007/s00521-022-07571-0
   Abualigah L, 2022, KNOWL-BASED SYST, V248, DOI 10.1016/j.knosys.2022.108833
   Abualigah L, 2022, ENG ANAL BOUND ELEM, V138, P13, DOI 10.1016/j.enganabound.2022.01.014
   Abualigah L, 2022, NEURAL COMPUT APPL, V34, P8823, DOI 10.1007/s00521-022-06906-1
   Abualigah L, 2023, J INTELL MANUF, V34, P1833, DOI 10.1007/s10845-021-01877-x
   Abualigah L, 2021, PROCESSES, V9, DOI 10.3390/pr9071155
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Agushaka JO, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6871
   Agushaka JO, 2022, J INTELL SYST, V31, P70, DOI 10.1515/jisys-2021-0164
   Agushaka JO, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0255703
   Ahanch M, 2021, 2021 N AM POW S NAPS, P1
   Ahmadi Bahman, 2021, 2021 56 INT U POW EN
   AlJame M, 2023, INT J APPL METAHEURI, V14, DOI 10.4018/IJAMC.318642
   Almalawi A, 2022, CHEMOSPHERE, V303, DOI 10.1016/j.chemosphere.2022.134960
   Alweshah M, 2022, JORDAN J COMPUT INFO, V8, P126, DOI 10.5455/jjcit.71-1639410312
   Anjum ZM, 2022, PLOS ONE, V17, DOI 10.1371/journal.pone.0264958
   Antonijevic M, 2022, 2022 30 TEL FOR TELF, P1
   Ardakani MM, 2022, J SUPERCOMPUT, V78, P16303, DOI 10.1007/s11227-022-04526-z
   Aslan M, 2022, ENERGY REP, V8, P18, DOI 10.1016/j.egyr.2022.06.101
   Aslan S, 2023, NEURAL COMPUT APPL, V35, P10311, DOI 10.1007/s00521-023-08236-2
   Ates A, 2022, Research Square
   Aydemir SB, 2023, EVOL INTELL, V16, P981, DOI 10.1007/s12065-022-00711-4
   Azizi M, 2022, ARTIF INTELL REV, V55, P4041, DOI 10.1007/s10462-021-10101-4
   Bacanin Dzakula N, 2022, SINT 2022 INT SCI C, P406
   Bacanin N, 2023, HELIYON, V9, DOI 10.1016/j.heliyon.2023.e15378
   Bahmanyar D, 2022, KNOWL-BASED SYST, V247, DOI 10.1016/j.knosys.2022.108762
   Bansal P, 2022, MULTIMED TOOLS APPL, V81, P8807, DOI 10.1007/s11042-022-11949-6
   Bas E., 2021, CLUSTER COMPUT, V9, P713, DOI 10.36306/konjes.904335
   Bas Emine, 2022, Research Square
   Bhat SJ, 2022, PEER PEER NETW APPL, V15, P1473, DOI 10.1007/s12083-022-01302-x
   Birbil SI, 2003, J GLOBAL OPTIM, V25, P263, DOI 10.1023/A:1022452626305
   Blum C, 2003, ACM COMPUT SURV, V35, P268, DOI 10.1145/937503.937505
   Bonyadi MR, 2012, OPER RES-GER, V12, P229, DOI 10.1007/s12351-010-0084-0
   Çelik E, 2023, KNOWL-BASED SYST, V260, DOI 10.1016/j.knosys.2022.110169
   Çetinbas I, 2022, IEEE ACCESS, V10, P19254, DOI 10.1109/ACCESS.2022.3151119
   Chakraborty A, 2017, MODEL OPTIM SCI TECH, P475, DOI 10.1007/978-3-319-50920-4_19
   Chandana Guddati Raghavendra Siri, 2022, 2022 4th International Conference on Circuits, Control, Communication and Computing (I4C), P259, DOI 10.1109/I4C57141.2022.10057640
   Chauhan S, 2021, 2021 INT C INT TECHN, P1
   Chauhan S, 2022, J SUPERCOMPUT, V78, P6234, DOI 10.1007/s11227-021-04105-8
   Chen C-Y, 2012, 2012 P 17 C EL POW D, P789, DOI DOI 10.1016/J.ASOC.2015.07.005
   Chen K, 2022, 2022 28 INT C MECH M, P1
   Chen MN, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10122152
   Dahou A, 2022, MEASUREMENT, V199, DOI 10.1016/j.measurement.2022.111445
   Montoya OD, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111680
   Das A, 2023, APPL SOFT COMPUT, V140, DOI 10.1016/j.asoc.2023.110268
   Debnath K, 2022, 2022 IEEE REG 10 S T, P1
   Deepa N, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2021.103455
   Devan PAM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020617
   Dey I, 2023, Int J Numer Model Electron Netw Devices Fields, Ve3105, P1
   Dhal KG, 2023, ARCH COMPUT METHOD E, V30, P3379, DOI 10.1007/s11831-023-09902-3
   Dhawale PG, 2023, T EMERG TELECOMMUN T, V34, DOI 10.1002/ett.4739
   Dhiman G, 2019, KNOWL-BASED SYST, V165, P169, DOI 10.1016/j.knosys.2018.11.024
   Dhiman G, 2018, KNOWL-BASED SYST, V159, P20, DOI 10.1016/j.knosys.2018.06.001
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Do DT., 2022, J SCI TECHNOL CIV EN, V16, P22, DOI [10.31814/stce.huce(nuce)2022-16(2)-03, DOI 10.31814/STCE.HUCE(NUCE)2022-16(2)-03]
   Dokeroglu T, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106040
   Ekinci S, 2022, SOFT COMPUT, V26, P12257, DOI 10.1007/s00500-022-07068-x
   Elkasem AHA, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10060854
   Elkasem AHA, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132112095
   Erdemir E., 2023, Int J Ind Eng Comput, V14, P309
   Ewees AA, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9182321
   Fang HP, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10162875
   Formato RA, 2009, INT J BIO-INSPIR COM, V1, P217, DOI 10.1504/IJBIC.2009.024721
   Ghith ES, 2023, IEEE ACCESS, V11, P27138, DOI 10.1109/ACCESS.2023.3258187
   Gölcük I, 2023, KNOWL-BASED SYST, V263, DOI 10.1016/j.knosys.2023.110274
   Golla NK, 2022, INT J RENEW ENERGY R, V12, P970
   Gul F, 2021, IEEE ACCESS, V9, P107738, DOI 10.1109/ACCESS.2021.3101210
   Guo HB, 2021, ENERG SOURCE PART A, DOI 10.1080/15567036.2021.1966138
   Gürses D, 2021, MATER TEST, V63, P448, DOI 10.1515/mt-2020-0076
   Hamad MW, 2023, AIP C P, V2591
   Hansen N, 2015, SPRINGER HANDBOOK OF COMPUTATIONAL INTELLIGENCE, P871
   Hao WK, 2022, APPL ENERG, V316, DOI 10.1016/j.apenergy.2022.119061
   Hao WK, 2022, APPL INTELL, V52, P11846, DOI 10.1007/s10489-021-03125-4
   Haridasan V, 2023, INTELL AUTOM SOFT CO, V35, P3531, DOI 10.32604/iasc.2023.030628
   Hijjawi M, 2023, PROCESSES, V11, DOI 10.3390/pr11051380
   HOLLAND JH, 1992, SCI AM, V267, P66, DOI 10.1038/scientificamerican0792-66
   Hu G, 2022, COMPUT METHOD APPL M, V394, DOI 10.1016/j.cma.2022.114901
   Hussain K, 2019, ARTIF INTELL REV, V52, P2191, DOI 10.1007/s10462-017-9605-z
   Ibrahim RA, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23091189
   Irshad K, 2023, SUSTAIN ENERGY TECHN, V57, DOI 10.1016/j.seta.2023.103165
   Issa M., 2022, Integrating Meta-Heuristics and Machine Learning for Real-World optimization problems, P399, DOI [10.1007/978-3-030-99079-4_15, DOI 10.1007/978-3-030-99079-4_15]
   Issa M, 2023, ARAB J SCI ENG, V48, P2191, DOI 10.1007/s13369-022-07136-2
   Izci Davut, 2021, 2021 5th International Symposium on Multidisciplinary Studies and Innovative Technologies (ISMSIT), P1, DOI 10.1109/ISMSIT52890.2021.9604531
   Izci D., 2022, 2022 INN INT SYST AP, P1
   Izci D., 2022, P INT JOINT C ADV CO, P283
   Izci D, 2022, SIGMA J ENG NAT SCI, V40, P529, DOI 10.14744/sigma.2022.00056
   Izci D, 2022, EVOL SYST-GER, V13, P453, DOI 10.1007/s12530-021-09402-4
   [贾鹤鸣 Jia Heming], 2022, [计算机科学与探索, Journal of Frontiers of Computer Science & Technology], V16, P1182
   Karthik E, 2022, NEURAL PROCESS LETT, V54, P4123, DOI 10.1007/s11063-022-10797-7
   Kaveh A., 2022, Advanced Metaheuristic Algorithms and their applications in Structural optimization, P323, DOI [10.1007/978-3-031-13429-6_10, DOI 10.1007/978-3-031-13429-6_10]
   Kaveh A., 2021, International Journal of Civil Engineering, V11, P663
   Kaveh A, 2022, STRUCTURES, V35, P748, DOI 10.1016/j.istruc.2021.11.012
   Kennedy J, 2006, Swarm Intelligence, P187, DOI DOI 10.1007/0-387-27705-66
   Khadanga RK, 2023, ISA T, V138, P534, DOI 10.1016/j.isatra.2023.02.025
   Khanduja N, 2021, Studies in computational intelligence, V916
   Kharrich M, 2022, J ENERGY STORAGE, V51, DOI 10.1016/j.est.2022.104343
   Khatir S, 2021, COMPOS STRUCT, V273, DOI 10.1016/j.compstruct.2021.114287
   Khodadadi N, 2022, IEEE ACCESS, V10, P106673, DOI 10.1109/ACCESS.2022.3212081
   Khodadadi N, 2022, IEEE ACCESS, V10, P16188, DOI 10.1109/ACCESS.2022.3146374
   Kong X, 2023, SPIE, V12609, P281
   Krishna Madugula Murali, 2022, Advances in Intelligent Computing and Communication: Proceedings of ICAC 2021. Lecture Notes in Networks and Systems (430), P217, DOI 10.1007/978-981-19-0825-5_23
   Kumar RA, 2022, MATER TODAY-PROC, V64, P435, DOI 10.1016/j.matpr.2022.04.803
   Kumar T., 2023, Inventive Computation and Information Technologies: Proceedings of ICICIT 2022. Lecture Notes in Networks and Systems (563), P563, DOI 10.1007/978-981-19-7402-1_40
   Kumar V, 2014, J COMPUT SCI-NETH, V5, P144, DOI 10.1016/j.jocs.2013.12.001
   Langdon W.B., 2013, Foundations of Genetic Programming
   Li XD, 2023, J INTELL FUZZY SYST, V44, P3527, DOI 10.3233/JIFS-221098
   Li XD, 2022, APPL INTELL, V52, P16718, DOI 10.1007/s10489-021-03037-3
   Lin X, 2021, PROCEEDINGS OF THE 2021 IEEE INTERNATIONAL CONFERENCE ON PROGRESS IN INFORMATICS AND COMPUTING (PIC), P265, DOI 10.1109/PIC53636.2021.9687010
   Liu HY, 2024, SOFT COMPUT, V28, P1127, DOI 10.1007/s00500-023-09153-1
   Liu HY, 2023, EXPERT SYST APPL, V224, DOI 10.1016/j.eswa.2023.119898
   Liu LS, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12091961
   Liu QX, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10091567
   Liu SL, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/1221186
   Liu XQ, 2022, COLOR RES APPL, V47, P644, DOI 10.1002/col.22750
   Liu ZL, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14051011
   Lu P., 2022, Data Science and Management, V5, P163, DOI [https://doi.org/10.1016/J.DSM.2022.08.002, DOI 10.1016/J.DSM.2022.08.002, 10.1016/j.dsm.2022.08.002]
   Madugula MK, 2022, 2022 INT C CONN SYST, P1
   Mahajan S, 2022, SOFT COMPUT, V26, P6749, DOI 10.1007/s00500-022-07079-8
   Mahajan S, 2022, MULTIMED TOOLS APPL, V81, P28755, DOI 10.1007/s11042-022-12922-z
   Mahajan S, 2022, SOFT COMPUT, V26, P4863, DOI 10.1007/s00500-022-06873-8
   Mahmoud MF, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.10.007
   Majdar RS, 2022, INT J IMAGE DATA FUS, V13, P262, DOI 10.1080/19479832.2021.2001051
   Malibari AA, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3987494
   Mandad B, 2023, SMART SCI, V11, P16, DOI 10.1080/23080477.2022.2065593
   Manzoor A., 2023, Discov. Int. Things, V3, P3, DOI 10.1007/s43926-023-00028-3
   Masdari M, 2022, Research Square
   Mi X., 2023, Res Square, DOI [10.21203/rs.3.rs-2876027/v1, DOI 10.21203/RS.3.RS-2876027/V1]
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohamed AA, 2023, SOFT COMPUT, V27, P5769, DOI 10.1007/s00500-022-07805-2
   Mohamed MAE, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-32793-0
   Moher D, 2009, ANN INTERN MED, V151, P264, DOI [10.7326/0003-4819-151-4-200908180-00135, 10.1136/bmj.b2700, 10.1371/journal.pmed.1000097, 10.1186/2046-4053-4-1, 10.1136/bmj.i4086, 10.1136/bmj.b2535, 10.1016/j.ijsu.2010.02.007, 10.1016/j.ijsu.2010.07.299]
   Montano J, 2022, RESULTS ENG, V16, DOI 10.1016/j.rineng.2022.100654
   Nurnajmin QA., 2023, Int J Electr Comput Eng, V13, P2167
   Ozmen H, 2023, Int J Model Simul, P1
   Panga N, 2021, 2021 IEEE MADR SEC C, P1
   Panneer Selvam AMD, 2022, Optimal fractional-order predictive PI controllers: for process control applications with additional filtering, P99
   Pashaei E, 2022, J SUPERCOMPUT, V78, P15598, DOI 10.1007/s11227-022-04507-2
   Pashaei E, 2023, MULTIMED TOOLS APPL, V82, P34725, DOI 10.1007/s11042-023-15025-5
   Patra Dipak Kumar, 2022, Evolution in Computational Intelligence: Proceedings of the 9th International Conference on Frontiers in Intelligent Computing: Theory and Applications (FICTA 2021). Smart Innovation, Systems and Technologies (267), P327, DOI 10.1007/978-981-16-6616-2_31
   Peng L, 2023, NEURAL COMPUT APPL, V35, P7561, DOI 10.1007/s00521-022-08052-0
   Prabu M, 2023, PATTERN ANAL APPL, V26, P367, DOI 10.1007/s10044-022-01086-z
   Premkumar M, 2021, IEEE ACCESS, V9, P84263, DOI 10.1109/ACCESS.2021.3085529
   Ragab M., 2022, Biomedical Data Analysis and Processing using Explainable (XAI) and responsive Artificial Intelligence (RAI), P123, DOI [10.1007/978-981-19-1476-8_9, DOI 10.1007/978-981-19-1476-8_9]
   Ragab M, 2022, CMC-COMPUT MATER CON, V73, P381, DOI 10.32604/cmc.2022.027327
   Rajagopal R, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104197
   Rajendran S, 2022, 2022 3 INT C EM TECH, P1
   Ramya VJ, 2021, Ann Rom Soc Cell Biol, P7333
   Ran TA, 2022, Optimization design of holding poles based on the response surface methodology and the improved arithmetic optimization algorithm, V43, P1113
   Ranjan M, 2022, SMART EN ADV POW TEC, V2, P513
   Ranjan RK, 2023, ARTIF INTELL REV, V56, P13015, DOI 10.1007/s10462-023-10451-1
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Rathore A, 2023, WIND ENG, V47, P935, DOI 10.1177/0309524X231166859
   Ridha HM, 2022, RENEW SUST ENERG REV, V162, DOI 10.1016/j.rser.2022.112436
   Shankar R, 2022, SMART TECHN POW GREE, P93
   Shaorong Ma, 2021, 2021 International Conference on Wireless Communications and Smart Grid (ICWCSG), P246, DOI 10.1109/ICWCSG53609.2021.00054
   Sharma A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10222834
   Shi XL, 2023, COMPOS STRUCT, V306, DOI 10.1016/j.compstruct.2022.116599
   Shirishti S, 2022, 2022 2 INT C POW CON, P1
   Singh S, 2023, EVOL SYST-GER, V14, P117, DOI 10.1007/s12530-022-09439-z
   Singh S, 2022, EXPERT SYST APPL, V209, DOI 10.1016/j.eswa.2022.118272
   Sravanthi G, 2024, CLUSTER COMPUT, V27, P931, DOI 10.1007/s10586-023-03994-z
   Stankovic Marko, 2022, Procedia Computer Science, P51, DOI 10.1016/j.procs.2022.12.006
   Stankovic Marko, 2023, Innovations in Bio-Inspired Computing and Applications: Proceedings of the 13th International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2022). Lecture Notes in Networks and Systems (649), P327, DOI 10.1007/978-3-031-27499-2_31
   Talpur N, 2023, J KING SAUD UNIV-COM, V35, P821, DOI 10.1016/j.jksuci.2023.01.020
   Thiyagarajan SK, 2023, SOFT COMPUT, DOI 10.1007/s00500-023-08225-6
   Thota R, 2022, ENERG SOURCE PART A, V44, P10116, DOI 10.1080/15567036.2022.2143959
   Tunc A, 2022, LECT NOTE NETW SYST, V504, P287, DOI 10.1007/978-3-031-09173-5_36
   Turgut MS, 2022, NEURAL COMPUT APPL, V34, P8103, DOI 10.1007/s00521-022-06899-x
   Wang Ran, 2022, 2022 3rd International Conference on Big Data, Artificial Intelligence and Internet of Things Engineering (ICBAIE), P589, DOI 10.1109/ICBAIE56435.2022.9985809
   Wang R, 2023, J MATH-UK, V2023, DOI 10.1155/2023/2017167
   Wang RB, 2021, Advances in smart vehicular technology, transportation, communication and Applications, P283
   Wang RB, 2021, J ADV TRANSPORT, V2021, DOI 10.1155/2021/3606895
   Wardani AL, 2021, 2021 3 INT C RES AC
   Xie LP, 2023, INTERDISCIP SCI, V15, P231, DOI 10.1007/s12539-023-00559-x
   Xu YP, 2021, ENERGY REP, V7, P2332, DOI 10.1016/j.egyr.2021.04.042
   Yang J, 2010, PSYCHOLOGY OF COURAGE: AN ADLERIAN HANDBOOK FOR HEALTHY SOCIAL LIVING, P1, DOI 10.1007/978-1-84996-129-5
   Yang Y, 2022, ENG APPL ARTIF INTEL, V113, DOI 10.1016/j.engappai.2022.104981
   Yang Y, 2022, J SUPERCOMPUT, V78, P19566, DOI 10.1007/s11227-022-04634-w
   Yao JY, 2022, MACHINES, V10, DOI 10.3390/machines10080602
   Yildiz BS, 2023, KNOWL-BASED SYST, V271, DOI 10.1016/j.knosys.2023.110554
   Yin DX, 2023, J ALGORITHMS COMPUT, V17, DOI 10.1177/17483026221151198
   Zafar MH, 2022, COMM COM INF SC, V1616, P197, DOI 10.1007/978-3-031-10525-8_16
   Zellagui M, 2021, PROCEEDINGS OF 9TH INTERNATIONAL CONFERENCE ON MODERN POWER SYSTEMS (MPS 2021), DOI 10.1109/MPS52805.2021.9492572
   Zhang FJ, 2022, J FOOD PROCESS ENG, V45, DOI 10.1111/jfpe.14096
   Zhang JZ, 2022, IEEE ACCESS, V10, P75040, DOI 10.1109/ACCESS.2022.3190481
   Zhang M, 2022, ISA T, V127, P473, DOI 10.1016/j.isatra.2021.08.036
   Zhang QF, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12010162
   Zhang R, 2022, ENERGY REP, V8, P2424, DOI 10.1016/j.egyr.2022.01.185
   Zhang YJ, 2022, ALEX ENG J, V61, P12367, DOI 10.1016/j.aej.2022.06.017
   Zhang YJ, 2022, IEEE ACCESS, V10, P10907, DOI 10.1109/ACCESS.2022.3144431
   Zheng N, 2023, BIOMED SIGNAL PROCES, V82, DOI 10.1016/j.bspc.2022.104543
   Zheng R, 2022, MATH BIOSCI ENG, V19, P473, DOI 10.3934/mbe.2022023
   Zheng R, 2021, PROCESSES, V9, DOI 10.3390/pr9101774
   Zhou YH, 2022, J ELECTR ENG TECHNOL, V17, P3223, DOI 10.1007/s42835-022-01140-0
   Zitar RA, 2023, NEURAL COMPUT APPL, V35, P10421, DOI 10.1007/s00521-023-08242-4
   Zivkovic M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11223798
   Zivkovic M, 2021, INT SYMP SYMB NUMERI, P259, DOI 10.1109/SYNASC54541.2021.00051
NR 206
TC 0
Z9 0
U1 13
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17084-0
EA OCT 2023
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100011
DA 2024-07-18
ER

PT J
AU Wang, YT
   Cui, WH
   Tao, Y
AF Wang, Yuting
   Cui, Wenhua
   Tao, Ye
TI A color image chunking encryption algorithm based on DNA and compound
   chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE DNA encoding; DNA operation; 2D-SALM; 1D-LATM; Image encryption
AB In this article, a color image chunking encryption algorithm based on DNA and compound chaotic systems is proposed. In the algorithm proposed in this article, two new chaotic systems are designed, the One Dimensional Logistic and Tent Mapping (1D-LATM) and the Two Dimensional Logistic and Sine mapping (2D-SALM). Firstly, associating 2D-SALM chaotic system with plain generates chaotic sequences to improve plain sensitivity. Secondly, splitting the color image into three two-dimensional matrices. And the matrices are filled with zeros as required. Thirdly, the chunking operation is performed on the matrix after the complementary zeros to increase the speed of running. Fourthly, DNA manipulations are performed on the image blocks, meanwhile, the rules are determined by chaotic sequences. The sequences are produced by 2D-SALM and 1D-LATM chaotic systems. Finally, we perform the random scrambling operation and the cyclic shift diffusion operation. The cryptogenerator generates two matrices through the 2D-SALM chaotic system. These matrices used in scrambling and diffusion operations. Through the above operation, we get the ultimate color encrypted picture. The outcomes of experimental and analyses of algorithm indicate that this algorithm has excellent encryption effectiveness, well safety and fast running speed. The algorithm proposed in this paper takes only 0.68 s to encrypt an image of size 256 x 256 and 1.32 s to encrypt an image of size 512 x 512. NPCR and UACI are 99.6095%, 33.4631%. The information entropy is 7.9983.
C1 [Wang, Yuting; Cui, Wenhua; Tao, Ye] Univ Sci & Technol Liaoning, Sch Comp Sci & Software Engn, Anshan 114051, Peoples R China.
   [Cui, Wenhua; Tao, Ye] Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan 114051, Peoples R China.
C3 University of Science & Technology Liaoning; University of Science &
   Technology Liaoning
RP Cui, WH (corresponding author), Univ Sci & Technol Liaoning, Sch Comp Sci & Software Engn, Anshan 114051, Peoples R China.; Cui, WH (corresponding author), Univ Sci & Technol Liaoning, Sch Elect & Informat Engn, Anshan 114051, Peoples R China.
EM taibeijack@126.com
RI lan, lan/JWO-3679-2024; Hui, Yang/KGL-7041-2024; Zhang,
   Xiaoyu/JXR-6386-2024; LIU, JIALIN/JXN-8034-2024; Zhang,
   Yan/JHT-3389-2023; lu, yuan/JZD-0832-2024; yan, yan/JVN-1800-2024; Chen,
   Fang/JZE-4446-2024; Chen, Jin/KBQ-0163-2024; Li, Yuanxiang/KCX-8706-2024
OI Zhang, Yan/0000-0003-2281-7807; Chen, Jin/0009-0005-5844-635X; 
FU This work was supported by Joint Fund Project of the National Natural
   Science Foundation of China (U1908218), and the Department of Education
   of Liaoning Province (LJKFZ20220197). [U1908218]; Joint Fund Project of
   the National Natural Science Foundation of China [LJKFZ20220197];
   Department of Education of Liaoning Province
FX This work was supported by Joint Fund Project of the National Natural
   Science Foundation of China (U1908218), and the Department of Education
   of Liaoning Province (LJKFZ20220197).
CR Alhamadani BN., 2021, INFORM J APPL MACH E, V2, P36
   Alvarez C, 2021, FLUIDS, V6, DOI 10.3390/fluids6050175
   Basha SM, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168956
   Chen HP, 2022, IEEE ACCESS, V10, P116031, DOI 10.1109/ACCESS.2022.3218668
   Chen Y, 2022, PHYS SCRIPTA, V97, DOI 10.1088/1402-4896/ac6d85
   Chong J., 2021, Proceedings of the 2021 4th International Conference on Artificial Intelligence and Pattern Recognition, P386
   Devipriya M, 2023, J CIRCUIT SYST COMP, V32, DOI 10.1142/S0218126623500652
   El-Khamy SE, 2020, IEEE ACCESS, V8, P148935, DOI 10.1109/ACCESS.2020.3015687
   Elkandoz MT, 2022, MULTIMED TOOLS APPL, V81, P25497, DOI 10.1007/s11042-022-12595-8
   Es-Sabry M, 2022, SCI AFR, V16, DOI 10.1016/j.sciaf.2022.e01217
   Gao XY, 2022, J KING SAUD UNIV-COM, V34, P1535, DOI 10.1016/j.jksuci.2022.01.017
   Ghorbani A, 2022, OPTIK, V259, DOI 10.1016/j.ijleo.2022.168961
   Hao J, 2021, IEEE ACCESS, V9, P52364, DOI 10.1109/ACCESS.2021.3069977
   Khan JS, 2020, IEEE ACCESS, V8, P159732, DOI 10.1109/ACCESS.2020.3020917
   Li X., 2022, Int J Bifurcation Chaos Appl Sci Eng, V3, P32
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu LD, 2020, IEEE ACCESS, V8, P27361, DOI 10.1109/ACCESS.2020.2971759
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Patel S., 2021, Neural Comput Applic, V14, P1
   Patro K. Abhimanyu Kumar, 2020, 2020 First International Conference on Power, Control and Computing Technologies (ICPC2T), P411, DOI 10.1109/ICPC2T48082.2020.9071483
   Schneier B, 1993, Comput Law Secur Rev, V10, DOI [10.1016/0267-3649(94)90017-5, DOI 10.1016/0267-3649(94)90017-5]
   Tang Z., 2022, J Chemother, V2022, P1
   Tao Y, 2022, ENG LET, V30
   Vega S., 2022, IEEE international conference on automation/XXV Congress of the Chilean Association of Automatic Control (ICA-ACCA), P1
   Wang XF, 2021, MULTIMED TOOLS APPL, V80, P943, DOI 10.1007/s11042-020-09533-x
   Wang XY, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03794-0
   Wang YJ, 2020, MULTIMED TOOLS APPL, V79, P18317, DOI 10.1007/s11042-020-08742-8
   Wanke D, 2013, QTM PROB WHT NOI, V30, P351
   Wei DY, 2021, OPTIK, V238, DOI 10.1016/j.ijleo.2021.166748
   Xiao YT, 2021, INT CONF SOFTW ENG, P38, DOI 10.1109/ICSESS52187.2021.9522277
   Yang S, 2021, INT CONF SOFTW ENG, P61, DOI 10.1109/ICSESS52187.2021.9522269
   Yu JW, 2022, CHAOS SOLITON FRACT, V162, DOI 10.1016/j.chaos.2022.112456
   Zhang SJ, 2021, MATH COMPUT SIMULAT, V190, P723, DOI 10.1016/j.matcom.2021.06.012
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 35
TC 0
Z9 0
U1 3
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 29
PY 2023
DI 10.1007/s11042-023-16869-7
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T3XY3
UT WOS:001077361600010
DA 2024-07-18
ER

PT J
AU Khan, I
   Guo, ZY
   Lim, K
   Kim, J
   Kwon, YW
AF Khan, Irshad
   Guo, Ziyi
   Lim, Kihwan
   Kim, Jaeseon
   Kwon, Young-Woo
TI Assessment of indoor risk through deep learning -based object
   recognition in disaster situations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Object recognition; Disaster assessment; Risk level; Indoor safety
ID CLASSIFICATION
AB Disasters can devastate individuals and their properties, highlighting the importance of risk assessment to promote safety. Recently, deep learning techniques have shown the potential in identifying hazardous situations during disasters. Recognizing potentially dangerous objects in indoor environments can be essential for assisting individuals in responding appropriately to emergencies. In this article, we present an indoor-risk analysis framework for disasters based on deep learning. Our framework utilizes modern deep learning techniques to calculate an indoor risk rating based on dangerous objects' sizes, enabling comprehensive risk assessment of indoor environments during disasters. To that end, we use (Mask R-CNN) to identify hazardous indoor objects in disaster situations with 94% accuracy. By incorporating object size information, our framework offers a more nuanced and detailed risk assessment than previous approaches. Our proposed system provides a valuable tool for promoting ongoing safety improvement and enhancing indoor safety during natural disasters.
C1 [Khan, Irshad; Guo, Ziyi; Kwon, Young-Woo] Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu 41566, South Korea.
   [Lim, Kihwan; Kim, Jaeseon] Natl Disaster Management Inst, Ulsan 44538, South Korea.
C3 Kyungpook National University
RP Kwon, YW (corresponding author), Kyungpook Natl Univ, Sch Comp Sci & Engn, Daegu 41566, South Korea.
EM irshad.cs@knu.ac.kr; gzy844425418@gmail.com; wasabi1999@korea.kr;
   js9996@korea.kr; ywkwon@knu.ac.kr
RI Khan, Irshad/AAN-8522-2020
OI Khan, Irshad/0000-0001-6960-2083
FU This research was supported by the National Disaster Management Research
   Institute (NDMI-2021-08-02-02) and the Digital Innovation Hub project
   supervised by the Daegu Digital Innovation Promotion Agency (DIP) grant
   funded by the Korea government(MSIT and D [NDMI-2021-08-02-02]; National
   Disaster Management Research Institute; Digital Innovation Hub project -
   Korea government(MSIT)
FX This research was supported by the National Disaster Management Research
   Institute (NDMI-2021-08-02-02) and the Digital Innovation Hub project
   supervised by the Daegu Digital Innovation Promotion Agency (DIP) grant
   funded by the Korea government(MSIT and Daegu Metropolitan City) in
   2023(No.DBS1-03).
CR Ahn K, 2020, Korea Patent, Patent No. 102136070
   Alizadeh M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10060975
   Amin MS, 2021, COGN SYST RES, V66, P221, DOI 10.1016/j.cogsys.2020.11.002
   anaconda, The Labeling Tool: Labelme
   Bell Sean, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601206
   Bell S, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601206
   Bhoi A, 2020, SOC NETW ANAL MIN, V10, DOI 10.1007/s13278-020-00692-1
   BUCKLAND M, 1994, J AM SOC INFORM SCI, V45, P12, DOI 10.1002/(SICI)1097-4571(199401)45:1<12::AID-ASI2>3.0.CO;2-L
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Can R, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8070300
   Chao WT, 2020, WATER-SUI, V12, DOI 10.3390/w12092394
   Chen PA, 2013, J HYDROL, V497, P71, DOI 10.1016/j.jhydrol.2013.05.038
   Chen R, 2020, IEEE ACCESS, V8, P201799, DOI 10.1109/ACCESS.2020.3032581
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dilley M, 2005, DISAST RISK MANAGE, P1
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Grega M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010047
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Jocher Glenn, 2020, Zenodo
   Kayalvizhi R, 2020, 2020 4 INT C COMP CO, P1
   Khan I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030800
   Kim H, 2020, US Patent App, Patent No. [16/557,980, 16557980]
   Kim SS, 2022, US Patent App, Patent No. [17/736,332, 17736332]
   Lee J, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121546
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Luque A, 2019, PATTERN RECOGN, V91, P216, DOI 10.1016/j.patcog.2019.02.023
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shimizu M, 2015, US Patent, Patent No. [9,170,332, 9170332]
   Sun WJ, 2020, NAT HAZARDS, V103, P2631, DOI 10.1007/s11069-020-04124-3
   The SPSSAU project, 2021, SPSSAU
   Wang HX, 2011, SYST ENG PROC, V1, P55, DOI 10.1016/j.sepro.2011.08.010
   Xiang FT, 2019, CHIN AUTOM CONGR, P454, DOI [10.1109/cac48633.2019.8996657, 10.1109/CAC48633.2019.8996657]
   Yuan K, 2020, Journal of physics: conference series, V1592
NR 40
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16711-0
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000022
DA 2024-07-18
ER

PT J
AU Kujawski, A
   Pelling, AJR
   Jekosch, S
   Sarradj, E
AF Kujawski, Adam
   Pelling, Art J. R.
   Jekosch, Simon
   Sarradj, Ennes
TI A framework for generating large-scale microphone array data for machine
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acoustic source localization (ASL); Acoustic source characterization
   (ASC); Microphone array; Machine learning
AB The use of machine learning for localization of sound sources from microphone array data has increased rapidly in recent years. Newly developed methods are of great value for hearing aids, speech technologies, smart home systems or engineering acoustics. The existence of openly available data is crucial for the comparability and development of new data-driven methods. However, the literature review reveals a lack of openly available datasets, especially for large microphone arrays. This contribution introduces a framework for generation of acoustic data for machine learning. It implements tools for the reproducible random sampling of virtual measurement scenarios. The framework allows computations on multiple machines, which significantly speeds up the process of data generation. Using the framework, an example of a development dataset for sound source characterization with a 64-channel array is given. A containerized environment running the simulation source code is openly available. The presented approach enables the user to calculate large datasets, to store only the features necessary for training, and to share the source code which is needed to reproduce datasets instead of sharing the data itself. This avoids the problem of distributing large datasets and enables reproducible research.
C1 [Kujawski, Adam; Pelling, Art J. R.; Jekosch, Simon; Sarradj, Ennes] Tech Univ Berlin, Inst Fluid Mech & Engn Acoust, Einsteinufer 25, D-10587 Berlin, Germany.
C3 Technical University of Berlin
RP Kujawski, A (corresponding author), Tech Univ Berlin, Inst Fluid Mech & Engn Acoust, Einsteinufer 25, D-10587 Berlin, Germany.
EM adam.kujawski@tu-berlin.de
OI Kujawski, Adam/0000-0003-4579-8813; Pelling, Art J.
   R./0000-0003-3228-6069; Sarradj, Ennes/0000-0002-0274-8456
FU Deutsche Forschungsgemeinschaft
FX No Statement Available
CR Abadi, 2015, TENSORFLOW LARGE SCA
   Adavanne S., 2019, P WORKSH DET CLASS A
   Bianco MJ, 2019, J ACOUST SOC AM, V146, P3590, DOI 10.1121/1.5133944
   Bianco MichaelJ., 2019, AS, V2, P71, DOI [DOI 10.1007/S42401-019-00026-W, 10.1007/s42401-019-00026-w]
   Brousmiche M, 2020, INT CONF ACOUST SPEE, P756, DOI [10.1109/ICASSP40776.2020.9053298, 10.1109/icassp40776.2020.9053298]
   Cabada EC, 2017, MECH SYST SIGNAL PR, V97, P33, DOI 10.1016/j.ymssp.2017.04.018
   Castellini P, 2020, P 400 8 BERLIN BEAMF, pD22
   Castellini P, 2021, APPL ACOUST, V177, DOI 10.1016/j.apacoust.2021.107947
   Choi J, 2022, IEEE SIGNAL PROC LET, V29, P1412, DOI 10.1109/LSP.2022.3181971
   Deleforge A, 2015, IEEE-ACM T AUDIO SPE, V23, P718, DOI 10.1109/TASLP.2015.2405475
   Diaz-Guerra D, 2021, IEEE-ACM T AUDIO SPE, V29, P300, DOI 10.1109/TASLP.2020.3040031
   Diaz-Guerra D, 2021, MULTIMED TOOLS APPL, V80, P5653, DOI 10.1007/s11042-020-09905-3
   Ernst D, 2020, P 400 8 BERLIN BEAMF, pD27
   Garofolo J. S., 1993, TIMIT acoustic-phonetic continuous speech corpus, DOI [DOI 10.35111/17GK-BN40, 10.35111/17GK-BN40]
   Goncalves Pinto W., 2021, P INTERNOISE C, P5397, DOI DOI 10.3397/IN-2021-3084
   Grumiaux PA, 2022, J ACOUST SOC AM, V152, P107, DOI 10.1121/10.0011809
   Guizzo E, 2022, INT CONF ACOUST SPEE, P9186, DOI 10.1109/ICASSP43922.2022.9746872
   Guizzo E, 2021, IEEE INT WORKS MACH, DOI 10.1109/MLSP52302.2021.9596248
   Haeb-Umbach R, 2021, P IEEE, V109, P124, DOI 10.1109/JPROC.2020.3018668
   He WP, 2018, IEEE INT CONF ROBOT, P74
   Herold G, 2017, J SOUND VIB, V401, P152, DOI 10.1016/j.jsv.2017.04.030
   Krause D, 2021, EUR SIGNAL PR CONF, P236, DOI 10.23919/EUSIPCO54536.2021.9616284
   Kujawski Adam, 2021, Zenodo, DOI 10.5281/ZENODO.5176234
   Kujawski A, 2019, J ACOUST SOC AM, V146, pEL225, DOI 10.1121/1.5126020
   Lam S. K., 2015, P 2 WORKSHOP LLVM CO, P1, DOI [DOI 10.1145/2833157.2833162, 10.1145/2833157.2833162]
   Lathoud G, 2005, LECT NOTES COMPUT SC, V3361, P182
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee SY, 2021, MECH SYST SIGNAL PR, V161, DOI 10.1016/j.ymssp.2021.107959
   Lee SY, 2020, P INT C AUG 23 26 SE
   Löllmann HW, 2018, PR IEEE SEN ARRAY, P410, DOI 10.1109/SAM.2018.8448644
   Vera-Diaz JM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103418
   Mazzon L., 2019, P DET CLASS AC SCEN
   Merino-Martnez R., 2019, CEAS Aeronaut. J, V10, P197, DOI DOI 10.1007/S13272-019-00383-4
   Moritz P, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P561
   Nagatomo K, 2022, INT CONF ACOUST SPEE, P156, DOI 10.1109/ICASSP43922.2022.9746544
   Park DS, 2019, INTERSPEECH, P2613, DOI 10.21437/Interspeech.2019-2680
   Paszke A, 2019, ADV NEUR IN, V32
   Politis A., 2021, P 6 DET CLASS AC SCE, P125
   Politis A., 2020, P DETECTION CLASSIFI, P165
   Politis A, 2022, Arxiv, DOI arXiv:2206.01948
   Pujol H, 2021, J ACOUST SOC AM, V149, P4248, DOI 10.1121/10.0005046
   Qian XY, 2022, IEEE SIGNAL PROC LET, V29, P1132, DOI 10.1109/LSP.2022.3165466
   Qian XY, 2019, IEEE T MULTIMEDIA, V21, P2576, DOI 10.1109/TMM.2019.2902489
   Rascon C, 2017, ROBOT AUTON SYST, V96, P184, DOI 10.1016/j.robot.2017.07.011
   Roman IR, 2021, P DETECTION CLASSIFI, P175
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salamon J, 2017, IEEE WORK APPL SIG, P344, DOI 10.1109/WASPAA.2017.8170052
   Sarradj E, 2016, P CD 6 BERL BEAMF C
   Sarradj E, 2017, APPL ACOUST, V116, P50, DOI 10.1016/j.apacoust.2016.09.015
   Sarradj E, 2012, ADV ACOUS VIB, V2012, DOI 10.1155/2012/292695
   Schulz Y, 2021, IEEE ROBOT AUTOM LET, V6, P2587, DOI 10.1109/LRA.2021.3062254
   Sheelvant R, 2019, P O COCOSDA, DOI [10.1109/O-COCOSDA46868.2019.9060842, DOI 10.1109/O-COCOSDA46868.2019.9060842]
   Shimada K, 2022, INT CONF ACOUST SPEE, P316, DOI 10.1109/ICASSP43922.2022.9746384
   SongGong KK, 2022, IEEE-ACM T AUDIO SPE, V30, P2475, DOI 10.1109/TASLP.2022.3190723
   Takahashi N, 2018, IEEE T MULTIMEDIA, V20, P513, DOI 10.1109/TMM.2017.2751969
   Van Veen B. D., 1988, IEEE ASSP Magazine, V5, P4, DOI 10.1109/53.665
   Wang Q, 2022, Tech. Rep.
   Wang Q., 2020, Tech rep, detection and classification of acoustic scenes and events 2020
   Xu P, 2020, P CD 8 BERL BEAMF C
   Xu PW, 2021, MECH SYST SIGNAL PR, V151, DOI 10.1016/j.ymssp.2020.107370
   Zhang J, 2019, Tech rep, detection and classification of acoustic scenes and events 2019
NR 61
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31211
EP 31231
DI 10.1007/s11042-023-16947-w
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400004
OA hybrid
DA 2024-07-18
ER

PT J
AU Liu, YT
   Shen, XJ
   Lyu, Y
   Wang, X
AF Liu, Yitong
   Shen, Xuanjing
   Lyu, Yingda
   Wang, Xue
TI MCA-Net: multi-cascade attention network for polyp segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Polyp segmentation; Edge fusion; Attention mechanism; Multi-cascade
   supervision
ID EXTRACTION
AB Accurate polyp segmentation is crucial for diagnosing colorectal cancer, but it remains challenging due to shape, texture, and scale variations, as well as difficulties in determining boundaries. Existing methods incorporating attention mechanisms have improved accuracy but lack effective fusion of different level features. Besides, extracting boundary information from surrounding mucosa and early polyps poses challenges. To tackle these issues, a multi-cascade attention-based network (MCA-Net) is proposed. Three components are introduced, including an axial receptive module (ARM), a multi-cascade feature aggregation module (MFA), and an edge fusion module (EFM). The ARM enhances multi-scale analysis by incorporating receptive fields and axial attention, providing the algorithm with a better knowledge of the features. Along with the integration of multi-cascade supervision, MFA selectively refines the information, effectively fusing relevant cues from different levels, suppressing background noise, and highlighting essential polyp features. The EFM focuses on capturing object boundary details, resulting in well-defined and accurate segmentation. Experiment results on five polyp datasets show that our MCA-Net outperforms state-of-the-art (SOTA) methods. Specifically, our MCA-Net achieves an 8.2% improvement in mean Dice compared to the state-of-the-art on the ETIS dataset.
C1 [Liu, Yitong] Jilin Univ, Coll Software, Changchun 130012, Peoples R China.
   [Liu, Yitong; Shen, Xuanjing; Wang, Xue] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Shen, Xuanjing; Wang, Xue] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Peoples R China.
   [Lyu, Yingda] Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Jilin University; Jilin University
RP Lyu, Y (corresponding author), Jilin Univ, Publ Comp Educ & Res Ctr, Changchun 130012, Peoples R China.
EM liuyt20@mails.jlu.edu.cn; xjshen@jlu.edu.cn; ydlv@jlu.edu.cn;
   wxue19@mails.jlu.edu.cn
FU This research is supported by the National Key Research and Development
   Program of China (2018YFB0804202, 2018YFB0804203), Regional Joint Fund
   of NSFC (U19A2057), the National Natural Science Foundation of China
   (61876070), Jilin University "Interdisciplin [2018YFB0804202,
   2018YFB0804203]; National Key Research and Development Program of China
   [U19A2057]; NSFC [61876070]; National Natural Science Foundation of
   China [JLUXKJC2021QZ01]; Jilin University "Interdisciplinary Integration
   and Innovation" Young Scholars Free Exploration Project [20190303134SF];
   Jilin Province Science and Technology Development Plan Project
   [GXXT-2021-008]; Anhui University Collaborative Innovation Project
   Subproject
FX This research is supported by the National Key Research and Development
   Program of China (2018YFB0804202, 2018YFB0804203), Regional Joint Fund
   of NSFC (U19A2057), the National Natural Science Foundation of China
   (61876070), Jilin University "Interdisciplinary Integration and
   Innovation" Young Scholars Free Exploration Project (JLUXKJC2021QZ01),
   Jilin Province Science and Technology Development Plan Project
   (20190303134SF), Anhui University Collaborative Innovation Project
   Subproject (GXXT-2021-008). The datasets generated during and/or
   analysed during the current study are available from the corresponding
   author on reasonable request.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ahmad RM, 2020, AIPR 2020: 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION, P180, DOI 10.1145/3430199.3430243
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bhatti UA, 2022, CHEMOSPHERE, V288, DOI 10.1016/j.chemosphere.2021.132569
   Bhatti UA, 2021, IEEE ACCESS, V9, P41019, DOI 10.1109/ACCESS.2021.3060744
   Bhatti UA, 2021, J MED IMAG HEALTH IN, V11, P7, DOI 10.1166/jmihi.2021.3313
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Chao P, 2019, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2019.00365
   Cheng MJ, 2021, LECT NOTES COMPUT SC, V12901, P720, DOI 10.1007/978-3-030-87193-2_68
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Chu XX, 2021, ADV NEUR IN
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B, 2021, PREPRINT
   Fan D-P, 2018, PREPRINT
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Ho J, 2019, PREPRINT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C, 2021, PREPRINT
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kingma D. P., 2014, arXiv
   Magaji BA, 2017, BMC CANCER, V17, DOI 10.1186/s12885-017-3336-z
   Mnih V, 2014, ADV NEUR IN, V27
   Nawaz SA, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0256971
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/CRV52889.2021.00032, 10.1109/crv52889.2021.00032]
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruifei Zhang, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P253, DOI 10.1007/978-3-030-59725-2_25
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Sun Jesse, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P797, DOI 10.1007/978-3-030-59719-1_77
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Valanarasu Jeya Maria Jose, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P363, DOI 10.1007/978-3-030-59719-1_36
   Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Vinson KE, 2016, INT J CANCER, V138, P1835, DOI 10.1002/ijc.29800
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Yang XF, 2019, IEEE T GEOSCI REMOTE, V57, P7209, DOI 10.1109/TGRS.2019.2912301
   Yin ZJ, 2022, I S BIOMED IMAGING, DOI 10.1109/ISBI52829.2022.9761402
   Zeeshan Z, 2021, INTELL DATA ANAL, V25, P1013, DOI 10.3233/IDA-205388
   Zhang H, 2019, 36 INT C MACHINE LEA, V97
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou Z., 2018, PREPRINT
NR 47
TC 0
Z9 0
U1 5
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33713
EP 33730
DI 10.1007/s11042-023-16805-9
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400005
DA 2024-07-18
ER

PT J
AU Wu, JH
   Ni, F
   Wang, ZJ
   Ju, HY
   Zhang, Y
   Hu, FQ
   Li, YF
AF Wu, Jianhui
   Ni, Fan
   Wang, Zijie
   Ju, Haoyu
   Zhang, Yue
   Hu, Fangqiang
   Li, Yifeng
TI Fine-grained person-based image captioning via advanced spectrum parsing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image captioning; Person-based images; Fine graininess; Spectrum domain
AB Recent image captioning models have demonstrated remarkable performance in capturing substantial global semantic information in coarse-grained images and achieving high object coverage rates in generated captions. When applied to fine-grained images that contain heterogeneous object attributes, these models often struggle to maintain the desired granularity due to inadequate attention to local content. This paper investigates a solution for fine-grained caption generation on person-based images and heuristically proposes the Advanced Spectrum Parsing (ASP) model. Specifically, we design a novel spectrum branch to unveil the potential contour features of detected objects in the spectrum domain. We also preserve the spatial feature branch employed in existing methods, and leverage a multi-level feature extraction module to extract both spatial and spectrum features. Further more, we optimize these features, aiming to learn the spatial-spectrum correlation and complete the feature concatenation procedure via a multi-scale feature fusion module. In the inference stage, the integrated features enable the model to focus more on the local semantic regions of the person in the image. Extensive experimental results demonstrate that the proposed ASP for person-based datasets can yield promising results with both comprehensiveness and fine graininess.
C1 [Wu, Jianhui; Ni, Fan; Wang, Zijie; Ju, Haoyu; Zhang, Yue; Hu, Fangqiang; Li, Yifeng] Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing 211816, Peoples R China.
C3 Nanjing Tech University
RP Hu, FQ (corresponding author), Nanjing Tech Univ, Sch Comp Sci & Technol, Nanjing 211816, Peoples R China.
EM jianhuiwu0211@163.com; fannienow@163.com; zijiewang9928@gmail.com;
   jhy1464951160@163.com; yoyoyuetwo@gmail.com; hufq@njtech.edu.cn;
   lyffz4637@163.com
RI Wu, Jianhui/JLF-2153-2023
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chang YS, 2018, MULTIMED TOOLS APPL, V77, P2959, DOI 10.1007/s11042-017-4593-1
   Cho J., 2022, ARXIV
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Devlin J., 2018, BERT PRE TRAINING DE
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   HARRIS FJ, 1978, P IEEE, V66, P51, DOI 10.1109/PROC.1978.10837
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jhamtani H, 2018, ARXIV
   Jia X, 2022, MULTIMED TOOLS APPL, V81, P21349, DOI 10.1007/s11042-022-12776-5
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Luo RT, 2018, PROC CVPR IEEE, P6964, DOI 10.1109/CVPR.2018.00728
   Mokady R, 2021, ARXIV
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park DH, 2019, IEEE I CONF COMP VIS, P4623, DOI 10.1109/ICCV.2019.00472
   PRUDVIRAJ J, 2022, MULTIMED TOOLS APPL, P1
   Radford A., 2019, LANGUAGE MODELS ARE
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shizhe Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9959, DOI 10.1109/CVPR42600.2020.00998
   Sutskever I, 2014, ADV NEUR IN, V27
   Tan HH, 2019, arXiv
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang SW, 2020, MULTIMED TOOLS APPL, V79, P11531, DOI 10.1007/s11042-019-08567-0
   Wang SW, 2020, MULTIMED TOOLS APPL, V79, P2013, DOI 10.1007/s11042-019-08209-5
   Wu J, 2021, IEEE T MULTIMEDIA, V23, P2413, DOI 10.1109/TMM.2020.3011317
   Xu GH, 2021, PROC CVPR IEEE, P12632, DOI 10.1109/CVPR46437.2021.01245
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zha ZJ, 2022, IEEE T PATTERN ANAL, V44, P710, DOI 10.1109/TPAMI.2019.2909864
   Zhu AC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P209, DOI 10.1145/3474085.3475369
NR 42
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 34015
EP 34030
DI 10.1007/s11042-023-16893-7
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100001
DA 2024-07-18
ER

PT J
AU Du, XT
   Shen, A
   Wang, XM
   Feng, ZL
   Deng, H
AF Du, Xiangtong
   Shen, Ao
   Wang, Ximing
   Feng, Zunlei
   Deng, Hai
TI NRD-Net: a noise-resistant distillation network for accurate diagnosis
   of prostate cancer with bi-parametric MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Prostate cancer diagnosis; bpMRI images; Online distillation;
   Dual-branch network
AB In recent years, deep learning-based methods have been extensively developed to diagnose Prostate Cancer (PCa) with bi-parametric Magnetic Resonance Imaging (bpMRI) images. Due to the vague characteristic of PCa bpMRI images, the spacial lesion annotations and grading annotations inevitably contain some noises, which has a serious impact on the performance of deep learning models for the diagnosis of PCa. Furthermore, the similar background features of PCa bpMRI image also disturb the prediction performance of deep learning models. In this paper, we propose a two-branch Noise-Resistant Distillation Network (NRD-Net) for the accurate diagnosis of PCa with bpMRI images. Firstly, the influence of irrelevant background on the classification can be reduced by segmenting the labeled constrained classification response maps. Then a novel confidence-based binarization segmentation scheme and a multi-branch online distillation classification scheme are proposed to reduce the spatial and grading noises simultaneously. Extensive experiments are conducted on a private dataset and the public PROSTATEx-2 dataset. For the private dataset, the proposed network obtains the best performance for GG prediction, achieving a mean quadratic weighted Kappa of 0.5115 and a mean positive predictive value (PPV) of 0.9506. For the public dataset, the proposed method achieves state-of-the-art results of 0.5058 Kappa and 0.9473 PPV.
C1 [Du, Xiangtong] Nanjing Univ Aeronaut & Astronaut, Sch Comp Sci & Technol, Nanjing 211106, Peoples R China.
   [Shen, Ao] Hohai Univ, Sch Internet Things Engn, Changzhou 213022, Jiangsu, Peoples R China.
   [Wang, Ximing] Soochou Univ, Dept Radiol, Affiliated Hosp 1, Suzhou 215006, Peoples R China.
   [Feng, Zunlei] Zhejiang Univ, Sch Software Technol, Hangzhou 310058, Peoples R China.
   [Deng, Hai] Florida Int Univ, Dept Elect & Comp Engn, Miami, FL 33174 USA.
C3 Nanjing University of Aeronautics & Astronautics; Hohai University;
   Zhejiang University; State University System of Florida; Florida
   International University
RP Du, XT (corresponding author), Nanjing Univ Aeronaut & Astronaut, Sch Comp Sci & Technol, Nanjing 211106, Peoples R China.
EM duxiangtong@nuaa.edu.cn
RI Shen, Ao/K-4432-2018; Wang, Ximing/AAB-6146-2022
OI Shen, Ao/0000-0001-7661-4269; 
FU Zhejiang Key Laboratory of Safety Engineering and Technology
FX This work is supported in part by Zhejiang Province Science and
   Technology Project for Public Welfare (LGF21F020020), and Suzhou
   Municipal Health and Family Planning Commission's Key Diseases Diagnosis
   and Treatment Program (LCZX202001).
CR Abraham Bejoy, 2019, Informatics in Medicine Unlocked, V17, P150, DOI 10.1016/j.imu.2019.100256
   Abraham B, 2019, J INTELL FUZZY SYST, V36, P2015, DOI 10.3233/JIFS-169913
   Abraham B, 2018, COMPUT MED IMAG GRAP, V69, P60, DOI 10.1016/j.compmedimag.2018.08.006
   Aldoj N, 2020, EUR RADIOL, V30, P1243, DOI 10.1007/s00330-019-06417-z
   Armato SG, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.4.044501
   Bednarova S, 2017, TRANSL ANDROL UROL, V6, P413, DOI 10.21037/tau.2017.03.53
   Betrouni N, 2007, PATTERN RECOGN LETT, V28, P1808, DOI 10.1016/j.patrec.2007.05.013
   Cao RM, 2019, IEEE T MED IMAGING, V38, P2496, DOI 10.1109/TMI.2019.2901928
   Chahal ES, 2022, MULTIMED TOOLS APPL, V81, P37333, DOI 10.1007/s11042-021-11334-9
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chen MY, 2020, CANCER MED-US, V9, P7172, DOI 10.1002/cam4.3386
   Chinmay C, 2022, IEEE Trans Comput Soc Syst, V99, P1
   Dai ZZ, 2023, MED PHYS, V50, P7748, DOI 10.1002/mp.16557
   Dgani Y, 2018, I S BIOMED IMAGING, P39, DOI 10.1109/ISBI.2018.8363518
   Dorbala S, 2018, J NUCL CARDIOL, V25, P1784, DOI 10.1007/s12350-018-1283-y
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Garg G, 2021, MULTIMED TOOLS APPL, V80, P30557, DOI 10.1007/s11042-021-11133-2
   Ge Y., 2021, ARXIV
   Ghavami N, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101558
   Hu J, 2022, Med Phys
   Hu JC, 2021, Medical Image Computing and Computer Assisted Intervention
   Hu JS, 2023, MED PHYS, V50, P2279, DOI 10.1002/mp.16102
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Ishioka J, 2018, BJU INT, V122, P411, DOI 10.1111/bju.14397
   Ju L, 2022, IEEE T MED IMAGING, V41, P1533, DOI 10.1109/TMI.2022.3141425
   Juneja M, 2021, MULTIMED TOOLS APPL, V80, P29199, DOI 10.1007/s11042-021-11044-2
   Khan Z., 2020, 14 INT C INTERFACES, P132
   Kishor A, 2022, WIRELESS PERS COMMUN, V127, P1615, DOI 10.1007/s11277-021-08708-5
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616
   Kumar S, 2018, CANCER LETT, V414, P153, DOI 10.1016/j.canlet.2017.11.011
   Liang G., 2020, Multimed Tools Appl, V81, P5089
   Lim JY, 2021, NEUROCOMPUTING, V459, P327, DOI 10.1016/j.neucom.2021.06.090
   Lin ZLC., 2015, Pathology, V47, pS68, DOI [10.1097/01.PAT.0000461503.70858.b2, DOI 10.1097/01.PAT.0000461503.70858.B2]
   Liu F, 2021, 2021 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P449, DOI 10.1109/IPDPSW52791.2021.00076
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Puech P, 2009, CURR OPIN UROL, V19, P168, DOI 10.1097/MOU.0b013e328323f5ed
   Qian W, 2022, NEUROCOMPUTING, V480, P89, DOI 10.1016/j.neucom.2022.01.043
   Rani JS, 2013, Int J Eng Res Technol, V2
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rundo L, 2019, NEUROCOMPUTING, V365, P31, DOI 10.1016/j.neucom.2019.07.006
   Seah J, 2017, Med Imaging
   Shen A, 2022, J Shanghai Jiaotong Univ (Science)
   Sim J, 2005, PHYS THER, V85, P257
   Song Y, 2018, J MAGN RESON IMAGING, V48, P1570, DOI 10.1002/jmri.26047
   Tian ZQ, 2021, NEUROCOMPUTING, V438, P84, DOI 10.1016/j.neucom.2020.05.121
   Tian ZQ, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.2.021208
   Tong CC, 2012, MAGN RESON IMAGING, V30, P1381, DOI 10.1016/j.mri.2012.04.005
   Vaishali S, 2015, 2015 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND COMMUNICATION ENGINEERING SYSTEMS (SPACES), P363, DOI 10.1109/SPACES.2015.7058284
   de Vente C, 2021, IEEE T BIO-MED ENG, V68, P374, DOI 10.1109/TBME.2020.2993528
   Wang XH, 2020, MED BIOL ENG COMPUT, V58, P2095, DOI 10.1007/s11517-020-02224-7
   Wang YY, 2020, PHYS MEDICA, V80, P92, DOI 10.1016/j.ejmp.2020.10.013
   Wang ZW, 2018, IEEE T MED IMAGING, V37, P1127, DOI 10.1109/TMI.2017.2789181
   Xiao J, 2023, MEASUREMENT, V214, DOI 10.1016/j.measurement.2023.112764
   Yu HQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205736
   Zaras A, 2021, PATTERN RECOGN LETT, V146, P215, DOI 10.1016/j.patrec.2021.03.014
   Zhiyu Liu, 2019, Artificial Intelligence in Radiation Therapy. First International Workshop, AIRT 2019. Held in Conjunction with MICCAI 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11850), P43, DOI 10.1007/978-3-030-32486-5_6
   Zhu JQ, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108897
NR 58
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33597
EP 33614
DI 10.1007/s11042-023-16712-z
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100009
DA 2024-07-18
ER

PT J
AU Anjeana, N
   Anusudha, K
AF Anjeana, N.
   Anusudha, K.
TI Real time face recognition system based on YOLO and InsightFace
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE YOLO-V7; InsightFace; Auto-Anchor Algorithm; Cosine Similarity Theorem;
   Arcface Loss; Eigenfaces
AB Face Recognition is an important research topics in Machine Learning and Artificial Intelligence. It analyses and compares person's facial traits with a database that contains different faces to automatically recognise and verify a person's identity. It has attracted a lot of attention recently due to its non-intrusive nature. Unlike other biometric identification systems, face recognition does not require physical contact with the individual being identified, making it more convenient and hygienic. Although the existing face recognition system has achieved better performance, recognizing the obscured and disguised faces is difficult. Thus, to deal with these problems, this paper reveals a new real time unique face recognition network called YOLO-InsightFace that combines YOLO-V7, a cutting-edge deep learning model and InsightFace, one-of-a-kind 2D & 3D face analysis python module. YOLO-V7 is highly accurate and fast, making it ideal for real-time applications while InsightFace is capable of recognizing faces by generating highly discriminative face embeddings.
C1 [Anjeana, N.; Anusudha, K.] Pondicherry Univ, Dept Elect Engn, Kalapet, India.
C3 Pondicherry University
RP Anjeana, N (corresponding author), Pondicherry Univ, Dept Elect Engn, Kalapet, India.
EM n.anjeana@gmail.com
FU We would like to thank each individual and organisations who helped with
   the research and writing for this article. We want to express our
   gratitude to the department head and other professors from the
   department of Electronics Engineering at Pondicherry U
FX We would like to thank each individual and organisations who helped with
   the research and writing for this article. We want to express our
   gratitude to the department head and other professors from the
   department of Electronics Engineering at Pondicherry University for
   their suggestions and insights.
CR Almomany A, 2022, J KING SAUD UNIV-COM, V34, P3815, DOI 10.1016/j.jksuci.2022.04.006
   CAKIROGLU O, 2019, 27 SIGN PROC COMM AP, P1
   Chen WJ, 2021, VISUAL COMPUT, V37, P805, DOI 10.1007/s00371-020-01831-7
   Dadure P, 2018, 2018 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS, MATERIALS ENGINEERING & NANO-TECHNOLOGY (IEMENTECH), P49
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng WH, 2019, IEEE ACCESS, V7, P118727, DOI 10.1109/ACCESS.2019.2936663
   Dharma Aria Satia, 2022, 2022 IEEE International Conference of Computer Science and Information Technology (ICOSNIKOM), P1, DOI 10.1109/ICOSNIKOM56551.2022.10034925
   Fatima B, 2020, APPL ARTIF INTELL, V34, P456, DOI 10.1080/08839514.2020.1723875
   George A, CRIMINAL FACE RECOGN
   George G, 2017, INT C CIRC POW COMP, P1
   Haoyu Wang, 2021, 2021 3rd International Conference on Artificial Intelligence and Advanced Manufacture (AIAM), P540, DOI 10.1109/AIAM54119.2021.00113
   Jiang Chenchen, 2022, 2022 7th International Conference on Image, Vision and Computing (ICIVC), P129, DOI 10.1109/ICIVC55077.2022.9886975
   Khan Maliha, 2019, 2019 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P116, DOI 10.1109/ICCCIS48478.2019.8974493
   Khan S, 2019, INT J POLYM SCI, V2019, DOI 10.1155/2019/6579239
   Khodabakhsh A, 2020, MEDD C EMBED COMPUT, P39
   Ludwiczuk B., 2016, Tech. Rep. CMU-CS-16-118
   MengAn Shi, 2021, 2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI), P273, DOI 10.1109/CISAI54367.2021.00058
   Menon MS, 2021, INT CO SIG PROC COMM, P454, DOI 10.1109/ICSPC51351.2021.9451684
   Prasad PS, 2020, LECT NOTES ELECTR EN, V570, P419, DOI 10.1007/978-981-13-8715-9_50
   Qi D., 2023, COMP VIS ECCV 2022 W
   Sarkar Sayan Deb, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P417, DOI 10.1109/SPIN48934.2020.9071378
   Shanthi K. G., 2022, 2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS), P295, DOI 10.1109/ICACCS54159.2022.9785051
   Sharma S, 2022, J DISCRET MATH SCI C, V25, P205, DOI 10.1080/09720529.2021.2014141
   Soni N, 2013, INT J COMPUT APPL, V76
   Suganthi ST, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.881
   Sugiharti E., 2020, J Phys Conf Ser, V1567, DOI DOI 10.1088/1742-6596/1567/3/032028
   Trigueros DS, 2018, ARXIV
   Wang H, 2022, AIDING FORENSIC INVE, P144, DOI DOI 10.4018/978-1-6684-4558-7.CH006
   Wu WQ, 2019, IEEE T CYBERNETICS, V49, P4017, DOI 10.1109/TCYB.2018.2859482
   Zainuddin Z, 2020, 2020 4 INT C INF COM, P1
   Zhang SF, 2021, IEEE T PATTERN ANAL, V43, P4008, DOI 10.1109/TPAMI.2020.2997456
   Zhou Yuquan, 2022, 2022 IEEE 5th International Conference on Automation, Electronics and Electrical Engineering (AUTEEE), P353, DOI 10.1109/AUTEEE56487.2022.9994569
NR 32
TC 2
Z9 2
U1 9
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31893
EP 31910
DI 10.1007/s11042-023-16831-7
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900021
DA 2024-07-18
ER

PT J
AU Dixit, M
   Yadav, RN
AF Dixit, Monika
   Yadav, Ram Narayan
TI A Review of Single Image Super Resolution Techniques using Convolutional
   Neural Networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single Image Super-Resolution (SISR); Convolutional Neural Networks
   (CNNs); Microscopic Image Analysis; Medical Imaging; Security and
   Surveillance; Astronomical Observation; Hyperspectral Imaging; Text
   Image Super-Resolution
ID QUALITY ASSESSMENT; SUPERRESOLUTION; CNN
AB Single Image Super- Resolution (SISR) is a complex restoration method to recover high-resolution (HR) image from degraded low-resolution (LR) form. SISR is used in many applications, such as microscopic image analysis, medical imaging, security and surveillance, astronomical observation, hyperspectral imaging, and text image super-resolution. Convolutional Neural Networks (CNNs) are most widely used technique to solve Super-Resolution (SR) problems. This paper presents review of SISR methods based on CNN. The SISR CNN models are analyzed based on the design and their performance on benchmark datasets: Set 5, Set 14, BSD 100, and Urban 100. Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index (SSIM) are used for quantitative analysis. ESRGAN model shows the best results on all benchmark datasets and reconstructs images with good visual quality at large upscaling factors. The model performs excellently with PSNR 27.03 dB and SSIM 0.8153 on the Urban 100 dataset for x4 upscaling factor. The models are further analyzed on the basis of the loss function, scalability, processing time, and number of parameters. The framework and implementation setup of SISR CNN models are also discussed. Perceptual loss function can help to boost the network performance by increasing the visual quality of the reconstructed images. Hence, it has emerged as a new research trend in recent years. It is also observed that there is tremendous growth in the field of blind or unsupervised SISR. The research has shifted to developing reference less performance evaluation parameters for unsupervised SISR.
C1 [Dixit, Monika; Yadav, Ram Narayan] Maulana Azad Natl Inst Technol, Dept Elect & Commun Engn, Bhopal, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Dixit, M (corresponding author), Maulana Azad Natl Inst Technol, Dept Elect & Commun Engn, Bhopal, Madhya Pradesh, India.
EM monikadixitec@gmail.com; rnyadav@gmail.com
RI Yadav, R N/B-1694-2017; Dixit, Monika/HSF-3006-2023
OI Yadav, R N/0000-0002-3635-5925; Dixit, Monika/0000-0002-1533-0323
FU Authors would like to express their gratitude to the anonymous reviewers
   for their insightful and productive feedback.
FX Authors would like to express their gratitude to the anonymous reviewers
   for their insightful and productive feedback.
CR Ahmadian K, 2022, MULTIMED TOOLS APPL, V81, P10607, DOI 10.1007/s11042-022-11970-9
   Ahn N., 2018, P EUR C COMP VIS ECC, P252, DOI DOI 10.1007/978-3-030-01249-6_16
   Barzegar S, 2020, MULTIMED TOOLS APPL, V79, P1119, DOI 10.1007/s11042-019-08218-4
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Bhuyan HK, 2022, CLUSTER COMPUT, V25, P4275, DOI 10.1007/s10586-022-03667-3
   Bhuyan HK, 2024, IEEE T COMPUT SOC SY, V11, P3131, DOI 10.1109/TCSS.2022.3164993
   Bhuyan HK, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12776
   BHUYAN HK, 2021, IEEE T ENG MANA 0416, pNIL1, DOI DOI 10.1109/TEM.2021.3065699
   Bisen D, 2022, MULTIMED TOOLS APPL, V81, P18011, DOI 10.1007/s11042-022-12775-6
   Bruna J., 2016, ICLR, P1
   Choi JS, 2017, IEEE COMPUT SOC CONF, P1150, DOI 10.1109/CVPRW.2017.153
   Dai SY, 2009, IEEE T IMAGE PROCESS, V18, P969, DOI 10.1109/TIP.2009.2012908
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   DUCHON CE, 1979, J APPL METEOROL, V18, P1016, DOI 10.1175/1520-0450(1979)018<1016:LFIOAT>2.0.CO;2
   Fan YC, 2017, IEEE COMPUT SOC CONF, P1157, DOI 10.1109/CVPRW.2017.154
   Freedman G, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1944846.1944852
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Fujimoto A, 2016, PROCEEDINGS OF THE 1ST INTERNATIONAL WORKSHOP ON COMICS ANALYSIS, PROCESSING AND UNDERSTANDING (MANPU 2016), DOI 10.1145/3011549.3011551
   Greeshma MS, 2020, MULTIMED TOOLS APPL, V79, P35125, DOI 10.1007/s11042-020-09352-0
   Guo D, 2019, IET IMAGE PROCESS, V13, P1201, DOI 10.1049/iet-ipr.2018.5907
   Guo FH, 2021, MULTIMED TOOLS APPL, V80, P7351, DOI 10.1007/s11042-020-09952-w
   Guo TT, 2017, IEEE COMPUT SOC CONF, P1100, DOI 10.1109/CVPRW.2017.148
   Gupta S, 2022, MULTIMED TOOLS APPL, V81, P4241, DOI 10.1007/s11042-021-11767-2
   Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178
   Hardiansyah B, 2021, MULTIMED TOOLS APPL, V80, P28713, DOI 10.1007/s11042-021-11062-0
   Haris M, 2018, PROC CVPR IEEE, P1664, DOI 10.1109/CVPR.2018.00179
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou MZ, 2022, MULTIMED TOOLS APPL, V81, P28231, DOI 10.1007/s11042-022-12911-2
   Hu J, 2015, MULTIMED TOOLS APPL, V74, P9259, DOI 10.1007/s11042-014-2079-y
   Hu SY, 2020, MULTIMED TOOLS APPL, V79, P1427, DOI 10.1007/s11042-019-08241-5
   Hu Y, 2018, P COMP VIS PATT REC, P512
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   HUANG JB, 2015, PROC CVPR IEEE, P5197, DOI DOI 10.1109/CVPR.2015.7299156
   Hui Z, 2018, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2018.00082
   Jiao JB, 2017, IEEE COMPUT SOC CONF, P1034, DOI 10.1109/CVPRW.2017.140
   Khan Ashraf Ali, 2015, 2015 17th European Conference on Power Electronics and Applications (EPE'15 ECCE-Europe), P1, DOI 10.1109/EPE.2015.7309136
   Kim J, 2018, P COMP VIS PATT REC, P886
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P1443, DOI 10.1109/TCYB.2020.2970104
   Lan RS, 2021, IEEE T CYBERNETICS, V51, P115, DOI 10.1109/TCYB.2019.2952710
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li JC, 2018, LECT NOTES COMPUT SC, V11212, P527, DOI 10.1007/978-3-030-01237-3_32
   Li YS, 2017, NEUROCOMPUTING, V266, P29, DOI 10.1016/j.neucom.2017.05.024
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu PJ, 2018, IEEE COMPUT SOC CONF, P886, DOI 10.1109/CVPRW.2018.00121
   Liu ZB, 2022, MULTIMED TOOLS APPL, V81, P6827, DOI 10.1007/s11042-021-11724-z
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mei SH, 2020, IEEE T GEOSCI REMOTE, V58, P4590, DOI 10.1109/TGRS.2020.2964288
   Mishra J, 2022, MULTIMED TOOLS APPL, V81, P18915, DOI 10.1007/s11042-022-12531-w
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Mutlag Wamidh K., 2020, Journal of Physics: Conference Series, V1591, DOI 10.1088/1742-6596/1591/1/012028
   Park SJ, 2018, LECT NOTES COMPUT SC, V11220, P455, DOI 10.1007/978-3-030-01270-0_27
   Peng YH, 2020, MULTIMED TOOLS APPL, V79, P9351, DOI 10.1007/s11042-019-7544-1
   Pham CH, 2017, I S BIOMED IMAGING, P197, DOI 10.1109/ISBI.2017.7950500
   Ren HY, 2017, IEEE COMPUT SOC CONF, P1050, DOI 10.1109/CVPRW.2017.142
   Ribeiro E, 2019, IET BIOMETRICS, V8, P69, DOI 10.1049/iet-bmt.2018.5146
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sajjadi Mehdi S. M., 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P4501, DOI 10.1109/ICCV.2017.481
   Salau Ayodeji Olalekan, 2019, 2019 International Conference on Signal Processing and Communication (ICSC), P158
   Salimans T, 2017, INT C LEARN REPR, P236
   Sharma A, 2023, MULTIMED TOOLS APPL, V82, P29587, DOI 10.1007/s11042-023-14765-8
   Sheikh HR, 2005, IEEE T IMAGE PROCESS, V14, P2117, DOI 10.1109/TIP.2005.859389
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Shukla AK, 2021, MULTIMED TOOLS APPL, V80, P30213, DOI 10.1007/s11042-020-08968-6
   Song ZY, 2021, MULTIMED TOOLS APPL, V80, P9765, DOI 10.1007/s11042-020-10152-9
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tai Y, 2017, IEEE I CONF COMP VIS, P4549, DOI 10.1109/ICCV.2017.486
   Tai Y, 2017, PROC CVPR IEEE, P2790, DOI 10.1109/CVPR.2017.298
   Tang JL, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10030854
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   van den Oord A, 2016, ADV NEUR IN, V29
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang YF, 2018, IEEE COMPUT SOC CONF, P977, DOI 10.1109/CVPRW.2018.00131
   Wang YQ, 2022, MULTIMED TOOLS APPL, V81, P6633, DOI 10.1007/s11042-021-11679-1
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2015, IEEE T IMAGE PROCESS, V24, P4359, DOI 10.1109/TIP.2015.2462113
   Wen R, 2018, IEEE SIGNAL PROC LET, V25, P1565, DOI 10.1109/LSP.2018.2861989
   Wu H., 2019, IEEE T CIRCUITS SYST, V5, P567
   Wu Q, 2020, MULTIMED TOOLS APPL, V79, P21265, DOI 10.1007/s11042-020-08878-7
   Yamanaka J, 2020, COMPUTER VISION PATT, P456
   Yan Q, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2414877
   Yang CY, 2014, LECT NOTES COMPUT SC, V8692, P372, DOI 10.1007/978-3-319-10593-2_25
   Yang XM, 2020, MULTIMED TOOLS APPL, V79, P8911, DOI 10.1007/s11042-019-7716-z
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Ying WY, 2023, MULTIMED TOOLS APPL, V82, P12117, DOI 10.1007/s11042-022-13815-x
   Yuan Y, 2018, IEEE COMPUT SOC CONF, P814, DOI 10.1109/CVPRW.2018.00113
   Yuan Y, 2017, IEEE J-STARS, V10, P1963, DOI 10.1109/JSTARS.2017.2655112
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang HC, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 109
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29741
EP 29775
DI 10.1007/s11042-023-16786-9
EA SEP 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001081631900012
DA 2024-07-18
ER

PT J
AU Guo, HP
   Wang, R
   Zhang, L
   Sun, YE
AF Guo, Huaping
   Wang, Rui
   Zhang, Li
   Sun, Yange
TI Dual convolutional neural network for crowd counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd counting; Dual network; Convolutional neural network
AB As a challenging issue in computer vision, crowd counting has been increasingly studied. A convolutional neural network (CNN) is an effective system for handling crowd counting, based on constructing a CNN to generate a high-quality density estimation map. However, conventional CNN-based methods only consider the mapping from the crowd image to the density map, neglecting reconstruction from the density map to the crowd image and the impact of this reconstruction on the CNN performance. Here, we present a novel model denoted a dual-CNN (DualCNN) to improve the conventional CNN performance on crowd counting. Our DualCNN comprises a primal network for generating the density maps from the crowd image and a secondary network for reconstructing the crowd image from the density map. The two networks are trained through an iterative and alternating learning process, and the performance of the final model is improved by considering the interactions of the two networks. In addition, we introduce the attention mechanism into the dual network to enhance the primal network robustness against the background influence of the crowd image. The experimental results indicate that the proposed method significantly improves the performance of CNNs in crowd counting.
C1 [Guo, Huaping; Zhang, Li; Sun, Yange] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Henan, Peoples R China.
   [Guo, Huaping; Sun, Yange] Chinese Acad Sci, Inst Automat, Res Ctr Precis Sensing & Control, Beijing 100190, Peoples R China.
   [Wang, Rui] Xinyang Univ, Sch Big Data & Artificial Intelligence, Xinyang 464000, Henan, Peoples R China.
   [Zhang, Li] Zhengzhou Univ, Sch Comp & Artificial Intelligence, Zhengzhou 450001, Henan, Peoples R China.
C3 Xinyang Normal University; Chinese Academy of Sciences; Institute of
   Automation, CAS; Xinyang University; Zhengzhou University
RP Guo, HP; Sun, YE (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Henan, Peoples R China.; Guo, HP; Sun, YE (corresponding author), Chinese Acad Sci, Inst Automat, Res Ctr Precis Sensing & Control, Beijing 100190, Peoples R China.
EM hpguo@xynu.edu.cn; yangesun@xynu.edu.cn
OI Guo, Huaping/0000-0002-6585-1805
FU We wish to thank Xu Mingliang's team of Zhengzhou University and
   Wensheng Zhang' team of Chinese Academy of Sciences for their
   constructive comments and recommendations, which have significantly
   improved the presentation of this paper.
FX We wish to thank Xu Mingliang's team of Zhengzhou University and
   Wensheng Zhang' team of Chinese Academy of Sciences for their
   constructive comments and recommendations, which have significantly
   improved the presentation of this paper.
CR Abdou Mohamed, 2020, 2020 IEEE International Conference on Informatics, IoT, and Enabling Technologies (ICIoT), P48, DOI 10.1109/ICIoT48696.2020.9089594
   Ali SS, 2021, IEEE T EMERG TOP COM, V9, P612, DOI 10.1109/TETC.2019.2915288
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2015, PROC 23 ACM INT C MU, DOI 10.1145/2733373.2806337
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chen JW, 2020, NEUROCOMPUTING, V382, P210, DOI 10.1016/j.neucom.2019.11.064
   Chen K., 2015, Abc-cnn: An attention based convolutional neural network for visual question answering
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Chen Y, 2019, IEEE T CIRC SYST VID, V29, P12, DOI 10.1109/TCSVT.2017.2776239
   Chu X., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1831, DOI DOI 10.1109/CVPR.2017.601
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dwibedi Debidatta, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10384, DOI 10.1109/CVPR42600.2020.01040
   Foadian S, 2019, INT J COMPUT MATH, V96, P105, DOI 10.1080/00207160.2017.1417593
   Gao G, 2020, CoRR abs/2003.12783
   Gao JY, 2020, IEEE T CIRC SYST VID, V30, P3486, DOI 10.1109/TCSVT.2019.2919139
   Hassen KB, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145286
   He D, 2016, ADV NEUR IN, V29
   He SH, 2021, MED IMAGE ANAL, V68, DOI 10.1016/j.media.2020.101892
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Jiang XH, 2020, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR42600.2020.00476
   Jiang Xiaolong, 2019, IEEE C COMP VIS PATT
   Kingma D. P., 2014, arXiv
   Kumar Avanish, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P153, DOI 10.1007/978-3-030-67187-7_17
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumari Shreya, 2021, International Conference on Deep Learning, Artificial Intelligence and Robotics ICDLAIR 2019. Proceedings. Lecture Notes in Networks and Systems (LNNS 175), P339, DOI 10.1007/978-3-030-67187-7_35
   Li B, 2015, IEEE I CONF COMP VIS, P4175, DOI 10.1109/ICCV.2015.475
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu YB, 2021, APPL INTELL, V51, P427, DOI 10.1007/s10489-020-01842-w
   Liu YT, 2020, IEEE T IMAGE PROCESS, V29, P6800, DOI 10.1109/TIP.2020.2994410
   Mallasto A, 2018, PROC CVPR IEEE, P5580, DOI 10.1109/CVPR.2018.00585
   Miao YQ, 2020, AAAI CONF ARTIF INTE, V34, P11765
   Negi A., 2021, DEEP LEARNING BASED, P187
   Negi A., 2021, INT C BIG DATA ANALY, P296, DOI DOI 10.1007/978-3-030-93620-4_21
   Negi A., 2021, CLASSIFICATION DETEC, P63
   Negi A., 2021, FACE MASK DETECTION, P255
   Negi A., 2021, Agricultural Informatics: Automation using the IoT and Machine Learning, P117, DOI [10.1002/9781119769231.ch6, DOI 10.1002/9781119769231.CH6]
   Negi A, 2020, 2020 5TH IEEE INTERNATIONAL CONFERENCE ON RECENT ADVANCES AND INNOVATIONS IN ENGINEERING (IEEE - ICRAIE-2020), DOI 10.1109/ICRAIE51050.2020.9358337
   Park Jongchan, 2018, CoRR abs/1807.06514
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Rehman Yasar Abbas Ur, 2020, International Joint Conference: 12th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2019) and 10th International Conference on EUropean Transnational Education (ICEUTE 2019). Proceedings. Advances in Intelligent Systems and Computing (AISC 951), P3, DOI 10.1007/978-3-030-20005-3_1
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sindagi V.A., 2019, 2019 16 IEEE INT C, P1
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Tian YJ, 2018, NEUROCOMPUTING, V310, P223, DOI 10.1016/j.neucom.2018.05.027
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Nguyen V, 2020, INT J MULTIMED INF R, V9, P63, DOI 10.1007/s13735-019-00181-y
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang JW, 2018, PROC CVPR IEEE, P7190, DOI 10.1109/CVPR.2018.00751
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Yan C, 2020, NEUROCOMPUTING, V393, P115, DOI 10.1016/j.neucom.2017.12.072
   Yang YF, 2020, PROC CVPR IEEE, P4373, DOI 10.1109/CVPR42600.2020.00443
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu JT, 2022, MULTIMED TOOLS APPL, V81, P17223, DOI 10.1007/s11042-022-12672-y
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang A, 2019, IEEE I CONF COMP VIS, P5713, DOI 10.1109/ICCV.2019.00581
   Zhang B, 2021, NEUROCOMPUTING, V451, P12, DOI 10.1016/j.neucom.2021.04.045
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhou FB, 2022, MULTIMED TOOLS APPL, V81, P20541, DOI 10.1007/s11042-022-12249-9
   Zhu AC, 2022, IEEE T INTELL TRANSP, V23, P8090, DOI 10.1109/TITS.2021.3075859
   Zhu M, 2020, PATTERN RECOGN LETT, V135, P279, DOI 10.1016/j.patrec.2020.05.009
NR 78
TC 1
Z9 1
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26687
EP 26709
DI 10.1007/s11042-023-16442-2
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001058323600008
DA 2024-07-18
ER

PT J
AU Sarkar, A
   Karmakar, R
   Roy, M
AF Sarkar, Arindam
   Karmakar, Rahul
   Roy, Mandira
TI GAN-guided artificial neural collaborative complex computation for
   efficient neural synchronization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial networks (GAN); Session key; Pseudorandom number
   generator (PRNG); Artificial neural network (ANN)
ID KEY AGREEMENT; SECURITY; LEVEL
AB Achieving neural synchronization, one must be able to evaluate the degree of cooperation across Artificial Neural Networks (ANNs) on various sides, regardless of each network's particular weights. However, traditional approaches suffer from delays in evaluating collaboration, thereby jeopardizing the concealment of neural coordination. Furthermore, there is a paucity of study on employing a trustworthy Pseudo-Random Number Generator (PRNG) to produce a common input and reciprocate training a group of ANNs. This paper introduces the use of a Generative Adversarial Network (GAN) to successfully handle these issues and synchronize a collection of neural networks for session key switch over. This approach enables efficient and effective assessment of the final synchronization state among multiple ANNs. Reciprocal learning is employed to achieve synchronization between two neural networks and distribute the neural key through a single channel. When the ANNs have previously generated identical outputs, coordination is assessed based on this criterion. The proposed method offers several advantages, including: (1) the generation of ANN input sequences using a PRNG based on a GAN. Additionally, a neural feed-forward structure is utilized, incorporating inputs from a non-random "counter" to represent the statefulness of the PRNG. (2) Moreover, a complex ANNs ring or B-tree-guided group is leveraged to facilitate reciprocal neuronal alignment, leading to the creation of the session key via the public network, (3) The suggested methodology takes into account simple, geometry, and majority attacks, (4) The proposed strategy enables two communication partners to detect full synchronization more rapidly compared to previous approaches. The effectiveness of this recommended approach was thoroughly tested, and the results indicate its superiority over similar methods described in the existing literature.
C1 [Sarkar, Arindam] Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
   [Karmakar, Rahul; Roy, Mandira] Univ Burdwan, Dept Comp Sci, Burdwan 713104, W Bengal, India.
C3 University of Burdwan
RP Sarkar, A (corresponding author), Ramakrishna Mission Vidyamandira, Dept Comp Sci & Elect, Howrah 711202, W Bengal, India.
EM arindam.vb@gmail.com
RI Karmakar, Rahul/ACF-7334-2022
OI Karmakar, Rahul/0000-0002-6607-2707; Sarkar, Arindam/0000-0002-4951-4729
FU DBT STAR College scheme of Ramakrishna Mission Vidyamandira
FX This work was supported by DBT STAR College scheme of Ramakrishna
   Mission Vidyamandira.
CR Abadi Martin, 2016, arXiv
   [Anonymous], 2010, FUZZY INFORM PROCESS
   Bernardi Marcello, 2019, ECML PKDD 2018 Workshops. Nemesis 2018, UrbReas 2018, SoGood 2018 IWAISe 2018, and Green Data Mining 2018. Proceedings: Lecture Notes in Artificial Intelligence (LNAI 11329), P191, DOI 10.1007/978-3-030-13453-2_15
   Boyd Colin., 2013, PROTOCOLS AUTHENTICA
   Cao B, 2021, IEEE T INTELL TRANSP, V22, P3832, DOI 10.1109/TITS.2020.3048844
   Cao H, 2022, FRONT PSYCHOL, V13, DOI 10.3389/fpsyg.2022.900195
   Cao KR, 2021, IEEE T INF FOREN SEC, V16, P786, DOI 10.1109/TIFS.2020.3023277
   Chen GM, 2022, MATH PROBL ENG, V2022, DOI 10.1155/2022/3215337
   Chen YY, 2022, ENERGY REP, V8, P15399, DOI 10.1016/j.egyr.2022.11.120
   Cheng B, 2017, IEEE ACM T NETWORK, V25, P2082, DOI 10.1109/TNET.2017.2705239
   Cheng L, 2022, IEEE SIGNAL PROC MAG, V39, P18, DOI 10.1109/MSP.2022.3198201
   Dai XX, 2024, IEEE T MOBILE COMPUT, V23, P2520, DOI 10.1109/TMC.2023.3259394
   Dai XX, 2023, IEEE T IND INFORM, V19, P480, DOI 10.1109/TII.2022.3158974
   Deng X, 2023, IEEE T IMAGE PROCESS, V32, P1078, DOI 10.1109/TIP.2023.3240024
   Dolecki M, 2015, LECT NOTES COMPUT SC, V9339, P451, DOI 10.1007/978-3-319-24369-6_37
   Dong T, 2020, IEEE T NEUR NET LEAR, V31, P4999, DOI 10.1109/TNNLS.2019.2955165
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu QX, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12081774
   Gu XZ, 2012, J COMMUN NETW-S KOR, V14, P418, DOI 10.1109/JCN.2012.6292248
   Guan ZY, 2023, IEEE T PATTERN ANAL, V45, P372, DOI 10.1109/TPAMI.2022.3141725
   INGEMARSSON I, 1982, IEEE T INFORM THEORY, V28, P714, DOI 10.1109/TIT.1982.1056542
   Jarecki S, 2011, IEEE T PARALL DISTR, V22, P879, DOI 10.1109/TPDS.2010.128
   Jeong S, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/6680782
   Jeong YS, 2018, INT CONF BIG DATA, P541, DOI 10.1109/BigComp.2018.00091
   Jiang SC, 2022, J ADV TRANSPORT, V2022, DOI 10.1155/2022/3815306
   Jiang X., 2008, P INT C COMP SCI SOF, V3, P994
   Jiang YH, 2022, INT J ELECTRON, V109, P854, DOI 10.1080/00207217.2021.1941295
   Joux A, 2000, LECT NOTES COMPUT SC, V1838, P385
   Karakaya B, 2019, CHAOS SOLITON FRACT, V119, P143, DOI 10.1016/j.chaos.2018.12.021
   Kelsey J, 1998, LECT NOTES COMPUT SC, V1372, P168
   Kim Y., 2000, ACM C COMPUTER COMMU, P235, DOI DOI 10.1145/352600.352638
   Konstantinou E, 2013, LNCS, P563
   Kumar A, 2019, J DISCRET MATH SCI C, V22, P499, DOI 10.1080/09720529.2019.1637154
   LI D, 2021, IEEE T SYST MAN CYBE, P1
   Li J, 2022, ACM T SENSOR NETWORK, V18, DOI 10.1145/3529509
   Li QK, 2020, IEEE T SYST MAN CY-S, V50, P4905, DOI 10.1109/TSMC.2018.2884510
   Li RH, 2022, MEASUREMENT, V192, DOI 10.1016/j.measurement.2022.110886
   Liao Q, 2022, IEEE T KNOWL DATA EN, V34, P5154, DOI 10.1109/TKDE.2021.3054993
   Liu AA, 2022, IEEE T CIRC SYST VID, V32, P3685, DOI 10.1109/TCSVT.2021.3107035
   Liu F, 2023, MECH SYST SIGNAL PR, V184, DOI 10.1016/j.ymssp.2022.109727
   Liu H, 2022, IEEE T IMAGE PROCESS, V31, P7389, DOI 10.1109/TIP.2022.3222918
   Liu H, 2022, IEEE T CIRC SYST VID, V32, P1564, DOI 10.1109/TCSVT.2021.3069838
   Liu H, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105608
   Liu LF, 2016, IET INFORM SECUR, V10, P87, DOI 10.1049/iet-ifs.2014.0192
   Liu P, 2019, IEEE T NEUR NET LEAR, V30, P2358, DOI 10.1109/TNNLS.2018.2884620
   Liu Q, 2021, IEEE T IMAGE PROCESS, V30, P6623, DOI 10.1109/TIP.2021.3096060
   Liu X, 2022, IEEE T IND INFORM, V18, P5628, DOI 10.1109/TII.2022.3144016
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P1978, DOI 10.1109/TIP.2022.3147032
   Lu SY, 2023, PEERJ COMPUT SCI, V9, DOI 10.7717/peerj-cs.1400
   Lu ZC, 2024, IEEE T EVOLUT COMPUT, V28, P323, DOI 10.1109/TEVC.2022.3233364
   Luo HL, 2023, COMBUST FLAME, V249, DOI 10.1016/j.combustflame.2022.112609
   Lv ZH, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106300
   Meneses F, 2016, INT J COMPUT SCI NET, V16, P55
   Mi C, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10121961
   Peng Y, 2023, INFORM SCIENCES, V621, P672, DOI 10.1016/j.ins.2022.11.101
   Perrig A., 1999, Proceedings of 1999 International Workshop on Cryptographic Techniques and E-Commerce, P192
   Qian L, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12084073
   Qu ZG, 2023, IEEE T INTELL TRANSP, V24, P8677, DOI 10.1109/TITS.2022.3203791
   Sarkar A, 2021, NEURAL PROCESS LETT, V53, P1355, DOI 10.1007/s11063-021-10443-8
   Shao ZT, 2023, IEEE T POWER SYST, V38, P2970, DOI 10.1109/TPWRS.2023.3256120
   Steiner M., 1996, 3rd ACM Conference on Computer and Communications Security, P31, DOI 10.1145/238168.238182
   Steiner M, 2000, IEEE T PARALL DISTR, V11, P769, DOI 10.1109/71.877936
   Sun W, 2023, IEEE T POWER ELECTR, V38, P8027, DOI 10.1109/TPEL.2023.3267883
   Teodoro AAM, 2022, WIRELESS PERS COMMUN, V127, P1085, DOI 10.1007/s11277-021-08566-1
   Wang FW, 2022, IEEE SENS J, V22, P19046, DOI 10.1109/JSEN.2022.3201015
   Wang JW, 2022, FRONT NEUROROBOTICS, V16, DOI 10.3389/fnbot.2022.877069
   Wang QZ, 2023, INFORM SCIENCES, V619, P263, DOI 10.1016/j.ins.2022.11.035
   Wang S., 2023, IEEE Trans. Ind. Inf.
   Wang YH, 2022, IEEE T CIRC SYST VID, V32, P4417, DOI 10.1109/TCSVT.2021.3121062
   Wang YT, 2023, WIREL NETW, V29, P47, DOI 10.1007/s11276-022-03099-2
   Wu QH, 2009, LECT NOTES COMPUT SC, V5479, P153
   Xiao Z, 2023, IEEE J SEL AREA COMM, V41, P457, DOI 10.1109/JSAC.2022.3227027
   Xie XL, 2021, NAT HAZARDS, V107, P2573, DOI 10.1007/s11069-021-04505-2
   Yang S, 2022, IEEE T CIRC SYST VID, V32, P8037, DOI 10.1109/TCSVT.2022.3182426
   Yuan HP, 2022, J MANAGE ENG, V38, DOI 10.1061/(ASCE)ME.1943-5479.0001015
   Zhang L, 2011, INFORM SCIENCES, V181, P4318, DOI 10.1016/j.ins.2011.05.009
   Zhang XZ, 2022, APPL ENERG, V306, DOI 10.1016/j.apenergy.2021.118018
   Zhang X, 2023, CAAI T INTELL TECHNO, V8, P1480, DOI [10.1049/cit2.12174, 10.7633/j.issn.1003-6202.2023.06.001]
   Zhang X, 2024, COMPUT J, V67, P236, DOI 10.1093/comjnl/bxac171
   Zheng YZ, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020704
   Zheng YZ, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10101399
   Zhong QS, 2022, IEEE T CIRCUITS-II, V69, P4979, DOI [10.1109/TCSII.2022.3188036, 10.1109/IECON49645.2022.9969035]
   Zhou XX, 2022, APPL INTELL, V52, P12556, DOI 10.1007/s10489-021-03121-8
   Zhu H, 2022, IEEE SIGNAL PROC LET, V29, P1437, DOI 10.1109/LSP.2022.3178656
   Zhu W, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2022.3178242
   Zong CJ, 2022, BRODOGRADNJA, V73, P23, DOI 10.21278/brod73102
NR 86
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26387
EP 26418
DI 10.1007/s11042-023-16517-0
EA AUG 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300009
DA 2024-07-18
ER

PT J
AU Dalbouchi, R
   Zitouni, A
AF Dalbouchi, Roukaya
   Zitouni, Abdelkrim
TI A software/hardware secure watermarking scheme for Internet of Things
   applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Internet of Things; Watermarking scheme; Motion vectors; Embedding;
   Security
ID VIDEO WATERMARKING; ROBUST WATERMARKING; IMAGE WATERMARKING; HARDWARE
   IMPLEMENTATION; DCT; ALGORITHM; HYBRID; DOMAIN; SVD
AB The security of applications that run over limited resources such as the Internet of Things becomes a new challenge for researchers. Digital watermarking (WM) is among the favorable solutions used to ensure the security for this type of applications, since it allows the integration of a message in a multimedia document without adding an overheard, as in classic encryption. This paper presents a software and hardware implementation WM scheme based on motion vectors to ensure copyright protection for a video sequence. To preserve the robustness of the proposed WM scheme, two security techniques are used: the digital WM to insert a watermark in the video and the scrambling technique for overall video protection. The watermark insertion is processed in the motion vectors. These vectors are generated during the motion estimation task using the four-step search block-matching algorithm. As a watermark, we use a binary sequence where only one bit is embedded into the horizontal and vertical components of the even motion vectors. The experimental results show that the proposed architecture preserves keeps the video quality with an average PSNR deviation rate of about 0.21dB and operates with low power consumption that did not exceed 119 mw and a maximum frequency of about 41.42 MHz.
C1 [Dalbouchi, Roukaya; Zitouni, Abdelkrim] Univ Kairouan, Inst Appl Sci & Technol Kasserine ISSATKas, POB 471, Kasserine 1200, Tunisia.
   [Zitouni, Abdelkrim] Univ Monastir, Lab Elect & Microelect, Monastir, Tunisia.
   [Zitouni, Abdelkrim] Fac Sci Monastir, Dept Phys, Monastir 5000, Tunisia.
C3 Universite de Kairouan; Universite de Monastir; Universite de Monastir
RP Dalbouchi, R (corresponding author), Univ Kairouan, Inst Appl Sci & Technol Kasserine ISSATKas, POB 471, Kasserine 1200, Tunisia.
EM roukayadalbouchi@yahoo.fr
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Acharjee S, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTROL, INSTRUMENTATION, COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICCICCT), P532, DOI 10.1109/ICCICCT.2014.6993019
   Aissaoui N, 2022, 2022 7 INT C IM SIGN, P1
   Al-Shayea TK, 2019, IEEE ICC
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P11751, DOI 10.1007/s11042-017-4815-6
   Alromih A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124346
   Aly HA, 2011, IEEE T INF FOREN SEC, V6, P14, DOI 10.1109/TIFS.2010.2090520
   Amara A, 2006, MICROELECTRON J, V37, P669, DOI 10.1016/j.mejo.2005.11.003
   [Anonymous], 2016 24 TEL FOR TELF, P1
   Ariatmanto D, 2022, J KING SAUD UNIV-COM, V34, P605, DOI 10.1016/j.jksuci.2020.02.005
   Bas P, 2001, PROC SPIE, V4472, P85, DOI 10.1117/12.449743
   Bas P., 2003, TATOUAGE IMAGES COUL
   Caldelli R, 2000, 2000 10 EUR SIGN PRO, P1
   Cox I. J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P6, DOI 10.1109/ITCC.2000.844175
   Cox IJ., 2007, DIGITAL WATERMARKING
   Daf M MP, 2020, REV PAPER NOVEL DESI, V3
   Dai YJ, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1845
   Das S, 2020, MICROPROCESS MICROSY, V76, DOI 10.1016/j.micpro.2020.103092
   Davis P., 2014, INT J ADV RES ELECT, V3, P122
   de Senneville BD, 2015, IEEE T MED IMAGING, V34, P974, DOI 10.1109/TMI.2014.2371995
   Elbasi E, 2020, 2020 7TH INTERNATIONAL CONFERENCE ON INTERNET OF THINGS: SYSTEMS, MANAGEMENT AND SECURITY (IOTSMS), DOI 10.1109/IOTSMS52051.2020.9340222
   Ferdowsi A, 2018, IEEE ICC
   Glissa G, 2017, INT WIREL COMMUN, P264, DOI 10.1109/IWCMC.2017.7986297
   Hammami A, 2021, MULTIMED TOOLS APPL, V80, P7479, DOI 10.1007/s11042-020-09982-4
   Houmansadr A, 2006, 2006 IEEE INT C ENG, P1
   Islam MN, 2018, INT SYMPOS VLSI DES
   Janu N., 2021, IOP conference series: materials science and engineering, V1131
   Joshi AM, 2015, INT J ELECTRON, V102, P141, DOI 10.1080/00207217.2014.954634
   Joumaa H, 2003, 19 C TRAIT SIGN IM F
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   KarthigaiKumar P, 2011, J SYST ARCHITECT, V57, P404, DOI 10.1016/j.sysarc.2010.03.008
   Kuo TY, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P853, DOI 10.1109/IIH-MSP.2008.230
   Lee SJ, 2001, ISIE 2001: IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS PROCEEDINGS, VOLS I-III, P272, DOI 10.1109/ISIE.2001.931796
   Li X, 2008, HARDWARE IMPLEMENTAT
   Liang W, 2021, IEEE T EMERG TOP COM, V9, P1410, DOI 10.1109/TETC.2020.2993032
   Liang W, 2020, IEEE INTERNET THINGS, V7, P6392, DOI 10.1109/JIOT.2020.2974281
   Lin KZ, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1105, DOI 10.1109/ISKE.2008.4731095
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Mane GV., 2013, Int J Sci Res Publ, V3, P1
   Manikandan LC, 2014, INT J SCI ENG RES, V5
   Mareen H, 2019, IEEE T INF FOREN SEC, V14, P1432, DOI 10.1109/TIFS.2018.2879301
   Mathai NJ, 2003, IEEE T SIGNAL PROCES, V51, P925, DOI 10.1109/TSP.2003.809382
   Mehta P, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.4.043043
   Mohanty SP, 2011, J SYST SOFTWARE, V84, P724, DOI 10.1016/j.jss.2010.12.012
   Mostafa K. S. A., 2016, J. Inf. Secur., V7, P260, DOI [10.4236/jis.2016.74021, DOI 10.4236/JIS.2016.74021]
   Najafi E, 2019, J INF SECUR APPL, V44, P144, DOI 10.1016/j.jisa.2018.12.002
   Pexaras K, 2019, IEEE T CIRCUITS-I, V66, P2088, DOI 10.1109/TCSI.2019.2907191
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Powar PV., 2013, INT J ELECT ELECT CO, V1, P99
   Priya CVL, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P2026, DOI 10.1109/ICCSP.2017.8286758
   Raghavendra K., 2010, IJCA, V4, P19, DOI [10.5120/863-1213, DOI 10.5120/863-1213]
   Rakheja P, 2019, OPTIK, V198, DOI 10.1016/j.ijleo.2019.163289
   Roy SD, 2013, IEEE T CIRC SYST VID, V23, P300, DOI 10.1109/TCSVT.2012.2203738
   Seddik H, 2005, INT C SCI EL TECHN I
   Shi GC, 2015, INT J SECUR APPL, V9, P19, DOI 10.14257/ijsia.2015.9.4.03
   Shin Yong-Dal, 2018, [JOURNAL OF KOREA MULTIMEDIA SOCIETY, 멀티미디어학회논문지], V21, P342, DOI 10.9717/kmms.2018.21.3.342
   Singh L, 2020, MULTIMED TOOLS APPL, V79, P15901, DOI 10.1007/s11042-018-6407-5
   Singh R, 2017, P 2 IET INT C BIOM I, P1, DOI [10.1049/cp.2017.0093, DOI 10.1049/CP.2017.0093]
   Song X, 2008, 2008 11 IEEE INT C C, P738
   Su K, 2001, IEEE IMAGE PROC, P818, DOI 10.1109/ICIP.2001.959171
   Tamilvanan K, 2014, INT J COMPUT SCI MOB, V3, P1321
   Tanaka K., 1990, MILCOM 90. A New Era. 1990 IEEE Military Communications Conference. Conference Record (Cat. No.90CH2831-6), P216, DOI 10.1109/MILCOM.1990.117416
   Hoang TM, 2020, 2020 34TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2020), P649, DOI [10.1109/ICOIN48656.2020.9016541, 10.1109/icoin48656.2020.9016541]
   Vassaux B, 2002, 2002 11 EUR SIGN PRO, P1
   Wang K, 2009, CORESA Compression et REpresentation des Signaux Audiovisuels
   Wazid M, 2020, J NETW COMPUT APPL, V150, DOI 10.1016/j.jnca.2019.102496
   Yann Bodo, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1501
   Yi LT, 2019, IEEE ACCESS, V7, P53079, DOI 10.1109/ACCESS.2019.2911395
   Zhang GY, 2017, SECUR COMMUN NETW, DOI 10.1155/2017/3126010
   Zhang J, 2001, XIV BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P179, DOI 10.1109/SIBGRAPI.2001.963053
NR 72
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 29
PY 2023
DI 10.1007/s11042-023-16533-0
EA AUG 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q9MT6
UT WOS:001060692700007
DA 2024-07-18
ER

PT J
AU Artois, J
   Courteaux, M
   Van Wallendael, G
   Lambert, P
AF Artois, Julie
   Courteaux, Martijn
   Van Wallendael, Glenn
   Lambert, Peter
TI OpenDIBR: Open Real-Time Depth-Image-Based renderer of light field
   videos for VR
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field rendering; View synthesis; Depth-image-based rendering; Real
   time; Virtual Reality
ID DIBR
AB In this work, we present a novel light field rendering framework that allows a viewer to walk around a virtual scene reconstructed from a multi-view image/video dataset with visual and depth information. With immersive media applications in mind, the framework is designed to support dynamic scenes through input videos, give the viewer full freedom of movement in a large area, and achieve real-time rendering, even in Virtual Reality (VR). This paper explores how Depth-Image-Based Rendering (DIBR) is one of the few state-of-the-art techniques that achieves all requirements. We therefor implemented OpenDIBR, an Openly available DIBR, as a proof of concept for the framework. It uses Nvidia's Video Codec SDK to rapidly decode the color and depth videos on the GPU. The decoded depth maps and color frames are then warped to the output view in OpenGL. Each input contribution is blended together through a per-pixel weighted average depending on the input and output camera positions. Experiments comparing the visual quality conclude that OpenDIBR is, objectively and subjectively, similar to TMIV and better than NeRF. Performancewise, OpenDIBR runs at 90 Hz for up to 4 full HD input videos on desktop, or 2-4 in VR, and there are options to further increase this by lowering the video bitrates, reducing the depth map resolution or dynamically lowering the number of rendered input videos.
C1 [Artois, Julie; Courteaux, Martijn; Van Wallendael, Glenn; Lambert, Peter] Ghent Univ Imec, IDLab MEDIA, Ghent, Belgium.
C3 Ghent University; IMEC
RP Artois, J (corresponding author), Ghent Univ Imec, IDLab MEDIA, Ghent, Belgium.
EM julie.artois@ugent.be
RI Van Wallendael, Glenn/H-8315-2015; Courteaux, Martijn/IUO-8125-2023
OI Van Wallendael, Glenn/0000-0001-9530-3466; Courteaux,
   Martijn/0000-0002-9971-3128
FU Research Foundation - Flanders (FWO) [1SD8221N]; IDLab (Ghent University
   - imec); European Union; Flanders Innovation and Entrepreneurship
   (VLAIO)
FX This work was funded in part by the Research Foundation - Flanders (FWO)
   under Grant 1SD8221N, in part by IDLab (Ghent University - imec),
   Flanders Innovation and Entrepreneurship (VLAIO), and the European
   Union.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   Attal B., 2020, P EUR C COMP VIS ECC, P441
   Baños RM, 2004, CYBERPSYCHOL BEHAV, V7, P734, DOI 10.1089/cpb.2004.7.734
   Biocca F., 1995, Communication in the age of virtual reality, V15, P10
   BOLLES RC, 1987, INT J COMPUT VISION, V1, P7, DOI 10.1007/BF00128525
   Bonatto D., 2020, ELECT IMAGING, DOI 10.2352/ISSN.2470-1173.2020.13. ERVR-382
   Bonatto D, 2021, IEEE ACCESS, V9, P146868, DOI 10.1109/ACCESS.2021.3123529
   Broxton M., 2020, ACM SIGGRAPH 2020 Immersive Pavilion, P1
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Chan SC, 2021, IMAGE BASED RENDERIN, P656
   Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153
   Chen XD, 2021, MULTIMED TOOLS APPL, V80, P11557, DOI 10.1007/s11042-020-10196-x
   Courteaux M, 2022, PROCEEDINGS OF THE 13TH ACM MULTIMEDIA SYSTEMS CONFERENCE, MMSYS 2022, P221, DOI 10.1145/3524273.3532890
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Dinechin GDd, 2020, 2020 IEEE C VIRTUAL, P348, DOI DOI 10.1109/VRW50115.2020.00076
   Do L, 2012, IEEE T CONSUM ELECTR, V58, P633, DOI 10.1109/TCE.2012.6227470
   Dziembowski A, 2020, document ISO/IEC JTC1/SC29/WG11 MPEG/M54176
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   FIELD DA, 1988, COMMUN APPL NUMER M, V4, P709, DOI 10.1002/cnm.1630040603
   Gersak G, 2020, MULTIMED TOOLS APPL, V79, P14491, DOI 10.1007/s11042-018-6969-2
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Hedman P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5855, DOI 10.1109/ICCV48922.2021.00582
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Jung J, 2022, JTC1SC29WG04 ISOIEC
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kertész G, 2015, 2015 IEEE 10TH JUBILEE INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P237, DOI 10.1109/SACI.2015.7208206
   Koniaris B, 2017, P 43 GRAPH INT C GI, P33, DOI DOI 10.20380/GI2017.05
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li JS, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4632, DOI 10.1145/3474085.3475339
   Mildenhall B, 2020, EUR C COMPUT VIS ECC
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   MPEG-I Visual, 2022, TEST MOD MPEG IMM VI
   Müller T, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530127
   Netflix Technology Blog, 2018, VMAF JOURN CONT
   NVidia, 2022, NVID VID COD SDK
   Oh KJ, 2009, PCS: 2009 PICTURE CODING SYMPOSIUM, P233
   Overbeck RS, 2018, ACM SIGGRAPH VIRTUAL
   Penner E, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130855
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Riegler Gernot, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P623, DOI 10.1007/978-3-030-58529-7_37
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   Stankiewicz O., 2013, JTC1SC29WG11 ISOIEC
   Sun W., 2010, APSIPA ASC 2010 ASIA, P1023
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xie Y., 2021, 2021 INT JOINT C NEU, P1
   Yao L, 2019, MULTIMED TOOLS APPL, V78, P19325, DOI 10.1007/s11042-019-7236-x
   Zhang C, 2004, SIGNAL PROCESS-IMAGE, V19, P1, DOI 10.1016/j.image.2003.07.001
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 50
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 25797
EP 25815
DI 10.1007/s11042-023-16250-8
EA AUG 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001052530800001
DA 2024-07-18
ER

PT J
AU Rabhi, B
   Elbaati, A
   Boubaker, H
   Pal, U
   Alimi, AM
AF Rabhi, Besma
   Elbaati, Abdelkarim
   Boubaker, Houcine
   Pal, Umapada
   Alimi, Adel M.
TI Multi-lingual handwriting recovery framework based on convolutional
   denoising autoencoder with attention model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Attention model; BGRU; Pressure recovery; SDA; Temporal order
   restoration; Velocity reconstruction
ID ORDER
AB For several decades, no satisfactory solutions have been provided to the problem of offline handwriting recognition. In the field of online recognition, researchers have had more successful performance, but the ability to extract dynamic information from static images has not been well explored yet. In this paper, we introduce a novel multi-lingual word handwriting recovery framework based on a convolutional denoising autoencoder with an attention model for pen up/down, velocity and temporal order recovery. The proposed framework consists of extracting robust features from a handwriting image using a stacked denoising autoencoder and an encoder Bidirectional Gated Recurrent Unit (BGRU) model. Then, the obtained vectors are decoded to produce an online script with dynamic characteristics using a BGRU with temporal attention. Evaluation is done on a Latin and Arabic Online and offline handwriting character / word databases and the proposed framework achieves high competitive results.
C1 [Rabhi, Besma; Boubaker, Houcine; Alimi, Adel M.] Univ Sfax, Natl Engn Sch Sfax, REGIM Lab, Res Grp Intelligent Machines, LR11ES48, Sfax 3038, Tunisia.
   [Elbaati, Abdelkarim; Boubaker, Houcine] Univ Monastir, Higher Inst Appl Sci & Technol Mahdia, REGIM Lab, Res Grp Intelligent Machines, LR11ES48, Mahdia 5121, Tunisia.
   [Boubaker, Houcine; Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, 203 B T Rd, Kolkata 700108, India.
   [Boubaker, Houcine; Alimi, Adel M.] Univ Johannesburg, Fac Engn & Built Environm, Dept Elect & Elect Engn Sci, Johannesburg, South Africa.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Monastir; Indian Statistical Institute; Indian Statistical
   Institute Kolkata; University of Johannesburg
RP Rabhi, B (corresponding author), Univ Sfax, Natl Engn Sch Sfax, REGIM Lab, Res Grp Intelligent Machines, LR11ES48, Sfax 3038, Tunisia.
EM besma.rebhi.2015@ieee.org; abdelkarim.elbaati@googlemail.com;
   houcine.boubaker1@gmail.com; umapada@isical.ac.in
RI Rabhi, Besma/IQV-6216-2023; Alimi, Adel M./A-5697-2012
OI Rabhi, Besma/0000-0003-2964-4363; Alimi, Adel M./0000-0002-0642-3384
CR Akouaydi H, 2019, PROC INT CONF DOC, P41, DOI 10.1109/ICDARW.2019.50114
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bhunia AK, 2018, INT C PATT RECOG, P3639, DOI 10.1109/ICPR.2018.8546093
   Boubaker H., 2012, Guide to OCR for Arabic Scripts, P541
   Chen Z., 2022, P AS C COMP VIS
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Crispo G, 2018, INT CONF FRONT HAND, P351, DOI 10.1109/ICFHR-2018.2018.00068
   Dhahri H, 2021, CMC-COMPUT MATER CON, V69, P3259, DOI 10.32604/cmc.2021.018449
   Dhieb T, 2019, PROC INT CONF DOC, P35, DOI 10.1109/ICDARW.2019.50113
   Diaz M, 2017, P INT C DOC AN REC I
   Diaz M, 2022, LECT NOTES COMPUT SC, V13424, P11, DOI 10.1007/978-3-031-19745-1_2
   El Baati A, 2005, I C COMP SYST APPLIC
   Elbaati Abdelkarim, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1116, DOI 10.1109/ICDAR.2009.266
   Hamdi Yahia, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P545, DOI 10.1109/ICDAR.2019.00093
   Hamdi Y, 2021, INT J DOC ANAL RECOG, V24, P283, DOI 10.1007/s10032-021-00376-2
   Hassaïne A, 2013, PROC INT CONF DOC, P1412, DOI 10.1109/ICDAR.2013.285
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jentzen A, 2020, J COMPLEXITY, V57, DOI 10.1016/j.jco.2019.101438
   Kato Y, 2000, IEEE T PATTERN ANAL, V22, P938, DOI 10.1109/34.877517
   Kha VA, 2016, REV J ELECT COMMUN, V6, P1
   Kherallah M, 2008, 11 INT C FRONT HANDW
   Dinh M, 2016, EXPERT SYST APPL, V64, P352, DOI 10.1016/j.eswa.2016.08.017
   Muramatsu D, 2007, LECT NOTES COMPUT SC, V4642, P503
   Nakai M, 2002, INT C PATT RECOG, P220, DOI 10.1109/ICPR.2002.1047834
   Noubigh Z, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P69, DOI 10.1109/ASAR.2017.8067762
   Qiao Y, 2006, IEEE T PATTERN ANAL, V28, P1724, DOI 10.1109/TPAMI.2006.216
   Rabhi Besma, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1231, DOI 10.1109/ICDAR.2019.00199
   Rabhi B, 2021, LECT NOTES COMPUT SC, V12916, P366, DOI 10.1007/978-3-030-86198-8_26
   Rabhi B, 2021, MEMET COMPUT, V13, P459, DOI 10.1007/s12293-021-00345-6
   Rousseau L, 2005, PROC INT CONF DOC, P1121, DOI 10.1109/ICDAR.2005.199
   Rui Zhang, 2019, 2019 Eleventh International Conference on Advanced Computational Intelligence (ICACI), P129, DOI 10.1109/ICACI.2019.8778533
   Sesa-Nogueras E, 2012, PATTERN RECOGN, V45, P128, DOI 10.1016/j.patcog.2011.06.002
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Steinherz T, 2009, IEEE T PATTERN ANAL, V31, P193, DOI 10.1109/TPAMI.2008.68
   Vargas J.F., 2008, Proc of the 11th Int'l Conference on Frontiers in Handwriting Recognition, P373
   Viard-Gaudin C., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P455, DOI 10.1109/ICDAR.1999.791823
   Vincent P., 2008, INT C MACH LEARN ICM, P1096, DOI [10.1145/1390156.1390294, DOI 10.1145/1390156.1390294]
   Wang Y, 2020, 2 STAGE FULLY CONVOL
   Yanikoglu B, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/260516
NR 42
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 21
PY 2023
DI 10.1007/s11042-023-16499-z
EA AUG 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q0AU5
UT WOS:001054228300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, SS
   Ni, WJ
   Zeng, QT
   Xie, NF
   Li, C
AF Wang, Shan-Song
   Ni, Wei-Jian
   Zeng, Qing-Tian
   Xie, Neng-Fu
   Li, Chao
TI APD-229: a textual-visual database for agricultural pests and diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Database; Multimedia technology adoption; Agricultural pests and
   diseases
ID CLASSIFICATION; IDENTIFICATION; FEATURES
AB The damage caused by agricultural pests and diseases has brought huge losses to the economy. Rapid recognition and timely treatment can minimize economic losses. Most of the existing image databases are produced in laboratories, where the shooting costs are expensive, and the background of these images are very different from the real farmland environment. Moreover, although the existing recognition systems can locate entities, they cannot provide discriminative evidence which is semantically interpretable, which makes it difficult for them to distinguish entities with very similar appearances. Fortunately, there are text descriptions in professional agricultural control documents that can clearly distinguish similar entities. In this paper, a textual-visual database for agricultural pests and diseases named APD-229 is constructed. The goal of APD-229 is to learn prior knowledge that can distinguish similar entities from the control documents, and to guide the image recognition system to complete the task of fine-grained classification. The database contains two sub databases: pest set and disease set. A total of 121,213 images and 8,209 text descriptions belong to 229 categories. Furthermore, extensive experiments were carried out on APD229, results show that in the single-modal image classification task, the accuracy of pest database is 75.15% and the accuracy of disease database is 61.23%. While in the multi modal image classification task, the accuracy is 78.74% and 71.67% respectively. Compare with the single-model experiment, the accuracy of multi-model is improved by 4.78% and 17% respectively. APD-229 is publicly available at https://github.com/SDUST-MMML/ APD-229.
C1 [Wang, Shan-Song; Ni, Wei-Jian; Zeng, Qing-Tian; Li, Chao] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
   [Xie, Neng-Fu] Chinese Acad Agr Sci, Inst Agr Informat, Beijing 100081, Peoples R China.
C3 Shandong University of Science & Technology; Chinese Academy of
   Agricultural Sciences
RP Ni, WJ; Zeng, QT (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM wangss15689457686@163.com; niweijian@gmail.com; qtzeng@163.com;
   nfxie@caas.net.cn; 1008lichao@163.com
FU National Key Ramp;D Program of China [2022ZD0119500, 2022ZD0119501];
   NSFC [U1931207, 61702306]; Sci. amp; Tech. Development Fund of Shandong
   Province of China [ZR2022MF288, ZR2023MF097]; Taishan Scholar Program of
   Shandong Province [ts20190936]; SDUST Research Fund [2015TDJH102,
   2019KJN024]; Shandong Chongqing Science and technology cooperation
   project [cstc2020jscx-lyjsAX0008]
FX This work is supported by National Key R & D Program of China
   [2022ZD0119500 and 2022ZD0119501]; NSFC [U1931207 and 61702306]; Sci. &
   Tech. Development Fund of Shandong Province of China [ZR2022MF288,
   ZR2023MF097]; the Taishan Scholar Program of Shandong
   Province[ts20190936], and SDUST Research Fund [2015TDJH102 and
   2019KJN024]; Shandong Chongqing Science and technology cooperation
   project [cstc2020jscx-lyjsAX0008].
CR Abbas I, 2021, PLANTS-BASEL, V10, DOI 10.3390/plants10122643
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Alfarisy AA, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON MATHEMATICS AND ARTIFICIAL INTELLIGENCE (ICMAI 2018), P21, DOI 10.1145/3208788.3208795
   Ali Ammar Alhaj, 2021, Artificial Intelligence in Intelligent Systems: Proceedings of 10th Computer Science On-line Conference 2021. Lecture Notes in Networks and Systems (229), P268, DOI 10.1007/978-3-030-77445-5_24
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   Amakdouf H, 2021, MULTIMED TOOLS APPL, V80, P3173, DOI 10.1007/s11042-020-09781-x
   Vo AT, 2017, INT CONF KNOWL SYS, P197, DOI 10.1109/KSE.2017.8119458
   Aravind KR, 2020, AUTOMATIKA-UK, V61, P260, DOI 10.1080/00051144.2020.1728911
   Ashraf Patankar A, 2020, ARXIV
   Center SFAI, 1994, 151611994 GBT CTR SF
   Cheng X, 2017, COMPUT ELECTRON AGR, V141, P351, DOI 10.1016/j.compag.2017.08.005
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dubey SR, 2022, IEEE T CIRC SYST VID, V32, P2687, DOI 10.1109/TCSVT.2021.3080920
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Espíndola RP, 2005, WIT TRANS INFO COMM, P25
   Fernández A, 2008, FUZZY SET SYST, V159, P2378, DOI 10.1016/j.fss.2007.12.023
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Gaonkar A., 2021 INT C INTELLIGE, V2021, P1, DOI DOI 10.1109/CONIT51480.2021.9498415
   Goldberg Y, 2014, Arxiv, DOI [arXiv:1402.3722, DOI 10.48550/ARXIV.1402.3722]
   Selvaraj MG, 2019, PLANT METHODS, V15, DOI 10.1186/s13007-019-0475-z
   Guo XJ, 2019, Arxiv, DOI [arXiv:1902.10859, DOI 10.48550/ARXIV.1902.10859]
   Gur S, 2021, Arxiv, DOI arXiv:2104.08108
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341692009 GBT
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341652009 GBT
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341642009 GBT
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341672009 GBT
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341662009 GBT
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341632009 GBT
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341622009 GBT
   Hebei Plant Protection PIS National Agricultural Technology Extension Service Center ZCPP Station PI, 2009, 2341682009 GBT
   Henan University of Technology CNGOIC, 2018, 17092018 LST CNGOIC, VLS/t 1709-2018
   Hyeon Park, 2018, 2018 International Conference on Computing and Network Communications (CoCoNet). Proceedings, P23, DOI 10.1109/CoCoNet.2018.8476914
   Iandola F, 2014, Arxiv, DOI [arXiv:1404.1869, DOI 10.48550/ARXIV.1404.1869]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiasen Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10434, DOI 10.1109/CVPR42600.2020.01045
   Kaur H, 2021, ARCH COMPUT METHOD E, V28, P4425, DOI 10.1007/s11831-021-09540-7
   Kheirkhah FM, 2019, IET COMPUT VIS, V13, P369, DOI 10.1049/iet-cvi.2018.5028
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni O, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Li JJ, 2022, INFORM FUSION, V79, P229, DOI 10.1016/j.inffus.2021.10.018
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ZY, 2016, SCI REP-UK, V6, DOI 10.1038/srep20410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Lu T, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-95218-w
   Mahalakshmi SD, 2021, J AMB INTEL HUM COMP, V12, P7375, DOI 10.1007/s12652-020-02413-0
   Nanni L, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101089
   Nuyts J, 2006, EXPR COGN CATEG, V1, P1
   Prabhakar M, 2020, MULTIMED TOOLS APPL, V79, P28773, DOI 10.1007/s11042-020-09461-w
   Rahman CR, 2020, BIOSYST ENG, V194, P112, DOI 10.1016/j.biosystemseng.2020.03.020
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Research Institute of Forest Ecology E Protection NFAFPCS Chinese Academy of Forestry, 2011, 157752011 GBT RES I
   Samanta R., 2012, International Journal of Computer Engineering Science (IJCES), V2, P1
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Shen J, 2020, INFORM SCIENCES, V569
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Szegedy C, 2015, Arxiv, DOI arXiv:1512.00567
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, DOI 10.48550/ARXIV.1409.4842]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   TRI of Chinese Academy of Agricultural Sciences, 2008, 232222008 GBT TRI CH
   Türkoglu M, 2019, TURK J ELECTR ENG CO, V27, P1636, DOI 10.3906/elk-1809-181
   Venugoban Kanesh, 2014, International Journal of Machine Learning and Computing, V4, P1, DOI 10.7763/IJMLC.2014.V4.376
   Wang JN, 2012, KNOWL-BASED SYST, V33, P102, DOI 10.1016/j.knosys.2012.03.014
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Wang SJ, 2020, IEEE WINT CONF APPL, P1497, DOI 10.1109/WACV45572.2020.9093614
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wickramanayake S, 2021, Arxiv, DOI arXiv:2101.03919
   Wu XP, 2019, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2019.00899
   Xiao XY, 2010, LECT NOTES ARTIF INT, V6216, P149, DOI 10.1007/978-3-642-14932-0_19
   Xie CJ, 2018, COMPUT ELECTRON AGR, V152, P233, DOI 10.1016/j.compag.2018.07.014
   Zhang Y, 2021, Computational Intelligence and Neuroscience
   Zhiyong Wang, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P650, DOI 10.1109/DICTA.2011.115
   Zhou CT, 2015, Arxiv, DOI [arXiv:1511.08630, DOI 10.48550/ARXIV.1511.08630]
NR 79
TC 0
Z9 0
U1 8
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 17
PY 2023
DI 10.1007/s11042-023-15393-y
EA AUG 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA P3YY0
UT WOS:001050048600002
DA 2024-07-18
ER

PT J
AU Yadav, A
   Vishwakarma, DK
AF Yadav, Ankit
   Vishwakarma, Dinesh Kumar
TI Deep learning algorithms for person re-identification: sate-of-the-art
   and research challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Person Re-Identification; Deep Learning; Convolutional Neural Network;
   Feature Extraction & Fusion
ID MULTI-LOSS; NETWORKS; VIDEO; REPRESENTATION; MODEL; FEATURES; MATCH
AB Person re-identification has received a lot of attention from the research community in recent times. Due to its vital role in security based applications, person re-identification lies at the heart of research relevant to tracking robberies, preventing terrorist attacks and other security critical events. While the last decade has seen tremendous growth in re-id approaches, very little review literature exists to comprehend and summarize this progress. This review deals with the latest state-of-the-art deep learning based approaches for person re-identification. While the few existing re-id review works have analysed re-id techniques from a singular aspect, this review evaluates numerous re-id techniques from multiple deep learning aspects such as deep architecture types, common Re-Id challenges (variation in pose, lightning, view, scale, partial or complete occlusion, background clutter), multi-modal Re-Id, cross-domain Re-Id challenges, metric learning approaches and video Re-Id contributions. This review also includes several re-id benchmarks collected over the years, describing their characteristics, specifications and top re-id results obtained on them. The inclusion of the latest deep re-id works makes this a significant contribution to the re-id literature. Lastly, the conclusion and future directions are included.
C1 [Yadav, Ankit; Vishwakarma, Dinesh Kumar] Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Bawana Rd, Delhi 110042, India.
C3 Delhi Technological University
RP Vishwakarma, DK (corresponding author), Delhi Technol Univ, Dept Informat Technol, Biometr Res Lab, Bawana Rd, Delhi 110042, India.
EM ankit4607@gmail.com; dvishwakarma@gmail.com
RI VISHWAKARMA, DINESH KUMAR/L-3815-2018; Yadav, Ankit/KHU-7192-2024
OI VISHWAKARMA, DINESH KUMAR/0000-0002-1026-0047; Yadav, Dr.
   Ankit/0000-0001-5012-1634
CR Almasawa MO, 2019, IEEE ACCESS, V7, P175228, DOI 10.1109/ACCESS.2019.2957336
   [Anonymous], 2009, BRIT MACH VIS C LOND
   [Anonymous], 2007, IEEE INT WORKSH PERF
   Avola D, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185365
   Bai X, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107036
   Bak S, 2018, IEEE T CIRC SYST VID, V28, P2690, DOI 10.1109/TCSVT.2017.2765242
   Baltieri D, 2011, MM 11 P 2011 ACM MUL
   Bao TL, 2019, INT J INNOV COMPUT I, V15, P1037, DOI 10.24507/ijicic.15.03.1037
   Barbosa IB, 2012, LECT NOTES COMPUT SC, V7583, P433, DOI 10.1007/978-3-642-33863-2_43
   Cai X, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106772
   Chang YS, 2020, PATTERN RECOGN LETT, V130, P306, DOI 10.1016/j.patrec.2018.08.011
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen M, 2018, IEEE ACCESS, V6, P68089, DOI 10.1109/ACCESS.2018.2879490
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chen Y, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104587
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Chen YQ, 2018, IMAGE VISION COMPUT, V79, P25, DOI 10.1016/j.imavis.2018.09.001
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Choe C, 2019, MULTIMED TOOLS APPL, V78, P27719, DOI 10.1007/s11042-019-07867-9
   Delussu R, 2023, EXPERT SYST APPL, V226, DOI 10.1016/j.eswa.2023.120216
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Ding ZM, 2019, IEEE T CIRC SYST VID, V29, P3173, DOI 10.1109/TCSVT.2018.2879626
   Duan YQ, 2018, IEEE T CIRC SYST VID, V28, P2644, DOI 10.1109/TCSVT.2017.2711015
   Ess A, 2007, IEEE I CONF COMP VIS, P2065
   Fan X, 2019, J VIS COMMUN IMAGE R, V60, P51, DOI 10.1016/j.jvcir.2019.01.010
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Feng ZX, 2018, IEEE T IMAGE PROCESS, V27, P3472, DOI 10.1109/TIP.2018.2818438
   Fu MX, 2019, IEEE ACCESS, V7, P73253, DOI 10.1109/ACCESS.2019.2920426
   Ganin Y, 2016, J MACH LEARN RES, V17
   Genç A, 2019, MULTIMED TOOLS APPL, V78, P5843, DOI 10.1007/s11042-018-6409-3
   Girija S, 2023, INTERNET THINGS 2023
   Gohar I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030949
   Gou MR, 2017, IEEE COMPUT SOC CONF, P1425, DOI 10.1109/CVPRW.2017.185
   Gupta A., 2022, INTELL SYST APPL, V16
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He L, 2023, OPTIK, V277
   He ZP, 2019, MULTIMED TOOLS APPL, V78, P5863, DOI 10.1007/s11042-018-6408-4
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hu JL, 2018, IEEE T PATTERN ANAL, V40, P2281, DOI 10.1109/TPAMI.2017.2749576
   Hu JL, 2016, IEEE T IMAGE PROCESS, V25, P5576, DOI 10.1109/TIP.2016.2612827
   Huang Y, 2017, NEUROCOMPUTING, V241, P191, DOI 10.1016/j.neucom.2017.02.055
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Jacques JCS Jr, 2018, IMAGE VISION COMPUT, V79, P76, DOI 10.1016/j.imavis.2018.08.001
   Jiang M, 2020, NEUROCOMPUTING, V381, P314, DOI 10.1016/j.neucom.2019.11.088
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Ke QH, 2018, IEEE ACCESS, V6, P48147, DOI 10.1109/ACCESS.2018.2867898
   Khatun A, 2023, PATTERN RECOGN, V137, DOI 10.1016/j.patcog.2022.109246
   Koo JH, 2018, SENSORS-BASEL, V18
   Ksibi S, 2019, MULTIMED TOOLS APPL, V78, P1583, DOI 10.1007/s11042-018-6200-5
   Li R, 2019, COMPUT ELECTR ENG, V79, DOI 10.1016/j.compeleceng.2019.106455
   Li SZ, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107016
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Y, 2022, J VIS COMMUN IMAGE R, V89
   Li Y, 2023, ACM T SENSOR NETWORK
   Li Y, 2021, KNOWL-BASED SYST, V228
   Li Y, 2020, KNOWLED BASED SYST, V187
   Li YT, 2023, IEEE T MOBILE COMPUT, V22, P5690, DOI 10.1109/TMC.2022.3186614
   Li YT, 2022, IEEE INTERNET THINGS, V9, P5447, DOI 10.1109/JIOT.2021.3108822
   Li YT, 2022, ACM T SENSOR NETWORK, V18, DOI 10.1145/3485060
   Li YS, 2022, SIGNAL PROCESS-IMAGE, V109, DOI 10.1016/j.image.2022.116868
   Lin L, 2017, IEEE T PATTERN ANAL, V39, P1089, DOI 10.1109/TPAMI.2016.2567386
   Ling HF, 2019, NEUROCOMPUTING, V347, P109, DOI 10.1016/j.neucom.2019.01.027
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu J, 2019, ACM T MULTIM COMPUT, V15
   Liu JA, 2023, COMPUT VIS IMAGE UND, V232, DOI 10.1016/j.cviu.2023.103708
   Liu Q, 2023, PATTERN RECOGN, V141
   Liu YX, 2021, NEUROCOMPUTING, V435, P1, DOI 10.1016/j.neucom.2021.01.010
   Liu YG, 2019, J VIS COMMUN IMAGE R, V58, P46, DOI 10.1016/j.jvcir.2018.11.023
   Liu ZS, 2023, NEURAL NETWORKS, V161, P105, DOI 10.1016/j.neunet.2023.01.033
   Loy CC, 2010, INT J COMPUT VISION, V90, P106, DOI 10.1007/s11263-010-0347-5
   Lu YH, 2023, IMAGE VISION COMPUT, V131, DOI 10.1016/j.imavis.2023.104633
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   McLaughlin N, 2019, IEEE T CIRC SYST VID, V29, P2613, DOI 10.1109/TCSVT.2017.2736599
   Meng JK, 2019, PATTERN RECOGN, V93, P430, DOI 10.1016/j.patcog.2019.04.008
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Pala F, 2016, IEEE T CIRC SYST VID, V26, P788, DOI 10.1109/TCSVT.2015.2424056
   Pan HH, 2023, NEURAL NETWORKS, V160, P22, DOI 10.1016/j.neunet.2022.12.015
   Perwiaz N, 2018, IEEE ACCESS, V6, P77334, DOI 10.1109/ACCESS.2018.2882254
   Qi MB, 2019, MULTIMED TOOLS APPL, V78, P27029, DOI 10.1007/s11042-017-4649-2
   Qian XL, 2020, IEEE T PATTERN ANAL, V42, P371, DOI 10.1109/TPAMI.2019.2928294
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Ren C-X, 2019, PATTERN RECOGNIT, V96
   Ren LL, 2019, IEEE T IMAGE PROCESS, V28, P4970, DOI 10.1109/TIP.2019.2915655
   Ren LL, 2017, PATTERN RECOGN, V72, P446, DOI 10.1016/j.patcog.2017.06.037
   Shen C, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3309881
   Si TZ, 2019, AD HOC NETW, V95, DOI 10.1016/j.adhoc.2019.101984
   Sikdar A, 2020, PATTERN RECOGN LETT, V129, P279, DOI 10.1016/j.patrec.2019.11.032
   Song WF, 2020, IEEE T IMAGE PROCESS, V29, P2860, DOI 10.1109/TIP.2019.2953587
   Song XL, 2022, KNOWL-BASED SYST, V256, DOI 10.1016/j.knosys.2022.109851
   Su C, 2018, PATTERN RECOGN, V75, P77, DOI 10.1016/j.patcog.2017.07.005
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Sun R, 2018, SENS, V18
   Sun R, 2020, IEEE ACCESS, V8, P3677, DOI 10.1109/ACCESS.2019.2962301
   Tang YZ, 2020, NEURAL NETWORKS, V124, P223, DOI 10.1016/j.neunet.2020.01.012
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Tian H, 2019, NEUROCOMPUTING, V359, P93, DOI 10.1016/j.neucom.2019.05.037
   Tian YM, 2019, MULTIMED TOOLS APPL, V78, P24187, DOI 10.1007/s11042-018-6998-x
   Vishwakarma DK, 2018, IEEE T MULTI-SCALE C, V4, P513, DOI 10.1109/TMSCS.2018.2870592
   Wan CQ, 2020, IEEE T MULTIMEDIA, V22, P1605, DOI 10.1109/TMM.2019.2946486
   Wang C, 2020, NEUROCOMPUTING, V382, P64, DOI 10.1016/j.neucom.2019.11.062
   Wang DW, 2023, J VIS COMMUN IMAGE R, V93, DOI 10.1016/j.jvcir.2023.103822
   Wang FY, 2020, PATTERN RECOGN LETT, V130, P293, DOI 10.1016/j.patrec.2018.11.016
   Wang GC, 2018, IEEE T CIRC SYST VID, V28, P2777, DOI 10.1109/TCSVT.2017.2748698
   Wang H, 2020, IEEE ACCESS, V8, P5339, DOI 10.1109/ACCESS.2019.2962581
   Wang JC, 2021, INFORM SCIENCES, V562, P370, DOI 10.1016/j.ins.2021.03.028
   Wang KJ, 2018, CAAI T INTELL TECHNO, V3, P219, DOI 10.1049/trit.2018.1001
   Wang M, 2023, ENG APPL ARTIF INTEL, V123B
   Wang P, 2020, IEEE T MULTIM
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang WH, 2023, INFORM SCIENCES, V637
   Wang Y, 2019, INT J INF COMMUN TEC, V15
   Wang Z, 2022, ENG APPL ARTIF INTEL, V116
   Wang Z, 2020, IEEE T IMAGE PROCESS, V29, P2013, DOI 10.1109/TIP.2019.2946975
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu D, 2019, IEEE ACCESS, V7, P28402, DOI 10.1109/ACCESS.2019.2901764
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Wu D, 2019, COGN SYST RES, V54, P74, DOI 10.1016/j.cogsys.2018.04.003
   Wu D, 2019, NEUROCOMPUTING, V324, P69, DOI 10.1016/j.neucom.2018.03.073
   Wu HY, 2019, IEEE ACCESS, V7, P91052, DOI 10.1109/ACCESS.2019.2927052
   Wu L, 2020, IEEE T CIRC SYST VID, V30, P2081, DOI 10.1109/TCSVT.2019.2909549
   Wu L, 2019, IEEE T NEUR NET LEAR, V30, P3347, DOI 10.1109/TNNLS.2019.2891244
   Wu L, 2020, IEEE T IMAGE PROCESS, V29, P1233, DOI 10.1109/TIP.2019.2940684
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xiang XZ, 2019, IEEE SENS J, V19, P11706, DOI 10.1109/JSEN.2019.2936916
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Xiong MF, 2019, J PARALLEL DISTR COM, V132, P230, DOI 10.1016/j.jpdc.2017.11.009
   Xu B, 2019, IEEE ACCESS, V7
   Xu BL, 2023, IMAGE VISION COMPUT, V132, DOI 10.1016/j.imavis.2023.104648
   Yan YC, 2019, PATTERN RECOGN LETT, V127, P156, DOI 10.1016/j.patrec.2018.08.024
   Yang F, 2019, PATTERN RECOGN, V86, P143, DOI 10.1016/j.patcog.2018.08.015
   Yang WX, 2019, NEUROCOMPUTING, V340, P125, DOI 10.1016/j.neucom.2019.02.042
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Yu T, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243217
   Yuan CH, 2019, MULTIMED TOOLS APPL, V78, P21145, DOI 10.1007/s11042-019-7446-2
   Yuan CH, 2019, NEUROCOMPUTING, V330, P127, DOI 10.1016/j.neucom.2018.11.010
   Zhang GQ, 2023, INFORM SCIENCES, V633, P70, DOI 10.1016/j.ins.2023.02.016
   Zhang JH, 2019, IEEE ACCESS, V7, P133686, DOI 10.1109/ACCESS.2019.2913559
   Zhang LX, 2021, NEUROCOMPUTING, V458, P690, DOI 10.1016/j.neucom.2019.12.142
   Zhang RJ, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109070
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhang W, 2020, IEEE T IMAGE PROCESS, V29, P3365, DOI 10.1109/TIP.2019.2959653
   Zhang Y, 2019, IEEE ACCESS, V7, P53585, DOI 10.1109/ACCESS.2019.2912844
   Zhang YS, 2019, IEICE T INF SYST, VE102D, P2230, DOI 10.1587/transinf.2019EDP7067
   Zhang ZZ, 2020, IEEE T IMAGE PROCESS, V29, P7104, DOI 10.1109/TIP.2020.2998931
   Zhang Z, 2020, IEEE TETCI, V4, P51, DOI 10.1109/TETCI.2018.2883348
   Zhang Z, 2020, AD HOC NETW, V97, DOI 10.1016/j.adhoc.2019.102019
   Zhang Z, 2018, EURASIP J WIREL COMM, DOI 10.1186/s13638-018-1060-2
   Zhao CR, 2019, PATTERN RECOGN LETT, V117, P161, DOI 10.1016/j.patrec.2018.04.029
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhong WL, 2019, J VIS COMMUN IMAGE R, V62, P267, DOI 10.1016/j.jvcir.2019.06.001
   Zhong WL, 2019, NEUROCOMPUTING, V334, P68, DOI 10.1016/j.neucom.2019.01.005
   Zhou SP, 2019, IEEE T IMAGE PROCESS, V28, P4671, DOI 10.1109/TIP.2019.2908065
   Zhou SP, 2018, PATTERN RECOGN, V76, P739, DOI 10.1016/j.patcog.2017.10.005
   Zhou SR, 2019, J VIS COMMUN IMAGE R, V59, P393, DOI 10.1016/j.jvcir.2019.01.029
   Zhu F, 2018, MULTIMED TOOLS APPL, V77
   Zhu FQ, 2017, IEEE T IMAGE PROCESS, V26, P4806, DOI 10.1109/TIP.2017.2695101
   Zhu JQ, 2018, IEEE T CIRC SYST VID, V28, P3183, DOI 10.1109/TCSVT.2017.2734740
   Zou GF, 2021, MULTIMED TOOLS APPL, V80, P26855, DOI 10.1007/s11042-021-10953-6
NR 175
TC 1
Z9 1
U1 11
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 10
PY 2023
DI 10.1007/s11042-023-16286-w
EA AUG 2023
PG 50
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O8QT2
UT WOS:001046412000001
DA 2024-07-18
ER

PT J
AU Mohammed, SJ
   Taha, DB
AF Mohammed, Saja J.
   Taha, Dujan B.
TI Paillier cryptosystem enhancement for Homomorphic Encryption technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cryptography; Homomorphic Encryption; Partial Homomorphic Encryption;
   Paillier cryptosystem; Chinese Reminder Theorem
AB Homomorphic Encryption (HE) is one of the most popular technologies which assists for keeping the confidentiality and privacy of user data on cloud storage. It can apply a mathematical computation to the ciphertext and return the result as if the operation was performed on the corresponding plaintext. Many of algorithms are known as a class of this interested technology, one of them is Paillier cryptosystem. This paper offers two solutions (MPEA-A and MPEA-B) for Paillier's cryptosystem bottleneck problem which causes delay in Paillier decrypting procedures. MPEA-A and MPEA-B algorithms are based on the Chinese Reminder Theorem CRT with appended principles to achieve the desired goal. Practical implementations are applied to the proposed algorithms, The results show that the two algorithms succeeded in reducing the decryption time with various ratios. The practical implementation proved that MPEA-A can be useful for encrypting with a medium Paillier key size, whereas MPEA-B is preferred for encrypting in a large key size value.
C1 [Mohammed, Saja J.] Univ Mosul, Coll Comp Sci & Math, Dept Comp Sci, Mosul, Iraq.
   [Taha, Dujan B.] Univ Mosul, Coll Comp Sci & Math, Dept Software, Mosul, Iraq.
C3 University of Mosul; University of Mosul
RP Mohammed, SJ (corresponding author), Univ Mosul, Coll Comp Sci & Math, Dept Comp Sci, Mosul, Iraq.
EM sj_alkado@uomosul.edu.iq
RI Taha, Prof. Dr.Dujan Basheer/KHD-9256-2024; Mohammed, Saja
   J./ADO-5964-2022
OI Mohammed, Saja J./0000-0002-3857-8057
CR Alaya B, 2020, COMPUT SCI REV, V36, DOI 10.1016/j.cosrev.2020.100235
   Aldossary S, 2016, INT J ADV COMPUT SC, V7, P485
   Bambrik Ilyas, 2020, SN Computer Science, V1, P249
   Chol KG, 2018, CRYPTOLOGY EPRINT AR, P1
   Ding C., 1996, Chinese Remainder Theorem: Applications in Computing, Coding, Cryptography, V2nd ed.
   El Makkaoui K, 2020, J AMB INTEL HUM COMP, V11, P2205, DOI 10.1007/s12652-019-01366-3
   Gill SH, 2022, INTELL AUTOM SOFT CO, V31, P117, DOI 10.32604/iasc.2022.016597
   HELLMAN ME, 1979, SCI AM, V241, P146, DOI 10.1038/scientificamerican0879-146
   Jia XX, 2019, INFORM SCIENCES, V473, P13, DOI 10.1016/j.ins.2018.09.024
   Kaaniche N, 2015, THESIS ET MARIE CURI
   KU YH, 1992, J FRANKLIN I, V329, P93, DOI 10.1016/0016-0032(92)90099-3
   Mohammed SJ, 2022, PROCEEDING OF THE 2ND 2022 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND SOFTWARE ENGINEERING (CSASE 2022), P89, DOI 10.1109/CSASE51777.2022.9759825
   Mohammed SJ., 2021, J PHYS C SER, DOI [10.1088/1742-6596/1963/1/012154, DOI 10.1088/1742-6596/1963/1/012154]
   Mohammed SJ., 2021, TELKOMNIKA TELECOMMU, V19, P1152, DOI [10.12928/telkomnika.v19i4.16875, DOI 10.12928/TELKOMNIKA.V19I4.16875]
   Ogunseyi Taiwo Blessing, 2020, 2020 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS), P803, DOI 10.1109/ICPICS50287.2020.9202325
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Stalling W., 2017, CRYPTOGRAPHY NETWORK
   Wang X, 2016, MATH FDN PUBLIC KEY
   Yi X., 2014, Homomorphic Encryption and Applications, P27, DOI [DOI 10.1007/978-3-319-12229-8_2, 10.1007/978-3-319-12229-8, DOI 10.1007/978-3-319-12229-8]
NR 19
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 7
PY 2023
DI 10.1007/s11042-023-16301-0
EA AUG 2023
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O4RY6
UT WOS:001043714700012
DA 2024-07-18
ER

PT J
AU Chen, L
   Cao, TY
   Zheng, YF
   Fang, Z
   Wang, Y
   Fu, BY
   Wang, YK
   Han, T
AF Chen, Lei
   Cao, Tieyong
   Zheng, Yunfei
   Fang, Zheng
   Wang, Yang
   Fu, Bingyang
   Wang, Yekui
   Han, Tong
TI Focusing intermediate pixels loss for salient object segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salient object segmentation; Loss function; Deep learning; Intermediate
   pixels
AB To improve the network performance of salient object segmentation, many researchers modified the loss functions and set weights to pixel losses. However, these loss functions paid less attention to intermediate pixels of which the predicted probabilities lie in the intermediate region between correct and incorrect classification. To solve this problem, focusing intermediate pixels loss is proposed. Firstly, foreground and background are divided into correct and incorrect classified sets respectively to discover intermediate pixels which are difficult to determine the category. Secondly, the intermediate pixels are paid more attention according to the predicted probability. Finally, misclassified pixels are strengthened dynamically with the order of training epochs. The proposed method can 1) make the model focus on intermediate pixels that have more uncertainty; 2) solve the vanishing gradient problem of Focal Loss for well-classified pixels. Experiment results on six public datasets and two different type of network structures show that the proposed method performs better than other state-of-the-art weighted loss functions and the average F-& beta; is increased by about 2.7% compared with typical cross entropy.
C1 [Chen, Lei; Cao, Tieyong; Zheng, Yunfei; Fang, Zheng; Wang, Yang; Fu, Bingyang; Wang, Yekui; Han, Tong] Army Engn Univ PLA, Nanjing 210007, Jiangsu, Peoples R China.
   [Zheng, Yunfei] PLA Army Acad Artillery & Air Def, Hefei 230031, Anhui, Peoples R China.
   [Zheng, Yunfei] Key Lab Polarizat Imaging Detect Technol, Hefei 230031, Anhui, Peoples R China.
C3 Army Engineering University of PLA
RP Cao, TY (corresponding author), Army Engn Univ PLA, Nanjing 210007, Jiangsu, Peoples R China.
EM cty_ice@sina.com
OI Chen, Lei/0000-0002-7843-8737
FU Natural Science Foundation of China [61801512, 62071484]; Natural
   Science Foundation of Jiangsu Province [BK20180080]
FX This work was supported by the Natural Science Foundation of China
   (61801512, 62071484), Natural Science Foundation of Jiangsu Province
   (BK20180080).
CR Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen ZX, 2021, IEEE T IMAGE PROCESS, V30, P431, DOI 10.1109/TIP.2020.3037536
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Feng L, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2206
   Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hossain MS, 2021, NEUROCOMPUTING, V462, P69, DOI 10.1016/j.neucom.2021.07.055
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Ji YZ, 2021, INFORM SCIENCES, V546, P835, DOI 10.1016/j.ins.2020.09.003
   Kim T, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2167, DOI 10.1145/3474085.3475375
   Kingma D. P., 2014, arXiv
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li XX, 2019, IEEE T VEH TECHNOL, V68, P4204, DOI 10.1109/TVT.2019.2895651
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2020, MULTIMED TOOLS APPL, V79, P25403, DOI 10.1007/s11042-020-09188-8
   Mao Y., 2021, ARXIV
   Mavroforakis ME, 2006, IEEE T NEURAL NETWOR, V17, P671, DOI 10.1109/TNN.2006.873281
   Pan C, 2020, MULTIMED TOOLS APPL, V79, P19925, DOI 10.1007/s11042-020-08866-x
   Pang YW, 2022, PROC CVPR IEEE, P2150, DOI 10.1109/CVPR52688.2022.00220
   Rahman Md Atiqur, 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P234, DOI 10.1007/978-3-319-50835-1_22
   Singh VK, 2020, MULTIMED TOOLS APPL, V79, P30045, DOI 10.1007/s11042-020-09467-4
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang Q, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107340
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang P., 2018, arXiv
   Zhao S., 2019, arXiv
NR 34
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19747
EP 19766
DI 10.1007/s11042-023-15873-1
EA JUL 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800012
DA 2024-07-18
ER

PT J
AU Ben Jabra, S
   Zagrouba, E
   Ben Farah, M
AF Ben Jabra, Saoussen
   Zagrouba, Ezzeddine
   Ben Farah, Mohamed
TI A new efficient anaglyph 3D image and video watermarking technique
   minimizing generation deficiencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D anaglyph watermarking; Color distortions; Signature robustness;
   Ghosting effect; Collusion attack; Retinal rivalry
ID ROBUST; STEREO
AB 3D Anaglyph system is among the most popular 3D displaying techniques thanks to its simplicity and the cheap glasses that it uses. Anaglyph generation and watermarking are two essential techniques that attracted researchers in 3D anaglyph domain where several techniques have been proposed. However, most of the previous anaglyph watermarking studies focused on the robustness and the visual difference between original and marked content and they have not considered the three deficiencies caused by the generation step, which are the distortion of colors, the retinal rivalry and the ghosting effect. In this paper, we propose the first watermarking technique that protect 3D anaglyph content before its transmission by embedding the signature simultaneously with generation step. In this technique, three signatures were embedded before, during and after the generation process using different domains to obtain robustness to several manipulations, especially against malicious attacks. Moreover, the chosen generation process avoids generation deficiencies and allows obtaining high visual quality of the marked content. The experimental results illustrate robustness against attacks such as compression and collusion where the minimum value of NC is close to 0.7 and the maximum value of BER is close to 0.2. Besides, the suggested technique provides high invisibility where PSNR and SSIM values are respectively close to 58 and 0.9, and it minimizes the generation deficiencies.
C1 [Ben Jabra, Saoussen] Univ Sousse, Natl Engn Sch Sousse, LimT Lab, Sousse, Tunisia.
   [Zagrouba, Ezzeddine] Univ Tunis El Manar, Higher Inst Comp Sci, LimT Lab, Ariana, Tunisia.
   [Ben Farah, Mohamed] Birmingham City Univ, Dept Networks & Cyber Secur, Birmingham B4 7XG, England.
C3 Universite de Sousse; Universite de Tunis-El-Manar; Birmingham City
   University
RP Ben Farah, M (corresponding author), Birmingham City Univ, Dept Networks & Cyber Secur, Birmingham B4 7XG, England.
EM saoussen.bj@gmail.com; mohamed.benfarah@bcu.ac.uk
RI Zagrouba, Ezzeddine/D-7896-2014
OI Zagrouba, Ezzeddine/0000-0002-2574-9080
CR [Anonymous], ANAGLYPH VIDEO DATAS
   Bayoudh I, 2018, MULTIMED TOOLS APPL, V77, P14361, DOI 10.1007/s11042-017-5033-y
   Ben Jabra S, 2022, VISUAL COMPUT, V38, P3611, DOI 10.1007/s00371-021-02191-6
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   Devi HS, 2017, ARAB J SCI ENG, V42, P3521, DOI 10.1007/s13369-017-2531-1
   Devi HS, 2016, CONT ENG SCI, V9, P1575, DOI [10.12988/ces.2016.69156, DOI 10.12988/CES.2016.69156]
   Dhaou D, 2020, E BUSINESS TELECOMMU, P157, DOI [10.1007/978-3-030-52686-3_7, DOI 10.1007/978-3-030-52686-3_7]
   Dhaou D, 2019, PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON E-BUSINESS AND TELECOMMUNICATIONS, VOL 2: SECRYPT, P260, DOI 10.5220/0007930102600267
   Dhaou D, 2019, LECT NOTES COMPUT SC, V11679, P96, DOI 10.1007/978-3-030-29891-3_9
   Dhaou D, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0231-1
   Dhaou D, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P501, DOI 10.5220/0006619305010510
   Dhaou D, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0223-1
   Dubois E, 2001, INT CONF ACOUST SPEE, P1661, DOI 10.1109/ICASSP.2001.941256
   El-Shahed RA, 2022, B ELECT ENG INF, V11, DOI [10.11591/eei.v11i4.2922, DOI 10.11591/EEI.V11I4.2922]
   Evsutin O, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116523
   Fan B, 2022, MULTIMEDIA SYST, V28, P295, DOI 10.1007/s00530-021-00835-0
   Ideses L, 2005, J OPT A-PURE APPL OP, V7, P755, DOI 10.1088/1464-4258/7/12/008
   Jain K, 2015, J INF SEC RES, V6
   Kaczynski M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22145376
   Kerbiche A, 2018, MULTIMED TOOLS APPL, V77, P26769, DOI 10.1007/s11042-018-5888-6
   Koley S, 2022, MULTIMED TOOLS APPL, V81, P19491, DOI 10.1007/s11042-021-11861-5
   Kunze LF, 2020, SIGNAL PROCESS-IMAGE, V85, DOI 10.1016/j.image.2020.115866
   Li SN, 2013, SIGNAL PROCESS-IMAGE, V28, P597, DOI 10.1016/j.image.2013.03.004
   Luo ZH, 2013, 2013 INTERNATIONAL CONFERENCE ON VIRTUAL REALITY AND VISUALIZATION (ICVRV 2013), P305, DOI 10.1109/ICVRV.2013.59
   Manaf AA., 2016, INT J APPL ENG RES, V11, P3484
   Matsuura F, 2008, J VISUAL-JAPAN, V11, P79, DOI 10.1007/BF03181917
   McAllister DF, 2010, PROC SPIE, V7524, DOI 10.1117/12.837163
   Munoz-Ramirez DO, 2015, P EUR WORKSH URB DAT, P1, DOI [10.1109/ICEEE.2015.7357955, DOI 10.2312/UDMV.20151341]
   Patel R., 2015, INT J ENG TECH RES I, V3, P55
   Prathap I, 2014, COMPUT ELECTR ENG, V40, P51, DOI 10.1016/j.compeleceng.2013.11.005
   Diaz ER, 2010, REV FAC ING-UNIV ANT, P111
   Salih JW, 2015, INT J ADV SCI TECHNO, V82, P11, DOI [10.14257/ijast.2015.82.02, DOI 10.14257/ijast.2015.82.02]
   Sanftmann H, 2011, COMPUT GRAPH FORUM, V30, P1251, DOI 10.1111/j.1467-8659.2011.01984.x
   Sanjay RZ., 2015, INT J EMERGING TREND, V2, P210
   Waleed Jumana, 2013, International Journal of Advancements in Computing Technology, V5, P163
   Wang C., 2015, INT J IMAGE PROCESS, V9, P156
   YR, 2016, INT J COMPUTER TREND, V41, P77, DOI 10.14445/22312803/IJCTT-V41P113
   Zadokar SR, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P483, DOI 10.1109/ICACCI.2013.6637219
   Zingarelli MRU, 2011, P 17 BRAZILIAN S MUL, V1, P205
NR 39
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19433
EP 19463
DI 10.1007/s11042-023-16272-2
EA JUL 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900006
DA 2024-07-18
ER

PT J
AU Mahmood, Z
   Khan, K
   Shahzad, M
   Fayyaz, A
   Khan, U
AF Mahmood, Zahid
   Khan, Khurram
   Shahzad, Mohsin
   Fayyaz, Ahmad
   Khan, Uzair
TI Enhanced detection and recognition system for vehicles and drivers using
   multi-scale retinex guided filter and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Face recognition; Image enhancement; Machine learning
ID FACE; COLOR; RESOLUTION; TRACKING; ROBUST; POSE
AB Accurate vehicle detection plays a vital role in intelligent transportation systems. Various day conditions, for instance, dawn, morning, noon, or non-uniform illuminations put restrictions on camera's visibility. Such scenarios impact the performance of detection and recognition algorithms that are used in surveillance systems and autonomous driving. This paper aims to solve the aforementioned issues using machine learning methods, such as face detection and recognition. The core theme of this paper is the development of a vehicle detection and driver recognition system, which also focuses the situation where an input image is degraded by non-uniform illuminations. The proposed system is composed of four main processing modules: (i) image acquisition, (ii) image enhancement, (iii) object detection that locates vehicles' and drivers' faces, and (iv) the Pool of Face Recognition Algorithms (PoFRA), which uses four face recognition algorithms to conclude the driver's identity. We implement suitable algorithms for each of the above-described modules to appraise its practicability. The system can be adjusted to work in different types of extreme weather conditions, such as strong or dim light. Experimental results demonstrate that the proposed system has significant potential to take the research on automated car parking systems to the next level.
C1 [Mahmood, Zahid; Shahzad, Mohsin; Fayyaz, Ahmad; Khan, Uzair] COMSATS Univ Islamabad, Dept Elect & Comp Engn, Abbottabad Campus, Abbottabad, Khyber Pakhtunk, Pakistan.
   [Khan, Khurram] Air Univ Islamabad, Dept Avion Engn, Islamabad, Pakistan.
   [Khan, Khurram] GIK Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi, Kpk, Pakistan.
C3 COMSATS University Islamabad (CUI); Quaid I Azam University; Air
   University Islamabad; GIK Institute Engineering Science & Technology
RP Mahmood, Z (corresponding author), COMSATS Univ Islamabad, Dept Elect & Comp Engn, Abbottabad Campus, Abbottabad, Khyber Pakhtunk, Pakistan.; Khan, K (corresponding author), Air Univ Islamabad, Dept Avion Engn, Islamabad, Pakistan.; Khan, K (corresponding author), GIK Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi, Kpk, Pakistan.
EM zahid0987@cuiatd.edu.pk; khurram.jadoon@giki.edu.pk;
   mohsinshahzad@cuiatd.edu.pk; afayyaz@cuiatd.edu.pk;
   uzairkhan@cuiatd.edu.pk
RI Shahzad, Mohsin/AEM-5472-2022
OI Shahzad, Mohsin/0000-0002-5251-4172; Mahmood, Zahid/0000-0003-4121-3558
CR Afifi M, 2021, PROC CVPR IEEE, P9153, DOI 10.1109/CVPR46437.2021.00904
   Afifi M, 2019, IEEE I CONF COMP VIS, P243, DOI 10.1109/ICCV.2019.00033
   Aghdam AH, 2018, IET INTELL TRANSP SY, V12, P793, DOI 10.1049/iet-its.2017.0085
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ameen M., 2017, INT J ELECT ELECT EN, V5, P94, DOI [10.18178/ijeee.5.1.94-98, DOI 10.18178/IJEEE.5.1.94-98]
   Asadianfam S, 2021, MULTIMED TOOLS APPL, V80, P2489, DOI 10.1007/s11042-020-09714-8
   Badii C, 2018, IEEE ACCESS, V6, P44059, DOI 10.1109/ACCESS.2018.2864157
   Breve B, 2022, MULTIMED TOOLS APPL, V81, P73, DOI 10.1007/s11042-021-11077-7
   Burgstahler D, 2014, 2014 IEEE 39TH CONFERENCE ON LOCAL COMPUTER NETWORKS WORKSHOPS (LCN WORKSHOPS), P514, DOI 10.1109/LCNW.2014.6927697
   Calabuig D, 2018, IEEE T INTELL TRANSP, V19, P1152, DOI 10.1109/TITS.2017.2718103
   Caruccio L, 2021, SEBD, P5
   Chen G, 2021, IEEE T INTELL TRANSP, V22, P7699, DOI 10.1109/TITS.2020.3007631
   Chu WQ, 2018, IEEE T IMAGE PROCESS, V27, P432, DOI 10.1109/TIP.2017.2762591
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Drakoulis R, 2018, IEEE T INTELL TRANSP, V19, P921, DOI 10.1109/TITS.2018.2791643
   Farid A., 2023, APPL SCI, V30, P1
   Ghimire D, 2011, IEEE T CONSUM ELECTR, V57, P858, DOI 10.1109/TCE.2011.5955233
   Giovanna C, 2016, IET INTELL TRANSP SY, V10, P279, DOI 10.1049/iet-its.2015.0127
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Han W, 2018, PROC CVPR IEEE, P1654, DOI 10.1109/CVPR.2018.00178
   Hao ZQ, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND COMPUTER SCIENCE, VOL 1, PROCEEDINGS, P476, DOI 10.1109/ITCS.2009.104
   Hassaballah M, 2021, IEEE T INTELL TRANSP, V22, P4230, DOI 10.1109/TITS.2020.3014013
   Hussain KF, 2019, IEEE T INTELL TRANSP, V20, P1181, DOI 10.1109/TITS.2018.2838117
   Kafai M, 2012, IEEE T IND INFORM, V8, P100, DOI 10.1109/TII.2011.2173203
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Lei A, 2017, IEEE INTERNET THINGS, V4, P1832, DOI 10.1109/JIOT.2017.2740569
   Leitloff J, 2014, REMOTE SENS-BASEL, V6, P11315, DOI 10.3390/rs61111315
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu LT, 2021, INT J CIRC THEOR APP, V49, P1028, DOI 10.1002/cta.2935
   Lu JW, 2006, IEEE T NEURAL NETWOR, V17, P166, DOI 10.1109/TNN.2005.860853
   Lv TF, 2022, APPL OPTICS, V61, P2219, DOI 10.1364/AO.449589
   Maeda S, 2020, PROC CVPR IEEE, P288, DOI 10.1109/CVPR42600.2020.00037
   Mahmood Z., 2018, ELSEVIER INFORM MED, V13, P9, DOI [10.1016/j.imu.2018.09.001, DOI 10.1016/J.IMU.2018.09.001]
   Mahmood Z, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22031245
   Mahmood Z, 2019, MULTIDIM SYST SIGN P, V30, P1991, DOI 10.1007/s11045-019-00639-6
   Mahmood Z, 2019, IET INTELL TRANSP SY, V13, P293, DOI 10.1049/iet-its.2018.5021
   Mahmood Z, 2017, KSII T INTERNET INF, V11, P6069, DOI 10.3837/tiis.2017.12.021
   Mahmood Z, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17500256
   Mahmood Z, 2016, IET BIOMETRICS, V5, P111, DOI 10.1049/iet-bmt.2015.0008
   Mahmood Z, 2015, PATTERN ANAL APPL, V18, P971, DOI 10.1007/s10044-014-0416-4
   Mahmood Z, 2015, IEEE I C EMBED SOFTW, P892, DOI 10.1109/HPCC-CSS-ICESS.2015.18
   Mahmood Z, 2014, INT CONF FRONT INFO, P263, DOI 10.1109/FIT.2014.56
   Masood S, 2020, 14 TH INT C OPEN SOU, P1
   Meng J, 2022, APPL OPTICS, V61, P1323, DOI 10.1364/AO.446207
   Min K, 2021, IEEE SYS MAN CYBERN, P2724, DOI 10.1109/SMC52423.2021.9659243
   Moranduzzo T, 2014, IEEE T GEOSCI REMOTE, V52, P1635, DOI 10.1109/TGRS.2013.2253108
   Naufal JK, 2018, IEEE T INTELL TRANSP, V19, P1925, DOI 10.1109/TITS.2017.2745678
   Reilly V, 2010, LECT NOTES COMPUT SC, V6313, P186
   Rushton C, 2018, IET INTELL TRANSP SY, V12, P1181, DOI 10.1049/iet-its.2018.5217
   Sadia H, 2018, INT CONF FRONT INFO, P82, DOI 10.1109/FIT.2018.00022
   Silla A, 2017, IET INTELL TRANSP SY, V11, P164, DOI 10.1049/iet-its.2016.0024
   Sultan F, 2023, APPL SCI-BASEL, V13, DOI 10.3390/app13063956
   Sun B, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P358, DOI 10.1109/CISP.2008.175
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Tuermer S, IEEE J SEL TOPICS AP, V6, P2327
   Ul Haq M, 2019, KSII T INTERNET INF, V13, P3144, DOI 10.3837/tiis.2019.06.021
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Q., 2020, P IEEE CVF C COMP VI, P8326, DOI [DOI 10.1109/CVPR42600.2020.00835, 10.1109/CVPR42600.2020.00835]
   Wang QC, 2021, IEEE T INF FOREN SEC, V16, P4534, DOI 10.1109/TIFS.2021.3109463
   Wang QC, 2020, IEEE T INF FOREN SEC, V15, P1640, DOI 10.1109/TIFS.2019.2946938
   Wang WS, 2017, IEEE T INTELL TRANSP, V18, P1440, DOI 10.1109/TITS.2016.2606347
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wen X., 2006, P 9 INT C CONTR AUT, P2421
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yuanming Hu, 2018, ACM Transactions on Graphics, V37, DOI 10.1145/3181974
   Zaki P, 2020, ARXIV
   Zhan XY, 2016, IEEE T INTELL TRANSP, V17, P2479, DOI 10.1109/TITS.2016.2521862
   Zhang JD, 2021, MULTIMED TOOLS APPL, V80, P18181, DOI 10.1007/s11042-020-10370-1
   Zhang ZF, 2019, PROC CVPR IEEE, P7974, DOI 10.1109/CVPR.2019.00817
   Zhang ZX, 2021, IEEE INT CONF COMP V, P2799, DOI 10.1109/ICCVW54120.2021.00314
   Zhao JY, 2022, IEEE ACCESS, V10, P8590, DOI 10.1109/ACCESS.2022.3143365
NR 73
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 15785
EP 15824
DI 10.1007/s11042-023-16140-z
EA JUL 2023
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700006
DA 2024-07-18
ER

PT J
AU Tabarej, MS
   Minz, S
AF Tabarej, Mohd Shamsh
   Minz, Sonajharia
TI Rough-graph-based hotspot detection of polygon vector data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rough-set; Rough graph; Hotspot detection; Socio economic data; Global
   autocorrelation
ID PATTERNS
AB Spatial polygon data represents the area of some events such as disease cases, crime, health care facilities, earthquakes, and fires. Finding the hotspot is crucial in exploratory data analysis. Although finding the spatially significant cluster is still challenging work. On this account, in this paper, we proposed a novel method based on the rough graph that finds the statistically significant hotspot. First, Global Moan's I index is calculated to find the presence of a hotspot in the data set. A positive value of Global Moran's I index shows the presence of a hotspot in the dataset. Then, the RGBHSD algorithm is used, which constructs a rough graph by considering each polygon as the node, and there is an edge between the two nodes if two polygons are neighbours of each other. Then boundary value analysis is done on the lower region of the rough graph, which considers some more boundary value polygon to be changed as the lower region. The polygons belonging to the lower region are considered the candidate hotspot. After detecting the candidate hotspot, a statistical significance test is done to find the significant hotspot. Finally, the RGBHSD algorithm is evaluated based on the evaluation metrics. We tested the algorithm on the socio-economic dataset of UP, India and Brexit dataset of UK. In the socioeconomic dataset the health facility provided in the villages is used to find the hotspot. In the Brexit dataset field related to the percent of the vote for the UK to be in the European union or not is taken. After the analysis, it is found that the hotspots generated are denser, and the time taken by the algorithm is less and the HPAI value is high than other literature methods. The result shows that the hotspots are scattered over the study region but clustered in some areas like west UP, east UP, etc. The hotspot offers health facilities in these virtuous areas and for Brexit data hotspot is clustered in the south region. This type of analysis is suitable for dealing with the pandemic, and to understand the pattern of any disaster drought, flood etc.
C1 [Tabarej, Mohd Shamsh; Minz, Sonajharia] Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
C3 Jawaharlal Nehru University, New Delhi
RP Tabarej, MS (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Sci, New Delhi 110067, India.
EM shamsh72_scs@jnu.ac.in; sonaminz@mail.jnu.ac.in
RI TABAREJ, MOHD/AGH-2882-2022
OI TABAREJ, MOHD/0000-0001-5230-2703
CR Acharjya DP, 2022, MULTIMED TOOLS APPL, V81, P13489, DOI 10.1007/s11042-021-11495-7
   Acharjya DP, 2022, MULTIMED TOOLS APPL, V81, P35117, DOI 10.1007/s11042-021-10518-7
   Anderson TK, 2009, ACCIDENT ANAL PREV, V41, P359, DOI 10.1016/j.aap.2008.12.014
   [Anonymous], 2018, NASA SOC DAT APPL CT, V1, P1
   Anselin L, 2006, GEOGR ANAL, V38, P5, DOI 10.1111/j.0016-7363.2005.00671.x
   ANSELIN L, 1995, GEOGR ANAL, V27, P93, DOI 10.1111/j.1538-4632.1995.tb00338.x
   Aral N, 2022, SUSTAIN CITIES SOC, V76, DOI 10.1016/j.scs.2021.103421
   Bai HX, 2022, INFORM SCIENCES, V586, P525, DOI 10.1016/j.ins.2021.12.019
   Beynon MJ, 2011, ENCY DECISION MAKING, DOI [10.4018/9781599048437.ch088, DOI 10.4018/9781599048437.CH088]
   Block R, 2007, SOC SCI COMPUT REV, V25, P272, DOI 10.1177/0894439307298562
   Bundy A., 1984, Catalogue of Artificial Intelligence Tools, P13, DOI DOI 10.1007/978-3-642-96868-6_25
   Chainey S, 2008, SECUR J, V21, P4, DOI 10.1057/palgrave.sj.8350066
   Chen XJ, 2021, COMPUT ENVIRON URBAN, V89, DOI 10.1016/j.compenvurbsys.2021.101661
   Das P, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105811
   Daszykowski M, 2009, COMPREHENSIVE CHEMOMETRICS: CHEMICAL AND BIOCHEMICAL DATA ANALYSIS, VOLS 1-4, pA635
   Eftelioglu E, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P1447, DOI 10.1109/ICDMW.2015.159
   Geary RC, 1954, INCORPORATED STATIST, V5, P115, DOI [10.2307/2986645, DOI 10.2307/2986645]
   GETIS A, 1992, GEOGR ANAL, V24, P189, DOI 10.1111/j.1538-4632.1992.tb00261.x
   Hart T. C., 2021, Criminal Justice Review, V46, P173, DOI [https://doi.org/10.1177/0734016821996785, DOI 10.1177/0734016821996785]
   Huang ZH, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107736
   Jiang JL, 2022, PHYSICA A, V586, DOI 10.1016/j.physa.2021.126455
   Kulldorff M, 1997, COMMUN STAT-THEOR M, V26, P1481, DOI 10.1080/03610929708831995
   Lessler J, 2017, AM J TROP MED HYG, V96, P1270, DOI 10.4269/ajtmh.16-0427
   Levine N., 2013, CrimeStat IV: A Spatial Statistics Program for the Analysis of Crime Incident Locations
   Li F, 2021, IEEE J-STARS, V14, P3695, DOI 10.1109/JSTARS.2021.3068308
   Li SJ, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.108025
   Lin WM, 2021, IEEE T COMPUT SOC SY, V8, P227, DOI 10.1109/TCSS.2020.2965234
   Mondal S, 2022, GEOJOURNAL, V87, P5287, DOI 10.1007/s10708-022-10573-z
   Nandana GM, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P158, DOI [10.1109/CONFLUENCE.2019.8776916, 10.1109/confluence.2019.8776916]
   NirmalaDevi K., 2015, INT J COMPUT APPL, V117, P37, DOI [10.5120/20593-3087, DOI 10.5120/20593-3087]
   ORD JK, 1995, GEOGR ANAL, V27, P286, DOI 10.1111/j.1538-4632.1995.tb00912.x
   Pawlak Z, 1998, CYBERNET SYST, V29, P661, DOI 10.1080/019697298125470
   Raj A, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106365
   S. G.-T. A. of M. Statistics and undefined, 1965, JSTOR
   Sahu R, 2021, Decision Making: Applications in Management and Engineering, V4, P104, DOI DOI 10.31181/DMAME2104104S
   Scott LM., 2009, HDB APPL SPATIAL ANA, P27, DOI [10.1007/978-3-642-03647-7_2, DOI 10.1007/978-3-642-03647-72, DOI 10.1007/978-3-642-03647-7_2]
   Shekhar S, 2011, WIRES DATA MIN KNOWL, V1, P193, DOI 10.1002/widm.25
   Songchitruksa P, 2010, TRANSPORT RES REC, P42, DOI 10.3141/2165-05
   Tabarej MS, 2019, COMMUN COMPUT PHYS, P655, DOI [10.1007/978-981-13-9942-8, DOI 10.1007/978-981-13-9942-8]
   Tabarej MS, 2020, ADV INTELLIGENT SYST, P325, DOI [10.1007/978-981-15-3383-9_30, DOI 10.1007/978-981-15-3383-9_30]
   Takahashi K., 2010, FleXScan User Guide Internet
   Ulak MB, 2019, COMPUT ENVIRON URBAN, V78, DOI 10.1016/j.compenvurbsys.2019.101398
   Worboys M., 2004, GIS: A Computing Perspective
   Wuu JY, 2011, INT SYM QUAL ELECT, P116
   Xia DW, 2022, MULTIMED TOOLS APPL, V81, P27523, DOI 10.1007/s11042-022-12077-x
   Yu DJ, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106467
   Zhou X, 2014, WIRES DATA MIN KNOWL, V4, P1, DOI 10.1002/widm.1113
NR 47
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16683
EP 16710
DI 10.1007/s11042-023-16246-4
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100013
DA 2024-07-18
ER

PT J
AU Hu, YK
   Lyu, L
   Wang, N
   Zhou, XL
   Fang, M
AF Hu, Yankun
   Lyu, Li
   Wang, Ning
   Zhou, XiaoLei
   Fang, Meng
TI Application of machine learning model optimized by improved sparrow
   search algorithm in water quality index time series prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Sparrow search algorithm; Time series prediction;
   Support vector regression; Random forest regression
AB Water quality index is an important indicator to evaluate the water quality of rivers. Machine learning models have been widely used in the task of water quality index prediction, but the problem of model parameter optimization still has not been effectively solved, which seriously affects the prediction accuracy and the applicability of the model. In recent years, a variety of intelligent optimization algorithms have been applied to solve model parameter optimization problems. For example, Sparrow Search Algorithm (SSA), Gray Wolf Optimization (GWO), Genetic Algorithm (GA), etc. However, the existing optimization algorithm has limited optimization capability and still needs further improvement so as to enhance the optimization capability. In this paper, we improve the standard sparrow search algorithm. The improved sparrow search algorithm (IMSSA) uses Tent chaotic sequences to initialize the sparrow population, thus increasing the population diversity; we add adaptive inertia weights and random inertia weights to the SSA, while incorporating the simulated annealing algorithm for optimization, which improves the search performance, convergence accuracy and the ability to jump out of local optimal solutions. We compare the IMSSA with other advanced optimization algorithms on several common test functions, and the results show that the algorithm outperforms other algorithms in terms of convergence accuracy and merit-seeking ability. Meanwhile, we used the IMSSA to optimize the parameters of support vector regression (SVR) and random forest regression (RFR) models to obtain two water quality index prediction models, IMSSA-SVR and IMSSA-RFR, and applied the models to river dissolved oxygen and permanganate index prediction. The experiments show that our model effectively improves the prediction accuracy of river water quality index and has strong practicality.
C1 [Hu, Yankun; Lyu, Li; Wang, Ning; Zhou, XiaoLei; Fang, Meng] Chinese Acad Sci, Shenyang Inst Comp Technol, Shenyang 110168, Peoples R China.
   [Hu, Yankun; Lyu, Li; Wang, Ning; Zhou, XiaoLei; Fang, Meng] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Wang, N (corresponding author), Chinese Acad Sci, Shenyang Inst Comp Technol, Shenyang 110168, Peoples R China.; Wang, N (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM wangning@sict.ac.cn
OI wang, ning/0000-0001-6731-2808
FU National Water Pollution Control and Treatment Science and Technology
   Major Special Project [2018ZX07601001]; Special project of guiding local
   science and technology development by the central government of Liaoning
   Province [2021010211-JH6/105]
FX This work was supported by the National Water Pollution Control and
   Treatment Science and Technology Major Special Project (NO.
   2018ZX07601001), the Special project of guiding local science and
   technology development by the central government of Liaoning Province
   (NO. 2021010211-JH6/105).
CR Antanasijevic D, 2020, NEURAL COMPUT APPL, V32, P3957, DOI 10.1007/s00521-019-04079-y
   Asadollah SBHS, 2021, J ENVIRON CHEM ENG, V9, DOI 10.1016/j.jece.2020.104599
   Bi J, 2021, INFORM SCIENCES, V571, P191, DOI 10.1016/j.ins.2021.04.057
   Chen SY, 2018, WATER-SUI, V10, DOI 10.3390/w10060806
   Chen WS, 2021, ENG COMPUT-GERMANY, V37, P1455, DOI 10.1007/s00366-019-00895-x
   Chen ZL, 2022, J SUPERCOMPUT, V78, P7227, DOI 10.1007/s11227-021-04142-3
   Demir FB, 2020, NEURAL COMPUT APPL, V32, P14227, DOI 10.1007/s00521-020-04815-9
   Feng B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104423
   Gupta P, 2022, CMC-COMPUT MATER CON, V71, P5659, DOI 10.32604/cmc.2022.023056
   Hu ZH, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19061420
   Huo FC, 2022, MULTIMED TOOLS APPL, V81, P2189, DOI 10.1007/s11042-021-11644-y
   Lee J, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107713
   Li XJ, 2022, APPL INTELL, V52, P10341, DOI 10.1007/s10489-021-02972-5
   Li XC, 2022, J PETROL SCI ENG, V208, DOI 10.1016/j.petrol.2021.109309
   Lin JCW, 2022, APPL INTELL, V52, P10604, DOI 10.1007/s10489-021-03134-3
   Lin JCW, 2021, APPL SOFT COMPUT, V108, DOI 10.1016/j.asoc.2021.107422
   Liu GY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041224
   Liu JH, 2021, IEEE ACCESS, V9, P117581, DOI 10.1109/ACCESS.2021.3106269
   Ma B, 2021, IEEE ACCESS, V9, P159218, DOI 10.1109/ACCESS.2021.3129255
   Noori N, 2020, J HYDROL, V590, DOI 10.1016/j.jhydrol.2020.125220
   Nouraki A, 2021, ENVIRON SCI POLLUT R, V28, P57060, DOI 10.1007/s11356-021-14560-8
   Pham AD, 2020, SOFT COMPUT, V24, P14965, DOI 10.1007/s00500-020-04848-1
   Ribeiro F, 2021, ASTRON COMPUT, V35, DOI 10.1016/j.ascom.2021.100468
   Sahu AK, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03365-9
   Shah MI, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13084576
   Shang ZH, 2020, NEURAL PROCESS LETT, V52, P1207, DOI 10.1007/s11063-020-10300-0
   Shao YA, 2023, IEEE T NEUR NET LEAR, V34, P2133, DOI 10.1109/TNNLS.2021.3105937
   Srinivasu PN, 2020, J INTELL FUZZY SYST, V38, P6031, DOI 10.3233/JIFS-179688
   Tiwari D, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12714
   Wang P, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/5556780
   Xu JL, 2021, WATER-SUI, V13, DOI 10.3390/w13223262
   Xu LQ, 2013, MATH COMPUT MODEL, V58, P801, DOI 10.1016/j.mcm.2012.12.023
   Xue JK, 2020, SYST SCI CONTROL ENG, V8, P22, DOI 10.1080/21642583.2019.1708830
   Zaqoot HA, 2018, APPL ARTIF INTELL, V32, P727, DOI 10.1080/08839514.2018.1506970
   Zhang CL, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106924
   Zhu YL, 2021, INT J HYDROGEN ENERG, V46, P9541, DOI 10.1016/j.ijhydene.2020.12.107
NR 36
TC 0
Z9 0
U1 9
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16097
EP 16120
DI 10.1007/s11042-023-16219-7
EA JUL 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200011
DA 2024-07-18
ER

PT J
AU Mondal, S
   De, P
   Malakar, S
   Sarkar, R
AF Mondal, Sayan
   De, Pratyay
   Malakar, Samir
   Sarkar, Ram
TI OMRNet: A lightweight deep learning model for optical mark recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical mark recognition; Multiple choice question; Transfer learning;
   OMRNet
ID LOW-COST
AB Existing Optical Mark Recognition (OMR) systems tend to be expensive and rigid in their operation, often resulting in erroneous evaluations due to strict correction protocols. This scenario airs the need for a flexible OMR system. Hence, in this work, we propose a lightweight transfer learning based Convolutional Neural Network (CNN) model, dubbed as OMRNet, which can classify answer boxes on any generalized OMR test sheet. Unlike most existing techniques that rely on image processing algorithms to recognize extracted answer boxes in two classes: confirmed and empty, the OMRNet is designed to classify the answer boxes into confirmed, crossed-out, and empty categories. That is, OMRNet is facilitating the crossing out of previously answered questions and thus removing the rigidity of templates in Multiple Choice Question (MCQ) tests. We have built OMRNet on top of a MobileNetV2 backbone connected to four fully connected layers with appropriate dropouts and activation functions in between. We have evaluated OMRNet on the Multiple Choice Answer Boxes dataset available at . We have performed experiments following a 5 fold cross validation scheme, and OMRNet has achieved accuracies of 95.29%, 95.88%, 93.97%, 97.45%, and 97.20%, with an average accuracy of 95.96%. Also, the experimental results confirm that the present model performs better than the compared state-of-the-art methods and standard CNN models in terms of accuracy, execution time, and memory required to store the trained module. Moreover, we have employed a quantization technique to make the trained module more memory efficient and deployed it to a web app using our own Representational State Transfer Application Programming Interface (REST API). It makes OMRNet available via a Hypertext Transfer Protocol (HTTP) endpoint, allowing potential users to connect to it via the Internet. The source code for the work is available at the following link: .
C1 [Mondal, Sayan; De, Pratyay] Natl Inst Technol Durgapur, Dept Elect Engn, Durgapur 713209, India.
   [Malakar, Samir] Asutosh Coll, Dept Comp Sci, Kolkata 700026, India.
   [Sarkar, Ram] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Durgapur; Jadavpur University
RP Malakar, S (corresponding author), Asutosh Coll, Dept Comp Sci, Kolkata 700026, India.
EM dgpmondal@gmail.com; pratyaydedgp@gmail.com; malakarsamir@gmail.com;
   ramjucse@gmail.com
OI De, Pratyay/0000-0002-6852-1094
CR Afifi M, 2019, INT J DOC ANAL RECOG, V22, P127, DOI 10.1007/s10032-019-00322-3
   Agarap A. F., 2018, ARXIV
   Ahad Rafel, 2019, 3rd International Conference on Electrical, Computer & Telecommunication Engineering (ICECTE 2019), P153, DOI 10.1109/ICECTE48615.2019.9303521
   Al-marakeby A, 2013, INT J COMPUT APPL, V68
   Anvarjon T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185212
   Fisteus JA, 2013, J SCI EDUC TECHNOL, V22, P560, DOI 10.1007/s10956-012-9414-8
   Bera SK, 2020, J INTELL SYST, V29, P688, DOI 10.1515/jisys-2018-0105
   Bhowal P, 2022, J AMB INTEL HUM COMP, P1
   Buleje Carlos Yinmel Castro, 2020, 2020 XLVI Latin American Computing Conference (CLEI), P172, DOI 10.1109/CLEI52000.2020.00027
   Calado M. Padoca, 2019, 2019 6th International Conference on Systems and Informatics (ICSAI), P1548, DOI 10.1109/ICSAI48974.2019.9010132
   Chai D, 2016, PROCEEDINGS OF 2016 IEEE INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT, AND LEARNING FOR ENGINEERING (TALE), P145, DOI 10.1109/TALE.2016.7851785
   Chattopadhyay S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11020315
   China R, 2016, REV BRASILEIRA INICI, V3
   Chinnasarn K, 1999, PROC SPIE, V3808, P702, DOI 10.1117/12.365883
   Cupic M, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1136, DOI 10.1109/MIPRO.2014.6859739
   Das S, 2021, BIG DATA RES, V25, DOI 10.1016/j.bdr.2021.100233
   de Elias E.M., 2021, SN COMPUT. SCI, V2, P367, DOI DOI 10.1007/S42979-021-00760-Z
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dey M, 2021, NEURAL COMPUT APPL, V33, P13367, DOI 10.1007/s00521-021-05964-1
   Dey S, 2022, APPL SOFT COMPUT, V114, DOI 10.1016/j.asoc.2021.108094
   Gillespie R, 1988, BRIT J HIST SCI
   Gyamfi E., 2017, ADV SCI TECHNOL ENG, V2, P121, DOI [10.25046/aj020417, DOI 10.25046/AJ020417]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussmann S, 2005, REAL-TIME IMAGING, V11, P19, DOI 10.1016/j.rti.2005.03.001
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jain Viraj, 2022, 2022 IEEE 6th Conference on Information and Communication Technology (CICT), P1, DOI 10.1109/CICT56698.2022.9997878
   Kamavisdar P., 2013, International Journal of Advanced Research in Computer and Communication Engineering, V2, P1005
   Karunanayake N, 2015, INT J RES EMERG SCI, V2
   Khan I, 2018, EFFICIENT COST EFFEC
   Kingma D. P., 2014, arXiv
   Koushik K. S., 2022, 2022 3rd International Conference on Electronics and Sustainable Communication Systems (ICESC), P728, DOI 10.1109/ICESC54411.2022.9885493
   KRISNADI D, 2017, DESTECH T COMPUTER S
   KUKLICK H, 1987, SCIENCE, V237, P1358, DOI 10.1126/science.237.4820.1358
   Makinen S, 2021, ARXIV
   Malakar S, 2023, VISUAL COMPUT, V39, P2909, DOI 10.1007/s00371-022-02500-7
   Malakar S, 2020, J INTELL SYST, V29, P719, DOI 10.1515/jisys-2017-0384
   Malakar S, 2012, PROC INT CONF EMERG, P303, DOI 10.1109/EAIT.2012.6407929
   Manzoor A., 2019, 2019 2 INT C NEW, P1, DOI [DOI 10.1109/ictcs.2019.8923092, 10.1109/ICTCS.2019.8923092, 10.1109/ictcs.2019.8923092]
   Marchant, 2021, ASSESSING VALIDITY M
   Mondal R, 2022, MULTIMED TOOLS APPL, V81, P975, DOI 10.1007/s11042-021-11425-7
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Pavithra U., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0857, DOI 10.1109/ICCSP.2019.8698095
   Rasiq GMRI, 2019, PROCEEDINGS OF THE 2019 8TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2019), P144, DOI [10.1109/smart46866.2019.9117468, 10.1109/SMART46866.2019.9117468]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sanguansat P., 2015, 2015 12th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology, P1, DOI [10.1109/ECTICon.2015.7206937, DOI 10.1109/ECTICON.2015.7206937]
   Seidaliyeva U, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143856
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinchai A, 2022, 2022 37TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2022), P268, DOI 10.1109/ITC-CSCC55581.2022.9895053
   Smith M., 1981, PROC9TH ANN ACM SIGU, P257, DOI [10.1145/800079.802600, DOI 10.1145/800079.802600]
   Spadaccini A, 2011, ARXIV
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   The University of Texas, 1973, ALC U TEX AUST AL MA, V61, P36
   Thummerer A, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/abb1d6
   Tien Dzung Nguyen, 2011, Proceedings of the 2011 International Conference on Advanced Technologies for Communications (ATC 2011), P268, DOI 10.1109/ATC.2011.6027482
   Tow Jingyi, 2021, 2021 International Conference on Computer & Information Sciences (ICCOINS), P322, DOI 10.1109/ICCOINS49721.2021.9497172
   Weaver D, 1997, J GEOGR HIGHER EDUC
   Wolberg G., 1990, Digital image warping
   Zhu M, 2021, NEUROCOMPUTING, V429, P110, DOI 10.1016/j.neucom.2020.11.068
   Zoph B., 2016, INT C LEARN REPR
NR 63
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14011
EP 14045
DI 10.1007/s11042-023-15408-8
EA JUL 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001028770200008
DA 2024-07-18
ER

PT J
AU Sigut, J
   Nuñez, O
   Fumero, F
   Alayon, S
   Diaz-Aleman, T
AF Sigut, Jose
   Nunez, Omar
   Fumero, Francisco
   Alayon, Silvia
   Diaz-Aleman, Tinguaro
TI Fovea localization in retinal images using spatial color histograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Retinal diseases diagnosis; Fovea localization; Spatial color histogram
ID OPTIC DISC; FUNDUS IMAGES; AUTOMATIC DETECTION
AB The automatic location of the fovea is very useful for diagnosing retinal diseases. It is a complex problem for which different solutions have been proposed based on classical image processing and Deep Learning techniques. The method presented in this paper is based on histograms that combine spatial and color information in such a way that the spatial coordinates are incorporated into conventional color histograms as an additional dimension. The binarization of these histograms retains a considerable amount of relevant information from the original image, allowing them to be processed as if they were ordinary images. This approach to the problem results in a simple, fast and effective method for locating the fovea. Different experiments have been carried out with three popular sets of images: Messidor, REFUGE1 and DIARETDB1, and a comparison was made with other state-of-the-art techniques. Our results show that the proposed method, despite its simplicity, is capable of surpassing many of these techniques.
C1 [Sigut, Jose; Nunez, Omar; Fumero, Francisco; Alayon, Silvia] Univ La Laguna ULL, Dept Comp Sci & Syst Engn, Ave Astrofis Francisco Sanchez S-N, San Cristobal la Laguna 38200, Santa Cruz De T, Spain.
   [Diaz-Aleman, Tinguaro] Canary Isl Univ Hosp, Dept Ophtalmol, Santa Cruz De Tenerife 38320, Spain.
C3 Universidad de la Laguna
RP Alayon, S (corresponding author), Univ La Laguna ULL, Dept Comp Sci & Syst Engn, Ave Astrofis Francisco Sanchez S-N, San Cristobal la Laguna 38200, Santa Cruz De T, Spain.
EM jfsigut@ull.edu.es; omar@isaatc.ull.es; ffumerob@ull.edu.es;
   salayon@ull.edu.es; vtdac@hotmail.com
RI Díaz Alemán, Valentín Tinguaro/JMB-1627-2023; Alayon, Silvia/I-3896-2016
OI Díaz Alemán, Valentín Tinguaro/0000-0003-4579-0555; Alayon,
   Silvia/0000-0001-8498-3275
FU CRUE-CSIC agreement with Springer Nature
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature.
CR academictorrents, DIARETDB1 DAT
   adcis, MESS DAT
   Aibing Rao, 1999, Proceedings 11th International Conference on Tools with Artificial Intelligence, P183, DOI 10.1109/TAI.1999.809784
   Al-Bander B, 2018, BIOMED SIGNAL PROCES, V40, P91, DOI 10.1016/j.bspc.2017.09.008
   Alamdar F, 2011, IJCSI INT J COMPUTER, V8, P42
   Aquino A, 2014, COMPUT BIOL MED, V55, P61, DOI 10.1016/j.compbiomed.2014.10.007
   Carmona EJ, 2021, NEURAL COMPUT APPL, V33, P1903, DOI 10.1007/s00521-020-05060-w
   Chalakkal RJ, 2018, IET IMAGE PROCESS, V12, P2100, DOI 10.1049/iet-ipr.2018.5666
   Cinque L, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P969, DOI 10.1109/MMCS.1999.778621
   Dashtbozorg B, 2016, IMAGE ANAL RECOGNITI, V9730
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Escorcia-Gutierrez J, 2020, COMPUT BIOL MED, V127, DOI 10.1016/j.compbiomed.2020.104049
   GeethaRamani R, 2018, COMPUT METH PROG BIO, V160, P153, DOI 10.1016/j.cmpb.2018.03.020
   Gegundez-Arias ME, 2013, COMPUT MED IMAG GRAP, V37, P386, DOI 10.1016/j.compmedimag.2013.06.002
   Github of Medical Image Analysis Group (MIAG), US
   Guo XX, 2020, IEEE J BIOMED HEALTH, V24, P2315, DOI 10.1109/JBHI.2020.2971593
   Gupta D, 2020, IMAGE AUGMENTATION M
   Gupta D, 2020, IMAGE SEGMENTATION T
   Gupta D, 2020, IMPLEMENTATION VARIO
   Hasan MK, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.102001
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang YJ, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101939
   Kablan EB, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106533
   Kao EF, 2014, COMPUT METH PROG BIO, V117, P92, DOI 10.1016/j.cmpb.2014.08.003
   Klviinen RVJPH., 2007, Medical Image Understanding and Analysis, V2007, P61
   Medhi JP, 2016, COMPUT BIOL MED, V74, P30, DOI 10.1016/j.compbiomed.2016.04.007
   Meyer MI, 2018, LECT NOTES COMPUT SC, V11071, P39, DOI 10.1007/978-3-030-00934-2_5
   OMahony N, 2019, SCI INF C, P128, DOI [DOI 10.1007/978-3-030-17795-9_10, 10.1007/978-3-030-17795-9_10]
   Orlando JI, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101570
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Qureshi RJ, 2012, COMPUT VIS IMAGE UND, V116, P138, DOI 10.1016/j.cviu.2011.09.001
   refuge.grand-challenge, REFUGE1 DAT
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sedai S, 2017, I S BIOMED IMAGING, P1083, DOI 10.1109/ISBI.2017.7950704
   Sigut J, 2017, PEERJ, V5, DOI 10.7717/peerj.3763
   Sinthanayothin C, 1999, BRIT J OPHTHALMOL, V83, P902, DOI 10.1136/bjo.83.8.902
   Sun JD, 2006, PATTERN RECOGN LETT, V27, P1122, DOI 10.1016/j.patrec.2005.12.014
   Syed AM, 2018, IEEE ACCESS, V6, P58784, DOI 10.1109/ACCESS.2018.2873415
   Welfer D, 2011, COMPUT METH PROG BIO, V104, P397, DOI 10.1016/j.cmpb.2010.07.006
   Xie RT, 2021, IEEE T MED IMAGING, V40, P116, DOI 10.1109/TMI.2020.3023254
   Zhao H., 2016, ARXIV
   Zheng SH, 2019, J MED IMAG HEALTH IN, V9, P847, DOI 10.1166/jmihi.2019.2665
NR 42
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17753
EP 17771
DI 10.1007/s11042-023-16244-6
EA JUL 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001028770200003
OA hybrid
DA 2024-07-18
ER

PT J
AU Renklier, A
   Öztürk, S
AF Renklier, Ayhan
   Ozturk, Serkan
TI Image authentication and recovery: Sudoku puzzle and MD5 hash algorithm
   based self-embedding fragile image watermarking method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-embedding; Self-recovery; Authentication; Sudoku
ID TAMPERING DETECTION; SCHEME; DCT
AB In recent years, image forgery has become an important issue with the use of images in many important areas. Several self-embedding fragile watermarking methods have been studied for image authentication with the additional capability of image recovery. However, these methods have certain shortcomings in terms of coincidence problem, imperceptibility, and image recovery. In this paper, we introduce a new self-embedding watermarking method based on the Sudoku puzzle, in which recovery is achieved by successfully reconstructing up to 80% tampered images. In the proposed method, initially, the grayscale host image is divided into twenty-five blocks based on the 5 x 5 Sudoku puzzle. These blocks are grouped and divided into 5 x 5 non-overlapping sub-blocks. The recovery information is obtained from the average pixel values of each sub-block. For each group, four copies of the sub block recovery information are embedded into the second least significant bits (LSBs) of the other group blocks based on Sudoku. Then, for each 5 x 5 sub-block authentication information is generated with MD5 hash algorithm using the block position, block pixel values, and a secret key. Finally, the 25-bit of the authentication information is embedded into the first LSBs of the sub-blocks. Experimental results show that the proposed method has good performance in different sized cropping, splicing, copy-move, salt-pepper, histogram equalization, sharpening, blurring, and text-addition attacks applied to different regions of the images. Also, the proposed method has obtained high quality recovered images since it efficiently minimizes the effect of coincidence problem.
C1 [Renklier, Ayhan] Kayseri Univ, Software Engn Dept, TR-38280 Kayseri, Turkiye.
   [Ozturk, Serkan] Erciyes Univ, Comp Engn Dept, TR-38039 Kayseri, Turkiye.
C3 Kayseri University; Erciyes University
RP Renklier, A (corresponding author), Kayseri Univ, Software Engn Dept, TR-38280 Kayseri, Turkiye.
EM ayhan@kayseri.edu.tr; serkan@erciyes.edu.tr
RI RENKLİER, AYHAN/ABD-2663-2020
OI RENKLİER, AYHAN/0000-0002-9164-4615
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Aminuddin A, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108207
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang C.-C., 2008, 2008 3 INT C INN COM, P17, DOI 10.1109/ICICIC.2008.149
   Chang CC, 2020, MULTIMED TOOLS APPL, V79, P24795, DOI 10.1007/s11042-020-09132-w
   Chen L, 2019, IEEE ACCESS, V7, P97549, DOI 10.1109/ACCESS.2019.2926831
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Felgenhauer B., 2006, Mathematical Spectrum, V39, P15
   Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   Gul E, 2021, MULTIMEDIA SYST, V27, P531, DOI 10.1007/s00530-021-00751-3
   Gul E, 2020, MULTIMED TOOLS APPL, V79, P31239, DOI 10.1007/s11042-020-09548-4
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Hemida O, 2020, MULTIMED TOOLS APPL, V79, P18695, DOI 10.1007/s11042-020-08727-7
   Lee CW, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.5.057006
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li CL, 2011, COMPUT ELECTR ENG, V37, P927, DOI 10.1016/j.compeleceng.2011.09.007
   Lin CC, 2022, MULTIMED TOOLS APPL, V81, P39431, DOI 10.1007/s11042-022-12995-w
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Molina-Garcia J, 2016, 2016 9 INT KHARKIV S, P1, DOI DOI 10.1109/MSMW.2016.7538148
   Piva A, 2005, INT J IMAGE GRAPH, V5, P149, DOI 10.1142/S0219467805001707
   Qian ZX, 2011, DIGIT SIGNAL PROCESS, V21, P278, DOI 10.1016/j.dsp.2010.04.006
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rajput V, 2020, MULTIMED TOOLS APPL, V79, P35519, DOI 10.1007/s11042-019-07971-w
   Renklier A, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6897
   Russell E., 2006, Mathematical Spectrum, V39, P54
   Shivani Shivendra, 2013, Pattern Recognition and Image Analysis. 6th Iberian Conference, IbPRIA 2013. Proceedings. LNCS 7887, P640
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P953, DOI 10.1007/s11042-015-3010-x
   Singh D, 2013, INT J IMAGE GRAPH, V13, DOI 10.1142/S0219467813400020
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Su GD, 2021, MULTIMED TOOLS APPL, V80, P12881, DOI 10.1007/s11042-020-10451-1
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Wu HC, 2022, MULTIMED TOOLS APPL, V81, P19351, DOI 10.1007/s11042-021-11018-4
   Yang CW, 2010, SIGNAL PROCESS, V90, P331, DOI 10.1016/j.sigpro.2009.07.007
   Yuan XC, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116038
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang XP, 2009, LECT NOTES COMPUT SC, V5703, P268, DOI 10.1007/978-3-642-03688-0_24
NR 38
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 13929
EP 13951
DI 10.1007/s11042-023-15999-2
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700009
DA 2024-07-18
ER

PT J
AU Hosseini, SH
   Monsefi, R
   Shadroo, S
AF Hosseini, Seyed Hesamoddin
   Monsefi, Reza
   Shadroo, Shabnam
TI Deep learning applications for lung cancer diagnosis: A systematic
   review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung cancer detection; Deep learning; Systematic Survey
ID COMPUTED-TOMOGRAPHY IMAGES; AUTOMATIC DETECTION; PULMONARY NODULES; CT
   IMAGES; CLASSIFICATION; SEGMENTATION; NETWORKS; CNNS
AB Lung cancer has been one of the most prevalent disease in recent years. According to the research of this field, more than 200,000 cases are identified each year in the US. Uncontrolled multiplication and growth of the lung cells result in malignant tumour formation. Recently, deep learning algorithms, especially Convolutional Neural Networks (CNN), have become a superior way to automatically diagnose disease. The purpose of this article is to review different models that lead to different accuracy and sensitivity in the diagnosis of early-stage lung cancer and to help physicians and researchers in this field. The main purpose of this work is to identify the challenges that exist in lung cancer based on deep learning. The survey is systematically written that combines regular mapping and literature review to review 32 conference and journal articles in the field from 2016 to 2021. In this work, after a complete analysis and review of the articles, the questions raised in the articles have been answered. This research work provides a more comprehensive review compared to previous published review articles in this research area. Furthermore, it includes recent studies and state of the art research works systematically.
C1 [Hosseini, Seyed Hesamoddin; Monsefi, Reza] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Iran.
   [Shadroo, Shabnam] Islamic Azad Univ, Dept Software Engn, Mashhad Branch, Mashhad, Iran.
C3 Ferdowsi University Mashhad; Islamic Azad University
RP Shadroo, S (corresponding author), Islamic Azad Univ, Dept Software Engn, Mashhad Branch, Mashhad, Iran.
EM hesamoddin.hosseini@mail.um.ac.ir; monsefi@um.ac.ir;
   sh_shadroo@mshdiau.ac.ir
RI shadroo, shabnam/AAO-5656-2021
OI shadroo, shabnam/0000-0002-0094-0372; Hosseini, Seyed
   Hesamoddin/0000-0001-8073-0609
CR Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   American Cancer Society, 2020, Key statistics for lung cancer
   Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   [Anonymous], 2015, International Journal of Hybrid Information Technology, DOI [10.14257/ijhit.2015.8.2.20, DOI 10.14257/IJHIT.2015.8.2.20]
   Aonpong P, 2021, IEEE ACCESS, V9, P90244, DOI 10.1109/ACCESS.2021.3088234
   Armato III S.G., 2015, DATA LIDC IDRI, DOI [DOI 10.7937/K9/TCIA.2015.LO9QL9SX, 10.7937/K9/TCIA.2015.LO 9QL9SX]
   Bakr S, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.202
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Breivold HP, 2012, INFORM SOFTWARE TECH, V54, P16, DOI 10.1016/j.infsof.2011.06.002
   Buckeye AJ, 2017, DATA SCI BOWL 2017
   Cai LQ, 2020, IEEE ACCESS, V8, P44400, DOI 10.1109/ACCESS.2020.2976432
   Chen W, 2019, IEEE ACCESS, V7, P75591, DOI 10.1109/ACCESS.2019.2921434
   Chiles C, 2015, RADIOLOGY, V276, P82, DOI 10.1148/radiol.15142062
   Ciompi F, 2017, SCI REP-UK, V7, DOI 10.1038/srep46479
   Cruz-Benito J, 2016, ZENODO, DOI [10.5281/zenodo.165773, DOI 10.5281/ZENODO.165773]
   Diagnostic Image Analysis Group, 2020, US
   Dou Q, 2017, IEEE T BIO-MED ENG, V64, P1558, DOI 10.1109/TBME.2016.2613502
   github, 2020, MULT DEEP LEARN MARG
   Guo HT, 2020, IEEE J BIOMED HEALTH, V24, P457, DOI 10.1109/JBHI.2019.2946066
   Hossain MS, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/858712
   Jakimovski G, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9030427
   Jiang HY, 2018, IEEE J BIOMED HEALTH, V22, P1227, DOI 10.1109/JBHI.2017.2725903
   Jin HS, 2018, MED PHYS, V45, P2097, DOI 10.1002/mp.12846
   Krishnaiah V., 2013, International Journal of Computer Science and Information Technologies, V4, P39
   Kuan K, 2017, ARXIV
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Li L, 2019, THORAC CANCER, V10, P183, DOI 10.1111/1759-7714.12931
   Li YF, 2019, IEEE ACCESS, V7, P37822, DOI 10.1109/ACCESS.2019.2905574
   Liu LH, 2020, IEEE T MED IMAGING, V39, P718, DOI 10.1109/TMI.2019.2934577
   Liu YJ, 2018, IEEE ACCESS, V6, P49080, DOI 10.1109/ACCESS.2018.2865544
   Liu Z, 2019, FUTURE GENER COMP SY, V97, P1, DOI 10.1016/j.future.2019.02.068
   Masood A, 2020, IEEE J TRANSL ENG HE, V8, DOI 10.1109/JTEHM.2019.2955458
   Mastouri R, 2020, J X-RAY SCI TECHNOL, V28, P591, DOI 10.3233/XST-200660
   Monkam P, 2019, IEEE ACCESS, V7, P78075, DOI 10.1109/ACCESS.2019.2920980
   Nasser IM, 2019, LUNG CANC DETECTION
   Ozdemir O, 2020, IEEE T MED IMAGING, V39, P1419, DOI 10.1109/TMI.2019.2947595
   Pang SC, 2020, IEEE ACCESS, V8, P4799, DOI 10.1109/ACCESS.2019.2962862
   Petersen K, 2015, INFORM SOFTWARE TECH, V64, P1, DOI 10.1016/j.infsof.2015.03.007
   Rendon-Gonzalez E., 2016, MILLIMETER SUBMILLIM, V2016, P1, DOI [10.1109/MSMW.2016.7537995, DOI 10.1109/MSMW.2016.7537995]
   Sahu P, 2019, IEEE J BIOMED HEALTH, V23, P960, DOI 10.1109/JBHI.2018.2879834
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shadroo S, 2018, COMPUT NETW, V139, P19, DOI 10.1016/j.comnet.2018.04.001
   Shakeel PM, 2019, MEASUREMENT, V145, P702, DOI 10.1016/j.measurement.2019.05.027
   Shakeel PM, 2020, HEALTH TECHNOL-GER, V10, P157, DOI 10.1007/s12553-018-0279-6
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Silva F, 2021, IEEE ACCESS, V9, P58667, DOI 10.1109/ACCESS.2021.3070701
   Sun WQ, 2015, MED PHYS, V42, P2853, DOI 10.1118/1.4919772
   Teramoto A, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/4067832
   via.cornell, 2020, VIS IM AN LAB
   Wang C, 2019, IEEE ACCESS, V7, P146533, DOI 10.1109/ACCESS.2019.2946000
   Wang J, 2019, IEEE ACCESS, V7, P46033, DOI 10.1109/ACCESS.2019.2908195
   Wang WZ, 2019, IEEE ACCESS, V7, P128796, DOI 10.1109/ACCESS.2019.2939850
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Yu H, 2020, IEEE ACCESS, V8, P86400, DOI 10.1109/ACCESS.2020.2992645
   Zhang C, 2019, ONCOLOGIST, V24, P1159, DOI 10.1634/theoncologist.2018-0908
   Zhang QH, 2020, IEEE ACCESS, V8, P90380, DOI 10.1109/ACCESS.2020.2993872
   Zheng J, 2020, IET IMAGE PROCESS, V14, P1481, DOI 10.1049/iet-ipr.2019.0248
NR 57
TC 7
Z9 7
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14305
EP 14335
DI 10.1007/s11042-023-16046-w
EA JUL 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001023992100005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Naik, BB
   Reddy, TJVR
   Karthik, KRV
   Kuila, P
AF Naik, B. Balaji
   Reddy, T. Jaya Venkata Rama
   Karthik, K. Rohith Venkata
   Kuila, Pratyay
TI An SQL query generator for cross-domain human language based questions
   based on NLP model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SQL; Sentence-Table Encoder; Table-aware Decoder; Sparc; Spider; CoSQL
ID INTERFACE
AB The amount of data generated in the modern world is so great that data lakes are now being used to store data. However, relational databases are currently the primary repository for the world's data. However, it is very time-consuming for a user to type each query every time, especially the queries that include complex keywords. Our proposed approach uses the interaction history by altering the preceding projected query to improve the generation quality, based on the finding that successive human language queries are frequently lin- guistically dependent, and their equivalent SQL queries overlap. This paper focuses on text-to-SQL conversion for cross-domain datasets. Our approach reuses results produced at the token level and considers SQL statements as sequences. Finally, we evaluate our approach on different datasets like the Sparc, Spider, and CoSQL datasets. It compared our proposed approach with existing famous algorithms like Seq2seq, and added attention and copying to the seq2seq model, SQLNet model, and TypeSQL model in terms of accuracy and F1 score.
C1 [Naik, B. Balaji] Natl Inst Technol Patna, Comp Sci & Engn, Patna 800005, Bihar, India.
   [Reddy, T. Jaya Venkata Rama; Karthik, K. Rohith Venkata; Kuila, Pratyay] Natl Inst Technol Sikkim, Comp Sci & Engn, Ravangla 737139, Sikkim, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna; National Institute of Technology (NIT System);
   National Institute of Technology Sikkim
RP Naik, BB (corresponding author), Natl Inst Technol Patna, Comp Sci & Engn, Patna 800005, Bihar, India.
EM balajinaik07@gmail.com; jayanthr865@gmail.com; b180039@nitsikkim.ac.in;
   pratyay.kuila@yahoo.com
RI Kuila, Pratyay/O-3544-2017
OI Kuila, Pratyay/0000-0002-4549-3246
CR Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695
   [Anonymous], 2013, P 2013 C EMP METH NA
   Artzi Y, 2013, T ASSOC COMPUT LING, V1, P49, DOI DOI 10.1162/TACL_A_00209
   Bai T, 2021, IEEE ACCESS, V9, P4233, DOI 10.1109/ACCESS.2020.3048164
   Berant J, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1415, DOI 10.3115/v1/p14-1133
   Bertomeu N, 2006, P INT QUEST ANSW WOR, P1
   Branavan S.R., 2009, P JOINT C 47 ANN M A, P82, DOI DOI 10.3115/1687878.1687892
   Buchsbaum BR, 2001, COGNITIVE SCI, V25, P663, DOI 10.1207/s15516709cog2505_2
   Cai Q., 2013, Long Papers, V1, P423
   Chen BZ, 2021, IEEE-ACM T AUDIO SPE, V29, P3592, DOI 10.1109/TASLP.2021.3129331
   Chen ZM, 2021, IEEE T SOFTWARE ENG, V47, P1943, DOI 10.1109/TSE.2019.2940179
   Dong L, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P731
   Ebadi A, 2021, SCIENTOMETRICS, V126, P725, DOI 10.1007/s11192-020-03744-7
   Goldwasser Dan, 2011, P 49 ANN M ASS COMP, P1486
   Guo, 2019, ARXIV
   Hemphill C. T., 1990, SPEECH NATURAL LANGU, V90, P96
   Hwang W, 2019, ARXIV
   Iyer S, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P963, DOI 10.18653/v1/P17-1089
   Katsogiannis-Meimarakis G, 2023, VLDB J, V32, P905, DOI 10.1007/s00778-022-00776-8
   Kollar T, 2010, ACMIEEE INT CONF HUM, P259, DOI 10.1109/HRI.2010.5453186
   Li F, 2014, PROC VLDB ENDOW, V8, P73, DOI 10.14778/2735461.2735468
   Li Q, 2020, IEEE T IND INFORM, V16, P2542, DOI 10.1109/TII.2019.2952929
   Liu QW, 2023, PHILOS T R SOC B, V378, DOI 10.1098/rstb.2021.0372
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, DOI DOI 10.18653/V1/D15-1166
   Matuszek C, 2012, PREPRINT
   Miaomiao Hong, 2019, 2019 IEEE Fourth International Conference on Data Science in Cyberspace (DSC). Proceedings, P388, DOI 10.1109/DSC.2019.00065
   Naik BB, 2017, INT CONF ADV COMMUN, P436, DOI 10.23919/ICACT.2017.7890126
   Price P. J., 1990, SPEECH NATURAL LANGU, P91
   Reddy S., 2014, TACL, V2, P377, DOI [DOI 10.1162/TACL_A_00190, /10.1162/tacla00190, 10.1162/tacl_a_00190]
   Shi P, 2021, AAAI CONF ARTIF INTE, V35, P13806
   Song MN, 2019, IEEE ACCESS, V7, P103706, DOI 10.1109/ACCESS.2019.2931464
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3508, DOI 10.1109/TPAMI.2021.3055780
   Wei C, 2022, MULTIMED TOOLS APPL, V81, P15205, DOI 10.1007/s11042-022-12573-0
   Wolfson T, 2020, T ASSOC COMPUT LING, V8, P183, DOI 10.1162/tacl_a_00309
   Wong Y. W., 2007, P 45 ANN M ASS COMP, P960
   Xiao LW, 2022, MULTIMED TOOLS APPL, V81, P19051, DOI 10.1007/s11042-020-10107-0
   Xie DD, 2021, NEUROCOMPUTING, V445, P167, DOI 10.1016/j.neucom.2021.03.005
   Xu Xiaojun, 2017, ARXIV
   Yin J, 2017, J COMPUT SCI TECH-CH, V32, P805, DOI 10.1007/s11390-017-1761-8
   Yu T, 2018, ARXIV
   Zettlemoyer LS, 2012, ARXIV
   Zhong Victor, 2017, ARXIV
NR 43
TC 0
Z9 0
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11861
EP 11884
DI 10.1007/s11042-023-15731-0
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900008
DA 2024-07-18
ER

PT J
AU Arnay, R
   Hernández-Aceituno, J
   Díaz-Alemán, T
   Sigut, J
   Alayón, S
   Fumero, F
AF Arnay, Rafael
   Hernandez-Aceituno, Javier
   Diaz-Aleman, Tinguaro
   Sigut, Jose
   Alayon, Silvia
   Fumero, Francisco
TI Optic cup segmentation of stereo retinal fundus images using virtual
   reality
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optic cup segmentation; Glaucoma classification; Stereo vision; Virtual
   reality; Mobile app
ID GLAUCOMA; OPHTHALMOLOGY; DISC
AB Glaucoma is one of the world leading causes of irreversible blindness. Early detection is essential to delay its progression and prevent vision loss. An accurate segmentation of the cup region in retinal fundus images is necessary to obtain relevant measurements for the detection of glaucoma. In recent years, multiple methods have been developed to automatically detect this region. All these methods are adjusted or trained using images that had been previously segmented by experts. In order to aid clinicians in performing this task, an interactive tool for the segmentation of the optic cup in stereo retinal fundus images using virtual reality has been developed. By using stereo images, the implemented virtual reality environment allows users to naturally perceive the three-dimensional structure of the optic cup region, which eases its segmentation compared to monocular images. The usage of the presented application was observed to increase accuracy of the delimitation, compared to using only two-dimensional fundus images, especially on areas with blood vessels.
C1 [Arnay, Rafael; Hernandez-Aceituno, Javier; Sigut, Jose; Alayon, Silvia; Fumero, Francisco] Univ La Laguna, Dept Ingn Informat & Sistemas, Astrofis Fco Sanchez S-N, San Cristobal la Laguna 38203, Canary Islands, Spain.
   [Diaz-Aleman, Tinguaro] Hosp Univ Canarias, Serv Oftalmol, Tenerife 38320, Spain.
C3 Universidad de la Laguna; Universidad de la Laguna
RP Arnay, R (corresponding author), Univ La Laguna, Dept Ingn Informat & Sistemas, Astrofis Fco Sanchez S-N, San Cristobal la Laguna 38203, Canary Islands, Spain.
EM rarnayde@ull.es; jhernaac@ull.es; vtdac@hotmail.com; jfsigut@ull.es;
   salayon@ull.es; ffumerob@ull.es
RI Díaz Alemán, Valentín Tinguaro/JMB-1627-2023
OI Díaz Alemán, Valentín Tinguaro/0000-0003-4579-0555
CR Abràmoff MD, 2007, INVEST OPHTH VIS SCI, V48, P1665, DOI 10.1167/iovs.06-1081
   AdobeCreative Team, 2002, AD PHOT 7 0 CLASSR B
   Alayon S, 2013, Arch Soc Esp Oftalmol, V88, P168, DOI 10.1016/j.oftal.2012.07.008
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   aragon, about us
   Bah T., 2011, Inkscape: guide to a vector drawing program, Vfourth
   Bakshi SK, 2021, BRIT J OPHTHALMOL, V105, P1325, DOI 10.1136/bjophthalmol-2020-316845
   Bayyari A., 2006, P ACM S VIRTUAL REAL, P368, DOI DOI 10.1145/1180495.1180570
   Bengtsson B, 2007, OPHTHALMOLOGY, V114, P205, DOI 10.1016/j.ophtha.2006.07.060
   Bennett TJ, 2009, CLIN EXP OPHTHALMOL, V37, P2, DOI 10.1111/j.1442-9071.2008.01812.x
   Bhartiya Shibal., 2010, Journal of Current Glaucoma Practice, V4, P115, DOI 10.5005/jp-journals-10008-1080
   Buteikiene D, 2012, INFORMATICA-LITHUAN, V23, P335
   Catmull E, 1974, inCom-puter Aided Geometric Design, P317, DOI [DOI 10.1016/B978-0-12-079050-0.50020-5, 10.1016/B978-0-12-079050-0.50020-5]
   Falah J, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P752, DOI 10.1109/SAI.2014.6918271
   Fumero F, 2015, 23 INT C CENTR EUR C, P91
   Fumero F, 2020, IMAGE ANAL STEREOL, V39, P161, DOI 10.5566/ias.2346
   Gao Y, 2022, VIRTUAL REAL-LONDON, V26, P415, DOI 10.1007/s10055-021-00577-4
   Garcia-Palacios A, 2007, CYBERPSYCHOL BEHAV, V10, P485, DOI 10.1089/cpb.2006.9926
   Giachetti A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2145, DOI 10.1109/ICIP.2011.6116035
   Izard SG, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102962
   google, About us
   Grillon H., 2006, Int. J. Disability Hum. Develop., V5, P243
   Hancock R, 2014, INT J OPHTHALMIC PRA, V5, P58
   Iakovidis DK, 2014, SCI WORLD J, DOI 10.1155/2014/286856
   Iskander M, 2021, ASIA-PAC J OPHTHALMO, V10, P244, DOI 10.1097/APO.0000000000000409
   Jonas Jost B, 2005, Curr Opin Ophthalmol, V16, P84, DOI 10.1097/01.icu.0000156135.20570.30
   Khalifa YM, 2006, SURV OPHTHALMOL, V51, P259, DOI 10.1016/j.survophthal.2006.02.005
   Koch F, 2009, KLIN MONATSBL AUGENH, V226, P672, DOI 10.1055/s-0028-1109383
   Merickel MB, 2006, PROC SPIE, V6143, DOI 10.1117/12.657923
   Muñoz EG, 2022, INFORMATION, V13, DOI 10.3390/info13050222
   Muramatsu C, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3622755
   Ong EP, 2015, IEEE ENG MED BIO, P4326, DOI 10.1109/EMBC.2015.7319352
   Pablo LE, 2010, EYE, V24, P123, DOI 10.1038/eye.2009.14
   Perez-Rovira A, 2011, IEEE ENG MED BIO, P3391, DOI 10.1109/IEMBS.2011.6090918
   Razeghinejad R, 2021, J GLAUCOMA, V30, P17, DOI 10.1097/IJG.0000000000001670
   Saleh GM, 2013, BRIT J OPHTHALMOL, V97, P789, DOI 10.1136/bjophthalmol-2012-302764
   Soans RS, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.745355
   Sommer C, 2011, I S BIOMED IMAGING, P230, DOI 10.1109/ISBI.2011.5872394
   Stapelfeldt J, 2021, TRANSL VIS SCI TECHN, V10, DOI 10.1167/tvst.10.12.10
   Tang L, 2011, IEEE T PATTERN ANAL, V33, P2245, DOI 10.1109/TPAMI.2011.69
   Trucco E, 2013, INVEST OPHTH VIS SCI, V54, P3546, DOI 10.1167/iovs.12-10347
   VARMA R, 1992, OPHTHALMOLOGY, V99, P215
   Williams MS, 2022, EPIDEMIOL INFECT, V150, DOI 10.1017/S0950268822001042
   Yonker SB, 2019, ELECT IMAGING, V2019, P188
NR 44
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9669
EP 9683
DI 10.1007/s11042-023-15651-z
EA JUN 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016153400003
OA hybrid
DA 2024-07-18
ER

PT J
AU Kaur, J
   Singh, W
AF Kaur, Jaskirat
   Singh, Williamjeet
TI A systematic review of object detection from images using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Computer vision; object detection; deep learning; Backbone architecture;
   object detection application
ID CONVOLUTIONAL NEURAL-NETWORK; REMOTE-SENSING IMAGES; HANDWRITTEN TEXT
   RECOGNITION; ICDAR 2015 COMPETITION; FACE RECOGNITION; CNN;
   CLASSIFICATION; VIDEO
AB The development of object detection has led to huge improvements in human interaction systems. Object detection is a challenging task because it involves many parameters including variations in poses, resolution, occlusion, and daytime versus nighttime detection. This study surveys on various aspects of object detection that includes (1) basics of object detection, (2) object detection techniques, (3) datasets, (4) metrics and deep learning libraries. This study presents a systematic analysis of recent publications on object detection covering around 400 research articles and synthesised the findings to provide empirical answers to research questions. The review is based on relevant articles published from 2015 through 2022, as well as discussions of challenges and future directions in this field. Furthermore, the survey examined the contributions of various researchers concerning their respective application domains, while emphasizing the advantages and disadvantages of the research work. Despite the success of various methods proposed in literature for predicting results, there remains room for improvement in the accuracy of object detection.
C1 [Kaur, Jaskirat] Punjabi Univ, Dept Comp Sci, Patiala, India.
   [Singh, Williamjeet] Punjabi Univ, Dept Comp Sci & Engn, Patiala, India.
C3 Punjabi University; Punjabi University
RP Kaur, J (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala, India.
EM jaskirat.scholar21@gmail.com; williamjeet@gmail.com
OI Kaur, Jaskirat/0000-0001-8819-7327
CR Ahmadi M, 2020, ARAB J SCI ENG, V45, P1421, DOI 10.1007/s13369-019-03969-6
   Alam A, 2020, INT J INTELL TRANSP, V18, P98, DOI 10.1007/s13177-019-00178-1
   An N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3441656
   Sánchez JA, 2017, PROC INT CONF DOC, P1383, DOI 10.1109/ICDAR.2017.226
   Sánchez JA, 2015, PROC INT CONF DOC, P1166, DOI 10.1109/ICDAR.2015.7333944
   Andrianov D. E., 2015, Procedia Engineering, V129, P374, DOI 10.1016/j.proeng.2015.12.126
   Angtian Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12642, DOI 10.1109/CVPR42600.2020.01266
   [Anonymous], 2017, IEEE T PATTERN ANAL
   Antioquia AMC, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON VISUAL COMMUNICATIONS AND IMAGE PROCESSING (IEEE VCIP)
   Arnold E, 2019, IEEE T INTELL TRANSP, V20, P3782, DOI 10.1109/TITS.2019.2892405
   Aslam A, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104095
   Athanasiadis I, 2018, ARXIV
   Ayalew AM, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2022.103530
   Aziz L, 2020, IEEE ACCESS, V8, P170461, DOI 10.1109/ACCESS.2020.3021508
   Bach M, 2018, IEEE INT C INTELL TR, P851, DOI 10.1109/ITSC.2018.8569522
   Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bamne Bulbul, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P328, DOI 10.1109/ICESC48915.2020.9156060
   Banerjee K, 2018, IEEE INT VEH SYM, P1632, DOI 10.1109/IVS.2018.8500699
   Behrendt Karsten, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1370, DOI 10.1109/ICRA.2017.7989163
   Bergstrom Trevor, 2020, HuMA'20: Proceedings of the 1st International Workshop on Human-centric Multimedia Analysis, P63, DOI 10.1145/3422852.3423481
   Bhamare D, 2018, FUZZY INF ENG, V10, P362, DOI 10.1080/16168658.2019.1611030
   Bin Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163158
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Boruah A, 2018, PROCEDIA COMPUT SCI, V133, P63, DOI 10.1016/j.procs.2018.07.009
   Bouras C, 2022, 36TH INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2022), P62, DOI 10.1109/ICOIN53446.2022.9687212
   Braun M, 2019, IEEE T PATTERN ANAL, V41, P1844, DOI 10.1109/TPAMI.2019.2897684
   Bui Thanh Hung, 2021, Research in Intelligent and Computing in Engineering. Select Proceedings of RICE 2020. Advances in Intelligent Systems and Computing (AISC 1254), P715, DOI 10.1007/978-981-15-7527-3_67
   Burlina P, 2017, COMPUT BIOL MED, V82, P80, DOI 10.1016/j.compbiomed.2017.01.018
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cao YW, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P3383, DOI 10.1145/3442381.3449834
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Ch'ng CK, 2017, PROC INT CONF DOC, P935, DOI 10.1109/ICDAR.2017.157
   Chahal KS, 2018, ARXIV
   Chapel MN, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100310
   Chen JC, 2023, SYST SCI CONTROL ENG, V11, DOI 10.1080/21642583.2023.2185916
   Chen Q, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107334
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen YD, 2021, INT C PATT RECOG, P850, DOI 10.1109/ICPR48806.2021.9412258
   Chen Z, 2021, INT J COMPUT VISION, V129, P1121, DOI 10.1007/s11263-020-01412-0
   Chen ZY, 2021, CAN J REMOTE SENS, V47, P83, DOI 10.1080/07038992.2021.1894915
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Chetouane A, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.5983
   Choi JD, 2023, ICT EXPRESS, V9, P222, DOI 10.1016/j.icte.2021.12.016
   Choi J, 2012, COMPUT VIS IMAGE UND, V116, P179, DOI 10.1016/j.cviu.2011.10.007
   Cole JH, 2017, NEUROIMAGE, V163, P115, DOI 10.1016/j.neuroimage.2017.07.059
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2016, ADV NEUR IN, V29
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Cesaro T, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105784
   de Charette R, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P333, DOI 10.1109/IROS.2009.5353941
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng ZP, 2018, ISPRS J PHOTOGRAMM, V145, P3, DOI 10.1016/j.isprsjprs.2018.04.003
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dey B, 2019, IET IMAGE PROCESS, V13, P673, DOI 10.1049/iet-ipr.2018.5985
   Dhillon A, 2020, PROG ARTIF INTELL, V9, P85, DOI 10.1007/s13748-019-00203-0
   Ding P, 2018, ISPRS J PHOTOGRAMM, V141, P208, DOI 10.1016/j.isprsjprs.2018.05.005
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Dominguez-Sanchez A, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110301
   Du FK, 2020, EVOL APPL, V13, P2377, DOI 10.1111/eva.13030
   Du MY, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4655
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Elmahdy MS, 2019, MED PHYS, V46, P3329, DOI 10.1002/mp.13620
   Ertler C, 2019, COMPUT VIS PATTERN R, P1
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan D, 2019, P ACM TUR CEL C CHIN, P1
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fang F, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107474
   Fengxin Li, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P130, DOI 10.1007/978-3-030-64221-1_12
   Fernandes D, 2021, INFORM FUSION, V68, P161, DOI 10.1016/j.inffus.2020.11.002
   Fregin A, 2018, IEEE INT CONF ROBOT, P3376
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu K, 2020, ISPRS J PHOTOGRAMM, V161, P294, DOI 10.1016/j.isprsjprs.2020.01.025
   Gao XH, 2017, INFORM FUSION, V36, P103, DOI 10.1016/j.inffus.2016.11.007
   Gawande Ujwalla, 2023, Procedia Computer Science, P2438, DOI 10.1016/j.procs.2023.01.219
   Gawande U, 2022, APPL INTELL, V52, P10398, DOI 10.1007/s10489-021-03073-z
   Ge C, 2020, COMPUT IND, V121, DOI 10.1016/j.compind.2020.103232
   Ge Z, 2021, NEUROCOMPUTING, V462, P272, DOI 10.1016/j.neucom.2021.07.094
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goldman E, 2019, COMPUT SPEECH LANG
   Grosicki E, 2011, PROC INT CONF DOC, P1459, DOI 10.1109/ICDAR.2011.290
   Gu WH, 2018, IET IMAGE PROCESS, V12, P2319, DOI 10.1049/iet-ipr.2018.5245
   Guo ZQ, 2021, COMPUT VIS IMAGE UND, V204, DOI 10.1016/j.cviu.2021.103170
   Guo ZX, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108063
   Gupta A, 2021, ARRAY-NY, V10, DOI 10.1016/j.array.2021.100057
   Gupta S, 2021, VISUAL COMPUT, V37, P447, DOI 10.1007/s00371-020-01814-8
   Han JM, 2021, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR46437.2021.00281
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hangaragi Shivalila, 2023, Procedia Computer Science, P741, DOI 10.1016/j.procs.2023.01.054
   Hanyao M, 2021, IEEE INFOCOM 2021 IE, P1
   Hao ZK, 2017, PROC CVPR IEEE, P1913, DOI 10.1109/CVPR.2017.207
   Hasan M, 2018, J INF SCI, V44, P443, DOI 10.1177/0165551517698564
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He SN, 2018, PROCEEDINGS OF THE 2018 THE NINETEENTH INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING (MOBIHOC '18), P1, DOI 10.1145/3209582.3209583
   He WH, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107026
   He ZL, 2020, IET INTELL TRANSP SY, V14, P323, DOI 10.1049/iet-its.2019.0409
   Heitz G, 2008, LECT NOTES COMPUT SC, V5302, P30, DOI 10.1007/978-3-540-88682-2_4
   Hinton G. E., 1986, Parallel Distributed Processing: Explorations in the Microstructure of Cognition: Foundations, V1, P2
   Hongyuan Yu, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P601, DOI 10.1109/ICDAR.2019.00102
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu K, 2017, EXPERT SYST APPL, V86, P135, DOI 10.1016/j.eswa.2017.05.062
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Hu YY, 2019, CHIN CONTR CONF, P8386, DOI [10.23919/ChiCC.2019.8865525, 10.23919/chicc.2019.8865525]
   Hua X, 2020, APPL SOFT COMPUT, V94, DOI 10.1016/j.asoc.2020.106495
   Huang H, 2019, NEUROCOMPUTING, V337, P372, DOI 10.1016/j.neucom.2019.01.084
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Huang QY, 2021, IEEE ACCESS, V9, P21777, DOI 10.1109/ACCESS.2021.3055243
   Huang W, 2019, IEEE T MED IMAGING, V38, P2338, DOI 10.1109/TMI.2019.2906677
   Hung Goon Li, 2020, SN Comp. Sci., V1, P1
   Irbaz Mohammad Sabik, 2022, Proceedings of the International Conference on Big Data, IoT, and Machine Learning: BIM 2021. Lecture Notes on Data Engineering and Communications Technologies (95), P153, DOI 10.1007/978-981-16-6636-0_13
   Ivasic-Kos M, 2019, PROCEEDINGS OF THE 2019 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND TECHNOLOGY APPLICATIONS (ICCTA 2019), P20, DOI 10.1145/3323933.3324076
   Jaderberg M, 2014, P BRIT MACH VIS C, P1
   Jaiswal D, 2020, J REAL-TIME IMAGE PR, V17, P1301, DOI 10.1007/s11554-019-00888-5
   Jamiya SS, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165818
   Jamtsho Y, 2021, ICT EXPRESS, V7, P104, DOI 10.1016/j.icte.2020.07.008
   Jani Devang, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P963, DOI 10.1109/ICCMC51019.2021.9418373
   Jian MW, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114219
   Jiang SQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1615, DOI 10.1109/ICMA.2013.6618156
   Jiang ZQ, 2018, IEEE T IMAGE PROCESS, V27, P1361, DOI 10.1109/TIP.2017.2779856
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Jiao L, 2020, COMPUT ELECTRON AGR, V174, DOI 10.1016/j.compag.2020.105522
   Jieji Ren, 2021, ICIGP 2021: The 4th International Conference on Image and Graphics Processing, P20, DOI 10.1145/3447587.3447591
   Jin J, 2021, MULTIMED TOOLS APPL, V80, P19377, DOI 10.1007/s11042-021-10702-9
   Jin Y, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107846
   Jinda Hu, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P1, DOI 10.1109/ICIVC50857.2020.9177438
   Jose A, 2019, NOVEL TRAFFI, V17
   Joseph K. J., 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P5826, DOI 10.1109/CVPR46437.2021.00577
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kalyanam J, 2017, ADDICT BEHAV, V65, P289, DOI 10.1016/j.addbeh.2016.08.019
   Kaplan C, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107468
   Karatzas D, 2011, PROC INT CONF DOC, P1485, DOI 10.1109/ICDAR.2011.295
   Kaur J., 2021, 3 INT C INN TRENDS E, P92
   Kaur J, 2022, MULTIMED TOOLS APPL, V81, P38297, DOI 10.1007/s11042-022-13153-y
   Kaur RP, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03687-8
   Khan A, 2018, IEEE T CYBERNETICS, V48, P187, DOI 10.1109/TCYB.2016.2628161
   Kilic E, 2019, INT J REMOTE SENS, V40, P4193, DOI 10.1080/01431161.2018.1562260
   Kim Y, 2022, IET IMAGE PROCESS, V16, P958, DOI 10.1049/ipr2.12159
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Kousik N, 2021, EXPERT SYST APPL, V166, DOI 10.1016/j.eswa.2020.114064
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulik Sergey, 2020, Procedia Computer Science, P164, DOI 10.1016/j.procs.2020.02.129
   Kumar Ashwani, 2020, Procedia Computer Science, V171, P2610, DOI 10.1016/j.procs.2020.04.283
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Kuznetsova Anna, 2020, Advances in Neural Networks - ISNN 2020. 17th International Symposium on Neural Networks, ISNN 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12557), P233, DOI 10.1007/978-3-030-64221-1_20
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lam D, 2018, ARXIV
   Laroca R, 2021, IET INTELL TRANSP SY, V15, P483, DOI 10.1049/itr2.12030
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Learned-Miller E, 2010, FDDB BENCHMARK FACE
   Lee DH, 2021, MULTIMED TOOLS APPL, V80, P34237, DOI 10.1007/s11042-020-09924-0
   Leira FS, 2021, J FIELD ROBOT, V38, P242, DOI 10.1002/rob.21985
   Leksut JT, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103912
   Li B, 2021, CHINESE J AERONAUT, V34, P145, DOI 10.1016/j.cja.2020.09.022
   Li C., 2022, ARXIV
   Li CY, 2020, NEUROCOMPUTING, V415, P411, DOI 10.1016/j.neucom.2020.05.108
   Li GJ, 2021, IET IMAGE PROCESS, V15, P1998, DOI 10.1049/ipr2.12171
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li X, 2020, NEED MORE SPECIFIC J, P185
   Li X, 2020, INT J REMOTE SENS, V41, P7327, DOI 10.1080/01431161.2020.1757782
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li YS, 2018, ISPRS J PHOTOGRAMM, V146, P182, DOI 10.1016/j.isprsjprs.2018.09.014
   Li YD, 2020, CHINESE J AERONAUT, V33, P1747, DOI 10.1016/j.cja.2020.02.024
   Li Z, 2018, DETNET BACKBONE NETW, P1
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409
   Liao JJ, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-021-00056-3
   Lin ML, 2019, ICDLT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON DEEP LEARNING TECHNOLOGIES, P42, DOI 10.1145/3342999.3343013
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu JJ, 2023, IEEE T PATTERN ANAL, V45, P887, DOI 10.1109/TPAMI.2021.3140168
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2021, NEUROCOMPUTING, V428, P92, DOI 10.1016/j.neucom.2020.11.022
   Liu Y, 2022, INT J REMOTE SENS, V43, P270, DOI 10.1080/01431161.2021.2018146
   Liu YL, 2019, PATTERN RECOGN, V90, P337, DOI 10.1016/j.patcog.2019.02.002
   Liu ZK, 2016, IEEE GEOSCI REMOTE S, V13, P1074, DOI 10.1109/LGRS.2016.2565705
   Liu ZW, 2017, IEEE I CONF COMP VIS, P4473, DOI [10.1109/ICCVW.2017.361, 10.1109/ICCV.2017.478]
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Lu SY, 2019, COMPUT ELECTR ENG, V77, P398, DOI 10.1016/j.compeleceng.2019.05.009
   Lu WX, 2019, PROC CVPR IEEE, P6382, DOI 10.1109/CVPR.2019.00655
   Lu XC, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3052575
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Luo XP, 2019, IET INTELL TRANSP SY, V13, P1011, DOI 10.1049/iet-its.2018.5489
   Lv X., 2021, Microprocessors and Microsystems
   Ma CX, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107684
   Ma JL, 2022, IET CONTROL THEORY A, V16, P1, DOI [10.1049/cth2.12191, 10.1109/TMM.2022.3162115]
   Ma WC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107149
   Maeda H, 2021, COMPUT-AIDED CIV INF, V36, P47, DOI 10.1111/mice.12561
   Mahmoud HAH, 2021, PERS UBIQUIT COMPUT, V25, P129, DOI 10.1007/s00779-020-01419-x
   Majumdar P, 2019, IEEE COMPUT SOC CONF, P11, DOI 10.1109/CVPRW.2019.00008
   Mao JF, 2019, SYST SCI CONTROL ENG, V7, P243, DOI 10.1080/21642583.2019.1647576
   Masita Katleho L., 2022, Proceedings of Sixth International Congress on Information and Communication Technology: ICICT 2021. Lecture Notes in Networks and Systems (216), P1, DOI 10.1007/978-981-16-1781-2_1
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Mehedi Shamrat F. M. Javed, 2021, Proceedings of the 5th International Conference on Trends in Electronics and Informatics (ICOEI 2021), P760, DOI 10.1109/ICOEI51242.2021.9452896
   Miao Cheng, 2020, 2020 IEEE 5th International Conference on Image, Vision and Computing (ICIVC), P11, DOI 10.1109/ICIVC50857.2020.9177437
   Mishra A., 2012, P BRIT MACH VIS C 20, V127, P1
   Misra I, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2886, DOI 10.1109/ICCV48922.2021.00290
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Mittal U, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS FOR COMPUTING RESEARCH (ICAICR '19), DOI 10.1145/3339311.3339357
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Murdock M, 2015, PROC INT CONF DOC, P1171, DOI 10.1109/ICDAR.2015.7333945
   Nada H, 2018, INT CONF BIOMETR THE
   Naiemi F, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114549
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Natarajan S, 2018, IET INTELL TRANSP SY, V12, P1396, DOI 10.1049/iet-its.2018.5171
   Neumann L, 2019, LECT NOTES COMPUT SC, V11361, P691, DOI 10.1007/978-3-030-20887-5_43
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Ogura R, 2020, ELECTR COMMUN JPN, V103, P35, DOI 10.1002/ecj.12268
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Ota K, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3092831
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Padilla R, 2020, INT CONF SYST SIGNAL, P237, DOI [10.1109/IWSSIP48289.2020.9145130, 10.1109/iwssip48289.2020.9145130]
   Pang YW, 2021, IEEE T IMAGE PROCESS, V30, P207, DOI 10.1109/TIP.2020.3034487
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pathak Ajeet Ram, 2018, Procedia Computer Science, V132, P1706, DOI 10.1016/j.procs.2018.05.144
   Pérez-Hernández F, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105590
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pouyanfar S, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3234150
   Qi Q, 2018, PROCEEDINGS OF 2018 10TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING (ICMLC 2018), P193, DOI 10.1145/3195106.3195120
   Qijing Huang, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P206, DOI 10.1145/3431920.3439295
   Qin SX, 2022, NEURAL COMPUT APPL, V34, P21551, DOI 10.1007/s00521-021-06147-8
   Qiu ZB, 2022, IET GENER TRANSM DIS, V16, P869, DOI 10.1049/gtd2.12333
   Rahman Md Mahfujur, 2021, Proceedings of International Conference on Trends in Computational and Cognitive Engineering. Proceedings of TCCE 2020. Advances in Intelligent Systems and Computing (AISC 1309), P581, DOI 10.1007/978-981-33-4673-4_47
   Rahman MM, 2020, IEEE T IMAGE PROCESS, V29, P2947, DOI 10.1109/TIP.2019.2955239
   Rahmaniar W., 2021, J ROBOTICS CONTROL J, V2, P462, DOI [10.18196/jrc.26123, DOI 10.18196/JRC.26123]
   Ramzi M, 2019, ACM INT C P SER, DOI [10.1145/3341325.3341999, DOI 10.1145/3341325.3341999]
   Ravishankar V, 2022, SENSOR INTEGRATION F, P759, DOI DOI 10.1007/978-981-16-6407-6_65
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rehman ZU, 2020, MED HYPOTHESES, V141, DOI 10.1016/j.mehy.2020.109705
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Renu Chebrolu Koti Naga, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0838, DOI 10.1109/ICCSP.2019.8698101
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Rukhovich D, 2022, IEEE WINT CONF APPL, P1265, DOI 10.1109/WACV51458.2022.00133
   Sabu K, 2021, COMPUT SPEECH LANG, V68, DOI 10.1016/j.csl.2021.101200
   Sahiner B, 2019, MED PHYS, V46, pe1, DOI 10.1002/mp.13264
   Sai Srinath Namburi Gnvv Satya, 2020, Procedia Computer Science, V171, P207, DOI 10.1016/j.procs.2020.04.022
   Saleh K, 2021, 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2021), P477, DOI 10.1109/SAMI50585.2021.9378657
   Schöller FET, 2019, IFAC PAPERSONLINE, V52, P64, DOI 10.1016/j.ifacol.2019.12.284
   Sermanet P, 2014, 2 INT C LEARN REPRES
   Setta Showmik, 2022, Data Management, Analytics and Innovation: Proceedings of ICDMAI 2021. Lecture Notes on Data Engineering and Communications Technologies (71), P505, DOI 10.1007/978-981-16-2937-2_32
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shao ZF, 2022, IEEE T MULTIMEDIA, V24, P2069, DOI 10.1109/TMM.2021.3075566
   Sharma N, 2015, PROC INT CONF DOC, P1196, DOI 10.1109/ICDAR.2015.7333950
   Sharma VK, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100301
   Sharma VK, 2022, J KING SAUD UNIV-COM, V34, P1687, DOI 10.1016/j.jksuci.2019.09.012
   Shashirangana J, 2022, INT J INTELL SYST, V37, P10211, DOI 10.1002/int.22471
   Shen ZY, 2019, IMAGE VISION COMPUT, V85, P14, DOI 10.1016/j.imavis.2019.03.004
   Shepley AJ, 2023, IEEE T PATTERN ANAL, V45, P11561, DOI 10.1109/TPAMI.2023.3273210
   Shi XP, 2018, PROC CVPR IEEE, P2295, DOI 10.1109/CVPR.2018.00244
   Shi Y, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2019.102740
   Shrivastava A., 2016, Beyond skip connections: Top-down modulation for object detection
   Shyu M, 2020, STRAD RES, V7, DOI [10.37896/sr7.8/037, DOI 10.37896/SR7.8/037]
   Siebert FW, 2020, ACCIDENT ANAL PREV, V134, DOI 10.1016/j.aap.2019.105319
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2018, PROCEDIA COMPUT SCI, V143, P536, DOI 10.1016/j.procs.2018.10.427
   Smolensky P., 1986, Information processing in dynamical systems: Foundations of harmony theory
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Song XB, 2019, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2019.00560
   Su H, 2019, INT GEOSCI REMOTE SE, P1454, DOI [10.1109/igarss.2019.8898573, 10.1109/IGARSS.2019.8898573]
   Sun F, 2021, EUR J REMOTE SENS, V54, P102, DOI 10.1080/22797254.2021.1880975
   Sun K., 2019, HIGH RESOLUTION REPR
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Sun P, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104036
   Sun SY, 2018, CAAI T INTELL TECHNO, V3, P191, DOI 10.1049/trit.2018.1026
   Sun X, 2021, ISPRS J PHOTOGRAMM, V173, P50, DOI 10.1016/j.isprsjprs.2020.12.015
   Suzuki T, 2020, IEEJ T ELECTR ELECTR, V15, P1448, DOI 10.1002/tee.23215
   Tamilselvi M, 2022, ALEX ENG J, V61, P4307, DOI 10.1016/j.aej.2021.09.043
   Tan M., 2019, arXiv
   Tang S, 2020, AUTOMAT CONSTR, V120, DOI 10.1016/j.autcon.2020.103356
   Tanner F, 2009, P IEEE APPL IM PATT, P1, DOI DOI 10.1109/AIPR.2009.5466304
   Tarchoun B, 2020, 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP'2020), DOI 10.1109/atsip49331.2020.9231712
   Taskiran M, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102809
   Terven J, 2023, COMPREHENSIVE REV YO, P1
   Tran TH, 2021, IEEE ICCE 2020: 2020 IEEE EIGHTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P262, DOI 10.1109/ICCE48956.2021.9352140
   Tian ZZ, 2020, REMOTE SENS LETT, V11, P416, DOI 10.1080/2150704X.2020.1722330
   Timofte R, 2014, MACH VISION APPL, V25, P633, DOI 10.1007/s00138-011-0391-3
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Tran P., 2021, The 19th International Conference on Computer Analysis of Images and Patterns (CAIP), P252
   Triantafyllidou D, 2018, BIG DATA RES, V11, P65, DOI 10.1016/j.bdr.2017.06.002
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Umer S, 2022, J AMB INTEL HUM COMP, V13, P721, DOI 10.1007/s12652-020-02845-8
   Phung VH, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214500
   Van Nhan Nguyen, 2019, IEEE Power and Energy Technology Systems Journal, V6, P11, DOI 10.1109/JPETS.2018.2881429
   Vandersteegen M, 2018, LECT NOTES COMPUT SC, V10882, P419, DOI 10.1007/978-3-319-93000-8_47
   Vashisht M, 2020, 2020 INT C COMPUT SC, DOI [10.1109/ICCSEA49143.2020.9132871, DOI 10.1109/ICCSEA49143.2020.9132871]
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Vennelakanti A, 2019, I SYMP CONSUM ELECTR
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Vuola AO, 2019, I S BIOMED IMAGING, P208, DOI [10.1109/isbi.2019.8759574, 10.1109/ISBI.2019.8759574]
   Wallace AM, 2021, IET RADAR SONAR NAV, V15, P359, DOI 10.1049/rsn2.12042
   Wan SH, 2021, IEEE T INTELL TRANSP, V22, P4487, DOI 10.1109/TITS.2020.3017505
   Wang C., 2020, ARXIV
   Wang C.-Y., 2022, YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors, P1
   Wang GB, 2022, IET IMAGE PROCESS, V16, P145, DOI 10.1049/ipr2.12340
   Wang HP, 2019, PROCEEDINGS OF 2019 IEEE 3RD INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC 2019), P2366, DOI [10.1109/ITNEC.2019.8729355, 10.1109/itnec.2019.8729355]
   Wang HY, 2022, EUR J REMOTE SENS, V55, P71, DOI 10.1080/22797254.2021.2018944
   Wang HC, 2019, PROCEEDINGS OF 2019 2ND INTERNATIONAL CONFERENCE ON BIG DATA TECHNOLOGIES (ICBDT 2019), P149, DOI 10.1145/3358528.3358574
   Wang J, 2017, FUNCTIONAL ECOLOGY, P1, DOI [10.1109/ICOCN.2017.8121187, DOI 10.1002/jcla.22185]
   Wang JF, 2021, PROC CVPR IEEE, P15844, DOI 10.1109/CVPR46437.2021.01559
   Wang J, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3466780
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wang N, 2022, CONTROL ENG PRACT, V118, DOI 10.1016/j.conengprac.2020.104458
   Wang Q, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107340
   Wang Q, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4675
   Wang R, 2019, SIGNAL PROCESS-IMAGE, V70, P145, DOI 10.1016/j.image.2018.09.013
   Wang SD, 2017, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON ROBOTICS, CONTROL AND AUTOMATION (ICRCA 2017), P50, DOI 10.1145/3141166.3141168
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WH, 2019, PROC CVPR IEEE, P9328, DOI 10.1109/CVPR.2019.00956
   Wang WH, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103986
   Wang ZQ, 2017, CHIN CONTR CONF, P11104, DOI 10.23919/ChiCC.2017.8029130
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wenbo Lan, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1547, DOI 10.1109/ICMA.2018.8484698
   Westberg S., 2018, arXiv preprint arXiv:1803.01164, DOI DOI 10.48550/ARXIV.1803.01164
   Wong FK, 2019, IET COMPUT VIS, V13, P742, DOI 10.1049/iet-cvi.2018.5654
   Wozniak M, 2018, NEUROCOMPUTING, V320, P76, DOI 10.1016/j.neucom.2018.09.003
   Wu CS, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622838
   Wu JJ, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108214
   Wu JL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2012, DOI 10.1145/3394171.3413634
   Wu KJ, 2021, IEEE ACCESS, V9, P113889, DOI 10.1109/ACCESS.2021.3103522
   Wu SX, 2018, INT SYM COMPUT INTEL, P280, DOI 10.1109/ISCID.2018.00070
   Wu SJ, 2023, INTERACT LEARN ENVIR, V31, P2351, DOI 10.1080/10494820.2021.1881799
   Wu YN, 2021, IET COMPUT VIS, V15, P36, DOI 10.1049/cvi2.12015
   Wu YH, 2021, IEEE T IMAGE PROCESS, V30, P3113, DOI 10.1109/TIP.2021.3058783
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xiao B, 2021, AUTOMAT CONSTR, V127, DOI 10.1016/j.autcon.2021.103721
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xiao YX, 2020, IEEE ACCESS, V8, P123075, DOI 10.1109/ACCESS.2020.3007610
   Xing JC, 2019, IEEE SYMP COMP COMMU, P174, DOI 10.1109/iscc47284.2019.8969595
   Xiong SH, 2021, IET GENER TRANSM DIS, V15, P1578, DOI 10.1049/gtd2.12088
   Xu BB, 2022, COMPUT ELECTRON AGR, V193, DOI 10.1016/j.compag.2021.106675
   Xu D, 2017, PROC CVPR IEEE, P4236, DOI 10.1109/CVPR.2017.451
   Xu H, 2022, IEEE T INTELL TRANSP, V23, P19760, DOI 10.1109/TITS.2021.3137253
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Xu XL, 2021, ACM T SENSOR NETWORK, V17, DOI 10.1145/3447032
   Xu YJ, 2019, IEEE I CONF COMP VIS, P9136, DOI 10.1109/ICCV.2019.00923
   Xue CH, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108494
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Yang HB, 2021, MICROSYST TECHNOL, V27, P1837, DOI 10.1007/s00542-019-04694-8
   Yang S, 2017, FACE DETECTION SCALE
   Yang S, 2018, IEEE T PATTERN ANAL, V40, P1845, DOI 10.1109/TPAMI.2017.2738644
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Yang TF, 2020, CHIN CONTR CONF, P7247, DOI 10.23919/CCC50068.2020.9188580
   Yang W, 2021, IET IMAGE PROCESS, V15, P57, DOI 10.1049/ipr2.12005
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yao L., 2019, P ACM TUR CEL C CHIN, DOI [10.1145/3321408.3322628, DOI 10.1145/3321408.3322628]
   Yi JR, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102827
   Yifan Lu, 2018, Computational Visual Media, V4, P253, DOI 10.1007/s41095-018-0116-x
   Yipeng Sun, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1557, DOI 10.1109/ICDAR.2019.00250
   Yuan J, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2019.107131
   Yuan L, 2018, INT CONF MACH LEARN, P115, DOI 10.1109/ICMLC.2018.8526987
   Yuan Yuan, 2022, Information Processing in Agriculture, P48, DOI [10.1016/j.inpa.2021.01.003, 10.1007/s40789-020-00398-x]
   Yucel MK, 2018, WILDEST FACES FACE D
   Yue YC, 2021, CHINESE J ELECTRON, V30, P931, DOI 10.1049/cje.2021.07.004
   Yuliang L, 2017, DETECTING CURVE TEXT
   Yuxin Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11750, DOI 10.1109/CVPR42600.2020.01177
   Zakria, 2022, IEEE J-STARS, V15, P1039, DOI 10.1109/JSTARS.2022.3140776
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7222, DOI 10.1109/ICCV.2019.00732
   Zhang H, 2019, MULTIMED TOOLS APPL, V78, P27809, DOI 10.1007/s11042-019-07898-2
   Zhang JL, 2020, NEUROCOMPUTING, V380, P180, DOI 10.1016/j.neucom.2019.10.087
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang LB, 2021, IEEE T GEOSCI REMOTE, V59, P9682, DOI 10.1109/TGRS.2020.3045708
   Zhang M, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P667, DOI 10.1145/3474085.3475231
   Zhang Q, 2017, ACM INT C P SER, P99, DOI [10.1145/3163080.3163101, DOI 10.1145/3163080.3163101]
   Zhang SF, 2019, INT J COMPUT VISION, V127, P537, DOI 10.1007/s11263-019-01159-3
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang WS, 2019, PROCEDIA COMPUT SCI, V147, P331, DOI 10.1016/j.procs.2019.01.232
   Zhang WG, 2021, ARTIF INTELL REV, V54, P5633, DOI 10.1007/s10462-021-09967-1
   Zhang X, 2022, NEUROCOMPUTING, V468, P384, DOI 10.1016/j.neucom.2021.10.068
   Zhang XL, 2021, SYST SCI CONTROL ENG, V9, P142, DOI 10.1080/21642583.2020.1824132
   Zhao W, 2019, IEEE ACCESS, V7, P43607, DOI 10.1109/ACCESS.2019.2908016
   Zhao XL, 2021, INT J REMOTE SENS, V42, P5754, DOI 10.1080/01431161.2021.1931537
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zheng Huang, 2019, 2019 International Conference on Document Analysis and Recognition (ICDAR). Proceedings, P1516, DOI 10.1109/ICDAR.2019.00244
   Zhong ZY, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106986
   Zhong ZY, 2019, INT J DOC ANAL RECOG, V22, P315, DOI 10.1007/s10032-019-00335-y
   Zhou P, 2017, IEEE COMPUT SOC CONF, P1831, DOI 10.1109/CVPRW.2017.229
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhu HG, 2015, IEEE IMAGE PROC, P3735, DOI 10.1109/ICIP.2015.7351502
   Zhu HM, 2019, REMOTE SENS LETT, V10, P959, DOI 10.1080/2150704X.2019.1633486
   Zhu YH, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104023
   Zhu YX, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107336
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
   Zou Z, 2019, OBJECT DETECTION 20, P1
   Zou ZX, 2018, IEEE T IMAGE PROCESS, V27, P1100, DOI 10.1109/TIP.2017.2773199
NR 406
TC 4
Z9 5
U1 82
U2 164
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 12253
EP 12338
DI 10.1007/s11042-023-15981-y
EA JUN 2023
PG 86
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000004
DA 2024-07-18
ER

PT J
AU Nigjeh, MP
   Ghanbari, S
AF Nigjeh, Mahnaz Panahandeh
   Ghanbari, Shirin
TI Leveraging ParsBERT for cross-domain polarity sentiment classification
   of Persian social media comments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-domain sentiment analysis; ParsBERT; Pre-trained language model;
   Transformer-based model; Persian multi-domain sentiment dataset
ID STRENGTH DETECTION
AB Sentiment analysis is the computational study of the emotions, attitudes and opinions of humans through the extraction of meaningful information. Social media platforms that allow consumers to share and publish content, are enriched with opinionating information that many analytical researches are currently, however, limited to a specific domain. This research presents an architecture to analyze a limited resource language, Persian language, and focuses on the analysis of social media, consisting of informal comments across different domains. The proposed model applies a transformer-based model, ParsBERT, to classify the sentiments of social media comments. Since social media comments have different domains, it is necessary for the proposed model to classify sentiments of comments in different domains. ParsBERT has been fine-tuned on a Persian corpus that has been generated for the purpose of this study. The generated corpus has been gathered from 28,710 Instagram comments in different topic domains and have been labeled as either negative or positive comments. The proposed model has been evaluated based on different test data belonging to different time-periods and topic domains and results have been compared with recent methods for the task of sentiment analysis for three different scenarios. Results show that when the training and test data are from different domains an accuracy of 68% is achieved, which is higher than other shallow methodologies and deep learning methods for determining the sentiments of social media comments in different domains.
C1 [Nigjeh, Mahnaz Panahandeh] Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
   [Ghanbari, Shirin] IRIB Univ, Dept ICT, Tehran, Iran.
C3 Amirkabir University of Technology
RP Nigjeh, MP (corresponding author), Amirkabir Univ Technol, Dept Comp Engn & Informat Technol, Tehran, Iran.
EM panahandeh1991@gmail.com; s_ghanbari@irib.ir
OI Panahandeh, Mahnaz/0000-0003-4874-794X
CR Akhoundzade R., 2019, 9 INT C COMP KNOWL E, DOI [10.1109/ICCKE48569.2019.8964692, DOI 10.1109/ICCKE48569.2019.8964692]
   Alimardani, 2015, J INF SYST TELECOMMU, V3, P135
   Amiri F., 2015, Proceedings of Recent Advances in Natural Language Processing, Hissar, P9
   [Anonymous], 2013, 21 IR C EL ENG ICEE, DOI DOI 10.1109/IRANIANCEE.2013.6599671
   Asgarian E, 2018, COGN COMPUT, V10, P117, DOI 10.1007/s12559-017-9513-1
   Basiri ME, 2020, J INF SCI, V46, P101, DOI 10.1177/0165551519827886
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Dashtipour K., 2021, Progresses in Artificial Intelligence and Neural Systems, P207
   Dashtipour K, 2020, LECT NOTES ARTIF INT, V11691, P497, DOI 10.1007/978-3-030-39431-8_48
   Dashtipour K, 2020, NEUROCOMPUTING, V380, P1, DOI 10.1016/j.neucom.2019.10.009
   Dastgheib MB., 2020, INT J INF SCI MANAG, V18, P1
   Dehdarbehbahani I, 2014, NEURAL NETWORKS, V58, P50, DOI 10.1016/j.neunet.2014.05.018
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Farahani M, 2021, NEURAL PROCESS LETT, V53, P3831, DOI 10.1007/s11063-021-10528-4
   Ghasemi R, 2022, J INF SCI, V48, P449, DOI 10.1177/0165551520962781
   He HY, 2022, SOFT COMPUT, V26, P10789, DOI 10.1007/s00500-022-06993-1
   Heidari M, 2020, 2020 6TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P284, DOI [10.1109/icwr49608.2020.9122270, 10.1109/ICWR49608.2020.9122270]
   Instagram, INST REP
   Jafarian Hamoon, 2021, 2021 7th International Conference on Web Research (ICWR), P5, DOI 10.1109/ICWR51868.2021.9443131
   Mohtaj S, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P1112
   Momtazi S, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1215
   Nezjiad ZB, 2019, IIUM ENG J, V20, P129, DOI 10.31436/iiumej.v20i1.1036
   Peters M, 2018, STUD LATEINAMERIKA, V32, P1, DOI 10.5771/9783845286846
   Pouromid M, 2021, 2021 26TH INTERNATIONAL COMPUTER CONFERENCE, COMPUTER SOCIETY OF IRAN (CSICC), DOI 10.1109/CSICC52343.2021.9420569
   Rajabi Z, 2021, COGN COMPUT, V13, P882, DOI 10.1007/s12559-021-09886-x
   Roshanfekr B, 2017, IRAN CONF ELECTR ENG, P1503, DOI 10.1109/IranianCEE.2017.7985281
   Saraee Mohamad, 2013, Natural Language Processing and Information Systems. 18th International Conference on Applications of Natural Language to Information Systems, NLDB 2013. Proceedings: LNCS 7934, P303, DOI 10.1007/978-3-642-38824-8_29
   Seraji M, 2015, ACTA U UPSAL, P45
   Shams M, 2012, AISP 2012, P216, DOI DOI 10.1109/AISP.2012.6313747
   Silapapiphat Piriyarangsan S, 2018, ASIAN POLITICAL SCI, P97, DOI [10.2139/ssrn.3229230, DOI 10.2139/SSRN.3229230]
   Thelwall M, 2012, J AM SOC INF SCI TEC, V63, P163, DOI 10.1002/asi.21662
   Thelwall M, 2010, J AM SOC INF SCI TEC, V61, P2544, DOI 10.1002/asi.21416
   Twitter Inc, 2021, TWITT ANN REP
   Vaswani A, 2017, ADV NEUR IN, V30
   Zhang YB, 2019, INFORM SCIENCES, V477, P55, DOI 10.1016/j.ins.2018.10.030
   Zimbra D, 2018, ACM TRANS MANAG INF, V9, DOI 10.1145/3185045
NR 36
TC 1
Z9 1
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10677
EP 10694
DI 10.1007/s11042-023-16067-5
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000002
DA 2024-07-18
ER

PT J
AU Sharma, SR
   Singh, B
   Kaur, M
AF Sharma, Suvita Rani
   Singh, Birmohan
   Kaur, Manpreet
TI A hybrid encryption model for the hyperspectral images: application to
   hyperspectral medical images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic maps; Decryption; Encryption; Hyperspectral images;
   Metaheuristic optimization algorithm
ID ALGORITHM; CHAOS; OPPOSITION
AB Hyperspectral images collect information across the electromagnetic spectrum and are widely used to recognize signals, identify materials, and find objects. However, the information in a hyperspectral image may be sensitive and must be protected. Therefore, this paper proposes a new information confidentiality model for hyperspectral images. In this model, Self Adaptive Bald Eagle Search (SABES) optimization algorithm is proposed to select the initial and control parameters of the chaos maps to improve the encryption process. A multi-level chaotic system is implemented to enhance the security of the hyperspectral images by increasing the randomness. A circular shift is utilized to secure the proposed model from differential attack. The proposed encryption model is authenticated with various security analyses. The experimental results show that the proposed cryptographic model is secure from different attacks (statistical, differential, noise, and cropping). The performance of the proposed model is validated by comparing the results of the proposed model with the state-of-the-art methods. The results prove that the proposed model is more secure and requires less computational time for image encryption and decryption in comparison to the existing methods. In addition, the proposed encryption model is applied to secure the hyperspectral medical images, demonstrating its utility in the medical field.
C1 [Sharma, Suvita Rani; Singh, Birmohan] St Longowal Inst Engn & Technol, Dept Comp Sci & Engn, Longowal 148106, Punjab, India.
   [Kaur, Manpreet] St Longowal Inst Engn & Technol, Dept Elect & Instrumentat Engn, Longowal 148106, Punjab, India.
C3 Sant Longowal Institute of Engineering & Technology (SLIET); Sant
   Longowal Institute of Engineering & Technology (SLIET)
RP Singh, B (corresponding author), St Longowal Inst Engn & Technol, Dept Comp Sci & Engn, Longowal 148106, Punjab, India.
EM suvita.sharma1204@gmail.com; birmohans@gmail.com; aneja_mpk@yahoo.com
RI Kaur, Manpreet/HJZ-4398-2023
OI Singh, Birmohan/0000-0001-6345-5537; Sharma, Suvita
   Rani/0000-0003-2131-6912
CR Abbas SZ, 2021, MULTIMED TOOLS APPL, V80, P26069, DOI 10.1007/s11042-021-10898-w
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   AlKhodaidi T, 2021, MULTIMED TOOLS APPL, V80, P1143, DOI 10.1007/s11042-020-09720-w
   Alsattar HA, 2020, ARTIF INTELL REV, V53, P2237, DOI 10.1007/s10462-019-09732-5
   Amina Souyah, 2018, Communications in Nonlinear Science and Numerical Simulation, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Bin Muhaya FT, 2013, TELECOMMUN SYST, V52, P573, DOI 10.1007/s11235-011-9462-z
   Cataltas O, 2017, 2017 INT ART INT DAT, P1, DOI [10.1109/IDAP.2017.8090342, DOI 10.1109/IDAP.2017.8090342]
   Chatterjee A, 2006, COMPUT OPER RES, V33, P859, DOI 10.1016/j.cor.2004.08.012
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cui DL, 2013, 2013 8TH INTERNATIONAL ICST CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P552, DOI 10.1109/ChinaCom.2013.6694656
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P94, DOI 10.1109/CEC.2001.934376
   El-Abd M, 2011, GECCO-2011: PROCEEDINGS OF THE 13TH ANNUAL GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P109
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Geng WH, 2018, LECT NOTES COMPUT SC, V10736, P890, DOI 10.1007/978-3-319-77383-4_87
   Haleem Abid, 2021, Sens Int, V2, P100117, DOI 10.1016/j.sintl.2021.100117
   Han L, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P624
   Hu XC, 2020, IEEE ACCESS, V8, P12452, DOI 10.1109/ACCESS.2020.2965740
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kamal ST, 2021, IEEE ACCESS, V9, P37855, DOI 10.1109/ACCESS.2021.3063237
   Kang LL, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106038
   Karakis R, 2015, SIG PROCESS COMMUN, P272, DOI 10.1109/SIU.2015.7129812
   Kishore PVV, 2014, 2014 FIRST INTERNATIONAL CONFERENCE ON NETWORKS & SOFT COMPUTING (ICNSC), P258, DOI 10.1109/CNSC.2014.6906662
   Kocarev L., 2001, IEEE Circuits and Systems Magazine, V1, P6, DOI 10.1109/7384.963463
   Kumar S, 2020, ENG OPTIMIZ, V52, P303, DOI 10.1080/0305215X.2019.1585832
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Muthu JS, 2021, SN COMPUT SCI, V2, DOI [10.1007/s42979-021-00778-3, DOI 10.1007/S42979-021-00778-3]
   Rahnamayan S, 2008, APPL SOFT COMPUT, V8, P906, DOI 10.1016/j.asoc.2007.07.010
   Rahnamayan S, 2008, IEEE T EVOLUT COMPUT, V12, P64, DOI 10.1109/TEVC.2007.894200
   Ravichandran D, 2021, MED BIOL ENG COMPUT, V59, P589, DOI 10.1007/s11517-021-02328-8
   Roy PK, 2014, INT J ELEC POWER, V57, P392, DOI 10.1016/j.ijepes.2013.12.006
   Salim MZ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010136
   Sharif A, 2017, MULTIMED TOOLS APPL, V76, P7849, DOI 10.1007/s11042-016-3398-y
   Srujana Oruganti Sai, 2020, 2020 Third ISEA Conference on Security and Privacy (ISEA-ISAP), P94, DOI 10.1109/ISEA-ISAP49340.2020.235006
   Suneja K, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P693, DOI [10.1109/ICCMC.2019.8819860, 10.1109/iccmc.2019.8819860]
   Tavazoei MS, 2007, APPL MATH COMPUT, V187, P1076, DOI 10.1016/j.amc.2006.09.087
   Usama M, 2010, COMPUT MATH APPL, V60, P326, DOI 10.1016/j.camwa.2009.12.033
   Ventresca M, 2010, APPL SOFT COMPUT, V10, P956, DOI 10.1016/j.asoc.2009.07.009
   Villa C., 2016, INT J LEGAL MED, P1
   Villaseñor C, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8071183
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang XY, 2021, OPT LASER ENG, V137, DOI 10.1016/j.optlaseng.2020.106393
   Wang XY, 2021, MULTIMED TOOLS APPL, V80, P591, DOI 10.1007/s11042-020-09688-7
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Xu YL, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.104966
   Ye GD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/8402578
   Yousif B, 2020, AIP ADV, V10, DOI 10.1063/5.0009225
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Yuan ZH, 2021, VISUAL COMPUT, V37, P1867, DOI 10.1007/s00371-020-01945-y
   Zeghid M, 2007, PROC WRLD ACAD SCI E, V21, P206
   Zhang Q, 2019, IEEE ACCESS, V7, P149414, DOI 10.1109/ACCESS.2019.2947470
   Zhang YP, 2009, IEEE SYS MAN CYBERN, P474, DOI 10.1109/ICSMC.2009.5346839
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu HG, 2021, MATH COMPUT SIMULAT, V185, P754, DOI 10.1016/j.matcom.2021.02.009
NR 58
TC 2
Z9 2
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11717
EP 11743
DI 10.1007/s11042-023-15587-4
EA JUN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019116600010
DA 2024-07-18
ER

PT J
AU Ajith, VS
   Jolly, KG
AF Ajith, V. S.
   Jolly, K. G.
TI Hybrid deep learning for object detection in drone imagery: a new
   metaheuristic based model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE African Vulture Updated Honey Badger Optimization (AVUHBO); Bi-GRU
   (Bidirectional Gated Recurrent Neural Network); Drone imagery; Hybrid
   deep learning model; LSTM (Long Short Term Memory); Region-based
   Convolution Neural Network (RCNN)SIFT (scale-invariant feature
   transform); LGBP (Local Gabor binary pattern)
ID OPTIMIZATION
AB It is a challenging problem and a little-researched subject that has recently gotten increased attention in the scientific community to identify items on drone footage. The shooting height and angle change when using a drone because the camera's position is not fixed during the shot, in addition to the weather and lighting circumstances. Offering a hybrid deep learning model for object detection that can aid in search and rescue operations is the goal of this research. The three working stages of this unique technique are pre-processing, feature extraction, and object recognition. First, the videos are turned into image frames, and then an improved region-based convolution neural network was used to detect objects in those frames (RCNN). Consequently, improved LGBP (Local Gabor Binary Pattern) features were also recovered from those images together with traditional ResNet and SIFT (scale-invariant feature transform) features. In the object recognition phase, the proposed African Vulture Updated Honey Badger Optimization (AVUHBO) will be applied to optimize the weight parameters of hybrid neural networks such as Bi-GRU and LSTM for object recognition based on the retrieved features. This optimization model boosts the classifier's performance to produce better results. In contrast to other approaches, our suggested AVUHBO achieves higher accuracy ratings of 0.91, 0.9, 0.91, and 0.9, while SHO only manages lower accuracy ratings of 0.84, 0.85, 0.87, and 0.88. This proves that our proposed AVUHBO can provide accurate object detection. The findings of the proposed object detection methodology are then compared to those of other existing techniques.
C1 [Ajith, V. S.] Jawaharlal Coll Engn & Technol, NSS Coll Engn, Dept Mech Engn, Palakkad, Kerala, India.
   [Jolly, K. G.] APJ Abdul Kalam Technol Univ, NSS Coll Engn, Dept Mech Engn, Palakkad, Kerala, India.
C3 NSS College of Engineering Palakkad; NSS College of Engineering Palakkad
RP Ajith, VS (corresponding author), Jawaharlal Coll Engn & Technol, NSS Coll Engn, Dept Mech Engn, Palakkad, Kerala, India.
EM vsajith981@gmail.com
RI V S, Ajith/ACG-8316-2022
OI V S, Ajith/0000-0001-5602-2995
CR Abdollahzadeh B, 2021, COMPUT IND ENG, V158, DOI 10.1016/j.cie.2021.107408
   Ajith V., 2021, J PHYS C SER, V2115, DOI DOI 10.1088/1742-6596/2115/1/012020
   Ajith VS, 2023, CYBERNET SYST, V54, P1397, DOI 10.1080/01969722.2022.2157607
   Cao YR, 2021, IEEE INT CONF COMP V, P2847, DOI 10.1109/ICCVW54120.2021.00319
   Dilshad N, 2020, I C INF COMM TECH CO, P728, DOI 10.1109/ICTC49870.2020.9289536
   Dousai Nayee Muddin Khan, 2021, APIT 2021: 2021 3rd Asia Pacific Information Technology Conference, P69, DOI 10.1145/3449365.3449377
   El habchi Ali, 2022, E3S Web of Conferences, V351, DOI 10.1051/e3sconf/202235101035
   Forkan ARM, 2022, EXPERT SYST APPL, V193, DOI 10.1016/j.eswa.2021.116461
   Fu R, 2016, 2016 31ST YOUTH ACADEMIC ANNUAL CONFERENCE OF CHINESE ASSOCIATION OF AUTOMATION (YAC), P324, DOI 10.1109/YAC.2016.7804912
   Gasienica-Jozkowy J, 2021, INTEGR COMPUT-AID E, V28, P221, DOI 10.3233/ICA-210649
   Hashim FA, 2022, MATH COMPUT SIMULAT, V192, P84, DOI 10.1016/j.matcom.2021.08.013
   Hou XY, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083547
   Huang YC, 2022, AAAI CONF ARTIF INTE, P1026
   Kalinov I, 2020, IEEE ROBOT AUTOM LET, V5, P6647, DOI 10.1109/LRA.2020.3010733
   Lee DH, 2021, MULTIMED TOOLS APPL, V80, P34237, DOI 10.1007/s11042-020-09924-0
   Li PP, 2020, ISPRS INT J GEO-INF, V9, DOI 10.3390/ijgi9110635
   Liu BY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13061198
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Montazeri A., 2021, Unmanned Aerial Systems, P47
   Sarwinda D, 2021, PROCEDIA COMPUT SCI, V179, P423, DOI 10.1016/j.procs.2021.01.025
   Sun CF, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/4013647
   Treneska S., 2021, P 18 INT C INF INF T, P6
   Walambe R, 2021, DRONES-BASEL, V5, DOI 10.3390/drones5030066
   Wan JF, 2021, IEEE INT CONF COMP V, P2820, DOI 10.1109/ICCVW54120.2021.00316
   Wang SG, 2022, IEEE ACCESS, V10, P40743, DOI 10.1109/ACCESS.2022.3166986
   Wen FQ, 2020, SIGNAL PROCESS, V173, DOI 10.1016/j.sigpro.2020.107512
   Zhang WC, 2007, INT J IMAGE GRAPH, V7, P777, DOI 10.1142/S021946780700291X
   Zhang ZL, 2020, INSECTS, V11, DOI 10.3390/insects11090565
   Zhang ZX, 2021, IEEE INT CONF COMP V, P2799, DOI 10.1109/ICCVW54120.2021.00314
   Zhu PF, 2019, IEEE INT CONF COMP V, P227, DOI 10.1109/ICCVW.2019.00031
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
NR 31
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8551
EP 8589
DI 10.1007/s11042-023-15785-0
EA JUN 2023
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000008
DA 2024-07-18
ER

PT J
AU Paul, B
   Bera, S
   Dey, T
   Phadikar, S
AF Paul, Bachchu
   Bera, Somnath
   Dey, Tanushree
   Phadikar, Santanu
TI Machine learning approach of speech emotions recognition using feature
   fusion technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature fusion; Speech emotion recognition (SER); Mel frequency cepstral
   coefficients; Linear predictive coefficients; Support vector machine;
   Linear discriminative analysis
ID FEATURE-SELECTION; SYSTEM
AB In advancement of machine learning aspect, speech based emotional states identification must have a profound impact on artificial intelligence. Proper feature selection performs a vital role on such emotion recognition. Therefore, feature fusion technology has been proposed in this study for obtaining high prediction accuracy by prioritizing the extraction of sole features. Mel Frequency Cepstral Coefficients (MFCC), Linear Predictive Coefficients (LPC), energy, Zero Crossing Rate (ZCR) and pitch are extracted and four different models are constructed for experimenting the impact of feature fusion techniques on four standard machine learning classifier namely Support Vector Machine (SVM), Linear Discriminative Analysis (LDA), Decision-Tree (D-Tree) and K Nearest Neighbour (KNN). Successful application of feature fusion techniques on our proposed classifiers give satisfactory recognition rate 96.90% on the Bengali (Indian Regional language) based dataset SUST Bangla Emotional Speech Corpus (SUBESCO), 99.82% on Toronto Emotional Speech Set (TESS) (English), 95% on Ryerson Audio-Visual Database for Emotional Speech and Song (RAVDEES) (English) and 95.33% on Berlin Database of Emotional Speech (EMO-DB) (Berlin) dataset. The presented model indicates that the proper fusion of features has a positive impact on emotion detection systems by increasing their accuracy and applicability.
C1 [Paul, Bachchu; Bera, Somnath; Dey, Tanushree] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, West Bengal, India.
   [Phadikar, Santanu] Maulana Abul Kalam Azad Univ Technol, Dept Comp Sci, Nadia 741249, West Bengal, India.
C3 Vidyasagar University; Maulana Abul Kalam Azad University of Technology
RP Bera, S (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, West Bengal, India.
EM ableb.paul@gmail.com; somnathh.beraa@gmail.com; deytanu87@gmail.com;
   sphadikar@yahoo.com
CR Aggarwal A, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062378
   Ancilin J, 2021, APPL ACOUST, V179, DOI 10.1016/j.apacoust.2021.108046
   [Anonymous], 2012, INT J COMPUT SCI INF
   Basu S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P109, DOI 10.1109/ICICCT.2017.7975169
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Chen LJ, 2012, DIGIT SIGNAL PROCESS, V22, P1154, DOI 10.1016/j.dsp.2012.05.007
   Choudhury AR, 2018, PROCEEDINGS OF 2018 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON), P257, DOI 10.1109/ASPCON.2018.8748626
   Dhar P, 2021, INT J MOL SCI, V7, P26, DOI [10.5815/ijmsc.2021.01.04, DOI 10.5815/IJMSC.2021.01.04]
   Dupuis Kate, 2011, Canadian Acoustics, V39, P182
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Esmaileyan Z, 2014, INT J ENG-IRAN, V27, P79, DOI 10.5829/idosi.ije.2014.27.01a.11
   Ingale Ashish B, 2012, International Journal of Soft Computing and Engineering (IJSCE), V2, P235
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Kim HK, 2000, IEEE T SPEECH AUDI P, V8, P195, DOI 10.1109/89.824705
   Koduru A, 2020, INT J SPEECH TECHNOL, V23, P45, DOI 10.1007/s10772-020-09672-4
   Koolagudi SG, 2012, INT J SPEECH TECHNOL, V15, P495, DOI 10.1007/s10772-012-9150-8
   Kuchibhotla S, 2016, INT J SPEECH TECHNOL, V19, P657, DOI 10.1007/s10772-016-9358-0
   Kumaran U, 2021, INT J SPEECH TECHNOL, V24, P303, DOI 10.1007/s10772-020-09792-x
   Lanjewar RB, 2015, PROCEDIA COMPUT SCI, V49, P50, DOI 10.1016/j.procs.2015.04.226
   Livi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193508
   Nwe TL, 2003, SPEECH COMMUN, V41, P603, DOI 10.1016/S0167-6393(03)00099-2
   Ooi CS, 2014, EXPERT SYST APPL, V41, P5858, DOI 10.1016/j.eswa.2014.03.026
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Palo HK., 2018, INT J ENG TECHNOL, V7, P111
   Pan Yixiong, 2012, International Journal of Smart Home, V6, P101, DOI DOI 10.5120/431-636
   Rong J, 2009, INFORM PROCESS MANAG, V45, P315, DOI 10.1016/j.ipm.2008.09.003
   Shah RD, 2007, INT J INNOV RES COMP, DOI [10.15680/IJIRCCE.2016.0403004, DOI 10.15680/IJIRCCE.2016.0403004]
   Shambhavi S., 2015, INT J ENG RES TECHNO, V4, P1067, DOI DOI 10.17577/IJERTV4IS060932
   Slimi A, 2020, MOMM 2020: THE 18TH INTERNATIONAL CONFERENCE ON ADVANCES IN MOBILE COMPUTING & MULTIMEDIA, P35, DOI 10.1145/3428690.3429153
   Sultana S, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250173
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wu SQ, 2011, SPEECH COMMUN, V53, P768, DOI 10.1016/j.specom.2010.08.013
   Xu MK, 2021, IEEE ACCESS, V9, P74539, DOI 10.1109/ACCESS.2021.3067460
   Yang B, 2010, SIGNAL PROCESS, V90, P1415, DOI 10.1016/j.sigpro.2009.09.009
NR 34
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8663
EP 8688
DI 10.1007/s11042-023-16036-y
EA JUN 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001014975000002
DA 2024-07-18
ER

PT J
AU Cheng, KY
   Meng, CY
   Ma, GJ
   Zhan, YZ
AF Cheng, Keyang
   Meng, Chunyun
   Ma, Guojian
   Zhan, Yongzhao
TI β-CLVAE: a semantic disentangled generative model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variational auto-encoder; Contrastive learning; Gram matrix;
   Disentangled representation
AB Learning disentangled representations from data that reveal inherent semantic information is crucial for the interpretability of generative models such as Variational Auto-Encoders (VAEs) and Generative Adversarial Networks (GANs). However, finding a balance between disentanglement and generation is challenging. The traditional disentangled model, beta-VAE, often fails to reconstruct clear images. To address this issue, we propose a novel contrastive learning method called beta-CLVAE that enhances the generation ability and improves the disentanglement of beta-VAE. In our method, we use a Recurrent Neural Network (RNN) to generate robust anchor samples that are fed, along with the reconstructions from beta-VAE, to a contrastive learning framework. We also introduce a pixel-level Gram matrix that imposes constraints on the input and output images to improve the quality of the decoder's reconstruction. By using contrastive learning, beta-CLVAE can learn valuable semantic information that benefits disentangled and generative representations. Our experiments demonstrate the advantages of our model in terms of qualitative comparison of disentangled features, quantitative comparison of disentanglement scores, and the accuracy of downstream classification tasks. Overall, beta-CLVAE is an excellent semantic disentangled representation model that is beneficial for downstream tasks.
C1 [Cheng, Keyang; Meng, Chunyun; Zhan, Yongzhao] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
   [Meng, Chunyun] Jiangsu Univ Sci & Technol, Sch Econ & Management, Zhenjiang, Peoples R China.
   [Ma, Guojian] Jiangsu Univ, Sch Management, Zhenjiang, Peoples R China.
C3 Jiangsu University; Jiangsu University of Science & Technology; Jiangsu
   University
RP Cheng, KY (corresponding author), Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Peoples R China.
EM kycheng@ujs.edu.cn; cymeng@stu.just.edu.cn; gjma@ujs.edu.cn;
   yzzhan@ujs.edu.cn
FU National Natural Science Foundation of China [61972183]
FX AcknowledgementsThis research is supported by National Natural Science
   Foundation of China (No.61972183).
CR Achille A, 2018, ARXIV
   Bouchacourt D, 2018, AAAI CONF ARTIF INTE, P2095
   Bukchin G, 2021, PROC CVPR IEEE, P8726, DOI 10.1109/CVPR46437.2021.00862
   Burgess C., 2018, arXiv
   Caselles-Dupre H., 2019, Advances in Neural Information Processing Systems, V32, P4606
   Chartsias A, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101535
   Chen H, 2020, IEEE T IMAGE PROCESS, V29, P8407, DOI 10.1109/TIP.2020.3014734
   Chen RT, 2018, ARXIV
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Conde MV, 2021, IEEE COMPUT SOC CONF, P3951, DOI 10.1109/CVPRW53098.2021.00444
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Gatys L. A., 2015, arXiv
   Heuillet A, 2021, KNOWL-BASED SYST, V214, DOI 10.1016/j.knosys.2020.106685
   Higgins I., 2016, BETA VAE LEARNING BA
   Higgins I., 2018, ARXIV
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hjelm R. D., 2018, ARXIV
   Jing LL, 2021, IEEE T PATTERN ANAL, V43, P4037, DOI 10.1109/TPAMI.2020.2992393
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kansal K, 2020, IEEE T CIRC SYST VID, V30, P3422, DOI 10.1109/TCSVT.2019.2963721
   Kim H, 2018, PR MACH LEARN RES, V80
   Kingma DP, 2013, ARXIV
   Li BY, 2021, PROC CVPR IEEE, P12378, DOI 10.1109/CVPR46437.2021.01220
   Li XY, 2021, AAAI CONF ARTIF INTE, V35, P1966
   Li Y, 2019, INFORM SCIENCES, V482, P73, DOI 10.1016/j.ins.2018.12.057
   Lin Z., 2020, INT C MACHINE LEARNI, V119, P6127
   Locatello F, 2019, PR MACH LEARN RES, V97
   Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018
   Majumdar A, 2009, INT CONF ACOUST SPEE, P861, DOI 10.1109/ICASSP.2009.4959720
   Mita G, 2021, PR MACH LEARN RES, V139
   Mnih A., 2013, Advances in Neural Information Processing Systems, V26, P2265
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saeed A, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P3875, DOI 10.1109/ICASSP39728.2021.9413528
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   vandenOord Aaron, 2018, ARXIV180703748
   Verma V., 2021, INT C MACHINE LEARNI, P10530
   Wang GQ, 2020, PROC CVPR IEEE, P6677, DOI 10.1109/CVPR42600.2020.00671
   Wang P, 2021, PROC CVPR IEEE, P943, DOI 10.1109/CVPR46437.2021.00100
   Wonkwang Lee, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P157, DOI 10.1007/978-3-030-58574-7_10
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13306, DOI 10.1109/CVPR42600.2020.01332
   Xu H, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3056645
   Ye Z, 2021, IEEE T MULTIMEDIA
   Zhang H, 2020, IEEE T INTELL TRANSP
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang ZY, 2019, PROC CVPR IEEE, P4705, DOI 10.1109/CVPR.2019.00484
NR 47
TC 0
Z9 0
U1 5
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8517
EP 8532
DI 10.1007/s11042-023-15833-9
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001010496600002
DA 2024-07-18
ER

PT J
AU Xie, XL
   Zhao, WJ
   Luo, CY
   Cui, L
AF Xie, Xinlin
   Zhao, Wenjing
   Luo, Chenyan
   Cui, Lei
TI Weakly supervised semantic segmentation with segments and neighborhood
   classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Image-level labels; Segments; Neighborhood
   classifiers; Weakly supervised
AB Semantic segmentation can provide basic semantic information for scene understanding, which has important theoretical research value and broad application prospects. Limited by the labeling cost and the scale of training data, weakly supervised semantic segmentation based on image-level labels has become a potential research issue. However, how to infer the location of image-level labels is a tough problem. Therefore, we propose a weakly-supervised semantic segmentation method with segments and neighborhood classifiers. First, we propose a scheme of segment generation based on the multiple of the number of image-level labels, which can provide high-precision boundary information with fewer regions. Second, to improve the precision of label location inference, we propose an inference method based on the most similar neighborhood granule. It can appropriately determine the number of segments contained in the inferred category label. Finally, we construct a decision table with features as conditional attribute and semantic label as decision attribute, and extract the discriminative features from attribute class reduction for neighborhood classifiers learning. Experiments evidence that our proposed algorithm can produce comparable and competitive results on widely-used MRSC and PASCAL VOC 2012 datasets.
C1 [Xie, Xinlin; Luo, Chenyan; Cui, Lei] Taiyuan Univ Sci & Technol, Sch Elect & Informat Engn, Taiyuan 030024, Peoples R China.
   [Xie, Xinlin; Luo, Chenyan; Cui, Lei] Shanxi Key Lab Adv Control & Equipment Intelligenc, Taiyuan 030024, Peoples R China.
   [Zhao, Wenjing] Taiyuan Univ Technol, Coll Elect & Power Engn, Taiyuan 030024, Peoples R China.
C3 Taiyuan University of Science & Technology; Taiyuan University of
   Technology
RP Xie, XL (corresponding author), Taiyuan Univ Sci & Technol, Sch Elect & Informat Engn, Taiyuan 030024, Peoples R China.; Xie, XL (corresponding author), Shanxi Key Lab Adv Control & Equipment Intelligenc, Taiyuan 030024, Peoples R China.
EM xiexinlin@tyust.edu.cn
RI CHEN, BING/KHX-6659-2024; Li, Zexi/KFA-6939-2024; Lu, Xin/KHW-8570-2024;
   Liu, Jiacheng/KHX-5326-2024
OI Lu, Xin/0000-0001-9885-6031; Liu, Jiacheng/0000-0002-0518-3577
CR Araslanov N, 2020, PROC CVPR IEEE, P4252, DOI 10.1109/CVPR42600.2020.00431
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan RC, 2018, LECT NOTES COMPUT SC, V11213, P371, DOI 10.1007/978-3-030-01240-3_23
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Hong YF, 2023, MULTIMED TOOLS APPL, V82, P6829, DOI 10.1007/s11042-022-13606-4
   Hu QH, 2008, EXPERT SYST APPL, V34, P866, DOI 10.1016/j.eswa.2006.10.043
   Huang ZL, 2018, PROC CVPR IEEE, P7014, DOI 10.1109/CVPR.2018.00733
   Kho S, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108953
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541
   Li Y, 2020, NEUROCOMPUTING, V391, P25, DOI 10.1016/j.neucom.2020.01.054
   Li Y, 2017, IEEE T SYST MAN CY-S, V47, P648, DOI 10.1109/TSMC.2016.2623683
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Liu Y, 2015, MULTIMED TOOLS APPL, V74, P543, DOI 10.1007/s11042-014-1967-5
   Liu Y, 2013, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR.2013.270
   Lu ZW, 2017, IEEE T PATTERN ANAL, V39, P486, DOI 10.1109/TPAMI.2016.2552172
   Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Pourian N, 2015, IEEE I CONF COMP VIS, P1359, DOI 10.1109/ICCV.2015.160
   Qi XJ, 2016, LECT NOTES COMPUT SC, V9912, P90, DOI 10.1007/978-3-319-46484-8_6
   Redondo-Cabrera C, 2019, IEEE T IMAGE PROCESS, V28, P3649, DOI 10.1109/TIP.2019.2901393
   Ru LX, 2022, PROC CVPR IEEE, P16825, DOI 10.1109/CVPR52688.2022.01634
   Saleh FS, 2018, IEEE T PATTERN ANAL, V40, P1382, DOI 10.1109/TPAMI.2017.2713785
   Shi ZY, 2017, IEEE T PATTERN ANAL, V39, P2525, DOI 10.1109/TPAMI.2016.2645157
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Vezhnevets A, 2012, PROC CVPR IEEE, P3162, DOI 10.1109/CVPR.2012.6248050
   Wang X, 2020, INT J COMPUT VISION, V128, P1736, DOI 10.1007/s11263-020-01293-3
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wu T, 2021, PROC CVPR IEEE, P16760, DOI 10.1109/CVPR46437.2021.01649
   Xu J, 2015, PROC CVPR IEEE, P3781, DOI 10.1109/CVPR.2015.7299002
   Xu J, 2014, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2014.408
   Xu Leiyang, 2022, IECON 2022 - 48th Annual Conference of the IEEE Industrial Electronics Society, P1, DOI 10.1109/IECON49645.2022.9968781
   Yao YZ, 2021, PROC CVPR IEEE, P2623, DOI 10.1109/CVPR46437.2021.00265
   Yu-Ting Chang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8988, DOI 10.1109/CVPR42600.2020.00901
   Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229
   Zeng Y, 2019, IEEE I CONF COMP VIS, P7222, DOI 10.1109/ICCV.2019.00732
   Zhang K., 2013, P 23 INT JOINT C ART, P1889
   Zhang W, 2015, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2015.7298888
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou L, 2021, IEEE T MULTIMEDIA, V23, P1035, DOI 10.1109/TMM.2020.2991592
NR 43
TC 0
Z9 0
U1 12
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 8311
EP 8330
DI 10.1007/s11042-023-15983-w
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001009946800001
DA 2024-07-18
ER

PT J
AU Wang, SB
   Yuan, WT
   Zhang, Z
   Wang, L
AF Wang, Shengbei
   Yuan, Weitao
   Zhang, Zhen
   Wang, Lin
TI Speech watermarking based tamper detection and recovery scheme with high
   tolerable tamper rate
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech watermarking; Tamper detection; Tamper recovery; Speech
   authentication
ID FRAGILE IMAGE WATERMARKING; AUDIO WATERMARKING; AUTHENTICATION;
   ALGORITHM
AB Speech watermarking has been widely used for tamper detection and recovery. In this paper, we propose a speech watermarking based tamper detection and recovery method after analyzing the characteristics of continuous and discontinuous tamper. The authentication watermarks and recovery watermarks are embedded into the original speech using align embedding and misalign embedding strategies, respectively. In particular, the misalign embedding strategy which distributes the recovery watermarks repeatedly and widely can effectively prevent the speech segment and its recovery watermarks from being tampered simultaneously, which significantly increases the tolerable tamper rate (TTR) of the proposed method. Several experiments concerning inaudibility, recovery rate, sound quality of recovered speech, and recovery percentage were carried out to evaluate the proposed method. The obtained results suggested that the proposed method had good inaudibility. Moreover, it could tolerate high tamper rate (around 50%) and provide satisfactory recovery rate (100%) and speech quality (PESQ & GE; 3.0 ODG and LSD & LE; 1.0 dB) under continuous tamper (for N & GE; 6). Similarly, it could recovery most of the speech after discontinuous tamper even under high tamper rate. These results verified the effectiveness of the proposed method.
C1 [Wang, Shengbei; Yuan, Weitao; Zhang, Zhen] Tiangong Univ, Tianjin Key Lab Autonomous Intelligence Technol &, Tianjin 300387, Peoples R China.
   [Wang, Lin] Techfantasy Co Ltd, Tianjin 300387, Peoples R China.
C3 Tiangong University
RP Yuan, WT (corresponding author), Tiangong Univ, Tianjin Key Lab Autonomous Intelligence Technol &, Tianjin 300387, Peoples R China.
EM wangshengbei@tiangong.edu.cn; weitaoyuan@tiangong.edu.cn;
   zhenzhang@tiangong.edu.cn; linwang@techfantasy.com.cn
OI Yuan, Weitao/0000-0003-1900-8259
FU National Natural Science Foundation of China [62176182, 62201314,
   61771340]; Natural Science Foundation of Shandong Province
   [ZR2020QF007]; Scientific Research Project of Tianjin Education
   Commission [19PTZWHZ00020]
FX AcknowledgementsThis work was supported in part by the National Natural
   Science Foundation of China (62176182, 62201314, and 61771340), in part
   by the Natural Science Foundation of Shandong Province (ZR2020QF007),
   and in part by the Scientific Research Project of Tianjin Education
   Commission under Grant 19PTZWHZ00020.
CR Dhawan A, 2008, HYBRID AUDIO WATERMA
   Fridrich J., 1999, P 1999 INT C IM PROC, P792, DOI [10.1109/ICIP.1999.817228, DOI 10.1109/ICIP.1999.817228]
   Galajit K, 2019, APSIPA TRANS SIGNAL, V8, DOI 10.1017/ATSIP.2019.4
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   Hoffmann E, 2012, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2012-14
   Hu HT, 2019, IEEE ACCESS, V7, P180395, DOI 10.1109/ACCESS.2019.2958095
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Hua G, 2016, SIGNAL PROCESS, V128, P222, DOI 10.1016/j.sigpro.2016.04.005
   Ito K., 2017, The LJ Speech Dataset
   Kanhe A, 2018, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-018-0139-3
   Karnjana J, 2017, ASIAPAC SIGN INFO PR, P193, DOI 10.1109/APSIPA.2017.8282027
   Lei BY, 2013, IEEE T AUDIO SPEECH, V21, P2368, DOI 10.1109/TASL.2013.2277929
   Li J, 2016, IEEE TRUST BIG, P678, DOI [10.1109/TrustCom.2016.124, 10.1109/TrustCom.2016.0125]
   Lin XD, 2017, DIGIT SIGNAL PROCESS, V60, P63, DOI 10.1016/j.dsp.2016.07.015
   Liu ZH, 2017, MULTIMED TOOLS APPL, V76, P12481, DOI 10.1007/s11042-016-3664-z
   Liu ZH, 2018, LECT NOTES COMPUT SC, V11068, P300, DOI 10.1007/978-3-030-00021-9_28
   Liu ZH, 2016, SIGNAL PROCESS, V123, P157, DOI 10.1016/j.sigpro.2015.10.023
   Lu WH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072390
   Mubeen Z, 2021, COMPUT ELECTR ENG, V91, DOI 10.1016/j.compeleceng.2021.107122
   Nematollahi MA, 2013, INT J SPEECH TECHNOL, V16, P471, DOI 10.1007/s10772-013-9192-6
   Nematollahi MA, 2017, MULTIMED TOOLS APPL, V76, P7251, DOI 10.1007/s11042-016-3350-1
   Podilchuk CI, 2001, IEEE SIGNAL PROC MAG, V18, P33, DOI 10.1109/79.939835
   Qian Q, 2018, TELECOMMUN SYST, V67, P635, DOI 10.1007/s11235-017-0360-x
   Qian Q, 2017, LECT NOTES COMPUT SC, V10082, P46, DOI 10.1007/978-3-319-53465-7_4
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Rakhmawati L, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-019-0462-3
   Rigoni R, 2016, INFORM SCIENCES, V328, P127, DOI 10.1016/j.ins.2015.08.040
   Sarreshtedari S, 2015, IEEE-ACM T AUDIO SPE, V23, P1917, DOI 10.1109/TASLP.2015.2456431
   Sarreshtedari S, 2015, IEEE T IMAGE PROCESS, V24, P2266, DOI 10.1109/TIP.2015.2414878
   Shokri S, 2017, WIRELESS PERS COMMUN, V95, P4457, DOI 10.1007/s11277-017-4095-5
   Unoki, 2017, P 8 INT C INTELLIGEN, P118
   WANG SB, 2019, INT CONF ACOUST SPEE, P2632, DOI DOI 10.1109/icassp.2019.8682352
   Wang SB, 2021, ASIAPAC SIGN INFO PR, P1621
   Wang SB, 2019, SPEECH COMMUN, V112, P1, DOI 10.1016/j.specom.2019.06.004
   Zhang QY, 2021, MULTIMED TOOLS APPL, V80, P24925, DOI 10.1007/s11042-021-10905-0
   Zhu X, 2007, SIGNAL PROCESS-IMAGE, V22, P515, DOI 10.1016/j.image.2007.03.004
NR 36
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6711
EP 6729
DI 10.1007/s11042-023-15580-x
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001012974800005
DA 2024-07-18
ER

PT J
AU Zhai, ML
   Gao, H
   Liu, Y
   Nie, JH
   Ni, K
AF Zhai, Mingliang
   Gao, Hao
   Liu, Ye
   Nie, Jianhui
   Ni, Kang
TI Learning graph-based representations for scene flow estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Scene flow estimation; Graph convolutional networks; 3D
   point cloud; Scene understanding
ID NETWORKS
AB Scene flow estimation is a fundamental task of autonomous driving. Compared with optical flow, scene flow can provide sufficient 3D motion information of the dynamic scene. With the increasing popularity of 3D LiDAR sensors and deep learning technology, 3D LiDAR-based scene flow estimation methods have achieved outstanding results on public benchmarks. Current methods usually adopt Multiple Layer Perceptron (MLP) or traditional convolution-like operation for feature extraction. However, the characteristics of point clouds are not exploited adequately in these methods, and thus some key semantic and geometric structures are not well captured. To address this issue, we propose to introduce graph convolution to exploit the structural features adaptively. In particular, multiple graph-based feature generators and a graph-based flow refinement module are deployed to encode geometric relations among points. Furthermore, residual connections are used in the graph-based feature generator to enhance feature representation and deep supervision of the graph-based network. In addition, to focus on short-term dependencies, we introduce a single gate-based recurrent unit to refine scene flow predictions iteratively. The proposed network is trained on the FlyingThings3D dataset and evaluated on the FlyingThings3D, KITTI, and Argoverse datasets. Comprehensive experiments show that all proposed components contribute to the performance of scene flow estimation, and our method can achieve potential performance compared to the recent approaches.
C1 [Zhai, Mingliang; Gao, Hao; Liu, Ye; Nie, Jianhui] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Jiangsu, Peoples R China.
   [Ni, Kang] Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications
RP Zhai, ML (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210023, Jiangsu, Peoples R China.
EM zhaimingliang@njupt.edu.cn; tsgaohao@gmail.com; yeliu@njupt.edu.cn;
   njh19@njupt.edu.cn; tznikang@163.com
FU Natural Science Foundation of Jiangsu Province of China [BK20210594,
   BK20210588]; Natural Science Foundation for Colleges and Universities in
   Jiangsu Province [21KJB520016, 21KJB520015]; Natural Science Foundation
   of Nanjing University of Posts and Telecommunications [NY221019,
   NY221074]; National Natural Science Foundation of China [61931012,
   61802204, 62101280]
FX AcknowledgementsThis work is sponsored in part by the Natural Science
   Foundation of Jiangsu Province of China (Grant No. BK20210594 and
   BK20210588), in part by the Natural Science Foundation for Colleges and
   Universities in Jiangsu Province (Grant No. 21KJB520016 and
   21KJB520015), in part by the Natural Science Foundation of Nanjing
   University of Posts and Telecommunications (Grant No. NY221019 and
   NY221074), and in part by the National Natural Science Foundation of
   China (Grant No. 61931012, 61802204, and 62101280).
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.482
   Behl A, 2017, IEEE I CONF COMP VIS, P2593, DOI 10.1109/ICCV.2017.281
   Chang MF, 2019, PROC CVPR IEEE, P8740, DOI 10.1109/CVPR.2019.00895
   Chen JT, 2020, PROC CVPR IEEE, P389, DOI 10.1109/CVPR42600.2020.00047
   Dewan A, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1765, DOI 10.1109/IROS.2016.7759282
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Gu XY, 2019, PROC CVPR IEEE, P3249, DOI 10.1109/CVPR.2019.00337
   Hadfield S, 2011, IEEE I CONF COMP VIS, P2290, DOI 10.1109/ICCV.2011.6126509
   Hornácek M, 2014, PROC CVPR IEEE, P3526, DOI 10.1109/CVPR.2014.451
   Huguet F, 2007, IEEE I CONF COMP VIS, P1342, DOI 10.1109/iccv.2007.4409000
   Hur J, 2021, PROC CVPR IEEE, P2683, DOI 10.1109/CVPR46437.2021.00271
   Ilg E, 2018, LECT NOTES COMPUT SC, V11216, P626, DOI 10.1007/978-3-030-01258-8_38
   Jiang HZ, 2019, IEEE I CONF COMP VIS, P3194, DOI 10.1109/ICCV.2019.00329
   Junhwa Hur, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7394, DOI 10.1109/CVPR42600.2020.00742
   Lai HY, 2019, PROC CVPR IEEE, P1890, DOI 10.1109/CVPR.2019.00199
   Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936
   Li Xian, 2021, ADV NEURAL INFORM PR
   Li YS, 2021, IEEE T IMAGE PROCESS, V30, P4540, DOI 10.1109/TIP.2021.3073318
   Lin ZH, 2020, PROC CVPR IEEE, P1797, DOI 10.1109/CVPR42600.2020.00187
   Liu PP, 2020, PROC CVPR IEEE, P6647, DOI 10.1109/CVPR42600.2020.00668
   Liu XY, 2019, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2019.00062
   Luo CX, 2020, IEEE T PATTERN ANAL, V42, P2624, DOI 10.1109/TPAMI.2019.2930258
   Ma WC, 2019, PROC CVPR IEEE, P3609, DOI 10.1109/CVPR.2019.00373
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, ISPRS ANN PHOTO REM, VII-3, P427, DOI 10.5194/isprsannals-II-3-W5-427-2015
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Pan LY, 2020, IEEE T IMAGE PROCESS, V29, P1748, DOI 10.1109/TIP.2019.2945867
   Paszke A, 2019, ADV NEUR IN, V32
   Pillai S, 2017, IEEE INT C INT ROBOT, P5533, DOI 10.1109/IROS.2017.8206441
   Pontes JK, 2020, INT CONF 3D VISION, P261, DOI 10.1109/3DV50981.2020.00036
   Puy Gilles, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P527, DOI 10.1007/978-3-030-58604-1_32
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2021, PROC CVPR IEEE, P6130, DOI 10.1109/CVPR46437.2021.00607
   Quiroga J, 2014, LECT NOTES COMPUT SC, V8695, P567, DOI 10.1007/978-3-319-10584-0_37
   Schuster R, 2020, INT J COMPUT VISION, V128, P527, DOI 10.1007/s11263-019-01258-1
   Shen W, 2021, IEEE C COMP VIS PATT, P10703
   Shi WJ, 2020, PROC CVPR IEEE, P1708, DOI 10.1109/CVPR42600.2020.00178
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Teed Zachary, 2020, EUR C COMP VIS, P402, DOI [DOI 10.1007/978-3-030-58536-524, DOI 10.1007/978-3-030-58536-5_24]
   Tishchenko I, 2020, INT CONF 3D VISION, P150, DOI 10.1109/3DV50981.2020.00025
   Ushani Arash K., 2017, International Conference on Robotics and Automation ICRA, P5666
   Vogel C, 2013, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2013.174
   Wang GM, 2021, IEEE T IMAGE PROCESS, V30, P5168, DOI 10.1109/TIP.2021.3079796
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang ZR, 2020, IEEE WINT CONF APPL, P91, DOI 10.1109/WACV45572.2020.9093302
   Wei Y, 2021, PROC CVPR IEEE, P6950, DOI 10.1109/CVPR46437.2021.00688
   Wu F, 2022, INFORM SCIENCES, V591, P142, DOI 10.1016/j.ins.2022.01.013
   Wu WX, 2019, PROC CVPR IEEE, P9613, DOI 10.1109/CVPR.2019.00985
   Wu Wenxuan, 2020, EUROPEAN C COMPUTER, P88
   Yang GS, 2020, PROC CVPR IEEE, P1331, DOI 10.1109/CVPR42600.2020.00141
   Yin ZC, 2018, PROC CVPR IEEE, P1983, DOI 10.1109/CVPR.2018.00212
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
NR 54
TC 0
Z9 0
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7317
EP 7334
DI 10.1007/s11042-023-15541-4
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001004157400001
DA 2024-07-18
ER

PT J
AU Kerfa, D
AF Kerfa, Djoudi
TI Moving objects detection in thermal scene videos using unsupervised
   Bayesian classifier with bootstrap Gaussian expectation maximization
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Infrared video sequences; Moving object detection; Block matching
   algorithm; Unsupervised bayesian classifier; Gaussian expectation of
   maximization
ID SEARCH ALGORITHM; MOTION ESTIMATION
AB In this paper, a new algorithm for moving object detection is proposed by using unsupervised Bayesian classifier with bootstrap Gaussian expectation maximization algorithm. It consists of the following steps: the first contains of classify and estimate the motion vectors between successive frames using the Star diamond search algorithm based on unsupervised Bayesian classifier with Gaussian Expectation of Maximization algorithm, this step serves also to detect the static and dynamic blocks. In the second step, the dynamic blocks are compensated with the white pixels value and the stationary are compensated by black pixels value. In the third step, the morphological opening and closing filters are used for refining the object detected. The proposed approach is trained and evaluated using available infrared (FLIR_ADAS_v2) dataset. The results demonstrate the effectiveness of the proposed method.
C1 [Kerfa, Djoudi] Natl Polytech Sch Oran Maurice Audin Ex Enset, PB1523, El Mnaouar 31000, Algeria.
RP Kerfa, D (corresponding author), Natl Polytech Sch Oran Maurice Audin Ex Enset, PB1523, El Mnaouar 31000, Algeria.
EM dj.kerfa@yahoo.fr
OI /0000-0002-0615-9464
CR Alam M., 2019, I SYMPOS LOW POWER E, P1, DOI DOI 10.1109/islped.2019.8824907
   Alsaqre FE, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P1856
   Banga C., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P638, DOI 10.1109/ICASSP.1993.319893
   Basher HA, 2011, IEEE SOUTHEASTCON, P384, DOI 10.1109/SECON.2011.5752971
   Boufares O, 2021, INT MULTICONF SYST, P1378, DOI 10.1109/SSD52085.2021.9429516
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Chen BH, 2014, IEEE T MULTIMEDIA, V16, P837, DOI 10.1109/TMM.2014.2298377
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   DEVOS L, 1989, IEEE T CIRCUITS SYST, V36, P1309, DOI 10.1109/31.44347
   Dou JF, 2019, CHIN CONT DECIS CONF, P3576, DOI [10.1109/ccdc.2019.8832900, 10.1109/CCDC.2019.8832900]
   El Rai M. C., 2020, IEEE 27 INT C EL CIR, P1
   Fu Huini, 2022, Proceedings of 2021 Chinese Intelligent Systems Conference. Lecture Notes in Electrical Engineering (803), P811, DOI 10.1007/978-981-16-6328-4_81
   Gangodkar Durgaprasad, 2011, International Journal of Information and Communication Technology, V3, P131, DOI 10.1504/IJICT.2011.041744
   Ghorbel F, 2012, RECENTES AVANCEES RE
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Kerfa D, 2014, COMPUTERS SOFTWARE, V744
   Kerfa D, 2020, MULTIMED TOOLS APPL, V79, P24173, DOI 10.1007/s11042-020-09040-z
   Kerfa D, 2016, MULTIMED TOOLS APPL, V75, P3161, DOI 10.1007/s11042-014-2428-x
   Koga T, 1981, NAT TEL C
   Kurmasha HTR., 2022, INT J ELECT COMPUT E, V12, P2517
   Li CL, 2017, IEEE T CIRC SYST VID, V27, P725, DOI 10.1109/TCSVT.2016.2556586
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu JH, 1997, IEEE T CIRC SYST VID, V7, P429, DOI 10.1109/76.564122
   Manap R. A., 2010, 2010 2nd International Conference on Computer Engineering and Technology (ICCET), P155, DOI 10.1109/ICCET.2010.5485814
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P2447, DOI 10.1007/s11042-018-6353-2
   Pandian S. Immanuel Alex, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P43, DOI 10.1007/978-981-13-1927-3_5
   Pham TT, 2021, 2021 IEEE 11TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P347, DOI 10.1109/CCWC51732.2021.9375959
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Rashed H, 2019, IEEE COMPUT SOC CONF, P364, DOI 10.1109/CVPRW.2019.00049
   Richardson IEG., 2010, H264 MPEG 4 VIDEO CO, V2, DOI [10.1002/9780470989418, DOI 10.1002/9780470989418]
   Rifat Rathyatul, 2019, 3rd International Conference on Electrical, Computer & Telecommunication Engineering (ICECTE 2019), P256, DOI 10.1109/ICECTE48615.2019.9303552
   Saha A, 2018, PERS UBIQUIT COMPUT, V22, P163, DOI 10.1007/s00779-017-1058-5
   Shanableh T, 2013, IEEE T CIRC SYST VID, V23, P1191, DOI 10.1109/TCSVT.2013.2241352
   Sultana M, 2019, MACH VISION APPL, V30, P375, DOI 10.1007/s00138-018-0993-0
   Talal M., 2018, INT C SIGN PESS INF, DOI [10.1109/cspis.2018.8642743, DOI 10.1109/CSPIS.2018.8642743]
   Tezcan MO, 2021, IEEE ACCESS, V9, P53849, DOI 10.1109/ACCESS.2021.3071163
   Tezcan MO, 2020, IEEE WINT CONF APPL, DOI 10.1109/WACV45572.2020.9093464
   Xuzhi Wang, 2010, 2010 Second Asia Pacific Conference on Postgraduate Research in Microelectronics & Electronics (PrimeAsia 2010), P89, DOI 10.1109/PRIMEASIA.2010.5604955
   Yao GL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17091945
   Yasakethu SLP, 2018, MULTIMED TOOLS APPL, V77, P30683, DOI 10.1007/s11042-018-6157-4
   Zha YF, 2019, IEEE ACCESS, V7, P89777, DOI 10.1109/ACCESS.2019.2927211
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao X, 2017, Arxiv, DOI arXiv:1707.07584
   Zhou YF, 2017, 2017 SENSOR DATA FUSION: TRENDS, SOLUTIONS, APPLICATIONS (SDF)
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 48
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15849-1
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OZ4
UT WOS:000995787000008
DA 2024-07-18
ER

PT J
AU Dhole, NV
   Dixit, VV
   Desai, D
AF Dhole, Nandini Vaibhav
   Dixit, Vaibhav V.
   Desai, Drakshyani
TI Detection of brain tumour in multi-modality images using hybrid features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain MRI image; Brain tumor; BraTS 2020; Hybrid DTCWT-WHT; Fuzzy group
   teaching; Adaptive may fly; Gabor filter
ID CLASSIFICATION; SEGMENTATION; FRAMEWORK; CONTRAST; FUSION
AB Brain is recognized as a focal part of nervous system and it is inflated by tumour. Therefore the lifespan among humans gets diminished. The anatomy of brain can be reflected by Magnetic resonance image (MRI) or Computed tomography (CT) image. The accuracy segmentation of brain tumour detection in a multimodality images with inadequate computing resource is a challenging task in a medical field. To take over the provisioned difficulties we proposed a new novel innovative approach. The segmentation process comprises the subsequent footsteps. To wipe out the noise and smoothen image there is a need for a pre-processing. Cross guided bilateral filter (CGBF) technique had introduced for the eradication of noises in multimodality images. In this paper, hybrid dual tree complex wavelet transform with Walsh hadamard transform (Hybrid DTCWT-WHT) and Gabor filter is proposed in order to extract the indispensable hybrid set of features from the respective wavelet transforms. The hybrid DTCWT-WHT approach is used for an accurate identification brain tumour in Multi-Modality brain images. Features are important one for differentiating and deciding the exact class of brain tumour. The proposed hybrid features are used for predicting the presence of brain tumours and helps to segment the brain region correctly. Secondly in this framework, Adaptive mayfly Optimization (AMO) is proposed for the selection of crucial features from the feature vectors and destroys the non-required features. Then the classification purpose is emphasized to categorize tumour and un-tumour images. To efficiently strengthen the segmentation resolution, Fuzzy group teaching (FGT) algorithm is proposed. Proposed scheme is consolidated in Brain Tumour segmentation (BraTS) 2020 dataset to brand a nominal segmentation process. The substantial outcome had been appraised in terms of 98.18%. Accuracy, 95.50% precision, 97.14% Recall, 97.14% F1-Score, 98.66% Specificity, 95.52% Structural similarity index metric (SSIM), 95.12% Universal quality index (UQI), 0.94% Jaccard and 0.97% dice coefficients correspondingly.
C1 [Dhole, Nandini Vaibhav; Desai, Drakshyani] Shri Jagdish Prasad Jhabarmal Tibrewala Univ, Churela 333001, Rajasthan, India.
   [Dixit, Vaibhav V.] RMD Sinhgad Sch Engn, Pune 412209, India.
RP Dhole, NV (corresponding author), Shri Jagdish Prasad Jhabarmal Tibrewala Univ, Churela 333001, Rajasthan, India.
EM nandini.dhole@gmail.com
CR Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Bauer S, 2013, PHYS MED BIOL, V58, pR97, DOI 10.1088/0031-9155/58/13/R97
   Chen BS, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105797
   Chen YP, 2017, EXPERT SYST APPL, V83, P1, DOI 10.1016/j.eswa.2017.04.019
   Corso JJ, 2008, IEEE T MED IMAGING, V27, P629, DOI 10.1109/TMI.2007.912817
   Deepak S, 2021, INT J IMAG SYST TECH, V31, P1655, DOI 10.1002/ima.22543
   Dong H, 2017, COMM COM INF SC, V723, P506, DOI 10.1007/978-3-319-60964-5_44
   Guillemaud R, 1997, IEEE T MED IMAGING, V16, P238, DOI 10.1109/42.585758
   Hafez AI, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)
   Hichem H, 2022, J KING SAUD UNIV-COM, V34, P316, DOI 10.1016/j.jksuci.2019.11.007
   Hussien Abdelazim G., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P79, DOI 10.1007/978-981-10-8863-6_9
   Janani V., 2013, International Journal of Computer Science and Mobile Computing, V2, P244
   Kaplan K, 2020, MED HYPOTHESES, V139, DOI 10.1016/j.mehy.2020.109696
   Kaymak S, 2017, PROCEDIA COMPUT SCI, V120, P126, DOI 10.1016/j.procs.2017.11.219
   Khan MA, 2019, SUST PLANT CROP PRO, P1, DOI [10.1007/978-3-030-23045-6_1, 10.1002/jemt.23238]
   LillyMaheepa P., 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P708, DOI 10.1109/ICCCA49541.2020.9250923
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mou LC, 2017, IEEE T GEOSCI REMOTE, V55, P3639, DOI 10.1109/TGRS.2016.2636241
   Nawaz M, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11101856
   Özyurt F, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109433
   Patel J., 2014, Adv. Electron. Electr. Eng, V4, P279
   Pereira S., 2013, P MICCAI GRAND CHALL
   Prajna Y, 2022, J INTELL FUZZY SYST, P1, DOI DOI 10.3233/JIFS-211479
   Ramakrishna R, 2015, NEUROSURGERY, V77, P175, DOI 10.1227/NEU.0000000000000753
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Schwartzbaum JA, 2006, NAT CLIN PRACT NEURO, V2, P494, DOI 10.1038/ncpneuro0289
   Sehgal V, 2006, J MAGN RESON IMAGING, V24, P41, DOI 10.1002/jmri.20598
   Sharif M, 2020, PATTERN RECOGN LETT, V129, P150, DOI 10.1016/j.patrec.2019.11.017
   Sharif M, 2020, COGN SYST RES, V59, P273, DOI 10.1016/j.cogsys.2019.10.001
   Smoll NR, 2013, J CLIN NEUROSCI, V20, P670, DOI 10.1016/j.jocn.2012.05.040
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Usman K, 2017, PATTERN ANAL APPL, V20, P871, DOI 10.1007/s10044-017-0597-8
   Vijayalakshmi D, 2020, PATTERN RECOGN IMAGE, V30, P691, DOI 10.1134/S1054661820040240
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Wu W, 2014, INT J COMPUT ASS RAD, V9, P241, DOI 10.1007/s11548-013-0922-7
   Wu YZ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P331, DOI 10.1109/ICASSP.2018.8462168
NR 36
TC 0
Z9 0
U1 2
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15667-5
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400008
DA 2024-07-18
ER

PT J
AU Sood, S
   Singh, H
AF Sood, Shivani
   Singh, Harjeet
TI A comparative study of grape crop disease classification using various
   transfer learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Convolutional neural networks; Plant disease detection;
   Grape crop disease classification; Plant disease recognition
ID NEURAL-NETWORKS; DEEP; MODELS
AB Grapes are one of the fruits, which provides a significant source of Vitamin C. Like the other plant diseases, grapes plants are also affected some diseases. In order to protect the grapes crop from such diseases, time-to-time monitoring is required. Moreover, some remedies actions can be used at early stages for disease detection. Hence, it is a challenging task to detect grape leaf diseases in their early stages. In this article, deep Convolutional Neural Networks (CNNs) are used to identify different types of diseases in grape crops. Thereafter, a Gaussian noise features are included during the training, by which an improvement in the training accuracy has been observed. Therefore, an attempt is made to remove overfitting from deep learning model for detecting different grape diseases. Moreover, for training the proposed model, a publicly online available dataset i.e., PlantVillage has been utilized. This dataset is also used for transfer learning or pre-trained CNN models i.e., VGG16, ResNet50, InceptionV3, and DenseNet121. Thereafter, the proposed model results are compared with other transfer learning models. Eventually, the proposed model achieved an accuracy rate of 99.88%, higher than other transfer learning models. This study concludes that adding the Gaussian noise feature during model training contributes in increasing the accuracy of the deep learning model.
C1 [Sood, Shivani; Singh, Harjeet] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Singh, H (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM shivani.sood@chitkara.edu.in; harjeet.singh@chitkara.edu.in
RI Singh, Harjeet/AAE-4215-2020
OI Singh, Harjeet/0000-0002-9760-5166
CR Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Aravind K. R., 2019, Proceedings of the International Conference on ISMAC in Computational Vision and Bio-Engineering 2018 (ISMAC-CVB).Lecture Notes in Computational Vision and Biomechanics (LNCVB 30), P1623, DOI 10.1007/978-3-030-00665-5_150
   Aravind K.R., 2020, Deep Learning for Data Analytics: Foundations, Biomedical Applications, and Challenges, P173, DOI [10.1016/B978-0-12-819764-6.00010-7, DOI 10.1016/B978-0-12-819764-6.00010-7]
   Boufenar C, 2018, COGN SYST RES, V50, P180, DOI 10.1016/j.cogsys.2017.11.002
   Budhouliya R, 2020, ICAART: PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE, VOL 2, P578, DOI 10.5220/0008960005780586
   Cecotti H, 2020, EXPERT SYST APPL, V159, DOI 10.1016/j.eswa.2020.113588
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Es-Saady Y, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL AND INFORMATION TECHNOLOGIES (ICEIT), P561, DOI 10.1109/EITech.2016.7519661
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Gangwar N, 2020, INT RES J ENG TECHNO
   Goyal P, 2019, IEEE I CONF COMP VIS, P6400, DOI 10.1109/ICCV.2019.00649
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaisakthi SM, 2019, 2019 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS 2019), DOI 10.1109/iccids.2019.8862084
   Karimi H, 2020, Arxiv, DOI [arXiv:1912.11460, DOI 10.48550/ARXIV.1912.11460]
   Khaing Zin Thet, 2020, 2020 International Conference on Advanced Information Technologies (ICAIT), P147, DOI 10.1109/ICAIT51105.2020.9261801
   Laurent C, 2016, INT CONF ACOUST SPEE, P2657, DOI 10.1109/ICASSP.2016.7472159
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li Y, 2019, Arxiv, DOI arXiv:1808.05385
   Liu XX, 2019, LANCET DIGIT HEALTH, V1, pE271, DOI 10.1016/S2589-7500(19)30123-2
   Mehmood A, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10020084
   Minoofam SAH., 2021, NASHRIYYAH I MUHANDI, V88, P69
   Minoofam SAH, 2023, IEEE T NEUR NET LEAR, V34, P2480, DOI 10.1109/TNNLS.2021.3106705
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Mugnai L, 1999, PLANT DIS, V83, P404, DOI 10.1094/PDIS.1999.83.5.404
   Owomugisha G, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P158, DOI [10.1109/ICMLA.2016.126, 10.1109/ICMLA.2016.0034]
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Salman S, 2019, Arxiv, DOI arXiv:1901.06566
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Silva C. M. da, 2014, African Journal of Agricultural Research, V9, P3001
   Sood Shivani, 2022, ECS Transactions, V107, P8877, DOI 10.1149/10701.8877ecst
   Sood Shivani, 2021, 2021 2nd International Conference on Smart Electronics and Communication (ICOSEC), P1453, DOI 10.1109/ICOSEC51865.2021.9591759
   Sood Shivani, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1035, DOI 10.1109/ICCMC51019.2021.9418023
   Sood Shivani, 2020, Proceedings of the 3rd International Conference on Intelligent Sustainable Systems (ICISS 2020), P341, DOI 10.1109/ICISS49785.2020.9316123
   Sood S, 2022, RUST DIS CLASSIFICAT
   Sood S, 2021, MULTIMED TOOLS APPL, V80, P27973, DOI 10.1007/s11042-021-11036-2
   Sosnowski MR, 2012, PLANT PATHOL, V61, P1093, DOI 10.1111/j.1365-3059.2012.02595.x
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tang Z, 2020, COMPUT ELECTRON AGR, V178, DOI 10.1016/j.compag.2020.105735
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Xu Q, 2019, NEUROCOMPUTING, V328, P69, DOI 10.1016/j.neucom.2018.03.080
   Yi D, 2010, ADV IMAG ELECT PHYS, V164, P329, DOI 10.1016/S1076.5670(10)64005.0
   Yosinski J, 2014, Arxiv, DOI [arXiv:1411.1792, 10.48550/arXiv.1411.1792]
   Zhang AS, 2022, Arxiv, DOI [arXiv:2106.11342, DOI 10.48550/ARXIV.2106.11342]
   Zhang GD, 2018, Arxiv, DOI arXiv:1810.12281
   Zhu JH, 2020, MULTIMED TOOLS APPL, V79, P14539, DOI 10.1007/s11042-018-7092-0
   Zhu YX, 2019, NEUROCOMPUTING, V365, P191, DOI 10.1016/j.neucom.2019.07.016
NR 50
TC 0
Z9 0
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 24
PY 2023
DI 10.1007/s11042-023-14808-0
EA MAY 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H2CU8
UT WOS:000994104400001
DA 2024-07-18
ER

PT J
AU Bossavit, B
   Fernández-Leiva, AJ
AF Bossavit, Benoit
   Fernandez-Leiva, Antonio J.
TI A scoping review and a taxonomy of the use of motion-based technology
   centered on the end user. A special focus on elderly health
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Motion-based technology; Elderly; Taxonomy; Digital games; Health
ID ACTIVE VIDEO GAMES; NINTENDO WII FIT; CONVENTIONAL PHYSICAL-THERAPY;
   DWELLING OLDER-ADULTS; QUALITY-OF-LIFE; PARKINSONS-DISEASE; FUNCTIONAL
   OUTCOMES; COGNITIVE FUNCTION; IMPROVING BALANCE; POSTURAL BALANCE
AB Motion-based technology (MBT) has been applied in the last decades with enormous success in a high number of applications. Its use continues growing and is specially interesting in the health area. Nowadays, its employment is being more and more specialised with respect to the profile of the end user (i.e., child, adolescent/teenager, adult or elderly). This paper first reviews the use of MBT centered in the end user from a global perspective. It also proposes a taxonomy that allows cataloguing the MBT employment directed to the end user. Then, from these results, the paper centers the review on the MBT application aiming to improve the health of elderly. The results highlighted in this paper can help to a better understanding of MBT, especially when it is applied thinking in elderly as the end users.
C1 [Bossavit, Benoit; Fernandez-Leiva, Antonio J.] Univ Malaga, ITIS, Lenguajes & Ciencias Comp, Malaga, Spain.
C3 Universidad de Malaga
RP Bossavit, B (corresponding author), Univ Malaga, ITIS, Lenguajes & Ciencias Comp, Malaga, Spain.
EM benoit.bossavit@uma.es
RI Fernández-Leiva, Antonio J./M-1265-2014
OI Fernández-Leiva, Antonio J./0000-0002-5330-5217
FU Universidad de Malaga; national project Bio4Res from the Ministerio de
   Ciencia e Innovacion de Espana (MCIN) [PID2021-125184NB-I00];
   Universidad de Malaga/CBUA
FX This study is partially funded by the Universidad de Malaga with the
   national project Bio4Res (PID2021-125184NB-I00) from the Ministerio de
   Ciencia e Innovacion de Espana (MCIN). Funding for open access charge:
   Universidad de Malaga/CBUA.
CR Amjad I, 2019, GAMES HEALTH J, V8, P144, DOI 10.1089/g4h.2018.0029
   Authors' name hidden for review, 2023, LIST REV ART
   Barth J, 2011, IEEE ENG MED BIO, P868, DOI 10.1109/IEMBS.2011.6090226
   Bieryla KA, 2013, CLIN INTERV AGING, V8, P775, DOI 10.2147/CIA.S46164
   Bregler C, 2007, IEEE SIGNAL PROC MAG, V24, P160, DOI 10.1109/MSP.2007.906023
   Bruno B, 2017, 2017 INTERNATIONAL CONFERENCE ON VIRTUAL REHABILITATION (ICVR)
   Cannell J, 2018, CLIN REHABIL, V32, P191, DOI 10.1177/0269215517720790
   Carmichael A, 2010, P 24 BCS INTERACTION, P278
   Costa L, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3891253
   Daniel K, 2012, REHABIL NURS, V37, P195, DOI 10.1002/rnj.25
   Eggenberger P, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00066
   Eggenberger P, 2015, CLIN INTERV AGING, V10, P1335, DOI 10.2147/CIA.S87732
   Feng H, 2019, MED SCI MONITOR, V25, P4186, DOI 10.12659/MSM.916455
   Field M, 2009, IEEE INT CONF CON AU, P1697, DOI 10.1109/ICCA.2009.5410185
   Franco JR, 2012, TECHNOL HEALTH CARE, V20, P95, DOI 10.3233/THC-2011-0661
   Gandolfi M, 2017, BIOMED RES INT, V2017, DOI 10.1155/2017/7962826
   García-Bravo S, 2021, DISABIL REHABIL, V43, P448, DOI 10.1080/09638288.2019.1631892
   Garcia-Lopez H, 2021, BRAIN SCI, V11, DOI 10.3390/brainsci11111435
   Gatica-Rojas Valeska, 2019, J Phys Ther Sci, V31, P1, DOI 10.1589/jpts.31.1
   Gerling Kathrin, 2014, Gerontechnology, V12, P68, DOI 10.4017/gt.2013.12.2.001.00
   Gerling K, 2020, ACM T ACCESS COMPUT, V13, DOI 10.1145/3374660
   Grammatikopoulou A, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P523, DOI 10.1145/3316782.3322757
   Nguyen H, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P3695
   Hickman R, 2017, DEV MED CHILD NEUROL, V59, P903, DOI 10.1111/dmcn.13464
   Hsu YL, 2014, IEEE J BIOMED HEALTH, V18, P1822, DOI 10.1109/JBHI.2014.2325413
   Jorgensen MG, 2013, J GERONTOL A-BIOL, V68, P845, DOI 10.1093/gerona/gls222
   Jung-Lang Yu, 2009, Proceedings of the 2009 Fourth International Conference on Communications and Networking in China. CHINACOM 2009, DOI 10.1109/CHINACOM.2009.5339928
   Kappen DL, 2019, INT J HUM-COMPUT INT, V35, P140, DOI 10.1080/10447318.2018.1441253
   Karahan AY, 2015, CENT EUR J PUBL HEAL, V23, pS14
   Kwok BC, 2016, AGE AGEING, V45, P621, DOI 10.1093/ageing/afw108
   Langhammer B, 2018, BIOMED RES INT-UK, V2018, DOI 10.1155/2018/7856823
   Lee NY, 2015, J PHYS THER SCI, V27, P145, DOI 10.1589/jpts.27.145
   Lee Y, 2017, J AGING PHYS ACTIV, V25, P621, DOI 10.1123/japa.2015-0271
   Li JH, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph182412939
   Li JH, 2018, AGING MENT HEALTH, V22, P1634, DOI 10.1080/13607863.2017.1385722
   Liao YY, 2019, FRONT AGING NEUROSCI, V11, DOI 10.3389/fnagi.2019.00162
   Liao YY, 2015, NEUROREHAB NEURAL RE, V29, P658, DOI 10.1177/1545968314562111
   Maillot P, 2012, PSYCHOL AGING, V27, P589, DOI 10.1037/a0026268
   Mainka S, 2021, MOV DISORD CLIN PRAC, V8, P1240, DOI 10.1002/mdc3.13352
   Marotta N, 2022, DISABIL REHABIL, V44, P331, DOI 10.1080/09638288.2020.1768301
   Martinho D, 2020, ARTIF INTELL REV, V53, P4863, DOI 10.1007/s10462-020-09809-6
   Maya RD, 2021, P INT C SYST EN ENV, P151, DOI [10.2139/ssrn.3791097, DOI 10.2139/SSRN.3791097]
   Medeiros Pamella de, 2017, Rev Paul Pediatr, V35, P464, DOI 10.1590/1984-0462/;2017;35;4;00013
   Menolotto M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195687
   Micarelli A, 2019, ARCH GERONTOL GERIAT, V83, P246, DOI 10.1016/j.archger.2019.05.008
   Mirelman A, 2016, LANCET, V388, P1170, DOI 10.1016/S0140-6736(16)31325-3
   Mogle J, 2013, PERSPECTIVES COGNITI, P49
   Monteiro RS, 2017, AGING CLIN EXP RES, V29, P387, DOI 10.1007/s40520-016-0595-5
   Montero-Alía P, 2019, AGE AGEING, V48, P506, DOI 10.1093/ageing/afz047
   Moschny A, 2011, INT J BEHAV NUTR PHY, V8, DOI 10.1186/1479-5868-8-121
   Moyle W, 2018, MATURITAS, V110, P10, DOI 10.1016/j.maturitas.2018.01.007
   Negrini S, 2017, J BODYW MOV THER, V21, P117, DOI 10.1016/j.jbmt.2016.06.001
   Norris E, 2016, J PEDIATR-US, V172, P40, DOI 10.1016/j.jpeds.2016.02.001
   Ordnung M, 2017, FRONT HUM NEUROSCI, V11, DOI 10.3389/fnhum.2017.00160
   Page M. J., 2021, BMJ (clinical Research Ed.), V88, DOI [10.1136/bmj.n71, DOI 10.1136/BMJ.N71, 10.1016/j.ijsu.2021.105906]
   Page ZE, 2017, J SCI MED SPORT, V20, P1087, DOI 10.1016/j.jsams.2017.05.001
   Pelosin E, 2020, J GERONTOL A-BIOL, V75, P722, DOI 10.1093/gerona/glz072
   Peng W, 2013, HEALTH EDUC BEHAV, V40, P171, DOI 10.1177/1090198112444956
   Pils K, 2016, WIEN MED WOCHENSCHR, V166, P44, DOI 10.1007/s10354-015-0420-3
   Pluchino A, 2012, ARCH PHYS MED REHAB, V93, P1138, DOI 10.1016/j.apmr.2012.01.023
   Ranasinghe DC, 2013, 2013 5TH IEEE INTERNATIONAL WORKSHOP ON ADVANCES IN SENSORS AND INTERFACES (IWASI), P224, DOI 10.1109/IWASI.2013.6576067
   Rendon AA, 2012, AGE AGEING, V41, P549, DOI 10.1093/ageing/afs053
   Bacha JMR, 2018, GAMES HEALTH J, V7, P24, DOI 10.1089/g4h.2017.0065
   Rica RL, 2020, GERIATR GERONTOL INT, V20, P195, DOI 10.1111/ggi.13857
   Rice M., 2011, P 2011 ACM SIGGRAPH, P17, DOI [10.1145/2018556.2018560, DOI 10.1145/2018556.2018560]
   Rosly MM, 2017, DISABIL REHABIL, V39, P727, DOI 10.3109/09638288.2016.1161086
   Santos P, 2019, NEUROREHABILITATION, V45, P255, DOI 10.3233/NRE-192771
   Sápi M, 2019, GAMES HEALTH J, V8, P41, DOI 10.1089/g4h.2018.0027
   Sato K, 2015, GAMES HEALTH J, V4, P161, DOI 10.1089/g4h.2014.0057
   Schättin A, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnag.2016.00278
   Schoene D, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057734
   Schwenk M, 2014, GERONTOLOGY, V60, P483, DOI 10.1159/000363136
   Seaborn K, 2015, INT J HUM-COMPUT ST, V74, P14, DOI 10.1016/j.ijhcs.2014.09.006
   Singh DKA, 2013, CLIMACTERIC, V16, P141, DOI 10.3109/13697137.2012.664832
   Singh DKA, 2012, MATURITAS, V73, P239, DOI 10.1016/j.maturitas.2012.07.011
   Singh I, 2016, CHALLENGES IN ELDER CARE, P37, DOI 10.5772/64294
   Smeddinck JD, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P4143, DOI 10.1145/2702123.2702598
   Song J, 2018, CLIN REHABIL, V32, P299, DOI 10.1177/0269215517721593
   Tarnanas Ioannis, 2013, 2013 International Conference on Virtual Rehabilitation (ICVR), P27, DOI 10.1109/ICVR.2013.6662099
   Tarnanas I, 2013, JMIR SERIOUS GAMES, V1, P16, DOI 10.2196/games.2778
   Thapa N, 2020, J CLIN MED, V9, DOI 10.3390/jcm9051283
   Uzor S, 2019, ACM T COMPUT-HUM INT, V26, DOI 10.1145/3325280
   Gomes GCV, 2018, MATURITAS, V118, P20, DOI 10.1016/j.maturitas.2018.10.002
   Whyatt C, 2015, GAMES HEALTH J, V4, P423, DOI 10.1089/g4h.2015.0006
   Wilkinson P, 1997, AGE AGEING, V26, P53, DOI 10.1093/ageing/26.1.53
   Xu WG, 2020, GAMES HEALTH J, V9, P389, DOI 10.1089/g4h.2019.0130
   Yang WC, 2016, J FORMOS MED ASSOC, V115, P734, DOI 10.1016/j.jfma.2015.07.012
   Yuqi Liu, 2020, HCI International 2020 - Late Breaking Papers. Universal Access and Inclusive Design. 22nd HCI International Conference, HCII 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12426), P608, DOI 10.1007/978-3-030-60149-2_46
   Zadro JR, 2019, PHYS THER, V99, P14, DOI 10.1093/ptj/pzy112
   Zhao YN, 2020, JMIR SERIOUS GAMES, V8, DOI 10.2196/16841
   Zheng JY, 2022, CLIN GERONTOLOGIST, V45, P1034, DOI 10.1080/07317115.2021.1980170
   Zheng LF, 2020, AGING CLIN EXP RES, V32, P2187, DOI 10.1007/s40520-019-01344-x
   Zhu W, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P121, DOI 10.1145/2982142.2982156
   Zhu XD, 2016, PROCEEDINGS OF 2016 10TH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P522, DOI 10.1109/CISIS.2016.134
NR 94
TC 0
Z9 0
U1 3
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 20
PY 2023
DI 10.1007/s11042-023-15185-4
EA MAY 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H0OU4
UT WOS:000993050400001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Nigam, R
   Jain, S
   Sharma, DK
AF Nigam, Ritu
   Jain, Satbir
   Sharma, Deepak Kumar
TI RF-BBFT: a random forest based multimedia big data routing technique for
   social opportunistic IoT networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Direct bonding; Intelligent techniques; IoT; Machine learning;
   Multimedia big data routing; Opportunistic IoT networks; Random Forest
ID PROTOCOL; INTERNET
AB Opportunistic Routing (OR) is an emerging and promising data communication technique in social Opportunistic IoT networks (social OppIoTs). The OR becomes more critical if data is multimedia big data (MBD) produced from multidimensional distributed mobile nodes. The research work carried out in this paper suggests an intelligent routing mechanism named RF-BBFT, which uses Machine Learning (ML) algorithm, namely, random forest (RF), to make smart routing decisions. The RF model is trained by utilizing traits like direct bonding metrics, node popularity, power consumption within a node, speed, and node location. Simulation results conducted through the ONE simulator demonstrate that RF-BBFT performs substantially better than BBFT concerning the successful transmissions, average latency, and average buffer time. The proposed RF-BBFT outperforms BBFT and MLProph by 14.69% and 15.42% respectively, in terms of the delivery success rate.
C1 [Nigam, Ritu; Jain, Satbir] Netaji Subhas Univ Technol, Dept Comp Engn, New Delhi, India.
   [Sharma, Deepak Kumar] Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Delhi, India.
C3 Netaji Subhas University of Technology; Indira Gandhi Delhi Technical
   University for Women (IGDTUW)
RP Sharma, DK (corresponding author), Indira Gandhi Delhi Tech Univ Women, Dept Informat Technol, Delhi, India.
EM ritu.nigam2106@gmail.com; jain_satbir@yahoo.com; dk.sharma1982@yahoo.com
OI Sharma, Deepak Kumar/0000-0001-6117-3464
CR Aneja M.J. S., 2018, Handbook of Research on Network Forensics and Analysis Techniques, P87, DOI DOI 10.4018/978-1-5225-4100-4.CH006
   [Anonymous], 1994, XIPH ORG VIDEO TEST, V3
   Bansal A, 2019, J AMB INTEL HUM COMP, V10, P2235, DOI 10.1007/s12652-018-0815-2
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Boldrini C, 2007, I S WORLD WIREL MOBI, P78
   Borrego C, 2019, COMPUT COMMUN, V137, P81, DOI 10.1016/j.comcom.2019.02.003
   Chen J, 2009, P 1 AS HIM INT C INT, P1, DOI [10.1109/AHICI.2009.5340292, DOI 10.1109/AHICI.2009.5340292]
   Ciobanu R-I, 2014, BIG DATA INTERNET TH, P3
   Conti M, 2010, IEEE COMMUN MAG, V48, P126, DOI 10.1109/MCOM.2010.5560597
   Cuka M, 2019, J AMB INTEL HUM COMP, V10, P519, DOI 10.1007/s12652-017-0676-0
   Duan YQ, 2019, INT J INFORM MANAGE, V48, P63, DOI 10.1016/j.ijinfomgt.2019.01.021
   Guo B., 2012, P 16 INT C COMP SUPP, V2012, P925, DOI DOI 10.1109/CSCWD.2012.6221932
   Guo B, 2013, J NETW COMPUT APPL, V36, P1531, DOI 10.1016/j.jnca.2012.12.028
   Gupta A., 2017, P INT C HIGH PERF CO, P121
   Gupta R., 2018, HDB E BUSINESS SECUR, P341, DOI [10.1201/9780429468254-14, DOI 10.1201/9780429468254]
   Holmes G., 1994, Proceedings of the 1994 Second Australian and New Zealand Conference on Intelligent Information Systems (Cat. No.94TH8019), P357, DOI 10.1109/ANZIIS.1994.396988
   Keranen A., 2009, P 2 INT C SIM TOOLS, P1, DOI 10.4108/ICST.SIMUTOOLS2009.5674
   Lindgren A., 2003, Probabilistic routing in intermittently connected networks, V7, P19, DOI DOI 10.1145/961268.961272
   Liu KH, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10080074
   Liu KH, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10080338
   Mtibaa A, 2010, IEEE INFOCOM SER
   Nigam R, 2019, SCALABLE COMPUT-PRAC, V20, P1, DOI 10.12694/scpe.v20i1.1469
   NN S, 2020, INTERNET THINGS, V11
   Sharma DK, 2018, IEEE SYST J, V12, P2207, DOI 10.1109/JSYST.2016.2630923
   Sharma DK, 2020, WIREL NETW, V26, P4319, DOI 10.1007/s11276-020-02331-1
   Sharma DK, 2019, J AMB INTEL HUM COMP, V10, P1289, DOI 10.1007/s12652-018-0697-3
   Sharma Deepak Kumar, 2017, 2017 10 INT C CONT C, P1, DOI [10.1109/IC3.2017.8284342, DOI 10.1109/IC3.2017.8284342]
   Singh A, 2020, MULTIMEDIA BIG DATA, V163, DOI [10.1007/978-981-13-8759-3_17, DOI 10.1007/978-981-13-8759-3_17]
   Sinha A, 2019, SUSTAIN COMPUT-INFOR, V23, P88, DOI 10.1016/j.suscom.2019.07.001
   Srinidhi N, 2021, J INF TECHNOL MANAG, V13, P68
   Suresh H, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATION SYSTEM AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTIONS (CSITSS), P80, DOI 10.1109/CSITSS.2016.7779444
   Team JV, JOINT SCAL VID MOD J
   Usama M, 2019, IEEE ACCESS, V7, P65579, DOI 10.1109/ACCESS.2019.2916648
   Vahdat A., 2000, EPIDEMIC ROUTING PAR
   Vashishth V, 2019, COMPUT COMMUN, V134, P138, DOI 10.1016/j.comcom.2018.12.001
   Vasudeva JS, 2022, INT J COMMUN SYST, V33, P4368, DOI [10.1016/B978-0-12-823978-0.00012-5, DOI 10.1016/B978-0-12-823978-0.00012-5]
   Zhao RN, 2017, T EMERG TELECOMMUN T, V28, DOI 10.1002/ett.3230
NR 37
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39815
EP 39839
DI 10.1007/s11042-023-15734-x
EA MAY 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000993050400022
DA 2024-07-18
ER

PT J
AU Liang, SX
   Zhao, Y
AF Liang, Sixin
   Zhao, Yue
TI Common pole-polar and common tangent properties of dual coplanar circles
   and their application in camera calibration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Camera intrinsic parameters; common pole-polar; dual coplanar circles;
   image of circular points
ID SELF-CALIBRATION; CONSTRAINTS; PARAMETERS
AB A novel linear calibration method for a camera using two coplanar circles as the calibration template is proposed. Under projective transformation, the common pole-polar and common tangent of coplanar circles maintain invariance and homogeneity, respectively. The two tangent points on the common tangent, the four intersections, and the line passing through the centers of the two coplanar circles can form two groups of vertical parallel lines. Considering duality, a common polar passes through the centers of two coplanar dual circles in various positions with their corresponding poles located at infinity. The common tangent problem was solved iteratively by employing a search algorithm. Further, in the camera model, the vanishing points are obtained by using three images including the two coplanar circle template. The internal parameters can be solved based on the constraint relationship between the imaged circular points and the imaged absolute conic(IAC). In the simulation experiment, the solution of the common tangent and the noise experiment of the internal parameters. In the real experiment, the internal parameters by each method are verified and the projection error is analyzed. The results show that the algorithm is feasible and effective.
C1 [Liang, Sixin; Zhao, Yue] Yunnan Univ, Inst Math & Stat, Kunming 650091, Peoples R China.
C3 Yunnan University
RP Zhao, Y (corresponding author), Yunnan Univ, Inst Math & Stat, Kunming 650091, Peoples R China.
EM zhao6685@yeah.net
OI Yue, Zhao/0000-0002-4896-2247
FU National Natural Science Foundation of China (NSFC) [61663048,
   11861075]; Programme for Innovative Research Team (in Science and
   Technology) in Universities of Yunnan Province; Key Joint Project of the
   Science and Technology Department of Yunnan Province and Yunnan
   University [2018FY001(-014)]
FX This study was supported in part by the National Natural Science
   Foundation of China (NSFC) (61663048 and 11861075), Programme for
   Innovative Research Team (in Science and Technology) in Universities of
   Yunnan Province, and the Key Joint Project of the Science and Technology
   Department of Yunnan Province and Yunnan University (2018FY001(-014)).
CR Barreto JP, 2003, SPRINGER TRAC ADV RO, V5, P245
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen Q, 2004, LECT NOTES COMPUT SC, V3023, P521
   Chen Q, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION (ICMA), P1775, DOI 10.1109/ICMA.2017.8016086
   Chen X, 2015, OPTIK, V126, P2565, DOI 10.1016/j.ijleo.2015.06.036
   Diwakar M, 2020, MULTIMED TOOLS APPL, V79, P14449, DOI 10.1007/s11042-018-6897-1
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   El Akkad N, 2018, MULTIMED TOOLS APPL, V77, P14055, DOI 10.1007/s11042-017-5012-3
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Gurdjos P., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P1214
   Gurdjos P, 2006, LECT NOTES COMPUT SC, V3951, P238
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Huang HF, 2016, IEEE IMAGE PROC, P1170, DOI 10.1109/ICIP.2016.7532542
   Huang HF, 2015, PROC CVPR IEEE, P4065, DOI 10.1109/CVPR.2015.7299033
   Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80
   Liang SX, 2020, APPL OPTICS, V59, P5167, DOI 10.1364/AO.388109
   Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information
   Meng XQ, 2003, PATTERN RECOGN, V36, P1155, DOI 10.1016/S0031-3203(02)00225-X
   Qi F, 2007, PATTERN RECOGN, V40, P1785, DOI 10.1016/j.patcog.2006.11.001
   Semple JG., 1999, ALGEBRAIC PROJECTIVE
   SHIH SW, 1992, P SOC PHOTO-OPT INS, V1614, P133, DOI 10.1117/12.57975
   Sun JH, 2015, OPT LASER TECHNOL, V65, P83, DOI 10.1016/j.optlastec.2014.07.009
   Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010
   Wang YL, 2019, MULTIMED TOOLS APPL, V78, P12223, DOI 10.1007/s11042-018-6763-1
   Wong KYK, 2011, IEEE T IMAGE PROCESS, V20, P305, DOI 10.1109/TIP.2010.2063035
   Wu FC, 2005, PATTERN RECOGN, V38, P755, DOI 10.1016/j.patcog.2004.11.005
   Wu YH, 2004, LECT NOTES COMPUT SC, V3021, P190
   Yang FL, 2019, APPL OPTICS, V58, P5901, DOI 10.1364/AO.58.005901
   Ying XH, 2007, LECT NOTES COMPUT SC, V4843, P138
   Yu J, 2018, J OPT SOC AM A, V35, P221, DOI 10.1364/JOSAA.35.000221
   Zhang ZY, 2004, IEEE T PATTERN ANAL, V26, P892, DOI 10.1109/TPAMI.2004.21
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao ZJ, 2014, J OPT SOC AM A, V31, P1186, DOI 10.1364/JOSAA.31.001186
NR 35
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 16
PY 2023
DI 10.1007/s11042-023-15684-4
EA MAY 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZR2
UT WOS:000988581800003
DA 2024-07-18
ER

PT J
AU Greeshma, MS
   Bindu, VR
AF Greeshma, M. S. M.
   Bindu, V. R. V.
TI Deep primitive convolutional neural network for image super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Primitive prior; Deep learning; Super-resolution; Network learning;
   Edge-preserving
ID QUALITY ASSESSMENT; SUPERRESOLUTION; DICTIONARY
AB Deep networks have emerged as a dominant solution in many research areas recently. Numerous approaches based on deep networks have been developed for image super-resolution problems with good performance. The Super-resolution Convolutional Neural Network model attempts to direct feature learning from low to high-resolution images but sometimes fails in network training when noisy examples are presented. In this work, we propose a super-resolution model that exploits an image represented by the deep structures while characterized by the primitive prior. More specifically, we discuss the use of traditional sparse representation being still sensible and combine processing of primitive prior with deep learning structure to attain further enhanced results. In addition, we apply the sparsity of primitive prior to the super-resolution problem and generate a sharp-edged high-resolution image from low-resolution image. The primitive priors are more informative structures, which can retain the high-resolution image effectively. The network simulation based on primitive prior leads to more effective network training and fine-tuning of the network. On evaluating the super-resolution model on different low-resolution images, an enhanced performance over existing algorithms is achieved in quantitative and qualitative validations. The quantitative results show that the proposed network outshines the other state-of-the-art approaches, surpassing the metric values. Qualitative analysis using the primitive network model achieves good visual quality concerning ridge and corner details.
C1 [Greeshma, M. S. M.; Bindu, V. R. V.] Mahatma Gandhi Univ, Sch Comp Sci, Kottayam, Kerala, India.
C3 Mahatma Gandhi University, Kerala
RP Bindu, VR (corresponding author), Mahatma Gandhi Univ, Sch Comp Sci, Kottayam, Kerala, India.
EM binduvr@mgu.ac.in
OI V R, Bindu/0000-0002-1447-8406
CR Ahn N, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108649
   Benecki P, 2018, ACTA ASTRONAUT, V153, P15, DOI 10.1016/j.actaastro.2018.07.035
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Cheng Ma, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7766, DOI 10.1109/CVPR42600.2020.00779
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Esmaeilzehi A., 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116509
   Fang FM, 2020, IEEE T IMAGE PROCESS, V29, P4656, DOI 10.1109/TIP.2020.2973769
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Greeshma MS, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INTELLIGENT SUSTAINABLE SYSTEMS (ICISS 2017), P20, DOI 10.1109/ISS1.2017.8389412
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Lai WS, 2017, PROC CVPR IEEE, P5835, DOI 10.1109/CVPR.2017.618
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liu H, 2020, INT CONF ACOUST SPEE, P1818, DOI [10.1109/ICASSP40776.2020.9053890, 10.1109/icassp40776.2020.9053890]
   Lu J, 2015, SIGNAL PROCESS-IMAGE, V32, P40, DOI 10.1016/j.image.2015.01.005
   Lv Z, 2017, SIGNAL PROCESS-IMAGE, V58, P199, DOI 10.1016/j.image.2017.08.006
   Lyu K, 2022, NEUROCOMPUTING, V489, P570, DOI 10.1016/j.neucom.2021.12.071
   Matsui Y, 2017, MULTIMED TOOLS APPL, V76, P21811, DOI 10.1007/s11042-016-4020-z
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nair Vinod, 2010, ICML, DOI DOI 10.5555/3104322.3104425
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Qiu DF, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105059
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song WL, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102633
   Sun J, 2003, PROC CVPR IEEE, P729
   Sun J, 2008, PROC CVPR IEEE, P2471, DOI 10.1109/CVPR.2008.4587659
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Tian CW, 2021, IEEE T MULTIMEDIA, V23, P1489, DOI 10.1109/TMM.2020.2999182
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Duong VV, 2021, IEEE IMAGE PROC, P1809, DOI 10.1109/ICIP42928.2021.9506786
   Wang CS, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3170493
   Wang C, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108498
   Wang SZ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3132093
   Wang SZ, 2022, AAAI CONF ARTIF INTE, P2522
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wei SF, 2018, SUSTAIN CITIES SOC, V37, P358, DOI 10.1016/j.scs.2017.11.012
   Xie QF, 2017, PROCEDIA COMPUT SCI, V107, P454, DOI 10.1016/j.procs.2017.03.089
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang WH, 2017, IEEE T IMAGE PROCESS, V26, P5895, DOI 10.1109/TIP.2017.2750403
   Yang WM, 2020, NEUROCOMPUTING, V398, P291, DOI 10.1016/j.neucom.2019.09.091
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhou Y, 2022, IEEE T CYBERNETICS, V52, P5855, DOI 10.1109/TCYB.2020.3044374
NR 54
TC 0
Z9 0
U1 8
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 15
PY 2023
DI 10.1007/s11042-023-15661-x
EA MAY 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZW1
UT WOS:000988586700003
DA 2024-07-18
ER

PT J
AU Peng, G
   Xiong, C
   Zhou, YC
   Yang, J
   Li, XD
AF Peng, Gang
   Xiong, Chao
   Zhou, Yicheng
   Yang, Jin
   Li, Xinde
TI Extraction method of dispensing track for components based on transfer
   learning and Mask-RCNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Component dispensing; Mark point; Mask-RCNN; Track extraction; Transfer
   learning
AB In the process of dispensing, the traditional dispensing robot generally obtains the component pad profile according to the Mark point assisted positioning, and directly uses the profile as the dispensing profile. However, due to the influence of welding and other factors, the posture of the components often changes after welding, which easily causes the actual dispensing contour to be difficult to completely match the pad, so there is a certain deviation in the dispensing. Moreover, component recognition based on convolutional neural network requires a large number of samples for training, which is not conducive to the expansion of dispensing components. This paper focuses on the high-precision dispensing task. Based on the indirect positioning components, this paper uses Mask RCNN to extract complex component dispensing track in different environments. Compared with traditional methods, this method has higher robustness and dispensing accuracy. At the same time, the transfer learning method is used to train the neural network, so that the algorithm has better scalability and flexibility when facing the detection and segmentation tasks of new components. The experimental results show that the component dispensing track extraction method proposed in this paper has higher precision and flexibility than the traditional method.
C1 [Peng, Gang; Xiong, Chao; Zhou, Yicheng; Yang, Jin] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan, Peoples R China.
   [Peng, Gang; Xiong, Chao; Zhou, Yicheng; Yang, Jin; Li, Xinde] Minist Educ, Key Lab Image Proc & Intelligent Control, Wuhan, Peoples R China.
   [Li, Xinde] South East Univ, Sch Automat, Nanjing, Peoples R China.
C3 Huazhong University of Science & Technology; Southeast University -
   China
RP Zhou, YC (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan, Peoples R China.; Zhou, YC (corresponding author), Minist Educ, Key Lab Image Proc & Intelligent Control, Wuhan, Peoples R China.
EM penggang@hust.edu.cn; m202173171@hust.edu.cn
OI Zhou, YiCheng/0000-0001-8034-6850
FU National Natural Science Foundation of China [91748106]; Hubei Province
   Natural Science Foundation of China [2019CFB526]; Shenzhen Science and
   Technology Innovation Project [CYZZ20160412111639184]
FX This work was supported by National Natural Science Foundation of China
   (No.91748106), Hubei Province Natural Science Foundation of China (No.
   2019CFB526), and Shenzhen Science and Technology Innovation
   Project(CYZZ20160412111639184).
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bao X., 2019, J ZHEJIANG SCI TECH, V41, P360
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Donahue J, 2014, PR MACH LEARN RES, V32
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Kuo CFJ, 2019, J INTELL MANUF, V30, P671, DOI 10.1007/s10845-016-1274-2
   Li Yandong, 2016, Journal of Computer Applications, V36, P2508, DOI 10.11772/j.issn.1001-9081.2016.09.2508
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   [李泽峰 Li Zefeng], 2020, [激光技术, Laser Technology], V44, P358
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma H-l, 2020, J QILU U TECHNOL, V34, P53
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tang De-wei, 2006, Robot, V28, P1
   Yosinski J, 2014, ADV NEUR IN, V27
   Zeng NY, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3153997
   Zhang JH, 2020, MULTIMED TOOLS APPL, V79, P2427, DOI 10.1007/s11042-019-08302-9
   Zhang K, 2018, MODULAR MACH TOOL AU, V7, P43
   [张铁虎 Zhang Tiehu], 2016, [现代制造工程, Modern Manufacturing Engineering], P101
   Zhou X., 2018, IND CONTROL COMPUT, V31, P111
NR 23
TC 0
Z9 0
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 13
PY 2023
DI 10.1007/s11042-023-15755-6
EA MAY 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G3ZM6
UT WOS:000988577200010
DA 2024-07-18
ER

PT J
AU Chakraborty, S
   Mazumdar, K
AF Chakraborty, Sheuli
   Mazumdar, Kaushik
TI A Hybrid GRASP-GA based collaborative task offloading technique in fog
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Collaborative Tasks; Edge Server; Greedy Randomized Adaptive Search
   Procedure (GRASP); Mobile Fog Computing; Task Offloading
ID MOBILE EDGE; CLOUD; OPTIMIZATION
AB The transfer of cloud-computing capabilities at the network's edge reduces the service latency and energy shortage problem in Mobile Fog Computing. Task offloading from resource-constraint devices to the edge servers addresses the limitations of the battery power and computational capability of Mobile Devices (MDs). Most of the offloading strategies proposed earlier comprehended independent tasks. Today's communication network demands the comprehensive study of collaborative task execution. The offloading of latency-sensitive sensor tasks in collaboration at a multi-access edge network promisingly utilizes the edge servers with increased performance. In this paper, we propose a dynamic edge server selection mechanism for task offloading, which collects all the collaborative tasks from allied edge servers and other end devices. A hybrid metaheuristic based on Greedy Randomized Adaptive Search Procedure (GRASP) and Genetic Algorithm (GA) is used to solve the offloading issues. The GRASP -GA based Collaborative Task Offloading technique implemented in the Mobile Fog Computing environment finds the optimal solution. Simulation results show that the proposed study achieves 11% to 63% better performance in depleting the total execution time and energy consumption compared with other existing state-of-art methods.
C1 [Chakraborty, Sheuli; Mazumdar, Kaushik] IIT Indian Sch Mines, Dept Elect Engn, Dhanbad 826004, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Chakraborty, S (corresponding author), IIT Indian Sch Mines, Dept Elect Engn, Dhanbad 826004, India.
EM sheuli.chakraborty@gmail.com; kaushik@iitism.ac.in
CR Aazam M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS), P518, DOI 10.1109/PERCOMW.2015.7134091
   Cao B, 2020, IEEE T NETW SCI ENG, V7, P2117, DOI 10.1109/TNSE.2020.3008381
   Chakraborty S, 2021, J CIRCUIT SYST COMP, V30, DOI 10.1142/S0218126621501747
   Chatzimisios P., 2005, EURASIP Journal on Wireless Communications and Networking, V2005, P67, DOI 10.1155/WCN.2005.67
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Elazhary H, 2019, J NETW COMPUT APPL, V128, P105, DOI 10.1016/j.jnca.2018.10.021
   FEO TA, 1995, J GLOBAL OPTIM, V6, P109, DOI 10.1007/BF01096763
   Geng YL, 2018, IEEE INFOCOM SER, P46, DOI 10.1109/INFOCOM.2018.8485875
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Guo ST, 2016, IEEE INFOCOM SER
   Hmimz Y, 2021, MULTIMED TOOLS APPL, V80, P17129, DOI 10.1007/s11042-020-09365-9
   Lee C-P, 2018 IEEE C INTERNET
   Leng LX, 2021, MULTIMED TOOLS APPL, V80, P29163, DOI 10.1007/s11042-021-11130-5
   Liu FG, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051105
   Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201
   Mazouzi H, 2019, COMPUT COMMUN, V144, P132, DOI 10.1016/j.comcom.2019.05.017
   Mehrabi M., 2021, Network, V1, P191, DOI DOI 10.3390/NETWORK1020012
   Mustafa E, 2022, CLUSTER COMPUT, V25, P2429, DOI 10.1007/s10586-021-03376-3
   Oueis J, 2014, IEEE WIREL COMMUNN, P12, DOI 10.1109/WCNCW.2014.6934853
   Pan SL, 2019, IEEE ACCESS, V7, P134742, DOI 10.1109/ACCESS.2019.2942052
   Parajuli N, 2020, MULTIMED TOOLS APPL, V79, P31567, DOI 10.1007/s11042-020-09516-y
   Peng K, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1526-x
   Ren L, 2020, IEEE T NETW SCI ENG, V7, P2286, DOI 10.1109/TNSE.2019.2942042
   Shu C, 2020, IEEE INTERNET THINGS, V7, P1678, DOI 10.1109/JIOT.2019.2943373
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Tinnirello I, 2010, IEEE T VEH TECHNOL, V59, P1055, DOI 10.1109/TVT.2009.2029118
   Wang J, 2019, IEEE COMMUN MAG, V57, P64, DOI 10.1109/MCOM.2019.1800971
   Wu CR, 2019, INT SYMPOS COMPUT NE, P204, DOI 10.1109/CANDAR.2019.00034
   Wu Q, 2017, MULTIMED TOOLS APPL, V76, P17163, DOI 10.1007/s11042-016-3667-9
   Xu ZC, 2016, IEEE T PARALL DISTR, V27, P2866, DOI 10.1109/TPDS.2015.2510638
   Yan J, 2020, IEEE T WIREL COMMUN, V19, P235, DOI 10.1109/TWC.2019.2943563
   Yang S, 2020, COMPUT COMMUN, V160, P759, DOI 10.1016/j.comcom.2020.07.008
   Zaman SKU, 2021, CLUSTER COMPUT, V24, P2735, DOI 10.1007/s10586-021-03268-6
   Zhang WW, 2015, IEEE T WIREL COMMUN, V14, P81, DOI 10.1109/TWC.2014.2331051
   Zhao WJ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8070775
   Zhou SC, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6687337
NR 36
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 10
PY 2023
DI 10.1007/s11042-023-15526-3
EA MAY 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9HG1
UT WOS:000985378600007
DA 2024-07-18
ER

PT J
AU Dhingra, D
   Dua, M
AF Dhingra, Deepti
   Dua, Mohit
TI A chaos-based novel approach to video encryption using dynamic S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Chaotic maps; Video encryption; S-box; Chaos-based encryption
ID IMAGE ENCRYPTION; SYSTEM; ALGORITHM; TRANSFORM; DESIGN; MAP
AB Video Encryption is the process of converting the video into an unrecognizable form to protect it from unauthorized access. This paper proposes a novel video encryption method based on a dynamic S-box generated using the Sine-Tent cosine chaos map. The proposed method mainly comprises four phases. In the first step, an input video is split into frames, and frame rotation is performed to shuffle the pixels within the frame. The second stage involves the generation of a novel dynamic S-Box by using the Sine-Tent Cosine map. The number of dynamic S-boxes to be generated in the method is equal to the number of frames in a video, as each frame is encrypted by a different S-box. As every time a new S-box is used for encryption, it makes it difficult for the adversary to access the information. Frame padding is used to protect the metadata of the frame, and to make the size of the video frame compatible with the S-box dimensions. In the third stage, generated dynamic S-Box is used to permute pixels within the video frame. At last, the pixels of the frame are diffused by applying add and mod operators on a chaotic sequence generated by a chaotic Sine-Tent Cosine map to obtain the final cipher frame as output. The differential analysis and statistical analysis are performed by using parameters such as Unified Average Changed Intensity (UACI), Number of Changing Pixel Rate (NPCR), and Correlation Coefficient (CC), Information Entropy, respectively. The work also tests the key sensitivity, Avalanche effect, and Peak Signal to Noise Ratio (PSNR), of the proposed scheme. The obtained results prove that the proposed scheme is secure from many attacks such as differential attacks, statistical attacks, known plain-text, and Brute Force attacks, and provides a higher level of security as compared to other existing video encryption methods.
C1 [Dhingra, Deepti; Dua, Mohit] Natl Inst Technol, Dept Comp Engn, Kurukshetra, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Dhingra, D (corresponding author), Natl Inst Technol, Dept Comp Engn, Kurukshetra, India.
EM deeptimona@gmail.com; er.mohitdua@nitkkr.ac.in
RI DHINGRA, DEEPTI/KPA-9641-2024; DUA, MOHIT/A-1409-2016
OI DHINGRA, DEEPTI/0000-0002-3443-4232; DUA, MOHIT/0000-0001-7071-8323
CR Al-Hayani N, 2013, INT SYMP IMAGE SIG, P240
   Alarood AA, 2022, AIN SHAMS ENG J, V13, DOI 10.1016/j.asej.2021.09.010
   Alawida M, 2019, IEEE ACCESS, V7, P150609, DOI 10.1109/ACCESS.2019.2947561
   Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alghafis A, 2021, MULTIMED TOOLS APPL, V80, P7967, DOI 10.1007/s11042-020-10142-x
   Alshammari BM, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13010129
   Ansari N, 2016, PROCEDIA COMPUT SCI, V78, P125, DOI 10.1016/j.procs.2016.02.021
   Belazi A, 2022, J INF SECUR APPL, V66, DOI 10.1016/j.jisa.2022.103131
   Bisht A, 2019, J AMB INTEL HUM COMP, V10, P3519, DOI 10.1007/s12652-018-1072-0
   Boyadjis B, 2017, IEEE T CIRC SYST VID, V27, P892, DOI 10.1109/TCSVT.2015.2511879
   Cassal-Quiroga BB, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/2702653
   Chandrasekaran Jeyamala, 2015, ScientificWorldJournal, V2015, P458272, DOI 10.1155/2015/458272
   Chen ZQ, 2010, NONLINEAR DYNAM, V62, P647, DOI 10.1007/s11071-010-9751-1
   Dua M, 2022, OPEN COMPUT SCI, V12, P37, DOI 10.1515/comp-2020-0225
   Dua M, 2021, COMPLEX INTELL SYST, V7, P327, DOI 10.1007/s40747-020-00201-z
   Eid M, 2021, FAST REAL TIME VIDEO
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Nguyen GN, 2021, J PARALLEL DISTR COM, V153, P150, DOI 10.1016/j.jpdc.2021.03.011
   Haridas D., 2021, SN COMPUT SCI, V2, P1, DOI [10.1007/s42979-021-00793-4, DOI 10.1007/S42979-021-00793-4]
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Ibrahim DR, 2021, MULTIMED TOOLS APPL, V80, P31927, DOI 10.1007/s11042-021-11229-9
   Jun WJ, 2021, IEEE ACCESS, V9, P120596, DOI 10.1109/ACCESS.2021.3108789
   Karmakar J, 2021, DIGIT SIGNAL PROCESS, V117, DOI 10.1016/j.dsp.2021.103143
   Kordov K, 2021, CYBERN INF TECHNOL, V21, P50, DOI 10.2478/cait-2021-0004
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P27785, DOI 10.1007/s11042-021-10970-5
   Kumar CM, 2022, APPL INTELL, V52, P2556, DOI 10.1007/s10489-021-02508-x
   Kumar HSR, 2017, CYBERN INF TECHNOL, V17, P134, DOI 10.1515/cait-2017-0046
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Liu J, 2022, INT J COMPUT INT SYS, V15, DOI 10.1007/s44196-022-00083-8
   Liu JZ, 2019, MULTIDIM SYST SIGN P, V30, P1637, DOI 10.1007/s11045-018-0622-0
   Malik MSM, 2020, IEEE ACCESS, V8, P35682, DOI 10.1109/ACCESS.2020.2973679
   Malladar R S., 2021, International Journal of Computer Network Information Security, V13, P40, DOI [10.5815/ijcnis.2021.05.04, DOI 10.5815/IJCNIS.2021.05.04]
   Mamta, 2021, IEEE-CAA J AUTOMATIC, V8, P1877, DOI 10.1109/JAS.2021.1004003
   Mukherjee I, 2018, MULTIMED TOOLS APPL, V77, P5281, DOI 10.1007/s11042-017-4431-5
   Neupane A, 2020, MULTIMED TOOLS APPL, V79, P29043, DOI 10.1007/s11042-020-09478-1
   Pankaj S, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00324-4
   Paul G, 2017, MULTIMED TOOLS APPL, V76, P7445, DOI 10.1007/s11042-016-3319-0
   Raghunandan KR, 2020, CYBERN INF TECHNOL, V20, P86, DOI 10.2478/cait-2020-0030
   Ramalingam Mritha, 2020, Procedia Computer Science, V171, P1147, DOI 10.1016/j.procs.2020.04.123
   Ratna AAP., 2021, ADV SCI TECHNOL ENG, V6, P316, DOI [10.25046/aj060136, DOI 10.25046/AJ060136]
   Saljoughi AS, 2019, PATTERN ANAL APPL, V22, P243, DOI 10.1007/s10044-018-0765-5
   Sallam AI, 2018, MULTIMEDIA SYST, V24, P419, DOI 10.1007/s00530-017-0568-3
   Shifa A, 2020, IEEE ACCESS, V8, P177131, DOI 10.1109/ACCESS.2020.3024926
   Substitution-boxes EB, NEW HYP SYST BAS DES, P1, DOI [10.3390/e20070525, DOI 10.3390/E20070525]
   Tewari A, 2020, INT J SEMANT WEB INF, V16, P20, DOI 10.4018/IJSWIS.2020070102
   ul Haq T, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102592
   Valli D, 2017, EUR PHYS J PLUS, V132, DOI 10.1140/epjp/i2017-11819-7
   Yan W., 2021, ELECTRONICS, V10, P1, DOI DOI 10.3969/J.ISSN.1007-7545.2021.03.001
   Yang C, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23101312
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zahid AH, 2021, IEEE ACCESS, V9, P67797, DOI 10.1109/ACCESS.2021.3077194
   Zhang LF, 2021, INT J CLOUD APPL COM, V11, P17, DOI 10.4018/IJCAC.2021040102
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zhu HH, 2020, MULTIMED TOOLS APPL, V79, P12329, DOI 10.1007/s11042-019-08478-0
NR 56
TC 6
Z9 6
U1 9
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 9
PY 2023
DI 10.1007/s11042-023-15593-6
EA MAY 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F9KB5
UT WOS:000985452800004
DA 2024-07-18
ER

PT J
AU Wu, CM
   Peng, SY
AF Wu, Chengmao
   Peng, Siyun
TI Deep neighborhood structure driven interval type-2 kernel fuzzy c-means
   clustering with local versus non-local information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Fuzzy c-means clustering; Interval type-2 fuzzy
   sets; Local information; Non-local information; Kernel metric
ID SPATIAL INFORMATION; IMAGE FUSION; SEGMENTATION; ALGORITHM;
   RECONSTRUCTION; FEATURES; NETWORK; SET; FCM
AB For images with high noise, existing robust fuzzy clustering-related methods are difficult to obtain satisfactory segmentation results. Hence, this paper proposes a novel single fuzzifier interval type-2 kernel-based fuzzy local and non-local information c-means clustering driven by a deep neighborhood structure for strong noise image segmentation. Based on the neighborhood window around the current pixel, we firstly construct the novel deep neighborhood window structure, which is composed of neighborhood window around the current pixel and neighborhood window around pixels in the neighborhood window around the current pixel. Secondly maximally and minimally neighborhood weighted distances between current pixels and clustering centers are obtained through deep neighborhood window structure. Thirdly, two local neighborhood distances are used to modify upper and lower fuzzy membership of robust single fuzzifier interval type-2 fuzzy clustering with kernel metric and local versus non-local information, and an enhanced robust interval type-2 kernel-based fuzzy clustering with single fuzzifier is presented for strong noise image segmentation. Experimental results indicate that the proposed algorithm has better segmentation performance and stronger anti-noise robustness, and outperforms existing state-of-the-art robust fuzzy clustering-related algorithms in the presence of high noise. In particular, the segmentation accuracy of the proposed algorithm is 20% higher than that of the important KWFLICM algorithm and has increased by 10% compared with the FALRCM algorithm proposed in recent years.
C1 [Wu, Chengmao; Peng, Siyun] Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
C3 Xi'an University of Posts & Telecommunications
RP Peng, SY (corresponding author), Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
EM wuchengmao123@sohu.com; pengsiyun97@163.com
OI peng, siyun/0000-0002-6562-8662
FU National Natural Science Foundation of China [61671377]; School of
   Electronic Engineering, Xi'an University of Posts & Telecommunications,
   Xi'an, China
FX This work was supported by the National Natural Science Foundation of
   China (grant numbers 61671377), Wu and Peng would like to thank the
   anonymous reviewers for their constructive suggestions to improve the
   overall quality of the paper. Besides, Wu and Peng would like to thank
   School of Electronic Engineering, Xi'an University of Posts &
   Telecommunications, Xi'an, China for financial support.
CR Abhishek Jeph A, 2013, P 3 INT C INFORM SYS, P1
   Ahmed MN, 2002, IEEE T MED IMAGING, V21, P193, DOI 10.1109/42.996338
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alruwaili M, 2020, EGYPT INFORM J, V21, P51, DOI 10.1016/j.eij.2019.10.005
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Bai XZ, 2019, IEEE J BIOMED HEALTH, V23, P2039, DOI 10.1109/JBHI.2018.2884208
   BEZDEK JC, 1987, IEEE T SYST MAN CYB, V17, P873, DOI 10.1109/TSMC.1987.6499296
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Chen SC, 2004, IEEE T SYST MAN CY B, V34, P1907, DOI 10.1109/TSMCB.2004.831165
   Nguyen DD, 2013, IEEE INT CONF FUZZY, DOI 10.1109/FUZZ-IEEE.2013.6622432
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Fan JL, 2003, PATTERN RECOGN LETT, V24, P1607, DOI 10.1016/S0167-8655(02)00401-4
   Feng QY, 2020, IEEE T FUZZY SYST, V28, P1420, DOI 10.1109/TFUZZ.2020.2966173
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gong MG, 2012, IEEE T IMAGE PROCESS, V21, P2141, DOI 10.1109/TIP.2011.2170702
   Guo YH, 2013, CIRC SYST SIGNAL PR, V32, P1699, DOI 10.1007/s00034-012-9531-x
   He H, 2019, SCI CHINA EARTH SCI, V62, P438, DOI 10.1007/s11430-017-9224-6
   Hu J, 2021, TSINGHUA SCI TECHNOL, V26, P185, DOI 10.26599/TST.2019.9010078
   Hwang C, 2007, IEEE T FUZZY SYST, V15, P107, DOI 10.1109/TFUZZ.2006.889763
   Jha P, 2021, COMPUT BIOL CHEM, V92, DOI 10.1016/j.compbiolchem.2021.107454
   Kalhori MRN., 2021, INFORM SCIENCES, V581, P7
   Kamili A, 2020, J INTELL FUZZY SYST, V39, P8389, DOI 10.3233/JIFS-189157
   Karnik NN, 2001, INFORM SCIENCES, V132, P195, DOI 10.1016/S0020-0255(01)00069-X
   Kiechle M, 2018, IEEE T IMAGE PROCESS, V27, P1994, DOI 10.1109/TIP.2018.2792904
   Kotaridis I, 2021, ISPRS J PHOTOGRAMM, V173, P309, DOI 10.1016/j.isprsjprs.2021.01.020
   Krinidis S, 2010, IEEE T IMAGE PROCESS, V19, P1328, DOI 10.1109/TIP.2010.2040763
   Lam CY, 2018, INT J CRIT INFR PROT, V22, P51, DOI 10.1016/j.ijcip.2018.05.005
   [雷涛 Lei Tao], 2019, [电子学报, Acta Electronica Sinica], V47, P1776
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Liu B, 2019, IEEE ACCESS, V7, P42169, DOI 10.1109/ACCESS.2019.2907573
   Liu SQ, 2020, IEEE ACCESS, V8, P90760, DOI 10.1109/ACCESS.2020.2993404
   Long MZ, 2018, IEEE T BIOMED CIRC S, V12, P993, DOI 10.1109/TBCAS.2018.2869530
   Ngo LT, 2015, COMPUT GEOSCI-UK, V83, P1, DOI 10.1016/j.cageo.2015.06.011
   Mahmoudi MR, 2020, ALEX ENG J, V59, P2811, DOI 10.1016/j.aej.2020.06.017
   McCulloch J, 2019, IEEE T FUZZY SYST, V27, P1506, DOI 10.1109/TFUZZ.2018.2882342
   Mendel JM, 2004, IEEE T FUZZY SYST, V12, P84, DOI 10.1109/TFUZZ.2003.822681
   Mendel JM, 2002, IEEE T FUZZY SYST, V10, P117, DOI 10.1109/91.995115
   Vu MN, 2016, STUD COMPUT INTELL, V642, P63, DOI 10.1007/978-3-319-31277-4_6
   Mishro PK, 2021, IEEE T CYBERNETICS, V51, P3901, DOI 10.1109/TCYB.2020.2994235
   Mittal M, 2019, IEEE ACCESS, V7, P33240, DOI 10.1109/ACCESS.2019.2902579
   Mújica-Vargas D, 2013, PATTERN RECOGN LETT, V34, P400, DOI 10.1016/j.patrec.2012.10.004
   Na IS, 2015, PATTERN ANAL APPL, V18, P667, DOI 10.1007/s10044-015-0459-1
   Nie F, 2021, IEEE TRANSFUZZY SYST, V30, P375
   Ruiz-García G, 2019, IEEE T FUZZY SYST, V27, P2381, DOI 10.1109/TFUZZ.2019.2898582
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Shirkhorshidi AS, 2021, IEEE T FUZZY SYST, V29, P560, DOI 10.1109/TFUZZ.2019.2956900
   Mai SD, 2015, LECT NOTES ARTIF INT, V9011, P387, DOI 10.1007/978-3-319-15702-3_38
   Su TF, 2020, ISPRS J PHOTOGRAMM, V168, P89, DOI 10.1016/j.isprsjprs.2020.07.017
   Szilágyi L, 2003, P ANN INT IEEE EMBS, V25, P724, DOI 10.1109/IEMBS.2003.1279866
   Tang YM, 2020, APPL SOFT COMPUT, V87, DOI 10.1016/j.asoc.2019.105928
   van Opbroek A, 2019, IEEE T MED IMAGING, V38, P213, DOI 10.1109/TMI.2018.2859478
   Wang QS, 2021, APPL SOFT COMPUT, V105, DOI 10.1016/j.asoc.2021.107245
   Wang QS, 2020, APPL SOFT COMPUT, V92, DOI 10.1016/j.asoc.2020.106318
   Wu C., 2019, P 2019 56 ACMEDACIEE, V97, P1
   Wu C., 2020, J XIAN U POSTS TELEC, V25, P1
   Wu CM, 2021, IEEE J-STARS, V14, P5903, DOI 10.1109/JSTARS.2021.3085606
   Wu CM, 2021, SOFT COMPUT, V25, P3751, DOI 10.1007/s00500-020-05403-8
   Wu D, 2007, NAFIPS 2007 - 2007 ANNUAL MEETING OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY, P184, DOI 10.1109/NAFIPS.2007.383834
   Yang J, 2020, IEEE ACCESS, V8, P45368, DOI 10.1109/ACCESS.2020.2976793
   Yin PS, 2020, IEEE ACCESS, V8, P116106, DOI 10.1109/ACCESS.2020.3002835
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   [张阿龙 Zhang Along], 2018, [测绘科学技术学报, Journal of Geomatics Science and Technology], V35, P376
   Zhang H, 2018, IEEE J-STARS, V11, P2896, DOI 10.1109/JSTARS.2018.2846603
   Zhang XF, 2021, INFORM SCIENCES, V550, P129, DOI 10.1016/j.ins.2020.10.039
   Zhang XL, 2020, IEEE ACCESS, V8, P95681, DOI 10.1109/ACCESS.2020.2995660
   Zhao F, 2014, EXPERT SYST APPL, V41, P4083, DOI 10.1016/j.eswa.2014.01.003
NR 70
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43455
EP 43515
DI 10.1007/s11042-023-15230-2
EA APR 2023
PG 61
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000970495100006
DA 2024-07-18
ER

PT J
AU Kalampokas, T
   Mentizis, D
   Vrochidou, E
   Papakostas, GA
AF Kalampokas, Theofanis
   Mentizis, Dimitrios
   Vrochidou, Eleni
   Papakostas, George A.
TI Connecting national flags - a deep learning approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer vision; Cultural heritage; Flags similarity;
   Similarity measure; Artificial intelligence; National flags; Vexillology
ID SYSTEM; RECOGNITION
AB National flags are the most recognizable symbols of the identity of a country. Similarities between flags may be observed due to cultural, historical, or ethical connections between nations, because they may be originated from the same group of people, or due to unrelated sharing of common symbols and colors. Although the fact that similar flags exist is indisputable, this has never been quantified. Quantifying flags' similarities could provide a useful body of knowledge for vexillologists and historians. To this end, this work aims to develop a supporting tool for the scientific study of nations' history and symbolisms, through the quantification of the varying degrees of similarity between their flags, by considering three initially stated hypotheses and by using a novel feature inclusion (FI) measure. The proposed FI measure aims to objectively quantify the overall similarity between flags based on optical multi-scaled features extracted from flag images. State-of-the-art deep learning models built for other applications tested their capability for the first time for the problem under study by using transfer learning, towards calculating the FI measure. More specifically, FI was quantified by six deep learning models: Yolo (V4 and V5), SSD, RetinaNet, Fast R-CNN, FCOS and CornerNet. Flags' images dataset included flags of 195 nations officially recognized by the United Nations. Experimental results reported maximum feature inclusion between flags of up to 99%. The extracted degrees of similarity were subsequently justified with the help of the Vexillology scientific domain, to support research findings and to raise questions for further investigation. Experimental results reveal that the proposed approach and FI measure are reliable and able to serve as a supporting tool to social sciences for knowledge extraction and quantification.
C1 [Kalampokas, Theofanis; Mentizis, Dimitrios; Vrochidou, Eleni; Papakostas, George A.] Int Hellen Univ, Dept Comp Sci, MLV Res Grp, Kavala 65404, Greece.
RP Papakostas, GA (corresponding author), Int Hellen Univ, Dept Comp Sci, MLV Res Grp, Kavala 65404, Greece.
EM gpapak@cs.ihu.gr
RI Vrochidou, Eleni/AAO-6932-2021; Papakostas, George/F-1038-2017
OI Vrochidou, Eleni/0000-0002-0148-8592; Papakostas,
   George/0000-0001-5545-1499; Kalampokas, Theofanis/0000-0002-1495-875X
FU HEAL-Link Greece
FX Open access funding provided by HEAL-Link Greece
CR Akhand MAH., 2013, INT J KNOWL ENG RES, V2, P212
   Alzubi JA, 2021, J INTELL FUZZY SYST, V40, P5761, DOI 10.3233/JIFS-189415
   Alzubi OA, 2022, CLUSTER COMPUT, V25, P2369, DOI 10.1007/s10586-021-03459-1
   Assael Y, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P6368
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Belhi A, 2018, I C COMP SYST APPLIC
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Bongini P, 2020, IOP CONF SER-MAT SCI, V949, DOI 10.1088/1757-899X/949/1/012074
   CERULO KA, 1993, SOCIOL FORUM, V8, P243, DOI 10.1007/BF01115492
   Cilia ND, 2020, PATTERN RECOGN LETT, V129, P137, DOI 10.1016/j.patrec.2019.11.025
   Gallwey J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11171994
   Ghosh M, 2021, J IMAGING, V7, DOI 10.3390/jimaging7080149
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Jhoor NH, 2019, 2019 IEEE JORDAN INTERNATIONAL JOINT CONFERENCE ON ELECTRICAL ENGINEERING AND INFORMATION TECHNOLOGY (JEEIT), P602, DOI [10.1109/JEEIT.2019.8717470, 10.1109/jeeit.2019.8717470]
   Kutlay MA, 2016, J ALZHEIMERS DIS, V4, DOI [10.21533/scjournal.v4i2.94, DOI 10.21533/SCJOURNAL.V4I2.94]
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   LINDAUER MS, 1969, PERCEPT MOTOR SKILL, V29, P892, DOI 10.2466/pms.1969.29.3.892
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   López-García P, 2018, J ARCHAEOL SCI-REP, V19, P100, DOI 10.1016/j.jasrep.2018.02.023
   Monisha GS, 2021, ADV INTELLIGENT SYST, P115, DOI [10.1007/978-981-15-7907-3_9, DOI 10.1007/978-981-15-7907-3_9]
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Podeh E, 2011, NATIONS NATL, V17, P419, DOI 10.1111/j.1469-8129.2010.00475.x
   Polak A, 2017, J CULT HERIT, V26, P1, DOI 10.1016/j.culher.2017.01.013
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sabatelli M, 2019, LECT NOTES COMPUT SC, V11130, P631, DOI 10.1007/978-3-030-11012-3_48
   Sharafi S, 2016, J ARCHAEOL SCI-REP, V8, P206, DOI 10.1016/j.jasrep.2016.06.024
   Sheng SR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2478, DOI 10.1145/3343031.3350972
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uehara Y, 2001, IEEE INT SYM MULTIM, P102
   Wang XJ, 2018, LECT NOTES COMPUT SC, V11258, P52, DOI 10.1007/978-3-030-03338-5_5
NR 32
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39435
EP 39457
DI 10.1007/s11042-023-15056-y
EA MAR 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600008
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhao, AT
   Li, JB
AF Zhao, Aite
   Li, Jianbo
TI A significantly enhanced neural network for handwriting assessment in
   Parkinson's disease detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Hand motion; CNN; BiGRU; Parkinson's disease
ID DIAGNOSIS
AB In recent years, machining learning aided diagnosis can provide non-invasive, low-cost tools to support clinicians and assist the diagnosis and monitoring of neurodegenerative disorders, in particular Parkinson's disease (PD). As an important motor symptom, disorder of the hand motion is usually used for diagnosis and evaluation of PD; moreover, majority of the patients with PD have handwriting abnormalities, which plays a special role in PD detection. In this paper, as an useful tool, we propose a novel hybrid model to learn the handwriting differences between PD patients and healthy controls, by learning and enhancing significant features from three handwriting exams, i.e., meander, circle and spiral. Based on a three-layer convolutional neural network (CNN) and a bidirectional gated recurrent unit (BiGRU), the proposed network can assess the potential of sequential information of handwriting in identifying Parkinsonian symptoms. Compared with several state of the art studies, the recognition rates of our proposed framework are 92.91%, 85.71% and 90.55% respectively in these three tests, which verifies the excellent classification effect.
C1 [Zhao, Aite] Qingdao Univ, Sch Business, Qingdao, Peoples R China.
   [Li, Jianbo] Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
C3 Qingdao University; Qingdao University
RP Li, JB (corresponding author), Qingdao Univ, Coll Comp Sci & Technol, Qingdao, Peoples R China.
EM zhaoaite@qdu.edu.cn; lijianbo@qdu.edu.cn
OI Zhao, Aite/0000-0003-3494-175X
FU National Key Research and Development Plan Key Special Projects
   [2018YFB2100303]; Shandong Province colleges and universities youth
   innovation technology plan innovation team project [2020KJN011];
   Shandong Provincial Natural Science Foundation [ZR2020MF060]; Program
   for Innovative Postdoctoral Talents in Shandong Province [40618030001];
   National Natural Science Foundation of China [62106117, ZR2021QF084];
   Postdoctoral Science Foundation of China [61802216]; Natural Science
   Foundation of Shandong Province;  [2018M642613]
FX This research was supported in part by National Key Research and
   Development Plan Key Special Projects under Grant No. 2018YFB2100303,
   Shandong Province colleges and universities youth innovation technology
   plan innovation team project under Grant No. 2020KJN011, Shandong
   Provincial Natural Science Foundation under Grant No. ZR2020MF060,
   Program for Innovative Postdoctoral Talents in Shandong Province under
   Grant No. 40618030001, National Natural Science Foundation of China
   under Grant No. 61802216, and Postdoctoral Science Foundation of China
   under Grant No.2018M642613, National Natural Science Foundation of China
   under Grant No. 62106117, and Natural Science Foundation of Shandong
   Province under Grant No.ZR2021QF084.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Achanta SDM, 2021, INT J SPEECH TECHNOL, DOI 10.1007/s10772-021-09893-1
   Ali L., 2019, 2019 INT C ELECT COM, DOI 10.1109/ICECCE47252.2019.8940696
   Amirkhani D, 2021, MULTIMED TOOLS APPL, V80, P26199, DOI 10.1007/s11042-021-10883-3
   [Anonymous], 2013, Nature, V503, P29
   Bevilacqua V, 2018, INTELLIGENT COMPUTIN
   Che ZP, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24271-9
   Darmatasia, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (ICOIC7), DOI 10.1109/ICoICT.2017.8074699
   Deharab ED, 2022, BIOCYBERN BIOMED ENG
   Diaz M, 2020, EXPERT SYST APPL
   Diaz M, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114405
   Drotár P, 2016, ARTIF INTELL MED, V67, P39, DOI 10.1016/j.artmed.2016.01.004
   Evers LJW, 2019, MOVEMENT DISORD, V34, P1480, DOI 10.1002/mds.27790
   Gazda M, 2022, IEEE T SYST MAN CY-S, V52, P78, DOI 10.1109/TSMC.2020.3048892
   Gholamalinezhad H, 2020, ARXIV
   Giancardo L, 2016, SCI REP-UK, V6, DOI 10.1038/srep34468
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hajihashemi V., 2020, 2020 INT C MACH VIS, P1, DOI DOI 10.1109/MVIP49855.2020.9116913
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jiang Z., 2021, IEEE T IMAGE PROCESS
   Kaur S, 2020, MULTIMED TOOLS APPL, P1
   Lamba Rohit, 2021, Journal of Reliable Intelligent Environments, V7, P253, DOI 10.1007/s40860-021-00130-9
   Li F, 2020, CONCURR COMP-PRACT E
   Li Y, 2017, J MED IMAG HEALTH IN, V7
   Lin G., 2019, COMPUT TECHNOL DEV, V29, P216
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Loconsole C, 2018, IEEE IJCNN
   Meoni S, 2020, NAT REV NEUROL, V16, P84, DOI 10.1038/s41582-019-0294-x
   Murthy ASD, 2022, SOFT COMPUT, V26, P12933, DOI 10.1007/s00500-021-06125-1
   P D., 2016, International Journal of Advanced Research Trends in Engineering and Technology, V3, P86
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pereira CR, 2016, SIBGRAPI, P340, DOI [10.1109/SIBGRAPI.2016.054, 10.1109/SIBGRAPI.2016.51]
   Sahu Bibhuprasad, 2021, International Journal of Information Technology, V13, P647, DOI 10.1007/s41870-020-00569-8
   Sainath TN, 2015, INT CONF ACOUST SPEE, P4580, DOI 10.1109/ICASSP.2015.7178838
   Sano Y, 2016, MED BIOL ENG COMPUT, V54, P953, DOI 10.1007/s11517-016-1467-z
   Senturk ZK, 2020, MED HYPOTHESES, V138, DOI 10.1016/j.mehy.2020.109603
   Shubhangi DC, 2020, INT J SCI RES COMPUT, P351
   Stamatakis J, 2013, COMPUT INTEL NEUROSC, V2013, DOI 10.1155/2013/717853
   Taleb C, 2023, EVOL INTELL, V16, P1813, DOI 10.1007/s12065-020-00470-0
   Taleb C, 2018, 2018 IEEE 2ND INTERNATIONAL WORKSHOP ON ARABIC AND DERIVED SCRIPT ANALYSIS AND RECOGNITION (ASAR), P7, DOI 10.1109/ASAR.2018.8480209
   Tripathi A, 2021, P CIKM 2020 WORKSHOP
   Voigtlaender P, 2016, INT CONF FRONT HAND, P228, DOI [10.1109/ICFHR.2016.0052, 10.1109/ICFHR.2016.48]
   Wang RZ, 2019, IEEE I CONF COMP VIS, P3056, DOI 10.1109/ICCV.2019.00315
   Wang Y, 2021, COGN COMPUT, V99
   Xu S., 2020, J PHYS C SER, V1631, P1
   Xu SJ, 2020, INT J MED INFORM, V144, DOI 10.1016/j.ijmedinf.2020.104283
   Yin D, 2020, MULTIMED TOOLS APPL, V79
   Yu XY, 2022, J AMB INTEL HUM COMP, V13, P1405, DOI 10.1007/s12652-020-02638-z
   Zagoruyko S, 2018, ARXIV
   Zhao AT, 2022, IEEE T MULTIMEDIA, V24, P846, DOI 10.1109/TMM.2021.3060280
   Zhao AT, 2022, IEEE T CYBERNETICS, V52, P9439, DOI 10.1109/TCYB.2021.3056104
   Zhao A, 2020, KNOWL-BASED SYST, V206, DOI 10.1016/j.knosys.2020.106273
   Zhao AT, 2020, IEEE ACCESS, V8, P93907, DOI 10.1109/ACCESS.2020.2994593
   Zhao AT, 2018, NEUROCOMPUTING, V315, P1, DOI 10.1016/j.neucom.2018.03.032
   Zhao AT, 2018, KNOWL-BASED SYST, V145, P91, DOI 10.1016/j.knosys.2018.01.004
NR 55
TC 3
Z9 3
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 38297
EP 38317
DI 10.1007/s11042-023-14647-z
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000956327700005
DA 2024-07-18
ER

PT J
AU Eleyan, A
AF Eleyan, Alaa
TI Statistical local descriptors for face recognition: a comprehensive
   study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature extraction; Local descriptors; Data fusion
ID INVARIANT TEXTURE CLASSIFICATION; BINARY PATTERN; FRONTALIZATION;
   REPRESENTATION; FEATURES; SCALE; PCA
AB The use of local statistical descriptors for image representation has emerged and gained a reputation as a powerful approach in the last couple of decades. Many algorithms have been proposed and applied, since then, in various application areas employing different datasets, classifiers, and testing parameters. In this paper, we felt the need to make a comprehensive study of frequently-used statistical local descriptors. We investigate the effect of using different histogram-based local feature extraction algorithms on the performance of the face recognition problem. Comparisons are conducted among 18 different algorithms. These algorithms are used for the extraction of the local statistical feature descriptors of the face images. Moreover, feature fusion/concatenation of different combinations of generated feature descriptors is applied, and the relevant impact on the system performance is evaluated. Comprehensive experiments are carried out using two well-known face databases with identical experimental settings. The obtained results indicate that the fusion of the descriptors can significantly enhance the system's performance.
C1 [Eleyan, Alaa] Amer Univ Middle East, Coll Engn & Technol, Egaila, Kuwait.
C3 American University of the Middle East
RP Eleyan, A (corresponding author), Amer Univ Middle East, Coll Engn & Technol, Egaila, Kuwait.
EM alaa.eleyan@aum.edu.kw
RI ELEYAN, ALAA/AAH-9481-2019
OI ELEYAN, ALAA/0000-0002-0644-8039
CR Ahmed F, 2012, ELECTRON LETT, V48, P1203, DOI 10.1049/el.2012.1841
   Ahmed F., 2013, CHINESE J ENG, DOI 10.1155/2013/831747
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T., 2008, 19th Intl. Conf. on Pattern Recognition, P1, DOI DOI 10.1109/ICPR.2008.4761847
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Albiol A, 2008, PATTERN RECOGN LETT, V29, P1537, DOI 10.1016/j.patrec.2008.03.017
   Alkhatib M, 2019, IEEE T IMAGE PROCESS, V28, P5407, DOI 10.1109/TIP.2019.2916742
   Alpaslan N, 2020, IEEE ACCESS, V8, P54415, DOI 10.1109/ACCESS.2020.2981720
   Atta R, 2010, IEEE T CONSUM ELECTR, V56, P1542, DOI 10.1109/TCE.2010.5606295
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Bashar F., 2014, INT C EL INF COMM TE, P1, DOI DOI 10.1109/EICT.2014.6777846
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Bukhari M, 2021, IEEE ACCESS, V9, P6465, DOI 10.1109/ACCESS.2020.3047266
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen ZG, 2019, IEEE ACCESS, V7, P81599, DOI 10.1109/ACCESS.2019.2924140
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Daugman John, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P271, DOI 10.1109/TBIOM.2020.2993225
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   de Leeuw K., 2007, HIST INFORM SECURITY, P264
   Deng WH, 2014, IEEE T PATTERN ANAL, V36, P1275, DOI 10.1109/TPAMI.2013.194
   Dong YS, 2019, IEEE ACCESS, V7, P87931, DOI 10.1109/ACCESS.2019.2924985
   Duan QY, 2021, IEEE T NEUR NET LEAR, V32, P214, DOI 10.1109/TNNLS.2020.2978127
   Dutta P, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/7961427
   Eleyan A, 2005, LECT NOTES COMPUT SC, V3512, P935
   Eleyan A., 2006, LECT NOTES COMPUT SC, DOI [10.1007/11848035_28, DOI 10.1007/11848035_28]
   Eleyan A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/185281
   Guillamet D, 2002, LECT NOTES ARTIF INT, V2504, P336
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Hafiane A, 2008, LECT NOTES COMPUT SC, V5112, P619, DOI 10.1007/978-3-540-69812-8_61
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Howland P, 2006, PATTERN RECOGN, V39, P277, DOI 10.1016/j.patcog.2005.06.013
   Hu M, 2019, IEEE ACCESS, V7, P118435, DOI 10.1109/ACCESS.2019.2936976
   Huang YJ, 2021, IEEE T CIRC SYST VID, V31, P148, DOI 10.1109/TCSVT.2020.2965739
   Huang YH, 2020, IEEE IMAGE PROC, P2161, DOI [10.1109/ICIP40778.2020.9191321, 10.1109/icip40778.2020.9191321]
   Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489
   Islam M.S., 2014, TRENDS APPL SCI RES, V9, P113, DOI [10.3923/tasr.2014.113.120, DOI 10.3923/tasr.2014.113.120]
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   Jabid T, 2012, INFORMATION-TOKYO, V15, P2007
   Jain A. K., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P726, DOI 10.1109/FG.2011.5771338
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Kasinski A., 2008, Image Processing and Communications, V13, P59
   Khadatkar A., 2016, WORLD C FUTURISTIC T, P1, DOI 10.1109/STARTUP.2016.7583985
   Kong XY, 2018, EBIOMEDICINE, V27, P94, DOI 10.1016/j.ebiom.2017.12.015
   Kruszka P, 2017, AM J MED GENET A, V173, P879, DOI 10.1002/ajmg.a.38199
   Li JL, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020417
   Li ST, 2013, NEUROCOMPUTING, V122, P272, DOI 10.1016/j.neucom.2013.05.038
   Liu YF, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104093
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MOAYER B, 1976, IEEE T COMPUT, V25, P262, DOI 10.1109/TC.1976.5009253
   Mohammad T., 2011, 2011 14th International Conference on Computer and Information Technology (ICCIT), P572, DOI 10.1109/ICCITechn.2011.6164854
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Rivera AR, 2015, PATTERN RECOGN LETT, V51, P94, DOI 10.1016/j.patrec.2014.08.012
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Soni N, 2021, J COMPUT SCI-NETH, V51, DOI 10.1016/j.jocs.2021.101352
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Taskiran M, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102809
   Thiam P, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030839
   Tosik C., 2013, SIG PROCESS COMMUN, P1, DOI DOI 10.1109/SIU.2013.6531374
   Tripathi RK, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114786
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wan JW, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107927
   Wiskott L., 1996, FACE RECOGNITION ELA
   Xiong FG, 2020, IEEE ACCESS, V8, P100120, DOI 10.1109/ACCESS.2020.2995369
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Yin XF, 2021, IEEE T PATTERN ANAL, V43, P1085, DOI 10.1109/TPAMI.2019.2949299
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhang YL, 2020, IEEE ACCESS, V8, P183391, DOI 10.1109/ACCESS.2020.3027846
   Zhen Lei, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P161, DOI 10.1109/FG.2011.5771391
   Zhou LB, 2012, IEEE IMAGE PROC, P2601, DOI 10.1109/ICIP.2012.6467431
NR 81
TC 3
Z9 3
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32485
EP 32504
DI 10.1007/s11042-023-14482-2
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000949737500005
PM 37362654
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Semwal, VB
   Jain, R
   Maheshwari, P
   Khatwani, S
AF Semwal, Vijay Bhaskar
   Jain, Rahul
   Maheshwari, Pushkar
   Khatwani, Saksham
TI Gait reference trajectory generation at different walking speeds using
   LSTM and CNN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biped robots; CNN; GRU; Human gait analysis; Personalized gait reference
   trajectory generation; LSTM; Rehabilitation robots
ID KINEMATICS; PREDICTION; KINETICS
AB Rehabilitation robots are gaining significant popularity for impaired gait rehabilitation. However, to make the recovering individual feel natural while walking and restore their original gait pattern, adapting the rehabilitation system according to the individual's need and walking characteristics becomes imperative. In this paper, we have compared four deep learning models for their ability to generate a personalized gait trajectory at different gait speeds. The first three models are primitive and are the basic implementations of long short term memory (LSTM), convolutional neural network (CNN) and gated recurrent unit (GRU). The fourth model is our proposed model, which is a sequential combination of LSTM and CNN. We considered hip, knee and ankle joints data as human gait is represented as the joint angle trajectories of these joints in the sagittal plane. We trained these models on a benchmark public human walking dataset consisting of treadmill walking data of 42 healthy individuals at eight different walking speeds. Anthropometric and demographic data along with gait speeds were given as input to the models. Our proposed LSTM-CNN sequential model is able to generate stable gait trajectories in the speed range of 0.49-1.76 m/s with a high correlation of 0.98 between the actual and the predicted trajectories, and an R-2 Score of 0.94 is obtained. This work can be utilized for providing personalized gait reference trajectories for the rehabilitation of amputees and stroke patients using rehabilitation systems such as exoskeleton robots and prosthetic legs. Also, this work can be utilized for generating stable walking trajectories for bipedal robots.
C1 [Semwal, Vijay Bhaskar; Jain, Rahul; Maheshwari, Pushkar; Khatwani, Saksham] MANIT, CSE Dept, Bhopal, India.
C3 National Institute of Technology (NIT System); Maulana Azad National
   Institute of Technology Bhopal
RP Jain, R (corresponding author), MANIT, CSE Dept, Bhopal, India.
EM vsemwal@gmail.com; rahuljain32cs@gmail.com; pushkar27mah@gmail.com;
   sakshamkhatwani@gmail.com
RI Jain, Rahul/ABD-6272-2021; Semwal, Vijay Bhaskar/B-5628-2017
OI Jain, Rahul/0000-0002-4969-6956; Semwal, Vijay
   Bhaskar/0000-0003-0767-6057
FU SERB, DST Govt. of India; Ministry of Education, Govt. of India
   [ECR/2018/000203];  [SAN/CSR/08/2021-22]
FX The authors would like to thank the Ministry of Education, Govt. of
   India for funding the project under HEFA CSR grant SAN/CSR/08/2021-22.
   The authors also like to thank SERB, DST Govt. of India, for funding the
   project to Dr. Vijay Bhaskar Semwal under the Early career award (ECR)
   scheme, DST No: ECR/2018/000203.
CR Aertbeliën E, 2014, P IEEE RAS-EMBS INT, P520, DOI 10.1109/BIOROB.2014.6913830
   Banbury C. R., 2020, arXiv
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chung Junyoung, 2014, ARXIV14123555
   Fang B, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00058
   Findlow A, 2008, GAIT POSTURE, V28, P120, DOI 10.1016/j.gaitpost.2007.11.001
   Fukuchi CA, 2019, GAIT POSTURE, V73, P269, DOI 10.1016/j.gaitpost.2019.07.500
   Fukuchi CA, 2018, PEERJ, V6, DOI 10.7717/peerj.4640
   Gholami M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102939
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Holanda LJ, 2017, J NEUROENG REHABIL, V14, DOI 10.1186/s12984-017-0338-7
   Horst F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38748-8
   Jain R, 2022, ROBOTICA, V40, P2567, DOI 10.1017/S026357472100179X
   Jain R, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12743
   Liang FY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P27, DOI 10.1109/ROBIO.2018.8664778
   Louie DR, 2016, J NEUROENG REHABIL, V13, DOI 10.1186/s12984-016-0162-5
   McGrath RL, 2017, INT C REHAB ROBOT, P270, DOI 10.1109/ICORR.2017.8009258
   Moissenet F, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45397-4
   Morone G, 2017, NEUROPSYCH DIS TREAT, V13, P1303, DOI 10.2147/NDT.S114102
   Muro-de-la-Herran A, 2014, SENSORS-BASEL, V14, P3362, DOI 10.3390/s140203362
   Ren Shixin, 2023, Journal of Ambient Intelligence and Humanized Computing, P15597, DOI 10.1007/s12652-019-01390-3
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Su BB, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20247127
   Luu TP, 2014, GAIT POSTURE, V39, P443, DOI 10.1016/j.gaitpost.2013.08.028
   Vallery H, 2009, IEEE T NEUR SYS REH, V17, P23, DOI 10.1109/TNSRE.2008.2008278
   Wu XY, 2018, IEEE T AUTOM SCI ENG, V15, P1459, DOI 10.1109/TASE.2018.2841358
   Yun Y, 2014, J BIOMECH, V47, P186, DOI 10.1016/j.jbiomech.2013.09.032
   Zaroug A, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00362
   Zhou ZK, 2021, IEEE T NEUR SYS REH, V29, P273, DOI 10.1109/TNSRE.2020.3045425
NR 30
TC 10
Z9 10
U1 12
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33401
EP 33419
DI 10.1007/s11042-023-14733-2
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000948950300012
DA 2024-07-18
ER

PT J
AU Zouhaier, L
   BenDalyHlaoui, Y
   Ayed, LB
AF Zouhaier, Lamia
   BenDalyHlaoui, Yousra
   Ayed, Leila Ben
TI Adaptive user interface based on accessibility context
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive user interfaces; Accessibility; Metamodel transformation;
   Model-driven engineering
ID SERVICES
AB The substantial involvement of Adaptive User Interfaces (AUI) in providing adaptive and accessible interactive systems has created the need to establish a multimodal framework based on scalable adaptation rules. This paper presents an Adaptive User Interface to Accessibility Context (AUIAC) framework that provides a generic adaptation approach according to the model-driven engineering. It is based on a sequential and layered transformation from platform independent model (PIM) to platform specific model (PSM). It supports different reifications and transitions using adaptive transformation rules specified for each disability and modality. We illustrate the application of some rules on a sample user interface for the case of blind people. Then, we present some usability evaluation results from an empirical study.
C1 [Zouhaier, Lamia; BenDalyHlaoui, Yousra; Ayed, Leila Ben] Tunis El Manar Univ, Fac Sci Tunis, LIPS Lab, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar; Faculte des Sciences de Tunis (FST)
RP Zouhaier, L (corresponding author), Tunis El Manar Univ, Fac Sci Tunis, LIPS Lab, Tunis, Tunisia.
EM zouhaier.lamia@yahoo.fr; yousra.hlaoui@fst.utm.tn;
   leila.benayed@ensi-uma.tn
RI hlaoui, yousra/ADI-6867-2022
CR Abascal J, 2011, EHUKATIK0111
   Abrahao S, 2021, SOFTW SYST MODEL, V20, P1335, DOI 10.1007/s10270-021-00909-7
   Akiki PA, 2016, IEEE T SOFTWARE ENG, V42, P1118, DOI 10.1109/TSE.2016.2553035
   [Anonymous], WHO INT CLASS FUNCT
   [Anonymous], 2019, SPSS Software
   [Anonymous], 2001, Model driven architecture (mda)
   Bobed, 2016, 10 INT C MOBILE UBIQ
   Burzagli L, 2022, UNIVERSAL ACCESS INF, V21, P437, DOI 10.1007/s10209-021-00797-0
   EcoreTools, 2017, ECORETOOLS 2017 GRAP
   Engel C, 2019, 12TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2019), P186, DOI 10.1145/3316782.3316793
   Firmenich S, 2019, WEB ACCESSIBILITY HU
   Gajos KZ, 2010, ARTIF INTELL, V174, P910, DOI 10.1016/j.artint.2010.05.005
   Gonçalves TG, 2018, COMPUT STAND INTER, V58, P53, DOI 10.1016/j.csi.2017.12.003
   Henry, 2010, WEB CONTENT ACCESSIB
   Hlaoui Y.Bendaly, 2018, J MULTIMODAL USER IN
   ISO, 2008, 9241171 ISO
   ISO, 1998, 1998 ISO
   ISO, 2017, 40500 ISOIEC
   Khan A, 2019, MULTIMED TOOLS APPL, V78, P17495, DOI 10.1007/s11042-018-7094-y
   Kosmas P, 2020, UNIVERSAL ACCESS INF, V19, P471, DOI 10.1007/s10209-019-00651-4
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Muller PA, 2005, LECT NOTES COMPUT SC, V3713, P264, DOI 10.1007/11557432_19
   Oliveira RF., 2018, Proceedings of the 17th Brazilian Symposium on Software Quality, P180
   Paterno F, 2011, DESIGN SPACE USER IN
   Peissner M., 2014, International Conf. on Universal Access in Human-Computer Interaction, P431
   PeiSSner M., 2012, SMART 2012, The First International Conference on Smart Systems, Devices and Technologies, P25
   Responsive Design, 2020, RESPONSIVE WEB DESIG
   Sauro J., 2011, MeasuringU: What Is A Good Task-Completion Rate?
   Sauro J., 2018, INTERPRETING SINGLE
   Scott MJ, 2015, COMPUT STAND INTER, V42, P113, DOI 10.1016/j.csi.2015.05.004
   Seffah A, 2006, SOFTWARE QUAL J, V14, P159, DOI 10.1007/s11219-006-7600-8
   Skillen KL, 2014, FUTURE GENER COMP SY, V34, P97, DOI 10.1016/j.future.2013.10.027
   Souidi E, 2022, 2022 IEEE 46TH ANNUAL COMPUTERS, SOFTWARE, AND APPLICATIONS CONFERENCE (COMPSAC 2022), P1462, DOI 10.1109/COMPSAC54236.2022.00232
   Stephanidis C., 1998, Intelligence in Services and Networks: Technology for Ubiquitous Telecom Services. 5th International Conference on Intelligence in Services and Networks, IS&N'98 Proceedings, P153, DOI 10.1007/BFb0056962
   Vanderheiden GC., 2004, CREATING GLOBAL PUBL, P506
   Zouhaier L, 2017, IEEE 41 ANN COMPUTER
   Zouhaier L, 2021, P INT COMP SOFTW APP, P1463, DOI 10.1109/COMPSAC51774.2021.00217
   Zouhaier L, 2017, LECT NOTES COMPUT SC, V10244, P73, DOI 10.1007/978-3-319-59105-6_7
   STATA STAT SOFTWARE
NR 39
TC 0
Z9 0
U1 7
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35621
EP 35650
DI 10.1007/s11042-023-14390-5
EA MAR 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946494700002
DA 2024-07-18
ER

PT J
AU Jalal, AS
   Sharma, DK
   Sikander, B
AF Jalal, Anand Singh
   Sharma, Dilip Kumar
   Sikander, Bilal
TI Suspect face retrieval system using multicriteria decision process and
   deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face recognition; Linguistic description; Facial attribute-value pair
ID RECOGNITION
AB The identification and apprehending of suspects by law enforcement authorities rely heavily on facial sketches. The sketch artist creates sketches based on the witnesses' memories. Sketch artists are few and limited in their availability. It is also evident that as time passes, the eyewitness forgets many of the important details, which can be expensive in time-sensitive investigations. The sketch was used to obtain the suspect's image through the state-of-the-art sketch-photo retrieval model, which missed the relevance of time sensitivity. A linguistic description-based suspect face image retrieval approach is presented in this study. In the proposed approach, the facial attribute-value pair is extracted from eyewitness descriptions. Facial attribute saliency is also studied in this work and validated with the Fuzzy Analytic Hierarchy Process (FAHP) model. A weighted score is computed to retrieve the suspect face images. The effectiveness of the proposed method is assessed by comparing it to existing linguistic sketch-based retrieval methods as well as the sketch to photo retrieval models. As compared to state-of-the-art approaches, experimental results give an accuracy of 94.98%.
C1 [Jalal, Anand Singh; Sharma, Dilip Kumar] GLA Univ, Mathura, India.
   [Sikander, Bilal] Prerna Soc Tech Educ & Res, Noida, India.
C3 GLA University
RP Jalal, AS (corresponding author), GLA Univ, Mathura, India.
EM asjalal@gla.ac.in
RI Sharma, Dilip Kumar/I-2008-2019
OI Sharma, Dilip Kumar/0000-0002-3860-7997; Jalal,
   Anand/0000-0002-7469-6608
FU Ministry of Electronics and Information Technology, Government of India
   [4(8)/2020-ITEA]
FX AcknowledgmentsThe authors highly acknowledge Ministry of Electronics
   and Information Technology, Government of India, for its fund Grant
   Approval No. 4(8)/2020-ITEA.
CR [Anonymous], QUOTEV
   Buoncompagni S, 2017, ADV INTELL SYST, P159
   Chang DY, 1996, EUR J OPER RES, V95, P649, DOI 10.1016/0377-2217(95)00300-2
   Dabhi M.K., 2016, International Journal of Science and Research (IJSR), V5, P62, DOI 10.21275/v5i4.nov162465
   Dalal S, 2020, PROCEDIA COMPUT SCI, V167, P562, DOI 10.1016/j.procs.2020.03.318
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Fang YK, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107249
   Gafar MG, 2020, J SUPERCOMPUT, V76, P2339, DOI 10.1007/s11227-018-2512-5
   Gupta V, 2019, CLIN DERMATOL, V37, P430, DOI 10.1016/j.clindermatol.2019.07.010
   Hurbain I, 2018, J INVEST DERMATOL, V138, P647, DOI 10.1016/j.jid.2017.09.039
   Jalal AS, 2023, VISUAL COMPUT, V39, P2609, DOI 10.1007/s00371-022-02482-6
   Karczmarek P, 2017, SOFT COMPUT, V21, P7503, DOI 10.1007/s00500-016-2305-9
   Karczmarek P, 2015, SPA 2015 SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS, P98, DOI 10.1109/SPA.2015.7365141
   Keomany J, 2006, ACTIVE SHAPE MODELS
   Khan MA, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112925
   Khan MA, 2019, EXPERT SYST APPL, V134, P138, DOI 10.1016/j.eswa.2019.05.040
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Liu DC, 2018, NEUROCOMPUTING, V302, P46, DOI 10.1016/j.neucom.2018.03.042
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Mangla FU, 2020, MULTIMED TOOLS APPL, V79, P27533, DOI 10.1007/s11042-020-09246-1
   Nagpal S, 2021, PATTERN RECOGN, V114, DOI 10.1016/j.patcog.2021.107815
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Öztürk S, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102601
   Pant G, 2020, ALGAL RES, V48, DOI 10.1016/j.algal.2020.101932
   Pasupa K, 2019, EXPERT SYST APPL, V120, P14, DOI 10.1016/j.eswa.2018.11.011
   Peng CL, 2019, PATTERN RECOGN, V90, P161, DOI 10.1016/j.patcog.2019.01.041
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Radman A, 2018, MULTIMED TOOLS APPL, V77, P25311, DOI 10.1007/s11042-018-5786-y
   Rahman A, 2015, INT J MACH LEARN CYB, V6, P597, DOI 10.1007/s13042-014-0256-y
   Sharma DK, 2022, 2022 9 INT C COMPUTI, P849
   Suchitra S, 2020, MULTIMED TOOLS APPL, V79, P24825, DOI 10.1007/s11042-020-09219-4
   Sunhem W, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P390, DOI 10.1109/ICACI.2016.7449857
   Tang JH, 2018, IEEE T NEUR NET LEAR, V29, P6154, DOI 10.1109/TNNLS.2018.2816743
   Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028
   Vishwakarma VP, 2019, MULTIMED TOOLS APPL, V78, P15213, DOI 10.1007/s11042-018-6837-0
   Wan W, 2019, NEURAL COMPUT APPL, V31, P9175, DOI 10.1007/s00521-019-04242-5
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu JY, 2021, VISUAL COMPUT, V37, P765, DOI 10.1007/s00371-020-01976-5
   Xu P, 2018, NEUROCOMPUTING, V278, P75, DOI 10.1016/j.neucom.2017.05.099
NR 39
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAR 6
PY 2023
DI 10.1007/s11042-023-14968-z
EA MAR 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9P0GI
UT WOS:000943970200003
DA 2024-07-18
ER

PT J
AU Feng, L
   Liu, LY
   Liu, SL
   Zhou, J
   Yang, HQ
   Yang, J
AF Feng, Lin
   Liu, Lu-Yao
   Liu, Sheng-Lan
   Zhou, Jian
   Yang, Han-Qing
   Yang, Jie
TI Multimodal speech emotion recognition based on multi-scale MFCCs and
   multi-view attention mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech emotion recognition; Multi-view attention; Mulit-scale MFCCs
ID AUDIO; INFORMATION
AB In recent years, speech emotion recognition (SER) increasingly attracts attention since it is a key component of intelligent human-computer interaction and sophisticated dialog systems. To obtain more abundant emotional information, a great number of studies in SER pay attention to the multimodal systems which utilize other modalities such as text and facial expression to assist the speech emotion recognition. However, it is difficult to structure a fusion mechanism which can selectively extract abundant emotion-related features from different modalities. To tackle this issue, we develop a multimodal speech emotion recognition model based on multi-scale MFCCs and multi-view attention mechanism, which is able to extract abundant audio emotional features and comprehensively fuse emotion-related features from four aspects (i.e., audio self-attention, textual self-attention, audio attention based on textual content, and textual attention based on audio content). Under different audio input conditions and attention configurations, it can be observed that the best emotion recognition accuracy can be achieved by jointly utilizing four attention modules and three different scales of MFCCs. In addition, based on multi-task learning, we regard the gender recognition as an auxiliary task to learn gender information. To further improve the accuracy of emotion recognition, a joint loss function based on softmax cross-entropy loss and center loss is used. The experiments are conducted on two different datasets (IEMOCAP and MSP-IMPROV). The experimental results demonstrate that the proposed model outperforms the previous models on IEMOCAP dataset, while it obtains the competitive performance on MSP-IMPROV dataset.
C1 [Feng, Lin; Liu, Lu-Yao; Liu, Sheng-Lan; Zhou, Jian] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
   [Yang, Han-Qing] Washington Univ, Comp Sci & Engn, St Louis, MO USA.
   [Yang, Jie] Tsinghua Univ, Res Inst Informat Technol, Beijing 100084, Peoples R China.
C3 Dalian University of Technology; Washington University (WUSTL); Tsinghua
   University
RP Liu, LY (corresponding author), Dalian Univ Technol, Sch Comp Sci & Technol, Dalian, Peoples R China.
EM fenglin@dlut.edu.cn; luyaol@mail.dlut.edu.cn; liusl@dlut.edu.cn;
   zhoujian@mail.dlut.edu.cn; alberty@wustl.edu; totoroyang@tsinghua.edu.cn
OI Liu, Lu-Yao/0000-0002-1366-4151
FU Fundamental Research Funds for the Central Universities [2019RC29,
   DUT19RC(3)012]; National Natural Science Foundation (NNSF) of China
   [61972064]; Gansu Provincial First-Class Discipline Program of Northwest
   Minzu University [11080305]; LiaoNing Revitalization Talents Program
   [XLYC1806006]
FX AcknowledgementsThis work was supported by Fundamental Research Funds
   for the Central Universities (Grants 2019RC29 and DUT19RC(3)012), by
   National Natural Science Foundation (NNSF) of China (Grant 61972064), by
   the Gansu Provincial First-Class Discipline Program of Northwest Minzu
   University (Grant 11080305), and by LiaoNing Revitalization Talents
   Program (Grant XLYC1806006).
CR Abdelwahab M, 2018, IEEE-ACM T AUDIO SPE, V26, P2423, DOI 10.1109/TASLP.2018.2867099
   Bhosale S, 2020, ICASSP 2020 2020 IEE, P7184
   Bird S., 2006, P COLING ACL INT PRE, P69, DOI DOI 10.3115/1118108.1118117
   Busso C, 2017, IEEE T AFFECT COMPUT, V8, P67, DOI 10.1109/TAFFC.2016.2515617
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cho J, 2018, INTERSPEECH, P247, DOI 10.21437/Interspeech.2018-2466
   Daneshfar F, 2020, MULTIMED TOOLS APPL, V79, P1261, DOI 10.1007/s11042-019-08222-8
   Dellaert F, 1996, ICSLP 96 - FOURTH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, PROCEEDINGS, VOLS 1-4, P1970, DOI 10.1109/ICSLP.1996.608022
   Deng J, 2018, IEEE-ACM T AUDIO SPE, V26, P31, DOI 10.1109/TASLP.2017.2759338
   Dobrisek S, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/54002
   Georgiou E, 2019, INTERSPEECH, P1646, DOI 10.21437/Interspeech.2019-3243
   Gobl C, 2003, SPEECH COMMUN, V40, P189, DOI 10.1016/S0167-6393(02)00082-1
   Guizzo E, 2020, INT CONF ACOUST SPEE, P6489, DOI [10.1109/icassp40776.2020.9053727, 10.1109/ICASSP40776.2020.9053727]
   Gupta S, 2020, MULTIMED TOOLS APPL, V79, P23347, DOI 10.1007/s11042-020-09068-1
   Lausen A, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.00882
   Li PC, 2018, INTERSPEECH, P3087, DOI 10.21437/Interspeech.2018-1242
   Liu J, 2020, ICASSP 2020 2020 IEE, P7169
   Liu Z, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2247
   Metallinou A, 2012, IEEE T AFFECT COMPUT, V3, P184, DOI 10.1109/T-AFFC.2011.40
   Miao HR, 2020, INT CONF ACOUST SPEE, P6084, DOI [10.1109/icassp40776.2020.9053165, 10.1109/ICASSP40776.2020.9053165]
   Nediyanchath A, 2020, INT CONF ACOUST SPEE, P7179, DOI [10.1109/icassp40776.2020.9054073, 10.1109/ICASSP40776.2020.9054073]
   Neiberg D, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P809
   NEUMANN M, 2019, INT CONF ACOUST SPEE, P7390, DOI DOI 10.1109/icassp.2019.8682541
   Pao TL, 2005, LECT NOTES COMPUT SC, V3784, P279
   Perez-Rosas V., 2013, P ANN M ASS COMP LIN, P973
   Poria S., 2015, P 2015 C EMP METH NA, P2539, DOI DOI 10.18653/V1/D15-1303
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Rozgic V, 2012, ASIAPAC SIGN INFO PR
   Schuller B, 2011, IEEE T AFFECT COMPUT, V2, P192, DOI 10.1109/T-AFFC.2011.17
   Shen JB, 2020, IEEE T CYBERNETICS, V50, P3068, DOI 10.1109/TCYB.2019.2936503
   Shirian A, 2020, COMPACT GRAPH ARCHIT
   Su BH, 2020, INTERSPEECH, P506, DOI 10.21437/Interspeech.2020-1733
   Tripathi S., 2018, Multi-modal emotion recognition on iemocap with neural networks
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J, 2020, ICASSP 2020 2020 IEE, P6469
   Wang YS, 2018, J BIOMED INFORM, V87, P12, DOI 10.1016/j.jbi.2018.09.008
   Wang YJ, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P15
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Williams C., 1981, SPEECH EVALUATION PS, P221
   Wu CH, 2015, INT CONF AFFECT, P477
   Xu HY, 2019, INTERSPEECH, P3569, DOI 10.21437/Interspeech.2019-3247
   Yoon S, 2020, INT CONF ACOUST SPEE, P3362, DOI [10.1109/ICASSP40776.2020.9054229, 10.1109/icassp40776.2020.9054229]
   Yoon S, 2018, IEEE W SP LANG TECH, P112, DOI 10.1109/SLT.2018.8639583
   Zhang ZX, 2019, INT CONF ACOUST SPEE, P6705, DOI 10.1109/ICASSP.2019.8682896
   Zhao ZP, 2019, INTERSPEECH, P206, DOI 10.21437/Interspeech.2019-1649
   Zheng WQ, 2015, INT CONF AFFECT, P827, DOI 10.1109/ACII.2015.7344669
NR 47
TC 1
Z9 1
U1 7
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 28917
EP 28935
DI 10.1007/s11042-023-14600-0
EA MAR 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000943638900016
DA 2024-07-18
ER

PT J
AU Shedthi, BS
   Siddappa, M
   Shetty, S
   Shetty, V
   Suresh, R
AF Shedthi, B. Shabari
   Siddappa, M.
   Shetty, Surendra
   Shetty, Vidyasagar
   Suresh, R.
TI Detection and classification of diseased plant leaf images using hybrid
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Hybrid clustering; K-means; Plant disease detection;
   Segmentation
ID K-MEANS; SEGMENTATION
AB Plant disease reduces the quantity and quality of the agricultural product, so identification of plant disease in the early stages is very important. Early detection of disease in plants helps to reduce the overuse of pesticides as well as save plants from further damage. In this research work, we designed a plant disease identification system using image processing and machine learning techniques. Segmentation of the leaf image is one of the strategies for extracting the diseased part of a leaf, which will be given to an automated plant disease recognition system. The challenge of the K-means algorithm is the selection of the optimal cluster number and cluster centroid initialization. The image is segmented using a hybrid clustering (Genetic Algorithm+K-means) algorithm. This hybrid algorithm helps to overcome the drawback of the local optimization problem of k-means algorithm and it selects the number of clusters automatically. Disease is classified using the Artificial neural network (ANN). This proposed algorithm experimental results are compared with traditional k-means.
C1 [Shedthi, B. Shabari] Nitte Deemed Univ, NMAM Inst Technol, Dept Comp Sci & Engn, Nitte 574110, India.
   [Siddappa, M.] Sri Siddhartha Inst Technolgy, Dept Comp Sci Engn, Tumkur, India.
   [Shetty, Surendra] Nitte Deemed be Univ, NMAM Inst Technol, Dept Masters Comp Applicat, Nitte 574110, India.
   [Shetty, Vidyasagar] Nitte Deemed Univ, NMAM Inst Technol, Dept Machan Engn, Nitte 574110, India.
   [Suresh, R.] M S Ramaiah Univ Appl Sci, Dept Mech & Mfg Engn, Bangaloree 560058, India.
C3 NITTE (Deemed to be University); NMAM Institute of Technology; NITTE
   (Deemed to be University); NMAM Institute of Technology; NITTE (Deemed
   to be University); NMAM Institute of Technology; M. S. Ramaiah
   University of Applied Sciences
RP Suresh, R (corresponding author), M S Ramaiah Univ Appl Sci, Dept Mech & Mfg Engn, Bangaloree 560058, India.
EM sureshchiru09@gmail.com
RI Shetty, Vidyasagar/KAM-3681-2024; Shedthi B, Shabari/GQI-2565-2022;
   Suresh, R/N-7708-2013
OI Shetty, Vidyasagar/0000-0001-5758-1289; Shedthi B,
   Shabari/0000-0003-2723-7641; Suresh, R/0000-0002-6956-9751
CR Al Bashish Dheeb, 2011, Information Technology Journal, V10, P267, DOI 10.3923/itj.2011.267.275
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   [Anonymous], 1990, PUBL HLTH IMP PEST U
   Babu M., 2007, LEAVES RECOGNITION U
   Bhanu B., 2012, GENETIC LEARNING ADA
   Bhowmik S., 2012, Int. J. Adv. Res. Comput. Engi. Technol, V1, P2278
   Bora D.J., 2015, International Journal of Emerging Technology and Advanced Engineering, V5, P192
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Chi Zhi-gang, 2002, Journal of Software, V13, P907
   Chouhan P., 2015, International Journal of Innovative Research in Electrical, Electronics, Instrumentation and Control Engineering, V3, P53, DOI [10.17148/ijireeice.2015.31212, DOI 10.17148/IJIREEICE.2015.31212]
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Gaikwad DS., 2016, INT J COMPUTER SCI I, V7, P519
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Han J, 2012, MOR KAUF D, P1
   Haralick R. M., 1985, Proceedings of the SPIE - The International Society for Optical Engineering, V548, P2, DOI [10.1016/S0734-189X(85)90153-7, 10.1117/12.948400]
   Hinz J, 2013, CLUSTERING WEB COMPA
   Ingale S., 2019, Int. J. Eng. Res. Technol, V8, P1179, DOI [10.1109/ICCCNT45670.2019.8944556, DOI 10.1109/ICCCNT45670.2019.8944556]
   Issad H. A., 2019, Engineering in Agriculture, Environment and Food, V12, P511
   Jacquet F, 2022, AGRON SUSTAIN DEV, V42, DOI 10.1007/s13593-021-00742-8
   Jain S, 2018, LECT NOTES ELECTR EN, V453, P189, DOI 10.1007/978-981-10-5565-2_17
   Jung YG, 2014, BIOTECHNOL BIOTEC EQ, V28, pS44, DOI 10.1080/13102818.2014.949045
   Kaushik B., 2016, INT J ADV ENG RES SC, V3, P66
   Khirade SD, 2015, 1ST INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION ICCUBEA 2015, P768, DOI 10.1109/ICCUBEA.2015.153
   Lingaraj H., 2016, International journal of computer sciences and Engineering, V4, P139
   Madhavan MV, 2021, CMC-COMPUT MATER CON, V66, P2939, DOI 10.32604/cmc.2021.012466
   Mallikarjuna B., 2020, CLIN INFECT DIS, V8, P521
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5
   MEYER F, 1992, IEE CONF PUBL, V354, P303
   Mitchell M., 1999, INTRO GENETIC ALGORI, DOI DOI 10.1016/S0898-1221(96)90227-8
   Mohanta RK., 2011, INT J COMPUT TECHNOL, V3, P720, DOI DOI 10.1109/JSTARS.2012.2182760
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Muthukannan K, 2018, MULTIMED TOOLS APPL, V77, P24387, DOI 10.1007/s11042-018-5710-5
   Nor Hazlyna Harun, 2010, 2010 10th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA 2010), P749, DOI 10.1109/ISSPA.2010.5605410
   Pratheba R, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1426, DOI 10.1109/ICCPCT.2014.7054833
   Rathod Arti N., 2013, INT J ADV RES COMPUT, V3
   Rawat S, 2020, ADV FOOD SECUR SUSTA, V5, P119, DOI 10.1016/bs.af2s.2020.08.001
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478
   Senthilkumaran N, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P844, DOI 10.1109/ARTCom.2009.219
   Shedthi BS, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P105, DOI 10.1109/ICICCT.2017.7975168
   Shen C, 2017, VISUAL COMPUT, V33, P1373, DOI 10.1007/s00371-016-1325-x
   Singh Vijai, 2017, Information Processing in Agriculture, V4, P41, DOI 10.1016/j.inpa.2016.10.005
   Singh V, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTER ENGINEERING AND APPLICATIONS (ICACEA), P1028, DOI 10.1109/ICACEA.2015.7164858
   Srinivasa Reddy A., 2016, INT J SIGNAL PROCESS, V9, P177
   Suarez AJB, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/6600049
   Tuba Eva, 2017, WSEAS Transactions on Information Science and Applications, V14, P31
   Vibhute A., 2012, International Journal of Computer Applications, V52, DOI DOI 10.5120/8176-1495
   Woods Keri, 2007, GENETIC ALGORITHMS C
   Xian-feng Wang, 2019, Intelligent Computing Theories and Application. 15th International Conference, ICIC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11643), P646, DOI 10.1007/978-3-030-26763-6_62
   Yimyam P., 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P458, DOI 10.1109/ROBIO.2012.6491009
   Zhang SW, 2019, NEURAL COMPUT APPL, V31, P1225, DOI 10.1007/s00521-017-3067-8
NR 52
TC 0
Z9 0
U1 3
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32349
EP 32372
DI 10.1007/s11042-023-14751-0
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943163700007
DA 2024-07-18
ER

PT J
AU Su, ZB
   Luo, JQ
   Wang, Y
   Kong, QM
   Dai, BS
AF Su, Zhongbin
   Luo, Jiaqi
   Wang, Yue
   Kong, Qingming
   Dai, Baisheng
TI Comparative study of ensemble models of deep convolutional neural
   networks for crop pests classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crop pest classification; Linear and nonlinear; Ensemble model
ID RECOGNITION
AB Pest infestations on wheat, corn, soybean, and other crops can cause substantial losses to their yield. Classification of crop pests is of considerable importance for accurate and intelligent pest control. Ensemble models can effectively improve the accuracy of crop pests classification and different ensemble models can produce different results. To study the advantages and disadvantages of ensemble models under different agricultural production environments, six basic models are trained on a D0 dataset. Then, three models with the best classification performance are selected. Finally, the ensemble models, i.e., linear ensemble named SAEnsemble and nonlinear ensemble SBPEnsemble, are designed to combine the basic models for crop pests classification. The accuracies of SAEnsemble and SBPEnsemble improved by 0.85% and 1.49% respectively compared to the basic model with the highest accuracy. Comparison of the two proposed ensemble models shows that the accuracy of SAEnsemble is lower when the pests are very similar to the background, while SBPEnsemble is more likely to make wrong predictions under the condition of huge difference between pests and background. Therefore, in practical agricultural production, choosing linear or nonlinear ensemble methods according to different situations can effectively improve the accuracy of crop pests classification.
C1 [Su, Zhongbin; Luo, Jiaqi; Wang, Yue; Kong, Qingming; Dai, Baisheng] Northeast Argicultural Univ, Coll Elect Engn & Informat, Harbin, Peoples R China.
RP Kong, QM (corresponding author), Northeast Argicultural Univ, Coll Elect Engn & Informat, Harbin, Peoples R China.
EM kkqqmmmm@126.com; bsdai@neau.edu.cn
FU Science and Technology Innovation 2030- "New Generation of Artificial
   Intelligence" major project [2021ZD0110904]; University Nursing Program
   [UNPYSCT]
FX This work was supported in part by the Science and Technology Innovation
   2030- "New Generation of Artificial Intelligence" major project
   (No.2021ZD0110904) and the University Nursing Program for Young Scholars
   with Creative Talents in Heilongjiang Province (No.UNPYSCT-2020091).
CR Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Barbedo JGA, 2018, COMPUT ELECTRON AGR, V153, P46, DOI 10.1016/j.compag.2018.08.013
   Ayan E, 2020, COMPUT ELECTRON AGR, V179, DOI 10.1016/j.compag.2020.105809
   Breitenreiter A., 2015, NATURE, V521, P2015
   Buiu C, 2020, PROCESSES, V8, DOI 10.3390/pr8050595
   Chao XF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104614
   Deng LM, 2018, BIOSYST ENG, V169, P139, DOI 10.1016/j.biosystemseng.2018.02.008
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fina F, 2013, INT J ADV BIOTECHNOL, V4, P189
   Forrest N., 2016, ARXIV
   Gandhi R., 2018, P 2018 IEEE INT C IN, P1, DOI 10.1109/ICIRD.2018.8376321
   Guan Q, 2019, ANN TRANSL MED, V7, DOI 10.21037/atm.2019.06.29
   Hanin B, 2019, MATHEMATICS-BASEL, V7, DOI 10.3390/math7100992
   Herrnson PS, 2019, POLIT BEHAV, V41, P871, DOI 10.1007/s11109-018-9474-4
   Kang ZF, 2019, KNOWL-BASED SYST, V176, P133, DOI 10.1016/j.knosys.2019.03.024
   Lee SH, 2020, PLANT PATHOL, V69, P1731, DOI 10.1111/ppa.13251
   Liu K, 2020, IEEE J-STARS, V13, P4738, DOI 10.1109/JSTARS.2020.3017676
   [孟琭 Meng Lu], 2020, [电子学报, Acta Electronica Sinica], V48, P1769
   Nanni L, 2020, ECOL INFORM, V57, DOI 10.1016/j.ecoinf.2020.101089
   Rahman CR, 2020, BIOSYST ENG, V194, P112, DOI 10.1016/j.biosystemseng.2020.03.020
   Rajinikanth V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103429
   Rangarajan AK, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59108-x
   Ren FJ, 2019, IEEE ACCESS, V7, P122758, DOI 10.1109/ACCESS.2019.2938194
   Taylor ME, 2009, J MACH LEARN RES, V10, P1633
   Thenmozhi K, 2019, COMPUT ELECTRON AGR, V164, DOI 10.1016/j.compag.2019.104906
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang FY, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105222
   Webb GI, 2004, IEEE T KNOWL DATA EN, V16, P980, DOI 10.1109/TKDE.2004.29
   Wen L, 2020, NEURAL COMPUT APPL, V32, P6111, DOI 10.1007/s00521-019-04097-w
   Xia ZF, 2022, PROC CVPR IEEE, P4784, DOI 10.1109/CVPR52688.2022.00475
   Xiang Y, 2000, PHYS REV E, V62, P4473, DOI 10.1103/PhysRevE.62.4473
   Xie CJ, 2018, COMPUT ELECTRON AGR, V152, P233, DOI 10.1016/j.compag.2018.07.014
   Zhang Q., 2018, Chongqing Daxue Xuebao/J. Chongqing Univ. Nat. Sci. Ed., DOI [10.11835/j.issn.1000-582X.2018.05.011, DOI 10.11835/J.ISSN.1000-582X.2018.05.011]
   Zhao YF, 2020, IEEE ACCESS, V8, P144205, DOI 10.1109/ACCESS.2020.3014508
NR 34
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 19
BP 29567
EP 29586
DI 10.1007/s11042-023-14884-2
EA MAR 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HU0F0
UT WOS:000941926100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Souyah, A
AF Souyah, Amina
TI Multimedia contents confidentiality preservation in constrained
   environments: a dynamic approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; 2D cellular automata; Internet of things (IoT); Boolean
   functions; Discrete dynamical systems image encryption
ID SECURE CIPHER SCHEME; IMAGE ENCRYPTION; CELLULAR-AUTOMATA; EFFICIENT;
   ALGORITHM; INTERNET
AB A novel image cryptographic scheme is introduced in this paper. The proposed method incorporates two modules: confusion module and diffusion module. A dynamic key, changed for every input image is generated, and employed as a base to produce sub-keys in both confusion and diffusion mechanisms. This dynamics conducted to random-like key-generation, rendered the cryptographic scheme with dynamic encryption structure, and hence only one round is needed to achieve good combination between efficient time-consuming and sufficient security. In the confusion module, pixels' positions are non-linearly first forwardly permuted and then backwardly permuted, without changing their values, aiming to de-correlate the relations among neighboring pixels. In the diffusion module, pixels' values are changed, firstly discrete dynamical system with delay defined by non-linear boolean function is employed, in which each pixel value is non-linearly modified to achieve the mixing effect of pixel value and introduce more the non-linearity property, and then memory reversible two-dimensional cellular automata is performed, in which each pixel value is sequentially modified to further attain high diffusion mechanism. We have conducted the most important experiments to assess the effectiveness of the proposed cryptographic scheme. The obtained results are interesting in terms of security degrees and time-consuming, and point to the advocacy of proposal and its suitability to be a good encryption candidate for constrained environments.
C1 [Souyah, Amina] Ecole Super Informat, LabRi Lab, Sidi Bel Abbes, Algeria.
RP Souyah, A (corresponding author), Ecole Super Informat, LabRi Lab, Sidi Bel Abbes, Algeria.
EM a.souyah@esi-sba.dz
CR Almalkawi IT, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102384
   Amina S, 2018, COMMUN NONLINEAR SCI, V60, P12, DOI 10.1016/j.cnsns.2017.12.017
   Bakoev V., 2017, Serdica J. Comput., V11, P45
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Faraoun KM, 2017, MULTIMED TOOLS APPL, V76, P6247, DOI 10.1007/s11042-016-3317-2
   Fawaz Z, 2018, MULTIMEDIA SYST, V24, P669, DOI 10.1007/s00530-018-0591-z
   Fawaz Z, 2016, SIGNAL PROCESS-IMAGE, V42, P90, DOI 10.1016/j.image.2016.01.009
   Encinas LH, 2018, TURK J MATH, V42, P57, DOI 10.3906/mat-1607-22
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Javeed A, 2020, CHINESE J PHYS, V66, P645, DOI 10.1016/j.cjph.2020.04.008
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Li JQ, 2022, MULTIMED TOOLS APPL, V81, P44335, DOI 10.1007/s11042-022-12736-z
   Lv XP, 2018, MULTIMED TOOLS APPL, V77, P28633, DOI 10.1007/s11042-018-6013-6
   del Rey AM, 2015, LOG J IGPL, V23, P485, DOI 10.1093/jigpal/jzv013
   del Rey AM, 2015, EXPERT SYST APPL, V42, P2114, DOI 10.1016/j.eswa.2014.10.035
   Michael F, 2012, IMAGE ENCRYPTION ALG
   Munir N, 2021, IEEE ACCESS, V9, P105678, DOI 10.1109/ACCESS.2021.3099004
   Noura H, 2019, MULTIMED TOOLS APPL, V78, P16527, DOI 10.1007/s11042-018-7000-7
   Noura H, 2019, INT J BIFURCAT CHAOS, V29, DOI 10.1142/S0218127419500597
   Noura H, 2018, MULTIMED TOOLS APPL, V77, P18383, DOI 10.1007/s11042-018-5660-y
   Noura HN, 2019, SIGNAL PROCESS-IMAGE, V78, P448, DOI 10.1016/j.image.2019.08.005
   Noura HN, 2019, MULTIMED TOOLS APPL, V78, P14837, DOI 10.1007/s11042-018-6845-0
   Roy S, 2021, J INF SECUR APPL, V61, DOI 10.1016/j.jisa.2021.102919
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   SMID ME, 1988, P IEEE, V76, P550, DOI 10.1109/5.4441
   Souyah A, 2016, NONLINEAR DYNAM, V86, P639, DOI 10.1007/s11071-016-2912-0
   Souyah A, 2016, NONLINEAR DYNAM, V84, P715, DOI 10.1007/s11071-015-2521-3
   Su YR, 2019, SIGNAL PROCESS-IMAGE, V72, P134, DOI 10.1016/j.image.2018.12.008
   Tsafack N, 2020, IEEE ACCESS, V8, P137731, DOI 10.1109/ACCESS.2020.3010794
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   von Neumann J., 1966, Theory of Self-Reproducing Automata
   Wang XY, 2019, INFORM SCIENCES, V486, P340, DOI 10.1016/j.ins.2019.02.049
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wolfram S., 2002, A new kind of science
   Wu XL, 2017, IEEE ACCESS, V5, P6429, DOI 10.1109/ACCESS.2017.2692043
   Yavuz E, 2021, J INF SECUR APPL, V63, DOI 10.1016/j.jisa.2021.103056
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang MW, 2019, PROCEEDINGS OF THE 2ND INTERNATIONAL ACM WORKSHOP ON SECURITY AND PRIVACY FOR THE INTERNET-OF-THINGS (IOT S&P'19), P38, DOI 10.1145/3338507.3358620
NR 39
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21775
EP 21800
DI 10.1007/s11042-023-14863-7
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000940065100011
DA 2024-07-18
ER

PT J
AU Nam, S
   Choi, J
AF Nam, SangHun
   Choi, JongIn
TI Development of a user evaluation system in virtual reality based on
   eye-tracking technology
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Eye tracking; User experience; Game engine
ID SPACE; TIME
AB This study proposes a user evaluation system based on a game engine, in which a user can measure their area or object of interest using an eye-tracking device. Eye tracking technology, which is widely used in various sectors such as human-computer interaction, user experience, and marketing research, measures the intentions of a human gazing on a part of their interest. However, creating a real-world test environment and model for user evaluation requires considerable time and money. Therefore, studies on user evaluation tests using virtual reality (VR) are being actively conducted. The VR user evaluation system based on the eye-tracking device proposed in this study was studied and developed using the unity game engine and an HTC VIVE Pro eye, in which an eye-tracking device was built in the head-mounted display. To make it appropriate for a VR environment, an eye-tracking algorithm was developed, and object- and surface-based eye-tracking and visualization technologies were applied. Moreover, the algorithm was developed to support component-based programming, so that an investigator can easily establish a test environment.
C1 [Nam, SangHun] Changwon Natl Univ, Dept Culture Technol, Changwon Si, Gyeongsangnam D, South Korea.
   [Choi, JongIn] Seoul Womens Univ, Dept Digital Media Design & Applicat, Seoul, South Korea.
C3 Changwon National University; Seoul Women's University
RP Nam, S (corresponding author), Changwon Natl Univ, Dept Culture Technol, Changwon Si, Gyeongsangnam D, South Korea.
EM sanghunnam@changwon.ac.kr; funtech@swu.ac.kr
OI Nam, SangHun/0000-0003-4634-9948
FU Institute of Information and Communications Technology Planning and
   Evaluation (IITP) - Korean government (MSIT) [.2021-0-00986]; National
   Research Foundation of Korea (NRF) - Ministry of Education
   [NRF-2020R1I1A3051739]
FX This research was supported by the Institute of Information and
   Communications Technology Planning and Evaluation (IITP), grant funded
   by the Korean government (MSIT) (No.2021-0-00986, Development of
   Interaction Technology to Maximize Realization of Virtual Reality
   Contentsusing Multimodal Sensory Interface) and by the Basic Science
   Research Program through the National Research Foundation of Korea (NRF)
   funded by the Ministry of Education (NRF-2020R1I1A3051739).
CR Andrienko G, 2010, INT J GEOGR INF SCI, V24, P1577, DOI 10.1080/13658816.2010.508043
   [Anonymous], 2015, P WORKSHOP EYE TRACK
   Blascheck T, 2017, COMPUT GRAPH FORUM, V36, P260, DOI 10.1111/cgf.13079
   Bulling A, 2010, IEEE PERVAS COMPUT, V9, P8, DOI 10.1109/MPRV.2010.86
   Duchowski A. T., 2017, EYE TRACKING METHODO
   Fortun Denis, 2015, Computer Vision and Image Understanding, V134, P1, DOI 10.1016/j.cviu.2015.02.008
   Gibson I., 2004, International Journal of Manufacturing Technology and Management, V6, P503, DOI 10.1504/IJMTM.2004.005931
   Haro A, 2000, PROC CVPR IEEE, P163, DOI 10.1109/CVPR.2000.855815
   Hickson S, 2019, IEEE WINT CONF APPL, P1626, DOI 10.1109/WACV.2019.00178
   Jacob RJK, 2003, MIND'S EYE: COGNITIVE AND APPLIED ASPECTS OF EYE MOVEMENT RESEARCH, P573, DOI 10.1016/B978-044451020-4/50031-1
   Khushaba RN, 2013, EXPERT SYST APPL, V40, P3803, DOI 10.1016/j.eswa.2012.12.095
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Kurzhals K, 2013, IEEE T VIS COMPUT GR, V19, P2129, DOI 10.1109/TVCG.2013.194
   Li Dongheng, 2005, IEEE COMP SOC C COMP, P79, DOI [10.1109/CVPR.2005.531, DOI 10.1109/CVPR.2005.531]
   Majaranta P., 2014, ADV PHYSL COMPUTING, P39, DOI DOI 10.1007/978-1-4471-6392-3_3
   Muller Mathias, 2016, Virtual, Augmented and Mixed Reality. 8th International Conference, VAMR 2016, held as part of HCI International 2016. Proceedings: LNCS 9740, P47, DOI 10.1007/978-3-319-39907-2_5
   Patney A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980246
   Pfeiffer J, 2020, INFORM SYST RES, V31, P675, DOI 10.1287/isre.2019.0907
   Scott N, 2019, CURR ISSUES TOUR, V22, P1244, DOI 10.1080/13683500.2017.1367367
   Stellmach Sophie., 2010, P INT C ADV VISUAL I, P345, DOI DOI 10.1145/1842993.1843058
   Sundstedt Veronica, 2016, SIGGRAPH ASIA 2016 Courses, P1
   Zhang LM, 2018, LEARNING ADAPTING PR, P431
   Zheng WL, 2014, IEEE ENG MED BIO, P5040, DOI 10.1109/EMBC.2014.6944757
NR 23
TC 1
Z9 1
U1 21
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 21117
EP 21130
DI 10.1007/s11042-023-14583-y
EA FEB 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000934850300002
DA 2024-07-18
ER

PT J
AU Chrysafiadi, K
   Kamitsios, M
   Virvou, M
AF Chrysafiadi, Konstantina
   Kamitsios, Margaritis
   Virvou, Maria
TI Fuzzy-based dynamic difficulty adjustment of an educational 3D-game
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic difficulty adjustment; Educational game; Engagement; Fuzzy
   logic; Serious game
ID ADAPTATION; GAMES; LOGIC
AB An educational game aims to employ the pleasant and fascinating environment of a game for educational purpose. However, when the game's educational content or playing environment does not match with the player's learning needs or game-playing skills, the player can find the game either too easy or too difficult and decide to drop it. Therefore, a successful educational game has to offer Dynamic Difficulty Adjustment (DDA) of both the game's educational content and the game's playing environment. Considering the above, in this paper a fuzzy-based DDA mechanism of a 3D-game, that teaches the programming language 'HTML', is presented. The game adapts dynamically the difficulty of battles and mazes navigation to each individual player's skills. The novelty of the presented game lies on the application of DDA in the two dimensions (educational content and playing environment) of an educational game and on the use of fuzzy logic for succeeding balance between the game's difficulty and the user's playing skills. The adaptation is realized in real-time, during the playing and not each time the player changes game level/track. Furthermore, fuzzy logic allows to apply DDA without the need of many learning data, like other Artificial Intelligence techniques for DDA (i.e. machine learning techniques). The presented game was evaluated through a comparative evaluation, which included questionnaires, an experiment in real conditions and t-test statistical analysis method. The evaluation results showed that the incorporated adaptation mechanism increases the user's motivation and succeeds to keep players' interest for the game undiminished.
C1 [Chrysafiadi, Konstantina; Kamitsios, Margaritis; Virvou, Maria] Univ Piraeus, Dept Informat, Software Engn Lab, Greece 80,M Karaoli & A Dimitriou St, Piraeus 18534, Greece.
C3 University of Piraeus
RP Chrysafiadi, K (corresponding author), Univ Piraeus, Dept Informat, Software Engn Lab, Greece 80,M Karaoli & A Dimitriou St, Piraeus 18534, Greece.
EM kchrysafiadi@unipi.gr; mkamitsios@unipi.gr; mvirvou@unipi.gr
RI VIRVOU, Maria/AAR-1415-2021
OI VIRVOU, MARIA/0000-0002-4008-4654
FU HEAL-Link Greece
FX Open access funding provided by HEAL-Link Greece.
CR [Anonymous], 2009, SPSS 17 0 STAT PROCE
   Capuano N, 2015, INT C INTELLIGENT NE
   Carver RH., 2009, DOING DATA ANAL SPSS
   Chrysafiadi K, 2013, COMPUT EDUC, V68, P322, DOI 10.1016/j.compedu.2013.05.020
   Demediuk Simon, 2017, 2017 IEEE Conference on Computational Intelligence and Games (CIG), P53, DOI 10.1109/CIG.2017.8080415
   Demediuk Simon., 2018, PLAYER RETENTION LEA, P1, DOI DOI 10.1145/3167918.3167937
   Denisova Alena., 2015, P 2015 ANN S COMPUTE, P97
   Dziedzic D, 2018, INT J HUM-COMPUT INT, V34, P707, DOI 10.1080/10447318.2018.1461764
   Frommel J, 2018, PROCEEDINGS OF THE 2018 ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY (CHI PLAY 2018), P163, DOI 10.1145/3242671.3242682
   Glavin F.G., 2018, 2018 IEEE Conference on Computational Intelligence and Games (CIG), P1, DOI DOI 10.1109/CIG.2018.8490405
   Hamdaoui N, 2018, SIMULAT GAMING, V49, P675, DOI 10.1177/1046878118783804
   Hendrix M, 2018, IEEE T GAMES
   Hocine N, 2015, USER MODEL USER-ADAP, V25, P65, DOI 10.1007/s11257-015-9154-6
   Hunicke Robin, 2005, P ACE 2005, P429, DOI DOI 10.1145/1178477.1178573
   Hunicke Robin., 2004, Challenges in Game Artificial Intelligence AAAI Workshop, P91, DOI [10.1145/1178477.1178573, DOI 10.1145/1178477.1178573]
   Koster Raph., 2014, THEORY FUN GAME DESI
   Lach E, 2017, INT C ARTIFICIAL INT
   Lindberg RSN, 2017, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON COMPUTER SUPPORTED EDUCATION (CSEDU), VOL 1, P450, DOI 10.5220/0006350304500457
   Mees M., 2018, EUROPEAN C GAMES BAS
   Missura O., 2011, Advances in Neural Information Processing Systems, P2007
   Mostefai B, 2019, COGN SYST RES, V56, P82, DOI 10.1016/j.cogsys.2019.03.006
   Papadimitriou S., 2017, INT C INFORM INTELLI, P1, DOI 10.1109/iisa.2017.8316453
   Papadimitriou S, 2019, MULTIMED TOOLS APPL, V78, P32023, DOI 10.1007/s11042-019-07955-w
   Alvarado-Magaña JP, 2013, STUD COMPUT INTELL, V451, P501
   Pirovano M., 2012, IEEE Computational Intelligence and Games, P179, DOI DOI 10.1109/CIG.2012.6374154
   Polycarpou I, 2010, PROCD SOC BEHV, V9, DOI 10.1016/j.sbspro.2010.12.246
   Rogers K, 2016, CHI PLAY 2016: PROCEEDINGS OF THE ANNUAL SYMPOSIUM ON COMPUTER-HUMAN INTERACTION IN PLAY COMPANION, P269, DOI 10.1145/2968120.2987725
   Salah J., 2018, P 17 INT C MOB UB MU, P215
   Streicher A, 2016, LECT NOTES COMPUT SC, V9970, P332, DOI 10.1007/978-3-319-46152-6_14
   Tsatsou D, 2019, J COMPUT EDUC, V6, P215, DOI 10.1007/s40692-018-0118-9
   Vahldick A, 2017, L N INST COMP SCI SO, V4
   Virvou M, 2005, EDUC TECHNOL SOC, V8, P54
   Virvou M, 2004, LECT NOTES COMPUT SC, V3038, P962
   Xue S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P465, DOI 10.1145/3041021.3054170
   Zadeh LA, 1996, IEEE T FUZZY SYST, V4, P103, DOI 10.1109/91.493904
   Zohaib M, 2018, ADV HUM-COMPUT INTER, V2018, DOI 10.1155/2018/5681652
NR 36
TC 2
Z9 2
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 18
BP 27525
EP 27549
DI 10.1007/s11042-023-14515-w
EA FEB 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA L4OB9
UT WOS:000939670800008
OA hybrid
DA 2024-07-18
ER

PT J
AU Suji, RJ
   Bhadauria, SS
   Godfrey, WW
   Dhar, J
AF Suji, R. Jenkin
   Bhadauria, Sarita Singh
   Godfrey, W. Wilfred
   Dhar, Joydip
TI On using a Particle Image Velocimetry based approach for candidate
   nodule detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle Image Velocimetry; Candidate nodule detection; Computed
   Tomography; Dicom slices
ID AUTOMATIC DETECTION; PULMONARY NODULES; LUNG NODULES; CT IMAGES;
   SEGMENTATION; MODEL
AB Detection and segmentation of candidate lung nodules from diagnostic images are vital steps in any image processing-based Computer-Aided Diagnostic (CAD) system for lung cancer. Computed Tomography (CT) is a commonly used modality for lung cancer screening due to the tissue contrast and anatomical resolution. This work aims to investigate the effectiveness of Particle Image Velocimetry, PIV, as a preprocessing tool for processing the input data frames. This is done by applying PIV processing to the input images and quantifying the nodules detected over a morphology-based image processing pipeline. Further, PIV processed images and images without PIV processing were input to the Convolution-based deep learning framework, and the candidate nodule detection effect was quantified and compared. The results validate the efficacy of the proposed workflow for candidate nodule detection both in the image processing pipeline and in the deep learning-based framework. Further, the work also presents the utility of the proposed preprocessing scheme through its ability to detect candidate nodules comprising the major nodule types, namely juxta-pleural, juxta-vascular, isolated, and ground-glass opacity nodules.
C1 [Suji, R. Jenkin; Godfrey, W. Wilfred; Dhar, Joydip] ABV IIITM, Gwalior, India.
   [Bhadauria, Sarita Singh] RGPV, Bhopal, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   Rajiv Gandhi Technological University
RP Suji, RJ (corresponding author), ABV IIITM, Gwalior, India.
EM sujijenkin@gmail.com
RI Dhar, Joydip/L-6769-2013
FU Kiran Division, Department of Science and Technology, Govt. of India
   [SR/WOSA/ET-153/2017]
FX The authors would like to acknowledge the Kiran Division, Department of
   Science and Technology, Govt. of India, for funding this research work
   through the SR/WOSA/ET-153/2017 Research Grant. The authors also thank
   the anonymous reviewers for their encouraging reviews and
   recommendations.
CR Abe Haruhiko, 2018, 2018 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2018.8579664
   Adrian RJ, 2011, Particle image velocimetry
   Aresta G, 2017, PROC SPIE, V10134, DOI 10.1117/12.2252022
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Badura P, 2008, ADV INTEL SOFT COMPU, V47, P192
   Barbu I, 2011, FORUM RECENT DEV REC
   Cavalcanti PG, 2016, QUANT IMAG MED SURG, V6, P16, DOI 10.3978/j.issn.2223-4292.2016.02.06
   Dhara AK, 2012, IETE TECH REV, V29, P265, DOI 10.4103/0256-4602.101306
   Edwards M, 2021, THESIS U BRISTOL
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Firmino M, 2016, BIOMED ENG ONLINE, V15, DOI 10.1186/s12938-015-0120-7
   Garcia JL, 2016, PHILOS ENG TECHNOL, V27, P1, DOI 10.1007/978-3-319-45538-9_1
   Gonçalves L, 2016, EXPERT SYST APPL, V61, P1, DOI 10.1016/j.eswa.2016.05.024
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jacobs C, 2014, MED IMAGE ANAL, V18, P374, DOI 10.1016/j.media.2013.12.001
   Javaid M, 2016, COMPUT METH PROG BIO, V135, P125, DOI 10.1016/j.cmpb.2016.07.031
   Joshi S R., 2009, J. Inst. Eng, V7, P6, DOI [10.3126/jie.v7i1.2057, DOI 10.3126/JIE.V7I1.2057]
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mansoor A, 2015, RADIOGRAPHICS, V35, P1056, DOI 10.1148/rg.2015140232
   Mukhopadhyay S, 2016, J DIGIT IMAGING, V29, P86, DOI 10.1007/s10278-015-9801-9
   Nagargoje M, 2017, INTRO PARTICLE IMAGE
   Naqi SM, 2018, INT J COMPUT ASS RAD, V13, P1083, DOI 10.1007/s11548-018-1715-9
   Nithila EE, 2019, BIOMED SIGNAL PROCES, V47, P57, DOI 10.1016/j.bspc.2018.08.008
   Olejniczak K.J., 2000, The Transforms and Applications Handbook, P281
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saien S, 2014, COMPUT BIOL MED, V54, P188, DOI 10.1016/j.compbiomed.2014.09.010
   Schroder AWillert C E., 2008, PARTICLE IMAGE VELOC
   Schultheiss M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-69789-z
   Setio AAA, 2015, MED PHYS, V42, P5642, DOI 10.1118/1.4929562
   Setio AAA, 2017, MED IMAGE ANAL, V42, P1, DOI 10.1016/j.media.2017.06.015
   Shaukat F, 2017, MED PHYS, V44, P3615, DOI 10.1002/mp.12273
   Suji R.J., 2019, INT C COMP VIS IM PR, P261
   Suji RJ, 2020, J DIGIT IMAGING, V33, P1306, DOI 10.1007/s10278-020-00346-w
   Tarashima Shuhei., 2010, 15 INT S APPL LASER
   Voorneveld J, 2019, CIRC-CARDIOVASC IMAG, V12, DOI 10.1161/CIRCIMAGING.119.008856
   Wang S, 2017, IEEE ENG MED BIO, P1752, DOI 10.1109/EMBC.2017.8037182
   Wang S, 2017, MED IMAGE ANAL, V40, P172, DOI 10.1016/j.media.2017.06.014
NR 37
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22871
EP 22888
DI 10.1007/s11042-023-14493-z
EA FEB 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000937945000003
DA 2024-07-18
ER

PT J
AU Sharath, MN
   Rajesh, TM
   Patil, M
AF Sharath, M. N.
   Rajesh, T. M.
   Patil, Mallanagouda
TI A novel encryption with bacterial foraging optimization algorithm based
   pixel selection scheme for video steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Video steganography; PNSR; Optimal pixel selection;
   Encryption; Embedding process; The extraction process
ID IMAGES
AB In the digital era, security is a challenging problem due to the drastic increase in the utilization of the Internet, personal computers, smartphones, etc. for communication purposes. A major issue in the data hiding process lies in the way of embedding the secure data by maintaining the quality of a cover object that necessitates complex techniques that conceal a massive quantity of payload and the robustness of these approaches over hackers. Video steganography is considered an effective way of securing data transmission, which encompasses two processes namely embedding and extraction. Several existing video steganography techniques hide the secret message with no selection of optimal pixels where the proper choice of pixels to hide data helps to improve quality and robustness. Therefore, this article introduces novel encryption with bacterial foraging optimization algorithm-based pixel selection scheme for video steganography (EBFOA-PSVS) technique. The hidden message will be successfully concealed in the cover video utilizing the proposed EBFOA-PSVS technique, which also uses the best possible BFOA pixel selection. The best pixels are then chosen using BFOA to produce the highest peak signal-to-noise ratio (PSNR). Finally, the cover video contains the hidden image that has been encrypted. The EBFOA-PSVS approach has improved in terms of various parameters, according to a thorough comparison investigation of the findings on benchmark test movies.
C1 [Sharath, M. N.] Dayanada Sagar Univ, Rajeev Inst Technol, Hassan, India.
   [Rajesh, T. M.] Dayananda Sagar Univ, Dept Comp Sci & Engn, Bengaluru, India.
   [Patil, Mallanagouda] RVITM, Dept Comp Sci & Engn, Bengaluru, India.
RP Sharath, MN (corresponding author), Dayanada Sagar Univ, Rajeev Inst Technol, Hassan, India.
EM sharathmn.res-soe-cse@dsu.edu.in; rajesh-cse@dsu.edu.in;
   mallanagoudap.rvitm@rvei.edu.in
RI T M, Dr. Rajesh/AAU-3185-2021
OI T M, Dr. Rajesh/0000-0001-9258-7870; Patil, Dr.
   Mallanagouda/0009-0009-3795-0919
CR Beenish M, 2008, IEEE INT S BIOM SEC, P1
   Bhardwaj R, 2016, PROCEDIA COMPUT SCI, V93, P832, DOI 10.1016/j.procs.2016.07.245
   Cataltas O, 2017, 2017 INT ART INT DAT, P1, DOI [10.1109/IDAP.2017.8090342, DOI 10.1109/IDAP.2017.8090342]
   Celik M, 2002, INT C IMAGE PROCESSI
   Chaudhary A, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON VISION, IMAGE AND SIGNAL PROCESSING (ICVISP 2018), DOI 10.1145/3271553.3271588
   Chen HL, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105884
   Cyril CPD, 2021, CONCURRENT ENG-RES A, V29, P386, DOI 10.1177/1063293X211031485
   Dixit M, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Gowshika U., 2015, INT J APPL ENG RES, V10, P8125
   Ibrahim A, 2022, ENERGIES, V15, DOI 10.3390/en15041488
   Jose A, 2020, MATER TODAY-PROC
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Liu YX, 2019, NEUROCOMPUTING, V335, P238, DOI 10.1016/j.neucom.2018.09.091
   Manisha S, 2019, MULTIDIM SYST SIGN P, V30, P529, DOI 10.1007/s11045-018-0568-2
   Mstafa RJ, 2014, 2014 IEEE LONG ISLAND SYSTEMS, APPLICATIONS AND TECHNOLOGY CONFERENCE (LISAT)
   Neelakandan S, 2021, SOFT COMPUT, V25, P12241, DOI 10.1007/s00500-021-05896-x
   Neelakandan S, 2021, J AMB INTEL HUM COMP, V12, P4979, DOI 10.1007/s12652-020-01937-9
   Nipanikar SI., 2017, ALEX ENG J, V77, P26135
   Ntalianis K, 2016, IEEE T EMERG TOP COM, V4, P156, DOI 10.1109/TETC.2015.2400135
   Parah SA, 2014, COMPUT ELECTR ENG, V40, P70, DOI 10.1016/j.compeleceng.2013.11.006
   Passino KM, 2010, INT J SWARM INTELL R, V1, P1, DOI 10.4018/jsir.2010010101
   Rajalakshmi K, 2018, MULTIMED TOOLS APPL, V77, P27427, DOI 10.1007/s11042-018-5930-8
   Ramalingam M, 2016, COMPUT ELECTR ENG, V54, P423, DOI 10.1016/j.compeleceng.2015.10.005
   Roselinkiruba R., 2021, International Journal of Information Technology, V13, P1797, DOI 10.1007/s41870-021-00774-z
   Sharath M. N., 2022, International Journal of Information Technology, V14, P2265, DOI 10.1007/s41870-022-01005-9
   Suresh M, 2022, J KING SAUD UNIV-COM, V34, P3489, DOI 10.1016/j.jksuci.2020.08.007
   Vital-Soto A, 2020, J MANUF SYST, V54, P74, DOI 10.1016/j.jmsy.2019.11.010
   Younus ZS, 2020, J INTELL SYST, V29, P1216, DOI 10.1515/jisys-2018-0225
   US
NR 31
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25197
EP 25216
DI 10.1007/s11042-023-14420-2
EA FEB 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000931739200002
DA 2024-07-18
ER

PT J
AU Sehar, EU
   Selwal, A
   Sharma, D
AF Sehar, Eain Ul
   Selwal, Arvind
   Sharma, Deepika
TI FinCaT: a novel approach for fingerprint template protection using
   quadrant mapping via non-invertible transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancellable biometrics; Template attacks; Template protection;
   Fingerprint; Quadrant mapping
ID SECURITY; MINUTIAE; ROBUST; BIOMETRICS; PRIVACY
AB The employment of various technologies for secured human authentication in the recent years has led to rapid expansion of biometric-based recognition. Among all biometrics, the fingerprint recognition systems (FRS) hold the largest market share and have been used in numerous computing applications such as forensic, governance, and securing critical infrastructure. Though biometric systems provide plentiful benefits over the traditional identification systems but these are also susceptible to various adversarial attacks. The most crucial among all the attacks involves security breaches of stored templates in a central database that may either degrade the overall performance or result in a complete failure of the FRS. To countermeasure these attacks, template protection mechanisms are designed that mitigate the masquerade attacks or template thefts. In this study, we present a novel cancellable approach for fingerprint template protection (FinCaT) using the novel notion of quadrant mapping via a non-invertible transformation function. Our method transforms original fingerprint templates to highly secured templates by using quadrant mapping that maps minutia points by using distinct parameters in each quadrant. The FinCAT approach yields high revocability and diversity as the compromised template of a genuine user can be replaced with a newly generated secured template. The approach is experimentally evaluated on the FVC 2002 fingerprint benchmark dataset. Our technique demonstrates decent performance in terms of an equal error rate (EER) of 5.95% and a recognition accuracy of 94.05%, which is promising as compared to similar state-of-the art template protection techniques.
C1 [Sehar, Eain Ul; Selwal, Arvind; Sharma, Deepika] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Jammu 181143, Jammu & Kashmir, India.
C3 Central University of Jammu
RP Sehar, EU (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Jammu 181143, Jammu & Kashmir, India.
EM eaini97@gmail.com
RI Selwal, Arvind/HTR-1625-2023
OI Selwal, Arvind/0000-0002-1075-6966; , Eain Ul Sehar/0000-0003-1931-0546
CR Abdullahi SM, 2020, IEEE T INF FOREN SEC, V15, P2587, DOI 10.1109/TIFS.2020.2971142
   Ajish S, 2023, INT J BIOMETRICS, V15, P78, DOI 10.1504/IJBM.2023.127726
   Ajish S, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2020.101714
   Ali SS, 2020, PATTERN RECOGN LETT, V129, P263, DOI 10.1016/j.patrec.2019.11.037
   Ali SS, 2018, IET BIOMETRICS, V7, P536, DOI 10.1049/iet-bmt.2018.5070
   Atighehchi K, 2019, FUTURE GENER COMP SY, V101, P819, DOI 10.1016/j.future.2019.07.022
   Bedari A, 2021, PATTERN RECOGN, V119, DOI 10.1016/j.patcog.2021.108074
   Cao K, 2015, IEEE T INF FOREN SEC, V10, P104, DOI 10.1109/TIFS.2014.2363951
   Chaurasia P, 2014, BIOMETRICS MINUTIAE
   Ferrara M, 2012, IEEE T INF FOREN SEC, V7, P1727, DOI 10.1109/TIFS.2012.2215326
   Gao QH, 2017, IET BIOMETRICS, V6, P448, DOI 10.1049/iet-bmt.2016.0192
   Jacob IJ, 2021, MULTIMED TOOLS APPL, V80, P7547, DOI 10.1007/s11042-020-10127-w
   Jain AK., 2008, 2008 BIOMETRICS S BS, DOI [10.1007/9780-387-71041-9, DOI 10.1007/9780-387-71041-9]
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jha DP, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P86, DOI 10.1109/ICICCS.2016.7542316
   Jin Z, 2012, EXPERT SYST APPL, V39, P6157, DOI 10.1016/j.eswa.2011.11.091
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Kavati I, 2021, ICT EXPRESS, V7, P497, DOI 10.1016/j.icte.2021.04.001
   Kho JB, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107323
   Kho JB, 2019, PATTERN RECOGN, V91, P245, DOI 10.1016/j.patcog.2019.01.039
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Manzoor SI, 2018, 2018 FIFTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (IEEE PDGC), P306, DOI 10.1109/PDGC.2018.8745722
   Mehmood R, 2020, INT ARAB J INF TECHN, V17, P926, DOI 10.34028/iajit/17/6/11
   Rajan RA, 2019, IEEE INT C INTELLIGE, DOI [10.1109/INCOS45849.2019.8951335, DOI 10.1109/INCOS45849.2019.8951335]
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Ross A, 2005, PROC SPIE, V5779, P68, DOI 10.1117/12.604477
   Sarkar A, 2021, MULTIMED TOOLS APPL, V80, P799, DOI 10.1007/s11042-020-09375-7
   Sehar Eain Ul, 2021, 2021 Fourth International Conference on Computational Intelligence and Communication Technologies (CCICT), P260, DOI 10.1109/CCICT53244.2021.00056
   Selwal A, 2015, 2015 2 INT C REC ADV, P1, DOI 10.1109/RAECS.2015.7453302
   Selwal A, 2017, J INTELL FUZZY SYST, V32, P3325, DOI 10.3233/JIFS-169274
   Selwal A, 2016, PROCEDIA COMPUT SCI, V85, P899, DOI 10.1016/j.procs.2016.05.280
   Shahzad M, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107735
   Sharma D., 2020, RECENT INNOVATIONS C, P701, DOI [10.1007/978-981-15-8297-4_38, DOI 10.1007/978-981-15-8297-4_38]
   Sharma D, 2021, PATTERN RECOGN LETT, V152, P225, DOI 10.1016/j.patrec.2021.10.013
   Sharma D, 2022, MULTIMED TOOLS APPL, V81, P22129, DOI 10.1007/s11042-021-11254-8
   Trivedi AK, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115832
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Trivedi AK, 2018, FORENSIC SCI INT, V288, P256, DOI 10.1016/j.forsciint.2018.04.045
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Wang S, 2017, PATTERN RECOGN, V66, P295, DOI 10.1016/j.patcog.2017.01.019
   Wang S, 2017, PATTERN RECOGN, V61, P447, DOI 10.1016/j.patcog.2016.08.017
   Wong WJ, 2016, PATTERN RECOGN, V51, P197, DOI 10.1016/j.patcog.2015.09.032
   Yang S., 2017, SW RESP CRITICAL CAR, V5, P34, DOI [10.12746/swrccc.v5i19.391, DOI 10.12746/SWRCCC.V5I19.391]
NR 43
TC 1
Z9 1
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 22795
EP 22813
DI 10.1007/s11042-023-14576-x
EA FEB 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000929853100002
DA 2024-07-18
ER

PT J
AU Manocha, A
   Afaq, Y
AF Manocha, Ankush
   Afaq, Yasir
TI Optical and SAR images-based image translation for change detection
   using generative adversarial network (GAN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep adaptation; Deep learning; SAR and optical; GAN; Change detection
AB Monitoring a specific area to analyze a continuous change has become more accessible by using optical images in remote sensing technology. However, several natural and artificial aspects such as fog and air pollution make it difficult to extract correct geometric information. To overcome the limitation of optical images, Synthetic Aperture Radar (SAR) images can be used to access more accurate information with respect to the targeted area. In this manner, optical and SAR images can be utilized together to detect the scale of change even in bad weather conditions. To process optical and SAR images, an image translation process-oriented Deep Adaptation-based Change Detection Technique (DACDT) is proposed. An optimized U-Net++ model is proposed that helps to improve the global and regional impacts of the images. Moreover, a multi-scale loss function is utilized to access the features of different dimensions. In this manner, the final change maps are generated by transferring the features of optical images to the SAR images for better change analysis. The prediction performance of the proposed approach is evaluated on four different datasets such as Gloucester I, Shuguang Village, Gloucester-II, and California. The calculated outcomes define the prediction performance of the proposed solution by registering the accuracy of 98.67%, 99.77%, 97.68%, and 98.87%, respectively.
C1 [Manocha, Ankush; Afaq, Yasir] Lovely Profess Univ, Jalandhar 144411, Punjab, India.
C3 Lovely Professional University
RP Manocha, A (corresponding author), Lovely Profess Univ, Jalandhar 144411, Punjab, India.
EM ankushmanocha31@gmail.com; khyasir2@gmail.com
RI Afaq, Dr. Yasir/AAT-1816-2021; Manocha, Ankush/AEH-9532-2022
OI Afaq, Dr. Yasir/0000-0001-6323-2683; Manocha, Ankush/0000-0001-5054-1655
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Ao DY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101597
   Asokan A, 2019, EARTH SCI INFORM, V12, P143, DOI 10.1007/s12145-019-00380-5
   Ayhan B, 2019, 2019 IEEE 10TH ANNUAL UBIQUITOUS COMPUTING, ELECTRONICS & MOBILE COMMUNICATION CONFERENCE (UEMCON), P192, DOI 10.1109/UEMCON47517.2019.8993038
   Chen R., 2020, PROC IEEECVF C COMPU, P8165, DOI DOI 10.1109/CVPR42600.2020.00819
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Coppin P, 2004, INT J REMOTE SENS, V25, P1565, DOI 10.1080/0143116031000101675
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Dellinger F, 2014, INT GEOSCI REMOTE SE, P1281, DOI 10.1109/IGARSS.2014.6946667
   Deng JS, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101230
   Geng J, 2019, IEEE T GEOSCI REMOTE, V57, P7365, DOI 10.1109/TGRS.2019.2913095
   Giustarini L, 2013, IEEE T GEOSCI REMOTE, V51, P2417, DOI 10.1109/TGRS.2012.2210901
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hou B, 2020, IEEE T GEOSCI REMOTE, V58, P1790, DOI 10.1109/TGRS.2019.2948659
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Lee K, 2018, PROC CVPR IEEE, P3702, DOI 10.1109/CVPR.2018.00390
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu Z, 2018, IEEE T IMAGE PROCESS, V27, P1822, DOI 10.1109/TIP.2017.2784560
   Longbotham N, 2012, IEEE J-STARS, V5, P331, DOI 10.1109/JSTARS.2011.2179638
   Luppino LT, 2019, ARXIV
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mercier G, 2008, IEEE T GEOSCI REMOTE, V46, P1428, DOI 10.1109/TGRS.2008.916476
   Mignotte M, 2020, IEEE T GEOSCI REMOTE, V58, P8046, DOI 10.1109/TGRS.2020.2986239
   Mubea K, 2012, MONITORING LAND USE
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Planinsic P, 2018, IEEE GEOSCI REMOTE S, V15, P297, DOI 10.1109/LGRS.2017.2786344
   Prendes J, 2015, IEEE T IMAGE PROCESS, V24, P799, DOI 10.1109/TIP.2014.2387013
   Rahman MM, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1682-y
   Saha S, 2018, PROC SPIE, V10789, DOI 10.1117/12.2325149
   Shang RH, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105542
   Shi Q, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3085870
   Shi Q, 2020, IEEE GEOSCI REMOTE S, V17, P1430, DOI 10.1109/LGRS.2019.2947473
   SINGH A, 1989, INT J REMOTE SENS, V10, P989, DOI 10.1080/01431168908903939
   Sun YL, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3053571
   Sun YL, 2021, IEEE T GEOSCI REMOTE, V59, P4841, DOI 10.1109/TGRS.2020.3013673
   Touati R, 2020, IEEE T IMAGE PROCESS, V29, P757, DOI 10.1109/TIP.2019.2933747
   Turnes JN, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2020.3031199
   Wan L, 2019, IEEE GEOSCI REMOTE S, V16, P1026, DOI 10.1109/LGRS.2019.2892432
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P810, DOI 10.1109/TPAMI.2013.214
   Wang YH, 2021, INT J APPL EARTH OBS, V104, DOI 10.1016/j.jag.2021.102582
   Wu F, 2019, IEICE T INF SYST, VE102D, P659, DOI 10.1587/transinf.2018EDL8107
   Wu F, 2020, IEEE T CYBERNETICS, V50, P1009, DOI 10.1109/TCYB.2018.2876591
   Xiong JF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11172068
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 45
TC 3
Z9 3
U1 7
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26289
EP 26315
DI 10.1007/s11042-023-14331-2
EA JAN 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000920820100002
DA 2024-07-18
ER

PT J
AU Tallapragada, VVS
   Manga, NA
   Kumar, GVP
AF Tallapragada, V. V. Satyanarayana
   Manga, N. Alivelu
   Kumar, G. V. Pradeep
TI A novel COVID diagnosis and feature extraction based on discrete wavelet
   model and classification using X-ray and CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE COVID-19 diagnosis; Pre-processing; Feature extraction; Classification;
   Hybrid MMG; Aquila optimizer
AB Recently, the Covid-19 pandemic has affected several lives of people globally, and there is a need for a massive number of screening tests to diagnose the existence of coronavirus. For the medical specialist, detecting COVID-19 cases is a difficult task. There is a need for fast, cheap and accurate diagnostic tools. The chest X-ray and the computerized tomography (CT) play a significant role in the COVID-19 diagnosis. The advancement of deep learning (DL) approaches helps to introduce a COVID diagnosis system to achieve maximum detection rate with minimum time complexity. This research proposed a discrete wavelet optimized network model for COVID-19 diagnosis and feature extraction to overcome these problems. It consists of three stages pre-processing, feature extraction and classification. The raw images are filtered in the pre-processing phase to eliminate unnecessary noises and improve the image quality using the MMG hybrid filtering technique. The next phase is feature extraction, in this stage, the features are extracted, and the dimensionality of the features is diminished with the aid of a modified discrete wavelet based Mobile Net model. The third stage is the classification here, the convolutional Aquila COVID detection network model is developed to classify normal and COVID-19 positive cases from the collected images of the COVID-CT and chest X-ray dataset. Finally, the performance of the proposed model is compared with some of the existing models in terms of accuracy, specificity, sensitivity, precision, f-score, negative predictive value (NPV) and positive predictive value (PPV), respectively. The proposed model achieves the performance of 99%, 100%, 98.5%, and 99.5% for the CT dataset, and the accomplished accuracy, specificity, sensitivity, and precision values of the proposed model for the X-ray dataset are 98%, 99%, 98% and 97% respectively. In addition, the statistical and cross validation analysis is conducted to validate the effectiveness of the proposed model.
C1 [Tallapragada, V. V. Satyanarayana] Mohan Babu Univ, Erstwhile Sree Vidyanikethan Engn Coll, Dept ECE, Tirupati 517102, India.
   [Manga, N. Alivelu] Synopsys India Private Ltd, Hyderabad, India.
   [Kumar, G. V. Pradeep] Chaitanya Bharathi Inst Technol, Dept ECE, Hyderabad, India.
C3 Synopsys Inc; Chaitanya Bharathi Institute of Technology
RP Tallapragada, VVS (corresponding author), Mohan Babu Univ, Erstwhile Sree Vidyanikethan Engn Coll, Dept ECE, Tirupati 517102, India.
EM satya.tvv@gmail.com
RI Tallapragada, V.V.Satyanarayana/E-2927-2010; Assistant Professor,
   G.V.Pradeep Kumar/ABG-9737-2020
OI Tallapragada, V.V.Satyanarayana/0000-0002-8764-9982; Assistant
   Professor, G.V.Pradeep Kumar/0000-0002-2109-1445
CR Abd Elaziz M, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111383
   Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Akter S, 2021, BIOLOGY-BASEL, V10, DOI 10.3390/biology10111174
   Cabello F, 2015, SPA 2015 SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS, P28, DOI 10.1109/SPA.2015.7365108
   Chen Joy Iong-Zong, 2021, J. ISMAC, V3, P02, DOI DOI 10.36548/JISMAC.2021.2.006
   Chola C, 2021, COMPUT SCI MATH FORU, V2, P13
   de Oliveira HM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103743
   Demir F, 2021, APPL SOFT COMPUT, V103, DOI 10.1016/j.asoc.2021.107160
   El-Kenawy EM, 2021, IEEE ACCESS, V9, P36019, DOI 10.1109/ACCESS.2021.3061058
   Elmuogy S, 2021, J INTELL FUZZY SYST, V40, P5225, DOI 10.3233/JIFS-201985
   Elpeltagy M, 2021, MULTIMED TOOLS APPL, V80, P26451, DOI 10.1007/s11042-021-10783-6
   Garg Gaurav, 2018, Proceedings of the International Conference on Computing and Communication Systems. I3CS 2016. Lecture Notes in Networks and Systems (LNNS 24), P829, DOI 10.1007/978-981-10-6890-4_79
   Garg G, 2021, MULTIMED TOOLS APPL, V80, P30557, DOI 10.1007/s11042-021-11133-2
   Garg G, 2019, MULTIMED TOOLS APPL, V78, P12689, DOI 10.1007/s11042-018-6487-2
   Garg G, 2018, ADV INTELL SYST, V564, P115, DOI 10.1007/978-981-10-6875-1_12
   Garg G, 2018, CURR MED IMAGING, V14, P19, DOI 10.2174/1573405613666170504145842
   Goyal M, 2021, J INFECT PUBLIC HEAL, V14, P910, DOI 10.1016/j.jiph.2021.04.011
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Hemalatha G, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION COMMUNICATION AND EMBEDDED SYSTEMS (ICICES)
   Houssein EH, 2021, NEURAL COMPUT APPL, V33, P16899, DOI 10.1007/s00521-021-06273-3
   Huang ML, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105604
   Huang SG, 2021, INT J BIOL SCI, V17, P1581, DOI 10.7150/ijbs.58855
   Hussein AF, 2018, COGN SYST RES, V52, P1, DOI 10.1016/j.cogsys.2018.05.004
   Ismael MR, 2018, INT CONF ELECTRO INF, P252, DOI 10.1109/EIT.2018.8500308
   Iyer TJ, 2021, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.368
   Jamil S, 2021, BIG DATA COGN COMPUT, V5, DOI 10.3390/bdcc5040053
   Kumar A, 2019, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM-2020), P45, DOI [10.23919/INDIACom49435.2020.9083712, 10.23919/indiacom49435.2020.9083712]
   Kumar M, 2022, MATER TODAY-PROC, V51, P2520, DOI 10.1016/j.matpr.2021.12.123
   Maheshan CM, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-019-1800-x
   Nigam B, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114883
   Nur-A-Alam, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041480
   Patel Prashant, CHEST XRAY COV 19 PN
   Pontone G, 2021, J CARDIOVASC COMPUT, V15, P27, DOI 10.1016/j.jcct.2020.08.013
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Rahman T, 2021, COMPUT BIOL MED, V132, DOI 10.1016/j.compbiomed.2021.104319
   Salehi M, 2021, BRIT J RADIOL, V94, DOI 10.1259/bjr.20201263
   Shankar K, 2021, APPL SOFT COMPUT, V113, DOI 10.1016/j.asoc.2021.107878
   Shankar K, 2023, COGN NEURODYNAMICS, V17, P1, DOI 10.1007/s11571-021-09712-y
   Shanker Kartik, 2021, Marine Turtle Newsletter, P1
   Siddiqui SY, 2021, CMC-COMPUT MATER CON, V66, P1719, DOI 10.32604/cmc.2020.012585
   Thamer SA., 2022, INT J MECH ENG, V7, P6523
   Tuncer T, 2021, CHEMOMETR INTELL LAB, V210, DOI 10.1016/j.chemolab.2021.104256
   Zhao J., 2020, ARXIV
NR 44
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 26183
EP 26224
DI 10.1007/s11042-023-14367-4
EA JAN 2023
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000918001600001
PM 36712955
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Sharma, D
   Taran, S
   Pandey, A
AF Sharma, Dhruv
   Taran, Sachin
   Pandey, Anukul
TI A fusion way of feature extraction for automatic categorization of music
   genres
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music genres; Feature extraction; Feature fusion; Tunable Q-wavelet
   transform; Teager energy operator; Neural network
ID CONVOLUTIONAL NEURAL-NETWORKS; RECOMMENDATION SYSTEM;
   PATTERN-RECOGNITION; CLASSIFICATION; ENHANCEMENT; MULTILEVEL
AB Over the past decade, the invention of streaming services has led to the magnification of the music industry. With a plethora of available song choices, there is a dire need for recommendation techniques to help listeners discover music genres complementing their palate. This makes a vital need for automatic music genre categorization systems. With this objective, in this work fusion of direct and indirect features is introduced for the automatic categorization of music genres. In direct Feature Extraction (FE), the physical characteristics of music genres are assessed by timbral, chroma, and source separation-based features. In indirect FE, tunable Q-Wavelet transform and Teager energy operator are used to explore the non-linear characteristics of music signals. The proposed algorithm is examined on the GTZAN dataset, primarily focusing on the four-class classification problem. The introduced features are tested with multiple machine learning techniques to explore the best for music genre categorization. The wide neural network classifier with a single fully connected layer churned out optimal performance fetching an overall accuracy and F1 score of 95.8% and 95.82%, respectively. The proposed algorithm also outperforms most of the state-of-the-art techniques for the given dataset.
C1 [Sharma, Dhruv; Taran, Sachin; Pandey, Anukul] Delhi Technol Univ DTU, New Delhi 110042, India.
C3 Delhi Technological University
RP Taran, S (corresponding author), Delhi Technol Univ DTU, New Delhi 110042, India.
EM taransachin2@gmail.com; anukul66@gmail.com
RI ; Pandey, Dr Anukul/Q-9577-2016
OI , Dhruv Sharma/0000-0002-9656-9714; Pandey, Dr
   Anukul/0000-0003-2737-112X
CR Abdoli S, 2019, EXPERT SYST APPL, V136, P252, DOI 10.1016/j.eswa.2019.06.040
   Baniya BK, 2016, MULTIMED TOOLS APPL, V75, P3013, DOI 10.1007/s11042-014-2418-z
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Bhatti UA, 2019, ENTERP INF SYST-UK, V13, P329, DOI 10.1080/17517575.2018.1557256
   Bhatti UA, 2018, HUM VACC IMMUNOTHER, V14, P165, DOI 10.1080/21645515.2017.1379639
   Borjian N, 2018, MULTIMED TOOLS APPL, V77, P6165, DOI 10.1007/s11042-017-4524-1
   Boudraa AO, 2018, DIGIT SIGNAL PROCESS, V78, P338, DOI 10.1016/j.dsp.2018.03.010
   Brisson R, 2020, PSYCHOL MUSIC, V48, P777, DOI 10.1177/0305735619828810
   Cai X, 2022, MULTIMEDIA SYST, V28, P779, DOI 10.1007/s00530-021-00886-3
   Caparrini A, 2020, J NEW MUSIC RES, V49, P269, DOI 10.1080/09298215.2020.1761399
   Castillo JR, 2021, IEEE ACCESS, V9, P18801, DOI 10.1109/ACCESS.2021.3053864
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   Doelling KB, 2019, P NATL ACAD SCI USA, V116, P10113, DOI 10.1073/pnas.1816414116
   Elbir A., 2018, 2018 EL EL COMP SCI, P1
   Ellis DPW, 2007, INT CONF ACOUST SPEE, P1429
   Ferretti S, 2018, MULTIMED TOOLS APPL, V77, P16003, DOI 10.1007/s11042-017-5175-y
   Foleis JH, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106127
   Fredriksson D, 2019, SYST MUSIKWISS, P101, DOI 10.1007/978-3-658-25253-3_10
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Haggblade M, 2011, MUSIC GENRE CLASSIFI, P1
   Holzapfel A, 2008, IEEE T AUDIO SPEECH, V16, P424, DOI 10.1109/TASL.2007.909434
   Jain U, 2018, 2018 INTERNATIONAL CONFERENCE ON SENSOR NETWORKS AND SIGNAL PROCESSING (SNSP 2018), P386, DOI 10.1109/SNSP.2018.00081
   Jha CK, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101875
   Kaiser J. F., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P149, DOI 10.1109/ICASSP.1993.319457
   KAISER JF, 1990, INT CONF ACOUST SPEE, P381, DOI 10.1109/ICASSP.1990.115702
   Kiran P., 2018, Am. J. Comput. Sci. Inf. Technol., V6, P19
   Kumaraswamy B, 2021, APPL SOFT COMPUT, P108
   Kumaraswamy B, 2022, MULTIMED TOOLS APPL, V81, P17071, DOI 10.1007/s11042-022-12254-y
   Lee CH, 2009, IEEE T MULTIMEDIA, V11, P670, DOI 10.1109/TMM.2009.2017635
   Lee J, 2017, IEEE SIGNAL PROC LET, V24, P1208, DOI 10.1109/LSP.2017.2713830
   Lee MC, 2008, ARTIF INTELL MED, V43, P61, DOI 10.1016/j.artmed.2008.03.002
   Li CB, 2018, MAR STRUCT, V60, P186, DOI 10.1016/j.marstruc.2018.03.013
   Li JX, 2022, NEURAL COMPUT APPL, V34, P10337, DOI 10.1007/s00521-022-06896-0
   Li JX, 2022, MULTIMED TOOLS APPL, V81, P4621, DOI 10.1007/s11042-020-10465-9
   Liu CF, 2021, MULTIMED TOOLS APPL, V80, P7313, DOI 10.1007/s11042-020-09643-6
   Markov K, 2014, IEEE ACCESS, V2, P688, DOI 10.1109/ACCESS.2014.2333095
   Nanni L, 2018, J NEW MUSIC RES, V47, P383, DOI 10.1080/09298215.2018.1438476
   Ng WWY, 2020, IEEE ACCESS, V8, P152713, DOI 10.1109/ACCESS.2020.3017661
   Panagakis Y, 2014, IEEE-ACM T AUDIO SPE, V22, P1905, DOI 10.1109/TASLP.2014.2355774
   Pelchat N, 2020, CAN J ELECT COMPUT E, V43, P170, DOI 10.1109/CJECE.2020.2970144
   Pichl M, 2021, MULTIMED TOOLS APPL, V80, P22509, DOI 10.1007/s11042-020-09890-7
   Sawhney A., 2018, LATENT FEATURE EXTRA
   Selesnick IW, 2011, IEEE T SIGNAL PROCES, V59, P3560, DOI 10.1109/TSP.2011.2143711
   Seo JS, 2011, SIGNAL PROCESS, V91, P2154, DOI 10.1016/j.sigpro.2011.03.019
   Sugianto Sugianto, 2019, 2019 International Seminar on Research of Information Technology and Intelligent Systems (ISRITI), P330, DOI 10.1109/ISRITI48646.2019.9034644
   Swaminathan S, 2015, EMOT REV, V7, P189, DOI 10.1177/1754073914558282
   Tachibana H, 2014, IEEE-ACM T AUDIO SPE, V22, P228, DOI 10.1109/TASLP.2013.2287052
   Taran S, 2019, NEURAL COMPUT APPL, V31, P6925, DOI 10.1007/s00521-018-3531-0
   Teager Herbert M., 1983, Speech Science: Recent Advances, P73
   TEAGER HM, 1980, IEEE T ACOUST SPEECH, V28, P599, DOI 10.1109/TASSP.1980.1163453
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Yu Y, 2020, NEUROCOMPUTING, V372, P84, DOI 10.1016/j.neucom.2019.09.054
   Zou Q, 2020, IEEE T VEH TECHNOL, V69, P41, DOI 10.1109/TVT.2019.2949603
NR 56
TC 1
Z9 1
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 25015
EP 25038
DI 10.1007/s11042-023-14371-8
EA JAN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000915813000001
DA 2024-07-18
ER

PT J
AU Alshathri, S
   Hemdan, EE
AF Alshathri, Samah
   Hemdan, Ezz El-Din
TI An efficient audio watermarking scheme with scrambled medical images for
   secure medical internet of things systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MIoT; Arnold transform; Audio watermarking; Wavelet fusion; Singular
   value decomposition; Medical image
ID COLOR IMAGES
AB In recent times, the security of communication channels between healthcare entities in Medical Internet of Things (MIoT) systems becomes a significant issue to facilitate and guarantee the exchange of medical image and expertise securely. This paper presents an efficient audio watermarking scheme employing professionally Wavelet-based Image Fusion, Arnold transforms, and Singular Value Decomposition (SVD) for the secure transmission of medical images and reports in the MIoT applications. The essential consequence of the proposed scheme is to first syndicate two medical watermarks into a fused watermark to upsurge the payload of the inserted medical images. The fused watermark is then scrambled utilizing Arnold transform. Lastly, the Arnold fused watermark is inserted in the audio signal using the SVD algorithm following converting it into a 2D format. The choice of the Arnold transform for watermark is ascribed to settling robustness that skirmishes respective types of severe attacks. Several assessment metrics such as SNR, LLR, SNRseg, SD, and Cr are used to evaluate the audio watermarked signal and extracted watermarks The results reveal that the proposed audio watermarking scheme increases the capacity with more embedded medical images and security of implanted medical images transmission deprived of affecting the quality of audio signals, especially for IoT-based Telemedicine systems.
C1 [Alshathri, Samah] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
   [Hemdan, Ezz El-Din] Menoufia Univ, Fac Elect Engn, Dept Comp Sci & Engn, Menoufia, Egypt.
C3 Princess Nourah bint Abdulrahman University; Egyptian Knowledge Bank
   (EKB); Menofia University
RP Alshathri, S (corresponding author), Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
EM Sealshathry@pnu.edu.sa; ezzvip@yahoo.com
OI alshathri, samah/0000-0002-8805-7890
FU Princess Nourah bint Abdulrahman University, Riyadh, Saudi Arabia; 
   [PNURSP2023R197]
FX AcknowledgmentsPrincess Nourah bint Abdulrahman University Researchers
   Supporting Project number (PNURSP2023R197), Princess Nourah bint
   Abdulrahman University, Riyadh, Saudi Arabia.
CR Abdelwahab KM, 2020, MULTIMED TOOLS APPL, V79, P5617, DOI 10.1007/s11042-019-08023-z
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   [Anonymous], 2013, IOSR J COMPUTER ENG
   CROCHIERE RE, 1980, IEEE T ACOUST SPEECH, V28, P318, DOI 10.1109/TASSP.1980.1163417
   Dhanalakshmi R, 2010, ARXIV
   El-Gazar S, 2018, INT J SPEECH TECHNOL, V21, P953, DOI 10.1007/s10772-018-9531-8
   El-Shafai W, 2019, MULTIMED TOOLS APPL, V78, P27211, DOI 10.1007/s11042-019-7448-0
   El-Shafai W, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3478
   Faragallah OS, 2020, IEEE ACCESS, V8, P103200, DOI 10.1109/ACCESS.2020.2994583
   Faragallah OS, 2018, WIRELESS PERS COMMUN, V98, P2009, DOI 10.1007/s11277-017-4960-2
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Harish N., 2013, INT J ADV ELECT ELEC, V2, P137
   Hemdan EED., P 3 INT C ADV CONTR
   Hemdan EED, 2013, NAT RADIO SCI CO, P220
   Kannammal A., 2012, EUR J SCI RES, V70, P46
   KUBICHEK RF, 1993, IEEE PACIF, P125, DOI 10.1109/PACRIM.1993.407206
   Lakhan A, 2023, IEEE J BIOMED HEALTH, V27, P664, DOI 10.1109/JBHI.2022.3165945
   Lakhan A, 2024, T EMERG TELECOMMUN T, V35, DOI 10.1002/ett.4363
   Mahajan LH, 2013, INT J ADV RES SCI EN, V2, P69
   McDermott B. J., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing, P581
   Shieh JM, 2006, COMPUT STAND INTER, V28, P428, DOI 10.1016/j.csi.2005.03.006
   WANG SH, 1992, IEEE J SEL AREA COMM, V10, P819, DOI 10.1109/49.138987
   Yang WH, 1998, INT CONF ACOUST SPEE, P541, DOI 10.1109/ICASSP.1998.674487
   Zhou XY, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091024
NR 25
TC 4
Z9 4
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20177
EP 20195
DI 10.1007/s11042-023-14357-6
EA JAN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000911269000001
PM 36685016
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Chatterjee, R
   Halder, R
   Maitra, T
   Pani, S
AF Chatterjee, Rajdeep
   Halder, Rohit
   Maitra, Tanmoy
   Pani, Santosh
TI A computer vision-based perceived attention monitoring technique for
   smart teaching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Attention; Augmented learning; Classification; Deep learning; Digital
   classroom; Learning behaviour; Smart teaching
AB This paper aims to improve the lecture delivery mechanism in real-time in a classroom and remote sessions over web-based applications. In the traditional system, a lecturer observes their students' attention levels from his/her experience. To date, no system automatically tracks the students' attention level in a class in real-time (or while the lecturer is delivering his/her lectures remotely over web-based applications). On the other hand, our proposed system periodically will monitor the learning behaviour of the whole class and track the attentiveness of each student. The proposed system is not meant to identify the non-attentive students and punish them. Contrary to the punishment-based mechanism, it introduces a counseling-based mechanism. This deep learning-based real-time face monitoring system will allow lecturers to improvise/her delivery either through bringing diversity in the class contents or personal care to those non-attentive students. The concept of the deep learning technique in an ensemble configuration has been used to predict the likelihood of eyes' openness. Separately, a student's facial expressions are also recognized using our Convolutional Neural Network (CNN) model. Finally, the net learning behaviour of a student has been computed by a weighted average of these two features (that is, eyes' openness and facial expressions). The student learning behaviour is validated twice with Pearson correlation coefficient and Spearman correlation coefficient measures between the openness of eye and facial expressions. Again, the Cosine similarity has been used to further examine the periodical similarity of the student's learning patterns. The proposed pipeline has performed even better than the state-of-the-art models such as ResNet50, MobileNetV2, and EfficientNet-B0 in terms of accuracy and f1-score.
C1 [Chatterjee, Rajdeep; Halder, Rohit; Maitra, Tanmoy; Pani, Santosh] KIIT Deemed Be Univ, Sch Comp Engn, Bhubaneswar 751024, Orissa, India.
C3 Kalinga Institute of Industrial Technology (KIIT)
RP Maitra, T (corresponding author), KIIT Deemed Be Univ, Sch Comp Engn, Bhubaneswar 751024, Orissa, India.
EM cse.rajdeep@gmail.com; rhaldar9@gmail.com; tanmoy.maitra@live.com;
   santoshpani.sp@gmail.com
RI Pani, Santosh/HGA-6862-2022; Maitra, Tanmoy/R-5983-2016
OI Maitra, Tanmoy/0000-0002-5887-649X
CR An N, 2020, J BIOMED INFORM, V105, DOI 10.1016/j.jbi.2020.103411
   Bdiwi R, 2019, RES LEARN TECHNOL, V27, DOI 10.25304/rlt.v27.2072
   Bi AQ, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3538385
   Chatterjee R., 2021, INT C ADV NETW TECHN, P517
   Chatterjee R, 2019, FUTURE GENER COMP SY, V98, P419, DOI 10.1016/j.future.2019.01.048
   Courtad CA, 2019, SMART INNOV SYST TEC, V144, P501, DOI 10.1007/978-981-13-8260-4_44
   Du S., 2022, DIALOGUES CLIN NEURO
   Francis B, 2020, BRIT J SOCIOL EDUC, V41, P626, DOI 10.1080/01425692.2020.1763162
   Ganaie M. A., 2021, ARXIV
   Geambasu R., 2022, arXiv
   Jaiswal S, 2019, MULTIMED TOOLS APPL, V78, P14231, DOI 10.1007/s11042-018-6755-1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu S, 2022, INT C HUM COMP INT, P161
   Lucey P., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Mazumdar Saptarshi, 2022, Advances in Data Computing, Communication and Security: Proceedings of I3CS2021. Lecture Notes on Data Engineering and Communications Technologies (106), P193, DOI 10.1007/978-981-16-8403-6_17
   Perdiz J, 2021, IEEE ACCESS, V9, P46011, DOI 10.1109/ACCESS.2021.3068055
   Riccio A, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00732
   Saurav S, 2022, J REAL-TIME IMAGE PR, V19, P607, DOI 10.1007/s11554-022-01211-5
   Shen F, 2019, 3 INT SEM ED INN EC
   Song FY, 2014, COMPUT VIS IMAGE UND, V122, P143, DOI 10.1016/j.cviu.2014.02.010
   Steil J, 2018, 2018 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2018), DOI 10.1145/3204493.3204538
   Ting-Mei Li, 2019, Innovative Technologies and Learning. Second International Conference, ICITL 2019. Proceedings. Lecture Notes in Computer Science (LNCS 11937), P498, DOI 10.1007/978-3-030-35343-8_53
   Wang Y, 2021, IEEE SENSORS J
   Wang Y, 2019, PATTERN RECOGN LETT, V123, P61, DOI 10.1016/j.patrec.2019.03.013
   Yoon HS, 2019, IEEE ACCESS, V7, P93448, DOI 10.1109/ACCESS.2019.2928339
NR 25
TC 0
Z9 0
U1 5
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11523
EP 11547
DI 10.1007/s11042-022-14283-z
EA DEC 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000901975400001
DA 2024-07-18
ER

PT J
AU Qobbi, Y
   Jarjar, A
   Essaid, M
   Benazzi, A
AF Qobbi, Younes
   Jarjar, Abdellatif
   Essaid, Mohamed
   Benazzi, Abdelhamid
TI Image encryption algorithm using dynamic permutation and large chaotic
   S-box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Substitution; Permutation; Encryption process; Chaotic
   map; Plain image
AB In this paper, a new image encryption algorithm is proposed by using the chaotic maps. This cryptosystem is used to encrypt the color images of any size using a dynamic permutation and a large substitution table. The permutation is used to perform the first phase of the encryption process. This permutation is generated by using three parameters calculated from the pixel's values of three color channels (Red, Green and Blue) of the plaintext image. The second phase consists to make a substitution of the pixels of each channel using a large substitution table generated by three chaotic permutations, chaotic control vector and chaotic rotation vector. In order to increase the avalanche effect of our system, an enhanced cipher block chaining ECBC is used. The results obtained after several simulations carried out by our algorithm on images of different sizes, prove the security of our algorithm against statistical, brutal and differential attacks.
C1 [Qobbi, Younes; Benazzi, Abdelhamid] Mohamed First Univ, AMSPCS Lab, HSTO, Oujda, Morocco.
   [Jarjar, Abdellatif] High Sch Moulay Rachid, Taza, Morocco.
   [Essaid, Mohamed] Abdel Malek Essaadi Univ, Fac Sci, Dept Comp Sci, Tetouan, Morocco.
C3 Mohammed First University of Oujda; Abdelmalek Essaadi University of
   Tetouan
RP Qobbi, Y (corresponding author), Mohamed First Univ, AMSPCS Lab, HSTO, Oujda, Morocco.
EM qobbi.younes@ump.ac.ma
OI Qobbi, Younes/0000-0002-3533-7960
CR Abd-El-Hafiz SK, 2016, OPT LASER ENG, V85, P72, DOI 10.1016/j.optlaseng.2016.04.023
   Ali TS, 2020, MULTIMED TOOLS APPL, V79, P19853, DOI 10.1007/s11042-020-08850-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Es-Sabry M, 2020, SOFT COMPUT, V24, P3829, DOI 10.1007/s00500-019-04151-8
   Gan ZH, 2019, NEURAL COMPUT APPL, V31, P7111, DOI 10.1007/s00521-018-3541-y
   Ghazvini M, 2020, MULTIMED TOOLS APPL, V79, P26927, DOI 10.1007/s11042-020-09058-3
   Huang LQ, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20070535
   Khan FA, 2017, J INTELL FUZZY SYST, V33, P3753, DOI 10.3233/JIFS-17656
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Li CH, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/8132547
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Mahmud M, 2020, OPT LASER TECHNOL, V121, DOI 10.1016/j.optlastec.2019.105818
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Niu Y, 2020, MULTIMED TOOLS APPL, V79, P25613, DOI 10.1007/s11042-020-09237-2
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Song YL, 2016, 2016 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P584, DOI 10.1109/CompComm.2016.7924768
   Sprott J. C, 2010, Elegant Chaos: Algebraically Simple Chaotic Flows, DOI [10.1142/7183, DOI 10.1142/7183, 10.1142/7183 1222.37005]
   Thanki RM, 2019, DIGITAL IMAGE PROCES, P19
   Wang XY, 2015, ENTROPY-SWITZ, V17, P3877, DOI 10.3390/e17063877
   Wang XY, 2014, CHINESE PHYS B, V23, DOI 10.1088/1674-1056/23/3/030503
   Zheng JY, 2020, IET IMAGE PROCESS, V14, P2310, DOI 10.1049/iet-ipr.2019.1340
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
NR 25
TC 2
Z9 2
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18545
EP 18564
DI 10.1007/s11042-022-14175-2
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000886859000003
DA 2024-07-18
ER

PT J
AU Wang, J
   Weitzen, J
   Bayat, O
   Sevindik, V
   Li, MZ
AF Wang, Jiao
   Weitzen, Jay
   Bayat, Oguz
   Sevindik, Volkan
   Li, Mingzhe
TI Performance model for factory automation in 5G networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE 5G; URLLC; Massive MIMO; Joint transmission; Interference coordination;
   Network slicing
AB The fifth generation (5G) of mobile networks is emerging as a key enabler of modern factory automation (FA) applications that ensure timely and reliable data exchange between network components. Network slicing (NS), which shares an underlying infrastructure with different applications and ensures application isolation, is the key 5G technology to support the diverse quality of service requirements of modern FA applications. In this article, an end-to-end (E2E) NS solution is proposed for FA applications in a 5G network. Regression approaches are used to construct a performance model for each slice to map the service level agreement to the network attributes. Interference coordination approaches for switched beam systems are proposed to optimize radio access network (RAN) performance models. A case study of a non-public network is used to show the proposed NS solution. Simulation result shows that for services with different QoS requirements, different IC approaches should be used as optimization methods. Design prediction using regression approach has been evaluated and shows that the prediction successful rate increases when more existing data are used.
C1 [Wang, Jiao; Weitzen, Jay; Sevindik, Volkan] Univ Massachusetts, Dept Elect & Comp Engn, Lowell, MA 01854 USA.
   [Bayat, Oguz] Istanbul Kemerburgaz Univ, Grad Sch Sci & Engn, Istanbul, Turkey.
   [Li, Mingzhe] Q Factor Commun, 255 Bear Hill Rd, Waltham, MA 02451 USA.
C3 University of Massachusetts System; University of Massachusetts Lowell;
   Altinbas University
RP Wang, J (corresponding author), Univ Massachusetts, Dept Elect & Comp Engn, Lowell, MA 01854 USA.
EM jiaowang2010@gmail.com; jay_weitzen@uml.edu; oguzbayat@grnail.com;
   vsevindik@grnail.com; mingzhe.li@grnail.com
RI Li, Mingzhe/JLK-8164-2023
OI wang, jiao/0000-0003-3658-8662
CR [Anonymous], 2018, 22804 3GPP TR
   Brown G, ULTRARELIABLE LOW LA
   Chen H, 2016, J OPT COMMUN NETW, V8, pB1, DOI 10.1364/JOCN.8.0000B1
   Chitimalla D, 2017, J OPT COMMUN NETW, V9, P172, DOI 10.1364/JOCN.9.000172
   Deb S, 2014, IEEE ACM T NETWORK, V22, P137, DOI 10.1109/TNET.2013.2246820
   Ejlali M, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P721, DOI 10.1109/ISTEL.2012.6483080
   Fehrenbach T., 2018, PROC IEEE 88 VEH TEC, P1
   GE fanuc intelligent platforms, 2009, SWITCH ETH LAT AN
   Gotsis K.A., 2011, Recent Developments in Mobile Communications-A Multidisciplinary Approach, P201
   Grobe K, 2011, IEEE COMMUN MAG, V49, pS25, DOI 10.1109/MCOM.2011.5706310
   Jantti R., 2018, THESIS AALTO U ESPOO
   Ji H, 2018, IEEE WIREL COMMUN, V25, P124, DOI 10.1109/MWC.2018.1700294
   Kwak K, 2013, IEEE VTS VEH TECHNOL
   Li RP, 2018, IEEE ACCESS, V6, P74429, DOI 10.1109/ACCESS.2018.2881964
   Li Z., 2018, 2018 15 INT S WIR CO, P1, DOI [10.1109/ISWCS.2018.8491078, DOI 10.1109/ISWCS.2018.8491078]
   Lindbom L., 2011, ENHANCED INTERCELL I
   Mehlführer C, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-29
   Michaloliakos A, 2016, 2016 INFORMATION THEORY AND APPLICATIONS WORKSHOP (ITA)
   Necker MC, 2007, ACM S MODEL ANAL SIM, P296
   Neumann P., 2005, WSEAS Transactions on Communications, V4, P235
   Novlan T., 2010, GLOBAL TELECOMMUNICA, P1, DOI DOI 10.1109/GLOCOM.2010.5683973
   Ordonez-Miranda Jose, 2019, 2019 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2019.8873040
   Popa L., 2010, P 6 INT C, P16
   Popescu DA, 2019, THESIS U CAMBRIDGE
   Rahman M, 2010, IEEE T WIREL COMMUN, V9, P1414, DOI 10.1109/TWC.2010.04.090256
   Vierimaa O., 2017, COST MODELING CLOUD
   Wang J, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1368-6
   Wang JY, 2015, IEEE ICC, P2387, DOI 10.1109/ICC.2015.7248682
   Wang K, 2017, J OPT COMMUN NETW, V9, P327, DOI 10.1364/JOCN.9.000327
NR 29
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 NOV 10
PY 2022
DI 10.1007/s11042-022-14119-w
EA NOV 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6A3GQ
UT WOS:000880546100001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Devanathan, B
   Kamarasan, M
AF Devanathan, B.
   Kamarasan, M.
TI Multi-objective Archimedes Optimization Algorithm with Fusion-based Deep
   Learning model for brain tumor diagnosis and classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor; Image classification; Magnetic resonance imaging; Deep
   learning; Multiobjective optimization; Fusion models; Computer aided
   diagnosis
ID SEGMENTATION
AB Earlier identification of brain tumors (BT) is essential to increase the survival rate. Magnetic Resonance Imaging (MRI) is a commonly employed method that records brain abnormalities by the use of several modalities for clinical study. The recently developed computer vision and image processing schemes can be used for the detection and localization of tumor regions in the brain, which can be utilized for further treatment. In this regard, the study presents a novel Multiobjective Archimedes Optimization Algorithm with Fusion based Deep Learning (MOAOA-FDL) technique for brain tumor diagnosis and classification. In addition, the MOAOA-FDL technique preprocesses the MRI images via contrast enhancement and skull stripping. Moreover, AOA with Shannon entropy based multi-level thresholding approach is developed for medical image segmentation. Furthermore, the fusion of two deep learning models namely MobileNet and EfficientNet models is employed for feature extraction process. Finally, the AOA with long short term memory (LSTM) method is applied for classification model and thus allocates proper class label to it. The AOA is used to properly choose the hyper parameters like batch size, learning rate, and epoch count. The design of fusion process and MOAOA for BT diagnosis demonstrates the innovation of this study. For showcasing the better performance of the MOAOA-FDL method, a series of simulations have been executed utilizing benchmark dataset. The experimental outcome shows that the MOAOA-FDL method has outperformed the other recent approaches in terms of several performance measures.
C1 [Devanathan, B.; Kamarasan, M.] Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, India.
C3 Annamalai University
RP Devanathan, B (corresponding author), Annamalai Univ, Dept Comp & Informat Sci, Chidambaram, India.
EM devacisau@gmail.com; smkrasan@yahoo.com
CR Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Amin J, 2020, PATTERN RECOGN LETT, V139, P118, DOI 10.1016/j.patrec.2017.10.036
   Amin J, 2018, FUTURE GENER COMP SY, V87, P290, DOI 10.1016/j.future.2018.04.065
   Chiu Y C, 2020, 2020 INT C SYSTEM SC, P1, DOI DOI 10.1109/ICSSE50014.2020.9219319
   Dash S, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11112017
   Devanathan B, 2020, IIOAB J, V11, P1
   Díaz-Pernas FJ, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9020153
   Ijaz MF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102809
   Jia Z., 2020, IEEE Access, DOI [10.1109/ACCESS.2020.3016319, DOI 10.1109/ACCESS.2020.3016319]
   Khan AR, 2021, MICROSC RES TECHNIQ, V84, P1389, DOI 10.1002/jemt.23694
   Khan IU., 2022, HUM ACTIVITY RECOGNI, V22, P323
   Kumar Y, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03612-z
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Ozyurt F, 2019, MEASUREMENT, V147, DOI 10.1016/j.measurement.2019.07.058
   Rahman MM, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1682-y
   Rajasree R, 2021, NEURAL COMPUT APPL, V33, P5543, DOI 10.1007/s00521-020-05332-5
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Sadad T, 2021, MICROSC RES TECHNIQ, V84, P1296, DOI 10.1002/jemt.23688
   Sharif MI, 2022, COMPLEX INTELL SYST, V8, P3007, DOI 10.1007/s40747-021-00321-0
   Srinivasu PN, 2021, CMC-COMPUT MATER CON, V69, P3303, DOI 10.32604/cmc.2021.018472
   Srinivasu PN, 2020, DEEP LEARNING TECHNIQUES FOR BIOMEDICAL AND HEALTH INFORMATICS, P97, DOI 10.1016/B978-0-12-819061-6.00004-5
   Srinivasu PN, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21082852
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wozniak M, 2023, NEURAL COMPUT APPL, V35, P14611, DOI 10.1007/s00521-021-05841-x
NR 24
TC 2
Z9 2
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16985
EP 17007
DI 10.1007/s11042-022-14164-5
EA NOV 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000878962500002
DA 2024-07-18
ER

PT J
AU Lopes, JF
   da Costa, VGT
   Barbin, DF
   Cruz-Tirado, LJP
   Baeten, V
   Barbon, S Jr
AF Lopes, Jessica Fernandes
   Turrisi da Costa, Victor G.
   Barbin, Douglas F.
   Pier Cruz-Tirado, Luis Jam
   Baeten, Vincent
   Barbon Junior, Sylvio
TI Deep computer vision system for cocoa classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Deep learning; Computer vision; Food quality
ID IMAGE FEATURES; AGRICULTURE; PREDICTION; PORK
AB Cocoa hybridisation generates new varieties which are resistant to several plant diseases, but has individual chemical characteristics that affect chocolate production. Image analysis is a useful method for visual discrimination of cocoa beans, while deep learning (DL) has emerged as the de facto technique for image processing . However, these algorithms require a large amount of data and careful tuning of hyperparameters. Since it is necessary to acquire a large number of images to encompass the wide range of agricultural products, in this paper, we compare a Deep Computer Vision System (DCVS) and a traditional Computer Vision System (CVS) to classify cocoa beans into different varieties. For DCVS, we used a Resnet18 and Resnet50 as backbone, while for CVS, we experimented traditional machine learning algorithms, Support Vector Machine (SVM), and Random Forest (RF). All the algorithms were selected since they provide good classification performance and their potential application for food classification A dataset with 1,239 samples was used to evaluate both systems. The best accuracy was 96.82% for DCVS (ResNet 18), compared to 85.71% obtained by the CVS using SVM. The essential handcrafted features were reported and discussed regarding their influence on cocoa bean classification. Class Activation Maps was applied to DCVS's predictions, providing a meaningful visualisation of the most important regions of the images in the model.
C1 [Lopes, Jessica Fernandes] Londrina State Univ UEL, Dept Elect Engn, Londrina, Parana, Brazil.
   [Turrisi da Costa, Victor G.] Londrina State Univ UEL, Dept Comp Sci, Londrina, Parana, Brazil.
   [Barbin, Douglas F.; Pier Cruz-Tirado, Luis Jam] Univ Campinas UNICAMP, Dept Food Engn, Campinas, Brazil.
   [Baeten, Vincent] Walloon Agr Res Ctr CRA W, Gembloux, Belgium.
   [Barbon Junior, Sylvio] Univ Trieste, Dipartimento Ingn & Architettura DIA, Trieste, Italy.
C3 Universidade Estadual de Londrina; Universidade Estadual de Londrina;
   Universidade Estadual de Campinas; University of Trieste
RP Barbon, S Jr (corresponding author), Univ Trieste, Dipartimento Ingn & Architettura DIA, Trieste, Italy.
EM jessicafernandes@uel.br; victorturrisi@uel.br; dfbarbin@unicamp.br;
   jampier_14_06@hotmail.com; v.baeten@cra.wallonie.be;
   sylvio.barbonjunior@units.it
RI Barbon Junior, Sylvio/L-6137-2013; Barbin, Douglas F/I-2198-2015; Cruz
   Tirado, Luis Jam Pier/U-2710-2018
OI Barbon Junior, Sylvio/0000-0002-4988-0702; Cruz Tirado, Luis Jam
   Pier/0000-0002-1963-4965; Fernandes Lopes, Jessica/0000-0002-2871-7252
FU Universita degli Studi di Trieste within the CRUI-CARE Agreement
FX Open access funding provided by Universit`a degli Studi di Trieste
   within the CRUI-CARE Agreement.
CR Aggarwal CC, 2014, CH CRC DATA MIN KNOW, P457
   Aguiar GJ, 2019, PATTERN RECOGN LETT, V128, P480, DOI 10.1016/j.patrec.2019.10.018
   [Anonymous], 2015, P IEEE C COMPUTER VI
   Arefi A, 2011, J FOOD AGRIC ENVIRON, V9, P379
   Barbon APAD, 2017, COMPUT ELECTRON AGR, V142, P536, DOI 10.1016/j.compag.2017.11.017
   Barbon APAC, 2016, COMPUT ELECTRON AGR, V127, P368, DOI 10.1016/j.compag.2016.06.028
   Barbon Junior Sylvio, 2020, Information Processing in Agriculture, V7, P342, DOI 10.1016/j.inpa.2019.07.001
   Bhargava A, 2020, MULTIMED TOOLS APPL, V79, P7857, DOI 10.1007/s11042-019-08564-3
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Campos GFC, 2016, SIBGRAPI, P370, DOI [10.1109/SIBGRAPI.2016.55, 10.1109/SIBGRAPI.2016.058]
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chu F, 2005, STUD FUZZ SOFT COMP, V177, P343
   Cruz-Tirado JP, 2020, FOOD CONTROL, V118, DOI 10.1016/j.foodcont.2020.107445
   da Costa AZ, 2020, BIOSYST ENG, V190, P131, DOI 10.1016/j.biosystemseng.2019.12.003
   Du CJ, 2006, J FOOD ENG, V72, P39, DOI 10.1016/j.jfoodeng.2004.11.017
   Engilberge M, 2018, PROC CVPR IEEE, P3984, DOI 10.1109/CVPR.2018.00419
   Fan FH, 2013, J FOOD ENG, V118, P426, DOI 10.1016/j.jfoodeng.2013.04.015
   Fang WP, 2014, J AGR FOOD CHEM, V62, P481, DOI 10.1021/jf404402v
   Gill HS, 2021, MULTIMED TOOLS APPL, V80, P27495, DOI 10.1007/s11042-021-10772-9
   Giraldo-Zuluaga JH, 2016, Arxiv, DOI arXiv:1611.02803
   Glorot X., 2010, 13 INT C ARTIFICIAL, V9, P249
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3_1
   Hassaballah M, 2019, STUDIES COMPUTATIONA
   Hassaballah M., 2020, Deep Learning in Computer Vision: Principles and Applications, DOI DOI 10.1201/9781351003827
   He KM, 2016, Arxiv, DOI arXiv:1603.05027
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   Huang G, 2018, Arxiv, DOI [arXiv:1608.06993, DOI 10.48550/ARXIV.1608.06993]
   Jentzsch PV, 2016, FOOD CHEM, V211, P274, DOI 10.1016/j.foodchem.2016.05.017
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kaur T, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01069-2
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laddi A, 2013, J FOOD ENG, V115, P226, DOI 10.1016/j.jfoodeng.2012.10.018
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu Y, 2021, TRENDS FOOD SCI TECH, V113, P193, DOI 10.1016/j.tifs.2021.04.042
   Lopes JF, 2020, BIOSYST ENG, V191, P129, DOI 10.1016/j.biosystemseng.2020.01.008
   Lopes JF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132953
   Lopes UV, 2011, CROP BREED APPL BIOT, V11, P73, DOI 10.1590/S1984-70332011000500011
   Mancini RA, 2005, MEAT SCI, V71, P100, DOI 10.1016/j.meatsci.2005.03.003
   Mastelini SM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053021
   Motamayor JC, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0003311
   Motilal L, 2003, GENET RESOUR CROP EV, V50, P799, DOI 10.1023/A:1025950902827
   Nixon Mark S, 2012, FEATURE EXTRACTION I, DOI DOI 10.1016/B978-0-12-396549-3.00007-0
   Okiyama DCG, 2017, TRENDS FOOD SCI TECH, V63, P103, DOI 10.1016/j.tifs.2017.03.007
   Oliveira MM, 2021, J FOOD COMPOS ANAL, V97, DOI 10.1016/j.jfca.2020.103771
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Pu HB, 2015, MEAT SCI, V99, P81, DOI 10.1016/j.meatsci.2014.09.001
   Fajardo MAR, 2011, REV FITOTEC MEX, V34, P175
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Risterucci A. M., 2001, Proceedings of the international workshop on new technologies and cocoa breeding, Kota Kinabalu, Sabah, Malaysia, 16-17 October 2000, P25
   Pereira LFS, 2018, COMPUT ELECTRON AGR, V145, P76, DOI 10.1016/j.compag.2017.12.029
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Scornet E, 2015, ANN STAT, V43, P1716, DOI 10.1214/15-AOS1321
   Scott GJ, 2017, IEEE GEOSCI REMOTE S, V14, P549, DOI 10.1109/LGRS.2017.2657778
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   SOBEL I, 1978, COMPUT VISION GRAPH, V8, P127, DOI 10.1016/S0146-664X(78)80020-3
   Sun DW, 2016, COMPUTER VISION TECHNOLOGY FOR FOOD QUALITY EVALUATION, 2ND EDITION, P1, DOI 10.1016/C2014-0-01718-2
   Sun J, 2019, 16 INT C MACH VIS AP
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tian Hong-kun, 2020, Information Processing in Agriculture, V7, P1, DOI 10.1016/j.inpa.2019.09.006
   Vapnik V., 1999, NATURE STAT LEARNING
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Xie SN, 2017, Arxiv, DOI [arXiv:1611.05431, 10.48550/arXiv.1611.05431]
   Xie SN, 2015, PROC CVPR IEEE, P2645, DOI 10.1109/CVPR.2015.7298880
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 71
TC 13
Z9 13
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 41059
EP 41077
DI 10.1007/s11042-022-13097-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000872701700054
OA hybrid
DA 2024-07-18
ER

PT J
AU Guarnera, L
   Giudice, O
   Livatino, S
   Paratore, AB
   Salici, A
   Battiato, S
AF Guarnera, Luca
   Giudice, Oliver
   Livatino, Salvatore
   Paratore, Antonino Barbaro
   Salici, Angelo
   Battiato, Sebastiano
TI Assessing forensic ballistics three-dimensionally through graphical
   reconstruction and immersive VR observation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Forensic science; Forensic firearm ballistics; 3D immersive tool; VR
   observation
ID VIRTUAL-REALITY; IMAGE-ANALYSIS; ALGORITHM; FIREARM; VISUALIZATION;
   IMPRESSIONS
AB A crime scene can provide valuable evidence critical to explain reason and modality of the occurred crime, and it can also lead to the arrest of criminals. The type of evidence collected by crime scene investigators or by law enforcement may accordingly effective involved cases. Bullets and cartridge cases examination is of paramount importance in forensic science because they may contain traces of microscopic striations, impressions and markings, which are unique and reproducible as "ballistic fingerprints". The analysis of bullets and cartridge cases is a complicated and challenging process, typically based on optical comparison, leading to the identification of the employed firearm. New methods have recently been proposed for more accurate comparisons, which rely on three-dimensionally reconstructed data. This paper aims at further advancing recent methods by introducing a novel immersive technique for ballistics comparison by means of Virtual Reality. Users can three-dimensionally examine the cartridge cases shapes through intuitive natural gestures, from any vantage viewpoint (including internal iper-magnified views), while having at their disposal sets of visual aids which could not be easily implemented in desktop-based applications. A user study was conducted to assess viability and performance of our solution, which involved fourteen individuals acquainted with the standard procedures used by law enforcement agencies. Results clearly indicated that our approach lead to faster adaptation of users to the UI/UX and more accurate and explainable ballistics examination results.
C1 [Guarnera, Luca; Battiato, Sebastiano] Univ Catania, Dipartimento Matemat & Informat, Viale Andrea Doria 6, I-95126 Catania, Italy.
   [Giudice, Oliver] Banca Italia, IT Dept, Appl Res Team, Rome, Italy.
   [Livatino, Salvatore] Univ Hertfordshire, Sch Phys Engn & Comp Sci, Hatfield AL10 9AB, Herts, England.
   [Paratore, Antonino Barbaro] Univ Catania, iCTLab Spinoff, Viale Andrea Doria 6, I-95126 Catania, Italy.
   [Salici, Angelo] Carabinieri Sci Invest Dept Messina, Via Monsignor Arrigo 5, I-98122 Messina, Italy.
C3 University of Catania; European Central Bank; Bank of Italy; University
   of Hertfordshire; University of Catania
RP Guarnera, L (corresponding author), Univ Catania, Dipartimento Matemat & Informat, Viale Andrea Doria 6, I-95126 Catania, Italy.
EM luca.guarnera@unict.it; giudice@dmi.unict.it; s.livatino@herts.ac.uk;
   antonino.paratore@ictlab.srl; angelo.salici@carabinieri.it;
   battiato@dmi.unict.it
RI Guarnera, Luca/ACS-0239-2022; Battiato, Sebastiano/ABI-1584-2020;
   Giudice, Oliver/V-7713-2019
OI Guarnera, Luca/0000-0001-8315-351X; Battiato,
   Sebastiano/0000-0001-6127-2470; Giudice, Oliver/0000-0002-8343-2049
FU Universita degli Studi di Catania within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Catania within
   the CRUI-CARE Agreement.
CR Banno A, 2004, FORENSIC SCI INT, V140, P233, DOI 10.1016/j.forsciint.2003.11.025
   Basu, 2022, FORENSIC SCI INT, VSynergy
   BESL PJ, 1992, P SOC PHOTO-OPT INS, V1611, P586, DOI 10.1117/12.57955
   Chapnick C, 2021, J FORENSIC SCI, V66, P557, DOI 10.1111/1556-4029.14602
   Chen Z, 2017, FORENSIC SCI INT, V280, P213, DOI 10.1016/j.forsciint.2017.08.033
   Chu W, 2013, J ASS FIREARMS TOOLM
   Diakogiannis FI, 2020, ISPRS J PHOTOGRAMM, V162, P94, DOI 10.1016/j.isprsjprs.2020.01.013
   Dutta SK, 2021, APPL SOFT COMPUT, V112, DOI 10.1016/j.asoc.2021.107789
   Giudice O, 2019, IEEE IMAGE PROC, P4045, DOI [10.1109/icip.2019.8803619, 10.1109/ICIP.2019.8803619]
   Hall A.L., 1931, AM J POLICE SCI, V2, P311, DOI DOI 10.2307/1147359
   Heard B.J., 2011, Handbook of Firearms and Ballistics: Examining and Interpreting Forensic Evidence
   Kara I, 2016, J FORENSIC SCI, V61, P775, DOI 10.1111/1556-4029.13073
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Koller S, 2019, FORENSIC SCI INT, V295, P30, DOI 10.1016/j.forsciint.2018.11.006
   Livatino S, 2015, IEEE T IND ELECTRON, V62, P525, DOI 10.1109/TIE.2014.2334675
   Ma MH, 2010, J FORENSIC SCI, V55, P1227, DOI 10.1111/j.1556-4029.2010.01453.x
   Moran B., 2002, AFTE J, V34, P227
   Morris KB, 2017, FORENSIC SCI INT, V280, P188, DOI 10.1016/j.forsciint.2017.09.004
   Riva F, 2014, J FORENSIC SCI, V59, P637, DOI 10.1111/1556-4029.12382
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salvatore L., 2008, Advances in Human Computer Interaction, DOI [10.5772/5925, DOI 10.5772/5925]
   Sieberth T, 2019, FORENSIC SCI MED PAT, V15, P41, DOI 10.1007/s12024-018-0058-8
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Song HX, 2022, J FORENSIC SCI, V67, P1417, DOI 10.1111/1556-4029.15026
   Song J, 2004, J RES NATL INST STAN, V109, P533, DOI 10.6028/jres.109.040
   Song J, 1998, P SOC PHOTO-OPT INS, V3426, P213, DOI 10.1117/12.328457
   Song J., 2015, AFTE Journal, V3, P177
   Song J, 2020, FORENSIC SCI INT, V317, DOI 10.1016/j.forsciint.2020.110502
   Song J, 2018, FORENSIC SCI INT, V284, P15, DOI 10.1016/j.forsciint.2017.12.013
   Song J, 2014, MEAS SCI TECHNOL, V25, DOI 10.1088/0957-0233/25/6/064005
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tai XH, 2020, ARXIV
   Tai XH, 2018, J FORENSIC SCI, V63, P440, DOI 10.1111/1556-4029.13577
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Tong MS, 2015, J RES NATL INST STAN, V120, P102, DOI 10.6028/jres.120.008
   Tong MS, 2014, J RES NATL INST STAN, V119, P575, DOI 10.6028/jres.119.023
   Vorburger TV., 2007, NIST IR 7362, DOI DOI 10.6028/NIST.IR.7362
   Zernike F, 1934, PHYSICA, V1, P689
   Zhang H, 2022, FORENSIC SCI INT, V333, DOI 10.1016/j.forsciint.2022.111229
   Zhang H, 2021, J FORENSIC SCI, V66, P571, DOI 10.1111/1556-4029.14634
   Zhang H, 2018, FORENSIC SCI INT, V286, P148, DOI 10.1016/j.forsciint.2018.02.026
NR 41
TC 2
Z9 2
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 20655
EP 20681
DI 10.1007/s11042-022-14037-x
EA OCT 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000870957300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Krishna, PR
   Prasad, VVKDV
   Battula, TK
AF Krishna, P. Rama
   Prasad, V. V. K. D. V.
   Battula, Tirumula Krishna
TI Optimization empowered hierarchical residual VGGNet19 network for
   multi-class brain tumour classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolution; Pooling; Batch normalization; Clustering; Machine learning;
   Deep learning; Hierarchical residual VGGNet19; Kernel K-means; Square
   Array filtering
ID DEEP; SEGMENTATION; FUSION; FEATURES
AB Brain tumour is a fatal disease and its diagnosis is a difficult procedure for radiologists due to the heterogeneous behaviour of tumour cells. Diagnosing brain tumour using MRI at early stage is essential by attaining higher accuracy with minimum error function. Based on this insight, the goal of the proposed research is to create a deep learning architecture that will aid in the automatic detection of brain tumour utilising two-dimensional MRI slices. The proposedSquare Array Filtering(SAF) approach is applied to the acquired input image in order to remove such noisy contents. To obtain a noiseless image, an array in square grid format is generated to update the missing pixel values of an image using SAF. This research employs the Kernel K-means clustering ((KC)-C-2) model for segmenting the injured region, with the weighted mean enhancement methodology efficiently removing noise from the image and the (KC)-C-2 method isolating the infected areas. The proposed Optimization empowered Hierarchical Residual VGGNet19 (HR-VGGNet19) model is designed to explore the discriminative information with the help of convolution layer employed in it. The proposed model combines both the low level and high-level features with the help of HR-VGGNet19 network and obtains the output class. The performance metric shows the proposed methodology outperforms better than the state-of-art methods. The proposed methodology is implemented in the working platform of MATLAB in terms of evaluation metrics like accuracy, sensitivity, specificity, PPV, NPV, FPR, FNR and FDR.
C1 [Krishna, P. Rama; Battula, Tirumula Krishna] Jawaharlal Nehru Technol Univ, Dept Elect & Commun Engn, Kakinada, India.
   [Prasad, V. V. K. D. V.] SR Gudlavalleru Engn Coll, Dept Elect & Commun Engn, Vijayawada, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Kakinada
RP Krishna, PR (corresponding author), Jawaharlal Nehru Technol Univ, Dept Elect & Commun Engn, Kakinada, India.
EM pramakrishna441@gmail.com
RI Varaprasad, VVKD/T-2816-2018; KRISHNA, B T/AAJ-4836-2020; Palaparthi,
   Rama Krishna/HCI-5766-2022
OI Varaprasad, VVKD/0000-0001-9554-3814; KRISHNA, B T/0000-0002-8316-7310;
   Palaparthi, Rama Krishna/0000-0002-6762-3099
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   Alhassan AM, 2020, IEEE ACCESS, V8, P201741, DOI 10.1109/ACCESS.2020.3035803
   Ali M, 2020, IEEE ACCESS, V8, P153589, DOI 10.1109/ACCESS.2020.3018160
   Amin J, 2020, PATTERN RECOGN LETT, V129, P115, DOI 10.1016/j.patrec.2019.11.016
   Amin J, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1483-2
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Biratu ES, 2021, J IMAGING, V7, DOI 10.3390/jimaging7090179
   Debnath S, 2019, MULTIMED TOOLS APPL, V78, P23689, DOI 10.1007/s11042-019-7673-6
   Deepak S, 2021, INT J IMAG SYST TECH, V31, P1655, DOI 10.1002/ima.22543
   Ghaffari M, 2020, ARXIV
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Hasan AM, 2019, IEEE ACCESS, V7, P79959, DOI 10.1109/ACCESS.2019.2922691
   Hashemzehi R, 2020, BIOCYBERN BIOMED ENG, V40, P1225, DOI 10.1016/j.bbe.2020.06.001
   Ismael SAA, 2020, ARTIF INTELL MED, V102, DOI 10.1016/j.artmed.2019.101779
   Kaur A, 2022, IEEEACM T COMPUTATIO, V1, P1
   Kaur A, 2023, IETE J RES, V69, P7907, DOI 10.1080/03772063.2022.2060869
   Kurmi Y, 2020, IET IMAGE PROCESS, V14, P2808, DOI 10.1049/iet-ipr.2019.1631
   Maharjan S, 2020, J NEUROSCI METH, V330, DOI 10.1016/j.jneumeth.2019.108520
   Mallick PK, 2019, IEEE ACCESS, V7, P46278, DOI 10.1109/ACCESS.2019.2902252
   Manogaran G, 2019, IEEE ACCESS, V7, P12, DOI 10.1109/ACCESS.2018.2878276
   Mehrotra R, 2020, MACH LEARN APPL, V2, DOI 10.1016/j.mlwa.2020.100003
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Nayak DR, 2022, COMPUTERS, V11, DOI 10.3390/computers11010010
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Pei LM, 2020, LECT NOTES COMPUT SC, V11993, P335, DOI 10.1007/978-3-030-46643-5_33
   Polat Ö, 2021, J SUPERCOMPUT, V77, P7236, DOI 10.1007/s11227-020-03572-9
   Rafi A, 2021, INT J IMAG SYST TECH, V31, P1519, DOI 10.1002/ima.22549
   Saba T, 2020, COGN SYST RES, V59, P221, DOI 10.1016/j.cogsys.2019.09.007
   Sarhan AM., 2020, J Biomed Sci Eng, V13, P102, DOI DOI 10.4236/JBISE.2020.136010
   Sasank VVS, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103090
   Shaheed K, 2022, EXPERT SYST APPL, V198, DOI 10.1016/j.eswa.2022.116786
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shaheed K, 2022, INFORM FUSION, V79, P84, DOI 10.1016/j.inffus.2021.10.004
   Sharif MI, 2022, COMPLEX INTELL SYST, V8, P3007, DOI 10.1007/s40747-021-00321-0
   Shrivastava Deepshikha., 2020, Smart Healthcare for Disease Diagnosis and Prevention, P175, DOI DOI 10.1016/B978-0-12-817913-0.00017-1
   SivaSai J.G., 2021, BIOINSPIRED NEUROCOM, P163
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Tandel GS, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104564
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Waghmare V.K., 2021, Studies in Big Data, P155, DOI DOI 10.1007/978-981-15-4112-4_8
   Walia S, 2021, IEEE ACCESS, V9, P99742, DOI 10.1109/ACCESS.2021.3096240
NR 43
TC 5
Z9 5
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 11
BP 16691
EP 16716
DI 10.1007/s11042-022-13994-7
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7WU3
UT WOS:000864589600001
DA 2024-07-18
ER

PT J
AU Zhang, L
   Liu, J
   Liu, BL
   Zhu, SJ
   An, JY
AF Zhang, Lei
   Liu, Jie
   Liu, Bailong
   Zhu, Shaojie
   An, Jiyong
TI Co-attention trajectory prediction by mining heterogeneous interactive
   relationships
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous information network; Semantic trajectory; Multi-modal;
   Meta-path
ID MODEL; NETWORKS; SYSTEM; ROUTE
AB In the multi-modal spatio-temporal semantic trajectory prediction, if we can make full use of its multi-modal characteristics and heterogeneous interaction, the prediction accuracy can be significantly improved. However, the existing methods have some thorny problems. Firstly, the process of constructing an effective and semantically rich heterogeneous information interaction scene is very complex. Secondly, it is difficult to obtain interaction path instances with high quality, high relevance and high reliability. Finally, how to introduce path instances into trajectory prediction is also a difficulty. This paper proposes a common attention prediction method based on heterogeneous information network (HBCAPM). Firstly, the heterogeneous information network is constructed to make effective use of the multi-modal features in the trajectory and the heterogeneous interaction between features. Secondly, HBCAPM mines multi-source heterogeneous nodes and interaction patterns in heterogeneous information networks. Then, a path generation algorithm based on matrix decomposition and rankwalk is designed to obtain high-quality path instances. Finally, a collaborative semantic enhancement mechanism based on attention mechanism is designed to obtain the collaborative semantics of users, destinations and meta-paths. In addition, a large number of experiments on two real data sets show that HBCAPM significantly improves the effectiveness of various evaluation criteria. Compared with the latest method we discussed, the prediction accuracy is improved by 1.28% and the average distance error is reduced by 65.5 m.
C1 [Zhang, Lei; Liu, Jie; Liu, Bailong; Zhu, Shaojie; An, Jiyong] China Univ Min & Technol, Sch Comp Sci, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhang, Lei; Liu, Jie; Liu, Bailong; Zhu, Shaojie; An, Jiyong] China Univ Min & Technol, Engn Res Ctr Mine Digitalizat, Minist Educ, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Liu, BL (corresponding author), China Univ Min & Technol, Sch Comp Sci, Xuzhou 221116, Jiangsu, Peoples R China.; Liu, BL (corresponding author), China Univ Min & Technol, Engn Res Ctr Mine Digitalizat, Minist Educ, Xuzhou 221116, Jiangsu, Peoples R China.
EM zhanglei@cumt.edu.cn; liujiezcumt@cumt.edu.cn; liubailong@cumt.edu.cn;
   1208162499@qq.com; ajy@cumt.edu.com
RI wang, yue/KDO-9209-2024
OI Liu, Bailong/0000-0001-5112-7720
FU Double-First-Rate Special Fund for Construction of China University of
   Mining and Technology [2018ZZCX14]; Fundamental Research Funds for the
   Central Universities [2019XKQYMS88]
FX This work was supported in part by "the Double-First-Rate Special Fund
   for Construction of China University of Mining and Technology, No.
   2018ZZCX14" and "the Fundamental Research Funds for the Central
   Universities, No. 2019XKQYMS88". The funder had no role in study design,
   data collection and preparation of the manuscript.
CR Alemany S, 2019, AAAI CONF ARTIF INTE, P468
   Altaf B, 2018, IEEE INT CONF BIG DA, P937, DOI 10.1109/BigData.2018.8622218
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Berahmand K, 2021, COMPUTING, V103, P2227, DOI 10.1007/s00607-021-00982-2
   Berahmand Kamal, 2021, J KING SAUD UNIV-COM
   Cao JP, 2020, KNOWL INF SYST, V62, P175, DOI 10.1007/s10115-019-01356-z
   Cao S, 2015, ACM INT C INFORM KNO
   Cen YK, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1358, DOI 10.1145/3292500.3330964
   Dong YX, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P135, DOI 10.1145/3097983.3098036
   Feng J, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1459, DOI 10.1145/3178876.3186058
   Forouzandeh S, 2022, FUZZY INF ENG, V14, P26, DOI 10.1080/16168658.2021.2019430
   Forouzandeh S, 2021, ENG APPL ARTIF INTEL, V104, DOI 10.1016/j.engappai.2021.104325
   Forouzandeh S, 2021, INT J INF TECH DECIS, V20, P399, DOI 10.1142/S0219622020500522
   Forouzandeh S, 2021, MULTIMED TOOLS APPL, V80, P7805, DOI 10.1007/s11042-020-09949-5
   Fu TY, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1797, DOI 10.1145/3132847.3132953
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Han JW, 2009, LECT NOTES ARTIF INT, V5808, P13
   Han QL, 2019, IEEE ACCESS, V7, P73756, DOI 10.1109/ACCESS.2019.2918594
   Hu BB, 2019, AAAI CONF ARTIF INTE, P946
   Hu BB, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1531, DOI 10.1145/3219819.3219965
   Huang H., 2021, IJCAI, P1470
   Huang PX, 2014, PROCEEDINGS OF THE ASME TURBO EXPO: TURBINE TECHNICAL CONFERENCE AND EXPOSITION, 2014, VOL 2D
   Karatzoglou Antonios, 2018, 2018 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P100, DOI 10.1109/PERCOMW.2018.8480230
   Karatzoglou A, 2019, 27TH ACM SIGSPATIAL INTERNATIONAL CONFERENCE ON ADVANCES IN GEOGRAPHIC INFORMATION SYSTEMS (ACM SIGSPATIAL GIS 2019), P448, DOI 10.1145/3347146.3359089
   Karatzoglou A, 2017, IEEE CONF WIREL MOB, P724
   Li MW, 2022, NONLINEAR DYNAM, V107, P2447, DOI 10.1007/s11071-021-07139-y
   Li ZC, 2019, IEEE T PATTERN ANAL, V41, P2070, DOI 10.1109/TPAMI.2018.2852750
   Li Zechao, 2021, IEEE Trans Pattern Anal Mach Intell
   Liu ZJ, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P995, DOI 10.1145/3340531.3411944
   Pouyaei A, 2020, GEOSCI MODEL DEV, V13, P3489, DOI 10.5194/gmd-13-3489-2020
   Rahmani Hossein A., 2020, Advances in Information Retrieval, 42nd European Conference on IR Research, ECIR 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12035), P205, DOI 10.1007/978-3-030-45439-5_14
   Romera EM, 2021, INT J CLIN HLTH PSYC, V21, DOI 10.1016/j.ijchp.2020.07.003
   Sadr H, 2020, IEEE ACCESS, V8, P86984, DOI 10.1109/ACCESS.2020.2992063
   Shi C, 2017, IEEE T KNOWL DATA EN, V29, P17, DOI 10.1109/TKDE.2016.2598561
   Sun P, 2020, IEEE NETWORK, V34, P178, DOI 10.1109/MNET.011.1900338
   Sun Y., 2012, Mining Heterogeneous Information Networks: Principles and Methodologies, DOI 10.2200/S00433ED1V01Y201207DMK005
   Sunt YZ, 2011, PROC VLDB ENDOW, V4, P992
   Sutskever I, 2014, ADV NEUR IN, V27
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang D, 2020, AAAI CONF ARTIF INTE, V34, P963
   Wang JC, 2020, PROC VLDB ENDOW, V13, P979, DOI 10.14778/3384345.3384348
   Wang XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P1082, DOI 10.1145/3366423.3380186
   Wang Y, 2022, IEEE T KNOWL DATA EN, V34, P3225, DOI 10.1109/TKDE.2020.3019488
   Wang Y, 2020, PROC INT CONF DATA, P1954, DOI 10.1109/ICDE48307.2020.00212
   Wang ZB, 2015, IEEE T MOBILE COMPUT, V14, P538, DOI 10.1109/TMC.2014.2322373
   Yao D, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2411, DOI 10.1145/3132847.3133056
   Zhang CX, 2014, P INT CONF NAT COMPU, P769, DOI 10.1109/ICNC.2014.6975934
   Zhang YJ, 2020, PROC INT C TOOLS ART, P799, DOI 10.1109/ICTAI50040.2020.00127
   Zhong QW, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P785, DOI 10.1145/3366423.3380159
NR 50
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 10
BP 15345
EP 15370
DI 10.1007/s11042-022-13942-5
EA OCT 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA C1MX3
UT WOS:000863811400002
DA 2024-07-18
ER

PT J
AU Kwon, H
AF Kwon, Hyun
TI Adversarial image perturbations with distortions weighted by color on
   deep neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Image classification; Adversarial example; Evasion
   attack; Deep neural network (DNN)
ID CIELAB
AB Deep neural networks provide good performance in image recognition, speech recognition, text recognition, and pattern analysis. However, deep neural networks are vulnerable to adversarial examples. Adversarial examples are data created by adding a small perturbation to a normal sample such that they are correctly recognizable to a human but will be misrecognized by the neural network model. In this paper, I propose an adversarial example with different distortion weights for different colors (red, green, and blue), determined by considering the characteristics of the normal data. In studies of adversarial examples to date, weights have not been assigned to the normal data according to color; the proposed method generates adversarial examples having less human-perceptible distortion by assigning weights according to color. The proposed method creates adversarial examples that will be misrecognized by the model while minimizing the distortion for red, green, and blue components of the image by using different weights for each color. Evaluation testing was performed using CIFAR-10 as a dataset and TensorFlow as the machine learning library. In an experiment, the proposed adversarial example was created by a human being to be similar to the normal sample, with a resulting average minimum distortion of 78.25 and 47.25 in targeted and untargeted attacks, respectively, and a 100% attack success rate.
C1 [Kwon, Hyun] Korea Mil Acad, Dept Artificial Intelligence & Data Sci, 574 Hwarang Ro, Seoul 01819, South Korea.
RP Kwon, H (corresponding author), Korea Mil Acad, Dept Artificial Intelligence & Data Sci, 574 Hwarang Ro, Seoul 01819, South Korea.
EM hkwon.cs@gmail.com
RI Kwon, Hyun/M-1140-2018
OI Kwon, Hyun/0000-0003-1169-9892
FU AI R&D Center of Korea Military Academy; Hwarang-Dae Research Institute
   of Korea Military Academy; National Research Foundation of Korea (NRF) -
   Ministry of Education [2021R1I1A1A01040308]
FX This study was supported by the AI R&D Center of Korea Military Academy,
   the Hwarang-Dae Research Institute of Korea Military Academy, and Basic
   Science Research Program through the National Research Foundation of
   Korea (NRF) funded by the Ministry of Education (2021R1I1A1A01040308).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Bassett R, 2020, ARXIV
   Behjati M, 2019, INT CONF ACOUST SPEE, P7345, DOI [10.1109/ICASSP.2019.8682430, 10.1109/icassp.2019.8682430]
   Benz Philipp, 2020, AS C COMP VIS
   Bhattad A, 2019, ARXIV
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Carlini N, 2018, 2018 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2018), P1, DOI 10.1109/SPW.2018.00009
   Collobert R, 2008, P 25 ICML, P160, DOI 10.1145/1390156.1390177
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Elaskily MA, 2020, MULTIMED TOOLS APPL, V79, P19167, DOI 10.1007/s11042-020-08751-7
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Johnson GM, 2003, COLOR RES APPL, V28, P425, DOI 10.1002/col.10195
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kingma D. P., 2014, arXiv
   Krizhevsky A., 2014, The cifar-10 dataset
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Kurakin Alexey, 2017, INT C LEARN REPR
   Laidlaw C, 2019, ARXIV
   Liu Y, 2017, 5 INT C LEARNING REP
   Luo M.R, 2001, CIEDE2000, V26, P340
   MAHNY M, 1994, COLOR RES APPL, V19, P105
   McDaniel P, 2016, IEEE SECUR PRIV, V14, P68, DOI 10.1109/MSP.2016.51
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Odena A, 2016, ARXIV
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Qin Y, 2019, PR MACH LEARN RES, V97
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tolias G, 2019, IEEE I CONF COMP VIS, P5036, DOI 10.1109/ICCV.2019.00514
   Zhao ZY, 2020, PROC CVPR IEEE, P1036, DOI 10.1109/CVPR42600.2020.00112
NR 36
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13779
EP 13795
DI 10.1007/s11042-022-12941-w
EA OCT 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000863553600001
DA 2024-07-18
ER

PT J
AU Machidon, O
   Asprov, J
   Fajfar, T
   Pejovic, V
AF Machidon, Octavian
   Asprov, Jani
   Fajfar, Tine
   Pejovic, Veljko
TI Context-aware adaptation of mobile video decoding resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile computing; Approximate computing; Video decoding; Context
   inference; Spatial information; Temporal information
ID ENERGY-CONSUMPTION; PERSONALITY; QUALITY
AB While the evolution of mobile computing is experiencing considerable growth, it is at the same time seriously threatened by the limitations of battery technology, which does not keep pace with the evergrowing increase in energy requirements of mobile applications. Yet, with the limits of human perception and the diversity of requirements that individuals may have, a question arises of whether the effort should be made to always deliver the highest quality result to a mobile user? In this work we investigate how a user's physical activity, the spatial/temporal properties of the video, and the user's personality traits interact and jointly influence the minimal acceptable playback resolution. We conduct two studies with 45 participants in total and find out that the minimal acceptable resolution indeed varies across different contextual factors. Our predictive models inferring the lowest acceptable playback resolution, together with the reduced power consumption we measure at lower resolutions, open an opportunity for saving a mobile's energy through context-adaptable approximate computing.
C1 [Machidon, Octavian; Asprov, Jani; Fajfar, Tine; Pejovic, Veljko] Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana, Slovenia.
C3 University of Ljubljana
RP Machidon, O (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Ljubljana, Slovenia.
EM octavian.machidon@fri.uni-lj.si
RI Pejović, Veljko/L-2530-2016; Machidon, Octavian-Mihai/B-1406-2015
OI Machidon, Octavian-Mihai/0000-0003-3133-1008
FU Slovenian Research Agency [P20098, P2-0426, N2-0136]; Austrian Science
   Fund (FWF) [P20098] Funding Source: Austrian Science Fund (FWF)
FX The research presented in this paper was funded by Slovenian Research
   Agency (grants no. P20098, P2-0426 and N2-0136 "Bringing Resource
   Efficiency to Smartphones with Approximate Computing").
CR Ahmad H, 2018, MULTIMED TOOLS APPL, V77, P23877, DOI 10.1007/s11042-017-5603-z
   [Anonymous], 2019, TOP 30 ENERGY CONSUM
   [Anonymous], VIDEOLAN VLC MEDIA P
   [Anonymous], 2020, YOUTUBE PRESS YOUTUB
   [Anonymous], NEWPIPE LIBRE LIGHTW
   [Anonymous], MONSOON SOLUTIONS HI
   [Anonymous], STATISTACOM SMARTPHO
   [Anonymous], 2016, AVERAGE NUMBER APPS
   Barman N, 2019, IEEE INT WORKSH COMP, DOI 10.1109/camad.2019.8858486
   Beech F.M., 2020, FORBES
   Boisgontier MP, 2016, NEUROSCI BIOBEHAV R, V68, P1004, DOI 10.1016/j.neubiorev.2016.05.034
   cisco, CISC VIS NETW IND GL
   Cohen B., 2008, Explaining psychological statistics
   Dell N., 2012, P SIGCHI C HUMAN FAC, P1321, DOI [DOI 10.1145/2207676.2208589, 10.1145/2207676.2208589]
   Elliot J, 2017, INT SEEDS C
   Elwardy M, 2019, ISCIT 2019: PROCEEDINGS OF 2019 19TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P436, DOI 10.1109/ISCIT.2019.8905186
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Ferrer AJ, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3243929
   Graziano W. G., 1997, HDB PERSONALITY PSYC, P795
   Gulliver SR, 2010, ONLINE INFORM REV, V34, P39, DOI 10.1108/14684521011024119
   Hamzaoui Khalil Ibrahim, 2020, International Journal of Reasoning-based Intelligent Systems, V12, P4
   Hoque MA, 2013, 2013 IEEE 14TH INTERNATIONAL SYMPOSIUM AND WORKSHOPS ON A WORLD OF WIRELESS, MOBILE AND MULTIMEDIA NETWORKS (WOWMOM)
   Hu WJ, 2017, INT CON DISTR COMP S, P2314, DOI 10.1109/ICDCS.2017.74
   Infortuna C, 2021, PERS INDIV DIFFER, V178, DOI 10.1016/j.paid.2021.110877
   ITU-T, 2008, ITU T P910 SUBJECTIV
   Kassambara A., 2018, Machine Learning Essentials: Practical Guide in R, V1st ed
   Khosravi MH, 2022, MULTIMED TOOLS APPL, V81, P23193, DOI 10.1007/s11042-022-12478-y
   Li S, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P341, DOI 10.1145/3205289.3205317
   Liang WY, 2013, IEEE ICCE, P344, DOI 10.1109/ICCE.2013.6486921
   Machidon Octavian, 2020, MobiQuitous '20: MobiQuitous 2020 - 17th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services, P168, DOI 10.1145/3448891.3448948
   Maia OB, 2015, COMPUT COMMUN, V57, P1, DOI 10.1016/j.comcom.2014.11.005
   McIntosh A, 2019, EMPIR SOFTW ENG, V24, P562, DOI 10.1007/s10664-018-9629-2
   McNeish D, 2019, PSYCHOL METHODS, V24, P20, DOI 10.1037/met0000182
   Mittal S, 2016, ACM J EMERG TECH COM, V12, DOI 10.1145/2821510
   Moorthy AK, 2012, IEEE J-STSP, V6, P652, DOI 10.1109/JSTSP.2012.2212417
   Pejovic V, 2018, GETMOBILE-MOB COMPU, V22, P9, DOI 10.1145/3325867.3325871
   Rammstedt B, 2007, J RES PERS, V41, P203, DOI 10.1016/j.jrp.2006.02.001
   Satgunam PN, 2013, IEEE T IMAGE PROCESS, V22, P5146, DOI 10.1109/TIP.2013.2282120
   Schuler A, 2019, PROCEEDINGS OF THE 16TH EAI INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS SYSTEMS: COMPUTING, NETWORKING AND SERVICES (MOBIQUITOUS'19), P404, DOI 10.1145/3360774.3360808
   Scott MJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P481, DOI 10.1145/2733373.2806254
   Scott MJ, 2016, IEEE T MULTIMEDIA, V18, P1796, DOI 10.1109/TMM.2016.2574623
   See-To EWK, 2012, TECHNOL FORECAST SOC, V79, P1484, DOI 10.1016/j.techfore.2012.03.005
   Shin H, 2019, MULTIMED TOOLS APPL, V78, P28461, DOI 10.1007/s11042-017-5494-z
   Song Wei., 2011, Proceedings_of_the_19th_ACM international_conference_on_Multimedia, P403
   Spolladore L, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23091202
   Tomczak M., 2014, NEED REPORT EFFECT S, DOI DOI 10.1186/S13054-016-1208-6
   Trestian R, 2012, IEEE INT SYM BROADB
   Xue JT, 2014, IEEE J-STSP, V8, P390, DOI 10.1109/JSTSP.2014.2313456
   Yan M, 2019, ENERGIES, V12, DOI 10.3390/en12010184
   Zhang W, 2017, ACM T INTEL SYST TEC, V9, DOI 10.1145/3102301
   Zhu Y, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3183512
   Zhu Y, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P801, DOI 10.1145/2964284.2964330
   Zhu Y, 2015, COMPUT HUM BEHAV, V49, P412, DOI 10.1016/j.chb.2015.02.054
   Zhu Y, 2015, PROC SPIE, V9394, DOI 10.1117/12.2085002
   Zou LH, 2017, IEEE INT SYM BROADB, P539
NR 55
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 17599
EP 17630
DI 10.1007/s11042-022-13787-y
EA OCT 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000863553600008
PM 36213340
OA hybrid, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU De Pessemier, T
   Vanhecke, K
   Thomas, P
   Vander Mynsbrugge, T
   Vercoutere, S
   Van de Velde, D
   De Vriendt, P
   Joseph, W
   Martens, L
   Botteldooren, D
   Devos, P
AF De Pessemier, Toon
   Vanhecke, Kris
   Thomas, Pieter
   Vander Mynsbrugge, Tara
   Vercoutere, Stefaan
   Van de Velde, Dominique
   De Vriendt, Patricia
   Joseph, Wout
   Martens, Luc
   Botteldooren, Dick
   Devos, Paul
TI Personalising augmented soundscapes for supporting persons with dementia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Soundscape; Experience; Personalized; Dementia
ID SOUND; INTERVENTION; EXPERIENCE; DESIGN
AB The world population is aging and more and more people suffer from dementia, which makes remembering and orientation in time and space difficult. Moreover dementia has a strong negative effect on the quality of living of the people suffering from it, but also of their relatives. In this paper, we investigate if and how the playback of carefully chosen and recognizable sounds, such as music, a clock tower, or nature sounds, can help these people and have a positive effect on the behavioral and psychological symptoms of dementia (BPSD). The selection and playback of these sounds, augmenting the existing soundscape, is performed in a personalized manner, since sounds can elicit a different response in different people. Caregivers can provide feedback on the soundscape based on the resident's behavior and response to hearing the sounds. This allows a continuous adaptation of the soundscape. The soundscape system was tested with 19 people suffering from dementia and resident of 6 different nursing homes. Comparison of the nursing home environment before and after installation of the soundscape system showed that most residents (13/19) experienced this as an improvement of the sound environment.
C1 [De Pessemier, Toon; Vanhecke, Kris; Vercoutere, Stefaan; Joseph, Wout; Martens, Luc] Univ Ghent, Dept Informat Technol, IMEC, WAVES, iGent Technol Pk 126, B-9052 Ghent, Belgium.
   [Thomas, Pieter; Botteldooren, Dick; Devos, Paul] Univ Ghent, Dept Informat Technol, WAVES, iGent Technol Pk 126, B-9052 Ghent, Belgium.
   [Vander Mynsbrugge, Tara; Van de Velde, Dominique; De Vriendt, Patricia] Artevelde Univ Coll, Dept Occupat Therapy, Hoogpoort 15, B-9000 Ghent, Belgium.
C3 IMEC; Ghent University; Ghent University; Artevelde University of
   Applied Sciences
RP De Pessemier, T (corresponding author), Univ Ghent, Dept Informat Technol, IMEC, WAVES, iGent Technol Pk 126, B-9052 Ghent, Belgium.
EM toon.depessemier@ugent.be; kris.vanhecke@ugent.be;
   pieter.thomas@ugent.be; tara.vandermynsbrugge@arteveldehs.be;
   stefaan.vercoutere@ugent.be; dominique.vandevelde@arteveldehs.be;
   patricia.devriendt@arteveldehs.be; wout.joseph@ugent.be;
   lucl.martens@ugent.be; dick.botteldooren@ugent.be; p.devos@ugent.be
RI De Vos, Paul/J-5392-2013; Botteldooren, Dick/P-1506-2019
OI Botteldooren, Dick/0000-0002-7756-7238; Van de Velde,
   Dominique/0000-0001-6982-1075; Devos, Paul/0000-0003-4940-8886
FU Ghent University, Belgium
FX This research was performed in the context of the Acusticare IOF project
   (https://www.acusticare.be/) and funded by Ghent University, Belgium.
CR Aletta F, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7090874
   Alzheimer Europe, 2019, DEM EUR YB 2019 EST
   [Anonymous], 2020, 43SC1 ISOTC
   Berkheimer SD, 2017, J AM MED DIR ASSOC, V18, P1089, DOI 10.1016/j.jamda.2017.09.009
   Brown A. L., 2004, Journal of Environmental Planning and Management, V47, P827, DOI 10.1080/0964056042000284857
   Council of Europe, 2000, Eur. Treaty Ser
   de Boer C, 2014, GERIATR GERONTOL INT, V14, P880, DOI 10.1111/ggi.12183
   De Pessemier T, 2022, J AMB INTEL SMART EN, V14, P99, DOI 10.3233/AIS-220621
   De Pessemier T, 2016, MULTIMED TOOLS APPL, V75, P3323, DOI 10.1007/s11042-014-2437-9
   Devos P, 2015, EUR GERIATR MED, V6, P593, DOI 10.1016/j.eurger.2015.10.004
   Devos P, 2018, P INTERNOISE 2018 C
   Devos P, 2019, INT J ENV RES PUB HE, V16, DOI 10.3390/ijerph16244904
   Downing J.M., 2000, J ACOUST SOC AM, V108, P2497, DOI [DOI 10.1121/1.4743220, 10.1121/1.4743220]
   Haruvi A, 2021, BIORXIV
   Hong JY, 2013, J ACOUST SOC AM, V134, P2026, DOI 10.1121/1.4817924
   Iyendo TO, 2017, COMPLEMENT THER CLIN, V29, P58, DOI 10.1016/j.ctcp.2017.08.004
   Iyendo TO, 2016, INT J NURS STUD, V63, P82, DOI 10.1016/j.ijnurstu.2016.08.008
   Janer J, 2011, ISMAR WORKSHOP AUTHO
   Joshi S, 2020, 22ND INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY (ASSETS '20), DOI 10.1145/3373625.3418029
   Kang J, 2016, BUILD ENVIRON, V108, P284, DOI 10.1016/j.buildenv.2016.08.011
   Kang J, 2010, FRONT STRUCT CIV ENG, V4, P403, DOI 10.1007/s11709-010-0091-5
   Leontjevas R, 2021, INT PSYCHOGERIATR, V33, P553, DOI 10.1017/S1041610220003348
   Marcuzzi A, 2021, ALZHEIMERS DIS EPIDE
   National Collaborating Centre for Mental Health, 2011, DEMENTIA SUPPORTING
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   Schäfer T, 2015, FRONT PSYCHOL, V6, DOI 10.3389/fpsyg.2015.01140
   Somnox, SOMN 2 BREATH SLEEP
   stopalzheimer, STICHTING ALZHEIMER
   Thomas P, 2020, APPL ACOUST, V159, DOI 10.1016/j.apacoust.2019.107103
   Van Renterghem T, 2020, LANDSCAPE URBAN PLAN, V194, DOI 10.1016/j.landurbplan.2019.103705
   Vink A.C., 2003, Cochrane Database of Systematic Reviews, V4
   Willacy, MINI MENTAL STATE EX
   World Health Organisation, 2021, Fact Sheets Dementia
NR 33
TC 2
Z9 2
U1 12
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 14171
EP 14192
DI 10.1007/s11042-022-13839-3
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000861190800005
OA Green Published
DA 2024-07-18
ER

PT J
AU Ozer, I
   Ozer, CK
   Karaca, AC
   Gorur, K
   Kocak, I
   Cetin, O
AF Ozer, Ilyas
   Ozer, Caner Kaya
   Karaca, Ali Can
   Gorur, Kutlucan
   Kocak, Ismail
   Cetin, Onursal
TI Species-level microfossil identification for globotruncana genus using
   hybrid deep learning algorithms from the scratch via a low-cost light
   microscope imaging
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Globotruncana microfossil species; Hybrid deep learning algorithms;
   Paleontology science; Light microscope imaging
ID CONVOLUTIONAL NEURAL-NETWORKS; AUTOMATIC RECOGNITION; CLASSIFICATION;
   CNN; EVOLUTION; ECOLOGY; IMAGES; LSTM
AB Paleontologists generally use a low-cost electro-optical system to classify microfossils. This manual identification is a time-consuming process and it may take about a long time, especially if there are thousands of microfossil samples. In order to solve this problem, we propose a hybrid method based on Convolutional Neural Networks (CNN) and Bidirectional/Long Short-Time Memory (LSTM/BiLSTM) networks for the automatic classification of Globotruncana microfossil species. First, the images of microfossil samples were collected with a low-cost system and labeled by a paleontologist. After preprocessing, the classification is carried out with different combinations of CNN, LSTM, and Bidirectional LSTM (BiLSTM) models from the scratch developed in this paper. Finally, detailed experimental analyses have been made using accuracy, sensitivity, specificity, precision, F-score, and area under curve metrics. In the existing literature, as far as we know, this study is the first investigation work of prediction Globotruncana microfossil species using hybrid deep learning algorithms. Experiments demonstrate that the proposed models have reached the best accuracy with 97.35% and the best AUC score of 0.968 for automatic identification of Globotruncana microfossil species.
C1 [Ozer, Ilyas] Bandirma Onyedi Eylul Univ, Comp Engn Dept, Balikesir, Turkey.
   [Ozer, Caner Kaya] Yozgat Bozok Univ, Geol Engn Dept, Engn & Architecture Fac, Yozgat, Turkey.
   [Karaca, Ali Can] Yildiz Tech Univ, Comp Engn Dept, Istanbul, Turkey.
   [Gorur, Kutlucan; Cetin, Onursal] Bandirma Onyedi Eylul Univ, Elect & Elect Engn Dept, Balikesir, Turkey.
   [Kocak, Ismail] Bandinna Onyedi Eylul Univ, Dept Engn Sci, Balikesir, Turkey.
C3 Bandirma Onyedi Eylul University; Bozok University; Yildiz Technical
   University; Bandirma Onyedi Eylul University
RP Cetin, O (corresponding author), Bandirma Onyedi Eylul Univ, Elect & Elect Engn Dept, Balikesir, Turkey.
EM ocetin@bandirma.edu.tr
RI Koçak, İsmail/C-7060-2016; Özer, İlyas/AAI-2260-2021; Ozer,
   Caner/AAJ-6881-2021; Karaca, Ali Can/B-6629-2016
OI Koçak, İsmail/0000-0002-4519-4561; Özer, İlyas/0000-0003-2112-5497;
   Karaca, Ali Can/0000-0002-6835-7634; CETIN, ONURSAL/0000-0001-5220-3959;
   CANER, KAYA OZER/0009-0007-3251-1744
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Anderson TI, 2020, COMPUT GEOSCI-UK, V145, DOI 10.1016/j.cageo.2020.104593
   Bhadoria R, 2019, BIOMETRIC COMPUTING
   BOLLI HANS M., 1957, U S NATL MUS BULL, V215, P51
   Bollmann J, 2005, IMAGE ANAL SEDIMENTS, P229, DOI DOI 10.1007/1-4020-2122-4_12
   Bronnimann P., 1956, Eclogae Geologicae Helvetiae, V48, P503
   Bronnimann P, 1952, GLOBIGERINIDAE UPPER
   Brotzen F, 1942, Die Foraminiferengattung Gavelinella nov. gen. und die Systematik der Rotaliiformes
   Cai L, 2020, ANN TRANSL MED, V8, DOI 10.21037/atm.2020.02.44
   Caron M., 1985, P17
   Carvalho LE, 2020, MAR MICROPALEONTOL, V158, DOI 10.1016/j.marmicro.2020.101890
   Cetin O, 2023, ARAB J SCI ENG, V48, P1973, DOI 10.1007/s13369-022-07086-9
   Charles JJ, 2011, MACH VISION APPL, V22, P53, DOI 10.1007/s00138-009-0200-4
   Chen C, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101819
   CUSHMAN JOSEPH A., 1927, CONTRIB CUSHMAN LAB FORAMINIFERAL RES, V3, P1
   De Lima R.P., 2019, Sediment. Rec, V17, P4, DOI [10.2110/sedred.2019.2.4, DOI 10.2110/SEDRED.2019.2.4]
   De Lima RP, 2020, PALAIOS, V35, P391, DOI 10.2110/palo.2019.102
   Díez-Pastor JF, 2020, MICROSC MICROANAL, V26, P1158, DOI 10.1017/S1431927620024629
   Elder LE, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.109
   Encyclopaedia Britannica, 2017, PAL SCI
   Gorur K, 2023, ARAB J SCI ENG, V48, P1315, DOI 10.1007/s13369-022-06822-5
   Gorur K, 2019, TRAIT SIGNAL, V36, P319, DOI 10.18280/ts.360404
   Harlan Johnson, 1944, AAPG BULL, V28, P902, DOI [10.1306/3d93368e-16b1-11d7-8645000102c1865d, DOI 10.1306/3D93368E-16B1-11D7-8645000102C1865D]
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Hou YM, 2021, J MICROPALAEONTOL, V40, P163, DOI 10.5194/jm-40-163-2021
   Hou YM, 2020, IEEE ACCESS, V8, P148744, DOI 10.1109/ACCESS.2020.3016267
   Hsiang AY, 2019, PALEOCEANOGR PALEOCL, V34, P1157, DOI 10.1029/2019PA003612
   Huber BT, 2008, J FORAMIN RES, V38, P162, DOI 10.2113/gsjfr.38.2.162
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Itaki T, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77812-6
   Itaki T, 2020, PROG EARTH PLANET SC, V7, DOI 10.1186/s40645-020-00332-4
   Johansen TH., 2020, Proc. North. Light Deep Learn. Work, V1, P6, DOI [10.7557/18.5144, DOI 10.7557/18.5144]
   Karaderi Tayfun, 2022, Pattern Recognition and Artificial Intelligence: Third International Conference, ICPRAI 2022, Proceedings, Part I. Lecture Notes in Computer Science (13363), P34, DOI 10.1007/978-3-031-09037-0_4
   Keçeli AS, 2017, COMPUT GEOSCI-UK, V109, P67, DOI 10.1016/j.cageo.2017.08.011
   Ketin I., 1963, Report No. 288
   Laporte LF., 1988, PALAIOS, V3, P453, DOI [10.2307/3514718, DOI 10.2307/3514718]
   Li JL, 2019, IEEE ACCESS, V7, P75464, DOI 10.1109/ACCESS.2019.2919566
   Liu XS, 2022, SOFT COMPUT, V26, P10741, DOI 10.1007/s00500-022-06957-5
   Marchant R, 2020, J MICROPALAEONTOL, V39, P183, DOI 10.5194/jm-39-183-2020
   Marmo R, 2006, INT C PATT RECOG, P691
   METZ CE, 1978, SEMIN NUCL MED, V8, P283, DOI 10.1016/S0001-2998(78)80014-2
   Mitra R, 2019, MAR MICROPALEONTOL, V147, P16, DOI 10.1016/j.marmicro.2019.01.005
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Ostrom JH, 2020, STRATIGRAPHY PALEONT
   Ozer I., 2020, M HENDISLIK BILIM AR, V2, P50, DOI [10.46387/bjesr.790225, DOI 10.46387/BJESR.790225]
   Ozer I, 2021, NEURAL COMPUT APPL, V33, P14975, DOI 10.1007/s00521-021-06133-0
   Ozer I, 2021, ALEX ENG J, V60, P3807, DOI 10.1016/j.aej.2021.02.050
   Pedraza A, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7050460
   Pessagno, 1967, UPPER CRETACEOUS PLA
   Petrizzo MR, 2011, CRETACEOUS RES, V32, P387, DOI 10.1016/j.cretres.2011.01.010
   Petrizzo MR, 2002, MAR MICROPALEONTOL, V45, P117, DOI 10.1016/S0377-8398(02)00020-8
   Postuma J., 1971, Manual of Planktonic Foraminifera, P1
   Prothero Donald., 2007, Evolution: What the Fossils Say and Why it Matters
   Rafi SH, 2021, IEEE ACCESS, V9, P32436, DOI 10.1109/ACCESS.2021.3060654
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rehn E, 2019, QUATERNARY SCI REV, V226, DOI 10.1016/j.quascirev.2019.106038
   Reichel M., 1950, Eclogae Geologicae Helvetiae, V42, P596
   Renaudie J, 2018, ACCURACY NEURAL NET, DOI [10.7287/peerj.preprints.27328v1, DOI 10.7287/PEERJ.PREPRINTS.27328V1]
   Rhanoui M, 2019, MACH LEARN KNOW EXTR, V1, P832, DOI 10.3390/make1030048
   Robaszynski F, 1984, ATLAS LATE CRETACEOU
   Singh LK, 2021, MED BIOL ENG COMPUT, V59, P333, DOI 10.1007/s11517-020-02307-5
   Solano GA, 2018, INT CONF INFORM INTE, P94
   Waikato TU of, 2021, WAIKATO TU
   Xiang L, 2021, MEASUREMENT, V175, DOI 10.1016/j.measurement.2021.109094
   Xiao SH, 2009, TRENDS ECOL EVOL, V24, P31, DOI 10.1016/j.tree.2008.07.015
   Xu YX, 2020, IEEE ACCESS, V8, P172972, DOI 10.1109/ACCESS.2020.3024819
   Yang S., 2017, Southwest Respir. Crit. Care Chron, V5, P34, DOI DOI 10.12746/SWRCCC.V5I19.391
   Yasuhara M, 2020, OCEANOGRAPHY, V33, P16, DOI 10.5670/oceanog.2020.225
NR 69
TC 8
Z9 8
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13689
EP 13718
DI 10.1007/s11042-022-13810-2
EA SEP 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000860416200002
DA 2024-07-18
ER

PT J
AU Gunisetti, L
   Koduri, SB
   Jagannathan, V
AF Gunisetti, Loshma
   Koduri, Shirin Bhanu
   Jagannathan, Veeraraghavan
TI Optimized deep learning system for smart maize leaf disease detection in
   IoT platform via routing algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Leaf disease detection; Routing; Statistical features; Competitive swarm
   optimizer; Competitive shuffled shepherd optimization
ID IDENTIFICATION; PROTOCOL
AB Automatic recognition of leaf disease in plant is a difficult task in trending intelligent agriculture because of the variances of appearances and surroundings of crop diseases. In this paper, initially, the IoT nodes are simulated for gathering leaf information and the gathered information is transmitted through the optimal routes where the routes are selected using developed Competitive Shuffled Shepherd Optimization (CSSO) algorithm. The CSSO algorithm is designed by the integration of Competitive Swarm Optimizer (CSO) and Shuffled Shepherd Optimization algorithm (SSOA) for selecting the optimal path. The Leaf disease detection process is performed in the base station, where the detection process includes, pre-processing, feature extraction and disease detection. The pre-processing is carried out though ROI extraction, and the features, like Convolutional Neural Network (CNN) features, statistical features and energy texture features is employed to extract the relevant features. Finally, the maize leaf disease is detected from the extracted features using Deep Quantum Neural Network (Deep QNN), where the weight of Deep QNN is trained using developed CSSO algorithm. The experimental result demonstrates that the developed method outperforms than the existing methods based on the accuracy, sensitivity, specificity, F-Measure, energy, and delay of 95.037%, 96.404%, 93.35%, 95.12%, 99.9 J and 11.3 s, respectively.
C1 [Gunisetti, Loshma; Koduri, Shirin Bhanu] Sri Vasavi Engn Coll, Dept Comp Sci & Engn, Pedatadepalli, Tadepalligudem, India.
   [Jagannathan, Veeraraghavan] Bharat Clouds Private Ltd, Chennai, Tamil Nadu, India.
RP Gunisetti, L (corresponding author), Sri Vasavi Engn Coll, Dept Comp Sci & Engn, Pedatadepalli, Tadepalligudem, India.
EM loshmagunis69@gmail.com
RI KODURI, SHIRIN BHANU/AAE-5717-2022; Gunisetti, Loshma/F-3319-2011
OI KODURI, SHIRIN BHANU/0000-0002-8469-8287; Gunisetti,
   Loshma/0000-0002-8664-7619; JAGANNATHAN,
   VEERARAGHAVAN/0009-0005-5481-5541
CR Anandkumar M., 2020, MULTIMEDIA RES, V3, P43, DOI [10.46253/j.mr.v3i4.a5, DOI 10.46253/J.MR.V3I4.A5]
   Anisi M. H., 2020, J. Wirel. Mob. NetworksUbiquitous Comput. Dependable Appl, V11, P77, DOI [DOI 10.22667/JOWUA.2020.12.31.077, 10.22667/JOWUA.2020.12.31.77, DOI 10.22667/JOWUA.2020.12.31.77]
   [Anonymous], MAIZE IMAGE
   Barbedo JGA, 2016, BIOSYST ENG, V144, P52, DOI 10.1016/j.biosystemseng.2016.01.017
   Badage Anuradha, 2018, Int Res J Eng Technol, V5, P866
   Balachandra M, 2014, WIREL NETW, V20, P2395, DOI 10.1007/s11276-014-0754-6
   Bansal Subodh, 2020, IOP Conference Series: Materials Science and Engineering, V998, DOI 10.1088/1757-899X/998/1/012065
   Beer K, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14454-2
   Cheng R, 2015, IEEE T CYBERNETICS, V45, P191, DOI 10.1109/TCYB.2014.2322602
   Dineva K., 2020, PROCEEDING 20 INT MU, V20, P207
   Farooq MS, 2019, IEEE ACCESS, V7, P156237, DOI 10.1109/ACCESS.2019.2949703
   Gu MS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154091
   Hu TQ, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102764
   Hu WJ, 2020, IEEE ACCESS, V8, P115287, DOI 10.1109/ACCESS.2020.3001237
   Ibrahim GJ, 2020, J PARALLEL DISTR COM, V143, P77, DOI 10.1016/j.jpdc.2020.05.002
   Iniyan S, 2020, ADV INTELL SYST COMP, V1056, P15, DOI 10.1007/978-981-15-0199-9_2
   Kar A, 2013, ARXIV, DOI DOI 10.48550/ARXIV.1312.1512
   Kaveh A, 2020, ENG COMPUTATION, V37, P2357, DOI 10.1108/EC-10-2019-0481
   Khattab A, 2019, COMPUT ELECTRON AGR, V166, DOI 10.1016/j.compag.2019.105028
   Kulkarni O, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Kumar R, 2016, WIREL NETW, V22, P1461, DOI 10.1007/s11276-015-1039-4
   Lai JC, 2010, AGR SCI CHINA, V9, P1221, DOI 10.1016/S1671-2927(09)60210-8
   Lakshmi ND, 2013, 3 INT C COMPUTATIONA
   Li Y, 2021, SOIL TILL RES, V205, DOI 10.1016/j.still.2020.104758
   Li Z, 2020, AGR WATER MANAGE, V242, DOI 10.1016/j.agwat.2020.106397
   Lokulwar PP, 2017, 2017 INTERNATIONAL CONFERENCE ON I-SMAC (IOT IN SOCIAL, MOBILE, ANALYTICS AND CLOUD) (I-SMAC), P721, DOI 10.1109/I-SMAC.2017.8058273
   Mishra M, 2021, J AMB INTEL HUM COMP, V12, P691, DOI 10.1007/s12652-020-02051-6
   Qadir QM, 2018, IEEE ACCESS, V6, P77454, DOI 10.1109/ACCESS.2018.2883151
   Saengchai S., 2019, International Journal of Supply Chain Management, V8, P572
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Shamsaldin A., 2019, UKH J. Sci. Eng., V3, P31, DOI 10.25079/ukhjse.v3n2y2019.pp31-40
   Shukla R, 2021, J SCI IND RES INDIA, V80, P699
   Thakur TB, 2020, INT J INNOV SCI MOD, V6, P1
   Thorat A, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P193, DOI 10.1109/BID.2017.8336597
   Tongke F., 2019, EDP SCI, V131
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Usak M, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4179
   Vipaporn, 2019, SYST REV PHARM, V10, P352
   Wu C, 2023, SOFT COMPUT, V27, P3307, DOI 10.1007/s00500-021-05839-6
   Xenakis A, 2020, INT CONF INFORM INTE, P28, DOI 10.1109/iisa50023.2020.9284356
   Yadav AK, 2017, PEER PEER NETW APPL, V10, P897, DOI 10.1007/s12083-016-0441-8
   Zhao YS, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106128
NR 42
TC 2
Z9 2
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2023
VL 82
IS 9
BP 13533
EP 13555
DI 10.1007/s11042-022-13775-2
EA SEP 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA F7PG4
UT WOS:000859866600006
DA 2024-07-18
ER

PT J
AU Londhe, AN
   Atulkar, M
AF Londhe, Aboli N.
   Atulkar, Mithilesh
TI A compact hybrid fully convolutional and BiLSTM network with squeeze and
   temporal excitation approach for semantic segmentation of ECG signal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; Semantic segmentation; Channel-mix convolution; Filter squeeze and
   temporal excitation; Compact hybrid network
ID HOLTER ECG; QT; ALGORITHM; DELINEATION; DETECTOR
AB Existing approaches for ECG wave segmentation, only focused on the P, QRS, and T wave localization using machine and deep learning approaches. Although, deep learning-based approaches have achieved satisfactory results, but these approaches generate a large number of trainable parameters which leads to the computational burden and overfitting problem. Moreover, the existing approaches do not consider PR and ST segments which affects the precise localization of fiducial points. Hence, to alleviate these problems a novel approach to compress deep architecture has been proposed to localize key ECG waves along with PR and ST segments. For compressing the deep models, we first time implemented a filter squeeze and temporal excitation approach. The proposed method involves- i) Semantic segmentation of ECG waves and segments using hybrid convolutional and BiLSTM networks to extract temporal dependencies, and ii) Integration of filter squeeze and temporal excitation (FS-TE) which adaptively recalibrates temporal feature responses by exhibiting temporal interdependencies. The experiments on the standard QT database of Physionet with the proposed network achieved similar to 3% increment in the performance and 2 times reduction in the number of parameters as compared to the existing method. The proposed model learns channel-wise relevant temporal features with less computational cost as compared to existing stacked BiLSTM-based approaches for semantic segmentation of ECG waves.
C1 [Londhe, Aboli N.; Atulkar, Mithilesh] Natl Inst Technol Raipur, Dept Comp Applicat, GE Rd, Raipur 492010, Chhattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Londhe, AN (corresponding author), Natl Inst Technol Raipur, Dept Comp Applicat, GE Rd, Raipur 492010, Chhattisgarh, India.
EM abolinimje@gmail.com
CR Abrishami Hedayat, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P210, DOI 10.1109/BHI.2018.8333406
   Abrishami H., 2018, 2018 Int'l Conf. Bioinformatics and Computational Biology (BIOCOMP'18), P71
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Altuve M, 2007, 4 LAT AM C BIOM ENG, P1254
   Andreao RV, 2006, IEEE T BIO-MED ENG, V53, P1541, DOI 10.1109/TBME.2006.877103
   [Anonymous], 2005, BMC Cardiovasc. Disord, DOI DOI 10.1186/1471-2261-5-28
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Beraza I, 2017, BIOMED SIGNAL PROCES, V34, P166, DOI 10.1016/j.bspc.2017.01.013
   Campbell MJ, 2017, HEART RHYTHM, V14, P848, DOI 10.1016/j.hrthm.2017.02.011
   de Chazal P, 1997, P IEEE EMBS, V18, P1399, DOI 10.1109/IEMBS.1996.647474
   Dumont J, 2005, COMPUT CARDIOL, V32, P707
   Francois Chollet., 2015, keras.io, DOI DOI 10.1086/316861
   Frénay B, 2009, IFMBE PROC, V22, P1212
   Ghaffari A, 2010, ANN BIOMED ENG, V38, P1497, DOI 10.1007/s10439-010-9919-3
   Graja S, 2003, I S INTELL SIG PR, P105
   Gupta R., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P63, DOI 10.1109/EAIT.2011.61
   Homaeinezhad MR, 2011, UNIFIED FRAMEWORK DE
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hughes NP, MARKOV MODELS AUTOMA
   Illanes-Manriquez A, 2010, IEEE ENG MED BIO, P2334, DOI 10.1109/IEMBS.2010.5627473
   Illanes-Martriquez A, 2008, COMPUTERS IN CARDIOLOGY 2008, VOLS 1 AND 2, P857, DOI 10.1109/CIC.2008.4749177
   Jane R, 1997, COMPUT CARDIOL, V24, P295, DOI 10.1109/CIC.1997.647889
   Kaiser W, 1996, J ELECTROCARDIOL, V29, P17, DOI 10.1016/S0022-0736(96)80004-5
   Karimipour A, 2014, COMPUT BIOL MED, V52, P153, DOI 10.1016/j.compbiomed.2014.07.002
   Kingma D. P., 2014, arXiv
   LAGUNA P, 1990, MED BIOL ENG COMPUT, V28, P67, DOI 10.1007/BF02441680
   LAGUNA P, 1994, COMPUT BIOMED RES, V27, P45, DOI 10.1006/cbmr.1994.1006
   Laguna P, 1997, COMPUT CARDIOL, V24, P673, DOI 10.1109/CIC.1997.648140
   Last T, 2004, BIOMED ENG ONLINE, V3, DOI 10.1186/1475-925X-3-26
   LI CW, 1995, IEEE T BIO-MED ENG, V42, P21, DOI 10.1109/10.362922
   Liang XH, 2022, COMPUT BIOL MED, V145, DOI 10.1016/j.compbiomed.2022.105445
   Londhe AN, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102162
   Londhe AN, 2020, MODELLING ANAL ACTIV, V2, P12
   Madeiro JPV, 2012, MED ENG PHYS, V34, P1236, DOI 10.1016/j.medengphy.2011.12.011
   Martínez A, 2010, PHYSIOL MEAS, V31, P1467, DOI 10.1088/0967-3334/31/11/005
   Martínez JP, 2000, COMPUT CARDIOL, V27, P81, DOI 10.1109/CIC.2000.898460
   Mukhopadhyay SK, 2011, P 2011 INT C COMMUNI
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nurmaini S, 2021, IEEE ACCESS, V9, P92600, DOI 10.1109/ACCESS.2021.3092631
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Schreier G, 2003, J ELECTROCARDIOL, V36, P145, DOI 10.1016/j.jelectrocard.2003.09.039
   Sodmann P, 2018, PHYSIOL MEAS, V39, DOI 10.1088/1361-6579/aae304
   Stamkopoulos T, 2000, COMPUT CARDIOL, V27, P529, DOI 10.1109/CIC.2000.898575
   Tutuko B, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062329
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Vila JA, 2000, IEEE T BIO-MED ENG, V47, P764, DOI 10.1109/10.844227
   Warner RA, 2002, J ELECTROCARDIOL, V35, P111, DOI 10.1054/jelc.2002.37163
   Xia HN, 2013, COMPUT METH PROG BIO, V110, P253, DOI 10.1016/j.cmpb.2012.11.008
NR 50
TC 0
Z9 0
U1 5
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12679
EP 12697
DI 10.1007/s11042-022-13821-z
EA SEP 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000855612200003
DA 2024-07-18
ER

PT J
AU Gupta, S
   Mishra, A
AF Gupta, Shikha
   Mishra, Atul
TI Revenue-maximizing ranking algorithm for advertisers in sponsored search
   advertising using novel adaptive keyword-weighted approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time; Keyword-based search; Sponsored search; Keywords; Bid term;
   Bid price; Bid period; Online advertisement
AB Sponsored search has emerged as a prominent form of advertising on the internet and acts as a major source of revenue for various search engines. In this, the attention of the user is drawn towards the ads, presented as sponsored links, along with organic search results, to the entered query, on a given search engine. Advertisers bid on keywords (also referred to as bid terms) of possible future search queries and pay accordingly on getting clicked. It is observed that normally the advertisers bid on frequently occurring keywords in the search queries which often leaves the revenue space of search engines underexplored. The paper presents a novel technique for maximizing the revenue of a given search engine by an adaptive keyword-weighted approach. The proposed approach ensures weight assignment to keywords based upon their impression-winning capability adaptively and progressively. It then couples the weights assigned with the rarity factor of the keywords leading to a revenue-maximizing ranking mechanism. Advertisers with lower bid values but relevant rare keywords are explored over the higher bidders. Quantitative analysis results show that the proposed algorithm is efficient and it shows significant improvement compared to the generalized balance algorithm.
C1 [Gupta, Shikha; Mishra, Atul] JC Bose Univ Sci & Technol, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Gupta, S (corresponding author), JC Bose Univ Sci & Technol, Faridabad, Haryana, India.
EM Shikha.0909@gmail.com; mish.atul@gmail.com
RI Gupta, Shikha/IRZ-7324-2023; MIshra, Atul/GON-8740-2022
OI MIshra, Atul/0000-0003-4929-2676
CR An W, 2011, IEEE T SYST MAN CY A, V41, P1092, DOI 10.1109/TSMCA.2011.2114342
   [Anonymous], GOOGLE ADS
   Baadsgaard J, 2018, WHAT IS GOOGLE ADWOR
   Bateni MohammadHossein, 2014, P 15 ACM C EC COMPUT, P715, DOI DOI 10.1145/2600057.2602874
   Choi TM, 2015, IEEE T SYST MAN CY-S, V45, P1178, DOI 10.1109/TSMC.2015.2394501
   Deshwal Parul., 2016, International Journal of Applied Research, V2, P200, DOI https://www.allresearchjournal.com/archives/2016/vol2issue2/PartD/2-1-131.pdf
   Devanur NR, 2009, 10TH ACM CONFERENCE ON ELECTRONIC COMMERCE - EC 2009, P71
   Edelman B, 2010, AM ECON REV, V100, P597, DOI 10.1257/aer.100.2.597
   Ghose A, 2007, WORKING PAPERS
   Grbovic M, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P375, DOI 10.1145/2911451.2911538
   Gupta Shikha, 2021, International Journal of Technology Diffusion, V12, P1, DOI 10.4018/IJTD.2021070104
   Gupta Shikha, 2020, IOP Conference Series: Materials Science and Engineering, V804, DOI 10.1088/1757-899X/804/1/012043
   Gupta S, 2021, BIG DATA ANALYTICS A, DOI [10.2139/ssrn.3884656, DOI 10.2139/SSRN.3884656]
   Jain R, 2010, AUTOMATICA, V46, P1276, DOI 10.1016/j.automatica.2010.05.013
   Johnson J, 2021, ADVERTISING REVENUE
   Klapdor S, 2014, J INTERACT MARK, V28, P285, DOI 10.1016/j.intmar.2014.07.001
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Li H, 2011, IEICE T INF SYST, VE94D, P1854, DOI 10.1587/transinf.E94.D.1854
   McLaughlin, 2016, 1605 ESI
   Nagarad S, 2019, GOOGLE ADWORDS
   Oberoi A, 2013, HIST ONLINE ADVERTIS
   Qu YZ, 2011, IEEE T SYST MAN CY A, V41, P810, DOI 10.1109/TSMCA.2011.2132705
   Ribeiro-Neto B., 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P496, DOI 10.1145/1076034.1076119
   Ruggiero C, 2017, INT WORLD WID WEB C
   Rusmevichientong DP, 2006, P 7 ACM C EL COMM EC, P260, DOI [DOI 10.1145/1134707.1134736, 10.1145/1134707.1134736]
   Shin W, 2015, MARKET SCI, V34, P882, DOI 10.1287/mksc.2015.0915
   Xia CL, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P485, DOI 10.1109/ASONAM.2016.7752279
   Yuan S, 2013, ARXIV
   Yuan S, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P1897, DOI 10.1145/2623330.2623357
NR 29
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 12043
EP 12064
DI 10.1007/s11042-022-13747-6
EA SEP 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000854848100002
DA 2024-07-18
ER

PT J
AU Singh, CEJ
   Jagatheeswari, A
AF Singh, C. Edward Jaya
   Jagatheeswari, A.
TI Secured blind digital certificate and Lamport Merkle cloud assisted
   medical image sharing using blockchain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic health record; Cloud computing environment; Blockchain; Blind
   digital Certificate; Lamport Merkle; Authentication
ID SYSTEM
AB In the standard Electronic Health Record (EHR) management system, the medical service center supervises and dispenses the corresponding health records that are found to be a laborious process for sharing on several medical platforms. In recent years, blockchain technology has started gaining as one of the most favored possibilities based on dissimilar platforms to share EHRs. However, with the increased nature and size of the EHR storing data also involves a tedious process. The computation and communication cost are the challenges involved in accessing medical image information is not analyzed. The falsification rate for HER was not focused. To sort out this issue, the cloud computing (CC) environment is contemplated as an encouraging solution. Woefully, the EHR with CC environment is found to be susceptible to several attacks due to the sending of sensitive medical image data over a public channel. A secured method with Blind Digital Certificate and Lamport Merkle (BBDC-LM) Cloud-assisted Medical Image Sharing using Blockchain is proposed in our work. In the proposed BBDC-LM method, blockchain performs the task of access control and therefore ensuring security and minimum falsification of the entire process. Blind Digital Certificate is used for generating keys to contribute communication and computational cost. On the other hand, the cloud server stores and manages the patient's five different classes of images (i.e., MRI, CT, X-ray, Annotated, and Ultrasound) to provide computationally efficient storage. The empirical results show that our proposed BBDC-LM method provides an efficient solution for reliable medical image data sharing between patients and medical analyzers in a secured manner. Lamport Merkle functions where the leaves from the authentication among patient and medical analyzer are performed by cloud server. The system evaluation and security analysis also demonstrate the performance improvements in minimum communication and computation cost with a minimum false positive rate compared to the existing medical image sharing methods.
C1 [Singh, C. Edward Jaya] Nesamony Mem Christian Coll, Comp Sci, Marthandam, India.
   [Jagatheeswari, A.] Lekshmipuram Coll Arts & Sci, Comp Sci, Lekshmipuram, India.
RP Singh, CEJ (corresponding author), Nesamony Mem Christian Coll, Comp Sci, Marthandam, India.
EM cmedwardsingh@gmail.com; ajagatheeswari@yahoo.com
OI , EDWARD JAYA SINGH/0000-0002-8878-1504
CR Benil T, 2020, COMPUT NETW, V178, DOI 10.1016/j.comnet.2020.107344
   Boussif M, 2018, IET NETW, V7, P294, DOI 10.1049/iet-net.2017.0180
   Chen Y, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1121-4
   Cheng WZ, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/6647562
   Chukwu E, 2020, IEEE ACCESS, V8, P21196, DOI 10.1109/ACCESS.2020.2969881
   Alonso SG, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1195-7
   Huang HP, 2021, J PARALLEL DISTR COM, V148, P46, DOI 10.1016/j.jpdc.2020.10.002
   Huang L, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8859961
   Kleinaki AS, 2018, COMPUT STRUCT BIOTEC, V16, P288, DOI 10.1016/j.csbj.2018.08.002
   Meier P, 2021, INF SYST E-BUS MANAG, V19, P13, DOI 10.1007/s10257-020-00476-2
   Nagasubramanian G, 2020, NEURAL COMPUT APPL, V32, P639, DOI 10.1007/s00521-018-3915-1
   Nguyen DC, 2019, IEEE ACCESS, V7, P66792, DOI 10.1109/ACCESS.2019.2917555
   Nweke HF, 2019, INFORM FUSION, V46, P147, DOI 10.1016/j.inffus.2018.06.002
   Pournaghi SM, 2020, J AMB INTEL HUM COMP, V11, P4613, DOI 10.1007/s12652-020-01710-y
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Roehrs A, 2019, J BIOMED INFORM, V92, DOI 10.1016/j.jbi.2019.103140
   Schrader L, 2020, J POPUL AGEING, V13, P139, DOI 10.1007/s12062-020-09260-z
   Silva CA, 2019, WIREL COMMUN MOB COM, DOI 10.1155/2019/1968960
   Wang H, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0994-6
NR 19
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9323
EP 9342
DI 10.1007/s11042-022-13719-w
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000847629600002
DA 2024-07-18
ER

PT J
AU Smerdov, A
   Somov, A
   Burnaev, E
   Stepanov, A
AF Smerdov, Anton
   Somov, Andrey
   Burnaev, Evgeny
   Stepanov, Anton
TI AI-enabled prediction of video game player performance using the data
   from heterogeneous sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eSports; Machine learning; Neural networks; Sensor network; Video gaming
ID SKILL; CLASSIFICATION; MOTION; STRESS; SPORTS
AB The emerging progress of video gaming and eSports lacks the tools for ensuring high-quality analytics and training in professional and amateur eSports teams. We report on an Artificial Intelligence (AI) enabled solution for predicting the eSports player in-game performance using exclusively the data from sensors. For this reason, we collected the physiological, environmental, and the smart chair data from professional and amateur players. The player performance is assessed from the game logs in a multiplayer game for each moment of time using a recurrent neural network. We have investigated an attention mechanism improves the generalization of the network and provides a straightforward feature importance as well. The best model achieves Area Under the Receiver Operating Characteristic Curve (ROC AUC) score 0.73 in predicting whether a player will perform better or worse in the next 240 seconds based on in-game metrics. The prediction of the performance of a particular player is realized although their data are not utilized in the training set. The proposed solution has a number of promising applications for professional eSports teams and amateur players, such as a learning tool or performance monitoring system.
C1 [Smerdov, Anton; Somov, Andrey; Burnaev, Evgeny; Stepanov, Anton] Skolkovo Inst Sci & Technol Skoltech, CDE, Moscow, Russia.
C3 Skolkovo Institute of Science & Technology
RP Somov, A (corresponding author), Skolkovo Inst Sci & Technol Skoltech, CDE, Moscow, Russia.
EM a.somov@skoltech.ru
RI Somov, Andrey/AAY-9278-2021; Stepanov, Anton/H-9037-2016; Burnaev,
   Evgeny/A-3703-2016
OI Somov, Andrey/0000-0002-4615-3008; Burnaev, Evgeny/0000-0001-8424-0690
FU Russian Foundation for Basic Research (RFBR) [18-29-22077]
FX The reported study was funded by Russian Foundation for Basic Research
   (RFBR) according to the research project No. 18-29-22077.
CR Ahmadi A, 2006, IEEE SENSOR, P980
   Ahmidi N, 2010, LECT NOTES COMPUT SC, V6363, P295
   Allen JG, 2016, ENVIRON HEALTH PERSP, V124, P805, DOI 10.1289/ehp.1510037
   Anderson C., 2018, P 10 INT C VIRTUAL W, DOI [DOI 10.1109/VS-GAMES.2018.8493445, 10.1109/VS-Games.2018.8493445]
   Ando B, 2020, IEEE T INSTRUM MEAS, V69, P8020, DOI 10.1109/TIM.2020.2967498
   Baig MZ, 2019, MULTIMODAL TECHNOLOG, V3, DOI 10.3390/mti3020037
   Blom PM, 2019, IEEE CONF COMPU INTE
   Buckley D., 2013, COMPUTATIONAL INTELL, P1, DOI [10.4324/9780203107386, DOI 10.1109/CIG.2013.6633655]
   Cornforth D.J., 2015, Serious Games Analytics: Methodologies for Performance Measurement, Assessment, and Improvement, P135, DOI 10.1007/978-3-319-05834-4_6
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Diaz-Romero DJ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3059467
   Drachen A., 2012, 2012 IEEE Conference on Computational Intelligence and Games (CIG 2012), P163, DOI 10.1109/CIG.2012.6374152
   Drachen A., 2010, Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games, P49, DOI DOI 10.1145/1836135.1836143
   Dymarski P., 2011, HIDDEN MARKOV MODELS, DOI [10.1002/sim.4780100317, DOI 10.1002/SIM.4780100317]
   Eggert C, 2015, LECT NOTES COMPUT SC, V9353, P112, DOI 10.1007/978-3-319-24589-8_9
   Ershad M, 2018, IEEE ENG MED BIO, P1829, DOI 10.1109/EMBC.2018.8512593
   Fan Jerome, 2006, CJEM, V8, P19
   FOWLES DC, 1980, PSYCHOPHYSIOLOGY, V17, P87, DOI 10.1111/j.1469-8986.1980.tb00117.x
   Gao L, 2013, CLASSIFYING DOTA 2 H
   Garmin Ltd, 2012, HEART RATE MONITOR
   Groh BH, 2017, PERVASIVE MOB COMPUT, V40, P42, DOI 10.1016/j.pmcj.2017.05.007
   Haladjian J, 2020, ACM T INTERNET THING, V1, DOI 10.1145/3372342
   Hara K, 2015, IEEE IJCNN, P1, DOI DOI 10.1109/IJCNN.2015.7280578
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hodge V, 2017, ARXIV
   Inc Digilent, 2017, PMOD HYGR REF MAN
   Inc Digilent, 2016, PMODTMP3 REFERENCE M
   InvenSense Inc, 2016, MPU 9250 PROD SPEC
   James D.A., 2009, SPORTS TECHNOL, V2, P129, DOI [DOI 10.1080/19346182.2009.9648510, 10.1080/19346182.2009.9648510]
   Khan A, 2015, PROCEEDINGS OF THE 2015 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP 2015), P1155, DOI 10.1145/2750858.2807534
   Khromov N, 2019, IEEE PERVAS COMPUT, V18, P31, DOI 10.1109/MPRV.2019.2926247
   Kim JH, 2009, COMPUT STAT DATA AN, V53, P3735, DOI 10.1016/j.csda.2009.04.009
   Kingma D. P., 2014, arXiv
   Kodama K, 2015, P 34 CHIN CONTR C SI, P139
   Kranz M, 2013, PERVASIVE MOB COMPUT, V9, P203, DOI 10.1016/j.pmcj.2012.06.002
   Kyong Jin Shim, 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P617, DOI 10.1109/PASSAT/SocialCom.2011.155
   Ladha C, 2013, UBICOMP'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P235, DOI 10.1145/2493432.2493492
   Lan L, 2011, INDOOR AIR, V21, P376, DOI 10.1111/j.1600-0668.2011.00714.x
   LEHRER PM, 1988, PSYCHOPHYSIOLOGY, V25, P562, DOI 10.1111/j.1469-8986.1988.tb01892.x
   Lin, LEAGUE LEGENDS MATCH
   Liu L., 2019, arXiv
   Ltd Zhengzhou Winsen Electronics Technology Co, 2016, INTELLIGENT INFRARED
   Makarov Ilya., 2017, INT C ANAL IMAGES SO, P183
   Märtens M, 2015, ANN WORK NETW
   Martin-Niedecken AL, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.00138
   Matsumura S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21030834
   Nagorsky E, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237584
   Newzoo, 2021, GLOB ESP MARK REP
   Qin Yao, 2017, ARXIV
   Roose Kaitlyn M., 2020, Proceedings of the Human Factors and Ergonomics Society Annual Meeting, V64, P1780, DOI 10.1177/1071181320641430
   Saponara S, 2017, IEEE T INSTRUM MEAS, V66, P2545, DOI 10.1109/TIM.2017.2677679
   Seeed Technology Inc, 2015, GROV GSR TECHN REP
   Seeed Technology Inc, 2015, GROV EMG DET
   Smerdov A, 2021, IEEE INTERNET THINGS, V8, P16680, DOI 10.1109/JIOT.2021.3074740
   Smerdov A, 2019, 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019), P1768, DOI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00314
   Smerdov A, 2019, 2019 IEEE 5TH WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P973, DOI [10.1109/wf-iot.2019.8767295, 10.1109/WF-IoT.2019.8767295]
   Smithies TD, 2021, RANDOM FOREST APPROA
   Stone T, 2019, IEEE T INSTRUM MEAS, V68, P2979, DOI 10.1109/TIM.2018.2872307
   Taelman J, 2009, IFMBE PROC, V22, P1366
   Tang H, 2018, IEEE W SP LANG TECH, P48, DOI 10.1109/SLT.2018.8639517
   Tsoi AC, 1997, NEUROCOMPUTING, V15, P183, DOI 10.1016/S0925-2312(97)00161-6
   Tuncer T, 2020, IEEE T INSTRUM MEAS, V69, P9441, DOI 10.1109/TIM.2020.3003395
   Velichkovsky BB, 2019, LECT NOTES COMPUT SC, V11746, P397, DOI 10.1007/978-3-030-29381-9_25
   Viggiato M., 2020, Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, V16, P294
   Wang JX, 2020, IEEE T INSTRUM MEAS, V69, P8526, DOI 10.1109/TIM.2020.2992183
   Wang YF, 2018, IEEE ACCESS, V6, P13758, DOI 10.1109/ACCESS.2018.2792220
   Wang ZL, 2018, IEEE T INSTRUM MEAS, V67, P2692, DOI 10.1109/TIM.2018.2826198
   Xenopoulos P, 2020, IEEE INT CONF BIG DA, P1283, DOI 10.1109/BigData50022.2020.9378154
   Xochicale M, 2017, BIOSYST BIOROBOT, V16, P149, DOI 10.1007/978-3-319-46532-6_25
   Yamamoto T, 2008, HUM MOVEMENT SCI, V27, P812, DOI 10.1016/j.humov.2008.07.001
   Yamanaka H, 2015, ADV UROL, V2015, DOI 10.1155/2015/495308
   Yang Y, 2016, ARXIV
   Yi S, 2017, ARXIV
   Yuji, 2005, MEMORY 32128MBIT
   Zhu MH, 2020, J EXPO SCI ENV EPID, V30, P285, DOI 10.1038/s41370-019-0154-1
NR 76
TC 1
Z9 1
U1 4
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 11021
EP 11046
DI 10.1007/s11042-022-13464-0
EA AUG 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000842923900002
PM 36035326
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Alarcao, SM
   Mendonça, V
   Maruta, C
   Fonseca, MJ
AF Alarcao, Soraia M.
   Mendonca, Vania
   Maruta, Carolina
   Fonseca, Manuel J.
TI ExpertosLF: dynamic late fusion of CBIR systems using online learning
   with relevance feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Late fusion; Prediction with expert
   advice; Online learning; Relevance feedback
ID IMAGE RETRIEVAL; NEURAL-NETWORKS; DESCRIPTOR; INTEGRATION; WAVELET;
   COLOR; HISTOGRAM; TEXTURE; SCALE
AB One of the main challenges in CBIR systems is to choose discriminative and compact features, among dozens, to represent the images under comparison. Over the years, a great effort has been made to combine multiple features, mainly using early, late, and hierarchical fusion techniques. Unveiling the perfect combination of features is highly domain-specific and dependent on the type of image. Thus, the process of designing a CBIR system for new datasets or domains involves a huge experimentation overhead, leading to multiple fine-tuned CBIR systems. It would be desirable to dynamically find the best combination of CBIR systems without needing to go through such extensive experimentation and without requiring previous domain knowledge. In this paper, we propose ExpertosLF, a model-agnostic interpretable late fusion technique based on online learning with expert advice, which dynamically combines CBIR systems without knowing a priori which ones are the best for a given domain. At each query, ExpertosLF takes advantage of user's feedback to determine each CBIR contribution in the ensemble for the following queries. ExpertosLF produces an interpretable ensemble that is independent of the dataset and domain. Moreover, ExpertosLF is designed to be modular, and scalable. Experiments on 13 benchmark datasets from the Biomedical, Real, and Sketch domains revealed that: (i) ExpertosLF surpasses the performance of state of the art late-fusion techniques; (ii) it successfully and quickly converges to the performance of the best CBIR sets across domains without any previous domain knowledge (in most cases, fewer than 25 queries need to receive human feedback).
C1 [Alarcao, Soraia M.; Fonseca, Manuel J.] Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
   [Mendonca, Vania] Univ Lisbon, Inst Super Tecn, INESC ID, Lisbon, Portugal.
   [Maruta, Carolina] Univ Lisbon, Fac Med, Ctr Estudos Egas Moniz, Lab Estudos Linguagem, Lisbon, Portugal.
C3 Universidade de Lisboa; Universidade de Lisboa; INESC-ID; Universidade
   de Lisboa; Instituto Superior de Ciencias da Saude Egas Moniz
RP Alarcao, SM (corresponding author), Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
EM smalarcao@ciencias.ulisboa.pt; vania.mendonca@tecnico.ulisboa.pt;
   carolmaruta@gmail.com; mjfonseca@ciencias.ulisboa.pt
RI Fonseca, Manuel J./D-5120-2011; Meneses Alarcão, Soraia/HLP-7664-2023;
   Maruta, Carolina/HTQ-4182-2023
OI Fonseca, Manuel J./0000-0002-3559-828X; Meneses Alarcão,
   Soraia/0000-0002-0794-2979; Maruta, Carolina/0000-0003-3359-379X;
   Mendonca, Vania/0000-0001-5729-7608
FU Fundacao para a Ciencia e a Tecnologia (FCT) [UIDB/00408/2020,
   UIDP/00408/2020]; INESC-ID Research Unit [UIDB/50021/2020]; FCT
   [SFRH/BD/12 1443/2016, SFRH/BD/138263/2018]; Fundação para a Ciência e a
   Tecnologia [SFRH/BD/138263/2018] Funding Source: FCT
FX This work was supported by national funds through FundacAo para a
   Ciencia e a Tecnologia (FCT) under the LASIGE Research Unit, ref.
   UIDB/00408/2020 and ref. UIDP/00408/2020, and the INESC-ID Research
   Unit, ref. UIDB/50021/2020. Soraia M. AlarcAo is funded by an FCT grant,
   ref. SFRH/BD/138263/2018, and Vania Mendonca was funded by an FCT grant,
   ref. SFRH/BD/12 1443/2016.
CR Ahmed A, 2020, IEEE ACCESS, V8, P79969, DOI 10.1109/ACCESS.2020.2990557
   Ahmed KT, 2019, INFORM FUSION, V51, P76, DOI 10.1016/j.inffus.2018.11.004
   Ahn E, 2019, MED IMAGE ANAL, V56, P140, DOI 10.1016/j.media.2019.06.005
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alzu'bi A, 2017, NEUROCOMPUTING, V249, P95, DOI 10.1016/j.neucom.2017.03.072
   [Anonymous], 1973, The Art of Color: The Subjective Experience and Objective Rationale of Color
   [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.45
   [Anonymous], 2017, INT J DATA SCI ANAL, DOI DOI 10.1007/S41060-017-0056-Z
   [Anonymous], 2013, CLARIFAI
   Ashraf R, 2020, MULTIMED TOOLS APPL, V79, P8553, DOI 10.1007/s11042-018-5961-1
   Ashraf R, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0880-7
   Babaie M., 2017, 2017 Seventh International Conference on Image Processing Theory, Tools and Applications (IPTA), P1
   Banerjee I, 2018, J BIOMED INFORM, V84, P123, DOI 10.1016/j.jbi.2018.07.002
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bella MIT, 2019, COMPUT ELECTR ENG, V75, P46, DOI 10.1016/j.compeleceng.2019.01.022
   Bhardwaj Shikha, 2020, International Journal of Computer Information Systems and Industrial Management Applications, P1, DOI 10.5303/JKAS.2020.53.6.169
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Camalan S, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0232776
   Cesa-Bianchi N., 2006, PREDICTION LEARNING, DOI DOI 10.1017/CBO9780511546921
   Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   Chatzichristofis S., 2009, Proc. ofthe 6th IASTED International Conference, V134643, page, P064
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Chu K, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/1461459
   Chung Y.A., 2017, ARXIV
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   de Ves E, 2016, NEUROCOMPUTING, V208, P99, DOI 10.1016/j.neucom.2016.02.073
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DICE LR, 1945, ECOLOGY, V26, P297, DOI 10.2307/1932409
   Dubey SR, 2017, J VIS COMMUN IMAGE R, V49, P141, DOI 10.1016/j.jvcir.2017.09.004
   Dang-Nguyen DT, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3103613
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Graf F., 2015, ROMAN FESTIVALS GREE
   Hamreras S, 2020, INTEGR COMPUT-AID E, V27, P317, DOI 10.3233/ICA-200625
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang J., 2001, US Patent, Patent No. [6,246,790, 6246790]
   Huu QN, 2021, MULTIMED TOOLS APPL, V80, P15351, DOI 10.1007/s11042-020-10400-y
   Imisketchsdb, 2012, IMISKETCHSDB
   Jaccard P., 1912, New Phytologist, V11, P37, DOI [10.1111/j.1469-8137.1912.tb05611.x, DOI 10.1111/J.1469-8137.1912.TB05611.X]
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jian MW, 2018, MULTIMED TOOLS APPL, V77, P29099, DOI 10.1007/s11042-018-6122-2
   Kanaparthi SK, 2020, MULTIMED TOOLS APPL, V79, P34875, DOI 10.1007/s11042-019-08029-7
   Karamti H, 2018, MULTIMED TOOLS APPL, V77, P5475, DOI 10.1007/s11042-017-4463-x
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Kriegel HP, 2011, 2 MULTICLUST WORKSH, P55
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P59, DOI 10.1016/j.imu.2018.12.001
   LAI TL, 1985, ADV APPL MATH, V6, P4, DOI 10.1016/0196-8858(85)90002-8
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li HL, 2016, VISUAL COMPUT, V32, P1351, DOI 10.1007/s00371-016-1232-1
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu PZ, 2017, IEEE T IMAGE PROCESS, V26, P5706, DOI 10.1109/TIP.2017.2736343
   Liu SL, 2017, MULTIDIM SYST SIGN P, V28, P1071, DOI 10.1007/s11045-016-0386-3
   Liu XR, 2016, IEEE IJCNN, P2872, DOI 10.1109/IJCNN.2016.7727562
   Lu HM, 2021, IEEE T FUZZY SYST, V29, P166, DOI 10.1109/TFUZZ.2020.2984991
   Lux M., 2013, SYNTHESIS LECT INFOR
   Mahmoud AM, 2020, MULTIMED TOOLS APPL, V79, P20281, DOI 10.1007/s11042-020-08825-6
   Majhi M, 2021, MULTIMED TOOLS APPL, V80, P7271, DOI 10.1007/s11042-020-10005-5
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Markonis D, 2017, ARXIV
   Mosbah Mawloud, 2017, International Journal of Web Science, V3, P58
   Muller H, 2010, IMAGE CLEF EXPT EVAL, V32
   Neshov NN, 2013, LECT NOTES COMPUT SC, V8131, P619, DOI 10.1007/978-3-642-40728-4_77
   OCHIAI AKIRA, 1957, BULL JAPANESE SOC SCI FISH, V22, P522
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Otsuka Y., 1936, BIOGEOGRAPH SOC JAPA, V6, P165
   Pavithra LK, 2018, COMPUT ELECTR ENG, V70, P580, DOI 10.1016/j.compeleceng.2017.08.030
   Pesenko Y.A., 1982, Principles and methods of quantitative analysis in faunistic research
   Phadikar BS, 2018, PATTERN ANAL APPL, V21, P469, DOI 10.1007/s10044-016-0589-0
   Pinjarkar L, 2020, J INTELL SYST, V29, P894, DOI 10.1515/jisys-2018-0083
   Piras L, 2017, INFORM FUSION, V37, P50, DOI 10.1016/j.inffus.2017.01.003
   Putzu L, 2020, MULTIMED TOOLS APPL, V79, P26995, DOI 10.1007/s11042-020-09292-9
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Raghuwanshi G, 2021, MULTIMED TOOLS APPL, V80, P2295, DOI 10.1007/s11042-020-09618-7
   Rana SP, 2019, J VIS COMMUN IMAGE R, V58, P205, DOI 10.1016/j.jvcir.2018.11.015
   Rao YB, 2018, WORLD WIDE WEB, V21, P1505, DOI 10.1007/s11280-017-0523-4
   Reta C, 2018, MULTIMED TOOLS APPL, V77, P8163, DOI 10.1007/s11042-017-4708-8
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Saritha RR, 2019, CLUSTER COMPUT, V22, pS4187, DOI 10.1007/s10586-018-1731-0
   Sathiamoorthy S, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1941-y
   Satish B, 2017, 2017 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT), P424
   Sezavar A, 2019, MULTIMED TOOLS APPL, V78, P20895, DOI 10.1007/s11042-019-7321-1
   Shete D.S., 2012, International Journal of Emerging Technology and Advanced Engineering, V2, P85
   Song Bai, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P774, DOI 10.1109/ICCV.2017.90
   Spanhol FA, 2017, IEEE SYS MAN CYBERN, P1868, DOI 10.1109/SMC.2017.8122889
   Spanhol FA, 2016, IEEE IJCNN, P2560, DOI 10.1109/IJCNN.2016.7727519
   Srensen T., 1948, K DANSKE VIDENSK SEL, V5, P1, DOI DOI 10.1234/12345678
   Srivastava P, 2017, J VIS COMMUN IMAGE R, V42, P78, DOI 10.1016/j.jvcir.2016.11.008
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Sze-To A, 2020, LECT NOTES ARTIF INT, P453, DOI 10.1007/978-3-030-59137-3_40
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tang JH, 2018, PATTERN RECOGN, V75, P25, DOI 10.1016/j.patcog.2017.03.028
   Tang X, 2017, IEEE J-STARS, V10, P1824, DOI 10.1109/JSTARS.2017.2664119
   Thapa R., 2020, arXiv
   Tizhoosh H. R., 2016, Advances in Visual Computing. 12th International Symposium, ISVC 2016. Proceedings: LNCS 10072, P617, DOI 10.1007/978-3-319-50835-1_55
   Tizhoosh HR, 2016, INT C PATT RECOG, P3150, DOI 10.1109/ICPR.2016.7900119
   Tschandl P, 2018, SCI DATA, V5, DOI 10.1038/sdata.2018.161
   Tsochatzidis L, 2017, PATTERN RECOGN, V71, P106, DOI 10.1016/j.patcog.2017.05.023
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Varish N, 2016, INT J IMAGE MINING
   Varish N, 2017, MULTIMED TOOLS APPL, V76, P15885, DOI 10.1007/s11042-016-3882-4
   Vatavu RD, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P273
   Vieira, 2014, THESIS IST ULISBOA
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P256, DOI 10.1016/j.jvcir.2016.03.008
   Wang XF, 2019, J VIS COMMUN IMAGE R, V61, P260, DOI 10.1016/j.jvcir.2019.03.024
   Wei Z, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6283987
   Xu H, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P629, DOI 10.1109/ICIVC.2017.7984632
   Xu N, 2016, PLOS ONE, V11, DOI [10.1371/journal.pone.0159623, 10.1371/journal.pone.0152463]
   Yan CG, 2019, IEEE T MULTIMEDIA, V21, P2675, DOI 10.1109/TMM.2019.2903448
   Yuan BH, 2020, NEURAL COMPUT APPL, V32, P11717, DOI 10.1007/s00521-019-04657-0
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhang J, 2018, IEEE T MULTIMEDIA, V20, P2400, DOI 10.1109/TMM.2018.2804763
   Zhang LN, 2016, IEEE T IMAGE PROCESS, V25, P1275, DOI 10.1109/TIP.2016.2516947
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zhou W., 2017, ARXIV
   Zhu YY, 2017, INFORM SCIENCES, V375, P246, DOI 10.1016/j.ins.2016.09.021
NR 123
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 8
BP 11619
EP 11661
DI 10.1007/s11042-022-13119-0
EA AUG 2022
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9O4PB
UT WOS:000842724300003
PM 36035324
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Fouladi, S
   Safaei, AA
   Arshad, NI
   Ebadi, MJ
   Ahmadian, A
AF Fouladi, Saman
   Safaei, Ali A.
   Arshad, Noreen Izza
   Ebadi, M. J.
   Ahmadian, Ali
TI The use of artificial neural networks to diagnose Alzheimer's disease
   from brain images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease; Artificial neural network; Deep learning; MRI; PET;
   CT; Diagnosis
ID MILD COGNITIVE IMPAIRMENT; DEEP LEARNING-MODEL; AUTOMATED DETECTION;
   DATA AUGMENTATION; CANCER-TREATMENT; STRUCTURAL MRI; CLASSIFICATION;
   PREDICTION; IDENTIFICATION; CONVOLUTION
AB Since Alzheimer's disease (AD) occurs in multiple stages of cognitive impairment, its early diagnosis can be helpful in the process of treatment. Its early diagnosis is thus drawn the attention of researchers and physicians. This study aims to investigate various types of artificial neural networks (ANNs) used to diagnose and predict AD based on brain images of subjects with mild cognitive impairment (MCI). In this study, articles indexed in the IEEE, Springer, Elsevier, and PubMed Central databases were systematically analyzed over the period from 2010 through the first half of 2020. The initial search was done for the keywords Alzheimer's, Magnetic resonance imaging (MRI), and neural network, continued for the keywords Alzheimer's, brain positron emission tomography(PET), and neural network, and ended with the keywords Alzheimer's, brain computed tomography (CT), and neural network. Eventually, the most relevant articles were selected based on the critical evaluation of the subject under investigation. Searching on the subject through the mentioned databases resulted in 900 articles. Excluding unrelated ones, only 134 articles remained, out of which, 54, 41, 35, and 4 numbers were respectively indexed in PubMed Central, Elsevier, Springer, and IEEE databases. The number of studies increased by about 2.5 times from 2016 to 2017 and followed this growing trend at the rate of 2 times by 2018. The number of these studies was increasing up to the first half of 2020. There was a wide use of data from Alzheimer's disease neuroimaging initiative (ADNI) database compared to open access series of imaging studies (OASIS) and other databases by the researchers. MRI images, PET images, and their combination were respectively used in 61%, 21%, and 15% of the researches. This is while only 2% of the studies used CT images, suggestive of their inefficiency compared to other brain imaging techniques in diagnosing AD. Most studies either grouped subjects into Alzheimer's patients and healthy people or classified them under three groups of subjects with Alzheimer's, cognitive impairment, and in good health. However, different stages of cognitive impairment have merely considered in 16% of the studies. The main purpose of all studies was AD classification and diagnosis. Further research should be conducted to classify and diagnose this disease in subjects with MCI. It is recommended to use ADNI as a comprehensive database of images from people with various degrees of cognitive impairment, AD, and health control (HC) in future research.
C1 [Fouladi, Saman; Safaei, Ali A.] Tarbiat Modares Univ, Fac Med Sci, Dept Med Informat, Tehran, Iran.
   [Arshad, Noreen Izza] Univ Teknol Petronas, Dept Comp & Informat Sci, Inst Autonomous Syst, Posit Comp Res Grp, Bandar Seri Iskandar 32610, Perak, Malaysia.
   [Ebadi, M. J.] Chabahar Maritime Univ, Dept Math, Chabahar, Iran.
   [Ebadi, M. J.] Int Telemat Univ Uninettuno, Sect Math, Corso Vittorio Emanuele II 39, I-00186 Rome, Italy.
   [Ahmadian, Ali] Mediterranea Univ Reggio Calabria, Decis Lab, I-89124 Reggio Di Calabria, Italy.
   [Ahmadian, Ali] Near East Univ, Dept Math, 10 Mersin, Nicosia, Trnc, Turkey.
C3 Tarbiat Modares University; Universiti Teknologi Petronas; UNINETTUNO;
   Universita Mediterranea di Reggio Calabria; Near East University
RP Ebadi, MJ (corresponding author), Chabahar Maritime Univ, Dept Math, Chabahar, Iran.; Ebadi, MJ (corresponding author), Int Telemat Univ Uninettuno, Sect Math, Corso Vittorio Emanuele II 39, I-00186 Rome, Italy.; Ahmadian, A (corresponding author), Mediterranea Univ Reggio Calabria, Decis Lab, I-89124 Reggio Di Calabria, Italy.; Ahmadian, A (corresponding author), Near East Univ, Dept Math, 10 Mersin, Nicosia, Trnc, Turkey.
EM ebadi@cmu.ac.ir; ahmadian.hosseini@unirc.it
RI Ahmadian, Ali/N-3697-2015; Ebadi, Javad/H-4423-2019; Safaei,
   Ali/ABD-3920-2021
OI Ahmadian, Ali/0000-0002-0106-7050; Ebadi, Javad/0000-0002-1324-6953;
   Safaei, Ali/0000-0003-1985-8720
CR Abrol A, 2020, J NEUROSCI METH, V339, DOI 10.1016/j.jneumeth.2020.108701
   Acharya UR, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1428-9
   Agatonovic-Kustrin S, 2000, J PHARMACEUT BIOMED, V22, P717, DOI 10.1016/S0731-7085(99)00272-1
   Aguilar C, 2013, PSYCHIAT RES-NEUROIM, V212, P89, DOI 10.1016/j.pscychresns.2012.11.005
   Akhila DB, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P748, DOI 10.1109/ICETECH.2016.7569348
   Altaher A., 2021, Journal of Bioengineering Research, V3, P1, DOI [10.22034/jbr.2021.262544.1037, DOI 10.22034/JBR.2021.262544.1037]
   Amin-Naji Mostafa, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P75, DOI 10.1109/PRIA.2019.8786031
   Amoroso N, 2018, J NEUROSCI METH, V302, P3, DOI 10.1016/j.jneumeth.2017.12.011
   [Anonymous], 2018, What You Need to Know about Foodborne Illnesses
   Azmi MH, 2017, RADIAT PHYS CHEM, V137, P135, DOI 10.1016/j.radphyschem.2016.08.028
   Bäckström K, 2018, I S BIOMED IMAGING, P149, DOI 10.1109/ISBI.2018.8363543
   Basaia S, 2019, NEUROIMAGE-CLIN, V21, DOI 10.1016/j.nicl.2018.101645
   Basheera S, 2019, ALZH DEMENT-TRCI, V5, P974, DOI 10.1016/j.trci.2019.10.001
   Baskar D, 2019, MULTIMED TOOLS APPL, V78, P12883, DOI 10.1007/s11042-018-6287-8
   Basu S., 2019, EARLY PREDICTION ALZ, P205
   Baydargil HB, 2019, INT C CONTR AUTOMAT, P891, DOI [10.23919/iccas47443.2019.8971696, 10.23919/ICCAS47443.2019.8971696]
   Beheshti I, 2015, COMPUT BIOL MED, V64, P208, DOI 10.1016/j.compbiomed.2015.07.006
   Ben Ahmed O, 2020, I S BIOMED IMAGING, P1459, DOI [10.1109/isbi45749.2020.9098419, 10.1109/ISBI45749.2020.9098419]
   Bertè F, 2014, FUNCT NEUROL, V29, P57, DOI 10.11138/FNeur/2014.29.1.057
   Bhagwat N, 2019, J PSYCHIATR NEUROSCI, V44, P246, DOI 10.1503/jpn.180016
   Bhatkoti P, 2016, INT CONF IMAG VIS, P250
   Bi XL, 2020, NEUROCOMPUTING, V392, P296, DOI 10.1016/j.neucom.2018.11.111
   Bidmon H, 2009, EUR NEUROL REV, V4, P76
   Bin Tufail A, 2020, J DIGIT IMAGING, V33, P1073, DOI 10.1007/s10278-019-00265-5
   Chaddad A, 2018, IEEE ACCESS, V6, P58213, DOI 10.1109/ACCESS.2018.2871977
   Chen YY, 2018, LECT NOTES ARTIF INT, V10989, P303, DOI 10.1007/978-3-030-00563-4_29
   Cheng D., 2017, CLASSIFICATION ALZHE, P106, DOI [DOI 10.1007/978-3-319-67389-93_13, 10.1007/978-3-319-67389-933]
   Cheng D, 2017, 2017 10TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI)
   Chincarini A, 2011, NEUROIMAGE, V58, P469, DOI 10.1016/j.neuroimage.2011.05.083
   Choi H, 2020, EUR J NUCL MED MOL I, V47, P403, DOI 10.1007/s00259-019-04538-7
   Choi H, 2018, BEHAV BRAIN RES, V344, P103, DOI 10.1016/j.bbr.2018.02.017
   Chrysos GG, 2022, IEEE T PATTERN ANAL, V44, P4021, DOI 10.1109/TPAMI.2021.3058891
   Chyzhyk D, 2014, NEUROCOMPUTING, V128, P73, DOI 10.1016/j.neucom.2013.01.065
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dehghan H., 2011, 2011 18th Iranian Conference of Biomedical Engineering (ICBME), P37, DOI 10.1109/ICBME.2011.6168581
   Dimitriadis SI, 2018, NEURAL REGEN RES, V13, P962, DOI 10.4103/1673-5374.233433
   Ebadi M. J., 2021, Progress in Intelligent Decision Science. Proceeding of IDS 2020. Advances in Intelligent Systems and Computing (AISC 1301), P185, DOI 10.1007/978-3-030-66501-2_15
   Ebadi M. J., 2018, Journal of Theoretical and Applied Information Technology, V96, P1999
   Ebadi MJ, 2017, NEUROCOMPUTING, V235, P164, DOI 10.1016/j.neucom.2017.01.010
   Ebadi M. J., 2020, J NEW RES MATH, V6, P97
   Ebrahimi-Ghahnavieh A, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON INDUSTRY 4.0, ARTIFICIAL INTELLIGENCE, AND COMMUNICATIONS TECHNOLOGY (IAICT), P133, DOI [10.1109/iciaict.2019.8784845, 10.1109/ICIAICT.2019.8784845]
   Eitel F, 2020, LECT NOTES COMPUT SC, V11797, P3, DOI 10.1007/978-3-030-33850-3_1
   El-Gamal FEZA, 2017, IEEE IMAGE PROC, P3270, DOI 10.1109/ICIP.2017.8296887
   Esmaeilzadeh S, 2018, LECT NOTES COMPUT SC, V11046, P337, DOI 10.1007/978-3-030-00919-9_39
   Ezazipour S, 2020, KYBERNETIKA, V56, P383, DOI 10.14736/kyb-2020-3-0383
   Farooq A, 2017, 2017 INTERNATIONAL SMART CITIES CONFERENCE (ISC2)
   Farooq A, 2017, IEEE CONF IMAGING SY, P111
   Feng CY, 2019, IEEE ACCESS, V7, P63605, DOI 10.1109/ACCESS.2019.2913847
   Feng CY, 2018, LECT NOTES COMPUT SC, V11121, P138, DOI 10.1007/978-3-030-00320-3_17
   Forouzannezhad P, 2018, 2018 17TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P1341, DOI 10.1109/ICMLA.2018.00218
   Fouladi S, 2021, COMPUT COMMUN, V176, P234, DOI 10.1016/j.comcom.2021.06.011
   Gao F, 2020, NEUROIMAGE-CLIN, V27, DOI 10.1016/j.nicl.2020.102290
   Gao XHW, 2017, COMPUT METH PROG BIO, V138, P49, DOI 10.1016/j.cmpb.2016.10.007
   Gao XHW, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P28, DOI 10.1109/SAI.2016.7555958
   Garali I, 2016, BIOMED SIGNAL PROCES, V27, P15, DOI 10.1016/j.bspc.2016.01.009
   García-Sebastián M, 2009, LECT NOTES COMPUT SC, V5517, P957, DOI 10.1007/978-3-642-02478-8_120
   Ghorui N, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2020.103811
   Golbabai A, 2020, NEURAL COMPUT APPL, V32, P3887, DOI 10.1007/s00521-019-04391-7
   Golbabai A, 2017, EXPERT SYST APPL, V82, P291, DOI 10.1016/j.eswa.2017.04.016
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guangyu He, 2019, 2019 10th International Conference on Information Technology in Medicine and Education (ITME). Proceedings, P13, DOI 10.1109/ITME.2019.00014
   Gunawardena KANNP, 2017, I C MECH MACH VIS PR, P173
   Guo JM, 2019, IEEE INT CONF BIG DA, P5359
   Han K., 2019, INT C PION COMP SCI, P658
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herrera LJ, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P846, DOI 10.1109/SocialCom.2013.127
   Heydarpoor F, 2020, INT J COMB OPTIM PRO, V11, P61
   Heydarpour F, 2020, INT J INTERACT MULTI, V6, P18, DOI 10.9781/ijimai.2020.11.011
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hon M, 2017, IEEE INT C BIOINFORM, P1166, DOI 10.1109/BIBM.2017.8217822
   Hong X, 2019, IEEE ACCESS, V7, P80893, DOI 10.1109/ACCESS.2019.2919385
   Hosseini-Asl E, 2016, IEEE IMAGE PROC, P126, DOI 10.1109/ICIP.2016.7532332
   Hu CH, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7510831
   Hyeon Kang, 2018, 2018 5th International Conference on Computational Science and Computational Intelligence (CSCI), P1442, DOI 10.1109/CSCI46756.2018.00281
   Islam J, 2017, LECT NOTES ARTIF INT, V10654, P213, DOI 10.1007/978-3-319-70772-3_20
   Islam J, 2018, LECT NOTES ARTIF INT, V11309, P359, DOI 10.1007/978-3-030-05587-5_34
   Islam Jyoti, 2018, Brain Inform, V5, P2, DOI 10.1186/s40708-018-0080-3
   Jabason E, 2018, IEEE INT NEW CIRC, P344, DOI 10.1109/NEWCAS.2018.8585550
   Jain N, 2021, RESULTS PHYS, V21, DOI 10.1016/j.rinp.2021.103813
   Jain R, 2019, COGN SYST RES, V57, P147, DOI 10.1016/j.cogsys.2018.12.015
   Jamali N, 2021, NEURAL PROCESS LETT, V53, P131, DOI 10.1007/s11063-020-10369-7
   Janghel RR, 2021, IRBM, V42, P258, DOI 10.1016/j.irbm.2020.06.006
   Ju RH, 2019, IEEE ACM T COMPUT BI, V16, P244, DOI 10.1109/TCBB.2017.2776910
   Karasawa H., 2018, DEEP 3D CONVOLUTIONA, P287
   Karwath A., 2017, CONVOLUTIONAL NEURAL, P316
   Kavitha M, 2019, 2019 IEEE 11TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA 2019), P89, DOI [10.1109/IWCIA47330.2019.8955006, 10.1109/iwcia47330.2019.8955006]
   Khagi B, 2018, 2018 11 BIOM ENG INT, P1, DOI DOI 10.1109/BMEICON.2018.8609974
   Kim HW, 2020, EUR J NUCL MED MOL I, V47, P2197, DOI 10.1007/s00259-019-04676-y
   Kim JY, 2019, NUCL MED MOLEC IMAG, V53, P340, DOI 10.1007/s13139-019-00610-0
   Koh JEW, 2020, PATTERN RECOGN LETT, V135, P106, DOI 10.1016/j.patrec.2020.03.014
   Kompanek M, 2019, INT CONF SYST SIGNAL, P115
   Korolev S, 2017, I S BIOMED IMAGING, P835, DOI 10.1109/ISBI.2017.7950647
   Kruthika K. R., 2019, Informatics in Medicine Unlocked, V14, P59, DOI 10.1016/j.imu.2018.12.001
   Kundu R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-93658-y
   Lazli L, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9100289
   Lemoine B., 2010, DATA FUSION FEATURE, P320
   Li F, 2017, 2017 IEEE INT C IM S, P1, DOI 10.1109/IST.2017.8261566
   Li XJ, 2017, LECT NOTES ARTIF INT, V10604, P519, DOI 10.1007/978-3-319-69179-4_36
   Lian CF, 2020, IEEE T PATTERN ANAL, V42, P880, DOI 10.1109/TPAMI.2018.2889096
   Liu MH, 2018, NEUROINFORMATICS, V16, P295, DOI 10.1007/s12021-018-9370-4
   Liu MX, 2019, IEEE T BIO-MED ENG, V66, P1195, DOI 10.1109/TBME.2018.2869989
   Liu SQ, 2015, IEEE T BIO-MED ENG, V62, P1132, DOI 10.1109/TBME.2014.2372011
   Liu XN, 2018, TRANSL RES, V194, P56, DOI 10.1016/j.trsl.2018.01.001
   López M, 2011, NEUROCOMPUTING, V74, P1260, DOI 10.1016/j.neucom.2010.06.025
   Lu DH, 2018, MED IMAGE ANAL, V46, P26, DOI 10.1016/j.media.2018.02.002
   Lulu Yue, 2018, 2018 14th International Conference on Natural Computation, Fuzzy Systems and Knowledge Discovery (ICNC-FSKD), P228, DOI 10.1109/FSKD.2018.8687207
   Mahanand BS, 2012, NEURAL NETWORKS, V32, P313, DOI 10.1016/j.neunet.2012.02.035
   Marghalani Bashayer Fouad, 2019, Procedia Computer Science, V163, P78, DOI 10.1016/j.procs.2019.12.089
   Martínez-Murcia EJ, 2018, 2018 IEEE NUCLEAR SCIENCE SYMPOSIUM AND MEDICAL IMAGING CONFERENCE PROCEEDINGS (NSS/MIC)
   Martínez-Murcia FJ, 2012, EXPERT SYST APPL, V39, P9676, DOI 10.1016/j.eswa.2012.02.153
   Mathew Nimmy Ann, 2018, 2018 International CET Conference on Control, Communication, and Computing (IC4), P161, DOI 10.1109/CETIC4.2018.8530910
   Morabito FC, 2016, 2016 IEEE 2ND INTERNATIONAL FORUM ON RESEARCH AND TECHNOLOGIES FOR SOCIETY AND INDUSTRY LEVERAGING A BETTER TOMORROW (RTSI), P162
   Murphy E, 1999, Lippincotts Prim Care Pract, V3, P578
   Duc NT, 2020, NEUROINFORMATICS, V18, P71, DOI 10.1007/s12021-019-09419-w
   Oh KT, 2020, J DIGIT IMAGING, V33, P816, DOI 10.1007/s10278-020-00321-5
   Pan Y., 2019, DIS IMAGE SPECIFIC G, P137
   Pan YS, 2018, LECT NOTES COMPUT SC, V11072, P455, DOI 10.1007/978-3-030-00931-1_52
   Pathak Ketki C., 2020, Soft Computing: Theories and Applications. Proceedings of SoCTA 2019. Advances in Intelligent Systems and Computing (AISC 1154), P731, DOI 10.1007/978-981-15-4032-5_66
   Piryonesi SM, 2020, J INFRASTRUCT SYST, V26, DOI 10.1061/(ASCE)IS.1943-555X.0000512
   Plant C, 2010, NEUROIMAGE, V50, P162, DOI 10.1016/j.neuroimage.2009.11.046
   Rafieipour H, 2020, Journal of Bioengineering Research, V2, P1
   Rafieipour Hoda., 2020, Journal of Soft Computing and Decision Support Systems, V7, P32
   Ramzan F, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1475-2
   Raut A, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P236, DOI 10.1109/ICCMC.2017.8282683
   Reitz C, 2011, NAT REV NEUROL, V7, P137, DOI [10.1038/nrneurol.2011.2, 10.1101/cshperspect.a006239]
   Ross H, 2017, CT COMPUTED TOMOGRAP
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saha P, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-87523-1
   Sahumbaiev I, 2018, 2018 IEEE 38TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P277, DOI 10.1109/ELNANO.2018.8477516
   Saraswathi S, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN MEDICAL IMAGING (CIMI), P42, DOI 10.1109/CIMI.2013.6583856
   Sarraf S, 2016, PROCEEDINGS OF 2016 FUTURE TECHNOLOGIES CONFERENCE (FTC), P816, DOI 10.1109/FTC.2016.7821697
   Sato R., 2019, Comparison of CNN models with different plane images and their combinations for classification of Alzheimer's disease using PET images, P169
   Segovia F., 2014, PATTERN RECOGN, P1
   Seliya N, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00514-x
   Shakarami A, 2020, OPTIK, V212, DOI 10.1016/j.ijleo.2020.164237
   Shakeri M., 2016, DEEP SPECTRAL BASED, P15
   Shen T, 2018, IEEE ENG MED BIO, P738, DOI 10.1109/EMBC.2018.8512398
   Shi BB, 2017, PATTERN RECOGN, V63, P487, DOI 10.1016/j.patcog.2016.09.032
   Shi J, 2018, IEEE J BIOMED HEALTH, V22, P173, DOI 10.1109/JBHI.2017.2655720
   Simon Blessy C., 2019, 2019 9th International Conference on Advances in Computing and Communication (ICACC). Proceedings, P204, DOI 10.1109/ICACC48162.2019.8986170
   Solano-Rojas Braulio, 2020, Impact of Digital Technologies on Public Health in Developed and Developing Countries. 18th International Conference, ICOST 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12157), P3, DOI 10.1007/978-3-030-51517-1_1
   Song TA, 2019, I S BIOMED IMAGING, P414, DOI 10.1109/ISBI.2019.8759531
   Spasov S, 2019, NEUROIMAGE, V189, P276, DOI 10.1016/j.neuroimage.2019.01.031
   Suk HI, 2015, TR AUGM HUM PERF, V5, P203, DOI 10.1007/978-94-017-7239-6_14
   Suk HI, 2017, MED IMAGE ANAL, V37, P101, DOI 10.1016/j.media.2017.01.008
   Suk HI, 2015, BRAIN STRUCT FUNCT, V220, P841, DOI 10.1007/s00429-013-0687-3
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tabarestani S, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), DOI 10.1109/bhi.2019.8834556
   Vu TD, 2018, SOFT COMPUT, V22, P6825, DOI 10.1007/s00500-018-3421-5
   towardsdatascience, NEAREST NEIGHBOR
   Van DerMalsburg C, 1986, BRAIN THEORY, P245, DOI DOI 10.1007/978-3-642-70911-1_20
   Vandenberghe R, 2013, NEUROIMAGE, V64, P517, DOI 10.1016/j.neuroimage.2012.09.015
   Vinutha N, 2018, 2018 FOURTEENTH INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICINPRO) - 2018, P201, DOI 10.1109/ICINPRO43533.2018.9096819
   Vu TD, 2017, INT CONF BIG DATA, P309, DOI 10.1109/BIGCOMP.2017.7881683
   Wada A, 2019, MAGN RESON MED SCI, V18, P219, DOI 10.2463/mrms.mp.2018-0091
   Wang HF, 2019, NEUROCOMPUTING, V333, P145, DOI 10.1016/j.neucom.2018.12.018
   Wang SH, 2018, J MED SYST, V42, DOI [10.1007/s10916-017-0845-x, 10.1007/s10916-018-0932-7]
   Wang Y, 2018, IEEE ENG MED BIO, P754, DOI 10.1109/EMBC.2018.8512372
   Xia Y., 2012, GA ADABOOST BASED FE, P128
   Xia ZM, 2020, I S BIOMED IMAGING, P416, DOI 10.1109/isbi45749.2020.9098621
   Xu MC, 2019, INT CONF CYBER DIST, P405, DOI 10.1109/CyberC.2019.00076
   Yan Y., 2018, GENERATION AMYLOID P, P26
   Yang BH, 2020, J MED BIOL ENG, V40, P545, DOI 10.1007/s40846-020-00548-1
   Yang Chengliang, 2018, AMIA Annu Symp Proc, V2018, P1571
   Yang ZG, 2020, SAUDI J BIOL SCI, V27, P659, DOI 10.1016/j.sjbs.2019.12.004
   Yoon HJ, 2019, J KOREAN PHYS SOC, V75, P597, DOI 10.3938/jkps.75.597
   Zeiler MD, 2013, HIERARCHICAL CONVOLU
   Zhang F, 2019, NEUROCOMPUTING, V361, P185, DOI 10.1016/j.neucom.2019.04.093
   Zhang J, 2012, BRAIN IMAGING BEHAV, V6, P61, DOI 10.1007/s11682-011-9142-3
   Zhang T, 2020, J NEUROSCI METH, V341, DOI 10.1016/j.jneumeth.2020.108795
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zheng CC, 2018, LECT NOTES COMPUT SC, V11266, P614, DOI 10.1007/978-3-030-02698-1_53
NR 176
TC 15
Z9 15
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37681
EP 37721
DI 10.1007/s11042-022-13506-7
EA AUG 2022
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000841079300002
DA 2024-07-18
ER

PT J
AU Chand, S
   Vishwakarma, VP
AF Chand, Sunita
   Vishwakarma, Virendra P.
TI A novel Deep Learning Framework (DLF) for classification of Acute
   Lymphoblastic Leukemia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Acute lymphoblastic leukemia; Deep learning; Convolutional neural
   network; Training of CNN; Image based classification
ID ILLUMINATION NORMALIZATION; BLOOD-CELLS; MACHINE; SEGMENTATION;
   PREDICTION; DIAGNOSIS; NUCLEI; SYSTEM
AB Cancer of blood, more specifically known as Leukemia, is a deadly disease that is responsible for the abnormal proliferation of immature white blood cells in bone marrow. Due to sudden surge in the speed of disease progression and lack of timely diagnosis, the chance of disease remission also diminish. Leukemia incidence rate has seen a steep rise of 144.7% in past 22 years from 28,700 in 1998 to 60,530 in 2020 (Hao et al. Sci Rep 9(1):1-13, 2019). Deep learning has revolutionised the solution to classification problems, more specifically, image based classification. Thus, in this paper, we propose a novel deep learning framework(DLF) based on convolution neural network for the diagnosis of Acute Lymphoblastic Leukemia (ALL), which is one of the four types of leukemia. The proposed method does not require feature extraction.Also it does not require any pre-training on any other database and thus can be used for real time application for detection of leukemia. The proposed framework is simple compared to existing deep networks. Number of free parameters to be tuned in the proposed framework is 41,626, which is quite less than the learnable parameters in the existing pre-trained complex networks such as, AlexNet (over 60 millions), Visual Geometry Group(VGG-Net)(138 million), Residual Network(ResNet 152)(60.3 millions). As the number of free parameters of the proposed framework is approximately 1400 times less than those of existing deep networks, the simulation of the proposed framework has been possible on simple processor(i5 @2.53GHz processor with 4 GB RAM), it does not require any GPU for processing. Despite of lesser number of free parameters in the proposed model, it is able to diagnose the disease with 100% accuracy in most of the repetitions and an average accuracy of 98.17%. This is the average of two other averages i.e., Experiment-A (98.62%), obtained when the data has been partitioned on (80%-20%) training and testing sets for 20 epochs and Experiment-B(97.73%) when the data has been partitioned as 60-48 training and testing images for 30 epochs.
C1 [Chand, Sunita] Guru Gobind Singh Indraprastha Univ, USIC & T, New Delhi, India.
   [Chand, Sunita] Univ Delhi, Hansraj Coll, Delhi, India.
   [Vishwakarma, Virendra P.] Guru Gobind Singh Indraprastha Univ, USICT, New Delhi, India.
C3 GGS Indraprastha University; University of Delhi; GGS Indraprastha
   University
RP Chand, S (corresponding author), Guru Gobind Singh Indraprastha Univ, USIC & T, New Delhi, India.; Chand, S (corresponding author), Univ Delhi, Hansraj Coll, Delhi, India.
EM sunita.usict.131164@ipu.ac.in
FU Ministry of Electronics and Information Technology, Government of India
FX The authors thank Ministry of Electronics and Information Technology,
   Government of India for supporting our research work under "Visvesvaraya
   PhD Scheme for Electronics and IT".
CR Agaian S, 2014, IEEE SYST J, V8, P995, DOI 10.1109/JSYST.2014.2308452
   Agrahari R, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24758-5
   Agrawal R, 2019, 2019 INT C VIS EM TR, P1, DOI [10.1109/ViTECoN.2019.8899602, DOI 10.1109/VITECON.2019.8899602]
   Ahmed N, 2019, DIAGNOSTICS, V9, DOI 10.3390/diagnostics9030104
   Ahuja B, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115308
   Ahuja B, 2021, MULTIMED TOOLS APPL, V80, P32423, DOI 10.1007/s11042-021-11097-3
   Alsalem MA, 2018, COMPUT METH PROG BIO, V158, P93, DOI 10.1016/j.cmpb.2018.02.005
   [Anonymous], 2011, IEEE INT C IMAGE PRO, P2089
   Chan SL, 2020, LIVER CANCER, V9, P167, DOI 10.1159/000504252
   Chand S, 2021, COMP SEGMENTATION AL, DOI [10.4108/EAI.16-5-2020.2303967, DOI 10.4108/EAI.16-5-2020.2303967]
   Chowdhury AB, 2020, IEEE ROBOT AUTOM LET, V5, P1047, DOI 10.1109/LRA.2020.2967290
   Claro M, 2020, INT CONF SYST SIGNAL, P63, DOI [10.1109/iwssip48289.2020.9145406, 10.1109/IWSSIP48289.2020.9145406]
   Cruz JA, 2006, CANCER INFORM, V2, P59
   Dalal S., 2021, WATER AIR SOIL POLL, V11, P1, DOI DOI 10.1038/S41598-020-79139-8
   Delen D, 2005, ARTIF INTELL MED, V34, P113, DOI 10.1016/j.artmed.2004.07.002
   Hao T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48445-1
   Hegde RB, 2019, MULTIMED TOOLS APPL, V78, P17879, DOI 10.1007/s11042-018-7107-x
   Höfener H, 2018, COMPUT MED IMAG GRAP, V70, P43, DOI 10.1016/j.compmedimag.2018.08.010
   Kant S, LEUKONET DCT BASED C
   Khened M, 2019, MED IMAGE ANAL, V51, P21, DOI 10.1016/j.media.2018.10.004
   Kourou K, 2015, COMPUT STRUCT BIOTEC, V13, P8, DOI 10.1016/j.csbj.2014.11.005
   Labati R. D., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2045, DOI 10.1109/ICIP.2011.6115881
   Laddha S, 2018, HELIX, V8, P4519, DOI 10.29042/2018-4519-4524
   Listgarten J, 2004, CLIN CANCER RES, V10, P2725, DOI 10.1158/1078-0432.CCR-1115-03
   Liu Y, 2019, LECT N BIOENG, P113, DOI 10.1007/978-981-15-0798-4_12
   Mathur P, 2020, JCO GLOB ONCOL, V6, P1063, DOI 10.1200/GO.20.00122
   Mishra Sonali, 2018, 2018 International Conference on Information Technology (ICIT), P61, DOI 10.1109/ICIT.2018.00024
   Mishra S, 2017, BIOMED SIGNAL PROCES, V33, P272, DOI 10.1016/j.bspc.2016.11.021
   Pansombut T, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/7519603
   Qin FW, 2018, COMPUT METH PROG BIO, V162, P243, DOI 10.1016/j.cmpb.2018.05.024
   Rajpurohit S, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2359, DOI 10.1109/ICACCI.2018.8554576
   Rawat J, 2017, BIOCYBERN BIOMED ENG, V37, P637, DOI 10.1016/j.bbe.2017.07.003
   Rawat J, 2015, PROCEDIA COMPUT SCI, V70, P748, DOI 10.1016/j.procs.2015.10.113
   Rehman A, 2018, MICROSC RES TECHNIQ, V81, P1310, DOI 10.1002/jemt.23139
   Safuan SNM, 2020, IEEE ST CONF RES DEV, P411, DOI 10.1109/SCOReD50371.2020.9251000
   Sahlol AT, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-59215-9
   Scotti F, 2005, PROCEEDINGS OF THE 2005 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS, P96
   Shafique S, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/6125289
   Shaheen M, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6658192
   Shahin AI, 2019, COMPUT METH PROG BIO, V168, P69, DOI 10.1016/j.cmpb.2017.11.015
   Shekhar Himanshu, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P667, DOI 10.1007/978-981-13-7403-6_58
   Shirazi SH, 2018, CLUSTER COMPUT, V21, P691, DOI 10.1007/s10586-017-0978-1
   Singh J., 2016, Intech, V11, P13, DOI DOI 10.5772/57353
   Sipes R, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P157, DOI 10.1109/ICCIA.2018.00036
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Tarver T, 2012, J CONS HLTH INTERNET, V16, P366, DOI 10.1080/15398285.2012.701177
   Thanh T. T. P., 2018, International Journal of Computer Theory and Engineering, V10, P54, DOI 10.7763/IJCTE.2018.V10.1198
   Thanh T. T. P., 2017, CS IT C PROC, P49, DOI 10.5121/csit.2017.71305
   Toprak A, 2018, MED SCI MONITOR, V24, P6537, DOI 10.12659/MSM.910520
   van Opbroek A, 2015, IEEE T MED IMAGING, V34, P1018, DOI 10.1109/TMI.2014.2366792
   Vishwakarma VP, 2020, MULTIMED TOOLS APPL, V79, P11503, DOI 10.1007/s11042-019-08537-6
   Vishwakarma VP, 2019, MULTIMED TOOLS APPL, V78, P15213, DOI 10.1007/s11042-018-6837-0
   Vogado LHS, 2017, SIBGRAPI, P367, DOI 10.1109/SIBGRAPI.2017.55
   Waddell Michael., 2005, BIOKDD 05, P21, DOI [DOI 10.1145/1134030.1134035, 10.1145/1134030.1134035]
   Wang LT, 2020, MED IMAGE ANAL, V61, DOI 10.1016/j.media.2020.101665
NR 55
TC 4
Z9 4
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37243
EP 37262
DI 10.1007/s11042-022-13543-2
EA AUG 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000840291300004
DA 2024-07-18
ER

PT J
AU Singh, LK
   Pooja
   Garg, H
   Khanna, M
AF Singh, Law Kumar
   Pooja
   Garg, Hitendra
   Khanna, Munish
TI An IoT based predictive modeling for Glaucoma detection in optical
   coherence tomography images using hybrid genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucomatous; Genetic algorithm; SVM; KNN; Random forest; XGboost;
   Internet of things
ID SPECTRAL-DOMAIN OCT; NERVE HEAD; DIAGNOSIS; SEGMENTATION; FEATURES;
   SYSTEM; CHALLENGES; BURDEN; DISC
AB The primary cause of irreversible blindness due to glaucoma is a silent, progressive disease with no noticeable symptoms. This eye disease gradually and rapidly damages the optic nerve, resulting in visual field defects. Glaucoma can cause substantial vision loss if left untreated. Early detection and proper treatment help limit those severe consequences. The benefits of screening for glaucoma while reducing the workload on eye specialists outweigh the extra effort required for screening. With unmanned aircraft, self-driving cars, facial recognition, and language processing, artificial intelligence (AI) has altered our way of life. AI is capable of outperforming humans in tasks like image recognition. Data analysis and processing are critical, as the volume of image data generated by ophthalmic imaging centers continues to grow at a breakneck pace. Glaucoma has been predicted using OCT and fundus images of prospective patients and for this prediction; AI can be employed to help medical practitioners to come out of these problems. In this paper, a novel AI and Internet of Things (IoT) based predictive modeling is proposed in which a bio-inspired and artificial intelligence based computing approach is employed for classification and prediction of glaucoma disease from Optical coherence tomography (OCT) images through continuous monitoring. That ultimately results in an improvement in healthcare by providing necessary medical instructions. We are the frontrunners to present a unique IoT embedded with artificial intelligence that supports Glaucoma screening, an automated and timely system based on the fusion of machine learning and bio-inspired computing approaches, in the form of this study.150 OCT pictures were utilized in the experiment, which were derived from a mixture of MENDELEY and a private dataset by a renowned eye physicians. This work presents a solution to the question of how to diagnose this condition at an early stage utilizing 45 critical characteristics retrieved using the ORB feature extractor and custom algorithms. Our suggested model has four dimensions; originally, these 45 features were reduced to 20% (i.e., 9) utilizing a statistically based univariate selection procedure. Following that, a Genetic Algorithm (GA) is used to discover an optimum subset of characteristics. These optimized characteristics are routed sequentially to state-of-the-art machine learning models (K-Nearest Neighbor (KNN), XGBoost, Random Forest, and Support Vector Machine (SVM)) for classification. Additionally to the above, the technique is fully integrated into an IoT framework and can be accessed remotely to aid ophthalmologists in diagnosing and treating glaucoma. Additionally, the proposed model facilitates the collection of health data from patients through IoT devices. It is concluded that out of four possible sets of results, GA-KNN based combination input of 9 features, enhanced the computed results with 99% accuracy for glaucoma recognition. The accuracy is obtained through a fivefold cross-validation technique. Because the proposed system has a brilliant ability to differentiate between healthy and glaucomatous eyes, this study will help to achieve high standards of glaucoma identification.
C1 [Singh, Law Kumar; Pooja] Sharda Univ, Dept Comp Sci & Engn, Greater Noida, India.
   [Singh, Law Kumar; Khanna, Munish] Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura, India.
   [Garg, Hitendra] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 Sharda University; GLA University
RP Singh, LK (corresponding author), Sharda Univ, Dept Comp Sci & Engn, Greater Noida, India.; Singh, LK (corresponding author), Hindustan Coll Sci & Technol, Dept Comp Sci & Engn, Mathura, India.
EM lawkumarcs@gmail.com; pooja.1@sharda.ac.in; Hitendra.garg@gmail.com;
   munishkhanna.official@rocketmail.com
RI Garg, Hitendra/AAV-6756-2020; Singh, Law Kumar/AAI-5450-2021
OI Singh, Law Kumar/0000-0002-7073-6852; Garg, Dr.
   Hitendra/0000-0002-4273-2328
CR Ajesh F, 2020, INT J IMAG SYST TECH, V30, P1143, DOI 10.1002/ima.22435
   Ajesh F, 2021, J AMB INTEL HUM COMP, V12, P4027, DOI 10.1007/s12652-020-01771-z
   Almazroa A, 2015, J OPHTHALMOL, V2015, DOI 10.1155/2015/180972
   An GZ, 2019, J HEALTHC ENG, V2019, DOI 10.1155/2019/4061313
   Asaoka R, 2017, AM J OPHTHALMOL, V174, P95, DOI 10.1016/j.ajo.2016.11.001
   Babu TRG, 2015, BIOMED PAP, V159, P607, DOI 10.5507/bp.2015.053
   Bambo MP, 2020, BMC OPHTHALMOL, V20, DOI 10.1186/s12886-020-1322-8
   Boulton M, 2001, EYE, V15, P384, DOI 10.1038/eye.2001.141
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chuanping Geng, 2020, Journal of Physics: Conference Series, V1616, DOI 10.1088/1742-6596/1616/1/012026
   David DS, 2020, MULTIMED TOOLS APPL, V79, P5213, DOI 10.1007/s11042-018-6265-1
   de Sousa JA, 2017, MULTIMED TOOLS APPL, V76, P19173, DOI 10.1007/s11042-017-4608-y
   Dimitrios B, 2019, J HEALTHCARE ENG
   Fan HD, 2017, COMPUT BIOL MED, V85, P75, DOI 10.1016/j.compbiomed.2017.03.025
   Farahani B, 2018, FUTURE GENER COMP SY, V78, P659, DOI 10.1016/j.future.2017.04.036
   Garcia G, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105855
   Gelman R, 2015, J OPHTHALMOL
   George R, 2010, J GLAUCOMA, V19, P391, DOI 10.1097/IJG.0b013e3181c4ac5b
   Gnanaselvi JA, 2020, J AMB INTEL HUM COMP, P1
   Gour N, 2020, PATTERN RECOGN LETT, V137, P3, DOI 10.1016/j.patrec.2019.04.004
   Gour N, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Jerith GG, 2020, MULTIMED TOOLS APPL, V79, P10341, DOI 10.1007/s11042-019-7224-1
   Karaca Y, 2019, INT J INFORM MANAGE, V45, P250, DOI 10.1016/j.ijinfomgt.2018.09.012
   Kausu TR, 2018, BIOCYBERN BIOMED ENG, V38, P329, DOI 10.1016/j.bbe.2018.02.003
   Khalil T, 2018, IEEE ACCESS, V6, P4560, DOI 10.1109/ACCESS.2018.2791427
   Khalil T, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P438, DOI 10.1109/SAI.2014.6918224
   Koh V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199134
   Krishnamoorthi N, 2019, MULTIMED TOOLS APPL, V78, P34247, DOI 10.1007/s11042-019-08249-x
   Lee WJ, 2018, AM J OPHTHALMOL, V196, P65, DOI 10.1016/j.ajo.2018.08.007
   Araujo JDL, 2019, MULTIMED TOOLS APPL, V78, P12987, DOI 10.1007/s11042-018-6429-z
   Maetschke S, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0219126
   Maheshwari S, 2019, COMPUT BIOL MED, V105, P72, DOI 10.1016/j.compbiomed.2018.11.028
   Maheshwari S, 2017, COMPUT BIOL MED, V88, P142, DOI 10.1016/j.compbiomed.2017.06.017
   Maini R., 2009, Int J Image Process, V3, P1
   McCann P, 2019, OPHTHALMOL GLAUCOMA, V2, P336, DOI 10.1016/j.ogla.2019.06.003
   Mingqi Li, 2020, IOP Conference Series: Materials Science and Engineering, V768, DOI 10.1088/1757-899X/768/7/072093
   Morejon A, 2019, CLIN OPHTHALMOL, V13, P33, DOI 10.2147/OPTH.S177581
   Nadernejad E., 2008, Appl. Math. Sci, V2, P1507
   Nayak SP, 2019, INT J SENS NETW, V30, P83, DOI 10.1504/IJSNET.2019.099471
   Nieves-Moreno M, 2018, TRANSL VIS SCI TECHN, V7, DOI 10.1167/tvst.7.1.20
   Pavithra G., 2019, DETECTION PRIMARY GL
   Perumal TSR, 2020, MULTIMED TOOLS APPL, V79, P16915, DOI 10.1007/s11042-019-7428-4
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Raghavendra U, 2018, BIOCYBERN BIOMED ENG, V38, P170, DOI 10.1016/j.bbe.2017.11.002
   Ratanawongphaibul K, 2021, OPHTHALMOL GLAUCOMA, V4, P604, DOI 10.1016/j.ogla.2021.03.010
   Rojo-Alvarez JL, 2018, SUPPORT VECTOR MACHI
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Salazar-Gonzalez A, 2014, IEEE J BIOMED HEALTH, V18, P1874, DOI 10.1109/JBHI.2014.2302749
   Sarmento RM, 2020, FUTURE GENER COMP SY, V105, P135, DOI 10.1016/j.future.2019.11.033
   Shehryar T, 2020, INT J IMAG SYST TECH, V30, P1046, DOI 10.1002/ima.22413
   Silva FR, 2013, ARQ BRAS OFTALMOL, V76, P170, DOI 10.1590/S0004-27492013000300008
   Singh A, 2016, COMPUT METH PROG BIO, V124, P108, DOI 10.1016/j.cmpb.2015.10.010
   Singh LK, 2021, INT J E-HEALTH MED C, V12, P32, DOI 10.4018/IJEHMC.20210701.oa3
   Singh LK, 2021, MED BIOL ENG COMPUT, V59, P333, DOI 10.1007/s11517-020-02307-5
   Smiti A, 2020, COMPUT SCI REV, V37, DOI 10.1016/j.cosrev.2020.100280
   Soumaya Z, 2021, APPL ACOUST, V171, DOI 10.1016/j.apacoust.2020.107528
   Tang C, 2020, ENG APPL ARTIF INTEL, V92, DOI 10.1016/j.engappai.2020.103627
   Tham Yih-Chung, 2014, Ophthalmology, V121, P2081, DOI 10.1016/j.ophtha.2014.05.013
   TUCK MW, 1992, OPHTHAL PHYSL OPT, V12, P400, DOI 10.1111/j.1475-1313.1992.tb00307.x
   Tyagi D, 2019, INTRO ORB ORIENTED F
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Vajaranant TS, 2012, INVEST OPHTH VIS SCI, V53, P2464, DOI 10.1167/iovs.12-9483d
   Viswanathan DG, 2016, FEATURES ACCELERATED
   Woo MW, 2018, FUTURE GENER COMP SY, V78, P626, DOI 10.1016/j.future.2017.04.004
   Xu XY, 2011, PATTERN RECOGN LETT, V32, P956, DOI 10.1016/j.patrec.2011.01.021
   Yang P, 2020, INT J COMPUT SCI ENG, V22, P146, DOI 10.1504/IJCSE.2020.107266
   Zemmal Nawel, 2018, International Journal of Intelligent Systems Technologies and Applications, V17, P310
   Zhang XB, 2017, AM J OPHTHALMOL, V184, P63, DOI 10.1016/j.ajo.2017.09.020
   Zhang Y, 2018, J NETW COMPUT APPL, V117, P10, DOI 10.1016/j.jnca.2018.05.007
   Zhao PY, 2018, JAMA OPHTHALMOL, V136, P1271, DOI 10.1001/jamaophthalmol.2018.3672
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
NR 74
TC 6
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37203
EP 37242
DI 10.1007/s11042-022-13540-5
EA AUG 2022
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000840056800006
DA 2024-07-18
ER

PT J
AU Said, L
   Alanazi, AS
   Khan, M
AF Said, Lal
   Alanazi, Ammar S.
   Khan, Majid
TI A novel dual-layer security scheme based on 3-cell cellular neural
   network encryption and data hiding scheme for color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3-Cell Cellular neural network; Image encryption; Steganography; Secret
   Information
ID CHAOS; MAP
AB The security of digital information is one of the significant problems of the existing world. In this work, we have proposed a dual-layer information hiding mechanism. We have utilized 3-Cell Cellular Neural Network (CNN) system to generate a pseudorandom number generator to fulfill diffusion requirements of a cryptosystem, and then utilizing highly non-linear substitution boxes (S-boxes) to complete the confusion process of cryptosystem design. The encrypted data are the hide in the cover image, the data hiding process comprises three steps, generation of transform matrix from the cover image, embedding matrix from transform matrix and secret encrypted image and the last step is to obtain a stego image. Less computational complexity without affecting the strength of the security scheme is the need of the day. Due to the simplicity and computational efficiency of the diffusion process of a 3-cell cellular neural network, the confusion created by predefined S-boxes, and the data hiding scheme effectively reduces the time for encryption and data hiding. The proposed scheme has been tested using state-of-the-art key performance indicators including information theory-based analysis, Histogram based analysis, analysis based on pixels difference, correlation-based measurements, and distance-based analysis. the results of this analysis show the efficiency and effectiveness of the proposed system.
C1 [Said, Lal] Inst Space Technol, Dept Avion Engn, Islamabad, Pakistan.
   [Said, Lal] Inst Space Technol, Dept Elect Engn, Islamabad, Pakistan.
   [Alanazi, Ammar S.] King Abdulaziz City Sci & Technol, Riyadh, Saudi Arabia.
   [Khan, Majid] Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
C3 King Abdulaziz City for Science & Technology
RP Khan, M (corresponding author), Inst Space Technol, Dept Appl Math & Stat, Islamabad, Pakistan.
EM mk.cfd1@gmail.com
RI Khan, Majid/T-9408-2019
OI Khan, Majid/0000-0001-5454-3770; , LALSAID/0000-0002-5325-6443
CR Alanazi AS, 2021, IEEE ACCESS, V9, P26583, DOI 10.1109/ACCESS.2021.3058112
   Alghafis A, 2020, MATH COMPUT SIMULAT, V177, P441, DOI 10.1016/j.matcom.2020.05.016
   Alghafis A, 2020, WIREL NETW, DOI 10.1007/s11276-020-02363-7
   Ali KM, 2019, MULTIMED TOOLS APPL, V78, P32585, DOI 10.1007/s11042-019-07866-w
   Arena P, 1998, INT J BIFURCAT CHAOS, V8, P1527, DOI 10.1142/S0218127498001170
   Arshad U, 2020, PHYSICA A, V546, DOI 10.1016/j.physa.2019.123458
   Batool S, 2014, NEURAL COMPUT APPL, V25, P2037, DOI 10.1007/s00521-014-1691-0
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   He Y, 2020, NEURAL COMPUT APPL, V32, P247, DOI 10.1007/s00521-018-3577-z
   Jamal SS, 2019, CHINESE J PHYS, V61, P301, DOI 10.1016/j.cjph.2019.09.006
   Jamal SS, 2019, WIREL NETW, V25, P1491, DOI 10.1007/s11276-017-1606-y
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khan LS, 2021, CHINESE J PHYS, V72, P558, DOI 10.1016/j.cjph.2021.03.029
   Khan M, 2022, MULTIMED TOOLS APPL, V81, P16353, DOI 10.1007/s11042-022-12441-x
   Khan M, 2020, MULTIMED TOOLS APPL, V79, P30983, DOI 10.1007/s11042-020-09610-1
   Khan M, 2019, MULTIMED TOOLS APPL, V78, P26203, DOI 10.1007/s11042-019-07818-4
   Khan M, 2014, NONLINEAR DYNAM, V76, P377, DOI 10.1007/s11071-013-1132-0
   Khan S, 2019, IEEE ACCESS, V7, P81333, DOI 10.1109/ACCESS.2019.2920383
   Malik A, 2019, J INF SECUR APPL, V48, DOI 10.1016/j.jisa.2019.102374
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Norouzi B, 2017, MULTIMED TOOLS APPL, V76, P13681, DOI 10.1007/s11042-016-3769-4
   Özkaynak F, 2020, PHYSICA A, V550, DOI 10.1016/j.physa.2019.124072
   Özkaynak F, 2010, PHYS LETT A, V374, P3733, DOI 10.1016/j.physleta.2010.07.019
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Wu HT, 2019, J VIS COMMUN IMAGE R, V62, P87, DOI 10.1016/j.jvcir.2019.04.015
   Younas I, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120913
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang LY, 2014, COMMUN NONLINEAR SCI, V19, P3653, DOI 10.1016/j.cnsns.2014.03.016
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
NR 30
TC 0
Z9 0
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 6127
EP 6145
DI 10.1007/s11042-022-13621-5
EA AUG 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000836084200003
DA 2024-07-18
ER

PT J
AU Sharma, A
   Mishra, PK
AF Sharma, Ajay
   Mishra, Pramod Kumar
TI Image enhancement techniques on deep learning approaches for automated
   diagnosis of COVID-19 features using CXR images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Chest X-ray; COVID-19 analysis; Image enhancement; Image
   denoising; Pneumonia classification
ID NETWORK
AB The outbreak of novel coronavirus (COVID-19) disease has infected more than 135.6 million people globally. For its early diagnosis, researchers consider chest X-ray examinations as a standard screening technique in addition to RT-PCR test. Majority of research work till date focused only on application of deep learning approaches that is relevant but lacking in better pre-processing of CXR images. Towards this direction, this study aims to explore cumulative effects of image denoising and enhancement approaches on the performance of deep learning approaches. Regarding pre-processing, suitable methods for X-ray images, Histogram equalization, CLAHE and gamma correction have been tested individually and along with adaptive median filter, median filter, total variation filter and gaussian denoising filters. Proposed study compared eleven combinations in exploration of most coherent approach in greedy manner. For more robust analysis, we compared ten CNN architectures for performance evaluation with and without enhancement approaches. These models are InceptionV3, InceptionResNetV2, MobileNet, MobileNetV2, Vgg19, NASNetMobile, ResNet101, DenseNet121, DenseNet169, DenseNet201. These models are trained in 4-way (COVID-19 pneumonia vs Viral vs Bacterial pneumonia vs Normal) and 3-way classification scenario (COVID-19 vs Pneumonia vs Normal) on two benchmark datasets. The proposed methodology determines with TVF + Gamma, models achieve higher classification accuracy and sensitivity. In 4-way classification MobileNet with TVF + Gamma achieves top accuracy of 93.25% with 1.91% improvement in accuracy score, COVID-19 sensitivity of 98.72% and F1-score of 92.14%. In 3-way classification our DenseNet201 with TVF + Gamma gains accuracy of 91.10% with improvement of 1.47%, COVID-19 sensitivity of 100% and F1-score of 91.09%. Proposed study concludes that deep learning modes with gamma correction and TVF + Gamma has superior performance compared to state-of-the-art models. This not only minimizes overlapping between COVID-19 and virus pneumonia but advantageous in time required to converge best possible results.
C1 [Sharma, Ajay; Mishra, Pramod Kumar] Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi 221005, Uttar Pradesh, India.
C3 Banaras Hindu University (BHU)
RP Sharma, A (corresponding author), Banaras Hindu Univ, Inst Sci, Dept Comp Sci, Varanasi 221005, Uttar Pradesh, India.
EM ajay.sharma17@bhu.ac.in; mishra@bhu.ac.in
OI Mishra, Prof P K/0000-0003-3957-1161
FU University Grants Commission (UGC), New Delhi, India; IoE grant of the
   Banaras Hindu University
FX The authors are highly thankful to the Editor-in-Chief and anonymous
   reviewers, whose valuable comments helped us greatly to improve this
   article. The first author is grateful to the University Grants
   Commission (UGC), New Delhi, India, for the research fellowship provided
   through UGC-JRF Scheme. The second author greatly acknowledge the IoE
   grant of the Banaras Hindu University.
CR Abbas A, 2021, APPL INTELL, V51, P854, DOI 10.1007/s10489-020-01829-7
   Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Afshar P, 2020, PATTERN RECOGN LETT, V138, P638, DOI 10.1016/j.patrec.2020.09.010
   Anand A, 2010, AMINO ACIDS, V39, P1385, DOI 10.1007/s00726-010-0595-2
   Apostolopoulos ID, 2020, PHYS ENG SCI MED, V43, P635, DOI 10.1007/s13246-020-00865-4
   Arias-Londono JD, 2020, IEEE ACCESS
   Ayaz M, 2021, PHYS ENG SCI MED, V44, P183, DOI 10.1007/s13246-020-00966-0
   Calderon-Ramirez S, 2021, IEEE ACCESS, V9, P85442, DOI 10.1109/ACCESS.2021.3085418
   Chakraborty M, 2021, APPL INTELL, V51, P3026, DOI 10.1007/s10489-020-01978-9
   Chaturvedi SS, 2020, MULTIMED TOOLS APPL, V79, P28477, DOI 10.1007/s11042-020-09388-2
   Chen YH, 2016, ENERGIES, V9, DOI 10.3390/en9020070
   Civit-Masot J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10134640
   Cohen J.P., 2020, arXiv
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Dhiman G, 2022, J BIOMOL STRUCT DYN, V40, P5836, DOI 10.1080/07391102.2021.1875049
   El-Kenawy EM, 2021, IEEE ACCESS, V9, P36019, DOI 10.1109/ACCESS.2021.3061058
   Eslami M, 2020, IEEE T MED IMAGING, V39, P2553, DOI 10.1109/TMI.2020.2974159
   Fan GF, 2013, ENERGIES, V6, P1887, DOI 10.3390/en6041887
   Fang ZY, 2022, IEEE T MOL BIO MULT, V8, P17, DOI 10.1109/TMBMC.2021.3099367
   Gao L, 2020, ARTIF INTELL MED, V108, DOI 10.1016/j.artmed.2020.101935
   Goel T, 2021, APPL INTELL, V51, P1351, DOI 10.1007/s10489-020-01904-z
   Hemdan E. E.- D., 2020, . arXiv preprint arXiv:2003.11055
   Huan EY, 2020, MULTIMED TOOLS APPL, V79, P11905, DOI 10.1007/s11042-019-08376-5
   Ibrahim AU, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09787-5
   Ikhsan IAM, 2014, 2014 IEEE 10TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2014), P208, DOI 10.1109/CSPA.2014.6805749
   Irvin J, 2019, AAAI CONF ARTIF INTE, P590
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Ketu S, 2021, CMC-COMPUT MATER CON, V66, P1897, DOI 10.32604/cmc.2020.012423
   Ketu S, 2022, COGN NEURODYNAMICS, V16, P73, DOI 10.1007/s11571-021-09678-x
   Ketu S, 2021, APPL INTELL, V51, P1492, DOI 10.1007/s10489-020-01889-9
   Khan AI, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105581
   Khan S, 2019, PATTERN RECOGN LETT, V125, P1, DOI 10.1016/j.patrec.2019.03.022
   Khatami F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-80061-2
   Li JX, 2021, IEEE J BIOMED HEALTH, V25, P1336, DOI 10.1109/JBHI.2021.3058293
   Li MW, 2021, NONLINEAR DYNAM, V103, P1167, DOI 10.1007/s11071-020-06111-6
   Loey M, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040651
   Mahmud T, 2020, COMPUT BIOL MED, V122, DOI 10.1016/j.compbiomed.2020.103869
   Mangal A, 2020, ARXIV
   Minaee S, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101794
   Mishra S, 2020, J INNOVATION ENTREPR, V9, P23, DOI DOI 10.1186/S13731-020-00126-4
   Mishra S., 2021, Journal of Innovation and Entrepreneurship, V10, P18, DOI [10.1186/s13731-021-00157-5, DOI 10.1186/S13731-021-00157-5]
   Mishra S, 2020, INT J FINANC ENG, V7, DOI 10.1142/S2424786320500309
   Mishra S, 2019, INT J FINANC ENG, V6, DOI 10.1142/S2424786319500361
   Mishra S, 2018, INT J FINANC ENG, V5, DOI 10.1142/S2424786318500111
   Mooney P, 2020, Chest x-ray images (pneumonia)
   Motwani M. C., 2004, P GSPX, V27, P27
   Mukherjee H, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09775-9
   Oh Y, 2020, IEEE T MED IMAGING, V39, P2688, DOI 10.1109/TMI.2020.2993291
   Ozturk T, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103792
   Perumal V, 2021, APPL INTELL, V51, P341, DOI 10.1007/s10489-020-01831-z
   Punn NS, 2021, APPL INTELL, V51, P2689, DOI 10.1007/s10489-020-01900-3
   Rahman S, 2021, COGN COMPUT, DOI 10.1007/s12559-020-09779-5
   Rajinikanth V, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10103429
   Rajpurkar P, 2018, PLOS MED, V15, DOI 10.1371/journal.pmed.1002686
   Rajpurkar P, 2017, Arxiv, DOI arXiv:1711.05225
   Rehman A, 2014, ARTIF INTELL REV, V42, P253, DOI 10.1007/s10462-012-9337-z
   Sedik A, 2022, NEURAL COMPUT APPL, V34, P11423, DOI 10.1007/s00521-020-05410-8
   Sharma Ajay, 2022, International Journal of Information Technology, V14, P1949, DOI 10.1007/s41870-021-00671-5
   Sharma A., 2020, J SCI RES, V64, P221, DOI DOI 10.37398/JSR.2020.640232
   Sharma A, 2021, I C INF COMM TECH CO, P453, DOI 10.1109/ICTC52510.2021.9620876
   Shiraishi J, 2000, AM J ROENTGENOL, V174, P71, DOI 10.2214/ajr.174.1.1740071
   Srivastava A, 2022, PATTERN RECOGNIT, Patent No. 108826
   Srivastava A, 2021, WIRELESS PERS COMMUN, V121, P745, DOI 10.1007/s11277-021-08659-x
   Stein A., 2020, PNEUMONIA DATASET AN
   Tang SJ, 2021, IEEE T IND INFORM, V17, P6539, DOI 10.1109/TII.2021.3057683
   Toraman S, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110122
   Waheed A, 2020, IEEE ACCESS, V8, P91916, DOI 10.1109/ACCESS.2020.2994762
   Waller JV, 2020, AM J ROENTGENOL, V215, P834, DOI 10.2214/AJR.20.23418
   Wang Linda, 2020, Sci Rep, V10, P19549, DOI 10.1038/s41598-020-76550-z
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   World Health Organization, 2020, 145 WHO
   Zhang J., 2020, ARXIV
   Zhou T, 2021, APPL SOFT COMPUT, V98, DOI 10.1016/j.asoc.2020.106885
   Zreik M, 2019, IEEE T MED IMAGING, V38, P1588, DOI 10.1109/TMI.2018.2883807
NR 75
TC 9
Z9 9
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42649
EP 42690
DI 10.1007/s11042-022-13486-8
EA AUG 2022
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000834017600002
PM 35938148
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Behzadpour, M
   Ghanbari, M
AF Behzadpour, Majid
   Ghanbari, Mohammad
TI Improving precision of objective image/video quality meters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Objective quality meters; Structural
   distortion; Structural similarity index
ID STRUCTURAL SIMILARITY
AB Although subjective test is the most accurate image/video quality assessment tool, it is extremely time demanding. In the past two decades, a variety of objective quality measuring tools, such as SSIM, IW-SSIM, SPSIM, FSIM, etc., have been devised, that well correlate with the subjective tests results. However, the main problem with these methods is that they do not discriminate the measured quality well enough, especially at high quality range. In this article we show how the accuracy/precision of these Image Quality Assessment (IQA) meters can be increased by mapping them into a Logistic Function (LF). The precisions are tested over a variety of image/video databases. Our experimental tests indicate while the used high-quality images can be discriminated by 23% resolution on the MOS subjective scores, discrimination resolution by the widely used IQAs are only 2%, but their mapped IQAs to Logistic Function at this quality range can be improved to 9 - 17%, depending on the characteristics of the LF function. Moreover, their precision at low to mid quality range can also be improved. At this quality range, while the discrimination resolution of MOS of the tested images is 23.2%, those of raw IQAs is nearly 8.9%, but discrimination of their adapted logistic functions can be very close to that of MOS. Moreover, with the used image databases the Pearson Linear Correlation Coefficient (PLCC) of MOS with the logistic function can be improved by 2 - 20% as well.
C1 [Behzadpour, Majid; Ghanbari, Mohammad] Univ Tehran, Coll Engn, Dept Elect & Comp Engn, Tehran, Iran.
   [Ghanbari, Mohammad] Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
C3 University of Tehran; University of Essex
RP Ghanbari, M (corresponding author), Univ Tehran, Coll Engn, Dept Elect & Comp Engn, Tehran, Iran.; Ghanbari, M (corresponding author), Univ Essex, Sch Comp Sci & Elect Engn, Colchester CO4 3SQ, Essex, England.
EM majid.behzadpour@ut.ac.ir; ghan@ut.ac.ir
RI Ghanbari, Mohammad/L-4053-2019
OI Ghanbari, Mohammad/0000-0002-5482-8378
CR [Anonymous], 2003, VQEG FINAL REPORT
   [Anonymous], 2019, CISC VIS NETW IND GL
   Baig MA, 2022, MULTIMED TOOLS APPL, V81, P7895, DOI 10.1007/s11042-022-11992-3
   Brunet D, 2012, IEEE T IMAGE PROCESS, V21, P1488, DOI 10.1109/TIP.2011.2173206
   Ghanbari M, 2011, US Patent, Patent No. [7,869,517, 7869517]
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Kazemi M, 2020, IEEE T IMAGE PROCESS, V29, P5937, DOI 10.1109/TIP.2020.2984356
   Larson E C, 2009, Categorical Image Quality (CSIQ) database [EB/OL]
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Netflix Inc, 2017, PERC VID QUAL ASS BA
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Shi ZF, 2018, SIGNAL PROCESS, V145, P99, DOI 10.1016/j.sigpro.2017.11.015
   Sun W, 2018, IEEE T IMAGE PROCESS, V27, P4232, DOI 10.1109/TIP.2018.2837341
   Tan KT, 2000, IEEE T CIRC SYST VID, V10, P1208, DOI 10.1109/76.875525
   Video Quality Experts Group, 2000, Final report from the video quality experts group on the validation of objective models of video quality assessment march 2000
   Viqar M, 2022, SIGNAL PROCESS-IMAGE, V103, DOI 10.1016/j.image.2022.116651
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang W, 2016, IEEE T NEUR NET LEAR, V27, P1266, DOI 10.1109/TNNLS.2015.2461603
NR 27
TC 3
Z9 3
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4465
EP 4478
DI 10.1007/s11042-022-13416-8
EA JUL 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832565900001
OA Green Accepted, hybrid
DA 2024-07-18
ER

PT J
AU Fan, C
   Lin, H
   Qiu, YY
   Yang, LT
AF Fan, Chao
   Lin, Hao
   Qiu, Yingying
   Yang, Litao
TI Res-attention net: an unsupervised PET - MRI brain image fusion model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Convolutional block attention module; Attention gate;
   Atrous spatial pyramid pooling
AB PET-MRI fusion images are of great significance in improving diagnostic accuracy and nursing quality. However, existing fusion methods usually subjectively define fusion rules to retain specific fusion regions, which will lead to information distortion. Complex processes or network design can also significantly slow down fusion speed. The fusion results of unsupervised models without artificially setting fusion rules are usually poor. To address these limitations, we designed an unsupervised model to accomplish the fusion of MRI-PET brain images. We use the attention modules CBAM (convolutional block attention module) and AG (attention gate) to dynamically highlight the salient features, and the ASPP (arous spatial pyramid pooling) module and residual structure are used to maximize the preservation of source image information. The unique design of each module saves us a lot of computational costs. In addition, we designed a fusion strategy for separating the bone density information and the fusion region, which solves the problem of MRI bone density information retention during image fusion. We have done lots of experiments to verify the superiority of the model. In comparison with the state-of-the-art methods, our model has a higher Q(G) than FusionDN at 68.9% and a Q(s) than U2Fusion at 120.49%, and the fusion efficiency has also reached a high level.
C1 [Fan, Chao] Henan Univ Technol, Sch Artificial Intelligence & Big Data, Zhengzhou, Henan, Peoples R China.
   [Fan, Chao] Minist Educ, Key Lab Grain Informat Proc & Control, Zhengzhou 450001, Henan, Peoples R China.
   [Lin, Hao; Qiu, Yingying; Yang, Litao] Henan Univ Technol, Sch Informat Sci & Engn, Zhengzhou, Henan, Peoples R China.
C3 Henan University of Technology; Henan University of Technology
RP Lin, H (corresponding author), Henan Univ Technol, Sch Informat Sci & Engn, Zhengzhou, Henan, Peoples R China.
EM 1961349448@qq.com
RI QIU, Yingying/HLQ-2160-2023
OI , lin/0000-0003-0290-230X
FU Henan Science and Technology Research Project [222102210309]; National
   Natural Science Foundation of China [62106067, 62106068]; Natural
   Science Project of Henan Education Department, China [21A520010];
   Natural Science Project of Zhengzhou Science and Technology Bureau,
   China [21ZZXTCX21]; Innovative Funds Plan of Henan University of
   Technology [2021ZKCJ14]
FX This work is supported by the Henan Science and Technology Research
   Project (No. 222102210309); the National Natural Science Foundation of
   China (Nos. 62106067 and 62106068); the Natural Science Project of Henan
   Education Department, China (No.21A520010); the Natural Science Project
   of Zhengzhou Science and Technology Bureau, China(No. 21ZZXTCX21); and
   the Innovative Funds Plan of Henan University of Technology
   (2021ZKCJ14).
CR Ahmad P, 2021, MULTIMED TOOLS APPL, V80, P27069, DOI 10.1007/s11042-021-10915-y
   Alseelawi N, 2022, INT J ONLINE BIOMED, V18, P114, DOI 10.3991/ijoe.v18i03.28011
   Ambati L. S., 2021, AMCIS
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Canayaz M, 2021, CHAOS SOLITON FRACT, V151, DOI 10.1016/j.chaos.2021.111310
   Chen K, 2021, ARXIV
   Chen K, 2021, COMPUTER SCI MACHINE
   Deng WJ, 2021, IEEE J-STARS, V14, P2611, DOI 10.1109/JSTARS.2021.3058097
   Dinh PH, 2021, APPL INTELL, V51, P8416, DOI 10.1007/s10489-021-02282-w
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Guo K, 2022, MULTIMED TOOLS APPL, V81, P5889, DOI 10.1007/s11042-021-11822-y
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036
   Huang J, 2020, IEEE ACCESS, V8, P55145, DOI 10.1109/ACCESS.2020.2982016
   Li J, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103171
   Li Y., 2021, Int J Cogn Comput Eng, V2, P21, DOI DOI 10.1016/J.IJCCE.2020.12.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Niu ZY, 2021, NEUROCOMPUTING, V452, P48, DOI 10.1016/j.neucom.2021.03.091
   Preethi S, 2021, MULTIMED TOOLS APPL, V80, P14789, DOI 10.1007/s11042-021-10538-3
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Shi WB, 2022, IEEE J BIOMED HEALTH, V26, P3976, DOI 10.1109/JBHI.2022.3158968
   Song X, 2019, LECT NOTES COMPUT SC, V11902, P278, DOI 10.1007/978-3-030-34110-7_24
   Strecke M, 2019, IEEE I CONF COMP VIS, P5864, DOI 10.1109/ICCV.2019.00596
   Tawfik N, 2021, MULTIMED TOOLS APPL, V80, P6369, DOI 10.1007/s11042-020-08834-5
   Wang ZY, 2021, EXPERT SYST APPL, V171, DOI 10.1016/j.eswa.2021.114574
   Xia KJ, 2019, CLUSTER COMPUT, V22, P1515, DOI 10.1007/s10586-018-2026-1
   Xu H, 2021, INFORM FUSION, V76, P177, DOI 10.1016/j.inffus.2021.06.001
   Xu H, 2020, AAAI CONF ARTIF INTE, V34, P12484
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Yin M, 2019, IEEE T INSTRUM MEAS, V68, P49, DOI 10.1109/TIM.2018.2838778
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhu Q, 1982, J PHYS C SER
   Zhu ZQ, 2018, INFORM SCIENCES, V432, P516, DOI 10.1016/j.ins.2017.09.010
NR 33
TC 0
Z9 0
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 4619
EP 4639
DI 10.1007/s11042-022-13560-1
EA JUL 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000832565900008
DA 2024-07-18
ER

PT J
AU Kumar, M
   Ray, S
   Yadav, DK
AF Kumar, Manoj
   Ray, Susmita
   Yadav, Dileep Kumar
TI Moving human detection and tracking from thermal video through
   intelligent surveillance system for smart applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Background subtraction; Human motion detection; Adaptive threshold;
   Kullback-Leibler divergence; Smart surveillance system; Multimedia
   applications
ID BACKGROUND SUBTRACTION; OBJECT DETECTION
AB In real-time based smart video surveillance system, the moving human detection in thermal video is a critical task that filters out redundant information and extracts exigent information. The thermal imaging-based system is used to extract the motion-based object in an unseen or dark environment because it captures heat generated from the human or manmade objects. It also penetrates challenging problems due to cluttered nature, low light, illumination variation, dust, mist, or haze available in the background. So, there is huge demand for identification and monitoring of unwanted activities, minimization of crime or trespassing, etc for safety and security. The state-of-the-art methods worked for various problems raised due to cluttered or illumination variation type of behavior of the background. This paper provides a performance analysis of state-of-the-art literature and also focus on the challenging issues involved. Here, the proposed work developed an adaptive method for the maintenance of the background model and adaptive threshold generation during testing phase. This threshold is applied to classify the moving and non-moving pixels by avoiding the external involvement for threshold selection at run-time. To evaluate the efficacy, the performance of the proposed work is analyzed through numerous parameters that achieved higher accuracy with minimum false alarm rate and impressive detection results. The qualitative and quantitative experimental results demonstrate better real-time performance and usability against considered peer methods.
C1 [Kumar, Manoj; Ray, Susmita] Manav Rachna Univ, Faridabad, Haryana, India.
   [Yadav, Dileep Kumar] Galgotias Univ, Greater Noida, UP, India.
C3 Galgotias University
RP Kumar, M (corresponding author), Manav Rachna Univ, Faridabad, Haryana, India.
EM manojattri003@gmail.com; susmita@mru.edu.in; dileep252000@gmail.com
RI Yadav, Dr. Dileep Kumar/AAI-6235-2020; Kumar, Manoj/AFS-0700-2022
OI Yadav, Dr. Dileep Kumar/0000-0003-1469-9433; Kumar,
   Manoj/0000-0001-9598-0280
CR Ahmad J, 2019, INFRARED PHYS TECHN, V98, P45, DOI 10.1016/j.infrared.2019.02.006
   Akula A, 2014, INFRARED PHYS TECHN, V63, P103, DOI 10.1016/j.infrared.2013.12.012
   [Anonymous], APPL THERMAL IMAGING
   [Anonymous], SECURITY INFILTRATIO
   [Anonymous], INFRARED DETECTOR TH
   Bandarupalli S, 2009, THESIS U NEW ORLEANS
   Bouwmans T., 2014, Background Modeling and Foreground Detection for Video Surveillance, DOI [10.1201/b17223, DOI 10.1201/B17223]
   Bouwmans T, 2017, COMPUT SCI REV, V23, P1, DOI 10.1016/j.cosrev.2016.11.001
   Chen P, 2018, IEEE T INTELL TRANSP, V19, P131, DOI 10.1109/TITS.2017.2750091
   Demir B, 2020, J REAL-TIME IMAGE PR, V17, P1625, DOI 10.1007/s11554-019-00921-7
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Gupta H, 2022, MULTIMED TOOLS APPL, V81, P19683, DOI 10.1007/s11042-021-11146-x
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Haque Mahfuzul, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P41, DOI 10.1109/AVSS.2008.12
   Hashemi M, 2019, IMAGE VISION COMPUT, V89, P95, DOI 10.1016/j.imavis.2019.06.001
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Jung CR, 2009, IEEE T MULTIMEDIA, V11, P571, DOI 10.1109/TMM.2009.2012924
   Lee S, EURASIP J IMAGE VIDE, V35, P2
   Mandal M, 2021, IEEE T IMAGE PROCESS, V30, P546, DOI 10.1109/TIP.2020.3037472
   Rai M., 2018, ADV INTELLIGENT VIDE, DOI [10.5772/intechopen.76444, DOI 10.5772/INTECHOPEN.76444]
   Reddy V, 2013, IEEE T CIRC SYST VID, V23, P83, DOI 10.1109/TCSVT.2012.2203199
   Saboo S, 2021, MULTIMED TOOLS APPL, V80, P20579, DOI 10.1007/s11042-021-10669-7
   Sanin A, 2012, PATTERN RECOGN, V45, P1684, DOI 10.1016/j.patcog.2011.10.001
   Shahbaz A, 2021, IEEE SENS J, V21, P11435, DOI 10.1109/JSEN.2020.3010563
   Sharma L., 2017, International Journal of Telemedicine and Clinical Practices, V2, P74
   Sharma L, 2016, INFRARED PHYS TECHN, V78, P118, DOI 10.1016/j.infrared.2016.07.012
   Song JR, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2020.103203
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tezcan MO, 2021, IEEE ACCESS, V9, P53849, DOI 10.1109/ACCESS.2021.3071163
   Tokmakov P, 2017, PROC CVPR IEEE, P531, DOI 10.1109/CVPR.2017.64
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Xu XG, 2019, INFRARED PHYS TECHN, V100, P87, DOI 10.1016/j.infrared.2019.02.014
   Yadav D.K., 2019, Intern. J. Spatio-Temp. Data Sci, V1, P4, DOI [10.1504/IJSTDS.2019.097600, DOI 10.1504/IJSTDS.2019.097600]
   Yadav DK, 2016, INFRARED PHYS TECHN, V76, P21, DOI 10.1016/j.infrared.2015.12.027
   Yadav DK, 2019, BOOKVISUAL SURVEIL I, P1
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Zeng Q, 2020, J REAL-TIME IMAGE PR, V17, P1103, DOI 10.1007/s11554-019-00858-x
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 40
TC 5
Z9 5
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39551
EP 39570
DI 10.1007/s11042-022-13515-6
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000830853600001
DA 2024-07-18
ER

PT J
AU Kadyan, V
   Hasija, T
   Singh, A
AF Kadyan, Virender
   Hasija, Taniya
   Singh, Amitoj
TI Prosody features based low resource Punjabi children ASR and T-NT
   classifier using data augmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Children Punjabi ASR; Prosody features; T-NT classifier; Data
   augmentation
ID AUTOMATIC SPEECH RECOGNITION; LIMITED DATA; SYSTEM; VARIABILITY; NOISE;
   EXTRACTION
AB Automatic children speech recognition is always challenging due to limited corpus and varying acoustic features. One among those is zero speech corpus and large acoustic variability which limits the power of learning of training dataset. To overcome this issue, an effort has been made to build two types of systems: ASR and Tonal-Non tonal (T-NT) classifiers. Initially, robust features are added into the front phase using prosody embedded feature vectors. Various prosody features are combined with MFCC feature vectors which outperformed conventional Mel Frequency Cepstral Coefficients (MFCC) features only. A small reduction in Word Error Rate (WER) is obtain on the original train and test dataset. To further enhance the recognition rate, training data scarcity is remove through two-level augmentation approach: external prosody modifications (using pitch and time scaling parameters) and internal augmentation using speed perturbation approaches (using 3, 4, and 5 way methods). For that purpose, an original and augmented dataset is pooled to learn more statistical parameters information. Significant improvement in the performance of both systems are observe due to two-level augmentations and prosody embedded features. Finally it achieve a relative improvement of 13.1% and 18.3% for ASR and T-NT classifier systems over the baseline system which are processed on a modified train and original test set respectively.
C1 [Kadyan, Virender] Univ Petr & Energy Studies UPES, Sch Comp Sci, Speech & Language Res Ctr, Energy Acres, Dehra Dun, Uttarakhand, India.
   [Hasija, Taniya] Chitkara Univ, Inst Engn & Technol, Ctr Excellence Speech & Multimodal Lab, Rajpura, Punjab, India.
   [Singh, Amitoj] Jagat Guru Nanak Dev Punjab State Open Univ, Sch Sci & Emerging Technol, Patiala, Punjab, India.
C3 University of Petroleum & Energy Studies (UPES); Chitkara University,
   Punjab
RP Singh, A (corresponding author), Jagat Guru Nanak Dev Punjab State Open Univ, Sch Sci & Emerging Technol, Patiala, Punjab, India.
EM vkadyan@ddn.upes.ac.in; taniya@chitkara.edu.in; amitojsingh@psou.ac.in
RI Hasija, Taniya/AFP-3082-2022
OI Hasija, Taniya/0000-0002-3891-3732; Singh, amitoj/0000-0002-5884-3145
CR Anusuya MA, 2011, INT J SPEECH TECHNOL, V14, P99, DOI 10.1007/s10772-010-9088-7
   Balam Jagadeesh, 2020, IMPROVING NOISE ROBU
   Bawa P, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107810
   Benzeghiba M, 2007, SPEECH COMMUN, V49, P763, DOI 10.1016/j.specom.2007.02.006
   Billa J, 2018, INTERSPEECH, P3207, DOI 10.21437/Interspeech.2018-2473
   Du CP, 2020, INT CONF ACOUST SPEE, P7719, DOI [10.1109/ICASSP40776.2020.9053139, 10.1109/icassp40776.2020.9053139]
   Dua M., 2012, INT J COMPUT SCI ISS, V9, P359
   Dua M, 2019, NEURAL COMPUT APPL, V31, P6747, DOI 10.1007/s00521-018-3499-9
   Dua M, 2019, J AMB INTEL HUM COMP, V10, P2301, DOI 10.1007/s12652-018-0828-x
   Dua M, 2018, ENG SCI TECHNOL, V21, P389, DOI 10.1016/j.jestch.2018.04.005
   Forsberg Markus., 2003, WHY IS SPEECH RECOGN
   Geng MZ, 2020, INTERSPEECH, P696, DOI 10.21437/Interspeech.2020-1161
   Gerosa M, 2007, SPEECH COMMUN, V49, P847, DOI 10.1016/j.specom.2007.01.002
   Ghahremani Pegah, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2494, DOI 10.1109/ICASSP.2014.6854049
   Goyal K, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03235-4
   Hakak S, 2021, FUTURE GENER COMP SY, V117, P47, DOI 10.1016/j.future.2020.11.022
   Jaitly N., 2013, Proc. ICML Workshop Deep. Learn. Audio Speech Lang, V117
   Kadyan V., 2018, THESIS CHITKARA U
   Kadyan V, 2019, INT J SPEECH TECHNOL, V22, P111, DOI 10.1007/s10772-018-09577-3
   Kadyan V, 2017, INT J SPEECH TECHNOL, V20, P761, DOI 10.1007/s10772-017-9446-9
   Kathania HK, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5519, DOI 10.1109/ICASSP.2018.8461668
   Kathania HK, 2020, INT CONF ACOUST SPEE, P7429, DOI [10.1109/ICASSP40776.2020.9053334, 10.1109/icassp40776.2020.9053334]
   KAUR A, 2016 INT C ADV COMP
   Kaur A, 2016, 2 INT C APPL THEORET
   Kaur H., 2020, FEATURE SPACE DISCRI
   Kaur J, 2021, ARCH COMPUT METHOD E, V28, P1039, DOI 10.1007/s11831-020-09414-4
   Ko T, 2017, INT CONF ACOUST SPEE, P5220, DOI 10.1109/ICASSP.2017.7953152
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kumar Y, 2021, SOFT COMPUT, V25, P1617, DOI 10.1007/s00500-020-05248-1
   Kwon O, 2019, 2019 34TH INTERNATIONAL TECHNICAL CONFERENCE ON CIRCUITS/SYSTEMS, COMPUTERS AND COMMUNICATIONS (ITC-CSCC 2019), P76, DOI 10.1109/itc-cscc.2019.8793393
   LATA S, 2012, WORKSH IND LANG DAT, P76
   Lata S, 2013, 2013 INTERNATIONAL CONFERENCE ON HUMAN COMPUTER INTERACTIONS (ICHCI), DOI 10.1109/ICHCI-IEEE.2013.6887793
   Lee S, 1999, J ACOUST SOC AM, V105, P1455, DOI 10.1121/1.426686
   Lei X, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1237
   Li CD, 2019, INTERSPEECH, P3446, DOI 10.21437/Interspeech.2019-2659
   Li XG, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3219
   Liang Wang, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P2375
   LITMAN DJ, 2000, P 1 N AM CHAPT ASS C, pA218
   Long YH, 2020, APPL ACOUST, V161, DOI 10.1016/j.apacoust.2019.107175
   Mary L, 2008, SPEECH COMMUN, V50, P782, DOI 10.1016/j.specom.2008.04.010
   Milde B., 2018, SPEECH COMMUN, P1
   Nguyen TS, 2020, INT CONF ACOUST SPEE, P7689, DOI [10.1109/ICASSP40776.2020.9054130, 10.1109/icassp40776.2020.9054130]
   Passricha V, 2020, J AMB INTEL HUM COMP, V11, P675, DOI 10.1007/s12652-019-01325-y
   Povey D., 2011, IEEE 2011 WORKSH AUT
   Rafi MS., 2010, LANGUAGE INDIA, V10, P56
   Ravinder K, 2010, LECT NOTES COMPUT SC, V6419, P244
   Rose R, 2011, INT CONF ACOUST SPEE, P4508
   Rostami M, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00398-3
   Rostami M, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00352-3
   Shahnawazuddin S, 2020, INTERSPEECH, P4382, DOI 10.21437/Interspeech.2020-1112
   Shahnawazuddin S, 2020, PATTERN RECOGN LETT, V131, P213, DOI 10.1016/j.patrec.2019.12.019
   Shahnawazuddin S, 2019, DIGIT SIGNAL PROCESS, V93, P34, DOI 10.1016/j.dsp.2019.06.015
   Shahnawazuddin S, 2018, SPEECH COMMUN, V105, P103, DOI 10.1016/j.specom.2018.11.001
   SHAHNAWAZUDDIN S, INT CONF ACOUST SPEE, P7554, DOI DOI 10.1109/ICASSP40776.2020.9053891
   Shahnawazuddin S, 2017, IEEE SIGNAL PROC LET, V24, P1749, DOI 10.1109/LSP.2017.2756347
   Shivakumar PG, 2020, COMPUT SPEECH LANG, V63, DOI 10.1016/j.csl.2020.101077
   Shriberg E, 2005, SPEECH COMMUN, V46, P455, DOI 10.1016/j.specom.2005.02.018
   Singh A, 2022, COMPLEX INTELL SYST, V8, P2623, DOI 10.1007/s40747-022-00665-1
   Singh A, 2020, ARTIF INTELL REV, V53, P3673, DOI 10.1007/s10462-019-09775-8
   Talkin D., 1995, Speech coding and synthesis, V495, P518
   Taniya, 2020, 2020 IEEE 5th International Conference on Computing Communication and Automation (ICCCA), P374, DOI 10.1109/ICCCA49541.2020.9250780
   Teixeira JP., 2013, Procedia Technology, V9, P1112, DOI DOI 10.1016/J.PROTCY.2013.12.124
   ten Bosch L, 2003, SPEECH COMMUN, V40, P213, DOI 10.1016/S0167-6393(02)00083-3
   Wang L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P352
   Wang Liang, 2006, INT S CHIN SPOK LANG, P485
   Yadav IC, 2019, DIGIT SIGNAL PROCESS, V86, P55, DOI 10.1016/j.dsp.2018.12.013
   Yeung G, 2018, INTERSPEECH, P1661, DOI 10.21437/Interspeech.2018-2297
   Zehra W, 2021, COMPLEX INTELL SYST, V7, P1845, DOI 10.1007/s40747-020-00250-4
   Zhang JS, 2000, INT CONF ACOUST SPEE, P1419, DOI 10.1109/ICASSP.2000.861859
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
   Zhu WZ, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P617
NR 71
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3973
EP 3994
DI 10.1007/s11042-022-13435-5
EA JUL 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000827364900001
DA 2024-07-18
ER

PT J
AU Nam, C
   Ryu, S
   Chu, C
   Kim, T
   Choe, S
   Choe, J
AF Nam, Cholman
   Ryu, Sun
   Chu, Changgon
   Kim, Taeguk
   Choe, Sungran
   Choe, Jinhyok
TI A hybrid spatial error concealment using human face and image edge over
   H.264/AVC video sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-direction-based filling interpolation; Horizontal symmetrical
   interpolation; Block division-based interpolation; Adaptive selection
   based hybrid error concealment; Bezier curve-based block division
ID INTERPOLATION
AB This paper proposes a human face and image edge-based hybrid spatial error concealment. Though human faces on video sequences are of most interest, the face error concealment is not yet easy in case of loss of face information. And furthermore, when there are bit errors in regular edge shapes in background, it affects more seriously to visual effect than irregular image characteristics. In order to overcome these challenges, the proposed algorithm, at first, classifies the lost block into foreground, boundary and background by using face detection, and then selects adaptively bilinear interpolation(BI) and horizontal symmetrical interpolation(HSI) for foreground, multi-direction filling interpolation(MDFI) for boundary and block division-based interpolation(BDI) for background. HSI, MDFI, Bezier curve-based block division of foreground and background and BDI of background are novel error concealments which are proposed in this paper. Our test reveals that the proposed error concealment can achieve a better PSNR compared with previous works including separate, adaptive or hybrid concealments, in terms of visual effect, PSNR and runtime, etc. The proposed algorithm may be utilized as an effective error resilient tool for real-time video applications, such as telephone conference, mobile telephone conference and wireless multimedia camera networks in which power consumption should be low.
C1 [Nam, Cholman; Chu, Changgon; Kim, Taeguk] Kim II Sung Univ, Informat & Commun Lab, Sch Informat Sci, Pyongyang, North Korea.
   [Ryu, Sun; Choe, Sungran] Kim II Sung Univ, Informat & Artificial Intelligence Lab, Sch Informat Sci, Pyongyang, North Korea.
   [Choe, Jinhyok] Kim II Sung Univ, Visual Informat Proc Lab, Sch Informat Sci, Pyongyang, North Korea.
RP Nam, C (corresponding author), Kim II Sung Univ, Informat & Commun Lab, Sch Informat Sci, Pyongyang, North Korea.
EM cm.nam@ryongnamsan.edu.kp
CR Agrafiotis D, 2006, SIGNAL PROCESS-IMAGE, V21, P130, DOI 10.1016/j.image.2005.08.002
   [Anonymous], 2009, H 264 SOFTWARE COORD
   Choe G, 2018, MULTIMED TOOLS APPL, V77, P31953, DOI 10.1007/s11042-018-6184-1
   Chung KL, 2007, J VIS COMMUN IMAGE R, V18, P331, DOI 10.1016/j.jvcir.2007.04.007
   El-Khamy Said E., 2007, 24th Radio National Science Conference (NRSC 2007), P1, DOI 10.1109/NRSC.2007.371365
   Hsia SC, 2004, IEEE SIGNAL PROC LET, V11, P577, DOI 10.1109/LSP.2004.827916
   Hsia SC, 2016, IET IMAGE PROCESS, V10, P693, DOI 10.1049/iet-ipr.2016.0043
   Kung WY, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL V, PROCEEDINGS, P700
   Lee YH, 2017, J SIGNAL PROCESS SYS, V88, P13, DOI 10.1007/s11265-016-1112-y
   Li X, 2002, IEEE T CIRC SYST VID, V12, P857, DOI 10.1109/TCSVT.2002.804882
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Nam CM, 2010, INT CONF SIGN PROCES, P1288, DOI 10.1109/ICOSP.2010.5657089
   Nam C, 2020, MULTIMED TOOLS APPL, V79, P1221, DOI 10.1007/s11042-019-08176-x
   Ogbemhe J, 2019, PROCEDIA MANUF, V33, P685, DOI 10.1016/j.promfg.2019.04.086
   Peinado AM, 2017, SIGNAL PROCESS-IMAGE, V55, P41, DOI 10.1016/j.image.2017.03.015
   Rodrigues L, 2002, 15 BRAZILIAN S COMPU, P7
   Suh JW, 1997, IEEE T CONSUM ELECTR, V43, P295, DOI 10.1109/30.628616
   Wang Z, 1998, IEEE T IMAGE PROCESS, V7, P1056, DOI 10.1109/83.701166
   Xu YL, 2004, IEEE T CONSUM ELECTR, V50, P1135, DOI 10.1109/TCE.2004.1362510
   Yufeng Ma, 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P65
   Zhang RF, 2004, IEEE T CONSUM ELECTR, V50, P335, DOI 10.1109/TCE.2004.1277882
NR 21
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3769
EP 3799
DI 10.1007/s11042-022-13408-8
EA JUL 2022
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000825912900007
DA 2024-07-18
ER

PT J
AU Rani, BK
   Rao, MV
   Patra, RK
   Srinivas, K
   Madhukar, G
AF Rani, B. Kavitha
   Rao, M. Varaprasad
   Patra, Raj Kumar
   Srinivas, K.
   Madhukar, G.
TI Vehicle type classification using graph ant colony optimizer based stack
   autoencoder model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ant colony optimizer; Gaussian mixture model; Histogram equalization;
   Histogram of oriented gradients; Local ternary pattern; Stack
   autoencoder; Vehicle type classification
ID GAUSSIAN MIXTURE MODEL; NETWORK
AB In the intelligent transport system, vehicle type classification technology plays a major role. With the growth of video processing and pattern recognition application, a deep learning model is proposed in this research article to improve vehicle type classification under dynamic background. Initially, the original video sequences are collected from MIOvision Traffic Camera Dataset (MIO-TCD), and CDnet2014 dataset. Additionally, the contrast and visible level of the video frames are improved by implementing histogram equalization method. Next, the moving vehicles are detected and tracked using Gaussian Mixture Model (GMM) and Kalman filter. Then, the feature extraction is accomplished using Dual Tree Complex Wavelet Transform (DTCWT), Histogram of Oriented Gradients (HOG), and Local Ternary Pattern (LTP) to extract the texture feature vectors. Further, a new graph clustering-Ant Colony Optimization (ACO) algorithm is proposed to select the active feature vectors for better vehicle type classification. Lastly, the selected active feature vectors are given as the input to stack autoencoder classifier to classify eleven vehicle types in MIO-TCD and four vehicle types in CDnet2014 dataset. In the experimental section, the graph ACO based stack autoencoder model achieved 99.09%, and 89.89% of classification accuracy on both MIO-TCD, and CDnet2014 dataset, which are better related to the existing models like attention based method, improved spatiotemporal sample consistency algorithm, and generative adversarial nets.
C1 [Rani, B. Kavitha; Rao, M. Varaprasad; Patra, Raj Kumar; Srinivas, K.; Madhukar, G.] CMR Tech Campus, Hyderabad, India.
RP Srinivas, K (corresponding author), CMR Tech Campus, Hyderabad, India.
EM phdknr1@gmail.com; varam78@gmail.com; patra.rajkumar@gmail.com;
   phdknr@gmail.com; madhu.mani536@gmail.com
RI Patra, Raj Kumar/ABC-8694-2020
OI Patra, Raj Kumar/0000-0003-4112-2365; M, Varaprasad
   Rao/0000-0003-1766-4826
CR [Anonymous], 2016, International Journal of Education and Management Engineering
   Aqel S, 2017, 2017 INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV)
   Bagade SS., 2011, International Journal of Software Engineering Research & Practices, V1, P6
   Chen ZZ, 2014, IET INTELL TRANSP SY, V8, P135, DOI 10.1049/iet-its.2012.0104
   Dong Z, 2015, IEEE T INTELL TRANSP, V16, P2247, DOI 10.1109/TITS.2015.2402438
   Ghimatgar H, 2018, KNOWL-BASED SYST, V159, P270, DOI 10.1016/j.knosys.2018.06.025
   Gothankar N, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE 2019), P217, DOI [10.1109/ICITE.2019.8880232, 10.1109/icite.2019.8880232]
   Hedeya MA, 2020, IEEE ACCESS, V8, P98266, DOI 10.1109/ACCESS.2020.2997286
   Indrabayu, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS, P115, DOI 10.1109/CyberneticsCom.2016.7892577
   Kwan C, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9061014
   Li FL, 2017, COMPUT NETW, V117, P76, DOI 10.1016/j.comnet.2017.02.013
   Li Suhao, 2018, Procedia Computer Science, V131, P564, DOI 10.1016/j.procs.2018.04.281
   Liu W, 2018, KNOWL-BASED SYST, V160, P167, DOI 10.1016/j.knosys.2018.06.035
   Luo ZM, 2018, IEEE T IMAGE PROCESS, V27, P5129, DOI 10.1109/TIP.2018.2848705
   Moradi P, 2015, KNOWL-BASED SYST, V84, P144, DOI 10.1016/j.knosys.2015.04.007
   Mukherjee D, 2013, IEEE T IMAGE PROCESS, V22, P5022, DOI 10.1109/TIP.2013.2281423
   Nasaruddin N, 2019, IEEE ACCESS, V7, P157564, DOI 10.1109/ACCESS.2019.2950162
   Rachmadi RF, 2018, J VIS COMMUN IMAGE R, V56, P265, DOI 10.1016/j.jvcir.2018.09.021
   Rassem TH, 2014, SCI WORLD J, DOI 10.1155/2014/373254
   Sharma M, 2018, INT J FUZZY SYST, V20, P1297, DOI 10.1007/s40815-018-0455-x
   Shvai N, 2020, IEEE T INTELL TRANSP, V21, P1288, DOI 10.1109/TITS.2019.2906821
   Sun W, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/5019592
   Theagarajan R, 2020, IEEE T INTELL TRANSP, V21, P1096, DOI 10.1109/TITS.2019.2902312
   Wang Q, 2018, J COMPUT SCI TECH-CH, V33, P335, DOI 10.1007/s11390-018-1822-7
   Wang XC, 2019, J REAL-TIME IMAGE PR, V16, P5, DOI 10.1007/s11554-017-0712-5
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wang Y, 2019, IEEE ACCESS, V7, P80287, DOI 10.1109/ACCESS.2019.2923199
   Yan G, 2016, OPTIK, V127, P7941, DOI 10.1016/j.ijleo.2016.05.092
   Zakaria A., 2018, INT J COMPUT APPL, V182, P9, DOI DOI 10.5120/IJCA2018917880
   Zhang BL, 2014, MACH VISION APPL, V25, P437, DOI 10.1007/s00138-013-0588-8
   Zhang FK, 2019, IEEE ACCESS, V7, P72660, DOI 10.1109/ACCESS.2019.2919103
   Zhang LK, 2022, J AM STAT ASSOC, V117, P1357, DOI 10.1080/01621459.2020.1858838
   Zhou PC, 2019, IEEE T GEOSCI REMOTE, V57, P4823, DOI 10.1109/TGRS.2019.2893180
   Zhu EX, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6061939
NR 34
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42163
EP 42182
DI 10.1007/s11042-021-11508-5
EA JUL 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000825246000001
DA 2024-07-18
ER

PT J
AU Qi, YH
   Zhang, HR
   Jin, Z
   Liu, WQ
AF Qi, Yinhe
   Zhang, Huanrong
   Jin, Zhi
   Liu, Wanquan
TI Depth-guided asymmetric CycleGAN for rain synthesis and image deraining
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rain synthesis; Deraining; Asymmetric CycleGAN; Depth information
ID MODEL
AB Based on supervised learning, most of the existing single image deraining networks are trained on paired images including one clean image and one rain image. Since it is difficult to obtain a sufficient number of paired images, most of the rain images are manually synthesized from the clean ones. However, it costs huge time and effort, and requires professional experience to mimic the real rain images well. Moreover, the superior performance of these deraining networks trained on manually synthetic rain images is hard to be maintained when tested on real rain images. In this work, to obtain more realistic rain images for training supervised deraining networks, the depth-guided asymmetric CycleGAN (DA-CycleGAN) is proposed to translate clean images to their rainy counterparts automatically. Due to the cycle consistency strategy, DA-CycleGAN can also implement the single image deraining task unsupervised while synthesizing rain on clean images. Since rain streaks and rain mist vary with depth from the camera, DA-CycleGAN adopts depth information as an aid for rain synthesis and deraining. Furthermore, we design generators with different architectures for these two processes due to the information asymmetry in rain synthesis and deraining. Extensive experiments indicate that the DA-CycleGAN can synthesize more lifelike rain images and provide commensurate deraining performance compared with the state-of-the-art deraining methods.
C1 [Qi, Yinhe; Zhang, Huanrong; Jin, Zhi; Liu, Wanquan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen Campus, Shenzhen 518107, Guangdong, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Robot & Digital Intelligen, Guangzhou 510535, Peoples R China.
C3 Sun Yat Sen University
RP Jin, Z (corresponding author), Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen Campus, Shenzhen 518107, Guangdong, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Robot & Digital Intelligen, Guangzhou 510535, Peoples R China.
EM qiyh6@mail2.sysu.edu.cn; zhanghr37@mail2.sysu.edu.cn;
   jinzh26@mail.sysu.edu.cn; liuwq63@mail.sysu.edu.cn
RI Zhao, YuHan/KIE-0813-2024; Huang, Liping/KIB-4430-2024; Jin,
   Zhi/AAB-2440-2022
OI Jin, Zhi/0000-0001-9670-7366; Zhang, Huanrong/0000-0003-3830-3480
FU National Natural Science Foundation of China [62071500]; Shenzhen
   Science and Technology Program [GXWD20201231165807008, 2021A26]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62071500), Shenzhen Science and Technology Program (Grant No.
   GXWD20201231165807008, 2021A26).
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Eigen D, 2014, ADV NEUR IN, V27
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Garg K, 2006, ACM T GRAPHIC, V25, P996, DOI 10.1145/1141911.1141985
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hensel M, 2017, ADV NEUR IN, V30
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu XW, 2019, PROC CVPR IEEE, P8014, DOI 10.1109/CVPR.2019.00821
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Junbo JZ, 2016, CORR
   Kingma D. P., 2014, arXiv
   Li RT, 2019, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2019.00173
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Liu MY, 2017, ADV NEUR IN, V30
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Paszke A, 2019, ADV NEUR IN, V32
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saxena A., 2006, NIPS, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tero K, 2017, CORR
   Wang TY, 2019, PROC CVPR IEEE, P12262, DOI 10.1109/CVPR.2019.01255
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Y, 2019, DERAINCYCLEGAN SIMPL
   Wei YY, 2019, IEEE DATA MINING, P628, DOI 10.1109/ICDM.2019.00073
   Wolk D, 2019, IEEE INT CONF ROBOT, P6101, DOI [10.1109/icra.2019.8794182, 10.1109/ICRA.2019.8794182]
   Yang W., 2017, PROC CVPR IEEE, P1685, DOI DOI 10.1109/CVPR.2017.183
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 46
TC 3
Z9 3
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35935
EP 35952
DI 10.1007/s11042-022-13342-9
EA JUL 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000823376700022
DA 2024-07-18
ER

PT J
AU Ceccarini, C
   Nisi, V
   Prandi, C
AF Ceccarini, Chiara
   Nisi, Valentina
   Prandi, Catia
TI Exploring <i>proximity</i>-based recommendation criteria as a tool for
   information exchange and interactions between locals and tourists
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sharing economy; People-to-people recommendation; Proximity; Authentic
   tourism
ID PEOPLE RECOMMENDATION; GAMIFICATION; FUTURE; POWER
AB Sharing economy and contemporary tourism are two emerging concepts that urge to be investigated together with new ubiquitous and immersive technologies, in the tourism and hospitality sector. In this rich scenario, we designed and implemented ShareCities, a platform to foster remote direct information exchange and meaningful interactions among tourists and locals. Exploiting ShareCities we here present an extended analysis on the opportunity to use people-to-people recommendation criteria based on proximity. We hence defined three criteria which drove our analysis: i) profile similarity, ii) geographical proximity, and iii) random exploration. Through an online questionnaire, we collect answers from 126 young-adult students, obtaining a general positive interest in the three criteria but also concerns in terms of privacy, trust, and feeling of disorientation.
C1 [Ceccarini, Chiara; Prandi, Catia] Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.
   [Nisi, Valentina] Univ Lisbon, Tecn, Lisbon, Portugal.
   [Nisi, Valentina; Prandi, Catia] ITI LARSyS, Funchal, Portugal.
C3 University of Bologna; Universidade de Lisboa
RP Prandi, C (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.; Prandi, C (corresponding author), ITI LARSyS, Funchal, Portugal.
EM chiara.ceccarini6@unibo.it; valentina.nisi@gmail.com;
   catia.prandi2@unibo.it
RI Nunes, Nuno Jardim/M-4006-2013; Ceccarini, Chiara/ADI-6093-2022; Prandi,
   Catia/KIB-1268-2024; Nisi, Valentina/G-8658-2018
OI Nunes, Nuno Jardim/0000-0002-2498-0643; Ceccarini,
   Chiara/0000-0001-9743-5833; Prandi, Catia/0000-0002-5566-2269; Nisi,
   Valentina/0000-0002-8051-3230
FU Alma Mater Studiorum - Universita di Bologna within the CRUICARE
   Agreement; LARSyS [UIDB/50009/2020]
FX Open access funding provided by Alma Mater Studiorum -Universit`a di
   Bologna within the CRUICARE Agreement. Moreover, this research was
   partially funded by LARSyS (Projeto -UIDB/50009/2020).
CR Abir T, 2022, ICT INNOVATOR TOURIS, P30
   Acquier A, 2017, TECHNOL FORECAST SOC, V125, P1, DOI 10.1016/j.techfore.2017.07.006
   Bartoli E., 2018, PSYCHOL BEHAV SCI, V8, P93
   Batle J, 2020, CURR ISSUES TOUR, V23, P1277, DOI 10.1080/13683500.2019.1604639
   Beierle F, 2020, J AMB INTEL HUM COMP, V11, P2277, DOI 10.1007/s12652-019-01355-6
   Belias D., 2021, ACAD J INTERDISCIP S, V10, P357, DOI [10.36941/ajis-2021-0144, DOI 10.36941/AJIS-2021-0144]
   Borrelli N, 2019, SHARING EC SUSTAINAB
   Bujari A, 2017, PERS UBIQUIT COMPUT, V21, P235, DOI 10.1007/s00779-016-0989-6
   CANDIDO J, 2020, CONSUM COMM NETWORK, pNIL85, DOI DOI 10.1109/ccnc46108.2020.9045124
   Casado-Diaz MA, 2020, SCAND J HOSP TOUR, V20, P268, DOI 10.1080/15022250.2019.1708455
   Chen L, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P240, DOI 10.1145/3308558.3313469
   Cheng MM, 2016, INT J HOSP MANAG, V57, P60, DOI 10.1016/j.ijhm.2016.06.003
   Chirico A, 2020, FRONT PSYCHOL, V11, DOI 10.3389/fpsyg.2020.01396
   Chirisa I., 2020, Journal of Social Sciences, V64, P1, DOI [DOI 10.31901/24566756.2020/64.1-3.2266, 10.31901/24566756.2020/64.1-3.2266]
   Chung J. Y., 2016, The use of social network analysis to examine the interactions between locals and tourists in an online community
   Cuomo MT, 2021, TECHNOL FORECAST SOC, V162, DOI 10.1016/j.techfore.2020.120345
   Dauni P, 2019, J PHYS CONF SER, V1402, DOI 10.1088/1742-6596/1402/7/077028
   Decrop A, 2018, J TRAVEL TOUR MARK, V35, P57, DOI 10.1080/10548408.2017.1307159
   Figueredo M, 2018, 2018 IEEE FOURTH INTERNATIONAL CONFERENCE ON BIG DATA COMPUTING SERVICE AND APPLICATIONS (IEEE BIGDATASERVICE 2018), P85, DOI 10.1109/BigDataService.2018.00021
   Furini M, 2020, MOBILE NETW APPL, V25, P1055, DOI 10.1007/s11036-020-01529-z
   Gosling SD, 2003, J RES PERS, V37, P504, DOI 10.1016/S0092-6566(03)00046-1
   Gretzel U, 2020, INF TECHNOL TOUR, V22, P187, DOI 10.1007/s40558-020-00181-3
   Gurini DF, 2018, FUTURE GENER COMP SY, V78, P430, DOI 10.1016/j.future.2017.03.020
   Hughes K, 2019, J TOUR FUTURES, V5, P228, DOI 10.1108/JTF-12-2018-0072
   Jeong M, 2020, J TRAVEL RES, V59, P1464, DOI 10.1177/0047287519883034
   Kim D, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9112082
   Krzywicki A, 2015, INT J HUM-COMPUT ST, V76, P50, DOI 10.1016/j.ijhcs.2014.12.003
   Kuhzady S, 2022, CURR ISSUES TOUR, V25, P3115, DOI 10.1080/13683500.2020.1786505
   Maxwell SE, 2008, ANNU REV PSYCHOL, V59, P537, DOI 10.1146/annurev.psych.59.103006.093735
   Menk A, 2017, PROC INT C TOOLS ART, P788, DOI 10.1109/ICTAI.2017.00124
   Mondal S, 2021, MANAG ENVIRON QUAL, V32, P64, DOI 10.1108/MEQ-03-2020-0054
   Moyle B, 2010, INT J CULT TOUR HOSP, V4, P96, DOI 10.1108/17506181011045172
   Negrusa AL, 2015, SUSTAINABILITY-BASEL, V7, P11160, DOI 10.3390/su70811160
   Niwattanakul Suphakit, 2013, IMECS 2013 Proceedings of International Multiconference of Engineers and Computer Scientists, P380
   Paulauskaite D, 2017, INT J TOUR RES, V19, P619, DOI 10.1002/jtr.2134
   Pimenidis E, 2019, J INF SCI, V45, P387, DOI 10.1177/0165551518792213
   Pizzato L, 2013, USER MODEL USER-ADAP, V23, P447, DOI 10.1007/s11257-012-9125-0
   Prandi Catia, 2021, GoodIT '21: Proceedings of the Conference on Information Technology for Social Good, P67, DOI 10.1145/3462203.3475930
   Radojevic B, 2020, GEOGR PANNONICA, V24, P221, DOI 10.5937/gp24-28009
   Ribeiro MA, 2018, J TRAVEL RES, V57, P279, DOI 10.1177/0047287517699089
   Saputra Kurnia, 2019, 2019 IEEE International Conference on Cybernetics and Computational Intelligence (CyberneticsCom). Proceedings, P40, DOI 10.1109/CYBERNETICSCOM.2019.8875686
   Sharma GD, 2021, TOUR MANAG PERSPECT, V37, DOI 10.1016/j.tmp.2020.100786
   Shi S, 2021, J TRAVEL RES, V60, P1714, DOI 10.1177/0047287520966395
   Soto CJ, 2011, J PERS SOC PSYCHOL, V100, P330, DOI 10.1037/a0021717
   Spreng RN, 2009, J PERS ASSESS, V91, P62, DOI 10.1080/00223890802484381
   Stylidis D, 2022, J TRAVEL RES, V61, P186, DOI 10.1177/0047287520969861
   Sun Y, 2016, T ENG TECHNOLOGIES, P45
   Xin MJ, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2019.102125
   Yochum P, 2020, IEEE ACCESS, V8, P16409, DOI 10.1109/ACCESS.2020.2967120
NR 49
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5229
EP 5252
DI 10.1007/s11042-022-13369-y
EA JUL 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000824937400001
PM 35821865
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Feng, F
   Li, KC
   Yang, EF
   Zhou, QG
   Han, LH
   Hussain, A
   Cai, MJ
AF Feng, Fang
   Li, Kuan-Ching
   Yang, Erfu
   Zhou, Qingguo
   Han, Lihong
   Hussain, Amir
   Cai, Mingjiang
TI A novel oversampling and feature selection hybrid algorithm for
   imbalanced data classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Imbalanced data; Oversampling; Feature selection; General vector machine
ID SAMPLING METHOD; BOOSTED SVM; SMOTE; PREDICTION; ENSEMBLE; CLASSIFIERS;
   STRATEGY; MACHINE; QUALITY; VERSION
AB Traditional approaches tend to cause classier bias in the imbalanced data set, resulting in poor classification performance for minority classes. In particular, there are many imbalanced data in financial fraud, network intrusion, and fault detection, where recognition rate of minority classes is pertinent than the classification performance of majority classes. Therefore, there is pressure on developing efficient algorithms to solve the class imbalance problem. To this end, this article presents a novel hybrid algorithm Negative Binary General (NBG), to improve the performance of imbalanced classifications by combining oversampling and a feature selection algorithm. A novel oversampling algorithm, Negative-positive Synthetic Minority Oversampling Technique (NPSMOTE), improves sample generation's practicability while the Binary Ant Lion Optimizer (BALO) algorithm extracts the most significant features to improve the classification performance. Simulation experiments carried out using seven benchmark imbalanced data sets demonstrate that, the proposed NBG algorithm significantly outperforms the classification of imbalanced small-sample data sets compared to nine other existing and six recently published algorithms.
C1 [Feng, Fang] Guizhou Univ Finance & Econ, Sch Informat, Guiyang, Guizhou, Peoples R China.
   [Feng, Fang; Zhou, Qingguo; Han, Lihong] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
   [Li, Kuan-Ching] Providence Univ, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
   [Yang, Erfu] Univ Strathclyde, Dept Design Manufacture & Engn Management, Glasgow G1 1XJ, Lanark, Scotland.
   [Hussain, Amir] Edinburgh Napier Univ, Sch Comp, Merchiston Campus, Edinburgh EH10 5DT, Midlothian, Scotland.
   [Cai, Mingjiang] Guizhou Univ Finance & Econ, Guiyang, Guizhou, Peoples R China.
C3 Guizhou University of Finance & Economics; Lanzhou University;
   Providence University - Taiwan; University of Strathclyde; Edinburgh
   Napier University; Guizhou University of Finance & Economics
RP Feng, F (corresponding author), Guizhou Univ Finance & Econ, Sch Informat, Guiyang, Guizhou, Peoples R China.; Feng, F (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou, Gansu, Peoples R China.
EM fengf15@lzu.edu.cn
RI Li, K/S-4073-2019; Zhou, Qingguo/JZT-9724-2024; Yang, Erfu/N-2673-2016
OI Li, K/0000-0003-1381-4364; Zhou, Qingguo/0000-0001-8054-5446; Yang,
   Erfu/0000-0003-1813-5950
FU Plan Project for Guizhou Provincial Basic Research [QKH-Basic-ZK[2022]
   General 018]; school level project of Guizhou University of Finance and
   economics [2021KYYB13]
FX This work was supported by Plan Project for Guizhou Provincial Basic
   Research (NO. QKH-Basic-ZK[2022] General 018) and the school level
   project of Guizhou University of Finance and economics in 2021 (NO.
   2021KYYB13).
CR Abdi L, 2016, IEEE T KNOWL DATA EN, V28, P238, DOI 10.1109/TKDE.2015.2458858
   Al-Ghraibah A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P557, DOI 10.1109/ICDMW.2015.188
   Alcalá-Fdez J, 2011, J MULT-VALUED LOG S, V17, P255
   Ali S, 2016, COMPUT BIOL MED, V73, P38, DOI 10.1016/j.compbiomed.2016.04.002
   Alibeigi M, 2012, DATA KNOWL ENG, V81-82, P67, DOI 10.1016/j.datak.2012.08.001
   Amin A, 2016, IEEE ACCESS, V4, P7940, DOI 10.1109/ACCESS.2016.2619719
   [Anonymous], IMBALANCED LEARNING
   [Anonymous], 2016, GEN VECTOR MACHINE
   Bae SH, 2015, IEEE T MED IMAGING, V34, P2379, DOI 10.1109/TMI.2015.2434398
   Bao L, 2016, NEUROCOMPUTING, V172, P198, DOI 10.1016/j.neucom.2014.05.096
   Barua S, 2014, IEEE T KNOWL DATA EN, V26, P405, DOI 10.1109/TKDE.2012.232
   Batista G. E., 2004, ACM SIGKDD EXPL NEWS, V6, P20, DOI DOI 10.1145/1007730.1007735
   Beyan C, 2015, PATTERN RECOGN, V48, P1653, DOI 10.1016/j.patcog.2014.10.032
   Bin Zikria Y, 2020, COMPUT COMMUN, V164, P50, DOI 10.1016/j.comcom.2020.08.017
   Blagus R, 2017, COMPUT STAT DATA AN, V113, P19, DOI 10.1016/j.csda.2016.07.016
   Bunkhumpornpat C, 2012, APPL INTELL, V36, P664, DOI 10.1007/s10489-011-0287-y
   Bunkhumpornpat C, 2009, LECT NOTES ARTIF INT, V5476, P475, DOI 10.1007/978-3-642-01307-2_43
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chawla NV, 2003, LECT NOTES ARTIF INT, V2838, P107, DOI 10.1007/978-3-540-39804-2_12
   Chen S, 2010, IEEE T NEURAL NETWOR, V21, P1624, DOI 10.1109/TNN.2010.2066988
   Cheng FY, 2016, PATTERN RECOGN LETT, V80, P107, DOI 10.1016/j.patrec.2016.06.009
   Cohen G, 2006, ARTIF INTELL MED, V37, P7, DOI 10.1016/j.artmed.2005.03.002
   Dubey R, 2014, NEUROIMAGE, V87, P220, DOI 10.1016/j.neuroimage.2013.10.005
   Elkan C., 2001, P 17 INT JOINT C ART, V17, P973
   Emary E, 2016, NEUROCOMPUTING, V213, P54, DOI 10.1016/j.neucom.2016.03.101
   Feng Fang, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1865, DOI 10.1007/s12652-018-0786-3
   Fernandez A., 2018, LEARNING IMBALANCED
   Fernández A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   García V, 2012, KNOWL-BASED SYST, V25, P13, DOI 10.1016/j.knosys.2011.06.013
   García-Pedrajas N, 2013, PROG ARTIF INTELL, V2, P29, DOI 10.1007/s13748-012-0028-4
   Ghazikhani A., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P611, DOI 10.1109/IranianCEE.2012.6292428
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   Han H, 2005, LECT NOTES COMPUT SC, V3644, P878, DOI 10.1007/11538059_91
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   He HB, 2008, IEEE IJCNN, P1322, DOI 10.1109/IJCNN.2008.4633969
   Ieracitano C, 2018, LECT NOTES ARTIF INT, V10989, P759, DOI 10.1007/978-3-030-00563-4_74
   Jin XB, 2018, COGN COMPUT, V10, P1042, DOI 10.1007/s12559-018-9583-8
   Kennedy J, 1997, IEEE SYS MAN CYBERN, P4104, DOI 10.1109/ICSMC.1997.637339
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan FA, 2019, IEEE ACCESS, V7, P30373, DOI 10.1109/ACCESS.2019.2899721
   Khoshgoftaar TM, 2011, INT J RELIAB QUAL SA, V18, P341, DOI 10.1142/S0218539311004287
   Krawczyk B, 2014, APPL SOFT COMPUT, V14, P554, DOI 10.1016/j.asoc.2013.08.014
   Kubat M., 1997, ICML, P179
   Laurikkala J, 2001, LECT NOTES ARTIF INT, V2101, P63, DOI 10.1007/3-540-48229-6_9
   Li YJ, 2016, KNOWL-BASED SYST, V94, P88, DOI 10.1016/j.knosys.2015.11.013
   Lim P, 2017, IEEE T CYBERNETICS, V47, P2850, DOI 10.1109/TCYB.2016.2579658
   Lima RF, 2015, 2015 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT), VOL 3, P219, DOI 10.1109/WI-IAT.2015.13
   Lin ZY, 2009, LECT NOTES COMPUT SC, V5678, P536
   López V, 2013, INFORM SCIENCES, V250, P113, DOI 10.1016/j.ins.2013.07.007
   Loyola-González O, 2016, NEUROCOMPUTING, V175, P935, DOI 10.1016/j.neucom.2015.04.120
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Malik ZK, 2016, NEUROCOMPUTING, V173, P127, DOI 10.1016/j.neucom.2014.12.119
   Mao WT, 2017, COGN COMPUT, V9, P780, DOI 10.1007/s12559-017-9504-2
   Menardi G, 2014, DATA MIN KNOWL DISC, V28, P92, DOI 10.1007/s10618-012-0295-5
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Moepya SO, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P183, DOI 10.1109/ICDMW.2014.141
   Mohammad RFA, 2017, UCI MACHINE LEARNING
   Nekooeimehr I, 2016, EXPERT SYST APPL, V46, P405, DOI 10.1016/j.eswa.2015.10.031
   Nguyen Hien M., 2011, International Journal of Knowledge Engineering and Soft Data Paradigms, V3, P4, DOI 10.1504/IJKESDP.2011.039875
   Oh SH, 2011, NEUROCOMPUTING, V74, P1058, DOI 10.1016/j.neucom.2010.11.024
   Pérez-Godoy MD, 2014, APPL SOFT COMPUT, V25, P26, DOI 10.1016/j.asoc.2014.09.011
   Poria S, 2017, Neurocomputing, Patent No. [S0925231217302023, 0925231217302023]
   Poria S, 2016, NEUROCOMPUTING, V174, P50, DOI 10.1016/j.neucom.2015.01.095
   Precision, 2015, DATA MINING IMBALANC
   Ramentol E, 2012, KNOWL INF SYST, V33, P245, DOI 10.1007/s10115-011-0465-6
   Rayhan F, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMPUTATIONAL SYSTEMS AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTION (CSITSS-2017), P70, DOI 10.1109/CSITSS.2017.8447534
   Ren FL, 2017, COMPUT MED IMAG GRAP, V55, P54, DOI 10.1016/j.compmedimag.2016.07.011
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Sáez JA, 2015, INFORM SCIENCES, V291, P184, DOI 10.1016/j.ins.2014.08.051
   Satapathy R, 2018, SENTIMENT ANAL BIOME, V7
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Shengguo Hu, 2009, Proceedings of the 2009 Second International Workshop on Computer Science and Engineering (WCSE 2009), P13, DOI 10.1109/WCSE.2009.756
   Song L, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-298
   Tian QT, 2020, APPL INTELL, V50, P3162, DOI 10.1007/s10489-020-01694-4
   TOMEK I, 1976, IEEE T SYST MAN CYB, V6, P769, DOI 10.1109/tsmc.1976.4309452
   Vluymans S, 2016, PATTERN RECOGN, V53, P36, DOI 10.1016/j.patcog.2015.12.002
   Wajid SK, 2018, EXPERT SYST APPL, V112, P388, DOI 10.1016/j.eswa.2017.11.057
   Wajid SK, 2015, EXPERT SYST APPL, V42, P6990, DOI 10.1016/j.eswa.2015.04.057
   Wei MH, 2013, QUAL QUANT, V47, P1761, DOI 10.1007/s11135-011-9624-9
   WILSON DL, 1972, IEEE T SYST MAN CYB, VSMC2, P408, DOI 10.1109/TSMC.1972.4309137
   Wong GY, 2018, INFORM SCIENCES, V454, P161, DOI 10.1016/j.ins.2018.04.068
   Xu J, 2020, COMPUT SCI INF SYST, V17, P665, DOI 10.2298/CSIS200406014X
   Yang P, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3339474
   Yu HL, 2016, KNOWL-BASED SYST, V92, P55, DOI 10.1016/j.knosys.2015.10.012
   Zayed AS, 2006, NEUROCOMPUTING, V69, P1868, DOI 10.1016/j.neucom.2006.02.017
   Zhao JK, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.106087
   Zhou QG, 2019, MULTIMED TOOLS APPL, V78, P3529, DOI 10.1007/s11042-018-6498-z
   Zhou QG, 2016, EAI ENDORSED TRANS S, V3, DOI 10.4108/eai.9-8-2016.151634
   Zieba M, 2015, SOFT COMPUT, V19, P3357, DOI 10.1007/s00500-014-1407-5
   Zieba M, 2014, APPL SOFT COMPUT, V14, P99, DOI [10.1016/j.asor.2013.07.016, 10.1016/j.asoc.2013.07.016]
   Zou Q, 2016, BIG DATA RES, V5, P2, DOI 10.1016/j.bdr.2015.12.001
NR 92
TC 12
Z9 12
U1 9
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 3
BP 3231
EP 3267
DI 10.1007/s11042-022-13240-0
EA JUN 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7Q1QA
UT WOS:000814956000001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Horst, R
   Gerstmeier, S
   Naraghi-Taghi-Off, R
   Wagner, J
   Rau, L
   Dörner, R
AF Horst, Robin
   Gerstmeier, Simon
   Naraghi-Taghi-Off, Ramtin
   Wagner, Julian
   Rau, Linda
   Doerner, Ralf
TI Virtual reality content creation based on self-contained components in
   the e-learning domain: Re-using pattern-based vr content in different
   authoring toolkits
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Virtual reality; E-Learning; Bite-sized learning; Authoring; Games
   engineering; Short virtual reality experiences; Virtual reality learning
   nuggets
AB In the context of e-learning, it is challenging to incorporate emerging technologies, such as alternate reality games or Virtual Reality (VR), within current learning trends. Microlearning is such a current trend. It divides large and complex chunks of content into small and elementary learning nuggets. These single self-contained nuggets are then composed to overarching lessons or courses. The concept of VR nuggets dovetails this educational trend. VR nuggets are standalone, self-contained, and rather short VR experiences that can be combined with other learning nuggets. By using initial implementations of VR nuggets, they can be used to let authors create VR earning content, for example, to let learners experience alternate realities. In this paper, we further investigate the VR nugget authoring concept and extent it. We introduce two novel authoring toolkits that rely on VR nuggets - one based on context-related module interaction (CoNMoD) and one based on visual scripting (ViNS Tiles). In two separate user studies, we examine the acceptance of the toolkits and compare them to existing authoring environments that also rely on VR nuggets but utilize different interface techniques. These studies' results emphasize the importance of exchanging content between different established tools and indicate the acceptance of our tools regarding their hedonic and pragmatic qualities, also compared to existing tools from related work. As a conclusion, we propose an exchange format for VR nuggets that supports their reusability. It enables authors that use different toolkits to work together. They can utilize VR nuggets created with other toolkits and still use their own preferred toolkit. By means of an expert survey, we draw conclusions on technical aspects and a suitable platform to make VR nuggets available to the community. This survey indicates that potential authors would use such an exchange-approach for creating and presenting VR content and that they are willing to share their work and to contribute in a VR nugget authoring community.
C1 [Horst, Robin; Gerstmeier, Simon; Naraghi-Taghi-Off, Ramtin; Wagner, Julian; Rau, Linda; Doerner, Ralf] RheinMain Univ Appl Sci, Kurt Schumacher Ring 18, D-65197 Wiesbaden, Germany.
RP Horst, R (corresponding author), RheinMain Univ Appl Sci, Kurt Schumacher Ring 18, D-65197 Wiesbaden, Germany.
EM robin.horst@hs-rm.de
OI Horst, Robin/0000-0003-1881-8743; Rau, Linda/0000-0001-7165-0041
FU Federal Ministry of Education and Research of Germany in the project
   Innovative Hochschule [03IHS071]
FX The work is supported by the Federal Ministry of Education and Research
   of Germany in the project Innovative Hochschule (funding number:
   03IHS071).
CR Ahmad TSAS, 2021, INT INVENTION INNOVA, P52
   Al Shehri A., 2021, INT J EDUC RES, V6, P176, DOI [10.24331/ijere.869642, DOI 10.24331/IJERE.869642]
   [Anonymous], 1964, Some rapid approximate statistical procedures
   [Anonymous], 2003, P M C 2003 INT BEW, DOI DOI 10.1097/00001756-200303030-00034
   [Anonymous], P 17 ANN ACM S US IN
   [Anonymous], 2008, SOFTWARE ENG ARCHITE
   [Anonymous], 1998, Practical nonparametric statistics
   Ashtari N, 2020, PROCEEDINGS OF THE 2020 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'20), DOI 10.1145/3313831.3376722
   Ausburn L.J., 2004, J IND TEACH ED, V41, P1
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Beaudin JS, 2007, LECT NOTES COMPUT SC, V4794, P55
   Beutner M, 2017, SOC INF TECHN TEACH, P744
   Bierbaum A, 2001, P IEEE VIRT REAL ANN, P89, DOI 10.1109/VR.2001.913774
   Billinghurst M., 1997, VRST'97. ACM Symposium on Virtual Reality Software and Technology 1997, P155, DOI 10.1145/261135.261163
   Buchem I., 2010, ELEARNING PAPERS, V21
   Carrozzino M., 2005, ADV COMPUTER ENTERTA, P270
   Davies AG, 2019, BMJ SIMUL TECHNOL EN, V5, P234, DOI 10.1136/bmjstel-2017-000295
   Doerner R, 2015, LECT NOTES COMPUT SC, V8844, P187, DOI 10.1007/978-3-319-17043-5_11
   Dorner R., 2003, Entertainment Computing. Technologies and Applications. IFIP First International Workshop on Entertainment Computing (IWEC 2002), P405
   Dunk A, 2010, PROCEDIA COMPUT SCI, V1, P2603, DOI 10.1016/j.procs.2010.04.294
   Eroglu S, 2021, 2021 IEEE VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI 10.1109/VR50410.2021.00020
   Fayad ME, 1997, COMMUN ACM, V40, P32, DOI 10.1145/262793.262798
   Figueroa PA., 2012, SBC J INTERACT SYST, V3, P2
   Figueroa P, 2008, PRESENCE-TELEOP VIRT, V17, P492, DOI 10.1162/pres.17.5.492
   Fuhrmann A.L., 2001, Proceedings of the ACM Symposium on Virtual Reality Software and Technology, VRST'01, P183
   Gamma E., 1994, Design patterns: Elements of reusable object-oriented software
   Geijtenbeek Thomas, 2011, P 10 INT C VIRT REAL, DOI [DOI 10.1145/2087756.2087785, 10.1145/2087756.2087785]
   Häfner P, 2013, PROCEDIA COMPUT SCI, V25, P251, DOI 10.1016/j.procs.2013.11.031
   Hargood C, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P128, DOI 10.1145/3209542.3209559
   Hassenzahl M., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P201, DOI 10.1145/332040.332432
   Hassenzahl M., 2018, FUNOLOGY, P301, DOI [10.1007/978-3-319-68213-6_19, DOI 10.1007/978-3-319-68213-6_19]
   Horst R., 2019, 2019 IEEE INT C ENG, P1, DOI [10.1109/TALE48000.2019.9225867, DOI 10.1109/TALE48000.2019.9225867]
   Horst R., 2019, P 16 WORKSHOP VIRTUA, P137, DOI [10.2370/9783844068870, DOI 10.2370/9783844068870]
   Horst R, 2020, J UNIVERS COMPUT SCI, V26, P947
   Horst R, 2019, 25TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2019), DOI 10.1145/3359996.3364261
   Horst R, 2018, ADJUNCT PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P381, DOI 10.1109/ISMAR-Adjunct.2018.00110
   Hug Th, 2005, P INT C MED TRANS 4
   Janghorbani S, 2019, AAMAS '19: PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS, P104
   Jee HK, 2014, MULTIMED TOOLS APPL, V68, P225, DOI 10.1007/s11042-011-0880-4
   Job MA., 2012, International journal of scientific technology research, V1, P92
   Johnson RE, 1997, COMMUN ACM, V40, P39, DOI 10.1145/262793.262799
   Klinker G, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P76, DOI 10.1109/ISMAR.2002.1115076
   Kovachev D., 2011, Advances in Web-Based Learning - ICWL 2011. Lecture Notes in Computer Science, V7048, DOI [DOI 10.1007/978-3-642-25813-8_6, 10.1007/978-3-642-25813-86, DOI 10.1007/978-3-642-25813-86]
   Krauss V, 2021, CHI '21: PROCEEDINGS OF THE 2021 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3411764.3445335
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Lee GA, 2005, COMMUN ACM, V48, P76, DOI 10.1145/1070838.1070840
   Lee GA, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P172, DOI 10.1109/ISMAR.2004.34
   Ltd ER, 2020, VIRT REAL TOOLK VRTK
   MANN HB, 1947, ANN MATH STAT, V18, P50, DOI 10.1214/aoms/1177730491
   Manning KD, 2021, BMC MED EDUC, V21, DOI 10.1186/s12909-021-02496-z
   MANSOURI H, 2009, P 14 INT S 3D WEB TE, P31
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Millard D, 2017, Authoring for interactive storytelling
   Monahan T, 2005, EUROGRAPHICS ED PAPE, P33
   Monahan T, 2008, COMPUT EDUC, V50, P1339, DOI 10.1016/j.compedu.2006.12.008
   Polsani P., 2003, J DIGITAL INFORM, V3
   Prouzeau A, 2020, PROCEEDINGS OF THE WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES AVI 2020, DOI 10.1145/3399715.3399743
   Reicher T., 2004, P INT WORKSH EXPL DE
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   So HJ, 2018, EXAMINING DESIGN MIC
   Souza M., 2014, Creative Education, V5, P672, DOI [10.4236/ce.2014.59079, DOI 10.4236/CE.2014.59079]
   Takala T.M., 2014, Proceedings of the 2Nd ACM Symposium on Spatial User Interaction, P94, DOI DOI 10.1145/2659766.2659774
   Tanriverdi Vildan, 2001, P ACM S VIRTUAL REAL, P175
   Technologies U, 2020, UN GAM ENG DESCR
   Wang YF, 2017, 2017 IEEE LIFE SCIENCES CONFERENCE (LSC), P27, DOI 10.1109/LSC.2017.8268135
   Yang H.H., 2013, Procedia - Social And Behavioral Sciences, V77, P429, DOI [10.1016/j.sbspro.2013.03.098, DOI 10.1016/J.SBSPRO.2013.03.098, DOI 10.1016/J.SBSPR0.2013.03.098]
   Youngblut C., 1998, ED USES VIRTUAL REAL
   Zhang DS, 2004, COMMUN ACM, V47, P75, DOI 10.1145/986213.986216
   Zohar OE, 2008, US Patent App, Patent No. [11/832,726, 11832726, 11/832726]
NR 69
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 JUN 18
PY 2022
DI 10.1007/s11042-022-13362-5
EA JUN 2022
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2F0JA
UT WOS:000812603300004
PM 35755621
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Aymaz, S
   Köse, C
   Aymaz, S
AF Aymaz, Samet
   Kose, Cemal
   Aymaz, Seyma
TI A novel approach with the dynamic decision mechanism (DDM) in
   multi-focus image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus; Image fusion; Deep learning; Focus metrics; CNN
ID ALGORITHM; TRANSFORM; FRAMEWORK; NETWORKS; WAVELET
AB Multi-focus image fusion merges multiple source images of the same scene with different focus values to obtain a single image that is more informative. A novel approach is proposed to create this single image in this paper. The method's primary stages include creating initial decision maps, applying morphological operations, and obtaining the fused image with the created fusion rule. Initial decision maps consist of label values represented as focused or non-focused. While determining these values, the first decision is made by feeding the image patches obtained from each source image to the modified CNN architecture. If the modified CNN architecture is unstable in determining label values, a new improvement mechanism designed based on focus measurements is applied for unstable regions where each image patch is labelled as non-focused. Then, the initial decision maps obtained for each source image are improved by morphological operations. Finally, the dynamic decision mechanism (DDM) fusion rule, designed considering the label values in the decision maps, is applied to minimize the disinformation resulting from classification errors in the fused image. At the end of all these steps, the final fused image is obtained. Also, in the article, a rich dataset containing two or more than two source images for each scene is created based on the COCO dataset. As a result, the method's success is measured with the help of objective and subjective metrics. When the visual and quantitative results are examined, it is proven that the proposed method successfully creates a perfect fused image.
C1 [Aymaz, Samet; Kose, Cemal; Aymaz, Seyma] Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
C3 Karadeniz Technical University
RP Aymaz, S (corresponding author), Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
EM sdemir@ceng.ktu.edu.tr
RI aymaz, şeyma/JEP-5707-2023
CR Amin-Naji M, 2020, J AMB INTEL HUM COMP, V11, P1749, DOI 10.1007/s12652-019-01199-0
   Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bai XZ, 2015, INFORM FUSION, V22, P105, DOI 10.1016/j.inffus.2014.05.003
   Bogoni L, 2001, PATTERN RECOGN, V34, P1515, DOI 10.1016/S0031-3203(00)00087-X
   Bouzos O, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2922097
   Burt P., 1984, Proc. SPIE, V0575, P173, DOI [10.1117/12.966501, DOI 10.1117/12.966501]
   Chen CH, 2015, CHEM ENGINEER TRANS, V46, P277, DOI 10.3303/CET1546047
   Chen L, 2013, OPT EXPRESS, V21, P5182, DOI 10.1364/OE.21.005182
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Du CB, 2019, OPTIK, V176, P567, DOI 10.1016/j.ijleo.2018.09.089
   Du CB, 2018, OPTIK, V157, P1003, DOI 10.1016/j.ijleo.2017.11.162
   Fu W, 2016, METHODSX, V3, P87, DOI 10.1016/j.mex.2015.12.004
   Gai D, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107681
   Guo XP, 2018, NEURAL COMPUT, V30, P1775, DOI 10.1162/neco_a_01098
   Hao XX, 2015, APPL OPTICS, V54, P8982, DOI 10.1364/AO.54.008982
   He KJ, 2018, NEUROCOMPUTING, V320, P157, DOI 10.1016/j.neucom.2018.09.018
   Hua KL, 2014, J VIS COMMUN IMAGE R, V25, P951, DOI 10.1016/j.jvcir.2014.02.009
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Jiang Q., 2016, NEUROCOMPUTING, V174, P733, DOI [10.1016/j.neucom.2015.09.092, DOI 10.1016/J.NEUCOM.2015.09.092]
   Jung H, 2020, IEEE T IMAGE PROCESS, V29, P3845, DOI 10.1109/TIP.2020.2966075
   Krizhevsky A., The cifar-10 dataset, in
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li HF, 2017, SIGNAL PROCESS, V138, P71, DOI 10.1016/j.sigpro.2017.03.008
   Li HF, 2012, OPT COMMUN, V285, P91, DOI 10.1016/j.optcom.2011.08.078
   Li HG, 2019, IEEE SENS J, V19, P9755, DOI 10.1109/JSEN.2019.2928818
   Li LL, 2021, MULTIMED TOOLS APPL, V80, P12389, DOI 10.1007/s11042-020-10462-y
   Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu CP, 2016, OPTIK, V127, P11354, DOI 10.1016/j.ijleo.2016.09.038
   Liu SQ, 2020, MULTIDIM SYST SIGN P, V31, P569, DOI 10.1007/s11045-019-00675-2
   Liu YP, 2014, SIGNAL PROCESS, V97, P9, DOI 10.1016/j.sigpro.2013.10.010
   Liu YP, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.2.023017
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2018, VISUAL COMPUT, V34, P589, DOI 10.1007/s00371-017-1363-z
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Moushmi S, 2016, ADV INTELLIGENT SYST
   Nejati M, 2017, INFORM FUSION, V36, P284, DOI 10.1016/j.inffus.2016.12.009
   Panigrahy C, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106141
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Wang HM, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0204225
   Wen Y, 2020, MULTIMED TOOLS APPL, V79, P34531, DOI 10.1007/s11042-020-08945-z
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang Y, 2017, SIGNAL IMAGE VIDEO P, V11, P439, DOI 10.1007/s11760-016-0979-1
   Yang Y, 2020, IEEE SYST J, V14, P852, DOI [10.1007/s13198-019-00887-6, 10.1109/JSYST.2019.2900336]
   Yin HP, 2016, NEUROCOMPUTING, V216, P216, DOI 10.1016/j.neucom.2016.07.039
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang XL, 2016, SIGNAL PROCESS, V123, P127, DOI 10.1016/j.sigpro.2016.01.006
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zheng YF, 2007, INFORM FUSION, V8, P177, DOI 10.1016/j.inffus.2005.04.003
NR 57
TC 2
Z9 2
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 2
BP 1821
EP 1871
DI 10.1007/s11042-022-13323-y
EA JUN 2022
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7U8IE
UT WOS:000810821800005
DA 2024-07-18
ER

PT J
AU Singh, S
   Garg, NK
   Kumar, M
AF Singh, Sukhjinder
   Garg, Naresh Kumar
   Kumar, Munish
TI Feature extraction and classification techniques for handwritten
   Devanagari text recognition: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Devanagari script; Handwritten character recognition; Feature
   extraction; Classification and deep learning
ID OPTICAL CHARACTER-RECOGNITION; DEVNAGARI CHARACTERS; INDIAN SCRIPTS;
   MODEL
AB The character recognition system is a vital area in the field of pattern recognition. One interesting, complex, and challenging task is handwritten character recognition because of various writing styles of individuals. The accuracy of such systems highly depends upon the extraction and selection of features. Many researchers proposed a variety of feature extraction and classification methods for various scripts including Devanagari. In view of that, this article presents a broad study of feature extraction and classification methods considered so far for online and offline Handwritten Character Recognition (HCR) for Devanagari script, which is essential in Optical Character Recognition (OCR) research. This article presents techniques used by authors, the dataset used, the accuracy achieved by the methods of the work already available for the OCR research. This article is depicting the latest studies, research gaps, challenges and future perspectives for the researchers working in the Devanagari text recognition domain. Moreover, methods developed for feature extraction and classification in the area of Devanagari character recognition are presented in a systematic way as an assistance for future researchers. It has been gathered that traditional feature extraction and classifications methods are being replaced with deep learning methods to achieve higher recognition accuracy in this area.
C1 [Singh, Sukhjinder] Maharaja Ranjit Singh Punjab Tech Univ, Dept Elect & Commun Engn, GZS Campus Coll Engn & Technol, Bathinda, Punjab, India.
   [Garg, Naresh Kumar] Maharaja Ranjit Singh Punjab Tech Univ, Dept Comp Sci & Engn, GZS Campus Coll Engn & Technol, Bathinda, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM munishcse@gmail.com
RI Kumar, Munish/P-7756-2018; SINGH, SUKHJINDER/AGF-8676-2022
OI Kumar, Munish/0000-0003-0115-1620; SINGH, SUKHJINDER/0000-0003-0696-4874
CR Abuzaraida M. A., 2021, International Journal of Electrical and Computer Engineering, V11, P3584
   Acharya J, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, NETWORKING AND COMMUNICATIONS (ICNC), P1, DOI 10.1109/ICCNC.2015.7069284
   Aggarwal Ashutosh, 2012, INT J ADV RES COMPUT, V2, P85
   Ajmire SP., 2015, INT J ADV RES COMPUT, V5, P787
   Alginahi Yasser, 2010, Character Recognition, P1
   Alrobah N, 2022, ARAB J SCI ENG, V47, P9943, DOI 10.1007/s13369-021-06363-3
   Alrobah N, 2021, IEEE ACCESS, V9, P87058, DOI 10.1109/ACCESS.2021.3087647
   [Anonymous], 2014, P INT C HIGH PERFORM, DOI DOI 10.1109/ICHPCA.2014.7045339
   [Anonymous], 2004, THESIS PUNJABI U
   [Anonymous], 2009, INT J ADV SCI TECHNO
   [Anonymous], 2010, INT J COMPUT APPL
   [Anonymous], 2010, INT J COMPUTER SCI S, DOI DOI 10.48550/ARXIV.1006.5908
   Ansari S., 2016, INT J ADV RES, V4, P2034, DOI [10.21474/IJAR01/2017, DOI 10.21474/IJAR01/2017]
   Ansari S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P11, DOI 10.1109/INFOP.2015.7489342
   Arica N, 2001, IEEE T SYST MAN CY C, V31, P216, DOI 10.1109/5326.941845
   Arora S., 2009, 2009 2nd International Conference on Emerging Trends in Engineering and Technology (ICETET 2009), P929, DOI 10.1109/ICETET.2009.215
   Arora S., 2010, IJCSI INT J COMPUTER, V7
   Arora S, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL II, PROCEEDINGS, P399, DOI 10.1109/ICCIMA.2007.254
   Bag S, 2013, SADHANA-ACAD P ENG S, V38, P133, DOI 10.1007/s12046-013-0121-9
   Bajaj R, 2002, SADHANA-ACAD P ENG S, V27, P59, DOI 10.1007/BF02703312
   Basu S, 2010, PATTERN RECOGN, V43, P3507, DOI 10.1016/j.patcog.2010.05.018
   Bathla AK., 2019, ASIAN J ENG APPL TEC, V8, P50, DOI [10.51983/ajeat-2019.8.1.1060, DOI 10.51983/AJEAT-2019.8.1.1060]
   Bhattacharya N, 2019, ACM T ASIAN LOW-RESO, V18, DOI 10.1145/3264735
   Bhattacharya U, 2009, IEEE T PATTERN ANAL, V31, P444, DOI 10.1109/TPAMI.2008.88
   Chaudhuri A, 2017, STUD FUZZ SOFT COMP, V352, P9
   Connell SD, 2000, INT C PATT RECOG, P368, DOI 10.1109/ICPR.2000.906089
   Dargan S, 2020, SOFT COMPUT, V24, P10111, DOI 10.1007/s00500-019-04525-y
   Dargan S, 2019, ARCH COMPUT METHOD E, V26, P1283, DOI 10.1007/s11831-018-9278-z
   Deore SP, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01484-1
   Deshpande PS, 2008, J COMPUT, V3, P11, DOI 10.4304/jcp.3.5.11-17
   Devi DP, 2021, MATER TODAY-PROC, V45, P626, DOI 10.1016/j.matpr.2020.02.720
   Dey R, 2022, MULTIMED TOOLS APPL, V81, P10469, DOI 10.1007/s11042-022-12148-z
   Dixit A., 2014, IND C INDICON, P1, DOI DOI 10.1109/INDICON.2014.7030525
   Dongre VJ, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P425
   Elkhayati M, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108288
   Elnagar A, 2003, J EXP THEOR ARTIF IN, V15, P299, DOI 10.1080/0952813021000047170
   Farkya S., 2015, INT J COMPUT INF SCI, V9, P491
   Gaur A, 2015, 2015 4TH INTERNATIONAL SYMPOSIUM ON EMERGING TRENDS AND TECHNOLOGIES IN LIBRARIES AND INFORMATION SERVICES (ETTLIS), P65, DOI 10.1109/ETTLIS.2015.7048173
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Ghosh R, 2015, PROC INT CONF DOC, P401, DOI 10.1109/ICDAR.2015.7333792
   Ghosh R, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P483, DOI 10.1109/SPIN.2015.7095313
   Gupta D, 2022, NEURAL COMPUT APPL, V34, P5665, DOI 10.1007/s00521-021-06672-6
   Gupta D, 2019, MULTIMED TOOLS APPL, V78, P19361, DOI 10.1007/s11042-019-7286-0
   Hanmandlu M, 2007, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P208
   Hanmandlu M, 2007, PATTERN RECOGN, V40, P1840, DOI 10.1016/j.patcog.2006.08.014
   Hanmandlu M., 2009, International Journal of Computer Processing of Oriental Languages, V22, P1
   Hanmandlu M, 2007, 9 BIENN C AUSTR PATT
   Jangid M, 2018, J IMAGING, V4, DOI 10.3390/jimaging4020041
   Jangid M, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1936, DOI 10.1109/ICACCI.2016.7732334
   Jawahar CV, 2003, PROC INT CONF DOC, P408
   Jayadevan R, 2011, IEEE T SYST MAN CY C, V41, P782, DOI 10.1109/TSMCC.2010.2095841
   Kale KV, 2013, 2013 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL AND BUSINESS INTELLIGENCE (ISCBI), P274, DOI 10.1109/ISCBI.2013.62
   Kamble PM, 2017, COMM COM INF SC, V709, P93, DOI 10.1007/978-981-10-4859-3_9
   Kaur H, 2021, DATA DRIVEN APPROACH, DOI 10.1007/978-981-15-9873-9_44
   Kaur H, 2018, PATTERN ANAL APPL, V21, P897, DOI 10.1007/s10044-018-0731-2
   Kompalli S, 2005, PROC INT CONF DOC, P327
   Kompalli S, 2006, SECOND INTERNATIONAL CONFERENCE ON DOCUMENT IMAGE ANALYSIS FOR LIBRARIES, PROCEEDINGS, P96, DOI 10.1109/DIAL.2006.12
   Korichi A, 2022, MULTIMED TOOLS APPL, V81, P20719, DOI 10.1007/s11042-022-11979-0
   Kubatur S, 2012, INT C HIGH PERF COMP, DOI DOI 10.1109/HPCSIM.2012.6266913
   Kumar M, 2021, SOFT COMPUT, V25, P11589, DOI 10.1007/s00500-021-06060-1
   Kumar M, 2020, ARTIF INTELL REV, V53, P2075, DOI 10.1007/s10462-019-09727-2
   Kumar M, 2020, ARCH COMPUT METHOD E, V27, P577, DOI 10.1007/s11831-019-09332-0
   Kumar M, 2019, NEURAL PROCESS LETT, V50, P43, DOI 10.1007/s11063-018-9913-6
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Kumar M, 2011, COMM COM INF SC, V205, P268
   Kumar P, 2018, PATTERN RECOGN LETT, V103, P1, DOI 10.1016/j.patrec.2017.12.014
   Kumar Satish, 2009, International Journal of Recent Trends in Engineering, V1, P33
   Kumar S, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1009, DOI 10.1109/ICCSP.2016.7754301
   Liang J, 2008, IEEE T PATTERN ANAL, V30, P591, DOI 10.1109/TPAMI.2007.70724
   Mahesh J., 2018, INT J IMAGE GRAPH, V18, P1
   Mane V., 2009, P INT C ADV COMPUTIN, P410, DOI 10.1145/1523103.1523184
   Meshesha M, 2008, INT J DOC ANAL RECOG, V11, P29, DOI 10.1007/s10032-008-0067-3
   More VN, 2008, P IEEE REGION 10 C T, P16, DOI [10.1109/TENCON.2008.4766863, DOI 10.1109/TENCON.2008.4766863]
   Mushtaq F, 2021, NEURAL COMPUT APPL, V33, P15229, DOI 10.1007/s00521-021-06144-x
   Narang S, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1126-9
   Narang SR, 2021, MULTIMED TOOLS APPL, V80, P20671, DOI 10.1007/s11042-021-10775-6
   Narang SR, 2020, SOFT COMPUT, V24, P17279, DOI 10.1007/s00500-020-05018-z
   Narang SR, 2019, SOFT COMPUT, V23, P13603, DOI 10.1007/s00500-019-03897-5
   Narang SR, 2019, MULTIMED TOOLS APPL, V78, P23255, DOI 10.1007/s11042-019-7620-6
   Narang V, 2013, PROC INT CONF DOC, P902, DOI 10.1109/ICDAR.2013.184
   Obaida MA., 2011, INT J COMPUT APPL, V28, P7, DOI [10.5120/3409-4759, DOI 10.5120/3409-4759]
   Pagare G, 2015, 2015 Fifth International Conference on Advances in Computing and Communications (ICACC), P46, DOI 10.1109/ICACC.2015.42
   Pal U, 2007, PROC INT CONF DOC, P749
   Pal U, 2007, PROC INT CONF DOC, P496
   Pal U., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P456, DOI 10.1109/ICDAR.2009.171
   Pal Umapada, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1111, DOI 10.1109/ICDAR.2009.244
   Pal U., 2008, Proc. 11th ICFHR, P367
   Pant A. K., 2012, 3 AS HIM INT C INT A, P1, DOI DOI 10.1109/AHICI.2012.6408440
   Pourmohammad S, 2013, 5 INT C MOD SIM APPL, P1
   Prashanth DS, 2022, WIRELESS PERS COMMUN, V122, P349, DOI 10.1007/s11277-021-08903-4
   Pratap N., 2012, INT J COMPUTER SCI T, V3, P77
   Ramteke AS., 2012, INT J SCI TECHNOL RE, V1, P142
   Ramteke RJ, 2006, P IEEE C CYBERNETICS, P16
   Sachdeva Juhee, 2022, Proceedings of Data Analytics and Management: ICDAM 2021. Lecture Notes on Data Engineering and Communications Technologies (90), P211, DOI 10.1007/978-981-16-6289-8_18
   SETHI IK, 1977, PATTERN RECOGN, V9, P69, DOI 10.1016/0031-3203(77)90017-6
   Sethi R, 2020, 9 IEEE INT C COMMUNI, P4954, DOI [10.1109/CSNT48778.2020.9115746, DOI 10.1109/CSNT48778.2020.9115746]
   Sharma N, 2006, LECT NOTES COMPUT SC, V4338, P805
   Sharma S, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/5945117
   Shaw B, 2008, ICIT 2008: PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, P256, DOI 10.1109/ICIT.2008.32
   Shaw B, 2008, ICIT 2008: PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, P203, DOI 10.1109/ICIT.2008.33
   Shelke Sushama, 2015, 2015 International Conference on Communication, Information & Computing Technology (ICCICT), P1, DOI 10.1109/ICCICT.2015.7045738
   Shelke S., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P215, DOI 10.1109/ICFHR.2010.41
   Shelke S, 2016, P IEEE INT ULTR S IU, P1, DOI [10.1109/ICONSIP.2016.7857482, DOI 10.1109/ICONSIP.2016.7857482]
   Singh A., 2015, INT J ADV RES COMPUT, V4, P123, DOI [10.17148/IJARCCE.2015.4825, DOI 10.17148/IJARCCE.2015.4825]
   Singh H, 2021, SOFT COMPUT, V25, P6329, DOI 10.1007/s00500-021-05620-9
   Singh S., 2020, ADV INTELLIGENT SYST, V1171, P97, DOI [10.1007/978-981-15-5400-1_11, DOI 10.1007/978-981-15-5400-1_11]
   Singh S, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100037
   Smith R., 2009, P INT WORKSHOP MULTI, P1, DOI DOI 10.1145/1577802.1577804
   Tanuja K., 2015, INT J ADV TECHNOLOGY, V2, P71
   Thakral B, 2014, 3 INT C RELIABILITY, P14, DOI [10.1109/ICRITO.2014.7014746, DOI 10.1109/ICRITO.2014.7014746]
   Ulges A, 2005, PROC INT CONF DOC, P1001, DOI 10.1109/ICDAR.2005.90
   Vamvakas G, 2009, P 10 INT C DOCUMENT
   Verma VK, 2015, INT CONF COMPUT INTE, P433, DOI 10.1109/CICN.2015.90
   Wakabayashi Tetsushi, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P196, DOI 10.1109/ICDAR.2009.197
   Wanchoo AnkitaS., 2016, INT J APPL ENG RES, V11, P4529
   Weng Y, 2020, MOBILE NETW APPL, V25, P402, DOI 10.1007/s11036-019-01243-5
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
NR 117
TC 11
Z9 11
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2023
VL 82
IS 1
BP 747
EP 775
DI 10.1007/s11042-022-13318-9
EA JUN 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7L1HB
UT WOS:000808527600006
DA 2024-07-18
ER

PT J
AU Penichet, VMR
   Lozano, MD
   Garrido, JE
   Albertos-Marco, F
   Bond, R
   Mulvenna, MD
AF Penichet, Victor M. R.
   Lozano, Maria D.
   Garrido, Juan E.
   Albertos-Marco, Felix
   Bond, Raymond
   Mulvenna, Maurice D.
TI Designing postures for rehabilitation therapies in a multimodal system
   based on a 3D virtual environment and movement-based interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rehabilitation technologies; Movement-based interaction; Interactive
   systems; Healthcare technology
AB Technological advances have facilitated new approaches to support different needs in healthcare environments. In particular, in the field of rehabilitation therapies, we can find software applications that have been developed to support the performance of specific exercises, often with different customization options. However, there are still many gaps that need to be addressed to provide more and better global solutions. In this article, we present a novel system aimed at physiotherapists, which allows them to create new rehabilitation exercises designed to meet the specific needs of their patients. This implies the creation of individualized therapies that contribute to a better and faster recovery of patients. The system consists of a virtual 3D environment with a 3D skeleton representing the patient. The physiotherapist can interact with the skeleton to design the desired postures that the patient should practice according to their personal limitations. The system allows physiotherapists to compose a complete and personalized set of exercises. Alternatively, the physiotherapist may also create the postures by means of a motion sensing device using motion- and voice-based interaction. Both options pose research challenges that the authors have addressed to provide the solution presented in this paper.
C1 [Penichet, Victor M. R.; Lozano, Maria D.] Univ Castilla La Mancha, Dept Comp Syst, Albacete, Spain.
   [Garrido, Juan E.] Univ Lleida, Dept Comp Sci & Engn, Lleida, Spain.
   [Albertos-Marco, Felix] Univ Castilla La Mancha, Dept Informat Technol & Syst, Talavera De La Reina, Spain.
   [Bond, Raymond; Mulvenna, Maurice D.] Univ Ulster, Sch Comp, Belfast, Antrim, North Ireland.
C3 Universidad de Castilla-La Mancha; Universitat de Lleida; Universidad de
   Castilla-La Mancha; Ulster University
RP Penichet, VMR (corresponding author), Univ Castilla La Mancha, Dept Comp Syst, Albacete, Spain.
EM victor.penichet@uclm.es
RI Penichet, Victor M. R./L-5524-2014; Lozano, Maria Dolores/L-6607-2014
OI Penichet, Victor M. R./0000-0003-1125-9344; Albertos-Marco,
   Felix/0000-0002-2406-5701; Mulvenna, Maurice/0000-0002-1554-0785
FU Ministry of Science, Innovation and Universities (Spain)
   [RTI2018-099942-B-I00]; regional government (JCCM)
   [SBPLY/17/180501/000495]; European Regional Development Fund (FEDER);
   CRUE-CSIC
FX Open Access funding provided thanks to the CRUE-CSIC agreement with
   Springer Nature. This work has been partially supported by the national
   project granted by the Ministry of Science, Innovation and Universities
   (Spain) with reference RTI2018-099942-B-I00 and by the regional project
   (ref: SBPLY/17/180501/000495) granted by the regional government (JCCM)
   and the European Regional Development Fund (FEDER).
CR Alabbasi H., 2015, IASI ROMANIA, P1, DOI [10.1109/EHB.2015.7391465, DOI 10.1109/EHB.2015.7391465]
   [Anonymous], 2006, 25062 ISOIEC
   Avola D, 2013, COMPUT METH PROG BIO, V110, P490, DOI 10.1016/j.cmpb.2013.01.009
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Brooke J, 2013, J USABILITY STUD, V8, P29
   Clark RA, 2019, GAIT POSTURE, V68, P193, DOI 10.1016/j.gaitpost.2018.11.029
   Garrido JE, 2013, INT CONF PER COMP, P319, DOI 10.4108/icst.pervasivehealth.2013.252368
   Navarro JEG, 2014, J MED INTERNET RES, V16, P232, DOI 10.2196/jmir.3154
   Fernndez-Valls JA., 2014, P 8 INT C PERVASIVE
   Fernndez-Valls JA., 2015, GETTING UP REHABILIT, P82
   Fikar P, 2013, INT CONF PER COMP, P327, DOI 10.4108/icst.pervasivehealth.2013.252224
   Garcia-Hernandez N, 2021, VIRTUAL REAL-LONDON, V25, P669, DOI 10.1007/s10055-020-00481-3
   Garrido JE, 2019, UNIVERSAL ACCESS INF, V18, P3, DOI 10.1007/s10209-017-0587-z
   Kayama H, 2013, INT CONF PER COMP, P362, DOI 10.4108/icst.pervasivehealth.2013.252253
   Kuroda T, 2018, J EXP ANAL BEHAV, V110, P522, DOI 10.1002/jeab.471
   Lange B, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P170
   Lewis JR, 2018, J USABILITY STUD, V13, P158
   Lozano-Quilis JA, 2013, INT CONF PER COMP, P366, DOI 10.4108/icst.pervasivehealth.2013.252208
   NIELSEN J, 1993, HUMAN FACTORS IN COMPUTING SYSTEMS, P206
   Putnam C., 2013, CHI 13 EXTENDED ABST, P391, DOI [10.1145/2468356.2468426, DOI 10.1145/2468356.2468426]
   Velloso Eduardo., 2013, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, P1309
   Wennrich K, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3281578
NR 22
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44445
EP 44466
DI 10.1007/s11042-022-13292-2
EA JUN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000805749900005
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Chen, H
   Han, Q
   Li, Q
   Tong, XJ
AF Chen, Hao
   Han, Qi
   Li, Qiong
   Tong, Xiaojun
TI Image steganalysis with multi-scale residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganalysis; Steganography; Deep residual network; Deep learning
AB In recent years, many deep neural network models are used in steganalysis. However, the deep neural network models on steganalysis usually use the single scale channel for detection. When the number of convolution kernels reaches a certain limit, the improvement of detection accuracy is very weak by increasing the number of convolution kernels. In this paper, we try to establish a wider range of image region correlation extraction, and propose a multi-scale deep neural network model. The model is based on the deep residual network and adopts end-to-end design. Different local receptive fields in the same layer were selected to generate the characteristic channels. By the channel recognition, variety of image steganographic features were achieved from different scale channels. Experiments show that the multi-scale residual network can further improve the accuracy of steganography detection more than the networks of the single scale channel.
C1 [Chen, Hao; Han, Qi; Li, Qiong; Tong, Xiaojun] Harbin Inst Technol, Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Han, Q (corresponding author), Harbin Inst Technol, Comp Sci & Technol, Harbin 150001, Heilongjiang, Peoples R China.
EM chenhaoxv@126.com; qi.han@hit.edu.cn; qiong.li@hit.edu.cn;
   tong_xiaojun@163.com
FU National Natural Science Foundation of China [61471141, 61361166006,
   61301099]; Key Technology Program of Shenzhen, China
   [JSGG20160427185010977]; Basic Research Project of Shenzhen, China
   [JCYJ20150513151706561]
FX This work was supported by the National Natural Science Foundation of
   China [grant numbers 61471141, 61361166006, 61301099]; Key Technology
   Program of Shenzhen, China, [grant number JSGG20160427185010977]; Basic
   Research Project of Shenzhen, China [grant number
   JCYJ20150513151706561]. The authors would like to thank the Digital Data
   Embedding Laboratory sharing code on the website, and Institute of
   Information Countermeasures Technology providing deep learning servers.
CR Avcibas I, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P645, DOI 10.1109/ICIP.2002.1039053
   Avcibas I, 2001, PROC SPIE, V4314, P523, DOI 10.1117/12.435436
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Chen M, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P75, DOI 10.1145/3082031.3083248
   Denemark T., 2016, Electron. Imag., V28, P1
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Denemark T, 2014, IEEE INT WORKS INFOR, P48, DOI 10.1109/WIFS.2014.7084302
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Furon T, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/597040
   Guo LJ, 2015, IEEE T INF FOREN SEC, V10, P2669, DOI 10.1109/TIFS.2015.2473815
   Guo LJ, 2014, IEEE T INF FOREN SEC, V9, P814, DOI 10.1109/TIFS.2014.2312817
   Guo LJ, 2012, IEEE INT WORKS INFOR, P169, DOI 10.1109/WIFS.2012.6412644
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2012, IEEE INT WORKS INFOR, P234, DOI 10.1109/WIFS.2012.6412655
   Kim J, 2020, MULTIMED TOOLS APPL, V79, P1355, DOI 10.1007/s11042-019-08251-3
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Li B, 2014, IEEE IMAGE PROC, P4206, DOI 10.1109/ICIP.2014.7025854
   Li L, 2020, IEEE T MULTIMEDIA, V22, P2526, DOI 10.1109/TMM.2019.2959909
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sedighi V, 2016, IEEE T INF FOREN SEC, V11, P221, DOI 10.1109/TIFS.2015.2486744
   Singh B, 2021, MULTIMED TOOLS APPL, V80, P4903, DOI 10.1007/s11042-020-09960-w
   Tang W, 2014, P 2 ACM WORKSH INF H, P91, DOI [10.1145/2600918.2600935, DOI 10.1145/2600918.2600935]
   Tang WX, 2016, IEEE T INF FOREN SEC, V11, P734, DOI 10.1109/TIFS.2015.2507159
   Wang P, 2019, MULTIMED TOOLS APPL, V78, P23309, DOI 10.1007/s11042-019-7654-9
   Westfeld A, 2001, INFORM HIDING
   Xu G., 2016, P 4 ACM WORKSH INF H, P103, DOI DOI 10.1145/2909827.2930798
   Xu GS, 2017, IH&MMSEC'17: PROCEEDINGS OF THE 2017 ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY, P67, DOI 10.1145/3082031.3083236
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Ye J, 2017, IEEE T INF FOREN SEC, V12, P2545, DOI 10.1109/TIFS.2017.2710946
NR 37
TC 6
Z9 6
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22009
EP 22031
DI 10.1007/s11042-021-11611-7
EA JUN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000804560500003
DA 2024-07-18
ER

PT J
AU Dezfuli, SRM
   Kheyrandish, M
AF Dezfuli, Seyedeh Razieh Mahmoudinejad
   Kheyrandish, Mohammad
TI An image encryption method based on chaotic system exploiting fuzzy
   system and arithmetic coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos theory; Image processing; Fuzzy logic; Logistic
   map; Arithmetic coding algorithm
ID GENETIC ALGORITHM; SCHEME; SELECTION; MODEL
AB Due to development of network and computer technology, safe storage, distribution and transmission of different media has become a significant issue. The use of cryptographic approaches plays a key role in securing images. Various cryptographic approaches have been proposed to protect images, some of which have failed due to high correlation between pixels, differences between images and so threatening by diverse attacks. Thus, designing a performant image encryption method is still an important challenge. Unique features of chaotic systems, such as high sensitivity to initial conditions and pseudo-random behavior, have made them suitable for image encryption. The combination of chaotic-based techniques and fuzzy systems provides a high level of image security and improves the performance and reliability of image encryption process. By exploiting the advantages of fuzzy rules, while focusing on the resistance feature of chaotic systems, against different attacks, this paper presents a novel image encryption method based on a combination of chaos theory, fuzzy systems and arithmetic coding. Fuzzy rules and arithmetic coding are used parallelly to improve the encryption process, while chaotic-based techniques improve image security and attack resistance, by permuting the image pixels, along the rows. Implementing and comparing the proposed method show superiorities in terms of factors such as entropy rate, correlation coefficient, key sensitivity, and more.
C1 [Dezfuli, Seyedeh Razieh Mahmoudinejad; Kheyrandish, Mohammad] Islamic Azad Univ, Dept Comp Engn, Dezful Branch, Dezful, Iran.
C3 Islamic Azad University
RP Kheyrandish, M (corresponding author), Islamic Azad Univ, Dept Comp Engn, Dezful Branch, Dezful, Iran.
EM Rose_mahmudi@yahoo.com; Mohammad.kheyrandish@iau.ac.ir
OI mahmudi nezhad, seyedeh raziyeh/0000-0002-3068-1834
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Alfalou A, 2015, PROG OPTICS, V60, P119, DOI 10.1016/bs.po.2015.02.002
   [Anonymous], 2014, J ADV MATH COMPUTER
   Behnia S, 2007, PHYS LETT A, V366, P391, DOI 10.1016/j.physleta.2007.01.081
   Blej M., 2016, International Journal of Applied Engineering Research, V11, P11071
   Bouslimi D, 2012, IEEE T INF TECHNOL B, V16, P891, DOI 10.1109/TITB.2012.2207730
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108041
   Chai XL, 2021, INFORM SCIENCES, V556, P305, DOI 10.1016/j.ins.2020.10.007
   Chai XL, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107684
   Chen JX, 2015, COMMUN NONLINEAR SCI, V20, P846, DOI 10.1016/j.cnsns.2014.06.032
   Davis, 2006, ENHANCING PATTERN CL
   Dey, 2018, IMAGE, V6
   Dutta S, 2013, CIRP J MANUF SCI TEC, V6, P212, DOI 10.1016/j.cirpj.2013.02.005
   El-Khamy SE, 2020, IEEE ACCESS, V8, P148935, DOI 10.1109/ACCESS.2020.3015687
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Erdal E, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040782
   Gad M, 2021, INT ARAB J INF TECHN, V18, P227, DOI 10.34028/iajit/18/2/12
   Ghebleh M, 2014, SIGNAL PROCESS-IMAGE, V29, P618, DOI 10.1016/j.image.2013.09.009
   Hua ZY, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.107998
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P4505, DOI 10.1007/s11071-021-06472-6
   Hua ZY, 2021, NONLINEAR DYNAM, V104, P807, DOI 10.1007/s11071-021-06308-3
   Hua ZY, 2020, IEEE T SIGNAL PROCES, V68, P1937, DOI 10.1109/TSP.2020.2979596
   Hua ZY, 2019, IEEE ACCESS, V7, P8660, DOI 10.1109/ACCESS.2018.2890116
   Hung WL, 2008, PATTERN RECOGN LETT, V29, P1317, DOI 10.1016/j.patrec.2008.02.003
   Jacquin AP, 2009, J HYDROINFORM, V11, P202, DOI 10.2166/hydro.2009.038
   Khandwani FI., 2018, Int. J. Electr. Electron. Comput. Sci. Eng, V5, P39
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Kushnir M, 2020, 15TH INTERNATIONAL CONFERENCE ON ADVANCED TRENDS IN RADIOELECTRONICS, TELECOMMUNICATIONS AND COMPUTER ENGINEERING (TCSET - 2020), P610, DOI 10.1109/TCSET49122.2020.235504
   Li HJ, 2011, OPT LASER ENG, V49, P753, DOI 10.1016/j.optlaseng.2011.03.017
   Li TY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21030319
   Lin KT, 2012, OPT COMMUN, V285, P2335, DOI 10.1016/j.optcom.2012.01.028
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Maan AnmolJyot., 2013, INT J INFORM COMPUTA, V3, P139
   Mbewe P, 2017, 2017 13TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P178, DOI 10.1109/FSKD.2017.8393036
   Mehran K., 2008, Industrial Automation, Robotics and Artificial Intelligence (EEE8005), V262
   Mousa Hardy M., 2018, International Journal of Computer Network and Information Security, V10, P10, DOI 10.5815/ijcnis.2018.04.02
   Moysis L, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22040474
   Pandian Anand, 2010, IEEE 4 INT C INT MUL, P1
   Ping P, 2018, NEUROCOMPUTING, V283, P53, DOI 10.1016/j.neucom.2017.12.048
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Singh K, 2011, INT J COMPUTER APPL, V23
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Webel K, 2012, ECON LETT, V115, P487, DOI 10.1016/j.econlet.2011.12.110
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Zarebnia M, 2019, MULTIMED TOOLS APPL, V78, P10491, DOI 10.1007/s11042-018-6644-7
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
   Zhou J, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106437
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
NR 51
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 30
BP 44263
EP 44289
DI 10.1007/s11042-022-13250-y
EA JUN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M8TR
UT WOS:000804560500006
DA 2024-07-18
ER

PT J
AU Kumar, S
AF Kumar, Sachin
TI Extending boolean operations-based secret image sharing to compartmented
   access structure
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret image sharing; Visual secret sharing; Visual cryptography;
   Boolean operations; Compartmented access structure; Multipartite access
   structure
ID RANDOM GRIDS; SCHEME; ENCRYPTION
AB The methods for sharing a secret image using Boolean operations are good candidates for Visual Secret Sharing (VSS) as limiting pixel expansion and the reconstruction process computational complexity in VSS schemes. The existing Boolean operations-based secret image sharing (SIS) schemes can only handle the sharing of a secret for (k, n)-threshold and general access structure. This paper extends the Boolean operations-based SIS scheme for Compartmented access structure. Two construction techniques are proposed to realize the sharing of a secret image into Compartmented access structure. The proposed scheme benefits by having wide applicability with better visual quality of the reconstructed secret and without involving complex computation in the reconstruction process. Formal proofs and experimental results are given to validate the correctness, security and performance of the proposed scheme.
C1 [Kumar, Sachin] Govt India, Delhi 110017, India.
RP Kumar, S (corresponding author), Govt India, Delhi 110017, India.
EM skiitd09@gmail.com
CR Bhattacharjee T, 2018, SIGNAL PROCESS-IMAGE, V61, P21, DOI 10.1016/j.image.2017.10.012
   BRICKELL EF, 1990, LECT NOTES COMPUT SC, V434, P468
   Chao KY, 2009, INT J PATTERN RECOGN, V23, P263, DOI 10.1142/S0218001409007090
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Chen TH, 2009, PATTERN RECOGN, V42, P2203, DOI 10.1016/j.patcog.2008.11.015
   Espejel-Trujillo A, 2014, INT CON ADV INFO NET, P240, DOI 10.1109/AINA.2014.34
   Fathimal PM, 2017, MULTIMED TOOLS APPL, V76, P5489, DOI 10.1007/s11042-016-4074-y
   Fathimal PM, 2016, INT J INF SECUR PRIV, V10, P1, DOI 10.4018/IJISP.2016070101
   Guo C, 2012, PATTERN RECOGN LETT, V33, P83, DOI 10.1016/j.patrec.2011.09.030
   Iftene S., 2005, IACR CRYPTOLOGY EPRI, V2005, P408
   Jha DP, 2016, 2016 1ST INTERNATIONAL CONFERENCE ON INNOVATION AND CHALLENGES IN CYBER SECURITY (ICICCS 2016), P86, DOI 10.1109/ICICCS.2016.7542316
   KAFRI O, 1987, OPT LETT, V12, P377, DOI 10.1364/OL.12.000377
   Kohli R, 2021, IOT HEALTHCARE AMBIE, P293, DOI 10.1007/978-981-15-9897-5_14
   Kumar S., 2013, INT J COMPUTER APPL, V83, P1, DOI [10.5120/14457-2741, DOI 10.5120/14457-2741]
   Kumar S, 2017, J DISCRET MATH SCI C, V20, P1069, DOI 10.1080/09720529.2014.996983
   Kumar S, 2015, FUND INFORM, V137, P369, DOI 10.3233/FI-2015-1185
   Kumar S, 2012, INT J SECUR APPL, V6, P9
   Kumar S, 2014, SECUR COMMUN NETW, V7, P653, DOI 10.1002/sec.769
   Kumar S, 2013, CRYPTOLOGIA, V37, P154, DOI 10.1080/01611194.2012.739585
   Martin K. M., 1991, B I COMBINATORIAL AP, V1, P71
   Naor M, 1995, LECT NOTES COMPUTER, V950, P112
   Pakniat N, 2014, J VIS COMMUN IMAGE R, V25, P1093, DOI 10.1016/j.jvcir.2014.03.004
   Shamir A., 1979, Communications of the ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2013, IEEE T CIRC SYST VID, V23, P414, DOI 10.1109/TCSVT.2012.2204940
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   SIMMONS GJ, 1990, LECT NOTES COMPUT SC, V403, P390
   Tassa T, 2007, J CRYPTOL, V20, P237, DOI 10.1007/s00145-006-0334-8
   Tassa T, 2009, J CRYPTOL, V22, P227, DOI 10.1007/s00145-008-9027-9
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang XF, 2017, CRYPTOGR COMMUN, V9, P625, DOI 10.1007/s12095-016-0205-6
   Wu Z, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8030448
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
   Yu YY, 2011, LECT NOTES COMPUT SC, V7043, P136, DOI 10.1007/978-3-642-25243-3_11
NR 34
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 14
BP 22063
EP 22082
DI 10.1007/s11042-021-11554-z
EA JUN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3YR2
UT WOS:000805063200007
DA 2024-07-18
ER

PT J
AU Yaman, O
   Tuncer, T
AF Yaman, Orhan
   Tuncer, Turker
TI Accurate deep and direction classification model based on the antiprism
   graph pattern feature generator using underwater acoustic for defense
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Antiprism graph pattern; Underwater sound classification; TQWT; INCA;
   Classification; Machine learning
AB Underwater acoustic is one of the hot-topic and complex research areas for advanced signal processing. In this research, our main motivation is to recommend a high accurate underwater sound classification method using a special graph-based feature generator. The most valuable features have been selected using ReliefF iterative neighborhood component analysis (RFINCA) selector. In the classification phase, Decision Tree (DT), k nearest neighbor (kNN), Linear Discriminant (LD), Naive Bayes (NB), and support vector machine (SVM) classifiers have been used with 10-fold cross-validation. To calculate the performance of the TQWT and antiprism graph pattern-based feature generation and RFINCA selector-based sound classification method, two underwater acoustic datasets have been collected. According to tests, the best accurate classifier is SVM. SVM attained 90.33% and 96.91% accuracies for the collected depth and direction datasets respectively. The calculated results denoted the success of the presented antiprism graph pattern-based method for underwater acoustic classification.
C1 [Yaman, Orhan; Tuncer, Turker] Firat Univ, Fac Technol, Dept Digital Forens Engn, Elazig, Turkey.
C3 Firat University
RP Yaman, O (corresponding author), Firat Univ, Fac Technol, Dept Digital Forens Engn, Elazig, Turkey.
EM orhanyaman@firat.edu.tr; turkertuncer@firat.edu.tr
RI YAMAN, Orhan/V-5800-2018; TUNCER, Turker/W-4846-2018
OI YAMAN, Orhan/0000-0001-9623-2284
FU Firat University Research Fund, Turkey [MMY.20.01]
FX This work is supported by Firat University Research Fund, Turkey.
   Project Numbers: MMY.20.01 and TEKF.20.10.
CR Alghamdi AS, 2020, APPL ACOUST, V164, DOI 10.1016/j.apacoust.2020.107279
   [Anonymous], GLADIUS MINI 4K UND
   Chang HH, 2019, IEEE J OCEANIC ENG, V44, P1130, DOI 10.1109/JOE.2018.2865045
   Cho H, 2015, J MAR SCI TECH-JAPAN, V20, P180, DOI 10.1007/s00773-014-0294-x
   Cho SH, 2016, IEEE T GEOSCI REMOTE, V54, P6833, DOI 10.1109/TGRS.2016.2591619
   Choi J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18093062
   Choi J, 2015, OCEANS 2015 - GENOVA, DOI 10.1109/OCEANS-Genova.2015.7271437
   Cui XD, 2021, APPL ACOUST, V174, DOI 10.1016/j.apacoust.2020.107728
   Ding JM, 2019, MEASUREMENT, V143, P112, DOI 10.1016/j.measurement.2019.05.006
   Ding XY, 2017, OCEANS-IEEE
   Dong YF, 2021, APPL ACOUST, V174, DOI 10.1016/j.apacoust.2020.107740
   Firat U., 2017, EMO Bilimsel Dergi, P25
   Fischell EM, 2018, IEEE INT C INTELL RO
   Gupta H, 2019, IEEE IMAGE PROC, P624, DOI [10.1109/ICIP.2019.8804200, 10.1109/icip.2019.8804200]
   Isbitiren G, 2011, IEEE T VEH TECHNOL, V60, P3897, DOI 10.1109/TVT.2011.2163538
   Jiang JJ, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108586
   Jiang JJ, 2020, MEASUREMENT, V166, DOI 10.1016/j.measurement.2020.108227
   Khare SK, 2020, APPL ACOUST, V163, DOI 10.1016/j.apacoust.2020.107234
   Koseoglu M, 2016, OCEANS 2016 MTS/IEEE MONTEREY, DOI 10.1109/OCEANS.2016.7761118
   Lee H, 2018, IEEE T GEOSCI REMOTE, V56, P5813, DOI 10.1109/TGRS.2018.2826556
   Li YX, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010061
   Liu YJ, 2021, APPL ACOUST, V172, DOI 10.1016/j.apacoust.2020.107594
   Lowes GJ, 2019, OCEAN 2019 MTSIEEE S, P19, DOI [10.23919/OCEANS40490.2019.8962399, DOI 10.23919/OCEANS40490.2019.8962399]
   Lv ZC, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107820
   Neves G, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112870
   Nie DH, 2014, OCEANS-IEEE
   Reis CDG, 2019, METHODS ECOL EVOL, V10, P1501, DOI 10.1111/2041-210X.13245
   Santos-Domínguez D, 2016, APPL ACOUST, V113, P64, DOI 10.1016/j.apacoust.2016.06.008
   Shao KX, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108580
   Sierra E, 2015, ANN C N AM FUZZ INF, P04, DOI [10.1109/NAFIPS-WConSC.2015.7284174, DOI 10.1109/NAFIPS-WCONSC.2015.7284174]
   Sutin A., 2010, International Waterside Security Conference (WSS), 2010, P1, DOI DOI 10.1109/WSSC.2010.5730286
   Sutin A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY (HST), P195, DOI 10.1109/THS.2013.6698999
   Tuncer T, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102173
   Xiao R, 2019, MEASUREMENT, V146, P479, DOI 10.1016/j.measurement.2019.06.050
   Yaman O, 2021, APPL ACOUST, V175, DOI 10.1016/j.apacoust.2020.107859
   Zhu CY, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111699
NR 36
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9961
EP 9985
DI 10.1007/s11042-022-13196-1
EA MAY 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000797298200002
DA 2024-07-18
ER

PT J
AU Garain, A
   Dawn, R
   Singh, S
   Chowdhury, C
AF Garain, Avishek
   Dawn, Rudrajit
   Singh, Saswat
   Chowdhury, Chandreyee
TI Differentially private human activity recognition for smartphone users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HAR; Noise; Privacy; Differential privacy; Deep MLP; Smartphones
AB User privacy is an important concern that should be handled in data intensive applications. Interestingly, differential privacy is a privacy model that can be applied to such datasets. This model is advantageous as it does not make any strong assumption about the adversary. In this work, we have introduced the notion of differential privacy in the domain of Human Activity Recognition (HAR). Real life accelerometer data has been collected from different smartphone configurations that were carried by the users in different manner according to their convenience. Our contribution in this work is to propose a privacy preserving HAR framework incorporating algorithms to preserve the differential privacy of the user data. The algorithm exploits the scalar and the vector parts of the accelerometer readings and applies privacy preserving mechanisms on it. A Deep Multi Layer Perceptron (DMLP) framework has been utilized for activity classification. We have achieved comparatively similar results with an enhanced surplus of achievement of privacy in terms of data and are so far the first of its kind in the aforementioned domain of HAR based on smartphone sensing data. The proposed framework is implemented both on collected real life dataset capturing different smartphone configurations and usage behavior and benchmark datasets.
C1 [Garain, Avishek; Dawn, Rudrajit; Singh, Saswat; Chowdhury, Chandreyee] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Chowdhury, C (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM avishekgarain@gmail.com; rudrajit.dawn@gmail.com;
   singhsaswat02@gmail.com; chandreyee.chowdhury@gmail.com
RI Garain, Avishek/AAV-3835-2020
OI Garain, Avishek/0000-0001-6225-3343
CR Agarwal Rashmi, 2021, Progress in Advanced Computing and Intelligent Engineering. Proceedings of ICACIE 2019. Advances in Intelligent Systems and Computing (AISC 1198), P257, DOI 10.1007/978-981-15-6584-7_25
   Tran AT, 2021, NEUROCOMPUTING, V422, P245, DOI 10.1016/j.neucom.2020.10.014
   Boutsis I, 2013, 2013 IEEE INT C PERV
   Clauset A, 2008, NATURE, V453, P98, DOI 10.1038/nature06830
   Dong S, 2021, COMPUT SCI REV, V40, DOI 10.1016/j.cosrev.2021.100379
   Fredrikson M., 2015, P 22 ACM SIGSAC C CO
   Hu R, 2020, IEEE INTERNET THINGS, V7, P9530, DOI 10.1109/JIOT.2020.2991416
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Ji SL, 2017, IEEE COMMUN SURV TUT, V19, P1305, DOI 10.1109/COMST.2016.2633620
   Kairouz P, 2014, ADV NEUR IN, V27
   Kasiviswanathan SP, 2013, LECT NOTES COMPUT SC, V7785, P457, DOI 10.1007/978-3-642-36594-2_26
   Le Cun Y., 2015, DEEP LEARNING NATURE, V521, P444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Liu AX, 2021, ALGORITHMS DATA COMP, P313
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rojas Raul, 1996, Neural networks: a systematic introduction, P149, DOI DOI 10.1007/978-3-642-61068-4
   Ryoo M, 2017, P AAAI C ARTIFICIAL, V31
   Saha J, 2021, MULTIMED TOOLS APPL, V80, P9895, DOI 10.1007/s11042-020-10046-w
   Saha J, 2018, INFORMATION, V9, DOI 10.3390/info9040094
   Sahnoune Z, 2021, INT J MOB COMMUN, V19, P22, DOI 10.1504/IJMC.2021.111895
   Samarah S, 2017, IEEE ACCESS, V5, P3848, DOI 10.1109/ACCESS.2017.2685531
   Shun Z, 2021, ARXIV 210112602
   Song C, 2017, P 2017 ACM SIGSAC C
   Stamate C, 2017, INT CONF PERVAS COMP, DOI 10.1109/PERCOM.2017.7917848
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Vecchio A, 2017, IEEE SENSOR LETT, V1, DOI 10.1109/LSENS.2017.2726759
   Wan SH, 2018, IEEE ACCESS, V6, P36825, DOI 10.1109/ACCESS.2018.2851382
   Wang W, 2016, IEEE ACM T NETWORK, V24, P3235, DOI 10.1109/TNET.2015.2512301
   Wolf FA, 2019, GENOME BIOL, V20, DOI 10.1186/s13059-019-1663-x
   Zheng HD, 2020, IEEE INTELL SYST, V35, P5, DOI 10.1109/MIS.2020.3010335
NR 29
TC 2
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40827
EP 40848
DI 10.1007/s11042-022-13185-4
EA MAY 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177900001
DA 2024-07-18
ER

PT J
AU Kaur, R
   Bhattacharya, J
   Chana, I
AF Kaur, Ravneet
   Bhattacharya, Jhilik
   Chana, Inderveer
TI Deep CNN based online image deduplication technique for cloud storage
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Near-exact image detection; Data
   deduplication; Online image deduplication technique; Storage systems;
   Cloud computing; Cloud storage
ID EFFICIENT; NETWORK; OBJECT
AB Online image detection is one of the most critical components of an image deduplication technique for an efficient cloud storage system. Although extensive research has been conducted in this field, the problem still remains challenging. Deep learning techniques have achieved significant success in solving a variety of computer vision issues and have high potential in image deduplication techniques. Deduplication is an efficient method in a cloud storage system that minimizes redundant data at the file or sub-file level using cryptographic hash signatures. Although significant research on offline image deduplication techniques have been reported, yet limited research is available on online image deduplication techniques. Online image matching accuracy and performance has been a major challenge for online image deduplication techniques to detect exact or near-exact images using feature extraction techniques. These first use feature extraction techniques to extract image features and then match these image features to detect duplicate images. In this paper, we have proposed a Deep CNN based online image deduplication technique for a cloud storage system to detect exact and near-exact images using cross-domains, even in the presence of perturbations in the form of blur, noise, compression, lighting variations and many more. The experimental results show that our proposed deep CNN for online image deduplication technique outperforms in terms of image matching accuracy and performance. The paper also proposed a Hot Decomposition Vector (HDV) for image patch generation to store efficiently dissimilar parts of near-exact images. The experimental results demonstrate that HDV exhibits higher and stable image matching accuracy in all three types of image deformations with relatively small computation time.
C1 [Kaur, Ravneet; Bhattacharya, Jhilik; Chana, Inderveer] Thapar Inst Engn & Technol Deemed Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kaur, R (corresponding author), Thapar Inst Engn & Technol Deemed Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM ravneet@thapar.edu; jhilik@thapar.edu; inderveer@thapar.edu
RI Chana, Inderveer/AAT-4399-2020
OI Chana, Inderveer/0000-0001-9799-5582
FU Department of Science and Technology, Government of India under WOS
   (Women Scientists Scheme) [SR/WOS-A/ET-119/2016]
FX This research is supported by the Department of Science and Technology,
   Government of India under WOS (Women Scientists Scheme) sponsored
   research project entitled "Distributed Data Deduplication Technique for
   efficient Cloud-Based Storage System" under File No:
   SR/WOS-A/ET-119/2016.
CR Alkawaz MH, 2018, NEURAL COMPUT APPL, V30, P183, DOI 10.1007/s00521-016-2663-3
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Banerji S, 2013, NEUROCOMPUTING, V117, P173, DOI 10.1016/j.neucom.2013.02.014
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Biadgie Y., 2014, 2014 INT C INF SCI A, P1, DOI DOI 10.1109/ICISA.2014.6847403
   Chen CC, 2015, J VIS COMMUN IMAGE R, V30, P86, DOI 10.1016/j.jvcir.2015.02.014
   Chen M, 2013, J COMPUT, V8, P2768, DOI 10.4304/jcp.8.11.2768-2775
   Chen M, 2012, INT CONF CLOUD COMPU, P624, DOI 10.1109/CCIS.2012.6664249
   Dharshini T, 2019, J INF COMPUT SCI, V9
   Di Pietro R, 2016, COMPUT COMMUN, V82, P71, DOI 10.1016/j.comcom.2016.01.011
   Diankun Zhang, 2020, Advances in 3D Image and Graphics Representation, Analysis, Computing and Information Technology. Algorithms and Applications. Proceedings of IC3DIT 2019. Smart Innovation, Systems and Technologies (SIST 180), P129, DOI 10.1007/978-981-15-3867-4_16
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Diwakar M, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101754
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Foo JJ, 2007, MULTIMEDIA EXPO IEEE
   Gang H, 2015, LECT NOTES COMPUT SC, V9357, P243, DOI 10.1007/978-3-319-24315-3_25
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   Grabner M, 2006, LECT NOTES COMPUT SC, V3851, P918
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huang F, 2019, INT J COMPUT SCI ENG, V18, P294, DOI 10.1504/IJCSE.2019.098540
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jung HM, 2011, LECT NOTES ARTIF INT, V6591, P78, DOI 10.1007/978-3-642-20039-7_8
   Jyoti, 2019, 2019 Women Institute of Technology Conference on Electrical and Computer Engineering (WITCON ECE). Proceedings, P129, DOI 10.1109/WITCONECE48374.2019.9092894
   Kalia R, 2011, 17 KOREA JAPAN JOINT, DOI 10.1109/FCV.2011.5739756
   Kaur R, 2018, J SUPERCOMPUT, V74, P2035, DOI 10.1007/s11227-017-2210-8
   Ke Y, 2004, PROC CVPR IEEE, P506
   Ke Y, 2004, P ACM INT C MULTIMED, V4
   Kordopatis-Zilos G., 2019, VIDEO VERIFICATION F, DOI 10.1007/978-3-030-26752-0_4
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Kumar M, 2019, J KING SAUD UNIV-COM, V31, P113, DOI 10.1016/j.jksuci.2016.12.002
   Kumar M, 2018, J KING SAUD UNIV-COM, V30, P41, DOI 10.1016/j.jksuci.2016.03.003
   Kumar PM, 2020, INT J GRID UTIL COMP, V11, P509
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Lee SH, 2015, IEEE IMAGE PROC, P452, DOI 10.1109/ICIP.2015.7350839
   Lei YQ, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2602186
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li J, 2015, MULTIMED TOOLS APPL, V74, P655, DOI 10.1007/s11042-014-2008-0
   Li Li, 2014, Journal of Multimedia, V9, P829, DOI 10.4304/jmm.9.6.829-834
   Li X, 2016, SOFT COMPUT, V20, P1437, DOI 10.1007/s00500-015-1596-6
   LIANG S, 2020, MULTIMEDIA MODELING
   Liu DZ, 2020, J REAL-TIME IMAGE PR, V17, P175, DOI 10.1007/s11554-019-00887-6
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P1282, DOI 10.1109/TIP.2015.2400229
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J., 2009, INT J IMAGE PROCESSI, V3, P143, DOI DOI 10.1007/S11270-006-2859-8
   Mao B, 2014, ACM T STORAGE, V10, DOI 10.1145/2512348
   Miksik O, 2012, INT C PATT RECOG, P2681
   Mohamed SMA, 2021, DISTRIB PARALLEL DAT, V39, P201, DOI 10.1007/s10619-020-07301-2
   Mohapatra S, 2020, ADV INTELL SYST COMP, V1120, P395, DOI 10.1007/978-981-15-2449-3_34
   Nbt Y., 2016, INT J ADV COMPUT SCI, V5, P12
   Nian FD, 2016, MULTIMED TOOLS APPL, V75, P2435, DOI 10.1007/s11042-015-2472-1
   Nilsback M.-E., 2006, IEEE C COMP VIS PATT, V2, P1447, DOI [DOI 10.1109/CVPR.2006.42, 10.1109/CVPR.2006.42]
   Pang YW, 2012, NEUROCOMPUTING, V85, P6, DOI 10.1016/j.neucom.2011.12.006
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Paulo J, 2014, ACM COMPUT SURV, V47, DOI 10.1145/2611778
   Peker Kadir A., 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P217, DOI 10.1109/CBMI.2011.5972548
   Raghavendra U, 2018, INFORM SCIENCES, V441, P41, DOI 10.1016/j.ins.2018.01.051
   Ramaiah NP, 2011, IEEE RECENT ADV INTE, DOI 10.1109/RAICS.2011.6069341
   Seo JS, 2004, SIGNAL PROCESS-IMAGE, V19, P325, DOI 10.1016/j.image.2003.12.001
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song JK, 2020, INT J COMPUT VISION, V128, P2243, DOI 10.1007/s11263-020-01305-2
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song JK, 2013, IEEE T MULTIMEDIA, V15, P1997, DOI 10.1109/TMM.2013.2271746
   Song Jingkuan, 2017, ARXIV170804150
   Srinivas S, 2016, FRONT ROBOT AI, V2, DOI 10.3389/frobt.2015.00036
   Sujatha G, 2020, ARTIF INTELL, V130, P529, DOI [10.1007/978-981-15-5329-5_49, DOI 10.1007/978-981-15-5329-5_49]
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Takeshita J., 2020, ARXIV200502330, DOI 10.1109/ICCCN49398.2020.9209728
   Thaiyalnayaki S., 2019, International Journal of Advanced Intelligence Paradigms, V12, P192
   Thaiyalnayaki S, 2018, MATER TODAY-PROC, V5, P1943, DOI 10.1016/j.matpr.2017.11.297
   Thyagharajan KK, 2021, ARCH COMPUT METHOD E, V28, P897, DOI 10.1007/s11831-020-09400-w
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Vedaldi A., 2015, Proceedings of the 23rd ACM international conference on Multimedia, P689, DOI DOI 10.1145/2733373.2807412
   Velmurugan K, 2011, GLOBAL J COMPUT SCI, V11
   Wan J, 2013, IPDPSW 20642070, DOI 10.1109/IPDPSW.2013.176
   Wang JG, 2010, 11 INT C CONTROL AUT
   Wang JF, 2016, DATA SCI ENG, V1, P178, DOI 10.1007/s41019-016-0018-9
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xia W, 2020, IEEE T PARALL DISTR, V31, P2017, DOI 10.1109/TPDS.2020.2984632
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Yao JL, 2015, IEEE SIGNAL PROC LET, V22, P1404, DOI 10.1109/LSP.2014.2377795
   Yu Han Liu, 2018, Journal of Physics: Conference Series, V1087, DOI 10.1088/1742-6596/1087/6/062032
   Yu Hua, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1616, DOI 10.1109/INFOCOM.2015.7218541
   Yu XH, 2009, IEEE INT SYMP CIRC S, P1665, DOI 10.1109/ISCAS.2009.5118093
   Zargar AJ, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON FUTURISTIC TRENDS ON COMPUTATIONAL ANALYSIS AND KNOWLEDGE MANAGEMENT (ABLAZE), P165
   Zeng XF, 2018, NEURAL COMPUT APPL, V30, P503, DOI 10.1007/s00521-016-2700-2
   Zhang J, 2008, 2008 11TH IEEE SINGAPORE INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS (ICCS), VOLS 1-3, P362, DOI 10.1109/ICCS.2008.4737205
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
   Zhou WX, 2018, ISPRS J PHOTOGRAMM, V145, P197, DOI 10.1016/j.isprsjprs.2018.01.004
   Zuo F, 2004, IEEE IMAGE PROC, P1425
   Zuo PF, 2017, INT CON DISTR COMP S, P1510, DOI 10.1109/ICDCS.2017.36
NR 92
TC 2
Z9 2
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40793
EP 40826
DI 10.1007/s11042-022-13182-7
EA MAY 2022
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000795177900005
DA 2024-07-18
ER

PT J
AU Rastogi, S
   Bansal, D
AF Rastogi, Shubhangi
   Bansal, Divya
TI Disinformation detection on social media: An integrated approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Covid-19; Fake; Disinformation; Satire; Machine learning; Neural
   network; Ensemble
ID INFORMATION; TRUE; CUES
AB The emergence of social media platforms has amplified the dissemination of false information in various forms. Social media gives rise to virtual societies by providing freedom of expression to users in a democracy. Due to the presence of echo chambers on social media, social science studies play a vital role in the spread of false news. To this aim, we provide a comprehensive framework that is adapted from several scholarly studies. The framework is capable of detecting information into various types, namely real, disinformation and satire based on authenticity as well as intention. The process highlights the use of interdisciplinary approaches derived from fundamental theories of social science and integrating them with modern computational tools and techniques. Few of these theories claim that malicious users suggest writing fabricated content in a different style to attract the audience. Style-based methods evaluate the intention i.e., the content is written with an intent to mislead the audience or not. However, the writing style can be deceptive. Thus, it is important to involve user-oriented social information to improve model strength. Therefore, the paper used an integrated approach by combining style based and propagation-based features with a total of thirty-one features. The extracted features are divided into ten categories: relative frequency, quantity, complexity, uncertainty, sentiment, subjectivity, diversity, informality, additional, and popularity. The features have been iteratively utilized by supervised classifiers and then selected the best-correlated ones using the ANOVA test. Our experimental results have shown that the selected features are able to distinguish real from disinformation and satirical news. It has been observed that the Ensemble machine learning model outperformed other models over the developed multi-labelled corpus.
C1 [Rastogi, Shubhangi; Bansal, Divya] Punjab Engn Coll Deemed Univ, Dept Comp Sci & Engn, Chandigarh, India.
C3 Punjab Engineering College (Deemed University)
RP Rastogi, S (corresponding author), Punjab Engn Coll Deemed Univ, Dept Comp Sci & Engn, Chandigarh, India.
EM shubhangi05.rastogi@gmail.com
RI Rastogi, Shubhangi/HKV-8764-2023
OI Rastogi, Shubhangi/0000-0003-0680-3384
CR Ahmed H, 2017, INT C INTELLIGENT SE
   Ahuja R, 2018, PROCEDIA COMPUT SCI, V143, P411, DOI 10.1016/j.procs.2018.10.412
   Ajao O, 2019, ICASSP 2019 2019 IEE
   Allouche O, 2006, J APPL ECOL, V43, P1223, DOI 10.1111/j.1365-2664.2006.01214.x
   Amado BG, 2015, EUR J PSYCHOL APPL L, V7, P3, DOI 10.1016/j.ejpal.2014.11.002
   Anburajan K., 2020, RECENT ADV COMPUTER, V13, P557, DOI DOI 10.2174/2213275912666190204141902
   Ayedee Nishu, 2020, ROLE MEDIA TELEVISIO, DOI [10.2139/ssrn.3605514, DOI 10.2139/SSRN.3605514]
   Bandura A, 2001, MEDIA PSYCHOL, V3, P265, DOI 10.1207/S1532785XMEP0303_03
   Bardenet R, 2013, INT C MACH LEARN
   Boididou C, 2018, MULTIMED TOOLS APPL, V77, P15545, DOI 10.1007/s11042-017-5132-9
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Conroy N. J., 2015, P ASS INFORM SCI TEC, V52, P1, DOI 10.1002/pra2.2015.145052010082
   DEUTSCH MORTON, 1955, JOUR ABNORMAL AND SOCIAL PSYCHOL, V51-31, P629, DOI 10.1037/h0046408
   Devassy BM, 2020, FORENSIC SCI INT, V311, DOI 10.1016/j.forsciint.2020.110194
   Elssied N. O. F., 2014, Research Journal of Applied Sciences, Engineering and Technology, V7, P625, DOI [10.19026/rjaset.7.299, DOI 10.19026/RJASET.7.299]
   Fersini E., 2020, CLEF LABS WORKSH NOT, P1
   Filzmoser P, 2008, COMPUT STAT DATA AN, V52, P1694, DOI 10.1016/j.csda.2007.05.018
   Gautam A, 2020, 2020 IEEE 6 INT C MU
   Gettleman Jeffrey., 2020, The New York Times
   Gillani N, 2018, P 2018 WORLD WIDE WE
   Glenski M, 2018, ARXIV 180512032
   Goldberg Y, 2014, ARXIV 14023722
   Gravanis G, 2019, EXPERT SYST APPL, V128, P201, DOI 10.1016/j.eswa.2019.03.036
   Hajek P, 2020, NEURAL COMPUT APPL, V32, P17259, DOI 10.1007/s00521-020-04757-2
   Horne BD, 2017, ARXIV 170309398
   Iwendi C, 2018, 2018 IEEE INT C IND
   Iwendi C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111331
   JOHNSON MK, 1981, PSYCHOL REV, V88, P67, DOI 10.1037/0033-295X.88.1.67
   Kajan E, 2020, COMPUT SCI INF SYST, V17, P403, DOI 10.2298/CSIS190822002K
   Kasthuri A, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319500322
   Khan JY, 2019, ARXIV 190504749
   Kumar M, 2015, PROCEDIA COMPUT SCI, V54, P301, DOI 10.1016/j.procs.2015.06.035
   Kumar S, 2018, SURVEY ARXIV 1804085
   Kuran T, 1999, STANFORD LAW REV, V51, P683, DOI 10.2307/1229439
   Kusen Ema, 2018, Online Social Networks and Media, V5, P37, DOI 10.1016/j.osnem.2017.12.002
   McCornack SA, 2014, J LANG SOC PSYCHOL, V33, P348, DOI 10.1177/0261927X14534656
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Mohseni S, 2019, ARXIV 190403016
   Moreno-Sandoval LG, 2020, CLEF LABS WORKSH NOT
   Pereira Francisco, 2009, Neuroimage, V45, pS199, DOI 10.1016/j.neuroimage.2008.11.007
   Posadas-Durn JP, 2015, WORKING NOTES PAPERS
   Potthast M, 2017, ARXIV 170205638
   Prez-Rosas V, 2017, ARXIV 170807104
   Rashkin H, 2017, P 2017 C EMP METH NA
   Reis JCS, 2019, IEEE INTELL SYST, V34, P76, DOI 10.1109/MIS.2019.2899143
   Rout JK, 2017, MULTIMED TOOLS APPL, V76, P3187, DOI 10.1007/s11042-016-3819-y
   Savyan PV, 2020, MULTIMED TOOLS APPL, V79, P19349, DOI 10.1007/s11042-020-08721-z
   Schreiner C, 2006, P HUM FACT ERG SOC A, V50
   Shao CC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06930-7
   Shu K, 2017, arXiv:1712.07709, V8
   Siering M, 2016, J MANAGE INFORM SYST, V33, P421, DOI 10.1080/07421222.2016.1205930
   Stefanidis A, 2013, CARTOGR GEOGR INF SC, V40, P116, DOI 10.1080/15230406.2013.776211
   Stenetorp P., 2012, P DEMONSTRATIONS SES, P102
   Tabachnick B. G., 2007, Experimental designs using ANOVA
   Trstenjak B, 2014, PROCEDIA ENGINEER, V69, P1356, DOI 10.1016/j.proeng.2014.03.129
   Vosoughi S, 2018, SCIENCE, V359, P1146, DOI 10.1126/science.aap9559
   Zannettou S, 2019, ACM J DATA INF QUAL, V11, DOI 10.1145/3309699
   Zhang DS, 2016, J MANAGE INFORM SYST, V33, P456, DOI 10.1080/07421222.2016.1205907
   Zhao ZL, 2020, EPJ DATA SCI, V9, DOI 10.1140/epjds/s13688-020-00224-z
   Zhou X, 2018, FAKE NEWS
   Zhou X, 2019, COMPANION P 2019 WOR
   Zhou XY, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3395046
   Zuckerman M, 1981, ADV EXP SOC PSYCHOL, V14, P159
NR 63
TC 6
Z9 6
U1 8
U2 42
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40675
EP 40707
DI 10.1007/s11042-022-13129-y
EA MAY 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000794073400001
PM 35582207
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Meenpal, A
   Majumder, S
   Oruganti, M
AF Meenpal, Ankita
   Majumder, Saikat
   Oruganti, Madhu
TI Pixel value splitting based reversible data embedding scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Place value; Pixel splitting; Watermarking
ID WATERMARKING
AB Reversible data hiding/embedding (RDH) is a well known technique in the field of image information security system. A novel RDH scheme is proposed in this article using place values of the grayscale image pixel's intensity level. All pixels of the image is split into two halves based on their place values i.e., 100's & 10's combined and is referred as group-A set and remaining 1's place value kept into group-B set. Based on the methodology we propose a Pixel Value Splitting based RDH scheme and may be abbreviated as PVS-RDH scheme. Smooth regions of the image generally have similar group-A values and is the desired region for PVS-RDH scheme. In the proposed scheme, data hiding is performed in the adjacent pairs whose group-A values are same. Further, to increase visual fidelity of the embedded image with respect to original image, corresponding group-B values are also modified by using positive or negative offsets accordingly to reduce the difference created by modification in corresponding group-A sets. Experimental results and performance metrics are analyzed with recent state of art methods which proven that the proposed scheme performs better.
C1 [Meenpal, Ankita; Majumder, Saikat; Oruganti, Madhu] NIT, Dept ECE, Raipur 492010, Madhya Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur
RP Oruganti, M (corresponding author), NIT, Dept ECE, Raipur 492010, Madhya Pradesh, India.
EM moruganti.phd2019.ece@nitrr.ac.in
RI Oruganti, Madhu/KIJ-9331-2024
OI Oruganti, Madhu/0000-0002-6274-3606
CR Abdulla AA., 2014, LECT NOTES COMPUTER, DOI [10.1007/978-3-319-14054-4_10, DOI 10.1007/978-3-319-14054-4_10]
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Ahmed F, 2006, 1 TRANSDISCIPLINARY
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Barni M, 2002, INT GEOSCI REMOTE SE, P1447, DOI 10.1109/IGARSS.2002.1026144
   Chang CC, 2006, J SYST SOFTWARE, V79, P1754, DOI 10.1016/j.jss.2006.03.035
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   Cox IJ, 2008, MKS MULTIMED INFORM, P425, DOI 10.1016/B978-012372585-1.50015-2
   Gujjunoori S, 2013, P 4 INT C SIGNAL IMA, P2012
   Gujjunoori S, 2019, MULTIMED TOOLS APPL, V78, P25889, DOI 10.1007/s11042-019-07767-y
   He WG, 2018, INFORM SCIENCES, V467, P784, DOI 10.1016/j.ins.2018.04.088
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Jung KH, 2017, MULTIMED TOOLS APPL, V76, P13127, DOI 10.1007/s11042-016-3739-x
   Kim CR, 2018, ELECTRON LETT, V54, P626, DOI 10.1049/el.2017.4276
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Kumar R, 2020, INFORM SCIENCES, V512, P96, DOI 10.1016/j.ins.2019.09.062
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Liu ML, 2012, SIGNAL PROCESS, V92, P819, DOI 10.1016/j.sigpro.2011.09.028
   Meenpal T, 2015, INT C INFORM SYSTEMS
   Meenpal T, 2011, 2011 INT S ELECT SYS
   Meenpal T, 2018, SADHANA-ACAD P ENG S, V43, DOI 10.1007/s12046-017-0773-y
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   r0k.us, DATASET2
   Rajkumar R, 2019, CLUSTER COMPUT, V22, P12313, DOI 10.1007/s10586-017-1614-9
   sipi.usc.edu, DATASET1
   Thodi DM, 2004, IEEE IMAGE PROC, P1549
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang WQ, 2017, IET IMAGE PROCESS, V11, P1002, DOI 10.1049/iet-ipr.2017.0151
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng SW, 2008, CIRC SYST SIGNAL PR, V27, P229, DOI 10.1007/s00034-008-9021-3
   Yang Q, 2012, INFORM ENTROPY USED
   Zhang B, 2010, 2010 INT C MACHINE L, V6
NR 38
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40535
EP 40560
DI 10.1007/s11042-022-13031-7
EA MAY 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793646300001
DA 2024-07-18
ER

PT J
AU Singh, B
   Sharma, PK
   Huddedar, SA
   Sur, A
   Mitra, P
AF Singh, Brijesh
   Sharma, Prasen Kumar
   Huddedar, Shashank Anil
   Sur, Arijit
   Mitra, Pinaki
TI StegGAN: hiding image within image using conditional generative
   adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image-hiding; Steganography; Steganalysis; Conditional-GAN
AB Steganography is the art of hiding a secret message in another innocuous-looking image (or any digital media). Statistical imperceptibility is one of the major concerns for conventional steganography. In recent times, deep learning-based schemes have shown remarkable success in hiding an image within an image. However, a majority of these approaches suffer from the visual artifacts in the embedded and extracted images. In this paper, we have proposed a conditional generative adversarial network-based architecture for hiding an image within an image. The proposed method ensures the visual quality, statistical un-detectability as well as a noise-free extraction by incorporating the perceptual loss function and adversarial training. The proposed framework is tested on various datasets, and results have shown notable improvement (similar to 1 dB) over existing methods. An ablation study is presented at the end of this paper to demonstrate the contributions of the various modules of the proposed architecture. Code is available at https://github.com/brijeshiitg/StegGAN.
C1 [Singh, Brijesh; Sharma, Prasen Kumar; Huddedar, Shashank Anil; Sur, Arijit; Mitra, Pinaki] Indian Inst Technol Guwahati, Dept CSE, Gauhati, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Singh, B (corresponding author), Indian Inst Technol Guwahati, Dept CSE, Gauhati, India.
EM brijesh.singh@iitg.ac.in; kumar176101005@iitg.ac.in;
   huddedar@alumni.iitg.ac.in; arijit@iitg.ac.in; pinaki@iitg.ac.in
RI Mitra, Pinaki/AAD-6785-2020; Sur, Arijit/AAB-4216-2020
OI Singh, Brijesh/0000-0003-2661-6244
FU Ministry of Human Resource Development [BT/COE/34/SP28408/2018]
FX This work is supproted by Ministry of Human Resource Development, Govt.
   of India. We also acknowledge the Department of Biotechnology, Govt. of
   India for the financial support for the project BT/COE/34/SP28408/2018.
CR Abdulla AA, 2013, 2013 IEEE INT S MULT
   Abdulla AA, 2014, PROC SPIE, V9120, DOI 10.1117/12.2050518
   Abdulla AA, 2013, PROC SPIE, V8755, DOI 10.1117/12.2018994
   Agustsson E, 2017, IEEE C COMPUTER VISI
   [Anonymous], 2016, EUROPEAN C COMPUTER
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Baluja S, 2017, ADV NEUR IN, V30
   Baluja S, 2020, IEEE T PATTERN ANAL, V42, P1685, DOI 10.1109/TPAMI.2019.2901877
   Boehm B., 2014, ARXIV 14106656
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chhajed M, 2020, MULTIMED TOOLS APPL, P115
   Franzen Rich, Kodak lossless true color image suite
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Goljan M, 2014, 2014 IEEE INT WORKSH
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu S, 2017, 2017 IEEE INT C COMP
   Hayes J, 2017, ADV NEUR IN, V30
   He K, 2015, ARXIV 150201852
   Holub V., 2012, 2012 IEEE INT WORKSH
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kaur G, 2020, 2020 7 INT C SIGN PR
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kingma D. P., 2014, arXiv
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Lang XP, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P677, DOI 10.1109/CISP.2008.179
   Li C, 2016, IEEE INT SEMICONDUCT
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Mirza M., 2014, ARXIV 14111784
   NASH JF, 1950, P NATL ACAD SCI USA, V36, P48, DOI 10.1073/pnas.36.1.48
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Pevn T., 2010, INT WORKSHOP INFORM
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Qian YL, 2015, PROC SPIE, V9409, DOI 10.1117/12.2083479
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarkar T., 2014, ARXIV 14052684
   Sheikh HR, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P709
   Shi HC, 2018, LECT NOTES COMPUT SC, V10735, P534, DOI 10.1007/978-3-319-77380-3_51
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2021, IEEE T COMPUT SOC SY, V8, P599, DOI 10.1109/TCSS.2021.3052520
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P18815, DOI 10.1007/s11042-020-08745-5
   Tan SQ, 2021, IEEE T INF FOREN SEC, V16, P131, DOI 10.1109/TIFS.2020.3005304
   Vapnik VN., 1995, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-2440-0
   Volkhonskiy D, 2020, PROC SPIE, V11433, DOI 10.1117/12.2559429
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wang Z, 2003, THRITY 7 ASILOMAR C, V2
   Weber, 1997, 3151 USC SIPI
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Yang M, 2015, IEEE IMAGE PROC, P402, DOI 10.1109/ICIP.2015.7350829
   Zhang KA., 2019, ARXIV 190103892
   Zhang R, 2019, MULTIMED TOOLS APPL, V78, P8559, DOI 10.1007/s11042-018-6951-z
   Zhu J., 2018, European Conference on Computer Vision (ECCV)
NR 61
TC 3
Z9 3
U1 6
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40511
EP 40533
DI 10.1007/s11042-022-13172-9
EA MAY 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000793006900001
DA 2024-07-18
ER

PT J
AU Gupta, P
   Dixit, M
AF Gupta, Priyanka
   Dixit, Manish
TI Image-based crack detection approaches: a comprehensive survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Image processing; Structure health monitoring; Crack
   detection; Machine learning; Deep convolutional neural network
ID CONCRETE; ALGORITHM; SYSTEM
AB Automatic crack detection is a challenging task that has been researched for decades due to the complex civil structures. Cracks on any structure are early signs of the deterioration of the object's surface. Therefore, detection and regular maintenance of cracks are necessary tasks as the propagation of cracks results in severe damage. Manual inspection is based on the expert's previous knowledge, and it can only be done in reachable human areas. On the other hand, autonomous detection of cracks by using image-based techniques may reduce human errors, less time-consuming, and more economical than human-based inspection for real-time crack detection. Since movable cameras can capture images for non-reachable areas, several techniques are available for crack detection. Several techniques are available for crack detection; however, image-based crack detection techniques have been analyzed in this survey. A detailed study is carried out to define the research problems and advancements in this area. This article analyses the pure image processing techniques and learning-based techniques based on the objectives, the methods, level of efficiency, level of errors, and type of crack image dataset. Besides the applications, limitations and other factors are explained for each technique. Moreover, the presented analysis shows the multiple problems related to cracks that could help the researcher perform further research.
C1 [Gupta, Priyanka; Dixit, Manish] MITS, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
C3 Madhav Institute of Technology & Science
RP Gupta, P (corresponding author), MITS, Dept Comp Sci & Engn, Gwalior, Madhya Pradesh, India.
EM guptapriya071@gmail.com; dixitmits@mitsgwalior.in
RI Dixit, Dr Manish/GPK-5830-2022; gupta, Priyanka/HNP-0476-2023
OI Dixit, Dr Manish/0000-0003-2589-6010; 
CR Aggarwal A, 2021, MULTIMED TOOLS APPL, V80, P1289, DOI 10.1007/s11042-020-09520-2
   Ai Q, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19194278
   Ali L, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051688
   [Anonymous], 2020, Road Traffic Injuries
   [Anonymous], 2021, TUNNEL COLLAPSE INJU
   Ansari MA, 2021, MULTIMED TOOLS APPL, V80, P8759, DOI 10.1007/s11042-020-10103-4
   Attard L, 2019, INT SYMP IMAGE SIG, P152, DOI 10.1109/ISPA.2019.8868619
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bang S, 2019, COMPUT-AIDED CIV INF, V34, P713, DOI 10.1111/mice.12440
   Calar FO., 2019, CONCRETE CRACK IMAGE, P2
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chaiyasarn K., 2018, INT S AUT ROB CONSTR, P118
   Chaiyasarn K, 2018, INT J GEOMATE, V15, P240, DOI 10.21660/2018.51.35376
   Chen FC, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01098-x
   Chen XL, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21051581
   Cho H, 2018, IEEE ACCESS, V6, P60100, DOI 10.1109/ACCESS.2018.2875889
   Choi W, 2020, IEEE T IND ELECTRON, V67, P8016, DOI 10.1109/TIE.2019.2945265
   Choudhary GK, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P404, DOI 10.1109/ICACI.2012.6463195
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dhital D, 2012, EXP MECH, V52, P1111, DOI 10.1007/s11340-011-9567-z
   Ding, 2018, GEOSHANGHAI INT C, DOI [10.1007/978-981-13-0017-2, DOI 10.1007/978-981-13-0017-2]
   Dorafshan S, 2018, DATA BRIEF, V21, P1664, DOI 10.1016/j.dib.2018.11.015
   Eisenbach M, 2017, IEEE IJCNN, P2039, DOI 10.1109/IJCNN.2017.7966101
   Feng CC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072069
   Garcia A, 2017, APPR DIGIT GAME STUD, V5, P1
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong Qimin, 2018, 2018 IEEE 4 INF TECH, DOI [10.1109/ITOEC.2018.8740390, DOI 10.1109/ITOEC.2018.8740390]
   Hao M, 2017, CYBERN INF TECHNOL, V17, P119, DOI 10.1515/cait-2017-0021
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hu GX, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5573590
   Huang HW, 2018, TUNN UNDERGR SP TECH, V77, P166, DOI 10.1016/j.tust.2018.04.002
   Kalfarisi R, 2020, J COMPUT CIVIL ENG, V34, DOI 10.1061/(ASCE)CP.1943-5487.0000890
   Kim B, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10228008
   Kim JJ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10228105
   Kim Kwang-Baek, 2010, [Journal of the Korea Institute Of Information and Communication Engineering, 한국정보통신학회논문지], V14, P1353
   Krizhevsky, 2012, P 2012 INT C ADV NEU, DOI [10.1129/9.205, DOI 10.1129/9.205]
   Kumare, 2019, EFFICIENT CONTRAST E, P181, DOI [10.1007/978-981-13-0589-4_17, DOI 10.1007/978-981-13-0589-4_17]
   Kylberg G, External report (Blue series, V35
   Laghrib A, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0075-4
   Lei Z., 2016, 2016 IEEE international conference on image processing (ICIP), P3708, DOI DOI 10.1109/ICIP.2016.7533052
   Li G, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030717
   Li L, 2018, CONSTR BUILD MATER, V162, P345, DOI 10.1016/j.conbuildmat.2017.12.010
   Li SY, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/6520620
   Li YD, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183781
   Liu YH, 2019, NEUROCOMPUTING, V338, P139, DOI 10.1016/j.neucom.2019.01.036
   Liu ZW, 2002, PROC SPIE, V4664, P145, DOI 10.1117/12.460191
   Luo QJ, 2019, CONSTR BUILD MATER, V204, P244, DOI 10.1016/j.conbuildmat.2019.01.150
   Masood A, 2020, IEEE T IND INFORM, V16, P7791, DOI 10.1109/TII.2020.2972918
   Medina R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17071670
   Mehndi, 2014, INT J TECHNOL RES AP, P2933
   Mohan A, 2018, ALEX ENG J, V57, P787, DOI 10.1016/j.aej.2017.01.020
   Hoang ND, 2018, ADV CIV ENG, V2018, DOI 10.1155/2018/7163580
   Niemeier, 2008, P 13 FIG S DEF MEAS, V12, DOI [10.1002/BATE.200710036, DOI 10.1002/BATE.200710036]
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouyang A., 2010, INT C COMPUTER COMPU, DOI DOI 10.1007/978-3-642-18369-0_42
   Ozgenel CF, 2018, IS P INT S AUT ROB C, V35, P1, DOI DOI 10.22260/ISARC2018/0094
   Park SE, 2020, CONSTR BUILD MATER, V252, DOI 10.1016/j.conbuildmat.2020.119096
   Patra S, 2021, MULTIMED TOOLS APPL, V80, P25171, DOI 10.1007/s11042-021-10874-4
   Pauly L., 2017, P 34 ISARC, V34, P479
   Pingrang Wang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2530, DOI 10.1109/CISP.2010.5647496
   Prasanna P, 2016, IEEE T AUTOM SCI ENG, V13, P591, DOI 10.1109/TASE.2014.2354314
   Prema KirubakaranA., 2018, Knowledge Computing and its Applications: Knowledge Computing in Specific Domains: Volume, VII, P29, DOI DOI 10.1007/978-981-10-8258-0_2
   Qu Z, 2016, IMAGING SCI J, V64, P119, DOI 10.1080/13682199.2016.1146816
   Qu Z, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0201109
   Qu Z, 2015, IEEJ T ELECTR ELECTR, V10, P214, DOI 10.1002/tee.22056
   Rao KA, 2021, SEP SCI TECHNOL, V56, P541, DOI 10.1080/01496395.2020.1718705
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren YP, 2020, CONSTR BUILD MATER, V234, DOI 10.1016/j.conbuildmat.2019.117367
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shahrokhinasab E., 2020, Journal of Soft Computing in Civil Engineering, V4, P127
   Sharma M., 2018, Sci. Technol. Asia, V23, P19
   Shi Y, 2016, IEEE T INTELL TRANSP, V17, P3434, DOI 10.1109/TITS.2016.2552248
   Simler C, 2019, PROC SPIE, V11144, DOI 10.1117/12.2531951
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Q, 2019, IEEE ACCESS, V7, P64186, DOI 10.1109/ACCESS.2019.2916330
   Sridevi M, 2012, PROC TECH, V1, P548, DOI 10.1016/j.protcy.2012.10.066
   Sundararajan D., 2017, Digital Image Processing: A Signal Processing and Algorithmic Approach
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Talab AMA, 2016, OPTIK, V127, P1030, DOI 10.1016/j.ijleo.2015.09.147
   Teng S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020813
   Wang XL, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P917, DOI 10.1109/ICTIS.2017.8047878
   Wang ZR, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174849
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yahya MM., 2020, CIVIL ENG RES J, V10, DOI 10.19080/CERJ.2020.10.555790
   Yamaguchi T, 2010, MACH VISION APPL, V21, P797, DOI 10.1007/s00138-009-0189-8
   Yang C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11062868
   Yang XC, 2018, COMPUT-AIDED CIV INF, V33, P1090, DOI 10.1111/mice.12412
   Yu SN, 2007, AUTOMAT CONSTR, V16, P255, DOI 10.1016/j.autcon.2006.05.003
   Yusof N. A. M., 2019, Journal of Physics: Conference Series, V1349, DOI 10.1088/1742-6596/1349/1/012020
   Zalama E, 2014, COMPUT-AIDED CIV INF, V29, P342, DOI 10.1111/mice.12042
   Zhang QY, 2021, ENGINEERING-PRC, V7, P1786, DOI 10.1016/j.eng.2020.07.026
   Zhang WY, 2014, SENSORS-BASEL, V14, P19307, DOI 10.3390/s141019307
   Zou Q, 2012, PATTERN RECOGN LETT, V33, P227, DOI 10.1016/j.patrec.2011.11.004
NR 97
TC 14
Z9 14
U1 3
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 40181
EP 40229
DI 10.1007/s11042-022-13152-z
EA MAY 2022
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000791638100005
DA 2024-07-18
ER

PT J
AU García, RG
   Rodríguez, SJ
   Martínez, BB
   Gracidas, CH
   Torres, RM
AF Gallardo Garcia, Rafael
   Jarquin Rodriguez, Sofia
   Beltran Martinez, Beatriz
   Hernandez Gracidas, Carlos
   Martinez Torres, Rodolfo
TI Efficient deep learning architectures for fast identification of
   bacterial strains in resource-constrained devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bacterial identification; Data augmentation; Deep learning; DIBaS
   dataset; MobileNets
ID AUTOMATIC IDENTIFICATION; CLASSIFICATION; SYSTEM
AB This work presents twelve fine-tuned deep learning architectures to solve the bacterial classification problem over the digital image of bacterial species dataset. The base architectures were mainly published as mobile or efficient solutions to the ImageNet challenge, and all experiments presented in this work consisted in making several modifications to the original designs, in order to make them able to solve the bacterial classification problem by using fine-tuning and transfer learning techniques. This work also proposes a novel data augmentation technique for this dataset, which is based on the idea of artificial zooming, strongly increasing the performance of every tested architecture, even doubling it in some cases. In order to get robust and complete evaluations, all experiments were performed with 10-fold cross-validation and evaluated with five different metrics: top-1 and top-5 accuracy, precision, recall, and F1 score. This paper presents a complete comparison of the twelve different architectures, cross-validated with the original and the augmented version of the dataset, the results are also compared with several literature methods. Overall, eight of the eleven architectures surpassed the 0.95 score in top-1 accuracy with our data augmentation method, being 0.9738 the highest top-1 accuracy. The impact of the data augmentation technique is reported with relative improvement scores.
C1 [Gallardo Garcia, Rafael; Beltran Martinez, Beatriz; Martinez Torres, Rodolfo] Benemerita Univ Autonoma Puebla, Language & Knowledge Engn Lab, Puebla De Zaragoza, Mexico.
   [Jarquin Rodriguez, Sofia] Benemerita Univ Autonoma Puebla, Fac Chem Sci, Puebla De Zaragoza, Mexico.
   [Hernandez Gracidas, Carlos] Benemerita Univ Autonoma Puebla, CONACYT, Fac Phys & Math Sci, Puebla De Zaragoza, Mexico.
C3 Benemerita Universidad Autonoma de Puebla; Benemerita Universidad
   Autonoma de Puebla; Benemerita Universidad Autonoma de Puebla
RP García, RG (corresponding author), Benemerita Univ Autonoma Puebla, Language & Knowledge Engn Lab, Puebla De Zaragoza, Mexico.
EM rafael.gallardo@alumno.buap.mx; ana.jarquin@alumno.buap.mx;
   bbeltran@cs.buap.mx; cahernandezgr@conacyt.mx; beetho@cs.buap.mx
RI Beltrán Martínez, Beatriz/HPD-5274-2023
OI Beltrán Martínez, Beatriz/0000-0003-4528-4222; Hernandez-Gracidas,
   Carlos/0000-0003-0267-6306; Gallardo Garcia, Rafael/0000-0001-5085-3501
CR Abd Elaziz M, 2020, APPL SOFT COMPUT, V95, DOI 10.1016/j.asoc.2020.106504
   Ahmed WM, 2013, IEEE J BIOMED HEALTH, V17, P232, DOI 10.1109/TITB.2012.2222654
   [Anonymous], 2018, PROC IEEE C COMPUT V
   Aslam B, 2017, J CHROMATOGR SCI, V55, P182, DOI 10.1093/chromsci/bmw167
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ferri C, 2009, PATTERN RECOGN LETT, V30, P27, DOI 10.1016/j.patrec.2008.08.010
   Forero MG, 2006, J MICROSC-OXFORD, V223, P120, DOI 10.1111/j.1365-2818.2006.01610.x
   Franco-Duarte R, 2019, MICROORGANISMS, V7, DOI 10.3390/microorganisms7050130
   Gallardo-Garca R, 2020, APLICACIONES CIENTFI, P6778
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Holmberg M, 1998, BIOTECHNOL TECH, V12, P319, DOI 10.1023/A:1008862617082
   Howard A, 2019, P IEEE INT C COMP VI
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   JENKINS SA, 1991, J APPL BACTERIOL, V71, P360, DOI 10.1111/j.1365-2672.1991.tb03801.x
   Khalifa Nour Eldeen Mahmoud, 2019, International Journal of Reasoning-based Intelligent Systems, V11, P256
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu J, 2001, MICROB ECOL, V41, P173, DOI 10.1007/s002480000004
   Loshchilov Ilya, 2017, ARXIV171105101
   Ma, 2018, P EUROPEAN C COMPUTE
   MicrobiologySociety, 2021, MICR DIS
   Mishra M., 2016, Microscopy Res., V4, P1, DOI DOI 10.4236/MR.2016.41001
   Nasip ÖF, 2018, 2018 2ND INTERNATIONAL SYMPOSIUM ON MULTIDISCIPLINARY STUDIES AND INNOVATIVE TECHNOLOGIES (ISMSIT), P684
   Nobile CJ, 2015, ANNU REV MICROBIOL, V69, P71, DOI 10.1146/annurev-micro-091014-104330
   Paszke A, 2019, ADV NEUR IN, V32
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Perronnin F., 2007, 2007 IEEE C COMPUTER, P18
   Satoto BD, 2020, 2020 INT C COMP ENG, P7075
   Sauer S, 2010, NAT REV MICROBIOL, V8, P74, DOI 10.1038/nrmicro2243
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singhal N, 2015, FRONT MICROBIOL, V6, DOI 10.3389/fmicb.2015.00791
   Sommer C, 2013, J CELL SCI, V126, P5529, DOI 10.1242/jcs.123604
   Spratt D.A., 2004, Endodontic Topics, V9, P5, DOI [DOI 10.1111/J.1601-1546.2004.00106.X, DOI 10.1371/journal.pone.0030600]
   Talo M., 2019, arXiv preprint arXiv
   Tan M., 2019, ARXIV190709595
   Trattner S, 2004, IEEE T MED IMAGING, V23, P807, DOI 10.1109/TMI.2004.827481
   Váradi L, 2017, CHEM SOC REV, V46, P4818, DOI 10.1039/c6cs00693k
   Voulodimos A, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7068349
   Zielinski B, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184554
NR 39
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 28
BP 39915
EP 39944
DI 10.1007/s11042-022-13022-8
EA MAY 2022
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5O8FJ
UT WOS:000790645700003
DA 2024-07-18
ER

PT J
AU Sadhya, D
   Rathore, SS
   Rajput, AS
   Anand, A
AF Sadhya, Debanjan
   Rathore, Santosh Singh
   Rajput, Amitesh Singh
   Anand, Abhinav
TI Securing multimedia videos using space-filling curves
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; diffusion; Space Filling Curves; encryption
ID CHAOS-BASED IMAGE; SELECTIVE ENCRYPTION; ALGORITHM
AB Securing online multimedia content has become a significant concern in this digital era. Nowadays, several organizations provide premium video content for skill development, academics and entertainment. The usage of Space-Filling Curves (SFC) for video and image encryption was initiated in the late 20th century. Although it is a promising approach for enforcing multimedia security, a cryptanalysis on SFCs was performed, which rendered the technique useless. In this paper, we have presented two strategies for countering the chosen plaintext-based attack. In the first method, the notion of diffusion is introduced in video frames by swapping two colour channels. Alternatively, in the second method, the frame sequences are scrambled twice to overcome the constraint of their restricted movements. Finally, the output pixel intensity values are modified to model a uniform distribution. Our empirical results demonstrate the superiority of the presented work over state-of-the-art approaches involving multimedia security. We have also evaluated the security of our approaches through standard measures like entropy, histogram analysis, and differential analysis. Hence, the presented work provides a holistic framework for securely distributing multimedia content over both online and offline platforms.
C1 [Sadhya, Debanjan; Rathore, Santosh Singh; Anand, Abhinav] Atal Bihari Vajpayee Indian Inst Informat Technol, Gwalior 474015, Madhya Pradesh, India.
   [Rajput, Amitesh Singh] Birla Inst Technol & Sci, Pilani 333031, Rajasthan, India.
C3 ABV-Indian Institute of Information Technology & Management, Gwalior;
   Birla Institute of Technology & Science Pilani (BITS Pilani)
RP Sadhya, D (corresponding author), Atal Bihari Vajpayee Indian Inst Informat Technol, Gwalior 474015, Madhya Pradesh, India.
EM debanjan.sadhya@gmail.com
RI Anand, Abhinav/GPF-6698-2022
OI Rathore, Santosh Singh/0000-0003-2087-1666
CR BERTILSSON M, 1990, LECT NOTES COMPUT SC, V434, P403
   Bhatnagar G, 2012, COMPUT J, V55, P667, DOI 10.1093/comjnl/bxs009
   Bhatnagar G, 2012, DIGIT SIGNAL PROCESS, V22, P648, DOI 10.1016/j.dsp.2012.02.005
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chiaraluce F, 2002, IEEE T CONSUM ELECTR, V48, P838, DOI 10.1109/TCE.2003.1196410
   Gaurav A, 2022, INT J SOFTW SCI COMP, V14, DOI 10.4018/IJSSCI.285593
   Gerhardt C, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Goyal D., 2014, INT J INF SECUR, V3, P11
   Gupta BB, 2019, J AMB INTEL HUM COMP, V10, P2907, DOI 10.1007/s12652-018-0919-8
   HASEGAWA HH, 1992, PHYS REV A, V46, P7401, DOI 10.1103/PhysRevA.46.7401
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hilbert D, 1935, Dritter Band: Analysis Grundlagen der Mathematik Physik Verschiedenes: Nebst Einer Lebensgeschichte, P1, DOI 10.1007/978-3-662-38452-7_1
   Kunte, 2019, SELECTIVE VIDEO ENCR, P603, DOI [10.1007/978-981-10-8797-4-61, DOI 10.1007/978-981-10-8797-4-61]
   Li JJ, 2018, MULTIMED TOOLS APPL, V77, P12837, DOI 10.1007/s11042-017-4916-2
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Massoudi A, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1683
   MATIAS Y, 1988, LECT NOTES COMPUT SC, V293, P398
   Mohamed A.H., 2016, J Diabetic Foot Complications, V8, P31
   Mohan A, 2021, COMPUT ELECTR ENG, V95, DOI 10.1016/j.compeleceng.2021.107385
   Mukherjee I, 2018, MULTIMED TOOLS APPL, V77, P5281, DOI 10.1007/s11042-017-4431-5
   Murali P, 2019, MULTIMED TOOLS APPL, V78, P2135, DOI 10.1007/s11042-018-6234-8
   Patro KAK, 2019, J INF SECUR APPL, V46, P23, DOI 10.1016/j.jisa.2019.02.006
   Peano G., 1890, Math. Ann., V36, P157, DOI [DOI 10.1007/BF01199438, 10.1007/BF01199438]
   Peng F, 2017, MULTIMED TOOLS APPL, V76, P3235, DOI 10.1007/s11042-016-3710-x
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Sagan H., 1994, HILBERTS SPACE FILLI, P9, DOI 10.1007/978-1-4612-0871-6
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Suresh V, 2012, DEFENCE SCI J, V62, P46, DOI 10.14429/dsj.62.1441
   Tabash FK, 2019, J INF SECUR APPL, V45, P20, DOI 10.1016/j.jisa.2019.01.001
   THUM C, 1984, OPT ACTA, V31, P203, DOI 10.1080/713821475
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wang XY, 2014, NONLINEAR DYNAM, V76, P1943, DOI 10.1007/s11071-014-1259-7
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yan WQ, 2016, LECT NOTES COMPUT SC, V9431, P775, DOI 10.1007/978-3-319-29451-3_61
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Zhang XC, 2019, IEEE ACCESS, V7, P74734, DOI 10.1109/ACCESS.2019.2921309
   Zhou ZL, 2023, IET IMAGE PROCESS, V17, P3660, DOI 10.1049/ipr2.12143
NR 41
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 27
BP 38685
EP 38704
DI 10.1007/s11042-022-13066-w
EA APR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 5K7JE
UT WOS:000787666500008
DA 2024-07-18
ER

PT J
AU Lu, SL
   Hu, XH
   Wang, CY
   Chen, L
   Han, SL
   Han, YJ
AF Lu, Shilin
   Hu, Xinghong
   Wang, Chengyou
   Chen, Lu
   Han, Shulu
   Han, Yuejia
TI Copy-move image forgery detection based on evolving circular domains
   coverage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Copy-move forgery detection (CMFD); Scale invariant
   feature transform (SIFT); Speed-up robust feature (SURF); Evolving
   circular domains coverage (ECDC)
ID OFFLINE SIGNATURE VERIFICATION; FEATURES; SURF
AB The aim of this paper is to improve the accuracy of copy-move forgery detection (CMFD) in image forensics by proposing a novel scheme and the main contribution is evolving circular domains coverage (ECDC) algorithm. The proposed scheme integrates both block-based and keypoint-based forgery detection methods. Firstly, the speed-up robust feature (SURF) in log-polar space and the scale invariant feature transform (SIFT) are extracted from an entire image. Secondly, generalized 2 nearest neighbor (g2NN) is employed to get massive matched pairs. Then, random sample consensus (RANSAC) algorithm is employed to filter out mismatched pairs, thus allowing rough localization of counterfeit areas. To present these forgery areas more accurately, we propose the efficient and accurate ECDC algorithm to present them. This algorithm can find satisfactory threshold areas by extracting block features from jointly evolving circular domains, which are centered on matched pairs. Finally, morphological operation is applied to refine the detected forgery areas. Experimental results indicate that the proposed CMFD scheme can achieve better detection performance under various attacks compared with other state-of-the-art CMFD schemes.
C1 [Lu, Shilin; Hu, Xinghong; Wang, Chengyou; Chen, Lu; Han, Shulu; Han, Yuejia] Shandong Univ, Sch Mech Elect & Informat Engn, Weihai 264209, Peoples R China.
   [Lu, Shilin] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Shandong University; Nanyang Technological University
RP Wang, CY (corresponding author), Shandong Univ, Sch Mech Elect & Informat Engn, Weihai 264209, Peoples R China.
EM wangchengyou@sdu.edu.cn
RI Wang, Chengyou/P-4504-2016
OI Wang, Chengyou/0000-0002-0901-2492; Lu, Shilin/0000-0003-2848-0619
FU Shandong Provincial Natural Science Foundation, China [ZR2021MF060,
   ZR2017MF020]; Education and Teaching Reform Research Project of Shandong
   University, Weihai [Y2021054]; National Natural Science Foundation of
   China [61702303]; Science and Technology Development Plan Project of
   Weihai Municipality in 2020; 14th Student Research Training Program
   (SRTP) at Shandong University [A19167]
FX This work was supported in part by the Shandong Provincial Natural
   Science Foundation, China (Nos. ZR2021MF060, ZR2017MF020), in part by
   the Education and Teaching Reform Research Project of Shandong
   University, Weihai (No. Y2021054), in part by the National Natural
   Science Foundation of China (No. 61702303), in part by the Science and
   Technology Development Plan Project of Weihai Municipality in 2020, and
   in part by the 14th Student Research Training Program (SRTP) at Shandong
   University, Weihai (No. A19167).
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chen HP, 2020, IEEE ACCESS, V8, P36863, DOI 10.1109/ACCESS.2020.2974804
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Kaura WCN, 2017, P INT C INN INF EMB, P1
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Okawa M, 2018, PATTERN RECOGN LETT, V113, P75, DOI 10.1016/j.patrec.2018.05.019
   Okawa M, 2018, PATTERN RECOGN, V79, P480, DOI 10.1016/j.patcog.2018.02.027
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pandey RC, 2014, P INT C IND INF SYST
   Park JY, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12040492
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Pun CM, 2018, INFORM SCIENCES, V463, P33, DOI 10.1016/j.ins.2018.06.040
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Sharma S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P795, DOI 10.1109/CICT.2015.88
   Shehab A, 2018, IEEE ACCESS, V6, P10269, DOI 10.1109/ACCESS.2018.2799240
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Tao T, 2017, PROC SPIE, V10225, DOI 10.1117/12.2267122
   Wang CY, 2019, IEEE ACCESS, V7, P170032, DOI 10.1109/ACCESS.2019.2955308
   Wang CY, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8040548
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   Wang XF, 2012, J VIS COMMUN IMAGE R, V23, P782, DOI 10.1016/j.jvcir.2012.03.005
   Wen BH, 2016, IEEE IMAGE PROC, P161, DOI 10.1109/ICIP.2016.7532339
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zheng JB, 2016, MULTIDIM SYST SIGN P, V27, P989, DOI 10.1007/s11045-016-0416-1
NR 45
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2022
VL 81
IS 26
BP 37847
EP 37872
DI 10.1007/s11042-022-12755-w
EA APR 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4Z1TS
UT WOS:000784679100003
OA hybrid, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Hossain, MA
   Hossain, MI
   Hossain, MD
   Huh, EN
AF Hossain, Md Alamgir
   Hossain, Md Imtiaz
   Hossain, Md Delowar
   Huh, Eui-Nam
TI DFC-D: A dynamic weight-based multiple features combination for
   real-time moving object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Moving object detection; Classification; Change detection; Foreground
   segmentation; Background subtraction
ID BACKGROUND SUBTRACTION; TRACKING; PIXEL
AB Real-time moving object detection is an emerging method in Industry 5.0, that is applied in video surveillance, video coding, human-computer interaction, IoT, robotics, smart home, smart environment, edge and fog computing, cloud computing, and so on. One of the main issues is accurate moving object detection in real-time in a video with challenging background scenes. Numerous existing approaches used multiple features simultaneously to address the problem but did not consider any adaptive/dynamic weight factor to combine these feature spaces. Being inspired by these observations, we propose a background subtraction-based real-time moving object detection method, called DFC-D. This proposal determines an adaptive/dynamic weight factor to provide a weighted fusion of non-smoothing color/gray intensity and non-smoothing gradient magnitude. Moreover, the color-gradient background difference and segmentation noise are employed to modify thresholds and background samples. Our proposed solution achieves the best trade-off between detection accuracy and algorithmic complexity on the benchmark datasets while comparing with the state-of-the-art approaches.
C1 [Hossain, Md Alamgir; Hossain, Md Imtiaz; Hossain, Md Delowar; Huh, Eui-Nam] Kyung Hee Univ, Dept Comp Sci & Engn, Global Campus, Yongin, South Korea.
C3 Kyung Hee University
RP Huh, EN (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Global Campus, Yongin, South Korea.
EM alamgir@khu.ac.kr; hossain.imtiaz@khu.ac.kr; delowar@khu.ac.kr;
   johnhuh@khu.ac.kr
RI Hossain, Md Imtiaz/ADF-5787-2022; Hong, Choong Seon/ABF-5527-2020
OI Hossain, Md Imtiaz/0000-0003-1085-2461; HOSSAIN, MD
   ALAMGIR/0000-0002-6865-6650; Huh, Eui-Nam/0000-0003-0184-6975; Hossain,
   Md. Delowar/0000-0002-6080-9720
FU MSIT (Ministry of Science and ICT), Korea, under the Grand Information
   Technology Research Center support program [IITP-2021-2015-0-00742,
   20210-00818]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the Grand Information Technology Research Center support
   program(IITP-2021-2015-0-00742) supervised by the IITP (Institute for
   Information & communications Technology Planning & Evaluation) and
   Project No.20210-00818, Machine Learning Based Low Bandwidth Image
   Communication Edge Computing System for Proactive Anomaly Detection on
   Smart Plant Environment.
CR [Anonymous], 2021, OPENCVORG
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Berjón D, 2018, PATTERN RECOGN, V74, P156, DOI 10.1016/j.patcog.2017.09.009
   Bilodeau GA, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P106, DOI 10.1109/CRV.2013.29
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   Chen ATY, 2019, J REAL-TIME IMAGE PR, V16, P2319, DOI 10.1007/s11554-018-0750-7
   Chen YQ, 2020, IEEE T IND ELECTRON, V67, P601, DOI 10.1109/TIE.2019.2893824
   Cuevas C, 2016, COMPUT VIS IMAGE UND, V152, P103, DOI 10.1016/j.cviu.2016.08.005
   Cuevas C, 2013, IMAGE VISION COMPUT, V31, P616, DOI 10.1016/j.imavis.2013.06.003
   De Gregorio M, 2014, IEEE COMPUT SOC CONF, P409, DOI 10.1109/CVPRW.2014.66
   Farcas D, 2012, MACH VISION APPL, V23, P1083, DOI 10.1007/s00138-012-0421-9
   Garcia-Garcia B, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100204
   Goyette N., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), DOI 10.1109/CVPRW.2012.6238919
   Guo LL, 2016, IEEE COMPUT SOC CONF, P1159, DOI 10.1109/CVPRW.2016.148
   Haines TSF, 2014, IEEE T PATTERN ANAL, V36, P670, DOI 10.1109/TPAMI.2013.239
   Hofmann Martin., 2012, 2012 IEEE COMPUTER S, P38, DOI DOI 10.1109/CVPRW.2012.6238925
   Hossain MA, 2020, FAST D NONSMOOTHING, V8, P756, DOI [10.1109/ACCESS.2020.3030108, DOI 10.1109/ACCESS.2020.3030108]
   Hossain MA, 2021, IET IMAGE PROCESS, V15, P350, DOI 10.1049/ipr2.12026
   Hu L, 2018, IEEE INTERNET THINGS, V5, P747, DOI 10.1109/JIOT.2017.2705560
   Kim J, 2015, IEEE I CONF COMP VIS, P3307, DOI 10.1109/ICCV.2015.378
   Laugraud B, 2015, LECT NOTES COMPUT SC, V9281, P477, DOI 10.1007/978-3-319-23222-5_58
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Liu DF, 2020, NEUROCOMPUTING, V409, P1, DOI 10.1016/j.neucom.2020.05.027
   Liu S, 2021, IEEE T MULTIMEDIA, V23, P2188, DOI 10.1109/TMM.2021.3065580
   Liu S, 2021, NEUROCOMPUTING, V458, P615, DOI 10.1016/j.neucom.2019.12.143
   Liu S, 2021, IEEE T FUZZY SYST, V29, P90, DOI 10.1109/TFUZZ.2020.3006520
   Liu Y, 2019, PROC SPIE, V10989, DOI 10.1117/12.2516023
   Mandal M, 2021, IEEE T IMAGE PROCESS, V30, P546, DOI 10.1109/TIP.2020.3037472
   Mondejar-Guerra V., 2019, British Machine Vision Conference, P266
   Panda DK, 2016, IEEE SIGNAL PROC LET, V23, P45, DOI 10.1109/LSP.2015.2498839
   Patil PW, 2019, IEEE T INTELL TRANSP, V20, P4066, DOI 10.1109/TITS.2018.2880096
   Ramirez-Quintana JA, 2018, APPL INTELL, V48, P4976, DOI 10.1007/s10489-018-1256-5
   Rodriguez P, 2016, J MATH IMAGING VIS, V55, P1, DOI 10.1007/s10851-015-0610-z
   Sajid H, 2017, IEEE T IMAGE PROCESS, V26, P3249, DOI 10.1109/TIP.2017.2695882
   Sedky M, 2014, IEEE COMPUT SOC CONF, P405, DOI 10.1109/CVPRW.2014.65
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   St-Charles PL, 2014, IEEE WINT CONF APPL, P509, DOI 10.1109/WACV.2014.6836059
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tiefenbacher P, 2014, IEEE IMAGE PROC, P3282, DOI 10.1109/ICIP.2014.7025664
   Van Droogenbroeck M., 2012, 2012 IEEE COMP SOC C, P32
   Vaswani N, 2018, IEEE SIGNAL PROC MAG, V35, P32, DOI 10.1109/MSP.2018.2826566
   Wang JY, 2023, INTERACT LEARN ENVIR, V31, P836, DOI [10.1080/10494820.2020.1813178, 10.1109/TASE.2020.2976560]
   Wang KF, 2018, IEEE ACCESS, V6, P15505, DOI 10.1109/ACCESS.2018.2812880
   Wang Q, 2021, IEEE T GEOSCI REMOTE, V59, P5028, DOI 10.1109/TGRS.2020.3011002
   Wang R, 2014, IEEE COMPUT SOC CONF, P420, DOI 10.1109/CVPRW.2014.68
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wei H, 2018, INT J ADV ROBOT SYST, V15, DOI 10.1177/1729881418783633
   Zhang YZ, 2012, PROCEDIA ENGINEER, V29, P2705, DOI 10.1016/j.proeng.2012.01.376
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 53
TC 4
Z9 4
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 32549
EP 32580
DI 10.1007/s11042-022-12446-6
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000783454600004
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, WK
   Lu, SL
   Liu, BH
   Chen, M
   Li, G
   Qian, TT
AF Chen, Wenkang
   Lu, Shenglian
   Liu, Binghao
   Chen, Ming
   Li, Guo
   Qian, Tingting
TI CitrusYOLO: A Algorithm for Citrus Detection under Orchard Environment
   Based on YOLOv4
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fruit recognition; Improved YOLOv4; Deep learning; Real-time detection
ID FRUIT DETECTION; LOCALIZATION; VISION
AB Achieving rapid and accurate detection of tree fruits under natural environments is essential for many precision agriculture application (such as harvesting robots and yield estimation). A real-time citrus recognition method was proposed in this paper by improving the latest YOLOv4 (You Only Look Once version 4) detector for using in orchard environments. The Canopy algorithm and the K-Means + + algorithm were used to automatically select the number and size of prior frames corresponding to the image dataset. Then, an attention mechanism module is added in front of the output layer of each feature of different scales, and a depthwise separable convolution module is added before the upsampling of the network neck to better detect clementines in complex backgrounds. Finally, the network is pruned using the scientific control-based neural network pruning (SCOP) algorithm, and the parameters of the pruned model were fine-tuned to restore some recognition accuracy. Five common used deep learning algorithms including the Faster R-CNN, SSD, YOLOv3, YOLOv4 and Detectron2 were compared to verify the effectiveness of the proposed method. The experimental results showed that our improved YOLOv4 detector works well for detecting different growth periods of citrus in natural orchard environment. The average accuracy increase from 92.89 to 96.15%, the detection time for each image is 0.06s, both are superior the above five algorithms. While the model size was down from 250 MB to 187 MB. This would promise the proposed method being suitable for orchard yield estimation and the development of fruit harvesting robots.
C1 [Chen, Wenkang; Lu, Shenglian; Chen, Ming; Li, Guo] Guangxi Normal Univ, Coll Comp Sci & Engn, Guilin 541004, Peoples R China.
   [Lu, Shenglian; Chen, Ming] Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Liu, Binghao] Guangxi Acad Specialty Crops, Guangxi Citrus Breeding & Cultivat Engn Technol C, Guilin 541004, Peoples R China.
   [Qian, Tingting] Shanghai Acad Agr Sci, Agr Informat Inst Sci & Technol, Shanghai 201403, Peoples R China.
C3 Guangxi Normal University; Shanghai Academy of Agricultural Sciences
RP Lu, SL (corresponding author), Guangxi Normal Univ, Coll Comp Sci & Engn, Guilin 541004, Peoples R China.; Lu, SL (corresponding author), Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.; Qian, TT (corresponding author), Shanghai Acad Agr Sci, Agr Informat Inst Sci & Technol, Shanghai 201403, Peoples R China.
EM lsl@gxnu.edu.cn; qiantingting@saas.sh.cn
RI Chen, Ming/HNJ-3707-2023
OI lu, shenglian/0000-0002-4957-9418
FU National Natural Science Foundation of China [61762013, 62062015,
   61662006]; Science and Technology Foundation of Guangxi Province [2018
   AD19339]; Innovation Project of Guangxi Graduate Education
   [XYCSZ2021007]; Research Fund of Guangxi Key Lab of Multi-source
   Information Mining Security [20-A-02-02]; Guangxi Scholarship Fund of
   the Guangxi Education Department
FX This work is supported by the National Natural Science Foundation of
   China (no. 61762013, 62062015 and 61662006), the Science and Technology
   Foundation of Guangxi Province (no. 2018 AD19339), Innovation Project of
   Guangxi Graduate Education (No. XYCSZ2021007) and Research Fund of
   Guangxi Key Lab of Multi-source Information Mining & Security (No.
   20-A-02-02). The authors also thank the Guangxi Scholarship Fund of the
   Guangxi Education Department for the support.
CR [Anonymous], 2013, Computer and Computing Technologies in Agriculture, DOI DOI 10.1007/978-3-642-36124-1
   Bargoti S, 2017, J FIELD ROBOT, V34, P1039, DOI 10.1002/rob.21699
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Chen P, 2020, J MAR SCI ENG, V8, DOI 10.3390/jmse8020112
   [戴加明 Dai Jiaming], 2018, [天文学进展, Progress in Astronomy], V36, P384
   Dorj UO, 2017, COMPUT ELECTRON AGR, V140, P103, DOI 10.1016/j.compag.2017.05.019
   Font D, 2014, SENSORS-BASEL, V14, P11557, DOI 10.3390/s140711557
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Gongal A, 2015, COMPUT ELECTRON AGR, V116, P8, DOI 10.1016/j.compag.2015.05.021
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   [黄小玉 Huang Xiaoyu], 2018, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V34, P142
   Jiang B, 2019, COMPUT ELECTRON AGR, V166, DOI 10.1016/j.compag.2019.104982
   Kang HW, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204599
   Koirala A, 2019, PRECIS AGRIC, V20, P1107, DOI 10.1007/s11119-019-09642-0
   Koirala A, 2019, COMPUT ELECTRON AGR, V162, P219, DOI 10.1016/j.compag.2019.04.017
   Kurtulmus F, 2014, EXPERT SYST APPL, V41, P7390, DOI 10.1016/j.eswa.2014.06.013
   Li FC, 2020, PROCEDIA MANUF, V48, P172, DOI 10.1016/j.promfg.2020.05.035
   Lin GC, 2019, BIOSYST ENG, V186, P34, DOI 10.1016/j.biosystemseng.2019.06.019
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Misra D., 2019, ARXIV190808681
   Nasiri A, 2019, POSTHARVEST BIOL TEC, V153, P133, DOI 10.1016/j.postharvbio.2019.04.003
   Osco LP, 2020, ISPRS J PHOTOGRAMM, V160, P97, DOI 10.1016/j.isprsjprs.2019.12.010
   Pham V, 2020, IEEE INT CONF BIG DA, P5592, DOI 10.1109/BigData50022.2020.9378027
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sengupta S, 2014, BIOSYST ENG, V117, P51, DOI 10.1016/j.biosystemseng.2013.07.007
   Takalkar MA, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106566
   Tang Yehui, 2020, ADV NEURAL INFORM PR, V33, P10936, DOI DOI 10.5555/3495724.3496642
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Vasconez JP, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105348
   Vasconez JP, 2019, BIOSYST ENG, V179, P35, DOI 10.1016/j.biosystemseng.2018.12.005
   Wang ChengLong Wang ChengLong, 2014, Transactions of the Chinese Society of Agricultural Engineering, V30, P245
   Wu DH, 2020, BIOSYST ENG, V189, P150, DOI 10.1016/j.biosystemseng.2019.11.017
   [熊俊涛 Xiong Juntao], 2020, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V51, P199
   Yang LX, 2021, PR MACH LEARN RES, V139
   Zhuang JJ, 2018, COMPUT ELECTRON AGR, V152, P64, DOI 10.1016/j.compag.2018.07.004
NR 38
TC 11
Z9 11
U1 5
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 22
BP 31363
EP 31389
DI 10.1007/s11042-022-12687-5
EA APR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3X7GP
UT WOS:000779805700002
DA 2024-07-18
ER

PT J
AU Kumar, S
   Kumar, S
   Shafi, M
   Chaube, MK
AF Kumar, Santosh
   Kumar, Sunil
   Shafi, Mehak
   Chaube, Mithilesh Kumar
TI A novel multimodal framework for automatic recognition of individual
   cattle based on hybrid features using sparse stacked denoising
   autoencoder and group sparse representation techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual animal bio-metrics; Muzzle point; Deep learning; Group sparse
   representation; SDAE
ID LOCAL BINARY PATTERNS; ANIMAL BIOMETRICS; IDENTIFICATION
AB Recently, visual animal bio-metrics have attracted much attention for identifying endangered species and animals based on their prominent bio-metric features. This study explores a new possibility of using facial recognition for an inexpensive and user-friendly bio-metric modality to identify cattle. This paper proposes an automatic recognition system to identify cattle based on face and muzzle image features using sparse Stacked Denoising Autoencoder (SDAE) and group sparse representation techniques. The discriminatory features are extracted from cattle's facial image and muzzle images using sparse SDAE and Deep Belief Networks (DBN) methods to represent extracted features. It mitigates the need for individual bio-metric feature representation from the single face and muzzle bio-metric modality features at various score levels. The single modality features and multi-features are fused at score level to represent better and classify individual cattle using group sparse representation technique. The proposed system's performance is compared with holistic and handcrafted texture feature extraction and representation technique and current state of the art methods. Author shows that the proposed recognition system yield 96.85% accuracy for identifying individual cattle based on the multi-feature-based representation of cattle's face and muzzle features.
C1 [Kumar, Santosh] IIIT Naya Raipur, Dept Comp Sci & Engn, Chhattisgarh 493661, India.
   [Kumar, Sunil] Marine Engn & Res Inst Kolkatta, Kolkata, India.
   [Shafi, Mehak] Shri Mata Vaishno Devi Univ, Dept Elect & Commun Engn, Katra, India.
   [Chaube, Mithilesh Kumar] IIIT Naya Raipur, Dept Math Sci, Chhattisgarh 493661, India.
C3 Shri Mata Vaishno Devi University
RP Kumar, S (corresponding author), IIIT Naya Raipur, Dept Comp Sci & Engn, Chhattisgarh 493661, India.
EM santosh.rs.cse12@iitbhu.ac.in; sk273303@gmail.com; mehak0sk@gmail.com;
   mithilesh@iiitnr.edu.in
RI Chaube, Mithilesh/AAV-7844-2020
OI Chaube, Mithilesh/0000-0001-7086-1277; Kumar, Dr.
   Santosh/0000-0003-2264-9014
CR Acharya UR, 2012, ULTRASOUND MED BIOL, V38, P899, DOI 10.1016/j.ultrasmedbio.2012.01.015
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Andrew W, 2019, IEEE INT C INT ROBOT, P237, DOI [10.1109/IROS40897.2019.8968555, 10.1109/iros40897.2019.8968555]
   Arymurthy, 2012, P 3 EUR C COMP SCI E, P110
   Awad AI, 2016, COMPUT ELECTRON AGR, V123, P423, DOI 10.1016/j.compag.2016.03.014
   Awad AI, 2013, FED CONF COMPUT SCI, P529
   Barry B, 2007, T ASABE, V50, P1073, DOI 10.13031/2013.23121
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bello R. W., 2019, Journal of Applied Sciences & Environmental Management, V23, P1825, DOI 10.4314/jasem.v23i10.9
   Bennamoun, 1999, WILEY ENCY ELECT ELE, P1
   Brust CA, 2017, IEEE INT CONF COMP V, P2820, DOI 10.1109/ICCVW.2017.333
   Chen HY, 2018, MULTIMED TOOLS APPL, V77, P3857, DOI 10.1007/s11042-016-4243-z
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Givens GH, 2013, WILEY INTERDISCIP RE, V5, P288, DOI 10.1002/wics.1262
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iakovidis DK, 2008, LECT NOTES COMPUT SC, V5112, P750, DOI 10.1007/978-3-540-69812-8_74
   Kühl HS, 2013, TRENDS ECOL EVOL, V28, P432, DOI 10.1016/j.tree.2013.02.013
   Kumar D, 2010, INT J IMAG SYST TECH, V20, P261, DOI 10.1002/ima.20248
   Kumar S, 2020, P NATL A SCI INDIA A, V90, P689, DOI 10.1007/s40010-019-00610-x
   Kumar S, 2017, IET BIOMETRICS, V6, P139, DOI 10.1049/iet-bmt.2016.0017
   Kusakunniran W, 2018, IEEE INT CONF INDUST, P1484, DOI 10.1109/ICIT.2018.8352400
   Lahiri M, 2011, Proceedings of the 1st ACM International Conference on Multimedia Retrieval, P1
   Lin S, 2010, U.S. Patent, Patent No. [7,668,376, 7668376]
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Low CY, 2019, IEEE T CIRC SYST VID, V29, P115, DOI 10.1109/TCSVT.2017.2761829
   Lu CL, 2019, BIOMETRICS, V75, P5, DOI 10.1111/biom.12969
   Méndez-Vázquez H, 2013, INT CONF BIOMETR
   Minagawa H., 2002, AFITA 2002: Asian agricultural information technology & management. Proceedings of the Third Asian Conference for Information Technology in Agriculture, Beijing, China, 26-28 October, 2002, P596
   Noviyanto A, 2013, COMPUT ELECTRON AGR, V99, P77, DOI 10.1016/j.compag.2013.09.002
   Nurtanio I., 2020, INT J INTERACT MOB T, V14, DOI DOI 10.3991/IJIM.V14I13.13237
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Qiao YL, 2019, IFAC PAPERSONLINE, V52, P318, DOI 10.1016/j.ifacol.2019.12.558
   Shao W, 2020, INT J REMOTE SENS, V41, P31, DOI 10.1080/01431161.2019.1624858
   Singh, 2014, J SOFTW ENG APPL, V7, P470, DOI [10.4236/jsea.2014.75044, DOI 10.4236/JSEA.2014.75044]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stevenson BC, 2019, BIOMETRICS, V75, P326, DOI 10.1111/biom.12983
   Sun JH, 2019, BIOMETRICS, V75, P69, DOI 10.1111/biom.12964
   Tan Fabian H. S., 2019, The International Journal of Advanced Smart Convergence, V8, P75, DOI 10.7236/IJASC.2019.8.4.75
   Tang X, 2014, NEUROCOMPUTING, V145, P402, DOI 10.1016/j.neucom.2014.05.012
   Tharwat A, 2014, ADV INTELL SYST, V303, P217, DOI 10.1007/978-3-319-08156-4_22
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wolf L, 2009, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2009.5459323
   Xiong C, 2016, IEEE T CIRC SYST VID, V26, P517, DOI 10.1109/TCSVT.2015.2406191
   Yao L., 2019, P ACM TUR CEL C CHIN, P1
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 49
TC 5
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 31075
EP 31106
DI 10.1007/s11042-022-12701-w
EA APR 2022
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000781336500010
DA 2024-07-18
ER

PT J
AU Rangari, T
   Kumar, S
   Roy, PP
   Dogra, DP
   Kim, BG
AF Rangari, Tushar
   Kumar, Sudhanshu
   Roy, Partha Pratim
   Dogra, Debi Prosad
   Kim, Byung-Gyu
TI Video based exercise recognition and correct pose detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OpenPose; Pose Estimation; Video Dataset; Deep Learning
AB Human pose estimation has gained significant attention from researchers of the present era. Personal exercise sessions can be monitored and supervised with the help of pose recognition. Existing work on exercise classification primarily relies on external or wearable sensors for recognizing poses. However, such sensors often fail to differentiate amongst similar exercises. Some essential extensions of human pose estimation are activity detection and activity prediction. In this paper, we first classify an individual's exercises and then predict whether the pose corresponding to an exercise is correct or not. The tasks mentioned above are performed with the help of 2-dimensional pose coordinates. We have used an RGB camera to capture the poses during exercises performed by individuals. We formulate our model with 2D coordinates obtained from the 2D pose. We consider 2D coordinates of 18 joints of a human body as the primary features to classify different exercises and predict correctness about the poses. We have developed a benchmark dataset consisting of human subjects of various age groups with varying heights. An accuracy of 97.01% has been obtained, and it is better than existing work when tested on our dataset.
C1 [Rangari, Tushar; Kumar, Sudhanshu; Roy, Partha Pratim] IIT Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
   [Dogra, Debi Prosad] IIT Bhubaneswar, Sch Elect Sci, Bhubaneswar 752050, Odisha, India.
   [Kim, Byung-Gyu] Sookmyung Womens Univ, Dept IT Engn, Seoul 04310, South Korea.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Bhubaneswar; Sookmyung
   Women's University
RP Kumar, S (corresponding author), IIT Roorkee, Dept Comp Sci & Engn, Roorkee 247667, Uttar Pradesh, India.
EM tushar786rangari@gmail.com; skumar2@cs.iitr.ac.in; partha@cs.iitr.ac.in;
   dpdogra@iitbbs.ac.in; bg.kim@sookmyung.ac.kr
RI Roy, Partha/J-2168-2019
OI kumar, sudhanshu/0000-0001-5424-7744
CR Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Dhar P, 2017, P INT C COMP VIS IM, P343
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Hidalgo G, 2019, IEEE I CONF COMP VIS, P6981, DOI 10.1109/ICCV.2019.00708
   Hu JF, 2016, IEEE T CIRC SYST VID, V26, P647, DOI 10.1109/TCSVT.2015.2397200
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hwang DH, 2020, IEEE WINT CONF APPL, P468, DOI [10.1109/WACV45572.2020.9093595, 10.1109/wacv45572.2020.9093595]
   Kai KZ, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P20, DOI 10.1145/1409635.1409639
   Koskimäki H, 2014, 2014 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE AND DATA MINING (CIDM), P321, DOI 10.1109/CIDM.2014.7008685
   Kumar P, 2019, IEEE T FUZZY SYST, V27, P956, DOI 10.1109/TFUZZ.2018.2870590
   Kumar P, 2018, MULTIMED TOOLS APPL, V77, P8823, DOI 10.1007/s11042-017-4776-9
   Kumawat S, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P1, DOI 10.1109/COMPTELIX.2017.8003927
   Lester J, 2005, 19TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI-05), P766
   Linna M, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P335, DOI 10.5220/0006624403350342
   Lukowicz P, 2004, LECT NOTES COMPUT SC, V3001, P18
   Maurer U, 2006, BSN 2006: INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P113
   Nie BX, 2015, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2015.7298734
   O'Reilly M, 2018, SPORTS MED, V48, P1221, DOI 10.1007/s40279-018-0878-4
   Pärkkä J, 2006, IEEE T INF TECHNOL B, V10, P119, DOI 10.1109/TITB.2005.856863
   Saini R, 2019, INT J MACH LEARN CYB, V10, P2529, DOI 10.1007/s13042-018-0887-5
   Saini R, 2018, NEUROCOMPUTING, V311, P99, DOI 10.1016/j.neucom.2018.05.042
   Seeger Christian., 2011, Proceedings of the 6th International Confer- ence on Body Area Networks, P1
   Shian-Ru Ke, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P489, DOI 10.1109/AVSS.2010.80
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Simon T, 2017, PROC CVPR IEEE, P4645, DOI 10.1109/CVPR.2017.494
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Ukita N, 2018, COMPUT VIS IMAGE UND, V170, P67, DOI 10.1016/j.cviu.2018.02.003
   Wang H., 2009, BMVC
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Zhe Zhang, 2018, 2018 24th Asia-Pacific Conference on Communications (APCC), P492, DOI 10.1109/APCC.2018.8633473
   Zhu A., 2019, AIP ADV, V9, P1
NR 35
TC 8
Z9 8
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2022
VL 81
IS 21
BP 30267
EP 30282
DI 10.1007/s11042-022-12299-z
EA APR 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3W1PB
UT WOS:000779045500011
DA 2024-07-18
ER

PT J
AU Kumar, KA
   Boda, R
AF Kumar, Katukuri Arun
   Boda, Ravi
TI A computer-aided brain tumor diagnosis by adaptive fuzzy active contour
   fusion model and deep fuzzy classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor classification; Skull stripping; Adaptive fuzzy active
   contour fusion model; Jaya-tunicate swarm algorithm; Modified
   convolutional neural network (CNN)-fuzzy classifier
ID SEGMENTATION; REPRESENTATION; ALGORITHM; NETWORKS
AB Brain tumor classification is a significant issue in Computer-Aided Diagnosis (CAD) for clinical applications. The classification process is crucial and plays a major role to diagnosis the brain tumors. The existing works focus on recognizing brain tumors through diverse classification approaches. Though, the conventional classification approaches are suffered from high false alarm rates. To improve the early-stage brain tumor diagnosis via classification, the main intention of this paper is to introduce a novel brain tumor segmentation and classification model. The dataset gathered from the two benchmark sources is subjected to pre-processing for enhancing the quality of images, and skull stripping for extracting the region of interest from the skull. Further, a new segmentation approach termed Adaptive Fuzzy Active Contour Fusion Model (AFACFM) with a new fitness function is developed. Here, the enhancement of the segmentation is performed by the hybrid Jaya-Tunicate Swarm Algorithm (J-TSA). Next, the combination of Convolutional Neural Network (CNN) and Fuzzy classifier is performed in the final classification phase. The deep features are extracted from the pooling layer of CNN, which are subjected to the Fuzzy classifier for classifying the images into normal, benign, and malignant. As a modification, the parameters of the CNN and Fuzzy classifier are tuned by the proposed J-TSA. The comparative analysis is finally done, and this work demonstrates the potential of using deep learning in MRI images to provide a non-invasive tool for simultaneous and automated tumor segmentation and classification. Through the performance analysis, the accuracy of the designed CNN-Fuzzy using J-TSA was 77%, 29%, 19%, 8.7%, 6.8%, and 1.6% enhanced than SVM, NN, DBN, CNN, Fuzzy, and CNN-Fuzzy, respectively.
C1 [Kumar, Katukuri Arun; Boda, Ravi] Koneru Lakshmaiah Educ Fdn KLEF, Dept ECE, Hyderabad, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Kumar, KA (corresponding author), Koneru Lakshmaiah Educ Fdn KLEF, Dept ECE, Hyderabad, Telangana, India.
EM arun.katkoori@gmail.com
RI Boda, Ravi/IWD-5725-2023; KUMAR, K. ARUN/ACA-2681-2022; Boda,
   Ravi/GNP-6278-2022
OI KUMAR, K. ARUN/0000-0001-6780-4124; Boda, Ravi/0000-0002-0335-6745
CR Abd-Ellah MK, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0332-4
   Ali M, 2020, IEEE ACCESS, V8, P153589, DOI 10.1109/ACCESS.2020.3018160
   Arakeri MP, 2013, INT J MULTIMED INF R, V2, P175, DOI 10.1007/s13735-013-0037-5
   Ayadi W, 2021, NEURAL PROCESS LETT, V53, P671, DOI 10.1007/s11063-020-10398-2
   Bhattacharyya D, 2011, COMM COM INF SC, V151, P307
   Biji CL, 2011, COMM COM INF SC, V193, P300
   Chen BS, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105797
   Cruz-Aceves I, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/419018
   Deng W, 2020, IEEE ACCESS, V8, P26665, DOI 10.1109/ACCESS.2020.2966879
   Fernández-Navarro F, 2017, IEEE T NEUR NET LEAR, V28, P2592, DOI 10.1109/TNNLS.2016.2598657
   Ghahfarrokhi SS, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102025
   Gooya A, 2011, IEEE T MED IMAGING, V30, P375, DOI 10.1109/TMI.2010.2078833
   Huang MY, 2014, IEEE T BIO-MED ENG, V61, P2633, DOI 10.1109/TBME.2014.2325410
   Huang ZG, 2020, IEEE ACCESS, V8, P89281, DOI 10.1109/ACCESS.2020.2993618
   Iglesias JE, 2013, MED IMAGE ANAL, V17, P1181, DOI 10.1016/j.media.2013.08.001
   Irmak E, 2021, IJST-T ELECTR ENG, V45, P1015, DOI 10.1007/s40998-021-00426-9
   Islam K., 2021, MACH LEARNING APPL, V5, P15
   Kalavathi P, 2016, J DIGIT IMAGING, V29, P365, DOI 10.1007/s10278-015-9847-8
   Kaur S, 2020, ENG APPL ARTIF INTEL, V90, DOI 10.1016/j.engappai.2020.103541
   Khosravanian A, 2021, COMPUT METH PROG BIO, V198, DOI 10.1016/j.cmpb.2020.105809
   Kumar A, 2019, APPL SOFT COMPUT, V82, DOI 10.1016/j.asoc.2019.105528
   Kumar T., 2010, Int J Comput Appl, V7, P7, DOI DOI 10.5120/1140-1493
   Lee H, 2011, IEEE T MED IMAGING, V30, P1154, DOI 10.1109/TMI.2011.2140380
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Masood M, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-0105-y
   Menaga D, 2020, BIOMED ENG-APP BAS C, V32, DOI 10.4015/S1016237220500131
   Menaga D., 2020, Intelligent Computing and Applications, V1172, P353
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Noreen N, 2020, IEEE ACCESS, V8, P55135, DOI 10.1109/ACCESS.2020.2978629
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Price S.R., 2019, IEEE INT C FUZZY SYS, P1, DOI [DOI 10.1109/FUZZ-IEEE.2019.8858790, 10.1109/FUZZIEEE.2019.8858790, DOI 10.1109/FUZZIEEE.2019.8858790]
   Rao R., 2016, Int J Ind Eng Comput, V7, P19, DOI [DOI 10.5267/J.IJIEC.2015.8.004, 10.5267/j.ijiec.2015.8.004]
   Razzak MI, 2019, IEEE J BIOMED HEALTH, V23, P1911, DOI 10.1109/JBHI.2018.2874033
   Senthilkumaran N., 2016, COMPUT SCI ENG INT J, V6, P1, DOI [DOI 10.5121/CSEIJ.2016.6101, 10.5121/cseij.2016, DOI 10.5121/CSEIJ.2016]
   Sert E, 2019, MED HYPOTHESES, V133, DOI 10.1016/j.mehy.2019.109413
   Shi QW, 2022, EVOL SYST-GER, V13, P535, DOI 10.1007/s12530-021-09392-3
   Sultan HH, 2019, IEEE ACCESS, V7, P69215, DOI 10.1109/ACCESS.2019.2919122
   Wang HZ, 2013, IEEE T PATTERN ANAL, V35, P611, DOI 10.1109/TPAMI.2012.143
   Wang LF, 2021, IEEE ACCESS, V9, P67634, DOI 10.1109/ACCESS.2021.3075953
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yeganejou M., 2019, 2019 IEEE INT C FUZZ, P1
   Zhang JX, 2020, IEEE ACCESS, V8, P58533, DOI 10.1109/ACCESS.2020.2983075
   Zhang ST, 2012, MED IMAGE ANAL, V16, P1385, DOI 10.1016/j.media.2012.07.007
   Zhong P, 2017, IEEE T GEOSCI REMOTE, V55, P3516, DOI 10.1109/TGRS.2017.2675902
   Zhou Y, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2020.101918
   Zhu YL, 2012, PHYSCS PROC, V25, P609, DOI 10.1016/j.phpro.2012.03.133
NR 47
TC 1
Z9 1
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 18
BP 25405
EP 25441
DI 10.1007/s11042-022-12213-7
EA MAR 2022
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2P6GW
UT WOS:000772288200001
DA 2024-07-18
ER

PT J
AU Albadr, MAA
   Tiun, S
   Ayob, M
   AL-Dhief, FT
   Omar, K
   Maen, MK
AF Albadr, Musatafa Abbas Abbood
   Tiun, Sabrina
   Ayob, Masri
   AL-Dhief, Fahad Taha
   Omar, Khairuddin
   Maen, Mhd Khaled
TI Speech emotion recognition using optimized genetic algorithm-extreme
   learning machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion speech recognition; Optimized genetic algorithm-extreme learning
   machine; Mel frequency cepstral coefficients
ID FEATURE-SELECTION; CLASSIFICATION; FEATURES; EXTRACTION; EFFICIENT
AB Automatic Emotion Speech Recognition (ESR) is considered as an active research field in the Human-Computer Interface (HCI). Typically, the ESR system is consisting of two main parts: Front-End (features extraction) and Back-End (classification). However, most previous ESR systems have been focused on the features extraction part only and ignored the classification part. Whilst the classification process is considered an essential part in ESR systems, where its role is to map out the extracted features from audio samples to determine its corresponding emotion. Moreover, the evaluation of most ESR systems has been conducted based on Subject Independent (SI) scenario only. Therefore, in this paper, we are focusing on the Back-End (classification), where we have adopted our recent developed Extreme Learning Machine (ELM), called Optimized Genetic Algorithm-Extreme Learning Machine (OGA-ELM). In addition, we used the Mel Frequency Cepstral Coefficients (MFCC) method in order to extract the features from the speech utterances. This work proves the significance of the classification part in ESR systems, where it improves the ESR performance in terms of achieving higher accuracy. The performance of the proposed model was evaluated based on Berlin Emotional Speech (BES) dataset which consists of 7 emotions (neutral, happiness, boredom, anxiety, sadness, anger, and disgust). Four different evaluation scenarios have been conducted such as Subject Dependent (SD), SI, Gender Dependent Female (GD-Female), and Gender Dependent Male (GD-Male). The highest performance of the OGA-ELM was very impressive in the four different scenarios and achieved an accuracy of 93.26%, 100.00%, 96.14% and 97.10% for SI, SD, GD-Male, and GD-Female scenarios, respectively. Besides, the proposed ESR system has shown a fast execution time in all experiments to identify the emotions.
C1 [Albadr, Musatafa Abbas Abbood; Tiun, Sabrina; Ayob, Masri; Omar, Khairuddin] Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, CAIT, Bangi, Selangor, Malaysia.
   [AL-Dhief, Fahad Taha] Univ Teknol Malaysia, Sch Elect Engn, Dept Commun Engn, Utm Johor Bahru, Johor, Malaysia.
   [Maen, Mhd Khaled] Uppsala Univ, Dept Informat & Technol, Uppsala, Sweden.
C3 Universiti Kebangsaan Malaysia; Universiti Teknologi Malaysia; Uppsala
   University
RP Albadr, MAA (corresponding author), Univ Kebangsaan Malaysia, Fac Informat Sci & Technol, CAIT, Bangi, Selangor, Malaysia.
EM mustafa_abbas1988@yahoo.com
RI Omar, Khairuddin/C-3534-2017; tiun, sabrina/M-4315-2019; Albadr,
   Musatafa Abbas Abbood/AAJ-6453-2020
OI Omar, Khairuddin/0000-0003-1794-019X; Albadr,
   Musatafa/0000-0003-2062-688X
FU Universiti Kebangsaan Malaysia under Dana Impak Perdana grant
   [GUP-2020-063]
FX This project was funded by the Universiti Kebangsaan Malaysia under Dana
   Impak Perdana grant (Research code: GUP-2020-063).
CR AL-Dhief FT, 2020, I SYMPOS TELECOM TEC, P99, DOI 10.1109/ISTT50966.2020.9279346
   Al-Dhief FT, 2020, IEEE ACCESS, V8, P64514, DOI 10.1109/ACCESS.2020.2984925
   Albadr MA, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12111758
   Albadr MAA, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242899
   Albadr MAA, 2020, CIRC SYST SIGNAL PR, V39, P4596, DOI 10.1007/s00034-020-01388-9
   Albadr MAA, 2019, INT J SPEECH TECHNOL, V22, P711, DOI 10.1007/s10772-019-09621-w
   Albadr MAA, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0194770
   Albadra MAA, 2017, INT J APPL ENG RES, V12, P4610, DOI DOI 10.37622/000000
   Alonso JB, 2015, EXPERT SYST APPL, V42, P9554, DOI 10.1016/j.eswa.2015.07.062
   [Anonymous], 2000, P 6 INT C SPOK LANG
   Badshah AM, 2017, 2017 INTERNATIONAL CONFERENCE ON PLATFORM TECHNOLOGY AND SERVICE (PLATCON), P125
   Baroi, 2019, 2019 1 INT C ADV SCI
   Basu S, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P109, DOI 10.1109/ICICCT.2017.7975169
   Bi WW, 2020, WATER-SUI, V12, DOI 10.3390/w12030695
   Burkhardt F, 2005, INTERSPEECH, V5, P1517, DOI DOI 10.21437/INTERSPEECH.2005-446
   Calvo RA, 2010, IEEE T AFFECT COMPUT, V1, P18, DOI 10.1109/T-AFFC.2010.1
   Cao HW, 2015, COMPUT SPEECH LANG, V29, P186, DOI 10.1016/j.csl.2014.01.003
   Choudhury AR, 2018, PROCEEDINGS OF 2018 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON), P257, DOI 10.1109/ASPCON.2018.8748626
   Dendukuri LS, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET 2019): ADVANCING WIRELESS AND MOBILE COMMUNICATIONS TECHNOLOGIES FOR 2020 INFORMATION SOCIETY, P192, DOI [10.1109/WiSPNET45539.2019.9032744, 10.1109/wispnet45539.2019.9032744]
   Deng CW, 2015, SCI CHINA INFORM SCI, V58, DOI 10.1007/s11432-014-5269-3
   Dogra A, 2019, IEEE INT CONF SIG PR, P134, DOI [10.1109/ISPCC48220.2019.8988336, 10.1109/ispcc48220.2019.8988336]
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Gangamohan P, 2016, INTEL SYST REF LIBR, V105, P205, DOI 10.1007/978-3-319-31056-5_11
   Ghasemi J, 2019, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-019-1230-x
   Gogna Anupriya, 2012, International Journal of Metaheuristics, V2, P80, DOI 10.1504/IJMHEUR.2012.048219
   Guo LL, 2019, IEEE ACCESS, V7, P75798, DOI 10.1109/ACCESS.2019.2921390
   Trang H, 2014, PROC INT CONF ADV, P697, DOI 10.1109/ATC.2014.7043477
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2006, IEEE T NEURAL NETWOR, V17, P879, DOI 10.1109/TNN.2006.875977
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jain M, 2020, USNC-URSI RADIO SCI, P147, DOI [10.23919/USNC/URSI49741.2020.9321614, 10.23919/usnc/ursi49741.2020.9321614]
   Juvela L, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5679, DOI 10.1109/ICASSP.2018.8461852
   Kaya H, 2018, NEUROCOMPUTING, V275, P1028, DOI 10.1016/j.neucom.2017.09.049
   Kaya H, 2016, LECT NOTES COMPUT SC, V9719, P115, DOI 10.1007/978-3-319-40663-3_14
   Kostoulas T, 2012, EXPERT SYST APPL, V39, P11072, DOI 10.1016/j.eswa.2012.03.067
   Kuchibhotla S, 2016, INT J SPEECH TECHNOL, V19, P657, DOI 10.1007/s10772-016-9358-0
   López-de-Ipiña K, 2015, COGN COMPUT, V7, P44, DOI 10.1007/s12559-013-9229-9
   MarLL Pa WP., 2019, 17 INT C COMP APPL I
   Muda Lindasalwa, 2010, Journal of Computing, DOI DOI 10.48550/ARXIV.1003.4083
   Murugappan M, 2020, 2020 16TH IEEE INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2020), P290, DOI [10.1109/CSPA48992.2020.9068709, 10.1109/cspa48992.2020.9068709]
   Neiberg D, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2755
   Özseven T, 2019, APPL ACOUST, V146, P320, DOI 10.1016/j.apacoust.2018.11.028
   Pakyurek M, 2020, ELEKTRON ELEKTROTECH, V26, P46, DOI 10.5755/j01.eie.26.1.25309
   Pan Yixiong, 2012, International Journal of Smart Home, V6, P101, DOI DOI 10.5120/431-636
   Poorna SS, 2019, INT J SPEECH TECHNOL, V22, P327, DOI 10.1007/s10772-019-09605-w
   Renanti MD, 2013, J THEORETICAL APPL I, V56
   Shah AF, 2017, 2017 INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION, EMBEDDED AND COMMUNICATION SYSTEMS (ICIIECS)
   Sokolova M, 2006, LECT NOTES COMPUT SC, V4304, P1015
   Tripathi A, 2020, REV EMOTION DETECTIO
   Tzinis E, 2017, INT CONF AFFECT, P190, DOI 10.1109/ACII.2017.8273599
   van Heeswijk M, 2015, ADV EXTREME LEARNING
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wang YG, 2011, NEUROCOMPUTING, V74, P2483, DOI 10.1016/j.neucom.2010.11.030
   Wei Han, 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C)
   Wilhelmstotter F., 2021, JENETICS LIB USERS M
   Yogesh CK, 2017, EXPERT SYST APPL, V69, P149, DOI 10.1016/j.eswa.2016.10.035
   Yu FR, 2016, 2016 INTERNATIONAL CONFERENCE ON NETWORK AND INFORMATION SYSTEMS FOR COMPUTERS (ICNISC), P151, DOI [10.1109/ICNISC.2016.22, 10.1109/ICNISC.2016.041]
   Zaidan Noor Aina, 2016, Advances in Machine Learning and Signal Processing, MALSIP 2015. Proceedings: LNEE 387, P141, DOI 10.1007/978-3-319-32213-1_13
   Zhang XY, 2014, PLOS ONE, V9, DOI [10.1371/journal.pone.0101532, 10.1371/journal.pone.0088075]
   Zhao S., 2014, 2014 IEEE INT C AC S
NR 61
TC 15
Z9 15
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 23963
EP 23989
DI 10.1007/s11042-022-12747-w
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000022
DA 2024-07-18
ER

PT J
AU Hosny, KM
   Darwish, MM
AF Hosny, Khalid M.
   Darwish, Mohamed M.
TI Robust color image watermarking using multiple fractional-order moments
   and chaotic map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robust watermarking; Multiple fractional-order orthogonal moments; Sine
   mapping; Geometric attacks
ID COMPLEX EXPONENTIAL TRANSFORM; ORTHOGONAL MOMENTS; ZERNIKE MOMENTS;
   FOURIER MOMENTS; MULTICHANNEL; ROTATION; SYSTEM; SCALE
AB Robust watermarking is an effective method and a promising solution for securing and protecting the copyright of digital images. Moments and moment invariants have become popular tools for robust watermarking due to their geometric invariance and favorable capability of image description. Many moments-based robust watermarking schemes have been proposed. However, there is a challenging problem of these schemes that should be addressed. One of these problems is to improve both imperceptibility and robustness. In contrast, the other problem, most of these schemes used inefficient, traditional computation methods of the moments, resulting in an inaccurate and inefficient performance of the watermarking schemes. To overcome these challenges, in this paper, we propose a novel robust color image-watermarking algorithm based on new multiple fractional multi-channel orthogonal moments, fractional-order exponent moments (MFrEMs), fractional-order polar harmonic transforms (MFrPHTs), and fractional-order radial harmonic Fourier moments (MFrRHFMs). Firstly, highly accurate fractional new multi-channel orthogonal moments are computed for the host color images. Then, more stable and accurate coefficients of fractional new multi-channel orthogonal moments are selected. Finally, a robust color image watermarking approach for multiple watermarks images is proposed based on MFrEMs, MFrPHTs, and MFrRHFMs using a 1D Sine chaotic map. The experimental results demonstrate that the proposed approach provides robustness against various attacks and better imperceptibility than the existing methods.
C1 [Hosny, Khalid M.] Zagazig Univ, Dept Informat Technol, Zagazig, Egypt.
   [Darwish, Mohamed M.] Assiut Univ, Dept Comp Sci, Assiut, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Assiut University
RP Hosny, KM (corresponding author), Zagazig Univ, Dept Informat Technol, Zagazig, Egypt.
EM k_hosny@yahoo.com
RI Darwish, SMIEEE, M. M. F./AAE-5964-2021; Hosny, Khalid M./B-1404-2008
OI Darwish, SMIEEE, M. M. F./0000-0001-9782-8813; Hosny, Khalid
   M./0000-0001-8065-8977
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB).
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Alghoniemy M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1291, DOI 10.1109/ICME.2000.871003
   [Anonymous], 2015, USC SIPI IMAGE DATAB
   [Anonymous], 2018, J INF HIDING MULTIME
   [Anonymous], 2002, NUMERICAL METHODS
   Darwish M.M., 2020, Multimedia security using chaotic maps: principles and methodologies, P137
   Hosny KM, 2021, CIRC SYST SIGNAL PR, V40, P6121, DOI 10.1007/s00034-021-01756-z
   Hosny KM, 2021, NEURAL COMPUT APPL, V33, P5419, DOI 10.1007/s00521-020-05280-0
   Hosny KM, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107545
   Hosny KM, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107324
   Hosny KM, 2020, IEEE ACCESS, V8, P40732, DOI 10.1109/ACCESS.2020.2976759
   Hosny KM, 2020, J FRANKLIN I, V357, P2533, DOI 10.1016/j.jfranklin.2020.01.025
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Hosny KM, 2019, PATTERN RECOGN, V88, P153, DOI 10.1016/j.patcog.2018.11.014
   Hosny KM, 2018, IEEE ACCESS, V6, P77212, DOI 10.1109/ACCESS.2018.2879919
   Hosny KM, 2018, MULTIMED TOOLS APPL, V77, P24727, DOI 10.1007/s11042-018-5670-9
   Hosny KM, 2017, COMPUT ELECTR ENG, V62, P429, DOI 10.1016/j.compeleceng.2017.05.015
   Hosny KM, 2019, J REAL-TIME IMAGE PR, V16, P1235, DOI 10.1007/s11554-016-0622-y
   Hu HT, 2014, PATTERN RECOGN, V47, P2596, DOI 10.1016/j.patcog.2014.02.014
   Hua ZY, 2019, INFORM SCIENCES, V480, P403, DOI 10.1016/j.ins.2018.12.048
   Ismail Ismail A., 2010, Journal of Computer Sciences, V6, P52, DOI 10.3844/jcssp.2010.52.59
   Kahlessenane F, 2021, CLUSTER COMPUT, V24, P2069, DOI 10.1007/s10586-020-03215-x
   Kamili A, 2021, IEEE T IND INFORM, V17, P5108, DOI 10.1109/TII.2020.3028612
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149, DOI 10.1007/s11042-020-08881-y
   Lazebnik S, 2005, IEEE I CONF COMP VIS, P832, DOI 10.1109/ICCV.2005.10
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   Liu YN, 2020, SIGNAL PROCESS-IMAGE, V88, DOI 10.1016/j.image.2020.115946
   Ma B, 2020, SIGNAL PROCESS, V172, DOI 10.1016/j.sigpro.2020.107544
   Nguyen TS, 2021, MULTIMED TOOLS APPL, V80, P25107, DOI 10.1007/s11042-021-10879-z
   Niu P, 2015, MULTIMED TOOLS APPL
   Ray A, 2020, INT J MULTIMED INF R, V9, P249, DOI 10.1007/s13735-020-00197-9
   Ren HP, 2003, J OPT SOC AM A, V20, P631, DOI 10.1364/JOSAA.20.000631
   Rhayma H, 2021, MULTIMED TOOLS APPL, V80, P26813, DOI 10.1007/s11042-021-10886-0
   Salomon D., 2004, Data Compression: the Complete Reference, V4th ed.
   Shao ZH, 2016, SIGNAL PROCESS, V120, P522, DOI 10.1016/j.sigpro.2015.10.005
   Singh C, 2018, DIGIT SIGNAL PROCESS, V78, P376, DOI 10.1016/j.dsp.2018.04.001
   Suk T, 2009, LECT NOTES COMPUT SC, V5702, P334, DOI 10.1007/978-3-642-03767-2_41
   Sun WW, 2021, IEEE T CIRC SYST VID, V31, P1208, DOI 10.1109/TCSVT.2020.2998476
   Tarhouni N, 2020, CIRC SYST SIGNAL PR, V39, P5059, DOI 10.1007/s00034-020-01401-1
   Thanki R, 2021, MULTIMED TOOLS APPL, V80, P27593, DOI 10.1007/s11042-021-11064-y
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Wang CP, 2017, MULTIMED TOOLS APPL, V76, P26355, DOI 10.1007/s11042-016-4130-7
   Wang XY, 2015, APPL MATH COMPUT, V256, P951, DOI 10.1016/j.amc.2015.01.075
   [王向阳 Wang Xiangyang], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P651
   Xia ZQ, 2019, SIGNAL PROCESS, V164, P368, DOI 10.1016/j.sigpro.2019.06.025
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Xin YQ, 2007, IEEE T IMAGE PROCESS, V16, P581, DOI 10.1109/TIP.2006.888346
   Xu HC, 2019, OPTIK, V183, P401, DOI 10.1016/j.ijleo.2019.02.001
   Yamni M, 2021, MULTIMED TOOLS APPL, V80, P21679, DOI 10.1007/s11042-021-10717-2
   Yamni M, 2020, SIGNAL PROCESS, V171, DOI 10.1016/j.sigpro.2020.107509
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yang HY, 2014, OPTIK, V125, P4456, DOI 10.1016/j.ijleo.2014.02.028
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Yuan XC, 2013, SIGNAL PROCESS, V93, P2087, DOI 10.1016/j.sigpro.2013.01.024
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
   2017, MULTIMED SYST APPL, P1
NR 58
TC 12
Z9 12
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 17
BP 24347
EP 24375
DI 10.1007/s11042-022-12282-8
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2Q1DF
UT WOS:000770754000004
OA hybrid
DA 2024-07-18
ER

PT J
AU Saikia, M
   Choudhury, HA
   Sinha, N
AF Saikia, Monjul
   Choudhury, Hussain Ahmed
   Sinha, Nidul
TI Optimized particle swarm optimization for faster and accurate video
   compression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block matching algorithm; Motion estimation; MAD; Particle swarm
   optimization; Cost function
ID DIAMOND SEARCH ALGORITHM; ROOD PATTERN SEARCH; MOTION ESTIMATION
AB The motion of objects in a video from one frame to another must be estimated quickly to speed up the video compression process. However, this should not deteriorate the visual appearance of the contents beyond the appropriate scope. This paper proposes improvisation of the fundamental Particle Swarm Optimization (PSO), known as Optimized PSO, to balance video compression quality and speed. The inertia portion of the particle velocity is modified dynamically to address the quality needed and broadly defines the movement to the global best place. To make the process quicker, additional stopping parameters, including predefined block distortion measurement, i.e., thresholds and the early identification of static macroblocks, are used to eradicate the movement estimation process for non-moving macroblocks. A small diamond search pattern is also implemented to investigate the impact of search patterns on optimizing the particulate swarm on the motion estimation process. The detailed simulations performed on different videos have proved that the proposed Optimized PSO versions for the block matching algorithm surpass several current modular block matching algorithms. It also produces even better estimation precision and speed than the possible particle swarm optimization-based motion estimation. The proposed versions of PSO-BMA referred to as Optimized PSOs have gained a speed up to 90-95% than that of FS with an acceptable compromise between the qualities of the reconstructed image.
C1 [Saikia, Monjul] North Eastern Reg Inst Sci & Technol, Dept Comp Sci & Engn, Nirjuli 791109, Arunachal Prade, India.
   [Choudhury, Hussain Ahmed] VIT Andhra Pradesh, Dept CSE, Amaravati, India.
   [Sinha, Nidul] Natl Inst Technol, Dept Elect Engn, Silchar 788010, Assam, India.
C3 North Eastern Regional Institute of Science & Technology (NERIST);
   VIT-AP University; National Institute of Technology (NIT System);
   National Institute of Technology Silchar
RP Saikia, M (corresponding author), North Eastern Reg Inst Sci & Technol, Dept Comp Sci & Engn, Nirjuli 791109, Arunachal Prade, India.
EM monjuls@gmail.com; jainhussain2018@gmail.com; nidul.sinha@nits.ac.in
RI Saikia, Monjul/E-6466-2014; Choudhury, Dr Hussain Ahmed/KHZ-4021-2024
OI Saikia, Monjul/0000-0002-7316-0254; Choudhury, Dr Hussain
   Ahmed/0009-0004-1190-2373
CR [Anonymous], 2009, THESIS
   Barjatya A., 2004, IEEE T EVOLUTION COM, V8, P225, DOI DOI 10.1109/TEVC.2004.826069
   Cai J, 2012, INFORM SCIENCES, V197, P53, DOI 10.1016/j.ins.2012.02.014
   CHAN MH, 1990, IEE PROC-I, V137, P205, DOI 10.1049/ip-i-2.1990.0029
   Chau LP, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P421
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   Cheung CH, 2002, IEEE T CIRC SYST VID, V12, P1168, DOI 10.1109/TCSVT.2002.806815
   Cheung CH, 2002, IEEE IMAGE PROC, P681
   Choudhury H, 2013, INT J ADV COMPUT ENG, V1, P73
   Choudhury HA, 2014, P INT C INF COMM EMB, P1
   Choudhury HA, 2019, J INTELL FUZZY SYST, V36, P5989, DOI 10.3233/JIFS-181790
   Choudhury HA, 2015, LECT NOTES ELECTR EN, V347, P149, DOI 10.1007/978-81-322-2464-8_12
   Chow KHK, 1993, IEEE T CIRC SYST VID, V3, P440, DOI 10.1109/76.260203
   Cuevas E, 2013, APPL SOFT COMPUT, V13, P3047, DOI 10.1016/j.asoc.2012.09.020
   Du GY, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5038
   GHANBARI M, 1990, IEEE T COMMUN, V38, P950, DOI 10.1109/26.57512
   HSIEH CH, 1990, ELECTRON LETT, V26, P276, DOI 10.1049/el:19900183
   JAIN JR, 1981, IEEE T COMMUN, V29, P1799, DOI 10.1109/TCOM.1981.1094950
   Jalloul MK, 2015, SIGNAL PROCESS-IMAGE, V39, P121, DOI 10.1016/j.image.2015.09.010
   Jia HJ, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P357
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kim JN, 1998, IEEE T CONSUM ELECTR, V44, P638, DOI 10.1109/30.713175
   Koga T, 1981, P NAT TELECOMMUN C
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Liaw YC, 2009, SIGNAL PROCESS, V89, P1115, DOI 10.1016/j.sigpro.2008.12.012
   Liu LK, 1996, IEEE T CIRC SYST VID, V6, P419, DOI 10.1109/76.510936
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Pandian SIA, 2013, ENG APPL ARTIF INTEL, V26, P1811, DOI 10.1016/j.engappai.2013.04.003
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Saha A, 2011, SIGNAL PROCESS-IMAGE, V26, P438, DOI 10.1016/j.image.2011.06.002
   Saha A, 2008, SIGNAL PROCESS-IMAGE, V23, P725, DOI 10.1016/j.image.2008.08.004
   Sengar SS, 2020, NEURAL COMPUT APPL, V32, P11443, DOI 10.1007/s00521-019-04635-6
   Song Y, 2007, IEICE T FUND ELECTR, VE90A, P764, DOI 10.1093/ietfec/e90-a.4.764
   Tsai JC, 1998, SIGNAL PROCESS-IMAGE, V13, P119, DOI 10.1016/S0923-5965(97)00052-0
   Yuan XD, 2008, IEEE I C EMBED SOFTW, P191, DOI 10.1109/ICESS.2008.35
   Yuelei Xu B, 2000, P 5 INT C SIGN PROC, V2
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 38
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 23289
EP 23310
DI 10.1007/s11042-022-12522-x
EA MAR 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000770549800021
DA 2024-07-18
ER

PT J
AU Hariri, M
   Avsar, E
AF Hariri, Muhab
   Avsar, Ercan
TI Tipburn disorder detection in strawberry leaves using convolutional
   neural networks and particle swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Calcium deficiency; Convolutional neural networks; Deep learning;
   Strawberry disorder; Particle swarm optimization
ID DISEASE DETECTION; CLASSIFICATION; TOMATO
AB Tipburn is a disorder that is caused by calcium deficiency in plants and may lead to decrements in crop yield. Therefore, it is important to detect tipburn for an appropriate treatment process. In this work, a sequential convolutional neural network (CNN) architecture was developed for tipburn detection in images of strawberry leaves. The parameters of the CNN architecture as well as the dropout and learning rates were determined through a two-stage search operation based on particle swarm optimization (PSO) algorithm. The resulting model, PSO-CNN, contains five convolutional layers and three fully-connected layers with varying number of filters and hidden units. The model development was performed using an original dataset of strawberry leaf images taken from the field under realistic conditions and has been made publicly available with this study. The performance of the PSO-CNN was compared with the performance of eight different benchmark CNN models, namely, VGG16, VGG19, MobileNetV2, EfficientNet, ResNetV2, NasNetMobile, InceptionV3 and InceptionResNetV2. According to the results obtained by ten independent re-runs of the classification task, PSO-CNN achieved the best average performance by 0.9895, 0.9863, and 0.9936 for accuracy, sensitivity, and specificity values, respectively. In addition, the number of parameters of the PSO-CNN model is smaller than those in the benchmark models. This means that PSO-CNN model requires relatively less amount of computation for an efficient model training and performing prediction on the test images. Finally, further experiments were performed on a multi-class problem to demonstrate the effectiveness of the PSO-CNN for tipburn detection.
C1 [Hariri, Muhab] Cukurova Univ, Elect & Elect Engn Dept, TR-01330 Adana, Turkey.
   [Avsar, Ercan] Dokuz Eylul Univ, Comp Engn Dept, TR-35390 Izmir, Turkey.
C3 Cukurova University; Dokuz Eylul University
RP Avsar, E (corresponding author), Dokuz Eylul Univ, Comp Engn Dept, TR-35390 Izmir, Turkey.
EM ercan.avsar@deu.edu.tr
OI Avsar, Ercan/0000-0002-1356-2753; Hariri, Muhab/0000-0002-2200-1915
CR Abdullahi HS, 2017, 2017 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH 2017), P155, DOI 10.1109/INTECH.2017.8102436
   Amara J., 2017, DATENBANKSYSTEME BUS
   Barbedo JGA, 2019, BIOSYST ENG, V180, P96, DOI 10.1016/j.biosystemseng.2019.02.002
   Atabay Habibollah Agh, 2017, Journal of Theoretical and Applied Information Technology, V95, P6800
   Atila Ü, 2021, ECOL INFORM, V61, DOI 10.1016/j.ecoinf.2020.101182
   Atlantic Working Group for Pest Management Education and Training Standards, 2005, LANDSC SAF MAN
   Bárcena A, 2019, SCI HORTIC-AMSTERDAM, V249, P93, DOI 10.1016/j.scienta.2019.01.023
   Crouse D.A., 2018, North Carolina Extension gardener handbook
   Durmus H, 2017, INT CONF AGRO-GEOINF, P46
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Hariri M, 2021, IMAGE DATASET TIPBUR
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hughes D, 2015, PEERJ COMPUT SCI
   Joly A., 2017, INT C CROSS LANG EV
   Kamal KC, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104948
   Kaya A, 2019, COMPUT ELECTRON AGR, V158, P20, DOI 10.1016/j.compag.2019.01.041
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan S., 2020, ADV COMPUT TECHNOL A, P187
   Khan S., 2020, J PHYS C SERIES
   Kim B, 2021, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.559172
   King DB, 2015, ACS SYM SER, V1214, P1
   Kuronuma T, 2018, AGRONOMY-BASEL, V8, DOI 10.3390/agronomy8100218
   Liu B, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010011
   Lu J, 2017, COMPUT ELECTRON AGR, V142, P369, DOI 10.1016/j.compag.2017.09.012
   Melis P., 2012, 7 INT STRAWB S
   Mikolajczyk Agnieszka, 2018, 2018 International Interdisciplinary PhD Workshop (IIPhDW), P117, DOI 10.1109/IIPHDW.2018.8388338
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Nie X, 2019, IEEE ACCESS, V7, P170003, DOI 10.1109/ACCESS.2019.2954845
   Olle M, 2017, J HORTIC SCI BIOTECH, V92, P223, DOI 10.1080/14620316.2016.1255569
   Palencia P, 2010, SCI HORTIC-AMSTERDAM, V126, P242, DOI 10.1016/j.scienta.2010.07.024
   Park H., 2018, 2018 INT C COMP NETW
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Rahnemoonfar M, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040905
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shin J, 2021, COMPUT ELECTRON AGR, V183, DOI 10.1016/j.compag.2021.106042
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh R, 2020, MULTIMEDIA SYST, V26, P313, DOI 10.1007/s00530-019-00645-5
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Uguz S, 2021, NEURAL COMPUT APPL, V33, P4133, DOI 10.1007/s00521-020-05235-5
   Vaishnnave MP, 2020, SOFT COMPUT, V24, P16347, DOI 10.1007/s00500-020-04946-0
   Xiao JR, 2021, PLANTS-BASEL, V10, DOI 10.3390/plants10010031
   Yalcin H, 2016, INT CONF AGRO-GEOINF, P233
   Zoph B, 2016, P 2016 C N AM CHAPTE
NR 52
TC 7
Z9 7
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 11795
EP 11822
DI 10.1007/s11042-022-12759-6
EA MAR 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000767748600012
DA 2024-07-18
ER

PT J
AU Bel, KNS
   Sam, IS
AF Bel, K. Nalini Sujantha
   Sam, I. Shatheesh
TI Incremental indexing with binary feature based Tversky index using black
   hole entropic fuzzy clustering in cloud computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Incremental indexing; Image retrieval; Cloud computing; Tversky index;
   Deep stacked autoencoder
ID IMAGE RETRIEVAL; EFFICIENT; TRANSFORM; SEARCH
AB Due to the large volume of computational and storage requirements of content based image retrieval (CBIR), outsourcing image to cloud providers become an attractive research. Even though, the cloud service provides efficient indexing of the condensed images, it remains a major issue in the process of incremental indexing. Hence, an effective incremental indexing mechanism named Black Hole Entropic Fuzzy Clustering +Deep stacked incremental indexing (BHEFC+deep stacked incremental indexing) is proposed in this paper to perform incremental indexing through the retrieval of images. The images are encrypted and stored in cloud server for ensuring the security of image retrieval process. The trained images are clustered using the clustering mechanism BHEFC based on Tversky index. With the incremental indexing process, the new training images are encrypted and are converted into the decimal form such that the weight is computed using deep stacked auto-encoder that enable to update the centroid with new score values. The experimental evaluations on benchmark datasets shows that the proposed BHEFC+deep stacked incremental indexing model achieves better results compared to the existing methods by obtaining maximum accuracy of 96.728%, maximum F-measure of 83.598%, maximum precision of 84.447%, and maximum recall of 94.817%, respectively.
C1 [Bel, K. Nalini Sujantha] Manonmaniam Sundaranar Univ, Dept Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Sam, I. Shatheesh] Manonmaniam Sundaranar Univ, Dept PG Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Bel, KNS (corresponding author), Manonmaniam Sundaranar Univ, Dept Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
EM nalinisb85@gmail.com; shatheeshsam@yahoo.com
CR Al Sibahee MA, 2018, INT J DISTRIB SENS N, V14, DOI 10.1177/1550147718761814
   Alsmadi MK, 2020, ARAB J SCI ENG, V45, P3317, DOI 10.1007/s13369-020-04384-y
   Annalakshmi M, 2019, CLUSTER COMPUT, V22, P11, DOI 10.1007/s10586-017-1585-x
   [Anonymous], CONTENT BASED IMAGE
   Barz B, 2019, IEEE WINT CONF APPL, P638, DOI 10.1109/WACV.2019.00073
   Bel KNS, 2020, 2020 7TH IEEE INTERNATIONAL CONFERENCE ON SMART STRUCTURES AND SYSTEMS (ICSSS 2020), P336, DOI 10.1109/icsss49621.2020.9202374
   Bel KNS, 2021, INFORM SCIENCES, V560, P1, DOI 10.1016/j.ins.2021.01.043
   Chen LX, 2017, SOFT COMPUT, V21, P4829, DOI 10.1007/s00500-017-2684-6
   Cui H, 2020, IEEE T IMAGE PROCESS, V29, P1271, DOI 10.1109/TIP.2019.2940693
   Curtmola R, 2011, J COMPUT SECUR, V19, P895, DOI 10.3233/JCS-2011-0426
   Galshetwar GM, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102615
   Garg M, 2021, NEURAL COMPUT APPL, V33, P1311, DOI 10.1007/s00521-020-05017-z
   Hu S, 2014, BIO-MED MATER ENG, V24, P129, DOI 10.3233/BME-130793
   Huang F, 2018, PATTERN RECOGN, V76, P537, DOI 10.1016/j.patcog.2017.11.032
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Khawandi Shadi, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P222, DOI 10.1109/COMITCon.2019.8862184
   Krishnaraj N, 2021, SOFTWARE PRACT EXPER, V51, P489, DOI 10.1002/spe.2834
   Kumar BM, 2018, IMAGING SCI J, V66, P84, DOI 10.1080/13682199.2017.1378285
   Latif A, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/9658350
   Li JS, 2020, IEEE ACCESS, V8, P114940, DOI 10.1109/ACCESS.2020.3003928
   Li YY, 2022, IEEE T CLOUD COMPUT, V10, P1142, DOI 10.1109/TCC.2020.2989923
   Liang HH, 2019, J VIS COMMUN IMAGE R, V61, P149, DOI 10.1016/j.jvcir.2019.03.021
   Liang H, 2018, STEM CELLS INT, V2018, DOI 10.1155/2018/1481243
   Liu DD, 2017, INFORMATION, V8, DOI 10.3390/info8030096
   Liu GF, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5105709
   Liu JF, 2018, IEEE T SYST MAN CY-S, V48, P1622, DOI 10.1109/TSMC.2017.2682883
   Mahmoudi SA, 2019, COMPUTERS, V8, DOI 10.3390/computers8020048
   Nalini K, 2009, ISECURE, P1, DOI [10.22042/isecure.2020.209056.497, DOI 10.22042/ISECURE.2020.209056.497]
   Pahariya G, 2018, DYNAMIC CLASS LEARNI, V841, P481, DOI [10.1007/978-981-13-0020-2, DOI 10.1007/978-981-13-0020-2]
   Pang SC, 2018, COMPUT METH PROG BIO, V158, P53, DOI 10.1016/j.cmpb.2018.02.003
   Pankaja V.S.K, 2018, SMART INTELLIGENT CO, P667, DOI 10.1007/978-981-13-1927-3
   Qin JH, 2019, IEEE ACCESS, V7, P24626, DOI 10.1109/ACCESS.2019.2894673
   Sergyán S, 2008, 2008 6TH INTERNATIONAL SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS, P206
   Singh S, 2020, MULTIMED TOOLS APPL, V79, P17731, DOI 10.1007/s11042-019-08401-7
   Singh Vibhav Prakash, 2015, 2015 International Conference on Futuristic Trends on Computational Analysis and Knowledge Management (ABLAZE). Proceedings, P664, DOI 10.1109/ABLAZE.2015.7154946
   Sundararajan SK, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1305-6
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XN, 2017, MULTIMED TOOLS APPL, V76, P21629, DOI 10.1007/s11042-016-4029-3
   Xia ZH, 2019, CMC-COMPUT MATER CON, V58, P27, DOI 10.32604/cmc.2019.02688
   Xia ZH, 2017, INFORM SCIENCES, V387, P195, DOI 10.1016/j.ins.2016.12.030
   Xu YY, 2019, IEEE ACCESS, V7, P160082, DOI 10.1109/ACCESS.2019.2951175
   Zaidi SAJ, 2019, INT J ADV COMPUT SC, V10, P611
   Zhang G, 2007, INT C WAVEL ANAL PAT, P169
   Zneit R.A., 2017, International Journal of Computer Science and Mobile Computing, V16, P205
NR 44
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18457
EP 18481
DI 10.1007/s11042-022-12699-1
EA MAR 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800005
DA 2024-07-18
ER

PT J
AU Zhu, YZ
   Yan, WQ
AF Zhu, Yanzhao
   Yan, Wei Qi
TI Traffic sign recognition based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Traffic sign recognition; CNN; YOLOv5; SSD
AB Intelligent Transportation System (ITS), including unmanned vehicles, has been gradually matured despite on road. How to eliminate the interference due to various environmental factors, carry out accurate and efficient traffic sign detection and recognition, is a key technical problem. However, traditional visual object recognition mainly relies on visual feature extraction, e.g., color and edge, which has limitations. Convolutional neural network (CNN) was designed for visual object recognition based on deep learning, which has successfully overcome the shortcomings of conventional object recognition. In this paper, we implement an experiment to evaluate the performance of the latest version of YOLOv5 based on our dataset for Traffic Sign Recognition (TSR), which unfolds how the model for visual object recognition in deep learning is suitable for TSR through a comprehensive comparison with SSD (i.e., single shot multibox detector) as the objective of this paper. The experiments in this project utilize our own dataset. Pertaining to the experimental results, YOLOv5 achieves 97.70% in terms of mAP@0.5 for all classes, SSD obtains 90.14% mAP in the same term. Meanwhile, regarding recognition speed, YOLOv5 also outperforms SSD.
C1 [Zhu, Yanzhao; Yan, Wei Qi] Auckland Univ Technol, CBD, Auckland, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, CBD, Auckland, New Zealand.
EM desyanwq@gmail.com
FU CAUL
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR Chen Q, 2018, CHIN CONTR C
   Ellahyani A, 2018, J OPT SOC AM A, V35, P1907, DOI 10.1364/JOSAA.35.001907
   Garg P, 2019, INT CONF COMPUT, DOI 10.1109/icccnt45670.2019.8944491
   Hao G, 2019, IEEE JOINT INT INF T
   He ZL, 2020, IET INTELL TRANSP SY, V14, P323, DOI 10.1049/iet-its.2019.0409
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hu GX, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5573590
   Huo A, 2020, INT C COMP NETW EL A
   Jin YM, 2020, IEEE ACCESS, V8, P38931, DOI 10.1109/ACCESS.2020.2975828
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kuznetsova A, 2020, INT S NEUR NETW
   Li SW, 2021, CONSTR BUILD MATER, V273, DOI 10.1016/j.conbuildmat.2020.121949
   Lian J, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093031
   Lim K, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173317
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XX, 2021, MULTIMED TOOLS APPL, V80, P15161, DOI 10.1007/s11042-020-10455-x
   Qin Z., 2021, INT S GEOM VIS ISGV, P13
   Shi X, 2021, INT C INTELL COMP SI
   Sun W, 2019, CMC-COMPUT MATER CON, V60, P147, DOI 10.32604/cmc.2019.03581
   Wang CY, 2018, IEEE INT C INT ROBOT, P150, DOI 10.1109/ICRIS.2018.00047
   Wu Y, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P562, DOI 10.1109/SIPROCESS.2018.8600536
   Xiaoping Z., 2021, INT J SENS SENS NETW, V9, P30, DOI 10.11648/j.ijssn.20210901.15
   Xie BQ, 2019, IEEE ACCESS, V7, P53330, DOI 10.1109/ACCESS.2019.2912311
   Xing J., 2021, P INT S GEOMETRY VIS, VVolume 1386, P85, DOI 10.1007/978-3-030-72073-5_7
   Xu S, 2018, INT CONF SYST INFORM, P957, DOI 10.1109/ICSAI.2018.8599471
   Yan B, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13091619
   Yao Y, 2019, INT C COMP ENG INF S
   Yu G., 2020, J Artif Intell, V2, P125, DOI 10.32604/jai.2020.010501
   Zhang J, 2018, INT C PATT RECOG, P1839, DOI 10.1109/ICPR.2018.8546289
NR 29
TC 40
Z9 41
U1 20
U2 145
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 17779
EP 17791
DI 10.1007/s11042-022-12163-0
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000765701900001
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bao, WJ
   Zhu, CX
AF Bao, Wenji
   Zhu, Congxu
TI A secure and robust image encryption algorithm based on compressive
   sensing and DNA coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaos; Compressive sensing; DNA coding
AB This paper proposed an image encryption algorithm combining compressive sensing and DNA coding. Firstly, the plain image is divided into three high-frequency blocks and one low-frequency block by haar wavelet transform. Then the chaotic sequence generated by Logistic map is used to scramble all the blocks. Next, the high-frequency blocks are measured by a measurement matrix which was constructed by using the Chen chaotic system. After that, we apply dynamic DNA coding and addition operation on all blocks, and DNA addition operations on the low-frequency block and high-frequency blocks are different specifically. Finally, we combine all blocks by row and scramble it by the Logistic map. What's more, the initial conditions of the used chaotic maps are calculated by the SHA256 value of the plain image which improved the algorithm's ability to resist known/chosen plaintext attacks. We analyze key space and sensitivity, information entropy, histogram, correlation coefficient of two adjacent pixels, differential attack, noise attack and occlusion attack of our algorithm with typical test images in different size. Experimental simulation results and analysis illustrated that the proposed algorithm has good performance of compression and encryption, showing that the proposed scheme is secure and robust to various typical attacks.
C1 [Bao, Wenji; Zhu, Congxu] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
C3 Central South University
RP Zhu, CX (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Peoples R China.
EM zhucx@csu.edu.cn
OI Zhu, Congxu/0000-0002-9662-0532
FU National Natural Science Foundation of China [62071496]
FX This work was supported by the National Natural Science Foundation of
   China under Grant NO. 62071496
CR Alawida M, 2019, SIGNAL PROCESS, V160, P45, DOI 10.1016/j.sigpro.2019.02.016
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bianchi T, 2014, 2014 IEEE INT C AC S
   Chai XL, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105837
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Huang Rong, 2011, P INT INF HID MULT S, P105, DOI DOI 10.1109/IIHMSP.2011.53
   Li HJ, 2019, OPT LASER ENG, V115, P197, DOI 10.1016/j.optlaseng.2018.12.002
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Liu DH, 2009, INT CONF WIRE COMMUN, P731
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Wang XY, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116246
   Wei DY, 2021, OPTIK, V238, DOI 10.1016/j.ijleo.2021.166748
   Xinpeng Zhang, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P222, DOI 10.1109/IIHMSP.2011.12
   Xu QY, 2019, OPT LASER ENG, V121, P203, DOI 10.1016/j.optlaseng.2019.04.011
   Yang YG, 2019, OPT LASER TECHNOL, V119, DOI 10.1016/j.optlastec.2019.105661
   Zhang YS, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501911
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu SL, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21080790
   Zhu SQ, 2020, MULTIMED TOOLS APPL, V79, P31957, DOI 10.1007/s11042-020-09699-4
   Zhu SQ, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22070772
NR 26
TC 23
Z9 23
U1 9
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15977
EP 15996
DI 10.1007/s11042-022-12623-7
EA MAR 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000763256600014
DA 2024-07-18
ER

PT J
AU Li, YC
   Li, H
   Gao, GW
AF Li, Yanchao
   Li, Hao
   Gao, Guangwei
TI Towards end-to-end container code recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Container code number recognition; End-to-End system; Region location;
   Character detection
ID TEXT
AB Container code recognition can improve the efficiency and economy of the management system in the port. However, the task is different and complex due to the degradation of image quality caused by uneven illumination, background variation, smear, inaccurate character extraction, and so on. Current processing methods on container images usually provide the framework or modules on specific tasks, such as region detection and character classification, which are hard to implement or to be combined into a whole process. In this paper, we propose a fast end-to-end method of automatic recognition of container code that fills the gap by locating the region and detecting characters as well as making the classification. This allows the three tasks to work collaboratively by pipeline, which is critical to identify the container code. For evaluation, we collect around six thousand container images, including all kinds of circumstances from the local port. Compared with a few other methods and two-step approaches consisting of state-of-the-art character detector and character classifier, our system achieves some competitive results. Finally, the proposed system is verified on this dataset and the overall accuracy reaches 97.30%.
C1 [Li, Yanchao; Gao, Guangwei] Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing, Peoples R China.
   [Li, Hao] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Science & Technology
RP Li, YC (corresponding author), Nanjing Univ Posts & Telecommun, Sch Comp Sci, Nanjing, Peoples R China.
EM yanchao@njupt.edu.cn; hao.li@njust.edu.cn; csgwgao@njupt.edu.cn
FU Key Program of the National Natural Science Foundation of China
   [61932013]; Natural Science Foundation of Jiangsu Province of China
   [BK20200739]; Natural Science Foundation of the Jiangsu Higher Education
   Institutions of China [20KJB520003]; China Postdoctoral Science
   Foundation [2021M691655]; Postdoctoral Science Foundation of Jiangsu
   Province of China [2021K172B]; NUPTSF [NY219149, NY220189]; Henan Key
   Laboratory of Food Safety Data Intelligence, ZZULI [KF2020YB01];
   Research Foundation of Jiangsu [BRA2020065]
FX We specially thanks the Nanjing Port for providing us the datasets and
   technique support. This work is supported in part by the Key Program of
   the National Natural Science Foundation of China (61932013), the Natural
   Science Foundation of Jiangsu Province of China (BK20200739), the
   Natural Science Foundation of the Jiangsu Higher Education Institutions
   of China (20KJB520003) and the Research Foundation of Jiangsu for "333
   high level talents training project" (BRA2020065). This work is also
   supported by the China Postdoctoral Science Foundation (2021M691655) and
   the Postdoctoral Science Foundation of Jiangsu Province of China
   (2021K172B). This article is also sponsored by NUPTSF (NY219149,
   NY220189). Yanchao Li is also supported by Henan Key Laboratory of Food
   Safety Data Intelligence, ZZULI (KF2020YB01).
CR Baek Y, 2019, PROC CVPR IEEE, P9357, DOI 10.1109/CVPR.2019.00959
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Chen XR, 2004, PROC CVPR IEEE, P366
   Compare M, 2020, IEEE INTERNET THINGS, V7, P4585, DOI 10.1109/JIOT.2019.2957029
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Feng BY, 2014, PATTERN RECOGN, V47, P2621, DOI 10.1016/j.patcog.2014.02.011
   Fu Y, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P843, DOI 10.1109/DASC.2009.150
   He DF, 2017, PROC CVPR IEEE, P474, DOI 10.1109/CVPR.2017.58
   He P, 2017, IEEE I CONF COMP VIS, P3066, DOI 10.1109/ICCV.2017.331
   He T, 2018, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR.2018.00527
   He WH, 2017, IEEE I CONF COMP VIS, P745, DOI 10.1109/ICCV.2017.87
   Li CH, 2019, IEEE ASME INT C ADV, P532, DOI [10.1109/aim.2019.8868819, 10.1109/AIM.2019.8868819]
   Li L, 2019, IEEE INTERNET THINGS, V6, P1911, DOI 10.1109/JIOT.2018.2883490
   Liao MH, 2018, IEEE T IMAGE PROCESS, V27, P3676, DOI 10.1109/TIP.2018.2825107
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Lyu PY, 2018, PROC CVPR IEEE, P7553, DOI 10.1109/CVPR.2018.00788
   Ozuysal M, 2007, IEEE C COMP VIS PATT, P9
   Shi BG, 2019, IEEE T PATTERN ANAL, V41, P2035, DOI 10.1109/TPAMI.2018.2848939
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Wu W, 2012, EXPERT SYST APPL, V39, P2842, DOI 10.1016/j.eswa.2011.08.143
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Yu TQ, 2019, IEEE INTERNET THINGS, V6, P1856, DOI 10.1109/JIOT.2018.2876695
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 34
TC 2
Z9 2
U1 2
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15901
EP 15918
DI 10.1007/s11042-022-12477-z
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000763256600008
DA 2024-07-18
ER

PT J
AU Yu, HL
   Li, ZQ
   Bi, CG
   Chen, HL
AF Yu, Helong
   Li, Ziqing
   Bi, Chunguang
   Chen, Huiling
TI An effective deep learning method with multi-feature and attention
   mechanism for recognition of Chinese rice variety information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Rice; Named entity recognition; Multi-head attention mechanism; Radical
   features; Word segmentation boundary features; Deep learning
ID NAMED ENTITY RECOGNITION; NETWORK
AB In the process of Chinese rice variety information named entity recognition, traditional methods cannot extract potential semantic information from data and cannot capture long-distance dependence. So, this paper proposes a Chinese rice variety information named entity recognition method based on a bidirectional long short-term memory network and conditional random field (BiLSTM-CRF), which combines radical features, word segmentation boundary features, and multi-head attention mechanism. First, the radical features and word segmentation boundary features are encoded and integrated into a pre-trained character vector as the model embedding to solve the disadvantage of the lack of semantic information. Then, the multi-head attention mechanism is introduced to assist the bidirectional long short-term memory network (BiLSTM) in acquiring long-distance context-dependence. Finally, a conditional random field (CRF) is used to realize character-level sequence annotation and then realize the named entity recognition task of Chinese rice variety information. The experimental results show that this model's precision, recall, and F1-score are 95.78%, 97.07%, and 96.42%, respectively. The three evaluation indices are better than those of the other models. The model proposed in this paper can effectively identify Chinese rice variety information entities and provides method support for the subsequent construction of a Chinese rice variety information knowledge graph.
C1 [Yu, Helong; Li, Ziqing; Bi, Chunguang] Jilin Agr Univ, Coll Informat Technol, Changchun 130118, Peoples R China.
   [Chen, Huiling] Wenzhou Univ, Dept Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
C3 Jilin Agricultural University; Wenzhou University
RP Bi, CG (corresponding author), Jilin Agr Univ, Coll Informat Technol, Changchun 130118, Peoples R China.; Chen, HL (corresponding author), Wenzhou Univ, Dept Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
EM chunguangb@jlau.edu.cn; chenhuiling.jlu@gmail.com
RI Chen, Huiling/N-8510-2019; zhu, yujie/KBC-4009-2024; helong,
   yu/KHD-6183-2024
OI Chen, Huiling/0000-0002-7714-9693; 
FU National Natural Science Foundation of China [U19A2061]; National Key
   R&D Program of China [2019YFC1710700]; Science and Technology
   Development Program of Jilin Province [20190301024NY]; Jilin Provincial
   Development and Reform Commission Project [2020C005]
FX This research was funded by the National Natural Science Foundation of
   China (U19A2061), the National Key R&D Program of China
   (2019YFC1710700), the Science and Technology Development Program of
   Jilin Province (20190301024NY), and the Jilin Provincial Development and
   Reform Commission Project (2020C005).
CR Abd Kharim M.A., 2020, MALAYSIAN J SUSTAINA, V4, P66, DOI [10.26480/mjsa.02.2020.66.70, DOI 10.26480/MJSA.02.2020.66.70]
   Ahmadianfar I, 2021, EXPERT SYST APPL, V181, DOI 10.1016/j.eswa.2021.115079
   [Anonymous], 2019, J TSINGHUA U SCI TEC, V59, P461
   [Anonymous], 2020, J NANJING AGR U, V43, P179
   Barua J., 2020, INT J INTELL INF DAT, V12, P279
   Brooke J, 2016, M ASS COMP LING
   Chen Y, 2022, INT J INTELL SYST, V37, P829, DOI 10.1002/int.22649
   Cho M, 2020, J BIOMED INFORM, V103, DOI 10.1016/j.jbi.2020.103381
   [樊湘鹏 Fan Xiangpeng], 2021, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V52, P210
   Gajendran S, 2020, J BIOMED INFORM, V112, DOI 10.1016/j.jbi.2020.103609
   [高冰涛 Gao Bingtao], 2019, [计算机应用研究, Application Research of Computers], V36, P45
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   GuoXuchao TangZhan, 2020, T OFTHE CHINESESOCIE, V51, P335
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hu B, 2022, IEEE T CYBERNETICS, V52, P10214, DOI 10.1109/TCYB.2021.3071110
   Jiang N., 2021, INT J INTELL SYST
   Jiang N, 2022, ACM T INTERNET TECHN, V22, DOI 10.1145/3432248
   Jiang N, 2020, IEEE INTERNET THINGS, V7, P2901, DOI 10.1109/JIOT.2020.2963927
   Jiang N, 2020, INFORM SCIENCES, V512, P1, DOI 10.1016/j.ins.2019.09.068
   Kong J, 2021, J BIOMED INFORM, V116, DOI 10.1016/j.jbi.2021.103737
   Lee WenChiat, 2020, J SUSTAIN AGR, V4, P04
   [李冬梅 Li Dongmei], 2019, [计算机科学与探索, Journal of Frontiers of Computer Science & Technology], V13, P2085
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Li X., 2017, T CHIN SOC AGR MACH, V48, P178, DOI [10.6041/j.issn.1000-1298.2017.S0.029, DOI 10.6041/J.ISSN.1000-1298.2017.S0.029]
   Li X, 2021, DATA INTELLIGENCE, V3, P376, DOI 10.1162/dint_a_00093
   Li XL, 2018, SPRINGERBRIEF MATH, P1, DOI 10.1007/978-3-319-89617-5_1
   Li Y, 2022, IEEE T MED IMAGING, V41, P237, DOI 10.1109/TMI.2021.3110829
   Li YM, 2022, IEEE T CYBERNETICS, V52, P10542, DOI 10.1109/TCYB.2021.3069587
   Liang GX, 2021, KNOWL-BASED SYST, V232, DOI 10.1016/j.knosys.2021.107501
   Liang J, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4898963
   Liao F, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11080180
   Lu Yiwei, 2020, J PHYS C SERIES, V1693
   Qin Ying, 2018, Journal of Shanghai Jiaotong University (Science), V23, P392, DOI 10.1007/s12204-018-1954-5
   QIU S, 2021, IEEE INTERNET THINGS
   Qiu S, 2022, INT J INTELL SYST, V37, P1646, DOI 10.1002/int.22689
   Qiu XP, 2020, SCI CHINA TECHNOL SC, V63, P1872, DOI 10.1007/s11431-020-1647-3
   Rastogi S, 2019, ACTA INFORM MALAYSIA, V3, P7
   Saber A, 2021, IEEE ACCESS, V9, P71194, DOI 10.1109/ACCESS.2021.3079204
   Salleh MS, 2020, WATER CONSERVATION M, V4, P78, DOI DOI 10.26480/WCM.02.2020.78.82
   Santoso J, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114856
   Dang TH, 2018, BIOINFORMATICS, V34, P3539, DOI 10.1093/bioinformatics/bty356
   Tian Y, 2021, NEUROCOMPUTING, V439, P12, DOI 10.1016/j.neucom.2021.01.060
   Tu J, 2021, J BIONIC ENG, V18, P674, DOI 10.1007/s42235-021-0050-y
   [王春雨 Wang Chunyu], 2014, [河北农业大学学报, Journal of Agricultural University of Hebei], V37, P132
   Wang T, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103135
   Wu ZD, 2021, KNOWL-BASED SYST, V220, DOI 10.1016/j.knosys.2021.106952
   Wu ZD, 2020, IEEE T VEH TECHNOL, V69, P5244, DOI 10.1109/TVT.2020.2981633
   Wu ZD, 2021, WORLD WIDE WEB, V24, P25, DOI 10.1007/s11280-020-00830-x
   Wu ZD, 2020, KNOWL-BASED SYST, V195, DOI 10.1016/j.knosys.2020.105679
   Wu ZD, 2020, J ASSOC INF SCI TECH, V71, P183, DOI 10.1002/asi.24227
   Xie C, 2021, J INN MONG AGR U NAT, V43, P86
   Xu GH, 2018, LECT NOTES COMPUT SC, V10988, P264, DOI 10.1007/978-3-319-96893-3_20
   Xue X, 2022, IEEE T SERV COMPUT, V15, P1760, DOI 10.1109/TSC.2020.3016660
   Xue X, 2019, IEEE T IND INFORM, V15, P3343, DOI 10.1109/TII.2018.2871167
   Yang LN, 2022, IEEE T INTELL TRANSP, V23, P16524, DOI 10.1109/TITS.2021.3134557
   Yang YT, 2021, EXPERT SYST APPL, V177, DOI 10.1016/j.eswa.2021.114864
   Yin MW, 2019, J BIOMED INFORM, V98, DOI 10.1016/j.jbi.2019.103289
   Yu HL, 2021, IEEE ACCESS, V9, P143824, DOI 10.1109/ACCESS.2021.3120379
   Yu HG, 2022, MECH SYST SIGNAL PR, V165, DOI 10.1016/j.ymssp.2021.108353
   Yuan XU., 2018, J SUN YAT SEN U MED, V39, P455
   Zhang L., 2021, IEEE SYST J, DOI [10.1109/JSYST.2021.3057333, DOI 10.1109/JSYST.2021.3057333]
   Zhang L., 2021, J PHYS C SER, V1744
   Zhang LJ, 2021, COMPUT SECUR, V105, DOI 10.1016/j.cose.2021.102249
   Zhang LJ, 2020, CMC-COMPUT MATER CON, V65, P597, DOI 10.32604/cmc.2020.011554
   Zhang XQ, 2021, INFORM SCIENCES, V560, P256, DOI 10.1016/j.ins.2020.12.042
   Zhang XQ, 2021, IEEE T CIRC SYST VID, V31, P3025, DOI 10.1109/TCSVT.2020.3035722
   Zhang XQ, 2020, COMPUT VIS IMAGE UND, V197, DOI 10.1016/j.cviu.2020.103003
   Zhang XQ, 2021, IEEE T PATTERN ANAL, V43, P238, DOI 10.1109/TPAMI.2019.2929043
   Zhang YM, 2020, INT SYMP INERT SENSO
   [赵鹏飞 Zhao Pengfei], 2021, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V52, P185
   ZHU X, IEEE T MULTIMEDIA, V1
   ZHU X, IEEE T CIRCUITS SYST, P1
   Zhuang H., 2021, J PHYS C SERIES IOP, V1848, P012101, DOI 10.1088/1742-6596/1848/1/012101
NR 73
TC 9
Z9 9
U1 11
U2 88
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15725
EP 15745
DI 10.1007/s11042-022-12458-2
EA MAR 2022
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902200001
DA 2024-07-18
ER

PT J
AU Sharma, A
   Chaturvedi, R
   Bhargava, A
AF Sharma, Abhay
   Chaturvedi, Rekha
   Bhargava, Anuja
TI A novel opposition based improved firefly algorithm for multilevel image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entropy; Variance; Segmentation; Thresholding; Firefly algorithm;
   Optimization
ID SEARCH ALGORITHM; OPTIMIZATION; ENTROPY
AB The data explosion caused by the Internet and its applications has given researchers immense scope for data analysis. A large amount of data is available in form of images. Image processing is required for better understandability of an image. Various image processing steps are available for improving the image in different application areas. Various applications like medical imaging, face recognition, biometric security, and traffic surveillance, etc. depend only on image and its analysis. This analysis in several applications is highly dependent on the outcome of image segmentation. This paper focuses on good segmentation through multi-level thresholding. In this research, the algorithm includes two modules related to Entropy and variance. The first module is concerned with the modified firefly algorithm (FA) with Kapur's, Tsallis, and Fuzzy Entropy. FA is used to optimize fuzzy parameters for obtaining optimal thresholds. The second module is derived from the principle of variance between two classes known as between variance or inter-cluster variance. The opposition-based the learning method is used for initializing the population of candidate solutions and levying flight and local search is implemented with FA. The various experiments have been performed on Berkeley and benchmark images with distinct threshold (i.e. 2, 3, 4, 5) values. The proposed algorithm has been estimated and compared with known metaheuristic optimization methods like particle swarm optimization (PSO) and electromagnetism optimization (EMO). The results have been assessed quantitatively and qualitatively by using parameters like Peak signal-to-noise ratio (PSNR), structured similarity index metric (SSIM), objective function values, and convergence curve. The algorithm proposed observed better experiment results than PSO, EMO in terms of persistency and quality.
C1 [Sharma, Abhay; Chaturvedi, Rekha] MIT ADT Univ, MIT SOE, Pune, Maharashtra, India.
   [Bhargava, Anuja] GLA Univ, Mathura, India.
C3 GLA University
RP Sharma, A (corresponding author), MIT ADT Univ, MIT SOE, Pune, Maharashtra, India.
EM abhaysharma2004@gmail.com; rekhachaturvedi12@gmail.com;
   anuja1012@gmail.com
RI BHARGAVA, ANUJA/AAP-5094-2021; Sharma, Abhay/IVU-8563-2023; Sharma,
   Abhay/AHE-7317-2022
OI BHARGAVA, ANUJA/0000-0002-2387-2552; Sharma, Abhay/0000-0001-5166-4278
CR Abdullah-Al-Wadud M, 2008, FOURTH INTERNATIONAL SYMPOSIUM ON INFORMATION ASSURANCE AND SECURITY, PROCEEDINGS, P83, DOI 10.1109/IAS.2008.65
   Anitha P, 2017, 2017 2 INT C EL COMP, P1
   [Anonymous], BERKLEY IMAGE SEGMEN
   Ansar W, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1004, DOI 10.1109/ICCSP.2016.7754300
   Bagri N., 2015, International Journal of Advanced Science and Technology, V80, P41
   Bejinariu SI, 2018, INT CONF EXPO ELECTR, P438, DOI 10.1109/ICEPE.2018.8559843
   Bejinariu SI, 2015, 2015 INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS (ISSCS)
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2020, IEEE T INSTRUM MEAS, V69, P1871, DOI 10.1109/TIM.2019.2922516
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Bhargava A, 2021, MULTIMED TOOLS APPL, V80, P19931, DOI 10.1007/s11042-021-10714-5
   Bozkurt ÖÖ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0175915
   Canayaz M, 2016, 2016 INT S INN INT S, P1
   Chao Y, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P752, DOI 10.1109/ICIT.2016.7474845
   Chaudhry A., 2017, DISCOVERING CLASS SP
   Chen K, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/1578056
   Chinta S, 2017, 2017 INTERNATIONAL CONFERENCE ON MICROELECTRONIC DEVICES, CIRCUITS AND SYSTEMS (ICMDCS)
   Cufoglu A, 2017, INT J MODEL SIMUL SC, V8, DOI 10.1142/S1793962317500568
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2382, DOI 10.1109/TGRS.2013.2260552
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hamdaoui F, 2015, 2015 4TH INTERNATIONAL CONFERENCE ON SYSTEMS AND CONTROL (ICSC), P498, DOI 10.1109/ICoSC.2015.7153305
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang KW, 2015, IEEE C EVOL COMPUTAT, P751, DOI 10.1109/CEC.2015.7256966
   Jia HM, 2019, IEEE ACCESS, V7, P44097, DOI 10.1109/ACCESS.2019.2908718
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kaur A, 2016, 2016 SECOND INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE & COMMUNICATION TECHNOLOGY (CICT), P187, DOI 10.1109/CICT.2016.45
   Khomri B, 2018, IET IMAGE PROCESS, V12, P2163, DOI 10.1049/iet-ipr.2018.5425
   Kumar M, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P257, DOI 10.1109/Confluence51648.2021.9377050
   Kumar M, 2019, J NETW COMPUT APPL, V143, P1, DOI 10.1016/j.jnca.2019.06.006
   Kumar M, 2018, SUSTAIN COMPUT-INFOR, V19, P147, DOI 10.1016/j.suscom.2018.06.002
   Kumar M, 2018, COMPUT ELECTR ENG, V69, P395, DOI 10.1016/j.compeleceng.2017.11.018
   Kumar V, 2014, ENG APPL ARTIF INTEL, V29, P93, DOI 10.1016/j.engappai.2013.11.008
   Kurban T, 2014, APPL SOFT COMPUT, V23, P128, DOI 10.1016/j.asoc.2014.05.037
   Liang HN, 2019, IEEE ACCESS, V7, P11258, DOI 10.1109/ACCESS.2019.2891673
   Liu S, 2021, J PHYS C SERIES, V1865
   Mousavirad SJ, 2017, EVOL INTELL, V10, P45, DOI 10.1007/s12065-017-0152-y
   Mozaffari MH, 2017, IET IMAGE PROCESS, V11, P605, DOI 10.1049/iet-ipr.2016.0489
   Muangkote N, 2016, INT JOINT CONF COMP, P460
   Ng HF, 2006, PATTERN RECOGN LETT, V27, P1644, DOI 10.1016/j.patrec.2006.03.009
   Oliva D, 2014, NEUROCOMPUTING, V139, P357, DOI 10.1016/j.neucom.2014.02.020
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Panda R, 2013, EXPERT SYST APPL, V40, P7617, DOI 10.1016/j.eswa.2013.07.060
   Preetha MMSJ, 2016, IEEE INTERNATIONAL CONFERENCE ON EMERGING TECHNOLOGICAL TRENDS IN COMPUTING, COMMUNICATIONS AND ELECTRICAL ENGINEERING (ICETT)
   Rajinikanth Venkatesan, 2020, Applications of Firefly Algorithm and its Variants, P221
   Rapaka S, 2018, IET IMAGE PROCESS, V12, P1721, DOI 10.1049/iet-ipr.2016.0917
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sharma Akash, 2016, 2016 International Conference on Information Technology (InCITe): Next-Generation IT Summit on the Theme "Internet of Things: Connect Your Worlds", P99, DOI 10.1109/INCITE.2016.7857598
   Singh G., 2016, 2016 1 IND INT C INF, P1, DOI [DOI 10.1109/CIMCA.2016.8053256, 10.1109/CIMCA.2016.8053256]
   Singh R, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P2220, DOI 10.1109/ICCSP.2016.7754088
   Somwanshi D., 2016, 2016 INT C REC ADV I, P1, DOI [DOI 10.1109/ICRAIE.2016.7939554, 10.11 09/ICRAIE.2016.7939554]
   Sridevi M, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P750, DOI 10.1109/ICICI.2017.8365235
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Turajlic E, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1104, DOI 10.23919/MIPRO.2018.8400201
   Wang D, 2017, J COMPUT PHYS, V350, P657, DOI 10.1016/j.jcp.2017.08.020
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Yang ZH, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P583
   Yu CJ, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P415, DOI 10.1109/IIH-MSP.2013.110
   Zhao D, 2021, KNOWL-BASED SYST, V216, DOI 10.1016/j.knosys.2020.106510
   Zhao F, 2019, IEEE ACCESS, V7, P64028, DOI 10.1109/ACCESS.2019.2916894
   Zhou CH, 2015, IEEE ANN INT CONF CY, P1420, DOI 10.1109/CYBER.2015.7288151
NR 62
TC 13
Z9 13
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15521
EP 15544
DI 10.1007/s11042-022-12303-6
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600020
DA 2024-07-18
ER

PT J
AU Yu, NN
   Li, JJ
   Hua, Z
AF Yu, Nana
   Li, Jinjiang
   Hua, Zhen
TI Attention based dual path fusion networks for multi-focus image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus image fusion; Convolutional neural network; Attention
   mechanism
ID SEGMENTATION; PERFORMANCE; INFORMATION
AB An important goal of multi-focus image fusion technology is to generate all-focus images that can better retain the source image information, while improving the quality and performance of image fusion. However, traditional image fusion methods usually have problems such as block artifacts, artificial edges, halo effects, and decreased contrast. To solve these problems, this paper proposes a dual-path fusion network (A-DPFN) with attention mechanism for multi-focus image fusion. Firstly, our method splits the complete image into image blocks, and obtains higher image classification with the preprocessing of the image blocks, so that our proposed dual-path fusion network accelerates the model convergence speed; Secondly, feature extraction block1 (FEB1) and feature extraction block2 (FEB2) in our network respectively extract the feature information of pair of focused images, in which we have added an attention mechanism; Finally, we merge the obtained pair of feature images as the input of the feature fusion block (FFB), and enhance the details of the image through the down-sampling block (DB) and the up-sampling block (UB). The experimental results show that the method has strong robustness and can effectively avoid problems such as block effect and artificial effect. Compared with the traditional image fusion method, the multi-focus image fusion method proposed in this paper is more effective.
C1 [Yu, Nana; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai 264005, Peoples R China.
   [Li, Jinjiang] Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
C3 Shandong Technology & Business University; Shandong Technology &
   Business University
RP Li, JJ (corresponding author), Shandong Technol & Business Univ, Sch Comp Sci & Technol, Yantai 264005, Peoples R China.
EM 871618293@qq.com; lijinjiang@gmail.com
RI Hua, Zhen/AGN-6068-2022
FU National Natural Science Foundation of China [61772319, 619-76125];
   Shandong Natural Science Foundation of China [ZR2017MF049]
FX L The authors acknowledge the National Natural Science Foundation of
   China (Grant nos. 61772319, 619-76125), and Shandong Natural Science
   Foundation of China (Grant no. ZR2017MF049).
CR Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Amin-Naji M, 2017, IRAN CONF MACH, P45, DOI 10.1109/IranianMVIP.2017.8342367
   Aymaz S, 2020, MULTIMED TOOLS APPL, V79, P13311, DOI 10.1007/s11042-020-08670-7
   Bavirisetti DP, 2019, CIRC SYST SIGNAL PR, V38, P5576, DOI 10.1007/s00034-019-01131-z
   Chakraborty C, 2016, J MED SYST, V40, DOI 10.1007/s10916-015-0424-y
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   Cvejic N, 2006, ELECTRON LETT, V42, P626, DOI 10.1049/el:20060693
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Gai D, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107681
   Guo R, 2020, FRONT INFORM TECH EL, V21, P1019, DOI 10.1631/FITEE.1900336
   Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292
   Guo YL, 2020, IEEE T GEOSCI REMOTE, V58, P4018, DOI 10.1109/TGRS.2019.2960322
   Hong R, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1663
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Kingma D.P., 2014, ARXIV14126980
   Krishnan MMR, 2010, EXPERT SYST APPL, V37, P470, DOI 10.1016/j.eswa.2009.05.045
   Lai R, 2019, IEEE ACCESS, V7, P114385, DOI 10.1109/ACCESS.2019.2935006
   Li G, 2019, IEEE T GEOSCI REMOTE, V57, P8506, DOI 10.1109/TGRS.2019.2921342
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Liu Y, 2015, IET IMAGE PROCESS, V9, P347, DOI 10.1049/iet-ipr.2014.0311
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Z, 2008, COMPUT VIS IMAGE UND, V109, P56, DOI 10.1016/j.cviu.2007.04.003
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   MA B, 2019, ARXIV190801703
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Sarkar A, 2021, IEEE ACCESS, V9, P16435, DOI 10.1109/ACCESS.2021.3052884
   Sarker MMK, 2019, IEEE ACCESS, V7, P39069, DOI 10.1109/ACCESS.2019.2902225
   Savi S, 2012, 19 IEEE INT C SYST S
   Shen HF, 2016, IEEE T GEOSCI REMOTE, V54, P7135, DOI 10.1109/TGRS.2016.2596290
   Song XY, 2018, INFECT CONT HOSP EP, V39, P1436, DOI 10.1017/ice.2018.260
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2
   Xiang KT, 2021, OPT EXPRESS, V29, P4802, DOI 10.1364/OE.416130
   Xu S., 2020, ARXIV PREPRINT ARXIV
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 50
TC 2
Z9 3
U1 8
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10883
EP 10906
DI 10.1007/s11042-022-12046-4
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700029
DA 2024-07-18
ER

PT J
AU Remya, KR
   Giriprasad, MN
AF Remya, K. R.
   Giriprasad, M. N.
TI An automated exudate detection scheme supporting diabetic retinopathy
   screening using spatial-spectral-statistical feature maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Diabetic retinopathy; Exudates; Phase congruency; Support vector
   machine; SSS feature maps
ID RETINAL IMAGES; SEGMENTATION; ALGORITHM
AB An automated Diabetic Retinopathy (DR) introspection scheme for early detection of retinopathy signs is realized in this paper. Presence of exudates in retina is considered as an early sign of DR. Therefore, the proposed methodology aims at detection of exudates by transforming the acquired fundus image into a high-dimensional feature map labelled as Spatial-Spectral-Statistical (SSS) feature map that uniquely represents the individual image pixels using a novel characterization scheme. At the onset, a slightly novel preprocessing scheme is fused into the mechanism to address the non-uniform illumination issues present in images. Later, separate feature characterizers and descriptors pertaining to the diverse domains are engaged for extraction of the different features from the input fundus image. These distinct features are then blended to yield the feature map representing the given image. Then a supervised classifier categorizes these features and finally aids in deciding the presence or absence of exudates for the given input. Extensive investigation and relative comparisons performed on publicly available dataset namely DIARETDB0, DIARETDB1 and MESSIDOR demonstrate a consistent average classification accuracy of 97.99%, an attribute owed to the unique feature aggregation scheme that also, makes the methodology robust under different imaging problems.
C1 [Remya, K. R.; Giriprasad, M. N.] JNTUA, Dept ECE, Anantapuramu, Andhra Pradesh, India.
C3 Jawaharlal Nehru Technological University - Anantapur
RP Remya, KR (corresponding author), JNTUA, Dept ECE, Anantapuramu, Andhra Pradesh, India.
EM remyakr.jntu@gmail.com; mahendragiri1960@gmail.com
RI Giri Prasad, Mahendra Nanjappa/JTU-4183-2023
CR Agurto C, 2014, IEEE J BIOMED HEALTH, V18, P1328, DOI 10.1109/JBHI.2013.2296399
   Agurto C, 2010, IEEE T MED IMAGING, V29, P502, DOI 10.1109/TMI.2009.2037146
   [Anonymous], 2002, P 5 AS C COMP VIS ME
   Aqeel AF, 2014, INT CONF ELECTRO INF, P206, DOI 10.1109/EIT.2014.6871763
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Fraz MM, 2017, BIOMED SIGNAL PROCES, V35, P50, DOI 10.1016/j.bspc.2017.02.012
   García M, 2013, IEEE ENG MED BIO, P5891, DOI 10.1109/EMBC.2013.6610892
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES, P122
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Harangi B, 2014, IEEE ENG MED BIO, P130, DOI 10.1109/EMBC.2014.6943546
   Hsu W, 2001, PROC CVPR IEEE, P246
   Kaur J, 2018, BIOCYBERN BIOMED ENG, V38, P27, DOI 10.1016/j.bbe.2017.10.003
   Khojasteh P, 2019, COMPUT BIOL MED, V104, P62, DOI 10.1016/j.compbiomed.2018.10.031
   Kovesi P.D., 1999, Videre: Journal of Computer Vision Research, V1
   Mo J, 2018, NEUROCOMPUTING, V290, P161, DOI 10.1016/j.neucom.2018.02.035
   Muhammad M, 2020, EXUDATE DETECTION DI, DOI 10.1155/2020/580187
   Niemeijer M, 2007, INVEST OPHTH VIS SCI, V48, P2260, DOI 10.1167/iovs.06-0996
   Pereira C, 2015, INFORM SCIENCES, V296, P14, DOI 10.1016/j.ins.2014.10.059
   Rocha A, 2012, IEEE REV BIOMED ENG, V4
   Sánchez CI, 2008, MED ENG PHYS, V30, P350, DOI 10.1016/j.medengphy.2007.04.010
   Sánchez CI, 2009, MED IMAGE ANAL, V13, P650, DOI 10.1016/j.media.2009.05.005
   Sopharak A, 2008, COMPUT MED IMAG GRAP, V32, P720, DOI 10.1016/j.compmedimag.2008.08.009
   van Grinsven MJJP, 2013, I S BIOMED IMAGING, P1444
   Wang J, 2020, IEEE J BIOMED HEALTH, V24, P3397, DOI 10.1109/JBHI.2020.3012547
   Wang J, 2019, IEEE ACCESS, V7, P102589, DOI 10.1109/ACCESS.2019.2930941
   Zaki WMDW, 2016, BIOMED SIGNAL PROCES, V24, P72, DOI 10.1016/j.bspc.2015.09.011
   Zhang XW, 2014, MED IMAGE ANAL, V18, P1026, DOI 10.1016/j.media.2014.05.004
NR 27
TC 0
Z9 0
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9829
EP 9853
DI 10.1007/s11042-022-12354-9
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000756497800006
DA 2024-07-18
ER

PT J
AU Reveilhac, M
   Steinmetz, S
   Morselli, D
AF Reveilhac, Maud
   Steinmetz, Stephanie
   Morselli, Davide
TI A systematic literature review of how and whether social media data can
   complement traditional survey data to study public opinion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Social media; Survey data; Data complementarity; Public opinion
ID POLITICAL COMMUNICATION; NONRESPONSE RATES; BIG DATA; TWITTER; BIAS
AB In this article, we review existing research on the complementarity of social media data and survey data for the study of public opinion. We start by situating our review in the extensive literature (N = 187) about the uses, challenges, and frameworks related to the use of social media for studying public opinion. Based on 187 relevant articles (141 empirical and 46 theoretical) - we identify within the 141 empircal ones six main research approaches concerning the complementarity of both data sources. Results show that the biggest share of the research has focused on how social media can be used to confirm survey findings, especially for election predictions. The main contribution of our review is to detail and classify other growing complementarity approaches, such as comparing both data sources on a given phenomenon, using survey measures as a proxy in social media research, enriching surveys with SMD, recruiting individuals on social media to conduct a second survey phase, and generating new insight on "old" or "under-investigated" topics or theories using SMD. We discuss the advantages and disadvantages associated with each of these approaches in relation to four main research purposes, namely the improvement of validity, sustainability, reliability, and interpretability. We conclude by discussing some limitations of our study and highlighting future paths for research.
C1 [Reveilhac, Maud; Steinmetz, Stephanie; Morselli, Davide] Lausanne Univ Switzerland, Fac Social & Polit Sci, Life Course & Social Inequal Res Ctr, Inst Social Sci, Lausanne, Switzerland.
   [Morselli, Davide] Swiss Ctr Expertise Life Course Res LIVES, Lausanne, Switzerland.
RP Reveilhac, M (corresponding author), Lausanne Univ Switzerland, Fac Social & Polit Sci, Life Course & Social Inequal Res Ctr, Inst Social Sci, Lausanne, Switzerland.
EM maud.reveilhac@unil.ch; stephanie.steimnetz@unil.ch;
   davide.morselli@unil.ch
OI Steinmetz, Stephanie/0000-0001-7136-6622; Morselli,
   Davide/0000-0002-1490-9691
FU University of Lausanne
FX Open access funding provided by University of Lausanne.
CR Adams-Cohen NJ, 2020, AM POLIT RES, V48, P612, DOI 10.1177/1532673X20920263
   Amaya A., 2020, BIG DATA MEETS SURVE, P163, DOI [10.1002/9781118976357.ch5, DOI 10.1002/9781118976357.CH5]
   [Anonymous], 2011, P 49 ANN M ASS COMP
   [Anonymous], 2020, DIGITAL GLOBAL REPOR
   [Anonymous], P 8 INT C WEBL SOC M
   [Anonymous], 2011, P INT AAAI C WEB SOC
   Anstead N, 2015, J COMPUT-MEDIAT COMM, V20, P204, DOI 10.1111/jcc4.12102
   Bakker R, 2021, EUI RES DATA
   Bakshy E, 2015, SCIENCE, V348, P1130, DOI 10.1126/science.aaa1160
   Barbera P, 2019, AM POLIT SCI REV, V113, P883, DOI 10.1017/S0003055419000352
   Barberá P, 2015, PSYCHOL SCI, V26, P1531, DOI 10.1177/0956797615594620
   Batrinca B, 2015, AI SOC, V30, P89, DOI 10.1007/s00146-014-0549-4
   Bekafigo MA, 2013, SOC SCI COMPUT REV, V31, P625, DOI 10.1177/0894439313490405
   Bennett J, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0245319
   Biemer PP., 2008, INT HDB SURVEY METHO, P317
   Bode L, 2016, J POLITICAL MARKETIN, V15, P311, DOI 10.1080/15377857.2014.959686
   Brick JM, 2013, ANN AM ACAD POLIT SS, V645, P36, DOI 10.1177/0002716212456834
   Cardenal AS, 2019, INT J PUBLIC OPIN R, V31, P589, DOI 10.1093/ijpor/edy025
   Chauhan P, 2021, J AMB INTEL HUM COMP, V12, P2601, DOI 10.1007/s12652-020-02423-y
   Clark TS, 2018, J LAW COURTS, V6, P93, DOI 10.1086/695423
   Conover M., 2011, P INT AAAI C WEB SOC, V5, P89
   Couper MP, 2013, SURV RES METHODS-GER, V7, P145
   Daas P, 2012, 201221 CTR BUR VOOR
   Dahlberg S, 2020, Z VGL POLITIKWISSENS, V14, P425, DOI 10.1007/s12286-020-00472-3
   Davis Matthew A, 2017, J Med Internet Res, V19, pe167, DOI 10.2196/jmir.6946
   De Heer W., 2002, Survey nonresponse, V41
   De Sio L, 2020, WEST EUR POLIT, V43, P720, DOI 10.1080/01402382.2019.1655968
   Del Vicario M, 2016, P NATL ACAD SCI USA, V113, P554, DOI 10.1073/pnas.1517441113
   Diaz F, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0145406
   Dubois E, 2020, SOC SCI COMPUT REV, V38, P57, DOI 10.1177/0894439318791527
   Eberl JM, 2020, J INF TECHNOL POLITI, V17, P48, DOI 10.1080/19331681.2019.1710318
   Ellison NB, 2011, PRIVACY ONLINE: PERSPECTIVES ON PRIVACY AND SELF-DISCLOSURE IN THE SOCIAL WEB, P19, DOI 10.1007/978-3-642-21521-6_3
   Ernst N, 2017, INFORM COMMUN SOC, V20, P1347, DOI 10.1080/1369118X.2017.1329333
   Gayo-Avello D, 2013, SOC SCI COMPUT REV, V31, P649, DOI 10.1177/0894439313493979
   Gayo-Avello D, 2011, COMMUN ACM, V54, P121, DOI 10.1145/2001269.2001297
   González-Bailón S, 2014, SOC NETWORKS, V38, P16, DOI 10.1016/j.socnet.2014.01.004
   Greene J. C., 1989, EDUC EVAL POLICY AN, V11, P255, DOI [10.3102/01623737011003255, DOI 10.3102/01623737011003255, https://doi.org/10.3102/01623737011003255]
   Groves RM, 2006, PUBLIC OPIN QUART, V70, P646, DOI 10.1093/poq/nfl033
   Groves RM, 2010, PUBLIC OPIN QUART, V74, P849, DOI 10.1093/poq/nfq065
   Habermas J., 1991, STRUCTURAL TRANSFORM
   Hatipoglu E, 2019, ALL AZIMUTH, V8, P183
   Herbst S., 1998, READING PUBLIC OPINI
   Jacobs K, 2019, INFORM COMMUN SOC, V22, P1681, DOI 10.1080/1369118X.2018.1449883
   Japec L, 2015, PUBLIC OPIN QUART, V79, P839, DOI 10.1093/poq/nfv039
   Johnson TP, 2017, SPRING GEOGR, P113, DOI 10.1007/978-3-319-40902-3_7
   Jungherr A, 2016, J INF TECHNOL POLITI, V13, P72, DOI 10.1080/19331681.2015.1132401
   Karlsen R, 2016, INT J PRESS/POLIT, V21, P338, DOI 10.1177/1940161216645335
   Keeter S, 2007, PUBLIC OPIN QUART, V71, P772, DOI 10.1093/poq/nfm053
   Kim DongSung., 2014, International Journal of Multimedia and Ubiquitous Engineering, V9, P373, DOI [DOI 10.14257/IJMUE.2014.9.11.36, 10.14257/ijmue.2014.9.11.36]
   Klasnja Marko., 2018, The Oxford Handbook of Polling and Survey Methods, P555
   Kreuter F, 2008, PUBLIC OPIN QUART, V72, P847, DOI 10.1093/poq/nfn063
   Lee Taeku., 2002, Mobilizing Public Opinion: Black Insurgency and Racial Attitudes in the Civil Rights Era
   Loureiro ML, 2020, ENERG POLICY, V143, DOI 10.1016/j.enpol.2020.111490
   Lukoianova T., 2014, WORKSH ADV CLASS RES, V24, P4, DOI DOI 10.7152/ACRO.V24I1.14671
   Lyberg, 2017, TOTAL SURVEY ERROR P, DOI DOI 10.1002/9781119041702.CH22
   McGregor SC, 2019, JOURNALISM, V20, P1070, DOI 10.1177/1464884919845458
   Metzler K., 2016, WHO IS DOING COMPUTA
   Moy P, 2016, J MASS COMMUN Q, V93, P16, DOI 10.1177/1077699016631108
   Murphy J, 2011, P 10 C HLTH SURV RES, P231
   OConnor B, 2010, ICWSM, P122, DOI DOI 10.1609/ICWSM.V4I1.14031
   Olteanu A, 2019, FRONT BIG DATA, V2, DOI 10.3389/fdata.2019.00013
   Park M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177865
   Pavalanathan U, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P315, DOI 10.1145/2740908.2743049
   Plescia C., 2019, REPRESENTATION, V55, P513, DOI [DOI 10.1080/00344893.2019.1635197, https://doi.org/10.1080/00344893.2019.1635197]
   Robillard JM, 2013, J MED INTERNET RES, V15, P222, DOI 10.2196/jmir.2313
   Rousidis D, 2020, MULTIMED TOOLS APPL, V79, P6279, DOI 10.1007/s11042-019-08291-9
   Scarborough WilliamJ., 2018, Socius, V4, P1, DOI DOI 10.1177/2378023118780760
   Schober MF, 2020, BIGSURV20 BIG DAT ME
   Schober MF, 2016, PUBLIC OPIN QUART, V80, P180, DOI 10.1093/poq/nfv048
   Sen I., 2019, TOTAL ERROR FRAMEWOR
   Shin J, 2020, SOC MEDIA SOC, V6, DOI 10.1177/2056305120981039
   Stier S, 2020, SOC SCI COMPUT REV, V38, P503, DOI 10.1177/0894439319843669
   Tavoschi L, 2020, HUM VACC IMMUNOTHER, V16, P1062, DOI 10.1080/21645515.2020.1714311
   Thompson L, 2015, CYBERPSYCH BEH SOC N, V18, P311, DOI 10.1089/cyber.2014.0620
   Tourangeau R., 2008, The SAGE handbook of public opinion research, P141
   Trepte S, 2011, PRIVACY ONLINE: PERSPECTIVES ON PRIVACY AND SELF-DISCLOSURE IN THE SOCIAL WEB, P1, DOI 10.1007/978-3-642-21521-6
   Turow J., 2015, 2820060 SSRN
   Vaccari C, 2016, SOC MEDIA SOC, V2, DOI 10.1177/2056305116664221
   Varol Onur, 2017, P INT AAAI C WEB SOC, P280, DOI DOI 10.1609/ICWSM.V11I1.14871
NR 79
TC 10
Z9 11
U1 7
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 FEB 14
PY 2022
DI 10.1007/s11042-022-12101-0
EA FEB 2022
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZA9TO
UT WOS:000756497800023
PM 35194384
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Ben Chaabane, S
   Hijji, M
   Harrabi, R
   Seddik, H
AF Ben Chaabane, Slim
   Hijji, Mohammad
   Harrabi, Rafika
   Seddik, Hassene
TI Face recognition based on statistical features and SVM classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature extraction; Statistical features; Principal
   component analysis; True success rate; Support vector machine;
   Classification
AB In this paper, a face recognition method based on statistical features and Support Vector Machine (SVM) algorithm is proposed. The statistical analysis is used to extract and select the statistical features, whereas, the SVM algorithm is employed to merge and classify the different features in order to increase the quality of the information and to obtain an optimal Human face recognition. Human face recognition results from the proposed method are validated and the True Success Rate (TSR) for the test data available is evaluated, and then a comparative study versus existing techniques is presented. The experimental results with 400 test images of 40 persons demonstrate the superiority of introducing the statistical features in SVM algorithm for human face recognition. In addition, the recognition speed of our method is faster than the classical SVM algorithm and other existing methods. Experimental results show that the algorithm identifies the face images with accuracy of 99.37%.
C1 [Ben Chaabane, Slim; Harrabi, Rafika] Univ Tabuk, Comp Engn Dept, Tabuk 47512, Saudi Arabia.
   [Ben Chaabane, Slim; Harrabi, Rafika; Seddik, Hassene] Univ Tunis, Elect Engn Dept, CEREP, ENSIT 5 Av, Tunis 1008, Tunisia.
   [Hijji, Mohammad] Univ Tabuk, Comp Sci Dept, Tabuk 47512, Saudi Arabia.
C3 University of Tabuk; Universite de Tunis; University of Tabuk
RP Ben Chaabane, S (corresponding author), Univ Tabuk, Comp Engn Dept, Tabuk 47512, Saudi Arabia.; Ben Chaabane, S (corresponding author), Univ Tunis, Elect Engn Dept, CEREP, ENSIT 5 Av, Tunis 1008, Tunisia.
EM s.chaabane@ut.edu.sa
RI HARRABI, RAFIKA/HSE-4591-2023; BEN CHAABANE, Slim/ACX-3297-2022; Hijji,
   Mohammad/HMP-1048-2023
OI BEN CHAABANE, Slim/0000-0003-0882-0057; Hijji,
   Mohammad/0000-0001-9279-401X
FU Industrial Innovation and Robotics Center, University of Tabuk
FX This research was partially sponsored by the Industrial Innovation and
   Robotics Center, University of Tabuk.
CR Arigbabu O. A., 2017, ARXIV170202537
   Bastanfard A, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P306, DOI 10.1109/CW.2004.65
   Bastanfard A, 2004, COMPUT ANIMAT VIRT W, V15, P347, DOI 10.1002/cav.38
   Beli ILK, 2017, J IMAGING, V3, DOI 10.3390/jimaging3030037
   Ben Chaabane S, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-4
   Ben Chaabane S, 2011, CIRC SYST SIGNAL PR, V30, P55, DOI 10.1007/s00034-010-9207-3
   Bhangale K.B., 2018, International Journal of Management, Technology and Engineering, V8, P1026
   Bonnen K, 2013, IEEE T INF FOREN SEC, V8, P239, DOI 10.1109/TIFS.2012.2226580
   Chaabane SB, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/367297
   Chalabi NE, 2021, MULTIMED TOOLS APPL, V80, P33257, DOI 10.1007/s11042-021-11367-0
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Fathima AA, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER GRAPHICS, VISION AND INFORMATION SECURITY (CGVIS), P220, DOI 10.1109/CGVIS.2015.7449925
   Gumus Ergun, 2014, WAVELETS SVM EXPERT, P6404
   Harifi S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON COMPUTING TECHNOLOGY AND INFORMATION MANAGEMENT (ICCTIM), P115, DOI 10.1109/ICCTIM.2015.7224603
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Nisha MD., 2017, Int. J. Exp. Diabetes Res, V5, P297
   OUERHANI Y., 2010, Proceedings of the 2010 IEEE International Conference on Imaging Systems and Techniques, Thessaloniki, Greece, 1-2 July 2010, P80
   Patel NP, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMMUNICATION AND COMPUTING TECHNOLOGY (ICACCT), P251, DOI 10.1109/ICACCT.2018.8529622
   Pei JF, 2013, IEEE INT C BIOINFORM
   Priya T.S. V., 2018, Int. J. Pure Appl. Math, V119, P1895
   Ren JF, 2013, IEEE IMAGE PROC, P3680, DOI 10.1109/ICIP.2013.6738759
   Sharma R, 2015, OPTIK, V126, P3483, DOI 10.1016/j.ijleo.2015.08.205
   Shen WC, 1997, P IEEE, V85, P1464, DOI 10.1109/5.628719
   Socolinsky DA, 2004, PROC CVPR IEEE, P1012
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   ul Hussain S, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.99
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wang N, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P217, DOI 10.1109/ISBAST.2013.38
   Wang N, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.2.023013
   Wang Q, 2017, ADV OPT PHOTONICS, V9, P1, DOI 10.1364/AOP.9.000001
   Xi M, 2016, IEEE IMAGE PROC, P3224, DOI 10.1109/ICIP.2016.7532955
   Yang WC, 2018, PATTERN RECOGN, V78, P242, DOI 10.1016/j.patcog.2018.01.026
   Zeebaree, 2020, COMPUTATIONAL BIOL J
   Zhao CH, 2015, OPTIK, V126, P1761, DOI 10.1016/j.ijleo.2015.04.068
NR 34
TC 20
Z9 20
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 8767
EP 8784
DI 10.1007/s11042-021-11816-w
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000751584600001
DA 2024-07-18
ER

PT J
AU Bhattacharjee, V
   Sahu, R
   Dutta, A
AF Bhattacharjee, Vandana
   Sahu, Raj
   Dutta, Amit
TI Enhanced Graph Representations for Graph Convolutional Network Models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Graph convolutional networks; Embeddings; Citation graphs; Overlap
   measures
ID LABEL PROPAGATION; CITATION
AB Graph Convolutional Network (GCN) is increasingly becoming popular among researchers for its capability of solving the task of classification of nodes, graphs or links. Graphs being a very useful representation for several application domains are increasingly grabbing the attention of researchers. Methods are being proposed to extract meaningful information in a form which can be used by machine learning tasks. Graph convolutional networks(GCN) fall among such methods. They propagate and transform node features information. Following the message passing strategy, a Graph neural network learns a node's embeddings representations by aggregating representations of its neighbours and itself. In this research work we incorporate the concept of overlap to the graph data thus capturing the structural similarities in the node features. The intuition behind this proposal is that the class or label of a document represented by node v(i) is influenced by its own node features and the node features of its neighbourhood. It is proposed to enhance the graph representation to capture this neighbourhood. This enhanced graph is then input to the graph convolutional network model for the classification task. These measures are seen to improve the accuracy of node classification. Experiments on a number of datasets with different similarity measures demonstrate that enhancing graph representations produces better results in terms of classification accuracy.
C1 [Bhattacharjee, Vandana; Sahu, Raj; Dutta, Amit] Birla Inst Technol, Ranchi, Bihar, India.
C3 Birla Institute of Technology Mesra
RP Bhattacharjee, V (corresponding author), Birla Inst Technol, Ranchi, Bihar, India.
EM vbhattacharya@bitmesra.ac.in; iamrajkashyap@gmail.com;
   amitdutta2406@gmail.com
RI Bhattacharjee, Vandana/IZP-5454-2023
OI BHATTACHARJEE, VANDANA/0000-0002-0680-2691
FU Birla Institute of Technology, Mesra, Ranchi
FX The research has been supported by Birla Institute of Technology, Mesra,
   Ranchi.
CR An Y, 2004, KNOWL INF SYST, V6, P664, DOI 10.1007/s10115-003-0128-3
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Berger-Wolf T, 2018, KDD 18
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Clough JR, 2015, J COMPLEX NETW, V3, P189, DOI 10.1093/comnet/cnu039
   Cui ZY, 2020, IEEE T INTELL TRANSP, V21, P4883, DOI 10.1109/TITS.2019.2950416
   Dai HJ, 2016, PR MACH LEARN RES, V48
   Defferrard M, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang Y, 2001, SCIENTOMETRICS, V50, P273
   Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947
   Gehring J, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P123, DOI 10.18653/v1/P17-1012
   Gong C, 2017, IEEE T NEUR NET LEAR, V28, P1452, DOI 10.1109/TNNLS.2016.2514360
   GORI M, 2005, IEEE IJCNN, P729, DOI DOI 10.1109/IJCNN.2005.1555942
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hammond DK, 2011, APPL COMPUT HARMON A, V30, P129, DOI 10.1016/j.acha.2010.04.005
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Joan B, 2014, ABS13126203 CORR
   Karasuyama Masayuki, 2013, Adv. Neural Inf. Process. Syst., V26, P1547
   Kipf TN, 2017, INT C LEARN REPR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leo E, 1990, INTRO INFORMETRICS Q, P228
   Leow Y. Y., 2019, P ICLR WORKSH REPR L
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Liao R., 2019, ICLR
   Liu YH, 2019, INT J PSYCHIAT CLIN, V23, P164, DOI 10.1080/13651501.2019.1569238
   Lu WZ, 2007, KNOWL INF SYST, V11, P105, DOI 10.1007/s10115-006-0023-9
   Luong T., 2015, P 2015 C EMP METH NA, DOI [DOI 10.18653/V1/D15-1166, 10.18653/v1/D15-1166]
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Monti F, 2017, ADV NEUR IN, V30
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Qu M, 2019, PR MACH LEARN RES, V97
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosenfeld, 2005, SEMISUPERVISED LEARN
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Sen P, 2008, AI MAG, V29, P93, DOI 10.1609/aimag.v29i3.2157
   Seo Y, 2018, LECT NOTES COMPUT SC, V11301, P362, DOI 10.1007/978-3-030-04167-0_33
   Shi XY, 2021, MULTIMED TOOLS APPL, V80, P8355, DOI 10.1007/s11042-020-09885-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun Y, 2021, ARTIF INTELL, V12737, DOI [10.1007/978-3-030-78612-0_13, DOI 10.1007/978-3-030-78612-0_13]
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Velickovic Petar, 2018, INT C LEARN REPR
   Wang DX, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1225, DOI 10.1145/2939672.2939753
   Wang F, 2008, IEEE T KNOWL DATA EN, V20, P55, DOI 10.1109/TKDE.2007.190672
   Wang H., 2020, ARXIV200206755
   Weston Jason, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P639, DOI 10.1007/978-3-642-35289-8_34
   Xiao GN, 2021, MULTIMED TOOLS APPL, V80, P22907, DOI 10.1007/s11042-020-08803-y
   Xiao LW, 2022, MULTIMED TOOLS APPL, V81, P19051, DOI 10.1007/s11042-020-10107-0
   Xu K, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350934
   Yi L, 2017, PROC CVPR IEEE, P6584, DOI 10.1109/CVPR.2017.697
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3634
   Zhang BX, 2022, MULTIMED TOOLS APPL, V81, P34263, DOI 10.1007/s11042-021-11033-5
   Zhang Z., 2007, P INT C NEUR INF PRO, P1593
   Zhao D., 2015, ANAL VISUALIZATION C
   Zhou K., 2019, ARXIV190903184
   Zhu X, 2021, MULTIMED TOOLS APPL, V80, P16247, DOI 10.1007/s11042-020-08790-0
   Zitnik M, 2017, BIOINFORMATICS, V33, pI190, DOI 10.1093/bioinformatics/btx252
NR 66
TC 0
Z9 0
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9649
EP 9666
DI 10.1007/s11042-021-11843-7
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000749966800006
DA 2024-07-18
ER

PT J
AU Ribas-Xirgo, L
AF Ribas-Xirgo, Lluis
TI A state-based multi-agent system model of taxi fleets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous mobile robots; BDI agents; Cooperating robots; Finite-state
   stack machines; MAS; State-based modelling; Traffic simulation
ID CONTRACT NET PROTOCOL; EFFICIENCY
AB Management and control of transportation systems benefit from simulation modeling. The design of the corresponding models is difficult because of their complexity. Multi-agent systems cope with this problem by a divide-and-conquer approach. However, agent model design is still quite a challenge. In this paper, we propose a layered architecture for agents where each component is a kind of a stack-based state machine of our own. This model complements extended finite-state machines with some basic state stack operations that enable not only dealing with hierarchy but also with planning, which is a key element for belief-desire-intention (BDI) agents. Special care was taken to make the representation of these extended finite-state stack machines ((EFSM)-M-2) simple so that their programming is straightforward. Through an educational example we show how such class of models are, and the potentiality of the solution. The taxi fleet simulation model is a metaphor for transportation systems in structured environments like factories or warehouses but can also be used as a vehicle traffic simulator. As for the latter case, we illustrate how it can be used to determine the efficiency and the quality of service of a taxi fleet in an urban area.
C1 [Ribas-Xirgo, Lluis] Univ Autonoma Barcelona, Microelect & Elect Syst Dept, Barcelona 08193, Spain.
C3 Autonomous University of Barcelona
RP Ribas-Xirgo, L (corresponding author), Univ Autonoma Barcelona, Microelect & Elect Syst Dept, Barcelona 08193, Spain.
EM Lluis.Ribas@uab.cat
OI Ribas-Xirgo, Lluis/0000-0003-1419-0485
CR Berry Gerard, 2004, The Esterel v5 Language Primer Version v5.91
   Boukredera D, 2012, FRONT ARTIF INTEL AP, V241, P83, DOI 10.3233/978-1-61499-096-3-83
   Casas J, 2010, INT SER OPER RES MAN, V145, P173, DOI 10.1007/978-1-4419-6142-6_5
   Hörl S, 2017, PROCEDIA COMPUT SCI, V109, P899, DOI 10.1016/j.procs.2017.05.418
   Kim H, 2005, TRANSPORT RES REC, P96, DOI 10.3141/1903-11
   Kim KH., 2011, CONTAINER TERMINALS
   Li ZW., 2009, INT J PROD RES, V48, P5541
   Nguyen J, 2021, OVERVIEW AGENT BASED, P51
   Perronnet F, 2019, IEEE T INTELL TRANSP, V20, P4219, DOI 10.1109/TITS.2018.2886247
   Postorino M. N., 2016, CEUR WORKSHOP PROC, V1664, P112
   Ptolemaeus C., 2014, System Design, Modeling, and Simulation using Ptolemy II
   Qin GY, 2017, TRANSPORT RES C-EMER, V79, P103, DOI 10.1016/j.trc.2017.03.013
   Ribas-Xirgo Ll., 2021, ADV PHYS AGENTS 2 WA
   Ribas-Xirgo Ll, 2020, MASLUA HOM
   Rivas D, 2019, IEEE INT C EMERG, P947, DOI [10.1109/etfa.2019.8869302, 10.1109/ETFA.2019.8869302]
   Rivas D, 2018, IEEE INT C EMERG, P1179, DOI 10.1109/ETFA.2018.8502451
   Rivas-Alonso D., 2018, ADV PHYS AGENTS
   Sakellariou I., 2009, P INT WKSHP ED US MU, P47
   Salanova JM, 2011, PROCD SOC BEHV, V20, DOI 10.1016/j.sbspro.2011.08.020
   SMITH RG, 1980, IEEE T COMPUT, V29, P1104, DOI 10.1109/TC.1980.1675516
   Yeung WL, 2018, INT J COMPUT INTEG M, V31, P1005, DOI 10.1080/0951192X.2018.1493227
   Zhang RD, 2020, IEEE T INTELL TRANSP, V21, P4123, DOI 10.1109/TITS.2019.2938762
NR 22
TC 0
Z9 0
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3515
EP 3534
DI 10.1007/s11042-021-11607-3
EA JAN 2022
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000742319000001
DA 2024-07-18
ER

PT J
AU Orjesek, R
   Jarina, R
   Chmulik, M
AF Orjesek, Richard
   Jarina, Roman
   Chmulik, Michal
TI End-to-end music emotion variation detection using iteratively
   reconstructed deep features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music emotion recognition; Arousal; Valence; End-to-end deep learning;
   Bi-directional gated recurrent unit; Iterative reconstruction
ID MODEL
AB Automatic music emotion recognition (MER) has received increased attention in areas of music information retrieval and user interface development. Music emotion variation detection (or dynamic MER) captures also temporal changes of emotion, and emotional content in music is expressed as a series of valence-arousal predictions. One of the issues in MER is extraction of emotional characteristics from audio signal. We propose a deep neural network based solution for mining music emotion-related salient features directly from raw audio waveform. The proposed architecture is based on stacking one-dimensional convolution layer, autoencoder-based layer with iterative reconstruction, and bidirectional gated recurrent unit. The tests on the DEAM dataset have shown that the proposed solution, in comparison with other state-of-the-art systems, can bring a significant improvement of the regression accuracy, notably for the valence dimension. It is shown that the proposed iterative reconstruction layer is able to enhance the discriminative properties of the features and further increase regression accuracy.
C1 [Orjesek, Richard] BrainItsk, Zilina, Slovakia.
   [Orjesek, Richard; Jarina, Roman; Chmulik, Michal] Univ Zilina, Zilina, Slovakia.
C3 University of Zilina
RP Jarina, R (corresponding author), Univ Zilina, Zilina, Slovakia.
EM roman.jarina@uniza.sk
RI Chmulik, Michal/IQW-1183-2023; Jarina, Roman/E-2541-2018
OI Chmulik, Michal/0000-0002-0513-5129; Jarina, Roman/0000-0002-0478-5808
CR Aljanaki A, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173392
   Amiriparian S, 2019, P MEDIAEVAL 2019 WOR
   [Anonymous], DEAM DATASET MEDIAEV
   [Anonymous], 2016, IJCAI
   [Anonymous], 2016, IEEE Energy Conversion Congress and Exposition ECCE
   [Anonymous], 2015, MEDIAEVAL 2015 WORKS
   [Anonymous], 2018, P ISMIR 2018 19 INT
   Bai JJ, 2016, 2016 IEEE 15TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P42, DOI 10.1109/ICCI-CC.2016.7862063
   Barthet M, 2013, LECT NOTES COMPUT SC, V7900, P228, DOI 10.1007/978-3-642-41248-6_13
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Cheung KP, 2020, INT RELIAB PHY SYM, DOI 10.1109/irps45951.2020.9128354
   Choi K, 2017, INT CONF ACOUST SPEE, P2392, DOI 10.1109/ICASSP.2017.7952585
   Coutinho E., 2015, P MEDIAEVAL 2015 WOR
   Coutinho E, 2011, EMOTION, V11, P921, DOI 10.1037/a0024700
   Deng JJ, 2015, IEEE T AFFECT COMPUT, V6, P137, DOI 10.1109/TAFFC.2015.2404352
   Dieleman Sander, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6964, DOI 10.1109/ICASSP.2014.6854950
   Dong YZ, 2019, IEEE T MULTIMEDIA, V21, P3150, DOI 10.1109/TMM.2019.2918739
   Eerola T, 2011, PSYCHOL MUSIC, V39, P18, DOI 10.1177/0305735610362821
   Goodfellow I. J., 2013, P 30 INT C MACHINE L, V28
   Inskip C, 2012, INT J DIGIT LIBRARIE, V12, P137, DOI 10.1007/s00799-012-0084-1
   Jarina R, 2019, P 29 INT C RAD APR 2, P1
   Kakade S., 2016, 5 INT C LEARN REPR I
   Kim J, 2020, NEURAL COMPUT APPL, V32, P1067, DOI 10.1007/s00521-019-04076-1
   Lim W, 2016, ASIAPAC SIGN INFO PR, DOI 10.1109/APSIPA.2016.7820699
   Malik M., 2017, Proc. Sound Music Comput. Conf, P208
   Markov K, 2014, IEEE ACCESS, V2, P688, DOI 10.1109/ACCESS.2014.2333095
   Panda R, 2020, IEEE T AFFECT COMPUT, V11, P614, DOI 10.1109/TAFFC.2018.2820691
   Richard G, 2013, P IEEE, V101, P1939, DOI 10.1109/JPROC.2013.2251591
   Sarkar R, 2020, MULTIMED TOOLS APPL, V79, P765, DOI 10.1007/s11042-019-08192-x
   Sharan RV, 2016, NEUROCOMPUTING, V200, P22, DOI 10.1016/j.neucom.2016.03.020
   Tokozume Y, 2017, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.2017.7952651
   Trigeorgis G, 2016, INT CONF ACOUST SPEE, P5200, DOI 10.1109/ICASSP.2016.7472669
   Tzirakis P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5089, DOI 10.1109/ICASSP.2018.8462677
   Wang SF, 2015, MULTIMED TOOLS APPL, V74, P1863, DOI 10.1007/s11042-013-1722-3
   Wei W, 2020, INT CONF ACOUST SPEE, P276, DOI [10.1109/ICASSP40776.2020.9054248, 10.1109/icassp40776.2020.9054248]
   Yang XY, 2018, MULTIMEDIA SYST, V24, P365, DOI 10.1007/s00530-017-0559-4
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yang YH, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168754
NR 38
TC 10
Z9 10
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5017
EP 5031
DI 10.1007/s11042-021-11584-7
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000740429700032
DA 2024-07-18
ER

PT J
AU Paul, S
   Saha, S
   Singh, JP
AF Paul, Sayanta
   Saha, Sriparna
   Singh, Jyoti Prakash
TI COVID-19 and cyberbullying: deep ensemble model to identify
   cyberbullying from code-switched languages during the pandemic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural language processing; Cyberbullying; Code-switched language; Deep
   ensemble
AB It has been declared by the World Health Organization (WHO) the novel coronavirus a global pandemic due to an exponential spread in COVID-19 in the past months reaching over 100 million cases and resulting in approximately 3 million deaths worldwide. Amid this pandemic, identification of cyberbullying has become a more evolving area of research over posts or comments in social media platforms. In multilingual societies like India, code-switched texts comprise the majority of the Internet. Identifying the online bullying of the code-switched user is bit challenging than monolingual cases. As a first step towards enabling the development of approaches for cyberbullying detection, we developed a new code-switched dataset, collected from Twitter utterances annotated with binary labels. To demonstrate the utility of the proposed dataset, we build different machine learning (Support Vector Machine & Logistic Regression) and deep learning (Multilayer Perceptron, Convolution Neural Network, BiLSTM, BERT) algorithms to detect cyberbullying of English-Hindi (En-Hi) code-switched text. Our proposed model integrates different handcrafted features and is enriched by sequential and semantic patterns generated by different state-of-the-art deep neural network models. Initial experimental results of the proposed deep ensemble model on our code-switched data reveal that our approach yields state-of-the-art results, i.e., 0.93 in terms of macro-averaged F1 score. The dataset and codes of the present study will be made publicly available on the paper's companion repository [https:// github.com/95sayanta/COVID-19-and-Cyberbullying].
C1 [Paul, Sayanta; Saha, Sriparna] Indian Inst Technol Patna, Bihta, India.
   [Singh, Jyoti Prakash] Natl Inst Technol Patna, Patna, Bihar, India.
C3 Indian Institute of Technology (IIT) - Patna; National Institute of
   Technology (NIT System); National Institute of Technology Patna
RP Saha, S (corresponding author), Indian Inst Technol Patna, Bihta, India.
EM 1811cs16@iitp.ac.in; sriparna@iitp.ac.in; jps@nitp.ac.in
RI Singh, Jyoti Prakash/I-4953-2016
OI Singh, Jyoti Prakash/0000-0002-3742-7484
CR Al-garadr MA, 2016, COMPUT HUM BEHAV, V63, P433, DOI 10.1016/j.chb.2016.05.051
   Bai S., 2018, CoRR
   Bansal S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P1018
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Devlin J., 2018, BERT PRE TRAINING DE
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Faruqui C., 2014, P 14 C EUR CHAPT ASS, P462, DOI [10.3115/v1/E14-1049, DOI 10.3115/V1/E14-1049]
   Genkin A, 2007, TECHNOMETRICS, V49, P291, DOI 10.1198/004017007000000245
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Grave E, 2018, PROCEEDINGS OF THE ELEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2018), P3483
   Hosseinmardi H, 2016, PROCEEDINGS OF THE 2016 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING ASONAM 2016, P186, DOI 10.1109/ASONAM.2016.7752233
   Jacovi Alon, 2018, P 2018 EMNLP WORKSHO, DOI DOI 10.18653/V1/W18-5408
   Jaech A, 2016, ARXIV PREPRINT ARXIV
   Krishnan J., 2021, MULTILINGUAL CODE SW
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Myers-Scotton Carol, 1993, DUELLING LANGUAGES G
   Parshad RD, 2016, PHYSICA A, V449, P375, DOI 10.1016/j.physa.2016.01.015
   Rao PR, 2016, CMEE IL CODE MIX ENT, P289
   Rosa H, 2018, IEEE IJCNN, P323
   Rudra Koustav, 2016, P 2016 C EMPIRICAL M, P1131
   Settles B., 2008, P NIPS WORKSHOP COST, VVolume 1
   Shakeel MH, 2020, PROCEEDINGS OF THE 35TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING (SAC'20), P903, DOI 10.1145/3341105.3374091
   Smith PK, 2008, J CHILD PSYCHOL PSYC, V49, P376, DOI 10.1111/j.1469-7610.2007.01846.x
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Vaswani A, 2017, ADV NEUR IN, V30
   Zhang X, 2016, 2016 15TH IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2016), P740, DOI [10.1109/ICMLA.2016.0132, 10.1109/ICMLA.2016.71]
   Zhao R., 2016, P 17 INT C DISTR COM, P1, DOI DOI 10.1145/2833312.2849567
   Zhou P., 2016, ARXIV161106639
NR 28
TC 11
Z9 11
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 8773
EP 8789
DI 10.1007/s11042-021-11601-9
EA JAN 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000740429700028
PM 35035263
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Yao, XM
AF Yao, Xiaoming
TI VPP_AHA: Visual Privacy Protection via Adaptive Histogram Adjustment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive coloration; Histogram adjustment; De-identification;
   Camouflage; Visual privacy protection
ID SYSTEM
AB A novel visual privacy protection (VPP) algorithm is proposed for camouflage of the visual identifiers in digital images. The challenge is to suffice the de-identification with a different look. This issue has been previously addressed by two classes of algorithms, i.e. modifying target features with or without a reference. The former ran well by finding a surrogate from randomized hybrid features between the target and the reference, and the latter made it by blurring or hiding the details of the region. Inspired by camouflage in animals for self-concealment, this paper presents a simple and efficient algorithm that imitates such behavior via adaptive histogram shift adjustment without a reference. The image is first blurred and segmented into several flat surfaces, then adaptively re-joined or split by shifts randomly chosen to produce the de-identified output. It is found that the success of the surface-based feature redaction depends on the shift diversity, the saliency, and coverage of the surfaces segmented, which are used as adjusting parameters for the camouflage. Extensive examples of real and synthetic images have demonstrated that our results compare favorably to those obtained by existing VPP methods, with required security, robustness, and selective reversibility.
C1 [Yao, Xiaoming] Hainan Univ, Sch Cyber Secur, Haikou 570228, Hainan, Peoples R China.
C3 Hainan University
RP Yao, XM (corresponding author), Hainan Univ, Sch Cyber Secur, Haikou 570228, Hainan, Peoples R China.
EM xiaomingyao@163.com
OI yao, xiaoming/0000-0003-2959-3500
CR AMP Lab, CORN MULT DAT
   Boult TE, 2006, COMPUTER VISION FOR INTERACTIVE AND INTELLIGENT ENVIRONMENTS, P27
   Cayre F, 2008, IEEE T INF FOREN SEC, V3, P1, DOI 10.1109/TIFS.2007.916006
   Chinomi K, 2008, LECT NOTES COMPUT SC, V4903, P144
   Çiftçi S, 2018, IEEE T MULTIMEDIA, V20, P68, DOI 10.1109/TMM.2017.2728479
   Cott H.B., 1940, AM NAT
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Dale K, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024164
   Di Martino JM, 2016, IMAGE PROCESS ON LIN, V6, P300, DOI 10.5201/ipol.2016.163
   Driessen B, COMMUNICATIONS MULTI, V8099, DOI [10.1007/978-3-642-40779-6_2, DOI 10.1007/978-3-642-40779-6_2]
   Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225
   Fan LY, 2018, LECT NOTES COMPUT SC, V10980, P148, DOI 10.1007/978-3-319-95729-6_10
   Farrugia RA, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1258, DOI 10.1109/MIPRO.2014.6859760
   Fleck S, 2008, P IEEE, V96, P1698, DOI 10.1109/JPROC.2008.928765
   Gafni O, 2019, IEEE I CONF COMP VIS, P9377, DOI 10.1109/ICCV.2019.00947
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Hari B, ROBUST FACE RECOGNIT
   Jourabloo A, 2015, INT CONF BIOMETR, P278, DOI 10.1109/ICB.2015.7139096
   Kanizsa G, 1979, ORG VISION ESSAYS GE
   Korshunov P, 2013, P 18 INT C DIG SIGN
   Korshunov P, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P208, DOI 10.1109/AVSS.2013.6636641
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Letournel G, 2015, IEEE IMAGE PROC, P4366, DOI 10.1109/ICIP.2015.7351631
   Li X, 2017, IEEE ACCESS, V5, P24332, DOI 10.1109/ACCESS.2017.2767622
   Li Yuanjun., 2019, SPE Annual Technical Conference and Exhibition, p16. isbn, DOI [DOI 10.2118/196011-MS, 10.2118/196011-MS]
   Merilaita S, 2017, PHILOS T R SOC B, V372, DOI 10.1098/rstb.2016.0341
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Nakashima Y, 2016, IEEE SECUR PRIV, V14, P55, DOI 10.1109/MSP.2016.3
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Paruchuri JK, 2009, EURASIP J INF SECUR, DOI 10.1155/2009/236139
   Padilla-López JR, 2015, SENSORS-BASEL, V15, P12959, DOI 10.3390/s150612959
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Ribaric S, 2016, SIGNAL PROCESS-IMAGE, V47, P131, DOI 10.1016/j.image.2016.05.020
   Saini M. K., 2013, INT J TRUST MANAGEME, V1, P23
   Saini M, 2010, IEEE INT CON MULTI, P60, DOI 10.1109/ICME.2010.5583334
   Venkatanath N, 2015, NATL CONF COMMUN
   Waltemate T, 2018, IEEE T VIS COMPUT GR, V24, P1643, DOI 10.1109/TVCG.2018.2794629
   Winkler G, 1995, IMAGE ANAL RANDOM FI
NR 39
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6277
EP 6303
DI 10.1007/s11042-021-11749-4
EA JAN 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000740419000003
DA 2024-07-18
ER

PT J
AU Garg, H
   Gupta, N
   Agrawal, R
   Shivani, S
   Sharma, B
AF Garg, Hitendra
   Gupta, Neeraj
   Agrawal, Rohit
   Shivani, Shivendra
   Sharma, Bhisham
TI A real time cloud-based framework for glaucoma screening using
   EfficientNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud-based; Glaucoma; Convolutional neural network; Real-time;
   EfficientNet
ID OPTIC CUP SEGMENTATION; FUNDUS IMAGES; DISC; SYSTEM
AB These days one of the major causes of partial or complete blindness that has affected a majority of people all around the world is glaucoma. Glaucoma is caused as a result of increased fluid pressure inside the optic nerves called intra ocular pressure. A real time cloud-based framework for screening the glaucoma suspect's retinal fundus images as received by the people on the public cloud, is proposed in this paper. In the proposed framework the existence of glaucoma and analysis of the retinal fundus images is achieved by deep learning technique and convolutional neural network respectively. EfficientNet and UNet++ models are used to identify the presence of glaucoma. On comparing our framework to various state-of-the-art models and quantitative assessment are performing on various benchmark datasets like RIM-ONE and DRISHTI-GS1, it was found that the proposed framework is scalable, location independent, and easily accessible to one and all due to the cloud platform.
C1 [Garg, Hitendra; Gupta, Neeraj; Agrawal, Rohit] GLA Univ, Mathura, Uttar Pradesh, India.
   [Shivani, Shivendra] Thapar Univ, Patiala, Punjab, India.
   [Sharma, Bhisham] Chitkara Univ, Sch Engn & Technol, Chandigarh, Himachal Prades, India.
C3 GLA University; Thapar Institute of Engineering & Technology; Chitkara
   University, Punjab
RP Sharma, B (corresponding author), Chitkara Univ, Sch Engn & Technol, Chandigarh, Himachal Prades, India.
EM hitendra.garg@gla.ac.in; neeraj.gupta@gla.ac.in; rohitagrwal@gla.ac.in;
   shivendra.shivani@thapar.edu; bhisham.sharma@chitkarauniversity.edu.in
RI Sharma, Bhisham/AAB-7076-2020; Garg, Hitendra/AAV-6756-2020; Shivani,
   Shivendra/AFN-2368-2022
OI Sharma, Bhisham/0000-0002-3400-3504; Shivani,
   Shivendra/0000-0002-5931-6603; Garg, Dr. Hitendra/0000-0002-4273-2328
CR Abdel-Hamid L, 2020, J DIGIT IMAGING, V33, P151, DOI 10.1007/s10278-019-00189-0
   Abdullah M, 2016, PEERJ, V4, DOI 10.7717/peerj.2003
   Aguilar-Rivera M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092570
   Al-Bander B, 2017, INT MULTICONF SYST, P207, DOI 10.1109/SSD.2017.8166974
   Almazroa A, 2017, CLIN OPHTHALMOL, V11, P841, DOI 10.2147/OPTH.S117157
   Arnay R, 2017, APPL SOFT COMPUT, V52, P409, DOI 10.1016/j.asoc.2016.10.026
   Bharkad S, 2017, BIOMED SIGNAL PROCES, V31, P483, DOI 10.1016/j.bspc.2016.09.009
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   Chen XY, 2015, LECT NOTES COMPUT SC, V9351, P669, DOI 10.1007/978-3-319-24574-4_80
   Chrástek R, 2005, P SOC PHOTO-OPT INS, V5747, P1604, DOI 10.1117/12.594492
   Christopher M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-35044-9
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P2493, DOI 10.1109/TMI.2018.2837012
   Fumero F, 2011, COMP MED SY
   Gupta N, 2022, VISUAL COMPUT, V38, P2315, DOI 10.1007/s00371-021-02114-5
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   Gupta N, 2019, MULTIMED TOOLS APPL, V78, P10821, DOI 10.1007/s11042-018-6613-1
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Kande GB, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P535
   Kumar Singh Law, 2019, 2019 International Conference on Computing, Communication, and Intelligent Systems (ICCCIS), P397, DOI 10.1109/ICCCIS48478.2019.8974539
   Li HQ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P394
   Li ZX, 2018, OPHTHALMOLOGY, V125, P1199, DOI 10.1016/j.ophtha.2018.01.023
   Liu SP, 2011, J MED BIOL ENG, V31, P405, DOI 10.5405/jmbe.773
   Lowell J, 2004, IEEE T MED IMAGING, V23, P256, DOI 10.1109/TMI.2003.823261
   Lu SJ, 2011, IEEE T MED IMAGING, V30, P2126, DOI 10.1109/TMI.2011.2164261
   Mehdizadeh M., 2009, Research Journal of Biological Sciences, V4, P922
   Ortega M, 2010, INT J MED INFORM, V79, P722, DOI 10.1016/j.ijmedinf.2010.07.005
   Owoyemi A, 2020, FRONT DIGIT HEALTH, V2, DOI 10.3389/fdgth.2020.00006
   Palaniappan K, 2019, MODEL SIMUL SCI ENG, P543, DOI 10.1007/978-3-030-25886-3_22
   Pallawala PMDS, 2004, LECT NOTES COMPUT SC, V3022, P139
   Quigley HA, 2006, BRIT J OPHTHALMOL, V90, P262, DOI 10.1136/bjo.2005.081224
   Rosenthal A, 2010, J BIOMED INFORM, V43, P342, DOI 10.1016/j.jbi.2009.08.014
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shibata N, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-33013-w
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh LK, 2021, INT J E-HEALTH MED C, V12, P32, DOI 10.4018/IJEHMC.20210701.oa3
   Singh LK, 2021, MED BIOL ENG COMPUT, V59, P333, DOI 10.1007/s11517-020-02307-5
   Singh LK, 2020, ALGO INTELL SY, P241, DOI 10.1007/978-981-15-1100-4_12
   Sivaswamy J., 2015, JSM Biomedical Imaging Data Papers, V2, P1004
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Soorya M, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1260-2
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tessier-Lavigne Marc., 2000, Principles of Neural Science, V4th, P507
   Thakur N, 2017, CURR MED IMAGING REV, V13, P99, DOI 10.2174/1573405612666160606124044
   Tobin KW, 2006, PROC SPIE, V6144, DOI 10.1117/12.641670
   Tuominen VJ, 2010, BREAST CANCER RES, V12, DOI 10.1186/bcr2615
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Wong DWK, 2008, IEEE ENG MED BIO, P2266, DOI 10.1109/IEMBS.2008.4649648
   Yin FS, 2015, IEEE ENG MED BIO, P1596, DOI 10.1109/EMBC.2015.7318679
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu XL, 2010, J DIGIT IMAGING, V23, P332, DOI 10.1007/s10278-009-9189-5
   Zilly Julian G., 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P136, DOI 10.1007/978-3-319-24888-2_17
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 54
TC 8
Z9 8
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 34737
EP 34758
DI 10.1007/s11042-021-11559-8
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000739790800002
DA 2024-07-18
ER

PT J
AU Sun, YA
   Su, QT
   Wang, HY
   Wang, G
AF Sun, Yehan
   Su, Qingtang
   Wang, Huanying
   Wang, Gang
TI A blind dual color images watermarking based on quaternion singular
   value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image; Watermarking; QSVD; Invisibility; Robustness
ID ALGORITHM; SCHEME; DCT
AB With the rapid development of the Internet, the color digital image copyright protection is facing severe challenges. Simultaneously, the color digital images are often attacked by a variety of attacks. For protecting the copyright of the color image, this paper proposes a blind color image watermarking algorithm based on Quaternion Singular Value Decomposition (QSVD). Firstly, the characteristic of quaternion that can make the color image channels associated with each other is applied to this paper for guaranteeing the anti-attack performance. Based on the above strategy, the non-overlapping image blocks are converted into quaternion image blocks. Then, the quaternion image blocks are decomposed by Singular Value Decomposition (SVD) and the diagonal matrix is obtained. Finally, the maximum eigenvalue of the diagonal matrix is quantized to complete the embedding and blind extraction of the color digital watermark. The simulation results show that the algorithm has good imperceptible and strong robustness for conventional and geometric attacks. Compared with other methods considered in this paper, the invisibility and robustness of the proposed method are improved.
C1 [Sun, Yehan; Su, Qingtang; Wang, Huanying; Wang, Gang] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
C3 Ludong University
RP Su, QT (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
EM sdytsqt@163.com
FU National Natural Science Foundations of China [61771231, 61772253,
   61873117, 61872170, 61803253]; Key Project of Shandong Natural Science
   Foundation [ZR2020KF023]; Key Research and Development Program of
   Shandong Province [2019GGX101025]
FX The work was supported by the National Natural Science Foundations of
   China (No. 61771231, 61772253, 61873117, 61872170 and 61803253), the Key
   Project of Shandong Natural Science Foundation (No. ZR2020KF023) and the
   Key Research and Development Program of Shandong Province (No.
   2019GGX101025).
CR Abdulrahman AK, 2019, MULTIMED TOOLS APPL, V78, P17027, DOI 10.1007/s11042-018-7085-z
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Dappuri B, 2020, MULTIMED TOOLS APPL, V79, P31103, DOI 10.1007/s11042-020-09433-0
   Dataset] University of Granada Computer Vision Group, 2002, CVG UGR IM DAT
   Dataset] University of Southern California Signal and Inage Processing Institute, 1997, USC SIPI IMAGE DATAB
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hsu CS, 2020, MULTIMED TOOLS APPL, V79, P11297, DOI 10.1007/s11042-019-08367-6
   Hu HT, 2020, INFORM SCIENCES, V519, P161, DOI 10.1016/j.ins.2020.01.019
   Liu DC, 2021, SIGNAL PROCESS-IMAGE, V95, DOI 10.1016/j.image.2021.116292
   Liu DC, 2021, EXPERT SYST APPL, V170, DOI 10.1016/j.eswa.2020.114540
   Liu DC, 2020, MULTIMED TOOLS APPL, V79, P7491, DOI 10.1007/s11042-019-08423-1
   Liu F, 2018, MULTIMED TOOLS APPL, V77, P23483, DOI 10.1007/s11042-018-5652-y
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Pal P, 2021, MULTIMED TOOLS APPL, V80, P21651, DOI 10.1007/s11042-021-10651-3
   Pandey MK, 2019, MICROSYST TECHNOL, V25, P3071, DOI 10.1007/s00542-018-4162-1
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Su QT, 2020, MULTIMED TOOLS APPL, V79, P30023, DOI 10.1007/s11042-020-09436-x
   Su QT, 2020, SOFT COMPUT, V24, P445, DOI 10.1007/s00500-019-03924-5
   Su QT, 2019, MULTIMED TOOLS APPL, V78, P8113, DOI 10.1007/s11042-018-6632-y
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Yuan ZH, 2020, MULTIMED TOOLS APPL, V79, P30557, DOI 10.1007/s11042-020-09499-w
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
   Zhang XT, 2020, OPTIK, V219, DOI 10.1016/j.ijleo.2020.165272
NR 33
TC 10
Z9 10
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 5
BP 6091
EP 6113
DI 10.1007/s11042-021-11815-x
EA JAN 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZG7CS
UT WOS:000739252200001
DA 2024-07-18
ER

PT J
AU Alrashed, S
   Min-Allah, N
   Ali, I
   Mehmood, R
AF Alrashed, Saleh
   Min-Allah, Nasro
   Ali, Ijaz
   Mehmood, Rashid
TI COVID-19 outbreak and the role of digital twin
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital twin; Disease spreads; Healthcare system; Control; COVID-19
AB COVID-19 has transformed the life of human beings and digital twin infrastructure can facilitates working remotely during COVID-19 outbreak by reducing burden on services and infrastructure. Currently, many organizations are installing and developing devices such as thermal cameras, sensors aiming to minimize human contact and so forth, in addition to enforcing social distancing resulting in reducing the risk of transmission. Due to economic reasons, lockdown restrictions are being relaxed/lifted in many countries and Pakistan which is one of the most densely populated countries in the world with a population of 220 + million is no exception. Though, Pakistan contained the first two waves of coronavirus infections reasonably well but the country is struggling to contain the third wave of the spread due to violations of social distancing norms. While our predictions may deviate from official statistics due to lack of mass testing and existence of asymptomatic infections, the described approach predicts the possible actual burden of infection over times. In view of the unique demographics, our data quantify the efficacy of social distancing as an effective measure to forestall the infection. We highlight few areas where digital twins can be created/deployed to provide services and essential facilities to citizens as COVID-19 is expected to have permanent impact on the way we work.
C1 [Alrashed, Saleh] Imam Abdulrahman Bin Faisal Univ, Management Informat Syst Dept, Coll Appl Studies & Community Serv, POB 1982, Dammam, Saudi Arabia.
   [Min-Allah, Nasro] Imam Abdulrahman Bin Faisal Univ, Dept Comp Sci, Coll Comp Sci & Informat Technol, POB 1982, Dammam, Saudi Arabia.
   [Ali, Ijaz] COMSATS Univ Islamabad, Dept Hlth Informat, Pk Rd, Islamabad, Pakistan.
   [Mehmood, Rashid] Alfaisal Univ, Dept Life Sci, Coll Sci & Gen Studies, Riyadh, Saudi Arabia.
C3 Imam Abdulrahman Bin Faisal University; Imam Abdulrahman Bin Faisal
   University; COMSATS University Islamabad (CUI); Alfaisal University
RP Min-Allah, N (corresponding author), Imam Abdulrahman Bin Faisal Univ, Dept Comp Sci, Coll Comp Sci & Informat Technol, POB 1982, Dammam, Saudi Arabia.
EM nabdullatief@iau.edu.sa
RI Min-Allah, Nasro/O-3147-2019; ALI, IJAZ/AAC-2691-2019
OI ALI, IJAZ/0000-0003-2163-8874; Mehmood, Rashid/0000-0003-3554-4078;
   min-allah, nasro/0000-0002-3435-8823
FU Deanship of Scientific Research, Imam Abdulrahman Bin Faisal University
   [Covid19-2020-063-CSIT]
FX This work was supported by the Deanship of Scientific Research, Imam
   Abdulrahman Bin Faisal University [Covid19-2020-063-CSIT].
CR Alexander Otto M., Covid-19 update: Transmission 5% or less among close contacts
   Algothami S.S., 2021, PANDEMIC LOCKDOWN DI, V7, P95, DOI DOI 10.1007/978-3-030-86274-9
   Alrashed Saleh, 2020, INFORMATICS ME UNPUB
   [Anonymous], 2021, COVID 19 VACC SURV R
   [Anonymous], 2020, Naming the coronavirus disease (COVID-19) and the virus that causes it
   [Anonymous], SECRET STRENGTH PAKI
   [Anonymous], 2020, BBC News
   [Anonymous], FORECASTING COVID 19
   [Anonymous], 2020, The Guardian
   Bloom D. E., 2018, Finance & Development, V55, P46
   Boseley Sarah, LOCKDOWNS CANT END C
   Chakraborty I, 2020, SCI TOTAL ENVIRON, V728, DOI 10.1016/j.scitotenv.2020.138882
   De Falco A, 2020, ARXIV200400553
   Deng TH, 2021, J MANAGE SCI ENG, V6, P125, DOI 10.1016/j.jmse.2021.03.003
   Food David, DOES DIGITAL TWIN FI
   GALLUP, 2020, SHORT ROUND HLTH INF
   Hamzaha Fairoza Amira Binti, 2020, CORONATRACKER WORLD
   Harko T, 2014, APPL MATH COMPUT, V236, P184, DOI 10.1016/j.amc.2014.03.030
   Horwitz Lauren, 2021, DIGITAL TWINS HLTH A
   Hui DS, 2020, INT J INFECT DIS, V91, P264, DOI 10.1016/j.ijid.2020.01.009
   Imai N, 2020, REPORT 3 TRANSMISSIB
   IMF, WORLD EC OUTL REP
   Jan F, 2024, MULTIMED TOOLS APPL, V83, P15223, DOI 10.1007/s11042-021-11075-9
   John Hopkins University, 2020, COR MAP
   Kermack WO, 1927, P R SOC LOND A-CONTA, V115, P700, DOI 10.1098/rspa.1927.0118
   Ketchell Misha, 2020, MODEL PANDEMIC
   Leite H, 2020, PUBLIC MONEY MANAGE, V40, P483, DOI 10.1080/09540962.2020.1748855
   LOCEY K, 2020, JAMIA OPEN
   Miller JC., 2017, INFECT DIS MODEL, DOI 10.1016/j.idm.2016.12.003
   Min-Allah N, 2021, MULTIMEDIA SYST, V27, P753, DOI 10.1007/s00530-021-00806-5
   Min-Allah N, 2020, SUSTAIN CITIES SOC, V59, DOI 10.1016/j.scs.2020.102231
   Pakistan, PAKISTAN COVID 19 SI
   Pakistan Bureau of Statistics, 2017, DIG DIG TWIN WILL PR
   Pilati F, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13137396
   Saxena Arnav, 2020, MATH LOCKDOWN SOCIAL
   Sonia Altizer., 2006, INFECT DIS PRIMATES
   Trading Economics, 2020, PAK HOSP BEDS
   Wang HW, 2020, CELL DISCOV, V6, DOI 10.1038/s41421-020-0148-0
   Waris A, 2020, NEW MICROB NEW INFEC, V35, DOI 10.1016/j.nmni.2020.100681
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   WHO (WORLD HEALTH ORGANIZATION), 2020, WHO DirectorGeneral's opening remarks at the media briefing on COVID19 11 March 2020
   Wu JT, 2020, LANCET, V395, P689, DOI 10.1016/S0140-6736(20)30260-9
   Yates Kit, 2019, MATH LIFE DEATH
NR 43
TC 9
Z9 9
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2022
VL 81
IS 19
BP 26857
EP 26871
DI 10.1007/s11042-021-11664-8
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 3B2OW
UT WOS:000737741900010
PM 35002471
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Meng, H
   Yuan, F
   Tian, Y
   Yan, TH
AF Meng, Hao
   Yuan, Fei
   Tian, Yang
   Yan, Tianhao
TI Cross-datasets facial expression recognition via distance metric
   learning and teacher-student model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance metric learning; Cross-datasets facial expression recognition;
   Teacher-Student Model; Dataset label quality; Fused large-scale
   expression dataset
ID FEATURES; NETWORK
AB Large-scale high-quality datasets are a particularly important condition for facial expression recognition(FER) in the era of deep learning, but most of the datasets used for FER are relatively small. A common method to address this problem is to use cross-datasets strategy. However, due to the different acquisition conditions and subjective labeling process, there are inevitable data inconsistencies and poor cross-dataset robustness between different FER datasets. Moreover, expression datasets collected in uncontrolled environments suffer from problems such as unclear expressions and low-quality face images, leading to low certainty in image annotation. This paper aims to improve the accuracy and generalization ability of expression recognition across datasets by optimizing the labels of fused large-scale datasets. Specifically, this paper adopts the similarity comparison of features, proposes a dataset label determination method based on distance metric learning and teacher-student model to improve the determinism of images. In addition, this paper provides an alternative scheme for fusion of datasets. The fusion of the source dataset and the target dataset provides the best trade-off between accuracy and generalization ability to achieve a better result for cross-dataset FER, address the problems of small dataset size and ignoring the performance of the source dataset in cross-dataset expression recognition. Experiments show that training on the fused large-scale datasets using the method proposed in this paper can achieve the state of the art results for cross-dataset expression recognition.
C1 [Meng, Hao; Yuan, Fei; Tian, Yang; Yan, Tianhao] Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.
   [Meng, Hao; Yuan, Fei; Tian, Yang; Yan, Tianhao] Harbin Engn Univ, Minist Educ, Key Lab Intelligent Technol & Applicat Marine Equ, Harbin 150001, Peoples R China.
C3 Harbin Engineering University; Harbin Engineering University
RP Yuan, F (corresponding author), Harbin Engn Univ, Coll Intelligent Syst Sci & Engn, Harbin 150001, Peoples R China.; Yuan, F (corresponding author), Harbin Engn Univ, Minist Educ, Key Lab Intelligent Technol & Applicat Marine Equ, Harbin 150001, Peoples R China.
EM bohelion@hrbeu.edu.cn
RI meng, hao/JHT-3327-2023
FU Development Project of Ship Situational Intelligent Awareness System,
   China [MC-201920-X01]
FX This work was supported by the Development Project of Ship Situational
   Intelligent Awareness System, China under Grant MC-201920-X01.
CR Abdel Hady MohamedFarouk., 2013, Semi-supervised Learning, P215, DOI DOI 10.1007/978-3-642-36657-4_7
   Bai Y, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500657
   Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Bejaoui H, 2019, MULTIMED TOOLS APPL, V78, P22773, DOI 10.1007/s11042-019-7632-2
   Cai J, 2018, Pancreas segmentation in CT and MRI images via domain specific network designing and recurrent neural contextual learning
   Chang WG, 2019, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2019.00753
   Chen W.Y., 2019, ICLR, DOI DOI 10.1109/MSR.2015.54
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   de Vazelhes W, 2020, J MACH LEARN RES, V21
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Douillard A., 2020, ARXIV PREPRINT ARXIV
   Fallahzadeh M.R., 2021, J. AI Data Min, V9, P259
   Farzaneh AH, 2021, IEEE WINT CONF APPL, P2401, DOI 10.1109/WACV48630.2021.00245
   Gao BB, 2017, IEEE T IMAGE PROCESS, V26, P2825, DOI 10.1109/TIP.2017.2689998
   Hosseini S, 2019, ARXIV PREPRINT ARXIV
   Hu Xuming, 2020, UPDATE, V9, P8
   Iscen A, 2019, PROC CVPR IEEE, P5065, DOI 10.1109/CVPR.2019.00521
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Lakshmi D, 2021, MICROPROCESS MICROSY, V82, DOI 10.1016/j.micpro.2021.103834
   Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053
   Li S., 2020, IEEE T AFFECT COMPUT
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2018, INT C PATT RECOG, P3092, DOI 10.1109/ICPR.2018.8545284
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Liu DZ, 2020, NEUROCOMPUTING, V413, P145, DOI 10.1016/j.neucom.2020.06.062
   Liu P, 2020, ARXIV PREPRINT ARXIV
   Liu XF, 2019, PATTERN RECOGN, V88, P1, DOI 10.1016/j.patcog.2018.11.001
   Liu XF, 2017, IEEE COMPUT SOC CONF, P522, DOI 10.1109/CVPRW.2017.79
   Long Mingsheng, 2017, arXiv preprint arXiv:1705.10667
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Suárez JL, 2021, NEUROCOMPUTING, V425, P300, DOI 10.1016/j.neucom.2020.08.017
   Ma H, 2019, ELECTRON LETT, V55, P184, DOI 10.1049/el.2018.7871
   Mei K, 2020, ARXIV PREPRINT ARXIV
   Radosavovic I, 2018, PROC CVPR IEEE, P4119, DOI 10.1109/CVPR.2018.00433
   Rahul M, 2019, INT J GRID UTIL COMP, V10, P488, DOI 10.1504/IJGUC.2019.102018
   Rizve Mamshad Nayeem, 2020, INT C LEARN REPR
   Sadeghi H, 2019, J VIS COMMUN IMAGE R, V62, P152, DOI 10.1016/j.jvcir.2019.05.004
   Shao J, 2019, NEUROCOMPUTING, V355, P82, DOI 10.1016/j.neucom.2019.05.005
   She J., 2021, CVPR 2021, P6248
   Shi S, 2018, J INTELL FUZZY SYST, V34, P2551, DOI 10.3233/JIFS-17422
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P445, DOI 10.1142/S0218001408006284
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tannugi DC, 2019, ARXIV PREPRINT ARXIV
   Taori R., 2020, Measuring Robustness to Natural Distribution Shifts in Image Classification
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Wang K., 2020, ARXIV PREPRINT ARXIV
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang YY, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10051897
   Wu H, 2018, IEEE T IMAGE PROCESS, V27, P1259, DOI 10.1109/TIP.2017.2772836
   Wu RL, 2020, PROC CVPR IEEE, P5020, DOI 10.1109/CVPR42600.2020.00507
   Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151
   Yalniz Ismet Zeki, 2019, Billion-scale semi-supervised learning for image classification
   Yasarla R, 2020, IEEE T IMAGE PROCESS, V29, P6251, DOI 10.1109/TIP.2020.2990354
   Zhou LJ, 2020, MULTIMED TOOLS APPL, V79, P675, DOI 10.1007/s11042-019-08157-0
NR 54
TC 1
Z9 1
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5621
EP 5643
DI 10.1007/s11042-021-11765-4
EA DEC 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000735344900002
DA 2024-07-18
ER

PT J
AU Zeng, SH
   Pan, ZL
AF Zeng, Sihan
   Pan, Zhongliang
TI An unsupervised font style transfer model based on generative
   adversarial networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese characters; Style transfer; Generative adversarial networks;
   Unsupervised learning; Style-attentional networks
ID CHINESE; CHARACTER
AB Chinese characters, because of their complex structure and a large number, lead to an extremely high cost of time for designers to design a complete set of characters. As a result, the dramatic growth of characters used in various fields such as culture and business has formed a strong contradiction between supply and demand with Chinese font design. Although most of the existing Chinese characters transformation models greatly alleviate the demand for character usage, the semantics of the generated characters cannot be guaranteed and the generation efficiency is low. At the same time, the models require large amounts of paired data for training, which requires a large amount of sample processing time. To address the problems of existing methods, this paper proposes an unsupervised Chinese characters generation method based on generative adversarial networks, which fuses Style-Attentional Net to a skip-connected U-Net as a GAN generator network architecture. It effectively and flexibly integrates local style patterns based on the semantic spatial distribution of content images while retaining feature information of different sizes. Our model generates fonts that maintain the source domain content features and the target domain style features at the end of training. The addition of the style specification module and the classification discriminator allows the model to generate multiple style typefaces. The generation results show that the model proposed in this paper can perform the task of Chinese character style transfer well. The model generates high-quality images of Chinese characters and generates Chinese characters with complete structures and natural strokes. In the quantitative comparison experiments and qualitative comparison experiments, our model has more superior visual effects and image performance indexes compared with the existing models. In sample size experiments, clearly structured fonts are still generated and the model demonstrates significant robustness. At the same time, the training conditions of our model are easy to meet and facilitate generalization to real applications.
C1 [Zeng, Sihan; Pan, Zhongliang] South China Normal Univ, Phys & Telecommun Engn, Guangzhou, Peoples R China.
C3 South China Normal University
RP Pan, ZL (corresponding author), South China Normal Univ, Phys & Telecommun Engn, Guangzhou, Peoples R China.
EM wles1996@126.com; panzhongliang@m.scnu.edu.cn
FU Guangzhou Science and Technology Project [201904010107]; Guangdong
   Provincial Natural Science Foundation of China [2019A1515010793];
   Guangdong Province Science and Technology Project [2016B090918071]
FX This work was supported by Guangzhou Science and Technology Project
   (201904010107), Guangdong Provincial Natural Science Foundation of China
   (2019A1515010793), Guangdong Province Science and Technology Project
   (2016B090918071).
CR [Anonymous], 2017, ARXIV171206424
   Atarsaikhan G, 2017, PROC INT CONF DOC, P51, DOI 10.1109/ICDAR.2017.328
   Azadil S, 2018, PROC CVPR IEEE, P7564, DOI 10.1109/CVPR.2018.00789
   Baxter William., 2010, I3D, P135
   Chang B, 2018, IEEE WINT CONF APPL, P199, DOI 10.1109/WACV.2018.00028
   Chen JF, 2019, IET IMAGE PROCESS, V13, P2680, DOI 10.1049/iet-ipr.2019.0009
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Gao YM, 2020, AAAI CONF ARTIF INTE, V34, P646
   Gholizadeh-Ansari M, 2020, J DIGIT IMAGING, V33, P504, DOI 10.1007/s10278-019-00274-4
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Hayashi H, 2019, KNOWL-BASED SYST, V186, DOI 10.1016/j.knosys.2019.104927
   Hensel M, 2017, ADV NEUR IN, V30
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Y, 2020, P 16 EUR C COMP VI 6, P156
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ji G, 2021, IEEE GEOSCI REMOTE S, V18, P296, DOI 10.1109/LGRS.2020.2969891
   Jiang Y, 2019, AAAI CONF ARTIF INTE, P4015
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Kingma D. P., 2014, arXiv
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   Lee J, 1999, IEEE COMPUT GRAPH, V19, P74, DOI 10.1109/38.761553
   Lian Z., 2016, SIGGRAPH ASIA 2016 T, P1, DOI DOI 10.1145/3005358.3005371
   Lian Z, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3213767
   Minoofam SAH, 2012, J CELL AUTOM, V7, P321
   Mirza M., 2014, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Modhej N, 2020, IEEE ACCESS, V8, P212803, DOI 10.1109/ACCESS.2020.3040298
   Musto L., 2020, ARXIV PREPRINT ARXIV
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Radford A., 2015, ARXIV151106434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tian Y, 2020, REWRITE
   Velek O, 2001, PROC INT CONF DOC, P556, DOI 10.1109/ICDAR.2001.953850
   Wang DD, 2020, IEEE ACCESS, V8, P26911, DOI 10.1109/ACCESS.2020.2971524
   Wang Y, 2008, INT CONF ACOUST SPEE, P1097
   Wen C, 2021, IEEE WINT CONF APPL, P3881, DOI 10.1109/WACV48630.2021.00393
   Wong HTF, 2000, COMPUT GRAPH-UK, V24, P99, DOI 10.1016/S0097-8493(99)00141-7
   Wu L, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206851
   Wu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P2073, DOI 10.1109/ICME.2006.262642
   Xu SH, 2005, IEEE INTELL SYST, V20, P32, DOI 10.1109/MIS.2005.41
   Yamini K., 2020, J ENG SCI, V11, P533
   Yang SS, 2022, IEEE T NEUR NET LEAR, V33, P4861, DOI 10.1109/TNNLS.2021.3061630
   Yang SM, 2022, IEEE T NEUR NET LEAR, V33, P2801, DOI 10.1109/TNNLS.2020.3045492
   Yang SM, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.601109
   Yang SM, 2020, IEEE T NEUR NET LEAR, V31, P148, DOI 10.1109/TNNLS.2019.2899936
   Yang SM, 2019, IEEE T CYBERNETICS, V49, P2490, DOI 10.1109/TCYB.2018.2823730
   Yuchen T, 2017, ZI2ZI MASTER CHINESE
   Zhang HY, 2019, PR MACH LEARN RES, V97
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhang YX, 2018, PROC CVPR IEEE, P8447, DOI 10.1109/CVPR.2018.00881
   Zhang Z., 2010, P 10 ANN JOINT C DIG, P99
   Zhou B., 2011, 2011 IEEE INT C MULT, P1
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 53
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 5305
EP 5324
DI 10.1007/s11042-021-11777-0
EA DEC 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000730528900002
DA 2024-07-18
ER

PT J
AU Dhanjal, AS
   Singh, W
AF Dhanjal, Amandeep Singh
   Singh, Williamjeet
TI An automatic machine translation system for multi-lingual speech to
   Indian sign language
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indian sign language; Speech recognition; Machine translation;
   Multi-lingual speech; HamNoSys; Speech to Indian sign language
ID RECOGNITION; TEXT
AB Sign language (SL) is the best suited communication medium for hearing impaired people. Even with the advancement of technology, there is a communication gap between the hearing impaired and hearing people. The aim of this research work is to bridge this gap by developing an automatic system that translates the speech to Indian Sign Language using Avatar (SISLA). The whole system works in three phases: (i) The first phase includes the speech recognition (SR) of isolated words for English, Hindi and Punjabi in speaker independent environment (ii) The second phase translates the source language into Indian Sign Language (ISL) (iii) HamNoSys based 3D avatar represents the ISL gestures. The four major implementation modules for SISLA include: requirement analysis, data collection, technical development and evaluation. The multi-lingual feature makes the system more efficient. The training and testing speech sample files for English (12,660, 4218), Hindi (12,610, 4211) and Punjabi (12,600, 4193) have been used to train and test the SR models. Empirical results of automatic machine translation show that the proposed trained models have achieved the minimum accuracy of 91%, 89% and 89% for English, Punjabi and Hindi respectively. Sign language experts have also been used to evaluate the sign error rate through feedback. Future directions to enhance the proposed system using non-manual SL features along with the sentence level translation has been suggested. Usability testing based on survey results confirm that the proposed SISLA system is suitable for education as well as communication purpose for hearing impaired people.
C1 [Dhanjal, Amandeep Singh; Singh, Williamjeet] Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
C3 Punjabi University
RP Dhanjal, AS (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
EM aman.dhanjal13@live.com; williamjeet@gmail.com
OI Singh, Amandeep/0000-0002-7763-9174
FU Department of Science and Technology, under the Scheme for Young
   Scientists & Technologists (SYST), by the Government of India
   [SP/YO/382/2018(G)]
FX This is supported by the Department of Science and Technology, under the
   Scheme for Young Scientists & Technologists (SYST), by the Government of
   India [SP/YO/382/2018(G)].
CR Abushariah M. A. M., 2010, Computer and Communication Engineering (ICCCE), 2010 International Conference on, P1
   Ahmed F, 2017, FUTURE EMERGING TREN, P122
   Ahmed M, 2016, PROCEEDINGS OF THE 2016 SAI COMPUTING CONFERENCE (SAI), P330, DOI 10.1109/SAI.2016.7556002
   Alfi El A. E. E., 2018, INT J COMPUTER APPL, V41, P19
   Alkhalifa S, 2018, MULTIMED TOOLS APPL, V77, P22007, DOI 10.1007/s11042-018-5860-5
   Almasoud A.M., 2012, Journal of Software Engineering and Applications, V5, P604, DOI DOI 10.4236/JSEA.2012.58069
   [Anonymous], 2016, P INT C INT US INT
   [Anonymous], 2015, INT J ADV RES COMPUT
   [Anonymous], 2011, P 2 WORKSH SPEECH LA
   [Anonymous], 2004, LREC
   Anuja K., 2009, Proceedings of the 2009 World Congress on Nature & Biologically Inspired Computing (NaBIC 2009), P1382, DOI 10.1109/NABIC.2009.5393721
   Arora S., 2012, International Journal of Computer Applications, V60, P34, DOI DOI 10.5120/9722-4190
   Arsan T., 2015, INT J COMPUTER SCI E, V6, P39, DOI [10.5121/ijcses.2015.6403, DOI 10.5121/IJCSES.2015.6403]
   Bhagwat SR, 2021, 2021 INTERNATIONAL CONFERENCE ON EMERGING SMART COMPUTING AND INFORMATICS (ESCI), P367, DOI 10.1109/ESCI50559.2021.9396900
   Bouzid Y, 2014, IEEE INT CONF ADV LE, P601, DOI 10.1109/ICALT.2014.176
   Bouzid Y, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING AND SOFTWARE APPLICATIONS (ICEESA), P215
   Bouzid Y, 2013, IEEE INT CONF ADV LE, P92, DOI 10.1109/ICALT.2013.31
   Bragg Danielle, 2021, CHI '21: Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems, DOI 10.1145/3411764.3445416
   Brour M, 2019, PROCEDIA COMPUT SCI, V148, P236, DOI 10.1016/j.procs.2019.01.066
   Bustamin A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND CYBERNETICS, P29, DOI 10.1109/CyberneticsCom.2016.7892562
   Buttussi F, 2007, WEB3D 2007 - 12TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, PROCEEDINGS, P61
   Caballero-Morales SO, 2013, COMPUT SIST, V17, P593, DOI 10.13053/CyS-17-4-2013-011
   Cox S., 2002, ASSETS 2002. Proceedings of the Fifth International ACM SIGCAPH Conference on Assistive Technologies, P205, DOI 10.1145/638249.638287
   Das B.P., 2012, INT J MODERN ENG RES, V2, P854
   Debevc M, 2011, MULTIMED TOOLS APPL, V54, P181, DOI 10.1007/s11042-010-0529-8
   Dewani Amirita, 2018, International Journal of Information Technology, V10, P225, DOI 10.1007/s41870-018-0105-4
   Dhanjal AS, 2020, EAI ENDORSED TRANS S, V7, DOI 10.4108/eai.13-7-2018.165279
   Elliott R., 2008, Universal Access in the Information Society, V6, P375, DOI 10.1007/s10209-007-0102-z
   Foong OM, 2009, LECT NOTES COMPUT SC, V5857, P868, DOI 10.1007/978-3-642-05036-7_82
   Futane P. R., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P377, DOI 10.1109/ICECTECH.2011.5941722
   Ganesh DS, 2015, 2015 INTERNATIONAL CONFERENCE ON MICROWAVE, OPTICAL AND COMMUNICATION ENGINEERING (ICMOCE), P365, DOI 10.1109/ICMOCE.2015.7489768
   GHAI W, 2013, J SPEECH SCI, V3, P69, DOI DOI 10.1007/978-94-024-0846-1_100175
   Glaser M, 2004, C WORKSH ASS TECHN V, P1
   Gorman BenjaminM., 2014, P 16 INT ACM SIGACCE, P337, DOI DOI 10.1145/2661334.2661410
   Grover Yuvraj, 2021, 2021 International Conference on Innovative Practices in Technology and Management (ICIPTM), P10, DOI 10.1109/ICIPTM52218.2021.9388330
   Halawani SM, 2013, INT J COMPUT SCI NET, V13, P43
   Hong R., 2010, Proceedings of the 18th ACM international conference on Multimedia, P421
   Hong RC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037681
   Jaballah K., 2012, P INT CROSS DISC C W, P1
   Joy J, 2020, ASSIST TECHNOL, V32, P153, DOI 10.1080/10400435.2018.1508093
   Kahlon NK, 2023, UNIVERSAL ACCESS INF, V22, P1, DOI 10.1007/s10209-021-00823-1
   Kallole NA, 2018, LECT NOTES ELECTR EN, V492, P263, DOI 10.1007/978-981-10-8575-8_26
   Kamal Z, 2020, LANG RESOUR EVAL, P117
   Kaneko H., 2010, Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and its Applications in Industry, P289, DOI [10.1145/1900179.1900240, DOI 10.1145/1900179.1900240]
   Kar P, 2007, P 5 INT C NAT LANG P, P1
   Karpouzis K, 2007, COMPUT EDUC, V49, P54, DOI 10.1016/j.compedu.2005.06.004
   Karpov A, 2016, PROCEDIA COMPUT SCI, V81, P201, DOI 10.1016/j.procs.2016.04.050
   Kaur K, 2016, PROCEDIA COMPUT SCI, V89, P794, DOI 10.1016/j.procs.2016.06.063
   Kaur Rajneet, 2018, 2018 International Conference on Smart Systems and Inventive Technology (ICSSIT), P498, DOI 10.1109/ICSSIT.2018.8748597
   Kaur R, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE IN DATA SCIENCE (ICCIDS)
   Kaur R, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2727, DOI 10.1109/ICACCI.2014.6968333
   Kaur S, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P909, DOI 10.1109/NGCT.2015.7375251
   Kennaway JR, 2007, ACM T COMPUT-HUM INT, V14, DOI 10.1145/1279700.1279705
   Kheir R, 2007, ITICSE 2007: 12TH ANNUAL CONFERENCE ON INNOVATION & TECHNOLOGY IN COMPUTER SCIENCE EDUCATION, P261
   Kipp Michael, 2011, Intelligent Virtual Agents. Proceedings 11th International Conference, IVA 2011, P113, DOI 10.1007/978-3-642-23974-8_13
   Kouremenos D, 2010, BEHAV INFORM TECHNOL, V29, P467, DOI 10.1080/01449290903420192
   Kumar Kuldeep, 2012, International Journal of Computational Systems Engineering, V1, P25, DOI 10.1504/IJCSYSE.2012.044740
   Kumar Y, 2017, INT J SPEECH TECHNOL, V20, P297, DOI 10.1007/s10772-017-9408-2
   Lee S, 2016, P 2016 CHI C HUM FAC, P32
   Lee S, 2016, MED BIOL ENG COMPUT, V54, P915, DOI 10.1007/s11517-015-1447-8
   Lopez-Zapata E., 2018, MECH MACHINE SCI, P274
   Lu PF, 2014, COMPUT SPEECH LANG, V28, P812, DOI 10.1016/j.csl.2013.10.004
   Luqman H, 2019, UNIVERSAL ACCESS INF, V18, P939, DOI 10.1007/s10209-018-0622-8
   Mahmudul Hassan K, 2017, SCI J CIRCUITS SYSTE, V6, P17, DOI [10.11648/j.cssp.20170602.12, DOI 10.11648/J.CSSP.20170602.12]
   Malik M, 2021, MULTIMED TOOLS APPL, V80, P9411, DOI 10.1007/s11042-020-10073-7
   Marschark M, 2012, DEAF EDUC INT, V14, P136, DOI 10.1179/1557069X12Y.0000000010
   Martin P., 2013, P 3 INT S SIGN LANG, P1
   Martins P, 2015, PROCEDIA COMPUT SCI, V67, P263, DOI 10.1016/j.procs.2015.09.270
   Matsumoto T, 2009, P 3 INT UN COMM S, P363
   Mehta N, 2020, UNIVERSAL ACCESS INF, V19, P725, DOI 10.1007/s10209-019-00668-9
   Mirzaei M.R., 2012, P 2012 VIRT REAL INT, P5
   Mittal P, 2019, INT J SPEECH TECHNOL, V22, P219, DOI 10.1007/s10772-019-09593-x
   Mittal S, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATION, & AUTOMATION (ICACCA) (FALL), P60
   Mohandes M., 2006, AIML J., V6, P15
   Moharram MA, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL ELECTROMAGNETICS (ICCEM), P5, DOI 10.1109/COMPEM.2015.7052535
   Mokhtar SA., 2017, P 11 INT C UB INF MA, P1
   Mon S. M., 2015, INT J SCI TECHNOLOGY, V4, P349
   Morrissey S, 2013, MACH TRANSL, V27, P25, DOI 10.1007/s10590-012-9133-1
   Naert L, 2021, MACH TRANSL, V35, P405, DOI 10.1007/s10590-021-09268-y
   Nawshin S, 2020, IEEE REGION 10 SYMP, P440
   Neves C, 2020, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION (LREC 2020), P6035
   Oliveira T, 2019, IEEE GLOB ENG EDUC C, P937, DOI [10.1109/EDUCON.2019.8725244, 10.1109/educon.2019.8725244]
   Othman A, 2010, LECT NOTES COMPUT SC, V6180, P169, DOI 10.1007/978-3-642-14100-3_26
   Otoom M, 2018, ASSIST TECHNOL, V30, P119, DOI 10.1080/10400435.2016.1268218
   Padmanabhan J, 2015, IETE TECH REV, V32, P240, DOI 10.1080/02564602.2015.1010611
   Parton BS, 2006, J DEAF STUD DEAF EDU, V11, P94, DOI 10.1093/deafed/enj003
   Prazák A, 2020, MULTIMED TOOLS APPL, V79, P1203, DOI 10.1007/s11042-019-08235-3
   Priyanks BR., 2019, INT RES J ENG TECHNO, V6, P1812
   Qaisar S.M., 2019, P 16 INT LEARNING TE, VVolume 163, P35
   Raghavendhar R.B., 2013, Int. J. Eng. Res. Appl. (IJERA), V3, P253
   Saifan RR, 2018, COMPUT APPL ENG EDUC, V26, P1008, DOI 10.1002/cae.21952
   Samcovic A, 2022, ASSIST TECHNOL, V34, P232, DOI 10.1080/10400435.2020.1757786
   San-Segundo R, 2008, SPEECH COMMUN, V50, P1009, DOI 10.1016/j.specom.2008.02.001
   Sarma H, 2017, ACM T ASIAN LOW-RESO, V17, DOI 10.1145/3137055
   Sawant S, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Shahriar R, 2017, IEEE REG 10 HUMANIT, P1, DOI 10.1109/R10-HTC.2017.8288892
   Sharan S, 2018, ADV INTELLIGENT SYST, P91, DOI DOI 10.1007/978-981-10-6626-9_10
   Singh P., 2011, 2011 Proceedings of International Conference on Computational Intelligence and Communication Networks (CICN 2011), P375, DOI 10.1109/CICN.2011.79
   Singh S, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P90, DOI 10.1109/PDGC.2016.7913121
   Smys S., 2021, J ISMAC, V3, P40, DOI DOI 10.36548/JISMAC.2021.1.004
   Sonawane P, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION, AND INTELLIGENT SYSTEMS (ICCCIS), P92, DOI 10.1109/ICCCIS51004.2021.9397097
   Soudi A, 2019, ASSETS'19: THE 21ST INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P658, DOI 10.1145/3308561.3354592
   Sugandhi KP., 2018, INT J COGNITIVE LANG, V12, P1116, DOI [10.5281/zenodo.1474397, DOI 10.5281/ZENODO.1474397]
   Yadava GT, 2020, INT J SPEECH TECHNOL, V23, P149, DOI 10.1007/s10772-020-09671-5
   Tripathy S, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P539, DOI 10.1109/ICIIP.2013.6707650
   Upadhyaya P, 2019, ADV INTELL SYST COMP, V748, P303, DOI 10.1007/978-981-13-0923-6_26
   Valanarasu MR., 2021, J INF TECHNOL-UK, V3, P77, DOI [10.36548/jitdw.2021.2.002, DOI 10.36548/JITDW.2021.2.002]
   Van Zijl L, 2006, P 2006 ANN RES C S A
   Vargas M.R., 2018, ICCSDET, P1
   Verma A., 2015, INT J COMPUT SCI TEC, V6, P117
   Villeval S., 2016, Proc. IEEE Sensor Array Multichannel Signal Process. Workshop, P1, DOI DOI 10.1109/SAM.2016.7569753
   Wray A, 2004, LANG COMMUN, V24, P59, DOI 10.1016/j.langcom.2003.08.001
   Yao D, 2009, P 2009 INT CROSS DIS, P101, DOI [10.1145/1535654.1535680, DOI 10.1145/1535654.1535680]
NR 113
TC 10
Z9 10
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 4283
EP 4321
DI 10.1007/s11042-021-11706-1
EA DEC 2021
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000727165500001
DA 2024-07-18
ER

PT J
AU Acharjya, DP
   Rathi, R
AF Acharjya, D. P.
   Rathi, R.
TI An extensive study of statistical, rough, and hybridized rough computing
   in bankruptcy prediction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Rough set; Rule generation; Indiscernibility;
   Classification; Reduct; Approximation; Linear regression
AB An extensive amount of data are generated from the electronic world each day. Possessing useful knowledge from this data is challenging, and it became a prime area of current research. Much research has been carried out in these directions initiating from statistical techniques to intelligent computing and further to hybridized computing. The foremost objective of this article is making a comparative study between statistical, rough computing, and hybridized computing approaches. Financial bankruptcy dataset of Polish companies is considered for comparative analysis. Results show that rough hybridization of the binary-coded genetic algorithm provides an accuracy of 98.3% and it is better as compared to other descriptive and rough computing techniques.
C1 [Acharjya, D. P.] VIT Vellore, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
   [Rathi, R.] VIT Vellore, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Acharjya, DP (corresponding author), VIT Vellore, Sch Comp Sci & Engn, Vellore, Tamil Nadu, India.
EM dpacharjya@gmail.com; raathiraj@gmail.com
RI /T-1205-2018
OI /0000-0003-3828-2050
CR ALTMAN EI, 1968, J FINANC, V23, P589, DOI 10.2307/2978933
   Anitha A, 2015, Int J Bioinform Res Appl, V11, P503
   BEAVER WH, 1966, J ACCOUNTING RES, V4, P71, DOI 10.2307/2490171
   Chen MY, 2012, INTELL AUTOM SOFT CO, V18, P65, DOI 10.1080/10798587.2012.10643227
   Chen N, 2013, EXPERT SYST APPL, V40, P385, DOI 10.1016/j.eswa.2012.07.047
   Cielen A, 2004, EUR J OPER RES, V154, P526, DOI 10.1016/S0377-2217(03)00186-3
   Deep K, 2007, APPL MATH COMPUT, V188, P895, DOI 10.1016/j.amc.2006.10.047
   Dimitras AI, 1999, EUR J OPER RES, V114, P263, DOI 10.1016/S0377-2217(98)00255-0
   DUBOIS D, 1990, INT J GEN SYST, V17, P191, DOI 10.1080/03081079008935107
   Greco S., 1998, Rough Sets and Current Trends in Computing. First International Conference, RSCTC'98. Proceedings, P60
   Hua ZS, 2007, EXPERT SYST APPL, V33, P434, DOI 10.1016/j.eswa.2006.05.006
   Jao-Hong Cheng, 2013, Advances in Information Sciences and Service Sciences, V5, P15
   Kar AK, 2016, EXPERT SYST APPL, V59, P20, DOI 10.1016/j.eswa.2016.04.018
   Lee MH, 2009, MATEMATIKA, V25, P67
   McKee T. E., 2000, International Journal of Intelligent Systems in Accounting, Finance and Management, V9, P159, DOI 10.1002/1099-1174(200009)9:3<159::AID-ISAF184>3.0.CO;2-C
   Min JH, 2009, EXPERT SYST APPL, V36, P5256, DOI 10.1016/j.eswa.2008.06.073
   Molodtsov D, 1999, COMPUT MATH APPL, V37, P19, DOI 10.1016/S0898-1221(99)00056-5
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pawlak Z., 1991, ROUGH SETS THEORETIC
   Rathi R, 2018, ARAB J SCI ENG, V43, P4215, DOI 10.1007/s13369-017-2838-y
   Rathi R., 2018, International Journal of Fuzzy Systems Applications, V7, P74, DOI 10.4018/IJFSA.2018010106
   Shafer Glenn, 1976, A mathematical theory of evidence, V42, DOI DOI 10.2307/J.CTV10VM1QB
   Shen Guicheng, 2014, Open J. Soc. Sci., V2, P204
   Siddique N, 2015, COGN COMPUT, V7, P706, DOI 10.1007/s12559-015-9370-8
   Slowinski R., 1995, International Journal of Intelligent Systems in Accounting, Finance and Management, V4, P27
   Xiao Z, 2012, KNOWL-BASED SYST, V26, P196, DOI 10.1016/j.knosys.2011.08.001
   Yeh CC, 2010, EXPERT SYST APPL, V37, P1535, DOI 10.1016/j.eswa.2009.06.088
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhang YD, 2011, ADV MATER RES-SWITZ, V186, P459, DOI 10.4028/www.scientific.net/AMR.186.459
   Zieba M, 2016, EXPERT SYST APPL, V58, P93, DOI 10.1016/j.eswa.2016.04.001
NR 30
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35387
EP 35413
DI 10.1007/s11042-020-10167-2
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA VM6PC
UT WOS:001028176800002
DA 2024-07-18
ER

PT J
AU Anand, S
   Gayathri, S
   Sangeethapriya, G
AF Anand, S.
   Gayathri, S.
   Sangeethapriya, G.
TI Optic disc analysis in retinal fundus using L<SUP>2</SUP> norm of
   contourlet subbands, superimposed edges, and morphological filling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE OD center; OD boundary; Retinal vasculature enhancement
ID VESSEL SEGMENTATION; IMAGE-ENHANCEMENT; SHARPENING ENHANCEMENT;
   BLOOD-VESSELS; EXTRACTION; FOVEA; LOCALIZATION; TRANSFORM;
   DECOMPOSITION; MACULOPATHY
AB Optic disc (OD) analysis is an important stage in detecting retinal diseases and existing approaches are not suitable for analyzing multiple examinations in a single process. This paper proposes a new unified method to detect (i) OD center, (ii) OD boundary, and (iii) enhancement of vasculature within the OD region in a single algorithm. This paper presents a unique strategy, which involves L-2 norm of contourlet subbands of retinal images to locate the OD center. A novel OD boundary tracing approach that integrates morphological operations, and segmentation region growing techniques, with the aid of the OD center as a seed point, is presented. Among the two novel OD vasculature enhancement techniques, one of which involves image sharpening to improve the local contrast followed by histogram equalization to increase the overall contrast of the fundus image. Edge superimposing with the flood fill technique is another approach used for vasculature enhancement. The algorithm is tested on DRIVE (40), STARE (81), MESSIDOR (1200), E-ophtha (87), Diaretdb1 (89) images, out of which 40, 77, 1182, 87, and 87 images are detected correctly. The Figure of Merit (FOM) is used to confirm the correctness of the boundary tracking performance (97.15%). EME, SSIM, and other parameters are used to assess the efficiency of the vasculature enhancement technique.
C1 [Anand, S.] Mepco Schlenk Engn Coll, Dept Elect & Commun Engn, Sivakasi 626005, Tamil Nadu, India.
   [Gayathri, S.] CTS, Chennai, Tamil Nadu, India.
   [Sangeethapriya, G.] Mepco Schlenk Engn Coll, Dept ECE, Sivakasi 626005, Tamil Nadu, India.
C3 Mepco Schlenk Engineering College; Mepco Schlenk Engineering College
RP Anand, S (corresponding author), Mepco Schlenk Engn Coll, Dept Elect & Commun Engn, Sivakasi 626005, Tamil Nadu, India.
EM ks.an@yahoo.com
RI S, Anand/S-7812-2019
OI S, Anand/0000-0002-0307-1942
CR Abramoff Michael D, 2010, IEEE Rev Biomed Eng, V3, P169, DOI 10.1109/RBME.2010.2084567
   Acharya UR, 2017, COMPUT BIOL MED, V84, P59, DOI 10.1016/j.compbiomed.2017.03.016
   Agurto C, 2015, COMPUT MED IMAG GRAP, V43, P137, DOI 10.1016/j.compmedimag.2015.01.001
   Agurto C, 2012, IEEE ENG MED BIO, P4946, DOI 10.1109/EMBC.2012.6347102
   Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Anand S, 2015, OPTIK, V126, P3150, DOI 10.1016/j.ijleo.2015.07.069
   Anand S, 2013, OPTIK, V124, P2121, DOI 10.1016/j.ijleo.2012.06.026
   [Anonymous], 2009, Medical Imaging 2009: Computer-Aided Diagnosis
   Aquino A, 2010, IEEE T MED IMAGING, V29, P1860, DOI 10.1109/TMI.2010.2053042
   Chakravarty A, 2017, COMPUT METH PROG BIO, V147, P51, DOI 10.1016/j.cmpb.2017.06.004
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Cheng J, 2018, IEEE T MED IMAGING, V37, P2536, DOI 10.1109/TMI.2018.2838550
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Diaretdb, 2009, DIARETDB1 DIABETIC R
   Fan Z, 2018, IEEE J BIOMED HEALTH, V22, P224, DOI 10.1109/JBHI.2017.2723678
   Foracchia M, 2004, IEEE T MED IMAGING, V23, P1189, DOI 10.1109/TMI.2004.829331
   Gegundez-Arias ME, 2017, COMPUT BIOL MED, V88, P100, DOI 10.1016/j.compbiomed.2017.07.007
   Gegundez-Arias ME, 2013, COMPUT MED IMAG GRAP, V37, P386, DOI 10.1016/j.compmedimag.2013.06.002
   Goatman KA, 2011, IEEE T MED IMAGING, V30, P972, DOI 10.1109/TMI.2010.2099236
   Harangi B, 2015, COMPUT BIOL MED, V65, P10, DOI 10.1016/j.compbiomed.2015.07.002
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Javidi M, 2017, COMPUT METH PROG BIO, V139, P93, DOI 10.1016/j.cmpb.2016.10.015
   Jiang G, 2015, OPTIK, V126, P5656, DOI 10.1016/j.ijleo.2015.08.173
   Joshi GD, 2011, IEEE T MED IMAGING, V30, P1192, DOI 10.1109/TMI.2011.2106509
   Kamble R, 2017, COMPUT BIOL MED, V87, P382, DOI 10.1016/j.compbiomed.2017.04.016
   Kao EF, 2014, COMPUT METH PROG BIO, V117, P92, DOI 10.1016/j.cmpb.2014.08.003
   Kar SS, 2016, COMPUT BIOL MED, V70, P174, DOI 10.1016/j.compbiomed.2015.12.018
   Koh JEW, 2017, COMPUT BIOL MED, V84, P89, DOI 10.1016/j.compbiomed.2017.03.008
   Lalonde M, 2001, IEEE T MED IMAGING, V20, P1193, DOI 10.1109/42.963823
   Lupascu CA, 2010, IEEE T INF TECHNOL B, V14, P1267, DOI 10.1109/TITB.2010.2052282
   Marin D, 2015, COMPUT METH PROG BIO, V118, P173, DOI 10.1016/j.cmpb.2014.11.003
   Medhi JP, 2016, COMPUT BIOL MED, V74, P30, DOI 10.1016/j.compbiomed.2016.04.007
   Mendonça AM, 2013, COMPUT MED IMAG GRAP, V37, P409, DOI 10.1016/j.compmedimag.2013.04.004
   Miri MS, 2011, IEEE T BIO-MED ENG, V58, P1183, DOI 10.1109/TBME.2010.2097599
   Mitra A, 2018, COMPUT METH PROG BIO, V156, P169, DOI 10.1016/j.cmpb.2018.01.001
   Narasimha-Iyer H, 2007, IEEE T BIO-MED ENG, V54, P1436, DOI 10.1109/TBME.2007.900807
   Palomera-Pérez MA, 2010, IEEE T INF TECHNOL B, V14, P500, DOI 10.1109/TITB.2009.2036604
   Roy PK, 2016, COMPUT BIOL MED, V74, P18, DOI 10.1016/j.compbiomed.2016.04.018
   Singh A, 2016, COMPUT METH PROG BIO, V124, P108, DOI 10.1016/j.cmpb.2015.10.010
   Soares I, 2016, IEEE J BIOMED HEALTH, V20, P574, DOI 10.1109/JBHI.2015.2392712
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Swaminathan A, 2013, BIOMED ENG-BIOMED TE, V58, P87, DOI 10.1515/bmt-2012-0055
   Tan NM, 2015, COMPUT MED IMAG GRAP, V40, P182, DOI 10.1016/j.compmedimag.2014.10.002
   Tramontan L, 2011, IEEE T BIO-MED ENG, V58, P818, DOI 10.1109/TBME.2010.2085001
   Vostatek P, 2017, COMPUT MED IMAG GRAP, V55, P2, DOI 10.1016/j.compmedimag.2016.07.005
   Wong CY, 2016, J MOD OPTIC, V63, P1618, DOI 10.1080/09500340.2016.1163428
   Xiong L, 2017, COMPUT METH PROG BIO, V143, P137, DOI 10.1016/j.cmpb.2017.02.026
   Xiong L, 2016, COMPUT MED IMAG GRAP, V47, P40, DOI 10.1016/j.compmedimag.2015.10.003
   Yazdanpanah A, 2011, IEEE T MED IMAGING, V30, P484, DOI 10.1109/TMI.2010.2087390
   Youssif AAHAR, 2008, IEEE T MED IMAGING, V27, P11, DOI 10.1109/TMI.2007.900326
   Zhang DB, 2016, IEEE J BIOMED HEALTH, V20, P333, DOI 10.1109/JBHI.2014.2365514
   Zhou M, 2018, IEEE T BIO-MED ENG, V65, P521, DOI 10.1109/TBME.2017.2700627
NR 52
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36129
EP 36152
DI 10.1007/s11042-021-11569-6
EA OCT 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000710608600001
DA 2024-07-18
ER

PT J
AU Pei, LL
   Zhang, H
   Yang, B
AF Pei, Lili
   Zhang, He
   Yang, Bo
TI Improved Camshift object tracking algorithm in occluded scenes based on
   AKAZE and Kalman
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AKAZE algorithm; Camshift algorithm; Feature matching; Kalman filtering;
   Object tracking; Video processing
ID CHAIN
AB Camshift algorithm tracking is susceptible to interference when a tracking object is occluded or when its hue is similar to the background. An improved Camshift object-tracking algorithm combining AKAZE (Accelerated-KAZE) feature matching and Kalman filtering is proposed. First, the video channel is converted for processing. Second, AKAZE is used to match the object feature points and Kalman filtering is used to predict the next position. Then different scenes are judged by the threshold and the Camshift and Kalman tracking algorithms are used for object tracking, respectively. Finally, the improved Camshift algorithm is used to test the moving object in a variety of situations and compared with the traditional Camshift algorithm and the Kalman filter improved Camshift algorithm. Experimental results show that the improved joint tracking algorithm can continue tracking under full occlusion. The effective frame rate of recognition is increased by about 20%, and the single-frame image processing time is less than 35 ms, which can meet the real-time tracking requirements.
C1 [Pei, Lili] Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
   [Zhang, He] Xian Xiangteng Microelect Technol Co Ltd, Xian 710068, Shaanxi, Peoples R China.
   [Yang, Bo] Datang Mobile Commun Equipment Co Ltd, Xian Branch, Xian 710061, Shaanxi, Peoples R China.
C3 Chang'an University; Datang Telecom Technology & Industry
RP Pei, LL (corresponding author), Changan Univ, Sch Informat Engn, Xian 710064, Shaanxi, Peoples R China.
EM peilili@chd.edu.cn
FU National key research and development program [2018YFB1600202]; Chang'an
   University Doctoral Candidates' Innovative Ability Cultivation Funding
   Project [:300203211241]
FX This research is funded by National key research and development program
   (Grant No.: 2018YFB1600202); Chang'an University Doctoral Candidates'
   Innovative Ability Cultivation Funding Project (Grant No.:300203211241).
CR Ali N.H., 2014, Int. J. Comput. Appl., V89, P15
   Baojun Z, 2019, MOVING TARGET DETECT, V15
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   Cao SX, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0223-0
   Chaoqian G, 2020, TARGET TRACKING BASE
   Chen Q., 2017, RES REAL TIME SINGLE
   Chengwen D, 2016, IND CONTROL COMPUTER, V29, P93
   Feng Wenbin, 2018, Computer Engineering and Applications, V54, P200, DOI 10.3778/j.issn.1002-8331.1610-0004
   Hai-Xia X, 2011, IET COMPUT VIS, V5, P282, DOI 10.1049/iet-cvi.2010.0086
   Kanagala SB, 2021, ASIAN J CONTROL, V23, P2495, DOI 10.1002/asjc.2358
   KEEHN DG, 1974, IBM SYST J, V13, P186, DOI 10.1147/sj.133.0186
   Keli H, 2018, ELEMENT WEIGHTED NEU, V9
   Lee E, 2013, 2013 INTERNATIONAL CONFERENCE ON TECHNOLOGICAL ADVANCES IN ELECTRICAL, ELECTRONICS AND COMPUTER ENGINEERING (TAEECE), P294
   Li Junwei, 2017, [Computational Visual Media, 计算可视媒体], V3, P325
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lu YW, 2020, NEUROCOMPUTING, V410, P229, DOI 10.1016/j.neucom.2020.06.019
   Mao WC, 2020, OPT COMMUN, V468, DOI 10.1016/j.optcom.2020.125599
   Mingxin J., 2012, ACTA AUTOMAT SIN, V38, P531, DOI DOI 10.3724/SP.J.1004.2012.00531
   Muhammad U, 2019, IET COMPUT VIS, V13, P395, DOI 10.1049/iet-cvi.2018.5069
   NADARAYA EA, 1965, THEOR PROBAB APPL+, V10, P186, DOI 10.1137/1110024
   Peng L, 2015, SCI SURVEYING MAPPIN, V40, P41
   Phogat KS, 2020, INT J ROBUST NONLIN, V30, P4449, DOI 10.1002/rnc.4984
   Vasif VN, 2017, FORENSIC SCI INT, V278
   Wang X, 2018, IFAC PAPERSONLINE, V51, P292, DOI 10.1016/j.ifacol.2018.09.315
   White JH, 2020, IEEE-CAA J AUTOMATIC, V7, P942, DOI 10.1109/JAS.2020.1003222
   Xiangnan Z, 2020, EURASIP J WIREL COMM, V2020
   Xu T, 2015, INT C MECH MAT CHEM
   Yan C, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P642, DOI 10.1109/CISP.2015.7407957
   Ye L, 2021, ASIAN J CONTROL, V23, P1441, DOI 10.1002/asjc.2297
   YiGuo C, 2014, RES APPL CAMSHIFT KA, V3593, P1685
   Yilmaz S, 2017, SCI LETT
   Yun W, 2017, MULTIVEHICLE DETECTI
   Zhang K., 2013, COMPUTER SCI
   Zongwei Z, 2020, PATTERN RECOGN, V107
NR 36
TC 6
Z9 8
U1 7
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2145
EP 2159
DI 10.1007/s11042-021-11673-7
EA OCT 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000709303300001
PM 34690530
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Khattak, A
   Asghar, MZ
   Ali, M
   Batool, U
AF Khattak, Asad
   Asghar, Muhammad Zubair
   Ali, Mushtaq
   Batool, Ulfat
TI An efficient deep learning technique for facial emotion recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial emotion recognition; Deep learning; CNN; Age recognition; Gender
   recognition
ID MODEL
AB Emotion recognition from facial images is considered as a challenging task due to the varying nature of facial expressions. The prior studies on emotion classification from facial images using deep learning models have focused on emotion recognition from facial images but face the issue of performance degradation due to poor selection of layers in the convolutional neural network model.To address this issue, we propose an efficient deep learning technique using a convolutional neural network model for classifying emotions from facial images and detecting age and gender from the facial expressions efficiently. Experimental results show that the proposed model outperformed baseline works by achieving an accuracy of 95.65% for emotion recognition, 98.5% for age recognition, and 99.14% for gender recognition.
C1 [Khattak, Asad] Zayed Univ, Coll Technol Innovat, Abu Dhabi Campus, Abu Dhabi 144534, U Arab Emirates.
   [Asghar, Muhammad Zubair; Batool, Ulfat] Gomal Univ, Inst Comp & Informat Technol, Dikhan, KP, Pakistan.
   [Ali, Mushtaq] Hazara Univ Mansehra, Dept Informat Technol, Dhodial, Pakistan.
C3 Zayed University
RP Asghar, MZ (corresponding author), Gomal Univ, Inst Comp & Informat Technol, Dikhan, KP, Pakistan.
EM asad.khattak@zu.ac.ae; zubair@gu.edu.pk; mushtaqalihu@gmail.com;
   batoolu45@gmail.com
RI Asghar, Muhammad Zubair/M-6411-2015
OI Asghar, Muhammad Zubair/0000-0003-3320-2074
FU Zayed University Research Incentives Fund [R19096]
FX This Research work was supported by Zayed University Research Incentives
   Fund# R19096
CR Adil B, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON NETWORKING AND ADVANCED SYSTEMS (ICNAS 2019), P69, DOI 10.1109/icnas.2019.8807883
   All things Image, 2019, IMAGE PREPROCESSING
   All things Keras, 2019, KERAS DEEP LEARNING
   [Anonymous], 2018, Understanding of convolutional neural network (cnn)-deep learning
   [Anonymous], 2017, P INT SYST DES APPL
   Asghar MZ, 2017, COGN COMPUT, V9, P868, DOI 10.1007/s12559-017-9503-3
   Avots E, 2019, MACH VISION APPL, V30, P975, DOI 10.1007/s00138-018-0960-9
   Balasubramanian Balaji, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P945, DOI 10.1109/ICOEI.2019.8862731
   Bouzakraoui MS, 2019, PROCEEDINGS OF 2019 IEEE 4TH WORLD CONFERENCE ON COMPLEX SYSTEMS (WCCS' 19), P230, DOI 10.1109/icocs.2019.8930761
   Cadayona AM, 2019, 2019 IEEE 6TH INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING AND APPLICATIONS (ICIEA), P667, DOI 10.1109/IEA.2019.8715171
   Chen JK, 2017, MACH VISION APPL, V28, P173, DOI 10.1007/s00138-016-0817-z
   Das A, 2019, LECT NOTES COMPUT SC, V11129, P573, DOI 10.1007/978-3-030-11009-3_35
   Egger HL, 2011, INT J METH PSYCH RES, V20, P145, DOI 10.1002/mpr.343
   Fathallah A, 2017, I C COMP SYST APPLIC, P745, DOI 10.1109/AICCSA.2017.124
   Guo J., 2019, ICC 2019-2019 IEEE International Conference on Communications (ICC), P1
   Guo J, 2018, DOMINANT COMPLEMENTA
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Joseph A, 2020, VISUAL COMPUT, V36, P529, DOI 10.1007/s00371-019-01628-3
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   KOLODZIEJ M, 2018, IN 19 INTERCONF COMP, P1, DOI DOI 10.1109/CPEE.2018.8507137
   Li THS, 2019, IEEE ACCESS, V7, P93998, DOI 10.1109/ACCESS.2019.2928364
   Liu KC, 2019, INT CONF SYST SCI EN, P120, DOI [10.1109/icsse.2019.8823409, 10.1109/ICSSE.2019.8823409]
   Lopez-Martin M, 2017, IEEE ACCESS, V5, P18042, DOI 10.1109/ACCESS.2017.2747560
   Lopez-Rincon A, 2019, INT CONF ELECTR COMM, P146, DOI [10.1109/CONIELECOMP.2019.8673111, 10.1109/conielecomp.2019.8673111]
   Lucey P, 2010, UTKFACE DATASET
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mellouk W., 2020, Procedia Computer Science, V175, P689, DOI [DOI 10.1016/J.PROCS.2020.07.101, 10.1016/j.procs.2020.07.101]
   NITHYASHRI J, 2012, 4 INT C ADV COMP ICO, DOI DOI 10.1109/ICOAC.2012.6416855
   Ozdes M., 2019, 2019 Medical Technologies Congress (TIPTEKNO), P1
   Papapicco C, 2020, MULTIMED TOOLS APPL, V79, P35973, DOI 10.1007/s11042-020-09166-0
   Pathar R, 2019, PROCEEDINGS OF 2019 1ST INTERNATIONAL CONFERENCE ON INNOVATIONS IN INFORMATION AND COMMUNICATION TECHNOLOGY (ICIICT 2019), DOI 10.1109/iciict1.2019.8741491
   Patil Mrinalini, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0420, DOI 10.1109/ICCSP.2019.8698045
   Rao, 2019, CONVOLUTIONAL NEURAL
   Rasamoelina AD, 2019, IN 2019 IEEE INT S I, P1
   Shan K, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P123, DOI 10.1109/SERA.2017.7965717
   Sinha S, 2017, INTERRES J ENG TECHN, V04
   TAHA B, 2019, P IEEE CAN C EL COMP, P1
   Tripathi S, 2017, AAAI CONF ARTIF INTE, P4746
   Verma A, 2019, INT CONF SYST SIGNAL, P169, DOI [10.1109/IWSSIP.2019.8787215, 10.1109/iwssip.2019.8787215]
   Wu CH, 2019, CHIN CONTR CONF, P7572, DOI [10.23919/ChiCC.2019.8866311, 10.23919/chicc.2019.8866311]
   Wu H, 2018, COMPUT CHEM ENG, V115, P185, DOI 10.1016/j.compchemeng.2018.04.009
   Xue D, 2016, CLASSIFICATION EMOTI
   Yang ZY, 2019, IEEE INT CON MULTI, P1090, DOI 10.1109/ICME.2019.00191
   Yarlagadda A, 2015, J KING SAUD UNIV-COM, V27, P468, DOI 10.1016/j.jksuci.2014.10.005
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zadeh MMT, 2019, 2019 IEEE 5TH CONFERENCE ON KNOWLEDGE BASED ENGINEERING AND INNOVATION (KBEI 2019), P577, DOI 10.1109/KBEI.2019.8734943
   Zhong L, 2019, IEEE INT CONF AUTOMA, P270
   Zhu L, 2019, IEEE ACCESS, V7, P158389, DOI 10.1109/ACCESS.2019.2948388
NR 48
TC 31
Z9 31
U1 17
U2 96
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1649
EP 1683
DI 10.1007/s11042-021-11298-w
EA OCT 2021
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000705789000001
DA 2024-07-18
ER

PT J
AU Puri, N
   Alsadoon, A
   Prasad, PWC
   Alsalami, N
   Rashid, TA
AF Puri, Nirakar
   Alsadoon, Abeer
   Prasad, P. W. C.
   Alsalami, Nada
   Rashid, Tarik A.
TI Mixed reality using illumination-aware gradient mixing in surgical
   telepresence: enhanced multi-layer visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Virtual reality; Mixed reality; Surgical
   telepresence; Visualization; Illumination-aware; Image pixel
   correlation; Particle swarm optimization
ID AUTOMATIC TRIMAP GENERATION; VIDEO; COLLABORATION
AB Surgical telepresence using augmented perception has been applied, but mixed reality is still being researched and is only theoretical. The aim of this work is to propose a solution to improve the visualization in the final merged video by producing globally consistent videos when the intensity of illumination in the input source and target video varies. The proposed system uses an enhanced multi-layer visualization with illumination-aware gradient mixing using Illumination Aware Video Composition algorithm. Particle Swarm Optimization Algorithm is used to find the best sample pair from foreground and background region and image pixel correlation to estimate the alpha matte. Particle Swarm Optimization algorithm helps to get the original colour and depth of the unknown pixel in the unknown region. Our results showed improved accuracy caused by reducing the Mean squared Error for selecting the best sample pair for unknown region in 10 each sample for bowel, jaw and breast. The amount of this reduction is 16.48% from the state of art system. As a result, the visibility accuracy is improved from 89.4 to 97.7% which helped to clear the hand vision even in the difference of light. Illumination effect and alpha pixel correlation improves the visualization accuracy and produces a globally consistent composition results and maintains the temporal coherency when compositing two videos with high and inverse illumination effect. In addition, this paper provides a solution for selecting the best sampling pair for the unknown region to obtain the original colour and depth.
C1 [Puri, Nirakar; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Prasad, P. W. C.] Kent Inst Australia, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
   [Alsalami, Nada] Worcester State Univ, Comp Sci Dept, Worcester, MA USA.
   [Rashid, Tarik A.] Univ Kurdistan Hewler, Comp Sci & Engn, Erbil, Krg, Iraq.
C3 Charles Sturt University; Western Sydney University; Massachusetts
   System of Public Higher Education; Worcester State University;
   University of Kurdistan Hewler
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Western Sydney Univ WSU, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Rashid, Tarik A./HLX-0184-2023;
   Rashid, Tarik A./P-3473-2019
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Rashid, Tarik
   A./0000-0002-8661-258X; Rashid, Tarik A./0000-0002-8661-258X; withana,
   chandana/0000-0002-3007-687X
CR Archer Jesse, 2018, Computational Visual Media, V4, P277, DOI 10.1007/s41095-018-0118-8
   Basnet BR, 2018, ORAL MAXILLOFAC SURG, V22, P385, DOI 10.1007/s10006-018-0719-5
   Cho D, 2017, IEEE T PATTERN ANAL, V39, P1504, DOI 10.1109/TPAMI.2016.2606397
   Choi SH, 2018, COMPUT IND, V101, P51, DOI 10.1016/j.compind.2018.06.006
   de Lima ES, 2018, MULTIMED TOOLS APPL, V77, P2333, DOI 10.1007/s11042-017-4423-5
   Fang DK, 2020, MOBILE NETW APPL, V25, P412, DOI 10.1007/s11036-019-01244-4
   Henry C, 2019, EXPERT SYST APPL, V133, P242, DOI 10.1016/j.eswa.2019.05.019
   Huang WD, 2018, J MULTIMODAL USER IN, V12, P77, DOI 10.1007/s12193-017-0250-2
   Murugesan YP, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1889
   Oyekan J, 2017, FUTURE GENER COMP SY, V67, P83, DOI 10.1016/j.future.2016.08.012
   Pluhacek M, 2014, SOFT COMPUT, V18, P631, DOI 10.1007/s00500-014-1222-z
   Shakya K., 2018, AM J APPL SCI, V15, P497, DOI DOI 10.3844/AJASSP.2018.497.509
   Shen Y, 2012, COMPUT ANIMAT VIRT W, V23, P179, DOI 10.1002/cav.1465
   Si WX, 2018, IEEE ACCESS, V6, P31493, DOI 10.1109/ACCESS.2018.2843378
   Venkata HS, 2019, COMPUT METH PROG BIO, V177, P253, DOI 10.1016/j.cmpb.2019.05.025
   Wang HC, 2007, GRAPH MODELS, V69, P57, DOI 10.1016/j.gmod.2006.06.002
   Wang JY, 2019, IEEE T IMAGE PROCESS, V28, P5077, DOI 10.1109/TIP.2019.2916769
   Wang P, 2019, INT J ADV MANUF TECH, V102, P1339, DOI 10.1007/s00170-018-03237-1
   Yan XM, 2018, INT J MACH LEARN CYB, V9, P621, DOI 10.1007/s13042-016-0584-1
   Zhang M, 2019, OPT LASER TECHNOL, V120, DOI 10.1016/j.optlastec.2019.105680
NR 20
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 1153
EP 1178
DI 10.1007/s11042-021-11343-8
EA SEP 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000698561700001
DA 2024-07-18
ER

PT J
AU Hao, J
   Mou, J
   Xiong, L
   Zhang, YQ
   Gao, XY
   Sha, YW
AF Hao, Jin
   Mou, Jun
   Xiong, Li
   Zhang, Yingqian
   Gao, Xinyu
   Sha, Yuwen
TI A novel color image encryption algorithm based on the fractional order
   laser chaotic system and the DNA mutation principle
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic system; DNA encryption
ID SCHEME; SYNCHRONIZATION
AB A novel color image encryption algorithm based on the fractional order laser chaotic system and DNA mutation principle is proposed in this paper. Using phase diagram, Lyapunov exponential spectrum, bifurcation diagram and C0 complexity, the dynamic characteristics of the fractional-order laser chaotic system are analyzed, and the hardware circuit simulation of the chaotic system is realized on the DSP platform. Based on the comprehensive analysis of the system, we have designed an image encryption algorithm. Firstly, the chaotic sequence and Arnold matrix are used to scramble the value of the image. Then, in the diffusion link, DNA diffusion algorithm and DNA mutation theory were used for the first time, which increased the randomness of the matrix. The performances of the designed encryption scheme are analyzed by key space, correlation coefficients, information entropy, histogram, differential attacks and robustness analysis., the experimental results prove that the algorithm has strong encryption capabilities and can withstand multiple decryption methods. The new color image encryption scheme proposed in this paper can realize the secure communication of digital images.
C1 [Hao, Jin; Mou, Jun; Xiong, Li; Gao, Xinyu; Sha, Yuwen] Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.
   [Mou, Jun; Xiong, Li] Hexi Univ, Sch Phys & Electromech Engn, Zhangye 734000, Peoples R China.
   [Zhang, Yingqian] Xiamen Univ, Sch Informat Sci & Technol, Tan Kah Kee Coll, Zhangzhou 363105, Peoples R China.
C3 Dalian Polytechnic University; Hexi University; Xiamen University
RP Mou, J (corresponding author), Dalian Polytech Univ, Sch Informat Sci & Engn, Dalian 116000, Peoples R China.; Mou, J (corresponding author), Hexi Univ, Sch Phys & Electromech Engn, Zhangye 734000, Peoples R China.
EM moujun@csu.edu.cn
RI Zhang, Yingqian/CAI-2129-2022; Zhang, Ying-Qian/AGS-3457-2022
OI Zhang, Yingqian/0000-0001-9568-0392; Mou, Jun/0000-0002-7774-2833
FU Natural Science Foundation of Liaoning province [2020-MS-274]; National
   Natural Science Foundation of China [62061014]
FX This paper is funded by the Natural Science Foundation of Liaoning
   province(2020-MS-274) and National Natural Science Foundation of China
   (Grant Nos. 62061014).
CR Buyadzhi VV, 2017, NONLINEAR CHAOTIC DY
   Chai XL, 2017, INT J MOD PHYS C, V28, DOI 10.1142/S0129183117500693
   Chen C, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107340
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen HK, 2005, CHAOS SOLITON FRACT, V23, P1245, DOI 10.1016/j.chaos.2004.06.040
   Chen LP, 2020, NEURAL NETWORKS, V125, P174, DOI 10.1016/j.neunet.2020.02.008
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   Farwa S, 2018, APPL MATH COMPUT, V334, P343, DOI 10.1016/j.amc.2018.03.105
   Ghadirli HM, 2019, SIGNAL PROCESS, V164, P163, DOI 10.1016/j.sigpro.2019.06.010
   Hikal NA, 2020, J KING SAUD UNIV-COM, V32, P870, DOI 10.1016/j.jksuci.2018.09.006
   Inubushi M, 2015, IEICE NONLINEAR THEO, V6, P133, DOI 10.1587/nolta.6.133
   Khan A, 2020, INT J MODEL SIMUL, V40, P366, DOI 10.1080/02286203.2019.1644600
   Khennaoui AA, 2019, CHAOS SOLITON FRACT, V119, P150, DOI 10.1016/j.chaos.2018.12.019
   Khurana M, 2020, MULTIMED TOOLS APPL, V79, P13967, DOI 10.1007/s11042-020-08658-3
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Kumar R, 2018, INT ARAB J INF TECHN, V15, P763
   Lai Q, 2020, COMMUN NONLINEAR SCI, V89, DOI 10.1016/j.cnsns.2020.105341
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Li GD, 2019, VISUAL COMPUT, V35, P1267, DOI 10.1007/s00371-018-1574-y
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Li P, 2019, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0402-7
   Li X., 2018, Int. J. Netw. Secur, V20, P110, DOI DOI 10.6633/IJNS.201801
   Li XJ, 2021, OPT LASER TECHNOL, V140, DOI 10.1016/j.optlastec.2021.107074
   Liu H, 2013, OPT LASER TECHNOL, V50, P1, DOI 10.1016/j.optlastec.2013.02.003
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu WH, 2017, INT J BIFURCAT CHAOS, V27, DOI 10.1142/S0218127417501711
   Luo YL, 2015, COMMUN NONLINEAR SCI, V20, P447, DOI 10.1016/j.cnsns.2014.05.022
   Malik A, 2018, MULTIMED TOOLS APPL, V77, P15803, DOI 10.1007/s11042-017-5156-1
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Natiq H, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010034
   Pecora LM, 2015, CHAOS, V25, DOI 10.1063/1.4917383
   Peng YX, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21010027
   Qin Y, 2018, OPT LASER ENG, V105, P118, DOI 10.1016/j.optlaseng.2018.01.014
   Rosenbluh M, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.046207
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Shukla MK, 2018, 2018 INT C INT CIRC
   Silva-García VM, 2018, APPL MATH COMPUT, V332, P123, DOI 10.1016/j.amc.2018.03.019
   Sun SL, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2817550
   Suryadi MT, 2018, J PHYS CONF SER, V974, DOI 10.1088/1742-6596/974/1/012028
   Vilardy JM, 2019, J PHY C
   Wang XY, 2018, MULTIMED TOOLS APPL, V77, P6243, DOI 10.1007/s11042-017-4534-z
   Wang XY, 2015, NONLINEAR DYNAM, V82, P1269, DOI 10.1007/s11071-015-2234-7
   Wang Yuhui, 2012, High Power Laser and Particle Beams, V24, P2063, DOI 10.3788/HPLPB20122409.2063
   Xu BR, 2019, NONLINEAR DYNAM, V96, P765, DOI 10.1007/s11071-019-04820-1
   Yang FF, 2020, OPT LASER ENG, V129, DOI 10.1016/j.optlaseng.2020.106031
   Yassen MT, 2005, CHAOS SOLITON FRACT, V23, P131, DOI 10.1016/j.chaos.2004.03.038
   Ye XL, 2020, NONLINEAR DYNAM, V99, P1489, DOI 10.1007/s11071-019-05370-2
   Zhang LM, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/10/100504
   Zhang Li-wen, 2010, Proceedings 2010 International Conference on Computational Intelligence and Security (CIS 2010), P437, DOI 10.1109/CIS.2010.101
   Zhang SY, 2018, ADV DIFFER EQU-NY, DOI 10.1186/s13662-018-1863-9
NR 50
TC 6
Z9 6
U1 4
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 559
EP 587
DI 10.1007/s11042-021-11431-9
EA SEP 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000695787100005
DA 2024-07-18
ER

PT J
AU Varshney, N
   Bakariya, B
   Kushwaha, AKS
AF Varshney, Neeraj
   Bakariya, Brijesh
   Kushwaha, Alok Kumar Singh
TI Human activity recognition using deep transfer learning of cross
   position sensor based on vertical distribution of data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transfer learning; Multi class classification; Sensor data; Human
   activity recognition; Deep learning
AB Sensor-based human activity recognition and health monitoring are attaining great interest in the eye of the researcher as it maintained the privacy of an individual. A model based on the transfer learning for the vertical distribution of cross position sensor data is proposed in this paper. The whole human body participates during an activity like walking, jumping, running, etc. When someone walk, run, jump, upstairs downstairs his hands and lags both act as per the activity. Existing methods of human activity recognition using sensor data learn from one dataset and transfer that learning for another one but in the proposed work combine learning of accelerometer, magnetometer and gyroscope placed at ankle of the body is used as starting point for the lower arm of the body. combination of sensor data from three sensors (accelerometer, gyroscope, magnetometer) obtain better result as compare to an individual and other combinations. Two publically available datasets are used, i.e. mHEALTH and PAMAP2. The proposed model has been compared to the state of art approaches. The experimental results show that the proposed approach performs batter compare to state-of-the-art methods. Model score 98.48 and 98.63 % test accuracy for balanced and unbalanced mHEALTH dataset and achieved 92.00 and 94.19 % test accuracy for balanced and unbalanced PAMAP2 dataset.
C1 [Varshney, Neeraj] I K Gujral Punjab Tech Univ, Kapurthala, India.
   [Bakariya, Brijesh] I K Gujral Punjab Tech Univ, Hoshiarpur Campus, Hoshiarpur, India.
   [Kushwaha, Alok Kumar Singh] Guru Ghasidas Vishwavidyalaya, Bilaspur, India.
C3 I. K. Gujral Punjab Technical University; I. K. Gujral Punjab Technical
   University; Guru Ghasidas Vishwavidyalaya
RP Varshney, N (corresponding author), I K Gujral Punjab Tech Univ, Kapurthala, India.
EM neeraj.varshney@gla.ac.in; dr.brijeshbakariya@ptu.ac.in;
   alokkumarsingh.jk@gmail.com
RI bakariya, brijesh/ABB-5497-2021; VARSHNEY, NEERAJ/AAD-9051-2019
OI KUSHWAHA, ALOK KUMAR SINGH/0000-0003-2928-998X
CR Akbari A, 2019, IPSN '19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS, P85, DOI 10.1145/3302506.3310391
   Banos Oresti, 2014, Ambient Assisted Living and Daily Activities. 6th International Work-Conference, IWAAL 2014. Proceedings: LNCS 8868, P91, DOI 10.1007/978-3-319-13105-4_14
   Cao L, 2018, J PARALLEL DISTR COM, V118, P67, DOI 10.1016/j.jpdc.2017.05.007
   Chen YQ, 2015, IEEE SYS MAN CYBERN, P1488, DOI 10.1109/SMC.2015.263
   Chun Zhu, 2009, 2009 4th ACM/IEEE International Conference on Human-Robot Interaction (HRI), P303
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu FQ, 2018, IEEE INTERNET THINGS, V5, P2085, DOI 10.1109/JIOT.2018.2823084
   Guo HD, 2016, UBICOMP'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1112, DOI 10.1145/2971648.2971708
   Gupta, 2020, DEEP CONVL STM SELF
   Hammerla N.Y., 2016, P 25 INT JOINT C ART
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Kasnesis P, 2019, ADV INTELL SYST COMP, V868, P101, DOI 10.1007/978-3-030-01054-6_7
   Khowaja SA, 2017, EXPERT SYST APPL, V88, P165, DOI 10.1016/j.eswa.2017.06.040
   Lee SM, 2017, INT CONF BIG DATA, P131, DOI 10.1109/BIGCOMP.2017.7881728
   Nguyen H.D., 2020, RELIABILITY STAT COM, P207
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   OShea K., 2015, ARXIV151108458, DOI DOI 10.48550/ARXIV.1511.08458
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pratt LorienY., 1993, Discriminability-Based Transfer between Neural Networks
   Qian HW, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5614
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Tahir SBUD, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22050579
   Tsiakmaki M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062145
   Uddin MZ, 2020, INFORM FUSION, V55, P105, DOI 10.1016/j.inffus.2019.08.004
   Wang J, 2019, PUBLIC HEALTH NUTR, V22, P654, DOI 10.1017/S1368980018002628
   Xi R, 2018, IEEE ACCESS, V6, P53381, DOI 10.1109/ACCESS.2018.2870841
   Zebin T, 2016, IEEE SENSOR
NR 27
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22307
EP 22322
DI 10.1007/s11042-021-11131-4
EA SEP 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000692075300001
DA 2024-07-18
ER

PT J
AU Huan, RH
   Zhan, ZW
   Ge, LQ
   Chi, KK
   Chen, P
   Liang, RH
AF Huan, Ruohong
   Zhan, Ziwei
   Ge, Luoqi
   Chi, Kaikai
   Chen, Peng
   Liang, Ronghua
TI A hybrid CNN and BLSTM network for human complex activity recognition
   with multi-feature fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Complex activity recognition; Deep learning; CNN; BLSTM; Feature fusion;
   Feature selection
AB A hybrid convolutional neural network (CNN) and bidirectional long short-term memory (BLSTM) network for human complex activity recognition with multi-feature fusion is proposed in this paper. Specifically, a new CNN model is designed to extract the spatial features from the sensor data. Considering that in the process of activity recognition, the output at the current moment is not only related to the previous state, but also to the subsequent state. BLSTM network is further used to extract the temporal context of state information to improve the performance of activity recognition. In order to fully mine the features from the sensor data and further improve the performance of activity recognition, a new feature selection method named SFSANW (sequential forward selection and network weights), which is based on sequential forward selection algorithm and network weights is proposed to select features extracted by the traditional methods to obtain dominant features. The dominant features are then fused with the feature vectors extracted by the hybrid CNN and BLSTM network. Experiments are performed on two complex activity datasets, PAMAP2 and UT-Data, and 92.23% and 98.07% F1 scores are obtained, respectively. The experimental results demonstrate that the proposed method can achieve better performance of complex activity recognition, which is superior to the traditional machine learning algorithms and the state-of-the-art deep learning algorithms.
C1 [Huan, Ruohong; Zhan, Ziwei; Ge, Luoqi; Chi, Kaikai; Chen, Peng; Liang, Ronghua] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
C3 Zhejiang University of Technology
RP Huan, RH (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
EM huanrh@zjut.edu.cn; yufengjue@qq.com; 2450894732@qq.com;
   kkchi@zjut.edu.cn; chenpeng@zjut.edu.cn; rhliang@zjut.edu.cn
RI liang, ronghua/H-4463-2012; Chen, Peng/T-7500-2019
OI Chen, Peng/0000-0001-6122-0574
FU Zhejiang Provincial Natural Science Foundation of China [LY19F020032];
   National Natural Science Foundation of China [61872322, U1909203,
   62036009]
FX This work was supported by the Zhejiang Provincial Natural Science
   Foundation of China [grant number LY19F020032], and National Natural
   Science Foundation of China [grant number 61872322, U1909203, 62036009].
CR Alo U.R., 2018, 2018 INT C COMPUTING, P1
   [Anonymous], 2015, P ACM INT JOINT C PE
   Blanke U, 2009, LECT NOTES COMPUT SC, V5561, P192, DOI 10.1007/978-3-642-01721-6_12
   Ciabattoni L, 2018, IEEE ICCE
   Dernbach S., 2012, Proceedings of the Eighth International Conference on Intelligent Environments (IE 2012), P214, DOI 10.1109/IE.2012.39
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Edel M, 2016, INT C INDOOR POSIT
   Gacav C, 2016, 2016 24TH SIGNAL PROCESSING AND COMMUNICATION APPLICATION CONFERENCE (SIU), P1481, DOI 10.1109/SIU.2016.7496031
   Gil-Martín M, 2020, COMPUT ELECTR ENG, V88, DOI 10.1016/j.compeleceng.2020.106822
   Guiry JJ, 2014, SENSORS-BASEL, V14, P5687, DOI 10.3390/s140305687
   Ha S, 2016, IEEE IJCNN, P381, DOI 10.1109/IJCNN.2016.7727224
   Hammerla N.Y., 2016, P 25 INT JOINT C ART
   Haque MR, 2019, IEEE SOUTHEASTCON, DOI 10.1109/southeastcon42311.2019.9020642
   Hernandez F, 2019, SYMP IMAG SIG PROC A, P1, DOI 10.1109/stsiva.2019.8730249
   Huynh T., 2005, P 2005 JOINT C SMART, P159
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   Lee SM, 2017, INT CONF BIG DATA, P131, DOI 10.1109/BIGCOMP.2017.7881728
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu L, 2016, INFORM SCIENCES, V340, P41, DOI 10.1016/j.ins.2016.01.020
   Liu L, 2015, KNOWL-BASED SYST, V90, P138, DOI 10.1016/j.knosys.2015.09.024
   Lv MQ, 2019, NEUROCOMPUTING, V362, P33, DOI 10.1016/j.neucom.2019.06.051
   Mobark M., 2017, P 2 INT C INF COMP I, P1
   Münzner S, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS (ISWC 17), P158, DOI 10.1145/3123021.3123046
   Murahari VS, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P100, DOI 10.1145/3267242.3267287
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Peng LY, 2019, IEEE T MOBILE COMPUT, V18, P1488, DOI 10.1109/TMC.2018.2863292
   Peng LY, 2017, IEEE T BIO-MED ENG, V64, P1369, DOI 10.1109/TBME.2016.2604856
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Rueda FM, 2018, INFORMATICS-BASEL, V5, DOI 10.3390/informatics5020026
   Sabour S, 2017, ADV NEUR IN, V30
   Saguna, 2013, ACM T COMPUT-HUM INT, V20, DOI 10.1145/2490832
   Seiter J, 2014, PERVASIVE MOB COMPUT, V15, P215, DOI 10.1016/j.pmcj.2014.05.007
   Shoaib M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16040426
   Huynh T, 2008, PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING (UBICOMP 2008), P10
   Wan SH, 2020, MOBILE NETW APPL, V25, P743, DOI 10.1007/s11036-019-01445-x
   Yang Z, 2018, IEEE ACCESS, V6, P56750, DOI 10.1109/ACCESS.2018.2873315
   Yu Guan, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3090076
   Yu Shen, 2018, 2018 IEEE Power & Energy Society General Meeting (PESGM), DOI 10.1109/PESGM.2018.8586593
   Yu T, 2018, INT CONF WIRE COMMUN
   Zeng M, 2018, ISWC'18: PROCEEDINGS OF THE 2018 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P56, DOI 10.1145/3267242.3267286
   Zheng ZW, 2019, LECT NOTES COMPUT SC, V11729, P498, DOI 10.1007/978-3-030-30508-6_40
   Zuo Z, 2016, IEEE T IMAGE PROCESS, V25, P2983, DOI 10.1109/TIP.2016.2548241
NR 42
TC 7
Z9 7
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36159
EP 36182
DI 10.1007/s11042-021-11363-4
EA SEP 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000691930500001
DA 2024-07-18
ER

PT J
AU Choudhary, M
   Tiwari, V
   Jain, S
AF Choudhary, Meenakshi
   Tiwari, Vivek
   Jain, Swati
TI Person re-identification using deep siamese network with multi-layer
   similarity constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Surveillance systems; Deep Siamese Network;
   Multi-layer similarity constraints
AB Person Re-identification is aimed to identify a person through multiple camera views. The task has attained a huge research interest due to its apparent importance in surveillance systems from security aspects. This paper introduces a novel methodology based on Siamese architecture with multi-layer similarity constraints. The baseline model embraces two dense blocks to preserve feature maps at each convolutional layer. Besides, the model training is performed by applying distinct similarity constraints on low-level and high-level layers. Two important observations validate the robustness of the proposed model. First, the similarity constraints can synchronize with the model's classification constraints and produce a unified multi-tasking network. Second, the similarity patterns are encoded in the framework in terms of learning parameters during model training. Therefore, a single image is required at the test time instead of the image pair, which makes the method time-efficient and suitable for wide-scale real-time applications. Experimental outcomes on various distinct datasets show that the proposed method surpasses the existing performance benchmarks for person re-identification.
C1 [Choudhary, Meenakshi; Tiwari, Vivek] DSPM IIIT Naya Raipur, Naya Raipur, India.
   [Jain, Swati] Govt J Yoganandam Chhattisgarh Coll, Raipur, CG, India.
RP Jain, S (corresponding author), Govt J Yoganandam Chhattisgarh Coll, Raipur, CG, India.
EM sjcscghedrp@gmail.com
RI Choudhary, Meenakshi/AAE-7545-2022
OI Choudhary, Meenakshi/0000-0002-6315-087X
CR [Anonymous], 2016, SURVEY LEARNING HASH
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2016, MULTITASK DEEP NETWO
   [Anonymous], 2016, ARXIV161201341
   Basha SM, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY (ICIT 2017), P96, DOI 10.1145/3176653.3176665
   Chen CH, 2021, MAGN RESON CHEM, V59, P975, DOI 10.1002/mrc.5141
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Choudhary M, 2019, SOFT COMPUT, P1
   Choudhary M, 2020, IEEE T CYBERN
   Choudhary M, 2021, NEURAL COMPUT APPL, V33, P5609, DOI 10.1007/s00521-020-05342-3
   Choudhary M, 2020, MULTIMED TOOLS APPL, V79, P32807, DOI 10.1007/s11042-020-09286-7
   Choudhary M, 2020, APPL SOFT COMPUT, V91, DOI 10.1016/j.asoc.2020.106206
   Choudhary M, 2019, FUTURE GENER COMP SY, V101, P1259, DOI 10.1016/j.future.2019.07.003
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Galiyawala H, 2021, MULTIMED TOOLS APPL, V80, P27343, DOI 10.1007/s11042-021-10983-0
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jose C, 2016, LECT NOTES COMPUT SC, V9909, P875, DOI 10.1007/978-3-319-46454-1_53
   Khan MBE, 2022, MAG CONCRETE RES, V74, P91, DOI 10.1680/jmacr.20.00162
   Li S, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2155
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Liu XK, 2015, IEEE WINT CONF APPL, P868, DOI 10.1109/WACV.2015.120
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Ma XL, 2017, PATTERN RECOGN, V65, P197, DOI 10.1016/j.patcog.2016.11.018
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen C, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1942, DOI 10.1145/3123266.3123452
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Soliman A., 2019, Proceedings of the 3rd ACM SIGSPATIAL international workshop on AI for geographic knowledge discovery, P69, DOI [10.1145/3356471.3365240, DOI 10.1145/3356471.3365240]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Subramaniam A, 2016, ADV NEUR IN, V29
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yukun Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14072, DOI 10.1109/CVPR42600.2020.01409
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao R, 2014, PROC CVPR IEEE, P144, DOI 10.1109/CVPR.2014.26
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
NR 58
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2022
VL 81
IS 29
BP 42099
EP 42115
DI 10.1007/s11042-021-11292-2
EA AUG 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 6M4LG
UT WOS:000687926200007
DA 2024-07-18
ER

PT J
AU Kaur, M
   Mehta, H
   Randhawa, S
   Sharma, PK
   Park, JH
AF Kaur, Maninder
   Mehta, Himika
   Randhawa, Sukhchandan
   Sharma, Pradip Kumar
   Park, Jong Hyuk
TI Ensemble learning-based prediction of contentment score using social
   multimedia in education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Student contentment; Regression; Machine learning; Ensemble approach
ID STUDENT SATISFACTION; DISTANCE; SUPPORT
AB Over the years, social multimedia has gained credibility as a source of information and a reliable platform on which organizations, students and employees can interact with expert audiences. In the areas of education and teaching, the technique, multimedia and network of use computerized methods to build a creative environment for learners and broaden our perspective on a variety of topics. Getting new information and sharing it with others has become much easier with social multimedia. To boost the productivity and growth of any university, student contentment is a critical factor. Student contentment level is the need of the hour that is necessitated to be analyzed every year for the progress of the university. In this paper, we use a social multimedia technique to collect data from the students of the university based on a designed questionnaire circulated. The collected information embraces different aspects like academics, research, recreational, and technology that portray the image of the university. The current work relies on developing a stacking ensemble machine learning model for prediction of student's overall contentment score, an indicator to perceive overall, how much the university gets the thumbs up from its current students. The work employs the cuckoo search meta-heuristic based wrapper method for feature selection from the original dataset with 78 features. The proposed ensemble model portrayed a lowest RMSE value of 0.373 by the combination of Self Organizing Map, Multilayer Perceptron, Boosted Generalized Linear Model and Gaussian Process with Polynomial Kernel along with Partial Least Squares as meta-learner, showcasing its ability to accurately predict student contentment levels of a University. The proposed machine learning framework acts as a great developmental tool for foreseeing and analyzing student contentment for its university.
C1 [Kaur, Maninder; Mehta, Himika; Randhawa, Sukhchandan] Thapar Univ, Dept Comp Sci & Engn, Patiala 147004, Punjab, India.
   [Sharma, Pradip Kumar] Univ Aberdeen, Dept Comp Sci, Aberdeen AB24 3FX, Scotland.
   [Park, Jong Hyuk] Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, SeoulTech, Seoul 01811, South Korea.
C3 Thapar Institute of Engineering & Technology; University of Aberdeen;
   Seoul National University of Science & Technology
RP Park, JH (corresponding author), Seoul Natl Univ Sci & Technol, Dept Comp Sci & Engn, SeoulTech, Seoul 01811, South Korea.
EM jhpark1@seoultech.ac.kr
RI Kaur, Maninder/IXD-4944-2023; Sharma, Pradip Kumar/I-8803-2019; Park,
   Jong Hyuk/AHD-6698-2022
OI Kaur, Maninder/0000-0001-7948-8085; Sharma, Pradip
   Kumar/0000-0001-6620-9083; 
CR Anastasiades PS, 2008, COMPUT EDUC, V50, P1527, DOI 10.1016/j.compedu.2007.02.003
   [Anonymous], 2010, GTOOLS VARIOUS R PRO
   [Anonymous], 2014, IEEE IST AFR C P
   Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Armenski G, 2014, IEEE GLOB ENG EDUC C, P630, DOI 10.1109/EDUCON.2014.6826159
   Athiyaman A., 1997, EUR J MARKETING, V31, P528, DOI DOI 10.1108/03090569710176655
   Babic ID, 2015, CROAT OPER RES REV, V6, P105, DOI 10.17535/crorr.2015.0009
   Becker S.A., 2018, NMC HORIZON REPORT 2
   Bolliger D.U., 2004, INT J E LEARNING, V3, P61
   Carney R., 1994, P S MARK HIGH ED AM
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Choudhary, 2012, INT C INF TECHN BAS, P1
   de Wit H, 2020, J INT STUDENTS, V10, pI, DOI 10.32674/jis.v10i1.1893
   Dejaeger K, 2012, EUR J OPER RES, V218, P548, DOI 10.1016/j.ejor.2011.11.022
   Faour H, 2012, INT C ED E LEARN INN, P1
   Gu K, 2019, SOFT COMPUT, V23, P6267, DOI 10.1007/s00500-018-3283-x
   Guo WW, 2010, EXPERT SYST APPL, V37, P3358, DOI 10.1016/j.eswa.2009.10.014
   Huang CX, 2019, NEUROCOMPUTING, V325, P283, DOI 10.1016/j.neucom.2018.09.065
   Kamis T, 2015, 2015 INNOVATION & COMMERCIALIZATION OF MEDICAL ELECTRONIC TECHNOLOGY CONFERENCE (ICMET), P114, DOI 10.1109/ICMETC.2015.7449584
   Kumar KK., 2012, IEEE INT C ENG ED, P1
   Kuo YC, 2013, INT REV RES OPEN DIS, V14, P16, DOI 10.19173/irrodl.v14i1.1338
   Lee HJ, 2009, EDUC TECHNOL SOC, V12, P372
   Li F, 2013, NEUROCOMPUTING, V116, P301, DOI 10.1016/j.neucom.2012.05.032
   Littlejohn A, 2008, COMPUT EDUC, V50, P757, DOI 10.1016/j.compedu.2006.08.004
   Long M, 2019, CMC-COMPUT MATER CON, V58, P493, DOI 10.32604/cmc.2019.04378
   Manzoor H., 2013, Global Journal of Management And Business Research
   Méndez-Giménez A, 2017, REV PSICODIDACT, V22, P150, DOI 10.1016/j.psicoe.2017.05.004
   Mo H, 2009, SCI CHINA SER F, V52, P780, DOI 10.1007/s11432-009-0089-6
   Negricea CI, 2014, PROCD SOC BEHV, V116, P4430, DOI 10.1016/j.sbspro.2014.01.961
   Nikolic S, 2015, IEEE T EDUC, V58, P151, DOI 10.1109/TE.2014.2346474
   Onditi E.O., 2017, International Journal of Scientific and Research Publications, V7, P328
   Rjaibi N, 2012, INT C ED E LEARN INN, P1
   Salvador-Ferrer C, 2017, AN PSICOL-SPAIN, V33, P114, DOI 10.6018/analesps.33.1.226671
   Song H, 2019, J INF PROCESS SYST, V15, P645, DOI 10.3745/JIPS.01.0044
   Tessema M.T., 2012, INT J HUMANITIES SOC, V2, P34
   Witten IH, 2011, MOR KAUF D, P1
   Xue Zhang, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P46, DOI 10.1109/ICSAI.2012.6223045
   Yin CY, 2019, HUM-CENT COMPUT INFO, V9, DOI 10.1186/s13673-019-0177-6
   Yukselturk E, 2008, EDUC TECHNOL SOC, V11, P51
   Zamakhsari Z, 2015, 2015 IEEE CONFERENCE ON E-LEARNING, E-MANAGEMENT AND E-SERVICES (IC3E), P143, DOI 10.1109/IC3e.2015.7403502
NR 40
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34423
EP 34440
DI 10.1007/s11042-021-10806-2
EA AUG 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000687926200003
DA 2024-07-18
ER

PT J
AU Sun, C
   Wen, M
   Zhang, K
   Meng, P
   Cui, RC
AF Sun, Chao
   Wen, Mi
   Zhang, Kai
   Meng, Ping
   Cui, Rongcheng
TI Traffic sign detection algorithm based on feature expression enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Target detection; Traffic sign detection; Small object detection; SSD
   algorithm
ID CONVOLUTIONAL NETWORKS; OBJECT DETECTION
AB Traffic sign detection is an important research direction in computer vision, which is of great significance for autonomous driving and advanced assisted driving systems. Due to the complexity of traffic signs in natural scenes, existing traffic sign detection algorithms have disadvantages such as high false detection rates and poor robustness. To improve the accuracy of traffic sign detection, a feature expression enhanced SSD(ESSD) detection algorithm is proposed. ESSD extracts semantic information in a lightweight way, adds detailed information for fusion, and forms a new feature map through multiple convolution operations to enhance feature expression. Meanwhile, a new target default box was designed to increase the focus on traffic signs. The SSD and ESSD were retrained on TT100K and CCTSDB datasets. Experimental results show that the mAP of the improved ESSD is 81.26% and 90.52% and can improve AP up to 40%. The robustness of the ESSD model was verified using the PASCAL VOC data set, which showed better detection of small objects.
C1 [Sun, Chao; Wen, Mi; Zhang, Kai; Meng, Ping; Cui, Rongcheng] Shanghai Univ Elect Power, Coll Comp Technol & Sci, Shanghai 200090, Peoples R China.
C3 Shanghai University of Electric Power
RP Zhang, K (corresponding author), Shanghai Univ Elect Power, Coll Comp Technol & Sci, Shanghai 200090, Peoples R China.
EM kzhang@shiep.edu.cn
RI cui, rongcheng/HSE-7993-2023
OI cui, rongcheng/0000-0001-8498-7209; Zhang, Kai/0000-0001-9728-4051
FU National Natural Science Foundation of China [61872230, U1936213,
   61802248, 61802249]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61872230, U1936213, No. 61802248, No. 61802249.
CR Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YC, 2020, IEEE T NETW SCI ENG, V7, P3279, DOI 10.1109/TNSE.2020.3024723
   Deng CF, 2022, IEEE T MULTIMEDIA, V24, P1968, DOI 10.1109/TMM.2021.3074273
   Everingham M., 2005, P MACHINE LEARNING C, P117
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Fu MY, 2010, INT C WAVEL ANAL PAT, P119, DOI 10.1109/ICWAPR.2010.5576425
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jeong J., 2017, P BRIT MACH VIS C, DOI [10.5244/C.31.76, DOI 10.5244/C.31.76]
   Klambauer G., 2017, Self-normalizing neural networks, P30, DOI 10.5555/3294771.3294864
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li Z., 2017, CORR
   Lian Duan, 2011, 2011 IEEE International Conference on Vehicular Electronics and Safety (ICVES 2011), P238, DOI 10.1109/ICVES.2011.5983821
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ring Haogiang, 2018, Computer Engineering, V44, P228, DOI 10.19678/j.issn.1000-3428.0048553
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2013, Advances in Neural Information Processing Systems, V26, P2553
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   [温捷文 Wen Jiewen], 2019, [计算机应用研究, Application Research of Computers], V36, P861
   Zhang JM, 2017, ALGORITHMS, V10, DOI 10.3390/a10040127
   Zou Z., 2019, ARXIV PREPRINT ARXIV
NR 34
TC 5
Z9 5
U1 9
U2 75
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33593
EP 33614
DI 10.1007/s11042-021-11413-x
EA AUG 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687012300001
DA 2024-07-18
ER

PT J
AU Alvin, M
   Adhinugraha, KM
   Alamri, S
   Mir, U
AF Alvin, Matias
   Adhinugraha, Kiki Maulana
   Alamri, Sultan
   Mir, Usama
TI Influence zone expansion for reverse k nearest neighbours query
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic k; Expansion; Influence zone; Region approach RkNN
ID ALGORITHM; TAXONOMY; SEARCH
AB The influence zone method is used to answer reverse k nearest neighbours (RkNN) queries using a region approach without having to verify each object; this makes the answering of a RkNN query more efficient than does the conventional point-to-point approach. However, the influence zone is unable to answer the dynamic value of k efficiently as it needs to know this value in advance. In this paper, a concept is introduced whereby the influence zone is expanded to enable answering the dynamic value of k as well. Furthermore, a concept is proposed that expands the influence zone of k= 1. Experimental results indicate that the expanded influence zone is able to answer RkNN queries even when the k value is dynamic, without the need to recompute it. Furthermore, the experiments show that the use of pre-computed regions will provide a stable query time for any value of k.
C1 [Alvin, Matias] Telkom Univ, Bandung 40257, Jawa Barat, Indonesia.
   [Adhinugraha, Kiki Maulana] La Trobe Univ, Melbourne, Vic, Australia.
   [Alamri, Sultan; Mir, Usama] Saudi Elect Univ, Riyadh, Saudi Arabia.
C3 Telkom University; La Trobe University; Saudi Electronic University
RP Alamri, S (corresponding author), Saudi Elect Univ, Riyadh, Saudi Arabia.
EM alvinmatias@students.telkomunversity.ac.id;
   k.adhinugraha@latrobe.edu.au; salamri@seu.edu.sa; U.Mir@seu.edu.sa
RI Mir, Usama/HNT-0516-2023
OI Alamri, Sultan/0000-0001-8429-6598
CR Adhinugraha KM, 2014, INT CON ADV INFO NET, P457, DOI 10.1109/AINA.2014.57
   Adhinugraha KM, 2014, CONCURR COMP-PRACT E, V26, P1142, DOI 10.1002/cpe.3056
   Alamri S, 2021, ISPRS INT J GEO-INF, V10, DOI 10.3390/ijgi10010008
   Alamri S, 2018, INT J WEB INF SYST, V14, P402, DOI 10.1108/IJWIS-05-2018-0039
   Alamri S, 2014, FUTURE GENER COMP SY, V37, P232, DOI 10.1016/j.future.2014.02.007
   AURENHAMMER F, 1991, COMPUT SURV, V23, P345, DOI 10.1145/116873.116880
   Bryant A, 2018, IEEE T KNOWL DATA EN, V30, P1109, DOI 10.1109/TKDE.2017.2787640
   Cheema MA, 2011, PROC INT CONF DATA, P577, DOI 10.1109/ICDE.2011.5767904
   Feng L, 2018, PH SENSITIVE POLYMER, P1, DOI DOI 10.1002/APP.45886,45886
   GOTOH Y, 2014, NETW BAS INF SYST NB, P614, DOI DOI 10.1109/NBIS.2014.55
   Gu Y, 2014, J INF SCI ENG, V30, P1569
   HongKui Yu, 2009, 2009 International Conference on Test and Measurement (ICTM 2009), P217, DOI 10.1109/ICTM.2009.5413070
   Hu LX, 2015, INT CONF MEAS, P6, DOI 10.1109/ICMTMA.2015.10
   Kang JamesM., 2007, ICDE, P806, DOI DOI 10.1109/ICDE.2007.367926
   Korn F, 2000, SIGMOD REC, V29, P201, DOI 10.1145/335191.335415
   Li B, 2011, GEOINF 2011 19 INT C, P1
   Okabe A, 2009, WILEY SERIES PROBABI
   Riviére S, 2007, ISVD 2007: THE 4TH INTERNATIONAL SYMPOSIUM ON VORONOI DIAGRAMS IN SCIENCE AND ENGINEERING 2007, PROCEEDINGS, P168
   Safar M, 2009, MULTIMEDIA SYST, V15, P295, DOI 10.1007/s00530-009-0167-z
   Shamos Michael Ian, 1975, 16 ANN S FDN COMP SC, P151, DOI [10.1109/SFCS.1975.8, DOI 10.1109/SFCS.1975.8]
   Stanoi I., 2001, Proceedings of the 27th International Conference on Very Large Data Bases, P99
   Taniar D, 2015, J COMPUT SYST SCI, V81, P1508, DOI 10.1016/j.jcss.2014.12.025
   Taniar D, 2013, J COMPUT SYST SCI, V79, P1017, DOI 10.1016/j.jcss.2013.01.017
   Tran QT, 2009, LECT NOTES COMPUT SC, V5740, P353, DOI 10.1007/978-3-642-03722-1_14
   Wang S, 2018, IEEE T KNOWL DATA EN, V30, P757, DOI 10.1109/TKDE.2017.2776268
   Wang SL, 2015, COMPUT J, V58, P40, DOI 10.1093/comjnl/bxt115
   Weihua Lin, 2009, 2009 1st International Conference on Information Science and Engineering (ICISE 2009), P2168, DOI 10.1109/ICISE.2009.1029
   Yang SY, 2017, VLDB J, V26, P151, DOI 10.1007/s00778-016-0445-2
   Zhang J., 2003, P 2003 ACM SIGMOD C, P443
NR 29
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 15253
EP 15266
DI 10.1007/s11042-021-11275-3
EA AUG 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:000683639000003
DA 2024-07-18
ER

PT J
AU Narayanan, KL
   Krishnan, RS
   Son, LH
   Tung, NT
   Julie, EG
   Robinson, YH
   Kumar, R
   Gerogiannis, VC
AF Narayanan, K. Lakshmi
   Krishnan, R. Santhana
   Son, Le Hoang
   Tung, Nguyen Thanh
   Julie, E. Golden
   Robinson, Y. Harold
   Kumar, Raghvendra
   Gerogiannis, Vassilis C.
TI Fuzzy Guided Autonomous Nursing Robot through Wireless Beacon Network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Robotics; Smart hospital; Ultrasonic sensor; Fuzzy logic; Bluetooth low
   energy beacon; Raspberry pi; Wireless beacon network
AB Robotics is one of the most emerging technologies today, and are used in a variety of applications, ranging from complex rocket technology to monitoring of crops in agriculture. Robots can be exceptionally useful in a smart hospital environment provided that they are equipped with improved vision capabilities for detection and avoidance of obstacles present in their path, thus allowing robots to perform their tasks without any disturbance. In the particular case of Autonomous Nursing Robots, major essential issues are effective robot path planning for the delivery of medicines to patients, measuring the patient body parameters through sensors, interacting with and informing the patient, by means of voice-based modules, about the doctors visiting schedule, his/her body parameter details, etc. This paper presents an approach of a complete Autonomous Nursing Robot which supports all the aforementioned tasks. In this paper, we present a new Autonomous Nursing Robot system capable of operating in a smart hospital environment area. The objective of the system is to identify the patient room, perform robot path planning for the delivery of medicines to a patient, and measure the patient body parameters, through a wireless BLE (Bluetooth Low Energy) beacon receiver and the BLE beacon transmitter at the respective patient rooms. Assuming that a wireless beacon is kept at the patient room, the robot follows the beacon's signal, identifies the respective room and delivers the needed medicine to the patient. A new fuzzy controller system which consists of three ultrasonic sensors and one camera is developed to detect the optimal robot path and to avoid the robot collision with stable and moving obstacles. The fuzzy controller effectively detects obstacles in the robot's vicinity and makes proper decisions for avoiding them. The navigation of the robot is implemented on a BLE tag module by using the AOA (Angle of Arrival) method. The robot uses sensors to measure the patient body parameters and updates these data to the hospital patient database system in a private cloud mode. It also makes uses of a Google assistant to interact with the patients. The robotic system was implemented on the Raspberry Pi using Matlab 2018b. The system performance was evaluated on a PC with an Intel Core i5 processor, while the solar power was used to power the system. Several sensors, namely HC-SR04 ultrasonic sensor, Logitech HD 720p image sensor, a temperature sensor and a heart rate sensor are used together with a camera to generate datasets for testing the proposed system. In particular, the system was tested on operations taking place in the context of a private hospital in Tirunelveli, Tamilnadu, India. A detailed comparison is performed, through some performance metrics, such as Correlation, Root Mean Square Error (RMSE), and Mean Absolute Percentage Error (MAPE), against the related works of Deepu et al., Huh and Seo, Chinmayi et al., Alli et al., Xu, Ran et al., and Lee et al. The experimental system validation showed that the fuzzy controller achieves very high accuracy in obstacle detection and avoidance, with a very low computational time for taking directional decisions. Moreover, the experimental results demonstrated that the robotic system achieves superior accuracy in detecting/avoiding obstacles compared to other systems of similar purposes presented in the related works.
C1 [Narayanan, K. Lakshmi] Francis Xavier Engn Coll, Dept Elect & Commun Engn, Tirunelveli, Tamil Nadu, India.
   [Krishnan, R. Santhana] SCAD Coll Engn & Technol, Dept Elect & Commun Engn, Tirunelveli, India.
   [Son, Le Hoang] Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
   [Tung, Nguyen Thanh] Vietnam Natl Univ, VNU Int Sch, Hanoi, Vietnam.
   [Julie, E. Golden] Anna Univ Reg Campus, Dept Comp Sci & Engn, Tirunelveli, India.
   [Robinson, Y. Harold] Sch Informat Technol Engn, Vellore Inst Technol, Vellore, Tamil Nadu, India.
   [Kumar, Raghvendra] GIET Univ, Comp Sci & Engn Dept, Gunupur, India.
   [Gerogiannis, Vassilis C.] Univ Thessaly, Fac Technol, Dept Digital Syst, Larisa, Greece.
C3 Vietnam National University Hanoi; Vietnam National University Hanoi;
   Anna University; Vellore Institute of Technology (VIT); VIT Vellore;
   GIET University; University of Thessaly
RP Son, LH (corresponding author), Vietnam Natl Univ, VNU Informat Technol Inst, Hanoi, Vietnam.
EM kyelyen@gmail.com; santhanakrishnan86@gmail.com; sonlh@vnu.edu.vn;
   tungnt@isvnu.vn; goldenjuliephd@gmail.com; yhrobinphd@gmail.com;
   raghvendraagrawal7@gmail.com; vgerogian@uth.gr
RI Al-obaidi, Abdullah Thair/P-8487-2017; krishnan, Santhana/CAA-0891-2022;
   Gerogiannis, Vassilis C./AID-6877-2022; Narayanan,
   K.Lakshmi/AAT-5349-2021; ROBINSON, HAROLD/A-1545-2016
OI Al-obaidi, Abdullah Thair/0000-0002-9971-5895; krishnan,
   Santhana/0000-0001-7930-8072; Gerogiannis, Vassilis
   C./0000-0002-9895-7606; ROBINSON, HAROLD/0000-0002-4881-7103; Hoang Son,
   Le/0000-0001-6356-0046
FU Vietnam National Foundation for Science and Technology Development
   (NAFOSTED) [102.05-2018.02]
FX This research is funded by Vietnam National Foundation for Science and
   Technology Development (NAFOSTED) under grant number 102.05-2018.02.
CR Alli K. S., 2018, Journal of Engineering and Applied Science, V13, P886
   Avirup, 2019, IEEE C INT C VIS EM
   Bae Y, 2019, ENERGIES, V12, DOI 10.3390/en12112212
   Bera A, 2017, IEEE INT C INT ROBOT, P7018, DOI 10.1109/IROS.2017.8206628
   Bialous SA, 2020, AM J TROP MED HYG, V103, P1, DOI 10.4269/ajtmh.20-0451
   Chinmayi R., 2018, P 2018 IEEE INT C CO, P1, DOI [10.1109/ICCIC.2018.8782344, DOI 10.1109/ICCIC.2018.8782344]
   Deepu R, 2015, PROCEDIA COMPUT SCI, V46, P1425, DOI 10.1016/j.procs.2015.02.061
   Dhiraj, 2019, INT RES J ENG TECHNO, V6, P1144
   Dirik M, 2019, APPL SYST INNOV, V2, DOI 10.3390/asi2020014
   Fang Z, 2010, LECT NOTES COMPUTER, V6425
   Ganesh E. N., 2019, Oriental Journal of Computer Science and Technology, V12, P8, DOI 10.13005/ojcst12.01.03
   Horiuchi Y, 2001, IEEE INT CONF ROBOT, P1728, DOI 10.1109/ROBOT.2001.932860
   Huang S, 2011, P 7 INT C NAT LANG P, pTOKUSHIMA425, DOI 10.1109/nlpke.2011.6138237
   Huh JH, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122917
   Jiang ZT, 2020, MULTIMED TOOLS APPL, V79, P14553, DOI 10.1007/s11042-018-7109-8
   Kamon I, 1997, IEEE T ROBOTIC AUTOM, V13, P814, DOI 10.1109/70.650160
   Karri C, 2021, MULTIMED TOOLS APPL, V80, P18611, DOI 10.1007/s11042-020-10253-5
   Karwa R., 2019, Int. J. Res. Appl. Sci. Eng. Technol, V7, P3617, DOI [10.22214/ijraset.2019.4607, DOI 10.22214/IJRASET.2019.4607]
   Kim S, 2015, INT J ROBOT RES, V34, P201, DOI 10.1177/0278364914555543
   Kolhatkar Chinmay, 2021, Innovations in Electrical and Electronic Engineering. Proceedings of ICEEE 2020. Lecture Notes in Electrical Engineering (LNEE 661), P397, DOI 10.1007/978-981-15-4692-1_30
   Kortli Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020342
   Kumar, 2018, INT J ELECT COMMUN E, V5, P22, DOI [10.14445/23488549/IJECE-V5I7P105, DOI 10.14445/23488549/IJECE-V5I7P105]
   Lee JY, 2018, J ADV NURS, V74, P2094, DOI 10.1111/jan.13711
   Lee TJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16030311
   Lumelsky V.J., 1990, Autonomous robot vehicles, P363
   LUMELSKY VJ, 1986, IEEE T AUTOMAT CONTR, V31, P1058, DOI 10.1109/TAC.1986.1104175
   McGuire KN, 2019, ROBOT AUTON SYST, V121, DOI 10.1016/j.robot.2019.103261
   Mohsin AH, 2021, MULTIMED TOOLS APPL, V80, P14137, DOI 10.1007/s11042-020-10284-y
   Norouzzadeh, 2009, INT C ADV INT MECH, P14
   Perez-Higueras Noe, 2014, ICINCO 2014. 11th International Conference on Informatics in Control, Automation and Robotics. Proceedings, P618
   Quang-Minh Ky, 2020, 2020 5th International Conference on Green Technology and Sustainable Development (GTSD), P597, DOI 10.1109/GTSD50082.2020.9303087
   Rajashree, 2018, INT J ENG RES TECHNO, V6, P1
   Rakshith, 2019, IEEE C INT C VIS EM
   Ran LY, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061341
   Rong Peng, 2006, 2006 3rd Annual IEEE Communications Society Conference on Sensor and Ad Hoc Communications and Networks (IEEE Cat. No. 06EX1523), P374
   Rostami SMH, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1396-2
   Sankaranarayanan A., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P1930, DOI 10.1109/ROBOT.1990.126290
   Shaikh Naziya S., 2016, IOSR J Comput Eng, V18, P3
   Singh NH, 2018, ARAB J SCI ENG, V43, P8013, DOI 10.1007/s13369-018-3267-2
   Stimpfel AW, 2012, HEALTH AFFAIR, V31, P2501, DOI 10.1377/hlthaff.2011.1377
   Xinyu, 2018, INSECURITY HOME DIGI
   Xu RX, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1352-1
   Zhang HB, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201701343
NR 43
TC 8
Z9 8
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3297
EP 3325
DI 10.1007/s11042-021-11264-6
EA JUL 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000679293200003
PM 34345198
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Tamoor, M
   Younas, I
   Mohy-Ud-Din, H
AF Tamoor, Maria
   Younas, Irfan
   Mohy-ud-Din, Hassan
TI Two-stage active contour model for robust left ventricle segmentation in
   cardiac MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised learning; Level set; Active contour model; Segmentation;
   Cardiac magnetic resonance imaging (CMR); Left ventricle (LV)
   segmentation
ID MAGNETIC-RESONANCE; AUTOMATIC SEGMENTATION; IMAGE SEGMENTATION; REGION;
   SHAPE; ALGORITHM; FRAMEWORK
AB Segmentation of the endocardial and epicardial boundaries on 3D cardiac magnetic resonance images plays a vital role in the assessment of ejection fraction, wall thickness, end-diastolic volume, end-systolic volume, and stroke volume. Accurate segmentation is significantly challenged by intensity inhomogeneity artifacts, low contrast, and ill-defined organ/region boundaries. We propose a two stage hybrid active contour model for robust left ventricle (LV) segmentation accompanied with a new initialization technique based on prior of the LV structure. The proposed approach includes a new level set method using local, spatially-varying, statistical model for image intensity, an edge-based term to capture region boundaries, and regularization functionals for smooth evolution of the segmenting curve and to avoid expensive reinitialization. Moreover, convex hull interpolation is employed to include the papillary muscles within the endocardial boundary for a refined depiction of LV geometry. The accuracy and robustness of the proposed algorithm were assessed using York, Sunnybrook and ACDC datasets (33 + 45 + 100 subjects), with a wide spectrum of normal hearts, congenital heart diseases, and cardiac dysfunction. Experiments showed that the proposed approach significantly outperformed other active contour methods (overall Dice score 0.90), generating accurate segmentations of left ventricular outflow tract (Dice score 0.91), apical slices (Dice score 0.82), systolic and diastolic phases (Dice scores 0.92 and 0.88 respectively). The percentage of good contours was about 92% and the average perpendicular distance was less than 1.8 mm. Automatically generated segmentation yielded superior estimates of ejection fraction with an R-2 >= 0.937. Furthermore, the proposed method was validated using 100 cine MRI cases consisting of five different cardiac classes from the ACDC MICCAI 2017 challenge. The proposed algorithm yielded superior segmentation performance compared with existing active contour models and other state-of-the-art cardiac segmentation techniques, with extensive validation on three standard cardiac datasets, with different cardiac pathologies and phases.
C1 [Tamoor, Maria; Younas, Irfan] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Lahore, Pakistan.
   [Mohy-ud-Din, Hassan] LUMS, Syed Babar Ali Sch Sci & Engn, Dept Elect Engn, Lahore 54792, Pakistan.
C3 Lahore University of Management Sciences
RP Mohy-Ud-Din, H (corresponding author), LUMS, Syed Babar Ali Sch Sci & Engn, Dept Elect Engn, Lahore 54792, Pakistan.
EM hassan.mohyuddin@lums.edu.pk
OI Tamoor, Dr. Maria/0000-0002-3023-6706; Younas, Irfan/0000-0002-2756-9980
FU National University of Computer and Emerging Sciences, Lahore
FX This work was supported by fellowship, awarded by National University of
   Computer and Emerging Sciences, Lahore. We are grateful to [8, 9, 17,
   23, 60] for sharing their codes.
CR Aganj I, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31333-5
   Andreopoulos A, 2008, MED IMAGE ANAL, V12, P335, DOI 10.1016/j.media.2007.12.003
   Avendi MR, 2016, MED IMAGE ANAL, V30, P108, DOI 10.1016/j.media.2016.01.005
   Barba L, 2018, MED BIOL ENG COMPUT, V56, P833, DOI 10.1007/s11517-017-1732-9
   Bernard O, 2018, IEEE T MED IMAGING, V37, P2514, DOI 10.1109/TMI.2018.2837502
   Bomma C, 2005, AM J CARDIOL, V95, P1507, DOI 10.1016/j.amjcard.2005.02.026
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang PL, 2007, COMP MED SY, P281, DOI 10.1109/CBMS.2007.48
   Codella NCF, 2010, J MAGN RESON IMAGING, V31, P845, DOI 10.1002/jmri.22080
   Contantinides, 2009, MIDAS J CARD MR LEFT
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Dweck MR, 2016, J AM COLL CARDIOL, V68, P2201, DOI 10.1016/j.jacc.2016.08.047
   Fedkiw, 2003, LEVEL SET METHODS
   Franco, 1985, COMPUTATIONAL GEOMET
   Gao Y, 2010, IEEE T MED IMAGING, V29, P1781, DOI 10.1109/TMI.2010.2052065
   Grosgeorge D, 2011, INT J COMPUT ASS RAD, V6, P573, DOI 10.1007/s11548-010-0532-6
   Hajiaghayi M, 2017, IEEE T BIO-MED ENG, V64, P134, DOI 10.1109/TBME.2016.2542243
   Hazirolan T, 2007, DIAGN INTERV RADIOL, V13, P33
   Hu HF, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114760
   Huang S, 2011, J DIGIT IMAGING, V24, P598, DOI 10.1007/s10278-010-9315-4
   Jain A, 2008, J CARDIOVASC MAGN R, V10, DOI 10.1186/1532-429X-10-32
   Khamechian MB, 2018, MAGN RESON IMAGING, V51, P51, DOI 10.1016/j.mri.2018.04.011
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Li B, 2010, JACC-CARDIOVASC IMAG, V3, P860, DOI 10.1016/j.jcmg.2010.04.013
   Li C, 2007, PROCEEDINGS OF THE 6TH INTERNATIONAL SYMPOSIUM ON COAL COMBUSTION, P1, DOI 10.1145/1329125.1329187
   Li CM, 2005, PROC CVPR IEEE, P430
   Liu H, 2012, ACAD RADIOL, V19, P723, DOI 10.1016/j.acra.2012.02.011
   Liu TT, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/890725
   Luijnenburg SE, 2010, INT J CARDIOVAS IMAG, V26, P57, DOI 10.1007/s10554-009-9501-y
   Margeta J, 2011, LECT NOTES COMPUTER
   Meng XR, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0183943
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nambakhsh CMS, 2013, MED IMAGE ANAL, V17, P1010, DOI 10.1016/j.media.2013.05.002
   Nasr M, 2018, ARXIV18020778
   Neill C, 2009, CRITICAL HEART DIS I
   Noureldin RA, 2012, J CARDIOVASC MAGN R, V14, DOI 10.1186/1532-429X-14-17
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Peng P, 2016, MAGN RESON MATER PHY, V29, P155, DOI 10.1007/s10334-015-0521-4
   Peterzan Mark A, 2016, Card Fail Rev, V2, P115, DOI 10.15420/cfr.2016.2.2.115
   Piazzese C, 2016, J ELECTROCARDIOL, V49, P383, DOI 10.1016/j.jelectrocard.2016.03.017
   Pluempitiwirijawej, 2005, MED IMAGING IEEE T, V24
   Queirós S, 2014, MED IMAGE ANAL, V18, P1115, DOI 10.1016/j.media.2014.06.001
   Radau P., 2009, The MIDAS J.
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sakuma H, 2007, J MAGN RESON IMAGING, V26, P3, DOI 10.1002/jmri.20976
   Santiago C, 2018, COMPUT METH PROG BIO, V154, P9, DOI 10.1016/j.cmpb.2017.10.028
   Sardanelli F, 2008, J MAGN RESON IMAGING, V27, P785, DOI 10.1002/jmri.21292
   Shahzad R, 2017, LECT NOTES COMPUT SC, V10129, P147, DOI 10.1007/978-3-319-52280-7_15
   Song YY, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214851
   Soomro S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191827
   Tian Y, 2013, MACH VISION APPL, V24, P47, DOI 10.1007/s00138-011-0363-7
   Tobias OJ, 2002, IEEE T IMAGE PROCESS, V11, P1457, DOI 10.1109/TIP.2002.806231
   Tran PV, 2016, ARXIV
   Tseng WYI, 2016, ACTA CARDIOL SIN, V32, P129, DOI 10.6515/ACS20150616A
   Ngo TA, 2013, IEEE IMAGE PROC, P695, DOI 10.1109/ICIP.2013.6738143
   Uzunbas MG, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P254, DOI 10.1109/ISBI.2012.6235532
   Wang H, 2016, NEUROCOMPUTING, V205, P130, DOI 10.1016/j.neucom.2016.03.050
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wang TH, 2014, COMPUT VIS IMAGE UND, V120, P14, DOI 10.1016/j.cviu.2013.10.013
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zheng Q, 2018, IEEE T MED IMAGING, V37, P2137, DOI 10.1109/TMI.2018.2820742
NR 63
TC 5
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32245
EP 32271
DI 10.1007/s11042-021-11155-w
EA JUL 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678480300002
DA 2024-07-18
ER

PT J
AU Li, MJ
   Yuan, XC
AF Li, Mianjie
   Yuan, Xiaochen
TI FD-TR: feature detector based on scale invariant feature transform and
   bidirectional feature regionalization for digital image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scale invariant feature transform; Bidirectional feature
   regionalization; Edge and neighbor filtering; Nonsubsampled Contourlet
   transform
ID LOCAL ZERNIKE MOMENTS; ROBUST; SELECTION; SECURE
AB In this paper we propose the FD-TR: Feature Detector Based on Scale Invariant Feature Transform and Bidirectional Feature Regionalization for digital image watermarking. The Scale Invariant Feature Transform method is applied to extract keypoints and an Edge and Neighbor Filtering method is proposed to generate the candidate feature points. Then the Bidirectional Feature Regionalization method is proposed and applied in order to classify candidate feature points and form candidate feature regions. On this basis, the Candidate Feature Region Filtering method is proposed to select the final feature regions for watermarking. During the watermarking process, the Nonsubsampled Contourlet Transform is employed to the extracted feature regions to extract the low-frequency coefficients. Next, we use the Diagonal Matrix-based Spread Transform Dither Modulation for watermark embedding and extraction. Extensive experiments have been conducted to evaluate the performance of the proposed scheme and the comparison with existing methods demonstrate that the proposed method is superior to the existing methods in terms of robustness and quality.
C1 [Li, Mianjie; Yuan, Xiaochen] Macau Univ Sci & Technol, Fac Informat Technol, Macau, Peoples R China.
   [Yuan, Xiaochen] Zhuhai MUST Sci & Technol Res Inst, Zhuhai, Guangdong, Peoples R China.
C3 Macau University of Science & Technology; Macau University of Science &
   Technology
RP Yuan, XC (corresponding author), Macau Univ Sci & Technol, Fac Informat Technol, Macau, Peoples R China.; Yuan, XC (corresponding author), Zhuhai MUST Sci & Technol Res Inst, Zhuhai, Guangdong, Peoples R China.
EM 1709853gii30010@student.must.edu.mo; xcyuan@must.edu.mo
FU National Natural Science Foundation of China [61902448]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61902448).
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   Ambadekar Sarita P., 2019, Recent Trends in Signal and Image Processing. ISSIP 2017. Advances in Intelligent Systems and Computing (AISC 727), P187, DOI 10.1007/978-981-10-8863-6_19
   Chaurasia P, 2014, BIOMETRICS MINUTIAE
   Cox IJ., 2007, DIGITAL WATERMARKING
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Elshazly EH, 2015, SIGNAL IMAGE VIDEO P, V9, P89, DOI 10.1007/s11760-014-0684-x
   Hamghalam M, 2014, IET IMAGE PROCESS, V8, P162, DOI 10.1049/iet-ipr.2013.0386
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Khosravi MR, 2019, EURASIP J WIREL COMM, V2019, DOI 10.1186/s13638-019-1572-4
   Liang YX, 2011, IEEE IMAGE PROC, P565, DOI 10.1109/ICIP.2011.6116611
   Liu Y, 2018, EXPERT SYST APPL, V97, P95, DOI 10.1016/j.eswa.2017.12.003
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Saha BJ, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P83, DOI 10.1109/ICISCON.2014.6965223
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Tsai JS, 2011, IEEE T IMAGE PROCESS, V20, P735, DOI 10.1109/TIP.2010.2073475
   Tsougenis ED, 2015, MULTIMED TOOLS APPL, V74, P3985, DOI 10.1007/s11042-013-1808-y
   Verma VS, 2015, SIGNAL IMAGE VIDEO P, V9, P1443, DOI 10.1007/s11760-013-0603-6
   Yuan XC, 2014, MULTIMED TOOLS APPL, V72, P777, DOI 10.1007/s11042-013-1405-0
   Yuan XC, 2013, SIGNAL PROCESS, V93, P2087, DOI 10.1016/j.sigpro.2013.01.024
NR 22
TC 2
Z9 2
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 32197
EP 32217
DI 10.1007/s11042-021-11134-1
EA JUL 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000678013400003
DA 2024-07-18
ER

PT J
AU Verma, T
   Dubey, S
AF Verma, Toran
   Dubey, Sipi
TI Prediction of diseased rice plant using video processing and LSTM-simple
   recurrent neural network with comparative study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video processing; Segmentation; Feature extraction; Long short-term
   memory; Simple recurrent neural network; Rice plant disease
ID SHORT-TERM-MEMORY; AUTOMATED DETECTION; CITRUS DISEASES; CLASSIFICATION;
   RECOGNITION; SEGMENTATION; SYSTEM; IMAGES; MODEL
AB The disease infliction of the plants severely influences the yield. It alters the essence and extent of crop production cause fiscal distress. Consequently, the diagnosis of numerous plant diseases is significant to decrease the yield perdition by discovering crop infections at their earlier stages. This paper introduces a new model using mobile video image processing and Long-Short Term Memory (LSTM)-Simple Recurrent Neural Network (SRNN) deep learning method for the prediction of the diseased or disinfected rice plant with dynamic learning capability. The rice plant videos captured under uncontrolled conditions in day-lighting using a mobile handset and divided into two sections for the designing and testing of LSTM-SRNN models. After shooting, the video images of the rice plant segmented using colour indexing and linear color space transformation with minimal daylight impact. Low-level spatial features; entropy, standard deviation, and fuzzy features extracted after video image segmentation. The excerpted characteristics with the composite combinations transformed in time-series datasets with the desired response. The datasets employed in the LSTM-SRNN model for progressive learning. The distinct test video features applied in LSTM-SRNN to appraise the generalization capability of the proposed system with performance analysis. The experimental outcomes of the proposed LSTM-SRNN model exhibit 99.99% prediction ability with fuzzy features. The model also presents possibilities for dynamic learning adaptability and temporal information processing to overcome the limitations of many well-known rule-based and machine learning approaches.
C1 [Verma, Toran; Dubey, Sipi] CSVTU, Rungta Coll Engn & Technol, Dept Comp Sci, Bhilai 490024, Chhattisgarh, India.
RP Verma, T (corresponding author), CSVTU, Rungta Coll Engn & Technol, Dept Comp Sci, Bhilai 490024, Chhattisgarh, India.
EM toran.verma@rungta.ac.in
RI VERMA, TORAN/AAA-5517-2022
OI VERMA, TORAN/0000-0003-0315-3099
CR Adeel A, 2019, SUSTAIN COMPUT-INFOR, V24, DOI 10.1016/j.suscom.2019.08.002
   Ali H, 2017, COMPUT ELECTRON AGR, V138, P92, DOI 10.1016/j.compag.2017.04.008
   Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Esgario JGM, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2019.105162
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Ferreira AD, 2017, COMPUT ELECTRON AGR, V143, P314, DOI 10.1016/j.compag.2017.10.027
   Gao C, 2019, INFORM SCIENCES, V502, P279, DOI 10.1016/j.ins.2019.06.039
   Hassanien AE, 2017, COMPUT ELECTRON AGR, V136, P86, DOI 10.1016/j.compag.2017.02.026
   Ilic M, 2018, COMPUT ELECTRON AGR, V150, P418, DOI 10.1016/j.compag.2018.05.008
   Iqbal Z, 2018, COMPUT ELECTRON AGR, V153, P12, DOI 10.1016/j.compag.2018.07.032
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Karlekar A, 2020, COMPUT ELECTRON AGR, V172, DOI 10.1016/j.compag.2020.105342
   Kerkech M, 2018, COMPUT ELECTRON AGR, V155, P237, DOI 10.1016/j.compag.2018.10.006
   Khan MA, 2019, IEEE ACCESS, V7, P46261, DOI 10.1109/ACCESS.2019.2908040
   Khan MA, 2018, COMPUT ELECTRON AGR, V155, P220, DOI 10.1016/j.compag.2018.10.013
   Kong FH, 2018, J COMPUT SCI-NETH, V26, P78, DOI 10.1016/j.jocs.2018.03.010
   Lee SH, 2020, COMPUT ELECTRON AGR, V170, DOI 10.1016/j.compag.2020.105220
   Lei JH, 2019, RENEW ENERG, V133, P422, DOI 10.1016/j.renene.2018.10.031
   Liang WJ, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-38966-0
   Liu B, 2020, IEEE ACCESS, V8, P102188, DOI 10.1109/ACCESS.2020.2998839
   Lv MJ, 2020, IEEE ACCESS, V8, P57952, DOI 10.1109/ACCESS.2020.2982443
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   Manjarrez-Sachez J, 2020, IEEE LAT AM T, V18, P1487, DOI 10.1109/TLA.2020.9111686
   Muthukannan K, 2018, MULTIMED TOOLS APPL, V77, P24387, DOI 10.1007/s11042-018-5710-5
   Panchal P., 2019, CSITSS 2019 2019 4 I, DOI [DOI 10.1109/CSITSS47250.2019.9031029, 10.1109/CSITSS47250.2019.9031029]
   Pantazi XE, 2019, COMPUT ELECTRON AGR, V156, P96, DOI 10.1016/j.compag.2018.11.005
   Peng YQ, 2019, COMPUT ELECTRON AGR, V157, P247, DOI 10.1016/j.compag.2018.12.023
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Rachmadi RF, 2018, J VIS COMMUN IMAGE R, V56, P265, DOI 10.1016/j.jvcir.2018.09.021
   Sabzi S, 2018, MEASUREMENT, V126, P22, DOI 10.1016/j.measurement.2018.05.037
   Safdar A, 2019, MICROSC RES TECHNIQ, V82, P1542, DOI 10.1002/jemt.23320
   Sengupta S, 2017, COMPUT ELECTRON AGR, V140, P443, DOI 10.1016/j.compag.2017.06.024
   Sethy PK, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105527
   Sharif M, 2018, COMPUT ELECTRON AGR, V150, P220, DOI 10.1016/j.compag.2018.04.023
   Sharma P, 2020, PROCEEDINGS OF THE CONFLUENCE 2020: 10TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING, P480, DOI [10.1109/confluence47617.2020.9057889, 10.1109/Confluence47617.2020.9057889]
   Singh S, 2019, GEODERMA REG, V18, DOI 10.1016/j.geodrs.2019.e00233
   Singh UP, 2019, IEEE ACCESS, V7, P43721, DOI 10.1109/ACCESS.2019.2907383
   Spiegel M., 2009, Probability and statistics
   Thanh TKN, 2018, LECT NOTES ARTIF INT, V10751, P565, DOI 10.1007/978-3-319-75417-8_53
   Too EC, 2019, COMPUT ELECTRON AGR, V161, P272, DOI 10.1016/j.compag.2018.03.032
   Toseef M, 2018, COMPUT ELECTRON AGR, V153, P1, DOI 10.1016/j.compag.2018.07.034
   Verma T., 2017, INT C NEXT GEN COMP, P790
   Verma T, 2020, ARCH COMPUT METHOD E, V27, P1611, DOI 10.1007/s11831-019-09364-6
   Wahab AHB, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P57, DOI [10.1109/ICISPC.2019.8935722, 10.1109/icispc.2019.8935722]
   Waheed A, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105456
   Wilamowski BM, 2010, IEEE T NEURAL NETWOR, V21, P930, DOI 10.1109/TNN.2010.2045657
   Yadhav S. Yegneshwar, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P564, DOI 10.1109/ICESC48915.2020.9155815
   Yuan Y, 2018, LECT NOTES COMPUT SC, V11257, P457, DOI 10.1007/978-3-030-03335-4_40
   Zhang DY, 2020, IEEE ACCESS, V8, P109876, DOI 10.1109/ACCESS.2020.3001652
   Zhang JF, 2018, J HYDROL, V561, P918, DOI 10.1016/j.jhydrol.2018.04.065
   Zhang SW, 2017, LECT NOTES COMPUT SC, V10361, P282, DOI 10.1007/978-3-319-63309-1_26
NR 51
TC 14
Z9 15
U1 4
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29267
EP 29298
DI 10.1007/s11042-021-10889-x
EA JUN 2021
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000664818500002
DA 2024-07-18
ER

PT J
AU Talukdar, AK
   Bhuyan, MK
AF Talukdar, Anjan Kumar
   Bhuyan, M. K.
TI A framework for continuous fingerspelling spotting for H.264/AVC
   compressed videos using spatio-temporal Markov random field
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressed domain; Motion vector; Continuous fingerspelling; Movement
   epenthesis; Outlier
ID STATISTICAL-ANALYSIS; SIGN-LANGUAGE; RECOGNITION
AB The continuous Sign Language recognition (SLR) system suffers from a problem called movement epenthesis (me) which involves certain intermediate connecting movement between two consecutive signs. In this paper, a novel framework for spotting of continuous fingerspelling sequence is proposed, which can directly extract motion information of signs from a compressed video. The framework is based on motion vectors extracted from H.264/AVC compressed videos. A Spatio-Temporal Markov Random Field (ST-MRF) based model is employed to model non-rigid motions of fingers as sign or me. The proposed framework is tested on a number of sign language videos encoded with an H.264/AVC JM encoder, and the accuracy of spotting was found to be around 75%.
C1 [Talukdar, Anjan Kumar; Bhuyan, M. K.] Indian Inst Technol Guwahati, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Talukdar, AK (corresponding author), Indian Inst Technol Guwahati, Gauhati 781039, India.
EM a.talukdar@iitg.ac.in
CR Abdari Ali, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P130, DOI 10.1109/PRIA.2019.8785055
   Aly W, 2019, IEEE ACCESS, V7, P123138, DOI 10.1109/ACCESS.2019.2938829
   Avola D, 2019, IEEE T MULTIMEDIA, V21, P234, DOI 10.1109/TMM.2018.2856094
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Chen YM, 2011, IEEE T MULTIMEDIA, V13, P421, DOI 10.1109/TMM.2011.2127464
   Chon JH, 2011, IEEE DATA COMPR CONF, P383, DOI 10.1109/DCC.2011.45
   Chuan CH, 2014, 2014 13TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P541, DOI 10.1109/ICMLA.2014.110
   Ciaramello FM, 2011, IEEE T IMAGE PROCESS, V20, P3014, DOI 10.1109/TIP.2011.2132730
   Jaehong Chon, 2009, 2009 43rd Asilomar Conference on Signals, Systems and Computers, P588, DOI 10.1109/ACSSC.2009.5469901
   Jalal MA, 2018, 2018 21ST INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P573, DOI 10.23919/ICIF.2018.8455725
   Jongseok Lee, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P306, DOI 10.1109/ICCE.2017.7889330
   Kane L, 2015, COMPUT VIS IMAGE UND, V141, P138, DOI 10.1016/j.cviu.2015.08.001
   Kang B, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P136, DOI 10.1109/ACPR.2015.7486481
   Kayaalp, 2003, THESIS METU
   Khatoonabadi SH, 2013, IEEE T IMAGE PROCESS, V22, P300, DOI 10.1109/TIP.2012.2214049
   Kim JG, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1171, DOI 10.1109/ICME.2000.871569
   Kim T, 2013, IEEE I CONF COMP VIS, P1521, DOI 10.1109/ICCV.2013.192
   Li S. Z., 2009, Markov random field modeling in image analysis
   Nguyen HBD, 2019, 2019 26TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), P314, DOI [10.1109/ict.2019.8798856, 10.1109/ICT.2019.8798856]
   Papageorgiou Konstantinos., 2019, 10th International Conference on Information, Intelligence, Systems and Applications (IISA), P1
   Ricco S, 2010, LECT NOTES COMPUT SC, V5996, P214
   Shi BW, 2018, IEEE W SP LANG TECH, P145, DOI 10.1109/SLT.2018.8639639
   Talukdar AK, 2018, 2018 IEEE RECENT ADVANCES IN INTELLIGENT COMPUTATIONAL SYSTEMS (RAICS), P26, DOI 10.1109/RAICS.2018.8634902
   Tazhigaliyeva Nazgul, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4531, DOI 10.1109/ICRA.2017.7989526
   Yang HD, 2010, PATTERN RECOGN, V43, P2858, DOI 10.1016/j.patcog.2010.03.007
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang RD, 2010, IEEE T PATTERN ANAL, V32, P462, DOI 10.1109/TPAMI.2009.26
   Yang R, 2007, PROC CVPR IEEE, P3501
NR 29
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28329
EP 28347
DI 10.1007/s11042-021-10910-3
EA JUN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000657588300001
DA 2024-07-18
ER

PT J
AU Yuchi, SY
   Xu, S
AF Yuchi, Shu-yi
   Xu, Shu
TI Research on cooperative classification of multimedia visual images based
   on deep machine learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep machine learning model; Multimedia; Visual image; Collaborative
   classification
ID COLLABORATIVE REPRESENTATION; KERNEL
AB Aiming at the low accuracy of multimedia visual image cooperative classification, a new method of multimedia visual image cooperative classification based on depth machine learning model is proposed. Firstly, HSV color space model is selected to extract color features of multimedia visual images, Gabor function is used to extract texture features, and shape invariant moments are used to extract shape features. Then the features of multimedia visual images are recognized and classified, and the model parameters are optimized and adjusted according to the deviation of training output. The experimental results show that the average accuracy of this method is 95.892%, and the classification efficiency is high. The classification accuracy of this method is basically above 95%, and the classification accuracy is high. The training time of image type samples is 19 s, the testing time of image type is 12 s, and the time consumption is low.
C1 [Yuchi, Shu-yi] Liaoning Univ Technol, Coll Art Design & Architecture, Jinzhou 121000, Liaoning, Peoples R China.
   [Xu, Shu] Hunan City Univ, Coll Informat & Elect Engn, Yiyang 413000, Hunan, Peoples R China.
C3 Liaoning University of Technology; Hunan City University
RP Xu, S (corresponding author), Hunan City Univ, Coll Informat & Elect Engn, Yiyang 413000, Hunan, Peoples R China.
EM shu-xu@hnteuni.com
CR Abdelhamid T, 2018, INVERSE PROBL SCI EN, V26, P1231, DOI 10.1080/17415977.2017.1391243
   Ao L, 2018, IEEE ACCESS, P1
   Dao M, 2016, IEEE T SIGNAL PROCES, V64, P2400, DOI 10.1109/TSP.2016.2521605
   Hu Xiangping, 2016, Computer Engineering and Applications, V52, P194, DOI 10.3778/j.issn.1002-8331.1309-0113
   Imani M, 2017, INT J REMOTE SENS, V38, P5524, DOI 10.1080/01431161.2017.1343513
   Imani M, 2017, IET IMAGE PROCESS, V11, P164, DOI 10.1049/iet-ipr.2016.0421
   Kowsari K., 2018, RMDL RANDOM MULTIMOD, V12, P65
   Liu R, 2016, PATTERN RECOGN, V53, P73, DOI 10.1016/j.patcog.2015.11.015
   Liu ZB, 2016, MON NOT R ASTRON SOC, V455, P4289, DOI 10.1093/mnras/stv2600
   Lu CY, 2016, IEEE T IMAGE PROCESS, V25, P2833, DOI 10.1109/TIP.2016.2553459
   Mishra M, 2018, IET GENER TRANSM DIS, V12, P388, DOI 10.1049/iet-gtd.2017.0502
   Murugan P., 2018, CATEGORICAL IMAGE CL, V72, P85
   Na JH, 2016, ELECTRON LETT, V52, P1114, DOI 10.1049/el.2016.0402
   Ran Q, 2018, REMOTE SENS LETT, V9, P597, DOI [10.1080/2150704X.2018.1452063, 10.1080/2150704x.2018.1452063]
   Wang JN, 2017, REMOTE SENS LETT, V8, P11, DOI 10.1080/2150704X.2016.1230279
   Wang X., 2016, API CALL SEQUENCE, V34, P133
   Wang YY, 2018, IEEE T FUZZY SYST, V26, P1164, DOI 10.1109/TFUZZ.2017.2710952
   Yeh CK., 2017, LEARNING DEEP LATENT, V12, P513
   Zhang Y., 2017, COMPUTER APPL, V37, P2244
   Zhao Y, 2016, ELECTRON LETT, V52, P1849, DOI 10.1049/el.2016.1328
NR 20
TC 1
Z9 1
U1 5
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22657
EP 22670
DI 10.1007/s11042-019-7637-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000669314100015
DA 2024-07-18
ER

PT J
AU Iradier, E
   Abuin, A
   Fanari, L
   Montalban, J
   Angueira, P
AF Iradier, Eneko
   Abuin, Aritz
   Fanari, Lorenzo
   Montalban, Jon
   Angueira, Pablo
TI Throughput, capacity and latency analysis of P-NOMA RRM schemes in 5G
   URLLC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G; Factory automation; NOMA; P-NOMA; Resource allocation; Resource
   block; RRM; TDMA; URLLC; Wireless communications
ID NONORTHOGONAL MULTIPLE-ACCESS; AUGMENTED REALITY SYSTEMS; INDUSTRIAL;
   802.11N; DESIGN
AB 5G is expected to cover a wide range of potential use cases due to its flexible and configurable physical layer waveform. One of the use cases proposed is the application of 5G on Ultra-Reliable Low Latency Communication (URLLC), which are characterized by very challenging reliability/availability and latency requirements. In addition, multimedia applications are being consolidated as a relevant aspect of current industrial environments. In order to meet those strict requirements, Radio Resource Management (RRM) becomes a critical phase of any wireless communication system. This work proposes the use of power domain Non-Orthogonal Multiple Access (P-NOMA) techniques in 5G RRM for factory automation environments. The research presented in this paper includes the design and evaluation of different RRM algorithms based on P-NOMA and on traditional Orthogonal Multiple Access (OMA) techniques, such as Time/Frequency Division Multiplexing Access (T/FDMA). Those algorithms are comprehensively explained and oriented to optimize the resource allocation based on different metrics (i.e., capacity, number of users, or cycle time). Moreover, extensive results are presented, where the performance of NOMA and OMA techniques is compared in terms of different metrics under the influence of several parameters, such as payload, bandwidth, or the number of users. Results indicate that although both NOMA and OMA provide positive aspects, eventually NOMA-based RRM algorithms are the solutions that enhance considerably the spectral efficiency.
C1 [Iradier, Eneko; Abuin, Aritz; Fanari, Lorenzo; Angueira, Pablo] Univ Basque Country, Dept Commun Engn, Bilbao, Spain.
   [Montalban, Jon] Univ Basque Country, Dept Elect Technol, Eibar, Spain.
C3 University of Basque Country; University of Basque Country
RP Iradier, E (corresponding author), Univ Basque Country, Dept Commun Engn, Bilbao, Spain.
EM eneko.iradier@ehu.eus; aabuin003@ikasle.ehu.eus; lorenzo.fanari@ehu.eus;
   jon.montalban@ehu.eus; pablo.angueira@ehu.eus
RI Montalban, Jon/M-1528-2015; Angueira, Pablo/M-2284-2014; Iradier,
   Eneko/AAD-9147-2020; Montalban, Jon/GRX-0617-2022
OI Montalban, Jon/0000-0003-0309-3401; Angueira, Pablo/0000-0002-5188-8412;
   Iradier, Eneko/0000-0002-0424-3857; Montalban, Jon/0000-0003-0309-3401;
   Fanari, Lorenzo/0000-0001-8023-1973; Abuin, Aritz/0000-0003-4868-4029
FU Basque Government (Project IOTERRAZ) [KK2019/00046]; Basque Government
   [IT1234-19]; Basque Government (PREDOC Grant Program) [PRE_2020_2_0105];
   Spanish Government (Project PHANTOM) under MCIU/AEI/FEDER, UE
   [RTI2018-099162-B-I00]
FX This work was supported in part by the Basque Government (Project
   IOTERRAZ) under Grant KK2019/00046 ELKARTEK 2019, Grant IT1234-19 and
   the PREDOC Grant Program PRE_2020_2_0105, and in part by the Spanish
   Government (Project PHANTOM) under Grant RTI2018-099162-B-I00
   (MCIU/AEI/FEDER, UE).
CR Aktas I, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292603
   Al-Turjman F, 2020, MULTIMED TOOLS APPL, V79, P8627, DOI 10.1007/s11042-018-6288-7
   [Anonymous], 2015, Recommendation ITU
   [Anonymous], 2018, 3GPP TS 38.214 V15.2.0.
   [Anonymous], 2017, Tech. Rep. (TR) 38.802, V14.2.0
   Anwar M, 2016, IEEE T IND INFORM, V12, P338, DOI 10.1109/TII.2015.2508719
   Ao Wu, 2019, 2019 IEEE International Conference on Industrial Internet (ICII). Proceedings, P423, DOI 10.1109/ICII.2019.00078
   BERGMANS PP, 1974, IEEE T INFORM THEORY, V20, P317, DOI 10.1109/TIT.1974.1055232
   Blanco-Novoa O, 2018, IEEE ACCESS, V6, P8201, DOI 10.1109/ACCESS.2018.2802699
   Coll JF, 2012, IEEE T ELECTROMAGN C, V54, P708, DOI 10.1109/TEMC.2012.2197753
   COVER TM, 1972, IEEE T INFORM THEORY, V18, P2, DOI 10.1109/TIT.1972.1054727
   Croonenbroeck R, 2017, IEEE CONF WIREL MOB, P616
   Drath R, 2014, IEEE IND ELECTRON M, V8, P56, DOI 10.1109/MIE.2014.2312079
   Egger-Lampl S., 2019, INT WORK QUAL MULTIM, P1, DOI DOI 10.1109/qomex.2019.8743266
   Fraga-Lamas P, 2018, IEEE ACCESS, V6, P13358, DOI 10.1109/ACCESS.2018.2808326
   Ghini V, 2019, 16 IEEE ANN CONS COM, P1, DOI [10.1109/CCNC.2019.8651683, DOI 10.1109/CCNC.2019.8651683]
   Ghosh A, 2019, IEEE ACCESS, V7, P127639, DOI 10.1109/ACCESS.2019.2939938
   Gong L, 2021, IEEE ACCESS, V9, P24796, DOI 10.1109/ACCESS.2021.3056752
   Hassan SM, 2017, PROCEDIA COMPUT SCI, V105, P240, DOI 10.1016/j.procs.2017.01.217
   Hoshyar R, 2008, IEEE T SIGNAL PROCES, V56, P1616, DOI 10.1109/TSP.2007.909320
   Hsu CY, 2017, IEEE INT SYM MULTIM, P376, DOI 10.1109/ISM.2017.75
   Iradier E, 2019, IEEE INT C EMERG, P200, DOI [10.1109/etfa.2019.8869055, 10.1109/ETFA.2019.8869055]
   Iradier E., 2019, 2019 IEEE INT S BROA, P1
   Iradier E, 2016, INT S BROADB MULT SY, P1, DOI [10.1109/BMSB.2016.7521985, DOI 10.1109/BMSB.2016.7521985]
   Iradier E, 2021, IEEE ACCESS, V9, P29541, DOI 10.1109/ACCESS.2021.3059069
   Iradier E, 2020, IEEE T BROADCAST, V66, P503, DOI 10.1109/TBC.2020.2981759
   Islam SMR, 2017, IEEE COMMUN SURV TUT, V19, P721, DOI 10.1109/COMST.2016.2621116
   Kumar M, 2018, MULTIMED TOOLS APPL, V77, P4491, DOI 10.1007/s11042-017-4832-5
   Liu YW, 2017, P IEEE, V105, P2347, DOI 10.1109/JPROC.2017.2768666
   Molisch A. F., 2004, IEEE P802, V15
   Montalban J, 2020, IEEE ACCESS, V8, P168546, DOI 10.1109/ACCESS.2020.3023275
   Montalban J, 2018, IEEE COMMUN MAG, V56, P96, DOI 10.1109/MCOM.2018.1700660
   Montgomery K., 2020, Wireless user requirements for the factory workcell
   Nawaratne R, 2017, IEEE IND ELEC, P4790, DOI 10.1109/IECON.2017.8216826
   Park SI, 2016, IEEE T BROADCAST, V62, P233, DOI 10.1109/TBC.2015.2492459
   Pedersen K, 2018, IEEE COMMUN MAG, V56, P210, DOI 10.1109/MCOM.2017.1700517
   Rondón R, 2017, INT J WIREL INF NETW, V24, P278, DOI 10.1007/s10776-017-0357-0
   Sachs J, 2018, IEEE NETWORK, V32, P24, DOI 10.1109/MNET.2018.1700232
   Schulz P, 2017, IEEE COMMUN MAG, V55, P70, DOI 10.1109/MCOM.2017.1600435CM
   Seijo O, 2018, 2018 14TH IEEE INTERNATIONAL WORKSHOP ON FACTORY COMMUNICATION SYSTEMS (WFCS 2018)
   Tramarin F, 2016, IEEE T IND INFORM, V12, P1877, DOI 10.1109/TII.2015.2504872
   Varghese A, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P634, DOI 10.1109/IC3I.2014.7019732
   Zhang L, 2020, IEEE T BROADCAST, V66, P490, DOI 10.1109/TBC.2020.2983563
   Zhang L, 2019, IEEE WIREL COMMUN, V26, P116, DOI 10.1109/MWC.2018.1800092
   Zhang L, 2016, IEEE T BROADCAST, V62, P216, DOI 10.1109/TBC.2015.2505408
NR 45
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12251
EP 12273
DI 10.1007/s11042-021-11086-6
EA MAY 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000656384900001
DA 2024-07-18
ER

PT J
AU Labinghisa, B
   Lee, DM
AF Labinghisa, Boney
   Lee, Dong Myung
TI A pose estimation scheme based on distance scaling algorithm in
   real-time environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D; 3D human pose estimation scheme; Deep learning; Computer vision;
   Distance scaling algorithm; OpenPose
AB The innovation of convolutional neural networks motivated the study on the many aspects of image processing and object detection. One topic of interest in the field of object detection is human detection and the human pose estimation scheme. Human pose estimation scheme enables computer vision with a higher accuracy of identifying human motion and movement. Pose estimation scheme has been applied in making 2D images into 3D representation. This paper aims to determine the distance between the camera and the human subject with real-time application which takes advantage of existing pose estimation schemes. The distance scaling applied in the paper showed high performance of about 0.27 m error from the actual distance.
C1 [Labinghisa, Boney; Lee, Dong Myung] Tongmyong Univ, Busan 48520, South Korea.
C3 Tongmyong University
RP Lee, DM (corresponding author), Tongmyong Univ, Busan 48520, South Korea.
EM blabinghisa@yahoo.com; dmlee@tu.ac.kr
OI Lee, Dong Myung/0000-0002-1314-8763
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2019R1F1A1062670]; BB21+ Project in 2020
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIT) (No.
   2019R1F1A1062670).; This work was supported by the BB21+ Project in
   2020.
CR Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Martinez Julieta, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2659, DOI 10.1109/ICCV.2017.288
   Moon G, 2019, IEEE I CONF COMP VIS, P10132, DOI 10.1109/ICCV.2019.01023
   Newell A., 2017, ADV NEUR IN, P2171
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Pathi SK, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143142
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Rhodin H, 2018, LECT NOTES COMPUT SC, V11214, P765, DOI 10.1007/978-3-030-01249-6_46
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
NR 15
TC 0
Z9 0
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34359
EP 34367
DI 10.1007/s11042-021-11027-3
EA MAY 2021
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000652455300003
DA 2024-07-18
ER

PT J
AU Zakraoui, J
   Saleh, M
   Al-Maadeed, S
   Jaam, JM
AF Zakraoui, Jezia
   Saleh, Moutaz
   Al-Maadeed, Somaya
   Jaam, Jihad Mohammed
TI Improving text-to-image generation with object layout guidance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image generation; Text processing; Scene graph; Object layout;
   Conditioning augmentation; StackGAN
AB The automatic generation of realistic images directly from a story text is a very challenging problem, as it cannot be addressed using a single image generation approach due mainly to the semantic complexity of the story text constituents. In this work, we propose a new approach that decomposes the task of story visualization into three phases: semantic text understanding, object layout prediction, and image generation and refinement. We start by simplifying the text using a scene graph triple notation that encodes semantic relationships between the story objects. We then introduce an object layout module to capture the features of these objects from the corresponding scene graph. Specifically, the object layout module aggregates individual object features from the scene graph as well as averaged or likelihood object features generated by a graph convolutional neural network. All these features are concatenated to form semantic triples that are then provided to the image generation framework. For the image generation phase, we adopt a scene graph image generation framework as stage-I, which is refined using a StackGAN as stage-II conditioned on the object layout module and the generated output image from stage-I. Our approach renders object details in high-resolution images while keeping the image structure consistent with the input text. To evaluate the performance of our approach, we use the COCO dataset and compare it with three baseline approaches, namely, sg2im, StackGAN and AttnGAN, in terms of image quality and user evaluation. According to the obtained assessment results, our object layout guidance-based approach significantly outperforms the abovementioned baseline approaches in terms of the accuracy of semantic matching and realism of the generated images representing the story text sentences.
C1 [Zakraoui, Jezia; Saleh, Moutaz; Al-Maadeed, Somaya; Jaam, Jihad Mohammed] Qatar Univ, Dept Comp Sci & Engn, Doha 2713, Qatar.
C3 Qatar University
RP Saleh, M (corresponding author), Qatar Univ, Dept Comp Sci & Engn, Doha 2713, Qatar.
EM moutaz.saleh@qu.edu.qa
RI Saleh, Moutaz/R-7449-2018
OI Saleh, Moutaz/0000-0002-6434-1790
FU NPRP grant from the Qatar National Research Fund (a member of Qatar
   Foundation) [10-0205-170346]
FX This work was made possible by NPRP grant #10-0205-170346 from the Qatar
   National Research Fund (a member of Qatar Foundation). The statements
   made herein are solely the responsibility of the authors.
CR Agam G, 2018, ARXIV180603027
   [Anonymous], 2017, ARXIV161009585
   Caesar H, 2018, PROC CVPR IEEE, P1209, DOI 10.1109/CVPR.2018.00132
   Dauphin Y. N., 2017, arXiv preprint arXiv: 1703.09452v3
   Gangyan Z., 2019, P 3 INT C COMP SCI A
   Gonçalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hensel M, 2017, ADV NEUR IN, V30
   Hinz Tobias, 2019, INT C LEARN REPR ICL
   Hong S, 2018, PROC CVPR IEEE, P7986, DOI 10.1109/CVPR.2018.00833
   Huang CJ, 2013, CONF TECHNOL APPL, P67, DOI 10.1109/TAAI.2013.26
   Huang X, 2017, PROC CVPR IEEE, P1866, DOI 10.1109/CVPR.2017.202
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Kingma D. P., 2013, ARXIV13126114
   Li Wenbo, 2019, Object-driven Text-to-Image Synthesis via Adversarial Training
   Li YK, 2019, ADV NEUR IN, V32
   Li YT, 2019, PROC CVPR IEEE, P6322, DOI 10.1109/CVPR.2019.00649
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mansimov E., 2016, arXiv
   Marshall S, 2018, ABS181103378 ARXIV
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Popescu Marius-Constantin, 2009, WSEAS Transactions on Circuits and Systems, V8, P579
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Qiao XT, 2019, PROC CVPR IEEE, P2628, DOI 10.1109/CVPR.2019.00274
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans T, 2016, ADV NEUR IN, V29
   SHARMA S, 2018, ARXIV180208216
   Sugimoto A, 2020, ARXIV PREPRINT ARXIV
   Sutskever I., 2014, ADV NEURAL INFORM PR, V4, P3104, DOI DOI 10.5555/2969033.2969173
   Tan Fuwen, 2019, IEEE C COMP VIS PATT
   Tang C-K, 2018, LECT NOTES COMPUTER, V11220
   Weisberg DS, 2020, INFANT CHILD DEV, V29, DOI 10.1002/icd.2182
   Wen F, 2020, ARXIV200308932
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
NR 37
TC 8
Z9 8
U1 3
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27423
EP 27443
DI 10.1007/s11042-021-11038-0
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000652455300005
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Zhao, JD
   Lei, W
   Li, ZJ
   Zhao, DF
   Han, MM
   Hou, XQ
AF Zhao, Jiandong
   Lei, Wei
   Li, Zijian
   Zhao, Dongfeng
   Han, Mingmin
   Hou, Xiaoqing
TI Detection of crowdedness in bus compartments based on ResNet algorithm
   and video images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bus; Crowdedness; Video images; Support vector machine; ResNet
ID TEXTURE CLASSIFICATION
AB The crowding in bus is an important factor affecting passenger satisfaction and bus dispatching level. However, how to use video images to detect crowding accurately is a difficult problem. In this paper, firstly, an image sample library is established based on the evaluation standard of crowding in bus, which contains 16346 sample images. Then, Local Binary Pattern (LBP) and Gray Level Co-occurrence Matrix (GLCM) are used to extract the texture features of the image in bus. Then, a rough classification method of crowding based on Support Vector Machine (SVM) is proposed. At the same time, in order to improve the accuracy of rough classification of crowding, the optimization effects of grid search algorithm, particle swarm optimization algorithm and genetic algorithm on SVM parameters are compared. The results show that the optimization effect of genetic algorithm is the best, and the accuracy rate is 93.20%. Finally, for the problem that the SVM method is not ideal in the fine classification of crowding, this paper proposes a new method based on ResNet. SGD, Adadelta and Adam are selected to optimize the parameters of ResNet model. The accuracy of the optimal Adam algorithm reaches 96.22%, which effectively solves the problem of the fine classification of crowding in bus.
C1 [Zhao, Jiandong; Li, Zijian; Zhao, Dongfeng] Beijing Jiaotong Univ, Sch Traff & Transportat, Beijing 100044, Peoples R China.
   [Zhao, Jiandong] Beijing Jiaotong Univ, Key Lab Transport Ind Big Data Applicat Technol C, Minist Transport, Beijing 100044, Peoples R China.
   [Lei, Wei; Han, Mingmin; Hou, Xiaoqing] Hebei Prov Commun Planning & Design Inst, Shijiazhuang 050000, Hebei, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Zhao, JD (corresponding author), Beijing Jiaotong Univ, Sch Traff & Transportat, Beijing 100044, Peoples R China.; Zhao, JD (corresponding author), Beijing Jiaotong Univ, Key Lab Transport Ind Big Data Applicat Technol C, Minist Transport, Beijing 100044, Peoples R China.
EM zhaojd@bjtu.edu.cn
RI Peng, Ziyi/JTT-8210-2023; YAN, LING/JXY-6904-2024; chen,
   qiang/JXY-6982-2024; luo, yuan/JLS-6416-2023
OI Zhao, Jiandong/0000-0001-8402-0380
FU National Key R&D Program of China [2019YFB1600200]; National Natural
   Science Foundation of China [71871011, 71890972/71890970, 71621001];
   first batch of science and technology projects of Jingde Expressway
   [JD-202014]
FX This work is supported by the National Key R&D Program of China
   (2019YFB1600200), National Natural Science Foundation of China
   (71871011, 71890972/71890970, 71621001), and the first batch of science
   and technology projects of Jingde Expressway (JD-202014).
CR [Anonymous], 1997, Image Processing for Security Applications, DOI DOI 10.1049/IC:19970387
   [Anonymous], 2013, Transit Capacity and Quality of Service Manual
   Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Cheng Cheng C C, CHINA ILLUM ENG J, V30 30, P50
   Chow TWS, 2002, ADV ENG INFORM, V16, P73, DOI 10.1016/S1474-0346(01)00002-7
   Chow TWS, 1999, ARTIF INTELL ENG, V13, P301, DOI 10.1016/S0954-1810(99)00016-3
   Comer ML, 1999, IEEE T IMAGE PROCESS, V8, P408, DOI 10.1109/83.748895
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   DAVIES AC, 1995, ELECTRON COMMUN ENG, V7, P37, DOI 10.1049/ecej:19950106
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   [李白萍 Li Baiping], 2018, [图学学报, Journal of Graphics], V39, P728
   Li DG, 2021, J BUS ECON STAT, V39, P741, DOI 10.1080/07350015.2020.1730856
   [李振龙 Li Zhenlong], 2015, [交通运输系统工程与信息, Journal of Transporation Systems Engineering & Information Technology], V15, P246
   Marana AN, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P354, DOI 10.1109/SIBGRA.1998.722773
   Mingov Mingov R R, SVM PARAMETER TUNING
   Ni Ni H H, TRANSP SYST ENG INFO, V12 12, P180
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shi XY, 2015, IAHS-AISH P, V368, P162
   Simard M, 2000, IEEE T GEOSCI REMOTE, V38, P2310, DOI 10.1109/36.868888
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Wang Wang X X, INSTRUMENTATION, V26 26, P15
   Wang Wang Y Y, RES POPULATION DENSI
   [吴明晖 Wu Minghui], 2018, [焊接学报, Transactions of the China Welding Institution], V39, P113
   Xueying Zhang, 2009, Proceedings of the 2009 Fifth International Conference on Natural Computation (ICNC 2009), P536, DOI 10.1109/ICNC.2009.257
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   [张杨忆 Zhang Yangyi], 2019, [哈尔滨工业大学学报, Journal of Harbin Institute of Technology], V51, P128
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao JD, 2019, MULTIMED TOOLS APPL, V78, P75, DOI 10.1007/s11042-017-5254-0
   Zhao J, 2017, J ADV TRANSPORT, P1, DOI 10.1155/2017/2130385
NR 32
TC 4
Z9 4
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4753
EP 4780
DI 10.1007/s11042-021-11008-6
EA MAY 2021
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000652106200002
DA 2024-07-18
ER

PT J
AU Park, S
   Choi, S
AF Park, Sangjin
   Choi, Sangil
TI Measurement method of determining natural and unnatural gaits using
   autocorrelation coefficients
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human gait; Gait analysis; Autocorrelation coefficient; Gait cycle
ID DISEASE
AB Walking is the most common physical activity in humans, and gait can be used as a measure of human health. If the gait is unnatural or uncomfortable, it indicates a problem inside or outside the person's body. In particular, for the elderly, walking is used as an important indicator of their health status. In this study, we developed an algorithm that can determine whether human walking is natural or unnatural, by comparing the autocorrelation coefficients of the left and right foot. We used F1-scores to measure the accuracy of the gait result determined by the algorithm. Natural walking was accurately distinguished with 80% accuracy, and unnatural with 60% accuracy. Owing to the splint attached to one foot to express unnatural walking, both feet affected gait, resulting in slightly lower accuracy than natural walking. As a future study, it is possible to devise a method to improve accuracy by extracting various gait features that can be obtained through gait and using artificial intelligence algorithms such as machine learning or deep learning.
C1 [Park, Sangjin] Sehan Univ, Dept Police Adm, Dangjin Si, Chungnam, South Korea.
   [Choi, Sangil] Gangneung Wonju Natl Univ, Dept Comp Sci & Engn, Wonju, South Korea.
C3 Sehan University; Kangnung Wonju National University
RP Choi, S (corresponding author), Gangneung Wonju Natl Univ, Dept Comp Sci & Engn, Wonju, South Korea.
EM idsjsj2@sehan.ac.kr; schoi@gwnu.ac.kr
OI CHOI, SANGIL/0000-0002-9272-7367
FU National Research Foundation of Korea (NRF) - Korean government (MSIT)
   [2020R1G1A1013937]
FX This study was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MSIT) (No.
   2020R1G1A1013937).
CR Adrian R-S, 2019, NEUROCOMPUTING, V389, P42
   Alaqtash M, 2011, IEEE ENG MED BIO, P453, DOI 10.1109/IEMBS.2011.6090063
   [Anonymous], 2013, P INT C BOD AR NETW
   Burgos CP, 2020, IEEE SENS J, V20, P12895, DOI 10.1109/JSEN.2020.3002589
   Chen S., 2011, Proc. International Conference on Body Sensor Networks, P71
   Del Din S, 2019, ANN NEUROL, V86, P357, DOI 10.1002/ana.25548
   Fineberg DB, 2013, J SPINAL CORD MED, V36, P313, DOI 10.1179/2045772313Y.0000000126
   Guang-Zhong Y, 2015, P INT C BOD SENS NET
   Howell AM, 2013, IEEE T BIO-MED ENG, V60, P3284, DOI 10.1109/TBME.2013.2250972
   Jeong-Ho Park, 2017, [Journal of the Korean Neurological Association, 대한신경과학회지], V35, P1, DOI 10.17340/jkna.2017.4.23
   Lemoyne R., 2020, 2020 INT C E HLTH BI, P1
   Li JX, 2018, INT C COMP SUPP COOP, P365, DOI 10.1109/CSCWD.2018.8465248
   Mannini A, 2011, IEEE ENG MED BIO, P4369, DOI 10.1109/IEMBS.2011.6091084
   Martin E., 2011, 2011 8th International Conference on Body Sensor Networks (BSN), P144, DOI 10.1109/BSN.2011.16
   Martin E., 2011, Proceedings of the 2011 IEEE Topical Conference on Biomedical Wireless Technologies, Networks, and Sensing Systems (BioWireleSS), P79, DOI 10.1109/BIOWIRELESS.2011.5724356
   Mc Ardle R, 2020, GAIT POSTURE, V76, P372, DOI 10.1016/j.gaitpost.2019.12.028
   Meng XL, 2013, IEEE ENG MED BIO, P4907, DOI 10.1109/EMBC.2013.6610648
   Muniz AMS, 2010, J BIOMECH, V43, P720, DOI 10.1016/j.jbiomech.2009.10.018
   Nagashima M, 2019, IEEE ENG MED BIO, P3629, DOI [10.1109/embc.2019.8857752, 10.1109/EMBC.2019.8857752]
   Panagiota A., 2012, Proceedings of the 2012 Ninth International Conference on Wearable and Implantable Body Sensor Networks (BSN 2012), P184, DOI 10.1109/BSN.2012.7
   Roozbeh J, 2011, P 2 C WIR HLTH
   Salarian A, 2004, IEEE T BIO-MED ENG, V51, P1434, DOI 10.1109/TBME.2004.827933
   Salarian A, 2013, IEEE T BIO-MED ENG, V60, P72, DOI 10.1109/TBME.2012.2223465
   Sang-Hyun, 2007, P 8 C KOR AC CLIN GE, V8, P346
   Sithi F, 2016, BIOMED RES-TOKYO, P112
   Studenski S, 2011, JAMA-J AM MED ASSOC, V305, P50, DOI 10.1001/jama.2010.1923
   Tanigawa A, 2018, GAIT POSTURE, V65, P176, DOI 10.1016/j.gaitpost.2018.07.165
   Tobias S, 2020, MICROPROCESSORS, V77
   Vathsangam H., 2010, 2010 4th International Conference on Pervasive Computing Technologies for Healthcare, P1
   Wang XC, 2017, INT C REHAB ROBOT, P467, DOI 10.1109/ICORR.2017.8009292
   Wook Choi Seung, 2009, [The Korean Society of Sports Science, 한국체육과학회지], V18, P1117
   Xu X., 2011, 2011 International Conference on Body Sensor Networks, P65
   허근섭, 2012, [Journal of the Korean Society for Precision Engineering, 한국정밀공학회지], V29, P1199, DOI 10.7736/KSPE.2012.29.11.1199
NR 33
TC 1
Z9 1
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36333
EP 36351
DI 10.1007/s11042-021-11014-8
EA MAY 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000650124300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Lawal, OM
AF Lawal, Olarewaju Mubashiru
TI Development of tomato detection model for robotic platform using deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tomato detection; YOLODenseNet; YOLOMixNet; Accuracy and speed; Double
   scene; Natural scene; Harvesting robots
ID AUTOMATIC RECOGNITION; IMAGE-ANALYSIS; VISION SYSTEM; COLOR; APPLES;
   FRUIT; AGRICULTURE; ALGORITHM; MACHINE; SCENES
AB Fruit detection plays a vital role in robotic harvesting platforms. However, natural scene attributes such as illumination variation, branch and leaf occlusion, clusters of tomatoes, shading, etc. and double scene including image augmentation and natural scene have made fruit detection a difficult task. An improved YOLOv3 model termed as Tomato detection models, which includes YOLODenseNet and YOLOMixNet was applied to solve these problems. YOLODenseNet incorporated DenseNet backbone, while the backbone of YOLOMixNet combined DarkNet and DenseNet. With the incorporation of spatial pyramid pooling (SPP), feature pyramid network (FPN), complete (CIoU) loss and Mish activation function into both models, the tested accuracy of YOLODenseNet at 98.3 % and YOLOMixNet at 98.4 % on natural scene performed better than YOLOv3 at 96.1 % and YOLOv4 at 97.6 %, but not with YOLOv4 under the double scene. Furthermore, the obtained detection speed of YOLOMixNet at 47.4FPS was noted to be in close par with the YOLOv4 at 48.9FPS. Finally, the Tomato detection models showed reliability, better generalization, and a high prospect for real - time harvesting robots.
C1 [Lawal, Olarewaju Mubashiru] Shanxi Agr Univ, Inst Agr Engn, Jinzhong City 030801, Peoples R China.
C3 Shanxi Agricultural University
RP Lawal, OM (corresponding author), Shanxi Agr Univ, Inst Agr Engn, Jinzhong City 030801, Peoples R China.
EM olarewajulawal@yahoo.com
FU Natural Science Foundation of Shanxi Province and Shanxi Agricultural
   University, China [2020BQ34]
FX This research work was supported by the Natural Science Foundation of
   Shanxi Province and Shanxi Agricultural University, China under Grant
   No. 2020BQ34.
CR Alexey B, 2020, COMPUTER VISION PATT
   Bulanon DM, 2009, BIOSYST ENG, V103, P12, DOI 10.1016/j.biosystemseng.2009.02.009
   Bulanon DM, 2002, BIOSYST ENG, V83, P405, DOI 10.1006/bioe.2002.0132
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang YQ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093079
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji W, 2012, COMPUT ELECTR ENG, V38, P1186, DOI 10.1016/j.compeleceng.2011.11.005
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kapach K., 2012, International Journal of Computational Vision and Robotics, V3, P4, DOI [DOI 10.1504/IJCVR.2012.046419, 10.1504/IJCVR.2012.046419]
   Kelman E, 2014, BIOSYST ENG, V118, P174, DOI 10.1016/j.biosystemseng.2013.11.007
   Koirala A, 2019, PRECIS AGRIC, V20, P1107, DOI 10.1007/s11119-019-09642-0
   Kurtulmus F, 2014, PRECIS AGRIC, V15, P57, DOI 10.1007/s11119-013-9323-8
   Kurtulmus F, 2011, COMPUT ELECTRON AGR, V78, P140, DOI 10.1016/j.compag.2011.07.001
   Le QV, 2019, Learning data augmentation strategies for object detection
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Linker R, 2012, COMPUT ELECTRON AGR, V81, P45, DOI 10.1016/j.compag.2011.11.007
   Liu GX, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072145
   Liu GX, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19092023
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luo LF, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16122098
   Mao W, 2009, P IEEE 2 INT C IM SI, P1, DOI DOI 10.1109/CISP.2009.5305224
   Misra D., 2019, ARXIV190808681
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Patrício DI, 2018, COMPUT ELECTRON AGR, V153, P69, DOI 10.1016/j.compag.2018.08.001
   Payne A, 2014, COMPUT ELECTRON AGR, V100, P160, DOI 10.1016/j.compag.2013.11.011
   Qiang L, 2014, INT J AGR BIOL ENG, V7, P115, DOI 10.3965/j.ijabe.20140702.014
   Ramachandran P., 2017, ARXIV171005941V1, V7, P1
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Tian YN, 2019, J SENSORS, V2019, DOI 10.1155/2019/7630926
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wei XQ, 2014, OPTIK, V125, P5684, DOI 10.1016/j.ijleo.2014.07.001
   Xiang R, 2014, COMPUT ELECTRON AGR, V106, P75, DOI 10.1016/j.compag.2014.05.006
   Yamamoto K, 2014, SENSORS-BASEL, V14, P12191, DOI 10.3390/s140712191
   Yin HP, 2009, IEEE SYS MAN CYBERN, P2984, DOI 10.1109/ICSMC.2009.5345994
   Zhao YS, 2016, COMPUT ELECTRON AGR, V127, P311, DOI 10.1016/j.compag.2016.06.022
   Zhao YS, 2016, BIOSYST ENG, V148, P127, DOI 10.1016/j.biosystemseng.2016.05.001
   Zhao YS, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16020173
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 48
TC 27
Z9 28
U1 2
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26751
EP 26772
DI 10.1007/s11042-021-10933-w
EA MAY 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000648376700001
DA 2024-07-18
ER

PT J
AU Al-Maadeed, TA
   Hussain, I
   Anees, A
   Mustafa, MT
AF Al-Maadeed, Temadher Alassiry
   Hussain, Iqtadar
   Anees, Amir
   Mustafa, Muhammad Tahir
TI A image encryption algorithm based on chaotic Lorenz system and novel
   primitive polynomial S-boxes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lorenz System; Chaos; Substitution box; Image encryption; Cryptanalysis
AB We have proposed a robust, secure and efficient image encryption algorithm based on chaotic maps and algebraic structure. Nowadays, the chaotic cryptosystems gained more attention due to their efficiency, the assurance of robustness and high sensitivity corresponding to initial conditions. In literature, there are many encryption algorithms that can simply guarantees security while the schemes based on chaotic systems only promises the uncertainty, both of them can not encounter the needs of current scenario. To tackle this issue, this article proposed an image encryption algorithm based on Lorenz chaotic system and primitive irreducible polynomial substitution box. First, we have proposed 16 different S-boxes based on projective general linear group and 16 primitive irreducible polynomials of Galois field of order 256, and then utilized these S-boxes with combination of chaotic map in image encryption scheme. Three chaotic sequences can be produced by the disturbed of Lorenz chaotic system corresponding to variables x, y and z. We have constructed a new pseudo random chaotic sequence k(i) based on x, y and z. The plain image is encrypted by the use of chaotic sequence k(i) and XOR operation to get a ciphered image. To show the strength of presented image encryption, some renowned analyses are performed.
C1 [Al-Maadeed, Temadher Alassiry; Hussain, Iqtadar; Mustafa, Muhammad Tahir] Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Doha 2713, Qatar.
   [Anees, Amir] Deakin Univ, Fac Sci Engn & Built Environm, Sch Info Technol, Melbourne, Vic, Australia.
C3 Qatar University; Deakin University
RP Al-Maadeed, TA (corresponding author), Qatar Univ, Coll Arts & Sci, Dept Math Stat & Phys, Doha 2713, Qatar.
EM t.alassiry@qu.edu.qa; iqtadarqau@qu.edu.qa; a.anees@deakin.edu.au;
   tahir.mustafa@qu.edu.qa
OI Almaadeed, Temadher/0000-0002-0308-2422
FU Qatar National Library
FX Open access funding provided by the Qatar National Library.
CR Ahmad J, 2015, NONLINEAR DYNAM, V82, P1839, DOI 10.1007/s11071-015-2281-0
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Amigó JM, 2007, PHYS LETT A, V366, P211, DOI 10.1016/j.physleta.2007.02.021
   Anees A, 2014, COMMUN NONLINEAR SCI, V19, P3106, DOI 10.1016/j.cnsns.2014.02.011
   Anees A, 2014, NONLINEAR DYNAM, V75, P807, DOI 10.1007/s11071-013-1105-3
   Bakhache B, 2014, IEEE SYST J, V8, P1021, DOI 10.1109/JSYST.2013.2246011
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Ben Farah MA, 2011, COMMUN NONLINEAR SCI, V16, P2543, DOI 10.1016/j.cnsns.2010.09.005
   Biham E., 1993, DIFFERENTIAL CRYPTAN
   Çavusoglu Ü, 2016, SECUR COMMUN NETW, V9, P1285, DOI 10.1002/sec.1414
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Çiçek S, 2013, J CIRCUIT SYST COMP, V22, DOI 10.1142/S0218126613500229
   Daemen J, 2020, The design of rijndael: the advanced encryption standard (AES), V2nd, DOI DOI 10.1007/978-3-662-60769-53
   Dillak, 2013, INF TECHN EL ENG ICI
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Jolfaei A., 2011, COMPUT INFORM SCI, V4, P172
   Khan M, 2016, NEURAL COMPUT APPL, V27, P677, DOI 10.1007/s00521-015-1887-y
   Kohli R, 2013, IJARCSSE, V3
   Liu HJ, 2014, AEU-INT J ELECTRON C, V68, P676, DOI 10.1016/j.aeue.2014.02.002
   Liu YB, 2012, COMMUN NONLINEAR SCI, V17, P3267, DOI 10.1016/j.cnsns.2011.11.040
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Morioka S, 2002, LECT NOTES COMPUT SC, V2523, P172
   Noura H, 2010, PROCEEDINGS OF THE 2010 8TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS (COMM), P423, DOI 10.1109/ICCOMM.2010.5509114
   Ott E, 1979, CHAOS DYNAMICAL SYST
   Özkaynak F, 2013, NONLINEAR DYNAM, V74, P551, DOI 10.1007/s11071-013-0987-4
   Pareschi F, 2010, IEEE T CIRCUITS-I, V57, P3124, DOI 10.1109/TCSI.2010.2052515
   Pehlivan I, 2012, TURK J ELECTR ENG CO, V20, P1229, DOI 10.3906/elk-1103-14
   Pisarchik AN, 2008, PHYSICA D, V237, P2638, DOI 10.1016/j.physd.2008.03.049
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Sharma MK, 2012, INT J COMPUT APPL, V60
   Shujun L., 2001, LECT NOTES COMPUTER, V2247, P316, DOI DOI 10.1007/3-540-45311-3_30
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P1901, DOI 10.1016/j.chaos.2004.07.033
   Tang GP, 2005, CHAOS SOLITON FRACT, V23, P413, DOI 10.1016/j.chaos.2004.04.023
   Ullah A, 2017, NONLINEAR DYNAM, V88, P2757, DOI 10.1007/s11071-017-3409-1
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wang Y, 2009, ECBI: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE AND BUSINESS INTELLIGENCE, PROCEEDINGS, P125, DOI 10.1109/ECBI.2009.15
   Wang Y, 2009, COMMUN NONLINEAR SCI, V14, P3089, DOI 10.1016/j.cnsns.2008.12.005
   Wu Y, 2010, CYBER J MULTIDISCIPL, P31
   Yang DG, 2009, CHAOS SOLITON FRACT, V41, P505, DOI 10.1016/j.chaos.2008.02.017
   Yang HQ, 2010, COMMUN NONLINEAR SCI, V15, P3507, DOI 10.1016/j.cnsns.2010.01.004
   Zhang, 2013, P 2013 INT C SENS NE
NR 46
TC 31
Z9 31
U1 8
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24801
EP 24822
DI 10.1007/s11042-021-10695-5
EA APR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700010
OA hybrid
DA 2024-07-18
ER

PT J
AU Kishor, A
   Chakraborty, C
   Jeberson, W
AF Kishor, Amit
   Chakraborty, Chinmay
   Jeberson, Wilson
TI Reinforcement learning for medical information processing over
   heterogeneous networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cloud computing; Fog computing; Medical information processing; Quality
   of service; Healthcare
AB Fog computing is an emerging trend in the healthcare sector for the care of patients in emergencies. Fog computing provides better results in healthcare by improving the quality of services in the heterogeneous network. The transmission of critical multimedia healthcare data is required to be transferred in real-time for saving the lives of patients using better quality networks. The main objective is to improve the quality of service over a heterogeneous network by reinforcement learning-based multimedia data segregation (RLMDS) algorithm and Computing QoS in Medical Information system using Fuzzy (CQMISF) algorithm in fog computing. The proposed algorithms works in three phase's such as classification of healthcare data, selection of optimal gateways for data transmission and improving the transmission quality with the consideration of parameters such as throughput, end-to-end delay and jitter. Proposed algorithms used to classify the healthcare data and transfer the classified high-risk data to end-user with by selecting the optimal gateway. To performance validation, extensive simulations were conducted on MATLAB R2018b on different parameters like throughput, end-to-end delay, and jitter. The performance of the proposed work is compared with FLQoS and AQCA algorithms. The proposed CQMISF algorithm achieves 81.7% overall accuracy and in comparison to FLQoS and AQCA algorithm, the proposed algorithms achieves the significant improvement of 6.195% and 2.01%.
C1 [Kishor, Amit; Jeberson, Wilson] Sam Higginbottom Univ Agr Technol & Sci SHUATS, Dept Comp Sci & Informat Technol, Allahabad, UP, India.
   [Chakraborty, Chinmay] Birla Inst Technol, Dept Elect & Commun Engn, Mesra, Jharkhand, India.
C3 Sam Higginbottom University of Agriculture, Technology & Sciences; Birla
   Institute of Technology Mesra
RP Kishor, A (corresponding author), Sam Higginbottom Univ Agr Technol & Sci SHUATS, Dept Comp Sci & Informat Technol, Allahabad, UP, India.
EM amit_kishor@rediffmail.com
RI Wilson, Jeberson/AGS-8211-2022; Chakraborty, Chinmay/N-3608-2017;
   Kishor, Dr. Amit/ABG-5949-2021
OI Wilson, Jeberson/0000-0002-2467-2165; Chakraborty,
   Chinmay/0000-0002-4385-0975; Kishor, Dr. Amit/0000-0002-4829-818X
CR Alam MGR, 2016, 2016 INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN), P285, DOI 10.1109/ICOIN.2016.7427078
   Amira RB, 2018, LECT NOTES COMPUT SC, V11230, P241, DOI 10.1007/978-3-030-02671-4_14
   Baek JY, 2019, IEEE WCNC
   Balaji BS, 2018, COMPUT ELECTR ENG, V69, P435, DOI 10.1016/j.compeleceng.2016.09.013
   Brogi A, 2017, IEEE INTERNET THINGS, V4, P1185, DOI 10.1109/JIOT.2017.2701408
   Chakraborty C. S. Chinmay, 2011, CIIT INT J FUZZY SYS, V3, P35
   Chakraborty C, 2017, WIRELESS PERS COMMUN, V96, P3655, DOI 10.1007/s11277-017-4281-5
   El Kafhali S, 2017, J SUPERCOMPUT, V73, P5261, DOI 10.1007/s11227-017-2083-x
   Kadhim AJ, 2019, AD HOC NETW, V84, P68, DOI 10.1016/j.adhoc.2018.09.018
   Kaur P, 2012, INT J COMPUT SCI COM, V1
   Kim HJ, 2014, MULTIMED TOOLS APPL, V72, P2163, DOI 10.1007/s11042-013-1507-8
   Li YN, 2019, IEEE T DEPEND SECURE, V16, P72, DOI 10.1109/TDSC.2017.2662216
   Liu LQ, 2018, IEEE INTERNET THINGS, V5, P283, DOI 10.1109/JIOT.2017.2780236
   Mahmud R, 2018, ICDCN'18: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, DOI 10.1145/3154273.3154347
   Mai L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092830
   Moazzemi K, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358203
   Mohammed Z., 2020, UHD J SCI TECHNOL, V4, P9, DOI [10.21928/uhdjst.v4n1y2020.pp9-17, DOI 10.21928/UHDJST.V4N1Y2020.PP9-17]
   Mohammed ZF, 2021, MULTIMED TOOLS APPL, V80, P6355, DOI 10.1007/s11042-020-10066-6
   Mondal HS, 2017, 2017 20 INT C COMP I, P1, DOI [10.1109/ICCITECHN.2017.8281825, DOI 10.1109/ICCITECHN.2017.8281825]
   Mutlag AA, 2019, FUTURE GENER COMP SY, V90, P62, DOI 10.1016/j.future.2018.07.049
   Naseri A, 2019, J AMB INTEL HUM COMP, V10, P1851, DOI 10.1007/s12652-018-0773-8
   Nishtala R, 2017, INT S HIGH PERF COMP, P409, DOI 10.1109/HPCA.2017.13
   Ramezani F, 2016, ASIA PAC J INF TECHN, V5, P39
   Ritu, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P47, DOI 10.1109/RTEICT.2016.7807780
   Selvakanmani S, 2021, J AMB INTEL HUM COMP, V12, P3423, DOI 10.1007/s12652-020-02156-y
   Singh S, 2019, INT J DISTRIB SENS N, V15, DOI 10.1177/1550147719844159
   Sodhro AH, 2020, NEURAL COMPUT APPL, V32, P723, DOI 10.1007/s00521-018-3931-1
   Sodhro AH, 2019, INT J INFORM MANAGE, V45, P308, DOI 10.1016/j.ijinfomgt.2018.08.004
   Soleymani SA, 2017, IEEE ACCESS, V5, P15619, DOI 10.1109/ACCESS.2017.2733225
   Sun Le, 2016, FUTURE GENER COMP SY, V57, P42, DOI 10.1016/j.future.2015.11.025
   Sundharakumar KB, 2015, PROCEDIA COMPUT SCI, V50, P143, DOI 10.1016/j.procs.2015.04.076
   Umoh U, 2017, INT J COMPUT INTELL, V16, DOI 10.1142/S1469026817500237
   Xiang HY, 2017, IEEE COMMUN MAG, V55, P110, DOI 10.1109/MCOM.2017.1700523
   Yousefpour A, 2018, IEEE INTERNET THINGS, V5, P998, DOI 10.1109/JIOT.2017.2788802
NR 34
TC 77
Z9 77
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23983
EP 24004
DI 10.1007/s11042-021-10840-0
EA MAR 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000634660700002
DA 2024-07-18
ER

PT J
AU Soussa, MRB
   de Senna, V
   da Silva, VL
   Soares, CL
AF Soussa, Marcio Rene Brandao
   de Senna, Valter
   da Silva, Valeria Loureiro
   Soares, Charles Lima
TI Modeling elderly behavioral patterns in single-person households
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Kernel estimator; Data mining; Single-person
   households
ID SMART HOMES; HEALTH; SYSTEM; TECHNOLOGY; SENSORS
AB This paper proposes and describes an unsupervised computational model that monitors an elderly person who lives alone and issues alarms when a risk to the elderly person's well-being is identified. This model is based on data extracted exclusively from passive infrared motion sensors connected to a ZigBee wireless network. The proposed monitoring system and model is non-intrusive, does not capture any images, and does not require any interaction with the monitored person. Thus, it is more likely to be adopted by members of the elderly population who might reject other more intrusive or complex types of technology. The developed computational model for activity discovery employs a kernel estimator and local outlier factor calculation, which are reliable and have a low computational cost. This model was tested with data collected over a period of 25 days from two elderly volunteers who live alone and have fairly different routines. The results demonstrate the model's ability to learn relevant behaviors, as well as identify and issue alarms for atypical activities that can be suggestive of health problems. This low-cost, minimalistic sensor network approach is especially suited to the reality of underdeveloped (and developing) countries where assisted living communities are not available and low cost and ease of use are paramount.
C1 [Soussa, Marcio Rene Brandao; de Senna, Valter; da Silva, Valeria Loureiro; Soares, Charles Lima] SENAI CIMATEC, Grad Program Computat Modeling & Ind Technol, Salvador, BA, Brazil.
C3 Faculdade de Tecnologia Senai Cimatec
RP Soussa, MRB (corresponding author), SENAI CIMATEC, Grad Program Computat Modeling & Ind Technol, Salvador, BA, Brazil.
EM marcio.soussa10@gmail.com
RI ; Loureiro da Silva, Valeria/HJY-8849-2023
OI SOARES, CHARLES/0000-0001-9477-7491; Loureiro da Silva,
   Valeria/0000-0001-5466-7933; Senna, Valter/0000-0002-4593-3459
FU SENAI-CIMATEC
FX SENAI-CIMATEC
CR Al-khafajiy M, 2019, MULTIMED TOOLS APPL, V78, P24681, DOI 10.1007/s11042-018-7134-7
   Alexander GL, 2011, NURS RES, V60, P318, DOI 10.1097/NNR.0b013e318225f3e1
   [Anonymous], 2015, WHO REP AG HLTH
   [Anonymous], 2019, World population prospects 2019
   Banerjee T, 2015, COMPUT VIS IMAGE UND, V140, P68, DOI 10.1016/j.cviu.2015.04.005
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Camargos Mirela Castro Santos, 2011, Rev. bras. estud. popul., V28, P217
   Chaimowicz F, 1999, REV SAUDE PUBL, V33, P454, DOI 10.1590/S0034-89101999000500004
   Chen LM, 2012, IEEE T SYST MAN CY C, V42, P790, DOI 10.1109/TSMCC.2012.2198883
   Cook DJ, 2014, J INTELL INF SYST, V43, P503, DOI 10.1007/s10844-014-0341-4
   Cook DJ, 2013, COMPUTER, V46, P62, DOI 10.1109/MC.2012.328
   Cook DJ, 2013, IEEE T CYBERNETICS, V43, P820, DOI 10.1109/TSMCB.2012.2216873
   Creutzberg M, 2007, REV LAT-AM ENFERM, V15, P1144, DOI 10.1590/S0104-11692007000600014
   Demiris G, 2008, INT J TECHNOL ASSESS, V24, P120, DOI 10.1017/S0266462307080154
   Demiris G, 2006, STUD HEALTH TECHNOL, V124, P45
   Demongeot J, 2002, CR BIOL, V325, P673, DOI 10.1016/S1631-0691(02)01480-4
   Diestel R, 2000, GRAPH THEORY ELECT
   Duchene F, 2002, HOME HLTH TELECARE P
   Eurostat Statistical Books, 2020, EU WORLD 2020 EDITIO
   Ghayvat H, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040766
   Haigh KZ, 2012, P ASS ADV ART INT AA
   Harvard University Joint Center for Housing Studies, 2019, HOUS AM OLD AD 2019
   Ibrahim Omar A., 2019, 2019 IEEE International Conference on Bioinformatics and Biomedicine (BIBM). Proceedings, P1043, DOI 10.1109/BIBM47256.2019.8983010
   Instituto Brasileiro de Geografia e Estatistica-IBGE, 2010, CENS DEM 2010 FAM DO
   Kaye JA, 2011, J GERONTOL B-PSYCHOL, V66, P180, DOI [10.1093/geronb/gbq095, 10.1093/geronb/ghq095]
   Ko J, 2010, P IEEE, V98, P1947, DOI 10.1109/JPROC.2010.2065210
   Loureiro da Silva V., 2018, R TECNOL INF COMUN, V8, P23
   Lowe SA, 2014, MED ENG PHYS, V36, P147, DOI 10.1016/j.medengphy.2013.11.010
   Luo XM, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060822
   Muir D, KERNEL DENSITY ESTIM
   Nakagawa EY, 2013, J SYST SOFTWARE, V86, P985, DOI 10.1016/j.jss.2012.10.013
   Palumbo F, 2014, SENSORS-BASEL, V14, P3833, DOI 10.3390/s140303833
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Pavel M, 2015, IEEE T BIO-MED ENG, V62, P2763, DOI 10.1109/TBME.2015.2484286
   Peek STM, 2014, INT J MED INFORM, V83, P235, DOI 10.1016/j.ijmedinf.2014.01.004
   Popescu M, 2012, METHOD INFORM MED, V51, P359, DOI 10.3414/ME11-02-0042
   Popescu M, 2013, 4 IEEE INT C EHB IAS
   Prendergast David, 2020, CULTURAL CONTEXT AGI, P130
   Rantz M, 2015, GERONTOLOGIST, V55, pS78, DOI 10.1093/geront/gnv044
   Rantz MJ, 2015, GERONTOLOGY, V61, P281, DOI 10.1159/000366518
   Rantz MJ, 2013, CIN-COMPUT INFORM NU, V31, P274, DOI 10.1097/NXN.0b013e318296298f
   Rantz MJ, 2013, J AM MED DIR ASSOC, V14, P386, DOI 10.1016/j.jamda.2013.02.018
   Reboucas SV., 2019, BLUCHER ENG P, V6, P506, DOI [10.1016/siintec2019-65, DOI 10.1016/SIINTEC2019-65]
   Reddy R., 2019, RESIDENTS AWARE NETW, DOI [10.1109/ICE.2019.8792628, DOI 10.1109/ICE.2019.8792628]
   Roepke SK, 2010, INDIAN J MED RES, V131, P302
   ROSENBLATT M, 1956, ANN MATH STAT, V27, P832, DOI 10.1214/aoms/1177728190
   Ruohonen K., Graph Theory
   Sheahen M, 2015, LECT NOTES COMPUT SC, V8456, P13, DOI 10.1007/978-3-319-14424-5_2
   Skapik J, 2013, IEEE R BME 6
   Sovacool BK, 2020, RENEW SUST ENERG REV, V120, DOI 10.1016/j.rser.2019.109663
   Sprint G, 2016, COMPUTER, V49, P29, DOI 10.1109/MC.2016.338
   Sung WT, 2014, APPL SOFT COMPUT, V22, P667, DOI 10.1016/j.asoc.2014.04.036
   Susnea I, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19102264
   Tapia EM, 2004, LECT NOTES COMPUT SC, V3001, P158, DOI 10.1007/978-3-540-24646-6_10
   United Nations, 2019, DEP EC SOC AFF HOUS
   United Nations Department of Economic and Social Affairs Population Division, 2013, STESASERA348 UN POP
   Wang SZ, 2019, HEALTHCARE-BASEL, V7, DOI 10.3390/healthcare7020060
   Wilson RJ, 1996, Introduction to Graph Theory
NR 58
TC 2
Z9 2
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 22097
EP 22120
DI 10.1007/s11042-021-10635-3
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000631790800001
OA hybrid
DA 2024-07-18
ER

PT J
AU Kumar, A
   Raghava, NS
AF Kumar, Ashish
   Raghava, N. S.
TI An efficient image encryption scheme using elementary cellular automata
   with novel permutation box
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cellular automata; Chaotic map; Confusion; Diffusion; Image encryption
ID SECURITY; CHAOS
AB Digital image communication over public networks requires a high level of security to protect picture elements that represent information. Security is an important and challenging issue that can be solved using cryptography techniques. Generally, image encryption techniques are based on multiple rounds and iterations. In this paper, a secured lightweight cryptosystem is designed based on lookup table operations that reduce computational overhead, resource requirement and power consumption compared to traditional security mechanisms. In this context, one-dimensional elementary cellular automaton has been combined with Henon chaotic map to design a cryptosystem, which can produce unprecedented results in cryptography. Initially, state attractors for rule space are investigated and analyzed in Wolfram's cellular automata to extract the properties and functional abilities to perform cryptographic operations. A novel algorithm of keyed transposition cipher is applied to digital image in P-Box module to produce shuffled image. Then, the extracted properties of ECA are preserved in a tabular form and further used in the diffusion process. Based on the simulation and comparison with other existing mechanisms, it is evident that the proposed algorithm is promising and obstructive to all kinds of statistical attacks, and it yields security primacy in various areas of cryptography. Encryption/Decryption is based on indexed based lookup tables principal using ECA and can be easily implemented using logic gates. The proposed algorithm provides confidentiality and can be adopted in IoT networks that require lightweight cryptography modules. Experimental results of color and gray images demonstrate flourishing results in the real-time environment of cryptography.
C1 [Kumar, Ashish] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
   [Raghava, N. S.] Delhi Technol Univ, Dept Elect & Commun Engn, Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Kumar, A (corresponding author), Delhi Technol Univ, Dept Informat Technol, Delhi, India.
EM ashishkumar@dtu.ac.in; nsraghava@dce.ac.in
RI Kumar, Ashish/KHD-8178-2024
OI KUMAR, ASHISH/0000-0003-3964-8843
CR Abdo AA, 2013, COMMUN NONLINEAR SCI, V18, P136, DOI 10.1016/j.cnsns.2012.05.023
   Abdulla A. A., 2015, Ph.D. dissertation
   Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Ahmad J, 2018, NEURAL COMPUT APPL, V30, P3847, DOI 10.1007/s00521-017-2970-3
   Azza AA, 2020, MULTIMED TOOLS APPL, V79, P21241, DOI 10.1007/s11042-020-08823-8
   Babaei A, 2020, OPTIK, V203, DOI 10.1016/j.ijleo.2019.164000
   Bhattacharjee K, 2020, NAT COMPUT, V19, P433, DOI 10.1007/s11047-018-9696-8
   Borriello E, 2017, COMPLEXITY, DOI 10.1155/2017/1280351
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Dooley JF, CIPHER MYSTERIES HIS, P263, DOI [10.1007/978-3-319-90443-6_16, DOI 10.1007/978-3-319-90443-6_16]
   Enayatifar R, 2019, OPT LASER ENG, V115, P131, DOI 10.1016/j.optlaseng.2018.11.017
   Flores-Gallegos N, 2016, CHEM PHYS LETT, V650, P57, DOI 10.1016/j.cplett.2016.02.061
   Gadekallu TR, 2021, J REAL-TIME IMAGE PR, V18, P1383, DOI 10.1007/s11554-020-00987-8
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   GARDNER M, 1970, SCI AM, V223, P120, DOI 10.1038/scientificamerican1070-120
   Ghazanfaripour H, 2020, OPT LASER TECHNOL, V131, DOI 10.1016/j.optlastec.2020.106339
   Hussain S, 2019, IEEE INTERNET THINGS, V6, P10936, DOI 10.1109/JIOT.2019.2934947
   Jadhav R., 2017, Int. J. Comput. Appl, V162, P14, DOI DOI 10.5120/IJCA2017913256
   Jin J, 2012, OPT LASER ENG, V50, P1836, DOI 10.1016/j.optlaseng.2012.06.002
   Jin Yang, 2018, International Journal of High Performance Computing and Networking, V11, P231
   Kamilya S, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418300082
   Kaushik S, 2019, INT J CLOUD APPL COM, V9, P21, DOI 10.4018/IJCAC.2019100102
   KEMENY JG, 1967, SCIENCE, V157, P180, DOI 10.1126/science.157.3785.180
   Li CH, 2017, NONLINEAR DYNAM, V87, P127, DOI 10.1007/s11071-016-3030-8
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Mayer RE, 2002, PSYCHOL LEARN MOTIV, V41, P85, DOI 10.1016/S0079-7421(02)80005-6
   McAndrew A, 2016, INTRO CRYPTOGRAPHY O, DOI [10.1201/9781439825716, DOI 10.1201/9781439825716]
   McGee AR, 2004, 11 INT TEL NETW STRA, DOI [10.1109/netwks.2004.240993, DOI 10.1109/NETWKS.2004.240993]
   Morán A, 2020, IEEE T COMPUT, V69, P392, DOI 10.1109/TC.2019.2949300
   Murugan B, 2016, IET COMPUT VIS, V10, P593, DOI 10.1049/iet-cvi.2015.0344
   Parker AT, 2001, IEEE T CIRCUITS-I, V48, P624, DOI 10.1109/81.922466
   Raghava NS., 2020, ENGG APPL SCI RES, V47, P66
   Ravichandran D, 2019, 3D KEY ENCRYPTING 2D, DOI [10.1109/vitecon.2019.8899349, DOI 10.1109/VITECON.2019.8899349]
   Rey AM, LECT NOTES COMPUTER, P52, DOI [10.1007/978-3-540-71805-5_6, DOI 10.1007/978-3-540-71805-5_6]
   Roy S, 2020, J AMB INTEL HUM COMP, V11, P5083, DOI 10.1007/s12652-020-01813-6
   Sanchez-Avila C, 2001, 35TH ANNUAL 2001 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P229, DOI 10.1109/CCST.2001.962837
   Seredynski F, 2004, PARALLEL COMPUT, V30, P753, DOI 10.1016/j.parco.2003.12.014
   Sfar AR, 2018, DIGIT COMMUN NETW, V4, P118, DOI 10.1016/j.dcan.2017.04.003
   Shifa A, 2016, 2016 SIXTH INTERNATIONAL CONFERENCE ON INNOVATIVE COMPUTING TECHNOLOGY (INTECH), P550, DOI 10.1109/INTECH.2016.7845081
   Singh Saurabh, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P1625, DOI 10.1007/s12652-017-0494-4
   Sreelaja NK, 2012, APPL SOFT COMPUT, V12, P2879, DOI 10.1016/j.asoc.2012.04.002
   Tewari Aakanksha, 2019, International Journal of High Performance Computing and Networking, V15, P106
   WOLFRAM S, 1986, LECT NOTES COMPUT SC, V218, P429
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
NR 44
TC 19
Z9 19
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21727
EP 21750
DI 10.1007/s11042-021-10750-1
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000630647100004
DA 2024-07-18
ER

PT J
AU Shah, B
   Alsadoon, A
   Prasad, PWC
   Al-Naymat, G
   Beg, A
AF Shah, Bhagyashree
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Naymat, Ghazi
   Beg, Azam
TI DPV: a taxonomy for utilizing deep learning as a prediction technique
   for various types of cancers detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancer prediction; Survival; Deep learning; Machine learning; Artificial
   intelligence
ID NEURAL-NETWORKS; CLASSIFICATION; IMAGES
AB Deep learning (DL) is a type of machine learning capable of processing large quantities of data to provide analytic results based on a particular framework's parameters and aims. DL is widely used in a variety of fields, including medicine. Currently, there are various DL-based prediction models for predicting cancer probability and survival. However, the specific problem is that no integrated system can predict cancer survival, probability, and presence in the medical patient's samples. Therefore, this research investigates the latest literature in the field of DL-based cancer prediction models for predicting the cancer probability and the patient survival rate. The name of this proposed model is Multimodal Incremental Recurrent Deep Neural Network; it can perform the analysis, prediction, and diagnosis of cancer using multi-dimensional data processing. It can also predict the cancer possibility and survival using incremental recurrent neural networks. The components of the proposed taxonomy are Data, Prediction technique, and View (DPV). This research's contribution is the critical analysis of the latest literature on the DL-based systems that can predict cancer and its outcomes. It provides a theoretical model that can predict the possibility, presence, and survival of cancer by processing multi-dimensional medical samples of the patient to make accurate predictions. We also highlight the importance of the proposed taxonomy.
C1 [Shah, Bhagyashree; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer] Univ Western Sydney, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Asia Pacific Int Coll, Dept Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Dept Informat Technol, Sydney, NSW, Australia.
   [Al-Naymat, Ghazi] Ajman Univ, Dept Informat Technol, Coll Engn & IT, Ajman, U Arab Emirates.
   [Beg, Azam] United Arab Emirates Univ, Coll Informat Technol, Abu Dhabi, U Arab Emirates.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; Ajman University; United Arab Emirates University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll, Dept Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Dept Informat Technol, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Alakwaa FM, 2018, J PROTEOME RES, V17, P337, DOI 10.1021/acs.jproteome.7b00595
   Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   Anders S, 2010, GENOME BIOL, V11, DOI 10.1186/gb-2010-11-10-r106
   Burke HB, 1997, CANCER, V79, P857, DOI 10.1002/(SICI)1097-0142(19970215)79:4<857::AID-CNCR24>3.0.CO;2-Y
   Bychkov D, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-21758-3
   Chen DH, 2017, LECT NOTES COMPUT SC, V10635, P43, DOI 10.1007/978-3-319-70096-0_5
   Choi H, 2018, BIOMED RES INT-UK, V2018, DOI 10.1155/2018/2914280
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Echaniz O, 2017, LECT NOTES COMPUT SC, V10338, P42, DOI 10.1007/978-3-319-59773-7_5
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fernandes K, 2018, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.154
   Fu M, 2018, BMC SYST BIOL, V12, DOI 10.1186/s12918-018-0572-z
   Hareendran SA, 2020, LECT NOTES COMPUTER, V12145, DOI 10.1007/978-3-030-53956-6_53
   Hashimoto Y, 2018, GASTROINTEST ENDOSC, V87, pAB434
   Islam MM, 2017, INT CONF ADV ELECTR, P59, DOI 10.1109/ICAEE.2017.8255327
   Kadir T, 2018, TRANSL LUNG CANCER R, V7, P304, DOI 10.21037/tlcr.2018.05.15
   Khan AM, 2014, IEEE T BIO-MED ENG, V61, P1729, DOI 10.1109/TBME.2014.2303294
   Kim BJ, 2018, P NATL ACAD SCI USA, V115, P1322, DOI 10.1073/pnas.1717960115
   Kim S, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0349-7
   Kooi T, 2017, MED IMAGE ANAL, V35, P303, DOI 10.1016/j.media.2016.07.007
   Labaki WW, 2018, AM J RESP CRIT CARE, V197, P148, DOI 10.1164/rccm.201709-1879ED
   Matsuo K, 2017, AM J OBSTET GYNECOL, V217, P703, DOI 10.1016/j.ajog.2017.08.012
   Mobadersany P, 2018, P NATL ACAD SCI USA, V115, pE2970, DOI 10.1073/pnas.1717139115
   Preuer K, 2018, BIOINFORMATICS, V34, P1538, DOI 10.1093/bioinformatics/btx806
   Sharma H, 2017, COMPUT MED IMAG GRAP, V61, P2, DOI 10.1016/j.compmedimag.2017.06.001
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Song Y, 2018, J MAGN RESON IMAGING, V48, P1570, DOI 10.1002/jmri.26047
   Sun DD, 2019, IEEE ACM T COMPUT BI, V16, P841, DOI 10.1109/TCBB.2018.2806438
   Sun YS, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-53989-3
   Urban G, 2019, IEEE ACM T COMPUT BI, V16, P1029, DOI 10.1109/TCBB.2018.2841396
   Velazquez ER, 2017, CANCER RES, V77, P3922, DOI 10.1158/0008-5472.CAN-17-0122
   Xiao YW, 2018, COMPUT METH PROG BIO, V153, P1, DOI 10.1016/j.cmpb.2017.09.005
   Yousefi S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11817-6
   Yuan XH, 2018, PATTERN RECOGN, V77, P160, DOI 10.1016/j.patcog.2017.12.017
   Zhu W, 2020, CANCERS, V12, DOI 10.3390/cancers12030603
NR 35
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21339
EP 21361
DI 10.1007/s11042-021-10769-4
EA MAR 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494100003
DA 2024-07-18
ER

PT J
AU Taheri, M
   Mozaffari, S
   Keshavarzi, P
AF Taheri, Motahareh
   Mozaffari, Saeed
   Keshavarzi, Parviz
TI Privacy-preserving biometric verification with outsourced correlation
   filter computation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric verification; Privacy preserving; Cloud computing; Outsourced
   computation
ID FACE-RECOGNITION; EFFICIENT; ENCRYPTION; SECURITY; SYSTEM; SCHEME
AB In traditional biometric verification systems, personal computer stores biometric database and performs verification process. Because of limited storage, capacity, and computational power, both cloud computing and data centers provide these facilities for users and enterprises. However, shifting from user-owned and user-operated system to public and untrusted access services have raised concerns over data security, either in storage or computation phases. In this work, we propose a framework for fully privacy-preserving biometric verification with outsourcing computational tasks to the commerical public cloudsl. Firstly, privacy of the data used for biometric verification is preserved by encrypting training images. Secondly, for protecting the privacy of the biometric verification model, all correlation filter computation and verification stage are performed over encrypted biometric images in server side. Finally, privacy of the biometric verification result is preserved by sending it to the client for further investigation. Our solution provides anonymous access, unlinkability, and the confidentiality of transmitted data. I will be shown that our scheme is secure in the semi-honest server and has it reaches accuracy of 93.7% on facial dataset and 92% on fingerprint dataset.
C1 [Taheri, Motahareh; Mozaffari, Saeed; Keshavarzi, Parviz] Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Mozaffari, S (corresponding author), Semnan Univ, Fac Elect & Comp Engn, Semnan, Iran.
EM m.taheri@semnan.ac.ir; mozaffari@semnan.ac.ir; p.keshavarzi@semnan.ac.ir
RI Keshavarzi, Parviz/M-2641-2017
OI zy, P/0009-0006-2820-8788
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Acar A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3214303
   Aliasgari M, 2017, INT J INF SECUR, V16, P577, DOI 10.1007/s10207-016-0350-0
   [Anonymous], 1982, P 14 ANN ACM S THEOR, DOI DOI 10.1145/800070.802212
   Bai Y, 2014, IEEE INT CON MULTI
   Banerjee PK, 2013, OPT LASER TECHNOL, V45, P217, DOI 10.1016/j.optlastec.2012.07.001
   Benaloh J., 1994, P WORKSH SEL AR CRYP, P120
   Bianchi T, 2009, IEEE T INF FOREN SEC, V4, P86, DOI 10.1109/TIFS.2008.2011087
   Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28
   Du L, 2019, J VIS COMMUN IMAGE R, V59, P347, DOI 10.1016/j.jvcir.2019.01.027
   ELGAMAL T, 1985, IEEE T INFORM THEORY, V31, P469, DOI 10.1109/TIT.1985.1057074
   Erkin Z, 2009, LECT NOTES COMPUT SC, V5672, P235, DOI 10.1007/978-3-642-03168-7_14
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Gomez-Barrero M, 2017, PATTERN RECOGN, V67, P149, DOI 10.1016/j.patcog.2017.01.024
   Gumaei A, 2019, J PARALLEL DISTR COM, V124, P27, DOI 10.1016/j.jpdc.2018.10.005
   Hariss K, 2020, MULTIMED TOOLS APPL, V79, P12139, DOI 10.1007/s11042-019-08511-2
   Hsu CY, 2012, IEEE T IMAGE PROCESS, V21, P4593, DOI 10.1109/TIP.2012.2204272
   Kiraz MS, 2016, INT J INF SECUR, V15, P519, DOI 10.1007/s10207-015-0308-7
   Lagendijk RL, 2013, IEEE SIGNAL PROC MAG, V30, P82, DOI 10.1109/MSP.2012.2219653
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, COMM COM INF SC, V186, P122
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li C, 2016, IEEE T INF FOREN SEC, V11, P543, DOI 10.1109/TIFS.2015.2505630
   Lin KP, 2016, KNOWL INF SYST, V49, P885, DOI 10.1007/s10115-016-0923-2
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Luo LK, 2017, J VIS COMMUN IMAGE R, V43, P138, DOI 10.1016/j.jvcir.2016.12.012
   Ma J, 2019, J VIS COMMUN IMAGE R, V63, DOI 10.1016/j.jvcir.2019.102578
   MAHALANOBIS A, 1994, APPL OPTICS, V33, P3751, DOI 10.1364/AO.33.003751
   Maltoni D., 2009, HDB FINGERPRINT RECO, DOI 10.1007/978-1-84882-254-2
   Osadchy M, 2010, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2010.39
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rahulamathavan Y, 2017, IEEE T DEPEND SECURE, V14, P326, DOI 10.1109/TDSC.2015.2453963
   Rahulamathavan Y, 2014, IEEE T DEPEND SECURE, V11, P467, DOI 10.1109/TDSC.2013.51
   Rahulamathavan Y, 2014, IEEE J BIOMED HEALTH, V18, P56, DOI 10.1109/JBHI.2013.2274899
   Rathgeb C, 2015, I W BIOMETRIC FORENS
   Sadeghi AR, 2010, LECT NOTES COMPUT SC, V5984, P229
   Sandhya M, 2017, IET BIOMETRICS, V6, P173, DOI 10.1049/iet-bmt.2016.0008
   Savvides M, 2004, INT C PATT RECOG, P922, DOI 10.1109/ICPR.2004.1334679
   Shakiba A, 2019, MULTIMED TOOLS APPL, V78, P34773, DOI 10.1007/s11042-019-08071-5
   Shokri R, 2015, ANN ALLERTON CONF, P909, DOI 10.1109/ALLERTON.2015.7447103
   Sultana S.F., 2015, INT J ADV RES COMPUT, V4, P395
   Taheri M, 2018, MULTIMED TOOLS APPL, V77, P17043, DOI 10.1007/s11042-017-5275-8
   Taheri M, 2015, J OPT SOC AM A, V32, P1772, DOI 10.1364/JOSAA.32.001772
   Trivedi AK, 2020, COMPUT SECUR, V90, DOI 10.1016/j.cose.2019.101690
   Veugen Thijs, 2014, International Journal of Applied Cryptography, V3, P166, DOI 10.1504/IJACT.2014.062738
   Wang Q, 2016, INT CON DISTR COMP S, P700, DOI 10.1109/ICDCS.2016.84
   Wu HT, 2019, J VIS COMMUN IMAGE R, V62, P87, DOI 10.1016/j.jvcir.2019.04.015
   Xiang C, 2016, SOFT COMPUT, V20, P3735, DOI 10.1007/s00500-015-1759-5
   Xu GW, 2017, COMPUT SECUR, V69, P114, DOI 10.1016/j.cose.2016.11.014
   You L, 2017, CHINESE J ELECTRON, V26, P236, DOI 10.1049/cje.2017.01.009
   Zhang Y, 2015, ROBUST PRIVACY PRESE
   Zhu YW, 2016, J PARALLEL DISTR COM, V89, P1, DOI 10.1016/j.jpdc.2015.11.004
NR 59
TC 1
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21425
EP 21448
DI 10.1007/s11042-021-10648-y
EA MAR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629494100004
DA 2024-07-18
ER

PT J
AU Dai, XA
   He, XW
   Guo, SH
   Liu, SH
   Ji, FJ
   Ruan, HH
AF Dai, Xiaoai
   He, Xuwei
   Guo, Shouheng
   Liu, Senhao
   Ji, Fujiang
   Ruan, Huihua
TI Research on hyper-spectral remote sensing image classification by
   applying stacked de-noising auto-encoders neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyper-spectral image classification; Deep learning; Stacked de-noising
   auto-encoders; Deep neural network; Softmax regression
AB Hyper-spectral image can provide precise information on land surface targets identification and classification thanks to its advanced feature on spectral resolution. However, due to its complicated hyper-dimension data structure, greater challenge is put on the conventional image classification methods for hyper-spectral images. To fill this technical knowledge gap, we introduce a deep learning-based feature extraction method for hyper-spectral data classification. Firstly, we used a Stacked De-noising Auto-encoders(SDAE) to extract the in-depth features of hyper-spectral image data: a large amount of unlabeled data was pre-trained to extract the depth characteristics of pixels. We added random noise into the input layer of the network to form a de-noising auto-encoder machine and added treated inputs to reconstruct original data. An L-BFGS (Limited-memory quasi-Newton code) was used to optimize the loss function. In the top layer, deep neural network was fine-tuned by a Softmax regression classifier. All these improvements directed towards the model to obtain the image element abstraction and robust expression in the classification task of the hyper-spectral images. We tested the model performance on a Hyspex imaging spectrometer image and found that the newly introduced model framework outperforms other traditional methods including principal component analysis (PCA), and support vector machine (SVM) classifier, combined PCA-SVM classifier, and Minimum Noise Fraction Rotation (MNF)-SVM classifier.
C1 [Dai, Xiaoai; He, Xuwei; Guo, Shouheng; Liu, Senhao; Ji, Fujiang] Chengdu Univ Technol, 1 Dongsan Rd, Chengdu, Peoples R China.
   [Liu, Senhao; Ji, Fujiang] Inst Remote Sensing & Digital Earth, 20 Datun Road, Beijing, Peoples R China.
   [Liu, Senhao; Ji, Fujiang] Univ Chinese Acad Sci, 19 A Yuquan Rd, Beijing, Peoples R China.
   [Ruan, Huihua] Guangdong Meteorol Observat Data Ctr, 312 Dongguan Zhuang Rd, Guangzhou, Peoples R China.
C3 Chengdu University of Technology; Chinese Academy of Sciences; The
   Institute of Remote Sensing & Digital Earth, CAS; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Dai, XA (corresponding author), Chengdu Univ Technol, 1 Dongsan Rd, Chengdu, Peoples R China.
EM daixiaoai@163.com
RI dai, Xiaoai/KJM-0593-2024
OI dai, Xiaoai/0000-0003-1342-6417; Ji, Fujiang/0000-0003-4623-7487
FU Key Research Fund of Sichuan Provincial Department of Education
   [ZHYJ17-ZD01]; Technology Foundation for Selected Overseas Chinese
   Scholar in Sichuan Province [10900-19BZ08-014]; National Students
   Training Program for Innovation and Entrepreneurship [201810616069];
   Science and Technology Planning Project of Guangdong Province
   [2018B020207012]; Research on Key Technologies of Vegetation Ecological
   Water (layer) Remote Sensing Monitoring and Resource Retrieval in the
   Western Sichuan Plateau [KJ-2020-5]
FX This research was funded by the Key Research Fund of Sichuan Provincial
   Department of Education (No.ZHYJ17-ZD01); Technology Foundation for
   Selected Overseas Chinese Scholar in Sichuan Province
   (10900-19BZ08-014); the National Students Training Program for
   Innovation and Entrepreneurship (201810616069); the Science and
   Technology Planning Project of Guangdong Province (2018B020207012);
   Research on Key Technologies of Vegetation Ecological Water (layer)
   Remote Sensing Monitoring and Resource Retrieval in the Western Sichuan
   Plateau(KJ-2020-5).
CR Ahmad M, 2019, OPTIK, V180, P370, DOI 10.1016/j.ijleo.2018.10.142
   Ahmad M, 2017, OPTIK, V140, P86, DOI 10.1016/j.ijleo.2017.03.051
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.90
   Aydemir MS, 2017, IEEE GEOSCI REMOTE S, V14, P621, DOI 10.1109/LGRS.2017.2665679
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Byrd RH, 2016, SIAM J OPTIMIZ, V26, P1008, DOI 10.1137/140954362
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Dai X, 2018, P 37 CHIN CONTR C WU
   Hoi SCH, 2020, 2020 IEEE CVF C COMP
   Holland S.M., 2008, PRINCIPAL COMPONENTS
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Izenman A. J., 2008, SPR TEXT S, DOI DOI 10.1007/978-0-387-78189-1_8
   Kanalici E, 2019, ICGDA 2019 P 2019 2
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   Landgrebe D.A., 2003, SIGNAL THEORY METHOD, P237
   Liu QW, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103333
   Ma L, 2010, IEEE T GEOSCI REMOTE, V48, P4099, DOI 10.1109/TGRS.2010.2055876
   Ratle F, 2010, IEEE T GEOSCI REMOTE, V48, P2271, DOI 10.1109/TGRS.2009.2037898
   Tan CC, 2008, 2008 CAN C EL COMP E
   Tan G, 2017, MINE SURVEYING, V45, DOI [10.3969/j.issn.1001-358X.2017.06.013, DOI 10.3969/J.ISSN.1001-358X.2017.06.013]
   Tao C, 2015, IEEE GEOSCI REMOTE S, V12, P2438, DOI 10.1109/LGRS.2015.2482520
   Verma C, 2020, IEEE ACCESS, V8, P130840, DOI 10.1109/ACCESS.2020.3008830
   Vincent E, 2008, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.2008.4517558
   Wang Y., 2014, THESIS
   [王知音 Wang Zhiyin], 2015, [计算机应用, Journal of Computer Applications], V35, P2706
   Zhang PZ, 2016, ISPRS J PHOTOGRAMM, V116, P24, DOI 10.1016/j.isprsjprs.2016.02.013
NR 27
TC 5
Z9 5
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21219
EP 21239
DI 10.1007/s11042-021-10735-0
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629113400005
DA 2024-07-18
ER

PT J
AU Shrestha, S
   Alsadoon, A
   Prasad, PWC
   Seher, I
   Alsadoon, OH
AF Shrestha, Sushma
   Alsadoon, Abeer
   Prasad, P. W. C.
   Seher, Indra
   Alsadoon, Omar Hisham
TI A novel solution of using deep learning for prostate cancer
   segmentation: enhanced batch normalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic prostate segmentation; Deep neural network; Magnetic resonance
   (MR) images; Prostate surgery
ID NETWORK
AB Deep learning has not been successfully implemented in the past with accurate segmentation of prostate on Magnetic Resonance (MR) image in nerve sparing prostate surgery. This was mainly due to the disease-specific change in shape, boundary of gland, and complexity in separating surrounding tissues. This research aims for accurate segmentation of prostate on MR images by combining multi-level features for decreasing the processing time of the process in prostate surgery. The proposed system consists of a deep neural network that extracts high-level and low-level features of MR images, and a propagation technique that combines the extracted features thus increasing the segmentation accuracy and reducing the time required for segmentation process. Accuracy is calculated using dice similarity coefficient and performance is calculated with total execution time of the datasets. The results show improved performance with 2.11 s against 2.29 s. In addition, the overall accuracy is improved to 95.3%% against 92.76% for the MR prostate segmentation. The proposed system focuses on automating the prostate segmentation in MR images with enhanced accuracy, and thus assisting prostate surgeries and disease diagnosis. This study solves the issues related to prostate shape recognition and prostate localization and improves the segmentation accuracy and performance.
C1 [Shrestha, Sushma; Alsadoon, Abeer; Prasad, P. W. C.; Seher, Indra] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Seher, Indra] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Iraq.
   [Alsadoon, Abeer] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Iraq.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Kent Inst Australia, Informat Technol Dept, Sydney, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X; Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Abu Anas Emran Mohammad, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P365, DOI 10.1007/978-3-319-66179-7_42
   Abu Anas EM, 2018, MED IMAGE ANAL, V48, P107, DOI 10.1016/j.media.2018.05.010
   Alkadi R, 2018, J DIGIT IMAGING, P1
   [Anonymous], 2012, MICCAI GRAND CHALLEN
   Dou Q, 2017, MED IMAGE ANAL, V41, P40, DOI 10.1016/j.media.2017.05.001
   Fu YB, 2018, MED PHYS, V45, P5129, DOI 10.1002/mp.13221
   Hassanzadeh T, 2019, IEEE ACCESS, V7, P36748, DOI 10.1109/ACCESS.2019.2903284
   Jia HZ, 2018, NEUROCOMPUTING, V275, P1358, DOI 10.1016/j.neucom.2017.09.084
   Karimi D, 2018, INT J COMPUT ASS RAD, V13, P1211, DOI 10.1007/s11548-018-1785-8
   Kirschner M, 2012, INT C MED IM COMP CO, P8
   Mahapatra D, 2014, IEEE T BIO-MED ENG, V61, P756, DOI 10.1109/TBME.2013.2289306
   Mehrtash A, 2019, IEEE T MED IMAGING, V38, P1026, DOI 10.1109/TMI.2018.2876796
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   To NN, 2018, INT J COMPUT ASS RAD, V13, P1687, DOI 10.1007/s11548-018-1841-4
   Mun J, 2017, IEEE IMAGE PROC, P3859, DOI 10.1109/ICIP.2017.8297005
   Ou YDJ, 2012, MICCAI GRAND CHALLEN
   Poudel RPK, 2017, LECT NOTES COMPUT SC, V10129, P83, DOI 10.1007/978-3-319-52280-7_8
   Taghanaki SA, 2019, COMPUT MED IMAG GRAP, V75, P24, DOI 10.1016/j.compmedimag.2019.04.005
   Tian ZQ, 2017, MED PHYS, V44, P558, DOI 10.1002/mp.12048
   Trigui R, 2017, BIOMED SIGNAL PROCES, V31, P189, DOI 10.1016/j.bspc.2016.07.015
   Tsehay YK, 2017, SPIE MED IMAGING
   Wang B, 2019, MED PHYS, V46, P1707, DOI 10.1002/mp.13416
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Yan K, 2019, COMPUT METH PROG BIO, V170, P11, DOI 10.1016/j.cmpb.2018.12.031
   Yang L, 2019, MED PHYS, V46, P3195
   Yu LQ, 2017, AAAI CONF ARTIF INTE, P66
   Zabihollahy F, 2019, MED PHYS, V46, P3078, DOI 10.1002/mp.13550
   Zeng Q, 2018, INT J COMPUT ASS RAD, V13, P749, DOI 10.1007/s11548-018-1742-6
NR 28
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21293
EP 21313
DI 10.1007/s11042-021-10779-2
EA MAR 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629113400001
DA 2024-07-18
ER

PT J
AU Dutta, J
   Roy, S
AF Dutta, Joy
   Roy, Sarbani
TI IndoorSense: context based indoor pollutant prediction using SARIMAX
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor air quality; CO2; Context data; Feature engineering; Feature
   selection; Time series forecasting; SARIMAX
AB Indoor air pollutants e.g., Carbon dioxide (CO2), Particulate Matter(PM)2.5, PM10, Total Volatile Organic Compounds (TVOC), etc. have a serious impact on human health. Out of these pollutants, CO2 is one of the most dominant one. Hence, proper monitoring and control of this pollutant is an important part of maintaining a healthy indoor. To make this happen, it is required to predict the next moment's indoor pollutant level at an acceptable accuracy range that ensures necessary steps can be taken beforehand to avoid a rise in the indoor pollution level for maintaining a healthy indoor all the time. It also helps people plan ahead, decreases the adverse effects on health and the costs associated. For this experiment, we have collected three months of real-life time-series data along with proper context information and have gone through feature engineering and feature selection process to create model ready data. Now, since the indoor CO2 concentration is dependent on multiple external factors (context data) which in turn is dependent on time, makes it a time-dependent function. Hence, to predict the indoor pollutant CO2, here we have used the time series forecasting model based on our collected data nature. This is a powerful tool and used in a wide range of research domains for predicting the next moment's target value. This model ready data is utilized in forecasting different time series models. According to our findings, among the selected popular time series models, the SARIMAX time series model is best suited for this forecasting problem which is utilizing indoor context information along with historical data (with 10 Fold Time-Series Split Cross-Validation score 0.907). We have achieved an average of RMSE 26.45 ppm (i.e., 97.36% accuracy) level based on a three day average for indoor pollutant prediction which is outperforming other relevant models in this domain.
C1 [Dutta, Joy; Roy, Sarbani] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 Jadavpur University
RP Dutta, J (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, Kolkata, India.
EM joydutta.rs@jadavpuruniversity.in; sarbani.roy@jadavpuruniversity.in
RI Dutta, Joy/N-7775-2016; Roy, Sarbani/J-1997-2018
OI Dutta, Joy/0000-0003-4862-1589; Roy, Sarbani/0000-0002-7598-8266
FU Visvesvaraya PhD Scheme, Ministry of Electronics & IT, Government of
   India; project entitled "Participatory and Realtime Pollution Monitoring
   System For Smart Cit" - Higher Education, Science & Technology and
   Biotechnology, Department of Science & Technology, Government of West
   Bengal, India
FX The research work of Joy Dutta is funded by "Visvesvaraya PhD Scheme,
   Ministry of Electronics & IT, Government of India". This research work
   is also supported by the project entitled "Participatory and Realtime
   Pollution Monitoring System For Smart Cit", funded by Higher Education,
   Science & Technology and Biotechnology, Department of Science &
   Technology, Government of West Bengal, India.
CR Ahn J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112476
   Airveda, 2020, AIR QUALITY MONITORS
   [Anonymous], PMDARIMA STAT PYTHON
   [Anonymous], RESET INT STANDARD H
   Arunraj NS, 2015, INT J PROD ECON, V170, P321, DOI 10.1016/j.ijpe.2015.09.039
   Azuma K, 2018, ENVIRON INT, V121, P51, DOI 10.1016/j.envint.2018.08.059
   Bommert A, 2020, COMPUT STAT DATA AN, V143, DOI 10.1016/j.csda.2019.106839
   Candanedo LM, 2016, ENERG BUILDINGS, V112, P28, DOI 10.1016/j.enbuild.2015.11.071
   Chi HR, 2016, IEEE INTL CONF IND I, P972, DOI 10.1109/INDIN.2016.7819302
   Dutta J, 2016, IEEE SENSOR
   Dutta J, 2019, MICROSYST TECHNOL, V25, P83, DOI 10.1007/s00542-018-3936-9
   Dutta J, 2017, 18TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING (ICDCN 2017), DOI 10.1145/3007748.3018286
   Dutta J, 2017, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE AND ENGINEERING (CONFLUENCE 2017), P237, DOI 10.1109/CONFLUENCE.2017.7943156
   Elamin N, 2018, ENERGY, V165, P257, DOI 10.1016/j.energy.2018.09.157
   Jacob M., 2020, MATH PLANET EARTH
   Jovic A, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1200, DOI 10.1109/MIPRO.2015.7160458
   Khazaei B, 2019, INT J ENVIRON SCI TE, V16, P729, DOI 10.1007/s13762-018-1642-x
   Lohani Divya, 2016, 2016 17th IEEE International Conference on Mobile Data Management (MDM), P64, DOI 10.1109/MDM.2016.91
   Middya AI, 2020, MOBILE NETW APPL, V25, P1249, DOI 10.1007/s11036-020-01539-x
   Priyamvada, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INVENTIVE COMPUTING AND INFORMATICS (ICICI 2017), P405, DOI 10.1109/ICICI.2017.8365383
   Raman RK, 2018, WETL ECOL MANAG, V26, P677, DOI 10.1007/s11273-018-9600-4
   Rodero A, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11247128
   Teleszewski T, 2019, INT J ENVIRON SCI TE, V16, P8031, DOI 10.1007/s13762-019-02412-5
   Vagropoulos SI, 2016, IEEE INT ENER CONF
   Wang HJ, 2016, IEEE INT CONF CON AU, P467, DOI 10.1109/ICCA.2016.7505321
   Zhang H, 2018, APPL INTELL, V48, P3827, DOI 10.1007/s10489-018-1181-7
NR 26
TC 8
Z9 9
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19989
EP 20018
DI 10.1007/s11042-021-10666-w
EA MAR 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000625344600002
DA 2024-07-18
ER

PT J
AU Kansal, S
   Kumar, R
   Mukherjee, S
AF Kansal, Sachin
   Kumar, Rajesh
   Mukherjee, Sudipto
TI Color invariant state estimator to predict the object trajectory and
   catch using dexterous multi-fingered delta robot architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RGB sensor; Kalman predictor; Delta robots; K-means clustering; ArUco
   library; Catching; Visual tracking; Feature tracking; Calibration
ID FUSION
AB This paper proposes a design of a state estimator for tracking and predicting the object trajectory for the manipulation using a dexterous multi-fingered Delta robot. The observations of the object state acquired from the cameras (Basler), in the real-time scenario. Initially, pixels are removed that corresponds to the background pixels using a mixture of Gaussian algorithms. Secondly, the color invariant approach is implemented as a Hough transform. The same is used for the tracking of the object. This results in the color invariant thresholding to filter the region of interest. As the successive frames have some noise, morphological operations have also performed in to remove if any present outlier. After removing the noise from the frame, estimating the object center followed by velocity estimation done using the k-means clustering. Kalman predictor is used for the prediction of the future state(s) using the current state and known system dynamics. The catching strategy of the object using the Delta robot-based multi-fingered architecture is also discussed. Different trajectories and objects are provided for the catching of the object.
C1 [Kansal, Sachin; Kumar, Rajesh; Mukherjee, Sudipto] Indian Inst Technol Delhi, Dept Mech Engn, New Delhi, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Kansal, S (corresponding author), Indian Inst Technol Delhi, Dept Mech Engn, New Delhi, India.
EM sachinkansal87@gmail.com
OI Kansal, Sachin/0000-0001-9335-1253
CR Alberto T, 2014, INT J ADV ROBOT SYST, DOI [10.5772/58526, DOI 10.5772/58526]
   [Anonymous], 2005, IFAC P VOLUMES
   Ben-Ezra M, 2004, IEEE T PATTERN ANAL, V26, P689, DOI 10.1109/TPAMI.2004.1
   Bhatt B, FILTERS THEORY IMPLE
   Bonev I. A., 2001, DELTA ROBOT STORY SU
   Bruno S, 2016, INT C ROB AUT LISB
   Codourey A, 1998, INT J ROBOT RES, V17, P1325, DOI 10.1177/027836499801701205
   Davison AJ, 2005, IEEE I CONF COMP VIS, P66
   Heinz W, 2010, INT C INT ROB BRISB
   Hussain N, 2024, MULTIMED TOOLS APPL, V83, P14935, DOI 10.1007/s11042-020-08852-3
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Khan MA, 2021, MULTIMED TOOLS APPL, V80, P35827, DOI 10.1007/s11042-020-09408-1
   Kosinska A, 2003, DESIGNING OPTIMIZATI
   Laribi M. A., 2006, ANAL DIMENSIONAL SYN
   Lesniak A., 2009, Schedae Informaticae, V17, P63, DOI 10.2478/v10149-010-0004-3
   Lin HI, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020333
   Matthias N, 2008, ROBOT AUTON SYST
   Morales A, 2002, 2002 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-3, PROCEEDINGS, P1711, DOI 10.1109/IRDS.2002.1044002
   Rashid M, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12125037
   Rashid M, 2019, MULTIMED TOOLS APPL, V78, P15751, DOI 10.1007/s11042-018-7031-0
   Roy P, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P236, DOI 10.1109/ICIIP.2013.6707590
   Sachin K., 2017, NEURAL COMPUT APPL, V7, P2661
   Seungsu Kim, 2012, Robotics and Autonomous Systems, V60, P1108, DOI 10.1016/j.robot.2012.05.022
   Simon D, FILTERING UNCERTAIN
   Tsai L.-W., 1999, POSITION ANAL PARALL
   Tsai L-W, 1999, STATIC ANAL PARALLEL, P285
   Yang M, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103867
   Yun XP, 2006, IEEE T ROBOT, V22, P1216, DOI 10.1109/TRO.2006.886270
   Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362
   Zhong JQ, 2020, IEEE ACCESS, V8, P23480, DOI 10.1109/ACCESS.2020.2969994
   Zsombor-Murray PJ., 2004, Descriptive geometric kinematic analysis of clavels Delta Robot,"
   Zubair M, 2016, AS C MULT DYN ACMD 2
NR 32
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11865
EP 11886
DI 10.1007/s11042-020-09937-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RQ2GA
UT WOS:000642237200006
DA 2024-07-18
ER

PT J
AU Gholamrezaii, M
   AlModarresi, SMT
AF Gholamrezaii, Marjan
   AlModarresi, S. M. T.
TI A time-efficient convolutional neural network model in human activity
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human activity recognition; Convolutional neural network; Pooling
   layers; Smartphone sensors; Deep learning; Fast fourier transform
AB Activity recognition represents the task of classifying data derived from different sensor types into one of predefined activity classes. The most popular and beneficial sensors in the area of action recognition are inertial sensors such as accelerometer and gyroscope. Convolutional neural network (CNN) as one of the best deep learning methods has recently attracted much attention to the problem of activity recognition, where 1D kernels capture local dependency over time in a series of observations measured at inertial sensors (3-axis accelerometers and gyroscopes) while in 2D kernels apart from time dependency, dependency between signals from different axes of same sensor and also over different sensors will be considered. Most convolutional neural networks used for recognition task are built using convolution and pooling layers followed by a few number of fully connected layers but large and deep neural networks have high computational costs. In this paper, we propose a new architecture that consists solely of convolutional layers and find that with removing the pooling layers and instead adding strides to convolution layers, the computational time will decrease notably while the model performance will not change or in some cases will even improve. Also both 1D and 2D convolutional neural networks with and without pooling layer will be investigated and their performance will be compared with each other and also with some other hand-crafted feature based methods. The third point that will be discussed in this paper is the impact of applying fast fourier transform (FFT) to inputs before training learning algorithm. It will be shown that this preprocessing will enhance the model performance. Experiments on benchmark datasets demonstrate the high performance of proposed 2D CNN model with no pooling layers.
C1 [Gholamrezaii, Marjan; AlModarresi, S. M. T.] Yazd Univ, Dept Elect Engn, Pajoohesh St, Yazd, Iran.
C3 University of Yazd
RP AlModarresi, SMT (corresponding author), Yazd Univ, Dept Elect Engn, Pajoohesh St, Yazd, Iran.
EM gholamrezaii@stu.yazd.ac.ir; smta@yazd.ac.ir
OI AlModarresi, SMT/0000-0002-3852-2512
CR Alsheikh M. A., 2016, P AAAI WORKSH
   Anguita D., 2012, P INT C AMB ASS LIV
   Anguita Davide, 2013, 21 EUR S ART NEUR NE, V3
   Banos Oresti, 2014, Ambient Assisted Living and Daily Activities. 6th International Work-Conference, IWAAL 2014. Proceedings: LNCS 8868, P91, DOI 10.1007/978-3-319-13105-4_14
   Banos O, 2015, BIOMED ENG ONLINE, V14, DOI 10.1186/1475-925X-14-S2-S6
   Edel M, 2016, INT C INDOOR POSIT
   Ha S, 2016, IEEE IJCNN, P381, DOI 10.1109/IJCNN.2016.7727224
   Ha S, 2015, IEEE SYS MAN CYBERN, P3017, DOI 10.1109/SMC.2015.525
   Hammerla N.Y., 2016, P 25 INT JOINT C ART
   Ignatov A, 2018, APPL SOFT COMPUT, V62, P915, DOI 10.1016/j.asoc.2017.09.027
   Jian C, 2013, INT C BOD AR NETW
   Jiang WC, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1307, DOI 10.1145/2733373.2806333
   Jordao A, 2018, SIGNAL IMAGE VIDEO P, V12, P1387, DOI 10.1007/s11760-018-1293-x
   KHAN AM, 2013, INT J INFORM ED TECH, V3, P60, DOI DOI 10.7763/IJIET.2013.V3.234
   Kwapisz JR., 2011, ACM SIGKDD EXPLORATI, V12, P74, DOI [DOI 10.1145/1964897.1964918, 10.1145/1964897.1964918]
   Lara OD, 2013, IEEE COMMUN SURV TUT, V15, P1192, DOI 10.1109/SURV.2012.110112.00192
   Lee SM, 2017, INT CONF BIG DATA, P131, DOI 10.1109/BIGCOMP.2017.7881728
   Masum Abdul Kadar Muhammad, 2019, 2019 3rd International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1332, DOI 10.1109/ICOEI.2019.8862610
   Oukrich N, 2016, COLLOQ INF SCI TECH, P818, DOI 10.1109/CIST.2016.7805000
   Panwar M, 2017, IEEE ENG MED BIO, P2438, DOI 10.1109/EMBC.2017.8037349
   Qin Z, 2020, INFORM FUSION, V53, P80, DOI 10.1016/j.inffus.2019.06.014
   Ramasamy Ramamurthy S, 2018, WIRES DATA MIN KNOWL, V8, DOI 10.1002/widm.1254
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P56, DOI 10.1109/JBHI.2016.2633287
   Ravì D, 2016, INT CONF WEARAB IMPL, P71, DOI 10.1109/BSN.2016.7516235
   Ronao C. A., 2015, P KIISE KOR COMP C
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   San Phyo P., 2017, Big Data Analytics for Sensor-Network Collected Intelligence, P186
   Sani S., 2017, P ICCBR WORKSH
   Sharma A., 2008, P INT C CONV HYBR IN
   Springenberg J. T., 2015, WORKSH CONTR ICLR
   Vu TH, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P179, DOI 10.1145/3126686.3126764
   Wang JD, 2019, PATTERN RECOGN LETT, V119, P3, DOI 10.1016/j.patrec.2018.02.010
   Wu WM, 2012, J MED INTERNET RES, V14, DOI 10.2196/jmir.2208
   Yang JB, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3995
   Yang Z, 2018, IEEE ACCESS, V6, P56750, DOI 10.1109/ACCESS.2018.2873315
NR 35
TC 15
Z9 15
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19361
EP 19376
DI 10.1007/s11042-020-10435-1
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000622247800004
DA 2024-07-18
ER

PT J
AU Arellano-Uson, J
   Magaña, E
   Morató, D
   Izal, M
AF Arellano-Uson, Jesus
   Magana, Eduardo
   Morato, Daniel
   Izal, Mikel
TI Protocol-agnostic method for monitoring interactivity time in remote
   desktop services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote desktop; Interactivity; Response times; Services in the cloud
AB The growing trend of desktop virtualisation has facilitated the reduction of management costs associated with traditional systems and access to services from devices with different capabilities. However, desktop virtualisation requires controlling the interactivity provided by an infrastructure and the quality of experience perceived by users. This paper proposes a methodology for the quantification of interactivity based on the measurement of the time elapsed between user interactions and the associated responses. Measurement error is controlled using a novel mechanism for the detection of screen changes, which can lead to erroneous measurements. Finally, a campus virtual desktop infrastructure and the Amazon WorkSpaces solution are analysed using this proposed methodology. The results demonstrate the importance of the location of virtualisation infrastructure and the types of protocols used by remote desktop services.
C1 [Arellano-Uson, Jesus; Magana, Eduardo; Morato, Daniel; Izal, Mikel] Univ Publ Navarra, Dept Elect Elect & Commun Engn, Pamplona, Spain.
   [Magana, Eduardo; Morato, Daniel; Izal, Mikel] Inst Smart Cities, Calle Tajonar 22, Pamplona 31006, Spain.
C3 Universidad Publica de Navarra
RP Arellano-Uson, J (corresponding author), Univ Publ Navarra, Dept Elect Elect & Commun Engn, Pamplona, Spain.
EM jesus.arellano@unavarra.es; eduardo.magana@unavarra.es;
   daniel.morato@unavarra.es; mikel.izal@unavarra.es
RI Magana, Eduardo/I-2648-2015; Morato, Daniel/G-9406-2015; Izal,
   Mikel/I-2503-2015
OI Magana, Eduardo/0000-0002-6851-3414; Morato, Daniel/0000-0002-0831-4042;
   Arellano-Uson, Jesus/0000-0002-3350-3793; Izal,
   Mikel/0000-0002-2770-912X
FU Spanish State Research Agency [PID2019-104451RB-C22/AEI]
FX \This work was supported by Spanish State Research Agency, project
   number PID2019-104451RB-C22/AEI/https://doi.org/10.13039/501100011033.
CR Amazon Web Services, 2020, CISC VIS NETW IND GL
   [Anonymous], 2011, REMOTE FRAMEBUFFER P
   [Anonymous], 2003, One-Way Transmission Time
   Berryman A., 2010, Proceedings of the 2010 IEEE 2nd International Conference on Cloud Computing Technology and Science (CloudCom 2010), P480, DOI 10.1109/CloudCom.2010.106
   BUZEN JP, 1976, ACTA INFORM, V7, P167, DOI 10.1007/BF00265769
   Fidler A, 2002, DENTOMAXILLOFAC RAD, V31, P379, DOI 10.1038/sj.dmfr.4600724
   Hinden R, 1990, RFC 1151
   ITU-T, 2014, EST END TO END PERF
   ITU-T, 2002, ERR CORR PROC DCES U
   Kleinrock L, 1975, QUEUEING SYST, P172
   Kodituwakku S., 2010, Indian Journal of Computer Science and Engineering, V1, P416
   Magaña E, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0207512
   Michael R., 2012, 2012 Second International Conference on Digital Information and Communication Technology and it's Applications (DICTAP), P383, DOI 10.1109/DICTAP.2012.6215389
   Nieh J, 2003, ACM T COMPUT SYST, V21, P87, DOI 10.1145/592637.592640
   Nieh J, 2000, COMP THIN CLIENT COM, DOI [10.7916/d8z329vf, DOI 10.7916/D8Z329VF]
   Packard H, 2006, CISC VIS NETW IND GL
   Peirce J, 2019, BEHAV RES METHODS, V51, P195, DOI 10.3758/s13428-018-01193-y
   PETERSON WW, 1961, P IRE, V49, P228, DOI 10.1109/JRPROC.1961.287814
   Ngo QT, 2017, MULTIMED TOOLS APPL, V76, P22217, DOI 10.1007/s11042-017-4692-z
   Rhee J, 2009, 2009 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2009) VOLS 1 AND 2, P622, DOI 10.1109/INM.2009.5188870
   Saiz E, 2014, PROCEEDINGS OF THE 2014 ITU KALEIDOSCOPE ACADEMIC CONFERENCE: LIVING IN A CONVERGED WORLD: IMPOSSIBLE WITHOUT STANDARDS?
   Scarmana G., 2014, ISPRS ANN PHOTOGRAMM, V2, P313, DOI [10.5194/isprsannals-II-5-313-2014, DOI 10.5194/ISPRSANNALS-II-5-313-2014]
   Schatz, 2013, QUALITY EXPERIENCE R, P1352
   Su X, 2014, INT SYMP WIREL, P204, DOI 10.1109/WPMC.2014.7014817
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Yuan F, 2023, MULTIMED TOOLS APPL, V82, P11149, DOI 10.1007/s11042-019-7241-0
   Zheng HD, 2019, MULTIMED TOOLS APPL, V78, P16755, DOI 10.1007/s11042-018-7058-2
NR 27
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 13
BP 19107
EP 19135
DI 10.1007/s11042-021-10708-3
EA FEB 2021
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SG0SC
UT WOS:000621282300001
OA hybrid
DA 2024-07-18
ER

PT J
AU Mukherjee, J
   Mukherjee, J
   Chakravarty, D
   Aikat, S
AF Mukherjee, Jit
   Mukherjee, Jayanta
   Chakravarty, Debashish
   Aikat, Subhash
TI Seasonal detection of coal overburden dump regions in unsupervised
   manner using landsat 8 OLI/TIRS images at jharia coal fields
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coal mine index; Coal overburden region; Clay mineral ratio; Surface
   mining; Silhouette score; K-Means clustering
ID DIFFERENCE WATER INDEX; MINING AREAS; COVER CLASSIFICATION; MINE;
   RECLAMATION; SEPARATION; BODIES; FIRES; NDWI
AB Classification and monitoring of surface mining areas have various research challenges. Surface mining produces various land classes such as, quarry, dump, overburden dump, reclamation area, etc. In the past, various land classes of surface mining areas are detected by supervised and semi-supervised machine learning techniques. It has been found challenging to detect such land classes using only spectral responses from satellite images. Coal Mine Index (CMI) detects coal quarry and coal dump region as a single land class. These regions have distinct properties as minerals stayed open in such regions. Though coal overburden dump regions also have higher mineral content than various land classes, they show similar spectral characteristics with few bare soil classes in particular with river beds. Hence, it is found more challenging to detect coal overburden regions in an unsupervised manner using spectral information. In this paper, a K-Means clustering in hierarchical fashion has been proposed using CMI values as feature space to detect coal overburden dump regions in automated manner. Yet, this procedure detects coal overburden dump and river beds as a single class. The method is further extended to distinguish river bed regions from coal overburden regions exploiting their distinctive spectral characteristics. The proposed method has average precision and recall of [76.43%,62.75%], and [70.37%,65.63%] for coal mine, and overburden dump regions, respectively.
C1 [Mukherjee, Jit] Indian Inst Technol, Adv Technol Dev Ctr, Kharagpur, W Bengal, India.
   [Mukherjee, Jayanta; Aikat, Subhash] Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur, W Bengal, India.
   [Chakravarty, Debashish] Indian Inst Technol, Dept Min Engn, Kharagpur, W Bengal, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kharagpur; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur
RP Mukherjee, J (corresponding author), Indian Inst Technol, Adv Technol Dev Ctr, Kharagpur, W Bengal, India.
EM jit.mukherjee@iitkgp.ac.in
RI Mukherjee, Jit/AAJ-2104-2020
OI Mukherjee, Jit/0000-0001-9045-2091
CR Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah LM, 2018, APPL INTELL, V48, P4047, DOI 10.1007/s10489-018-1190-6
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2018, SPECTRAL CHARACTERIS
   [Anonymous], 2018, USING USGS LANDSAT8
   Aswatha SM, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293405
   Aswatha SM, 2017, IEEE J-STARS, V10, P1096, DOI 10.1109/JSTARS.2016.2602390
   Chen WT, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12010082
   Chen WT, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010015
   Chen WH, 2004, INT GEOSCI REMOTE SE, P3379
   Cloutis EA, 2003, FUEL, V82, P2239, DOI 10.1016/S0016-2361(03)00209-6
   Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Demirel N, 2011, INT J MIN RECLAM ENV, V25, P342, DOI 10.1080/17480930.2011.608889
   Demirel N, 2011, INT J COAL GEOL, V86, P3, DOI 10.1016/j.coal.2010.11.010
   Drury S.A., 1993, Image interpretation in geolgy.-, V2nd
   Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gao BC, 1996, REMOTE SENS ENVIRON, V58, P257, DOI 10.1016/S0034-4257(96)00067-3
   Han YX, 2007, NEW ZEAL J AGR RES, V50, P1243, DOI 10.1080/00288230709510408
   Huo HY, 2015, REMOTE SENS-BASEL, V7, P3088, DOI 10.3390/rs70303088
   Jiaxing Zhao, 2018, Computational Visual Media, V4, P333, DOI 10.1007/s41095-018-0123-y
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karan SK, 2018, GEOCARTO INT, V33, P1084, DOI 10.1080/10106049.2017.1333534
   Karan SK, 2018, INT J REMOTE SENS, V39, P84, DOI 10.1080/01431161.2017.1381355
   Karan SK, 2016, J ENVIRON MANAGE, V182, P272, DOI 10.1016/j.jenvman.2016.07.070
   Kuenzer C, 2007, APPL GEOGR, V27, P42, DOI 10.1016/j.apgeog.2006.09.007
   Li XJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060514
   Lima AT, 2016, ENVIRON SCI POLICY, V66, P227, DOI 10.1016/j.envsci.2016.07.011
   Lobo FD, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10081178
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Mezned N, 2018, J SPAT SCI, V63, P135, DOI 10.1080/14498596.2017.1345666
   Mien T, 2012, GEOSYSTEM ENG, V15, P66, DOI 10.1080/12269328.2012.674430
   Mukherjee J, 2019, LECT NOTES COMPUT SC, V11941, P397, DOI 10.1007/978-3-030-34869-4_43
   Mukherjee J, 2019, INT GEOSCI REMOTE SE, P2435, DOI [10.1109/igarss.2019.8898789, 10.1109/IGARSS.2019.8898789]
   Mukherjee J, 2019, IEEE J-STARS, V12, P2550, DOI 10.1109/JSTARS.2019.2895385
   Mukherjee J, 2019, IEEE J-STARS, V12, P891, DOI 10.1109/JSTARS.2019.2896842
   Mukherjee J, 2018, INT GEOSCI REMOTE SE, P8961, DOI 10.1109/IGARSS.2018.8517579
   Petropoulos GP, 2013, GEOCARTO INT, V28, P323, DOI 10.1080/10106049.2012.706648
   Popelková R, 2016, EUR J REMOTE SENS, V49, P973, DOI 10.5721/EuJRS20164951
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Rai Arvind Kumar, 2011, International Journal of Environmental Sciences, V1, P1350
   Raval S, 2013, T I MIN METALL A, V122, P200, DOI 10.1179/1743286313Y.0000000039
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sharad K, 2003, WATER RESOURCES SYST
   Silleos N.G., 2006, Geocarto International, V21, P21, DOI DOI 10.1080/10106040608542399
   Sinha A.K., 1986, Journal of the Indian Society of Remote Sensing, V14, P1, DOI [10.1007/BF03007217, DOI 10.1007/BF03007217]
   Sinha A.K., 1987, J INDIAN SOC REMOTE, V15, P7, DOI [10.1007/BF03017779, DOI 10.1007/BF03017779]
   Stracher GB, 2004, INT J COAL GEOL, V59, P7, DOI 10.1016/j.coal.2003.03.002
   Le TN, 2019, COMPUT VIS IMAGE UND, V184, P45, DOI 10.1016/j.cviu.2019.04.006
   Vermote E, 2016, REMOTE SENS ENVIRON, V185, P46, DOI 10.1016/j.rse.2016.04.008
   Wan Y, 2004, INT J REMOTE SENS, V25, P593, DOI 10.1080/0143116031000150112
   Wang J, 2004, INT J REMOTE SENS, V25, P3127, DOI 10.1080/0143116032000160499
   Yan Gao, 2009, Geocarto International, V24, P25, DOI 10.1080/10106040802395648
   Zeng XJ, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.015025
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhou W, 2017, INT ARCH PHOTOGRAMME, V42
NR 59
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35605
EP 35627
DI 10.1007/s11042-020-10479-3
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000620422600001
DA 2024-07-18
ER

PT J
AU Wang, X
   Bian, HX
   Qian, DL
   Miao, CS
   Zhan, SW
AF Wang, Xing
   Bian, Hao-xuan
   Qian, Dai-li
   Miao, Chun-sheng
   Zhan, Shao-wei
TI An automatic identifying method of the squall line based on Hough
   transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Squall line; Hough transform; Automatic identifying; Severe disasters;
   Weather radar
AB The squall line is a linear mesoscale convective system often seen in summer, which could bring severe disasters, such as thunderstorms, hails and tornadoes. So, the identification and forecast of squall lines are the important and difficult problems in operational weather nowcasting. In this paper, based on weather radar data an automatic identifying method of the squall line is presented. After image de-noising, extraction of the central axis of strong echo areas, and the Hough Transform, the spatial form and intensity variation characteristics of the reflectivity factors in the radar image are analyzed. On this basis, the automatic identification of squall line could be achieved. This method can overcome the adverse effects of the discontinuity of strong echo areas on the automatic identification of squall lines. The verification of squall line cases shows that the successful identification rate of squall lines is over 95%. Especially, when the boundary of the strong echo area is clear and is in a straight line or minor arc, the identification rate is higher. Overall, this new method has realized the automatic identification of squall lines on radar images, which could greatly improve the accuracy and time-effectiveness of squall line identification, and could provide a solid basis for the automatic forecast of squall lines in operational weather nowcasting.
C1 [Wang, Xing; Bian, Hao-xuan; Qian, Dai-li; Miao, Chun-sheng; Zhan, Shao-wei] Nanjing Univ Informat Sci & Technol, Natl Demonstrat Ctr Expt Atmospher Sci & Environm, Nanjing, Peoples R China.
   [Miao, Chun-sheng; Zhan, Shao-wei] Nanjing Xinda Inst Meteorol Sci & Technol, Nanjing, Peoples R China.
C3 Nanjing University of Information Science & Technology
RP Wang, X (corresponding author), Nanjing Univ Informat Sci & Technol, Natl Demonstrat Ctr Expt Atmospher Sci & Environm, Nanjing, Peoples R China.
EM wx@nuist.edu.cn
OI Xing, Wang/0000-0002-7300-9677
FU National Natural Science Foundation of China [41805033]; Jiangsu
   Province Industry-University-Research Cooperation Project of China
   [BY2018010]
FX This work is financially supported by the National Natural Science
   Foundation of China (Grand No. 41805033) and the Jiangsu Province
   Industry-University-Research Cooperation Project of China (Grand No.
   BY2018010). We would like to acknowledge the National Demonstration
   Center for Experimental Atmospheric Science and Environmental
   Meteorology Education at Nanjing University of Information Science and
   Technology for providing experimental environment and meteorological
   observations. We thank Nanjing Hurricane Translation for reviewing the
   English language quality of this paper.
CR Alajarmeh A, 2018, MULTIMED TOOLS APPL, V77, P26315, DOI 10.1007/s11042-018-5861-4
   Bala, 2019, P 2 INT C MICR COMP, DOI 10.1007/978-981-10-8234-4_11
   BLUESTEIN HB, 1987, MON WEATHER REV, V115, P2719, DOI 10.1175/1520-0493(1987)115<2719:FOMLOP>2.0.CO;2
   Bryan GH, 2006, MON WEATHER REV, V134, P2772, DOI 10.1175/MWR3226.1
   Congedo F, 2017, METEOROL APPL, V24, P338, DOI 10.1002/met.1632
   DIXON M, 1993, J ATMOS OCEAN TECH, V10, P785, DOI 10.1175/1520-0426(1993)010<0785:TTITAA>2.0.CO;2
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   GAMACHE JF, 1982, MON WEATHER REV, V110, P118, DOI 10.1175/1520-0493(1982)110<0118:MAMAWA>2.0.CO;2
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Hou, 2018, T ATMOSPHERIC SCI, DOI 10.13878/j.cnki.dqkxxb.20171021004
   Kamani MM, 2018, APPL SOFT COMPUT, V70, P1154, DOI 10.1016/j.asoc.2017.05.037
   LEAVERS VF, 1993, CVGIP-IMAG UNDERSTAN, V58, P250, DOI 10.1006/ciun.1993.1041
   Lee HY, 2007, MULTIMED TOOLS APPL, V34, P337, DOI 10.1007/s11042-007-0112-0
   [李哲 Li Zhe], 2017, [高原气象, Plateau Meteorology], V36, P801
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mafi M, 2019, SIGNAL PROCESS, V157, P236, DOI 10.1016/j.sigpro.2018.12.006
   Maki M, 2001, J APPL METEOROL, V40, P1393, DOI 10.1175/1520-0450(2001)040<1393:COTRSD>2.0.CO;2
   Noor A, 2020, MULTIMED TOOLS APPL, V79, P18553, DOI 10.1007/s11042-020-08657-4
   Oliveira FP, 2020, METEOROL APPL, V27, DOI 10.1002/met.1799
   ROTUNNO R, 1988, J ATMOS SCI, V45, P463, DOI 10.1175/1520-0469(1988)045<0463:ATFSLL>2.0.CO;2
   Schenkman AD, 2016, ATMOS RES, V170, P1, DOI 10.1016/j.atmosres.2015.11.003
   [盛杰 Sheng Jie], 2019, [气象, Meteorological Monthly], V45, P141
   Sun, 2018, THESIS LANZHOU U
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Trapp RJ, 2003, MON WEATHER REV, V131, P2804, DOI 10.1175/1520-0493(2003)131<2804:LMWSLA>2.0.CO;2
   Uckun, 2003, US Patent, Patent No. [2003 6 650,275, 20036650275]
   Wang L, 2019, J ATMOS SOL-TERR PHY, V193, DOI 10.1016/j.jastp.2019.105080
   Wilks D. S, 2011, International Geophysics Series, V100, DOI DOI 10.1002/MET.16
   [吴芳芳 Wu Fangfang], 2013, [气象学报, Acta Meteorologica Sinica], V71, P209
   [吴瑞姣 Wu Ruijiao], 2019, [气象, Meteorological Monthly], V45, P155
   Zhang Ping, 2018, JIANGXI SCI, DOI 10.13990/j.issn1001-3679.2018.01.020
NR 34
TC 1
Z9 1
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18993
EP 19009
DI 10.1007/s11042-021-10689-3
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000620109300001
DA 2024-07-18
ER

PT J
AU Kumar, NMS
   Hariprasath, K
   Tamilselvi, S
   Kavinya, A
   Kaviyavarshini, N
AF Kumar, N. M. Saravana
   Hariprasath, K.
   Tamilselvi, S.
   Kavinya, A.
   Kaviyavarshini, N.
TI Detection of stages of melanoma using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Melanoma; Deep Learning; Skin cancer; Levels of melanoma; HAM10000
ID DIAGNOSIS; PROTEIN
AB Human Skin is the most utilized and largest organs next to blood acts as an outer protective covering of the entire body to protect the underlying internal organs from harmful UV rays, dust and pollution. One of the major concerns of such harmful rays is its ability that affects the human skin by mutating the DNA sequence of melanocytes cells which in turn stimulates an uncontrollable rapid growth of infelicitous cells as undesirable peripheral protuberances and in later progressive, prolonged and well-infected stages, it starts to grew inwards as well and reports majority of the deaths due to a skin cancer across the world. The premature detection of the melanoma enables the complete cure of the cancer and it significantly drags down the death rate. Though many research works concentrated on detecting the melanoma, this work narrow down the scope in finding the levels of skin carcinoma by using deep learning methodologies that boosts the accuracy in the detection of melanoma and can give an appropriate treatment with respect to the level of the cancer. In this work, state-of-art techniques like Random Forest, Support Vector Machine, Artificial Neural network along with the proposed fusion-based Deep learning methodology has been experimented. Various performance metric such as Mean Square Error, Peak Signal to Noise ratio for assessing the quality of the pre-processing strategy and Accuracy, Precision and Recall for evaluating the proposed methodology. With the experimental results, it is evident that the Deep learning using the feature-fusion methodology has the accuracy of 97% than other state-of-art techniques. On comparing with recent works done using same methodology, the proposed work has 11% more accuracy than the existing well-known works.
C1 [Kumar, N. M. Saravana] M Kumarasamy Coll Engn, Dept Comp Sci & Engn, Karur, India.
   [Hariprasath, K.; Kavinya, A.; Kaviyavarshini, N.] Vivekanandha Coll Engn Women, Dept Informat Technol, Namakkal, India.
   [Tamilselvi, S.] Bannari Amman Inst Technol, Dept Biotechnol, Erode, India.
C3 M.Kumarasamy College of Engineering; Bannari Amman Institute of
   Technology
RP Kumar, NMS (corresponding author), M Kumarasamy Coll Engn, Dept Comp Sci & Engn, Karur, India.
EM saravanakumaar2008@gmail.com; khariprasathit@gmail.com;
   tamilselvis@bitsathy.ac.in; kavinyasre21@gmail.com;
   kaviyanaagarrajan97@gmail.com
RI Prince dr k Vasudevan college of engineering, Prince dr k Vasudevan
   college of engineering/JFB-2865-2023; Kumar, N M Saravana/AAD-8116-2019
OI Saravana Kumar, N.M./0000-0002-6017-5115; K,
   Hariprasath/0000-0003-1590-0725
CR Adegun AA, 2020, IEEE ACCESS, V8, P7160, DOI 10.1109/ACCESS.2019.2962812
   Alheejawi S, 2019, COMPUT MED IMAG GRAP, V73, P19, DOI 10.1016/j.compmedimag.2019.01.006
   Alsafy, 2017, INT J INTERACTIVE MU
   [Anonymous], REPORT WORLD CANC RE
   Ardakani, 2019, EARLY STAGE DETECTIO
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bánkfalvi A, 2000, HISTOPATHOLOGY, V37, P411, DOI 10.1046/j.1365-2559.2000.00984.x
   Bhati P, 2015, 2015 COMMUNICATION, CONTROL AND INTELLIGENT SYSTEMS (CCIS), P181, DOI 10.1109/CCIntelS.2015.7437904
   BRUNO S, 1992, CELL PROLIFERAT, V25, P31, DOI 10.1111/j.1365-2184.1992.tb01435.x
   Gayathiri, 2017, INT RES J ENG TECHNO, V4, P1301
   Hasayen, 2017, APPL ELECT ENG COMPU
   Pham HN, 2019, INT CONF SYST SCI EN, P142, DOI [10.1109/ICSSE.2019.8823129, 10.1109/icsse.2019.8823129]
   Jha N, 2019, IEEE CAN C EL COMP E
   Khan MQ, 2019, IEEE ACCESS, V7, P90132, DOI 10.1109/ACCESS.2019.2926837
   Mungle T, 2017, COMPUT METH PROG BIO, V139, P149, DOI 10.1016/j.cmpb.2016.11.002
   Murugan A, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1400-8
   Nandhini S, 2019, SKIN CANC CLASSIFICA, V4, P39
   Okur E, 2018, ENG APPL ARTIF INTEL, V73, P50, DOI 10.1016/j.engappai.2018.04.028
   Pérez-Ortiz M, 2016, IEEE IJCNN, P2156, DOI 10.1109/IJCNN.2016.7727466
   Reshma M, 2017, 2017 CONFERENCE ON EMERGING DEVICES AND SMART SYSTEMS (ICEDSS), P257, DOI 10.1109/ICEDSS.2017.8073689
   Satheesha TY, 2014, 2014 INTERNATIONAL CONFERENCE ON CIRCUITS, COMMUNICATION, CONTROL AND COMPUTING (I4C), P387, DOI 10.1109/CIMCA.2014.7057829
   Shalu, 2018, 2018 FIRST INTERNATIONAL CONFERENCE ON SECURE CYBER COMPUTING AND COMMUNICATIONS (ICSCCC 2018), P508, DOI 10.1109/ICSCCC.2018.8703309
   Siegel RL, 2019, CA-CANCER J CLIN, V69, P7, DOI 10.3322/caac.21551
   Singh S, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, POWER AND COMMUNICATION TECHNOLOGIES (GUCON), P472, DOI 10.1109/GUCON.2018.8675085
   Talati, 2019, AUTOMATED MELANOMA T
   Wang YH, 2009, IEEE J-STSP, V3, P112, DOI 10.1109/JSTSP.2008.2011157
NR 26
TC 11
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18677
EP 18692
DI 10.1007/s11042-021-10572-1
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619738400004
DA 2024-07-18
ER

PT J
AU Ma, X
   Yan, WQ
AF Ma, Xin
   Yan, Wei Qi
TI Banknote serial number recognition using deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Serial numbers of banknotes; Data augmentation; SegLink; CRNN; Attention
   model
ID IMAGES
AB In this paper, we recognize serial numbers on banknotes using deep learning. The samples used in this paper are digital images which have been preprocessed with data labelling and data augmentation, e.g., scaling transformation, etc. The algorithms based on deep learning are proposed and have the stability for serial number recognition with complex backgrounds. In this paper, a pipeline of deep neural networks is established for the recognition of banknote serial numbers. Because high reliability is more important than accuracy in financial applications, DenseNet is set forth as the primary classifier, the scaling transformation of SegLink is put forward to locate the characters, the detection rate is up to 95.80%. A convolutional neural network with residual attention model is proposed for serial number recognition, the precision is up to 97.09%.
C1 [Ma, Xin; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM dcsyanwq@gmail.com
CR Arlot S, 2010, STAT SURV, V4, P40, DOI 10.1214/09-SS054
   Athiwaratkun B, 2017, INT CONF ACOUST SPEE, P2482, DOI 10.1109/ICASSP.2017.7952603
   Ban SW, 2008, NEUROCOMPUTING, V71, P853, DOI 10.1016/j.neucom.2007.03.003
   Bissacco A, 2013, IEEE I CONF COMP VIS, P785, DOI 10.1109/ICCV.2013.102
   Chowdhury MA, 2013, INT J COMPUT APPL, V74, P18
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Defferrard M, 2016, ADV NEUR IN, V29
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Gao YZ, 2019, NEUROCOMPUTING, V339, P161, DOI 10.1016/j.neucom.2019.01.094
   Ghadhban HQ, 2020, ADV INTELL SYST COMP, V978, P358, DOI 10.1007/978-3-030-36056-6_34
   Guan JT, 2020, NEUROCOMPUTING, V377, P301, DOI 10.1016/j.neucom.2019.10.054
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Jayadevan R, 2012, INT J DOC ANAL RECOG, V15, P267, DOI 10.1007/s10032-011-0170-8
   Khomenko V, 2016, PROCEEDINGS OF THE 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA STREAM MINING & PROCESSING (DSMP), P100, DOI 10.1109/DSMP.2016.7583516
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Son LH, 2019, IEEE ACCESS, V7, P23319, DOI 10.1109/ACCESS.2019.2899260
   Lee CY, 2016, PROC CVPR IEEE, P2231, DOI 10.1109/CVPR.2016.245
   Li J., 2012, Advances in Computer Science and Information Engineering. Advances in Intelligent and Soft Computing, V169
   Li YT, 2020, ACM T SENSOR NETWORK, V16, DOI 10.1145/3397179
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Liang S, 2018, GENES-BASEL, V9, DOI 10.3390/genes9080382
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mahmood H, 2020, THESIS LOUGHBOROUGH
   Mohamad N.S., 2014, INT S RES INNOVATION, V26, P1865
   Mu RH, 2019, KSII T INTERNET INF, V13, P1738, DOI 10.3837/tiis.2019.04.001
   Nweke HF, 2018, EXPERT SYST APPL, V105, P233, DOI 10.1016/j.eswa.2018.03.056
   Peddinti V, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3214
   Peters GW, 2016, NEW ECON WINDOWS, P239, DOI 10.1007/978-3-319-42448-4_13
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ryan M, 2015, PROCEDIA COMPUT SCI, V59, P520, DOI 10.1016/j.procs.2015.07.534
   Schroth G., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P77, DOI 10.1109/ISM.2011.21
   Schulz R, 2015, IEEE INT CONF ROBOT, P1100, DOI 10.1109/ICRA.2015.7139313
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Sufri NAJ, 2019, 2019 IEEE 10TH CONTROL AND SYSTEM GRADUATE RESEARCH COLLOQUIUM (ICSGRC), P5, DOI [10.1109/icsgrc.2019.8837068, 10.1109/ICSGRC.2019.8837068]
   Tao CY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4418
   Tay FEH, 2001, OMEGA-INT J MANAGE S, V29, P309, DOI 10.1016/S0305-0483(01)00026-3
   Ting-ting Zhao, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1951, DOI 10.1109/CISP.2010.5648046
   Tran A, 2017, IEEE INT CONF COMP V, P3110, DOI 10.1109/ICCVW.2017.368
   Vaswani A, 2017, ADV NEUR IN, V30
   Wilfer K., 2015, U.S. Patent, Patent No. [9,123,192, 9123192]
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Yan HK, 2020, INT CONF ACOUST SPEE, P7489, DOI [10.1109/icassp40776.2020.9054618, 10.1109/ICASSP40776.2020.9054618]
   Yan WQ, 2019, INTRO INTELLIGENT SU, P9
   Zhang Q., 2019, J BANK FINANC TECHNO, V3, P59, DOI DOI 10.1007/S42786-018-00007-1
   Zhang Q, 2018, COMPLEXITY, DOI 10.1155/2018/9528313
   Zhang Z, 2015, PROC CVPR IEEE, P2558, DOI 10.1109/CVPR.2015.7298871
   Zhao J, 2018, INT C EMP METH NAT L
   Zhu YY, 2016, FRONT COMPUT SCI-CHI, V10, P19, DOI 10.1007/s11704-015-4488-0
NR 53
TC 0
Z9 0
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18445
EP 18459
DI 10.1007/s11042-020-10461-z
EA FEB 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619425300011
DA 2024-07-18
ER

PT J
AU Li, JX
   Han, LX
   Li, XS
   Zhu, J
   Yuan, BH
   Gou, ZN
AF Li, Jingxian
   Han, Lixin
   Li, Xiaoshuang
   Zhu, Jun
   Yuan, Baohua
   Gou, Zhinan
TI An evaluation of deep neural network models for music classification
   using spectrograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DNN models; Deep learning; Transfer learning; Music classification;
   Spectrograms
ID GENRE CLASSIFICATION; ARCHITECTURES
AB Deep Neural Network (DNN) models have lately received considerable attention for that the network structure can extract deep features to improve classification accuracy and achieve excellent results in the field of image. However, due to the different content forms of music and images, transferring deep learning to music classification is still a problem. To address this issue, in the paper, we transfer the state-of-the-art DNN models to music classification and evaluate the performance of the models using spectrograms. Firstly, we convert the music audio files into spectrograms by modal transformation, and then classify music through deep learning. In order to alleviate the problem of overfitting during training, we propose a balanced trusted loss function and build the balanced trusted model ResNet50_trust. Finally, we compare the performance of different DNN models in music classification. Furthermore, this work adds music sentiment analysis based on the newly constructed music emotion dataset. Extensive experimental evaluations on three music datasets show that our proposed model Resnet50_trust consistently outperforms other DNN models.
C1 [Li, Jingxian; Han, Lixin; Li, Xiaoshuang; Zhu, Jun] Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
   [Li, Jingxian] Jinling Inst Technol, Sch Software Engn, Nanjing, Peoples R China.
   [Yuan, Baohua] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Gou, Zhinan] Hebei Univ Econ & Business, Coll Informat Technol, Shijiazhuang, Hebei, Peoples R China.
C3 Hohai University; Jinling Institute of Technology; City University of
   Hong Kong; Hebei University of Economics & Business
RP Han, LX (corresponding author), Hohai Univ, Sch Comp & Informat, Nanjing, Peoples R China.
EM lixinhan2002@aliyun.com
OI Li, Jingxian/0000-0002-2450-6052; Yuan, Baohua/0000-0001-9694-9250
FU Natural Science Foundation of the Colleges and Universities in Anhui
   Province of China [KJ2020A0035]; Scientific Research Project of Hebei
   Education Department of China [QN2020198]
FX This work was supported in part by the Natural Science Foundation of the
   Colleges and Universities in Anhui Province of China under Grant
   No.KJ2020A0035; and in part by the Scientific Research Project of Hebei
   Education Department of China under Grant No.QN2020198.
CR Aguiar RL, 2016, 35 INT C CHIL COMP S, P1
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Chaurasiya H, 2020, PROCEDIA COMPUT SCI, V167, P1901, DOI 10.1016/j.procs.2020.03.209
   Choi Keunwoo, 2016, ARXIV160600298, DOI 10.5281/zenodo.1416254
   Costa YMG, 2017, APPL SOFT COMPUT, V52, P28, DOI 10.1016/j.asoc.2016.12.024
   Defferrard Michael, 2016, ADV NEURAL INFORM PR, P3837, DOI DOI 10.5555/3157382.3157527
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   Glauner PO, 2015, COMPUT SCI
   Gulli A., 2017, Deep learning with Keras
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Khunarsal P, 2013, INFORM SCIENCES, V243, P57, DOI 10.1016/j.ins.2013.04.014
   Kim T, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P366, DOI 10.1109/ICASSP.2018.8462046
   Kingma D. P., 2014, arXiv
   Kobayashi T, 2018, IEEE INT SYM MULTIM, P180, DOI 10.1109/ISM.2018.00-15
   Kong Q, 2014, P INT SOC MUS INF RE
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lidy T, 2016, MIREX2016
   Liu X, 2017, Deep Recurrent Neural Network for Protein Function Prediction from Sequence, DOI [DOI 10.1101/103994, 10.1101/103994]
   Ma X, 2018, INTERSPEECH, P3683, DOI 10.21437/Interspeech.2018-2228
   McKinney M.F., 2003, Proc. ISMIR, V3, P151
   Nam J, 2019, IEEE SIGNAL PROC MAG, V36, P41, DOI 10.1109/MSP.2018.2874383
   Panagakis Yannis, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P1, DOI 10.1109/PS.2009.5307817
   Papakostas M, 2018, EXPERT SYST APPL, V114, P334, DOI 10.1016/j.eswa.2018.05.016
   Pons J, 2019, INT CONF ACOUST SPEE, P336, DOI 10.1109/ICASSP.2019.8682912
   Ferrolino AR, 2019, AIP CONF PROC, V2192, DOI 10.1063/1.5139154
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Satt A, 2017, INTERSPEECH, P1089, DOI 10.21437/Interspeech.2017-200
   Simonyan K., 2014, CORR
   Song GX, 2018, NEUROCOMPUTING, V292, P104, DOI 10.1016/j.neucom.2018.02.076
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Valerio V D, 2018, 31 INT FLAIRS C
   Zhang WB, 2016, INTERSPEECH, P3304, DOI 10.21437/Interspeech.2016-1236
   Zhou ZH, 2019, NATL SCI REV, V6, P74, DOI 10.1093/nsr/nwy108
   Zoph B, 2016, P 2016 C N AM CHAPTE
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 39
TC 17
Z9 18
U1 5
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2022
VL 81
IS 4
BP 4621
EP 4647
DI 10.1007/s11042-020-10465-9
EA FEB 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZF7SH
UT WOS:000616467500001
OA Bronze
DA 2024-07-18
ER

PT J
AU Mittal, H
   Pandey, AC
   Saraswat, M
   Kumar, S
   Pal, R
   Modwel, G
AF Mittal, Himanshu
   Pandey, Avinash Chandra
   Saraswat, Mukesh
   Kumar, Sumit
   Pal, Raju
   Modwel, Garv
TI A comprehensive survey of image segmentation: clustering methods,
   performance parameters, and benchmark datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Clustering methods; Performance parameters;
   Benchmark datasets
ID PARTICLE SWARM OPTIMIZATION; GENETIC ALGORITHM; 2D HISTOGRAM; K-MEANS
AB Image segmentation is an essential phase of computer vision in which useful information is extracted from an image that can range from finding objects while moving across a room to detect abnormalities in a medical image. As image pixels are generally unlabelled, the commonly used approach for the same is clustering. This paper reviews various existing clustering based image segmentation methods. Two main clustering methods have been surveyed, namely hierarchical and partitional based clustering methods. As partitional clustering is computationally better, further study is done in the perspective of methods belonging to this class. Further, literature bifurcates the partitional based clustering methods into three categories, namely K-means based methods, histogram-based methods, and meta-heuristic based methods. The survey of various performance parameters for the quantitative evaluation of segmentation results is also included. Further, the publicly available benchmark datasets for image-segmentation are briefed.
C1 [Mittal, Himanshu; Pandey, Avinash Chandra; Saraswat, Mukesh; Pal, Raju] Jaypee Inst Informat Technol, Noida, Uttar Pradesh, India.
   [Kumar, Sumit] Amity Univ, Noida, Uttar Pradesh, India.
   [Modwel, Garv] Valeo India Private Ltd, Chennai, Tamil Nadu, India.
C3 Jaypee Institute of Information Technology (JIIT); Amity University
   Noida
RP Pal, R (corresponding author), Jaypee Inst Informat Technol, Noida, Uttar Pradesh, India.
EM raju3131.pal@gmail.com
RI Kumar, Sumit/HHS-8959-2022; Pandey, Avinash Chandra/AAN-1729-2020;
   kumar, sumit/AAZ-5668-2021; Pal, Raju/AAC-2589-2020
OI Pandey, Avinash Chandra/0000-0002-0487-6742; kumar,
   sumit/0000-0002-0205-8412; Pal, Raju/0000-0001-5715-5204
CR ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Agustín-Blas LE, 2012, EXPERT SYST APPL, V39, P9695, DOI 10.1016/j.eswa.2012.02.149
   Amhaz R, 2020, AUTOMATIC CRACK DETE
   [Anonymous], 2020, **DROPPED REF**
   [Anonymous], 2020, JUNQIANGCHEN LITS LI
   [Anonymous], 2020, BERKELEY SEGMENTATIO
   [Anonymous], 2020, ABERYSTWYTH LEAF EVA
   [Anonymous], 2020, SEGMENTATION EVALUAT
   [Anonymous], 2020, SKY DATASET
   [Anonymous], 2020, BRAIN MRI SEGMENTATI
   [Anonymous], 2020, COVID 19 MEDICAL SEG
   [Anonymous], 2020, UC BERKELEY COMPUTER
   [Anonymous], 2018, CS231n: Convolutional Neural Networks for Visual Recognition
   [Anonymous], 2020, ICG 3DPITOTIDATASET
   [Anonymous], 2000, P KDD WORKSHOP TEXT
   [Anonymous], 2020, EVIMO MOTION SEGMENT
   [Anonymous], 2020, DATA MASTER NICOLA S
   [Anonymous], 2020, USE CASE 1 NUCLEI SE
   [Anonymous], 2011, ENCY MACHINE LEARNIN
   [Anonymous], 2020, ROADMARKING
   [Anonymous], 2020, USE CASE 2 EPITHELIU
   [Anonymous], 2020, ADE20K DATASET
   [Anonymous], 2020, DAIMLER PEDESTRIAN S
   [Anonymous], 2020, CVONLINE IMAGE DATAB
   [Anonymous], 2020, CAD 120 AFFORDANCE D
   [Anonymous], 2020, COIFT
   Arnold DV, 2002, IEEE T EVOLUT COMPUT, V6, P30, DOI 10.1023/A:1015059928466
   BABU GP, 1994, PATTERN RECOGN, V27, P321, DOI 10.1016/0031-3203(94)90063-9
   Bansal J C, 2011, 3 WORLD C NAT BIOL I, P633, DOI [10.1109/NaBIC.2011.6089659, DOI 10.1109/NABIC.2011.6089659]
   Bansal JC, 2014, MEMET COMPUT, V6, P31, DOI 10.1007/s12293-013-0128-0
   Bezdek J. C., 1994, Proceedings of the First IEEE Conference on Evolutionary Computation. IEEE World Congress on Computational Intelligence (Cat. No.94TH0650-2), P34, DOI 10.1109/ICEC.1994.350046
   Bezdek J.C., 1973, Cluster validity with fuzzy sets, P58
   Bhaduri A, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P517, DOI 10.1109/ARTCom.2009.115
   Bin Zhang, 2001, Temporal, Spatial, and Spatio-Temporal Data Mining. First International Workshop, TSDM 2000. Revised Papers (Lecture Notes in Artificial Intelligence Vol.2007), P31
   Bouguettaya A, 2015, EXPERT SYST APPL, V42, P2785, DOI 10.1016/j.eswa.2014.09.054
   Chaturvedi A, 2001, J CLASSIF, V18, P35, DOI 10.1007/s00357-001-0004-3
   Chavent M, 2007, COMPUT STAT DATA AN, V52, P687, DOI 10.1016/j.csda.2007.03.013
   Chowdhury A, 2011, LECT NOTES COMPUT SC, V7077, P105, DOI 10.1007/978-3-642-27242-4_13
   Chuang LY, 2011, EXPERT SYST APPL, V38, P14555, DOI 10.1016/j.eswa.2011.05.027
   Dasgupta D., 2013, EVOLUTIONARY ALGORIT
   DAVE RN, 1992, IEEE T NEURAL NETWOR, V3, P643, DOI 10.1109/72.159055
   Dhillon I. S., 2003, Journal of Machine Learning Research, V3, P1265, DOI 10.1162/153244303322753661
   Dorigo M, 2005, THEOR COMPUT SCI, V344, P243, DOI 10.1016/j.tcs.2005.05.020
   GUENOCHE A, 1991, J CLASSIF, V8, P5, DOI 10.1007/BF02616245
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Hatamlou A, 2012, SWARM EVOL COMPUT, V6, P47, DOI 10.1016/j.swevo.2012.02.003
   Huang KY, 2011, KNOWL-BASED SYST, V24, P420, DOI 10.1016/j.knosys.2010.12.003
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jiao LC, 2010, IEEE COMPUT INTELL M, V5, P78, DOI 10.1109/MCI.2010.936307
   José-García A, 2016, APPL SOFT COMPUT, V41, P192, DOI 10.1016/j.asoc.2015.12.001
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Langham AE, 1999, LECT NOTES ARTIF INT, V1674, P621
   Lin WY, 2012, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2012.6247651
   Liu T, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 2, PROCEEDINGS, P347, DOI 10.1109/FSKD.2008.67
   Lu ZW, 2011, PATTERN RECOGN LETT, V32, P1956, DOI 10.1016/j.patrec.2011.09.022
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5
   Mittal H, 2021, MULTIMED TOOLS APPL, V80, P7581, DOI 10.1007/s11042-020-09831-4
   Mittal H, 2019, SWARM EVOL COMPUT, V45, P15, DOI 10.1016/j.swevo.2018.12.005
   Mittal H, 2018, ENG APPL ARTIF INTEL, V71, P226, DOI 10.1016/j.engappai.2018.03.001
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   Pal R, 2020, COMPLEX INTELL SYST, V6, P391, DOI 10.1007/s40747-020-00137-4
   Pal R, 2019, APPL INTELL, V49, P3406, DOI 10.1007/s10489-019-01460-1
   Pandey AC, 2020, J AMB INTEL HUM COMP, V11, P719, DOI 10.1007/s12652-019-01330-1
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Phillips SJ, 2002, LECT NOTES COMPUT SC, V2409, P166
   Saraswat M, 2020, IEEE T FUZZY SYST
   Saraswat M, 2013, SWARM EVOL COMPUT, V11, P46, DOI 10.1016/j.swevo.2013.02.003
   Sarkar S, 2013, IEEE T IMAGE PROCESS, V22, P4788, DOI 10.1109/TIP.2013.2277832
   Saxena A, 2017, NEUROCOMPUTING, V267, P664, DOI 10.1016/j.neucom.2017.06.053
   SEIFODDINI HK, 1989, COMPUT IND ENG, V16, P419, DOI 10.1016/0360-8352(89)90160-5
   SELIM SZ, 1991, PATTERN RECOGN, V24, P1003, DOI 10.1016/0031-3203(91)90097-O
   Sheng WG, 2004, IEEE C EVOL COMPUTAT, P77, DOI 10.1109/CEC.2004.1330840
   Sun Feng-jie, 2010, Proceedings 2010 International Conference on Computational and Information Sciences (ICCIS 2010), P677, DOI 10.1109/ICCIS.2010.343
   Tripathi AK, 2020, IEEE T INDUST INFORM
   Tripathi AK, 2018, BIG DATA RES, V14, P93, DOI 10.1016/j.bdr.2018.05.002
   Tsai CY, 2011, EXPERT SYST APPL, V38, P6565, DOI 10.1016/j.eswa.2010.11.082
   van der Merwe D, 2003, IEEE C EVOL COMPUTAT, P215, DOI 10.1109/CEC.2003.1299577
   Wan M, 2012, J INTELL INF SYST, V38, P321, DOI 10.1007/s10844-011-0158-3
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xu D., 2015, Annals of Data Science, V2, P165, DOI [DOI 10.1007/S40745-015-0040-1, 10.1007/s40745-015-0040-1]
   Xu R, 2010, IEEE C EVOL COMPUTAT
   Xue-guang W., 2012, INF SCI LETT, V1, P77, DOI [10.12785/isl/010202, DOI 10.12785/ISL/010202]
   YAGER RR, 1994, IEEE T SYST MAN CYB, V24, P1279, DOI 10.1109/21.299710
   Yang FQ, 2009, EXPERT SYST APPL, V36, P9847, DOI 10.1016/j.eswa.2009.02.003
   Yang XS, 2010, INT J BIO-INSPIR COM, V2, P78, DOI 10.1504/IJBIC.2010.032124
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   Zhang Y, 2011, EXPERT SYST APPL, V38, P9036, DOI 10.1016/j.eswa.2011.01.041
   Zou WP, 2010, DISCRETE DYN NAT SOC, V2010, DOI 10.1155/2010/459796
NR 93
TC 54
Z9 56
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 24
BP 35001
EP 35026
DI 10.1007/s11042-021-10594-9
EA FEB 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4V0CE
UT WOS:000616467500004
PM 33584121
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Liu, Y
   Lu, QH
   Zhu, CS
   Yu, QY
AF Liu, Yue
   Lu, Qinghua
   Zhu, Chunsheng
   Yu, Qiuyu
TI A blockchain-based platform architecture for multimedia data management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Multimedia; Data management; Access control; Architecture;
   Self-sovereign identity
AB Massive amounts of multimedia data (i.e., text, audio, video, graphics and animation) are being generated everyday. Conventionally, multimedia data are managed by the platforms maintained by multimedia service providers, which are generally designed using centralised architecture. However, such centralised architecture may lead to a single point of failure and disputes over royalties or other rights. It is hard to ensure the data integrity and track fulfilment of obligations listed on the copyright agreement. To tackle these issues, in this paper, we present a blockchain-based platform architecture for multimedia data management. We adopt self-sovereign identity for identity management and design a multi-level capability-based mechanism for access control. We implement a proof-of-concept prototype using the proposed approach and evaluate it using a use case. The results show that the proposed approach is feasible and has scalable performance.
C1 [Liu, Yue] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
   [Liu, Yue; Lu, Qinghua] CSIRO, Data61, Sydney, NSW, Australia.
   [Zhu, Chunsheng] Southern Univ Sci & Technol, SUSTech Inst Future Networks, Shenzhen, Peoples R China.
   [Zhu, Chunsheng] Peng Cheng Lab, PCL Res Ctr Networks & Commun, Shenzhen, Peoples R China.
   [Yu, Qiuyu] China Univ Petr East China, Coll Comp Sci & Technol, Qingdao, Peoples R China.
C3 University of New South Wales Sydney; Commonwealth Scientific &
   Industrial Research Organisation (CSIRO); Southern University of Science
   & Technology; Peng Cheng Laboratory; China University of Petroleum
RP Zhu, CS (corresponding author), Southern Univ Sci & Technol, SUSTech Inst Future Networks, Shenzhen, Peoples R China.; Zhu, CS (corresponding author), Peng Cheng Lab, PCL Res Ctr Networks & Commun, Shenzhen, Peoples R China.
EM chunsheng.tom.zhu@gmail.com
RI Lu, Qinghua/AAG-3378-2021
OI Liu, Yue/0000-0003-2958-9923
FU National Key R&D Program of China [2020YFB2104301, LZC0019]
FX This work is partially supported by the National Key R&D Program of
   China (2020YFB2104301), and the project "PCL Future Greater-Bay Area
   Network Facilities for Large-scale Experiments and Applications
   (LZC0019)".
CR Aitzhan NZ, 2018, IEEE T DEPEND SECURE, V15, P840, DOI 10.1109/TDSC.2016.2616861
   [Anonymous], CHRISTOPHER ALLEN PA
   Avizienis A, 2004, IEEE T DEPEND SECURE, V1, P11, DOI 10.1109/TDSC.2004.2
   Bhowmik D, 2017, INT CONF DIGIT SIG
   Copyright law of people's republic of china, 2016, COPYRIGHT LAW PEOPLE
   Dabrowski M., 2008, 2008 Second International Conference on Emerging Security Information, Systems and Technologies (SECUREWARE), P232, DOI 10.1109/SECURWARE.2008.18
   Guo JQ, 2020, MULTIMED TOOLS APPL, V79, P9735, DOI 10.1007/s11042-019-08059-1
   Kshetri N, 2018, IEEE SOFTWARE, V35, P95, DOI 10.1109/MS.2018.2801546
   Laplante PA, 2018, IT PROF, V20, P15, DOI 10.1109/MITP.2018.032501742
   Lee D, 2021, MULTIMED TOOLS APPL, V80, P34517, DOI 10.1007/s11042-020-08776-y
   Liu Y, 2020, IEEE SOFTWARE, V37, P30, DOI 10.1109/MS.2020.2992783
   Lu QH, 2019, FUTURE GENER COMP SY, V101, P564, DOI 10.1016/j.future.2019.05.051
   Lu QH, 2017, IEEE SOFTWARE, V34, P21, DOI 10.1109/MS.2017.4121227
   Meadows A, NETFIX USERS COLLECT
   Modinis IDM, 2005, 2005 MODINIS IDM STU
   Nakamoto S., 2008, DECENTRAL BUS REV
   Omohundro Steve., 2014, AI MATTERS, V1, P19, DOI [10.1145/2685328.2685334, DOI 10.1145/2685328.2685334]
   Rathee G, 2020, MULTIMED TOOLS APPL, V79, P9711, DOI 10.1007/s11042-019-07835-3
   Reed D, Draft Community Group Report
   Tschorsch F, 2016, IEEE COMMUN SURV TUT, V18, P2084, DOI 10.1109/COMST.2016.2535718
   Vishwa A, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1941, DOI 10.1109/SSCI.2018.8628636
   Xu XL, 2020, MULTIMED TOOLS APPL, V79, P9819, DOI 10.1007/s11042-019-07900-x
   Xu XW, 2019, FUTURE GENER COMP SY, V92, P399, DOI 10.1016/j.future.2018.10.010
   Zhang Peng., 2017, Proceedings of the ACM on Human-Computer Interaction, V1, P1
NR 24
TC 9
Z9 9
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30707
EP 30723
DI 10.1007/s11042-021-10558-z
EA FEB 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000613628000004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mor, B
   Garhwal, S
   Kumar, A
AF Mor, Bhavya
   Garhwal, Sunita
   Kumar, Ajay
TI MIMVOGUE: modeling Indian music using a variable order gapped HMM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE VOUGE; Hidden Markov model; Sequence mining; Raga; Bandish; Musical note
   sequences
AB The computer-assisted music composition is an active research area since mid-1900. In this paper, we have applied the VOGUE model for designing musical sequence of bandish notations of raga Bhairav, a classical Indian music. Variable Order and Gapped hidden Markov model for unstructured elements can capture variable length dependencies with variable gaps in sequential data. In most of raga pattern, a particular pattern repeats itself which may be separated by variable length gaps. VOGUE mines the frequent patterns in raga having different length gaps. These mined patterns are used to model VOGUE for Indian music ragas. Furthermore, we analyzed the benefits of VOGUE model over the standard HMM. To the best of author's knowledge, this is the very first attempt to model Indian classical music with variable order gapped HMM.
C1 [Mor, Bhavya; Garhwal, Sunita; Kumar, Ajay] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kumar, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM ajayloura@gmail.com
RI kumar, ajay/G-1509-2014
OI kumar, ajay/0000-0002-4452-4725; Garhwal, Sunita/0000-0002-8959-3724
CR [Anonymous], 2005, P INT S FRONTIERS RE
   Benetos E, 2013, P INT SOC MUS INF RE, P269
   Berget G. E., 2017, USING HIDDEN MARKOV
   Bouqata B, 2006, P EUR C PRINC PRACT, P18
   Chen CH, 2009, IEEE T SYST MAN CY C, V39, P114, DOI 10.1109/TSMCC.2008.2001716
   CHEN MY, 1995, IEEE T IMAGE PROCESS, V4, P1675, DOI 10.1109/83.477074
   Chen R., 2012, P 13 INT SOC MUS INF, P445
   Chithra S, 2015, PROCEDIA COMPUT SCI, V46, P381, DOI 10.1016/j.procs.2015.02.034
   Chordia P, 2011, J NEW MUSIC RES, V40, P105, DOI 10.1080/09298215.2011.576318
   Coviello E, 2011, IEEE T AUDIO SPEECH, V19, P1343, DOI 10.1109/TASL.2010.2090148
   Dalin-Volsing, 2017, CLASSIFICATION MUSIC
   Dang S, 2017, J NEUROSCI METH, V278, P87, DOI 10.1016/j.jneumeth.2016.12.019
   Dharini D., 2018, 2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P486, DOI 10.1109/I-SMAC.2018.8653774
   Graci, 2015, MODELING MUSIC USING
   Hoffman M, 2008, P 32 INT COMP MUS C, P24
   Jun Lin, 2018, 2018 International Conference on Intelligent Transportation, Big Data & Smart City (ICITBS). Proceedings, P732, DOI 10.1109/ICITBS.2018.00189
   Kerr, 2011, MELODIC ANAL USING H
   Khorasani A, 2016, BIOMED ENG-BIOMED TE, V61, P119, DOI 10.1515/bmt-2014-0089
   Li T, 2019, IEEE INT CONF BIG DA, P6128, DOI [10.1109/BigData47090.2019.9005695, 10.1109/bigdata47090.2019.9005695]
   Liu ZY, 2017, PAC-BASIN FINANC J, V44, P127, DOI 10.1016/j.pacfin.2017.06.007
   McCormack J., 1996, Complex Systems, V3, P321
   Nakamura E, 2015, P 16 INT SOC MUS INF, P26
   Nakamura E, 2014, J NEW MUSIC RES, V43, P183, DOI 10.1080/09298215.2014.884145
   Nakano M, 2014, P IEEE INT C AC SPEE, P2424
   Ozerov Alexey, 2009, 2009 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA), P121, DOI 10.1109/ASPAA.2009.5346527
   Pandey G., 2003, P 1 IND INT C ART IN, P1350
   Pikrakis A, 2006, IEEE T AUDIO SPEECH, V14, P1795, DOI 10.1109/TSA.2005.858542
   Qi YT, 2007, IEEE T SIGNAL PROCES, V55, P5209, DOI 10.1109/TSP.2007.898782
   Ren L, 2010, J AM STAT ASSOC, V105, P458, DOI 10.1198/jasa.2009.ap08497
   Román-Gálvez R, 2015, MATH COMPUT SIMULAT, V118, P320, DOI 10.1016/j.matcom.2014.11.009
   Sekhar PK, 2017, P 23 NAT C COMM NCC, P2
   Senturk S., 2011, COMPUTATIONAL MODELI
   Sertan Senturk., 2011, 12th International Society for Music Information Retrieval Conference, P269
   SHEN J, 2010, P 33 INT ACM SIGIR C, P635
   Shen JL, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P455, DOI 10.1145/2348283.2348346
   Small, 2020, PHYSICA A, V124351, P1
   Smith, 2002, MACH LEARN PROJ, P308
   Stanculescu I, 2014, IEEE J BIOMED HEALTH, V18, P1560, DOI 10.1109/JBHI.2013.2294692
   Wang CP, 2017, PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON BIOTECHNOLOGY & MEDICAL SCIENCE, P19
   Weiland Michele., 2005, LEARNING MUSICAL PIT
   Xiao QL, 2018, INT J ADV MANUF TECH, V94, P1283, DOI 10.1007/s00170-017-0916-7
   Yanchenko Anna K., 2017, Classical Music Composition Using State Space Models
   Zaki MJ, 2010, ACM T KNOWL DISCOV D, V4, DOI 10.1145/1644873.1644878
   Zhai ChengXiang., 2003, BRIEF NOTE HIDDEN MA
NR 44
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14853
EP 14866
DI 10.1007/s11042-020-10303-y
EA JAN 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613057400001
DA 2024-07-18
ER

PT J
AU Xie, ZH
   Niu, JY
   Yi, L
   Lu, GY
AF Xie, Zhihua
   Niu, Jieyi
   Yi, Li
   Lu, Guoyu
TI Regularization and attention feature distillation base on light CNN for
   Hyperspectral face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral imaging; Face recognition; Transfer learning; Channel
   attention; Feature distillation
ID SPECTRUM
AB The hyperspectral imaging, capturing discriminative information across a series of spectrum bands, leads to building a robust face recognition system. Motivated by the success of deep convolutional network and transferring learning, this paper proposed an end-to-end hyperspectral face recognition model based on a light Convolutional Neural Network (CNN) and transfer learning. To boost the performance of hyperspectral face recognition, the Max-Feature-Map (MFM) activation function and fine-tuning (structure regularization(L2SP) or attention feature distillation (AFD)) are introduced to optimize the deep network, which will learn the fine feature representation across different bands. Especially, this method incorporates regularization and AFD cooperation into the transfer learning strategy on the visible face data. By feeding back hyperspectral images to the pretrained light CNN network, we can design an end-to end model that can leverage the generalization ability for hyperspectral face images. Finally, the entire model is trained and verified on the PolyU-HSFD, CMU, and UWA hyperspectral face datasets using the associated standard evaluation protocols. Experimental results demonstrate that the improved Light CNN network can get good representations of hyperspectral face features and the joint training with a combination of L2SP and AFD exhibits better recognition performance than the state-of-the-art methods based on other deep networks.
C1 [Xie, Zhihua; Niu, Jieyi; Yi, Li] Jiangxi Sci & Technol Normal Univ, Key Lab Opt Elect & Commun, Nanchang, Jiangxi, Peoples R China.
   [Lu, Guoyu] Rochester Inst Technol, Chester Carlson Ctr Imaging Sci, Rochester, NY 14623 USA.
C3 Jiangxi Science & Technology Normal University; Rochester Institute of
   Technology
RP Xie, ZH (corresponding author), Jiangxi Sci & Technol Normal Univ, Key Lab Opt Elect & Commun, Nanchang, Jiangxi, Peoples R China.
EM xie_zhihua68@aliyun.com
RI Xie, Zhihua/ACB-0501-2022
OI Lu, Guoyu/0000-0002-2685-5563; Xie, Zhihua/0000-0002-4226-7497
FU National Nature Science Foundation of China [61861020]; Science
   &Technology Project of Education Bureau of Jiangxi Province [GJJ190578];
   Jiangxi Province Graduate Innovation Special Fund Project [YC2020-S571]
FX This paper is supported by the National Nature Science Foundation of
   China (No.61861020), Science &Technology Project of Education Bureau of
   Jiangxi Province (No. GJJ190578), Jiangxi Province Graduate Innovation
   Special Fund Project (No. YC2020-S571).
CR Allen D, 2016, FACE RECOGNITION IMA, P1, DOI DOI 10.1007/978-3-319-28501-6_1
   [Anonymous], IEEE WINT C APPL COM
   [Anonymous], 2014, ARXIV14117923
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Chunjuan Bo, 2018, Multimedia Tools and Applications, V77, P10419, DOI 10.1007/s11042-017-4403-9
   Denes L, 2002, CMURITR0225
   Di W, 2010, IEEE T SYST MAN CY A, V40, P1354, DOI 10.1109/TSMCA.2010.2052603
   Diba, 2016, HYPERSPECTRAL CNN IM
   Ghasemzadeh A, 2018, IET BIOMETRICS, V7, P49, DOI 10.1049/iet-bmt.2017.0082
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kruse, 2002, 11 JPL AIRB GEOSC WO
   Kumar GVS, 2017, MULTIMED TOOLS APPL, V76, P8355, DOI 10.1007/s11042-016-3420-4
   Li XL, 2019, PR MACH LEARN RES, V97
   Li XH, 2018, PR MACH LEARN RES, V80
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lin MPH, 2014, DES AUT CON, DOI 10.1145/2593069.2593179
   Osia N, 2014, IMAGE VISION COMPUT, V32, P847, DOI 10.1016/j.imavis.2014.06.010
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Uzair M, 2015, IEEE T IMAGE PROCESS, V24, P1127, DOI 10.1109/TIP.2015.2393057
   Uzair M, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.57
   Wang K, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207355
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yosinski J, 2014, ADV NEUR IN, V27
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang XR, 2018, MULTIMED TOOLS APPL, V77, P29759, DOI 10.1007/s11042-017-5552-6
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhihua Xie, 2019, 2019 6th International Conference on Systems and Informatics (ICSAI), P1270, DOI 10.1109/ICSAI48974.2019.9010511
NR 37
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19151
EP 19167
DI 10.1007/s11042-021-10537-4
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000610019400007
DA 2024-07-18
ER

PT J
AU Brito, R
   Biuk-Aghai, RP
   Fong, SM
AF Brito, Ricardo
   Biuk-Aghai, Robert P.
   Fong, Simon
TI GPU-based parallel Shadow Features generation at neural system for
   improving gait human activity recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural networks; Shadow features; CUDA; GPU; Human Activity Recognition
   (HAR)
AB In this paper, we propose a new method for improving human activity recognition (HAR) datasets in order to increase their classification accuracy when trained with a certain classifier like a Neural Network. In this paper a novel training/testing process for building/testing a classification model for human activity recognition (HAR) is proposed. Traditionally, HAR is done by a classifier that learns what activities a person is doing by training with skeletal data obtained from a motion sensor such as Microsoft Kinect or accelerometer sensors. These skeletal data are the spatial coordinates (x, y, z) of different parts of the human body. In addition to the spatial features that describe current positions in the skeletal data, new features called Shadow Features are used to improve the supervised learning efficiency and accuracy of Neural Network classifiers. Shadow Features are inferred from the dynamics of body movements, thereby modelling the underlying momentum of the performed activities. They provide extra dimensions of information for characterizing activities in the classification process and thus significantly improving the accuracy. These Shadow Features are generated based on the existing features obtained from sensor datasets. In this paper we show that the accuracy of a neural network classifier can be significantly improved by the addition of Shadow Features and we also show that the generation of Shadow Features can be achieved with little time cost, on the fly, with the NVIDIA GPU technology and the CUDA programming model, this way we can improve the Neural Network accuracy at almost no time cost. GPUs are particularly suitable for generating Shadow Features, since they possess multiple cores which can be taken advantage of, in order to generate Shadow Features for multiple data columns in parallel, therefore reducing a lot of processing time, especially when dealing with huge datasets.
C1 [Brito, Ricardo; Biuk-Aghai, Robert P.; Fong, Simon] Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Ave Univ, Taipa, Macau, Peoples R China.
C3 University of Macau
RP Brito, R (corresponding author), Univ Macau, Dept Comp & Informat Sci, Fac Sci & Technol, Ave Univ, Taipa, Macau, Peoples R China.
EM yb87473@um.edu.mo; robertb@umac.mo; ccfong@umac.mo
RI Biuk-Aghai, Robert P/A-4287-2008; Fong, Simon/C-9388-2009
OI Fong, Simon/0000-0002-1848-7246
FU University of Macau, FST [MYRG2016-00069-FST]; RDAO; FDCT Macau
   [FDCT/126/2014/A3]
FX The authors are grateful for the financial support from the Research
   Grants, (1) Nature-Inspired Computing and Meta-heuristics Algorithms for
   Optimizing DataMining Performance, Grant no. MYRG2016-00069-FST, offered
   by the University of Macau, FST, and RDAO; and (2) A Scalable Data
   Stream Mining Methodology: Stream-based Holistic Analytics and Reasoning
   in Parallel, Grant no. FDCT/126/2014/A3, offered by FDCT Macau.
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   [Anonymous], 2019, World Bank Open Data
   Iglesias JA, 2010, INT J NEURAL SYST, V20, P355, DOI 10.1142/S0129065710002462
   Babiker Mohanad., 2017, 2017 IEEE 4 INT C SM, P1, DOI DOI 10.1109/ICSIMA.2017.8312024
   Bagate A, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICCS), P902, DOI [10.1109/ICCS45141.2019.9065460, 10.1109/iccs45141.2019.9065460]
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Campbell LW, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P157, DOI 10.1109/AFGR.1996.557258
   Chan JH, 2016, J MED IMAG HLTH INFO
   Danafar S, 2007, LECT NOTES COMPUT SC, V4844, P457
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Gadekallu TR, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01963-7
   Gavrilova M, 2018, IEEE CONSUM ELECTR M, V71, P1
   Ke Y, 2007, IEEE I CONF COMP VIS, P1424
   Kim Y., 2014, LECT NOTES ELECT ENG, V309, P457
   Köse N, 2017, IEEE IMAGE PROC, P3963, DOI 10.1109/ICIP.2017.8297026
   Lee KS, 2019, INT C REHAB ROBOT, P583, DOI [10.1109/icorr.2019.8779475, 10.1109/ICORR.2019.8779475]
   Lee SM, 2017, INT CONF BIG DATA, P131, DOI 10.1109/BIGCOMP.2017.7881728
   Leo M, 2004, HUMAN ACTIVITY RECOG, P124
   Liu CC, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P33, DOI 10.1109/SIPROCESS.2018.8600483
   Mitra SK, 2011, P 3 IEEE NAT C COMP, P239
   Müller M, 2005, ACM T GRAPHIC, V24, P677, DOI 10.1145/1073204.1073247
   Museum TJPG, 1990, PHOTOGRAPHY DISCOVER
   Psychoula I, 2018, INT CONF PERVAS COMP, DOI 10.1109/PERCOMW.2018.8480247
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Singh D, 2017, CONVOLUTIONAL RECURR, P194
   Singh D, 2017, LECT NOTES COMPUT SC, V10410, P267, DOI 10.1007/978-3-319-66808-6_18
   Song W., 2014, LECT NOTES ELECT ENG, V309, P485
   SORKUN MC, 2018, 2018 26 SIGN PROC CO, P1
   Thuc HoangLe Uyen., 2012, FRONTIERS COMPUTER V, P6
   Tsitsoulis A, 2013, INT J ARTIF INTELL T, V22, DOI 10.1142/S0218213013500309
   Uyen Thuc HoangLe., 2012, Computing and Communication Technologies, Research, Innovation, and Vision for the Future (RIVF), 2012 IEEE RIVF International Conference on, P1
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
NR 32
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12293
EP 12308
DI 10.1007/s11042-020-10274-0
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606409000005
OA hybrid
DA 2024-07-18
ER

PT J
AU Chaudhary, V
   Kumar, V
AF Chaudhary, Vishal
   Kumar, Vinay
TI Target based image fusion using multi-scale feature selection in three
   regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic range; Multi-scale; Exposure time; Multi-exposure fusion
ID INFORMATION MEASURE; EXPOSURE FUSION; DECOMPOSITION; PERFORMANCE
AB Image captured by low dynamic range (LDR) camera fails to capture entire exposure level of scene, and instead only covers certain range of exposures. In order to cover entire exposure level in single image, bracketed exposure LDR images are combined. The range of exposures in different images results in information loss in certain regions. These regions need to be addressed and based on this motive a novel methodology of layer based fusion is proposed to generate high dynamic range image. High and low-frequency layers are formed by dividing each image based on pixel intensity variations. The regions are identified based on information loss section created in differently exposed images. High-frequency layers are combined using region based fusion with Dense SIFT which is used as activity level testing measure. Low-frequency layers are combined using weighted sum. Finally combined high and low-frequency layers are merged together on pixel to pixel basis to synthesize fused image. Objective analysis is performed to compare the quality of proposed method with state-of-the-art. The measures indicate superiority of the proposed method.
C1 [Chaudhary, Vishal; Kumar, Vinay] Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Chaudhary, V (corresponding author), Thapar Inst Engn & Technol, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM vishalch.nsit@gmail.com; vinay.kumar@thapar.edu
OI Chaudhary, Vishal/0000-0002-5982-5299
CR Chaudhary V, 2020, MULTIDIM SYST SIGN P, V31, P157, DOI 10.1007/s11045-019-00655-6
   Chaudhary V, 2018, SIGNAL IMAGE VIDEO P, V12, P271, DOI 10.1007/s11760-017-1155-y
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   Gallo O., 2009, P IEEE INT C COMP PH, P1
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Hayat N, 2019, IET IMAGE PROCESS, V13, P2554, DOI 10.1049/iet-ipr.2019.0438
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Huang LP, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9010011
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Jevnisek RJ, 2017, PROC CVPR IEEE, P3816, DOI 10.1109/CVPR.2017.406
   Jinno T, 2012, IEEE T IMAGE PROCESS, V21, P358, DOI 10.1109/TIP.2011.2160953
   Jo KH, 2011, COMPUT HUM BEHAV, V27, P1507, DOI 10.1016/j.chb.2010.10.015
   Kim K, 2011, IEEE T CONSUM ELECTR, V57, P1807, DOI 10.1109/TCE.2011.6131157
   Kuang JT, 2007, J VIS COMMUN IMAGE R, V18, P406, DOI 10.1016/j.jvcir.2007.06.003
   Lee JW, 2010, IEEE T CONSUM ELECTR, V56, P2772, DOI 10.1109/TCE.2010.5681168
   Li ST, 2012, IEEE T CONSUM ELECTR, V58, P626, DOI 10.1109/TCE.2012.6227469
   Li XG, 2013, IET IMAGE PROCESS, V7, P701, DOI 10.1049/iet-ipr.2012.0494
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Liu Y, 2015, J VIS COMMUN IMAGE R, V31, P208, DOI 10.1016/j.jvcir.2015.06.021
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Ma JY, 2019, INFORM FUSION, V45, P153, DOI 10.1016/j.inffus.2018.02.004
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P2519, DOI 10.1109/TIP.2017.2671921
   Merianos I, 2019, J IMAGING, V5, DOI 10.3390/jimaging5030032
   Mertens T, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P382, DOI 10.1109/PG.2007.17
   Paul S, 2016, J CIRCUIT SYST COMP, V25, DOI 10.1142/S0218126616501231
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qi GQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061597
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Radhika V, 2018, J SIGNAL PROCESS SYS, V90, P947, DOI 10.1007/s11265-017-1252-8
   Raman S., 2009, P 26 INT C MACHINE L, P1
   Shan Q, 2010, IEEE T VIS COMPUT GR, V16, P663, DOI 10.1109/TVCG.2009.92
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Shen R, 2013, IEEE T IMAGE PROCESS, V22, P2469, DOI 10.1109/TIP.2012.2236346
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Shutao Li, 2001, Information Fusion, V2, P169, DOI 10.1016/S1566-2535(01)00038-0
   Simone G., 2002, Information Fusion, V3, P3, DOI 10.1016/S1566-2535(01)00056-2
   Song ML, 2012, IEEE T IMAGE PROCESS, V21, P341, DOI 10.1109/TIP.2011.2157514
   Thomas C, 2008, IEEE T GEOSCI REMOTE, V46, P1301, DOI 10.1109/TGRS.2007.912448
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Várkonyi-Kóczy AR, 2008, IEEE T INSTRUM MEAS, V57, P1779, DOI 10.1109/TIM.2008.925715
   Wang SP, 2020, IEEE ACCESS, V8, P39034, DOI 10.1109/ACCESS.2020.2975896
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yu ML, 2015, MULTIMED TOOLS APPL, V74, P2745, DOI 10.1007/s11042-013-1660-0
   Zhang JM, 2019, IEEE ACCESS, V7, P83873, DOI 10.1109/ACCESS.2019.2924944
   Zhang W, 2012, IEEE T IMAGE PROCESS, V21, P2318, DOI 10.1109/TIP.2011.2170079
   Zhou ZQ, 2016, INFORM FUSION, V30, P15, DOI 10.1016/j.inffus.2015.11.003
NR 53
TC 0
Z9 0
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 11959
EP 11984
DI 10.1007/s11042-020-09940-0
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606296800005
DA 2024-07-18
ER

PT J
AU Xiong, QH
   Zhou, SJ
   Chen, QS
AF Xiong, Qinghua
   Zhou, Sijia
   Chen, Qiushi
TI Abnormal driving behavior detection based on kernelization-sparse
   representation in video surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Intelligent transportation system; Abnormal driving behavior; Behavior
   detection; Sparse reconstruction; Hybrid kernel
ID FACE RECOGNITION; IDENTIFICATION; CLASSIFICATION
AB The detection of abnormal driving behaviors based on video surveillance systems is an important part of Intelligent Transportation System (ITS), which can help reduce disturbances on traffic flow and improve traffic safety. First, the study proposes a novel nonlinear sparse reconstruction method for abnormal driving behavior detection in video surveillance. A hybrid kernel function formed by convexly combining a local kernel of radial basis function (RBF) and a global kernel of homogeneous polynomial is been applied in sparse reconstruction method. Then, a novel Hybrid Kernel Orthogonal Matching Pursuit (HKOMP) algorithm is designed to solve the proposed sparse reconstruction model. Finally, the performance of the abnormal detection method is tested on two datasets i.e. stop sign dataset and car parking dataset. In addition, comparative experiments with five classical methods are carried out. The experimental results indicate that the proposed method outperforms other five comparison methods in terms of accuracy.
C1 [Xiong, Qinghua] South Cent Univ Nationalities, Coll Fine Arts, Minyuan Rd St, Wuhan 430074, Peoples R China.
   [Zhou, Sijia] Wenzhou Univ, Coll Mech & Elect Engn, Wenzhou 325035, Peoples R China.
   [Chen, Qiushi] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan 430070, Peoples R China.
C3 South Central Minzu University; Wenzhou University; Wuhan University of
   Technology
RP Zhou, SJ (corresponding author), Wenzhou Univ, Coll Mech & Elect Engn, Wenzhou 325035, Peoples R China.
EM jmjeremyzhang@sina.com
FU Provincial Key R&D program of Zhejiang province [2019C04002];
   Fundamental Research Funds for the Central Universities, South-Central
   University for Nationalities [CST20010]
FX This work is supported by the Provincial Key R&D program of Zhejiang
   province (Grant Number: 2019C04002), and the Fundamental Research Funds
   for the Central Universities", South-Central University for
   Nationalities (Grant Number: CST20010).
CR Ahmadi P, 2016, IET IMAGE PROCESS, V10, P235, DOI 10.1049/iet-ipr.2015.0399
   Amaldi E, 1998, THEOR COMPUT SCI, V209, P237, DOI 10.1016/S0304-3975(97)00115-1
   Cai YF, 2015, IET INTELL TRANSP SY, V9, P810, DOI 10.1049/iet-its.2014.0238
   Chang X, 2019, ACCIDENT ANAL PREV, V128, P197, DOI 10.1016/j.aap.2019.04.019
   Chang X, 2019, J ADV TRANSPORT, DOI 10.1155/2019/8591623
   Chen DS, 2014, INT J SIMUL MODEL, V13, P219, DOI 10.2507/IJSIMM13(2)CO8
   Chen ZJ, 2017, IEEE T INTELL TRANSP, V18, P236, DOI 10.1109/TITS.2016.2587814
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Chen ZJ, 2018, OCEAN ENG, V161, P69, DOI 10.1016/j.oceaneng.2018.04.072
   Chen ZJ, 2017, J INTELL TRANSPORT S, V21, P409, DOI 10.1080/15472450.2017.1305271
   Chen ZJ, 2015, KNOWL-BASED SYST, V89, P203, DOI 10.1016/j.knosys.2015.07.004
   Chong YW, 2011, TRANSPORT RES REC, P74, DOI 10.3141/2243-09
   Cristianint Nello, 2000, INTRO SUPPORT VECTOR
   Dalal N, 2005, P 2005 IEEE COMP SOC
   Gao SH, 2010, LECT NOTES COMPUT SC, V6314, P1
   Gocken T, 2019, INT J SIMUL MODEL, V18, P574, DOI 10.2507/IJSIMM18(4)485
   Hsieh JW, 2006, IEEE T INTELL TRANSP, V7, P175, DOI 10.1109/TITS.2006.874722
   Hu J, 2020, IEEE T VEH TECHNOL, V69, P6943, DOI 10.1109/TVT.2020.2993247
   Huang W, 2019, IEEE ACCESS, V7, P64571, DOI 10.1109/ACCESS.2019.2917213
   Mangasarian OL, 2006, J MACH LEARN RES, V7, P1517
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Oh C, 2013, TRANSPORT RES REC, P9, DOI 10.3141/2381-02
   Okyere AGY, 2014, TRANSPORT RES REC, P35, DOI 10.3141/2463-05
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Ramyar S, 2016, IEEE SYS MAN CYBERN, P4405, DOI 10.1109/SMC.2016.7844924
   Saligrama V, 2010, IEEE SIGNAL PROC MAG, V27, P18, DOI 10.1109/MSP.2010.937393
   Simon C, 2010, MULTIMED TOOLS APPL, V50, P95, DOI 10.1007/s11042-009-0364-y
   Wang C, 2019, LECT NOTES COMPUT SC, V11514, P125, DOI 10.1007/978-3-030-23551-2_9
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu XR, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P266, DOI 10.1109/ICACI.2018.8377618
   Yang M, 2010, LECT NOTES COMPUT SC, V6316, P448, DOI 10.1007/978-3-642-15567-3_33
   Yu JD, 2017, IEEE T MOBILE COMPUT, V16, P2198, DOI 10.1109/TMC.2016.2618873
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zhang YS, 2017, TRANSPORT RES REC, P195, DOI 10.3141/2645-21
   Zhao XH, 2019, TRANSPORT RES F-TRAF, V62, P529, DOI 10.1016/j.trf.2019.02.004
   Zhu, 2003, ADV NEURAL INFORM PR
NR 37
TC 3
Z9 3
U1 4
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2021 JAN 7
PY 2021
DI 10.1007/s11042-020-10172-5
EA JAN 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XS6KS
UT WOS:000733015900001
DA 2024-07-18
ER

PT J
AU Chen, LT
   Lou, J
   Xu, FL
   Ren, MW
AF Chen, Longtao
   Lou, Jing
   Xu, Fenglei
   Ren, Mingwu
TI Grid-based multi-object tracking with Siamese CNN based appearance edge
   and access region mechanism
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Grid-based tracking; Globally optimization tracking; Multi-object
   tracking; Siamese neural networks
ID MULTITARGET TRACKING; PEOPLE TRACKING; ASSOCIATION; FLOW
AB Receiving growing attention for its various applications during the last few years, multi-object tracking remains a complex and challenging problem. Conventional grid-based tracking method is an efficient and effective method to tackle multi-object tracking, whose performance can be further boosted by intuitively taking into account the appearance similarity information yet. Therefore, we introduce appearance similarity edge into the grid-based method, where a Siamese network is utilized to produce the proposed similarity edge. In addition, we build a grid model with hexagonal cells and propose an access region mechanism including accessible area definition and an automatic-generation approach for entrance/exit grids. Since our tracking framework follows 'tracking-by-detection' paradigm, the corresponding detection information is available to be integrated into access region mechanism, which will facilitate appropriate grid modeling. We verify the proposed Siamese network based appearance edge and access region mechanism through the experiments on some popular datasets like PETS-09, KITTI.
C1 [Chen, Longtao; Xu, Fenglei; Ren, Mingwu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Xiaolingwei 200, Nanjing 210094, Peoples R China.
   [Lou, Jing] Changzhou Inst Mechatron Technol, Sch Informat Engn, Changzhou 213164, Jiangsu, Peoples R China.
C3 Nanjing University of Science & Technology
RP Ren, MW (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Xiaolingwei 200, Nanjing 210094, Peoples R China.
EM mingwuren@163.com
RI Lou, Jing/B-3258-2011; Xu, Fenglei/HGF-1737-2022
CR Andriyenko A, 2010, LECT NOTES COMPUT SC, V6311, P466, DOI 10.1007/978-3-642-15549-9_34
   [Anonymous], 2018, P 2018 IEEE INT C CO
   [Anonymous], 2009, Twelfth IEEE International Workshop on Performance Evaluation of Tracking and Surveillance (PETS-Winter), DOI DOI 10.1109/PETS-WINTER.2009.5399488
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bewley A, 2016, IEEE INT CONF ROBOT, P2212, DOI 10.1109/ICRA.2016.7487371
   Carlsson S., 2006, 2006 IEEE COMPUTER S, V2, P2187, DOI 10.1109/CVPR.2006.198
   Chen LL, 2015, IEEE T IMAGE PROCESS, V24, P4197, DOI 10.1109/TIP.2015.2451013
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   ELFES A, 1989, COMPUTER, V22, P46, DOI 10.1109/2.30720
   Ess A, 2009, IEEE ICRA WORKSH PEO
   Ess A, 2008, PROC CVPR IEEE, P1857
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Geiger A, 2014, IEEE T PATTERN ANAL, V36, P1012, DOI 10.1109/TPAMI.2013.185
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hsu CY, 2013, INT C INT MULT COMP, P113
   Ju J, 2017, IET COMPUT VIS, V11, P87, DOI 10.1049/iet-cvi.2016.0068
   Leal-Taixe L., 2015, MOTChallenge 2015: Towards a Benchmark for Multi-Target Tracking
   Li Zhang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563097
   Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Milan A, 2016, IEEE T PATTERN ANAL, V38, P2054, DOI 10.1109/TPAMI.2015.2505309
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schulter S, 2017, PROC CVPR IEEE, P2730, DOI 10.1109/CVPR.2017.292
   Shen FM, 2018, IEEE T PATTERN ANAL, V40, P3034, DOI 10.1109/TPAMI.2018.2789887
   Shen FM, 2017, IEEE T MULTIMEDIA, V19, P2022, DOI 10.1109/TMM.2017.2699863
   Shen FM, 2016, IEEE T IMAGE PROCESS, V25, P5610, DOI 10.1109/TIP.2016.2612883
   Song Y., 2016, 2016 IEEE INT C VEHI, P1, DOI DOI 10.1109/ICVES.2016.7548171
   Sun S, 2018, ARXIV181011780
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang B, 2014, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2014.161
   Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045
   Yang WK, 2018, IEEE ACCESS, V6, P7445, DOI 10.1109/ACCESS.2017.2784800
   Yoon K, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030559
   Yoon Y, 2018, 2018 15 IEEE INT C A, P1, DOI [10.1109/AVSS.2018.8639078, DOI 10.1109/AVSS.2018.8639078]
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
NR 50
TC 3
Z9 3
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35333
EP 35351
DI 10.1007/s11042-019-07747-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900034
DA 2024-07-18
ER

PT J
AU Kanaparthi, SK
   Raju, USN
   Shanmukhi, P
   Aneesha, GK
   Rahman, MEU
AF Kanaparthi, Suresh Kumar
   Raju, U. S. N.
   Shanmukhi, P.
   Aneesha, G. Khyathi
   Rahman, Mohammed Ehsan Ur
TI Image Retrieval by Integrating Global Correlation of Color and Intensity
   Histograms with Local Texture Features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Conference on Recent Trends in Image Processing and
   Pattern Recognition (RTIP2R)
CY DEC 21-22, 2018
CL Solapur, INDIA
DE CBIR; Inter-Channel Voting; Total Minimum Retrieval Epoch; Diagonally
   Symmetric Pattern; Color Auto Correlogram
AB Research on Content-Based Image Retrieval is being done to improvise existing methods. Most of the techniques that were proposed use color and texture features independently. In this paper, to get the correspondence between color and texture, we use congruence on Hue, Saturation, and Intensity by using inter-channel voting. Gray Level Co-occurrence Matrix (GLCM) on Diagonally Symmetric Pattern is computed to get texture features of an image. The similarity metrics between two images is computed using congruence and GLCM. To measure the performance; Average Precision Rate (APR), Average Recall Rate (ARR), F-measure, Average Normalized Modified Retrieval Rank (ANMRR) are calculated. In addition to these parameters, one more parameter has been proposed: Total Minimum Retrieval Epoch (TMRE) to calculate the average number of images to be traversed for each query image to get all the images of that category. To validate the performance of the proposed method, it has been applied to six image databases: Corel-1 K, Corel-5 K, Corel-10 K, VisTex, STex, and Color Brodatz. The results of most of the databases show significant improvement.
C1 [Kanaparthi, Suresh Kumar; Raju, U. S. N.] Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
   [Shanmukhi, P.; Aneesha, G. Khyathi] Natl Inst Technol Andhra Pradesh, Dept Comp Sci & Engn, Tadepalligudem 534101, Andhra Pradesh, India.
   [Rahman, Mohammed Ehsan Ur] Kakatiya Inst Technol & Sci, Comp Sci & Engn, Warangal 506015, Telangana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Warangal; National Institute of Technology (NIT System);
   National Institute of Technology Andhra Pradesh; Kakatiya University
RP Raju, USN (corresponding author), Natl Inst Technol Warangal, Dept Comp Sci & Engn, Warangal 506004, Telangana, India.
EM sureshkonline@gmail.com; usnraju@nitw.ac.in;
   shanmukhipuchakayala@gmail.com; gkhyathian@gmail.com
RI Raju, U S N/AAN-7582-2020; KUMAR, KANAPARTHI SURESH/KIG-2014-2024
OI Raju, U S N/0000-0003-1049-7949; KUMAR, KANAPARTHI
   SURESH/0000-0003-4945-6554; Rahman, Mohammed Ehsan
   Ur/0000-0003-2875-3162
CR Al-Shemarry MS, 2020, IEEE T INTELL TRANSP, V21, P553, DOI 10.1109/TITS.2019.2897990
   [Anonymous], 2018, DIGITAL IMAGE PROCES
   [Anonymous], 2001, INTRO MPEG 7 MULTIME
   [Anonymous], ALEX SANDY PENTLAND
   Aptoula E, 2009, IEEE T IMAGE PROCESS, V18, P2505, DOI 10.1109/TIP.2009.2027363
   Bhunia AK, 2020, PATTERN ANAL APPL, V23, P703, DOI 10.1007/s10044-019-00827-x
   Chamorro-Martínez J, 2017, IEEE T FUZZY SYST, V25, P1264, DOI 10.1109/TFUZZ.2016.2612259
   Chen JJ, 2012, IEEE T IMAGE PROCESS, V21, P828, DOI 10.1109/TIP.2011.2166558
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   Daschiel H, 2005, IEEE T MULTIMEDIA, V7, P1036, DOI 10.1109/TMM.2005.858383
   Dong-Chen, ABDELMOUNAIME SAFIA
   Gnaneswara Rao N., 2014, INT J MULTIMEDIA UBI, V9, P327, DOI [10.14257/ijmue.2014.9.4.34, DOI 10.14257/IJMUE.2014.9.4.34]
   Guang-Hai Liu, COREL 10K DATASET
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Hu RX, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2013.2286330
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Joblove G.H., 1978, P 5 ANN C COMP GRAPH, VVolume 12, P20, DOI DOI 10.1145/965139.807362
   Karargyris A, 2016, INT J COMPUT ASS RAD, V11, P99, DOI 10.1007/s11548-015-1242-x
   Kekre HB., 2012, INT J ELECT COMPUT S, V44, P0975, DOI [10.5120/6265-8418, DOI 10.5120/6265-8418]
   Konstantinidis K, 2005, OPT COMMUN, V248, P375, DOI 10.1016/j.optcom.2004.12.029
   Li B, 2019, SPECIAL SECTION THEO, V7, P37220, DOI [10.1109/ACCESS.2019.2905304, DOI 10.1109/ACCESS.2019.2905304]
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu L, 2019, IEEE T IMAGE PROCESS
   Mathew SP, 2015, ACTA POLYTECH HUNG, V12, P103
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Naidu RR, 2016, IEEE T SIGNAL PROCES, V64, P3566, DOI 10.1109/TSP.2016.2550020
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Osowski S, 2002, PATTERN RECOGN, V35, P1949, DOI 10.1016/S0031-3203(01)00153-4
   Quellec G, 2010, IEEE T INF TECHNOL B, V14, P1227, DOI 10.1109/TITB.2010.2053716
   Ramos J, 2016, IEEE J BIOMED HEALTH, V20, P281, DOI 10.1109/JBHI.2014.2375491
   Roland Kwitt, SALZBURG TEXTURE IMA
   Santosh KC, 2018, IEEE T MED IMAGING, V37, P1168, DOI 10.1109/TMI.2017.2775636
   Santosh KC, 2016, INT J COMPUT ASS RAD, V11, P1637, DOI 10.1007/s11548-016-1359-6
   Santosh KC, 2016, IEEE INTELL SYST, V31, P66, DOI 10.1109/MIS.2016.24
   Singha M., 2012, Signal Image Process, V3, P39, DOI DOI 10.5121/SIPIJ.2012.3104
   Singha M., 2012, SIGNAL IMAGE PROCESS, V3, P239, DOI [10.1109/ICSIP.2010.5697476, DOI 10.1109/ICSIP.2010.5697476]
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Strat T.M., 1993, DARPA, V93, P217
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TOMINAGA S, 1992, COLOR RES APPL, V17, P230, DOI 10.1002/col.5080170405
   Vajda S, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0991-9
   Verma M, 2015, NEUROCOMPUTING, V165, P255, DOI 10.1016/j.neucom.2015.03.015
   Wan X, 1998, IEEE T CIRC SYST VID, V8, P628, DOI 10.1109/76.718509
   Wang JH., MODELING OBJECTS CON
   Wang XY, 2014, MULTIMED TOOLS APPL, V68, P545, DOI 10.1007/s11042-012-1055-7
   Xia ZH, 2018, IEEE T CLOUD COMPUT, V6, P276, DOI 10.1109/TCC.2015.2491933
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang LN, 2012, IEEE T IMAGE PROCESS, V21, P2294, DOI 10.1109/TIP.2011.2177846
   Zheng YS, 2018, IEEE T MED IMAGING, V37, P1641, DOI 10.1109/TMI.2018.2796130
NR 54
TC 17
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34875
EP 34911
DI 10.1007/s11042-019-08029-7
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900010
DA 2024-07-18
ER

PT J
AU Liang, JY
   Guo, JL
   Guo, YM
   Lao, SY
AF Liang, Jingyun
   Guo, Jinlin
   Guo, Yanming
   Lao, Songyang
TI PFNet: a novel part fusion network for fine-grained visual
   categorization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained visual categorization; Image classification; Convolutional
   neural network
ID CLASSIFICATION; SCALE
AB The existing methods in fine-grained visual categorization focus on integrating multiple deep CNN models or complicated attention mechanism, resulting in increasing cumbersome networks. In addition, most methods rely on part annotations which requires expensive expert guidance. In this paper, without extra annotation, we propose a novel part fusion network (PFNet) to effectively fuse discriminative image parts for classification. More specifically, PFNet consists of a part feature extractor to extract part features and a two-level classification network to utilize part-level and image-level features simultaneously. Part-level features are trained with the weighted part loss, which embeds a weighting mechanism based on different parts' characteristics. Easy parts, hard parts and background parts are proposed and discriminatively used for classification. Moreover, part-level features are fused to form an image-level feature so as to introduce global supervision and generate final predictions. Experiments on three popular benchmark datasets show that our framework achieves competitive performance compared with the state-of-the-art. Code is available at .
C1 [Liang, Jingyun; Guo, Jinlin; Guo, Yanming; Lao, Songyang] Natl Univ Def Technol, Coll Syst Engn, Changsha, Peoples R China.
C3 National University of Defense Technology - China
RP Guo, JL (corresponding author), Natl Univ Def Technol, Coll Syst Engn, Changsha, Peoples R China.
EM gjlin99@nudt.edu.cn
CR [Anonymous], 2016, ARXIV160608572
   [Anonymous], 2016, ARXIV160506878
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Branson S., 2014, BIRD SPECIES CATEGOR, V1, P7
   Cai SJ, 2017, IEEE I CONF COMP VIS, P511, DOI 10.1109/ICCV.2017.63
   Chen X., 2017, IMPLEMENTATION FASTE
   Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Farrell R, 2011, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2011.6126238
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Karessli N, 2017, PROC CVPR IEEE, P6412, DOI 10.1109/CVPR.2017.679
   Kong S, 2017, PROC CVPR IEEE, P7025, DOI 10.1109/CVPR.2017.743
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li XQ, 2017, PROC IEEE MICR ELECT, P821, DOI 10.1109/MEMSYS.2017.7863534
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13
   Liu L., 2018, ARXIV180110324
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang S, 2012, IEEE T MULTIMEDIA, V14, P43, DOI 10.1109/TMM.2011.2168198
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vedaldi A., 2013, Technical report
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276
   Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131
   Xiao LX, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511399
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xie SN, 2015, PROC CVPR IEEE, P2645, DOI 10.1109/CVPR.2015.7298880
   Xu Z, 2015, IEEE I CONF COMP VIS, P2524, DOI 10.1109/ICCV.2015.290
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zheng Y, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P1224, DOI 10.1109/WCICA.2012.6358068
NR 48
TC 0
Z9 0
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33397
EP 33416
DI 10.1007/s11042-018-7047-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000594855000005
DA 2024-07-18
ER

PT J
AU Dutta, P
   Saha, S
   Naskar, S
AF Dutta, Pratik
   Saha, Sriparna
   Naskar, Sukanya
TI A multi-objective based PSO approach for inferring pathway activity
   utilizing protein interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pathway activity; Particle swarm optimization; Gene markers;
   Protein-protein interaction; Weightedt-score
ID PARTICLE SWARM OPTIMIZATION; OUTCOME PREDICTION; T-TEST; EXPRESSION;
   ALGORITHM; GENES; CLASSIFICATION
AB The pathway information of a given microarray gene expression data can be collected from the available public databases. Inferring the activity of a pathway is a crucial task in functional genomics. In general, the set of genes that are associated with a given pathway are equally considered for measuring goodness. But the contribution of each gene should be quantified differently. In the current study, we have quantified the degrees of relevance of different genes participating in a pathway by optimizing different goodness measures of pathway activity. Two popular goodness measures, namely t-score and z-score are modified to measure the goodness of the weighted gene vectors. Moreover, another goodness measure based on the protein-protein interaction scores of pairs of genes participated in a pathway is utilized as another objective function. All these measures are designed to handle the weighted importance of individual genes. The search capability of a multiobjective based particle swarm optimization (PSO) is utilized for searching the appropriate relevance vectors for different genes. The proposed approach is applied to five real-life gene expression datasets, and the performance is compared with eight existing feature selection methods. The comparative results demonstrate the superiority of the proposed particle swarm optimization based technique. The efficacy of the performance of the proposed method is validated by using a statistical significance test, and further, a biological significant test is done to justify the biological relevance of the extracted pathway-based gene markers.
C1 [Dutta, Pratik; Saha, Sriparna] Indian Inst Technol Patna, Dept Comp Sci & Engn, Bihta, India.
   [Naskar, Sukanya] Indian Inst Engn Sci & Technol Shibpur, Dept Informat Technol, Howrah, India.
C3 Indian Institute of Technology (IIT) - Patna; Indian Institute of
   Engineering Science Technology Shibpur (IIEST)
RP Saha, S (corresponding author), Indian Inst Technol Patna, Dept Comp Sci & Engn, Bihta, India.
EM sriparna@iitp.ac.in
FU Visvesvaraya PhD Scheme for Electronics and IT, an initiative of
   Ministry of Electronics and Information Technology (MeitY), Government
   of India; Young Faculty Research Fellowship (YFRF) Award - Visvesvaraya
   PhD scheme for Electronics and IT, Ministry of Electronics and
   Information Technology (MeitY), Government of India
FX Pratik Dutta acknowledges Visvesvaraya PhD Scheme for Electronics and
   IT, an initiative of Ministry of Electronics and Information Technology
   (MeitY), Government of India for fellowship support. Dr. Sriparna Saha
   gratefully acknowledges the Young Faculty Research Fellowship (YFRF)
   Award, supported by Visvesvaraya PhD scheme for Electronics and IT,
   Ministry of Electronics and Information Technology (MeitY), Government
   of India, being implemented by Digital India Corporation (formerly Media
   Lab Asia) for carrying out this research.
CR Abdel-Basset M, 2020, MULTIMED TOOLS APPL, V79, P5419, DOI [10.1007/s11042-018-6266-0, 10.1007/s11042-018-5840-9]
   An FP, 2019, MULTIMED TOOLS APPL, V78, P17239, DOI 10.1007/s11042-018-7097-8
   [Anonymous], 2016, STAT ENG SCI STUDENT
   [Anonymous], 2016, FDN APPL STAT BIOL U
   Baldi P, 2001, BIOINFORMATICS, V17, P509, DOI 10.1093/bioinformatics/17.6.509
   Bandyopadhyay S, 2008, IEEE T EVOLUT COMPUT, V12, P269, DOI 10.1109/TEVC.2007.900837
   Bandyopadhyay S, 2014, IEEE ACM T COMPUT BI, V11, P95, DOI 10.1109/TCBB.2013.147
   Borawake-Satao R, 2019, MULTIMED TOOLS APPL, V78, P32659, DOI 10.1007/s11042-019-7619-z
   Chakraborty R, 2019, MULTIMED TOOLS APPL, V78, P34027, DOI 10.1007/s11042-019-08114-x
   Daneshfar F, 2019, MULTIMED TOOLS APPL, P1
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deng L, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P1104, DOI 10.1109/DATE.2004.1269040
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Dutta P, 2020, SCI REP-UK, V10, P1, DOI DOI 10.1038/S41598-019-56847-4
   Dutta P, 2019, IEEE ACM T COMPUTATI
   Dutta P, 2019, IEEE J BIOMED HEALTH, V23, P2670, DOI 10.1109/JBHI.2019.2894374
   Dutta P, 2018, LECT NOTES COMPUT SC, V11305, P3, DOI 10.1007/978-3-030-04221-9_1
   Dutta P, 2017, COMPUT BIOL MED, V89, P31, DOI 10.1016/j.compbiomed.2017.07.015
   Fox RJ, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-126
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Huang DW, 2009, NAT PROTOC, V4, P44, DOI 10.1038/nprot.2008.211
   Jiang HY, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-81
   Kamaruddin M., 2011, 2011 International Conference on Electrical Engineering and Infomatics, P1
   Kennedy J., 1995, 1995 IEEE International Conference on Neural Networks Proceedings (Cat. No.95CH35828), P1942, DOI 10.1109/ICNN.1995.488968
   Kushwaha N, 2019, MULTIMED TOOLS APPL, V78, P23917, DOI 10.1007/s11042-018-6324-7
   Lee E, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.1000217
   Liu KQ, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-126
   Liu W, 2017, MOL BIOSYST, V13, P537, DOI 10.1039/c6mb00757k
   López Y, 2015, DATABASE-OXFORD, DOI 10.1093/database/bav117
   Mandal M, 2015, IEEE T NANOBIOSCI, V14, P591, DOI 10.1109/TNB.2015.2425471
   Mandal M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090949
   Marcano-Cedeno A., 2010, IECON 2010 - 36th Annual Conference of IEEE Industrial Electronics, P2845, DOI 10.1109/IECON.2010.5675075
   Maulik U, 2009, PATTERN RECOGN, V42, P2135, DOI 10.1016/j.patcog.2009.01.011
   Mukherjee S.N., 2003, SIGKDD Explor. Newsl, V5, P16, DOI DOI 10.1145/980972.980976
   Mukhopadhyay A, 2014, IEEE ACM T COMPUT BI, V11, P1170, DOI 10.1109/TCBB.2014.2323065
   Ogata H, 1999, NUCLEIC ACIDS RES, V27, P29, DOI 10.1093/nar/27.1.29
   Parsopoulos KE, 2010, PARTICLE SWARM OPTIMIZATION AND INTELLIGENCE: ADVANCES AND APPLICATIONS, P1, DOI 10.4018/978-1-61520-666-7
   Pinero J., 2016, Nucleic acids research
   Sayers EW, 2012, NUCLEIC ACIDS RES, V40, pD13, DOI [10.1093/nar/gks1189, 10.1093/nar/gky1069, 10.1093/nar/gkr1184]
   Seo M, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0040419
   Sethi R, 2019, MULTIMED TOOLS APPL, V78, P31823, DOI 10.1007/s11042-019-07938-x
   Shin Y, 2015, 2015 INTERNATIONAL CONFERENCE ON CLOUD AND AUTONOMIC COMPUTING (ICCAC), P220, DOI 10.1109/ICCAC.2015.23
   Shipp MA, 2002, NAT MED, V8, P68, DOI 10.1038/nm0102-68
   Su J, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S6-S8
   Troyanskaya OG, 2002, BIOINFORMATICS, V18, P1454, DOI 10.1093/bioinformatics/18.11.1454
   Wang K, 2007, AM J HUM GENET, V81, P1278, DOI 10.1086/522374
   Wang XM, 2019, BMC MED GENOMICS, V12, DOI 10.1186/s12920-018-0466-3
   Wang YH, 2005, BIOINFORMATICS, V21, P1530, DOI 10.1093/bioinformatics/bti192
   WELCH BL, 1947, GEN STUDENTS PROBLEM, V34
   Xiao YF, 2014, BIOINFORMATICS, V30, P801, DOI 10.1093/bioinformatics/btr671
NR 50
TC 2
Z9 2
U1 2
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30283
EP 30303
DI 10.1007/s11042-020-09269-8
EA SEP 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000572335500003
DA 2024-07-18
ER

PT J
AU Avani, VS
   Shaila, SG
   Vadivel, A
AF Avani, V. Suma
   Shaila, S. G.
   Vadivel, A.
TI Interval graph of facial regions with common intersection salient points
   for identifying and classifying facial expression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotions; Facial expressions; Interval graph; Salient points;
   Deformation; Direction
ID EMOTION RECOGNITION; TRACKING; FACE; LANDMARKS; FEATURES
AB Measuring the facial expression is an important research and used in many real-time applications. Various methods are proposed in the academia and industry for a decade and still continue to have research potential. This paper proposes a novel scheme by using Interval graph of facial regions. It is assumed that common intersecting salient points of facial regions can be used for estimating the emotions. The facial region is decomposed in four sub regions and the Interval graph is extracted for each region. The common salient points and degree of deformation and direction of deformation are measured for vertical, horizontal and diagonal directions. These values are considered as feature vectors. The well-known datasets such as JAFEE and CK++ are used for evaluating the performance of various classification algorithms and estimating their average classification accuracy. The average classification of the proposed approach is 95.9% and 94.7% for CK++ dataset and JAFEE dataset respectively. The performance of the proposed approach is better when compared to other state of art approaches.
C1 [Avani, V. Suma; Shaila, S. G.] Dayananda Sagar Univ, Dept CSE, Bangalore, Karnataka, India.
   [Vadivel, A.] SRM Univ, Dept CSE, Amaravati, Andra Pradesh, India.
C3 SRM University-AP
RP Vadivel, A (corresponding author), SRM Univ, Dept CSE, Amaravati, Andra Pradesh, India.
EM sumaavani2@gmail.com; shaila-cse@dsu.edu.in; vadivel.a@srmap.edu.in
RI A, Vadivel/AAX-2522-2020
OI A, Vadivel/0000-0002-0884-4676; AVANI, V SUMA/0000-0001-7296-2768
CR [Anonymous], 2012, 11 WSEAS INT C EL HA
   [Anonymous], 2014, REAL TIME EMOTION RE
   [Anonymous], 2015, INT C ADV MECH ENG I, DOI DOI 10.2991/AMEII-15.2015.271
   [Anonymous], 2001, VIP 00
   Bashir Y, 2017, MOLECULES, V22, DOI 10.3390/molecules22060867
   Batur AU, 2005, IEEE T IMAGE PROCESS, V14, P1707, DOI 10.1109/TIP.2005.854473
   Castrillón M, 2011, MACH VISION APPL, V22, P481, DOI 10.1007/s00138-010-0250-7
   Castrillon-Santana Modesto, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P82, DOI 10.1007/978-3-642-33275-3_10
   Chen HT, 2004, INT C PATT RECOG, P736
   Chen XW, 2003, PATTERN RECOGN LETT, V24, P1295, DOI 10.1016/S0167-8655(02)00371-9
   Chien SI, 2000, LECT NOTES COMPUT SC, V1811, P379
   Cohen I, 2003, IEEE COMP SOC C COMP, pI
   Corcoran P, 2007, INT S SIGN CIRC SYST, V1, P1
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Darwin C., 1872, P374
   Ding Y, 2017, IEEE ACCESS, V5
   Donahue J, 2014, PR MACH LEARN RES, V32
   Ekman P., 1978, Facial action coding system
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fasel B, 2000, INT C PATT RECOG, P1100, DOI 10.1109/ICPR.2000.905664
   Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445
   Geetha A, 2009, EXPERT SYST APPL, V36, P303, DOI 10.1016/j.eswa.2007.09.002
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   HaqMU SA, 2019, KSII T INTERNET INF, V13, P3144
   He C, 2011, LECT NOTES COMPUTER, V7106
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Kahou SE, 2015, LECT NOTES COMPUT SC, V8926, P135, DOI 10.1007/978-3-319-16181-5_10
   Khan H, 2020, NEUROCOMPUTING, V381, P141, DOI 10.1016/j.neucom.2019.10.005
   Kim YK, 2015, ADV SCI LETT, V107, P57, DOI [10.14257/astl.2015.107.14, DOI 10.14257/ASTL.2015.107.14]
   Ko KE, 2010, LECT NOTES ARTIF INT, V6424, P702, DOI 10.1007/978-3-642-16584-9_67
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee YH, 2015, MULTIMED TOOLS APPL, V74, P8821, DOI 10.1007/s11042-013-1565-y
   Liang S, 2013, IEEE ENG MED BIO, P6482, DOI 10.1109/EMBC.2013.6611039
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Ma L, 2004, IEEE T SYST MAN CY B, V34, P1588, DOI 10.1109/TSMCB.2004.825930
   Mahmood Z, 2019, MULTIDIM SYST SIGN P, V30, P1991, DOI 10.1007/s11045-019-00639-6
   Mahmood Z, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17500256
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Nguyen HT, 2004, IEEE T PATTERN ANAL, V26, P1099, DOI 10.1109/TPAMI.2004.45
   Pali V, 2014, 2014 6TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS, P142, DOI 10.1109/CICN.2014.43
   Pardàs M, 2002, INT CONF ACOUST SPEE, P3624
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Qi C, 2018, IEEE ACCESS, V6, P18795, DOI 10.1109/ACCESS.2018.2816044
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Su C, 2010, LECT NOTES ARTIF INT, V6334, P346
   Susskind JM, 2007, NEUROPSYCHOLOGIA, V45, P152, DOI 10.1016/j.neuropsychologia.2006.05.001
   Swaminathan A, 2022, IETE J RES, V68, P3235, DOI 10.1080/03772063.2020.1756471
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang L, 2014, INT J CONTROL AUTOM, V12, P459, DOI 10.1007/s12555-013-0361-9
   Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853
   Yang WK, 2017, MULTIMED TOOLS APPL, V76, P4491, DOI 10.1007/s11042-016-3446-7
   Yoshikawa H, 2011, PROCEEDINGS OF THE 18TH INTERNATIONAL CONFERENCE ON NUCLEAR ENGINEERING 2010, VOL 1, P131
   Zhou F, 2020, NEUROCOMPUTING, V392, P38
NR 60
TC 4
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3367
EP 3390
DI 10.1007/s11042-020-09806-5
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000571689900001
DA 2024-07-18
ER

PT J
AU Al-Radhi, MS
   Csapó, TG
   Németh, G
AF Al-Radhi, Mohammed Salah
   Csapo, Tamas Gabor
   Nemeth, Geza
TI Noise and acoustic modeling with waveform generator in text-to-speech
   and neutral speech conversion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech synthesis; Vocoder; Temporal envelope; Neural network; Voice
   conversion
ID DYNAMIC-PROGRAMMING ALGORITHM; DEEP NEURAL-NETWORKS; VOICE CONVERSION;
   ENVELOPE; EXTRACTION; VOCODER; HMM
AB This article focuses on developing a system for high-quality synthesized and converted speech by addressing three fundamental principles. Although the noise-like component in the state-of-the-art parametric vocoders (for example, STRAIGHT) is often not accurate enough, a novel analytical approach for modeling unvoiced excitations using a temporal envelope is proposed. Discrete All Pole, Frequency Domain Linear Prediction, Low Pass Filter, and True envelopes are firstly studied and applied to the noise excitation signal in our continuous vocoder. Second, we build a deep learning model based text-to-speech (TTS) which converts written text into human-like speech with a feed-forward and several sequence-to-sequence models (long short-term memory, gated recurrent unit, and hybrid model). Third, a new voice conversion system is proposed using a continuous fundamental frequency to provide accurate time-aligned voiced segments. The results have been evaluated in terms of objective measures and subjective listening tests. Experimental results showed that the proposed models achieved the highest speaker similarity and better quality compared with the other conventional methods.
C1 [Al-Radhi, Mohammed Salah; Csapo, Tamas Gabor; Nemeth, Geza] Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Budapest, Hungary.
   [Csapo, Tamas Gabor] MTA ELTE Lendulet Lingual Articulat Res Grp, Budapest, Hungary.
C3 Budapest University of Technology & Economics; Eotvos Lorand University
RP Al-Radhi, MS (corresponding author), Budapest Univ Technol & Econ, Dept Telecommun & Media Informat, Budapest, Hungary.
EM malradhi@tmit.bme.hu; csapot@tmit.bme.hu; nemeth@tmit.bme.hu
RI Al-Radhi, Mohammed Salah/C-9727-2018; Nemeth, Geza/N-1734-2013
OI Al-Radhi, Mohammed Salah/0000-0003-3094-6916; Nemeth,
   Geza/0000-0002-2311-4858
FU European Union's Horizon 2020 research and innovation programme (AI4EU)
   [825619]; National Research Development and Innovation Office of Hungary
   [FK 124584, PD 127915]; Budapest University of Technology and Economics;
   H2020 - Industrial Leadership [825619] Funding Source: H2020 -
   Industrial Leadership
FX The research was partly supported by the European Union's Horizon 2020
   research and innovation programme under grant agreement No. 825619
   (AI4EU), and by the National Research Development and Innovation Office
   of Hungary (FK 124584 and PD 127915). The Titan X GPU used was donated
   by NVIDIA Corporation. We would like to thank the subjects for
   participating in the listening test.; Open access funding provided by
   Budapest University of Technology and Economics.
CR Al-Radhi MS, 2017, INTERSPEECH, P434, DOI 10.21437/Interspeech.2017-678
   Al-Radhi MS, 2017, LECT NOTES ARTIF INT, V10458, P282, DOI 10.1007/978-3-319-66429-3_27
   [Anonymous], 2016, P INT SPEECH COMM AS
   [Anonymous], 2010, P INT SPEECH COMM AS
   [Anonymous], 1985, THESIS
   Athineos M, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P261, DOI 10.1109/ASRU.2003.1318451
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Cabral Joao P., 2013, Advances in Nonlinear Speech Processing. 6th International Conference, NOLISP 2013. Proceedings. LNCS 7911, P67, DOI 10.1007/978-3-642-38847-7_9
   Csapo Tamas Gabor, 2015, Statistical Language and Speech Processing. Third International Conference, SLSP 2015. Proceedings: LNCS 9449, P27, DOI 10.1007/978-3-319-25789-1_4
   Degottex G, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-014-0038-1
   Desai S, 2009, INT CONF ACOUST SPEE, P3893, DOI 10.1109/ICASSP.2009.4960478
   Ding C, 2015, MULTIMED TOOLS APPL, V74, P9871, DOI 10.1007/s11042-014-2156-2
   Drugman Thomas, 2014, IEEE Signal Processing Letters, V21, P1230, DOI 10.1109/LSP.2014.2332186
   Drugman T, 2012, IEEE T AUDIO SPEECH, V20, P968, DOI 10.1109/TASL.2011.2169787
   DRULLMAN R, 1995, J ACOUST SOC AM, V97, P585, DOI 10.1121/1.413112
   ELJAROUDI A, 1991, IEEE T SIGNAL PROCES, V39, P411, DOI 10.1109/78.80824
   Espic F, 2017, INTERSPEECH, P1383, DOI 10.21437/Interspeech.2017-1647
   Fan Y, 1964, P INT SING
   Fisher N. I., 1993, STAT ANAL CIRCULAR D, DOI DOI 10.1017/CBO9780511564345
   Garner PN, 2013, IEEE SIGNAL PROC LET, V20, P102, DOI 10.1109/LSP.2012.2231675
   Heiga Zen, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3844, DOI 10.1109/ICASSP.2014.6854321
   Herre J, 1996, P 101 AUD ENG SOC CO
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu Q., 2013, Proc. ISCA SSW8, P155
   Imai S., 1983, Electr. Commun. Jpn., V66, P10, DOI [DOI 10.1002/ECJA.4400660203, DOI 10.1002/ecja.4400660203]
   *ITU R, 2001, BS1534 ITUR
   Kaneko T, 2017, INTERSPEECH, P1283, DOI 10.21437/Interspeech.2017-970
   Kawahara H, 1999, SPEECH COMMUN, V27, P187, DOI 10.1016/S0167-6393(98)00085-5
   Kobayashi K., 2018, SPEAK LANG REC WORKS, P203
   Kominek J., 2003, CMU ARCTIC DATABASES
   Kotani G, 2017, ASIAPAC SIGN INFO PR, P1218, DOI 10.1109/APSIPA.2017.8282216
   Li XL, 2018, MULTIMED TOOLS APPL, V77, P29847, DOI 10.1007/s11042-018-5856-1
   Ma JF, 2009, J ACOUST SOC AM, V125, P3387, DOI 10.1121/1.3097493
   Maia R, 1833, P INT
   Morise M., 2010, The IEICE Transactions on Information and Systems, VJ93-D, P109
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Morise M, 2015, SPEECH COMMUN, V67, P1, DOI 10.1016/j.specom.2014.09.003
   Najafabadi MM, 2015, Journal of big data, V2, P1, DOI [10.1186/s40537-014-0007-7, DOI 10.1186/S40537-014-0007-7]
   Nakamura K, 2012, SPEECH COMMUN, V54, P134, DOI 10.1016/j.specom.2011.07.007
   Nakashika T, 2013, INTERSPEECH, P369
   Nakashika T, 2014, IEICE T INF SYST, VE97D, P1403, DOI 10.1587/transinf.E97.D.1403
   NEY H, 1984, IEEE T ACOUST SPEECH, V32, P263, DOI 10.1109/TASSP.1984.1164320
   Pantazis Y, 2008, INT CONF ACOUST SPEE, P4609, DOI 10.1109/ICASSP.2008.4518683
   Quackenbush S.R., 1988, Objective Measures of Speech Quality
   Robel A., 2005, 8th International Conference on Digital Audio Effects, DAFx 2005 Proceedings, P30
   Röbel A, 2007, PATTERN RECOGN LETT, V28, P1343, DOI 10.1016/j.patrec.2006.11.021
   Saito Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5274, DOI 10.1109/ICASSP.2018.8461384
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472
   Stylianou Y, 2001, IEEE T SPEECH AUDI P, V9, P21, DOI 10.1109/89.890068
   Sun LF, 2015, INT CONF ACOUST SPEE, P4869, DOI 10.1109/ICASSP.2015.7178896
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Toda T, 2012, IEEE T AUDIO SPEECH, V20, P2505, DOI 10.1109/TASL.2012.2205241
   Tokuda K., 1994, ICSLP 94. 1994 International Conference on Spoken Language Processing, P1043
   Tokuda K, 2002, IEICE T INF SYST, VE85D, P455
   Villavicencio F, 2006, INT CONF ACOUST SPEE, P869
   Wu Z., 2016, SSW, P202, DOI DOI 10.21437/SSW.2016-33
   Wu ZZ, 2015, INT CONF ACOUST SPEE, P4460, DOI 10.1109/ICASSP.2015.7178814
   Wu ZZ, 2015, MULTIMED TOOLS APPL, V74, P9943, DOI 10.1007/s11042-014-2180-2
   Yu K, 2011, IEEE T AUDIO SPEECH, V19, P1071, DOI 10.1109/TASL.2010.2076805
   Zen HG, 2013, INT CONF ACOUST SPEE, P7962, DOI 10.1109/ICASSP.2013.6639215
   Zen H, 2009, SPEECH COMMUN, V51, P1039, DOI 10.1016/j.specom.2009.04.004
NR 63
TC 3
Z9 3
U1 4
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 1969
EP 1994
DI 10.1007/s11042-020-09783-9
EA SEP 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000568184100008
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Kovelan, P
   Kartheeswaran, T
   Thisenthira, N
AF Kovelan, Parameswaran
   Kartheeswaran, Thangathurai
   Thisenthira, Nadarajah
TI A GPS controlled automated soil testing rover
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automation; Soil parameters; Rover; pH sensor; Agriculture
ID SYSTEM
AB This study proposes A GPS controlled Automated Soil testing Rover to test the soil for agricultural purposes. The contribution of computer science to agriculture is essential for the sustainability of human beings in the world by keeping food production up to a satisfactory level. The automation technology is a suitable and efficient solution to overcome difficulties in agriculture. This technique will increase the productivity and reduces the hardness of human effort in the field. The traditional soil testing mechanism has many difficulties and drawbacks such as time-consuming, poor knowledge of sample collection and variation in laboratory results compared to field results. The proposed GPS controlled Automated Soil testing Rover will be a solid solution to overcome the problems of the traditional soil testing mechanism. The device has a temperature, moisture and pH sensors to measure the soil parameters such as temperature, moisture, electro conductivity, and pH. The GPS controlled Automated Soil testing Rover will be able to navigate in the given area of the field with the guidance of GPS and it is capable of avoiding obstacles in the field. The data sensed will be sent to a website to get visualized and will be stored in a database. Also, the data is used to select the suitable crop based on the parameters sensed.
C1 [Kovelan, Parameswaran; Kartheeswaran, Thangathurai; Thisenthira, Nadarajah] Univ Jaffna, Dept Phys Sci, Vavuniya Campus, Vavuniya 43000, Sri Lanka.
C3 University Jaffna
RP Kartheeswaran, T (corresponding author), Univ Jaffna, Dept Phys Sci, Vavuniya Campus, Vavuniya 43000, Sri Lanka.
EM pkovelan5@gmail.com; karthees@vau.jfn.ac.lk; thisa93@gmail.com
RI Kartheeswaran, Thangathurai/AAP-6365-2021; Thangathurai,
   Kartheeswaran/M-7281-2016
OI Kartheeswaran, Thangathurai/0000-0001-7265-3922; Thangathurai,
   Kartheeswaran/0000-0001-7265-3922
CR Al-Faiz MZ, 2015, GPS BASED NAVIGATED, V4, P3
   [Anonymous], 2013, EXPR SMART CONN PLAT
   Athani S., 2017, INT C I SMAC IOT SOC
   Balakrishna K, 2018, INT J COMPUT SCI ENG, V6, P837
   Boopathy S, 2016, INT J MODERN COMPUT, V4, P3
   Boopathy S, 2014, INT J ENG RES TECHNO, V3, P10
   Bugai T, 2013, GPS GUIDED AUTONOMOU
   Chandramohan J, 2015, INTELLIGENT SMART HO, V6, P20694, DOI 10.18535/ijecs/v6i3.53
   Chavan C.H., 2014, International Journal of Engineering Trends and Technology (IJETT), V11, P493, DOI DOI 10.14445/22315381/IJETT-V11P296
   Hong Z., 2016, 2016 IEEE INT C SMAR, P1, DOI [10.1109/SMARTCOMP.2016.7501673, DOI 10.1109/SMARTCOMP.2016.7501673]
   Jung SJ, 2013, IEEE SENSOR, P792
   Lawlor L, 2014, THINGSPEAK
   NEVO A, 1994, AGR SYST, V45, P73, DOI 10.1016/S0308-521X(94)90281-X
   Paradkar A.D., 2016, GPS GUIDED AUTONOMOUS ROBOT
   Roser M., 2018, Employment in Agriculture
   Snehal K, 2018, INT J FUTURE REVOL C, V4, P467
   Srividyadevi P, 2013, MEASUREMENT POWER EN, V2
   Suresh DS, 2013, ITSI T ELECT ELECT E, V1, P115
   Traunfeld K, 2017, HOME GARDEN INFORM C
   Yen KS, APPL HIGH SENSITIVIT
   Yuksel T, 2005, TECHNICAL REPORT
NR 21
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1273
EP 1287
DI 10.1007/s11042-020-09358-8
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566871700008
DA 2024-07-18
ER

PT J
AU Sankaranarayanan, M
   Mala, C
   Mathew, S
AF Sankaranarayanan, Manipriya
   Mala, C.
   Mathew, Samson
TI Pre-processing framework with virtual mono-layer sequence of boxes for
   video based vehicle detection applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent Transportation Systems (ITS); Pre-processing; Background
   classification; Video image processing; Vehicle detection; Background
   subtraction; Multilevel parallelism
ID TRACKING; MODEL
AB The increase in day to day vehicular traffic demands an efficient, automated and innovative approach for its management and regulation. One of the most practical and commonly used Intelligent Transportation Systems (ITS) based solution in recent times is video based traffic monitoring. The primary task of such systems is vehicle detection and the existing methods are not robust enough to handle diverse backgrounds and illumination changes in the traffic video. In order to address this issue, a Pre-processing Framework with Virtual Mono-Layered Sequence of Boxes (PF-VMSB) is proposed to make any vehicle detection process robust and efficient. The two composite modules of the proposed system include Effective Element Estimation (E3) module and Dynamic Multilevel Parallel Video Image Processing (D-MPVIP) module. The E3 module enhances the illumination of the traffic video only when necessary to produce an ideal environment for detection. Further, it classifies the type of background in video content (Static, Moderate or Dynamic) to provide an option to choose the appropriate image processing algorithm suitable for vehicle detection. In D-MPVIP module, the redundant video content are eliminated from processing to reduce the computational cost and processing time. Additionally, the spatial color information of the traffic video content is preserved and processed in parallel.The efficiency of the proposed framework of VMSB with E3 and D-MPVIP were analysed using benchmark datasets such as DETRAC, Urban Trackr, Ko-per and self recorded videos. The results shows an overall accuracy of detection rate using conventional image processing techniques such as Background Subtraction (BS) increases by 34.6% and the processing time is reduced by 37.5%. By incorporating the proposed framework into any vehicle detection process, the processing time and computational cost are improved without compromising the detection accuracy. The resultant of the detection process can be utilized by ITS application to enumerate traffic parameters such as vehicle volume count, congestion estimation, speed monitoring, travel time prediction, etc.
C1 [Sankaranarayanan, Manipriya; Mala, C.] Natl Inst Technol Tiruchirappalli, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
   [Mathew, Samson] Natl Inst Technol Tiruchirappalli, Dept Civil Engn, Tiruchirappalli, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Tiruchirappalli; National Institute of Technology (NIT
   System); National Institute of Technology Tiruchirappalli
RP Sankaranarayanan, M (corresponding author), Natl Inst Technol Tiruchirappalli, Dept Comp Sci & Engn, Tiruchirappalli, Tamil Nadu, India.
EM grtmanipriya@gmail.com; mala@nitt.edu; sams@nitt.edu
RI SankaraNarayanan, Manipriya/AAR-9669-2021; C, MALA/ABB-3659-2021
OI SankaraNarayanan, Manipriya/0000-0002-0973-2131; 
CR Atibi M, 2015, PROCEDIA COMPUT SCI, V73, P24, DOI 10.1016/j.procs.2015.12.044
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bouwmans T, 2019, CURRENT MODELS FUTUR
   Chen ZZ, 2014, COMPUT VIS IMAGE UND, V122, P35, DOI 10.1016/j.cviu.2014.01.004
   El Baf F, 2008, IEEE INT CONF FUZZY, P1731
   Gonzalez R., 2017, DIGITAL IMAGE PROCES
   Induja C., 2018, J RES APPL SCI ENG T, V6, P4471, DOI DOI 10.22214/ijraset.2018.4732
   KaewTraKulPong P, 2002, VIDEO-BASED SURVEILLANCE SYSTEMS: COMPUTER VISION AND DISTRIBUTED PROCESSING, P135
   Kamkar S, 2016, IET INTELL TRANSP SY, V10, P406, DOI 10.1049/iet-its.2015.0157
   Kanagamalliga S, 2016, MIDDLE E J SCI RES, V24, P51, DOI DOI 10.5829/IDOSI.MEJSR.2016.24.IIECS.23139
   Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0
   Kyungnam TH, 2005, REAL TIME FOREGROUND
   Liang D, 2015, PATTERN RECOGN, V48, P1374, DOI 10.1016/j.patcog.2014.10.020
   Manich Bou S., 2015, DCIS'15-XXX Conference on Design of Circuits and Integrated Systems, P1
   Manipriya S, 2014, IERI PROC, V10, P63, DOI 10.1016/j.ieri.2014.09.092
   Manipriya S, 2016, P 5 INT C COMP COMM
   Monika, 2017, IEEE PUBL INT C EL E
   Mu KN, 2016, J INF PROCESS SYST, V12, P183, DOI 10.3745/JIPS.02.0040
   Piccardi M, 2004, P IEEE INT C SYST MA, V4
   Robert PL, 2017, COMPUTER VISION IMAG, V1
   Seenouvong W, 2016, P INT JOINT C COMP S, P1
   Shah M, 2014, MACH VISION APPL, V25, P1105, DOI 10.1007/s00138-013-0552-7
   Sivasamy P, 2016, INDIAN J SCI TECHNOL, V9
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Taha M, 2017, INT J COMPUTER ELECT, V10, P93
   Ershadi NY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0191355
   Yang S, 2012, ELECTRON LETT, V48, P995, DOI 10.1049/el.2012.1922
   Yang Z, 2018, IMAGE VISION COMPUT, V69, P143, DOI 10.1016/j.imavis.2017.09.008
   Zhang YS, 2016, IET INTELL TRANSP SY, V10, P445, DOI 10.1049/iet-its.2015.0141
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 30
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 1095
EP 1122
DI 10.1007/s11042-020-09587-x
EA SEP 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566665500003
DA 2024-07-18
ER

PT J
AU Molero, D
   Schez-Sobrino, S
   Vallejo, D
   Glez-Morcillo, C
   Albusac, J
AF Molero, D.
   Schez-Sobrino, S.
   Vallejo, D.
   Glez-Morcillo, C.
   Albusac, J.
TI A novel approach to learning music and piano based on mixed reality and
   gamification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Learning music; Mixed reality; Gamification; Piano
ID AUGMENTED REALITY; STUDENTS
AB Learning music has been demonstrated to provide many benefits for children. However, music students, especially beginners, often suffer from lack of motivation and even can be frustrated if their musical skills do not improve as they practice over and over. In such situations, they usually end up dropping out of music school. To face this challenge, in this work a novel approach based on mixed reality and gamification is proposed to motivate music students. This approach has been validated thanks to HoloMusic XP, a multimedia tool that helps students learn music and piano. The devised architecture that supports HoloMusic XP has been designed and developed to scale when new music concepts must be addressed. Thanks to the use of mixed reality, the usually steep learning curve for beginner students can be mitigated and complex music concepts can be simplified due to the use of visual metaphors. The system has been evaluated in a real environment by teachers and students to measure its effectiveness and usability. After conducting the experiments, an increase in the students' motivation and a general understanding of the multimedia representation have been achieved.
C1 [Molero, D.; Schez-Sobrino, S.; Vallejo, D.; Glez-Morcillo, C.; Albusac, J.] Univ Castilla La Mancha, Paseo Univ 4, Ciudad Real 13071, Spain.
C3 Universidad de Castilla-La Mancha
RP Vallejo, D (corresponding author), Univ Castilla La Mancha, Paseo Univ 4, Ciudad Real 13071, Spain.
EM David.Vallejo@uclm.es
RI Sánchez, Santiago/HPH-3304-2023; Morcillo, Carlos Gonzalez/I-2361-2015
OI Albusac Jimenez, Javier Alonso/0000-0003-1889-3065; Schez-Sobrino,
   Santiago/0000-0001-6620-1719
FU Department of Technologies and Information Systems [00421372];
   University of Castilla-La Mancha (AIR Research Group) [2020-GRIN-28886]
FX This research was partially funded by the Department of Technologies and
   Information Systems (grant number 00421372) and by the University of
   Castilla-La Mancha (AIR Research Group, grant number 2020-GRIN-28886).
CR Akçayir M, 2017, EDUC RES REV-NETH, V20, P1, DOI 10.1016/j.edurev.2016.11.002
   [Anonymous], 2013, P 14 AUSTR US INT C, DOI DOI 10.5555/2525493.2525501
   Cai Minya, 2019, 2019 IEEE 8th Global Conference on Consumer Electronics (GCCE), P49, DOI 10.1109/GCCE46687.2019.9015530
   Chou Y.-K., 2013, Octalysis: A Complete Gamification Framework
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   Costa-Giomi E, 2005, J RES MUSIC EDUC, V53, P234, DOI 10.2307/3598682
   Costanza Peter, 2017, CRITICAL ESSAYS MUSI, V1, P255, DOI DOI 10.4324/9781315095257-14
   Dannenberg RB, 1990, ICMC
   DAVIS FD, 1993, INT J MAN MACH STUD, V38, P475, DOI 10.1006/imms.1993.1022
   Degli Innocenti E, 2019, COMPUT EDUC, V139, P102, DOI 10.1016/j.compedu.2019.04.010
   Feng Huang, 2011, 2011 International Conference on Intelligent Human-Machine Systems and Cybernetics, P47, DOI 10.1109/IHMSC.2011.82
   Fletcher C, 2019, INT CONF GAMES VIRTU, P222, DOI 10.1109/vs-games.2019.8864592
   Hackl D., 2017, P 10 FORUM MEDIA TEC, P140
   Jun Yin, 2005, 13th Annual ACM International Conference on Multimedia, P976, DOI 10.1145/1101149.1101353
   Kalantari M, 2018, PROGR IS, P229, DOI 10.1007/978-3-319-64027-3_16
   Martin-Gutierrez J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072425
   McPherson GE, 2010, RES STUD MUSIC EDUC, V32, P101, DOI 10.1177/1321103X10384202
   Molloy W, 2019, 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC), P178, DOI 10.23919/elinfocom.2019.8706474
   MOOG B, 1986, J AUDIO ENG SOC, V34, P394
   Overy K., 1998, Psychology of Music, V26, P97, DOI DOI 10.1177/0305735698261009
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Pesek M, 2020, IEEE ACCESS, V8, P97090, DOI 10.1109/ACCESS.2020.2994389
   Rusiñol M, 2018, MULTIMED TOOLS APPL, V77, P13773, DOI 10.1007/s11042-017-4991-4
   Smoliar SW, 1995, ACM MULTIMEDIA, V95
   Del Rio-Guerra MS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9214527
   Walsh Andrew, 2009, Library Hi Tech News, V26, P7, DOI 10.1108/07419050910985255
   Zeng H, 2019, J PHYS CONF SER, V1229, DOI 10.1088/1742-6596/1229/1/012072
NR 27
TC 17
Z9 18
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 165
EP 186
DI 10.1007/s11042-020-09678-9
EA SEP 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000565163400003
DA 2024-07-18
ER

PT J
AU Kumari, M
   Gupta, S
   Malik, A
AF Kumari, Manju
   Gupta, Shailender
   Malik, Anjali
TI A superlative image encryption technique based on bit plane using
   key-based electronic code book
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bit plane scrambling; Block cipher; Confusion; Cryptanalysis;
   Cryptography; Diffusion; Electronic code book; Encryption; Initial
   permutation block; Quantum chaotic map
ID SCHEME
AB To contend with the growing concern of information security, firms are espousing cryptography for protection. To comprehend this need, the paper proposes a block cipher that ensures confidentiality and secrecy for secure data communication network. A high-quality cryptographic process ensures high entropy, high key sensitivity, ability to resist known plaintext and chosen-plaintext attack, high speed of execution, high key space, high randomness and resistance towards differential attack. In projected work, encryption mechanism is comprises of multiple processes and each process is devised key dependent utilizing diverse keys to ensure high key sensitivity and vast resistance power towards differential attack. The keys are generated using contemporary encryption process- the quantum chaotic map due to its high randomness and non periodicity, which includes confusion and diffusion processes. For the confusion process, Electronic Code Book (ECB), Initial Permutation (IP), Bit plane scrambling, and Inter bit plane scrambling are employed. The ECB and IP, being matching processes are chosen for high speed of execution.Bit level permutation unlike byte level is applied to reinforce randomness, in conjunction with variable number of rounds as per the security key. For diffusion process, the folding technique is used along eight directions, exploiting different keys. To reveal the efficacy of the proposed methodology, it is compared with the existing renowned methods on the basis of Cryptanalysis, Perceptibility analysis, Statistical analysis, etc. It is asserted that results such as differential attack, cryptanalysis, and key space analysis are reasonably enhanced than others while entropy and speed of execution are at equivalence with other techniques.
C1 [Kumari, Manju; Gupta, Shailender; Malik, Anjali] JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
C3 J.C. Bose University of Science & Technology, YMCA
RP Malik, A (corresponding author), JC Bose Univ Sci & Technol, YMCA, Faridabad, Haryana, India.
EM manjunimesh88@gmail.com; shailender81@gmail.com;
   anjalimalik0611@gmail.com
RI gupta, shailender/Y-8231-2019
OI gupta, shailender/0000-0003-1383-7152; Malik, Anjali/0009-0006-9598-3522
CR Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Ahmed HAM, 2007, INZ MINER, P1
   Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Akhshani A, 2012, COMMUN NONLINEAR SCI, V17, P4653, DOI 10.1016/j.cnsns.2012.05.033
   Anderson T. W., 1958, INTRO MULTIVARIATE S, V2
   [Anonymous], 2014, P INT J INN RES ADV
   [Anonymous], RESEARCH-CHINA, DOI DOI 10.18502/JDER.4069
   Bansal R, 2017, MULTIMED TOOLS APPL, V76, P16529, DOI 10.1007/s11042-016-3926-9
   Barker E, 2017, NIST Special Publication (SP) 800-67 Rev. 2 (Draft))
   Basu Sandipan., 2011, Journal of global research in Computer Science, V2, P116
   François M, 2012, SIGNAL PROCESS-IMAGE, V27, P249, DOI 10.1016/j.image.2011.11.003
   Hanchinamani G, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0062-7
   Hui Liu, 2017, International Journal of Network Security, V19, P347, DOI 10.6633/IJNS.201703.19(3).04
   Kester QA, 2013, ARXIV13077786
   Kumari M, 2018, 3D RES, V9, DOI 10.1007/s13319-018-0162-2
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu XB, 2019, IEEE ACCESS, V7, P6937, DOI 10.1109/ACCESS.2018.2889896
   Matsui M., 1994, Advances in Cryptology - CRYPTO '94. 14th Annual International Cryptology Conference. Proceedings, P1
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mousa A., 2006, Int. J. Comput. Sci. Appl., V3, P44
   Ran QW, 2015, OPT COMMUN, V348, P43, DOI 10.1016/j.optcom.2015.03.016
   Rayarikar R., 2012, Int J Comput Appl, V50, P12
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   SCHNEIER B, 1994, DR DOBBS J, V19, P38
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
NR 28
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 33161
EP 33191
DI 10.1007/s11042-020-09627-6
EA AUG 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000567296800001
DA 2024-07-18
ER

PT J
AU Fotopoulou, F
   Economou, G
AF Fotopoulou, Foteini
   Economou, George
TI 3D shape clustering with Nonnegative Least Squares coding and fusion on
   multilayer graphs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D shape clustering; Sparse representation; Nonnegative least squares;
   Laplace-Beltrami; Spectral clustering; Graph fusion
ID AFFINITY AGGREGATION; OBJECT RETRIEVAL; DESCRIPTORS
AB The well-known method of spectral clustering for 3D shape datasets is revisited. The graph construction by NNLS (Nonnegative Least Squares) coding technique is at the core of our method. Using graph-based encoding techniques and well-known shape descriptors, a framework is presented here which is applied to 3D shape clustering. Provided a shape database, a graph is first constructed. Weights in the graph are calculated so as to approximate each shape as a sparse linear combination of the remaining dataset objects. This framework is further enhanced by using the multilayer graphs process combining NNLS with L2graph. The L2graph is a sparse similarity graph, which conveys complementary information to NNLS coding. A criterion for the complementary action of the two graphs in terms of graph distance is also presented. Experimental results conducted on SHREC10, SHREC11 and SCHREC15 datasets validate the excellent performance of our clustering framework.
C1 [Fotopoulou, Foteini] Univ Patras, Dept Comp Engn & Informat, Patras 26500, Greece.
   [Economou, George] Univ Patras, Dept Phys, Elect Lab, Patras 26500, Greece.
C3 University of Patras; University of Patras
RP Fotopoulou, F (corresponding author), Univ Patras, Dept Comp Engn & Informat, Patras 26500, Greece.
EM fotopoulou@ceid.upatras.gr
OI Fotopoulou, Foteini/0000-0002-0916-3047; Economou,
   George/0000-0001-9938-0768
CR Ben Hamza A, 2016, NEUROCOMPUTING, V211, P11, DOI 10.1016/j.neucom.2015.12.130
   Ben Hamza A, 2016, KNOWL-BASED SYST, V92, P92, DOI 10.1016/j.knosys.2015.10.019
   BLASHFIELD RK, 1991, J CLASSIF, V8, P277
   Bro R, 1997, J CHEMOMETR, V11, P393, DOI 10.1002/(SICI)1099-128X(199709/10)11:5<393::AID-CEM483>3.0.CO;2-L
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Bunke H, 1998, PATTERN RECOGN LETT, V19, P255, DOI 10.1016/S0167-8655(97)00179-7
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Chaudhari AJ, 2014, PHYS MED BIOL, V59, P961, DOI 10.1088/0031-9155/59/4/961
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   Cheng B, 2010, IEEE T IMAGE PROCESS, V19, P858, DOI 10.1109/TIP.2009.2038764
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dong XW, 2014, IEEE T SIGNAL PROCES, V62, P905, DOI 10.1109/TSP.2013.2295553
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Feng Y, 2019, MESHNET MESH NEURAL
   Fotopoulou F, 2019, MULTIMED TOOLS APPL, V78, P34689, DOI 10.1007/s11042-019-08152-5
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Gao ZH, 2014, COMPUT AIDED DESIGN, V53, P62, DOI 10.1016/j.cad.2014.03.008
   Han Song., 2017, University Lecture
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Huang HC, 2012, PROC CVPR IEEE, P773, DOI 10.1109/CVPR.2012.6247748
   Kazmi IK, 2013, 10 INT C COMP GRAPH
   Li CY, 2014, MULTIMEDIA SYST, V20, P253, DOI 10.1007/s00530-013-0318-0
   Li YF, 2013, NEUROCOMPUTING, V118, P41, DOI 10.1016/j.neucom.2013.02.012
   Lian Z., 2010, Eurographics Workshop on 3D Object Retrieval, V10, P101, DOI [10.2312/3DOR/3DOR10/101-108, 10.1109/CVPR.2014.491, DOI 10.2312/3DOR/3DOR10/101-108]
   Lian ZH, 2015, 2015 INTERNATIONAL CONFERENCE ON MANAGEMENT SCIENCE AND ENGINEERING, MSE 2015, P1
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Liao BL, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0115888
   LIPMAN Y, 2010, ACM T GRAPHIC, V29
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Luciano L, 2017, DEEP LEARNING GEODES
   Masoumi M, 2015, SHAPE CLASSIFICATION
   Masoumi M, 2017, J VIS COMMUN IMAGE R, V43, P198, DOI 10.1016/j.jvcir.2017.01.001
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Peng X, 2017, IEEE T CYBERNETICS, V47, P1053, DOI 10.1109/TCYB.2016.2536752
   Qiao LS, 2010, PATTERN RECOGN, V43, P331, DOI 10.1016/j.patcog.2009.05.005
   Rabin J, 2010, LECT NOTES COMPUT SC, V6315, P771, DOI 10.1007/978-3-642-15555-0_56
   RAND WM, 1971, J AM STAT ASSOC, V66, P846, DOI 10.2307/2284239
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Schenker A, 2006, ADV INFORM KNOWLEDGE
   Song Bai, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P774, DOI 10.1109/ICCV.2017.90
   Sun MJ, 2018, SIGNAL PROCESS, V149, P118, DOI 10.1016/j.sigpro.2018.03.006
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang C, 2017, FOOD CONTROL, V77, P1, DOI 10.1016/j.foodcont.2017.01.016
   Wang D, 2019, IEEE T MULTIMEDIA, V21, P2071, DOI 10.1109/TMM.2019.2892004
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   WANG ZW, 2016, WORLD SCI, P1, DOI DOI 10.1145/2996884.2996885
   Wu ZZ, 2013, COMPUT GRAPH-UK, V37, P628, DOI 10.1016/j.cag.2013.05.015
   Yang W, 2015, PATTERN RECOGNITION
   Yu HP, 2020, MULTIMED TOOLS APPL, V79, P5743, DOI 10.1007/s11042-019-08493-1
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zheng CH, 2011, IEEE ACM T COMPUT BI, V8, P1273, DOI 10.1109/TCBB.2011.20
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
NR 54
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 32607
EP 32622
DI 10.1007/s11042-020-09668-x
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000564977900003
DA 2024-07-18
ER

PT J
AU Kim, H
   Hong, S
   Kim, J
   Jang, T
   Woo, W
   Heo, S
   Lee, B
AF Kim, Hyunju
   Hong, Sanghwa
   Kim, Junki
   Jang, Taesoo
   Woo, Woontaek
   Heo, Seongkook
   Lee, Byungjoo
TI RealityBrush: an AR authoring system that captures and utilizes kinetic
   properties of everyday objects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Kinetic property; AR authoring
AB This study introduces RealityBrush, a novel augmented reality (AR) authoring system that allows designers to quickly and easily create realistic virtual objects by capturing and utilizing the kinetic properties of everyday physical objects in the early stages of design. The RealityBrush system consists of a handheld device, a data analysis module and an AR feedback module. The handheld device, which is made in the shape of a rod, is equipped with a depth camera and a force sensor at the tip. When a user holds the device and pokes a physical object, the local force applied to the object and the resulting deformations of the object are measured simultaneously. By analyzing the relationship between measured force and deformations, the RealityBrush system can identify two kinetic properties of the poked object: stiffness and motion resistance. The user can then use the handheld device as a 3D brush to create a virtual object in the air and assign the measured kinetic properties to the created virtual object. Finally, the system's physics engine allows the user to interact with the created object by using the device to poke or push the object. The technical evaluation showed that the system can successfully extract the stiffness and motion resistance of everyday objects. We also report initial user feedback on AR authoring using the RealityBrush system.
C1 [Kim, Hyunju; Hong, Sanghwa; Kim, Junki; Jang, Taesoo; Woo, Woontaek; Lee, Byungjoo] Korea Adv Inst Sci & Technol, Daejeon, South Korea.
   [Heo, Seongkook] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
C3 Korea Advanced Institute of Science & Technology (KAIST); University of
   Virginia
RP Lee, B (corresponding author), Korea Adv Inst Sci & Technol, Daejeon, South Korea.
EM byungjoo.lee@kaist.ac.kr
RI Hong, Sanghwa/AAL-1403-2021; Woo, Woontack/C-3696-2012
OI Hong, Sanghwa/0000-0003-1616-5312; Woo, Woontack/0000-0002-5501-4421
FU National Research Foundation of Korea [2020R1A2C4002146]; Korea Creative
   Content Agency [R2019020010]; Ministry of Trade, Industry and Energy
   [10077849]
FX This research was funded by the National Research Foundation of Korea
   (2020R1A2C4002146), the Korea Creative Content Agency (R2019020010), and
   partly by Ministry of Trade, Industry and Energy (10077849).
CR Bickel B, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778800
   Bickel B, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531395
   Bowden FP, 2001, FRICTION LUBRICATION, V1
   Carfagni M, 2017, IEEE SENS J, V17, P4508, DOI 10.1109/JSEN.2017.2703829
   Nguyen C, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P5428, DOI 10.1145/3025453.3025675
   Fernandez-Sanchez EJ, 2013, SENSORS-BASEL, V13, P8895, DOI 10.3390/s130708895
   Follmer S, 2012, P SIGCHI C HUM FACT, P2401
   Hartmann B, 2010, 2010 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, P421
   Hettiarachchi A, 2013, P 4 AUGM HUM INT C A, P1
   Holm R, 2002, P IEEE VIRT REAL ANN, P93, DOI 10.1109/VR.2002.996511
   Hong S, 2018, P 31 ANN ACM S US IN
   Israel JH, 2009, COMPUT GRAPH-UK, V33, P462, DOI 10.1016/j.cag.2009.05.005
   Jensen SQ, 2018, P 2018 CHI C HUM FAC
   Jeon S, 2009, PRESENCE-TELEOP VIRT, V18, P387, DOI 10.1162/pres.18.5.387
   Kattinakere RS, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P317
   Keefe D. F., 2001, PROCEEDINGS OF THE 2, P85
   Kim H, 2008, CHI 08 HUM FACT COMP, P2337
   Kuchenbecker KJ, 2006, IEEE T VIS COMPUT GR, V12, P219, DOI 10.1109/TVCG.2006.32
   Lee GA, 2005, COMMUN ACM, V48, P76, DOI 10.1145/1070838.1070840
   Lee GA, 2002, P ACM S VIRT REAL SO, P41
   Liu HW, 2014, J VIS COMMUN IMAGE R, V25, P709, DOI 10.1016/j.jvcir.2013.03.012
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Ma ZZJ, 2018, THESIS
   Ryokai K, 2004, P SIGCHI C HUM FACT, P303
   Ryokai K, 2005, CHI 05 EXTENDED ABST, P1037
   Ryokai K, 2007, CHI 07 EXTENDED ABST, P1995
   Umakatsu A, 2014, T VIRTUAL REALITY SO, V19, P141
   Wasenmüller O, 2017, LECT NOTES COMPUT SC, V10117, P34, DOI 10.1007/978-3-319-54427-4_3
   WICKIEWICZ TL, 1984, J APPL PHYSIOL, V57, P435, DOI 10.1152/jappl.1984.57.2.435
   Wozniewski M, 2011, P ISMAR
   Wu J., 2015, ADV NEURAL INF PROCE, V28, P127
   Yamauchi J, 2010, GERONTOLOGY, V56, P167, DOI 10.1159/000235814
NR 32
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 31135
EP 31158
DI 10.1007/s11042-020-09332-4
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000562943300009
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Zhao, ZD
   Deng, YJ
   Zhang, XH
   Zhang, Y
AF Zhang, Yefei
   Zhao, Zhidong
   Deng, Yanjun
   Zhang, Xiaohong
   Zhang, Yu
TI Heart biometrics based on ECG signal by sparse coding and bidirectional
   long short-term memory
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG biometrics; Human identification; Long short-term memory (LSTM);
   Sparse coding (SC)
ID CONVOLUTIONAL NEURAL-NETWORK; HUMAN IDENTIFICATION; FEATURE-SELECTION;
   MATCHING PURSUIT; EXTRACTION; RECOVERY; ROBUST
AB Physiological signal-based biometrics are gaining increasing attention in the context of increasing privacy and security requirements. This paper proposes a novel electrocardiogram (ECG)-based algorithm to be used for human identification by integrating multiple local feature vectors with sparse-constraint-based sparse coding (SCSC) and bidirectional long short-term memory (BLSTM). Three local feature vectors of ECG signals: morphology characteristics in the time domain, instantaneous characteristics in the frequency domain, and phase spectral characteristics in the phase domain are constructed. Sparsity constraints to model this relationship are imposed because ECGs show high inter-class similarity and subtle intra-class differences in these three domains, and traditional sparse coding (SC) can only learn from a single dictionary. This paper joints optimization of the summed reconstruction error, the sparsity constraints of the correlations and the differences between the feature vectors, proposed the SCSC algorithm. Via this approach, the overlap problem of local feature vectors is solved and a lightweight and interpretable feature vector is obtained. Additionally, the BLSTM-based deep neural network model is supplemented for exploring the spatial information of the reconstructed feature vectors, and a more representative and discriminative signal feature representation is obtained. Comparing five classical machine learning and deep learning algorithms within 360 public samples, using two protocols, we show that, in addition to multiscale information extraction, joint encoding of the correlations and differences between local feature vectors is critically important for feature discrimination. The experimental results demonstrated a high identification accuracy of 99.44%, indicating that the proposed algorithm has practical utility in network information security.
C1 [Zhang, Yefei; Zhao, Zhidong; Deng, Yanjun; Zhang, Xiaohong; Zhang, Yu] Hangzhou Dianzi Univ, Coll Elect & Informat Engn, Hangzhou 300318, Peoples R China.
C3 Hangzhou Dianzi University
RP Zhao, ZD (corresponding author), Hangzhou Dianzi Univ, Coll Elect & Informat Engn, Hangzhou 300318, Peoples R China.
EM zhaozd@hdu.edu.cn
RI Zhang, Yuchen/GYI-8858-2022; Zhang, Yefei/JGV-1801-2023
OI Zhang, Yefei/0000-0002-1083-459X
FU Industrial Project of Public Welfare Technology research plan of
   Zhejiang Province [LGG20F010008]; National Natural Science Foundation of
   China [61571173]; Welfare Project of the Science Technology Department
   of Zhejiang Province [LGG18F010012]; Key research and development
   program of Zhejiang Province [2017C03047]
FX This work was supported by the Industrial Project of Public Welfare
   Technology research plan of Zhejiang Province (Grant No. LGG20F010008),
   National Natural Science Foundation of China (Grant No. 61571173),
   Welfare Project of the Science Technology Department of Zhejiang
   Province (Grant No. LGG18F010012), Key research and development program
   of Zhejiang Province (Grant No. 2017C03047).
CR Biel L, 2001, IEEE T INSTRUM MEAS, V50, P808, DOI 10.1109/19.930458
   Cai TT, 2011, IEEE T INFORM THEORY, V57, P4680, DOI 10.1109/TIT.2011.2146090
   Choi GH, 2019, IEEE ACCESS, V7, P34862, DOI 10.1109/ACCESS.2019.2902870
   Goshvarpour A, 2019, COMPUT METH PROG BIO, V172, P87, DOI 10.1016/j.cmpb.2019.02.009
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Islam MS, 2017, MULTIMED TOOLS APPL, V76, P12709, DOI 10.1007/s11042-016-3694-6
   Islam MS, 2017, IEEE ACCESS, V5, P1753, DOI 10.1109/ACCESS.2017.2667224
   Islam MS, 2015, COMPUT J, V58, P2622, DOI 10.1093/comjnl/bxu150
   Labati RD, 2019, PATTERN RECOGN LETT, V126, P78, DOI 10.1016/j.patrec.2018.03.028
   Mesin L, 2016, SMART INNOV SYST TEC, V54, P425, DOI 10.1007/978-3-319-33747-0_42
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014
   Peng SL, 2019, IEEE T NEUR NET LEAR, V30, P718, DOI 10.1109/TNNLS.2018.2850703
   Richhariya B, 2018, EXPERT SYST APPL, V106, P169, DOI 10.1016/j.eswa.2018.03.053
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Shao YH, 2011, IEEE T NEURAL NETWOR, V22, P962, DOI 10.1109/TNN.2011.2130540
   Tantawi MM, 2015, SIGNAL IMAGE VIDEO P, V9, P1271, DOI 10.1007/s11760-013-0568-5
   Tanveer M, 2015, COGN COMPUT, V7, P137, DOI 10.1007/s12559-014-9278-8
   Tanveer M, 2016, APPL INTELL, V45, P174, DOI 10.1007/s10489-015-0751-1
   Yazdi SV, 2018, PATTERN RECOGN LETT, V112, P1, DOI 10.1016/j.patrec.2018.05.017
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   Zhang QX, 2017, IEEE ACCESS, V5, P11805, DOI 10.1109/ACCESS.2017.2707460
   Zhang ZQ, 2014, APPL INTELL, V41, P1097, DOI 10.1007/s10489-014-0586-1
   Zhao ZD, 2018, COMPUT BIOL MED, V102, P168, DOI 10.1016/j.compbiomed.2018.09.027
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
NR 26
TC 2
Z9 2
U1 1
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30417
EP 30438
DI 10.1007/s11042-020-09608-9
EA AUG 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000562697300001
DA 2024-07-18
ER

PT J
AU Karn, P
   He, XH
   Zhang, J
   Zhang, YT
AF Karn, Pradeep
   He, XiaoHai
   Zhang, Jin
   Zhang, Yanteng
TI An experimental study of relative total variation and probabilistic
   collaborative representation for iris recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Iris recognition; Relative total variation; Gabor filter;
   Probabilistic collaborative representation-based classification
ID DISCRIMINANT-ANALYSIS; FACE RECOGNITION; SUBSPACE; MODEL
AB Iris images collected under different conditions often suffer from specular reflections, cast shadows, motion blur, defocus blur, occlusion caused by eyelashes and eyelids, eyeglasses, hair and other artifacts. Existing iris recognition systems do not perform well on these types of images. To overcome these problems, an iris recognition method based on relative total variation (RTV) and probabilistic collaborative representation is proposed. RTV uses thel(1)norm regularization method to robustly suppress noisy pixels to achieve accurate iris localization, while probability collaborative representation maximizes the probability that the test sample belongs to each of the multiple classes. The final recognition rate is calculated based on the class having maximum probability. Experimental results using CASIA-V4-Lamp and IIT-Delhi V1iris image databases showed that the proposed method achieved competitive performance in both recognition accuracy and computational efficiency.
C1 [Karn, Pradeep; He, XiaoHai; Zhang, Jin; Zhang, Yanteng] Sichuan Univ, Coll Elect & Informat Engn, Image Informat Inst, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Karn, P (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Image Informat Inst, Chengdu 610065, Peoples R China.
EM prkarn@scu.edu.cn
OI Karn, Pradeep/0000-0003-0423-8297
FU National Natural Science Foundation of China (NSFC) [61871279];
   Industrial Cluster Collaborative Innovation Project of Chengdu Grant
   [2016-XT00-00015-GX]; Sichuan Science and Technology Program
   [2018HH0143]; Sichuan Education Department Program [18ZB0355]
FX The authors thank the anonymous reviewers for their thorough and
   valuable comments and suggestions. This work was supported by the
   National Natural Science Foundation of China (NSFC) Grant No. 61871279,
   the Industrial Cluster Collaborative Innovation Project of Chengdu Grant
   No. 2016-XT00-00015-GX, the Sichuan Science and Technology Program Grant
   No. 2018HH0143 and the Sichuan Education Department Program Grant No.
   18ZB0355.
CR Ahamed A, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P548, DOI 10.1109/ICIEV.2012.6317442
   Al-Raisi Ahmad N., 2008, Telematics and Informatics, V25, P117, DOI 10.1016/j.tele.2006.06.005
   Alliney S, 1997, IEEE T SIGNAL PROCES, V45, P913, DOI 10.1109/78.564179
   [Anonymous], IST2002507634
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   Barpanda SS, 2018, MULTIMED TOOLS APPL, V77, P7637, DOI 10.1007/s11042-017-4668-z
   Belcher C, 2009, OPT LASER ENG, V47, P139, DOI 10.1016/j.optlaseng.2008.07.004
   Bhateja AK, 2016, PATTERN RECOGN LETT, V73, P13, DOI 10.1016/j.patrec.2015.12.009
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Chen CH, 2009, EXPERT SYST APPL, V36, P10351, DOI 10.1016/j.eswa.2009.01.033
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2006, P IEEE, V94, P1927, DOI 10.1109/JPROC.2006.884092
   Davies ER, 2012, COMPUTER AND MACHINE VISION: THEORY, ALGORITHMS, PRACTICALITIES, 4TH EDITION, P1
   Farouk RM, 2011, COMPUT VIS IMAGE UND, V115, P1239, DOI 10.1016/j.cviu.2011.04.002
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   Haghighat M, 2015, EXPERT SYST APPL, V42, P7905, DOI 10.1016/j.eswa.2015.06.025
   Hajari K, 2016, PROCEDIA COMPUT SCI, V78, P675, DOI 10.1016/j.procs.2016.02.116
   He F, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.2.023005
   Hua JL, 2017, NEURAL COMPUT APPL, V28, pS225, DOI 10.1007/s00521-016-2299-3
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jan F, 2012, DIGIT SIGNAL PROCESS, V22, P971, DOI 10.1016/j.dsp.2012.06.001
   Jeong DS, 2010, IMAGE VISION COMPUT, V28, P254, DOI 10.1016/j.imavis.2009.04.001
   Karn P, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.6.063002
   Khalighi S, 2015, J SIGNAL PROCESS SYS, V81, P111, DOI 10.1007/s11265-014-0911-2
   Kumar A., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P59, DOI DOI 10.1109/CVPRW.2012.6239216
   Labati RD, 2010, IMAGE VISION COMPUT, V28, P270, DOI 10.1016/j.imavis.2009.05.004
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Li PH, 2010, IMAGE VISION COMPUT, V28, P246, DOI 10.1016/j.imavis.2009.04.010
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Majumdar A, 2010, IEEE T SYST MAN CY B, V40, P1359, DOI 10.1109/TSMCB.2009.2038493
   Meshgini S, 2013, COMPUT ELECTR ENG, V39, P727, DOI 10.1016/j.compeleceng.2012.12.011
   Minaee S., 2016, IEEE Region, P1
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Poursaberi A, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/36751
   Rahulkar AD, 2012, IEEE T INF FOREN SEC, V7, P230, DOI 10.1109/TIFS.2011.2166069
   Rai H, 2014, EXPERT SYST APPL, V41, P588, DOI 10.1016/j.eswa.2013.07.083
   Raja KB, 2017, PATTERN RECOGN LETT, V91, P27, DOI 10.1016/j.patrec.2016.12.025
   Ross A, 2004, EUR SIGN PROC C
   Roy K, 2011, ENG APPL ARTIF INTEL, V24, P458, DOI 10.1016/j.engappai.2010.06.014
   Shen L, 2007, IMAGE VISION COMPUT, V25, P553, DOI 10.1016/j.imavis.2006.05.002
   Si YL, 2012, IEEE T IND INFORM, V8, P110, DOI 10.1109/TII.2011.2166791
   Song Y, 2014, NEUROCOMPUTING, V137, P198, DOI 10.1016/j.neucom.2013.06.051
   Tsai CC, 2012, IEEE T SYST MAN CY B, V42, P150, DOI 10.1109/TSMCB.2011.2163817
   Viriri S, 2017, INT J ADV ROBOT SYST, V14, DOI 10.1177/1729881417703931
   Wang N, 2014, MULTIMED TOOLS APPL, V71, P1411, DOI 10.1007/s11042-012-1278-7
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiao F, 2018, MULTIMED TOOLS APPL, P1
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhao Z, 2017, IEEE I CONF COMP VIS, P3829, DOI 10.1109/ICCV.2017.411
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 53
TC 2
Z9 2
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31783
EP 31801
DI 10.1007/s11042-020-09553-7
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360200005
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Liu, GX
   Gao, JY
   Zhang, HY
AF Zhang, Yi
   Liu, Guixi
   Gao, Jiayu
   Zhang, Haoyang
TI Robust visual tracker integrating adaptively foreground segmentation
   into multi-feature fusion framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Foreground segmentation; Correlation filter tracking; Color histogram;
   Response maps fusion
ID OBJECT TRACKING
AB Existing Discriminative Correlation Filter (DCF) based methods suffer from the limitations of rectangular shape assumptions. Aiming at this issue, in this paper, we propose an effective tracking approach which integrates a pixel-wise foreground segmentation mask into the correlation filter within a multi-feature fusion framework. Specifically, we first propose a novel segmentation algorithm which combines the color histogram with the spatial prior. On this basis, we implement a target-masked correlation filter (TMCF) tracker by introducing the foreground mask into a ridge regression, which successfully suppresses unexpected background information inside the bounding box. Secondly, we apply the alternating direction method of multipliers (ADMM) to solve our TMCF model efficiently to obtain the closed-form solution. Finally, a complementary fusion tracker by the combining of TMCF and color histogram scores (fTMCFCH) is formulated, which is robust to deformations and illumination changes simultaneously. The fusion factor is determined adaptively by the reliability derived from the target resolution of the trackers separately in each frame. We perform extensive experiments on three benchmarks: OTB-2013, OTB-2015 and Temple-Color-128. The concrete experimental results demonstrate that our tracker outperforms several state-of-the-art trackers.
C1 [Zhang, Yi; Liu, Guixi; Zhang, Haoyang] Xidian Univ, Sch Mechanoelect Engn, Xian 710071, Peoples R China.
   [Zhang, Yi; Liu, Guixi; Gao, Jiayu; Zhang, Haoyang] Shaanxi Key Lab Integrated & Intelligent Nav, Xian 710068, Peoples R China.
   [Gao, Jiayu] Xian Res Inst Nav Technol, Xian 710068, Peoples R China.
C3 Xidian University
RP Liu, GX (corresponding author), Xidian Univ, Sch Mechanoelect Engn, Xian 710071, Peoples R China.; Liu, GX (corresponding author), Shaanxi Key Lab Integrated & Intelligent Nav, Xian 710068, Peoples R China.
EM gxliu@xidian.edu.cn
RI Zhang, Yuyao/KEH-7175-2024; Zhang, Haoyang/ABF-4117-2022
OI Zhang, Haoyang/0000-0003-3392-320X
FU Foundation of Preliminary Research Field of China [6140312030217,
   61405170206]; 13th Five-Year Equipment Development Project of China
   [41412010202]; National Natural Science Foundation of China [61972307];
   Open Foundation of Shaanxi Key Laboratory of Integrated and Intelligent
   Navigation [SKLIIN-20180108]
FX This work is supported by the Foundation of Preliminary Research Field
   of China (Grant No. 6140312030217, 61405170206), the 13th Five-Year
   Equipment Development Project of China (Grant No. 41412010202), National
   Natural Science Foundation of China(Grant No.61972307, and the Open
   Foundation of Shaanxi Key Laboratory of Integrated and Intelligent
   Navigation under Grant No. SKLIIN-20180108.
CR Aeschliman C, 2010, PROC CVPR IEEE, P1371, DOI 10.1109/CVPR.2010.5539810
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danesi M, 2014, TARTU SEMIO LIBR, V14, P1
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Kart Ugur, 2018, ECCV WORKSH
   Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li CL, 2017, AAAI CONF ARTIF INTE, P4126
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Tang M, 2015, IEEE I CONF COMP VIS, P3038, DOI 10.1109/ICCV.2015.348
   Tsai YH, 2016, PROC CVPR IEEE, P3899, DOI 10.1109/CVPR.2016.423
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yeo D, 2017, PROC CVPR IEEE, P511, DOI 10.1109/CVPR.2017.62
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang HY, 2018, J VIS COMMUN IMAGE R, V56, P1, DOI 10.1016/j.jvcir.2018.08.018
   Zhang HY, 2018, VISUAL COMPUT, V34, P41, DOI 10.1007/s00371-016-1310-4
   Zhu GB, 2016, AAAI CONF ARTIF INTE, P3690
NR 43
TC 0
Z9 0
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 43-44
BP 31865
EP 31888
DI 10.1007/s11042-020-09443-y
EA AUG 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OB0VC
UT WOS:000562360200004
DA 2024-07-18
ER

PT J
AU Majdabadi, MM
   Ko, SB
AF Molahasani Majdabadi, Mahdiyar
   Ko, Seok-Bum
TI Capsule GAN for robust face super resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative Adversarial Network (GAN); Capsule network; Super resolution;
   Face hallucination
AB Face hallucination is an emerging sub-field of Super-Resolution (SR) which aims to reconstruct the High-Resolution (HR) facial image given its Low-Resolution (LR) counterpart. The task becomes more challenging when the LR image is extremely small due to the image distortion in the super-resolved results. A variety of deep learning-based approaches has been introduced to address this issue by using attribute domain information. However, a more complex dataset or even further networks is required for training these models. In order to avoid these complexities and yet preserve the precision in reconstructed output, a robust Multi-Scale Gradient capsule GAN for face SR is proposed in this paper. A novel similarity metric called Feature SIMilarity (FSIM) is introduced as well. The proposed network surpassed state-of-the-art face SR systems in all metrics and demonstrates more robust performance while facing image transformations.
C1 [Molahasani Majdabadi, Mahdiyar; Ko, Seok-Bum] Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.
   [Ko, Seok-Bum] Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK, Canada.
C3 University of Saskatchewan; University of Saskatchewan
RP Ko, SB (corresponding author), Univ Saskatchewan, Dept Elect & Comp Engn, Saskatoon, SK, Canada.; Ko, SB (corresponding author), Univ Saskatchewan, Div Biomed Engn, Saskatoon, SK, Canada.
EM m.molahasani@usask.ca; seokbum.ko@usask.ca
RI Molahasani Majdabadi, Mahdiyar/AHE-4246-2022; Ko, Seokbum/H-8366-2012
OI Ko, Seokbum/0000-0002-9287-317X
CR Brock Andrew, 2018, ARXIV180911096
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karnewar Animesh, 2019, ARXIV PREPRINT ARXIV
   Kim Deokyun, 2019, PROC C EMPIRICAL MET, P2, DOI DOI 10.23919/ELINFOCOM.2019.8706453
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Majdabadi MM, 2020, 2020 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND COMMUNICATION (ICEIC)
   Rajput SS, 2019, MULTIMED TOOLS APPL, V78, P25407, DOI 10.1007/s11042-019-07791-y
   Sabour S, 2017, ADV NEUR IN, V30
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Son S, 2018, INT CONF BIG DATA, P721, DOI 10.1109/BigComp.2018.00135
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu X, 2018, PROC CVPR IEEE, P908, DOI 10.1109/CVPR.2018.00101
   Yu X, 2017, AAAI CONF ARTIF INTE, P4327
   Yu X, 2017, PROC CVPR IEEE, P5367, DOI 10.1109/CVPR.2017.570
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhu SZ, 2016, LECT NOTES COMPUT SC, V9909, P614, DOI 10.1007/978-3-319-46454-1_37
NR 26
TC 7
Z9 7
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31205
EP 31218
DI 10.1007/s11042-020-09489-y
EA AUG 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560998800004
DA 2024-07-18
ER

PT J
AU Franzoni, V
   Biondi, G
   Milani, A
AF Franzoni, Valentina
   Biondi, Giulio
   Milani, Alfredo
TI Emotional sounds of crowds: spectrogram-based analysis using deep
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Image recognition; Crowd computing; CNN; Transfer
   learning; Crowd emotions
AB Crowds express emotions as a collective individual, which is evident from the sounds that a crowd produces in particular events, e.g., collective booing, laughing or cheering in sports matches, movies, theaters, concerts, political demonstrations, and riots. A critical question concerning the innovative concept ofcrowd emotionsis whether the emotional content of crowd sounds can be characterized by frequency-amplitude features, using analysis techniques similar to those applied on individual voices, where deep learning classification is applied to spectrogram images derived by sound transformations. In this work, we present a technique based on the generation of sound spectrograms from fragments of fixed length, extracted from original audio clips recorded in high-attendance events, where the crowd acts as a collective individual. Transfer learning techniques are used on a convolutional neural network, pre-trained on low-level features using the well-known ImageNet extensive dataset of visual knowledge. The original sound clips are filtered and normalized in amplitude for a correct spectrogram generation, on which we fine-tune the domain-specific features. Experiments held on the finally trained Convolutional Neural Network show promising performances of the proposed model to classify the emotions of the crowd.
C1 [Franzoni, Valentina; Milani, Alfredo] Univ Perugia, Dept Math & Comp Sci, Perugia, Italy.
   [Biondi, Giulio] Univ Florence, Dept Math & Comp Sci, Florence, Italy.
C3 University of Perugia; University of Florence
RP Franzoni, V (corresponding author), Univ Perugia, Dept Math & Comp Sci, Perugia, Italy.
EM valentina.franzoni@dmi.unipg.it; giulio.biondi@unifi.it; milani@unipg.it
RI Biondi, Giulio/GWZ-8298-2022; Franzoni, Valentina/IYJ-4816-2023;
   Franzoni, Valentina/AAC-7783-2021
OI Biondi, Giulio/0000-0002-1854-2196; Franzoni,
   Valentina/0000-0002-2972-7188
FU Universita degli Studi di Perugia within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Perugia within
   the CRUI-CARE Agreement.
CR Bhor HN, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON INVENTIVE SYSTEMS AND CONTROL (ICISC 2018), P1398, DOI 10.1109/ICISC.2018.8399038
   Biondi G, 2017, LNCS
   Biondi G, 2019, APPROACH IMPROVING A, P649
   Bonarini A, 2016, ADAPT BEHAV, V24, P335, DOI 10.1177/1059712316664187
   Canales L, 2014, P WORKSHOP NATURAL L, P37, DOI DOI 10.3115/V1/W14-6905
   Chen L, 2019, EXPERT SYST APPL
   Deng J., 2009, CVPR
   Deng JJ, 2015, ACM T INTERACT INTEL
   Du JC, 2017, BMC MED INFORM DECIS, V17, DOI 10.1186/s12911-017-0469-6
   Dvir-Gvirsman S, 2017, NEW MEDIA SOC, V19, P1072, DOI 10.1177/1461444815625945
   Ekman P, 1992, COGN EMOT
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fayek H. M., 2015, 2015 9 INT C SIGN
   Fayek HM, 2017, NEURAL NETWORKS, V92, P60, DOI 10.1016/j.neunet.2017.02.013
   Forsell M., 2007, Acoustic Correlates of Perceived Emotions in Speech
   Franzoni V., 2019, PROC INT C SYST, P32
   Franzoni V, 2019, 2019 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE WORKSHOPS (WI 2019 COMPANION), P91, DOI 10.1145/3358695.3361750
   Gervasi O, 2019, WEB INTELL
   Hawks H, 1932, CROWD ROAR WARNER BR
   Huang Z, 2014, SPEECH EMOTION RECOG
   Kim Y, 2019, COMPUT HUM BEHAV, V99, P219, DOI 10.1016/j.chb.2019.05.022
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lech M., 2018, Adv Sci Technol Eng Syst, V3, P363, DOI DOI 10.25046/AJ030437
   Liu X, 2019, IEEE T IMAGE PROCESS
   Mirsamadi S, 2017, ICASSP IEEE INT C AC
   MOORE BJC, 1983, J ACOUST SOC AM
   Prasomphan S, 2015, PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON DATA SCIENCE AND ADVANCED ANALYTICS (IEEE DSAA 2015), P113
   Quatieri TF, 1993, IEEE T SIGNAL PROCES
   Riganelli M, 2017, LNCS
   Sailunaz K, 2019, J COMPUT SCI-NETH, V36, DOI 10.1016/j.jocs.2019.05.009
   Srinivasan SM, 2019, IEEE TECHNOL SOC MAG, V38, P58, DOI 10.1109/MTS.2019.2894472
   Stevens SS, 1937, J ACOUST SOC AM, V8, P185, DOI 10.1121/1.1915893
   Stolar MN, 2018, 2017 11 INT C SIGN P
   Yadollahi A, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3057270
   ZWICKER E, 1961, J ACOUST SOC AM, V33, P248, DOI 10.1121/1.1908630
NR 35
TC 21
Z9 22
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 36063
EP 36075
DI 10.1007/s11042-020-09428-x
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000560912100001
PM 32837250
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Ghimire, S
   Lee, B
AF Ghimire, Sarala
   Lee, Bumshik
TI A data integrity verification method for surveillance video system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decryption; ECC; Encryption; Hash; Integrity; Randomization; Video
ID CRYPTOGRAPHIC HASH FUNCTION
AB Due to the massive popularity and consciousness towards requirements in evidence, the usage of the surveillance system has tremendously increased. Although video data recorded by the surveillance system contains important information and provides crucial evidence, it is susceptible to malicious alterations. Thus, the authenticity and integrity of the visual evidence need to be examined before the investigation proceeding. In this paper, we propose an integrity verification method for surveillance videos. The proposed method utilizes a randomized hashing method in combination with the elliptic curve cryptography (ECC) for video data integrity verification. In the proposed approach, the video content with a predefined size (segment) is randomized with the unique random value, and then a hash algorithm is applied. The hash algorithm here utilizes the random initialization vector, which is generated with a secret key. Besides, the combination of the randomized hash output and the key is encrypted with the ECC encryption algorithm that ensures the additional security of the data. The experimental results obtained from computer simulation and accident data recorder (ADR)-embedded system show that the proposed method achieves perfect forgery detection for various kinds of tampering such as copy-move, insert, and delete. A complexity analysis based on the execution time for different sized videos shows the minimal overhead of less than 4% for each segment and consumes less memory than the conventional method that utilizes individual frames for hashing.
C1 [Ghimire, Sarala; Lee, Bumshik] Chosun Univ, Dept Informat & Commun Engn, Gwangju, South Korea.
C3 Chosun University
RP Lee, B (corresponding author), Chosun Univ, Dept Informat & Commun Engn, Gwangju, South Korea.
EM srlaghm@chosun.kr; bslee@chosun.ac.kr
OI Lee, Bumshik/0000-0003-2482-1869; Ghimire, Sarala/0000-0002-6645-6559
FU Chosun University
FX This work was supported by research fund from Chosun University, 2017.
CR Athanasiou GS, 2014, IET COMPUT DIGIT TEC, V8, P70, DOI 10.1049/iet-cdt.2013.0010
   Bellare M., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P1
   Bellare M, 2000, AUTHENTICATED ENCRYP, P24
   Calabresi M., 2016, INTRO ELLIPTIC CURVE, P10
   Chaves R, 2008, IEEE T VLSI SYST, V16, P999, DOI 10.1109/TVLSI.2008.2000450
   Chum CS, 2014, 2014 23 WIR OPT COMM, P1, DOI [10.1109/WOCC.2014.6839925, DOI 10.1109/WOCC.2014.6839925]
   DAMGARD IB, 1990, LECT NOTES COMPUT SC, V435, P416
   Danko D, 2019, IEEE INT CONF MOB, P48, DOI 10.1109/MASSW.2019.00016
   Gayoso V., 2010, J. Comput. Sci. Eng, V2, P7
   Ghimire S., 2018, P KIIT C JUN, P419
   Ghimire S., 2018, P KSAE ANN AUT C EXH, P788
   Halevi S, IMPLEMENTING HALEVI, P1
   Halevi S, 2006, LECT NOTES COMPUT SC, V4117, P41
   Hankerson D., GUIDE ELLIPTIC CURVE
   Jayamalar T., 2010, International Journal of Engineering Science and Technology, V2, P6963
   Jiang Xinghao, 2014, ScientificWorldJournal, V2014, P802347, DOI 10.1155/2014/802347
   Jiang XH, 2013, IEEE SIGNAL PROC LET, V20, P447, DOI 10.1109/LSP.2013.2251632
   Khan PW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030484
   Kim M, 2014, I C INF COMM TECH CO, P636, DOI 10.1109/ICTC.2014.6983237
   Krawczyk H, 2001, ORDER ENCRYPTION AUT, P310
   Kwon H., 2016, SIGMATA STORAGE INTE
   Lee S, 2015, IEICE T INF SYST, VE98D, P95, DOI 10.1587/transinf.2014MUL0001
   Liu F, 2011, IACR CRYPTOL EPRINT, V2011, P649, DOI [10.12928/telkomnika.v11i2.940, DOI 10.12928/TELKOMNIKA.V11I2.940]
   Lokhande RR, 2014, J COMPUT SCI, V2014, P39
   Okamoto T, 2000, IEEE P1363A
   Rasjid ZE, 2017, PROCEDIA COMPUT SCI, V116, P381, DOI 10.1016/j.procs.2017.10.072
   Richardson IE, 2011, H 264 ADV VIDEO COMP, P349
   Sadi KA, 2017, INT J ELECTRON, V104, P673, DOI 10.1080/00207217.2016.1242163
   Singh LD, 2015, PROCEDIA COMPUT SCI, V54, P472, DOI 10.1016/j.procs.2015.06.054
   Stallings W., 2017, CRYPTOGRAPHY NETWORK, V7th
   Upadhyay S., 2012, INT J COMPUT SCI ISS, V9, P10
   Yu LY, 2016, NEUROCOMPUTING, V205, P84, DOI 10.1016/j.neucom.2016.03.051
   Zhao XB, 2012, GLOB CONGRESS INTELL, P429, DOI 10.1109/GCIS.2012.97
   Zhao Yong-Xia, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P271, DOI 10.1109/MMIT.2010.186
NR 34
TC 4
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30163
EP 30185
DI 10.1007/s11042-020-09482-5
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559655000001
DA 2024-07-18
ER

PT J
AU Hassan, FS
   Gutub, A
AF Hassan, Fatuma Saeid
   Gutub, Adnan
TI Efficient reversible data hiding multimedia technique based on smart
   image interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible steganography; Image interpolation; NMI; Pixel intensity; LSB
   substitution
AB Reversible data hiding (RDH) within images is the process of securing data into cover images without degradation. Its challenge is to hide a large payload while taking into account the human visual system so that the distortion of the stego-image is negligible. It is highly desired for the images that have special requirements like the ones in the medical and military fields where the original images are required to be regenerated with no loss after extracting the data. In this paper, we propose an interpolation-based RDH (IRDH) scheme that improves Lee and Huang's scheme and Malik et al.'s scheme by combining their embedding techniques along with the optimal pixel adjustment process (OPAP) in a way that increases the embedding capacity and the visual quality of both the schemes. In this presented scheme, we start by stretching the size of the original image using the existing enhanced neighbor mean interpolation (ENMI) interpolation technique then the data is embedded into the interpolated pixels using our novel embedding method that depends on the intensity of the pixels and the maximized difference values. This innovative scheme presented all steps covering generation of the interpolated image, data embedding, data extraction and image recovery, making it in testing situation to be compared fairly with others. The experimental results demonstrate that the achieved embedding capacity by our hiding technique is more than 537 Kb for all the test images. Also, the experiments show that our proposed scheme has the highest embedding capacity among five current schemes which are Jung and Yoo's scheme, Lee and Huang's scheme, Chang et al.'s scheme, Zhang et al.'s scheme and Malik et al.'s scheme with attractive image security quality.
C1 [Hassan, Fatuma Saeid; Gutub, Adnan] Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
EM toma2u@hotmail.com; aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X
FU Umm Al-Qura University (UQU)
FX Thanks to Umm Al-Qura University (UQU) for supporting this work.
CR Alanazi N, 2020, J KING SAUD UNIV-COM, V34, P1343, DOI 10.1016/j.jksuci.2020.04.011
   ALASSAF N, 2019, MULTIMED TOOLS APPL, V0078, P32633, DOI DOI 10.1007/S11042-018-6801-Z
   ALASSAF N, 2019, INT J E HEALTH MED C, V0010, P00001, DOI DOI 10.4018/IJEHMC.2019100101
   Alattar AM, ICASSP IEEE INT C AC
   ALJUAID N, 2019, SN APPL SCI, V0001, DOI DOI 10.1007/S42452-019-0875-8
   ALJUAID N, 2019, SN APPL SCI, V0001, DOI DOI 10.1007/S42452-019-0875-8
   ALNOFAIE SMA, 2020, MULTIMED TOOLS APPL, V0079, P00019, DOI DOI 10.1007/S11042-019-08025-X
   CHAN CK, 2004, PATTERN RECOGN, V0037, P00469, DOI DOI 10.1016/J.PATCOG.2003.08.007
   CHANG YT, 2013, J SUPERCOMPUT, V0066, P01093, DOI DOI 10.1007/S11227-013-1016-6
   GOVIND PVS, 2016, PROC TECH, V0024, P01311, DOI DOI 10.1016/J.PROTCY.2016.05.129
   GUTUB A, 2019, MULTIMED TOOLS APPL, V0078, P05591, DOI DOI 10.1007/S11042-017-5293-6
   GUTUB A, 2020, ARAB J SCI ENG, V0045, P02631, DOI DOI 10.1007/S13369-020-04413-W
   GUTUB A, 2020, MULTIMED TOOLS APPL, V0079, P07951, DOI DOI 10.1007/S11042-019-08427-X
   Hassan FS, 2022, J KING SAUD UNIV-COM, V34, P2017, DOI 10.1016/j.jksuci.2020.07.008
   HU J, 2015, COMPUT ELECT ENG, V0046, P00447, DOI DOI 10.1016/J.COMPELECENG.2015.04.014
   HUANG CT, 2013, IMAGING SCI J, V0061, P00195, DOI DOI 10.1179/1743131X11Y.0000000031
   HUANG CT, 2018, J SUPERCOMPUT, V0074, P04295, DOI DOI 10.1007/S11227-016-1874-9
   HWANG J, 2006, LECT NOTES COMPUT SC, V4283, P00348, DOI DOI 10.1007/11922841_28
   Jan SR, 2011, P 7 INT C INT INF HI, P185
   JUNG KH, 2009, COMPUT STAND INTER, V0031, P00465, DOI DOI 10.1016/J.CSI.2008.06.001
   KIM C, 2018, J REAL TIME IMAGE PR, V0014, P00101, DOI DOI 10.1007/S11554-016-0641-8
   LEE CF, 2012, EXPERT SYST APPL, V0039, P06712, DOI DOI 10.1016/J.ESWA.2011.12.019
   LIAO X, 2017, SIGNAL PROCESS IMAGE, V0058, P00146, DOI DOI 10.1016/J.IMAGE.2017.07.006
   LIAO X, 2017, MULTIMED TOOLS APPL, V0076, P20739, DOI DOI 10.1007/S11042-016-3971-4
   LIAO X, 2020, IEEE T CIRC SYST VID, V0030, P00685, DOI DOI 10.1109/TCSVT.2019.2896270
   Lin CC, 2019, SYMMETRY, V11
   LIU YC, 2011, MULTIMED TOOLS APPL, V0052, P00263, DOI DOI 10.1007/S11042-010-0496-0
   MALIK A, 2020, MULTIMED TOOLS 0225, DOI DOI 10.1007/S11042-020-08691-2
   NI ZC, 2006, IEEE T CIRC SYST VID, V0016, P00354, DOI DOI 10.1109/TCSVT.2006.869964
   OU B, 2013, IEEE T IMAGE PROCESS, V0022, P05010, DOI DOI 10.1109/TIP.2013.2281422
   PARVEZ MT, 2011, KUWAIT J SCI ENG, V0038, P00127
   TIAN J, 2003, IEEE T CIRC SYST VID, V0013, P00890, DOI DOI 10.1109/TCSVT.2003.815962
   TSAI P, 2009, SIGNAL PROCESS, V0089, P01129, DOI DOI 10.1016/J.SIGPRO.2008.12.017
   WANG JX, 2019, SIGNAL PROCESS, V0159, P00193, DOI DOI 10.1016/J.SIGPRO.2019.02.013
   Yalman Y, 2010, P 2010 13 IEEE INT C, P346
   YANG CN, 2017, COMPUT STAND INTER, V0050, P00209, DOI DOI 10.1016/J.CSI.2016.10.005
   ZHANG XQ, 2017, MULTIMED TOOLS APPL, V0076, P09195, DOI DOI 10.1007/S11042-016-3521-0
NR 37
TC 45
Z9 45
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 30087
EP 30109
DI 10.1007/s11042-020-09513-1
EA AUG 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559430400003
DA 2024-07-18
ER

PT J
AU Asgharian, L
   Ebrahimnezhad, H
AF Asgharian, Lida
   Ebrahimnezhad, Hossein
TI How many sample points are sufficient for 3D model surface
   representation and accurate mesh simplification?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mesh simplification; 3D model approximation; Re-meshing; Detail
   preservation; Nyquist theorem; Adaptive sampling; Surface representation
ID RECONSTRUCTION; SIGNALS
AB Growing of 3D model products and its applications in mobile devices and multimedia tools increases demands to establish an effective approach for representing and compressing of these models. In this paper, we propose an algorithm to simplify a complex 3D mesh and reduce the number of vertices by re-sampling the mesh based on the Nyquist theorem in order to find the sufficient number of samples that is necessary to save the quality of the reconstructed mesh, precisely. To achieve the optimum number of samples in the simplified mesh, both maximum curvature (C-max) and minimum curvature (C-min) in the original mesh are employed for adaptive sampling in different directions. Since the samples are adaptively taken regarding the curvature variations in both directions of maximum and minimum curvatures, the least number of vertices is obtained to represent the model. Hence, the method not only simplifies the complex mesh, but also preserves fine scale features in the mesh. The proposed method is applied to different complex mesh surfaces. The experimental results demonstrate that our proposed framework can represent a mesh surface with the least number of samples besides preserving important features in the surface.
C1 [Asgharian, Lida; Ebrahimnezhad, Hossein] Sahand Univ Technol, Elect Engn Fac, Comp Vis Res Lab, Tabriz, Iran.
C3 Sahand University of Technology
RP Ebrahimnezhad, H (corresponding author), Sahand Univ Technol, Elect Engn Fac, Comp Vis Res Lab, Tabriz, Iran.
EM L_asgharian@sut.ac.ir; ebrahimnezhad@sut.ac.ir
RI ebrahimnezhad, hossein/ABC-3865-2021; Ebrahimnezhad,
   Hossein/ACP-2704-2022
OI ebrahimnezhad, hossein/0000-0003-4071-2750; 
CR Alliez P, 2003, ACM T GRAPHIC, V22, P485, DOI 10.1145/882262.882296
   [Anonymous], 2008, MESHLAB OPEN SOURCE, DOI DOI 10.2312/LOCALCHAPTEREVENTS/ITALCHAP/ITALIANCHAPCONF2008/129-136
   Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1
   Cai XT, 2015, INTEGR COMPUT-AID E, V22, P243, DOI 10.3233/ICA-150487
   Chen HK, 2017, MULTIMED TOOLS APPL, V76, P25391, DOI 10.1007/s11042-017-4607-z
   Cignoni P, 1998, COMPUT GRAPH FORUM, V17, P167, DOI 10.1111/1467-8659.00236
   Cohen J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P119, DOI 10.1145/237170.237220
   Cohen LD, 2001, J MATH IMAGING VIS, V14, P225, DOI 10.1023/A:1011281928379
   CURTIS SR, 1987, IEEE T ACOUST SPEECH, V35, P890, DOI 10.1109/TASSP.1987.1165212
   DYN N, 1990, ACM T GRAPHIC, V9, P160, DOI 10.1145/78956.78958
   Eck M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P173, DOI 10.1145/218380.218440
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Hajizadeh M, 2018, MULTIMED TOOLS APPL, V77, P19347, DOI 10.1007/s11042-017-5394-2
   He TS, 1995, VISUALIZATION '95 - PROCEEDINGS, P296, DOI 10.1109/VISUAL.1995.485142
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   JERRI AJ, 1977, P IEEE, V65, P1565, DOI 10.1109/PROC.1977.10771
   Kim SK, 2010, MULTIMED TOOLS APPL, V47, P147, DOI 10.1007/s11042-009-0411-8
   Kok-Lim Low, 1997, Proceedings 1997 Symposium on Interactive 3D Graphics, P75
   Lavoué G, 2011, COMPUT GRAPH FORUM, V30, P1427, DOI 10.1111/j.1467-8659.2011.02017.x
   Lee H, 2016, VISUAL COMPUT, V32, P967, DOI 10.1007/s00371-016-1242-z
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Li K, 2016, FRONT COMPUT SCI-CHI, V10, P689, DOI 10.1007/s11704-016-5106-5
   Liu XP, 2018, GRAPH MODELS, V98, P14, DOI 10.1016/j.gmod.2018.05.001
   Loop CT, 1987, THESIS
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21, P163, DOI 10.1145/37401.37422
   Luebke D., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P199, DOI 10.1145/258734.258847
   Luebke DP, 2001, IEEE COMPUT GRAPH, V21, P24, DOI 10.1109/38.920624
   MARVASTI FA, 1989, J OPT SOC AM A, V6, P52, DOI 10.1364/JOSAA.6.000052
   Marvasti FA, 1993, ADV TOPICS SHANNON S
   Marvasti FA, 2001, THEORY PRACTICE NONU
   Mirloo M, 2018, MULTIMED TOOLS APPL, V77, P6987, DOI 10.1007/s11042-017-4617-x
   MOUNT DM, 1985, CARTR121 U MAR DEP C
   Papageorgiou A, 2015, VISUAL COMPUT, V31, P235, DOI 10.1007/s00371-014-1039-x
   Park J, 2016, MULTIMED TOOLS APPL, V75, P1983, DOI 10.1007/s11042-014-2383-6
   Peyré G, 2006, INT J COMPUT VISION, V69, P145, DOI 10.1007/s11263-006-6859-3
   Ramos F, 2014, MULTIMED TOOLS APPL, V73, P961, DOI 10.1007/s11042-012-1200-3
   Rossignac J., 1993, Geometric Modeling in Computer Graphics, P455
   Salomon D, 2007, CURVES SURFACES COMP
   SCHROEDER WJ, 1992, COMP GRAPH, V26, P65, DOI 10.1145/142920.134010
   Sumner RW, 2004, ACM T GRAPHIC, V23, P399, DOI 10.1145/1015706.1015736
   Unity3d, 2020, LEV DET
   Wan Fang, 2010, Journal of Multimedia, V5, P629, DOI 10.4304/jmm.5.6.629-638
   WANG SW, 1994, IEEE COMPUT GRAPH, V14, P26, DOI 10.1109/38.310721
   Windowscentral, 2018, SIMPL YOUR MOD 3D PR
   Yirci Murat, 2009, 2009 IEEE 17th Signal Processing and Communications Applications Conference (SIU), P736, DOI 10.1109/SIU.2009.5136501
   Zhang J, 2016, 2016 IEEE INTERNATIONAL CONFERENCE OF ONLINE ANALYSIS AND COMPUTING SCIENCE (ICOACS), P202, DOI 10.1109/ICOACS.2016.7563080
NR 47
TC 5
Z9 6
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29595
EP 29620
DI 10.1007/s11042-020-09395-3
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000567227300007
DA 2024-07-18
ER

PT J
AU Fazlali, H
   Shirani, S
   McDonald, M
   Brown, D
   Kirubarajan, T
AF Fazlali, Hamidreza
   Shirani, Shahram
   McDonald, Mike
   Brown, Daly
   Kirubarajan, Thia
TI Aerial image dehazing using a deep convolutional autoencoder
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aerial images and videos; Dehazing; Deep convolutional autoencoder;
   Airborne surveillance; Wide area motion imagery
ID FEATURES; CNN
AB Aerial images and videos are extensively used for object detection and target tracking. However, due to the presence of thin clouds, haze or smoke from buildings, the processing of aerial data can be challenging. Existing single-image dehazing methods that work on ground-to-ground images, do not perform well on aerial images. Moreover, current dehazing methods are not capable for real-time processing. In this paper, a new end-to-end aerial image dehazing method using a deep convolutional autoencoder is proposed. Using the convolutional autoencoder, the dehazing problem is divided into two parts, namely, encoder, which aims extract important features to dehaze hazy regions and decoder, which aims to reconstruct the dehazed image using the down-sampled image received from the encoder. In this proposed method, we also exploit the superpixels in two different scales to generate synthetic thin cloud data to train our network. Since this network is trained in an end-to-end manner, in the test phase, for each input hazy aerial image, the proposed algorithm outputs a dehazed version without requiring any other information such as transmission map or atmospheric light value. With the proposed method, hazy regions are dehazed and objects within hazy regions become more visible while the contrast of non-hazy regions is increased. Experimental results on synthetic and real hazy aerial images demonstrate the superiority of the proposed method compared to existing dehazing methods in terms of quality and speed.
C1 [Fazlali, Hamidreza; Shirani, Shahram; McDonald, Mike; Brown, Daly; Kirubarajan, Thia] McMaster Univ, ECE Dept, 1280 Main St West, Hamilton, ON, Canada.
C3 McMaster University
RP Fazlali, H (corresponding author), McMaster Univ, ECE Dept, 1280 Main St West, Hamilton, ON, Canada.
EM fazlalih@mcmaster.com
CR ABADI M, 2016, P 12 USENIX S OP SYS, V16, P256
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2006, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2016.2621478
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gonzalez R.C., 2002, Digital image processing second edition, P455
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kingma D. P., 2014, arXiv
   Lee H, 2017, IEEE T IMAGE PROCESS, V26, P4843, DOI 10.1109/TIP.2017.2725580
   Li BQ, 2018, STOCH ENV RES RISK A, V32, P37, DOI 10.1007/s00477-017-1424-x
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu HM, 2016, MULTIMED TOOLS APPL, V75, P17081, DOI 10.1007/s11042-015-2977-7
   MANNOS JL, 1974, IEEE T INFORM THEORY, V20, P525, DOI 10.1109/TIT.1974.1055250
   McCartney E. J., 1976, Optics of the atmosphere. Scattering by molecules and particles
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Odena A., 2016, DISTILL, V1, P3, DOI [10.23915/distill.00003., DOI 10.23915/DISTILL, 10.23915/distill.00003, DOI 10.23915/DISTILL.00003]
   Reilly V, 2010, LECT NOTES COMPUT SC, V6313, P186
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P27363, DOI 10.1007/s11042-018-5924-6
   Sommer L.W., 2016, 2016 IEEE WINTER C A, P1
   Su F, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P280, DOI 10.1109/ISCIT.2016.7751636
   Su SC, 2017, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.2017.33
   Tang KT, 2014, PROC CVPR IEEE, P2995, DOI 10.1109/CVPR.2014.383
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Teutsch Michael, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P26, DOI 10.1109/CVPRW.2015.7301396
   Teutsch M, 2016, IEEE COMPUT SOC CONF, P1434, DOI 10.1109/CVPRW.2016.180
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 34
TC 6
Z9 6
U1 4
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29493
EP 29511
DI 10.1007/s11042-020-09383-7
EA AUG 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400004
DA 2024-07-18
ER

PT J
AU Wan, H
   Wang, H
   Scotney, B
   Liu, J
   Ng, WWY
AF Wan, Huan
   Wang, Hui
   Scotney, Bryan
   Liu, Jun
   Ng, Wing W. Y.
TI Within-class multimodal classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Within-class multimodality; Linear discriminant analysis; Subclass
   discriminant analysis; Separability-oriented subclass discriminant
   analysis
AB In many real-world classification problems there exist multiple subclasses (or clusters) within a class; in other words, the underlying data distribution is within-class multimodal. One example is face recognition where a face (i.e. a class) may be presented in frontal view or side view, corresponding to different modalities. This issue has been largely ignored in the literature or at least under studied. How to address the within-class multimodality issue is still an unsolved problem. In this paper, we present an extensive study of within-class multimodality classification. This study is guided by a number of research questions, and conducted through experimentation on artificial data and real data. In addition, we establish a case for within-class multimodal classification that is characterised by the concurrent maximisation of between-class separation, between-subclass separation and within-class compactness. Extensive experimental results show that within-class multimodal classification consistently leads to significant performance gains when within-class multimodality is present in data. Furthermore, it has been found that within-class multimodal classification offers a competitive solution to face recognition under different lighting and face pose conditions. It is our opinion that the case for within-class multimodal classification is established, therefore there is a milestone to be achieved in some machine learning algorithms (e.g. Gaussian mixture model) when within-class multimodal classification, or part of it, is pursued.
C1 [Wan, Huan; Wang, Hui; Liu, Jun] Ulster Univ, Sch Comp, Jordanstown, North Ireland.
   [Scotney, Bryan] Ulster Univ, Sch Comp, Coleraine, Londonderry, North Ireland.
   [Ng, Wing W. Y.] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Peoples R China.
C3 Ulster University; Ulster University; South China University of
   Technology
RP Wan, H (corresponding author), Ulster Univ, Sch Comp, Jordanstown, North Ireland.
EM h.wang@ulster.ac.uk; h.wang@ulster.ac.uk; bw.scotney@ulster.ac.uk;
   j.liu@ulster.ac.uk; wingng@ieee.org
RI wang, hui/HSG-6135-2023; Liu, Jun/C-1338-2011; wang, yue/ISA-4119-2023;
   Wang, Hui/HMU-9512-2023
OI Ng, Wing W. Y./0000-0003-0783-3585; Wang, Hui/0000-0003-2633-6015
FU EU [700381, H2020-EU.3.7.]
FX The work is partially funded by EU Horizon 2020 project "Analysis System
   for Gathered Raw Data" (Project Acronym: ASGARD, Project ID: 700381,
   Project Call: H2020-EU.3.7. - Secure societies - Protecting freedom and
   security of Europe and its citizens)
CR Bai Y, 2017, IEEE INT CON MULTI, P1452, DOI 10.1109/ICME.2017.8019371
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Dua D., 2017, UCI MACHINE LEARNING
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gkalelis N, 2011, IEEE SIGNAL PROC LET, V18, P319, DOI 10.1109/LSP.2011.2127474
   Hayashi, 2000, ECONOMETRICS
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Jia WJ, 2019, MATH FDN COMPUT, V2, P73, DOI 10.3934/mfc.2019006
   Kanghang He, 2018, IEEE Transactions on Smart Grid, V9, P1739, DOI 10.1109/TSG.2016.2598872
   Kaselimi M, 2020, IEEE T SMART GRID, V11, P3054, DOI 10.1109/TSG.2020.2974347
   Kaselimi M, 2019, INT CONF ACOUST SPEE, P2747, DOI 10.1109/ICASSP.2019.8683110
   Li CN, 2019, IEEE T NEURAL NETWOR
   Li HX, 2020, INFORM SCIENCES, V510, P283, DOI 10.1016/j.ins.2019.09.032
   Louppe G., 2014, Ph.D. thesis
   Martínez AM, 2005, IEEE T PATTERN ANAL, V27, P1934, DOI 10.1109/TPAMI.2005.250
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Murray D, 2019, INT CONF ACOUST SPEE, P8330, DOI 10.1109/ICASSP.2019.8682486
   Nie FP, 2020, ACM T KNOWL DISCOV D, V14, DOI 10.1145/3369870
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   RAO CR, 1948, J ROY STAT SOC B, V10, P159
   Seber G. A., 2012, Linear regression analysis, V329
   Sharma A, 2015, INT J MACH LEARN CYB, V6, P443, DOI 10.1007/s13042-013-0226-9
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vishwakarma VP, 2020, MULTIMED TOOLS APPL, V79, P11503, DOI 10.1007/s11042-019-08537-6
   Wan H, 2018, IEEE T PATTERN ANAL, V40, P409, DOI 10.1109/TPAMI.2017.2672557
   Wang F, 2019, IEEE T KNOWLEDGE DAT
   Wen YD, 2019, INT J COMPUT VISION, V127, P668, DOI 10.1007/s11263-018-01142-4
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Ye J, 2010, THEORY METHODS APPL
   Zhang W, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2018.2827948
   Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172
NR 32
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 29327
EP 29352
DI 10.1007/s11042-020-09238-1
EA AUG 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000559640400002
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Banu, SA
   Amirtharajan, R
AF Banu, S. Aashiq
   Amirtharajan, Rengarajan
TI Tri-level scrambling and enhanced diffusion for DICOM image cipher- DNA
   and chaotic fused approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Permutation; DNA diffusion; Tinkerbell map; DICOM
ID CRYPTANALYSIS
AB Tele-health and e-healthcare are some of the innovative e-commerce appliances that can eliminate the barrier between time and distance among health care centres and patients. The proposed work approaches the obstacle to secure digital medical image data in a public cloud. The most crucial part of e-healthcare and telemedicine industries is cyber-attacks. To thwart cyber-attacks, it is necessary to protect the medical images and transmit them securely. In this paper, a novel way of scrambling and Deoxyribonucleic Acid (DNA) sequence operations is performed to encrypt the digital medical images. A chaotic tri-level scrambling is carried out by a two dimensional Tinkerbell map. Experimental outcomes and security analyses such as statistical, differential, keyspace, encryption quality, along with chosen-plaintext attack analysis have been perpetrated to determine the feasibility and potency of the proposed Digital Imaging and Communications in Medicine (DICOM) image encryption method. The algorithm attains average entropy of 7.99 and near-zero correlation with NPCR and UACI of 99.6 and 33.4, respectively. Further, the efficiency of the algorithm is compared with the state of the literature encryption techniques.
C1 [Banu, S. Aashiq; Amirtharajan, Rengarajan] SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Amirtharajan, R (corresponding author), SASTRA Deemed Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM amir@ece.sastra.edu
RI Amirtharajan, Rengarajan/C-6471-2011
OI Amirtharajan, Rengarajan/0000-0003-1574-3045; , Dr. Aashiq
   Banu/0000-0002-7708-0307
FU Department of Science & Technology, New Delhi [SR/FST/ET-II/2018/221]
FX Authors thank Department of Science & Technology, New Delhi for the FIST
   funding (SR/FST/ET-II/2018/221). Also, Authors wish to thank the
   Intrusion Detection Lab at School of Electrical & Electronics
   Engineering, SASTRA Deemed University for providing infrastructural
   support to carry out this research work.
CR Al-Hazaimeh OM, 2019, NEURAL COMPUT APPL, V31, P2395, DOI 10.1007/s00521-017-3195-1
   Arumugham S, 2018, J BIOMED INFORM, V86, P90, DOI 10.1016/j.jbi.2018.08.010
   Banu SA, 2020, MED BIOL ENG COMPUT, V58, P1445, DOI 10.1007/s11517-020-02178-w
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chandrasekaran J, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/6729896
   Chidambaram N, 2019, MULTIMED TOOLS APPL, V78, P33837, DOI 10.1007/s11042-019-08166-z
   Dagadu JC, 2019, WIRELESS PERS COMMUN, V108, P591, DOI 10.1007/s11277-019-06420-z
   Dhall S, 2018, SIGNAL PROCESS, V146, P22, DOI 10.1016/j.sigpro.2017.12.021
   Dou YQ, 2017, OPTIK, V145, P456, DOI 10.1016/j.ijleo.2017.08.050
   Dzwonkowski M, 2019, IEEE T IMAGE PROCESS, V28, P371, DOI 10.1109/TIP.2018.2868388
   El Assad S, 2016, SIGNAL PROCESS-IMAGE, V41, P144, DOI 10.1016/j.image.2015.10.004
   Enayatifar R, 2017, OPT LASER ENG, V90, P146, DOI 10.1016/j.optlaseng.2016.10.006
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huo DM, 2019, PHYS LETT A, V383, P915, DOI 10.1016/j.physleta.2018.12.011
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Kumar R, 2019, J MOD OPTIC, V66, P776, DOI 10.1080/09500340.2019.1572807
   Li YT, 2019, MULTIMED TOOLS APPL, V78, P17973, DOI 10.1007/s11042-018-7122-y
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Parvees M. Y. Mohamed, 2018, International Journal of Cloud Computing, V7, P15
   Parvees MYM, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0809-1
   Praveenkumar P, 2018, MULTIMED TOOLS APPL, V77, P8393, DOI 10.1007/s11042-017-4741-7
   Rajagopalan S, 2020, IET IMAGE PROCESS, V14, P1354, DOI 10.1049/iet-ipr.2019.0562
   Rajagopalan S, 2018, MULTIMED TOOLS APPL, V77, P23449, DOI 10.1007/s11042-017-5566-0
   Ravichandran D, 2019, J SIGNAL PROCESS SYS, V91, P475, DOI 10.1007/s11265-018-1337-z
   Ravichandran D, 2017, IEEE T NANOBIOSCI, V16, P850, DOI 10.1109/TNB.2017.2780881
   Subashanthini S, 2020, INF SYST E-BUS MANAG, V18, P379, DOI 10.1007/s10257-019-00419-6
   Sun S, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2766087
   Suri S, 2019, J AMB INTEL HUM COMP, V10, P2277, DOI 10.1007/s12652-018-0825-0
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang Y, 2018, MULTIMED TOOLS APPL, V77, P21589, DOI 10.1007/s11042-017-5585-x
   Zhang YS, 2015, NONLINEAR DYNAM, V82, P1831, DOI 10.1007/s11071-015-2280-1
NR 35
TC 21
Z9 21
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 39-40
BP 28807
EP 28824
DI 10.1007/s11042-020-09501-5
EA AUG 2020
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NY7SQ
UT WOS:000556646300012
DA 2024-07-18
ER

PT J
AU Tagore, NK
   Chattopadhyay, P
   Wang, LP
AF Tagore, Nirbhay Kumar
   Chattopadhyay, Pratik
   Wang, Lipo
TI T-MAN: a neural ensemble approach for person re-identification using
   spatio-temporal information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatio-temporal information; Ensemble model; Person re-identification;
   Deep learning
AB Person re-identification plays a central role in tracking and monitoring crowd movement in public places, and hence it serves as an important means for providing public security in video surveillance application sites. The problem of person re-identification has received significant attention in the past few years, and with the introduction of deep learning, several interesting approaches have been developed. In this paper, we propose an ensemble model called Temporal Motion Aware Network (T-MAN) for handling the visual context and spatio-temporal information jointly from the input video sequences. Our methodology makes use of the long-range motion context with recurrent information for establishing correspondences among multiple cameras. The proposed T-MAN approach first extracts explicit frame-level feature descriptors from a given video sequence by using three different sub-networks (FPAN,MPN, andLSTM), and then aggregates these models using an ensemble technique to perform re-identification. The method has been evaluated on three publicly available data sets, namely, thePRID-2011,iLIDS-VID, andMARS, and re-identification accuracy of 83.0%, 73.5%, and 83.3% have been obtained from these three data sets, respectively. Experimental results emphasize the effectiveness of our approach and its superiority over the state-of-the-art techniques for video-based person re-identification.
C1 [Tagore, Nirbhay Kumar; Chattopadhyay, Pratik] BHU, Indian Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Varanasi 221005, Uttar Pradesh, India.
   [Wang, Lipo] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi); Banaras Hindu University
   (BHU); Nanyang Technological University
RP Chattopadhyay, P (corresponding author), BHU, Indian Inst Technol, Dept Comp Sci & Engn, Pattern Recognit Lab, Varanasi 221005, Uttar Pradesh, India.
EM nirbhaykrtag.rs.cse17@iitbhu.ac.in; pratik.cse@iitbhu.ac.in;
   ELPWang@ntu.edu.sg
RI Wang, Lipo/A-5154-2011
OI Chattopadhyay, Pratik/0000-0002-5805-6563
FU NVIDIA
FX The authors would like to acknowledge NVIDIA for supporting their
   research with a TITAN Xp Graphics processing unit.
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2008, P 19 BRIT MACH VIS C
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chen DY, 2011, P AM MATH SOC, V139, P2891, DOI 10.1090/S0002-9939-2011-10720-2
   Cheng L., 2019, METALL MAT T B, P1
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fawaz HI, 2019, ARXIV190306602
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gao CX, 2016, IEEE IMAGE PROC, P4284, DOI 10.1109/ICIP.2016.7533168
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Nguyen HD, 2019, MULTIMED TOOLS APPL, V78, P4563, DOI 10.1007/s11042-018-6141-z
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Karanam Srikrishna, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P33, DOI 10.1109/CVPRW.2015.7301392
   Kviatkovsky I, 2013, IEEE T PATTERN ANAL, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   MA B, 2012, P EUR C COMPUT VIS, P413, DOI DOI 10.1007/978-3-642-33863-241
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Ma M., 2019, MULTIMED TOOLS APPL, P1
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Mehdian S, 2017, P AMER CONTR CONF, P1747, DOI 10.23919/ACC.2017.7963205
   Minetto R, 2019, IEEE T GEOSCI REMOTE
   Ouyang W, 2017, CVPR, P5790, DOI DOI 10.1109/CVPR.2017.499
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Tagore NK, 2019, CROWD COUNTING HIGHL
   Muñoz DU, 2019, LECT NOTES COMPUT SC, V11506, P806, DOI 10.1007/978-3-030-20521-8_66
   Wang TQ, 2016, IEEE T PATTERN ANAL, V38, P2501, DOI 10.1109/TPAMI.2016.2522418
   Wang ZS, 2020, IEEE ACCESS, V8, P71353, DOI 10.1109/ACCESS.2020.2986267
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xiong K, 2014, NETW TELECOMMUN SER, P1, DOI 10.1002/9781118898598
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang X, 2019, MULTIMED TOOLS APPL, P1
   Ye M, 2019, IEEE T IMAGE PROCESS, V28, P2976, DOI 10.1109/TIP.2019.2893066
   Yo HF, 2020, IEEE T GEOSCI REMOTE, V58, P1281, DOI 10.1109/TGRS.2019.2945591
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2017, P IEEE C COMP VIS PA, P3346, DOI DOI 10.1109/CVPR.2017.357
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zhu XK, 2018, IEEE T IMAGE PROCESS, V27, P5683, DOI 10.1109/TIP.2018.2861366
NR 55
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28393
EP 28409
DI 10.1007/s11042-020-09398-0
EA AUG 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000555361800002
DA 2024-07-18
ER

PT J
AU Sharma, S
   Kumar, V
AF Sharma, Sahil
   Kumar, Vijay
TI Voxel-based 3D occlusion-invariant face recognition using game theory
   and simulated annealing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D mesh; Voxelization; Adversarial triplet loss; Generator;
   Discriminator; Simulated annealing
ID OPTIMIZATION; ALGORITHM; CLASSIFICATION; REGRESSION; DATABASE
AB A novel voxel-based occlusion-invariant 3D face recognition framework (V3DOFR) based on game theory and simulated annealing is proposed. In V3DOFR approach, 3D meshes are converted to voxel form of sizes 4(3), 8(3), and 16(3). After that, locality preserving projection-based embeddings are computed for removing the sparseness of voxels and generating consistent linear embedding per mesh with size 64 x 3, 128 x 3, and 256 x 3, respectively. The generator of triplets provides the triplets of sizes 64x3x3, 128x3x3, and 256x3x3. The simulated annealing is used to check the threshold value of adversarial triplet loss generated after ensembling losses of different grid sizes. The proposed framework is compared with four well-known methods using three face datasets, namely, Bosphorus, UMBDB, and KinectFaceDB. The performance evaluation has been done using four different cases of experimentations, viz. voxel based face recognition, occlusion invariant face recognition, landmarks based 3D face recognition, and 3D mesh based face recognition. Seven evaluation metrics are used to compare the proposed technique with other methods. The proposed method provides better accuracy and computation time over the other existing techniques in the majority of cases.
C1 [Sharma, Sahil] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
   [Kumar, Vijay] Natl Inst Technol, Comp Sci & Engn Dept, Hamirpur, India.
C3 Thapar Institute of Engineering & Technology; National Institute of
   Technology (NIT System); National Institute of Technology Hamirpur
RP Sharma, S (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM sahil301290@gmail.com; vijaykumarchahar@gmail.com
RI Sharma, Sahil/AAI-2846-2021; Sharma, Sahil/AAE-2833-2022; Sharma,
   Sahil/JXM-8658-2024; Chahar, Vijay Kumar/A-2782-2015
OI Sharma, Sahil/0000-0002-6694-3365; Sharma, Sahil/0000-0002-3187-4929;
   Chahar, Vijay Kumar/0000-0002-3460-6989
CR Abrevaya VF, 2019, IEEE I CONF COMP VIS, P9418, DOI 10.1109/ICCV.2019.00951
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   [Anonymous], 2007, ND 2006 FACE DATA SE
   [Anonymous], 2011, Biometrics (IJCB), 2011 International Joint Conference on
   [Anonymous], 2011, P ACM SIGGRAPH S HIG
   [Anonymous], 2005, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.268
   [Anonymous], 2016, in Face Detec-tion and Facial Image Analysis, DOI DOI 10.1007/978-3-319-25958-1_8
   [Anonymous], P 2008 8 IEEE INT C, DOI DOI 10.1109/AFGR.2008.4813324
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Bai S, 2017, AAAI CONF ARTIF INTE, P3967
   Bandyopadhyay S, 2001, INT J PATTERN RECOGN, V15, P269, DOI 10.1142/S0218001401000927
   Bandyopadhyay S, 2008, IEEE T EVOLUT COMPUT, V12, P269, DOI 10.1109/TEVC.2007.900837
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Bowyer KW, 2004, SURVEY 3D MULTIMODAL
   Caves R, 1998, IEEE T IMAGE PROCESS, V7, P1534, DOI 10.1109/83.725361
   Chen YH, 2009, J MACH LEARN RES, V10, P747
   Cho M., 2020, ARXIV200300697, V3, P7
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   di Bernardo M, 2011, IEEE INT SYMP CIRC S, P2713
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Do TT, 2019, PROC CVPR IEEE, P10396, DOI 10.1109/CVPR.2019.01065
   Dong YQ, 2018, ENERGIES, V11, DOI 10.3390/en11041009
   Dou P, 2017, PROC CVPR IEEE, P1503, DOI 10.1109/CVPR.2017.164
   El Sayed A, 2018, ARXIV181104358
   El Sayed AR, 2018, IMAGING SCI J, V66, P23, DOI 10.1080/13682199.2017.1376772
   Faltemier TC, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P19
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Goodfellow I., 2016, NIPS 2016 TUTORIAL G
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   He X., 2003, ADV NEURAL INFORM PR, P153
   He X, 2005, THESIS
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hong WC, 2019, APPL MATH MODEL, V72, P425, DOI 10.1016/j.apm.2019.03.031
   Hong WC, 2011, ENERGIES, V4, P960, DOI 10.3390/en4060960
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI DOI 10.5121/IJDKP.2015.5201
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   JIAO Y., 2019, 2019 IEEE Visual Communications and Image Processing (VCIP), P1
   Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Kim D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P133, DOI 10.1109/BTAS.2017.8272691
   Kingma D. P., 2014, arXiv
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Korshunov P., 2018, arXiv
   Larsen A.B.L, 2015, ARXIV151209300, DOI DOI 10.3390/RS12223815
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6
   Li HB, 2014, NEUROCOMPUTING, V133, P179, DOI 10.1016/j.neucom.2013.11.018
   Liu F., 2018, IEEE Transactions on Pattern Analysis and Machine Intelligence, P1
   Maulik U., 2001, Knowledge and Information Systems, V3, P374, DOI 10.1007/PL00011674
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Min R, 2014, IEEE T SYST MAN CY-S, V44, P1534, DOI 10.1109/TSMC.2014.2331215
   Moreno A.B., 2004, WHITENING RACE ESSAY, P75
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Ogáyar CJ, 2007, VISUAL COMPUT, V23, P535, DOI 10.1007/s00371-007-0097-8
   Parkhi OM, 2015, Proceedings of the British Machine Vision Conference, DOI DOI 10.5244/C.29.41
   Patil H, 2015, ARTIF INTELL REV, V44, P393, DOI 10.1007/s10462-015-9431-0
   Perarnau G., 2016, NIPS WORKSH ADV TRAI
   Pham HX, 2015, ARXIV150702779
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ranjan A, 2018, LECT NOTES COMPUT SC, V11207, P725, DOI 10.1007/978-3-030-01219-9_43
   Rathgeb C, 2019, IEEE ACCESS, V7, P152667, DOI 10.1109/ACCESS.2019.2948526
   Salimans T, 2016, ADV NEUR IN, V29
   Sanderson C., 2002, The vidtimit database
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Scherhag U, 2019, IEEE ACCESS, V7, P23012, DOI 10.1109/ACCESS.2019.2899367
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sharma SK, 2020, INT J ADV APPL SCI, V7, P1, DOI 10.21833/ijaas.2020.05.001
   Song Bai, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P774, DOI 10.1109/ICCV.2017.90
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Spreeuwers L, 2011, INT J COMPUT VISION, V93, P389, DOI 10.1007/s11263-011-0426-2
   TAN Y, 2018, ARXIV181009658
   Wang X., 2008, J CHANGCHUN U SCI TE, V31, P11
   Westberg S., 2018, arXiv preprint arXiv:1803.01164, DOI DOI 10.48550/ARXIV.1803.01164
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Wu Z., 2014, CoRR
   Xu D, 2008, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2008, PROCEEDINGS, P261, DOI 10.1109/SMI.2008.4547997
   Xu HC, 2017, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/aa7a3e
   Yang X-S, 2010, Nature-Inspired Metaheuristic Algorithms, V2
   Yi Dong, 2014, ARXIV14117923
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang J., 2020, PROC IEEECVFCONF COM, DOI DOI 10.1109/CVPR42600.2020.01256
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Y, 2015, EXPERT SYST APPL, V42, P8678, DOI 10.1016/j.eswa.2015.07.022
   Zhang ZC, 2020, IEEE ACCESS, V8, P14642, DOI 10.1109/ACCESS.2020.2966712
   Zhang ZC, 2019, NONLINEAR DYNAM, V98, P1107, DOI 10.1007/s11071-019-05252-7
   Zhao DP, 2013, INT J ADV ROBOT SYST, V10, DOI 10.5772/56759
   Zhao J, 2019, INT GEOSCI REMOTE SE, P4791, DOI [10.1109/igarss.2019.8900630, 10.1109/IGARSS.2019.8900630]
   Zhao Y, 2018, IRF2018: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON INTEGRITY-RELIABILITY-FAILURE, P507
   Zheng T., 2018, Tech. Rep., V5
   Zheng Tianyue, 2017, CROSS AGE LFW DATABA
   Zhou YX, 2019, PROC CVPR IEEE, P1097, DOI 10.1109/CVPR.2019.00119
   Zhu W., 2010, Northeast SAS Users Group 2010: Health Care and Life Sciences, P1
NR 99
TC 12
Z9 13
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26517
EP 26547
DI 10.1007/s11042-020-09331-5
EA JUL 2020
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000549313700005
DA 2024-07-18
ER

PT J
AU Roy, A
   Manam, L
   Laskar, RH
AF Roy, Amarjit
   Manam, Lalit
   Laskar, Rabul Hussain
TI Removal of 'Salt & Pepper' noise from color images using adaptive fuzzy
   technique based on histogram estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt and pepper noise; Noise percentage estimation; Adaptive fuzzy
   filter based on histogram estimation; Iterative filter; Gaussian mean
   filtering; And FSIMC
ID DENSITY IMPULSE NOISE; LINEAR PREDICTION; MEDIAN FILTERS
AB This paper presents an algorithm for removal of 'salt and pepper' noise from color images. Adaptive fuzzy filter based on histogram estimation (AFHE) has been proposed in which the size of the processing window is adapted based on local noise densities using fuzzy based criterion. In the algorithm, AFHE has been used iteratively and an additional Gaussian mean based iterative procedure has been incorporated for processing at mid and high density impulse noise corrupted image respectively. The experiments have been carried out on a large database for different classes of images and the performance is measured in terms of PSNR, SSIM and FSIMC. The proposed algorithm outperforms some of the existing state-of-the-art filters in terms of PSNR by at least 6 dB and in terms of the structural similarity by at least 0.3 over 50% noise density. The performance improvement is obtained keeping a trade-off between the restored image quality and the computational complexity. The visual observation, shown in this work, also suggests that the proposed filter provides satisfactory performance even when the image is corrupted at a high impulse noise of 90%.
C1 [Roy, Amarjit] BML Munjal Univ, Dept ECE, Kapriwas 122413, India.
   [Manam, Lalit] IISc, Dept Elect Engn, Bangalore 560012, Karnataka, India.
   [Laskar, Rabul Hussain] NIT, Dept ECE, Silchar 788010, India.
C3 BML Munjal University; Indian Institute of Science (IISC) - Bangalore;
   National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Roy, A (corresponding author), BML Munjal Univ, Dept ECE, Kapriwas 122413, India.
EM royamarjit90@gmail.com; l.manam1995@gmail.com; rabul18@yahoo.com
RI Roy, Amarjit/ABD-1033-2020; Laskar, Rabul Hussain/AFU-7180-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; Roy,
   Amarjit/0000-0003-3725-4568
FU Speech and Image Processing Laboratory, Department of Electronics and
   Communication Engineering, National Institute of Technology Silchar,
   India
FX The authors would like to acknowledge the Speech and Image Processing
   Laboratory, Department of Electronics and Communication Engineering,
   National Institute of Technology Silchar, India for providing the
   necessary support and facilities for carrying out this work.
CR Ahmed F, 2014, IEEE T FUZZY SYST, V22, P1352, DOI 10.1109/TFUZZ.2013.2286634
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Bhadouria VS, 2014, SIGNAL IMAGE VIDEO P, V8, P71, DOI 10.1007/s11760-013-0487-5
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Jung-Hua Wang, 1999, Proceedings of the National Science Council, Republic of China, Part A (Physical Science and Engineering), V23, P630
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Lukac R., 2003, International Journal of Applied Mathematics and Computer Science, V13, P369
   Masood S, 2014, APPL SOFT COMPUT, V21, P107, DOI 10.1016/j.asoc.2014.03.006
   Meher SK, 2014, AEU-INT J ELECTRON C, V68, P1173, DOI 10.1016/j.aeue.2014.06.006
   Pitas I., 1990, NONLINEAR DIGITAL FI
   POMALAZARAEZ CA, 1984, IEEE T ACOUST SPEECH, V32, P571, DOI 10.1109/TASSP.1984.1164361
   Rabbani H, 2008, IEEE T BIO-MED ENG, V55, P2152, DOI 10.1109/TBME.2008.923140
   Rahman T, 2014, 2014 17TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P217, DOI 10.1109/ICCITechn.2014.7073143
   Roy A, 2015, TENCON IEEE REGION
   Roy A, 2019, MULTIMED TOOLS APPL, V78, P1785, DOI 10.1007/s11042-018-6303-z
   Roy A, 2018, IEEE T IND ELECTRON, V65, P7268, DOI 10.1109/TIE.2018.2793225
   Roy A, 2017, AEU-INT J ELECTRON C, V72, P114, DOI 10.1016/j.aeue.2016.12.006
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Roy A, 2016, APPL SOFT COMPUT, V46, P816, DOI 10.1016/j.asoc.2015.09.032
   Schulte S, 2007, IMAGE VISION COMPUT, V25, P1377, DOI 10.1016/j.imavis.2006.10.002
   Singh KM, 2014, IMAGING SCI J, V62, P313, DOI 10.1179/1743131X14Y.0000000072
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Umbaugh SE., 1998, Computer Vision and Image Processing: A practical approach using CVIP tools, V6st ed.
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JT, 2014, SIGNAL PROCESS, V98, P359, DOI 10.1016/j.sigpro.2013.11.035
   Zhang CB, 2015, AEU-INT J ELECTRON C, V69, P226, DOI 10.1016/j.aeue.2014.09.006
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 28
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34851
EP 34873
DI 10.1007/s11042-020-09107-x
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000546865300002
DA 2024-07-18
ER

PT J
AU Ding, C
   Wang, WW
   He, HL
   Yang, WT
AF Ding, Chao
   Wang, Weiwei
   He, Hailang
   Yang, Wanting
TI Research on tomographic image reconstruction algorithms based on
   fixed-point rotation X-CT system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lambert law; TV constrained iterative FBP model; Central slice theorem;
   Passive ray drive
AB Aiming at the problem of parameter calibration and image reconstruction of typical two-dimensional CT system, this paper uses back projection, iradon function, Fourier transform, Lambert law, visualization and other methods to establish projection centroid model, convolution back projection model, TV constrained iterative filtering back projection model, and uses MATLAB, Solidworks, Lingo and other software to visualize data types, so as to achieve better results. Better to find X-CT system tomography reconstruction methods.
C1 [Ding, Chao; Wang, Weiwei; He, Hailang; Yang, Wanting] Anhui Jianzhu Univ, Coll Environm & Energy Engn, Hefei 230031, Anhui, Peoples R China.
   [Ding, Chao] Univ Sci & Technol China, State Key Lab Fire Sci, Hefei 230026, Peoples R China.
C3 Anhui Jianzhu University; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS
RP Ding, C (corresponding author), Anhui Jianzhu Univ, Coll Environm & Energy Engn, Hefei 230031, Anhui, Peoples R China.; Ding, C (corresponding author), Univ Sci & Technol China, State Key Lab Fire Sci, Hefei 230026, Peoples R China.
EM chalnity@mail.ustc.edu.cn
RI Yang, Wanting/JTT-7789-2023; Lan, Qingyuan/IQV-3646-2023; ding,
   chao/P-5458-2018
OI Yang, Wanting/0000-0002-6918-3701; Lan, Qingyuan/0000-0003-2067-8583;
   ding, chao/0000-0002-3267-1840
FU National Natural Science Foundation of China [51706218]; Open Project
   Program of the State Key Laboratory of Fire Science [HZ2020-KF01];
   National Key Research and Development Program of China [2018YFC0808600];
   Project of Anhui Jianzhu University 2019 Talent Research Program
   [2019QDZ21]
FX This work was supported by the National Natural Science Foundation of
   China under grant No. 51706218, the Open Project Program of the State
   Key Laboratory of Fire Science under grant No. HZ2020-KF01, the National
   Key Research and Development Program of China under grant No.
   2018YFC0808600 and the Project of Anhui Jianzhu University 2019 Talent
   Research Program under grant No. 2019QDZ21.
CR Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8
   Baek CH, 2015, NUCL INSTRUM METH A, V799, P132, DOI 10.1016/j.nima.2015.08.008
   Bieberle M, 2009, EXP FLUIDS, V47, P369, DOI 10.1007/s00348-009-0617-6
   Bingzhao F, 2018, MODERN IND EC INFORM, V15, P82
   Chunxia Sun, 2017, RES ALGORITHM SEGMEN
   Feng Wang, 2014, RES FORWARD INVERSE
   Guo L, 2016, RES CALIBRATION METH
   Johansen GA, 1996, MEAS SCI TECHNOL, V7, P297, DOI 10.1088/0957-0233/7/3/010
   Kim D, 2018, OPTIK, V161, P270, DOI 10.1016/j.ijleo.2018.02.049
   [戚玉涵 Qi Yuhan], 2016, [林业科学, Scientia Silvae Sinicae], V52, P121
   Ren QY, 2008, CHIN MED EQUIP J, V29, P32
   Suyi N, 2014, J OPT, V34, P346
   Wang W, 2018, ELECT TEST, V23, P53
   Wang X-L, 2007, THESIS
   Zhen Li, 2014, GEOMETRIC CALIBRATIO
NR 15
TC 0
Z9 0
U1 4
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25463
EP 25496
DI 10.1007/s11042-020-08861-2
EA JUL 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000545195600003
DA 2024-07-18
ER

PT J
AU Carfora, V
   Di Massimo, F
   Rastelli, R
   Catellani, P
   Piastra, M
AF Carfora, Valentina
   Di Massimo, Francesca
   Rastelli, Rebecca
   Catellani, Patrizia
   Piastra, Marco
TI Dialogue management in conversational agents through psychology of
   persuasion and machine learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Conversational agent; Theory of planned behavior; Psychology of
   persuasion; Machine learning; Reinforcement learning; Monte carlo tree
   search
ID FRAMED MESSAGES; MEAT; PROMOTION; CONSUMPTION; INTENTIONS; FRUIT
AB To be really effective, conversational agents must integrate well with the characteristics of the humans with whom they interact. This exploratory study focuses on a method for integrating well-assessed methods from the field of social psychology in the design of task-oriented conversational agents in which the dialogue management module is developed through machine learning. In particular, the aim is to achieve agents whose policies could take into account the psychological features of the human interactants to deliver personalized and more effective messages. The paper presents the psychological study performed and outlines the overall theoretical architecture of the software framework proposed. On the psychosocial side, we first assessed the effectiveness of differently framed messages aimed to reducing red meat consumption taking the Theory of Planned Behavior (TPB) as the psychosocial model of reference. Turning to the machine learning field, the resulting Structural Equation Model (SEM) was first translated into a probabilistic predictor using Dynamic Bayesian Network (DBN). In turn, such DBN became the fundamental element of a Partially Observable Markov Decision Processes (POMDP) in a reinforcement learning setting. The possibility to elicit complete interaction policies was then studied by applying Neural Monte Carlo Tree Search (Neural MCTS) methods. The results thus obtained introduce the possibility to develop new multidisciplinary and integrated techniques for the development of automated dialogue managing systems.
C1 [Di Massimo, Francesca; Rastelli, Rebecca; Piastra, Marco] Univ Pavia, Comp Vis & Multimedia Lab, Pavia, Italy.
   [Carfora, Valentina; Catellani, Patrizia] Univ Cattolica Milano, Dipartimento Psicol, Milan, Italy.
C3 University of Pavia; Catholic University of the Sacred Heart
RP Carfora, V (corresponding author), Univ Cattolica Milano, Dipartimento Psicol, Milan, Italy.
EM valentina.carfora@unicatt.it;
   francesca.dimassimo01@universitadipavia.it;
   rebecca.rastelli01@universitadipavia.it; patrizia.catellani@unicatt.it;
   marco.piastra@unipv.it
RI Carfora, Valentina/U-3352-2017
OI Carfora, Valentina/0000-0002-4111-6443; Catellani,
   Patrizia/0000-0002-7195-8967
CR AJZEN I, 1991, ORGAN BEHAV HUM DEC, V50, P179, DOI 10.1016/0749-5978(91)90020-T
   Bach-Faig A, 2011, PUBLIC HEALTH NUTR, V14, P2274, DOI 10.1017/S1368980011002515
   Bailey R, 2001, IEEE INT SYMP ELECTR, P4, DOI 10.1109/ISEE.2001.924494
   BEN GI, 2007, BAYESIAN NETWORKS EN
   Bertolotti M, 2020, APPL PSYCHOL-HLTH WE, V12, P212, DOI 10.1111/aphw.12180
   Bertolotti M, 2020, HEALTH COMMUN, V35, P475, DOI 10.1080/10410236.2019.1567444
   Bianchi F, 2019, BMJ OPEN, V9, DOI 10.1136/bmjopen-2018-027016
   Bohm I, 2015, APPETITE, V95, P101, DOI 10.1016/j.appet.2015.06.015
   Bosone L, 2017, INT REV SOC PSYCHOL, V30, P184, DOI 10.5334/irsp.15
   Carfora V, 2019, J ENVIRON PSYCHOL, V65, DOI 10.1016/j.jenvp.2019.101319
   Carfora V, 2017, APPETITE, V117, P152, DOI 10.1016/j.appet.2017.06.025
   Carfora V, 2019, APPETITE, V141, DOI 10.1016/j.appet.2019.104331
   Carfora V, 2018, APPETITE, V130, P236, DOI 10.1016/j.appet.2018.08.017
   Caso D., 2017, PSICOLOGIA SALUTE, V1, P97, DOI DOI 10.3280/PDS2017-001005
   Cesario J, 2013, J EXP SOC PSYCHOL, V49, P238, DOI 10.1016/j.jesp.2012.10.014
   CHASLOT G, 2008, BIJDRAGEN
   Cheng T, 2011, SOC MARK Q, V17, P48, DOI 10.1080/15245004.2011.570859
   Corrin T, 2017, APPETITE, V109, P40, DOI 10.1016/j.appet.2016.11.018
   DAGUM P, 1992, P 8 C UNC ART INT
   de Carolis B, 2017, INT J HUM-COMPUT ST, V108, P70, DOI 10.1016/j.ijhcs.2017.05.005
   Dijkstra A, 2011, PSYCHOL HEALTH, V26, P1036, DOI 10.1080/08870446.2010.526715
   Eagly A. H., 1993, PSYCHOL ATTITUDES
   Eshel G, 2006, EARTH INTERACT, V10, DOI 10.1175/EI167.1
   FABIANI P, 2010, MARKOV DECISION PROC
   Farchi S, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0182960
   Godinho CA, 2016, APPETITE, V96, P416, DOI 10.1016/j.appet.2015.10.001
   Graça J, 2015, APPETITE, V95, P113, DOI 10.1016/j.appet.2015.06.024
   Hancock G.R., 2007, Advances in Latent Variable Mixture Models
   Iacobucci D, 2010, J CONSUM PSYCHOL, V20, P90, DOI 10.1016/j.jcps.2009.09.003
   Kaelbling LP, 1998, ARTIF INTELL, V101, P99, DOI 10.1016/S0004-3702(98)00023-X
   Katt S, 2017, PR MACH LEARN RES, V70
   Kline R.B., 1988, PRINCIPLES PRACTICE
   Kocsis L, 2006, ENERGY AND THE ENVIRONMENT 2006, VOL I, P287
   Laczniak R.N., 1993, J PSYCHOL MARKETING, V10, P301
   LIU B, 2018, THESIS
   Misra R, 2018, CURR DIABETES REP, V18, DOI 10.1007/s11892-018-1071-8
   Pearl J., 1988, PROBABILISTIC REASON
   Petty R. E., 2012, Communication and persuasion: Central and peripheral routes to attitude change
   PETTY RE, 1984, ADV CONSUM RES, V11, P668
   Rothman AJ, 2006, J COMMUN, V56, pS202, DOI 10.1111/j.1460-2466.2006.00290.x
   Silver D., 2010, ADV NEURAL INFORM PR, P2164, DOI DOI 10.5555/2997046.2997137
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Stea S, 2019, ENVIRON COMMUN, V13, P633, DOI 10.1080/17524032.2017.1412994
   Stephenson MT, 2003, COMMUN RES, V30, P332, DOI 10.1177/0093650203030003004
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Vainio A, 2018, APPETITE, V125, P217, DOI 10.1016/j.appet.2018.02.002
   Weller KE, 2014, J NUTR EDUC BEHAV, V46, P324, DOI 10.1016/j.jneb.2014.01.002
   Wood W, 2000, ANNU REV PSYCHOL, V51, P539, DOI 10.1146/annurev.psych.51.1.539
   Zur I, 2014, BRIT FOOD J, V116, P629, DOI 10.1108/BFJ-08-2012-0193
NR 49
TC 22
Z9 23
U1 5
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35949
EP 35971
DI 10.1007/s11042-020-09178-w
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000543678900001
DA 2024-07-18
ER

PT J
AU Pinheiro, CAD
   Nedjah, N
   Mourelle, LD
AF de Pinho Pinheiro, Cesar Affonso
   Nedjah, Nadia
   Mourelle, Luiza de Macedo
TI Detection and classification of pulmonary nodules using deep learning
   and swarm intelligence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Swarm intelligence; Nodule detection; Convolutional
   neural networks
ID ALGORITHM; OPTIMIZATION; ABC
AB Cancer diagnosis is usually an arduous task in medicine, especially when it comes to pulmonary cancer, which is one of the most deadly and hard to treat types of that disease. Early detecting pulmonary cancerous nodules drastically increases surviving chances but also makes it an even harder problem to solve, as it mostly depends on a visual inspection of tomography scans. In order to help improving cancer detection and surviving rates, engineers and scientists have been developing computer-aided diagnosis systems, similar to the one presented in this paper. These systems are used as second opinions, to help health professionals during the diagnosis of numerous diseases. This work uses computational intelligence techniques to propose a new approach towards solving the problem of detecting pulmonary carcinogenic nodules in computed tomography scans. The applied technology consists of using Deep Learning and Swarm Intelligence to develop different nodule detection and classification models. We exploit seven different swarm intelligence algorithms and convolutional neural networks, prepared for biomedical image segmentation, to find and classify cancerous pulmonary nodules in the Lung Image Database Consortium and Image Database Resource Initiative (LIDC-IDRI) databases. The aim of this work is to use swarm intelligence to train convolutional neural networks and verify whether this approach brings more efficiency than the classic training algorithms, such as back-propagation and gradient descent methods. As main contribution, this work confirms the superiority of swarm-trained models over the back-propagation-based model for this application, as three out of the seven algorithms are proved to be superior regarding all four performance metrics, which are accuracy, precision, sensitivity, and specificity, as well as training time, where the best swarm-trained model operates 25% faster than the back-propagation model. The performed experiments show that the developed models can achieve up to 93.71% accuracy, 93.53% precision, 92.96% sensitivity, and 98.52% specificity.
C1 [de Pinho Pinheiro, Cesar Affonso; Nedjah, Nadia] Univ Estado Rio De Janeiro, Fac Engn, Dept Elect Engn & Telecommun, Rio De Janeiro, Brazil.
   [Mourelle, Luiza de Macedo] Univ Estado Rio De Janeiro, Fac Engn, Dept Syst Engn & Computat, Rio De Janeiro, Brazil.
C3 Universidade Federal de Juiz de Fora; Universidade do Estado do Rio de
   Janeiro; Universidade do Estado do Rio de Janeiro; Universidade Federal
   de Juiz de Fora
RP Nedjah, N (corresponding author), Univ Estado Rio De Janeiro, Fac Engn, Dept Elect Engn & Telecommun, Rio De Janeiro, Brazil.
EM cesaraffonso05@hotmail.com; nadia@eng.uerj.br; ldmm@eng.uerj.br
RI de Macedo Mourelle, Luiza/AAG-8935-2019
OI de Macedo Mourelle, Luiza/0000-0002-4680-2047; Nedjah,
   Nadia/0000-0002-1656-6397
CR [Anonymous], U NET
   [Anonymous], DETECTION LUNG CANC
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2012, GRAVITATIONAL SEARCH
   [Anonymous], 2017, FIREFLY MATING ALGOR
   [Anonymous], 2016, INT J ADV RES BASIC
   [Anonymous], 2017, ARXIV170509435
   [Anonymous], BIOPS
   [Anonymous], 2019, CAUS OF DEATH
   [Anonymous], CANC COSTS PROJ RES
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Chon A., 2017, Deep convolutional neural networks for lung cancer detection
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   Hossain MM, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P1, DOI 10.1109/ICCITechn.2015.7488032
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kennedy J., 1995, PARTICLE SWARM OPTIM
   Lee MC, 2010, ARTIF INTELL MED, V50, P43, DOI 10.1016/j.artmed.2010.04.011
   Mazurowski MA, 2008, NEURAL NETWORKS, V21, P427, DOI 10.1016/j.neunet.2007.12.031
   Morais RG, 2018, LECT NOTES ARTIF INT, V11056, P169, DOI 10.1007/978-3-319-98446-9_16
   Passino KM, 2010, INT J SWARM INTELL R, V1, P1, DOI 10.4018/jsir.2010010101
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sivakumar S, 2013, INT J ENG TECHNOL, V5, P179
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan Y, 2010, LECT NOTES COMPUT SC, V6145, P355
   Wang SH, 2015, INT J IMAG SYST TECH, V25, P153, DOI 10.1002/ima.22132
   Zhang Y, 2010, PROG ELECTROMAGN RES, V109, P325, DOI 10.2528/PIER10090105
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhou ZH, 2002, ARTIF INTELL MED, V24, P25, DOI 10.1016/S0933-3657(01)00094-X
NR 28
TC 20
Z9 21
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15437
EP 15465
DI 10.1007/s11042-019-7473-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900060
DA 2024-07-18
ER

PT J
AU Gonçalves, G
   Melo, M
   Vasconcelos-Raposo, J
   Bessa, M
AF Goncalves, Guilherme
   Melo, Miguel
   Vasconcelos-Raposo, Jose
   Bessa, Maximino
TI A novel method to enhance the touristic 360° promotional video
   experience
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual reality; Tourism promotion; User satisfaction; Interaction;
   Presence; Cybersickness; 360 degrees video
ID VIRTUAL-REALITY; TRAVEL; INFORMATION; TECHNOLOGY
AB Promotional 360 degrees videos are now widely used to promote touristic sites, giving consumers a more immersive glimpse of what they can expect from those places. However, these 360 degrees videos often comprise so much information that it overloads the users, not allowing them to benefit from such a rich multimedia experience. To overcome this issue, we propose and evaluate a novel method that allows the experience of immersive 360 degrees promotional videos to be more interactive and informative without overloading users. The evaluation study focuses on how the proposed interaction method performs versus the non-interactive method in terms of user satisfaction, presence, and cybersickness in both a low-immersive (computer monitor) setup and an immersive platform (head-mounted display (HMD)). Our sample (N = 50) was randomly divided into four groups: 360 degrees (computer monitor without interaction), 360 degrees Interaction (computer monitor with interaction), IVR360 degrees (HMD without interaction) and IVR360 degrees Interaction (HMD with interaction). The results show that the novel proposed method is preferred by users over the non-interactive approach regardless of the setup (low-immersive or immersive). For cybersickness, there were no differences across all the experimental scenarios. We conclude that our method has the potential to bring added value to touristic promotion when compared to conventional promotional approaches.
C1 [Goncalves, Guilherme; Vasconcelos-Raposo, Jose; Bessa, Maximino] UTAD, Vila Real, Portugal.
   [Melo, Miguel; Vasconcelos-Raposo, Jose; Bessa, Maximino] INESC TEC Inst Syst & Comp Engn, Informat Syst & Comp Graph, Porto, Portugal.
C3 University of Tras-os-Montes & Alto Douro; INESC TEC
RP Gonçalves, G (corresponding author), UTAD, Vila Real, Portugal.
EM guilhermeg@utad.pt
RI VASCONCELOS-RAPOSO, JOSÉ/G-3743-2010; Gonçalves,
   Guilherme/ISS-7521-2023; VASCONCELOS-RAPOSO, JOSE/JMB-6306-2023
OI VASCONCELOS-RAPOSO, JOSÉ/0000-0002-3456-9727; Gonçalves,
   Guilherme/0000-0002-3264-587X; Melo, Miguel/0000-0003-4050-3473; Bessa,
   Maximino/0000-0002-3002-704X
FU ERDF - European Regional Development Fund through the Operational
   Programme for Competitiveness and Internationalisation - COMPETE 2020
   Programme; Portuguese funding agency, FCT - Fundacao para a Ciencia e a
   Tecnologia [POCI-01-0145-FEDER-031309]
FX This work is financed by the ERDF - European Regional Development Fund
   through the Operational Programme for Competitiveness and
   Internationalisation - COMPETE 2020 Programme and by National Funds
   through the Portuguese funding agency, FCT - Fundacao para a Ciencia e a
   Tecnologia within project POCI-01-0145-FEDER-031309 entitled
   "PromoTourVR - Promoting Tourism Destinations with Multisensory
   Immersive Media".
CR Abou-Shouk M, 2013, J HOSP TOUR RES, V37, P490, DOI 10.1177/1096348012442544
   Andersson TD, 2007, SCAND J HOSP TOUR, V7, P46, DOI 10.1080/15022250701224035
   [Anonymous], 2009, HOSPITALITY TRAVEL M
   [Anonymous], 2020, Adobe Creative Cloud
   Benckendorff P J., 2014, CABI Tourism Texts, V2nd
   Buhalis D, 2008, TOURISM MANAGE, V29, P609, DOI 10.1016/j.tourman.2008.01.005
   Cheng S, 2011, J HOSP TOUR RES, V35, P488, DOI 10.1177/1096348010384598
   CHEONG R, 1995, TOURISM MANAGE, V16, P417, DOI 10.1016/0261-5177(95)00049-T
   Coelho Hugo, 2018, Trends and Advances in Information Systems and Technologies. Advances in Intelligent Systems and Computing (AISC 746), P309, DOI 10.1007/978-3-319-77712-2_30
   Coelho H, EXPERT SYSTEMS
   Coelho H, 2019, MULTIMED TOOLS APPL, V2019, P1
   Cramer D.B., 1968, Diagnostic criteria for grading the severity of acute motion sickness
   David S, 2014, PROCEEDINGS OF INTERNATIONAL CONFERENCE INFORMATION SYSTEMS AND DESIGN OF COMMUNICATION (ISDOC2014), P1, DOI 10.1145/2618168.2618169
   DUNN OJ, 1964, TECHNOMETRICS, V6, P241, DOI 10.2307/1266041
   Formica S, 2008, J TRAVEL RES, V46, P355, DOI 10.1177/0047287507312410
   GRETZEL U, 2003, SEARCHING FUTURE WHI
   Guttentag DA, 2010, TOURISM MANAGE, V31, P637, DOI 10.1016/j.tourman.2009.07.003
   HOBSON PERRY., 1994, Journal o f Vacation Marketing, V1, P125
   Huang YC, 2016, INT J TOUR RES, V18, P116, DOI 10.1002/jtr.2038
   Kennedy RS, 1993, The international journal of aviation psychology, V3, P203, DOI [DOI 10.1207/S15327108IJAP0303, 10.1207/s15327108ijap0303_3]
   Kim YY, 2005, PSYCHOPHYSIOLOGY, V42, P616, DOI 10.1111/j.1469-8986.2005.00349.x
   Kolasinski EM, 1995, TECH REP
   La Viola J. J.  Jr., 2000, SIGCHI Bulletin, V32, P47, DOI 10.1145/333329.333344
   Lee O, 2007, CYBERPSYCHOL BEHAV, V10, P584, DOI 10.1089/cpb.2007.9987
   Lewis J. R., 1991, SIGCHI Bulletin, V23, P78, DOI 10.1145/122672.122692
   MagalhAes M.R., 2017, THESIS
   Matos H, 2018, SPR TRANS CIV ENV EN, P1, DOI 10.1007/978-981-10-7170-6_1
   McCauley M. E., 1992, Presence: Teleoperators & Virtual Environments, V1, P311, DOI DOI 10.1162/PRES.1992.1.3.311
   Melo M, 2017, COMPUTERS GRAPHICS
   Moorhouse N, 2018, PROGR IS, P133, DOI 10.1007/978-3-319-64027-3_10
   Schubert T, 2001, PRESENCE-VIRTUAL AUG, V10, P266, DOI 10.1162/105474601300343603
   Schuemie JM, 2001, RES PRESENCE VIRTUAL, V4, P183
   Slater M, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00074
   Slater Mel, 2003, Presence connect, V3, P1, DOI DOI 10.3389/FNINS.2019.01409
   Tussyadiah IP, 2018, TOURISM MANAGE, V66, P140, DOI 10.1016/j.tourman.2017.12.003
   Tussyadiah IP., 2017, Information and Communication Technologies in Tourism 2017: Proceedings of the International Conference. Rome, P229, DOI DOI 10.1007/978-3-319-51168-917
   van Emmerik ML, 2011, DISPLAYS, V32, P169, DOI 10.1016/j.displa.2010.11.003
   Vasconcelos-Raposo J, 2016, PRESENCE-VIRTUAL AUG, V25, P191, DOI 10.1162/PRES_a_00261
   Wan ChinSheng Wan ChinSheng, 2007, Information Technology and Tourism, V9, P45, DOI 10.3727/109830507779637611
   Witmer BG, 1998, PRESENCE-TELEOP VIRT, V7, P225, DOI 10.1162/105474698565686
NR 40
TC 9
Z9 10
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22905
EP 22927
DI 10.1007/s11042-020-09026-x
EA JUN 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000537402100001
DA 2024-07-18
ER

PT J
AU Lee, S
   Jo, W
   Eo, S
   Shon, T
AF Lee, Seokjun
   Jo, Wooyeon
   Eo, Soowoong
   Shon, Taeshik
TI ExtSFR: scalable file recovery framework based on an Ext file system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Consumer electronics; Data recovery; Data security; Digital forensics;
   File systems
AB As the technologies based on the Internet of Things, the Cloud, Big Data, and mobile technology have recently become the engine of the next-generation fusion environment, the use of consumer electronics with Linux/Unix-based operating systems which include mobile and embedded operating systems has been gradually increasing. As these technologies are applied in the real world, digital forensics and post-processing techniques in the next-generation environment are required for security/privacy perspective. In this paper, an Ext2/3/4 file system's file recovery framework which is suitable for the next-generation environment is proposed. Also, Ext4 used from small to large size file systems in recent consumer electronics such as home appliances, mobile devices, home-office devices, entertainment devices, etc. The proposed framework takes the various Ext4 file systems created in the IoT/Cloud/Big Data/mobile environment into account, and it is configured to accommodate not only Ext4 used mainly in the recent environment but also Ext2/3 legacy environment. Additionally, the proposed framework is implemented as a prototype and validated it by comparing it with the existing commercial technologies, showing that the accuracy and efficiency of the prototype of the proposed framework for large file system recovery rates are superior to those of the existing technologies.
C1 [Lee, Seokjun] Kennesaw State Univ, Dept Comp Sci, Marietta, GA 30067 USA.
   [Jo, Wooyeon; Eo, Soowoong; Shon, Taeshik] Ajou Univ, Dept Comp Engn, Suwon 16499, South Korea.
C3 University System of Georgia; Kennesaw State University; Ajou University
RP Shon, T (corresponding author), Ajou Univ, Dept Comp Engn, Suwon 16499, South Korea.
EM slee235@kennesaw.edu; dndusdndus12@gmail.com; archinitus@gmail.com;
   tsshon@ajou.ac.kr
CR Alazab M., 2009, Ubiquitous Computing and Communication Journal, V4, P551
   [Anonymous], 2013, P 11 AUSTR DIGITAL F, DOI DOI 10.4225/75/57B3D766FB873
   [Anonymous], FILESYSTEM FORENSIC
   Fairbanks KD, 2012, DIGIT INVEST, V9, pS118, DOI 10.1016/j.diin.2012.05.010
   Gregorio N, 2007, TAKING ADVANTAGE EXT, P10
   Lee S, 2014, J SUPERCOMPUT, V70, P20, DOI 10.1007/s11227-014-1282-y
   Lee S, 2014, MOBILE NETW APPL, V19, P382, DOI 10.1007/s11036-014-0504-0
   Nabity P, 2010, P SW DECISION SCI I
   Naiqi L, 2008, COMP COMM CONTR MAN, V1, P519
   Park Y, 2016, MULTIMED TOOLS APPL, V75, P14721, DOI 10.1007/s11042-015-2713-3
   Piper S, 2005, INT FED INFORM P, V14, P245
   Poisel R., 2011, Journal of Wireless Mobile Networks, Ubiquitous Computing, and Dependable Applications, V2, P42
   Richard GG, 2006, COMMUN ACM, V49, P76, DOI 10.1145/1113034.1113074
   Seo J, 2015, PEER PEER NETW APPL, V8, P694, DOI 10.1007/s12083-013-0217-3
   Veenman Cor J., 2007, 2007 3rd International Symposium on Information Assurance and Security, P393
   Yoo B, 2012, MULTIMED TOOLS APPL, V61, P243, DOI 10.1007/s11042-010-0704-y
   Zhao S, 2008, COMPUT ENG DES
NR 17
TC 12
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16093
EP 16111
DI 10.1007/s11042-019-7199-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600016
DA 2024-07-18
ER

PT J
AU Li, WH
   Qu, F
   Liu, JL
   Sun, FD
   Wang, Y
AF Li, Wenhui
   Qu, Feng
   Liu, Jialun
   Sun, Fengdong
   Wang, Ying
TI A lane detection network based on IBN and attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lane detection; Deep learning; CNN; IBN-net; Attention
ID TRACKING
AB In intelligent transportation system and advanced driving assistant system, lane detection is an indispensable security link. At present, deep learning has been applied to the task of lane detection, and some methods used semantic segmentation to separate lanes from background. This paper presents a modified encoder-decoder network with instance-batch normalization net (IBN-NET) and attention mechanism based on LaneNet structure. In view of the shortcomings of batch normalization (BN) in capturing texture in end-to-end segmentation, we consider further optimizing this part from the idea of image style transfer, which we solve the problem by replacing pixel-wise classification for scene labeling with capturing content images structure. To take advantage of visual and appearance invariance of instance normalization in encoder stage, IBN layers are applied to replace normal BN layers. Secondly, attention mechanism is added to the network, forcing it to focus on lane regions. This structure is very suitable for two-class semantics segmentation task with only lane and background. The experimental results show that the method can improve detection effect.
C1 [Li, Wenhui; Qu, Feng; Liu, Jialun; Sun, Fengdong; Wang, Ying] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University
RP Qu, F (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM qufeng_jlu@163.com
RI Lu, Wang/JVO-0416-2024; Zeng, Yun/JFK-6190-2023; LI,
   Wenhui/JCD-9947-2023
OI Qu, Feng/0000-0002-0189-1760
CR Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   Azimi SM, 2018, AERIAL LANENET LANE
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   De Brabandere Bert, 2017, Semantic Instance Segmentation with a Discriminative Loss Function
   Ghafoorian M., 2018, 15 EUR C COMP VIS EC
   Gopalan R, 2012, IEEE T INTELL TRANSP, V13, P1088, DOI 10.1109/TITS.2012.2184756
   He B, 2016, IEEE INTELLIGENT VEH
   Huang X, 2018, MULTIMODAL UNSUPERVI
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kim J, 2017, IEEE COMPUT SOC CONF, P1194, DOI 10.1109/CVPRW.2017.158
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Liu GC, 2018, IEEE ACCESS, V6, P29283, DOI 10.1109/ACCESS.2018.2834916
   Liu S, 2017, IET IMAGE PROCESS, V11, P815, DOI 10.1049/iet-ipr.2016.0862
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu XL, 2017, PROC INT C TOOLS ART, P1128, DOI 10.1109/ICTAI.2017.00172
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Meyer A, 2018, P IEEE RSJ INT C INT, P871
   Neven D, 2018, IEEE INT VEH SYM, P286
   Niu JW, 2016, PATTERN RECOGN, V59, P225, DOI 10.1016/j.patcog.2015.12.010
   Oliveira Gabriel L, 2016, IEEE INT C INT ROB S
   Ozgunalp U, 2017, IEEE T INTELL TRANSP, V18, P621, DOI 10.1109/TITS.2016.2586187
   Pan X., 2017, SPATIAL DEEP SPATIAL
   Paszke A., 2016, ARXIV160602147
   Piao J, 2017, IET IMAGE PROCESS, V11, P1210, DOI 10.1049/iet-ipr.2016.0506
   Song W, 2018, IEEE SENS J PP, P1
   Tian L, 2018, 2018 IEEE 4TH INTERNATIONAL CONFERENCE ON CONTROL SCIENCE AND SYSTEMS ENGINEERING (ICCSSE 2018), P484, DOI 10.1109/CCSSE.2018.8724760
   Ulyanov Dmitry, 2016, arXiv
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xing Y, 2018, IEEE-CAA J AUTOMATIC, V5, P645, DOI 10.1109/JAS.2018.7511063
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Ye YY, 2018, IET INTELL TRANSP SY, V12, P513, DOI 10.1049/iet-its.2017.0143
   Yin W., 2016, Transactions of the Association for computational linguistics, V4, P259, DOI [DOI 10.1162/TACL_A_00097, DOI 10.1162/TACLA00244, 10.1162/tacla00097, DOI 10.1162/TACLA00097]
   Yu G, 2017, SAE INT J PASSENG CA, V11, DOI [10.4271/2017-01-1970, DOI 10.4271/2017-01-1970]
   Zhang H., 2018, ARXIV180508318
NR 34
TC 14
Z9 16
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16473
EP 16486
DI 10.1007/s11042-019-7475-x
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600037
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Zheng, ZQ
   Wang, C
   Gu, ZR
   Fu, M
   Yu, ZB
   Zheng, HY
   Wang, N
   Zheng, B
AF Zhao, Yan
   Zheng, Ziqiang
   Wang, Chao
   Gu, Zhaorui
   Fu, Min
   Yu, Zhibin
   Zheng, Haiyong
   Wang, Nan
   Zheng, Bing
TI Fine-grained facial image-to-image translation with an attention based
   pipeline generative adversarial framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained image-to-image generation; Facial images; GANs; Attention;
   Pipeline
ID DEEP; RECOGNITION; FEATURES; MODEL
AB Fine-grained feature detection and recognition is an important but tough work due to the resolution and noisy representation. Synthesize images with a specified tiny feature is even more challenging. Existing image-to-image generation studies usually focus on improving image generation resolution and increasing the representation learning abilities under coarse features. However, generating images with fine-grained attributes under an image-to-image framework is still a tough work. In this paper, we propose an attention based pipeline generative adversarial network (Atten-Pip-GAN) to generate various facial images under multi-label fine-grained attributes with only a neutral facial image. First, we use a pipeline adversarial structure to generate images with multiple features step by step. Second, we use an independent image-to-image framework as a prepossessing method to detection the small fine-grained features and provide an attention map to improve the generation performance of delicate features. Third, we also propose an attention-based location loss to improve the generated performance on small fine-grained features. We apply this method to an open facial image database RaFD and demonstrate the efficiency of Atten-Pip-GAN on generating fine-grained attribute facial images.
C1 [Zhao, Yan; Wang, Chao] Ocean Univ China, Coll Informat Sci & Engn, 238 Songling Rd, Qingdao, Shandong, Peoples R China.
   [Zheng, Ziqiang] Ocean Univ China, 238 Songling Rd, Qingdao, Shandong, Peoples R China.
   [Gu, Zhaorui; Fu, Min; Yu, Zhibin; Zheng, Haiyong; Wang, Nan; Zheng, Bing] Ocean Univ China, Dept Elect Engn, 238 Songling Rd, Qingdao, Shandong, Peoples R China.
C3 Ocean University of China; Ocean University of China; Ocean University
   of China
RP Yu, ZB (corresponding author), Ocean Univ China, Dept Elect Engn, 238 Songling Rd, Qingdao, Shandong, Peoples R China.
EM yuzhibin@ouc.edu.cn
RI fu, mingyu/KHW-8636-2024; FU, MINGYU/GRS-3707-2022; Fu,
   Ming/HMD-6061-2023; Yu, Zhibin/Z-1138-2019
OI Fu, Ming/0000-0003-2734-6725; Yu, Zhibin/0000-0003-4372-1767
CR [Anonymous], 2017, Advances in neural information processing systems
   [Anonymous], 2017, P ASM 36 INT C OC
   [Anonymous], 2015, Open Source Computer Vision Library
   Bau David, 2018, arXiv preprint arXiv:1811.10597
   Brock Andrew, 2018, ARXIV180911096
   Calvo MG, 2008, BEHAV RES METHODS, V40, P109, DOI 10.3758/BRM.40.1.109
   Che Tong, 2016, CoRR
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Cong DC, 2019, INT CONF ACOUST SPEE, P1892, DOI [10.1109/icassp.2019.8683673, 10.1109/ICASSP.2019.8683673]
   Dauphin Y. N., 2017, arXiv preprint arXiv: 1703.09452v3
   Elfenbein HA, 2002, PSYCHOL BULL, V128, P203, DOI 10.1037//0033-2909.128.2.203
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Ge Z, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1, DOI 10.1109/ROBIO.2016.7866266
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heusel M., 2017, ADV NEURAL INFORM PR, V30, P6626
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang H., 2018, ARXIV180304469
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kan M, 2014, PROC CVPR IEEE, P1883, DOI 10.1109/CVPR.2014.243
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Kim T, 2017, PR MACH LEARN RES, V70
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kingma D. P., 2014, arXiv
   Kingma D. P., 2013, ARXIV13126114
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee HS, 2006, PATTERN RECOGN LETT, V27, P747, DOI 10.1016/j.patrec.2005.11.003
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu HM, 2019, IEEE WIREL COMMUN, V26, P90, DOI 10.1109/MWC.2019.1800325
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, FUTURE GENER COMP SY, V82, P142, DOI 10.1016/j.future.2018.01.001
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Maji, 2017, BMVC
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Ou WH, 2020, MULTIMED TOOLS APPL, V79, P14733, DOI 10.1007/s11042-019-7343-8
   Ou WH, 2018, PATTERN RECOGN LETT, V107, P41, DOI 10.1016/j.patrec.2017.07.006
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sicre R, 2015, COMPUT VIS IMAGE UND, V141, P28, DOI 10.1016/j.cviu.2015.08.002
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang ZH, 2018, NEUROCOMPUTING, V275, P1231, DOI 10.1016/j.neucom.2017.09.061
   Xiao LX, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511399
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Yu SY, 2017, NEUROCOMPUTING, V257, P97, DOI 10.1016/j.neucom.2016.09.116
   Zhang H., 2018, ARXIV180508318
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zheng Z, 2017, ARXIV171110742
   Zhou Q, 2019, WORLD WIDE WEB, V22, P555, DOI 10.1007/s11280-018-0556-3
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 64
TC 2
Z9 2
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14981
EP 15000
DI 10.1007/s11042-019-08346-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900037
DA 2024-07-18
ER

PT J
AU Zhong, Y
   Liu, LZ
   Zhao, D
   Li, HY
AF Zhong, Yue
   Liu, Lizhuang
   Zhao, Dan
   Li, Hongyang
TI A generative adversarial network for image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Generative adversarial network; Densenet;
   Wasserstein-GAN
ID IMPLEMENTATION
AB Recent studies have shown that the performance of image denoising methods can be improved significantly by using deep convolutional neural networks(CNN). The traditional CNN ways mainly focus on minimizing the Mean Squared Error (MSE), resulting in a feeling that the images lack of high-frequency details. So we apply a generative adversarial network (GAN) in image denoising. A very deep convolutional densenet framework is acting as our generator, which benefits in easing the vanishing-gradient problem of very deep networks. Moreover, we use Wasserstein-GAN as our loss function to stabilize the training process. Also, the Wasserstein distance between real and generated images from discriminator can be regarded as an indicator that has been proved highly relevant to the quality of the generated sample. A photo-realistic image with higher quality can be produced through our work than in traditional ways.
C1 [Zhong, Yue] Shanghai Univ, Shanghai 200444, Peoples R China.
   [Zhong, Yue; Liu, Lizhuang; Zhao, Dan; Li, Hongyang] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China.
C3 Shanghai University; Chinese Academy of Sciences; Shanghai Advanced
   Research Institute, CAS
RP Liu, LZ (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai 201210, Peoples R China.
EM zhongyue@sari.ac.cn; liulz@sari.ac.cn; zhaodan@sari.ac.cn;
   lihongyang@sari.ac.cn
CR Abadi Martin, 2016, TENSORFLOW LARGE SCA, V16, P265
   [Anonymous], 2016, JMLR INT C MACH LEAR
   Arjovsky M., 2017, ARXIV170107875
   Ba J. L., 2016, LAYER NORMALIZATION, DOI DOI 10.48550/ARXIV.1607.06450
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Burger H., 2012, CVPR
   Divakar N, 2017, IEEE COMPUT SOC CONF, P1076, DOI 10.1109/CVPRW.2017.145
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Goodfellow IJ, 2017, ADV NEUR IN, V2, P2672
   Gulrajani I., 2017, Advances in neural information processing systems, P5769
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P96, DOI 10.5201/ipol.2012.llm-ksvd
   Lebrun M, 2012, IMAGE PROCESS ON LIN, V2, P175, DOI 10.5201/ipol.2012.l-bm3d
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338
   Lehtinen J, 2018, PR MACH LEARN RES, V80
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Radford A., 2015, ARXIV
   Salimans T, 2016, ADV NEUR IN, V29
   Su F, 2016, 2016 16TH INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES (ISCIT), P280, DOI 10.1109/ISCIT.2016.7751636
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Timofte R, 2017, IEEE COMPUT SOC CONF, P1110, DOI 10.1109/CVPRW.2017.149
   Tong T, 2017, IEEE I CONF COMP VIS, P4809, DOI 10.1109/ICCV.2017.514
   Xiong RQ, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2621478
   Xu B., 2015, Empirical evaluation of rectified activations in convolutional network, DOI DOI 10.48550/ARXIV.1505.00853
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
NR 30
TC 22
Z9 25
U1 3
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 16517
EP 16529
DI 10.1007/s11042-019-7556-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600040
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Gao, XY
   Wang, LF
   Gao, ED
AF Pan, Zhibin
   Gao, Xinyi
   Wang, Lingfei
   Gao, Erdun
TI Effective reversible data hiding using dynamic neighboring pixels
   prediction based on prediction-error histogram
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding (RDH); Prediction-error histogram (PEH)
   modification; Gradient feature; Dynamic neighboring pixels (DNP)
   predictor; Parameter selection
ID EMBEDDING STRATEGY; IMAGE; PVO; STEGANOGRAPHY; WATERMARKING; ALGORITHM;
   EXPANSION
AB In this paper, an efficient PEH-based scheme using dynamic neighboring pixels (DNP) predictor and adaptive embedding strategy is proposed. Concerning four gradient regions (horizontal/vertical/rhombus/plane gradient region) of the current pixel, the prediction method is generated adaptively by DNP predictor. After complexity calculating, the current pixel belonging to the flat, semi-flat and normal areas are applied for histogram modification and data embedding. Moreover, by using our selection strategy of thresholds and embedding bin pairs, the search procedure is accelerated and higher fidelity of stego-image is obtained. Experimental results indicate that our dynamic neighboring pixels prediction-error histogram (DNPPEH) scheme is more effective comparing with six state-of-the-art histogram-based RDH schemes in spatial domain.
C1 [Pan, Zhibin; Gao, Xinyi; Wang, Lingfei; Gao, Erdun] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.; Pan, ZB (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Peoples R China.
EM zbpan@xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
CR Abu-Marie W, 2010, INT J SIG IMAGE PROC, V1
   [Anonymous], 2012, PROC IWDW
   Chen XY, 2017, J INTERNET TECHNOL, V18, P313, DOI 10.6138/JIT.2017.18.2.20160815
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Coltuc D, 2011, IEEE T INF FOREN SEC, V6, P873, DOI 10.1109/TIFS.2011.2145372
   Dragoi IC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549458
   Feng GR, 2012, J SYST SOFTWARE, V85, P392, DOI 10.1016/j.jss.2011.08.033
   Gao ED, 2019, INFORM SCIENCES, V505, P549, DOI 10.1016/j.ins.2019.07.101
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   He WG, 2017, J VIS COMMUN IMAGE R, V49, P351, DOI 10.1016/j.jvcir.2017.10.001
   He WG, 2017, J VIS COMMUN IMAGE R, V46, P58, DOI 10.1016/j.jvcir.2017.03.010
   Hong TP, 2010, APPL COMPUT INTELL S, V2010, DOI 10.1155/2010/360796
   Hong WE, 2010, J SYST SOFTWARE, V83, P2653, DOI 10.1016/j.jss.2010.08.047
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Howard PG, 1998, IEEE T CIRC SYST VID, V8, P838, DOI 10.1109/76.735380
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Jia YJ, 2019, SIGNAL PROCESS, V163, P238, DOI 10.1016/j.sigpro.2019.05.020
   Kim S, 2018, INT J TECHNOL ASSESS, V34, P78, DOI 10.1017/S0266462317004500
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lukac R, 2004, IEEE T CONSUM ELECTR, V50, P15, DOI 10.1109/TCE.2004.1277836
   Ma XX, 2015, J VIS COMMUN IMAGE R, V28, P71, DOI 10.1016/j.jvcir.2015.01.012
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2017, NEUROCOMPUTING, V226, P23, DOI 10.1016/j.neucom.2016.11.017
   Ou B, 2016, J VIS COMMUN IMAGE R, V38, P328, DOI 10.1016/j.jvcir.2016.03.011
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Pan ZB, 2019, MULTIMED TOOLS APPL, V78, P26047, DOI 10.1007/s11042-019-7692-3
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Peng F, 2014, DIGIT SIGNAL PROCESS, V25, P255, DOI 10.1016/j.dsp.2013.11.002
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang C, 2010, IEEE IMAGE PROC, P3673, DOI 10.1109/ICIP.2010.5652508
   Wang LF, 2014, J VIS COMMUN IMAGE R, V25, P454, DOI 10.1016/j.jvcir.2013.12.004
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Weng SW, 2017, J VIS COMMUN IMAGE R, V48, P317, DOI 10.1016/j.jvcir.2017.05.005
   Weng SW, 2016, INFORM SCIENCES, V369, P144, DOI 10.1016/j.ins.2016.05.030
   Wu HT, 2012, SIGNAL PROCESS, V92, P3000, DOI 10.1016/j.sigpro.2012.05.034
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Yuan CS, 2017, J INTERNET TECHNOL, V18, P435, DOI 10.6138/JIT.2017.18.2.20160624c
NR 48
TC 10
Z9 10
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12569
EP 12595
DI 10.1007/s11042-019-08335-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400058
DA 2024-07-18
ER

PT J
AU Shen, LL
   Hang, N
   Hou, CP
AF Shen, Lili
   Hang, Ning
   Hou, Chunping
TI Feature-segmentation strategy based convolutional neural network for
   no-reference image quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE No-reference image quality assessment; Deep learning; Convolutional
   neural network(CNN); Feature-segmentation
ID ENHANCEMENT; STATISTICS
AB Convolutional neural networks (CNN) have been shown to deliver outstanding performance for image quality assessment (IQA). Most CNN models are trained using small image patches with a fixed resolution of 32 x 32. However, more information of image content and human visual system should be taken into account. This paper proposes a post segmentation based CNN model for no-reference quality assessment without any pre-processing. The network consists of five convolutional layers with max pooling, one special fully connected layer feature-segmentation and one output layer. This paper adopts the feature-segmentation strategy to assure enough training data. We modify the structure of fully connected layer and regard every feature vector of the last pooling maps as an independent sample to train our proposed model. In this way, the raw images can be fed into the input and do not need to be split into patches, to avoid any hand-crafted features. Moreover, the size of the input images is not fixed, and the size of the extracted feature vector is invariant. Experiments on LIVE, CSIQ and TID2008 databases demonstrate that our approach has high consistency with the subjective evaluation scores. The experimental results show that the proposed network outperforms state-of-the-art no-reference IQA algorithms and is comparable to some full-reference IQA algorithms.
C1 [Shen, Lili; Hang, Ning; Hou, Chunping] Tianjin Univ, Sch Elect & Informat Engn, Weijin Rd, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Shen, LL (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Weijin Rd, Tianjin 300072, Peoples R China.
EM sll@tju.edu.cn; hangning@tju.edu.cn; hcp@tju.edu.cn
RI shen, lili/IUQ-2187-2023
CR Bosse S, 2018, IEEE T IMAGE PROCESS, V27, P206, DOI 10.1109/TIP.2017.2760518
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Group VQE, 2000, PHAS 2 FR TV2 VQEG M
   Gu J, 2018, IEEE T MULTIMEDIA, V20, P1140, DOI 10.1109/TMM.2017.2761993
   Hao SJ, 2019, MULTIMED TOOLS APPL, V78, P3817, DOI 10.1007/s11042-018-6257-1
   Hao SJ, 2016, SIGNAL PROCESS, V120, P789, DOI 10.1016/j.sigpro.2015.02.017
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Holzinger Andreas, 2018, 2018 World Symposium on Digital Intelligence for Systems and Machines (DISA). Proceedings, P55, DOI 10.1109/DISA.2018.8490530
   Holzinger A, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1312
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jin X, 2017, INFORM SYST FRONT, V19, P1357, DOI 10.1007/s10796-016-9650-1
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim J, 2017, IEEE J-STSP, V11, P206, DOI 10.1109/JSTSP.2016.2639328
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Liu X, 2017, RANKIQA LEARN RANK N
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P1202, DOI 10.1109/TIP.2017.2774045
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Wu J, 2018, IEEE INT C IM PROC
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 28
TC 4
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11891
EP 11904
DI 10.1007/s11042-019-08298-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400028
DA 2024-07-18
ER

PT J
AU Zhang, H
   Zhao, L
   Dai, G
AF Zhang, Hong
   Zhao, Liang
   Dai, Gang
TI Surveillance videos classification based on multilayer long short-term
   memory networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video recognition; Deep learning; Resnet; LSTM
ID CONVOLUTIONAL NETWORKS; FACE
AB Image classification and video recognition are always a key issue in computer vision. Until now, the recognition of videos has not achieved good results in some application filed, such as the recognition of surveillance videos. In order to achieve better recognition results, in this paper, we propose a new algorithm to recognize video by five coherent pictures. Firstly, the features of the video frames are extracted by Resnet, and then the features are sent to a 2-layer LSTM for processing, and finally classification by gathering the fully connected layer. We use the collected shipping data as a dataset to detect the algorithm model in this paper. The results of experiment show that the recognition of the proposed algorithm are better than other methods, and the total accuracy increased from 0.967 to 0.981.
C1 [Zhang, Hong; Zhao, Liang; Dai, Gang] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.
   [Zhang, Hong; Zhao, Liang; Dai, Gang] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
C3 Wuhan University of Science & Technology
RP Zhang, H (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430081, Peoples R China.; Zhang, H (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan, Peoples R China.
EM zhanghong_wust@163.com
CR [Anonymous], 2007, CIVR '07
   [Anonymous], SUPERVISED SEQUENCE
   [Anonymous], 2011, P 4 INT C ART INT ST
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Ballas Nicolas, 2015, ARXIV151106432
   Bengio Y, 2013, INT CONF ACOUST SPEE, P8624, DOI 10.1109/ICASSP.2013.6639349
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chen YN, 2006, INT C PATT RECOG, P552
   Cho Kyunghyun, 2014, SYNTAX SEMANTICS STR, P5, DOI [10.3115/v1/w14-4012, 10.3115 /v1/D14-1179, DOI 10.3115/V1/D14-1179]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2017, IEEE T PATTERN ANAL, V39, P677, DOI 10.1109/TPAMI.2016.2599174
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hochreiter S, 1998, INT J UNCERTAIN FUZZ, V6, P107, DOI 10.1142/S0218488598000094
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kiperwasser E.Goldberg., 2016, Simple and accurate dependency parsing using bidirectional lstm feature representations
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Simonyan K, 2014, ADV NEUR IN, V27
   Sutskever I., 2013, TRAINING RECURRENT N
   Szarvas M, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P224
   Tivive FHC, 2005, ISSPA 2005: THE 8TH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P90
   Tivive FHC, 2003, IEEE IJCNN, P2157
   Wang XY, 2015, PROC CVPR IEEE, P4418, DOI 10.1109/CVPR.2015.7299071
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhu LG, 2019, IRONMAK STEELMAK, V46, P499, DOI 10.1080/03019233.2017.1405153
NR 36
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 12125
EP 12137
DI 10.1007/s11042-019-08431-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400038
DA 2024-07-18
ER

PT J
AU Zhang, WF
   Hu, H
   Hu, HY
   Yu, J
AF Zhang, Weifeng
   Hu, Hua
   Hu, Haiyang
   Yu, Jing
TI Automatic image annotation via category labels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic image annotation; Image understanding; Deep learning; Sparse
   coding
ID RECOGNITION
AB Automatic image annotation aims to assign relevant keywords to images and has become a research focus. Although many techniques have been proposed to solve this problem in the last decade, giving promissing performance on standard datasets, we propose a novel automatic image annotation technique in this paper. Our method uses a label transfer mechanism to automatically recommend those promising tags to each image by using the category information of images. As image representation is one of the key technique in image annotation, we use sparse coding based spatial pyramid matching and deep convolutional neural networks to model image features. And metric learning technique is further used to combine these features to achieve more effective image representation in this paper. Experimental results illustrate that the proposed method get similar or better results than the state-of-the-art methods on three standard image datasets.
C1 [Zhang, Weifeng] Jiaxing Univ, Coll Math Phys & Informat Engn, Jiaxing, Zhejiang, Peoples R China.
   [Hu, Hua; Hu, Haiyang] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Hu, Hua] Hangzhou Normal Univ, Sch Informat Sci & Engn, Hangzhou, Peoples R China.
   [Yu, Jing] Chinese Acad Sci, Inst Informat Engn, Beijing, Peoples R China.
C3 Jiaxing University; Hangzhou Dianzi University; Hangzhou Normal
   University; Chinese Academy of Sciences; Institute of Information
   Engineering, CAS
RP Hu, H; Hu, HY (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.; Hu, H (corresponding author), Hangzhou Normal Univ, Sch Informat Sci & Engn, Hangzhou, Peoples R China.
EM 244235824@qq.com; huhua@hdu.edu.cn; haiyanghu@hdu.edu.cn;
   yujing02@iie.ac.cn
CR [Anonymous], ICMLC
   [Anonymous], 2015, ASK ME ANYTHING DYNA
   [Anonymous], 2008, P 17 INT C WORLD WID
   [Anonymous], NIPS
   [Anonymous], 2003, P 11 ACM INT C MULT
   [Anonymous], 2018, MODELING TEXT GRAPH
   [Anonymous], 2006, IEEECOMPUT SOC C COM
   [Anonymous], IEEE T NEURAL NETWOR
   [Anonymous], INL PAC RIM C MULT A
   [Anonymous], CIVR
   [Anonymous], ACM MM
   Barnard K, 2005, ARTIF INTELL, V167, P13, DOI 10.1016/j.artint.2005.04.009
   Chen JJ, 2014, INT C TRANS OPT NETW
   Dehghani M, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P65, DOI 10.1145/3077136.3080832
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hare JS, 2006, PROC SPIE, V6073, DOI 10.1117/12.647755
   Haug T, 2018, LECT NOTES COMPUT SC, V10772, P611, DOI 10.1007/978-3-319-76941-7_52
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jeon J., 2003, P 26 ANN INT ACM SIG
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavrenko V, 2004, ADV NEUR IN, V16, P553
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Li ZC, 2013, PATTERN RECOGN, V46, P2700, DOI 10.1016/j.patcog.2013.03.016
   Moran S., 2014, P INT C MULTIMEDIA R, P113
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Song JK, 2018, IEEE T IMAGE PROCESS, V27, P3210, DOI 10.1109/TIP.2018.2814344
   Song J, 2016, IEEE T IMAGE PROCESS, V25, P4999, DOI 10.1109/TIP.2016.2601260
   Song Y, 2008, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE 2007, VOL 6, PTS A AND B, P515, DOI 10.1145/1390334.1390423
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Verma Y, 2012, LECT NOTES COMPUT SC, V7574, P836, DOI 10.1007/978-3-642-33712-3_60
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang Xianghui, 2004, Chinese Journal of Clinical Oncology, V1, P10
   Wang XH, 2017, IEEE SIGNAL PROC LET, V24, P510, DOI 10.1109/LSP.2016.2611485
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Wu XP, 2018, MAGN RESON MED, V80, P1857, DOI 10.1002/mrm.27189
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang W, 2018, ACTA PHARMACOL SIN, V39, P1, DOI 10.1038/aps.2017.77
NR 45
TC 3
Z9 3
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 17-18
BP 11421
EP 11435
DI 10.1007/s11042-019-07929-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LK4YJ
UT WOS:000530872400007
DA 2024-07-18
ER

PT J
AU Hao, PY
   Ye, TT
   Xie, XH
   Wu, FL
   Ding, WL
   Zuo, WH
   Chen, W
   Wu, J
   Luo, XN
AF Hao, Pengyi
   Ye, Taotao
   Xie, Xuhang
   Wu, Fuli
   Ding, Weilong
   Zuo, Wuheng
   Chen, Wei
   Wu, Jian
   Luo, Xiaonan
TI Radiographs and texts fusion learning based deep networks for skeletal
   bone age assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bone age assessment; Convolutional neural network; Attention mechanism;
   Spatial pyramid pooling; Fusion learning
AB Bone age assessment is a pediatric examination that determines the difference between skeletal age and chronological age. The discrepancy between the two ages will often trigger the likelihood of genetic disorders, hormonal complications and abnormalities of maturity in the skeletal system. Recently, although some automated bone age assessment methods by analyzing radiographs have been researched, the available text data from radiological reports are not used. Texts and radiographs are two different modals, the fusion of them can give us much more information for bone age assessment. In this paper, we present a novel multi-modal data fusion-learning network, called RT-FuseNet, for bone age assessment utilizing radiographs and texts. Specifically, we develop a convolutional neural network with spatial pyramid pooling layer and attention mechanism module to ensure the integrity of the image space information and enhance the subtle difference of features among radiographs respectively. In addition, texts are incorporated into the learning model to jointly learn non-linear correlations between various heterogeneous data. To evaluate the proposed approach, two datasets are used and several neural network structures are compared. Experimental results show that the proposed approach performs well.
C1 [Hao, Pengyi; Ye, Taotao; Xie, Xuhang; Wu, Fuli; Ding, Weilong] Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Zuo, Wuheng] Zhejiang Univ Technol, Coll Educ Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Chen, Wei] Zhejiang Univ, Affiliated Hosp 1, Hangzhou, Peoples R China.
   [Chen, Wei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Peoples R China.
   [Wu, Jian] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Wu, Jian] Zhejiang Univ, Real Doctor Res Ctr, Hangzhou, Zhejiang, Peoples R China.
   [Luo, Xiaonan] Guilin Univ Elect Technol, Inst Artificial Intelligence, Guilin, Peoples R China.
C3 Zhejiang University of Technology; Zhejiang University of Technology;
   Zhejiang University; Zhejiang University; Zhejiang University; Zhejiang
   University; Guilin University of Electronic Technology
RP Wu, FL (corresponding author), Zhejiang Univ Technol, Coll Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
EM fuliwu@zjut.edu.cn
FU Zhejiang Provincial Natural Science Foundation of China [LY18F020034,
   LY18C130012]; National Natural Science Foundation of China [61801428,
   61672543]; Zhejiang University Education Foundation [K18-511120-004,
   K17-518051-021]; Major Scientific Project of Zhejiang Lab [2018DG0ZX01]
FX This project was supported by Zhejiang Provincial Natural Science
   Foundation of China (No. LY18F020034, LY18C130012), National Natural
   Science Foundation of China (No.61801428, 61672543), the Zhejiang
   University Education Foundation (No. K18-511120-004 and No.
   K17-518051-021), and the Major Scientific Project of Zhejiang Lab (No.
   2018DG0ZX01).
CR ALBANESE A, 1995, CLIN ENDOCRINOL, V43, P105, DOI 10.1111/j.1365-2265.1995.tb01899.x
   [Anonymous], 2019, NEUROCOMPUTING
   Athanasios C., 2007, PEDIATR RADIOL, V37, P1241
   CHEN T, 2019, IEEE 16 INT S BIOM I
   Gao F, 2018, MULTIMED TOOLS APPL, V77, P29269, DOI 10.1007/s11042-018-5868-x
   Greulich W. W., 1959, AM J MED SCI, V238, P393, DOI DOI 10.1097/00000441-195909000-00030
   Guo C, 2016, 2016 INTERNATIONAL CONFERENCE ON CYBER-ENABLED DISTRIBUTED COMPUTING AND KNOWLEDGE DISCOVERY PROCEEDINGS - CYBERC 2016, P278, DOI 10.1109/CyberC.2016.61
   Hahmann F, 2013, LECT NOTES COMPUT SC, V8142, P313, DOI 10.1007/978-3-642-40602-7_34
   Hao PY, 2019, MATH BIOSCI ENG, V16, P6454, DOI 10.3934/mbe.2019323
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang GL, 2017, IEEE ICC
   Iglovikov VI, 2018, LECT NOTES COMPUT SC, V11045, P300, DOI 10.1007/978-3-030-00889-5_34
   Lee H, 2017, J DIGIT IMAGING, V30, P427, DOI 10.1007/s10278-017-9955-8
   Liu AN, 2017, I C OPT COMMUN NETW
   Mutasa S, 2018, J DIGIT IMAGING, V31, P513, DOI 10.1007/s10278-018-0053-3
   REN X, 2018, IEEE J BIOMED HEALTH, P2168
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Somkantha K, 2011, J DIGIT IMAGING, V24, P1044, DOI 10.1007/s10278-011-9372-3
   Souza D, 2018, SIBGRAPI, P197, DOI 10.1109/SIBGRAPI.2018.00032
   Spampinato C, 2017, MED IMAGE ANAL, V36, P41, DOI 10.1016/j.media.2016.10.010
   STEENKISTE TV, 2018, 40 ANN INT C IEEE EN, P674
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tanner JM, 1983, Assessment of Skeletal Maturity and Prediction of Adult Height (TW2 Method), V2nd
   Thodberg HH, 2009, IEEE T MED IMAGING, V28, P52, DOI 10.1109/TMI.2008.926067
   van Rijn RR, 2013, ACTA RADIOL, V54, P1024, DOI 10.1258/ar.2012.120443
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Wu ER, 2019, I S BIOMED IMAGING, P1158, DOI [10.1109/isbi.2019.8759332, 10.1109/ISBI.2019.8759332]
   Zhang LL, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P47, DOI 10.1109/ICAIBD.2018.8396165
NR 30
TC 4
Z9 5
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16347
EP 16366
DI 10.1007/s11042-020-08943-1
EA APR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000529468100005
DA 2024-07-18
ER

PT J
AU Li, R
   Duan, XM
   He, W
   You, L
AF Li, Ran
   Duan, Xiaomeng
   He, Wei
   You, Lei
TI Entropy-assisted adaptive compressive sensing for energy-efficient
   visual sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual sensor; Compressive sensing; Sensed entropy; Adaptive allocation;
   Fast recovery
AB Compressive Imaging (CI) is a potential sensing technology for energy-efficient visual sensors, and its rate-distortion performance can be improved by adaptive Compressive Sensing (CS) of image. However, due to the unavailability of original image, it is a challenge for CI-based adaptive CS to extract an effective feature from measurements to evaluate the sparsity of image. In view of that, this paper presents an entropy-assisted adaptive CS system, whose merit is its definition of the sensed entropy without the original image. Based on sensed entropy, each image block is allocated sufficient measuring resources, guaranteeing a cost-effective reconstruction of image. Experimental results show that the proposed entropy-assisted adaptive CS system provides better objective and subjective recovery qualities with a low measuring and recovering complexity.
C1 [Li, Ran; Duan, Xiaomeng; He, Wei; You, Lei] Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
C3 Xinyang Normal University
RP Li, R (corresponding author), Xinyang Normal Univ, Sch Comp & Informat Technol, Xinyang 464000, Peoples R China.
EM liran@xynu.edu.cn
RI Li, Ran/N-3389-2013
OI Li, Ran/0000-0001-7475-759X
FU National Natural Science Foundation of China [61601396, 31872704];
   Innovation Team Support Plan of University Science and Technology of
   Henan Province [19IRTSTHN014]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant nos. 61601396, 31872704, in part by
   Innovation Team Support Plan of University Science and Technology of
   Henan Province (no. 19IRTSTHN014).
CR Baraniuk R, 2008, CONSTR APPROX, V28, P253, DOI 10.1007/s00365-007-9003-x
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Baraniuk RG, 2017, IEEE SIGNAL PROC MAG, V34, P52, DOI 10.1109/MSP.2016.2602099
   Becker S, 2011, SIAM J IMAGING SCI, V4, P1, DOI 10.1137/090756855
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Chen C, 2011, CONF REC ASILOMAR C, P1193, DOI 10.1109/ACSSC.2011.6190204
   Chen Z, 2020, IEEE T CIRC SYST VID, V30, P1109, DOI 10.1109/TCSVT.2019.2898908
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Duarte M., 2005, WRA'2005 - II Workshop on Augmented Reality, P1
   Elhoseny M, 2020, IEEE T SUST COMPUT, V5, P174, DOI 10.1109/TSUSC.2017.2782737
   Figueiredo MAT, 2007, IEEE J-STSP, V1, P586, DOI 10.1109/JSTSP.2007.910281
   Fowler JE, 2010, FOUND TRENDS SIGNAL, V4, P297, DOI 10.1561/2000000033
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gharbia R, 2018, FUTURE GENER COMP SY, V88, P501, DOI 10.1016/j.future.2018.06.022
   León-López KM, 2019, IEEE T IMAGE PROCESS, V28, P253, DOI 10.1109/TIP.2018.2867171
   Li R, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/9059204
   Memos VA, 2018, FUTURE GENER COMP SY, V83, P619, DOI 10.1016/j.future.2017.04.039
   Muhammad K, 2019, IEEE COMMUN MAG, V57, P60, DOI 10.1109/MCOM.2018.1800371
   Mun S, 2010, IEEE DATA COMPR CONF, P547, DOI 10.1109/DCC.2010.90
   Plageras AP, 2018, FUTURE GENER COMP SY, V82, P349, DOI 10.1016/j.future.2017.09.082
   Psannis KE, 2006, EURASIP J WIREL COMM, DOI 10.1155/WCN/2006/24616
   Psannis KE, 2019, IEEE T SUST COMPUT, V4, P77, DOI 10.1109/TSUSC.2018.2817043
   Ralasic I, 2019, IEEE T INSTRUM MEAS, V68, P502, DOI 10.1109/TIM.2018.2847018
   Shen Y, 2015, INVERSE PROBL IMAG, V9, P231, DOI 10.3934/ipi.2015.9.231
   Stergiou C, 2018, FUTURE GENER COMP SY, V78, P964, DOI 10.1016/j.future.2016.11.031
   Vargas E, 2019, IEEE T IMAGE PROCESS, V28, P2271, DOI 10.1109/TIP.2018.2884081
   Wang AH, 2011, IEICE ELECTRON EXPR, V8, P575, DOI 10.1587/elex.8.575
   Wang LZ, 2019, IEEE T IMAGE PROCESS, V28, P2257, DOI 10.1109/TIP.2018.2884076
   Wei ZR, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2891061
   WU Minghu, 2012, INT J DIGITAL CONTEN, V6, P141, DOI DOI 10.4156/jdcta.vol6.issue4.17
   Xue J, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11020193
   Yu Y, 2010, IEEE SIGNAL PROC LET, V17, P973, DOI 10.1109/LSP.2010.2080673
   ZHANG JG, 2017, MULTIMED TOOLS APPL, V76, P4227, DOI DOI 10.1007/s11042.016.3496.x
   Zheng S, 2019, IEEE T MULTIMEDIA, V21, P1905, DOI 10.1109/TMM.2019.2891415
NR 35
TC 4
Z9 4
U1 2
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20821
EP 20843
DI 10.1007/s11042-020-08900-y
EA APR 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000528990000003
DA 2024-07-18
ER

PT J
AU Bonanomi, C
   Balletti, S
   Lecca, M
   Anisetti, M
   Rizzi, A
   Damiani, E
AF Bonanomi, Cristian
   Balletti, Simone
   Lecca, Michela
   Anisetti, Marco
   Rizzi, Alessandro
   Damiani, Ernesto
TI I3D: a new dataset for testing denoising and demosaicing algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image dataset; Demosaicing; Denoising; Image quality
ID COLOR DEMOSAICKING; IMAGE; INTERPOLATION; IMPLEMENTATION; EDGE
AB In this paper we present a dataset of images to test the performance of image processing algorithms, in particular demosaicing and denoising methods. Despite the plethora of demosaicing and denoising algorithms present in the literature, only few benchmarks are available to test their performance, and most of them are quite old, thus inadequate to represent the images captured by modern devices. The proposed dataset is composed by twenty 16 bit-depth images that can be used to test full-reference image quality metrics. More specifically, twelve pictures have been synthetically created by means of 2D or 3D softwares, while eight images have been captured by a high-end digital camera.
C1 [Bonanomi, Cristian; Balletti, Simone; Anisetti, Marco; Rizzi, Alessandro] Univ Milan, Dept Comp Sci, Via Comelico 39, I-20135 Milan, Italy.
   [Lecca, Michela] Fdn Bruno Kessler, Ctr Informat & Commun Technol, Via Sommar 18, I-38123 Trento, Italy.
   [Damiani, Ernesto] ETISALAT BT Innovat Ctr Khalifa Univ, Abu Dhabi, U Arab Emirates.
C3 University of Milan; Fondazione Bruno Kessler
RP Bonanomi, C (corresponding author), Univ Milan, Dept Comp Sci, Via Comelico 39, I-20135 Milan, Italy.
EM cristian.bonanomi@unimi.it; simone.balletti@studenti.unimi.it;
   lecca@fbk.eu; marco.anisetti@unimi.it; alessandro.rizzi@unimi.it;
   ernesto.damiani@kustar.ac.ae
RI damiani, ernesto/AAI-5709-2020; Anisetti, Marco/AAC-9656-2021
OI damiani, ernesto/0000-0002-9557-6496; Anisetti,
   Marco/0000-0002-5438-9467; Bonanomi, Cristian/0000-0003-4515-9122
FU "Ministero degli Affari Esteri e della Cooperazione Internazionale" of
   Italy [PGR00217]
FX This work was partially supported by the "Ministero degli Affari Esteri
   e della Cooperazione Internazionale" of Italy under Grant PGR00217.
CR ADAMS JE, 1995, P SOC PHOTO-OPT INS, V2416, P144
   Akiyama H, 2015, IEEE IMAGE PROC, P4778, DOI 10.1109/ICIP.2015.7351714
   [Anonymous], 2016, KODAC RICH FRANZEN
   Assembly IR, 2003, METH SUBJ ASS QUAL T
   Baek M, 2014, P WORLD C ENG COMP S
   Baraniuk R, 1999, PROC SPIE, V3813, P196, DOI 10.1117/12.366780
   Ben Hamza A, 1999, J MATH IMAGING VIS, V11, P161, DOI 10.1023/A:1008395514426
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616
   Bui TD, 1998, IEEE T SIGNAL PROCES, V46, P3414, DOI 10.1109/78.735315
   Choi H, 1998, PROCEEDINGS OF THE IEEE-SP INTERNATIONAL SYMPOSIUM ON TIME-FREQUENCY AND TIME-SCALE ANALYSIS, P613, DOI 10.1109/TFSA.1998.721499
   Chung KH, 2006, IEEE T IMAGE PROCESS, V15, P2944, DOI 10.1109/TIP.2006.877521
   Chung KH, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3432484
   Cohen I, 1999, SIGNAL PROCESS, V75, P201, DOI 10.1016/S0165-1684(98)00234-5
   Condat L, 2012, IEEE IMAGE PROC, P2781, DOI 10.1109/ICIP.2012.6467476
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Duran J, 2015, IMAGE PROCESS ON LIN, V5, P311, DOI 10.5201/ipol.2015.145
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fodor IK, 2003, J ELECTRON IMAGING, V12, P151, DOI 10.1117/1.1525793
   Froment J, 2014, IMAGE PROCESS ON LIN, V4, P300, DOI 10.5201/ipol.2014.120
   Gao DH, 2012, J VIS COMMUN IMAGE R, V23, P1019, DOI 10.1016/j.jvcir.2012.06.009
   Gharbi M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982399
   Go J, 2000, IEEE T CONSUM ELECTR, V46, P610, DOI 10.1109/30.883419
   Gonzalez R.E., 2008, Woods, Digital Image Processing, V3rd ed.
   Goossens B, 2013, IEEE IMAGE PROC, P445, DOI 10.1109/ICIP.2013.6738092
   HIBBARD RH, 1995, Patent No. 5382976
   Hirakawa K, 2006, IEEE T IMAGE PROCESS, V15, P2146, DOI 10.1109/TIP.2006.875241
   Hyvarinen A, 1998, INT C PATT RECOG, P1268, DOI 10.1109/ICPR.1998.711932
   Jain P, 2016, INFORM SYST FRONT, V18, P159, DOI 10.1007/s10796-014-9527-0
   John DM, 2015, 206 PUBLS CARN I, P1
   Jung A., 2001, P WORKSH GK NONL REG, V39, P127
   Kakarala R, 2002, IEEE T CONSUM ELECTR, V48, P932, DOI 10.1109/TCE.2003.1196423
   Khashabi D, 2014, IEEE T IMAGE PROCESS, V23, DOI 10.1109/TIP.2014.2359774
   Kimmel R, 1999, IEEE T IMAGE PROCESS, V8, P1221, DOI 10.1109/83.784434
   Klatzer T, 2016, IEEE INT CONF COMPUT, P43
   Kodac-Bradley J, 2016, LUCIER
   Lang M, 1995, SPIES 1995 S OE AER, P640
   Laroche C., 1994, United States Patent, Patent No. 5373322
   Lebrun M, 2015, IMAGE PROCESS ON LIN, V5, P1, DOI 10.5201/ipol.2015.125
   Lebrun M, 2013, IMAGE PROCESS ON LIN, V3, P1, DOI 10.5201/ipol.2013.16
   Lee K., 2014, INT J DISTRIB SENS N, V2014, P1
   Lian NX, 2007, IEEE T IMAGE PROCESS, V16, P2515, DOI 10.1109/TIP.2007.904459
   Menon Daniele, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P181
   Menon D, 2009, IEEE IMAGE PROC, P477, DOI 10.1109/ICIP.2009.5414364
   Motwani M. C., 2004, P GSPX, V27, P27
   Nuño-Maganda MA, 2005, 2005 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2005), P1, DOI 10.1109/RECONFIG.2005.34
   Paliy D, 2008, ELECT IMAGING 2008, p68221K
   Park J, 2016, ETRI J, V38, P164, DOI 10.4218/etrij.16.0114.1371
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   Pekkucuksen I, 2013, IEEE T IMAGE PROCESS, V22, P157, DOI 10.1109/TIP.2012.2210726
   Pierazzo N, 2017, IMAGE PROCESS ON LIN, V7, P93, DOI 10.5201/ipol.2017.203
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Prakash VS, 2016, ALEXANDRIA ENG J
   Preethi S, 2012, INT J COMPUT APPL, V58
   RAJAEI B, 2014, IMAGE PROCESS LINE, V4, P44, DOI DOI 10.5201/ipol.2014.86
   Rizzi A, 2004, CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS, P187
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Shao L, 2014, SIGNAL PROCESS, V103, P84, DOI 10.1016/j.sigpro.2013.07.017
   Strela V, 2001, PROG MATH, V202, P619
   Su CY, 2006, IEEE T CONSUM ELECTR, V52, P639, DOI 10.1109/TCE.2006.1649690
   Sung DC, 2015, ELECTRON LETT, V51, P228, DOI 10.1049/el.2014.1557
   Tao B, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P252
   Thung KH, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P153
   Wang J, 2019, CRIT REV FOOD SCI, V59, P1027, DOI 10.1080/10408398.2017.1389691
   Wang YQ, 2015, IMAGE PROCESS ON LIN, V5, P257, DOI 10.5201/ipol.2015.137
   Wang Z, 2005, PROC SPIE, V5666, P149, DOI 10.1117/12.597306
   WIENER N, 1949, T AM NEUROL ASSOC, P9
   Wu J, 2016, IEEE T IMAGE PROCESS
   Wu JJ, 2016, IEEE T IMAGE PROCESS, V25, P5369, DOI 10.1109/TIP.2016.2604489
   Yang B, 2016, INFORM PROCESS LETT, V116, P447, DOI 10.1016/j.ipl.2016.03.001
   YANG RK, 1995, IEEE T SIGNAL PROCES, V43, P591, DOI 10.1109/78.370615
   Zhang C, 2016, IEEE T IMAGE PROCESS, V25, P5173, DOI 10.1109/TIP.2016.2601266
   Zhang HP, 2000, INT CONF ACOUST SPEE, P2179, DOI 10.1109/ICASSP.2000.859269
   Zhang L, 2005, IEEE T IMAGE PROCESS, V14, P2167, DOI 10.1109/TIP.2005.857260
   Zhang L, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3600632
   Zhang L, 2009, IEEE T IMAGE PROCESS, V18, P797, DOI 10.1109/TIP.2008.2011384
   ZHU SM, 1992, 14TH INTERNATIONAL CONGRESS ON ACOUSTICS, PROCEEDINGS, VOLS 1-4, P559
NR 78
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8599
EP 8626
DI 10.1007/s11042-018-6396-4
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MH7PH
UT WOS:000546915700001
DA 2024-07-18
ER

PT J
AU Chaki, J
   Dey, N
AF Chaki, Jyotismita
   Dey, Nilanjan
TI Pattern analysis of genetics and genomics: a survey of the state-of-art
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genomic; Genetic; Pattern analysis; Pre-processing; Feature selection;
   Classification; Clustering
ID NONLINEAR DIMENSIONALITY REDUCTION; PARTICLE SWARM OPTIMIZATION; MISSING
   VALUE IMPUTATION; MULTIPLE CANCER TYPES; EXPRESSION DATA;
   FEATURE-SELECTION; MICROARRAY DATA; BACKGROUND CORRECTION; TUMOR
   CLASSIFICATION; DIFFUSION MAPS
AB The endless enhancement and decreasing charges of a complete human genome have given rise to fast acceptance of genetic and genomic information at both research institutions and clinics. Biologists are enchanting the primary steps in the direction of knowing the locations and functions of all the genes and controlling sites in the genomes of various organisms. As these researchers govern the nucleotide arrangement of large stretches of the human genome, they are constructing excessive volumes of sequence data. Direct research laboratory investigation of this data is expensive and tough, creating computational techniques vital. The arena of pattern analysis, which intends to build computer algorithms that enhance with knowledge, embraces the capacity to empower computers to support humans in the analysis of complex, large genetic and genomic data sets. Here, an overview of pattern analysis techniques for the study of genome sequencing datasets, as well as the proteomics, epigenetic and metabolomic data is delivered. These techniques employ data pre-processing, feature extraction and selection, classification and clustering. The aim of this survey is to present deliberations and recurring challenges in the application of pattern analysis methods, as well as of discriminative and reproductive modeling approaches and discuss the future research directions of these methods for the analysis of genomic and genetic data sets.
C1 [Chaki, Jyotismita] Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
   [Dey, Nilanjan] Techno India Coll Technol, Dept Informat Technol, Kolkata, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore
RP Chaki, J (corresponding author), Vellore Inst Technol, Sch Informat Technol & Engn, Vellore, Tamil Nadu, India.
EM jyotismita.c@gmail.com
RI Chaki, Jyotismita/T-4882-2019
OI Chaki, Jyotismita/0000-0003-1804-8590
CR Abeel T, 2009, BIOINFORMATICS, V25, pI313, DOI 10.1093/bioinformatics/btp191
   Ahmed AA, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh047
   Akgün M, 2015, J BIOMED INFORM, V56, P103, DOI 10.1016/j.jbi.2015.05.022
   Alexa A, 2006, BIOINFORMATICS, V22, P1600, DOI 10.1093/bioinformatics/btl140
   Alexe G, 2006, ANN OPER RES, V148, P189, DOI 10.1007/s10479-006-0084-x
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   Allendorf FW, 2010, NAT REV GENET, V11, P697, DOI 10.1038/nrg2844
   Ambroise C, 2002, P NATL ACAD SCI USA, V99, P6562, DOI 10.1073/pnas.102102699
   Angerer P, 2016, BIOINFORMATICS, V32, P1241, DOI 10.1093/bioinformatics/btv715
   [Anonymous], P 29 ANN C GERM CLAS
   [Anonymous], 2016, Genome Research
   [Anonymous], TECHNICAL REPORT
   [Anonymous], INT J ADV SOFT COMPU
   [Anonymous], 2017, BIORXIV
   [Anonymous], HUM GENOMICS PROTEOM
   [Anonymous], 2013, CURRENT PROTOCOLS MO
   Arcuri A, 2018, PROCEEDINGS 2018 IEEE/ACM 11TH INTERNATIONAL WORKSHOP ON SEARCH-BASED SOFTWARE TESTING (SBST), P21, DOI 10.1145/3194718.3194732
   Ardaneswari G, 2017, J PHYS CONF SER, V893, DOI 10.1088/1742-6596/893/1/012046
   Armstrong SA, 2002, NAT GENET, V30, P41, DOI 10.1038/ng765
   Arsenio J, 2014, NAT IMMUNOL, V15, P365, DOI 10.1038/ni.2842
   Asshauer KP, 2015, BIOINFORMATICS, V31, P2882, DOI 10.1093/bioinformatics/btv287
   Ayday E, 2014, LECT NOTES COMPUT SC, V8247, P133, DOI 10.1007/978-3-642-54568-9_9
   Barros RC, 2014, IEEE T EVOLUT COMPUT, V18, P873, DOI 10.1109/TEVC.2013.2291813
   Bartenhagen C, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-567
   Ben-Dor A, 2003, J COMPUT BIOL, V10, P373, DOI 10.1089/10665270360688075
   Best MG, 2015, CANCER CELL, V28, P666, DOI 10.1016/j.ccell.2015.09.018
   Birnbaum K, 2003, SCIENCE, V302, P1956, DOI 10.1126/science.1090022
   Bolón-Canedo V, 2014, INFORM SCIENCES, V282, P111, DOI 10.1016/j.ins.2014.05.042
   Botía JA, 2017, BMC SYST BIOL, V11, DOI 10.1186/s12918-017-0420-6
   Brennecke P, 2015, NAT IMMUNOL, V16, P933, DOI 10.1038/ni.3246
   Brozynska M, 2016, PLANT BIOTECHNOL J, V14, P1070, DOI 10.1111/pbi.12454
   Caldecott KW, 2008, NAT REV GENET, V9, P619, DOI 10.1038/nrg2380
   Campbell K., 2015, Laplacian eigenmaps and principal curves for high resolution pseudotemporal ordering of single-cell RNA-seq profiles
   Cao KAL, 2014, GENOMICS, V103, P239, DOI 10.1016/j.ygeno.2014.03.001
   Castillo-Davis CI, 2003, BIOINFORMATICS, V19, P891, DOI 10.1093/bioinformatics/btg114
   Çetin GS, 2017, BMC MED GENOMICS, V10, DOI 10.1186/s12920-017-0276-z
   Chandra B, 2011, EXPERT SYST APPL, V38, P1293, DOI 10.1016/j.eswa.2010.06.076
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chavez-Alvarez R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0093233
   Cheadle C, 2003, J MOL DIAGN, V5, P73, DOI 10.1016/S1525-1578(10)60455-2
   Chen KH, 2014, APPL SOFT COMPUT, V24, P773, DOI 10.1016/j.asoc.2014.08.032
   Chen KH, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-49
   Chen X., 2017, IEEE ACM T COMPUTATI
   Chen Yi-Ju, 2003, J Biopharm Stat, V13, P57, DOI 10.1081/BIP-120017726
   Chen YF, 2016, BIOINFORMATICS, V32, P1832, DOI 10.1093/bioinformatics/btw074
   Chen YM, 2017, J BIOMED INFORM, V67, P59, DOI 10.1016/j.jbi.2017.02.007
   Chinnaswamy A., 2016, INNOVATIONS BIOINSPI, P229, DOI [DOI 10.1007/978-3-319-28031-8_20, 10.1007/978-3-319-28031-8_20]
   Chinnaswamy A, 2017, ADV KNOWL ACQUISITIO, P41, DOI 10.4018/978-1-5225-2375-8.ch002
   Chou CC, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh099
   Chu ZF, 2018, J PHYS CONF SER, V1069, DOI 10.1088/1742-6596/1069/1/012121
   Cohen IR, 2018, US Patent Application No, V10, P503, Patent No. [10 /082 503, 10082503]
   Conesa A, 2016, GENOME BIOL, V17, DOI 10.1186/s13059-016-0881-8
   Corus D, 2017, IEEE T EVOL COMPUT
   Craddock TJA, 2015, BMC MED GENOMICS, V8, DOI 10.1186/s12920-015-0111-3
   Cui P, 2018, BBA-MOL BASIS DIS, V1864, P2274, DOI 10.1016/j.bbadis.2017.12.004
   D'haeseleer P, 2005, NAT BIOTECHNOL, V23, P1499, DOI 10.1038/nbt1205-1499
   Dai JJ, 2006, STAT APPL GENET MOL, V5
   Dai JH, 2013, APPL SOFT COMPUT, V13, P211, DOI 10.1016/j.asoc.2012.07.029
   Damelin SB, 2015, MATH MODEL NAT PHENO, V10, P207, DOI 10.1051/mmnp/201510315
   Danaee P, 2017, BIOCOMPUT-PAC SYM, P219
   Das K, 2016, INT J PHARM BIO SCI, V7, P1215
   Das S, 2018, GENOMICS, V110, P263, DOI 10.1016/j.ygeno.2017.11.003
   Melo ALD, 2016, CRIT REV BIOTECHNOL, V36, P317, DOI 10.3109/07388551.2014.960793
   DeLaughter DM, 2016, DEV CELL, V39, P480, DOI 10.1016/j.devcel.2016.10.001
   Dettling M, 2003, BIOINFORMATICS, V19, P1061, DOI 10.1093/bioinformatics/btf867
   Dheda K, 2004, BIOTECHNIQUES, V37, P112, DOI 10.2144/04371RR03
   Díaz-Uriarte R, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-3
   Ding C, 2003, PROCEEDINGS OF THE 2003 IEEE BIOINFORMATICS CONFERENCE, P523, DOI 10.1109/CSB.2003.1227396
   Dopazo J, 2017, BMC SYST BIOL, V11, DOI 10.1186/s12918-017-0495-0
   Edwards D, 2003, BIOINFORMATICS, V19, P825, DOI 10.1093/bioinformatics/btg083
   El-Assaad W, 2015, DIABETOLOGIA, V58, P149, DOI 10.1007/s00125-014-3429-z
   Eren AM, 2015, ISME J, V9, P968, DOI 10.1038/ismej.2014.195
   Fan R, 2011, GENET EPIDEMIOL, V35, P706, DOI 10.1002/gepi.20621
   Frandsen PB, 2015, BMC EVOL BIOL, V15, DOI 10.1186/s12862-015-0283-7
   Franzén O, 2015, MICROBIOME, V3, DOI 10.1186/s40168-015-0105-6
   Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961
   Fundel K, 2008, OSTEOARTHR CARTILAGE, V16, P947, DOI 10.1016/j.joca.2007.12.007
   Furey TS, 2000, BIOINFORMATICS, V16, P906, DOI 10.1093/bioinformatics/16.10.906
   Gagnon E, 2016, PHYTOKEYS, P1, DOI 10.3897/phytokeys.71.9203
   Gamazon ER, 2015, NAT GENET, V47, P1091, DOI 10.1038/ng.3367
   Gao C, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004791
   Gardner JW, 2005, SENSOR ACTUAT B-CHEM, V106, P114, DOI 10.1016/j.snb.2004.05.043
   Geiss GK, 2000, VIROLOGY, V266, P8, DOI 10.1006/viro.1999.0044
   Gerstung M, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms6901
   Ghasemi R, 2017, IEEE J BIOMED HEALTH, V21, P1466, DOI 10.1109/JBHI.2016.2625299
   Ghosh A, 2016, GENE, V583, P112, DOI 10.1016/j.gene.2016.02.015
   Ginsburg GS, 2009, TRANSL RES, V154, P277, DOI 10.1016/j.trsl.2009.09.005
   Goodwin CR, 2015, CHEM BIOL, V22, P661, DOI 10.1016/j.chembiol.2015.03.020
   Grabherr MG, 2011, NAT BIOTECHNOL, V29, P644, DOI 10.1038/nbt.1883
   Guo GJ, 2016, CELL REP, V14, P956, DOI 10.1016/j.celrep.2015.12.089
   Gupta A, 2015, IEEE INT C BIOINFORM, P1328, DOI 10.1109/BIBM.2015.7359871
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Haghverdi L, 2015, BIOINFORMATICS, V31, P2989, DOI 10.1093/bioinformatics/btv325
   Hartuv E, 2000, GENOMICS, V66, P249, DOI 10.1006/geno.2000.6187
   Hauskrecht M., 2007, ... And Proteomics, P149
   He KY, 2017, INT J MOL SCI, V18, DOI 10.3390/ijms18020412
   Heintzman ND, 2009, NATURE, V459, P108, DOI 10.1038/nature07829
   Hernandez JCH, 2007, LECT NOTES COMPUT SC, V4447, P90
   Herrero J, 2003, BIOINFORMATICS, V19, P655, DOI 10.1093/bioinformatics/btg040
   Herrero J, 2003, NUCLEIC ACIDS RES, V31, P3461, DOI 10.1093/nar/gkg591
   Heydarian Z, 2018, FRONT MICROBIOL, V9, DOI 10.3389/fmicb.2018.01297
   Hira Zena M., 2015, Advances in Bioinformatics, V2015, P198363, DOI 10.1155/2015/198363
   Huang DS, 2006, BIOINFORMATICS, V22, P1855, DOI 10.1093/bioinformatics/btl190
   Inza I, 2002, J INTELL FUZZY SYST, V12, P25
   Jain I, 2018, APPL SOFT COMPUT, V62, P203, DOI 10.1016/j.asoc.2017.09.038
   Jaskowiak PA, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-S2-S2
   Jiang DX, 2004, IEEE T KNOWL DATA EN, V16, P1370, DOI 10.1109/TKDE.2004.68
   Jin X, 2006, LECT NOTES COMPUT SC, V3916, P106
   Johnson TA, 2016, MBIO, V7, DOI 10.1128/mBio.02214-15
   Kamal Md Sarwar, 2017, International Journal of Information Technology, V9, P59, DOI 10.1007/s41870-017-0005-z
   Kamal MS, J INTELLIGENT FUZZY, P1
   Kar S, 2015, EXPERT SYST APPL, V42, P612, DOI 10.1016/j.eswa.2014.08.014
   Kasabov NK, 2014, NEURAL NETWORKS, V52, P62, DOI 10.1016/j.neunet.2014.01.006
   Keller NP, 2015, NAT CHEM BIOL, V11, P671, DOI [10.1038/nchembio.1897, 10.1038/NCHEMBIO.1897]
   Khalid S, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P372, DOI 10.1109/SAI.2014.6918213
   Kim DH, 2015, CELL STEM CELL, V16, P88, DOI 10.1016/j.stem.2014.11.005
   Kooperberg C, 2002, J COMPUT BIOL, V9, P55, DOI 10.1089/10665270252833190
   Kursa MB, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-8
   Kuznetsova I., 2018, INT SERIES INFORM SY, P32
   Lamparter D, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1004714
   Lan K, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1003-9
   Lancashire LJ, 2008, ARTIF INTELL MED, V43, P99, DOI 10.1016/j.artmed.2008.03.001
   Landfors M, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0027942
   Lazar C, 2012, IEEE ACM T COMPUT BI, V9, P1106, DOI 10.1109/TCBB.2012.33
   Lazzeroni L, 2002, STAT SINICA, V12, P61
   Leardi R, 2004, J CHEMOMETR, V18, P486, DOI 10.1002/cem.893
   Lee AB, 2010, GENET EPIDEMIOL, V34, P51, DOI 10.1002/gepi.20434
   Lee G, 2008, IEEE ACM T COMPUT BI, V5, P368, DOI 10.1109/TCBB.2008.36
   Lee PS, 2000, CURR OPIN BIOTECH, V11, P171, DOI 10.1016/S0958-1669(00)00077-X
   Lee Y, 2003, BIOINFORMATICS, V19, P1132, DOI 10.1093/bioinformatics/btg102
   Leung YF, 2003, TRENDS GENET, V19, P649, DOI 10.1016/j.tig.2003.09.015
   Li J, 2016, BIODATA MIN, V9, DOI 10.1186/s13040-016-0093-5
   Li LP, 2001, BIOINFORMATICS, V17, P1131, DOI 10.1093/bioinformatics/17.12.1131
   Li LP, 2001, COMB CHEM HIGH T SCR, V4, P727
   Li MW, 2015, NEUROCOMPUTING, V157, P243, DOI 10.1016/j.neucom.2015.01.010
   Li QH, 2005, BIOINFORMATICS, V21, P2875, DOI 10.1093/bioinformatics/bti447
   Li T, 2004, BIOINFORMATICS, V20, P2429, DOI 10.1093/bioinformatics/bth267
   Liang HD, 2015, COMM COM INF SC, V562, P249, DOI 10.1007/978-3-662-49014-3_23
   Liberzon A, 2015, CELL SYST, V1, P417, DOI 10.1016/j.cels.2015.12.004
   Liew AWC, 2011, BRIEF BIOINFORM, V12, P498, DOI 10.1093/bib/bbq080
   LIU B, 2004, BMC BIOINFORMATICS, V5, P1, DOI DOI 10.1186/1471-2105-5-136
   Liu Huiqing, 2002, Genome Inform, V13, P51
   Liu JL, 2017, IEEE C EVOL COMPUTAT, P2145, DOI 10.1109/CEC.2017.7969564
   Liu ZQ, 2005, J BIOMED BIOTECHNOL, P155, DOI 10.1155/JBB.2005.155
   Loomba R, 2015, GASTROENTEROLOGY, V149, P1784, DOI 10.1053/j.gastro.2015.08.011
   Lu HJ, 2017, LECT NOTES ARTIF INT, V10363, P732, DOI 10.1007/978-3-319-63315-2_64
   Luo F, 2003, THIRD IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING - BIBE 2003, PROCEEDINGS, P328
   Mallick Partho, 2019, Emerging Technologies in Data Mining and Information Security. Proceedings of IEMIS 2018. Advances in Intelligent Systems and Computing (AISC 814), P863, DOI 10.1007/978-981-13-1501-5_75
   MANIKANDAN SP, 2016, CURR SIGNAL TRANSD T, V11, P76, DOI DOI 10.2174/1574362411666160607084415
   Mann KM, 2016, NAT BIOTECHNOL, V34, P962, DOI 10.1038/nbt.3637
   McCarthy MI, 2010, NEW ENGL J MED, V363, P2339, DOI 10.1056/NEJMra0906948
   McGee M, 2006, STAT APPL GENET MOL, V5, DOI 10.2202/1544-6115.1237
   McInerney JO, 2017, CANCER
   McLachlan GJ, 2002, BIOINFORMATICS, V18, P413, DOI 10.1093/bioinformatics/18.3.413
   McPherson JD, 2001, NATURE, V409, P934, DOI 10.1038/35057157
   McSharry PE, 2016, ARXIV160602801
   Medvedovic M, 2002, BIOINFORMATICS, V18, P1194, DOI 10.1093/bioinformatics/18.9.1194
   Mehrotra Parikha, 2016, J Oral Biol Craniofac Res, V6, P153, DOI 10.1016/j.jobcr.2015.12.002
   Meng J, 2015, IEEE ACM T COMPUT BI, V12, P433, DOI 10.1109/TCBB.2014.2361329
   Min X., 2015, METALLURGICAL MINING, V7, P186
   Moorthy K, 2014, CURR BIOINFORM, V9, P18, DOI 10.2174/1574893608999140109120957
   Murray SN, 2014, BUILD ENVIRON, V75, P98, DOI 10.1016/j.buildenv.2014.01.011
   National Research Council, 1988, MAPP SEQ HUM GEN
   Newton MA, 2001, J COMPUT BIOL, V8, P37, DOI 10.1089/106652701300099074
   Nilsson J, 2006, NONLINEAR DIMENSIONA
   Njeunje FON, 2014, LINEAR NONLINEAR DIM
   Oba S, 2003, BIOINFORMATICS, V19, P2088, DOI 10.1093/bioinformatics/btg287
   Oghabian A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090801
   Ogutu JO, 2012, BMC PROCEDINGS, V6, P1, DOI DOI 10.1186/1753-6561-6-S2-S10
   Orsenigo Carlotta, 2013, Evolutionary Computation, Machine Learning and Data Mining in Bioinformatics. 11th European Conference, EvoBIO 2013. Proceedings, P92, DOI 10.1007/978-3-642-37189-9_9
   Ott J, 2015, NAT REV GENET, V16, P275, DOI 10.1038/nrg3908
   Palmer OMP, 2018, SHOCK, V50, P53, DOI 10.1097/SHK.0000000000001029
   Pan M, 2018, BIOTECHNOL BIOTEC EQ, V32, P751, DOI 10.1080/13102818.2017.1419376
   Paradis E, 2017, MOL ECOL RESOUR, V17, P54, DOI 10.1111/1755-0998.12577
   Parikshak NN, 2016, NATURE, V540, P423, DOI 10.1038/nature20612
   Parmigiani G., 2003, The Analysis of Gene Expression Data, P1
   Parry RM, 2010, PHARMACOGENOMICS J, V10, P292, DOI 10.1038/tpj.2010.56
   Perkins AD, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-S11-S4
   Petralia F, 2015, BIOINFORMATICS, V31, P197, DOI 10.1093/bioinformatics/btv268
   Pickett JA, 2016, NEW PHYTOL, V212, P856, DOI 10.1111/nph.14274
   Pillati M, 2005, STATISTICA, V65, P61
   Prabhakaran S, 2016, PR MACH LEARN RES, V48
   Qiu X, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-124
   Quang D, 2016, NUCLEIC ACIDS RES, V44, DOI 10.1093/nar/gkw226
   Rajan K, 2015, ANNU REV MATER RES, V45, P153, DOI 10.1146/annurev-matsci-070214-021132
   Ramalho JS, 2001, BMC GENET, V2, DOI 10.1186/1471-2156-2-2
   Ray SS, 2016, IEEE T NEUR NET LEAR, V27, P1890, DOI 10.1109/TNNLS.2015.2460994
   Reverter F, 2014, BMC SYST BIOL, V8, DOI 10.1186/1752-0509-8-S2-S6
   Ritchie MD, 2015, NAT REV GENET, V16, P85, DOI 10.1038/nrg3868
   Ritchie ME, 2007, BIOINFORMATICS, V23, P2700, DOI 10.1093/bioinformatics/btm412
   Robinson MD, 2010, BIOINFORMATICS, V26, P139, DOI 10.1093/bioinformatics/btp616
   Rocke DM, 2003, BIOINFORMATICS, V19, P966, DOI 10.1093/bioinformatics/btg107
   Rodríguez-Rodríguez J, 2015, ANNU REV FLUID MECH, V47, P405, DOI 10.1146/annurev-fluid-010814-014658
   Roffler GH, 2016, EVOL APPL, V9, P805, DOI 10.1111/eva.12389
   Romualdi C, 2003, HUM MOL GENET, V12, P823, DOI 10.1093/hmg/ddg093
   Ruiz R, 2006, PATTERN RECOGN, V39, P2383, DOI 10.1016/j.patcog.2005.11.001
   Rupp R, 2016, ANIM FRONT, V6, P39, DOI 10.2527/af.2016-0006
   Ryman N, 2006, MOL ECOL NOTES, V6, P285, DOI 10.1111/j.1471-8286.2005.01146.x
   Saelens W, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03424-4
   Saghir H, 2013, IEEE INT CONF COMP, P191, DOI 10.1109/CIVEMSA.2013.6617419
   Salleh AHM, 2015, BIOTECHNOL BIOPROC E, V20, P685, DOI 10.1007/s12257-015-0276-9
   Santosh, 2018, J AMBIENT INTELLIGEN, P1
   Saul L. K., 2006, Semi-Supervised Learn., V3, P292
   Schmitt P., 2015, Journal of Biometrics and Biostatistics, V6, P1, DOI DOI 10.4172/2155-6180.1000224
   Seno A, 2016, CANC INFORM, pCIN
   Sewer Alain, 2014, BMC Res Notes, V7, P302, DOI 10.1186/1756-0500-7-302
   Shabani Mahsa, 2015, Life Sci Soc Policy, V11, P3, DOI 10.1186/s40504-014-0022-7
   Shamir R, 2002, CURRENT TOPICS COMPU, V269
   Sharbaf FV, 2016, GENOMICS, V107, P231, DOI 10.1016/j.ygeno.2016.05.001
   Shehu A, 2014, P ACM COMP PUBL 2014, P839
   Sherlock G, 2000, CURR OPIN IMMUNOL, V12, P201, DOI 10.1016/S0952-7915(99)00074-6
   Shimada K, 2008, CANCER SCI, V99, P39, DOI 10.1111/j.1349-7006.2007.00655.x
   Shreem SS, 2014, INFORM SCIENCES, V258, P108, DOI 10.1016/j.ins.2013.10.012
   Simerska P, 2011, MED RES REV, V31, P520, DOI 10.1002/med.20191
   Simko I, 2016, TRENDS PLANT SCI, V21, P528, DOI 10.1016/j.tplants.2016.01.004
   Singh D, 2002, CANCER CELL, V1, P203, DOI 10.1016/S1535-6108(02)00030-2
   Slonim DK, 2002, NAT GENET, V32, P502, DOI 10.1038/ng1033
   Southern EM, 1992, CURR OPIN GENET DEV, V2, P412, DOI 10.1016/S0959-437X(05)80151-0
   Steiner L, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0046811
   Sun SQ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102541
   Tabakhi S, 2015, NEUROCOMPUTING, V168, P1024, DOI 10.1016/j.neucom.2015.05.022
   Tan A.C., 2003, ENSEMBLE MACHINE LEA
   Tang EK, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-95
   Tang HX, 2016, BMC MED GENOMICS, V9, DOI 10.1186/s12920-016-0224-3
   Tibshirani R, 2002, P NATL ACAD SCI USA, V99, P6567, DOI 10.1073/pnas.082099299
   Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520
   Tuikkala J, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-202
   Tutz G, 2015, COMPUT STAT DATA AN, V90, P84, DOI 10.1016/j.csda.2015.04.009
   Uuz H., 2011, KNOWL-BASED SYST, V24, P1024, DOI [DOI 10.1016/j.knosys.2011.04.014, 10.1016/j.knosys.2011.04.014, DOI 10.1016/J.KNOSYS.2011.04.014]
   van Hijum SAFT, 2008, BMC BIOINFORMATICS, V9, DOI 10.1186/1471-2105-9-93
   Ha VS, 2016, LECT NOTES ARTIF INT, V9729, P459, DOI 10.1007/978-3-319-41920-6_36
   Venna J, 2010, J MACH LEARN RES, V11, P451
   Vepakomma P, 2016, APPL COMPUT HARMON A, V40, P622, DOI 10.1016/j.acha.2015.10.004
   Vidaki A, 2017, FORENSIC SCI INT-GEN, V29, P165, DOI 10.1016/j.fsigen.2017.04.010
   Vohradsky J, 2001, FASEB J, V15, P846, DOI 10.1096/fj.00-0361com
   Wang AG, 2017, COMPUT BIOL MED, V81, P11, DOI 10.1016/j.compbiomed.2016.12.002
   WANG H, 2011, BMC BIOINFORMATICS, V12, P1, DOI DOI 10.1093/bib/bbq008
   Wang Z., 2016, FIXED POINT THEORY A, V2016, DOI [DOI 10.1038/srep26818, DOI 10.1038/srep25385]
   Westcott SL, 2015, PEERJ, V3, DOI 10.7717/peerj.1487
   Willems E, 2008, ANAL BIOCHEM, V379, P127, DOI 10.1016/j.ab.2008.04.036
   Wilson A, 2016, ECOGRAPHY, V39, P87, DOI 10.1111/ecog.01297
   Wong MHT, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-017-1564-5
   Xu JC, 2018, COMPUT MATH METHOD M, V2018, DOI 10.1155/2018/5490513
   Xu R, 2007, P ANN INT IEEE EMBS, P4613, DOI 10.1109/IEMBS.2007.4353367
   Xu Y, 2002, BIOINFORMATICS, V18, P536, DOI 10.1093/bioinformatics/18.4.536
   Xuan P, 2011, GENET MOL RES, V10, P588, DOI 10.4238/vol10-2gmr969
   Yang Yaran, 2014, Genomics Proteomics & Bioinformatics, V12, P190, DOI 10.1016/j.gpb.2014.09.001
   Yang YH, 2002, J COMPUT GRAPH STAT, V11, P108, DOI 10.1198/106186002317375640
   Ye JP, 2004, IEEE ACM T COMPUT BI, V1, P181, DOI 10.1109/TCBB.2004.45
   Yeung KY, 2001, BIOINFORMATICS, V17, P309, DOI 10.1093/bioinformatics/17.4.309
   Yeung KY, 2001, BIOINFORMATICS, V17, P977, DOI 10.1093/bioinformatics/17.10.977
   Yu ZW, 2007, BIOINFORMATICS, V23, P2888, DOI 10.1093/bioinformatics/btm463
   Yuan B, 2015, J INTELL MANUF, V26, P159, DOI 10.1007/s10845-013-0770-x
   Zamani-Dahaj SA, 2016, MOL BIOL EVOL, V33, P1843, DOI 10.1093/molbev/msw062
   Zeng T, 2015, BMC BIOINFORMATICS, V16, DOI 10.1186/s12859-015-0553-9
   Zhang L, 2015, COMPUT BIOL MED, V64, P236, DOI 10.1016/j.compbiomed.2015.07.008
   Zhang SQ, 2011, HUM MOL GENET, V20, P3176, DOI 10.1093/hmg/ddr223
   Zhu ZX, 2007, PATTERN RECOGN, V40, P3236, DOI 10.1016/j.patcog.2007.02.007
   Zou Q, 2016, NEUROCOMPUTING, V173, P346, DOI 10.1016/j.neucom.2014.12.123
NR 259
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 11163
EP 11194
DI 10.1007/s11042-019-7181-8
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600077
OA Bronze
DA 2024-07-18
ER

PT J
AU Kumar, R
   Sankaran, KS
   Sampath, R
   Shakeel, PM
AF Kumar, R.
   Sankaran, K. Sakthidasan
   Sampath, R.
   Mohamed Shakeel, P.
TI RETRACTED: Analysis of regional atrophy and prolong adaptive exclusive
   atlas to detect the alzheimers neuro disorder using medical images
   (Retracted article. See vol. 82, pg. 15921, 2023)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Alzheimer's neurodegenerative disease; Single photon emission nuclear
   tomographic imaging (SPECT); Prolong adaptive exclusive analytical Atlas
   (PAEA); Regional atrophy analysis; Gray matters; White matters;
   Alzheimer's disease
ID DISEASE
AB Alzheimer's Neurodegenerative Disease is understood neurological issue, which is influenced cerebrum cells are causes the intellectual decrease and memory misfortune, the sickness begins gentle and deteriorates. There is a serious necessity to identify Alzheimer's disease at an earlier stage, therefore that the appropriate treatment can initiate early. The foremost causes for Alzheimer's diseases are low blood flow and brain activity. So, the serious Alzheimer disease has been recognized by several existing methodologies but they are fails to recognize the disease in the earlier stage. Thus, in this work use Single Photon Emission Nuclear Tomographic Imaging(SPECT) for find the Alzheimer's diseases. The collected SPECT image noise is removed by applying Lucy-Richardson method and affected region is segmented by using Prolong adaptive exclusive analytical Atlas (PAEA). After this segmentation process Regional Atrophy Analysis (RAA) is apply for find the values of Gray Matters (GM) and White Matters (WM) regions in SPECT image. Finally Artificial Neural Network is applying for classification process. The experimental results shows that the promising outcomes in term of accuracy, sensitivity, and specificity.
C1 [Kumar, R.] NIT Nagaland, Dept Elect & Instrumentat Engn, Chumukedima 797103, Dimapur, India.
   [Sankaran, K. Sakthidasan] Hindustan Inst Technol & Sci, Dept Elect & Commun Engn, Chennai 603103, Tamil Nadu, India.
   [Sampath, R.] AJ Coll Engn, Chennai 603103, Tamil Nadu, India.
   [Mohamed Shakeel, P.] Univ Teknikal Malaysia Melaka, Fac Informat & Commun Technol, Durian Tunggal, Malaysia.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland; Hindustan Institute of Technology & Science;
   Universiti Teknologi Malaysia; University Teknikal Malaysia Melaka
RP Sampath, R (corresponding author), AJ Coll Engn, Chennai 603103, Tamil Nadu, India.
EM sampathrajaram14@gmail.com
RI Mohamed Shakeel, Pethuraj/P-4135-2019; Sankaran,
   Sakthidasan/D-7185-2019; Chennai, Mohamed Sathak A J College of
   Engineering/IAN-3234-2023; Kumar, Rajesh/G-1408-2014; Rajaram,
   Sampath/GLV-6161-2022
OI Sankaran, Sakthidasan/0000-0002-5905-0809; Kumar,
   Rajesh/0000-0002-6019-0702; Rajaram, Sampath/0000-0001-9806-3912; HITS,
   Hindustan Institute of Technology and Science/0009-0004-3570-2675;
   Kumar, R./0000-0002-0462-5628
CR Alam S, 2017, ALZHEIMER DIS CLASSI, DOI [10.1002/ima.22217/abstract, DOI 10.1002/IMA.22217/ABSTRACT]
   Arora A, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/7462014
   Chen G, 2011, RADIOLOGY, V259, P213, DOI 10.1148/radiol.10100734
   Chien DT, 2014, J ALZHEIMERS DIS, V38, P171, DOI 10.3233/JAD-130098
   Güler I, 2009, DIGIT SIGNAL PROCESS, V19, P668, DOI 10.1016/j.dsp.2008.08.002
   Huang X, 2007, INT J BIOMEDICAL IMA, V65641, P8
   Lahmiri S., 2013, ALZHEIMERS DIS DETEC
   Landau SM, 2010, NEUROLOGY, V75, P230, DOI 10.1212/WNL.0b013e3181e8e8b8
   Lian HL, 2008, PROCEEDINGS OF THE CONFERENCE ON ENGINEERED WOOD PRODUCTS BASED ON POPLAR/WILLOW WOOD, P167
   López MM, 2009, NEUROSCI LETT, V464, P233, DOI 10.1016/j.neulet.2009.08.061
   Magnin B, 2009, NEURORADIOLOGY, V51, P73, DOI 10.1007/s00234-008-0463-x
   Manoochehri M, 2014, INT J ADV MANUF TECH, V73, P241, DOI 10.1007/s00170-014-5788-5
   Meena A, 2012, INT J COMPUT APPL, V57
   Mosconi L, 2007, EARLY DETECTION ALZH
   Mosconi L, 2007, EXP GERONTOL, V42, P129, DOI 10.1016/j.exger.2006.05.016
   Oyelade O.J., 2010, International Journal of Computer Science and Information Security (IJCSIS), P292, DOI DOI 10.48550/ARXIV.1002
   Plant C, 2010, NEUROIMAGE, V50, P162, DOI 10.1016/j.neuroimage.2009.11.046
   Sadek RA, 2013, INT J SIGNAL PROCESS, P61
   Shakeel PM, 2020, HEALTH TECHNOL-GER, V10, P157, DOI 10.1007/s12553-018-0279-6
   Shakeel PM, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0054-0
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Watanabe Hiroyuki, 2015, ScientificWorldJournal, V2015, P124192, DOI 10.1155/2015/124192
   Yuan HC, 2003, COMPUT ELECTRON AGR, V40, P57, DOI 10.1016/S0168-1699(03)00011-5
   Zaidi H, 2012, EUR J NUCL MED MOL I, V39, P881, DOI 10.1007/s00259-011-2053-0
   Zhang DQ, 2011, NEUROIMAGE, V55, P856, DOI 10.1016/j.neuroimage.2011.01.008
NR 26
TC 11
Z9 11
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10249
EP 10265
DI 10.1007/s11042-019-7213-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600028
DA 2024-07-18
ER

PT J
AU Li, ZJ
   Hu, HY
   Huang, BB
   Chen, J
   Li, CY
   Hu, H
   Huang, LG
AF Li, Zhongjin
   Hu, Haiyang
   Huang, Binbin
   Chen, Jie
   Li, Chuanyi
   Hu, Hua
   Huang, Liguo
TI Security and performance-aware resource allocation for enterprise
   multimedia in mobile edge computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Enterprise multimedia security; Resource allocation; Lyapunov
   optimization; Mobile edge computing
ID REAL-TIME APPLICATIONS; SCHEDULING ALGORITHM; SCIENTIFIC WORKFLOW;
   CHANNEL ALLOCATION; COMMUNICATION; OPTIMIZATION; INTERNET; PRIVACY;
   TASKS; MANAGEMENT
AB Mobile edge computing (MEC) is a promising computing model and has gained remarkable popularity, as it deploys the resources (e.g., computation, network, and storage) to the evolved NodeB (eNB) to provide enormous benefits such as low delay and energy consumption. More and more enterprises construct their edge computing platforms to store multimedia contents (i.e., video, audio, photos, and text data) for the user equipment (UE). However, both the eNB and UEs will experience serious security attacks when transmitting or receiving multimedia data via the wireless network. Existing MEC studies mainly focus on task offloading and performance improvement without considering the enterprise multimedia security problem. This paper proposes a security and performance-aware resource allocation (Spara) algorithm for enterprise multimedia in MEC environment. More specifically, we first build the architecture of enterprise multimedia security for sending the data requests to UEs, which mainly consists of computing and bandwidth resource allocation. Then, we formulate the stochastic data transmission problem to minimize the delay and energy consumption of UEs subject to the security guarantee. To achieve this goal, two queues, namely front-end queue and back-end queue, are used for each UE, and the Lyapunov optimization technique is applied to determine how to allocate the computing and bandwidth resources. Rigorous theoretical analysis shows that Spara algorithm meets the [O(1/V), O(V)] energy-delay tradeoff. Extensive simulation experiments validate this analysis result and the effectiveness of Spara algorithm.
C1 [Li, Zhongjin; Hu, Haiyang; Huang, Binbin; Chen, Jie; Hu, Hua] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Li, Zhongjin; Hu, Haiyang; Huang, Binbin] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
   [Li, Chuanyi] Nanjing Univ, Software Inst, Nanjing, Peoples R China.
   [Hu, Hua] Hangzhou Normal Univ, Inst Serv Engn, Hangzhou, Peoples R China.
   [Huang, Liguo] Southern Methodist Univ, Dept Comp Sci & Engn, Dallas, TX 75275 USA.
C3 Hangzhou Dianzi University; Beijing University of Posts &
   Telecommunications; Nanjing University; Hangzhou Normal University;
   Southern Methodist University
RP Hu, HY (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.; Hu, HY (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
EM huhaiyang@hdu.edu.cn
RI Chen, John/GPW-8839-2022
OI Huang, LiGuo/0000-0001-7790-0195; hu, haiyang/0000-0002-6070-8524
CR Abbas N, 2018, IEEE INTERNET THINGS, V5, P450, DOI 10.1109/JIOT.2017.2750180
   Abdallah A, 2018, IEEE T COMMUN, V66, P3217, DOI 10.1109/TCOMM.2018.2812731
   Beraldi R, 2017, 2017 SECOND INTERNATIONAL CONFERENCE ON FOG AND MOBILE EDGE COMPUTING (FMEC), P94, DOI 10.1109/FMEC.2017.7946414
   Chang V, 2017, 2017 INT C ENG TECHN, P1
   Chen HK, 2017, IEEE T PARALL DISTR, V28, P2674, DOI 10.1109/TPDS.2017.2678507
   Georgiadis Leonidas, 2006, Foundations and Trends in Networking, V1, P1, DOI 10.1561/1300000001
   Gupta BB, 2018, MULTIMED TOOLS APPL, V77, P9203, DOI 10.1007/s11042-017-5301-x
   Haus M, 2017, IEEE COMMUN SURV TUT, V19, P1054, DOI 10.1109/COMST.2017.2649687
   Hong HS, 2018, MULTIMED TOOLS APPL, V77, P4477, DOI 10.1007/s11042-017-4804-9
   Hsu RH, 2015, IEEE CONF COMM NETW, P451, DOI 10.1109/CNS.2015.7346857
   Hu HY, 2020, PATTERN RECOGN LETT, V130, P267, DOI 10.1016/j.patrec.2018.10.011
   Hu H, 2018, MULTIMED TOOLS APPL, V77, P21693, DOI 10.1007/s11042-017-5602-0
   Huang BB, 2019, FUTURE GENER COMP SY, V97, P755, DOI 10.1016/j.future.2019.03.011
   Hussain M, 2016, MULTIMED TOOLS APPL, V75, P5345, DOI 10.1007/s11042-015-2936-3
   Jiang W, 2018, IEEE CONF COMPUT, P511
   Jiang W, 2015, J SYST ARCHITECT, V61, P282, DOI 10.1016/j.sysarc.2015.05.005
   Lee C, 2017, CLUSTER COMPUT, V20, P559, DOI 10.1007/s10586-016-0706-2
   Li JG, 2016, IEEE INTERNET THINGS, V3, P408, DOI 10.1109/JIOT.2015.2495321
   Li ZJ, 2017, FUTURE GENER COMP SY, V73, P63, DOI 10.1016/j.future.2016.12.017
   Li ZJ, 2016, FUTURE GENER COMP SY, V65, P140, DOI 10.1016/j.future.2015.12.014
   Liang FS, 2017, INT J ADV MANUF TECH, V92, P2001, DOI 10.1007/s00170-017-0249-6
   Lin X, 2015, IEEE T SERV COMPUT, V8, P175, DOI 10.1109/TSC.2014.2381227
   Liu CY, 2017, AER ADV ENG RES, V120, P1, DOI 10.1109/glocomw.2017.8269175
   Liu YC, 2018, ENTERP INF SYST-UK, V12, P218, DOI 10.1080/17517575.2017.1309686
   Lyu XC, 2017, IEEE J SEL AREA COMM, V35, P2606, DOI 10.1109/JSAC.2017.2760186
   Mao YY, 2017, IEEE COMMUN SURV TUT, V19, P2322, DOI 10.1109/COMST.2017.2745201
   Mao YY, 2017, IEEE T WIREL COMMUN, V16, P5994, DOI 10.1109/TWC.2017.2717986
   Neely M., 2010, STOCHASTIC NETWORK O
   Roman R, 2018, FUTURE GENER COMP SY, V78, P680, DOI 10.1016/j.future.2016.11.009
   Salodkar N, 2010, IEEE T MOBILE COMPUT, V9, P1391, DOI 10.1109/TMC.2010.106
   Santhi S, 2018, MULTIMED TOOLS APPL, V77, P10329, DOI 10.1007/s11042-018-5688-z
   Shirazi SN, 2017, IEEE J SEL AREA COMM, V35, P2586, DOI 10.1109/JSAC.2017.2760478
   Song SS, 2006, IEEE T COMPUT, V55, P703, DOI 10.1109/TC.2006.89
   Song W, 2017, IEEE T PARALL DISTR, V28, P2979, DOI 10.1109/TPDS.2017.2696942
   Song W, 2018, IEEE T SERV COMPUT, V11, P215, DOI 10.1109/TSC.2016.2536025
   Sun G, 2017, J NETW COMPUT APPL, V89, P3, DOI 10.1016/j.jnca.2016.10.011
   Sun G, 2017, FUTURE GENER COMP SY, V74, P375, DOI 10.1016/j.future.2016.08.023
   Sun YX, 2017, IEEE J SEL AREA COMM, V35, P2637, DOI 10.1109/JSAC.2017.2760160
   Tang XY, 2011, IEEE T COMPUT, V60, P1017, DOI 10.1109/TC.2010.117
   Tran TX, 2019, IEEE T VEH TECHNOL, V68, P856, DOI 10.1109/TVT.2018.2881191
   Wang CZ, 2018, INT J MACH LEARN CYB, V9, P1929, DOI 10.1007/s13042-017-0712-6
   Wang F, 2018, IEEE T WIREL COMMUN, V17, P1784, DOI 10.1109/TWC.2017.2785305
   Xie T, 2008, IEEE T PARALL DISTR, V19, P682, DOI 10.1109/TPDS.2007.70776
   Xie T, 2006, IEEE T COMPUT, V55, P864, DOI 10.1109/TC.2006.110
   Xu J, 2018, COMPUT NETW, V133, P104, DOI 10.1016/j.comnet.2018.01.017
   Yao Y, 2014, IEEE T PARALL DISTR, V25, P200, DOI 10.1109/TPDS.2012.341
   Yu CH, 2011, IEEE T WIREL COMMUN, V10, P2752, DOI 10.1109/TWC.2011.060811.102120
   Zeng LF, 2015, J PARALLEL DISTR COM, V75, P141, DOI 10.1016/j.jpdc.2014.09.002
   Zhang AQ, 2016, IEEE T VEH TECHNOL, V65, P2659, DOI 10.1109/TVT.2015.2416002
   Zhang WW, 2015, IEEE T WIREL COMMUN, V14, P81, DOI 10.1109/TWC.2014.2331051
NR 50
TC 3
Z9 3
U1 2
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10751
EP 10780
DI 10.1007/s11042-019-08557-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600057
DA 2024-07-18
ER

PT J
AU Sheeja, R
   Sutha, J
AF Sheeja, R.
   Sutha, J.
TI Soft fuzzy computing to medical image compression in wireless sensor
   network-based tele medicine system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Remote medical monitoring; Wireless sensor network;
   Fuzzy logic; Image compression
ID CLUSTERING-ALGORITHM; ENERGY-EFFICIENT; DESIGN; RELIABILITY; PROTOCOL
AB Wireless sensor network can be used to construct a telemedicine scheme to bring together the patient data and expansion of medical conveniences when disaster occurs. The Remote Medical Monitoring (RMM) scheme of the disaster period can be constructed using the Health care center (CC), Wireless sensor nodes and a few Primary health care centers (PHC). The sensor nodes possess the capacity of making communication between patients and PHCs. This type of WSN experiences limited lifetime problem due to the limited battery energy and transmission of medical data in large quantity. This paper proposes a new and novel WSN based Disaster Rescue Telemedicine Scheme to minimize energy consumption and to maximize network lifetime. The proposed method reaches this milestone using three novel algorithms namely 'Network clustering using Non-border CH oriented Genetic algorithm, Fuzzy rules and Kernel FCM (NCNBGF)', 'High gain MDC algorithm (HGMDC)' and 'Critical node handling using job limiting and job shifting (CJLS)'. The principal technologies used in this paper are Network node clustering, Medical image compression and Critical state node energy management to elongate the life period of WSN. The Simulation results prove that the proposed method amplifies the WSN topology lifetime to a significant level than the earlier versions. The Existing methods compared in this paper holds only 20% energy at the round 80,the proposed method stays with 43% of energy.
C1 [Sheeja, R.] Saveetha Sch Engn, Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Sutha, J.] AAA Coll Engn & Technol, Amathur, Sivakasi, India.
C3 Saveetha Institute of Medical & Technical Science; Saveetha School of
   Engineering
RP Sheeja, R (corresponding author), Saveetha Sch Engn, Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM researchsheeja@gmail.com
RI Raghavan, Dr Sheeja/AAX-3608-2020
OI Raghavan, Dr Sheeja/0000-0001-7242-2817; Joypaul,
   Sutha/0000-0002-9585-8784
CR Ahilan A, 2016, ADV INTELL SYST, V412, P237, DOI 10.1007/978-981-10-0251-9_24
   Ahilan A, 2015, MICROELECTRON RELIAB, V55, P2108, DOI 10.1016/j.microrel.2015.06.075
   Ahilan A, 2011, 2011 THIRD INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING (ICOAC), P353, DOI 10.1109/ICoAC.2011.6165201
   Ahilan A., 2015, 2015 INT C COMP COMM, P1
   Ahilan A., 2015, International Journal of Applied and Engineering Research, V10, P9643
   Ahmadinia M, 2013, IETE J RES, V59, P774, DOI 10.4103/0377-2063.126958
   Arunraja M, 2015, ISA T, V59, P180, DOI 10.1016/j.isatra.2015.07.014
   Dutta T, 2015, IEEE SENS J, V15, P778, DOI 10.1109/JSEN.2014.2354394
   Ebrahimi F, 2004, P SOC PHOTO-OPT INS, V5558, P300, DOI 10.1117/12.564835
   Elhabyan RSY, 2015, J NETW COMPUT APPL, V52, P116, DOI 10.1016/j.jnca.2015.02.004
   Fong B, 2012, IEEE WIREL COMMUN, V19, P83, DOI 10.1109/MWC.2012.6339476
   Hsu SJ, 2010, INTELL AUTOM SOFT CO, V16, P537, DOI 10.1080/10798587.2010.10643099
   Islam MR, 2012, IETE TECH REV, V29, P336, DOI 10.4103/0256-4602.101314
   Izadi D, 2015, IEEE SENS J, V15, P4148, DOI 10.1109/JSEN.2015.2411598
   Kalayci TE, 2011, CYBERNET SYST, V42, P605, DOI 10.1080/01969722.2011.634676
   Kaur SP, 2015, IETE J RES, V61, P170, DOI 10.1080/03772063.2014.999833
   Kumar JS, 2019, CLUSTER COMPUT, V22, P15007, DOI 10.1007/s10586-018-2486-3
   Lin WS, 2006, IEEE T IMAGE PROCESS, V15, P2513, DOI 10.1109/TIP.2006.877415
   Mahajan SM, 2015, IEEE 5 INT C COMM SY
   Manna PS, 2016, IMPROVED METAHEURIST, DOI [10.1016/j.engappai.2016.10.014, DOI 10.1016/J.ENGAPPAI.2016.10.014]
   Menon D, 2007, IEEE T IMAGE PROCESS, V16, P132, DOI 10.1109/TIP.2006.884928
   Mrak M, 2003, EUROCON 2003
   Nayak P, 2016, IEEE SENS J, V16, P137, DOI 10.1109/JSEN.2015.2472970
   Prathiba G, 2018, MICROELECTRON RELIAB, V88-90, P91, DOI 10.1016/j.microrel.2018.07.095
   Saeedian E, 2011, CFGA CLUSTERING WIRE
   SenthilKumar K., 2015, Australian Journal of Electrical & Electronics Engineering, V12, P293, DOI 10.1080/1448837X.2015.1092919
   Sharmaa R, 2015, 3 INT C REC TRENDS C
   Sim I, 2010, INTELL AUTOM SOFT CO, V16, P567, DOI 10.1080/10798587.2010.10643101
   Singh AK, 2014, INT J ELECTRON, V101, P605, DOI 10.1080/00207217.2013.794480
   Singh S., 2016, INT C ADV COMP COMM
   Sivasankari B, 2018, MICROELECTRON RELIAB, V88-90, P1316, DOI 10.1016/j.microrel.2018.07.078
   Virmani D, 2014, INT C INF COMM TECHN
NR 32
TC 33
Z9 33
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10215
EP 10232
DI 10.1007/s11042-019-7223-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600026
DA 2024-07-18
ER

PT J
AU Abdelwahab, KM
   Abd El-atty, SM
   El-Shafai, W
   El-Rabaie, S
   Abd El-Samie, FE
AF Abdelwahab, Khaled M.
   Abd El-atty, Saied M.
   El-Shafai, W.
   El-Rabaie, S.
   Abd El-Samie, F. E.
TI Efficient SVD-based audio watermarking technique in FRT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; FRT; Multimedia attacks
ID IMAGE; QUALITY; ROBUST; ATTACKS
AB This paper presents an audio watermarking technique based on singular value decomposition (SVD) and fractional Fourier transform (FRT). The basic idea of this technique is to implement SVD watermarking on the audio signals in the FRT domain due to its recommended degree of security resulting from using a rotation angle in addition to the frequency-domain transformation. The SVD has an invariance to changes in the signal after watermark embedding. Hence, the proposed technique has a large degree of security and resistance to attacks. This technique is based on embedding an image watermark in either the audio signal or a transformed version of this signal. Experimental results show that watermark embedding in the FRT of an audio signal achieves less distortion of the audio signal in the absence of attacks. In the presence of attacks, it is recommended that the embedding is performed in the FRT of the audio signal to maintain a high detection correlation coefficient between the original watermark and the obtained watermark. A segment-based implementation of the proposed audio watermarking technique is also presented. This implementation succeeds in obtaining a high detection correlation coefficient in the presence of severe attacks. It is noticed from the results that in the presence of attacks, the SVD watermarking in the FRT domain with a phase angle of 5 pi/4 is better for watermark detection than watermarking using other angles in the FRT domain.
C1 [Abdelwahab, Khaled M.; Abd El-atty, Saied M.; El-Shafai, W.; El-Rabaie, S.; Abd El-Samie, F. E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Abdelwahab, KM (corresponding author), Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
EM eng_khaled_abdelwahab@yahoo.com; sabdelatty@gmail.com;
   eng.waled.elshafai@gmail.com; elsayedelrabaie@gmail.com;
   fathi_sayed@yahoo.com
RI Sayed, Fathi/HRA-4752-2023; El-Shafai, Walid/AAG-4796-2021
OI Sayed, Fathi/0000-0001-8749-9518; El-Shafai, Walid/0000-0001-7509-2120;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Abd El-Samie FE, 2009, INT J SPEECH TECHNOL, V12, P27, DOI 10.1007/s10772-009-9056-2
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   Alsalami MAT, DIGITAL AUDIO WATERM
   [Anonymous], 2011, INT J SIGNAL PROCESS
   Arnold M., AUDIO WATERMARKING F
   ARNOLD M, 2000, IEEE INT C MULT EXP
   Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Chen S-T, J ADAPTIVE AUDIO WAT
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   CROCHIERE RE, 1980, IEEE T ACOUST SPEECH, V28, P318, DOI 10.1109/TASSP.1980.1163417
   El-bendary MAM., 2011, J TELECOMMUN INFORM, V4, P99
   El-Samie FEA, 2015, INT J SPEECH TECHNOL, V18, P565, DOI 10.1007/s10772-015-9292-6
   Elshazly AR, 2016, 2016 FOURTH INTERNATIONAL JAPAN-EGYPT CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND COMPUTERS (JEC-ECC), P52, DOI 10.1109/JEC-ECC.2016.7518966
   Elshazly EH, 2015, SIGNAL IMAGE VIDEO P, V9, P89, DOI 10.1007/s11760-014-0684-x
   Furht B, 2003, TECHNICAL REPORT
   Ghouti L, 2006, IEEE T SIGNAL PROCES, V54, P1519, DOI 10.1109/TSP.2006.870624
   Goenka KV, 2012, INT J EMERGING TECHN, V2
   Guillemain P, 1996, P IEEE, V84, P561, DOI 10.1109/5.488700
   Huh JH, 2019, J SUPERCOMPUT, V75, P1831, DOI 10.1007/s11227-018-2342-5
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   KUBICHEK RF, 1993, IEEE PACIF, P125, DOI 10.1109/PACRIM.1993.407206
   Lee S, 2019, J SUPERCOMPUT, V75, P4267, DOI 10.1007/s11227-018-2440-4
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Lim J.S., 1990, 2 DIMENSIONAL SIGNAL, P710
   Lindley CA, 1991, DIGITAL IMAGE PROCES
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Liu Z, 2003, IEEE T CIRC SYST VID, V13, P801, DOI 10.1109/TCSVT.2003.815960
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Macq B, 2004, P IEEE, V92, P971, DOI 10.1109/JPROC.2004.827361
   MCBRIDE AC, 1987, IMA J APPL MATH, V39, P159, DOI 10.1093/imamat/39.2.159
   McDermott B. J., 1978, Proceedings of the 1978 IEEE International Conference on Acoustics, Speech and Signal Processing, P581
   Ozaktas H.M., 2001, FRACTIONAL FOURIER T
   OZAKTAS HM, 1995, SIGNAL PROCESS, V46, P119, DOI 10.1016/0165-1684(95)00076-P
   Panaousis E. A., 2009, P 5 INT ICST MOB MUL, P34
   Prochazka UJ, 1998, SIGNAL ANAL PREDICTI
   Schneier B., 1996, Applied Cryptography: Protocols, Algorithms, and Source Code in C
   Shelke RD, 2017, AUDIO WATERMARKING T
   Sun X, 2008, P INT C INT INF HID
   Walker J.S., 2002, A primer on wavelets and their scientific applications
   WANG SH, 1992, IEEE J SEL AREA COMM, V10, P819, DOI 10.1109/49.138987
   Wornell GW, 1996, P IEEE, V84, P586, DOI 10.1109/5.488701
   Wu LF, 2014, IEEE COMMUN MAG, V52, P80, DOI 10.1109/MCOM.2014.6766089
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
   Xiao L, 2003, APCC 2003: 9TH ASIA-PACIFIC CONFERENCE ON COMMUNICATION, VOLS 1-3, PROCEEDINGS, P1
   Yang WH, 1998, INT CONF ACOUST SPEE, P541, DOI 10.1109/ICASSP.1998.674487
   Zhao HV, 2005, IEEE T IMAGE PROCESS, V14, P646, DOI 10.1109/TIP.2005.846035
   Zhu X, P 18 INT C PATT REC
NR 48
TC 44
Z9 45
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 5617
EP 5648
DI 10.1007/s11042-019-08023-z
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900009
DA 2024-07-18
ER

PT J
AU Abid, A
   Rouached, M
   Messai, N
AF Abid, Ahmed
   Rouached, Mohsen
   Messai, Nizar
TI Semantic web service composition using semantic similarity measures and
   formal concept analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SOA; Semantic web service; Semantic similarity; Matching; Discovery;
   Composition
AB One of the main assets of the Service Oriented Architecture (SOA) is composition, which consists in developing higher-level services by re-using well-known functionality provided by other services in a low-cost and rapid development process. In this paper, we present IDECSE a new integrated approach for composite services engineering. By considering semantic Web services, IDECSE addresses the challenge of fully automating the classification, discovery and composition while reducing development time and cost. The classification and the discovery processes rely on adequate semantic similarity measures. Both semantic and syntactic descriptions are integrated through specific techniques for computing similarity measures between services. Formal Concept Analysis (FCA) is used then to classify Web services into concept lattices in order to facilitate relevant services identification. A graph based semantic Web service composition process was proposed within the IDECSE framework. Using semantic similarities in grouping classes of services and in composing services shows a significant improvement compared to other approaches.
C1 [Abid, Ahmed] Easy Global Market, Sophia Antipolis, France.
   [Rouached, Mohsen] Univ Bahrain, Zallaq, Bahrain.
   [Messai, Nizar] Univ Tours, Tours, France.
C3 University of Bahrain; Universite de Tours
RP Abid, A (corresponding author), Easy Global Market, Sophia Antipolis, France.
EM ahmed.abid@eglobalmark.com; mrouached@uob.edu.bh;
   nziar.messai@univ-tours.fr
OI Abid, Ahmed/0000-0002-5321-9247
CR Abid A, 2014, JOINT P CAISE 2014 F, P105
   Abid A, 2015, 2015 IEEE 24TH INTERNATIONAL CONFERENCE ON ENABLING TECHNOLOGIES - INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, P128, DOI 10.1109/WETICE.2015.48
   Acampora G, 2010, ACM T AUTON ADAP SYS, V5, DOI 10.1145/1740600.1740604
   [Anonymous], 2012, FORMAL CONCEPT ANAL
   [Anonymous], 2007, ONTOLOGY MATCHING
   [Anonymous], 2008, P 17 INT C WORLD WID, DOI DOI 10.1145/1367497.1367605
   [Anonymous], P FRENCH SPEAK C SOF
   Azmeh Zeina, 2011, Proceedings of the 2011 IEEE International Conference on Web Services (ICWS 2011), P395, DOI 10.1109/ICWS.2011.47
   Azmeh Z, 2011, FORMAL CONCEPT ANAL
   Baryannis G, 2010, LECT NOTES COMPUT SC, V6500, P55
   Benouaret K., 2011, Proceedings of the 2011 IEEE International Conference on Web Services (ICWS 2011), P540, DOI 10.1109/ICWS.2011.93
   Chafle G, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES, PROCEEDINGS, P839
   Chen FZ, 2017, ENTERP INF SYST-UK, V11, P452, DOI 10.1080/17517575.2015.1081987
   Chen FZ, 2017, EXPERT SYST APPL, V67, P19, DOI 10.1016/j.eswa.2016.09.028
   Cheniki N, 2018, LECT NOTES COMPUT SC, V10845, P448, DOI 10.1007/978-3-319-91662-0_36
   Daagi M, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P172, DOI 10.1109/ICWS.2017.30
   Davey B. A., 2002, INTRO LATTICES ORDER, V2nd, DOI DOI 10.1017/CBO9780511809088
   Devogele T., 2017, P S APPL COMP, P1319
   Elgazzar Khalid, 2010, 2010 IEEE International Conference on Web Services (ICWS), P147, DOI 10.1109/ICWS.2010.31
   Elmaghraoui H, 2011, ARXIV11116401
   Fellah A., 2019, Web Services: Concepts, Methodologies, Tools, and Applications, P859, DOI [https://doi.org/10.4018/978-1-5225-7501-6.ch047, DOI 10.4018/978-1-5225-7501-6.CH047]
   Ganjisaffar Y, 2006, P IEEE WIC ACM INT C, P2006
   Hasan Mohd Hilmi, 2014, Journal of Communications, V9, P81
   Hatzi O, 2013, KNOWL ENG REV, V28, P137, DOI 10.1017/S0269888912000392
   Kumara BTGS, 2014, INT J WEB SERV RES, V11, P24, DOI 10.4018/ijwsr.2014040102
   Kumara BT, 2013, 2013 IEEE 20 INT C W
   Lecue Freddy, 2008, 2008 IEEE International Conference on Web Services (ICWS), P211, DOI 10.1109/ICWS.2008.96
   Lécué F, 2006, LECT NOTES COMPUT SC, V4273, P385
   Liu W, 2009, INT J AGENT ORIENTED
   Ma JM, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1098
   Medhlom MK, 2016, JORDAN J CIV ENG, V10, P107, DOI 10.14525/JJCE.10.1.3409
   Messai N., 2009, THESIS
   Messai N, 2010, FRONT ARTIF INTEL AP, V215, P847, DOI 10.3233/978-1-60750-606-5-847
   Mouhoub ML, 2014, LECT NOTES COMPUT SC, V8831, P123, DOI 10.1007/978-3-662-45391-9_9
   Naim H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS), P73, DOI 10.1109/ICWS.2016.19
   Paolucci M, 2002, LECT NOTES COMPUT SC, V2342, P333
   Papazoglou MP, 2007, COMPUTER, V40, P38, DOI 10.1109/MC.2007.400
   Plebani P, 2009, IEEE T KNOWLEDGE DAT
   Rahimi MR, 2012, INT CONF UTIL CLOUD, P83, DOI 10.1109/UCC.2012.25
   Rodriguez-Mier P, 2016, IEEE T SERV COMPUT, V9, P537, DOI 10.1109/TSC.2015.2402679
   Zapater JJS, 2015, EXPERT SYST APPL, V42, P3833, DOI 10.1016/j.eswa.2015.01.005
   Sánchez D, 2012, EXPERT SYST APPL, V39, P7718, DOI 10.1016/j.eswa.2012.01.082
   Sangers J, 2013, EXPERT SYST APPL, V40, P4660, DOI 10.1016/j.eswa.2013.02.011
   Tarjan R., 1972, SIAM Journal on Computing, V1, P146, DOI 10.1137/0201010
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   van der Merwe D, 2004, LECT NOTES ARTIF INT, V2961, P372
   Wenqiang Li, 2010, Proceedings First International Conference on Networking and Distributed Computing (ICNDC 2010), P89, DOI 10.1109/ICNDC.2010.27
   Wu J, 2014, KNOWL INF SYST, V38, P207, DOI 10.1007/s10115-013-0623-0
   Yan YX, 2008, I W ADV ISS E COMMER, P335, DOI [10.1109/CECandEEE.2008.124, 10.1109/CEC/EEE.2008.45]
NR 49
TC 11
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6569
EP 6597
DI 10.1007/s11042-019-08441-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900051
DA 2024-07-18
ER

PT J
AU Cevik, T
   Fettahoglu, M
   Cevik, N
   Yilmaz, S
AF Cevik, Taner
   Fettahoglu, Mustafa
   Cevik, Nazife
   Yilmaz, Serdar
TI FTSH: a framework for transition from square image processing to
   hexagonal image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hexagonal image processing; Square image processing; Framework
ID LOCAL BINARY PATTERN; FACE RECOGNITION; TEXTURE CLASSIFICATION;
   DESCRIPTOR; TRANSFORMATIONS; SCALE
AB This paper proposes a novel framework for transition from the ordinary square-pixel-based image processing (SIP) domain to the hexagonal-pixel-based (HIP) domain (FTSH). The conventional image acquisition and processing are based on square pixels. However, HIP can provide promising advantages in many respects, such as degrading the curse of data size and accordingly reducing the processing time. HIP did not achieve satisfactory attraction because all software, including libraries, methods and structures, as well as mathematical operations and methodologies developed to date, are aimed at SIP. In this study, we propose a framework containing the corresponding HIP equivalents of some basic SIP methods and operations. In addition, the results of these basic operations in both SIP and HIP areas are presented comparatively. Since there is no common and standardized framework or library for HIP, this study can be used by other researchers who wish to enter the HIP. Simulation results support the competitive performance of HIP, and this promising performance can be carried far beyond when properly handled and focused.
C1 [Cevik, Taner; Yilmaz, Serdar] Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
   [Fettahoglu, Mustafa] Istanbul Aydin Univ, Dept Comp Engn, Istanbul, Turkey.
   [Cevik, Nazife] Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul Aydin University; Istanbul Aydin University; Istanbul Arel
   University
RP Cevik, T (corresponding author), Istanbul Aydin Univ, Dept Software Engn, Istanbul, Turkey.
EM tanercevik@aydin.edu.tr; mustafafettahoglu@stu.aydin.edu.tr;
   nazifecevik@arel.edu.tr; serdaryilmaz1@aydin.edu.tr
RI ÇEVİK, TANER/AAD-9934-2022; ÇEVİK, TANER/AAD-9997-2022; YILMAZ,
   Serdar/HII-3190-2022; YILMAZ, Serdar/AAC-6164-2021
OI ÇEVİK, TANER/0000-0001-9653-5832; ÇEVİK, TANER/0000-0001-9653-5832;
   YILMAZ, Serdar/0000-0002-4316-3737; Fettahoglu,
   Mustafa/0000-0002-3496-5260
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], IMAGE ALGEBRA MORPHO
   [Anonymous], HEXAGONAL IMAGE PROC
   BELL SBM, 1989, IMAGE VISION COMPUT, V7, P194, DOI 10.1016/0262-8856(89)90044-9
   BURT PJ, 1980, COMPUT VISION GRAPH, V14, P271, DOI 10.1016/0146-664X(80)90056-8
   Cevik N., 2019, TURKISH STUD INF TEC, V14, P149, DOI [10.29228/TurkishStudies.22825, DOI 10.29228/TURKISHSTUDIES.22825]
   Çevik N, 2020, PATTERN ANAL APPL, V23, P371, DOI 10.1007/s10044-019-00803-5
   Cevik N, 2019, MULTIMED TOOLS APPL, V78, P15909, DOI 10.1007/s11042-018-6967-4
   Cevik N, 2019, IET IMAGE PROCESS, V13, P1097, DOI 10.1049/iet-ipr.2018.6423
   Cevik T, 2019, MULTIMED TOOLS APPL, V78, P26537, DOI 10.1007/s11042-019-07816-6
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   CURCIO CA, 1987, SCIENCE, V236, P579, DOI 10.1126/science.3576186
   Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368
   Dan ZP, 2014, OPTIK, V125, P6320, DOI 10.1016/j.ijleo.2014.08.003
   Dubey SR, 2017, ARXIV170909518CSCV
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   GIBSON L, 1982, COMPUT VISION GRAPH, V20, P82, DOI 10.1016/0146-664X(82)90075-2
   Gibson L., 1982, Proceedings of PRIP 82. IEEE Computer Society Conference on Pattern Recognition and Image Processing, P566
   Gibson L., 1986, Proceedings of the IEEE 1986 National Aerospace and Electronics Conference, NAECON 1986 (Cat. No.86CH2307-7), P215
   Hales TC, 2001, DISCRETE COMPUT GEOM, V25, P1, DOI 10.1007/s004540010071
   Hales Thomas C., 2000, NOT AM MATH SOC, V47, P440
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   HER I, 1994, CVGIP-GRAPH MODEL IM, V56, P336, DOI 10.1006/cgip.1994.1030
   HER I, 1995, IEEE T IMAGE PROCESS, V4, P1213, DOI 10.1109/83.413166
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Knuth D. E., 1969, The Art of Computer Programming, Vol. 2, Seminumerical Algorithms, V2
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Libor S, 2000, FACE RECOGNITION DAT
   LUCAS D, 1979, P AM MATH SOC, V74, P1
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   MAHESH B, 1989, P SOC PHOTO-OPT INS, V1199, P764, DOI 10.1117/12.970087
   Melendez J, 2008, PATTERN ANAL APPL, V11, P365, DOI 10.1007/s10044-007-0097-3
   MERSEREAU RM, 1979, P IEEE, V67, P930, DOI 10.1109/PROC.1979.11356
   Middleton L., 2005, Hexagonal Image Processing: A Practical Approach
   Miller EG, 1999, COMPUT VIS IMAGE UND, V74, P193, DOI 10.1006/cviu.1999.0754
   OVERINGTON I, 1992, COMPUTER VISION UNIF
   Pirenne M.H., 1967, VISION EYE
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Rivera AR, 2015, IEEE T PATTERN ANAL, V37, P2146, DOI 10.1109/TPAMI.2015.2392774
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570
   ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7
   Sarasota FL, 1994, P 2 IEEE WORKSH APPL
   SERRA J, 1986, COMPUT VISION GRAPH, V35, P283, DOI 10.1016/0734-189X(86)90002-2
   Sheridan P, 2000, IMAGE VISION COMPUT, V18, P907, DOI 10.1016/S0262-8856(00)00036-6
   Snyder WE, 1999, PROC SPIE, V3661, P716, DOI 10.1117/12.348629
   Staunton RC, 1999, ADV IMAG ELECT PHYS, V107, P231, DOI 10.1016/S1076-5670(08)70188-5
   STEVENSON RL, 1985, J OPT SOC AM A, V2, P1009, DOI 10.1364/JOSAA.2.001009
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang Y, 2005, SYSTEM SIMULATION AND SCIENTIFIC COMPUTING, VOLS 1 AND 2, PROCEEDINGS, P525
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   WATSON AB, 1989, IEEE T BIO-MED ENG, V36, P97, DOI 10.1109/10.16453
   WUTHRICH CA, 1991, CVGIP-GRAPH MODEL IM, V53, P324, DOI 10.1016/1049-9652(91)90036-J
   Yang B, 2013, NEUROCOMPUTING, V120, P365, DOI 10.1016/j.neucom.2012.10.032
   Yang S, 2011, IEEE INT SYMP INFO, P2866, DOI 10.1109/ISIT.2011.6034099
   Yin QB, 2008, CHINESE J ELECTRON, V17, P646
   Zhou E, 2005, IEEE WCNC, P18
NR 58
TC 1
Z9 1
U1 1
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7021
EP 7048
DI 10.1007/s11042-019-08487-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100006
DA 2024-07-18
ER

PT J
AU Fan, ZZ
   Wei, C
AF Fan, Zizhu
   Wei, Chao
TI Fast kernel sparse representation based classification for Undersampling
   problem in face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse representation based classification (SRC); Kernel sparse
   representation; L-1 norm minimization; Coordinate descent method;
   Classification
ID DICTIONARY; REGULARIZATION
AB We propose a fast kernel sparse representation based classification (SRC) for undersampling problem, i.e., each class has very few training samples, in face recognition. The proposed algorithm exploits a nonlinear mapping to map the data from the original input space into a high-dimensional feature space. Then, it performs very fast sparse representation and classification of samples in this space. Similar to the typical SRC methods, the proposed approach is based on the L1 norm minimization, whose direct solution can be very time-consuming. In order to improve the computational efficiency, our method uses the coordinate descent method in the feature space, which can avoid directly solving the L1 norm minimization problem, and significantly expedites the computational procedure. Compared with other SRC methods based on the L1 norm minimization, our proposed method achieves very high computational efficiency, without significantly degrading the classification performance. Several experiments on popular face databases demonstrate that our method is a promising efficient kernel SRC based method.
C1 [Fan, Zizhu; Wei, Chao] East China Jiaotong Univ, Sch Sci, Nanchang, Jiangxi, Peoples R China.
C3 East China Jiaotong University
RP Fan, ZZ (corresponding author), East China Jiaotong Univ, Sch Sci, Nanchang, Jiangxi, Peoples R China.
EM zzfan3@163.com
RI Wei, Chao/ABD-3057-2020
CR Adamo A, 2015, MACH VISION APPL, V26, P837, DOI 10.1007/s00138-015-0694-x
   [Anonymous], P 25 ACM INT C MULT
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], INT C MED IM COMP CO
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], ICCV 2011 BARC SPAIN
   Basri R, 2011, IEEE T PATTERN ANAL, V33, P266, DOI 10.1109/TPAMI.2010.110
   Beveridge JR, 2009, IEEE T PATTERN ANAL, V31, P351, DOI 10.1109/TPAMI.2008.200
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Chen ZH, 2015, INFORM SCIENCES, V292, P15, DOI 10.1016/j.ins.2014.08.066
   Deng WH, 2013, PROC CVPR IEEE, P399, DOI 10.1109/CVPR.2013.58
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Fan ZZ, 2015, J VIS COMMUN IMAGE R, V28, P15, DOI 10.1016/j.jvcir.2015.01.001
   Fan ZZ, 2015, NEUROCOMPUTING, V151, P304, DOI 10.1016/j.neucom.2014.09.035
   Fan ZZ, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033027
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gao SH, 2014, IEEE T MULTIMEDIA, V16, P762, DOI 10.1109/TMM.2014.2299516
   Gao SH, 2013, IEEE T IMAGE PROCESS, V22, P423, DOI 10.1109/TIP.2012.2215620
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Huang KK, 2017, IEEE T NEUR NET LEAR, V28, P1082, DOI 10.1109/TNNLS.2016.2522431
   Jian M, 2013, IEEE T SIGNAL PROCES, V61, P4416, DOI 10.1109/TSP.2013.2271479
   Kim SJ, 2007, IEEE J-STSP, V1, P606, DOI 10.1109/JSTSP.2007.910971
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Liu WY, 2015, PATTERN RECOGN, V48, P3076, DOI 10.1016/j.patcog.2015.04.014
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Nie F, 2010, 24 ANN C ADV NEURAL, V23, P1821, DOI 10.1016/j.neuroimage.2010.10.081
   Ren CX, 2012, PATTERN RECOGN, V45, P2708, DOI 10.1016/j.patcog.2012.01.003
   Schölkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641
   Shao CB, 2017, INFORM SCIENCES, V393, P1, DOI 10.1016/j.ins.2017.02.017
   Shekhar S, 2014, IEEE T PATTERN ANAL, V36, P113, DOI 10.1109/TPAMI.2013.109
   Shrivastava A, 2014, IEEE T IMAGE PROCESS, V23, P3013, DOI 10.1109/TIP.2014.2324290
   Song BQ, 2016, IEEE J-STARS, V9, P1613, DOI 10.1109/JSTARS.2015.2508285
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wang J, 2014, IEEE T CYBERNETICS, V44, P2368, DOI 10.1109/TCYB.2014.2307067
   Wang LF, 2014, IEEE T CIRC SYST VID, V24, P1132, DOI 10.1109/TCSVT.2014.2302496
   Wang SJ, 2012, IEEE T NEUR NET LEAR, V23, P876, DOI 10.1109/TNNLS.2012.2191620
   Wang ZY, 2010, PROCEEDINGS OF THE ASME INTERNATIONAL HEAT TRANSFER CONFERENCE - 2010, VOL 7, P105, DOI 10.1145/1816041.1816060
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2016, PATTERN RECOGN, V54, P68, DOI 10.1016/j.patcog.2015.12.017
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1950, DOI 10.1109/TCYB.2014.2300175
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Xu ZB, 2012, IEEE T NEUR NET LEAR, V23, P1013, DOI 10.1109/TNNLS.2012.2197412
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang J, 2013, IEEE T NEUR NET LEAR, V24, P1023, DOI 10.1109/TNNLS.2013.2249088
   Yang J, 2012, PATTERN RECOGN, V45, P1104, DOI 10.1016/j.patcog.2011.08.022
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yin J, 2012, NEUROCOMPUTING, V77, P120, DOI 10.1016/j.neucom.2011.08.018
   Zhang GQ, 2016, IEEE T IMAGE PROCESS, V25, P4271, DOI 10.1109/TIP.2016.2587119
   Zhang L, 2012, IEEE T SIGNAL PROCES, V60, P1684, DOI 10.1109/TSP.2011.2179539
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
NR 55
TC 9
Z9 10
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7319
EP 7337
DI 10.1007/s11042-019-08211-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100019
DA 2024-07-18
ER

PT J
AU Li, LW
   Qin, SY
   Lu, Z
   Xu, KH
   Hu, ZY
AF Li, Lianwei
   Qin, Shiyin
   Lu, Zhi
   Xu, Kuanhong
   Hu, Zhongying
TI One-shot learning gesture recognition based on joint training of 3D
   ResNet and memory module
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; One-shot learning; Joint training; 3D ResNet;
   Memory module
ID RGB-D DATA; DATASET
AB As a research hotspot in the field of human-machine interaction, a great progress of hand gesture recognition has been achieved with the development of deep learning of neural networks. However, in the deep learning based recognition methods, it is necessary to rely heavily on large-scale labeled dataset which is very hard to build in practical applications. In order to achieve a well performance under some strict constraint of few sample data, one-shot learning gesture recognition is studied and a joint deep training method by combination of 3D ResNet with a memory module is presented in this paper. In our scheme a combinatorial optimization of feature extraction by 3D ResNet with memory capacity of rare event by memory module is carried out with an effective strategy of optimal decision and two relative performance indices. In order to implement one-shot learning gesture recognition, the memory module is employed to remember the features extracted by well-trained 3D ResNet and the classification decision is performed by the nearest neighbor algorithm with cosine similarity measure. In view of real-world applications about human-machine interaction technology, its ability to deal with negative samples plays a significant role thus a mechanism based on the threshold of cosine similarity is built to realize effective classification and rejection respectively. In order to validate and evaluate the performance of our proposed method, a special hand gesture dataset containing 3045 gesture videos is built and a series of experiment results on our collected dataset and public datasets demonstrate the feasibility and effectiveness of our method.
C1 [Li, Lianwei; Qin, Shiyin; Lu, Zhi] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.
   [Qin, Shiyin] Dongguan Univ Technol, Sch Elect Engn & Intelligentizat, Dongguan 523808, Guangdong, Peoples R China.
   [Xu, Kuanhong; Hu, Zhongying] Sony China Res Lab, Artificial Intelligence Res Dept, Beijing 100028, Peoples R China.
C3 Beihang University; Dongguan University of Technology
RP Li, LW (corresponding author), Beihang Univ, Sch Automat Sci & Elect Engn, Beijing 100191, Peoples R China.
EM llw2017@buaa.edu.cn; qsy@buaa.edu.cn; by1603117@buaa.edu.cn;
   Kuanhong.Xu@sony.com; Zhongying.Hu@sony.com
RI li, lian/HSG-2194-2023; qin, shi/JNY-1785-2023
CR [Anonymous], 2017, ABS170805038 CORR
   [Anonymous], ARXIV170303129
   [Anonymous], 2016, Software available from tensorflow org
   [Anonymous], 2014, ICLR 15
   [Anonymous], 2016, Residual Networks Behave Like Ensembles of Relatively Shallow Networks
   Bartunov S., 2016, ARXIV160506065
   Bertinetto L., 2016, Advances in neural information processing systems, P523
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   Finn C, 2017, PR MACH LEARN RES, V70
   Glorot X., 2010, P INT C ART INT STAT, P249
   Guo JJ, 2018, MULTIMED TOOLS APPL, V77, P30233, DOI 10.1007/s11042-018-6130-2
   Guyon I, 2014, MACH VISION APPL, V25, P1929, DOI 10.1007/s00138-014-0596-3
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holzinger A, 2018, LECT NOTES COMPUT SC, V11015, P1, DOI 10.1007/978-3-319-99740-7_1
   Ioffe S., 2015, P INT C MACH LEARN, VVolume 1, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kingma D.P., 2014, ARXIV14126980
   Koch G, 2015, P 32 INT C MACHINE L
   Konecny J, 2014, J MACH LEARN RES, V15, P2513
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JJ, 2018, MULTIMED TOOLS APPL, V77, P17181, DOI 10.1007/s11042-017-5285-6
   Li YN, 2016, INT C PATT RECOG, P25, DOI 10.1109/ICPR.2016.7899602
   Lin J, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16122171
   Lin J, 2015, CHIN CONT DECIS CONF, P4947
   Liu XJ, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P194, DOI 10.1109/ICIVC.2017.7984545
   Loshchilov I., 2016, Proc. 5th International Conf. on Learning Representations
   Malgireddy M.R., 2012, 2012 ieee computer society conference on computer vision and pattern recognition workshops, P43
   Malgireddy MR, 2013, J MACH LEARN RES, V14, P2189
   Molchanov Pavlo, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163132
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Molchanov P, 2016, PROC CVPR IEEE, P4207, DOI 10.1109/CVPR.2016.456
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ravi S, 2016, PROC INT C LEARN REP
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wan J, 2016, IEEE COMPUT SOC CONF, P761, DOI 10.1109/CVPRW.2016.100
   Wan J, 2016, IEEE T PATTERN ANAL, V38, P1626, DOI 10.1109/TPAMI.2015.2513479
   Wan J, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.2.023017
   Wan J, 2014, IEEE T IMAGE PROCESS, V23, P3152, DOI 10.1109/TIP.2014.2328181
   Wan J, 2013, J MACH LEARN RES, V14, P2549
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang T, 2017, IEEE ACCESS, V5, P17627, DOI 10.1109/ACCESS.2017.2746095
   Zhang HL, 2019, MULTIMED TOOLS APPL, V78, P9919, DOI 10.1007/s11042-018-6622-0
   Zhang L, 2017, IEEE INT CONF COMP V, P3120, DOI 10.1109/ICCVW.2017.369
   Zhang YF, 2018, IEEE T MULTIMEDIA, V20, P1038, DOI 10.1109/TMM.2018.2808769
   Zhu GM, 2016, INT C PATT RECOG, P19, DOI 10.1109/ICPR.2016.7899601
   Zhu GM, 2017, IEEE ACCESS, V5, P4517, DOI 10.1109/ACCESS.2017.2684186
NR 59
TC 10
Z9 11
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6727
EP 6757
DI 10.1007/s11042-019-08429-9
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900058
DA 2024-07-18
ER

PT J
AU Maalej, R
   Kherallah, M
AF Maalej, Rania
   Kherallah, Monji
TI Improving the DBLSTM for on-line Arabic handwriting recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dropout; ReLU; Maxout; Arabic handwriting recognition; BLSTM
ID NEURAL-NETWORKS; DROPOUT; LSTM; TEXT
AB Various applications involved in the computer recognition of pen-input handwritten words, such as the online form filling, text editing, note taking, and so on. Therefore, a great deal of research work tries to improve the recognition rate of those online words recognition systems resulting in several effective methods. Relevant results related to Latin and Chinese scripts have been achieved. However, the Arabic script has been neglected so far, which stimulated us to propose a new online Arabic handwriting recognition system based on DBLSTM that relies on three techniques that were applied in order to enhance its performance. First, the dropout was applied, in different positions, to prevent overfitting. Then, ReLU and Maxout units were added, in different ways, to overcome the vanishing gradient problem. These proposed systems were tested on a large database ADAB to prove its performance against difficult conditions such as the variety of writers, the large vocabulary and the diversity of style. According to the experimental results and compared to the baseline system, the best tested architecture gives a reduction of 10.99% in label error rate.
C1 [Maalej, Rania] Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
   [Kherallah, Monji] Univ Sfax, Fac Sci, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Faculty of Sciences Sfax
RP Maalej, R (corresponding author), Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
EM rania.mlj@gmail.com
RI MAALEJ, Rania/AAF-6695-2019
OI MAALEJ, Rania/0000-0003-1657-3324; KHERALLAH, Monji/0000-0002-4549-1005
CR Abdelazeem S, 2011, PROC INT CONF DOC, P1304, DOI 10.1109/ICDAR.2011.262
   Abdou S., 2009, P 2 INT C AR LANG RE, P24
   [Anonymous], 2017, P INTERSPEECH
   Bin Ahmed S, 2019, NEURAL COMPUT APPL, V31, P1143, DOI 10.1007/s00521-017-3146-x
   Bluche T, 2015, PROC INT CONF DOC, P681, DOI 10.1109/ICDAR.2015.7333848
   Boubaker H., 2012, Guide to OCR for Arabic Scripts, P541
   Cai M, 2016, SPEECH COMMUN, V77, P53, DOI 10.1016/j.specom.2015.12.003
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   El Abed H, 2011, INT J DOC ANAL RECOG, V14, P15, DOI 10.1007/s10032-010-0124-6
   Frinken V, 2015, PROC INT CONF DOC, P911, DOI 10.1109/ICDAR.2015.7333894
   FUNAHASHI K, 1993, NEURAL NETWORKS, V6, P801, DOI 10.1016/S0893-6080(05)80125-X
   Fung I, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2511, DOI 10.1109/ICASSP.2018.8462280
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Goodfellow IJ, 2013, ARXIV13024389
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A., 2008, ADV NEURAL INFORM PR, V20, P1
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   LEVENSHT.VI, 1965, DOKL AKAD NAUK SSSR+, V163, P845
   Li XG, 2015, INT CONF ACOUST SPEE, P4600, DOI 10.1109/ICASSP.2015.7178842
   Liwicki M, 2005, PROC INT CONF DOC, P956, DOI 10.1109/ICDAR.2005.132
   Liwicki M, 2007, PROC INT CONF DOC, P367
   Luo Y, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (IEEE ROBIO 2017), P1599, DOI 10.1109/ROBIO.2017.8324646
   Maalej R, 2016, LECT NOTES COMPUT SC, V9887, P431, DOI 10.1007/978-3-319-44781-0_51
   Maalej R, 2016, LECT NOTES COMPUT SC, V9730, P746, DOI 10.1007/978-3-319-41501-7_83
   Maalej R, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P417, DOI 10.1109/DAS.2016.49
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Ray A., 2015, P 2015 8 INT C ADV P, P1, DOI [10.1109/ICAPR.2015.7050699, DOI 10.1109/ICAPR.2015.7050699]
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Ul-Hasan A, 2013, PROC INT CONF DOC, P1061, DOI 10.1109/ICDAR.2013.212
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
NR 34
TC 14
Z9 14
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17969
EP 17990
DI 10.1007/s11042-020-08740-w
EA FEB 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000515925400003
DA 2024-07-18
ER

PT J
AU Wang, H
   Wang, KX
   Wu, YQ
   Wang, ZZ
   Zou, L
AF Wang, Han
   Wang, Kexin
   Wu, Yuqing
   Wang, Zhongzhi
   Zou, Ling
TI User preference-aware video highlight detection via deep reinforcement
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reinforcement learning; Video understanding; Soft computing for vision
   and learning
AB Video highlight detection is a technique to retrieval short video clips that capture a user's primary attention or interest within an unedited video. There exists a substantial interest in automatizing highlight detection to facilitate efficient video browsing. Recent research often focuses on objectively finding frames that are visual representative as well as diversity to form highlights. However, the user preferences are relatively subjective and may vary from person to person. Therefore, it is not trivial to find different highlights over a same video for different users. This paper describes a reinforcement learning-based framework that detects different highlights according to different user's preferences. Under this framework, a novel reward function that accounts for relevance of user preference to candidate highlights is introduced. During training, the framework strives for earning higher rewards by learning to detect more diverse and more preference-aware highlights. The effectiveness of the proposed method is illustrated by applying it to different types of real world movies, and show it achieves state-of-the-art results.
C1 [Wang, Han; Wang, Kexin; Wu, Yuqing; Wang, Zhongzhi] Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing, Peoples R China.
   [Zou, Ling] Beijing Film Acad, Digital Media Sch, Beijing, Peoples R China.
C3 Beijing Forestry University
RP Wang, ZZ (corresponding author), Beijing Forestry Univ, Sch Informat Sci & Technol, Beijing, Peoples R China.
EM wanghan@bjfu.edu.cn
RI Wu, Julia/W-5337-2019
FU Fundamental Research Funds for the Central Universities [2018ZY03,
   2015ZCQ-XX]; Natural Science Foundation of China (NSFC) [61703046];
   Scientific Research Program of Beijing Education Commission
   [KM201910050001]
FX This work was supported in part by the Fundamental Research Funds for
   the Central Universities (2018ZY03, 2015ZCQ-XX), the Natural Science
   Foundation of China (NSFC) (61703046) and Scientific Research Program of
   Beijing Education Commission (KM201910050001).
CR Araujo A, 2018, IEEE T CIRC SYST VID, V28, P1406, DOI 10.1109/TCSVT.2017.2667710
   Gou JP, 2019, EXPERT SYST APPL, V115, P356, DOI 10.1016/j.eswa.2018.08.021
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOSU IA, 2016, ARXIV13125602
   KAWAI Y, 2007, P ACM INT C IM VID R, P49
   Koutras P, 2015, IEEE IMAGE PROC, P4361, DOI 10.1109/ICIP.2015.7351630
   LAN X, 2017, BRIT MACH VIS C
   LEI J, 2018, IEEE T CIRC SYS VIDE
   Li Y., 2017, ARXIV170107274, DOI DOI 10.1007/978-3-319-56991-8_32
   Li Y, 2015, PROC CVPR IEEE, P4758, DOI 10.1109/CVPR.2015.7299108
   Liu Q, 2017, KNOWL-BASED SYST, V134, P189, DOI 10.1016/j.knosys.2017.07.032
   Masumitsu K, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P267, DOI 10.1109/ICIP.2000.899351
   Ou WH, 2018, MULTIMED TOOLS APPL, V77, P10569, DOI 10.1007/s11042-017-4672-3
   Quan Z, 2018, WORLD WIDE WEB, V22, P1
   Rao YM, 2017, IEEE I CONF COMP VIS, P3951, DOI 10.1109/ICCV.2017.424
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharghi A, 2017, PROC CVPR IEEE, P2127, DOI 10.1109/CVPR.2017.229
   Smith JR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1799, DOI 10.1145/3123266.3127906
   SONG X, 2016, IEEE INT C MULT EXP
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang H, 2015, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2015.526
   Zhang K, 2016, LECT NOTES COMPUT SC, V9911, P766, DOI 10.1007/978-3-319-46478-7_47
   Zhou KY, 2018, AAAI CONF ARTIF INTE, P7582
NR 25
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 15015
EP 15024
DI 10.1007/s11042-020-08668-1
EA FEB 2020
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000516442500003
DA 2024-07-18
ER

PT J
AU Liu, Y
AF Liu, Yang
TI Design and implementation of multimedia teaching platform based on SOA
   architecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia technology; Instrument teaching; Multimedia teaching
   platform; SOA architecture
ID MAINTAINABILITY; J2EE; API
AB Music teaching, as an important part of quality education, plays an important role in training high-quality innovative talents in the twenty-first century. Because of the dependence of musical instrument teaching on musical instruments, it is difficult to popularize musical instrument teaching in specific occasions. In order to achieve better instrument teaching, based on multimedia technology and SOA architecture, this paper designs a multimedia teaching platform for indoor instrument teaching based on SOA. Firstly, the characteristics and requirements of multimedia are analyzed from the specific requirements, and the related functions are designed and implemented for each operator. Secondly, using the current mainstream SOA architecture, centralized management and distributed deployment, the efficient application, flexible expansion and convenient maintenance of the system are realized. Finally, a small-scale multimedia teaching platform is constructed, and the effectiveness of the teaching platform designed in this paper is verified by the actual test. Through the analysis of the performance of the platform, it is found that the teaching platform designed in this paper can promote students to master knowledge, and is conducive to the realization of indoor music teaching.
C1 [Liu, Yang] Xiamen Univ, Art Coll, Mus Dept, Xiamen, Fujian, Peoples R China.
C3 Xiamen University
RP Liu, Y (corresponding author), Xiamen Univ, Art Coll, Mus Dept, Xiamen, Fujian, Peoples R China.
EM 123120356@qq.com
CR Alshinina R, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030536
   Altendorf E, 2002, IEEE SOFTWARE, V19, P81, DOI 10.1109/52.991368
   Alwadain A, 2016, DATA KNOWL ENG, V105, P39, DOI 10.1016/j.datak.2015.09.004
   Andersen R, 2015, IEEE T PROF COMMUN, V58, P247, DOI 10.1109/TPC.2016.2516619
   Arostegui J.L., 2016, ARTS ED POLICY REV, V117, P96, DOI [DOI 10.1080/10632913.2015.1007406, 10.1080/10632913.2015.1007406]
   Baski D, 2011, IET SOFTW, V5, P320, DOI 10.1049/iet-sen.2010.0089
   Baumann FW, 2017, INT J ADV MANUF TECH, V92, P1519, DOI 10.1007/s00170-017-0260-y
   Brok PD, 2010, TEACH TEACH, V16, P717, DOI [10.1080/13540602.2010.517689, DOI 10.1080/13540602.2010.517689]
   Choi K, 2016, P ASS INFO SCI TECHN, V53, P1
   Conkling SW, 2003, COLL MUSIC SYM, V43, P55
   Dionyssiou Zoe, 2000, MUSIC EDUC RES, V2, P141, DOI DOI 10.1080/14613800050165613
   Guruge A, 2004, WEB SERVICES, V2, P145, DOI [10.1016/B978-155558282-1/50006-3, DOI 10.1016/B978-155558282-1/50006-3]
   Jingping LU, 2003, J CHONGQING U, V2, P57
   Kevan JM, 2016, TECHNOL KNOWL LEARN, V21, P143, DOI 10.1007/s10758-015-9260-x
   Kopecky J, 2007, IEEE INTERNET COMPUT, V11, P60, DOI 10.1109/MIC.2007.134
   Läufer K, 2005, COMPUT SCI ENG, V7, P80, DOI 10.1109/MCSE.2005.85
   Lawless M. S., 2016, J ACOUST SOC AM, V139, P2096, DOI [10.1121/1.4950223, DOI 10.1121/1.4950223]
   Li D, 2016, J COMPUT THEOR NANOS, V13, P4812, DOI [10.1166/jctn.2016.5580, DOI 10.1166/JCTN.2016.5580]
   Liu JX, 2016, IEEE T SERV COMPUT, V9, P686, DOI 10.1109/TSC.2015.2433251
   Mayr C, 2011, DATA KNOWL ENG, V70, P794, DOI 10.1016/j.datak.2011.05.004
   MUNCH RH, 1948, IND ENG CHEM, V40, pA83
   Nasridinov A, 2016, SECUR COMMUN NETW, V9, P492, DOI 10.1002/sec.934
   Palma ND, 2011, IEEE T PARALL DISTR, V23, P330, DOI [10.1109/TPDS.2011.161, DOI 10.1109/TPDS.2011.161]
   Russell DA, 2016, J ACOUST SOC AM, V139, P2096, DOI [10.1121/1.4950221, DOI 10.1121/1.4950221]
   Tan W, 2016, IEEE INTERNET COMPUT, V20, P64, DOI 10.1109/MIC.2016.74
   Yu L, 2014, SENSOR LETT, V12, P448, DOI [10.1166/sl.2014.3273, DOI 10.1166/SL.2014.3273]
NR 26
TC 9
Z9 9
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10899
EP 10914
DI 10.1007/s11042-020-08735-7
EA FEB 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000520065100001
DA 2024-07-18
ER

PT J
AU Kumar, KPS
   Bhavani, R
AF Kumar, K. P. Sanal
   Bhavani, R.
TI Human activity recognition in egocentric video using HOG, GiST and color
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; egocentric vision; Histogram of Oriented Gradients;
   Genetic algorithm; Random Forest classifier
AB With the rapid increase in digital technology, most research areas are involved in human activity recognition, which can help to analyze the activities of patients. A novel approach for human activity recognition in egocentric video has been invoked in this research article. Generally, only the objects are identified, but the actions are not recognized. With this motivation and new trends, this paper presents an efficient technique to recognize the activities. In our approach, first the various activity dataset is trained, and the feature vector values are stored for various activities, which are applied to the testing inputs. Here, we use a filtering technique, i.e., a median filter followed by a segmentation method using watershed and feature extraction, such as a Histogram of Oriented Gradient (HOG), Color and GiST and a combination of all Features. Features are reduced using a genetic algorithm, and classification is done using Support Vector Machine (SVM) and a Random Forest classifier. The experimental results demonstrate that the Random Forest classifier outperformed the SVM classifier.
C1 [Kumar, K. P. Sanal] Annamalai Univ, Dept ECE, Chidambaram, India.
   [Bhavani, R.] Annamalai Univ, Dept CSE, Chidambaram, India.
C3 Annamalai University; Annamalai University
RP Kumar, KPS (corresponding author), Annamalai Univ, Dept ECE, Chidambaram, India.
EM sanalprabha@yahoo.co.in; bhavaniaucse@gmail.com
RI Kumar, K. P. Sanal/AAR-3609-2020
OI Kumar, K. P. Sanal/0000-0002-4047-197X
CR Bieniek A, 2000, PATTERN RECOGN, V33, P907, DOI 10.1016/S0031-3203(99)00154-5
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de San Roman PP, 2017, COMPUT VIS IMAGE UND, V164, P82, DOI [10.1016/j.cviu.2017.03.001, 10.1016/j.cviu2017.03.001]
   Fathi A, 2011, IEEE I CONF COMP VIS, P407, DOI 10.1109/ICCV.2011.6126269
   Fong S, 2016, J SUPERCOMPUT, V72, P3927, DOI 10.1007/s11227-016-1639-5
   Gemmell J, 2006, COMMUN ACM, V49, P88, DOI 10.1145/1107458.1107460
   Hassan M., 2014, J. Image Graph, V2, P28, DOI DOI 10.12720/JOIG.2.1.28-32
   Hori T., 2003, ACM SIGMM INT WORKSH, P31, DOI DOI 10.1145/973264.973270
   Jacobson L., 2015, GENETIC ALGORITHMS J
   Knoop S, 2005, EXTRACTION EVALUATIO
   Kumar KPS, 2016, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON INFORMATICS AND ANALYTICS (ICIA' 16)
   Kumar KPS, 2017, IOP CONF SER-MAT SCI, V225, DOI 10.1088/1757-899X/225/1/012226
   Kuncheva LI, 2014, COMBINING PATTERN CLASSIFIERS: METHODS AND ALGORITHMS, 2ND EDITION, P1
   Li CH, 2014, J SUPERCOMPUT, V67, P854, DOI 10.1007/s11227-013-1056-y
   Maurer U, 2006, BSN 2006: INTERNATIONAL WORKSHOP ON WEARABLE AND IMPLANTABLE BODY SENSOR NETWORKS, PROCEEDINGS, P113
   Niebles JuanCarlos., 2010, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P655, DOI DOI 10.1109/CVPR.2010.5540152
   Ortis A, 2017, PATTERN RECOGN, V72, P207, DOI 10.1016/j.patcog.2017.07.010
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Rachmadi RF, LARGE SCALE SCENE CL
   Salman N., 2006, The International Arab Journal of Information Technology, V3, Issue, P104
   Sanal Kumar KP, 2017, HUMAN ACTIVITY RECOG
   Solomon C, 2010, FUNDAMENTALS DIGITAL, P1
   Song S, 2014, COMP VIS ACCV 2014 W
   Suresha, 2012, INT CONF COMPUT
   Tukey J. W., 1974, P EASCOM, P673
   Vaca-Castano G, 2016, COMP VIS IMAGE UNDER
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang X, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/9183796
   Wu JB, 2010, ACS NANO, V4, P43, DOI 10.1021/nn900728d
NR 29
TC 18
Z9 20
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3543
EP 3559
DI 10.1007/s11042-018-6034-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700023
DA 2024-07-18
ER

PT J
AU Virupakshappa
   Amarapur, B
AF Virupakshappa
   Amarapur, Basavaraj
TI Computer-aided diagnosis applied to MRI images of brain tumor using
   cognition based modified level set and optimized ANN classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Histogram equalization; Median filter; Modified level set segmentation;
   Moment invariant features; Gabor features; Grey level co-occurrence
   matrix; Artificial neural network; Whale optimization algorithm
ID SEGMENTATION; ALGORITHM
AB MRI image segmentation and classification is one of the important tasks in medical image analysis and visualization, despite occurrence of noise makes it tough to segment the region of interest. In this paper, the MRI images are pre-processed and segmentation is carried out using modified Level set method for the tumor segmentation. Also, it is important to extract the useful features to predict the image class accurately. The proposed method operates Multi-Level wavelet decomposition features and for the wavelet coefficients modified chief descriptions like Grey Level Co-Occurrence Matrix (GLCM), Gabor and moment invariant features are extracted. The classification is carried out using the Adaptive Artificial Neural Network (AANN) methodology. In the adaptive ANN, the layer neurons are optimized using Whale Optimization Algorithm (WOA). The adaptive neural network optimizes the network structure to increase the classification accuracy and thus gives better classification results of tumors based on the segmented images. The proposed method will be executed in the working platform of MATLAB and the results are compared with the previous state of the art techniques. Finally, the proposed method results in classification accuracy of 98%.
C1 [Virupakshappa] Appa Inst Engn & Technol, Dept CSE, Kalaburagi, Karnataka, India.
   [Amarapur, Basavaraj] Poojya Doddappa Appa Coll Engn, Dept E&E, Kalaburagi, Karnataka, India.
C3 Poojya Dodappa Appa College of Engineering
RP Virupakshappa (corresponding author), Appa Inst Engn & Technol, Dept CSE, Kalaburagi, Karnataka, India.
EM virupakshi.108@gmail.com; bamarapur@yahoo.com
RI Patil, Virupakshappa/AAP-1929-2021
OI Patil, Virupakshappa/0000-0002-1395-0262
CR Ahmadvand A, 2017, MULTIMED TOOLS APPL
   Anitha V, 2016, IET COMPUT VIS, V10, P9, DOI 10.1049/iet-cvi.2014.0193
   [Anonymous], 2017, PAT RECOG LETT
   [Anonymous], 2010, (IJCSE) International Journal on Computer Science and Engineering
   Arularasan AN, 2019, CLUSTER COMPUT, V22, pS4035, DOI 10.1007/s10586-018-2616-y
   Chinnasamy A, 2019, CLUSTER COMPUT, V22, P12795, DOI 10.1007/s10586-018-1760-8
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P4, DOI [10.1109/JBHI.2014.2350651, DOI 10.1109/JBHI.2014.2350651]
   Fletcher-Heath LM, 2001, ARTIF INTELL MED, V21, P43, DOI 10.1016/S0933-3657(00)00073-7
   Gupta N, 2017, SIGNAL PROCESS-IMAGE, V59, P18, DOI 10.1016/j.image.2017.05.013
   Kannan N, 2019, CLUSTER COMPUT, V22, P14709, DOI 10.1007/s10586-018-2384-8
   Liew AWC, 2003, IEEE T MED IMAGING, V22, P1063, DOI 10.1109/TMI.2003.816956
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Nayak DR, 2016, MULTIMED TOOLS APPL
   Patil PG, 2016, INT RES J ENG TECHNO, V03, P10
   Pereira S, 2016, IEEE T MED IMAGING, V35, P1240, DOI 10.1109/TMI.2016.2538465
   Selvarani P, 2019, CLUSTER COMPUT, V22, pS4007, DOI 10.1007/s10586-018-2609-x
   Sharma M, 2013, ADV INTELL SYST, V177, P329
   Suresh A, 2020, J SUPERCOMPUT, V76, P4262, DOI 10.1007/s11227-018-2302-0
   Suresh A, 2018, WIRELESS PERS COMMUN, V103, P1239, DOI 10.1007/s11277-018-5504-0
   Suresh A, 2018, MULTIMED TOOLS APPL, V77, P27075, DOI 10.1007/s11042-018-5905-9
   Suresh A., 2019, Cluster Computing, V22, P11039, DOI 10.1007/s10586-017-1293-6
   Suresh A., 2012, Journal of Computer Science, V8, P2106, DOI 10.3844/jcssp.2012.2106.2111
   Suresh A., 2012, EUR J SCI RES, V75, P591
   Tang H, 2000, COMPUT MED IMAG GRAP, V24, P349, DOI 10.1016/S0895-6111(00)00037-9
   Virupakshappa Amarapur B, 2018, COGN TECHNOL WORK
   Vishnumurthy TD, 2016, 2016 INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER AND OPTIMIZATION TECHNIQUES (ICEECCOT), P6, DOI 10.1109/ICEECCOT.2016.7955176
   Yang G., 2015, MULTIMED TOOLS APPL, P1
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang YR, 2016, J STAT MECH-THEORY E, P1, DOI 10.1088/1742-5468/2016/11/113207
   Zhu W, 2015, MULTIMED TOOLS APPL
NR 30
TC 32
Z9 33
U1 3
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3571
EP 3599
DI 10.1007/s11042-018-6176-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700025
DA 2024-07-18
ER

PT J
AU Zhang, LH
   Jia, ZH
   Koefoed, L
   Yang, J
   Kasabov, N
AF Zhang, Lanhua
   Jia, Zhenhong
   Koefoed, Lucien
   Yang, Jie
   Kasabov, Nikola
TI Remote sensing image enhancement based on the combination of adaptive
   nonlinear gain and the PLIP model in the NSST domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image enhancement; Linear stretch; PLIP; NSST; Adaptive nonlinear
   enhancement
ID HISTOGRAM EQUALIZATION; CONTOURLET TRANSFORM; WAVELET TRANSFORM; UNSHARP
   MASKING; CONTRAST; ALGORITHM
AB To enhance image detail and contrast effectively, we present a novel enhancement method for remotely sensed images. This method is based on the combination of adaptive nonlinear gain and the parameterized logarithmic image processing model (PLIP) in the nonsubsampled shearlet transform (NSST) domain. The algorithm works in several stages by deconstructing the image into low- and high-frequency components, applying different functions to each set of frequency components, and then applying further enhancement functions to the reconstructed image. The experimental results show that the proposed method performs well in terms of definition gain, the contrast improvement index (CII) and the measure of enhancement by entropy (EMEE) when compared to several state-of-the-art image enhancement algorithms, including the nonsubsampled contourlet transform (NSCT) with fuzzy field enhancement, the NSCT with unsharp masking, the feature-linking model, linking synaptic computation for image enhancement and improved fuzzy contrast in the NSST domain.
C1 [Zhang, Lanhua; Jia, Zhenhong] Xinjiang Univ, Coll Informat Sci & Engn, 666 Shengli Rd, Tianshan Dist, Urumqi, Peoples R China.
   [Koefoed, Lucien; Kasabov, Nikola] Auckland Univ Technol, Knowledge Engn & Discovery Res Inst, Auckland 92006, New Zealand.
   [Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 2-427 SEIEE Bldg,800 Dong Chun Rd, Shanghai, Peoples R China.
C3 Xinjiang University; Auckland University of Technology; Shanghai Jiao
   Tong University
RP Jia, ZH (corresponding author), Xinjiang Univ, Coll Informat Sci & Engn, 666 Shengli Rd, Tianshan Dist, Urumqi, Peoples R China.
EM jzhh9009@sohu.com
RI Yang, Jie/JCD-9867-2023; Kasabov, Nikola Kirilov/JQJ-5530-2023
OI Kasabov, Nikola/0000-0003-4433-7521
FU National Science Foundation of China [61,665,012]; International Science
   Cooperation Project of the Ministry of Education of the People's
   Republic of China [2016-2196]
FX This work was supported by the National Science Foundation of China
   (nos. 61,665,012) and the International Science Cooperation Project of
   the Ministry of Education of the People's Republic of China (2016-2196).
CR Aboshosha S, 2019, MULTIMED TOOLS APPL, V78, P18751, DOI 10.1007/s11042-018-7022-1
   AGAIAN SS, 2000, IAST INT C SIGN PROC
   Asmare MH, 2015, SIGNAL IMAGE VIDEO P, V9, P1679, DOI 10.1007/s11760-014-0626-7
   Chen S, 2016, MED BIOL ENG COMPUT, V54, P1793, DOI 10.1007/s11517-016-1469-x
   Chen ZF, 2010, PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON REGIONAL MANAGEMENT SCIENCE AND ENGINEERING, P810
   Dabeer O, 2011, IEEE T SIGNAL PROCES, V59, P1868, DOI 10.1109/TSP.2010.2101071
   DENG G, 1995, IEEE T IMAGE PROCESS, V4, P506, DOI 10.1109/83.370681
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Fu XY, 2015, IEEE GEOSCI REMOTE S, V12, P2301, DOI 10.1109/LGRS.2015.2473164
   GRANRATH DJ, 1981, P IEEE, V69, P552, DOI 10.1109/PROC.1981.12024
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   Hashemi M, 2010, IEEE SIGNAL PROC LET, V17, P12, DOI 10.1109/LSP.2009.2030856
   Hou W, 2011, IEEE IND ELEC, P2222
   Huang CX, 2014, J INDIAN SOC REMOTE, V42, P645, DOI 10.1007/s12524-013-0359-z
   Huang LD, 2015, IET IMAGE PROCESS, V9, P908, DOI 10.1049/iet-ipr.2015.0150
   Jiang Q, 2018, IEEE SENS J, V18, P2494, DOI 10.1109/JSEN.2018.2791642
   JOURLIN M, 1995, SIGNAL PROCESS, V41, P225, DOI 10.1016/0165-1684(94)00102-6
   JOURLIN M, 1988, J MICROSC-OXFORD, V149, P21, DOI 10.1111/j.1365-2818.1988.tb04559.x
   Kansal S, 2018, MULTIMED TOOLS APPL, V77, P26919, DOI 10.1007/s11042-018-5894-8
   Kaplan NH, 2018, OPTIK, V155, P139, DOI 10.1016/j.ijleo.2017.10.132
   Laine AF, 1996, P SOC PHOTO-OPT INS, V2825, P238, DOI 10.1117/12.255235
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Li LL, 2019, MULTIMED TOOLS APPL, V78, P18077, DOI 10.1007/s11042-019-7203-6
   Lin HN, 2014, OPTIK, V125, P7143, DOI 10.1016/j.ijleo.2014.07.118
   Liu L, 2017, T I MEAS CONTROL, V39, P183, DOI 10.1177/0142331215604210
   Liu XS, 2010, P SOC PHOTO-OPT INS, V7850, DOI 10.1117/12.869985
   Lu C, 2010, INT CO SIG PROC COMM
   Lv DL, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.10.103104
   Mishra N, 2000, IETE J RES, V46, P309, DOI 10.1080/03772063.2000.11416170
   Panetta K, 2011, IEEE T SYST MAN CY B, V41, P460, DOI 10.1109/TSMCB.2010.2058847
   Pu XT, 2014, CONCURR COMP-PRACT E, V26, P742, DOI 10.1002/cpe.3041
   Qian Li, 2014, Information Technology Journal, V13, P153, DOI 10.3923/itj.2014.153.158
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Singh H, 2019, MULTIMED TOOLS APPL, V78, P20431, DOI 10.1007/s11042-019-7383-0
   Suresh S, 2017, APPL SOFT COMPUT, V61, P622, DOI 10.1016/j.asoc.2017.08.019
   TANG SW, 2010, P 2010 INT FOR INF T, V1, P1, DOI DOI 10.1109/ANTHOLOGY.2013.6784750
   [陶飞翔 Tao Feixiang], 2015, [测绘学报, Acta Geodetica et Cartographica Sinica], V44, P884
   Teng L, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2902959
   TONG Y, 2017, EURASIP J WIREL 0309
   Wang LH, 2015, PLANT CELL PHYSIOL, V56, DOI 10.1093/pcp/pcu175
   Xu XJ, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P194, DOI 10.1109/SIPROCESS.2016.7888251
   Zhan K, 2017, NEUROCOMPUTING, V238, P1, DOI 10.1016/j.neucom.2017.01.031
   Zhan K, 2016, NEURAL COMPUT, V28, P1072, DOI 10.1162/NECO_a_00832
NR 43
TC 6
Z9 6
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13647
EP 13665
DI 10.1007/s11042-019-08586-x
EA FEB 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000510371400002
DA 2024-07-18
ER

PT J
AU Roy, SS
   Basu, A
   Chattopadhyay, A
AF Roy, Subhrajit Sinha
   Basu, Abhishek
   Chattopadhyay, Avik
TI On the implementation of a copyright protection scheme using digital
   image watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive; Imperceptible; LSB; Payload; Robust; Saliency; Spatial
ID SALIENCY DETECTION; ROBUST
AB In this paper, a spatial domain based digital image watermarking scheme has been developed to serve the purpose of copyright protection for digital images. This scheme proposes how to embed copyright information, i.e. the watermark bits by adaptive LSB replacement technique. Here, to improve imperceptibility, imperfect nature of human visual system has been exploited by means of saliency map generation. Robustness and data hiding capacity are also optimized by modifying the higher bit-planes instead of only the LSB. A few signal processing attacks are applied to evaluate the robustness, and several image quality metrics are involved in this purpose. The quality metrics are also used in verifying experimental results in terms of imperceptibility; and finally the system proficiency is compared to some existing frameworks. A proper benchmarking is also employed for a quantitative justification of the visual image degradation, caused by watermark insertion.
C1 [Roy, Subhrajit Sinha; Basu, Abhishek] RCC Inst Informat Technol, Elect & Commun Engn Dept, South Canal Rd, Kolkata 700015, India.
   [Roy, Subhrajit Sinha; Chattopadhyay, Avik] Univ Calcutta, Inst Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
C3 RCC Institute of Information Technology (RCCIIT); University of Calcutta
RP Roy, SS (corresponding author), RCC Inst Informat Technol, Elect & Commun Engn Dept, South Canal Rd, Kolkata 700015, India.; Roy, SS (corresponding author), Univ Calcutta, Inst Radio Phys & Elect, 92 Acharya Prafulla Chandra Rd, Kolkata 700009, India.
EM subhrajitkcs@gmail.com
RI Roy, Subhrajit Sinha/AAU-3651-2021; Basu, Abhishek/S-6016-2019
OI Basu, Abhishek/0000-0003-4167-3722
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Ghamdi M, 2019, MULTIMED TOOLS APPL, V78, P16283, DOI 10.1007/s11042-018-6977-2
   Al-Juaid N., 2018, J INF SECUR CYBERCRI, V1, P8, DOI [10.26735/16587790.2018.006, DOI 10.26735/16587790.2018.006]
   Alanizy N., 2018, J RES ENG APPL SCI J, V3, P118, DOI DOI 10.46565/JREAS.2018.V03I04.001
   [Anonymous], P INT C SIGN PROC
   [Anonymous], 2015, INT C EL EL SIGN COM
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2018, J COMPUT SCI COMPUT, DOI DOI 10.20967/JCSCM.2018.03.002
   [Anonymous], 1999, DIGITAL WATERMARKING
   [Anonymous], 2000, Digital Watermarking
   Basu A., 2011, Lecture Notes in Computer Science, V7119, P1
   Basu A, 2016, 2016 SECOND IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P269, DOI 10.1109/ICRCICN.2016.7813669
   Basu A, 2013, INF SECUR J, V22, P10, DOI 10.1080/19393555.2013.779400
   Chopra D, 2014, INT J ADV RES COMPUT, V3
   Chu YP, 2006, FIRST INTERNATIONAL MULTI-SYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS 2006), PROCEEDINGS, VOL 1, P726, DOI 10.1109/IMSCCS.2006.112
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Fan YC, 2008, CIRC SYST SIGNAL PR, V27, P763, DOI 10.1007/S00034-008-9055-6
   Foris P, 2007, RADIOENGINEERING, V16, P45
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Goyal R., 2014, Int J Appl Innov Eng Manag, V3, P15
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Gutub A, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0216-0
   Han SC, 2018, OPTOELECTRON LETT, V14, P61, DOI 10.1007/s11801-018-7212-0
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Hong W, 2012, IEEE T INF FOREN SEC, V7, P176, DOI 10.1109/TIFS.2011.2155062
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Huang JW, 1998, ELECTRON LETT, V34, P748, DOI 10.1049/el:19980545
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Kim YS, 1999, ELECTRON LETT, V35, P466, DOI 10.1049/el:19990327
   Kumar C, 2020, MULTIMED TOOLS APPL, V79, P11069, DOI 10.1007/s11042-018-6177-0
   Kutter M., 1999, ELECT IMAGING 99 SEC, P3657
   Lee HK, 2005, 2005 ASIA-PACIFIC CONFERENCE ON COMMUNICATIONS (APCC), VOLS 1& 2, P512, DOI 10.1109/APCC.2005.1554112
   Li JB, 2012, 2012 6TH INTERNATIONAL CONFERENCE ON NEW TRENDS IN INFORMATION SCIENCE, SERVICE SCIENCE AND DATA MINING (ISSDM2012), P472
   Li W, 2011, ADV INTEL SOFT COMPU, V129, P535
   Majumder S., 2011, 2011 International Conference on Recent Trends in Information Technology (ICRTIT 2011), P938, DOI 10.1109/ICRTIT.2011.5972409
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Mishra S., 2013, INT J COMPUT SCI INF, V4, P451
   Mohanty SP, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1413862.1413865
   Ni RR, 2006, INT C PATT RECOG, P934
   Niu YQ, 2011, EUR SIGNAL PR CONF, P2039
   Pareek R, 2012, INT J ENG ADV TECHNO, V1
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Shaikh S, 2013, INT J ENG ADV TECHNO, V3, P158
   Sinha Roy S, 2019, PERSPECTIVES DIGITAL
   Sinha Roy S, 2015, P FRCCD 2015, P50
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Sur A, 2009, ANNU IEEE IND CONF, P43
   Verma M., 2013, INT J ADV RES COMPUT, V2, P2913
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wong M. L. D., 2013, INT J INNOVATION MAN, V4, P228
   Wu Q, 2016, J INF SECUR APPL, V26, P1, DOI 10.1016/j.jisa.2015.08.003
   Xu H, 2010, INFORM SCIENCES, V180, P1201, DOI 10.1016/j.ins.2009.12.027
   Yang CH, 2008, PATTERN RECOGN, V41, P2674, DOI 10.1016/j.patcog.2008.01.019
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
NR 56
TC 14
Z9 15
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13125
EP 13138
DI 10.1007/s11042-020-08652-9
EA JAN 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000509343300001
DA 2024-07-18
ER

PT J
AU Li, SH
   Wang, AH
   Hong, SG
   Wu, YC
   Li, DH
   Wu, YC
   Liang, J
AF Li, Sihan
   Wang, Anhong
   Hong Shangguan
   Wu, Yingchun
   Li, Donghong
   Wu, Youcheng
   Liang, Jie
TI Super resolution of single depth image based on multi-dictionary
   learning with edge feature regularization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Super resolution reconstruction; Sparse representation; Depth image;
   Dictionary learning; Edge regularization
ID SUPERRESOLUTION; SPARSE; ALGORITHM
AB Currently, the acquisition and application of depth images are attracting a lot of attention thanks to the rapid development of 3D video. However, the current depth cameras cannot obtain high quality depth images due to the limitations in the imaging system. In this paper, to address this issue, we propose a scheme for single depth image super resolution based on multi-dictionary learning with edge regularization model. In the training stage, we focus on the edge information that represents the structure of the image, and extract the edge part, the low frequency and high frequency parts from the high resolution depth image set respectively. After that, three dictionaries are learned for the three parts with the constraint of the same sparse representation. In the image synthesis stage, we employ an edge-preserving regularization model as a reconstruction constraint to preserve the sharp structure, and reconstruct the depth image via the dictionaries learned from the training stage. Experimental results show that our proposed method can achieve good results in edge preservation, and both PSNR and SSIM values of the reconstructed depth images are superior to the state-of-art methods.
C1 [Li, Sihan; Wang, Anhong; Hong Shangguan; Wu, Yingchun; Li, Donghong; Wu, Youcheng] Taiyuan Univ Sci & Technol, Inst Digital Multimedia & Commun, Taiyuan 030024, Peoples R China.
   [Liang, Jie] Simon Fraser Univ, Engn Sci, Burnaby, BC V5A 1S6, Canada.
C3 Taiyuan University of Science & Technology; Simon Fraser University
RP Wang, AH (corresponding author), Taiyuan Univ Sci & Technol, Inst Digital Multimedia & Commun, Taiyuan 030024, Peoples R China.
EM lisihan_1993@163.com; wah_ty@163.com
RI Li, Sihan/HNS-2512-2023
OI Li, Sihan/0000-0003-2496-7147; Liang, Jie/0000-0003-3003-4343
FU National Natural Science Foundation of China [61672373, 61501315];
   Scientific and Technological Innovation Team of Shanxi Province
   [201705D131025]; Key Innovation Team of Shanxi 1331 Project [2017015];
   Collaborative Innovation Center of Internet+3D Printing in Shanxi
   Province [201708]; Program of "One hundred Talented People" of Shanxi
   Province, Shanxi Province Science Foundation for Youths [201701D221106];
   Taiyuan University of Science and Technology [20162044]
FX This work has been supported in part by National Natural Science
   Foundation of China (No.61672373 and No.61501315), Scientific and
   Technological Innovation Team of Shanxi Province (No. 201705D131025),
   Key Innovation Team of Shanxi 1331 Project(2017015), Collaborative
   Innovation Center of Internet+3D Printing in Shanxi Province(201708),
   The Program of "One hundred Talented People" of Shanxi Province, Shanxi
   Province Science Foundation for Youths (201701D221106); Taiyuan
   University of Science and Technology doctoral promoter (20162044). The
   authors thank the anonymous reviewers for their valuable comments and
   suggestions to improve the quality of this paper.
CR Aafaque A, 2016, RTIP2R319332, P319
   [Anonymous], 2012, INT C INT MULT COMP
   [Anonymous], 2014, LUC GOOLA ADJUSTED A
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Coates Adam, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P561, DOI 10.1007/978-3-642-35289-8_30
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Dong Y, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.4.043004
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gui ZG, 2012, IEEE T NUCL SCI, V59, P1984, DOI 10.1109/TNS.2012.2198495
   Ha S, 2015, PHYS MED BIOL, V60, P869, DOI 10.1088/0031-9155/60/2/869
   Han JW, 2010, IEEE T CONSUM ELECTR, V56, P175, DOI 10.1109/TCE.2010.5439142
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Köhler T, 2015, LECT NOTES COMPUT SC, V9358, P91, DOI 10.1007/978-3-319-24947-6_8
   Lee C, 1998, IEEE T IMAGE PROCESS, V7, P679, DOI 10.1109/83.668025
   Li CG, 2017, MACH VISION APPL, V28, P1, DOI 10.1007/s00138-016-0796-0
   Li SQ, 2017, COMPUT BIOL MED, V84, P156, DOI 10.1016/j.compbiomed.2017.03.017
   Pati YC, 1993, SIGN SYST COMP 1993, P40, DOI DOI 10.1109/ACSSC.1993.342465
   Peleg T, 2014, STAT PREDICTION MODE
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Santosh KC, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417570038
   Santosh KC, 2016, INT J COMPUT ASS RAD, V11, P1637, DOI 10.1007/s11548-016-1359-6
   Santosh KC, 2015, COMP MED SY, P360, DOI 10.1109/CBMS.2015.50
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tronicke J., 2013, 2013 7 INT WORKSHOP, P1, DOI DOI 10.1109/IWAGPR.2013.6601539
   Wang R, 2016, INT S NEUR NETW
   Xie J, 2015, P IEEE INT C E-SCI, P237, DOI 10.1109/eScience.2015.47
   Xiong ZW, 2013, IEEE T MULTIMEDIA, V15, P1458, DOI 10.1109/TMM.2013.2264654
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang SY, 2014, IEEE T IMAGE PROCESS, V23, P2793, DOI 10.1109/TIP.2014.2319742
   Yanjie Li, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P152, DOI 10.1109/ICME.2012.30
   Yuxiang Yang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P163, DOI 10.1109/ICIG.2011.79
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang A, 2016, INT SOC OPTICS PHOTO, p97843O
   Zhang J, 2012, IEEE INT SYMP CIRC S, P1688
   Zhang YB, 2016, IEEE T MULTIMEDIA, V18, P405, DOI 10.1109/TMM.2015.2512046
   Zhang YL, 2015, LECT NOTES COMPUT SC, V9315, P63, DOI 10.1007/978-3-319-24078-7_7
   Zhao LJ, 2017, IEEE INT CON MULTI, P739, DOI 10.1109/ICME.2017.8019331
   Zheng H, 2013, IEEE IMAGE PROC, P957, DOI 10.1109/ICIP.2013.6738198
   Zohora Fatema Tuz, 2017, International Journal of Computer Vision and Image Processing, V7, P36, DOI 10.4018/IJCVIP.2017040103
NR 43
TC 3
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 34813
EP 34834
DI 10.1007/s11042-019-08500-5
EA JAN 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000574100600001
DA 2024-07-18
ER

PT J
AU Chanukya, PSVVN
   Thivakaran, TK
AF Chanukya, Padira S. V. V. N.
   Thivakaran, T. K.
TI Multimodal biometric cryptosystem for human authentication using
   fingerprint and ear
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Preprocessing; Classification; Median filter; Firefly; Mismatched
ID SCORE LEVEL FUSION; FACE
AB The multimodal biometrics is mainly used for the purpose of person certification and proof. Lot of biometrics is used for human authentication. In which ear and fingerprint are efficient one. There are three vital phases involved in the biometric detection which include the Preprocessing, Feature extraction and the classification. Initially, preprocessing is done with the help of median filter which lends a helping hand to the task of cropping the image for choosing the position. Then, from the preprocessed Finger print and ear image texture and shape features are extracted. In the long run, the extracted features are integrated. The integrated features, in turn, are proficiently classified by means of the optimal neural network (ONN). Here, the NN weights are optimally, selected with the help of firefly algorithm (FF). The biometric image is classified into fingerprint and ear if the identical person images are amassed in one group and the uneven images are stored in a different group. The performance of the proposed approach is analyzed in terms of evaluation metrics.
C1 [Chanukya, Padira S. V. V. N.] Meenakshi Acad Higher Educ & Res MAHER Univ, Dept Elect & Commun Engn, Chennai 600078, Tamil Nadu, India.
   [Thivakaran, T. K.] Presedency Univ, Dept Comp Sci & Engn, Yelahanka 560064, Bengaluru, India.
C3 Meenakshi Academy of Higher Education & Research (MAHER); Presidency
   University, Bangalore
RP Chanukya, PSVVN (corresponding author), Meenakshi Acad Higher Educ & Res MAHER Univ, Dept Elect & Commun Engn, Chennai 600078, Tamil Nadu, India.
EM padirasvvnchanukya0888@gmail.com
OI padira, s v v n chanukya/0000-0002-5496-2809
CR [Anonymous], 2006, 9 INT C CONTR AUT RO, DOI DOI 10.1109/ICARCV.2006.345473
   Basha A.J., 2010, 2010 IEEE INT C COMP, P1, DOI [10.1109/ICCIC.2010.5705857, DOI 10.1109/ICCIC.2010.5705857]
   Chan TS, 2012, PATTERN RECOGN LETT, V33, P1870, DOI 10.1016/j.patrec.2011.11.013
   Chin YJ, 2011, C IND ELECT APPL, P1971, DOI 10.1109/ICIEA.2011.5975915
   Choi H, 2009, 2009 FIRST ASIAN CONFERENCE ON INTELLIGENT INFORMATION AND DATABASE SYSTEMS, P346, DOI 10.1109/ACIIDS.2009.49
   Dahel SK, 2003, IEEE SYSTEMS, MAN AND CYBERNETICS SOCIETY INFORMATION ASSURANCE WORKSHOP, P170, DOI 10.1109/SMCSIA.2003.1232417
   Hanmandlu M, 2011, PATTERN RECOGN LETT, V32, P1843, DOI 10.1016/j.patrec.2011.06.029
   He MX, 2010, PATTERN RECOGN, V43, P1789, DOI 10.1016/j.patcog.2009.11.018
   Huang H, 2011, NEUROCOMPUTING, V74, P3103, DOI 10.1016/j.neucom.2011.04.022
   Huang ZX, 2013, PATTERN RECOGN, V46, P2156, DOI 10.1016/j.patcog.2013.01.022
   Islam SMS, 2013, PATTERN RECOGN, V46, P613, DOI 10.1016/j.patcog.2012.09.016
   Khan MK, 2008, NEUROCOMPUTING, V71, P3026, DOI 10.1016/j.neucom.2007.12.017
   Kumar A, 2013, PATTERN RECOGN, V46, P73, DOI 10.1016/j.patcog.2012.06.020
   Madhavi, 2007, HDB BIOMETRICS
   Maple C, 2006, FIRST INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY, PROCEEDINGS, P929, DOI 10.1109/ARES.2006.141
   Monwar MM, 2009, IEEE T SYST MAN CY B, V39, P867, DOI 10.1109/TSMCB.2008.2009071
   Nadir Z, 2010, LECT NOTES ENG COMP, P804
   Pflug A, 2012, IET BIOMETRICS, V1, P114, DOI 10.1049/iet-bmt.2011.0003
   Raghavendra R., 2010, Proceedings of the Third International Conference on Emerging Trends in Engineering and Technology (ICETET 2010), P526, DOI 10.1109/ICETET.2010.14
   Rahman M., 2007, INT J COMPUTER INTER, V15, P1
   Ross Arun, 2004, 2004 12th European Signal Processing Conference (EUSIPCO), P1221
   Ross A, 2011, COMPUTER, V44, P79, DOI 10.1109/MC.2011.344
   Seal A., 2011, 2011 International Conference on Image Information Processing, P1, DOI DOI 10.1109/ICIIP.2011.6108928
   Semwal VB, 2014, ROBOT AUTON SYST
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal Vijay Bhaskar, 2018, MACH INTELL, P135
   Yang J, 2010, INT CONF ACOUST SPEE, P4046, DOI 10.1109/ICASSP.2010.5495761
   Yaoa Y-F, 2007, NEUROCOMPUTING, V9
   Yuan L, 2012, PATTERN RECOGN LETT, V33, P182, DOI 10.1016/j.patrec.2011.09.041
NR 29
TC 22
Z9 22
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 659
EP 673
DI 10.1007/s11042-019-08123-w
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600026
DA 2024-07-18
ER

PT J
AU Luo, AW
   Gong, LH
   Zhou, NR
   Zou, WP
AF Luo, An-Wei
   Gong, Li-Hua
   Zhou, Nan-Run
   Zou, Wei-Ping
TI Adaptive and blind watermarking scheme based on optimal SVD blocks
   selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Singular value decomposition; Information entropy; Optimal SVD blocks
   selection strategy; Adaptive watermarking scheme
ID DIGITAL IMAGE WATERMARKING; COLOR IMAGES; ROBUST; DCT; DOMAIN
AB To protect the ownership of the digital products, a novel adaptive and blind watermarking scheme is designed. Firstly, the underlying reason of image quality degradation in singular value decomposition (SVD)-based watermarking scheme is analyzed and the potential scenario causing visible destroy is pointed out. Then the optimal SVD blocks selection strategy is proposed to improve the imperceptibility. Different from other block selection rules devised by subjective evaluation means, our selection rule aims to retain the image quality as much as possible from the source. Furthermore, information entropy is utilized to achieve the purpose of adaptive embedding. In the experiment, the proposed watermarking scheme is tested under several attacks, such as noise attack, JPEG compression, blurring, sharping, and etc. Finally, the proposed watermarking scheme is compared with other existing schemes, and the experimental results demonstrate the robustness, imperceptibility and superior of the proposed watermarking scheme.
C1 [Luo, An-Wei; Gong, Li-Hua; Zhou, Nan-Run] Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
   [Zou, Wei-Ping] Univ Poitiers, XLIM UMR CNRS 7252, Poitiers, France.
C3 Nanchang University; Centre National de la Recherche Scientifique
   (CNRS); Universite de Poitiers
RP Zhou, NR (corresponding author), Nanchang Univ, Dept Elect Informat Engn, Nanchang 330031, Jiangxi, Peoples R China.
EM nrzhou@ncu.edu.cn
RI Zhou, Nanrun/HGC-4650-2022
OI ZHOU, Nanrun/0000-0002-5080-2189
FU National Natural Science Foundation of China [61861029, 61462061];
   Department of Human Resources and Social security of Jiangxi Province;
   Major Academic Discipline and Technical Leader of Jiangxi Province
   [20162BCB22011]; Natural Science Foundation of Jiangxi Province
   [20171BAB202002]; Cultivation Plan of Applied Research of Jiangxi
   Province [20181BBE58022]
FX This work is supported by the National Natural Science Foundation of
   China (Grant Nos. 61861029 and 61462061), the Department of Human
   Resources and Social security of Jiangxi Province, the Major Academic
   Discipline and Technical Leader of Jiangxi Province (Grant No.
   20162BCB22011), the Natural Science Foundation of Jiangxi Province
   (Grant No. 20171BAB202002), and the Cultivation Plan of Applied Research
   of Jiangxi Province (Grant no. 20181BBE58022).
CR Abdallah EE, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2764466
   Abuturab MR, 2015, J OPT SOC AM A, V32, P1811, DOI 10.1364/JOSAA.32.001811
   Al-Otum HM, 2010, SIGNAL PROCESS, V90, P2498, DOI 10.1016/j.sigpro.2010.02.017
   [Anonymous], 2016 INT C INF TECHN
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chang CS, 2017, IEEE T IMAGE PROCESS, V26, P3921, DOI 10.1109/TIP.2017.2706502
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Chen L, 2017, SIGNAL PROCESS-IMAGE, V54, P56, DOI 10.1016/j.image.2017.02.011
   Chung KL, 2007, APPL MATH COMPUT, V188, P54, DOI 10.1016/j.amc.2006.09.117
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Esgandari R, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P988, DOI 10.1109/KBEI.2015.7436179
   Fan MQ, 2008, APPL MATH COMPUT, V203, P926, DOI 10.1016/j.amc.2008.05.003
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Horng SJ, 2014, MULTIMED TOOLS APPL, V72, P3085, DOI 10.1007/s11042-013-1579-5
   Horng SJ, 2013, J VIS COMMUN IMAGE R, V24, P1099, DOI 10.1016/j.jvcir.2013.07.008
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Kakarala R, 2001, IEEE T IMAGE PROCESS, V10, P724, DOI 10.1109/83.918566
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kumar S, 2016, INT CONF RECENT
   Lee Y, 2011, COMM COM INF SC, V263, P139
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Pei SC, 2015, IEEE T SIGNAL PROCES, V63, P4207, DOI 10.1109/TSP.2015.2437845
   Prasetyo H, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTER, CONTROL, INFORMATICS AND ITS APPLICATIONS (IC3INA), P181, DOI 10.1109/IC3INA.2018.8629513
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Run RS, 2012, EXPERT SYST APPL, V39, P673, DOI 10.1016/j.eswa.2011.07.059
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Su QT, 2018, MULTIDIM SYST SIGN P, V29, P1055, DOI 10.1007/s11045-017-0487-7
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, AEU-INT J ELECTRON C, V67, P652, DOI 10.1016/j.aeue.2013.01.009
   Vaidya SP, 2018, MULTIMED TOOLS APPL, V77, P5609, DOI 10.1007/s11042-017-4476-5
   Weng SW, 2019, INFORM SCIENCES, V489, P136, DOI 10.1016/j.ins.2019.03.032
   Weng SW, 2019, IEEE ACCESS, V7, P34570, DOI 10.1109/ACCESS.2019.2904174
   Weng SW, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010049
NR 39
TC 33
Z9 34
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 243
EP 261
DI 10.1007/s11042-019-08074-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600011
DA 2024-07-18
ER

PT J
AU Zhao, ZQ
   Xiong, LW
   Mei, ZL
   Wu, B
   Cui, ZM
   Wang, TJ
   Zhao, ZJ
AF Zhao, Zhiqiang
   Xiong, Liwen
   Mei, Zhuolin
   Wu, Bin
   Cui, Zongmin
   Wang, Tianjiang
   Zhao, Zhijian
TI Robust object tracking based on ridge regression and multi-scale local
   sparse coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Ridge regression; Correlation filtering; Sparse coding;
   Particle filtering
ID APPEARANCE MODEL; VISUAL TRACKING
AB Recently, the technology of visual object tracking has achieved great success. However, it is still extraordinary challenging for some factors, such as scale variations, partial occlusions and so on. To deal with the problem of scale variations of the target, this paper proposes a hybrid tracking algorithm based on ridge regression and multi-scale local sparse coding. The hybrid tracking algorithm contains three parts. Firstly, a discriminative model based on two ridge regression models which include a correlation filtering ridge regression model and a color statistics ridge regression model, is used to estimate the approximate position of the target. Secondly, a multi-scale local sparse coding with particle filtering model, which combines local overlapped patches and local non-overlapped patches, is used to estimate the precise position and scale variations of the target. Thirdly, the appearance model of the target in the discriminative model based on ridge regression is updated according to the precise position and scale variations of the target in the second part. At the end, extensive experiments verify the effectiveness of the hybrid tracking algorithm in dealing with scale variations of the target.
C1 [Zhao, Zhiqiang; Xiong, Liwen; Mei, Zhuolin; Wu, Bin; Cui, Zongmin] Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Jiangxi, Peoples R China.
   [Wang, Tianjiang] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Intelligent & Distributed Comp Lab, Wuhan 430074, Peoples R China.
   [Zhao, Zhijian] Hunan Univ, Sch Business, Changsha 410006, Hunan, Peoples R China.
C3 Jiujiang University; Huazhong University of Science & Technology; Hunan
   University
RP Zhao, ZQ (corresponding author), Jiujiang Univ, Sch Informat Sci & Technol, Jiujiang 332005, Jiangxi, Peoples R China.
EM zqzhao2000@foxmail.com; xlwxiong@163.com; meizhuolin@126.com;
   wubincs@gmail.com; cuizm01@gmail.com; tjwang@hust.edu.cn;
   zzj0827@foxmail.com
OI Zhiqiang, Zhao/0000-0001-6627-9807
FU Science and Technology Research Project of Jiangxi Education Department
   [GJJ180904]; National Natural Science Foundation of China [61762055,
   61962029, 61572214]; Jiangxi Provincial Natural Science Foundation of
   China [20181BAB202014]; Humanities and Social Sciences Foundation of
   Colleges and Universities in Jiangxi Province [TQ18111]
FX Thank the editor and the anonymous referees for their valuable comments.
   This research was supported by the Science and Technology Research
   Project of Jiangxi Education Department (No. GJJ180904), the National
   Natural Science Foundation of China (No. 61762055, 61962029 and
   61572214), the Jiangxi Provincial Natural Science Foundation of China
   (No. 20181BAB202014) and the Humanities and Social Sciences Foundation
   of Colleges and Universities in Jiangxi Province (No. TQ18111).
CR [Anonymous], 2016, CVPR
   [Anonymous], NEUROCOMPUTING
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristensen J, 2014, IEEE INT CONF ELECT
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Mueller M., 2016, BENCHMARK SIMULATOR, P445, DOI 10.1007/978-3-319-46448-0_27
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Ning Jifeng, 2016, COMPUTER VISION PATT
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Triggs ND, 2005, COMPUTER VISION PATT
   Vojir T, 2014, PATTERN RECOGN LETT, V49, P250, DOI 10.1016/j.patrec.2014.03.025
   Wang C, 2018, KERNEL CROSS CORRELA
   Wang D, 2012, INT J IMAGE GRAPH, V12, DOI 10.1142/S0219467812500210
   Wang D, 2014, PROC CVPR IEEE, P3478, DOI 10.1109/CVPR.2014.445
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xiao ZY, 2012, INT C PATT RECOG, P1351
   Xie CJ, 2014, MACH VISION APPL, V25, P1859, DOI 10.1007/s00138-014-0632-3
   Yong H, 2017, IEEE T PATTERN ANAL, V99, P1
   Zarezade A, 2014, IEEE T IMAGE PROCESS, V23, P4496, DOI 10.1109/TIP.2014.2346029
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhao ZQ, 2017, NEUROCOMPUTING, V237, P101, DOI 10.1016/j.neucom.2016.09.031
   Zhong W, 2014, IEEE T IMAGE PROCESS, V23, P2356, DOI 10.1109/TIP.2014.2313227
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zuo W., 2018, IEEE T PATTERN ANAL
NR 48
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 785
EP 804
DI 10.1007/s11042-019-08139-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000517987600032
DA 2024-07-18
ER

PT J
AU Meng, DM
   Meng, CM
   Macleod, M
AF Meng, Dongmei
   Meng, Chunming
   Macleod, Michelle
TI Multimedia web-based intervention and implementation of motivational
   factors in incentive strategies on learning motivation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia web-based intervention; Second language acquisition (SLA);
   Incentive strategies; Incentive intervention
AB Learning motivation is the most dynamic factor among the individual factors of language learners and the driving force of foreign language learning. This paper attempts to explore the multimedia web-based intervention mechanism of incentive strategies in the process of second language acquisition (SLA) through four aspects of factors affecting foreign language learning motivation, including cognition, emotion, social environment and learners' characteristics, in order to improve the affective disorder in language learning and transform the SLA from static into multi-level dynamic learning activity, so as to improve the learning effect. The study implemented the experiment and evaluated its results. The results indicate that the intervention of motivational factors in second language acquisition has positive effect on learners' acquisition of English.
C1 [Meng, Dongmei] East China Jiaotong Univ, Sch Foreign Languages, Res Ctr Appl Translat Transportat & Engn, Nanchang 330013, Jiangxi, Peoples R China.
   [Meng, Chunming] Jiangxi Coll Foreign Studies, Nanchang 330000, Jiangxi, Peoples R China.
   [Macleod, Michelle] Univ Aberdeen, Sch Language Literature Mus & Visual, Aberdeen AB24 3UD, Scotland.
C3 East China Jiaotong University; University of Aberdeen
RP Meng, DM (corresponding author), East China Jiaotong Univ, Sch Foreign Languages, Res Ctr Appl Translat Transportat & Engn, Nanchang 330013, Jiangxi, Peoples R China.
EM 1971@ecjtu.edu.cn; 851947881@qq.com; m.macleod@abdn.ac.uk
RI meng, meng/KHW-8303-2024
OI Macleod, Michelle/0000-0002-6573-7447
FU Fund Project of the Postgraduate Teaching Reform Project in Jiangxi
   [JXYJG-2017083]; Chinese Scholarship Council (CSC)
FX The Fund Project of the Postgraduate Teaching Reform Project in Jiangxi
   (JXYJG-2017083).; This research is also funded by the Chinese
   Scholarship Council (CSC).
CR Al-Huneidi A.M., 2012, International Journal of Emerging Technologies in Learning, V7, P4, DOI DOI 10.3991/IJET.V7I1.1792
   Bloom BS, 1964, HUMAN CHARACTERISTIC
   Brown H.D., 1994, TEACHING PRINCIPLES
   Gao Yi-Hong, 2002, FOREIGN LANGUAGE TEA, V4, P18
   Keller J., 1983, INSTRUCTIONAL DESIGN, P383
   Littlewood W., 2002, COMMUNICATIVE LANGUA
   Meng D, 2013, MOTIVATIONAL INSTRUC
   Meng D, 2015, COMPUTER ASSISTED FO, P50
   OXFORD R, 1994, MOD LANG J, V78, P12, DOI 10.2307/329249
   Scardamalia M, 2000, ICCE ICCAI 2000 C LE
   Spitzer DR, 1999, HDB HUMAN PERFORMANC
   Suhail NA, 2010, LFIP ADV INFORM COMM, P166
   Thoms B, 2015, EDUC INF TECHNOL, V20, P265, DOI 10.1007/s10639-013-9279-3
   Tuzun H., 2004, MOTIVATING LEARNERS
   Wang Zhenping., 1991, ASIA MAJOR, V4, P7
   WEINER B, 1979, J EDUC PSYCHOL, V71, P3, DOI 10.1037/0022-0663.71.1.3
   Wen Qiufang, 2001, FOREIGN LANGUAGE TEA, V2, P105
NR 17
TC 0
Z9 1
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10915
EP 10933
DI 10.1007/s11042-019-07972-9
EA DEC 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000504481500002
DA 2024-07-18
ER

PT J
AU Bruder, V
   Ben Lahmar, H
   Hlawatsch, M
   Frey, S
   Burch, M
   Weiskopf, D
   Herschel, M
   Ertl, T
AF Bruder, Valentin
   Ben Lahmar, Houssem
   Hlawatsch, Marcel
   Frey, Steffen
   Burch, Michael
   Weiskopf, Daniel
   Herschel, Melanie
   Ertl, Thomas
TI Volume-based large dynamic graph analysis supported by evolution
   provenance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic graphs; Volume rendering; Evolution provenance; Visual analytics
ID VISUALIZATION; TIME; SEQUENCE
AB We present an approach for the visualization and interactive analysis of dynamic graphs that contain a large number of time steps. A specific focus is put on the support of analyzing temporal aspects in the data. Central to our approach is a static, volumetric representation of the dynamic graph based on the concept of space-time cubes that we create by stacking the adjacency matrices of all time steps. The use of GPU-accelerated volume rendering techniques allows us to render this representation interactively. We identified four classes of analytics methods as being important for the analysis of large and complex graph data, which we discuss in detail: data views, aggregation and filtering, comparison, and evolution provenance. Implementations of the respective methods are presented in an integrated application, enabling interactive exploration and analysis of large graphs. We demonstrate the applicability, usefulness, and scalability of our approach by presenting two examples for analyzing dynamic graphs. Furthermore, we let visualization experts evaluate our analytics approach.
C1 [Bruder, Valentin; Ben Lahmar, Houssem; Hlawatsch, Marcel; Frey, Steffen; Weiskopf, Daniel; Herschel, Melanie; Ertl, Thomas] Univ Stuttgart, Stuttgart, Germany.
   [Burch, Michael] Eindhoven Univ Technol, Eindhoven, Netherlands.
C3 University of Stuttgart; Eindhoven University of Technology
RP Bruder, V (corresponding author), Univ Stuttgart, Stuttgart, Germany.
EM valentin.bruder@visus.uni-stuttgart.de
OI Bruder, Valentin/0000-0001-5063-4894
FU Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
   [SFB/Transregio 161, 251654672]
FX We would like to thank the Deutsche Forschungsgemeinschaft (DFG, German
   Research Foundation) for support within Projects A02, B01, and D03 of
   SFB/Transregio 161 (project number 251654672).
CR Abdelaal M, 2018, VISION MODELING VISU
   Amanatides John, 1987, P EUROGRAPHICS, P3
   [Anonymous], 2009, FINDING GROUPS DATA
   Archambault D, 2011, IEEE T VIS COMPUT GR, V17, P539, DOI 10.1109/TVCG.2010.78
   Bach B, 2017, COMPUT GRAPH FORUM, V36, P36, DOI 10.1111/cgf.12804
   Bach B, 2015, COMPUT GRAPH FORUM, V34, P31, DOI 10.1111/cgf.12615
   Bach B, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P877, DOI 10.1145/2556288.2557010
   BALABANIAN JP, 2008, P 4 INT S 3D DAT PRO, P81
   Beck F, 2017, COMPUT GRAPH FORUM, V36, P133, DOI 10.1111/cgf.12791
   Beck F, 2012, S VIS LANG HUM CEN C, P185, DOI 10.1109/VLHCC.2012.6344514
   Behrisch M, 2016, COMPUT GRAPH FORUM, V35, P693, DOI 10.1111/cgf.12935
   Ben Lahmar H., 2018, P INT C EXT DAT TECH, P686
   Ben Lahmar H, 2017, WORKSH THEOR PRACT P
   Bruder V, 2018, IEEE INT CON INF VIS, P210, DOI 10.1109/iV.2018.00045
   Burch M, 2017, COMPUT GRAPH FORUM, V36, P261, DOI 10.1111/cgf.13185
   Burch Michael, 2013, 2013 17th International Conference on Information Visualisation, P66, DOI 10.1109/IV.2013.8
   Burch M, 2011, IEEE T VIS COMPUT GR, V17, P2344, DOI 10.1109/TVCG.2011.226
   Callahan StevenP., 2006, SIGMOD
   Cuthill E., 1969, P 1969 24 NAT C, P157, DOI [10.1145/800195.805928, DOI 10.1145/800195.805928]
   Ellkvist T, 2008, USING PROVENANCE SUP, P266
   Frey S, 2012, IEEE T VIS COMPUT GR, V18, P2023, DOI 10.1109/TVCG.2012.284
   Ghoniem M., 2005, Information Visualization, V4, P114, DOI 10.1057/palgrave.ivs.9500092
   Gratzl S, 2016, COMPUT GRAPH FORUM, V35, P491, DOI 10.1111/cgf.12925
   Hadwiger M, 2008, ACM SIGGRAPH ASIA CO
   Herschel M, 2017, VLDB J, V26, P881, DOI 10.1007/s00778-017-0486-1
   Hlawatsch M, 2014, IEEE T VIS COMPUT GR, V20, P1590, DOI 10.1109/TVCG.2014.2322594
   King I. P., 1970, International Journal for Numerical Methods in Engineering, V2, P523, DOI 10.1002/nme.1620020406
   Milo T, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2137, DOI 10.1145/2882903.2899392
   MISUE K, 1995, J VISUAL LANG COMPUT, V6, P183, DOI 10.1006/jvlc.1995.1010
   Perer Adam, 2012, AMIA Annu Symp Proc, V2012, P716
   Schneider T, 2016, 2016 IEEE WORKING CONFERENCE ON SOFTWARE VISUALIZATION, P116, DOI 10.1109/VISSOFT.2016.17
   Siek JG, 2001, PORTABLE DOCUMENTS P
   SLOAN SW, 1986, INT J NUMER METH ENG, V23, P239, DOI 10.1002/nme.1620230208
   Stegmaier S, 2005, VOLUME GRAPHICS 2005, P187
   Tversky B, 2002, INT J HUM-COMPUT ST, V57, P247, DOI 10.1006/ijhc.1017
   van den Elzen S, 2016, IEEE T VIS COMPUT GR, V22, P1, DOI 10.1109/TVCG.2015.2468078
   van den Elzen S, 2014, IEEE T VIS COMPUT GR, V20, P1087, DOI 10.1109/TVCG.2013.263
   von Landesberger T, 2011, COMPUT GRAPH FORUM, V30, P1719, DOI 10.1111/j.1467-8659.2011.01898.x
   Woodring J., 2003, P 2003 EUROGRAPHICSI, P27, DOI DOI 10.1145/827051.827054
   Woodring J, 2006, IEEE T VIS COMPUT GR, V12, P909, DOI 10.1109/TVCG.2006.164
   Yi JS, 2010, INT J HUM-COMPUT INT, V26, P1031, DOI 10.1080/10447318.2010.516722
NR 41
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32939
EP 32965
DI 10.1007/s11042-019-07878-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600016
DA 2024-07-18
ER

PT J
AU Chakraborty, R
   Sushil, R
   Garg, ML
AF Chakraborty, Rupak
   Sushil, Rama
   Garg, M. L.
TI Hyper-spectral image segmentation using an improved PSO aided with
   multilevel fuzzy entropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Improved particle swarm optimization (IPSO); Multilevel-thresholding;
   Hyper-spectral imageries; Fuzzy entropy; Support vector machine (SVM);
   Composite kernel
ID PARTICLE SWARM OPTIMIZATION; MINIMUM CROSS-ENTROPY; THRESHOLD SELECTION
   METHOD; CUCKOO SEARCH ALGORITHM; GLOBAL OPTIMIZATION; CLASSIFICATION;
   DESIGN; SYSTEM; KAPURS
AB This paper proposes a novel histogram-based multi-level segmentation scheme of hyper-spectral images. In the proposed scheme an Improved Particle Swarm Optimization (IPSO) algorithm is implemented as a nature-inspired evolutionary algorithm to overcome the drawback of premature convergence and hence getting stuck in local optima problem of PSO. The high-dimension of PSO is decomposed into several one-dimensional problems and premature convergence is removed from each one-dimensional problem. This algorithm is further extended for replacing the worst particles by the fittest particles, determined by their fitness values. Multiple optimal threshold values have been evaluated based on fuzzy-entropy aided with the proposed algorithm. The performance of the IPSO is compared statistically with other global optimization algorithms namely Cuckoo Search (CS), Differential Evolution (DE), FireFly (FF), Genetic Algorithm (GA), and PSO. The produced segmented output of IPSO-fuzzy is then combined with the available ground truth values of image classes to train a Support Vector Machine (SVM) classifier via the composite kernel approach to improving the classification accuracy. This hybrid approach (IPSO-SVM) is then applied to popular hyper-spectral imageries acquired by AVRIS and ROSIS sensors. The final evaluated outcomes of the proposed scheme are also qualitatively compared to show its effectiveness over the other state-of-art global optimizers.
C1 [Chakraborty, Rupak] Bennett Univ, Dept Comp Sci & Engn, Greater Noida, India.
   [Sushil, Rama] DIT Univ, Dept Informat Technol, Dehra Dun, India.
   [Garg, M. L.] DIT Univ, Dept Comp Sci & Engn, Dehra Dun, India.
C3 DIT University; DIT University
RP Chakraborty, R (corresponding author), Bennett Univ, Dept Comp Sci & Engn, Greater Noida, India.
EM rupak.jis@gmail.com; rama.sushil@dituniversity.edu.in;
   dr.ml.garg@dituniversity.edu.in
RI Sushil, Rama/AAR-5272-2020; Chakraborty, Rupak/AAA-4734-2020;
   Chakraborty, Rupak/GLN-8156-2022
OI Chakraborty, Rupak/0000-0002-2900-5863; Sushil, Rama/0000-0001-9006-2982
CR Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Akay B, 2013, APPL SOFT COMPUT, V13, P3066, DOI 10.1016/j.asoc.2012.03.072
   [Anonymous], 2008, ARXIV08023424
   [Anonymous], ALEXANDRIA ENG J
   Arifin AZ, 2006, PATTERN RECOGN LETT, V27, P1515, DOI 10.1016/j.patrec.2006.02.022
   Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Baskar S, 2005, IEE P-MICROW ANTEN P, V152, P340, DOI 10.1049/ip-map:20045087
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Boskovitz V, 2002, IEEE T FUZZY SYST, V10, P247, DOI 10.1109/91.995125
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Cao L, 2008, IMAGE VISION COMPUT, V26, P716, DOI 10.1016/j.imavis.2007.08.007
   Chander A, 2011, EXPERT SYST APPL, V38, P4998, DOI 10.1016/j.eswa.2010.09.151
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Dong LJ, 2008, PATTERN RECOGN LETT, V29, P1311, DOI 10.1016/j.patrec.2008.02.001
   Fauvel M, 2013, P IEEE, V101, P652, DOI 10.1109/JPROC.2012.2197589
   Frattini F, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON SOFTWARE RELIABILITY ENGINEERING WORKSHOPS (ISSREW), P383, DOI 10.1109/ISSREW.2014.57
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Ghamisi P, 2014, IEEE T GEOSCI REMOTE, V52, P2382, DOI 10.1109/TGRS.2013.2260552
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Hammouche K, 2010, ENG APPL ARTIF INTEL, V23, P676, DOI 10.1016/j.engappai.2009.09.011
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karaboga D, 2014, ARTIF INTELL REV, V42, P21, DOI 10.1007/s10462-012-9328-0
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Kurugollu F, 2001, IMAGE VISION COMPUT, V19, P915, DOI 10.1016/S0262-8856(01)00052-X
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Li J, 2013, IEEE T GEOSCI REMOTE, V51, P4816, DOI 10.1109/TGRS.2012.2230268
   Li J, 2012, IEEE T GEOSCI REMOTE, V50, P809, DOI 10.1109/TGRS.2011.2162649
   Li L, 2018, NEUROCOMPUTING, V275, P1725, DOI 10.1016/j.neucom.2017.09.004
   Li W, 2018, IEEE GEOSC REM SEN M, V6, P15, DOI 10.1109/MGRS.2018.2793873
   Li W, 2017, IEEE T GEOSCI REMOTE, V55, P844, DOI 10.1109/TGRS.2016.2616355
   Liang JJ, 2006, IEEE T EVOLUT COMPUT, V10, P281, DOI 10.1109/TEVC.2005.857610
   Mughees A, 2016, 2016 55TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1466, DOI 10.1109/SICE.2016.7749195
   Mukhopadhyay S, 2012, EXPERT SYST APPL, V39, P917, DOI 10.1016/j.eswa.2011.07.089
   Nayak DR, 2018, NEUROCOMPUTING, V282, P232, DOI 10.1016/j.neucom.2017.12.030
   Önüt S, 2008, COMPUT IND ENG, V54, P783, DOI 10.1016/j.cie.2007.10.012
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pal NR, 1996, PATTERN RECOGN, V29, P575, DOI 10.1016/0031-3203(95)00111-5
   Pare S, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P730, DOI 10.1109/ICDSP.2015.7251972
   Pare S, 2017, COMPUTERS ELECT ENG
   PEREZ A, 1987, IEEE T PATTERN ANAL, V9, P742, DOI 10.1109/TPAMI.1987.4767981
   Peters J, 2017, ADAPT COMPUT MACH LE
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI 10.1109/tevc.2004.826071
   Revol C, 1997, PATTERN RECOGN LETT, V18, P249, DOI 10.1016/S0167-8655(97)00012-3
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   Sarkar S, 2016, EXPERT SYST APPL, V50, P120, DOI 10.1016/j.eswa.2015.11.016
   Sarkar S, 2015, PATTERN RECOGN LETT, V54, P27, DOI 10.1016/j.patrec.2014.11.009
   Sathya P. D., 2010, International Journal of Computer Applications, V5, P39, DOI [10.5120/903-1279, DOI 10.5120/903-1279]
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Sezgin M, 2000, PATTERN RECOGN LETT, V21, P151, DOI 10.1016/S0167-8655(99)00142-7
   Suresh S, 2016, EXPERT SYST APPL, V58, P184, DOI 10.1016/j.eswa.2016.03.032
   Tarabalka Y, 2010, PATTERN RECOGN, V43, P2367, DOI 10.1016/j.patcog.2010.01.016
   Toksöz MA, 2016, IET COMPUT VIS, V10, P433, DOI 10.1049/iet-cvi.2015.0077
   Toksöz MA, 2016, IEEE T GEOSCI REMOTE, V54, P4039, DOI 10.1109/TGRS.2016.2535458
   van den Bergh F, 2004, IEEE T EVOLUT COMPUT, V8, P225, DOI [10.1109/TEVC.2004.826069, 10.1109/tevc.2004.826069]
   Wang ST, 2008, PATTERN RECOGN, V41, P117, DOI 10.1016/j.patcog.2007.03.029
   WESZKA JS, 1978, COMPUT VISION GRAPH, V7, P259, DOI 10.1016/0146-664X(78)90116-8
   WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P866, DOI 10.1109/21.35351
   Xu XD, 2018, IEEE T GEOSCI REMOTE, V56, P937, DOI 10.1109/TGRS.2017.2756851
   Zahara E, 2005, PATTERN RECOGN LETT, V26, P1082, DOI 10.1016/j.patrec.2004.10.003
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zhang XW, 2017, J APPL REMOTE SENS, V11, DOI 10.1117/1.JRS.11.015004
   Zheng H, 2014, C IND ELECT APPL, P1662, DOI 10.1109/ICIEA.2014.6931434
NR 68
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 34027
EP 34063
DI 10.1007/s11042-019-08114-x
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600065
DA 2024-07-18
ER

PT J
AU Li, CY
   Zhou, ZP
   Zhang, W
AF Li, Chunye
   Zhou, Zhiping
   Zhang, Wei
TI An image retrieval method based on semantic matching with multiple
   positional representations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Image caption; Sentence matching; Multiple positional
   representations
AB Text-based image retrieval requires manual annotation or automatic labeling of the machine. Manual annotation is time-consuming, and simple text description is difficult to fully express the content of the image. Existing deep models rely on the representation of a single sentence, and such methods cannot well capture the contextualized local information in the matching process. In response to these problems, this paper presents a new retrieval idea based on image caption. First, the image description sentences of images are generated by using the image caption model. Then, for the sentence matching model, we propose a multiple positional representations semantic matching model. We use two interrelated Bi-LSTMs and the attention mechanism to match sentences. the matching score is finally produced by aggregating interactions between these different positional sentence representations. The sentence matching model is used to match the retrieval sentence with the image description sentences in the image library. In our experiments, the accuracy of the proposed image caption model and the sentence matching model are all improved compared with the competitive models, and our method can complete the image retrieval task.
C1 [Li, Chunye; Zhou, Zhiping; Zhang, Wei] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhou, Zhiping] Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Zhou, ZP (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.; Zhou, ZP (corresponding author), Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Jiangsu, Peoples R China.
EM taoliluoying@163.com; zzp@jiangnan.edu.cn; 805265490@qq.com
FU Postgraduate Research & Practice Innovation Program of Jiangsu Province
   of the People's Republic of China [SJCX19_0797]
FX This work is supported by Postgraduate Research & Practice Innovation
   Program of Jiangsu Province of the People's Republic of China under
   SJCX19_0797.
CR [Anonymous], 2015, COMPUT SCI
   [Anonymous], COGN COMPUT
   [Anonymous], 2008, PROC INT C MACHINE L
   [Anonymous], ARXIV180103406 CORR
   [Anonymous], 2017, P IEEE INT C COMP VI
   [Anonymous], 3 INT C LEARN REPR I
   [Anonymous], 2015, CORR
   [Anonymous], ARXIV160507912 CORR
   [Anonymous], 2014, COMPUT SCI
   [Anonymous], P 13 AAAI C ART INT
   [Anonymous], CONVOLUTIONAL NEURAL
   [Anonymous], CONCURRENCY COMPUTAT
   Berger A., 2000, SIGIR Forum, V34, P192
   Bi Xiaojun, 2017, Systems Engineering and Electronics, V39, P2359, DOI 10.3969/j.issn.1001-506X.2017.10.30
   Blacoe W., 2012, P 2012 JOINT C EMP M, P546
   Dolan B., 2004, P INT C COMP LING
   Eakins J.P., 1996, Proceedings of Third International Conference on Electronic Library and Visual Information Research e, V3, P123
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Ferreira R, 2018, COMPUT SPEECH LANG, V47, P59, DOI 10.1016/j.csl.2017.07.002
   Harmandas V, 1997, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P296, DOI 10.1145/278459.258594
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermann Karl Moritz, 2015, Teaching Machines to Read and Comprehend, P1
   Hu B., 2015, Advances in Neural Information Processing Systems, V3, P2042
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Kiros Ryan., 2015, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems, P3294
   Li H, 2013, FOUND TRENDS INF RET, V7, P345, DOI 10.1561/1500000035
   Li YN, 2015, IEEE SIGNAL PROC LET, V22, P2396, DOI 10.1109/LSP.2015.2487824
   Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu B, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P1237, DOI 10.1145/3178876.3186022
   Liu L, 2016, AAAI CONF ARTIF INTE, P2630
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Palangi H, 2016, IEEE-ACM T AUDIO SPE, V24, P694, DOI 10.1109/TASLP.2016.2520371
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Plummer BA, 2015, IEEE I CONF COMP VIS, P2641, DOI 10.1109/ICCV.2015.303
   Qin C, 2018, INFORM SCIENCES, V423, P284, DOI 10.1016/j.ins.2017.09.060
   Qiu XP, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1305
   Qu SR, 2017, CHIN CONT DECIS CONF, P4789, DOI 10.1109/CCDC.2017.7979342
   Shen YL, 2014, WWW'14 COMPANION: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P373, DOI 10.1145/2567948.2577348
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Socher R, 2013, P 26 INT C NEUR INF, V26, P926
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wan SX, 2016, AAAI CONF ARTIF INTE, P2835
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yin W., 2015, P 2015 C N AM CHAPT, P901
   Yin WP, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P63
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
NR 52
TC 1
Z9 2
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35607
EP 35631
DI 10.1007/s11042-019-08165-0
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800061
DA 2024-07-18
ER

PT J
AU Ma, C
   Sun, ZX
AF Ma, Chen
   Sun, Zhengxing
TI StitchGeneration: Modeling and creation of random-needle embroidery
   based on Markov chain model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Random-needle embroidery; Multi-layer stitch; Single-layer stitch; The
   Markov chain; Simulated annealing strategy; Image-based artistic
   rendering
ID IMAGE STYLIZATION; PAINT
AB Random-needle Embroidery is a new form of Chinese embroidery. The multi-layering of stitch is the notable characteristic of this embroidery art because the embroidery is generated by stacking single-layer stitch multiple times. To generate this kind of multi-layer stitch, the main challenge lies on the single-layer stitch modeling so that the multi-layer stitch can be generated based on stacking single-layer stitches. However, due to the complex structure of threads, single-layer stitch modeling is not easy, especially the long threads are intersected to each other. Besides, to avoid artificial in single-layer stitch, threads with different but similar line lengths and angles are intersected to each other. To tackle these challenges, we regards the single-layer stitch as a combination of many intersecting stitches which are the style primitives of our method, then we propose a method with two steps: intersecting stitches layout and connection to generate single-layer stitch. We introduce a Markov chain model which formulates the selection of intersecting stitches for layout as a sequential decision-making process, and can avoid artificial in single-layer stitch. Then a novel connectivity metrics and simulated annealing strategy based method is used to connect more intersecting stitch while maintain the structure of threads. Finally, this multi-layer stitch is obtained by stacking single-layer stitches multiple times to maintain the characteristic of multi-layering. We apply our method according to many reference images, and stitches with laying and aesthetics can be obtained in all case.
C1 [Ma, Chen; Sun, Zhengxing] Nanjing Univ, Natl Key Lab Novel Software Technol, Xianlin Campus,163 Xianlin Ave, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing University
RP Sun, ZX (corresponding author), Nanjing Univ, Natl Key Lab Novel Software Technol, Xianlin Campus,163 Xianlin Ave, Nanjing 210023, Jiangsu, Peoples R China.
EM szx@nju.edu.cn
RI Sun, Zhengxing/A-7411-2011
FU National High Technology Research and Development Program of China
   [2007AA01Z334]; National Natural Science Foundation of China [61321491,
   61272219]; Innovation Fund of State Key Laboratory for Novel Software
   Technology [ZZKT2013A12, ZZKT2016A11, ZZKT2018A09]
FX This work was supported by National High Technology Research and
   Development Program of China (No.2007AA01Z334), National Natural Science
   Foundation of China (Nos.61321491 and 61272219), Innovation Fund of
   State Key Laboratory for Novel Software Technology (Nos. ZZKT2013A12,
   ZZKT2016A11 and ZZKT2018A09).
CR [Anonymous], 2016, ENCY ALGORITHMS
   [Anonymous], J VIS COMPUT ANIMAT
   [Anonymous], 2009, Proceedings of the 7th International Symposium on Non-Photorealistic Animation and Rendering (NPAR), DOI DOI 10.1145/1572614.1572623
   [Anonymous], 2002, P 2 INT S NONPH AN R, DOI DOI 10.1145/508535.508537
   [Anonymous], 2012, P GRAPHICS INTERFACE
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], ABSCS0607050 CORR
   Böhme M, 2019, IEEE T SOFTWARE ENG, V45, P489, DOI 10.1109/TSE.2017.2785841
   Chen GN, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360702
   Chi MT, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360661
   Davidson R, 1996, ACM T GRAPHIC, V15, P301, DOI 10.1145/234535.234538
   Du Q, 1999, SIAM REV, V41, P637, DOI 10.1137/S0036144599352836
   GRANVILLE V, 1994, IEEE T PATTERN ANAL, V16, P652, DOI 10.1109/34.295910
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Hertzmann A, 2003, IEEE COMPUT GRAPH, V23, P70, DOI 10.1109/MCG.2003.1210867
   Huang H, 2011, VISUAL COMPUT, V27, P861, DOI 10.1007/s00371-011-0596-5
   Huang L, 2003, PROC INT CONF DOC, P780
   Igarashi Yuki., 2015, ACM SIGGRAPH 2015 Posters, P1
   Inglis TC, 2012, COMPUT GRAPH-UK, V36, P607, DOI 10.1016/j.cag.2012.03.003
   Jobard Bruno., 1997, VISUALIZATION SCI CO, P43, DOI DOI 10.1007/978-3-7091-6876-9_5
   Jodoin Pierre-Marc., 2002, PROC NPAR, P29
   Kang H, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P43
   Kang HW, 2006, VISUAL COMPUT, V22, P814, DOI 10.1007/s00371-006-0066-7
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Lindemeier T, 2013, COMPUT GRAPH-UK, V37, P293, DOI 10.1016/j.cag.2013.01.005
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Maharik R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964995
   Martino L, 2015, IEEE T SIGNAL PROCES, V63, P3123, DOI 10.1109/TSP.2015.2420537
   Reinert B, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508409
   Semmo A, 2016, COMPUT GRAPH-UK, V55, P157, DOI 10.1016/j.cag.2015.12.001
   Shen QQ, 2017, LECT NOTES COMPUT SC, V10133, P233, DOI 10.1007/978-3-319-51814-5_20
   Streit L, 1998, COMPUT GRAPH FORUM, V17, pC207, DOI 10.1111/1467-8659.00268
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong FJ, 2013, VISUAL COMPUT, V29, P729, DOI 10.1007/s00371-013-0809-1
   Xu J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239480
   Xu XM, 2017, IEEE T VIS COMPUT GR, V23, P1910, DOI 10.1109/TVCG.2016.2569084
   Xu XM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778789
   Yang KW, 2018, MULTIMED TOOLS APPL, V77, P12259, DOI 10.1007/s11042-017-4882-8
   Yang KW, 2018, LECT NOTES COMPUT SC, V10704, P479, DOI 10.1007/978-3-319-73603-7_39
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Zeng K, 2009, ACM T GRAPHIC, V29, DOI 10.1145/1640443.1640445
   Zhang E, 2007, IEEE T VIS COMPUT GR, V13, P94, DOI 10.1109/TVCG.2007.16
   Zhou J, 2014, J ZHEJIANG U-SCI C, V15, P729, DOI 10.1631/jzus.C1400099
   Zou SK, 2017, METALS-BASEL, V7, DOI 10.3390/met7010001
NR 44
TC 2
Z9 2
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 34065
EP 34094
DI 10.1007/s11042-019-08053-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600066
DA 2024-07-18
ER

PT J
AU Safari, RM
   Rahmani, AM
   Alizadeh, SH
AF Safari, Rahebeh Mojtahedi
   Rahmani, Amir Masoud
   Alizadeh, Sasan H.
TI User behavior mining on social media: a systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Systematic literature review; User behavior mining; Behavioral data;
   Individual behavior; Collective behavior; Social media; User-generated
   content; Information diffusion
ID INFORMATION DIFFUSION; STOCHASTIC BLOCKMODELS; NETWORKS; MODEL;
   INTERESTS; DYNAMICS; TWITTER; TIE; INFLUENCERS; STRENGTH
AB User behavior mining on Social Media (UBMSM) is the process of representing, analyzing, and extracting operational and behavioral patterns from user behavioral data in social media. It discusses theories and methodologies from different disciplines such as combining theorems and techniques from computer science, data mining, machine learning, social network analysis, and other related disciplines. User behavior mining provides a deep understanding of user behavioral data such that we observe not only individual behavioral patterns, but also interaction and communication among users by considering collective behavior of users. The aim of this study is to provide a systematic literature review on the significant aspects and approaches in addressing user behavior mining on social media. A systematic literature review was performed to find the related literature, and 174 articles were selected as primary studies. We classified the surveyed studies into four categories based on their focused area: users, user-generated content, the structure of network that content spreads on it and information diffusion. The majority of the primary articles focus on user aspect (66%); 6% of them focus on content aspect; 6% of them focus on network structure aspect, 22% of them focus on information diffusion aspect.
C1 [Safari, Rahebeh Mojtahedi] Islamic Azad Univ, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
   [Rahmani, Amir Masoud] Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
   [Alizadeh, Sasan H.] Iran Telecommun Res Ctr, Dept Informat Technol, ICT Res Inst, Tehran, Iran.
C3 Islamic Azad University; Islamic Azad University
RP Rahmani, AM (corresponding author), Islamic Azad Univ, Sci & Res Branch, Dept Comp Engn, Tehran, Iran.
EM R.Mojtahedi@qiau.ac.ir; rahmani@srbiau.ac.ir; s.alizadeh@itrc.ac.ir
RI Rahmani, Amir Masoud/K-2702-2013; Alizadeh, Sasan/GPW-8328-2022; safari,
   rahebeh mojtahedi/AAO-5798-2021
OI Rahmani, Amir Masoud/0000-0001-8641-6119; Alizadeh,
   Sasan/0000-0003-3618-8845; 
CR Abel F, 2012, INT C WEB ENG
   Abel F, 2011, P 3 INT WEB SCI C
   Abel F, 2013, USER MODEL USER-ADAP, V23, P169, DOI 10.1007/s11257-012-9131-2
   Abrahao B, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P491
   Adamic N., 2005, INT WORKSHOP LINK DI, P36, DOI DOI 10.1145/1134271.1134277
   Aggarwal C. C., 2012, P SIAM INT C DAT MIN, P624
   Ahmed A., 2011, P 17 ACM SIGKDD INT
   Aiello LM, 2012, ACM T WEB, V6, DOI 10.1145/2180861.2180866
   Almars A, 2019, DATA KNOWL ENG, V119, P139, DOI 10.1016/j.datak.2019.01.005
   Almgren K, 2015, DIG INF MAN ICDIM 20
   Alp ZZ, 2018, KNOWL-BASED SYST, V141, P211, DOI 10.1016/j.knosys.2017.11.021
   [Anonymous], P 2013 IEEE ACM INT
   [Anonymous], 2009, ACM SIGCOMM
   [Anonymous], 2012, ICML
   [Anonymous], 2011, P 4 ACM INT C WEB SE, DOI DOI 10.1145/1935826.1935844
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], 2018 4 INT C WEB RES
   Aral S, 2009, P NATL ACAD SCI USA, V106, P21544, DOI 10.1073/pnas.0908800106
   Artzi Y., 2012, P 2012 C N AM CHAPT
   Backstrom Lars., 2011, ICWSM, V11, P23
   Baingana B, 2017, IEEE T SIGNAL PROCES, V65, P985, DOI 10.1109/TSP.2016.2628354
   Bakshy E., 2012, P 21 INT C WORLD WID, P519
   Bakshy E., 2011, P 4 ACM INT C WEB SE, P65
   Bao Q, 2017, IEEE T CYBERNETICS, V47, P1078, DOI 10.1109/TCYB.2016.2537366
   Barabási AL, 2005, NATURE, V435, P207, DOI 10.1038/nature03459
   Bhattacharya P, 2014, PROCEEDINGS OF THE 8TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'14), P357, DOI 10.1145/2645710.2645765
   Bloch F, 2018, INT ECON REV, V59, P421, DOI 10.1111/iere.12275
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bordianu GC, 2012, LEARNING INFLUENCE P
   Borgatti SP, 2005, SOC NETWORKS, V27, P55, DOI 10.1016/j.socnet.2004.11.008
   Brereton P, 2007, J SYST SOFTWARE, V80, P571, DOI 10.1016/j.jss.2006.07.009
   Budak C, 2014, MSRTR201468
   Cano AE, 2014, SEMANT WEB, V5, P357, DOI 10.3233/SW-130108
   Cao LB, 2010, INFORM SCIENCES, V180, P3067, DOI 10.1016/j.ins.2010.03.025
   Cha M., 2010, P INT AAAI C WEB SOC, V4, P10, DOI DOI 10.1145/2897659.2897663
   Cha Y, 2013, P 36 INT ACM SIGIR C
   Cha Y, 2012, P 35 INT ACM SIGIR C
   Chen JL, 2010, CHI2010: PROCEEDINGS OF THE 28TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P821
   Colleoni E, 2014, J COMMUN, V64, P317, DOI 10.1111/jcom.12084
   Conover M., 2011, P INT AAAI C WEB SOC, V5, P89
   Crandall DavidJ., 2008, KDD, P160, DOI DOI 10.1145/1401890.1401914
   Cui P, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P185
   Daneshmand H, 2014, PR MACH LEARN RES, V32, P793
   Dang A, 2015, ADV SOC NETW AN MIN
   Davenport T.H., 2013, The attention economy: Understanding the new currency of business
   Davoudi A, 2016, BIG DAT BIG DAT 2016
   De Choudhury M, 2011, PRIV SEC RISK TRUST
   DEUTSCH MORTON, 1955, JOUR ABNORMAL AND SOCIAL PSYCHOL, V51-31, P629, DOI 10.1037/h0046408
   Ding Y, 2014, AS INF RETR S
   Dougnon RY, 2015, CAN C ART INT
   Efstathiades H, 2016, BIG DAT BIG DAT 2016
   Ferrara E, 2013, 2013 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P554
   Fogués RL, 2014, INFORM SYST FRONT, V16, P225, DOI 10.1007/s10796-013-9453-6
   Gabrilovich E., 2007, IJCAI
   Gallos LK, 2012, PHYS REV X, V2, DOI 10.1103/PhysRevX.2.031014
   Garousi V, 2013, J SYST SOFTWARE, V86, P1354, DOI 10.1016/j.jss.2012.12.051
   Ghosh R., 2011, Proceedings of the Fourth ACM International Conference on Web Search and Data Mining, WSDM '11, P665
   Ghosh R, 2010, P KDD WORKSH SOC NET
   Ghosh S, 2012, SIGIR 2012: PROCEEDINGS OF THE 35TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P575, DOI 10.1145/2348283.2348361
   Gilbert E, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P211
   Golub B, 2012, Q J ECON, V127, P1287, DOI 10.1093/qje/qjs021
   Gomez-Rodriguez M., 2011, P 28 INT C MACH LEAR, P561, DOI DOI 10.5555/3104482.3104553
   Gomez-Rodriguez M, 2012, ACM T KNOWL DISCOV D, V5, DOI 10.1145/2086737.2086741
   Gonçalves B, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0022656
   Goyal A., 2010, P 3 ACM INT C WEB SE, P241, DOI DOI 10.1145/1718487.1718518
   GRANOVETTER M, 1978, AM J SOCIOL, V83, P1420, DOI 10.1086/226707
   GRANOVETTER MS, 1973, AM J SOCIOL, V78, P1360, DOI 10.1086/225469
   Greenberger Martin., 1971, Computers, Communications, and the Public Interest
   Guille A, 2013, SIGMOD REC, V42, P17
   Halberstam Y, 2016, J PUBLIC ECON, V143, P73, DOI 10.1016/j.jpubeco.2016.08.011
   Han J, 2016, INFORM SCIENCES, V358, P112, DOI 10.1016/j.ins.2016.04.020
   Hannon J, 2010, P 4 ACM C REC SYST
   Hannon J., 2012, INT C US MOD AD PERS
   Harvey M, 2013, 22 ACM INT C C INF K
   He J, 2016, LECT NOTES ELECTR EN, V348, P935, DOI 10.1007/978-81-322-2580-5_85
   HOLLAND PW, 1983, SOC NETWORKS, V5, P109, DOI 10.1016/0378-8733(83)90021-7
   Hong L., 2013, P 6 ACM INT C WEB SE
   Hosseini-Pozveh M, 2019, EXPERT SYST APPL, V119, P476, DOI 10.1016/j.eswa.2018.07.064
   Hosseini-Pozveh M, 2016, INTELL DATA ANAL, V20, P199, DOI 10.3233/IDA-150801
   Hu Y, 2016, COMM ICC 2016 IEEE I
   Hu Z, 2013, ABS13120860 CORR
   Huang AH, 2018, MANAGE SCI, V64, P2833, DOI 10.1287/mnsc.2017.2751
   Huang X, 2016, LECT NOTES COMPUT SC, V9931, P256, DOI 10.1007/978-3-319-45814-4_21
   Hung Chia-Chuan, 2008, WORKSH INT TECHN WEB
   Jackson MO., 2013, Netw. Sci, V1, P49, DOI 10.1017/nws.2012.7
   JafariAsbagh M, 2014, SOC NETW ANAL MIN, V4, DOI 10.1007/s13278-014-0237-x
   Jiang B, 2015, PROCEDIA COMPUT SCI, V51, P503, DOI 10.1016/j.procs.2015.05.275
   Jiang CX, 2014, IEEE T SIGNAL PROCES, V62, P4573, DOI 10.1109/TSP.2014.2339799
   Jin DW, 2018, MOBILE NETW APPL, V23, P717, DOI 10.1007/s11036-018-1004-4
   Jones JJ, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0052168
   Kang J, 2019, J INTELL INF SYST, V52, P191, DOI 10.1007/s10844-018-0534-3
   Kapanipathi P, 2014, EUR SEM WEB C
   Kaplan AM, 2010, BUS HORIZONS, V53, P59, DOI 10.1016/j.bushor.2009.09.003
   Karrer B, 2011, PHYS REV E, V84, DOI 10.1103/PhysRevE.84.036106
   Karsai M, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.025102
   Kelman H. C., 2017, FURTHER THOUGHTS PRO, P125
   Kempe David, 2003, P 9 ACM SIGKDD INT C, P137, DOI DOI 10.1145/956750.956769
   Khan HU, 2017, COMPUT HUM BEHAV, V68, P64, DOI 10.1016/j.chb.2016.11.012
   Khemmarat S, 2014, INT C PASS ACT NETW
   Kim HN, 2011, DECIS SUPPORT SYST, V51, P772, DOI 10.1016/j.dss.2011.01.012
   Kossinets G, 2009, AM J SOCIOL, V115, P405, DOI 10.1086/599247
   Kumar R, 2010, LINK MINING: MODELS, ALGORITHMS, AND APPLICATIONS, P337, DOI 10.1007/978-1-4419-6515-8_13
   Kwak HG, 2010, INT CONF ADV COMMUN, P591
   Lahuerta-Otero E, 2016, COMPUT HUM BEHAV, V64, P575, DOI 10.1016/j.chb.2016.07.035
   Lazer D, 2009, SCIENCE, V323, P721, DOI 10.1126/science.1167742
   Lehmann T, 2012, J CIRCUIT SYST COMP, V21, DOI 10.1142/S0218126612400166
   Lerman K., 2012, ARXIV12023162
   Li JX, 2014, EXPERT SYST APPL, V41, P5115, DOI 10.1016/j.eswa.2014.02.038
   Lim KH, 2013, CSH PERSPECT BIOL, V5, DOI 10.1101/cshperspect.a011247
   Liu C, 2014, COMMUN NONLINEAR SCI, V19, P896, DOI 10.1016/j.cnsns.2013.08.028
   Liu L, 2018, PHYSICA A, V496, P318, DOI 10.1016/j.physa.2017.12.026
   Liu L, 2012, DATA MIN KNOWL DISC, V25, P511, DOI 10.1007/s10618-012-0252-3
   Lobel I, 2015, THEOR ECON, V10, P807, DOI 10.3982/TE1549
   Locher DavidA., 2002, COLLECTIVE BEHAV
   Lomi A, 2016, SOC NETWORKS, V44, P266, DOI 10.1016/j.socnet.2015.10.006
   Lu C., 2012, Workshops at the Twenty-Sixth AAAI Conference on Artificial Intelligence, P33
   Ma Y, 2011, INT C ACT MED TECHN
   Mahmud J, 2014, ICWSM
   McPherson M, 2001, ANNU REV SOCIOL, V27, P415, DOI 10.1146/annurev.soc.27.1.415
   Mehrotra R, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P889
   Meng L, 2016, IEEE T NETW SCI ENG, V3, P32, DOI 10.1109/TNSE.2016.2523798
   Mezghani M, 2014, INT CONF RES CHAL
   Michelle GG, 2016, ADV EL EL INF COMM B
   Michelson M., 2010, P WORKSHOP ANALYTICS, P73, DOI [DOI 10.1145/1871840.1871852, 10.1145/1871840.1871852]
   Milenkovic T, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0023016
   Miritello G, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.045102
   Mislove A., 2010, P 3 ACM INT C WEB SE, P251, DOI [DOI 10.1145/1718487.1718519, 10.1145/1718487.1718519]
   MUSCILLO A., 2014, DISCRETE MODELS INFO
   Myers S, 2010, ADV NEUR INF PROC SY
   Narducci F, 2013, INT C EL COMM WEB TE
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Orlandi F, 2012, P 8 INT C SEM SYST
   Oselio B, 2014, IEEE J-STSP, V8, P514, DOI 10.1109/JSTSP.2014.2328312
   Ottoni R., 2014, ICWSM
   Pal A, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P1203, DOI 10.1145/2872427.2883078
   Pennacchiotti M, 2011, P 20 INT C COMP WORL
   Pereira FSF, 2018, MACH LEARN, V107, P1745, DOI 10.1007/s10994-018-5740-2
   Piao G, 2016, P 12 INT C SEM SYST
   Piao G, 2016, P 2016 C US MOD AD P
   Piao G, 2016, P 25 ACM INT C INF K
   Pochampally R., 2011, WORKSH ENR INF RETR, P1
   Ramage Daniel., 2009, EMNLP, DOI DOI 10.3115/1699510.1699543
   Ramanathan K, 2009, INT C CONC MOD
   Rashotte L., 2007, The Blackwell encyclopedia of social psychology, V9, P562
   Riquelme F, 2016, INFORM PROCESS MANAG, V52, P949, DOI 10.1016/j.ipm.2016.04.003
   RodriguezM Gomez, 2013, P 6 ACM INT C WEB SE
   Rogati M., 2010, Proceedings of the 19th international conference on World wide web, P981, DOI DOI 10.1145/1772690.1772790
   ROGERS EM, 1962, PUBLIC OPIN QUART, V26, P435, DOI 10.1086/267118
   Romero DM, 2011, LECT NOTES ARTIF INT, V6913, P18, DOI 10.1007/978-3-642-23808-6_2
   Romero DM, 2011, ARXIV11121115
   Saito K, 2012, ARXIV12044528
   Saito K, 2010, ACML
   Saito K, 2008, KNOWL BAS INT INF EN
   Saito K, 2012, KNOWL INF SYST, V30, P613, DOI 10.1007/s10115-011-0396-2
   Schifanella R., 2010, Proceedings of the 3rd ACM Int'l Conf. on Web Search and Data Mining, P271
   Servia-Rodríguez S, 2013, COMM COM INF SC, V367, P71
   Shah B, 2018, P INT C COMP INT DAT
   Sharma N, 2012, ACM SIGCOMM COMP COM, V42, P533, DOI 10.1145/2377677.2377782
   Sheikhahmadi A, 2017, J INF SCI, V43, P412, DOI 10.1177/0165551516644171
   Shu X, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.10.106005
   Slaughter AJ, 2016, SOC NETWORKS, V44, P334, DOI 10.1016/j.socnet.2015.11.002
   Sneppen K, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0013326
   Snijders TAB, 2016, METHODS SER, V12, P15, DOI 10.1007/978-3-319-24520-1_2
   Sohrabi MK, 2016, COMPUT HUM BEHAV, V60, P534, DOI 10.1016/j.chb.2016.02.092
   Steeg GV, 2011, ARXIV11021985
   Sun QD, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416590151
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Tabasso N, 2015, DIFFUSION MULTIPLE I
   Tan C, 2010, P 16 ACM SIGKDD INT
   Tang J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P807
   Tang JH, 2019, IEEE T PATTERN ANAL, V41, P2027, DOI 10.1109/TPAMI.2019.2906603
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   Tang SY, 2011, IEEE T MULTIMEDIA, V13, P1163, DOI 10.1109/TMM.2011.2159706
   Tao K, 2011, EXT SEM WEB C
   Tong C, 2016, PHYSICA A, V444, P297, DOI 10.1016/j.physa.2015.10.026
   Trikha AK, 2018, EUR C INF RETR
   Uysal I., 2011, CIKM, P2261, DOI DOI 10.1145/2063576.2063941
   Vespignani A, 2009, SCIENCE, V325, P425, DOI 10.1126/science.1171990
   Wan JH, 2019, NEUROCOMPUTING, V333, P169, DOI 10.1016/j.neucom.2018.12.062
   Wang F, 2016, AS PAC SER COMP C
   Wang F, 2013, DISTR COMP SYST ICDC
   Wang F, 2012, DISTR COMP SYST WORK
   Wang H, 2018, INTELL DATA ANAL, V22, P515, DOI 10.3233/IDA-173414
   Wang P, 2016, SOC NETWORKS, V44, P346, DOI 10.1016/j.socnet.2014.12.003
   Wang Yongqing, 2013, ARXIV13103911
   Watts DJ, 2007, NATURE, V445, P489, DOI 10.1038/445489a
   Weng J., 2010, P 3 ACM INT C WEB SE, P261, DOI [10.1145/1718487.1718520, DOI 10.1145/1718487.1718520]
   Weng L, 2013, SCI REP-UK, V3, DOI [10.1038/srep02304, 10.1038/srep02522]
   Weng L., 2014, INFORM DIFFUSION ONL
   Weng LL, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0118410
   Weng Lilian., 2014, ICWSM
   Wu F, 2007, P NATL ACAD SCI USA, V104, P17599, DOI 10.1073/pnas.0704916104
   Wuchty S, 2003, J THEOR BIOL, V223, P45, DOI 10.1016/S0022-5193(03)00071-7
   Xiao YP, 2019, PHYSICA A, V521, P578, DOI 10.1016/j.physa.2019.01.117
   Xu KS, 2014, IEEE J-STSP, V8, P552, DOI 10.1109/JSTSP.2014.2310294
   Xu Tao., 2011, Machine Learning for Signal Processing (MLSP), 2011 IEEE International Workshop on, P1, DOI [10.1002/meet.2011.14504801186, DOI 10.1002/MEET.2011.14504801186]
   Yang J, 2010, DAT MIN ICDM 2010 IE
   Yang L., 2012, P 21 INT C WORLD WID, P261, DOI DOI 10.1145/2187836.2187872
   Ye S, 2010, INT C SOC INF
   Yi YX, 2018, PHYSICA A, V509, P783, DOI 10.1016/j.physa.2018.06.063
   Yin HZ, 2015, ACM T INFORM SYST, V33, DOI 10.1145/2699670
   Zarrinkalam F, 2019, INFORM RETRIEVAL J, V22, P93, DOI 10.1007/s10791-018-9337-y
   Zarrinkalam F, 2018, INFORM PROCESS MANAG, V54, P339, DOI 10.1016/j.ipm.2017.12.003
   Zhang X, 2018, IEEE T KNOWL DATA EN
   Zhao WNX, 2011, LECT NOTES COMPUT SC, V6611, P338, DOI 10.1007/978-3-642-20161-5_34
   Zhao Z., 2015, P 24 INT C WORLD WID
   Zhong E, 2012, P 18 ACM SIGKDD INT
   Zhou E, 2019, INT C INF
   Zhu ZG, 2015, COMPUT HUM BEHAV, V52, P184, DOI 10.1016/j.chb.2015.04.072
   Zhu ZG, 2013, PHYSICA A, V392, P3459, DOI 10.1016/j.physa.2013.03.035
   Zhuang KC, 2017, MULTIMED TOOLS APPL, V76, P3169, DOI 10.1007/s11042-016-3818-z
NR 211
TC 9
Z9 9
U1 22
U2 147
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 33747
EP 33804
DI 10.1007/s11042-019-08046-6
PG 58
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600054
DA 2024-07-18
ER

PT J
AU Silva, AR
   Farias, MCQ
AF Silva, Alessandro R.
   Farias, Mylene C. Q.
TI Perceptual quality assessment of 3D videos with stereoscopic
   degradations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video quality; Psychophysical experiments; Stereoscopic degradations;
   Quality databases
AB In the last decade, several aspects of the 3D video technology have been improved, including the 3D content production, distribution, and display. Still, the level of acceptability and popularity of 3D video applications are strongly correlated to the user Quality of Experience (QoE). Since research in this area depends heavily on data acquired in psychophysical experiments, public databases with typical stereoscopic degradations are considered important tools to researchers. Although currently there are number of available public 3D video quality databases, most of them contain only compression and transmission degradations. In this work, our first goal was to build a database (UnB-3D) that contains stereoscopic distortions. We created a set of Computer Graphics Imaging (CGI) scenes and rendered it using different parameters, generating 3D videos containing stereoscopic degradations at different strengths. Our second goal is to understand how these stereoscopic degradations are perceived by viewers. So, we performed a psychophysical experiment to analyze the perceived quality and comfort of these videos. Finally we conducted the statistical analysis and model generation. Results shows that users that have little familiarity with 3D content have difficulties identifying stereoscopic distortions. Also, the source content has a great influence on the user's comfort. Similarly, the 3D quality is affected by the spatial and temporal information of the content, specially when the disparity is high.
C1 [Silva, Alessandro R.] Inst Fed Goias, Anapolis, Brazil.
   [Farias, Mylene C. Q.] Univ Brasilia, Dept Elect Engn, UnB, Grad Program Informat, Brasilia, DF, Brazil.
   [Farias, Mylene C. Q.] Univ Brasilia, Dept Elect Engn, UnB, Grad Program Elect Syst & Automat Engn PGEA, Brasilia, DF, Brazil.
C3 Instituto Federal de Goias (IFG); Universidade de Brasilia; Universidade
   de Brasilia
RP Silva, AR (corresponding author), Inst Fed Goias, Anapolis, Brazil.
EM alessandro.rodrigues@ifg.edu.br; mylene@ieee.org
RI Farias, Mylene/C-4900-2015
OI Farias, Mylene/0000-0002-1957-9943
CR Alatan AA, 2007, IEEE T CIRC SYST VID, V17, P1587, DOI 10.1109/TCSVT.2007.909974
   [Anonymous], 2006, VISUAL EXPERIENCE 3D
   [Anonymous], 2011, 341 ITUJ
   [Anonymous], 2007, 788 ITUR
   Boev A., 2008, CLASSIFICATION STERE
   Corrigan D., 2010, Proceedings 2010 Conference on Visual Media Production (CVMP 2010). 7th European Conference on Visual Media Production, P64, DOI 10.1109/CVMP.2010.16
   Dumic E, 2017, MULTIMED TOOLS APPL, V76, P2087, DOI 10.1007/s11042-015-3172-6
   Farias M, 2019, UNB 3D VIDEO QUALITY
   Fontaine DB, 2010, IEEE INT C IM PROC
   Goldmann L, 2010, IEEE IMAGE PROC, P3241, DOI 10.1109/ICIP.2010.5651142
   Lebreton P, 2012, IEEE J-STSP, V6, P710, DOI 10.1109/JSTSP.2012.2213236
   Lipton L., 1982, FDN STEREOSCOPIC CIN
   Meesters LMJ, 2004, IEEE T CIRC SYST VID, V14, P381, DOI 10.1109/TCSVT.2004.823398
   Seuntiens P, 2007, 10 ANN INT WORKSH PR
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Staelens N, 2012, INT WORKSH VID PROC
   Urey H, 2011, P IEEE, V99, P540, DOI 10.1109/JPROC.2010.2098351
   Urvoy M, 2012, NAMA3DS1 COSPAD1 SUB
   WOODS A, 1993, P SOC PHOTO-OPT INS, V1915, P36, DOI 10.1117/12.157041
NR 19
TC 3
Z9 3
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1603
EP 1623
DI 10.1007/s11042-019-08386-3
EA NOV 2019
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000494629200001
DA 2024-07-18
ER

PT J
AU Guo, WP
   Xu, ZM
   Zhang, HB
AF Guo, Wenping
   Xu, Zhuoming
   Zhang, Haibo
TI Interstitial lung disease classification using improved DenseNet
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interstitial lung disease; Deep learning; Convolutional neural network;
   DenseNet; SK-DenseNet
ID FACIAL EXPRESSION RECOGNITION; NEURAL-NETWORKS; EMPHYSEMA
AB Interstitial Lung Disease (ILD) is one of the popular respiratory diseases. The correct diagnosis of ILD is beneficial to improve the effect of treatment for patients. This paper presents an improved DenseNet called small kernel DenseNet (SK-DenseNet) to improve ILD classification performance. According to the characteristics of HRCT features of lung disease, the SK-DenseNet network is more effective to extract high level and small pathological features for ILD classification. Our experiment results show that the proposed SK-DenseNet obtains an outstanding performance (98.4%),which improves 5% performance compared with DenseNet. A comparative analysis with other CNNs, such as AlexNet, VGGNet, ResNet has also demonstrated that the effectiveness of SK-DenseNet in terms of classifying lung disease patterns is superior than those compared ones. The research has validated that using small convolution kernel is useful to improve the recognition efficiency when feature patterns are small.
C1 [Guo, Wenping; Xu, Zhuoming] Hohai Univ, Coll Comp & Informat, Nanjing 210098, Jiangsu, Peoples R China.
   [Guo, Wenping; Zhang, Haibo] Taizhou Univ, Inst Intelligent Informat Proc, Taizhou 317000, Peoples R China.
C3 Hohai University; Taizhou University
RP Guo, WP (corresponding author), Hohai Univ, Coll Comp & Informat, Nanjing 210098, Jiangsu, Peoples R China.; Guo, WP (corresponding author), Taizhou Univ, Inst Intelligent Informat Proc, Taizhou 317000, Peoples R China.
EM gwp@hhu.edu.cn; zmxu@hhu.edu.cn; zhanghb@tzc.edu.cn
RI Zhang, Haibo/HLP-9266-2023
OI guo, wenping/0000-0002-0405-1775; Xu, Zhuoming/0000-0002-0080-6501
FU Natural Science Foundation of Zhejiang Province China [LY14F020036]
FX This work is supported by the Natural Science Foundation of Zhejiang
   Province China, under Grant No. LY14F020036.
CR [Anonymous], 2002, Am J Respir Crit Care Med, V165, P277304, DOI [DOI 10.1164/AJRCCM.165.2.ATS01, 10.1164/ajrccm.165.2.ats01]
   Anthimopoulos M, 2014, IEEE ENG MED BIO, P6040, DOI 10.1109/EMBC.2014.6945006
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   CARRINGTON CB, 1976, CHEST, V69, P261
   Depeursinge A, 2012, IEEE T INF TECHNOL B, V16, P665, DOI 10.1109/TITB.2012.2198829
   Depeursinge A, 2012, COMPUT MED IMAG GRAP, V36, P227, DOI 10.1016/j.compmedimag.2011.07.003
   Depeursinge A, 2010, ARTIF INTELL MED, V50, P13, DOI 10.1016/j.artmed.2010.04.006
   Gao MC, 2018, COMP M BIO BIO E-IV, V6, P1, DOI 10.1080/21681163.2015.1124249
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jacobs C, 2011, 14 INT C MED IM COMP, P207
   King TE, 2005, AM J RESP CRIT CARE, V172, P268, DOI 10.1164/rccm.200503-483OE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Naghavi M, 2015, LANCET, V385, P117, DOI 10.1016/S0140-6736(14)61682-2
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Y, 2015, MED IMAGE ANAL, V22, P102, DOI 10.1016/j.media.2015.03.003
   Song Y, 2013, IEEE T MED IMAGING, V32, P797, DOI 10.1109/TMI.2013.2241448
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Uppaluri R, 1999, AM J RESP CRIT CARE, V160, P648, DOI 10.1164/ajrccm.160.2.9804094
   Vos T, 2015, LANCET, V386, P743, DOI 10.1016/S0140-6736(15)60692-4
   Wang Y, 2018, IEEE T NEURAL NETWOR, P99
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wu L, 2019, IEEE T MULTIMEDIA, V21, P1412, DOI 10.1109/TMM.2018.2877886
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Xu Y, 2006, IEEE T MED IMAGING, V25, P464, DOI 10.1109/TMI.2006.870889
   Zhang SQ, 2013, MULTIMED TOOLS APPL, V63, P615, DOI 10.1007/s11042-011-0887-x
   Zhao XM, 2015, IETE TECH REV, V32, P347, DOI 10.1080/02564602.2015.1017542
   Zhao XM, 2011, SENSORS-BASEL, V11, P9573, DOI 10.3390/s111009573
NR 33
TC 19
Z9 19
U1 10
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30615
EP 30626
DI 10.1007/s11042-018-6535-y
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200055
DA 2024-07-18
ER

PT J
AU Wang, HB
   Li, HH
   Peng, JJ
   Fu, XP
AF Wang, Huibing
   Li, Haohao
   Peng, Jinjia
   Fu, Xianping
TI Multi-feature distance metric learning for non-rigid 3D shape retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-view learning; Distance metric learning; Non-rigid 3D shape
   retrieval
ID DESCRIPTORS
AB In the past decades, feature-learning-based 3D shape retrieval approaches have been received widespread attention in the computer graphic community. These approaches usually explored the hand-crafted distance metric or conventional distance metric learning methods to compute the similarity of the single feature. The single feature always contains onefold geometric information, which cannot characterize the 3D shapes well. Therefore, the multiple features should be used for the retrieval task to overcome the limitation of single feature and further improve the performance. However, most conventional distance metric learning methods fail to integrate the complementary information from multiple features to construct the distance metric. To address these issue, a novel multi-feature distance metric learning method for non-rigid 3D shape retrieval is presented in this study, which can make full use of the complimentary geometric information from multiple shape features by utilizing the KL-divergences. Minimizing KL-divergence between different metric of features and a common metric is a consistency constraints, which can lead the consistency shared latent feature space of the multiple features. We apply the proposed method to 3D model retrieval, and test our method on well known benchmark database. The results show that our method substantially outperforms the state-of-the-art non-rigid 3D shape retrieval methods.
C1 [Wang, Huibing; Peng, Jinjia; Fu, Xianping] Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Peoples R China.
   [Li, Haohao] Dalian Univ Technol, Sch Math Sci, Dalian 116024, Peoples R China.
C3 Dalian Maritime University; Dalian University of Technology
RP Fu, XP (corresponding author), Dalian Maritime Univ, Coll Informat & Sci Technol, Dalian 116021, Peoples R China.
EM huibing.wang@dlmu.edu.cn; hhl820@mail.dlut.edu.cn;
   pengjinjia123@dlmu.edu.cn; fxp@dlmu.edu.cn
RI Li, Hao Hao/GSN-1035-2022
OI Li, Haohao/0000-0002-0171-1205
FU National Natural Science Foundation of China [61370142, 61272368];
   Fundamental Research Funds for the Central Universities [3132016352];
   Fundamental Research of Ministry of Transport of P.R. China
   [2015329225300]
FX This study was funded by the National Natural Science Foundation of
   China Grant 61370142 and Grant 61272368, by the Fundamental Research
   Funds for the Central Universities Grant 3132016352, by the Fundamental
   Research of Ministry of Transport of P.R. China Grant 2015329225300.
   Huibing Wang, Haohao Li and Xianping Fu declare that they have no
   conflict of interest. Huibing Wang and Haohao Li contribute equally to
   this article. This article does not contain any studies with human
   participants or animals performed by any of the authors.
CR [Anonymous], 2018, IEEE Trans. Multimedia
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Chiotellis I, 2016, LECT NOTES COMPUT SC, V9906, P327, DOI 10.1007/978-3-319-46475-6_21
   Davis J. V., 2007, ICML, P209
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kuang ZZ, 2015, COMPUT GRAPH-UK, V46, P209, DOI 10.1016/j.cag.2014.09.033
   Kumar D, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P1413
   Li CY, 2013, INT J MULTIMED INF R, V2, P261, DOI 10.1007/s13735-013-0041-9
   Li CY, 2014, MULTIMEDIA SYST, V20, P253, DOI 10.1007/s00530-013-0318-0
   Lian Z, 2015, SHREC 15 TRACK NONRI
   Lian Z., 2010, Eurographics Workshop on 3D Object Retrieval, V10, P101, DOI [10.2312/3DOR/3DOR10/101-108, 10.1109/CVPR.2014.491, DOI 10.2312/3DOR/3DOR10/101-108]
   Lian Z., 2011, EUR WORKSH 3D OBJ RE
   Lian ZH, 2013, PATTERN RECOGN, V46, P449, DOI 10.1016/j.patcog.2012.07.014
   Limberger F.A., 2015, BMVC, P56
   Limberger FA, 2017, THESIS
   Litman R, 2014, COMPUT GRAPH FORUM, V33, P127, DOI 10.1111/cgf.12438
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   OHBUCHI R., 2010, Proceedings of the ACM workshop on 3D object retrieval, P63
   Pickup D, 2014, EUR WORKSH 3D OBJ RE
   Pinkall U., 1993, Exp. Math., V2, P15, DOI 10.1080/10586458.1993.10504266
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Rustamov Raif M, 2007, P S GEOM PROC, V257, P225
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Sun JA, 2009, COMPUT GRAPH FORUM, V28, P1383, DOI 10.1111/j.1467-8659.2009.01515.x
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Wang HB, 2016, IEEE T MULTIMEDIA, V18, P1579, DOI 10.1109/TMM.2016.2569412
   Wang Y, 2016, INT JOINT C ART INT
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2018, NEURAL NETWORKS, V103, P1, DOI 10.1016/j.neunet.2018.03.006
   Wang Y, 2017, IEEE T IMAGE PROCESS, V26, P1393, DOI 10.1109/TIP.2017.2655449
   Wang Y, 2017, IEEE T NEUR NET LEAR, V28, P57, DOI 10.1109/TNNLS.2015.2498149
   Wang Y, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P79, DOI 10.1145/2733373.2806233
   Wang Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P981, DOI 10.1145/2647868.2654999
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Wu  L., 2018, ARXIV181210222
   Wu L, 2019, IEEE T IMAGE PROCESS, V28, P1602, DOI 10.1109/TIP.2018.2878970
   Wu L, 2019, IEEE T CYBERNETICS, V49, P1791, DOI 10.1109/TCYB.2018.2813971
   Wu L, 2018, PATTERN RECOGN, V76, P727, DOI 10.1016/j.patcog.2017.10.004
   Wu L, 2018, PATTERN RECOGN, V73, P275, DOI 10.1016/j.patcog.2017.08.029
   Wu PC, 2016, IEEE T KNOWL DATA EN, V28, P454, DOI 10.1109/TKDE.2015.2477296
   Xie J, 2017, IEEE T MULTIMEDIA, V19, P2463, DOI 10.1109/TMM.2017.2698200
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Xu C., 2013, arXiv
   Xu C, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3974
   Zhai DM, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168767
NR 51
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 30943
EP 30958
DI 10.1007/s11042-019-7670-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200070
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, TT
   Xu, JH
   Su, XH
   Li, CS
   Chi, Y
AF Wang, TianTian
   Xu, JiaHuan
   Su, XiaoHong
   Li, ChenShi
   Chi, Yang
TI Automatic debugging of operator errors based on efficient mutation
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mutation analysis; Fault-localization; Automatic repair; Operator error
AB It takes a lot of time and effort to manually locate and fix software bugs. This paper proposes a method for automatically debugging operator related bugs. Testing, fault localization, and bug-fixing are closely linked based on mutation analysis. However, in the process of mutation analysis, the generation of a large number of mutants and the execution of test cases on mutants, is fairly time-consuming. To solve this problem, optimization methods for selection of mutants and test cases have been proposed. Experiment results has shown that it can improve the efficiency of mutation analysis, so that the cost of fault-localization and bug-fixing can be reduced. We also implemented the exhaustive mutation method and the random mutation method and compared these three methods. These three method have different application scenarios. As the mutation based fault localization can rank statements by suspiciousness, the method integrated with fault localization is more stable and has batter performance. Also, it is more suitable for analyzing program with multi-bugs.
C1 [Wang, TianTian; Xu, JiaHuan; Su, XiaoHong; Li, ChenShi; Chi, Yang] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Wang, TT (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin, Heilongjiang, Peoples R China.
EM sweetwtt@126.com
OI Wang, Tiantian/0000-0003-2958-8066
FU National Key R&D Program of China [2018YFB1004800]; National Natural
   Science Foundation of China [61672191]; Harbin science and technology
   innovation talents research project [2016RAQXJ013]
FX This study was supported by National Key R&D Program of China (Grant No.
   2018YFB1004800), the National Natural Science Foundation of China(Grant
   No. 61672191) and Harbin science and technology innovation talents
   research project(Grant No. 2016RAQXJ013).
CR Abreu R, 2007, TAIC PART 2007 - TESTING: ACADEMIC AND INDUSTRIAL CONFERENCE - PRACTICE AND RESEARCH TECHNIQUES, PROCEEDINGS, P89, DOI 10.1109/TAIC.PART.2007.13
   Debroy V, 2014, J SYST SOFTWARE, V90, P45, DOI 10.1016/j.jss.2013.10.042
   DEMILLO RA, 1978, COMPUTER, V11, P34, DOI 10.1109/C-M.1978.218136
   Gazzola L., 2017, IEEE T SOFTWARE ENG, P1
   HUANG JC, 1978, COMPUTER, V11, P25, DOI 10.1109/C-M.1978.218134
   Jia Y, 2011, IEEE T SOFTWARE ENG, V37, P649, DOI 10.1109/TSE.2010.62
   Lin B, 2016, IEEE T NETW SERV MAN, V13, P581, DOI 10.1109/TNSM.2016.2554143
   Lu RC, 2015, P IEEE INT FREQ CONT, P1, DOI 10.1109/FCS.2015.7138781
   Moon S, 2014, 2014 IEEE SEVENTH INTERNATIONAL CONFERENCE ON SOFTWARE TESTING, VERIFICATION AND VALIDATION (ICST), P153, DOI 10.1109/ICST.2014.28
   Offutt A. J., 1996, ACM Transactions on Software Engineering and Methodology, V5, P99, DOI 10.1145/227607.227610
   Papadakis M., 2014, Proceedings of the 29th Annual ACM Symposium on Applied Computing, P1293
   Renieris M, 2003, 18TH IEEE INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING, PROCEEDINGS, P30, DOI 10.1109/ASE.2003.1240292
   Wei W, 2011, SENSORS-BASEL, V11, P4794, DOI 10.3390/s110504794
   Wong WE, 2016, IEEE T SOFTWARE ENG, V42, P707, DOI 10.1109/TSE.2016.2521368
   Yang X., 2012, INT J DISTRIB SENS N, V8, P1
   Zheng HF, 2018, IEEE T SYST MAN CY-S, V48, P2315, DOI 10.1109/TSMC.2017.2734886
NR 16
TC 1
Z9 2
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 21
BP 29881
EP 29898
DI 10.1007/s11042-018-6603-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JR2TZ
UT WOS:000499485200014
DA 2024-07-18
ER

PT J
AU Chai, XL
   Zhang, JT
   Gan, ZH
   Zhang, YS
AF Chai, Xiuli
   Zhang, Jitong
   Gan, Zhihua
   Zhang, Yushu
TI Medical image encryption algorithm based on Latin square and memristive
   chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Medical image; Latin square; Chaotic system
ID DNA ENCRYPTION; GENETIC ALGORITHM; SCHEME; MAP; SUBSTITUTION;
   PERMUTATION; SECURITY; DESIGN; MODEL
AB Medical image encryption may help protect medical privacy. In this paper, we propose a new medical image encryption scheme combined Latin square and chaotic system. The architecture of permutation and diffusion is adopted. Using Latin square and the plain image information, permutation based on plain image and Latin square (PPILS) is presented to shuffle the pixels of the plain image to different rows and columns, effectively weaken the strong correlations between adjacent pixels, and different images have different permutation effect. To improve the encryption effect, bi-directional adaptive diffusion is proposed to spread little change of plain images to the entire pixels of cipher images. Chaotic sequences employed in permutation and diffusion are generated from the four-dimensional memristive chaotic system, its initial values are computed by SHA 256 hash value of the plain image, and thus the proposed algorithm may withstand known-plaintext and chosen-plaintext attacks. Simulation results and performance analyses show that our image encryption scheme has good security and robustness, and it may be applied for medical image encryption applications.
C1 [Chai, Xiuli; Zhang, Jitong] Henan Univ, Sch Comp & Informat Engn, Henan Key Lab Big Data Anal & Proc, Kaifeng 475004, Peoples R China.
   [Gan, Zhihua] Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
   [Zhang, Yushu] Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.
   [Zhang, Yushu] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
C3 Henan University; Henan University; Chongqing University of Posts &
   Telecommunications; Nanjing University of Aeronautics & Astronautics
RP Gan, ZH (corresponding author), Henan Univ, Sch Software, Kaifeng 475004, Peoples R China.
EM gzh@henu.edu.cn
RI liu, miao/KGL-7043-2024
OI gan, zhihua/0000-0002-1138-1887
FU National Natural Science Foundation of China [41571417, U1604145,
   61802111, 61872125, 61871175]; Science and Technology Foundation of
   Henan Province of China [182102210027, 182102410051]; China Postdoctoral
   Science Foundation [2018 T110723]; Key Scientific Research Projects for
   Colleges and Universities of Henan Province [19A413001]; Research
   Foundation of Henan University [xxjc20140006]; Engineering Research
   Center of Mobile Communications, Ministry of Education
   [cqupt-mct-201901]
FX All the authors are deeply grateful to the editors for smooth and fast
   handling of the manuscript. The authors would also like to thank the
   anonymous referees for their valuable suggestions to improve the quality
   of this paper. The authors also thank Dr. Daojun Han for his hard work
   in the revised manuscript. This work is supported by the National
   Natural Science Foundation of China (Grant No. 41571417, U1604145,
   61802111, 61872125, 61871175), Science and Technology Foundation of
   Henan Province of China (Grant No. 182102210027, 182102410051), China
   Postdoctoral Science Foundation (Grant No. 2018 T110723, 2016 M602235),
   Key Scientific Research Projects for Colleges and Universities of Henan
   Province (Grant No. 19A413001), the Research Foundation of Henan
   University (Grant No. xxjc20140006), and Engineering Research Center of
   Mobile Communications, Ministry of Education (Grant No.
   cqupt-mct-201901).
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Ahmad J, 2016, MULTIMED TOOLS APPL, V75, P12669, DOI 10.1007/s11042-016-3436-9
   Ahmad M, 2015, ADV INTELL SYST, V327, P481, DOI 10.1007/978-3-319-11933-5_53
   Ahmed F, 2014, WIRELESS PERS COMMUN, V77, P2771, DOI 10.1007/s11277-014-1667-5
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Anees A, 2014, COMMUN NONLINEAR SCI, V19, P3106, DOI 10.1016/j.cnsns.2014.02.011
   Cao WJ, 2017, SIGNAL PROCESS, V132, P96, DOI 10.1016/j.sigpro.2016.10.003
   Chai XL, 2017, CHINESE PHYS B, V26, DOI 10.1088/1674-1056/26/2/020504
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chai XL, 2019, NEURAL COMPUT APPL, V31, P219, DOI 10.1007/s00521-017-2993-9
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, SIGNAL PROCESS-IMAGE, V52, P6, DOI 10.1016/j.image.2016.12.007
   Chai XL, 2017, SIGNAL PROCESS, V134, P35, DOI 10.1016/j.sigpro.2016.11.016
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2015, NONLINEAR DYNAM, V81, P1151, DOI 10.1007/s11071-015-2057-6
   Chen JX, 2019, NONLINEAR DYNAM, V96, P301, DOI 10.1007/s11071-019-04791-3
   Chen L, 2015, COMPUT BIOL MED, V65, P69, DOI 10.1016/j.compbiomed.2015.07.024
   Chen X, 2017, SAUDI J BIOL SCI, V24, P1821, DOI 10.1016/j.sjbs.2017.11.023
   CHUA LO, 1976, P IEEE, V64, P209, DOI 10.1109/PROC.1976.10092
   Dai Y, 2016, INT J PATTERN RECOGN, V30, DOI 10.1142/S0218001416570019
   Dömösi P, 2015, STUD SCI MATH HUNG, V52, P221, DOI 10.1556/012.2015.52.2.1309
   Dzwonkowski M, 2019, IEEE T IMAGE PROCESS, V28, P371, DOI 10.1109/TIP.2018.2868388
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P27919, DOI 10.1007/s11042-018-5974-9
   Hu GQ, 2017, NONLINEAR DYNAM, V88, P1305, DOI 10.1007/s11071-016-3311-2
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Hua ZY, 2018, SIGNAL PROCESS, V144, P134, DOI 10.1016/j.sigpro.2017.10.004
   Huang XL, 2014, MULTIMED TOOLS APPL, V72, P57, DOI 10.1007/s11042-012-1331-6
   Huang XL, 2014, COMMUN NONLINEAR SCI, V19, P4094, DOI 10.1016/j.cnsns.2014.04.012
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P15851, DOI 10.1007/s11042-017-5159-y
   Laiphrakpam DS, 2017, OPTIK, V147, P88, DOI 10.1016/j.ijleo.2017.08.028
   Li C., 2015, IEICE ELECTRON EXPR, V12
   Li CQ, 2018, IEEE MULTIMEDIA, V25, P46, DOI 10.1109/MMUL.2018.2873472
   Li CQ, 2018, IEEE ACCESS, V6, P75834, DOI 10.1109/ACCESS.2018.2883690
   Li CQ, 2017, IEEE MULTIMEDIA, V24, P64, DOI 10.1109/MMUL.2017.3051512
   Liu DD, 2018, SIGNAL PROCESS, V151, P130, DOI 10.1016/j.sigpro.2018.05.008
   Liu GY, 2016, NEURAL COMPUT APPL, V27, P687, DOI 10.1007/s00521-015-1888-x
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   Liu JY, 2018, MULTIMED TOOLS APPL, V77, P10217, DOI 10.1007/s11042-017-5406-2
   Liu JZ, 2018, MULTIMED TOOLS APPL, V77, P22787, DOI 10.1007/s11042-017-5534-8
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Liu YS, 2015, INT J BIFURCAT CHAOS, V25, DOI 10.1142/S0218127415501886
   Luo YL, 2018, NONLINEAR DYNAM, V93, P1165, DOI 10.1007/s11071-018-4251-9
   Machkour M, 2015, 3D RES, V6, DOI 10.1007/s13319-015-0068-1
   Moumen A, 2015, NONLINEAR DYNAM, V82, P1475, DOI 10.1007/s11071-015-2253-4
   Natiq H, 2018, EUR PHYS J PLUS, V133, DOI 10.1140/epjp/i2018-11834-2
   Nematzadeh H, 2018, OPT LASER ENG, V110, P24, DOI 10.1016/j.optlaseng.2018.05.009
   Norcen R, 2003, COMPUT BIOL MED, V33, P277, DOI 10.1016/S0010-4825(02)00094-X
   Pal SK, 2010, J DISCRET MATH SCI C, V13, P233, DOI 10.1080/09720529.2010.10698290
   Panduranga HT, 2014, EUR PHYS J-SPEC TOP, V223, P1663, DOI 10.1140/epjst/e2014-02119-9
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Pareek NK, 2016, SOFT COMPUT, V20, P763, DOI 10.1007/s00500-014-1539-7
   Preishuber M, 2018, IEEE T INF FOREN SEC, V13, P2137, DOI 10.1109/TIFS.2018.2812080
   Prousalis DA, 2017, NONLINEAR DYNAM, V90, P1681, DOI 10.1007/s11071-017-3758-9
   Wang MX, 2018, OPT LASER TECHNOL, V108, P558, DOI 10.1016/j.optlastec.2018.07.052
   Wang XY, 2015, NONLINEAR DYNAM, V79, P2449, DOI 10.1007/s11071-014-1824-0
   Wang XY, 2015, OPT LASER ENG, V66, P10, DOI 10.1016/j.optlaseng.2014.08.005
   Wang XY, 2014, NONLINEAR DYNAM, V75, P567, DOI 10.1007/s11071-013-1086-2
   Wen W., 2016, SCI REP, V6, P1, DOI [10.1038/s41598-016-0001-8, DOI 10.1038/S41598-016-0001-8]
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Zhang LY, 2018, INFORM SCIENCES, V430, P228, DOI 10.1016/j.ins.2017.11.021
   Zhang LB, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/940638
   Zhang XP, 2014, SIGNAL PROCESS-IMAGE, V29, P902, DOI 10.1016/j.image.2014.06.012
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhang YS, 2014, INFORM SCIENCES, V289, P254, DOI 10.1016/j.ins.2014.08.005
   Zhang YS, 2013, SIGNAL PROCESS-IMAGE, V28, P292, DOI 10.1016/j.image.2012.12.009
NR 74
TC 83
Z9 86
U1 6
U2 92
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35419
EP 35453
DI 10.1007/s11042-019-08168-x
EA OCT 2019
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000490846300002
DA 2024-07-18
ER

PT J
AU Liao, HQ
   Wen, GH
   Hu, Y
   Wang, CJ
AF Liao, Huiqiang
   Wen, Guihua
   Hu, Yang
   Wang, ChangJun
TI Convolutional herbal prescription building method from multi-scale
   facial features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural networks; Face; Prescription; Traditional Chinese
   medicine
ID NEURAL-NETWORKS; MEDICINE; SEGMENTATION; PATTERN; MODEL; TCM
AB In Traditional Chinese Medicine (TCM), facial features are important basis for diagnosis and treatment. A doctor of TCM can prescribe according to a patient's physical indicators such as face, tongue, voice, symptoms, pulse. Previous works analyze and generate prescription according to symptoms. However, research work to mine the association between facial features and prescriptions has not been found for the time being. In this work, we try to use deep learning methods to mine the relationship between the patient's face and herbal prescriptions (TCM prescriptions), and propose to construct convolutional neural networks that generate TCM prescriptions according to the patient's face image. It is a novel and challenging job. In order to mine features from different granularities of faces, we design a multi-scale convolutional neural network based on three-grained face, which mines the patient's face information from the organs, local regions, and the entire face. Our experiments show that convolutional neural networks can learn relevant information from face to prescribe, and the multi-scale convolutional neural networks based on three-grained face perform better.
C1 [Liao, Huiqiang; Wen, Guihua; Hu, Yang] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Wang, ChangJun] Guangdong Gen Hosp, Dept Tradit Chinese Med, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology; Guangdong Academy of Medical
   Sciences & Guangdong General Hospital
RP Wen, GH (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
EM huiqiangliao@163.com; crghwen@scutedu.cn; superhy199148@hotmail.com;
   gzwchj@126.com
RI Liao, Hui/IQU-4142-2023
OI Hu, Yang/0000-0002-4856-5014
FU China National Science Foundation [60973083, 61273363]; Science and
   Technology Planning Project of Guangdong Province [2014A010103009,
   2015A020217002]; Guangzhou Science and Technology Planning Project
   [201504291154480, 201604020179, 201803010088]
FX This study was supported by the China National Science Foundation
   (60973083, 61273363), Science and Technology Planning Project of
   Guangdong Province (2014A010103009, 2015A020217002), and Guangzhou
   Science and Technology Planning Project (201504291154480, 201604020179,
   201803010088).
CR [Anonymous], DICT TRADITIONAL CHI
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chaabouni S, 2017, MULTIMED TOOLS APPL, V76, P22527, DOI 10.1007/s11042-017-4796-5
   Chen NC, 2017, IEEE INT CONGR BIG, P1, DOI 10.1109/BigDataCongress.2017.10
   Cheung F, 2011, NATURE, V480, pS82, DOI 10.1038/480S82a
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   DEHAN L, 2014, 2014 INT C INF SCI E, V1, P453, DOI DOI 10.1109/INFOSEEE.2014.6948152
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hon M, 2017, IEEE INT C BIOINFORM, P1166, DOI 10.1109/BIBM.2017.8217822
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Jain V., 2010, Fddb: A benchmark for face detection in unconstrained settings
   Jones AL, 2018, EVOL HUM BEHAV, V39, P19, DOI 10.1016/j.evolhumbehav.2017.09.005
   Kassim YM, 2017, IEEE IMAGE PROC, P580, DOI 10.1109/ICIP.2017.8296347
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu BY, 2012, STAT MED, V31, P653, DOI 10.1002/sim.4417
   Peng YJ, 2019, MULTIMED TOOLS APPL, V78, P10965, DOI 10.1007/s11042-018-6523-2
   Qiu J, 2007, NATURE, V448, P126, DOI 10.1038/448126a
   Sekaran K, 2020, MULTIMED TOOLS APPL, V79, P10233, DOI 10.1007/s11042-019-7419-5
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stanitsas P, 2017, IEEE IMAGE PROC, P1367, DOI 10.1109/ICIP.2017.8296505
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wang J, 2017, IEEE T MED IMAGING, V36, P1172, DOI 10.1109/TMI.2017.2655486
   Weng H, 2017, LECT NOTES COMPUT SC, V10594, P170, DOI 10.1007/978-3-319-69182-4_18
   Weng JC, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P233, DOI 10.1145/3083187.3083226
   Xie D, 2017, 2017 IEEE 19TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM)
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu ZP, 2017, IEEE INT C BIOINFORM, P745, DOI 10.1109/BIBM.2017.8217748
   Yao L, 2018, IEEE T KNOWL DATA EN, V30, P1007, DOI 10.1109/TKDE.2017.2787158
   Yao L, 2015, J BIOMED INFORM, V58, P260, DOI 10.1016/j.jbi.2015.10.012
   YIQIN W, 2012, CHIN ARCH TRADIT CHI, V30, P349
   Yu LQ, 2017, IEEE T MED IMAGING, V36, P994, DOI 10.1109/TMI.2016.2642839
   Yu T, 2017, ARTIF INTELL MED, V77, P48, DOI 10.1016/j.artmed.2017.04.001
   Yuan YD, 2017, IEEE T MED IMAGING, V36, P1876, DOI 10.1109/TMI.2017.2695227
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang ML, 2014, IEEE T KNOWL DATA EN, V26, P1819, DOI 10.1109/TKDE.2013.39
   Zhang Nevin L., 2012, New Frontiers in Applied Data Mining. PAKDD 2011 International Workshops. Revised Selected Papers, P353, DOI 10.1007/978-3-642-28320-8_30
   Zhao XM, 2018, MED IMAGE ANAL, V43, P98, DOI 10.1016/j.media.2017.10.002
   Zhao Y, 2017, MED IMAGE ANAL, V42, P200, DOI 10.1016/j.media.2017.08.005
   ZHENG G, 2014, PRESCRIPTION ANAL MI, P97
   Zhu XY, 2020, MULTIMED TOOLS APPL, V79, P1585, DOI 10.1007/s11042-019-08158-z
NR 49
TC 7
Z9 8
U1 5
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35665
EP 35688
DI 10.1007/s11042-019-08118-7
EA OCT 2019
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000489940100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cao, YC
   Lu, XB
AF Cao, Yichao
   Lu, Xiaobo
TI Learning spatial-temporal representation for smoke vehicle detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoke vehicle detection; CNN; LSTM; Spatial-temporal representation
ID FEATURE-SELECTION; NEURAL-NETWORK; VIDEO
AB Vehicle exhaust emissions are notorious for being unhealthy both for humans and the environment. Smoke vehicle, emitting excess levels of visible black smoke, is representative heavy pollution vehicle. It is a challenging task to recognize smoke vehicles from traffic surveillance due to the large variance of smoke color, texture, and interference. To solve this problem, this paper proposes smoke vehicle detection methods by learning spatial-temporal representation from image sequences. Firstly, motion detection algorithm is used to obtain the rear section of vehicle that need to be identified. Then, space information of each suspected frame is captured by Inception V3 convolutional neural network (CNN), and a temporal Multi-Layer Perception (MLP) or Long Short Term Memory network (LSTM) is used to effectively train the smoke vehicle model. The first method attempts to jointly model spatial-temporal clues for smoke vehicle detection in the video by fully-connected layers. The second method aims to learn temporal dependencies between video frames with LSTM. LSTM networks could combine image information in video over a longer period of time. Experimental results on our dataset have shown that the LSTM-based model achieve a highly accuracy of 97.6875%, and there is 9.25% improvement over the single frame model.
C1 [Cao, Yichao; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Cao, Yichao; Lu, Xiaobo] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.; Lu, XB (corresponding author), Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
RI 曹, 毅超/HHS-1274-2022
OI Cao, Yichao/0000-0003-2997-4012
FU National Natural Science Foundation of China [61871123]; Key Research
   and Development Program in Jiangsu Province [BE2016739]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX This work was supported by the National Natural Science Foundation of
   China (No. 61871123), Key Research and Development Program in Jiangsu
   Province (No. BE2016739) and a Project Funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions.
CR [Anonymous], 2017, ARXIV170809545
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Cardoso G. C., 2014, U.S. Patent, Patent No. 8854223
   Chen JY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P898, DOI 10.1145/2964284.2964314
   Favorskaya M, 2015, PROCEDIA COMPUT SCI, V60, P671, DOI 10.1016/j.procs.2015.08.205
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Gubbi J, 2009, FIRE SAFETY J, V44, P1110, DOI 10.1016/j.firesaf.2009.08.003
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu Y, 2018, MULTIMED TOOLS APPL, V77, P1
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji Z, 2019, PATTERN RECOGN LETT, V120, P89, DOI 10.1016/j.patrec.2019.01.010
   Kaabi R, 2017, 2017 INTERNATIONAL CONFERENCE ON SMART, MONITORED AND CONTROLLED CITIES (SM2C), P81, DOI 10.1109/SM2C.2017.8071823
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YH, 2017, SCI TOTAL ENVIRON, V586, P512, DOI 10.1016/j.scitotenv.2017.01.215
   Mozer M. C., 1995, Complex Systems, V3, P349
   Pyykönen P, 2016, INT C INTELL COMP CO, P233, DOI 10.1109/ICCP.2016.7737152
   Raj M, 2018, NEURAL COMPUT APPL, V30, P1747, DOI 10.1007/s00521-016-2744-3
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Robinson A., 1987, UTILITY DRIVEN DYNAM
   Salehinejad H., 2017, Recent advances in recurrent neural networks, DOI DOI 10.48550/ARXIV.1801.01078
   Semwal VB, 2019, ADV INTELL SYST COMP, V748, P135, DOI 10.1007/978-981-13-0923-6_12
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Song XM, 2018, ACM/SIGIR PROCEEDINGS 2018, P5, DOI 10.1145/3209978.3209996
   Song XM, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P753, DOI 10.1145/3123266.3123314
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tao D., 2017, IEEE T CIRCUITS SYST, P1
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Tao HJ, 2019, SIGNAL IMAGE VIDEO P, V13, P217, DOI 10.1007/s11760-018-1348-z
   Tao HJ, 2018, MULTIMED TOOLS APPL, V77, P32153, DOI 10.1007/s11042-018-6248-2
   Tao HJ, 2018, PROC SPIE, V10806, DOI 10.1117/12.2502873
   Tao HJ, 2018, SIGNAL IMAGE VIDEO P, V12, P1061, DOI 10.1007/s11760-018-1254-4
   Tatikonda RR, 2017, ADV INTELL SYST, V469, P109, DOI 10.1007/978-981-10-1678-3_10
   Tian HD, 2011, IEEE INT WORKSH MULT
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Toreyin B. Ugur, 2005, 2005 13th European Signal Processing Conference, P1
   WERBOS PJ, 1988, NEURAL NETWORKS, V1, P339, DOI 10.1016/0893-6080(88)90007-X
   Yin MX, 2019, MULTIMED TOOLS APPL, V78, P237, DOI 10.1007/s11042-017-5561-5
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
NR 49
TC 13
Z9 13
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27871
EP 27889
DI 10.1007/s11042-019-07926-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000049
DA 2024-07-18
ER

PT J
AU Hu, CH
   Lu, XB
   Wu, F
   Wu, SS
   Jing, XY
AF Hu, Chang-Hui
   Lu, Xiao-Bo
   Wu, Fei
   Wu, Song-Song
   Jing, Xiao-Yuan
TI General logarithm difference model for severe illumination variation
   face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Logarithm difference; Severe illumination variations; Positive and
   negative logarithm differences; Illumination variation face recognition
ID COMPENSATION; NORMALIZATION; HALLUCINATION; FRAMEWORK; RETINEX; IMAGES
AB Logarithm difference is the subtraction of the center pixel and its neighbor in the face local region. The commonly-used assumption of the illumination invariant measure is that illumination intensities of neighbor pixels are approximately equal in the face local region. However, logarithm difference based illumination invariant measure performs unsatisfactorily under severe illumination variations, since severe varying illumination cause differences of illumination intensities are large in the face local region. In this paper, the general logarithm difference model (GLDM) is proposed to tackle severe illumination variations. In spired by the fact that a logarithm difference is the subtraction of two neighbor pixels, which may be a positive or negative numerical value, we divide a face local region into a positive region and a negative region, and the GLDM is developed by integrating positive and negative logarithm differences. Then, the multiscale logarithm difference edge-maps (MSLDE) [7] is employed as the test-bed, and the proposed GLDM is introduced into MSLDE to form General MSLDE (GMSLDE). Further, the proposed GMSLDE method is integrated with the advanced deep learning model VGG to obtain GMSLDE-VGG. Finally, the performance of GMSLDE and GMSLDE-VGG are verified not only on the Extended Yale B and CMU PIE face databases with severe illumination variations, but also on the LFW and our self-built Driver face databases with moderate illumination variations. The experimental results indicate that the proposed GLDM can efficiently improve the performance of logarithm difference edge-map against illumination variations, especially for severe illumination variations.
C1 [Hu, Chang-Hui; Wu, Fei; Wu, Song-Song; Jing, Xiao-Yuan] Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Jiangsu, Peoples R China.
   [Hu, Chang-Hui; Wu, Fei; Wu, Song-Song; Jing, Xiao-Yuan] Nanjing Univ Posts & Telecommun, Coll Artificial Intelligence, Nanjing 210023, Jiangsu, Peoples R China.
   [Hu, Chang-Hui; Lu, Xiao-Bo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Southeast University - China
RP Hu, CH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Automat, Nanjing 210023, Jiangsu, Peoples R China.; Hu, CH (corresponding author), Nanjing Univ Posts & Telecommun, Coll Artificial Intelligence, Nanjing 210023, Jiangsu, Peoples R China.; Hu, CH (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM hchnjupt@126.com
RI Hu, Chang-Hui/AAD-8822-2020; Zhang, Yunxuan/IXD-9283-2023
OI Hu, Chang-Hui/0000-0002-7291-4931
FU National Natural Science Foundation of China [61802203]; Natural Science
   Foundation of Jiangsu Province [BK20180761]; China Postdoctoral Science
   Foundation [2019 M651653]; NUPTSF [NY218119]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61802203), Natural Science Foundation of Jiangsu
   Province (Grant No. BK20180761), China Postdoctoral Science Foundation
   (Grant No. 2019 M651653) and NUPTSF (Grant No. NY218119).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Baradarani A, 2013, PATTERN RECOGN, V46, P57, DOI 10.1016/j.patcog.2012.06.007
   Cao X, 2012, PATTERN RECOGN, V45, P1299, DOI 10.1016/j.patcog.2011.09.010
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Chen WL, 2006, IEEE T SYST MAN CY B, V36, P458, DOI 10.1109/TSMCB.2005.857353
   Choi SI, 2007, PATTERN RECOGN, V40, P2118, DOI 10.1016/j.patcog.2006.11.020
   Dandpat S, 2018, P INT C EL EL COMP C
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Dustdar S, 2013, 2013 2ND INTERNATIONAL WORKSHOP ON GREEN AND SUSTAINABLE SOFTWARE (GREENS), P1, DOI 10.1109/GREENS.2013.6606415
   Fang SS, 2018, MULTIMED TOOLS APPL, V77, P2807, DOI 10.1007/s11042-017-4412-8
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Horn BKP., 1997, ROBOT VISION
   Hu CH, 2019, IEEE T IMAGE PROCESS, V28, P2624, DOI 10.1109/TIP.2018.2887346
   Hu CH, 2017, MULTIMED TOOLS APPL, V76, P26523, DOI 10.1007/s11042-016-4180-x
   Hu CH, 2017, PATTERN RECOGN, V64, P60, DOI 10.1016/j.patcog.2016.10.029
   Huang GS, 2007, 2007 7TH IEEE CONFERENCE ON NANOTECHNOLOGY, VOL 1-3, P7, DOI 10.1109/NANO.2007.4601129
   Jian MW, 2018, COMPUT IND, V99, P110, DOI 10.1016/j.compind.2018.03.034
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Jian MW, 2014, INFORM SCIENCES, V269, P60, DOI 10.1016/j.ins.2014.01.019
   Jian MW, 2014, SIGNAL PROCESS, V100, P9, DOI 10.1016/j.sigpro.2014.01.004
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jian MW, 2013, PATTERN RECOGN, V46, P3091, DOI 10.1016/j.patcog.2013.03.020
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Lai ZR, 2015, IEEE T IMAGE PROCESS, V24, P1735, DOI 10.1109/TIP.2015.2409988
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Park YK, 2008, SIGNAL PROCESS, V88, P1929, DOI 10.1016/j.sigpro.2008.01.028
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Qing LY, 2005, INT J PATTERN RECOGN, V19, P513, DOI 10.1142/S0218001405004186
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shan SG, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P157
   Shim H, 2008, IEEE T IMAGE PROCESS, V17, P1331, DOI 10.1109/TIP.2008.925390
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wu Y, 2014, NEUROCOMPUTING, V136, P262, DOI 10.1016/j.neucom.2014.01.006
   Xie XD, 2005, PATTERN RECOGN, V38, P221, DOI 10.1016/j.patcog.2004.07.002
   Xie XH, 2011, IEEE T IMAGE PROCESS, V20, P1807, DOI 10.1109/TIP.2010.2097270
   Zhang TP, 2009, PATTERN RECOGN, V42, P251, DOI 10.1016/j.patcog.2008.03.017
   Zhang TP, 2009, IEEE T IMAGE PROCESS, V18, P2599, DOI 10.1109/TIP.2009.2028255
   Zhang WM, 2019, IEEE T PATTERN ANAL, V41, P611, DOI 10.1109/TPAMI.2018.2803179
   Zhang YB, 2020, MIN PROC EXT MET REV, V41, P75, DOI 10.1080/08827508.2018.1538986
   Zhu JY, 2017, PATTERN RECOGN, V66, P313, DOI 10.1016/j.patcog.2016.12.029
NR 44
TC 1
Z9 1
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27425
EP 27447
DI 10.1007/s11042-019-07830-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000029
DA 2024-07-18
ER

PT J
AU Li, JH
   Wang, SW
   Wang, YT
   Tang, Z
AF Li, Jiahui
   Wang, Siwei
   Wang, Yongtao
   Tang, Zhi
TI Synthesizing data for text recognition with style transfer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic data; Text recognition; Style transfer; Data augmentation
AB Most of the existing datasets for scene text recognition merely consist of a few thousand training samples with a very limited vocabulary, which cannot meet the requirement of the state-of-the-art deep learning based text recognition methods. Meanwhile, although the synthetic datasets (e.g., SynthText90k) usually contain millions of samples, they cannot fit the data distribution of the small target datasets in natural scenes completely. To address these problems, we propose a word data generating method called SynthText-Transfer, which is capable of emulating the distribution of the target dataset. SynthText-Transfer uses a style transfer method to generate samples with arbitray text content, which preserve the texture of the reference sample in the target dataset. The generated images are not only visibly similar with real images, but also capable of improving the accuracy of the state-of-the-art text recognition methods, especially for the English and Chinese dataset with a large alphabet (in which many characters only appear in few samples, making it hard to learn for sequence models). Moreover, the proposed method is fast and flexible, with a competitive speed among common style transfer methods.
C1 [Li, Jiahui; Wang, Siwei; Wang, Yongtao; Tang, Zhi] Peking Univ, Inst Comp Sci & Technol, Beijing, Peoples R China.
C3 Peking University
RP Wang, YT (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing, Peoples R China.
EM jarveelee@gmail.com; wangsiwei17@pku.edu.cn; wyt@pku.edu.cn;
   tangzhi@pku.edu.cn
RI wang, Xiaoming/KBB-8854-2024
FU National Natural Science Foundation of China [61673029]
FX This work is supported by National Natural Science Foundation of China
   under Grant 61673029. This work is also a research achievement of Key
   Laboratory of Science, Technology and Standard in Press Industry (Key
   Laboratory of Intelligent Press Media Technology).
CR [Anonymous], 2017, Stable and Controllable Neural Texture Synthesis and Style Transfer Using Histogram Losses
   [Anonymous], ICPR MTWI 2018 CHALL
   [Anonymous], 2017, CVPR
   [Anonymous], 2016, ARXIV161204337
   [Anonymous], 2015, NATURE COMMUNICATION
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duck S. Y., 2016, PAINTER NUMBERS
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   He P, 2016, AAAI CONF ARTIF INTE, P3501
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Jaderberg M., 2014, ARXIV
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li YJ, 2017, ADV NEUR IN, V30
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Mishra A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.127
   Ravi S, 2016, PROC INT C LEARN REP
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smith Raymond, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P411, DOI 10.1007/978-3-319-46604-0_30
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
NR 28
TC 2
Z9 2
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29183
EP 29196
DI 10.1007/s11042-018-6656-3
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700043
DA 2024-07-18
ER

PT J
AU Aly, S
   Sayed, A
AF Aly, Saleh
   Sayed, Asmaa
TI Human action recognition using bag of global and local Zernike moment
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action recognition; Global Zernike moments; Local Zernike moments;
   K-means; Bag-of-features
ID INVARIANTS; NETWORK; HISTORY
AB Human action recognition is a fundamental and challenging building block for many computer vision applications. It has been included in many applications such as: video surveillance, human computer interaction and multimedia retrieval systems. Various approaches have been proposed to solve human action recognition problem. Among others, moment-based methods considered as one of the most simple and successful approach. However, moment-based methods take into consideration only global features while neglect the discriminative properties of local features. In this paper, we propose a new efficient method which combine both Global and Local Zernike Moment (GLZM) features based on Bag-of-Features (BoF) technique. Since using only global features are not sufficient to discriminate similar actions like running, walking and jogging, augmenting these features with localized features helps to improve the recognition accuracy. The proposed method first calculate local temporal Motion Energy Images (MEI) by accumulating frame differences of short time consecutive frames. Then, global and local features are calculated using Zernike moments with different polynomial orders to represent global and local motion patterns respectively. Global features are calculated from the whole region of the human performing action while local features focused on localized regions of the human in order to represent local motion information. Both local and global features are preprocessed using whitening transformation, then bag-of-features algorithm is employed to combine those pool of features and represent each action using new GLZM feature descriptor. Finally, we use multi-class Support Vector Machine (SVM) classifier to recognize human actions. In order to validate the proposed method, we perform a set of experiments using three publicly available datasets: Weizmann, KTH and UCF sports action. Experimental results using leave-one-out strategy show that proposed method achieves promising results compared with other state-of-the-art methods.
C1 [Aly, Saleh; Sayed, Asmaa] Aswan Univ, Fac Engn, Dept Elect Engn, Aswan 81542, Egypt.
   [Aly, Saleh] Majmaah Univ, Coll Comp & Informat Sci, Dept Informat Technol, Al Majmaah 11952, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Aswan University; Majmaah University
RP Aly, S (corresponding author), Aswan Univ, Fac Engn, Dept Elect Engn, Aswan 81542, Egypt.; Aly, S (corresponding author), Majmaah Univ, Coll Comp & Informat Sci, Dept Informat Technol, Al Majmaah 11952, Saudi Arabia.
EM saleh@aswu.edu.eg; asmaa.sayed@eng.aswu.edu.eg
RI Aly, Saleh/B-9095-2019
OI Aly, Saleh/0000-0002-1772-4254
FU Deanship of Scientific Research at Majmaah University [1440-99]
FX The first author would like to thank Deanship of Scientific Research at
   Majmaah University for supporting this work under Project Number No.
   1440-99.
CR Ahad MAR, 2016, J MULTIMODAL USER IN, V10, P335, DOI 10.1007/s12193-016-0229-4
   Ahad MAR, 2012, MACH VISION APPL, V23, P255, DOI 10.1007/s00138-010-0298-4
   Ahmad M, 2010, IMAGE VISION COMPUT, V28, P814, DOI 10.1016/j.imavis.2009.09.018
   Al-Azzo F, 2017, INT J ADV COMPUT SC, V8, P13
   Aly S, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE 2019), P52, DOI [10.1109/itce.2019.8646504, 10.1109/ITCE.2019.8646504]
   [Anonymous], 2013, BMVC
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], INT J COMPUTER ENG A
   [Anonymous], 2014 11 INT MULT SYS
   [Anonymous], ACM T INFORM SYST
   [Anonymous], 2008, WSEAS INT C P MATH C
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT J ACII
   [Anonymous], 2008 CVPR 2008 IEEE
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Belouchrani A, 2000, ELECTRON LETT, V36, P2050, DOI 10.1049/el:20001436
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Cheng ZY, 2016, SIGNAL PROCESS, V124, P13, DOI 10.1016/j.sigpro.2015.10.037
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Fan XJ, 2017, PATTERN RECOGN, V64, P399, DOI 10.1016/j.patcog.2016.12.002
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Ji YL, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1510, DOI 10.1145/3240508.3240675
   Lan T, 2011, IEEE INT C COMPUTER, P1
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lei Q, 2018, MULTIMED TOOLS APPL, V77, P11403, DOI 10.1007/s11042-018-5626-0
   Liu L, 2016, 30 AAAI C ART INT
   Liu Y, 2015, 24 INT JOINT C ART I
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YA, 2012, INT C INTEL HUM MACH, P76, DOI 10.1109/IHMSC.2012.114
   Marouf H., 2013, INT J COMPUTER SCI E, V3, P1
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Onofri L, 2014, IET COMPUT VIS, V8, P26, DOI 10.1049/iet-cvi.2013.0015
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Sariyanidi E, 2012, IEEE IMAGE PROC, P585, DOI 10.1109/ICIP.2012.6466927
   Schindler K, 2008, 2008 CVPR 2008 IEEE, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Singla N., 2014, INT J INFORM COMPUTA, V4, P1560
   Somasundaram G, 2014, COMPUT VIS IMAGE UND, V123, P1, DOI 10.1016/j.cviu.2014.01.002
   Su ZX, 2009, SMI 2009: IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P1, DOI 10.1109/SMI.2009.5170156
   Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   Whytock T., 2012, 4th UK Computer Vision (BMVC 2012 Student Workshop), P1
   Wu JS, 2017, IEEE ACCESS, V5, P3322, DOI 10.1109/ACCESS.2017.2675478
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Zhang MX, 2018, SIGNAL PROCESS, V145, P137, DOI 10.1016/j.sigpro.2017.12.008
   Zhen XT, 2014, INFORM SCIENCES, V281, P295, DOI 10.1016/j.ins.2014.05.021
NR 55
TC 16
Z9 18
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24923
EP 24953
DI 10.1007/s11042-019-7674-5
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900057
DA 2024-07-18
ER

PT J
AU Dhassi, Y
   Aarab, A
AF Dhassi, Younes
   Aarab, Abdellah
TI Robust visual tracking based on adaptive gradient descent optimization
   of a cost function with parametric models of appearance and geometry
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Gaussian mixture model; Expectation maximization;
   Gradient descent
ID MEAN-SHIFT
AB In the field of visual tracking, there are many issues to consider which make the development of a robust tracking method very difficult, among these complications; the appearance change of the target, the fast motion, the background clutter, the camera motion, scale variation and the in plane Rotation. To override these problems, we develop an effective general framework for object tracking that addresses most of these issues. First the tracking problem is formulated in the form of a robust cost function which is a composition of the appearance and dynamic model, this formulation ensures the integration of the appearance and motion informations. Second the minimization is accomplished by the gradient descent optimization with adaptive step size prediction, the step size adaptation accelerates the optimization process and increases the accuracy. Throughout, we present experimental results made on different challenging sequences, the experimentations results demonstrate the efficiency and effectiveness of our methods.
C1 [Dhassi, Younes; Aarab, Abdellah] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, Dept Phys, Lab Elect Signals Syst & Comp, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Dhassi, Y (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, Dept Phys, Lab Elect Signals Syst & Comp, Fes, Morocco.
EM dyounes2003@gmail.com
RI DHASSI, Younes/JLM-7247-2023
CR Ali A, 2016, FRONT COMPUT SCI-CHI, V10, P167, DOI 10.1007/s11704-015-4246-3
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Choe GM, 2015, MULTIMED TOOLS APPL, V74, P7595, DOI 10.1007/s11042-014-1993-3
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Dhassi Y, 2018, MULTIMED TOOLS APPL, V77, P1
   Iswanto IA, 2017, PROCEDIA COMPUT SCI, V116, P587, DOI 10.1016/j.procs.2017.10.010
   Jeong J, 2017, EXPERT SYST APPL, V79, P194, DOI 10.1016/j.eswa.2017.02.043
   Karasulu B, 2011, MULTIMED TOOLS APPL, V55, P677, DOI 10.1007/s11042-010-0591-2
   Karavasilis V, 2015, COMPUTER VISION IMAG, P1
   Klein S, 2009, INT J COMPUT VISION, V81, P227, DOI 10.1007/s11263-008-0168-y
   Kong J, 2016, NEUROCOMPUTING, V213, P155, DOI 10.1016/j.neucom.2016.03.100
   Leichter I, 2010, COMPUT VIS IMAGE UND, V114, P400, DOI 10.1016/j.cviu.2009.12.006
   Li G, 2008, IM PROC ICIP 2008 15
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Lin SFD, 2015, IET IMAGE PROCESS, V9, P959, DOI 10.1049/iet-ipr.2014.0666
   Liu B, 2012, PROC INT CONF ANTI
   Liu Z, 2016, SIGNAL IMAGE VIDEO P, V10, P359, DOI 10.1007/s11760-015-0749-5
   Pan Z, 2018, J PARALLEL DISTR COM, V120, P182, DOI 10.1016/j.jpdc.2018.06.012
   Shi Y, 2015, OPTIK, V126, P937, DOI 10.1016/j.ijleo.2015.02.077
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   van Mourik MJW, 2019, J AM SOC ECHOCARDIOG, V32, P65, DOI 10.1016/j.echo.2018.09.007
   Villagra J, 2018, INTELLIGENT VEHICLES: ENABLING TECHNOLOGIES AND FUTURE DEVELOPMENTS, P275, DOI 10.1016/B978-0-12-812800-8.00008-4
   Vysochanskij D., 1980, Theory of Probability and Mathematical Statistics, V21, P25
   Wang HL, 2015, AUTOMATICA, V55, P294, DOI 10.1016/j.automatica.2015.02.029
   Yang WM, 2018, IEEE ACCESS, V6, P14790, DOI 10.1109/ACCESS.2018.2813374
   Ye L, 2012, P 21 INT C PATT REC
   Yu WS, 2017, MULTIMED TOOLS APPL, V76, P10973, DOI 10.1007/s11042-016-3472-5
   Zhi-Qiang H, 2014, INTELLIGENT SYSTEMS
   Zhou ZP, 2017, MULTIMED TOOLS APPL, V76, P2979, DOI 10.1007/s11042-015-3211-3
NR 32
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21349
EP 21373
DI 10.1007/s11042-019-7386-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400038
DA 2024-07-18
ER

PT J
AU Fatemi, M
   Safayani, M
AF Fatemi, Masoud
   Safayani, Mehran
TI Joint sentiment/topic modeling on text data using a boosted restricted
   Boltzmann Machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Topic modeling; Sentiment analysis; Neural networks; Restricted
   Boltzmann Machine; Probabilistic model
AB Recently by the development of the Internet and the Web, different types of social media such as web blogs become an immense source of text data. Through the processing of these data, it is possible to discover practical information about different topics, individual's opinions and a thorough understanding of the society. Therefore, applying models which can automatically extract the subjective information from documents would be efficient and helpful. Topic modeling methods and sentiment analysis are the raised topics in natural language processing and text mining fields. In this paper a new structure for joint sentiment-topic modeling based on a Restricted Boltzmann Machine (RBM) which is a type of neural networks is proposed. By modifying the structure of RBM as well as appending a layer which is analogous to sentiment of text data to it, we propose a generative structure for joint sentiment topic modeling based on neural networks. The proposed method is supervised and trained by the Contrastive Divergence algorithm. The new attached layer in the proposed model is a layer with the multinomial probability distribution which can be used in text data sentiment classification or any other supervised application. The proposed model is compared with existing models in the experiments such as evaluating as a generative model, sentiment classification, information retrieval and the corresponding results demonstrate the efficiency of the method.
C1 [Fatemi, Masoud; Safayani, Mehran] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
C3 Isfahan University of Technology
RP Safayani, M (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
EM m.fatemi@ec.iut.ac.ir; safayani@cc.iut.ac.ir
OI Fatemi, Masoud/0000-0002-3000-0381
CR [Anonymous], 2005, AISTATS BRIDGETOWN B
   [Anonymous], 2007, Latent Semantic Analysis: A Road to Meaning. Ed. by
   [Anonymous], INT J COMPUTER APPL
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blitzer J., 2007, Proceedings of the 45th annual meeting of the association of computational linguistics, V45, P440
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Hinton G. E., 2012, Neural networks: tricks of the trade, P599
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton GE, 2009, INT C NEURAL INF PRO, P1607
   Jo Yohan, 2011, P 4 ACM INT C WEB SE, P815, DOI DOI 10.1145/1935826.1935932
   Lang K., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P331
   Larochelle H, 2011, NEURAL AUTOREGRESSIV, P29
   Larochelle H., 2012, NIPS
   Lewis DD, 2004, J MACH LEARN RES, V5, P361
   Lin CH, 2012, IEEE T KNOWL DATA EN, V24, P1134, DOI 10.1109/TKDE.2011.48
   Lyang T, PATTERN ANAL APPL
   Mohr JW, 2013, POETICS, V41, P545, DOI 10.1016/j.poetic.2013.10.001
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Pang B, 2004, P ACL POL DAT V2 0
   Qin ZC, 2016, PATTERN ANAL APPL, V19, P1007, DOI 10.1007/s10044-015-0478-y
   Smolensky P., 1986, Information processing in dynamical systems: Foundations of harmony theory
   Woodford O, 2013, TECH REP
NR 23
TC 8
Z9 9
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 20637
EP 20653
DI 10.1007/s11042-019-7427-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400004
DA 2024-07-18
ER

PT J
AU Huang, PC
   Chang, CC
   Li, YH
   Liu, YJ
AF Huang, Peng-Cheng
   Chang, Chin-Chen
   Li, Yung-Hui
   Liu, Yanjun
TI High-payload secret hiding mechanism for QR codes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret hiding; QR code; Turtle shell; Reed-Solomon code
AB QR code is an important approach of information transmission and is widely used in our daily life. As a public patent, the message embeded in a QR code can be easily decoded by any QR code reader, thus can lead to information leaks when delivering the secret message with QR code. To overcome this weakness, we exploited the characteristics of Reed-Solomon code and turtle shell matrix to propose a simple yet efficient data embedding mechanism to hide secret messages in the QR code while maintaining the marked QR code valid. Different from the traditional schemes, the proposed scheme of this paper hides the secret messages without sacrificing the error correction capacity of QR code and is able to achieve a higher secret payload. Meanwhile, the public message of generated marked QR code still can be decoded by standard QR code reader. Such nature will reduce the risk due to the curiosity of the malicious users. Experiments were performed to evaluate the performance of the proposed scheme. Experimental results showed that the proposed scheme is robust to several common image attacks.
C1 [Huang, Peng-Cheng] Xiamen Univ Technol, Dept Comp Sci, 600 Ligong Rd, Xiamen 361024, Fujian, Peoples R China.
   [Huang, Peng-Cheng; Chang, Chin-Chen; Liu, Yanjun] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Li, Yung-Hui] Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Zhongda Rd, Taoyuan 32001, Taiwan.
C3 Xiamen University of Technology; Feng Chia University; National Central
   University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM alan3c@gmail.com
RI 刘, 严君/GZL-5764-2022; Chang, Ching-Chun/JAN-6210-2023; zhang,
   ling/JXW-6931-2024; liu, yan/HGV-1365-2022; liu, yan/HCI-5542-2022
CR [Anonymous], 2016, PROC IEEE INT C MULT
   Bui TV, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P520, DOI 10.1109/IIH-MSP.2014.135
   Chang CC, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P89, DOI 10.1109/IIH-MSP.2014.29
   Chiang YJ, 2013, KSII T INTERNET INF, V7, P2527, DOI 10.3837/tiis.2013.10.012
   Cox R., 2012, QArt codes
   ELIAS P, 1991, IEEE T INFORM THEORY, V37, P5, DOI 10.1109/18.61123
   Erlangga W, 2016, INT WORKSH DIG WAT, P327
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J, 2006, IEEE T INF FOREN SEC, V1, P102, DOI 10.1109/TIFS.2005.863487
   Huang PC, 2018, KSII T INTERNET INF, V12, P2348
   Inc. D-W, 2003, QR COD STAND
   Lin PY, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0155-0
   Liu L, 2017, MULTIMED TOOLS APPL, V76, P12233, DOI 10.1007/s11042-016-3624-7
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Teraura N., 2012, 2012 IEEE 1st Global Conference on Consumer Electronics (GCCE 2012), P652, DOI 10.1109/GCCE.2012.6379943
   Tkachenko I, 2016, IEEE T INF FOREN SEC, V11, P571, DOI 10.1109/TIFS.2015.2506546
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
NR 18
TC 3
Z9 3
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22331
EP 22350
DI 10.1007/s11042-019-7600-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400008
DA 2024-07-18
ER

PT J
AU Li, HZ
   Wang, WQ
   Lv, K
AF Li, Hongzhu
   Wang, Weiqiang
   Lv, Ke
TI N-FTRN: Neighborhoods based fully convolutional network for Chinese text
   line recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chinese text recognition; Fully convolutional network (FCN);
   Connectionist temporal classification (CTC)
ID NEURAL-NETWORK
AB The convolutional recurrent neural network is one of the most popular text recognition methods. Recurrent structures can extract long-term dependencies, but they are time consuming in computation compared with convolutional structures. We argue that the Chinese text line recognition can be performed based on neighbor rather than entire contextual information, and the information extracted from neighborhoods should only be a supplement to the information extracted from character regions. Therefore, we propose a novel neighborhoods based fully convolutional text recognition network (N-FTRN). It first extracts character-level feature sequences from text lines, then uses residual blocks instead of the recurrent structure to utilize contextual information. A reshape layer is applied to enable the network to recognize both vertical and horizontal text lines. Extensive experiments have been conducted to validate the efficiency and effectiveness of the proposed network. Compared with the state-of-the-art methods, we achieve comparable recognition performances on a Chinese scene text competition dataset (TRW) in ICDAR 2015 with much more compact models.
C1 [Li, Hongzhu; Lv, Ke] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Weiqiang] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS
RP Wang, WQ (corresponding author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
EM wqwang@ucas.ac.cn
FU National Key R&D Program of China [2017YFB1002203]; NSFC Key Projects of
   International (Regional) Cooperation and Exchanges [61860206004]
FX This work is supported by National Key R&D Program of China under
   contract No. 2017YFB1002203, and NSFC Key Projects of International
   (Regional) Cooperation and Exchanges under Grant 61860206004.
CR [Anonymous], ARXIV E PRINTS
   [Anonymous], 2014, INF SOFTW TECHNOL
   [Anonymous], 2014, DEEP FEATURES TEXT S
   [Anonymous], ARXIV E PRINTS
   [Anonymous], ARXIV E PRINTS
   [Anonymous], ICDAR 2015 TEXT READ
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], 2014, SYNTHETIC DATA ARTIF
   [Anonymous], 2018, IEEE T PATTERN ANAL
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], ARXIV E PRINTS
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Cheng ZZ, 2018, PROC CVPR IEEE, P5571, DOI 10.1109/CVPR.2018.00584
   Cheng ZZ, 2017, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2017.543
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A., 2006, P 23 INT C MACHINE L, P369
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Grosicki Emmanuele, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1398, DOI 10.1109/ICDAR.2009.184
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He P, 2016, AAAI CONF ARTIF INTE, P3501
   Hinton G. E., 2012, 12070580 ARXIV
   Huang S, 2014, IEEE IMAGE PROC, P3087, DOI 10.1109/ICIP.2014.7025624
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Liu CL, 2002, IEEE T PATTERN ANAL, V24, P1425, DOI 10.1109/TPAMI.2002.1046151
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XQ, 2012, IEEE T MULTIMEDIA, V14, P482, DOI 10.1109/TMM.2011.2177646
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Messina R, 2015, PROC INT CONF DOC, P171
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Shi BG, 2016, PROC CVPR IEEE, P4168, DOI 10.1109/CVPR.2016.452
   Su TH, 2009, PATTERN RECOGN, V42, P167, DOI 10.1016/j.patcog.2008.05.012
   Wang T, 2012, INT C PATT RECOG, P3304
   Wu Y, 2018, SCANNING, DOI 10.1155/2018/3697063
   Wu YC, 2017, PATTERN RECOGN, V65, P251, DOI 10.1016/j.patcog.2016.12.026
   Xie L, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3133
   Xie ZC, 2018, IEEE T PATTERN ANAL, V40, P1903, DOI 10.1109/TPAMI.2017.2732978
   Xu L, 2014, INT J DOC ANAL RECOG, V17, P91, DOI 10.1007/s10032-013-0208-1
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Zecheng Xie, 2016, 2016 23rd International Conference on Pattern Recognition (ICPR). Proceedings, P4011, DOI 10.1109/ICPR.2016.7900261
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 42
TC 3
Z9 4
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22249
EP 22268
DI 10.1007/s11042-019-7410-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400004
DA 2024-07-18
ER

PT J
AU Shabbir, Z
   Irtaza, A
   Javed, A
   Mahmood, MT
AF Shabbir, Zain
   Irtaza, Aun
   Javed, Ali
   Mahmood, Muhammad Tariq
TI Tetragonal Local Octa-Pattern (T-LOP) based image retrieval using
   genetically optimized support vector machines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tetragonal Local Octa-Pattern; Image retrieval; Genetic algorithm; SVM
ID TEXTURE CLASSIFICATION; COLOR; REPRESENTATION; FEATURES; SHAPE
AB The enormous increase in digital image collections motivates the research community to propose powerful Content Based Image Retrieval (CBIR) algorithms to employ in critical scientific domains. In this paper, we have proposed Tetragonal Local Octa-Patterns for CBIR that are based on the direction of center pixel and generate an 8-bit octa-pattern. Neighbors at three diagonal locations are then used to generate Tetragonal Octa-Patterns. In order to enhance the precision, Genetic algorithm has been applied on obtained features to resolve the class imbalance problem for better classification through SVM. Experimental results prove the reliability of method by comparing against state-of-the-art methods in terms of precision and recall.
C1 [Shabbir, Zain] Univ Engn & Technol Lahore, Dept Elect Elect & Commun Engn, Faisalabad Campus, Faisalabad, Pakistan.
   [Irtaza, Aun] Univ Engn & Technol, Dept Comp Sci, Taxila, Pakistan.
   [Javed, Ali] Univ Engn & Technol, Dept Software Engn, Taxila, Pakistan.
   [Mahmood, Muhammad Tariq] Korea Univ Technol & Educ, Sch Comp Sci & Engn, Cheonan, South Korea.
C3 University of Engineering & Technology Taxila; University of Engineering
   & Technology Taxila; Korea University of Technology & Education
RP Shabbir, Z (corresponding author), Univ Engn & Technol Lahore, Dept Elect Elect & Commun Engn, Faisalabad Campus, Faisalabad, Pakistan.
EM zain.shabbir@uet.edu.pk; aun.irtaza@uettaxila.edu.pk;
   ali.javed@uettaxila.edu.pk; tariq@koreatech.ac.kr
RI JAVED, ALI/X-3334-2019; Irtaza, Aun/HTP-2773-2023
OI Irtaza, Aun/0000-0001-7757-5839; Mahmood, Muhammad/0000-0001-6814-3137
CR [Anonymous], ARABIAN J SCI ENG
   Arevalillo-Herráez M, 2011, APPL SOFT COMPUT, V11, P1782, DOI 10.1016/j.asoc.2010.05.022
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Campana Bilson J. L., 2010, Statistical Analysis and Data Mining, V3, P381, DOI 10.1002/sam.10093
   Cinque L, 2001, IMAGE VISION COMPUT, V19, P979, DOI 10.1016/S0262-8856(01)00060-9
   ElAlami ME, 2014, APPL SOFT COMPUT, V14, P407, DOI 10.1016/j.asoc.2013.10.003
   ElAlami ME, 2011, KNOWL-BASED SYST, V24, P23, DOI 10.1016/j.knosys.2010.06.001
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Guha T, 2014, IEEE T MULTIMEDIA, V16, P980, DOI 10.1109/TMM.2014.2306175
   Guo JM, 2015, IEEE T IMAGE PROCESS, V24, P1010, DOI 10.1109/TIP.2014.2372619
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Herrera F, 2005, SOFT COMPUT, V9, P280, DOI 10.1007/S00500-004-0380-9
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Irtaza A, 2015, SIGNAL IMAGE VIDEO P, V9, P1503, DOI 10.1007/s11760-013-0601-8
   Irtaza A, 2014, MULTIMED TOOLS APPL, V72, P1911, DOI 10.1007/s11042-013-1489-6
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Jin C, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0132-0
   Lai CC, 2011, IEEE T INSTRUM MEAS, V60, P3318, DOI 10.1109/TIM.2011.2135010
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Raveaux R, 2013, J VIS COMMUN IMAGE R, V24, P1252, DOI 10.1016/j.jvcir.2013.08.010
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Yang XH, 2014, IET COMPUT VIS, V8, P141, DOI 10.1049/iet-cvi.2012.0157
   Youssef SM, 2012, COMPUT ELECTR ENG, V38, P1358, DOI 10.1016/j.compeleceng.2012.05.010
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
NR 36
TC 6
Z9 6
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 23617
EP 23638
DI 10.1007/s11042-019-7597-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400063
DA 2024-07-18
ER

PT J
AU Yu, CR
   Chen, HJ
   Li, YF
   Peng, YH
   Li, JP
   Yang, F
AF Yu, Cuiru
   Chen, Houjin
   Li, Yanfeng
   Peng, Yahui
   Li, Jupeng
   Yang, Fan
TI Breast cancer classification in pathological images based on hybrid
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer; Nuclei segmentation; Deep learning; Hybrid features;
   Pathological image
ID SEGMENTATION; DATASET
AB Breast cancer has become an important factor affecting human health. Diagnosis based on pathological images is considered the gold standard in the clinic. In this paper, an automatic breast cancer detection method based on hybrid features is proposed for pathological images. To obtain better segmentation results under conditions of crowded and chromatin-sparse nuclei, a 3-output convolutional neural network (CNN) is employed to segment the nuclei. Due to the weak correlation between the hematoxylin (H) and eosin (E) channels, texture features are separately extracted for the two channels, which provides more representative results. From multiple perspectives, the morphological features, spatial structural features and texture features are extracted and fused. Using a support vector machine (SVM) classifier with improved generalization, the pathological image is classified as benign or malignant on the basis of the relief method for feature selection. For the University of California, Santa Barbara database (UCSB), the classification accuracy of the method is 96.7%, and the area under the curve (AUC) is 0.983. The experimental results show that the proposed method yields superior classification performance compared with existing techniques.
C1 [Yu, Cuiru; Chen, Houjin; Li, Yanfeng; Peng, Yahui; Li, Jupeng; Yang, Fan] Beijing Jiaotong Univ, Sch Elect Informat Engn, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Li, YF (corresponding author), Beijing Jiaotong Univ, Sch Elect Informat Engn, Beijing 100044, Peoples R China.
EM yf.li@bjtu.edu.cn
RI Peng, Yahui/O-5290-2018
OI Peng, Yahui/0000-0002-2520-1170
FU National Natural Science Foundation of China [61872030, 61571036]
FX This work was supported in part by the National Natural Science
   Foundation of China under no. 61872030 and no. 61571036.
CR Ali S, 2012, IEEE T MED IMAGING, V31, P1448, DOI 10.1109/TMI.2012.2190089
   Anuranjeeta A., 2017, BIOMED PHARMACOL J, V10, P353, DOI DOI 10.13005/bpj/1116
   Arganda-Carreras I, 2017, BIOINFORMATICS, V33, P2424, DOI 10.1093/bioinformatics/btx180
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bayramoglu N, 2016, INT C PATT RECOG, P2440, DOI 10.1109/ICPR.2016.7900002
   Beevi KS, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P740, DOI 10.1109/IC3I.2014.7019762
   Chang H, 2013, IEEE T MED IMAGING, V32, P670, DOI 10.1109/TMI.2012.2231420
   Collobert R., 2002, Torch: a modular machine learning software library
   de Berg M., 2000, Math. Gazette, V19, P333
   Doyle S, 2008, I S BIOMED IMAGING, P496, DOI 10.1109/ISBI.2008.4541041
   Ferlay J, 2015, BREAST CANC STAT
   Gelasca ED, 2008, IEEE IMAGE PROC, P1816, DOI 10.1109/ICIP.2008.4712130
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hatipoglu N, 2017, MED BIOL ENG COMPUT, V55, P1829, DOI 10.1007/s11517-017-1630-1
   He X, 2000, COMPUTER ENG APPL
   Hu ZL, 2018, PATTERN RECOGN, V83, P134, DOI 10.1016/j.patcog.2018.05.014
   Kong H, 2011, IEEE T MED IMAGING, V30, P1661, DOI 10.1109/TMI.2011.2141674
   Kumar N, 2017, IEEE T MED IMAGING, V36, P1550, DOI 10.1109/TMI.2017.2677499
   Lei T, 2018, IEEE T FUZZY SYST, P1
   Li XY, 2015, PROC SPIE, V9420, DOI 10.1117/12.2079935
   Liu X, 2014, INT C GRAPH IM PROC, V9069, P361
   Okabe A, 2001, SPATIAL TESSELLATION, V3, P357
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Petushi Sokol, 2006, BMC Med Imaging, V6, P14, DOI 10.1186/1471-2342-6-14
   Plissiti ME, 2012, IEEE T IMAGE PROCESS, V21, P4568, DOI 10.1109/TIP.2012.2206041
   Qi X, 2012, IEEE T BIO-MED ENG, V59, P754, DOI 10.1109/TBME.2011.2179298
   Ruifrok AC, 2001, ANAL QUANT CYTOL, V23, P291
   Sabeena B. K., 2016, BIO CYBERNETICS BIOM, V36, P584
   Spanhol F, 2017, 2017 IEEE INT C SYST
   Spanhol FA, 2016, BREAST CANC HISTOPAT
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Tahir MA, 2005, ANALOG INTEGR CIRC S, V43, P205, DOI 10.1007/s10470-005-6793-2
   Veta M, 2011, I S BIOMED IMAGING, P618, DOI 10.1109/ISBI.2011.5872483
   Veta M, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070221
   Vink JP, 2013, J MICROSC-OXFORD, V249, P124, DOI 10.1111/jmi.12001
   Wu GS, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2854
   Xiangsheng Z, 2014, PATHOLOGICAL DIAGNOS
   Yang Song, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P306, DOI 10.1007/978-3-319-46604-0_22
   Zhang M, 2015, IEEE T BIO-MED ENG, V62, P1051, DOI 10.1109/TBME.2014.2360154
   Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7
   Zulpe N., 2012, Int. J. Comput. Sci. Issues (IJCSI), V9, P354
NR 41
TC 20
Z9 22
U1 0
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21325
EP 21345
DI 10.1007/s11042-019-7468-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400036
DA 2024-07-18
ER

PT J
AU Zhang, F
   Lu, W
   Liu, HM
   Yeung, YL
   Xue, YJ
AF Zhang, Fang
   Lu, Wei
   Liu, Hongmei
   Yeung, Yuileong
   Xue, Yingjie
TI Reversible data hiding in binary images based on image magnification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Cross-shape pattern; Reference block pattern;
   Image magnification
ID DISTORTION MEASURE; SPLICING DETECTION; INTERPOLATION; TRANSFORM;
   SCHEME; AUTHENTICATION; EXPANSION; STEP
AB Over the past few years, many methods have been proposed for reversible data hiding in digital images, but few have been applied to binary images. The existing methods mainly employ run-length to embed the secret message, but the capacity is low. In this paper, we propose a reversible data hiding method based on image magnification. Firstly, image cross-shape patterns are analyzed to select the reference block pattern. Then, to improve the capacity and ensure reversibility, an image magnification strategy based on the reference block pattern is designed to scale up the original image to get the reference image. Finally, to ensure the visual quality of stego image, an inner-block flippable pixel selection strategy is designed to embed data. Experimental results have demonstrated that the proposed reversible data hiding scheme can restore the original image after extracting the embedded message, and achieve high embedding capacity and good visual quality.
C1 [Zhang, Fang; Lu, Wei; Liu, Hongmei; Yeung, Yuileong; Xue, Yingjie] Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Minist Educ,Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Key Lab Machine Intelligence & Adv Comp, Guangdong Key Lab Informat Secur Technol, Minist Educ,Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
EM zhangf236@mail2.sysu.edu.cn; luwei3@mail.sysu.edu.cn;
   isslhm@mail.sysu.edu.cn; yeungyl@mail2.sysu.edu.cn;
   xueyj@mail2.sysu.edu.cn
OI Lu, Wei/0000-0002-4068-1766
FU National Natural Science Foundation of China [U1736118]; Natural Science
   Foundation of Guangdong [2016A030313350]; Special Funds for Science and
   Technology Development of Guangdong [2016KZ010103]; Key Project of
   Scientific Research Plan of Guangzhou [201804020068]; Shanghai Minsheng
   Science and Technology Support Program [17DZ1205500]; Shanghai Sailing
   Program [17YF1420000]; Fundamental Research Funds for the Central
   Universities [16lgjc83, 17lgjc45]
FX This work is supported by the National Natural Science Foundation of
   China (No. U1736118), the Natural Science Foundation of Guangdong (No.
   2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Key Project of
   Scientific Research Plan of Guangzhou (No. 201804020068), Shanghai
   Minsheng Science and Technology Support Program (17DZ1205500), Shanghai
   Sailing Program (17YF1420000), the Fundamental Research Funds for the
   Central Universities (No. 16lgjc83 and No. 17lgjc45).
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   [Anonymous], J APPL SCI
   Cao G, 2014, IEEE T INF FOREN SEC, V9, P515, DOI 10.1109/TIFS.2014.2300937
   Cao H, 2013, IEEE T INF FOREN SEC, V8, P1508, DOI 10.1109/TIFS.2013.2274041
   Chen JL, 2018, J VIS COMMUN IMAGE R, V55, P149, DOI 10.1016/j.jvcir.2018.06.004
   Chen JJ, 2018, CMC-COMPUT MATER CON, V55, P201, DOI 10.3970/cmc.2018.01781
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Chen LK, 2012, INT J DIGIT CRIME FO, V4, P49, DOI 10.4018/jdcf.2012010104
   Chen X, 2018, IEEE T NEUR NET LEAR, V29, P3938, DOI 10.1109/TNNLS.2017.2740318
   Chen X, 2018, IEEE T PATTERN ANAL, V40, P1697, DOI 10.1109/TPAMI.2017.2726061
   Cheng J, 2007, IEEE T IMAGE PROCESS, V16, P1691, DOI 10.1109/TIP.2007.896619
   Chiew KL, 2010, LECT NOTES COMPUT SC, V6047, P341, DOI 10.1007/978-3-642-12827-1_25
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Feng BW, 2017, LECT NOTES COMPUT SC, V10082, P312, DOI 10.1007/978-3-319-53465-7_23
   Feng BW, 2017, J VIS COMMUN IMAGE R, V46, P119, DOI 10.1016/j.jvcir.2017.01.008
   Feng BW, 2016, SIGNAL PROCESS-IMAGE, V41, P1, DOI 10.1016/j.image.2015.10.007
   Feng BW, 2015, MULTIMED TOOLS APPL, V74, P9623, DOI 10.1007/s11042-014-2140-x
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Feng BW, 2015, J VIS COMMUN IMAGE R, V26, P284, DOI 10.1016/j.jvcir.2014.10.003
   Feng BW, 2014, LECT NOTES COMPUT SC, V8389, P514, DOI 10.1007/978-3-662-43886-2_37
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Ho YA, 2009, COMPUT STAND INTER, V31, P787, DOI 10.1016/j.csi.2008.09.014
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jung KH, 2009, COMPUT STAND INTER, V31, P465, DOI 10.1016/j.csi.2008.06.001
   Kim C., 2014, P INT C INF SEC CRYP, P317
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Li JW, 2017, MULTIMED TOOLS APPL, V76, P20483, DOI 10.1007/s11042-016-3967-0
   Li JX, 2018, MULTIMED TOOLS APPL, V77, P31895, DOI 10.1007/s11042-018-6175-2
   Li XL, 2013, IEEE T INF FOREN SEC, V8, P1091, DOI 10.1109/TIFS.2013.2261062
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lin C, 2019, MULTIMED TOOLS APPL, V78, P30081, DOI 10.1007/s11042-018-6922-4
   Lin C, 2018, MULTIMED TOOLS APPL, V77, P14241, DOI 10.1007/s11042-017-5027-9
   Liu XJ, 2019, MULTIMED TOOLS APPL, V78, P7947, DOI 10.1007/s11042-018-6411-9
   Liu XJ, 2020, IEEE T CIRC SYST VID, V30, P618, DOI 10.1109/TCSVT.2019.2893353
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Lu HP, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P806
   Lu W, 2018, IEEE T CIRCUITS SYST
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Malik A, 2017, MULTIMED TOOLS APPL, V76, P13025, DOI 10.1007/s11042-016-3707-5
   Meng Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1441, DOI 10.1109/ICPR.2010.356
   Muhammad K, 2018, FUTURE GENER COMP SY, V86, P951, DOI 10.1016/j.future.2016.11.029
   Muhammad K, 2017, MULTIMED TOOLS APPL, V76, P8597, DOI 10.1007/s11042-016-3383-5
   Muhammad K, 2016, MULTIMED TOOLS APPL, V75, P14867, DOI 10.1007/s11042-015-2671-9
   Muhammad K, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0473-x
   Muhammad K, 2015, KSII T INTERNET INF, V9, P1938
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ogiela L, 2017, INT CONF INTEL INFOR, P165, DOI 10.1109/ICIIBMS.2017.8279717
   Ogiela L, 2017, IEEE SYST J, V11, P405, DOI 10.1109/JSYST.2015.2409213
   Ogiela U, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4362
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Shi YQ, 1999, IMAGE AND VIDEO COMP
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tsai CL, 2005, PATTERN RECOGN, V38, P1993, DOI 10.1016/j.patcog.2005.03.001
   Tseng YC, 2002, IEEE T COMMUN, V50, P1227, DOI 10.1109/TCOMM.2002.801488
   Wang RM, 2018, ADV MECH ENG, V10, DOI 10.1177/1687814018769003
   Wei Z, 2013, IEEE T IMAGE PROCESS, V22, P4271, DOI 10.1109/TIP.2013.2271849
   Weng SW, 2008, IEEE SIGNAL PROC LET, V15, P721, DOI 10.1109/LSP.2008.2001984
   Wu HM, 2018, J VIS COMMUN IMAGE R, V55, P424, DOI 10.1016/j.jvcir.2018.06.019
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Xiao HM, 2019, J VIS COMMUN IMAGE R, V59, P52, DOI 10.1016/j.jvcir.2018.12.048
   Xie ZZ, 2018, J INF SECUR APPL, V43, P37, DOI 10.1016/j.jisa.2018.10.003
   Xu Z, 2018, IEEE T CIRCUITS SYST
   Xuan GR, 2008, INT C PATT RECOG, P1694
   Xue F, 2018, MULTIMEDIA TOOLS APP
   Xue F, 2017, SIGNAL PROCESS-IMAGE, V57, P76, DOI 10.1016/j.image.2017.05.008
   Xue YJ, 2019, J REAL-TIME IMAGE PR, V16, P601, DOI 10.1007/s11554-018-0822-8
   Yang Chyuan-Huei Thomas, 2014, 2014 International Conference on Trustworthy Systems and their Applications, P69, DOI 10.1109/TSA.2014.20
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yang HJ, 2008, IEEE T MULTIMEDIA, V10, P339, DOI 10.1109/TMM.2008.917404
   Yang HJ, 2007, IEEE T MULTIMEDIA, V9, P475, DOI 10.1109/TMM.2006.887990
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yuan YF, 2017, LECT NOTES COMPUT SC, V10602, DOI 10.1007/978-3-319-68505-2_10
   Zhang FJ, 2018, MULTIMED TOOLS APPL, V77, P26239, DOI 10.1007/s11042-018-5847-2
   Zhang JH, 2019, J VIS COMMUN IMAGE R, V58, P600, DOI 10.1016/j.jvcir.2018.12.038
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang QB, 2018, MULTIMED TOOLS APPL, V77, P31239, DOI 10.1007/s11042-018-6230-z
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang XP, 2011, IEEE T IMAGE PROCESS, V20, P485, DOI 10.1109/TIP.2010.2066981
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
   Zheng QM, 2018, IEEE ACCESS, V6, DOI 10.1109/ACCESS.2017.2775038
   Zou LM, 2019, MULTIMED TOOLS APPL, V78, P7965, DOI 10.1007/s11042-018-6444-0
NR 90
TC 7
Z9 8
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 15
BP 21891
EP 21915
DI 10.1007/s11042-019-7519-2
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IQ0SO
UT WOS:000480461400059
DA 2024-07-18
ER

PT J
AU Dhargupta, S
   Chakraborty, A
   Ghosal, SK
   Saha, S
   Sarkar, R
AF Dhargupta, S.
   Chakraborty, A.
   Ghosal, S. K.
   Saha, S.
   Sarkar, R.
TI Fuzzy edge detection based steganography using modified Gaussian
   distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Edge detection; Fuzzy approach; Gaussian function;
   Payload; Cover image
ID IMAGE; SUBSTITUTION; COMMON; LSB
AB This paper proposes a fuzzy edge detection based steganography approach to effectively hide data within images. Instead of applying conventional edge detection algorithms, the method uses a fuzzy edge detection approach in order to estimate more number of pixels where the data can be hidden. At the outset, the cover image is masked and the fuzzy edge detection is performed on the masked image thus retaining edge information. The number of bits to be embedded in a particular pixel is dependent on whether the pixel is an edge pixel, where more bits are embedded. In case the pixel is not an edge pixel and also not a background pixel then the amount of data that is to be embedded depends on the Euclidean distance of the respective pixel from the nearest edge pixel and is determined by the Gaussian function. Experimental results ensure that the scheme offers variable payload with acceptable quality distortion in the stego-image.
C1 [Dhargupta, S.; Chakraborty, A.; Saha, S.; Sarkar, R.] Jadavpur Univ, Dept Comp Sci & Engn, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
   [Ghosal, S. K.] Nalhati Govt Polytech, Dept Comp Sci & Technol, Nalhati 731243, Birbhum, India.
C3 Jadavpur University
RP Sarkar, R (corresponding author), Jadavpur Univ, Dept Comp Sci & Engn, 188 Raja SC Mallick Rd, Kolkata 700032, W Bengal, India.
EM raamsarkar@gmail.com
RI Sarkar, Ram/AAX-3822-2020
OI Sarkar, Ram/0000-0001-8813-4086; SAHA, SHASWATA/0000-0003-1834-0495
CR Alshennawy A., 2009, WORLD ACAD SCI ENG, V51, P185
   Atawneh S, 2013, IETE TECH REV, V30, P344, DOI 10.4103/0256-4602.116724
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Dube RR., 2016, INT J SCI RES, V5, P1976, DOI DOI 10.21275/V5I6.NOV164686
   Gupta GS, 2002, IETE TECH REV, V19, P221, DOI 10.1080/02564602.2002.11417035
   GUPTA S., 2013, Int. J. Comput. Sci. Manag. Res, V2, P1578
   Hussain M, 2018, IETE TECH REV, V35, P53, DOI 10.1080/02564602.2016.1244496
   Ingemar J.C., 2008, DIGITAL WATERMARKING, V2nd
   Islam S, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P771, DOI 10.1109/HPCC.2014.129
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Lan X., 2018, PATTERN RECOGN LETT
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Lan XY, 2014, PROC CVPR IEEE, P1194, DOI 10.1109/CVPR.2014.156
   Lee C-F, 2010, P 4 INT C GEN EV COM
   Liu Y, 2016, Delving into transferable adversarial examples and black-box attacks"
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ratan R, 2002, IETE TECH REV, V19, P213, DOI 10.1080/02564602.2002.11417034
   Suneetha D., 2017, INT J APPL ENG RES, V12, P5565
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang ZC, 2018, IETE TECH REV, V35, P351, DOI 10.1080/02564602.2017.1304289
NR 24
TC 17
Z9 17
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17589
EP 17606
DI 10.1007/s11042-018-7123-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200013
DA 2024-07-18
ER

PT J
AU Liu, H
   Zhao, B
   Huang, L
AF Liu, Hui
   Zhao, Bo
   Huang, Linquan
TI A novel quantum image encryption algorithm based on crossover operation
   and mutation operation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crossover operation; Mutation operation; Quantum chaos sequence;
   Two-dimensional logistic map; Nearest-neighboring coupled-map lattices
ID COLOR; PERMUTATION; CHAOS; DIFFUSION; TRANSFORM; SECURE; MAP
AB In this paper, a new algorithm of image encryption based on random selection of crossover operation and mutation operation is proposed. Crossover operation and mutation operation come from genetic algorithm that gets high-quality solutions to optimization. First, quantum chaos sequence and two-dimensional logistic sequence are XORed with plain-image. And then, adjacent pixels of the image are carried out bit-level crossover operation and crossover bits rely heavily on chaotic maps for chaotic property. Finally, two different bits of each pixel are employed to perform mutation for high randomness. In order to obtain the high complexity and unpredictability further, quantum chaotic map is coupled with nearest-neighboring coupled-map lattices (NCML). Computer simulations and statistical analyses show that the proposed algorithm has more than 10(45) bits key space, low correlation closed to 0, ideal information entropy closed to 8, acceptable speed performance 4.7081Mbt/s and resistance to various attacks.
C1 [Liu, Hui; Zhao, Bo] Wuhan Univ, Sch Cyber Sci & Engn, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan 430072, Hubei, Peoples R China.
   [Huang, Linquan] Hankou Univ, Sch Comp Sci & Technol, Wuhan 430212, Hubei, Peoples R China.
C3 Wuhan University; Hankou University
RP Zhao, B (corresponding author), Wuhan Univ, Sch Cyber Sci & Engn, Minist Educ, Key Lab Aerosp Informat Secur & Trusted Comp, Wuhan 430072, Hubei, Peoples R China.
EM zhaobo@whu.edu.cn
OI liu, hui/0000-0003-1345-5736
FU National Key Basic Research Program of China (973 Program)
   [2014CB340600]; Wuhan Frontier Program of Application Foundation
   [2018010401011295]
FX The work is supported by the National Key Basic Research Program of
   China (973 Program) (No.2014CB340600) and the Wuhan Frontier Program of
   Application Foundation (No.2018010401011295).
CR Akhshani A, 2014, COMMUN NONLINEAR SCI, V19, P101, DOI 10.1016/j.cnsns.2013.06.017
   Alassaf N, 2018, MULTIMED TOOLS APPL, P1
   [Anonymous], IEEE ACCESS
   [Anonymous], 2014, 3D RES
   Beg AH, 2016, IEEE C EVOL COMPUTAT, P2114, DOI 10.1109/CEC.2016.7744049
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, SIGNAL PROCESS, V142, P340, DOI 10.1016/j.sigpro.2017.07.034
   Friedrich T, 2017, IEEE T EVOLUT COMPUT, V21, P477, DOI 10.1109/TEVC.2016.2613739
   Guesmi R, 2016, MULTIMED TOOLS APPL, V75, P4753, DOI 10.1007/s11042-015-2501-0
   Guo JM, 2018, IEEE ACCESS, V6, P46297, DOI 10.1109/ACCESS.2018.2863021
   Hamza R, 2018, IEEE ACCESS, V6, P60160, DOI 10.1109/ACCESS.2017.2762405
   Hossein N, 2018, OPT LASER ENG, V111, P24
   Hua ZY, 2015, IEEE SYS MAN CYBERN, P1804, DOI 10.1109/SMC.2015.316
   Hui Liu, 2017, International Journal of Network Security, V19, P347, DOI 10.6633/IJNS.201703.19(3).04
   Jain A, 2016, MULTIMED TOOLS APPL, V75, P5455, DOI 10.1007/s11042-015-2515-7
   Jha Y, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P177, DOI 10.1109/ICCSP.2016.7754116
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Kumar J, 2018, ADV INTELL SYST, V562, P63, DOI 10.1007/978-981-10-4603-2_7
   Li JZ, 2016, J OPT SOC KOREA, V20, P42, DOI 10.3807/JOSK.2016.20.1.042
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   Metawa N, 2017, EXPERT SYST APPL, V80, P75, DOI 10.1016/j.eswa.2017.03.021
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Nkapkop JDD, 2017, INT ARAB J INF TECHN, V14, P812
   Parvaz R, 2018, OPT LASER TECHNOL, V101, P30, DOI 10.1016/j.optlastec.2017.10.024
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patidar V, 2017, J APPL NONLINEAR DYN, V2017, P1
   Patro KAK, 2018, J INF SECUR APPL, V40, P111, DOI 10.1016/j.jisa.2018.03.006
   Qin C, 2018, SIGNAL PROCESS, V153, P109, DOI 10.1016/j.sigpro.2018.07.008
   Rehman AU, 2016, 3D RES, V7, DOI 10.1007/s13319-016-0084-9
   Seyedzadeh S. M., 2015, NONLINEAR DYNAM, V81, P1
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wei W, 2018, COMPUT ELECTR ENG, V65, P282
   Wu JH, 2018, SIGNAL PROCESS, V142, P292, DOI 10.1016/j.sigpro.2017.06.014
   Xiao D, 2017, OPT LASER TECHNOL, V91, P212, DOI 10.1016/j.optlastec.2016.12.024
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yuan YB, 2016, ADV ENERGY MATER, V6, DOI 10.1002/aenm.201501803
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
NR 40
TC 22
Z9 25
U1 3
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20465
EP 20483
DI 10.1007/s11042-019-7186-3
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800068
DA 2024-07-18
ER

PT J
AU Narayanan, R
   Rangan, VP
   Gopalakrishnan, U
   Hariharan, B
AF Narayanan, Ramkumar
   Rangan, Venkat P.
   Gopalakrishnan, Uma
   Hariharan, Balaji
TI Multiparty gaze preservation through perspective switching for
   interactive elearning environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gaze alignment; ELearning; Perspective switching; Gesture recognition
ID PARTICIPATION; PERFORMANCE
AB Existing live tele-teaching systems enable eye-contact between interacting participants, however, they are often incomplete as they neglect finer levels of adherence to gaze such as gaze awareness and gaze following. A multilocation eLearning classroom setting often does not preserve relative neighborhood i.e., displays showing videos of remote participants at each location might not be congruent with their actual seating positions. This leads to incoherent gaze patterns during interactions. We present a media-rich distributed classroom architecture with multiple cameras and displays in each classroom. During interaction changes, cameras capturing appropriate perspectives of participants are streamed to displays in other classrooms. Hence for all interactions, the physical participants of a classroom are presented with appropriate perspectives of remote participants resembling gaze patterns during conventional-classroom interactions. We also present a framework to systematically analyze gaze patterns with its dependencies. The framework dictates optimal placement of media devices ensuring minimal deviation in capturing appropriate perspectives for a given set of resources. Evaluation results on a three classroom test-bed indicates a marked reduction in viewer cognitive load in discerning the entity-at-focus in an eLearning classroom environment.
C1 [Narayanan, Ramkumar; Rangan, Venkat P.; Gopalakrishnan, Uma; Hariharan, Balaji] Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Amrita Ctr Wireless Networks & Applicat AmritaWNA, Coimbatore 641112, Tamil Nadu, India.
C3 Amrita Vishwa Vidyapeetham; Amrita Vishwa Vidyapeetham Coimbatore
RP Narayanan, R (corresponding author), Amrita Vishwa Vidyapeetham, Amrita Sch Engn, Amrita Ctr Wireless Networks & Applicat AmritaWNA, Coimbatore 641112, Tamil Nadu, India.
EM ramkumar@am.amrita.edu; venkat@amrita.edu; umag@am.amrita.edu;
   hbalaji@am.amrita.edu
CR [Anonymous], 2000, QUESTIONNAIRE DESIGN
   Arkorful V., 2015, INT J INSTRUCTIONAL, V12, P29, DOI DOI 10.1016/J.PR0CS.2012.10.037
   Baek ET, 2017, SIGNAL IMAGE VIDEO P, V11, P187, DOI 10.1007/s11760-016-0918-1
   Bailenson JN, 2008, J LEARN SCI, V17, P102, DOI 10.1080/10508400701793141
   Barzuza T, 2015, US Patent App., Patent No. [14/601,535, 14601535]
   Bijlani K., 2011, P 3 INT ACM WORKSHOP, P13
   Bijlani K., 2010, 2 INT C ED TECHN COM, V2, pV2
   Davies J, 2005, BRIT J EDUC TECHNOL, V36, P657, DOI 10.1111/j.1467-8535.2005.00542.x
   Flom R., 2007, GAZE FOLLOWING ITS D
   Ford DA, 2017, US Patent, Patent No. [9,538,130, 9538130]
   Gemmell J., 2000, IEEE Multimedia, V7, P26, DOI 10.1109/93.895152
   Guntha R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1135, DOI 10.1109/ICACCI.2016.7732197
   Harrell RK, 2010, US Patent, Patent No. [7,679,639, 7679639]
   Jerald J., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P77, DOI 10.1145/507072.507088
   Jokinen K, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2018
   Jung I, 2002, INNOV EDUC TEACH INT, V39, P153, DOI 10.1080/13558000210121399
   MacPherson AC, 2007, GAZE FOLLOWING ITS D
   Marks M, 1979, PROFESSIONAL ETHICS, V2
   Monk AF, 2002, DISCOURSE PROCESS, V33, P257, DOI 10.1207/S15326950DP3303_4
   Noh Seungtak., 2015, ICAT-EGVE, P61
   Norden B, 2015, GLOBAL KNOWLEDGE FOR
   Owens J., 2009, Journal of Distance Education, V23, P53
   Pejsa T, 2016, ACM CONFERENCE ON COMPUTER-SUPPORTED COOPERATIVE WORK AND SOCIAL COMPUTING (CSCW 2016), P1716, DOI 10.1145/2818048.2819965
   Ramkumar N, 2017, J INTELL FUZZY SYST, V32, P2963, DOI 10.3233/JIFS-169239
   Regenbrecht H., 2015, COMMUNICATIONS ASS I, V37, P45
   Rosinski RR, 1979, TECH REP
   Sharma P., 2014, P INT C LEARN SCI, P1017
   Subramanian N.S., 2014, P 2014 INT C INT ADV, P53
   Thies J., 2016, ARXIV161003151
   Varghese JM, 2016, ADV INTELL SYST, V380, P37, DOI 10.1007/978-81-322-2523-2_4
   Vertegaal R, 2000, PROC GRAPH INTERF, P95
   Zhang Z, 2004, US Patent, Patent No. [6,771,303, 6771303]
NR 32
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17461
EP 17494
DI 10.1007/s11042-018-7078-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200007
DA 2024-07-18
ER

PT J
AU Pal, O
   Alam, B
AF Pal, Om
   Alam, Bashir
TI Efficient and secure conditional access system for pay-TV systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Key distribution; Key management; Conditional access system; Digital TV
   broadcasting; Pay-TV system
ID KEY MANAGEMENT; SCHEME
AB In Digital TV service, subscribers get the access of channels of their interest. In Conditional Access Systems (CAS), multimedia content is delivered securely using the Control Word (CW). To frequent update of the CW, a large number of messages are exchanged in the conventional key distribution systems. In this paper, a centralized key distribution scheme based on dynamicity of the groups and with freedom of channel package composition is proposed. Scheme has also efficient mechanism of load balancing at Group Controller (GC) side. To speed up the search of the channel package in the existing database, Optimal Binary Search Tree (OBST) data structure and Finite State Machine (FSM) are used. Scheme also provides the efficient leaving and joining mechanism for single user as well as batch users.
C1 [Pal, Om] Govt India, Minist Elect & Informat Technol, New Delhi, India.
   [Alam, Bashir] Jamia Millia Islamia, Fac Engn & Technol, Dept Comp Engn, New Delhi, India.
C3 Jamia Millia Islamia
RP Pal, O (corresponding author), Govt India, Minist Elect & Informat Technol, New Delhi, India.
EM ompal.cdac@gmail.com; balam2@jmi.ac.in
RI ALAM, BASHIR/KGL-8679-2024
OI ALAM, BASHIR/0000-0003-0479-682X
CR [Anonymous], 1992, ITU R REC 810
   Chin-Yu Sun, 2016, International Journal of Network Security, V18, P594
   Cremers C, 2015, INT J INF SECUR
   Huang YL, 2004, IEEE T MULTIMEDIA, V6, P760, DOI 10.1109/TMM.2004.834861
   Jiang TP, 2004, IEEE T CONSUM ELECTR, V50, P225, DOI 10.1109/TCE.2004.1277866
   Kim JY, 2010, IEEE T MULTIMEDIA, V12, P337, DOI 10.1109/TMM.2010.2046362
   LEE W, 1996, P INT C CRYPT INF SE, P82
   Liu BF, 2004, IEEE T CONSUM ELECTR, V50, P632, DOI 10.1109/TCE.2004.1309442
   MACQ BM, 1995, P IEEE, V83, P944, DOI 10.1109/5.387094
   Mapoka TT, 2015, IEEE T MOBILE COMPUT, V14, P1545, DOI 10.1109/TMC.2014.2362760
   Naranjo JAM, 2012, J COMPUT APPL MATH, V236, P3042, DOI 10.1016/j.cam.2011.02.015
   Peinado A, 2011, LECT NOTES COMPUT SC, V6694, P177, DOI 10.1007/978-3-642-21323-6_22
   Shiuh-Jeng Wang, 2010, International Journal of Information Technology, Communications and Convergence, V1, P66, DOI 10.1504/IJITCC.2010.035227
   Sun HM, 2008, IEEE T MULTIMEDIA, V10, P1109, DOI 10.1109/TMM.2008.2001381
   Trappe W, 2003, IEEE T MULTIMEDIA, V5, P544, DOI 10.1109/TMM.2003.813279
   Trappe W, 2013, INTRO CRYPTOGRAPHY C, P66
   Tu FK, 1998, 1998 IE INT S CONS E, V45, P151
   Varalakshmi R, 2015, MULTIMED TOOLS APPL, V74, P2899, DOI 10.1007/s11042-013-1753-9
   Vijayakumar P, 2013, COMPUT MATH APPL, V65, P1360, DOI 10.1016/j.camwa.2012.01.038
   Vijayakumar P, 2014, IET INFORM SECUR, V8, P179, DOI 10.1049/iet-ifs.2012.0352
   Yeh LY, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487271
NR 21
TC 5
Z9 5
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18835
EP 18853
DI 10.1007/s11042-019-7257-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200066
DA 2024-07-18
ER

PT J
AU Su, W
   Wang, ZF
AF Su, Wen
   Wang, Zengfu
TI Widening residual refine edge reserved neural network for semantic
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic segmentation; Convolutional neural network; Widening residual
   network; Refine residual feature pyramid; Rolling guidance edge reserved
AB Over the past several years, deep convolutional neural networks have pushed the performance of computer vision systems to soaring heights on semantic segmentation. In this paper, we put forward a novel practical convolutional neural network for effective semantic segmentation. The network is comprised of three modules. The module of widening residual convolutional neural network is firstly used to generate a full-size segmentation with localization of object boundaries. Feature maps generated by widening residual network are integrated by the module called as refine residual feature pyramid. The module of rolling guidance edge reserved layer is used for improving segmentation boundary. The innovations of this paper consist of these points. Widening residual skipped connections are utilized to preserve low-level features allowing accurate boundary localization. The refine residual feature pyramid is incorporated to achieve the observation of existence of objects at multiple scale. For modeling long-range context dependence and increasing accuracy near object boundary, rolling guidance edge reserved layer are implemented. The experimental results, on PASCAL VOC 2012 semantic segmentation dataset and Cityscapes dataset, demonstrate the proposed method can offer an effective way of producing pixel-wise image labeling.
C1 [Su, Wen] Zhejiang Sci Tech Univ, Fac Mech Engn & Automat, Hangzhou, Zhejiang, Peoples R China.
   [Su, Wen; Wang, Zengfu] Chinese Acad Sci, Inst Intelligent Machines, Hefei, Anhui, Peoples R China.
   [Su, Wen; Wang, Zengfu] Univ Sci & Technol China, Hefei, Anhui, Peoples R China.
   [Su, Wen; Wang, Zengfu] Natl Engn Lab Speech & Language Informat Proc, Hefei, Anhui, Peoples R China.
C3 Zhejiang Sci-Tech University; Chinese Academy of Sciences; Hefei
   Institutes of Physical Science, CAS; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS
RP Su, W (corresponding author), Zhejiang Sci Tech Univ, Fac Mech Engn & Automat, Hangzhou, Zhejiang, Peoples R China.; Su, W (corresponding author), Chinese Acad Sci, Inst Intelligent Machines, Hefei, Anhui, Peoples R China.; Su, W (corresponding author), Univ Sci & Technol China, Hefei, Anhui, Peoples R China.; Su, W (corresponding author), Natl Engn Lab Speech & Language Informat Proc, Hefei, Anhui, Peoples R China.
EM wensu@mail.ustc.edu.cn; zfwang@ustc.edu.cn
OI Su, Wen/0000-0001-6787-4384
FU National Natural Science Foundation of China [44961472393]; Special Fund
   for the cultivation of academic backbone of ZSTU [11130131281802]
FX The National Natural Science Foundation of China (No: 44961472393) is
   hosted by Zengfu Wang. This paper is also founded by the former
   Foundation. Special Fund for the cultivation of academic backbone of
   ZSTU(No. 11130131281802) is hosted by Wen Su, and this paper is also
   funded by it.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.348
   [Anonymous], 2015, CVPR, DOI DOI 10.1109/CVPR.2015.7298642
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Badrinarayanan V., 2017, TPAMI, DOI DOI 10.1109/TPAMI.2016.2644615
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong RC, 2017, IEEE T IMAGE PROCESS, V26, P4128, DOI 10.1109/TIP.2017.2710635
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li HF, 2018, PATTERN RECOGN, V79, P130, DOI 10.1016/j.patcog.2018.02.005
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Liu WF, 2017, J VIS COMMUN IMAGE R, V49, P47, DOI 10.1016/j.jvcir.2017.08.001
   Liu ZW, 2015, IEEE I CONF COMP VIS, P1377, DOI 10.1109/ICCV.2015.162
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Malcolm J, 2007, IEEE IMAGE PROC, P2061
   Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F, 2008, P BRIT MACH VIS C, P1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su W, 2017, IET IMAGE PROCESS, V11, P880, DOI 10.1049/iet-ipr.2017.0070
   Su W, 2015, COMM COM INF SC, V546, P448, DOI 10.1007/978-3-662-48558-3_45
   Tao DP, 2019, IEEE T NEUR NET LEAR, V30, P163, DOI 10.1109/TNNLS.2018.2836969
   Uhrig J, 2016, LECT NOTES COMPUT SC, V9796, P14, DOI 10.1007/978-3-319-45886-1_2
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vemulapalli R, 2016, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2016.351
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhao H., 2016, ARXIV161201105
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou B., 2014, CORR, V1412, P6856
NR 44
TC 5
Z9 8
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 18229
EP 18247
DI 10.1007/s11042-018-7121-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200040
DA 2024-07-18
ER

PT J
AU Elaskily, MA
   Elnemr, HA
   Dessouky, MM
   Faragallah, OS
AF Elaskily, Mohamed A.
   Elnemr, Heba A.
   Dessouky, Mohamed M.
   Faragallah, Osama S.
TI Two stages object recognition based copy-move forgery detection
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Morphological operation; Object detection;
   Connected component labeling; Speeded up robust features
AB Copy-Move Forgery Detection (CMFD) is a key issue of image forensics. A copy-move forgery is a type of image tampering that is created by copying a part of the image and pasting it on another part of the same image to perniciously hide or clone certain regions. This paper presents a new methodology for CMFD in digital images. The proposed algorithm is performed in two successive stages; matching stage and refinement stage. In the matching stage, close morphological operation and Connected Component Labeling (CCL) are used to segment the target image into different objects. The Speeded Up Robust Features (SURF) are extracted from each object and used to build an object catalog. The objects in the catalog are compared to each other, and matched objects are determined. If matched objects exist, the image is categorized as forged image. Otherwise, it is categorized as original image. The refinement stage, on the other hand, is implemented to ensure the originality of the target image. Thus, the candidate image that is classified as original is fed into the refinement stage to certify its originality. In this stage, close and open morphological operations as well as CCL are utilized to obtain the various objects in the image. Afterward, the SURF features are extracted from each object and used to build a new object catalog. The match between the objects in this catalog is obtained. If similar objects are found, the candidate image is classified as forged. Otherwise, the image is categorized as original. The proposed technique is assessed on four popular datasets. The results demonstrate the capability and robustness of the proposed technique in detecting the copy-move forgery under different geometrical attacks. Furthermore, the outcomes show that the suggested technique outperforms the previous CMFD methods in terms of Accuracy and execution time.
C1 [Elaskily, Mohamed A.] Elect Res Inst, Dept Informat, Cairo, Egypt.
   [Elaskily, Mohamed A.; Dessouky, Mohamed M.; Faragallah, Osama S.] Menoufia Univ, Fac Elect Engn, Comp Sci & Engn Dept, Menoufia 32952, Egypt.
   [Elnemr, Heba A.] Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
   [Faragallah, Osama S.] Taif Univ, Coll Comp & Informat Technol, Dept Informat Technol, Al Hawiya 21974, Saudi Arabia.
C3 Egyptian Knowledge Bank (EKB); Electronics Research Institute (ERI);
   Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Electronics Research Institute (ERI); Taif University
RP Elnemr, HA (corresponding author), Elect Res Inst, Comp & Syst Dept, Cairo, Egypt.
EM heba_elnemr@yahoo.com; osam_sal@yahoo.com
RI Dessouky, Mohamed M./AAS-1043-2020; Elaskily, Mohamed A./AAA-8852-2022;
   Faragallah, Osama S./AHB-8031-2022; Elaskily, Mohamed A./AAK-7369-2020
OI Dessouky, Mohamed M./0000-0003-2609-2225; Elaskily, Mohamed
   A./0000-0002-9136-0970; Faragallah, Osama S./0000-0003-1982-335X;
   elnemr, heba/0000-0001-9637-6982
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   Ali Qureshi M, 2014, MULT SYST SIGN DEV S, P11
   Amerini I, 2011, IEEE T INF FORENSICS, V6
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2013, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2013-8
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Costanzo A, 2014, IEEE T INF FORENSICS, V9
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   DERROLL D, 2015, INT J ADV COMPUT TEC, V4
   Dixit R, 2017, IET IMAGE PROCESS, V11, P301, DOI 10.1049/iet-ipr.2016.0537
   ELASKILY MA, 2017, INT C ADV CONTR CIRC
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hashmi MF, 2014, AASRI PROC, V9, P84, DOI 10.1016/j.aasri.2014.09.015
   He LF, 2017, PATTERN RECOGN, V70, P25, DOI 10.1016/j.patcog.2017.04.018
   Herron TJ, 2012, FRONT NEUROINFORM, V6, DOI 10.3389/fninf.2012.00025
   Huynh TK, 2015, IEEE RIVF INT C COMP
   Kaur H, 2015, INT J ELECT ELECT CO, P4
   Kaur R, 2016, INT J COMPUT APPL, V139
   Kaur R, 2016, INT J COMPUT SCI INF, V6
   Liu Y.-S., 2015, Sci. World J, V2015, P2, DOI DOI 10.1016/J.LINDIF.2015.02.002
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahmood T, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/8713202
   MAHMOUD K, 2016, INT J COMPUT SCI INF, V14
   Mahmoud K, 2016, INT ARAB J INF TECHN, V13, P930
   Maind RA, 2014, INT J SOFT COMPUTING, V4, P2231
   MATTHEWS BW, 1975, BIOCHIM BIOPHYS ACTA, V405, P442, DOI 10.1016/0005-2795(75)90109-9
   Mishra P, 2013, SCI WORLD J, DOI 10.1155/2013/267691
   Pandey RC, 2014, 9 INT SYST C IND INF
   Prakash CS, 2016, P INT C COMP VIS IM, P355
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Sreenivasu T, 2017, INT J RECENT SCI RES, V8, P17389
   Sunil K, 2015, P 48 ANN CONV COMP S, VII, P577
   Thuong LT, 2017, INFORM-J COMPUT INFO, V41, P59
NR 37
TC 20
Z9 20
U1 2
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15353
EP 15373
DI 10.1007/s11042-018-6891-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700053
OA Bronze
DA 2024-07-18
ER

PT J
AU Lahmyed, R
   El Ansari, M
   Ellahyani, A
AF Lahmyed, Redouan
   El Ansari, Mohamed
   Ellahyani, Ayoub
TI A new thermal infrared and visible spectrum images-based pedestrian
   detection system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pedestrian detection; Thermal images; Visible images; Random forests;
   Support vector machines (SVMs); Histogram of oriented gradients (HOG);
   Histograms of oriented optical flow (HOOF); Local binary pattern (LBP)
ID TRACKING; FUSION; FEATURES; HOG
AB In this paper, we propose a hybrid system for pedestrian detection, in which both thermal and visible images of the same scene are used. The proposed method is achieved in two basic steps: (1) Hypotheses generation (HG) where the locations of possible pedestrians in an image are determined and (2) hypotheses verification (HV), where tests are done to check the presence of pedestrians in the generated hypotheses. HG step segments the thermal image using a modified version of OTSU thresholding technique. The segmentation results are mapped into the corresponding visible image to obtain the regions of interests (possible pedestrians). A post-processing is done on the resulting regions of interests to keep only significant ones. HV is performed using random forest as classifier and a color-based histogram of oriented gradients (HOG) together with the histograms of oriented optical flow (HOOF) as features. The proposed approach has been tested on OSU Color-Thermal, INO Video Analytics and LITIV data sets and the results justify its effectiveness.
C1 [Lahmyed, Redouan; El Ansari, Mohamed; Ellahyani, Ayoub] Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
C3 Ibn Zohr University of Agadir
RP Lahmyed, R (corresponding author), Ibn Zohr Univ, Dept Comp Sci, LabSIV, Fac Sci, BP 8106, Agadir 80000, Morocco.
EM lahmyed.redouan@yahoo.fr; m.elansari@uiz.ac.mamelansari@gmail.com;
   ayoub.ellahyani@gmail.com
RI Ellahyani, Ayoub/ABA-8951-2021; El Ansari, Mohamed/L-9738-2016
OI Ellahyani, Ayoub/0000-0001-5881-3328; El Ansari,
   Mohamed/0000-0001-5394-9066; Lahmyed, Redouan/0000-0003-1023-2502
CR Akhloufi, 2013, P SPIE, V9076
   [Anonymous], 2011, P CVPR 2011 WORKSHOP
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Castillo J. C., 2012, Proceedings of the Eighth International Conference on Intelligent Environments (IE 2012), P178, DOI 10.1109/IE.2012.73
   Charfi S, 2018, MULTIMED TOOLS APPL, V77, P4047, DOI 10.1007/s11042-017-4555-7
   Choi S, 2017, ROBOT AUTON SYST, V91, P11, DOI 10.1016/j.robot.2016.12.003
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Cuntoor N, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P113
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   El Ansari M, 2018, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2018), VOL 5: VISAPP, P325, DOI 10.5220/0006620803250334
   Elguebaly T, 2013, COMPUT VIS IMAGE UND, V117, P1659, DOI 10.1016/j.cviu.2013.07.007
   Ellahyani A, 2016, APPL SOFT COMPUT, V46, P805, DOI 10.1016/j.asoc.2015.12.041
   Fendri E, 2017, PATTERN ANAL APPL, V20, P907, DOI 10.1007/s10044-017-0621-z
   Foster JP, 2003, PATTERN RECOGN LETT, V24, P2489, DOI 10.1016/S0167-8655(03)00094-1
   Gascuena JM, 2014, TRENDS PRACTICAL APP, P131
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Ge JF, 2009, IEEE T INTELL TRANSP, V10, P283, DOI 10.1109/TITS.2009.2018961
   Guo L, 2012, EXPERT SYST APPL, V39, P4274, DOI 10.1016/j.eswa.2011.09.106
   Herrmann C, 2016, SPIE SECURITY DEFENC
   Huang DY, 2009, PATTERN RECOGN LETT, V30, P275, DOI 10.1016/j.patrec.2008.10.003
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Ino, IN VID AN DAT
   Ji QB, 2016, MULTIMED TOOLS APPL, V75, P13163, DOI 10.1007/s11042-015-3005-7
   John V, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P246, DOI 10.1109/MVA.2015.7153177
   Kai Jungling, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P30, DOI 10.1109/CVPR.2009.5204085
   Kallhammer J-E, 2016, TRANSPORTATION RES F
   Kassani PH, 2016, APPL SOFT COMPUT
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lahmyed R., 2016, IEEE ACS INT C COMP, P1
   Lee L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P663
   Li HF, 2018, IEEE ACCESS, V6, P37977, DOI 10.1109/ACCESS.2018.2853259
   Li JF, 2010, INFRARED PHYS TECHN, V53, P267, DOI 10.1016/j.infrared.2010.03.005
   Liang CW, 2015, APPL SOFT COMPUT, V28, P483, DOI 10.1016/j.asoc.2014.09.051
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Morales Y, 2017, ROBOT AUTON SYST, V87, P355, DOI 10.1016/j.robot.2016.09.010
   Nanda H, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P15
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouloul IM, 2018, MULTIMED TOOLS APPL, P1
   Per J, 2007, MOTION BASED HUMAN I
   Pers J, 2010, PATTERN RECOGN LETT, V31, P1369, DOI 10.1016/j.patrec.2010.03.024
   Premebida C, 2009, J FIELD ROBOT, V26, P696, DOI 10.1002/rob.20312
   Radman A., 2018, MULTIMED TOOLS APPL, P1
   San-Biagio M., 2012, 2012 5 INT S COMM CO, P1, DOI [10.1109/ISCCSP.2012.6217877, DOI 10.1109/ISCCSP.2012.6217877]
   Serrano-Cuerda Juan, 2014, ELCVIA ELECT LETT CO, V13, P17
   Souaidi M, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Souaidi M, 2019, MULTIMED TOOLS APPL, V78, P13091, DOI 10.1007/s11042-018-6086-2
   Souaidi M, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P183
   Sun H, 2011, NEUROCOMPUTING, V74, P797, DOI 10.1016/j.neucom.2010.10.009
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Torabi A, 2012, COMPUT VIS IMAGE UND, V116, P210, DOI 10.1016/j.cviu.2011.10.006
   Usher JM, 2017, SIMUL MODEL PRACT TH, V75, P96, DOI 10.1016/j.simpat.2017.03.012
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Wagner J., 2016, EUR S ART NEUR NETW
   Wang YT, 2017, IEEE T CIRC SYST VID, V27, P1895, DOI 10.1109/TCSVT.2016.2555740
   Yang T, 2017, MULTIMED TOOLS APPL, V76, P11021, DOI 10.1007/s11042-016-3461-8
   Zhang J, 2016, ARTIF INTELL REV, V46, P543, DOI 10.1007/s10462-016-9491-9
   Zhang L., 2007, Corporate social responsibility, applicants' ethical predispositions and organizational attraction: A person-organization fit perspective, P1
   Zin T.T., 2011, Fusion of infrared and visible images for robust person detection
NR 63
TC 24
Z9 28
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 15861
EP 15885
DI 10.1007/s11042-018-6974-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500007
DA 2024-07-18
ER

PT J
AU Liu, TC
   Liao, JX
   Wang, YL
   Wang, JY
   Qi, Q
AF Liu, Tongcun
   Liao, Jianxin
   Wang, Yulong
   Wang, Jingyu
   Qi, Qi
TI Collaborative tensor-topic factorization model for personalized activity
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location-based social network; Tensor factorization; Biterm topic model;
   Activity recommendation
AB Activity recommendation is a new aspect of location-based social networks (LBSNs) that is being increasingly researched in academia and industry. Previous studies focus mainly on the identification of behavioral regularity by users and use sporadic check-in data, so they suffer severely from data sparsity problems and provide inaccurate recommendations. Furthermore, tips that imply a user's interests and the semantic data available for locations have not been extensively investigated. In this paper, we describe a collaborative tensor-topic factorization (CTTF) model that incorporates user interest topics and activity topics into a tensor factorization framework to create improved activity recommendations for users. We represent user activity feedback with a third-order tensor and penalize false preferences inferred from check-ins using term frequency-inverse document frequency. A biterm topic model was used to learn user interest topics and activity topics from location content information. We learned the latent relations between users, activities, and times by incorporating user interest topics and activity topics into a tensor factorization framework. Experimental results on real world datasets show that the CTTF model outperforms current state-of-the-art approaches.
C1 [Liu, Tongcun; Liao, Jianxin; Wang, Yulong; Wang, Jingyu; Qi, Qi] Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Liu, TC (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Networking & Switching Technol, Beijing 100876, Peoples R China.
EM tongcun.liu@gmail.com
RI Wang, Jingyu/JFK-6346-2023; wang, jing/HJA-5384-2022; liu,
   jiajia/IUN-0901-2023
OI Wang, Jingyu/0000-0002-2182-2228; Liu, TongCun/0000-0002-0520-7807
FU National Natural Science Foundation of China [617710686, 61671079,
   61471063, 61372120, 61421061]; Beijing Municipal Natural Science
   Foundation [4182041, 4152039]; National Basic Research Program of China
   [2013CB329102]
FX This work was jointly supported by: (1) National Natural Science
   Foundation of China (Nos. 617710686, 61671079, 61471063, 61372120, and
   61421061); (2) Beijing Municipal Natural Science Foundation (Nos.
   4182041 and 4152039); and (3) the National Basic Research Program of
   China (No. 2013CB329102).
CR Al-Ayyoub M, 2019, MULTIMED TOOLS APPL, V78, P33435, DOI 10.1007/s11042-018-6557-5
   Al-Ayyoub M, 2018, MULTIMED TOOLS APPL, V77, P4939, DOI 10.1007/s11042-016-4218-0
   Bhargava P, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P130, DOI 10.1145/2736277.2741077
   Bui TH, 2017, MULTIMED TOOLS APPL, V76, P23435, DOI 10.1007/s11042-016-4114-7
   Feng SS, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2069
   Ference G, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P721, DOI 10.1145/2505515.2505637
   Gao H, 2013, CHIN CONT DECIS CONF, P92
   Gao HJ, 2015, AAAI CONF ARTIF INTE, P1721
   He J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1837
   Hong DZ, 2015, BUILDSYS'15 PROCEEDINGS OF THE 2ND ACM INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS FOR ENERGY-EFFICIENT BUILT, P123, DOI 10.1145/2821650.2821657
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Karatzoglou Alexandros, 2010, Multiverse recommendation: N-dimensional tensor factorization for context-aware collaborative filtering, P79, DOI DOI 10.1145/1864708.1864727
   [李晓莎 Li Xiaosha], 2017, [干旱地区农业研究, Agricultural Research in the Arid Areas], V35, P1
   Lian DF, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P831, DOI 10.1145/2623330.2623638
   Liao JX, 2018, IEEE ACCESS, V6, P21980, DOI 10.1109/ACCESS.2018.2827422
   Liu B, 2015, IEEE T KNOWL DATA EN, V27, P1167, DOI 10.1109/TKDE.2014.2362525
   Liu Bin., 2013, P 13 SIAM INT C DATA, P396, DOI DOI 10.1137/1.9781611972832.44
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ren XY, 2017, NEUROCOMPUTING, V241, P38, DOI 10.1016/j.neucom.2017.02.005
   Rendle S., 2010, P 19 INT C WORLD WID, P811, DOI DOI 10.1145/1772690.1772773
   Rendle Steffen, 2010, P 3 ACM INT C WEB SE, P81, DOI DOI 10.1145/1718487.1718498
   Salakhutdinov Ruslan, 2008, ADV NEURAL INFORM PR, P1257, DOI DOI 10.5555/2981562.2981720
   Wang H, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/3097983.3098122
   Wang L, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P171
   Wang WY, 2016, IJCAI, P2132
   Wang YL, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P25, DOI 10.1145/2623330.2623656
   Xiong L., 2010, P 2010 SIAM INT C DA, P211, DOI DOI 10.1137/1.9781611972801.19
   Yan X., 2013, P 22 INT C WORLD WID, P1445, DOI DOI 10.1145/2488388.2488514
   Yang DQ, 2015, IEEE T SYST MAN CY-S, V45, P129, DOI 10.1109/TSMC.2014.2327053
   Yin HZ, 2017, IEEE T KNOWL DATA EN, V29, P2537, DOI 10.1109/TKDE.2017.2741484
   Ying YK, 2017, NEUROCOMPUTING, V242, P195, DOI 10.1016/j.neucom.2017.02.067
   Zhang FZ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P353, DOI 10.1145/2939672.2939673
   Zheng VW, 2010, P 19 INT C WORLD WID, P1029
   Zheng XL, 2016, INFORM SCIENCES, V372, P276, DOI 10.1016/j.ins.2016.08.042
   Zhu Hengshu., 2014, ACM Trans. Intell. Syst. Technol, V5, p58:1, DOI DOI 10.1145/2532515
NR 37
TC 3
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16923
EP 16943
DI 10.1007/s11042-018-7019-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500053
DA 2024-07-18
ER

PT J
AU Musanna, F
   Kumar, S
AF Musanna, Farhan
   Kumar, Sanjeev
TI A novel fractional order chaos-based image encryption using Fisher Yates
   algorithm and 3-D cat map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-Arnold cat map; Fractional order Chen's system; Fisher Yates shuffle;
   Chaotic maps; Image encryption
ID PERMUTATION; SYNCHRONIZATION
AB This paper presents a novel image encryption scheme using 3-D Arnold cat map and Fisher-Yates shuffling algorithm. A plain image is divided into various slices of equal size and then the 3-D representation of the image is shuffled by the 3-D chaotic map. A fractional order system of nonlinear differential equations is used to implement the diffusion in the intensity values of the shuffled image pixels. The solution of this fractional order system develops a strange attractor which is the onset of the chaos. Fisher-Yates is used to make a chaotic matrix which is used for arranging the data points. Experimental results are given on various images with comprehensive analysis which demonstrates the high security and sensitivity of the scheme.
C1 [Musanna, Farhan; Kumar, Sanjeev] Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Musanna, F (corresponding author), Indian Inst Technol Roorkee, Dept Math, Roorkee 247667, Uttar Pradesh, India.
EM 15691.dma2016@iitr.ac.in; malikfma@iitr.ernet.in
RI Kumar, Sanjeev/JTV-5459-2023; Kumar, Sanjeev/HKN-6866-2023
OI Kumar, Sanjeev/0000-0001-7728-3668
FU Ministry of Human Resource Development (MHRD), Government of India;
   Indian Space Research Organization [OGP-150]; IIT Roorkee
FX One of the authors, Farhan Musanna is thankful to IIT Roorkee and
   Ministry of Human Resource Development (MHRD), Government of India for
   the financial support for carrying out this work. This work is also
   supported by the Indian Space Research Organization through their
   project OGP-150 (RESPOND).
CR Ahmad M, 2015, PROCEDIA COMPUT SCI, V57, P852, DOI 10.1016/j.procs.2015.07.494
   [Anonymous], 2001, NIST SPECIAL PUBLICA
   [Anonymous], 2004, Differential Equations, Dynamical Systems, and An Introduction to Chaos
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Bhatnagar G, 2014, INFORM SCIENCES, V277, P247, DOI 10.1016/j.ins.2014.02.018
   Bhatnagar G, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3210015
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Diethelm K, 2002, NONLINEAR DYNAM, V29, P3, DOI 10.1023/A:1016592219341
   Dosselmann R., 2008, FORMAL ASSESSMENT ST
   DURSTENFELD R, 1964, COMMUN ACM, V7, P420, DOI 10.1145/364520.364540
   FORD J, 1991, PHYSICA D, V50, P493, DOI 10.1016/0167-2789(91)90012-X
   Fouda JSAE, 2014, COMMUN NONLINEAR SCI, V19, P578, DOI 10.1016/j.cnsns.2013.07.016
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Institute ANS Committee I. C. S. S Board IS, 1985, IEEE STAND BIN FLOAT
   Kanso A, 2012, COMMUN NONLINEAR SCI, V17, P2943, DOI 10.1016/j.cnsns.2011.11.030
   Kocarev L, 2008, INTELLIGENT COMPUTIN
   Li CP, 2004, CHAOS SOLITON FRACT, V22, P443, DOI 10.1016/j.chaos.2004.02.013
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Mao Y, 2005, CHAOS BASED IMAGE EN, P231
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Musanna Farhan, 2018, Proceedings of 2nd International Conference on Computer Vision & Image Processing. CVIP 2017. Advances in Intelligent Systems and Computing (AISC 704), P365, DOI 10.1007/978-981-10-7898-9_30
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Rani A, 2014, MULTIMED TOOLS APPL, V72, P2225, DOI 10.1007/s11042-013-1528-3
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   SMID ME, 1988, P IEEE, V76, P550, DOI 10.1109/5.4441
   Stallings W, 2002, CRYPTOLOGIA, V26, P165, DOI 10.1080/0161-110291890876
   Volos CK, 2013, SIGNAL PROCESS, V93, P1328, DOI 10.1016/j.sigpro.2012.11.008
   Wang XY, 2015, OPT LASER ENG, V73, P53, DOI 10.1016/j.optlaseng.2015.03.022
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Wong KW, 2008, SPRINGER, V14, P333
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xu Y, 2014, COMMUN NONLINEAR SCI, V19, P3735, DOI 10.1016/j.cnsns.2014.02.029
   Zhang W, 2016, SIGNAL PROCESS, V118, P36, DOI 10.1016/j.sigpro.2015.06.008
   Zhang YQ, 2014, INFORM SCIENCES, V273, P329, DOI 10.1016/j.ins.2014.02.156
   Zhou YC, 2013, SIGNAL PROCESS, V93, P3039, DOI 10.1016/j.sigpro.2013.04.021
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 44
TC 39
Z9 39
U1 2
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14867
EP 14895
DI 10.1007/s11042-018-6827-2
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700033
DA 2024-07-18
ER

PT J
AU Ye, FJ
   Li, XF
   Zhang, XL
AF Ye, Fajie
   Li, Xiongfei
   Zhang, Xiaoli
TI FusionCNN: a remote sensing image fusion algorithm based on deep
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensingimage fusion; Convolutional neural networks; Deep
   learning; Image enhancement
ID CONTOURLET TRANSFORM; WAVELET TRANSFORM; RETRIEVAL; IHS
AB In remote sensing image fusion field, traditional algorithms based on the human-made fusion rules are severely sensitive to the source images. In this paper, we proposed an image fusion algorithm using convolutional neural networks (FusionCNN). The fusion model implicitly represents a fusion rule whose inputs are a pair of source images and the output is a fused image with end-to-end property. As no datasets can be used to train FusionCNN in remote sensing field, we constructed a new dataset from a natural image set to approximate MS and Pan images. In order to obtain higher fusion quality, low frequency information of MS is used to enhance the Pan image in the pre-processing step. The method proposed in this paper overcomes the shortcomings of the traditional fusion methods in which the fusion rules are artificially formulated, because it learns an adaptive strong robust fusion function through a large amount of training data. In this paper, Landsat and Quickbird satellite data are used to verify the effectiveness of the proposed method. Experimental results show that the proposed fusion algorithm is superior to the comparative algorithms in terms of both subjective and objective evaluation.
C1 [Ye, Fajie; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.
   [Ye, Fajie; Li, Xiongfei; Zhang, Xiaoli] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
C3 Jilin University; Jilin University
RP Zhang, XL (corresponding author), Jilin Univ, Key Lab Symbol Computat & Knowledge Engn, Minist Educ, Changchun 130012, Jilin, Peoples R China.; Zhang, XL (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Jilin, Peoples R China.
EM zhangxiaoli@jlu.edu.cn
RI Zhang, Yanchao/JMB-7717-2023; wu, yi/JEP-1581-2023; Zhang,
   Xiaoli/ABC-2210-2021
FU National Science & Technology Pillar Program of China [2012BAH48F02];
   National Natural Science Foundation of China [61272209, 61801190];
   Natural Science Foundation of Jilin Province [20180101055JC];
   Outstanding Young Talent Foundation of Jilin Province [20180520029JH];
   China Postdoctoral Science Foundation [2017M611323]
FX The work was supported by National Science & Technology Pillar Program
   of China (Grant No. 2012BAH48F02), National Natural Science Foundation
   of China (Grant No. 61272209, 61801190), Natural Science Foundation of
   Jilin Province (Grant No. 20180101055JC), Outstanding Young Talent
   Foundation of Jilin Province (Grant No. 20180520029JH) and China
   Postdoctoral Science Foundation (Grant No. 2017M611323). The authors
   would like to thank Dr. Shuang Yu for her help on technical editing of
   the manuscript, and Prof. Xiaoying Sun for scientific advices.
CR Amro I, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-79
   [Anonymous], IEEE INT C IM SYST T
   [Anonymous], IEEE ACCESS
   [Anonymous], APPL MECH MAT
   [Anonymous], 2012, P ADV NEUR INF PROC
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cheng J, 2015, ISPRS J PHOTOGRAMM, V104, P158, DOI 10.1016/j.isprsjprs.2015.02.015
   Choi M, 2005, IEEE GEOSCI REMOTE S, V2, P136, DOI 10.1109/LGRS.2005.845313
   Chu H, 2008, IEEE GEOSCI REMOTE S, V5, P653, DOI 10.1109/LGRS.2008.2002034
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Fan C, 2016, MULTIMED TOOLS APPL, V75, P12201, DOI 10.1007/s11042-015-3004-8
   Gangkofner UG, 2008, PHOTOGRAMM ENG REM S, V74, P1107, DOI 10.14358/PERS.74.9.1107
   Ghahremani M, 2015, INT J REMOTE SENS, V36, P4131, DOI 10.1080/01431161.2015.1071897
   Ghassemian H, 2016, INFORM FUSION, V32, P75, DOI 10.1016/j.inffus.2016.03.003
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hnatushenko VV, 2016, INT ARCH PHOTOGRAMM, V41, P653, DOI 10.5194/isprsarchives-XLI-B7-653-2016
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Kong WW, 2011, IET IMAGE PROCESS, V5, P113, DOI 10.1049/iet-ipr.2009.0425
   Nakazawa T, 2018, IEEE T SEMICONDUCT M, V31, P309, DOI 10.1109/TSM.2018.2795466
   Paramanandham N, 2018, MULTIMED TOOLS APPL, V77, P12405, DOI 10.1007/s11042-017-4895-3
   Park CC, 2018, IEEE T PATTERN ANAL, V40, P945, DOI 10.1109/TPAMI.2017.2700381
   Pohl C, 1998, INT J REMOTE SENS, V19, P823, DOI 10.1080/014311698215748
   Shah VP, 2008, IEEE T GEOSCI REMOTE, V46, P1323, DOI 10.1109/TGRS.2008.916211
   Shahdoosti HR, 2015, IEEE GEOSCI REMOTE S, V12, P611, DOI 10.1109/LGRS.2014.2353135
   Shandoosti HR, 2016, INFORM FUSION, V27, P150, DOI 10.1016/j.inffus.2015.06.006
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Sutskever I, 2014, ADV NEUR IN, V27
   Te-Ming Tu, 2001, Information Fusion, V2, P177, DOI 10.1016/S1566-2535(01)00036-7
   Tu TM, 2004, IEEE GEOSCI REMOTE S, V1, P309, DOI 10.1109/LGRS.2004.834804
   Valizadeh SA, 2012, 2012 SIXTH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P1184, DOI 10.1109/ISTEL.2012.6483168
   Wu B, 2015, J APPL REMOTE SENS, V9, DOI 10.1117/1.JRS.9.097291
   Zhang XL, 2017, MULTIMED TOOLS APPL, V76, P8175, DOI 10.1007/s11042-016-3453-8
NR 34
TC 28
Z9 33
U1 2
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14683
EP 14703
DI 10.1007/s11042-018-6850-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700025
DA 2024-07-18
ER

PT J
AU Gianaria, E
   Grangetto, M
AF Gianaria, Elena
   Grangetto, Marco
TI Robust gait identification using Kinect dynamic skeleton data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait recognition; Computer vision; Biometrics; Person identification;
   Microsoft Kinect
ID RECOGNITION; PERFORMANCE; EXTRACTION
AB Gait has been recently proposed as a biometric feature that, with respect to other human characteristics, can be captured at a distance without requiring the collaboration of the observed subject. Therefore, it turns out to be a promising approach for people identification in several scenarios, e.g. access control and forensic applications. In this paper, we propose an automatic gait recognition system based on a set of features acquired using the 3D skeletal tracking provided by the popular Kinect sensor. Gait features are defined in terms of distances between selected sets of joints and their vertical and lateral sway with respect to walking direction. Moreover we do not rely on any geometrical assumptions on the position of the sensor. The effectiveness of the defined gait features is shown in the case of person identification based on supervised classification, using the principal component analysis and the support vector machine. A rich set of experiments is provided in two scenarios: a controlled identification setup and a classical video-surveillance setting, respectively. Moreover, we investigate if gait can be considered invariant over time for an individual, at least in a time interval of few years, by comparing gait samples of several subjects three years apart. Our experimental analysis shows that the proposed method is robust to acquisition settings and achieves very competitive identification accuracy with respect to the state of the art.
C1 [Gianaria, Elena; Grangetto, Marco] Univ Turin, Comp Sci Dept, Corso Svizzera 185, I-10149 Turin, Italy.
C3 University of Turin
RP Gianaria, E (corresponding author), Univ Turin, Comp Sci Dept, Corso Svizzera 185, I-10149 Turin, Italy.
EM elena.gianaria@unito.it
RI Grangetto, Marco/D-1222-2010
CR Ahmed F, 2015, VISUAL COMPUT, V31, P915, DOI 10.1007/s00371-015-1092-0
   Allard P., 1997, 3 DIMENSIONAL ANAL H
   Andersson V., 2015, P 29 ASS ADV ART INT
   [Anonymous], 8 INT C COMP VIS THE
   [Anonymous], 1998, Biometrics, personal identification in networked society
   Ashbourn J., 2002, BIOMETRICS ADV IDENT
   Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Boyd JE, 2005, LECT NOTES COMPUT SC, V3161, P19
   Chattopadhyay P, 2015, PATTERN RECOGN LETT, V63, P9, DOI 10.1016/j.patrec.2015.06.004
   Chattopadhyay P, 2014, IEEE T INF FOREN SEC, V9, P1843, DOI 10.1109/TIFS.2014.2352114
   Connie T., 2016, IEEE T CYBERNETICS
   Cucchiara R., 2005, IEE P VIS IM SIGN PR
   Franc V, 2004, CZECH CTR MACHINE PE
   Gianaria E, 2017, LECT NOTES COMPUT SC, V10485, P648, DOI 10.1007/978-3-319-68548-9_59
   Gianaria E, 2014, LECT NOTES COMPUT SC, V8897, P16, DOI 10.1007/978-3-319-13386-7_2
   Gianaria E, 2013, IEEE INT WORKSH MULT, P440, DOI 10.1109/MMSP.2013.6659329
   Goffredo M, 2010, MULTIMED TOOLS APPL, V50, P75, DOI 10.1007/s11042-009-0378-5
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hegeman J, 2007, J VESTIBUL RES-EQUIL, V17, P75
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Janssen LJF, 2009, GAIT POSTURE, V29, P575, DOI 10.1016/j.gaitpost.2008.12.009
   Jung SU, 2012, IEEE T INF FOREN SEC, V7, P1802, DOI 10.1109/TIFS.2012.2218598
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Kusakunniran W, 2014, IEEE T INF FOREN SEC, V9, P1416, DOI 10.1109/TIFS.2014.2336379
   Larsen PK, 2007, P VIDEOMETRICS, V6491
   Liu LF, 2009, LECT NOTES ARTIF INT, V5755, P652
   Livingston MA, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P119, DOI 10.1109/VR.2012.6180911
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Pala F, 2015, IEEE T CIRC SYST VID, V8215, P1
   Pei JF, 2013, IEEE INT C BIOINFORM
   Preis J., 2012, P 1 WORKSH KIN PERV
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Urtasun R, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P17, DOI 10.1109/AFGR.2004.1301503
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang N, 2010, PROCEEDINGS OF THE 2ND (2010) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, P320
   Yang K, 2016, J VISUAL COMMUNICATI
   Zhang YT, 2015, IEEE T CYBERNETICS, V45, P1864, DOI 10.1109/TCYB.2014.2361287
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 41
TC 14
Z9 14
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13925
EP 13948
DI 10.1007/s11042-018-6865-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ID4NZ
UT WOS:000471654900059
DA 2024-07-18
ER

PT J
AU Neogi, N
   Adhikari, A
   Roy, M
AF Neogi, Nivedita
   Adhikari, Arunabha
   Roy, Madhusudan
TI Use of a novel set of features based on texture anisotropy for
   identification of liver steatosis from ultrasound images: a simple
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anisotropy features; Classification; Texture; Human liver; Ultrasound
ID COOCCURRENCE MATRIX; CLASSIFICATION; FATTY; DISEASE; TRANSFORM; SYSTEM
AB Detection of fatty liver disease (steatosis) from the ultra sound (US) images using pattern recognition techniques is attempted by many authors. Different pre-processing methods, feature extraction, feature selection and classification models are reported in the literature. The present work uses a hitherto unexplored property of liver texture. A careful visual observation reveals that the liver texture is anisotropic. A novel set of features exploiting this anisotropy is explicitly proposed. These anisotropy features are derived from gray level difference histogram (GLDH), pair correlation function (PCF), probabilistic local directionality statistics and randomness of texture (GLCM-(8)). For comparison with other features, the most popular gray level co-occurrence matrix (GLCM) derived features are also extracted. Accordingly, three alternative data sets are prepared to classify the images with five different classifiers -Bayesian, multilayer perceptron (MLP), probabilistic neural network (PNN), learning vector quantisation (LVQ) and support vector machine (SVM). A comparative evaluation in terms of specificity, sensitivity, discrimination score and accuracy has been made while classifying US images of human livers. On the basis of results this paper enumerates as to how the anisotropy feature provides better entity for classification purpose in the present context. It is also shown that the highest accuracy of 99% is obtained using anisotropy features with PNN. Anisotropy features leads to 100% sensitivity with PNN and SVM. The present classification system with anisotropy features outperforms the existing models available in the literature keeping in mind the simplicity of the algorithm.
C1 [Neogi, Nivedita] Meghnad Saha Inst Technol, Dept Informat Technol, Techno India Grp, Kolkata, India.
   [Adhikari, Arunabha] West Bengal State Univ, Barasat, India.
   [Roy, Madhusudan] Saha Inst Nucl Phys, Kolkata, India.
C3 West Bengal State University; Saha Institute of Nuclear Physics
RP Adhikari, A (corresponding author), West Bengal State Univ, Barasat, India.
EM arunabha.adhikari@gmail.com
OI , Nivedita Neogi/0000-0003-3814-7000
CR Acharya UR, 2016, COMPUT BIOL MED, V79, P250, DOI 10.1016/j.compbiomed.2016.10.022
   Acharya UR, 2016, INFORM FUSION, V31, P43, DOI 10.1016/j.inffus.2015.12.007
   Acharya UR, 2016, INFORM FUSION, V29, P32, DOI 10.1016/j.inffus.2015.09.006
   Acharya UR, 2012, MED PHYS, V39, P4255, DOI 10.1118/1.4725759
   Alivar A, 2016, BIOCYBERN BIOMED ENG, V36, P697, DOI 10.1016/j.bbe.2016.07.003
   Andrade A, 2012, PROC TECH, V5, P763, DOI 10.1016/j.protcy.2012.09.084
   [Anonymous], COGN MODEL
   [Anonymous], COMPUTATIONAL LEARNI
   Aras B, 1999, PROCEEDINGS OF THE IEEE-EURASIP WORKSHOP ON NONLINEAR SIGNAL AND IMAGE PROCESSING (NSIP'99), P858
   Araújo AR, 2018, LIVER INT, V38, P47, DOI 10.1111/liv.13643
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P1513, DOI 10.1016/S0167-8655(02)00390-2
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   CELEBI E, LECT NOTES COMPUT SC, V1909, P216
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chetverikov D., 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P444, DOI 10.1109/ICPR.1994.576320
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   CLAUSI DA, 1996, THESIS U WATERLOO WA
   Cordón O, 1999, INT J APPROX REASON, V20, P21, DOI 10.1016/S0888-613X(00)88942-2
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   CUI Y, 2008, IEEE, V3, P95, DOI DOI 10.1109/CISP.2008.397
   Duseja A, 2010, INDIAN J GASTROENTER, V29, P217, DOI 10.1007/s12664-010-0069-1
   Eleyan A, 2011, TURK J ELECTR ENG CO, V19, P97, DOI 10.3906/elk-0906-27
   Gaitini D, 2005, ULTRASCHALL MED, V26, P197, DOI 10.1055/s-2005-858267
   Gao S, 2014, BIO-MED MATER ENG, V24, P1209, DOI 10.3233/BME-130922
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haykin S, 2004, NEURAL NETWORKS, V2, P41
   Japkowicz N., 2000, P 2000 INT C ART INT
   Kohonen T., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P545, DOI 10.1109/IJCNN.1990.137622
   Lee WL, 2003, IEEE T MED IMAGING, V22, P382, DOI 10.1109/TMI.2003.809593
   Lehoucq R, 2015, FRONT PHYS, V2, DOI 10.3389/fphy.2014.00084
   Li GK, 2008, IEEE ENG MED BIO, P4768, DOI 10.1109/IEMBS.2008.4650279
   Ling CharlesX., 1998, P 4 INT C KNOWL DISC
   Longstaff D, 1995, P DICTA 95 3 INT C D
   Minhas FUA, 2012, J MED SYST, V36, P3163, DOI 10.1007/s10916-011-9803-1
   Mitchell T. M., 1997, MACHINE LEARNING
   Moldovanu S., 2012, INT J BIOL BIOMED EN, V6, P69
   Neogi N, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE (ICIS), P114, DOI 10.1109/INFOSCI.2016.7845311
   Ogawa K, 1998, IEEE T NUCL SCI, V45, P3069, DOI 10.1109/23.737666
   Owjimehr Mehri, 2015, J Med Signals Sens, V5, P21
   Patel MB, 2008, IEEE IMAGE PROC, P585, DOI 10.1109/ICIP.2008.4711822
   Ribeiro R, 2012, IEEE ENG MED BIO, P6547, DOI 10.1109/EMBC.2012.6347494
   Saba L, 2016, COMPUT METH PROG BIO, V130, P118, DOI 10.1016/j.cmpb.2016.03.016
   Sharma G, 2012, LECT NOTES COMPUT SC, V7578, P1, DOI 10.1007/978-3-642-33786-4_1
   Singh M., 2012, INT J COMPUT ELECT E, V4, P605, DOI [10.7763/IJCEE.2012.V4.567, DOI 10.7763/IJCEE.2012.V4.567]
   Singh M, 2014, INFORM FUSION, V19, P91, DOI 10.1016/j.inffus.2013.05.007
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Tou Jing Yi, 2007, P INT WORKSH ADV IM
   Valckx FMJ, 1997, ULTRASOUND MED BIOL, V23, P559, DOI 10.1016/S0301-5629(97)00041-0
   WAN J, 2010, IMAGE AND SIGNAL PRO, V2, P949
   WELCH BL, 1947, BIOMETRIKA, V34, P28, DOI 10.2307/2332510
   Yali Huang, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P562, DOI 10.1109/CISP.2010.5647275
   Yeh WC, 2003, ULTRASOUND MED BIOL, V29, P1229, DOI 10.1016/S0301-5629(03)01010-X
   Yu F, 2018, LEARNING RICH IMAGE
   ZUCKER SW, 1980, COMPUT VISION GRAPH, V12, P286, DOI 10.1016/0146-664X(80)90016-7
NR 56
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11105
EP 11127
DI 10.1007/s11042-018-6675-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900002
DA 2024-07-18
ER

PT J
AU Zouari, R
   Boubaker, H
   Kherallah, M
AF Zouari, Ramzi
   Boubaker, Houcine
   Kherallah, Monji
TI Multi-language online handwriting recognition based on beta-elliptic
   model and hybrid TDNN-SVM classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Online handwriting; Multi-language; Beta-elliptic model; Velocity beta
   impulse; Pseudo-word; RNN-LSTM; TDNN; Receptive field
ID REPRESENTATION; MOVEMENTS; TIME
AB Recently, several researches were carried on handwritten document analysis field thanks to the evolution of data capture technologies. For a given document, multiple components could be treated as text, signatures and graphics. In this study, we present a new framework for a Multilanguage online handwritten text analysis where both script identification and recognition are made. The proposed system proceeds by segmenting the script into continuous trajectories delimited between two successive pen-down and pen-up moments. These segments are clustered and trained using Time Delay Neural Network (TDNN) according to their beta-elliptic parameters. In script identification process, the segments belonging to the same script are gathered and brought to a Recurrent Neural Network with Long Short Term Memory (RNN-LSTM) in order to identify its language. For script recognition stage, the samples from the already selected language database are trained and tested using the fuzzy output description obtained by the TDNN coupled to a Support Vector Machines (SVM). The Experiments were made on a large multi-language database containing 45686 online handwriting words from Latin, Arabic and digit scripts and shows very promising results that exceed the recognition rate of 99%.
C1 [Zouari, Ramzi; Boubaker, Houcine] Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
   [Kherallah, Monji] Univ Sfax, Fac Sci Sfax, Sfax, Tunisia.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; Faculty of Sciences Sfax
RP Zouari, R (corresponding author), Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
EM ramzi.zouari@gmail.com; houcine-boubaker@ieee.org;
   monji.kherallah@enis.rnu.tn
OI Zouari, Ramzi/0000-0002-2634-5280; KHERALLAH, Monji/0000-0002-4549-1005
FU General Direction of Scientific Research and Technological Renovation
   (DGRST), Tunisia, under the ARUB program [01/UR/11/02]
FX This work was supported by grants from the General Direction of
   Scientific Research and Technological Renovation (DGRST), Tunisia, under
   the ARUB program 01/UR/11/02.
CR Ahmed H, 2011, PROC INT CONF DOC, P1324, DOI 10.1109/ICDAR.2011.266
   Alimi A. M., 2003, TASK Quarterly, V7, P23
   Alimoglu F., 2001, Turkish Journal Electrical Engineering and Computer Sciences, Elektrik, V9, P1
   [Anonymous], 1996, INT WORKSHOP FRONTIE
   Bezine H, 2004, NINTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION, PROCEEDINGS, P515, DOI 10.1109/IWFHR.2004.45
   Bhattacharya S, 2016, INT CONF FRONT HAND, P373, DOI [10.1109/ICFHR.2016.71, 10.1109/ICFHR.2016.0076]
   Boubaker H., 2012, Guide to OCR for Arabic Scripts, P541
   Boubaker H, 2015, COMPUT METHOD BIOMEC, V18, P1632, DOI 10.1080/10255842.2014.940331
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Elleuch M, 2016, LECT NOTES COMPUT SC, V9887, P136, DOI 10.1007/978-3-319-44781-0_17
   Gargouri M, 2013, PROC INT CONF DOC, P428, DOI 10.1109/ICDAR.2013.93
   Ghosh R, 2016, INT CONF FRONT HAND, P435, DOI [10.1109/ICFHR.2016.0087, 10.1109/ICFHR.2016.82]
   Ghosh R, 2015, PROC INT CONF DOC, P401, DOI 10.1109/ICDAR.2015.7333792
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Guo Xian Tan, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P336, DOI 10.1109/ICDAR.2009.162
   GUYON I, 1994, INT C PATT RECOG, P29, DOI 10.1109/ICPR.1994.576870
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HOLLERBACH JM, 1981, BIOL CYBERN, V39, P139, DOI 10.1007/BF00336740
   Indhu TR, 2015, 2015 FIFTH INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATIONS (ICACC), P33, DOI 10.1109/ICACC.2015.11
   Keysers D, 2017, IEEE T PATTERN ANAL, V39, P1180, DOI 10.1109/TPAMI.2016.2572693
   Kherallah M, 2009, ENG APPL ARTIF INTEL, V22, P153, DOI 10.1016/j.engappai.2008.05.010
   Kherallah M., 2002, IEEE International Conference on Systems, Man and Cybernetics, V2, P164
   Kherallah M, 2008, PATTERN RECOGN LETT, V29, P580, DOI 10.1016/j.patrec.2007.11.011
   Kherallah M, 2011, PROC INT CONF DOC, P1454, DOI 10.1109/ICDAR.2011.289
   Khlif H, 2016, INT CONF FRONT HAND, P399, DOI [10.1109/ICFHR.2016.0081, 10.1109/ICFHR.2016.76]
   Maalej R, 2016, PROCEEDINGS OF 12TH IAPR WORKSHOP ON DOCUMENT ANALYSIS SYSTEMS, (DAS 2016), P417, DOI 10.1109/DAS.2016.49
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Nakkach H, 2016, 3 INT C AUT CONTR EN, P120
   Namboodiri AM, 2004, IEEE T PATTERN ANAL, V26, P124, DOI 10.1109/TPAMI.2004.1261096
   Nguyen T, 2014, SEMIINCREMENTAL RECO
   O'Reilly C, 2009, PATTERN RECOGN, V42, P3324, DOI 10.1016/j.patcog.2008.10.017
   PLAMONDON R, 1995, BIOL CYBERN, V72, P309, DOI 10.1007/BF00202786
   PLAMONDON R, 1993, BIOL CYBERN, V69, P119, DOI 10.1007/BF00226195
   Samanta O, 2015, PROC INT CONF DOC, P1251, DOI 10.1109/ICDAR.2015.7333964
   Sun LF, 2016, ACSR ADV COMPUT, V47, P271
   Tagougui N., 2013, World Congress in Computer and Information Technology (WCCIT), P1
   Vapnik V, 1998, STAT LEARNING THEORY, V1, P1735
   VIVIANI P, 1982, NEUROSCIENCE, V7, P431, DOI 10.1016/0306-4522(82)90277-9
   Pham V, 2014, INT CONF FRONT HAND, P285, DOI 10.1109/ICFHR.2014.55
   WAIBEL A, 1989, IEEE T ACOUST SPEECH, V37, P328, DOI 10.1109/29.21701
   Yang WX, 2015, PROC INT CONF DOC, P551, DOI 10.1109/ICDAR.2015.7333822
   Zhou XD, 2014, PATTERN RECOGN, V47, P1904, DOI 10.1016/j.patcog.2013.12.002
   Zhu BL, 2016, INT CONF FRONT HAND, P417, DOI [10.1109/ICFHR.2016.0084, 10.1109/ICFHR.2016.79]
   Zouari R, 2016, TIME DELAY NEURAL NE
NR 44
TC 7
Z9 7
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12103
EP 12123
DI 10.1007/s11042-018-6764-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900046
DA 2024-07-18
ER

PT J
AU Cao, GH
   Wang, XY
AF Cao, Guanghui
   Wang, Xingyuan
TI Image encryption based on the combination of roulette wheel selection
   with linear congruence pixel transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic system; Roulette wheel selection; Linear congruence; Linear
   congruence transformation
ID ALGORITHM; SCHEME; CHAOS; MAP; SYNCHRONIZATION; DEGRADATION; SECURITY
AB To overcome the challenges encountered in chaotic image encryption system, such as dynamic degradation, weak security, and low encryption efficiency, this paper proposes a new image encryption algorithm. In terms of key generation method, a roulette wheel selection algorithm is designed, which effectively reduces dynamic degradation. In pixel coding, a linear congruence pixel transformation method is proposed, which enhances the security of pixel transform. In the overall layout of the encryption algorithm, the substitution-permutation-substitution structure is adopted. Under the joint action of various aspects, encryption efficiency is improved while security of our proposed encryption algorithm is guaranteed. Additionally, during design, the motivation of each part of the algorithm is explained. Theoretical analysis and experimental results show our proposed algorithm has a good application prospect.
C1 [Cao, Guanghui] Liaoning Univ Technol, Sch Elect & Informat Engn, Jin Zhou 121001, Peoples R China.
   [Wang, Xingyuan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Xingyuan] Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian 116024, Peoples R China.
C3 Liaoning University of Technology; Dalian Maritime University; Dalian
   University of Technology
RP Cao, GH (corresponding author), Liaoning Univ Technol, Sch Elect & Informat Engn, Jin Zhou 121001, Peoples R China.
EM caoguanghuineu@163.com; wangxy@dlut.edu.cn
RI Wang, Xing-yuan/I-6353-2015
OI guanghui, cao/0000-0001-9726-1271
FU National Natural Science Foundation of China [61672124, 61370145,
   61502216, 61802161, 51679116]; Password Theory Project of the 13th
   Five-Year Plan National Cryptography Development Fund [MMJJ20170203];
   Natural Science Foundation of Liaoning Province, People Republic of
   China [201602365, 201602372, 20170540434, 20170540448]
FX This research is supported by the National Natural Science Foundation of
   China (Nos: 61672124, 61370145, 61502216,61802161 and 51679116), the
   Password Theory Project of the 13th Five-Year Plan National Cryptography
   Development Fund (No: MMJJ20170203), Natural Science Foundation of
   Liaoning Province, People Republic of China (Nos: 201602365, 201602372,
   20170540434 and 20170540448).
CR [Anonymous], HUM
   Cao GG, 2014, INT J SECUR APPL, V8, P77, DOI 10.14257/ijsia.2014.8.4.08
   Deng YS, 2015, INFORM SCIENCES, V305, P146, DOI 10.1016/j.ins.2015.01.028
   HEIDARIBATENI G, 1994, IEEE T COMMUN, V42, P1524, DOI 10.1109/TCOMM.1994.582834
   Hu HP, 2008, CHAOS SOLITON FRACT, V38, P439, DOI 10.1016/j.chaos.2006.11.027
   Hua ZY, 2016, INFORM SCIENCES, V339, P237, DOI 10.1016/j.ins.2016.01.017
   Hua ZY, 2015, INFORM SCIENCES, V297, P80, DOI 10.1016/j.ins.2014.11.018
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Li CQ, 2008, IEEE INT SYMP CIRC S, P3290, DOI 10.1109/ISCAS.2008.4542161
   Li CQ, 2013, INT J BIFURCAT CHAOS, V23, DOI 10.1142/S0218127413500752
   Li H, 2011, ACTA PHYS SIN-CH ED, V60, DOI 10.7498/aps.60.070512
   Li SJ, 2005, INT J BIFURCAT CHAOS, V15, P3119, DOI 10.1142/S0218127405014052
   Li SJ, 2003, COMPUT PHYS COMMUN, V153, P52, DOI 10.1016/S0010-4655(02)00875-5
   Li X, 2013, MATH COMPUT MODEL, V58, P85, DOI 10.1016/j.mcm.2012.06.033
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liu HJ, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P3016, DOI 10.1109/ICYCS.2008.449
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu SB, 2009, CHINESE PHYS B, V18, P5219, DOI 10.1088/1674-1056/18/12/019
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Nagaraj N, 2008, EUR PHYS J-SPEC TOP, V165, P73, DOI 10.1140/epjst/e2008-00850-4
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Papadimitriou S, 2001, INT J BIFURCAT CHAOS, V11, P3107, DOI 10.1142/S0218127401004030
   Ping P, 2014, SIGNAL PROCESS, V105, P419, DOI 10.1016/j.sigpro.2014.06.020
   Rowlands T, MORE RESILIENT APPRO
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Teekeng W, 2012, PROCEDIA COMPUT SCI, V12, P122, DOI 10.1016/j.procs.2012.09.041
   Wang CQ, 2017, MULTIMED TOOLS APPL, V76, P24251, DOI 10.1007/s11042-016-4102-y
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P6229, DOI 10.1007/s11042-016-3311-8
   Wang XY, 2012, OPT COMMUN, V285, P412, DOI 10.1016/j.optcom.2011.10.010
   Wei D, 2017, MATH METHOD APPL SCI, V40, P4259, DOI 10.1002/mma.4302
   Wheeler D. D., 1991, Cryptologia, V15, P140, DOI 10.1080/0161-119191865821
   Wheeler DD., 1989, CRYPTOLOGIA, V13, P243, DOI DOI 10.1080/0161-118991863934
   WU Y, 2012, IMAGE, V21, P3014
   Wu Y, 2014, IEEE T CIRCUITS-I, V61, P3469, DOI 10.1109/TCSI.2014.2336512
   Xia XH, 2012, PHYSCS PROC, V24, P269, DOI 10.1016/j.phpro.2012.02.040
   Xiao D, 2005, CHAOS SOLITON FRACT, V24, P65, DOI 10.1016/j.chaos.2004.07.003
   Yang YG, 2016, INFORM SCIENCES, V345, P257, DOI 10.1016/j.ins.2016.01.078
   Zhang H, 2017, OPT LASER ENG, V88, P65, DOI 10.1016/j.optlaseng.2016.07.004
   Zhang XQ, 2012, OPT COMMUN, V285, P1736, DOI 10.1016/j.optcom.2011.12.023
   Zhang XW, MULTIMAP ORBIT HOPPI
   Zhang Y, 2016, IETE TECH REV, V33, P310, DOI 10.1080/02564602.2015.1087350
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zou YP, 2006, INT C COMMUN CIRCUIT, P1732, DOI 10.1109/ICCCAS.2006.285008
NR 46
TC 8
Z9 9
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10625
EP 10647
DI 10.1007/s11042-018-6635-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400049
DA 2024-07-18
ER

PT J
AU Joseph, J
   Anoop, BN
   Williams, J
AF Joseph, Justin
   Anoop, B. N.
   Williams, Joseph
TI A modified unsharp masking with adaptive threshold and objectively
   defined amount based on saturation constraints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Edge enhancement; Gaussian high pass filter; Homomorphic filtering;
   Image sharpening; Unsharp masking
ID QUALITY ASSESSMENT; ENHANCEMENT; SEGMENTATION; FILTER; INTENSITY;
   FEATURES; IMAGES; ERROR
AB Unsharp Masking (UM) is a popular technique widely used for sharpening medical imagery. However, UM has two operational parameters which have crucial influence on its performance. They are amount () and threshold (). Improper selection of the threshold and amount will cause noise amplification and overshoot artefact, respectively. A fully adaptive UM with data driven operational parameters, for sharpening Magnetic Resonance (MR) images is proposed in this paper. The proposed sharpening scheme is compared with the homomorphic filter in terms of sharpness of the output image, width of salient edges, feature preservation, saturation and edge quality degradation due to noise. The proposed scheme of UM is found to be superior to homomorphic filter in terms of edge strength and feature preservation and it is free from overshoot artefacts. Modified configuration of UM, proposed in this paper can be used for improving the edge quality of MR images. It can be incorporated as a plug-in in software tools used for the automated analysis of MRI.
C1 [Joseph, Justin] Natl Inst Technol, Dept Biomed Engn, Raipur 492010, Madhya Pradesh, India.
   [Anoop, B. N.] St Josephs Coll Engn & Technol, Sch Elect, Palai 686579, India.
   [Williams, Joseph] All India Inst Med Sci, Dept ENT & Head & Neck Surg, Raipur, Chattisgarh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; All India Institute of Medical Sciences (AIIMS)
   Raipur
RP Joseph, J (corresponding author), Natl Inst Technol, Dept Biomed Engn, Raipur 492010, Madhya Pradesh, India.
EM josephjusti@gmail.com
RI B N, ANOOP/AAZ-4587-2021
OI B N, ANOOP/0000-0002-6082-391X; Joseph, Justin/0000-0001-6705-9902
CR Aja-Fernández S, 2015, MED IMAGE ANAL, V20, P184, DOI 10.1016/j.media.2014.11.005
   Alasadi AHH, 2017, J MED SYST, P41
   [Anonymous], ACTION2ACTIVITY RECO
   [Anonymous], NEURAL COMPUT APPL
   Anoop BN, 2018, AUSTRALAS PHYS ENG S, V41, P415, DOI 10.1007/s13246-018-0638-7
   Brettle D, 2011, BRIT DENT J, V211, P167, DOI 10.1038/sj.bdj.2011.676
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Datta E, 2017, NEUROIMAGE, V147, P788, DOI 10.1016/j.neuroimage.2016.07.062
   Deng G, 2011, IEEE T IMAGE PROCESS, V20, P1249, DOI 10.1109/TIP.2010.2092441
   Deng H, 2016, SCI REP-UK, V6, DOI 10.1038/srep35760
   Fan CN, 2011, PATTERN RECOGN LETT, V32, P1468, DOI 10.1016/j.patrec.2011.03.023
   Feichtenhofer C, 2013, IEEE SIGNAL PROC LET, V20, P379, DOI 10.1109/LSP.2013.2248711
   Geng Y., 2016, ARXIV160908417
   Grigoryan AM, 2016, SIGNAL PROCESS, V121, P111, DOI 10.1016/j.sigpro.2015.11.006
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   Hajiaghayi M, 2017, IEEE T BIO-MED ENG, V64, P134, DOI 10.1109/TBME.2016.2542243
   Hari VS, 2013, PATTERN RECOGN, V46, P3198, DOI 10.1016/j.patcog.2013.05.014
   Ilk HG, 2011, INFRARED PHYS TECHN, V54, P427, DOI 10.1016/j.infrared.2011.06.002
   Ilunga-Mbuyamba E, 2017, NEUROCOMPUTING, V220, P84, DOI 10.1016/j.neucom.2016.07.057
   Joseph J, 2017, BIOCYBERNETICS BIOME
   Joseph J, 2018, COMPUT ELECTR ENG, V69, P782, DOI 10.1016/j.compeleceng.2018.02.033
   Joseph J, 2018, BIOMED SIGNAL PROCES, V39, P271, DOI 10.1016/j.bspc.2017.08.003
   Khadidos A, 2017, IEEE T IMAGE PROCESS, V26, P1979, DOI 10.1109/TIP.2017.2666042
   Krasula L, 2017, IEEE T IMAGE PROCESS, V26, P1496, DOI 10.1109/TIP.2017.2651374
   Liang RZ, 2016, P IEEE 28 INT C TOOL
   Liang RZ, 2016, P 23 INT C PATT REC
   Lin SCF, 2016, OPTIK, V127, P407, DOI 10.1016/j.ijleo.2015.08.046
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Panetta K, 2011, IEEE T INF TECHNOL B, V15, P918, DOI 10.1109/TITB.2011.2164259
   Polesel A, 2000, IEEE T IMAGE PROCESS, V9, P505, DOI 10.1109/83.826787
   Trentacoste M, 2012, COMPUT GRAPH FORUM, V31, P555, DOI 10.1111/j.1467-8659.2012.03056.x
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao LM, 2016, NEUROCOMPUTING, V195, P56, DOI 10.1016/j.neucom.2015.08.113
   Zhao Y, 2017, MAGN RESON IMAGING, V39, P1, DOI 10.1016/j.mri.2016.04.003
NR 36
TC 11
Z9 12
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 11073
EP 11089
DI 10.1007/s11042-018-6682-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400068
DA 2024-07-18
ER

PT J
AU Kharel, J
   Shin, SY
AF Kharel, Jeevan
   Shin, Soo Young
TI Multimedia service utilizing hierarchical fog computing for vehicular
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicular networks; Fog computing; Wireless communication; Internet of
   things; Performance evaluation
AB This paper focuses on the enhancement of multimedia streaming services for passengers travelling in vehicles. Online media streaming and sharing is popular and has increased tremendously these days whether it is used at home, in the office or while travelling. The millions of internet users accessing media contents consumes a huge bandwidth and can create Internet bottlenecks or traffic congestion. Media traffic like videos flowing from such congested links can introduce even higher delays increasing buffering time. This can bring a bad Quality of Service (QoS) and bad Quality of Experience (QoE) to users. Such degradation is seen even more when streaming requests are sent by clients within mobile nodes like vehicles. To tackle this issue this paper proposes a hierarchical fog computing based multimedia streaming that reduces latency and minimizes Internet bandwidth consumption. A simulation was conducted for the performance evaluation of the proposed architecture and video streaming service was considered for evaluation. The result acquired from the simulation showed that proposed architecture enhances the QoS and brings better QoE to users.
C1 [Kharel, Jeevan; Shin, Soo Young] Kumoh Natl Inst Technol, Dept IT Convergence Engn, Gumi 39177, Gyeongbuk, South Korea.
C3 Kumoh National University Technology
RP Kharel, J (corresponding author), Kumoh Natl Inst Technol, Dept IT Convergence Engn, Gumi 39177, Gyeongbuk, South Korea.
EM jeevankharel@kumoh.ac.kr
RI Shin, Soo Young/ABG-4608-2021
OI Shin, Soo Young/0000-0002-2526-2395; Kharel, Jeevan/0000-0003-3599-8993
FU MSIT (Ministry of Science and ICT), Korea, under the ITRC (Information
   Technology Research Center) [IITP-2017-2014-0-00639]
FX This research was supported by the MSIT (Ministry of Science and ICT),
   Korea, under the ITRC (Information Technology Research Center) support
   program(IITP-2017-2014-0-00639) supervised by the IITP (Institute for
   Information & communications Technology Promotion).
CR [Anonymous], 2015, ITU G 107 E MODEL CO
   [Anonymous], IND CVN FOR METH 201
   [Anonymous], I REC 1225 GUID EV R
   Batalla JM, 2017, IEEE COMMUN MAG, V55, P98, DOI 10.1109/MCOM.2017.1600225CM
   Blaunstein N., 1999, Radio Propagation in Cellular Networks
   Bonomi Flavio, 2012, P 1 MCC WORKSH MOB C, P13, DOI 10.1145/2342509.2342513
   Boukerche A, 2018, COMPUT NETW, V135, P171, DOI 10.1016/j.comnet.2018.01.004
   Demichelis C., 2002, IP packet delay variation metric for IP performance metrics (IPPM). RFC 3393
   Emmerson R.H.C., MAR ENVIRON RES, V34, P960, DOI [10.1016/S0025-326X(97)00067-2, DOI 10.1016/S0141-1136(97)00002-0]
   Huang CM, 2016, IEEE SYST J, V10, P568, DOI 10.1109/JSYST.2014.2326002
   Huang JS, 2013, FUTURE INTERNET, V5, P535, DOI 10.3390/fi5040535
   Ickin S, 2010, C LOCAL COMPUT NETW, P663, DOI 10.1109/LCN.2010.5735791
   Jiang Q, 2015, IEEE T COMMUN, V63, P4682, DOI 10.1109/TCOMM.2015.2496260
   Li F, 2007, IEEE VEH TECHNOL MAG, V2, P12, DOI 10.1109/MVT.2007.912927
   Liang WE, 2016, INT CONF COMPUT NETW, P556, DOI 10.1109/iccnc.2017.7876189
   MA G, 2017, JSAC, V35, P1076, DOI DOI 10.1109/JSAC.2017.2680958
   Mammeri A, 2016, IEEE SYST J, V10, P785, DOI 10.1109/JSYST.2015.2455813
   Meneguette RI, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/8198597
   Peng MG, 2016, IEEE NETWORK, V30, P46, DOI 10.1109/MNET.2016.7513863
   Rappaport T, 2001, COMMUNICATIONS WIREL
   Sheikh AM, 2014, IEEE T MULTIMEDIA, V16, P2294, DOI 10.1109/TMM.2014.2357716
   Sun L, 2017, IEEE T VEH TECHNOL, V66, P734, DOI 10.1109/TVT.2016.2535659
   Wang F, 2016, IEEE ACM T NETWORK, V24, P272, DOI 10.1109/TNET.2014.2362541
   Whaiduzzaman M, 2014, J NETW COMPUT APPL, V40, P325, DOI 10.1016/j.jnca.2013.08.004
   Wu D, 2011, IEEE INT C INTELL TR, P2057, DOI 10.1109/ITSC.2011.6083019
   Yaacoub E, 2015, IEEE J-STSP, V9, DOI 10.1109/JSTSP.2014.2330343
   Yousefi S, 2008, IEEE T VEH TECHNOL, V57, P3341, DOI 10.1109/TVT.2008.2002957
   Zhou HB, 2016, IEEE J SEL AREA COMM, V34, P2260, DOI 10.1109/JSAC.2016.2577219
NR 28
TC 5
Z9 5
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9405
EP 9428
DI 10.1007/s11042-018-6530-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800079
DA 2024-07-18
ER

PT J
AU Obeso, AM
   Benois-Pineau, J
   Vázquez, MSG
   Acosta, AAR
AF Montoya Obeso, A.
   Benois-Pineau, J.
   Garcia Vazquez, M. S.
   Acosta, A. A. Ramirez
TI Saliency-based selection of visual content for deep convolutional neural
   networks: Application to architectural style classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data selection; Visual attention prediction; Cultural heritage; Deep
   learning
ID RECOGNITION; OBJECTS
AB The automatic description of digital multimedia content was mainly developed for classification tasks, retrieval systems and massive ordering of data. Preservation of cultural heritage is a field of high importance of application of these methods. We address classification problem in cultural heritage such as classification of architectural styles in digital photographs of Mexican cultural heritage. In general, the selection of relevant content in the scene for training classification models makes the models more efficient in terms of accuracy and training time. Here we use a saliency-driven approach to predict visual attention in images and use it to train a Deep Convolutional Neural Network. Also, we present an analysis of the behavior of the models trained under the state-of-the-art image cropping and the saliency maps. To train invariant models to rotations, data augmentation of training set is required, which posses problems of filling normalization of crops, we study were different padding techniques and we find an optimal solution. The results are compared with the state-of-the-art in terms of accuracy and training time. Furthermore, we are studying saliency cropping in training and generalization for another classical task such as weak labeling of massive collections of images containing objects of interest. Here the experiments are conducted on a large subset of ImageNet database. This work is an extension of preliminary research in terms of image padding methods and generalization on large scale generic database.
C1 [Montoya Obeso, A.] Inst Politecn Nacl, Comp Sci, Mexico City, DF, Mexico.
   [Garcia Vazquez, M. S.] Inst Politecn Nacl, CITEDI, Digital Technol Res & Dev Ctr, Mexico City, DF, Mexico.
   [Montoya Obeso, A.; Benois-Pineau, J.] Univ Bordeaux, Comp Sci, Bordeaux, France.
   [Acosta, A. A. Ramirez] MIRAL R&D&I, Res Dev Integrat Innovat, San Diego, CA USA.
C3 Instituto Politecnico Nacional - Mexico; Instituto Politecnico Nacional
   - Mexico; Universite de Bordeaux
RP Obeso, AM (corresponding author), Inst Politecn Nacl, Comp Sci, Mexico City, DF, Mexico.; Obeso, AM (corresponding author), Univ Bordeaux, Comp Sci, Bordeaux, France.
EM amontoyao1500@alumno.ipn.mx
RI Montoya, Abraham/AAB-7107-2019; Benois-Pineau, Jenny/ABG-6325-2020
OI Benois-Pineau, Jenny/0000-0003-0659-8894
FU CONACYT [SIP2017]
FX This work was sponsored by CONACYT and SIP2017.
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Ali H, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P837, DOI 10.1109/ICIAP.2007.4362880
   [Anonymous], 1935, How people look at pictures: A study of the psychology and perception in art
   [Anonymous], P 15 INT WORKSH CONT
   [Anonymous], INT SOC OPTICS PHOTO
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2013, INT C MACHINE LEARNI
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017 7 INT C IM PROC
   [Anonymous], 2010, Int. J. Soft Comput., DOI DOI 10.3923/IJSCOMP.2010.19.28
   [Anonymous], 1983, SOV MATH DOKL
   [Anonymous], TRAIN SYST
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   BenoisPineau J, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57687-9
   Berg AC, 2007, IEEE 11 INT C 2007 C, P1
   Bhowmik N, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.011019
   Buso V, 2015, SIGNAL PROCESS-IMAGE, V39, P418, DOI 10.1016/j.image.2015.05.006
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Ghodrati A, 2017, INT J COMPUT VISION, V124, P115, DOI 10.1007/s11263-017-1006-x
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   González-Díaz I, 2016, PATTERN RECOGN, V56, P129, DOI 10.1016/j.patcog.2016.03.007
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Howard A. G., 2013, Some improvements on deep convolutional neural network based image classification
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Liu ZJ, 2005, INT GEOSCI REMOTE SE, P2250
   Llamas Jose, 2016, Digital Heritage. Progress in Cultural Heritage: Documentation, Preservation and Protection. 6th International Conference, EuroMed 2016. Proceedings: LNCS 10059, P25, DOI 10.1007/978-3-319-48974-2_4
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Mathe S, 2012, LECT NOTES COMPUT SC, V7573, P842, DOI 10.1007/978-3-642-33709-3_60
   Mathias M, 2011, INT ARCH PHOTOGRAMM, V38-5, P171
   Obeso AM, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.011016
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Ren XF, 2010, PROC CVPR IEEE, P3137, DOI 10.1109/CVPR.2010.5540074
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   San Biagio M, 2014, IEEE IMAGE PROC, P2734, DOI 10.1109/ICIP.2014.7025553
   Shalunts G., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P316
   Shalunts Gayane, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P280, DOI 10.1007/978-3-642-24031-7_28
   Shalunts G, 2015, LECT NOTES COMPUT SC, V9474, P285, DOI 10.1007/978-3-319-27857-5_26
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   SIKORA T, 1995, IEEE T CIRC SYST VID, V5, P59, DOI 10.1109/76.350781
   Simonyan K., 2014, 14091556 ARXIV
   Soares RD, 2012, PROC INT C TOOLS ART, P1070, DOI 10.1109/ICTAI.2012.151
   Su YY, 2014, PATTERN RECOGN, V47, P1826, DOI 10.1016/j.patcog.2013.11.028
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Q, 2013, IEEE T CIRC SYST VID, V23, P1150, DOI 10.1109/TCSVT.2012.2226528
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Xu Z, 2014, LECT NOTES COMPUT SC, V8689, P600, DOI 10.1007/978-3-319-10590-1_39
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 54
TC 10
Z9 10
U1 1
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 9553
EP 9576
DI 10.1007/s11042-018-6515-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400003
DA 2024-07-18
ER

PT J
AU Wu, ZJ
   Lin, JJ
   Liu, WJ
AF Wu, Zeju
   Lin, Jiajia
   Liu, Wenjing
TI Joint inspection in X-ray #0 belt tire based on periodic texture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Joint defects in #0 belt; Locating; Quantify; False positive rate; False
   negative rate
ID CLASSIFICATION
AB Based on X-ray image of tire with periodic texture, this paper proposes an algorithm of detecting joint in #0 belt. Firstly, by projecting #0 belt image at 45 degrees direction, we divide #0 belt image into several blocks with the same size based on periodic texture. Then, we find out the block containing joint and locate its upper and lower boundaries. Finally, upper and lower boundaries of joint are located by comparing the block containing joint with its corresponding standard block. The standard block is one of segmented blocks in first step. We quantify joint defects in #0 belt (large joint, small joint or appropriate joint), and experimental results show that our algorithm can accurately locate the joint and quantify the size of joint with 3.4% false positive rate and 2% false negative rate, which meets the industrial requirements.
C1 [Wu, Zeju; Liu, Wenjing] Qingdao Univ Technol, Dept Informat & Control Engn, Qingdao 266520, Shandong, Peoples R China.
   [Lin, Jiajia] Qingdao Univ Sci & Technol, Dept Automat & Elect Engn, Qingdao 266042, Shandong, Peoples R China.
C3 Qingdao University of Technology; Qingdao University of Science &
   Technology
RP Wu, ZJ (corresponding author), Qingdao Univ Technol, Dept Informat & Control Engn, Qingdao 266520, Shandong, Peoples R China.
EM alinequst@163.com
FU National Natural Science Foundation of China [61501278, 61602229];
   Natural Science Foundation of Shandong [ZR2016FM13, ZR2014FP003,
   ZR2014FQ012]; Project of Shandong Province Higher Educational Science
   and Technology Program [J14LN25]; Qingdao Municipal Applied Basic
   Research Project [15-9-1-111-jch]
FX We would like to thank anonymous reviewers for their helpful comments on
   the paper. This research was supported by National Natural Science
   Foundation of China (No. 61501278, 61602229), Natural Science Foundation
   of Shandong (ZR2016FM13, ZR2014FP003, ZR2014FQ012), Project of Shandong
   Province Higher Educational Science and Technology Program (No.
   J14LN25), and Qingdao Municipal Applied Basic Research Project (No.
   15-9-1-111-jch).
CR Aranda LA, 2017, IEEE T NUCL SCI, V64, P2219, DOI 10.1109/TNS.2017.2666843
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   de la Calle FJ, 2015, IEEE LAT AM T, V13, P1462, DOI 10.1109/TLA.2015.7112003
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Fan Deng-Ping, 2018, FACE SKETCH SYNTHESI
   Huang F, 2004, TIRE IND, V24, P559
   Ji Q, 2000, IEEE T MED IMAGING, V19, P1144, DOI 10.1109/42.896790
   Jiang Yong-lin, 2008, Optics and Precision Engineering, V16, P172
   [仕 LI Shi], 2008, [光学精密工程, Optics and Precision Engineering], V16, P2414
   [卢光明 LU Guangming], 2007, [计算机应用, Journal of Computer Applications], V27, P1490
   Luo X, 2008, COMPUTER APPL SOFTWA, V25, P241
   Lyu G, 2014, J COMPUT INF SYST, V10, P10683, DOI [10.12733/jcis12708, DOI 10.12733/JCIS12708]
   Mir A H, 1995, Biomed Sci Instrum, V31, P213
   Ngan HYT, 2010, IEEE T AUTOM SCI ENG, V7, P58, DOI 10.1109/TASE.2008.2005418
   Shang Y, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3032, DOI 10.1109/ICMLC.2008.4620927
   Wang F, 2006, TIRE IND, V26, P457, DOI [.3969/j.issn.1006-8171.2006.08.002, DOI 10.3969/J.ISSN.1006-8171.2006.08.002]
   Yang Jin-ji, 2013, Computer Engineering, V39, P214, DOI 10.3969/j.issn.1000-3428.2013.09.048
   Yang Xiao-min, 2009, Optics and Precision Engineering, V17, P2276
   [杨有 YANG You], 2008, [计算机科学, Computer Science], V35, P243
   Zhang XM, 2009, IEEE SIGNAL PROC LET, V16, P295, DOI 10.1109/LSP.2009.2014293
   Zhang Y L, 2014, THESIS
   Zhang Y, 2017, IEEE T AUTOM SCI ENG, V14, P1378, DOI 10.1109/TASE.2015.2469594
   Zhao Ying, 2008, Chinese Journal of Scientific Instrument, V29, P787
   Zheng X., 2016, THESIS
NR 24
TC 3
Z9 4
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 9299
EP 9310
DI 10.1007/s11042-018-6507-2
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800074
DA 2024-07-18
ER

PT J
AU Mansour, A
   Chenchah, F
   Lachiri, Z
AF Mansour, Asma
   Chenchah, Farah
   Lachiri, Zied
TI Emotional speaker recognition in real life conditions using multiple
   descriptors and i-vector speaker modeling technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; Emotion; I-vector; MFCC-SDC; SVM; Noise
AB Emotional speaker recognition under real life conditions becomes an urgent need for several applications. This paper proposes a novel approach using multiple feature extraction methods and i-vector modeling technique in order to improve emotional speaker recognition under real conditions. The performance of the proposed approach is evaluated on real condition speech signal (IEMOCAP corpus) under clean and noisy environments using various SNR levels. We examined divers known spectral features in speaker recognition (MFCC, LPCC and RASTA-PLP) and performed combined features called MFCC-SDC coefficients. The feature vectors are then classified using the multiclass Support Vector Machines (SVM). Experimental results illustrate good robustness of the proposed system against talking conditions (emotions) and against real life environment (noise). Besides, results reveal that MFCC-SDC features outperforms the conventional MFCCs.
C1 [Mansour, Asma; Chenchah, Farah; Lachiri, Zied] Univ Tunis El Manar, LR SITI Lab, Natl Sch Engn Tunis, BP 3, Tunis 1002, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Mansour, A (corresponding author), Univ Tunis El Manar, LR SITI Lab, Natl Sch Engn Tunis, BP 3, Tunis 1002, Tunisia.
EM asmamansour86@gmail.com; farahchenchah@yahoo.fr; lachiri.z@gmail.com
CR [Anonymous], 1998, STAT LEARNING THEORY
   Boulianne G, 2005, IEEE T SPEECH AUD P
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Devi J. Sirisha, 2014, INT J COMPUTER NETWO, V7, P61
   Dhonde SB, 2015, INT J RECENT TECHNOL, P2
   El Ayadi M, 2011, PATTERN RECOGN, V44, P572, DOI 10.1016/j.patcog.2010.09.020
   Hermansky H, 1992, IEEE INT C AC SPEECH, V1
   Hsu C., 2001, IEEE T NEURAL NETWOR, V13
   Kenny P, 2009, SUPPORT VECTOR MACHI
   Krishna NM, 2013, INT J ADV COMPUT SC, V4, P116
   Mackov L, 2015, BEST FEATURE SELECTI
   Mackov L, 2014, IEEE INT C
   Ouellet P, 2007, IEEE T
   Prithvi P, 2015, INT J SCI ENG RES IJ, P2347
   Quatieri TF, 2000, DIGITAL SIGNAL PROCE
   Richardson F, 2015, UNI ED DEEP NEURAL N
   Rusu Corneliu, 2011, P SPAMEC
   Sarmah K., 2014, International Journal of Computer Applications, V85, P36, DOI [10.5120/14840-3103, DOI 10.5120/14840-3103]
   Shahin Ismail, 2013, SPEAKER IDENTIFICATI
   Shahin Ismail, 2009, IRANIAN J ELECT COMP, V8
   Shashidhar G, 2012, S RAO EMOTION RECOGN
   Sreenivasa Rao K, 2012, COMMUNICATIONS COMPU
   TAO D, 2018, TIP, V27, P325, DOI DOI 10.1109/TIP.2017.2762588
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T IMAGE PROCESS, V25, P2726, DOI 10.1109/TIP.2016.2553446
   Van Leeuwen D, 2013, ACCENT RECOGNITION U
   Xia R, 2012, USING I VECTOR SPACE
   Xu M, 2007, P INTERSPEECH
   Yang Y, 2013, EMOTIONAL SPEAKER RE
   Yang YC, 2011, LECT NOTES COMPUT SC, V7098, P167, DOI 10.1007/978-3-642-25449-9_21
   Yeh JH, 2011, COMPUT HUM BEHAV, V27, P1545, DOI 10.1016/j.chb.2010.10.027
NR 33
TC 13
Z9 14
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 6441
EP 6458
DI 10.1007/s11042-018-6256-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700002
DA 2024-07-18
ER

PT J
AU Song, YJ
   Kim, JM
AF Song, You-Jin
   Kim, Jin-Monk
TI Characterization of privacy based on context sensitivity and user
   preference for multimedia context-aware on IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia-awareness, context-aware; Privacy protection; Context
   sensitivity; User preference; PIV (privacy invasion value); IoT
   (internet of things)
ID INTERNET; THINGS
AB In an IoT environment, building a Context-Aware system is mandatory and can provide a suitable and timely (just-in-time) service suited to the context of the user. In addition, the IoT environment is made on the assumption that maximum collection of the user's context is done. However, if the context of the user is collected beyond necessary, or when a context the user did not agree with was collected, a problem arises regarding a violation on the user's privacy. Asking for the user's approval on the collection of all context brings unnecessarily many steps and inconvenience to the users. Therefore, there is a need for user preferences to be dynamically controlled by the system. An IoT system must adjust its preferences so that it provides the maximum context to the service provider and minimizes the intrusion of the user's privacy. However, the current Context-Aware IoT does not consider these problems. Therefore, there is a need for a Dynamic Preference structure that protects the privacy of the user. This paper uses quantitative methods in formalizing the Privacy Invasion Value (PIV) of the users and discusses the methods in minimizing the PIV values through Dynamic Preference. The method used in this paper can solve privacy infringement issues in the Context-Aware IoT environment.
C1 [Song, You-Jin] Dongguk Univ, Dept Management, 123 Dongdae Ro, Gyeongju Si 38066, Gyeongsangbuk D, South Korea.
   [Kim, Jin-Monk] Sunmoon Univ, Div Informat Technol Educ, 70,Sunmoon Ro 221 Beon Gil, Asan 31460, Chungcheongnam, South Korea.
C3 Dongguk University; Sun Moon University
RP Kim, JM (corresponding author), Sunmoon Univ, Div Informat Technol Educ, 70,Sunmoon Ro 221 Beon Gil, Asan 31460, Chungcheongnam, South Korea.
EM song@dongguk.ac.kr; calf0425@sunmoon.ac.kr
FU National Research Foundation of Korea (NRF) - Ministry of Education
   [2016R1D1A1B03931689]; Dongguk University
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education (2016R1D1A1B03931689). This work was also
   supported by the Dongguk University Research Fund of 2017.
CR Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   [Anonymous], 2009, 802212008 IEEE
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Bandyopadhyay D, 2011, WIRELESS PERS COMMUN, V58, P49, DOI 10.1007/s11277-011-0288-5
   Coetzee L., 2011, 2011 1 AFRICA C P, P1
   Dey AK, 2001, HUM-COMPUT INTERACT, V16, P97, DOI 10.1207/S15327051HCI16234_02
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Miorandi D, 2012, AD HOC NETW, V10, P1497, DOI 10.1016/j.adhoc.2012.02.016
   Sarma AC, 2009, WIRELESS PERS COMMUN, V49, P353, DOI 10.1007/s11277-009-9697-0
NR 9
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5355
EP 5366
DI 10.1007/s11042-018-6103-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100016
DA 2024-07-18
ER

PT J
AU Kar, NB
   Babu, KS
   Sangaiah, AK
   Bakshi, S
AF Kar, Nikunja Bihari
   Babu, Korra Sathya
   Sangaiah, Arun Kumar
   Bakshi, Sambit
TI Face expression recognition system based on ripplet transform type II
   and least square SVM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face expression recognition; Linear discriminant analysis; Principal
   component analysis; Ripplet transform
ID SUPPORT VECTOR MACHINE; WAVELET TRANSFORM; ADABOOST; ENTROPY
AB This paper discusses the development of an efficient and automated system for the recognition of facial expressions, which is essentially an application augmented with many multimedia computing systems. The proposed scheme works in three stages. In the first stage, ripplet transform type II (ripplet-II) is employed to extract the features from facial images because of its efficiency in representing edges and textures. In the next stage, a principal component analysis (PCA)+linear discriminant analysis (LDA) approach is utilized to obtain a more compact and discriminative feature set. In the final stage, classification is performed using a least squares variant of support vector machine (LS-SVM) with radial basis function (RBF) kernel. The proposed system is validated on two benchmark datasets namely the Extended Cohn-Kanade (CK + ) and Japanese female facial expression (JAFFE). The experimental results demonstrate that the propose system yields superior performance as compared to other state-of-the-art schemes.
C1 [Kar, Nikunja Bihari; Babu, Korra Sathya; Bakshi, Sambit] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
   [Sangaiah, Arun Kumar] VIT Univ, Sch Engn & Comp Sci, Vellore 632014, Tamil Nadu, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela; Vellore Institute of Technology (VIT); VIT Vellore
RP Kar, NB (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela 769008, Odisha, India.
EM nikunjakar@gmail.com; ksathyababu@nitrkl.ac.in; sarunkumar@vit.ac.in;
   sambitbaksi@gmail.com
RI Korra, Sathya Babu/R-2218-2017; Sangaiah, Arun Kumar/U-6785-2019;
   Bakshi, Sambit/JDC-3355-2023; Korra, Sathya Babu/JBR-9336-2023
OI Korra, Sathya Babu/0000-0002-5963-5735; Sangaiah, Arun
   Kumar/0000-0002-0229-2460; Bakshi, Sambit/0000-0002-6107-114X; Kar,
   Nikunja/0000-0003-0409-2080
FU Fund for Improvement of S&T Infrastructure in Universities and Higher
   Educational Institutions (FIST) Program 2016, Department of Science and
   Technology, Government of India [ETI/359/2014]
FX This research is partially supported by the following project: Grant No.
   ETI/359/2014 by Fund for Improvement of S&T Infrastructure in
   Universities and Higher Educational Institutions (FIST) Program 2016,
   Department of Science and Technology, Government of India.
CR [Anonymous], TIP
   [Anonymous], 2003020 AI MIT
   [Anonymous], 2013, INT WORKSH AMB ASS L, DOI [DOI 10.1007/978-3-319-03092-0_17, DOI 10.1007/978-3-319-03092-0]
   [Anonymous], 2012, ARXIV12036722
   [Anonymous], 2014, INT WORKSH EL COMP E
   [Anonymous], 2017, P INT C COMPUTER VIS, DOI DOI 10.1007/978-981-10-2107-719
   [Anonymous], TKDE
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Ben-Hur A, 2002, J MACH LEARN RES, V2, P125, DOI 10.1162/15324430260185565
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Chen Jingying., 2012, IEEE COMP SOC C COMP, P29, DOI [DOI 10.1109/CVPRW.2012.6238905, 10.1111/j.1601-183X.2012.00843.x]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dahmane Mohamed, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P884, DOI 10.1109/FG.2011.5771368
   Deshmukh S, 2016, IET BIOMETRICS, V5, P155, DOI 10.1049/iet-bmt.2014.0104
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Elaiwat S, 2016, PATTERN RECOGN, V49, P152, DOI 10.1016/j.patcog.2015.07.006
   Gandhi T, 2008, IEEE INT VEH SYM, P795
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Guo M, 2017, MULTIMED TOOLS APPL, V76, P2995, DOI 10.1007/s11042-016-3282-9
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Hsieh CC, 2016, MULTIMED TOOLS APPL, V75, P6663, DOI 10.1007/s11042-015-2598-1
   Hung-Hsu Tsai, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P2697, DOI 10.1109/ICMLC.2010.5580938
   Jung H., 2015, ARXIV PREPRINT ARXIV
   Kazmi SB, 2012, SOFT COMPUT, V16, P369, DOI 10.1007/s00500-011-0721-4
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   Mlakar U, 2015, SIGNAL IMAGE VIDEO P, V9, P245, DOI 10.1007/s11760-015-0810-4
   Moraes D, 2016, J VIS COMMUN IMAGE R, V38, P340, DOI 10.1016/j.jvcir.2016.03.007
   Nayak DR, 2017, CNS NEUROL DISORD-DR, V16, P137, DOI 10.2174/1871527315666161024142036
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Qayyum H, 2017, MATH PROBL ENG, V2017, DOI 10.1155/2017/9854050
   Saeed A, 2014, ADV HUM-COMPUT INTER, V2014, DOI 10.1155/2014/408953
   Shi Dongcheng, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1970, DOI 10.1109/CISP.2010.5648166
   Sun YM, 2007, PATTERN RECOGN, V40, P3358, DOI 10.1016/j.patcog.2007.04.009
   Suwa M., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P408
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Theodoridis S., 1999, Pattern recognition, P3
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Uddin MZ, 2017, IEEE ACCESS, V5, P4525, DOI 10.1109/ACCESS.2017.2676238
   Uddin MZ, 2016, MULTIMED TOOLS APPL, V75, P6871, DOI 10.1007/s11042-015-2614-5
   Uddin MZ, 2016, INT CONF ADV COMMUN, P726, DOI 10.1109/ICACT.2016.7423536
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Wang XH, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P227, DOI 10.1109/SII.2013.6776664
   Xu J, 2012, IET IMAGE PROCESS, V6, P374, DOI 10.1049/iet-ipr.2010.0225
   Xu J, 2008, PROC SPIE, V6970, DOI 10.1117/12.777302
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhang YD, 2016, IEEE ACCESS, V4, P8375, DOI 10.1109/ACCESS.2016.2628407
NR 52
TC 27
Z9 27
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4789
EP 4812
DI 10.1007/s11042-017-5485-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200045
DA 2024-07-18
ER

PT J
AU Liu, F
   Chen, ZG
   Wang, J
AF Liu, Feng
   Chen, Zhigang
   Wang, Jie
TI Video image target monitoring based on RNN-LSTM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recurrent neural network; Long short-term memory; Deep learning network;
   Video image; Target monitoring; Algorithm design
ID MODEL
AB Traditional image object classification and detection algorithms and strategies cannot meet the problem of video image acquisition and processing. Deep learning deliberately simulates the hierarchical structure of human brain, and establishes the mapping from low-level signals to high-level semantics, so as to achieve hierarchical feature representation of data. Deep learning technology has powerful visual information processing ability, which has become the forefront technology and domestic and international research hotspots to deal with this challenge. In order to solve the problem of target space location in video surveillance system, time-consuming and other problems, in this paper, we propose the algorithm based on RNN-LSTM deep learning. At the same time, according to the principle of OpenGL perspective imaging and photogrammetry consistency, we use 3D scene simulation imaging technology, relying on the corresponding relationship between video images and simulation images we locate the target object. In the 3D virtual scene, we set up the virtual camera to simulate the imaging processing of the actual camera, and the pixel coordinates in the video image of the surveillance target are substituted into the simulation image, next, the spatial coordinates of the target are inverted by the inverse process of the virtual imaging. The experimental results show that the detection of target objects has high accuracy, which has an important reference value for outdoor target localization through video surveillance images.
C1 [Liu, Feng; Chen, Zhigang] Cent S Univ, Sch Software, Changsha 410075, Hunan, Peoples R China.
   [Liu, Feng] Univ Jinan, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Wang, Jie] Hengyang Normal Univ, Coll Comp Sci & Technol, Hengyang, Peoples R China.
C3 Central South University; University of Jinan; Hengyang Normal
   University
RP Chen, ZG (corresponding author), Cent S Univ, Sch Software, Changsha 410075, Hunan, Peoples R China.
EM chenzhigangcsu@yahoo.com
OI Liu, Feng/0000-0001-9435-2098
CR Al-Ayyoub M, 2015, CLUSTER COMPUT, V18, P919, DOI 10.1007/s10586-015-0449-5
   [Anonymous], 2016, Early Visual Concept Learning with Unsupervised Deep Learning
   [Anonymous], 2016, ARXIV160905143
   Arvind KS, 2017, CLUSTER COMPUT, V20, P1535, DOI 10.1007/s10586-017-0797-4
   Boru D, 2015, CLUSTER COMPUT, V18, P385, DOI 10.1007/s10586-014-0404-x
   Cheng Z, 2019, CLUSTER COMPUT, V22, pS8553, DOI 10.1007/s10586-018-1900-1
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Harris J., 2016, Proceedings of Society for Information Technology Teacher Education International Conference, P2864
   Hassan MF, 2018, SIGNAL IMAGE VIDEO P, V12, P1019, DOI 10.1007/s11760-018-1247-3
   Huang WZ, 2019, CLUSTER COMPUT, V22, P13077, DOI 10.1007/s10586-017-1205-9
   Islam S, 2018, SIGNAL IMAGE VIDEO P, V12, P853, DOI 10.1007/s11760-017-1228-y
   Karami H, 2019, NEURAL COMPUT APPL, V31, P5951, DOI 10.1007/s00521-018-3412-6
   Kim Y-K., 2012, ENGLISH LANGUAGE LIT, V18, P1
   Li P, 2018, CLUSTER COMPUT, V21, P277, DOI 10.1007/s10586-017-0849-9
   Liu HW, 2018, NEURAL COMPUT APPL, V29, P1, DOI 10.1007/s00521-017-3243-x
   Liyu Tang, 2011, Proceedings of the 2011 IEEE International Conference on Spatial Data Mining and Geographical Knowledge Services (ICSDM 2011), P308, DOI 10.1109/ICSDM.2011.5969053
   Ma WT, 2018, SIGNAL IMAGE VIDEO P, V12, P117, DOI 10.1007/s11760-017-1137-0
   Ma X, 2018, NEURAL COMPUT APPL, V29, P579, DOI 10.1007/s00521-016-2721-x
   Mamoshina P, 2016, MOL PHARMACEUT, V13, P1445, DOI 10.1021/acs.molpharmaceut.5b00982
   Mliki H, 2018, SIGNAL IMAGE VIDEO P, V12, P845, DOI 10.1007/s11760-017-1227-z
   Rho MJ, 2015, CLUSTER COMPUT, V18, P321, DOI 10.1007/s10586-014-0356-1
   Varatharajan R., 2018, Cluster Computing, V21, P681, DOI 10.1007/s10586-017-0977-2
   Yang XS, 2014, NEURAL COMPUT APPL, V24, P169, DOI 10.1007/s00521-013-1367-1
   Yang Z, 2019, NEURAL COMPUT APPL, V31, P6469, DOI 10.1007/s00521-018-3468-3
   Yücelbas C, 2018, NEURAL COMPUT APPL, V29, P17, DOI 10.1007/s00521-016-2445-y
   Zhang SW, 2018, SIGNAL IMAGE VIDEO P, V12, P1035, DOI 10.1007/s11760-018-1246-4
   Zhang SW, 2018, OPTIK, V157, P866, DOI 10.1016/j.ijleo.2017.11.190
   Zhang WJ, 2018, NEURAL COMPUT APPL, V29, P1143, DOI 10.1007/s00521-016-2483-5
NR 28
TC 13
Z9 14
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4527
EP 4544
DI 10.1007/s11042-018-6058-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200032
DA 2024-07-18
ER

PT J
AU Lombardo, G
   Fornacciari, P
   Mordonini, M
   Sani, L
   Tomaiuolo, M
AF Lombardo, Gianfranco
   Fornacciari, Paolo
   Mordonini, Monica
   Sani, Laura
   Tomaiuolo, Michele
TI A combined approach for the analysis of support groups on Facebook - the
   case of patients of hidradenitis suppurativa
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network analysis; Emotion detection; Sentiment analysis;
   Hidradenitis suppurativa; Facebook
ID SOCIAL MEDIA; CLASSIFICATION; EMOTION
AB Hidradenitis Suppurativa (HS), also known as Acne Inversa, is a chronic, underdiagnosed, often debilitating and painful disease that affects the folds of the skin. It has a considerable negative impact on the quality of life and on the emotional well-being. In this paper we discuss some results obtained by applying automatic Emotion Detection and Social Network Analysis techniques on the Facebook group of the Italian patients' association (Inversa Onlus). In particular, we analyze the patients' emotional states, as expressed by the posts and comments published from 2009 to 2017, and how these emotions are influenced by different social network factors, such as interactions and friendships in the group, during the observed years.
C1 [Lombardo, Gianfranco; Fornacciari, Paolo; Mordonini, Monica; Sani, Laura; Tomaiuolo, Michele] Univ Parma, Dipartimento Ingn & Architettura, Parma, Italy.
C3 University of Parma
RP Lombardo, G (corresponding author), Univ Parma, Dipartimento Ingn & Architettura, Parma, Italy.
EM gianfranco.lombardo@unipr.it
RI Lombardo, Gianfranco/AFR-0932-2022; Mordonini, Monica/Q-5792-2016;
   Tomaiuolo, Michele/H-8332-2012
OI lombardo, gianfranco/0000-0003-1808-4487; Sani,
   Laura/0000-0002-3288-5945; Tomaiuolo, Michele/0000-0002-6030-9435
CR Addis A., 2008, COMMUN SIWN, V5, P28
   Angiani G, 2017, ADV SOC NETW ONLINE, P196, DOI 10.4018/978-1-5225-1963-8.ch010
   Angiani G, 2016, LECT NOTES COMPUT SC, V10037, P51, DOI 10.1007/978-3-319-49130-1_5
   [Anonymous], 2001, EMOTIONS SOCIAL PSYC
   Bettoli V, 2016, J EUR ACAD DERMATOL, V30, P1965, DOI 10.1111/jdv.13687
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Dumais S., 2000, SIGIR Forum, V34, P256
   Franchi E, 2016, INT J INF SYST MODEL, V7, P18, DOI 10.4018/IJISMD.2016010102
   Ghazi D, 2010, LECT NOTES ARTIF INT, V6085, P40
   Greaves F, 2013, BMJ QUAL SAF, V22, P251, DOI 10.1136/bmjqs-2012-001527
   Greene JA, 2011, J GEN INTERN MED, V26, P287, DOI 10.1007/s11606-010-1526-3
   Huang XL, 2014, 2014 IEEE 11TH INTL CONF ON UBIQUITOUS INTELLIGENCE AND COMPUTING AND 2014 IEEE 11TH INTL CONF ON AUTONOMIC AND TRUSTED COMPUTING AND 2014 IEEE 14TH INTL CONF ON SCALABLE COMPUTING AND COMMUNICATIONS AND ITS ASSOCIATED WORKSHOPS, P844, DOI 10.1109/UIC-ATC-ScalCom.2014.48
   Kao ECC, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION MANAGEMENT AND ENGINEERING, PROCEEDINGS, P70, DOI 10.1109/ICIME.2009.113
   Liu Bing., 2012, Synthesis Lectures on Human Language Technologies, V5
   Lombardo G, 2018, DYNAMICS EMOTIONS RE, P269
   Maddali HT, 2015, ARXIV150205263
   Mohammad SM, 2016, EMOTION MEASUREMENT, P201, DOI 10.1016/B978-0-08-100508-8.00009-6
   Onderdijk AJ, 2013, J EUR ACAD DERMATOL, V27, P473, DOI 10.1111/j.1468-3083.2012.04468.x
   Roccetti M, 2017, JMIR PUBLIC HLTH SUR
   Sani L, 2018, LECT NOTES COMPUT SC, V10784, P125, DOI 10.1007/978-3-319-77538-8_10
   Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9
   Xinyu Wang, 2013, Trends and Applications in Knowledge Discovery and Data Mining. PAKDD 2013 International Workshops: DMApps, DANTH, QIMIE, BDM, CDA, CloudSD. Revised Selected Papers: LNCS 7867, P201, DOI 10.1007/978-3-642-40319-4_18
NR 22
TC 10
Z9 10
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3321
EP 3339
DI 10.1007/s11042-018-6512-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600037
DA 2024-07-18
ER

PT J
AU Park, S
   Kang, J
   Kim, J
   Lee, S
   Sohn, M
AF Park, Seyoung
   Kang, Jaewoong
   Kim, Jongmo
   Lee, Seongil
   Sohn, Mye
TI Unsupervised and non-parametric learning-based anomaly detection system
   using vibration sensor data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anomaly detection; Unsupervised and non-parametric machine learning;
   Pattern recognition; Non-stationary Markov chain; Vibration data
ID BEARING FAULT-DETECTION; CLASSIFICATION; DIAGNOSIS; FEATURES; MODEL
AB In this paper, we propose an anomaly detection system of machines using a hybrid learning mechanism that combines two kinds of machine learning approaches, namely unsupervised and non-parametric learning. To do so, we used vibration data, which is known to be suitable for anomaly detection in machines during operation. Furthermore, in order to take into account various characteristics of abnormal data such as scarcity and diversity, we propose a novel method that can detect anomalous behaviors using normal patterns instead of abnormal patterns from the machines. That is, we first perform a machine learning of the normal patterns of the machines during operation, and if any of the operation patterns deviates from the normal pattern, we identify that pattern as abnormal. A key characteristic of our system is that it does not use any prior information such as predefined data labels or data distributions to learn the normal operation patterns. To demonstrate the superiority of our system, we constructed a test bed consisting of a washing machine and a 3-axis accelerometer. We also demonstrated that our system can improve the accuracy of anomaly detection for the machines compared to other approaches.
C1 [Park, Seyoung; Kang, Jaewoong; Kim, Jongmo; Lee, Seongil; Sohn, Mye] Sungkyunkwan Univ, Dept Ind Engn, Suwon, South Korea.
C3 Sungkyunkwan University (SKKU)
RP Sohn, M (corresponding author), Sungkyunkwan Univ, Dept Ind Engn, Suwon, South Korea.
EM restatistical@skku.edu; kjw1727@skku.edu; dignity@skku.edu;
   silee@skku.edu; myesohn@skku.edu
OI Kang, Jaewoong/0000-0002-7194-5920; Sohn, Mye/0000-0002-1951-3493
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology [NRF-2016
   R1D1A1B03932110]; IT R&D program of KEIT [1005-0810]
FX This research was partially supported by Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science and Technology (NRF-2016 R1D1A1B03932110)
   and partially supported by the IT R&D program of KEIT (No. 1005-0810,
   Development of Disability Independent Accessibility Enhancement
   Technology for Input and Abnormality of Home Appliances).
CR Ahmad S, 2017, NEUROCOMPUTING, V262, P134, DOI 10.1016/j.neucom.2017.04.070
   [Anonymous], 2016 INT C COMP SCI
   [Anonymous], 2012 5 INT C INT COM
   [Anonymous], 2015 IE INT C SYST M
   [Anonymous], 2016 IE INT C SIGN I
   [Anonymous], 2015 IE INT C COMP I
   [Anonymous], 2016, INT J CONDITION MONI, DOI DOI 10.1784/204764216819708104
   [Anonymous], 2016, REMOTE SENSING AIR S
   [Anonymous], 2017 IE 18 INT S HIG
   Prieto MD, 2013, IEEE T IND ELECTRON, V60, P3398, DOI 10.1109/TIE.2012.2219838
   Goldstein M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0152173
   Lee SK, 1998, J SOUND VIB, V217, P485, DOI 10.1006/jsvi.1998.1767
   Li C, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060895
   Li LS, 2016, TRANSPORT RES C-EMER, V64, P45, DOI 10.1016/j.trc.2016.01.007
   Li WL, 2014, IEEE T INSTRUM MEAS, V63, P2651, DOI 10.1109/TIM.2014.2313035
   Liu J, 2013, ANN NUCL ENERGY, V56, P23, DOI 10.1016/j.anucene.2013.01.005
   Liu Q, 2017, REMOTE SENS ENVIRON, V202, P75, DOI 10.1016/j.rse.2017.01.034
   Martí L, 2015, SENSORS-BASEL, V15, P2774, DOI 10.3390/s150202774
   Nandi A K., 2013, Proceedings of the International Conference Surveillance 7, P1
   Peerbhay KY, 2015, IEEE J-STARS, V8, P3107, DOI 10.1109/JSTARS.2015.2396577
   Rassam MA, 2014, KNOWL-BASED SYST, V60, P44, DOI 10.1016/j.knosys.2014.01.003
   Ross T. J., 2010, Fuzzy logic with engineering applications, V3rd, DOI [DOI 10.1002/9781119994374, 10.1002/9781119994374]
   Shen CQ, 2013, MEASUREMENT, V46, P1551, DOI 10.1016/j.measurement.2012.12.011
   Song J, 2013, INFORM SCIENCES, V231, P4, DOI 10.1016/j.ins.2011.08.011
   Sun C, 2011, J PHYS CONF SER, V305, DOI 10.1088/1742-6596/305/1/012028
   Tong LN, 2013, IEEE SENS J, V13, P1849, DOI 10.1109/JSEN.2013.2245231
   Wang G, 2014, J FRANKLIN I, V351, P3231, DOI 10.1016/j.jfranklin.2014.03.004
   Widodo A, 2011, EXPERT SYST APPL, V38, P8430, DOI 10.1016/j.eswa.2011.01.038
   Wijayasekara D, 2014, IEEE T IND INFORM, V10, P1829, DOI 10.1109/TII.2014.2328291
   Zarei J, 2014, MECHATRONICS, V24, P151, DOI 10.1016/j.mechatronics.2014.01.003
   Zhang F, 2014, J MECH SCI TECHNOL, V28, P4441, DOI 10.1007/s12206-014-1012-7
   Zhang LW, 2018, KNOWL-BASED SYST, V139, P50, DOI 10.1016/j.knosys.2017.10.009
   Zhou YH, 2014, APPL INTELL, V40, P613, DOI 10.1007/s10489-013-0492-y
   Zimroz R, 2014, MECH SYST SIGNAL PR, V46, P16, DOI 10.1016/j.ymssp.2013.09.010
NR 34
TC 4
Z9 6
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4417
EP 4435
DI 10.1007/s11042-018-5845-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200027
DA 2024-07-18
ER

PT J
AU Radhakrishna, V
   Aljawarneh, SA
   Kumar, PV
   Janaki, V
AF Radhakrishna, Vangipuram
   Aljawarneh, Shadi A.
   Kumar, Puligadda Veereswara
   Janaki, Vinjamuri
TI ASTRA - A Novel interest measure for unearthing latent temporal
   associations and trends through extending basic gaussian membership
   function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Temporal association pattern; Prevalence time sequence; Dissimilarity;
   Time profiled; Transaction database; Temporal databases
ID SEQUENTIAL PATTERNS; SIMILARITY MEASURE; FREQUENT PATTERNS; PERIODIC
   PATTERNS; LARGE DATABASES; DISCOVERY; RULES; ALGORITHM; SYSTEM
AB Time profiled association mining is one of the important and challenging research problems that is relatively less addressed. Time profiled association mining has two main challenges that must be addressed. These include addressing i) dissimilarity measure that also holds monotonicity property and can efficiently prune itemset associations ii) approaches for estimating prevalence values of itemset associations over time. The pioneering research that addressed time profiled association mining is by J.S. Yoo using Euclidean distance. It is widely known fact that this distance measure suffers from high dimensionality. Given a time stamped transaction database, time profiled association mining refers to the discovery of underlying and hidden time profiled itemset associations whose true prevalence variations are similar as the user query sequence under subset constraints that include i) allowable dissimilarity value ii) a reference query time sequence iii) dissimilarity function that can find degree of similarity between a temporal itemset and reference. In this paper, we propose a novel dissimilarity measure whose design is a function of product based gaussian membership function through extending the similarity function proposed in our earlier research (G-Spamine). Our approach, MASTER (Mining of Similar Temporal Associations) which is primarily inspired from SPAMINE uses the dissimilarity measure proposed in this paper and support bound estimation approach proposed in our earlier research. Expression for computation of distance bounds of temporal patterns are designed considering the proposed measure and support estimation approach. Experiments are performed by considering naive, sequential, Spamine and G-Spamine approaches under various test case considerations that study the scalability and computational performance of the proposed approach. Experimental results prove the scalability and efficiency of the proposed approach. The correctness and completeness of proposed approach is also proved analytically.
C1 [Radhakrishna, Vangipuram] VNR Vignana Jyothi Inst Engn & Technol Autonomous, Dept Informat Technol, Hyderabad 500090, Telangana, India.
   [Aljawarneh, Shadi A.] Jordan Univ Sci & Technol, Dept Software Engn, Irbid, Jordan.
   [Kumar, Puligadda Veereswara] Acharya Inst Technol, Dept Comp Sci & Engn, Bangalore, Karnataka, India.
   [Kumar, Puligadda Veereswara] Osmania Univ, Univ Coll Engn, Hyderabad, Telangana, India.
   [Janaki, Vinjamuri] Vaagdevi Coll Engn Autonomous, Dept Comp Sci & Engn, Warangal, Andhra Pradesh, India.
C3 Vallurupalli Nageswara Rao Vignana Jyothi Institute of Engineering
   &Technology (VNR VJIET); Jordan University of Science & Technology;
   Osmania University
RP Radhakrishna, V (corresponding author), VNR Vignana Jyothi Inst Engn & Technol Autonomous, Dept Informat Technol, Hyderabad 500090, Telangana, India.
EM vrkrishna@acm.org; saaljawarneh@just.edu.jo; pvkumar58@gmail.com;
   janakicse@yahoo.com
RI Aljawarneh, Shadi/ABD-6329-2021; Radhakrishna, Vangipuram/N-2997-2019
OI Aljawarneh, Shadi/0000-0001-5748-4921; Radhakrishna,
   Vangipuram/0000-0002-7373-6276; Janaki, Vinjamuri/0000-0002-1455-6611
CR Agrawal R., 1993, SIGMOD Record, V22, P207, DOI 10.1145/170036.170072
   AGRAWAL R, 1993, IEEE T KNOWL DATA EN, V5, P914, DOI 10.1109/69.250074
   AGRAWAL R, 1995, PROC INT CONF DATA, P3, DOI 10.1109/ICDE.1995.380415
   Agrawal R, 1996, IEEE T KNOWL DATA EN, P487
   Agrawal R., P 20 INT C VERY LARG
   Ale J., 2000, P 2000 ACM S APPL CO, P294
   Aljawarneh S., 2016, 2016 International conference on engineering MIS (ICEMIS), P1, DOI DOI 10.1109/ICEMIS.2016.7745355
   Aljawarneh S, 2018, J COMPUT SCI-NETH, V25, P152, DOI 10.1016/j.jocs.2017.03.006
   Aljawarneh SA, 2017, COMPUT ELECTR ENG, V61, P275, DOI 10.1016/j.compeleceng.2016.12.003
   Aljawarneh SA, 2017, FUTURE GENER COMP SY, V74, P430, DOI 10.1016/j.future.2017.01.013
   Aljawarneh SA, 2016, FUTURE GENER COMP SY, V60, P67, DOI 10.1016/j.future.2016.01.020
   Bettini C., 1996, Proceedings of the Fifteenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1996, P68, DOI 10.1145/237661.237680
   Bettini C, 1998, IEEE T KNOWL DATA EN, V10, P222, DOI 10.1109/69.683754
   Bettini C., 1998, B TECH COMMITTEE DAT, V21, P32
   Borgelt Christian., 2005, Proceedings of the 1st International Workshop on Open Source Data Mining: Frequent Pattern Mining Implementations, P66
   Calders T, 2003, THEOR COMPUT SCI, V290, P669, DOI 10.1016/S0304-3975(02)00081-6
   Chanda AK, 2017, EXPERT SYST APPL, V79, P207, DOI 10.1016/j.eswa.2017.02.028
   Chang-Hung Lee, 2001, Proceedings of the 2001 ACM CIKM. Tenth International Conference on Information and Knowledge Management, P263
   Chen CH, 2016, APPL SOFT COMPUT, V41, P265, DOI 10.1016/j.asoc.2016.01.008
   CHEN X, 2000, P 2000 INT C DAT ENG
   Chen YC, 2015, IEEE T KNOWL DATA EN, V27, P3318, DOI 10.1109/TKDE.2015.2454515
   Cheng Yang, 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P194, DOI 10.1145/502512.502539
   Cherrafi A, 2017, INT J PROD RES, V55, P4481, DOI 10.1080/00207543.2016.1266406
   Cheung DW, 1996, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1996.492094
   Cohen E, 2001, IEEE T KNOWL DATA EN, V13, P64, DOI 10.1109/69.908981
   Dong G., 1999, P 5 ACM SIGKDD INT C, P43, DOI [10.1145/312129., DOI 10.1145/312129, DOI 10.1145/312129.312191]
   Gharib TF, 2010, DATA KNOWL ENG, V69, P800, DOI 10.1016/j.datak.2010.03.002
   Grahne G, 2005, IEEE T KNOWL DATA EN, V17, P1347, DOI 10.1109/TKDE.2005.166
   Guil F, 2013, EXPERT SYST APPL, V40, P1296, DOI 10.1016/j.eswa.2012.08.061
   Guil F, 2012, KNOWL-BASED SYST, V35, P186, DOI 10.1016/j.knosys.2012.04.027
   Han JW, 1999, PROC INT CONF DATA, P106, DOI 10.1109/ICDE.1999.754913
   Han JW, 2004, DATA MIN KNOWL DISC, V8, P53, DOI 10.1023/B:DAMI.0000005258.31418.83
   Imran A, J UNIVER COMPUT SCI, V22, P494
   Jiang JY, 2011, IEEE T KNOWL DATA EN, V23, P335, DOI 10.1109/TKDE.2010.122
   Jiawei Han, 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P420
   Jong Soo Park, 1997, Proceedings of the Sixth International Conference on Information and Knowledge Management. CIKM'97, P151, DOI 10.1145/266714.266886
   Kumar GR., 2015, P THE INT C ENG MIS, P69, DOI DOI 10.1145/2832987.2833082
   Kumar GR, 2017, FUTURE GENER COMP SY, V74, P417, DOI 10.1016/j.future.2016.12.040
   Kumar GR, 2016, J UNIVERS COMPUT SCI, V22, P589
   Kumar R, 2016, INT CONF IND INF SYS, P1, DOI 10.1109/ICIINFS.2016.8262896
   Last M, 2001, IEEE T SYST MAN CY B, V31, P160, DOI 10.1109/3477.907576
   LEE C, 2003, TKDE, V15, P1004, DOI DOI 10.1109/TKDE.2003.1209015
   Lee WJ, 2004, IEEE SYS MAN CYBERN, P3122, DOI 10.1109/ICSMC.2004.1400819
   Lee WJ, 2004, IEEE T SYST MAN CY B, V34, P2330, DOI 10.1109/TSMCB.2004.835352
   Lee YJ, 2009, J SYST SOFTWARE, V82, P155, DOI 10.1016/j.jss.2008.07.037
   Li YJ, 2003, DATA KNOWL ENG, V44, P193, DOI 10.1016/S0169-023X(02)00135-0
   Li YJ, 2001, EIGHTH INTERNATIONAL SYMPOSIUM ON TEMPORAL REPRESENTATION AND REASONING, PROCEEDINGS, P111, DOI 10.1109/TIME.2001.930706
   Lin MY, 2008, INFORM SCIENCES, V178, P4228, DOI 10.1016/j.ins.2008.07.012
   Lin MY, 2002, LECT NOTES COMPUTER, V2454, DOI [10. 1007/3-540-46145-0_15, DOI 10.1007/3-540-46145-0_15]
   LIN YS, 2014, TKDE, V26, P1575, DOI DOI 10.1109/TKDE.2013.19
   Lind DA, 2004, STAT TECHNIQUES BU E
   Liu B, 1999, P INT C KNOWL DISC D
   MANNILA H, 1995, DISCOVERING FREQUENT, P210
   Ozden B, 1998, PROC INT CONF DATA, P412, DOI 10.1109/ICDE.1998.655804
   Pasquier N, 1999, LECT NOTES COMPUT SC, V1540, P398
   Pei J, 2001, PROC INT CONF DATA, P215
   R. Srikant, 1996, LECT NOTES COMPUTER, V1057
   Radhakrishna V, 2016, 2016 INT C ENG MIS I, P1
   Radhakrishna V., 2015, P INT C ENG MIS 2015, DOI 10.1145/2832987.2833071
   Radhakrishna V, 2016, 2016 INT C ENG MIS I, P1, DOI DOI 10.1109/ICEMIS.2016.7745347
   Radhakrishna V., 2016, P 22 INT C SOFT COMP, V576, DOI [10.1007/978-3-319-58088-3_19, DOI 10.1007/978-3-319-58088-3_19]
   Radhakrishna V., 2016, P 22 INT C SOFT COMP, V576, DOI [10.1007/978-3-319-58088-3_20, DOI 10.1007/978-3-319-58088-3_20]
   Radhakrishna V., 2015, Proceedings of the The International Conference on Engineering MIS 2015, P1, DOI DOI 10.1145/2832987.2833064
   Radhakrishna V, 2018, MULTIMED TOOLS APPL, V77, P17643, DOI 10.1007/s11042-017-5185-9
   Radhakrishna V, 2018, SOFT COMPUT, V22, P1903, DOI 10.1007/s00500-016-2445-y
   Radhakrishna V, 2018, FUTURE GENER COMP SY, V83, P582, DOI 10.1016/j.future.2017.03.016
   Radhakrishna V, 2016, SMART INNOV SYST TEC, V51, P607, DOI 10.1007/978-3-319-30927-9_60
   Radhakrishna V, 2016, J UNIVERS COMPUT SCI, V22, P475
   Ramaswamy S., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P368
   Sohrabi MK, 2012, KNOWL-BASED SYST, V33, P41, DOI 10.1016/j.knosys.2012.03.003
   Srikant R., 1995, VLDB '95. Proceedings of the 21st International Conference on Very Large Data Bases, P407
   Srikant R., 1996, Mining sequential patterns: Generalizations and performance improvements, V25, P1, DOI [10.1007/BFb0014140, DOI 10.1145/235968.233311]
   Tansel UA, 2007, INF TECHN 2007 ITNG, P371, DOI [10. 1109/ITNG. 2007. 78, DOI 10.1109/ITNG.2007.78]
   TUNG AKH, 2001, P 2001 INT C DAT THE
   Vangipuram R, IADIS INT J COMPUTER, V142, P126
   Vangipuram R, IADIINT J COMPUTER, V12, P45
   Vangipuram R, DATABASE SYSTEMS J, V7, P22
   Villafane R., 1999, Data Warehousing and Knowledge Discovery. First International Conference, DaWaK'99. Proceedings (Lecture Notes in Computer Science Vol.1676), P318
   Winarko E, 2007, DATA KNOWL ENG, V63, P76, DOI 10.1016/j.datak.2006.10.009
   Yoo JS, 2012, INTEL SYST REF LIBR, V23, P29
   Yoo JS, 2008, P 20 INT C SCI STAT, V17, P401, DOI [10. 1007/978-3-540-69497-7_26, DOI 10.1007/978-3-540-69497-7_26]
   Yoo JS, 2005, LECT NOTES COMPUTER
   YOO JS, 2009, TKDE, V21, P1147, DOI DOI 10.1109/TKDE.2008.185
   Zaki M., 2003, P 9 ACM SIGKDD INT C, P326, DOI [10.1145/956750.956788, DOI 10.1145/956750.956788]
   Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291
   Zhu FD, 2007, PROC INT CONF DATA, P681
   Zhuang DEH, 2014, IEEE T KNOWL DATA EN, V26, P2969, DOI 10.1109/TKDE.2014.2310219
NR 87
TC 31
Z9 32
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4217
EP 4265
DI 10.1007/s11042-017-5280-y
PG 49
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200018
DA 2024-07-18
ER

PT J
AU Chakraborty, D
   Tarafder, MK
   Banerjee, A
   Chaudhuri, SRB
AF Chakraborty, D.
   Tarafder, M. K.
   Banerjee, A.
   Chaudhuri, S. R. Bhadra
TI Gabor-based spectral domain automated notch-reject filter for
   quasi-periodic noise reduction from digital images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periodic; quasi-periodic noise; Multiple populations; Gabor transform;
   Exponential thresholding; Noisy bitmap; Automated notch-reject filter
ID FREQUENCY; REMOVAL; SENSOR; SPACE
AB Well-organized restoration techniques for attenuating the impact of periodic/quasi-periodic noise structures from digital images is one of the significant research fields in modern days. These are encountered in various imagery applications like remote-sensing (satellite, aerial), the digitization of canvas paintings, etc. In this paper, a novel spectral domain algorithm for periodic/quasi-periodic de-noising has been presented where an Automated Notch-Reject Filter (ANRF) is lucratively used to remove unwanted periodic patterns from Gabor-transformed corrupted images. As an initial stage, the Low-Frequency Region (LFR) has been conserved ingeniously by finding squared spectral difference after representing the image spectrum as multiple populations. Thereafter, the contrast of any corrupted image spectrum has been increased using Gabor transform for making the noisy components more prominent. Then, an adaptive exponential thresholding procedure has been applied efficiently for detecting those noisy components. The final stage of our proposed algorithm is to filter out those noisy components properly where a novel adaptive notch-reject filter has been applied along with an automated control of filtering profile in proportion to different noise spectrum profile. The supremacy of our algorithm over other state-of-the-art algorithms has been productively established with the help of experimental results in terms of visual and statistical metrics.
C1 [Chakraborty, D.; Tarafder, M. K.; Banerjee, A.; Chaudhuri, S. R. Bhadra] IIEST, ETC, Howrah, India.
C3 Indian Institute of Engineering Science Technology Shibpur (IIEST)
RP Chakraborty, D (corresponding author), IIEST, ETC, Howrah, India.
EM debolina.chk@gmail.com; ayan@telecom.becs.ac.in; prof.srbc@ieee.org
CR Aizenberg I, 2002, P SOC PHOTO-OPT INS, V4667, P181, DOI 10.1117/12.467980
   Aizenberg I, 2008, IMAGE VISION COMPUT, V26, P1347, DOI 10.1016/j.imavis.2007.08.011
   Al Hudhud GA, 2005, IEEE SIGNAL PROC LET, V12, P573, DOI 10.1109/LSP.2005.851257
   Al-Najjar YAY., 2012, Int J Sci Eng Res, V3, P1
   [Anonymous], AEU INT J ELECT COMM
   [Anonymous], 2002, INT TICSP WORKSH SPE
   [Anonymous], INF COMM SIGN PROC I
   [Anonymous], ADV SIGNAL PROCESSIN
   [Anonymous], 2006, Remote Sensing: Models and Methods for Image Processing
   [Anonymous], 2012, DIGITAL TRANSMISSION
   [Anonymous], INTRO INFRARED ELECT
   [Anonymous], INT J SCI ENG TECHNO
   [Anonymous], INT J EMERG TECHNOL
   [Anonymous], INT C BIOINF BIOM EN
   [Anonymous], INT ARCH PHOTOGRAMM
   Castelli V., 2002, Image Databases: Search and Retrieval of Digital Imagery
   Chang Y, 2015, IEEE T IMAGE PROCESS, V24, P1852, DOI 10.1109/TIP.2015.2404782
   Chu Y, 2006, TENCON IEEE REGION, P16
   Cornelis B, 2012, SIGNAL PROCESS, V92, P1166, DOI 10.1016/j.sigpro.2011.11.012
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Fehrenbach J, 2012, IEEE T IMAGE PROCESS, V21, P4420, DOI 10.1109/TIP.2012.2206037
   Feuerstein D, 2009, ANAL CHEM, V81, P4987, DOI 10.1021/ac900161x
   GUTTMAN N, 1963, J ACOUST SOC AM, V35, P610, DOI 10.1121/1.1918551
   Ji TY, 2007, SIGNAL PROCESS, V87, P2799, DOI 10.1016/j.sigpro.2007.05.024
   Kelcey J, 2012, REMOTE SENS-BASEL, V4, P1462, DOI 10.3390/rs4051462
   Ketenci S, 2012, INT S INN INT SYST A, P1, DOI DOI 10.1109/INISTA.2012.6246937
   Konstantinidis AC, 2010, NUCL INSTRUM METH A, V620, P549, DOI 10.1016/j.nima.2010.03.138
   Koukou V, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/574238
   Marques Oge., 2011, Practical image and video processing using MATLAB
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Moallem P, 2015, SIGNAL IMAGE VIDEO P, V9, P1179, DOI 10.1007/s11760-013-0560-0
   Moallemi P., 2010, AUT J ELECT ENG, V42, P1, DOI [10.22060/EEJ.2010.94, DOI 10.22060/EEJ.2010.94]
   RINDFLEISCH TC, 1971, J GEOPHYS RES, V76, P394, DOI 10.1029/JB076i002p00394
   Song ML, 2013, NEUROCOMPUTING, V119, P222, DOI 10.1016/j.neucom.2013.03.037
   Sur F, 2015, IEEE IMAGE PROC, P3841, DOI 10.1109/ICIP.2015.7351524
   Sur F, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013003
   Varghese J, 2016, IET IMAGE PROCESS, V10, P646, DOI 10.1049/iet-ipr.2015.0750
   Varghese J, 2016, CAN J ELECT COMPUT E, V39, P82, DOI 10.1109/CJECE.2015.2490598
   Wang YT, 2017, IEEE T CIRC SYST VID, V27, P1895, DOI 10.1109/TCSVT.2016.2555740
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
NR 42
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1757
EP 1783
DI 10.1007/s11042-018-6194-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700024
DA 2024-07-18
ER

PT J
AU Li, Z
   Wang, ZJ
   Liu, C
   Jiang, ZY
AF Li, Zhe
   Wang, Zongjun
   Liu, Cong
   Jiang, Zhenyu
TI The knowledge flow analysis on multimedia information using evolutionary
   game model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge flow; Multimedia information; Complementarity; Similarity;
   Evolutionary game
ID RESEARCH-AND-DEVELOPMENT; DEVELOPMENT ALLIANCES; STRATEGIC ALLIANCES;
   IMPACT; PERFORMANCE; INNOVATION; SPILLOVERS; SIMILARITY;
   COMPLEMENTARITIES; CAPABILITY
AB Knowledge flow of multimedia information can trigger the formation of alliances and clusters. Our study focuses on the conditions when alliances or clusters emerge subsequent to the perception of knowledge flow. Based on several fundamental assumptions, we build an evolutionary game model for quantitative calculation and further conclude several propositions via geometrical analysis. The findings show that when originators participate in games without perception to the outflowing of knowledge via multimedia, the similarity, complementarity and spillage of knowledge all facilitate alliances formation after spillovers, and when originators participate in games with perception to the outflowing information, alliance formation is still positively related to the similarity and complementarity of knowledge, while the effect of spillage depends on initial conditions. This study not only analyzes the multimedia information from knowledge spillover perspective, but also introduces the evolutionary game model into the exploration of multimedia information flow, thus it provides novel guidance for the further research.
C1 [Li, Zhe; Wang, Zongjun; Liu, Cong; Jiang, Zhenyu] Huazhong Univ Sci & Technol, Sch Management, Wuhan, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology
RP Jiang, ZY (corresponding author), Huazhong Univ Sci & Technol, Sch Management, Wuhan, Hubei, Peoples R China.
EM jzyazy@hust.edu.cn
FU 'Fundamental Research Funds for the Central Universities', HUST
   [2015AB021]
FX We would like to thank the editor and three anonymous reviewers for
   their insightful comments on this paper.The authors are very indebted to
   Prof. Cao and Dr. Yang for their valuable comments on the earlier draft
   of this paper. In addition, this research is supported by 'the
   Fundamental Research Funds for the Central Universities', HUST: No.
   2015AB021. The authors wish to thank related funding agencies.
CR Adner R, 2006, STRATEGIC MANAGE J, V27, P215, DOI 10.1002/smj.513
   Alnuaimi T, 2016, STRATEGIC MANAGE J, V37, P1263, DOI 10.1002/smj.2383
   Anbarci N, 2002, INT J IND ORGAN, V20, P191, DOI 10.1016/S0167-7187(00)00081-3
   Artz KW, 2000, J ECON BEHAV ORGAN, V41, P337, DOI 10.1016/S0167-2681(99)00080-3
   Badir YF, 2015, J PROD INNOVAT MANAG, V32, P154, DOI 10.1111/jpim.12222
   Bai CG, 2016, ANN OPER RES, V240, P583, DOI 10.1007/s10479-014-1737-9
   Basile R, 2012, PAP REG SCI, V91, P697, DOI 10.1111/j.1435-5957.2012.00438.x
   Blazsek S, 2010, J ECONOMETRICS, V159, P14, DOI 10.1016/j.jeconom.2010.04.004
   Cantwell J., 2000, J. Manag. Govern., V4, P117
   Chen YD, 2017, KYBERNETES, V46, P450, DOI 10.1108/K-03-2016-0034
   Chiambaretto P, 2018, RESOURCE UTILIZATION
   Ding XH, 2010, EUR J OPER RES, V201, P949, DOI 10.1016/j.ejor.2009.04.008
   Donate MJ, 2017, ADV BUS INFORM SYST, P128, DOI 10.4018/978-1-5225-1680-4.ch006
   Fang E, 2011, ORGAN SCI, V22, P158, DOI 10.1287/orsc.1090.0512
   Farrell J, 2001, ANTITRUST LAW J, V68, P685
   Florian N, 2013, J BUS RES, V66, P2000
   García AB, 2014, KNOWL MAN RES PRACT, V12, P246, DOI 10.1057/kmrp.2014.2
   Gattai V, 2007, REV WORLD ECON, V143, P1, DOI 10.1007/s10290-007-0096-x
   Cai G, 2009, INT J PROD ECON, V117, P80, DOI 10.1016/j.ijpe.2008.08.053
   GROSSMAN GM, 1991, EUR ECON REV, V35, P517, DOI 10.1016/0014-2921(91)90153-A
   Hammadou H, 2014, RES POLICY, V43, P1217, DOI 10.1016/j.respol.2014.01.011
   Hilbe C, 2011, B MATH BIOL, V73, P2068, DOI 10.1007/s11538-010-9608-2
   Hofbauer J., 1998, EVOLUTIONARY GAMES P
   Hu S, 2015, PHYSICA A, V430, P46, DOI 10.1016/j.physa.2015.02.094
   Huang CC, 2016, PHYSICA A, V458, P399, DOI 10.1016/j.physa.2016.03.066
   JAFFE AB, 1993, Q J ECON, V108, P577, DOI 10.2307/2118401
   Jaffe AB, 2001, RAND J ECON, V32, P167, DOI 10.2307/2696403
   JONES CI, 1995, J POLIT ECON, V103, P759, DOI 10.1086/262002
   Khamseh HM, 2017, IND MARKET MANAG, V63, P92, DOI 10.1016/j.indmarman.2016.12.004
   Luo XW, 2009, J MANAGE STUD, V46, P1005, DOI 10.1111/j.1467-6486.2009.00842.x
   Macro C, 2012, STRATEG MANAG J, V34, P404
   Malik TH, 2013, INT BUS REV, V22, P699, DOI 10.1016/j.ibusrev.2012.11.001
   Manley K, 2016, ENG CONSTR ARCHIT MA, V23, P511, DOI 10.1108/ECAM-06-2015-0084
   Manzini R, 2016, R&D MANAGE, V46, P579, DOI 10.1111/radm.12126
   Mindruta D, 2016, STRATEGIC MANAGE J, V37, P206, DOI 10.1002/smj.2448
   Myerson RB, 2013, GAME THEORY, P26
   Nakamura H, 2015, TECHNOL FORECAST SOC, V94, P187, DOI 10.1016/j.techfore.2014.09.009
   O'Dwyer M, 2018, J BUS RES, V87, P58, DOI 10.1016/j.jbusres.2018.02.020
   Phene A, 2014, J MANAGE STUD, V51, P1058, DOI 10.1111/joms.12088
   Piccinelli C, 2015, EPIDEMIOL PREV, V39, P202
   Reuer JJ, 2014, ORGAN SCI, V25, P283, DOI 10.1287/orsc.1120.0805
   ROMER PM, 1990, J POLIT ECON, V98, pS71, DOI 10.1086/261725
   Ryoo SY, 2015, EXPERT SYST APPL, V42, P3029, DOI 10.1016/j.eswa.2014.11.055
   Sampson RC, 2007, ACAD MANAGE J, V50, P364, DOI 10.5465/AMJ.2007.24634443
   Serrat O., 2017, Knowledge Solutions, P639, DOI DOI 10.1007/978-981-10-0983-9_71
   Shin K, 2016, ASIA PAC J MANAG, V33, P141, DOI 10.1007/s10490-015-9439-7
   Simth JM, 1982, EVOLUTION THEORY GAM, P21
   SMITH JM, 1973, NATURE, V246, P15, DOI 10.1038/246015a0
   Subramanian AM, 2017, LONG RANGE PLANN, V50, P636, DOI 10.1016/j.lrp.2016.11.001
   Szabó G, 2007, PHYS REP, V446, P97, DOI 10.1016/j.physrep.2007.04.004
   Tallman S, 2004, ACAD MANAGE REV, V29, P258, DOI 10.2307/20159032
   Tezuka S, 2004, INT J TECHNOL MANAGE, V28, P714, DOI 10.1504/IJTM.2004.005779
   Thavikulwat P, 2013, SIMULAT GAMING, V44, P706, DOI 10.1177/1046878113503419
   Thomas M, 2014, J BUSINESS EC, V81, P71
   Toole AA, 2015, ECON INNOV NEW TECH, V24, P532, DOI 10.1080/10438599.2014.988519
   Walsh JP, 2016, RES POLICY, V45, P172, DOI 10.1016/j.respol.2016.04.013
   Yang CX, 2012, PHYSICA A, V391, P3513, DOI 10.1016/j.physa.2012.02.003
   Ye J, 2018, FUTURE GENER COMP SY, V81, P433, DOI 10.1016/j.future.2017.09.030
   Young HP, 2007, GAME 5 QUESTIONS, P69
   Yu CY, 2016, SCI REP-UK, V6, DOI 10.1038/srep26264
   Zaheer A, 2011, GLOB STRATEG J, V1, P109, DOI 10.1002/gsj.6
   Zahra SA, 2002, ACAD MANAGE REV, V27, P185, DOI 10.2307/4134351
   Zhang SX, 2015, COMPUT SYST SCI ENG, V30, P377
   Zhao JY, 2018, EXPERT SYST APPL, V98, P242, DOI 10.1016/j.eswa.2017.11.012
   Zollo M, 2004, STRATEGIC MANAGE J, V25, P1233, DOI 10.1002/smj.426
NR 65
TC 3
Z9 3
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 965
EP 994
DI 10.1007/s11042-018-6025-2
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500055
DA 2024-07-18
ER

PT J
AU Xu, CY
   Yang, J
   Gao, JB
AF Xu, Chunyan
   Yang, Jian
   Gao, Junbin
TI Coupled-learning convolutional neural networks for object recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Coupled-learning mechanism; Convolutional neural network; Object
   recognition; Semantic information
AB Recently, convolutional neural networks (CNN) have been attracting considerable attention in various computer vision tasks. Motivated by neuroscience, CNN has several similar properties with the learning process of human brain. A prominent difference is that each CNN is an independent learning process while the effective interaction/communication between people can play important role in the human visual system. Inspired by this fact, we proposed a novel Coupled-learning Convolutional Neural Network (Co-CNN) for the task of object recognition, which boosts its discriminative capability by employing the dynamic interaction between neural networks. Contrary to existing network architectures posing the network optimization problem as an isolated learning process, the intuition behind the Co-CNN framework is that the coupled learning mechanism may prevent the algorithm away from over-fitting to one or more particular objective functions. The proposed Co-CNN framework has three unique characteristics: (1) Co-CNN, which is a novel deep network learning framework, can simultaneously optimize both neural networks with same/different structures. (2) The learned semantic information, which can be gradually mined from neural networks, is employed to guide the communication between neural networks. (3) Co-CNN well incorporates the coupled-learning mechanism into the process of learning neural networks, and then further improve the recognition performance of neural networks by adopting the learned semantic information. Comprehensive evaluations on five benchmark datasets (CIFAR-10, CIFAR-100, MNIST, SVHN and Imagenet) well demonstrate the significant superiority of our proposed Co-CNN framework over other existing algorithms.
C1 [Xu, Chunyan; Yang, Jian] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Gao, Junbin] Univ Sydney, Business Sch, Discipline Business Analyt, Sydney, NSW 2006, Australia.
C3 Nanjing University of Science & Technology; University of Sydney
RP Xu, CY (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
EM cyx@njust.edu.cn
RI Gao, Junbin/C-6566-2008; Gao, Junbin/A-1766-2009
OI Gao, Junbin/0000-0001-9803-0256
FU National Natural Science Foundation of China [61602244, 61502235];
   CCF-Tencent Open Research Fund
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 61602244 and 61502235) and partially sponsored by
   CCF-Tencent Open Research Fund.
CR [Anonymous], 2015, INT C COMP VIS
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2000, HDB SELF REGULATION
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2015, ARXIV150602351
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, ICCV
   [Anonymous], 2015, ICLR
   [Anonymous], 2013, Maxout networks
   [Anonymous], MODELING ENV INTRO S
   [Anonymous], 2014, ARXIV14096070
   [Anonymous], IEEE CONFERENCE ON C
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2011, NEUR INF PROC SYST N
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, INT C COMP VIS
   [Anonymous], VISION SCI PHOTONS P
   [Anonymous], 2015, IEEE C COMP VIS PATT
   Berg A., 2010, Large scale visual recognition challenge
   Dayan P., 2001, THEORETICAL NEUROSCI
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Hou XX, 2017, IEEE WINT CONF APPL, P1133, DOI 10.1109/WACV.2017.131
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee C., 2015, P 19 TH INT C ARTIFI
   Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434
   Li Y., 2017, ARXIV170300577
   Lin M., 2014, P 2014 INT C LEARN R
   Sánchez J, 2011, PROC CVPR IEEE, P1665, DOI 10.1109/CVPR.2011.5995504
   Simonyan K, 2015, IEEE INT C ICLR
   Srivastava RK., 2015, P 28 INT C NEURAL IN, P2377, DOI DOI 10.48550/ARXIV.1507.06228
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wen XZ, 2015, INFORM SCIENCES, V295, P395, DOI 10.1016/j.ins.2014.10.040
   Xu CY, 2016, IEEE T CIRC SYST VID, V26, P2273, DOI 10.1109/TCSVT.2015.2477937
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yang M, 2017, PATTERN RECOGN, V66, P117, DOI 10.1016/j.patcog.2016.12.028
   Yuan CS, 2016, CHINA COMMUN, V13, P60, DOI 10.1109/CC.2016.7559076
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 40
TC 5
Z9 5
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 573
EP 589
DI 10.1007/s11042-017-5262-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500032
DA 2024-07-18
ER

PT J
AU Hachaj, T
   Koptyra, K
   Ogiela, MR
AF Hachaj, Tomasz
   Koptyra, Katarzyna
   Ogiela, Marek R.
TI Averaging of motion capture recordings for movements' templates
   generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Signal averaging; Movements' templates; Motion capture; Kalman filter;
   Dynamic time warping; Barycenter averaging; Karate
ID GESTURE RECOGNITION; FILTER; DTW
AB In this paper we propose, describe and evaluate the novel motion capture (MoCap) data averaging framework. It incorporates hierarchical kinematic model, angle coordinates' preprocessing methods, that recalculate the original MoCap recording making it applicable for further averaging algorithms, and finally signals averaging processing. We have tested two signal averaging methods namely Kalman Filter (KF) and Dynamic Time Warping barycenter averaging (DBA). The propose methods have been tested on MoCap recordings of elite Karate athlete, multiple champion of Oyama karate knockdown kumite who performed 28 different karate techniques repeated 10 times each. The proposed methods proved to have not only high effectiveness measured with root-mean-square deviation (4.04 +/- 5.03 degrees for KF and 5.57 +/- 6.27 for DBA) and normalized Dynamic Time Warping distance (0.90 +/- 1.58 degrees for KF and 0.93 +/- 1.23 for DBA), but also the reconstruction and visualization of those recordings persists all crucial aspects of those complicated actions. The proposed methodology has many important applications in classification, clustering, kinematic analysis and coaching. Our approach generates an averaged full body motion template that can be practically used for example for human actions recognition. In order to prove it we have evaluated templates generated by our method in human action classification tasks using DTW classifier. We have made two experiments. In first leave - one - out cross - validation we have obtained 100% correct recognitions. In second experiment when we classified recordings of one person using templates of another recognition rate 94.2% was obtained.
C1 [Hachaj, Tomasz] Pedag Univ Krakow, Inst Comp Sci & Comp Methods, 2 Podchorazych Ave, PL-30084 Krakow, Poland.
   [Koptyra, Katarzyna; Ogiela, Marek R.] AGH Univ Sci & Technol, Cryptog & Cognit Informat Res Grp, 30 Mickiewicza Ave, PL-30059 Krakow, Poland.
C3 Pedagogical University of Cracow; AGH University of Krakow
RP Hachaj, T (corresponding author), Pedag Univ Krakow, Inst Comp Sci & Comp Methods, 2 Podchorazych Ave, PL-30084 Krakow, Poland.
EM tomekhachaj@o2.pl; kkoptyra@agh.edu.pl; mogiela@agh.edu.pl
RI Hachaj, Tomasz/C-1741-2013; Ogiela, Marek R/A-7735-2013
OI Hachaj, Tomasz/0000-0003-1390-9021
FU National Science Center, Poland [2015/17/D/ST6/04051]
FX This work has been supported by the National Science Center, Poland,
   under project number 2015/17/D/ST6/04051.
CR Adistambha K, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P626
   [Anonymous], 2012, INT J SPORTS SCI ENG
   [Anonymous], 2018, ACM T MULTIM COMPUT, DOI DOI 10.1145/3182179
   [Anonymous], EUR J SCI RES
   Arici T, 2014, ROBUST GESTURE RECOG, V72
   Arici T, 2014, MULTIMED TOOLS APPL, V72, P3045, DOI 10.1007/s11042-013-1591-9
   Bianco S, 2013, INPROCEEDINGS SPIE
   Bielecka M, 2015, APPL SOFT COMPUT, V30, P179, DOI 10.1016/j.asoc.2015.01.023
   Burke M, 2016, J BIOMECH, V49, P1854, DOI 10.1016/j.jbiomech.2016.04.016
   Burns A-M, 2011, USING VIRTUAL HUMANS
   Celiktutan O., 2013, P 1 ACM INT WORKSHOP, P23
   Chen X, 2015, NEUROCOMPUTING, V149, P387, DOI 10.1016/j.neucom.2013.10.046
   Endres F, 2012, P ROBOTIK 2012, P1
   Etienne L, 2016, INT J GEOGR INF SCI, V30, P835, DOI 10.1080/13658816.2015.1081205
   Firouzmanesh A, 2011, IEEE T MULTIMEDIA, V13, P829, DOI 10.1109/TMM.2011.2129497
   Furlanello C, 2006, IEEE T SIGNAL PROCES, V54, P2436, DOI 10.1109/TSP.2006.873715
   Gheller RG, 2015, HUM MOVEMENT SCI, V42, P71, DOI 10.1016/j.humov.2015.04.010
   Giorgino T, 2009, J STAT SOFTW, V31, P1, DOI 10.18637/jss.v031.i07
   Glowacz A, 2016, BIOCYBERN BIOMED ENG, V36, P95, DOI 10.1016/j.bbe.2015.12.005
   Glowacz A, 2015, MEAS SCI REV, V15, P167, DOI 10.1515/msr-2015-0024
   Gupta S, 2012, PROCEDIA ENGINEER, V41, P827, DOI 10.1016/j.proeng.2012.07.250
   Hachaj T, 2016, MULTIMED TOOLS APPL, V75, P16265, DOI 10.1007/s11042-015-2928-3
   Hachaj T, 2015, 2015 10TH INTERNATIONAL CONFERENCE ON BROADBAND AND WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA 2015), P247, DOI 10.1109/BWCCA.2015.15
   Hachaj T, 2015, SYMMETRY-BASEL, V7, P1670, DOI 10.3390/sym7041670
   Hachaj T, 2015, DIGIT SIGNAL PROCESS, V46, P239, DOI 10.1016/j.dsp.2015.07.004
   Hachaj T, 2012, COMM COM INF SC, V353, P1
   Hadizadeh M, 2016, GAIT POSTURE, V48, P152, DOI 10.1016/j.gaitpost.2016.05.002
   Helske J., 2016, KFAS KALMAN FILTER S
   Helske J, 2016, J STAT SOFTWARE
   Huu P. C., 2014, VNU J. Sci.: Comput. Sci. Comput. Eng., V30, P22
   Izzetoglu M, 2010, BIOMED ENG ONLINE, V9, DOI 10.1186/1475-925X-9-16
   James LP, 2016, SPORTS MED, V46, P1525, DOI 10.1007/s40279-016-0493-1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jin M, 2014, MEASUREMENT, V49, P196, DOI 10.1016/j.measurement.2013.11.022
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kok M., 2014, IFAC PAPERSONLINE, V47, P79, DOI [DOI 10.3182/20140824-6-ZA-1003.02252, 10.3182/20140824-6-za-1003.02252, 10.3182/20140824-6-ZA-1003.02252]
   Kwon D.Y., 2005, P 2005 ACM SIGCHI IN, P94, DOI DOI 10.1145/1178477.1178490
   Larouche BP, 2014, AUTON ROBOT, V37, P157, DOI 10.1007/s10514-014-9383-2
   Lehrmann AM, 2014, IEEE C COMP VIS PATT
   Li YM, 2007, APPL MATH MECH-ENGL, V28, P1535, DOI 10.1007/s10483-007-1113-5
   Liu GD, 2006, VISUAL COMPUT, V22, P721, DOI 10.1007/s00371-006-0080-9
   López-Méndez A, 2012, IMAGE VISION COMPUT, V30, P808, DOI 10.1016/j.imavis.2012.06.007
   Mead R, 2013, INT J SOC ROBOT, V5, P367, DOI 10.1007/s12369-013-0189-8
   Miranda L, 2014, PATTERN RECOGN LETT, V39, P65, DOI 10.1016/j.patrec.2013.10.005
   Mitsuhashi Kaoru, 2014, ICINCO 2014. 11th International Conference on Informatics in Control, Automation and Robotics. Proceedings, P550
   Muller M., 2007, Information retrieval for music and motion, P69, DOI [10.1007/978-3-540-74048-3_4, DOI 10.1007/978-3-540-74048-3_4]
   Neto OP, 2008, J ELECTROMYOGR KINES, V18, P1047, DOI 10.1016/j.jelekin.2007.03.009
   Palma C, 2016, ARXIV160203742
   Peng LY, 2017, IEEE T BIO-MED ENG, V64, P1369, DOI 10.1109/TBME.2016.2604856
   Petitjean F, 2011, PATTERN RECOGN, V44, P678, DOI 10.1016/j.patcog.2010.09.013
   Neto OP, 2012, HUM MOVEMENT SCI, V31, P824, DOI 10.1016/j.humov.2011.07.016
   Piorkowski A, 2009, COMM COM INF SC, V39, P218, DOI 10.1007/978-3-642-02671-3_26
   Pliske G, 2016, AGING CLIN EXP RES, V28, P1179, DOI 10.1007/s40520-015-0508-z
   Qi Y, 2014, WEAR WIR ULTR SENS N
   Quinzi F, 2013, J ELECTROMYOGR KINES, V23, P140, DOI 10.1016/j.jelekin.2012.09.006
   Moreira PVS, 2016, J ELECTROMYOGR KINES, V30, P55, DOI 10.1016/j.jelekin.2016.06.001
   Sbriccoli P, 2010, EUR J APPL PHYSIOL, V108, P1269, DOI 10.1007/s00421-009-1338-5
   Seto S, 2015, 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1399, DOI 10.1109/SSCI.2015.199
   Slama R, 2013, EUR WORKSH 3D OBJ RE, DOI [10. 2312/3DOR/3DOR13/033-040, DOI 10.2312/3D0R/3D0R13/033-040]
   Stasinopoulos S, 2012, INPR 2012 19 IEEE IN
   Su CJ, 2014, APPL SOFT COMPUT, V22, P652, DOI 10.1016/j.asoc.2014.04.020
   Sul CW, 1998, LECT NOTES ARTIF INT, V1537, P100
   Timmi A, 2011, BIOMECHANICAL ANAL 2
   VencesBrito AM, 2011, J ELECTROMYOGR KINES, V21, P1023, DOI 10.1016/j.jelekin.2011.09.007
   Vignais N, 2015, HUM MOVEMENT SCI, V39, P12, DOI 10.1016/j.humov.2014.10.006
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yin S, 2011, COMPUT VIS IMAGE UND, V115, P885, DOI 10.1016/j.cviu.2011.02.010
   Zhang SG, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3090343
NR 70
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30353
EP 30380
DI 10.1007/s11042-018-6137-8
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600010
OA hybrid
DA 2024-07-18
ER

PT J
AU Korichi, M
   Kherfi, ML
   Batouche, M
   Bouanane, K
AF Korichi, Meriem
   Kherfi, Mohamed Lamine
   Batouche, Mohamed
   Bouanane, Khadra
TI Extended Bayesian generalization model for understanding user's
   intention in semantics based images retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; User's intention; Bayesian models of generalization;
   Ontology; ImageNet
ID QUERY; SYSTEM
AB Learning concepts from examples presented in user's query and infer the other items that belong to this query is still a significant challenge for images retrieval systems. Existing models from cognitive science namely Bayesian models of generalization mainly focus on this challenge where they remarkably succeed at explaining how to generalize from few examples in a wide range of domains. However their success largely depends on the validity of examples. They require that each example is a good representative, which is not always the case in the context of images retrieval. In this paper, we will extend the Bayesian models of generalization to identify the appropriate level of generalization for a given query in the context of query by semantic example systems. Our model uses an ontology as the basis of its hypothesis space which allows us to take advantages of its semantic richness and inference capacity. Experimental study using the ImageNet benchmark verifies the efficiency of our model in comparison to the state-of-the-art models of generalization.
C1 [Korichi, Meriem] Univ Constantine 2 Abdelhamid Mehri, Dept Comp Sci, Constantine, Algeria.
   [Batouche, Mohamed] Univ Constantine 2 Abdelhamid Mehri, Dept Comp Sci, Coll NTIC, Constantine, Algeria.
   [Kherfi, Mohamed Lamine] Univ Quebec Trois Rivieres, LAMIA Lab, Trois Rivieres, PQ, Canada.
   [Kherfi, Mohamed Lamine] Univ Ouargla Kasdi Merbah, LINATI Lab, Ouargla, Algeria.
   [Bouanane, Khadra] Univ Ouargla Kasdi Merbah, Dept Math, Ouargla, Algeria.
C3 University of Quebec; University of Quebec Trois Rivieres
RP Korichi, M (corresponding author), Univ Constantine 2 Abdelhamid Mehri, Dept Comp Sci, Constantine, Algeria.
EM meriemkorichi@gmail.com; Mohammedlamine.Kherfi@uqtr.ca;
   mohamed.batouche@univ-constantine2.dz; khadra.bouanane@gmail.com
RI Batouche, Mohamed/KHC-4727-2024; Kherfi, Mohammed Lamine/AAF-2930-2020
OI Kherfi, Mohammed Lamine/0000-0003-1017-1113; Bouanane,
   Khadra/0000-0001-9018-076X; Batouche, Mohamed/0000-0002-2456-7859
CR Allani O, 2016, PROCEDIA COMPUT SCI, V96, P1428, DOI 10.1016/j.procs.2016.08.188
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2009, P 17 ACM INT C MULTI
   [Anonymous], 2006, Advances in Neural Information Processing Systems
   [Anonymous], 2008, 2008 IEEE COMP SOC C
   [Anonymous], P ACM SIGIR
   [Anonymous], P 34 ANN C COGN SCI
   Austerweil JL, 2001, LEARNING HYPOTHESIS, P73
   Austerweil JL, 2011, COGNITIVE SCI, V35, P499, DOI 10.1111/j.1551-6709.2010.01161.x
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   Ben-Haim N, 2006, P INTLWORKSHOP SEM L
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Celik C, 2017, PATTERN RECOGN, V68, P1, DOI 10.1016/j.patcog.2017.03.006
   Datta D, 2017, EXPERT SYST APPL, V68, P81, DOI 10.1016/j.eswa.2016.09.039
   Deepa C, 2017, AUTOM CONTROL COMPUT, V51, P108, DOI 10.3103/S014641161702002X
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Filali Jalila, 2016, ICAART 2016. 8th International Conference on Agents and Artificial Intelligence. Proceedings, P560
   Gao LL, 2017, IEEE T MULTIMEDIA, V19, P2045, DOI 10.1109/TMM.2017.2729019
   Gao LL, 2017, MULTIMEDIA SYST, V23, P303, DOI 10.1007/s00530-015-0494-1
   Hannan MA, 2016, WASTE MANAGE, V50, P10, DOI 10.1016/j.wasman.2016.01.046
   Hartvedt Christian, 2010, Proceedings of the Second International Conference on Advances in Multimedia (MMEDIA 2010), P130, DOI 10.1109/MMEDIA.2010.35
   Heller K., 2008, THESIS
   Heller KA, 2006, IEEE C COMP VIS PATT
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hsu WH, 2006, P 14 ANN ACM INT C M
   Jia Y, 2013, ADV NEURAL INF PROCE, V1, P1
   Jing Y, 2008, P INT C WORLD WID WE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lamine Mohammed, 2008, ADV HUMAN COMPUTER I
   Liaqat M, 2017, MULTIMEDIA TOOLS APP
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Natsev A.P., 2007, P 15 INT C MULT
   Nematzadeh A, 2015, P 2015 C EMP METH NA, P1795
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Park G, 2003, P 2 INT C IM VID RET
   Rasiwasia N, 2007, IEEE T MULTIMEDIA, V9, P923, DOI 10.1109/TMM.2007.900138
   SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243
   Silva R, 2007, INT C AI STAT
   Song J, 2017, ARXIV170107901
   Song JK, 2018, PATTERN RECOGN, V75, P175, DOI 10.1016/j.patcog.2017.03.021
   Tang XO, 2012, IEEE T PATTERN ANAL, V34, P1342, DOI 10.1109/TPAMI.2011.242
   Tenenbaum J, 2000, PROCEEDINGS OF THE TWENTY-SECOND ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, P16
   Tenenbaum JB, 2001, GEN SIMILARITY BAYES, P629
   Tolias G, 2014, PATTERN RECOGN, V47, P3466, DOI 10.1016/j.patcog.2014.04.007
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang JD, 2018, IEEE T PATTERN ANAL, V40, P769, DOI 10.1109/TPAMI.2017.2699960
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Yu D., 2013, ABS13013605 CORR
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhao F, 2015, PROC CVPR IEEE, P1556, DOI 10.1109/CVPR.2015.7298763
NR 52
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 31115
EP 31138
DI 10.1007/s11042-018-6205-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600043
DA 2024-07-18
ER

PT J
AU Lüsi, I
   Bolotnikova, A
   Daneshmand, M
   Ozcinar, C
   Anbarjafari, G
AF Luesi, Iiris
   Bolotnikova, Anastasia
   Daneshmand, Morteza
   Ozcinar, Cagri
   Anbarjafari, Gholamreza
TI Optimal image compression via block-based adaptive colour reduction with
   minimal contour effect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive colour reduction; Image compression; Block processing; Colour
   image processing
ID SINGULAR-VALUE DECOMPOSITION; QUALITY ASSESSMENT; EDGE-DETECTION;
   QUANTIZATION; ALGORITHM; SCREEN; OPTIMIZATION; DISCRETE
AB Current image acquisition devices require tremendous amounts of storage for saving the data returned. This paper overcomes the latter drawback through proposing a colour reduction technique which first subdivides the image into patches, and then makes use of fuzzy c-means and fuzzy-logic-based inference systems, in order to cluster and reduce the number of the unique colours present in each patch, iteratively. The colours available in each patch are quantised, and the emergence of false edges is checked for, by means of the Sobel edge detection algorithm, so as to minimise the contour effect. At the compression stage, a methodology taking advantage of block-based singular value decomposition and wavelet difference reduction is adopted. Considering 35000 sample images from various databases, the proposed method outperforms centre cut, moment-preserving threshold, inter-colour correlation, generic K-means and quantisation by dimensionality reduction.
C1 [Luesi, Iiris; Bolotnikova, Anastasia; Daneshmand, Morteza; Anbarjafari, Gholamreza] Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.
   [Ozcinar, Cagri] Trinity Coll Dublin, Sch Comp Sci & Stat, Dublin 2, Ireland.
   [Anbarjafari, Gholamreza] Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkey.
C3 University of Tartu; Trinity College Dublin; Hasan Kalyoncu University
RP Anbarjafari, G (corresponding author), Univ Tartu, Inst Technol, iCV Res Grp, EE-50411 Tartu, Estonia.; Anbarjafari, G (corresponding author), Hasan Kalyoncu Univ, Dept Elect & Elect Engn, Gaziantep, Turkey.
EM iiris@icv.tuit.ut.ee; nana@icv.tuit.ut.ee; md@icv.tuit.ut.ee;
   ozcinarc@scss.tcd.ie; shb@icv.tuit.ut.ee
RI Anbarjafari, Gholamreza/A-3845-2010; Bolotnikova,
   Anastasia/ABA-2040-2020; Daneshmand, Morteza/AAA-8605-2019
OI Anbarjafari, Gholamreza/0000-0001-8460-5717; Daneshmand,
   Morteza/0000-0003-2122-2051; Ozcinar, Cagri/0000-0003-4915-2251
FU Estonian Research Council [PUT638]; Scientific and Technological
   Research Council of Turkey (TUBITAK) 1001 Project [116E097]; Estonian
   Centre of Excellence in IT (EXCITE) - European Regional Development
   Fund; NVIDIA Corporation
FX This work has been partially supported by Estonian Research Council
   Grant PUT638, the Estonian Research Council Grant (PUT638), The
   Scientific and Technological Research Council of Turkey (TUBITAK) 1001
   Project (116E097), and the Estonian Centre of Excellence in IT (EXCITE)
   funded by the European Regional Development Fund. The authors would like
   to thank the RoboCup SPL Team of University of Tartu, Philosopher, for
   helping to conduct real-time experiments and also gratefully acknowledge
   the support of NVIDIA Corporation with the donation of the Titan X
   Pascal GPU.
CR Abdi H., 2007, ENCY MEASUREMENT STA, P907, DOI DOI 10.4135/9781412952644.N413
   Akarun L, 1997, IEEE T IMAGE PROCESS, V6, P950, DOI 10.1109/83.597270
   Akenine-Moller TG, 2016, US Patent, Patent No. [9,357,236, 9357236]
   Amasyal SAF, 2003, INT 12 TURK S ART IN
   Anbarjafari G, 2015, SIGNAL IMAGE VIDEO P, V9, P87, DOI 10.1007/s11760-012-0422-1
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Bao P, 2005, IEEE T CIRC SYST VID, V15, P96, DOI 10.1109/TCSVT.2004.836745
   Boardman JW, 1989, 12 CAN S REM SENS GE
   Bolotnikova A, 2015, PROC SPIE, V9817, DOI 10.1117/12.2227994
   Braquelaire JP, 1997, IEEE T IMAGE PROCESS, V6, P1048, DOI 10.1109/83.597280
   Celebi ME, 2011, IEEE IMAGE PROC, P1729, DOI 10.1109/ICIP.2011.6115792
   Celebi ME, 2011, IMAGE VISION COMPUT, V29, P260, DOI 10.1016/j.imavis.2010.10.002
   Chandra DS, 2002, 2002 45 MIDW S CIRC, V3, P3
   Charrier M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P131, DOI 10.1109/MMCS.1999.779134
   Chou CH, 2004, IEEE IMAGE PROC, P2331
   DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003
   Demirel H, 2010, IEEE GEOSCI REMOTE S, V7, P333, DOI 10.1109/LGRS.2009.2034873
   Di Martino F, 2014, INFORM SCIENCES, V266, P101, DOI 10.1016/j.ins.2014.01.014
   Dunn J. C., 1973, Journal of Cybernetics, P32, DOI 10.1080/01969727308546046
   Emre Celebi M., 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P876
   FREIRE SLM, 1988, GEOPHYSICS, V53, P778, DOI 10.1190/1.1442513
   Ganic Emir, 2004, P 2004 WORKSHOP MULT, P166, DOI DOI 10.1145/1022431.1022461
   Goffman-Vinopal L, 2002, P INT C IM PROC, V2, pII
   Groach M., 2012, INT J ENG RES APPL, V2, P560
   Gu K, 2016, IEEE T BROADCAST, V62, P446, DOI 10.1109/TBC.2015.2511624
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Gu K, 2016, NEUROCOMPUTING, V196, P140, DOI 10.1016/j.neucom.2015.11.101
   Gu K, 2014, IEEE IMAGE PROC, P506, DOI 10.1109/ICIP.2014.7025101
   Huan Yang, 2014, 2014 Sixth International Workshop on Quality of Multimedia Experience (QoMEX), P257, DOI 10.1109/QoMEX.2014.6982328
   Huang CY, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2537855
   Huang G.B., 2014, LABELED FACES WILD U
   Hughes JF., 2014, Computer Graphics: Principles and Practice, V3
   Iwai S, 1987, US Patent, Patent No. [4,710,806, 4710806]
   Joy G., 1993, Visual Computer, V10, P62, DOI 10.1007/BF01905532
   Kanjanawanishkul K, 2005, J VIS COMMUN IMAGE R, V16, P311, DOI 10.1016/j.jvcir.2004.07.002
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Lamsrichan P, 2006, IEEE IMAGE PROC, P1137, DOI 10.1109/ICIP.2006.312757
   Lewandowski F, 2012, 2012 INTERNATIONAL CONFERENCE ON SIGNALS AND ELECTRONIC SYSTEMS (ICSES), DOI 10.1109/ICSES.2012.6382237
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li JSJ, 2010, 2010 25TH INTERNATIO, P1
   Li QZ, 2010, J VIS COMMUN IMAGE R, V21, P762, DOI 10.1016/j.jvcir.2010.05.003
   Li Y, 2002, INT C PATT RECOG, P952, DOI 10.1109/ICPR.2002.1048195
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   MacDonald LW, 1993, US Patent, Patent No. [5,254,977, 5254977]
   MacInnis AG, 2004, US Patent, Patent No. [6,819,330, 6819330]
   Mavridis P., 2012, J COMPUTER GRAPHICS, V1, P19
   Mikolov T, 2008, COLOR REDUCTION USIN
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Nikolaou N, 2009, INT J IMAG SYST TECH, V19, P14, DOI 10.1002/ima.20174
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Omran MG, 2005, INFORMATICA, V29
   Papamarkos N, 2002, IEEE T SYST MAN CY B, V32, P44, DOI 10.1109/3477.979959
   Parraga C, 2009, PERCEPTION, V38, P180
   Parraga CA, 2010, P EUR C COL GRAPH IM, V2010, P50
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Puzicha J, 2000, IEEE T IMAGE PROCESS, V9, P666, DOI 10.1109/83.841942
   Raja S. P., 2010, 2010 International Conference on Communication Control and Computing Technologies, P661, DOI 10.1109/ICCCCT.2010.5670757
   Recommendation ITU-R, 2012, REC ITU R BT 500 13
   Rufai AM, 2013, P SIGN PROC COMM APP, V21, P1, DOI DOI 10.1109/SIU.2013.6531592
   Rufai AM, 2014, DIGIT SIGNAL PROCESS, V24, P117, DOI 10.1016/j.dsp.2013.09.008
   Rui X, 2002, FIRST IEEE INTERNATION WORKSHOP ON ELECTRONIC DESIGN, TEST AND APPLICATIONS, PROCEEDINGS, P321, DOI 10.1109/DELTA.2002.994639
   Scheunders P, 1997, PATTERN RECOGN, V30, P859, DOI 10.1016/S0031-3203(96)00131-8
   Skodras A. N., 2006, 2006 IEEE International Symposium on Circuits and Systems (IEEE Cat. No. 06CH37717C)
   Sudhakar R., 2005, ICGSTGVIP J, V5, P25
   Sun B, 2006, EUR WORKSH NAT PHEN
   Tkacik G, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0020409
   UCHIYAMA T, 1994, PATTERN RECOGN, V27, P1415, DOI 10.1016/0031-3203(94)90074-4
   Vazquez J, 2009, J IMAG SCI TECHNOL J, V1, P1
   Velho L, 1997, X BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P203, DOI 10.1109/SIGRA.1997.625178
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walker JS, 2000, OPT ENG, V39, P1891, DOI 10.1117/1.602573
   Walker JS, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P182, DOI 10.1109/ICIP.2000.899325
   Walker JS, 2005, COMP JPEG2000 LOSSY
   WAN SJ, 1990, COLOR RES APPL, V15, P52, DOI 10.1002/col.5080150109
   Wang S, 2016, IEEE COMPUT GRAPH AP
   Wang SQ, 2015, IEEE IMAGE PROC, P1434, DOI 10.1109/ICIP.2015.7351037
   WATSON AB, 1994, IEEE IMAGE PROC, P100, DOI 10.1109/ICIP.1994.413283
   Xiang ZG, 1997, ACM T GRAPHIC, V16, P260, DOI 10.1145/256157.256159
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Yang CK, 1996, PATTERN RECOGN LETT, V17, P481, DOI 10.1016/0167-8655(95)00112-3
   Yang CK, 1998, PATTERN RECOGN LETT, V19, P205, DOI 10.1016/S0167-8655(97)00166-9
   Yang H, 2015, IEEE T IMAGE PROCESS, V24, P4408, DOI 10.1109/TIP.2015.2465145
   YANG JF, 1995, IEEE T IMAGE PROCESS, V4, P1141, DOI 10.1109/83.403419
   Yoshikawa H, 2012, PHOTONICS ASIA
   Yuan Y, 2005, IEE P-VIS IMAGE SIGN, V152, P9, DOI 10.1049/ip-vis:20051183
   Yuan Y, 2003, 2003 INT C IM PROC 2, V2, pII
   Zabala A, 2013, INT J REMOTE SENS, V34, P2796, DOI 10.1080/01431161.2012.750772
   Zhang DQ, 2004, ARTIF INTELL MED, V32, P37, DOI [10.1016/j.artmed.2004.01.012, 10.1016/j.artmed. 2004.01.012]
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
   Zhu L, 2014, J SUPERCOMPUT, V68, P820, DOI 10.1007/s11227-013-1068-7
NR 92
TC 4
Z9 4
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30939
EP 30968
DI 10.1007/s11042-018-6118-y
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600036
DA 2024-07-18
ER

PT J
AU Rafi, M
   Mukhopadhyay, S
AF Rafi, Mudassir
   Mukhopadhyay, Susanta
TI Texture description using multi-scale morphological GLCM
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Texture description; Feature extraction; Texture classification
ID BINARY PATTERN; IMAGE; CLASSIFICATION; FEATURES; RESOLUTION; MULTIPLE;
   SCALE
AB Texture is the collective repetitive pattern that characterizes the surface of real world objects. The main challenge in the texture description is its application specific definition. The present work aims at bringing the definition of textures under a generalized framework and propose some texture descriptors. In order to accomplish this, authors have extensively studied the properties of texture, drawn four observations and used some of them to devise two texture descriptors under the framework of multi-scale mathematical morphology and co-occurrence matrices. Thereafter, the descriptors are used for texture classification and tested on three benchmark datasets. Before applying the descriptors to texture classification, a dependence between number of decomposition levels (scales) and classification percentage is established using hypothesis testing. Once the dependence is established, the corresponding scale and distance parameter is chosen for each dataset. The classification results are compared with a number of existing methods. The efficacy of results prove the supremacy of the proposed methods over the existing ones.
C1 [Rafi, Mudassir; Mukhopadhyay, Susanta] Indian Inst Technol ISM, Dhanbad 826004, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Rafi, M (corresponding author), Indian Inst Technol ISM, Dhanbad 826004, Bihar, India.
EM mudassir@cse.ism.ac.in; msushanta2001@gmail.com
RI Rafi, Mudassir/AAC-7520-2019
CR Ando S, 2000, PAMI, V22, P320, DOI [10.1109/34.841757, DOI 10.1109/34.841757]
   [Anonymous], 2016, P ISR 2016 47 INT S
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Berg AC, 2006, SHAPE MATCHING OBJEC
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Chi J, 2017, COMPUTER VISION IMAG
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   de Siqueira FR, 2013, NEUROCOMPUTING, V120, P336, DOI 10.1016/j.neucom.2012.09.042
   Demin Wang, 1993, Journal of Visual Communication and Image Representation, V4, P197, DOI 10.1006/jvci.1993.1019
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Galloway MM., 1975, COMPUTER GRAPHICS IM, V4, P172, DOI DOI 10.1016/S0146-664X(75)80008-6
   Gonzalez RC, 1992, REWOODS DIGITAL IMAG
   Guo ZH, 2016, IEEE T IMAGE PROCESS, V25, P687, DOI 10.1109/TIP.2015.2507408
   Hanbury A, 2005, COMPUT IMAGING VIS, V30, P377
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hawkins J.K., 1970, Picture processing and psychopictorics, P347
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Jeulin D, 2016, MATH MORPHOL THEORY, V1, P216
   Kurmyshev EV, 1996, REV MEX FIS, V42, P104
   Liu L., 2018, ARXIV180110324
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   Petrou M., 2006, IMAGE PROCESSING
   Qian XM, 2014, MULTIMED TOOLS APPL, V69, P897, DOI 10.1007/s11042-012-1151-8
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   RICHARDS W, 1974, KYBERNETIK, V16, P155, DOI 10.1007/BF00271719
   Ryu J, 2015, IEEE T IMAGE PROCESS, V24, P2254, DOI 10.1109/TIP.2015.2419081
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tamura H., 1978, IEEE Transactions on Systems, Man and Cybernetics, VSMC-8, P460, DOI 10.1109/TSMC.1978.4309999
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   WERMAN M, 1985, IEEE T PATTERN ANAL, V7, P730, DOI 10.1109/TPAMI.1985.4767732
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Xue J, 2017, IEEE C COMP VIS PATT, V5
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zucker S. W., 1981, IEEE Computer Society Conference on Pattern Recognition and Image Processing, P609
NR 49
TC 7
Z9 7
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30505
EP 30532
DI 10.1007/s11042-018-5989-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600017
DA 2024-07-18
ER

PT J
AU Zare, S
AF Zare, Sajjad
TI A program-driven approach joint with pre-buffering and popularity to
   reduce latency during channel surfing periods in IPTV networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; Pre-buffering; Popularity; Channel switching; Surfing period;
   Program-driven
ID TIME; SCHEME
AB Internet protocol television (IPTV), which is quickly growing in popularity, can provide hundreds of channels; however, finding a desired IPTV channel among hundreds of channels is a difficult and time consuming issue. Since the very big number of channels, and the delay in switching between them due to network bandwidth limitations, can make it difficult for viewers to find the content they want. To solve this problem, we propose a novel method to reduce channel surfing period that is called Pre-Buffering join with Program Driven (PBPD) method. It is noted that the number of channel switches has a main effect on the channel surfing period. Our proposed method is based on programs; it means that instead of choosing channels, users select their desired programs by which they can reach the channels playing the programs. In addition we send all channels playing the selected program type plus one channel (most popular) from each group of channels playing other types of program in time slots to the STB(set-top box) including minimum one I-frame and finally we use popularity to select the channel in the STB. Simulation results show that the proposed method can reduce the number of channel switches, waiting time for the delivery of the earliest key-frame after selecting a channel and average time to join a broadcasting group; therefore, the proposed method has a good performance in comparison to other methods.
C1 [Zare, Sajjad] Payame Noor Univ, Dept Informat Technol Engn, Tehran, Iran.
C3 Payame Noor University
RP Zare, S (corresponding author), Payame Noor Univ, Dept Informat Technol Engn, Tehran, Iran.
EM sajjad.zare@pnu.ac.ir
RI zare, sajjad/AAF-9796-2022; zare, sajjad/AFK-2526-2022
OI zare, sajjad/0000-0002-6539-8510; zare, sajjad/0000-0002-6539-8510
FU Payame Noor University (PNU), Iran
FX This research was financially supported by Payame Noor University (PNU),
   Iran.
CR Azgin A, 2013, IEEE T BROADCAST, V59, P471, DOI 10.1109/TBC.2013.2265773
   Bejerano Y, 2009, IEEE INFOCOM SER, P1971, DOI 10.1109/INFCOM.2009.5062119
   Boyce JM, 2005, IEEE ICCE, P1
   Caenegem TV, 2010, CHANGE CHANNEL FAST, P7
   Cho C, 2004, 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P971
   Degrande N, 2008, IEEE COMMUN MAG, V46, P94, DOI 10.1109/MCOM.2008.4473090
   Hei XJ, 2007, IEEE T MULTIMEDIA, V9, P1672, DOI 10.1109/TMM.2007.907451
   Jennehag U, 2007, IEEE T BROADCAST, V53, P69, DOI 10.1109/TBC.2006.887167
   Joo H, 2008, IEEE T BROADCAST, V54, P208, DOI 10.1109/TBC.2008.915767
   Lee E, 2014, IEEE T CONSUM ELECTR, V60, P124, DOI 10.1109/TCE.2014.6780934
   Lee E, 2009, IEEE T CONSUM ELECTR, V55, P1945, DOI 10.1109/TCE.2009.5373754
   Lee Y, 2008, IEEE T CONSUM ELECTR, V54, P912, DOI 10.1109/TCE.2008.4560178
   Li Y., 2011, Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference, P209, DOI [10.1145/2068816, DOI 10.1145/2068816]
   Manjunath L, 2013, INT J ENG RES APPL I, V3, P1331
   Yang C, 2015, IEEE T MULTIMEDIA, V17, P1096, DOI 10.1109/TMM.2015.2429552
   Zare S, 2016, MULTIMED TOOLS APPL, V75, P16059, DOI 10.1007/s11042-015-2913-x
   Zare S, 2014, J NETW COMPUT APPL, V37, P240, DOI 10.1016/j.jnca.2013.02.012
   Zare S, 2012, J NETW COMPUT APPL, V35, P459, DOI 10.1016/j.jnca.2011.09.008
NR 18
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 32093
EP 32105
DI 10.1007/s11042-018-6235-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000026
DA 2024-07-18
ER

PT J
AU Cai, YQ
   Wang, WQ
   Huang, S
   Ma, J
   Lu, K
AF Cai, Yuanqiang
   Wang, Weiqiang
   Huang, Shao
   Ma, Jin
   Lu, Ke
TI Spatiotemporal text localization for videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Text localization; Spatiotemporal domain; Sampling-and-recovery;
   Divide-and-conquer; Overlaid text
ID FEATURE-SELECTION; RECOGNITION; COMPETITION; TRACKING
AB Text in videos contains rich semantic information, which is useful for content based video understanding and retrieval. Although a great number of state-of-the-art methods are proposed to detect text in images and videos, few works focus on spatiotemporal text localization in videos. In this paper, we present a spatiotemporal text localization method with an improved detection efficiency and performance. Concretely, a unified framework is proposed which consists of the sampling-and-recovery model (SaRM) and the divide-and-conquer model (DaCM). SaRM aims at exploiting the temporal redundancy of text to increase the detection efficiency for videos. DaCM is designed to efficiently localize the text in spatiotemporal domain simultaneously. Besides, we construct a challenging video overlaid text dataset named UCAS-STLData, which contains 57070 frames with spatiotemporal ground truths. In the experiments, we comprehensively evaluate the proposed method on the publicly available overlaid text datasets and UCAS-STLData. A slight performance improvement is achieved compared with the state-of-the-art methods for spatiotemporal text localization, with a significant efficiency improvement.
C1 [Cai, Yuanqiang; Wang, Weiqiang; Huang, Shao; Ma, Jin] Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China.
   [Lu, Ke] Univ Chinese Acad Sci, Sch Engn Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS
RP Wang, WQ (corresponding author), Univ Chinese Acad Sci, Sch Comp & Control Engn, Beijing 101408, Peoples R China.
EM caiyuanqiang15@mails.ucas.ac.cn; wqwang@ucas.ac.cn;
   huangshao11@mails.ucas.ac.cn; majin12b@mails.ucas.ac.cn; luk@ucas.ac.cn
FU National Key R&D Program of China [2017YFB1002203]; National Nature
   Science Foundation of China (NSFC) [61772495]
FX This work is supported by National Key R&D Program of China under
   contract No. 2017YFB1002203, and also supported by National Nature
   Science Foundation of China (NSFC) under Grant Nos. 61772495.
CR [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014, Handbook of Document Image Processing and Recognition, DOI [10.1007/978-0-85729-859-1_28, DOI 10.1007/978-0-85729-859-1_28]
   Bai Nong, 2016, ARXIV160609002
   Bai X, 2017, PATTERN RECOGN, V66, P437, DOI 10.1016/j.patcog.2016.12.005
   Busta M, 2015, INT C COMP VIS COMP
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Fang SC, 2017, MULTIMED TOOLS APPL, V76, P15083, DOI 10.1007/s11042-017-4538-8
   Fernández DG, 2018, MULTIMED TOOLS APPL, V77, P5907, DOI 10.1007/s11042-017-4503-6
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Han YH, 2015, IEEE T IMAGE PROCESS, V24, P5114, DOI 10.1109/TIP.2015.2479917
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Huang WL, 2014, LECT NOTES COMPUT SC, V8692, P497, DOI 10.1007/978-3-319-10593-2_33
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Khare V, 2017, MULTIMED TOOLS APPL, V76, P16625, DOI 10.1007/s11042-016-3941-x
   Khare V, 2016, PATTERN RECOGN, V54, P128, DOI 10.1016/j.patcog.2016.01.008
   Li Z, 2017, IEEE T NEURAL NETW L, P1
   Li ZC, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2624140
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Liang GZ, 2015, IEEE T IMAGE PROCESS, V24, P4488, DOI 10.1109/TIP.2015.2465169
   Liao MH, 2017, AAAI CONF ARTIF INTE, P4161
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X., 2010, P 18 INT C MULTIMEDI, P843
   Liu XQ, 2012, IEEE T MULTIMEDIA, V14, P482, DOI 10.1109/TMM.2011.2177646
   Liu YL, 2017, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2017.368
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Ma J, 2017, IEEE INT CON MULTI, P367, DOI 10.1109/ICME.2017.8019440
   Minetto R, 2011, IEEE IMAGE PROC, P505, DOI 10.1109/ICIP.2011.6116563
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Nguyen PX, 2014, IEEE WINT CONF APPL, P776, DOI 10.1109/WACV.2014.6836024
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi BG, 2017, PROC CVPR IEEE, P3482, DOI 10.1109/CVPR.2017.371
   Shivakumara P, 2013, IEEE T CIRC SYST VID, V23, P1729, DOI 10.1109/TCSVT.2013.2255396
   Shivakumara P, 2012, IEEE T CIRC SYST VID, V22, P1227, DOI 10.1109/TCSVT.2012.2198129
   Shivakumara P, 2011, PATTERN RECOGN, V44, P1671, DOI 10.1016/j.patcog.2011.02.008
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tian S., 2016, IJCAI
   Wu L, 2015, IEEE T MULTIMEDIA, V17, P1137, DOI 10.1109/TMM.2015.2443556
   Yang C, IEEE T IMAGE PROCESS, V26
   Yang ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P146, DOI 10.1145/3123266.3123327
   Yao C, 2012, PROC CVPR IEEE, P1083, DOI 10.1109/CVPR.2012.6247787
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yi Chucai, 2011, IEEE Trans Image Process, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhao Shichao., 2017, IEEE Transactions on Circuits and Systems for Video Technology
   Zhou XY, 2017, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2017.283
NR 54
TC 1
Z9 1
U1 4
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29323
EP 29345
DI 10.1007/s11042-018-6081-7
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800008
DA 2024-07-18
ER

PT J
AU Fang, YM
   Zhang, C
   Yang, WH
   Liu, JY
   Guo, ZM
AF Fang, Yuming
   Zhang, Chi
   Yang, Wenhan
   Liu, Jiaying
   Guo, Zongming
TI Blind visual quality assessment for image super-resolution by
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual image quality assessment; Image super-resolution; Deep neural
   network
ID SPARSE REPRESENTATION; REGULARIZATION; STATISTICS; VIDEO
AB Image super-resolution aims to increase the resolution of images with good visual experience. Over the past decades, there have been many image super-resolution algorithms proposed for various multimedia processing applications. However, how to evaluate the visual quality of high-resolution images generated by image super-resolution methods is still challenging. In this paper, a Convolutional Neural Network is designed to predict the visual quality of image super-resolution. The proposed network consists of two convolutional layers, two pooling layers including average, min and max pooling, three fully connected layers and one regression layer. The contribution of the proposed method is twofold. The first one is that we propose a the deep convolutional neural network to extract the high-level intrinsic features more effectively than the hand-crafted features for super-resolution images, which can be used to estimate the image quality accurately. The other is that we divide the super-resolution image into small patches, to consider the local information for the visual quality assessment of super-resolution image as well as increase the number of training data for the deep neural network. Experimental results show that the proposed metric can obtain better performance than other existing ones in visual quality assessment of image super-resolution.
C1 [Fang, Yuming; Zhang, Chi] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang, Jiangxi, Peoples R China.
   [Yang, Wenhan; Liu, Jiaying; Guo, Zongming] Peking Univ, Inst Comp Sci & Technol, Beijing, Peoples R China.
C3 Jiangxi University of Finance & Economics; Peking University
RP Guo, ZM (corresponding author), Peking Univ, Inst Comp Sci & Technol, Beijing, Peoples R China.
EM fa0001ng@e.ntu.edu.sg; guozongming@pku.edu.cn
RI Liu, JY/GYJ-0138-2022
OI Liu, Jiaying/0000-0002-0468-9576; Zhang, Chi/0000-0002-4174-3201
FU Natural Science Foundation of China [61571212]; Natural Science
   Foundation of Jiangxi Province in China [20071BBE50068, 20171BCB23048,
   20161ACB21014, GJJ160420]
FX This work was partially funded by the Natural Science Foundation of
   China under Grant 61571212, and by Natural Science Foundation of Jiangxi
   Province in China under Grant 20071BBE50068, 20171BCB23048,
   20161ACB21014 and Grant GJJ160420.
CR Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 1984, ADV COMPUTER VISION
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE 37 AS C SIGN SY
   [Anonymous], INFORM FUSION
   [Anonymous], IEEE T CIRCUIT SYSTE
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], ACM T GRAPH
   [Anonymous], COMPUTER SCI
   [Anonymous], 2017, IEEE Transactions on Image Processing A Publication of the IEEE Signal Processing Society
   [Anonymous], COMPUTER SCI
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], IEEE T CYBERNETICS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], KOR JAP JOINT WORKSH
   Burger HC, 2013, LECT NOTES COMPUT SC, V8142, P121, DOI 10.1007/978-3-642-40602-7_13
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen ZY, 2014, PROC CVPR IEEE, P3003, DOI 10.1109/CVPR.2014.384
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Dong WS, 2013, IEEE T IMAGE PROCESS, V22, P1618, DOI 10.1109/TIP.2012.2235847
   Fang YM, 2017, IEEE T IMAGE PROCESS, V26, P2016, DOI 10.1109/TIP.2017.2669840
   Fang YM, 2015, IEEE SIGNAL PROC LET, V22, P838, DOI 10.1109/LSP.2014.2372333
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Glorot X., 2010, P INT C ART INT STAT, P249
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P432, DOI 10.1109/TMM.2016.2518868
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   Guo Y, 2017, IEEE INT CONF SOFTW, P1, DOI 10.1109/ICST.2017.8
   He L, 2013, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2013.51
   He LH, 2012, PROC CVPR IEEE, P1146, DOI 10.1109/CVPR.2012.6247795
   Hou WL, 2015, IEEE T NEUR NET LEAR, V26, P1275, DOI 10.1109/TNNLS.2014.2336852
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Huang W, 2018, SIGNAL PROCESS, V142, P104, DOI 10.1016/j.sigpro.2017.07.015
   Huang W, 2016, SIGNAL PROCESS, V124, P233, DOI 10.1016/j.sigpro.2015.08.004
   Ichigaya A, 2008, IEEE T CIRC SYST VID, V18, P817, DOI 10.1109/TCSVT.2008.920658
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Katkovnik V, 2010, INT J COMPUT VISION, V86, P1, DOI 10.1007/s11263-009-0272-7
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   LEGGE GE, 1980, J OPT SOC AM, V70, P1458, DOI 10.1364/JOSA.70.001458
   Li CF, 2011, IEEE T NEURAL NETWOR, V22, P793, DOI 10.1109/TNN.2011.2120620
   Li MD, 2015, IEEE T CIRC SYST VID, V25, P200, DOI 10.1109/TCSVT.2014.2347531
   Li QH, 2016, IEEE T MULTIMEDIA, V18, P2457, DOI 10.1109/TMM.2016.2601028
   Li X, 2002, IEEE IMAGE PROC, P449
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lin ZY, 2017, PUBLIC TRANSPORT, V9, P137, DOI 10.1007/s12469-016-0138-7
   Lin ZJ, 2017, IEEE T CYBERNETICS, V47, P4342, DOI 10.1109/TCYB.2016.2608906
   Liu JY, 2017, IEEE T MULTIMEDIA, V19, P302, DOI 10.1109/TMM.2016.2614427
   Luo GY, 2012, INT J PHOTOENERGY, V2012, DOI 10.1155/2012/275209
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Marquina A, 2008, J SCI COMPUT, V37, P367, DOI 10.1007/s10915-008-9214-8
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Mosseri I, 2013, IEEE INT CONF COMPUT
   Nasrollahi K, 2014, MACH VISION APPL, V25, P1423, DOI 10.1007/s00138-014-0623-4
   Pei SC, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440172
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sun JA, 2010, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.2010.5540206
   Timofte R, 2016, COMPUT VIS IMAGE UND, V142, P1, DOI 10.1016/j.cviu.2015.09.008
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZY, 2015, IEEE T IMAGE PROCESS, V24, P4359, DOI 10.1109/TIP.2015.2462113
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wang Z, 2011, IEEE T IMAGE PROCESS, V20, P1185, DOI 10.1109/TIP.2010.2092435
   Wu QB, 2016, IEEE T CIRC SYST VID, V26, P425, DOI 10.1109/TCSVT.2015.2412773
   Wu QB, 2015, J VIS COMMUN IMAGE R, V32, P205, DOI 10.1016/j.jvcir.2015.08.009
   Wu QC, 2018, IEEE T SYST MAN CY-S, V48, P1005, DOI 10.1109/TSMC.2017.2771227
   Xiong ZW, 2013, IEEE T MULTIMEDIA, V15, P1458, DOI 10.1109/TMM.2013.2264654
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P4850, DOI 10.1109/TIP.2014.2355716
   Yang CY, 2011, LECT NOTES COMPUT SC, V6494, P497, DOI 10.1007/978-3-642-19318-7_39
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2013, IEEE T MULTIMEDIA, V15, P498, DOI 10.1109/TMM.2012.2232646
   Yue HJ, 2013, IEEE T IMAGE PROCESS, V22, P4865, DOI 10.1109/TIP.2013.2279315
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2426416
   Zhang P, 2017, NEUROCOMPUTING, V257, P115, DOI 10.1016/j.neucom.2016.10.073
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhang YQ, 2015, IEEE T IMAGE PROCESS, V24, P2797, DOI 10.1109/TIP.2015.2431435
   Zhu Y, 2014, PROC CVPR IEEE, P2917, DOI 10.1109/CVPR.2014.373
   Zhu ZL, 2014, IEEE T MULTIMEDIA, V16, P2178, DOI 10.1109/TMM.2014.2364976
   Zontak M, 2011, PROC CVPR IEEE, P977, DOI 10.1109/CVPR.2011.5995401
NR 93
TC 42
Z9 47
U1 2
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 22
BP 29829
EP 29846
DI 10.1007/s11042-018-5805-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HC4NQ
UT WOS:000451780800037
DA 2024-07-18
ER

PT J
AU Qian, RD
AF Qian, Runda
TI Inverse transformation based weighted fusion for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Virtual images; Non-linear transformation; Adaptive
   weighted fusion
ID REPRESENTATION; IMAGE
AB Score fusion is a promising approach in face recognition. This paper proposes an algorithm that can integrate original images and virtual images. We obtain face-like virtual images that provide reverse representations of original face images by utilizing a new non-linear transformation. Pixels with high intensities in original images correspond to pixels with low intensities in virtual images and vice versa. The correlation coefficient between the two kinds of data sources is relatively low, which indicates that the reverse face images are complementary to original face images. In this study, a linear model is used for calculating the distances between test samples and training samples, and all the distances are sorted in ascending order; we exploit the difference between the best score and the second-best score to calculate the weight. According to the experimental results, the proposed method outperforms other state-of-the-art methods in recognition accuracy and has a high computational efficiency.
C1 [Qian, Runda] Xidian Univ, Sch Tech Phys & Optoelect Engn, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Qian, RD (corresponding author), Xidian Univ, Sch Tech Phys & Optoelect Engn, Xian 710071, Shaanxi, Peoples R China.
EM qianrunda@163.com
CR Agrawal AK, 2017, MULTIMED TOOLS APPL, V76, P3751, DOI 10.1007/s11042-016-3976-z
   [Anonymous], CIVR
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], M ASS COMP LING
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], INT C IM SIGN PROC
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Choi JY, 2012, IEEE T SYST MAN CY B, V42, P1270, DOI 10.1109/TSMCB.2012.2185693
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Damer N, 2014, 17 INT C INFORM FUSI, P1
   Heo J., 2004, Computer Vision and Pattern Recognition Workshop, page, P122, DOI DOI 10.1109/CVPR.2004.35
   Hong XP, 2014, IEEE T IMAGE PROCESS, V23, P2557, DOI 10.1109/TIP.2014.2316640
   Kim C, 2007, PATTERN RECOGN, V40, P1592, DOI 10.1016/j.patcog.2006.09.010
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mertens T, 2009, COMPUT GRAPH FORUM, V28, P161, DOI 10.1111/j.1467-8659.2008.01171.x
   Nandakumar K, 2008, IEEE T PATTERN ANAL, V30, P342, DOI 10.1109/TPAMI.2007.70796
   Price JR, 2005, PATTERN RECOGN, V38, P209, DOI 10.1016/j.patcog.2004.07.001
   Shao CB, 2017, MULTIMED TOOLS APPL, V76, P6641, DOI 10.1007/s11042-016-3349-7
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Xie L, 2014, MULTIMED TOOLS APPL, V73, P267, DOI 10.1007/s11042-013-1748-6
   Xu Y, 2016, PATTERN RECOGN, V54, P68, DOI 10.1016/j.patcog.2015.12.017
   Xu Y, 2015, PATTERN RECOGN LETT, V68, P9, DOI 10.1016/j.patrec.2015.07.032
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1738, DOI 10.1109/TCYB.2013.2293391
   Xu Y, 2014, NEUROCOMPUTING, V131, P191, DOI 10.1016/j.neucom.2013.10.025
   Xu Y, 2013, PATTERN RECOGN, V46, P1151, DOI 10.1016/j.patcog.2012.11.003
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zhang W, 2012, J VIS COMMUN IMAGE R, V23, P467, DOI 10.1016/j.jvcir.2012.01.006
NR 37
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28441
EP 28456
DI 10.1007/s11042-018-5987-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500029
DA 2024-07-18
ER

PT J
AU Agilandeeswari, L
   Ganesan, K
AF Agilandeeswari, L.
   Ganesan, K.
TI RST invariant robust video watermarking algorithm using quaternion
   curvelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copyright protection; Digital watermarking; Imperceptibility;
   Robustness; Payload; Quaternion curvelet transform; Security; Rotation;
   Translation; Scaling
ID COLOR IMAGE WATERMARKING; WAVELET TRANSFORM; DIGITAL IMAGE; EXPONENT
   MOMENTS; SCHEME; DOMAIN; DECOMPOSITION; SVD; AMPLITUDE; SYSTEM
AB Digital images are widely distributed today over the internet and through other mediums. There are powerful digital image processing tools which have made perfect image duplication a trivial procedure. Therefore, security, copyright protection, and integrity verification of digital video have become an urgent issue in the digital world, which can be achieved by means of a technique called digital watermarking. The issues of watermarking are to achieve imperceptibility, robustness, payload and security simultaneously. This paper presents a new Quaternion Curvelet Transform (QCT) based video watermarking technique for embedding a video on another video in a secure and optimized way. However, many of the existing techniques are unable to handle the problem of rotation, translation and scaling attacks on watermarked video. This study presents a novel embedding approach where in the quaternion transform followed by the traditional Curvelet transform is able to overcome the above disadvantages. In this paper, we first represent the color cover video frames in the quaternion form and subsequently generate Quaternion Curvelet Transform (QCT) coefficients for each such quaternion frames. Second, in order to withstand the desynchronization causes due to the geometrical attacks, the Harris corner detection algorithm is used to determine the invariant feature points on the QCT coefficients, which is followed by the calculation of energy for each block centered on those feature points. Third, in order to maintain the trade-off among the watermarking characteristics, the optimized location for embedding the watermark frames is determined using the cuckoo search optimization algorithm. Finally, to attain the authenticity, an authentication key generation procedure is employed using the owner's biometric image and the watermarked frames. The experimental results prove that the proposed method is promising in terms of robustness, imperceptibility and security to most notable image processing attacks, geometrical attacks, and video processing attacks among the various conventional watermarking algorithms.
C1 [Agilandeeswari, L.] Vellore Inst Technol, SITE, Vellore 632014, Tamil Nadu, India.
   [Ganesan, K.] Vellore Inst Technol, TIFAC CORE Automot Infotron, Vellore 632014, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Vellore; Vellore Institute of
   Technology (VIT); VIT Vellore
RP Agilandeeswari, L (corresponding author), Vellore Inst Technol, SITE, Vellore 632014, Tamil Nadu, India.
EM mail2agi05@gmail.com
RI L, A/GYV-6221-2022; L, Agilandeeswari/P-8997-2016; L, A/HZI-4043-2023
OI L, Agilandeeswari/0000-0001-6147-9535; 
CR Acharya UR, 2001, IEEE T INF TECHNOL B, V5, P320, DOI 10.1109/4233.966107
   Agilandeeswari L., 2016, International Journal of Information Privacy, Security and Integrity, V2, P257
   Agilandeeswari L, 2016, J ENG SCI TECHNOL, V11, P327
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P8745, DOI 10.1007/s11042-015-2789-9
   Agilandeeswari L, 2016, MULTIMED TOOLS APPL, V75, P7211, DOI 10.1007/s11042-015-2642-1
   Agilandeeswari L, 2013, INT J SECUR APPL, V7, P145
   Ali M., 2014, P 3 INT C SOFT COMP, V258, P413, DOI DOI 10.1007/978-81-322-1771-8_36
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2013, Communications in Computer and Information Science (CCIS) Series
   [Anonymous], 2015, INT J SIGNAL PROCESS
   Bhatnagar G, 2012, IET IMAGE PROCESS, V6, P386, DOI 10.1049/iet-ipr.2010.0400
   Bhatnagar G, 2014, EXPERT SYST APPL, V41, P4563, DOI 10.1016/j.eswa.2014.01.023
   Briassouli A, 2004, IEEE T CIRC SYST VID, V14, P1308, DOI 10.1109/TCSVT.2004.836753
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   Chang CC, 2005, PATTERN RECOGN LETT, V26, P1577, DOI 10.1016/j.patrec.2005.01.004
   Chen BJ, 2012, SIGNAL PROCESS, V92, P308, DOI 10.1016/j.sigpro.2011.07.018
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chen CH, 2014, OPTIK, V125, P1134, DOI 10.1016/j.ijleo.2013.07.126
   Cox I. J., 2002, Digital Watermarking
   Delaigle JF, 1998, SIGNAL PROCESS, V66, P319, DOI 10.1016/S0165-1684(98)00013-9
   Faragallah OS, 2013, AEU-INT J ELECTRON C, V67, P189, DOI 10.1016/j.aeue.2012.07.010
   Ganesan K, 2014, EUR PHYS J-SPEC TOP, V223, P1611, DOI 10.1140/epjst/e2014-02123-1
   Guo JM, 2014, J VIS COMMUN IMAGE R, V25, P1149, DOI 10.1016/j.jvcir.2014.03.012
   Guo LQ, 2012, OPT EXPRESS, V20, P18846, DOI 10.1364/OE.20.018846
   Hasnaoui M, 2014, SIGNAL PROCESS-IMAGE, V29, P107, DOI 10.1016/j.image.2013.07.007
   Huang HC, 2009, SOFT COMPUT, V13, P333, DOI 10.1007/s00500-008-0333-9
   Jiwu Huang, 2001, ISCAS 2001. The 2001 IEEE International Symposium on Circuits and Systems (Cat. No.01CH37196), P239, DOI 10.1109/ISCAS.2001.922029
   Kundur D, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P544, DOI 10.1109/ICIP.1997.647970
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Lari MRA, 2014, SIGNAL IMAGE VIDEO P, V8, P687, DOI 10.1007/s11760-013-0586-3
   Lei BY, 2014, NONLINEAR DYNAM, V78, P2897, DOI 10.1007/s11071-014-1634-4
   Leung HY, 2010, INT J WAVELETS MULTI, V8, P941, DOI 10.1142/S0219691310003870
   Liu Y, 2010, SIGNAL PROCESS, V90, P626, DOI 10.1016/j.sigpro.2009.08.001
   Loganathan A, 2016, EXPERT SYST APPL, V63, P412, DOI 10.1016/j.eswa.2016.05.019
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Mathur S, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2696, DOI 10.1109/ICACCI.2016.7732468
   Memon N., 2001, IEEE P, V3, P1019
   Mingzhi C., 2013, J MULTIMED, V8, P299
   Mubeen M, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT (ICDIM), P67, DOI 10.1109/ICDIM.2013.6693979
   Nikolaidis A, 2003, IEEE T IMAGE PROCESS, V12, P563, DOI 10.1109/TIP.2003.810586
   Niu XM, 2000, IEEE T CONSUM ELECTR, V46, P375, DOI 10.1109/30.846673
   Papakostas G. A., 2010, 2010 IEEE International Conference on Imaging Systems and Techniques (IST 2010), P464, DOI 10.1109/IST.2010.5548512
   Peterson G., 1997, ARNOLDS CAT MAP, V45, P1
   Ranjbar S, 2013, SIGNAL PROCESS-IMAGE, V28, P1526, DOI 10.1016/j.image.2013.07.002
   Sangwine SJ, 1996, ELECTRON LETT, V32, P1979, DOI 10.1049/el:19961331
   Singh TR, 2013, AEU-INT J ELECTRON C, V67, P645, DOI 10.1016/j.aeue.2013.01.008
   Storath M, 2011, SIAM J IMAGING SCI, V4, P57, DOI 10.1137/100803924
   Storath M, 2010, IEEE IMAGE PROC, P353, DOI 10.1109/ICIP.2010.5651318
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Tsougenis ED, 2013, OPT LASER TECHNOL, V54, P84, DOI 10.1016/j.optlastec.2013.05.004
   Tsui TK, 2006, MM 06
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang XY, 2013, J SYST SOFTWARE, V86, P255, DOI 10.1016/j.jss.2012.08.015
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Wu XT, 2013, APPL SOFT COMPUT, V13, P1170, DOI 10.1016/j.asoc.2012.09.028
   Xin-She Yang, 2010, International Journal of Mathematical Modelling and Numerical Optimisation, V1, P330, DOI 10.1504/IJMMNO.2010.035430
   Yang HY, 2014, OPTIK, V125, P4456, DOI 10.1016/j.ijleo.2014.02.028
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
NR 61
TC 15
Z9 18
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25431
EP 25474
DI 10.1007/s11042-018-5800-4
PG 44
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400038
DA 2024-07-18
ER

PT J
AU Ashwini, K
   Amutha, R
AF Ashwini, K.
   Amutha, R.
TI Compressive sensing based simultaneous fusion and compression of
   multi-focus images using learned dictionary
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Compression; Dictionary; Fusion; Multi-focus images
ID MEASUREMENT MATRIX; ALGORITHM; TRANSFORM; SCHEME; RECOVERY
AB In this paper, we present a framework of fusion and compression of multi-focus images using learned dictionary. A single dictionary, learned from a set of natural images is used to initially fuse the multi-focus images. Using the same dictionary as the basis matrix, the fused coefficients are compressed using compressive sensing theory. Recovery of the fused image using the compressively sensed measurements is carried out at the receiver end using well known Sl(0) recovery algorithm. Fusion and compression is thus achieved simultaneously using a single learned dictionary. Experiments on multi-focus images show the effectiveness of the proposed method in fusing and compressing the images concurrently. Simulation results also verify that the proposed method outperforms some of the existing compression methods especially at lower sampling rates.
C1 [Ashwini, K.; Amutha, R.] SSN Coll Engn, Dept Elect & Commun, Madras, Tamil Nadu, India.
C3 SSN College of Engineering
RP Ashwini, K (corresponding author), SSN Coll Engn, Dept Elect & Commun, Madras, Tamil Nadu, India.
EM ashwini88.k@gmail.com
RI Amutha, R./AAB-9399-2020
OI Ashwini, K/0000-0003-1974-2162
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen G, 2016, J VIS COMMUN IMAGE R, V38, P407, DOI 10.1016/j.jvcir.2016.03.018
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   George M, 2016, PROC TECH, V25, P52, DOI 10.1016/j.protcy.2016.08.080
   Hassan Shombe N., 2011, International Journal of Biodiversity Science Ecosystem Services & Management, V7, P122, DOI 10.1080/21513732.2011.617710
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   Jagalingam P, 2015, AQUAT PR, V4, P133, DOI 10.1016/j.aqpro.2015.02.019
   Ji XX, 2017, MULTIMED TOOLS APPL, V76, P17633, DOI 10.1007/s11042-015-2879-8
   Liu ET, 2012, IEEE T INFORM THEORY, V58, P2040, DOI 10.1109/TIT.2011.2177632
   Liu XB, 2016, OPT COMMUN, V366, P22, DOI 10.1016/j.optcom.2015.12.024
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu ZD, 2015, OPT COMMUN, V335, P168, DOI 10.1016/j.optcom.2014.07.093
   Mohimani H, 2009, IEEE T SIGNAL PROCES, V57, P289, DOI 10.1109/TSP.2008.2007606
   Patel VM, 2011, 2011 FIRST ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P325, DOI 10.1109/ACPR.2011.6166711
   Phamila AVY, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.0411
   Phamila AV, 2013, OPT APPL, V43, P693, DOI 10.5277/oa130406
   Phamila YAV, 2013, INFORM PROCESS LETT, V113, P672, DOI 10.1016/j.ipl.2013.06.008
   Phamila YAV, 2014, SIGNAL PROCESS, V95, P161, DOI 10.1016/j.sigpro.2013.09.001
   Phamila YAV, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041107
   Shen YF, 2015, NEUROCOMPUTING, V151, P1153, DOI 10.1016/j.neucom.2014.06.082
   Xiao D, 2017, OPT LASER TECHNOL, V91, P212, DOI 10.1016/j.optlastec.2016.12.024
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yao SH, 2017, MULTIMED TOOLS APPL, V76, P17699, DOI 10.1007/s11042-015-2953-2
   Yuan HY, 2015, IET IMAGE PROCESS, V9, P993, DOI 10.1049/iet-ipr.2015.0117
   Zhang J, 2014, SIGNAL PROCESS, V103, P114, DOI 10.1016/j.sigpro.2013.09.025
   Zhang X, 2014, COMM COM INF SC, V484, P89
   Zhang YX, 2014, OPTIK, V125, P5002, DOI 10.1016/j.ijleo.2014.04.002
   Zhao CH, 2015, INFRARED PHYS TECHN, V72, P266, DOI 10.1016/j.infrared.2015.07.026
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 34
TC 9
Z9 9
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25889
EP 25904
DI 10.1007/s11042-018-5824-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400054
DA 2024-07-18
ER

PT J
AU Girdhar, A
   Kumar, V
AF Girdhar, Ashish
   Kumar, Vijay
TI A RGB image encryption technique using Lorenz and Rossler chaotic system
   on DNA sequences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Chaotic systems; DNA cryptography; Lorenz-Rossler
   chaotic system
ID ALGORITHM; PERMUTATION
AB In this paper, a robust color image encryption system using Lorenz-Rossler chaotic map is proposed. The proposed encryption system uses hybrid of two chaotic systems namely Lorenz and Rossler to generate the random sequence. These generated sequences are used for encryption of red, green and blue channels of color image. Rules of DNA cryptosystem are used to encode the plain image in proposed approach. Cross channel operation is proposed to increase randomness in plain image. The proposed encryption approach is tested over different well-known images that are taken from USC-SIPI image dataset. Its performance is compared with recently developed eight image encryption techniques. The experimental results reveal that the proposed approach performs better than the existing techniques in terms of correlation coefficient. The security analyses such as statistical analysis and key sensitivity analysis are performed to validate the security of proposed encryption approach. The key space of proposed approach is large enough to resist against brute force attacks.
C1 [Girdhar, Ashish; Kumar, Vijay] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Girdhar, A (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM ashishgirdhar410@gmail.com
RI Chahar, Vijay Kumar/A-2782-2015
OI Chahar, Vijay Kumar/0000-0002-3460-6989; Girdhar, Dr.
   Ashish/0000-0003-0129-236X
CR Ahmad J., 2012, International Journal of Video and Image Processing and Network Security, V12, P18
   Alsafasfeh, 2011, CIRCUITS SYST, V2, P101, DOI DOI 10.4236/CS.2011.22015
   [Anonymous], 2017, SIPI IMAGE DATABASE
   [Anonymous], 2017, IEEE STAND FLOAT POI
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bashir Zia, 2016, Pacific Science Review A: Natural Science and Engineering, V18, P254, DOI 10.1016/j.psra.2016.11.003
   Cao YY, 2008, International Conference on Intelligent Computation Technology and Automation, Vol 2, Proceedings, P104, DOI 10.1109/ICICTA.2008.397
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Gaborit P, 2005, THEOR COMPUT SCI, V334, P99, DOI 10.1016/j.tcs.2004.11.004
   Gao TG, 2006, INT J MOD PHYS C, V17, P471, DOI 10.1142/S0129183106008625
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Gupta R., 2014, INT J COMPUTER APPL, V85, P27
   Gupta S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P726
   Jolfaei A, 2016, IEEE T INF FOREN SEC, V11, P235, DOI 10.1109/TIFS.2015.2489178
   Kadhim F.A., 2016, 2016 AL SADEQ INT C, P1
   Kong Tao, 2004, Journal of Software, V15, P1558
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Kumar M, 2015, J INF SECUR APPL, V21, P20, DOI 10.1016/j.jisa.2014.11.003
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Liu XD, 2008, INT J COMPUT SCI NET, V8, P64
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Mills AP, 1999, BIOSYSTEMS, V52, P175, DOI 10.1016/S0303-2647(99)00044-1
   Mishra DC, 2014, FRACTALS, V22, DOI 10.1142/S0218348X1450011X
   Murillo-Escobar MA, 2015, SIGNAL PROCESS, V109, P119, DOI 10.1016/j.sigpro.2014.10.033
   Ni ZC, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P156, DOI 10.1109/SIPROCESS.2016.7888243
   Niu Y, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4079793
   Niyat A, 2015, P INT C TECHN C TECH
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Ping P, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION, P429, DOI 10.1109/ICInfA.2015.7279326
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Qi DX, 2000, SCI CHINA SER E, V43, P304, DOI 10.1007/BF02916835
   ROSSLER OE, 1976, PHYS LETT A, V57, P397, DOI 10.1016/0375-9601(76)90101-8
   Sarah M, 2015, ANTIINFLAMMATORY EFF, P1
   Saranya MR, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P1022, DOI 10.1109/IC3I.2014.7019805
   Srivastava N., 2017, INT C WIR COMM SIGN, DOI [10.1109/ICRAIE.2016.7939542, DOI 10.1109/ICRAIE.2016.7939542]
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Xiang T, 2007, CHAOS, V17, DOI 10.1063/1.2728112
   Xu L, 2017, OPT LASER ENG, V91, P41, DOI 10.1016/j.optlaseng.2016.10.012
   Yanling W, 2009, P 1 INT WORKSH ED TE
   Ye GD, 2010, PATTERN RECOGN LETT, V31, P347, DOI 10.1016/j.patrec.2009.11.008
   Zhang Q, 2013, IETE TECH REV, V30, P404, DOI 10.4103/0256-4602.123123
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zou J, 2004, P 2004 INT S, V3
NR 55
TC 56
Z9 57
U1 1
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27017
EP 27039
DI 10.1007/s11042-018-5902-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500035
DA 2024-07-18
ER

PT J
AU Ramezani, M
   Yaghmaee, F
AF Ramezani, Mohsen
   Yaghmaee, Farzin
TI Motion pattern based representation for improving human action retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content Based Video Retrieval; Big data; Human action; STIP; Motion
   pattern
ID RECOGNIZING HUMAN ACTIONS; ACTION RECOGNITION; IMAGE RETRIEVAL;
   RELEVANCE FEEDBACK; VIDEO RETRIEVAL; SEARCH
AB In recent years, many videos have been shared on the Internet. Finding desired videos among the large amount of video files is known as a major challenge in big data. Due to various problems in tag based search methods, content based search has been introduced as an alternative way for finding desired videos. On the other hand, there are many relative videos to humans and human actions are considered as the basis content for searching videos that is called human action retrieval. Action retrieval methods use some features (whether global or local) to represent the actions. Due to the stability of local features against noise, local features are used for representing the human action. In this paper, we represent the human actions by the pattern of body motions. Focusing on patterns can capture more accurate information about the actions. To this end, the complexity of the pattern of the body motions on different scales of coordinate axes is calculated to describe the body motion and the human action. The complexity of motion patterns is calculated by inspiration from the fractal dimension calculation. Our method can discriminate different actions, which have similar movements, more accurate than the state-of-the-art methods. Experimental results on KTH, UCFYT, and HMDB datasets shows the better performance of our method than the state-of-the-art methods.
C1 [Ramezani, Mohsen; Yaghmaee, Farzin] Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
C3 Semnan University
RP Yaghmaee, F (corresponding author), Semnan Univ, Dept Elect & Comp Engn, Semnan, Iran.
EM f_yaghmaee@semnan.ac.ir
RI Ramezani, Mohsen/AAY-7530-2020; Yaghmaee, Farzin/AAZ-6590-2021
OI Ramezani, Mohsen/0000-0002-3801-0517; Yaghmaee,
   Farzin/0000-0001-7430-542X
CR [Anonymous], P 3 INT C INT MULT C
   [Anonymous], 2010, P 5 INT C RECENT ADV
   [Anonymous], 2010, P ACM INT C IM VID R, DOI DOI 10.1145/1816041.1816077
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], HUMAN ACTION ANAL RA
   [Anonymous], 2005, P INT C MUS INF RETR
   Ardizzone E, 1997, MULTIMED TOOLS APPL, V4, P29, DOI 10.1023/A:1009630331620
   Arman E., 1994, Proceedings ACM Multimedia '94, P97, DOI 10.1145/192593.192630
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Belkhatir M, 2012, INFORM PROCESS MANAG, V48, P489, DOI 10.1016/j.ipm.2011.03.003
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Bulbul MF, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P389, DOI 10.1109/BigMM.2015.82
   Chen SL, 2016, MULTIMED TOOLS APPL, V75, P787, DOI 10.1007/s11042-014-2325-3
   Choi J., 2008, ACM ICMR, P291
   Ciptadi A, 2014, LECT NOTES COMPUT SC, V8690, P695, DOI 10.1007/978-3-319-10605-2_45
   COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   Dagan I., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P150
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   DeMenthon D, 2006, MULTIMED TOOLS APPL, V30, P229, DOI 10.1007/s11042-006-0029-z
   Ding SH, 2017, MULTIMED TOOLS APPL, V76, P6521, DOI 10.1007/s11042-016-3307-4
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Duta IC, 2017, MULTIMED TOOLS APPL, V76, P22445, DOI 10.1007/s11042-017-4795-6
   Gkonela C, 2014, MULTIMED TOOLS APPL, V69, P383, DOI 10.1007/s11042-012-1016-1
   Gómez-Conde I, 2015, EXPERT SYST APPL, V42, P5472, DOI 10.1016/j.eswa.2015.03.010
   Grauman K., 2007, ADV NEURAL INFORM PR, V19, P505, DOI DOI 10.7551/MITPRESS/7503.003.0068
   Halvey M, 2010, INFORM PROCESS MANAG, V46, P733, DOI 10.1016/j.ipm.2009.11.007
   Ji RR, 2011, PATTERN RECOGN, V44, P624, DOI 10.1016/j.patcog.2010.08.022
   Jiang XB, 2016, MULTIMED TOOLS APPL, V75, P11019, DOI 10.1007/s11042-015-2829-5
   Jin R, 2010, ADV PATTERN RECOGNIT, P1, DOI 10.1007/978-1-84996-507-1_1
   Jones S, 2014, PROC CVPR IEEE, P820, DOI 10.1109/CVPR.2014.110
   Jones S, 2014, NEUROCOMPUTING, V124, P89, DOI 10.1016/j.neucom.2013.07.031
   Jones S, 2013, INFORM SCIENCES, V236, P56, DOI 10.1016/j.ins.2013.02.018
   Jones S, 2012, PATTERN RECOGN LETT, V33, P446, DOI 10.1016/j.patrec.2011.05.001
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lee YH, 2015, INTELL AUTOM SOFT CO, V21, P39, DOI 10.1080/10798587.2014.914274
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Li ZC, 2015, IEEE T MULTIMEDIA, V17, P1989, DOI 10.1109/TMM.2015.2477035
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Liu L, 2016, NEUROCOMPUTING, V173, P355, DOI 10.1016/j.neucom.2014.12.120
   Luan HB, 2011, INFORM SCIENCES, V181, P4197, DOI 10.1016/j.ins.2011.05.018
   Makantasis K, 2016, MULTIMED TOOLS APPL, V75, P3593, DOI 10.1007/s11042-014-2191-z
   Menier C, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P389
   Natarajan P, 2013, COMPUT VIS IMAGE UND, V117, P1329, DOI 10.1016/j.cviu.2012.08.011
   Ntalianis K, 2016, MULTIMED TOOLS APPL, V75, P15123, DOI 10.1007/s11042-015-2454-3
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Qin J, 2017, COMPUT VIS IMAGE UND, V156, P104, DOI 10.1016/j.cviu.2016.09.009
   Ramezani M, 2016, ARTIF INTELL REV, V46, P485, DOI 10.1007/s10462-016-9473-y
   Ramezani M, 2016, PHYSICA A, V457, P607, DOI 10.1016/j.physa.2016.03.101
   Salton G, 1972, IEEE T PROF COMMUN P, V15, DOI [10. 1109/TPC. 1972. 6591971, DOI 10.1109/TPC.1972.6591971]
   Scherp A, 2014, MULTIMED TOOLS APPL, V70, P7, DOI 10.1007/s11042-013-1427-7
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shao L, 2014, IEEE T CIRC SYST VID, V24, P504, DOI 10.1109/TCSVT.2013.2276700
   Shao L, 2011, IEEE IMAGE PROC, P209, DOI 10.1109/ICIP.2011.6116023
   Smeaton AF, 2006, INFORM PROCESS MANAG, V42, P1330, DOI 10.1016/j.ipm.2005.11.003
   Tang J, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P306, DOI 10.1109/AVSS.2013.6636657
   Tsikrika T, 2012, IEEE MULTIMEDIA, V19, P24, DOI 10.1109/MMUL.2012.17
   Tuan Hue Thi, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P204, DOI 10.1109/AVSS.2010.76
   Veinidis C, 2017, MULTIMED TOOLS APPL, V76, P2059, DOI 10.1007/s11042-015-3137-9
   Wang J, 2016, P IEEE, V104, P34, DOI 10.1109/JPROC.2015.2487976
   Wang ZX, 2009, IEEE IMAGE PROC, P3545, DOI 10.1109/ICIP.2009.5414085
   Wei S.-E., 2014, P 1 ACM INT WORKSH H, P7
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Yu G, 2011, PROC CVPR IEEE, P865, DOI 10.1109/CVPR.2011.5995488
   Zhai XH, 2013, MULTIMEDIA SYST, V19, P395, DOI 10.1007/s00530-012-0297-6
   Zhang LL, 2018, MULTIMED TOOLS APPL, V77, P2057, DOI 10.1007/s11042-017-4353-2
   Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
   Zhu F, 2013, PATTERN RECOGN LETT, V34, P20, DOI 10.1016/j.patrec.2012.04.016
NR 76
TC 8
Z9 8
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 26009
EP 26032
DI 10.1007/s11042-018-5835-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400060
DA 2024-07-18
ER

PT J
AU Singh, D
   Kumar, V
AF Singh, Dilbag
   Kumar, Vijay
TI Dehazing of outdoor images using notch based integral guided filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hazy images; Dark channel prior; Notch coefficient based integral guided
   filter
ID DARK CHANNEL; HAZE; ENHANCEMENT; REMOVAL; FOG
AB The dehazing problem is an ill-posed and can be regularized by designing an efficient filter to refine the coarse estimated atmospheric veil. The most of existing dehazing techniques suffer from over-saturation, halo artifacts, and gradient reversal artifacts problems. In this paper, a dehazing technique is proposed to remove halo and gradient reversal artifacts problem. In this technique, a notch based integral guided filter is proposed. Moreover, the visibility restoration model is also modified to reduce over-saturation problem. The proposed dehazing technique is compared with seven well-known existing dehazing techniques over ten benchmark hazy images. The experimental results demonstrate that proposed technique is able to remove the haze from hazy images as well as significantly improve the image's visibility. It also reveals that the restored image has little or no artifacts.
C1 [Singh, Dilbag; Kumar, Vijay] Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Singh, D (corresponding author), Thapar Inst Engn & Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
EM dggill2@gmail.com; vijaykumarchahar@gmail.com
RI Singh, Dilbag/AAQ-6339-2020; Chahar, Vijay Kumar/A-2782-2015
OI Singh, Dilbag/0000-0001-6475-4491; Chahar, Vijay
   Kumar/0000-0002-3460-6989
CR [Anonymous], 2015, INFRARED LASER ENG
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2016, COSMIN ANCUTI CDV CO
   Anwar MI, 2017, ENG SCI TECHNOL, V20, P1075, DOI 10.1016/j.jestch.2016.11.015
   Bin Xie, 2010, Proceedings 2010 International Conference on Intelligent System Design and Engineering Application (ISDEA 2010), P848, DOI 10.1109/ISDEA.2010.141
   Chang HH, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.023028
   Chaudhury KN, 2011, IEEE T IMAGE PROCESS, V20, P3376, DOI 10.1109/TIP.2011.2159234
   Chen BH, 2016, J DISP TECHNOL, V12, P753, DOI 10.1109/JDT.2016.2518646
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Crebolder JM, 2004, APPL ERGON, V35, P371, DOI 10.1016/j.apergo.2004.02.005
   Cui T, 2017, IET IMAGE PROCESS, V11, P145, DOI 10.1049/iet-ipr.2016.0377
   Ding WL, 2016, IET COMPUT VIS, V10, P852, DOI 10.1049/iet-cvi.2015.0390
   El Khoury J, 2018, MULTIMED TOOLS APPL, V77, P15409, DOI 10.1007/s11042-017-5122-y
   Fan X, 2016, IET COMPUT VIS, V10, P503, DOI 10.1049/iet-cvi.2015.0313
   Fang S, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.3.033014
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu LM, 2016, IET COMPUT VIS, V10, P173, DOI 10.1049/iet-cvi.2014.0411
   Galdran A, 2017, IEEE SIGNAL PROC LET, V24, P151, DOI 10.1109/LSP.2016.2643168
   Gibson KB, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-37
   Gu XD, 2017, IET COMPUT VIS, V11, P220, DOI 10.1049/iet-cvi.2016.0241
   Guo JM, 2017, IEEE T IMAGE PROCESS
   Guo L, 2017, INT J PATTERN RECOGN
   Hao D, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.1.013020
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   Hautiere N., 2007, 2007 IEEE C COMP VIS, P1
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hung-Yu Yang, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P17, DOI 10.1109/IBICA.2011.9
   Jang DW, 2017, IET IMAGE PROCESS, V11, P587, DOI 10.1049/iet-ipr.2017.0192
   Jha DK, 2016, IET COMPUT VIS, V10, P331, DOI 10.1049/iet-cvi.2014.0449
   Jiang B, 2018, MULTIMED TOOLS APPL, V77, P3125, DOI 10.1007/s11042-017-4954-9
   Jiang YT, 2017, IEEE T IMAGE PROCESS, V26, P3397, DOI 10.1109/TIP.2017.2700720
   Kishan H, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.5.053021
   Koschmieder H, 1938, NATURWISSENSCHAFTEN, V26, P521, DOI 10.1007/BF01774261
   Li B, 2014, IET COMPUT VIS, V8, P131, DOI 10.1049/iet-cvi.2013.0011
   Li JF, 2015, NEUROCOMPUTING, V156, P1, DOI 10.1016/j.neucom.2015.01.026
   Li ZG, 2015, IEEE T IMAGE PROCESS, V24, P120, DOI 10.1109/TIP.2014.2371234
   Lian XH, 2018, MULTIMED TOOLS APPL, V77, P15695, DOI 10.1007/s11042-017-5142-7
   Liu W, 2016, IET IMAGE PROCESS, V10, P996, DOI 10.1049/iet-ipr.2016.0308
   Liu X, 2016, IET IMAGE PROCESS, V10, P877, DOI 10.1049/iet-ipr.2016.0138
   Long J, 2014, IEEE GEOSCI REMOTE S, V11, P59, DOI 10.1109/LGRS.2013.2245857
   McCartney E.J., 1976, Optics of the atmosphere: Scattering by molecules and particles, P421
   MODIS, 2016, GLOB LAND COV FAC
   Narasimhan S. G., 2003, Interactive (de) weathering of an image using physical models, V6, P1
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Papari G., 2016, IEEE T IMAGE PROCESS, V26, P251
   Park J, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.4.043024
   Riaz I, 2016, IET COMPUT VIS, V10, P817, DOI 10.1049/iet-cvi.2015.0451
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sheng H, 2017, IEEE T IMAGE PROCESS, V26, P5758, DOI 10.1109/TIP.2017.2745100
   Singh D., 2017, IET COMPUTER VISION
   Singh D, 2018, MULTIMED TOOLS APPL, V77, P9595, DOI 10.1007/s11042-017-5321-6
   Singh D, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.1.013004
   Singh D, 2017, IMAGING SCI J, V65, P282, DOI 10.1080/13682199.2017.1329792
   Singh D, 2017, J MOD OPTIC, V64, P2165, DOI 10.1080/09500340.2017.1344736
   Singh D, 2017, IMAGING SCI J, V65, P108, DOI 10.1080/13682199.2017.1289629
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tripathi AK, 2012, IETE TECH REV, V29, P148, DOI 10.4103/0256-4602.95386
   Wang D, 2015, IET COMPUT VIS, V9, P950, DOI 10.1049/iet-cvi.2015.0063
   Wang JB, 2015, NEUROCOMPUTING, V149, P718, DOI 10.1016/j.neucom.2014.08.005
   Wang LQ, 2015, IET IMAGE PROCESS, V9, P43, DOI 10.1049/iet-ipr.2014.0209
   Wang WC, 2017, IEEE-CAA J AUTOMATIC, V4, P410, DOI 10.1109/JAS.2017.7510532
   Wang WC, 2017, IEEE T MULTIMEDIA, V19, P1142, DOI 10.1109/TMM.2017.2652069
   Wang WC, 2013, IEEE T IMAGE PROCESS, V22, P4237, DOI 10.1109/TIP.2013.2271426
   Wang Z, 2014, COMPUT ELECTR ENG, V40, P785, DOI 10.1016/j.compeleceng.2013.06.009
   Wang ZH, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.023021
   Xiang RX, 2017, J ELECTRON IMAGING, V26, DOI 10.1117/1.JEI.26.3.033027
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Yoon SM, 2016, IMAGING SCI J, V64, P82, DOI 10.1080/13682199.2015.1133010
   Zhang L, 2016, IET IMAGE PROCESS, V10, P840, DOI 10.1049/iet-ipr.2015.0844
   Zhang WB, 2018, MULTIMED TOOLS APPL, V77, P2947, DOI 10.1007/s11042-017-4547-7
   Zheng L, 1740, MOD PHYS LETT B, V31
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu X, 1740, MOD PHYS LETT B, V31
NR 77
TC 35
Z9 36
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27363
EP 27386
DI 10.1007/s11042-018-5924-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500050
DA 2024-07-18
ER

PT J
AU Sun, JD
   Wang, YF
   Li, J
   Wan, WB
   Cheng, D
   Zhang, HX
AF Sun, Jiande
   Wang, Yufei
   Li, Jing
   Wan, Wenbo
   Cheng, De
   Zhang, Huaxiang
TI View-invariant gait recognition based on kinect skeleton feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gait Recognition; Second Generation Kinect; View-Invariant; 3D Joint
   Information; Gait Dataset
ID TRANSFORMATION MODEL; IMAGE; IDENTIFICATION; BIOMETRICS; FRAMEWORK;
   WALKING; ANGLE
AB Gait recognition is a popular remote biometric identification technology. Its robustness against view variation is one of the challenges in the field of gait recognition. In this paper, the second-generation Kinect (2G-Kinect) is used as a tool to build a 3D-skeleton-based gait dataset, which includes both 2D silhouette images captured by 2G-Kinect and their corresponding 3D coordinates of skeleton joints. Given this dataset, a human walking model is constructed. Referring to the walking model, the length of some specific skeletons is selected as the static features, and the angles of swing limbs as the dynamic features, which are verified to be view-invariant. In addition, the gait recognition abilities of the static and dynamic features are investigated respectively. Given the investigation, a view-invariant gait recognition scheme is proposed based on the matching-level-fusion of the static and dynamic features, and the nearest neighbor (NN) method is used for recognition. Comparison between the existing Kinect-based gait recognition method and the proposed one on different datasets show that the proposed one has better recognition performance.
C1 [Sun, Jiande; Li, Jing; Wan, Wenbo; Zhang, Huaxiang] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Sun, Jiande; Wan, Wenbo; Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan, Shandong, Peoples R China.
   [Wang, Yufei] Shandong Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.
   [Li, Jing] Shandong Management Univ, Sch Mech & Elect Engn, Jinan, Shandong, Peoples R China.
   [Cheng, De] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Shaanxi, Peoples R China.
C3 Shandong Normal University; Shandong Normal University; Shandong
   University; Shandong Management University; Xi'an Jiaotong University
RP Sun, JD (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Shandong, Peoples R China.; Sun, JD (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan, Shandong, Peoples R China.
EM jiandesun@hotmail.com
RI Zhang, Yuchen/GYI-8858-2022; 辛, 雨菲/JBS-6390-2023
FU Natural Science Foundation for Distinguished Young Scholars of Shandong
   Province [JQ201718]; National Science Foundation of China [61572298];
   Key Research and Development Foundation of Shandong Province
   [2016GGX101009]
FX This work is supported by Natural Science Foundation for Distinguished
   Young Scholars of Shandong Province (JQ201718), National Science
   Foundation of China (61572298), and Key Research and Development
   Foundation of Shandong Province (2016GGX101009). The contact author is
   Jiande Sun (jiandesun@hotmail.com).
CR Andersson VO, 2015, AAAI CONF ARTIF INTE, P425
   Araujo R.M., 2013, Proceedings of the 28th Annual ACM Symposium on Applied Computing, P21
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Cappelli R, 2010, IEEE T PATTERN ANAL, V32, P2128, DOI 10.1109/TPAMI.2010.52
   Cunado D, 1997, LECT NOTES COMPUT SC, V1206, P95
   Faisal A, 2015, J WSCG, V23, P147
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   GUO Y, 1994, INT C PATT RECOG, P325, DOI 10.1109/ICPR.1994.576929
   Hadid A, 2013, LECT NOTES COMPUT SC, V8157, P1, DOI 10.1007/978-3-642-41184-7_1
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hofmann M, 2014, J VIS COMMUN IMAGE R, V25, P195, DOI 10.1016/j.jvcir.2013.02.006
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Hu MD, 2013, IEEE T INF FOREN SEC, V8, P2034, DOI 10.1109/TIFS.2013.2287605
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Jean F, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P89, DOI 10.1109/CRV.2007.19
   Johnson AY, 2001, LECT NOTES COMPUTER, V2091
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   Kastaniotis D, 2015, PATTERN RECOGN LETT, V68, P327, DOI 10.1016/j.patrec.2015.06.020
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Krzeszowski T, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P232, DOI 10.1109/AVSS.2013.6636645
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Kusakunniran W, 2012, IEEE T CIRC SYST VID, V22, P966, DOI 10.1109/TCSVT.2012.2186744
   Lam THW, 2006, LECT NOTES COMPUT SC, V3832, P612
   Lee S., 2007, Celebrity Fandom and its Relationship to Tourism and Leisure Behaviors: The Case of Korean Wave, Texas AM Repository, P1
   Makihara Y., 2015, Wiley Encyclopedia of Electrical and Electronics Engineering, DOI [10.1002/047134608X.W8261, DOI 10.1002/047134608X.W8261]
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Marcolin F, 2017, MULTIMED TOOLS APPL, V76, P13805, DOI 10.1007/s11042-016-3741-3
   Milovanovic M, 2013, IEEE MULTIMEDIA, V20, P28, DOI 10.1109/MMUL.2013.16
   Muramatsu D, 2016, IEEE T CYBERNETICS, V46, P1602, DOI 10.1109/TCYB.2015.2452577
   Muramatsu D, 2015, IEEE T IMAGE PROCESS, V24, P140, DOI 10.1109/TIP.2014.2371335
   Pala F, 2016, IEEE T CIRC SYST VID, V26, P788, DOI 10.1109/TCSVT.2015.2424056
   Pfister Alexandra, 2014, Journal of Medical Engineering & Technology, V38, P274, DOI 10.3109/03091902.2014.909540
   Preis J., 2012, 1st international workshop on kinect in pervasive computing, P1
   ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shutler J, 2002, APPL SCI SOFT COMPUT, V24, P339
   Sivapalan Sabesan, 2011, 2011 INT JOINT C BIO, P1, DOI [10.1109/IJCB.2011.6117504, 10.1155/2011/375897]
   Stoia DI, 2011, E HLTH BIOENG C EHB, P1
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Tsuji A, 2010, PROC CVPR IEEE, P717, DOI 10.1109/CVPR.2010.5540144
   Wang C, 2010, LECT NOTES COMPUT SC, V6311, P257, DOI 10.1007/978-3-642-15549-9_19
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang YP, 2016, COLD REG SCI TECHNOL, V126, P10, DOI 10.1016/j.coldregions.2016.02.013
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wu ZF, 2017, IEEE T PATTERN ANAL, V39, P209, DOI 10.1109/TPAMI.2016.2545669
   Yamauchi Koichiro, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P45, DOI 10.1109/CVPR.2009.5204296
   Yang K, 2016, J VIS COMMUN IMAGE R, V39, P209, DOI 10.1016/j.jvcir.2016.05.020
   Yang SXM, 2014, J FORENSIC SCI, V59, P494, DOI 10.1111/1556-4029.12322
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
NR 52
TC 51
Z9 52
U1 1
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24909
EP 24935
DI 10.1007/s11042-018-5722-1
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400015
DA 2024-07-18
ER

PT J
AU Thakur, A
   Jindal, N
AF Thakur, Abhishek
   Jindal, Neeru
TI Image forensics using color illumination, block and key point based
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital signal processing (DSP); Image forgery (IF); Discrete wavelet
   transform (DWT); Simple linear iterative clustering (SLIC); Block
   matching threshold (BMT); Feature extraction (FE)
ID FORGERY
AB Every individual is keen to exhibit socialism and connectedness posting their personal photos and videos on several social websites. Thus, it has become literally easy for the onlookers to see and modify their photos and videos. Here the concept enumerates in picture as image forensics, whereby it is possible to examine the authenticity and genuineness of photograph and video into consideration. In addition to this,nowadays photograph and videos are considered as a firm and valid proof in the court room for investigation, validation and judgement. Several experts are continuously working in an image forensic field to discover and develop better techniques for the detection of forgeries in image and videos. Detection of image forgeries is done in two ways. Firstly the forged image we are already familiar with is called active forgery detection technique and secondly, where we don't know the forgery, then is referred to as the passive forgery detection technique. Passive technique is incorporated to detect forgery in this paper where hybridization is used. We have used DWT, color illumination Algorithm, SLIC Algorithm; SIFT Algorithm, Correlation Coefficient Map generation Algorithm, Block Matching Threshold Algorithm and Feature Extraction Algorithm for the detection and ramifying forgeries. The novelty of the proposed hybrid technique is the use of color illumination which detect image edges and trace them correctly to detect forged region. We have tested 48 images from database and find out image forgery detection at image level with Precision=97. 25%; Recall=100% and F1=98. 53%.
C1 [Thakur, Abhishek; Jindal, Neeru] Thapar Univ, ECED, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Jindal, N (corresponding author), Thapar Univ, ECED, Patiala, Punjab, India.
EM abhishek@thapar.edu; neeru.jindal@thapar.edu
RI Thakur, Abhishek/Y-6041-2019
OI -, Abhishek/0000-0002-9955-9693
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], 2011, 2011 18 INT C SYST S
   [Anonymous], IEEE T IMAGE PROCESS
   Ansari MD, 2014, IETE Journal of Education, V55, P40, DOI DOI 10.1080/09747338.2014.921415
   Anuja Dixit J, 2016, INT J SIGNAL PROCESS, V9, P71, DOI [10.14257/ijsip.2016.9.3.07, DOI 10.14257/IJSIP.2016.9.3.07]
   Bashar M, 2010, IEEE Trans Image Process, DOI 10.1109/TIP.2010.2046599
   Bayram S, 2009, ACOUSTICS SPEECH SIG, DOI [10. 1109/ICASSP. 2009. 4959768, DOI 10.1109/ICASSP.2009.4959768]
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Carvalho T, 2016, IEEE T INF FOREN SEC, V11, P720, DOI 10.1109/TIFS.2015.2506548
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   Dhania VS, 2016, ENG TECHNOL, V5, P14723
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Hassaballah M, 2016, STUD COMPUT INTELL, V630, P11, DOI 10.1007/978-3-319-28854-3_2
   Hieu Cuong Nguyen, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P134, DOI 10.1109/IIH-MSP.2012.38
   Li G., 2007, IEEE INT C MULT EXP, DOI DOI 10.1109/ICME.2007.4285009
   Luo WQ, 2006, INT C PATT RECOG, P746
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Muhammad G, 2011, P 17 INT C DIG SIGN, DOI [10. 1109/ICDSP. 2011. 6004974, DOI 10.1109/ICDSP.2011.6004974]
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Sekeh MA, 2013, DIGIT INVEST, V10, P73, DOI 10.1016/j.diin.2013.02.007
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Upase SG., 2016, INT J COMPUTER APPL, V148, P37
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wang Jun-Wen, 2009, Acta Automatica Sinica, V35, P1488, DOI 10.3724/SP.J.1004.2009.01488
   Wang JW, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P25, DOI 10.1109/MINES.2009.142
   [王衍学 Wang Yanxue], 2012, [振动与冲击, Journal of Vibration and Shock], V31, P9
   XiaoBing Kang, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P926, DOI 10.1109/CSSE.2008.876
   Xu Bo, 2010, Proceedings 2010 Second International Conference on Multimedia Information Networking and Security (MINES 2010), P889, DOI 10.1109/MINES.2010.189
NR 34
TC 7
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 26033
EP 26053
DI 10.1007/s11042-018-5836-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400061
DA 2024-07-18
ER

PT J
AU Kaur, R
   Juneja, M
   Mandal, AK
AF Kaur, Ravinder
   Juneja, Mamta
   Mandal, A. K.
TI A comprehensive review of denoising techniques for abdominal CT images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Computed tomography; Noise; Gaussian; Poisson; Filters; Medical; Images
ID LOW-DOSE CT; NOISE-REDUCTION; WAVELET TRANSFORM; PROJECTION DATA;
   MEDICAL IMAGES; NONLOCAL MEANS; REMOVAL; CLASSIFICATION; SEGMENTATION;
   STATISTICS
AB Computed Tomography (CT) is one of the effective imaging modality in medical sciences that assist in diagnosing various pathologies inside the human body. Despite considerable advancement in acquisition speed, signal to noise ratio and image resolution of computed tomography imaging technology, CT images are still affected by noise and artifacts. A tradeoff between the amount of noise reduced and conservation of genuine image details has to be made in such a way that it enhances the clinically relevant image content. Therefore, noise reduction in medical images is an important and challenging task, as it helps to improve the performance of other image processing procedures such as segmentation or classification to perform better diagnosis by clinicians. Different techniques have been suggested in the literature on denoising of CT images, and each technique has its own presumptions, benefits, and drawbacks. To the best of our knowledge, no survey paper was found in the literature that compares the performance of various denoising techniques for CT images. This study aims to compare the capabilities of several notable and contemporary denoising techniques in the presence of different types of noise present in abdominal CT images. This comparative analysis helps to determine the most suitable denoising technique for practitioners and researchers that can be used in real life scenarios. Furthermore, the advantages and disadvantages of considered denoising methods have also been discussed along with some recommendations for further research in this area.
C1 [Kaur, Ravinder] Panjab Univ, Comp Sci & Engn, Univ Inst Engn & Technol, Chandigarh, India.
   [Juneja, Mamta] Panjab Univ, Univ Inst Engn & Technol, Dept CSE, Chandigarh, India.
   [Mandal, A. K.] PGIMER, Dept Urol, Chandigarh, India.
C3 Panjab University; Panjab University; Post Graduate Institute of Medical
   Education & Research (PGIMER), Chandigarh
RP Kaur, R (corresponding author), Panjab Univ, Comp Sci & Engn, Univ Inst Engn & Technol, Chandigarh, India.
EM ravinder.kaur7@yahoo.com; mamtajuneja@pu.ac.in; drarupkumar@gmail.com
RI Kaur, Ravinder/AEN-2893-2022
OI Kaur, Ravinder/0000-0002-8535-6617; Juneja, Mamta/0000-0002-2611-9005
FU University Grant Commission (UGC), New Delhi, India
FX This research work has been financially supported by University Grant
   Commission (UGC), New Delhi, India. Additionally, the authors would like
   to thank PGIMER Chandigarh for providing the image data set for carrying
   out this research.
CR ADMIRE, 2017, ADV MOD IT REC
   Al Asadi AHH, 2015, INT J IMAGE PROCES I, V9, P22
   Ali SA, 2010, EUROPEAN J SCI RES, V48, P315
   Andria G, 2013, MEASUREMENT, V46, P57, DOI 10.1016/j.measurement.2012.05.016
   Attivissimo F, 2010, IEEE T INSTRUM MEAS, V59, P1251, DOI 10.1109/TIM.2010.2040932
   Baek J, 2011, MED PHYS, V38, P2122, DOI 10.1118/1.3556590
   Bhadauria H. S., 2011, 2011 Proceedings of International Conference on Emerging Trends in Electrical and Computer Technology (ICETECT 2011), P666, DOI 10.1109/ICETECT.2011.5760201
   Bian ZY, 2013, COMPUT MED IMAG GRAP, V37, P293, DOI 10.1016/j.compmedimag.2013.05.004
   Borsdorf A, 2008, IEEE T MED IMAGING, V27, P1685, DOI 10.1109/TMI.2008.923983
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Campadelli P., 2009, ELECT LETT COMPUTER, V8, P1
   Candes E., 2005, FAST DISCRETE CURVEL
   Chen F, 2015, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2015.76
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deng J, 2011, COMMUNICATION SYSTEM, P681
   Dinh Hoan Trinh, 2012, Journal of Electronic Science and Technology, V10, P124, DOI 10.3969/j.issn.1674-862X.2012.02.006
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Elbakri LA, 2003, P SOC PHOTO-OPT INS, V5032, P1839, DOI 10.1117/12.480302
   Glisson CL, 2011, MED PHYS, V38, P6265, DOI 10.1118/1.3653220
   Goldman LW, 2007, J NUCL MED TECHNOL, V35, P115, DOI 10.2967/jnmt.107.042978
   Gravel P, 2004, IEEE T MED IMAGING, V23, P1221, DOI 10.1109/TMI.2004.832656
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Hsieh J., 2003, Computed Tomography: Principles, Design, Artifacts, and Recent Advances, DOI DOI 10.1117/3.2197756
   Huang J, 2011, I S BIOMED IMAGING, P1167, DOI 10.1109/ISBI.2011.5872609
   Jiang JL, 2014, IEEE T IMAGE PROCESS, V23, P2651, DOI 10.1109/TIP.2014.2317985
   Kaur R, 2016, INDIAN J SCI TECHNOL, V9
   Kaur R, 2018, ADV INTELL SYST, V518, P47, DOI 10.1007/978-981-10-3373-5_4
   Kingsbury N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P375, DOI 10.1109/ICIP.2000.899397
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lin DT, 2006, IEEE T INF TECHNOL B, V10, P59, DOI 10.1109/TITB.2005.855561
   Linguraru MG, 2011, MED PHYS, V38, P5738, DOI 10.1118/1.3633898
   Liu B, 2016, COMPUT METH PROG BIO, V127, P318, DOI 10.1016/j.cmpb.2015.12.012
   Lu HB, 2002, PROC SPIE, V4682, P146, DOI 10.1117/12.465552
   Ma JH, 2011, MED PHYS, V38, P5713, DOI 10.1118/1.3638125
   Manduca A, 2009, MED PHYS, V36, P4911, DOI 10.1118/1.3232004
   Matrecano M, 2010, 10 IEEE INT C INF TE, P1
   Muller P., 2012, INT J METROL QUAL EN, V3, P107, DOI [10.1051/ijmqe/2012011, DOI 10.1051/IJMQE/2012011]
   Nayak DR, 2016, NEUROCOMPUTING, V177, P188, DOI 10.1016/j.neucom.2015.11.034
   Neumann J, 2005, INT J WAVELETS MULTI, V3, P43, DOI 10.1142/S0219691305000749
   Oulhaj H, 2012, INT CONF MULTIMED, P344, DOI 10.1109/ICMCS.2012.6320218
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qiu D., 2016, RADIOL OPEN J, V1, P42, DOI [10.17140/ROJ-1-108, DOI 10.17140/ROJ-1-108]
   Rabbani H, 2009, IEEE T BIO-MED ENG, V56, P2826, DOI 10.1109/TBME.2009.2028876
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Rust GF, 2002, P SOC PHOTO-OPT INS, V4683, P186, DOI 10.1117/12.463582
   Sanches JM, 2008, IEEE T IMAGE PROCESS, V17, P1522, DOI 10.1109/TIP.2008.2001398
   Selesnick I.W., 2001, WAVELETS SIGNAL IMAG
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Thakur N, 2017, CURR MED IMAGING REV, V13, P99, DOI 10.2174/1573405612666160606124044
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tsagaan B, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1059, DOI 10.1109/ICIP.2001.958309
   Vitulano S, 1997, PATTERN RECOGN LETT, V18, P1125, DOI 10.1016/S0167-8655(97)00097-4
   Wang J, 2005, PROC SPIE, V5747, P2058, DOI 10.1117/12.595662
   Wang J, 2008, PHYS MED BIOL, V53, P3327, DOI 10.1088/0031-9155/53/12/018
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WEAVER JB, 1991, MAGNET RESON MED, V21, P288, DOI 10.1002/mrm.1910210213
   Wong WCK, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P820
   Wong WCK, 2004, INT CONGR SER, V1268, P171, DOI 10.1016/j.ics.2004.03.143
   Xie Y, 2016, IEEE T IMAGE PROCESS, V25, P4842, DOI 10.1109/TIP.2016.2599290
   Xu J, 2015, IEEE I CONF COMP VIS, P244, DOI 10.1109/ICCV.2015.36
   Zhang L., 2009, 3rd International Conference on Bioinformatics and Biomedical Engineering ICBBE 2009, P1
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang Y, 2008, J X-RAY SCI TECHNOL, V16, P143
   Zhong JM, 2004, IEEE T MED IMAGING, V23, P696, DOI 10.1109/TMI.2004.826944
   Zhu F, 2012, PHYS MED BIOL, V57, pN183, DOI 10.1088/0031-9155/57/12/N183
   Zuo WM, 2014, IEEE T IMAGE PROCESS, V23, P2459, DOI 10.1109/TIP.2014.2316423
NR 69
TC 31
Z9 32
U1 1
U2 55
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22735
EP 22770
DI 10.1007/s11042-017-5500-5
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500052
DA 2024-07-18
ER

PT J
AU Li, R
   Pan, ZB
   Wang, Y
AF Li, Rui
   Pan, Zhibin
   Wang, Yang
TI A general codebook design method for vector quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vector quantization; General codebook (GCB); Private codebook (PCB);
   Common codebook (CCB); Bit rate (BR)
ID ALGORITHM; SCHEME; IMAGE; OPTIMIZATION
AB Vector quantization (VQ) is widely used in image processing applications, the primary focus of VQ is to determine a codebook to represent the original image well. In order to make a codebook perform better on both distortion and bit rate (BR), a general codebook (GCB) for VQ is proposed in this paper. Unlike common codebook (CCB) or private codebook (PCB), GCB is a new structure of codebook where the codewords can either come from CCB or by training the input image. By applying the codewords in CCB that perform well and updating inactive codewords, only the new generated codewords and flags of codewords to be replaced are transmitted along with index table (IT). Therefore,the BR can be significantly reduced while the performance of distortion can be efficiently improved. The experimental results demonstrate that our proposed GCB has a better performance than CCB and various kinds of PCB-based methods.
C1 [Li, Rui; Pan, Zhibin; Wang, Yang] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, 28 Xianning West Rd, Xian 710049, Shaanxi, Peoples R China.
EM pofazhelirui@126.com; zbpan@mail.xjtu.edu.cn; wty2977892@126.com
RI Pan, Zhibin/I-8212-2012
FU Open Project Program of the State Key Lab of Novel Software Technology,
   Nanjing University [KFKT2016B14]; Priority Academic Program Development
   of Jiangsu Higher Education Institutions (PAPD); Open Research Fund of
   Key Laboratory of Spectral Imaging Technology, Chinese Academy of
   Sciences [LSIT201606D]; Industrial Program of Zhejiang Province
   [2016C31G4180003]
FX This work is supported in part by the Open Project Program of the State
   Key Lab of Novel Software Technology (Grant No. KFKT2016B14), Nanjing
   University, the Priority Academic Program Development of Jiangsu Higher
   Education Institutions (PAPD), the Open Research Fund of Key Laboratory
   of Spectral Imaging Technology, Chinese Academy of Sciences (Grant No.
   LSIT201606D) and the Industrial Program of Zhejiang Province (Grant No.
   2016C31G4180003).
CR Ayoobkhan MUA, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0184-3
   Chang CC, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P660, DOI 10.1109/FSKD.2007.513
   Chang CC, 2006, IEEE T CIRC SYST VID, V16, P1301, DOI 10.1109/TCSVT.2006.882380
   Chen L, 2014, INT J ELECTRON, V101, P1205, DOI 10.1080/00207217.2013.828188
   Chen Q, 2010, PROC SPIE, V7546, DOI 10.1117/12.855647
   Chuang JC, 2011, J VIS COMMUN IMAGE R, V22, P440, DOI 10.1016/j.jvcir.2011.03.011
   Dao SD, 2017, EXPERT SYST APPL, V90, P196, DOI 10.1016/j.eswa.2017.08.018
   Ding C., 2004, P 21 INT C MACH LEAR, P29, DOI DOI 10.1145/1015330.1015408
   Eswaran C, 2016, INT C COMP SCI TECHN
   Feng HM, 2007, EXPERT SYST APPL, V32, P213, DOI 10.1016/j.eswa.2005.11.012
   Fränti P, 2000, PATTERN RECOGN LETT, V21, P61, DOI 10.1016/S0167-8655(99)00133-6
   Hammer B, 2014, NEUROCOMPUTING, V131, P43, DOI 10.1016/j.neucom.2013.05.054
   Hu KC, 2015, IEEE ICCE, P92, DOI 10.1109/ICCE-TW.2015.7217048
   Hu YC, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.7.073110
   Jolliffe I.T., 1986, PRINCIPAL COMPONENT, P199, DOI DOI 10.1007/978-1-4757-1904-8_11
   Lakshmi M, 2016, APPL SOFT COMPUT, V46, P1030, DOI 10.1016/j.asoc.2015.12.025
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu J, 2005, SOFT COMPUT, V9, P448, DOI 10.1007/s00500-004-0363-x
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu T.C., 2010, J. Inf. Hiding Multim. Signal Process., V1, P190
   Ma TH, 2016, NEUROCOMPUTING, V207, P488, DOI 10.1016/j.neucom.2016.05.020
   Ma XX, 2015, IET IMAGE PROCESS, V9, P290, DOI 10.1049/iet-ipr.2014.0125
   PAN JS, 1995, ELECTRON LETT, V31, P1418, DOI 10.1049/el:19951031
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Park H, 2017, IEICE T INF SYST, VE100D, P1934, DOI 10.1587/transinf.2017EDL8029
   Peng ZR, 2017, COMPUT METH PROG BIO, V145, P157, DOI 10.1016/j.cmpb.2017.04.015
   Song J, 2017, IEEE T COMMUN, V65, P1859, DOI 10.1109/TCOMM.2017.2665497
   Tsai JT, 2015, INT J ELECTRON, V102, P1
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Vesanto J., 1999, Intelligent Data Analysis, V3, P111, DOI 10.1016/S1088-467X(99)00013-X
   Wang Z, 2012, COMPUT INF SCI, V5, P112
   Watanabe K, 2015, NEUROCOMPUTING, V165, P32, DOI 10.1016/j.neucom.2015.01.081
   Zheng WM, 2006, INT J INNOV COMPUT I, V2, P1317
   Zhou ZL, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717694172
NR 36
TC 0
Z9 0
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23803
EP 23823
DI 10.1007/s11042-018-5700-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900032
DA 2024-07-18
ER

PT J
AU Abbas, Q
   Ibrahim, MEA
   Jaffar, MA
AF Abbas, Qaisar
   Ibrahim, Mostafa E. A.
   Jaffar, M. Arfan
TI Video scene analysis: an overview and challenges on deep learning
   algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Computer vision; Video processing; Activity
   classification; Scene interpretation; Video description; Video
   captioning
ID EMOTION RECOGNITION; NEURAL-NETWORKS; MODEL; MULTIPLE
AB Video scene analysis is a recent research topic due to its vital importance in many applications such as real-time vehicle activity tracking, pedestrian detection, surveillance, and robotics. Despite its popularity, the video scene analysis is still an open challenging task and require more accurate algorithms. However, the advances in deep learning algorithms for video scene analysis have been emerged in last few years for solving the problem of real-time processing. In this paper, a review of the recent developments in deep learning and video scene analysis problems is presented. In addition, this paper also briefly describes the most recent used datasets along with their limitations. Moreover, this review provides a detailed overview of the particular challenges existed in real-time video scene analysis that has been contributed towards activity recognition, scene interpretation, and video description/captioning. Finally, the paper summarizes the future trends and challenges in video scene analysis tasks and our insights are provided to inspire further research efforts.
C1 [Abbas, Qaisar; Ibrahim, Mostafa E. A.; Jaffar, M. Arfan] Al Imam Muhamad Ibn Saud Islamic Univ, Dept Comp Sci, Riyadh, Saudi Arabia.
   [Ibrahim, Mostafa E. A.] Benha Univ, Benha Fac Engn, Banha, Egypt.
C3 Imam Mohammad Ibn Saud Islamic University (IMSIU); Egyptian Knowledge
   Bank (EKB); Benha University
RP Abbas, Q (corresponding author), Al Imam Muhamad Ibn Saud Islamic Univ, Dept Comp Sci, Riyadh, Saudi Arabia.
EM qaisarabbasphd@gmail.com
RI Muhammad Abas, Qaisar Abbas/GPX-7906-2022; Ibrahim,
   Mostafa/HNQ-0489-2023; El-Sayed, Mostafa/K-4309-2019; Jaffar,
   Arfan/GQB-2768-2022; Muhammad Abas, Qaisar Abbas/ABI-6501-2020
OI Muhammad Abas, Qaisar Abbas/0000-0002-0361-1363; Ibrahim,
   Mostafa/0000-0003-0730-6857; Muhammad Abas, Qaisar
   Abbas/0000-0002-0361-1363
CR Abdulnabi AH, 2015, IEEE T MULTIMEDIA, V17, P1949, DOI 10.1109/TMM.2015.2477680
   Acar E, 2017, MULTIMED TOOLS APPL, V76, P11809, DOI 10.1007/s11042-016-3618-5
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2015, CORR
   Baccouche M, 2012, INT C PATT RECOG, P3823
   Ballan L, 2012, IEEE T MULTIMEDIA, V14, P1234, DOI 10.1109/TMM.2012.2191268
   Ballas Nicolas, 2016, INT C LEARN REPR
   Barros P, 2015, NEURAL NETWORKS, V72, P140, DOI 10.1016/j.neunet.2015.09.009
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Chan CS, 2016, LECT NOTES COMPUT SC, V9908, P505, DOI 10.1007/978-3-319-46493-0_31
   Charalampous K, 2016, PATTERN ANAL APPL, V19, P337, DOI 10.1007/s10044-014-0404-8
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Ciresan D., 2012, NIPS, P2843
   Couprie C, 2013, INT C LEARN REPR ICL, P8
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Etezadifar P, 2017, MULTIMED TOOLS APPL, V76, P7947, DOI 10.1007/s11042-016-3433-z
   Evans KK, 2011, WIRES COGN SCI, V2, P503, DOI 10.1002/wcs.127
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Farrajota M, 2016, LECT NOTES COMPUT SC, V9738, P370, DOI 10.1007/978-3-319-40244-4_36
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gao X, 2017, AUTON ROBOT, V41, P1, DOI 10.1007/s10514-015-9516-2
   Gilani SO, 2016, 2016 IEEE 14TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 14TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 2ND INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/DATACOM/CYBERSC, P530, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2016.102
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guadarrama S, 2013, IEEE I CONF COMP VIS, P2712, DOI 10.1109/ICCV.2013.337
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hasan M, 2015, IEEE T MULTIMEDIA, V17, P1909, DOI 10.1109/TMM.2015.2477242
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hinton GE, 2007, TRENDS COGN SCI, V11, P428, DOI 10.1016/j.tics.2007.09.004
   Ho CT, 2016, LECT NOTES COMPUT SC, V9947, P3, DOI 10.1007/978-3-319-46687-3_1
   Hong CQ, 2015, IEEE T IMAGE PROCESS, V24, P5659, DOI 10.1109/TIP.2015.2487860
   Huang SY, 2016, IEEE T IMAGE PROCESS, V25, P5892, DOI 10.1109/TIP.2016.2613686
   Husain F, 2016, IEEE ROBOT AUTOM LET, V1, P984, DOI 10.1109/LRA.2016.2529686
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang Y., 2011, P ACM INT C MULT RET
   Jiu MY, 2014, PATTERN RECOGN LETT, V50, P122, DOI 10.1016/j.patrec.2013.09.021
   Kaya H, 2016, J MULTIMODAL USER IN, V10, P139, DOI 10.1007/s12193-015-0175-6
   Kingma D. P., 2014, arXiv
   Kong Y, 2016, ACTION RECOGNITION H, P23, DOI [10.1007/978-3-319-27004-32, DOI 10.1007/978-3-319-27004-32]
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee JT, 2016, LECT NOTES COMPUT SC, V9555, P299, DOI 10.1007/978-3-319-30285-0_24
   Lee K, 2013, ROBOT AUTON SYST, V61, P1323, DOI 10.1016/j.robot.2013.08.003
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Li SZ, 2015, NEUROCOMPUTING, V151, P565, DOI 10.1016/j.neucom.2014.06.086
   Li SJ, 2015, IEEE I CONF COMP VIS, P2848, DOI 10.1109/ICCV.2015.326
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Lin L, 2016, INT J COMPUT VISION, V118, P256, DOI 10.1007/s11263-015-0876-z
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin Zhihui, 2016, P 22 INT C MULT MOD, P256, DOI DOI 10.1007/978-3-319-27674-823
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2016, J MULTIMODAL USER IN, V10, P113, DOI 10.1007/s12193-015-0204-5
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu Y, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P43, DOI 10.1145/2671188.2749300
   Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Mathieu Michael, 2016, ICLR, DOI DOI 10.48550/ARXIV.1511.05440
   Mnih V, 2014, ADV NEUR IN, V27
   Mocanu DC, 2015, PATTERN RECOGN LETT, V66, P100, DOI 10.1016/j.patrec.2015.01.013
   Neumann B, 2008, IMAGE VISION COMPUT, V26, P82, DOI 10.1016/j.imavis.2007.08.013
   Ouyang WL, 2016, INT J COMPUT VISION, V120, P14, DOI 10.1007/s11263-016-0890-9
   Pan YW, 2016, PROC CVPR IEEE, P4594, DOI 10.1109/CVPR.2016.497
   Pei LS, 2016, VISUAL COMPUT, V32, P1395, DOI 10.1007/s00371-015-1090-2
   Pei LS, 2016, SIGNAL IMAGE VIDEO P, V10, P199, DOI 10.1007/s11760-014-0726-4
   Perez M, 2017, NEUROCOMPUTING, V230, P279, DOI 10.1016/j.neucom.2016.12.017
   Pigou L, 2018, INT J COMPUT VISION, V126, P430, DOI 10.1007/s11263-016-0957-7
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Revathi AR, 2017, SIGNAL IMAGE VIDEO P, V11, P291, DOI 10.1007/s11760-016-0935-0
   Rohrbach A, 2015, LECT NOTES COMPUT SC, V9358, P209, DOI 10.1007/978-3-319-24947-6_17
   Ronao CA, 2016, EXPERT SYST APPL, V59, P235, DOI 10.1016/j.eswa.2016.04.032
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Sarkar S, 2017, J SIGNAL PROCESS SYS, V88, P205, DOI 10.1007/s11265-016-1209-3
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shen JL, 2016, MULTIMEDIA SYST, V22, P99, DOI 10.1007/s00530-014-0399-4
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Singh S, 2015, PROC CVPR IEEE, P3422, DOI 10.1109/CVPR.2015.7298964
   Soomro K., 2014, COMPUTER VISION SPOR, V71, P181, DOI [DOI 10.1007/978-3-319-09396-3_9, DOI 10.1007/978-3-319-09396-39]
   Sun B, 2016, COMM COM INF SC, V663, P621, DOI 10.1007/978-981-10-3005-5_51
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tomè D, 2016, SIGNAL PROCESS-IMAGE, V47, P482, DOI 10.1016/j.image.2016.05.007
   Trumble M, 2016, LECT NOTES COMPUT SC, V9915, P871, DOI 10.1007/978-3-319-49409-8_70
   Varior RR, 2016, IEEE T IMAGE PROCESS, V25, P3395, DOI 10.1109/TIP.2016.2531280
   Venugopalan S., 2015, P ANN C N AM CHAPT A, P1494, DOI 10.3115/v1/N15-1173
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vincent Pascal, 2008, P 25 INT C MACHINE L, DOI DOI 10.1145/1390156.1390294
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang DL, 2007, STUD COMPUT INTELL, V63, P163
   Wu CP, 2016, 14TH ACM/IEEE SYMPOSIUM ON EMBEDDED SYSTEMS FOR REAL-TIME MULTIMEDIA (ESTIMEDIA 2016), P2, DOI 10.1145/2993452.2994306
   Wu GS, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3076
   Xia DX, 2017, MULTIMEDIA SYST, V23, P515, DOI 10.1007/s00530-016-0518-5
   Xu D, 2017, COMPUT VIS IMAGE UND, V156, P117, DOI 10.1016/j.cviu.2016.10.010
   Xu WR, 2015, LECT NOTES COMPUT SC, V8925, P786, DOI 10.1007/978-3-319-16178-5_55
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang WS, 2016, IEEE T IND INFORM, V12, P2166, DOI 10.1109/TII.2016.2560802
   Zhang XS, 2016, IEEE T IMAGE PROCESS, V25, P1033, DOI 10.1109/TIP.2015.2511585
   Zhang YQ, 2015, NEUROCOMPUTING, V168, P454, DOI 10.1016/j.neucom.2015.05.082
   Zhao F, 2016, INT J COMPUT VISION, V119, P329, DOI 10.1007/s11263-016-0896-3
   Zhou BL, 2015, INT J COMPUT VISION, V111, P50, DOI 10.1007/s11263-014-0735-3
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
   Zhu XT, 2016, INT J COMPUT VISION, V117, P247, DOI 10.1007/s11263-015-0864-3
   Zhu YK, 2015, IEEE I CONF COMP VIS, P19, DOI 10.1109/ICCV.2015.11
   Zúñiga MD, 2013, NEUROCOMPUTING, V100, P3, DOI 10.1016/j.neucom.2012.02.038
NR 113
TC 33
Z9 33
U1 1
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 20415
EP 20453
DI 10.1007/s11042-017-5438-7
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300006
DA 2024-07-18
ER

PT J
AU Chen, CC
   Yeh, HC
AF Chen, Chien-Chang
   Yeh, Hsin-Cheng
TI Using dynamic pixel value mapping method to construct visible and
   reversible image watermarking scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermark; Visible watermark; Difference expansion; Dynamic
   pixel value mapping
ID DIFFERENCE-EXPANSION
AB A reversible and visible image watermarking scheme extracts a visibly embedded binary watermark image and recovers the original cover image. This paper presents a reversible and visible image watermarking scheme that embeds visible watermarks into a part of the cover image, called the embedded region R, and embeds required binary strings into the whole image through the conventional difference-expansion method. The size of the embedded visible watermark is determined by the coefficient k; a large k value leads to a large embedded region for the visible watermark. The embedded region R is first segmented to non-overlapped kxk blocks, and each block is related to one bit of the watermark image. For those blocks that are related to the logo bits of the watermark image, these kxk blocks are adjusted by the proposed dynamic pixel value mapping method for highly visual detection. The binary bit string S, composed of the binary watermark image and LSB bits of the logo watermark bits' corresponding kxk blocks, is embedded into the cover image using the conventional difference-expansion method. Experimental results show that the watermark is clearly embedded into the embedded region R and that the distortion of the reversible embedding is limited.
C1 [Chen, Chien-Chang; Yeh, Hsin-Cheng] Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
C3 Tamkang University
RP Chen, CC (corresponding author), Tamkang Univ, Dept Comp Sci & Informat Engn, 151 Yingzhuan Rd, New Taipei 25137, Taiwan.
EM ccchen34@mail.tku.edu.tw
RI Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   Bhowmik D, 2016, IEEE ACCESS, V4, P8002, DOI 10.1109/ACCESS.2016.2627241
   Chen CC, 2017, MULTIMED TOOLS APPL, V76, P8497, DOI 10.1007/s11042-016-3452-9
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Jawad K, 2013, J SYST SOFTWARE, V86, P2742, DOI 10.1016/j.jss.2013.06.023
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Lin CC, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P8, DOI 10.1109/CISP.2008.64
   Lin PY, 2013, IMAGE VISION COMPUT, V31, P311, DOI 10.1016/j.imavis.2013.02.002
   Liu ML, 2012, SIGNAL PROCESS, V92, P819, DOI 10.1016/j.sigpro.2011.09.028
   Liu TY, 2010, IEEE T IMAGE PROCESS, V19, P1224, DOI 10.1109/TIP.2010.2040757
   Lu TC, 2008, IMAGE VISION COMPUT, V26, P632, DOI 10.1016/j.imavis.2007.07.011
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Wu HZ, 2017, IEEE T CIRC SYST VID, V27, P1620, DOI 10.1109/TCSVT.2016.2556585
   Wu HC, 2009, J SYST SOFTWARE, V82, P1966, DOI 10.1016/j.jss.2009.06.056
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
   Zhang WM, 2016, IEEE T MULTIMEDIA, V18, P1469, DOI 10.1109/TMM.2016.2569497
NR 27
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19327
EP 19346
DI 10.1007/s11042-017-5370-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500020
DA 2024-07-18
ER

PT J
AU Chen, ZY
   Liu, S
   Zhai, YL
   Lin, J
   Cao, XC
   Yang, L
AF Chen, Zhiyong
   Liu, Si
   Zhai, Yanlong
   Lin, Jia
   Cao, Xiaochun
   Yang, Liang
TI Human parsing by weak structural label
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human parsing; Deep learning
AB Human parsing, which decomposes a human centric image into several semantic labels, e.g., face, skin etc, is an active topic in recent years. Traditional human parsing methods are always conducted on a supervised setting, i.e., the pixel-wise labels are available during the training process, which require tedious human labeling efforts. In this paper, we propose a weakly supervised deep parsing method to alleviate the human from the time-consuming labeling. More specifically, we resort to train a robust human parser with the structural image-level labels, e.g., "red jeans" etc. The structural label contains an attribute, e.g., "red", as well as a class label, e.g., "jeans". Our framework is based on the Fully Convolution Network (FCN) (Pathak et al. 2014) with two critical differences. First, the loss function defined on the pixel by FCN (Pathak et al. 2014) is modified to the image-level loss by aggregating the pixel-wise prediction of the whole image into a multiple instance learning manner. Besides, we develop a novel logistic pooling layer to constrain that the pixels responding to the color and corresponding category labels are the same to interpret the structural label. Extensive experiments in the publicly available dataset (Liu et al. IEEE Trans Multimedia 16(1):253-265, 2014) show the effectiveness of the proposed method.
C1 [Chen, Zhiyong] Lanzhou Univ, Sch Informat Sci & Engn, 222 TianShui South Rd, Lanzhou, Gansu, Peoples R China.
   [Liu, Si; Cao, Xiaochun] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, 89 Minzhuang Rd, Beijing, Peoples R China.
   [Zhai, Yanlong] Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing, Peoples R China.
   [Lin, Jia] JD Com, North Star Century Ctr, 10 Floor, Beijing, Peoples R China.
   [Yang, Liang] Tianjin Univ Commerce, Sch Informat Engn, 409 Guangrong Rd, Tianjin, Peoples R China.
C3 Lanzhou University; Chinese Academy of Sciences; Beijing Institute of
   Technology; Tianjin University of Commerce
RP Zhai, YL (corresponding author), Beijing Inst Technol, Sch Comp Sci & Technol, 5 Zhongguancun South St, Beijing, Peoples R China.
EM changingivan@gmail.com; liusi@iie.ac.cn; ylzhai@bit.edu.cn;
   linjia1@jd.com; caoxiaochun@iie.ac.cn; yangliang@vip.qq.com
FU National Natural Science Foundation of China [61572493, 61503281,
   U1536203, 61602037]
FX This work was supported by National Natural Science Foundation of China
   (No. 61572493, No. 61503281, Grant U1536203, Grant 61602037).
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], ARXIV161109587
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, P ACM INT C MULT
   [Anonymous], 2015, ARXIV150100901
   [Anonymous], ARXIV170208319
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748
   Liu S, 2015, IEEE T MULTIMEDIA, V17, P1347, DOI 10.1109/TMM.2015.2443559
   Liu S, 2014, IEEE T MULTIMEDIA, V16, P253, DOI 10.1109/TMM.2013.2285526
   Luo P, 2013, IEEE I CONF COMP VIS, P2648, DOI 10.1109/ICCV.2013.329
   Papandreou G, 2015, IEEE I CONF COMP VIS, P1742, DOI 10.1109/ICCV.2015.203
   Pathak D., 2014, arXiv
   Pathak D, 2015, IEEE I CONF COMP VIS, P1796, DOI 10.1109/ICCV.2015.209
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Van De Weijer J, 2007, IEEE C COMPUTER VISI, P1
   Wang C, 2016, MULTIMED TOOLS APPL, V75, P9255, DOI 10.1007/s11042-016-3380-8
   Wang H, 2016, MULTIMED TOOLS APPL, V75, P9277, DOI 10.1007/s11042-015-3141-0
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang W, 2014, PROC CVPR IEEE, P3182, DOI 10.1109/CVPR.2014.407
   Zhang HW, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P325, DOI 10.1145/2911451.2911502
   Zhou B., 2014, CORR, V1412, P6856
   Zhou BL, 2014, ADV NEUR IN, V27
NR 38
TC 2
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 15
BP 19795
EP 19809
DI 10.1007/s11042-017-5368-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP2YI
UT WOS:000440703500041
DA 2024-07-18
ER

PT J
AU Lal, KN
   Kumar, A
AF Lal, Kumari Nidhi
   Kumar, Anoj
TI A Centrality-measures based Caching Scheme for Content-centric
   Networking (CCN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-centric network; Routing; Centrality; Caching; Content delivery
AB Content-centric networking (CCN) is gradually becoming an alternative approach to the conventional Internet architecture through the distribution of enlightening information (named as content) on the Internet. It is evaluated that the better performance can be achieved by caching is done on a subset of content routers instead of all the routers in the content delivery path. The subset of a content router must be selected in a manner such that maximum cache performance can be achieved. Motivated by this, we propose a Centrality-measures based algorithm (CMBA) for selection of an appropriate content router for caching of the contents. The Centrality-measures are based on the question: "Who are the most important or central content router in the network for the caching of contents?". We found that our novel CMBA could improve content cache performance along the content delivery path by using only a subset of available content routers. Our results recommend that our proposed work consistently achieves better caching gain across the multiple network topologies.
C1 [Lal, Kumari Nidhi; Kumar, Anoj] Motilal Nehru Natl Inst Technol, Dept Comp Sci & Engn, Allahabad 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Lal, KN (corresponding author), Motilal Nehru Natl Inst Technol, Dept Comp Sci & Engn, Allahabad 211004, Uttar Pradesh, India.
EM nidhi.2592@gmail.com; anojk@mnnit.ac.in
RI Lal, Nidhi/AFK-7639-2022
OI Lal, Nidhi/0000-0001-6935-3005
CR Aljawarneh SA, 2017, FUTURE GENER COMP SY, V74, P430, DOI 10.1016/j.future.2017.01.013
   [Anonymous], 2016, 7927 RFC
   [Anonymous], 2015, 7476 RFC
   [Anonymous], 2011, P FUTURE NETW MO JUN
   Chai WK, 2011, IEEE COMMUN MAG, V49, P112, DOI 10.1109/MCOM.2011.5723808
   Chanda A., 2013, IEEE C COMP COMM WOR
   Che H, 2002, IEEE J SEL AREA COMM, V20, P1305, DOI 10.1109/JSAC.2002.801752
   Cho K, 2012, 2012 IEEE C COMP COM
   Chu WB, 2016, COMPUT COMMUN, V76, P54, DOI 10.1016/j.comcom.2015.09.009
   Chuanhua He, 2016, International Journal of Wireless and Mobile Computing, V10, P130
   Ghodsi A., 2011, ACM HOTNETS, DOI DOI 10.1145/2070562.2070563
   Ioannou A, 2016, IEEE COMMUN SURV TUT, V18, P2847, DOI 10.1109/COMST.2016.2565541
   Jokela P, 2009, ACM SIGCOMM COMP COM, V39, P195, DOI 10.1145/1594977.1592592
   Koponen T, 2007, ACM SIGCOMM COMP COM, V37, P181, DOI 10.1145/1282427.1282402
   Lal KN, 2016, PROCEDIA COMPUT SCI, V89, P73, DOI 10.1016/j.procs.2016.06.011
   Laoutaris N, 2006, PERFORM EVALUATION, V63, P609, DOI 10.1016/j.peva.2005.05.003
   Li YH, 2015, IEEE T NETW SERV MAN, V12, P420, DOI 10.1109/TNSM.2015.2458271
   Majeed M. F., 2017, COMPUTER NETWORKS
   Mangili M, 2016, COMPUT NETW, V94, P80, DOI 10.1016/j.comnet.2015.11.019
   Michel S, 1998, COMPUT NETWORKS ISDN, V30, P2169, DOI 10.1016/S0169-7552(98)00246-3
   Nirmala P, 2016, KNOWL INF SYST, V46, P213, DOI 10.1007/s10115-015-0844-5
   Plass M.F., 2009, P 5 INT C EMERGING N, P1, DOI [10.1145/1658939.1658941, DOI 10.1145/1658939.1658941]
   Psaras I., 2012, P 2 ED ICN WORKSH IN, P55, DOI DOI 10.1145/2342488.2342501
   Radhakrishna V, 2016, ARXIV160405272
   Rak J, 2017, OPT SWITCH NETW, V23, P156, DOI 10.1016/j.osn.2016.06.002
   Wang, 2012, IEEE INFOCOM NOMEN W
   Xylomenos G, 2014, IEEE COMMUN SURV TUT, V16, P1024, DOI 10.1109/SURV.2013.070813.00063
   Yamamoto M, 2016, IEICE T COMMUN, VE99B, P961, DOI 10.1587/transcom.2015AMI0001
   Yaqub M. A., 2016, CONTENT CENTRIC NETW, P19
NR 29
TC 19
Z9 19
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17625
EP 17642
DI 10.1007/s11042-017-5183-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900006
DA 2024-07-18
ER

PT J
AU Karimi, M
   Samavi, S
   Karimi, N
   Soroushmehr, SMR
   Lin, WS
   Najarian, K
AF Karimi, Maryam
   Samavi, Shadrokh
   Karimi, Nader
   Soroushmehr, S. M. Reza
   Lin, Weisi
   Najarian, Kayvan
TI Pyramidal modeling of geometric distortions for retargeted image quality
   evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; Image retargeting; pyramidal pooling; salient
   region deformation
AB Content-aware retargeting methods are used to adjust images to different resolutions and aspect ratios with low deformation and information loss in salient regions. Effective objective quality assessment of retargeted images can provide a way to improve retargeting methods. The non-uniform geometrical degradations caused by retargeting algorithms make it impossible to use traditional image quality assessment metrics for retargeted images. Although some quality evaluation methods have been proposed till now, the resulted quality scores are not well correlated with the subjective ones. In this paper we propose a pyramidal global-to-local pooling method to combine pixel/block deformation measures. In each level of locality, the Euclidean distance between the retargeted and original image is used as an individual feature. Therefore, in addition to the global summation, assessment of local deformations, contributes toward better quality evaluation. Learning a regression model based on the extracted features results in better performance compared to relevant existing retargeted image quality methods.
C1 [Karimi, Maryam; Samavi, Shadrokh; Karimi, Nader] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan 8415683111, Iran.
   [Samavi, Shadrokh; Soroushmehr, S. M. Reza; Najarian, Kayvan] Univ Michigan, Michigan Ctr Integrat Res Crit Care, Ann Arbor, MI 48109 USA.
   [Soroushmehr, S. M. Reza; Najarian, Kayvan] Univ Michigan, Dept Emergency Med, Ann Arbor, MI 48109 USA.
   [Lin, Weisi] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Najarian, Kayvan] Univ Michigan, Dept Computat Med & Bioinformat, Ann Arbor, MI 48109 USA.
C3 Isfahan University of Technology; University of Michigan System;
   University of Michigan; University of Michigan System; University of
   Michigan; Nanyang Technological University; University of Michigan
   System; University of Michigan
RP Soroushmehr, SMR (corresponding author), Univ Michigan, Michigan Ctr Integrat Res Crit Care, Ann Arbor, MI 48109 USA.; Soroushmehr, SMR (corresponding author), Univ Michigan, Dept Emergency Med, Ann Arbor, MI 48109 USA.
EM ssoroush@umich.edu
RI karimi, maryam/AAZ-9303-2021; Karimi, Nader/HWP-4206-2023; Lin,
   Weisi/A-3696-2011; Lin, Weisi/A-8011-2012
OI Karimi, Nader/0000-0001-8904-1607; Lin, Weisi/0000-0001-9866-1947;
   karimi, maryam/0000-0002-7597-0680; Soroushmehr,
   S.M.Reza/0000-0001-8417-9260
CR [Anonymous], 2008, 2008 IEEE C COMPUTER
   [Anonymous], RETARGET ME BENCHMAR
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   [Anonymous], IEEE T VIS COMPUT GR
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Dong WM, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618471
   Fang YM, 2014, IEEE J EM SEL TOP C, V4, P95, DOI 10.1109/JETCAS.2014.2298919
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Guo YW, 2009, IEEE T MULTIMEDIA, V11, P856, DOI 10.1109/TMM.2009.2021781
   Han JG, 2011, IEEE MULTIMEDIA, V18, P72, DOI 10.1109/MMUL.2010.24
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Karimi M, 2017, J VIS COMMUN IMAGE R, V43, P108, DOI 10.1016/j.jvcir.2016.12.011
   Karni Z, 2009, COMPUT GRAPH FORUM, V28, P1257, DOI 10.1111/j.1467-8659.2009.01503.x
   Kopf S, 2011, MULTIMED TOOLS APPL, V51, P819, DOI 10.1007/s11042-010-0717-6
   Kopf Stephan, 2011, 2011 IEEE WORKSH APP, P9, DOI [10.1109/WACV.2011.5711477, DOI 10.1109/WACV.2011.5711477]
   Krähenbühl P, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1616452.1618472, 10.1145/1618452.1618472]
   Lin Jin, 2015, ScientificWorldJournal, V2015, P657086, DOI 10.1155/2015/657086
   Liu AM, 2015, SIGNAL PROCESS-IMAGE, V39, P444, DOI 10.1016/j.image.2015.08.001
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Liu YJ, 2011, COMPUT GRAPH FORUM, V30, P583, DOI 10.1111/j.1467-8659.2011.01881.x
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mantiuk R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964935
   Pele O, 2009, IEEE I CONF COMP VIS, P460, DOI 10.1109/ICCV.2009.5459199
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Ren TW, 2010, IEEE IMAGE PROC, P1569, DOI 10.1109/ICIP.2010.5653559
   Ren TW, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1397, DOI 10.1109/ICME.2008.4607705
   Rubinstein M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531329
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Rychetsky M., 2001, Algorithms and architectures for machine learning based on regularized neural networks and support vector approaches
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Wang J, 2012, 4 INT C INT MULT COM, P140
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Ya M.L., 2014, 2014 S DESIGN TEST I, P1
   Zhang JY, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P257, DOI 10.1145/2647868.2654922
   Zhang YB, 2016, IEEE T IMAGE PROCESS, V25, P4286, DOI 10.1109/TIP.2016.2585884
   Zhongyan Qiu, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P428, DOI 10.1109/ICIG.2013.92
NR 38
TC 5
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13799
EP 13820
DI 10.1007/s11042-017-4994-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900033
DA 2024-07-18
ER

PT J
AU Lakrissi, Y
   Saaidi, A
   Essahlaoui, A
AF Lakrissi, Youssra
   Saaidi, Abderrahim
   Essahlaoui, Abdelouahed
TI Novel dynamic color image watermarking based on DWT-SVD and the human
   visual system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic watermarking; Dwt; SVD; JND; Robustness; Imperceptibility; False
   positive error
ID WAVELET-BASED WATERMARKING; DIGITAL WATERMARKING; DIFFERENTIAL
   EVOLUTION; ROBUST; SCHEME; ALGORITHM; DOMAIN; SEGMENTATION
AB In this paper, a novel dynamic color image watermarking based on discrete wavelet transform (DWT) and singular value decomposition (SVD) is proposed. The watermark is embedded in different random block in every execution. This random movement minimizes more the risk of detecting the watermark and makes it difficult to find and to destroy. The encrypted binary watermark is embedded by modifying the singular values of a dynamic block generated randomly using a pseudo random generator from the sub-band LL after applying the DWT on the original image. This method respects the Human visual system (HVS) since the scaling factor used is adaptive to the image features in order to achieve the tradeoff between robustness and visual quality of the watermarked image. It is a semi-blind scheme because some of the original data are used for extraction. The experimental results show a good visual quality for the watermarked images and high robustness against several attacks avoiding at the same time the false positive error known by most of the SVD schemes and ensuring more security the authors.
C1 [Lakrissi, Youssra; Saaidi, Abderrahim; Essahlaoui, Abdelouahed] Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac, Engn Sci Lab, LSI, BP 1223, Taza, Morocco.
   [Saaidi, Abderrahim] Fac Sci Dhar Mhraz, Dept Math & Comp Sci, LIIAN, BP 1796, Atlas Fez, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez
RP Lakrissi, Y (corresponding author), Sidi Mohamed Ben Abdellah Univ, Polydisciplinary Fac, Engn Sci Lab, LSI, BP 1223, Taza, Morocco.
EM lakrissi.youssra@gmail.com; abderrahim.saaidi@usmba.ac.ma;
   abdelouahed.essahlaoui@usmba.ac.ma
RI Saaidi, Abderrahim/R-1916-2019
OI Saaidi, Abderrahim/0000-0003-1708-0468
CR Acharya R, 2004, COMPUT METH PROG BIO, V76, P13, DOI 10.1016/j.cmpb.2004.02.009
   Agreste S, 2007, J COMPUT APPL MATH, V210, P13, DOI 10.1016/j.cam.2006.10.087
   Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   [Anonymous], 2014, MULTIMEDIA TOOLS APP
   [Anonymous], STAT TABLES BIOL AGR
   [Anonymous], ODIFICATON ALGORITHM
   [Anonymous], 2010, J ARID ENV, DOI DOI 10.1109/CCNC.2010
   [Anonymous], TEXT AND MONOGRAPHS
   [Anonymous], MED DATA PRIVACY HDB
   [Anonymous], INT J RES ENG TECHNO
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Baker Kirk., 2013, Singular Value Decomposition Tutorial Contents
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Bhatnagar G, 2009, COMPUT STAND INTER, V31, P1002, DOI 10.1016/j.csi.2008.09.031
   Chen C. C., 2016, MULTIMED TOOLS APPL, P1
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Feng Liu, 2011, 2011 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA), P206, DOI 10.1109/ICMTMA.2011.57
   Ford A., 1998, Color space conversions
   Gan JY, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P197
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Gupta AK, 2012, SADHANA-ACAD P ENG S, V37, P425, DOI 10.1007/s12046-012-0089-x
   Hongqin Shi, 2014, Journal of Software, V9, P1749, DOI 10.4304/jsw.9.7.1749-1756
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P26723, DOI 10.1007/s11042-016-4202-8
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Khalili M, 2013, IET SIGNAL PROCESS, V7, P177, DOI 10.1049/iet-spr.2012.0380
   Kumari GRN, 2014, ADV INTELL SYST, V248, P59, DOI 10.1007/978-3-319-03107-1_7
   Lang J, 2014, OPT LASER ENG, V53, P112, DOI 10.1016/j.optlaseng.2013.08.021
   Li CL, 2016, COMPUT ELECTR ENG, V54, P484, DOI 10.1016/j.compeleceng.2016.01.026
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li Q, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1947, DOI 10.1109/ICACT.2007.358752
   Lou DC, 2012, OPT COMMUN, V285, P2510, DOI 10.1016/j.optcom.2012.01.021
   Loukhaoukha K., 2011, J Inf Hiding Multim Signal Process, V2, P303
   Lusson F, 2013, SIGNAL PROCESS, V93, P1268, DOI 10.1016/j.sigpro.2012.10.018
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Mishra A, 2014, EXPERT SYST APPL, V41, P7858, DOI 10.1016/j.eswa.2014.06.011
   Munib S, 2017, MULTIMED TOOLS APPL, V76, P8695, DOI 10.1007/s11042-016-3485-0
   Naderahmadian Y, 2014, MULTIMED TOOLS APPL, V72, P2597, DOI 10.1007/s11042-013-1559-9
   Pakdaman Z, 2017, MULTIMED TOOLS APPL, V76, P8517, DOI 10.1007/s11042-016-3490-3
   Roy A, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P537, DOI 10.1109/SPIN.2015.7095399
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh RK, 2015, PROCEDIA COMPUT SCI, V54, P612, DOI 10.1016/j.procs.2015.06.071
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, OPTIK, V124, P3254, DOI 10.1016/j.ijleo.2012.10.005
   Su QT, 2012, OPT COMMUN, V285, P1792, DOI 10.1016/j.optcom.2011.12.065
   Subramanyam AV, 2011, LECT NOTES COMPUT SC, V6730, P37, DOI 10.1007/978-3-642-24556-5_3
   Sun GM, 2007, C IND ELECT APPL, P1823
   Tirkel A.Z., 1993, ELECT WATERMARK, P666
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2625, DOI 10.1016/S0167-8655(03)00106-5
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Vahedi E, 2007, ICIAS 2007: INTERNATIONAL CONFERENCE ON INTELLIGENT & ADVANCED SYSTEMS, VOLS 1-3, PROCEEDINGS, P641
   Vahedi E, 2012, DIGIT SIGNAL PROCESS, V22, P153, DOI 10.1016/j.dsp.2011.08.006
   Verma AK, 2012, COMM COM INF SC, V292, P187
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Xin Zhou, 2011, 2011 6th International Forum on Strategic Technology (IFOST 2011), P1118, DOI 10.1109/IFOST.2011.6021216
   Yadav N, 2015, SIGNAL IMAGE VIDEO P, V9, P1531, DOI 10.1007/s11760-013-0607-2
   Yang CT, 2015, P INT COMP SOFTW APP, P68, DOI 10.1109/COMPSAC.2015.194
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 64
TC 14
Z9 15
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13531
EP 13555
DI 10.1007/s11042-017-4974-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900021
DA 2024-07-18
ER

PT J
AU Pan, ZB
   Ku, WP
   Wang, YD
AF Pan, Zhibin
   Ku, Weiping
   Wang, Yidi
TI Dynamic initial search pattern defined on Cartesian product of
   neighboring motion vectors for fast block-based motion estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Block matching algorithm; Cartesian product; Video
   coding; Initial search pattern
ID EFFICIENT MOTION; ESTIMATION ALGORITHM; SELECTION
AB Block-based motion estimation is widely used in video compression for reducing the temporal data redundancy. However, it is still a main problem to effectively reduce the computational complexity of motion estimation. The median predictor is usually used for initial search center prediction, however it is not always accurate enough, especially for fast motion sequences. In this paper, a novel dynamic initial search pattern algorithm for fast block-based motion estimation is proposed. Based on the observation that the components of the current motion vector are very similar to the corresponding components of its neighboring motion vectors, Cartesian product of neighboring motion vectors is introduced to generate the proposed dynamic initial search pattern (DISP). And then the cross search pattern is employed to search for the best matching block. The number of search points of the proposed DISP is adaptive to the neighboring correlation of the current block. In fact, the proposed DISP can be considered as a generalization of median prediction scheme and it performs better in capturing the best matching block than median prediction. Experiment results show that the proposed DISP method with small cross search pattern can save about 1.71 search points on average compared with adaptive rood pattern search (ARPS) algorithm and can achieve the similar PSNR to full search (FS) algorithm by combining large cross search pattern.
C1 [Pan, Zhibin; Ku, Weiping; Wang, Yidi] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.
   [Pan, Zhibin] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
C3 Xi'an Jiaotong University; Nanjing University
RP Pan, ZB (corresponding author), Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Shaanxi, Peoples R China.; Pan, ZB (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Jiangsu, Peoples R China.
EM zbpan@mail.xjtu.edu.cn
RI Pan, Zhibin/I-8212-2012
FU Open Project Program of the State Key Lab of Novel Software Technology
   [KFKT2016B14]; Nanjing University; Priority Academic Program Development
   of Jiangsu Higher Education Institutions (PAPD); Key Science and
   Technology Program of Shaanxi Province [2016GY-097]; Industrial Program
   of Zhejiang Province [2016C31G4180003]
FX This work is supported in part by the Open Project Program of the State
   Key Lab of Novel Software Technology (Grant No. KFKT2016B14), Nanjing
   University, the Priority Academic Program Development of Jiangsu Higher
   Education Institutions (PAPD), the Key Science and Technology Program of
   Shaanxi Province (Grant No. 2016GY-097) and the Industrial Program of
   Zhejiang Province (Grant No. 2016C31G4180003).
CR Ahn TG, 2004, IEEE T CIRC SYST VID, V14, P1265, DOI 10.1109/TCSVT.2004.835146
   Amirpour H, 2016, SIVIP, V10, P1
   Chen ZX, 2011, J VIS COMMUN IMAGE R, V22, P727, DOI 10.1016/j.jvcir.2011.05.004
   Gao XQ, 2000, IEEE T IMAGE PROCESS, V9, P501, DOI 10.1109/83.826786
   Ismail Y, 2012, IEEE T CIRC SYST VID, V22, P28, DOI 10.1109/TCSVT.2011.2148450
   Jakubowski M, 2013, OPTO-ELECTRON REV, V21, P86, DOI 10.2478/s11772-013-0071-0
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   Kerfa D, 2016, MULTIMED TOOLS APPL, V75, P3161, DOI 10.1007/s11042-014-2428-x
   Ko YH, 2011, IEEE T CONSUM ELECTR, V57, P726, DOI 10.1109/TCE.2011.5955214
   Kuo CM, 2009, IEEE T CIRC SYST VID, V19, P893, DOI 10.1109/TCSVT.2009.2017420
   Liu MX, 2016, IEEE T PATTERN ANAL, V38, P2335, DOI 10.1109/TPAMI.2015.2430325
   Luo J, 2015, MULTIMED TOOLS APPL, V74, P11821, DOI 10.1007/s11042-014-2280-z
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   Nisar H, 2009, PATTERN RECOGN, V42, P475, DOI 10.1016/j.patcog.2008.08.010
   Pan ZQ, 2016, J VIS COMMUN IMAGE R, V40, P516, DOI 10.1016/j.jvcir.2016.07.018
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Paramkusam AV, 2014, ELECTRON LETT, V50, P276, DOI 10.1049/el.2013.4032
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Soroushmehr SMR, 2014, MULTIMED TOOLS APPL, V71, P1615, DOI 10.1007/s11042-012-1298-3
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu C, 2004, IEEE T CIRC SYST VID, V14, P1210, DOI 10.1109/TCSVT.2004.833166
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
   Zou BJ, 2010, IEEE T CIRC SYST VID, V20, P156, DOI 10.1109/TCSVT.2009.2031461
NR 26
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 14803
EP 14816
DI 10.1007/s11042-017-5063-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200015
DA 2024-07-18
ER

PT J
AU Song, R
   Li, YS
   Jia, Y
   Wang, YL
   Rao, P
AF Song, Rui
   Li, Yunsong
   Jia, Yuan
   Wang, Yangli
   Rao, Peng
TI Efficient, robust and divisible paired comparison for subjective quality
   assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Subjective quality assessment; Paired comparison; Efficient; Robust;
   Divisible; Image quality assessment; Video quality assessment; Database
ID DATABASE
AB The scale of a database is important for machine learning based image and video quality assessment. Nevertheless, it is greatly limited by the subjective test method. Among the various methods, Paired Comparison(PC) is acknowledged as the most reliable one. However, the test duration grows with square of the number of samples. To solve the dilemma, we propose an improved paired comparison method in this paper. Three types of priori are incorporated to cut down the test duration, including the long-term priori as experience results condensed in existing quality metric, the short-term priori as the subjective scores calculated by the predecessor in ongoing session, and the dynamic priori as the previous decision made by the current assessor. Based on these priori knowledge, only indispensable part of decision is needed to be made by the assessor. Equivalent performance could be achieved in one-tenth of the time used in full paired comparison method. While it is robust to mis-click and divisible to expand the database to a large scale.
C1 [Song, Rui; Li, Yunsong; Jia, Yuan; Wang, Yangli] Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.
   [Song, Rui; Rao, Peng] Chinese Acad Sci, Shanghai Inst Tech Phys, Key Lab Infrared Syst Detect & Imaging Technol, Shanghai 200083, Peoples R China.
C3 Xidian University; Chinese Academy of Sciences; Shanghai Institute of
   Technical Physics, CAS
RP Song, R (corresponding author), Xidian Univ, State Key Lab ISN, Xian 710071, Shaanxi, Peoples R China.; Song, R (corresponding author), Chinese Acad Sci, Shanghai Inst Tech Phys, Key Lab Infrared Syst Detect & Imaging Technol, Shanghai 200083, Peoples R China.
EM rsong@xidian.edu.cn
RI chen, bin/KBQ-8114-2024
OI chen, bin/0000-0002-3398-1314
FU NSFC [61401337, 61222101]; Programme of Introducing Talents of
   Discipline to Universities (111 Project) [B08038]; Innovation ability
   support plan of Shaanxi Province [606160967047]; Key Laboratory of
   Infrared System Detection and Imaging Technology, Shanghai Institute of
   Technical Physics, Chinese Academy of Sciences
FX This work was supported by NSFC Grant No. 61401337, 61222101, the
   Programme of Introducing Talents of Discipline to Universities (111
   Project), Grant No. B08038, Innovation ability support plan of Shaanxi
   Province, No. 606160967047, and Key Laboratory of Infrared System
   Detection and Imaging Technology, Shanghai Institute of Technical
   Physics, Chinese Academy of Sciences.
CR [Anonymous], BT2021 ITUR
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Daniel Wayne W., 1990, Applied Nonparametric Statistics, V2nd, P358
   DYKSTRA O, 1960, BIOMETRICS, V16, P176, DOI 10.2307/2527550
   Glickman ME, 2005, J STAT PLAN INFER, V127, P279, DOI 10.1016/j.jspi.2003.09.022
   Huynh-Thu Q, 2005, Seventh IASTED International Conference on Signal and Image Processing, P70
   ITU, 2002, BT50011 ITU
   ITU, 1996, P910 ITUT
   ITU-R, 2012, GEN VIEW COND SUBJ A
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Lee JS, 2013, MULTIMED TOOLS APPL, V67, P31, DOI 10.1007/s11042-012-1011-6
   Lee JS, 2011, IEEE T MULTIMEDIA, V13, P882, DOI 10.1109/TMM.2011.2157333
   Li JY, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON ENERGY, P1
   Li J, 2012, IEEE IMAGE PROC, P629, DOI 10.1109/ICIP.2012.6466938
   Lin JY, 2015, J VIS COMMUN IMAGE R, V30, P1, DOI 10.1016/j.jvcir.2015.02.012
   Liu TJ, 2013, IEEE T IMAGE PROCESS, V22, P1793, DOI 10.1109/TIP.2012.2236343
   Ninassi A, 2006, PROC SPIE, V6057, DOI 10.1117/12.650780
   Pinson MH, 2015, IEEE SIGNAL PROC MAG, V32, P101, DOI 10.1109/MSP.2013.2292535
   Pinson MH, 2012, IEEE J-STSP, V6, P640, DOI 10.1109/JSTSP.2012.2215306
   Ponomarenko N., 2008, 2008 IEEE 10th Workshop on Multimedia Signal Processing (MMSP), P403, DOI 10.1109/MMSP.2008.4665112
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2013, LECT NOTES COMPUT SC, V8192, P402, DOI 10.1007/978-3-319-02895-8_36
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Silverstein DA, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P242
   Silverstein DA, 2001, J ELECTRON IMAGING, V10, P394, DOI 10.1117/1.1344187
   Song R, 2015, J INF SCI ENG, V31, P1593
   Xu Q, 2012, IEEE T MULTIMEDIA, V14, P844, DOI 10.1109/TMM.2012.2190924
   Xu Qianqian., 2011, ACM INT C MULTIMEDIA, P393
NR 31
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13597
EP 13613
DI 10.1007/s11042-017-4977-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900024
DA 2024-07-18
ER

PT J
AU Chen, JX
   Wang, GW
   Hu, X
   Shen, JY
AF Chen, Jianxin
   Wang, Guanwen
   Hu, Xiao
   Shen, Jiayun
TI Lower-body control of humanoid robot NAO via Kinect
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Humanoid robot; Kinect; Lower-body; Joint angle
AB Humanoid robot has been concerned as it can perform some movements as human, especially imitating human motion in real time with motion tracking equipments. To imitate the human motion, there are still some challenges for the lower-body control of robot due to the physical difference between human and robot. In this paper, we propose a joint angle-based control (JAC) scheme for the lower-body control of humanoid robot to imitate human motion via Kinect sensor. Due to factors such as noise, tracking error and robot joint constrains, the motion information captured from the Kinect sensor applied to the robot directly will arise the problem of balance control. To overcome it, we optimize the joint angles in the lower-body of NAO, and define a gain factor to compensate the difference between the human motion and the robot so as to keep the balance of humanoid robot during imitation. Experimental results show that the proposed control scheme works efficiently even when the humanoid robot performs some complex movements such as standing on single foot.
C1 [Chen, Jianxin] Nanjing Univ Posts & Telecommun, Informat & Telecommun Engn Sch, Nanjing, Jiangsu, Peoples R China.
   [Wang, Guanwen] Nanjing Univ Posts & Telecommun, Commun & Informat Engn Sch, Telecommun Engn, Nanjing, Jiangsu, Peoples R China.
   [Hu, Xiao] Nanjing Univ Posts & Telecommun, Commun & Informat Engn Sch, Commun Engn, Nanjing, Jiangsu, Peoples R China.
   [Shen, Jiayun] Nanjing Univ Posts & Telecommun, Telecommun Engn, Nanjing, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications; Nanjing University of Posts &
   Telecommunications; Nanjing University of Posts & Telecommunications
RP Chen, JX (corresponding author), Nanjing Univ Posts & Telecommun, Informat & Telecommun Engn Sch, Nanjing, Jiangsu, Peoples R China.
EM chenjx@njupt.edu.cn; wgw4524@icloud.com; hxiao2014@outlook.com;
   nino06177@163.com
OI CHEN, Jianxin/0000-0001-6204-1121
FU Technique Innovation Training Program [201610293001Z]; Key Lab of
   Broadband Wireless Communication and Sensor Network Technology (Nanjing
   University of Posts and Telecommunications, Ministry of Education)
   [JZNY201704]; Nanjing University of Posts and Telecommunications
   [NY217021]; Natural Science Foundation of Jiangsu Province [BK20140891];
   National Natural Science Foundation of China [61401228]; China
   Postdoctoral Science Foundation [2015M581841]; Postdoctoral Science
   Foundation of Jiangsu Province [1501019A]
FX This work was supported by the Technique Innovation Training Program
   (No. 201610293001Z), Key Lab of Broadband Wireless Communication and
   Sensor Network Technology (Nanjing University of Posts and
   Telecommunications, Ministry of Education, JZNY201704), Nanjing
   University of Posts and Telecommunications (NY217021), Natural Science
   Foundation of Jiangsu Province (BK20140891), National Natural Science
   Foundation of China (Grant No. 61401228), China Postdoctoral Science
   Foundation (Grant No. 2015M581841), and Postdoctoral Science Foundation
   of Jiangsu Province (Grant No. 1501019A).
CR Almetwally I, 2013, IEEE INT C NETW SENS, P463, DOI 10.1109/ICNSC.2013.6548783
   [Anonymous], 7 LAT AM S CIRC SYST
   [Anonymous], INT C ROB INT COMP S
   [Anonymous], 2013, 13th International Conference on Autonomous Robot Systems (Robotica)
   [Anonymous], REAL TIME INVERSE KI
   Arbulu M, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2136, DOI 10.1109/ROBIO.2013.6739785
   Bakker P., 1996, AISB96 WORKSH LEARN, P3
   Cheng G, 2000, INTELLIGENT AUTONOMOUS SYSTEMS 6, P273
   Cheng LY, 2012, CHIN CONT DECIS CONF, P971, DOI 10.1109/CCDC.2012.6242992
   Csapo A, 2012, 3RD IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFOCOMMUNICATIONS (COGINFOCOM 2012), P666
   Do Martin, 2008, 2008 8th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2008), P545, DOI 10.1109/ICHR.2008.4756029
   Igorevich Rustam Rakhimov, 2011, 2011 8th International Conference on Ubiquitous Robots and Ambient Intelligence (URAI 2011), P655, DOI 10.1109/URAI.2011.6145902
   Indrajit Wisnu, 2013, 2013 International Conference on QiR (Quality in Research), P138, DOI 10.1109/QiR.2013.6632552
   Kim S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P2518, DOI 10.1109/IROS.2009.5354271
   Koenemann J, 2014, IEEE INT CONF ROBOT, P2806, DOI 10.1109/ICRA.2014.6907261
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2018, IEEE INTERNET THINGS, V5, P2315, DOI 10.1109/JIOT.2017.2737479
   Merai M, 2016, IEEE IND ELEC, P2301, DOI 10.1109/IECON.2016.7794101
   Ou YS, 2015, INT J SOC ROBOT, V7, P587, DOI 10.1007/s12369-015-0296-9
   Riley M, 2003, IEEE INT CONF ROBOT, P2368, DOI 10.1109/ROBOT.2003.1241947
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Shon AP, 2007, IEEE INT CONF ROBOT, P2847, DOI 10.1109/ROBOT.2007.363903
   Stephens B, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P4026
   Thobbi A., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P92, DOI 10.1109/ICHR.2010.5686324
   Nguyen VV, 2012, 2012 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P93, DOI 10.1109/SII.2012.6427340
   Wang BC, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P3903, DOI 10.1109/WCICA.2012.6359124
   Wang F, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P3692, DOI 10.1109/WCICA.2012.6359088
   Xiaojun Zhao, 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P840
   Yamane K., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P504, DOI 10.1109/ICHR.2010.5686312
   Yang NJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2191, DOI 10.1109/ROBIO.2013.6739794
   Zatsiorsky V., 1983, Biomechanics viii-b, V56, P1152
   Zhang L, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P1430, DOI 10.1109/ROBIO.2016.7866528
   Zuher F., 2012, 2012 Brazilian Robotics Symposium and Latin American Robotics Symposium (SBR-LARS 2012), P190, DOI 10.1109/SBR-LARS.2012.38
NR 33
TC 8
Z9 9
U1 5
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 10883
EP 10898
DI 10.1007/s11042-017-5332-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900030
DA 2024-07-18
ER

PT J
AU Lei, Q
   Zhang, HB
   Xin, MH
   Cai, YQ
AF Lei, Qing
   Zhang, Hongbo
   Xin, Minghai
   Cai, Yiqiao
TI A hierarchical representation for human action recognition in realistic
   scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Realistic scenes; Feature selection; Action
   modelling; Video processing
ID GREEN COMMUNICATIONS
AB BoF statistic-based local space-time features action representation is very popular for human action recognition due to its simplicity. However, the problem of large quantization en or and weak semantic representation decrease traditional BoF model's discriminant ability when applied to human action recognition in realistic scenes. To deal with the problems, we investigate the generalization ability of BoF framework for action representation as well as more effective feature encoding about high-level semantics. Towards this end, we present two-layer hierarchical codebook learning framework for human action classification in realistic scenes. In the first-layer action modelling, superpixel GMM model is developed to filter out noise features in STIP extraction resulted from cluttered background, and class-specific learning strategy is employed on the refined STIP feature space to construct compact and descriptive in-class action codebooks. In the second-layer of action representation, LDA-Km learning algorithm is proposed for feature dimensionality reduction and for acquiring more discriminative inter-class action codebook for classification. We take advantage of hierarchical framework's representational power and the efficiency of BoF model to boost recognition performance in realistic scenes. In experiments, the performance of our proposed method is evaluated on four benchmark datasets: KTH, YouTube (UCF 11), UCF Sports and Holly-wood2. Experimental results show that the proposed approach achieves improved recognition accuracy than the baseline method. Comparisons with state-of-the-art works demonstrates the competitive ability both in recognition performance and time complexity.
C1 [Lei, Qing; Zhang, Hongbo; Xin, Minghai; Cai, Yiqiao] Univ Huaqiao, Coll Comp Sci & Technol, Xiamen, Peoples R China.
   [Lei, Qing] Xiamen Univ, Dept Cognit Sci, Xiamen, Peoples R China.
   [Lei, Qing] Fujian Prov Key Lab Data Intens Comp, Quanzhou, Peoples R China.
C3 Huaqiao University; Xiamen University
RP Lei, Q (corresponding author), Univ Huaqiao, Coll Comp Sci & Technol, Xiamen, Peoples R China.; Lei, Q (corresponding author), Xiamen Univ, Dept Cognit Sci, Xiamen, Peoples R China.; Lei, Q (corresponding author), Fujian Prov Key Lab Data Intens Comp, Quanzhou, Peoples R China.
EM leiqing@hqu.edu.cn
FU National Nature Science Foundation of China [61502182]; Natural Science
   Foundation of Fujian Province, China [2017 J01110, 2015 J01253, 2015
   J01256, 2015 J01258]; Science and Technology Plan Projects in Fujian
   Province, China [2015H0025]; Scientific Research Funds of Huaqiao
   University, China [16BS812]
FX The authors would like to thank the anonymous reviewers for the valuable
   and insightful comments of this manuscript. This work is supported by
   the National Nature Science Foundation of China (Grant no. 61502182),
   the Natural Science Foundation of Fujian Province, China (Grant no. 2017
   J01110,2015 J01253,2015 J01256,2015 J01258), the Science and Technology
   Plan Projects in Fujian Province, China (Grant no. 2015H0025), the
   Scientific Research Funds of Huaqiao University, China (16BS812).
CR AlZain MA, 2015, INT J CLOUD APPL COM, V5, P35, DOI 10.4018/IJCAC.2015070103
   [Anonymous], 2007, PROC IEEE C COMPUT V
   Bhushan K, 2018, MULTIMED TOOLS APPL, V77, P4609, DOI 10.1007/s11042-017-4742-6
   Castrodad A, 2012, INT J COMPUT VISION, V100, P1, DOI 10.1007/s11263-012-0534-7
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Ding C., 2007, P 24 INT C MACH LEAR, P521
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Garcica RH, 2017, EXPERT SYST APPL, V92, P182
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gupta BB, 2017, INT J CLOUD APPL COM, V7, P1, DOI 10.4018/IJCAC.2017010101
   Gupta S, 2018, MULTIMED TOOLS APPL, V77, P4829, DOI 10.1007/s11042-016-3735-1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Laptev I, 2004, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2004.1334003
   Laptev I, 2013, P INT C COMP VIS, P432
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Li Y, 2016, VISUAL COMPUT, V32, P1525, DOI 10.1007/s00371-015-1137-4
   Liu JE, 2012, COMPUT VIS IMAGE UND, V116, P361, DOI 10.1016/j.cviu.2011.08.010
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sun J., 2009, International Conference on Information Engineering and Computer Science, P1
   Sun QR, 2016, NEUROCOMPUTING, V174, P722, DOI 10.1016/j.neucom.2015.09.074
   Wang HS, 2010, BIOL RHYTHM RES, V41, P167, DOI 10.1080/09291011003687924
   Wu JS, 2016, IEEE SYST J, V10, P873, DOI 10.1109/JSYST.2016.2550538
   Wu JS, 2016, IEEE SYST J, V10, P888, DOI 10.1109/JSYST.2016.2550530
   Wu JS, 2015, IEEE COMMUN MAG, V53, P214, DOI 10.1109/MCOM.2015.7105667
   Wu JS, 2014, IEEE COMMUN MAG, V52, P102, DOI 10.1109/MCOM.2014.6957149
   Zhen XT, 2016, IMAGE VISION COMPUT, V50, P1, DOI 10.1016/j.imavis.2016.02.006
NR 34
TC 5
Z9 5
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11403
EP 11423
DI 10.1007/s11042-018-5626-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900056
DA 2024-07-18
ER

PT J
AU Peng, X
   Xia, XY
   Liao, WZ
   Guo, ZW
AF Peng, Xue
   Xia, Xiaoyun
   Liao, Weizhi
   Guo, Zhanwei
TI Running time analysis of the Pareto archived evolution strategy on
   pseudo-Boolean functions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pareto archived evolution strategy; Running time analysis;
   Multi-objective optimization
ID MULTIOBJECTIVE OPTIMIZATION; ALGORITHMS
AB Evolutionary algorithms have long been quite successfully applied to solve multi-objective optimization problems. However, theoretical analysis of multi-objective evolutionary algorithms (MOEAs) is mainly restricted to the simple evolutionary multi-objective optimizer (SEMO). The Pareto archived evolution strategy (PAES) is a simple but important multi-objective evolutionary algorithm which is come from the study of telecommunication problems, and it has been successfully applied to many optimization problems, such as image processing and signal processing. In this paper, we make a first step toward studying the rigorous running time analysis for PAES. We show that the PAES outperforms the SEMO on function PATH when the PAES uses a simple mutation operator. However, it can not find the whole Pareto front with overwhelming probability on the well-studied function LOTZ. Additional experiments show that the experimental results are in agreement with the theoretical results.
C1 [Peng, Xue] Guangdong Polytech Normal Univ, Sch Math & Syst Sci, Guangzhou 510665, Guangdong, Peoples R China.
   [Xia, Xiaoyun; Liao, Weizhi] Jiaxing Univ, Coll Math Phys & Informat Engn, Jiaxing 314001, Zhejiang, Peoples R China.
   [Guo, Zhanwei] Guangdong Univ Finance & Econ, Huashang Coll, Guangzhou 511300, Guangdong, Peoples R China.
C3 Guangdong Polytechnic Normal University; Jiaxing University; Guangdong
   University of Finance & Economics
RP Xia, XY (corresponding author), Jiaxing Univ, Coll Math Phys & Informat Engn, Jiaxing 314001, Zhejiang, Peoples R China.
EM pxue2008@163.com; scutxxy@gmail.com; 1507715916@qq.com
OI Xia, Xiaoyun/0000-0001-7922-3343
FU National Natural Science Foundation of China [61773410, 61703183];
   Natural Science Foundation of Jiangxi Province of China
   [20151BAB217008]; Foundation for Distinguished Young Talents in Higher
   Education of Guangdong [2015KQNCX086]
FX This work was supported by the National Natural Science Foundation of
   China (61773410, 61703183), the Natural Science Foundation of Jiangxi
   Province of China (20151BAB217008) and the Foundation for Distinguished
   Young Talents in Higher Education of Guangdong (2015KQNCX086).
CR Al-Ayyoub M, 2016, MULTIMED TOOLS APP, P1
   Nguyen AQ, 2015, THEOR COMPUT SCI, V561, P24, DOI 10.1016/j.tcs.2014.06.023
   [Anonymous], 2001, P 5 C EVOLUTIONARY M
   [Anonymous], 2001, P 6 INT C PAR PROBL
   Brockhoff D, 2013, J MULTI-CRITERIA DEC, V20, P291, DOI 10.1002/mcda.1502
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Friedrich T, 2015, EVOL COMPUT, V23, P131, DOI 10.1162/EVCO_a_00126
   Giel O, 2003, LECT NOTES COMPUT SC, V2607, P415
   GIEL O, 2003, RUNTIME ANAL SIMPLE
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Gutjahr WJ, 2008, METHODOL COMPUT APPL, V10, P409, DOI 10.1007/s11009-007-9047-1
   Hanne T, 2001, LECT NOTES COMPUT SC, V1993, P197
   Jararweh Y, 2019, MULTIMED TOOLS APPL, V78, P3961, DOI 10.1007/s11042-017-5092-0
   Knowles J, 1999, P 1999 C EV COMP CEC, P98, DOI [DOI 10.1109/CEC.1999.781913, 10.1109/cec.1999.781913]
   Knowles JD, 2000, IEEE C EVOL COMPUTAT, P325, DOI 10.1109/CEC.2000.870313
   Kumar R, 2006, THEOR COMPUT SCI, V358, P104, DOI 10.1016/j.tcs.2006.03.007
   Laumanns M, 2004, IEEE T EVOLUT COMPUT, V8, P170, DOI 10.1109/TEVC.2004.823470
   Laumanns M., 2002, Proceedings of the Genetic and Evolutionary Computation Conference (GECCO '02), P439
   Laumanns Marco, 2004, Natural Computing, V3, P37, DOI 10.1023/B:NACO.0000023415.22052.55
   Neumann F, 2007, THEOR COMPUT SCI, V378, P32, DOI 10.1016/j.tcs.2006.11.002
   Neumann F, 2011, ALGORITHMICA, V59, P323, DOI 10.1007/s00453-009-9370-8
   Qian C, 2013, ARTIF INTELL, V204, P99, DOI 10.1016/j.artint.2013.09.002
   Rhazali Y, 2016, INT J CLOUD APPL COM, V6, P11, DOI 10.4018/IJCAC.2016040102
   SCHARNOW J, 2002, P PAR PROBL SOLV NAT, V2439, P54
   Sudholt D, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P493
   Xia XY, 2018, INFORM SCIENCES, V426, P87, DOI 10.1016/j.ins.2017.10.038
   Xia XY, 2015, INT J COMPUT MATH, V92, P2023, DOI 10.1080/00207160.2014.964695
   Zhang QF, 2007, IEEE T EVOLUT COMPUT, V11, P712, DOI 10.1109/TEVC.2007.892759
   Zhou YR, 2009, IEEE T EVOLUT COMPUT, V13, P1083, DOI 10.1109/TEVC.2009.2016570
NR 29
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11203
EP 11217
DI 10.1007/s11042-017-5466-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900046
DA 2024-07-18
ER

PT J
AU Sekhavat, YA
   Parsons, J
AF Sekhavat, Yoones A.
   Parsons, Jeffrey
TI The effect of tracking technique on the quality of user experience for
   augmented reality mobile navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Mobile navigation; AR tracking; User experience;
   Quality of user experience
ID CONTEXT AWARENESS; TECHNOLOGIES; GUIDANCE; DEVICE; SYSTEM; PLACE
AB Augmented reality (AR) technology is changing the way we interact with the world by making the journey seamless and interactive. This is done by layering digital enhancements over an existing reality or real life scenario. However, employing AR technologies in wayfinding and navigation does not automatically bring positive experiences. We argue that tracking techniques are important in mobile AR navigation and fundamentally affect the quality of user experience. In this paper, we propose two different tourist AR applications based on different tracking techniques. In addition to the analysis of the applications, we conducted a user evaluation to study the effect of different AR tracking techniques on the performance of users and the quality of user experience.
C1 [Sekhavat, Yoones A.] Tabriz Islamic Art Univ, Fac Multimedia, Azadi Blvd,Hakim Nezami Sq, Tabriz 5164736931, East Azerbaijan, Iran.
   [Parsons, Jeffrey] Mem Univ Newfoundland, Fac Business Adm, St John, NF A1B 3X5, Canada.
C3 Memorial University Newfoundland
RP Sekhavat, YA (corresponding author), Tabriz Islamic Art Univ, Fac Multimedia, Azadi Blvd,Hakim Nezami Sq, Tabriz 5164736931, East Azerbaijan, Iran.
EM sekhavat@tabriziau.ac.ir; jeffreyp@mun.ca
RI Parsons, Jeffrey/AAF-3380-2020; Sekhavat, Yoones A./KGK-5867-2024;
   Sekhavat, Yoones A./ABC-4693-2020
OI Sekhavat, Yoones A./0000-0003-3654-9583; Sekhavat, Yoones
   A./0000-0003-3654-9583; Parsons, Jeffrey/0000-0002-4819-2801
FU Tabriz Islamic Art University [1405/1, 2106/02/04]
FX This paper is financially supported by Tabriz Islamic Art University
   based on the research project 1405/1, 2106/02/04.
CR [Anonymous], 2011, PROC 1 INT WORKSHOP, DOI DOI 10.1145/2025876.2025881
   [Anonymous], 92412102009 ISO FDIS
   [Anonymous], 2004, TELEGEOINFORMATICS L
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Beeharee AK, 2006, P 8 C HUM COMP INT M, P81
   Benyon D, 2014, AI SOC, V29, P521, DOI 10.1007/s00146-013-0493-8
   Bruns E, 2009, PERS UBIQUIT COMPUT, V13, P165, DOI 10.1007/s00779-008-0194-3
   Chang YL, 2015, EDUC TECHNOL SOC, V18, P166
   Chen WQ, 2014, PROCEDIA COMPUT SCI, V35, P979, DOI 10.1016/j.procs.2014.08.180
   Cheng KH, 2013, J SCI EDUC TECHNOL, V22, P449, DOI 10.1007/s10956-012-9405-9
   Chumkamon S, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P765, DOI 10.1109/ECTICON.2008.4600543
   Chung N, 2015, COMPUT HUM BEHAV
   Danado J., 2003, EUR 2003 C GRAN SPAI
   Dunser A., 2008, SURVEY EVALUATION TE, P5
   Emmanouilidis C, 2013, J NETW COMPUT APPL, V36, P103, DOI 10.1016/j.jnca.2012.04.007
   Endsley MR, 2000, SITUATION AWARENESS ANALYSIS AND MEASUREMENT, P3
   Gebril Z. M., 2012, ADV COMPUT SCI ENG A, V2, P305
   Geiger Philip., 2014, Location-based mobile augmented reality applications: Challenges, examples, lessons learned
   Greene K., 2006, TECHNOLOGY REV
   Hassenzahl M, 2006, BEHAV INFORM TECHNOL, V25, P91, DOI 10.1080/01449290500330331
   Hering E., 1964, OUTLINES THEORY LIGH
   Hervás R, 2014, IEEE J BIOMED HEALTH, V18, P368, DOI 10.1109/JBHI.2013.2266480
   Hervás R, 2011, LECT NOTES COMPUT SC, V6693, P17, DOI 10.1007/978-3-642-21303-8_3
   Hile H, 2008, IEEE COMPUT GRAPH AP, V28
   Hsiao KF, 2015, MULTIMED TOOLS APPL, V74, P3543, DOI 10.1007/s11042-013-1649-8
   Ishikawa T, 2009, LECT NOTES COMPUT SC, V5756, P330, DOI 10.1007/978-3-642-03832-7_20
   Jung T, 2015, TOURISM MANAGE, V49, P75, DOI 10.1016/j.tourman.2015.02.013
   Kapoor P, 2013, P C ADV COMM CONTR S
   Katz BFG, 2012, VIRTUAL REAL-LONDON, V16, P253, DOI 10.1007/s10055-012-0213-6
   Kim S., 2013, INT J MULTIMEDIA UBI, V8, P313
   Kourouthanassis P.E., 2013, MULTIMED TOOLS APPL, V74, P1045
   Kourouthanassis P, 2015, PERVASIVE MOB COMPUT, V18, P71, DOI 10.1016/j.pmcj.2014.08.009
   LaMarca A, 2005, LECT NOTES COMPUT SC, V3468, P116
   Lee S, 2013, INT CONF ADV COMMUN, P401
   Marimon D., 2010, MOBIAR TOURIST EXPER
   Mulloni A., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P229, DOI 10.1109/ISMAR.2011.6092390
   Nakayama Y, 2015, IST SPIE EL IM
   Olsson T., 2011, 2011 IEEE International Symposium on Mixed and Augmented Reality, P75, DOI 10.1109/ISMAR.2011.6092372
   Olsson T, 2013, PERS UBIQUIT COMPUT, V17, P287, DOI 10.1007/s00779-011-0494-x
   Olsson T, 2012, J AMB INTEL SMART EN, V4, P29, DOI 10.3233/AIS-2011-0127
   Patkar RS, 2013, MARKER BASED AUGMENT
   Rehrl K, 2014, J LOCAT BASED SERV, V8, P75, DOI 10.1080/17489725.2014.946975
   Reitmayr Gerhard, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P109, DOI 10.1109/ISMAR.2006.297801
   Sekhavat YA, 2016, INT J COMPUTER GAMES
   Sekhavat YA, 2017, IEEE T MULTIMEDIA, V19, P1041, DOI 10.1109/TMM.2016.2639380
   Sekhavat YA, 2017, INT J ARTIF INTELL T, V26, DOI 10.1142/S0218213017300010
   Seo BK, 2011, LECT NOTES COMPUT SC, V6469, P276
   Shneiderman B, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P336, DOI 10.1109/VL.1996.545307
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   Takacs G., 2008, MIR 08, P427, DOI DOI 10.1145/1460096.1460165
   Tutunea M. F. S., 2013, USV ANN EC PUBLIC AD, V13, P215
   Venkatesh V, 2012, MIS QUART, V36, P157
   Willis S, 2005, NINTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P34, DOI 10.1109/ISWC.2005.46
   Yamabe T, 2013, MULTIMED TOOLS APPL, V62, P259, DOI 10.1007/s11042-011-0979-7
   Yeh T, 2004, P 2004 IEEE COMP SOC, V2, pII
   Yovcheva Z., 2013, ENG AUGMENTED TOURIS, P24
NR 56
TC 15
Z9 15
U1 2
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11635
EP 11668
DI 10.1007/s11042-017-4810-y
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100003
DA 2024-07-18
ER

PT J
AU Srivastava, P
   Khare, A
AF Srivastava, Prashant
   Khare, Ashish
TI Utilizing multiscale local binary pattern for content-based image
   retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Local binary pattern; Multiscale local binary pattern;
   Gray level co-occurrence matrix
ID CLASSIFICATION; REPRESENTATION; DESCRIPTOR; TRANSFORM; FEATURES;
   MOMENTS; COLOR; SHAPE
AB With the development of different image capturing devices, huge amount of complex images are being produced everyday. Easy access to such images requires proper arrangement and indexing of images which is a challenging task. The field of Content-Based Image Retrieval (CBIR) deals with finding solutions to such problems. This paper proposes a CBIR technique through multiscale Local Binary Pattern (LBP). Instead of considering consecutive neighbourhood pixels, Local Binary Pattern of different combinations of eight neighbourhood pixels is computed at multiple scales. The final feature vector is constructed through Gray Level Co-occurrence Matrix (GLCM). Advantage of the proposed multiscale LBP scheme is that it overcomes the limitations of single scale LBP and acts as more robust feature descriptor. It efficiently captures large scale dominant features of some textures which single scale LBP fails to do and also overcomes some of the limitations of other multiscale LBP techniques. Performance of the proposed technique is tested on five benchmark datasets, namely, Corel-1K, Olivia-2688, Corel-5K, Corel-10K, and GHIM-10K and measured in terms of precision and recall. The experimental results demonstrate that the proposed method outperforms other multiscale LBP techniques as well as some of the other state-of-the-art CBIR methods.
C1 [Srivastava, Prashant; Khare, Ashish] Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
C3 University of Allahabad
RP Khare, A (corresponding author), Univ Allahabad, Dept Elect & Commun, Allahabad, Uttar Pradesh, India.
EM prashant.jk087@gmail.com; ashishkhare@hotmail.com
RI Khare, Ashish/D-4566-2012; Srivastava, Prashant/V-5825-2019; Prakash,
   Om/AAL-4460-2021
OI Prakash, Om/0000-0001-6395-9989; Srivastava,
   Prashant/0000-0002-5812-2022
CR Chao Zhu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3065, DOI 10.1109/ICPR.2010.751
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Flores-Pulido L, 2008, ELE COM ENG, P40
   Fu X, 2006, INT C PATT RECOG, P417
   Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guo ZH, 2010, IEEE IMAGE PROC, P4521, DOI 10.1109/ICIP.2010.5653119
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang J, 1997, U S Patent, Patent No. [6, 246,790, 6246790]
   Huang XD, 2016, PROCEEDINGS OF THE 2016 12TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P3056, DOI 10.1109/WCICA.2016.7578372
   Khare A, 2013, 2 INT C CONT AW SYST, P228
   Lee SM, 1998, ETRI J, V20, P272, DOI 10.4218/etrij.98.0198.0302
   Li LJ, 2014, INT J COMPUT VISION, V107, P20, DOI 10.1007/s11263-013-0660-x
   Liang RZ, 2016, ARXIV160406620
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Murala S, 2012, INT J MULTIMED INF R, V1, P191, DOI 10.1007/s13735-012-0008-2
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nigam S, 2015, MULTIMED TOOLS APPL, V74, P7037, DOI 10.1007/s11042-014-1951-0
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Rashedi E, 2015, MULTIMED TOOLS APPL, V74, P3799, DOI 10.1007/s11042-013-1800-6
   Smith JR, 1996, P SOC PHOTO-OPT INS, V2670, P426, DOI 10.1117/12.234781
   Srivastava P, 2014, INT CONF CONTR AUTO, P159, DOI 10.1109/ICCAIS.2014.7020550
   Srivastava P, 2014, MOBILE NETW APPL, V19, P618, DOI 10.1007/s11036-014-0526-7
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Wang HX, 2014, PROC INT C TOOLS ART, P853, DOI 10.1109/ICTAI.2014.131
   Wang SY, 2016, INT J DISTRIB SENS N, DOI 10.1155/2016/3159805
   Xia Y, 2013, MULTISCALE LOCAL SPA, P423
   Yang GL, 2016, MULTIMED TOOLS APPL, V75, P15601, DOI [10.1007/s11042-015-2649-7, 10.1155/2015/932029]
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhang M, 2014, J VIS COMMUN IMAGE R, V25, P1574, DOI 10.1016/j.jvcir.2014.06.016
   Zhang YD, 2015, J MED IMAG HEALTH IN, V5, P1395, DOI 10.1166/jmihi.2015.1542
NR 40
TC 32
Z9 33
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12377
EP 12403
DI 10.1007/s11042-017-4894-4
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100033
DA 2024-07-18
ER

PT J
AU Ahmadvand, A
   Daliri, MR
   Zahiri, SM
AF Ahmadvand, Ali
   Daliri, Mohammad Reza
   Zahiri, Sayyed Mohammadreza
TI Segmentation of brain MR images using a proper combination of DCS based
   method with MRF
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MRI; Ensemble methods; Combination of multiple classifier; MRF; Dynamic
   classifier system; Weighted local accuracy; Segmentation
ID MIXTURE MODEL; CLASSIFICATION; FRAMEWORK; TISSUES
AB Manual segmentation of Magnetic Resonance Images (MRI) is a time-consuming process, thus automatic segmentation of brain MR images has attracted more attention in recent years. In this paper, we introduce Dynamic Classifier Selection Markov Random Field (DCSMRF) algorithm for supervised segmentation of brain MR images into three main tissues such as White Matter (WM), Gray Matter (GM) and Cerebrospinal Fluid (CSF). DCSMRF combines a novel ensemble method with the Markov Random Field (MRF) algorithm and tries to obtain the advantages of both algorithms. For the ensemble part of DCSMRF, we propose an ensemble method called Dynamic Classifier System-Weighted Local Accuracy (DCS-WLA) which is a type of Combination of Multiple Classifier (CMC) algorithm. Later, the MRF algorithm is utilized for incorporating spatial, contextual and textural information in this paper. For the MRF section, an energy function based on the output of the DCS-WLA algorithm is proposed, then maximum value for Maximum A Posterior (MAP) criterion is searched to obtain optimal segmentation. The MRF algorithm applies similar to a post processing step in which only a subset of pixels is selected for optimization step. Hence, a vast amount of search space is pruned. Consequently, the computational burden of the proposed algorithm is more tolerable than the conventional MRF-based methods. Moreover, by employing ensemble algorithms, the accuracy and reliability of final results are enhanced compared to the individual methods.
C1 [Ahmadvand, Ali] IUST, Sch Comp Engn, Tehran, Iran.
   [Ahmadvand, Ali] Emory Univ, Dept Math & Comp Sci, Atlanta, GA 30322 USA.
   [Daliri, Mohammad Reza] IUST, Sch Elect Engn, Dept Biomed Engn, Neurosci & Neuroengn Res Lab, Tehran 1684613114, Iran.
   [Zahiri, Sayyed Mohammadreza] Georgia Inst Technol, Dept Elect & Comp Engn, Atlanta, GA 30332 USA.
C3 Iran University Science & Technology; Emory University; Iran University
   Science & Technology; University System of Georgia; Georgia Institute of
   Technology
RP Daliri, MR (corresponding author), IUST, Sch Elect Engn, Dept Biomed Engn, Neurosci & Neuroengn Res Lab, Tehran 1684613114, Iran.
EM daliri@iust.ac.ir
RI Daliri, Mohammad Reza/S-9308-2018; Daliri, Mohammad Reza/AAF-4609-2021
OI Daliri, Mohammad Reza/0000-0001-9241-8751
FU IUST University
FX The work has been supported by internal funding from IUST University. No
   external financial support has been obtained for this work.
CR Ahmadvand A, 2014, SIGNAL IMAGE VIDEO P, P1
   Ahmadvand A., 2014, OMICS J Radiol, V3, pe130, DOI [10.4172/2167-7964.1000e130, DOI 10.4172/2167-7964.1000E130]
   Ahmadvand A, 2015, 2015 2 INT C KNOWL B
   Ahmadvand A, 2015, AUSTRALAS PHYS ENG S, V38, P241, DOI 10.1007/s13246-015-0352-7
   Ahmadvand A, 2015, APPL MATH COMPUT, V256, P808, DOI 10.1016/j.amc.2015.01.053
   [Anonymous], ADV LARGE MARGIN CLA
   Bae MH, 2010, EXPERT SYST APPL, V37, P4955, DOI 10.1016/j.eswa.2009.12.018
   Bae MH, 2009, NEUROIMAGE, V46, P717, DOI 10.1016/j.neuroimage.2009.02.012
   Balafar MA, 2012, ARTIF INTELL REV, V35, P1
   BESAG J, 1975, J ROY STAT SOC D-STA, V24, P179, DOI 10.2307/2987782
   Caldairou B, 2011, PATTERN RECOGN, V44, P1916, DOI 10.1016/j.patcog.2010.06.006
   da Silva ARF, 2007, MED IMAGE ANAL, V11, P169, DOI 10.1016/j.media.2006.12.002
   Dubes R, 1990, PATT REC 1990 P 10 I
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Greenspan H, 2006, IEEE T MED IMAGING, V25, P1233, DOI 10.1109/TMI.2006.880668
   Hammersley J., 1971, Markov fields on finite graphs and lattices
   Hashemi R. H., 2012, MRI: The Basics: The Basics
   Jiménez-Alaniz JR, 2006, IEEE T MED IMAGING, V25, P74, DOI 10.1109/TMI.2005.860999
   Kim W, 2011, COMPUT VIS IMAGE UND, V115, P1623, DOI 10.1016/j.cviu.2011.05.015
   Liu Y.-T., 2011, J CHINA U POSTS TELE, V18, P129, DOI DOI 10.1016/S1005-8885(10)60135-5
   Mayer A, 2009, IEEE T MED IMAGING, V28, P1238, DOI 10.1109/TMI.2009.2013850
   Ortiz A., 2012, ADV ARTIFICIAL NEURA, V2012, P1
   Ortiz A, 2013, NEUROCOMPUTING, V114, P118, DOI 10.1016/j.neucom.2012.08.047
   Ortiz A, 2011, LECT NOTES COMPUT SC, V6687, P49, DOI 10.1007/978-3-642-21326-7_6
   Ouadfel S., 2003, ELCVIA ELECT LETT CO, V2, P12
   Pham D, 1997, INT J PATTERN RECOGN, V11, P1189, DOI 10.1142/S021800149700055X
   Prakash RM, 2016, ARAB J SCI ENG, P1
   Qian H., 2011, INTELLIGENT SURVEILL, P119, DOI 10.1007/978-94-007-1137-2_8
   Rajapakse JC, 1997, IEEE T MED IMAGING, V16, P176, DOI 10.1109/42.563663
   Rivest-Hénault D, 2011, MAGN RESON IMAGING, V29, P243, DOI 10.1016/j.mri.2010.08.007
   Siyal MY, 2005, PATTERN RECOGN LETT, V26, P2052, DOI 10.1016/j.patrec.2005.03.019
   Tohka J, 2005, P EUR MED BIOL ENG C
   Tohka J, 2007, IEEE T MED IMAGING, V26, P696, DOI 10.1109/TMI.2007.895453
   VAIDYANATHAN M, 1995, MAGN RESON IMAGING, V13, P719, DOI 10.1016/0730-725X(95)00012-6
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Woods K, 1996, COMP VIS PATT REC 19
   Worth A., 1996, Internet Brain Segmentation Repository
   Wu T, 2012, NEUROIMAGE, V59, P2298, DOI 10.1016/j.neuroimage.2011.09.053
   Yousefi S, 2012, MED IMAGE ANAL, V16, P840, DOI 10.1016/j.media.2012.01.001
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 41
TC 11
Z9 11
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8001
EP 8018
DI 10.1007/s11042-017-4696-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800011
DA 2024-07-18
ER

PT J
AU Lin, YK
   Yang, CH
   Tsai, JT
AF Lin, Yih-Kai
   Yang, Cheng-Hsing
   Tsai, Jinn-Tsong
TI More secure lossless visible watermarking by DCT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE DCT; Watermarking; Lossless; Integer mapping
AB This study proposes a scheme for using modified coefficients of the DCT of an image to generate a lossless visible watermark. The major contribution of the proposed technique is the improved security against attack to remove watermarks under stricter assumption of Kerckhoffs' principle. After the host images and watermarks are decomposed into several frequencies, the DCT coefficients of the watermark are embedded into the DCT coefficients of the host image. Integer mapping is then used to perform 2-dimensional DCT. The major advantage of the method is the improved security achieved by using a random permutation matrix to factorize the transformation matrix. That is, since the embedding stage multiplies the transformation matrix by a random permutation matrix, illicit users, even under the stricter assumption of Kerckhoffs principle that the proposed embedding method is known by illicit users, cannot properly recover the host image without the correct permutation matrix. Unlike methods that embed the watermark in quantized frequency-domain coefficients, the watermarked image remains in raw lossless image form instead of some lossy form of quantized coefficients e.g., JPEG-formatted. Maintaining the lossless format of the watermarked image provides reversibility.
C1 [Lin, Yih-Kai; Yang, Cheng-Hsing; Tsai, Jinn-Tsong] Natl PingTung Univ, Dept Comp Sci, Pingtung, Taiwan.
C3 National Pingtung University
RP Lin, YK (corresponding author), Natl PingTung Univ, Dept Comp Sci, Pingtung, Taiwan.
EM yklin@mail.nptu.edu.tw
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alotaibi N, 2015, 12 LEARN TECHN C WEA, P12
   [Anonymous], 1883, Journal des Sciences Militaires
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Farrugia RA, 2010, IEEE MEDITERR ELECT, P212, DOI 10.1109/MELCON.2010.5476303
   Hao PW, 2001, IEEE T SIGNAL PROCES, V49, P2314, DOI 10.1109/78.950787
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Li XL, 2009, IEEE SIGNAL PROC LET, V16, P69, DOI 10.1109/LSP.2008.2008947
   Lin SD, 2004 IEEE INT S CONS
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Liu TY, 2010, IEEE T IMAGE PROCESS, V19, P1224, DOI 10.1109/TIP.2010.2040757
   Mohanty SP, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1029, DOI 10.1109/ICME.2000.871535
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Sinduja R, 2012, COMPUTER INFORM SCI, V270
   Tsai HM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P2106
   Wu MH, 2011, REVERSIBLE WATERMARK
   Yang Y, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2952843
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
   Yip SK, 2006, P INT C MULT EXP, P2106
NR 20
TC 5
Z9 6
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8579
EP 8601
DI 10.1007/s11042-017-4753-3
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800036
DA 2024-07-18
ER

PT J
AU Pang, C
   Yao, HX
   Sun, XS
   Zhao, SC
   Yu, W
AF Pang, Cheng
   Yao, Hongxun
   Sun, Xiaoshuai
   Zhao, Sicheng
   Yu, Wei
TI Rediscover flowers structurally
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image classification; Fine-grained classification; Saliency detection;
   Feature extraction
ID ATTENTION MAP
AB Existing methods for flower classification are usually focused on segmentation of the foreground, followed by extraction of features. After extracting the features from the foreground, global pooling is performed for final classification. Although this pipeline can be applied to many recognition tasks, however, these approaches have not explored structural cues of the flowers due to the large variation in their appearances. In this paper, we argue that structural cues are essential for flower recognition. We present a novel approach that explores structural cues to extract features. The proposed method encodes the structure of flowers into the final feature vectors for classification by operating on salient regions, which is robust to appearance variations. In our framework, we first segment the flower accurately by refining the existing segmentation method, and then we generate local features using our approach. We combine our local feature with global-pooled features for classification. Evaluations on the Oxford Flower dataset shows that by introducing the structural cues and locally pooling of some off-the-shelf features, our method outperforms the state-of-the-arts which employ specific designed features and metric learning.
C1 [Pang, Cheng; Yao, Hongxun; Sun, Xiaoshuai; Zhao, Sicheng; Yu, Wei] Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
C3 Harbin Institute of Technology
RP Yao, HX (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, 92 West Dazhi St, Harbin 150001, Heilongjiang, Peoples R China.
EM h.yao@hit.edu.cn
RI Yu, Wei/GPX-1311-2022
OI Pang, Cheng/0000-0001-7829-8992
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Angelova A., 2012, DEV DEPLOYMENT LARGE
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   Angelova A, 2013, IEEE WORK APP COMP, P39, DOI 10.1109/WACV.2013.6474997
   [Anonymous], BMVC
   [Anonymous], 2010, Int. J. Comput. Appl.
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Branson S, 2014, INT J COMPUT VISION, V108, P3, DOI 10.1007/s11263-014-0698-4
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Guru DS, 2011, MATH COMPUT MODEL, V54, P1030, DOI 10.1016/j.mcm.2010.11.032
   Kanan C, 2010, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2010.5539947
   Khan FS., 2011, Advances in Neural Information Processing Systems 24 (NIPS-2011), P1323
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Lu Y, 2012, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2012.6247785
   Mancas M, 2006, IEEE IMAGE PROC, P445, DOI 10.1109/ICIP.2006.312489
   Mattos AB, 2014, IEEE IMAGE PROC, P5197, DOI 10.1109/ICIP.2014.7026052
   Nilsback M-E., 2009, AUTOMATIC VISUAL FLO
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Parkhi OM, 2012, PROC CVPR IEEE, P3498, DOI 10.1109/CVPR.2012.6248092
   Parkhi OM, 2011, IEEE I CONF COMP VIS, P1427, DOI 10.1109/ICCV.2011.6126398
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
   Wah C, 2015, IEEE WINT CONF APPL, P502, DOI 10.1109/WACV.2015.73
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
NR 27
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 7851
EP 7863
DI 10.1007/s11042-017-4679-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800003
DA 2024-07-18
ER

PT J
AU Subhedar, MS
   Mankar, VH
AF Subhedar, Mansi S.
   Mankar, Vijay H.
TI Curvelet transform and cover selection for secure steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Image complexity; Curvelet transform; Image
   quality; Steganalysis
ID IMAGE STEGANOGRAPHY; SCHEME; VISIBILITY; CAPACITY
AB In this paper, we present curvelet transform (CT) based image steganography that embeds scrambled secret image in appropriately selected cover image. Curvelet transform offers optimal nonadaptive sparse representation of objects with edges and possesses high directional sensitivity and anisotropy. Cover image is decomposed using curvelet transform and adaptive block based embedding is carried out only in non-uniform regions of high frequency curvelet coefficients. In addition, this work also demonstrates a new cover selection method to choose suitable cover from image database. Spatial information based image complexity is modelled using fuzzy logic to identify set of images that yields least detectable stego image. From this set of ranked images, best cover can be chosen for carrying secret information depending on amount of information to be embedded. Cover selection offers reduced risk of detectability and ensures security. It is evident from experimental results that proposed method outperforms conventional methods in terms of imperceptibility, robustness and security.
C1 [Subhedar, Mansi S.] BD Coll Engn, Dept Elect & Telecommun, Wardha 442102, India.
   [Mankar, Vijay H.] Govt Polytech, Dept Elect & Telecommun, Nagpur 441206, Maharashtra, India.
RP Subhedar, MS (corresponding author), BD Coll Engn, Dept Elect & Telecommun, Wardha 442102, India.
EM mansi_subhedar@rediffmail.com
RI Mankar, Vijay H/G-2293-2012; Subhedar, Mansi/ABE-4740-2020
OI Subhedar, Mansi/0000-0002-4628-354X
CR Al-Dmour H, 2016, EXPERT SYST APPL, V46, P293, DOI 10.1016/j.eswa.2015.10.024
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2 INT C KNOWL BAS EN
   [Anonymous], HINDAWI MATH PROBLEM
   [Anonymous], 1996, T180103 ANTSI
   Boubchir L, 2005, P 8 INT C SIGN P ITS, P747
   Candes E., 2005, FAST DISCRETE CURVEL
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Cho S, 2010, IEEE INT S CIRC SYST
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Donoho DL, 2000, P SOC PHOTO-OPT INS, V4056, P12, DOI 10.1117/12.381679
   Farid H, 2002, INT C IM PROC ROCH
   Fridrich J, 2007, MM SEC 07
   FRIDRICH J, 2004, P 6 INF HID WORKSH T
   Kanan HR, 2014, EXPERT SYST APPL, V41, P6123, DOI 10.1016/j.eswa.2014.04.022
   Kharrazi M, 2006, IEEE IMAGE PROC, P117, DOI 10.1109/ICIP.2006.312386
   Khosravi MJ, 2014, MULTIMEDIA SYST, V20, P215, DOI 10.1007/s00530-013-0341-1
   Lyu S, 2003, LECT NOTES COMPUT SC, V2578, P340
   Mostafa R, 2015, 2015 IEEE SEVENTH INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INFORMATION SYSTEMS (ICICIS), P300, DOI 10.1109/IntelCIS.2015.7397238
   Muhammad N, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1534-1
   Nazari S, 2013, J INFORM SYST TELECO, V1, P131
   Rabie T, 2016, MULTIMEDIA TOOLS APP
   Sajasi S, 2015, APPL SOFT COMPUT, V30, P375, DOI 10.1016/j.asoc.2015.01.032
   Sajedi H, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P379, DOI 10.1109/CIT.2008.Workshops.34
   Sajedi H, 2010, INT J INF SECUR, V9, P337, DOI 10.1007/s10207-010-0112-3
   Sajedi H, 2010, J SIGNAL PROCESS SYS, V61, P367, DOI 10.1007/s11265-010-0460-2
   Sajedi H, 2008, INT CONF SIGN PROCES, P745, DOI 10.1109/ICOSP.2008.4697237
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xiao MY, 2015, PROC SPIE, V9811, DOI 10.1117/12.2205279
   Yifeng Sun, 2010, 2010 2nd International Workshop on Education Technology and Computer Science (ETCS), P159, DOI 10.1109/ETCS.2010.33
   Yu C, 2017, MULTIMED TOOLS APPL, V76, P6821, DOI 10.1007/s11042-015-3205-1
   Yu HH, 2013, INT WORK QUAL MULTIM, P12, DOI 10.1109/QoMEX.2013.6603194
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
NR 39
TC 24
Z9 24
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8115
EP 8138
DI 10.1007/s11042-017-4706-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800016
DA 2024-07-18
ER

PT J
AU Venianaki, M
   Salvetti, O
   de Bree, E
   Maris, T
   Karantanas, A
   Kontopodis, E
   Nikiforaki, K
   Marias, K
AF Venianaki, M.
   Salvetti, O.
   de Bree, E.
   Maris, T.
   Karantanas, A.
   Kontopodis, E.
   Nikiforaki, K.
   Marias, K.
TI Pattern recognition and pharmacokinetic methods on DCE-MRI data for
   tumor hypoxia mapping in sarcoma
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Dynamic MR imaging; Biomedical image processing;
   Soft tissue sarcomas; Tumor hypoxia; Matrix factorization
ID CONTRAST-ENHANCED MRI; NONNEGATIVE MATRIX FACTORIZATION; SOFT-TISSUE
   SARCOMAS; MODEL; BREAST; PARAMETERS; FEASIBILITY; ALGORITHMS
AB The main purpose of this study is to analyze the intrinsic tumor physiologic characteristics in patients with sarcoma through model-free analysis of dynamic contrast enhanced MR imaging data (DCE-MRI). Clinical data were collected from three patients with two different types of histologically proven sarcomas who underwent conventional and advanced MRI examination prior to excision. An advanced matrix factorization algorithm has been applied to the data, resulting in the identification of the principal time-signal uptake curves of DCE-MRI data, which were used to characterize the physiology of the tumor area, described by three different perfusion patterns i.e. hypoxic, well-perfused and necrotic one. The performance of the algorithm was tested by applying different initialization approaches with subsequent comparison of their results. The algorithm was proven to be robust and led to the consistent segmentation of the tumor area in three regions of different perfusion, i.e. well-perfused, hypoxic and necrotic. Results from the model-free approach were compared with a widely used pharmacokinetic (PK) model revealing significant correlations.
C1 [Venianaki, M.] IMT Sch Adv Studies Lucca, Image Anal Res Unit, Lucca, Italy.
   [Venianaki, M.; Kontopodis, E.; Nikiforaki, K.; Marias, K.] Fdn Res & Technol Hellas, Inst Comp Sci, Computat Biomed Lab, Iraklion, Greece.
   [Salvetti, O.] CNR, Area Ric CNR Pisa, Ist Sci & Tecnol Informaz Alessandro Faedo, Pisa, Italy.
   [de Bree, E.] Crete Univ Hosp, Dept Surg Oncol, Sch Med, Iraklion, Greece.
   [Maris, T.; Karantanas, A.] Univ Crete, Dept Radiol, Sch Med, Iraklion, Greece.
C3 IMT School for Advanced Studies Lucca; Foundation for Research &
   Technology - Hellas (FORTH); Consiglio Nazionale delle Ricerche (CNR);
   Istituto di Scienza e Tecnologie dell'Informazione "Alessandro Faedo"
   (ISTI-CNR); University of Crete; University of Crete
RP Venianaki, M (corresponding author), IMT Sch Adv Studies Lucca, Image Anal Res Unit, Lucca, Italy.; Venianaki, M (corresponding author), Fdn Res & Technol Hellas, Inst Comp Sci, Computat Biomed Lab, Iraklion, Greece.
EM maria.venianaki@imtlucca.it; ovidio.salvetti@isti.cnr.it; debree@uoc.gr;
   tmaris@med.uoc.gr; akarantanas@gmail.com; elko@ics.forth.gr;
   kat@ics.forth.gr; kmarias@ics.forth.gr
RI Maris, Thomas George/AAJ-6208-2020; Karantanas, Apostolos/AAE-6820-2020;
   Marias, Kostas/AAM-2330-2021
OI Karantanas, Apostolos/0000-0002-0927-2403; Marias,
   Kostas/0000-0003-3783-5223; Maris, Thomas/0000-0002-2629-6474
FU CHIC project - 7th Framework Programme of the European Commission
   [GA600841]
FX KM acknowledges support from the CHIC project GA600841 funded by the 7th
   Framework Programme of the European Commission. The authors thank
   Mariam-Eleni Oraiopoulou for helpful discussions and comments regarding
   tumor physiology that greatly improved the manuscript.
CR Berry MW, 2007, COMPUT STAT DATA AN, V52, P155, DOI 10.1016/j.csda.2006.11.006
   Cho HJ, 2009, NEOPLASIA, V11, P247, DOI 10.1593/neo.81360
   Eyal E, 2009, NMR BIOMED, V22, P40, DOI 10.1002/nbm.1221
   Fisher SM, 2016, EUR J RADIOL, V85, P1336, DOI 10.1016/j.ejrad.2016.05.003
   Fukumura D, 2007, J CELL BIOCHEM, V101, P937, DOI 10.1002/jcb.21187
   Han SH, 2013, NMR BIOMED, V26, P519, DOI 10.1002/nbm.2888
   Hockel M, 1996, SEMIN RADIAT ONCOL, V6, P3, DOI 10.1016/S1053-4296(96)80031-2
   HOFFMANN U, 1995, MAGNET RESON MED, V33, P506, DOI 10.1002/mrm.1910330408
   Jensen RL, 2014, NEURO-ONCOLOGY, V16, P280, DOI 10.1093/neuonc/not148
   Knopp MV, 1999, JMRI-J MAGN RESON IM, V10, P260, DOI 10.1002/(SICI)1522-2586(199909)10:3<260::AID-JMRI6>3.0.CO;2-7
   Kontopodis E, 2016, CGI 16 P 33 COMP GRA, P101, DOI [10.1145/2949035.2949061, DOI 10.1145/2949035.2949061]
   Kuhl CK, 1999, RADIOLOGY, V211, P101, DOI 10.1148/radiology.211.1.r99ap38101
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Menon C, 2005, CANCER LETT, V221, P225, DOI 10.1016/j.canlet.2004.06.029
   Neal ML, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0051951
   Newbold K, 2009, INT J RADIAT ONCOL, V74, P29, DOI 10.1016/j.ijrobp.2008.07.039
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Roniotis A, 2015, CANCER INFORM, V14, P7, DOI 10.4137/CIN.S19339
   Schabel MC, 2012, MAGN RESON MED, V68, P1632, DOI 10.1002/mrm.24162
   Soldatos T, 2016, RADIOLOGY, V278, P831, DOI 10.1148/radiol.2015142463
   Sourbron SP, 2011, MAGN RESON MED, V66, P735, DOI 10.1002/mrm.22861
   Stoyanova R, 2012, TRANSL ONCOL, V5, P437, DOI 10.1593/tlo.12319
   Surov A, 2017, TRANSL ONCOL, V10, P17, DOI 10.1016/j.tranon.2016.10.001
   Swanson KR, 2009, J NUCL MED, V50, P36, DOI 10.2967/jnumed.108.055467
   TOFTS PS, 1991, MAGNET RESON MED, V17, P357, DOI 10.1002/mrm.1910170208
   Venianaki M, 2016, IEEE CONF IMAGING SY, P183, DOI 10.1109/IST.2016.7738220
   Venianaki M., 2016, CGI 16 P 33 COMP GRA, P105, DOI DOI 10.1145/2949035.2949062
   Walsh JC, 2014, ANTIOXID REDOX SIGN, V21, P1516, DOI 10.1089/ars.2013.5378
   Xu YY, 2013, SIAM J IMAGING SCI, V6, P1758, DOI 10.1137/120887795
   Zheng LF, 2015, AM J TRANSL RES, V7, P535
NR 31
TC 3
Z9 6
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9417
EP 9439
DI 10.1007/s11042-017-5046-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200014
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Günay, A
   Nabiyev, V
AF Gunay, Asuman
   Nabiyev, Vasif
TI A new facial age estimation method using centrally overlapped block
   based local texture features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary patterns; Weber local descriptor; Local phase quantization;
   Feature extraction; Age estimation
ID FACE IMAGES; CLASSIFICATION; REGRESSION; MANIFOLD; PATTERNS
AB This paper introduces a new age estimation method based on the fusion of local features extracted using histogram-based local texture descriptors. In the study the age estimation performances of well-known powerful texture descriptor Local Binary Patterns (LBP), and new texture descriptors Weber Local Descriptor (WLD) and Local Phase Quantization (LPQ) which have not been analyzed in depth for age estimation, are investigated. Also multi-scale and spatial texture analysis is performed for all descriptors. In the spatial texture analysis, a new approach using the Centrally Overlapped Blocks (COB) obtained by combining the centers of discrete blocks is proposed to capture the related information between the blocks. Then feature fusion is performed to investigate the age estimation accuracies of different combinations of local texture descriptors. After dimensionality reduction with Principal Component Analysis (PCA), Multiple Linear Regression (MLR) is used to estimate the specific age. The results show that the age estimation accuracy of the proposed method is better when compared to previous methods on FG-NET, MORPH and PAL databases.
C1 [Gunay, Asuman] Karadeniz Tech Univ, Trabzon Vocat Sch, Dept Comp Technol, TR-61300 Trabzon, Turkey.
   [Nabiyev, Vasif] Karadeniz Tech Univ, Dept Comp Engn, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University; Karadeniz Technical University
RP Günay, A (corresponding author), Karadeniz Tech Univ, Trabzon Vocat Sch, Dept Comp Technol, TR-61300 Trabzon, Turkey.
EM gunaya@ktu.edu.tr; vasif@ktu.edu.tr
RI Günay Yılmaz, Asuman/AAR-5221-2020; Nabiyev, Vasif/AAK-3768-2021
OI Günay Yılmaz, Asuman/0000-0003-3960-5085; 
CR Albert AM, 2007, FORENSIC SCI INT, V172, P1, DOI 10.1016/j.forsciint.2007.03.015
   [Anonymous], 2008, FG NET AGING DATABAS
   [Anonymous], 2008, P 2008 23 INT S COMP
   [Anonymous], 2001, J Appl Sci Eng, DOI DOI 10.6180/JASE.2001.4.3.05
   Bekhouche, 2015, CONTR ENG INF TECHN, P1
   Carcagnì P, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0089-y
   Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cuixian Chen, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P200, DOI 10.1109/FG.2011.5771398
   Dehshibi MM, 2010, SIGNAL PROCESS, V90, P2431, DOI 10.1016/j.sigpro.2010.02.015
   Flury B., 1988, MULTIVARIATE STAT, P54
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fukai Hironobu, 2007, SICE '07. 46th SICE Annual Conference, P2808
   Gao F, 2009, PROCEEDINGS OF THE 19TH INTERNATIONAL WOOD MACHINING SEMINAR, P132
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   GONZALEZ-ULLOA M, 1965, Plast Reconstr Surg, V36, P239, DOI 10.1097/00006534-196508000-00013
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guodong Guo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563041
   Hadid A, 2004, PROC CVPR IEEE, P797
   Higashi A, 2011, IEEE STAT SIGN PROC, P505
   Huerta I, 2015, LECT NOTES COMPUT SC, V8926, P667, DOI 10.1007/978-3-319-16181-5_51
   Ju CH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P885, DOI 10.1109/ICMLC.2009.5212400
   Kohli S, 2013, NEUROCOMPUTING, V120, P164, DOI 10.1016/j.neucom.2012.08.069
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Liu JY, 2014, SIGNAL PROCESS, V94, P576, DOI 10.1016/j.sigpro.2013.07.025
   Liu KH, 2015, IEEE T INF FOREN SEC, V10, P2408, DOI 10.1109/TIFS.2015.2462732
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Luu K., 2011, P INT JOINT C BIOM, P1
   Ma Y, 2015, NEUROCOMPUTING, V147, P380, DOI 10.1016/j.neucom.2014.06.047
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Mokadem A., 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P88, DOI 10.1109/PSIVT.2010.22
   Ni BB, 2011, IEEE T MULTIMEDIA, V13, P1217, DOI 10.1109/TMM.2011.2167317
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Pedone M, 2012, 21 INT C PATT REC IC, P2776
   Ren HY, 2015, LECT NOTES COMPUT SC, V9003, P115, DOI 10.1007/978-3-319-16865-4_8
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Ross A., 2004, P BIOM CONS C BCC, P1
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang CC, 2009, IEEE INT CON MULTI, P282, DOI 10.1109/ICME.2009.5202490
   Xu Y, 2010, PATTERN RECOGN, V43, P1106, DOI 10.1016/j.patcog.2009.09.013
NR 47
TC 3
Z9 3
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6555
EP 6581
DI 10.1007/s11042-017-4572-6
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700006
DA 2024-07-18
ER

PT J
AU Jung, DJ
   Lee, HK
AF Jung, Dae-Jin
   Lee, Heung-Kyu
TI Frame-rate conversion detection based on periodicity of motion artifact
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital forensics; Video forensics; Frame-rate conversion; Motion
   artifact
ID RATE UP-CONVERSION; VIDEO; SIMILARITY; FORENSICS
AB With the advances in digital video technology, it is becoming easier to forge the digital video without introducing any artificial visual trace. The temporal domain of the digital videos is one of the main targets of video tampering, and video frame-rate conversion is one of the common operations for temporal video tampering such as temporal splicing and video speed adjustment. This operation necessarily accommodates temporal interpolation that introduces the periodic motion artifact on the motion trajectories. In this paper, the frame-rate converted video detection method is proposed based on the motion artifact. The experimental results demonstrated the performance of the proposed method through the extensive experiments on 1300 original videos and 18,000 frame-rate converted videos in uncompressed and H.264/AVC formats. Especially, for the nearest neighbor and motion-based interpolation, the proposed method could detect over than 93.35% of the frame-rate up-converted videos while exhibiting 0.01 false positive rate.
C1 [Jung, Dae-Jin] Agcy Def Dev, POB 35, Daejoen 34186, South Korea.
   [Lee, Heung-Kyu] Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejoen 34141, South Korea.
C3 Agency of Defense Development (ADD), Republic of Korea; Korea Advanced
   Institute of Science & Technology (KAIST)
RP Lee, HK (corresponding author), Korea Adv Inst Sci & Technol, Sch Comp, 291 Daehak Ro, Daejoen 34141, South Korea.
EM daejin84@gmail.com; heunglee@kaist.ac.kr
RI Lee, Heung Kyu/C-1941-2011
FU National Research Foundation of Korea(NRF) - Korea government(MSIP)
   [2016R1A2B2009595]; Institute for Information & communications
   Technology Promotion (IITP) - Korean government (MSIP) [R0126-16-1024]
FX This work was supported by the National Research Foundation of
   Korea(NRF) grant funded by the Korea government(MSIP) (No.
   2016R1A2B2009595), and by the Institute for Information & communications
   Technology Promotion (IITP) grant funded by the Korean government (MSIP)
   (No. R0126-16-1024, Managerial Technology Development and Digital
   Contents Security of 3D Printing based on Micro Licensing Technology).
CR [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], IJCA SPECIAL ISSUE C
   [Anonymous], 2007, 3 INT S INF ASS SEC
   [Anonymous], ELECT IMAGING 2007
   Ascenso C., 2005, 5th EURASIP Conference on Speech and Image Processing, Multimedia Communications and Services, P1
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bestagini P, 2013, INT CONF ACOUST SPEE, P3033, DOI 10.1109/ICASSP.2013.6638215
   Bian S, 2014, MULTIMED TOOLS APPL, V72, P437, DOI 10.1007/s11042-013-1364-5
   Bouguet JY, 2013, PYRAMIDAL IMPLEMENTA
   Castagno R, 1996, IEEE T CIRC SYST VID, V6, P436, DOI 10.1109/76.538926
   Choi BT, 2000, IEEE T CONSUM ELECTR, V46, P603, DOI 10.1109/30.883418
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Farid H, 2004, IEEE T IMAGE PROCESS, V13, P496, DOI 10.1109/TIP.2004.823819
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Gallagher AC, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P65, DOI 10.1109/CRV.2005.33
   Horn B.K.P, 1986, Robot Vision
   Kirchner M, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P11, DOI 10.1145/1411328.1411333
   Milani S, 2012, APSIPA TRANS SIGNAL, V1, DOI 10.1017/ATSIP.2012.2
   Popescu AC, 2005, INT S INF HID, P128
   Simoncelli E.P., 1999, Bayesian Multi-Scale Differential Optical Flow, volume 2 of Handbook of Computer Vision and Applications
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Wang W, 2007, IEEE T INF FOREN SEC, V2, P438, DOI 10.1109/TIFS.2007.902661
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
NR 24
TC 3
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 6095
EP 6116
DI 10.1007/s11042-017-4519-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800044
DA 2024-07-18
ER

PT J
AU Konstantoudakis, K
   Vrysis, L
   Papanikolaou, G
   Dimoulas, C
AF Konstantoudakis, Konstantinos
   Vrysis, Lazaros
   Papanikolaou, George
   Dimoulas, Charalampos
TI High accuracy block-matching sub-pixel motion estimation through
   detection of error surface minima
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interpolation; Sub-pixel motion estimation; Benchmarking
ID PHASE CORRELATION; SUPERRESOLUTION; MODEL; REGISTRATION; PERFORMANCE;
   ALGORITHM; EXTENSION
AB The present paper focuses on high-accuracy block-based sub-pixel motion estimation utilizing a straightforward error minimization approach. In particular, the mathematics of bilinear interpolation are utilized for the selection of the candidate motion vectors that minimize the error criterion, by estimating local minima in the error surface with arbitrary accuracy. The implemented approach favors optimum accuracy over computational load demands, making it ideal as a benchmark for faster methods to compare against; however, it is not best suited to real-time critical applications (i.e. video compression). Other video processing needs relying on motion vectors and requiring high-resolution/accuracy can also take advantage of the proposed solution (and its simplified nature in terms of underlying theoretical complexity), such as motion-compensation filtering for super resolution image enhancement, motion analysis in sensitive areas (e.g. high-speed video monitoring, medical imaging, motion analysis in sport science, big-data visual surveillance, etc.). The proposed method is thoroughly evaluated using both real video and synthetic motion sequences from still images, adopting well-tested block-based motion estimation evaluation procedures. Assessment includes comparisons to a number of existing block-based methods with respect to PSNR and SSIM metrics over ground-truth samples. The conducted evaluation takes into consideration both the original (arbitrary-accuracy) and the truncated motion vectors (after rounding them to the nearest half, quarter, or eighth of a pixel), where superior performance with more accurate motion vector estimation is revealed. In this context, the degree to which sub-pixel motion estimation methods actually produce sub-pixel motion vectors is investigated, and the implications thereof are discussed.
C1 [Konstantoudakis, Konstantinos; Vrysis, Lazaros; Papanikolaou, George; Dimoulas, Charalampos] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
C3 Aristotle University of Thessaloniki
RP Dimoulas, C (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM babis@eng.auth.gr
RI Dimoulas, Charalampos/ABU-1098-2022; Vrysis, Lazaros/V-2260-2019
OI Dimoulas, Charalampos/0000-0001-7923-9361; Vrysis,
   Lazaros/0000-0003-2900-4657; Konstantoudakis,
   Konstantinos/0000-0001-5092-8796
CR Abdou IE, 1998, P SOC PHOTO-OPT INS, V3653, P371, DOI 10.1117/12.334685
   [Anonymous], 2002, NUMERICAL METHODS
   Argyriou V, 2005, IEE P-VIS IMAGE SIGN, V152, P107, DOI 10.1049/ip-vis:20051073
   Argyriou V, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P215, DOI 10.1109/ISSPA.2003.1224852
   Argyriou V, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P329
   Argyriou Vasileios., 2006, Proc. of British Machine Vision Conference (BMVC), P387
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bo Zhou, 2003, Proceedings of the 2003 10th IEEE International Conference on Electronics, Circuits, and Systems (IEEE Cat. No.03EX749), P611
   Bovik Alan C, 2010, Handbook of image and video processing
   Brehm M, 2013, MED PHYS, V40, DOI 10.1118/1.4820537
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Chen Z., 2009, INT J SIGNAL PROCESS, P133
   Cheng FH, 1999, IEEE T CIRC SYST VID, V9, P977, DOI 10.1109/76.795049
   Chi YM, 2007, INT CONF ACOUST SPEE, P1017
   Davis C. Q., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P7, DOI 10.1109/ISCV.1995.476969
   Dimoulas A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/792028
   Dimoulas CA, 2014, J CULT HERIT, V15, P234, DOI 10.1016/j.culher.2013.05.003
   DUFAUX F, 1995, P IEEE, V83, P858, DOI 10.1109/5.387089
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Hoge WS, 2003, IEEE T MED IMAGING, V22, P277, DOI 10.1109/TMI.2002.808359
   Hu J, 2015, MULTIMED TOOLS APPL, V74, P9259, DOI 10.1007/s11042-014-2079-y
   Jeong J, 2003, ICCE: 2003 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS, DIGEST OF TECHNICAL PAPERS, P174, DOI 10.1109/ICCE.2003.1218867
   Keren D., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P742, DOI 10.1109/CVPR.1988.196317
   Kwon DN, 2005, IEEE PACIF, P261
   Larson R., 2010, CALCULUS
   Lee VR, 2015, J SCI EDUC TECHNOL, V24, P178, DOI 10.1007/s10956-014-9521-9
   Li XM, 1996, IEEE T CIRC SYST VID, V6, P118, DOI 10.1109/76.486427
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Magarey J, 1996, P SOC PHOTO-OPT INS, V2825, P674, DOI 10.1117/12.255276
   Marti-Puig P, 2012, J MATH IMAGING VIS, V42, P176, DOI 10.1007/s10851-011-0290-2
   Ng ACK, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P605, DOI 10.1109/ICIP.1998.727336
   Ouji K, 2013, J MATH IMAGING VIS, V47, P124, DOI 10.1007/s10851-012-0399-y
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Porto M, 2013, MULTIMED TOOLS APPL, V63, P107, DOI 10.1007/s11042-012-1033-0
   Ren JC, 2010, IEEE T IMAGE PROCESS, V19, P1379, DOI 10.1109/TIP.2009.2039056
   Sayed M, 2009, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2009.5414600
   Scharcanski J, 2013, COMPUT MED IMAG GRAP, V37, P377, DOI 10.1016/j.compmedimag.2013.06.004
   Schultz RR, 1998, J VIS COMMUN IMAGE R, V9, P38, DOI 10.1006/jvci.1997.0370
   Shekarforoush H, 1996, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.1996.517123
   Steel K, 2015, PSYCHON B REV, V22, P78, DOI 10.3758/s13423-014-0659-5
   Stone HS, 2001, IEEE T GEOSCI REMOTE, V39, P2235, DOI 10.1109/36.957286
   Strang G, 2006, Linear Algebra and its Applications
   Suh JW, 2009, ELECTRON LETT, V45, P618, DOI 10.1049/el.2009.3632
   Suh JW, 2004, IEEE T CONSUM ELECTR, V50, P968, DOI 10.1109/TCE.2004.1341708
   TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9
   Trocan M, 2012, MULTIMED TOOLS APPL, V61, P819, DOI 10.1007/s11042-011-0845-7
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   Vegiris CE, 2008, INT J DIGIT MULTIMED, V2008, DOI 10.1155/2008/250654
   Wang Y., 2002, Video processing and commu- nications, V5
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei Zhenyu, 2004, Proceedings. Third International Conference on Image and Graphics, P345
   Wong HM, 2005, IEEE INT SYMP CIRC S, P5477
   Yu YH, 2012, COMM COM INF SC, V321, P186
   Zhai B, 2016, MULTIMED TOOLS APPL, V75, P12173, DOI 10.1007/s11042-015-3183-3
   Zhang P, 2016, NEUROCOMPUTING, V204, P87, DOI 10.1016/j.neucom.2015.07.149
NR 55
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5837
EP 5856
DI 10.1007/s11042-017-4497-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800032
DA 2024-07-18
ER

PT J
AU Bhushan, K
   Gupta, BB
AF Bhushan, Kriti
   Gupta, B. B.
TI A novel approach to defend multimedia flash crowd in cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flash crowd; DDoS attack; Cloud security; User's QoE; Hierarchi
   calcaching; Flash crowd neutralization
ID DDOS ATTACKS; VIDEO
AB Cloud computing is an intelligent integration of distributed computing, hardware virtualization techniques, automated data center techniques and Internet technologies. Due to its appealing features, it has become most prevailing computing platform. Since, a large number of customers are moving towards cloud, attackers are also more interested in attacking cloud services. Distributed Denial of Service (DDoS) attack is one of the most popular methods to disrupt the services of a cloud platform hosting multimedia services. Modern day attackers use botnets to perform variety of DDoS attacks. With the advancement in the technology, bots are now capable to simulate the DDoS attacks as flash crowd events. During a flash crowd event, requests are sent by legitimate users; therefore these requests should not be denied and the server should be able to ensure user's QoE during a flash crowd event. Based on our study of botnets, flash crowd and DDoS attacks, in this paper, we propose a flow confidence based discrimination algorithm to distinguish between flash crowd event and DDoS attack. Moreover, we have given an effective, efficient and economical approach to ensure user's QoE during flash crowd events. We have performed various experiments using benchmark datasets to support our theoretical claims which also determine the efficiency and effectiveness of the proposed approach in real world scenario.
C1 [Bhushan, Kriti; Gupta, B. B.] Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Gupta, BB (corresponding author), Natl Inst Technol Kurukshetra, Kurukshetra, Haryana, India.
EM gupta.brij@gmail.com
RI Bhushan, Kriti/AAL-4576-2020; Gupta, Brij B/E-9813-2011
OI Gupta, Brij B/0000-0003-4929-4698
FU SERB, DST, Government of India [SB/FTP/ETA-131/2014]
FX This research work is being supported by Project grant
   (SB/FTP/ETA-131/2014) from SERB, DST, Government of India.
CR Adhikary T, 2017, MULTIMED TOOLS APPL, V76, P14485, DOI 10.1007/s11042-016-3852-x
   Al-Ali Z, 2015, 2015 IEEE 2nd International Conference on Cyber Security and Cloud Computing (CSCloud), P512, DOI 10.1109/CSCloud.2015.66
   Alamri A, 2016, MULTIMED TOOLS APPL, V75, P13333, DOI 10.1007/s11042-015-3074-7
   [Anonymous], 2016, HDB RES MODERN CRYPT
   [Anonymous], INT SEC INF C EISIC
   [Anonymous], 1998, 1998 WORLD CUP WEB S
   [Anonymous], P USENIX LEET
   [Anonymous], 2008, LEET
   [Anonymous], 2007, HDB COMPUTER NETWORK
   ARLITT M., 1999, HP LABS TECHNICAL RE
   Bailey M, 2009, CATCH 2009: CYBERSECURITY APPLICATIONS AND TECHNOLOGY CONFERENCE FOR HOMELAND SECURITY, PROCEEDINGS, P299, DOI 10.1109/CATCH.2009.40
   Bhushan K., 2017, INT J BIG DATA INTEL, V4, P81
   Buyya R., 2010, Cloud Computing: Principles and Paradigms
   Carl G, 2006, IEEE INTERNET COMPUT, V10, P82, DOI 10.1109/MIC.2006.5
   Chen Y, 2006, J PARALLEL DISTR COM, V66, P1137, DOI 10.1016/j.jpdc.2006.04.007
   de Paula U, 2015, 30TH ANNUAL ACM SYMPOSIUM ON APPLIED COMPUTING, VOLS I AND II, P769, DOI 10.1145/2695664.2695839
   Feitosa E, 2012, COMPUT NETW, V56, P2805, DOI 10.1016/j.comnet.2012.04.018
   Gupta BB, 2017, NEURAL COMPUT APPL, V28, P3655, DOI 10.1007/s00521-016-2317-5
   Gupta BB, 2009, INF SECUR J, V18, P224, DOI 10.1080/19393550903317070
   Hossfeld T, 2015, PROCEEDINGS OF THE 2015 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM), P1274, DOI 10.1109/INM.2015.7140480
   Ianelli N., 2007, INT J FORENSIC COMPU, P19, DOI 10.5769/j200701002
   Jia SJ, 2016, CHINA COMMUN, V13, P151, DOI 10.1109/CC.2016.7582307
   Jung J., 2002, Proceedings of the 11th international conference on World Wide Web, P293, DOI DOI 10.1145/511446.511485
   Kandula S, 2005, USENIX Association Proceedings of the 2nd Symposium on Networked Systems Design & Implementation (NSDI '05), P287
   Kleinrock L., 1975, Queueing Systems-Volume 1: Theory, V1
   Kumar PAR, 2013, COMPUT COMMUN, V36, P303, DOI 10.1016/j.comcom.2012.09.010
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, KNOWL-BASED SYST, V79, P18, DOI 10.1016/j.knosys.2014.04.010
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Luo HB, 2013, IEEE NETWORK, V27, P60, DOI 10.1109/MNET.2013.6678928
   Maksoudian Y., 1969, Probability and statistics, with applications
   Mell P., 2010, NIST DEFINITION CLOU
   Oikonomou G, 2009, IEEE ICC, P625
   Peng T, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1216370.1216373
   Rahmani H, 2012, COMPUT COMMUN, V35, P1380, DOI 10.1016/j.comcom.2012.04.002
   Scherrer A, 2007, IEEE T DEPEND SECURE, V4, P56, DOI 10.1109/TDSC.2007.12
   Segalin D, 2015, P INT COMP SOFTW APP, P897, DOI 10.1109/COMPSAC.2015.138
   Thing VLL, 2007, INT FED INFO PROC, V232, P229
   Wu Y, 2011, INT CON DISTR COMP S, P268, DOI 10.1109/ICDCS.2011.50
   Xiao Z, 2014, IEEE T COMPUT, V63, P1111, DOI 10.1109/TC.2012.284
   Xie Y, 2009, IEEE ACM T NETWORK, V17, P15, DOI 10.1109/TNET.2008.925628
   Xie Y, 2009, IEEE ACM T NETWORK, V17, P54, DOI 10.1109/TNET.2008.923716
   Yipei Niu, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1044, DOI 10.1109/INFOCOM.2015.7218477
   Yu S, 2015, IEEE T COMPUT, V64, P139, DOI 10.1109/TC.2013.191
   Yu S, 2014, IEEE T PARALL DISTR, V25, P2245, DOI 10.1109/TPDS.2013.181
   Yu S, 2012, IEEE T PARALL DISTR, V23, P1073, DOI 10.1109/TPDS.2011.262
NR 46
TC 14
Z9 14
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 4609
EP 4639
DI 10.1007/s11042-017-4742-6
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500032
DA 2024-07-18
ER

PT J
AU Chang, YS
AF Chang, Yan-Shuo
TI Fine-grained attention for image caption generation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fine-grained attention; Image caption generation; Attention generation
AB Despite the progress, generating natural language descriptions for images is still a challenging task. Most state-of-the-art methods for solving this problem apply existing deep convolutional neural network (CNN) models to extract a visual representation of the entire image, based on which the parallel structures between images and sentences are exploited using recurrent neural networks. However, there is an inherent drawback that their models may attend to a partial view of a visual element or a conglomeration of several concepts. In this paper, we present a fine-grained attention based model based on a deep recurrent architecture that combines recent advances in computer vision and machine translation. The model contains three sub-networks: a deep recurrent neural network for sentences, a deep convolutional network for images, and a region proposal network for nearly cost-free region proposals. Our model is able to automatically learn to fix its gaze on salient region proposals. The process of generating the next word, given the previously generated ones, is aligned with this visual perception experience. We validate the effectiveness of the proposed model on three benchmark datasets (Flickr 8K, Flickr 30K and MS COCO). The experimental results confirm the effectiveness of the proposed system.
C1 [Chang, Yan-Shuo] China Xian Inst Silk Rd Res, Xian 710100, Shaanxi, Peoples R China.
   [Chang, Yan-Shuo] Xian Univ Finance & Econ, Sch Informat, Xian 710100, Shaanxi, Peoples R China.
C3 Xi'an University of Finance & Economics
RP Chang, YS (corresponding author), China Xian Inst Silk Rd Res, Xian 710100, Shaanxi, Peoples R China.; Chang, YS (corresponding author), Xian Univ Finance & Econ, Sch Informat, Xian 710100, Shaanxi, Peoples R China.
EM changyanshuo@foxmail.com
FU Science Foundation of The China(Xi'an) Institute for Silk Road Research
   [2016SY10, 2016SY18]; scientific research program of Shaanxi Provincial
   Department of Education [2013JK1141]; Research Foundation of XAUFE
   [15XCK14]
FX The research is supported by Science Foundation of The China(Xi'an)
   Institute for Silk Road Research (2016SY10, 2016SY18), the scientific
   research program of Shaanxi Provincial Department of
   Education(2013JK1141) and Research Foundation of XAUFE (15XCK14).
CR [Anonymous], ARXIV14112539 CORR
   [Anonymous], 2014, Transactions of the Association for Computational Linguistics
   [Anonymous], NAACL HLT WORKSH
   [Anonymous], ARXIV14101090 CORR
   [Anonymous], 2015, NIPS
   [Anonymous], 2013, P 2013 C EMP METH NA
   [Anonymous], 2013, ACL
   Ba J, 2015, ADV NEUR IN, V28
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Chen X, 2014, ARXIV14115654 CORR
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Cho K., 2014, ARXIV14061078
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Denil M, 2012, NEURAL COMPUT, V24, P2151, DOI 10.1162/NECO_a_00312
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Devlin J, 2015, ARXIV150504467 CORR
   Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jingna Mao, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348279
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Karpathy Andrej, 2014, Advances in neural information processing systems, P1889
   Kingma D. P., 2014, arXiv
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kuznetsova Polina, 2012, Association for Computational Linguistics
   Larochelle Hugo, 2010, ADV NEURAL INFORM PR, V23
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mason R, 2014, PROCEEDINGS OF THE 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 2, P592
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Pascanu R., 2014, ICLR
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang Yichuan., 2014, NIPS
   Tieleman T, 2012, LECT 6 5RMSPROP
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang S, 2016, IEEE T KNOWL DATA EN, V28, P3191, DOI 10.1109/TKDE.2016.2605687
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y, 2011, ACL
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zaremba W., 2014, RECURRENT NEURAL NET, P1, DOI DOI 10.1016/S0893-6080(96)00073-1
NR 51
TC 15
Z9 15
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 2959
EP 2971
DI 10.1007/s11042-017-4593-1
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600003
DA 2024-07-18
ER

PT J
AU Lee, N
   Kim, E
   Kwon, O
AF Lee, Namyeon
   Kim, Eunji
   Kwon, Ohbyung
TI Combining TF-IDF and LDA to generate flexible communication for
   recommendation services by a humanoid robot
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-robot interaction; Text mining; TF-IDF; LDA; Unstructured data;
   Recommendation systems
ID TOPIC MODEL
AB Linguistic flexibility around non-predetermined expressions is important for more effective human-robot face-to-face interaction. In the past, most robots have been fitted with a limited and supervised response process and programmed with certain responses for predetermined words or sentences. As a result, implementing viable robot-based recommendation services has been difficult. The purpose of this paper is to propose a text-mining approach to flexible robot-based recommendation services in which, when the robot encounters linguistic expressions that differ substantially from the programmed linguistic database, flexible responses are generated based on understanding of several external corpora and a knowledge-learning process. This study combines two text-mining methods, TF-IDF and LDA, to generate flexible communication, which enables a robot to respond with recommendation content that is not pre-programmed. The results of our analysis suggest that the proposed combined approach outperforms the TF-IDF and LDA methods in terms of overall accuracy and F-score.
C1 [Lee, Namyeon] Hanshin Univ, Dept IT Business Adm, Osan, Gyeonggi, South Korea.
   [Kim, Eunji] Kyung Hee Univ, CAITECH, Seoul, South Korea.
   [Kwon, Ohbyung] Kyung Hee Univ, Sch Management, Seoul, South Korea.
C3 Hanshin University; Kyung Hee University; Kyung Hee University
RP Kwon, O (corresponding author), Kyung Hee Univ, Sch Management, Seoul, South Korea.
EM nylee@sungkyul.ac.kr; yukimouse@khu.ac.kr; obkwon@khu.ac.kr
FU National Strategic R&D Program for Industrial Technology [10041659];
   Ministry of Trade, Industry, and Energy (MOTIE)
FX This work was funded by the National Strategic R&D Program for
   Industrial Technology (10041659) and funded by the Ministry of Trade,
   Industry, and Energy (MOTIE).
CR [Anonymous], 10 INT S ROB RES NOV
   Baddoura R, 2013, INT J SOC ROBOT, V5, P529, DOI 10.1007/s12369-013-0207-x
   Blei DM, 2007, ANN APPL STAT, V1, P17, DOI 10.1214/07-AOAS114
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Causo A, 2016, MECH MACH SCI, V37, P75, DOI 10.1007/978-3-319-22368-1_8
   Chung W, 2010, ICIS 2010 P, P233
   Datta C, 2010, ACMIEEE INT CONF HUM, P87, DOI 10.1109/HRI.2010.5453256
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Ding CHQ, 2005, J AM SOC INF SCI TEC, V56, P597, DOI 10.1002/asi.20148
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   He YL, 2013, ACM T INTEL SYST TEC, V5, DOI 10.1145/2542182.2542188
   Hong L., 2010, P 1 WORKSH SOC MED A, P80, DOI [10.1145/1964858.1964870, DOI 10.1145/1964858.1964870]
   Ishiguro H, 2001, IND ROBOT, V28, P498, DOI 10.1108/01439910110410051
   Kamei K., 2010, INT C MULT INT WORKS, P19, DOI DOI 10.1145/1891903.1891929
   Lee S, 2010, J COMPUT INFORM SYST, V51, P1
   Li S, 2007, AAAI SPRING S INT CH, P72
   Lin J., 2011, P 17 ACM SIGKDD INT, P422
   Park K.-M., 2012, LECT NOTES COMPUTER, V7240, P105
   Scholtz J.C., 2002, MULTIROBOT SYSTEMS S
   Shiomi M, 2013, INT J SOC ROBOT, V5, P251, DOI 10.1007/s12369-013-0180-4
   Sugiura K, 2014, IEEE INT CONF ROBOT, P2237, DOI 10.1109/ICRA.2014.6907168
   Vijay R, 2012, 2012 9TH INTERNATIONAL CONFERENCE ON UBIQUITOUS ROBOTS AND AMBIENT INTELLIGENCE (URAL), P120, DOI 10.1109/URAI.2012.6462949
   Yang GB, 2015, EXPERT SYST APPL, V42, P1340, DOI 10.1016/j.eswa.2014.09.015
NR 23
TC 15
Z9 16
U1 7
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 4
BP 5043
EP 5058
DI 10.1007/s11042-017-5113-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW4PQ
UT WOS:000425296500053
DA 2024-07-18
ER

PT J
AU Chen, N
   Li, W
   Xiao, HD
AF Chen, Ning
   Li, Wei
   Xiao, Haidong
TI Fusing similarity functions for cover song identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cover song identification (CSI); Qmax; Dmax; Similarity network fusion
   (SNF)
ID MUSIC INFORMATION-RETRIEVAL; AUDIO; FEATURES
AB Cover Song Identification (CSI) technique, refers to the process of identifying an alternative version, performance, rendition, or recording of a previously recorded musical composition by measuring and modeling the musical similarity between them quantitatively and objectively. However, it is not possible to describe the similarity between tracks comprehensively and reliably with only one similarity function. In this paper, the Similarity Network Fusion (SNF) technique, which was originally proposed for combining different kernels for predicting drug-target interactions, is adopted to fuse different similarities based on the same descriptor and different similarity functions. First, the Harmonic Pitch Class Profile (HPCP) is extracted from each track. Next, the similarities, in terms of Qmax and Dmax measures, between the HPCP descriptors of any two tracks are calculated, respectively. Then, the track-by-track similarity networks based on Qmax and on Dmax similarity are constructed separately and then fused into one network by SNF. Finally, the fused similarities obtained from the fused similarity network are adopted to train a classifier, which can then be used to identify whether the input two tracks belong to reference/cover or reference/non-cover pair. Experimental results on Covers80 (http:// labrosa. ee. columbia. edu/projects/coversongs/ covers80/), subset of SecondHandSongs (SHS) (http:// labrosa. ee. columbia. edu/millionsong/secondhand), and the Mixed Collection and Mazurka Cover Collection provided by MIREX (http:// www. music-ir.org/mirex/wiki/2016: Audio Cover Song Identification) demonstrate that the proposed scheme performs comparably with or even better than state-of-the-art CSI schemes.
C1 [Chen, Ning] East China Univ Sci & Technol, Sch Informat Sci & Engn, 130 Meilong Rd, Shanghai 200237, Peoples R China.
   [Li, Wei] Fudan Univ, Sch Comp Sci & Technol, Shanghai 201203, Peoples R China.
   [Xiao, Haidong] Chinese Acad Sci, Shanghai Adv Res Inst, Shanghai, Peoples R China.
C3 East China University of Science & Technology; Fudan University; Chinese
   Academy of Sciences; Shanghai Advanced Research Institute, CAS
RP Chen, N (corresponding author), East China Univ Sci & Technol, Sch Informat Sci & Engn, 130 Meilong Rd, Shanghai 200237, Peoples R China.
EM chenning_750210@163.com
FU National Natural Science Foundation of China [61271349]
FX This work was supported by the National Natural Science Foundation of
   China (61271349)
CR Bello J.P., 2007, ISMIR, P239
   Casey MA, 2008, P IEEE, V96, P668, DOI 10.1109/JPROC.2008.916370
   Chen N, 2016, ELECTRON LETT, V52, P1173, DOI 10.1049/el.2015.4013
   Chen N, 2015, APPL ACOUST, V99, P92, DOI 10.1016/j.apacoust.2015.06.003
   Degani A, 2013, P 14 INT WORKSH IM A, P1
   Downie JS, 2008, ACOUST SCI TECHNOL, V29, P247, DOI 10.1250/ast.29.247
   Egorov A, 2008, MIREX
   Ellis D.P., 2006, MIREX 2006, P1, DOI DOI 10.7916/D8B284N1
   Ellis DPW, 2007, INT CONF ACOUST SPEE, P1429
   Foucard R, 2010, INT CONF ACOUST SPEE, P5514, DOI 10.1109/ICASSP.2010.5495217
   Fujishima T., 1999, P INT COMP MUS C, P464
   Gomez E, 2006, THESIS
   Gomez E., 2006, P ISMIR INT SOC MUS, P180
   Gómez E, 2006, INFORMS J COMPUT, V18, P294, DOI 10.1287/ijoc.1040.0126
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Julia J Serra, 2011, THESIS
   Khadkevich Maksim, 2013, Proc. International Society for Music Information Retrieval (ISMIR), P233
   Marolt M, 2008, IEEE T MULTIMEDIA, V10, P1617, DOI 10.1109/TMM.2008.2007293
   Marolt Matija, 2006, ISMIR, P280
   Müller M, 2010, IEEE T AUDIO SPEECH, V18, P649, DOI 10.1109/TASL.2010.2041394
   Ravuri S, 2009, MIREX
   Ravuri S, 2010, INT CONF ACOUST SPEE, P65, DOI 10.1109/ICASSP.2010.5496214
   Sailer Christian, 2006, MIREX
   Salamon J, 2013, THESIS
   Salamon J., 2012, Proceedings of the 21st international conference companion on World Wide Web, P887
   Salamon J, 2013, INT J MULTIMED INF R, V2, P45, DOI 10.1007/s13735-012-0026-0
   Serra J, 2009, J PHYS, V11
   Serrà J, 2008, IEEE T AUDIO SPEECH, V16, P1138, DOI 10.1109/TASL.2008.924595
   Serrà J, 2010, STUD COMPUT INTELL, V274, P307
   Serrato J.M. H., 2009, El coaching y su desarrollo, P1
   Tai-Ming Chang, 2013, 2013 IEEE 2nd Global Conference on Consumer Electronics (GCCE), P55, DOI 10.1109/GCCE.2013.6664919
   Tsai WH, 2008, J INF SCI ENG, V24, P1669
   Tsai Wei-Ho., 2005, Proceeding of the International Symposium on Music Information Retrieval (ISMIR), V5, P183
   Walters TC, 2013, LECT NOTES COMPUT SC, V7900, P197, DOI 10.1007/978-3-642-41248-6_11
   Wang B, 2014, NAT METHODS, V11, P333, DOI [10.1038/nmeth.2810, 10.1038/NMETH.2810]
   Xiao Chuan, 2012, 2012 International Conference on Systems and Informatics (ICSAI 2012), P2170, DOI 10.1109/ICSAI.2012.6223482
   Yang Fan, 2016, Journal of East China University of Science and Technology (Natural Science Edition), V42, P247, DOI 10.14135/j.cnki.1006-3080.2016.02.015
NR 37
TC 11
Z9 12
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2629
EP 2652
DI 10.1007/s11042-017-4456-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400049
DA 2024-07-18
ER

PT J
AU de la Rosa, JI
   Villa-Hernández, J
   Cortez, J
   Gamboa, H
   Arceo, JG
   González, E
AF de la Rosa, Jose I.
   Villa-Hernandez, Jesus
   Cortez, Joaquin
   Gamboa, Hamurabi
   Arceo, Jose G.
   Gonzalez, Efren
TI On the comparison of different kernel functionals and neighborhood
   geometry for nonlocal means filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image filtering; Nonlocal means; Kernel functionals; Sparse learning
   techniques; Collaborative filtering
ID MINIMUM-ENTROPY; IMAGE; SELECTION; TRANSFORM; ALGORITHM; ROBUST
AB The present work proposes a review and comparison of different Kernel functionals and neighborhood geometry for Nonlocal Means (NLM) in the task of digital image filtering. Some different alternatives to change the classical exponential kernel function used in NLM methods are explored. Moreover, some approaches that change the geometry of the neighborhood and use dimensionality reduction of the neighborhood or patches onto principal component analysis (PCA) are also analyzed, and their performance is compared with respect to the classic NLM method. Mainly, six approaches were compared using quantitative and qualitative evaluations, to do this an homogeneous framework has been established using the same simulation platform, the same computer, and same conditions for the initializing parameters. According to the obtained comparison, one can say that the NLM filtering could be improved when changing the kernel, particularly for the case of the Tukey kernel. On the other hand, the excellent performance given by recent hybrid approaches such as NLM SAP, NLM PCA (PH), and the BM3D SAPCA lead to establish that significantly improvements to the classic NLM could be obtained. Particularly, the BM3D SAPCA approach gives the best denoising results, however, the computation times were the longest.
C1 [de la Rosa, Jose I.; Villa-Hernandez, Jesus; Gamboa, Hamurabi; Arceo, Jose G.; Gonzalez, Efren] Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Antiguo Camino Bufa 1, Zacatecas 98000, Mexico.
   [de la Rosa, Jose I.; Cortez, Joaquin] Inst Tecnol Sonora, Dept Ingn Elect & Elect, Campus Nainari,Av Antonio Caso 2266, Obregon 85130, Sonora, Mexico.
C3 Universidad Autonoma de Zacatecas
RP de la Rosa, JI (corresponding author), Univ Autonoma Zacatecas, Unidad Acad Ingn Elect, Antiguo Camino Bufa 1, Zacatecas 98000, Mexico.; de la Rosa, JI (corresponding author), Inst Tecnol Sonora, Dept Ingn Elect & Elect, Campus Nainari,Av Antonio Caso 2266, Obregon 85130, Sonora, Mexico.
EM ismaelrv@ieee.org
RI Olague, Jose Guadalupe Arceo/AAQ-2201-2020; De la Rosa, José
   Ismael/N-7394-2019
OI Olague, Jose Guadalupe Arceo/0000-0002-7240-8158; De la Rosa, José
   Ismael/0000-0002-7337-8974; Cortez, Joaquin/0000-0003-3900-5880;
   GONZALEZ-RAMIREZ, EFREN/0000-0002-8060-6170
FU Universidad Autonoma de Zacatecas (UAZ); CONACyT; PIFI Mexican Program
   from UAZ
FX The first author acknowledge all support given by the Universidad
   Autonoma de Zacatecas (UAZ) during the years 2014-2015 to realize one
   academic year (invited professor-researcher) of leave at the Instituto
   Tecnologico de Sonora (ITSON). Additional acknowledgements for the
   support given by CONACyT, particularly the postgraduate programs in
   Electrical Engineering Sciences of both institutions (UAZ and ITSON).
   Also, our deep gratitude to the Secretaria de Educacion Publica (SEP) of
   Mexico, this work was partially supported through the PIFI 2014-2015
   Mexican Program from UAZ. Finally, we acknowledge the valuable comments
   and recommendations made by two anonymous reviewers.
CR Berlinet A, 1994, PUBLICATIONS LINSTIT, V38, P3
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Buades A, 2011, COMMUN ACM, V54, P109, DOI 10.1145/1941487.1941513
   Colom M, 2014, J OPT SOC AM A, V31, P863, DOI 10.1364/JOSAA.31.000863
   Dabov K., 2009, SPARS 09 SIGNAL PROC
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Danielyan A, 2009, LNLA: 2009 INTERNATIONAL WORKSHOP ON LOCAL AND NON-LOCAL APPROXIMATION IN IMAGE PROCESSING, P41, DOI 10.1109/LNLA.2009.5278404
   de la Rosa JI, 2013, J EUR OPT SOC-RAPID, V8, DOI 10.2971/jeos.2013.13047
   De la Rosa JI, 2003, IEEE T INSTRUM MEAS, V52, P1009, DOI 10.1109/TIM.2003.814816
   de la Rosa JI, 2002, IEEE IMTC P, P1205, DOI 10.1109/IMTC.2002.1007129
   Deledalle CA, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.25
   Deledalle CA, 2012, J MATH IMAGING VIS, V43, P103, DOI 10.1007/s10851-011-0294-y
   Deledalle CA, 2009, IEEE T IMAGE PROCESS, V18, P2661, DOI 10.1109/TIP.2009.2029593
   DEVROYE L, 1992, ANN STAT, V20, P2037, DOI 10.1214/aos/1176348901
   Devroye L, 1999, STAT PROBABIL LETT, V44, P299, DOI 10.1016/S0167-7152(99)00021-8
   Devroye L, 1997, TEST-SPAIN, V6, P223
   DEVROYE L, 1989, ANN I H POINCARE-PR, V25, P533
   Dinesh P. J., 2009, INT J OPEN PROBLEMS, V2, P293
   Escalante N, 2013, OPT LASER ENG, V51, P1060, DOI 10.1016/j.optlaseng.2013.03.007
   Goossens B., 2008, 2008 International Workshop on Local and Non-Local Approximation in Image Processing, P143
   Juditsky A, 2010, APPL COMPUT HARMON A, V29, P354, DOI 10.1016/j.acha.2010.01.003
   Lebrun M, 2013, IMAGE PROCESS ON LIN, V3, P1, DOI 10.5201/ipol.2013.16
   Lin L, 2009, P 5 IEEE INT C INT I, P471
   Liu YL, 2008, J COMPUT SCI TECH-CH, V23, P270, DOI 10.1007/s11390-008-9129-8
   Loader CR, 1999, ANN STAT, V27, P415, DOI 10.1214/aos/1018031201
   Maleki A, 2013, APPL COMPUT HARMON A, V35, P452, DOI 10.1016/j.acha.2012.11.003
   MASRY E, 1983, IEEE T INFORM THEORY, V29, P696, DOI 10.1109/TIT.1983.1056736
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   Ponomarenko NN, 2007, INT GEOSCI REMOTE SE, P472, DOI 10.1109/IGARSS.2007.4422833
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Sutour C, 2016, EUR SIGNAL PR CONF, P76, DOI 10.1109/EUSIPCO.2016.7760213
   Sutour C, 2014, IEEE T IMAGE PROCESS, V23, P3506, DOI 10.1109/TIP.2014.2329448
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Talebi H, 2013, IEEE T IMAGE PROCESS, V22, P1468, DOI 10.1109/TIP.2012.2231691
   TERRELL GR, 1985, J AM STAT ASSOC, V80, P209, DOI 10.2307/2288074
   TERRELL GR, 1990, J AM STAT ASSOC, V85, P470, DOI 10.2307/2289786
   Tian J, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2964, DOI 10.1109/ICMLC.2008.4620915
   Van de Ville D, 2011, IEEE T IMAGE PROCESS, V20, P2683, DOI 10.1109/TIP.2011.2121083
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   You SJ, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-60
   You SJ, 2011, INT CONF ACOUST SPEE, P1141
NR 43
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1205
EP 1235
DI 10.1007/s11042-016-4322-1
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400050
DA 2024-07-18
ER

PT J
AU de Lima, ES
   Feijó, B
   Furtado, AL
AF de Lima, Edirlei Soares
   Feijo, Bruno
   Furtado, Antonio L.
TI Video-based interactive storytelling using real-time video compositing
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive storytelling; Video compositing; Video-based interactive
   storytelling; Virtual cinematography; Interactive cinema
AB Interactive storytelling systems usually adopt computer graphics to represent virtual story worlds, which facilitates the dynamic generation of visual content. However, the quality of the images and motion produced by these systems is still inferior compared to the high quality experience found in live-action films. Interactive rates in photorealistic rendering for the film industry will not be possible for decades to come. A promising alternative is the replacement of 3D virtual characters with video sequences with real actors. In this paper, we propose a new method for video-based interactive narratives that uses video compositing algorithms that run at truly interactive frame rates. The proposed method is consistent with plots that are generated by nondeterministic planning algorithms. Moreover, we propose a system of artificial intelligent agents that perform the same roles played by filmmaking professionals. A user evaluation of the proposed method is presented. We believe that future improvements of the techniques proposed in this paper represent an important contribution to the quest for new and more immersive forms of interactive cinema.
C1 [de Lima, Edirlei Soares] Rio de Janeiro State Univ UERJ, Dept Computat Modeling, Nova Friburgo, RJ, Brazil.
   [Feijo, Bruno; Furtado, Antonio L.] Pontifical Catholic Univ Rio de Janeiro, Dept Informat, Rio De Janeiro, RJ, Brazil.
C3 Universidade do Estado do Rio de Janeiro; Pontificia Universidade
   Catolica do Rio de Janeiro
RP de Lima, ES (corresponding author), Rio de Janeiro State Univ UERJ, Dept Computat Modeling, Nova Friburgo, RJ, Brazil.
EM edirlei.lima@uerj.br
RI de Lima, Edirlei Soares/ABB-7904-2020; Feijo, Bruno/AAE-1603-2022
OI de Lima, Edirlei Soares/0000-0002-2617-3394; Feijo,
   Bruno/0000-0003-4441-2632
FU CNPq (National Council for Scientific and Technological Development);
   FAPERJ (Carlos Chagas Filho Research Support Foundation of the State of
   Rio de Janeiro); FINEP (Brazilian Innovation Agency); Ministry of
   Science, Technology and Innovation
FX We would like to thank CNPq (National Council for Scientific and
   Technological Development), FAPERJ (Carlos Chagas Filho Research Support
   Foundation of the State of Rio de Janeiro) and FINEP (Brazilian
   Innovation Agency), which belong to the Ministry of Science, Technology
   and Innovation, for the financial support. Also we are grateful to the
   anonymous reviewers for their valuable comments.
CR Ahanger G, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P526, DOI 10.1109/MMCS.1997.609765
   [Anonymous], 1976, Grammar of the film language
   [Anonymous], 2010, P 18 ACM INT C MULTI
   Barbosa SDJ, 2014, COMPUT ENTERTAIN, V12, DOI 10.1145/2702109.2633407
   Bocconi S, 2006, THESIS
   Bredow R, 2015, COURS 28 SIGGRAPH 20
   Brown Blain., 2011, Cinematography: Theory and Practice
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Brown StuartL., 2009, Play: How It Shapes the Brain, Opens the Imagination, and Invigorates the Soul
   Cavazza M, 2002, IEEE INTELL SYST, V17, P17, DOI 10.1109/MIS.2002.1024747
   Cavazza M., 2007, P 15 ACM INT C MULT, P651, DOI DOI 10.1145/1291233.1291387
   Chabert CF, 2006, ACM SIGGRAPH 2006 SK
   CHUA TS, 1995, ACM T INFORM SYST, V13, P373, DOI 10.1145/211430.211431
   Ciarlini A.E.M., 2005, P ACM SIGCHI INT C A, P133, DOI DOI 10.1145/1178477.1178495
   Davenport G., 1995, P 3 ACM INT C MULT M, P377
   de Lima E. S., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P806, DOI 10.1109/ICME.2012.83
   de Lima ES, 2016, ENTERTAIN COMPUT, V17, P31, DOI 10.1016/j.entcom.2016.08.003
   de Lima ES, 2014, ENTERTAIN COMPUT, V5, P33, DOI 10.1016/j.entcom.2013.06.004
   de Lima ES, 2015, LECT NOTES COMPUT SC, V9353, P286, DOI 10.1007/978-3-319-24589-8_22
   Doria TR, 2008, P ACM MULT 2008 2 AC, P21
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Feijo Bruno, 2014, SBC J 3D INTERACTIVE, V5, P39
   Foster J., 2010, The green screen handbook: real-world production techniques
   Ghallab M., 2004, AUTOMATED PLANNING T
   da Silva FAG, 2010, LECT NOTES ARTIF INT, V6433, P133
   Haykin S., 2010, Neural Networks and Learning Machines
   Joshi N, 2006, ACM T GRAPHIC, V25, P779, DOI 10.1145/1141911.1141955
   Jung Von Matt/Spree, 2010, LAST CALL
   Liang C, 2013, IEEE T MULTIMEDIA, V15, P401, DOI 10.1109/TMM.2012.2229972
   Lima ES, 2012, P 11 BRAZ S COMP GAM, P154
   Mascelli Joseph V., 1965, The Five C's of Cinematography: Motion Picture Filming Techniques Simplified
   Mateas M, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P236
   Mateas M., 2002, THESIS
   Mehlmann G., 2011, P 13 INT C MULT INT, P385
   Mehta SU, 2012, COMPUT GRAPH FORUM, V31, P1501, DOI 10.1111/j.1467-8659.2012.03146.x
   Muller W, 2013, ICIDS 13 P 6 INT C I, P71, DOI DOI 10.1007/978-3-319-02756-2_
   Ng R, 2003, ACM T GRAPHIC, V22, P376, DOI 10.1145/882262.882280
   Piacenza A., 2011, Proceedings of the 19th ACM international conference on Multimedia (MM '11), P223, DOI DOI 10.1145/2072298.2072329
   Pizzi D, 2007, AAAI FALL S INT NARR
   Porter T., 1984, Computers & Graphics, V18, P253
   Riedl MO, 2006, IEEE COMPUT GRAPH, V26, P23, DOI 10.1109/MCG.2006.56
   Schoenau-Fog Henrik, 2011, Interactive Storytelling. Proceedings 4th International Conference on Interactive Digital Storytelling, ICIDS 2011, P219, DOI 10.1007/978-3-642-25289-1_24
   Shen EYT, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P809
   Soares de Lima Edirlei, 2012, Entertainment Computing, 11th International Conference (ICEC - 2012). Proceedings, P1, DOI 10.1007/978-3-642-33542-6_1
   Sun J, 2006, ACM T GRAPHIC, V25, P772, DOI 10.1145/1141911.1141954
   Thompson R., 2009, GRAMMAR OF THE SHOT
   Ursu MF, 2008, MULTIMEDIA SYST, V14, P115, DOI 10.1007/s00530-008-0119-z
NR 47
TC 7
Z9 7
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2333
EP 2357
DI 10.1007/s11042-017-4423-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400037
DA 2024-07-18
ER

PT J
AU Furini, M
AF Furini, Marco
TI On introducing timed tag-clouds in video lectures indexing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video lecture indexing; Timed tag-clouds; Video lecture archives; Video
   lecture browsing
ID QUALITY; SPEECH
AB The amount of digital material in video lecture archives is growing rapidly, causing the search&retrieval process to be time-consuming and almost impractical. Indeed, after the search, students receive a list of videos and often must use VCR-like functions to find the specific piece of video that covers the searched topic. Therefore, a more efficient method for video retrieval in digital video lecture archives is needed. In this paper, we propose VLB (Video Lecture Browsing), a system designed to facilitate both the retrieval of video lectures within video archives and the finding of the most appropriate segment of a video lecture that covers a searched topic by automatically producing a general picture of the contents of a video lecture. To achieve these goals, the system introduces the idea of timed tag-clouds, which are produced with a combination of aural and visual analysis. Results of a MOS evaluation show that users highly appreciate the timed tag-clouds approach and a comparison study against other popular approaches shows that 93 % of users prefer to use VLB to handle video lectures.
C1 [Furini, Marco] Univ Modena & Reggio Emilia, Dipartimento Comunicaz & Econ, Viale Allegri 9, I-42121 Reggio Emilia, Italy.
C3 Universita di Modena e Reggio Emilia
RP Furini, M (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Comunicaz & Econ, Viale Allegri 9, I-42121 Reggio Emilia, Italy.
EM marco.furini@unimore.it
RI Furini, Marco/O-2867-2016
OI Furini, Marco/0000-0003-1094-6521
CR Che X., 2013, P 21 ACM INT C MULT
   Dickson PE., 2012, Proceedings of the 17th ACM Annual Conference on Innovation and Technology in Computer Science Education, ITiCSE '12, DOI DOI 10.1145/2325296.2325334
   Federico M, 2014, MULTIMED TOOLS APPL, V72, P21, DOI 10.1007/s11042-012-1318-3
   Federico Maria., 2012, P INT CROSS DISC C W, P40, DOI DOI 10.1145/2207016.2207053
   Furini M., 2006, WWW 06 P 15 INT C WO, P91
   Furini M, 2007, IEEE ICC, P1679, DOI 10.1109/ICC.2007.281
   Furini M, 2008, IEEE T CONSUM ELECTR, V54, P513, DOI 10.1109/TCE.2008.4560123
   Furini M, 2016, ENTERTAIN COMPUT, V14, P23, DOI 10.1016/j.entcom.2015.08.002
   Furini M, 2009, INFORM-J COMPUT INFO, V33, P77
   Furini M, 2010, MULTIMED TOOLS APPL, V46, P47, DOI 10.1007/s11042-009-0307-7
   Furini M, 2008, CONSUM COMM NETWORK, P1112, DOI 10.1109/ccnc08.2007.251
   Grcar M, 2009, LECT NOTES ARTIF INT, V5782, P730, DOI 10.1007/978-3-642-04174-7_51
   Hayashi Y, 2003, SIGIR P TOR CAN AUG, P441
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Jeong HJ., 2012, COMUNICA O APRESENTA, DOI [DOI 10.1145/2428955.2429011, 10.1145/2428955.2429011]
   Kamabathula V. K., 2011, Proceedings of the 2011 Third International Conference on Technology for Education (T4E 2011), P96, DOI 10.1109/T4E.2011.23
   Keith Toni-Jan, 2013, Proc. ACM SIGCHI Conf. Human Factors in Comput. Syst, P1139
   Kim SK, 2005, LECT NOTES COMPUT SC, V3568, P276
   Liu HY, 2003, ISPA 2003: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, PTS 1 AND 2, P793
   Liu T., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P574
   Repp S, 2008, IEEE T LEARN TECHNOL, V1, P145, DOI 10.1109/TLT.2008.22
   Shin HV, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818123
   Sleit A, 2010, P INT C INT SEM WEB
   Toppin IN, 2011, EDUC INF TECHNOL, V16, P383, DOI 10.1007/s10639-010-9140-x
   Tuna T., 2011, APPL IMAGERY PATTERN, P1
   Wang F, 2008, PATTERN RECOGN, V41, P3257, DOI 10.1016/j.patcog.2008.03.024
   Yang HJ, 2014, IEEE T LEARN TECHNOL, V7, P142, DOI 10.1109/TLT.2014.2307305
   Zhu W, 2001, P IEEE INT C MULT EX, P829
NR 28
TC 12
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 967
EP 984
DI 10.1007/s11042-016-4282-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400041
DA 2024-07-18
ER

PT J
AU Huang, YH
   Lin, TJ
AF Huang, Yong-Huai
   Lin, Tseng-Jung
TI Novel quality-efficient universal demosaicing for arbitrary color filter
   array images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Arbitrary CFA images; Color artifacts; CPSNR; Edge-directed
   interpolation; Fourier transform; Gradient information; Quality of
   demosaiced images; S-CIELAB; Universal demosaicing
ID DIGITAL STILL CAMERAS; INTERPOLATION
AB To save cost, nowadays most digital cameras equip with a single sensor covered with a specific color filter array (CFA) and each pixel in the captured CFA image is composed of only one color. Universal demosaicing is the process to reconstruct the full-RGB (red-green-blue) color image through an input arbitrary CFA image. In this paper, we propose a novel quality-efficient universal demosaicing method which exploits both the edge information and the color correlation during demosaicing and can work for arbitrary RGB and non-RGB CFA images. In the proposed method, two main contributions are made and they are (1) an effective universal edge-directed color difference based interpolation is designed to specially demosaic the edge regions which usually appear severe artifacts by using the existing universal demosaicing methods and (2) a new Fourier transform-based technique combined with the Sobel edge detection is developed to derive the masks for extracting gradient information from arbitrary CFA images so as to provide better weights in the proposed universal edge-directed interpolation, leading to better quality of the demosaiced images. Based on the 24 typical testing images from Kodak collection, experimental results showed that the proposed universal demosaicing method possesses the quality advantage in terms of average color peak signal-to-noise ratio (CPSNR) and S-CIELAB and demonstrates less color artifacts in terms of visual perception when compared with the three state-of-the-art universal demosaicing methods and some existing demosaicing methods designed for non-RGB CFA images.
C1 [Huang, Yong-Huai] Jinwen Univ Sci & Technol, Dept Comp Sci & Informat Engn, 99 Anchung Rd, New Taipei 23154, Taiwan.
   [Lin, Tseng-Jung] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
C3 National Taiwan University of Science & Technology
RP Huang, YH (corresponding author), Jinwen Univ Sci & Technol, Dept Comp Sci & Informat Engn, 99 Anchung Rd, New Taipei 23154, Taiwan.
EM yonghuai@ms28.hinet.net
CR Adams JE, 1996, U.S. Patent, Patent No. 5506619
   Alleysson D, 2005, IEEE T IMAGE PROCESS, V14, P439, DOI 10.1109/TIP.2004.841200
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Chung KH, 2006, IEEE T IMAGE PROCESS, V15, P2944, DOI 10.1109/TIP.2006.877521
   Chung KL, 2008, IEEE T IMAGE PROCESS, V17, P2356, DOI 10.1109/TIP.2008.2005561
   Cok D. R., 1987, US Patent, Patent No. [4,642,678, 4642678]
   Dubois E, 2005, IEEE SIGNAL PROC LET, V12, P847, DOI 10.1109/LSP.2005.859503
   Honda H, 2007, P SPIEX EL IM
   Horé A, 2011, IEEE T IMAGE PROCESS, V20, P3136, DOI 10.1109/TIP.2011.2159229
   HUNT RWG, 1992, MEASURING COLOUR
   Kimmel R, 1999, IEEE T IMAGE PROCESS, V8, P1221, DOI 10.1109/83.784434
   Kuno T, 1999, IEEE T CONSUM ELECTR, V45, P259, DOI 10.1109/30.754444
   Laroche C., 1994, United States Patent, Patent No. 5373322
   Lian NX, 2007, IEEE T IMAGE PROCESS, V16, P2515, DOI 10.1109/TIP.2007.904459
   Lukac R, 2005, PATTERN RECOGN, V38, P2208, DOI 10.1016/j.patcog.2005.04.008
   Lukac R, 2006, SIGNAL PROCESS, V86, P1559, DOI 10.1016/j.sigpro.2005.09.005
   MAHNY M, 1994, COLOR RES APPL, V19, P105
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   Sakamoto T, 1998, IEEE T CONSUM ELECTR, V44, P1342, DOI 10.1109/30.735836
   Sugiyama T., 2005, U. S. Patent App. No, Patent No. 0231618
   Yang WJ, 2013, IEEE T CIRC SYST VID, V23, P591, DOI 10.1109/TCSVT.2012.2210805
NR 21
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 1475
EP 1499
DI 10.1007/s11042-016-4326-x
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400061
DA 2024-07-18
ER

PT J
AU Chang, YT
   Lin, YC
   Chen, YC
   Wang, WS
AF Chang, Yao-Tang
   Lin, Yih-Chuan
   Chen, Yu-Chang
   Wang, Wei-Siang
TI Scrambling-based cryptography with a programmable SLM-based
   filter-triggered chaotic tent/hologram mapping algorithm for secure
   H.264/AVC video streaming over a WDM network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scrambling-based cryptography; Chaos-based secret sequence; Spatial
   light modulator based filter (SLM based filter); Wavelength division
   multiplexing network (WDM network)
ID OPTICAL CDMA; PERFORMANCE; ENCRYPTION; PON
AB Traditional chaos-based encryption techniques use pseudorandom codes to implement encryption (e.g., XOR; exclusive or operation) directly, resulting in the violation of requirements for media compression formats for image transmission. In this study, a programmable spatial light modulator (SLM)-based optical wavelength filter was investigated for implementing a scrambling-based cryptographic scheme in WDM networks. A new chaotic tent/hologram mapping algorithm (THmA) and advanced THmA are proposed for triggering the programmable SLM-based filter array. Similarly, an approximately symmetric scheme was used to configure a scrambling SLM-based decryption scheme for performing decryption operations when the initial value and control parameters of the chaotic sequence as individual secret keys are communicated in advance over a private channel. The proposed scheme was evaluated using video application-layer experiments. The results revealed that compared with conventional reconfigurable schemes involving triggered registers and switches behind an AWG router, the number of code space sizes involved in the proposed cryptographic scheme increased by more than 1.31E + 89 times, thereby avoiding eavesdropping attacks in the physical layer. Furthermore, on the basis of the reduced peak signal-to-noise ratio of the encrypted videos and the unidentifiability of the videos to unauthorized users, the scrambling efficiency of the proposed scheme was sufficiently high.
C1 [Chang, Yao-Tang] Kao Yuan Univ, Dept Informat Technol, Kaohsiung 82151, Taiwan.
   [Lin, Yih-Chuan; Wang, Wei-Siang] Natl Formosa Univ, Dept Comp Sci & Informat Engn, Huwei Township 63201, Yunlin, Taiwan.
   [Chen, Yu-Chang] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 701, Taiwan.
C3 National Formosa University; National Cheng Kung University
RP Chang, YT (corresponding author), Kao Yuan Univ, Dept Informat Technol, Kaohsiung 82151, Taiwan.
EM t10066@cc.kyu.edu.tw
FU Ministry of Science and Technology, Taiwan [MOST 105-2221-E-244-004]
FX This study was supported under grant No. MOST 105-2221-E-244-004 from
   the Ministry of Science and Technology, Taiwan. We thank Prof. Jen-Fa
   Huang for providing invaluable suggestion.
CR Ahadpour S., 2012, IJCSI INT J COMPUT S, P449
   AHADPOUR S., 2012, INT J COMPUTER APPL, V42, P25
   Baugher M., 2004, 3711 IETF RFC
   Borujeni S.E., 2015, APPL MATH, V6, P773, DOI [10.4236/am.2015.65073, DOI 10.4236/am.2015.65073]
   Chang Y-T, 2017, LNCS
   Chang YT, 2007, J LIGHTWAVE TECHNOL, V25, P1931, DOI 10.1109/JLT.2007.901333
   Chang YT, 2016, MULTIMED TOOLS APPL, V75, P9837, DOI 10.1007/s11042-015-2784-1
   Chang YT, 2015, COMPUT ELECT ENG
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Chiaraluce F, 2002, IEEE T CONSUM ELECTR, V48, P838, DOI 10.1109/TCE.2003.1196410
   Devaney RL., 1989, An introduction to chaotic dynamical systems, V2
   DIXIT S, 2003, IP WDM BUILDING NEXT
   Dufaux F, 2008, IEEE T CIRC SYST VID, V18, P1168, DOI 10.1109/TCSVT.2008.928225
   Huang J.-F., 2014, OPT ENG, V53
   Huang JF, 2014, PROCEDIA COMPUT SCI, V34, P39, DOI 10.1016/j.procs.2014.07.024
   Karafolas N., 1996, Optical Fiber Technology: Materials, Devices and Systems, V2, P149, DOI 10.1006/ofte.1996.0017
   KAVEHRAD M, 1995, J LIGHTWAVE TECHNOL, V13, P534, DOI 10.1109/50.372451
   Kim KS, 2003, INFORM SCIENCES, V149, P21, DOI 10.1016/S0020-0255(02)00241-4
   Kitayama K, 2006, J LIGHTWAVE TECHNOL, V24, P1654, DOI 10.1109/JLT.2006.871030
   Kocarev L, 2011, STUD COMPUT INTELL, V354, P1, DOI 10.1007/978-3-642-20542-2
   Kramer G, 2002, IEEE COMMUN MAG, V40, P66, DOI 10.1109/35.983910
   LI TY, 1975, AM MATH MON, V82, P985, DOI 10.2307/2318254
   MARIC SV, 1993, IEEE T COMMUN, V41, P1217, DOI 10.1109/26.231965
   Massoudi A, 2008, EURASIP J INF SECUR, DOI 10.1155/2008/179290
   MAY RM, 1976, NATURE, V261, P459, DOI 10.1038/261459a0
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Parker MC, 1998, J LIGHTWAVE TECHNOL, V16
   Petzold C., 1998, Programming Windows, Vfifth
   Sakthidasan K., 2011, INT J NFO ED TECH, V1, P137, DOI DOI 10.7763/IJIET.2011.V1.23
   SALEHI JA, 1989, IEEE T COMMUN, V37, P824, DOI 10.1109/26.31181
   Shake TH, 2005, J LIGHTWAVE TECHNOL, V23, P1652, DOI 10.1109/JLT.2005.844504
   Shake TH, 2005, J LIGHTWAVE TECHNOL, V23, P655, DOI 10.1109/JLT.2004.838844
   Suhring K., 2009, H 264 AVC REFERENCE
   Tseng SP, 2011, IEEE ICC
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wu BB, 2006, OPT EXPRESS, V14, P3738, DOI 10.1364/OE.14.003738
NR 36
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25421
EP 25453
DI 10.1007/s11042-017-4525-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300047
DA 2024-07-18
ER

PT J
AU Chang, YC
AF Chang, Yen-Ching
TI An almost automatic image fusion scheme for balancing clarity and visual
   effects
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-focus; Image fusion; Focus measure; Sharpness measure
ID OF-THE-ART; WAVELET TRANSFORM; FOCUS; PERFORMANCE; CRITERION
AB Multi-focus image fusion aims to combine multiple images with different focuses to form a single sharp image. The basic principle is to first compare the local content information of every block or pixel from distinct input images, and then choose the largest contrast among them because the maximum is generally viewed as the clearest. However, this is usually impossible unless a perfect sharpness measure is adopted. For some cases, especially with smooth and plain areas on images, a higher value of sharpness measurement does not always come from a more focused region and thus a wrong selection of a block or pixel is prone to bring about blocking effects. In addition, how to select the optimal block size suitable for all sorts of images is another relatively important issue, but so far no existing method has provided the skill. On the other hand, modern techniques tend to obtain an effective algorithm by some complicated procedures, thereby increasing computational time and being difficult to implement. In order to effectively overcome potential blocking effects and provide a simple as well as easily extended approach, an almost automatic image fusion scheme for balancing clarity and visual effects, a combination of a sharpness measure and the occurrence rate of the maximum sharpness for each pixel lying in different block sizes, is proposed. Through the proposed scheme, three regions are naturally obtained: the focus region, the transition region and the blur region. Experimental results confirm that the proposed scheme does efficiently achieve much satisfactory visual quality.
C1 [Chang, Yen-Ching] Chung Shan Med Univ, Dept Med Informat, Taichung 40201, Taiwan.
   [Chang, Yen-Ching] Chung Shan Med Univ Hosp, Dept Med Imaging, Taichung 40201, Taiwan.
C3 Chung Shan Medical University; Chung Shan Medical University; Chung Shan
   Medical University Hospital
RP Chang, YC (corresponding author), Chung Shan Med Univ, Dept Med Informat, Taichung 40201, Taiwan.; Chang, YC (corresponding author), Chung Shan Med Univ Hosp, Dept Med Imaging, Taichung 40201, Taiwan.
EM nicholas@csmu.edu.tw
FU National Science Council, Republic of China [NSC 101-2221-E-040-010]
FX This work was supported by the National Science Council, Republic of
   China, under Grant NSC 101-2221-E-040-010.
CR Aslantas V, 2009, OPT COMMUN, V282, P3231, DOI 10.1016/j.optcom.2009.05.021
   Bai LY, 2015, OPTIK, V126, P4804, DOI 10.1016/j.ijleo.2015.09.201
   Bhavana V, 2015, PROCEDIA COMPUT SCI, V70, P625, DOI 10.1016/j.procs.2015.10.057
   Buerkle A, 2001, P SOC PHOTO-OPT INS, V4568, P187, DOI 10.1117/12.444125
   Chen SH, 2008, SENSORS-BASEL, V8, P2500, DOI 10.3390/s8042500
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   Hu JW, 2012, INFORM FUSION, V13, P196, DOI 10.1016/j.inffus.2011.01.002
   Wei H, 2007, PATTERN RECOGN LETT, V28, P493, DOI 10.1016/j.patrec.2006.09.005
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Kotwal K, 2013, INFORM FUSION, V14, P5, DOI 10.1016/j.inffus.2011.03.008
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li ST, 2002, PATTERN RECOGN LETT, V23, P985, DOI 10.1016/S0167-8655(02)00029-6
   Myna A. N., 2014, INT J EMERGING TREND, V3, P131
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Pan JJ, 2016, DIGIT SIGNAL PROCESS, V50, P61, DOI 10.1016/j.dsp.2015.12.003
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Saeedi J, 2013, PATTERN ANAL APPL, V16, P365, DOI 10.1007/s10044-011-0235-9
   Sahu D., 2012, Int. J. Mod. Eng. Res. (IJMER), V2, P4298
   Tian J, 2011, OPT COMMUN, V284, P80, DOI 10.1016/j.optcom.2010.08.085
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
   Wong A, 2008, PATTERN RECOGN LETT, V29, P173, DOI 10.1016/j.patrec.2007.08.018
   Xiao JS, 2016, SIGNAL PROCESS, V125, P171, DOI 10.1016/j.sigpro.2016.01.014
   Xu XJ, 2016, BIOMED SIGNAL PROCES, V27, P103, DOI 10.1016/j.bspc.2016.02.008
   Xu ZP, 2014, INFORM FUSION, V19, P38, DOI 10.1016/j.inffus.2013.01.001
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Yu BT, 2016, NEUROCOMPUTING, V182, P1, DOI 10.1016/j.neucom.2015.10.084
   Zhang XL, 2016, SIGNAL PROCESS, V123, P127, DOI 10.1016/j.sigpro.2016.01.006
NR 32
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25455
EP 25476
DI 10.1007/s11042-017-4588-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300048
DA 2024-07-18
ER

PT J
AU Hong, XD
   Yu, ZT
   Tang, MM
   Xian, YT
AF Hong, Xudong
   Yu, Zhengtao
   Tang, Moming
   Xian, Yantuan
TI Cross-lingual event-centered news clustering based on elements semantic
   correlations of different news
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-lingual; Document clustering; Bipartite graph; Spectral
   clustering; GVSM
AB Cross-lingual event-centered news clustering aims to perform the clustering of news documents written in different languages into groups of documents that describe the same event. In order to solve the problem of similarity computation between bi-lingual documents, this paper propose a new method based on semantic correlations of news elements. First, using bilingual entity lexical and terms co-occurrences in news to acquire the semantic correlation of news elements in different language. Then, we compute the similarity between news in different languages using the GVSM model on this basis. Finally, Spectral Clustering is applied to categorize news stories. Experimental results show our method achieves promising results on the F value.
C1 [Hong, Xudong] Anhui Univ Technol, Sch Comp Sci & Technol, Maanshan 243002, Peoples R China.
   [Yu, Zhengtao; Tang, Moming; Xian, Yantuan] Kunming Univ Sci & Technol, Sch Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
C3 Anhui University of Technology; Kunming University of Science &
   Technology
RP Yu, ZT (corresponding author), Kunming Univ Sci & Technol, Sch Informat Engn & Automat, Kunming 650500, Yunnan, Peoples R China.
EM ztyu@hotmail.com
OI Yu, Zhengtao/0000-0003-1094-5668
FU National Natural Science Foundation of China [61175068]
FX Supported by the National Natural Science Foundation of China (Grant No.
   61175068).
CR Boyd-Graber J, 2012, C UNC TAINT ART ART, P75
   Dhillon I. S., 2001, KDD-2001. Proceedings of the Seventh ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P269, DOI 10.1145/502512.502550
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606
   He X, 2002, COMPUT STAT DATA AN, V41, P19, DOI 10.1016/S0167-9473(02)00070-1
   Hu XH, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P389
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Kim YM, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P821
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Leek T, 2000, TDT EVALUATION SYSTE, P894
   Mathieu B, 2004, COMPUTER ASSISTED IN, P116
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Mimno David, 2009, EMNLP, P880
   Navigli R, 2012, ARTIF INTELL, V193, P217, DOI 10.1016/j.artint.2012.07.001
   Ni X., 2009, P 18 INT C WORLD WID, P1155
   Pouliquen B, 2004, INT C COMP LING RALF, P20
   Romeo S., 2014, SEMANTIC BASED MULTI
   Tang G, 2014, INT J PATTERN RECOGN, V29, P1
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wei CP, 2008, DECIS SUPPORT SYST, V45, P606, DOI 10.1016/j.dss.2007.07.008
   Xu W., 2003, P 26 ANN INT ACM SIG, P267
   Yogatama D, 2009, C EMP METH NAT LANG, P871
NR 21
TC 5
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25129
EP 25143
DI 10.1007/s11042-017-4838-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300031
DA 2024-07-18
ER

PT J
AU Hu, HT
   Chang, JR
   Hsu, LY
AF Hu, Hwai-Tsu
   Chang, Jieh-Ren
   Hsu, Ling-Yuan
TI Windowed and distortion-compensated vector modulation for blind audio
   watermarking in DWT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind audio watermarking; Windowed vector modulation; Distortion
   compensation; Discrete wavelet transform; Rational dither modulation
ID QUANTIZATION INDEX MODULATION; TIME-DOMAIN; ROBUST; SCHEME; ALGORITHM;
   DCT; SYNCHRONIZATION; CAPACITY
AB A windowed vector modulation (WVM) scheme incorporable with distortion compensation is proposed to enhance the imperceptibility and robustness of blind audio watermarking in the norm space of discrete wavelet transform (DWT) domain. The merits of WVM are demonstrated through performance comparison among three DWT-based watermarking methods that adaptively modulate the vectors collected from the approximation subband after 2-level DWT decomposition of audio signals. The incorporation of window weighting into modulation formulation can smooth the transitions across adjacent vectors, while the employment of distortion compensation allows the WVM to be executable using larger quantization steps without introducing additional distortion. Experiment results confirm that the perceptual quality is noticeably improved through the windowing process, and the bit error rates of retrieved watermarks are manifestly reduced after integrating WVM with distortion compensation.
C1 [Hu, Hwai-Tsu; Chang, Jieh-Ren] Natl Ilan Univ, Dept Elect Engn, Yi Lan 26041, Taiwan.
   [Hsu, Ling-Yuan] St Marys Jr Coll Med Nursing & Management, Dept Informat Management, Yi Lan 26644, Taiwan.
C3 National Ilan University
RP Hu, HT (corresponding author), Natl Ilan Univ, Dept Elect Engn, Yi Lan 26041, Taiwan.
EM hthu@mail.niu.edu.tw
OI Hsu, Ling-Yuan/0000-0002-9543-6872
FU Ministry of Science and Technology, Taiwan, ROC [MOST
   104-2221-E-197-023]
FX This research work was supported by the Ministry of Science and
   Technology, Taiwan, ROC under Grant MOST 104-2221-E-197-023.
CR Bassia P, 2001, IEEE T MULTIMEDIA, V3, P232, DOI 10.1109/6046.923822
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Daubechies I., 1992, 10 LECT WAVELETS
   He X., 2008, WATERMARKING AUDIO K
   Hu HT, 2016, CIRC SYST SIGNAL PR, V35, P553, DOI 10.1007/s00034-015-0074-9
   Hu HT, 2015, SIGNAL PROCESS, V109, P226, DOI 10.1016/j.sigpro.2014.11.011
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Hu HT, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-12
   Hu HT, 2012, SIGNAL PROCESS, V92, P1109, DOI 10.1016/j.sigpro.2011.11.001
   Kabal P., 2002, MMSP Lab Technical Report
   Katzenbeisser S., 2000, ARTECH HOUSE COMPUTE
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Lei BY, 2012, SIGNAL PROCESS, V92, P1985, DOI 10.1016/j.sigpro.2011.12.021
   Li W, 2006, IEEE T MULTIMEDIA, V8, P60, DOI 10.1109/TMM.2005.861291
   Li X, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P397, DOI 10.1109/ICME.2000.869624
   Lie WN, 2006, IEEE T MULTIMEDIA, V8, P46, DOI 10.1109/TMM.2005.861292
   Liu SC, 2006, J INF SCI ENG, V22, P535
   Megías D, 2010, SIGNAL PROCESS, V90, P3078, DOI 10.1016/j.sigpro.2010.05.012
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Tachibana R, 2002, SIGNAL PROCESS, V82, P1455, DOI 10.1016/S0165-1684(02)00284-0
   Wang HQ, 2008, APPL ACOUST, V69, P868, DOI 10.1016/j.apacoust.2007.06.001
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wang XY, 2009, PATTERN RECOGN, V42, P3057, DOI 10.1016/j.patcog.2009.01.015
   Wang XK, 2014, MULTIMED TOOLS APPL, V71, P1157, DOI 10.1007/s11042-012-1259-x
   Wang XK, 2013, SIGNAL PROCESS, V93, P913, DOI 10.1016/j.sigpro.2012.11.003
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang S., 2011, EURASIP J ADV SIG PR, P1
   Yeo IK, 2003, IEEE T SPEECH AUDI P, V11, P381, DOI 10.1109/TSA.2003.812145
NR 30
TC 9
Z9 11
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26723
EP 26743
DI 10.1007/s11042-016-4202-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500053
DA 2024-07-18
ER

PT J
AU Su, X
   Wang, Y
   Choi, D
   Kim, P
   Choi, C
AF Su, Xin
   Wang, Yang
   Choi, Dongmin
   Kim, Pankoo
   Choi, Chang
TI Channel allocation and power control schemes for cross-tier 3GPP LTE
   networks to support multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3GPP LTE; Femetocell; Interference graph; Game theory; Channel
   allocation; Power control; Multimedia
ID FEMTOCELL NETWORKS
AB In this paper, we present the framework of a channel allocation (CA) and power control (PC) schemes for the minimization of interference in cross-tier 3GPP LTE networks that aim to support internet of multimedia things. Channel allocation scheme based on an interference graph preserving the minimum number of interfered MUEs by femtocells (IG-MIM) is proposed to mitigate interference amongst femtocells, and a game theory based power control algorithm is also proposed to reduce interference to surrounding macrocell users (MUEs). The proposed IG-MIM scheme constructs the interference graph based on a predefined threshold and allocates the subchannels to the femtocells that maintain the smallest number of interfered MUEs. For the power control, we design a payoff function based on the rewards from the achieved data rates and the penalties from the interference in regards to its adjacent femtocells. The simulation results show that the IG-MIM channel allocation significantly improves the SINR performance for the femtocell users (FUEs) being served; the game theory based power control decreases the power requirements of a femtocell and alleviates the interference to the MUEs.
C1 [Su, Xin] Hohai Univ, Coll IOT Engn, Changzhou Key Lab Robot & Intelligent Technol, 200 North Jinling Rd, Changzhou 213022, Peoples R China.
   [Wang, Yang] Guangdong Planning & Designing Inst Telecommun CO, Guangzhou 510630, Guangdong, Peoples R China.
   [Choi, Dongmin] Chosun Univ, Div Undeclared Majors, Gwangju, South Korea.
   [Kim, Pankoo; Choi, Chang] Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
C3 Hohai University; Chosun University; Chosun University
RP Choi, C (corresponding author), Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
EM enduranceaura@gmail.com
RI Choi, Chang/U-7208-2019
OI Choi, Chang/0000-0002-2276-2378
FU National Research Foundation of Korea (NRF) - Korea government(MSIP)
   [NRF-2016R1A2B4012638]; Natural Science Foundation of Jiangsu Province
   [BK20160287]; Fundamental Research Funds for the Central Universities
   [2015B30614]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government(MSIP) (No.
   NRF-2016R1A2B4012638). This research was also supported by the Natural
   Science Foundation of Jiangsu Province under Grant BK20160287, and in
   part by the Fundamental Research Funds for the Central Universities
   under Grant 2015B30614.
CR Alpcan T, 2009, 2009 INTERNATIONAL CONFERENCE ON GAME THEORY FOR NETWORKS (GAMENETS 2009), P164, DOI 10.1109/GAMENETS.2009.5137398
   [Anonymous], 2016, MOB INF SYST
   [Anonymous], 2008, IPSAS" workshop at the University of Napoli "Parthenope"
   [Anonymous], 2010, document TR 36
   [Anonymous], P INT C MOB NETW MAN
   [Anonymous], 36921 3GPP TR
   [Anonymous], 2009, 3GPP TSG RAN WG4
   [Anonymous], IT CONV PRACT INPRA
   [Anonymous], 2019, 36211 3GPP TS
   Bello-Orgaz G, 2016, INFORM FUSION, V28, P45, DOI 10.1016/j.inffus.2015.08.005
   Bharucha Z, 2010, EURASIP J WIREL COMM, DOI 10.1155/2010/143413
   Chandrasekhar V, 2008, IEEE COMMUN MAG, V46, P59, DOI 10.1109/MCOM.2008.4623708
   Chandrasekhar V, 2009, IEEE T WIREL COMMUN, V8, P4316, DOI 10.1109/TWC.2009.081386
   Claussen H, 2009, BELL LABS TECH J, V14, P155, DOI 10.1002/bltj.20378
   DEBREU G, 1952, P NATL ACAD SCI USA, V38, P886, DOI 10.1073/pnas.38.10.886
   FAN K, 1952, P NATL ACAD SCI USA, V38, P121, DOI 10.1073/pnas.38.2.121
   GLICKSBERG IL, 1952, P AM MATH SOC, V3, P170, DOI 10.2307/2032478
   Liu X., 2013, ADV DIFFER EQU-NY, V2013
   Nguyen DT, 2017, FUTURE GENER COMP SY, V66, P137, DOI 10.1016/j.future.2016.04.012
   Richard JL, 2003, GAME THEORETIC LOOK
   Pham XH, 2016, ACTA POLYTECH HUNG, V13, P195
   Youngs D., 1995, 5 IEE C TELECOMMUNIC, P179
   Zhang KZ, 2010, LECT NOTES COMPUT SC, V6129, P1, DOI 10.1007/978-3-642-13509-5_1
   Zheng K, 2011, IET COMMUN, V5, P2533, DOI 10.1049/iet-com.2011.0134
NR 24
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 25875
EP 25891
DI 10.1007/s11042-016-4320-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500019
DA 2024-07-18
ER

PT J
AU Wang, XY
   Li, S
   Liu, YN
   Niu, Y
   Yang, HY
   Zhou, ZL
AF Wang, Xiang-Yang
   Li, Shuo
   Liu, Yu-Nan
   Niu, Ying
   Yang, Hong-Ying
   Zhou, Zhi-Li
TI A new keypoint-based copy-move forgery detection for small smooth
   regions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Superpixel; Adaptive feature points
   detector; Exponent moments; Reversed generalized 2 nearest-neighbor
AB Copy-move forgery is one of the most common types of image forgeries, where a region from one part of an image is copied and pasted onto another part, thereby concealing the image content in the latter region. Keypoint based copy-move forgery detection approaches extract image feature points and use local visual features, rather than image blocks, to identify duplicated regions. Keypoint based approaches exhibit remarkable performance with respect to computational cost, memory requirement, and robustness. But unfortunately, they usually do not work well if smooth background areas are used to hide small objects, as image keypoints cannot be extracted effectively from those areas. It is a challenging work to design a keypoint-based method for detecting forgeries involving small smooth regions. In this paper, we propose a new keypoint-based copy-move forgery detection for small smooth regions. Firstly, the original tampered image is segmented into nonoverlapping and irregular superpixels, and the superpixels are classified into smooth, texture and strong texture based on local information entropy. Secondly, the stable image keypoints are extracted from each superpixel, including smooth, texture and strong texture ones, by utilizing the superpixel content based adaptive feature points detector. Thirdly, the local visual features, namely exponent moments magnitudes, are constructed for each image keypoint, and the best bin first and reversed generalized 2 nearest-neighbor algorithm are utilized to find rapidly the matching image keypoints. Finally, the falsely matched image keypoints are removed by customizing the random sample consensus, and the duplicated regions are localized by using zero mean normalized cross-correlation measure. Extensive experimental results show that the newly proposed scheme can achieve much better detection results for copy-move forgery images under various challenging conditions, such as geometric transforms, JPEG compression, and additive white Gaussian noise, compared with the existing state-of-the-art copy-move forgery detection methods.
C1 [Wang, Xiang-Yang; Li, Shuo; Liu, Yu-Nan; Niu, Ying; Yang, Hong-Ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
   [Zhou, Zhi-Li] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Zhou, Zhi-Li] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
C3 Liaoning Normal University; Nanjing University of Information Science &
   Technology; Nanjing University of Information Science & Technology
RP Wang, XY; Yang, HY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Yang, Jing/JFK-4046-2023; Liu, Yunan/JGM-3801-2023; Liu,
   Yunan/GXH-9776-2022
OI Yang, Jing/0009-0004-8274-9863; 
FU National Natural Science Foundation of China [61472171, 61272416];
   Natural Science Foundation of Liaoning Province of China [201602463];
   Priority Academic Program Development of Jiangsu Higher Education
   Institutions; Jiangsu Collaborative Innovation Center on Atmospheric
   Environment and Equipment Technology
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61472171 & 61272416, the Natural Science
   Foundation of Liaoning Province of China under Grant No. 201602463, A
   Project Funded by the Priority Academic Program Development of Jiangsu
   Higher Education Institutions, and Jiangsu Collaborative Innovation
   Center on Atmospheric Environment and Equipment Technology.
CR Al-Qershi OM, 2015, LECT NOTES COMPUT SC, V9023, P485, DOI 10.1007/978-3-319-19321-2_37
   Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], J INNER MONGOLIA NOR
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bi XL, 2016, INFORM SCIENCES, V345, P226, DOI 10.1016/j.ins.2016.01.061
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Caldelli R., 2012, 2012 5th International Symposium on Communications Control and Signal Processing, P1
   Chambers J, 2015, MULTIMED TOOLS APPL, V74, P4013, DOI 10.1007/s11042-013-1809-x
   Chen BJ, 2015, J MATH IMAGING VIS, V51, P124, DOI 10.1007/s10851-014-0511-6
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Costanzo A, 2014, IEEE T INF FOREN SEC, V9, P1450, DOI 10.1109/TIFS.2014.2337654
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Da S, 2009, RES DENSITY BASED IM
   Davarzani R, 2013, FORENSIC SCI INT, V231, P61, DOI 10.1016/j.forsciint.2013.04.023
   Fattah SA, 2014, MIDWEST SYMP CIRCUIT, P801, DOI 10.1109/MWSCAS.2014.6908536
   Imamoglu MB, 2013, 2013 8TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONICS ENGINEERING (ELECO), P311
   Jaberi M, 2014, MACH VISION APPL, V25, P451, DOI 10.1007/s00138-013-0522-0
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Ketenci S, 2014, INT CONF SYST SIGNAL, P171
   Lee JC, 2015, INFORM SCIENCES, V321, P250, DOI 10.1016/j.ins.2015.03.009
   Lee JC, 2015, J VIS COMMUN IMAGE R, V31, P320, DOI 10.1016/j.jvcir.2015.07.007
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li Y, 2015, J ELECT INF TECHNOL, P1767
   Li YL, 2015, NEUROCOMPUTING, V149, P736, DOI 10.1016/j.neucom.2014.08.003
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Ustubioglu B, 2015, IEEE SIGN PROC COMM, P1741
   Wang XY, 2015, COMPUT ELECTR ENG, V46, P403, DOI 10.1016/j.compeleceng.2015.04.001
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   YunJie Wu., 2014, SCI CHINA INFORM SCI, V57, P1
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
   Zhou ZL, 2017, IEEE T INF FOREN SEC, V12, P48, DOI 10.1109/TIFS.2016.2601065
NR 42
TC 28
Z9 28
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23353
EP 23382
DI 10.1007/s11042-016-4140-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700011
DA 2024-07-18
ER

PT J
AU Xu, LW
   Gulliver, TA
AF Xu, Lingwei
   Gulliver, T. Aaron
TI Performance analysis for M2M video transmission cooperative networks
   using transmit antenna selection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE M2M video transmission; Amplify-and-forward; Outage probability;
   Transmit antenna selection; Power allocation
ID FADING CHANNELS; NAKAGAMI; PROTOCOLS
AB Due to mobile-to-mobile (M2M) communication unpredictability and difficulty in securing reliable channels, transmission of video over M2M networks is challenging. Cooperative communication and transmit antenna selection are two different techniques which can benefit from path diversity for robust video communication. In this paper, the outage probability (OP) performance of multi-relay-based M2M video transmission networks with transmit antenna selection over N-Nakagami fading channels is investigated. The exact closed-form expressions for OP of optimal and suboptimal TAS schemes are derived. The power allocation problem is formulated for performance optimization. Then the OP performance under different conditions is evaluated through numerical simulations to verify the analysis. The simulation results showed that the power-allocation parameter has a significant effect on the OP performance.
C1 [Xu, Lingwei] Qingdao Univ Sci & Technol, Dept Informat Sci & Technol, Qingdao 266061, Peoples R China.
   [Gulliver, T. Aaron] Univ Victoria, Dept Elect & Comp Engn, Victoria, BC V8W 2Y2, Canada.
C3 Qingdao University of Science & Technology; University of Victoria
RP Xu, LW (corresponding author), Qingdao Univ Sci & Technol, Dept Informat Sci & Technol, Qingdao 266061, Peoples R China.
EM gaomilaojia2009@163.com
RI Xu, Lingwei/I-1675-2019; Gulliver, Aaron/K-7925-2012
OI Xu, Lingwei/0000-0002-2169-6356
FU National Natural Science Foundation of China [61304222, 61301139];
   Shandong Province Outstanding Young Scientist Award Fund [2014BSE28032]
FX The authors would like to thank the referees and editors for providing
   very helpful comments and suggestions. This project was supported by
   National Natural Science Foundation of China (no. 61304222, no.
   61301139), Shandong Province Outstanding Young Scientist Award Fund (no.
   2014BSE28032).
CR AbdelNabi AA, 2016, IEEE T COMMUN, V64, P525, DOI 10.1109/TCOMM.2015.2496291
   Elkashlan M, 2012, IEEE T VEH TECHNOL, V61, P1416, DOI 10.1109/TVT.2012.2185259
   Gong FK, 2012, IET COMMUN, V6, P3165, DOI 10.1049/iet-com.2012.0215
   Gong FK, 2011, IEEE COMMUN LETT, V15, P34, DOI 10.1109/LCOMM.2010.111910.101683
   Huo YK, 2014, IEEE VEH TECHNOL MAG, V9, P104, DOI 10.1109/MVT.2014.2334411
   Ilhan H, 2009, IEEE T VEH TECHNOL, V58, P3301, DOI 10.1109/TVT.2009.2014685
   Karagiannidis GK, 2007, IEEE T COMMUN, V55, P1453, DOI 10.1109/TCOMM.2007.902497
   Kumbhani B, 2015, IETE TECH REV, V32, P252, DOI 10.1080/02564602.2015.1010612
   Mumtaz S, 2014, IEEE WIREL COMMUN, V21, P14, DOI 10.1109/MWC.2014.6940429
   Ochiai H, 2006, IEEE T INFORM THEORY, V52, P4299, DOI 10.1109/TIT.2006.880055
   Salo J, 2006, IEEE T ANTENN PROPAG, V54, P3114, DOI 10.1109/TAP.2006.883964
   Seyfi M, 2011, IEEE SIGNAL PROC LET, V18, P134, DOI 10.1109/LSP.2010.2102017
   Shankar PM, 2013, ANN TELECOMMUN, V68, P477, DOI 10.1007/s12243-012-0338-3
   Talha B, 2011, IEEE VEH TECHNOL MAG, V6, P33, DOI 10.1109/MVT.2011.940793
   Xu L., 2015, INT J SIGNAL PROCESS, V8, P357, DOI DOI 10.14257/IJSIP.2015.8.3.33
   Xu L.W., 2015, INT J SIGNAL PROCESS, V8, P249, DOI DOI 10.14257/IJSIP.2015.8.5.26
   Xu L. W., 2015, INT J MULTIMEDIA UBI, V10, P211
   Xu LW, 2016, WIREL NETW, V22, P1595, DOI 10.1007/s11276-015-1055-4
   Xu LW, 2015, J APPL SCI ENG, V18, P309, DOI 10.6180/jase.2015.18.3.12
   Xu LW, 2015, KSII T INTERNET INF, V9, P3983, DOI 10.3837/tiis.2015.10.012
NR 20
TC 11
Z9 11
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23891
EP 23902
DI 10.1007/s11042-016-4138-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700035
DA 2024-07-18
ER

PT J
AU Zhou, XF
   Liu, Z
   Sun, GL
   Wang, XY
AF Zhou, Xiaofei
   Liu, Zhi
   Sun, Guangling
   Wang, Xiangyang
TI Adaptive saliency fusion based on quality assessment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency model; Adaptive fusion; Quality assessment; Boosting
ID OBJECT DETECTION; MODEL; DENSE
AB A variety of saliency models based on different schemes and methods have been proposed in the recent years, and the performance of these models often vary with images and complement each other. Therefore it is a natural idea whether we can elevate saliency detection performance by fusing different saliency models. This paper proposes a novel and general framework to adaptively fuse saliency maps generated using various saliency models based on quality assessment of these saliency maps. Given an input image and its multiple saliency maps, the quality features based on the input image and saliency maps are extracted. Then, a quality assessment model, which is learned using the boosting algorithm with multiple kernels, indicates the quality score of each saliency map. Next, a linear summation method with power-law transformation is exploited to fuse these saliency maps adaptively according to their quality scores. Finally, a graph cut based refinement method is exploited to enhance the spatial coherence of saliency and generate the high-quality final saliency map. Experimental results on three public benchmark datasets with state-of-the-art saliency models demonstrate that our saliency fusion framework consistently outperforms all saliency models and other fusion methods, and effectively elevates saliency detection performance.
C1 [Zhou, Xiaofei; Liu, Zhi; Sun, Guangling; Wang, Xiangyang] Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
C3 Shanghai University
RP Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai, Peoples R China.
EM zxforchid@outlook.com; liuzhisjtu@163.com; sunguangling@shu.edu.cn;
   wangxiangyang@shu.edu.cn
RI Xiaofei, Zhou/AAE-8347-2020; LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Foundation of China [61471230, 61171144];
   Program for Professor of Special Appointment (Eastern Scholar) at
   Shanghai Institutions of Higher Learning
FX This work was supported by National Natural Science Foundation of China
   under Grant No. 61471230 and No. 61171144, and by the Program for
   Professor of Special Appointment (Eastern Scholar) at Shanghai
   Institutions of Higher Learning.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], P AS C COMP VIS
   [Anonymous], 2013, MOL CELLULAR BIOCH
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], THUR15000 DATASET
   Aytekin Ç, 2014, INT C PATT RECOG, P112, DOI 10.1109/ICPR.2014.29
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Cao Z., 2007, P 24 INT C MACHINE L, P129, DOI DOI 10.1145/1273496.1273513
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Du H, 2013, J VIS COMMUN IMAGE R, V24, P499, DOI 10.1016/j.jvcir.2013.03.003
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Fang YM, 2012, IEEE T MULTIMEDIA, V14, P187, DOI 10.1109/TMM.2011.2169775
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hiremath, 2008, International Journal of Image Processing, V2, P10
   Hu P, 2016, IEEE T IMAGE PROCESS, V25, P4653, DOI 10.1109/TIP.2016.2594489
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia YQ, 2013, IEEE I CONF COMP VIS, P1761, DOI 10.1109/ICCV.2013.221
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kim J, 2016, IEEE T IMAGE PROCESS, V25, P9, DOI 10.1109/TIP.2015.2495122
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li J, 2013, IEEE SIGNAL PROC LET, V20, P845, DOI 10.1109/LSP.2013.2268868
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P33, DOI 10.1007/978-3-642-14267-3_2
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2011, IET IMAGE PROCESS, V5, P122, DOI 10.1049/iet-ipr.2009.0382
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Liu Z, 2013, OPT LETT, V38, P700, DOI 10.1364/OL.38.000700
   Liu Z, 2012, IEEE T MULTIMEDIA, V14, P1275, DOI 10.1109/TMM.2012.2190385
   Liu Z, 2010, IEEE IMAGE PROC, P253, DOI 10.1109/ICIP.2010.5652613
   Mai L, 2014, LECT NOTES COMPUT SC, V8691, P76, DOI 10.1007/978-3-319-10578-9_6
   Mai L, 2013, PROC CVPR IEEE, P1131, DOI 10.1109/CVPR.2013.150
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan ZB, 2013, INFORM SCIENCES, V221, P284, DOI 10.1016/j.ins.2012.09.003
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shamir A, 2009, COMMUN ACM, V52, P77, DOI 10.1145/1435417.1435437
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Shen LQ, 2013, MULTIMED TOOLS APPL, V63, P709, DOI 10.1007/s11042-011-0893-z
   Shi JB, 1997, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.1997.609407
   Shi R, 2012, IEEE SIGNAL PROC LET, V19, P215, DOI 10.1109/LSP.2012.2188388
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Xie YL, 2013, IEEE T IMAGE PROCESS, V22, P1689, DOI 10.1109/TIP.2012.2216276
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang Fan, 2011, P AS C COMP VIS, P39
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zou WB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.78
NR 58
TC 12
Z9 12
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23187
EP 23211
DI 10.1007/s11042-016-4093-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700003
DA 2024-07-18
ER

PT J
AU Chang, HY
   Huang, SC
   Wu, JH
AF Chang, Hong-Yi
   Huang, Shih-Chang
   Wu, Jia-Hao
TI A personalized music recommendation system based on
   electroencephalography feedback
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation System; Music Content Classification;
   Electroencephalography (EEG)
ID CLASSIFICATION; RESPONSES; RETRIEVAL
AB Numerous domestic and foreign studies have demonstrated that music can relieve stress and that listening to music is one method of stress relief used presently. Although stress-relief music is available on the market, various music genres produce distinct effects on people. Clinical findings have indicated that approximately 30 % of people listen to inappropriate music genres for relaxation and, consequently, their stress level increases. Therefore, to achieve the effect of stress relief, choosing the appropriate music genre is crucial. For example, a 70-year-old woman living in a military community since childhood might not consider general stress-relief music to be helpful in relieving stress, but when patriotic songs are played, her autonomic nervous system automatically relaxes because of her familiarity with the music style. Therefore, people have dissimilar needs regarding stress-relief music. In this paper, we proposed a personalized stress-relieving music recommendation system based on electroencephalography (EEG) feedback. The system structure comprises the following features: (a) automated music categorization, in which a new clustering algorithm, K-MeansH, is employed to precluster music and improve processing time; (b) the access and analysis of users' EEG data to identify perceived stress-relieving music; and (c) personalized recommendations based on collaborative filtering and provided according to personal preferences. Experimental results indicated that the overall clustering effect of K-MeansH surpassed that of K-Means and K-Medoids by approximately 71 and 57 %, respectively. In terms of accuracy, K-MeansH also surpassed K-Means and K-Medoids.
C1 [Chang, Hong-Yi; Wu, Jia-Hao] Natl Chiayi Univ, Dept Management Informat Syst, Chiayi, Taiwan.
   [Huang, Shih-Chang] Natl Formosa Univ, Dept Comp Sci & Informat Engn, Huwei Township, Yunlin, Taiwan.
C3 National Chiayi University; National Formosa University
RP Huang, SC (corresponding author), Natl Formosa Univ, Dept Comp Sci & Informat Engn, Huwei Township, Yunlin, Taiwan.
EM hychang@mail.ncyu.edu; schuang@nfu.edu.tw; s1011401@mail.ncyu.edu.tw
RI Huang, Shih-Chang/F-1469-2011
OI Huang, Shih-Chang/0000-0003-4058-9465
FU Ministry of Science and Technology (MOST) project of Taiwan [MOST
   103-2221-E-415-021-, MOST 104-2221-E-415-003-]
FX This work was supported by Ministry of Science and Technology (MOST)
   project of Taiwan [MOST 103-2221-E-415-021-] and [MOST
   104-2221-E-415-003-].
CR Blood AJ, 1999, NAT NEUROSCI, V2, P382, DOI 10.1038/7299
   Brecheisen S, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1385, DOI 10.1109/ICME.2006.262797
   Cabredo R, 2013, J ADV COMPUT INTELL, V17, P362, DOI 10.20965/jaciii.2013.p0362
   Carter JR, 2005, AM J PHYSIOL-HEART C, V288, pH904, DOI 10.1152/ajpheart.00569.2004
   Chang C-J, 2008, J PHYS ED NATL CHUNG, V9, P67
   Hsiao Tsai-Yun, 2009, Hu Li Za Zhi, V56, P105
   Hsieh J-K, 2010, J HLTH WORLD TAIWAN, V292, P83
   Kim J, 2008, IEEE T PATTERN ANAL, V30, P2067, DOI 10.1109/TPAMI.2008.26
   Kim YoungmooE., 2010, Proceedings of the 11th International Society for Music Information Retrieval Conference (ISMIR 2010), P255
   Lartillot O, 2007, INT C DIG AUD EFF, P237
   Lee OKA, 2005, J CLIN NURS, V14, P609, DOI 10.1111/j.1365-2702.2004.01103.x
   Li SZ, 2000, IEEE T SPEECH AUDI P, V8, P619, DOI 10.1109/89.861383
   Lin Hui-Chuan, 2007, Hu Li Za Zhi, V54, P38
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Michele B, 2005, AORN J, V78, P816
   Mok Esther, 2003, AORN J, V77, P396, DOI 10.1016/S0001-2092(06)61207-6
   Moraska Albert, 2010, Evid Based Complement Alternat Med, V7, P409, DOI 10.1093/ecam/nen029
   ODENDAAL JW, 1994, IEEE T ANTENN PROPAG, V42, P1386, DOI 10.1109/8.320744
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Shin Y-N, 2008, J TAIWAN OCCUPATIONA, V4, P27
   Trevisan AA, 2011, IET SEM ASS LIV 6 AP, P1
   Tung H-T, 2000, J LONG TERM CARE TAI, V10, P296
   Wang YY, 2014, 2014 IEEE WORKSHOP ON ELECTRONICS, COMPUTER AND APPLICATIONS, P269, DOI 10.1109/IWECA.2014.6845608
   Wold E, 1996, IEEE MULTIMEDIA, V3, P27, DOI 10.1109/93.556537
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
NR 26
TC 22
Z9 23
U1 4
U2 62
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19523
EP 19542
DI 10.1007/s11042-015-3202-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500012
DA 2024-07-18
ER

PT J
AU Hyun, J
   Moon, B
AF Hyun, Jongkil
   Moon, Byungin
TI A simplified rectification method and its hardware architecture for
   embedded multimedia systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo vision; Stereo matching; Rectification; Hardware implementation
AB Stereo vision, a future disruptive technology for obtaining three-dimensional distance information, can be applied to various embedded multimedia systems. Reducing the computational overhead of stereo vision necessitates the pre-processing procedure of rectification. For the implementation of rectification, several studies have proposed a look-up table- and computational logic-based approaches. However, the former exhibits excessive growth of memory with an increasing resolution of the image, and the latter requires numerous hardware resources for implementing the necessary computational logic. Thus, this paper proposes a simplified rectification calculation method and its optimized hardware architecture. By replacing matrix multiplications of the conventional method with simple accumulations and removing division operations, the proposed method reduces addition, multiplication, and division operations by 50, 100, and 100 %, respectively, compared with the conventional method. Although the experimental results show negligible differences between rectification by the conventional method and that by the proposed method, the latter consumes fewer hardware resources. Therefore, the proposed method and its architecture are more practical for real-time embedded multimedia systems.
C1 [Hyun, Jongkil; Moon, Byungin] Kyungpook Natl Univ, Sch Elect Engn, Daegu, South Korea.
C3 Kyungpook National University
RP Moon, B (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, Daegu, South Korea.
EM bihmoon@knu.ac.kr
RI Moon, Byungin/ACE-5308-2022
OI Moon, Byungin/0000-0002-8102-4818
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) [IITP-2016-H8601-16-1002]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) (IITP-2016-H8601-16-1002) supervised by the IITP (Institute for
   Information & communications Technology Promotion).
CR Akin A, 2013, IEEE INT CONF VLSI, P272, DOI 10.1109/VLSI-SoC.2013.6673288
   [Anonymous], 1997, P BRIT MACHINE VISIO
   Bajd T., 2013, Introduction to Robotics
   Bensrhair A, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P465
   Chilian A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4571, DOI 10.1109/IROS.2009.5354535
   Franke U, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P339, DOI 10.1109/IVS.1996.566403
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   Gluckman J, 2002, IEEE T PATTERN ANAL, V24, P224, DOI 10.1109/34.982902
   Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x
   Han SK, 2009, I CONF VLSI DESIGN, P287, DOI 10.1109/VLSI.Design.2009.89
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Huh K, 2008, OPT LASER ENG, V46, P168, DOI 10.1016/j.optlaseng.2007.08.002
   Hyun J, 2015, P INT WORKSH ADV COM, P20
   Jawed Khurram, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P277, DOI 10.1109/CSE.2009.473
   Jin S, 2010, IEEE T CIRC SYST VID, V20, P15, DOI 10.1109/TCSVT.2009.2026831
   Kaempchen N, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P459
   Loop C., 1999, Comput. Vision Pattern Recognit, V1, P1125, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]
   Sabe K, 2004, IEEE INT CONF ROBOT, P592, DOI 10.1109/ROBOT.2004.1307213
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Vancea C, 2007, INT C INTELL COMP CO, P147, DOI 10.1109/ICCP.2007.4352154
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
   Zicari P, 2013, MICROPROCESS MICROSY, V37, P1144, DOI 10.1016/j.micpro.2013.09.007
NR 23
TC 4
Z9 4
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19761
EP 19779
DI 10.1007/s11042-016-3517-9
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500026
DA 2024-07-18
ER

PT J
AU Jung, KD
   Moon, SJ
   Kim, JM
AF Jung, Kye-Dong
   Moon, Seok-Jae
   Kim, Jin-Mook
TI Data access control method for multimedia content data sharing and
   security based on XMDR-DAI in mobile cloud storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile; Cloud; Multimedia content; XMDR-Dai; Storage; Secure
ID ARCHITECTURE
AB Mobile cloud storage service is used for users' multimedia content data sharing or synchronization in effective way with several mobile devices. To save various content data in the mobile cloud storage, the matters of security should be treated in the process of data sharing to provide flexibility and expandability for solving its heterogeneousness. Currently, the cloud storage service generally encrypts the content data for the security. However, this method is not perfectly safe for it manages ID, password, and encryption key simply with software; thus it may accept unauthorized users. This research suggests the data access control model and the method for multimedia content sharing and security based on XMDR-DAI in the mobile cloud storage. It supports key management based on hardware, identification for the integrity of client software, and security key sharing. Also, the suggested model saves/manages different types of multimedia content, thus it establishes XMDR-DAI-based metadata relationship for the problems that occurred in searching to increase the reliability. And this research suggests the prototype using TPM emulator that is operated in secure world of ARM TrustZone and TrustZone environment.
C1 [Jung, Kye-Dong; Moon, Seok-Jae] Kwangwoon Univ, Dept Culture, 20 Kwangwoon Ro, Seoul 01897, South Korea.
   [Kim, Jin-Mook] Sunmoon Univ, Div IT Educ, 221 Bun Gil 70,Sunmoon Ro, Asan 31460, Chungnam, South Korea.
C3 Kwangwoon University; Sun Moon University
RP Kim, JM (corresponding author), Sunmoon Univ, Div IT Educ, 221 Bun Gil 70,Sunmoon Ro, Asan 31460, Chungnam, South Korea.
EM gdchung@kw.ac.kr; msj8086@kw.ac.kr; calf0425@sunmoon.ac.kr
CR [Anonymous], 2006, Trusted Platform Module Basics: Using TPM in Embedded Systems
   Bright JD, 2003, P 20 IEEE 11 NASA GO
   Gibson GA, 2000, COMMUN ACM, V43, P37, DOI 10.1145/353360.353362
   Greene M, 2016, U. S. Patent Application, Patent No. [11/492,581, 11492581]
   Holdings A, 2009, CISC VIS NETW IND GL
   Horne JD, 2010, U. S. Patent No, Patent No. [7,721,333, 7721333]
   Hyang-Jin L, 2012, SECURITY CONSIERATIO
   KECK KD, 2005, XMDR PROPOSED PROTOT
   Khan AN, 2013, FUTURE GENER COMP SY, V29, P1278, DOI 10.1016/j.future.2012.08.003
   Michael O. A., 2003, U.S. Patent, Patent No. [6 564 228, 6564228]
   Mishra Asit K., 2010, Performance Evaluation Review, V37, P34, DOI 10.1145/1773394.1773400
   Moon S, 2010, COMM COM INF SC, V74, P72
   Mousa A., 2006, Int. J. Comput. Sci. Appl., V3, P44
   Nahum N, 2005, U. S. Patent No, Patent No. [6,898,670, 6898670]
   Sanaei Z, 2012, ARXIV12053247
   Sanaei Z, 2014, IEEE COMMUN SURV TUT, V16, P369, DOI 10.1109/SURV.2013.050113.00090
   Sharma S, 2004, INFOCOM 2004 23 ANN, V4
   Tang W, 2011, PROCEDIA ENVIRON SCI, V11, P499, DOI 10.1016/j.proenv.2011.12.079
   Winter Johannes, 2008, P 3 ACM WORKSH SCAL
   Zhou Z, 2012, P 8 INT C NETW SERV
NR 20
TC 4
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19983
EP 19999
DI 10.1007/s11042-016-4016-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500039
DA 2024-07-18
ER

PT J
AU Leite, DQ
   Duarte, JC
   Neves, LP
   de Oliveira, JC
   Giraldi, GA
AF Leite, Diego Q.
   Duarte, Julio C.
   Neves, Luiz P.
   de Oliveira, Jauvane C.
   Giraldi, Gilson A.
TI Hand gesture recognition from depth and infrared Kinect data for CAVE
   applications interaction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect; Depth and speckle pattern images; Gesture spotting;
   Bag-of-visual-words; SVM; Hand gesture recognition; CAVE
ID FEATURES
AB This paper presents a real-time framework that combines depth data and infrared laser speckle pattern (ILSP) images, captured from a Kinect device, for static hand gesture recognition to interact with CAVE applications. At the startup of the system, background removal and hand position detection are performed using only the depth map. After that, tracking is started using the hand positions of the previous frames in order to seek for the hand centroid of the current one. The obtained point is used as a seed for a region growing algorithm to perform hand segmentation in the depth map. The result is a mask that will be used for hand segmentation in the ILSP frame sequence. Next, we apply motion restrictions for gesture spotting in order to mark each image as a 'Gesture' or 'Non-Gesture'. The ILSP counterparts of the frames labeled as "Gesture" are enhanced by using mask subtraction, contrast stretching, median filter, and histogram equalization. The result is used as the input for the feature extraction using a scale invariant feature transform algorithm (SIFT), bag-of-visual-words construction and classification through a multi-class support vector machine (SVM) classifier. Finally, we build a grammar based on the hand gesture classes to convert the classification results in control commands for the CAVE application. The performed tests and comparisons show that the implemented plugin is an efficient solution. We achieve state-of-the-art recognition accuracy as well as efficient object manipulation in a virtual scene visualized in the CAVE.
C1 [Leite, Diego Q.; de Oliveira, Jauvane C.; Giraldi, Gilson A.] Natl Lab Sci Comp, Petropolis, RJ, Brazil.
   [Leite, Diego Q.; Duarte, Julio C.] Mil Inst Engn, Rio De Janeiro, RJ, Brazil.
   [Neves, Luiz P.] Univ Fed Parana, Curitiba, Parana, Brazil.
C3 Laboratorio Nacional de Computacao Cientifica (LNCC); Universidade
   Federal do Parana
RP Leite, DQ (corresponding author), Natl Lab Sci Comp, Petropolis, RJ, Brazil.; Leite, DQ (corresponding author), Mil Inst Engn, Rio De Janeiro, RJ, Brazil.
EM diego@diegoleite.com; duarte@ime.eb.br; lapneves@gmail.com;
   jauvane@acm.org; gilson@lncc.br
RI Duarte, Julio Cesar/U-9541-2017; Neves, Luis/E-6382-2011; de Oliveira,
   Jauvane C./Q-8242-2019; Giraldi, Gilson Antonio/AAS-7135-2020
OI Neves, Luis/0000-0001-5034-8417; de Oliveira, Jauvane
   C./0000-0002-7522-7846; Giraldi, Gilson Antonio/0000-0003-0623-9461
CR [Anonymous], P 1 ACM INT WORKSH M
   [Anonymous], J REAL TIME IMAGE PR
   [Anonymous], WORLD ACAD SCI ENG T
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], INT J SCI ENG RES
   [Anonymous], COMPLETE GUIDE NIGHT
   [Anonymous], THESIS
   [Anonymous], 2 WORKSH ASS SERV RO
   [Anonymous], REAL TIME SKELETON T
   [Anonymous], 1985, TECHNOLOGY ACCEPTANC
   [Anonymous], APCHI 12
   [Anonymous], 2013 INT S SIGN CIRC
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], INT J COMPUTER APPL
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bibby C, 2010, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2010.5539818
   Cai Ziyun, 2016, Multimedia Tools and Applications, P1
   Caputo M., 2012, MENSCH COMPUTER, P293
   Chaudhary A, 2011, COMM COM INF SC, V133, P46
   Corradini A, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P82, DOI 10.1109/RATFG.2001.938914
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   De Almeida Thomaz V., 2012, 2012 14th Symposium on Virtual and Augmented Reality (SVR), P108, DOI 10.1109/SVR.2012.29
   Dias JMS, 2004, XVII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P33, DOI 10.1109/SIBGRA.2004.1352940
   Elmezain M., 2010, Proceedings 2010 IEEE International Symposium on Signal Processing and Information Technology (ISSPIT 2010), P131, DOI 10.1109/ISSPIT.2010.5711749
   Hackenberg G, 2011, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2011.5759431
   Hartanto R, 2014, 2014 6 INT C INF TEC, P1
   Hartigan J. A., 1975, CLUSTERING ALGORITHM, V458, P468
   Hasan H, 2014, ARTIF INTELL REV, V41, P147, DOI 10.1007/s10462-011-9303-1
   Hong-Min Zhu, 2012, 2012 Ninth International Conference on Computer Graphics, Imaging and Visualization (CGIV), P49, DOI 10.1109/CGIV.2012.13
   Hulik R, 2012, IEEE INT C INT ROBOT, P1665, DOI 10.1109/IROS.2012.6385868
   Joo SI, 2014, SCI WORLD J, DOI 10.1155/2014/284827
   Khan N. Y., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P501, DOI 10.1109/DICTA.2011.90
   Leite DATQ, 2014, SYMP VIRTUAL AUGMENT, P246, DOI 10.1109/SVR.2014.13
   Li Q, 2013, IEEE SIGNAL PROC LET, V20, P67, DOI 10.1109/LSP.2012.2228852
   Li Y, 2012, 2012 17TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES (CGAMES), P126, DOI 10.1109/CGames.2012.6314563
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Lin Wei-Syun, 2013, ADV INTELLIGENT SYST, V2, P235, DOI [10.1007/978-3-642-35473-1_24, DOI 10.1007/978-3-642-35473-1_24]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Micó V, 2011, SPRINGER SER SURF SC, V46, P347, DOI 10.1007/978-3-642-15813-1_13
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moehring M, 2011, IEEE T VIS COMPUT GR, V17, P1195, DOI 10.1109/TVCG.2011.36
   Morguet P, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P193, DOI 10.1109/ICIP.1998.999009
   Nagarajan S., 2013, Int. J. Comput. Appl, V82, DOI [10.5120/14106-2145, DOI 10.5120/14106-2145]
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Otiniano Rodriguez K., 2013, 2013 XXVI Conference on Graphics, Patterns and Images (SIBGRAPI 2013), P1, DOI 10.1109/SIBGRAPI.2013.10
   Pedersoli F, 2014, VISUAL COMPUT, V30, P1107, DOI 10.1007/s00371-014-0921-x
   Plouffe G, 2016, IEEE T INSTRUM MEAS, V65, P305, DOI 10.1109/TIM.2015.2498560
   Priyal SP, 2013, PATTERN RECOGN, V46, P2202, DOI 10.1016/j.patcog.2013.01.033
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Rao G. Mallikarjuna, 2013, International Journal of Image, Graphics and Signal Processing, V5, P57, DOI 10.5815/ijigsp.2013.06.08
   Rao VS, 2006, FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSSING, PROCEEDINGS, P145
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ros G, 2012, INT C PATT RECOG, P3581
   Sanchez-Nielsen E., 2004, WSCG, P395
   Thalmann Daniel., 2012, P 20 ACM INT C MULTI, P785, DOI DOI 10.1145/2393347.2396312
   Uddin MZ, 2010, IEEE IMAGE PROC, P713, DOI 10.1109/ICIP.2010.5651953
   Um D, 2011, IEEE SENS J, V11, P3352, DOI 10.1109/JSEN.2011.2159200
   Van Bang Le, 2014, International Journal of Information and Electronics Engineering, V4, P176, DOI 10.7763/IJIEE.2014.V4.430
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Yoon HS, 2001, PATTERN RECOGN, V34, P1491, DOI 10.1016/S0031-3203(00)00096-0
   Yu Chen Zhou, 2010, Proceedings of the 2010 IEEE Congress on Services (SERVICES-1), P1, DOI 10.1109/SERVICES.2010.43
   Yuen K.K., 2010, Computer-Aided Design and Applications, V7, P235, DOI DOI 10.3722/CADAPS.2010.235-245
   Zhu YX, 2002, COMPUT VIS IMAGE UND, V85, P189, DOI 10.1006/cviu.2002.0967
NR 65
TC 19
Z9 19
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20423
EP 20455
DI 10.1007/s11042-016-3959-0
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400003
DA 2024-07-18
ER

PT J
AU Rawashdeh, M
   Shorfuzzaman, M
   Artoli, AM
   Hossain, MS
   Ghoneim, A
AF Rawashdeh, Majdi
   Shorfuzzaman, Mohammad
   Artoli, Abdel Monim
   Hossain, M. Shamim
   Ghoneim, Ahmed
TI Mining tag-clouds to improve social media recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social tagging; Recommendation; Annotation; Collaborative tagging
ID SYSTEMS
AB Massive amounts of data are available on social websites, therefore finding the suitable item is a challenging issue. According to recent social statistics, we have more than 930 million people are using WhatsApp with more than 340 million active daily users and 955 million people who access Facebook daily with an average daily photo uploads up to 325 million. The approach presented in this paper employs the collaborative tagging accumulated by huge number of users to improve social media recommendation. Our approach has two phases, in the first phase, we compute the tag-item weight model and in the second phase, we compute the user-tag preference model. After that we employ the two models to find the suitable items tailored to the user's preferences and recommend the items with the highest score. Also our model can compute the tag score and suggest the tags with the highest weight to the user according to their preferences. The experiment results performed on Flicker and MovieLens prove that our approach is capable to improve the social media recommendation.
C1 [Rawashdeh, Majdi] Princess Sumaya Univ Technol, Amman, Jordan.
   [Shorfuzzaman, Mohammad] Taif Univ, Dept Comp Sci, At Taif, Saudi Arabia.
   [Artoli, Abdel Monim] King Saud Univ, Dept Comp Sci, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Hossain, M. Shamim; Ghoneim, Ahmed] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
   [Ghoneim, Ahmed] Menoufia Univ, Dept Math & Comp Sci, Fac Sci, Menoufia 32721, Egypt.
C3 Princess Sumaya University for Technology; Taif University; King Saud
   University; King Saud University; Egyptian Knowledge Bank (EKB); Menofia
   University
RP Rawashdeh, M (corresponding author), Princess Sumaya Univ Technol, Amman, Jordan.
EM m.rawashdeh@psut.edu.jo; m.shorf@tu.edu.sa; aartoli@ksu.edu.sa;
   mshossain@ksu.edu.sa; ghoneim@ksu.edu.sa
RI Shorfuzzaman, Mohammad/AAZ-1145-2020; ghoneim, ahmed/L-3019-2013;
   Hossain, M. Shamim/K-1362-2014; Guizani, Mohsen/AAX-4534-2021; Artoli,
   Abdel Monim/L-3779-2019
OI Shorfuzzaman, Mohammad/0000-0002-8050-8431; Hossain, M.
   Shamim/0000-0001-5906-9422; Guizani, Mohsen/0000-0002-8972-8094;
   Ghoneim, Ahmed/0000-0003-2076-8925
FU Deanship of Scientific Research at King Saud University, Riyadh, Saudi
   Arabia [RGP-229]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University, Riyadh, Saudi Arabia for funding this
   work through the research group project no. RGP-229.
CR Alhamid MF, 2015, MULTIMED TOOLS APPL, V74, P11399, DOI 10.1007/s11042-014-2236-3
   [Anonymous], 2006, P INT C MULT INF SCI
   [Anonymous], 2016, PROC IEEE WINTER C A
   [Anonymous], 2010, P INT C MULTIMEDIA I
   [Anonymous], 2011, Categorical data analysis, DOI 10.1007/978-3-642-04898-2_161
   Balakrishnan S, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P163, DOI 10.1145/2740908.2742843
   Chen C, 2016, 13 AAAI C ART INT
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Diaz-Aviles Ernesto., 2010, Proceedings of the 4th ACM Conference on Recommender Systems, P309
   Doerfel S, 2016, ACM T WEB, V10, DOI 10.1145/2896821
   Eunji Ha, 2016, KIISE Transactions on Computing Practices, V22, P290, DOI 10.5626/KTCP.2016.22.6.290
   Fang Q, 2015, IEEE T MULTIMEDIA, V17, P1031, DOI 10.1109/TMM.2015.2430819
   Harper FM, 2016, ACM T INTERACT INTEL, V5, DOI 10.1145/2827872
   Hossain MS, 2009, CONCURR COMP-PRACT E, V21, P1450, DOI 10.1002/cpe.1400
   Huang CL, 2014, KNOWL-BASED SYST, V56, P86, DOI 10.1016/j.knosys.2013.11.001
   Ifada N, 2016, PROCEEDINGS OF THE NINTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM'16), P23, DOI 10.1145/2835776.2835790
   Kim HN, 2011, EXPERT SYST APPL, V38, P8488, DOI 10.1016/j.eswa.2011.01.048
   Krestel R., 2009, Proceedings of the 3rd ACM Conference on Recommender Systems, P61, DOI [DOI 10.1145/1639714.1639726, 10.1145/1639714.1639726]
   Mao J, 2016, J INF SCI, V42, P711, DOI 10.1177/0165551515603321
   Milicevic AK, 2010, ARTIF INTELL REV, V33, P187, DOI 10.1007/s10462-009-9153-2
   Min WQ, 2015, IEEE T MULTIMEDIA, V17, P1787, DOI 10.1109/TMM.2015.2463226
   Pirolli P, 2013, USER MODEL USER-ADAP, V23, P139, DOI 10.1007/s11257-012-9132-1
   Qian S., 2015, ACM T MULTIM COMPUT, V11, P1
   Stone Z, 2010, P IEEE, V98, P1408, DOI 10.1109/JPROC.2010.2044551
   Wattenberg MM, 2015, U.S. Patent, Patent No. [9,058,316, 9058316]
   Xie HR, 2016, INFORM PROCESS MANAG, V52, P61, DOI 10.1016/j.ipm.2015.03.001
   Xu ZZ, 2016, COMPUT SCI INF SYST, V13, P359, DOI [10.2298/CSIS150730007Z, 10.2298/CSIS1507300072]
   Yang XS, 2015, IEEE T MULTIMEDIA, V17, P346, DOI 10.1109/TMM.2015.2393635
   Zanardi V, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P51
   Zhao W, 2015, NEUROCOMPUTING, V148, P521, DOI 10.1016/j.neucom.2014.07.011
   Zhao Y D, 2015, ARXIV151208325
NR 31
TC 6
Z9 6
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21157
EP 21170
DI 10.1007/s11042-016-4039-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400037
DA 2024-07-18
ER

PT J
AU Joshi, P
   Prakash, S
AF Joshi, Piyush
   Prakash, Surya
TI Retina inspired no-reference image quality assessment for blur and noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image quality assessment; No-reference image quality assessment;
   Difference of Gaussians (DoG); Multiple frequencies
AB A blind image quality assessment technique with no-training is proposed in this paper. The proposed technique considers two important types of distortions viz. noise and blur for quality estimation of an image. The technique is motivated by two significant phenomena of perception in the retina of an eye. First being the center-surround retinal receptive field and second, existence of multiple spatial frequency channels. Center-surround retinal receptive field in the proposed technique is modeled with the help of Difference of Gaussians (DoG). In retina, multiple spatial frequencies have been found and due to this, signals generated from center and surround fields exist at different frequencies. In order to mimic center-surround receptive field at multiple frequencies, we compute multiple DoG images at multiple standard deviation values generated for different frequencies. Further, two significant features based on entropy and edges are extracted from the obtained DoG images and are subsequently used to compute the quality of the image. The proposed technique does not require any training with distorted or pristine images; or subjective human score to predict quality of the image. We evaluate the proposed technique on LIVE, CSIQ and TID08 databases and observe that the obtained results match very well with human subjective opinions. The proposed technique outperforms the latest no-training, no-reference (NR) based image quality assessment techniques.
C1 [Joshi, Piyush; Prakash, Surya] Indian Inst Technol Indore, Indore 453552, Madhya Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore
RP Joshi, P (corresponding author), Indian Inst Technol Indore, Indore 453552, Madhya Pradesh, India.
EM piyushjoshi3839@gmail.com; surya@iiti.ac.in
RI Prakash, Surya/S-6308-2019
OI Prakash, Surya/0000-0001-8039-1280
CR Blumenfeld H, 2002, NEUROANATOMY CLIN CA
   Bovik AC, 2001, INT CONF ACOUST SPEE, P1725, DOI 10.1109/ICASSP.2001.941272
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen MJ, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-3
   DeValois R. L., SPATIAL VISION
   Gao XJ, 2010, J APPL MECH-T ASME, V77, DOI 10.1115/1.4001544
   Kandel E S, 1994, PRINCIPLES NEURAL 5
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li C, 2013, OPT ENG, V52
   Liang LH, 2010, SIGNAL PROCESS-IMAGE, V25, P502, DOI 10.1016/j.image.2010.01.007
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Marziliano P, 2004, SIGNAL PROCESS-IMAGE, V19, P163, DOI 10.1016/j.image.2003.08.003
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mittal A, 2012, IEEE SIGNAL PROC LET, V19, P75, DOI 10.1109/LSP.2011.2179293
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Ong EP, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 1, PROCEEDINGS, P469, DOI 10.1109/ISSPA.2003.1224741
   Ponomarenko C. J. N., 2009, ADV MODERN RADIOELEC, V10, P30
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   RODIECK RW, 1965, J NEUROPHYSIOL, V28, P833, DOI 10.1152/jn.1965.28.5.833
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Saha A, 2015, IEEE T IMAGE PROCESS, V24, P1879, DOI 10.1109/TIP.2015.2411436
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Tang HX, 2011, PROC CVPR IEEE, P305, DOI 10.1109/CVPR.2011.5995446
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Wu H.R., 2005, DIGITAL VIDEO IMAGE
   Wu HR, 1997, IEEE SIGNAL PROC LET, V4, P317, DOI 10.1109/97.641398
   Xue WF, 2013, PROC CVPR IEEE, P995, DOI 10.1109/CVPR.2013.133
   Ye P, 2012, IEEE T IMAGE PROCESS, V21, P3129, DOI 10.1109/TIP.2012.2190086
   Zhang J, 2011, SIGNAL PROCESS, V91, P2575, DOI 10.1016/j.sigpro.2011.05.011
NR 36
TC 12
Z9 12
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18871
EP 18890
DI 10.1007/s11042-017-4418-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800034
DA 2024-07-18
ER

PT J
AU Koohborfardhaghighi, S
   Lee, DB
   Kim, J
AF Koohborfardhaghighi, Somayeh
   Lee, Dae Bum
   Kim, Juntae
TI How different connectivity patterns of individuals within an
   organization can speed up organizational learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knowledge management system; Knowledge sharing; Centrality measures;
   Informal communication network topology; Organizational learning;
   Agent-based modeling
ID EXPLORATION; EXPLOITATION; CENTRALITY
AB Knowledge sharing within a cooperative organization is an important issue since the power of its outcome has been the principal source of competitive advantage over the competitors in the market. However, without a proper collective knowledge management, its utilization as a strategic weapon or competitive advantage becomes difficult and inefficient. From an organizational perspective, the most important aspect of knowledge management is to transfer knowledge. In this regards, organizations must adopt structures that allow them to create and transfer more knowledge. Organizational communication structure affects the nature of human interactions and information flow which in its own turn can lead to a competitive advantage in the knowledge economy. However, in addition to that, social relationships between individuals in an organization can also be utilized to produce positive returns. In this article we emphasize the role of individual structural importance within an organizational informal communication structure as a mechanism for knowledge flow and speeding up organizational learning. Our experimental results indicate the fact that structural position of individuals within their informal communication networks can help the network members to have a better access to ongoing information exchange processes in the organization. The results of our analyses also show that organizational learning through an informal communication network of people in the form of scale-free connectivity pattern is faster comparing to the small-world connectivity style.
C1 [Koohborfardhaghighi, Somayeh; Lee, Dae Bum; Kim, Juntae] Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
C3 Dongguk University
RP Koohborfardhaghighi, S; Kim, J (corresponding author), Dongguk Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM skhaghighi@yahoo.com; dblee@dongguk.edu; jkim@dongguk.edu
RI Kim, Juntae/AAE-2103-2021
FU "Leaders Industry-University Cooperation" Project; Ministry of Education
FX This research has been funded by the "Leaders Industry-University
   Cooperation" Project, supported by the Ministry of Education.
CR Alazmi M, 2003, TOTAL QUAL MANAG BUS, V14, P199, DOI 10.1080/1478336032000051386
   [Anonymous], 2004, HIDDEN POWER SOCIAL
   [Anonymous], PHYS0605220 ARXIV
   [Anonymous], 1999, WWW 1999
   [Anonymous], NETLOGO M
   Argote L, 2007, ORGAN SCI, V18, P337, DOI 10.1287/orsc.1070.0280
   Argyris C., 1996, Organizational Learning II Theory, Method, and Practice
   Axley S.R., 2000, IND MANAG, V42, P18
   Barabási AL, 1999, SCIENCE, V286, P509, DOI 10.1126/science.286.5439.509
   Barua A, 2007, INFORM TECHNOL MANAG, V8, P31, DOI 10.1007/s10799-006-0001-7
   Berkhin P, 2005, INTERNET MATH, V2, P73, DOI 10.1080/15427951.2005.10129098
   BONACICH P, 1972, J MATH SOCIOL, V2, P113, DOI 10.1080/0022250X.1972.9989806
   Bonacich P, 2001, SOC NETWORKS, V23, P191, DOI 10.1016/S0378-8733(01)00038-7
   Bontis N, 2002, J MANAGE STUD, V39, P437, DOI 10.1111/1467-6486.t01-1-00299
   Brandes U, 2001, J MATH SOCIOL, V25, P163, DOI 10.1080/0022250X.2001.9990249
   Crossan MM, 2003, STRATEGIC MANAGE J, V24, P1087, DOI 10.1002/smj.342
   Fang C, 2010, ORGAN SCI, V21, P625, DOI 10.1287/orsc.1090.0468
   Fleming L, 2001, MANAGE SCI, V47, P117, DOI 10.1287/mnsc.47.1.117.10671
   FREEMAN LC, 1991, SOC NETWORKS, V13, P141, DOI 10.1016/0378-8733(91)90017-N
   Gupta AK, 2006, ACAD MANAGE J, V49, P693, DOI 10.5465/20159793
   Harshman EF, 1999, J BUS ETHICS, V19, P3, DOI 10.1023/A:1006141704179
   Hasanali F., 2002, CRITICAL SUCCESS FAC
   Hatala J.P., 2006, Human Resource Development Review, V5, P45, DOI [10.1177/1534484305284318, DOI 10.1177/1534484305284318]
   Hatala JP, 2009, PERFORM IMPROV Q, V21, P5, DOI 10.1002/piq.20036
   Jansen JJP, 2006, MANAGE SCI, V52, P1661, DOI 10.1287/mnsc.1060.0576
   Johanson J., 2000, SCAND J MANAG, V16, P249, DOI DOI 10.1016/S0956-5221(99)00027-5]
   Kane GC, 2007, ORGAN SCI, V18, P796, DOI 10.1287/orsc.1070.0286
   KIM DH, 1998, LINK INDIVIDUAL ORG
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Koohborfardhaghighi S, 2013, APPL INTELL, V38, P255, DOI 10.1007/s10489-012-0371-y
   Lewin AY, 1999, ORGAN SCI, V10, P535, DOI 10.1287/orsc.10.5.535
   Liebowitz J., 2000, BUILDING ORG INTELLI
   March, 1994, A Primer on Decision Making: How Decisions Happen
   March J.G., 1988, Decisions and Organizations
   March JG, 1991, ORGAN SCI, V2, P71, DOI 10.1287/orsc.2.1.71
   Miller KD, 2006, ACAD MANAGE J, V49, P709, DOI 10.2307/20159794
   Newman MEJ, 2001, PHYS REV E, V64, DOI [10.1103/PhysRevE.64.016132, 10.1103/PhysRevE.64.016131]
   Nonaka I, 1995, KNOWLEDGE CREATING C
   Pedler M., 1997, LEARNING CO STRATEGY, V2nd
   Senge P. M., 1990, 5 DISCIPLINE ART PRA
   Senge PM, 1996, TRAINING DEV, V50, P36
   Siggelkow N, 2005, ORGAN SCI, V16, P101, DOI 10.1287/orsc.1050.0116
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
NR 45
TC 3
Z9 5
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 17
BP 17923
EP 17936
DI 10.1007/s11042-016-3348-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA FB8CF
UT WOS:000406365800019
DA 2024-07-18
ER

PT J
AU Singh, SK
   Kumar, S
   Dwivedi, JP
AF Singh, Sandip Kumar
   Kumar, Sandeep
   Dwivedi, J. P.
TI Compound fault prediction of rolling bearing using multimedia data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia signals; Ensemble empirical mode distribution; Intrinsic mode
   functions; Independent component analysis; Convolution neural network;
   Combined mode functions; Artificial neural networks; Compound faults
ID EMPIRICAL MODE DECOMPOSITION; WAVELET TRANSFORM; DIAGNOSIS; MACHINE
AB Catastrophic failure of mechanical systems due to faults occurring on rolling bearing is still a great challenge. These faults, which are of multiple type, are compounded in nature. Vibration analysis of multimedia signals is one of the most effective techniques for the health monitoring of these bearings. A compound fault signal usually consists of multiple characteristic signals and strong confusion noise, which makes it a tough task to separate weak fault signals from them. To resolve the compound fault diagnosis problem of rolling bearings byseparation of multimedia signals' (obtained from acoustic or acceleration sensors), ensemble empirical mode decomposition (EEMD) method along with some classifier (like independent component analysis (ICA) technique) has been used to some degree of success. But, they are not found capable of detecting difficult faults existing on small balls of the bearing. In order to solve this problem, we are going to propose a new method based on use of Combined Mode Functions (CMF) for selecting the intrinsic mode functions(IMFs) instead of the maximum cross correlation coefficient based EEMD technique, sandwiched with, Convolution Neural Networks (CNN), which are deep neural nets, used as fault classifiers. This composite CNN-CMF-EEMD methodovercomes the deficiencies of other approaches, such as the inability to learn the complex non-linear relationships in fault diagnosis issues and fine compound faults like those occurring on small balls of the bearing. The difficult compound faults can be separated effectively by executing CNN-CMF-EEMD method, which makes the fault features more easily extracted and more clearly identified. Experimental results reinforce the effectiveness of using CNN-CMF--EEMD technique for fine compound faults. A comparison of CNN-CMF-EEMD with Artificial Neural Networks (ANN) based ANN-CMF-EEMD shows the capability of CNN as a powerful classifier in the domain of compound fault features of rolling bearing.
C1 [Singh, Sandip Kumar; Kumar, Sandeep; Dwivedi, J. P.] Indian Inst Technol BHU, Dept Mech Engn, Varanasi, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Singh, SK (corresponding author), Indian Inst Technol BHU, Dept Mech Engn, Varanasi, Uttar Pradesh, India.
EM sandipks.rs.mec15@itbhu.ac.in; sandeep.mec@iitbhu.ac.in; jpd@bhu.ac.in
RI Kumar, Sandeep/IWU-7273-2023; Singh, Sandip Kumar/U-9209-2019; Kumar,
   Santosh/JVO-5600-2024; Kumar, Sandeep/IUQ-2320-2023
OI Kumar, Sandeep/0000-0002-7008-4735; Kumar, Sandeep/0000-0002-0848-632X
CR [Anonymous], INT C ICICI BME
   [Anonymous], ROLLING BEARING VIBR
   [Anonymous], P IEEE INT S IND EL
   Arifianto D., 2011, 2011 2nd International Conference on Instrumentation Control and Automation (ICA 2011), P274, DOI 10.1109/ICA.2011.6130171
   Ballal MS, 2007, IEEE T IND ELECTRON, V54, P250, DOI 10.1109/TIE.2006.888789
   Bin GF, 2012, MECH SYST SIGNAL PR, V27, P696, DOI 10.1016/j.ymssp.2011.08.002
   Chen WY, 2012, 2012 XXTH INTERNATIONAL CONFERENCE ON ELECTRICAL MACHINES (ICEM), P2390, DOI 10.1109/ICElMach.2012.6350218
   Ciresan DC, 2010, NEURAL COMPUT, V22, P3207, DOI 10.1162/NECO_a_00052
   Gao Q, 2008, MECH SYST SIGNAL PR, V22, P1072, DOI 10.1016/j.ymssp.2007.10.003
   Grasso M, 2016, MECH SYST SIGNAL PR, V81, P126, DOI 10.1016/j.ymssp.2016.02.067
   Hong TP, 2009, EXPERT SYST APPL, V36, P11844, DOI 10.1016/j.eswa.2009.04.016
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   Kim K, 2003, IEEE T IND ELECTRON, V50, P1038, DOI 10.1109/TIE.2003.817693
   Kim K, 2002, IEEE-ASME T MECH, V7, P201, DOI 10.1109/TMECH.2002.1011258
   Kowalski CT, 2003, MATH COMPUT SIMULAT, V63, P435, DOI 10.1016/S0378-4754(03)00087-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei YG, 2009, MECH SYST SIGNAL PR, V23, P1327, DOI 10.1016/j.ymssp.2008.11.005
   Li B, 2000, IEEE T IND ELECTRON, V47, P1060, DOI 10.1109/41.873214
   Li X, 2013, MEASUREMENT, V46, P2726, DOI 10.1016/j.measurement.2013.04.081
   Liu J, 2008, MEAS SCI TECHNOL, V19, DOI 10.1088/0957-0233/19/1/015105
   Lou XS, 2004, MECH SYST SIGNAL PR, V18, P1077, DOI 10.1016/S0888-3270(03)00077-3
   Peng ZK, 2005, MECH SYST SIGNAL PR, V19, P974, DOI 10.1016/j.ymssp.2004.01.006
   Saidi L, 2013, ISA T, V52, P140, DOI 10.1016/j.isatra.2012.08.003
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Wang HQ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0109166
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Yan QS, 2014, DISCRETE DYN NAT SOC, V2014, DOI 10.1155/2014/390579
   Yan RQ, 2014, SIGNAL PROCESS, V96, P1, DOI 10.1016/j.sigpro.2013.04.015
   Zidani F, 2008, IEEE T IND ELECTRON, V55, P586, DOI 10.1109/TIE.2007.911951
NR 30
TC 17
Z9 18
U1 1
U2 96
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18771
EP 18788
DI 10.1007/s11042-017-4419-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800030
DA 2024-07-18
ER

PT J
AU Syu, JL
   Li, HT
   Chiang, JS
   Hsia, CH
   Wu, PH
   Hsieh, CF
   Li, SA
AF Syu, Jia-Liang
   Li, Hsin-Ting
   Chiang, Jen-Shiun
   Hsia, Chih-Hsien
   Wu, Po-Han
   Hsieh, Chi-Fang
   Li, Shih-An
TI A computer vision assisted system for autonomous forklift vehicles in
   real factory environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Industry 4.0; Automated storage and retrieval systems; Forklift;
   Adaboost; Pallet detection
ID DISCRETE WAVELET TRANSFORM; GENERATION; IMAGES
AB Industry 4.0 is an important trend in factory automation nowadays. Among the Automated-Storage-and-Retrieval-System (ASRS) is one of the most important issues for industry. It is widely used in a variety of industries for a variety of storage applications in factories and warehouses. However, the cost of constructing an ASRS is so high that most small/medium enterprises cannot afford it. A forklift system is a cheaper alternative to a complicated ASRS. In this work, a new pallet detection method that uses an Adaptive Structure Feature (ASF) and Direction Weighted Overlapping (DWO) ratio to allow forklifts to pick up a pallet is proposed, using a monocular vision system on the forklift. Combining the ASF and DWO ratio for pallet detection, the proposed method removes most of the non-stationary (dynamic) background and significantly increases the processing efficiency. A Haar like-based Adaboost scheme uses an AS for pallets algorithm to detect pallets. It detects the pallet in a dark environment. Finally, by calculating the DWO ratio between the detected pallets and tracking records, it avoids erroneous candidates during object tracking. Therefore, this work improves the pallet detection to solve the problem with an effective design. As results show that the hybrid algorithms that are proposed in this work increase the average pallet detection rate by 95 %.
C1 [Syu, Jia-Liang; Chiang, Jen-Shiun; Li, Shih-An] Tamkang Univ, Dept Elect & Comp Engn, New Taipei, Taiwan.
   [Li, Hsin-Ting; Wu, Po-Han; Hsieh, Chi-Fang] Boltun Corp, Ctr Engn, Tainan, Taiwan.
   [Hsia, Chih-Hsien] Chinese Culture Univ, Dept Elect Engn, Taipei, Taiwan.
C3 Tamkang University; Chinese Culture University
RP Hsia, CH (corresponding author), Chinese Culture Univ, Dept Elect Engn, Taipei, Taiwan.
EM chhsia625@gmail.com
OI Hsia, Chih-Hsien/0000-0003-2665-0821
FU Ministry of Science and Technology of Taiwan [MOST
   104-2221-E-034-013-MY2]
FX The authors would like to thank the anonymous reviewers of their paper
   for the many helpful suggestions. This work was supported by the
   Ministry of Science and Technology of Taiwan. under grant number MOST
   104-2221-E-034-013-MY2.
CR [Anonymous], INT C FUT GEN COMM N
   [Anonymous], 2000, BMVC
   [Anonymous], MED C CONTR AUT
   Byun S, 2008, PROC INT C TOOLS ART, P505, DOI 10.1109/ICTAI.2008.124
   Chen CY, 2016, MULTIMED TOOLS APPL, V75, P9949, DOI 10.1007/s11042-015-2776-1
   Chen G, 2012, INT C WIRELESS COMMU, P1
   Cui GZ, 2010, INT ASIA CONF INFORM, P286, DOI 10.1109/CAR.2010.5456688
   Fogel Menasheh, 2007, Proceedings of the 3rd Annual IEEE Conference on Automation Science and Engineering, P678
   Garibotto G, 1996, IROS 96 - PROCEEDINGS OF THE 1996 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS - ROBOTIC INTELLIGENCE INTERACTING WITH DYNAMIC WORLDS, VOLS 1-3, P656, DOI 10.1109/IROS.1996.571028
   He Zhendong, 2010, 2010 International Conference on Measuring Technology and Mechatronics Automation (ICMTMA 2010), P260, DOI 10.1109/ICMTMA.2010.464
   Horng YR, 2010, IEEE INT SYMP CIRC S, P2650, DOI 10.1109/ISCAS.2010.5537052
   Hsia CH, 2016, IEEE SENS J, V16, P4521, DOI 10.1109/JSEN.2016.2542259
   Hsia CH, 2014, SIGNAL PROCESS, V96, P138, DOI 10.1016/j.sigpro.2013.09.007
   Hsia CH, 2009, IEEE T CIRC SYST VID, V19, P1202, DOI 10.1109/TCSVT.2009.2020259
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Lecking D, 2006, IEEE INT C EMERG, P585
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Liu X, 2015, IEEE T NEUR NET LEAR, V26, P1060, DOI 10.1109/TNNLS.2014.2333751
   Pan ZQ, 2016, IEEE T BROADCAST, V62, P675, DOI 10.1109/TBC.2016.2580920
   Seelinger M, 2005, IEEE INT CONF ROBOT, P4068
   Seungwoo Jeon, 2010, Proceedings of the Seventh International Conference on Information Technology: New Generations (ITNG 2010), P834, DOI 10.1109/ITNG.2010.193
   Shen J, 2015, J INTERNET TECHNOL, V16, P171
   Robert V, 2014, INT C INTELL COMP CO, P239, DOI 10.1109/ICCP.2014.6937003
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
NR 27
TC 16
Z9 19
U1 1
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18387
EP 18407
DI 10.1007/s11042-016-4123-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800010
DA 2024-07-18
ER

PT J
AU Bok, K
   Hwang, J
   Lim, J
   Kim, Y
   Yoo, J
AF Bok, Kyoungsoo
   Hwang, Jaemin
   Lim, Jongtae
   Kim, Yeonwoo
   Yoo, Jaesoo
TI An efficient MapReduce scheduling scheme for processing large multimedia
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MapReduce; Scheduling; Deadline; I/Oload; Speculative task; Large
   multimedia data
ID PERFORMANCE; ALGORITHM
AB In this paper, we propose a scheduling scheme to minimize the deadline miss of jobs to which deadlines are assigned when processing large multimedia data such as video and image in MapReduce frameworks. The proposed scheme checks the satisfaction of data locality to process assigned jobs within a time limit and considers whether I/O load and deadline requirement are satisfied. If jobs are run in a node with excessive I/O load, multimedia data from the replica node can be utilized to improve a job task processing speed. If available nodes are not found due to expected job completion time exceeding the deadline, the job tasks in nodes whose deadlines are available are paused temporarily to shorten the job completion time. In addition, speculative tasks and hot data block replication are employed to prevent the overall deadline miss ratio from increasing due to the repetition of job pauses whose deadlines are available for the purpose of processing urgent jobs quickly. The speculative task is a technique for assigning the same job to other nodes redundantly and for taking the result from the node that completes the job first and then cancelling the other jobs assigned previously. To verify the superiority of the proposed scheme, a performance evaluation is conducted by comparing it with the existing scheme. The performance evaluation result showed that the proposed scheme reduced completion time by 13.8 % and improved the deadline success ratio by 11 % compared with those of the existing scheme on average.
C1 [Bok, Kyoungsoo; Hwang, Jaemin; Lim, Jongtae; Kim, Yeonwoo; Yoo, Jaesoo] Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
C3 Chungbuk National University
RP Yoo, J (corresponding author), Chungbuk Natl Univ, Sch Informat & Commun Engn, Chungdae Ro 1, Cheongju 28644, Chungbuk, South Korea.
EM ksbok@chungbuk.ac.kr; passionhjm@naver.com; efzotz@gmail.com;
   sage106@nate.com; yjs@chungbuk.ac.kr
OI YOO, JAESOO/0000-0001-9926-9947
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) [IITP-2016-H8501-16-1013];
   National Research Foundation of Korea (NRF) - Ministry of Education
   [2015R1D1A3A01015962]; National Research Foundation of Korea (NRF) -
   Korea government (MSIP) [2016R1A2B3007527]; Support Program for
   Establishment of a National Scientific Data Governance System of Korea
   Institute of Science and Technology Information [K-16-L03-C01-S02]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2016-H8501-16-1013) supervised by the IITP
   (Institute for Information & communication Technology Promotion), by
   Basic Science Research Program through the National Research Foundation
   of Korea (NRF) funded by the Ministry of Education
   (2015R1D1A3A01015962), by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP) (No.
   2016R1A2B3007527), and by the Support Program for Establishment of a
   National Scientific Data Governance System (K-16-L03-C01-S02) of Korea
   Institute of Science and Technology Information.
CR Alam A, 2014, 2014 INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND COMPUTATIONAL INTELLIGENCE (CSCI), VOL 2, P288, DOI 10.1109/CSCI.2014.140
   Alham NK, 2011, COMPUT MATH APPL, V62, P2801, DOI 10.1016/j.camwa.2011.07.046
   Althebyan Q, 2015, CONCURR COMP-PRACT E, V27, P5686, DOI 10.1002/cpe.3595
   Apache&TRADE; Hadoop, 2013, FAIR SCHED
   Asahara M., 2012, 2012 IEEE 4th International Conference on Cloud Computing Technology and Science (CloudCom). Proceedings, P317, DOI 10.1109/CloudCom.2012.6427572
   Assunçao MD, 2015, J PARALLEL DISTR COM, V79-80, P3, DOI 10.1016/j.jpdc.2014.08.003
   Azzedin F, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P155
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Dai XM, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511252
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dittrich J, 2012, PROC VLDB ENDOW, V5, P2014, DOI 10.14778/2367502.2367562
   Dörre J, 2015, CONCURR COMP-PRACT E, V27, P1734, DOI 10.1002/cpe.3333
   Dong B, 2014, J SYST SOFTWARE, V93, P132, DOI 10.1016/j.jss.2014.02.038
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Ghemawat S., 2003, ACM SIGOPS OPERATING, V37, P29, DOI [DOI 10.1145/945445.945450, DOI 10.1145/1165389.945450, 10.1145/1165389.945450]
   Hare JS, 2014, MULTIMED TOOLS APPL, V71, P1215, DOI 10.1007/s11042-012-1256-0
   Hua XY, 2014, J PARALLEL DISTR COM, V74, P2770, DOI 10.1016/j.jpdc.2014.03.010
   Idris M, 2015, CONCURR COMP-PRACT E, V27, P5332, DOI 10.1002/cpe.3578
   Kao YC, 2016, J SYST SOFTWARE, V112, P65, DOI 10.1016/j.jss.2015.11.001
   Kim Y, 2015, IEICE T INF SYST, VE98D, P835, DOI 10.1587/transinf.2014EDP7258
   Kurazumi S, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON NETWORKING AND COMPUTING (ICNC 2012), P288, DOI 10.1109/ICNC.2012.53
   Landset S., 2015, Journal of Big Data, V2, P1, DOI DOI 10.1186/S40537-015-0032-1
   Li HL, 2014, CONCURR COMP-PRACT E, V26, P766, DOI 10.1002/cpe.3050
   Ryu C, 2013, INT CONF CLOUD COMP, P305, DOI 10.1109/CloudCom.2013.153
   Shvachko K., 2010, 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), P1
   Tan J, 2012, IEEE INFOCOM SER, P2586, DOI 10.1109/INFCOM.2012.6195658
   Tang Z, 2013, CLUSTER COMPUT, V16, P651, DOI 10.1007/s10586-012-0236-5
   Tian C, 2009, 2009 EIGHTH INTERNATIONAL CONFERENCE ON GRID AND COOPERATIVE COMPUTING, PROCEEDINGS, P218, DOI 10.1109/GCC.2009.19
   Wang K, 2013, J COMPUTATIONAL INFO, V9, P2819
   Xuelian Lin, 2012, 2012 IEEE International Conference on Cluster Computing Workshops (Cluster Workshops 2012), P231, DOI 10.1109/ClusterW.2012.24
   Yang SJ, 2015, J NETW COMPUT APPL, V57, P61, DOI 10.1016/j.jnca.2015.07.012
   Yazdanov L, 2015, 2015 IEEE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, P821, DOI 10.1109/CLOUD.2015.113
   Zaharia M., 2009, P HAD SUMM
   Zaharia M., 2008, P 8 USENIX C OP SYST, P29
   Zaharia M, 2010, EUROSYS'10: PROCEEDINGS OF THE EUROSYS 2010 CONFERENCE, P265
NR 35
TC 10
Z9 11
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17273
EP 17296
DI 10.1007/s11042-016-4026-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500022
DA 2024-07-18
ER

PT J
AU Khare, V
   Shivakumara, P
   Paramesran, R
   Blumenstein, M
AF Khare, Vijeta
   Shivakumara, Palaiahnakote
   Paramesran, Raveendran
   Blumenstein, Michael
TI Arbitrarily-oriented multi-lingual text detection in video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Higher order moments; Stroke width distance; dynamic window; Caption
   text; Region growing; Arbitrarily-oriented text detection; Multi-lingual
   text detection
ID SCENE TEXT; TRACKING; WAVELET
AB Text detection in arbitrarily-oriented multi-lingual video is an emerging area of research because it plays a vital role for developing real-time indexing and retrieval systems. In this paper, we propose to explore moments for identifying text candidates. We introduce a novel idea for determining automatic windows to extract moments for tackling multi-font and multi-sized text in video based on stroke width information. The temporal information is explored to find deviations between moving and non-moving pixels in successive frames iteratively, which results in static clusters containing caption text and dynamic clusters containing scene text, as well as background pixels. The gradient directions of pixels in static and dynamic clusters are analyzed to identify the potential text candidates. Furthermore, boundary growing is proposed that expands the boundary of potential text candidates until it finds neighbor components based on the nearest neighbor criterion. This process outputs text lines appearing in the video. Experimental results on standard video data, namely, ICDAR 2013, ICDAR 2015, YVT videos and on our own English and Multi-lingual videos demonstrate that the proposed method outperforms the state-of-the-art methods.
C1 [Khare, Vijeta; Paramesran, Raveendran] Univ Malaya, Fac Engn, Kuala Lumpur, Malaysia.
   [Shivakumara, Palaiahnakote] Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.
   [Shivakumara, Palaiahnakote] Univ Malaya, Comp Syst & Informat Technol, BS-18,Annex Bldg, Kuala Lumpur 50603, Malaysia.
   [Blumenstein, Michael] Univ Technol Sydney, Sch Software, Sydney, NSW, Australia.
C3 Universiti Malaya; Universiti Malaya; Universiti Malaya; University of
   Technology Sydney
RP Shivakumara, P (corresponding author), Univ Malaya, Fac Comp Sci & Informat Technol, Kuala Lumpur, Malaysia.; Shivakumara, P (corresponding author), Univ Malaya, Comp Syst & Informat Technol, BS-18,Annex Bldg, Kuala Lumpur 50603, Malaysia.
EM kharevijeta@gmail.com; hudempsk@yahoo.com; ravee58@gmail.com;
   Michael.Blumenstein@uts.edu.au
RI Paramesran, Raveendran/AAA-1895-2019; Palaiahnakote,
   Shivakumara/ITU-6488-2023; Palaiahnakote, Shivakumara/B-6261-2013;
   Khare, Vijeta/W-2643-2018
OI Paramesran, Raveendran/0000-0001-5093-7027; Khare,
   Vijeta/0000-0002-2952-0734
FU University of Malaya HIR [UM.C/625/1/HIR/MOHE/ENG/42]
FX The work is also partly supported by the University of Malaya HIR under
   Grant No: UM.C/625/1/HIR/MOHE/ENG/42. The authors would like to thank
   the anonymous reviewers for their constructive comments and suggestions,
   which helped us to improve the quality and to clarify the paper
   significantly.
CR [Anonymous], 2013, P 12 INT C DOC AN RE
   Bernsen J., 1986, In: Proceedings of the Eighth International Conference on Pattern Recognition, P1251
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Huang XD, 2014, MULTIMED TOOLS APPL, V70, P1703, DOI 10.1007/s11042-012-1201-2
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Khare V, 2015, EXPERT SYST APPL, V42, P7627, DOI 10.1016/j.eswa.2015.06.002
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Liang GZ, 2015, IEEE T IMAGE PROCESS, V24, P4488, DOI 10.1109/TIP.2015.2465169
   Lijie Li, 2010, Proceedings of the 2010 International Conference on Computer and Information Application (ICCIA 2010), P434, DOI 10.1109/ICCIA.2010.6141629
   Liu CM, 2005, PROC INT CONF DOC, P610
   Liu X, 2008, PATTERN RECOGN, V41, P484, DOI 10.1016/j.patcog.2007.06.004
   Liu XQ, 2012, IEEE T MULTIMEDIA, V14, P482, DOI 10.1109/TMM.2011.2177646
   Mi Y., 2005, INT C INFORM COMMUNI, P678, DOI DOI 10.1109/ICICS.2005.1689133
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Phan T.Q., 2012, Proceedings of ACM MM'12, ACM, P765
   Nguyen PX, 2014, IEEE WINT CONF APPL, P776, DOI 10.1109/WACV.2014.6836024
   Qian XM, 2014, MULTIMED TOOLS APPL, V70, P1487, DOI 10.1007/s11042-012-1168-z
   Risnumawan A, 2014, EXPERT SYST APPL, V41, P8027, DOI 10.1016/j.eswa.2014.07.008
   Roy S, 2015, EXPERT SYST APPL, V42, P5554, DOI 10.1016/j.eswa.2015.02.030
   Shi BG, 2015, PROC INT CONF DOC, P531, DOI 10.1109/ICDAR.2015.7333818
   Shivakumara P, 2014, MULTIMED TOOLS APPL, V72, P515, DOI 10.1007/s11042-013-1385-0
   Shivakumara P, 2013, IEEE T CIRC SYST VID, V23, P1729, DOI 10.1109/TCSVT.2013.2255396
   Shivakumara P, 2012, IEEE T CIRC SYST VID, V22, P1227, DOI 10.1109/TCSVT.2012.2198129
   Shivakumara P, 2011, IEEE T PATTERN ANAL, V33, P412, DOI 10.1109/TPAMI.2010.166
   Shivakumara P, 2010, IEEE T CIRC SYST VID, V20, P1520, DOI 10.1109/TCSVT.2010.2077772
   Su F, 2015, PROC INT CONF DOC, P916, DOI 10.1109/ICDAR.2015.7333895
   Tian SX, 2016, PATTERN RECOGN, V51, P125, DOI 10.1016/j.patcog.2015.07.009
   Wang GH, 2008, INT C PATT RECOG, P3466
   Wang YK, 2006, INT C PATT RECOG, P754
   Wu H, 2016, AUTOMATIC VIDEO TEXT
   Wu L, 2015, IEEE T MULTIMEDIA, V17, P1137, DOI 10.1109/TMM.2015.2443556
   Xiaodong Huang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P469, DOI 10.1109/CISP.2011.6099945
   Yang HJ, 2014, MULTIMED TOOLS APPL, V69, P217, DOI 10.1007/s11042-012-1250-6
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2014, IEEE T PATTERN ANAL, V36, P970, DOI 10.1109/TPAMI.2013.182
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P790, DOI 10.1109/TIP.2010.2068553
   Zhou JC, 2007, INTERNATIONAL CONFERENCE ON MACHINE VISION 2007, PROCEEDINGS, P119, DOI 10.1109/ICMV.2007.4469284
   Zhou YH, 2013, PROC INT CONF DOC, P457, DOI 10.1109/ICDAR.2013.98
NR 38
TC 19
Z9 20
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 15
BP 16625
EP 16655
DI 10.1007/s11042-016-3941-x
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KF
UT WOS:000404609100025
DA 2024-07-18
ER

PT J
AU Sung, CS
   Kim, CH
   Park, JY
AF Sung, Chang Soo
   Kim, Chi Ha
   Park, Joo Yeon
TI Development of humming call system for blocking spam on a smartphone
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smart device; Smart phone; Humming call system; Spam call; Spam mail;
   Security
AB Smart devices such as smart phone play an important role in networked environments as connecting to other network devices and Internet Things. Smart phone combines the features of cell phone and a personal computer operating system. And it has become one of vital elements for modern people and society. However, smartphone has drawbacks like spam and security. Globally, people are exposed to spam call that they receive promotion calls from twice to dozens of times a day, spam call and voice phishing due to hacking and personal information leak in the internet environment. This phenomenon can cause personal stress, anxiety due to phone bank fraud, waste of time for receiving spam call, disturbance during work, criminal and the other serious social problems. In the present study, Humming Call system has been studied and developed to provide the measurement for evaluation and activation of service to prevent spam call in advance as a solution for the aforementioned problem. Hamming call is a service which receives information to help call through differentiation from existing service related to anti-spam system from DB (Internal DB) and Server. Then it provides the information for incoming call and outgoing call. To measure the actual performance by utilizing the system of this present study, DB has used CUBRID DBMS for 6 months and data stored in DB have been extracted through SQL Statement. The results indicate that this system prevents such problem for over 30%. If main function among various functions of this system is specialized and developed focusing on management of spam call from phone number, the system would perform more effectively.
C1 [Sung, Chang Soo; Kim, Chi Ha] Dongguk Univ, Grad Sch Technol Entrepreneurship, Seoul, South Korea.
   [Park, Joo Yeon] Yonsei Univ, Yonsei Business Sch, Seoul, South Korea.
C3 Dongguk University; Yonsei University
RP Park, JY (corresponding author), Yonsei Univ, Yonsei Business Sch, Seoul, South Korea.
EM redsun44@dongguk.edu; kingch@letscombine.com; park3500@naver.com
OI Park, Joo Yeon/0000-0002-5231-5405
CR Anand R, 2014, MOBILE PHONE DIRECTO
   Christophe N, 2016, FULL SCREEN CALLER I
   Gogolook, 2013, WHOSC SERV
   Jenny C, 2014, WHY NAVER SPENT MILL
   Kok FK, 2016, TRUEINSIGHTS NEW SPA
   Korea Internet & Security Agency (KISA), 2015, US GUID PREV ILL SPA, P85
   Kwon OH, 2014, J KOREAN MED ASSOC, V57, P1027, DOI 10.5124/jkma.2014.57.12.1027
   Lalit K, 2016, TRUECALLER FINDS UNK
   Mathieu B, 2008, IEEE SECUR PRIV, V6, P52, DOI 10.1109/MSP.2008.149
   Rosenberg J, 2008, 5039 IETF RFC
   Schlegel R, 2006, GLOB TELECOMM CONF
   Shin D, 2006, IEEE NETWORK, V20, P18, DOI 10.1109/MNET.2006.1705879
   Victoria W, 2015, ANDROID MALWARE MAKE
   Yang CS, 2013, STATUS SPAM DISTRIBU
NR 14
TC 3
Z9 3
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17371
EP 17383
DI 10.1007/s11042-017-4511-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500027
DA 2024-07-18
ER

PT J
AU Huang, C
   Luo, W
   Xie, YR
AF Huang, Chao
   Luo, Wang
   Xie, Yurui
TI Local-class-shared-topic latent Dirichlet allocation based scene
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene classification; Local-class-shared topic; Local-class-specific
   topic; Graphical model
ID SEGMENTATION; MODEL
AB In this paper, we propose a hierarchical probabilistic model for scene classification. This model infers the local-class-shared and local-class-specific latent topics respectively. Our approach consists of first learning the latent topics from the BoW representation and subsequently, training SVM on the distribution of the latent topics. This approach is compared to that of using traditional graphical models to learn the latent topics and training SVM on the topic distribution. The experiments on a variety of datasets show that the topics learned by our model have higher discriminative power.
C1 [Huang, Chao; Xie, Yurui] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Peoples R China.
   [Luo, Wang] NARI Grp Corp, State Grid Elect Power Res Inst, Nanjing, Jiangsu, Peoples R China.
C3 University of Electronic Science & Technology of China; State Grid
   Corporation of China; Nari Group Corp
RP Huang, C (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu, Peoples R China.
EM huangchao_usetc@aliyun.com; luowang@sgepri.sgcc.com.cn;
   gloriousxyr@163.com
RI Huang, Chao/JJD-0553-2023; Huang, Chao/L-1445-2019
OI Huang, Chao/0000-0001-8775-3192; 
FU National Natural Science Foundation of China [61525102, 61271289]; The
   program for Science and Technology Innovative Research Team for Young
   Scholars in Sichuan Province, China [2014TD0006]
FX This work was supported in part by National Natural Science Foundation
   of China (No. 61525102, 61271289), and by The program for Science and
   Technology Innovative Research Team for Young Scholars in Sichuan
   Province, China (No. 2014TD0006).
CR [Anonymous], 2004, WORKSH STAT LEARN CO
   [Anonymous], 2012, LIBSVM LIB SUPPORT V
   [Anonymous], 2006, 2006 C COMP VIS PATT
   [Anonymous], 2010, P NIPS
   [Anonymous], CATEGORY SPECIFIC DI
   [Anonymous], CVPR
   [Anonymous], 2008, P ADV NEURAL INFORM
   [Anonymous], CONVOLUTIONAL NEURAL
   [Anonymous], IEEE T GEOSCI REMOTE
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], 2015, Mathematical Problems in Engineering
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Breiman L., 2001, Mach. Learn., V45, P5
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li HL, 2014, IEEE T IMAGE PROCESS, V23, P3545, DOI 10.1109/TIP.2014.2330759
   Li HL, 2013, IEEE T MULTIMEDIA, V15, P1896, DOI 10.1109/TMM.2013.2271476
   Li HL, 2011, IEEE T IMAGE PROCESS, V20, P3365, DOI 10.1109/TIP.2011.2156803
   Li L. J., 2007, IEEE INT C COMPUTER, P1
   Li LJ, 2009, PROC CVPR IEEE, P2036, DOI 10.1109/CVPRW.2009.5206718
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   Niu ZX, 2012, PROC CVPR IEEE, P2743, DOI 10.1109/CVPR.2012.6247997
   Niu ZX, 2011, PROC CVPR IEEE, P1769, DOI 10.1109/CVPR.2011.5995426
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F., 2007, IEEE C COMPUTER VISI
   Rasiwasia N, 2013, IEEE T PATTERN ANAL, V35, P2665, DOI 10.1109/TPAMI.2013.69
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Winn J, 2005, J MACH LEARN RES, V6, P661
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
   Zhu J., 2009, Proceedings of the 26th Annual International Conference on Machine Learning, ICML '09, P1257, DOI DOI 10.1145/1553374.1553535
NR 40
TC 1
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15661
EP 15679
DI 10.1007/s11042-016-3863-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900020
DA 2024-07-18
ER

PT J
AU Kalamaras, I
   Dimitriou, N
   Drosou, A
   Tzovaras, D
AF Kalamaras, Ilias
   Dimitriou, Nikolaos
   Drosou, Anastasios
   Tzovaras, Dimitrios
TI Accessibility-based reranking in multimedia search engines
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Accessibility-based search engines; Accessibility reranking;
   Accessibility feature extraction; Multi-objective optimization
ID VISUAL-ACUITY; VISION; OPTIMIZATION; CATARACT
AB Traditional multimedia search engines retrieve results based mostly on the query submitted by the user, or using a log of previous searches to provide personalized results, while not considering the accessibility of the results for users with vision or other types of impairments. In this paper, a novel approach is presented which incorporates the accessibility of images for users with various vision impairments, such as color blindness, cataract and glaucoma, in order to rerank the results of an image search engine. The accessibility of individual images is measured through the use of vision simulation filters. Multi-objective optimization techniques utilizing the image accessibility scores are used to handle users with multiple vision impairments, while the impairment profile of a specific user is used to select one from the Pareto-optimal solutions. The proposed approach has been tested with two image datasets, using both simulated and real impaired users, and the results verify its applicability. Although the proposed method has been used for vision accessibility-based reranking, it can also be extended for other types of personalization context.
C1 [Kalamaras, Ilias] Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England.
   [Dimitriou, Nikolaos; Drosou, Anastasios; Tzovaras, Dimitrios] Ctr Res & Technol Hellas, Inst Informat Technol, Thessaloniki, Greece.
C3 Imperial College London; Centre for Research & Technology Hellas
RP Kalamaras, I (corresponding author), Imperial Coll London, Dept Elect & Elect Engn, London SW7 2AZ, England.
EM i.kalamaras11@imperial.ac.uk; nikdim@iti.gr; drosou@iti.gr;
   dimitrios.tzovaras@iti.gr
RI Drosou, Anastasios/AAV-5969-2020; Tzovaras, Dimitrios/ABB-9576-2021;
   Dimitriou, Nikolaos/AAF-4700-2020
OI Tzovaras, Dimitrios/0000-0001-6915-6722; Dimitriou,
   Nikolaos/0000-0002-6650-7758
FU EU [FP7-287704, FP7-610510]
FX This work was partially supported by the EU funded projects CUbRIK
   (FP7-287704) and Prosperity4All (FP7-610510).
CR Adomavicius G, 2011, RECOMMENDER SYSTEMS HANDBOOK, P217, DOI 10.1007/978-0-387-85820-3_7
   [Anonymous], 2001, TECH REP GLORIASTRAS, DOI DOI 10.3929/ETHZ-A-004284029
   [Anonymous], 2013, Colour Appearance Models
   [Anonymous], 2008, INTRO INFORM RETRIEV, DOI DOI 10.1017/CBO9780511809071
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Backstrom Lars., 2008, P 17 INT C WORLD WID, P357, DOI DOI 10.1145/1367497.1367546
   BELKIN NJ, 1995, INFORM PROCESS MANAG, V31, P431, DOI 10.1016/0306-4573(94)00057-A
   Brettel H, 1997, J OPT SOC AM A, V14, P2647, DOI 10.1364/JOSAA.14.002647
   Cao Huanhuan, 2008, P 14 ACM SIGKDD INT, P875
   Chen YR, 2006, MATER SCI FORUM, V505-507, P277, DOI 10.4028/www.scientific.net/MSF.505-507.277
   Chin T.-J., 2009, NIPS, P333
   Coello Carlos A Coello, 2007, EVOLUTIONARY ALGORIT, V5
   Ehrgott M., 2005, Multicriteria optimization, V2
   Fine EM, 1999, OPTOMETRY VISION SCI, V76, P468, DOI 10.1097/00006324-199907000-00022
   Fox E., 1994, Combination of multiple searches, P243
   Friedman DS, 2002, OPHTHALMOLOGY, V109, P1902, DOI 10.1016/S0161-6420(02)01267-8
   Giakoumis D, 2013, ENABLING USER INTERF, P1
   HIRVELA H, 1995, ACTA OPHTHALMOL SCAN, V73, P111
   JI TL, 1994, IEEE T MED IMAGING, V13, P573, DOI 10.1109/42.363111
   Johnson GM, 2001, NINTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P108
   Kalamaras I, 2014, IEEE T MULTIMEDIA, V16, P1460, DOI 10.1109/TMM.2014.2316473
   Kim HW, 2012, IEEE T CONSUM ELECTR, V58, P1416, DOI 10.1109/TCE.2012.6415015
   Kim IY, 2005, STRUCT MULTIDISCIP O, V29, P149, DOI 10.1007/s00158-004-0465-1
   LAVERY JR, 1988, OPHTHAL PHYSL OPT, V8, P390, DOI 10.1111/j.1475-1313.1988.tb01174.x
   Lawrence S., 2000, IEEE DATA ENG B, V23, P25
   Leung KWT, 2013, IEEE T KNOWL DATA EN, V25, P820, DOI 10.1109/TKDE.2012.23
   Liu F, 2004, IEEE T KNOWL DATA EN, V16, P28, DOI 10.1109/TKDE.2004.1264820
   Liu J, 2014, IEEE T MULTIMEDIA, V16, P588, DOI 10.1109/TMM.2014.2302732
   Nikulin Y, 2012, OR SPECTRUM, V34, P69, DOI 10.1007/s00291-010-0224-1
   Sang JT, 2012, IEEE T MULTIMEDIA, V14, P963, DOI 10.1109/TMM.2011.2181344
   Tajima S, 2015, IEEE T IMAGE PROCESS, V24, P1115, DOI 10.1109/TIP.2015.2393056
   Thang TC, 2004, IEEE IMAGE PROC, P993
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P330, DOI 10.1109/TMM.2010.2046364
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wong HS, 2011, IEEE I CONF COMP VIS, P1044, DOI 10.1109/ICCV.2011.6126350
   Xiang BA, 2010, SIGIR 2010: PROCEEDINGS OF THE 33RD ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH DEVELOPMENT IN INFORMATION RETRIEVAL, P451
   Yang S, 2004, ETRI J, V26, P195, DOI 10.4218/etrij.04.0603.0007
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
NR 38
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 14
BP 15923
EP 15949
DI 10.1007/s11042-016-3886-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EZ3KN
UT WOS:000404609900031
OA hybrid
DA 2024-07-18
ER

PT J
AU Li, YF
   Chen, RN
AF Li, Yufeng
   Chen, Ruining
TI Motion vector recovery for video error concealment based on the plane
   fitting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264 video; Error concealment; Plane fitting; Motion vector
AB In a wireless transmission, the compressed video stream can result in lower quality of image reconstruction with the motion vector mismatch. A motion vector recovery for video error concealment based on the plane fitting algorithm is proposed. According to the characteristics of the H.264 video standard, the adjacent macro blocks and the multi reference frame have the correlation. The motion vector which surrounds the lost macro-block in each divided block is projected by one plane which adopts one point to present the MV changing tendency in small regions. This algorithm reconstructs the motion vector of the damaged macro-block by the fitting plane algorithm based on the improved boundary matching algorithm, and then the optimal motion vector is selected to reconstruct the damaged images. This algorithm not only avoids the block effects that caused by the original algorithm, but also in different probability of RTP packet losing, the peak signal to noise ratio of the algorithm has improved 0.3 similar to 2.5 dB compared to the adaptive intra-frame error concealment algorithm .
C1 [Li, Yufeng] Shenyang Aerosp Univ, Coll Elect & Informat Engn, Shenyang 264025, Peoples R China.
   [Chen, Ruining] Shenyang Aerosp Univ, Sch Elect & Informat Engn, Shenyang 110136, Peoples R China.
C3 Shenyang Aerospace University; Shenyang Aerospace University
RP Li, YF (corresponding author), Shenyang Aerosp Univ, Coll Elect & Informat Engn, Shenyang 264025, Peoples R China.
EM 18804038409@163.com
CR Asheri H, 2012, IEEE T CONSUM ELECTR, V58, P880, DOI 10.1109/TCE.2012.6311331
   Chang Yueh-Lun., 2014, Improving end-user video quality through error concealment and packet importance modeling
   Ghasemi ARA, 2016, SIVIP, V10, P311
   He Jiming, 2012, Video Engineering, V36, P35
   Josh H, 2016, MACH VISION APPL, V27, P967, DOI 10.1007/s00138-016-0764-8
   Kim D, 2010, OPT ENG, V49, DOI 10.1117/1.3454381
   Koloda J, 2013, CIRC SYST SIGNAL PR, V32, P815, DOI 10.1007/s00034-012-9504-0
   Lawal IA, 2017, IEEE T CIRC SYST VID, V27, P2395, DOI 10.1109/TCSVT.2016.2580401
   Lee PJ, 2016, INT J FUZZY SYST, V18, P62, DOI 10.1007/s40815-015-0097-1
   Lie WN, 2014, IEEE T MULTIMEDIA, V16, P216, DOI 10.1109/TMM.2013.2281587
   Liu XM, 2017, IEEE T IMAGE PROCESS, V26, P782, DOI 10.1109/TIP.2016.2623481
   Qaratlu MM, 2011, SIGNAL PROCESS-IMAGE, V26, P304, DOI 10.1016/j.image.2011.04.004
   Ranjbar M, 2009, COMPUT ELECTR ENG, V35, P536, DOI 10.1016/j.compeleceng.2008.08.002
   Salama P., 1998, EORROR CONCEALMENT E, P199
   Tasdemir K, 2016, IEEE T IMAGE PROCESS, V25, P3316, DOI 10.1109/TIP.2016.2567073
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Y. K., 2002, P ICIP, P154
   Wang Zhao, 2016, IEEE T IMAGE PROCESS
   Xiang YJ, 2011, MULTIMED TOOLS APPL, V52, P91, DOI 10.1007/s11042-009-0457-7
   Xiao XM, 2015, IEEE T AERO ELEC SYS, V51, P2864, DOI 10.1109/TAES.2015.140378
   Yan B, 2011, IEEE T BROADCAST, V57, P253, DOI 10.1109/TBC.2011.2127550
   Yang ML, 2016, SIGNAL PROCESS-IMAGE, V47, P313, DOI 10.1016/j.image.2016.05.014
   Zhang YB, 2012, IEEE T CIRC SYST VID, V22, P12, DOI 10.1109/TCSVT.2011.2130450
   Zhou J, 2011, IEEE T BROADCAST, V57, P75, DOI 10.1109/TBC.2010.2086771
   Zlokazov VB, 2014, J PHYS PART NUCL LET, V11, P48
NR 25
TC 7
Z9 7
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14993
EP 15006
DI 10.1007/s11042-017-4407-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400025
DA 2024-07-18
ER

PT J
AU Shi, ZH
   Zhu, MM
   Bin Guo
   Zhao, MH
AF Shi, Zhenghao
   Zhu, Meimei
   Bin Guo
   Zhao, Minghua
TI A photographic negative imaging inspired method for low illumination
   night-time image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low illumination night-time image; Image enhancement; Negative image;
   Dark channel prior
ID CONTRAST ENHANCEMENT; BRIGHTNESS
AB Images captured in low illumination conditions usually suffer from a poor visibility which has an important affect on the performance of computer vision systems. Thereby low illumination image enhancement is critical for image-related applications. In this paper, we proposed a photographic negative imaging inspired method for enhancing the images taken under low illumination environments. It consists of three basic components. First, the input night-time image is reversed to obtain its corresponding negative image (which is comparable with the latent image of a photographic film). Second, a rectification on the negative image is performed (Which is comparable with the chemical development in the process of film processing) by using an image dehazing method. This operation is inspired by the observation that the negative image looks like a hazed image and thereby it can be enhanced using a dehazing method. Third, the rectified negative image is reversed to obtain the final enhanced image (Which is comparable with the operation of fixing in the later stage of film processing.). Experiments over a large quantity of low contrast night-time images show that the proposed method is effective for enhancing low illumination images. Compared with six state-of-the-art image enhancement methods, the proposed method is superior to them in both enhancing image quality and decreasing time cost.
C1 [Shi, Zhenghao; Zhu, Meimei; Zhao, Minghua] Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
   [Bin Guo] Northwestern Polytech Univ, Sch Comp, Xian 710072, Peoples R China.
C3 Xi'an University of Technology; Northwestern Polytechnical University
RP Shi, ZH (corresponding author), Xian Univ Technol, Sch Comp Sci & Engn, Xian 710048, Peoples R China.
EM ylshi@xaut.edu.cn
OI Guo, Bin/0000-0001-6097-2467
FU National Natural Science Foundation of China [61202198, 61401355,
   41601353]; China Scholarship Council [201608610048]; Key Laboratory
   Foundation of Shaanxi Education Department [14JS072]; Nature Science
   Foundation of Science Department of PeiLin count at Xi'an [GX1619]
FX This work was supported in part by a grant from the National Natural
   Science Foundation of China (No. 61202198, No.61401355, No. 41601353), a
   grant from the China Scholarship Council (No.201608610048), the Key
   Laboratory Foundation of Shaanxi Education Department (No.14JS072) and
   the Nature Science Foundation of Science Department of PeiLin count at
   Xi'an(GX1619). The authors gratefully acknowledge the helpful comments
   and suggestions of the reviewers.
CR [Anonymous], 2016, IEEE INTELL SYST
   Chang J, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P257, DOI 10.1109/CISP.2015.7407886
   Elad M, 2005, LECT NOTES COMPUT SC, V3459, P217
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hogervorst MA, 2010, INFORM FUSION, V11, P69, DOI 10.1016/j.inffus.2009.06.005
   Huang SC, 2013, ENG APPL ARTIF INTEL, V26, P1487, DOI 10.1016/j.engappai.2012.11.011
   Jang CY, 2012, INT SOC DESIGN CONF, P37, DOI 10.1109/ISOCC.2012.6406919
   Jang CY, 2012, P INT C IM PROC COMP, P1
   Jang IS, 2009, J IMAGING SCI TECHN, V53, P501
   Jang S., 2010, 2010 INT S OPT TECHN, P1
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6
   LAND EH, 1986, VISION RES, V26, P7, DOI 10.1016/0042-6989(86)90067-2
   LAND EH, 1986, P NATL ACAD SCI USA, V83, P3078, DOI 10.1073/pnas.83.10.3078
   Lin SCF, 2015, COMPUT ELECTR ENG, V46, P356, DOI 10.1016/j.compeleceng.2015.06.001
   Qian XY, 2012, INFRARED PHYS TECHN, V55, P122, DOI 10.1016/j.infrared.2011.10.008
   Rahman ZU, 2011, J VIS COMMUN IMAGE R, V22, P237, DOI 10.1016/j.jvcir.2010.12.006
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Tsagaris V, 2005, DISPLAYS, V26, P191, DOI 10.1016/j.displa.2005.06.007
   Wang W, 2008, INT C WAVEL ANAL PAT, P80, DOI 10.1109/ICWAPR.2008.4635754
   [肖俊 XIAO Jun], 2008, [中国图象图形学报, Journal of Image and Graphics], V13, P2302
   Xu Q, 2014, SIGNAL PROCESS, V103, P309, DOI 10.1016/j.sigpro.2014.02.013
   Yin SF, 2010, INFRARED PHYS TECHN, V53, P146, DOI 10.1016/j.infrared.2009.10.007
   Zhao H., 2015, EMERGING TRENDS IMAG, P249
   Zhou ZG, 2014, OPTIK, V125, P1795, DOI 10.1016/j.ijleo.2013.09.051
NR 26
TC 13
Z9 13
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 15027
EP 15048
DI 10.1007/s11042-017-4453-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400027
DA 2024-07-18
ER

PT J
AU You, F
   Li, YH
   Huang, L
   Chen, K
   Zhang, RH
   Xu, JM
AF You, Feng
   Li, Yao-hua
   Huang, Ling
   Chen, Kang
   Zhang, Rong-hui
   Xu, Jian-min
TI Monitoring drivers' sleepy status at night based on machine vision
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Night monitoring; IR illumination; Gabor filter; Fatigue driving
ID INFRARED IMAGE-ENHANCEMENT; VIDEO STRUCTURAL DESCRIPTION; RAPID OBJECT
   DETECTION; DESCRIPTION TECHNOLOGY; EQUALIZATION; ALGORITHM; FEATURES;
   DROWSINESS; HISTOGRAM; BLINKS
AB Driver fatigue is a chief cause of traffic accidents. For this reason, it is essential to develop a monitoring system for drivers' level of fatigue. In recent years, driver fatigue monitoring technology based on machine vision has become a research hotspot, but most research focuses on driver fatigue detection during the day. This paper presents a night monitoring system for real-time fatigue driving detection, which makes up for the deficiencies of fatigue driving detection technology at night. First, we use infrared imaging to capture a driver's image at night, and then we design an algorithm to detect the driver's face. Second, we propose a new eye-detection algorithm that combines a Gabor filter with template matching to locate the position of the corners of the eye, and add an eye-validation process to increase the accuracy of the detection rate. Third, we use a spline function to fit the eyelid curve. After extracting eye fatigue features, we use eye blinking parameters to evaluate fatigue. Our system has been tested on the IMMFace Database, which contains more than 200 faces, as well as in a real-time test. The experimental results show that the system has good accuracy and robustness.
C1 [You, Feng; Li, Yao-hua; Huang, Ling; Chen, Kang; Xu, Jian-min] South China Univ Technol, Sch Civil Engn & Transportat, Guangzhou 510640, Guangdong, Peoples R China.
   [Zhang, Rong-hui] Sun Yat Sen Univ, Sch Engn, Res Ctr Intelligent Transportat Syst, Guangzhou 510275, Guangdong, Peoples R China.
C3 South China University of Technology; Sun Yat Sen University
RP Zhang, RH (corresponding author), Sun Yat Sen Univ, Sch Engn, Res Ctr Intelligent Transportat Syst, Guangzhou 510275, Guangdong, Peoples R China.
EM zrh1981819@126.com
RI Zhang, Ronghui/ABF-1614-2021
OI Zhang, Ronghui/0000-0001-7838-0638; Zhang, Ronghui/0000-0001-6107-4044
FU National Natural Science Foundation of China [51408237, 51108192,
   51208500]; Chinese Postdoctoral Science Foundation [2012 M521824, 2013
   T60904]; Public Welfare Research and Capacity Building Project of
   Guangdong Province [B2161520]; Students' Research Program (SRP) of the
   South China University of Technology; China new energy automobile
   products testing conditions research and development-Guangzhou traffic
   condition data collection
FX This work was partially supported by the National Natural Science
   Foundation of China (Grant Nos. 51408237, 51108192 and 51208500), the
   Chinese Postdoctoral Science Foundation (Grant Nos. 2012 M521824 and
   2013 T60904), the Public Welfare Research and Capacity Building Project
   of Guangdong Province (Grant No. B2161520), the 2016 Students' Research
   Program (SRP) of the South China University of Technology, and China new
   energy automobile products testing conditions research and
   development-Guangzhou traffic condition data collection.
CR [Anonymous], INT J VEH TECHNOL
   [Anonymous], INT J COMPUTER APPL
   Author SJJ, 2011, OPT ENG, V50
   Bai XZ, 2011, INFRARED PHYS TECHN, V54, P61, DOI 10.1016/j.infrared.2010.12.001
   Bansode NK, 2013, SIGNAL IMAGE PROCESS, V3
   Branchitta F, 2008, OPT ENG, V47, DOI 10.1117/1.2956655
   Brill JC, 2003, DRIV FAT IS SOM MISS, P16
   Dinges D.F., 1998, PERCLOS VALID PSYCHO
   Dong YC, 2011, IEEE T INTELL TRANSP, V12, P596, DOI 10.1109/TITS.2010.2092770
   Fan X, 2010, PATTERN RECOGN LETT, V31, P234, DOI 10.1016/j.patrec.2009.08.014
   Hu CP, 2015, FRONT COMPUT SCI-CHI, V9, P980, DOI 10.1007/s11704-015-3482-x
   Ilk HG, 2011, INFRARED PHYS TECHN, V54, P427, DOI 10.1016/j.infrared.2011.06.002
   Jin LS, 2013, ADV MECH ENG, DOI 10.1155/2013/648431
   Jo J, 2014, EXPERT SYST APPL, V41, P1139, DOI 10.1016/j.eswa.2013.07.108
   Khan R, 2013, INT BHURBAN C APPL S, P117, DOI 10.1109/IBCAST.2013.6512142
   Lai R, 2010, OPT COMMUN, V283, P4283, DOI 10.1016/j.optcom.2010.06.072
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin CL, 2011, INFRARED PHYS TECHN, V54, P84, DOI 10.1016/j.infrared.2011.01.001
   Perdersoli M., 2012, BOOSTING HISTOGRAMS
   Ranney T. A., 2001, SAE Tech. Pap., P9
   Schleicher R, 2008, ERGONOMICS, V51, P982, DOI 10.1080/00140130701817062
   Shen YH, 2011, FRONT COMPUT SCI CHI, V5, P227, DOI 10.1007/s11704-011-9190-2
   Sun D, 2015, DETECTING PEDESTRIAN, P1
   Suzuki M, 2006, IEEE SYS MAN CYBERN, P2891, DOI 10.1109/ICSMC.2006.385313
   Vickers VE, 1996, OPT ENG, V35, P1921, DOI 10.1117/1.601006
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang BJ, 2006, INFRARED PHYS TECHN, V48, P77, DOI 10.1016/j.infrared.2005.04.008
   Wang YZ, 2013, J HANGZHOU DIANZI U
   Watanabe Tomoki, 2010, IPSJ Transactions on Computer Vision and Applications, V2, P39, DOI 10.2197/ipsjtcva.2.39
   Wei SD, 2008, IEEE T IMAGE PROCESS, V17, P2227, DOI 10.1109/TIP.2008.2004615
   Xu X, 2015, FACIAL EXPRESSION RE
   Xu Z, 2015, COMPUT SYST SCI ENG, V30
   Xu Z, 2016, CLUSTER COMPUT, V19, P1283, DOI 10.1007/s10586-016-0581-x
   Xu Z, 2016, MULTIMED TOOLS APPL, V75, P12155, DOI 10.1007/s11042-015-3112-5
   Xu Z, 2016, COMPUTING, V98, P35, DOI 10.1007/s00607-014-0408-7
   Yoo JC, 2009, CIRC SYST SIGNAL PR, V28, P819, DOI [10.1007/s00034-009-9130-7, 10.1007/S00034-009-9130-7]
   Zhao JF, 2014, INFRARED PHYS TECHN, V62, P86, DOI 10.1016/j.infrared.2013.11.008
   Zhao WD, 2014, INFRARED PHYS TECHN, V66, P152, DOI 10.1016/j.infrared.2014.05.018
   Zheng ZL, 2005, PATTERN RECOGN LETT, V26, P2252, DOI 10.1016/j.patrec.2005.03.033
NR 40
TC 22
Z9 22
U1 0
U2 67
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2017
VL 76
IS 13
BP 14869
EP 14886
DI 10.1007/s11042-016-4103-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX2EX
UT WOS:000403039400018
DA 2024-07-18
ER

PT J
AU Garces, E
   Agarwala, A
   Hertzmann, A
   Gutierrez, D
AF Garces, Elena
   Agarwala, Aseem
   Hertzmann, Aaron
   Gutierrez, Diego
TI Style-based exploration of illustration datasets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illustration; Style; Exploration; Visualization
AB Searching by style in illustration data sets is a particular problem in Information Retrieval which has received little attention so far. One of its main problems is that the perception of style is highly subjective, which makes labeling styles a very difficult task. Despite being difficult to predict computationally, certain properties such as colorfulness, line style or shading can be successfully captured by existing style metrics. However, there is little knowledge about how we distinguish between different styles and how these metrics can be used to guide users in style-based interactions. In this paper, we propose several contributions towards a better comprehension of illustration style and its usefulness for data exploration and retrieval. First, we provide new insights about how we perceive style in illustration. Second, we evaluate a handmade style clustering of clip art pieces with an existing style metric to analyze how this metric aligns with expert knowledge. Finally, we propose a method for efficient navigation and exploration of large clip art data sets which takes into account both semantic labeling of the data and its style. Our approach combines hierarchical clustering with dimensionality reduction techniques, and strategic sampling to obtain intuitive visualizations and useful visualizations.
C1 [Garces, Elena; Gutierrez, Diego] Univ Zaragoza, IIS Dept, Zaragoza, Spain.
   [Agarwala, Aseem] Google Res, Seattle, WA USA.
   [Hertzmann, Aaron] Adobe Res, San Francisco, CA USA.
C3 University of Zaragoza; Google Incorporated; Adobe Systems Inc.
RP Garces, E (corresponding author), Univ Zaragoza, IIS Dept, Zaragoza, Spain.
EM egarces@unizar.es; aseem@agarwala.org; hertzman@adobe.com;
   diegog@unizar.es
OI Hertzmann, Aaron/0000-0001-9667-0292; Garces, Elena/0000-0003-3509-8485;
   Gutierrez Perez, Diego/0000-0002-7503-7022
FU Gobierno de Aragon; Ministerio de Economia y Competitividad
FX We would like to thank all reviewers for their thoughtful comments. We
   also thank Carlos Bobed for insightful comments and proofreading the
   paper. This work was partially supported by the the Gobierno de Aragon,
   the Ministerio de Economia y Competitividad (project LIGHTSLICE and
   BLINK), and a generous gift from Adobe Systems.
CR [Anonymous], 2013, FDN TRENDS MACHINE L
   [Anonymous], P INT C MACH LEARN
   [Anonymous], 2001, P SIGGRAPH
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2012, ACM T GRAPHICS
   [Anonymous], 2006, TECH REP
   Averkiou M, 2014, COMP GRAPH FOR P EUR
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Campbell NDF, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601212
   Durand F, 2002, P NPAR
   Eitz M., 2012, ACM T GRAPHICS
   Fried O., 2015, COMPUT GRAPH FORUM, V34, P2
   Frisby J. P., 2010, Seeing: The Computational Approach to Biological Vision, V2
   Garces E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601131
   Han Z, 2014, VIS COMPUT, V31
   Huang SS, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461954
   Jin R, 2009, P NEUR INF PROC SYST
   Kleiman Y, 2013, P EUR ACMSIGGRAPH S
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Li H, 2013, COMPUT GRAPH FORUM, V32, P77, DOI 10.1111/cgf.12015
   Liu TQ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766898
   Lun ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766929
   Luo Y, 2014, IEEE T IMAGE PROCESS, V23, P3789, DOI 10.1109/TIP.2014.2332398
   Nguyen CH, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2699645
   O'Donovan P, 2014, P COMP AESTH
   O'Donovan P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601110
   REINERT B., 2013, ACM SIGGRAPH, V32, P6
   Rubinstein M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866186
   Saleh B, 2015, P GRAPH INT C
   Schultz M., 2003, P NEUR INF PROC SYST
   Shapira L, 2009, COMPUT GRAPH FORUM, V28, P629, DOI 10.1111/j.1467-8659.2009.01403.x
   Sidi O, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024160
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Ward J.H., 1963, J AM STAT ASS, V58
   WILLATS J., 2005, AXIOMATHES, V15
   Yamaguchi K, 2015, IEEE T PATTERN ANAL, V37, P1028, DOI 10.1109/TPAMI.2014.2353624
NR 36
TC 13
Z9 13
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13067
EP 13086
DI 10.1007/s11042-016-3702-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900005
DA 2024-07-18
ER

PT J
AU Kanrar, S
   Mandal, NK
AF Kanrar, Soumen
   Mandal, Niranjan Kumar
TI Video traffic analytics for large scale surveillance
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interactive session; Video on demand; Surveillance; Mixed strategy;
   Topology; Compact space; Mesh structure; Hybrid architecture
ID SYSTEM
AB The video traffic analysis is the most important issue for large scale surveillance. In the large scale surveillance system, huge amount of live digital video data is submitted to the storage servers through the number of externally connected scalable components. The system also contains huge amount of popular and unpopular old videos in the archived storage servers. The video data is delivered to the viewers, partly or completely on demand through a compact system. In real time, huge amount of video data is imported to the viewer's node for various analysis purposes. The viewers use a number of interactive operations during the real time tracking suspect. The compact video on demand system is used in peer to peer mesh type hybrid architecture. The chunk of video objects move fast through the real time generated compact topological space. Video traffic analytics is required to transfer compressed multimedia data efficiently. In this work, we present a dynamically developed topological space, using mixed strategy by game approach to move the video traffic faster. The simulation results are well addressed in real life scenario.
C1 [Kanrar, Soumen] Vehere Interact Pvt Ltd, Kolkata 700053, W Bengal, India.
   [Kanrar, Soumen; Mandal, Niranjan Kumar] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Vidyasagar University
RP Kanrar, S (corresponding author), Vehere Interact Pvt Ltd, Kolkata 700053, W Bengal, India.; Kanrar, S (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM soumen.kanrar@veheretech.com; nkmandal.vu@gmail.com
RI Kanrar, Soumen/N-3113-2019
OI Kanrar, Soumen/0000-0002-0331-4932
CR Annapureddy S, 2007, IEEE INFOCOM SER, P2571, DOI 10.1109/INFCOM.2007.323
   Atrey PK, 2006, ACM MULTIMED SYST J
   Atrey PK, 2007, LECT NOTES COMPUT SC, V4352, P155
   Ayesta U, 2012, QUEUEING SYST, V71, P53, DOI 10.1007/s11134-012-9277-y
   Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   Bramberger M, 2004, RTAS 2004: 10TH IEEE REAL-TIME AND EMBEDDED TECHNOLOGY AND APPLICATIONS SYMPOSIUM, PROCEEDINGS, P174, DOI 10.1109/RTTAS.2004.1317262
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Collins R., 2000, CMURITR0012 VSAM
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   DUFAUX F, 2006, P IEEE WORKSH PRIV R
   Hampapur I, 2005, IEEE SIGNAL PROC MAG, V22, P38
   Heartwell CH, 2002, 36TH ANNUAL 2002 INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P87, DOI 10.1109/CCST.2002.1049231
   Jiang DD, 2015, ANN TELECOMMUN, V70, P427, DOI 10.1007/s12243-015-0465-8
   Jiang DD, 2014, AEU-INT J ELECTRON C, V68, P915, DOI 10.1016/j.aeue.2014.04.011
   Jiang DD, 2014, J NETW COMPUT APPL, V40, P292, DOI 10.1016/j.jnca.2013.09.014
   Junejo IN, 2004, INT C PATT RECOG, P716, DOI 10.1109/ICPR.2004.1334359
   Kanrar S., 2011, 2011 International Conference on Recent Trends in Information Systems (ReTIS), P52, DOI 10.1109/ReTIS.2011.6146839
   Kanrar S., 2014, ADV COMPUTING NETWOR, V2, P461, DOI [10.1007/978-3-319-07350-7_51, DOI 10.1007/978-3-319-07350-7_51]
   Kanrar S, 2015, 6TH INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT-2015), P95, DOI 10.1145/2818567.2818585
   Kanrar S, 2016, ADV MULTIMED, V2016, DOI 10.1155/2016/7829570
   Kanrar S, 2016, ADV MULTIMED, V2016, DOI 10.1155/2016/5429187
   Kanrar S, 2016, ADV INTELL SYST, V404, P97
   Kanrar S, 2015, ADV INTELL SYST, V339, P21, DOI 10.1007/978-81-322-2250-7_3
   Khoshabeh Ramsin, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P259, DOI 10.1109/ITSC.2007.4357750
   Kwak S, 2011, OPT ENG, V50, DOI 10.1117/1.3542038
   Lee D, 2001, IEEE T COMPUT, V50, P1352, DOI 10.1109/tc.2001.970573
   Li VOK, 2003, Patent US, Patent No. [6543053 B1, 6543053]
   Liao HYM, 2006, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2006.1692634
   Lu N., 2008, IAENG INT J COMPUTER, V35, P1
   Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652
   Morris BT, 2008, IEEE T INTELL TRANSP, V9, P425, DOI 10.1109/TITS.2008.922970
   Morris BT, 2012, IEEE T INTELL TRANSP, V13, P1667, DOI 10.1109/TITS.2012.2208222
   Muller-Schneiders S., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P137
   Nie LS, 2013, COMPUT ELECTR ENG, V39, P1422, DOI 10.1016/j.compeleceng.2013.04.002
   Oner Sebe I, 2003, ACM P IWVS 03
   Rath SK, 2010, INDIA Q, V66, P359, DOI 10.1177/097492841006600403
   Remagnino P, 2007, MACH VISION APPL, V18, P135, DOI 10.1007/s00138-006-0059-6
   Saleemi I, 2009, IEEE T PATTERN ANAL, V31, P1472, DOI 10.1109/TPAMI.2008.175
   Saunier Nicolas, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P872, DOI 10.1109/ITSC.2007.4357793
   Shah M, 2007, IEEE MULTIMEDIA, V14, P30, DOI 10.1109/MMUL.2007.3
   Shiang HP, 2010, IEEE T CIRC SYST VID, V20, P505, DOI 10.1109/TCSVT.2009.2035837
   Shrutivandana S, 2009, IEEE ACM T NETWORK, V17, P1819, DOI 10.1109/TNET.2009.2020162
   Suh K, 2006, CRPRL2006110001 THOM
   Suh K, 2007, IEEE J SEL AREA COMM, V25, P1706, DOI 10.1109/JSAC.2007.071209
   Tan B, 2013, IEEE ACM T NETWORK, V21, P566, DOI 10.1109/TNET.2012.2208199
   Turner-Fairbank-Highway Research Center, 2013, PED BIC INT SAF IND
   Victor O, 1996, IEEE J SEL AREA COMM, V14, P1099
   Yoshitaka A, 2012, 8 INT C SIGN IM TECH, P1
   Yu H, 2006, ACM P EUR SYS LEUV B
   Yunus D, 2012, IEEE T MOBILE COMPUT, V11, P835, DOI [10.1109/TMC.2011.115, DOI 10.1109/TMC.2011.115]
   Zhang XY, 2005, IEEE INFOCOM SER, P2102
NR 51
TC 7
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13315
EP 13342
DI 10.1007/s11042-016-3752-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900018
DA 2024-07-18
ER

PT J
AU Li, LJ
   Dai, SL
AF Li, Lijun
   Dai, Shuling
TI Action recognition with spatio-temporal augmented descriptor and fusion
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Fusion; Augmented descriptor; Normalization
AB Action recognition is one of the most popular fields of computer vision, and lots of efforts have been made to improve recognition accuracy. While multiple descriptors are extracted to represent action, the spatio-temporal information is lost. In order to incorporate spatio-temporal information, we propose a novel method called augmented descriptor by adding the information to the original descriptor. As descriptors represent different video features, such as static appearance and motion information, previous methods just concatenate various descriptors. However, we propose a fusion method to boost the recognition accuracy of action recognition. The Multiple Kernel Learning is utilized to fuse different descriptors to get better representation in our fusion method. We also evaluate the contribution of normalization method to recognition accuracy. Our proposed methods are tested on the benchmark datasets, Olympic Sports dataset and HMDB51 dataset. The experimental results show that our approaches outperform the baseline method of improved trajectories and are effective in recognizing various actions.
C1 [Li, Lijun; Dai, Shuling] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
C3 Beihang University
RP Li, LJ (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
EM lilijun1990@buaa.edu.cn; sldai@yeah.net
RI Li, Lijun/AAG-9407-2019
OI Li, Lijun/0000-0002-7406-6702
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], ARXIV14054506
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2005, VIS SURV PERF EV TRA
   [Anonymous], P 2009 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2009.5206557
   [Anonymous], COMP VIS PATT REC CV
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], BMVC 2012 BRIT MACH
   [Anonymous], ARXIV151004565
   [Anonymous], BMVC 2008 19 BRIT MA
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], AS C COMP VIS
   Arandjelovic R, 2013, PROC CVPR IEEE, P1578, DOI 10.1109/CVPR.2013.207
   Bishop C, 2007, RECOGNITION PATTERN
   Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Cherian A, 2014, PROC CVPR IEEE, pCP32, DOI 10.1109/CVPR.2014.302
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Fan XC, 2015, PROC CVPR IEEE, P1347, DOI 10.1109/CVPR.2015.7298740
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hoai M, 2015, LECT NOTES COMPUT SC, V9007, P3, DOI 10.1007/978-3-319-16814-2_1
   Jain Ashesh., 2012, KDD, P750
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Philbin J., 2008, P CVPR, P1
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sánchez J, 2012, PATTERN RECOGN LETT, V33, P2216, DOI 10.1016/j.patrec.2012.07.019
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun C, 2013, IEEE I CONF COMP VIS, P913, DOI 10.1109/ICCV.2013.453
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Varma M., 2009, P 26 ANN INT C MACHI, P1065
   Vishwanathan S., 2010, Proc. of Neural Information Processing Systems, P2361
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
NR 55
TC 5
Z9 5
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13953
EP 13969
DI 10.1007/s11042-016-3789-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800012
DA 2024-07-18
ER

PT J
AU Nikooghadam, M
   Jahantigh, R
   Arshad, H
AF Nikooghadam, Morteza
   Jahantigh, Reza
   Arshad, Hamed
TI A lightweight authentication and key agreement protocol preserving user
   anonymity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Key agreement; Security; User anonymity; Password
   guessing attacks
ID PASSWORD AUTHENTICATION; SCHEME; EFFICIENT; CRYPTANALYSIS; IMPROVEMENT;
   NETWORKS; SECURITY
AB Nowadays with widespread employment of the Internet, servers provide various services for legal users. The vital issue in client/server connections is authentication protocols that make the communication channel safe and secure against famous attacks. Recently, Kumari et al. and Chaudhry et al. proposed two authentication and key agreement protocols and illustrated that their proposed protocols are secure against various security attacks. However, in this paper we demonstrate that both protocols are vulnerable to off-line password guessing attacks. Moreover, we show that Kumari et al.'s protocol does not provide the property of user anonymity. In order to overcome these weaknesses, we propose a lightweight authentication and key agreement protocol. The correctness of the proposed protocol is proved using BAN logic. Security analysis demonstrates that the proposed protocol resists various security attacks and provides user anonymity. Furthermore, performance analysis confirms that the computation cost of the proposed protocol is acceptable.
C1 [Nikooghadam, Morteza; Jahantigh, Reza] Imam Reza Int Univ, Dept Comp Engn & Informat Technol, Mashhad, Iran.
   [Arshad, Hamed] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Nikooghadam, M (corresponding author), Imam Reza Int Univ, Dept Comp Engn & Informat Technol, Mashhad, Iran.
EM m.nikooghadam@imamreza.ac.ir; r.jahantigh@imamreza.ac.ir;
   hamedarshad@aol.com
RI Nikooghadam, Morteza/AAR-7984-2020; Arshad, Hamed/D-3598-2017
OI Nikooghadam, Morteza/0000-0003-3894-3103; Arshad,
   Hamed/0000-0003-3885-7408
CR Amin R, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0318-z
   [Anonymous], IACR CRYPTOLOGY EPRI
   [Anonymous], 15 INT C ADV COMM TE
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P 2 USENIX SEC WORKS
   [Anonymous], INFORM PROCESSING LE
   [Anonymous], CRYPTOLOGY EPRINT AR
   [Anonymous], INT J COMMUN SYST
   [Anonymous], 2013, IACR CRYP TOLOGY EPR
   [Anonymous], ADV CRYPTOLOGY CRYPT
   [Anonymous], PROCEEDINGS OF 2012
   [Anonymous], SECUR COMMUN NETW
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad H, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0259-6
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Awasthi AK, 2011, COMPUT ELECTR ENG, V37, P869, DOI 10.1016/j.compeleceng.2011.09.015
   Bonneau J, 2012, P IEEE S SECUR PRIV, P538, DOI 10.1109/SP.2012.49
   BURROWS M, 1989, P ROY SOC LOND A MAT, V426, P233, DOI 10.1098/rspa.1989.0125
   Chan CK, 2000, IEEE T CONSUM ELECTR, V46, P992, DOI 10.1109/30.920451
   Chang YF, 2014, INT J COMMUN SYST, V27, P3430, DOI 10.1002/dac.2552
   Chaudhry SA, 2015, J SUPERCOMPUT, P1
   Chaudhry SA, 2016, MULTIMED TOOLS APPL, V75, P12705, DOI 10.1007/s11042-015-3194-0
   Chaudhry SA, 2015, SECUR COMMUN NETW, V8, P3782, DOI 10.1002/sec.1299
   Chaudhry SA, 2017, PEER PEER NETW APPL, V10, P1, DOI 10.1007/s12083-015-0400-9
   Chaudhry SA, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0244-0
   Chen BL, 2014, INT J COMMUN SYST, V27, P377, DOI 10.1002/dac.2368
   Chien HY, 2002, COMPUT SECUR, V21, P372, DOI 10.1016/S0167-4048(02)00415-7
   Hsieh WB, 2012, COMPUT SECUR, V31, P791, DOI 10.1016/j.cose.2012.06.001
   Hwang MS, 2000, IEEE T CONSUM ELECTR, V46, P28, DOI 10.1109/30.826377
   Jiang Q, 2015, INT J COMMUN SYST, V28, P383, DOI 10.1002/dac.2644
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Ku WC, 2003, IEICE T COMMUN, VE86B, P1682
   Kumari S, 2017, PEER PEER NETW APPL, V10, P92, DOI 10.1007/s12083-015-0409-0
   Kumari S, 2016, FUTURE GENER COMP SY, V63, P56, DOI 10.1016/j.future.2016.04.016
   Kumari S, 2014, COMPUT ELECTR ENG, V40, P1997, DOI 10.1016/j.compeleceng.2014.05.007
   Kumari S, 2014, SECUR COMMUN NETW, V7, P1921, DOI 10.1002/sec.906
   LAMPORT L, 1981, COMMUN ACM, V24, P770, DOI 10.1145/358790.358797
   LENNON RE, 1981, IEEE T COMMUN, V29, P773, DOI 10.1109/TCOM.1981.1095067
   Li CT, 2013, IET INFORM SECUR, V7, P3, DOI 10.1049/iet-ifs.2012.0058
   Lu Y., 2015, MATH PROBL ENG, V2015, P1, DOI DOI 10.1109/IEDM.2015.7409770
   Ma CG, 2014, INT J COMMUN SYST, V27, P2215, DOI 10.1002/dac.2468
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Mir O, 2017, PEER PEER NETW APPL, V10, P79, DOI 10.1007/s12083-015-0408-1
   Mir O, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0265-8
   Mir O, 2015, WIRELESS PERS COMMUN, V83, P2439, DOI 10.1007/s11277-015-2538-4
   Mishra D, 2015, J INF SECUR APPL, V23, P28, DOI 10.1016/j.jisa.2015.06.003
   Odelu V, 2015, J INF SECUR APPL, V21, P1, DOI 10.1016/j.jisa.2015.01.001
   Odelu V, 2015, IEEE T INF FOREN SEC, V10, P1953, DOI 10.1109/TIFS.2015.2439964
   Sun HM, 2000, IEEE T CONSUM ELECTR, V46, P958, DOI 10.1109/30.920446
   von Ahn L, 2004, COMMUN ACM, V47, P57, DOI 10.1145/966389.966390
   Wang D, 2015, INFORM SCIENCES, V321, P162, DOI 10.1016/j.ins.2015.03.070
   Wang D, 2014, AD HOC NETW, V20, P1, DOI 10.1016/j.adhoc.2014.03.003
   Wang XM, 2007, COMPUT STAND INTER, V29, P507, DOI 10.1016/j.csi.2006.11.005
   Wang YY, 2009, COMPUT COMMUN, V32, P583, DOI 10.1016/j.comcom.2008.11.008
   Wen FT, 2012, COMPUT ELECTR ENG, V38, P381, DOI 10.1016/j.compeleceng.2011.11.010
   Yoon EJ, 2004, IEEE T CONSUM ELECTR, V50, P612, DOI 10.1109/TCE.2004.1309437
   Zhan L., 2014, 2014 IEEE PES General Meeting: Conference & Exposition, DOI 10.1109/PESGM.2014.6938906
NR 57
TC 47
Z9 48
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13401
EP 13423
DI 10.1007/s11042-016-3704-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900022
DA 2024-07-18
ER

PT J
AU Liu, MF
   Zhang, H
   Hu, HJ
   Wei, W
AF Liu, Maofu
   Zhang, He
   Hu, Huijun
   Wei, Wei
TI Topic categorization and representation of health community generated
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Health community generated data; Learning model; Semantic
   representation; Health topic categorization
ID IMAGE; VOCABULARY
AB The representation and categorization of professional health provider released data have been well investigated and practically implemented. These have facilitated browsing, search and high-order learning of health information. On the other hand, there has been little corresponding studies on the representation and categorization of health community generated data. It is usually more complex, inconsistent and ambiguous, and consequently raises challenges for data access and analytics. This paper explores various representations for health community generated data and categorizes these data in terms of health topics. In addition, this work utilizes pseudo-labeled data to train the supervised topic categorization models, and this makes the whole categorization process unsupervised and extendable to handle large-scale data. The extensive experiments on two real-world datasets reveal our interesting findings of the informative representation approaches and effective categorization models for health community generated data.
C1 [Liu, Maofu; Zhang, He; Hu, Huijun] Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Peoples R China.
   [Liu, Maofu; Zhang, He; Hu, Huijun] Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Peoples R China.
   [Wei, Wei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Wuhan University of Science & Technology; Huazhong University of Science
   & Technology
RP Liu, MF (corresponding author), Wuhan Univ Sci & Technol, Coll Comp Sci & Technol, Wuhan 430065, Peoples R China.; Liu, MF (corresponding author), Hubei Prov Key Lab Intelligent Informat Proc & Re, Wuhan 430065, Peoples R China.
EM e_mfliu@163.com; cheesezh@qq.com; huhuijun@wust.edu.cn; weiw@hust.edu.cn
OI Wei, Wei/0000-0003-4488-0102
FU National Natural Science Foundation of China [61100133]; Major Projects
   of National Social Science Foundation of China [11ZD189]
FX The work presented in this paper is partially supported by the National
   Natural Science Foundation of China under Grant No. 61100133 and the
   Major Projects of National Social Science Foundation of China under
   Grant No. 11&ZD189.
CR [Anonymous], P ACM INT C IM VID R
   [Anonymous], 2014, P INT ACM SIGIR WORK
   Babashzadeh A, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P801
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chan W, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P959, DOI 10.1145/2505515.2505676
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   HERSH WR, 1994, J AM MED INFORM ASSN, V1, P51, DOI 10.1136/jamia.1994.95236136
   Kanavos A, 2015, INT J ARTIF INTELL T, V24, DOI 10.1142/S0218213015400047
   Kim M., 2010, Computing Research Repository, P1
   Li JQ, 2015, COMPUT IND, V69, P81, DOI 10.1016/j.compind.2014.09.004
   Limsopatham Nut, 2013, Advances in Information Retrieval. 35th European Conference on IR Research, ECIR 2013. Proceedings, P747, DOI 10.1007/978-3-642-36973-5_75
   Limsopatham N, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P833
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P2107, DOI 10.1109/TKDE.2015.2399298
   Nie LQ, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1245, DOI 10.1145/2600428.2611176
   Nie LQ, 2015, IEEE T KNOWL DATA EN, V27, P396, DOI 10.1109/TKDE.2014.2330813
   Nie LQ, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559157
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Qu B, 2012, J AM SOC INF SCI TEC, V63, P889, DOI 10.1002/asi.22611
   Srinivasan P, 1996, INFORM PROCESS MANAG, V32, P503, DOI 10.1016/0306-4573(96)00025-8
   Trieschnigg D., 2010, Proceedings of the 19th ACM international conference on information and knowledge management (CIKM), P169
   Velardi P, 2001, P WORKSH HUM LANG TE, DOI [10.3115/1118220.1118225, DOI 10.3115/1118220.1118225]
   Yan Y., 2013, ACM International Conference on Multimedia, P537
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yang SH, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P993
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P564, DOI 10.1109/TIE.2014.2327558
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P4150, DOI 10.1109/TIP.2014.2344433
   Zhang LM, 2014, IEEE T IMAGE PROCESS, V23, P2235, DOI 10.1109/TIP.2014.2311658
   Zhang LM, 2014, IEEE T MULTIMEDIA, V16, P470, DOI 10.1109/TMM.2013.2293424
   Zhang LM, 2013, IEEE T IMAGE PROCESS, V22, P5071, DOI 10.1109/TIP.2013.2278465
   Zhang Weinan., 2012, COLING, P3105
   Zhu DQ, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P1025
NR 36
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 10541
EP 10553
DI 10.1007/s11042-015-3094-3
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400015
DA 2024-07-18
ER

PT J
AU Yang, JC
   Liu, Y
   Wei, W
   Meng, QG
   Gao, ZQ
   Lin, YC
AF Yang, Jiachen
   Liu, Yun
   Wei, Wei
   Meng, Qinggang
   Gao, Zhiqun
   Lin, Yancong
TI A new research on contrast sensitivity function in 3D space
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human visual system; Contrast sensitivity function; Spatial frequency;
   Three-dimensional space
ID QUALITY ASSESSMENT; 3-D VIDEO; IMAGE
AB In this paper, it tries to extend the characteristics of human eyes' contrast sensitivity Function(CSF) into (3D) space, but the experimental results show that the traditional characteristics of CSF have limitations in 3D space for lack of depth information. In order to investigate the characteristics of CSF in 3D space, traditional CSF tests are further developed to measure the corresponding properties of CSF with different inclined planes, and describe the oee integral-C S F characteristics of human eyes based on the inclined angles oee integral. According to the tests, the mathematical expression of oee integral-C S F is built up. In addition, the concept of spatial frequency in the direction of depth (f (D) ) is proposed, and f (D) -C S F characteristic surface is also achieved. The proposed 3D CSF has significant effects on the research of human visual characteristics and 3D image processing.
C1 [Yang, Jiachen; Gao, Zhiqun; Lin, Yancong] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
   [Liu, Yun] Univ Calif Berkeley, Sch Optometry, Berkeley, CA 94720 USA.
   [Wei, Wei] Xian Univ Technol, Sch Comp Sci & Engn, Xian, Shanxi, Peoples R China.
   [Meng, Qinggang] Loughborough Univ, Sch Sci, Dept Comp Sci, Loughborough, Leics, England.
C3 Tianjin University; University of California System; University of
   California Berkeley; Xi'an University of Technology; Loughborough
   University
RP Liu, Y (corresponding author), Univ Calif Berkeley, Sch Optometry, Berkeley, CA 94720 USA.
EM yunliu@tju.edu.cn
RI wei, wei/HHR-8613-2022; Wei, Wei/ABB-8665-2021; wei, wei/IQW-1347-2023;
   Yang, Jiachen/ABH-5032-2020
OI Wei, Wei/0000-0002-8751-9205; Yang, Jiachen/0000-0003-2558-552X
FU National Natural Science Foundation of China [61471260, 61271324];
   Program for New Century Excellent Talents in University [NCET-12-0400]
FX This research is supported by the National Natural Science Foundation of
   China (No. 61471260 and No.61271324), and Program for New Century
   Excellent Talents in University (NCET-12-0400).
CR ARUNDALE K, 1978, BRIT J OPHTHALMOL, V62, P213, DOI 10.1136/bjo.62.4.213
   BODISWOLLNER I, 1976, BRAIN, V99, P695, DOI 10.1093/brain/99.4.695
   Bradley AP, 1999, IEEE T IMAGE PROCESS, V8, P717, DOI 10.1109/83.760338
   Brandao T, 2010, IEEE T CIRC SYST VID, V20, P1437, DOI 10.1109/TCSVT.2010.2077474
   Chen H, 2010, IEEE T CIRCUITS SYST, V20
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Chen Y, 2009, IMAGE VIS COMPUT, V27
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Deng CW, 2012, IEEE T MULTIMEDIA, V14, P278, DOI 10.1109/TMM.2011.2181491
   Gaddipatti A, 1997, COMPUT GRAPH FORUM, V16, pC241, DOI 10.1111/1467-8659.00161
   Gao XB, 2009, IEEE T IMAGE PROCESS, V18, P1409, DOI 10.1109/TIP.2009.2018014
   Imamoglu N, 2013, IEEE T MULTIMEDIA, V15, P96, DOI 10.1109/TMM.2012.2225034
   James L, 1974, IEEE T INFORM THEORY, VIT-20, P525
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Jung SW, 2012, IEEE T IMAGE PROCESS, V21, P3624, DOI 10.1109/TIP.2012.2191569
   Lang M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778812
   Li P, 2013, IEEE T MULTIMEDIA, V15, P141, DOI 10.1109/TMM.2012.2199970
   Li SN, 2011, IEEE T MULTIMEDIA, V13, P935, DOI 10.1109/TMM.2011.2152382
   Liu F, 2013, IEEE T MULTIMEDIA, V15, P129, DOI 10.1109/TMM.2012.2225033
   Mocan MC, 2005, J AAPOS, V9, P48, DOI 10.1016/j.jaapos.2004.11.007
   Müller K, 2011, P IEEE, V99, P643, DOI 10.1109/JPROC.2010.2091090
   Nadenau MJ, 2003, IEEE T IMAGE PROCESS, V12, P58, DOI 10.1109/TIP.2002.807358
   Ng KT, 2012, IEEE T MULTIMEDIA, V14, P1631, DOI 10.1109/TMM.2012.2199291
   SCHADE OH, 1956, J OPT SOC AM, V46, P721, DOI 10.1364/JOSA.46.000721
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350
   Tao D, 2009, IEEE T SYST MAN CY B, V39
   Wei W, 2014, INT J COMMUN SYST, V27, P3013, DOI 10.1002/dac.2522
   Wei W, 2012, INT J DISTRIB SENS N, DOI 10.1155/2012/135054
   Wei W, 2012, MATH PROBL ENG, V2012, DOI 10.1155/2012/154630
   Wei W, 2011, SENSORS-BASEL, V11, P4794, DOI 10.3390/s110504794
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wu GL, 2011, IEEE T MULTIMEDIA, V13, P1181, DOI 10.1109/TMM.2011.2166249
   Xing LY, 2012, IEEE T MULTIMEDIA, V14, P326, DOI 10.1109/TMM.2011.2172402
   Yan B, 2012, IEEE T MULTIMEDIA, V14, P936, DOI 10.1109/TMM.2012.2184743
   Zeng WJ, 2002, SIGNAL PROCESS-IMAGE, V17, P85, DOI 10.1016/S0923-5965(01)00029-7
   Zhang F., 2011, IEEE T MULTIMEDIA, V13
NR 37
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 11127
EP 11142
DI 10.1007/s11042-016-3541-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400047
DA 2024-07-18
ER

PT J
AU Chen, CC
   Tsai, YH
   Yeh, HC
AF Chen, Chien-Chang
   Tsai, Yao-Hong
   Yeh, Hsin-Cheng
TI Difference-expansion based reversible and visible image watermarking
   scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermark; Visible watermark; Difference expansion; Partition
   strategy
ID TRANSFORM
AB A reversible image watermarking scheme recovers the original cover image after extracting the embedded watermarks. A visible image watermarking scheme embeds watermarks to create a visible watermark effect on the cover image. A general reversible image watermarking scheme embeds invisible watermarks. This paper presents a reversible and visible image watermarking scheme that uses a conventional difference-expansion method. The cover image is first segmented to non-overlapped kxk blocks. Each block is then applied to two watermarking schemes; a difference-expansion based invisible watermarking scheme and a visible watermarking scheme to embed one watermark bit. Exceeding numbers, larger than 255 or smaller than 0, generated from the difference-expansion method require being recorded for a lossless recovery. Experimental results show that the proposed scheme embeds visible watermarks with few recorded exceeding numbers. However, not recording any exceeding numbers still results in a high similarity of extracted watermark image and good quality of recovered cover image.
C1 [Chen, Chien-Chang; Yeh, Hsin-Cheng] Tamkang Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Tsai, Yao-Hong] Hsuan Chuang Univ, Dept Informat Management, Hsinchu 300, Taiwan.
C3 Tamkang University; Hsuan Chuang University
RP Tsai, YH (corresponding author), Hsuan Chuang Univ, Dept Informat Management, Hsinchu 300, Taiwan.
EM tyh@wmail.hcu.edu.tw
RI Chen, Chien-Chang/P-3956-2017
OI Chen, Chien-Chang/0000-0001-6974-2422
FU National Science Council of the Republic of China [MOST
   104-2221-E-364-002]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments and suggestions to improve the quality of the paper.
   This paper was partially supported by the National Science Council of
   the Republic of China under contract MOST 104-2221-E-364-002.
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   Al-Qershi OM, 2011, J SYST SOFTWARE, V84, P105, DOI 10.1016/j.jss.2010.08.055
   Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Dong WS, 2014, IEEE T IMAGE PROCESS, V23, P3618, DOI 10.1109/TIP.2014.2329449
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Hu YJ, 2009, IEEE T CIRC SYST VID, V19, P250, DOI 10.1109/TCSVT.2008.2009252
   Hu YJ, 2008, IEEE T MULTIMEDIA, V10, P1500, DOI 10.1109/TMM.2008.2007341
   Jawad K, 2013, J SYST SOFTWARE, V86, P2742, DOI 10.1016/j.jss.2013.06.023
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   Lee CF, 2010, J SYST SOFTWARE, V83, P1864, DOI 10.1016/j.jss.2010.05.078
   Lin PY, 2013, IMAGE VISION COMPUT, V31, P311, DOI 10.1016/j.imavis.2013.02.002
   Liu ML, 2012, SIGNAL PROCESS, V92, P819, DOI 10.1016/j.sigpro.2011.09.028
   Liu TY, 2010, IEEE T IMAGE PROCESS, V19, P1224, DOI 10.1109/TIP.2010.2040757
   Lu TC, 2008, IMAGE VISION COMPUT, V26, P632, DOI 10.1016/j.imavis.2007.07.011
   Lu TC, 2014, MULTIMED TOOLS APPL, V72, P417, DOI 10.1007/s11042-013-1369-0
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, J SYST SOFTWARE, V86, P2700, DOI 10.1016/j.jss.2013.05.077
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Wu HC, 2009, J SYST SOFTWARE, V82, P1966, DOI 10.1016/j.jss.2009.06.056
   Yang Y, 2009, IEEE T CIRC SYST VID, V19, P656, DOI 10.1109/TCSVT.2009.2017401
NR 23
TC 26
Z9 28
U1 3
U2 37
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8497
EP 8516
DI 10.1007/s11042-016-3452-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800039
DA 2024-07-18
ER

PT J
AU Lu, GL
   Zhou, YQ
   Li, XY
   Yan, P
AF Lu, Guoliang
   Zhou, Yiqi
   Li, Xueyong
   Yan, Peng
TI Unsupervised, efficient and scalable key-frame selection for automatic
   summarization of surveillance videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video summarization; Martingale test; Key frame selection; Surveillance
   videos
ID SCENE DETECTION; TIME-SERIES; SEGMENTATION; ABSTRACTION
AB Recent years have witnessed a dramatical growth of the deployment of visionbased surveillance in public spaces. Automatic summarization of surveillance videos (ASOSV) is hence becoming more and more desirable in many real-world applications. For this purpose, a novel frame-selection framework is proposed in the present paper, which has three properties: 1) un-supervision: it can work without requirements of any supervised learning or training; 2) efficiency: it can work very fast, with experiments demonstrating efficiency faster than real-timeness and 3) scalability: it can achieve a hierarchical analysis/overview of video content. The performance of proposed framework is systematically evaluated and compared with various state-of-the-art frame selection techniques on some collected video sequences and publicly-available ViSOR dataset. The experimental results demonstrate promising performance and good applicability for real-world problems.
C1 [Lu, Guoliang; Zhou, Yiqi; Li, Xueyong; Yan, Peng] Shandong Univ, Sch Mech Engn, Jinan, Peoples R China.
   [Lu, Guoliang; Zhou, Yiqi; Li, Xueyong; Yan, Peng] Shandong Univ, Key Lab Highefficiency & Clean Mech Mfg, Minist Educ, Beijing, Peoples R China.
C3 Shandong University; Shandong University
RP Lu, GL (corresponding author), Shandong Univ, Sch Mech Engn, Jinan, Peoples R China.
EM luguoliang@sdu.edu.cn; yqzhou@sdu.edu.cn; lxy88@sdu.edu.cn;
   yanpeng@sdu.edu.cn
FU National Natural Science Foundation of China [61403232]; Natural Science
   Foundation of Shandong Province, China [ZR2014FQ025]; Scientific
   Research Foundation for the Returned Overseas Chinese Scholars, State
   Education Ministry of China; Open Projects Program of National
   Laboratory of Pattern Recognition (NLPR) of China [201407346]
FX The work is financially supported in part by National Natural Science
   Foundation of China (61403232), Natural Science Foundation of Shandong
   Province, China (ZR2014FQ025), the Scientific Research Foundation for
   the Returned Overseas Chinese Scholars, State Education Ministry of
   China, and the Open Projects Program of National Laboratory of Pattern
   Recognition (NLPR) of China (201407346).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Angadi S, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P271, DOI 10.1109/ICSIP.2014.49
   [Anonymous], 1962, Ann. Inst. Fourier (Grenoble), DOI [10.5802/aif.126, DOI 10.5802/AIF.126]
   [Anonymous], 18 INT C DIG SIGN PR
   [Anonymous], P 8 INT C BIOINSP CO
   [Anonymous], 2014, INT J ELECT ELECT CO
   [Anonymous], 2007, SINGLE VIEW HUMAN AC
   [Anonymous], 2009, 2009 CHIN C PATT REC
   Chang HS, 1999, IEEE T CIRC SYST VID, V9, P1269, DOI 10.1109/76.809161
   Cotsaces C, 2006, IEEE SIGNAL PROC MAG, V23, P28, DOI 10.1109/MSP.2006.1621446
   Do TT, 2009, IEEE IMAGE PROC, P1393, DOI 10.1109/ICIP.2009.5414631
   Ejaz N, 2013, SIGNAL PROCESS-IMAGE, V28, P34, DOI 10.1016/j.image.2012.10.002
   Elhamifar E, 2012, PROC CVPR IEEE, P1600, DOI 10.1109/CVPR.2012.6247852
   Fox EB, 2014, ANN APPL STAT, V8, P1281, DOI 10.1214/14-AOAS742
   Gong D, 2014, IEEE T PATTERN ANAL, V36, P1414, DOI 10.1109/TPAMI.2013.244
   Hammoud RI, 2014, IEEE COMPUT SOC CONF, P237, DOI 10.1109/CVPRW.2014.44
   Ho SS, 2010, IEEE T PATTERN ANAL, V32, P2113, DOI 10.1109/TPAMI.2010.48
   Holt G. A., 2007, P 19 ANN C ADV SCH C, P1
   Ji QG, 2013, SIGNAL PROCESS-IMAGE, V28, P241, DOI 10.1016/j.image.2012.11.008
   Jones S, 2014, IEEE WINT CONF APPL, P816, DOI 10.1109/WACV.2014.6836019
   Keogh E, 2005, P THE 5 IEEE INT C D, P1
   Kim TK, 2007, PROC CVPR IEEE, P1275
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Liu TY, 2004, PATTERN RECOGN LETT, V25, P1451, DOI 10.1016/j.patrec.2004.05.020
   Mahmoud KM, 2013, LECT NOTES COMPUT SC, V8156, P733
   Mentzelopoulos M., 2004, P 6 ACM SIGMM INT WO, P39, DOI DOI 10.1145/1026711.1026719
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ngo CW, 2005, IEEE T CIRC SYST VID, V15, P296, DOI 10.1109/TCSVT.2004.841694
   Porter SV, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P460, DOI 10.1109/ICIAP.2003.1234093
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rasheed Z, 2003, PROC CVPR IEEE, P343
   Shao L, 2009, 2009 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P88, DOI 10.1109/CRV.2009.36
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sun XD, 2000, REAL-TIME IMAGING, V6, P449, DOI 10.1006/rtim.1999.0197
   Sundaram H, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1145, DOI 10.1109/ICME.2000.871563
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Tseng BL, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA541
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Vovk Vladimir, 2003, Testing exchangeability on-line, P768
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Xiong Z., 2006, A unified framework for video summarization, browsing, and retrieval with applications to consumer and surveillance video
   Yang Shuping, 2005, Tsinghua Science and Technology, V10, P169, DOI 10.1016/S1007-0214(05)70050-X
   Yu XD, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P117
   Zhang X, 2014, IEEE T KNOWL DATA EN, V26, P1293, DOI 10.1109/TKDE.2013.114
NR 44
TC 25
Z9 25
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6309
EP 6331
DI 10.1007/s11042-016-3263-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400012
DA 2024-07-18
ER

PT J
AU Paul, G
   Davidson, I
   Mukherjee, I
   Ravi, SS
AF Paul, Goutam
   Davidson, Ian
   Mukherjee, Imon
   Ravi, S. S.
TI Keyless dynamic optimal multi-bit image steganography using
   <i>energetic</i> pixels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energetic pixels; Data hiding; Embedding capacity; Ising energy;
   Multibit steganography
AB Steganography plays an important role to hide data in apparently innocuous media (e.g., image, audio, video, text, etc.). Since most of the steganographic algorithms do not consider the image content while locating the message bearing pixels, in most occasions, they are bound to defeat against visual, structural and statistical attacks. We distribute the message bits in selective parts of a cover image, particularly in the `busy' part, i.e., where a perceptible change in the pixel intensity occurs, using a variety of embedding schemes. The energetic pixels, as per our definition, capture this notion of `busy' part of the image and our data hiding schemes keep the energy function invariant between the cover image and its stego version for lossless data extraction. The schemes do not need to share any key/seed or a pass-phrase between the sender and the receiver. We show that our proposed algorithms provide imperceptible visual distortions for embedding data at most 4 bits per pixels with high embedding efficiencies and can withstand popular first order statistical tests.
C1 [Paul, Goutam] Indian Stat Inst, RC Bose Ctr Cryptol & Secur, CSRU, Kolkata 700108, India.
   [Davidson, Ian] Univ Calif Davis, Dept Comp Sci, Davis, CA 95616 USA.
   [Mukherjee, Imon] St Thomas Coll Engn & Technol, Dept Comp Sci & Engn, Kolkata 700023, India.
   [Ravi, S. S.] SUNY Albany, Dept Comp Sci, Albany, NY 12222 USA.
C3 Indian Statistical Institute; Indian Statistical Institute Kolkata;
   University of California System; University of California Davis; State
   University of New York (SUNY) System; State University of New York
   (SUNY) Albany
RP Paul, G (corresponding author), Indian Stat Inst, RC Bose Ctr Cryptol & Secur, CSRU, Kolkata 700108, India.
EM goutam.paul@isical.ac.in; davidson@cs.ucdavis.edu;
   mukherjee.imon@gmail.com; ravi@cs.albany.edu
RI Mukherjee, Imon/AFP-2409-2022
OI Mukherjee, Imon/0000-0002-8598-148X
CR [Anonymous], 2011, P 13 INF HID C PRAG
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   CIPRA BA, 1987, AM MATH MON, V94, P937, DOI 10.2307/2322600
   Das SK, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P395, DOI 10.1109/ICRCICN.2015.7434271
   Deshmukh P.U., 2014, IEEE INT C INF COMM, P27
   Dumitrescu S, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P641, DOI 10.1109/ICIP.2002.1039052
   Feng BW, 2015, IEEE T INF FOREN SEC, V10, P243, DOI 10.1109/TIFS.2014.2368364
   Filler T, 2010, IEEE T INF FOREN SEC, V5, P705, DOI 10.1109/TIFS.2010.2077629
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Fridrich J, 2007, IEEE T INFORM THEORY, V53, P1547, DOI 10.1109/TIT.2007.892768
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Hajizadeh M, 2010, ADV ELECTR COMPUT EN, V10, P96, DOI 10.4316/AECE.2010.03016
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mukherjee Imon, 2013, Information Systems Security. 9th International Conference, ICISS 2013. Proceedings: LNCS 8303, P270, DOI 10.1007/978-3-642-45204-8_21
   NAKATANI H, 1992, OPT ENG, V31, P280, DOI 10.1117/12.56069
   Oskoei M. A., 2010, CES506 U ESS SCH COM
   Park YR, 2005, LECT NOTES ARTIF INT, V3802, P581
   Paul G., 2012, INT C INF SYST SEC, P134, DOI 10.1007/978-3-642-35130-3_10
   Provos N., 2001, 10 USENIX SEC S, P325
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Wayner Peter., 2002, DISAPPEARING CRYPTOG
   Westfeld A., 1999, LECT NOTES COMPUTER, P61, DOI [10.1007/107197245, DOI 10.1007/107197245]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 31
TC 29
Z9 29
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 7445
EP 7471
DI 10.1007/s11042-016-3319-0
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400060
DA 2024-07-18
ER

PT J
AU Cabitza, F
   Fogli, D
   Lanzilotti, R
   Piccinno, A
AF Cabitza, Federico
   Fogli, Daniela
   Lanzilotti, Rosa
   Piccinno, Antonio
TI Rule-based tools for the configuration of ambient intelligence systems:
   a comparative user study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE End-user development; Internet of things; Ambient intelligence;
   Interconnection; Rule-based programming; User study
ID SMART HOME; USABILITY-SCALE; ENVIRONMENTS; TECHNOLOGIES
AB This paper describes a 63-participant user study that compares two widely known systems supporting end users in creating trigger-action rules for the Internet of Things and Ambient Intelligence scenarios. The user study is the first stage of a research agenda that concerns the implementation of a novel conceptual framework for the design and continuous evolution of 'sentient multimedia systems', namely socio-technical systems, where people and many kinds of hardware/software components (sensors, robots, smart devices, web services, etc.) interact with one another through the exchange of multimedia information, to give rise to intelligent, proactive behaviors. The conceptual framework is structured along three layers physical, inference and user - and is based on an information space of events, conditions and actions, linked together in Event-Condition-Action rules and operating according to the interconnection metaphor. The results of the user study have provided some indications for the implementation of the user layer, suggesting which could be the most suitable interaction style for rule design by a community of end users (e.g. a family) and which issues should be addressed in such a wide context.
C1 [Cabitza, Federico] Univ Studi Milano Bicocca, Dipartimento Informat & Comunicaz, Dipartimento Sistemist & Comunicaz, Milan, Italy.
   [Fogli, Daniela] Univ Studi Brescia, Dipartimento Ingn Informaz, Brescia, Italy.
   [Lanzilotti, Rosa; Piccinno, Antonio] Univ Studi Bari BAldo Moro, Dipartimento Informat, Bari, Italy.
C3 University of Milano-Bicocca; University of Brescia
RP Cabitza, F (corresponding author), Univ Studi Milano Bicocca, Dipartimento Informat & Comunicaz, Dipartimento Sistemist & Comunicaz, Milan, Italy.; Fogli, D (corresponding author), Univ Studi Brescia, Dipartimento Ingn Informaz, Brescia, Italy.; Lanzilotti, R; Piccinno, A (corresponding author), Univ Studi Bari BAldo Moro, Dipartimento Informat, Bari, Italy.
EM cabitza@disco.unimib.it; daniela.fogli@unibs.it;
   rosa.lanzilotti@uniba.it; antonio.piccinno@uniba.it
RI Cabitza, Federico/L-2263-2013; Lanzilotti, Rosa/AAJ-6787-2020; Piccinno,
   Antonio/I-8952-2012
OI Cabitza, Federico/0000-0002-4065-3415; Piccinno,
   Antonio/0000-0003-1561-7073
FU Italian Ministry of University and Research (MIUR) [PON02_00563_3470993
   "VINCENTE", PON04a2_B "EDOC@WORK3.0", PON03PE_00136_1 "DSE"]; Italian
   Ministry of Economic Development (MISE) under grant PON Industria [2015
   MI01_00294 "LOGIN"]
FX This work is partially supported by the Italian Ministry of University
   and Research (MIUR) under grants PON02_00563_3470993 "VINCENTE",
   PON04a2_B "EDOC@WORK3.0", and PON03PE_00136_1 "DSE" and by the Italian
   Ministry of Economic Development (MISE) under grant PON Industria 2015
   MI01_00294 "LOGIN".
CR [Anonymous], 2002, Usability Engineering: Scenario-based Development of Human-Computer Interaction
   [Anonymous], END USER DEV
   [Anonymous], USABILITY EVALUATION
   [Anonymous], 1993, Constructing Questions for Interviews and Questionnaires. Constructing Questions for Interviews and Questionnaires: Theory and Practice in Social Research, DOI [DOI 10.1017/CBO9780511518201, 10.1017/CBO9780511518201]
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Augusto JC, 2006, LECT NOTES COMPUT SC, V4008, P1
   Augusto JC, 2008, INT J COMPUT INT SYS, V1, P361
   Bahadori S, 2004, INTELL ARTIF, V1, P16
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Barricelli BR, 2015, LECT NOTES COMPUT SC, V9083, P9, DOI 10.1007/978-3-319-18425-8_2
   Benini L, 2003, AMBIENT INTELLIGENCE: IMPACT ON EMBEDDED SYSTEM DESIGN, P31
   Benzi F, 2015, LECT NOTES COMPUT SC, V9425, P353, DOI 10.1007/978-3-319-26005-1_25
   Bikakis A, 2010, LECT NOTES COMPUT SC, V6403, P74, DOI 10.1007/978-3-642-16289-3_8
   Blackwell AF, 2004, COMMUN ACM, V47, P65, DOI 10.1145/1015864.1015892
   Borsci S, 2009, COGN PROCESS, V10, P193, DOI 10.1007/s10339-009-0268-9
   Cabitza F., 2005, IEE Seminar on Intelligent Building Environments, P63
   Cabitza F., 2014, LNISO, P193, DOI DOI 10.1007/978-3-319-07040-7_
   Cabitza F, 2014, ADV HUM SOC ASPEC T, P182, DOI 10.4018/978-1-4666-4623-0.ch009
   Cabitza F, 2014, J VISUAL LANG COMPUT, V25, P684, DOI 10.1016/j.jvlc.2014.10.014
   Cabitza Federico., 2015, Proceedings of the 11th Biannual Conference on Italian SIGCHI Chapter, P146, DOI DOI 10.1145/2808435.2808446
   Castelfranchi C, 2012, AMB INTELL SMART ENV, V12, P17, DOI 10.3233/978-1-61499-050-5-17
   Cook DJ, 2006, LECT NOTES COMPUT SC, V4008, P165
   Cook DJ, 2009, PERVASIVE MOB COMPUT, V5, P277, DOI 10.1016/j.pmcj.2009.04.001
   Coutaz J, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P895, DOI 10.1145/2638728.2641559
   Crowley JL, 2015, LECT NOTES COMPUT SC, V9425, P1, DOI 10.1007/978-3-319-26005-1_1
   Cvijikj IP, 2011, ARCHITECTING THE INTERNET OF THINGS, P65
   Dahl Y, 2011, LECT NOTES COMPUT SC, V6770, P118, DOI 10.1007/978-3-642-21708-1_14
   Danado J, 2014, J VISUAL LANG COMPUT, V25, P297, DOI 10.1016/j.jvlc.2014.03.005
   Davidoff S, 2006, LECT NOTES COMPUT SC, V4206, P19
   Davidoff Scott., 2006, Proceedings of the international symposium on intelligent environments, P41
   Demeure A, 2014, AMB INTELL SMART ENV, V18, P141, DOI 10.3233/978-1-61499-411-4-141
   Demeure A, 2015, LECT NOTES COMPUT SC, V9083, P125, DOI 10.1007/978-3-319-18425-8_9
   Dey AK, 2006, LECT NOTES COMPUT SC, V3968, P254
   Emani S, 2012, J MED INTERNET RES, V14, P310, DOI 10.2196/jmir.2278
   Fogli Daniela, 2013, End User Development. 4th International Symposium, IS-EUD 2013. Proceedings. LNCS 7897, P153
   García-Herranz M, 2008, J UNIVERS COMPUT SCI, V14, P1529
   García-Herranz M, 2010, J UNIVERS COMPUT SCI, V16, P1633
   Graziano A.M., 2012, Research methods: A process of inquiry, V8th
   Humble J, 2003, LECT NOTES COMPUT SC, V2864, P256
   Klos A., 2012, SSRN ELECT J, DOI [10.2139/ssrn.2050899, DOI 10.2139/SSRN.2050899]
   Kubitza T, 2015, LECT NOTES COMPUT SC, V9083, P230, DOI 10.1007/978-3-319-18425-8_21
   Lewis JR, 2009, LECT NOTES COMPUT SC, V5619, P94, DOI 10.1007/978-3-642-02806-9_12
   Litvinova E, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P1090
   Lucci G, 2014, LECT NOTES COMPUT SC, V8742, P182, DOI 10.1007/978-3-662-44811-3_11
   Mavrommati I, 2007, LECT NOTES COMPUT SC, V4551, P864
   Mavrommati I, 2004, PERS UBIQUIT COMPUT, V8, P255, DOI 10.1007/s00779-004-0286-7
   Mehandjiev N, 2015, LECT NOTES COMPUT SC, V9083, P242, DOI 10.1007/978-3-319-18425-8_23
   Riva Giuseppe., 2005, Ambient intelligence: the evolution of technology, communication and cognition towards the future of human-computer interaction, V6
   Sadri F., 2009, ENCY ARTIFICIAL INTE, P85, DOI DOI 10.4018/978-1-59904-849-9.CH013
   SADRI F, 2007, P 2 WORKSH ART TECHN, P62
   Sadri F, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1978802.1978815
   Schmidt A, 2015, LECT NOTES COMPUT SC, V9083, P3, DOI 10.1007/978-3-319-18425-8_1
   Shafti LS, 2013, J AMB INTEL SMART EN, V5, P563, DOI 10.3233/AIS-130232
   Ur B., 2014, CHI, DOI 10.1145/2556288.2557420
   Wisner P, 2007, CONSUM COMM NETWORK, P716
   Zhang T, 2004, P 2 INT C SMART HOM, DOI 10.1.1.93.869
NR 56
TC 22
Z9 22
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5221
EP 5241
DI 10.1007/s11042-016-3511-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500024
OA Green Published
DA 2024-07-18
ER

PT J
AU Lee, J
   Chae, J
   Kim, DW
AF Lee, Jaesung
   Chae, Jonghoon
   Kim, Dae-Won
TI Effective music searching approach based on tag combination by
   exploiting prototypical acoustic content
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Music recommendation; Music tag; Acoustic feature; Associative tag
   mining
ID EMOTION
AB Within the music information retrieval community, many studies and applications have focused on tag-based music categorization. The limitation in employing music tags is the ambiguity of each tag. Thus, a single music tag covers too many sub-categories. To circumvent this, multiple tags can be used simultaneously to specify music clips more precisely. However, in conventional music recommendation systems, this might not be achieved because music clips identified by the system might not be prototypical to both or each tag. In this paper, we propose a new technique for ranking proper tag combinations based on the acoustic similarity of music clips. Based on empirical experiments, proper tag combinations are suggested by our proto-typicality analysis.
C1 [Lee, Jaesung; Chae, Jonghoon; Kim, Dae-Won] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
C3 Chung Ang University
RP Kim, DW (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
EM dwkim@cau.ac.kr
OI Lee, Jaesung/0000-0002-3757-3510
FU Ministry of Culture, Sports and Tourism (MCST); Korea Creative Content
   Agency (KOCCA) in the Culture Technology (CT) Research & Development
   Program
FX This research is supported by Ministry of Culture, Sports and Tourism
   (MCST) and Korea Creative Content Agency (KOCCA) in the Culture
   Technology (CT) Research & Development Program 2016.
CR Agrawal R., P 20 INT C VERY LARG
   [Anonymous], 2013, P INT SOC MUS INF RE
   [Anonymous], 2012, P 13 INT C MUS INF R
   Chen W, 2007, P IEEE INT C DAT MIN
   Deng J. J., 2013, INT C MULTIMEDIA MOD, P524
   Font F, 2014, KNOWL-BASED SYST, V67, P131, DOI 10.1016/j.knosys.2014.06.003
   Fu ZY, 2011, IEEE T MULTIMEDIA, V13, P303, DOI 10.1109/TMM.2010.2098858
   Huron D., 2000, Cognition, V10, P83
   Juslin PN, 2000, J EXP PSYCHOL HUMAN, V26, P1797, DOI 10.1037//0096-1523.26.6.1797
   Lamere P, 2008, J NEW MUSIC RES, V37, P101, DOI 10.1080/09298210802479284
   Lartillot O., 2007, P 10 INT C DIG AUD E, V237, P244, DOI DOI 10.1007/978-3-540-78246-9_31
   Lin YC, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037683
   LIU B, 1998, P INT C KNOWL DISC D
   Miotto R, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180870
   Nanopoulos A, 2011, INT CONF ACOUST SPEE, P165
   Ness S.R., 2009, Proceedings of the ACM International Conference on Multimedia, P705, DOI 10.1145/1631272.1631393
   Song Y., 2013, P 14 INT SOC MUSIC I, P89
   Tax DMJ, 2000, INT C PATT RECOG, P672, DOI 10.1109/ICPR.2000.906164
   Tingle D., 2010, P ISMIR, P55
   Trohidis K, 2008, INT SOC MUSIC INFORM
   Turnbull D, 2008, IEEE T AUDIO SPEECH, V16, P467, DOI 10.1109/TASL.2007.913750
   Turnbull D, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P387, DOI 10.1145/1571941.1572009
   Wang D., 2010, Proceedings of the International Conference on Music Information Retrieval, P57
   Wang J-C., 2011, Proc. of ACM MM, P293
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Zhao Z, 2010, P 18 INT C MULT FIR, P204
NR 26
TC 2
Z9 2
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 6065
EP 6077
DI 10.1007/s11042-016-3554-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500065
DA 2024-07-18
ER

PT J
AU Lu, TC
   Chen, CM
   Lin, MC
   Huang, YH
AF Lu, Tzu-Chuen
   Chen, Chang-Mu
   Lin, Mei-Chen
   Huang, Ying-Hsuan
TI Multiple predictors hiding scheme using asymmetric histograms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Gradient adjusted gap; Median edge detect;
   Asymmetric histogram
ID EDGE SENSING PREDICTION; ADAPTIVE PREDICTION; EXPANSION; PAYLOAD; IMAGES
AB In recent years, many data hiding techniques have been proposed, and they can be generally classified into two types according to the reversibility of the image; these two types are reversible and irreversible data hiding. This study focused on reversible data hiding, which makes recovering the cover image possible after the secret data has been extracted. In 2013, Chen et al. proposed an asymmetric-histogram reversible data hiding method. In their scheme, two prediction error histograms (maximum and minimum error histograms) were used to embed the secret message. Two histograms were shifted in opposite directions. Hence, some stego-pixels were shifted to their original values. The complementary embedding strategy is effective. However, the predictor in the method is rough. Only neighboring pixels were used to generate the prediction errors, thereby resulting in poor prediction efficiency. To enhance the prediction efficiency, this paper combines several well-known predictors such as gradient adjusted gap (GAP), median edge detect, and interpolation by neighboring pixel (INP) to generate prediction errors. Different predictors along with the asymmetric-histogram method can achieve better results. The predictor GAP used more neighboring pixels to obtain the prediction value; therefore, it is suitable for complex images. However, the predictor INP only considers that closer pixels can achieve great results for smooth images. Hence, the proposed scheme combines GAP and asymmetric histogram for complex images. However, the predictor INP along with asymmetric histogram is used for smooth images. Experimental results showed that the PSNR value of the proposed method is greater than that of the asymmetric-histogram shifting method and other recent approaches.
C1 [Lu, Tzu-Chuen; Chen, Chang-Mu; Lin, Mei-Chen] Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung, Taiwan.
   [Huang, Ying-Hsuan] Natl Chung Shan Inst Sci & Technol, Aeronaut Res Lab, Taichung 407, Taiwan.
C3 Chaoyang University of Technology
RP Lu, TC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, 168 Jifeng East Rd, Taichung, Taiwan.
EM tclu@cyut.edu.tw; s10114608@gm.cyut.edu.tw; mangy001@gmail.com;
   ying.hsuan0909@gmail.com
OI Lu, Tzu-Chuen/0000-0001-7305-4622
FU Taiwan's Ministry of Science and Technology [MOST 103-2221-E-324 -014 -]
FX This study was financially supported by a research grant from Taiwan's
   Ministry of Science and Technology (MOST 103-2221-E-324 -014 -).
CR Chen XY, 2013, J SYST SOFTWARE, V86, P2620, DOI 10.1016/j.jss.2013.04.086
   De SF, 2014, AEU-INT J ELECTRON C, V68, P933
   Fallahpour M, 2008, IEICE ELECTRON EXPR, V5, P870, DOI 10.1587/elex.5.870
   Feng GR, 2012, J SYST SOFTWARE, V85, P392, DOI 10.1016/j.jss.2011.08.033
   Hong W, 2012, OPT COMMUN, V285, P101, DOI 10.1016/j.optcom.2011.09.005
   Lee CF, 2012, EXPERT SYST APPL, V39, P6712, DOI 10.1016/j.eswa.2011.12.019
   Lu TC, 2014, SIGNAL PROCESS, V104, P152, DOI 10.1016/j.sigpro.2014.04.001
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2015, J VIS COMMUN IMAGE R, V31, P64, DOI 10.1016/j.jvcir.2015.05.005
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wen JY, 2012, INT J FUZZY SYST, V14, P244
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
   Zhang WM, 2014, SIGNAL PROCESS, V94, P118, DOI 10.1016/j.sigpro.2013.06.023
NR 18
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 3361
EP 3382
DI 10.1007/s11042-016-3960-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200011
DA 2024-07-18
ER

PT J
AU Norouzi, B
   Mirzakuchaki, S
AF Norouzi, Benyamin
   Mirzakuchaki, Sattar
TI Breaking a novel image encryption scheme based on an improper fractional
   order chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption algorithm; Cryptanalysis; Keystream; Chosen plaintext
   attack
AB In this paper, we analyze the security of a recent image encryption algorithm based on an improper fractional-order chaotic system suggested by Zhao et al. The fatal flaw in the cryptosystem is that the keystream generated depends on neither the plain-image nor the cipher-image. Another main issue with this algorithm is using the same key (the last key in the keystream) in all encryption equations. Based on these points, it is easy to recover the plain-image and the keystream by applying chosen plaintext attack in only one plain-image. Both mathematical analysis and experimental results confirm the feasibility of this attack. As a result, the cryptosystem under study is not suitable for cryptography.
C1 [Norouzi, Benyamin; Mirzakuchaki, Sattar] Iran Univ Sci & Technol, Elect Res Ctr, Sch Elect Engn, POB 16846-13114, Tehran, Iran.
C3 Iran University Science & Technology
RP Norouzi, B (corresponding author), Iran Univ Sci & Technol, Elect Res Ctr, Sch Elect Engn, POB 16846-13114, Tehran, Iran.
EM Benyamin_Norouzi@elec.iust.ac.ir; M_Kuchaki@iust.ac.ir
RI Mirzakuchaki, Sattar/JCO-4452-2023; Mirzakuchaki, Sattar/I-8764-2016
OI Mirzakuchaki, Sattar/0000-0003-0232-9267
CR Jolfaei A, 2014, DIGIT SIGNAL PROCESS, V32, P34, DOI 10.1016/j.dsp.2014.05.011
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P4363, DOI 10.1007/s11042-015-2479-7
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Norouzi B, 2015, MULTIMED TOOLS APPL, V74, P781, DOI 10.1007/s11042-013-1699-y
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Pareek NK, 2013, DIGIT SIGNAL PROCESS, V23, P894, DOI 10.1016/j.dsp.2013.01.005
   Parvin Z, 2016, MULTIMED TOOLS APPL, V75, P10631, DOI 10.1007/s11042-014-2115-y
   Patidar V, 2009, COMMUN NONLINEAR SCI, V14, P3056, DOI 10.1016/j.cnsns.2008.11.005
   Rhouma R, 2008, PHYS LETT A, V372, P5790, DOI 10.1016/j.physleta.2008.07.042
   Rhouma R, 2010, COMMUN NONLINEAR SCI, V15, P1887, DOI 10.1016/j.cnsns.2009.07.007
   Sam IS, 2012, MULTIMED TOOLS APPL, V56, P315, DOI 10.1007/s11042-010-0652-6
   Seyedzadeh SM, 2015, NONLINEAR DYNAM, V81, P511, DOI 10.1007/s11071-015-2008-2
   Wen WY, 2016, MULTIMED TOOLS APPL, V75, P3553, DOI 10.1007/s11042-015-2464-1
   Zhang YQ, 2014, NONLINEAR DYNAM, V77, P687, DOI 10.1007/s11071-014-1331-3
   Zhang YS, 2014, MULTIMED TOOLS APPL, V73, P1885, DOI 10.1007/s11042-013-1684-5
   Zhao JF, 2015, NONLINEAR DYNAM, V80, P1721, DOI 10.1007/s11071-015-1911-x
   Zhu CX, 2013, NONLINEAR DYNAM, V71, P25, DOI 10.1007/s11071-012-0639-0
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 21
TC 33
Z9 33
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1817
EP 1826
DI 10.1007/s11042-015-3085-4
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000010
DA 2024-07-18
ER

PT J
AU Song, Y
   Zeng, Y
   Li, XY
   Cai, BY
   Yang, GB
AF Song, Yun
   Zeng, Ye
   Li, Xueyu
   Cai, Biye
   Yang, Gaobo
TI Fast CU size decision and mode decision algorithm for intra prediction
   in HEVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding; CU size decision; Mode decision algorithm;
   Intra prediction
ID VIDEO CODING HEVC; STANDARD
AB In the intra prediction process, High Efficiency Video Coding (HEVC) provides a quadtree-based coding unit (CU) block partitioning structure and up to 35 kinds of prediction modes to improve the coding performance. These technologies improve the coding efficiency significantly while the coding complexity is simultaneously increased rapidly as well. In this paper, a novel fast CU size decision and mode decision algorithm is proposed for the intra prediction of HEVC. The overall algorithm consists of two processes, the fast CU size decision and fast mode decision. In the fast CU size decision process, we adopt an adaptive discretization total variation (DTV) threshold-based CU size determination algorithm to skip some specific depth levels. In the fast mode decision process, an orientation gradient-based mode decision is proposed to reduce the candidate modes involved in the rough mode decision (RMD) and the rate distortion optimization (RDO) process. The experimental results on the HEVC reference software HM demonstrate that the proposed algorithm can significantly reduce the coding time with negligible performance loss.
C1 [Song, Yun; Zeng, Ye; Li, Xueyu; Cai, Biye] Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha, Hunan, Peoples R China.
   [Song, Yun; Yang, Gaobo] Hunan Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.
   [Song, Yun; Zeng, Ye; Li, Xueyu; Cai, Biye] Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha, Hunan, Peoples R China.
C3 Changsha University of Science & Technology; Hunan University; Changsha
   University of Science & Technology
RP Song, Y (corresponding author), Changsha Univ Sci & Technol, Sch Comp & Commun Engn, Changsha, Hunan, Peoples R China.; Song, Y (corresponding author), Hunan Univ, Sch Informat Sci & Engn, Changsha, Hunan, Peoples R China.; Song, Y (corresponding author), Changsha Univ Sci & Technol, Hunan Prov Key Lab Intelligent Proc Big Data Tran, Changsha, Hunan, Peoples R China.
EM sonie@126.com; 980193148@qq.com; 401756139@qq.com; 512932680@qq.com;
   yanggaobo@hnu.edu.cn
FU Hunan Province Science and Technology Planning Project [2014FJ6047,
   2014GK3030]; Science Research Key Project of the Education Department of
   Hunan Province [13A107, 15A007]; Changsha Science and Technology
   Planning Project [K1403028-11]
FX This work was supported in part by the Hunan Province Science and
   Technology Planning Project (nos. 2014FJ6047 and 2014GK3030), the
   Science Research Key Project of the Education Department of Hunan
   Province (nos. 13A107 and 15A007), and the Changsha Science and
   Technology Planning Project (no. K1403028-11).
CR [Anonymous], ELECTRONIC JOURNAL O, DOI DOI 10.1109/VCIP.2011.6115979
   Bossen F., 2013, JCTVCL1100
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   Fini M. R., 2015, MULTIMED TOOLS APPL, P1
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kim J, 2013, IEEE ICCE, P637, DOI 10.1109/ICCE.2013.6487050
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Li Y, 2014, VIS COMM IM PROC C 2
   Pan ZQ, 2015, IEEE T BROADCAST, V61, P166, DOI 10.1109/TBC.2015.2419824
   Piao Y., 2010, JCTVCC207 ISOIEC ITU
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Song Y, 2014, IET COMMUN, V8, P1654, DOI 10.1049/iet-com.2013.0797
   Song Yun, 2013, Chinese Journal of Computers, V36, P1757, DOI 10.3724/SP.J.1016.2013.01757
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Vanne J, 2012, IEEE T CIRC SYST VID, V22, P1885, DOI 10.1109/TCSVT.2012.2223013
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wiegand T, 2003, 1449610 ISOIEC AVC
   Yan SQ, 2012, 8TH INTERNATIONAL CONFERENCE ON SIGNAL IMAGE TECHNOLOGY & INTERNET BASED SYSTEMS (SITIS 2012), P225, DOI 10.1109/SITIS.2012.41
   Zhang H, 2014, IEEE T CIRC SYST VID, V24, P660, DOI 10.1109/TCSVT.2013.2290578
   Zhang MM, 2012, IEEE IMAGE PROC, P221, DOI 10.1109/ICIP.2012.6466835
NR 21
TC 40
Z9 42
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2001
EP 2017
DI 10.1007/s11042-015-3155-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000019
DA 2024-07-18
ER

PT J
AU Wang, C
   Shen, MM
   Yao, C
AF Wang, Ci
   Shen, Minmin
   Yao, Chen
TI Rain streak removal by multi-frame-based anisotropic filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Structural noise; Anisotropic filter; Rain removal
ID SPARSE REPRESENTATION; IMAGE; DICTIONARIES; DIFFUSION; ALGORITHM; SIGNAL
AB Dynamic weather conditions, such as rain and snow, often produce strong intensity discontinuity among frames, thus seriously degrade their visual or compression performance. How to remove these artifacts is a challenging task and has been intensively studies recently. The state-of-the-art algorithms detect these scratches before removing them from the scene. Visual effect of rain or snow is complex and difficult to be distinguished from the background; hence the precision of its detection and segmentation by hard decision is usually unsatisfactory. As an anisotropic filter performs well in structural noise removal, such as linear, planar as well as isotropic noise, it is utilized in this paper to analyze image content and suppress scratch noise simultaneously. Compared with the state-of-the-art algorithms, the proposed algorithm is better and more robust in dynamic scenes.
C1 [Wang, Ci] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai, Peoples R China.
   [Shen, Minmin] South China Univ Technol, Sch Software Engn, Guangzhou, Guangdong, Peoples R China.
   [Yao, Chen] Minist Publ Secur, Res Inst 3, Shangahai, Peoples R China.
   [Yao, Chen] Shanghai Key Lab Digital Media Proc & Transmiss, Shangahai, Peoples R China.
C3 East China Normal University; South China University of Technology;
   Ministry of Public Security (China)
RP Yao, C (corresponding author), Minist Publ Secur, Res Inst 3, Shangahai, Peoples R China.; Yao, C (corresponding author), Shanghai Key Lab Digital Media Proc & Transmiss, Shangahai, Peoples R China.
EM yaochensing@126.com
RI Sun, Yuchen/JZD-1692-2024
FU National Nature Science Foundation of China [61302121, 61201446];
   Science and Technology Commission of Shanghai Municipality
   [14DZ2260800]; Shanghai Key Laboratory of Digital Media Processing and
   Transmission
FX This work is supported by National Nature Science Foundation of China,
   No. 61302121, 61201446, Science and Technology Commission of Shanghai
   Municipality under research grant no. 14DZ2260800, as well as the
   Opening Project of Shanghai Key Laboratory of Digital Media Processing
   and Transmission
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Brewer N, 2008, LECT NOTES COMPUT SC, V5342, P451, DOI 10.1007/978-3-540-89689-0_49
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chen DY, 2014, IEEE T CIRC SYST VID, V24, P1430, DOI 10.1109/TCSVT.2014.2308627
   Chen RY, 2007, J ATMOS SCI, V64, P3843, DOI 10.1175/2007JAS2126.1
   Dean N, 2005, BMC BIOINFORMATICS, V6, DOI 10.1186/1471-2105-6-173
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Fadili JM, 2010, COMPUT SCI ENG, V12, P44, DOI 10.1109/MCSE.2010.14
   Fernández JJ, 2003, J STRUCT BIOL, V144, P152, DOI 10.1016/j.jsb.2003.09.010
   Frangakis AS, 2001, IEEE T BIO-MED ENG, V48, P213, DOI 10.1109/10.909642
   Garg K, 2005, IEEE I CONF COMP VIS, P1067
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   Garg K, 2006, ACM T GRAPHIC, V25, P996, DOI 10.1145/1141911.1141985
   Hase H., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P406, DOI 10.1109/ICIP.1999.822927
   Kang L, 2011, IMAGE PROCESS IEEE T, V99, P1
   Mairal J, 2008, IEEE T IMAGE PROCESS, V17, P53, DOI 10.1109/TIP.2007.911828
   Starck J. L., 2005, P SPIE, V5914
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Yao C, 2014, ENTROPY-SWITZ, V16, P3302, DOI 10.3390/e16063302
   Zhang XP, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P461, DOI 10.1109/ICME.2006.262572
   Zhano M, 2008, IEEE T IMAGE PROCESS, V17, P2324, DOI 10.1109/TIP.2008.2006658
NR 24
TC 7
Z9 9
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2019
EP 2038
DI 10.1007/s11042-015-3195-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000020
DA 2024-07-18
ER

PT J
AU Choi, R
   Cho, CS
AF Choi, Ran
   Cho, Chang-Suk
TI An efficient approach for obtaining 3D surface curvature using blocked
   pattern projection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern projection; Lattice pattern; 3D surface; Reconstruction
AB According to the development of 3D printer the need for 3D scanning technology becomes one of the most rapid increasing parts among industries. In order to obtain 3D surface curvature of a back, an efficient approach using lattice pattern is presented. The surface curvature can be obtained from the distorted block edges projected with the black and white lattice pattern. This method uses the block patterns like chess plate in order to obtain surface curvature of a back efficiently. The block pattern provides robust result and uniform resolutions to vertical and horizontal curvature comparing to slit line pattern. The precision of this method was calculated by the experiment to a sphere model and the reconstruction result of a back was presented.
C1 [Choi, Ran; Cho, Chang-Suk] Hanshin Univ, Div Informat & Telecom, Yangsan Dong 447791, Osan Si, South Korea.
C3 Hanshin University
RP Cho, CS (corresponding author), Hanshin Univ, Div Informat & Telecom, Yangsan Dong 447791, Osan Si, South Korea.
EM cscho@hs.ac.kr
FU Hanshin university grant
FX This work was supported by Hanshin university grant.
CR AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626
   [Anonymous], J CONVERGENCE
   [Anonymous], 2000, THESIS
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Guan C, 2003, OPT EXPRESS, V11, P406, DOI 10.1364/OE.11.000406
   HAUSLER G, 1988, APPL OPTICS, V27, P5165, DOI 10.1364/AO.27.005165
   Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136
   Jang W, 2013, OPT LASER ENG, V51, P1255, DOI 10.1016/j.optlaseng.2013.05.001
   Je C, 2013, SIGNAL PROCESS-IMAGE, V28, P1046, DOI 10.1016/j.image.2013.05.005
   Kim GS, 2012, 38 KIPS FALL C 2012, V19, P499
   Kim J, 2014, J INF PROCESS SYST, V10, P23, DOI 10.3745/JIPS.2014.10.1.023
   Li Y, 2010, OPT EXPRESS, V18, P21628, DOI 10.1364/OE.18.021628
   Navalyal GU, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0011-0
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park JY, 2013, LECT NOTES ELECT ENG, V279, P115
   Salvi J, 2010, PATTERN RECOGN, V43, P2666, DOI 10.1016/j.patcog.2010.03.004
   SATO Y, 1982, IEEE T PATTERN ANAL, V4, P641, DOI 10.1109/TPAMI.1982.4767318
   Udayan JD, 2013, J CONVERG, V4, P6
   VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402
NR 19
TC 2
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15679
EP 15691
DI 10.1007/s11042-015-2902-0
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700035
DA 2024-07-18
ER

PT J
AU Hong, GS
   Kim, BG
   Hwang, YS
   Kwon, KK
AF Hong, Gwang-Soo
   Kim, Byung-Gyu
   Hwang, Young-Sup
   Kwon, Kee-Koo
TI Fast multi-feature pedestrian detection algorithm based on histogram of
   oriented gradient using discrete wavelet transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural user interface (NUI); Region of interest (ROI); Discrete wavelet
   transform (DWT); Histogram of oriented gradient (HOG)
ID RECOGNITION
AB A convergence between a natural user interface (NUI) and advanced driver assistance system is considered as a next generation technology. This kind of interfacing system technology becomes more popular in driver assistance system of automobile. Especially, pedestrian detection is an important cue for intelligent vehicles and interactive driver assistance system. In this paper, we propose a pedestrian detection feature and technique by combining histogram of the oriented gradient (HOG) and discrete wavelet transform (DWT). In the method, the magnitude of motion is used to set region of interest (ROI) for improving detection speed. Then, we employ multi-feature for a pedestrian detection based on the HOG and DWT. In last stage, to classify whether a candidate window contains a pedestrian or not, the designed multi-feature is learned by using the training data with the support vector machine (SVM) mechanism. Experimental results show that the proposed algorithm increases the speed-up factor of 27.21 % by comparing to the existing method using the original HOG feature.
C1 [Hong, Gwang-Soo; Kim, Byung-Gyu; Hwang, Young-Sup] SunMoon Univ, Dept Comp Engn, Asan, South Korea.
   [Kwon, Kee-Koo] ETRI, Automot IT Platform Res Team, Daegu, South Korea.
C3 Sun Moon University; Electronics & Telecommunications Research Institute
   - Korea (ETRI)
RP Kim, BG (corresponding author), SunMoon Univ, Dept Comp Engn, Asan, South Korea.
EM honzolv@mpcl.sunmoon.ac.kr; bg.kim@ieee.org; young@sunmoon.ac.kr;
   kwonkk@etri.re.kr
FU agency specific research program of MSIP, Korea
FX This work was supported by the agency specific research program of MSIP,
   Korea [Development of multi-sensor platform technology for context
   cognitive smart-car]
CR [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   [Anonymous], J CONVERGENCE
   Cellario M., 2001, IEEE Intelligent Systems, V16, P78, DOI 10.1109/5254.941364
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Gandhi T, 2007, IEEE T INTELL TRANSP, V8, P413, DOI 10.1109/TITS.2007.903444
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Guoqing Xu, 2011, Proceedings 2011 International Conference on Information and Automation (ICIA 2011), P384, DOI 10.1109/ICINFA.2011.5949022
   Hou C., 2007, P AS C COMP VIS, P18
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Nagi GM, 2013, J INF PROCESS SYST, V9, P173, DOI 10.3745/JIPS.2013.9.1.173
   Panganiban A, 2011, J INF PROCESS SYST, V7, P425, DOI 10.3745/JIPS.2011.7.3.425
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Patil PB, 2013, J INF PROCESS SYST, V9, P349, DOI 10.3745/JIPS.2013.9.3.349
   Sabzmeydani P., 2007, IEEE C COMPUTER VISI, P1
   Tsuduki Y, 2009, LECT NOTES COMPUT SC, V5414, P25, DOI 10.1007/978-3-540-92957-4_3
   Walk S, 2010, PROC CVPR IEEE, P1030, DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Xun Z., 2009, INT J BIOMED IMAGING, P1
   Zhang SS, 2013, 2013 IEEE WORKSHOP ON ROBOT VISION (WORV), P102, DOI 10.1109/WORV.2013.6521921
NR 25
TC 18
Z9 20
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15229
EP 15245
DI 10.1007/s11042-015-2455-2
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700007
DA 2024-07-18
ER

PT J
AU Lee, S
   Kim, JW
   Ahn, E
AF Lee, Suyeol
   Kim, Jae-Won
   Ahn, Eunyoung
TI A visual simulation method for weathering progress of stone artifacts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural collapse; Stone artifacts; Voxelization; Visualization
ID FREEZE-THAW; DETERIORATION; CYCLES; ROCKS
AB This paper focuses on a new method to visualize weathering effects due to the physical changes of stone artifacts. Major parameters concerned with both the breakdown process and changes of properties of the particles that comprise the stone artifact are considered. We pay attention to the fact that the common and main cause of weathering is granular disintegration and that such disintegration depends on the porosity, that is to say the percentage of voids. We define an estimation function in time for transient behaviors of the physical properties of stone, the material for sculpture. In order to visualize the erosion of a stone sample, voxel-based representation has a decided advantage. Accordingly, a representation of a sculpture with surface modeling using polygons and mesh is converted to a voxel-based representation. The voxels are treated as particles of a sculpture; we observe the transient changes of the physical properties for each voxel. To ensure natural conditions, initial states of the particles are defined using a probability distribution function. It was possible to realize a natural expression of the aging effects of stone by applying weighting factors depending on how voxels are exposed to the surrounding environment. In addition, for computational efficiency, instead of including all voxels when calculating property changes, only the surface voxels of the sculpture are calculated for transient changes.
C1 [Lee, Suyeol; Ahn, Eunyoung] Hanbat Natl Univ, Dept Multimedia Engn, Daejeon, South Korea.
   [Kim, Jae-Won] Sunmoon Univ, Dept Mech Engn, Asan, South Korea.
C3 Hanbat National University; Sun Moon University
RP Ahn, E (corresponding author), Hanbat Natl Univ, Dept Multimedia Engn, Daejeon, South Korea.
EM cr301080@hanbat.ac.kr; jwk@sunmoon.ac.kr; aey@hanbat.ac.kr
FU National Research Foundation of Korea (NRF) - Ministry of Education,
   Science and Technology through the Basic Science Research Program
   [201204400001]
FX This research is supported by National Research Foundation of Korea
   (NRF) funded by the Ministry of Education, Science and Technology
   through the Basic Science Research Program (201204400001).
CR [Anonymous], J CONVERGENCE
   Chen TC, 2004, COLD REG SCI TECHNOL, V38, P127, DOI 10.1016/j.coldregions.2003.10.001
   Christou G, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-15
   Hall K, 1999, GEOMORPHOLOGY, V31, P47, DOI 10.1016/S0169-555X(99)00072-0
   Jung M-H, 2009, KOREA ACAD IND COOP, V10, P2026
   Mutlutürk M, 2004, INT J ROCK MECH MIN, V41, P237, DOI 10.1016/S1365-1609(03)00095-9
   Nicholson DT, 2000, EARTH SURF PROC LAND, V25, P1295, DOI 10.1002/1096-9837(200011)25:12<1295::AID-ESP138>3.0.CO;2-E
   Ryu S, 2012, KOREAN SOC ROCK MECH, V22, P276
   Tan XJ, 2011, COLD REG SCI TECHNOL, V68, P130, DOI 10.1016/j.coldregions.2011.05.007
   Udayan JD, 2013, J CONVERGENCE, V4, P6
   Um J-G, 2012, KOREAN SOC ROCK MECH, V22, P32
   Woo I, 2009, TUNNEL UNDERGROUND S, V19, P213
   Yang J-H, 2011, KOREAN GEOMORPHOL AS, V18, P21
   Yavuz H, 2006, INT J ROCK MECH MIN, V43, P767, DOI 10.1016/j.ijrmms.2005.12.004
NR 14
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15247
EP 15259
DI 10.1007/s11042-015-2507-7
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700008
DA 2024-07-18
ER

PT J
AU Nyeem, H
   Boles, W
   Boyd, C
AF Nyeem, Hussain
   Boles, Wageeh
   Boyd, Colin
TI Modelling attacks on self-authentication watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Counterfeiting attack; Fragile watermarking; Information assurance;
   Multimedia security; Self-authentication
ID IMAGE TAMPER DETECTION; COUNTERFEITING ATTACKS; DIGITAL SIGNATURE;
   SECURE; SCHEME
AB Although the Self-Authentication Watermarking (SAW) schemes are promising to tackle the multimedia information assurance problem, their unknown security level seems to impair their potential. In this paper, we identify three new counterfeiting attacks on those schemes and present their countermeasure. We develop, analyse, and validate the models of the identified attacks followed by the development of a new SAW model to resist those attacks. The identified attack models generalize three main security levels that capture all the possible counterfeiting instances. We focus on the block-wise dependent fragile watermarking schemes, and their general weaknesses. Experimental results successfully demonstrate the practicality and consequences of the identified attacks in exploiting those weaknesses to maliciously and undetectably alter valid watermarked images. To resist the identified attacks, we further determine a set of general requirements for SAW schemes and illustrate their attainment in developing an extended SAW model. While the identified attack models can be used as a means to systematically examine the security levels of similar SAW schemes, the extended SAW model may lead to developing their more secure variants. Our study has also revealed some open challenges in the development and formal analysis of SAW schemes.
C1 [Nyeem, Hussain] Khulna Univ Engn & Technol, Dept Elect & Commun Engn ECE, Khulna 9203, Bangladesh.
   [Boles, Wageeh] Queensland Univ Technol, Sch Elect Engn & Comp Sci EECS, Brisbane, Qld 4001, Australia.
   [Boyd, Colin] Norwegian Univ Sci & Technol NTNU, Dept Telemat, N-7491 Trondheim, Norway.
   [Boyd, Colin] QUT, Sch EECS, Brisbane, Qld 4001, Australia.
C3 Khulna University of Engineering & Technology (KUET); Queensland
   University of Technology (QUT); Norwegian University of Science &
   Technology (NTNU); Queensland University of Technology (QUT)
RP Nyeem, H (corresponding author), Khulna Univ Engn & Technol, Dept Elect & Commun Engn ECE, Khulna 9203, Bangladesh.
EM h.nyeem@kuet.ac.bd; w.boles@qut.edu.au; colin.boyd@item.ntnu.no
RI Nyeem, Hussain/G-7075-2014; Boles, Wageeh W/I-9633-2012
OI Nyeem, Hussain/0000-0003-4839-5059; Boles, Wageeh W/0000-0002-5093-2952
CR Ahmed F, 2010, SIGNAL PROCESS, V90, P1456, DOI 10.1016/j.sigpro.2009.05.024
   [Anonymous], 2010, Understanding Cryptography
   [Anonymous], 2008, US Patent, Patent No. [7,389,420, 7389420]
   Bartolini F, 2001, P IEEE, V89, P1403, DOI 10.1109/5.959338
   Celik MU, 2002, IEEE T IMAGE PROCESS, V11, P585, DOI 10.1109/TIP.2002.1014990
   Chang CC, 2008, PATTERN RECOGN, V41, P654, DOI 10.1016/j.patcog.2007.06.003
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Edupuganti VG, 2012, EFFICIENT BLOCK BASE
   Fei CH, 2006, IEEE T INF FOREN SEC, V1, P43, DOI 10.1109/TIFS.2005.863505
   Fridrich J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P792, DOI 10.1109/ICIP.1999.817228
   Fridrich J., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P178, DOI 10.1109/ITCC.2000.844203
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Fridrich J, 2002, J ELECTRON IMAGING, V11, P262, DOI 10.1117/1.1459449
   Fridrich J, 2000, PROC SPIE, V3971, P286, DOI 10.1117/12.384982
   Fridrich J, 1999, SYMPOSIUM ON CONTENT
   Han SH, 2010, INT J INF SECUR, V9, P19, DOI 10.1007/s10207-009-0093-2
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   He HJ, 2009, SIGNAL PROCESS, V89, P1557, DOI 10.1016/j.sigpro.2009.02.009
   He HJ, 2006, INT J COMPUT SCI NET, V6, P251
   Holliman M, 2000, IEEE T IMAGE PROCESS, V9, P432, DOI 10.1109/83.826780
   Katzenbeisser S, 2013, CHALLENGES SOLUTIONS
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Lee TY, 2008, PATTERN RECOGN, V41, P3497, DOI 10.1016/j.patcog.2008.05.003
   Li Weng, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P380, DOI 10.1109/ICME.2012.163
   Lie WN, 2006, IEEE T INF FOREN SEC, V1, P330, DOI 10.1109/TIFS.2006.879297
   Lin PL, 2005, PATTERN RECOGN, V38, P2519, DOI 10.1016/j.patcog.2005.02.007
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Mobasseri BG, 2000, IEEE IMAGE PROC, P458, DOI 10.1109/ICIP.2000.900994
   Nyeem H., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P468, DOI 10.1109/DICTA.2011.85
   Nyeem H, 2012, P ICIEV 12
   Nyeem H., 2013, P 6 INT C SEC INF NE, P86
   Nyeem H.A., 2014, THESIS
   Nyeem H, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-135
   Phen-Lan Lin, 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P146
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Sencar HT, 2009, STAT SCI INTERDISC R, V3, P325
   Siau-Chuin Liew, 2010, Journal of Computer Sciences, V6, P794, DOI 10.3844/jcssp.2010.794.799
   Sun QB, 2005, IEEE T MULTIMEDIA, V7, P480, DOI 10.1109/TMM.2005.846776
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Xie LH, 2001, IEEE T MULTIMEDIA, V3, P242, DOI 10.1109/6046.923823
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
   Zain Jasni M, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P3270
   Zhang Hong-bin, 2004, Acta Electronica Sinica, V32, P196
   Zhu BB, 2004, IEEE SIGNAL PROC MAG, V21, P40, DOI 10.1109/MSP.2004.1276112
NR 44
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15849
EP 15880
DI 10.1007/s11042-015-2893-x
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700043
DA 2024-07-18
ER

PT J
AU Punithan, XJ
   Kim, JD
   Kim, D
   Choi, YH
AF Punithan, Xaiver Jerald
   Kim, Jong-Deok
   Kim, Dongseok
   Choi, Yoon-Ho
TI A game theoretic model for dynamic configuration of large-scale
   intrusion detection signatures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Game; Network security; Intrusion detection signature; Dynamic
   configuration
AB In this paper, we note that the signature-based intrusion detection system (S-IDS) can cause the low accuracy against mutants of intrusion packets. This is because the S-IDS commonly detects network intrusion in data flows by identifying the existence of the predefined intrusion signatures, which is called static intrusion signature configuration (SISC). To increase the accuracy, all intrusion signatures corresponding to all possible mutants of a pertinent attack may be activated. However, the static intrusion signature configuration with all possible intrusion signatures can largely increase the size of storage and the signature search time in the process of signature analysis. To solve the problems that occur when activating all possible intrusion signatures, we propose a two-player non-cooperative zero-sum game with incomplete information for dynamic intrusion signature configuration (DISC), where the various lengths of an intrusion signature have been activated in a time-shared manner. After formulating the problem into the game theoretic approach, we found the optimal strategy for DISC in the S-IDS. To the best of our knowledge, this work is the first approach that analyzes the optimal DISC strategy against the various mutants of intrusion packets. From evaluation results, we show that the DISC by the defender is more effective than the SISC against various mutants of intrusion packets by the intruder.
C1 [Punithan, Xaiver Jerald] SNU, Sch Elect & Comp Engn, Seoul, South Korea.
   [Kim, Jong-Deok; Choi, Yoon-Ho] PNU, Sch Comp Sci & Engn, Busan, South Korea.
   [Kim, Dongseok] KGU, Dept Math, Suwon, South Korea.
C3 Seoul National University (SNU)
RP Choi, YH (corresponding author), PNU, Sch Comp Sci & Engn, Busan, South Korea.
EM maxje@cnslab.snu.ac.kr; kimjd@pusan.ac.kr; dongseok@kyonggi.ac.kr;
   choi.yuno@gmail.com
RI Choi, Yoon Ho/JXM-6303-2024
FU ICT R&D program of MSIP/IITP [2014(1711021663)]
FX This work was supported by the ICT R&D program of MSIP/IITP.
   [2014(1711021663) Research on Implementation Techniques of Realistic
   Experience-type Contents based Smart Street].
CR Agah A, 2004, THIRD IEEE INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS, PROCEEDINGS, P343, DOI 10.1109/NCA.2004.1347798
   Alpcan T., 2004, P 43 IEEE C DEC CONT
   [Anonymous], P IEEE S SEC PRIV
   [Anonymous], J CONVERGENCE
   Cho Y.S., 2013, J CONVERG, V4, P36
   Choi YH, 2011, COMPUT COMMUN, V34, P1750, DOI 10.1016/j.comcom.2011.03.014
   Conitzer Vincent, 2003, P 18 INT JOINT C ART, P765
   Elsayed E, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-19
   Howard N, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-9
   HUA N, 2009, 28 C COMP COMM INFOC
   Kim H.-A., 2004, P 13 USENIX SEC S
   Kodialam M, 2003, IEEE INFOCOM SER, P1880
   KREIBICH C, 2003, P 2 WORKSH HOT TOP N
   Kumar S, 2006, P 2006 ACM IEEE S AR
   Kumar S, 2006, ACM SIGCOMM 06
   Liu Y, 2006, P 2006 IEEE NT C COM
   Malkawi M, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-3
   Mehrandish M, 2006, P 2006 IEEE INT C CO
   Owen G., 1995, GAME THEORY
   Patcha A, 2004, PROCEEDINGS FROM THE FIFTH IEEE SYSTEMS, MAN AND CYBERNETICS INFORMATION ASSURANCE WORKSHOP, P280, DOI 10.1109/IAW.2004.1437828
   Singh S, 2003, CS20030761 UCSD
   Smith R, 2008, P IEEE S SECUR PRIV, P187, DOI 10.1109/SP.2008.14
   Verma OP, 2013, J INF PROCESS SYST, V9, P575, DOI 10.3745/JIPS.2013.9.4.575
   Von Neuman J., 1947, THEORY GAMES EC BEHA
   Yang X., 2013, J CONVERG, V4, P11
   Yoon SH, 2013, J INF PROCESS SYST, V9, P621, DOI 10.3745/JIPS.2013.9.4.621
   Zhu C, 2013, J INF PROCESS SYST, V9, P511, DOI 10.3745/JIPS.2013.9.4.511
NR 27
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15461
EP 15477
DI 10.1007/s11042-015-2508-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700021
DA 2024-07-18
ER

PT J
AU Sahu, N
   Rana, S
   Sur, A
AF Sahu, Nilkanta
   Rana, Shuvendu
   Sur, Arijit
TI MCDCT-TF based video watermarking resilient to temporal and quality
   scaling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable Video Coding (SVC); Scale invariant; Block DCT; MCDCT-TF;
   Scalable watermarking; Blind watermarking
AB Heterogeneity among the end using display devices and corresponding varying system requirements make scalable version of H.264/AVC standard more popular. Existing watermarking based authentication system may not be suitable well for this new extension, because the scalability property of the codec may itself is perceived as an attack popularly known as content adaptation attack. In this paper, a blind scalable video watermarking scheme is proposed, which is robust against quality and temporal scalability. In the proposed scheme, Discrete Cosine Transform (DCT) based temporal filtering and wavelet based spatial filtering is used for choosing suitable watermark embedding zone. Experimental evidences are provided to justify the improved robustness of the proposed scheme over existing related watermarking schemes. The visual quality of the watermarked video has also been evaluated to show the efficiency of the proposed scheme.
C1 [Sahu, Nilkanta; Rana, Shuvendu; Sur, Arijit] IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Sahu, N (corresponding author), IIT Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
EM nilkanta@iitg.ernet.in; shuvendu@iitg.ac.in; arijit@iitg.ac.in
RI Sur, Arijit/AAB-4216-2020; Rana, Shuvendu/J-5190-2019; Rana,
   Shuvendu/ACC-7002-2022
OI Rana, Shuvendu/0000-0002-8372-5669; Rana, Shuvendu/0000-0002-8372-5669;
   Sur, Arijit/0000-0002-9038-8138
CR Atta R, 2006, IEEE T CIRC SYST VID, V16, P43, DOI 10.1109/TCSVT.2005.858743
   Bhowmik D, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P127
   Choi SJ, 1999, IEEE T IMAGE PROCESS, V8, P155, DOI 10.1109/83.743851
   Dutta T, 2013, P 21 ACM INT C MULT, P1039, DOI 10.1145/2502081.2502211
   Fan X., 2002, JVTE070
   Flierl M, 2004, SIGNAL PROCESS-IMAGE, V19, P561, DOI 10.1016/j.image.2004.05.002
   Meerwald P, 2008, PROC SPIE, V6819, DOI 10.1117/12.766444
   Meerwald P, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P357, DOI 10.1109/ICME.2008.4607445
   Mokhtarian K, 2010, IEEE T MULTIMEDIA, V12, P730, DOI 10.1109/TMM.2010.2051410
   National Institute of Standards and Technology, 2001, FIPS197
   Ohm JR, 1993, IEEE T CIRC SYST VID, V3, P208, DOI 10.1109/76.224231
   Rana S, 2015, MULTIMED TOOLS APPL, V74, P7773, DOI 10.1007/s11042-014-2023-1
   Stütz T, 2012, IEEE T CIRC SYST VID, V22, P325, DOI 10.1109/TCSVT.2011.2162290
   Vatolin D., 2001, MSU VIDEO QUALITY ME
   Verdicchio F, 2004, IEEE IMAGE PROC, P2845
   Vinod P., 2006, IEE Proceedings-Information Security, V153, P61, DOI 10.1049/ip-ifs:20055088
   Vural C, 2015, SIGNAL IMAGE VIDEO P, V9, P1613, DOI 10.1007/s11760-014-0618-7
   Wang C J, 2006, MODERNIZ AGAR, V4, P6
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 1998, PERCEPTUAL VIDEO QUA, DOI [10.1117/12.320105, DOI 10.1117/12.320105]
NR 20
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 16835
EP 16860
DI 10.1007/s11042-015-2949-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600006
DA 2024-07-18
ER

PT J
AU Hwang, J
   Park, S
AF Hwang, Junsik
   Park, Seongbin
TI LIDAB: a user-friendly display system for linked multimedia data and its
   application in education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Semantic web; Linked data; Linked multimedia browser
ID WEB
AB The Semantic Web is an extension of the current Web where information is represented in a way that computer programs such as software agents can understand the meaning of the information without human's intervention. Like the Web, huge number of hyperlinked data exist on the Semantic Web which results in the Web of Linked Data. In addition, one can easily encounter hyperlinked multimedia data such as image files, video clips, etc. on the Semantic Web. In this paper, we propose a browsing system called LIDAB which shows user-friendly views of different types of linked multimedia data sources on the Semantic Web. The motivation behind our research is to provide lay users without technical backgrounds on the Semantic Web with intuitive views on the linked multimedia data. While there exist well-known linked data browsing systems such as Tabulator, Disco, etc., using these systems are not always easy for novice users since they do not show intuitive views on browser screens. On the other hand, our system generates a view that looks almost like a normal HTML view that one can see on a Web browser. Our system has two types of audience: non-expert users who browse the information on the Semantic Web and Web designers who can create HTML documents. It is easy to use the proposed system in various educational scenarios where students can surf the Semantic Web to study learning materials.
C1 [Hwang, Junsik; Park, Seongbin] Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
C3 Korea University
RP Park, S (corresponding author), Korea Univ, Dept Comp Sci Educ, Seoul, South Korea.
EM hyperspace@korea.ac.kr
FU Basic Science Research Program through National Research Foundation of
   Korea (NRF) - Ministry of Education [2013R1A1A2062713]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (2013R1A1A2062713). The authors would like to thank
   anonymous reviewers for valuable comments about the manuscript and
   suggestions for future work.
CR Berners-Lee T., 2006, P 3 INT SEM WEB US I
   Berners-Lee T., 2001, The Semantic Web
   Bizer C., 2007, Disco-Hyperdata Browser: A simple browser for navigating the Semantic Web
   Bizer C, 2009, IEEE INTELL SYST, V24, P87, DOI 10.1109/MIS.2009.102
   d'Aquin M., 2013, Proceedings of the 5th Annual ACM Web Science Conference, P43, DOI [10.1145/2464464.2464487, DOI 10.1145/2464464.2464487]
   Dadzie AS, 2011, SEMANT WEB, V2, P89, DOI 10.3233/SW-2011-0037
   Devedzic V, 2006, INTEGRATED SERIES IN, P12
   Heim P, 2009, LECT NOTES COMPUT SC, V5887, P182, DOI 10.1007/978-3-642-10543-2_21
   Herder E, 2013, UMAP EXTENDED P
   Moore GC, 1991, INFORM SYST RES, V2, P192, DOI 10.1287/isre.2.3.192
   Motta E, 2006, LECT NOTES COMPUT SC, V4185, P24
   Shadbolt N, 2006, IEEE INTELL SYST, V21, P96, DOI 10.1109/MIS.2006.62
   STOJANOVIC L, 2001, WORLD C WWW INT
   Tiropanis T, 2009, IEEE INTELL SYST, V24, P49, DOI 10.1109/MIS.2009.121
   Tummarello G, 2010, J WEB SEMANT, V8, P355, DOI 10.1016/j.websem.2010.08.003
NR 15
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13149
EP 13162
DI 10.1007/s11042-015-2994-6
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800011
DA 2024-07-18
ER

PT J
AU Makantasis, K
   Protopapadakis, E
   Doulamis, A
   Matsatsinis, N
AF Makantasis, Konstantinos
   Protopapadakis, Eftychios
   Doulamis, Anastasios
   Matsatsinis, Nikolaos
TI Semi-supervised vision-based maritime surveillance system using fused
   visual attention maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vision-based system; Maritime surveillance; Semi-supervised learning;
   Visual attention maps; Vehicle tracking
AB This paper presents a vision-based system for maritime surveillance, using moving PTZ cameras. The proposed methodology fuses a visual attention method that exploits low-level image features appropriately selected for maritime environment, with appropriate tracker, without making any assumptions about environmental or visual conditions. The offline initialization is based on large graph semi-supervised technique. System's performance was evaluated with videos from cameras placed at Limassol port and Venetian port of Chania. Results suggest high detection ability, despite dynamically changing visual conditions and different kinds of vessels, all in real time.
C1 [Makantasis, Konstantinos; Protopapadakis, Eftychios] Tech Univ Crete, Khania, Greece.
   [Matsatsinis, Nikolaos] Tech Univ Crete, Sch Prod Engn & Management, Informat & Decis Support Syst, Khania, Greece.
   [Doulamis, Anastasios] Natl Tech Univ Athens, Image Video & Multimedia Lab, Athens, Greece.
C3 Technical University of Crete; Technical University of Crete; National
   Technical University of Athens
RP Protopapadakis, E (corresponding author), Tech Univ Crete, Khania, Greece.
EM kmakantasis@isc.tuc.gr; eprotopapadakis@isc.tuc.gr; adoulam@cs.ntua.gr;
   nikos@ergasya.tuc.gr
RI Makantasis, Konstantinos/Q-4475-2018; Doulamis,
   Anastasios/AAL-5972-2021; Protopapadakis, Eftychios/AAP-1371-2021;
   Matsatsinis, Nikolaos F/Q-8291-2016
OI Makantasis, Konstantinos/0000-0002-0889-2766; Protopapadakis,
   Eftychios/0000-0003-3876-0024; 
FU IKY Fellowships of excellence for postgraduate studies in Greece-Siemens
   program; European Union; national funds from Greece and Cyprus under the
   project POSEIDON: Development of an Intelligent System for Coast
   Monitoring using Camera Arrays and Sensor Networks in the context of the
   inter-regional programme INTERREG (Greece-Cyprus cooperation) [K1 3
   1017/6/2011]
FX The work has been partially supported by IKY Fellowships of excellence
   for postgraduate studies in Greece-Siemens program. The work has, also,
   been supported by European Union funds and national funds from Greece
   and Cyprus under the project POSEIDON: Development of an Intelligent
   System for Coast Monitoring using Camera Arrays and Sensor Networks in
   the context of the inter-regional programme INTERREG (Greece-Cyprus
   cooperation) - contract agreement K1 3 1017/6/2011.
CR Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Agnew DJ, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004570
   Albrecht T., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P302, DOI 10.1109/DICTA.2010.59
   Albrecht T.W.J., 2011, Chemeca 2011: Engineering a Better World
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2011 INT C DIG IM CO
   [Anonymous], P COASTGIS 2013 C MO
   [Anonymous], ONLINE LEARNING SHIP
   [Anonymous], 2013, P INT WORKSH AN RETR
   [Anonymous], COMP EVALUATION ANOM
   [Anonymous], USING MANIFOLD STRUC
   [Anonymous], 2012 13 INT WORKSH I
   [Anonymous], VISUAL SURVEILLANCE
   [Anonymous], TARGET IDENTIFICATIO
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Doulamis N, 2012, LECT NOTES COMPUT SC, V7585, P345, DOI 10.1007/978-3-642-33885-4_35
   Edlund, 2008, 2008 11 INT C INF FU, P1
   Fischer Y., 2010, P INT WAT SID SEC C, P1, DOI [10.1109/WSSC.2010.5730244, DOI 10.1109/WSSC.2010.5730244]
   Lafferty J. D., 2003, P INT C MACH LEARN, P912, DOI DOI 10.5555/3041838.3041953
   Lei PR, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENCE AND SECURITY INFORMATICS: BIG DATA, EMERGENT THREATS, AND DECISION-MAKING IN SECURITY INFORMATICS, P271, DOI 10.1109/ISI.2013.6578839
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Liu W., 2010, PROC ICML, P679
   Makantasis K, 2013, 2013 14TH INTERNATIONAL WORKSHOP ON IMAGE ANALYSIS FOR MULTIMEDIA INTERACTIVE SERVICES (WIAMIS)
   Maresca S., 2010, 2010 2nd International Workshop on Cognitive Information Processing (CIP 2010), P40, DOI 10.1109/CIP.2010.5604209
   McIlhagga W, 2011, INT J COMPUT VISION, V91, P251, DOI 10.1007/s11263-010-0392-0
   Nadler B., 2009, Advances in Neural Information Processing Systems, P1330
   Onuoha FC, 2009, AFR SECUR REV, V18, P31, DOI 10.1080/10246029.2009.9627540
   Socek D, 2005, LECT NOTES COMPUT SC, V3708, P340
   Stanslas PT, 2010, J MARIT LAW COMMER, V41, P595
   Szpak ZL, 2011, EXPERT SYST APPL, V38, P6669, DOI 10.1016/j.eswa.2010.11.068
   Yasri I., 2008, EL DES 2008 ICED 200, P1, DOI DOI 10.1109/ICED.2008.4786751
   Zemmari R, 2013, INT RADAR SYMP PROC, P245
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 34
TC 15
Z9 15
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 22
BP 15051
EP 15078
DI 10.1007/s11042-015-2512-x
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6YQ
UT WOS:000386775500060
DA 2024-07-18
ER

PT J
AU Navarro-Newball, AA
   Moreno, I
   Prakash, E
   Arya, A
   Contreras, VE
   Quiceno, VA
   Lozano, S
   Mejía, JD
   Loaiza, DF
AF Adolfo Navarro-Newball, Andres
   Moreno, Isidro
   Prakash, Edmond
   Arya, Ali
   Contreras, Victoria E.
   Quiceno, Victor A.
   Lozano, Santiago
   David Mejia, Juan
   Fernando Loaiza, Diego
TI Gesture based human motion and game principles to aid understanding of
   science and cultural practices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture; Human motion; Gamification; Museum
AB We present a novel approach for recreating life-like experiences through an easy and natural gesture-based interaction. By focusing on the locations and transforming the role of the user, we are able to significantly maximise the understanding of an ancient cultural practice, behaviour or event over traditional approaches. Technology-based virtual environments that display object reconstructions, old landscapes, cultural artefacts, and scientific phenomena are coming into vogue. In traditional approaches the user is a visitor navigating through these virtual environments observing and picking objects. However, cultural practices and certain behaviours from nature are not normally made explicit and their dynamics still need to be understood. Thus, our research idea is to bring such practices to life by allowing the user to enact them. This means that user may re-live a step-by-step process to understand a practice, behaviour or event. Our solution is to enable the user to enact using gesture-based interaction with sensor-based technologies such as the versatile Kinect. This allows easier and natural ways to interact in multidimensional spaces such as museum exhibits. We use heuristic approaches and semantic models to interpret human gestures that are captured from the user's skeletal representation. We present and evaluate three applications. For each of the three applications, we integrate these interaction metaphors with gaming elements, thereby achieving a gesture-set to enact a cultural practice, behaviour or event. User evaluation experiments revealed that our approach achieved easy and natural interaction with an overall enhanced learning experience.
C1 [Adolfo Navarro-Newball, Andres; Contreras, Victoria E.; Quiceno, Victor A.; Lozano, Santiago; David Mejia, Juan; Fernando Loaiza, Diego] Pontificia Univ Javeriana PUJC, Cali, Colombia.
   [Moreno, Isidro] Univ Complutense Madrid, Informat Sci Fac, Madrid, Spain.
   [Prakash, Edmond] Univ Bourhemouth, Comp Games Technol, Poole, Dorset, England.
   [Arya, Ali] Carleton Univ, Sch Informat Technol, Ottawa, ON, Canada.
   [Arya, Ali] Carleton Univ, Interact Multimedia, Ottawa, ON, Canada.
C3 Complutense University of Madrid; Carleton University; Carleton
   University
RP Navarro-Newball, AA (corresponding author), Pontificia Univ Javeriana PUJC, Cali, Colombia.
EM anavarro@javerianacali.edu.co
RI Loaiza, Diego/ABA-2582-2021; Sánchez, Isidro Moreno/K-7502-2014; Loaiza
   Buitrago, Diego Fernando/AIA-3998-2022
OI Sánchez, Isidro Moreno/0000-0001-5820-8523; Loaiza Buitrago, Diego
   Fernando/0000-0002-5569-3102
FU Ministerio de Economa y Competitividad, Spain [HAR2011-25953]; Ministry
   of economy and competitiveness; Ministry of education, culture and
   sport; Museo de America, Madrid; Fundacion ITMA, Museo Convento Santo
   Domingo-Qorikancha, Cusco, Optimedia, Schwann Beijing; Telefonica ICT
FX Archaeological museum La Merced, Cali - Colombia. Natural Sciences
   Museum, Cali - Colombia. Museo de America, Madrid. This project is part
   of the I+D+i research "augmented knowledge and accessibility:
   Musegraphic representation of complex cultural content" (reference:
   HAR2011-25953. Ministerio de Economa y Competitividad, Spain) from the
   research group Museum I+D+C (Universidad Complutense, Madrid). Digital
   culture and hypermedia museology laboratory, with the collaboration of
   the project MOMU (interactive model for museums - DESTINO research
   group, Pontificia Universidad Javeriana, Cali), financed by the Ministry
   of economy and competitiveness and by the Ministry of education, culture
   and sport, and supported by the Museo de America, Madrid, Fundacion
   ITMA, Museo Convento Santo Domingo-Qorikancha, Cusco, Optimedia, Schwann
   Beijing, Telefonica ICT and the performing arts group El Tinglao that
   integrates people with functional diversity.
CR [Anonymous], 2013, P 12 ACM SIGGRAPHEUR, DOI DOI 10.1145/2485895.2485903
   [Anonymous], 2014, P 2 ACM S SPAT US IN
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], APPL MECH MAT
   Bulling A, 2014, ACM COMPUT SURV, V46, DOI 10.1145/2499621
   Contreras VE, 2014, ARTECNOLOGA AUGMENTE, P241
   Ibañez R, 2014, ADV ENG SOFTW, V76, P171, DOI 10.1016/j.advengsoft.2014.07.005
   Kamal A, 2014, P ACM C INT US INT, P73
   LaViola JJ, 2011, ACM SIGGRAPH 2011 CO, DOI 10.1145/2037636.2037637
   Li JJ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P57, DOI 10.1145/2647868.2654911
   Microsoft Corporation, 2013, KIN WIND HUM INT GUI
   Navarro A. A., 2014, ARTECNOLOGIA CONOCIM, P196
   Navarro-Newball AA, 2014, ENTERTAIN COMPUT, V5, P401, DOI 10.1016/j.entcom.2014.10.005
   Pietroni E, 2014, ACM J COMPUT CULT HE, V7, DOI 10.1145/2611375
   Rosner D, 2014, COMMUN ACM, V57, P82, DOI 10.1145/2602695.2602701
   Ruta M, 2014, IEEE INT C SEMANT CO, P15, DOI 10.1109/ICSC.2014.28
   Sanchez IM, 2013, COMUNICACIN CULTURAL, V18, P541
   Topsom M., 2008, P CYB 2008 BEIJ CHIN, P39
   Virtualware, 2012, MUS CTR INT ARM VUEL
   Virtualware, 2012, VUEL VIRT CINC VILL
   Xiao Y., 2013, Proceedings of the VRST '13 19th ACM Symposium on Virtual Reality Software and Technology, P133, DOI DOI 10.1145/2503713.2503727
   Zhao X, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2648583
NR 22
TC 8
Z9 8
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11699
EP 11722
DI 10.1007/s11042-015-2667-5
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200007
DA 2024-07-18
ER

PT J
AU Herranz, L
   Jiang, SQ
AF Herranz, Luis
   Jiang, Shuqiang
TI Scalable storyboards in handheld devices: applications and evaluation
   metrics
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable storyboards; Video browsing; Usability; Quality metrics
ID VIDEO ABSTRACTION; ADAPTATION; FRAMEWORK; SUMMARIES; RETRIEVAL;
   ALGORITHM
AB Summaries are an essential component of video retrieval and browsing systems. Most research in video summarization has focused on content analysis to obtain compact yet comprehensive representations of video items. However, important aspects such as how they can be effectively integrated in mobile interfaces and how to predict the quality and usability of the summaries have not been investigated. Conventional summaries are limited to a single instance with certain length (i.e. a single scale). In contrast, scalable summaries target representations with multiple scales, that is, a set of summaries with increasing length in which longer summaries include more information about the video. Thus, scalability provides high flexibility that can be exploited in devices such as smartphones or tablets to provide versions of the summary adapted to the limited visualization area. In this paper, we explore the application of scalable storyboards to summary adaptation and zoomable video navigation in handheld devices. By introducing a new adaptation dimension related with the summarization scale, we can formulate navigation and adaptation in a two-dimensional adaptation space, where different navigation actions modify the trajectory in that space. We also describe the challenges to evaluate scalable summaries and some usability issues that arise from having multiple scales, proposing some objective metrics that can provide useful insight about their potential quality and usability without requiring very costly user studies. Experimental results show a reasonable agreement with the trends shown in subjective evaluations. Experiments also show that content-based scalable storyboards are less redundant and useful than the content-blind baselines.
C1 [Herranz, Luis; Jiang, Shuqiang] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Herranz, L (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM luis.herranz@vipl.ict.ac.cn; sqjiang@ict.ac.cn
RI Herranz, Luis/B-4573-2016
OI Herranz, Luis/0000-0002-7022-3395
FU National Basic Research Program of China (973 Program) [2012CB316400];
   National Natural Science Foundation of China [61322212, 61035001,
   61350110237]; National Hi-Tech Development Program (863 Program) of
   China [2014AA015202]; Chinese Academy of Sciences Fellowships for Young
   International Scientists [2011Y1GB05]; Lenovo Outstanding Young
   Scientists Program (LOYS)
FX This work was supported in part by the National Basic Research Program
   of China (973 Program): 2012CB316400, in part by the National Natural
   Science Foundation of China: 61322212, 61035001 and 61350110237, in part
   by the National Hi-Tech Development Program (863 Program) of China:
   2014AA015202, and in part by the Chinese Academy of Sciences Fellowships
   for Young International Scientists: 2011Y1GB05. This work was also
   funded by Lenovo Outstanding Young Scientists Program (LOYS).
CR Adami N, 2007, IEEE T CIRC SYST VID, V17, P1238, DOI 10.1109/TCSVT.2007.906828
   Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   Albanese M, 2006, INFORM SYST, V31, P679, DOI 10.1016/j.is.2005.12.003
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P 1 INT C INT MULT C
   [Anonymous], INT J DIGIT MULTIMED
   [Anonymous], TRECVID
   [Anonymous], P INT C MOB UB MULT
   Benini S, 2006, IEEE IMAGE PROC, P133, DOI 10.1109/ICIP.2006.312377
   Bescós J, 2007, SIGNAL PROCESS-IMAGE, V22, P651, DOI 10.1016/j.image.2007.05.009
   Chang SF, 2005, P IEEE, V93, P148, DOI 10.1109/JPROC.2004.839600
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Dong P, 2015, MULTIMED TOOLS APPL, V74, P9449, DOI 10.1007/s11042-014-2126-8
   Dumont E, 2010, MULTIMED TOOLS APPL, V48, P51, DOI 10.1007/s11042-009-0374-9
   Friedland G, 2013, MULTIMED TOOLS APPL, V63, P387, DOI 10.1007/s11042-011-0877-z
   Gong YH, 2000, PROC CVPR IEEE, P174, DOI 10.1109/CVPR.2000.854772
   Haesen M, 2013, MULTIMED TOOLS APPL, V63, P331, DOI 10.1007/s11042-011-0809-y
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P1280, DOI 10.1109/76.809162
   Herranz L, 2012, IEEE T MULTIMEDIA, V14, P1290, DOI 10.1109/TMM.2012.2192917
   Herranz L, 2010, IEEE T CIRC SYST VID, V20, P1265, DOI 10.1109/TCSVT.2010.2057020
   Herranz L, 2009, SIGNAL PROCESS-IMAGE, V24, P499, DOI 10.1016/j.image.2009.02.010
   Herranz L, 2008, IEEE IMAGE PROC, P2544, DOI 10.1109/ICIP.2008.4712312
   Irie G., 2010, P 18 ACM INT C MULTI, P839
   Li YS, 2010, PROCEEDINGS OF THE ASME PRESSURE VESSELS AND PIPING CONFERENCE 2010, VOL 1: CODES AND STANDARDS, P851, DOI 10.1145/1873951.1874095
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Liu HP, 2016, MULTIMED TOOLS APPL, V75, P2031, DOI 10.1007/s11042-014-2390-7
   Marchionini G, 2006, J AM SOC INF SCI TEC, V57, P1629, DOI 10.1002/asi.20336
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   Mukherjee D, 2005, IEEE T CIRC SYST VID, V15, P1280, DOI 10.1109/TCSVT.2005.854220
   Mundur P, 2006, INT J DIGIT LIBRARIE, V6, P219, DOI 10.1007/s00799-005-0129-9
   Ohm JR, 2005, P IEEE, V93, P42, DOI 10.1109/JPROC.2004.839611
   Over P., 2008, Proc. of the 2nd ACM TRECVid Video Summarization Workshop, P1, DOI [DOI 10.1145/1463563.1463564, 10.1145/1463563.1463564]
   Santini S, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P177, DOI 10.1109/ICSC.2007.96
   Scherp A, 2014, MULTIMED TOOLS APPL, V70, P7, DOI 10.1007/s11042-013-1427-7
   Schoeffmann K, 2014, IEEE MULTIMEDIA, V21, P8, DOI 10.1109/MMUL.2014.56
   Schoeffmann K, 2014, IEEE T MULTIMEDIA, V16, P1942, DOI 10.1109/TMM.2014.2333666
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   SIBSON R, 1973, COMPUT J, V16, P30, DOI 10.1093/comjnl/16.1.30
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Valdes V, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2240136.2240138
   Vetro A, 2004, IEEE MULTIMEDIA, V11, P84, DOI 10.1109/MMUL.2004.1261111
   Xin J, 2005, P IEEE, V93, P84, DOI 10.1109/JPROC.2004.839620
   Yang Y, 2013, IEEE I CONF COMP VIS, P2104, DOI 10.1109/ICCV.2013.456
   Yuan Z, 2011, P 10 INT C MOB UB MU, P109
   Zhang LM, 2014, IEEE T CYBERNETICS, V44, P1408, DOI 10.1109/TCYB.2013.2285219
   Zhao S., 2013, INT C MULT MOD MMM 2, P7732, DOI DOI 10.1007/978-3-642-35725-1_34
   Zhao SC, 2013, NEUROCOMPUTING, V119, P101, DOI 10.1016/j.neucom.2012.04.042
   Zhu XQ, 2004, MULTIMEDIA SYST, V10, P98, DOI 10.1007/s00530-004-0142-7
   Zhu XQ, 2003, MULTIMEDIA SYST, V9, P31, DOI 10.1007/s00530-003-0076-5
   Zhuang YT, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P866, DOI 10.1109/ICIP.1998.723655
NR 51
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 20
BP 12597
EP 12625
DI 10.1007/s11042-014-2421-4
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV5UD
UT WOS:000382994700018
DA 2024-07-18
ER

PT J
AU Matiolanski, A
   Maksimova, A
   Dziech, A
AF Matiolanski, Andrzej
   Maksimova, Aleksandra
   Dziech, Andrzej
TI CCTV object detection with fuzzy classification and image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pattern recognition; Fuzzy classifier; Fuzzy inference; Data analysis;
   Knife detection; Feature descriptor; Image enhancement
AB In this paper we propose a novel approach for pattern recognition problems with non-uniform classes of images. The main concept of this classification method is to describe classes of images with their fuzzy portraits. This approach is a good generalization of the algorithm. The fuzzy set is calculated as a preliminary result of the algorithm before the final decision or rejection that solves the problem of uncertainty at the boundaries of classes. We use the method to solve the problem of knife detection in still images. The main aim of this paper is to test fuzzy classification with feature vectors in a real environment. We used selected MPEG-7 descriptor schemes as feature vectors. The method was experimentally validated on a dataset of over 12,000 images. The article describes the results of six experiments which confirm the accuracy of our method. In addition we conducted a test with enhanced images, achieved with two state-of-the-art super-resolution algorithms.
C1 [Matiolanski, Andrzej; Dziech, Andrzej] AGH Univ Sci & Technol, Dept Telecommun, Krakow, Poland.
   [Maksimova, Aleksandra] Natl Acad Sci Ukraine, Inst Appl Math & Mech, Donetsk, Ukraine.
C3 AGH University of Krakow; National Academy of Sciences Ukraine;
   Institute of Applied Mathematics & Mechanics of the NAS of Ukraine
RP Matiolanski, A (corresponding author), AGH Univ Sci & Technol, Dept Telecommun, Krakow, Poland.
EM matiolanski@kt.agh.edu.pl; maximova.alexandra@mail.ru;
   dziech@kt.agh.edu.pl
RI Matiolanski, Andrzej/B-9649-2015
FU European Regional Development Fund under the Innovative Economy
   Operational Programme, INSIGMA project [POIG.01.01.02-00-062/09]
FX This research has been financed by the European Regional Development
   Fund under the Innovative Economy Operational Programme, INSIGMA project
   No. POIG.01.01.02-00-062/09.
CR [Anonymous], 2005, ADV INFO PROC
   Baran R, 2015, MULTIMED TOOLS APPL, V74, P4269, DOI 10.1007/s11042-013-1545-2
   Bezdek JC, 2005, FUZZY MODELS AND ALG
   Chen N, 2004, LECT NOTES ARTIF INT, V3327, P41
   Glowacz A., 2013, MULTIMEDIA TOOLS APP
   Hung KW, 2012, INT CONF ACOUST SPEE, P1269, DOI 10.1109/ICASSP.2012.6288120
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Kmiec Marcin, 2011, Machine Graphics & Vision, V20, P215
   Kmiec M, 2012, COMM COM INF SC, V287, P148
   Konor A., 2005, COMPUTATIONAL INTELL
   Kuncheva L.I., 2005, FUZZY CLASSIFIER DES
   Maksimova A., 1995, INT J COMPUTING, p[11, 17]
   Maksimova A., 2013, ARTIF INTELL, V3, P171
   Maksimova A, 2013, P 6 INT C MULT COMM, P143
   Mery D, 2013, IEEE COMPUT SOC CONF, P368, DOI 10.1109/CVPRW.2013.62
   PAL NR, 1995, IEEE T FUZZY SYST, V3, P370, DOI 10.1109/91.413225
   Ro YM, 2001, ETRI J, V23, P41, DOI 10.4218/etrij.01.0101.0201
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
   Yu M.A., 2011, P 11 INT C PATT REC, P54
   Zywicki M., 2011, P 11 INT C PATT REC, P139
NR 20
TC 8
Z9 8
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10513
EP 10528
DI 10.1007/s11042-015-2697-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800020
OA hybrid
DA 2024-07-18
ER

PT J
AU Szczodrak, M
   Czyzewski, A
AF Szczodrak, Maciej
   Czyzewski, Andrzej
TI Video analytics-based algorithm for monitoring egress from buildings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd; Crowd behavior; Egress monitoring
AB A concept and a practical implementation of the algorithm for detecting of potentially dangerous situations related to crowding in passages is presented. An example of such a situation is a crush which may be caused by an obstructed pedestrian pathway. The surveillance video camera signal analysis performed in the online mode is employed in order to detect hold-ups near bottlenecks like doorways or staircases. The details of the implemented algorithm which uses the optical flow method combined with fuzzy logic are explained. The experiments were carried out on a set of gathered video recordings from the surveillance camera installed in the campus of Gdansk University of Technology. The results of experiments performed on gathered video recordings shows high efficiency of the algorithm.
C1 [Szczodrak, Maciej; Czyzewski, Andrzej] Gdansk Univ Technol, Fac Elect Telecommun & Informat, Multimedia Syst Dept, Narutowicza 11-12, PL-80233 Gdansk, Poland.
C3 Fahrenheit Universities; Gdansk University of Technology
RP Szczodrak, M (corresponding author), Gdansk Univ Technol, Fac Elect Telecommun & Informat, Multimedia Syst Dept, Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM szczodry@sound.eti.pg.gda.pl; andcz@multimed.org
RI Czyzewski, Andrzej/JXN-0946-2024
OI Czyzewski, Andrzej/0000-0001-9159-8658
CR [Anonymous], 1992, An Introduction to Multigrid Methods
   [Anonymous], 2001, P 2 EUR WORKSH ADV V
   Baker S., 2007, P IEEE 11 INT C COMP, P1
   Briggs William, 2000, A Multigrid Tutorial, Vsecond
   Bruhn A., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P454
   DALKA P, 2010, VIDEO CONTENT ANAL U, P241, DOI DOI 10.1007/978-3-642-13396-1_11
   Dalka P, 2012, COMM COM INF SC, V287, P58
   Hammami M, 2013, MULTIMED TOOLS APPL, V63, P899, DOI 10.1007/s11042-011-0935-6
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jia Hong Yin, 1996, Recent Developments in Computer Vision. Second Asian Conference on Computer Vision, ACCV '95. Invited Session Papers, P489
   Kopaczewski K, 2015, MULTIMED TOOLS APPL, V74, P4289, DOI 10.1007/s11042-013-1628-0
   Kosko B., 1997, FUZZY ENG
   Kotus J, 2014, MULTIMED TOOLS APPL, V68, P5, DOI 10.1007/s11042-012-1183-0
   Krausz B, 2010, MULTIMED TOOLS APPL, V50, P123, DOI 10.1007/s11042-009-0367-8
   Krawczyk H, 2010, SIGMAP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND MULTIMEDIA APPLICATION, P26
   Liu X, 2009, PHYSICA A, V388, P2717, DOI 10.1016/j.physa.2009.03.017
   Lo BPL, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P158, DOI 10.1109/ISIMP.2001.925356
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Marana A, 1983, SAFETY SCI, V28, P165
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   POLUS A, 1983, J TRANSP ENG-ASCE, V109, P46, DOI 10.1061/(ASCE)0733-947X(1983)109:1(46)
   Saxena S, 2008, LECT NOTES COMPUT SC, V5259, P970, DOI 10.1007/978-3-540-88458-3_88
   Seyfried A, 2005, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2005/10/P10002
   Szwoch G, 2012, COMM COM INF SC, V287, P340
   Taylor Peter., 1989, The Hillsborough Stadium disaster: 15 April 1989: inquiry by Lord Justice Taylor : interim report : presented to Parliament by the Secretary of State for the Home Department by command of Her Majesty, August 1989
   Wagner U, 2013, ANAESTHESIST, V62, P39, DOI 10.1007/s00101-012-2124-z
   ZADEH LA, 1994, COMMUN ACM, V37, P77, DOI 10.1145/175247.175255
NR 28
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10733
EP 10743
DI 10.1007/s11042-014-2143-7
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800031
OA hybrid
DA 2024-07-18
ER

PT J
AU Chen, CY
   Hsia, CH
   Yang, CY
AF Chen, Ching-Yi
   Hsia, Chin-Hsien
   Yang, Chun-Yuan
TI Evolutionary design of multiplierless lifting-based 2D DWT filters for
   low-resolution image processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Real-time processing; Discrete Wavelet Transform; Low-resolution;
   Particle Swarm Optimization
ID LOW-COMPLEXITY; TRACKING; IDENTIFICATION; ARCHITECTURE; ALGORITHM;
   SCHEME; SYSTEM
AB The most difficult challenge in developing a high-efficiency embedded image processing system relates to how to execute complicated Digital Signal Processing (DSP) algorithm with embedded processor, especially when processing high-resolution images. A whole system may start to run very slowly because of the large volumes of data being processed and the complexity of the algorithm, rendering it unable to achieve real-time processing. Executing motion detection in low-resolution image was already proved to be able to reduce the loading of data manipulation and to be able to help filter out noise and fake motion. However, smoothing filter pointed out in the work will affect the quality of image. Although the LL-band signal of a 2D Discrete Wavelet Transform (DWT) domain can retain the main part of the energy and information of the original image, a complex algorithm is more suitable for the application of a low-pass filter. Symmetric Mask-based DWT (SMDWT) has the advantage of reduced complexity, regular signal coding, and independent subband coding processing. In this paper, we use a Particle Swarm Optimization (PSO) approach to automatically evolve the multiplierless 2D SMDWT filters hardware architecture. The architecture employs only shift-and-addition operations to replace the complex floating-point multiplication and division operations. It can use shift-and-add based SMDWT filter to decompose a low-resolution image and do real-time image processing system design with low-resolution image processing technique.
C1 [Chen, Ching-Yi; Yang, Chun-Yuan] Ming Chuan Univ, Dept Informat & Telecommun Engn, Taoyuan, Taiwan.
   [Hsia, Chin-Hsien] Chinese Culture Univ, Dept Elect Engn, Taipei, Taiwan.
C3 Ming Chuan University; Chinese Culture University
RP Chen, CY (corresponding author), Ming Chuan Univ, Dept Informat & Telecommun Engn, Taoyuan, Taiwan.
EM chingyi@mail.mcu.edu.tw; chhsia625@gmail.com
OI Hsia, Chih-Hsien/0000-0003-2665-0821
FU Ministry of Science and Technology of Taiwan, R.O.C. [NSC 102-2221-E-130
   -021, MOST-103-2221-E-034-010]
FX The authors would like to thank the anonymous reviewers of their paper
   for the many helpful suggestions. This work was supported by the
   Ministry of Science and Technology of Taiwan, R.O.C. under grant number
   NSC 102-2221-E-130 -021 and MOST-103-2221-E-034-010.
CR [Anonymous], 1996, Theory of self-reproducing automata
   Chen CY, 2013, J APPL SCI ENG, V16, P249, DOI 10.6180/jase.2013.16.3.04
   Cheng FH, 2006, PATTERN RECOGN, V39, P1126, DOI 10.1016/j.patcog.2005.12.010
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   de Garis H., 1993, Artificial Neural Nets and Genetic Algorithms. Proceedings of the International Conference, P441
   Dugad R, 2001, IEEE T CIRC SYST VID, V11, P461, DOI 10.1109/76.915353
   Gustafsson O, 2010, IEEE SIGNAL PROC LET, V17, P173, DOI 10.1109/LSP.2009.2036384
   Heikkilä J, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P74, DOI 10.1109/VS.1999.780271
   Higuchi T, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P187, DOI 10.1109/ICEC.1997.592293
   Hong JH, 2009, IEEE T SYST MAN CY B, V39, P1446, DOI 10.1109/TSMCB.2009.2018292
   Hsia CH, 2014, J INTERNET TECHNOL, V15, P1083, DOI 10.6138/JIT.2014.15.7.01
   Hsia CH, 2013, IEEE T CIRC SYST VID, V23, P671, DOI 10.1109/TCSVT.2012.2211953
   Hsia CH, 2012, SIGNAL PROCESS, V92, P89, DOI 10.1016/j.sigpro.2011.06.009
   Hsia CH, 2009, IEEE T CIRC SYST VID, V19, P1202, DOI 10.1109/TCSVT.2009.2020259
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Koza J. R., 1997, IEEE Transactions on Evolutionary Computation, V1, P109, DOI 10.1109/4235.687879
   Kumar RC, 2009, EUR J SCI RES, V36, P473
   Paschalakis S, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P214, DOI 10.1109/FPT.2003.1275750
   ROBOTIS Inc, 2010, DARWIN OP E MAN V1 2
   SIPPER M, 1999, IEEE T EVOLUTIONARY, V3
   Sugandi B, 2009, INT J INNOV COMPUT I, V5, P1179
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Teng HC, 2006, THESIS
   Thompson A, 1998, LECT NOTES COMPUT SC, V1478, P13, DOI 10.1007/BFb0057603
   Thompson A, 1997, LECT NOTES COMPUT SC, V1259, P390
   Vasicek Zdenek, 2007, International Journal of Innovative Computing and Applications, V1, P63, DOI 10.1504/IJICA.2007.013402
   Vasicek Z, 2010, DES AUT TEST EUROPE, P1731
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HC, 2008, THESIS
   Wilscy M., 2011, SIGNAL IMAGE PROCESS, V2, P173
NR 30
TC 4
Z9 4
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9949
EP 9972
DI 10.1007/s11042-015-2776-1
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500024
DA 2024-07-18
ER

PT J
AU Ding, IJ
   Chang, CW
AF Ding, Ing-Jr
   Chang, Che-Wei
TI Feature design scheme for Kinect-based DTW human gesture recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect camera; Human gesture recognition; Gesture feature; DTW;
   Recognition performance
AB Feature selection is a crucial factor in Kinect-based pattern recognition, including common human gesture recognition. For Kinect-based human gesture recognition, the information contained in the feature extracted for gesture recognition is conventionally the (x,y,z) coordinates of the primary joints in the human body. However, such traditionally used feature information containing only joint positions is apparently insufficient for clearly describing the characteristics of human activity patterns. This paper proposes a feature design scheme involving hybridizations of joint positions and joint angles for human gesture recognition with the Kinect camera. The presented feature design method effectively hybridizes the 20 main human joint positions captured by the Kinect camera and the joint angle information of 12 critical joints, along with significant angle variations when a gesture is made. The method is employed in dynamic time warping (DTW) gesture recognition. When the proposed feature design method is used for Kinect-based DTW human gesture recognition, it derives an appropriately sized feature vector for each of the gesture categories in the DTW-referenced template database according to the activity characteristics of a certain category of gestures. Experiments on Kinect-based DTW gesture recognition involving 14 common categories of human gestures show that the feature determined using the proposed approach is superior to that obtained using the conventional approach, which considers only the joint position information.
C1 [Ding, Ing-Jr; Chang, Che-Wei] Natl Formosa Univ, Dept Elect Engn, Huwei Township, Yunlin, Taiwan.
C3 National Formosa University
RP Ding, IJ (corresponding author), Natl Formosa Univ, Dept Elect Engn, Huwei Township, Yunlin, Taiwan.
EM ingjr@nfu.edu.tw
FU Ministry of Science and Technology (MOST) in Taiwan under Grant MOST
   [103-2221-E-150-046]
FX This research is partially supported by the Ministry of Science and
   Technology (MOST) in Taiwan under Grant MOST 103-2221-E-150-046.
CR [Anonymous], INT J ADV ROBOT SYST
   Bautista MA, 2013, LECT NOTES COMPUT SC, V7854, P126
   Carmona Josep Maria, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P236, DOI 10.1007/978-3-642-33275-3_29
   Ding IJ, 2016, MULTIMED TOOLS APPL, V75, P15537, DOI 10.1007/s11042-015-2505-9
   Ding IJ, 2015, APPL MATH MODEL, V39, P5769, DOI 10.1016/j.apm.2014.12.054
   Ding IJ, 2015, MULTIMED TOOLS APPL, V74, P5131, DOI 10.1007/s11042-013-1587-5
   Ding IJ, 2013, J INTELL FUZZY SYST, V25, P49, DOI 10.3233/IFS-2012-0613
   Han J., 2013, IEEE T CYBERNETICS, V43, P2168
   Lee E.J., 2012, INT J MULTIMEDIA UBI, V7, P335
   Lichao Zhang, 2012, Proceedings of the 2012 International Conference on Computer Science and Information Processing (CSIP), P1163, DOI 10.1109/CSIP.2012.6309065
   Qian K., 2013, Int. J. of Smart Home, V7, P203
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Su C., 2012, Proceedings of the Asia Pacific Industrial Engineering Management Systems Conference, P884
   Su Chuan-Jun, 2013, International Journal of Information and Education Technology, V3, P448, DOI DOI 10.7763/IJIET.2013.V3.316
   Tashev I, 2013, IEEE SIGNAL PROC MAG, V30, P129, DOI 10.1109/MSP.2013.2266959
   Wu J, 2013, INT CONF ACOUST SPEE, P2371, DOI 10.1109/ICASSP.2013.6638079
   Zhang X, 2013, IEEE MULTIMEDIA, V20, P85, DOI 10.1109/MMUL.2013.50
NR 17
TC 15
Z9 16
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 9669
EP 9684
DI 10.1007/s11042-015-2782-3
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500010
DA 2024-07-18
ER

PT J
AU Zhu, SH
   Shi, Z
   Sun, CJ
AF Zhu, Songhao
   Shi, Zhe
   Sun, Chengjian
TI Tracklet association based multi-target tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tracklet association; Scene self-adaptive model; Incremental linear
   discriminant appearance model; Non-linear motion model
ID MULTIOBJECT TRACKING; MULTIPLE
AB This paper proposes a novel multi-target tracking framework, where two different association strategies are utilized to obtain local and global tracking trajectories. Specifically, a scene self-adaptive model is first utilized to generate local trajectories by constructing the association between detection responses and tracking tracklets; then, a novel incremental linear discriminative appearance model is utilized to generate global trajectories by constructing the association between local trajectories; finally, a non-linear motion model is utilized to fill the vacancies between global trajectories to obtain continuous and smooth tracking trajectories. Experimental results conducted on PETS2009/2010, TUD-Stadtmitte, and Town Center video libraries demonstrate the proposed framework can achieve continuous and smooth tracking trajectories under the case of significant deformation, appearance change, similar appearance, motion direction change, and long-time occlusion.
C1 [Zhu, Songhao; Shi, Zhe; Sun, Chengjian] Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210046, Jiangsu, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Zhu, SH (corresponding author), Nanjing Univ Posts & Telecommun, Sch Automat, Nanjing 210046, Jiangsu, Peoples R China.
EM zhush@njupt.edu.cn
FU Postdoctoral Foundation of China [2014 M550297]; Postdoctoral Foundation
   of Jiangsu Province [1302087B]; Graduate Education Reform Research and
   Practice Program of Jiangsu Province [JGZZ13_041, JGLX15_055]; Graduate
   Research and Innovation Program of Jiangsu [KYLX15_0854, SJZZ15_0105]
FX This work is supported by Postdoctoral Foundation of China under No.
   2014 M550297, Postdoctoral Foundation of Jiangsu Province under No.
   1302087B, Graduate Education Reform Research and Practice Program of
   Jiangsu Province under No. JGZZ13_041 and JGLX15_055, Graduate Research
   and Innovation Program of Jiangsu under No. KYLX15_0854 and No.
   SJZZ15_0105.
CR Andriyenko A, 2012, PROC CVPR IEEE, P1926, DOI 10.1109/CVPR.2012.6247893
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Avidan S, 2005, PROC CVPR IEEE, P494
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Benfold B., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3457, DOI 10.1109/CVPR.2011.5995667
   Boccignone G, 2010, IEEE SIGNAL PROC LET, V17, P129, DOI 10.1109/LSP.2009.2030862
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Chang X, 2015, ACM MULTIMED, P1
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Craciun P, 2015, IEEE WINT CONF APPL, P177, DOI 10.1109/WACV.2015.31
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Henriques JF, 2011, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2011.6126532
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kratz L, 2010, PROC CVPR IEEE, P693, DOI 10.1109/CVPR.2010.5540149
   Kuo CH, 2010, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2010.5540148
   Magee DR, 2004, IMAGE VISION COMPUT, V22, P143, DOI 10.1016/S0262-8856(03)00145-8
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44
   Song XA, 2010, PROC CVPR IEEE, P739, DOI 10.1109/CVPR.2010.5540143
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xing JL, 2011, IEEE T IMAGE PROCESS, V20, P1652, DOI 10.1109/TIP.2010.2102045
   Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yang B, 2012, PROC CVPR IEEE, P1918, DOI 10.1109/CVPR.2012.6247892
   Yeh YJ, 2009, IEEE T CIRC SYST VID, V19, P442, DOI 10.1109/TCSVT.2009.2013520
   Yu SI, 2013, PROC CVPR IEEE, P3714, DOI 10.1109/CVPR.2013.476
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhang LJ, 2008, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD006286.pub2
NR 35
TC 2
Z9 2
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9489
EP 9506
DI 10.1007/s11042-015-3238-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500035
DA 2024-07-18
ER

PT J
AU Jeng, FG
   Wu, YT
   Chen, TH
AF Jeng, Fuh-Gwo
   Wu, Yan-Ting
   Chen, Tzung-Her
TI A multi-watermarking protocol for health information management
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking protocol; Health informationmanagement; Multi-watermarking
ID PROTECTION; EFFICIENT; PRIVACY
AB Buyer-seller watermarking protocols, combining digital watermarking and cryptographic tools, have become a feasible technique to guarantee piracy tracing. For securing health information management, watermarking protocols may be introduced to solve the problem of traitor tracing, i.e., tracing the physician who illegally discloses the patient's health information. As a physician asks the health information system (HIS) for the intended patient's health information, the relationship between the physician and HIS is similar to that between buyer and seller. By watermarking protocol, it can prevent physician from illegally distributing the patient's health information over telemedicine environments in case remote physician and local physician exchange the patient's health information and diagnosis views. While unauthorized health information is found, HIS can trace and accuse some physician who illegally releases the sensitive patient's health information. However, buyer-seller protocols mentioned above cannot be applied to telemedicine systems directly because there is more than one physician involved. This paper proposes a multi-watermarking protocol to solve this problem, in which a well-defined single watermarking protocol is extended to form a novel multi-watermarking protocol. In addition, the proposed protocol adopts symmetric cryptosystem into watermark embedding so that the computation cost is lower than the protocols based on public key operation.
C1 [Jeng, Fuh-Gwo] Natl Chiayi Univ, Dept Appl Math, Chiayi, Taiwan.
   [Wu, Yan-Ting; Chen, Tzung-Her] Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
C3 National Chiayi University; National Chiayi University
RP Chen, TH (corresponding author), Natl Chiayi Univ, Dept Comp Sci & Informat Engn, Chiayi 60004, Taiwan.
EM thchen@mail.ncyu.edu.tw
RI Wu, Yanting/IUN-0484-2023
OI Wu, Yanting/0000-0003-1386-3422; Chen, Tzung-Her/0000-0001-5775-6034
FU National Science Council, Taiwan, R.O.C. [NSC 102-2221-E-415-014, NSC
   102-2221-E-415-007]
FX This work was partially supported National Science Council, Taiwan,
   R.O.C., under contract by NSC 102-2221-E-415-014 and NSC
   102-2221-E-415-007.
CR Adelsbach A, 2006, LECT NOTES COMPUT SC, V4058, P136
   Celik MU, 2007, INT CONF ACOUST SPEE, P153
   Chen TH, 2005, J CHIN INST ENG, V28, P535, DOI 10.1080/02533839.2005.9671019
   Cheung SC, 2002, P INT COMP SOFTW APP, P105, DOI 10.1109/CMPSAC.2002.1044539
   Das Vinu V., 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P807, DOI 10.1109/ICETET.2008.61
   Deng M, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTERNET AND WEB APPLICATIONS AND SERVICES (ICIW 2008), P524, DOI 10.1109/ICIW.2008.28
   Gritzalis S, 2005, IEEE T INF TECHNOL B, V9, P413, DOI 10.1109/TITB.2005.847498
   Ibrahim Ibrahim M., 2007, 2007 3rd International Symposium on Information Assurance and Security, P21
   Katzenbeisser S, 2008, IEEE T INF FOREN SEC, V3, P783, DOI 10.1109/TIFS.2008.2002939
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Lei CL, 2004, IEEE T IMAGE PROCESS, V13, P1618, DOI 10.1109/TIP.2004.837553
   Lemma A, 2006, LECT NOTES COMPUT SC, V4283, P433
   Li MY, 2005, COMPUT MED IMAG GRAP, V29, P367, DOI 10.1016/j.compmedimag.2005.02.003
   Memon N, 2001, IEEE T IMAGE PROCESS, V10, P643, DOI 10.1109/83.913598
   Yong S, 2005, LECT NOTES COMPUT SC, V3710, P54
   Zhang J, 2006, IEE P INF SEC, V153
NR 16
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8123
EP 8135
DI 10.1007/s11042-015-2728-9
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300001
DA 2024-07-18
ER

PT J
AU Su, SZ
   Wu, SS
   Chen, SY
   Duh, DJ
   Li, SZ
AF Su, Songzhi
   Wu, Sin-Sian
   Chen, Shu-Yuan
   Duh, Der-Jyh
   Li, Shaozi
TI Multi-view fall detection based on spatio-temporal interest points
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; Impact shock; Spatio-temporal interest points; Human
   silhouette; Multiple-view; Foreground segmentation; Camera calibration
ID REAL-TIME; SYSTEM; VIDEO; ACCELEROMETER; MOTION; SENSOR; SOUND
AB Many countries are experiencing a rapid increase in their elderly populations, increasing the demand for appropriate healthcare systems including fall-detection systems. In recent years, many fall-detection systems have been developed, although most require the use of wearable devices. Such systems function only when the subject is wearing the device. A vision-based system presents a more convenient option. However, visual features typically depend on camera view; a single, fixed camera may not properly identify falls occurring in various directions. Thus, this study presents a solution that involves using multiple cameras. The study offers two main contributions. First, in contrast to most vision-based systems that analyze silhouettes to detect falls, the present system proposes a novel feature for measuring the degree of impact shock that is easily detectable with a wearable device but more difficult with a computer vision system. In addition, the degree of impact shock is less sensitive to camera views and can be extracted more robustly than a silhouette. Second, the proposed method uses a majority-voting strategy based on multiple views to avoid performing the tedious camera calibration required by most multiple-camera approaches. Specifically, the proposed method is based on spatio-temporal interest points (STIPs). The number of local STIP clusters is designed to indicate the degree of impact shock and body vibration. Sequences of these features are concatenated into feature vectors that are then fed into a support vector machine to classify the fall event. A majority-voting strategy based on multiple views is then used for the final determination. The proposed method has been applied to a publicly available dataset to offer evidence that the proposed method outperforms existing methods based on the same data input.
C1 [Su, Songzhi; Li, Shaozi] Xiamen Univ, Sch Informat Sci & Technol, Xiamen, Fujian, Peoples R China.
   [Su, Songzhi; Li, Shaozi] Xiamen Univ, Fujian Key Lab Brain Like Intelligent Syst, Xiamen, Fujian, Peoples R China.
   [Wu, Sin-Sian; Chen, Shu-Yuan] Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
   [Duh, Der-Jyh] Chien Hsin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 Xiamen University; Xiamen University; Yuan Ze University; Chien Hsin
   University of Science & Technology
RP Li, SZ (corresponding author), Xiamen Univ, Sch Informat Sci & Technol, Xiamen, Fujian, Peoples R China.; Li, SZ (corresponding author), Xiamen Univ, Fujian Key Lab Brain Like Intelligent Syst, Xiamen, Fujian, Peoples R China.; Chen, SY (corresponding author), Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan, Taiwan.
EM cschen@saturn.yzu.edu.tw; szlig@xmu.edu.cn
RI Li, SZ/G-3959-2010
FU National Science Council of Taiwan, Republic of China
   [NSC-103-2221-E-155-033-]; Nature Science Foundation of China
   [61202143]; Natural Science Foundation of Fujian Province [2013J05100]
FX The authors would like to thank E. Auvinet, C. Rougier, J. Meunier, A.
   St-Arnaud, and J. Rousseau for providing "Multiple cameras fall
   dataset," and anonymous reviewers for the valuable and insightful
   comments on the earlier version of this manuscript. This work was
   supported by the National Science Council of Taiwan, Republic of China
   (NSC-103-2221-E-155-033-), the Nature Science Foundation of China (No.
   61202143), and the Natural Science Foundation of Fujian Province (No.
   2013J05100).
CR Alpaydin E., 2010, Introduction to Machine Learning
   Alwan Majd., 2006, 2006 2 INT C INFORM, V1, P1003, DOI DOI 10.1109/ICTTA.2006.1684511
   Anderson D, 2009, COMPUT VIS IMAGE UND, V113, P80, DOI 10.1016/j.cviu.2008.07.006
   Auvinet E., 2010, Multiple cameras fall dataset
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Banerjee T, 2014, IEEE T FUZZY SYST, V22, P483, DOI 10.1109/TFUZZ.2013.2260756
   Belbachir AN, 2012, IEEE INT SYMP CIRC S, P731, DOI 10.1109/ISCAS.2012.6272141
   Bianchi F, 2010, IEEE T NEUR SYS REH, V18, P619, DOI 10.1109/TNSRE.2010.2070807
   Boissy P, 2007, TELEMED J E-HEALTH, V13, P683, DOI 10.1089/tmj.2007.0007
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dollar P., 2005, VISUAL SURVEILLANCE
   Doukas CN, 2011, IEEE T INF TECHNOL B, V15, P277, DOI 10.1109/TITB.2010.2091140
   Fleck S, 2008, P IEEE, V96, P1698, DOI 10.1109/JPROC.2008.928765
   Fleury A, 2010, IEEE T INF TECHNOL B, V14, P274, DOI 10.1109/TITB.2009.2037317
   Goutte C, 2005, LECT NOTES COMPUT SC, V3408, P345
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hawley-Hague H, 2014, INT J MED INFORM, V83, P416, DOI 10.1016/j.ijmedinf.2014.03.002
   Huang S, 2013, P IEEE INT C MACH VI, P439
   Karantonis DM, 2006, IEEE T INF TECHNOL B, V10, P156, DOI 10.1109/TITB.2005.856864
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lee T, 2005, J TELEMED TELECARE, V11, P194, DOI 10.1258/1357633054068946
   Lin CS, 2007, MEASUREMENT, V40, P831, DOI 10.1016/j.measurement.2007.04.001
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   Miaou SG, 2006, P INT C DISTR DIAGN
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Mubashir M, 2013, NEUROCOMPUTING, V100, P144, DOI 10.1016/j.neucom.2011.09.037
   Nait-Charif H, 2004, INT C PATT RECOG, P323, DOI 10.1109/ICPR.2004.1333768
   Noury N, 2007, P ANN INT IEEE EMBS, P1663, DOI 10.1109/IEMBS.2007.4352627
   Ozcan K, 2013, IEEE J EM SEL TOP C, V3, P125, DOI 10.1109/JETCAS.2013.2256832
   Qian H, 2008, P INT C CONTR AUT RO
   Rimminen H, 2010, IEEE T INF TECHNOL B, V14, P1475, DOI 10.1109/TITB.2010.2051956
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Scovanner Paul, 2007, ACM MULTIMEDIA
   Sixsmith A, 2004, IEEE PERVAS COMPUT, V3, P42, DOI 10.1109/MPRV.2004.1316817
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Thome N, 2008, IEEE T CIRC SYST VID, V18, P1522, DOI 10.1109/TCSVT.2008.2005606
   Toreyin BU, 2006, P IEEE SIGN PROC COM
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yu M, 2012, IET COMPUT VIS, V6, P90, DOI 10.1049/iet-cvi.2011.0046
   Yu X, 2008, P INT C E HLTH NETW
   Zhang T, 2006, INT J COMPUT SCI NET, V6, P277
   Zigel Y, 2009, IEEE T BIO-MED ENG, V56, P2858, DOI 10.1109/TBME.2009.2030171
NR 44
TC 12
Z9 12
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8469
EP 8492
DI 10.1007/s11042-015-2766-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300015
DA 2024-07-18
ER

PT J
AU Huang, GH
   Pun, CM
   Lin, C
   Zhou, YC
AF Huang, Guoheng
   Pun, Chi-Man
   Lin, Cong
   Zhou, Yicong
TI Non-rigid visual object tracking using user-defined marker and Gaussian
   kernel
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object tracking; Non-rigid; Superpixel; Interactive segmentation;
   Gaussian kernel
ID INTERACTIVE IMAGE SEGMENTATION
AB A novel non-rigid object tracking based on interactive user-define marker and superpixel Gaussian kernel is proposed in this paper. In the initialization stage, instead of using the traditional bounding box to locate the targeted object, we have employed an interactive segmentation with user-defined marker to segment the object accurately in the first frame of the input video to avoid the background influence in the traditional bounding box. During the tracking stage, by using a Gaussian kernel as movement constraint, each superpixel is tracked independently to locate the object in the next frame. Experimental results show that the proposed method compared to state of the art methods can achieve better robustness and accuracy for various challenging video clips.
C1 [Huang, Guoheng; Pun, Chi-Man; Lin, Cong; Zhou, Yicong] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Pun, CM (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM yb27405@umac.mo; cmpun@umac.mo; yb17403@umac.mo; yicongzhou@umac.mo
RI Zhou, Yicong/A-8017-2009; Pun, Chi Man/GRJ-3703-2022
OI Zhou, Yicong/0000-0002-4487-6384; Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG134-FST11-PCM,
   MYRG181-FST11-PCM]; Science and Technology Development Fund of Macau SAR
   [008/2013/A1]
FX The authors would like to thank the referees for their valuable comments
   and Dr. Regina Chan for her proof reading of the manuscript. This
   research was supported in part by Research Committee of the University
   of Macau (MYRG134-FST11-PCM, MYRG181-FST11-PCM) and the Science and
   Technology Development Fund of Macau SAR (Project No. 008/2013/A1).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Adam A, 2006, P IEEE C COMP VIS PA, P545
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Cehovin L, 2011, IEEE I CONF COMP VIS, P1363, DOI 10.1109/ICCV.2011.6126390
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Collins RT, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P346
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Han B, 2009, IEEE T PATTERN ANAL, V31, P919, DOI 10.1109/TPAMI.2008.134
   Han BY, 2005, IEEE I CONF COMP VIS, P1492
   Jepson AD, 2001, PROC CVPR IEEE, P415
   Jung C, 2014, PATTERN RECOGN, V47, P2745, DOI 10.1016/j.patcog.2014.02.010
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235
   Mazinan AH, 2013, INT J ADV MANUF TECH, V64, P1643, DOI 10.1007/s00170-012-4129-9
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Noma A, 2012, PATTERN RECOGN, V45, P1159, DOI 10.1016/j.patcog.2011.08.017
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Protiere A, 2007, IEEE T IMAGE PROCESS, V16, P1046, DOI 10.1109/TIP.2007.891796
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yang M, 2005, PROC CVPR IEEE, P1059
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang X, 2013, P SPIE INT S MULT IM
NR 36
TC 4
Z9 4
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5473
EP 5492
DI 10.1007/s11042-015-2516-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600006
DA 2024-07-18
ER

PT J
AU Tamrakar, D
   Khanna, P
AF Tamrakar, Deepti
   Khanna, Pritee
TI Noise and rotation invariant RDF descriptor for palmprint identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Radon transform; Dual tree complex wavelet transform; Fourier transform;
   Euclidean distance; Gaussian noise
ID TREE COMPLEX WAVELET; PATTERN-RECOGNITION; FEATURE-EXTRACTION; RADON;
   TRANSFORMS; SHIFT
AB Rotation and noise invariant feature extraction is a challenge in palmprint recognition. This work presents a novel RDF descriptor based on Radon, Dual tree complex wavelet, and Fourier transforms. Combined properties of these transforms help to explore efficiency and robustness of RDF descriptor for palmprint identification. Radon transform can capture directional features of the palmprint and is robust to additive white Gaussian noise also. It converts rotation into translation. 1D Dual tree complex wavelet transform (DTCWT) applied on Radon coefficients in angle direction removes translation in Radon coefficients due to palmprint rotation. The magnitude of 2D Fourier transform performed on resultant coefficients helps to extract rotation and illumination invariant features. The performance of the proposed RDF descriptor is evaluated on noisy and rotated palmprints upto 10.. Trained with normal palmprints only, the proposed system gives good results for rotated and noisy palmprints. Experiments are performed on PolyU 2D, CASIA, and IIITDMJ databases. Theoretical foundations and experimental results show the robustness of RDF descriptor against additive white noise and rotation.
C1 [Tamrakar, Deepti; Khanna, Pritee] Pandit Dwarka Prasad Mishra Indian Inst Informat, Dumna Airport Rd, Jabalpur 482005, Madhya Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Khanna, P (corresponding author), Pandit Dwarka Prasad Mishra Indian Inst Informat, Dumna Airport Rd, Jabalpur 482005, Madhya Pradesh, India.
EM pkhanna@iiitdmj.ac.in
RI Tamrakar, Deepti/G-7861-2019; Khanna, Pritee/V-5418-2019
OI Tamrakar, Deepti/0000-0002-4591-2156; Khanna, Pritee/0000-0003-0518-2133
CR [Anonymous], IEEE INT C IM PROC 2
   [Anonymous], 2007, INT S INT SIGN PROC
   [Anonymous], POLYU 2D 3D PALMPRIN
   [Anonymous], PROCEDIA ENG
   [Anonymous], 2011, SIGNAL IMAGE PROCESS, DOI DOI 10.5121/SIPIJ.2011.2114
   Badrinath GS, 2011, APPL SOFT COMPUT, V11, P4267, DOI 10.1016/j.asoc.2010.05.031
   Badrinath GS, 2012, FUTURE GENER COMP SY, V28, P287, DOI 10.1016/j.future.2010.11.029
   Badrinath GS, 2009, LECT NOTES COMPUT SC, V5558, P554, DOI 10.1007/978-3-642-01793-3_57
   Bhanu B, 2008, ADV PATTERN RECOGNIT, P1
   Bin Mansoor A, 2011, J NETW COMPUT APPL, V34, P159, DOI 10.1016/j.jnca.2010.08.004
   Chen GY, 2007, IMAGE VISION COMPUT, V25, P960, DOI 10.1016/j.imavis.2006.07.009
   Chen GY, 2010, PATTERN RECOGN, V43, P579, DOI 10.1016/j.patcog.2009.08.020
   Chen GY, 2009, PATTERN RECOGN, V42, P2013, DOI 10.1016/j.patcog.2008.10.008
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   Fahmy MMM, 2010, AIN SHAMS ENG J, V1, P39, DOI 10.1016/j.asej.2010.09.005
   Hoang TV, 2012, PATTERN RECOGN, V45, P271, DOI 10.1016/j.patcog.2011.06.020
   Imtiaz H, 2013, DIGIT SIGNAL PROCESS, V23, P244, DOI 10.1016/j.dsp.2012.06.016
   Jadhav DV, 2008, SIGNAL PROCESS, V88, P2604, DOI 10.1016/j.sigpro.2008.04.017
   Jadhav DV, 2010, PATTERN RECOGN LETT, V31, P1002, DOI 10.1016/j.patrec.2009.12.026
   Jadhav DV, 2009, NEUROCOMPUTING, V72, P1951, DOI 10.1016/j.neucom.2008.05.001
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kingsbury N, 1999, INT CONF ACOUST SPEE, P1221, DOI 10.1109/ICASSP.1999.756198
   Kingsbury N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P375, DOI 10.1109/ICIP.2000.899397
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Li HJ, 2014, MULTIMED TOOLS APPL, V70, P2331, DOI 10.1007/s11042-012-1240-8
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Mu MR, 2011, NEUROCOMPUTING, V74, P3351, DOI 10.1016/j.neucom.2011.05.026
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   Pang YW, 2013, IEEE T NEUR NET LEAR, V24, P1292, DOI 10.1109/TNNLS.2013.2253798
   Pang YW, 2010, IEEE T CIRC SYST VID, V20, P172, DOI 10.1109/TCSVT.2009.2020337
   Srinivas BG, 2009, COMM COM INF SC, V40, P250, DOI 10.1007/978-3-642-03547-0_24
   Tamrakar D., 2010, Proceedings of the 2010 International Conference on Computational Intelligence and Communication Networks (CICN 2010), P20, DOI 10.1109/CICN.2010.15
   Tamrakar D, 2015, SIGNAL IMAGE VIDEO P, V9, P535, DOI 10.1007/s11760-013-0475-9
   Wang X, 2012, KNOWL-BASED SYST, V27, P451, DOI 10.1016/j.knosys.2011.10.008
   Wang X, 2010, J VIS COMMUN IMAGE R, V21, P29, DOI 10.1016/j.jvcir.2009.09.010
   Xiao B, 2012, PATTERN RECOGN, V45, P314, DOI 10.1016/j.patcog.2011.06.017
   Xiao SS, 2007, CHIN OPT LETT, V5, P513
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zuo WM, 2011, PATTERN RECOGN, V44, P964, DOI 10.1016/j.patcog.2010.09.017
NR 40
TC 22
Z9 22
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 10
BP 5777
EP 5794
DI 10.1007/s11042-015-2541-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DN6PD
UT WOS:000377196600020
DA 2024-07-18
ER

PT J
AU Wang, WY
   Zhao, JY
AF Wang, Wenyi
   Zhao, Jiying
TI Hiding depth information in compressed 2D image/video using reversible
   watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MVD; Stereo images; Reversible watermarking; Depth information;
   Customized entropy coding
ID 3-D VIDEO; RECONSTRUCTION FILTER; REPRESENTATION
AB In this paper, a novel joint coding scheme is proposed for 3D media content including stereo images and multiview-plus-depth (MVD) video for the purpose of depth information hiding. The depth information is an image or image channel which reveals the distance of scene objects' surfaces from a viewpoint. With the concern of copyright protection, access control and coding efficiency for 3D content, we propose to hide the depth information into the texture image/video by a reversible watermarking algorithm called Quantized DCT Expansion (QDCTE). Considering the crucial importance of depth information for depth-image-based rendering (DIBR), full resolution depth image/video is compressed and embedded into the texture image/video, and it can be extracted without extra quality degradation other than compression itself. The reversibility of the proposed algorithm guarantees that texture image/video quality will not suffer from the watermarking process even if high payload (i.e. depth information) is embedded into the cover image/video. In order to control the size increase of watermarked image/video, the embedding function is carefully selected and the entropy coding process is also customized according to watermarking strength. Huffman and content-adaptive variable-length coding (CAVLC), which are respectively used for JPEG image and H.264 video entropy encoding, are analyzed and customized. After depth information embedding, we propose a new method to update the entropy codeword table with high efficiency and low computational complexity according to watermark embedding strength. By using our proposed coding scheme, the depth information can be hidden into the compressed texture image/video with little bitstream size overhead while the quality degradation of original cover image/video from watermarking can be completely removed at the receiver side.
C1 [Wang, Wenyi; Zhao, Jiying] Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Zhao, JY (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM wwang020@uottawa.ca; jzhao@uottawa.ca
OI Wang, Wenyi/0000-0003-1619-0294
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   [Anonymous], P IEEE ICIP
   Bal C, 2014, IEEE T CIRC SYST VID, V24, P995, DOI 10.1109/TCSVT.2014.2302520
   Coltuc D, 2010, 2010 3RD INTERNATIONAL SYMPOSIUM ON ELECTRICAL AND ELECTRONICS ENGINEERING (ISEEE), P256, DOI 10.1109/ISEEE.2010.5628504
   Coltuc D, 2009, ISSCS 2009: INTERNATIONAL SYMPOSIUM ON SIGNALS, CIRCUITS AND SYSTEMS, VOLS 1 AND 2, PROCEEDINGS,, P121
   Cox I., 2001, Digital Watermarking
   Daribo I, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/258920
   Ekmekcioglu E, 2009, IEEE IMAGE PROC, P733, DOI 10.1109/ICIP.2009.5414296
   Ellinas J.N., 2009, International Journal of Signal Processing, V5, P210
   Fehn C., 2002, PROC INT BROADCAST C, P357
   Grewatsch S, 2004, IEEE IMAGE PROC, P3271
   ISO/IEC Moving Picture Experts Group, 2003, 14496102003 ISOIEC M
   Khanna A, 2009, COMPLET TECHNOL GUID, P1, DOI 10.1016/B978-0-12-374956-7.00001-2
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lin YH, 2011, IEEE T BROADCAST, V57, P542, DOI 10.1109/TBC.2011.2131510
   Liu Q, 2012, IEEE SIGNAL PROC LET, V19, P295, DOI 10.1109/LSP.2012.2190060
   Maitre M, 2008, IEEE IMAGE PROC, P1768, DOI 10.1109/ICIP.2008.4712118
   McMillan L, 1997, IMAGE BASED APPROACH
   Morvan Yannick., 2006, Proceedings of SPIE: Stereoscopic Displays and Applications, V6055, P93
   Oh BT, 2011, IEEE J-STSP, V5, P1344, DOI 10.1109/JSTSP.2011.2164893
   Oh KJ, 2011, IEEE T CIRC SYST VID, V21, P350, DOI 10.1109/TCSVT.2011.2116590
   Oh KJ, 2009, IEEE SIGNAL PROC LET, V16, P747, DOI 10.1109/LSP.2009.2024112
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shahid Z, 2011, IEEE IMAGE PROC
   Shahid Z, 2011, CONSIDERING RECONSTR, V5, P75
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shao F, 2012, IEEE T MULTIMEDIA, V14, P157, DOI 10.1109/TMM.2011.2169045
   Smolic A, 2005, P IEEE, V93, P98, DOI 10.1109/JPROC.2004.839608
   Smolic A, 2007, IEEE T CIRC SYST VID, V17, P1606, DOI 10.1109/TCSVT.2007.909972
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Yang Y, 2010, ETRI J, V32, P566, DOI 10.4218/etrij.10.0109.0391
   Zhang Y, 2013, IEEE T IMAGE PROCESS, V22, P3497, DOI 10.1109/TIP.2013.2265883
NR 33
TC 9
Z9 9
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2016
VL 75
IS 8
BP 4285
EP 4303
DI 10.1007/s11042-015-2475-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DJ8JD
UT WOS:000374457700006
DA 2024-07-18
ER

PT J
AU Kambhatla, KKR
   Paluri, S
   Matyjas, JD
   Kumar, S
AF Kambhatla, Kashyap K. R.
   Paluri, Seethal
   Matyjas, John D.
   Kumar, Sunil
TI Cross-Layer prioritized H.264 video packetization and error protection
   over noisy channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264/AVC; Video compression; Cross-layer; Priority-adaptive packet
   formation; Packet discarding; Error protection; Live streaming
ID PACKET SIZE; TRANSMISSION; OPTIMIZATION; IMPROVEMENT; ALGORITHM
AB Video transmission over wireless channels is affected by channel-induced packet losses. Distortion due to channel errors can be alleviated by applying forward error correction. Aggregating H.264/AVC slices to form video packets with sizes adapted to their importance can also improve transmission reliability. Larger packets are more likely to be in error but smaller packets require more overhead. We present a cross-layer dynamic programming (DP) approach to minimize the expected received video distortion by jointly addressing the priority-adaptive packet formation at the application layer and rate compatible punctured convolutional (RCPC) code rate allocation at the physical layer for prioritized slices of each group of pictures (GOP). Some low priority slices are also discarded to improve protection to more important slices and meet the channel bit-rate limitations. We propose two schemes. Our first scheme carries out joint optimization for all slices of a GOP at a time. The second scheme extends our cross-layer DP-based approach to slices of each frame by predicting the expected channel bit budget per frame for live streaming. The prediction uses a generalized linear model developed over the cumulative mean squared error per frame, channel SNR, and normalized compressed frame bit budget. The parameters are determined over a video dataset that spans high, medium and low motion complexity. The predicted frame bit budget is used to derive the packet sizes and corresponding RCPC code rates for live transmission using our DP-based approach. Simulation results show that both proposed schemes significantly improve the received video quality over contemporary error protection schemes.
C1 [Kambhatla, Kashyap K. R.; Kumar, Sunil] Univ Calif San Diego, Elect & Comp Engn, La Jolla, CA 92093 USA.
   [Paluri, Seethal] San Diego State Univ, Computat Sci Res Ctr, San Diego, CA 92182 USA.
   [Matyjas, John D.] Air Force Res Lab, Rome, NY USA.
C3 University of California System; University of California San Diego;
   California State University System; San Diego State University; United
   States Department of Defense; United States Air Force; US Air Force
   Research Laboratory
RP Kambhatla, KKR (corresponding author), Univ Calif San Diego, Elect & Comp Engn, La Jolla, CA 92093 USA.
EM kkambhat@ucsd.edu; spaluri@mail.sdsu.edu; john.matyjas@us.af.mil;
   skumar@mail.sdsu.edu
RI Kumar, Sunil/AAT-4942-2020
OI Kumar, Sunil/0000-0001-9957-5661
FU U.S. Air Force Research Laboratory [FA8750-08-1-0078, FA8750-11-1-0048]
FX Approved for Public Release; Distribution Unlimited: 88ABW-2014-5102, 4
   Nov. 2014. This research was partially supported by awards from the U.S.
   Air Force Research Laboratory under contract #FA8750-08-1-0078 and
   #FA8750-11-1-0048. Opinions, interpretations, and conclusions are those
   of the authors and are not necessarily endorsed by the United States
   Government.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], 2007, LOCAL METROPOLITA 11
   Bandyopadhyay SK, 2006, IEEE SARNOFF SYMPOS, P97
   Chakareski J, 2004, IEEE T COMMUN, V52, P1675, DOI 10.1109/TCOMM.2004.836436
   Chen Z., 2012, 15 INT POWER ELECT M, P1
   Choi BY, 2009, IEEE T MULTIMEDIA, V11, P1194, DOI 10.1109/TMM.2009.2026103
   Chou PA, 2006, IEEE T MULTIMEDIA, V8, P390, DOI 10.1109/TMM.2005.864313
   Choudhury S, 2008, IEEE COMMUN LETT, V12, P11, DOI 10.1109/LCOMM.2008.071434
   Choudhury S, 2007, IEEE J SEL AREA COMM, V25, P796, DOI 10.1109/JSAC.2007.070515
   Connie AT, 2008, CONSUM COMM NETWORK, P800, DOI 10.1109/ccnc08.2007.185
   Duffield NG, 1998, IEEE INFOCOM SER, P1093, DOI 10.1109/INFCOM.1998.662919
   Fallah YP, 2007, CONSUM COMM NETWORK, P875, DOI 10.1109/CCNC.2007.177
   Fallah YP, 2008, EURASIP J WIREL COMM, V2008, P1
   Garibotto G, 2013, LECT NOTES COMPUT SC, V8157, P721, DOI 10.1007/978-3-642-41184-7_73
   HAGENAUER J, 1988, IEEE T COMMUN, V36, P389, DOI 10.1109/26.2763
   HANNAN EJ, 1979, J ROY STAT SOC B MET, V41, P190
   Horn U, 1999, SIGNAL PROCESS-IMAGE, V15, P77, DOI 10.1016/S0923-5965(99)00025-9
   Huang YZ, 2007, INT CONF ACOUST SPEE, P845
   Jelenkovic PR, 2008, MOBIHOC'08: PROCEEDINGS OF THE NINTH ACM INTERNATIONAL SYMPOSIUM ON MOBILE AD HOC NETWORKING AND COMPUTING, P73
   Kambhatla KKR, 2012, IEEE IMAGE PROC, P1649, DOI 10.1109/ICIP.2012.6467193
   Kambhatla KKR, 2012, IEEE T MULTIMEDIA, V14, P1480, DOI 10.1109/TMM.2012.2196508
   Korhonen J, 2005, IEEE WCNC, P1608
   Ksentini A, 2006, IEEE COMMUN MAG, V44, P107, DOI 10.1109/MCOM.2006.1580940
   Lee CW, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/10131
   Lee CW, 2009, INT WIR COMM MOB COM, P1062
   Li D, 2006, INT SERIES OPERATION
   Li F, 2009, IEEE T CIRC SYST VID, V19, P1908, DOI 10.1109/TCSVT.2009.2031457
   Lin H, 2011, IEEE VTC, P1
   Lin TL, 2010, IEEE SIGNAL PROC LET, V17, P505, DOI 10.1109/LSP.2010.2044938
   Luo HY, 2011, IEEE T CIRC SYST VID, V21, P1040, DOI 10.1109/TCSVT.2011.2129810
   Modiano E, 1999, WIREL NETW, V5, P279, DOI 10.1023/A:1019111430288
   NELDER JA, 1972, J R STAT SOC SER A-G, V135, P370, DOI 10.2307/2344614
   OTT T, 1992, IEEE INFOCOM SER, P776, DOI 10.1109/INFCOM.1992.263505
   Paluri S, 2012, IEEE IMAGE PROC, P689, DOI 10.1109/ICIP.2012.6466953
   Pinson MH, 2004, IEEE T BROADCAST, V50, P312, DOI 10.1109/TBC.2004.834028
   Schier M, 2012, IEEE T MULTIMEDIA, V14, P415, DOI 10.1109/TMM.2011.2178235
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shih C.H., 2012, INT J COMPUT SCI ISS, V9, P146
   Shih CH, 2010, IEEE 6 IIH MSP DARMS, P256
   Tsai MF, 2011, WIRELESS PERS COMMUN, V56, P435, DOI 10.1007/s11277-010-9981-z
   van der Schaar M, 2005, IEEE WIREL COMMUN, V12, P50, DOI 10.1109/MWC.2005.1497858
   Venables WN., 2002, MODERN APPL STAT S
   Vosoughi A, 2013, INT CONF ACOUST SPEE, P2050, DOI 10.1109/ICASSP.2013.6638014
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wiegand T, 2000, IEEE J SEL AREA COMM, V18, P1050, DOI 10.1109/49.848255
   Wu TY, 2011, WIREL NETW, V17, P291, DOI 10.1007/s11276-010-0280-0
   Yoo T, 2006, IEEE COMMUN LETT, P1
NR 47
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3235
EP 3257
DI 10.1007/s11042-014-2432-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600015
DA 2024-07-18
ER

PT J
AU Nian, FD
   Li, T
   Wu, XY
   Gao, QW
   Li, FF
AF Nian, Fudong
   Li, Teng
   Wu, Xinyu
   Gao, Qingwei
   Li, Feifeng
TI Efficient near-duplicate image detection with a local-based binary
   representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Near-duplicate image detection; Binary representation; Similarity
   matching
AB Efficient near-duplicate image detection is important for several applications that feature extraction and matching need to be taken online. Most image representations targeting at conventional image retrieval problems are either computationally expensive to extract and match, or limited in robustness. Aiming at this problem, in this paper, we propose an effective and efficient local-based representation method to encode an image as a binary vector, which is called Local-based Binary Representation (LBR). Local regions are extracted densely from the image, and each region is converted to a simple and effective feature describing its texture. A statistical histogram can be calculated over all the local features, and then it is encoded to a binary vector as the holistic image representation. The proposed binary representation jointly utilizes the local region texture and global visual distribution of the image, based on which a similarity measure can be applied to detect near-duplicate image effectively. The binary encoding scheme can not only greatly speed up the online computation, but also reduce memory cost in real applications. In experiments the precision and recall, as well as computational time of the proposed method are compared with other state-of-the-art image representations and LBR shows clear advantages on online near-duplicate image detection and video keyframe detection tasks.
C1 [Nian, Fudong; Li, Teng; Gao, Qingwei] Anhui Univ, Coll Elect Engn & Automat, Hefei 230601, Anhui, Peoples R China.
   [Wu, Xinyu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen, Peoples R China.
   [Li, Feifeng] Huainan Union Univ, Huainan 232001, Anhui, Peoples R China.
C3 Anhui University; Chinese Academy of Sciences; Shenzhen Institute of
   Advanced Technology, CAS
RP Li, T (corresponding author), Anhui Univ, Coll Elect Engn & Automat, Hefei 230601, Anhui, Peoples R China.
EM tenglwy@gmail.com
RI wu, xinyu/KRQ-4615-2024
FU National Natural Science Foundation (NSF) of China [61300056]; Ph.D.
   Programs Foundation of Ministry of Education of China [20133401120005];
   Anhui Provincial Natural Science Foundation of China [1408085QF118];
   National Laboratory of Pattern Recognition (NLPR) [201306282]; Shenzhen
   Science and Technology Project [ZDS Y20120617113312191]
FX This work is supported by the National Natural Science Foundation (NSF)
   of China (No. 61300056), the Ph.D. Programs Foundation of Ministry of
   Education of China (No. 20133401120005), the Anhui Provincial Natural
   Science Foundation of China (No. 1408085QF118), the Open Project Program
   of the National Laboratory of Pattern Recognition (NLPR) (No. 201306282)
   and a grant from Shenzhen Science and Technology Project (No. ZDS
   Y20120617113312191).
CR [Anonymous], 2014, INT J DIFF EQS, DOI DOI 10.1074/JBC.M114.550012
   [Anonymous], P ACM SIGMM WORKSH M
   [Anonymous], 2007, CVPR
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P4380, DOI 10.1109/TIP.2013.2273665
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Chang EY, 1998, P SOC PHOTO-OPT INS, V3527, P58, DOI 10.1117/12.325852
   Choi Y, 2014, 12 AS C COMP VIS ACC
   Chum O., 2008, BMVC, P812, DOI DOI 10.5244/C.22.50
   Crow F. C., 1984, Computers & Graphics, V18, P207
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   Ke Yan., 2004, MULTIMEDIA 04 P 12 A, P869, DOI DOI 10.1145/1027527.1027729
   Kim C, 2003, SIGNAL PROCESS-IMAGE, V18, P169, DOI 10.1016/S0923-5965(02)00130-3
   Krawetz N, 2011, IMAGE INDEXING
   Law-To Julien., 2007, P 6 ACM INT C IMAGE, P371
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Liu B, 2010, IEEE INT CON MULTI, P100, DOI 10.1109/ICME.2010.5583860
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Meng Y, 2003, PROC CVPR IEEE, P416
   Mishra P., 2014, INT J RES COMPUT ENG, V3
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Shang L., 2010, Proceedings of the International Conference on Multimedia, P531
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Takala V, 2005, LECT NOTES COMPUT SC, V3540, P882
   Thomee B., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P59
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang M, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2333112.2333120
   Wu A. G., 2007, P ACM MM, P218
   Wu X, 2009, IEEE T MULTIMEDIA, V11, P196, DOI 10.1109/TMM.2008.2009673
   Yang C, 2013, OPEN J APPL SCI, V3, P16
   Yang X., 2009, P 1 ACM WORKSH LARG, P73, DOI DOI 10.1145/1631058.1631073
   Zhang S, 2014, IMAGE PROCESS
   Zhaofeng Li, 2013, Journal of Multimedia, V8, P557, DOI 10.4304/jmm.8.5.557-564
NR 36
TC 11
Z9 11
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2435
EP 2452
DI 10.1007/s11042-015-2472-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000003
DA 2024-07-18
ER

PT J
AU Ou, ZH
   Chen, LH
AF Ou, Zhan-He
   Chen, Ling-Hwei
TI A robust watermarking method for stereo-pair images based on unmatched
   block bitmap
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo-pair images; Watermarking; Ownership proof; AC coefficient swap;
   Unmatched block
AB A stereo-pair image contains two views of a scene called the left image and right image. This paper proposes a novel watermarking method for stereo-pair images. The proposed method is divided into three parts: watermark creation, watermark embedding, and watermark verification. Because the left and right images of a stereo pair appear to be highly similar, a robust watermark is first created based on a feature map that records the positions of the unmatched blocks between these two images. The created watermark is then embedded into the left image by swapping the AC coefficients. A feature map is first extracted from the watermarked stereo-pair image during the verification process. Subsequently, the embedded watermark is extracted from the watermarked left image and converted into an estimated feature map. Ownership is proved when the feature map and the estimated feature map are similar. Experimental results indicate that the proposed method exhibits greater robustness against malicious attacks and produces less distortion than existing methods do.
C1 [Ou, Zhan-He; Chen, Ling-Hwei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Chen, LH (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM lhchen@cc.nctu.edu.tw
FU National Science Council of Republic of China
   [NSC-103-2221-E-009-121-MY2]
FX This work is supported in part by National Science Council of Republic
   of China under grant NSC-103-2221-E-009-121-MY2
CR [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT C INT TEC
   [Anonymous], P 2 WORKSH INF HID
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], 1998, 1998 IEEE DIG SIGN P
   Campisi P, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3009554
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Kim HD, 2012, IEEE T BROADCAST, V58, P533, DOI 10.1109/TBC.2012.2206851
   Petitcolas FAP, 2000, IEEE SIGNAL PROC MAG, V17, P58, DOI 10.1109/79.879339
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
NR 11
TC 7
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 6
BP 3259
EP 3280
DI 10.1007/s11042-014-2433-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DH6BI
UT WOS:000372875600016
DA 2024-07-18
ER

PT J
AU Zhou, SY
   Lu, ZM
   Wen, XM
   Fu, B
   Shao, H
   Chen, YW
AF Zhou, Shiyu
   Lu, Zhaoming
   Wen, Xiangming
   Fu, Bin
   Shao, Hua
   Chen, Yawen
TI Bursty interference-oriented video quality assessment method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bursty interference; Hysteresis model; Video quality assessment; QoE
ID VISUAL-ATTENTION; MODEL
AB The frequent bursty interference leads to wireless throughput variability in future networks, which results in video quality of experience (QoE) degradation. It is highly desirable to be able to predict video quality to meet QoE requirements. There has been a great deal of studies on video quality assessment, but only limited work has been reported for assessing video quality under bursty interference environment. In this paper, we seek to ameliorate this by developing a bursty interference-oriented video quality assessment algorithm. First, a subjective experiment has been carried out and a hysteresis model was proposed by analyzing the experiment data. Simulation result shows that in burst traffic environment, the model has a better correlation with human visual system (HVS) effect. Then we proposed an objective quality assessment algorithm by taking the video color, brightness, motion and other spatial features together with Structural Similarity Index Measurement (SSIM) into consideration, which outperforms Peak Signal Noise Rate (PSNR), Visual Information Fidelity (VIF) and SSIM in bursty environment.
C1 [Zhou, Shiyu; Lu, Zhaoming; Wen, Xiangming; Fu, Bin; Shao, Hua; Chen, Yawen] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst Architecture & Conve, Beijing 100088, Peoples R China.
   [Zhou, Shiyu] China United Network Commun Corp Ltd, Network Technol Res Inst, Res Dept Network Optimizat & Management Technol, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; China United Network
   Communications Limited
RP Lu, ZM (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst Architecture & Conve, Beijing 100088, Peoples R China.
EM lzy_0372@163.com
RI Chen, John/GPW-8839-2022; Chen, Ya-Wen/AAG-7549-2019
OI Chen, Ya-Wen/0000-0002-6080-8859
CR [Anonymous], 2000, APS COMM NETW MULTIM
   [Anonymous], P IEEE PICT COD S MA
   [Anonymous], 2003, Final report from the video quality experts group on the validation of objective models of video quality assessment
   [Anonymous], 2013, White Paper
   [Anonymous], 2009, 2009 INT C ELECT MAC
   Ansgar KR, J VISION, V7, P6
   BT RECOMMENDATION ITU-R, 2002, METH SUBJ ASS QUAL T
   Carmi R, 2006, VISION RES, V46, P4333, DOI 10.1016/j.visres.2006.08.019
   Culibrk D., 2009, 16th International Conference on Digital Signal Processing, P1
   Damnjanovic A, 2011, IEEE WIREL COMMUN, V18, P10, DOI 10.1109/MWC.2011.5876496
   De Simone F, 2009, INT WORK QUAL MULTIM, P204, DOI 10.1109/QOMEX.2009.5246952
   Engelke U, 2011, IEEE SIGNAL PROC MAG, V28, P50, DOI 10.1109/MSP.2011.942473
   Fu B, 2013, P 16 INT S WIR PERS, P1
   Hou TB, 2011, IEEE T IMAGE PROCESS, V20, P3383, DOI 10.1109/TIP.2011.2150236
   Inazumi Y., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P338, DOI 10.1109/ICIP.1999.819608
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Lee C, 2003, OPT ENG, V42, P265, DOI 10.1117/1.1523420
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Li SN, 2012, IEEE T CIRC SYST VID, V22, P1100, DOI 10.1109/TCSVT.2012.2190473
   Li X, 2010, INT CONF BIOMED, P1, DOI 10.1109/BMEI.2010.5639520
   Ma L, 2012, IEEE INT SYMP CIRC S, P2677, DOI 10.1109/ISCAS.2012.6271858
   Ma L, 2012, IEEE J-STSP, V6, P626, DOI 10.1109/JSTSP.2012.2211996
   Masry MA, 2004, SIGNAL PROCESS-IMAGE, V19, P133, DOI 10.1016/j.image.2003.08.001
   Moorthy AK, 2010, IEEE T CIRC SYST VID, V20, P587, DOI 10.1109/TCSVT.2010.2041829
   Rensink RA, 2000, VISION RES, V40, P1469, DOI 10.1016/S0042-6989(00)00003-1
   Seshadrinathan K, 2009, SPIE ELECT IMAGING S, V72, p400X
   Seshadrinathan K, 2011, INT CONF ACOUST SPEE, P1153
   Seshadrinathan K, 2010, IEEE T IMAGE PROCESS, V19, P1427, DOI 10.1109/TIP.2010.2042111
   Seshadrinathan K, 2008, IEEE IMAGE PROC, P1200, DOI 10.1109/ICIP.2008.4711976
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Singh S, 2012, IEEE J SEL AREA COMM, V30, P1259, DOI 10.1109/JSAC.2012.120811
   Tan KT, 1998, SIGNAL PROCESS, V70, P279, DOI 10.1016/S0165-1684(98)00129-7
   Taylor CN, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P3081, DOI 10.1109/ICC.2004.1313098
   Telefon AB LM Ericsson ST- Ericsson SA, TDOCS4AHI118
   TOM MD, 1995, IEEE T NEURAL NETWOR, V6, P387, DOI 10.1109/72.363474
   Tsotsos JK, 2005, COMPUT VIS IMAGE UND, V100, P3, DOI 10.1016/j.cviu.2004.10.011
   Wandell B. A, 1995, Foundations of vision
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P65, DOI 10.1109/ICIP.2002.1038904
   Wang Z, 2003, SYST COMPUT, V2, P1398
   Watson A.B., 1993, SID INT S, V24, P946
   You JY, 2014, IEEE T IMAGE PROCESS, V23, P200, DOI 10.1109/TIP.2013.2287611
   Zhao Y, 2011, IEEE T CIRC SYST VID, V21, P1890, DOI 10.1109/TCSVT.2011.2157189
   Zink M, 2003, LECT NOTES COMPUT SC, V2707, P137
NR 44
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2741
EP 2768
DI 10.1007/s11042-015-2787-y
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000022
DA 2024-07-18
ER

PT J
AU Chu, ETH
   Wu, CC
AF Chu, Edward T. -H.
   Wu, Chung-Chih
TI An image-based seismic damage assessment system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Multimedia applications; Emergency system; Disaster
   management; Information verification; Earthquake assessment
AB Surveillance systems are commonly used by command centers to monitor and assess seismic damage inside buildings, such as schools, shopping malls, office buildings and skyscrapers. It is expected that checking camera images manually on monitors can be a very time-consuming and inefficient process, especially for a large surveillance system. One of the alternative ways is to first deploy sensors to monitor objects inside buildings, such as tables, cabinets, bookcases and so on, and, after fusing sensor data, to assess damage. However, deploying sensors can be impractical and costly when there are too many objects needed to be monitored. In this paper, we present IDEAS, an image-based disaster damage assessment system, to evaluate seismic damage inside buildings. IDEAS first compares images taken inside a building before and after an earthquake, it then maps the damage to a Mercalli intensity scale. In order to investigate the effectiveness and accuracy of IDEAS, we collect over forty pairs of closed-circuit television (CCTV) images from Youtube website. Each pair of images represents a real scenario of an earthquake inside a building. Our results show that IDEAS performs better than existing methods and can achieve an average accuracy of 97.6 % in mapping Mercalli intensity scale.
C1 [Chu, Edward T. -H.; Wu, Chung-Chih] Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
C3 National Yunlin University Science & Technology
RP Chu, ETH (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Comp Sci & Informat Engn, Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
EM edwardchu@yuntech.edu.tw; M10117032@yuntech.edu.tw
FU Academia Sinica Project [AS-101-TP2-A01]
FX The work was supported by Academia Sinica Project AS-101-TP2-A01.
CR [Anonymous], 2014, MATLAB
   [Anonymous], 2014, YOUTUBE
   [Anonymous], 2010, 2010 18 INT C GEOINF
   Chu ET-H, 2014, THE LIST OF VIDEOS
   Conde C, 2013, NEUROCOMPUTING, V100, P19, DOI 10.1016/j.neucom.2011.12.037
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Ergin T., 2012, 14 INT C COMP CIV BU
   Gunawan LT, 2012, PROCEEDINGS OF THE 2, P241
   Huang L, 2010, INT GEOSCI REMOTE SE, P1007, DOI 10.1109/IGARSS.2010.5653392
   Huang L, 2010, INT J REMOTE SENS, V31, P2169, DOI 10.1080/01431161003621585
   Kuno Y., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P865, DOI 10.1109/ICPR.1996.547291
   Liu JWS, 2013, COMPUTER, V46, P69, DOI 10.1109/MC.2012.149
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Naidu V, 2014, MULTIMODAL IMAGE SEG
   Natural Resources Canada, 2014, MOD MERC MM INT SCAL
   O'Callaghan RJ, 2005, IEEE T IMAGE PROCESS, V14, P49, DOI 10.1109/TIP.2004.838695
   OASIS Emergency Management Technical Committee, 2010, CAP COMM AL PROT V1
   Shumei Zhang, 2012, 2012 Third International Conference on Intelligent Control and Information Processing (ICICIP 2012), P605, DOI 10.1109/ICICIP.2012.6391540
   Soille P, 2014, MORPHOLOGICAL IMAGE, P173
   Soille P, 2014, MORPHOLOGICAL IMAGE, P170
   VANDENBOOMGAARD R, 1992, CVGIP-GRAPH MODEL IM, V54, P252, DOI 10.1016/1049-9652(92)90055-3
   Vural Ulas, 2011, Video Surveillance, P335
NR 22
TC 5
Z9 6
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1721
EP 1743
DI 10.1007/s11042-015-2602-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600020
DA 2024-07-18
ER

PT J
AU Li, YS
   Liu, WM
   Huang, QH
   Li, XL
AF Li, Yanshan
   Liu, Weiming
   Huang, Qinghua
   Li, Xuelong
TI Fuzzy bag of words for social image description
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bag of words; Fuzzy sets theory; Image description; Social images
ID FEATURES
AB Rapid growth of social media resources brings huge challenges and opportunities for image description technologies. The performance of image description method directly affects the accuracy of image retrieval, image annotation and image recognition. Bag of Words (BoW) as an efficient approach to describing the images has been attracting more and more attention. However, in traditional BoW, the maps between the words in the codebook and the features extracted from the images are actually ambiguous. As the Fuzzy Sets Theory (FST) is a powerful means for dealing with uncertainty efficiently, we utilize the FST to solve the problem caused by the ambiguity between the features and words. Accordingly, we propose a new type of BoW named as FBoW to describe images based on FST. Firstly, the features are extracted from the images. Secondly, k-means is utilized to learn the codebook. Thirdly, a fuzzy membership function is designed to measure the similarity between the features and words. The optimal parameters of the fuzzy membership function are obtained by using a Genetic Algorithm (GA). The histogram is generated by adding up the fuzzy membership values of each word to describe the images. The experimental results show that the proposed FBoW outperforms traditional BoW for social image description.
C1 [Li, Yanshan; Huang, Qinghua] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Peoples R China.
   [Li, Yanshan; Liu, Weiming] S China Univ Technol, Sch Civil Engn & Transportat, Guangzhou 510640, Peoples R China.
   [Li, Yanshan] Shenzhen Univ, Shenzhen 518060, Peoples R China.
   [Li, Xuelong] Chinese Acad Sci, Ctr Opt IMagery Anal & Learning OPTIMAL, State Key Lab Transient Opt & Photon, Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.
C3 South China University of Technology; South China University of
   Technology; Shenzhen University; State Key Laboratory of Transient
   Optics & Photonics; Chinese Academy of Sciences; Xi'an Institute of
   Optics & Precision Mechanics, CAS
RP Huang, QH (corresponding author), S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Peoples R China.
EM qhhuang@scut.edu.cn
RI Li, Xuelong/Z-3785-2019; Li, Xuelong/ABF-3381-2020; Huang,
   Qinghua/L-8708-2019; li, xiang/GWM-6319-2022
OI Huang, Qinghua/0000-0003-1080-6940; Li, Xuelong/0000-0002-0019-4197;
   liu, Weiming/0000-0003-3700-4307
FU National Natural Science Funds of China [61125106, 61372007, 91120302,
   61072093]; Guangdong Provincial Project of Transportation Science and
   Technology [2012-02-084]; Natural Science Funds of Guangdong Province
   [S2012010009885]; Fundamental Research Funds for the Central
   Universities [2014ZG0038]; Projects of innovative science and
   technology, Department of Education, Guangdong Province [2013KJCX0012];
   Shaanxi Key Innovation Team of Science and Technology [2012KCT-04]
FX The research was supported by National Natural Science Funds of China
   (Nos. 61125106, 61372007, 91120302, and 61072093), Guangdong Provincial
   Project of Transportation Science and Technology (No. 2012-02-084),
   Natural Science Funds of Guangdong Province (No. S2012010009885), the
   Fundamental Research Funds for the Central Universities (No.
   2014ZG0038), Projects of innovative science and technology, Department
   of Education, Guangdong Province (No. 2013KJCX0012), and Shaanxi Key
   Innovation Team of Science and Technology (Grant No.: 2012KCT-04).
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2013, P 5 INT C INTERNET M, DOI DOI 10.1145/2499788.2499873
   [Anonymous], INFORM SCI IN PRESS
   Banerji S, 2013, LECT NOTES COMPUT SC, V8047, P490, DOI 10.1007/978-3-642-40261-6_59
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Farhangi MM, 2013, ADV INTELL SYST, V177, P681
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Grana C, 2013, PROC SPIE, V8667, DOI 10.1117/12.2008460
   Huang QH, 2011, APPL MATH COMPUT, V218, P4353, DOI 10.1016/j.amc.2011.10.011
   Huang QH, 2012, ULTRASONICS, V52, P266, DOI 10.1016/j.ultras.2011.08.011
   Huang QH, 2011, IEEE T SYST MAN CY B, V41, P1471, DOI 10.1109/TSMCB.2011.2151256
   Ji RR, 2012, INT J COMPUT VISION, V96, P290, DOI 10.1007/s11263-011-0472-9
   Ji RR, 2014, IEEE T GEOSCI REMOTE, V52, P1811, DOI 10.1109/TGRS.2013.2255297
   Ji RR, 2013, IEEE T MULTIMEDIA, V15, P153, DOI 10.1109/TMM.2012.2225035
   Ji RR, 2012, IEEE T IMAGE PROCESS, V21, P2282, DOI 10.1109/TIP.2011.2176950
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li J, 2013, IEEE T NEUR NET LEAR, V24, P964, DOI 10.1109/TNNLS.2013.2245341
   Li J, 2013, IEEE T NEUR NET LEAR, V24, P485, DOI 10.1109/TNNLS.2012.2234134
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DP, 2011, PROC INT CONF DOC, P1012, DOI 10.1109/ICDAR.2011.205
   Tao DP, 2012, NEUROCOMPUTING, V91, P11, DOI 10.1016/j.neucom.2012.02.024
   van Gemert Jan C., 2008, Computer Vision. Proceedings 10th European Conference on Computer Vision, ECCV 2008, P696, DOI 10.1007/978-3-540-88690-7_52
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wu L, 2011, IEEE MULTIMEDIA, V18, P24, DOI 10.1109/MMUL.2011.7
   Wu L, 2010, IEEE T IMAGE PROCESS, V19, P1908, DOI 10.1109/TIP.2010.2045169
   Wu Z, 2009, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2009.5459439
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zha ZJ, 2013, IEEE T CIRC SYST VID, V23, P856, DOI 10.1109/TCSVT.2012.2226526
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zha ZJ, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823747
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zheng SH, 2012, APPL ACOUST, V73, P423, DOI 10.1016/j.apacoust.2011.09.013
NR 36
TC 16
Z9 16
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1371
EP 1390
DI 10.1007/s11042-014-2138-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600002
DA 2024-07-18
ER

PT J
AU Mzoughi, O
   Yahiaoui, I
   Boujemaa, N
   Zagrouba, E
AF Mzoughi, Olfa
   Yahiaoui, Itheri
   Boujemaa, Nozha
   Zagrouba, Ezzeddine
TI Semantic-based automatic structuring of leaf images for advanced plant
   species identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Botanical concepts; Structuring; Categorisation; Partition; Leaf species
   identification
ID SHAPE; MULTISCALE; CURVATURE
AB Structuring the search space based on domain-specific vocabulary (or concepts) is capital for enhanced image retrieval. In this paper, we study the opportunities and the impact of exploiting such a strategy in a particular problem which is the leaf species identification. We believe that such a solution is promising to reduce the effect of the high variability across and within species and define more specific and relevant leaf image representations. Among botanical concepts that describe leaves (and particularly their architecture), we focus mainly on three of the most basic and commonly-used concepts: the leaf arrangement, lobation and partition. These concepts define two different structuring types: (1) One is a coarse categorisation of leaf datasets into three subsets, namely simple lobed, simple not lobed and compound (2) The other is a decomposition of the entire leaf images into semantic regions (or parts). We perform the whole structuring process automatically by defining simple geometric parameters (extracted from the leaf contour) based on the analysis of botanical definitions. A fine recognition process is then established in order to determine the species identity. It is defined, typically, using standard (texture or contour) descriptors followed by a KNN classifier. Enriched by the proposed structuring process, the search for species candidates will be restricted to the correspondent category of the query and based on a fusion of each part responses. Experiments carried out on the Scan Pictures of the ImageCLEF 2011 dataset (3070 images totalling 70 species) have shown an increase in performances for different descriptor configurations compared to global leaf representations as well as to some recent related studies.
C1 [Mzoughi, Olfa; Yahiaoui, Itheri] INRIA, Saclay, France.
   [Boujemaa, Nozha] INRIA, Saclay Ile de France Res Ctr, Saclay, France.
   [Mzoughi, Olfa; Zagrouba, Ezzeddine] Univ Tunis El Manar, Intitut Super Informat, SIIVA RIADI, Tunis, Tunisia.
   [Yahiaoui, Itheri] CReSTIC Univ Reims, Champagne Ardenne, France.
C3 Inria; Inria; Universite de Tunis-El-Manar
RP Mzoughi, O (corresponding author), INRIA, Saclay, France.; Mzoughi, O (corresponding author), Univ Tunis El Manar, Intitut Super Informat, SIIVA RIADI, Tunis, Tunisia.
EM olfa.mzoughi@inria.fr
RI Zagrouba, Ezzeddine/D-7896-2014; mzoughi, olfa/HMW-1127-2023
OI Zagrouba, Ezzeddine/0000-0002-2574-9080; mzoughi,
   olfa/0000-0001-8758-9740
CR Agarwal G, 2006, TAXON, V55, P597, DOI 10.2307/25065637
   [Anonymous], 1999, GROUP 65P LAW UNK MO
   [Anonymous], 2011, INDIAN J ENG MATER S
   [Anonymous], ICMR
   Backes AR, 2010, LECT NOTES COMPUT SC, V6134, P463, DOI 10.1007/978-3-642-13681-8_54
   Backes AR, 2009, PATTERN RECOGN, V42, P54, DOI 10.1016/j.patcog.2008.07.006
   Beghin T, 2010, SHAPE TEXTURE BASED, P345
   Boujemaa N, 2013, P 3 ACM C INT C MULT
   Casanova D, 2009, INT J IMAGING SYST T
   Cerutti Guillaume, 2011, Advances in Visual Computing. Proceedings 7th International Symposium, ISVC 2011, P202
   Cerutti G, 2013, IEEE IMAGE PROC, P1471, DOI 10.1109/ICIP.2013.6738302
   Chi YT, 2003, T ASAE, V46, P175
   Cope JS, 2012, EXPERT SYST APPL, V39, P7562, DOI 10.1016/j.eswa.2012.01.073
   Cope JS, 2010, LECT NOTES COMPUT SC, V6454, P669, DOI 10.1007/978-3-642-17274-8_65
   Dalal N, 2005, P CVPR, P01
   FERECATU M, 2005, THESIS U VERSAILLES
   Florindo JB, 2010, LECT NOTES COMPUT SC, V6134, P456, DOI 10.1007/978-3-642-13681-8_53
   Goeau H., 2011, ACM MULTIMEDIA
   Goeau H, 2011, WORK NOT CLEF 2011 C
   Gu X, 2005, ICIC 1
   Hearn DJ, 2009, TAXON, V58, P934, DOI 10.1002/tax.583021
   Jia W., 2012, IEEE T IMAGE PROCESS
   Jovic M, 2006, LECT NOTES COMPUT SC, V4223, P461
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Mizuno S, 2007, LECT NOTES COMPUT SC, V4418, P400
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Mokhtarian F, 2004, IEEE T IMAGE PROCESS, V13, P653, DOI 10.1109/TIP.2004.826126
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Mouine S., 2012, ICMR, DOI [10.1145/2324796.2324853, DOI 10.1145/2324796.2324853]
   Mzoughi O, 2013, ICME
   Mzoughi O., 2013, IEEE INT C IM PROC I
   Nanni L, 2012, EXPERT SYST APPL
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park J, 2008, J SYST SOFTWARE, V81, P71, DOI 10.1016/j.jss.2007.05.001
   Prasad S., 2011, Proceedings of the Conference on Communication, Computing Security, P343, DOI 10.1145/1947940.1948012
   Sfar AsmaRejeb., 2013, CVPR
   Snelick R., 2003, P 5 INT C MULT INT I
   Wang J, 2012, PATTERN RECOGN LETT
   Wang XF, 2008, APPL MATH COMPUT, V205, P916, DOI 10.1016/j.amc.2008.05.108
   Wang Z, 2003, IEE P-VIS IMAGE SIGN, V150, P34, DOI 10.1049/ip-vis:20030160
   Wu SG, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, VOLS 1-3, P120
   Yahiaoui Itheri, 2012, ICME2012
NR 42
TC 9
Z9 10
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1615
EP 1646
DI 10.1007/s11042-015-2603-8
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600016
DA 2024-07-18
ER

PT J
AU Manikandan, MSK
   Saurigresan, P
   Ramkumar, R
AF Manikandan, M. S. K.
   Saurigresan, P.
   Ramkumar, R.
TI Grouped frequency interleaved ordering with pre-fetching for efficient
   channel navigation in internet protocol television
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE IPTV; Channel navigation; Channel zapping; Pre-fetching; Frequency
   interleaved ordering; Scalable video coding; Zipf parameter
ID IPTV; TIME
AB Internet Protocol Television (IPTV) is becoming one of the major internet applications due to its variety of contents and services. However, the increased number of channels makes very difficult to find one's desired contents of the channel, because the biggest challenge in IPTV is the channel zapping delay which occurs during channel switching. In this paper, a Grouped Frequency Interleaved Ordering (GFIO) with Pre-Fetching (PF) has been proposed to reduce the channel zapping delay in an IPTV. The channel zapping delay is reduced by minimizing the channel seek distance and seek time of the IPTV channels. Thereby, minimizing the channel seek distance by grouping similar category of channels and reordering that based on popularity ranking. The channel seek time is reduced by pre-fetching the contents of channels as adjacent to the main channel (currently watching channel). Additionally, main channel only coded as using both base and enhancement layer while all other PF channels are coded only with the base layer in the proposed scheme rather than all channels coded with both layers. Trace- driven simulations with various experimental conditions show that the proposed scheme performs better than the existing schemes. When the number of IPTV channels is 150, the average seek distance is reduced to 57.14% and the average seek time is reduced to 77.78% by combining GFIO with the adjacent channel PF scheme. The proposed scheme also saving 24.75 % of the bit rate, reduces 26.92 % of the encoding time and 27.59 % of decoding time.
C1 [Manikandan, M. S. K.; Saurigresan, P.; Ramkumar, R.] Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai 625015, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Saurigresan, P (corresponding author), Thiagarajar Coll Engn, Dept Elect & Commun Engn, Madurai 625015, Tamil Nadu, India.
EM manimsk@tce.edu; saurigresan@tce.edu; ramraniruk@gmail.com
RI MSK, Manikandan/AAP-9121-2020
FU University Grants Commission (UGC), New Delhi
FX The authors would like to thank the University Grants Commission (UGC),
   New Delhi for sponsoring this project; The reviewers for their
   thoughtful comments and valuable suggestions in improving this paper;
   Vennila Dhanagiri and Surendar Maruthu for their valuable discussions.
CR Ali Begen C, 2012, PRESENTED IPTV INTER
   [Anonymous], 2010, COD MOV PICT AUD JOI
   [Anonymous], 1949, Human behaviour and the principle of least-effort
   Boyce J. M., 2005, P IEEE INT C CONS EL
   Cho C, 2004, 6TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY, VOLS 1 AND 2, PROCEEDINGS, P971
   Hodis Florin, IPTV CHALLENGES METR
   Joint Video Team (JVT) of ISO/IEC MPEG & ITU-T VCEG, 2008, JVTAB203 MPEGITUT IS
   Joo H, 2008, IEEE T BROADCAST, V54, P208, DOI 10.1109/TBC.2008.915767
   Kim Y., 2008, P IEEE INT S BROADB
   Kooij R, 2006, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS AND NETWORKS, P155
   LEE E, 2009, IEEE T CONSUMER ELEC, V55
   Lee Y, 2008, IEEE T CONSUM ELECTR, V54, P912, DOI 10.1109/TCE.2008.4560178
   Lim J, 2007, J AM SOC INF SCI TEC, V58, P1346, DOI 10.1002/asi.20577
   Mandal S., 2008, Intelligent Pre-Fetching to Reduce Channel Switching Delay in IPTV Systems
   Oh U, 2010, IEEE T CONSUM ELECTR, V56, P483, DOI 10.1109/TCE.2010.5505959
   Palacios Francisco, IPTV TESTING DSL
   QIU T, 2009, P 11 INT JOINT C MEA
   Ramos FMV, 2011, SIGNAL PROCESS-IMAGE, V26, P400, DOI 10.1016/j.image.2011.03.005
   SASAKI C, 2008, P IEEE INT C COMM IC
NR 19
TC 3
Z9 3
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 2
BP 887
EP 902
DI 10.1007/s11042-014-2330-6
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB7YX
UT WOS:000368734700009
DA 2024-07-18
ER

PT J
AU Marco, J
   Cerezo, E
   Baldassarri, S
AF Marco, Javier
   Cerezo, Eva
   Baldassarri, Sandra
TI Lowering the threshold and raising the ceiling of tangible
   expressiveness in hybrid board-games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tabletop; Framework; Tangible; Board-games; Hybrid games; Playing
   pieces; Design; Prototyping
AB Tabletop devices offer an attractive environment for the creation of hybrid board-games that seamlessly integrate physical and digital interaction. However, the prototyping of Tangible User Interfaces involves the integration of physical and virtual aspects, challenging both designers and developers, and hindering the rapid exploration of richer physical interactions with the game. Although the recent appearance of tabletop frameworks has helped to lower the threshold for coding tangible tabletop applications, the cost is a serious limitation on the degree of expressiveness of the tangible interaction. This paper presents "ToyVision", a software framework for the prototyping of tabletop games based on the manipulation of conventional playing pieces. ToyVision architecture is based on a Widget layer of abstraction that is able to express the manipulation of playing pieces in the context of the game. This Widget layer supports a wide range of passive and active manipulations with conventional objects. Designers and developers can visually model all passive and active manipulations involved in their game concepts in a Graphic Assistant, and test them immediately in a tabletop device. The paper also describes a set of evaluation sessions which demonstrate that ToyVision has been effective in lowering the threshold of developing applications for tabletop devices, while being sufficiently expressive to give support to innovative concepts for hybrid games that fully explore the tangible feasibilities of conventional playing pieces.
C1 [Marco, Javier] Univ Zaragoza, Dept Comp Sci, GIGA Affect Lab, Zaragoza, Spain.
   [Cerezo, Eva; Baldassarri, Sandra] Univ Zaragoza, Dept Comp Sci, GIGA Affect Lab, Engn Res Inst Aragon I3A, Zaragoza, Spain.
C3 University of Zaragoza; University of Zaragoza
RP Marco, J (corresponding author), Univ Zaragoza, Dept Comp Sci, GIGA Affect Lab, Zaragoza, Spain.
EM jmarco2000@gmail.com; ecerezo@unizar.es; sandra@unizar.es
RI Cerezo, Eva/L-6095-2014; Baldassarri, Sandra/L-6033-2014
OI Cerezo, Eva/0000-0003-4424-0770; 
FU Spanish Government [TIN2011-24660]
FX We thank Elisa Ubide for helping in the development of ToyVision. We
   also thank all the students, designers and developers who participated
   in our evaluation sessions. This work has been partly financed by the
   Spanish Government through the DGICYT contract TIN2011-24660.
CR Al Mahmud A, 2008, P NORDICHI OCT
   [Anonymous], 2001, 91261 ISO
   [Anonymous], 2013, PROC EICS 13
   Bollhoefer KW, 2009, TECHNICAL REPORT
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Clements P, 2002, EVALUATING SOFTWARE
   Echtler Florian., 2008, Proceedings of the 5th Nordic conference on Human-computer interaction: building bridges, NordiCHI '08, P463, DOI DOI 10.1145/1463160.1463220
   Greenberg S., 2001, 01UIST. Proceedings of the 14th Annual ACM Symposium on User Interface Software and Technology, P209, DOI 10.1145/502348.502388
   Greenberg S, 2002, GROUPWARE DESIGN IMP, P1
   Hansen Thomas., 2009, ITS 09 P ACM INT C I, P17
   Heijboer M, 2008, P NORDICHI 2008, P162, DOI DOI 10.1145/1463160.1463178
   Heng X, 2008, P PPD 08
   Hinske S., 2009, Proceedings of the 3rd International Conference on Tangible and Embedded Interaction, P99, DOI DOI 10.1145/1517664.1517691
   Holmquist LE, 1999, LECT NOTES COMPUT SC, V1707, P234
   Hornecker E, 2006, P SIGCHI C HUM FACT, P437, DOI [10.1145/1124772.1124838, DOI 10.1145/1124772.1124838]
   Ishii H., 1997, P ACM SIGCHI C HUM F, P234, DOI DOI 10.1145/258549.258715
   Iwata T, 2010, TEI 2010, P237
   Kaltenbrunner M, 2005, 6 INT GEST WORKSH
   Klemmer S.R., 2004, CHI '04: Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, ACM, New York, NY, USA, P399
   Krzywinski A, 2009, P INT C ADV COMP ENT, P107
   LEITNER J, 2010, COMPUT ENTERTAIN, V7
   Li Y, 2008, LECT NOTES COMPUT SC, V5294, P182
   Lin H.-H, 2007, HUMAN COMPUTER INTER
   Marco J., 2012, Proceedings of the 4th ACM SIGCHI Symposium on Engineering Interactive Computing Systems, EICS '12, P71, DOI [10.1145/2305484.2305498, DOI 10.1145/2305484.2305498]
   Marco J, 2012, INT J ARTS TECHNOL, V5, P151, DOI 10.1504/IJART.2012.046272
   Marco Javier, 2013, P 7 INT C TANGIBLE E, P291, DOI [10.1145/2460625.2460674, DOI 10.1145/2460625.2460674]
   Mikhak B, 2003, CHI 2003 UNPUB
   Myers B., 2000, ACM Transactions on Computer-Human Interaction, V7, P3, DOI 10.1145/344949.344959
   Resnick M, 2009, COMMUN ACM, V52, P60, DOI 10.1145/1592761.1592779
   Rogers Y., 2004, PUBLIC SITUATED DISP, P45
   Ryan R. M., 1985, INTRINSIC MOTIVATION
   Shaer O, 2009, ACM T COMPUT-HUM INT, V16, DOI 10.1145/1614390.1614395
   Shen Chia., 2004, CHI 04, P167, DOI DOI 10.1145/985692.985714
   Ullmer B., 1997, Proceedings of the ACM Symposium on User Interface Software and Technology. 10th Annual Symposium. UIST '97, P223, DOI 10.1145/263407.263551
   Wright M., 2005, Organised Sound, V10, P193
NR 35
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2016
VL 75
IS 1
BP 425
EP 463
DI 10.1007/s11042-014-2298-2
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA5QB
UT WOS:000367856500021
DA 2024-07-18
ER

PT J
AU Leng, L
   Teoh, ABJ
   Li, M
   Khan, MK
AF Leng, Lu
   Teoh, Andrew Beng Jin
   Li, Ming
   Khan, Muhammad Khurram
TI Orientation range of transposition for vertical correlation suppression
   of 2DPalmPhasor Code
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Orientation range of transposition; 2DPalmPhasor Code; Vertical
   correlation suppression; Correlation analysis
AB Two-dimensional PalmPhasor Code (2DPPC) was proposed as a means of cancelable palmprint coding scheme for secure palmprint template protection. 2DPPC is generated from Gabor features, whereby palmprint image and 2DGabor filters are convoluted. However, vertical correlation (VC), which is a notion of inherent correlation between the vertically adjacent entries in 2DPPC, can weaken the robustness against statistical analysis attacks. When the orientation of 2DGabor filter approaches vertical orientation, the real and imaginary parts of Gabor features can be transposed to suppress the VC in 2DPPC. Yet, the VC analysis and orientation range of transposition for 2DPPC generation are remained unsolved. In this paper, we attempt to bridge the relation between the orientation of 2DGabor filter and the VC in 2DPPC. By following the analysis, we determine the exact orientation range of transposition for VC suppression.
C1 [Leng, Lu; Teoh, Andrew Beng Jin] Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, Seoul 120749, South Korea.
   [Leng, Lu; Li, Ming] Nanchang Hangkong Univ, Key Lab Nondestruct Test, Minist Educ, Nanchang 330063, Peoples R China.
   [Khan, Muhammad Khurram] King Saud Univ, Riyadh 11653, Saudi Arabia.
C3 Yonsei University; Nanchang Hangkong University; King Saud University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Coll Engn, Seoul 120749, South Korea.
EM bjteoh@yonsei.ac.kr
RI Khan, Muhammad/IXN-8470-2023; KHAN, MUHAMMAD KHURRAM/E-4836-2014; Nusa,
   Nuhammad/JXY-5819-2024; Teoh, Andrew Beng Jin/F-4422-2010
OI KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533; Teoh, Andrew Beng
   Jin/0000-0001-5063-9484
FU Institute of BioMed-IT, Energy-IT and Smart-IT Technology (BEST), a
   Brain Korea 21 Plus Program, Yonsei University; Basic Science Research
   Program through the National Research Foundation (NRF) of Korea -
   Ministry of Science, ICT and Future Planning [2013006574]
FX This work has been supported by Institute of BioMed-IT, Energy-IT and
   Smart-IT Technology (BEST), a Brain Korea 21 Plus Program, Yonsei
   University, and by Basic Science Research Program through the National
   Research Foundation (NRF) of Korea funded by Ministry of Science, ICT
   and Future Planning (2013006574).
CR [Anonymous], INT C BIOM
   [Anonymous], SCI RES ESS
   Bhatnagar G, 2012, IEEE T SYST MAN CY A, V42, P262, DOI 10.1109/TSMCA.2011.2147307
   Blondel VD, 2000, AUTOMATICA, V36, P1249, DOI 10.1016/S0005-1098(00)00050-9
   Cheung KH, 2005, CISST '05: PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY: COMPUTER GRAPHICS, P40
   Cheung KH, 2005, LECT NOTES ARTIF INT, V3683, P1168
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   Cui JR, 2015, MULTIMED TOOLS APPL, V74, P10989, DOI 10.1007/s11042-014-1887-4
   De Marsico M, 2014, MULTIMED TOOLS APPL, V73, P109, DOI 10.1007/s11042-012-1279-6
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hammami M, 2014, MULTIMED TOOLS APPL, V68, P1023, DOI 10.1007/s11042-012-1109-x
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   JIN A.T.B., 2010, Scholarpedia, V5, P9201
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Jin Teoh AndrewBeng., 2006, 9th International Conference on Control, Automation, Robotics and Vision, (ICARCV'06), P1, DOI DOI 10.1109/ICARCV.2006.345404
   Kong A, 2006, PATTERN RECOGN, V39, P1359, DOI 10.1016/j.patcog.2005.10.025
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kong AWK, 2004, LECT NOTES COMPUT SC, V3072, P761
   Leng L, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P230, DOI 10.1109/ISBAST.2013.40
   Leng L, 2014, NEUROCOMPUTING, V131, P377, DOI 10.1016/j.neucom.2013.10.005
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, COMM COM INF SC, V186, P122
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li HJ, 2014, MULTIMED TOOLS APPL, V70, P2331, DOI 10.1007/s11042-012-1240-8
   Ma B, 2014, MULTIMED TOOLS APPL, V72, P637, DOI 10.1007/s11042-013-1372-5
   Peng JL, 2015, MULTIMED TOOLS APPL, V74, P4469, DOI 10.1007/s11042-013-1817-x
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2012, IET BIOMETRICS, V1, P94, DOI 10.1049/iet-bmt.2011.0001
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Teoh ABJ, 2005, PATTERN RECOGN LETT, V26, P1454, DOI 10.1016/j.patrec.2004.11.021
   Teoh ABJ, 2007, IEEE T SYST MAN CY B, V37, P1096, DOI 10.1109/TSMCB.2007.903538
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2012, IEEE SIGNAL PROC LET, V19, P663, DOI 10.1109/LSP.2012.2211589
NR 36
TC 19
Z9 19
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11683
EP 11701
DI 10.1007/s11042-014-2255-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600031
DA 2024-07-18
ER

PT J
AU Rahmani, P
   Dastghaibyfard, G
AF Rahmani, Peyman
   Dastghaibyfard, Gholamhossein
TI A low distortion reversible data hiding scheme for search order coding
   of VQ indices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Vector quantization; Search order coding; Reversible;
   Data hiding; Data embedding
ID VECTOR QUANTIZATION; COMPRESSED IMAGES; SIDE-MATCH; STEGANOGRAPHY;
   STRATEGIES; TABLE; PATH
AB In recent years many reversible data hiding schemes for vector quantization (VQ)-compressed images have been developed. However most of them generate non-legitimate codes as output and make the data hiding behavior detectable. Moreover existing schemes with legitimate outputs usually need side information to achieve reversibility. In this paper a reversible data hiding scheme for VQ-compressed images based on search order coding (SOC) is proposed which generate legitimate SOC codes as output. For each index of the input VQ index table which finds a match in its corresponding SOC path, the indices located in the SOC path are clustered, and then SOC codes of some blocks are changed to SOC code of one of the indices in the same cluster to hide data. Some SOC codes are re-encoded using original index value (OIV) codes for recovery purpose. By the strategy of re-encoding, the proposed scheme doesn't need any side information. The proposed scheme adaptively adjusts the criteria of exchangeability of the indices based on the smoothness level of each image block to prevent appearing spots in the stego-image. Experimental results show that the proposed scheme on average could embed about 0.5 bits per index by only about 0.67 dB degradation of image quality for a set of test images includes smooth an complicated images. Also superiority of the proposed scheme when compared with the previous schemes is confirmed from various aspects; hiding capacity, stego-image quality, the average of the bit rate of the output code, and the execution time.
C1 [Rahmani, Peyman] Islamic Azad Univ, Nourabad Mamasani Branch, Dept Comp Engn, Nourabad Mamasani, Iran.
   [Dastghaibyfard, Gholamhossein] Shiraz Univ, Dept Comp Sci & Engn, Shiraz, Iran.
C3 Islamic Azad University; Shiraz University
RP Rahmani, P (corresponding author), Islamic Azad Univ, Nourabad Mamasani Branch, Dept Comp Engn, Nourabad Mamasani, Iran.
EM rahmani@cse.shirazu.ac.ir; dstghaib@shirazu.ac.ir
RI Rahmani, Peyman/S-9484-2019
OI Rahmani, Peyman/0000-0002-9606-277X
CR [Anonymous], INT J COMPUT ELECT E
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1253, DOI 10.1016/j.patrec.2004.04.003
   Chang CC, 2007, IEEE T INF FOREN SEC, V2, P341, DOI 10.1109/TIFS.2007.902683
   Chang CC, 2007, J VIS COMMUN IMAGE R, V18, P207, DOI 10.1016/j.jvcir.2006.11.005
   Chang CC, 2006, IEEE T INF FOREN SEC, V1, P493, DOI 10.1109/TIFS.2006.885034
   Chang CC, 2006, J SYST SOFTWARE, V79, P1120, DOI 10.1016/j.jss.2005.11.576
   Chang CC, 2013, J SYST SOFTWARE, V86, P389, DOI 10.1016/j.jss.2012.09.001
   Chang CC, 2012, INFORM SCIENCES, V201, P70, DOI 10.1016/j.ins.2011.12.025
   Chang CC, 2011, J VIS COMMUN IMAGE R, V22, P664, DOI 10.1016/j.jvcir.2011.06.005
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang CC, 2009, J VIS COMMUN IMAGE R, V20, P57, DOI 10.1016/j.jvcir.2008.08.005
   Chen WJ, 2009, DIGIT SIGNAL PROCESS, V19, P433, DOI 10.1016/j.dsp.2008.11.003
   Chang CC, 2007, INFORM SCIENCES, V177, P1796, DOI 10.1016/j.ins.2006.09.014
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   Hsieh CH, 1996, IEEE T IMAGE PROCESS, V5, P1579, DOI 10.1109/83.541428
   Kim TJ, 1992, IEEE T IMAGE PROCESS, V1, P170, DOI 10.1109/83.136594
   Lee JD, 2013, INFORM SCIENCES, V221, P419, DOI 10.1016/j.ins.2012.09.020
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lu ZM, 2009, J SYST SOFTWARE, V82, P1016, DOI 10.1016/j.jss.2009.01.010
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Pan ZB, 2013, J SYST SOFTWARE, V86, P2863, DOI 10.1016/j.jss.2013.06.066
   Qin C, 2013, SIGNAL PROCESS, V93, P2687, DOI 10.1016/j.sigpro.2013.03.036
   Shie SC, 2009, COMPUT STAND INTER, V31, P1143, DOI 10.1016/j.csi.2008.12.003
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, IET IMAGE PROCESS, V3, P100, DOI 10.1049/iet-ipr.2007.0220
   Wang JX, 2009, INFORM SCIENCES, V179, P3332, DOI 10.1016/j.ins.2009.05.021
   Wang WJ, 2013, INFORM SCIENCES, V246, P69, DOI 10.1016/j.ins.2013.05.007
   Wang ZH, 2010, J SYST SOFTWARE, V83, P2073, DOI 10.1016/j.jss.2010.06.007
   Wu MN, 2008, CIRC SYST SIGNAL PR, V27, P137, DOI 10.1007/s00034-008-9026-y
   Yang CH, 2011, J SYST SOFTWARE, V84, P388, DOI 10.1016/j.jss.2010.11.924
   Yang CH, 2011, INFORM SCIENCES, V181, P2218, DOI 10.1016/j.ins.2011.01.015
   Yang CH, 2010, J VIS COMMUN IMAGE R, V21, P334, DOI 10.1016/j.jvcir.2010.02.008
   Yang CH, 2009, J VIS COMMUN IMAGE R, V20, P399, DOI 10.1016/j.jvcir.2009.04.001
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
NR 35
TC 8
Z9 8
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10713
EP 10734
DI 10.1007/s11042-014-2200-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700026
DA 2024-07-18
ER

PT J
AU Yang, HY
   Wang, P
   Wang, XY
   Niu, PP
   Miao, EN
   Zhang, Y
AF Yang, Hong-ying
   Wang, Pei
   Wang, Xiang-yang
   Niu, Pan-pan
   Miao, E-no
   Zhang, Yan
TI Robust digital watermarking based on local invariant radial harmonic
   fourier moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Local geometric distortions; Radial harmonic Fourier
   moment; Speeded-up robust features
ID IMAGE WATERMARKING; DETECTORS
AB It is a challenging work to design a robust image watermarking scheme against local geometric distortions. Radial harmonic Fourier moments (RHFMs) is a powerful tool in image processing owing to its better image description capability, lower noise sensitivity, and geometric invariance property. Based on SURF (Speeded-up robust features) detector and invariant RHFMs, we proposed a robust image watermarking scheme against local geometric distortions in this paper. Firstly, the SURF detector, which is a fast and highly performant multiscale feature detector, is used to extract image feature points in original image. Secondly, the stable and non-overlapped local circular regions centered at feature points are thereafter constructed and selected by combining characteristic scales and feature points refinement. And finally, the digital watermark is embedded in the invariant RHFMs of the local circular regions. Similarly to watermark insertion, the digital watermark can be blindly detected from the local circular regions. Experimental results confirm the validity of our approach and its higher robustness against various attacks (especially local geometric distortions) compared to alternative watermarking methods in the literature.
C1 [Yang, Hong-ying; Wang, Pei; Wang, Xiang-yang; Niu, Pan-pan; Miao, E-no; Zhang, Yan] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [61272416, 60873222,
   60773031]; Open Project Program of Jiangsu Key Laboratory of Image and
   Video Understanding for Social Safety (Nanjing University of Science and
   Technology) [30920130122006]; Open Foundation of Zhejiang Key Laboratory
   for Signal Processing [ZJKL_4_SP-OP2013-01]; Open Foundation of
   Provincial Key Laboratory for Computer Information Processing Technology
   (Soochow University) [KJS1325]; Open Project Program of State Key Lab of
   CAD&CG, Zhejiang University [A1425]; Liaoning Research Project for
   Institutions of Higher Education of China [L2013407]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61272416, 60873222, & 60773031, the Open Project
   Program of Jiangsu Key Laboratory of Image and Video Understanding for
   Social Safety (Nanjing University of Science and Technology) under Grant
   No. 30920130122006, the Open Foundation of Zhejiang Key Laboratory for
   Signal Processing under Grant No. ZJKL_4_SP-OP2013-01, the Open
   Foundation of Provincial Key Laboratory for Computer Information
   Processing Technology (Soochow University) under Grant No. KJS1325, the
   Open Project Program of the State Key Lab of CAD&CG (Grant No. A1425),
   Zhejiang University, and Liaoning Research Project for Institutions of
   Higher Education of China under Grant No. L2013407.
CR Barni M, 2005, IEEE SIGNAL PROC LET, V12, P158, DOI 10.1109/LSP.2004.840872
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Cao J, 2012, IEEE T INF FOREN SEC, V7, P821, DOI 10.1109/TIFS.2012.2184093
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Deng Cheng, 2010, Acta Automatica Sinica, V36, P221, DOI 10.3724/SP.J.1004.2010.00221
   Gauglitz S, 2011, INT J COMPUT VISION, V94, P335, DOI 10.1007/s11263-011-0431-5
   Kuo WC, 2013, J INFORM HIDING MULT, V4, P127
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Li LD, 2012, INFORM SCIENCES, V199, P1, DOI 10.1016/j.ins.2012.02.062
   [李旭东 LI Xu-dong], 2010, [光电工程, Opto-Electronic Engineering], V37, P96
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Liu HJ, 2012, PROC SPIE, V8303, DOI 10.1117/12.907861
   Maity SP, 2013, J SYST SOFTWARE, V86, P47, DOI 10.1016/j.jss.2012.06.057
   Nasir I, 2012, IET IMAGE PROCESS, V6, P354, DOI 10.1049/iet-ipr.2010.0421
   Nikolaidis A., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2729, DOI 10.1109/ICIP.2011.6116233
   Ren HP, 2003, J OPT SOC AM A, V20, P631, DOI 10.1364/JOSAA.20.000631
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Su P, 2013, IEEE T SIGNAL PROCES, V51, P950
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Tsougenis ED, 2012, J SYST SOFTWARE, V85, P1864, DOI 10.1016/j.jss.2012.02.045
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Valizadeh A, 2012, IEEE T INF FOREN SEC, V7, P1127, DOI 10.1109/TIFS.2012.2199312
   Wang XY, 2012, APPL SOFT COMPUT, V12, P887, DOI 10.1016/j.asoc.2011.10.003
   Yuan XC, 2013, SIGNAL PROCESS, V93, P2087, DOI 10.1016/j.sigpro.2013.01.024
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
NR 29
TC 6
Z9 6
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10559
EP 10579
DI 10.1007/s11042-014-2187-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700019
DA 2024-07-18
ER

PT J
AU Cao, XQ
   Liu, ZQ
AF Cao, Xiao-Qin
   Liu, Zhi-Qiang
TI Sequential Markov random fields for human body parts tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human action; Body part detector; Sequential Monte Carlo; Markov random
   fields
ID PARTICLE; MODEL
AB This paper presents a novel human body part tracker called sequential Markov random fields (SMRFs), which can be used to extract spatiotemporal features in human action recognition. Given a video sequence of human action in the monocular settings, SMRF can effectively detect the key spatiotemporal feature points on human body parts. We also develop efficient learning algorithms for the SMRF tracker using relaxation labeling (RL). Our results show that the SMRF tracker performs better than some state-of-the-art trackers for human action recognition.
C1 [Cao, Xiao-Qin; Liu, Zhi-Qiang] City Univ Hong Kong, Sch Creat Media, Kowloon Tong, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Cao, XQ (corresponding author), City Univ Hong Kong, Sch Creat Media, Tat Chee Ave 83, Kowloon Tong, Hong Kong, Peoples R China.
EM xiaoqcao@student.cityu.edu.hk; zq.liu@cityu.edu.hk
FU GRF grant from RGC UGC Hong Kong (GRF) [9041574]; City University of
   Hong Kong [7008026]; NSFC [61003154, 61373092, 61033013]; Natural
   Science Foundation of the Jiangsu Higher Education Institutions of China
   [12KJA520004]; Innovative Research Team in Soochow University
   [SDT2012B02]
FX This work is supported by a GRF grant from RGC UGC Hong Kong (GRF
   Project No. 9041574) and a grant from City University of Hong Kong
   (Project No. 7008026). It is partly supported by by NSFC (Grant No.
   61003154, 61373092 and 61033013), Natural Science Foundation of the
   Jiangsu Higher Education Institutions of China (Grant No. 12KJA520004)
   and Innovative Research Team in Soochow University (Grant No.
   SDT2012B02).
CR [Anonymous], 2009, CVPR
   [Anonymous], 2001, COMP SCI W
   [Anonymous], 2008, CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], P BRIT MACH VIS C
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Gu BY, 2001, INFORM SCIENCES, V138, P79, DOI 10.1016/S0020-0255(01)00127-X
   Hue C, 2002, IEEE T SIGNAL PROCES, V50, P309, DOI 10.1109/78.978386
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kato H, 2004, IEEE T INTELL TRANSP, V5, P142, DOI 10.1109/TITS.2004.833791
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lee MW, 2009, IEEE T PATTERN ANAL, V31, P27, DOI 10.1109/TPAMI.2008.35
   MAGNENATTHALMANN N, 1991, IEEE COMPUT GRAPH, V11, P32, DOI 10.1109/38.90566
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Song Y, 2003, IEEE T PATTERN ANAL, V25, P814, DOI 10.1109/TPAMI.2003.1206511
   Tomasi Carlo, 1991, Image Rochester NY, DOI DOI 10.1016/S0031-3203(03)00234-6
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   Wu Y, 2006, IEEE T PATTERN ANAL, V28, P753, DOI 10.1109/TPAMI.2006.87
   Wu Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1094, DOI 10.1109/ICCV.2003.1238471
   Yang CJ, 2005, IEEE I CONF COMP VIS, P212
   Yu Q, 2009, IEEE T PATTERN ANAL, V31, P2196, DOI 10.1109/TPAMI.2008.253
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zeng J., 2009, ICDM
   Zeng J, 2008, IEEE T FUZZY SYST, V16, P747, DOI 10.1109/TFUZZ.2007.905916
   Zeng J, 2008, IEEE T PATTERN ANAL, V30, P767, DOI 10.1109/TPAMI.2007.70734
   Zeng J, 2013, IEEE T PATTERN ANAL, V35, P1121, DOI 10.1109/TPAMI.2012.185
   Zeng J, 2012, J MACH LEARN RES, V13, P2233
   Zeng J, 2010, INFORM SCIENCES, V180, P301, DOI 10.1016/j.ins.2009.09.011
NR 34
TC 0
Z9 0
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 6671
EP 6690
DI 10.1007/s11042-014-1924-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800005
DA 2024-07-18
ER

PT J
AU Demarty, CH
   Penet, C
   Soleymani, M
   Gravier, G
AF Demarty, Claire-Helene
   Penet, Cedric
   Soleymani, Mohammad
   Gravier, Guillaume
TI VSD, a public dataset for the detection of violent scenes in movies:
   design, annotation, analysis and evaluation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based analysis; Multimedia evaluation; Violent scene detection;
   Corpus design; Physical violence definition; Semantic audio concepts;
   Semantic video concepts
ID CLASSIFICATION; AUDIO
AB Content-based analysis to find where violence appears in multimedia content has several applications, from parental control and children protection to surveillance. This paper presents the design and annotation of the Violent Scene Detection dataset, a corpus targeting the detection of physical violence in Hollywood movies. We discuss definitions of physical violence and provide a simple and objective definition which was used to annotate a set of 18 movies, thus resulting in the largest freely-available dataset for such a task. We discuss borderline cases and compare with annotations based on a subjective definition which requires multiple annotators. We provide a detailed analysis of the corpus, in particular regarding the relationship between violence and a set of key audio and visual concepts which were also annotated. The VSD dataset results from two years of benchmarking in the framework of the MediaEval initiative. We provide results from the 2011 and 2012 benchmarks as a validation of the dataset and as a state-of-the-art baseline. The VSD dataset is freely available at the address: http://www.technicolor.com/en/innovation/research-innovation/scientific-data-sharing/violent-scenes-dataset.
C1 [Demarty, Claire-Helene; Penet, Cedric] Technicolor, ZAC Champs Blancs, F-35576 Cesson Sevigne, France.
   [Soleymani, Mohammad] Univ London Imperial Coll Sci Technol & Med, London SW7 2AZ, England.
   [Gravier, Guillaume] CNRS Irisa, F-35042 Rennes, France.
C3 Technicolor SA; Imperial College London; Universite de Rennes; Centre
   National de la Recherche Scientifique (CNRS)
RP Demarty, CH (corresponding author), Technicolor, ZAC Champs Blancs, 975 Ave Champs Blancs, F-35576 Cesson Sevigne, France.
EM claire-helene.demarty@technicolor.com; penetcedric@gmail.com;
   m.soleymani@imperial.ac.uk; guig@irisa.fr
RI Soleymani, Mohammad/AAS-2161-2020
OI Soleymani, Mohammad/0000-0003-2770-7236
FU Quaero Program
FX This work was partially supported by the Quaero Program. We would also
   like to acknowledge the MediaEval Multimedia Benchmark for providing the
   framework to evaluate the task of violent scene detection.
CR Acar E, 2012, MEDIAEVAL 2012
   Acar E, 2011, MEDIAEVAL 2011
   [Anonymous], 2001, P 9 ACM INT C MULT
   [Anonymous], TRECVID 2011 TREC VI
   [Anonymous], MEDIAEVAL 2012 MULT
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   de Souza F. D. M., 2010, Proceedings of the 23rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2010), P224, DOI 10.1109/SIBGRAPI.2010.38
   Demarty C-H, 2011, MEDIAEVAL 2012 WORKS, V927
   Demarty C-H, 2011, CEUR WORKSHOP P, P807
   Demarty CH, 2012, LECT NOTES COMPUT SC, V7585, P416, DOI 10.1007/978-3-642-33885-4_42
   Derbas N, 2012, MEDIAEVAL 2012
   Giannakopoulos T, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P90, DOI 10.1109/MMSP.2007.4412825
   Giannakopoulos T, 2006, LECT NOTES COMPUT SC, V3955, P502
   Giannakopoulos T, 2010, LECT NOTES ARTIF INT, V6040, P91, DOI 10.1007/978-3-642-12842-4_13
   Gninkoun G, 2011, MEDIAEVAL 2011
   Gong Y, 2008, LECT NOTES COMPUT SC, V5353, P317, DOI 10.1007/978-3-540-89796-5_33
   Jiang Y-G, 2012, MEDIAEVAL 2012
   Kriegel B., 2003, TECHNICAL REPORT
   Krug EG, 2002, LANCET, V360, P1083, DOI 10.1016/S0140-6736(02)11133-0
   Lam V, 2011, MEDIAEVAL 2011
   Lam V, 2012, MEDIAEVAL 2011
   Larson M, 2011, CEUR WORKSHOP P, V807
   Larson M, 2012, CEUR WORKSHOP P, V927
   Lei Li, 2012, Proceedings of the 2012 Ninth International Conference on Information Technology: New Generations (ITNG), P7, DOI 10.1109/ITNG.2012.9
   Liang-Hua Chen, 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P119, DOI 10.1109/CGIV.2011.14
   Liang-Hua Chen, 2009, Journal of Multimedia, V4, P248
   Lin JA, 2009, LECT NOTES COMPUT SC, V5879, P930
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1057, DOI 10.1109/TCSVT.2010.2057013
   Marszalek M., 2009, IEEE C COMP VIS PATT
   Moncrieff S., 2001, P IEEE INT C MULT EX, P989
   Penet C, 2011, CEUR WORKSHOP P, V807
   Penet C, 2012, MEDIAEVAL 2012
   Perperis T, 2011, EXPERT SYST APPL, V38, P14102, DOI 10.1016/j.eswa.2011.04.219
   Safadi B, 2011, MEDIAEVAL 2011
   Schluter J, 2012, MEDIAEVAL 2012
   Vasconcelos N, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P25, DOI 10.1109/ICIP.1997.647375
   Wang SH, 2008, IEEE IMAGE PROC, P2508, DOI 10.1109/ICIP.2008.4712303
   World Health Organization, 1996, GLOB CONS VIOL HLTH
   Yan Chen, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P95, DOI 10.1109/IBICA.2011.28
   Zajdel W, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P200, DOI 10.1109/AVSS.2007.4425310
NR 40
TC 38
Z9 40
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 17
BP 7379
EP 7404
DI 10.1007/s11042-014-1984-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP7MI
UT WOS:000360071800035
DA 2024-07-18
ER

PT J
AU Huang, ZP
   Gong, GH
   Han, L
AF Huang, Zhanpeng
   Gong, Guanghong
   Han, Liang
TI Physically-based smoke simulation for computer graphics: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Smoke and gaseous phenomena; Physically-based methods; Animation
   control; Real-time rendering
ID ADAPTIVE MESH REFINEMENT; VORTEX METHODS; FLUID; ANIMATION; TURBULENCE;
   COMPUTATION; PROJECTION; FLOWS; FIRE
AB We present an up-to-date survey on physically-based smoke simulation. Physically-based method becomes predominant in smoke simulation in computer graphics community. It prevails over traditional methods for its plausible visual effect. Significant results have been carried out over past two decades. We give a latest overview of state-of-the-art of smoke simulation and also compare various techniques according to their characteristics. We discuss several issues in terms of computational efficiency, numerical stability, numerical dissipation, and runtime performance. A number of open challenging problems are also addressed for further exploration.
C1 [Huang, Zhanpeng; Gong, Guanghong; Han, Liang] Beijing Univ Aeronaut & Astronaut, Sch Automat Sci & Elect Engn, Beijing 100083, Peoples R China.
C3 Beihang University
RP Huang, ZP (corresponding author), Beijing Univ Aeronaut & Astronaut, Sch Automat Sci & Elect Engn, Beijing 100083, Peoples R China.
EM soaroc@asee.buaa.edu.cn; ggh@buaa.edu.cn; hanliang@buaa.edu.cn
RI Han, Liang/KFR-6745-2024
CR [Anonymous], P SIGGRAPH LOS ANG
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], P 20 ANN C COMP GRAP
   [Anonymous], THESIS U CALIFORNIA
   [Anonymous], P ACM SIGGRAPH EUR S
   [Anonymous], FLUID SIMULATION FO
   [Anonymous], 2005, Technical report
   [Anonymous], 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, DOI DOI 10.1145/1073368.1073380
   [Anonymous], P ACM SIGGRAPH EUR S
   [Anonymous], 2004, GPU gems
   Azevedo VC, 2013, COMPUT GRAPH FORUM, V32, P235, DOI 10.1111/cgf.12231
   Batchelor G.K., 1965, An Introduction to Fluid Dynamics
   BATTY C, 2007, P ACM SIGGRAPH
   BERGER MJ, 1989, J COMPUT PHYS, V82, P64, DOI 10.1016/0021-9991(89)90035-1
   BERGER MJ, 1984, J COMPUT PHYS, V53, P484, DOI 10.1016/0021-9991(84)90073-1
   Bolz J, 2003, ACM T GRAPHIC, V22, P917, DOI 10.1145/882262.882364
   BRACKBILL JU, 1986, J COMPUT PHYS, V65, P314, DOI 10.1016/0021-9991(86)90211-1
   Bridson R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276435, 10.1145/1239451.1239497]
   Cook RL, 2005, ACM T GRAPHIC, V24, P803, DOI 10.1145/1073204.1073264
   CRANE K, 2007, GPU GEMS 3 REAL TIME
   Drone S., 2007, SIGGRAPH 07, P80
   Ebert D. S., 1990, Computer Graphics, V24, P357, DOI 10.1145/97880.97918
   Fattal R, 2004, ACM T GRAPHIC, V23, P441, DOI 10.1145/1015706.1015743
   FELDMAN BE, 2005, ACM SIGGRAPH EUR S C
   Foster N., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P181, DOI 10.1145/258734.258838
   Foster N, 1996, GRAPH MODEL IM PROC, V58, P471, DOI 10.1006/gmip.1996.0039
   Foster N, 1997, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P178, DOI 10.1109/CGI.1997.601299
   Foster N, 2001, COMP GRAPH, P23, DOI 10.1145/383259.383261
   Gamito M. N., 1995, Computer Animation and Simulation '95. Proceedings of the Eurographics Workshop, P3
   Gardner G. Y., 1985, Computer Graphics, V19, P297, DOI 10.1145/325165.325248
   Golas A, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366167
   Goodnight N., 2003, P ACM SIGGRAPHEUROGR, P102
   HARLOW FH, 1965, PHYS FLUIDS, V8, P2182, DOI 10.1063/1.1761178
   He S, 2013, COMPUT GRAPH FORUM, V32, P27, DOI 10.1111/j.1467-8659.2012.03228.x
   Hong JM, 2004, COMPUT ANIMAT VIRT W, V15, P147, DOI 10.1002/cav.17
   Horvath C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531347
   Huang RG, 2013, VISUAL COMPUT, V29, P751, DOI 10.1007/s00371-013-0798-0
   Ihm I., 2004, PROC 2004 ACM SIGGRA, P203
   Kajiya J. T., 1984, Computers & Graphics, V18, P165
   Kharevych L, 2009, ACM T GRAPHIC, V28, DOI [10.1145/1531326.1531357, 10.1145/15313261531357]
   Kim D, 2008, COMPUT GRAPH FORUM, V27, P467, DOI 10.1111/j.1467-8659.2008.01144.x
   Kim D, 2012, IEEE T VIS COMPUT GR, V18, P1488, DOI 10.1109/TVCG.2011.264
   Kipfer P., 2004, GRAPHICS HARDWARE, P115
   KLINGNER BM, 2006, P ACM SIGGRAPH
   Lentine M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778851
   Li W, 2003, VISUAL COMPUT, V19, P444, DOI 10.1007/s00371-003-0210-6
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   McAdams A., 2010, EUR ACM SIGGRAPH S C
   McNamara A, 2004, ACM T GRAPHIC, V23, P449, DOI 10.1145/1015706.1015744
   Muller Matthias., 2008, ACM SIGGRAPH 2008 CL, P1, DOI [DOI 10.1145/1401132.1401245, 10.1145/1401132.1401245]
   Nguyen DQ, 2002, ACM T GRAPHIC, V21, P721, DOI 10.1145/566570.566643
   Park S. I., 2005, Computer Animation, Conference Proceedings, P261, DOI [DOI 10.1145/1073368.1073406, 10.1145/1073368.1073406]
   Perlin K., 1985, Computer Graphics, V19, P287, DOI 10.1145/325165.325247
   PFAFF T, 2012, ACM T GRAPHIC, V31, pNIL_0944, DOI DOI 10.1145/2185520.2185608
   Pfaff T, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866196
   Pfaff T, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618467
   Ploumhans P, 2002, J COMPUT PHYS, V178, P427, DOI 10.1006/jcph.2002.7035
   Ploumhans P, 2000, J COMPUT PHYS, V165, P354, DOI 10.1006/jcph.2000.6614
   Rasmussen N, 2003, ACM T GRAPHIC, V22, P703, DOI 10.1145/882262.882335
   REEVES WT, 1983, ACM T GRAPHIC, V2, P91, DOI 10.1145/964967.801167
   Sakas G., 1993, Visual Computer, V9, P200, DOI 10.1007/BF01901724
   Schechter H., 2008, Symposium on Computer animation, P1
   Selle Andrew., 2008, J SCI COMPUT
   Song OY, 2005, ACM T GRAPHIC, V24, P81, DOI 10.1145/1037957.1037962
   Stam J, 1999, COMP GRAPH, P121, DOI 10.1145/311535.311548
   Stam J, 2000, COMMUN ACM, V43, P76, DOI 10.1145/341852.341866
   Stam J., 2001, Journal of Graphics Tools, V6, P43, DOI 10.1080/10867651.2001.10487540
   Stam Jos., 1995, Proceedings of the 22nd annual conference on Computer graphics and interactive techniques, SIGGRAPH '95, P129
   STEINHOFF J, 1994, PHYS FLUIDS, V6, P2738, DOI 10.1063/1.868164
   Sussman M, 1999, J COMPUT PHYS, V148, P81, DOI 10.1006/jcph.1998.6106
   Treuille A, 2003, ACM T GRAPHIC, V22, P716, DOI 10.1145/882262.882337
   Weissmann S, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778852
   WeiSSmann Steffen., 2009, VRIPHYS, P1
   Wicke M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531345
   Witting P, 1999, COMP GRAPH, P129, DOI 10.1145/311535.311549
   Wu XY, 2013, COMPUT GRAPH FORUM, V32, P389, DOI 10.1111/cgf.12059
   Xu YX, 2012, COMM COM INF SC, V346, P467
   Yaeger L., 1986, Computer Graphics, V20, P85, DOI 10.1145/15886.15895
   Yang B, 2013, COMPUT GRAPH-UK, V37, P775, DOI 10.1016/j.cag.2013.05.001
   Yngve GD, 2000, COMP GRAPH, P29, DOI 10.1145/344779.344801
   Yuan Z, 2011, ACM T GRAPHIC, V30, P6, DOI DOI 10.1145/2070781.2024170
   Zhu Y. L., 2005, THESIS
   Zhu YN, 2005, ACM T GRAPHIC, V24, P965, DOI 10.1145/1073204.1073298
   ZHUANG LC, 2009, FLUID MECH
   Zuo Q, 2013, VISUAL COMPUT, V29, P883, DOI 10.1007/s00371-013-0848-7
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 126
TC 4
Z9 6
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7569
EP 7594
DI 10.1007/s11042-014-1992-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200008
DA 2024-07-18
ER

PT J
AU Pun, CM
   Yuan, XC
AF Pun, Chi-Man
   Yuan, Xiao-Chen
TI Histogram modification based image watermarking resistant to geometric
   distortions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometrically invariant; Histogram modification; Feature extraction;
   Adaptive Harris Detector with simulated attacks
ID FEATURE POINTS; ROBUST; SCHEME
AB A geometrically invariant digital image watermarking scheme based on histogram modification is proposed in this paper. The feature extraction method called Adaptive Harris Detector with Simulated Attacks is proposed and employed, which adjusts and ranks the response threshold value of the traditional Harris Corner Detector, and trains the input image with several simulated attacks, to extract the most reliable feature points for watermark data bits embedding and extraction. The watermark embedding regions are then found as square patches centering at the selected geometric invariant feature points. In each region, the intensity-level histogram is modified by moving some pixels to form a specific pattern according to the corresponding watermark bit. For watermark extraction, the proposed Adaptive Harris Detector with Simulated Attacks is proposed to restore the watermarked image to its original position if any geometric attack exists, and to retrieve the watermarked regions. According to the pattern of intensity-level histogram distribution in these regions, a sequence of watermark bits is then extracted. Experimental results show that the proposed scheme is robust against both the geometric attacks and common signal processing, such as rotation, scaling, cropping, JPEG compression, median filtering, low-pass Gaussian filtering and also noise pollution.
C1 [Pun, Chi-Man; Yuan, Xiao-Chen] Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
C3 University of Macau
RP Yuan, XC (corresponding author), Univ Macau, Dept Comp & Informat Sci, Macau, Peoples R China.
EM cmpun@umac.mo; xcyuan@umac.mo
RI Yuan, Xiaochen/ABH-5255-2020; Pun, Chi Man/GRJ-3703-2022
OI Yuan, Xiaochen/0000-0002-7490-6695; Pun, Chi-Man/0000-0003-1788-3746
FU Research Committee of the University of Macau [MYRG134-FST11-PCM,
   MYRG181-FST11-PCM]; Science and Technology Development Fund of Macau SAR
   [034/2010/A2, 008/2013/A1]
FX The authors would like to thank the referees for their valuable
   comments. This research was supported in part by Research Committee of
   the University of Macau (MYRG134-FST11-PCM and MYRG181-FST11-PCM) and
   the Science and Technology Development Fund of Macau SAR (Project No.
   034/2010/A2 and 008/2013/A1).
CR Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   [Anonymous], 1980, CMURITR8003 STANF U
   Bas P, 2000, PROC SPIE, V3971, P99, DOI 10.1117/12.385013
   Filipe J, 2009, COMMUN COMPUT PHYS, V48, P345, DOI DOI 10.1007/978-3-642-05197-5_
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Harris CG, 1988, P ALV VIS C
   Lee HY, 2006, OPT ENG, V45, DOI 10.1117/1.2181887
   Lin CH, 2006, IEE P-VIS IMAGE SIGN, V153, P483, DOI 10.1049/ip-vis:20050107
   Lin YT, 2011, IET IMAGE PROCESS, V5, P328, DOI 10.1049/iet-ipr.2009.0264
   Liu Y, 2006, INT C COMMUN CIRCUIT, P49
   Nasir I, 2012, IET IMAGE PROCESS, V6, P354, DOI 10.1049/iet-ipr.2010.0421
   Pereira S, 2000, IEEE T IMAGE PROCESS, V9, P1123, DOI 10.1109/83.846253
   Pun CM, 2009, ADV MULTIMEDIA INFOR, P2009
   Seo JS, 2004, PATTERN RECOGN, V37, P1365, DOI 10.1016/j.patcog.2003.12.013
   Su PC, 2013, IEEE T INF FOREN SEC, V8, P1897, DOI 10.1109/TIFS.2013.2282121
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Tsai JS, 2012, SIGNAL PROCESS, V92, P1431, DOI 10.1016/j.sigpro.2011.11.033
   Yoo HM, 2009, CONS COMM NETW C 200, P1
   Yu YW, 2006, SIGN PROC 2006 8 INT
   Yuan X, 2011, COMP GRAPH IM VIS CG, P109, DOI [10.1109/CGIV.2011.22, DOI 10.1109/CGIV.2011.22]
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
   Zheng F., 2006, IEEE P 2006 INT C IN, P79
NR 23
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2015
VL 74
IS 18
BP 7821
EP 7842
DI 10.1007/s11042-014-2025-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ1RV
UT WOS:000360377200019
DA 2024-07-18
ER

PT J
AU Park, D
   Park, S
AF Park, Daewon
   Park, Suhyun
TI E-Navigation-supporting data management system for variant S-100-based
   data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE E-navigation; S-100; Data management system; S-100-based data;
   Geographic information
ID INFORMATION; GIS
AB Currently the International Maritime Organization (IMO) is taking the lead in developing e-navigation as an information service framework. E-navigation supports sharing, harmonization and utilization of various marine and marine-related data both shipboard and onshore. Recently, the IMO adopted the International Hydrographic Organization (IHO)'s S-100 as the basis of the Common Maritime Data Structure (CMDS) of e-navigation. Thus, the various data are to be provided to e-navigation services in formats consistent with the S-100 data model. E-navigation services, in order to provide appropriate information to users, utilize and harmonize many kinds of S-100-based data such as Electronic Navigation Chart (ENC) data, bathymetric data, tidal data, meteorology data, radar-image data, and Automatic Identification System (AIS) data. In e-navigation, data management systems dealing with S-100-based data facilitate e-navigation services' harmonization and utilization of the various S-100-based data. In this paper, we present an S-100 data management system that deals with various S-100-based data. We designed the system by generalization of the System ENC (SENC) kernel that manages S-101 ENC data. For development of a data management system that supports the management of various kinds of S-100-based data, we analyzed the characteristics of the S-100 data model and S-100-based data products. The S-100 data management system is designed to store S-100-based feature-oriented geographic data in the form of < key, value > pairs.
C1 [Park, Daewon] Pusan Natl Univ, Dept Comp Sci & Engn, Busan 609735, South Korea.
   [Park, Suhyun] Dongseo Univ, Div Comp & Informat Engn, Busan 617716, South Korea.
C3 Pusan National University; Dongseo University
RP Park, S (corresponding author), Dongseo Univ, Div Comp & Informat Engn, Jureyro 47, Busan 617716, South Korea.
EM mr.daewonpark@gmail.com; subak63@gmail.com
FU IT R&D program of MOTIE/KEIT [10041790]; Brain Busan 21 Project
FX This work was partially supported by the IT R&D program of MOTIE/KEIT
   [10041790, Development of Advanced Ship Navigation Supporting System
   based on Oncoming International Marine Data Standard] and the Brain
   Busan 21 Project in 2013.
CR Abdelmoty A. I., 1994, LNCS, V856, P445
   Alexander L., 2010, CAN HYDR C
   Almeida CN, 2013, JAWRA J AM WATER RES
   [Anonymous], 2018, S 100 UN HYDR DAT MO
   Arctur D., 2004, Designing geodatabases: case studies in GIS data modeling
   Austin M, 2005, OCEANS-IEEE, P839
   Bergmann M, 2013, MARINE NAVIGATION SA, P63
   Burrough P.A., 1998, PRINCIPLES GEOGRAPHI, V333
   Chang K., 2010, Introduction to Geographic Information Systems
   Gardner CJC, 1999, HYDROGRAPHIC C P
   International Hydrographic Organization, 2018, S 210 INTERVTS EXCH
   Jones CB, 1996, INT J GEOGR INF SYST, V10, P901, DOI 10.1080/026937996137648
   Longley P. A., 2005, Geographic Information Systems and Science
   Malyankar R., 2011, ENAV10INF7 IALA
   Neal G.M., 2014, HYDROGRAPHIC DATA MA
   Neteler M, 2012, ENVIRON MODELL SOFTW, V31, P124, DOI 10.1016/j.envsoft.2011.11.014
   Park D, 2013, INT C IT CONV SEC IC, P1
   Park D., 2013, ADV SCI TECHNOLOGY E, V44, P40
   Patraiko D, 2007, ADV MARINE NAVIGATIO
   Patraiko D., 2007, INTRO E NAVIGATION R
   WARD R, 2009, INT HYDROGR REV, V1, P44
   WORBOYS MF, 1994, INT J GEOGR INF SYST, V8, P385, DOI 10.1080/02693799408902008
NR 22
TC 7
Z9 8
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6573
EP 6588
DI 10.1007/s11042-014-2242-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700032
DA 2024-07-18
ER

PT J
AU Chen, X
   Zhao, Y
AF Chen, Xu
   Zhao, Yue
TI A linear approach for determining camera intrinsic parameters using
   tangent circles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera intrinsic parameters; Circular points; Vanishing point; Tangent
   circle
ID QUASI-AFFINE INVARIANCE; CALIBRATION
AB A linear approach using three tangent circles is proposed for determining the intrinsic parameters of cameras. A projected circle can be used to compute the image coordinate of the centre of each tangent circle and to find the points in the image corresponding to the tangent points associated with the images of the centres of the projected circles. The vanishing point can be determined along the circle diameter according to the invariance of the cross-ratio. Solving the equations for the tangent lines produced a curve in the image of the tangent point and its corresponding point. The other vanishing point can be obtained from the intersection point of the two tangent lines. With vanishing points in two orthogonal directions, the intrinsic parameters can be linearly determined. The results of our experiments show that this approach is effective and highly precise.
C1 [Chen, Xu] Yunnan Univ, Lijiang Tourism & Culture Coll, Kunming, Yunnan, Peoples R China.
   [Zhao, Yue] Yunnan Univ, Sch Math & Stat, Kunming, Yunnan, Peoples R China.
C3 Yunnan University; Yunnan University
RP Zhao, Y (corresponding author), Yunnan Univ, Sch Math & Stat, Kunming, Yunnan, Peoples R China.
EM zhao6685@yeah.net
FU Nation Natural Science Foundation of China [11361074]; Natural
   Foundation of Yunnan Province, China [2011FB017]; Scientific Research
   Foundation of Yunnan Education Department of China [2013Y167]
FX The author wishes to thank the anonymous reviewers for their many
   valuable suggestions. This research was supported by the Nation Natural
   Science Foundation of China (No. 11361074), the Natural Foundation of
   Yunnan Province, China (2011FB017), and the Scientific Research
   Foundation of Yunnan Education Department of China (2013Y167).
CR [Anonymous], P 4 ALV VIS C, DOI DOI 10.5244/C.2.23
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Hu Zhaozheng, 2006, Journal of Xi'an Jiaotong University, V40, P1065
   Junejo IN, 2010, COMPUT VIS IMAGE UND, V114, P991, DOI 10.1016/j.cviu.2010.05.003
   Kim JS, 2005, IEEE T PATTERN ANAL, V27, P637, DOI 10.1109/TPAMI.2005.80
   MENG XQ, 2000, P 11 BRIT MACH VIS C, P496
   Richard H., 2000, Multiple View Geometry in ComputerVision
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   Wu L, 2010, COMPUT VIS IMAGE UND, V114, P915, DOI 10.1016/j.cviu.2010.04.003
   Wu YH, 2004, LECT NOTES COMPUT SC, V3021, P190
   Wu YH, 2006, IMAGE VISION COMPUT, V24, P319, DOI 10.1016/j.imavis.2005.11.008
   Yang CJ, 2000, INT C PATT RECOG, P555, DOI 10.1109/ICPR.2000.905398
   Zhang ZY, 1997, J OPT SOC AM A, V14, P2938, DOI 10.1364/JOSAA.14.002938
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao Y, 2011, INT J DIGITAL CONTEN, P249
   Zhao ZJ, 2010, MACH VISION APPL, V21, P301, DOI 10.1007/s00138-008-0162-y
NR 16
TC 6
Z9 6
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5709
EP 5723
DI 10.1007/s11042-014-1879-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100016
DA 2024-07-18
ER

PT J
AU Ding, IJ
   Yen, CT
AF Ding, Ing-Jr
   Yen, Chih-Ta
TI Enhancing GMM speaker identification by incorporating SVM speaker
   verification for intelligent web-based speech applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE EGMM-SVM; Gaussian mixture model; Support vector machine; Speaker
   recognition; GMM likelihood score
ID SUPPORT VECTOR MACHINES; RECOGNITION; ALGORITHM; DISTANCE; KERNEL
AB Speech applications, which operate a system by voice commands, facilitate web access for disabled and visually impaired users. Human-computer interactions, such as speaking and listening to web applications, provide options for developing a multimodal interaction tool in the accessible design of an intelligent web. Speaker identification and verification are essential functionalities for intelligent web programs with speech applications. This paper proposes an enhanced Gaussian mixture model (GMM) method by incorporating the information derived from the support vector machine (SVM), called EGMM-SVM, for web-based applications with speaker recognition. The EGMM-SVM improves the accuracy of the estimated likelihood scores between the speech frame and the GMM. In EGMM-SVM, SVMplays a crucial role in transmitting the quality information of the utterances from a test speaker, through the GMM when performing GMM likelihood calculations. The experimental results show that speaker recognition by using the developed EGMM-SVM with an accurate operation mechanism for Gaussian distribution derivations yields a higher recognition rate than does a conventional GMM without any considerations on the quality of test speech utterances.
C1 [Ding, Ing-Jr; Yen, Chih-Ta] Natl Formosa Univ, Dept Elect Engn, Huwei Township 632, Yunlin County, Taiwan.
C3 National Formosa University
RP Yen, CT (corresponding author), Natl Formosa Univ, Dept Elect Engn, 64 Wunhua Rd, Huwei Township 632, Yunlin County, Taiwan.
EM chihtayen@gmail.com
FU National Science Council (NSC) in Taiwan [NSC 101-2221-E-150-084]
FX This research is partially supported by the National Science Council
   (NSC) in Taiwan under grant NSC 101-2221-E-150-084.
CR Bharkad S, 2012, J INF PROCESS SYST, V8, P85, DOI 10.3745/JIPS.2012.8.1.085
   Boujelbene Z. B., 2010, Int.J. Digit. Cont. Technol. Appl, V4, P100, DOI [10.4156/jdcta.vol4.issue6.12, DOI 10.4156/JDCTA.VOL4.ISSUE6.12]
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Burget L, 2007, IEEE T AUDIO SPEECH, V15, P1979, DOI 10.1109/TASL.2007.902499
   Campbell WM, 2007, IEEE T AUDIO SPEECH, V15, P2085, DOI 10.1109/TASL.2007.902874
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Fan C-I, 2012, J CONVERGENCE, V3, P21
   Gaikwad SK., 2010, INT J COMPUT APPL, V10, P16, DOI DOI 10.5120/1462-1976
   Griol D, 2011, LECT NOTES ARTIF INT, V7023, P393, DOI 10.1007/978-3-642-25274-7_40
   Jourani R, 2011, P INT C MULT COMP SY, P1
   Kenny P, 2007, IEEE T AUDIO SPEECH, V15, P1448, DOI 10.1109/TASL.2007.894527
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   McLaren M, 2010, IEEE T AUDIO SPEECH, V18, P1496, DOI 10.1109/TASL.2009.2035786
   Qiang Zhang, 2009, Proceedings of the 2009 9th International Conference on Electronic Measurement & Instruments (ICEMI 2009), P1, DOI 10.1109/ICEMI.2009.5274002
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Satone MP, 2012, J INF PROCESS SYST, V8, P483
   You CH, 2010, IEEE T AUDIO SPEECH, V18, P1300, DOI 10.1109/TASL.2009.2032950
   You CH, 2009, IEEE SIGNAL PROC LET, V16, P49, DOI 10.1109/LSP.2008.2006711
   Zhang M, 2008, ICIC EXPRESS LETT, V2, P263
NR 19
TC 11
Z9 12
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5131
EP 5140
DI 10.1007/s11042-013-1587-5
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900009
DA 2024-07-18
ER

PT J
AU Hung, JC
   Yen, NY
   Jeong, HY
   Chan, YW
AF Hung, Jason C.
   Yen, Neil Y.
   Jeong, Hwa-Young
   Chan, Yu-Wei
TI Adaptive mechanism for schedule arrangement and optimization in
   socially-empowered professional sports games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sports scheduling; Recommender system; Schedule optimization; Social
   search
ID TABU SEARCH; ALGORITHM
AB World financial crisis has caused a great impact to our daily lives. The price reflects the difficulty not only to transportation but finance status. In this paper, an adaptive scheduling algorithm for professional sports games was proposed, which greatly improved the performance of conventional game-match scheduling results by hybridizing the Tabu Search algorithm and Genetics algorithm. The purpose of this work is to reduce the travelling cost of all teams. The information of famous sports league (e.g. NBA and MLB) was adopted as preliminary experiment data. Using the new method proposed, it is efficient to find better results than approaches developed before. In addition to finding a feasible schedule that meets all the timing restrictions, the problem addressed in this paper has the extra complexity of having the objective of minimizing the travel costs and every team has the balancing number of the games in home. We formalize the scheduling problem into an optimization problem and adopt the concept of evolution strategy, with consideration of sequential events in a socially world, to solve the challenging issue.
C1 [Hung, Jason C.] Overseas Chinese Univ, Dept Informat Management, Taichung, Taiwan.
   [Yen, Neil Y.] Univ Aizu, Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima, Japan.
   [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
   [Chan, Yu-Wei] Chung Chou Univ Sci & Technol, Dept Informat Management, Changhua, Taiwan.
C3 University of Aizu; Kyung Hee University
RP Yen, NY (corresponding author), Univ Aizu, Sch Comp Sci & Engn, Aizu Wakamatsu, Fukushima, Japan.
EM neil219@gmail.com
RI Chan, Yu-Wei/AAC-1420-2019
OI Jeong, Hwa-Young/0000-0002-5017-934X
FU National Science Council, Taiwan [NSC-99-2221-E-240-003]
FX This work is partially supported by the National Science Council,
   Taiwan, under the grants No. "NSC-99-2221-E-240-003". Miller Chien is
   appreciated for his assistance on both implementation and experiment.
CR [Anonymous], J CONVERGENCE
   Baack Thomas., 1996, Evolutionary Algorithms in Theory and Practice
   BALAS E, 1991, OPER RES, V39, P150, DOI 10.1287/opre.39.1.150
   Barone L, 2006, IEEE CEC, P3377
   BEAN JC, 1980, INTERFACES, V10, P98, DOI 10.1287/inte.10.3.98
   Cooper TB, 1996, PRACTICE THEORY AUTO, P281
   COSTA D, 1995, INFOR, V33, P161
   Davidson J, 2000, HOCKEY FOR DUMMIES
   Dinitz J, 1995, HDB COMBINATORIAL DE, P578
   Eiben A. E., 2015, INTRO EVOLUTIONARY C
   Elshaafi H, 2013, J CONVERG, V4, P31
   FRIEZE AM, 1981, J OPER RES SOC, V32, P989, DOI 10.1057/jors.1981.207
   Glover F, 2000, CONTROL CYBERN, V29, P653
   Gopalakrishnan AK, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-17
   Henz M, 2004, EUR J OPER RES, V153, P92, DOI 10.1016/S0377-22l7(03)00101-2
   Hwang YS, 2013, J INF PROCESS SYST, V9, P395
   Ibrahim N, 2013, HUM-CENTRIC COMPUT I, V3, DOI 10.1186/2192-1962-3-1
   Magos D, 1996, J GLOBAL OPTIM, V8, P35
   Matthews HD, 2009, NATURE, V459, P829, DOI 10.1038/nature08047
   McAloon K, 1997, P 1997 ILOG OPT SUIT
   Nemhauser GL, 1998, OPER RES, V46, P1, DOI 10.1287/opre.46.1.1
   RUSSELL RA, 1994, OPER RES, V42, P614, DOI 10.1287/opre.42.4.614
   Saltzman RM, 1996, EUR J OPER RES, V93, P469, DOI 10.1016/0377-2217(96)00135-X
   Sarkar K, 2012, J INF PROCESS SYST, V8, P693
   Searchinger T, 2008, SCIENCE, V319, P1238, DOI 10.1126/science.1151861
   Taylor B.W., 1999, INTRO MANAGEMENT SCI
   Yang JT, 2002, IEEE C EVOL COMPUTAT, P1660, DOI 10.1109/CEC.2002.1004491
NR 27
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 14
BP 5085
EP 5108
DI 10.1007/s11042-014-1852-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XU
UT WOS:000358214900007
DA 2024-07-18
ER

PT J
AU Tang, LL
   Huang, CT
   Pan, JS
   Liu, CY
AF Tang, Lin-Lin
   Huang, Chun Ta
   Pan, Jeng-Shyang
   Liu, Chang-Yong
TI Dual watermarking algorithm based on the Fractional Fourier Transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking techniques; Fractional Fourier Transform (FRFT);
   Gray relational analysis; Binary image
ID AUTHENTICATION
AB A novel dual watermarking algorithm is proposed based on the Fractional Fourier Transform (FRFT) and the digital watermarking techniques in this paper. The 0, 1 sequence is mapped into two different random sequences to realize the robust watermarking process. The gray relational analysis method, the easy blocking method and the hierarchical embedding method are used here. Good performance both in robustness and in fragile in the experiments shows the efficiency of our proposed method. Future research orientations are mentioned in the conclusion.
C1 [Tang, Lin-Lin; Huang, Chun Ta; Pan, Jeng-Shyang; Liu, Chang-Yong] Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci & Technol, IIIRC, Harbin 150006, Peoples R China.
   [Tang, Lin-Lin; Huang, Chun Ta; Pan, Jeng-Shyang; Liu, Chang-Yong] Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
C3 Harbin Institute of Technology; Purdue University System; Purdue
   University
RP Tang, LL (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci & Technol, IIIRC, Harbin 150006, Peoples R China.
EM lltanghit@gmail.com
RI Pan, Jeng-Shyang/AEO-3450-2022
OI Pan, Jeng-Shyang/0000-0002-3128-9025
FU NSFC (National Natural Science Foundation of China) [61202456]; 
   [KQC201109020055A]
FX The authors would like to thank the reviewers for providing very helpful
   comments and suggestions. The authors would also like to thank for the
   support from the project named Research on Multiple Description Coding
   Frames with Watermarking Techniques in Wavelet Domain which belongs to
   the NSFC (National Natural Science Foundation of China) with the Grant
   number 61202456. And we also would like to thank for the support from
   the project named Intelligent vehicle Terminal system with the Grant
   number KQC201109020055A which belongs to the Shenzhen overseas
   high-level talents special funds for innovation and entrepreneurship.
CR ALMEIDA LB, 1994, IEEE T SIGNAL PROCES, V42, P3084, DOI 10.1109/78.330368
   [Anonymous], J INFORM HIDING MULT
   Candan Ç, 2000, IEEE T SIGNAL PROCES, V48, P1329, DOI 10.1109/78.839980
   Deng Julong, 1989, Journal of Grey Systems, V1, P1
   Djurovic I, 2001, J NETW COMPUT APPL, V24, P167, DOI 10.1006/jnca.2000.0128
   Fridrich J, 2002, PROC SPIE, V4675, P691, DOI 10.1117/12.465330
   Kocarev L, 2001, PHYS LETT A, V289, P199, DOI 10.1016/S0375-9601(01)00609-0
   Kocarev L, 2006, IEEE T CIRCUITS-I, V53, P1300, DOI 10.1109/TCSI.2006.874181
   Lin ET, 2000, PROC SPIE, V3971, P152, DOI 10.1117/12.384969
   Loukhaoukha K., 2012, J INF HIDING MULTIME, V3, P135
   Noriega R.M., 2011, J INFORM HIDING MULT, V2, P91
   Phen-Lan Lin, 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P146
   Unoki M., 2011, J INF HIDING MULTIME, V2, P1
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
NR 14
TC 12
Z9 12
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4397
EP 4413
DI 10.1007/s11042-013-1531-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600013
DA 2024-07-18
ER

PT J
AU Song, W
   Cho, K
AF Song, Wei
   Cho, Kyungeun
TI Real-time terrain reconstruction using 3D flag map for point clouds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile robot; Terrain reconstruction; GPU programming; Large-scale point
   cloud; Real-time visualization
AB Mobile robot operators need to make quick decisions based on information about the robot's surrounding environment. This study proposes a graphics processing unit (GPU)-based terrain modeling system for large-scale LiDAR (Light Detection And Ranging) dataset visualization using a voxel map and a textured mesh. A 3D flag map is proposed for incrementally registering large-scale point clouds in a terrain model in real time. The sensed 3D point clouds are quantized into regular 3D grids that are allocated in the GPU memory to remove redundant spatial and temporal points. Subsequently, the sensed vertices are segmented as ground and non-ground classes. The ground indices are rendered using a textured mesh to represent the ground surface, and the non-ground indices, using a colored voxel map by a particle rendering method. The proposed approach was tested using a mobile robot equipped with a LiDAR sensor, video camera, GPS receiver, and gyroscope. The simulation was evaluated through a test in an outdoor environment containing trees and buildings, demonstrating the real-time visualization performance of the proposed method in a large-scale environment.
C1 [Song, Wei] North China Univ Technol, Coll Informat Engn, Beijing 100144, Peoples R China.
   [Song, Wei; Cho, Kyungeun] Dongguk Univ Seoul, Dept Multimedia Engn, Seoul 100715, South Korea.
C3 North China University of Technology; Dongguk University
RP Cho, K (corresponding author), Dongguk Univ Seoul, Dept Multimedia Engn, 26 Pildong 3GaJung Gu, Seoul 100715, South Korea.
EM cke@dongguk.edu
FU Agency for Defense Development, Korea
FX This work was supported by the Agency for Defense Development, Korea.
CR [Anonymous], 2011, US MAN PROGR GUID HD
   Bao XH, 2003, PROC SPIE, V5009, P225, DOI 10.1117/12.473936
   CROWLEY JL, 1989, PROCEEDINGS - 1989 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOL 1-3, P674, DOI 10.1109/ROBOT.1989.100062
   Gingras David, 2010, Proceedings of the 2010 Seventh Canadian Conference on Computer and Robot Vision (CRV 2010), P191, DOI 10.1109/CRV.2010.32
   Haselich M, 2012, ROBOTICS AU IN PRESS
   Huber Daniel, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1518, DOI 10.1109/ICCVW.2009.5457431
   Kammerl J, 2012, IEEE INT CONF ROBOT, P778, DOI 10.1109/ICRA.2012.6224647
   Kim G, 2008, IEEE WORK APP COMP, P145
   Knauer U, 2010, INT ARCH PHOTOGRAMM, V38, P337
   Livny Y, 2009, VISUAL COMPUT, V25, P197, DOI 10.1007/s00371-008-0214-3
   Luo HL, 2011, HUM-CENT COMPUT INFO, V1, DOI 10.1186/2192-1962-1-5
   Matsushita Y, 2011, ROBOT AUTON SYST, V59, P274, DOI 10.1016/j.robot.2011.02.009
   Nie DH, 2009, J INF PROCESS SYST, V5, P105, DOI 10.3745/JIPS.2009.5.2.105
   Pan Yi, 2012, J. Converg., V3, P23
   Pellenz J., 2010, P 2010 IEEE SAF SEC, P1, DOI [10.1109/SSRR.2010.5981567, DOI 10.1109/SSRR.2010.5981567, 10.1109/ssrr.2010.5981567]
   Rovira-Más F, 2008, COMPUT ELECTRON AGR, V60, P133, DOI 10.1016/j.compag.2007.07.007
   Saxena A, 2008, INT J COMPUT VISION, V76, P53, DOI 10.1007/s11263-007-0071-y
   Sukumar S.R., 2006, P SOC PHOTO-OPT INS, V6230, P65
   Wang C, 2007, IEEE INT CONF INF VI, P607
   Yan Zhuang, 2010, 2010 International Conference on Modelling, Identification and Control (ICMIC), P692
   Zhao Y., 2009, Proceedings of BMEI, P1
NR 21
TC 11
Z9 11
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2015
VL 74
IS 10
BP 3459
EP 3475
DI 10.1007/s11042-013-1669-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI1GY
UT WOS:000354493000015
DA 2024-07-18
ER

PT J
AU Chang, Y
   Oh, S
AF Chang, YoungHyun
   Oh, SangYeob
TI A study on the development of one source multi use cross-platform based
   on zero coding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-platform; Osmu(one source multi use); Zero coding; Mobile app;
   Native app
AB This study is to research and develop a native application based development tool which can perfectly satisfy both OSMU and cross-platform, and secure stable H/W control and execution speed. Additionally, this study is to enable developers in beginner or intermediate level to develop an application with the 'zero coding methodology' reflected tool developed by this study and not using the conventional program coding methods, eventually providing the environment that anyone, who can use MS office programs, can easily develop an application. The explosively increasing demand for the development of mobile apps is due to all works on typical PCs that should be converted to the smart basis. Although functions to be implemented are the same, different apps should be developed for each platform to result in cost, period and task forces increased a few times. The web-based application platform emerging as a solution for cross platforms is not capable of embodying the desired One Source Multi Use due to speed, UI, and technical incompleteness. Therefore if a "native-based OSMU development platform" is implemented which can develop native apps operating in various mobile operating systems, their high development productivity will contribute to remarkably reduced task forces, costs and time for development and maintenance. Also it will be possible to preoccupy the market of a potential as great as the exiting operating systems, for example, Android, iOS, Windows 8, etc. In order to develop and makes fullest use of smart app authoring tool different approaches should be appropriately employed. Firstly, it is required to have a close relation with legacy systems. Secondly, developers are fully qualified to use office programs. Thirdly, different programs should be also differently developed for business uses. This study aims to commercialize the authoring tool technology of the GUI method without coding and the source technology for driving apps in the cross platform environment. The high development productivity of one source multi use cross-platform based on Zero Coding will contribute to remarkably reduced task forces, costs and time for development and maintenance. The final goal of this paper is to establish operating platform specialized for business under predominant operating systems such as Google's Android or Apple's iOS, and to create making tools for application programs based on GUI, in which anyone can easily learn and implement by this platform.
C1 [Chang, YoungHyun] Baewha Womens Univ, Dept Comp Informat, Seoul 110735, South Korea.
   [Oh, SangYeob] Gachon Univ, Dept Interact Media, Songnam 461701, Gyeonggi Do, South Korea.
C3 Gachon University
RP Oh, S (corresponding author), Gachon Univ, Dept Interact Media, Songnam 461701, Gyeonggi Do, South Korea.
EM cyh@baewha.ac.kr; syoh1234@gmail.com
FU Gachon University [GCU-2013-R290]
FX This work was supported by the Gachon University research fund of 2013.
   (GCU-2013-R290)
CR Bang E-Y, 2011, J KOREA SOC COMPUT I, V19, P385
   Chang Y-H, 2011, J KOREA SOC COMPUT I, V19, P123
   Chang YH, 2011, COMM COM INF SC, V206, P160
   Chang Young-Hyun, 2011, J KOREA I MARITIME I, V16, P192
   Chung KY, 2014, MULTIMED TOOLS APPL, V71, P843, DOI 10.1007/s11042-013-1355-6
   Han JS, 2015, MULTIMED TOOLS APPL, V74, P9087, DOI 10.1007/s11042-013-1664-9
   Hanback Electronics Education Division, 2010, ANDR BAS APPL PROGR
   Hanback Electronics HandsOn Lab, 2011, INTR APP INV LEARN A
   Kim G.-W., 2005, SOFTWARE ENG STATE O
   Kim Gil-Wong, 2011, MOBILE APP PROGRAM D
   Kim SH, 2015, MULTIMED TOOLS APPL, V74, P8939, DOI 10.1007/s11042-013-1584-8
   Ko JW, 2015, MULTIMED TOOLS APPL, V74, P8907, DOI 10.1007/s11042-013-1581-y
   Oh SY, 2014, CLUSTER COMPUT, V17, P893, DOI 10.1007/s10586-013-0284-5
   Son Young-Bae, 2011, J KOREA I MARITIME I, V15, P429
NR 14
TC 4
Z9 4
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 7
BP 2219
EP 2235
DI 10.1007/s11042-014-1886-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE0TU
UT WOS:000351520200003
DA 2024-07-18
ER

PT J
AU Goh, HN
   Soon, LK
   Haw, SC
AF Goh, Hui-Ngo
   Soon, Lay-Ki
   Haw, Su-Cheng
TI Automatic discovery of person-related named-entity in news articles
   based on verb analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Verb; Named-entity; Semantic content; Text mining; Pattern extraction
AB Verb is the most important word in a sentence as it asserts an action, events, feeling about the subject and object discussed in the sentence. For news articles, it is observable that there is always at least a verb attached to the person(s) mentioned in the news. As such, a hypothesis has been formed such that there must exist some verbs that specifically describe human being conducts within a news article. In this paper, we propose an approach which aims to identify named-entity (NE) that performs human activity automatically. More specifically, our approach attempts to identify person-related NE generally and "person name" predefined type specifically by studying the nature of verb that associated with human activity via TreeTagger, Stanford packages and WordNet. The experimental results show that it is viable to use verb in identifying "person name"entity type. In addition, our empirical study proves that the approach is applicable to small text size articles. Another significant contribution of our approach is that it does not require training data set and anaphora resolution.
C1 [Goh, Hui-Ngo; Soon, Lay-Ki; Haw, Su-Cheng] Multimedia Univ, Fac Comp & Informat, Jalan Multimedia, Cyberjaya 63100, Selangor, Malaysia.
C3 Multimedia University
RP Goh, HN (corresponding author), Multimedia Univ, Fac Comp & Informat, Jalan Multimedia, Cyberjaya 63100, Selangor, Malaysia.
EM hngoh@mmu.edu.my; lksoon@mmu.edu.my; sucheng@mmu.edu.my
RI ., Haw Su Cheng/ABE-3251-2021; Soon, Lay-Ki/K-8129-2019; ., Haw Su
   Cheng/ABF-4418-2021
OI ., Haw Su Cheng/0000-0002-7190-0837; ., Haw Su
   Cheng/0000-0002-7190-0837; Soon, Lay-Ki/0000-0002-8072-242X
CR [Anonymous], EMNLP
   [Anonymous], LREC
   [Anonymous], 2003, Text, DOI [10.1515/text.2003.014, DOI 10.1515/TEXT.2003.014]
   Artiles J, 2009, C EMP METH NAT LANG, P534
   Boas H.C., 2010, BELGIAN J LINGUISTIC, V24, P54, DOI DOI 10.1075/BJL.24.03BOA
   Brown S.W., 2011, PROC IWCS 2011, P85
   Chafe WallaceL., 1970, MEANING STRUCTURE LA
   Dannells D., 2012, P 6 EACL WORKSH LANG, P18
   Doran C, 1996, ACL SIGPARSE WORKSH
   Eckert Penelope., 1997, Age as a sociolinguistic variable, P151
   Elson DK, 2010, AAAI
   Farmakiotou D., 2000, P WORKSHOP COMPUTATI, P75
   Fillmore C.J., 1968, Foundations of Language, V4, P373
   Fleischman M, 2002, 19 INT C COMP LING, P1
   Freire N., 2012, 9 EXT SEM WEB C GREE, V7295, P718
   Goh HN, 2012, 25 INT C IND ENG OTH
   Goh HN, 2012, 16 PAC AS C KNOWL DI, P395
   Gruhl D, 2009, LECT NOTES COMPUT SC, V5823, P260, DOI 10.1007/978-3-642-04930-9_17
   Huong TL, 2010, S INF COMM TECHN VIE, P71
   Karaa WBA, 2011, INT J MANAG INF TECH, V3
   Kim KS, 2012, PRICAI 2012, P194
   Klein D, 2003, 7 C NAT LANG LEARN, P180
   Klenner M, 2012, 17 INT C APPL NAT LA, P35
   Krupka GR, 1995, 6 MESS UND C MUC 6 P, P221
   Li Dingcheng, 2011, ACL, P1169
   Liao ZH, 2010, LECT NOTES ARTIF INT, V6230, P620, DOI 10.1007/978-3-642-15246-7_59
   Lobo P. V., 2010, LANG RES EV C LREC 2
   Ma W.-Y., 2009, P ACL IJCNLP, P333
   Madhyastha HV, 2003, PR GR LAK SYMP VLSI, P16, DOI 10.1109/RIDE.2003.1249841
   Messiant C., 2008, P ACL 08 HLT STUD RE, P55
   Mikheev A, 1998, 7 MESS UND C
   Minkov Einat., 2005, HLT 05, P443
   Novischi A, 2006, COLING/ACL 2006, VOLS 1 AND 2, PROCEEDINGS OF THE CONFERENCE, P897
   Plachouras V, 2012, 16 PAC AS C KNOWL DI, P554
   Rau LF, 1991, IEEE C ART INT APPL, P20
   Roberts W, 2012, P 8 INT C LANG RES E
   Santorini Beatrice., 1991, Part-of-Speech Tagging Guidelines for the Penn Treebank Project
   Schwartz HA, 2008, P 21 INT FLOR ART IN, P213
   Sekine S, 2004, C LANG RES EV
   Sharma A, 2010, IEEE INT C SEMANT CO, P377, DOI 10.1109/ICSC.2010.14
   Silva FJVD, 2010, LECT NOTES COMPUTER, V6433, P336
   Siorpaes K, 2010, WORLD WIDE WEB, V13, P33, DOI 10.1007/s11280-009-0078-0
   Smarr J., 2002, DBPUBS200246 STANF U
   Trudgill P., 1972, Language in Society, V1, P179, DOI DOI 10.1017/S0047404500000488
   Whitelaw C, 2008, 17 ACM C INF KNOWL M, P123
   Williams J, 2012, P 50 ANN M ASS COMP, P223
   Williams J, 2012, LREC 2012 - EIGHTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P293
NR 47
TC 0
Z9 0
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2015
VL 74
IS 8
BP 2587
EP 2610
DI 10.1007/s11042-013-1618-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CE2ZL
UT WOS:000351692300003
DA 2024-07-18
ER

PT J
AU Kim, T
   Kim, EJ
AF Kim, Taekook
   Kim, Eui-Jik
TI Hybrid storage-based caching strategy for content delivery network
   services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content delivery network (CDN); Content distribution network (CDN);
   Caching scheme; Caching algorithm; Solid state drive (SSD); Future
   internet; YouTube
AB This study proposes a novel caching scheme for content delivery network services. In general, video content users often watch the first part of video clips and then switch to other content. Therefore, a caching scheme is proposed, in which the first part of the frequently referenced content is stored on a solid state drive (SSD) while the remaining video content is stored on a hard disk drive (HDD),. The proposed hybrid (SSD/HDD) caching scheme offers several benefits, such as an improved average data output capacity due to the high average data rate and average hit capacity of the SSD. That is, performance can be significantly improved at a low extra cost with the cache server of a content delivery network (CDN).
C1 [Kim, Taekook] Korea Univ, Dept Elect Engn, Seoul 136713, South Korea.
   [Kim, Eui-Jik] Hallym Univ, Dept Convergence Software, Chuncheon Si 200702, Gangwon Do, South Korea.
C3 Korea University; Hallym University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 200702, Gangwon Do, South Korea.
EM ejkim32@hallym.ac.kr
FU ICT R&D program of MSIP/IITP [B0101-14-0059]; Hallym University Research
   Fund [HRF-201406-005]
FX This work was supported by the ICT R&D program of MSIP/IITP
   [B0101-14-0059, Human Resource Development Program for Future Internet].
   This research was also supported by Hallym University Research Fund,
   2014 (HRF-201406-005).
CR [Anonymous], 2014, CISCO VISUAL NETWORK
   [Anonymous], P INT WORKSH WEB CON
   [Anonymous], MULTIMEDIA INFORM ST
   [Anonymous], SPRINGER SERIES ADV
   [Anonymous], CONTENT DISTRIBUTION
   Arpaci-Dusseau Remzi., 2012, Operating Systems: Three Easy Pieces, V0.5
   Balamash A, 2004, IEEE COMMUN SURV TUT, V6, P44, DOI 10.1109/COMST.2004.5342239
   Breslau L, 1999, IEEE INFOCOM SER, P126, DOI 10.1109/INFCOM.1999.749260
   Cho K, 2011, IEEE COMMUN MAG, V49, P156, DOI 10.1109/MCOM.2011.6035830
   Dilley J, 2002, IEEE INTERNET COMPUT, V6, P50, DOI 10.1109/MIC.2002.1036038
   Gurumurthi S, 2009, IEEE MICRO, V29, P68, DOI 10.1109/MM.2009.92
   Han T, 2013, IEEE COMMUN SURV TUT, V15, P1314, DOI 10.1109/SURV.2012.100412.00094
   Kim T, 2014, IEICE T FUND ELECTR, VE97A, P907, DOI 10.1587/transfun.E97.A.907
   Lazar I., 2001, IT Professional, V3, P47, DOI 10.1109/6294.946620
   Loulloudes N, 2008, LECT NOTES ELECTR EN, V9, P343
   Vakali A, 2003, IEEE INTERNET COMPUT, V7, P68, DOI 10.1109/MIC.2003.1250586
NR 16
TC 12
Z9 14
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1697
EP 1709
DI 10.1007/s11042-014-2215-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900011
DA 2024-07-18
ER

PT J
AU Park, J
   Oh, SH
   Lee, YS
AF Park, Jongsu
   Oh, Seung-Ho
   Lee, Yong-Surk
TI Network security camera system and its application for consumer
   electronics in ubiquitous environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Network camera processor (NCP); System on a chip; Remote security; Home
   security
ID DIGITAL SIGNAL PROCESSOR; STILL CAMERA; CCD
AB This paper presents a network security camera system and its application to provide visual information to consumer electronics devices in ubiquitous environment. For this system, we developed a network camera processor chip and a network security board. The processor includes a digital camera processor, a motion JPEG encoder, an Ethernet controller and an ARM processor, which serve to enhance the quality of raw images from a CCD image sensor, compress the image data size and transmit the compressed data via Internet. The processor was fabricated with 0.25um CMOS technology. The die area is 60.84 mm(2) and the gate count is approximately 1.2 million. The network security board consists of the board driving the network camera processor chip and the CCD image sensor board. To demonstrate the applicability of the network security system to consumer electronics, we applied the proposed system to a vacuum cleaner.
C1 [Park, Jongsu; Lee, Yong-Surk] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
   [Oh, Seung-Ho] Chipsbrain Global Corp Ltd, Songnam 463816, Gyeonggi, South Korea.
C3 Yonsei University
RP Park, J (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, 134 Sinchon Dong, Seoul 120749, South Korea.
EM jspark@yonsei.ac.kr; sunny@chipsbrain.com; yonglee@yonsei.ac.kr
CR Ahn HJ, 2007, ETRI J, V29, P259, DOI 10.4218/etrij.07.0506.0025
   Atzori L, 2010, COMPUT NETW, V54, P2787, DOI 10.1016/j.comnet.2010.05.010
   Chen M, 2013, MULTIMED TOOLS APPL, V67, P167, DOI 10.1007/s11042-012-1013-4
   Hassar MA, 2005, P DES AUTOM TEST EUR, V1, P554
   Johansson H, 2002, IEEE T SIGNAL PROCES, V50, P2757, DOI 10.1109/TSP.2002.804089
   Kami H, 1999, IEEE T CONSUM ELECTR, V45, P1206, DOI 10.1109/30.809210
   Kim H, 1998, IEEE T CONSUM ELECTR, V44, P1389, DOI 10.1109/30.735842
   Luo HL, 2011, HUM-CENT COMPUT INFO, V1, DOI 10.1186/2192-1962-1-5
   Nakano N, 1998, IEEE T CONSUM ELECTR, V44, P581, DOI 10.1109/30.713166
   Okada S, 1999, IEEE T CONSUM ELECTR, V45, P584, DOI 10.1109/30.793544
   Zen H, 1998, IEEE T CONSUM ELECTR, V44, P289, DOI 10.1109/30.681940
NR 11
TC 1
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2015
VL 74
IS 5
BP 1577
EP 1591
DI 10.1007/s11042-013-1442-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CC7UC
UT WOS:000350572900004
DA 2024-07-18
ER

PT J
AU Mohsenfar, SM
   Mosleh, M
   Barati, A
AF Mohsenfar, Seyed Mohammadreza
   Mosleh, Mohammad
   Barati, Ali
TI Audio watermarking method using QR decomposition and genetic algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Genetic algorithm; Matrices decomposition; Audio signal; Watermarking;
   Embedding; Extraction
ID TIME-SCALE MODIFICATION; ROBUST
AB Watermarking is a method used to hide the owner's data in the host signal in an inaudible way. The watermark signal must not reduce the quality of host signal. Furthermore, it must be resistant to various attacks. In this paper, we will propose an intelligent audio watermarking method in terms of collaborating QR decomposition (QR factorization) method and Genetic Algorithm (GA). At the outset, the host signal is segmented into several frames. Then, every frame is decomposed by using QR decomposition method, and, subsequently, the best place for embedding the watermark bit which has a high robustness to the possible attacks is searched by using GA. In order to evaluate effectiveness of this method, we have examined the robustness of watermark against several attacks for several different audio signals. The results indicate that the proposed method has more robustness in comparison with previous robust audio watermarking methods.
C1 [Mohsenfar, Seyed Mohammadreza; Mosleh, Mohammad; Barati, Ali] Islamic Azad Univ, Dezfoul Branch, Dept Comp Engn, Dezfoul, Iran.
C3 Islamic Azad University
RP Mohsenfar, SM (corresponding author), Islamic Azad Univ, Dezfoul Branch, Dept Comp Engn, Dezfoul, Iran.
EM s_m_mohsenfar@yahoo.com; mosleh@iaud.ac.ir; abarati@iaud.ac.ir
RI Mosleh, Mohammad/T-6461-2019; Barati, Ali/AAN-7646-2021
OI Mosleh, Mohammad/0000-0002-0991-1623; Barati, Ali/0000-0001-5132-5540
CR Abd El-Samie FE, 2009, INT J SPEECH TECHNOL, V12, P27, DOI 10.1007/s10772-009-9056-2
   Al-Nuaimy W, 2011, DIGIT SIGNAL PROCESS, V21, P764, DOI 10.1016/j.dsp.2011.01.013
   [Anonymous], 2001, BS1387 ITUR REC
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Bhat V, 2011, MULTIMED TOOLS APPL, V52, P369, DOI 10.1007/s11042-010-0515-1
   Bhat KV, 2010, DIGIT SIGNAL PROCESS, V20, P1547, DOI 10.1016/j.dsp.2010.02.006
   Chen B, 1999, P SOC PHOTO-OPT INS, V3657, P342, DOI 10.1117/12.344684
   Chang CY, 2006, IEEE SYS MAN CYBERN, P1214, DOI 10.1109/ICSMC.2006.384880
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Cvejic N, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P227, DOI 10.1109/ASPAA.2001.969584
   Erfani Y, 2009, DIGIT SIGNAL PROCESS, V19, P809, DOI 10.1016/j.dsp.2009.04.003
   Fan MQ, 2009, COMPUT ELECTR ENG, V35, P506, DOI 10.1016/j.compeleceng.2008.12.004
   Haupt R.L., 2004, PRACTICAL GENETIC AL, DOI [10.1002/0471671746, DOI 10.1002/0471671746]
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Huang CH, 2000, P SOC PHOTO-OPT INS, V3971, P516, DOI 10.1117/12.385007
   Ketcham M, 2007, PROC WRLD ACAD SCI E, V20, P336
   Ketcham M, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS AND INFORMATION TECHNOLOGIES, VOLS 1-3, P1235
   Kim HJ, 2004, AUDIO WATERMARKING T
   Kirovski D, 2001, INT CONF ACOUST SPEE, P1345, DOI 10.1109/ICASSP.2001.941177
   Lee S-K, 2000, IEEE T CONSUM ELECT, V46
   Li W, 2006, IEEE T MULTIMEDIA, V8, P60, DOI 10.1109/TMM.2005.861291
   Ozer H, 2005, P IEEE 13 C SIGN PRO, P452
   Peng H, 2011, ANN TELECOMMUN, V66, P307, DOI 10.1007/s12243-010-0200-4
   Shieh CS, 2004, PATTERN RECOGN, V37, P555, DOI 10.1016/j.patcog.2003.07.003
   VANSCHYNDELL RG, 1994, IEEE IMAGE PROC, P86, DOI 10.1109/ICIP.1994.413536
   Wang J, 2011, SIGNAL PROCESS, V91, P1693, DOI 10.1016/j.sigpro.2011.01.014
   Wang RD, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P2393
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   Xiang SJ, 2007, IEEE T MULTIMEDIA, V9, P1357, DOI 10.1109/TMM.2007.906580
NR 30
TC 22
Z9 22
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 3
BP 759
EP 779
DI 10.1007/s11042-013-1694-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZO
UT WOS:000349356400006
DA 2024-07-18
ER

PT J
AU Safadi, B
   Derbas, N
   Quénot, G
AF Safadi, Bahjat
   Derbas, Nadia
   Quenot, Georges
TI Descriptor optimization for multimedia indexing and retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia indexing and retrieval; Descriptor optimization;
   Dimensionality reduction
AB In this paper, we propose and evaluate a method for optimizing descriptors used for content-based multimedia indexing and retrieval. A large variety of descriptors are commonly used for this purpose. However, the most efficient ones often have characteristics preventing them to be easily used in large scale systems. They may have very high dimensionality (up to tens of thousands dimensions) and/or be suited for a distance which is costly to compute (e.g. chi (2)). The proposed method combines a PCA-based dimensionality reduction with pre- and post-PCA non-linear transformations. The resulting transformation is globally optimized. The produced descriptors have a much lower dimensionality while performing at least as well, and often significantly better, with the Euclidean distance than the original high dimensionality descriptors with their optimal distance. Our approach also includes a hyper-parameter optimization procedure based on the use of a fast kNN classifier and on a polynomial fit to overcome the MAP metric instability. The method has been validated and evaluated on a variety of descriptors using the TRECVid 2010 semantic indexing task data. It has been applied at large scale for the TRECVid 2012 semantic indexing task on tens of descriptors of various types and with initial dimensionalities ranging from 15 up to 32,768. The same transformation can be used also for multimedia retrieval in the context of query by example and/or of relevance feedback.
C1 [Safadi, Bahjat; Derbas, Nadia; Quenot, Georges] CNRS, LIG UMR 5217, Grenoble INP, UJF Grenoble 1 UPMF Grenoble 2, F-38041 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Quénot, G (corresponding author), CNRS, LIG UMR 5217, Grenoble INP, UJF Grenoble 1 UPMF Grenoble 2, F-38041 Grenoble, France.
EM georges.quenot@imag.fr
FU OSEO, French State agency for innovation; French project VideoSense of
   the ANR [ANR-09-CORD-026]; CNRS; RENATER
FX This work was partly realized as part of the Quaero Program funded by
   OSEO, French State agency for innovation. This work was supported in
   part by the French project VideoSense ANR-09-CORD-026 of the ANR.
   Experiments presented in this paper were carried out using the Grid'5000
   experimental testbed, being developed under the INRIA ALADDIN
   development action with support from CNRS, RENATER and several
   Universities as well as other funding bodies (see
   https://www.grid5000.fr). The authors wish to thanks the participants of
   the IRIM (Indexation et Recherche d'Information Multimedia) group of the
   GDR-ISIS research network from CNRS for providing the descriptors used
   in these experiments.
CR [Anonymous], INT C IM VID RETR
   [Anonymous], P 10 INT WORKSH CONT
   [Anonymous], P TRECVID WORKSH GAI
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Gorisse D, 2011, PATTERN RECOGN, V44, P2343, DOI 10.1016/j.patcog.2010.12.009
   Gorisse D., 2010, TREC VID RETR EV WOR
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   KRAMER MA, 1991, AICHE J, V37, P233, DOI 10.1002/aic.690370209
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahalanobis P. C., 1936, P NATL I SCI INDIA, V2, P49
   Nasrabadi N.M, 2007, Pattern recognition and machine learning, V16
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Redi M, P 1 ACM INT C MULT R, P39
   Safadi B., 2011, Proceedings of the 20th ACM international conference on Information and knowledge management, P2081
   Safadi B, 2012, P TRECVID WORKSH GAI
   Safadi B, 2010, RIAO
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
NR 27
TC 11
Z9 14
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2015
VL 74
IS 4
BP 1267
EP 1290
DI 10.1007/s11042-014-2071-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CB0ZN
UT WOS:000349356300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Atrey, PK
   Alharthi, S
   Hossain, MA
   AlGhamdi, A
   El Saadik, A
AF Atrey, Pradeep K.
   Alharthi, Saeed
   Hossain, M. Anwar
   AlGhamdi, Abdullah
   El Saadik, Abdulmotaleb
TI Collective control over sensitive video data using secret sharing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital video; Secret sharing; Security
ID ENCRYPTION; WATERMARKING
AB Today digital video is used extensively in many applications. Sometimes a video could be treated as a top secret for an organization, for example military secrets, surveillance footage and corporate product designs, and may need to be shared among a group of people in a secure manner. Traditional data security methods such as encryption techniques are prone to single-point attack, i.e. the secret can be revealed by obtaining the decryption key from any single person. Alternatively, the secret sharing scheme provides collective control over the secrecy of information and is considered information theoretically secure. In this paper, we propose to adopt a secret sharing based approach to provide collective control over a given sensitive video. We present three methods that utilize the spatial and temporal redundancy in videos in different ways. We analyze the security of these methods and compare them for efficiency in terms of computation time and space using extensive experimentation.
C1 [Atrey, Pradeep K.] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
   [Alharthi, Saeed] Taibah Univ, Branch Badr, Dept Comp Sci & Informat, Al Madinah, Saudi Arabia.
   [Hossain, M. Anwar] King Saud Univ, Coll Comp & Informat Sci, Software Engn Dept, Riyadh, Saudi Arabia.
   [AlGhamdi, Abdullah] King Saud Univ, Coll Comp & Informat Sci, SWE Dept, Riyadh, Saudi Arabia.
   [El Saadik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON, Canada.
C3 University of Winnipeg; Taibah University; King Saud University; King
   Saud University; University of Ottawa
RP Atrey, PK (corresponding author), Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
EM p.atrey@uwinnipeg.ca; sharthi@taibahu.edu.sa; mahossain@ksu.edu.sa;
   Ghamdi@ksu.edu.sa; abed@mcrlab.uottawa.ca
RI Hossain, M. Anwar/J-9601-2013
FU National Plan for Science and Technology (NPST) program by King Saud
   University [11-INF1830-02]
FX Authors would like to thank their colleagues, Majid Khabbazian from
   University of Alberta and Manoranjan Mohanty from National University of
   Singapore, for their help in security analysis of the proposed methods.
   This research is supported by National Plan for Science and Technology
   (NPST) program by King Saud University Project Number 11-INF1830-02.
CR Alharthi S, 2010, P APSIPA ANN SUMM C
   Alharthi Saeed S., 2010, P 2 ACM WORKSH MULT, P53
   Atrey PK, 2011, P INT C FRONT COMP S
   Bai L, 2006, DASC 2006: 2ND IEEE INTERNATIONAL SYMPOSIUM ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P31
   Cramer R, 2000, LECT NOTES COMPUT SC, V1807, P316
   Eskicioglu AM, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P573, DOI 10.1109/ICME.2002.1035846
   Eskicioglu AM, 2003, P ROY SOC LONDON, P197
   Guo HP, 2003, MULTIMEDIA SYST, V9, P249, DOI 10.1007/s00530-003-0096-1
   Kezia H, 2008, ADCOM: 2008 16TH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING AND COMMUNICATIONS, P40, DOI 10.1109/ADCOM.2008.4760425
   Krawczyk H., 1994, Advances in Cryptology - CRYPTO '93. 13th Annual International Cryptology Conference Proceedings, P136
   Li SJ, 2002, PROC SPIE, V4666, P149, DOI 10.1117/12.458527
   Liu F, 2008, IET INFORM SECUR, V2, P151, DOI 10.1049/iet-ifs:20080066
   Liu FW, 2010, COMPUT SECUR, V29, P3, DOI 10.1016/j.cose.2009.06.004
   Lukac R, 2004, IEEE IMAGE PROC, P2893
   Ma CG, 2008, LECT NOTES COMPUT SC, V4990, P182
   Mink A, 2006, P SPIE
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Raju CN, 2008, IEEE IMAGE PROC, P3136, DOI 10.1109/ICIP.2008.4712460
   Schoenmakers B., 1999, IACR INT CRYPT C CRY, P784
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Simitopoulos D, 2003, MULTIMEDIA SYST, V9, P217, DOI 10.1007/s00530-003-0093-4
   STINSON DR, 1995, CRYPTOGRAPHY THEORY, pCH11
   Takizawa O., 2004, Transactions of the Information Processing Society of Japan, V45, P320
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
NR 25
TC 1
Z9 1
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1459
EP 1486
DI 10.1007/s11042-013-1644-0
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200017
DA 2024-07-18
ER

PT J
AU Seetharaman, K
   Kamarasan, M
AF Seetharaman, K.
   Kamarasan, M.
TI Statistical framework for image retrieval based on multiresolution
   features and similarity method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optimum level; Autocorrelogram; GLCM; CBIR; Multiresolution; Wavelet
   transform
ID COLOR; TEXTURE; CLASSIFICATION
AB The advent of large scale digital image database leads to great challenges in contentbased image retrieval (CBIR) method. The CBIR is considered an active area of research; however, it comprises a strong backdrop for new methodologies and system implementations. Hence, many research contributions focus on these techniques to enable higher image retrieval accuracy while preserving the low level computational complexity. This paper proposes a CBIR method, which is based on an efficient combination of multiresolution based color and texture features. This paper considers color autocorrelogram of the hue(H) and saturation(s) components of HSV color space for color features, and value(V) component of HSV color space for texture features. These two image features are extracted by computing co-occurrence matrix at optimum level image, which is the basis for the formation of feature vector. Though the optimum level is constructed based on wavelet transform, which contains a few dominant wavelet coefficients. The efficiency of the proposed system is tested with standard image databases, and the experimental results show that the proposed method achieves better retrieval accuracy at optimum level; moreover, the proposed method is very fast with low computational load. The obtained results are compared with existing techniques such as orthogonal polynomial model, multiresolution with BDIP-BVLC method and GLCMbased system, and results reveal that the proposed method outperforms the existing methods.
C1 [Seetharaman, K.; Kamarasan, M.] Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.
C3 Annamalai University
RP Kamarasan, M (corresponding author), Annamalai Univ, Dept Comp Sci & Engn, Annamalainagar 608002, Tamil Nadu, India.
EM kseethadde@yahoo.com; smkrasan@yahoo.com
CR Akono A, 2005, INT J REMOTE SENS, V24, P1957
   Androutsos D, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P770, DOI 10.1109/ICIP.1998.723652
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   Gersho A., 2003, Vector Quantization and Signal Compression
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P602, DOI 10.1109/ICCV.1998.710779
   Jiang J, 2008, OPTICAL ENG, V47, DOI [10.1117/1.2894149, DOI 10.1117/1.2894149]
   Kavitha C., 2011, J COMPUTER APPL, V15, P33
   Krishnamoorthi R, 2012, J VIS COMMUN IMAGE R, V23, P18, DOI 10.1016/j.jvcir.2011.07.011
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Lin CH, 2009, IMAGE VISION COMPUT, V27, P658, DOI 10.1016/j.imavis.2008.07.004
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   MIT Media Laboratory, VIST TEXT IM DAT
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Ojala T., 2001, Proceedings of 12th Scandinavian Conference on Image Analysis, P621
   Pannirselvam S, 2009, INT J SOFT COMPUT, V4, P229
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Premchaiswadi Wichian, 2010, WSEAS Transactions on Computers, V9, P465
   Reddy PVN, 2011, INT J COMPUT APPL, V17, P39
   Sai NST, 2011, INT J COMPUT SCI TEC, V2
   Seetharaman K, 2013, INT J IMAGE DATA FUS, V4, P342, DOI 10.1080/19479832.2013.804007
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Youssif AAA, 2010, INT J COMPUT SCI NET, V10, P157
   Zhang J, 2008, HPCC 2008: 10TH IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, PROCEEDINGS, P782, DOI 10.1109/HPCC.2008.55
NR 32
TC 13
Z9 14
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1943
EP 1962
DI 10.1007/s11042-013-1637-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200038
DA 2024-07-18
ER

PT J
AU Nair, R
   Varadharajan, V
   Joglekar, S
   Nallusamy, R
   Paul, S
AF Nair, Rohit
   Varadharajan, Vijayaraghavan
   Joglekar, Sagar
   Nallusamy, Rajarathnam
   Paul, Sanjoy
TI Robust transcoding resistant watermarking for H.264 standard
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE H.264; Robust watermark; x264; ffmpeg; DCT
AB Content in the digital form can be easily copied and distributed without permission of the owner. As a result, it is of paramount importance to protect content and deter illegal distribution using content protection mechanisms like embedding an imperceptible watermark into the content. Given that consumers want access to content from anywhere using any device, it is necessary to transcode content keeping in mind the limitations of the devices in terms of processing power and network connectivity. However, it is important that the watermark embedded in the content is preserved even after transcoding. The proposed approach embeds in a video, an imperceptible yet robust watermark which is resistant to transcoding. This approach focuses on the H.264 codec because of its widespread use in the industry.
C1 [Nair, Rohit; Varadharajan, Vijayaraghavan; Joglekar, Sagar; Nallusamy, Rajarathnam; Paul, Sanjoy] Infosys Ltd, Infosys Labs, Bangalore 560100, Karnataka, India.
C3 Infosys Limited
RP Varadharajan, V (corresponding author), Infosys Ltd, Infosys Labs, 44 Elect City, Bangalore 560100, Karnataka, India.
EM roguehit@gmail.com; vijayaraghavan_V01@infosys.com;
   sagarjoglekar@gmail.com; rajarathnam_N@infosys.com;
   sanjoy.paul@gmail.com
RI Paul, Sanjoy/K-2618-2019
OI Paul, Sanjoy/0000-0001-9523-179X; Joglekar, Sagar/0000-0002-8388-9137
CR Caccia G, 2001, EUROCON 2001 INT C T, V2, P363, DOI [10.1109/EURCON.2001.938138, DOI 10.1109/EURCON.2001.938138]
   Coria L, 2006, 6 ACM WORKSH DIG RIG, P97
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Ishtiaq M, 2009, COMM COM INF SC, V61, P177
   Kuo T-Y, 2010, IEEE AS PAC POW EN E, P1, DOI 10.1109/ISBMSB.2010.5463151
   Liu Q, 2008, 4 INT C WIR COMM NET, P1, DOI [10.1109/WiCom.2008.770, DOI 10.1109/WICOM.2008.770]
   NASIR I, 2007, P IEEE INT C SIGN IM, P942, DOI DOI 10.1109/SITIS.2007.67
   PAUL S, 2008, ANN REV COMMUNICATIO, V61, P221
   Sridevi T, 2010, A2CWIC 10 P 1 AMR AC, DOI [10.1145/1858378.1858413, DOI 10.1145/1858378.1858413]
   Vijayaraghavan V., 2010, International Journal of Multimedia Intelligence and Security, V1, P350, DOI 10.1504/IJMIS.2010.039236
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
NR 11
TC 4
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 763
EP 778
DI 10.1007/s11042-012-1208-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700008
DA 2024-07-18
ER

PT J
AU Jeong, ES
   Kim, BH
   Lee, DH
AF Jeong, Eun Su
   Kim, Bum Han
   Lee, Dong Hoon
TI A generic partial encryption scheme for low-power mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital rights management; Partial encryption; Mobile DRM; PSNR;
   Selective encryption
AB Content protection that allows only legitimate users to use specified content is essential in order to secure business in the consumer market. However, service providers and users suffer from low responsiveness when content is encrypted with traditional cryptographic tools that require strong decryption algorithms on mobile devices. In this paper, we introduce a generic partial encryption scheme for low-power mobile devices. Our primary goal is to design a generic architecture for partial encryption of downloadable and real-time streaming contents, and also to facilitate a trade-off between minimizing the encryption/decryption overhead and providing sufficient DRM security for the service provider. We also evaluate the efficacy of our proposed scheme by applying it to real-world multimedia contents. The results of our experiments indicate that encrypting only a small portion (about 2.5 %) of video content can effectively impose DRM restriction on the content. This significantly reduces the decryption overhead on low-power mobile devices. In the smart phone environment, it is shown that the time overhead during the decryption is less that 5 % of on-the-fly decoding time and the power overhead is reduced by up to 94.5 %, compared to the traditional full encryption scheme.
C1 [Jeong, Eun Su; Kim, Bum Han; Lee, Dong Hoon] Korea Univ, CIST, Seoul, South Korea.
C3 Korea University
RP Lee, DH (corresponding author), Korea Univ, CIST, Seoul, South Korea.
EM eunsu.jeong@sk.com; i.bhkim@gmail.com; donghlee@korea.ac.kr
FU Next-Generation Information Computing Development Program through the
   National Research Foundation of Korea (NRF) - the Ministry of Education,
   Science and Technology [2012-0006419]
FX This research was supported by Next-Generation Information Computing
   Development Program through the National Research Foundation of Korea
   (NRF) funded by the Ministry of Education, Science and Technology
   (2012-0006419).
CR [Anonymous], 2010, INT J COMPUT ELECT E, DOI DOI 10.7763/IJCEE.2010.V2.141
   [Anonymous], 2002, COUNTER MODE SECURIT
   Bellare M., 1997, P 38 S FDN COMP SCI
   Furht B, 2005, INTERNET COMMUN SER, P95
   Han J, 2008, ICISS 2008: INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND SECURITY, PROCEEDINGS, P108, DOI 10.1109/ICISS.2008.13
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Le Gall D., 1991, COMMUNICATIONS ACM
   Li CH, 2008, LECT NOTES COMPUT SC, V5353, P496
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Liu X., 2003, 2 INT C COMM INT INF
   Mauro B, 2006, DOCUMENT IMAGE COMPR, V968, P168
   *OP MOB ALL, 2004, DRM SPEC V2 0
   Shahid Z, 2011, IEEE T CIRC SYST VID, V21, P565, DOI 10.1109/TCSVT.2011.2129090
   THOMOS N, 2006, IEEE T IMAGE PROCESS, V15
   Welstead StephenT., 1999, Fractal and wavelet image compression techniques, P155, DOI DOI 10.1117/3.353798
   Wu CP, 2005, IEEE T MULTIMEDIA, V7, P828, DOI 10.1109/TMM.2005.854469
   Xiangjun L, 2007, ICME 2007 SCH COMP E, P947
NR 17
TC 3
Z9 3
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2087
EP 2106
DI 10.1007/s11042-013-1389-9
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300002
DA 2024-07-18
ER

PT J
AU Soysal, M
   Logoglu, KB
   Tekin, M
   Esen, E
   Saracoglu, A
   Acar, BO
   Ozan, EC
   Ates, TK
   Sevimli, H
   Sevinç, M
   Atil, I
   Özkan, S
   Arabaci, MA
   Tankiz, S
   Karadeniz, T
   Önür, D
   Selçuk, S
   Alatan, AA
   Çiloglu, T
AF Soysal, Medeni
   Logoglu, K. Berker
   Tekin, Mashar
   Esen, Ersin
   Saracoglu, Ahmet
   Acar, Banu Oskay
   Ozan, Ezgi Can
   Ates, Tugrul K.
   Sevimli, Hakan
   Sevinc, Muge
   Atil, Ilkay
   Ozkan, Savas
   Arabaci, Mehmet Ali
   Tankiz, Seda
   Karadeniz, Talha
   Onur, Duygu
   Selcuk, Sezin
   Alatan, A. Aydin
   Ciloglu, Tolga
TI Multimodal concept detection in broadcast media: KavTan
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent multimedia systems; Concept detection; Broadcast video
   indexing; Multimodal semantic indexing
ID RELEVANCE FEEDBACK; AUDIO CLASSIFICATION; RETRIEVAL; RECOGNITION; VIDEO;
   NEWS
AB Concept detection stands as an important problem for efficient indexing and retrieval in large video archives. In this work, the KavTan System, which performs high-level semantic classification in one of the largest TV archives of Turkey, is presented. In this system, concept detection is performed using generalized visual and audio concept detection modules that are supported by video text detection, audio keyword spotting and specialized audio-visual semantic detection components. The performance of the presented framework was assessed objectively over a wide range of semantic concepts (5 high-level, 14 visual, 9 audio, 2 supplementary) by using a significant amount of precisely labeled ground truth data. KavTan System achieves successful high-level concept detection performance in unconstrained TV broadcast by efficiently utilizing multimodal information that is systematically extracted from both spatial and temporal extent of multimedia data.
C1 [Soysal, Medeni; Logoglu, K. Berker; Tekin, Mashar; Esen, Ersin; Saracoglu, Ahmet; Acar, Banu Oskay; Ozan, Ezgi Can; Ates, Tugrul K.; Sevimli, Hakan; Sevinc, Muge; Atil, Ilkay; Ozkan, Savas; Arabaci, Mehmet Ali; Tankiz, Seda; Karadeniz, Talha; Onur, Duygu; Selcuk, Sezin; Alatan, A. Aydin; Ciloglu, Tolga] TUBITAK UZAY, Ankara, Turkey.
C3 Turkiye Bilimsel ve Teknolojik Arastirma Kurumu (TUBITAK)
RP Soysal, M (corresponding author), TUBITAK UZAY, METU Campus, Ankara, Turkey.
EM medenis@gmail.com
RI Alatan, A. Aydin/E-3927-2012; Arabacı, Mehmet Ali/GYJ-2329-2022
OI Arabacı, Mehmet Ali/0000-0002-5433-5864; Soysal,
   Medeni/0000-0002-7846-7052; ciloglu, tolga/0000-0002-9703-5861
CR Akbani R, 2004, LECT NOTES COMPUT SC, V3201, P39, DOI 10.1007/978-3-540-30115-8_7
   [Anonymous], IEEE 14 SIG P COM AP
   [Anonymous], 2007, CIVR '07
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Ates T. K., 2011, 2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU 2011), P1004, DOI 10.1109/SIU.2011.5929823
   Barrington L, 2007, INT CONF ACOUST SPEE, P725
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Biatov K, 2008, P ICSPCS, P1
   Chang S.F., 2008, P TRECVID
   Chang YC, 2006, IEEE T EVOLUT COMPUT, V10, P617, DOI 10.1109/TEVC.2005.863130
   Changkaew P., 2010, Proceedings of the 2010 First International Conference on Integrated Intelligent Computing (ICIIC 2010), P12, DOI 10.1109/ICIIC.2010.25
   Cheng J, 2000, INT C PATT RECOG, P668, DOI 10.1109/ICPR.2000.905476
   Chu S, 2009, IEEE T AUDIO SPEECH, V17, P1142, DOI 10.1109/TASL.2009.2017438
   Clarin C., 2006, P PAC COAST SOFTB C, V6, P150
   Clavel C, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1307
   Crandall D, 2004, PROC CVPR IEEE, P379
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deselaers T, 2008, INT C PATT RECOG, P2100
   Fergus R, 2003, PROC CVPR IEEE, P264
   Ghimire D., 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P422, DOI 10.1109/PSIVT.2010.77
   GOTLIEB CC, 1990, COMPUT VISION GRAPH, V51, P70, DOI 10.1016/S0734-189X(05)80063-5
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang RQ, 2006, IEEE T AUDIO SPEECH, V14, P907, DOI 10.1109/TSA.2005.858057
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jansohn C., 2009, PROC 17 ACM INT C MU, P601, DOI [DOI 10.1145/1631272.1631366, 10.1145/1631272.1631366]
   Jones M, 1999, P CVPR, V1
   Jones M., 2003, P ICCV
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Lin CC, 2005, IEEE T SPEECH AUDI P, V13, P644, DOI 10.1109/TSA.2005.851880
   Lopes A, 2009, P ESPC CIT
   Lopes APB, 2009, SIBGRAPI, P224, DOI 10.1109/SIBGRAPI.2009.32
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mamou Jonathan, 2007, 30th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P615, DOI 10.1145/1277741.1277847
   Manjunath B.S., 2002, Introduction to MPEG-7: multimedia content description interface, V1
   Mesaros A, 2010, EUR SIGNAL PR CONF, P1267
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   MPEG, 2001, 15938 ISOIEC
   Müller H, 2000, INT C PATT RECOG, P1043, DOI 10.1109/ICPR.2000.905650
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Over P, 2011, P TRECVID
   Ozan E. C., 2011, 2011 IEEE 19th Signal Processing and Communications Applications Conference (SIU 2011), P391, DOI 10.1109/SIU.2011.5929669
   Peng Y, 2008, P TRECVID, V3
   Petridis S, 2010, LECT NOTES ARTIF INT, V6040, P399, DOI 10.1007/978-3-642-12842-4_50
   Phan R, 2008, P CCECE 2008
   Phan R, 2010, COMPUT VIS IMAGE UND, V114, P66, DOI 10.1016/j.cviu.2009.07.004
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Portêlo J, 2009, INT CONF ACOUST SPEE, P1973, DOI 10.1109/ICASSP.2009.4959998
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Saracoglu Ahmet, 2010, 2010 IEEE 18th Signal Processing and Communications Applications Conference (SIU 2010), P621, DOI 10.1109/SIU.2010.5650360
   Schölkopf B, 2000, NEURAL COMPUT, V12, P1207, DOI 10.1162/089976600300015565
   Smeaton AF, 2009, SIGNALS COMMUN TECHN, P151, DOI 10.1007/978-0-387-76569-3_6
   Snoek CGM, 2007, IEEE T MULTIMEDIA, V9, P280, DOI 10.1109/TMM.2006.886275
   Snoek CGM, 2006, IEEE T PATTERN ANAL, V28, P1678, DOI 10.1109/TPAMI.2006.212
   Snoek CGM, 2010, P TRECVID
   Sundaram S, 2008, INT CONF ACOUST SPEE, P49, DOI 10.1109/ICASSP.2008.4517543
   Tao L, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P138, DOI 10.1109/ITCC.2004.1286612
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Viola M., 2003, P CVPR
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Wenjing Jia, 2006, 2006 IEEE Conference on Systems, Man, and Cybernetics, P2413
   Wu P, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P3, DOI 10.1109/IVL.1999.781114
   Yilmaz Emine, 2006, Proceedings of the 2006 ACM CIKM International Conference on Information and Knowledge Management, Arlington, Virginia, USA, November 6-11, 2006, P102, DOI [10.1145/1183614.1183633 (cit. on p. 34, DOI 10.1145/1183614.1183633(CIT.ONP.34]
   Yizhi Liu, 2009, Proceedings of the 2009 12th International Conference on Computer and Information Technology (ICCIT 2009), P404, DOI 10.1109/ICCIT.2009.5407272
   Yoon JH, 2001, IEEE IMAGE PROC, P42, DOI 10.1109/ICIP.2001.958948
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P287, DOI 10.1016/j.image.2010.02.001
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
   Zubari U, 2010, EUSIPCO
   Zuo HQ, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P37, DOI 10.1109/ICME.2008.4607365
NR 69
TC 1
Z9 1
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2014
VL 72
IS 3
BP 2787
EP 2832
DI 10.1007/s11042-013-1564-z
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AN4IE
UT WOS:000340550300032
DA 2024-07-18
ER

PT J
AU Huang, R
   Rhee, K
   Uchida, S
AF Huang, R.
   Rhee, K. H.
   Uchida, S.
TI A parallel image encryption method based on compressive sensing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive sensing; Image encryption; Parallel structure; Chaotic
   model; Optimal diffusion
ID SIGNAL RECONSTRUCTION
AB Recently, compressive sensing-based encryption methods which combine sampling, compression and encryption together have been proposed. However, since the quantized measurement data obtained from linear dimension reduction projection directly serve as the encrypted image, the existing compressive sensing-based encryption methods fail to resist against the chosen-plaintext attack. To enhance the security, a block cipher structure consisting of scrambling, mixing, S-box and chaotic lattice XOR is designed to further encrypt the quantized measurement data. In particular, the proposed method works efficiently in the parallel computing environment. Moreover, a communication unit exchanges data among the multiple processors without collision. This collision-free property is equivalent to optimal diffusion. The experimental results demonstrate that the proposed encryption method not only achieves the remarkable confusion, diffusion and sensitivity but also outperforms the existing parallel image encryption methods with respect to the compressibility and the encryption speed.
C1 [Huang, R.; Rhee, K. H.; Uchida, S.] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Nishi Ku, Fukuoka 812, Japan.
   [Rhee, K. H.] Pukyong Natl Univ, Dept IT Convergence & Applicat Engn, Pusan 608737, South Korea.
C3 Kyushu University; Pukyong National University
RP Huang, R (corresponding author), Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Nishi Ku, 744 Motooka, Fukuoka 812, Japan.
EM rong.huang01@gmail.com
OI Uchida, Seiichi/0000-0001-8592-7566
FU National Research Foundation of Korea [NRF-2011-013-D00121]
FX The second author acknowledges the support provided by Grant
   NRF-2011-013-D00121 from the National Research Foundation of Korea.
CR [Anonymous], HDB APPL CRYPTOGRAPH
   [Anonymous], J SOFTW
   Babadi B, 2010, IEEE T SIGNAL PROCES, V58, P4013, DOI 10.1109/TSP.2010.2048103
   Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P118, DOI 10.1109/MSP.2007.4286571
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P2992, DOI 10.1109/TIP.2007.909319
   Blumensath T, 2008, IEEE T SIGNAL PROCES, V56, P2370, DOI 10.1109/TSP.2007.916124
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Fei P, 2005, INT C COMMUN CIRCUIT, P1135
   Gan L, 2007, PROCEEDINGS OF THE 2007 15TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, P403
   Gao DH, 2010, LECT NOTES ARTIF INT, V6216, P334
   Gorodnitsky IF, 1997, IEEE T SIGNAL PROCES, V45, P600, DOI 10.1109/78.558475
   Grangetto M, 2006, IEEE T MULTIMEDIA, V8, P905, DOI 10.1109/TMM.2006.879919
   Lian S., 2008, Multimedia Content Encryption: Techniques And Applications
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Liu D. H., 2009, INT C WIRELESS COMMU, P1
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lustig M, 2008, IEEE SIGNAL PROC MAG, V25, P72, DOI 10.1109/MSP.2007.914728
   Mastan JMK, 2011, COMM COM INF SC, V193, P524
   Mirzaei O, 2012, NONLINEAR DYNAM, V67, P557, DOI 10.1007/s11071-011-0006-6
   Mollin R.A., 2006, An introduction to cryptography
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Orsdemir A, 2008, IEEE MILIT COMMUN C, P1040
   Rachlin Y, 2008, ANN ALLERTON CONF, P813, DOI 10.1109/ALLERTON.2008.4797641
   Shtewi AA, 2010, INT J COMPUT SCI NET, V10, P218
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Wang SH, 2002, PHYS REV E, V66, DOI 10.1103/PhysRevE.66.065202
   Wu C.P., 2000, SPIE INT S INFORM TE, V4209, P284
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Zhou Q, 2008, CHAOS SOLITON FRACT, V38, P1081, DOI 10.1016/j.chaos.2007.01.034
   [周庆 Zhou Qing], 2010, [电子与信息学报, Journal of Electronics & Information Technology], V32, P2015
NR 32
TC 95
Z9 98
U1 4
U2 81
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 71
EP 93
DI 10.1007/s11042-012-1337-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800005
DA 2024-07-18
ER

EF