FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Li, CF
   Yun, LX
   Xu, SK
AF Li, Chaofeng
   Yun, LiXia
   Xu, Shoukun
TI Blind stereoscopic image quality assessment using 3D saliency selected
   binocular perception and 3D convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind stereoscopic image quality assessment; Convolutional neural
   network; 3D saliency map; Summation and difference image; Cyclopean
   image
ID PREDICTION; ALGORITHM
AB The purpose of stereoscopic image quality assessment (SIQA) is to design an objective evaluation algorithm to automatically evaluate the quality of stereoscopic image. In this paper, we propose a blind SIQA method via 3D saliency selected binocular perception and 3D convolutional neural network (CNN). Given a pair of stereoscopic images, we first generate 3D saliency map by weighted average of 2D saliency map and depth saliency map. Then, when the value of 3D saliency map patches is higher than the setting threshold, these patches from left and right images are selected to feed to 3D-CNN to predict the perceived quality. Finally, the score of the distorted stereoscopic image is computed by the weighted average of the quality scores of these saliency image patches. Experimental results on LIVE 3D Phase I and Phase II databases show that our proposed method is robust and competitive with the state-of-the-art NR SIQA methods.
C1 [Li, Chaofeng; Yun, LiXia] Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 201306, Peoples R China.
   [Xu, Shoukun] Changzhou Univ, Sch Informat Sci & Engn, Changzhou 213164, Jiangsu, Peoples R China.
C3 Shanghai Maritime University; Changzhou University
RP Li, CF (corresponding author), Shanghai Maritime Univ, Inst Logist Sci & Engn, Shanghai 201306, Peoples R China.
EM wxlichaofeng@126.com
OI Li, Chaofeng/0000-0002-3236-3143
FU National Natural Science Foundation of China [62176150, 61771223]
FX This work was supported by the National Natural Science Foundation of
   China (No. 62176150, No. 61771223).
CR Agrawal, 2014, PIXELS VOXELS MODELI, V1, P1
   Akhter R, 2010, PROC SPIE, V7524, DOI 10.1117/12.838775
   Appina B, 2016, SIGNAL PROCESS-IMAGE, V43, P1, DOI 10.1016/j.image.2016.02.001
   Benoit A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/659024
   Chen MJ, 2013, SIGNAL PROCESS-IMAGE, V28, P1143, DOI 10.1016/j.image.2013.05.006
   Chen MJ, 2013, IEEE T IMAGE PROCESS, V22, P3379, DOI 10.1109/TIP.2013.2267393
   Han Y, 2016, IEEE T BROADCAST, V62, P654, DOI 10.1109/TBC.2016.2529294
   Henriksen S, 2016, CURR BIOL, V26, pR500, DOI 10.1016/j.cub.2016.04.049
   Hong GS, 2017, DISPLAYS, V49, P80, DOI 10.1016/j.displa.2017.07.006
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Jiang GY, 2018, IET IMAGE PROCESS, V12, P810, DOI 10.1049/iet-ipr.2017.0650
   Joveluro P, 2010, 3DTV CONF
   Kang L, 2014, PROC CVPR IEEE, P1733, DOI 10.1109/CVPR.2014.224
   Kim BG, 2003, PATTERN RECOGN LETT, V24, P2995, DOI 10.1016/S0167-8655(03)00160-0
   Kim BG, 2002, ELECTRON LETT, V38, P696, DOI 10.1049/el:20020507
   Kim J, 2017, IEEE SIGNAL PROC MAG, V34, P130, DOI 10.1109/MSP.2017.2736018
   Li SM, 2019, IEEE T MULTIMEDIA, V21, P2616, DOI 10.1109/TMM.2019.2907470
   Li YF, 2019, IEEE ACCESS, V7, P46706, DOI 10.1109/ACCESS.2019.2909073
   Li YM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P685, DOI 10.1109/ICDSP.2016.7868646
   LI ZP, 1994, NETWORK-COMP NEURAL, V5, P157, DOI 10.1088/0954-898X/5/2/003
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Liu Y, 2020, IEEE ACCESS, V8, P33666, DOI 10.1109/ACCESS.2020.2974006
   Lv YQ, 2016, SIGNAL PROCESS-IMAGE, V47, P346, DOI 10.1016/j.image.2016.07.003
   May KA, 2016, CURR BIOL, V26, P1571, DOI 10.1016/j.cub.2016.04.037
   May KA, 2012, CURR BIOL, V22, P28, DOI 10.1016/j.cub.2011.11.025
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2013, SIGNAL PROCESS-IMAGE, V28, P870, DOI 10.1016/j.image.2012.08.004
   Mukherjee P, 2019, IEEE IMAGE PROC, P4539, DOI [10.1109/icip.2019.8803717, 10.1109/ICIP.2019.8803717]
   Potapova Ekaterina, 2011, Computer Vision Systems. Proceedings 8th International Conference (ICVS 2011), P132, DOI 10.1007/978-3-642-23968-7_14
   Shao F, 2018, IEEE T CIRC SYST VID, V28, P573, DOI 10.1109/TCSVT.2016.2628082
   Shao F, 2017, IEEE ACCESS, V5, P15706, DOI 10.1109/ACCESS.2017.2733161
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Sun GM, 2020, IEEE T MULTIMEDIA, V22, P2938, DOI 10.1109/TMM.2020.2965461
   Talebi H, 2018, IEEE T IMAGE PROCESS, V27, P3998, DOI 10.1109/TIP.2018.2831899
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   Wang JH, 2015, IEEE T IMAGE PROCESS, V24, P3400, DOI 10.1109/TIP.2015.2446942
   Wang JL, 2013, IEEE T IMAGE PROCESS, V22, P2151, DOI 10.1109/TIP.2013.2246176
   Wang YF, 2019, NEUROCOMPUTING, V332, P298, DOI 10.1016/j.neucom.2018.12.029
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Yang J, 2019, REMOTE SENS-BASEL, V11, P1
   Yang JC, 2019, INFORM SCIENCES, V474, P1, DOI 10.1016/j.ins.2018.08.066
   Yang JC, 2018, NEUROCOMPUTING, V309, P83, DOI 10.1016/j.neucom.2018.04.072
   Yang JC, 2018, APPL OPTICS, V57, P3915, DOI 10.1364/AO.57.003915
   Yue GH, 2018, SIGNAL PROCESS, V150, P204, DOI 10.1016/j.sigpro.2018.04.019
   Zhang L, 2013, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2013.6738036
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang PB, 2019, IEEE T NEUR SYS REH, V27, P31, DOI 10.1109/TNSRE.2018.2884641
   Zhang W, 2016, PATTERN RECOGN, V59, P176, DOI 10.1016/j.patcog.2016.01.034
   Zhou WJ, 2017, PATTERN RECOGN, V71, P207, DOI 10.1016/j.patcog.2017.06.008
NR 52
TC 2
Z9 2
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18437
EP 18455
DI 10.1007/s11042-022-12707-4
EA MAR 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766430800010
DA 2024-07-18
ER

PT J
AU Parihar, AS
   Chakraborty, SK
AF Parihar, Ashish Singh
   Chakraborty, Swarnendu Kumar
TI Handling of resource allocation in flying ad hoc network through dynamic
   graph modeling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distributed system; Dynamic graphs; Flying ad hoc network; Resource
   allocation problem; Mutual exclusion; Neo4j
ID MUTUAL EXCLUSION ALGORITHM; DISTRIBUTED ALGORITHM
AB Now a days, Flying ad hoc network (FANET) as a trending wireless classification has a vibrant area of research. FANET architecture can also be viewed as a special form of a distributed system in which unmanned aerial vehicles are the nodes with highly dynamic behavior in terms of their mobility. Now, resource allocation problem is always a concern in distributed architecture, so as in FANET. The concept of mutual exclusion plays a vital role and ensures the access of shared resources in a mutual access manner by the nodes running on different processors. Through this research work, we modeled FANET as an application of a dynamic graph by applying its properties and propose a token-based resource allocation algorithm in FANET to achieve distributed mutual exclusion. We have used Neo4j as a graph database to model our work and present better results in terms of various performance metrics as compared to existing work in FANET till date.
C1 [Parihar, Ashish Singh; Chakraborty, Swarnendu Kumar] Natl Inst Technol NIT, Dept Comp Sci & Engn, Jote, Arunachal Prade, India.
   [Parihar, Ashish Singh] Delhi NCR, Dept Comp Sci, KIET Grp Inst, Ghaziabad, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Arunachal Pradesh; KIET Group of Institutions
RP Parihar, AS (corresponding author), Natl Inst Technol NIT, Dept Comp Sci & Engn, Jote, Arunachal Prade, India.; Parihar, AS (corresponding author), Delhi NCR, Dept Comp Sci, KIET Grp Inst, Ghaziabad, Uttar Pradesh, India.
EM ashish.phd20@nitap.ac.in; swarnendu@nitap.ac.in
RI Parihar, Ashish/GQA-7509-2022; Parihar, Ashish Singh/AAR-5709-2021
OI Parihar, Ashish Singh/0000-0003-3451-1557
CR Akyildiz IF, 2020, IEEE ACCESS, V8, P133995, DOI 10.1109/ACCESS.2020.3010896
   AL-Sharuee MT, 2021, APPL INTELL, V51, P51, DOI 10.1007/s10489-020-01668-6
   Anacleto O, 2017, BAYESIAN ANAL, V12, P491, DOI 10.1214/16-BA1010
   [Anonymous], 2012, Wkly Epidemiol Rec, V87, P1
   Attiya H, 2010, IEEE T MOBILE COMPUT, V9, P361, DOI 10.1109/TMC.2009.137
   Attiya H, 2008, INT CON DISTR COMP S, P321, DOI 10.1109/ICDCS.2008.82
   Azevedo M. I. B., 2019, Mob Comput, DOI [10.5772/intechopen.86544, DOI 10.5772/INTECHOPEN.86544]
   Baála H, 2003, J PARALLEL DISTR COM, V63, P97, DOI 10.1016/S0743-7315(02)00028-X
   Béres F, 2019, APPL NETW SCI, V4, DOI 10.1007/s41109-019-0169-5
   Chen Y, 2005, J PARALLEL DISTR COM, V65, P1072, DOI 10.1016/j.jpdc.2005.03.009
   CHEN Y., 2002, Proceedings of the 6th International Workshop on Discrete Algorithms and Methods for Mobile Computing and Communications, P34, DOI [10.1145/570810.570815, DOI 10.1145/570810.570815]
   DIJKSTRA EW, 1965, COMMUN ACM, V8, P569, DOI 10.1145/365559.365617
   DIJKSTRA EW, 1974, COMMUN ACM, V17, P643, DOI 10.1145/361179.361202
   Ferone Daniele, 2017, Pesqui. Oper., V37, P487
   Giordan D, 2020, B ENG GEOL ENVIRON, V79, P3437, DOI 10.1007/s10064-020-01766-2
   Harary F, 1997, MATH COMPUT MODEL, V25, P79, DOI 10.1016/S0895-7177(97)00050-2
   Ismail DPII, 2007, 2007 ASIA-PACIFIC CONFERENCE ON APPLIED ELECTROMAGNETICS, PROCEEDINGS, P519
   Jain M, 2017, 2017 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P1957, DOI 10.1109/ICCSP.2017.8286742
   Kazemi S. M., 2020, J MACH LEARN RES, V21, p70:1
   Khanna A, 2020, COMPUT COMMUN, V156, P101, DOI 10.1016/j.comcom.2020.03.036
   Khanna A, 2019, COMPUT ELECTR ENG, V76, P82, DOI 10.1016/j.compeleceng.2019.03.005
   Khanna A, 2016, ARAB J SCI ENG, V41, P5181, DOI 10.1007/s13369-016-2199-y
   Lim J, 2018, J SUPERCOMPUT, V74, P1090, DOI 10.1007/s11227-016-1799-3
   Mellier R., 2004, MOBILE WIRELESS COMM, V162, DOI [10.1007/0-387-23150-1_25, DOI 10.1007/0-387-23150-1_25]
   Muzaffar R, 2020, AUTON ROBOT, V44, P75, DOI 10.1007/s10514-019-09851-6
   Parihar A.S., 2021, P INT C MACHINE INTE, DOI [10.1007/978-981-33- 4087-9_5, DOI 10.1007/978-981-33-4087-9_5]
   Parihar AS, 2022, WIREL NETW, V28, P779, DOI 10.1007/s11276-022-02889-y
   Parihar AS, 2021, J SUPERCOMPUT, V77, P14305, DOI 10.1007/s11227-021-03802-8
   Pokorny J, 2015, LECT NOTES COMPUT SC, V9339, P58, DOI 10.1007/978-3-319-24369-6_5
   Sang QQ, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12060971
   Shakhatreh H, 2019, IEEE ACCESS, V7, P48572, DOI 10.1109/ACCESS.2019.2909530
   Shehu HA, 2020, IEEE ACCESS, V8, P138277, DOI 10.1109/ACCESS.2020.3012573
   Singhal M, 1997, INTELLIGENT INFORMATION SYSTEMS, (IIS'97) PROCEEDINGS, P557, DOI 10.1109/IIS.1997.645389
   Srivastava A, 2021, COMPUT SCI REV, V39, DOI 10.1016/j.cosrev.2020.100359
   Tamhane SA, 2012, PERVASIVE MOB COMPUT, V8, P795, DOI 10.1016/j.pmcj.2011.08.002
   Thiare O., 2012, FGCN COMMUNICATIONS, V350, DOI [10.1007/978-3-642-35594-3_34, DOI 10.1007/978-3-642-35594-3_34]
   Thiare O, 2007, INNOVATIONS AND ADVANCED TECHNIQUES IN COMPUTER AND INFORMATION SCIENCES AND ENGINEERING, P373, DOI 10.1007/978-1-4020-6268-1_67
   Walter JE, 2001, WIREL NETW, V7, P585, DOI 10.1023/A:1012363200403
   Wang Z, 2007, J SYST ENG ELECTRON, V18, P398, DOI 10.1016/S1004-4132(07)60104-2
   Wu W, 2007, LECT NOTES COMPUT SC, V4864, P572
   Wu WG, 2015, IEEE T PARALL DISTR, V26, P65, DOI 10.1109/TPDS.2013.2297097
   Wu WG, 2008, PERVASIVE MOB COMPUT, V4, P139, DOI 10.1016/j.pmcj.2007.08.001
   Zaki A, 2016, INT J ADV COMPUT SC, V7, P573
   Zhang X, 2017, EUR PHYS J B, V90, DOI 10.1140/epjb/e2017-80122-8
NR 44
TC 9
Z9 9
U1 3
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 13
BP 18641
EP 18669
DI 10.1007/s11042-022-11950-z
EA MAR 2022
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1A5TI
UT WOS:000766438300018
DA 2024-07-18
ER

PT J
AU Khehra, BS
   Pharwaha, APS
   Jindal, B
   Mavi, BS
AF Khehra, Baljit Singh
   Pharwaha, Amar Partap Singh
   Jindal, Balkrishan
   Mavi, Bhupinder Singh
TI Classification of clustered microcalcifications using different variants
   of backpropagation training algorithms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Back propagation; Breast cancer; Gaussian fuzzy membership function;
   Levenberg-Marquardt training algorithm; Microcalcifications; TLBO
ID LEARNING-BASED OPTIMIZATION; CONTRAST ENHANCEMENT; AUTOMATIC DETECTION;
   FEATURES; DESIGN
AB In mammography, the most frequently type of breast cancer recognized is DCISand the most frequent signs of DCIS are MCCs. In the proposed research work, MCs are enhanced using fuzzy approach. In this approach Gaussian fuzzy membership function is used and its parameters are optimized by TLBO. After this, the local window based statistical texture features are extracted from ROIs of enhanced mammograms. At the end, different variants of Back propagation are explored to divide MCCs into two categories, one is benign and other is malignant. Here, the main goal is to select an optimal classifier for classifying MCCs as benign or malignant because the performance of CAD system depends on classifier. In this study,the performance of different variants of Back propagationtraining algorithms is not only examined from the accuracy point of view, but also examined from computational point of view. For evaluating the performance of different variants of Back propagation training algorithms, texture features are extracted from mammograms. For experimental results, mammograms of mini-MIAS database are considered.The accuracy is calculated from ROC.88.24% accuracy is achieved by Levenberg-Marquardt training algorithm that is the highest among other variants of Back propagation. Mean Square Error in Levenberg-Marquardt training algorithm case is 3.68e-16 that is the lowest among other variants of Back propagation. Levenberg-Marquardt training algorithm is trained in only 23 iterations for obtaining the above said accuracy. Thus, from experimental results, it is observed that the performance of Levenberg-Marquardt training algorithm is better than other variants of Backpropagation from the accuracy point of view and the computational complexity point of view.
C1 [Khehra, Baljit Singh] Baba Banda Singh Bahadur Engn Coll, Dept Comp Sci & Engn, Fatehgarh Sahib 140407, Punjab, India.
   [Pharwaha, Amar Partap Singh] SantLongowal Inst Engn & Technol, Dept Elect & Commun Engn, Sangrur 148106, Punjab, India.
   [Jindal, Balkrishan] Punjabi Univ, Yadvindra Coll Engn, Comp Engn Sect, Guru Kashi Campus, Talwandi Sabo 151302, Punjab, India.
   [Mavi, Bhupinder Singh] HNC Virtual Solut, 50430 Pontiac Trail, Wixon, MI 48393 USA.
C3 Sant Longowal Institute of Engineering & Technology (SLIET); Punjabi
   University
RP Jindal, B (corresponding author), Punjabi Univ, Yadvindra Coll Engn, Comp Engn Sect, Guru Kashi Campus, Talwandi Sabo 151302, Punjab, India.
EM Baljitkhehra74@gmail.com; amarpartapsingh@yahoo.com;
   balkrishan@pbi.ac.in; bmavi@hnc-vs.com
CR Alam N, 2019, J IMAGING, V5, DOI 10.3390/jimaging5090076
   Arodz T, 2005, COMPUT METH PROG BIO, V79, P135, DOI 10.1016/j.cmpb.2005.03.009
   Aslan AA, 2021, ACAD RADIOL, V28, P963, DOI 10.1016/j.acra.2020.05.032
   Basile TMA, 2019, PHYS MEDICA, V64, P1, DOI 10.1016/j.ejmp.2019.05.022
   Cascio D, 2018, P 2018 IEEE NUCL SCI, P1
   Cheng HD, 2006, PATTERN RECOGN, V39, P646, DOI 10.1016/j.patcog.2005.07.006
   Cheng HD, 1998, INT C PATT RECOG, P1549, DOI 10.1109/ICPR.1998.712004
   Christopher D., 2020, P COMPUT SCI, V167, P285, DOI [10.1016/j.procs.2020.03.223, DOI 10.1016/J.PROCS.2020.03.223]
   DHAWAN AP, 1986, IEEE T MED IMAGING, V5, P8, DOI 10.1109/TMI.1986.4307733
   Fu JC, 2005, COMPUT MED IMAG GRAP, V29, P419, DOI 10.1016/j.compmedimag.2005.03.002
   GORDON R, 1984, APPL OPTICS, V23, P560, DOI 10.1364/AO.23.000560
   Gulsrud TO, 2001, IEEE T BIO-MED ENG, V48, P1272, DOI 10.1109/10.959323
   Helwan A, 2017, PROCEDIA COMPUT SCI, V120, P402, DOI 10.1016/j.procs.2017.11.256
   Henley SJ, 2020, CANCER-AM CANCER SOC, V126, P2225, DOI [10.1002/cncr.32802, 10.1002/cncr.31551]
   Howell A, 2010, BREAST CANCER RES, V12, DOI 10.1186/bcr2739
   Jebathangam J., 2021, 2021 5th International Conference on Intelligent Computing and Control Systems (ICICCS), P806, DOI 10.1109/ICICCS51141.2021.9432381
   Jenifer S, 2016, APPL SOFT COMPUT, V42, P167, DOI 10.1016/j.asoc.2016.01.039
   Jia HM, 2019, IEEE ACCESS, V7, P134448, DOI 10.1109/ACCESS.2019.2942064
   Jiang JM, 2005, COMPUT MED IMAG GRAP, V29, P83, DOI 10.1016/j.compmedimag.2004.06.005
   Khairuzzaman AKM, 2019, MULTIMED TOOLS APPL, V78, P33573, DOI 10.1007/s11042-019-08117-8
   Kim JK, 1997, NEURAL NETWORKS FOR SIGNAL PROCESSING VII, P199, DOI 10.1109/NNSP.1997.622399
   MCSWEENEY MB, 1983, AM J ROENTGENOL, V140, P9, DOI 10.2214/ajr.140.1.9
   Mohanalin, 2010, COMPUT MATH APPL, V60, P2426, DOI 10.1016/j.camwa.2010.08.038
   Mohanalin, 2010, SIGNAL PROCESS, V90, P952, DOI 10.1016/j.sigpro.2009.09.012
   Mohanalin J, 2009, 2009 IEEE INTERNATIONAL ADVANCE COMPUTING CONFERENCE, VOLS 1-3, P636, DOI 10.1109/IADCC.2009.4809086
   Mohanalin J, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL ACQUISITION AND PROCESSING, P3, DOI 10.1109/ICSAP.2009.17
   MORROW WM, 1992, IEEE T MED IMAGING, V11, P392, DOI 10.1109/42.158944
   Muthuvel M, 2017, PATTERN RECOGN LETT, V94, P127, DOI 10.1016/j.patrec.2017.05.002
   Pal NR, 2008, NEUROCOMPUTING, V71, P2625, DOI 10.1016/j.neucom.2007.06.015
   Rao RV, 2015, ENERGY, V80, P535, DOI 10.1016/j.energy.2014.12.008
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Ren JC, 2011, ENG APPL ARTIF INTEL, V24, P638, DOI 10.1016/j.engappai.2011.02.011
   Saad G, 2016, EGYPT J RADIOL NUC M, V47, P1803, DOI 10.1016/j.ejrnm.2016.08.020
   Sahu BK, 2015, APPL SOFT COMPUT, V27, P240, DOI 10.1016/j.asoc.2014.11.027
   Shachor Y, 2019, I S BIOMED IMAGING, P1065, DOI [10.1109/ISBI.2019.8759433, 10.1109/isbi.2019.8759433]
   Sheshadri HS, 2007, COMPUT MED IMAG GRAP, V31, P46, DOI 10.1016/j.compmedimag.2006.09.015
   SICKLES EA, 1986, RADIOLOGY, V160, P289, DOI 10.1148/radiology.160.2.3726103
   Soltanian-Zadeh H, 2004, PATTERN RECOGN, V37, P1973, DOI 10.1016/j.patcog.2003.03.001
   Sujatha K, 2020, ADV UBIQUIT SENS APP, V7, P115, DOI 10.1016/B978-0-12-815369-7.00005-7
   Sundaram M, 2011, APPL SOFT COMPUT, V11, P5809, DOI 10.1016/j.asoc.2011.05.003
   Tawani Sagar S., 2019, 2019 International Conference on Innovative Trends and Advances in Engineering and Technology (ICITAET), P47, DOI 10.1109/ICITAET47105.2019.9170247
   THURFJELL EL, 1994, RADIOLOGY, V191, P241, DOI 10.1148/radiology.191.1.8134580
   Touil A, 2020, BIOCYBERN BIOMED ENG, V40, P1155, DOI 10.1016/j.bbe.2020.05.002
   Tripathy S., 2020, P COMPUT SCI, V171, P1848, DOI [10.1016/j.procs.2020.04.198, DOI 10.1016/J.PROCS.2020.04.198]
   Verma B, 2010, EXPERT SYST APPL, V37, P3344, DOI 10.1016/j.eswa.2009.10.016
   Wirth MA, 2005, NAFIPS 2005 - 2005 Annual Meeting of the North American Fuzzy Information Processing Society, P436, DOI 10.1109/NAFIPS.2005.1548575
   Yu SN, 2010, EXPERT SYST APPL, V37, P5461, DOI 10.1016/j.eswa.2010.02.066
NR 47
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17509
EP 17526
DI 10.1007/s11042-022-12017-9
EA MAR 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000765701900007
DA 2024-07-18
ER

PT J
AU Liu, TY
   Yan, DQ
   Yan, N
   Chen, G
AF Liu, Tianyun
   Yan, Diqun
   Yan, Nan
   Chen, Gang
TI Anti-forensics of fake stereo audio using generative adversarial network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generative adversarial network; Anti-forensics; Stereo faking
ID IDENTIFICATION; VERIFICATION
AB Fake-quality audio detection is an important branch in the field of digital audio forensics. Resampling and recompression are the two typical operations to achieve fake audio quality, in which an audio with low sampling/bit rate can be converted to one with higher sampling/bit rate pretending to be in high quality. Stereo-faking is another fake-quality operation, with which a mono audio can be converted into a stereo one. To detect the stereo-faking, a few forensic methods have been proposed. Little consideration, however, has been given to the security of these methods themselves. To expose the weakness of these stereo-faking detectors, an anti-forensic framework based on generative adversarial network is proposed. The fake stereo audio is created by generating a new channel audio based on a mono audio. Skip connection is adopted to ensure the quality of the generated audio. Considering that stereo application scenarios are mostly music and film recording, a large number of music and film recordings are downloaded from the Internet as our datasets. Use these datasets to train our model. The anti-forensic samples generated by the model are used to attack the most effective fake stereo audio detectors. Experimental results show that the generated fake stereo audio of music can significantly reduce its detection accuracy from about 99-30%, and the false acceptance rate can increase from 0.08% to about 69%. The fake stereo audio generated from the film recording can significantly reduce its detection accuracy from about 99-1.7%, and the false acceptance rate can increase from 0.02% to about 98%.
C1 [Liu, Tianyun; Yan, Diqun] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
   [Yan, Nan; Chen, Gang] Ningbo Polytech, Ningbo 315800, Zhejiang, Peoples R China.
C3 Ningbo University; Ningbo Polytechnic
RP Yan, DQ (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
EM yandiqun@nbu.edu.cn
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276
FU National Natural Science Foundation of China [61300055]; Zhejiang
   Natural Science Foundation [LY20F020010, LY17F020010]; Ningbo Natural
   Science Foundation [202003N4089]; Ningbo Science and Technology
   Innovation 2025 Major Project [2018B10010, 2019B10075]; K.C. Wong Magna
   Fund in Ningbo University
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61300055), Zhejiang Natural Science Foundation (Grant
   No. LY20F020010, LY17F020010), Ningbo Natural Science Foundation (Grant
   No. 202003N4089), Ningbo Science and Technology Innovation 2025 Major
   Project (Grant No. 2018B10010, 2019B10075), and K.C. Wong Magna Fund in
   Ningbo University.
CR Bao Yongqiang, 2016, Journal of Data Acquisition and Processing, V31, P252, DOI 10.16337/j.1004-9037.2016.02.003
   Chen C, 2018, IEEE IMAGE PROC, P535, DOI 10.1109/ICIP.2018.8451503
   Chintala S., 2017, TRAIN GAN TIPS TRICK
   Collobert R, 2011, BIGLEARN NIPS WORKSH, P1
   Da Luo, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2669, DOI 10.1109/ICASSP.2014.6854084
   Galka J, 2015, SPEECH COMMUN, V67, P143, DOI 10.1016/j.specom.2014.12.003
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   HAAS H, 1972, J AUDIO ENG SOC, V20, P146
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Li XW, 2019, IEEE ACCESS, V7, P184332, DOI 10.1109/ACCESS.2019.2960097
   Liu T, 2021, ARXIV210409832
   Luo D, 2018, IEEE T INF FOREN SEC, V13, P2179, DOI 10.1109/TIFS.2018.2812185
   Luo D, 2017, IEEE T INF FOREN SEC, V12, P432, DOI 10.1109/TIFS.2016.2622012
   Mascia M, 2015, P 23 EUR SIGN PROC C, P357
   MUNSON WA, 1950, J ACOUST SOC AM, V22, P675, DOI 10.1121/1.1917190
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Peng F, 2020, IEEE T MULTIMEDIA, V22, P2511, DOI 10.1109/TMM.2019.2959443
   Qi SM, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P426, DOI 10.1109/SIPROCESS.2016.7888298
   Quackenbush S.R., 1988, Objective Measures of Speech Quality
   Wu HJ, 2014, IEEE T INF FOREN SEC, V9, P489, DOI 10.1109/TIFS.2014.2301912
   Wu HJ, 2013, INT CONF ACOUST SPEE, P3013, DOI 10.1109/ICASSP.2013.6638211
   Wu JY, 2020, ASIAPAC SIGN INFO PR, P1442
   Wu T, 2020, LECT NOTES ELECT ENG, P25
   Xu H., 2018, TELECOMMUN SCI, V34, P46
   Yan DQ, 2020, SECUR COMMUN NETW, V2020, DOI 10.1155/2020/8849902
   Yang R, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P117
   Zhao H, 2016, IEEE T INF FOREN SEC, V11, P1603, DOI 10.1109/TIFS.2016.2543205
   Zou L, 2015, INT CONF ACOUST SPEE, P1787, DOI 10.1109/ICASSP.2015.7178278
NR 28
TC 1
Z9 1
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 17155
EP 17167
DI 10.1007/s11042-022-12448-4
EA MAR 2022
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000764960200003
DA 2024-07-18
ER

PT J
AU Arora, A
   Sharma, RK
AF Arora, Amit
   Sharma, Rajendra K.
TI Cryptanalysis and enhancement of image encryption scheme based on
   word-oriented feed back shift register
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Decryption; Chosen plaintext attack; wfsr; Logistic map;
   Arnold transformation
ID CHAOTIC SYSTEM; COMBINATION
AB In the recent past, an image encryption scheme has been proposed by Deb et al., based on the Logistic map, Arnold transformation, and word-oriented feedback shift register (wfsr). In this scheme, first the plain image is randomized and scrambled with the help of a Logistic map and Arnold transformation. Then, the pixels of an intermediate image are bit-wise XORed with output of the wfsr to obtain the cipher image. It is claimed that the scheme is secure against brute force and other existing cryptanalytical attacks. However, it is demonstrated that the scheme is not secure against chosen plaintext attack (CPA). In our study, first, the output sequence of wfsr, corresponding to the fixed key, is obtained by choosing one plain and cipher image pair. Subsequently, the composition of Logistic map and Arnold transformation is inverted with the help of four randomly chosen plain and cipher image pairs. After that, the plain image is retrieved from the cipher image in real-time with the help of recovered wfsr sequence and inverse of composite function. Mathematical proof and experimental validation is given. Based on this analysis, the reason for applicability of CPA is discussed. Finally, the original scheme is modified in such a way that it resists CPA and also maintains the qualities of the original scheme.
C1 [Arora, Amit; Sharma, Rajendra K.] Indian Inst Technol, Dept Math, New Delhi 110016, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Arora, A (corresponding author), Indian Inst Technol, Dept Math, New Delhi 110016, India.
EM amitarora.iitd@gmail.com; rksharmaiitd@gmail.com
OI Arora, Amit/0000-0002-7431-6548
CR Abd El-Latif A. A., 2012, RES J APPL SCI ENG T, V4, P322
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Abd El-Latif AA, 2013, AEU-INT J ELECTRON C, V67, P136, DOI 10.1016/j.aeue.2012.07.004
   Aissa B, 2013, NEW TRENDS MATH SCI, V1, P10
   [Anonymous], 2007, IACR CRYPTOLOGY EPRI
   [Anonymous], 2014, IMAGE ENCRYPTION USI, DOI DOI 10.1109/ICRTIT.2014.6996091
   Arnold V. I., 1968, ERGODIC PROBLEMS CLA
   Bao JH, 2012, NONLINEAR DYNAM, V70, P1365, DOI 10.1007/s11071-012-0539-3
   Chen JX, 2018, NONLINEAR DYNAM, V93, P2399, DOI 10.1007/s11071-018-4332-9
   Chen L, 2017, NONLINEAR DYNAM, V87, P1797, DOI 10.1007/s11071-016-3153-y
   Deb S, 2021, MULTIMED TOOLS APPL, V80, P19803, DOI 10.1007/s11042-020-10308-7
   Deb S, 2019, MULTIMED TOOLS APPL, V78, P34901, DOI 10.1007/s11042-019-08086-y
   Dou YQ, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062187
   DYSON FJ, 1992, AM MATH MON, V99, P603, DOI 10.2307/2324989
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Guo Q, 2010, OPT LASER ENG, V48, P1174, DOI 10.1016/j.optlaseng.2010.07.005
   Hu GQ, 2017, NONLINEAR DYNAM, V88, P1305, DOI 10.1007/s11071-016-3311-2
   Kaur Gurjinder, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P727, DOI 10.1109/SPIN48934.2020.9071330
   Kaur G, 2021, ARCH COMPUT METHOD E, V28, P3517, DOI 10.1007/s11831-020-09512-3
   Kumar S, 2017, MULTIMED TOOLS APPL, V76, P8757, DOI 10.1007/s11042-016-3504-1
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li CQ, 2014, NONLINEAR DYNAM, V78, P1545, DOI 10.1007/s11071-014-1533-8
   Li CQ, 2013, NONLINEAR DYNAM, V73, P2083, DOI 10.1007/s11071-013-0924-6
   Li M, 2013, ADV INTEL SYS RES, V84, P1309
   Liu Y, 2020, NONLINEAR DYNAM, V100, P2917, DOI 10.1007/s11071-020-05654-y
   Liu ZJ, 2012, OPT LASER ENG, V50, P248, DOI 10.1016/j.optlaseng.2011.08.006
   Liu ZJ, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3557790
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Ma YL, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102566
   Mao YB, 2005, HANDBOOK OF GEOMETRIC COMPUTING: APPLICATIONS IN PATTERN RECOGNITION, COMPUTER VISION, NEURALCOMPUTING, AND ROBOTICS, P231, DOI 10.1007/3-540-28247-5_8
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Solak E, 2010, INT J BIFURCAT CHAOS, V20, P1405, DOI 10.1142/S0218127410026563
   Vajapeyam, ARXIV14052061 CORR
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   Wu JH, 2021, J MOD OPTIC, V68, P409, DOI 10.1080/09500340.2021.1900440
   Wu JJ, 2021, MULTIMED TOOLS APPL, V80, P2647, DOI 10.1007/s11042-020-09828-z
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhu CX, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20110843
NR 39
TC 4
Z9 4
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 12
BP 16679
EP 16705
DI 10.1007/s11042-022-11973-6
EA MAR 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0Z1RL
UT WOS:000763872100012
DA 2024-07-18
ER

PT J
AU Song, Q
   Wang, H
   Yang, L
   Xin, XS
   Liu, C
   Hu, MJ
AF Song, Qing
   Wang, Hao
   Yang, Lu
   Xin, Xueshi
   Liu, Chun
   Hu, Mengjie
TI Double parallel branches FCOS for human detection in a crowd
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Deep learning; Human detection; Image
   processing
ID NMS
AB The improvement from region-level to pixel-level and fewer hyper-parameters make anchor-free detectors popular. Most anchor-free algorithms will set a center-ness branch to reduce prediction points far away from the center of the target, which will indirectly weaken the more important features of the head in the pedestrian dataset. However, in a dense crowd, the head features of humans are critical to alleviating the problem of occlusion. In order to alleviate this problem, we have counted the characteristics of the target scale of a dense pedestrian dataset and introduced a Double Parallel Branches FCOS(DPB-FCOS) detector method. Based on the original prediction branch, we add a head branch to generate additional prediction boxes, and redefine the positive sample selection method of this branch, so that it can generate more prediction boxes in the head position of the human body. At the same time, considering the three factors of overlap area, distance, and aspect ratio, we designed a regression loss that is more suitable for anchor-free detectors. The center point distance in DIoU is used instead by the distance between the upper left and lower right corner points, which significantly improves the model's performance. We verify our method on two popular models. Compared with baseline, FCOS can improve the accuracy by 5.9% and ATSS can improve the accuracy by 3.8% on the CrowdHuman dataset.
C1 [Song, Qing; Wang, Hao; Yang, Lu; Xin, Xueshi; Liu, Chun; Hu, Mengjie] Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Vis Lab, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Song, Q (corresponding author), Beijing Univ Posts & Telecommun, Pattern Recognit & Intelligent Vis Lab, Beijing, Peoples R China.
EM priv@bupt.edu.cn; wanghao1996@bupt.edu.cn; soeaver@bupt.edu.cn;
   61730607@qq.com; chun.liu@bupt.edu.cn; mengjie.hu@bupt.edu.cn
RI yang, lu/GLV-5144-2022; Liu, Chun/I-1886-2016
OI Liu, Chun/0000-0002-2834-9461
CR [Anonymous], 2013, P IEEE COMP SOC C CO
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Du XZ, 2017, IEEE WINT CONF APPL, P953, DOI 10.1109/WACV.2017.111
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Huang X, 2020, PS RCNN DETECTING SE
   Huang Z, 2020, VISIBLE FEATURE GUID
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2019, 2019 IEEECVF C COMPU
   Liu W, 2017, 2017 IEEE INT C COMP
   Liu W, 2018, LECT NOTES COMPUT SC, V11218, P643, DOI 10.1007/978-3-030-01264-9_38
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Novak B, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P165, DOI [10.1109/zinc50678.2020.9161446, 10.1109/ZINC50678.2020.9161446]
   Pang C., 2020, MULTIMED TOOLS APPL, V6, P1
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Santosh KC, 2020, MULTIMED TOOLS APPL, V79, P34697, DOI 10.1007/s11042-020-10093-3
   Shao S., 2018, CROWDHUMAN BENCHMARK
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Q., 2020, J SEL TOP APPL EARTH, V99, P1
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang S., 2018, PCN PART CONTEXT INF
   Wang X, 2017, Point linking network for object detection
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Xiao Y, 2020, MULTIMED TOOLS APPL
   Yang L, 2020, P ECCV
   Zhang Kevin, 2019, DOUBLE ANCHOR R CNN
   Zhang SJ, 2020, I S MOD ANAL SIM COM, P1, DOI 10.1109/mascots50786.2020.9285955
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou CL, 2018, LECT NOTES COMPUT SC, V11205, P138, DOI 10.1007/978-3-030-01246-5_9
   Zhou SR, 2021, MULTIMED TOOLS APPL, V80, P11539, DOI 10.1007/s11042-020-10191-2
NR 48
TC 1
Z9 1
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15707
EP 15723
DI 10.1007/s11042-022-12439-5
EA MAR 2022
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762902200007
DA 2024-07-18
ER

PT J
AU Hu, J
   Xiawu, LJ
   Qiao, SJ
   Tan, WR
   Yin, F
   Liu, T
   Han, N
AF Hu, Jian
   Xiawu, Lijia
   Qiao, Shaojie
   Tan, Wenrong
   Yin, Feng
   Liu, Tao
   Han, Nan
TI Geometric correction method for Tibetan woodcut document images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tibetan woodcut document; Document image; Skew detection; Geometric
   correction; Projective transformation
ID SKEW; DISTORTION
AB In the information age, a large volume of Tibetan document images in woodcut edition have been produced. Geometric correction for Tibetan images is the basis of document analysis and character recognition, to which the traditional methods cannot be easily applied because of the complexity and variability of page deformation. To solve the above difficulties, we propose a new geometric correction method that is different from the existing methods. Firstly, we give a generic definition of piecewise strategy for image geometric correction by taking into full consideration the difficulty of seamless joint between sub-images. Then, we provide an effective geometric correction solution for Tibetan document images in woodcut edition, and theoretically prove the condition of seamless splicing between sub-images. According to this condition, appropriate reference points are selected to partition a Tibetan document image into several sub-images, then these sub-images are corrected by projective transformation, and finally the corrected sub-images are spliced to compose a corrected Tibetan document image. Experiments were conducted on real Tibetan woodcut document images by comparing the proposed method with classical algorithms including the FFT (Fast Fourier Transformation) method, the Hough method, the projection profile method and the cross correlation method. The visualized observation results and the statistical results proved that the proposed method can obtain a better correction performance, and took less than half the time of the comparison methods.
C1 [Hu, Jian; Tan, Wenrong] Southwest MinZu Univ, Key Lab Comp Syst, State Ethn Affairs Commiss, Chengdu 610041, Peoples R China.
   [Hu, Jian] Southwest MinZu Univ, Minzu Languages Informat Proc Lab, Chengdu 610041, Peoples R China.
   [Hu, Jian; Tan, Wenrong; Liu, Tao] Southwest MinZu Univ, Sch Comp Sci & Technol, Chengdu 610041, Peoples R China.
   [Xiawu, Lijia] Southwest MinZu Univ, Southwest Nationalities Res Acad, Chengdu 610041, Peoples R China.
   [Qiao, Shaojie] Chengdu Univ Informat Technol, Sch Software Engn, Chengdu 610225, Peoples R China.
   [Qiao, Shaojie] Chengdu Univ Informat Technol, Automat Software Generat & Intelligence Serv, Key Lab Sichuan Prov, Chengdu 610225, Peoples R China.
   [Yin, Feng] Southwest MinZu Univ, Lib, Chengdu 610041, Peoples R China.
   [Han, Nan] Chengdu Univ Informat Technol, Sch Management, Chengdu 610225, Peoples R China.
C3 Southwest Minzu University; Southwest Minzu University; Southwest Minzu
   University; Southwest Minzu University; Chengdu University of
   Information Technology; Chengdu University of Information Technology;
   Southwest Minzu University; Chengdu University of Information Technology
RP Qiao, SJ (corresponding author), Chengdu Univ Informat Technol, Sch Software Engn, Chengdu 610225, Peoples R China.; Qiao, SJ (corresponding author), Chengdu Univ Informat Technol, Automat Software Generat & Intelligence Serv, Key Lab Sichuan Prov, Chengdu 610225, Peoples R China.
EM hujian@swun.edu.cn; sjqiao@cuit.edu.cn
OI Qiao, Shaojie/0000-0002-4703-780X; Hu, Jian/0000-0001-8292-0190
FU National Natural Science Foundation of China [16BTQ037, 61772091,
   61802035, 61962006, 61962038, U1802271, U2001212, 62072311]; Fundamental
   Research Funds for the Central Universities [2020NQN23]; Sichuan Science
   and Technology Program [2021JDJQ0021, 22ZDYF2680, 2021YZD0009,
   2021ZYD0033]; Chengdu Major Science and Technology Innovation Project
   [2021-YF08-00156-GX, 2021-YF08-00159-GX]; Chengdu Technology Innovation
   and Research and Development Project [2021-YF05-00491-SN,
   2021-YF05-02414-GX, 2021-YF05-02413-GX, 2021-YF05-02424-GX,
   2021-JB00-00025-GX]; Chengdu "Take the lead" Science and Technology
   Project [2021-JB00-00025-GX]; Digital Media Art, Key Laboratory of
   Sichuan Province, Sichuan Conservatory of Music, Chengdu, China
   [21DMAKL02]; College Student Innovation and Entrepreneurship Training
   Program of Chengdu University of Information Technology [202110621179,
   202110621186]; Science and Technology Innovation Seedling Project of
   Sichuan Province [2021006]; Guangdong Basic and Applied Basic Research
   Foundation [2020B1515120028]
FX This work was partially supported by National Natural Science Foundation
   of China under grants 16BTQ037, 61772091, 61802035, 61962006, 61962038,
   U1802271, U2001212, 62072311; Fundamental Research Funds for the Central
   Universities under grant 2020NQN23; Sichuan Science and Technology
   Program under grants 2021JDJQ0021, 22ZDYF2680, 2021YZD0009, 2021ZYD0033;
   Chengdu Major Science and Technology Innovation Project under grant
   2021-YF08-00156-GX, 2021-YF08-00159-GX; Chengdu Technology Innovation
   and Research and Development Project under grant 2021-YF05-00491-SN,
   2021-YF05-02414-GX, 2021-YF05-02413-GX, 2021-YF05-02424-GX; Chengdu
   "Take the lead" Science and Technology Project under grant
   2021-JB00-00025-GX; Digital Media Art, Key Laboratory of Sichuan
   Province, Sichuan Conservatory of Music, Chengdu, China under grant
   21DMAKL02; College Student Innovation and Entrepreneurship Training
   Program of Chengdu University of Information Technology, under grants
   202110621179, 202110621186; Science and Technology Innovation Seedling
   Project of Sichuan Province under grant 2021006; Guangdong Basic and
   Applied Basic Research Foundation under grant 2020B1515120028.
CR Ai SJ, 2013, OPTIK, V124, P7014, DOI 10.1016/j.ijleo.2013.05.160
   [Anonymous], 2014, INT J SCI RES PUBL
   Boudraa O, 2020, MATH COMPUT SIMULAT, V167, P389, DOI 10.1016/j.matcom.2019.05.009
   HANEISHI H, 1995, IEEE T MED IMAGING, V14, P548, DOI 10.1109/42.414620
   Huang HM, 2014, OPTIK, V125, P1034, DOI 10.1016/j.ijleo.2013.07.101
   Jan, 2013, STRAIGHTEN IMAGE
   Jundale TA, 2015, PROCEDIA COMPUT SCI, V45, P305, DOI 10.1016/j.procs.2015.03.147
   Lu Y, 2003, PROC INT CONF DOC, P503
   Mandip K., 2013, INT J SCI TECHNOL RE, V2, P164
   Mohammed SW, 2018, L N COMPUT VIS BIOME, V28, P556, DOI 10.1007/978-3-319-71767-8_48
   Ngodrup, 2010, P CHIN C PATT REC CC, P84
   Pstl, 1986, P 8 INT C PATT REC, P487
   Ramanan M., 2019, Asian J. Res. Comput. Sci., V4, P1
   Shemiakina J, 2017, PROC SPIE, V10341, DOI 10.1117/12.2268590
   Shi, 2006, P S HIST PRINT CHIN, P73
   Subrahmanyam M. S. L. B., 2018, International Journal of Image, Graphics and Signal Processing, V10, P47, DOI 10.5815/ijigsp.2018.03.06
   Vinod HC, 2018, ADV INTELL SYST, V721, P376, DOI 10.1007/978-3-319-73450-7_36
   Xiaoyi Jiang, 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P629, DOI 10.1109/ICDAR.1999.791866
   YAN H, 1993, CVGIP-GRAPH MODEL IM, V55, P538, DOI 10.1006/cgip.1993.1041
   Yixi LM., 2017, MINZU MINSU WENHUA, V5, P77
   Zohrevand Abbas, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P70, DOI 10.1109/PRIA.2019.8786006
NR 21
TC 1
Z9 1
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15609
EP 15632
DI 10.1007/s11042-022-12338-9
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000762173600007
DA 2024-07-18
ER

PT J
AU Hu, AD
   Wu, LJ
   Huang, JK
   Fan, D
   Xu, ZY
AF Hu, Ande
   Wu, Lijian
   Huang, Jiankang
   Fan, Ding
   Xu, Zhenya
TI Recognition of weld defects from X-ray images based on improved
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Weld defect recognition; Convolution neural network; ELU function;
   Pooling
ID ALGORITHM
AB When convolutional neural network (CNN) is used for welding defect detection image recognition, the recognition result will be affected by many factors such as human factors, the activation function is sensitive to input parameters, and the edge features are weakened. In order to overcome the above problems, the methods include image processing, exponential linear unit (ELU) activation function and improved pooling model are used. According to the experiment, the image processing method can effectively segment the weld and defects, and the defect location in the weld image can be located. Using the ELU activation function in the CNN model can improve the robustness of the neural network to the input parameters and increase the sparsity of the network to increase the model's convergence speed. The improved pooling method based on grayscale adaptation can increase the extraction range of weld defect features and reduce the impact of noise, and has certain dynamic adaptability to the defect features. The result shows that the improved convolutional neural network(ICNN) method can effectively improve the accuracy of recognition in weld image recognition, and the overall recognition rate can reach 98.13%.
C1 [Hu, Ande; Fan, Ding] Lanzhou Univ Technol, State Key Lab Adv Proc & Recycling Nonferrous Met, Lanzhou 730050, Peoples R China.
   [Wu, Lijian; Huang, Jiankang] Lanzhou Univ Technol, Sch Mat Sci & Engn, Lanzhou 730050, Peoples R China.
   [Xu, Zhenya] Baoshan Iron & Steel Co Ltd, Shanghai 201900, Peoples R China.
C3 Lanzhou University of Technology; Lanzhou University of Technology;
   China Baowu Steel Group
RP Fan, D (corresponding author), Lanzhou Univ Technol, State Key Lab Adv Proc & Recycling Nonferrous Met, Lanzhou 730050, Peoples R China.; Huang, JK (corresponding author), Lanzhou Univ Technol, Sch Mat Sci & Engn, Lanzhou 730050, Peoples R China.
EM sr2810@163.com; fand@lut.cn
RI peng, yan/JCO-1763-2023; Wang, Luyao/JLL-2001-2023; Huang,
   Jiankang/P-3193-2014; Wang, Tianqi/JJD-7473-2023
OI Huang, Jiankang/0000-0002-1257-8622; 
FU National Natural Science Foundation of China [01020607]
FX This work is funded by the National Natural Science Foundation of China
   (No. 01020607).
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Bharodiya AK, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02743
   Ding, 2020, T CHINA WELD I, V41, P7
   Federer C, 2020, NEURAL NETWORKS, V131, P103, DOI 10.1016/j.neunet.2020.07.013
   Gao L., 2007, J TRANSPORT INFORM S, V25, P73
   Gorban AN, 2020, COGN COMPUT, V12, P388, DOI 10.1007/s12559-019-09667-7
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li T, 2016, IMAGE VISION COMPUT, V55, P64, DOI 10.1016/j.imavis.2016.04.002
   Li YS, 2017, PATTERN RECOGN, V63, P371, DOI 10.1016/j.patcog.2016.10.019
   Lin JY, 2007, PATTERN RECOGN, V40, P2211, DOI 10.1016/j.patcog.2007.01.003
   McIlhagga W, 2011, INT J COMPUT VISION, V91, P251, DOI 10.1007/s11263-010-0392-0
   Mery D, 2015, J NONDESTRUCT EVAL, V34, DOI 10.1007/s10921-015-0315-7
   O'Shea T, 2017, IEEE T COGN COMMUN, V3, P563, DOI 10.1109/TCCN.2017.2758370
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sakamoto M, 2020, J SIGNAL PROCESS SYS, V92, P335, DOI 10.1007/s11265-019-01507-z
   Shao WJ, 2019, INT J ADV MANUF TECH, V104, P2971, DOI 10.1007/s00170-019-04029-x
   [孙怡 Sun Yi], 2004, [焊接学报, Transactions of the China Welding Institution], V25, P115
   Wang F., 2017, WELDING TECHNOLOGY, V46, P127
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Yang LQ, 2020, IEEE ACCESS, V8, P30271, DOI 10.1109/ACCESS.2020.2972464
   Yang ML, 2019, NEUROCOMPUTING, V330, P48, DOI 10.1016/j.neucom.2018.10.075
   Yang Z., 2018, J SIGNAL PROCESS, V34, P84
   [余永维 Yu Yongwei], 2016, [农业机械学报, Transactions of the Chinese Society for Agricultural Machinery], V47, P407
   Zhang ZH, 2019, PATTERN RECOGN, V88, P38, DOI 10.1016/j.patcog.2018.11.002
   Zhang ZC, 2020, NEUROCOMPUTING, V410, P185, DOI 10.1016/j.neucom.2020.05.075
   Zhang ZC, 2019, ENG APPL ARTIF INTEL, V85, P254, DOI 10.1016/j.engappai.2019.06.017
   [周飞燕 Zhou Feiyan], 2017, [计算机学报, Chinese Journal of Computers], V40, P1229
NR 30
TC 9
Z9 10
U1 9
U2 53
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2022
VL 81
IS 11
BP 15085
EP 15102
DI 10.1007/s11042-022-12546-3
EA FEB 2022
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0X7NC
UT WOS:000769532200001
DA 2024-07-18
ER

PT J
AU Paul, A
   Wu, ZF
   Liu, K
   Gong, SF
AF Paul, Agyemang
   Wu, Zhefu
   Liu, Kai
   Gong, Shufeng
TI Personalized recommendation: From clothing to academic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Personalized recommendation; Category hierarchy; Temporal dynamics;
   Adversarial training; Academic services
AB Information retrieval is useful in all aspects of life, ranging from clothing shopping to education and academic pursuits. Many systems optimize models with pairwise ranking techniques such as Bayesian Personalized Ranking (BPR) for personalized information retrieval. A Bayesian personalized ranking system can assist specific shoppers, students, and researchers based on their interaction, which has illustrated an enormous capability for improvement by generating intelligent recommendations, such as clothing, books, and other related information. However, for such users, finding the desired clothing and books online is complex and is influenced by various factors (e.g., visual appearance and time). As such, traditional personalized recommendation methods that model only user-product interaction data would deliver unsatisfactory recommendation results. In this paper, we propose combining visual, temporal, and sequential information for personalized recommendations. Technically speaking, our main contributions include: (1) We incorporate the image features of clothing and books into personalized ranking to model users' preferences. (2) We design a new time model for personalized recommender systems. The visual features are then injected into the time model to capture the temporal dynamics of visual preferences. (3) To this end, we present a Time Hierarchical Embedding (T-Sherlock) approach, which can incorporate sequential and temporal information simultaneously to model users' preferences for different categories of products. To reduce the impact of adversarial noise, we train a T-Sherlock objective function using minimax adversarial training (AT-Sherlock). Experiments on real-world datasets demonstrated the efficacy of our methods in comparison to baselines.
C1 [Paul, Agyemang; Wu, Zhefu; Liu, Kai; Gong, Shufeng] Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Peoples R China.
C3 Zhejiang University of Technology
RP Wu, ZF (corresponding author), Zhejiang Univ Technol, Coll Informat Engn, Hangzhou 310023, Peoples R China.
EM wzf@zjut.edu.cn
RI Liu, Kaixin/HNQ-4200-2023
OI Liu, Kaixin/0000-0001-5573-1781
CR Deldjoo Y, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P869, DOI 10.1145/3336191.3371877
   Deldjoo Y, 2016, J DATA SEMANT, V5, P99, DOI 10.1007/s13740-016-0060-9
   Donaldson J, 2007, RECSYS 07: PROCEEDINGS OF THE 2007 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P187
   Geng X, 2015, IEEE I CONF COMP VIS, P4274, DOI 10.1109/ICCV.2015.486
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   He R., 2016, P 25 INT JOINT C ART, P3740
   He RN, 2016, AAAI CONF ARTIF INTE, P144
   He XN, 2018, ACM/SIGIR PROCEEDINGS 2018, P355, DOI 10.1145/3209978.3209981
   He XN, 2018, IEEE T KNOWL DATA EN, V30, P2354, DOI 10.1109/TKDE.2018.2831682
   Hu YF, 2008, IEEE DATA MINING, P263, DOI 10.1109/ICDM.2008.22
   Jian M, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P344, DOI 10.1145/3323873.3325054
   Kang WC, 2017, IEEE DATA MINING, P207, DOI 10.1109/ICDM.2017.30
   Koren Y, 2011, RECOMMENDER SYSTEMS HANDBOOK, P145, DOI 10.1007/978-0-387-85820-3_5
   Kurakin Alexey, 2017, INT C LEARN REPR
   Liu Q, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P841, DOI 10.1145/3077136.3080658
   McAuley J, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2783258.2783381
   Miyato T., 2016, Adversarial Training Methods for Semi-Supervised Text Classification
   Rendle S., 2009, P 25 C UNC ART INT, P452, DOI DOI 10.5555/1795114.1795167
   Tang JH, 2020, IEEE T KNOWL DATA EN, V32, P855, DOI 10.1109/TKDE.2019.2893638
   Tie-Yan Liu, 2009, Foundations and Trends in Information Retrieval, V3, P225, DOI 10.1561/1500000016
   Wang SH, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P391, DOI 10.1145/3038912.3052638
   Wu L, 2020, IEEE T KNOWL DATA EN, V32, P1854, DOI 10.1109/TKDE.2019.2913394
   Wu Z, 2017, INT WORKSH COMPL SYS
   Yin RP, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P3434, DOI 10.1145/3308558.3313739
   [俞东进 Yu Dongjin], 2018, [电子学报, Acta Electronica Sinica], V46, P2626
   Yu WH, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P649, DOI 10.1145/3178876.3186146
NR 26
TC 4
Z9 5
U1 2
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14573
EP 14588
DI 10.1007/s11042-022-12259-7
EA FEB 2022
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300007
DA 2024-07-18
ER

PT J
AU Sinhal, R
   Sharma, S
   Ansari, IA
   Bajaj, V
AF Sinhal, Rishi
   Sharma, Sachin
   Ansari, Irshad Ahmad
   Bajaj, Varun
TI Multipurpose medical image watermarking for effective security solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image watermarking; Ownership verification; Tamper localization;
   ROI recovery; Reversibility; Blind watermarking
ID TRANSFORM; SCHEME; ROBUST; MANAGEMENT
AB Digital medical images contain important information regarding patient's health and very useful for diagnosis. Even a small change in medical images (especially in the region of interest (ROI)) can mislead the doctors/practitioners for deciding further treatment. Therefore, the protection of the images against intentional/unintentional tampering, forgery, filtering, compression and other common signal processing attacks are mandatory. This manuscript presents a multipurpose medical image watermarking scheme to offer copyright/ownership protection, tamper detection/localization (for ROI (region of interest) and different segments of RONI (region of non-interest)), and self-recovery of the ROI with 100% reversibility. Initially, the recovery information of the host image's ROI is compressed using LZW (Lempel-Ziv-Welch) algorithm. Afterwards, the robust watermark is embedded into the host image using a transform domain based embedding mechanism. Further, the 256-bit hash keys are generated using SHA-256 algorithm for the ROI and eight RONI regions (i.e. RONI-1 to RONI-8) of the robust watermarked image. The compressed recovery data and hash keys are combined and then embedded into the segmented RONI region of the robust watermarked image using an LSB replacement based fragile watermarking approach. Experimental results show high imperceptibility, high robustness, perfect tamper detection, significant tamper localization, and perfect recovery of the ROI (100% reversibility). The scheme doesn't need original host or watermark information for the extraction process due to the blind nature. The relative analysis demonstrates the superiority of the proposed scheme over existing schemes.
C1 [Sinhal, Rishi; Ansari, Irshad Ahmad; Bajaj, Varun] PDPM Indian Inst Informat Technol Design & Mfg, Elect & Commun Engn, Jabalpur 482005, MP, India.
   [Sharma, Sachin] Jagadish Chandra Bose Res Org, Res Div, Gautam Budh Nagar 203207, Uttar Pradesh, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur
RP Ansari, IA (corresponding author), PDPM Indian Inst Informat Technol Design & Mfg, Elect & Commun Engn, Jabalpur 482005, MP, India.
EM rishi.sinhal.jec@gmail.com; sheorajsachin@gmail.com;
   irshad@iiitdmj.ac.in; varunb@iiitdmj.ac.in
RI Ansari, Irshad Ahmad/AAT-2761-2020; Sinhal, Rishi/IYT-1836-2023
OI Ansari, Irshad Ahmad/0000-0003-2991-0908
FU Jagadish Chandra Bose Research Organisation (JCBRO)
FX This research work was supported by Jagadish Chandra Bose Research
   Organisation (JCBRO).
CR Alshanbari HS, 2021, MULTIMED TOOLS APPL, V80, P16549, DOI 10.1007/s11042-020-08814-9
   Avudaiappan T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1053-z
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Casado-Vara R, 2019, J INTELL FUZZY SYST, V36, P2381, DOI 10.3233/JIFS-169949
   Chao HM, 2002, IEEE T INF TECHNOL B, V6, P46, DOI 10.1109/4233.992161
   Cheung WN, 2000, TENCON IEEE REGION, pB374
   Coatrieux G, 2000, ENG MED BIOL SOC ANN, P250, DOI 10.1109/ITAB.2000.892396
   Das S, 2013, COMPUT METH PROG BIO, V111, P662, DOI 10.1016/j.cmpb.2013.05.027
   Eswaraiah R, 2014, INT J TELEMED APPL, V2014, DOI 10.1155/2014/984646
   Giakoumaki A, 2006, MED BIOL ENG COMPUT, V44, P619, DOI 10.1007/s11517-006-0081-x
   Gong LH, 2021, MULTIMED TOOLS APPL, V80, P439, DOI 10.1007/s11042-020-09677-w
   Guo XT, 2009, J DIGIT IMAGING, V22, P53, DOI 10.1007/s10278-007-9043-6
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Islam M, 2018, MULTIMED TOOLS APPL, V77, P14407, DOI 10.1007/s11042-017-5035-9
   Jeong C, 2014, INT SOC DESIGN CONF, P224, DOI 10.1109/ISOCC.2014.7087617
   Kammeraat M., 2020, 2020 IEEE INT C DES, P1, DOI DOI 10.1109/DTS48731.2020.9196134
   Lai CC, 2010, IEEE T INSTRUM MEAS, V59, P3060, DOI 10.1109/TIM.2010.2066770
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2018, MULTIMED TOOLS APPL, V77, P10033, DOI 10.1007/s11042-017-4946-9
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Luo AW, 2020, MULTIMED TOOLS APPL, V79, P243, DOI 10.1007/s11042-019-08074-2
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Mousavi SM, 2014, J DIGIT IMAGING, V27, P714, DOI 10.1007/s10278-014-9700-5
   Navas K., 2007, P INTERNATION C SCI, P25
   Panchal UH, 2015, INT CONF COMM SYST, P591, DOI 10.1109/CSNT.2015.165
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P10599, DOI 10.1007/s11042-015-3127-y
   Rachmawati D, 2018, J PHYS CONF SER, V978, DOI 10.1088/1742-6596/978/1/012116
   Ray PP, 2019, J NETW COMPUT APPL, V140, P1, DOI 10.1016/j.jnca.2019.05.005
   Selesnick IW, 1999, IEEE T SIGNAL PROCES, V47, P1304, DOI 10.1109/78.757218
   Sinhal R, 2020, SOFT COMPUTING THEOR, V1053, DOI [10.1007/978-981-15-0751-9_89, DOI 10.1007/978-981-15-0751-9_89]
   Sinhal R, 2020, J REAL-TIME IMAGE PR, V17, P2077, DOI 10.1007/s11554-019-00937-z
   Swaraja K, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101665
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Thabit R, 2014, J SYST SOFTWARE, V88, P74, DOI 10.1016/j.jss.2013.09.033
   WELCH TA, 1984, COMPUTER, V17, P8, DOI 10.1109/MC.1984.1659158
   Zain J, 2005, SEC TELEMEDICINE ISS
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang XP, 2008, IEEE T MULTIMEDIA, V10, P1490, DOI 10.1109/TMM.2008.2007334
   Zhou NR, 2019, MULTIMED TOOLS APPL, V78, P2507, DOI 10.1007/s11042-018-6322-9
   Zhou NR, 2018, MULTIMED TOOLS APPL, V77, P30251, DOI 10.1007/s11042-018-6128-9
NR 41
TC 16
Z9 17
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 14045
EP 14063
DI 10.1007/s11042-022-12082-0
EA FEB 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000761979300005
PM 35233177
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Deepika, MM
   Raajan, NR
   Srinivasan, A
AF Deepika, M. Malini
   Raajan, N. R.
   Srinivasan, A.
TI Three dimensional reconstruction of brain tumor along with space
   occupying in lesions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gradient Vector Flow (GVF); Computed Tomography (CT); Magnetic Resonance
   Imaging (MS); 3D
ID SEGMENTATION; IMAGES
AB The three-dimensional models of brain tumors serve as diagnostic assistance for physicians, surgeons, and radiologists. The proposed system establishes an accurate 3D model of the skull vault and overcomes the limitations in the traditional tumors localization methods reported in previous studies. The three-dimensional Gradient Vector Flow (GVF) System recommended in this study uses Magnetic Resonance Images (MRI) and Computed Tomography (CT) as input. It detects the contour of the tumor and the skull region in different slices. Thus, the system constructs a 3D model of the tumor and the skull surface and excludes other tissues. The accuracy of the reconstructed 3D model depends on the accuracy of the tumor contour detection since GVFS plays a significant role in confirming the results obtained without any data loss. Various experiments are conducted to evaluate its accuracy in contour detection and compared the results with those traditional contour detection methods. The recorded results demonstrate that the GVFS method has the highest accuracy in contour detection. Though identifying the suspected region depends on the observer, the outcome is optimistic and unbiased in GVFS. The 2D model can easily be converted into 3D by triggering the elasticity which is already present in GVFS. Hence the proposed method employs direct reconstruction rather than using two different approaches to produce segmentation and reconstruction.
C1 [Deepika, M. Malini; Raajan, N. R.] SASTRA Deemed Univ, Dept Elect & Commun Engn, Thanjavur, India.
   [Srinivasan, A.] Thanjavur Med Coll & Hosp, Thanjavur, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Deepika, MM (corresponding author), SASTRA Deemed Univ, Dept Elect & Commun Engn, Thanjavur, India.
EM malinideepika@gmail.com
RI Renga Raajan, Narasimhan/IST-5582-2023; N R, Dr. RAAJAN/HDN-4829-2022
OI N R, Dr. RAAJAN/0000-0002-9537-1140; Manickavasagam, Malini
   Deepika/0000-0003-1873-3395
FU Thanjavur Medical College, Tamil Nadu; Council of Scientific and
   Industrial Research (CSIR), India [09/1095(0048)19-EMR-I]
FX This work would not have been possible without the guidance support by
   Dr. A. Srinivasan, Head, Department of Radiology and Radiological
   Sciences, Thanjavur Medical College, Tamil Nadu. I am especially
   indebted to Ethical committee members, Dr. S. Jeyakumar., Ms., MCh.,
   DNB., FRCS, Dean, TMC, and Other technical support faculty. The authors
   also wish to express their sincere thanks to the Research Associate
   Fellowship (No.09/1095(0048)19-EMR-I), Council of Scientific and
   Industrial Research (CSIR), India for their financial support.
CR Aloui K, 2009, WORLD ACAD SCI ENG T, V33, P127
   Amruta A., 2010, 2nd International Conference on Computer Technology and Development (ICCTD 2010), P305, DOI 10.1109/ICCTD.2010.5645867
   [Anonymous], 2006, SPIE
   Bashir H., 2015, SMART COMPUT REV, V5, P429
   Bharathi AS., 2015, ARPN J ENG APPL SCI, V10, P9227
   Cho KR, 2005, EUR J RADIOL, V54, P365, DOI 10.1016/j.ejrad.2004.07.006
   Corts, 2009, INT J COMPUT INF ENG, V3, P235
   Haider S., 2011, COMPUTER ENG INTELLI, V2, P96
   Jumaat AK, 2010, P 2 INT C COMP RES D, DOI [10.1109/iccrd.2010.109, DOI 10.1109/ICCRD.2010.109]
   Karkavelas G, 2002, IMAGING OF BRAIN TUMORS WITH HISTOLOGICAL CORRELATIONS, P1
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Khotanlou H, 2009, FUZZY SET SYST, V160, P1457, DOI 10.1016/j.fss.2008.11.016
   Kistler M, 2013, J MED INTERNET RES, V15, DOI 10.2196/jmir.2930
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mojsilovic A, 2002, ANAL QUANT CYTOL, V24, P125
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Popuri K, 2012, INT J COMPUT ASS RAD, V7, P493, DOI 10.1007/s11548-011-0649-2
   Scholl I, 2011, COMPUT SCI-RES DEV, V26, P5, DOI 10.1007/s00450-010-0146-9
   Siddiqi A. A., 2012, 2012 4th International Conference on Computational Intelligence, Communication Systems and Networks (CICSyN 2012), P257, DOI 10.1109/CICSyN.2012.55
   Siddiqi A. A., 2011, 2011 IEEE International Conference on Signal and Image Processing Applications (ICSIPA 2011), P72, DOI 10.1109/ICSIPA.2011.6144062
   Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350
   Suri J, 2005, TECHNOL CANCER RES T, V4, P83, DOI 10.1177/153303460500400111
   Tabrizi JH., 2003, USING ACTIVE CONTOUR
   Xu C., 2000, HDB MEDICAL IMAGING, V2, P129, DOI [10.1117/3.831079.ch3, DOI 10.1117/3.831079.CH3]
   Xu CY, 2009, HANDBOOK OF MEDICAL IMAGE PROCESSING AND ANALYSIS, 2ND EDITION, P181, DOI 10.1016/B978-012373904-9.50018-0
   Xu CY, 1997, PROC CVPR IEEE, P66, DOI 10.1109/CVPR.1997.609299
   Yang X, 2009, 3D INTERPOLATION IMA, P1
   Zhou W., 2013, COMPUT MATH METHODS, V2013
NR 29
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 12701
EP 12724
DI 10.1007/s11042-022-12352-x
EA FEB 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000758973600004
DA 2024-07-18
ER

PT J
AU Maratha, P
   Gupta, K
AF Maratha, Priti
   Gupta, Kapil
TI Linear optimization and fuzzy-based clustering for WSNs assisted
   internet of things
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sensor networks; Network lifetime; Fuzzy logic; Residual energy; Node
   centrality; Linear programming problem
ID WIRELESS SENSOR NETWORKS; ROUTING ALGORITHM; ENERGY EFFICIENCY; LOGIC
AB Wireless data transmission on the Internet of Things (IoT) needs data-aware communication protocols. Clustering is one of the effective network management approaches that enhance the lifetime of IoT. The primary challenge in the data transmission across IoT is designing an energy-efficient clustering mechanism. Existing protocols struggle with the non-optimal selection of CHs and frequent re-clustering on IoT, which leads to significant energy consumption. If the cluster head (CH) lifetime of the devices (nodes) is known prior, then re-clustering can be avoided to a reasonable extent. Therefore, in this paper, we estimate the lifetime of devices as CHs by solving a linear optimization problem to extend the first node death as much as possible and also, stalls the frequent re-clustering process to minimize the energy consumption. We also apply the uniform distribution of CHs to ensure balanced energy consumption on IoT devices. The proposed clustering technique named ECFEL (Efficient Clustering using Fuzzy logic based on Estimated Lifetime) for IoT outperforms the existing protocols, namely Low Energy Adaptive Clustering Hierarchy (LEACH), MODified LEACH (MOD-LEACH), Dynamic k-LEACH (DkLEACH), Novel-PSO-LEACH, FM-SCHEL, and M-IWOCA techniques in terms of first node death (FND), half node death (HND), last node death (LND). Our simulation results showcase that ECFEL is having a better lifetime in terms of FND, HND, and LND, respectively. Furthermore, the experiments also confirm that ECFEL consumes less energy while maintaining a packet delivery ratio for a more extended period.
C1 [Maratha, Priti; Gupta, Kapil] Natl Inst Technol Kurukshetra, Dept Comp Applicat, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Maratha, P (corresponding author), Natl Inst Technol Kurukshetra, Dept Comp Applicat, Kurukshetra, Haryana, India.
EM niki.maratha19@gmail.com
RI Maratha, Priti/GPX-5316-2022; Aggarwal, Kapil/ACA-2420-2022
OI Aggarwal, Kapil/0000-0001-7658-5058
FU University Grant Commission, New Delhi [ID-3361/(NET-JUNE 2015)]
FX We thank Ashish Kumar Luhach from The PNG University of Technology,
   Papua New Guinea and Arnab Chakroborty from the Indian Statistical
   Institute, Kolkata for their constructive ideas and insightful
   discussion on improving the outlook of the paper. Priti Maratha, as part
   of the National Eligibility Test-Junior Research Fellowship scheme with
   Reference ID-3361/(NET-JUNE 2015), acknowledges the assistance from
   University Grant Commission, New Delhi.
CR Ahmad A, 2017, ANN TELECOMMUN, V72, P173, DOI 10.1007/s12243-017-0560-0
   Ali A, 2020, IEEE WIREL COMMUNN, DOI 10.1109/wcncw48565.2020.9124879
   Asghari P, 2019, COMPUT NETW, V148, P241, DOI 10.1016/j.comnet.2018.12.008
   Bagci H, 2010, IEEE INT CONF FUZZY
   Dhumane AV, 2019, WIREL NETW, V25, P399, DOI 10.1007/s11276-017-1566-2
   Din S, 2017, IEEE ACCESS, V5, P5069, DOI 10.1109/ACCESS.2017.2679207
   Ding XX, 2017, WIRELESS PERS COMMUN, V96, P6369, DOI 10.1007/s11277-017-4482-y
   Falcon R, 2007, LECT NOTES ARTIF INT, V4827, P483
   Farahani M, 2019, WIRELESS PERS COMMUN, V106, P1183, DOI 10.1007/s11277-019-06209-0
   Haseeb K, 2020, ENVIRON TECHNOL INNO, V20, DOI 10.1016/j.eti.2020.101129
   Heiniger R. W., 2000, Proceedings of the 5th International Conference on Precision Agriculture, Bloomington, Minnesota, USA, 16-19 July, 2000, P1
   Huang JH, 2018, COMPUT NETW, V147, P38, DOI 10.1016/j.comnet.2018.09.024
   Lee JS, 2012, IEEE SENS J, V12, P2891, DOI 10.1109/JSEN.2012.2204737
   Li J, 2018, SUSTAIN CITIES SOC, V40, P657, DOI 10.1016/j.scs.2018.02.017
   Lin DY, 2020, ACM T SENSOR NETWORK, V17, DOI 10.1145/3414315
   Lin J, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010079
   Liu XC, 2019, ACM T SENSOR NETWORK, V15, DOI 10.1145/3322497
   Logambigai R, 2016, WIREL NETW, V22, P945, DOI 10.1007/s11276-015-1013-1
   Lu JY, 2012, INT CONF COMP SCI ED, P662, DOI 10.1109/ICCSE.2012.6295161
   Maheswari DU, 2019, WIRELESS PERS COMMUN, V104, P1209, DOI 10.1007/s11277-018-6076-8
   Mahmood D, 2013, 2013 EIGHTH INTERNATIONAL CONFERENCE ON BROADBAND, WIRELESS COMPUTING, COMMUNICATION AND APPLICATIONS (BWCCA 2013), P158, DOI 10.1109/BWCCA.2013.34
   Majadi N., 2013, INT J RECENT TRENDS, V8, P84
   Maratha P, 2019, STUD COMPUT INTELL, V771, P373, DOI 10.1007/978-981-10-8797-4_39
   Mirzaie M, 2017, COMPUT COMMUN, V111, P56, DOI 10.1016/j.comcom.2017.07.005
   Moorthi, 2020, COMPUT COMMUN, V149, P90, DOI 10.1016/j.comcom.2019.10.006
   Orlin J, 2013, LP TRANSFORMATION TE
   Pourghebleh B, 2020, CLUSTER COMPUT, V23, P641, DOI 10.1007/s10586-019-02950-0
   Preeth S.S.L., 2018, J. Ambient Intell. Human. Comput., P1, DOI [10.1007/s12652-018-1154-z, DOI 10.1007/S12652-018-1154-Z]
   Qureshi KN, 2020, SUSTAIN CITIES SOC, V62, DOI 10.1016/j.scs.2020.102392
   Rostami AS, 2018, J SUPERCOMPUT, V74, P277, DOI 10.1007/s11227-017-2128-1
   Sert SA, 2015, APPL SOFT COMPUT, V30, P151, DOI 10.1016/j.asoc.2014.11.063
   Shahraki A, 2020, COMPUT NETW, V180, DOI 10.1016/j.comnet.2020.107376
   Sharma R., 2019, J KING SAUD UNIV-COM
   Singh AK, 2013, INT J ELECTRON, V100, P126, DOI 10.1080/00207217.2012.687191
   Souri A, 2022, T EMERG TELECOMMUN T, V33, DOI 10.1002/ett.3736
   Sreenivasamurthy S, 2018, I S MOD ANAL SIM COM, P319, DOI 10.1109/MASCOTS.2018.00038
   Sung Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18040961
   Ullah MF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19040829
   Wazid M, 2019, J SYST ARCHITECT, V97, P185, DOI 10.1016/j.sysarc.2018.12.005
   Xu LN, 2017, IEEE INTERNET THINGS, V4, P1229, DOI 10.1109/JIOT.2017.2726014
   Xu X, 2015, ACM T SENSOR NETWORK, V11, DOI 10.1145/2700264
   Xu Y, 2019, IEEE ACCESS, V7, P145667, DOI 10.1109/ACCESS.2019.2944669
NR 42
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2023
VL 82
IS 4
BP 5161
EP 5185
DI 10.1007/s11042-021-11850-8
EA FEB 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 8K2ER
UT WOS:000758308400003
DA 2024-07-18
ER

PT J
AU Goel, L
AF Goel, Lavika
TI A novel approach for face recognition using biogeography based
   optimization with extinction and evolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biogeography based optimization; Principal component analysis; Support
   vector machine; Evolutionary algorithm; Eigenspace; Feature space
ID FEATURE-SELECTION; KRILL HERD
AB Evolutionary algorithms are one of the most emerging fields in pattern recognition and many computationally complex problems can be solved using evolutionary algorithms as heuristics. Face recognition is one of the most studied research topics all due to its very vast application in almost every field of the present hour but there is no such algorithm present which almost give 100% accuracy on different datasets. A variant of Biogeography Based Optimization (BBO) which includes the features of evolution, extinction and changes in the methodology of migration (immigration and emigration) have been applied to solve the problem of face recognition. Evolutionary algorithms iteratively try to improve the candidate solutions for a given fitness function and BBO is one such algorithm. This inclusion of extra features improves the performance of BBO significantly. The most important task in face recognition is feature extraction which helps to differentiate between the faces. A combination of PCA (Principal Component Analysis) for feature extraction and SVM (Support Vector Machine) for classification. The proposed variant of BBO is applied with the vectors as the candidate solution and an optimal set of eigenfaces are obtained which are then used to project the points to a new feature space where the interclass distance is minimal at the same time intraclass distance is maximal. The test images are then classified in this feature space. On testing our algorithm for 5 face different datasets namely Extended Yale B, MUCT, Faces96, Georgia Tech and Grimace the accuracy obtained with such a large variety of datasets clearly shows the effectiveness of our proposed algorithm. Even though the datasets are varied in terms of size, length of images, brightness, ethnicity of subjects, expressions, focus on the facial parts the algorithm achieve 100% accuracy on Grimace and Extended Yale B and a near to 100% accuracy of 99% on MUCT and 99.50% on faces96. On Georgia Tech dataset, an accuracy of 97.34% has been achieved which is enough to prove a significant improvement from the previous used algorithms of face detection.
C1 [Goel, Lavika] Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
C3 National Institute of Technology (NIT System); Malaviya National
   Institute of Technology Jaipur
RP Goel, L (corresponding author), Malaviya Natl Inst Technol, Dept Comp Sci & Engn, Jaipur 302017, Rajasthan, India.
EM lavika.cse@mnit.ac.in
CR AbdELminaam DS, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0242269
   Al-Waisy AS, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P548, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.78
   Auria L, 2008, DIW BERLIN DISCUSSIO, V13, P18, DOI [10.1109/5254.708428, DOI 10.1109/5254.708428]
   Banzhaf W., 2000, IEEE INTELL SYST APP, V30, P1, DOI [10.1145/2070781.2024186, DOI 10.1145/2070781.2024186]
   Barnouti NH, 2016, INT J ADV COMPUT SC, V7, P371
   Chakraborti T, 2014, ENG APPL ARTIF INTEL, V33, P80, DOI 10.1016/j.engappai.2014.04.006
   Chen K., 2021, FAST RELIABLE PROBAB
   Chu WS, 2011, PATTERN RECOGN, V44, P1567, DOI 10.1016/j.patcog.2011.02.011
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Du L, 2007, ICNC 2007: THIRD INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 3, PROCEEDINGS, P287
   Faruqe MO, 2009, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON ANTI-COUNTERFEITING, SECURITY, AND IDENTIFICATION IN COMMUNICATION, P97, DOI 10.1109/ICASID.2009.5276938
   Gandomi AH, 2012, COMMUN NONLINEAR SCI, V17, P4831, DOI 10.1016/j.cnsns.2012.05.010
   Gupta D., 2013, 2 INT C ADV COMP SCI, DOI [10.1007/978-3-319-47952-1_16, DOI 10.1007/978-3-319-47952-1_16]
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   Hui KH, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/5582132
   Kanan HR, 2008, APPL MATH COMPUT, V205, P716, DOI 10.1016/j.amc.2008.05.115
   Khan AA, 2021, IEEE T CLOUD COMPUT, V9, P1305, DOI 10.1109/TCC.2019.2920914
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Malkauthekar M. D., 2013, P 3 INT C COMP INT I, P503
   Nefian AV., 2002, IEEE INT C MULT EXP, P12, DOI [10.1109/ICME.2002.1035530, DOI 10.1109/ICME.2002.1035530]
   Price KV., 1997, DIFFERENTIAL EVOLUTI, P2425, DOI [10.3934/mbe.2021123, DOI 10.3934/MBE.2021123]
   Silva EM, 2018, PRAI 2018: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND ARTIFICIAL INTELLIGENCE, P11, DOI 10.1145/3243250.3243262
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Wang GG, 2014, APPL MATH MODEL, V38, P2454, DOI 10.1016/j.apm.2013.10.052
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Yuan ZG, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/8861987
   Zhao XY, 2013, PATTERN RECOGN, V46, P2647, DOI 10.1016/j.patcog.2013.03.015
NR 30
TC 2
Z9 2
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10561
EP 10588
DI 10.1007/s11042-022-12158-x
EA FEB 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700017
DA 2024-07-18
ER

PT J
AU Rani, M
   Kaushal, S
AF Rani, Monika
   Kaushal, Sakshi
TI A novel framework for multiclass supervised classification of
   location-sensitive events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Location-sensitive events classification; Context-based vector space
   models; Geographic scope resolution; Multiclass classification
ID NAMED ENTITIES; TEXT; MODEL; NEWS
AB In the past couple of years, location-sensitive information retrieval has gained significant attention in terms of extracting and utilizing location information present in the unstructured text. It requires analysis of documents both geographically and thematically that makes it a challenging task. The semantics of text needs to be associated with location features present in the text. Such information association is beneficial in conducting fine-grained analysis of events reported in the text, e.g., Tourist location recommendation, Disaster surveillance, Political activeness and Happiness index, etc. Recently, context-based vector space models have attained much importance in text mining as they intelligently preserve semantics of the text while representing text in vector space of desired dimension. In this paper, a framework for multiclass supervised classification of location-sensitive events, namely, LDoc2Vec is proposed that integrates context-based vector space models with geographic scope resolution of events reported in the text documents. Variants of the Doc2Vec model have been integrated with location features and their performance for multiclass supervised event classification is analysed. Experimental results with various machine learning classifiers indicate that the proposed framework outperforms baseline Doc2Vec models for multiclass classification of location-sensitive events as expressed by renowned performance measurement metrics viz. precision, recall and F1-score.
C1 [Rani, Monika; Kaushal, Sakshi] Panjab Univ, Univ Inst Engn & Technol, Chandigarh 160014, India.
C3 Panjab University
RP Rani, M (corresponding author), Panjab Univ, Univ Inst Engn & Technol, Chandigarh 160014, India.
EM monikaubs@pu.ac.in; sakshi@pu.ac.in
CR Al-Rfou R, 2015, ARXIV14103791
   Ali D, 2021, SCI PROGRAMMING-NETH, V2021, DOI 10.1155/2021/6660651
   Amitay E., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P273, DOI 10.1145/1008992.1009040
   Anastácio I, 2009, LECT NOTES ARTIF INT, V5816, P598, DOI 10.1007/978-3-642-04686-5_49
   Andogah G, 2012, DATA KNOWL ENG, V81-82, P1, DOI 10.1016/j.datak.2012.07.002
   [Anonymous], 2014, Int. J. Datab. Theory Appl, DOI [DOI 10.14257/IJDTA.2014.7.1.06, DOI 10.14257/IJDTA.2014.7.1.0]
   Bendimerad A, 2021, IEEE T KNOWL DATA EN, V33, P796, DOI 10.1109/TKDE.2019.2931340
   Bilgin M, 2019, INT ARAB J INF TECHN, V16, P953
   Cao TH, 2012, INTEL SYST REF LIBR, V23, P267
   Census of India, 2020, LIST TOWNS
   Cha M, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P2003, DOI 10.1145/3132847.3133104
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Choi D, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11020577
   Cybulska A, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P3355
   Erkan G, 2008, IMPROVED NEAREST NEI
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Fragos K, 2014, PROCD SOC BEHV, V147, P307, DOI 10.1016/j.sbspro.2014.07.098
   Frank E, 2006, LECT NOTES ARTIF INT, V4213, P503
   Friburger N., 2002, Proceedings of the workshopMathematical/FormalMethods in Information Retrieval (MFIR2002) at the 25 th ACM SIGIR Conference, P155
   Hui JLO, 2017, PROCEDIA COMPUT SCI, V124, P77, DOI 10.1016/j.procs.2017.12.132
   Jin PQ, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P69, DOI 10.1145/3041021.3054151
   Kang DK, 2005, LECT NOTES ARTIF INT, V3607, P134
   Kumaran G., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P297, DOI 10.1145/1008992.1009044
   Lazaridou K, 2018, WEBSCI'18: PROCEEDINGS OF THE 10TH ACM CONFERENCE ON WEB SCIENCE, P229, DOI 10.1145/3201064.3201068
   Li HJ, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P331, DOI 10.1145/1571941.1571999
   Li QZ, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4668
   Lieberman M.D., 2007, P 15 ACM INT S ADV G, P1
   Liu B, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P425
   Lu Yonghe, 2019, Am. J. Inf. Sci. Technol., V3, P62
   Manning Christopher, 2009, INTRO INFORM RETRIEV, P253
   Martins B, 2005, Fifth IEEE International Conference on Data Mining, Proceedings, P741, DOI 10.1109/ICDM.2005.6
   Medvet E, 2012, 2012 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY (WI-IAT 2012), VOL 1, P297, DOI 10.1109/WI-IAT.2012.36
   Montalvo S, 2007, LECT NOTES ARTIF INT, V4629, P107
   Noble J, 2020, P SAS GLOB FOR 2020
   Odon De Alencar R, 2010, P 6 WORKSH GEOGR INF, P1, DOI [10.1145/1722080.1722096, DOI 10.1145/1722080.1722096]
   Le Q, 2014, PR MACH LEARN RES, V32, P1188
   Sheela J., 2016, INT J SIGNAL PROCESS, V4, P382, DOI [10.18178/ijsps.4.5.382-388, DOI 10.18178/IJSPS.4.5.382-388]
   Silva MJ, 2006, COMPUT ENVIRON URBAN, V30, P378, DOI 10.1016/j.compenvurbsys.2005.08.003
   Smith D. A., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P191, DOI 10.1145/544220.544260
   Stankeviius L., 2019, INT C INF TECHN, V2470, P104
   Uteuov A, 2018, PROCEDIA COMPUT SCI, V136, P293, DOI 10.1016/j.procs.2018.08.285
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   Valentin S, 2018, PROCEDIA COMPUT SCI, V126, P490, DOI 10.1016/j.procs.2018.07.283
   WOODRUFF AG, 1994, J AM SOC INFORM SCI, V45, P645, DOI 10.1002/(SICI)1097-4571(199410)45:9<645::AID-ASI2>3.0.CO;2-8
   Wrobel K, 2018, ICAART 2018, V2, P531, DOI [10.5220/0006641505310538, DOI 10.5220/0006641505310538]
   Wu QY, 2014, KNOWL-BASED SYST, V67, P105, DOI 10.1016/j.knosys.2014.06.004
   Zhang T, 2001, INFORM RETRIEVAL, V4, P5, DOI 10.1023/A:1011441423217
NR 47
TC 0
Z9 0
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 7
BP 9667
EP 9692
DI 10.1007/s11042-021-11842-8
EA FEB 2022
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9N7RG
UT WOS:000756332700021
DA 2024-07-18
ER

PT J
AU Wang, HC
   Chen, CC
   Li, TW
AF Wang, Hei-Chia
   Chen, Chun-Chieh
   Li, Ting-Wei
TI Automatic content curation of news events
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content curation; Automatic news summary; Event story; Topic detection;
   Document summarization; News event
ID TEXT
AB With the rapid development of the internet, a large amount of online news has brought readers a variety of information. Some important events last for some time as the event develops or the topic spreads. When readers want to catch up on the details of a specific news event, most of them use a search engine to collect news and understand the whole story. It usually takes readers a considerable amount of time to sort out the causes and effects of the event. The general method of online news provision aggregates and organizes the content of news articles from a large number of events and presents the content to readers. Most of this type of information is manually organized. To solve these problems, this study proposes an automated method of news curation. First, we extract the topics from the event data set and use word sequences to find the sequence of topic transfer through a hidden Markov model. Second, we calculate the strength of the topic and the variation in the strength to detect important time points during the development of the news event. Finally, a concise summary is generated at each time point. This paper combines two characteristics, chronology and summary, to design a curation method that can effectively help readers quickly grasp the context of a news event. The experimental results show that the method has good performance in each module, such as the detection of the important phases of events and the creation of the news summary.
C1 [Wang, Hei-Chia; Chen, Chun-Chieh; Li, Ting-Wei] Natl Cheng Kung Univ, Inst Informat Management, Tainan, Taiwan.
   [Wang, Hei-Chia] Natl Cheng Kung Univ, Ctr Innovat Fintech Business Models, Tainan, Taiwan.
   [Chen, Chun-Chieh] Natl Dev Council, Dept Informat Management, Taipei, Taiwan.
C3 National Cheng Kung University; National Cheng Kung University
RP Wang, HC (corresponding author), Natl Cheng Kung Univ, Inst Informat Management, Tainan, Taiwan.; Wang, HC (corresponding author), Natl Cheng Kung Univ, Ctr Innovat Fintech Business Models, Tainan, Taiwan.
EM hewang@mail.ncku.edu.tw; scout.chen@gmail.com;
   r76064124@mail.ncku.edu.tw
FU Ministry of Science and Technology, Taiwan
FX Ministry of Science and Technology, Taiwan.
CR Allan J., 1998, P DARPA BROADC NEWS
   [Anonymous], 2008, A Semantic Web Primer
   Burnette-Lemon J., 2012, COMMUN WORLD, V29, P24
   Chang HT, 2015, ASLIB J INFORM MANAG, V67, P687, DOI 10.1108/AJIM-10-2014-0147
   Dale S., 2014, BUS INFORM REV, V31, P199, DOI DOI 10.1177/0266382114564267
   Dhillon IS, 2001, MACH LEARN, V42, P143, DOI 10.1023/A:1007612920971
   Endres DM, 2003, IEEE T INFORM THEORY, V49, P1858, DOI 10.1109/TIT.2003.813506
   Erkan G, 2004, J ARTIF INTELL RES, V22, P457, DOI 10.1613/jair.1523
   Giomelakis D, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11120261
   Guidi B, 2021, IEEE T COMPUT SOC SY, V8, P365, DOI 10.1109/TCSS.2020.3042745
   Haribhakta Y, 2012, P CUBE INT INFORM TE, P314
   Herther Nancy K., 2012, Searcher, V20, P30
   Hopp FR, 2020, J COMMUN, V70, P335, DOI 10.1093/joc/jqaa015
   Hou SL, 2020, INFORM SYST, V94, DOI 10.1016/j.is.2020.101615
   Huang TC, 2018, DATA TECHNOL APPL, V52, P351, DOI 10.1108/DTA-09-2017-0062
   Huang YX, 2020, INT J MACH LEARN CYB, V11, P2039, DOI 10.1007/s13042-020-01093-8
   Kanke T, 2021, LIBR HI TECH, V39, P64, DOI 10.1108/LHT-04-2019-0087
   Li HR, 2019, IEEE T KNOWL DATA EN, V31, P996, DOI 10.1109/TKDE.2018.2848260
   Liu B, 2020, ACM T KNOWL DISCOV D, V14, DOI 10.1145/3377939
   Liu TP, 2020, MULTIMED TOOLS APPL, V79, P33431, DOI 10.1007/s11042-019-7567-7
   Loan F.A., 2011, International Journal of Digital Library Services, V1, P43
   Ma XH, 2020, J INTELL FUZZY SYST, V38, P55, DOI 10.3233/JIFS-179380
   Makhortykh M, 2021, NEW MEDIA SOC, V23, P2773, DOI 10.1177/1461444820933221
   Marujo L, 2016, KNOWL-BASED SYST, V94, P33, DOI 10.1016/j.knosys.2015.11.005
   Merrouni ZA, 2020, J INTELL INF SYST, V54, P391, DOI 10.1007/s10844-019-00558-9
   Nenkova A., 2012, MINING TEXT DATA, P43, DOI [10.1007/978-1-4614-3223-4_3, 10.1007/978- 1- 4614-3223- 4_3.]
   Newman N., 2017, Digital News Report
   Po Hu, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P260, DOI 10.1109/ICDM.2011.71
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sankarasubramaniam Y, 2014, INFORM PROCESS MANAG, V50, P443, DOI 10.1016/j.ipm.2014.02.001
   Wang CY, 2018, WORLD WIDE WEB, V21, P1069, DOI 10.1007/s11280-017-0501-x
   Xu J, 2015, IEEE SYS MAN CYBERN, P2730, DOI 10.1109/SMC.2015.477
   Zhai C., 2004, Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P743, DOI DOI 10.1145/1014052.1014150
   Zhao TT, 2018, CONCURR COMP-PRACT E, V30, DOI 10.1002/cpe.4642
NR 34
TC 2
Z9 2
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 8
BP 10445
EP 10467
DI 10.1007/s11042-022-12224-4
EA FEB 2022
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0C2VW
UT WOS:000756332700034
PM 35194386
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU You, W
   Wang, X
   Zhang, WH
   Qiang, ZF
AF You, Wei
   Wang, Xue
   Zhang, Weihang
   Qiang, Zhenfeng
TI Generic enhanced ensemble learning with multi-level kinematic
   constraints for 3D action recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Skeleton; Kinematic constraint; Ensemble learning
ID CONVOLUTION; FEATURES; MOTION
AB The 3D human body skeleton conveys rich information of human action and is regarded as an important data modality for action recognition. Due to the diversity of human action and the noise in skeleton data, skeleton-based action recognition methods face the challenges of overcoming the interference of irrelevant data and learning enough valid information of human action. Previous research has led us to a variety of effective skeleton features and many deep network models with strong learning abilities. However, a single model using a single feature cannot make full use of the valid information in the skeleton. To address this problem, this paper proposes the multi-level kinematic constraints to construct multiple skeleton features. By using different levels of constraints, a set of features containing information from local to global are extracted. The variability among these features leads to significant variability in classifiers trained on them, thus enhancing the ensemble performance of these classifiers. Extensive experiments on three representative datasets and four kinds of classification models demonstrate the generality of the proposed method. A substantial improvement can be achieved on multiple kinds of existing well-performing models and our method surpasses most state-of-the-art skeleton-based action recognition methods.
C1 [You, Wei; Wang, Xue; Zhang, Weihang; Qiang, Zhenfeng] Tsinghua Univ, Dept Precis Instrument, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Wang, X (corresponding author), Tsinghua Univ, Dept Precis Instrument, Beijing 100084, Peoples R China.
EM youw16@mails.tsinghua.edu.cn; wangxue@mail.tsinghua.edu.cn
OI You, Wei/0000-0001-9729-9763; Zhang, Weihang/0000-0002-6633-1801; Wang,
   Xue/0000-0003-4842-3160
FU Nation Key Research and Development Program of China [2018YFB2003500]
FX This work was supported by the Nation Key Research and Development
   Program of China under Grant 2018YFB2003500.
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Avola D, 2020, IEEE T MULTIMEDIA, V22, P2481, DOI 10.1109/TMM.2019.2960588
   Bian CL, 2021, IEEE T IMAGE PROCESS, V30, P2963, DOI 10.1109/TIP.2021.3056895
   Chen YF, 2020, MULTIMED TOOLS APPL, V79, P1707, DOI 10.1007/s11042-019-08261-1
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Ding WW, 2018, PATTERN RECOGN, V77, P75, DOI 10.1016/j.patcog.2017.12.004
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Fan ZX, 2019, IEEE T MULTIMEDIA, V21, P363, DOI 10.1109/TMM.2018.2859620
   Fernando B, 2017, IEEE T PATTERN ANAL, V39, P773, DOI 10.1109/TPAMI.2016.2558148
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hu GY, 2020, IEEE T MULTIMEDIA, V22, P2207, DOI 10.1109/TMM.2019.2953325
   Hu JF, 2017, IEEE T PATTERN ANAL, V39, P2186, DOI 10.1109/TPAMI.2016.2640292
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Keselman L, 2017, IEEE COMPUT SOC CONF, P1267, DOI 10.1109/CVPRW.2017.167
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li J, 2022, IEEE T ENG MANAGE, V69, P1902, DOI 10.1109/TEM.2019.2940702
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Li YS, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107293
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P1453, DOI 10.1109/TPAMI.2019.2898954
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Nie Q, 2019, IEEE T IMAGE PROCESS, V28, P3959, DOI 10.1109/TIP.2019.2907048
   Pakrashi A, 2019, INFORM SCIENCES, V485, P456, DOI 10.1016/j.ins.2019.02.017
   Peddinti V, 2018, IEEE SIGNAL PROC LET, V25, P373, DOI 10.1109/LSP.2017.2723507
   Shahri Alimohammad, 2016, 2016 IEEE Tenth International Conference on Research Challenges in Information Science (RCIS), P1, DOI 10.1109/RCIS.2016.7549312
   Shahroudy A, 2016, IEEE T PATTERN ANAL, V38, P2123, DOI 10.1109/TPAMI.2015.2505295
   Shi L, 2020, IEEE T IMAGE PROCESS, V29, P9532, DOI 10.1109/TIP.2020.3028207
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun B, 2019, MULTIMED TOOLS APPL, V78, P6329, DOI 10.1007/s11042-018-6370-1
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang HS, 2018, PATTERN RECOGN, V81, P23, DOI 10.1016/j.patcog.2018.03.030
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang J, 2014, IEEE T PATTERN ANAL, V36, P914, DOI 10.1109/TPAMI.2013.198
   Wang PC, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P97, DOI 10.1145/2964284.2967191
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Xu YY, 2018, IEEE SIGNAL PROC LET, V25, P1044, DOI 10.1109/LSP.2018.2841649
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang JY, 2021, IEEE T MULTIMEDIA, V23, P883, DOI 10.1109/TMM.2020.2990082
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Yang YH, 2017, IEEE T MULTIMEDIA, V19, P519, DOI 10.1109/TMM.2016.2626959
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2019, IEEE T PATTERN ANAL, V41, P1963, DOI 10.1109/TPAMI.2019.2896631
   Zhang SY, 2018, IEEE T MULTIMEDIA, V20, P2330, DOI 10.1109/TMM.2018.2802648
   Zhang X., 2020, P IEEE CVF C COMP VI, P14333, DOI DOI 10.1109/CVPR42600202001434
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
NR 60
TC 0
Z9 0
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9685
EP 9711
DI 10.1007/s11042-022-11919-y
EA FEB 2022
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000754122200001
DA 2024-07-18
ER

PT J
AU Kazi, A
   Panda, SP
AF Kazi, Aafreen
   Panda, Siba Prasada
TI Determining the freshness of fruits in the food industry by image
   classification using transfer learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Food industry; CNN architectures; Image classification; Deep learning
   algorithms; Classical convolutional networks; Residual networks
AB Convolutional neural networks (CNNs) play a significant role in a number of computer vision applications like image classification and object detection. Past studies have focused on the application of deep neural networks and convolutional neural networks for detecting the freshness of perishable goods like fruits and vegetables. However, this study tries to explore the potential of transfer learning with respect to the CNN models in image classification of fruits rather than implementing the traditional CNN architectures. In this study, the determination of three different types of fruits and its relative freshness was classified using various architectures of classical convolutional neural networks and a residual convolutional neural network. The performance of each model of the convolutional neural network was evaluated on the given set of data. The study tried to evaluate the best performing model on image data that consisted of six different types of fruits based on their test scores. The results suggest that the freshness of fruits could be determined with high accuracy by using traditional and residual convolutional neural networks. However, the residual networks perform extremely well on the fruits dataset which was considered with a test accuracy score greater than 99%. A glimpse on the implementation of the given algorithm in the food industry was also explored. Thus, this study attempts to select the CNN model that could be applied in the food industry in complementation with other computer vision techniques like background reduction, image augmentation methods.
C1 [Kazi, Aafreen] NMIMS Univ, MPSTME, Mumbai, Maharashtra, India.
   NMIMS Univ, MPSTME, Dept Data Sci, Mumbai, Maharashtra, India.
C3 SVKM's NMIMS (Deemed to be University); SVKM's NMIMS (Deemed to be
   University)
RP Kazi, A (corresponding author), NMIMS Univ, MPSTME, Mumbai, Maharashtra, India.
EM kaziaafrcen.ak@gmail.com
RI Kazi, Aafreen/CAG-6085-2022
CR Ananthi N., 2019, INT J INNOVATIVE TEC, V9
   Aniket H, 2020, INT RES J MODERN ENG
   Ann N, 2019, INT J ONLINE BIOMED
   Ayman E, 2012, UNDERSTANDING COLOR
   Bennedsen BS, 2005, COMPUT ELECTRON AGR, V48, P92, DOI 10.1016/j.compag.2005.01.003
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Dameshwari S, 2017, AM J ARTIF INTELL
   Dariush A, 2021, MULTIMEDIA TOOLS APP
   Dariush A, 2019, 5 IR C SIGN PROC INT
   David I, 2019, ARTIF INTELL AGR
   Dayanand S, 2012, INT J ENG INNOV TECH
   HAMEED K, 2018, IMAGE VISION COMPUT
   He K, 2012, DEEP RESIDUAL LEARNI
   Ke S., 2016, SCI REP-UK
   Kondo N, 2010, TRENDS FOOD SCI TECH, V21, P145, DOI 10.1016/j.tifs.2009.09.002
   Koyama K, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0248769
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lu Wang, 2014, DETECTION FRUIT SKIN
   Mahmoud H, 2018, ADV COMPUT INTELL SY
   Modhej N, 2020, PATTERN SEPARATION N
   Muresan H, 2018, ACTA U SAPIEN INFORM, V10, P26, DOI 10.2478/ausi-2018-0002
   Santi B, 2020, J AMBIENT INTELL HUM
   Shiv D, 2016, SIGNAL IMAGE VIDEO P
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singham P., 2015, J FOOD PROCESS TE-US, V6, P488
   Zeng GX, 2017, 2017 IEEE 3RD INFORMATION TECHNOLOGY AND MECHATRONICS ENGINEERING CONFERENCE (ITOEC), P613, DOI 10.1109/ITOEC.2017.8122370
   Zhong R, 2017, IND MANAGE DATA SYST, V117, P2085, DOI 10.1108/IMDS-09-2016-0391
NR 27
TC 20
Z9 21
U1 12
U2 65
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 6
BP 7611
EP 7624
DI 10.1007/s11042-022-12150-5
EA JAN 2022
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZW3UA
UT WOS:000749232600005
DA 2024-07-18
ER

PT J
AU Koley, S
AF Koley, Subhadeep
TI Bat optimized 3D anaglyph image watermarking based on maximum noise
   fraction in the digital Shearlet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anaglyph image; Digital watermarking; Cryptography; MNF; Digital
   Shearlet transform; Bat algorithm
ID SCHEME; ROBUST; QUALITY
AB The unparalleled growth of multimedia data sharing through the internet has made copyright protection and authentication a topical affair. In this paper, we propose a robust watermarking scheme for 3D red-cyan anaglyph stereo image authentication and copyright protection with Maximum Noise Fraction in the digital Shearlet domain. A precise Human Visual System-based approach has been integrated via Digital Shearlet Transform, to make full utilization of perceptual watermarking. The highest energy Maximum Noise Fraction Eigen image has been selected via entropy calculation followed by impregnation of the watermark inside the highest energy first Eigen image returned by Maximum Noise Fraction, using a total insertion based approach. An efficient watermarking approach is always a trade-off between imperceptibility and robustness. A reliable metaheuristic optimization approach, namely the Bat algorithm has been incorporated to find the optimum embedding factor, which provides high robustness while maintaining sublime imperceptibility. Moreover, the watermark's security has further been improved by encrypting it with a novel Henon chaotic system-based cryptic algorithm. Qualitative and quantitative comparison with other state-of-the-art methods is a proof of the primacy of the proposed framework under most intentional and unintentional malicious impairments.
C1 [Koley, Subhadeep] RCC Inst Informat Technol, Dept ECE, Kolkata, India.
C3 RCC Institute of Information Technology (RCCIIT)
RP Koley, S (corresponding author), RCC Inst Informat Technol, Dept ECE, Kolkata, India.
EM subhadeepkoley@gmail.com
RI Koley, Subhadeep/HME-1003-2023
OI Koley, Subhadeep/0000-0002-4010-4387
CR Ahmaderaghi B, 2018, IEEE T COMPUT IMAG, V4, P46, DOI 10.1109/TCI.2018.2794065
   [Anonymous], 2007, IEEE Conference on Computer Vision and Pattern Recognition
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Bhatnagar G, 2011, J VISUAL-JAPAN, V14, P85, DOI 10.1007/s12650-010-0067-5
   Devi HS, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102424
   Devi HS, 2017, ARAB J SCI ENG, V42, P3521, DOI 10.1007/s13369-017-2531-1
   Devi HS, 2016, CONT ENG SCI, V9, P1575, DOI [10.12988/ces.2016.69156, DOI 10.12988/CES.2016.69156]
   Dhaou D, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0223-1
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001
   Guo K., 2006, Wavelets and Splines, P189
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Kaur Gurjinder, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P727, DOI 10.1109/SPIN48934.2020.9071330
   Koley S, 2022, J KING SAUD UNIV-COM, V34, P636, DOI 10.1016/j.jksuci.2019.03.002
   Koley S, 2020, 2020 ZOOMING INNOVATION IN CONSUMER TECHNOLOGIES CONFERENCE (ZINC), P40, DOI [10.1109/zinc50678.2020.9161783, 10.1109/ZINC50678.2020.9161783]
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P32239, DOI 10.1007/s11042-019-07997-0
   Kumar R, 2019, MULTIMED TOOLS APPL, V78, P22977, DOI 10.1007/s11042-019-7640-2
   Kumar R, 2018, MULTIMED TOOLS APPL, V77, P13445, DOI 10.1007/s11042-017-4960-y
   Kutyniok G, 2012, APPL NUMER HARMON AN, P239, DOI 10.1007/978-0-8176-8316-0_7
   Liu RZ, 2002, IEEE T MULTIMEDIA, V4, P121, DOI 10.1109/6046.985560
   Luo GC, 2016, CAN J REMOTE SENS, V42, P106, DOI 10.1080/07038992.2016.1160772
   Malik Sunesh, 2019, International Journal of Information Technology, V11, P373, DOI 10.1007/s41870-018-0259-0
   Munoz-Ramirez DO, 2015, P EUR WORKSH URB DAT, P1, DOI [10.1109/ICEEE.2015.7357955, DOI 10.2312/UDMV.20151341]
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Prathap I, 2014, COMPUT ELECTR ENG, V40, P51, DOI 10.1016/j.compeleceng.2013.11.005
   Tibaduiza DA, 2013, P 6 EUR WORKSH STRUC, P1
   Wang C., 2015, INT J IMAGE PROCESS, V9, P156
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weber A., 1997, The usc-sipi image database
   Wu Y, 2011, Cyber J Multidiscip J Sci Technol J Sel Areas Telecommun (JSAT), V1, P31
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
NR 35
TC 4
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19491
EP 19523
DI 10.1007/s11042-021-11861-5
EA JAN 2022
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000750865600007
DA 2024-07-18
ER

PT J
AU Tu, YL
   Lin, WY
   Lin, YC
AF Tu, Yi-Lin
   Lin, Wei-Yang
   Lin, Yao-Cheng
TI Toward automatic plant phenotyping: starting from leaf counting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Leaf counting; Automated plant phenotyping
AB The development of automatic plant phenotyping systems has drawn great attention in the recent years. It can help improve the throughput of phenotyping measurements and reduce the associated human labor cost. Working towards the goal of automatic plant phenotyping, here we begin with developing an automatic method for leaf counting. Most of the previous approaches for leaf counting are based on regression modeling or instance segmentation. In contrast to these approaches, we consider the task of leaf counting as a object detection problem. In particular, we perform object detection and localization for leaves in the input images. The location and size of a leaf is indicated by a bounding box. Thus, we can obtain the number of leaves by counting the number of bounding boxes. We develop our leaf counting network architecture based on YOLOv3. In order to evaluate our proposed method, we utilize the cauliflower images from the ABRC (Agricultural Biotechnology Research Center, Academia Sinica) and the Arabidopsis images from the CVPPP (Computer Vision Problems in Plant Phenotyping) dataset. Our proposed method achieves state of the art results on these datasets.
C1 [Tu, Yi-Lin; Lin, Wei-Yang] Natl Chung Cheng Univ, Dept CSIE, Minhsiung, Chiayi, Taiwan.
   [Lin, Yao-Cheng] Acad Sinica, Agr Biotechnol Res Ctr, Nangang Dist, Taiwan.
C3 National Chung Cheng University; Academia Sinica - Taiwan
RP Lin, WY (corresponding author), Natl Chung Cheng Univ, Dept CSIE, Minhsiung, Chiayi, Taiwan.
EM yilin585198@gmail.com; wylin@cs.ccu.edu.tw; yalin@sinica.edu.tw
RI LIN, Yao-Cheng/B-4394-2008
OI LIN, Yao-Cheng/0000-0002-9390-795X
FU Ministry of Science and Technology (MOST), Taiwan [MOST
   108-2221-E-194-045]
FX This work was partially supported by the Ministry of Science and
   Technology (MOST), Taiwan, under Grant MOST 108-2221-E-194-045.
CR Aich S, 2017, IEEE INT CONF COMP V, P2080, DOI 10.1109/ICCVW.2017.244
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bisen D, 2021, MULTIMED TOOLS APPL, V80, P6443, DOI 10.1007/s11042-020-10038-w
   Bochkovskiy A., 2020, PREPRINT
   Buzzy M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20236896
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dobrescu A, 2017, IEEE INT CONF COMP V, P2072, DOI 10.1109/ICCVW.2017.243
   Farjon G, 2021, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.575751
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Giuffrida M.V., 2015, P COMP VIS PROB PLAN, p1.1, DOI [10.5244/C.29.CVPPP.1, DOI 10.5244/C.29.CVPPP.1]
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   Hsiao JK, 2014, 2014 SCIENCE AND INFORMATION CONFERENCE (SAI), P389, DOI 10.1109/SAI.2014.6918216
   Itzhaky Y., 2018, P BMVC, P328
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946
   Jou-Ken Hsiao, 2014, 2014 IEEE International Conference on Consumer Electronics - Taiwan (ICCE-TW), P209, DOI 10.1109/ICCE-TW.2014.6904061
   Kuznichov D, 2019, IEEE COMPUT SOC CONF, P2580, DOI 10.1109/CVPRW.2019.00314
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu MJ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082238
   Minervini M, 2017, PLANT J, V90, P204, DOI 10.1111/tpj.13472
   Minervini M, 2016, PATTERN RECOGN LETT, V81, P80, DOI 10.1016/j.patrec.2015.10.013
   Qiu ZF, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.4.043023
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren MY, 2017, PROC CVPR IEEE, P293, DOI 10.1109/CVPR.2017.39
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ubbens J, 2018, PLANT METHODS, V14, DOI 10.1186/s13007-018-0273-z
   Ubbens JR, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01190
   Weyler J, 2021, IEEE ROBOT AUTOM LET, V6, P3599, DOI 10.1109/LRA.2021.3060712
   Xiao YZ, 2020, MULTIMED TOOLS APPL, V79, P23729, DOI 10.1007/s11042-020-08976-6
   Xu LL, 2018, JOINT INT CONF SOFT, P180, DOI 10.1109/SCIS-ISIS.2018.00038
   Yeh CH, 2022, IEEE T NEUR NET LEAR, V33, P6129, DOI 10.1109/TNNLS.2021.3072414
   Zexing Du, 2019, Journal of Physics: Conference Series, V1314, DOI 10.1088/1742-6596/1314/1/012202
   Zhang Y, 2019, OPTIK, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Zhu Y., 2018, P BRIT MACH VIS C BM, P324
NR 33
TC 3
Z9 3
U1 4
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 9
BP 11865
EP 11879
DI 10.1007/s11042-021-11886-w
EA JAN 2022
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0P3ES
UT WOS:000748678300003
DA 2024-07-18
ER

PT J
AU Nagaraju, M
   Chawla, P
   Kumar, N
AF Nagaraju, M.
   Chawla, Priyanka
   Kumar, Neeraj
TI Performance improvement of Deep Learning Models using image augmentation
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial intelligence; Augmentation techniques; CNN Models; Deep
   learning; Image acquisition; Image augmentations
ID LEAF; IDENTIFICATION; CLASSIFICATION
AB The major barrier while using deep learning models is lack of large number of images in the training dataset. In fact, there is a need of thousands of images in each image categories based on the complexity of problem. Prior studies have shown that picture augmentation techniques can be used to enhance the number of images in a training dataset artificially. These techniques can aid in improving the overall learning process and performance of a deep learning model. Hence, to address this problem we have proposed three algorithms. Firstly, two image acquisition algorithms have been proposed to systematically obtain real field images for testing and images from public datasets for training a model. Secondly, an algorithm is proposed to describe the procedure how the augmentations can be applied to enhance the datasets. During this study, we have investigated 52 augmentations that can allow enhancing the size of input dataset by improving the quantity of images. To perform the classification process of four maize crop diseases, a new convolutional neural network model is developed and several experiments have been performed to prove its effectiveness. Firstly, two tests were carried out using the original dataset from Kaggle public repository and the augmented dataset. When compared with the original dataset, the model improved by 5.14% with the augmented dataset. Secondly, three experiments carried out to evaluate the performance of proposed augmentation method. Experimental results demonstrated that the proposed approach outperforms the existing three approaches by 27.38%, 3.14%, and 1.34% during the classification process. The proposed IPA augmentation method has been compared with six existing methods: Full Stage Data Augmentation Framework, LeafGAN, Novel Augmentation method based on GAN, Wasserstein Generative Adversarial Network (WGAN), Activation Reconstruction-GAN, and Step-by-Step Data Augmentation Method and experimental results show that performance is better than existing methods by 28.31%, 19.76%, 20.18%, 13.75%, 2.42%, and 12.68% respectively.
C1 [Nagaraju, M.; Chawla, Priyanka] Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
   [Kumar, Neeraj] Thapar Inst Engn Technol, Dept Comp Sci & Engn, Patiala, Punjab, India.
C3 Lovely Professional University; Thapar Institute of Engineering &
   Technology
RP Chawla, P (corresponding author), Lovely Profess Univ, Sch Comp Sci & Engn, Phagwara, Punjab, India.
EM priyankachawla.cse@gmail.com
RI nagaraju, mamillapally/AHC-1086-2022; Kumar, Neeraj/L-3500-2016
OI nagaraju, mamillapally/0000-0001-8898-1090; Kumar,
   Neeraj/0000-0002-3020-3947
CR Arsenovic M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11070939
   Avuçlu E, 2021, MEASUREMENT, V180, DOI 10.1016/j.measurement.2021.109577
   Bansilal S, 2017, PYTHAGORAS, V38, DOI 10.4102/pythagoras.v38i1.314
   Bi LN, 2020, FRONT PLANT SCI, V11, DOI 10.3389/fpls.2020.583438
   Cap QH, 2022, IEEE T AUTOM SCI ENG, V19, P1258, DOI 10.1109/TASE.2020.3041499
   Chen K, 2021, ARXIV PREPRINT ARXIV, P1, DOI DOI 10.1061/(ASCE)EY.1943-7897.0000804
   Dyrmann M, 2016, BIOSYST ENG, V151, P72, DOI 10.1016/j.biosystemseng.2016.08.024
   Enkvetchakul P., 2021, APPL SCI ENG PROG, V15, P3810, DOI [10.14416/j.asep.2021.01.003, DOI 10.14416/J.ASEP.2021.01.003]
   Fengle Zhua M., 2020, COMPUT ELECTRON AGR, V175
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Kaur S, 2019, ARCH COMPUT METHOD E, V26, P507, DOI 10.1007/s11831-018-9255-6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leevy JL, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0151-6
   Pires RDL, 2016, COMPUT ELECTRON AGR, V125, P48, DOI 10.1016/j.compag.2016.04.032
   Ma JC, 2018, COMPUT ELECTRON AGR, V154, P18, DOI 10.1016/j.compag.2018.08.048
   PEREZ L, 2007, COMPUTER VISION PATT, P1, DOI DOI 10.5354/0718-0527.2007.13935
   Prasad S, 2016, SIGNAL IMAGE VIDEO P, V10, P379, DOI 10.1007/s11760-015-0751-y
   Ramcharan A, 2017, FRONT PLANT SCI, V8, DOI 10.3389/fpls.2017.01852
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Tian YN, 2019, J SENSORS, V2019, DOI 10.1155/2019/7630926
   Xu Y., 2016, ARXIV160103651, P1461
   Yan Q, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123535
   Zhang JY, 2021, INT J DISTRIB SENS N, V17, DOI 10.1177/15501477211007407
   Zhang SW, 2015, J ANIM PLANT SCI, V25, P42
   Zhang XH, 2018, IEEE ACCESS, V6, P30370, DOI 10.1109/ACCESS.2018.2844405
   Zheng QH, 2020, DISCRETE DYN NAT SOC, V2020, DOI 10.1155/2020/4706576
NR 28
TC 6
Z9 6
U1 4
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2022
VL 81
IS 7
BP 9177
EP 9200
DI 10.1007/s11042-021-11869-x
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZY3PL
UT WOS:000746354000003
DA 2024-07-18
ER

PT J
AU Fang, LL
   Zhang, LR
AF Fang, Lingling
   Zhang, Lirong
TI Segmentation of the optic disc and optic cup using a machine
   learning-based biregional contour evolution model for the cup-to-disc
   ratio
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Glaucoma; Machine learning; Biregional contour evolution; Optic disc and
   optic cup segmentation; Cup-to-disc ratio
ID EDGE-STOP FUNCTIONS; EXTRACTION; BOUNDARY
AB Glaucoma, a chronic eye disease with irreversible blindness, is difficult to diagnose early. The cup-to-disc ratio is an important diagnostic index in glaucoma screening. Segmenting the optic disc and the optic cup is critical for glaucoma screening. Artificial glaucoma screening is time-consuming and laborious, so computer-aided function is important to save more human resources. In this paper, a biregional contour evolution model based on machine learning is proposed to segment the optic disc and the optic cup. To segment probability information in a more complete OD-OC, feature space is integrated into the edge indicator function by a machine learning method, and the intensity, edge, and region features of the OD-OC are obtained. In addition, the cup-to-disc ratio is calculated to diagnose glaucoma because it is currently practiced and can effectively assist doctors in clinical diagnosis. To evaluate the reliability and effectiveness of the proposed model, qualitative and quantitative results are obtained in the Dhristi-GS, DRIVE, and REFUGE datasets.
C1 [Fang, Lingling; Zhang, Lirong] Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
   [Fang, Lingling] Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.
C3 Liaoning Normal University; Nanchang Institute Technology
RP Fang, LL (corresponding author), Liaoning Normal Univ, Dept Comp & Informat Technol, Dalian, Liaoning, Peoples R China.; Fang, LL (corresponding author), Nanchang Inst Technol, Nanchang, Jiangxi, Peoples R China.
EM fanglingling@lnnu.edu.cn
RI Zhang, Liqun/JDN-3523-2023; zhang, lin/IZQ-4870-2023; Zhang,
   Li/GWM-7501-2022; Fang, Lingling/N-1534-2018
OI Fang, Lingling/0000-0002-4397-7212
FU Natural Science Foundations of China [6180120]; Dalian Youth Science and
   Technology Star [2019RQ021]
FX This work was supported by the Natural Science Foundations of China
   [grant number 6180120] and Dalian Youth Science and Technology Star
   [Grant Number 2019RQ021].
CR Aquino A, 2010, IEEE T MED IMAGING, V29, P1860, DOI 10.1109/TMI.2010.2053042
   Bengani S, 2021, MULTIMED TOOLS APPL, V80, P3443, DOI 10.1007/s11042-020-09778-6
   Biswal B, 2020, IET IMAGE PROCESS, V14, P592, DOI 10.1049/iet-ipr.2019.0845
   Bouacheria M, 2020, PHYS ENG SCI MED, V43, P1265, DOI 10.1007/s13246-020-00930-y
   Chakravarty A, 2017, COMPUT METH PROG BIO, V147, P51, DOI 10.1016/j.cmpb.2017.06.004
   Ehkan Phaklen, 2020, IOP Conference Series: Materials Science and Engineering, V767, DOI 10.1088/1757-899X/767/1/012054
   Fang JX, 2019, IEEE ACCESS, V7, P184518, DOI 10.1109/ACCESS.2019.2909981
   Fu HZ, 2018, IEEE T MED IMAGING, V37, P1597, DOI 10.1109/TMI.2018.2791488
   Haleem MS, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0859-4
   Juneja M, 2020, MULTIMED TOOLS APPL, V79, P15531, DOI 10.1007/s11042-019-7460-4
   Khalil T, 2018, IEEE ACCESS, V6, P4560, DOI 10.1109/ACCESS.2018.2791427
   Li S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060909
   Memon AA, 2020, COMPUT MATH METHOD M, V2020, DOI 10.1155/2020/6317415
   Nannini DR, 2018, OPHTHALMOLOGY, V125, P815, DOI 10.1016/j.ophtha.2017.12.014
   Pratondo A, 2016, IEEE SIGNAL PROC LET, V23, P222, DOI 10.1109/LSP.2015.2508039
   Rao PV, 2015, PROC MAT SCI, V10, P446, DOI 10.1016/j.mspro.2015.06.080
   Sedai S, 2016, IEEE ENG MED BIO, P3260, DOI 10.1109/EMBC.2016.7591424
   Sekhar S, 2008, I S BIOMED IMAGING, P1577, DOI 10.1109/ISBI.2008.4541312
   Shehryar T, 2020, INT J IMAG SYST TECH, V30, P1046, DOI 10.1002/ima.22413
   Shen J, 2018, APPL SURF SCI, V433, P358, DOI 10.1016/j.apsusc.2017.10.077
   Tabassum M, 2020, IEEE ACCESS, V8, P102733, DOI 10.1109/ACCESS.2020.2998635
   Tan NM, 2015, COMPUT MED IMAG GRAP, V40, P182, DOI 10.1016/j.compmedimag.2014.10.002
   Tan ZN, 2020, FUTURE GENER COMP SY, V108, P521, DOI 10.1016/j.future.2020.02.076
   Thakur N, 2019, EXPERT SYST APPL, V127, P308, DOI 10.1016/j.eswa.2019.03.009
   Ünver HM, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9020350
   Yang CL, 2018, BIOMED ENG ONLINE, V17, DOI 10.1186/s12938-018-0560-y
   Yang XJ, 2020, INT J AMBIENT COMPUT, V11, P87, DOI 10.4018/IJACI.2020010105
   Yu S, 2018, IEEE J BIOMED HEALTH, V22, P886, DOI 10.1109/JBHI.2017.2710201
   Zhao J, 2020, SIGNAL PROCESS, V166, DOI 10.1016/j.sigpro.2019.107270
NR 29
TC 2
Z9 2
U1 4
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36217
EP 36238
DI 10.1007/s11042-021-11583-8
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000740429700014
DA 2024-07-18
ER

PT J
AU Alijani, S
   Tanha, J
   Mohammadkhanli, L
AF Alijani, Shadi
   Tanha, Jafar
   Mohammadkhanli, Leyli
TI An ensemble of deep learning algorithms for popularity prediction of
   flickr images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image popularity; Social network; Convolutional neural networks; Deep
   learning; Ensemble of hybrid networks
AB Content popularity prediction is a technique that helps service providers to apply user behavior analysis to provide better services or products. Popularity prediction on social networks is mainly performed using different contents, such as texts, images, voices, or videos. Recent studies on popularity prediction on images show significant results and provide several effective factors for popular content. These studies mainly use feature-based, time-series-based, or deep-learning based approaches to handle popularity prediction tasks. However, in complex data containing diverse subjects, popularity prediction is a challenging task. The first challenge in this task is to use images effectively along with their textual contents, like user data, text content, and time data. Since, the nature of data on social networks originally is noisy, this further increases the complexity of data and degrades the performance of the prediction model. To address these difficulties, we focus on image content along with textual features to design a hybrid deep-based model. Furthermore, to deal with the noise, several data adaptation and normalization approaches are proposed to generate the proper format of data as input of the proposed hybrid model. The proposed hybrid model consists of three sub-models to extract features simultaneously from image content and the normalized user-time data. In the final step, an ensemble of hybrid networks is proposed based on the constructed component classifiers. For popularity prediction, data from Flickr are employed in these experiments. The experimental results of this study on the Flickr dataset show that the proposed method achieves 87.55% classification accuracy and results in 9.04% improvement. Furthermore, the proposed hybrid model significantly outperforms the baseline methods in this study.
C1 [Alijani, Shadi; Tanha, Jafar; Mohammadkhanli, Leyli] Univ Tabriz, Elect & Comp Engn Dept, 29 Bahman St, Tabriz, Iran.
C3 University of Tabriz
RP Tanha, J (corresponding author), Univ Tabriz, Elect & Comp Engn Dept, 29 Bahman St, Tabriz, Iran.
EM shadi.alijani96@ms.tabrizu.ac.ir; tanha@tabrizu.ac.ir;
   l-khanli@tabrizu.ac.ir
RI tanha, jafar/AAO-2736-2020
OI tanha, jafar/0000-0002-0779-6027
CR Albelwi S, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19060242
   Aloufi S, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030631
   [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273592
   [Anonymous], 2009, Proceedings of the 18th ACM conference on Information and knowledge management, DOI 10.1145/1645953.1646225
   [Anonymous], 2015, Batch-normalized maxout network in network
   [Anonymous], 2014, Journal of Computational Information Systems
   [Anonymous], 2012, P 5 ACM INT C WEB SE, DOI [10.1145/2124295.2124320, DOI 10.1145/2124295.2124320]
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI DOI 10.1145/2433396.2433443
   [Anonymous], 2014, P INT AAAI C WEB SOC
   Bandari R., 2012, ICWSM, P26
   Bao P, 2015, WWW'15 COMPANION: PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P9, DOI 10.1145/2740908.2742744
   Bruch S, 2019, PROCEEDINGS OF THE 2019 ACM SIGIR INTERNATIONAL CONFERENCE ON THEORY OF INFORMATION RETRIEVAL (ICTIR'19), P75, DOI 10.1145/3341981.3344221
   Cao Q, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1149, DOI 10.1145/3132847.3132973
   Carta S, 2020, INFORMATION, V11, DOI 10.3390/info11090453
   Chen GD, 2019, NEUROCOMPUTING, V333, P221, DOI 10.1016/j.neucom.2018.12.039
   Chittaragi NB, 2018, ARAB J SCI ENG, V43, P4289, DOI 10.1007/s13369-017-2941-0
   De S, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEMS, COMPUTING AND IT APPLICATIONS (CSCITA), P174, DOI 10.1109/CSCITA.2017.8066548
   Deng SG, 2017, IEEE T NEUR NET LEAR, V28, P1164, DOI 10.1109/TNNLS.2016.2514368
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Gürsun G, 2011, IEEE INFOCOM SER, P16, DOI 10.1109/INFCOM.2011.5934965
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Hu Y, 2016, NEUROCOMPUTING, V210, P55, DOI 10.1016/j.neucom.2015.10.143
   Huan EY, 2020, MULTIMED TOOLS APPL, V79, P11905, DOI 10.1007/s11042-019-08376-5
   Jia AL, 2018, COMPUT NETW, V140, P112, DOI 10.1016/j.comnet.2018.05.004
   Khosla A, 2014, WWW'14: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P867, DOI 10.1145/2566486.2567996
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CL, 2017, 2017 IEEE SECOND INTERNATIONAL CONFERENCE ON DC MICROGRIDS (ICDCM), P577, DOI 10.1109/ICDCM.2017.8001105
   Liu XY, 2017, IEEE INT C INTELL TR
   Lucic M., 2017, Are gans created equal? a large-scale study
   Ma JJ, 2018, TONGUE IMAGE CONSTIT
   Mao XX, 2019, KNOWL-BASED SYST, V165, P253, DOI 10.1016/j.knosys.2018.11.033
   Aiello LM, 2013, IEEE T MULTIMEDIA, V15, P1268, DOI 10.1109/TMM.2013.2265080
   Mariani G., 2018, Bagan: Data augmentation with balancing gan
   Mishra S, 2016, CIKM'16: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1069, DOI 10.1145/2983323.2983812
   Pal S, 2016, IEEE MILIT COMMUN C, P588, DOI 10.1109/MILCOM.2016.7795391
   Pannu HS, 2020, MULTIMED TOOLS APPL, V79, P21941, DOI 10.1007/s11042-020-08905-7
   Rizoiu MA, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P735, DOI 10.1145/3038912.3052650
   Rousidis D., 2020, MULTIMEDIA TOOLS APP
   Samanta B, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2679
   Sen Pratap Chandra, 2020, Emerging Technology in Modelling and Graphics. Proceedings of IEM Graph 2018. Advances in Intelligent Systems and Computing (AISC 937), P99, DOI 10.1007/978-981-13-7403-6_11
   ShakirulIslam M, 2019, INCEPTB CNN BASED CL, V143, P595
   Shen HW, 2014, AAAI CONF ARTIF INTE, P291
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Smith L. N., 2018, A disciplined approach to neural network hyper-parameters: Part 1 learning rate, batch size, momentum, and weight decay
   Sutskever I, 2014, ADV NEUR IN, V27
   Szabo G, 2010, COMMUN ACM, V53, P80, DOI 10.1145/1787234.1787254
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Trzcinski T, 2017, IEEE T MULTIMEDIA, V19, P2561, DOI 10.1109/TMM.2017.2695439
   Trzcinski T, 2017, LECT NOTES ARTIF INT, V10352, P146, DOI 10.1007/978-3-319-60438-1_15
   Wang YT, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19235270
   Warde-Farley David., 2013, An Empirical Analysis of Dropout in Piecewise Linear Networks. ArXiv e-prints
   Wu B, 2016, AAAI CONF ARTIF INTE, P272
   Wu B, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1336, DOI 10.1145/2964284.2964335
   Yang J., 2011, P 4 ACM INT C WEB SE, P177, DOI DOI 10.1145/1935826.1935863
   Yu F, 2016, SIGIR'16: PROCEEDINGS OF THE 39TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P729, DOI 10.1145/2911451.2914683
   Zhao QY, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1513, DOI 10.1145/2783258.2783401
   Zohourian A, 2018, 2018 4TH INTERNATIONAL CONFERENCE ON WEB RESEARCH (ICWR), P111, DOI 10.1109/ICWR.2018.8387246
NR 58
TC 2
Z9 2
U1 3
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3253
EP 3274
DI 10.1007/s11042-021-11517-4
EA JAN 2022
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000740429600001
DA 2024-07-18
ER

PT J
AU Rathee, A
   Chhabra, JK
AF Rathee, Amit
   Chhabra, Jitender Kumar
TI Feature-based critical components identification in multimedia software
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Critical Component; Key Class; Multimedia Software; Hierarchical
   Clustering; Features of a Class
ID KEY CLASSES; MAINTENANCE; SYSTEM
AB Software maintenance is a necessary and frequently occurring activity in software engineering. However, different factors such as inadequate documentation, project size, complex dependencies, and hard to understand architecture cause software maintenance to consume a large part of project resources. Therefore, it is important to assist the newcomers by providing program comprehension facilities that can reveal important information about the software system and can speed up the maintenance tasks. This important information about software includes knowledge about the core part (classes, components, design, etc.) of the system that mainly controls its whole functionality. In literature, different researches attempted to determine core part of the software using various structural, dynamic, and network metrics and termed them as key or critical classes. These approaches have an open scope for modeling coupling relations among different elements of software and most of these approaches need human expertise to identify key classes of the software. Moreover, multimedia software systems are generally interface driven and thus many micro level classes collectively constitute macro level units called as multimedia components. Therefore, this paper focuses to identify key critical units of the multimedia software at component level. The proposed approach in this paper consists of three main phases. In the first phase, different features of a class are identified and assigned a coupling based functional score that represents its significance in the overall functionality of the class. In the second phase, different independent components present in the multimedia software are identified by modeling the system as a dependency graph at the class level. Finally, key critical components of the multimedia software are identified by performing hierarchical agglomerative clustering based on the dependency strength among different identified components. The proposed approach is empirically evaluated on open-source multimedia software of different sizes and the obtained results support the feasibility and usability of the proposed approach of this paper.
C1 [Rathee, Amit] GC, Dept Comp Sci, Sonipat, Haryana, India.
   [Chhabra, Jitender Kumar] Natl Inst Technol, Dept Comp Engn, Kurukshetra, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Rathee, A (corresponding author), GC, Dept Comp Sci, Sonipat, Haryana, India.
EM amit1983_rathee@rediffmail.com; jitenderchhabra@gmail.com
RI Rathee, Amit/AAJ-5526-2020; Chhabra, Jitender Kumar/A-1026-2016
OI Rathee, Amit/0000-0001-5335-3756; Chhabra, Jitender
   Kumar/0000-0002-2257-0982
CR Broy M, 1998, SOFTWARE-CONC TOOL, V19, P49, DOI 10.1007/s003780050007
   Bruce KimB., 2002, Foundations of Object-Oriented Languages: Types and Semantics
   Chhabra A., 2019, INFORM SYST FRONT, P1
   Ding Y, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3858637
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Fernández-Sáez AM, 2015, INFORM SOFTWARE TECH, V57, P644, DOI 10.1016/j.infsof.2014.05.014
   Guerrouj L, 2017, SOFTWARE QUAL J, V25, P641, DOI 10.1007/s11219-016-9318-6
   Hirakawa M, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P85, DOI 10.1109/MMCS.1999.779125
   Jonsson H., 2008, Proceedings of the Institution of Mechanical Engineers, Part O (Journal of Risk and Reliability), V222, P235, DOI 10.1243/1748006XJRR138
   Kamran M., 2013, LECT NOTES ELECT ENG, V211, P3
   Mallick C, 2019, ADV INTELL SYST, V758, P137, DOI 10.1007/978-981-13-0514-6_14
   Maruyama Katsuhisa, 2014, P 22 INT C PROGRAM C, P207
   Meyer P, 2014, ADV COMPLEX SYST, V17, DOI 10.1142/S0219525915500046
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Neate B, 2006, 2006 AUSTRALIAN SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P369
   Noda K, 2018, IEICE T INF SYST, VE101D, P1751, DOI 10.1587/transinf.2017KBP0018
   Osman H, 2013, PROC IEEE INT CONF S, P140, DOI 10.1109/ICSM.2013.25
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Pan WF, 2018, FUTURE GENER COMP SY, V81, P188, DOI 10.1016/j.future.2017.10.006
   Park K, 2020, APPL ARTIF INTELL, V34, P396, DOI 10.1080/08839514.2020.1723868
   Rathee A, 2020, INFORM SYST FRONT, V22, P1519, DOI 10.1007/s10796-019-09948-4
   Rathee A, 2019, J COMPUT LANG, V52, P26, DOI 10.1016/j.cola.2019.01.006
   Rathee A, 2019, MULTIMED TOOLS APPL, V78, P20065, DOI 10.1007/s11042-019-7382-1
   Rathee A, 2018, J UNIVERS COMPUT SCI, V24, P1731
   Rathee A, 2018, PROCEDIA COMPUT SCI, V125, P740, DOI 10.1016/j.procs.2017.12.095
   Sharma KK, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103928
   Sharma KK, 2019, EXPERT SYST APPL, V137, P100, DOI 10.1016/j.eswa.2019.06.050
   Sora I, 2019, INFORM SOFTWARE TECH, V116, DOI 10.1016/j.infsof.2019.106176
   Sora I, 2015, 2015 IEEE 10TH JUBILEE INTERNATIONAL SYMPOSIUM ON APPLIED COMPUTATIONAL INTELLIGENCE AND INFORMATICS (SACI), P495, DOI 10.1109/SACI.2015.7208254
   Steidl D., 2012, 2012 19th Working Conference on Reverse Engineering (WCRE), P93, DOI 10.1109/WCRE.2012.19
   Szyperski C., 2002, Component Software: Beyond Object-Oriented Programming
   Thung F., 2014, P 22 INT C PROGR COM, P110, DOI 10.1145/2597008.2597157
   Vale LD, 2019, INT J SOFTW ENG KNOW, V29, P1439, DOI 10.1142/S0218194019500451
   Vale LD, 2015, PROC IEEE INT CONF S, P566, DOI 10.1109/ICSM.2015.7332515
   Van Rijsbergen C. J., 1980, New Models in Probabilistic Information Retrieval, V5587
   VONMAYRHAUSER A, 1995, COMPUTER, V28, P44, DOI 10.1109/2.402076
   Wang Yu-ying, 2007, Journal of Shanghai University, V11, P474, DOI 10.1007/s11741-007-0507-2
   Xiaocheng Ge, 2010, Proceedings of the 2010 Agile Conference (AGILE 2010), P35, DOI 10.1109/AGILE.2010.10
   Yang XL, 2016, P INT COMP SOFTW APP, P22, DOI 10.1109/COMPSAC.2016.83
   Zaidman A, 2008, J SOFTW MAINT EVOL-R, V20, P387, DOI 10.1002/smr.370
   Zanatta AL, 2018, SBES'18: PROCEEDINGS OF THE XXXII BRAZILIAN SYMPOSIUM ON SOFTWARE ENGINEERING, P5, DOI 10.1109/MS.2017.32
   Zhou YM, 2007, J SYST SOFTWARE, V80, P1349, DOI 10.1016/j.jss.2006.10.049
NR 42
TC 1
Z9 1
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 35595
EP 35618
DI 10.1007/s11042-021-11277-1
EA JAN 2022
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000737106100001
DA 2024-07-18
ER

PT J
AU Jun, C
   Yue, G
   Luo, LB
   Gong, WP
   Yong, W
AF Jun, Chen
   Yue, Gu
   Luo Linbo
   Gong Wenping
   Yong, Wang
TI Two-view correspondence learning via complex information extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Correspondences; Outlier removal; Attention mechanism; Pose estimation
ID IMAGE; REGISTRATION; LOCALITY
AB Establishing reliable correspondences plays a vital role in many feature-matching based computer vision tasks. Given putative correspondences of feature points in two images, in this paper, we propose a novel network for inferring the probabilities of correspondences being inliers or outliers and regressing the relative pose encoded by the essential matrix. Previous research proposed an end-to-end permutation-equivariant classification network based on multi-layer perceptrons and context normalization. However, the context normalization treats each correspondence equally and ignore the extraction of channel information, as a result the representation capability of potential inliers can be reduced. To solve this problem, we apply attention mechanism in our network to capture complex information of the feature maps. Specifically, we introduce two types of attention blocks. We adopt the spatial attention block to capture complex spatial contextual information, and the rich channel information can be obtained by utilizing the channel attention block. To obtain richer contextual information and feature maps with stronger representative capacity, We combine these attention blocks with the PointCN block to form a new network with strong representative ability. Experimental results on several benchmark datasets show that the performance on outlier removal and camera pose estimation is significantly improved over the state-of-the-arts.
C1 [Jun, Chen; Yue, Gu] China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.
   [Jun, Chen; Yue, Gu] Hubei Key Lab Adv Control & Intelligent Automat C, Wuhan 430074, Peoples R China.
   [Jun, Chen; Yue, Gu] Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan 430074, Peoples R China.
   [Luo Linbo; Yong, Wang] China Univ Geosci, Sch Mech Engn & Elect Informat, Wuhan 430074, Peoples R China.
   [Gong Wenping] China Univ Geosci, Fac Engn, Wuhan 430074, Peoples R China.
C3 China University of Geosciences; China University of Geosciences; China
   University of Geosciences
RP Jun, C (corresponding author), China Univ Geosci, Sch Automat, Wuhan 430074, Peoples R China.; Jun, C (corresponding author), Hubei Key Lab Adv Control & Intelligent Automat C, Wuhan 430074, Peoples R China.; Jun, C (corresponding author), Minist Educ, Engn Res Ctr Intelligent Technol Geoexplorat, Wuhan 430074, Peoples R China.
EM chenjun71983@163.com
RI Gong, Wenping/GZM-8565-2022
OI Chen, Jun/0000-0001-9005-6849
FU National Natural Science Foundation of China [62073304, 41977242,
   61973283]
FX This work was supported by the National Natural Science Foundation of
   China nos. 62073304, 41977242 and 61973283.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.445
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   Camps-Valls G., 2011, Recherches sur la Methode, V5, P1, DOI 10.2200/S00392ED1V01Y201107IVM012
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dellinger F, 2015, IEEE T GEOSCI REMOTE, V53, P453, DOI 10.1109/TGRS.2014.2323552
   DeTone D, 2018, IEEE COMPUT SOC CONF, P337, DOI 10.1109/CVPRW.2018.00060
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Jiang XY, 2021, INFORM FUSION, V73, P22, DOI 10.1016/j.inffus.2021.02.012
   Jiang XY, 2019, IEEE T GEOSCI REMOTE, V57, P6462, DOI 10.1109/TGRS.2019.2906183
   Jiang XY, 2020, IEEE T IMAGE PROCESS, V29, P736, DOI 10.1109/TIP.2019.2934572
   Jiang XY, 2019, INT CONF ACOUST SPEE, P2217, DOI 10.1109/ICASSP.2019.8682372
   Lenc K, 2016, LECT NOTES COMPUT SC, V9915, P100, DOI 10.1007/978-3-319-49409-8_11
   Li XR, 2010, INT J COMPUT VISION, V89, P1, DOI 10.1007/s11263-010-0318-x
   Lin WY, 2018, IEEE T PATTERN ANAL, V40, P34, DOI 10.1109/TPAMI.2017.2652468
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01359-2
   Ma JY, 2019, IEEE T IMAGE PROCESS, V28, P4045, DOI 10.1109/TIP.2019.2906490
   Ma JY, 2019, INT J COMPUT VISION, V127, P512, DOI [10.1109/TMAG.2017.2763198, 10.1007/s11263-018-1117-z]
   Ma JY, 2019, IEEE T NEUR NET LEAR, V30, P3584, DOI 10.1109/TNNLS.2018.2872528
   Ma JY, 2018, IEEE INT CONF ROBOT, P7254
   Ma JY, 2018, IEEE T GEOSCI REMOTE, V56, P4435, DOI 10.1109/TGRS.2018.2820040
   Ma JY, 2017, AAAI CONF ARTIF INTE, P4218
   Ma JY, 2016, IEEE T IMAGE PROCESS, V25, P53, DOI 10.1109/TIP.2015.2467217
   Ma JY, 2015, IEEE T SIGNAL PROCES, V63, P1115, DOI 10.1109/TSP.2014.2388434
   Ma JY, 2015, IEEE SIGNAL PROC LET, V22, P767, DOI 10.1109/LSP.2014.2358625
   Ma JY, 2014, IEEE T IMAGE PROCESS, V23, P1706, DOI 10.1109/TIP.2014.2307478
   Ma JY, 2013, PATTERN RECOGN, V46, P3519, DOI 10.1016/j.patcog.2013.05.017
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Miao S, 2016, IEEE T MED IMAGING, V35, P1352, DOI 10.1109/TMI.2016.2521800
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pan BY, 2021, MULTIMED TOOLS APPL, V80, P19179, DOI 10.1007/s11042-021-10662-0
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sedaghat A, 2015, IEEE T GEOSCI REMOTE, V53, P5283, DOI 10.1109/TGRS.2015.2420659
   Simonovsky Martin, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9902, P10, DOI 10.1007/978-3-319-46726-9_2
   Sun W, 2019, IEEE I CONF COMP VIS, P10530, DOI 10.1109/ICCV.2019.01063
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Wang YT, 2020, NEUROCOMPUTING, V382, P87, DOI 10.1016/j.neucom.2019.11.051
   Yang K, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9060581
   Yang X, 2017, NEUROIMAGE, V158, P378, DOI 10.1016/j.neuroimage.2017.07.008
   Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang JH, 2019, IEEE I CONF COMP VIS, P5844, DOI 10.1109/ICCV.2019.00594
   Zhang X, 2017, IEEE I CONF COMP VIS, P4605, DOI 10.1109/ICCV.2017.492
   Zhang ZY, 2017, MULTIMED TOOLS APPL, V76, P18513, DOI 10.1007/s11042-016-4162-z
   Zhao C, 2019, PROC CVPR IEEE, P215, DOI 10.1109/CVPR.2019.00030
   Zhao C, 2020, IEEE T IMAGE PROCESS, V29, P3506, DOI 10.1109/TIP.2019.2962678
   Zhao J, 2011, PROC CVPR IEEE, P2977, DOI 10.1109/CVPR.2011.5995336
NR 59
TC 3
Z9 3
U1 5
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 3
BP 3939
EP 3957
DI 10.1007/s11042-021-11731-0
EA NOV 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ZE7LS
UT WOS:000722484100001
DA 2024-07-18
ER

PT J
AU Paul, A
   Kundu, A
   Chaki, N
   Dutta, D
   Jha, CS
AF Paul, Arati
   Kundu, Ahana
   Chaki, Nabendu
   Dutta, Dibyendu
   Jha, C. S.
TI Wavelet enabled convolutional autoencoder based deep neural network for
   hyperspectral image denoising
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperspectral image; Denoising; Convolutional neural networks; Residual
   learning; Discrete wavelet transformation
ID FRAMEWORK
AB Denoising of hyperspectral images (HSIs) is an important preprocessing step to enhance the performance of its analysis and interpretation. In reality, a remotely sensed HSI experiences disturbance from different sources and therefore gets affected by multiple noise types. However, most of the existing denoising methods concentrates in removal of a single noise type ignoring their mixed effect. Therefore, a method developed for a particular noise type doesn't perform satisfactorily for other noise types. To address this limitation, a denoising method is proposed here, that effectively removes multiple frequently encountered noise patterns from HSI including their combinations. The proposed dual branch deep neural network based architecture works on wavelet transformed bands. The first branch of the network uses deep convolutional skip connected layers with residual learning for extracting local and global noise features. The second branch includes layered autoencoder together with subpixel upsampling that performs repeated convolution in each layer to extract prominent noise features from the image. Two hyperspectral datasets are used in the experiment to evaluate the performance of the proposed method for denoising of Gaussian, stripe and mixed noises. Experimental results demonstrate the superior performance of the proposed network compared to other state-of-the-art denoising methods with PSNR 36.74, SSIM 0.97 and overall accuracy 94.03 %.
C1 [Paul, Arati; Dutta, Dibyendu] ISRO, Reg Remote Sensing Ctr East, NRSC, Kolkata, India.
   [Kundu, Ahana; Chaki, Nabendu] Univ Calcutta, Dept Comp Sci & Engn, Kolkata, India.
   [Jha, C. S.] ISRO, Reg Ctr, NRSC, Hyderabad, India.
C3 Department of Space (DoS), Government of India; Indian Space Research
   Organisation (ISRO); National Remote Sensing Centre (NRSC); University
   of Calcutta; Department of Space (DoS), Government of India; Indian
   Space Research Organisation (ISRO); National Remote Sensing Centre
   (NRSC)
RP Paul, A (corresponding author), ISRO, Reg Remote Sensing Ctr East, NRSC, Kolkata, India.
EM aratipaul@yahoo.com
RI CHAKI, NABENDU/A-5869-2015
OI Paul, Arati/0000-0003-0422-5656; Kundu, Ahana/0000-0002-2150-7359
CR Alsaiari A, 2019, 2019 IEEE 2ND INTERNATIONAL CONFERENCE ON INFORMATION AND COMPUTER TECHNOLOGIES (ICICT), P126, DOI [10.1109/INFOCT.2019.8710893, 10.1109/infoct.2019.8710893]
   Burger H., 2012, CVPR
   CHEN C, 2018, INFORM SWITZERLAND
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fan LW, 2019, VIS COMPUT IND BIOME, V2, DOI 10.1186/s42492-019-0016-7
   Garg V. K, 2007, Wireless Communications Networking, P85
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   GUAN J, 2019, IEEE ACCESS
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kheradmand A, 2014, IEEE T IMAGE PROCESS, V23, P5136, DOI 10.1109/TIP.2014.2362059
   Kuang XD, 2017, IEEE PHOTONICS J, V9, DOI 10.1109/JPHOT.2017.2717948
   Liu X, 2019, IEEE INT GEOSCI REMO, DOI 10.1109/IGARSS.2019.8900642
   LU X, 2021, IEEE T CIRCUITS SYST
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P2228, DOI 10.1109/TPAMI.2020.3040258
   Maffei A, 2020, IEEE T GEOSCI REMOTE, V58, P2516, DOI 10.1109/TGRS.2019.2952062
   Paul Arati, 2020, Advanced Computing and Systems for Security. Volume Twelve. Advances in Intelligent Systems and Computing (AISC 1136), P11, DOI 10.1007/978-981-15-2930-6_2
   Paul A., 2021, ANN DATA SCI, V8, P261, DOI [10.1007/s40745-019-00210-x, DOI 10.1007/S40745-019-00210-X]
   Paul AN, 2021, NEURAL COMPUT APPL, V33, P16345, DOI 10.1007/s00521-021-06233-x
   Paul A, 2022, GEOCARTO INT, V37, P2312, DOI 10.1080/10106049.2020.1822929
   Paul A, 2021, EVOL INTELL, V14, P1793, DOI 10.1007/s12065-020-00460-2
   Paul A, 2019, PATTERN RECOGN IMAGE, V29, P72, DOI 10.1134/S1054661819010085
   Paul A, 2015, GISCI REMOTE SENS, V52, P643, DOI 10.1080/15481603.2015.1075180
   QUESADA P, 2016, IMAGE SIGNAL PROCESS
   Rasti B, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030482
   Reddy ASB, 2019, INT C COMM SIGN PROC, DOI 10.1109/ICCSP.2019.8697909
   RONNEBERGAR O, 2015, U NET CONVOLUTIONAL
   Sagar GV, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P444, DOI 10.1109/ICIIP.2015.7414814
   SHAN W, 2019, IEEE ACCESS
   Sharma A, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P293, DOI 10.1109/CISP.2013.6744005
   Song Y, 2019, IEEE SENSOR, DOI 10.1109/sensors43011.2019.8956667
   SU H, 2014, IEEE J-STARS
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   TSAI F, 2008, IEEE T GEOSCI ELECT
   Vidal M, 2012, CHEMOMETR INTELL LAB, V117, P138, DOI 10.1016/j.chemolab.2012.05.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao F, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.749
   Xiao PF, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2854303
   Xie Junyuan, 2012, ADV NEURAL INFORM PR, P341, DOI [DOI 10.5555/2999134.2999173, DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605]
   XIE W, 2018, NEUROCOMPUTING
   Xie WY, 2017, IEEE GEOSCI REMOTE S, V14, P1963, DOI 10.1109/LGRS.2017.2743738
   Xu J, 2019, ARXIV190606878V3CSCV
   Yang H, 2012, INT C COMP COMP TECH, DOI 10.1007/978-3-642-27278-3_47
   YUAN Q, 2018, IEEE T GEOSCI ELECT
   Zhang JJ, 2020, PHOTOGRAMM REC, V35, P357, DOI 10.1111/phor.12328
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
   Zhang Q, 2019, IEEE T GEOSCI REMOTE, V57, P7317, DOI 10.1109/TGRS.2019.2912909
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 53
TC 13
Z9 14
U1 2
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2529
EP 2555
DI 10.1007/s11042-021-11689-z
EA OCT 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000713070300002
DA 2024-07-18
ER

PT J
AU Zhu, XY
   Song, XF
   Min, XK
   Zhou, HF
   Sun, W
   Wang, J
   Zhai, GT
AF Zhu, Xiangyang
   Song, Xuefei
   Min, Xiongkuo
   Zhou, Huifang
   Sun, Wei
   Wang, Jia
   Zhai, Guangtao
TI Calculation of ophthalmic diagnostic parameters on a single eye image
   based on deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ophthalmic measurement; CNN; Medical image processing; Object detection
ID PUPIL LOCALIZATION; IRIS; RECOGNITION
AB It is necessary to manually measure many parameters of eyes when an ophthalmologist diagnoses, which is time consuming, unsanitary, subjective and unrepeatable. Those manually achieved parameters often risk clinical trials in challenges on objectivity, resulting in unreliable clinical conclusions. We designed a two-phase algorithm to automatically measure these parameters instead of manual measurement to facilitate the diagnosis procedure of ptosis, eyelid retraction and other eye pathologies. Firstly, cornea, sclera, and internal and external canthus were identified using a multi-task convolutional neural network (CNN). Then we used the identification results to calculate a series of eye parameters needed in clinic. Totally 9 widely accepted parameters were calculated, including the height of ocular fissure, the longitudinal and transverse diameters of cornea, etc. The experimental results showed that most of parameters had achieved good accuracy, and most errors were less than 2 mm. We found that our approach can improve the measurements accuracy of eyelid, conjunctiva, cornea, sclera, and internal and external canthus, and promote efficiency and efficacy of relative clinical researches.
C1 [Zhu, Xiangyang; Min, Xiongkuo; Sun, Wei; Wang, Jia; Zhai, Guangtao] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, 800 Dong Chuan Rd, Shanghai, Peoples R China.
   [Song, Xuefei; Zhou, Huifang] Shanghai Jiao Tong Univ, Shanghai Peoples Hosp 9, Sch Med, 639 Zhi Zao Ju Rd, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University; Shanghai Jiao Tong University
RP Zhu, XY (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, 800 Dong Chuan Rd, Shanghai, Peoples R China.
EM zhuxy_sjtu_m@sjtu.edu.cn
RI zhu, y x/IVU-7833-2023; 朱, 欣妍/JZD-6639-2024; zhu, xin/JXN-3188-2024;
   Zhai, Guangtao/X-5949-2019; Sun, Weijie/GLU-8735-2022; Min,
   Xiongkuo/A-7097-2019
OI Zhai, Guangtao/0000-0001-8165-9322; Sun, Weijie/0000-0003-0112-0461;
   Min, Xiongkuo/0000-0001-5693-0416; Song, Xuefei/0000-0002-5666-6894
CR Abate AF, 2015, PATTERN RECOGN LETT, V57, P43, DOI 10.1016/j.patrec.2014.10.017
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Chen CJ, 2018, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW.2018.00011
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Das AK, 2016, IEEE INT FUZZY SYST, P2501, DOI 10.1109/FUZZ-IEEE.2016.7738008
   Das S, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P232, DOI [10.1109/ASPCON49795.2020.9276718, 10.1109/aspcon49795.2020.9276718]
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   de Castro A, 2018, INVEST OPHTH VIS SCI, V59, P897, DOI 10.1167/iovs.17-23596
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   Gao XT, 2015, IEEE T BIO-MED ENG, V62, P2693, DOI 10.1109/TBME.2015.2444389
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Jayanthi J, 2021, J AMB INTEL HUM COMP, V12, P3271, DOI 10.1007/s12652-020-02172-y
   Kerrigan D, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987299
   Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lucio D.R., 2018, P 2018 IEEE INT C BI, V2225, P1
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Petros R, 2016, PSYCHIAT QUART, V87, P417, DOI 10.1007/s11126-015-9397-8
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rot P, 2020, ADV COMPUT VIS PATT, P395, DOI 10.1007/978-3-030-27731-4_13
   Setio AAA, 2016, IEEE T MED IMAGING, V35, P1160, DOI 10.1109/TMI.2016.2536809
   Severo E, 2018, IEEE IJCNN
   Susitha N, 2019, COGN SYST RES, V57, P78, DOI 10.1016/j.cogsys.2018.09.029
   Thakker Manoj M, 2002, Ophthalmol Clin North Am, V15, P101, DOI 10.1016/S0896-1549(01)00005-0
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Wang CY, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987270
   Wang C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3670
   Wood E, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P131, DOI 10.1145/2857491.2857492
   Yang P, 2004, IEEE IMAGE PROC, P67
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
NR 40
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 2311
EP 2331
DI 10.1007/s11042-021-11047-z
EA OCT 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000711317800001
DA 2024-07-18
ER

PT J
AU Wang, B
   Peng, Q
   Wang, ER
   Xiang, W
   Wu, X
AF Wang, Bing
   Peng, Qiang
   Wang, Eric
   Xiang, Wei
   Wu, Xiao
TI User-dependent interactive light field video streaming system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light field video; Video compression; Video transmission; Prediction
   structure; User dependent
ID MULTIVIEW
AB The sheer size and complex structure of light field (LF) videos bring new challenges to their compression and transmission. There have been numerous LF video compression algorithms reported in the literature to date. All of these algorithms compress and transmit all the views of an LF video. However, in some interactive or selective applications where users can choose the area of interest to be displayed, these algorithms generate a significant computational load and enormous data redundancies. In this paper, we propose an interaUser-dependent Interactive light field video streaming system eaming system based on a user-dependent view selection scheme and an LF video coding method, which streams only the required data. Specifically, by predicting trajectories and using projection models, the viewing area of users in a limited consecutive number of time slots is firstly calculated, and then a user-dependent view selection method is proposed to determine the selected views of users for streaming. Finally, with the novel LF video sequence formed by only the selected sets of views, an adaptive coding method is presented for different LF video sequences based on users' gestures. Experimental results illustrate that the proposed interactive LF video streaming system can achieve the best performance compared with other comparison methods.
C1 [Wang, Bing; Peng, Qiang; Wu, Xiao] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
   [Wang, Eric] James Cook Univ, Sch Sci & Engn, Cairns, Qld 4878, Australia.
   [Xiang, Wei] La Trobe Univ, Sch Engn & Math Sci, Melbourne, Vic 3686, Australia.
C3 Southwest Jiaotong University; James Cook University; La Trobe
   University
RP Wang, B (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
RI Xiang, Wei/C-6765-2009
OI Xiang, Wei/0000-0002-0608-065X
FU China Scholarship Council (CSC) [201707000093]
FX Thanks are due to Dr. Pan Gao for assistance with the experiments and
   paper revision. In addition, the work of Bing Wang was partially
   supported by the China Scholarship Council (CSC) under Grant
   201707000093.
CR Avramelos V, 2020, MULTIMED TOOLS APPL, V79, P12847, DOI 10.1007/s11042-019-08605-x
   Bakir N, 2018, IEEE IMAGE PROC, P1128, DOI 10.1109/ICIP.2018.8451597
   Bjontegaard G, 2001, VCEGM33
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Dai F, 2015, IEEE IMAGE PROC, P4733, DOI 10.1109/ICIP.2015.7351705
   Fecker Ulrich, 2005, 2005 13th European Signal Processing Conference, P1
   Jia CM, 2019, IEEE J EM SEL TOP C, V9, P177, DOI 10.1109/JETCAS.2018.2886642
   Khoury J, 2019, INT CONF COMPUT NETW, P588, DOI [10.1109/ICCNC.2019.8685526, 10.1109/iccnc.2019.8685526]
   Kovacs P. T., 2014, 3DTV C TRUE VIS CAPT, P1
   Kurutepe E, 2007, IEEE T CIRC SYST VID, V17, P1558, DOI 10.1109/TCSVT.2007.903664
   Lafruit G., 2016, ELECT IMAGING, P1, DOI DOI 10.2352/ISSN.2470-1173.2016.5.SDA-426
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   Li L, 2017, IEEE J-STSP, V11, P1107, DOI 10.1109/JSTSP.2017.2725198
   Liu D, 2016, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2016.7574674
   Mehajabin N, 2019, IEEE IMAGE PROC, P3567, DOI [10.1109/icip.2019.8803668, 10.1109/ICIP.2019.8803668]
   Merkle P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1717, DOI 10.1109/ICME.2006.262881
   Ng R, 2005, RES REPORT, DOI DOI 10.1145/3097571
   Pan ZY, 2011, IEEE ICC
   Peixoto E, 2018, IEEE IMAGE PROC, P3289, DOI 10.1109/ICIP.2018.8451748
   Peixoto E, 2017, IEEE IMAGE PROC, P1925, DOI 10.1109/ICIP.2017.8296617
   Perra C, 2016, 2016 24TH TELECOMMUNICATIONS FORUM (TELFOR), P917
   Perwass C, 2012, PROC SPIE, V8291, DOI 10.1117/12.909882
   Ramanathan, 2005, THESIS STANDFORD U
   Tech G, 2016, IEEE T CIRC SYST VID, V26, P35, DOI 10.1109/TCSVT.2015.2477935
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang B, 2019, IEEE ACCESS, V7, P41183, DOI 10.1109/ACCESS.2019.2907572
   Wang G, 2016, IEEE T IMAGE PROCESS, V25, P5104, DOI 10.1109/TIP.2016.2603602
   Wang GK, 2016, COMPUT METH PROG BIO, V125, P103, DOI 10.1016/j.cmpb.2015.11.002
   Wang TY, 2017, ACTA OCEANOL SIN, V36, P1, DOI 10.1007/s13131-017-0987-1
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Zhao S, 2016, 2016 VISUAL COMMUNIC, P1, DOI [DOI 10.1109/ICME.2016.7552952., DOI 10.1109/INEC.2016.7589349]
   Zhao SY, 2017, IEEE IMAGE PROC, P4562, DOI 10.1109/ICIP.2017.8297146
   Zhao ZH, 2018, IEEE INT CON MULTI
NR 33
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 2
BP 1893
EP 1918
DI 10.1007/s11042-021-11602-8
EA OCT 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YP0UV
UT WOS:000707534600001
DA 2024-07-18
ER

PT J
AU Yadav, SK
   Sharma, K
   Kumar, C
   Arora, A
AF Yadav, Sumit Kumar
   Sharma, Kavita
   Kumar, Chanchal
   Arora, Arushi
TI Blockchain-based synergistic solution to current cybersecurity
   frameworks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; Cryptocurrency; Artificial neural network; Cloud computing;
   Smart contracts; Ethereum
ID NETWORK ARCHITECTURE; SMART CONTRACTS; CYBER SECURITY; INTERNET;
   ATTACKS; FUTURE; MODEL
AB Securing the network is a top priority for all organizations. Many high-profile breaches in the field of cybersecurity claim to threaten the global economy. In addition to that, they impose a threat for system infiltration and data theft, clearly warning organizations and companies to strengthen the existing cybersecurity frameworks and policies. In this paper, a real-time blockchain based integrated solution is proposed that fortifies the security against cyber-attacks. The scheme introduces the concept of Cyber-Soldiers that work together to update the Artificial Neural Network (ANN) based framework, which exists on the cloud for incentives. The enterprises can subscribe to this scheme monthly. This research work introduces its cryptocurrency CyberCent for the network. Also, smart contracts are deployed on the conditionally public blockchain to carry out monetary transactions. The experimental analysis with state-of-art compression of the framework is also demonstrated in the paper.
C1 [Yadav, Sumit Kumar] Income Tax Dept, Delhi, India.
   [Sharma, Kavita] GL Bajaj Inst Technol & Management, Dept Comp Sci & Engn, Greater Noida, India.
   [Kumar, Chanchal] Jamia Millia Islamia, Dept Comp Engn, New Delhi, India.
   [Arora, Arushi] Purdue Univ, W Lafayette, IN 47907 USA.
C3 Jamia Millia Islamia; Purdue University System; Purdue University
RP Sharma, K (corresponding author), GL Bajaj Inst Technol & Management, Dept Comp Sci & Engn, Greater Noida, India.
EM sumitarya007@gmail.com; kavitasharma_06@yahoo.co.in;
   kumarchanchal943@gmail.com; arora105@purdue.edu
RI Arora, Arushi/JED-6932-2023
CR Amarasinghe N, 2019, PROCEEDINGS OF THE AUSTRALASIAN COMPUTER SCIENCE WEEK MULTICONFERENCE (ACSW 2019), DOI 10.1145/3290688.3290693
   Amini M, 2006, COMPUT SECUR, V25, P459, DOI 10.1016/j.cose.2006.05.003
   Latif RAM, 2022, MULTIMED TOOLS APPL, V81, P26609, DOI 10.1007/s11042-020-10087-1
   [Anonymous], 2019, BUSINESS TRANSFORMAT, DOI 10.1007/978-3-319-99058-3_3
   Arora Arushi, 2019, Proceedings of 2nd International Conference on Communication, Computing and Networking. ICCCN 2018. Lecture Notes in Networks and Systems (LNNS 46), P233, DOI 10.1007/978-981-13-1217-5_23
   Arora A., 2018, P 3 INT C INT THINGS, P26
   Arora A., 2018, Handbook of Research on Network Forensics and Analysis Techniques, P117, DOI DOI 10.4018/978-1-5225-4100-4.CH008
   Azaria A, 2016, PROCEEDINGS 2016 2ND INTERNATIONAL CONFERENCE ON OPEN AND BIG DATA - OBD 2016, P25, DOI 10.1109/OBD.2016.11
   Buczak AL, 2016, IEEE COMMUN SURV TUT, V18, P1153, DOI 10.1109/COMST.2015.2494502
   Carpenter SG, 2017, United States patent, Va, Patent No. [15/001,073, 15001073]
   Choo KKR, 2018, IEEE T IND INFORM, V14, P3567, DOI 10.1109/TII.2018.2841049
   Christidis K, 2016, IEEE ACCESS, V4, P2292, DOI 10.1109/ACCESS.2016.2566339
   Dave D., 2018, Big Data Analytics, P499, DOI DOI 10.1007/978-981-10-6620-7_48
   Demirkan S, 2020, J MANAG ANAL, V7, P189, DOI 10.1080/23270012.2020.1731721
   Ding DR, 2017, IEEE T CYBERNETICS, V47, P1936, DOI 10.1109/TCYB.2016.2582802
   Dorri Ali, 2017, 2017 IEEE International Conference on Pervasive Computing and Communications Workshops (PerCom Workshops), P618, DOI 10.1109/PERCOMW.2017.7917634
   Feng Tian, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538424
   Gan CQ, 2021, MULTIMED TOOLS APPL, V80, P30605, DOI 10.1007/s11042-020-09322-6
   Hackius Niels, 2017, DIGITALIZATION SUPPL, V23, P3, DOI DOI 10.15480/882.1444
   Huh S, 2017, INT CONF ADV COMMUN, P464, DOI 10.23919/ICACT.2017.7890132
   Isozaki Y, 2016, IEEE T SMART GRID, V7, P1824, DOI 10.1109/TSG.2015.2427380
   Jalili R, 2005, LECT NOTES COMPUT SC, V3439, P192
   Khari M, 2017, ADV INF SECUR PRIV, P177, DOI 10.4018/978-1-5225-2154-9.ch013
   Kim H, 2019, MULTIMED TOOLS APPL, V78, P3153, DOI 10.1007/s11042-018-5897-5
   Laurie B., 2004, PROOF OF WORK PROVES
   Li ZT, 2018, IEEE T IND INFORM, V14, P3690, DOI 10.1109/TII.2017.2786307
   Liang XP, 2017, IEEE ACM INT SYMP, P468, DOI 10.1109/CCGRID.2017.8
   Liu B, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P468, DOI 10.1109/ICWS.2017.54
   Liu S, 2016, NEUROCOMPUTING, V207, P708, DOI 10.1016/j.neucom.2016.05.060
   Liu Y, 2015, PROCEEDINGS OF THE 24TH USENIX SECURITY SYMPOSIUM, P1009
   Lucia W, 2016, 2016 SCIENCE OF SECURITY FOR CYBER-PHYSICAL SYSTEMS WORKSHOP (SOSCYPS)
   MacDonald TJ, 2016, NEW ECON WINDOWS, P279, DOI 10.1007/978-3-319-42448-4_14
   Malik Nisha, 2018, 2018 17th IEEE International Conference On Trust, Security And Privacy In Computing And Communications/ 12th IEEE International Conference On Big Data Science And Engineering (TrustCom/BigDataSE). Proceedings, P674, DOI 10.1109/TrustCom/BigDataSE.2018.00099
   Mallikarjuna B, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12778
   Mousavian S, 2018, IEEE T SMART GRID, V9, P6160, DOI 10.1109/TSG.2017.2705188
   Mukhopadhyay Ujan, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P745, DOI 10.1109/PST.2016.7906988
   Nakamoto S., 2008, DECENT BUS REV, V21260, DOI https://bitcoin.org/bitcoin.pdf
   Page J., 2017, Journal of Data Protection Privacy, V1, P173
   Peters GW, 2016, NEW ECON WINDOWS, P239, DOI 10.1007/978-3-319-42448-4_13
   Pramanik BK, 2020, MULTIMED TOOLS APPL, V79, P9785, DOI 10.1007/s11042-019-08341-2
   Restuccia F., 2019, BLOCKCHAIN INTERNET
   Ron D., 2013, P INT C FIN CRYPT DA, P6
   Roy S, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON NETWORKING, SYSTEMS AND SECURITY (NSYSS), P84
   Sawa T, 2019, ELECTR ENG JPN, V206, P11, DOI 10.1002/eej.23167
   Scott Brett., 2016, How Can Cryptocurrency and Blockchain Technology Play a Role in Building Social and Solidarity Finance?
   Sharma PK, 2018, FUTURE GENER COMP SY, V86, P650, DOI 10.1016/j.future.2018.04.060
   Sharma PK, 2017, J INF PROCESS SYST, V13, P184
   Shrivastava G., 2018, HDB RES NETWORK FORE
   Shrivastava G., 2020, CRYPTOCURRENCIES BLO, DOI [10.1002/9781119621201, DOI 10.1002/9781119621201]
   Shrivastava G, 2020, IEEE T COMPUT SOC SY, V7, P1159, DOI 10.1109/TCSS.2020.3014135
   Tapscott A., 2017, HARVARD BUS REV, V1, P2
   Ten CW, 2010, IEEE T SYST MAN CY A, V40, P853, DOI 10.1109/TSMCA.2010.2048028
   Yeom S, 2021, MULTIMED TOOLS APPL, V80, P34085, DOI 10.1007/s11042-019-08583-0
   Zhang F, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P270, DOI 10.1145/2976749.2978326
   Zhang L, 2019, VEH COMMUN, V16, P85, DOI 10.1016/j.vehcom.2019.03.003
   Zyskind G, 2015, 2015 IEEE SECURITY AND PRIVACY WORKSHOPS (SPW), P180, DOI 10.1109/SPW.2015.27
NR 56
TC 5
Z9 5
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2022
VL 81
IS 25
BP 36623
EP 36644
DI 10.1007/s11042-021-11465-z
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 4W1TT
UT WOS:000696465800007
DA 2024-07-18
ER

PT J
AU Sun, ZQ
   Wang, CL
   Tian, EG
   Yin, Z
AF Sun Zhanquan
   Wang Chaoli
   Tian Engang
   Yin Zhong
TI ECG signal classification via combining hand-engineered features with
   deep neural network features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ECG; Automatic classification; Deep learning; Feature selection; Mutual
   information
ID FEATURE-EXTRACTION; FIBRILLATION; EFFICIENT; DESIGN
AB The electrocardiogram (ECG) has been proven to be the most common and effective approach to investigate cardiovascular diseases because that it is simple, noninvasive and inexpensive. However, the differences among ECG signals are difficult to be distinguished. In this paper, hand-engineered ECG features and automatic ECG features extracted with deep neural networks are combined to generate high dimensional features. First, rich hand-engineered features were extracted using some extraction methods for common ECG features. Second, a convolutional neural network model was designed to extract the ECG features automatically. High dimensional feature set is obtained through combing hand-engineered features and automatic features. To get the most informative ECG feature combination, a feature selection method based on mutual information was proposed. An ensemble learning method was then used to build the classification model for abnormal ECG types. Six atrial arrhythmia subtypes' ECG signals from the Chinese cardiovascular disease database dataset were analyzed through the proposed method. The precision of the classification results reaches 98.41%, which is higher than the results based on other current methods.
C1 [Sun Zhanquan; Wang Chaoli; Tian Engang; Yin Zhong] Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Engn Res Ctr Opt Instrument & Syst, Minist Educ, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Sun, ZQ (corresponding author), Univ Shanghai Sci & Technol, Shanghai Key Lab Modern Opt Syst, Engn Res Ctr Opt Instrument & Syst, Minist Educ, Shanghai 200093, Peoples R China.
EM sunzhq@usst.edu.cn
FU Medical Engineering Cross Project of USST [10-21-302-413,
   10-202-302-424]; Natural Science Foundation of Shanghai [19ZR1436000];
   National Natural Science Foundation of China [61374040, 61703277];
   Shanghai Sailing Program [17YF1427000]
FX This paper was partially supported by Medical Engineering Cross Project
   of USST (10-21-302-413) and <BOLD>(</BOLD>10-202-302-424) and Natural
   Science Foundation of Shanghai (19ZR1436000), National Natural Science
   Foundation of China (61374040), National Natural Science Foundation of
   China (Grant No. 61703277) and the Shanghai Sailing Program (Grant No.
   17YF1427000).
CR Abdar M, 2019, MEASUREMENT, V146, P557, DOI 10.1016/j.measurement.2019.05.022
   Acharya UR, 2019, APPL INTELL, V49, P16, DOI 10.1007/s10489-018-1179-1
   Acharya UR, 2017, INFORM SCIENCES, V377, P17, DOI 10.1016/j.ins.2016.10.013
   Ai DN, 2015, EURASIP J ADV SIG PR, DOI 10.1186/s13634-015-0231-0
   Al Abdi RM, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P57, DOI 10.1109/CSPA.2018.8368685
   Al Rahhal MM, 2016, INFORM SCIENCES, V345, P340, DOI 10.1016/j.ins.2016.01.082
   Boonchuay K, 2017, PATTERN ANAL APPL, V20, P769, DOI 10.1007/s10044-016-0533-3
   Brüser C, 2013, IEEE J BIOMED HEALTH, V17, P162, DOI 10.1109/TITB.2012.2225067
   Chang S, 2020, J MENT HEALTH, V29, P33, DOI 10.1080/09638237.2018.1466046
   Fan RE, 2005, J MACH LEARN RES, V6, P1889
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gutta S, 2016, IEEE J BIOMED HEALTH, V20, P460, DOI 10.1109/JBHI.2015.2402199
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   Hesar HD, 2017, IEEE J BIOMED HEALTH, V21, P1581, DOI 10.1109/JBHI.2017.2706298
   Huang HF, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-72
   Ibn Hasan N, 2019, BIOMED SIGNAL PROCES, V52, P128, DOI 10.1016/j.bspc.2019.04.005
   Ibtehaz N, 2019, BIOMED SIGNAL PROCES, V49, P349, DOI 10.1016/j.bspc.2018.12.016
   Jin LP, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/6212684
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Labati RD, 2019, PATTERN RECOGN LETT, V126, P78, DOI 10.1016/j.patrec.2018.03.028
   Li HQ, 2016, CIRC SYST SIGNAL PR, V35, P1187, DOI 10.1007/s00034-015-0108-3
   Li PF, 2017, IEEE T BIO-MED ENG, V64, P78, DOI 10.1109/TBME.2016.2539421
   Li Z., 2017, NEURAL COMPUT APPL, V28, P5613
   Manikandan MS, 2014, HEALTHC TECHNOL LETT, V1, P40, DOI 10.1049/htl.2013.0019
   Pal S, 2009, IFMBE PROC, V23, P590
   Pan ZB, 2017, KNOWL-BASED SYST, V121, P142, DOI 10.1016/j.knosys.2017.01.021
   Park J, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0660-9
   Perryman AL, 2018, PHARM RES-DORDR, V35, DOI 10.1007/s11095-018-2439-9
   Poungponsri S, 2013, NEUROCOMPUTING, V117, P206, DOI 10.1016/j.neucom.2013.02.010
   Rad AB, 2017, IEEE T BIO-MED ENG, V64, P2411, DOI 10.1109/TBME.2017.2688380
   Rahman MZU, 2012, IEEE SENS J, V12, P566, DOI 10.1109/JSEN.2011.2111453
   Sahadat MN, 2014, IEEE ENG MED BIO, P1440, DOI 10.1109/EMBC.2014.6943871
   Shi HT, 2019, BIOMED SIGNAL PROCES, V51, P97, DOI 10.1016/j.bspc.2019.02.012
   Sucheta C., 2020, BIOMED SIGNAL PROCES, V63, P102194
   Tantawi MM, 2015, SIGNAL IMAGE VIDEO P, V9, P1271, DOI 10.1007/s11760-013-0568-5
   Velmurugan S, 2019, CLUSTER COMPUT, V22, P14219, DOI 10.1007/s10586-018-2273-1
   Wang G, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101824
   Zhang JW, 2012, INT J ARTIF INTELL T, V21, DOI 10.1142/S0218213012400209
   Zhang ZC, 2014, COMPUT BIOL MED, V46, P79, DOI 10.1016/j.compbiomed.2013.11.019
   Zhou FY, 2017, ARTIF INTELL MED, V79, P42, DOI 10.1016/j.artmed.2017.06.004
   Zou Y, 2015, IEEE T CIRCUITS-II, V62, P119, DOI 10.1109/TCSII.2014.2368619
NR 41
TC 3
Z9 3
U1 1
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2022
VL 81
IS 10
BP 13467
EP 13488
DI 10.1007/s11042-021-11523-6
EA SEP 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 0V4PU
UT WOS:000695102100002
DA 2024-07-18
ER

PT J
AU Yadav, S
   Mehra, A
   Rohmetra, H
   Ratnakumar, R
   Narang, P
AF Yadav, Sahil
   Mehra, Aryan
   Rohmetra, Honnesh
   Ratnakumar, Rahul
   Narang, Pratik
TI DerainGAN: Single image deraining using wasserstein GAN
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image deraining; Generative Adversarial Networks; Deep learning;
   Wasserstein Loss; Perceptual Loss
ID GENERATIVE ADVERSARIAL NETWORK; RAIN STREAKS; REMOVAL; QUALITY; MODEL
AB Rainy weather greatly affects the visibility of salient objects and scenes in the captured images and videos. The object/scene visibility varies with the type of raindrops, i.e. adherent rain droplets, streaks, rain, mist, etc. Moreover, they pose multifaceted challenges to detect and remove the raindrops to reconstruct the rain-free image for higher-level tasks like object detection, road segmentation etc. Recently, both Convolutional Neural Networks (CNN) and Generative Adversarial Network (GAN) based models have been designed to remove rain droplets from a single image by dealing with it as an image to image mapping problem. However, most of them fail to capture the complexities of the task, create blurry output, or are not time efficient. GANs are a prime candidate for solving this problem as they are extremely effective in learning image maps without harsh overfitting. In this paper, we design a simple yet effective 'DerainGAN' framework to achieve improved deraining performance over the existing state-of-the-art methods. The learning is based on a Wasserstein GAN and perceptual loss incorporated into the architecture. We empirically analyze the effect of different parameter choices to train the model for better optimization. We also identify the strengths and limitations of various components for single image deraining by performing multiple ablation studies on our model. The robustness of the proposed method is evaluated over two synthetic and one real-world rainy image datasets using Peak Signal to Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM) values. The proposed DerainGAN significantly outperforms almost all state-of-the-art models in Rain100L and Rain700 datasets, both in semantic and visual appearance, achieving SSIM of 0.8201 and PSNR 24.15 in Rain700 and SSIM of 0.8701 and PSNR of 28.30 in Rain100L. This accounts for an average improvement of 10 percent in PSNR and 20 percent in SSIM over benchmarked methods. Moreover, the DerainGAN is one of the fastest methods in terms of time taken to process the image, giving it over 0.1 to 150 seconds of advantage in some cases.
C1 [Yadav, Sahil; Mehra, Aryan; Rohmetra, Honnesh; Narang, Pratik] BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
   [Ratnakumar, Rahul] MNIT, Dept ECE, Jaipur, Rajasthan, India.
   [Ratnakumar, Rahul] KNIT, Dept Elect Engn, Sultanpur, UP, India.
C3 Birla Institute of Technology & Science Pilani (BITS Pilani); National
   Institute of Technology (NIT System); Malaviya National Institute of
   Technology Jaipur; Kamla Nehru Institute of Technology Sultanpur
RP Narang, P (corresponding author), BITS Pilani, Dept CSIS, Pilani, Rajasthan, India.
EM pratik.narang@pilani.bits-pilani.ac.in
RI Mehra, Aryan/HPC-3885-2023
OI Ratnakumar, Rahul/0000-0002-2079-9062
FU BITS Additional Competitive Research Grant [PLN/AD/2018-19/5]; NVIDIA
   Corporation; IBM
FX This work is supported by BITS Additional Competitive Research Grant
   funding under Project Grant File no. PLN/AD/2018-19/5 for the Project
   titled "Disaster Monitoring from Aerial Imagery using Deep Learning".
   The authors gratefully acknowledge the support of NVIDIA Corporation for
   the donation of the Titan Xp GPU used in this research, and the support
   of IBM for providing with online Power9 GPU server grant.
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Awan N, 2021, IEEE ACCESS, V9, P26502, DOI 10.1109/ACCESS.2021.3056926
   Barnum PC, 2010, INT J COMPUT VISION, V86, P256, DOI 10.1007/s11263-008-0200-2
   Bi XJ, 2020, IEEE ACCESS, V8, P69838, DOI 10.1109/ACCESS.2020.2983436
   Bossu J, 2011, INT J COMPUT VISION, V93, P348, DOI 10.1007/s11263-011-0421-7
   Chen YL, 2013, IEEE I CONF COMP VIS, P1968, DOI 10.1109/ICCV.2013.247
   Cui YB, 2021, IET IMAGE PROCESS, V15, P2937, DOI 10.1049/ipr2.12280
   Deng LJ, 2018, APPL MATH MODEL, V59, P662, DOI 10.1016/j.apm.2018.03.001
   Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84
   Fu XY, 2020, IEEE T NEUR NET LEAR, V31, P1794, DOI 10.1109/TNNLS.2019.2926481
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Fu XY, 2017, IEEE T IMAGE PROCESS, V26, P2944, DOI 10.1109/TIP.2017.2691802
   Garg K, 2005, IEEE I CONF COMP VIS, P1067
   GARG K, 2004, PROC CVPR IEEE, P528, DOI DOI 10.1109/CVPR.2004.1315077
   Garg K, 2006, ACM T GRAPHIC, V25, P996, DOI 10.1145/1141911.1141985
   Gu SH, 2017, IEEE I CONF COMP VIS, P1717, DOI 10.1109/ICCV.2017.189
   Hang RL, 2021, IEEE T GEOSCI REMOTE, V59, P1424, DOI 10.1109/TGRS.2020.3003341
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jin X, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107143
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim JH, 2015, IEEE T IMAGE PROCESS, V24, P2658, DOI 10.1109/TIP.2015.2428933
   Kim JH, 2013, IEEE IMAGE PROC, P914, DOI 10.1109/ICIP.2013.6738189
   King DB, 2015, ACS SYM SER, V1214, P1
   Kwok Tai Chui, 2020, IEEE Access, V8, P86745, DOI 10.1109/ACCESS.2020.2992869
   LeCun Y., 1995, The handbook of brain theory and neural networks, V3361, DOI [10.5555/303568.303704, DOI 10.5555/303568.303704]
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li SL, 2019, PROC CVPR IEEE, P11919, DOI 10.1109/CVPR.2019.01220
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li Y, 2016, PROC CVPR IEEE, P2736, DOI 10.1109/CVPR.2016.299
   Luo Y, 2015, IEEE I CONF COMP VIS, P3397, DOI 10.1109/ICCV.2015.388
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mehra A, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103137
   Mehta A, 2021, IEEE WINT CONF APPL, P413, DOI 10.1109/WACV48630.2021.00046
   Mehta A, 2020, IEEE COMPUT SOC CONF, P846, DOI 10.1109/CVPRW50498.2020.00114
   Qian R, 2018, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR.2018.00263
   Radford A., 2015, ARXIV
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Ren Y, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061591
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schaefer G, 2004, PROC SPIE, V5307, P472, DOI 10.1117/12.525375
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha H, 2021, AAAI CONF ARTIF INTE, V35, P15895
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Wang C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2517, DOI 10.1145/3394171.3413559
   Wang YT, 2021, IEEE T NEUR NET LEAR, V32, P3664, DOI 10.1109/TNNLS.2020.3015897
   Wang YL, 2020, IEEE ACCESS, V8, P54802, DOI 10.1109/ACCESS.2020.2981643
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xianhui Zheng, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P258, DOI 10.1007/978-3-642-42051-1_33
   Xu B, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/832093
   Yang W., 2017, PROC CVPR IEEE, P1685, DOI DOI 10.1109/CVPR.2017.183
   Yasarla R, 2020, IEEE T IMAGE PROCESS, V29, P4544, DOI 10.1109/TIP.2020.2973802
   Zhang D, 2019, ADV NEUR IN, V32
   Zhang H, 2020, IEEE T CIRC SYST VID, V30, P3943, DOI 10.1109/TCSVT.2019.2920407
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang H, 2017, IEEE WINT CONF APPL, P1259, DOI 10.1109/WACV.2017.145
   Zhang Z, 2017, INT JOINT C ART INT
   Zheng Q, 2019, IEEE IMAGE PROC, P2766, DOI [10.1109/ICIP.2019.8803225, 10.1109/icip.2019.8803225]
   Zhu L, 2017, IEEE I CONF COMP VIS, P2545, DOI 10.1109/ICCV.2017.276
NR 63
TC 8
Z9 8
U1 6
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2021
VL 80
IS 30
BP 36491
EP 36507
DI 10.1007/s11042-021-11442-6
EA SEP 2021
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XI4QI
UT WOS:000693494700004
DA 2024-07-18
ER

PT J
AU Zheng, Y
   Zhou, Y
   Zhao, JQ
   Jian, M
   Yao, R
   Liu, B
   Chen, Y
AF Zheng, Yi
   Zhou, Yong
   Zhao, Jiaqi
   Jian, Meng
   Yao, Rui
   Liu, Bing
   Chen, Ying
TI A siamese pedestrian alignment network for person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Deep learning; Neural network; Verification
   loss; Feature learning
ID MULTIOBJECTIVE OPTIMIZATION
AB Deep learning methods show strong ability in extracting high-level features for images in the field of person re-identification. The produced features help inherently distinguish pedestrian identities in images. However, on deep learning models over-fitting and discriminative ability of the learnt features are still challenges for person re-identification. To alleviate model over-fitting and further enhance the discriminative ability of the learnt features, we propose siamese pedestrian alignment networks (SPAN) for person re-identification. SPAN employs two streams of PAN (pedestrian alignment networks) to increase the size of network inputs over limited training samples and effectively alleviate network over-fitting in learning. In addition, a verification loss is constructed between the two PANs to adjust the relative distance of two input pedestrians of the same or different identities in the learned feature space. Experimental verification is conducted on six large person re-identification data sets and the experimental results demonstrate the effectiveness of the proposed SPAN for person re-identification.
C1 [Zheng, Yi; Zhou, Yong; Zhao, Jiaqi; Yao, Rui; Liu, Bing; Chen, Ying] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zheng, Yi; Zhou, Yong; Zhao, Jiaqi; Yao, Rui; Liu, Bing; Chen, Ying] Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
   [Jian, Meng] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
C3 China University of Mining & Technology; Beijing University of
   Technology
RP Zhou, Y (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.; Zhou, Y (corresponding author), Minist Educ Peoples Republ China, Engn Res Ctr Mine Digitizat, Xuzhou 221116, Jiangsu, Peoples R China.
EM yzhou@cumt.edu.cn
FU Fundamental Research Funds for the Central Universities [2018XKQYMS27]
FX This work was supported by the Fundamental Research Funds for the
   Central Universities (No.2018XKQYMS27).
CR [Anonymous], 2015, PROC CVPR IEEE
   Bai S, 2017, AAAI CONF ARTIF INTE, P1281
   Cao JL, 2020, IEEE T IMAGE PROCESS, V29, P3143, DOI 10.1109/TIP.2019.2957927
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang G. B., 2012, NIPS
   Huang K, 2016, ARXIV160307054
   Huang Y, 2019, IEEE T IMAGE PROCESS, V28, P1391, DOI 10.1109/TIP.2018.2874715
   Karanam S., 2016, ARXIV PREPRINT ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Ma AJ, 2013, IEEE I CONF COMP VIS, P3567, DOI 10.1109/ICCV.2013.443
   Ma L., 2016, ARXIV160502464
   Pang YW, 2019, IEEE T INF FOREN SEC, V14, P3322, DOI 10.1109/TIFS.2019.2916592
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen Y, 2015, IEEE I CONF COMP VIS, P3200, DOI 10.1109/ICCV.2015.366
   Shi ZY, 2015, PROC CVPR IEEE, P4184, DOI 10.1109/CVPR.2015.7299046
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tan SB, 2018, IEEE T CIRC SYST VID, V28, P356, DOI 10.1109/TCSVT.2016.2555739
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang Y, 2016, AAAI CONF ARTIF INTE, P3655
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu R., 2017, BMVC
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhao JQ, 2018, APPL SOFT COMPUT, V67, P322, DOI 10.1016/j.asoc.2018.03.005
   Zhao JQ, 2016, INFORM SCIENCES, V367, P80, DOI 10.1016/j.ins.2016.05.026
   Zhedong Zheng, 2017, ACM Transactions on Multimedia Computing, Communications and Applications, V14, DOI 10.1145/3159171
   Zheng L, 2019, IEEE T IMAGE PROCESS, V28, P4500, DOI 10.1109/TIP.2019.2910414
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang, 2016, arXiv preprint arXiv
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
NR 59
TC 3
Z9 3
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33951
EP 33970
DI 10.1007/s11042-021-11302-3
EA AUG 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000691163100001
DA 2024-07-18
ER

PT J
AU Thiyagarajan, A
   Gunasekar, K
AF Thiyagarajan, Akila
   Gunasekar, Kumaragurubaran
TI An improved feature selection based classifier for prediction of
   different regions in sar images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Synthetic aperture radar (SAR); Satellite image processing; Pyramid
   histogram of oriented gradients; Principal component analysis; Random
   forest classifier
ID SUPERPIXEL SEGMENTATION; NEURAL-NETWORK
AB Satellite images play an essential role in various applications like geographical information systems, remote sensing, ecology, and oceanography. Synthetic Aperture Radar (SAR) imaging is used to achieve high-resolution images on earth. However, these images are positively affected by unnecessary noises by compression and transmission errors. The noise removal process is a challenging task that it had artefacts and blurring of images. Existing researches and studies proposed various de-noising techniques to improve the accuracy of these images, and that attains specific application. These techniques had not yet attained the high performances due to the inaccurate prediction of objects. The primary aim of this research is to enhance the classification accuracy of different regions like water region, residential area, land region, and forest region from SAR images. From input SAR images, the features are extracted by using proposed hybrid saliency mapping and pyramid histogram of oriented gradients. The most important features are selected by using the Improved Principal Component Analysis (IPCA) technique. Further, the classification of regions is achieved by using a novel forest classifier. The performance of the proposed framework ha analyzed with the measures of accuracy, specificity, sensitivity, precision, recall, and f-score. In the result analysis, the proposed method had achieved 98% of accuracy compared than the state-of-the-art algorithms. From the estimation results, it is concluded that the proposed approach offers better results with increased accuracy for the prediction of different objects in SAR images.
C1 [Thiyagarajan, Akila] King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
   [Gunasekar, Kumaragurubaran] Univ Strathclyde, Dept Engn, Glasgow, Lanark, Scotland.
C3 King Khalid University; University of Strathclyde
RP Thiyagarajan, A (corresponding author), King Khalid Univ, Dept Comp Sci, Abha, Saudi Arabia.
EM ajan@kku.edu.sa
CR Abburu S., 2015, Int. J. Comput. Appl, V119, P20, DOI [10.5120/21088-3779, DOI 10.5120/21088-3779]
   Adelabu S, 2015, GEOCARTO INT, V30, P457, DOI 10.1080/10106049.2014.885589
   Arisoy S, 2016, IEEE GEOSCI REMOTE S, V13, P1721, DOI 10.1109/LGRS.2016.2605583
   Baghi A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P229, DOI 10.1109/PRIA.2017.7983052
   Buono A, 2016, IEEE T GEOSCI REMOTE, V54, P5862, DOI 10.1109/TGRS.2016.2574561
   Chen JW, 2016, IEEE GEOSCI REMOTE S, V13, P1467, DOI 10.1109/LGRS.2016.2592503
   Chen L, 2020, REMOTE SENS LETT, V11, P807, DOI 10.1080/2150704X.2020.1773564
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Dellinger F, 2015, IEEE T GEOSCI REMOTE, V53, P453, DOI 10.1109/TGRS.2014.2323552
   Duan YP, 2017, PATTERN RECOGN, V64, P255, DOI 10.1016/j.patcog.2016.11.015
   Gao F, 2019, IEEE ACCESS, V7, P108617, DOI 10.1109/ACCESS.2019.2933459
   Gu J, 2016, IEEE J-STARS, V9, P1265, DOI 10.1109/JSTARS.2015.2502991
   Guan DD, 2018, IEEE GEOSCI REMOTE S, V15, P1035, DOI 10.1109/LGRS.2018.2821711
   Hou B, 2016, IEEE GEOSCI REMOTE S, V13, P33, DOI 10.1109/LGRS.2015.2493242
   Javed U, 2016, IEEE T AERO ELEC SYS, V52, P181, DOI 10.1109/TAES.2015.120817
   Kavzoglu T, 2017, HANDBOOK OF NEURAL COMPUTATION, P607, DOI 10.1016/B978-0-12-811318-9.00033-8
   Kohli D, 2016, J SPAT SCI, V61, P405, DOI 10.1080/14498596.2016.1138247
   Kumar RP, 2020, MACHINE LEARNING ML, V29, P231
   Li HC, 2015, IEEE GEOSCI REMOTE S, V12, P2458, DOI 10.1109/LGRS.2015.2484220
   Li HG, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010156
   Li MQ, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/4576015
   Li WJ, 2017, INT GEOSCI REMOTE SE, P846, DOI 10.1109/IGARSS.2017.8127085
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   Liu FQ, 2016, IEEE GEOSCI REMOTE S, V13, P242, DOI 10.1109/LGRS.2015.2507982
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   Lv N, 2018, IEEE T IND INFORM, V14, P5530, DOI 10.1109/TII.2018.2873492
   Persello C, 2017, IEEE GEOSCI REMOTE S, V14, P2325, DOI 10.1109/LGRS.2017.2763738
   Qin FC, 2015, IEEE GEOSCI REMOTE S, V12, P13, DOI 10.1109/LGRS.2014.2322960
   Quickbird, 2020, QUICKBIRD SATELLITE
   Rostami O, 2021, COMPUTAT GEOSCI, V25, P911, DOI 10.1007/s10596-020-10030-1
   Santi F, 2016, IEEE T GEOSCI REMOTE, V54, P6217, DOI 10.1109/TGRS.2016.2583784
   Shang RH, 2016, IEEE J-STARS, V9, P1640, DOI 10.1109/JSTARS.2016.2516014
   Traore BB, 2017, EXPERT SYST APPL, V72, P443, DOI 10.1016/j.eswa.2016.10.010
   Wang F, 2017, IEEE T GEOSCI REMOTE, V55, P537, DOI 10.1109/TGRS.2016.2611060
   Wang S., 2021, J Big Data, V3, P1, DOI [10.32604/jbd.2021.010364, DOI 10.32604/JBD.2021.010364, DOI 10.1186/S42825-020-00042-Z]
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhang ZM, 2017, IEEE T GEOSCI REMOTE, V55, P7177, DOI 10.1109/TGRS.2017.2743222
NR 40
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2021
VL 80
IS 25
BP 33641
EP 33662
DI 10.1007/s11042-021-11416-8
EA AUG 2021
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WK6LS
UT WOS:000687012300003
DA 2024-07-18
ER

PT J
AU Song, E
   Do, J
   Yu, S
AF Song, Eungyeol
   Do, Jinkyung
   Yu, Sunjin
TI Real-time low-cost human skeleton detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skeleton detection; CNNs; Human skeleton; Multi-stage CNN
AB The human skeleton or deep learning framework is useful for accurately recognizing human behavior and analyzing that behavior across different situations. This work introduces a low-cost human skeleton detection network for detecting human skeleton shapes in real time. The proposed network is divided into two parts: pattern extraction and multi-stage convolutional neural networks (CNNs). In the multi-stage CNN step, we use repeated stages, including two branches for the estimation of the heatmap and the part affinity fields (PAFs). In addition, the network consists of inverted bottleneck layers and separable convolutions to extract features efficiently. With test videos, our method achieved an average video analysis speed of approximately 10.45 fps, which is significantly higher than the value of 4.33 fps achieved by the OpenPose algorithm.
C1 [Song, Eungyeol; Do, Jinkyung] Codevision Inc, Res & Dev Dept, 50 Yonsei R, Seoul, South Korea.
   [Yu, Sunjin] Changwon Natl Univ, Dept Culture Technol, Chang Won, South Korea.
C3 Changwon National University
RP Yu, S (corresponding author), Changwon Natl Univ, Dept Culture Technol, Chang Won, South Korea.
EM song@codevision.kr; jkdo0923@gmail.com; sjyu@cwnu.ac.kr
OI Song, Eungyeol/0000-0002-5065-2969; Yu, Sunjin/0000-0001-9292-4099
FU Technology Innovation Program - Ministry of Trade, Industry & Energy
   (MOTIE, Korea) [20006697]
FX This work was supported by the Technology Innovation Program (20006697,
   multi sensor based artificial intelligence technology passenger
   recognition and air clean console for autonomous design companion animal
   family centered) funded By the Ministry of Trade, Industry & Energy
   (MOTIE, Korea).
CR Asadi-Aghbolaghi M, 2018, MULTIMED TOOLS APPL, V77, P14115, DOI 10.1007/s11042-017-5017-y
   Cao, 2017, PROC IEEE C COMPUT V
   Carrara F, 2019, MULTIMED TOOLS APPL, V78, P27309, DOI 10.1007/s11042-019-07827-3
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Donahue, 2015, PROC IEEE C COMPUT V
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HEILBRON FC, 2015, PROC CVPR IEEE, P961, DOI DOI 10.1109/CVPR.2015.7298698
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Iandola Forrest N, 2016, SQUEEZENET ALEXNET L
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B, 2018, MULTIMED TOOLS APPL, V77, P22901, DOI 10.1007/s11042-018-5642-0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
NR 22
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34389
EP 34402
DI 10.1007/s11042-021-11308-x
EA AUG 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000683216400001
DA 2024-07-18
ER

PT J
AU Yu, J
   Li, F
   Lv, XG
AF Yu, Jing
   Li, Fang
   Lv, Xiaoguang
TI Contrast preserving decolorization based on the weighted normalized L1
   norm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Decolorization; Contrast preserving; Contrast features; Weighted
   normalized L1 norm; Discrete searching solver
ID COLOR-TO-GRAY; IMAGE DECOLORIZATION; QUALITY ASSESSMENT; CONVERSION;
   MODEL
AB Image decolorization is to transform a color image into a grayscale image with the preserved contrast and consistent details. It is an important tool in image processing and realistic applications, such as monochrome printing and e-ink display. In this paper, we propose a novel contrast preserving method for image decolorization. Our main contribution is threefold: Firstly, we define a new contrast feature for a color image which combine the correlated information among R, G and B channels with the color contrast in each channel. Secondly, we propose to use the weighted normalized L1 norm to measure the distance between the grayscale image and the color image contrast features, and formulate an constrained optimization problem. Finally, we utilize a discrete searching solver to solve the optimization problem efficiently. The proposed decolorization method is good at preserving low contrast as well as high contrast structures in the color image. The objective and subjective evaluation on three benchmark datasets demonstrates that our decolorization method is effective and competitive with some state-of-the-art decolorization methods.
C1 [Yu, Jing; Li, Fang] East China Normal Univ, Sch Math Sci, Shanghai 200062, Peoples R China.
   [Li, Fang] East China Normal Univ, Shanghai Key Lab PMMP, Shanghai 200062, Peoples R China.
   [Lv, Xiaoguang] Jiangsu Ocean Univ, Sch Sci, Lianyungang 222005, Jiangsu, Peoples R China.
C3 East China Normal University; East China Normal University; Jiangsu
   Ocean University
RP Li, F (corresponding author), East China Normal Univ, Sch Math Sci, Shanghai 200062, Peoples R China.; Li, F (corresponding author), East China Normal Univ, Shanghai Key Lab PMMP, Shanghai 200062, Peoples R China.
EM 51195500058@stu.ecnu.edu.cn; fli@math.ecnu.edu.cn; xiaoguanglv@126.com
OI Li, Fang/0000-0001-6804-2651
FU National Natural Science Foundation of China (NSFC) [61731009,
   11671002]; Fundamental Research Funds for the Central Universities;
   Nature Science Foundation of Jiangsu Province [BK20181483]; Science and
   Technology Commission of Shanghai Municipality [19JC1420102,
   18dz2271000]
FX This work is supported in part by the National Natural Science
   Foundation of China (NSFC) (No. 61731009, No. 11671002), the Fundamental
   Research Funds for the Central Universities, Nature Science Foundation
   of Jiangsu Province (BK20181483), and Science and Technology Commission
   of Shanghai Municipality (No. 19JC1420102, No. 18dz2271000).
CR Ancuti Cosmin, 2019, 2019 IEEE International Conference on Image Processing (ICIP). Proceedings, P3242, DOI 10.1109/ICIP.2019.8803485
   Ancuti CO, 2011, LECT NOTES COMPUT SC, V6492, P79, DOI 10.1007/978-3-642-19315-6_7
   Ancuti CO, 2011, PROC CVPR IEEE, P257, DOI 10.1109/CVPR.2011.5995414
   Ancuti C, 2016, IEEE IMAGE PROC, P4107, DOI 10.1109/ICIP.2016.7533132
   Boyd S., 2006, Convex Optimization
   Brunet D, 2012, IEEE T IMAGE PROCESS, V21, P1488, DOI 10.1109/TIP.2011.2173206
   Cadík M, 2008, COMPUT GRAPH FORUM, V27, P1745
   Cai BL, 2018, IEEE IMAGE PROC, P2810, DOI 10.1109/ICIP.2018.8451303
   Chen H, 2019, IEEE INT CON MULTI, P1240, DOI 10.1109/ICME.2019.00216
   Du H, 2015, IEEE T IMAGE PROCESS, V24, P434, DOI 10.1109/TIP.2014.2380172
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   Grundland M, 2007, PATTERN RECOGN, V40, P2891, DOI 10.1016/j.patcog.2006.11.003
   Hou XX, 2018, IEEE ACCESS, V6, P49779, DOI 10.1109/ACCESS.2018.2868733
   Jin ZM, 2014, SIAM J IMAGING SCI, V7, P944, DOI 10.1137/130935197
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   Kim Y, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618507
   Liu CW, 2013, IEEE IMAGE PROC, P1105, DOI 10.1109/ICIP.2013.6738228
   Liu D, 2019, IEEE T AUTOM SCI ENG, V16, P668, DOI 10.1109/TASE.2018.2848635
   Liu QG, 2019, VISUAL COMPUT, V35, P205, DOI 10.1007/s00371-017-1464-8
   Liu QG, 2019, INFORM FUSION, V46, P114, DOI 10.1016/j.inffus.2018.05.007
   Liu QG, 2017, IEEE T IMAGE PROCESS, V26, P5772, DOI 10.1109/TIP.2017.2745104
   Liu QG, 2017, IEEE T CIRC SYST VID, V27, P1856, DOI 10.1109/TCSVT.2016.2555779
   Liu QG, 2017, MULTIMED TOOLS APPL, V76, P14055, DOI 10.1007/s11042-016-3748-9
   Liu QG, 2015, IEEE T IMAGE PROCESS, V24, P2889, DOI 10.1109/TIP.2015.2423615
   Liu SG, 2019, IEEE T MULTIMEDIA, V21, P2461, DOI 10.1109/TMM.2019.2903413
   Lotto RB, 1999, NAT NEUROSCI, V2, P1010, DOI 10.1038/14808
   Lu CW, 2014, INT J COMPUT VISION, V110, P222, DOI 10.1007/s11263-014-0732-6
   Ma KD, 2015, IEEE T IMAGE PROCESS, V24, P4673, DOI 10.1109/TIP.2015.2460015
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nafchi HZ, 2017, IEEE SIGNAL PROC LET, V24, P1651, DOI 10.1109/LSP.2017.2755077
   Qin L, 2012, 2012 IEEE FIFTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P1, DOI [10.1109/ICACI.2012.6463111, 10.1109/ICCH.2012.6724460]
   Shizume T, 2014, J SOC INF DISPLAY, V22, P588, DOI 10.1002/jsid.291
   Smith K, 2008, COMPUT GRAPH FORUM, V27, P193, DOI 10.1111/j.1467-8659.2008.01116.x
   Wang W, 2020, IEEE T IMAGE PROCESS, V29, P1776, DOI 10.1109/TIP.2019.2939946
   Wang W, 2018, IEEE T IMAGE PROCESS, V27, P5464, DOI 10.1109/TIP.2018.2855424
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang XL, 2018, VISUAL COMPUT, V34, P1099, DOI 10.1007/s00371-018-1524-8
NR 38
TC 6
Z9 6
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2021
VL 80
IS 21-23
BP 31753
EP 31782
DI 10.1007/s11042-021-11172-9
EA JUL 2021
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WD8WR
UT WOS:000674550000001
DA 2024-07-18
ER

PT J
AU Jose, A
   Subramanian, K
AF Jose, Asha
   Subramanian, Kamalraj
TI High-capacity reversible data hiding using quotient multi pixel value
   differencing scheme in encrypted images by fuzzy based encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; Information redundancy; Encryption; Texture classification
   and fuzzy-based group teaching
ID DECRYPTION; PROTECTION; SYSTEM
AB The Reversible data hiding (RDH) approach can retrieve the original image from the marked image without any distortion. RDH in encrypted images is an approach that hides extra information into the ciphertext using a skill of recovering the actual data losslessly. To guarantee reversibility for addressing the information redundancy drawback, the cover image pixels are copied into two images. This paper presents a high capacity RDH scheme in encrypted images using fuzzy-based encryption. Initially, the texture classification is processed by a convolutional neural network (CNN) to classify the dense and transparent region. It automatically identifies the significant features without any individual supervision. Then, the plain text encryption is activated by the fuzzy group teaching with infinite elliptic curve (FGTIE) method. To overcome the demerit of FCM, the GTA is hybrid with FCM approach and the encryption is processed by the IE method. Next, a new embedding approach is used to enhance the embedding capacity, namely quotient multi-pixel value differencing (QMPVD). In order to obtain the higher PSNR and payload, the multi-pixel differencing is hybrid with the quotient value differencing. Finally, the original data is extracted and recovered with good quality and high capacity. The performances are evaluated using several performance metrics such as PSNR, SSIM, BER, MSE, embedding capacity/payload, sensitivity, specificity, tampering ratio, correlation coefficient, number of pixel change rate and unified average changing intensity. The performance of PSNR and capacity is compared with existing approaches named Encrypted image-based RDH with Paillier cryptosystem (EIRDH-PC), EIRDH with Redundancy Transfer (EIRDH-RT) and EIRDH with pixel value ordering (EIRDH-PVO). The performance is calculated for three groups of images such as the brain, lungs and abdomen. The implementation results show that the introduced model attained better performance compared to existing approaches in terms of PSNR and capacity. Besides, the proposed approach achieved the merits of no pixel expansion, lossless and alternative order recovery.
C1 [Jose, Asha] Karpagam Univ, Karpagam Acad Higher Educ, Coimbatore, Tamil Nadu, India.
   [Subramanian, Kamalraj] Karpagam Acad Higher Educ, Dept Elect & Commun, Coimbatore, Tamil Nadu, India.
C3 Karpagam Academy of Higher Education (KAHE); Karpagam Academy of Higher
   Education (KAHE)
RP Jose, A (corresponding author), Karpagam Univ, Karpagam Acad Higher Educ, Coimbatore, Tamil Nadu, India.
EM ashajose07@gmail.com
CR Abd El-Latif AA, 2020, PHYSICA A, V541, DOI 10.1016/j.physa.2019.123687
   Ahmad J, 2018, COMPUT SCI ELECTR, P208, DOI 10.1109/CEEC.2018.8674208
   Amin M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3360179
   Bai L., 2019, J INFORM HIDING PRIV, V1, P1
   Belazi A, 2015, INT WIREL COMMUN, P606, DOI 10.1109/IWCMC.2015.7289152
   Benrhouma O, 2016, MULTIMED TOOLS APPL, V75, P8695, DOI 10.1007/s11042-015-2786-z
   Chen KM, 2019, MULTIMED TOOLS APPL, V78, P31441, DOI 10.1007/s11042-019-07946-x
   Guan B, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102744
   Hao JL, 2019, COMPUT NETW, V153, P1, DOI 10.1016/j.comnet.2019.02.008
   Horng JH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092739
   Jiang CL, 2020, MULTIMED TOOLS APPL, V79, P693, DOI 10.1007/s11042-019-07874-w
   Kaw JA, 2019, INT J INFORM MANAGE, V45, P262, DOI 10.1016/j.ijinfomgt.2018.09.008
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V155, P630, DOI 10.1016/j.procs.2019.08.089
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P584, DOI 10.1016/j.procs.2019.11.043
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P491, DOI 10.1016/j.procs.2019.11.059
   Kovalchuk A, 2019, PROCEDIA COMPUT SCI, V160, P503, DOI 10.1016/j.procs.2019.11.057
   Liang XK, 2020, MULTIMED TOOLS APPL, V79, P2719, DOI 10.1007/s11042-019-08295-5
   Liu SH, 2018, DISCRETE APPL MATH, V241, P48, DOI 10.1016/j.dam.2016.06.028
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Manikandan V. M., 2020, Procedia Computer Science, V171, P951, DOI 10.1016/j.procs.2020.04.103
   Migliardi M, 2018, 2018 32ND INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (WAINA), P559, DOI 10.1109/WAINA.2018.00144
   Ntahobari M, 2018, THESIS I TEKNOLOGI S
   Puteaux P, 2021, IEEE T MULTIMEDIA, V23, P636, DOI 10.1109/TMM.2020.2985537
   Qian ZX, 2014, IEEE T MULTIMEDIA, V16, P1486, DOI 10.1109/TMM.2014.2316154
   Qin C, 2019, INFORM SCIENCES, V487, P176, DOI 10.1016/j.ins.2019.03.008
   Qin C, 2015, J VIS COMMUN IMAGE R, V31, P154, DOI 10.1016/j.jvcir.2015.06.009
   Qiu YQ, 2020, SIGNAL PROCESS, V167, DOI 10.1016/j.sigpro.2019.107288
   Rosu M, 2007, MED PHYS, V34, P233, DOI 10.1118/1.2400624
   Sharma Sakshi, 2019, 2019 Third International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), P644, DOI 10.1109/I-SMAC47947.2019.9032554
   Shi H, 2018, MULTIMED TOOLS APPL, V77, P20535, DOI 10.1007/s11042-017-5446-7
   Singh P, 2018, INFORM SCIENCES, V422, P77, DOI 10.1016/j.ins.2017.08.077
   Sun YX, 2020, MULTIMED TOOLS APPL, V79, P27659, DOI 10.1007/s11042-020-08626-x
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Wang YM, 2021, IEEE T MULTIMEDIA, V23, P1466, DOI 10.1109/TMM.2020.2999187
   Xiao D, 2017, J VIS COMMUN IMAGE R, V45, P1, DOI 10.1016/j.jvcir.2017.02.001
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
   Yu MJ, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00502-w
   Zhang TJ, 2015, INT J SECUR APPL, V9, P217, DOI 10.14257/ijsia.2015.9.7.19
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 41
TC 2
Z9 2
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 29453
EP 29479
DI 10.1007/s11042-021-11122-5
EA JUN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000667012200001
DA 2024-07-18
ER

PT J
AU Hardiansyah, B
   Lu, Y
AF Hardiansyah, Bagus
   Lu, Yao
TI Single image super-resolution via multiple linear mapping anchored
   neighborhood regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Single image super-resolution (SR); Anchored neighborhood regression
   (ANR); Optimization principal component analysis (OPCA); Multiple linear
   mapping (MLM)
ID FACE SUPERRESOLUTION; HALLUCINATION; DICTIONARY
AB The goal of learning-based image super-resolution (SR) is to generate a plausible and visually high-resolution (HR) image from a single low-resolution (LR) input image. The SR is an important branch of image reconstruction that concentrates on the improvement of image resolution and the problem is severely underconstrained. It's to rely on examples or some strong image priors to reconstruct the missing HR image details. The paper addresses the problem of learning the mapping functions is, projection matrix between the LR and HR images based on a dictionary of LR and HR exemplars. In this paper, we present a self-learning single image SR method, which restores an HR image from self-examples extracted from the LR input image itself without relying on additional external training images. This paper proposes a novel computationally to further improve the SR performance of single image SR method that learns multiple linear mappings (MLM) based on SR method functions anchored neighborhood regression (ANR) to directly transform LR feature subspaces into HR subspaces. Moreover, we utilize segmentation flipped and rotated with a matrix-vector of the self-examples to expand the internal patch space. Furthermore, we set up MLM from the input LR features to the desire HR outputs to obtain stable. In particular, we improved SR efficiency using optimization principal component analysis (OPCA) based on dimensionality reduction to generate from low-dimensional into high-dimensional with matrix-vector patch space. For our proposed model, there are three regularization parameters analysis that require to optimize the training and refine the outcome. Experimental result indicates that our approach comparison on the standard benchmark with state-of-the-art method validation the effectiveness of our proposed.
C1 [Hardiansyah, Bagus; Lu, Yao] Beijing Inst Technol, Beijing, Peoples R China.
   [Hardiansyah, Bagus; Lu, Yao] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing, Peoples R China.
   [Hardiansyah, Bagus] Univ 17 Agustus 1945 Surabaya, Surabaya, Indonesia.
C3 Beijing Institute of Technology; Beijing Institute of Technology
RP Hardiansyah, B (corresponding author), Beijing Inst Technol, Beijing, Peoples R China.; Hardiansyah, B (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing, Peoples R China.; Hardiansyah, B (corresponding author), Univ 17 Agustus 1945 Surabaya, Surabaya, Indonesia.
EM bagus_hardian_syah@bit.edu.cn; vis_yl@bit.edu.cn
RI Hardiansyah, Bagus/GPG-3491-2022
FU National Nature Science Foundation of China [61273273]; National Key
   Research and Development Plan of China [2017YFC0112001]
FX This work was supported in part by the National Nature Science
   Foundation of China under Grant 61273273, and in part by the National
   Key Research and Development Plan of China under Grant 2017YFC0112001.
CR [Anonymous], 2008, ACM T GRAPHIC, DOI DOI 10.1145/1409060.1409106
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bevilacqua M, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.135
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen D, 2015, IEEE T PARALL DISTR, V26, P847, DOI 10.1109/TPDS.2014.2311805
   Chen D, 2015, IEEE T COMPUT, V64, P707, DOI 10.1109/TC.2013.2295806
   Dong WS, 2011, IEEE T IMAGE PROCESS, V20, P1838, DOI 10.1109/TIP.2011.2108306
   Fan W, 2007, PROC CVPR IEEE, P244
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P3194, DOI 10.1109/TIP.2012.2190080
   Gao XB, 2012, IEEE T IMAGE PROCESS, V21, P469, DOI 10.1109/TIP.2011.2161482
   Glasner D, 2009, IEEE I CONF COMP VIS, P349, DOI 10.1109/ICCV.2009.5459271
   Greenspan H, 2009, COMPUT J, V52, P43, DOI 10.1093/comjnl/bxm075
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Hung KW, 2009, IEEE IMAGE PROC, P1193, DOI 10.1109/ICIP.2009.5413696
   Jia K, 2013, IEEE T PATTERN ANAL, V35, P367, DOI 10.1109/TPAMI.2012.95
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P15, DOI 10.1109/TMM.2016.2599145
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Jiang JJ, 2016, INFORM SCIENCES, V367, P354, DOI 10.1016/j.ins.2016.05.032
   Jiang JJ, 2014, IEEE T IMAGE PROCESS, V23, P4220, DOI 10.1109/TIP.2014.2347201
   Jiang JJ, 2014, IEEE T MULTIMEDIA, V16, P1268, DOI 10.1109/TMM.2014.2311320
   Johnson R.A., 2007, Applied multivariate statistial analysis, Vsixth
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2010, IEEE T PATTERN ANAL, V32, P1127, DOI 10.1109/TPAMI.2010.25
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu HY, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060499
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Sun J, 2003, PROC CVPR IEEE, P729
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tam WS, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3358372
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang LZ, 2015, IEEE GEOSCI REMOTE S, V12, P736, DOI 10.1109/LGRS.2014.2360457
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang JC, 2012, IEEE T IMAGE PROCESS, V21, P3467, DOI 10.1109/TIP.2012.2192127
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zeyde R., 2012, INT C CURV SURF, P711, DOI DOI 10.1007/978-3-642-27413-8_47
   Zhang KB, 2017, OPT COMMUN, V404, P169, DOI 10.1016/j.optcom.2017.06.102
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang KB, 2013, IEEE T NEUR NET LEAR, V24, P1648, DOI 10.1109/TNNLS.2013.2262001
   Zhang KB, 2012, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2012.6247791
   Zhang KB, 2011, IEEE J-STSP, V5, P230, DOI 10.1109/JSTSP.2010.2048606
NR 45
TC 5
Z9 5
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28713
EP 28730
DI 10.1007/s11042-021-11062-0
EA JUN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000659401100003
DA 2024-07-18
ER

PT J
AU Chen, CQ
   Qi, MB
   Huang, GH
   Wu, JJ
   Jiang, JG
   Li, XH
AF Chen, Cuiqun
   Qi, Meibin
   Huang, Guanghong
   Wu, Jingjing
   Jiang, Jianguo
   Li, Xiaohong
TI Learning discriminative features with a dual-constrained guided network
   for video-based person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video-based person re-identification; Discriminative features;
   Dual-constrained guided network; Frame-level constraint; Sequence-level
   constraint
ID ATTENTION
AB Video-based person re-identification (ReID) aims at matching pedestrians in a large video gallery across different cameras. However, some interference factors in most real-world scenarios, such as occlusion, pose variations and new appearances, make ReID a challenging task. Most existing methods learn the features of each frame independently without using the complementary information between different frames, which leads to the fact that the extracted frame features do not have enough discriminability to solve the above problems. In this paper, we propose a novel dual-constrained guided network (DCGN) to capture discriminative features by modeling the relations across frames with two steps. First, to learn the frame-level discriminative features, we design a frame-constrained module (FCM) that learns the channel attention weights by means of combining the intra-frame information and inter-frame information. Next, we propose a sequence-constrained module (SCM) to determine the importance of each frame in a video. This module models the relations between the frame-level features and sequence-level features, alleviating the frame redundancy from a global perspective. We conduct comparison experiments on four representative datasets, i.e., MARS, DukeMTMC-VideoReID, iLIDS-VID and PRID2011. In particular, the Rank-1 reaches 89.65%, 95.35%, 78.51% and 90.82% on four datasets, which outperforms the second-best method by 2.35%, 1.35%, 3.41% and 2.72%, respectively.
C1 [Chen, Cuiqun; Qi, Meibin; Huang, Guanghong; Wu, Jingjing; Jiang, Jianguo; Li, Xiaohong] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
   [Qi, Meibin] Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei, Peoples R China.
   [Huang, Guanghong] Anhui Siliepoch Technol Co Ltd, Hefei, Anhui, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Chen, CQ (corresponding author), Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230009, Anhui, Peoples R China.
EM chencuiqun_hfut@163.com; qimeibin@163.com
RI liang, liang/IAO-8518-2023; li, xiao/GSN-6181-2022; li,
   xiao/HKV-8405-2023; wang, xu/IAN-4886-2023; li, xiaofeng/GXF-9442-2022;
   li, xiao/HJP-5134-2023; liu, jiaming/IWE-3196-2023
OI chen, cuiqun/0000-0002-4133-0028
FU National Natural Science Foundation of China [61771180, 61876056];
   Innovation Fund of Anhui Siliepoch Technology Co., Ltd.
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61771180 and Grant 61876056, the
   Innovation Fund of Anhui Siliepoch Technology Co., Ltd. The authors
   would like to thank the anonymous reviewers for their valuable advice
   and constructive criticism.
CR Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   [Anonymous], ARXIV160601609
   Chao HQ, 2019, AAAI CONF ARTIF INTE, P8126
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen ZQ, 2020, AAAI CONF ARTIF INTE, V34, P10591
   CHENG L, 2020, MULTIMED TOOLS APPL, V79
   Cheng L, 2020, NEURAL COMPUT APPL, V32, P12841, DOI 10.1007/s00521-020-04730-z
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Gao Jinyang., 2018, CoRR
   Gu XQ, 2019, IEEE I CONF COMP VIS, P9646, DOI 10.1109/ICCV.2019.00974
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang HJ, 2020, IEEE T IMAGE PROCESS, V29, P7468, DOI 10.1109/TIP.2020.3003442
   Huang Y, 2019, IEEE I CONF COMP VIS, P9526, DOI 10.1109/ICCV.2019.00962
   Huang Y, 2019, IEEE T IMAGE PROCESS, V28, P1391, DOI 10.1109/TIP.2018.2874715
   Kingma D. P., 2014, arXiv
   Lejbolle AR, 2020, IEEE T INF FOREN SEC, V15, P1216, DOI 10.1109/TIFS.2019.2938870
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2020, IEEE T IMAGE PROCESS, V29, P4461, DOI 10.1109/TIP.2020.2972108
   Li R, 2020, ACTA PHARMACOL SIN, V41, P1289, DOI 10.1038/s41401-019-0338-1
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Liu C.-T., 2019, ARXIV190801683
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu Z, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10155385
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Munir A, 2020, IEEE IMAGE PROC, P2351, DOI [10.1109/icip40778.2020.9191115, 10.1109/ICIP40778.2020.9191115]
   Ouyang W, 2017, CVPR, P5790, DOI DOI 10.1109/CVPR.2017.499
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Song W, 2021, MINIM INVASIV THER, V30, P139, DOI 10.1080/13645706.2020.1720250
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wu Y, 2018, AAAI CONF ARTIF INTE, P7412
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xiang SC, 2020, MULTIMED TOOLS APPL, V79, P32079, DOI 10.1007/s11042-020-09569-z
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xinqian Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P228, DOI 10.1007/978-3-030-58536-5_14
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Ye M, 2020, IEEE T PATTERN ANAL, P1, DOI DOI 10.1109/TPAMI.2020.3013379
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zamir AR, 2012, LECT NOTES COMPUT SC, V7573, P343, DOI 10.1007/978-3-642-33709-3_25
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhang W, 2020, IEEE T IMAGE PROCESS, V29, P3365, DOI 10.1109/TIP.2019.2959653
   Zhang YZ, 2020, IEEE IMAGE PROC, P2436, DOI 10.1109/ICIP40778.2020.9191079
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhou QQ, 2020, IEEE T IMAGE PROCESS, V29, P7578, DOI 10.1109/TIP.2020.3004267
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 70
TC 4
Z9 4
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 19
BP 28673
EP 28696
DI 10.1007/s11042-021-11072-y
EA JUN 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UC8NB
UT WOS:000658627200001
DA 2024-07-18
ER

PT J
AU Saini, A
   Daniel, S
   Saini, S
   Mittal, A
AF Saini, Aradhya
   Daniel, Sandeep
   Saini, Satyam
   Mittal, Ankush
TI EffKannadaRes-NeXt: An efficient residual network for Kannada numeral
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep residual network; Kannada numerals; Recognition; ResNeXt; VGG16;
   CNN; Hand-crafted
AB In this article a framework regarding correct and efficient identification of Kannada handwritten numerals has been proposed. The EffKannadaRes-NeXt model is based on deep residual network ResNeXt and takes binary as well as gray-scale representations of numeral images into consideration. The study deals with handling numeral images from MNIST-sized Kannada-MNIST dataset and Dig-MNIST dataset, an out-of-domain test dataset. The test datasets derive test sets from two different scenarios and these sets are beneficial for evaluating the robustness of the model. The EffKannadaRes-Next is observed to achieve an accuracy of 97.81% and 97.37% on the Kannada-MNIST test dataset along with 82.08% and 81.67% on Dig-MNIST dataset. A comparison of results with those available in the literature is performed and a close agreement shows the versatility of the present technique.
C1 [Saini, Aradhya] Indian Inst Technol Roorkee, Roorkee, Uttar Pradesh, India.
   [Daniel, Sandeep] VIT Chennai, Chennai, Tamil Nadu, India.
   [Saini, Satyam] Jaypee Inst Informat Technol, Noida, India.
   [Mittal, Ankush] Raman Classes, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee; Vellore Institute of Technology (VIT); VIT
   Chennai; Jaypee Institute of Information Technology (JIIT)
RP Saini, A (corresponding author), Indian Inst Technol Roorkee, Roorkee, Uttar Pradesh, India.
EM aradhya.saini91@gmail.com; sandeepjoshuadaniel@gmail.com;
   satyamsaini97@gmail.com; dr.ankush.mittal@gmail.com
OI Saini, aradhya/0000-0003-0864-0267
CR Ahlawat S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123344
   Ahlawat S, 2017, PROCEDIA COMPUT SCI, V122, P1092, DOI 10.1016/j.procs.2017.11.478
   Al-wajih E, 2020, ADV INTELL SYST COMP, V978, P25, DOI 10.1007/978-3-030-36056-6_3
   [Anonymous], 2020, AKHCRNET BENGALI HAN
   Asha K., 2018, 2018 3rd International Conference on Computational Systems and Information Technology for Sustainable Solutions (CSITSS), P299, DOI 10.1109/CSITSS.2018.8768745
   Basri R., 2020, P INT C COMPUTING AD, P1
   Bora R, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET), P196, DOI 10.1109/WiSPNET.2017.8299747
   Chaithra D, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P548, DOI 10.1109/RTEICT.2017.8256657
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ghadekar P, 2018, 2018 FOURTH INTERNATIONAL CONFERENCE ON COMPUTING COMMUNICATION CONTROL AND AUTOMATION (ICCUBEA)
   Ghosh Manosij, 2018, Intelligent Engineering Informatics. Proceedings of the 6th International Conference on FICTA. Advances in Intelligent Systems and Computing (AISC 695), P471, DOI 10.1007/978-981-10-7566-7_46
   Ghosh T., 2020, Bulletin of Electrical Engineering and Informatics, V9, P2547, DOI [10.11591/eei.v9i6.2234, DOI 10.11591/EEI.V9I6.2234]
   Guha R, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420520096
   Gupta D, 2021, EXPERT SYST APPL, V165, DOI 10.1016/j.eswa.2020.113784
   Hallur VC, 2019, INT J TECHNOL HUM IN, V15, P63, DOI 10.4018/IJTHI.2019100106
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang WW, 2020, IEICE T INF SYST, VE103D, P720, DOI 10.1587/transinf.2019EDL8199
   Karthik S, 2019, CLUSTER COMPUT, V22, pS4673, DOI 10.1007/s10586-018-2274-0
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar M, 2019, ARTIF INTELL REV, V52, P2235, DOI 10.1007/s10462-017-9607-x
   Kumar M, 2018, NATL ACAD SCI LETT, V41, P29, DOI 10.1007/s40009-017-0606-x
   Mhapsekar M., 2020, Advanced computing technologies and applications, algorithms for intelligent systems, P137, DOI DOI 10.1007/978-981-15-3242-9_14
   Mukarambi G., 2020, INT J COMPUTAT VISIO, V10, P156, DOI [10.1504/IJCVR.2020.105684, DOI 10.1504/IJCVR.2020.105684]
   Nan FZ, 2020, MULTIMED TOOLS APPL, V79, P34459, DOI 10.1007/s11042-020-09053-8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pasha S, 2015, 2015 INTERNATIONAL CONFERENCE ON EMERGING RESEARCH IN ELECTRONICS, COMPUTER SCIENCE AND TECHNOLOGY (ICERECT), P346, DOI 10.1109/ERECT.2015.7499039
   Prabhu VU., 2019, ARXIV PREPRINT ARXIV
   Pramanik R, 2018, WORKSHOP DOCUMENT AN, P41
   Prasad, 2019, IMPROVEMENT ONLINE H
   Saini A, 2015, DESIGNING INTERCONNE
   Saini A, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P138, DOI 10.1109/BID.2017.8336587
   Saini A, 2016, 2016 FOURTH INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P468, DOI 10.1109/PDGC.2016.7913241
   Saini S, 2020, LECT NOTES ELECTR EN, V605, P613, DOI 10.1007/978-3-030-30577-2_54
   Sharma N, 2006, ICIT 2006: 9TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY, PROCEEDINGS, P133
   Shukla P, 2017, IEEE WINT CONF APPL, P705, DOI 10.1109/WACV.2017.84
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Trivedi A, 2018, PROCEDIA COMPUT SCI, V125, P525, DOI 10.1016/j.procs.2017.12.068
   Upadhye GD, 2019, INT C SOFT COMP SIGN, P613
   van der Maaten L. J. P., 2008, Journal of Machine Learning Research, V9, P2579, DOI DOI 10.1007/S10479-011-0841-3
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhan H., 2019, AS C PATT REC, P262
   Zhang ZL, 2018, ADV NEUR IN, V31
NR 45
TC 1
Z9 1
U1 2
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28391
EP 28417
DI 10.1007/s11042-021-10797-0
EA JUN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000658077800001
DA 2024-07-18
ER

PT J
AU Liu, S
   Keren, G
   Parada-Cabaleiro, E
   Schuller, B
AF Liu, Shuo
   Keren, Gil
   Parada-Cabaleiro, Emilia
   Schuller, Bjoern
TI N-HANS: A neural network-based toolkit for in-the-wild audio enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Residual block; Auxiliary network; Selective noise suppression;
   Conditioned recording; Audio context; Source separation; Speech
   denoising
ID SPEECH ENHANCEMENT; NOISE; QUALITY; INTELLIGIBILITY
AB The unprecedented growth of noise pollution over the last decades has raised an always increasing need for developing efficient audio enhancement technologies. Yet, the variety of difficulties related to processing audio sources in-the-wild, such as handling unseen noises or suppressing specific interferences, makes audio enhancement a still open challenge. In this regard, we present N-HANS (the Neuro-Holistic Audio-eNhancement System), a Python toolkit for in-the-wild audio enhancement that includes functionalities for audio denoising, source separation, and -for the first time in such a toolkit-selective noise suppression. The N-HANS architecture is specially developed to automatically adapt to different environmental backgrounds and speakers. This is achieved by the use of two identical neural networks comprised of stacks of residual blocks, each conditioned on additional speech- and noise-based recordings through auxiliary sub-networks. Along to a Python API, a command line interface is provided to researchers and developers, both of them carefully documented. Experimental results indicate that N-HANS achieves great performance w. r. t. existing methods, preserving also the audio quality at a high level; thus, ensuring a reliable usage in real-life application, e. g., for in-the-wild speech processing, which encourages the development of speech-based intelligent technology.
C1 [Liu, Shuo; Keren, Gil; Parada-Cabaleiro, Emilia; Schuller, Bjoern] Univ Augsburg, Chair Embedded Intelligence Hlth Care & Wellbeing, Augsburg, Germany.
   [Schuller, Bjoern] Imperial Coll London, GLAM Grp Language, Audio, Mus, London, England.
C3 University of Augsburg; Imperial College London
RP Liu, S (corresponding author), Univ Augsburg, Chair Embedded Intelligence Hlth Care & Wellbeing, Augsburg, Germany.
EM shuo.liu@informatik.uni-augsburg.de;
   gil.keren@informatik.uni-augsburg.de;
   emilia.parada-cabaleiro@informatik.uni-augsburg.de; schuller@ieee.org
RI Parada-Cabaleiro, Emilia/GXF-2079-2022; Schuller, Björn
   Wolfgang/D-3241-2011
OI Parada-Cabaleiro, Emilia/0000-0003-1843-3632; Schuller, Björn
   Wolfgang/0000-0002-6478-8699; Liu, Shuo/0000-0001-8133-8588
FU Projekt DEAL
FX Open Access funding enabled and organized by Projekt DEAL.
CR [Anonymous], 1993, NASA STIRECON TECH R, V93, DOI DOI 10.6028/NIST.IR.4930
   Atmaca E, 2005, POL J ENVIRON STUD, V14, P721
   Avila AR, 2018, INTERSPEECH, P3663, DOI 10.21437/Interspeech.2018-2350
   Bharitkar S, 2003, IEEE T MULTIMEDIA, V5, P329, DOI 10.1109/TMM.2003.811656
   Bimbot F., 2014, ICASSP, P3
   Bittner EJHRM, 2018, P ISMIR NEW YORK CIT, P3
   Choi Hyeong- Seok, 2019, P ICLR
   Chung JS, 2018, INTERSPEECH, P1086
   Delic V, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/4368036
   Freitag M, 2018, J MACH LEARN RES, V18
   Fritschi L, 2011, Burden of disease from environmental noise-Quantification of healthy life years lost in Europe
   Garofolo JS, 1993, PHILADELPHIA LINGUIS
   Gemmeke JF, 2017, INT CONF ACOUST SPEE, P776, DOI 10.1109/ICASSP.2017.7952261
   Girin L, 2019, COMPUT VIS PATT REC, P53, DOI 10.1016/B978-0-12-814601-9.00022-5
   Goehring T, 2017, HEARING RES, V344, P183, DOI 10.1016/j.heares.2016.11.012
   Goines L, 2007, SOUTH MED J, V100, P287, DOI 10.1097/SMJ.0b013e3180318be5
   Gustafsson S, 1998, INT CONF ACOUST SPEE, P397, DOI 10.1109/ICASSP.1998.674451
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hershey JR, 2016, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2016.7471631
   Hu Y, 2008, IEEE T AUDIO SPEECH, V16, P229, DOI 10.1109/TASL.2007.911054
   Jeon KM, 2017, DIGIT SIGNAL PROCESS, V68, P138, DOI 10.1016/j.dsp.2017.06.001
   Jung H, 2017, IEEE COMPUT SOC CONF, P934, DOI 10.1109/CVPRW.2017.129
   Keren G., 2018, PROC CHIME WORKSHOP, P25
   Kim J, 2019, IEEE SIGNAL PROC LET, V26, P770, DOI 10.1109/LSP.2019.2905660
   Kim M, 2013, INT CONF ACOUST SPEE, P896, DOI 10.1109/ICASSP.2013.6637778
   Kolbæk M, 2017, IEEE-ACM T AUDIO SPE, V25, P1901, DOI 10.1109/TASLP.2017.2726762
   Kolbæk M, 2016, IEEE W SP LANG TECH, P305, DOI 10.1109/SLT.2016.7846281
   Kolbaek M, 2017, IEEE-ACM T AUDIO SPE, V25, P153, DOI 10.1109/TASLP.2016.2628641
   Kumar A, 2016, INTERSPEECH, P3738, DOI 10.21437/Interspeech.2016-88
   Li H, 2018, ADV NEUR IN, V31
   Liu D, 2014, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINEERING CONGRESS AND EXPOSITION, 2013, VOL 3A
   Liu YZ, 2019, IEEE-ACM T AUDIO SPE, V27, P2092, DOI [10.1109/taslp.2019.2941148, 10.1109/TASLP.2019.2941148]
   Lu XG, 2013, INTERSPEECH, P436
   Luo Y, 2019, IEEE-ACM T AUDIO SPE, V27, P1256, DOI 10.1109/TASLP.2019.2915167
   Luo Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P696, DOI 10.1109/ICASSP.2018.8462116
   Makino S, 2018, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-3-319-73031-8
   Michelsanti D, 2017, INTERSPEECH, P2008, DOI 10.21437/Interspeech.2017-1620
   Miedema HME, 2001, ENVIRON HEALTH PERSP, V109, P409, DOI 10.2307/3454901
   Ming J, 2011, IEEE T AUDIO SPEECH, V19, P822, DOI 10.1109/TASL.2010.2064312
   Monaghan JJM, 2017, J ACOUST SOC AM, V141, P1985, DOI 10.1121/1.4977197
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Parada-Cabaleiro E, 2020, INT J SPEECH TECHNOL, V23, P169, DOI 10.1007/s10772-020-09675-1
   Parada-Cabaleiro E, 2017, INTERSPEECH, P3246, DOI 10.21437/Interspeech.2017-104
   Pariente M, 2020, INTERSPEECH, P2637, DOI 10.21437/Interspeech.2020-1673
   Pascual S, 2019, INTERSPEECH, P1791, DOI 10.21437/Interspeech.2019-2688
   Pascual S, 2017, INTERSPEECH, P3642, DOI 10.21437/Interspeech.2017-1428
   Po-Sen Huang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1562, DOI 10.1109/ICASSP.2014.6853860
   Putraya GG, 2017, United States Patent, Patent No. 9769588
   Rethage D, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5069, DOI 10.1109/ICASSP.2018.8462417
   Roma G, 2016, P ISMIR NEW YORK CIT, P4
   Santurkar S, 2018, ADV NEUR IN, V31
   Sari L, 2018, P MLSLP HYD, P3
   Schmitt M, 2017, J MACH LEARN RES, V18
   Shon S, 2019, INTERSPEECH, P2888, DOI 10.21437/Interspeech.2019-1496
   Soni MH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5039, DOI 10.1109/ICASSP.2018.8462068
   Stöter FR, 2018, LECT NOTES COMPUT SC, V10891, P293, DOI 10.1007/978-3-319-93764-9_28
   Thiemann J., 2013, J. Acoustical Soc. Amer., V133
   Tolooshams B, 2020, INT CONF ACOUST SPEE, P836, DOI [10.1109/icassp40776.2020.9053989, 10.1109/ICASSP40776.2020.9053989]
   Triantafyllopoulos A, 2019, INTERSPEECH, P1691, DOI 10.21437/Interspeech.2019-1811
   Tzivian L, 2016, ENVIRON HEALTH PERSP, V124, P1361, DOI 10.1289/ehp.1509824
   Valin JM, 2018, IEEE INT WORKSH MULT
   Veaux C, 2013, INT CONF SPEECH DATA
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Vydana HK, 2017, EUR SIGNAL PR CONF, P543, DOI 10.23919/EUSIPCO.2017.8081266
   Wang DL, 2018, IEEE-ACM T AUDIO SPE, V26, P1702, DOI 10.1109/TASLP.2018.2842159
   Wang ZQ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P686, DOI 10.1109/ICASSP.2018.8462507
   Weninger F, 2011, INT CONF ACOUST SPEE, P1625
   Westhausen NL, 2020, INTERSPEECH, P2477, DOI 10.21437/Interspeech.2020-2631
   Wittkop T, 2003, SPEECH COMMUN, V39, P111, DOI 10.1016/S0167-6393(02)00062-6
   Wright B, 2014, NOISE HEALTH, V16, P166, DOI 10.4103/1463-1741.134917
   Xu R., 2020, in Neural Information Processing Systems, P9633
   Xu Y, 2015, IEEE-ACM T AUDIO SPE, V23, P7, DOI 10.1109/TASLP.2014.2364452
   Xu Y, 2014, IEEE SIGNAL PROC LET, V21, P65, DOI 10.1109/LSP.2013.2291240
   Yu G, 2008, IEEE T SIGNAL PROCES, V56, P1830, DOI 10.1109/TSP.2007.912893
   Yul D, 2017, INT CONF ACOUST SPEE, P241, DOI 10.1109/ICASSP.2017.7952154
   Zannin P.H. T., 2003, ENV IMPACE ASSESSMEN, V23, P245, DOI [DOI 10.1016/S0195-9255(02)00092-6, DOI 10.1016/50195-9255(02100092-6]
   Zhang JB, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P353, DOI 10.1145/2623330.2623618
NR 79
TC 5
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28365
EP 28389
DI 10.1007/s11042-021-11080-y
EA JUN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000657588300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Al-Rahlawee, ATH
   Rahebi, J
AF Al-Rahlawee, Anfal Thaer Hussein
   Rahebi, Javad
TI Multilevel thresholding of images with improved Otsu thresholding by
   black widow optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Thresholding; Otsu; Swarm intelligence algorithms; Black widow
   optimization algorithm
AB One of the most important methods of image processing is image thresholding, which is based on image histogram analysis. These methods analyze the image histogram diagram and try to present optimal values for the image thresholds so that the image regions can be distinguished by these thresholds. Thresholding is a popular method in image processing and is used in most research related to image segmentation due to its accuracy and efficiency. Multi-level thresholding, such as the Otsu method, is one of the most common methods of thresholding image processing. These methods have high computational complexity despite their accuracy and efficiency. When the number of thresholds used increases, these methods lose their efficiency due to increased complexity and execution time. One of the ways to find thresholds in the Otsu threshold method is to use metaheuristic algorithms such as the Black Widow Spider Optimization Algorithm. These algorithms can find the appropriate thresholds for the image at the logical time. In the proposed method, each threshold is a component or one dimension of a solution of the Black Widow Spider Optimization Algorithm, and an attempt is made to calculate the optimal threshold value without high complexity by this algorithm. Experiments on several standard images show that the proposed algorithm finds better thresholds than the particle swarm optimization algorithm, the firefly algorithm, the genetic algorithm, and the gray wolf optimization algorithm. The analysis shows that the proposed method in the PSNR index has a better value in 83.33% of the experiments than other algorithms and also in 80% of the experiments the proposed method has a better SSIM index than these methods. Analysis of the proposed algorithm on several pertussis images also shows that the proposed method has a good ability to threshold medical images such as brain tumors and optic disc detection in human retinal images.
C1 [Al-Rahlawee, Anfal Thaer Hussein; Rahebi, Javad] Altinbas Univ, Dept Elect & Comp Engn, Istanbul, Turkey.
C3 Altinbas University
RP Rahebi, J (corresponding author), Altinbas Univ, Dept Elect & Comp Engn, Istanbul, Turkey.
EM anfal.alrahlawee@ogr.altinbas.edu.tr; cevat.rahebi@altinbas.edu.tr
CR Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bhuvan Chander, 2020, 2020 7th International Conference on Signal Processing and Integrated Networks (SPIN), P1132, DOI 10.1109/SPIN48934.2020.9071220
   Elaziz MA, 2020, EXPERT SYST APPL
   Gao H, 2018, COMPUT ELECTR ENG, V70, P931, DOI 10.1016/j.compeleceng.2017.12.037
   Goh TY, 2018, MEASUREMENT, V114, P298, DOI 10.1016/j.measurement.2017.09.052
   Hashmi MU, 2020, INNOV SMART GRID TEC, DOI 10.1109/isgt45199.2020.9087772
   Hayyolalam V, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103249
   He LF, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106063
   Jin ML, 2019, PROC SPIE, V11179, DOI 10.1117/12.2539638
   Jyotiyana P, 2019, LECT NOTE NETW SYST, V40, P687, DOI 10.1007/978-981-13-0586-3_67
   Kang C, 2020, IEEE ACCESS, V8, P17025, DOI 10.1109/ACCESS.2020.2964335
   Küçükugurlu B, 2020, EXPERT SYST APPL, V147, DOI 10.1016/j.eswa.2020.113210
   Kumar IV, 2020, APPL SOFT COMPUT
   Liu W, 2018, CHIN AUTOM CONGR, P1
   Malviya Utsav Kumar, 2020, 2020 Fourth International Conference on Computing Methodologies and Communication (ICCMC). Proceedings, P126, DOI 10.1109/ICCMC48092.2020.ICCMC-00026
   Merzban MH, 2019, EXPERT SYST APPL, V116, P299, DOI 10.1016/j.eswa.2018.09.008
   Hoang ND, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6765274
   Rahebi J, 2016, MED BIOL ENG COMPUT, V54, P453, DOI 10.1007/s11517-015-1330-7
   Rajinikanth V., 2020, ARXIV PREPRINT ARXIV
   Rajinikanth Venkatesan, 2020, Applications of Firefly Algorithm and its Variants, P221
   Rani NS, 2020, PROCEDIA COMPUT SCI, V167, P273, DOI 10.1016/j.procs.2020.03.221
   Santamaría J, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10061928
   Sentenská L, 2020, ANIM BEHAV, V160, P53, DOI 10.1016/j.anbehav.2019.11.021
   Shanker R, 2020, BIOCYBERN BIOMED ENG, V40, P815, DOI 10.1016/j.bbe.2020.03.003
   Song SB, 2020, J PETROL SCI ENG, V190, DOI 10.1016/j.petrol.2020.107074
   Upadhyay P, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105522
   Vinoth Kumar B., 2020, Advanced Engineering Optimization Through Intelligent Techniques. Select Proceedings of AEOTIT 2018. Advances in Intelligent Systems and Computing (AISC 949), P291, DOI 10.1007/978-981-13-8196-6_27
   Xiao LY, 2019, OPTIK, V196, DOI 10.1016/j.ijleo.2019.163106
   Zhan YT, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11030431
NR 29
TC 30
Z9 31
U1 2
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 28217
EP 28243
DI 10.1007/s11042-021-10860-w
EA JUN 2021
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000657212500005
DA 2024-07-18
ER

PT J
AU Sun, HP
   Wen, XL
AF Sun, Hao-peng
   Wen, Xiaolong
TI Research on learning progress tracking of multimedia port user based on
   improved CamShift algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia port; User's learning progress; Eye tracking technology; Eye
   tracker
ID EYE-TRACKING; ATTENTION
AB Aiming at the shortcomings of the existing methods which lead to low tracking accuracy, poor real-time performance and low tracking success rate, this paper proposes a method for learning progress tracking of multimedia port user based on improved CamShift algorithm. The infrared image is processed by multimedia technology, and the binary image is obtained. The initial pupil center position is obtained in the image. Finally, the eye tracking algorithm based on improved CamShift is used to further track the initial pupil center, and the learning progress tracking of multimedia port user is realized. The experimental results show that the average time consumed by the proposed method is 0.0065 s and the average number of iterations is 1.5. The real-time performance of the proposed method is the best, and the success rate of eye tracking is more than 80%. The overall performance of the proposed method is good.
C1 [Sun, Hao-peng] Changchun Inst Technol, Sch Comp Technol & Engn, Changchun 130012, Peoples R China.
   [Wen, Xiaolong] Hunan City Univ, Coll Civil Engn, Yiyang 413000, Hunan, Peoples R China.
C3 Changchun Institute Technology; Hunan City University
RP Wen, XL (corresponding author), Hunan City Univ, Coll Civil Engn, Yiyang 413000, Hunan, Peoples R China.
EM xiaolongw@aliyun.com
CR Cheng Shi-wei, 2016, Journal of Zhejiang University. Engineering Science, V50, P1160, DOI 10.3785/j.issn.1008-973X.2016.06.021
   Garry J, 2016, SURGERY, V159, P938, DOI 10.1016/j.surg.2015.08.012
   Li M, 2016, J INT MED RES, V44, P1072, DOI 10.1177/0300060516662134
   Li W.J., 2017, COMPUTER SIMULATION, V34, P337
   Niefind F, 2016, PSYCHOPHYSIOLOGY, V53, P1784, DOI 10.1111/psyp.12765
   Oberwelland E, 2016, NEUROIMAGE, V130, P248, DOI 10.1016/j.neuroimage.2016.02.026
   Oliveira D, 2016, LWT-FOOD SCI TECHNOL, V68, P160, DOI 10.1016/j.lwt.2015.11.066
   Privitera CM, 2016, OPT LETT, V41, P1728, DOI 10.1364/OL.41.001728
   Qin BZ, 2017, AUTOMATION INSTRUMEN, V39, P35
   Shi LY., 2017, J CHINA ACAD ELECT I, V12, P383
   Song ZJ., 2017, J INTELLIGENCE, V36, P76
   Stevenson SB, 2016, VISION RES, V118, P98, DOI 10.1016/j.visres.2015.01.019
   Stuart S, 2018, MED BIOL ENG COMPUT, V56, P289, DOI 10.1007/s11517-017-1669-z
   Yang QH., 2016, J MECH ELECT ENG, V33, P904
   Yu YN., 2016, J TIANJIN U TECHNOLO, V26, P50
NR 15
TC 2
Z9 2
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 22719
EP 22732
DI 10.1007/s11042-019-07761-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000669314100019
DA 2024-07-18
ER

PT J
AU Badii, C
   Difino, A
   Nesi, P
   Paoli, I
   Paolucci, M
AF Badii, Claudio
   Difino, Angelo
   Nesi, Paolo
   Paoli, Irene
   Paolucci, Michela
TI Classification of users' transportation modalities from mobiles in real
   operating conditions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE User behaviour analysis; Smart city; Mobile phones; Transportation
   modes; Classification model; Machine learning
AB The modern mobile phones and the complete digitalization of the public and private transport networks have allowed to access useful information to understand the user's mean of transportation. This enables a plethora of old and new applications in the fields of sustainable mobility, smart transportation, assistance, and e-health. The precise understanding of the travel means is at the basis of the development of a large range of applications. In this paper, a number of metrics has been identified to understand whether an individual on the move is stationary, walking, on a motorized private or public transport, with the aim of delivering to city users personalized assistance messages for: sustainable mobility, health, and/or for a better and enjoyable life, etc. Differently from the state-of-the-art solutions, the proposed approach has been designed to provide results, and thus collect metrics, in real operating conditions (imposed on the mobile phones as: a range of different mobile phone kinds, operating system constraints managing Applications, active battery consumption manager, etc.). The paper reports the whole experimentations and results. The solution has been developed in the context of Sii-Mobility Km4City Research Project infrastructure and tools, performed with the collaboration of public transport operators, and GDPR compliant. The same solution has been used in Snap4City mobile Apps with experiments performed in Antwerp and Helsinki.
C1 [Badii, Claudio; Difino, Angelo; Nesi, Paolo; Paoli, Irene; Paolucci, Michela] Univ Florence, Dept Informat Engn, Distributed Syst & Internet Tech Lab, DISIT Lab, Florence, Italy.
C3 University of Florence
RP Nesi, P (corresponding author), Univ Florence, Dept Informat Engn, Distributed Syst & Internet Tech Lab, DISIT Lab, Florence, Italy.
EM paolo.nesi@unifi.it
OI nesi, paolo/0000-0003-1044-3107; Badii, Claudio/0000-0001-9343-7065
FU Universita degli Studi di Firenze within the CRUI-CARE Agreement
FX Open access funding provided by Universita degli Studi di Firenze within
   the CRUI-CARE Agreement.
CR Ashqar HI, 2019, IEEE T INTELL TRANSP, V20, P244, DOI 10.1109/TITS.2018.2817658
   Badii C, 2018, 2018 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED & TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI), P2109, DOI 10.1109/SmartWorld.2018.00353
   Badii C, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP), P93
   Badii C, 2017, FUTURE GENER COMP SY, V75, P14, DOI 10.1016/j.future.2017.05.001
   Badii C, 2016, IEEE INT C SMART COM, P1
   Badii C, 2018, IEEE ACCESS, V6, P44059, DOI 10.1109/ACCESS.2018.2864157
   Bellini P, 2014, INT J MULTIMED INF R, V3, P147, DOI 10.1007/s13735-014-0058-8
   Biancat J., 2014, EAI Endorsed Trans. Ambient Syst, V1, pe7, DOI [10.4108/AMSYS.1.4.E7, DOI 10.4108/AMSYS.1.4.E7]
   Biljecki F, 2013, INT J GEOGR INF SCI, V27, P385, DOI 10.1080/13658816.2012.692791
   Breiman L, 2001, STAT SCI, V16, P199, DOI 10.1214/ss/1009213726
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Hemminki S., 2013, P 11 ACM C EMB NETW, P1, DOI [10.1145/2517351.2517367, DOI 10.1145/2517351.2517367]
   Li XX, 2015, J GEODESY, V89, P607, DOI 10.1007/s00190-015-0802-8
   Lv ZH, 2018, FUTURE GENER COMP SY, V81, P443, DOI 10.1016/j.future.2017.08.047
   Manzoni V., 2010, TRANSPORTATION MODE
   Misra P., 2010, Global Positioning System: Signals, Measurements, and Performance, V2nd
   Polley E.C., 2010, Super learner in prediction
   Prelipcean AC, 2017, TRANSPORT REV, V37, P442, DOI 10.1080/01441647.2016.1246489
   Prelipcean AC, 2014, J LOCAT BASED SERV, V8, P229, DOI 10.1080/17489725.2014.973917
   Reddy S, 2010, ACM T SENSOR NETWORK, V6, DOI 10.1145/1689239.1689243
   Schapire RE, 1996, EXPT NEW BOOSTING AL, P96
   Tenneth L, 2011, P 19 ACM INT C ADV, P54, DOI DOI 10.1145/2093973.2093982
   van der Laan M. J., 2003, Unified cross-validation methodology for selection among estimators and a general cross-validated adaptive epsilon-net estimator: Finite sample oracle inequalities and examples, V130, P1
   van der Laan MJ, 2006, STATIST RISK MODEL, V24, P373, DOI 10.1524/stnd.2006.24.3.373
   van der Laan MJ, 2007, STAT APPL GENET MOL, V6, DOI 10.2202/1544-6115.1309
   Wang SL, 2010, PROCEEDINGS OF 2010 INTERNATIONAL CONFERENCE ON INDUSTRY ENGINEERING AND MANAGEMENT, P44, DOI 10.1109/APWCS.2010.18
   Yanyun G., 2017, INT C INDOOR POSIT, P1
   Yu MC, 2014, PROC VLDB ENDOW, V7, P1429, DOI 10.14778/2733004.2733015
NR 32
TC 8
Z9 9
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 115
EP 140
DI 10.1007/s11042-021-10993-y
EA MAY 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000655178800001
PM 34075301
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Bui, DD
   Ogata, K
AF Bui, Dang Duy
   Ogata, Kazuhiro
TI Better state pictures facilitating state machine characteristic
   conjecture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anderson protocol; Gestalt principles; Graphical animation; MCS
   protocol; SMGA; State machine; State picture design
ID GESTALT PSYCHOLOGY; VISUALIZATION
AB The mutual exclusion protocol invented by Mellor-Crummey and Scott (called MCS protocol) is used to exemplify that state picture designs based on which the state machine graphical animation (SMGA) tool produces graphical animations should be better visualized. Variants of MCS protocol have been used in Java virtual machines and therefore the 2006 Edsger W. Dijkstra Prize in Distributed Computing went to their paper on MCS protocol. The new state picture design of a state machine formalizing MCS protocol is assessed based on Gestalt principles, more specifically proximity principle and similarity principle. We report on a core part of a formal verification case study in which the new state picture design and the SMGA tool largely contributed to the successful completion of the formal proof that MCS protocol enjoys the mutual exclusion property. The lessons learned acquired through our experiments are summarized as two groups of tips. The first group is some new tips on how to make state picture designs. The second one is some tips on how to conjecture state machine characteristics by using the SMGA tool. We also report on one more case study in which the state picture design has been made for the mutual exclusion protocol invented by Anderson (called Anderson protocol) and some characteristics of the protocol have been discovered based on the tips.
C1 [Bui, Dang Duy; Ogata, Kazuhiro] Japan Adv Inst Sci & Technol JAIST, Sch Informat Sci, 1-1 Asahidai, Nomi, Ishikawa 9231292, Japan.
C3 Japan Advanced Institute of Science & Technology (JAIST)
RP Ogata, K (corresponding author), Japan Adv Inst Sci & Technol JAIST, Sch Informat Sci, 1-1 Asahidai, Nomi, Ishikawa 9231292, Japan.
EM bddang@jaist.ac.jp; ogata@jaist.ac.jp
OI Bui, Dang Duy/0000-0002-2700-1762
FU JSPS KAKENHI [JP19H04082]; FY2020
FX This work was partially supported by JSPS KAKENHI Grant Number
   JP19H04082 and FY2020 grant-in-aid for new technology research
   activities at universities (SHIBUYA SCIENCE CULTURE AND SPORTS
   FOUNDATION).
CR Anderson T. E., 1990, IEEE Transactions on Parallel and Distributed Systems, V1, P6, DOI 10.1109/71.80120
   Artho C, 2007, P INT COMP SOFTW APP, P541
   Artho C, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1102, DOI 10.1109/ASE.2019.00112
   Aung MT., 2018, INT J SOFTW ENG COMP, V4, P1, DOI [10.15282/ijsecs.4.2.2018.1.0045, DOI 10.15282/IJSECS.4.2.2018.1.0045]
   Beschastnikh I, 2020, ACM T SOFTW ENG METH, V29, DOI 10.1145/3375633
   Brodlie KW, 1992, SCI VISUALIZATION TE, DOI DOI 10.1007/978-3-642-76942-9
   Bui DD, 2019, JVLC, V2019, P105, DOI [10.18293/JVLC2019-N2-012, DOI 10.18293/JVLC2019-N2-012]
   Caine K, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P981, DOI 10.1145/2858036.2858498
   Cao F., 2004, Computing and Visualization in Science, V7, P3, DOI 10.1007/s00791-004-0123-6
   Carpendale S, 2008, LECT NOTES COMPUT SC, V4950, P19, DOI 10.1007/978-3-540-70956-5_2
   Clavel M., 2007, ALL MAUDE A HIGH PER, DOI DOI 10.1007/978-3-540-71999-1
   Desolneux A, 2003, IEEE T PATTERN ANAL, V25, P508, DOI 10.1109/TPAMI.2003.1190576
   Garae J, 2016, IEEE TRUST BIG, P1923, DOI [10.1109/TrustCom.2016.0294, 10.1109/TrustCom.2016.292]
   Hwang W, 2010, COMMUN ACM, V53, P130, DOI 10.1145/1735223.1735255
   Isenberg T, 2013, IEEE T VIS COMPUT GR, V19, P2818, DOI 10.1109/TVCG.2013.126
   Lamport L, 1998, ACM T COMPUT SYST, V16, P133, DOI 10.1145/279227.279229
   Magee J., 2000, Proceedings of the 2000 International Conference on Software Engineering. ICSE 2000 the New Millennium, P499, DOI 10.1109/ICSE.2000.870440
   MELLORCRUMMEY JM, 1991, ACM T COMPUT SYST, V9, P21, DOI 10.1145/103727.103729
   Merino L, 2018, J SYST SOFTWARE, V144, P165, DOI 10.1016/j.jss.2018.06.027
   Nesbitt KV, 2002, SIXTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P737, DOI 10.1109/IV.2002.1028859
   Ogata, 2020, 26 INT DMS C VIS VIS, P7, DOI [10.18293/DMSVIVA20-007, DOI 10.18293/DMSVIVA20-007]
   Schmettow M, 2012, COMMUN ACM, V55, P64, DOI 10.1145/2133806.2133824
   Nguyen TTT, 2018, LECT NOTES COMPUT SC, V10795, P3, DOI 10.1007/978-3-319-90104-6_1
   Nguyen TTT, 2017, 2017 IEEE 15TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 15TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 3RD INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS(DASC/PICOM/DATACOM/CYBERSCI, P604, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2017.107
   Nguyen TTT, 2017, 2017 ANNUAL CONFERENCE ON SOFTWARE ANALYSIS, TESTING AND EVOLUTION (SATE 2017), P53, DOI 10.1109/SATE.2017.15
   Todorovic D., 2008, Scholarpedia, V3, P5345, DOI [DOI 10.4249/SCHOLARPEDIA.5345, 10.4249/scholarpedia.5345]
   Tran DD, 2020, ASIA PAC SOFWR ENG, P21, DOI 10.1109/APSEC51365.2020.00010
   Wagemans J, 2012, PSYCHOL BULL, V138, P1172, DOI 10.1037/a0029333
   Wagemans J, 2012, PSYCHOL BULL, V138, P1218, DOI 10.1037/a0029334
   Walter JE, 2001, WIREL NETW, V7, P585, DOI 10.1023/A:1012363200403
   Ware C., 2020, INFORM VISUALIZATION
   Yalcinkaya M, 2019, ENG CONSTR ARCHIT MA, V26, P1024, DOI 10.1108/ECAM-10-2017-0226
NR 32
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2022
VL 81
IS 1
BP 237
EP 272
DI 10.1007/s11042-021-10992-z
EA MAY 2021
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA YK3LN
UT WOS:000655178800003
OA hybrid
DA 2024-07-18
ER

PT J
AU Afif, M
   Ayachi, R
   Said, Y
   Atri, M
AF Afif, Mouna
   Ayachi, Riadh
   Said, Yahia
   Atri, Mohamed
TI Deep learning-based application for indoor wayfinding assistance
   navigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Indoor sign detection; Indoor wayfinding; Blind and visually impaired
   persons; Deep learning; Convolution neural network (CNN)
ID OBJECT RECOGNITION
AB There is an increasing need to develop new adaptive technologies and new wayfinding assistance systems for blind and visually impaired persons in order to improve their daily lives. To address this need, we propose in this paper to develop a new deep learning-based indoor wayfinding assistance system consisting of detecting landmark indoor signs. Assistive technologies used for blind and sighted persons used to support daily activities to improve social inclusion are developing very fast. Training and testing experiments were performed on the proposed indoor signage dataset. Through the experiments conducted, we demonstrated the efficiency of the proposed indoor wayfinding aid system. We obtained 93.45% as a mean average precision (mAP) of the proposed indoor wayfinding and signage detection system.
C1 [Afif, Mouna; Ayachi, Riadh; Said, Yahia; Atri, Mohamed] Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect EE, Monastir, Tunisia.
   [Said, Yahia] Northern Border Univ, Coll Engn, Elect Engn Dept, Ar Ar, Saudi Arabia.
   [Atri, Mohamed] King Khalid Univ, Coll Comp Sci, Abha, Saudi Arabia.
C3 Universite de Monastir; Northern Border University; King Khalid
   University
RP Afif, M (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Elect & Microelect EE, Monastir, Tunisia.
EM mouna.afif@outlook.fr
RI Ayachi, Riadh/AAU-2160-2020; Said, Yahia/A-7333-2018; ATRI,
   Mohamed/C-4069-2014
OI Ayachi, Riadh/0000-0003-4683-9592; Said, Yahia/0000-0003-0613-4037;
   ATRI, Mohamed/0000-0001-8528-5647
CR AFIF M, 2018, INT C SCI EL TECHN I, P364, DOI DOI 10.1007/978-3-030-21005-2_35
   Afif M, 2020, NEURAL PROCESS LETT, V51, P2827, DOI 10.1007/s11063-020-10231-w
   Afif M, 2020, MULTIMED TOOLS APPL, V79, P31645, DOI 10.1007/s11042-020-09662-3
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Ali A, 2019, INT C PAR DISTRIB SY, P125, DOI 10.1109/ICPADS47876.2019.00025
   Ayachi R, 2020, NEURAL PROCESS LETT, V52, P2655, DOI 10.1007/s11063-020-10367-9
   Ayachi R, 2020, NEURAL PROCESS LETT, V51, P837, DOI 10.1007/s11063-019-10115-8
   Bashiri FS, 2018, LECT NOTES COMPUT SC, V11241, P500, DOI 10.1007/978-3-030-03801-4_44
   Chen ZJ, 2020, SAFETY SCI, V130, DOI 10.1016/j.ssci.2020.104812
   Chen ZJ, 2019, EXPERT SYST APPL, V138, DOI 10.1016/j.eswa.2019.06.041
   Fei Z., 2017, 2017 ASABE ANN INT M, P1
   Fusco Giovanni, 2020, Comput Help People Spec Needs, V12376, P485, DOI 10.1007/978-3-030-58796-3_56
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kanwal N, 2015, APPL BIONICS BIOMECH, V2015, DOI 10.1155/2015/479857
   Kingma DP, 2014, ARXIV 2014 ARXIV PRE
   Kunhoth J, 2020, HUM-CENT COMPUT INFO, V10, DOI 10.1186/s13673-020-00222-0
   Lin BS, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061371
   Mekhalfi ML, 2016, EXPERT SYST APPL, V46, P129, DOI 10.1016/j.eswa.2015.09.054
   Rituerto A, 2016, ASSETS'16: PROCEEDINGS OF THE 18TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P287, DOI 10.1145/2982142.2982202
   Ruder S., 2016, ARXIV
   Sivan S, 2016, 7TH INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND NETWORKING TECHNOLOGIES (ICCCNT 2016), DOI 10.1145/2967878.2967923
   Tepelea L, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ENGINEERING OF MODERN ELECTRIC SYSTEMS (EMES), P228, DOI 10.1109/EMES.2017.7980421
   Tian Y., 2014, Computer Vision and Machine Learning with RGB-D Sensors, P173, DOI DOI 10.1007/978-3-319-08651-4_9
   Tian YL, 2010, LECT NOTES COMPUT SC, V6180, P255, DOI 10.1007/978-3-642-14100-3_38
   Trabelsi R, 2019, NEUROCOMPUTING, V330, P94, DOI 10.1016/j.neucom.2018.11.032
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wang SH, 2013, NETW MODEL ANAL HLTH, V2, P81, DOI 10.1007/s13721-013-0027-9
   Yang K., 1954, SENSORS, V2016, P16
   Ye C, 2018, IEEE T NEUR SYS REH, V26, P441, DOI 10.1109/TNSRE.2017.2748419
   Ye Cang, 2016, IEEE Syst Man Cybern Mag, V2, P33, DOI 10.1109/MSMC.2015.2501167
NR 30
TC 3
Z9 3
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 18
BP 27115
EP 27130
DI 10.1007/s11042-021-10999-6
EA MAY 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TR2TB
UT WOS:000650124300001
DA 2024-07-18
ER

PT J
AU Bhardwaj, R
AF Bhardwaj, Rupali
TI An improved separable reversible patient data hiding algorithm for
   E-healthcare
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electronic Patient Information (EPI); Separable reversible data hiding;
   Pixel geometry; Bit error rate
AB In the telemedicine industry, a standout among the most significant issue is the exchange of Electronic Patient Information (EPI) between patient and a doctor that are remotely connected. A minute change to EPI may result in a wrong diagnosis for the patient. To ensure secure and safe communication for telemedicine applications, a dual-image separable block-based reversible data hiding algorithm in encrypted domain for embedding secret message in base(5) numeral framework is proposed here. The proposed scheme has not been suffering from underflow and overflow problem so that empowering it to embed and recover information precisely from low-intensity pixels too. This property makes our proposed methodology truly reasonable for its utilization on medical images. To prove the effectiveness of our proposed approach, experiments have been performed on different test images. The average PSNR value is 54.10 dB for an embedding capacity of 327,680 bits for all test images which demonstrates that the method is capable of giving good quality stego images even at high payload also. The experimental study revealed that for all types of test images, the proposed methodology altogether beaten all the compared methodologies in its ability to embed secret message and precisely recover it by maintaining the visual quality of stego images too.
C1 [Bhardwaj, Rupali] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Bhardwaj, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala, Punjab, India.
EM rupali.bhardwaj@thapar.edu
RI Bhardwaj, Rupali/AAO-6850-2021
CR Abdulla AA, 2020, ARXIV 200412467
   Abdulla AA, 2019, EXPLOITING SIMILARIT
   Bhalerao S, 2019, PATTERN RECOGN LETT, V125, P463, DOI 10.1016/j.patrec.2019.06.004
   Bhardwaj R, 2020, PATTERN RECOGN LETT, V139, P60, DOI 10.1016/j.patrec.2018.01.014
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chen YC, 2014, J VIS COMMUN IMAGE R, V25, P1164, DOI 10.1016/j.jvcir.2014.04.003
   Chi LP, 2018, MULTIMED TOOLS APPL, V77, P8785, DOI 10.1007/s11042-017-4774-y
   Hong W, 2012, IEEE SIGNAL PROC LET, V19, P199, DOI 10.1109/LSP.2012.2187334
   Kim YS., 2015, Applied Mathematics Information Sciences, V9, P2627, DOI [10.12988/ams.2015.52103, DOI 10.12988/AMS.2015.52103]
   Lee CF, 2013, TELECOMMUN SYST, V52, P2237, DOI 10.1007/s11235-011-9529-x
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Lu TC, 2017, MULTIMED TOOLS APPL, V76, P23903, DOI 10.1007/s11042-016-4135-2
   Lu TC, 2015, SIGNAL PROCESS, V115, P195, DOI 10.1016/j.sigpro.2015.03.017
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   Mansour RF, 2019, MULTIDIM SYST SIGN P, V30, P791, DOI 10.1007/s11045-018-0575-3
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Paillier P, 1999, LECT NOTES COMPUT SC, V1592, P223
   Parah SA, 2017, MULTIMED TOOLS APPL, V76, P3943, DOI 10.1007/s11042-016-4196-2
   Parah SA, 2017, J BIOMED INFORM, V66, P214, DOI 10.1016/j.jbi.2017.01.006
   Puech W, 2008, PROC SPIE, V6819, DOI 10.1117/12.766754
   Qian ZX, 2016, MULTIMED TOOLS APPL, V75, P13749, DOI 10.1007/s11042-015-2760-9
   Shi YQ, 2005, LECT NOTES COMPUT SC, V3304, P1
   Shiu HJ, 2017, COMPUT METH PROG BIO, V151, P159, DOI 10.1016/j.cmpb.2017.08.015
   Tai WL, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10010023
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wu XT, 2014, SIGNAL PROCESS, V104, P387, DOI 10.1016/j.sigpro.2014.04.032
   Xiao B, 2010, IEEE ICC
   Yao H, 2017, SIGNAL PROCESS, V135, P26, DOI 10.1016/j.sigpro.2016.12.029
   Zhang XP, 2011, IEEE SIGNAL PROC LET, V18, P255, DOI 10.1109/LSP.2011.2114651
NR 29
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26429
EP 26449
DI 10.1007/s11042-020-10344-3
EA MAY 2021
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000646953200002
DA 2024-07-18
ER

PT J
AU Shikalgar, AJ
   Sonavane, S
AF Shikalgar, Arifa Javid
   Sonavane, Shefali
TI A novel gradient foster shared-representation convolutional network
   optimization for multi-modalities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network (CNN); Multi-modalities; Non-convex
   optimization; Gradient foster shared-representation convolutional
   network; GoogLeNet; Stochastic variance reduced ascension approach
AB Significant growth has been made with multi-modal data as its entrance in the field of deep learning; whereas, Convolutional Neural Network (CNN) provides sufficient training data to develop a representative encrusted image. Yet, the multi-modality approach in CNN affect the performance by slowly converge the variance along with high-dimensionality, heterogeneity and non-aconvex optimization problems. To abridge these issues, a novel Gradient Foster Shared-representation Convolutional Network (GFSCN) framework is proposed, which improve and optimize the performance interms of accuracy and dimensionality reduction. Initially, the framework incorporates a multiple scant weighted de-noising autoencoder to solve the heterogeneity problem and reduces the dimensionality of data by transforming shared feature representation. Consequently, the work integrated enhanced stochastic variance reduced ascension approach. This approach diminishes the non-convex optimization problem through integrating two gradients consuming mini-batches, which reduced the loss function thereby achieves faster convergence even with the usage of larger dataset. Thus, the proposed framework achieves better performance in terms of achieving utmost accuracy with faster convergence and reduced variance.
C1 [Shikalgar, Arifa Javid; Sonavane, Shefali] Walchand Coll Engn Sangli, Sangli, Maharashtra, India.
C3 Walchand College of Engineering
RP Shikalgar, AJ (corresponding author), Walchand Coll Engn Sangli, Sangli, Maharashtra, India.
EM arifajavidshikalgar213@gmail.com
RI Sonavane, Shefali/AAS-5761-2021
OI Sonavane, Shefali/0000-0003-4075-5857
CR Chang DQ, 2019, IEEE T NEUR NET LEAR, V30, P3338, DOI 10.1109/TNNLS.2019.2891088
   Chen YT, 2021, VISUAL COMPUT, V37, P1691, DOI 10.1007/s00371-020-01932-3
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Dolz J, 2019, IEEE T MED IMAGING, V38, P1116, DOI 10.1109/TMI.2018.2878669
   Hardt M, 2018, J MACH LEARN RES, V19
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Jeon, 2019, IEEE T CIRCUITS SYST
   Law S, 2020, INT J GEOGR INF SCI, V34, P681, DOI 10.1080/13658816.2018.1555832
   Lu WP, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102794
   Passos LA., 2019, APPL SOFT COMPUT, V2019
   Poczos, 2020, ARXIV PREPRINT ARXIV
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sun L, 2020, IEEE J-STARS, V13, P1174, DOI 10.1109/JSTARS.2020.2980576
   Sun WJ, 2016, MEASUREMENT, V89, P171, DOI 10.1016/j.measurement.2016.04.007
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   Xiang LY, 2018, IEEE ACCESS, V6, P35305, DOI 10.1109/ACCESS.2018.2847037
   Yu H, 2019, AAAI CONF ARTIF INTE, P5693
   Yuan K, 2016, SIAM J OPTIMIZ, V26, P1835, DOI 10.1137/130943170
   Zhang YT, 2020, MULTIMED TOOLS APPL, V79, P14751, DOI 10.1007/s11042-019-7240-1
NR 23
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 17
BP 26181
EP 26198
DI 10.1007/s11042-021-10774-7
EA APR 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE8TI
UT WOS:000645531100003
DA 2024-07-18
ER

PT J
AU Akdeniz, F
   Kayikcioglu, I
   Kayikcioglu, T
AF Akdeniz, Fulya
   Kayikcioglu, Ilknur
   Kayikcioglu, Temel
TI Classification of cardiac arrhythmias using Zhao-Atlas-Marks
   time-frequency distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiogram (ECG); Arrhythmia classification; Zhao-Atlas mark
   distribution; Cubic support vector machine; Telemedicine
ID FEATURE-EXTRACTION; HEARTBEAT CLASSIFICATION; ECG; TRANSFORMS
AB The major function of heart is to pump blood to tissues and organs necessary for the body metabolism. It is therefore one of the organs that affects human life. However, adverse situations, such as paralysis and death are the major problems that can lead to a heart failure. Healthy heart is very important to live comfortably. To prevent adverse events, it is important to monitor and detect heart diseases early. The aim of proposed method is to determine and classify nine types of ECG arrhythmias, including normal beats. A large feature set was obtained from the MIT-BIH Arrhythmia database. Zhao Atlas-Mark time-frequency distribution was used to extract the feature set. Five classification algorithms have been tried. The Cubic Support Vector Machine algorithm yielded best performance results. The proposed method achieved accuracy, sensitivity, specificity, F-score, positive predictive, and negative predictive values of 96.39%, 94.22%, 92.02%, 93.91%, 93.90% and 96.72%, respectively. Considering the data size, performance values, and number of arrythmias, the proposed method provided superiority to other studies. Furthermore, running time is suitable for telemedicine systems.
C1 [Akdeniz, Fulya] Kocaeli Univ, Dept Comp Engn, Kocaeli, Turkey.
   [Akdeniz, Fulya] Recep Tayyip Erdogan Univ, Dept Comp Engn, Rize, Turkey.
   [Kayikcioglu, Ilknur] Karadeniz Tech Univ, Dept Comp Engn, Trabzon, Turkey.
   [Kayikcioglu, Ilknur] Bulent Ecevit Univ, Dept Comp Engn, Zonguldak, Turkey.
   [Kayikcioglu, Temel] Karadeniz Tech Univ, Dept Elect & Elect Engn, Trabzon, Turkey.
C3 Kocaeli University; Recep Tayyip Erdogan University; Karadeniz Technical
   University; Zonguldak Bulent Ecevit University; Karadeniz Technical
   University
RP Akdeniz, F (corresponding author), Kocaeli Univ, Dept Comp Engn, Kocaeli, Turkey.; Akdeniz, F (corresponding author), Recep Tayyip Erdogan Univ, Dept Comp Engn, Rize, Turkey.
EM fulya.akdeniz@kocaeli.edu.tr; ilknurkayikcioglu@ktu.edu.tr;
   tkayikci@ktu.edu.tr
RI Kayikcioglu, Temel/ABB-6149-2020
OI kayikcioglu, ilknur/0000-0002-3991-5676
FU TUBITAK [114E452]
FX This study has been supported by the TUBITAK under grant 114E452 project
   within the scope of 1003 programs.
CR Abdalla FYO, 2019, SIGNAL IMAGE VIDEO P, V13, P1283, DOI 10.1007/s11760-019-01479-4
   Acharya UR, 2017, COMPUT BIOL MED, V89, P389, DOI 10.1016/j.compbiomed.2017.08.022
   Akdeniz F, 2016, 2016 39TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P409, DOI 10.1109/TSP.2016.7760908
   Alqudah AM, 2019, AUSTRALAS PHYS ENG S, V42, P149, DOI 10.1007/s13246-019-00722-z
   Amorim P, 2018, COMPUT METH PROG BIO, V161, P125, DOI 10.1016/j.cmpb.2018.04.021
   Bastiaans MJ, 2002, IEEE SIGNAL PROC LET, V9, P378, DOI 10.1109/LSP.2002.805118
   Benali R, 2012, J MED SYST, V36, P883, DOI 10.1007/s10916-010-9551-7
   Chiu CY, 2013, INT J COMPUT INTELL, V12, DOI 10.1142/S1469026813400051
   Dalvi Rodolfo de Figueiredo, 2016, Res. Biomed. Eng., V32, P318, DOI 10.1590/2446-4740.05815
   De Capua C, 2010, IEEE T INSTRUM MEAS, V59, P2530, DOI 10.1109/TIM.2010.2057652
   El Rahman SA, 2019, MULTIMED TOOLS APPL, V78, P17555, DOI 10.1007/s11042-019-7152-0
   Engin M, 2004, PATTERN RECOGN LETT, V25, P1715, DOI 10.1016/j.patrec.2004.06.014
   GUO ZY, 1994, IEEE T SIGNAL PROCES, V42, P1700, DOI 10.1109/78.298277
   Hadjidimitriou SK, 2013, IEEE T AFFECT COMPUT, V4, P161, DOI 10.1109/T-AFFC.2013.6
   Hlawatsch F, 1992, IEEE SIGNAL PROC MAG, V9, P21, DOI 10.1109/79.127284
   Hou BR, 2020, IEEE T INSTRUM MEAS, V69, P1232, DOI 10.1109/TIM.2019.2910342
   Huang HF, 2012, J MED SYST, V36, P1235, DOI 10.1007/s10916-010-9585-x
   Hussein AF, 2018, J MED SYST, V42, DOI 10.1007/s10916-017-0871-8
   Karpagachelvi S, 2012, NEURAL COMPUT APPL, V21, P1331, DOI 10.1007/s00521-011-0572-z
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Krishnakumari A, 2016, PROCEDIA ENGINEER, V144, P297, DOI 10.1016/j.proeng.2016.05.136
   Lin CC, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/712474
   Lin CC, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P650, DOI 10.1109/IS3C.2014.175
   Luz EJD, 2016, COMPUT METH PROG BIO, V127, P144, DOI 10.1016/j.cmpb.2015.12.008
   Luz EJD, 2013, EXPERT SYST APPL, V40, P3561, DOI 10.1016/j.eswa.2012.12.063
   Mert A, 2016, PHYSIOL MEAS, V37, P530, DOI 10.1088/0967-3334/37/4/530
   Muthuvel K, 2019, MULTIMED TOOLS APPL, V78, P35351, DOI 10.1007/s11042-019-08132-9
   Nascimento NMM, 2020, CIRC SYST SIGNAL PR, V39, P631, DOI 10.1007/s00034-019-01196-w
   Nurmaini S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142921
   Oh SL, 2018, COMPUT BIOL MED, V102, P278, DOI 10.1016/j.compbiomed.2018.06.002
   Pal M, 2010, IEEE T GEOSCI REMOTE, V48, P2297, DOI 10.1109/TGRS.2009.2039484
   Pan GL, 2018, MULTIMED TOOLS APPL, V77, P21905, DOI 10.1007/s11042-017-5225-5
   Park J, 2017, J MED SYST, V41, DOI 10.1007/s10916-016-0660-9
   Qurraie SS, 2017, BIOMED ENG LETT, V7, P325
   Rai HM, 2013, MEASUREMENT, V46, P3238, DOI 10.1016/j.measurement.2013.05.021
   Rajesh KNVPS, 2017, COMPUT BIOL MED, V87, P271, DOI 10.1016/j.compbiomed.2017.06.006
   Rashkovska A., 2011, 2011 Proceedings of 34th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO 20111), P262
   Son J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17061360
   Venkatesan C, 2018, MULTIMED TOOLS APPL, V77, P10365, DOI 10.1007/s11042-018-5762-6
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   Yeh YC, 2012, EXPERT SYST APPL, V39, P1000, DOI 10.1016/j.eswa.2011.07.101
   Yildirim O, 2019, COMPUT METH PROG BIO, V176, P121, DOI 10.1016/j.cmpb.2019.05.004
   Zacharias, 2014, ANAL VIBROACOUSTIC M
   ZHAO YX, 1990, IEEE T ACOUST SPEECH, V38, P1084, DOI 10.1109/29.57537
NR 44
TC 1
Z9 1
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30523
EP 30537
DI 10.1007/s11042-021-10945-6
EA APR 2021
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000644268000001
DA 2024-07-18
ER

PT J
AU Kiani, A
   Ahmadi, FF
   Ebadi, H
AF Kiani, Abbas
   Ahmadi, Farshid Farnood
   Ebadi, Hamid
TI Correction of training process in object-based image interpretation via
   knowledge based system capabilities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; High spatial resolution image; Knowledge based system;
   Object based interpretation; Remote sensing; Support vector machine
ID REMOTE-SENSING DATA; SAMPLE SELECTION; CLASSIFICATION
AB For accurate interpretation of high-resolution images, correct training-samples are required to model the decision-making process for data classification. The automatic production of that is an important step; however, the control and correction, whether at the level of pruning the wrong data or resolving their defects, should be considered. Accordingly, in this research, a hybrid (combined deductive and inductive) interpretation system by modeling and improving the training processing was proposed for very high-resolution images. In other words, an automatic knowledge-based method is performed to apply the modeling of the ontological relationships in order to train and control the object-based support vector machine classification. In the correction process, sequence stages including automatic separation and expanding the training data and the ontology properties of the target classes for improving the defect of training data were used. Finally, high-resolution test images are used to validate the results and evaluate the method. In this respect, the proposed method is tested in different implementation cases and compared with other algorithms in each step. The experimental results indicate the reliability and efficiency of the proposed method.
C1 [Kiani, Abbas] Babol Nooshirvani Univ Technol, Dept Geomat Engn, Babol, Iran.
   [Ahmadi, Farshid Farnood] Univ Tabriz, Dept Geomat Engn, 29 Bahman Blvd, Tabriz, Iran.
   [Ebadi, Hamid] KN Toosi Univ Technol, Fac Geodesy & Geomat Engn, Tehran, Iran.
C3 University of Tabriz; K. N. Toosi University of Technology
RP Ahmadi, FF (corresponding author), Univ Tabriz, Dept Geomat Engn, 29 Bahman Blvd, Tabriz, Iran.
EM Farnood@tabrizu.ac.ir
RI kiani, abbas/AAD-8879-2022
CR [Anonymous], 2014, INT ARCH PHOTOGRAMM, DOI DOI 10.5194/ISPRSARCHIVES-XL-7-63-2014
   Benz UC, 2004, ISPRS J PHOTOGRAMM, V58, P239, DOI 10.1016/j.isprsjprs.2003.10.002
   Bracewell R. N., 1986, FOURIER TRANSFORM IT
   Buschenfeld T, 2012, ISPRS ANN PHOTOGRAMM, VI-7, P117
   Chu, 2012, REM SENS ENV TRANSP
   De Leeuw J, 2006, INT J REMOTE SENS, V27, P223, DOI 10.1080/01431160500275762
   Dragut L, 2014, ISPRS J PHOTOGRAMM, V88, P119, DOI 10.1016/j.isprsjprs.2013.11.018
   Feitosa, 2001, WORLD SCI, P108, DOI [10.1142/9789812777249_0010, DOI 10.1142/9789812777249_0010]
   Foody GM, 2004, PHOTOGRAMM ENG REM S, V70, P627, DOI 10.14358/PERS.70.5.627
   Gerke M, 2014, NORMALIZED DSM HEIGH
   Hajahmadi S, 2013, INT ARCH PHOTOGRAMM, V40-1-W3, P185
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang X, 2013, IEEE T GEOSCI REMOTE, V51, P257, DOI 10.1109/TGRS.2012.2202912
   Jia K, 2015, GEOCARTO INT, V30, P882, DOI 10.1080/10106049.2014.997310
   Jia K, 2014, REMOTE SENS LETT, V5, P148, DOI 10.1080/2150704X.2014.889862
   Khatami R, 2016, REMOTE SENS ENVIRON, V177, P89, DOI 10.1016/j.rse.2016.02.028
   Kiani A, 2020, J INDIAN SOC REMOTE, V48, P197, DOI 10.1007/s12524-019-01069-4
   Kiani A, 2019, ISPRS INT J GEO-INF, V8, DOI 10.3390/ijgi8090398
   Kumar DA, 2017, IEEE J-STARS, V10, P5201, DOI 10.1109/JSTARS.2017.2743982
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Lid, 2015, COMP ENG EL ICECEE
   Ma L, 2017, ISPRS J PHOTOGRAMM, V130, P277, DOI 10.1016/j.isprsjprs.2017.06.001
   Maxwell AE, 2018, INT J REMOTE SENS, V39, P2784, DOI 10.1080/01431161.2018.1433343
   McFeeters SK, 1996, INT J REMOTE SENS, V17, P1425, DOI 10.1080/01431169608948714
   Millard K, 2015, REMOTE SENS-BASEL, V7, P8489, DOI 10.3390/rs70708489
   Novack T, 2017, PFG-J PHOTOGRAMM REM, V85, P365, DOI 10.1007/s41064-017-0039-7
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prasad S, 2008, IEEE T GEOSCI REMOTE, V46, P1448, DOI 10.1109/TGRS.2008.916207
   Radoux J, 2014, REMOTE SENS-BASEL, V6, P3965, DOI 10.3390/rs6053965
   Rottensteiner F, 2013, ISPRS Test Project on Urban Classification and 3D Building Reconstruction
   Rouse J.W., 1974, P 3 EARTH RESOURCE T, V351, P309
   Salah M., 2017, J. Geomat, V11, P1
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   van der Linden S, 2015, REMOTE SENS-BASEL, V7, P11249, DOI 10.3390/rs70911249
   Xiong XJ, 2000, INT C PATT RECOG, P897, DOI 10.1109/ICPR.2000.903688
   Yang C, 2018, INT CONF GEOINFORM
   Yu XC, 2014, IEEE INT FUZZY SYST, P223, DOI 10.1109/FUZZ-IEEE.2014.6891759
   Zhen Z, 2013, INT J REMOTE SENS, V34, P6914, DOI 10.1080/01431161.2013.810822
NR 38
TC 2
Z9 2
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 24901
EP 24924
DI 10.1007/s11042-021-10824-0
EA APR 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000639518700008
DA 2024-07-18
ER

PT J
AU Li, JJ
   Tang, PQ
   Wu, Y
   Pan, MA
   Tang, Z
   Hui, GB
AF Li, Jianjun
   Tang, Peiqi
   Wu, Yong
   Pan, Mian
   Tang, Zheng
   Hui, Guobao
TI Scene change detection: semantic and depth information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene change; Depth estimation; Feature fusion; Semantic information
AB Change detection is widely used in city construction, remote image detection, autonomous driving and so on. The most important challenge in change detection is how to define the real change, that is to say, how to detect the real changes while ignoring the unexpected changes? such as varying illumination, shadows, seasonal scene changes. Motivated by the key issue, in this paper, we propose a novel two-classified method that utilizes the depth information to assist the semantic information for better detecting changes. A gradual modification strategy is also designed to combine the high-level semantics and the low-level edge-sensitive features to achieve better depth estimation. The proposed framework was evaluated by using the VL-CMU-CD streetscape change detection dataset. Both quantitative and qualitative experiments have been implemented for evaluating the performance of the framework under different light and seasons. Experimental results show that the proposed method outperforms most of the current state-of-the-art results.
C1 [Li, Jianjun; Tang, Peiqi; Wu, Yong; Pan, Mian] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.
   [Li, Jianjun; Tang, Peiqi; Wu, Yong; Pan, Mian] Key Lab Brain Machine Collaborat Intelligence Zhe, Hangzhou, Peoples R China.
   [Tang, Zheng; Hui, Guobao] Key Lab Data Link Technol CETC, Xian, Peoples R China.
C3 Hangzhou Dianzi University
RP Li, JJ (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou, Peoples R China.; Li, JJ (corresponding author), Key Lab Brain Machine Collaborat Intelligence Zhe, Hangzhou, Peoples R China.
EM jianjun.li@hdu.edu.cn; wuyong@hdu.edu.cn; ai@hdu.edu.cn;
   tangzheng@gmail.com; huiguobao@gmail.com
OI Li, Jianjun/0000-0001-6658-9709
FU National Science Fund of China [61871170, JCKY2017210A001]
FX This work was supported in part by National Science Fund of China
   no.61871170 and The National Defense Basic Research Program of
   JCKY2017210A001.
CR Alcantarilla PF, 2018, AUTON ROBOT, V42, P1301, DOI 10.1007/s10514-018-9734-5
   Badino H, 2011, IEEE INT VEH SYM, P794, DOI 10.1109/IVS.2011.5940504
   Badino H, 2012, IEEE INT CONF ROBOT, P1635, DOI 10.1109/ICRA.2012.6224716
   Bovolo F, 2007, IEEE T GEOSCI REMOTE, V45, P218, DOI 10.1109/TGRS.2006.885408
   Bruzzone L, 2002, IEEE T IMAGE PROCESS, V11, P452, DOI 10.1109/TIP.2002.999678
   Chen WJ, 2019, PROC CVPR IEEE, P7234, DOI 10.1109/CVPR.2019.00741
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Guo E., 2018, ARXIV181009111
   Hayat H, 2016, INT C ART INT IND EN
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiaojiao Zhao, 2014, 2014 International Joint Conference on Neural Networks (IJCNN), P411, DOI 10.1109/IJCNN.2014.6889510
   Khan S, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Leng L, 2014, INT C IM SIGN PROC
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2011, J NETW COMPUT APPL, V34, P1979, DOI 10.1016/j.jnca.2011.07.003
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   LILLESTRAND RL, 1972, IEEE T COMPUT, VC 21, P654, DOI 10.1109/T-C.1972.223570
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo Y, 2018, PROC CVPR IEEE, P155, DOI 10.1109/CVPR.2018.00024
   Ma WP, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11060626
   Mahmoodzadeh H, 2007, INT J ENVIRON RES, V1, P35
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Moser G, 2011, IEEE GEOSCI REMOTE S, V8, P725, DOI 10.1109/LGRS.2010.2102333
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Peng DF, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11111382
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosin PL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P274, DOI 10.1109/ICCV.1998.710730
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Saha S, 2019, IEEE T GEOSCI REMOTE, V57, P3677, DOI 10.1109/TGRS.2018.2886643
   Sakurada K, 2010, SELF SUPERVISED SIMU
   Sakurada K, 2020, IEEE INT CONF ROBOT, P6861, DOI [10.1109/icra40945.2020.9196985, 10.1109/ICRA40945.2020.9196985]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taneja A, 2011, IEEE I CONF COMP VIS, P2336, DOI 10.1109/ICCV.2011.6126515
   Toth D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P3, DOI 10.1109/IAI.2000.839561
   Toth D, 2001, INT C IM PROC
   ULSTAD MS, 1973, PATTERN RECOGN, V5, P323, DOI 10.1016/0031-3203(73)90024-1
   Xian K, 2018, PROC CVPR IEEE, P311, DOI 10.1109/CVPR.2018.00040
NR 50
TC 0
Z9 1
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19301
EP 19319
DI 10.1007/s11042-021-10793-4
EA APR 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000636626800001
DA 2024-07-18
ER

PT J
AU Sharma, A
   Alsadoon, A
   Prasad, PWC
   Al-Dala'in, T
   Haddad, S
AF Sharma, Arma
   Alsadoon, Abeer
   Prasad, P. W. C.
   Al-Dala'in, Thair
   Haddad, Sami
TI A novel augmented reality visualization in jaw surgery: enhanced ICP
   based modified rotation invariant and modified correntropy
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Augmented reality; Jaw surgery; Image registration; Correntropy;
   Iterative closest point (ICP); Global reference point; Rotation
   invariant
AB Image registration, accuracy, processing time and occlusions are the main limitations of augmented reality (AR) based jaw surgery. Therefore, the main aim of this paper is to reduce the registration error, which will help in improving the accuracy and reducing the processing time. Also, it aims to remove outliers and remove the registration outcomes trapped in local minima to improve the alignment problems and remove the occlusion caused by surgery instrument. The enhanced Iterative Closest Point (ICP) algorithm with rotation invariant and correntropy was used for the proposed system. Markerless image registration technique was used for AR-based jaw surgery. The problem of occlusion caused by surgical tools and blood is solved by using stereo based tracing with occlusion handling techniques. This research reduced alignment error 0.59 mm similar to 0.62 mm against 0.69 similar to 0.72 mm of state-of-the-art solution. The processing time of video frames was enhanced to 11.9 similar to 12.8 fps against 8 similar to 9.15 fps in state-of-the-art solution. This paper is focused on providing fast and accurate AR-based system for jaw surgery. The proposed system helps in improving the AR visualization during jaw surgery. The combination of methods and technology helped in improving AR visualization for jaw surgery and to overcome the failure caused by a large rotation angle and provides an initial parameter for better image registration. It also enhances performance by removing outliers and noises. The pose refinement stage provides a better result in terms of processing time and accuracy.
C1 [Sharma, Arma; Alsadoon, Abeer; Prasad, P. W. C.; Al-Dala'in, Thair] Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.
   [Alsadoon, Abeer] Crown Inst Higher Educ, Informat Technol Dept, Sydney, NSW, Australia.
   [Alsadoon, Abeer; Al-Dala'in, Thair] Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
   [Haddad, Sami] Cent Coast Area Hlth, Dept Oral & Maxillofacial Serv, Gosford, Australia.
C3 Charles Sturt University; Western Sydney University; Southern Cross
   University; Florey Institute of Neuroscience & Mental Health
RP Alsadoon, A (corresponding author), Charles Sturt Univ CSU, Sch Comp & Math, Wagga Wagga, NSW, Australia.; Alsadoon, A (corresponding author), Univ Western Sydney UWS, Sch Comp Data & Math Sci, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Southern Cross Univ SCU, Sch Informat Technol, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Crown Inst Higher Educ, Informat Technol Dept, Sydney, NSW, Australia.; Alsadoon, A (corresponding author), Asia Pacific Int Coll APIC, Informat Technol Dept, Sydney, NSW, Australia.
EM aalsadoon@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; withana,
   chandana/0000-0002-3007-687X
CR Basnet BR, 2018, ORAL MAXILLOFAC SURG, V22, P385, DOI 10.1007/s10006-018-0719-5
   Bernhardt S, 2017, MED IMAGE ANAL, V37, P66, DOI 10.1016/j.media.2017.01.007
   Burström G, 2019, SPINE, V44, P1097, DOI 10.1097/BRS.0000000000003006
   Chen XJ, 2015, J BIOMED INFORM, V55, P124, DOI 10.1016/j.jbi.2015.04.003
   De Paolis LT, 2019, MED BIOL ENG COMPUT, V57, P995, DOI 10.1007/s11517-018-1929-6
   Du SY, 2020, PATTERN RECOGN LETT, V132, P91, DOI 10.1016/j.patrec.2018.06.028
   Gribaudo M, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105505
   Gui HJ, 2013, J ORAL MAXIL SURG, V71, P1563, DOI 10.1016/j.joms.2013.04.001
   Hassfeld S, 2001, INT J ORAL MAX SURG, V30, P2, DOI 10.1054/ijom.2000.0024
   Kim TT, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/5716235
   Ma LF, 2019, MED BIOL ENG COMPUT, V57, P47, DOI 10.1007/s11517-018-1861-9
   Ma QC, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.1997
   Murugesan YP, 2018, INT J MED ROBOT COMP, V14, DOI 10.1002/rcs.1889
   Pokhrel S, 2019, INT J MED ROBOT COMP, V15, DOI 10.1002/rcs.1958
   Rose AS, 2019, LARYNGOSCOPE, V129, pS1, DOI 10.1002/lary.28098
   Sakuma I, 2017, INT J MED ROBOT COMP, V13
   Talaat S, 2019, ORTHOD CRANIOFAC RES, V22, P62, DOI 10.1111/ocr.12286
   Wang JC, 2019, INT J COMPUT ASS RAD, V14, P763, DOI 10.1007/s11548-019-01921-5
   Wang R, 2018, IEEE J BIOMED HEALTH, V22, P1540, DOI 10.1109/JBHI.2017.2770214
   Zhang XH, 2019, INT J COMPUT ASS RAD, V14, P1285, DOI 10.1007/s11548-019-01974-6
   Zhu M, 2016, ANN PLAS SURG, V77, P662, DOI 10.1097/SAP.0000000000000644
NR 21
TC 3
Z9 3
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2021
VL 80
IS 16
BP 23923
EP 23947
DI 10.1007/s11042-021-10787-2
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TE3BL
UT WOS:000633749500001
DA 2024-07-18
ER

PT J
AU Anbarasi, A
   Ravi, S
   Vaishnavi, J
   Matla, SVSB
AF Anbarasi, A.
   Ravi, S.
   Vaishnavi, J.
   Matla, S. V. Suresh Babu
TI Computer aided decision support system for mitral valve diagnosis and
   classification using depthwise separable convolution neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Medical imaging; Mitral valve; Random forest;
   Segmentation; Watershed
ID HIDDEN MARKOV MODEL; HEART; STENOSIS; EXTRACTION; DISEASE
AB The significance of mitral valve (MV) treatment is increasing recently because of an aging population. The computer vision-based acquisition and quantification of the valve anatomy becomes helpful for surgical and intercessional planning. The right option of common treatment and implantation is pertinent for the most favorable results. Several studies reported that the decision support system (DSS) could offer decisions based on the virtual involvement planning and prediction models. Generally, the segmentation and classification of MV from the computed tomography (CT) images are highly complicated, owing to the variations in appearance and visibility. In this paper, an efficient automated DSS model is introduced using watershed segmentation with Xception model for the MV classification. It incorporates four modules: bilateral filtering (BF) based preprocessing, watershed segmentation, Xception based feature extraction and random forest (RF) classification. A watershed algorithm with channel separation is used to segment the MV images. The Xception model with random forest (RF) model is utilized for training and classifying images. A detailed simulation is performed on the CT images collected from hospitals. The presented WS-X model is tested and a comparative study is made with the relevant works to highlight its superior nature. The obtained results stressed out that the WS-X model is an appropriate model for the MV problem under various aspects.
C1 [Anbarasi, A.; Ravi, S.; Vaishnavi, J.; Matla, S. V. Suresh Babu] Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Pondicherry, India.
C3 Pondicherry University
RP Ravi, S (corresponding author), Pondicherry Univ, Sch Engn & Technol, Dept Comp Sci, Pondicherry, India.
EM anbarasi.a@gmail.com; sravicite@gmail.com; roshugee@gmail.com;
   suresh.matla@gmail.com
OI A, Anbarasi/0000-0002-2755-8368; Subban, Ravi/0000-0001-7267-9233
CR Ahlstrom C, 2006, ANN BIOMED ENG, V34, P1666, DOI 10.1007/s10439-006-9187-4
   Beucher S., 1992, Scanning Microsc. Suppl, P299
   Brusco M, 2005, P ANN INT IEEE EMBS, P3506, DOI 10.1109/IEMBS.2005.1617235
   Chauhan S, 2008, COMPUT BIOL MED, V38, P221, DOI 10.1016/j.compbiomed.2007.10.006
   CHOLLET F, 2017, PROC CVPR IEEE, P1800, DOI DOI 10.1109/CVPR.2017.195
   Çomak E, 2007, COMPUT BIOL MED, V37, P21, DOI 10.1016/j.compbiomed.2005.11.002
   Criley SR, 2000, COMPUT CARDIOL, V27, P591, DOI 10.1109/CIC.2000.898591
   Funkat A, 2014, THORAC CARDIOV SURG, V62, P380, DOI 10.1055/s-0034-1383430
   Gopalakrishnan K, 2017, CONSTR BUILD MATER, V157, P322, DOI 10.1016/j.conbuildmat.2017.09.110
   Harold JG, 2014, J AM COLL CARDIOL, V63, pE57, DOI [10.1016/j.jacc.2014.02.537, 10.1016/j.jacc.2014.02.536, 10.1016/j.jtcvs.2014.05.014]
   Hebden JE, 1997, COMPUT CARDIOL, V24, P109, DOI 10.1109/CIC.1997.647842
   Herold J, 2005, MED BIOL ENG COMPUT, V43, P451, DOI 10.1007/BF02344725
   Higuchi K., 2006, Journal of Medical Engineering & Technology, V30, P61, DOI 10.1080/03091900500131110
   KAY GL, 1994, J THORAC CARDIOV SUR, V108, P871, DOI 10.1016/S0022-5223(94)70185-7
   Mary NAB, 2018, MULTIMED TOOLS APPL, V77, P31545, DOI 10.1007/s11042-018-6148-5
   Mary NAB, 2019, MULTIMED TOOLS APPL, V78, P11387, DOI 10.1007/s11042-018-6673-2
   Neugebauer M, 2019, INT J COMPUT ASS RAD, V14, P357, DOI 10.1007/s11548-018-1868-6
   Nygaard H, 1993, J Heart Valve Dis, V2, P454
   Paris S, 2008, FOUND TRENDS COMPUT, V4, P1, DOI 10.1561/0600000020
   Pavlopoulos SA, 2004, BIOMED ENG ONLINE, V3, DOI 10.1186/1475-925X-3-21
   Saraçoglu R, 2012, ENG APPL ARTIF INTEL, V25, P1523, DOI 10.1016/j.engappai.2012.07.005
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Turkoglu I, 2002, EXPERT SYST APPL, V23, P229, DOI 10.1016/S0957-4174(02)00042-8
   Uguz H, 2007, PATTERN RECOGN LETT, V28, P395, DOI 10.1016/j.patrec.2006.08.009
   Vogel-Claussen J, 2006, RADIOGRAPHICS, V26, P1769, DOI 10.1148/rg.266065035
   Voss A, 2005, ANN BIOMED ENG, V33, P1167, DOI 10.1007/s10439-005-5347-x
NR 26
TC 5
Z9 5
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21409
EP 21424
DI 10.1007/s11042-021-10770-x
EA MAR 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000629113200001
DA 2024-07-18
ER

PT J
AU Chen, W
   He, CY
   Ji, CL
   Zhang, MY
   Chen, SY
AF Chen, Wei
   He, Cenyu
   Ji, Chunlin
   Zhang, Meiying
   Chen, Siyu
TI An improved K-means algorithm for underwater image background
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Underwater image; Image segmentation; Background segmentation; K-means
   algorithm
AB Conventional algorithms fail to obtain satisfactory background segmentation results for underwater images. In this study, an improved K-means algorithm was developed for underwater image background segmentation to address the issue of improper K value determination and minimize the impact of initial centroid position of grayscale image during the gray level quantization of the conventional K-means algorithm. A total of 100 underwater images taken by an underwater robot were sampled to test the aforementioned algorithm in respect of background segmentation validity and time cost. The K value and initial centroid position of grayscale image were optimized. The results were compared to the other three existing algorithms, including the conventional K-means algorithm, the improved Otsu algorithm, and the Canny operator edge extraction method. The experimental results showed that the improved K-means underwater background segmentation algorithm could effectively segment the background of underwater images with a low color cast, low contrast, and blurred edges. Although its cost in time was higher than that of the other three algorithms, it none the less proved more efficient than the time-consuming manual segmentation method. The algorithm proposed in this paper could potentially be used in underwater environments for underwater background segmentation.
C1 [Chen, Wei; He, Cenyu] Nanjing Inst Technol, Coll Innovat & Entrepreneurship, Ind Ctr, Nanjing 211167, Peoples R China.
   [Chen, Wei; Zhang, Meiying] Shenzhen Kuang Chi Space Technol Co Ltd, Shenzhen 518000, Peoples R China.
   [Ji, Chunlin] Shenzhen Kuang Chi Inst Adv Technol, Shenzhen 518000, Peoples R China.
   [Chen, Siyu] Tech Univ Munich, Dept Elect & Comp Engn, D-80333 Munich, Germany.
C3 Nanjing Institute of Technology; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; Technical University of Munich
RP Chen, SY (corresponding author), Tech Univ Munich, Dept Elect & Comp Engn, D-80333 Munich, Germany.
EM chenwei@njit.edu.cn; 851758060@qq.com; chunlin.ji@kuang-chi.com;
   meiying.zhang@kuang-chi.com; chensy-nj@163.com
RI liu, xq/JDW-2596-2023
FU Nanjing Industry-University-Research Cooperation Funding Project
   [221722072]
FX Open Access funding enabled and organized by Projekt DEAL. This research
   was supported by the Nanjing Industry-University-Research Cooperation
   Funding Project (No. 221722072).
CR ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   Ahmad A, 2007, DATA KNOWL ENG, V63, P503, DOI 10.1016/j.datak.2007.03.016
   Al-Jabery K., 2019, Computational learning approaches to data analytics in biomedical applications, DOI [10.1016/C2016-0-04633-8, DOI 10.1016/C2016-0-04633-8]
   [Anonymous], 2018, GLOB GEOL, DOI DOI 10.3969/j.issn.1673-9736.2018.02.07
   Arvis V., 2004, Image Analysis & Stereology, V23, P63, DOI 10.5566/ias.v23.p63-72
   Bazeille S., 2006, CMM'06
   Bo Shaobo, 2007, Control & Management, P280
   Cao Lu, 2012, Computer Engineering and Applications, V48, P208, DOI 10.3778/j.issn.1002-8331.2012.01.060
   [曹宇 CAO Yu], 2009, [计算机科学, Computer Science], V36, P265
   Chan MT, 2019, U.S. patent application no, Patent No. [15/864, 912, 15864912]
   Chen CP, 2012, APPL MECH MATER, V220-223, P1315, DOI 10.4028/www.scientific.net/AMM.220-223.1315
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02066-z
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Dehariya V. K., 2010, Proceedings of the 2010 International Conference on Computational Intelligence and Communication Networks (CICN 2010), P386, DOI 10.1109/CICN.2010.80
   Du H, 2019, OPT COMMUN, V453, DOI 10.1016/j.optcom.2019.06.044
   Fielding S, 2019, FRONT MAR SCI, V6, DOI 10.3389/fmars.2019.00340
   [胡敏 Hu Min], 2010, [电子测量与仪器学报, Journal of Electronic Measurement and Instrument], V24, P443
   Jain S, 2018, LECT NOTES ELECTR EN, V453, P189, DOI 10.1007/978-981-10-5565-2_17
   Jiang Yan-hui, 2010, Computer Engineering and Applications, V46, P175, DOI 10.3778/j.issn.1002-8331.2010.10.055
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Li ZY, 2011, APPL SOFT COMPUT, V11, P5630, DOI 10.1016/j.asoc.2011.04.001
   Luo YJ, 2020, J REAL-TIME IMAGE PR, V17, P125, DOI 10.1007/s11554-019-00917-3
   MacKay D., 2003, INFORM THEORY INFERE
   [宁旭 NING Xu], 2007, [中国医学物理学杂志, Chinese Journal of Medical Physics], V24, P326
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Priyadharsini R, 2019, PROCEDIA COMPUT SCI, V165, P759, DOI 10.1016/j.procs.2020.01.015
   Rugna JD, 2011, P WORLD C ENG COMP E, V1, P19
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sun FJ, 2009, 2009 INTERNATIONAL FORUM ON INFORMATION TECHNOLOGY AND APPLICATIONS, VOL 2, PROCEEDINGS, P600, DOI 10.1109/IFITA.2009.171
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Wu Zhengping, 2002, Journal of Computer Aided Design & Computer Graphics, V14, P743
   [徐晓昭 XU Xiaozhao], 2008, [测控技术, Measurement & Control Technology], V27, P10
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yang WeiZhong Yang WeiZhong, 2016, Transactions of the Chinese Society of Agricultural Engineering, V32, P197
NR 38
TC 9
Z9 10
U1 2
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 14
BP 21059
EP 21083
DI 10.1007/s11042-021-10693-7
EA MAR 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SH8DG
UT WOS:000628104400004
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Sharma, S
   Sharma, H
   Sharma, JB
AF Sharma, Sourabh
   Sharma, Harish
   Sharma, Janki Ballabh
TI Artificial bee colony based perceptually tuned blind color image
   watermarking in hybrid LWT-DCT domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial bee colony (ABC); Blind color watermarking; Imperceptibility;
   Robustness
AB A perceptually tuned blind digital watermarking method for color images in a hybrid lifting wavelet transform (LWT) and discrete cosine transform (DCT) domain is proposed in this work. The color watermark is scrambled by arnold transform before embedding to enhance the security level. The color host image is firstly transformed by lifting wavelet transform and the approximate sub-band is partitioned into different blocks each of size 8 x 8. The pixel values of each block are quantized using a quantization table. Each quantized-block is further decomposed by the DCT, to generate the AC coefficient matrix. Scrambled watermark is thereafter inserted into the AC coefficient matrix using the perceptually tuned dynamic embedding strength factor. The visual quality and robustness of the proposed watermarking are balanced by optimizing the value of perceptually tuned strength factor by the Artificial bee colony (ABC) optimization algorithm. Experimental results show that the color watermark is undetectable (with CPSNR > 40 dB) into the host image and robust enough (with NC > 0.9) to resist the image processing and manipulation attacks. Comparison analysis with other related watermarking methods highlights the efficacy of the proposed work.
C1 [Sharma, Sourabh; Sharma, Harish] Rajasthan Tech Univ, Dept Comp Sci & Engn, Kota 324010, Rajasthan, India.
   [Sharma, Janki Ballabh] Rajasthan Tech Univ, Dept Elect & Commun, Kota 324010, Rajasthan, India.
C3 Rajasthan Technical University; Rajasthan Technical University
RP Sharma, S (corresponding author), Rajasthan Tech Univ, Dept Comp Sci & Engn, Kota 324010, Rajasthan, India.
EM ssharmacse@gmail.com; hsharma@rtu.ac.in; jbsharma@rtu.ac.in
RI Sharma, Sourabh/HGU-1698-2022; Sharma, J.B./AAS-9698-2020
OI Sharma, Sourabh/0000-0001-6359-6532; 
CR Abdelhakim AM, 2018, MULTIMED TOOLS APPL, V77, P27895, DOI 10.1007/s11042-018-6014-5
   Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Ansari IA, 2016, OPTIK, V127, P5711, DOI 10.1016/j.ijleo.2016.03.070
   Ansari IA, 2016, ENG APPL ARTIF INTEL, V49, P114, DOI 10.1016/j.engappai.2015.12.004
   Celik MU, 2006, IEEE T IMAGE PROCESS, V15, P1042, DOI 10.1109/TIP.2005.863053
   Cui LH, 2011, IEEE T IMAGE PROCESS, V20, P1047, DOI 10.1109/TIP.2010.2079551
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Guo Y, 2017, IET IMAGE PROCESS, V11, P406, DOI 10.1049/iet-ipr.2016.0515
   Guo Y, 2016, IET IMAGE PROCESS, V10, P773, DOI 10.1049/iet-ipr.2015.0818
   Haghighi BB, 2019, INFORM SCIENCES, V486, P204, DOI 10.1016/j.ins.2019.02.055
   Herre, 1998, AUDIO ENG SOC CONVEN, V105
   Hsu LY, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113225
   Hu HT, 2017, MULTIMED TOOLS APPL, V76, P6575, DOI 10.1007/s11042-016-3332-3
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Ko HJ, 2020, INFORM SCIENCES, V517, P128, DOI 10.1016/j.ins.2019.11.005
   Liu XL, 2018, IEEE T CIRC SYST VID, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Makbol NM, 2014, DIGIT SIGNAL PROCESS, V33, P134, DOI 10.1016/j.dsp.2014.06.012
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Sharma H, 2013, MEMET COMPUT, V5, P213, DOI 10.1007/s12293-012-0104-0
   Sharma JB, 2013, J OPT-INDIA, V42, P214, DOI 10.1007/s12596-013-0125-1
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Shen SY, 2018, MULTIMED TOOLS APPL, V77, P12563, DOI 10.1007/s11042-017-4905-5
   Singh AK, 2019, MULTIMED TOOLS APPL, V78, P30523, DOI 10.1007/s11042-018-7115-x
   Su QT, 2019, MULTIMED TOOLS APPL, V78, P8113, DOI 10.1007/s11042-018-6632-y
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Verma VS, 2015, EXPERT SYST APPL, V42, P8184, DOI 10.1016/j.eswa.2015.06.041
   Xiang LY, 2018, MULTIMED TOOLS APPL, V77, P28969, DOI 10.1007/s11042-018-6072-8
   Zeng WJ, 1999, IEEE T IMAGE PROCESS, V8, P1534, DOI 10.1109/83.799882
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 35
TC 16
Z9 17
U1 6
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18753
EP 18785
DI 10.1007/s11042-021-10610-y
EA FEB 2021
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000619738400002
DA 2024-07-18
ER

PT J
AU Yadav, M
   Singh, R
AF Yadav, Mainejar
   Singh, Ranvijay
TI Essential secret image sharing approach with same size of meaningful
   shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Essential participants; Meaningful shadows; Random grid; Secret image
   sharing
AB Essential Secret Image Sharing (ESIS) is a method to decompose a secret image into two groups of shares, where one group is essential and the other group is non-essential. In this method, recovery of secret image is possible only if threshold number of shares along with all essential shares will be present. Existing state of art has some limitations such as different share size, complex computation, random pattern (meaningless) share, explicit codebook requirement, pixel expansion and constraint on image type. These limitations restrict the applications of the secret image sharing. In this paper, a novel approach of generating shares of similar size as that of the secret image has been proposed. The proposed "essential secret image sharing approach with same size of meaningful shares" (ESISMS) scheme produces meaningful shares based on bitwise XORing. This proposed approach resolves all the above stated issues and the advantages and applicability of this approach have been demonstrated by the theoretical analysis and experimental results.
C1 [Yadav, Mainejar; Singh, Ranvijay] MNNIT Allahabad, Comp Sci & Engn Dept, Prayagraj, India.
   [Yadav, Mainejar] REC Sonbhadra, Comp Sci & Engn Dept, Churk, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Yadav, M (corresponding author), MNNIT Allahabad, Comp Sci & Engn Dept, Prayagraj, India.; Yadav, M (corresponding author), REC Sonbhadra, Comp Sci & Engn Dept, Churk, India.
EM rahulit1210@gmail.com; ranvijay@mnnit.ac.in
OI , RANVIJAY/0000-0002-0502-6993
CR Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Adhikari, 2020, SIGNAL PROCESSING IM
   Chang CC, 2008, INFORM SCIENCES, V178, P2433, DOI 10.1016/j.ins.2007.12.016
   Chen CC, 2018, J VIS COMMUN IMAGE R, V52, P143, DOI 10.1016/j.jvcir.2018.02.006
   Chen CC, 2016, J VIS COMMUN IMAGE R, V38, P595, DOI 10.1016/j.jvcir.2016.04.004
   Chen SK, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.1.013103
   Cu DH, 2015, SIGNAL PROCESS, V108, P604, DOI 10.1016/j.sigpro.2014.10.011
   Hu YX, 2019, J INF SECUR APPL, V47, P371, DOI 10.1016/j.jisa.2019.06.003
   Hung KH, 2008, OPT ENG, V47, DOI 10.1117/1.2911719
   Hwa-Ching Hsu, 2004, 2004 IEEE International Conference on Networking, Sensing and Control (IEEE Cat. No.04EX761), P996
   Li L, 2019, CLUSTER COMPUT, V22, P2293, DOI 10.1007/s10586-017-1345-y
   Li P, 2016, DIGIT SIGNAL PROCESS, V50, P51, DOI 10.1016/j.dsp.2015.12.004
   Li P, 2013, J VIS COMMUN IMAGE R, V24, P1106, DOI 10.1016/j.jvcir.2013.07.005
   Niu, 2014, SIGNAL IMAGE VIDEO P, V9
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Sudha, 2020, MULTIMED TOOLS APPL
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Wu Z, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11010069
   Yan X, 2014, LNCS, V9, P68, DOI DOI 10.1007/978-3-642-55046-1
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P9279, DOI 10.1007/s11042-014-2080-5
   Yan XH, 2015, MULTIMED TOOLS APPL, V74, P3231, DOI 10.1007/s11042-013-1784-2
   Yan XH, 2015, SIGNAL IMAGE VIDEO P, V9, P499, DOI 10.1007/s11760-013-0465-y
   Yan XH, 2014, LECT NOTES COMPUT SC, V8836, P636, DOI 10.1007/978-3-319-12643-2_77
   Yang CN, 2015, SIGNAL PROCESS-IMAGE, V31, P1, DOI 10.1016/j.image.2014.11.003
   1987, OPT LETT, V12, P377
NR 28
TC 16
Z9 16
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2022
VL 81
IS 16
BP 22677
EP 22694
DI 10.1007/s11042-021-10625-5
EA FEB 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 2I0NV
UT WOS:000619738400007
DA 2024-07-18
ER

PT J
AU Naik, AJ
   Gopalakrishna, MT
AF Naik, Anuja Jana
   Gopalakrishna, M. T.
TI Deep-violence: individual person violent activity detection in video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Violent activity; Deep learning; LSTM
ID MOVEMENT
AB The need for automatic activity detection systems has been elevated since the number of surveillance cameras installed in the surroundings is increased. Automatic activity detection systems can be productively used to cooperate with human operators and for offline inspection to generate an on-line alarm in case of abnormal activities. Although the activity detection problem is a trending field belonging to computer vision, automatically characterizing violent scenes has been considerably less studied in the surveillance system which is vindicated by the demand of providing safer surroundings for the public. Thus in the proffered work, a deep neural network model based on an ensemble of the Mask Region-based Convolutional Neural network (Mask RCNN), Key-point detection, and Long Short Term Memory (LSTM) has been put forward to identify single person, violent activities such as Punching, kicking. Former to extract human key-points and mask and later to capture temporal information of the data. The upshot of experiments manifests that the ensemble model can outperform individual models. The proposed approach has managed to accomplish a good accuracy rate of 73.1%, 93.4%, and 86.5% on Weizmann, KTH, and own Dataset respectively. The proposed work is more relevant to the industry, which in turn is helpful in serving society as it deals with security.
C1 [Naik, Anuja Jana; Gopalakrishna, M. T.] SJB Inst Technol, Dept Comp Sci & Engn, Bengaluru, India.
   [Naik, Anuja Jana; Gopalakrishna, M. T.] Visvesvaraya Technol Univ, Belgaum, Karnataka, India.
C3 SJB Institute of Technology; Visvesvaraya Technological University
RP Naik, AJ (corresponding author), SJB Inst Technol, Dept Comp Sci & Engn, Bengaluru, India.; Naik, AJ (corresponding author), Visvesvaraya Technol Univ, Belgaum, Karnataka, India.
EM anuja2188@gmail.com
RI MT, Gopalakrishna/AAG-5511-2021; MT, Gopalakrishna/O-3037-2017
OI MT, Gopalakrishna/0000-0001-5410-0144; naik, anuja/0000-0003-1802-4070
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Badi, 2017, INTELLIGENT IND SYST, V3, P59, DOI [10.1007/s40903-017-0072-2, DOI 10.1007/S40903-017-0072-2]
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 1997, PHILOS T ROY SOC B, V352, P1257, DOI 10.1098/rstb.1997.0108
   Chalidabhongse, 2011, 11 INT S COMM INF TE
   Chen C.-C., 2009, Workshop on motion and video computing, P1, DOI [DOI 10.1109/WMVC.2009.5399231, 10.1109/WMVC.2009.5399231]
   Dong ZH, 2016, COMM COM INF SC, V662, P517, DOI 10.1007/978-981-10-3002-4_43
   Gao Y, 2016, IMAGE VISION COMPUT, V48-49, P37, DOI 10.1016/j.imavis.2016.01.006
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krüger V, 2007, ADV ROBOTICS, V21, P1473
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Naik, 2016, INT J LATEST RES ENG, P11
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Senst Tobias, 2015, 6th International Conference on Imaging for Crime Prevention and Detection (ICDP-15)
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Sudhakaran S., 2017, 2017 14 IEEE INT C A, P1, DOI DOI 10.1109/AVSS.2017.8078468
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Ullah FUM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112472
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Xu L, 2014, INT CONF ACOUST SPEE
   Yan Chen, 2011, Proceedings of the 2011 2nd International Conference on Innovations in Bio-Inspired Computing and Applications (IBICA 2011), P95, DOI 10.1109/IBICA.2011.28
   Zhang T, 2017, MULTIMED TOOLS APPL, V76, P1419, DOI 10.1007/s11042-015-3133-0
   Zhang T, 2016, MULTIMED TOOLS APPL, V75, P7327, DOI 10.1007/s11042-015-2648-8
   Zhou PP, 2017, J PHYS CONF SER, V844, DOI 10.1088/1742-6596/844/1/012044
NR 31
TC 18
Z9 18
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18365
EP 18380
DI 10.1007/s11042-021-10682-w
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000618948700011
DA 2024-07-18
ER

PT J
AU Bi, HB
   Liu, ZQ
   Yang, LN
   Wang, K
   Li, N
AF Bi, Hongbo
   Liu, Ziqi
   Yang, Lina
   Wang, Kang
   Li, Ning
TI Face sketch synthesis: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face sketch synthesis (FSS); Face sketch-photo synthesis; Face
   hallucination; Traditional models; Deep learning models
ID IMAGE; RECOGNITION; EIGENFACES
AB Face sketch synthesis (FSS) has been widely applied to various computer vision tasks, such as criminal detection, information security, digital entertainment, etc. In the past several years, various FSS models with promising performance have been proposed. However, an in-depth understanding of these models in this topic remains lacking. The current survey: i) investigates few models; ii) classifies the models abstractly and monotonously; iii) lacks analysis of existing databases. iv) evaluates models in single evaluation metric. In this paper, we provide a comprehensive survey of the 50 state-of-the-art (SOTA) FSS models. Then we further describe the typical models objectively and analyze the results subjectively. Moreover, we divide these models into two main categories: traditional models and deep learning models. In addition, a novel classification is proposed: coefficient models and regression models. Finally, for the aforementioned problems, we discuss several challenges and highlight some directions of FSS for future research about new database and evaluation strategy.
C1 [Bi, Hongbo; Liu, Ziqi; Yang, Lina; Wang, Kang] Northeast Petr Univ, Sch Elect & Informat Engn, Daqing, Peoples R China.
   [Li, Ning] Chengdu Lead Sci & Technol Co Ltd, Chengdu, Peoples R China.
C3 Northeast Petroleum University
RP Li, N (corresponding author), Chengdu Lead Sci & Technol Co Ltd, Chengdu, Peoples R China.
EM lnlndy@126.com
RI Liu, Ziqi/AAP-2559-2020
OI Liu, Ziqi/0000-0001-9096-840X
FU NEPU Natural Science Foundation [2017PYZL - 05, JYCX CX06 2018, JYCX
   JG06 2018]
FX This study was funded by the NEPU Natural Science Foundation under Grant
   No. 2017PYZL - 05, JYCX CX06 2018 and JYCX JG06 2018.
CR [Anonymous], 2014, INT C EM TRENDS COMP
   [Anonymous], 2005, P 2 INT C AUDIO VIDE
   [Anonymous], 2017, ARXIV171200899
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bhatt HS, 2012, IEEE T INF FOREN SEC, V7, P1522, DOI 10.1109/TIFS.2012.2204252
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Chen BC, 2014, LECT NOTES COMPUT SC, V8694, P768, DOI 10.1007/978-3-319-10599-4_49
   Chen C, 2018, IEEE WINT C APPL COM, P18
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chunlei Peng, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P3, DOI 10.1007/978-3-319-46604-0_1
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Fang Y, 2020, PATTERN RECOGNIT, P102
   Gao XB, 2008, NEUROCOMPUTING, V71, P1921, DOI 10.1016/j.neucom.2007.10.025
   Gao XN, 2008, IEEE T CIRC SYST VID, V18, P487, DOI 10.1109/TCSVT.2008.918770
   Gao XB, 2012, IEEE T CIRC SYST VID, V22, P1213, DOI 10.1109/TCSVT.2012.2198090
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang JJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1952, DOI 10.1109/ICASSP.2018.8462145
   Jiang JJ, 2019, IEEE T IMAGE PROCESS, V28, P628, DOI 10.1109/TIP.2018.2870936
   Jiao LC, 2018, PATTERN RECOGN, V76, P125, DOI 10.1016/j.patcog.2017.10.025
   Kim M, 2008, GLOB TELECOMM CONF, DOI 10.1109/GLOCOM.2008.ECP.1093
   Lei YT, 2020, NEUROCOMPUTING, V396, P13, DOI 10.1016/j.neucom.2020.02.024
   Li J, 2017, NEUROCOMPUTING, V269, P152, DOI 10.1016/j.neucom.2016.10.095
   Liang Chang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2146, DOI 10.1109/ICPR.2010.526
   Liu PC, 2019, NONLINEAR DYNAM, V98, P1447, DOI 10.1007/s11071-019-05170-8
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Liu W, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2141
   Lu Cewu., 2012, Proc. NPAR, P65
   Lu D, 2019, NEUROCOMPUTING, V365, P113, DOI 10.1016/j.neucom.2019.07.008
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Nannan Wang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P82, DOI 10.1109/ICIG.2011.112
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Peng CL, 2017, IEEE T CIRC SYST VID, V27, P288, DOI 10.1109/TCSVT.2015.2502861
   Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sankarasrinivasan S, 2014, COMPRESSED MEASUREME
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Song YB, 2014, LECT NOTES COMPUT SC, V8694, P800, DOI 10.1007/978-3-319-10599-4_51
   Sun L, 2019, IEEE SENS J, V19, P3487, DOI 10.1109/JSEN.2018.2888815
   Tang X, 2002, IEEE IMAGE PROC, P257
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   Tang ZC, 2019, FRONT INFORM TECH EL, V20, P1087, DOI 10.1631/FITEE.1800083
   Tang ZC, 2019, IEEE ACCESS, V7, P128185, DOI 10.1109/ACCESS.2019.2940034
   Tu CT, 2016, IEEE T IMAGE PROCESS, V25, P3546, DOI 10.1109/TIP.2016.2570571
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang LD, 2018, IEEE INT CONF AUTOMA, P83, DOI 10.1109/FG.2018.00022
   Wang NN, 2018, IEEE T CIRC SYST VID, V28, P2154, DOI 10.1109/TCSVT.2017.2709465
   Wang NN, 2018, PATTERN RECOGN LETT, V107, P59, DOI 10.1016/j.patrec.2017.06.012
   Wang NN, 2018, PATTERN RECOGN, V76, P215, DOI 10.1016/j.patcog.2017.11.008
   Wang NN, 2017, NEUROCOMPUTING, V257, P214, DOI 10.1016/j.neucom.2016.07.071
   Wang NN, 2017, IEEE T IMAGE PROCESS, V26, P1264, DOI 10.1109/TIP.2017.2651375
   Wang NN, 2017, SIGNAL PROCESS, V130, P1, DOI 10.1016/j.sigpro.2016.06.014
   Wang NN, 2016, NEUROCOMPUTING, V214, P991, DOI 10.1016/j.neucom.2016.06.070
   Wang NN, 2014, INT J COMPUT VISION, V106, P9, DOI 10.1007/s11263-013-0645-9
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang X., 2004, P IEEE COMP SOC C CO, P2
   Wang XG, 2004, PROC CVPR IEEE, P564
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wu Y, 2018, ARXIV180402975 CORR
   Xiao B, 2010, NEUROCOMPUTING, V73, P840, DOI 10.1016/j.neucom.2009.10.014
   Yang ZL, 2019, IEEE T INF FOREN SEC, V14, P1280, DOI 10.1109/TIFS.2018.2871746
   Ye LB, 2019, NEUROCOMPUTING, V358, P294, DOI 10.1016/j.neucom.2019.04.074
   Yuqian Zhang, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P64, DOI 10.1007/978-3-319-46604-0_5
   Zhang DY, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2623485
   Zhang LL, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P627, DOI 10.1145/2671188.2749321
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang MJ, 2020, IEEE T IMAGE PROCESS, V29, P1507, DOI 10.1109/TIP.2019.2942514
   Zhang MJ, 2020, IEEE T NEUR NET LEAR, V31, P2623, DOI 10.1109/TNNLS.2019.2933590
   Zhang MJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1142
   Zhang MJ, 2018, IEEE T CYBERNETICS, V48, P904, DOI 10.1109/TCYB.2017.2664499
   Zhang SC, 2019, IEEE T NEUR NET LEAR, V30, P1419, DOI 10.1109/TNNLS.2018.2869574
   Zhang SC, 2017, IEEE T CIRC SYST VID, V27, P275, DOI 10.1109/TCSVT.2015.2511482
   Zhang SC, 2016, IEEE T IMAGE PROCESS, V25, P220, DOI 10.1109/TIP.2015.2501755
   Zhang SC, 2015, IEEE T IMAGE PROCESS, V24, P2466, DOI 10.1109/TIP.2015.2422578
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhang W, 2010, LECT NOTES COMPUT SC, V6316, P420, DOI 10.1007/978-3-642-15567-3_31
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou H, 2012, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2012.6247788
   Zhu MR, 2019, IEEE T NEUR NET LEAR, V30, P3096, DOI 10.1109/TNNLS.2018.2890018
   Zhu MR, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3574
NR 89
TC 1
Z9 1
U1 2
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18007
EP 18026
DI 10.1007/s11042-020-10301-0
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617667500002
DA 2024-07-18
ER

PT J
AU Jeong, I
   Lee, C
AF Jeong, Inho
   Lee, Chul
TI An optimization-based approach to gamma correction parameter estimation
   for low-light image enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-light image enhancement; Contrast enhancement; Gamma correction;
   Convex optimization; Image fusion; Parameter estimation
AB We propose an efficient low-light image enhancement algorithm based on an optimization-based approach for gamma correction parameter estimation. We first separate an input color image into the luminance and chrominance channels, and then normalize the luminance channel using the logarithmic function to make it consistent with the human perception. Then, we divide the luminance image into dark and bright regions, and estimate the optimal gamma correction parameter for each region independently. Specifically, based on the statistical properties of the input image, we formulate a convex optimization problem that maximizes the image contrast subject to the constraint on the gamma value. By efficiently solving the optimization problems using the convex optimization theories, we obtain the optimal gamma parameter for each region. Finally, we obtain an enhanced image by merging the independently enhanced dark and bright regions with the optimal gamma parameters. Experimental results on real-world images demonstrate that the proposed algorithm can provide higher enhancement performance than state-of-the-art algorithms in terms of both subjective and objective evaluations, while providing a substantial improvement in speed.
C1 [Jeong, Inho] Pukyong Natl Univ, Dept Comp Engn, Busan 48513, South Korea.
   [Lee, Chul] Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
C3 Pukyong National University; Dongguk University
RP Lee, C (corresponding author), Dongguk Univ, Dept Multimedia Engn, Seoul 04620, South Korea.
EM dlsgh251@pukyong.ac.kr; chullee@dongguk.edu
OI Lee, Chul/0000-0001-9329-7365
FU National Research Foundation of Korea (NRF) - Korea Government (MSIT)
   [NRF-2019R1A2C4069806]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea Government (MSIT) (No.
   NRF-2019R1A2C4069806).
CR Agaian SS, 2007, IEEE T IMAGE PROCESS, V16, P741, DOI 10.1109/TIP.2006.888338
   Arici T, 2009, IEEE T IMAGE PROCESS, V18, P1921, DOI 10.1109/TIP.2009.2021548
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Celik T, 2016, IEEE T IMAGE PROCESS, V25, P4719, DOI 10.1109/TIP.2016.2599103
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   Chang Y, 2018, IEEE ACCESS, V6, P11782, DOI 10.1109/ACCESS.2018.2797872
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Fu QT, 2018, IEEE ACCESS, V6, P61277, DOI 10.1109/ACCESS.2018.2870638
   Guo C., 2020, P IEEE CVF C COMP VI, P1780
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hao SJ, 2018, MULTIMED TOOLS APPL, V77, P29639, DOI 10.1007/s11042-017-5448-5
   Heidrich Wolfgang, ERIK REINHARD
   Huang SC, 2013, IEEE T IMAGE PROCESS, V22, P1032, DOI 10.1109/TIP.2012.2226047
   Ju MY, 2018, IEEE SIGNAL PROC LET, V25, P1084, DOI 10.1109/LSP.2018.2839580
   Kim D, 2017, IEEE SIGNAL PROC LET, V24, P804, DOI 10.1109/LSP.2017.2687945
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Lee C, 2018, J REAL-TIME IMAGE PR, V14, P733, DOI 10.1007/s11554-016-0665-0
   Lee C, 2016, IEEE T IMAGE PROCESS, V25, P4145, DOI 10.1109/TIP.2016.2585047
   Lee C, 2013, IEEE T IMAGE PROCESS, V22, P5372, DOI 10.1109/TIP.2013.2284059
   Lee C, 2012, IEEE T IMAGE PROCESS, V21, P80, DOI 10.1109/TIP.2011.2159387
   Lim J, 2017, J VIS COMMUN IMAGE R, V45, P107, DOI 10.1016/j.jvcir.2017.02.016
   Loh YP, 2019, SIGNAL PROCESS-IMAGE, V74, P175, DOI 10.1016/j.image.2019.02.001
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nocedal J, 2006, SPRINGER SER OPER RE, P135
   Park S, 2018, IEEE ACCESS, V6, P22084, DOI 10.1109/ACCESS.2018.2812809
   Rahman S, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0138-1
   Ren WQ, 2019, IEEE T IMAGE PROCESS, V28, P4364, DOI 10.1109/TIP.2019.2910412
   Ren XT, 2020, IEEE T IMAGE PROCESS, V29, P5862, DOI 10.1109/TIP.2020.2984098
   Tan SF, 2019, IEEE ACCESS, V7, P70842, DOI 10.1109/ACCESS.2019.2918557
   Tao L, 2017, IEEE IMAGE PROC, P3215, DOI 10.1109/ICIP.2017.8296876
   Wang SQ, 2015, IEEE SIGNAL PROC LET, V22, P2387, DOI 10.1109/LSP.2015.2487369
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Yang KF, 2019, IEEE T CIRC SYST VID, V29, P640, DOI 10.1109/TCSVT.2018.2810212
   Yang WH, 2020, PROC CVPR IEEE, P3060, DOI 10.1109/CVPR42600.2020.00313
   Yue HJ, 2017, IEEE T IMAGE PROCESS, V26, P3981, DOI 10.1109/TIP.2017.2703078
NR 38
TC 14
Z9 14
U1 0
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 18027
EP 18042
DI 10.1007/s11042-021-10614-8
EA FEB 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617667500001
DA 2024-07-18
ER

PT J
AU Shakiba, A
AF Shakiba, Ali
TI A novel 2D cascade modulation couple hyperchaotic mapping for randomized
   image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Hyperchaos; Cascade modulation coupled hyperchaotic
ID CHAOTIC SYSTEM; ALGORITHM; MAP; COMPRESSION
AB In this paper, we design a novel two-dimensional hyperchaotic with two positive Lyapunov exponents and a phase distribution region close to uniform. Then, we propose a novel randomized hyperchaotic image encryption algorithm based on the proposed two-dimensional hyperchaotic mapping. The algorithm is designed in such a way that first adds randomization to the input image, and uses the SHA-256 value of the randomized image with the key for extracting required parameters. This randomization property is required for CPA-security. The security performance of the proposed encryption algorithm is illustrated by several experiments, including robustness against noise and data loss attacks, statistical, differential, and brute-force attacks. These experiments reveal acceptable security in comparison with several recent chaotic image encryption algorithms.
C1 [Shakiba, Ali] Vali E Asr Univ Rafsanjan, Dept Comp Sci, Rafsanjan 7718897111, Iran.
C3 Vali-e-Asr University of Rafsanjan
RP Shakiba, A (corresponding author), Vali E Asr Univ Rafsanjan, Dept Comp Sci, Rafsanjan 7718897111, Iran.
EM a.shakiba.iran@gmail.com
RI Shakiba, Ali/J-6420-2016
OI Shakiba, Ali/0000-0002-2253-1166
CR [Anonymous], 2010, IJ NETWORK SECURITY
   BLUM L, 1986, SIAM J COMPUT, V15, P364, DOI 10.1137/0215025
   Cao C, 2018, SIGNAL PROCESS, V143, P122, DOI 10.1016/j.sigpro.2017.08.020
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Dworkin M., 2001, RECOMMENDATION BLOCK
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gong LH, 2019, OPT LASER ENG, V121, P169, DOI 10.1016/j.optlaseng.2019.03.006
   Gong LH, 2019, OPT LASER TECHNOL, V115, P257, DOI 10.1016/j.optlastec.2019.01.039
   He D, 2001, IEEE T CIRCUITS-I, V48, P900, DOI 10.1109/81.933333
   Hermassi H, 2013, TELECOMMUN SYST, V52, P539, DOI 10.1007/s11235-011-9459-7
   Hu T, 2017, SIGNAL PROCESS, V134, P234, DOI 10.1016/j.sigpro.2016.12.008
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Kadir A, 2014, OPTIK, V125, P1671, DOI 10.1016/j.ijleo.2013.09.040
   Katz J., 2014, INTRO MODERN CRYPTOG
   Kocarev L, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P28
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Liu HJ, 2013, OPTIK, V124, P3527, DOI 10.1016/j.ijleo.2012.10.068
   Liu WH, 2016, OPT LASER ENG, V84, P26, DOI 10.1016/j.optlaseng.2016.03.019
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Matthews R., 1989, Cryptologia, V13, P29, DOI [10.1080/0161-118991863745, DOI 10.1080/0161-118991863745]
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Rijmen Vincent., 2001, P FEDERAL INFORM PRO, P19, DOI DOI 10.1007/978-3-662-04722-4_1
   Rostami MJ, 2017, COMPUT ELECTR ENG, V62, P384, DOI 10.1016/j.compeleceng.2017.04.004
   Shakiba A, 2020, GENERATING DYNAMIC S
   Shakiba A, 2021, J KING SAUD UNIV-COM, V33, P562, DOI 10.1016/j.jksuci.2019.03.003
   Shakiba A, 2020, MULTIMED TOOLS APPL, V79, P32575, DOI 10.1007/s11042-020-09434-z
   Shakiba A, 2019, MULTIMED TOOLS APPL, V78, P34773, DOI 10.1007/s11042-019-08071-5
   Shakiba A, 2016, INT J BIFURCAT CHAOS, V26, DOI 10.1142/S0218127416501121
   Song CY, 2013, OPTIK, V124, P3329, DOI 10.1016/j.ijleo.2012.11.002
   Stallings W., 2017, Cryptography and Network Security: Principles and Practice, V7th ed.
   Tong XJ, 2008, IMAGE VISION COMPUT, V26, P843, DOI 10.1016/j.imavis.2007.09.005
   Wang XY, 2018, OPT LASER ENG, V103, P1, DOI 10.1016/j.optlaseng.2017.11.009
   Wang XY, 2015, NONLINEAR DYNAM, V79, P1141, DOI 10.1007/s11071-014-1729-y
   Wu JH, 2018, SIGNAL PROCESS, V153, P11, DOI 10.1016/j.sigpro.2018.06.008
   Wu XJ, 2017, NONLINEAR DYNAM, V90, P855, DOI 10.1007/s11071-017-3698-4
   Wu Y, 2014, INFORM SCIENCES, V264, P317, DOI 10.1016/j.ins.2013.11.027
   Xu L, 2016, OPT LASER ENG, V78, P17, DOI 10.1016/j.optlaseng.2015.09.007
   Ye GD, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500104
   Ye GD, 2012, NONLINEAR DYNAM, V69, P2079, DOI 10.1007/s11071-012-0409-z
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yin Q, 2018, INT J BIFURCAT CHAOS, V28, DOI 10.1142/S0218127418500475
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhang YS, 2014, COMMUN NONLINEAR SCI, V19, P74, DOI 10.1016/j.cnsns.2013.06.031
   Zhen P, 2016, MULTIMED TOOLS APPL, V75, P6303, DOI 10.1007/s11042-015-2573-x
   Zhou NR, 2015, QUANTUM INF PROCESS, V14, P1193, DOI 10.1007/s11128-015-0926-z
   Zhou NR, 2018, OPT LASER ENG, V110, P72, DOI 10.1016/j.optlaseng.2018.05.014
NR 51
TC 5
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17983
EP 18006
DI 10.1007/s11042-021-10584-x
EA FEB 2021
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617667500003
DA 2024-07-18
ER

PT J
AU Kim, SH
   Koh, HM
   Lee, BD
AF Kim, Sang-Hyun
   Koh, Hyun Min
   Lee, Byoung-Dai
TI Classification of colorectal cancer in histological images using deep
   neural networks: an investigation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Colorectal cancer; Adenocarcinoma
AB Colorectal cancer refers to cancer of the colon or rectum; and has high incidence rates worldwide. Colorectal cancer most often occurs in the form of adenocarcinoma, which is known to arise from adenoma, a precancerous lesion. In general, colorectal tissue collected through a colonoscopy is prepared on glass slides and diagnosed by a pathologist through a microscopic examination. In the pathological diagnosis, an adenoma is relatively easy to diagnose because the proliferation of epithelial cells is simple and exhibits distinct changes compared to normal tissue. Conversely, in the case of adenocarcinoma, the degree of fusion and proliferation of epithelial cells is complex and shows continuity. Thus, it takes a considerable amount of time to diagnose adenocarcinoma and classify the degree of differentiation, and discordant diagnoses may arise between the examining pathologists. To address these difficulties, this study performed pathological examinations of colorectal tissues based on deep learning. The approach was tested experimentally with images obtained via colonoscopic biopsy from Gyeongsang National University Changwon Hospital from March 1, 2016, to April 30, 2019. Accordingly, this study demonstrates that deep learning can perform a detailed classification of colorectal tissues, including colorectal cancer. To the best of our knowledge, there is no previous study which has conducted a similarly detailed feasibility analysis of a deep learning-based colorectal cancer classification solution.
C1 [Kim, Sang-Hyun; Lee, Byoung-Dai] Kyonggi Univ, Div Comp Sci & Engn, Suwon, South Korea.
   [Koh, Hyun Min] Gyeongsang Natl Univ, Dept Pathol, Changwon Hosp, Chang Won, South Korea.
C3 Kyonggi University; Gyeongsang National University
RP Lee, BD (corresponding author), Kyonggi Univ, Div Comp Sci & Engn, Suwon, South Korea.
EM kws02352@kyonggi.ac.kr; shekoh@hanmail.net; blee@kyonggi.ac.kr
FU GRRC program of Gyeonggi province [GRRC KGU 2020-B04]
FX This work was supported by the GRRC program of Gyeonggi province. [GRRC
   KGU 2020-B04, Image/Network-based Intellectual Information Manufacturing
   Service Research]
CR [Anonymous], 1974, Pattern Recognition Principles, DOI DOI 10.1002/ZAMM.19770570626
   Awan R, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-16516-w
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Dif N, 2020, INT J SWARM INTELL R, V11, P72, DOI 10.4018/IJSIR.2020070105
   Egger J., 2020, MED DEEP LEARNING SY, V2010
   Graham S, 2019, MED IMAGE ANAL, V52, P199, DOI 10.1016/j.media.2018.12.001
   Gunaya IW., 2020, Telkomnika, V18, P1934, DOI [10.12928/telkomnika.v18i4.14864, DOI 10.12928/TELKOMNIKA.V18I4.14864]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kamnitsas K, 2017, MED IMAGE ANAL, V36, P61, DOI 10.1016/j.media.2016.10.004
   Kim M, 2020, NEUROSPINE, V17, P471, DOI 10.14245/ns.1938396.198.c1
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Ponzio F., 2018, Proceedings of the 11th International Joint Conference on Biomedical Engineering Systems and Technologies (BIOIMAGING), V2, P58
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wu N, 2020, IEEE T MED IMAGING, V39, P1184, DOI 10.1109/TMI.2019.2945514
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 21
TC 7
Z9 7
U1 3
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35941
EP 35953
DI 10.1007/s11042-021-10551-6
EA FEB 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000617415000005
DA 2024-07-18
ER

PT J
AU Phang, JTS
   Lim, KH
   Chiong, RCW
AF Phang, Jonathan Then Sien
   Lim, King Hann
   Chiong, Raymond Choo Wee
TI A review of three dimensional reconstruction techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE 3D modeling; Discriminative learning model; Generative learning model;
   Unsupervised learning; Reconstruction
AB Three dimensional (3D) modeling is an important stereoscopic representation of an object for multiple viewpoints aggregation and geometrical information. A general 3D modeling pipeline consists of data acquisition, 3D reconstruction and surface reconstruction. The core computational process in 3D modeling is always associated with the 3D reconstruction, which can be categorized into three types, i.e. statistical models, discriminative learning models and generative learning models. Statistical models derive handcrafted feature descriptor from mathematical theory to extract the spatial and geometric features of 3D data. A corresponding matching is performed between multiple viewpoints 3D data to search for the maximum region likelihood across datasets and compute the best match of affine transformation. Discriminative learning models learn spatial coherent of 3D data through data-driven training that leads to the computation of affine transformation with data inferencing. Generative models, on the other hand, have the unsupervised capability of ingesting raw 3D data directly to learn latent representation of input 3D data and later generate ambient output sample from the latent representation. In this paper, a detailed comparison on the three types of 3D reconstruction techniques are reviewed in term of input data structure, correspondence accuracy, precision and recall using four benchmark datasets, i.e. ModelNet10/40, ICL-NUIM, and Semantic3D. The advantages and disadvantages of 3D reconstruction techniques are highlighted for implementation guideline and future improvement.
C1 [Phang, Jonathan Then Sien; Lim, King Hann; Chiong, Raymond Choo Wee] Curtin Univ Malaysia, Dept Elect & Comp Engn, CDT 250, Miri 98009, Sarawak, Malaysia.
C3 Curtin University Malaysia
RP Phang, JTS (corresponding author), Curtin Univ Malaysia, Dept Elect & Comp Engn, CDT 250, Miri 98009, Sarawak, Malaysia.
EM jonathanpts@postgrad.curtin.edu.my
RI Lim, Hann/AAI-9930-2020; Chiong, Choo Wee Raymond/X-9837-2019
OI Lim, Hann/0000-0002-5679-7747; Chiong, Choo Wee
   Raymond/0000-0002-4977-9073; Phang, Jonathan Then
   Sien/0000-0002-4797-7375
FU Sarawak Multimedia Authority (SMA) [SMA-1077]; NVIDIA Corporation
FX This study is funded by Sarawak Multimedia Authority (SMA) with the
   project ID -SMA-1077. We would like to gratefully acknowledge the
   support of NVIDIA Corporation with the donation of the the Quadro P6000
   GPU used for this research.
CR Achlioptas P, 2018, PR MACH LEARN RES, V80
   Ahmed E., 2018, ARXIV180801462
   Altwaijry H, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.15
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Azimi S, 2019, ARXIV190900866
   Berger M., 2014, Eurographics 2014-State of the Art Reports, V1, P161, DOI [DOI 10.2312/EGST.20141040, 10.2312/egst.20141040]
   CHE T, 2017, INT C LEARN REPR
   Ciaparrone G, 2020, NEUROCOMPUTING, V381, P61, DOI 10.1016/j.neucom.2019.11.023
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grilli E, 2017, INT ARCH PHOTOGRAMM, V42-2, P339, DOI 10.5194/isprs-archives-XLII-2-W3-339-2017
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Guo YC, 2020, IEEE ICC, DOI 10.1109/icc40277.2020.9149375
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Hackel T, 2017, ISPRS ANN PHOTOGRAMM, P91, DOI 10.5194/isprs-annals-IV-1-W1-91-2017
   Handa A, 2014, IEEE INT CONF ROBOT, P1524, DOI 10.1109/ICRA.2014.6907054
   Hinton G.E., 2018, INT C LEARN REPR
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Huang FC, 2017, ACM T GRAPHIC, V36, DOI [10.1145/3072959.3073654, 10.1145/3137609]
   Imanullah Muhammad, 2019, 2019 International Seminar on Intelligent Technology and Its Applications (ISITIA), P288, DOI 10.1109/ISITIA.2019.8937292
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Jing Cao, 2017, 2017 Conference on Lasers and Electro-Optics Europe & European Quantum Electronics Conference (CLEO/Europe-EQEC), DOI 10.1109/CLEOE-EQEC.2017.8087245
   Khoury M, 2017, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2017.26
   Kim P, 2018, AUTOMAT CONSTR, V89, P38, DOI 10.1016/j.autcon.2018.01.009
   Kim VG, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461933
   Kingma D. P., 2013, ARXIV13126114
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Li HS, 2019, INT J COMPUT INT SYS, V12, P697, DOI 10.2991/ijcis.d.190617.001
   Li ZF, 2018, CHIN AUTOM CONGR, P2928, DOI 10.1109/CAC.2018.8623194
   Ligon J, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P731, DOI 10.1109/CCWC.2018.8301688
   Liu MH, 2020, AAAI CONF ARTIF INTE, V34, P11596
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Lunz Sebastian, 2020, arXiv preprint arXiv:2002.12674
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   McGregor Andrew, 2013, Approximation, Randomization, and Combinatorial Optimization. Algorithms and Techniques. Algorithms and Techniques. 16th International Workshop, APPROX 2013 and 17th International Workshop, RANDOM 2013. Proceedings: LNCS 8096, P274, DOI 10.1007/978-3-642-40328-6_20
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Patel MS, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ADVANCED COMPUTING AND COMMUNICATION (ISACC), P213, DOI 10.1109/ISACC.2015.7377344
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   RaviPrakash H, 2020, ARXIV201009102
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Shapira L, 2010, INT J COMPUT VISION, V89, P309, DOI 10.1007/s11263-009-0279-0
   Smith Edward J., 2017, P MACH LEARN RES, V78, P87
   Srivastava Nitish., 2019, ARXIV191203310
   Srivastava S, 2019, PATTERN RECOGN LETT, V127, P27, DOI 10.1016/j.patrec.2019.02.027
   Srivastava S, 2018, IEEE WINT CONF APPL, P179, DOI 10.1109/WACV.2018.00026
   Tan HH, 2019, 2019 7TH INTERNATIONAL CONFERENCE ON SMART COMPUTING & COMMUNICATIONS (ICSCC), P286, DOI 10.1109/icscc.2019.8843652
   Wen X., 2019, ARXIV190811026
   Wu JJ, 2016, ADV NEUR IN, V29
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yao R., 2019, ARXIV PREPRINT ARXIV
   Yu QH, 2018, COMPUT VIS IMAGE UND, V167, P109, DOI 10.1016/j.cviu.2017.12.001
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhao Y., 2020, EUR C COMP VIS, P1, DOI DOI 10.1007/978-3-030-58452-81
   Zhao YH, 2019, PROC CVPR IEEE, P1009, DOI 10.1109/CVPR.2019.00110
   Zhou L, 2018, LECT NOTES COMPUT SC, V11219, P527, DOI 10.1007/978-3-030-01267-0_31
   Zhu AF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185086
   Zollhöfer M, 2018, COMPUT GRAPH FORUM, V37, P625, DOI 10.1111/cgf.13386
   Zollhofer M., 2019, RGB D IMAGE ANAL PRO, P3, DOI DOI 10.1007/978-3-030-28603-3_1
NR 67
TC 7
Z9 9
U1 17
U2 167
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 12
BP 17879
EP 17891
DI 10.1007/s11042-021-10605-9
EA FEB 2021
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SF2YW
UT WOS:000617415000002
DA 2024-07-18
ER

PT J
AU Jamshidi, S
   Azmi, R
   Sharghi, M
   Soryani, M
AF Jamshidi, Samaneh
   Azmi, Reza
   Sharghi, Mehran
   Soryani, Mohsen
TI Hierarchical deep neural networks to detect driver drowsiness
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Drowsiness detection; Deep learning; ResNet; LSTM
ID HEAD POSE; EYE STATE; SYSTEM
AB Driver drowsiness is one of the main reasons for deadly accidents, especially on suburban roads. Researchers have used many methods for analyzing videos and detecting drowsiness, and the most up-to-date methods among them are using deep learning. This paper proposes a hierarchical framework comprising deep networks with split spatial and temporal phases referred to as hierarchical deep drowsiness detection (HDDD) network. The proposed method uses ResNet to detect the driver's face, lighting condition, and whether the driver is wearing glasses or not. This phase also causes a significant increase in eyes and mouth detection percentage in the next stage. Afterward, the LSTM network is used to take advantage of temporal information between the frames. The average accuracy of the drowsiness detection system is reached 87.19 percent.
C1 [Jamshidi, Samaneh; Azmi, Reza; Sharghi, Mehran] Alzahra Univ, Fac Engn, Tehran, Iran.
   [Soryani, Mohsen] Iran Univ Sci & Technol, Sch Comp Engn, Tehran, Iran.
C3 Alzahra University; Iran University Science & Technology
RP Jamshidi, S (corresponding author), Alzahra Univ, Fac Engn, Tehran, Iran.
EM Sp.jamshidi@gmail.com
RI Soryani, Mohsen/T-1403-2018
OI Soryani, Mohsen/0000-0002-8555-9617; Jamshidi,
   Parisa/0000-0001-7055-2706
CR Alioua N, 2014, INT J VEH TECHNOL, V2014
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   Aware, 2014, INT J SCI ENG TECHNO, V3, P203
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Breuer R., 2017, ARXIV170501842
   Choi IH, 2014, INT CONF BIG DATA, P241, DOI 10.1109/BIGCOMP.2014.6741444
   Diaz-Chito K, 2016, APPL SOFT COMPUT, V45, P98, DOI 10.1016/j.asoc.2016.04.027
   Feng RJ, 2009, IEEE INT C NETW SENS, P887
   González-Ortega D, 2013, PATTERN ANAL APPL, V16, P285, DOI 10.1007/s10044-013-0331-0
   Gritzman AD, 2015, SIGNAL IMAGE VIDEO P, V9, P947, DOI 10.1007/s11760-014-0615-x
   Guo JM, 2019, MULTIMED TOOLS APPL, V78, P29059, DOI 10.1007/s11042-018-6378-6
   Hachisuka S, 2013, 2013 INTERNATIONAL CONFERENCE ON BIOMETRICS AND KANSEI ENGINEERING (ICBAKE), P320, DOI 10.1109/ICBAKE.2013.89
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Ibrahim MM, 2015, BIOMED SIGNAL PROCES, V18, P360, DOI 10.1016/j.bspc.2015.02.006
   Ingre M, 2006, J SLEEP RES, V15, P47, DOI 10.1111/j.1365-2869.2006.00504.x
   Ishii Y, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P2449, DOI 10.1109/ROBIO.2014.7090707
   Jones M., 2003, Mitsubishi Electric Research Lab TR-20003-96, V3, P2
   Kalbkhani H., 2012, Journal of world's electrical engineering and technology, V1, P12
   Kaplan S, 2015, IEEE T INTELL TRANSP, V16, DOI 10.1109/TITS.2015.2462084
   Li G, 2015, IEEE SENS J, V15, P7169, DOI 10.1109/JSEN.2015.2473679
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li ZJ, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030495
   Lin CT, 2010, IEEE T BIOMED CIRC S, V4, P214, DOI 10.1109/TBCAS.2010.2046415
   Mandal B, 2017, IEEE T INTELL TRANSP, V18, P545, DOI 10.1109/TITS.2016.2582900
   Mbouna RO, 2013, IEEE T INTELL TRANSP, V14, P1462, DOI 10.1109/TITS.2013.2262098
   Mehta S., 2019, SSRN ELECT J, P1333, DOI [DOI 10.2139/SSRN.3356401, 10.2139/ssrn.3356401]
   Omidyeganeh M, 2016, IEEE T INSTRUM MEAS, V65, P570, DOI 10.1109/TIM.2015.2507378
   Ouhyoung M, 2011, P IPPR C COMP VIS GR
   Park S, 2017, LECT NOTES COMPUT SC, V10118, P154, DOI 10.1007/978-3-319-54526-4_12
   Pratama BG, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON SCIENCE AND TECHNOLOGY - COMPUTER (ICST), P70, DOI 10.1109/ICSTC.2017.8011855
   Saini V., 2014, Int. J. Comput. Sci. Inf. Technol, V5, P4245
   Shih TH, 2017, LECT NOTES COMPUT SC, V10118, P146, DOI 10.1007/978-3-319-54526-4_11
   Tansakul Wasan, 2016, Journal of Automation and Control Engineering, V4, P33, DOI 10.12720/joace.4.1.33-39
   Weng CH, 2017, LECT NOTES COMPUT SC, V10118, P117, DOI 10.1007/978-3-319-54526-4_9
   Wood R., 2012, Proceedings of the International Conference on Bio-inspired Systems and Signal Processing (BIOSIGNALS 2012), P494
   Yu JT, 2016, IEEE INT SYMP NANO, P165, DOI 10.1145/2950067.2950071
   Zhang LY, 2015, ACM T INTEL SYST TEC, V6, DOI 10.1145/2629482
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhao L, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.5.053024
NR 42
TC 18
Z9 18
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 16045
EP 16058
DI 10.1007/s11042-021-10542-7
EA FEB 2021
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000616158900006
DA 2024-07-18
ER

PT J
AU Naik, MK
   Panda, R
   Wunnava, A
   Jena, B
   Abraham, A
AF Naik, Manoj Kumar
   Panda, Rutuparna
   Wunnava, Aneesh
   Jena, Bibekananda
   Abraham, Ajith
TI A leader Harris hawks optimization for 2-D Masi entropy-based multilevel
   image thresholding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Swarm intelligence; Harris hawks optimization; Optimal multilevel image
   thresholding; Multimedia applications; Masi entropy
ID MAXIMUM TSALLIS ENTROPY; CUCKOO SEARCH ALGORITHM; DIFFERENTIAL
   EVOLUTION; SEGMENTATION
AB The multilevel image thresholding is one of the important steps in multimedia tools to understand and interpret the object in the real world. Nevertheless, 1-D Masi entropy is quite new in the thresholding application. However, the 1-D Masi entropy-based image thresholding fails to consider the contextual information. To address this problem, we propose a 2-D Masi entropy-based multilevel image thresholding by utilizing a 2-D histogram, which ensures the contextual information during the thresholding process. The computational complexity in multilevel thresholding increases due to the exhaustive search process, which can be reduced by a nature-inspired optimizer. In this work, we propose a leader Harris hawks optimization (LHHO) for multilevel image thresholding, to enhance the exploration capability of Harris hawks optimization (HHO). The increased exploration can be achieved by an adaptive perching during the exploration phase together with a leader-based mutation-selection during each generation of Harris hawks. The performance of LHHO is evaluated using the standard classical 23 benchmark functions and found better than HHO. The LHHO is employed to obtain optimal threshold values using 2-D Masi entropy-based multilevel thresholding objective function. For the experiments, 500 images from the Berkeley segmentation dataset (BSDS 500) are considered. A comparative study on state-of-the-art algorithm-based thresholding methods, using segmentation metrics such as - peak signal-to-noise ratio (PSNR), structural similarity index (SSIM), and the feature similarity index (FSIM), is performed. The experimental results reveal a remarkable difference in the thresholding performance. For instance, the average PSNR values (computed over 500 images) for the level 5 are increased by 2% to 4% in case of 2-D Masi entropy over 1-D Masi entropy.
C1 [Naik, Manoj Kumar; Wunnava, Aneesh] Siksha O Anusandhan, Fac Engn & Technol, Bhubaneswar 751030, Odisha, India.
   [Panda, Rutuparna] Veer Surendra Sai Univ Technol, Dept Elect & Telecommun Engn, Burla 768018, Odisha, India.
   [Jena, Bibekananda] Anil Neerukonda Inst Technol & Sci, Dept Elect & Commun Engn, Visakhapatnam 531162, Andhra Pradesh, India.
   [Abraham, Ajith] Sci Network Innovat & Res Excellence, Machine Intelligence Res Labs, Washington, DC 98071 USA.
C3 Siksha 'O' Anusandhan University; Veer Surendra Sai University of
   Technology
RP Naik, MK (corresponding author), Siksha O Anusandhan, Fac Engn & Technol, Bhubaneswar 751030, Odisha, India.
EM naik.manoj.kumar@gmail.com; r_ppanda@yahoo.co.in;
   aneeshwunnava@gmail.com; bibekananda.jena@gmail.com;
   ajith.abraham@ieee.org
RI Abraham, Ajith/A-1416-2008; Wunnava, Aneesh/KJM-6505-2024; Jena,
   Bibekananda/AAB-9202-2021; Naik, Manoj Kumar/O-2982-2017; Panda,
   Rutuparna/AAA-3214-2021
OI Abraham, Ajith/0000-0002-0169-6738; Wunnava, Aneesh/0000-0002-3869-1324;
   Jena, Bibekananda/0000-0003-1675-6120; Naik, Manoj
   Kumar/0000-0002-8077-1811; Panda, Rutuparna/0000-0002-8676-0144
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Agrawal S, 2020, IEEE T SYST MAN CY-S, V50, P4688, DOI 10.1109/TSMC.2018.2859429
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Barthelemy P, 2008, NATURE, V453, P495, DOI 10.1038/nature06948
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P8707, DOI 10.1016/j.eswa.2015.07.025
   Bhandari AK, 2014, EXPERT SYST APPL, V41, P3538, DOI 10.1016/j.eswa.2013.10.059
   Chen YL, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106335
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   Dhiman G, 2019, ENG APPL ARTIF INTEL, V82, P148, DOI 10.1016/j.engappai.2019.03.021
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Gandomi A., 2013, ENG COMPUT-GERMANY, V29, P245, DOI [10.1007/s00366-012-0308-4, DOI 10.1007/S00366-012-0308-4]
   Gandomi AH, 2011, COMPUT STRUCT, V89, P2325, DOI 10.1016/j.compstruc.2011.08.002
   Gao H, 2010, IEEE T INSTRUM MEAS, V59, P934, DOI 10.1109/TIM.2009.2030931
   Hammouche K, 2008, COMPUT VIS IMAGE UND, V109, P163, DOI 10.1016/j.cviu.2007.09.001
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Horng MH, 2011, EXPERT SYST APPL, V38, P13785, DOI 10.1016/j.eswa.2011.04.180
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   Ayala HVH, 2015, EXPERT SYST APPL, V42, P2136, DOI 10.1016/j.eswa.2014.09.043
   Jia HM, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11080942
   Kandhway P, 2019, CIRC SYST SIGNAL PR, V38, P3058, DOI 10.1007/s00034-018-0993-3
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Khairuzzaman AKM, 2019, MULTIMED TOOLS APPL, V78, P33573, DOI 10.1007/s11042-019-08117-8
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Li HR, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106593
   Li HR, 2020, SWARM EVOL COMPUT, V58, DOI 10.1016/j.swevo.2020.100743
   Li HR, 2020, SOFT COMPUT, V24, P6851, DOI 10.1007/s00500-019-04324-5
   Liang YQ, 2020, INTEGR COMPUT-AID E, V27, P417, DOI 10.3233/ICA-200641
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Liu Jianzhuang, 1991, China 1991 International Conference on Circuits and Systems. Conference Proceedings (Cat. No.91TH0387-1), P325, DOI 10.1109/CICCAS.1991.184351
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Masi M, 2005, PHYS LETT A, V338, P217, DOI 10.1016/j.physleta.2005.01.094
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Naik MK, 2016, STUD COMPUT INTELL, V611, P3, DOI 10.1007/978-81-322-2544-7_1
   Naik MK, 2016, APPL SOFT COMPUT, V38, P661, DOI 10.1016/j.asoc.2015.10.039
   Naik MK., 2020, COMPUT INTELL-US, P1
   Nie FY, 2017, SIGNAL PROCESS, V134, P23, DOI 10.1016/j.sigpro.2016.11.004
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1989, SIGNAL PROCESS, V16, P97, DOI 10.1016/0165-1684(89)90090-X
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Panda R, 2017, APPL SOFT COMPUT, V50, P94, DOI 10.1016/j.asoc.2016.11.011
   Panda R, 2013, EXPERT SYST APPL, V40, P7617, DOI 10.1016/j.eswa.2013.07.060
   Pavesic N, 2000, IEEE MEDITERR ELECT, P631
   Peng-Yeng Yin, 1994, ISSIPNN '94. 1994 International Symposium on Speech, Image Processing and Neural Networks Proceedings (Cat. No.94TH0638-7), P45, DOI 10.1109/SIPNN.1994.344969
   Raja NSM, 2014, MOD SIMUL ENG, V2014, DOI 10.1155/2014/794574
   Rao RV, 2013, SCI IRAN, V20, P710, DOI 10.1016/j.scient.2012.12.005
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Sahoo PK, 2006, PATTERN RECOGN LETT, V27, P520, DOI 10.1016/j.patrec.2005.09.017
   Sahoo PK, 2004, PATTERN RECOGN, V37, P1149, DOI 10.1016/j.patcog.2003.10.008
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sankur B., 2001, PATTERN RECOGN, V34, P1573
   Sarkar S, 2013, IEEE T IMAGE PROCESS, V22, P4788, DOI 10.1109/TIP.2013.2277832
   Sathya PD, 2011, ENG APPL ARTIF INTEL, V24, P595, DOI 10.1016/j.engappai.2010.12.001
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shahabi F., 2019, J DECISIONS OPERATIO, V4, P33, DOI [10.22105/dmor.2019.88580, DOI 10.22105/DMOR.2019.88580]
   Shubham S, 2019, MULTIMED TOOLS APPL, V78, P17197, DOI 10.1007/s11042-018-7034-x
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Song J, 2017, J Inf Hiding Multim Signal Process, V8, P578
   TSALLIS C, 1988, J STAT PHYS, V52, P479, DOI 10.1007/BF01016429
   Tsallis C., 2001, Nonextensive Statistical Mechanics and Its Applications, DOI DOI 10.1007/3-540-40919-X_1
   Upadhyay P, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.105522
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xin-She Yang, 2012, Unconventional Computation and Natural Computation. Proceedings of the 11th International Conference, UCNC 2012, P240, DOI 10.1007/978-3-642-32894-7_27
   Xing ZK, 2020, MULTIMED TOOLS APPL, V79, P1137, DOI 10.1007/s11042-019-08229-1
   Yang X.S., 2019, Mathematical Foundations of Nature-Inspired Methods
   Yang XS, 2012, ENG COMPUTATION, V29, P464, DOI 10.1108/02644401211235834
   Yao X, 1999, IEEE T EVOLUT COMPUT, V3, P82, DOI 10.1109/4235.771163
   Ye ZW, 2005, PROCEEDINGS OF THE 2005 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS AND BRAIN, VOLS 1-3, P728
   Yin PY, 2007, APPL MATH COMPUT, V184, P503, DOI 10.1016/j.amc.2006.06.057
   Yin PY, 1997, SIGNAL PROCESS, V60, P305, DOI 10.1016/S0165-1684(97)00080-7
   Zaitoun NM, 2015, PROCEDIA COMPUT SCI, V65, P797, DOI 10.1016/j.procs.2015.09.027
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang YD, 2011, ENTROPY-SWITZ, V13, P841, DOI 10.3390/e13040841
NR 79
TC 49
Z9 52
U1 5
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35543
EP 35583
DI 10.1007/s11042-020-10467-7
EA FEB 2021
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000615564900003
DA 2024-07-18
ER

PT J
AU Pérez, FJ
   Garrido, VJ
   García, A
   Zambrano, M
   Kozik, R
   Choras, M
   Muhlenberg, D
   Pallmer, D
   Müller, W
AF Perez, Francisco J.
   Garrido, Victor J.
   Garcia, Alberto
   Zambrano, Marcelo
   Kozik, Rafal
   Choras, Michal
   Muhlenberg, Dirk
   Pallmer, Dirk
   Mueller, Wilmuth
TI Multimedia analysis platform for crime prevention and investigation
   Results of MAGNETO project
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Law enforcement; Information extraction; Distributed infrastructure;
   Situational awareness
AB Nowadays,the use of digital technologies is promoting three main characteristics of information, i.e. the volume, the modality and the frequency. Due to the amount of information generated by tools and individuals, it has been identified a critical need for the Law Enforcement Agencies to exploit this information and carry out criminal investigations in an effective way. To respond to the increasing challenges of managing huge amounts of heterogeneous data generated at high frequency, the paper outlines a modular approach adopted for the processing of information gathered from different information sources, and the extraction of knowledge to assist criminal investigation. The proposed platform provides novel technologies and efficient components for processing multimedia information in a scalable and distributed way, allowing Law Enforcement Agencies to make the analysis and a multidimensional visualization of criminal information in a single and secure point.
C1 [Perez, Francisco J.; Garrido, Victor J.; Garcia, Alberto] Univ Politecn Valencia, Valencia, Spain.
   [Zambrano, Marcelo] Univ Tecn Norte, Ibarra, Ecuador.
   [Zambrano, Marcelo] Inst Super Tecnol Ruminahui, Ruminahui, Ecuador.
   [Kozik, Rafal; Choras, Michal] ITTI Sp Zoo, Poznan, Poland.
   [Kozik, Rafal; Choras, Michal] UTP Univ Sci & Technol Bydgoszcz, Bydgoszcz, Poland.
   [Muhlenberg, Dirk; Pallmer, Dirk; Mueller, Wilmuth] Fraunhofer IOSB, Karlsruhe, Germany.
C3 Universitat Politecnica de Valencia; Bydgoszcz University of Science &
   Technology
RP Pérez, FJ (corresponding author), Univ Politecn Valencia, Valencia, Spain.
EM frapecar@upvnet.upv.es; omzambrano@utn.edu.ec; mchoras@itti.com.pl;
   wilmuth.mueller@iosb.fraunhofer.de
OI PEREZ CARRASCO, FRANCISCO JOSE/0000-0001-9254-9962; Kozik,
   Rafal/0000-0001-7122-3306; Zambrano Vizuete, Oscar
   Marcelo/0000-0001-5152-7572
FU European Union [H2020 786629]
FX This work has been performed under the H2020 786629 project MAGNETO,
   which has received funding from the European Union's Horizon 2020
   Programme. This paper reflects only the authors' view, and the European
   Commission is not liable to any use that may be made of the information
   contained therein.
CR Chauhan C, 2017, INT C COMP COMM AUT, DOI [10.1109/CCAA.2017.8229823, DOI 10.1109/CCAA.2017.8229823]
   Computer Science Department Stanford, 2019, TUFFY SCALABLE MARKO
   Dragos V, 2013, INT J KNOWLEDGE BASE
   Feng MC, 2019, IEEE ACCESS, V7, P106111, DOI 10.1109/ACCESS.2019.2930410
   Hassani H, 2016, STAT ANAL DATA MIN, V9, P139, DOI 10.1002/sam.11312
   Hussain D, 2012, INT C ADV ENG SCI MA
   Komalavalli C, 2019, 2019 9TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2019), P223, DOI [10.1109/CONFLUENCE.2019.8776932, 10.1109/confluence.2019.8776932]
   Ku CH, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P466, DOI 10.1109/IRI.2012.6303045
   Luay A, 2017, 8 INT C INF INT SYST, DOI [10.1109/IISA.2017.8316400, DOI 10.1109/IISA.2017.8316400]
   Naik N, 2017, DOCKER CONTAINER BAS, DOI [10.1109/SysEng.2017.8088294, DOI 10.1109/SYSENG.2017.8088294]
   Sill A, 2016, IEEE CLOUD COMPUT, V3, P76, DOI 10.1109/MCC.2016.111
   Trunzer E, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1106, DOI 10.1109/ICIT.2017.7915517
   Truyen E, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P468, DOI 10.1109/CLOUD.2018.00066
   Yang M, 2015, IFIP ADV INF COMM TE, V462, P61, DOI 10.1007/978-3-319-24123-4_4
   Yu H, 2016, 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON DATA SCIENCE IN CYBERSPACE (DSC 2016), P323, DOI 10.1109/DSC.2016.84
NR 15
TC 3
Z9 3
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23681
EP 23700
DI 10.1007/s11042-020-10206-y
EA FEB 2021
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000615564900001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU An, FP
   Liu, JE
AF An, Feng-Ping
   Liu, Jun-e
TI Medical image segmentation algorithm based on multilayer boundary
   perception-self attention deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image; Image segmentation; Deep learning; Multilayer boundary
   perception; Self-attention mechanism
ID NETWORK; BREAST
AB Traditional medical image segmentation methods have problems such as low segmentation accuracy and low adaptive ability. Therefore, many scholars have proposed a medical image segmentation method based on deep learning, which has achieved good results in the field of medical image segmentation. However, this type of method has the following problems in the application process: (1) Medical image segmentation target boundary positioning problem. Constrained by factors such as medical image contrast, heterogeneity, and boundary resolution, existing convolution models still cannot accurately locate boundaries. (2) Deep adaptability of deep learning network structure to medical images. Because medical images have more distinct and different feature information than natural images, the current deep learning-based medical segmentation methods have not fully considered this feature. In view of this, this paper proposes a multi-level boundary-aware RUNet segmentation model. The network structure consists of a U-Net-based segmentation network and a multi-level boundary detection network. It can solve the problem of boundary positioning. At the same time, in order to solve the problem of poor adaptability of deep learning network structures to medical images, this paper proposes to introduce a new interactive self-attention module into deep learning models. It can make the feature map get global information, and realize the effective extraction of medical image feature information. It solves the problem of weak matching between the deep learning network structure and medical images. Based on the above ideas, this paper proposes an image segmentation algorithm based on a multi-layer boundary perception-self-attention mechanism deep learning model. This method and other mainstream segmentation algorithms are used to perform experiments on related medical databases. The results show that the proposed method not only improves the segmentation effect significantly compared with traditional machine learning methods, but also improves it to a certain extent compared with other deep learning methods.
C1 [An, Feng-Ping] Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223300, JS, Peoples R China.
   [An, Feng-Ping] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, BJ, Peoples R China.
   [Liu, Jun-e] Beijing Wuzi Univ, Sch Informat, Beijing 100061, BJ, Peoples R China.
C3 Huaiyin Normal University; Beijing Institute of Technology; Beijing Wuzi
   University
RP An, FP (corresponding author), Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223300, JS, Peoples R China.; An, FP (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, BJ, Peoples R China.; Liu, JE (corresponding author), Beijing Wuzi Univ, Sch Informat, Beijing 100061, BJ, Peoples R China.
EM anfengping@163.com; 2924175349@qq.com
OI AN, FENGPING/0000-0002-2220-2987
FU National Natural Science Foundation of China [61701188]; China
   Postdoctoral Science Foundation [2019 M650512]; Scientific and
   technological innovation service capacity building-high-level discipline
   construction (city level)
FX This paper is supported by National Natural Science Foundation of China
   (No. 61701188), China Postdoctoral Science Foundation funded project
   (No. 2019 M650512) and Scientific and technological innovation service
   capacity building-high-level discipline construction (city level).
CR Ahmad M., 2018, CHIN C IM GRAPH TECH, P243, DOI DOI 10.1007/978-981-10-7389-2_24
   [Anonymous], 2005, 16i/l British Machine Vison Conference
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bertels J, 2019, LECT NOTES COMPUT SC, V11765, P92, DOI 10.1007/978-3-030-32245-8_11
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   Chen Y, 2019, CONCURR COMP-PRACT E, P1
   Chen YB, 2020, J CONTEMP CHINA, V29, P1, DOI [10.1080/10670564.2019.1621526, 10.1080/01932691.2020.1791172, 10.1007/s12652-020-02066-z]
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Fan DP, 2020, IEEE T MED IMAGING, V39, P2626, DOI 10.1109/TMI.2020.2996645
   Fritscher K, 2015, IM COMP ASS RAD THER, P1
   Fritscher KD, 2014, MED PHYS, V41, DOI 10.1118/1.4871623
   Gu ZW, 2019, IEEE T MED IMAGING, V38, P2281, DOI 10.1109/TMI.2019.2903562
   Hancer E., 2020, Recent advances on memetic algorithms and its applications in image processing, V873, P47, DOI DOI 10.1007/978
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Ibragimov B, 2017, MED PHYS, V44, P547, DOI 10.1002/mp.12045
   Kumar V, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0202127
   Lang I, 2016, COMPUT BIOL MED, V72, P30, DOI 10.1016/j.compbiomed.2016.02.017
   Li ZY, 2016, PATTERN RECOGN, V52, P317, DOI 10.1016/j.patcog.2015.10.009
   Liao ZF, 2019, IEEE ACCESS, V7, P26411, DOI 10.1109/ACCESS.2019.2901742
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Men K, 2019, MED PHYS, V46, P286, DOI 10.1002/mp.13296
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Olszewska JI, 2019, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON AGENTS AND ARTIFICIAL INTELLIGENCE (ICAART), VOL 2, P850, DOI 10.5220/0007585208500856
   Olszewska JI, 2015, NEUROCOMPUTING, V161, P65, DOI 10.1016/j.neucom.2014.12.089
   Park B, 2019, J DIGIT IMAGING, V32, P1019, DOI 10.1007/s10278-019-00254-8
   Ramakrishnan T, 2016, J MED IMAG HEALTH IN, V6, P1426, DOI 10.1166/jmihi.2016.1822
   Rikitake R, 2019, JPN J CLIN ONCOL, V49, P639, DOI 10.1093/jjco/hyz042
   Rodrigues R, 2015, ULTRASOUND MED BIOL, V41, P1737, DOI 10.1016/j.ultrasmedbio.2015.01.012
   Sinha P, 2020, SN APPL SCI, V2, DOI 10.1007/s42452-020-1956-4
   Song B, 2019, J MED IMAG HEALTH IN, V9, P1011, DOI 10.1166/jmihi.2019.2686
   Sourati J, 2019, IEEE T MED IMAGING, V38, P2642, DOI 10.1109/TMI.2019.2907805
   Tang W, 2018, LECT NOTES COMPUT SC, V11140, P137, DOI 10.1007/978-3-030-01421-6_14
   Tong N, 2018, MED PHYS, V45, P4558, DOI 10.1002/mp.13147
   Tsafack N, 2020, INFORM SCIENCES, V515, P191, DOI 10.1016/j.ins.2019.10.070
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Wachinger C, 2017, IEEE T BIO-MED ENG, V64, P1492, DOI 10.1109/TBME.2016.2603119
   Wang GT, 2019, NEUROCOMPUTING, V338, P34, DOI 10.1016/j.neucom.2019.01.103
   Wang ZS, 2018, IEEE T IMAGE PROCESS, V27, P923, DOI 10.1109/TIP.2017.2768621
   Xu Y, 2019, ULTRASONICS, V91, P1, DOI 10.1016/j.ultras.2018.07.006
   Yang F, 2020, J MED IMAG HEALTH IN, V10, P11, DOI 10.1166/jmihi.2020.2830
   Yu SD, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081827
   Zhang JM, 2020, IEEE ACCESS, V8, P29742, DOI 10.1109/ACCESS.2020.2972338
   Zhang JM, 2020, ANN TELECOMMUN, V75, P369, DOI 10.1007/s12243-019-00731-9
   Zhang Y, 2018, PROC CVPR IEEE, P4320, DOI 10.1109/CVPR.2018.00454
   Zhou SH, 2020, IEEE T IMAGE PROCESS, V29, P461, DOI 10.1109/TIP.2019.2919937
NR 48
TC 24
Z9 24
U1 9
U2 94
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 15017
EP 15039
DI 10.1007/s11042-021-10515-w
EA FEB 2021
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613628000003
DA 2024-07-18
ER

PT J
AU Alshinwan, M
   Abualigah, L
   Shehab, M
   Abd Elaziz, M
   Khasawneh, AM
   Alabool, H
   Al Hamad, H
AF Alshinwan, Mohammad
   Abualigah, Laith
   Shehab, Mohammad
   Abd Elaziz, Mohamed
   Khasawneh, Ahmad M.
   Alabool, Hamzeh
   Al Hamad, Husam
TI Dragonfly algorithm: a comprehensive survey of its results, variants,
   and applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dragonfly algorithm; Meta-heuristic optimization algorithms;
   Optimization problems; Nature-inspired algorithms; Swarm intelligence
AB This paper thoroughly introduces a comprehensive review of the so-called Dragonfly algorithm (DA) and highlights its main characteristics. DA is considered one of the promising swarm optimization algorithms because it successfully applied in a wide range of optimization problems in several fields, such as engineering design, medical applications, image processing, power and energy systems, and economic load dispatch problems. The review describes the available literature on DA, including its variants like binary, discrete, modify, and hybridization of DA. Conclusions focus on the current work on DA, highlighting its disadvantages with suggests possible future research directions. Researchers and practitioners of DA belonging to a wide range of audiences from the domains of optimization, engineering, medical, data mining, and clustering, among others will benefit from this study.
C1 [Alshinwan, Mohammad; Abualigah, Laith; Khasawneh, Ahmad M.; Al Hamad, Husam] Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
   [Shehab, Mohammad] Aqaba Univ Technol, Comp Sci Dept, Aqaba 77110, Jordan.
   [Abd Elaziz, Mohamed] Wuhan Univ Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
   [Abd Elaziz, Mohamed] Zagazig Univ, Dept Math, Fac Sci, Zagazig, Egypt.
   [Alabool, Hamzeh] Saudi Elect Univ, Coll Comp & Informat, Abha, Saudi Arabia.
C3 Wuhan University of Technology; Egyptian Knowledge Bank (EKB); Zagazig
   University; Saudi Electronic University
RP Alshinwan, M (corresponding author), Amman Arab Univ, Fac Comp Sci & Informat, Amman 11953, Jordan.
EM mohmdsh@aau.edu.jo; Aligah.2020@gmail.com; moh.shehab12@gmail.com;
   sabd_el_aziz_m@yahoo.com; a.khasawneh@aau.edu.jo; dr.boul@gmail.com;
   hhamad@aau.edu.jo
RI , mohamed/AAH-8886-2019; Shehab, Mohammad/Q-1436-2019; Abualigah,
   Laith/ABC-9695-2020; Khasawneh, Ahmad Mohammad/AFJ-8626-2022; Al Hamad,
   Dr. Husam Ahmad/KIB-6051-2024; Shehab, Mohammad/AFK-4694-2022
OI , mohamed/0000-0002-7682-6269; Shehab, Mohammad/0000-0003-0211-3503;
   Abualigah, Laith/0000-0002-2203-4549; Khasawneh, Ahmad
   Mohammad/0000-0002-1850-3269; Al Hamad, Dr. Husam
   Ahmad/0000-0002-5530-1658; Shehab, Mohammad/0000-0003-0211-3503; Al
   Shinwan, Mohammad/0000-0002-3864-7323
CR Aadil F, 2018, J SUPERCOMPUT, V74, P4542, DOI 10.1007/s11227-018-2305-x
   Abdel-Basset M, 2017, LECT NOTES ARTIF INT, V10363, P491, DOI 10.1007/978-3-319-63315-2_43
   Abdelmadjid C, 2013, ENRGY PROCED, V36, P746, DOI 10.1016/j.egypro.2013.07.087
   Abdulameer AT., 2018, I ALHAITHAM J PURE A, V31, P268, DOI [10.30526/31.1.1834, DOI 10.30526/31.1.1834]
   Abualigah, ARCH COMPUT METHODS
   Abualigah L., 2020, SWARM INTELLIGENCE C, P127, DOI DOI 10.1201/9780429020582-5
   Abualigah L., 2019, Recent Advances in NLP: The Case of Arabic Language, P1
   Abualigah L. M. Q., 2019, Feature selection and enhanced krill herd algorithm for text document clustering, DOI [DOI 10.1007/978-3-030-10674-4, 10.1007/978-3-030-10674-4]
   Abualigah L, 2022, ENG COMPUT-GERMANY, V38, P1149, DOI 10.1007/s00366-020-01067-y
   Abualigah L, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10113827
   Abualigah L, 2021, CLUSTER COMPUT, V24, P205, DOI 10.1007/s10586-020-03075-5
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P12381, DOI 10.1007/s00521-020-04839-1
   Abualigah L, 2020, NEURAL COMPUT APPL, V32, P11195, DOI 10.1007/s00521-019-04629-4
   Abualigah LM, 2020, CURR MED IMAGING, V16, P296, DOI 10.2174/1573405614666180903112541
   Abualigah LM, 2018, J COMPUT SCI-NETH, V25, P456, DOI 10.1016/j.jocs.2017.07.018
   Abualigah LM, 2017, J SUPERCOMPUT, V73, P4773, DOI 10.1007/s11227-017-2046-2
   Abualigah LM, 2017, 2017 PALESTINIAN INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (PICICT), P22, DOI 10.1109/PICICT.2017.30
   Al Shinwan M, 2021, MULTIMED TOOLS APPL, V80, P16763, DOI 10.1007/s11042-020-08856-z
   Al-qaness MAA, 2020, INT J ENV RES PUB HE, V17, DOI 10.3390/ijerph17103520
   Alfar HE, 2020, Recent Advances in NLP: The Case of Arabic Language, P129, DOI DOI 10.1007/978-3-030-34614-0_7
   Aljarah I, 2020, Nature-Inspired Optimizers: Theories, Literature Reviews and Applications, P47, DOI [DOI 10.1007/978-3-030-12127-34, DOI 10.1007/978-3-030-12127-3_4]
   Alshaer YA, 2017, DRAGONFLY ESTIMATOR, V17, P108
   Amini Z, 2018, INT J NETW DISTRIB C, V6, P35
   Amroune M, 2018, ARAB J SCI ENG, V43, P3023, DOI 10.1007/s13369-017-3046-5
   [Anonymous], 2017, INT RES J ENG TECHNO
   Arulraj R., 2018, 2018 International Conference on Power, Energy, Control and Transmission Systems (ICPECTS). Proceedings, P258, DOI 10.1109/ICPECTS.2018.8521605
   Babayigit B, 2018, INT J ELECTRON, V105, P784, DOI 10.1080/00207217.2017.1407964
   Bhavani R., 2019, International Journal of Business Intelligence and Data Mining, V14, P62
   Bhesdadiya RH, 2016, 2016 INTERNATIONAL CONFERENCE ON ENERGY EFFICIENT TECHNOLOGIES FOR SUSTAINABILITY (ICEETS), P436, DOI 10.1109/ICEETS.2016.7583794
   Bolaji AL, 2016, APPL SOFT COMPUT, V49, P437, DOI 10.1016/j.asoc.2016.08.041
   Chen YY, 2019, MOLECULES, V24, DOI 10.3390/molecules24030421
   Cheng MY, 2014, COMPUT STRUCT, V139, P98, DOI 10.1016/j.compstruc.2014.03.007
   Chu X, 2017, DRAGONFLY ALGORITHM, P151, DOI [10.1007/978-981-10-5221-7_15, DOI 10.1007/978-981-10-5221-7_15]
   Daely PT, 2016, INT CONF UBIQ FUTUR, P1012, DOI 10.1109/ICUFN.2016.7536950
   Debnath S, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P226, DOI 10.1109/SPIN.2018.8474051
   Dhiman G, 2017, ADV ENG SOFTW, V114, P48, DOI 10.1016/j.advengsoft.2017.05.014
   Díaz-Cortés MA, 2018, INFRARED PHYS TECHN, V93, P346, DOI 10.1016/j.infrared.2018.08.007
   Dsouza, APPL COMPUT INF
   Gandomi AH, 2013, NEURAL COMPUT APPL, V22, P1239, DOI 10.1007/s00521-012-1028-9
   Ghosh S, 2018, ENERGIES, V11, DOI 10.3390/en11071892
   Glover F., 1977, DECISION SCI, V8, P156, DOI DOI 10.1111/J.1540-5915.1977.TB01074.X
   Gotmare A, 2017, SWARM EVOL COMPUT, V32, P68, DOI 10.1016/j.swevo.2016.06.007
   Grandis, 2018, EAGE HAGI 1 AS PAC M
   Gudi Siva Leela Krishna Chand, 2019, Journal of Information and Communication Convergence Engineering, V17, P84, DOI 10.6109/jicce.2019.17.1.84
   Guha D, 2018, COMPUT ELECTR ENG, V72, P137, DOI 10.1016/j.compeleceng.2018.09.003
   Hammouri AI, 2018, 2018 8TH IEEE INTERNATIONAL CONFERENCE ON CONTROL SYSTEM, COMPUTING AND ENGINEERING (ICCSCE 2018), P136, DOI 10.1109/ICCSCE.2018.8684963
   Hariharan M, 2018, COMPUT METH PROG BIO, V155, P39, DOI 10.1016/j.cmpb.2017.11.021
   He Q, 2007, APPL MATH COMPUT, V186, P1407, DOI 10.1016/j.amc.2006.07.134
   He Q, 2007, ENG APPL ARTIF INTEL, V20, P89, DOI 10.1016/j.engappai.2006.03.003
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   HEMA C, 2016, 2016 INT C COMM SIGN
   Huang FZ, 2007, APPL MATH COMPUT, V186, P340, DOI 10.1016/j.amc.2006.07.105
   Hussien SA, INT J SCI RES ENG TE, V6
   Jafari M, 2017, EUR J MECH A-SOLID, V66, P1, DOI 10.1016/j.euromechsol.2017.06.003
   Kajaan NAM, OPTIMIZING PEMFC MOD
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kaveh A, 2017, ADV ENG SOFTW, V110, P69, DOI 10.1016/j.advengsoft.2017.03.014
   Kaveh A, 2016, COMPUT STRUCT, V167, P69, DOI 10.1016/j.compstruc.2016.01.008
   Kaveh A, 2012, COMPUT STRUCT, V112, P283, DOI 10.1016/j.compstruc.2012.09.003
   Kaveh A, 2010, ENG COMPUTATION, V27, P155, DOI 10.1108/02644401011008577
   Khadanga RK, 2018, ARAB J SCI ENG, V43, P3103, DOI 10.1007/s13369-018-3151-0
   Khalilpourazari S, 2020, NEURAL COMPUT APPL, V32, P3987, DOI 10.1007/s00521-018-3872-8
   Khalilpourazari S, 2020, OPER RES-GER, V20, P1729, DOI 10.1007/s12351-018-0397-y
   Khasawneh Ahmad M., 2020, Journal of Physics: Conference Series, V1550, DOI 10.1088/1742-6596/1550/3/032145
   Khishe M, 2019, WIRELESS PERS COMMUN, V108, P2241, DOI 10.1007/s11277-019-06520-w
   Khunkitti S, 2018, ENERGIES, V11, DOI 10.3390/en11092270
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kouba NE, 2018, ELECTR POW COMPO SYS, V46, P2054, DOI 10.1080/15325008.2018.1533604
   Koziel S, 2011, STUD COMPUT INTELL, V356, P1, DOI 10.1007/978-3-642-20859-1
   KS SR, 2017, EXPERT SYST APPL, V83, P63, DOI DOI 10.1016/j.eswa.2017.04.033
   Kumar CA, 2019, CLUSTER COMPUT, V22, P1401, DOI 10.1007/s10586-018-1977-6
   LD DB, 2013, APPL SOFT COMPUT, V13, P2292, DOI DOI 10.1016/j.asoc.2013.01.025
   Lee KS, 2005, COMPUT METHOD APPL M, V194, P3902, DOI 10.1016/j.cma.2004.09.007
   Li LL, 2020, J CLEAN PROD, V242, DOI 10.1016/j.jclepro.2019.118447
   Lloret, IEEE SYS J
   Long W, 2019, EXPERT SYST APPL, V123, P108, DOI 10.1016/j.eswa.2018.11.032
   Mafarja M, 2020, DRAGONFLY ALGORITHM, P47
   Mafarja MM, 2017, 2017 INTERNATIONAL CONFERENCE ON NEW TRENDS IN COMPUTING SCIENCES (ICTCS), P12, DOI 10.1109/ICTCS.2017.43
   Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033
   MAHSEUR M, 2018, INT S MOD IMPL COMPL, P47
   Malhotra R, 2017, SWARM EVOL COMPUT, V32, P85, DOI 10.1016/j.swevo.2016.10.002
   Mezura-Montes E, 2008, INT J GEN SYST, V37, P443, DOI 10.1080/03081070701303470
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2015, KNOWL-BASED SYST, V89, P228, DOI 10.1016/j.knosys.2015.07.006
   Mirjalili S, 2016, NEURAL COMPUT APPL, V27, P495, DOI 10.1007/s00521-015-1870-7
   Mirjalili S, 2015, ADV ENG SOFTW, V83, P80, DOI 10.1016/j.advengsoft.2015.01.010
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Moghdani R, 2018, APPL SOFT COMPUT, V64, P161, DOI 10.1016/j.asoc.2017.11.043
   Nashaat H, 2020, IEEE ACCESS, V8, P35392, DOI 10.1109/ACCESS.2020.2974856
   Palappan A, 2018, GAZI U J SCI, V31, P1107
   Pathania AK, 2016, IND INT C POW ELECT
   Pathania Ajay Kumar RC., 2016, INT J ENG RES, V5, P861, DOI DOI 10.17950/IJER/V5S11/1106
   Polepally V, 2018, KYBERNETES, V47, P1138, DOI 10.1108/K-02-2017-0059
   Rakshit P, 2017, SWARM EVOL COMPUT, V33, P18, DOI 10.1016/j.swevo.2016.09.002
   Raman G, 2016, LECT NOTES COMPUT SC, V9712, P211, DOI 10.1007/978-3-319-41000-5_21
   Ramezani F, 2014, INT J PARALLEL PROG, V42, P739, DOI 10.1007/s10766-013-0275-4
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Reddy AS., 2016, J ELECTR ENG-SLOVAK, V16, P273
   Reddy M.S.K., 2017, INT J PURE APPL MATH, V116, P41
   Safari MJS, 2021, J HYDRAUL RES, V59, P500, DOI 10.1080/00221686.2020.1780501
   Salam MA, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (INISTA)
   Sawhney Ramit, 2018, 2018 International Conference on Communication, Computing and Internet of Things (IC3IoT). Proceedings, P91, DOI 10.1109/IC3IoT.2018.8668174
   Sayed GI, 2019, APPL INTELL, V49, P188, DOI 10.1007/s10489-018-1261-8
   Shehab M, 2021, ENG COMPUT-GERMANY, V37, P2931, DOI 10.1007/s00366-020-00971-7
   Shehab M, 2017, APPL SOFT COMPUT, V61, P1041, DOI 10.1016/j.asoc.2017.02.034
   Shehzad MU, 2021, INT J INNOV MANAG, V25, DOI 10.1142/S1363919621500286
   Shilaja C, 2019, FUTURE GENER COMP SY, V98, P319, DOI 10.1016/j.future.2018.12.070
   Shin PT, 2017, CHINES J, P419
   Simhadri K, 2019, ADV INTELL SYST, V698, P11, DOI 10.1007/978-981-13-1819-1_2
   Singh S, 2019, ADV INTELL SYST, V698, P211, DOI 10.1007/978-981-13-1819-1_21
   Song JM, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INFORMATION AND AUTOMATION (IEEE ICIA 2017), P1178, DOI 10.1109/ICInfA.2017.8079080
   Sudabattula SK, 2018, 2ND INTERNATIONAL CONFERENCE ON INTELLIGENT CIRCUITS AND SYSTEMS (ICICS 2018), P393, DOI 10.1109/ICICS.2018.00086
   Sugave SR, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P701, DOI 10.1109/ICCONS.2017.8250554
   Suresh M. C. V., 2018, Renewables: Wind, Water, and Solar, V5, DOI 10.1186/s40807-018-0050-7
   Suresh V, 2017, COMPUTING, V99, P59, DOI 10.1007/s00607-016-0514-9
   Tharwat A., 2017, INT C ADV INT SYST I, P309, DOI [DOI 10.1007/978-3-319-64861-3_29, 10.1007/978-3-319-64861-3_29]
   Vanishree J, 2018, INT J RENEW ENERGY R, V8, P56
   Veeramsetty V, 2018, ENERGY SYST, V9, P709, DOI 10.1007/s12667-017-0268-2
   Vikram KA, 2018, IOP CONF SER-MAT SCI, V310, DOI 10.1088/1757-899X/310/1/012154
   Vimala, 2018, J CIRC SYS COMPUT, P1950115
   Wang T, IEEE ACCESS
   Xu, 2020, APPL SOFT COMPUT, P106739
   Xu JZ, 2019, ARAB J SCI ENG, V44, P3473, DOI 10.1007/s13369-018-3536-0
   Xu L, 2019, IEEE ACCESS, V7, P19502, DOI 10.1109/ACCESS.2019.2896673
   Yang XS, 2009, WOR CONG NAT BIOL, P210, DOI 10.1109/nabic.2009.5393690
   Yang XS, 2010, STUD COMPUT INTELL, V284, P65, DOI 10.1007/978-3-642-12538-6_6
   Yasen M, 2018, INT CONF COMP SCI, P71, DOI 10.1109/CSIT.2018.8486178
   Yixuan F., 2016, J E CHINA JIAOTONG U, V4, P17
   Yousri D, 2020, ENERG CONVERS MANAGE, V223, DOI 10.1016/j.enconman.2020.113279
   Yue J, 2018, INT C SMART INT BUIL, P433
NR 130
TC 42
Z9 42
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14979
EP 15016
DI 10.1007/s11042-020-10255-3
EA JAN 2021
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000613170500001
DA 2024-07-18
ER

PT J
AU Preethi, S
   Aishwarya, P
AF Preethi, S.
   Aishwarya, P.
TI An efficient wavelet-based image fusion for brain tumor detection and
   segmentation over PET and MRI image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE ODNN; SMO; GLCM; Weighted k-means; Brain tumor; CT image;
   Classification; Segmentation; Fusion
ID NEURAL-NETWORK; CLASSIFICATION
AB A brain tumor is an abnormal growth of cells, reproducing themselves in an uncontrolled manner. In a medical diagnosis system, the accurate detection of location and size plays a very important role in the diagnosis of brain tumors. Magnetic Resonance Imaging (MRI) and Positron Emission Tomography (PET) are the most widely used techniques for diagnosis. The detection of a brain tumor in PET and MRI images is a challenging task due to its low sensitive boundary pixels. For accurate detection of brain tumors, in this paper, an efficient fusion-based brain tumor detection and segmentation is proposed. Here, at first, we fuse the input image using a discrete wavelet transform (DWT) and novel fusion rule. After the fusion process, the gray-level co-occurrence matrix (GLCM) features are extracted. Then, we categorize the brain images as normal and abnormal images using Optimal Deep Neural Network (ODNN). Here, the network weights of DNN are optimally selected using Spider Monkey Optimization (SMO) algorithm. After the classification process, the brain tumor region is extracted from abnormal brain images using the weighted k-means technique. The performance of the proposed methodology is analyzed in terms of sensitivity, specificity, and accuracy.
C1 [Preethi, S.] Atria Inst Technol, Dept CSE, Bengaluru, Karnataka, India.
   [Aishwarya, P.] Atria Inst Technol, Comp Sci Dept, Bangalore, Karnataka, India.
RP Preethi, S (corresponding author), Atria Inst Technol, Dept CSE, Bengaluru, Karnataka, India.
EM preethis0378@gmail.com
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   [Anonymous], 2015, International Journal of Emerging Technology and Advanced Engineering
   [Anonymous], 2014, P WIN CONTR C
   Antoniadis A, 2003, BIOINFORMATICS, V19, P563, DOI 10.1093/bioinformatics/btg062
   Ari A, 2018, TURK J ELECTR ENG CO, V26, P2275, DOI 10.3906/elk-1801-8
   Bahadure NB, 2017, INT J BIOMED IMAGING, V2017, DOI 10.1155/2017/9749108
   Bandyopadhyay SK., 2012, INT J INFORM COMMUN, V2
   Bansal JC, 2014, MEMET COMPUT, V6, P31, DOI 10.1007/s12293-013-0128-0
   Cheng Z, 2018, COMPLEXITY, DOI 10.1155/2018/2879610
   Chu J, 2018, IEEE ACCESS, V6, P19959, DOI 10.1109/ACCESS.2018.2815149
   Daimary D, 2020, PROCEDIA COMPUT SCI, V167, P2419, DOI 10.1016/j.procs.2020.03.295
   Damodharan S, 2015, INT ARAB J INF TECHN, V12, P42
   Deepak S, 2019, COMPUT BIOL MED, V111, DOI 10.1016/j.compbiomed.2019.103345
   Demirhan A, 2015, IEEE J BIOMED HEALTH, V19, P1451, DOI 10.1109/JBHI.2014.2360515
   Ding Y, 2020, NEUROCOMPUTING, V412, P19, DOI 10.1016/j.neucom.2020.06.078
   Havaei M, 2017, MED IMAGE ANAL, V35, P18, DOI 10.1016/j.media.2016.05.004
   He, 2020, NEUROCOMPUTING
   Jayachandran A, 2014, ARAB J SCI ENG, V39, P7073, DOI 10.1007/s13369-014-1334-x
   Jerry M, 2017, INT EL DEVICES MEET
   Kamboj A., 2019, ADV INTELL SYST COMP, V714, P2019
   Kaur T, 2019, MULTIMEDIA TOOLS APP
   Kavitha A. R., 2019, International Journal of Business Intelligence and Data Mining, V15, P71
   Kumar P., 2015, MIDDLE-EAST J SCI RE, V23, P2106, DOI DOI 10.5829/idosi.mejsr.2015.23.09.22458
   Leng L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20092644
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2015, PATTERN RECOGN, V48, P2290, DOI 10.1016/j.patcog.2015.01.021
   Leng L, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P1705, DOI 10.1109/CISP.2013.6743951
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2013, NEUROCOMPUTING, V108, P1, DOI 10.1016/j.neucom.2012.08.028
   Leng L, 2012, 2012 25TH IEEE CANADIAN CONFERENCE ON ELECTRICAL & COMPUTER ENGINEERING (CCECE)
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu HF, 2017, IEEE T KNOWL DATA EN, V29, P1129, DOI 10.1109/TKDE.2017.2650229
   Lu Leng, 2012, Proceedings of the 2012 International Conference on Wavelet Analysis and Pattern Recognition (ICWAPR), P164, DOI 10.1109/ICWAPR.2012.6294772
   Ma C, 2018, IEEE T MED IMAGING, V37, P1943, DOI 10.1109/TMI.2018.2805821
   Nabizadeh N, 2015, COMPUT ELECTR ENG, V45, P286, DOI 10.1016/j.compeleceng.2015.02.007
   Preethi S, 2019, J INTELL SYST, V28, P571, DOI 10.1515/jisys-2017-0090
   Seetha J., 2018, BIOMED PHARMACOL J, V11, P1457, DOI [DOI 10.13005/bpj/1511, 10.13005/bpj/1511]
   Selvapandian A, 2018, COMPUT METH PROG BIO, V166, P33, DOI 10.1016/j.cmpb.2018.09.006
   Shanthakumar P, 2015, COMPUT ELECTR ENG, V45, P302, DOI 10.1016/j.compeleceng.2015.05.011
   Wang D, 2020, INT J APPROX REASON, V127, P33, DOI 10.1016/j.ijar.2020.08.010
   Yang ZY, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8121464
   Yin B, 2020, BIOMED SIGNAL PROCES, V56, DOI 10.1016/j.bspc.2019.101728
   Zhang YQ, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20041010
NR 44
TC 20
Z9 20
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14789
EP 14806
DI 10.1007/s11042-021-10538-3
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612270700001
DA 2024-07-18
ER

PT J
AU Mousavi, SMR
   Naghsh, A
AF Mousavi, Sayed Mohammad Raza
   Naghsh, Alireza
TI A robust Plenoptic image watermarking method using graph-based transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Plenoptic images; Digital image watermarking; Graph-based transform
   (GBT); Genetic algorithm (GA)
ID DWT
AB Numerous methods have been introduced for digital images watermarking. But there are fewer studies on plenoptic images. This image has more information (such as depth) and costs more than regular digital images. So, protecting the ownership of plenoptic is important. In this paper a robust plenoptic image watermarking has been introduced which is based on Graph-based Transform (GBT). Also, in order to maximizing the robustness of watermarking an optimization has been used to find the best graph structure of GBT. This optimization has done using a Genetic Algorithm. One of the common ways to robust the watermarking is the use of discrete cosine transform (DCT). In this study, we have shown that the proposed method is much more powerful than DCT. The proposed method is tested on three plenoptic images namely Alley, Basic Shapes and Coffee Table and the results show that the proposed method is more robust to similar methods such as DCT methods. Watermarking was evaluated using BER, SSIM and PSNR criteria and Gaussian noise attacks with varying intensities.
C1 [Mousavi, Sayed Mohammad Raza; Naghsh, Alireza] Islamic Azad Univ, Najafabad Branch, Dept Elect Engn, Najafabad, Iran.
C3 Islamic Azad University
RP Naghsh, A (corresponding author), Islamic Azad Univ, Najafabad Branch, Dept Elect Engn, Najafabad, Iran.
EM mmousavi.sr@gmail.com; naghsh.a@pel.iaun.ac.ir
RI naghsh, alireza/AAO-2400-2021
OI naghsh, alireza/0000-0002-0842-0419
CR Ansari A, 2018, OPT LASER ENG, V107, P325, DOI 10.1016/j.optlaseng.2018.03.028
   Araghi TK, 2019, FUTURE GENER COMP SY, V101, P1223, DOI 10.1016/j.future.2019.07.064
   Farzaneh M, 2018, 2018 9TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P410, DOI 10.1109/ISTEL.2018.8661027
   Fatahalian K, 2011, LECT 18 LIGHT FIELD
   Goli MS, 2017, 3 INT C PATT REC IM
   Hajjaji MA, 2019, SECUR COMMUN NETW, DOI 10.1155/2019/1294267
   Hou JH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P177, DOI 10.1109/ICDSP.2016.7868540
   Kim WS, 2012, INT CONF ACOUST SPEE, P813, DOI 10.1109/ICASSP.2012.6288008
   Rajak DK, 2020, J ADHES SCI TECHNOL, V34, P2613, DOI 10.1080/01694243.2020.1780716
   Liu JX, 2019, IEEE ACCESS, V7, P80849, DOI 10.1109/ACCESS.2019.2915596
   Moosazadeh M, 2019, J INF SECUR APPL, V47, P28, DOI 10.1016/j.jisa.2019.04.001
   Naghsh, 2019, J INTELLIGENT PROCED, V10, P13
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Potdar VA, 2005, 2005 3RD IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS (INDIN), P709
   Savakar DG, 2019, ARAB J SCI ENG, V44, P3995, DOI 10.1007/s13369-019-03751-8
   Toroghi, 2020, ARXIV PREPRINT ARXIV
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Wang XY, 2016, NEUROCOMPUTING, V174, P627, DOI 10.1016/j.neucom.2015.09.082
   Yang HY, 2013, COMPUT ELECTR ENG, V39, P893, DOI 10.1016/j.compeleceng.2012.07.009
NR 19
TC 3
Z9 4
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14591
EP 14608
DI 10.1007/s11042-021-10555-2
EA JAN 2021
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000612271000001
DA 2024-07-18
ER

PT J
AU Kumar, A
   Kumar, M
   Kaur, A
AF Kumar, Ashu
   Kumar, Munish
   Kaur, Amandeep
TI Face detection in still images under occlusion and non-uniform
   illumination
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face detection; Occlusion; Human computer interaction; Illumination
ID NEURAL-NETWORK
AB Face detection is important part of face recognition system. In face recognition, face detection is taken not so seriously. Face detection is taken for granted; primarily focus is on face recognition. Also, many challenges associated with face detection, increases the value of TN (True Negative). A lot of work has been done in field of face recognition. But in field of face detection, especially with problems of face occlusion and non-uniform illumination, not so much work has been done. It directly affects the efficiency of applications linked with face detection, example face recognition, surveillance, etc. So, these reasons motivate us to do research in field of face detection, especially with problems of face occlusion and non-uniform illumination. The main objective of this article is to detect face in still image. Experimental work has been conducted on images having problem of face occlusion and non-uniform illumination. Experimental images have been taken from public dataset AR face dataset and Color FERET dataset. One manual dataset has also been created for experimental purpose. The images in this manual dataset have been taken from the internet. This involves making the machine intelligent enough to acquire the human perception and knowledge to detect, localize and recognize the face in an arbitrary image with the same ease as humans do it. This article proposes an efficient technique for face detection from still images under occlusion and non-uniform illumination. The authors have presented a face detection technique using a combination of YCbCr, HSV and L x a x b color model. The proposed technique improved results in terms of Accuracy, Detection Rate, False Detection Rate and Precision. This technique can be useful in the surveillance and security related applications.
C1 [Kumar, Ashu] Punjabi Univ, Dept Comp Sci, Patiala, Punjab, India.
   [Kumar, Munish] Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
   [Kaur, Amandeep] Cent Univ Punjab, Dept Comp Sci & Technol, Bathinda, Punjab, India.
C3 Punjabi University; Central University of Punjab
RP Kumar, M (corresponding author), Maharaja Ranjit Singh Punjab Tech Univ, Dept Computat Sci, Bathinda, Punjab, India.
EM ashu_sa@pbi.ac.in; munishcse@gmail.com; aman_k2007@hotmail.com
RI Kumar, Munish/P-7756-2018; kaur, Amandeep/S-1044-2019
OI Kumar, Munish/0000-0003-0115-1620; kaur, Amandeep/0000-0002-7397-3511;
   Sarao, Amandeep Kaur/0000-0003-4844-9299
CR Bellil W, 2016, MULTIMED TOOLS APPL, V75, P365, DOI 10.1007/s11042-014-2294-6
   Bonnen K, 2013, IEEE T INF FOREN SEC, V8, P239, DOI 10.1109/TIFS.2012.2226580
   Chen Zhipeng, 2010, 2010 2nd International Conference on Networking and Digital Society (ICNDS 2010), P664, DOI 10.1109/ICNDS.2010.5479392
   Cheney J, 2015, INT CONF BIOMETR, P229, DOI 10.1109/ICB.2015.7139089
   Guo ZH, 2018, 2018 14TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P106, DOI 10.1109/CIS2018.2018.00031
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   HU W-C., 2011, Journal of Information Hiding and Multimedia Signal Processing, V2, P123
   Jiang HZ, 2017, IEEE INT CONF AUTOMA, P650, DOI [10.1109/FG.2017.82, 10.1109/MWSYM.2017.8058653]
   Khandait S. P., 2009, International Journal of Recent Trends in Engineering, V2, P179
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Nasir AFA., 2019, J INTELL MANUF MECHA, V1, P58
   Ranjan Rajeev, 2017, Proceedings of the Indian National Science Academy Part B Biological Sciences, V87, P377, DOI 10.1007/s40011-015-0618-6
   Rowley HA, 1996, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.1996.517075
   Sharma R, 2018, P REC FIND INT COMP, P193
   Soundararajan R, 2019, SIGNAL PROCESS-IMAGE, V72, P92, DOI 10.1016/j.image.2018.12.012
   Sun X., 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Tao DC, 2008, IEEE T CIRC SYST VID, V18, P1397, DOI 10.1109/TCSVT.2008.2002825
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang L, 2020, IEEE T CYBERNETICS, V50, P3330, DOI 10.1109/TCYB.2019.2894498
   Zhang LQ, 2017, INT CON DISTR COMP S, P129, DOI 10.1109/ICDCS.2017.95
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
NR 21
TC 51
Z9 51
U1 5
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 10
BP 14565
EP 14590
DI 10.1007/s11042-020-10457-9
EA JAN 2021
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RU2AM
UT WOS:000611964400003
DA 2024-07-18
ER

PT J
AU Yan, LY
   Fu, JR
   Wang, CZ
   Ye, ZW
   Chen, HW
   Ling, HF
AF Yan, Lingyu
   Fu, Jiarun
   Wang, Chunzhi
   Ye, Zhiwei
   Chen, Hongwei
   Ling, Hefei
TI Enhanced network optimized generative adversarial network for image
   enhancement
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Enhanced network; Generative adversarial networks; Low-light; Image
   enhancement
ID RETINEX
AB With the development of image recognition technology, face, body shape, and other factors have been widely used as identification labels, which provide a lot of convenience for our daily life. However, image recognition has much higher requirements for image conditions than traditional identification methods like a password. Therefore, image enhancement plays an important role in the process of image analysis for images with noise, among which the image of low-light is the top priority of our research. In this paper, a low-light image enhancement method based on the enhanced network module optimized Generative Adversarial Networks(GAN) is proposed. The proposed method first applied the enhancement network to input the image into the generator to generate a similar image in the new space, Then constructed a loss function and minimized it to train the discriminator, which is used to compare the image generated by the generator with the real image. We implemented the proposed method on two image datasets (DPED, LOL), and compared it with both the traditional image enhancement method and the deep learning approach. Experiments showed that our proposed network enhanced images have higher PNSR and SSIM, the overall perception of relatively good quality, demonstrating the effectiveness of the method in the aspect of low illumination image enhancement.
C1 [Yan, Lingyu; Fu, Jiarun; Wang, Chunzhi; Ye, Zhiwei; Chen, Hongwei] Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
   [Ling, Hefei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan, Peoples R China.
C3 Hubei University of Technology; Huazhong University of Science &
   Technology
RP Yan, LY (corresponding author), Hubei Univ Technol, Sch Comp Sci, Wuhan, Peoples R China.
EM yanlingyu@hbut.edu.cn; jiarunfu@163.com; chunzhiwang@163.com;
   weizhiye@163.com; chw@sina.com; hefei_ling@hust.edu.cn
FU National Natural Science Foundation of China [61772180, 61701173];
   Technological innovation project of Hubei Province 2019 [2019AAA047];
   Green Industry Science and Technology Leadership Program of Hubei
   University of Technology [CPYF2018005]; Hubei province graduate
   education innovation plan
FX This work is funded by the National Natural Science Foundation of China
   under Grant No.61772180 & No. 61701173, Technological innovation project
   of Hubei Province 2019(2019AAA047), Green Industry Science and
   Technology Leadership Program of Hubei University of
   Technology(No.CPYF2018005) and Hubei province graduate education
   innovation plan.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Chen C, 2018, PROC CVPR IEEE, P3291, DOI 10.1109/CVPR.2018.00347
   Chen JT, 2021, IEEE ACM T COMPUT BI, V18, P103, DOI 10.1109/TCBB.2020.2991173
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Fu QT, 2018, IEEE ACCESS, V6, P61277, DOI 10.1109/ACCESS.2018.2870638
   Fu XY, 2016, PROC CVPR IEEE, P2782, DOI 10.1109/CVPR.2016.304
   Gao HH, 2020, IEEE INTERNET THINGS, V7, P4532, DOI 10.1109/JIOT.2019.2956827
   Gao WJ, 2019, COMPUT INTELL-US, V35, P496, DOI 10.1111/coin.12202
   Gonçalves GR, 2018, SIBGRAPI, P110, DOI 10.1109/SIBGRAPI.2018.00021
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Ignatov A, 2017, IEEE I CONF COMP VIS, P3297, DOI 10.1109/ICCV.2017.355
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   King DB, 2015, ACS SYM SER, V1214, P1
   Lan M, 2020, INFORM SCIENCES, V535, P156, DOI 10.1016/j.ins.2020.05.062
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Li CL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P414, DOI 10.1109/ICIVC.2017.7984589
   Li Q.Z., 2015, CHIN J LASERS, V42, P272, DOI 10.3788/CJL201542.0209001
   Liu D., 2019, ENLIGHTENGAN DEEP LI
   Lore KG, 2017, PATTERN RECOGN, V61, P650, DOI 10.1016/j.patcog.2016.06.008
   Lv F., 2018, P BMVC, V220, P4
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Radford A., 2015, ARXIV
   Shen L., 2017, ARXIV PREPRINT ARXIV, P171102488
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wei Cui, 2018, 2018 Photonics North (PN), DOI 10.1109/PN.2018.8438843
   Yuan L, 2012, LECT NOTES COMPUT SC, V7575, P771, DOI 10.1007/978-3-642-33765-9_55
   Zhang YH, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1632, DOI 10.1145/3343031.3350926
NR 36
TC 18
Z9 20
U1 7
U2 48
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 14363
EP 14381
DI 10.1007/s11042-020-10310-z
EA JAN 2021
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000611041300004
OA hybrid
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, BK
AF Kumar, Sanjay
   Singh, Binod Kumar
TI An improved watermarking scheme for color image using alpha blending
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermark; Entropy; Color image; LWT; Arnold cat map
ID SINGULAR-VALUE DECOMPOSITION; WAVELET TRANSFORM; ROBUST; DOMAIN;
   ALGORITHM
AB This paper proposes a robust and secure watermarking method for a color image in YCbCr color space. In this study, watermarking is performed using Lifting Wavelet Transform (LWT). Here, edge entropy and information entropy is used to find the block to embed watermark. In this work alpha blending scheme is used for embedding and extraction of watermarks in the LWT domain. The use of LWT makes the proposed scheme faster and more efficient. The Arnold Cat Map (ACM) is used to enhance watermark security. Numerous tests are presented to illustrate the feasibility of the proposed scheme. The experimental results obtained are compared to state-of-the-art schemes, which demonstrate the superiority of the proposed scheme.
C1 [Kumar, Sanjay; Singh, Binod Kumar] Natl Inst Technol Jamshedpur, Comp Sci & Engn, Jamshedpur, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Kumar, S (corresponding author), Natl Inst Technol Jamshedpur, Comp Sci & Engn, Jamshedpur, Bihar, India.
EM 2017rscs001@nitjsr.ac.in; bksingh.cse@nitjsr.ac.in
RI Kumar, Dr. Sanjay/V-3889-2019; Singh, Binod/AAB-8663-2019
OI Kumar, Dr. Sanjay/0000-0002-4564-1085; Singh, Binod/0000-0002-2697-8918
CR Ali M, 2015, INFORM SCIENCES, V301, P44, DOI 10.1016/j.ins.2014.12.042
   Bajaj A, 2014, 2014 INTERNATIONAL CONFERENCE ON ADVANCES IN ENGINEERING AND TECHNOLOGY RESEARCH (ICAETR)
   Chou H-H, 2020, INFORM SCIENCES
   Chowdhury FS, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12020266
   Degadwala SD, 2020, PROCEDIA COMPUT SCI, V167, P213, DOI 10.1016/j.procs.2020.03.198
   Desai SD, 2017, STUD COMPUT INTELL, V660, P15, DOI 10.1007/978-3-319-44790-2_2
   Ernawan F, 2020, VISUAL COMPUT, V36, P19, DOI 10.1007/s00371-018-1567-x
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Fragoso-Navarro E, 2018, IEEE ACCESS, V6, P75767, DOI 10.1109/ACCESS.2018.2883322
   Hosny KM, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3325193
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Kejgir SG, 2014, INT J COMPUT SCI ENG, V9, P371, DOI 10.1504/IJCSE.2014.060719
   Kumar R, 2016, INT CONF IND INF SYS, P1, DOI 10.1109/ICIINFS.2016.8262896
   Kumar S, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1802, DOI 10.1109/RTEICT.2016.7808145
   Kutter M, 1999, PROC SPIE, V3657, P226, DOI 10.1117/12.344672
   Laur L, 2015, RADIOENGINEERING, V24, P1025, DOI 10.13164/re.2015.1025
   Liu DC, 2020, MULTIMED TOOLS APPL, V79, P7491, DOI 10.1007/s11042-019-08423-1
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Maity SP, 2010, AEU-INT J ELECTRON C, V64, P243, DOI 10.1016/j.aeue.2008.10.004
   Makbol NM, 2016, IET IMAGE PROCESS, V10, P34, DOI 10.1049/iet-ipr.2014.0965
   Mehta R, 2016, MULTIMED TOOLS APPL, V75, P4129, DOI 10.1007/s11042-015-3084-5
   Moeinaddini E, 2019, SOFT COMPUT, V23, P9685, DOI 10.1007/s00500-018-3535-9
   Pandey MK, 2020, INT J SYST ASSUR ENG, V11, P320, DOI 10.1007/s13198-019-00859-w
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Prabha K, 2020, MULTIMED TOOLS APPL, V79, P6845, DOI 10.1007/s11042-019-08212-w
   Roy S, 2019, IJST-T ELECTR ENG, V43, P201, DOI 10.1007/s40998-018-0109-x
   Roy S, 2018, WIRELESS PERS COMMUN, V98, P2223, DOI 10.1007/s11277-017-4971-z
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Shi GM, 2009, IEEE T CIRCUITS-II, V56, P290, DOI 10.1109/TCSII.2009.2015393
   Singh R, 2020, IET IMAGE PROCESS, V14, P2052, DOI 10.1049/iet-ipr.2019.1059
   Singh SP, 2019, MULTIMED TOOLS APPL, V78, P20765, DOI 10.1007/s11042-019-7394-x
   Su QT, 2020, MULTIMED TOOLS APPL, V79, P30023, DOI 10.1007/s11042-020-09436-x
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Wang CP, 2017, SIGNAL PROCESS, V134, P197, DOI 10.1016/j.sigpro.2016.12.010
   Wang J, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112868
   Yadav M, MULTIMED TOOLS APPL, P1
NR 38
TC 18
Z9 18
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13975
EP 13999
DI 10.1007/s11042-020-10397-4
EA JAN 2021
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000609068600001
DA 2024-07-18
ER

PT J
AU Enamoto, L
   Li, WG
   Rocha, GP
AF Enamoto, Liriam
   Weigang, Li
   Filho, Geraldo P. Rocha
TI Generic framework for multilingual short text categorization using
   convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Convolutional neural network; Text categorization; Multilingual text;
   Social media
ID SOCIAL MEDIA
AB Online social media is a powerful source of information that can influence users' decisions. Due to the huge volume of data generated by such media, many researches have been done to automate text categorization. However, finding useful information to satisfy user's needs is not an easy task. There are many challenges to overcome especially in short text categorization that in addition to being a time-consuming and costly process, short messages have misspellings, typos, irony words and lack of context. To solve these challenges, this article proposes GM-ShorT, a Generic framework for Multilingual Short Text Categorization based on Convolutional Neural Network (CNN). For this, GM-ShorT collects online social media data. Such data were used as input to CNN that is combined with a word embedding mechanism to categorize short text messages. We explored several architectures for CNN and show that GM-ShorT can be used in multilingual Short text categorization with an accuracy of 13.58% higher when compared to other classical approaches.
C1 [Enamoto, Liriam; Weigang, Li; Filho, Geraldo P. Rocha] Univ Brasilia, Dept Comp Sci, Brasilia, DF, Brazil.
C3 Universidade de Brasilia
RP Enamoto, L (corresponding author), Univ Brasilia, Dept Comp Sci, Brasilia, DF, Brazil.
EM liriam.enamoto@gmail.com; weigang@unb.br; geraldof@unb.br
RI Filho, Geraldo Pereira Rocha/Q-6497-2016; Pereira, Geraldo/D-6912-2012;
   Weigang, Li/ISV-0473-2023; Weigang, Li/AAK-1351-2020
OI Filho, Geraldo Pereira Rocha/0000-0001-6795-2768; Weigang,
   Li/0000-0003-1826-1850; Weigang, Li/0000-0003-1826-1850; Enamoto,
   Liriam/0000-0003-0188-5966
CR [Anonymous], 2016, INT C INF SYST CRIS
   [Anonymous], 2016, ARXIV161008229
   [Anonymous], 2014, Effective Use of Word Order for Text Categorization with Convolutional Neural Networks
   [Anonymous], 2013, AD VANCES NEURAL INF
   Bengio Y, 2001, ADV NEUR IN, V13, P932
   Vilas AF, 2019, MULTIMED TOOLS APPL, V78, P9217, DOI 10.1007/s11042-018-6388-4
   Filho GPR, 2019, INTERNET THINGS-NETH, V5, P153, DOI 10.1016/j.iot.2018.12.004
   Georgakopoulos SV, 2018, 10TH HELLENIC CONFERENCE ON ARTIFICIAL INTELLIGENCE (SETN 2018), DOI 10.1145/3200947.3208069
   Hartmann N, 2017, P 11 BRAZ S INF HUM, P122
   Kim Y., 2014, P 2014 C EMPIRICAL M
   Lai SW, 2015, AAAI CONF ARTIF INTE, P2267
   Merchant RM, 2011, NEW ENGL J MED, V365, P289, DOI 10.1056/NEJMp1103591
   Mori T, 2017, INF MEDIA TECHNOL, V12, P111
   Mori T., 2017, 23 ANN M NATURALLANG, P787
   Neto J., 2018, J COMPUT SCI-NETH, V14, P1420, DOI [10.3844/jcssp.2018.1420.1430, DOI 10.3844/JCSSP.2018.1420.1430]
   Nguyen Dat Tien, 2016, ARXIV161001030
   Oliveira DFM, 2019, PHYSICA A, V525, P657, DOI 10.1016/j.physa.2019.03.034
   Rocha  GP, 2020, FUTURE GENER COMP SY, V103, P18, DOI 10.1016/j.future.2019.09.045
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Simon T, 2015, INT J INFORM MANAGE, V35, P609, DOI 10.1016/j.ijinfomgt.2015.07.001
   Sosa P M, 2016, TWITTER SENTIMENT AN
   Steiner-Correa F, 2018, SOFT COMPUT, V22, P8227, DOI 10.1007/s00500-017-2766-5
   Sun F, 2014, IEEE C COMP INTEL FI, P122, DOI 10.1109/CIFEr.2014.6924063
   Wang J, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2915
   Yang Y., 2018, Ti-cnn: Convolutional neural networks for fake news detection
   Zhang X, 2017, ARXIV170802657
   Zhang X, 2015, ADV NEUR IN, V28
   Zhang Y, 2015, ARXIV PREPRINT ARXIV
NR 29
TC 9
Z9 9
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2021
VL 80
IS 9
BP 13475
EP 13490
DI 10.1007/s11042-020-10314-9
EA JAN 2021
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RR7PU
UT WOS:000607776200002
DA 2024-07-18
ER

PT J
AU Karanwal, S
AF Karanwal, Shekhar
TI A comparative study of 14 state of art descriptors for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature extraction; Global approaches; Local approaches; Gray scale
   images and color images
ID LOCAL BINARY PATTERNS; TEXTURE; CLASSIFICATION; FEATURES; DEEP;
   EIGENFACES; LBP
AB This research paper presents a comparative study between 14 state of art descriptors which includes Local Binary Pattern (LBP), Median Binary Pattern (MBP), 6 x 6 Multiscale Block LBP (6 x 6 MB-LBP), Local Neighborhood Difference Pattern (LNDP), Logically Connected-LBP (LC-LBP), Local Phase Quantization (LPQ), Compound LBP (CLBP), Horizontal Elliptical LBP (HELBP), Vertical Elliptical LBP (VELBP), ELBP, Neighborhood Intensity Based LBP (NI-LBP), Median Robust Extended LBP Based on NI (MRELBP-NI), Radial Difference-LBP (RD-LBP) and Transition LBP (tLBP). For all the descriptors the features are extracted globally and the dimensionality of the feature size is reduced by employing Principal Component Analysis (PCA) and Fishers Linear Discriminant Analysis (FLDA). Finally classification is performed by Support Vector Machines (SVMs) and Nearest Neighbor (NN). Experiments are performed on 8 challenging databases which covers all the major challenges such as pose variations, illumination variations, expression variations and occlusion changes. The 8 challenging databases includes ORL, GT, Faces94, MIT-CBCL, Yale, YB, EYB and SOF. Out of all the descriptors it is the performance of the CLBP descriptor which is most encouraging. On some occasions the MRELBP-NI descriptor also achieves good results. But all in all the CLBP descriptor achieves the best results. In addition to this Deep learning based descriptors are also discussed in the paper.
C1 [Karanwal, Shekhar] Graph Era, Dept Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
C3 Graphic Era University
RP Karanwal, S (corresponding author), Graph Era, Dept Comp Sci & Engn, Dehra Dun, Uttarakhand, India.
EM shekhar.karanwal@gmail.com
RI Karanwal, Dr. Shekhar/AGF-1442-2022
OI Karanwal, Dr. Shekhar/0000-0003-2932-4132
CR Afifi M, 2019, J VIS COMMUN IMAGE R, V62, P77, DOI 10.1016/j.jvcir.2019.05.001
   Ahmed F., 2011, 2011 Proceedings of IEEE 12th International Symposium on Computational Intelligence and Informatics (CINTI 2011), P391, DOI 10.1109/CINTI.2011.6108536
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Anbarjafari G, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-6
   [Anonymous], 2013, INT C BIOM ICB
   [Anonymous], 2018, ABS180406655 CORR
   [Anonymous], 2010, P COMP VIS WINT WORK
   [Anonymous], 2014, RECENT ADV COMPUTER
   Awad AI, 2016, STUD COMPUT INTELL, V630, P1, DOI 10.1007/978-3-319-28854-3
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen J, 2008, P INT C COMP VIS PAT
   Choi I, 2012, PRIMO VASCULAR SYSTEM: ITS ROLE IN CANCER AND REGENERATION, P121, DOI 10.1007/978-1-4614-0601-3_17
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030699
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Faraji MR, 2016, NEUROCOMPUTING, V199, P16, DOI 10.1016/j.neucom.2016.01.094
   Georgescu MI, 2019, IEEE ACCESS, V7, P64827, DOI 10.1109/ACCESS.2019.2917266
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goyani M.M., 2017, Electronic Letters on Computer Vision and Image Analysis, V16, P54
   Hadi-Vencheh A, 2015, INT J COMPUT INTEG M, V28, P534, DOI 10.1080/0951192X.2014.880948
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   Han H, 2013, PATTERN RECOGN, V46, P1691, DOI 10.1016/j.patcog.2012.11.022
   Hassaballah M, 2015, IET COMPUT VIS, V9, P614, DOI 10.1049/iet-cvi.2014.0084
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hu R, 2018, MULTIMED TOOLS APPL, V77, P6863, DOI 10.1007/s11042-017-4604-2
   Huang MM, 2015, PATTERN RECOGN LETT, V54, P56, DOI 10.1016/j.patrec.2014.12.001
   Huang XH, 2013, LECT NOTES COMPUT SC, V7944, P1
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Kittler J, 2003, IMAGE VISION COMPUT, V21, P1163, DOI 10.1016/j.imavis.2003.09.013
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lei Z, 2012, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2012.6247967
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Leng L., 2012, P INT C WAV AN PATT, P164, DOI DOI 10.1109/ICWAPR.2012.6294772
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2014, SECUR COMMUN NETW, V7, P1860, DOI 10.1002/sec.900
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Liu BY, 2019, IEEE I CONF COMP VIS, P10051, DOI 10.1109/ICCV.2019.01015
   Liu L, 2016, IEEE T IMAGE PROCESS, V25, P1368, DOI 10.1109/TIP.2016.2522378
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Mohammadi MR, 2013, IRAN CONF MACH, P315, DOI 10.1109/IranianMVIP.2013.6780002
   Montazer GA, 2015, LECT NOTES COMPUT SC, V9094, P241, DOI 10.1007/978-3-319-19258-1_21
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Rahman MM, 2015, 2015 18TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (ICCIT), P390, DOI 10.1109/ICCITechn.2015.7488102
   Rakshit RD, 2017, J CHIN INST ENG, V40, P82, DOI 10.1080/02533839.2016.1259020
   Rassem TH, 2014, SCI WORLD J, DOI 10.1155/2014/373254
   Ren JF, 2015, INT CONF ACOUST SPEE, P1503, DOI 10.1109/ICASSP.2015.7178221
   Ren JF, 2013, IEEE T IMAGE PROCESS, V22, P4049, DOI 10.1109/TIP.2013.2268976
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shakoor MH, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417500197
   Sohail ASM, 2007, LECT NOTES COMPUT SC, V4418, P555
   Sun YP, 2015, ADV DIFFER EQU-NY, P1, DOI 10.1186/s13662-015-0433-7
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang SF, 2010, LECT NOTES COMPUT SC, V6064, P104, DOI 10.1007/978-3-642-13318-3_14
   Wang XB, 2019, IEEE I CONF COMP VIS, P9357, DOI 10.1109/ICCV.2019.00945
   WEYRAUCH B, 2004, 1 IEEE WORKSH FAC PR, P1
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang WK, 2011, 2011 9TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2011), P48, DOI 10.1109/WCICA.2011.5970590
   Yu W, 2014, SIGNAL IMAGE VIDEO P, V8, pS155, DOI 10.1007/s11760-014-0652-5
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhou H, 2008, INFORM SCIENCES, V178, P4314, DOI 10.1016/j.ins.2008.07.015
   Zhu C, 2013, PATTERN RECOGN, V46, P1949, DOI 10.1016/j.patcog.2013.01.003
NR 74
TC 18
Z9 18
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 8
BP 12195
EP 12234
DI 10.1007/s11042-020-09833-2
EA JAN 2021
PG 40
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RO1IL
UT WOS:000606409000007
DA 2024-07-18
ER

PT J
AU Singh, A
   Singh, J
AF Singh, Amanjot
   Singh, Jagroop
TI A content adaptive method of de-blocking and super-resolution of
   compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image upscaling; Image interpolation; Image de-blocking; Super
   resolution; High resolution; Low resolution
ID DEBLOCKING; ARTIFACTS; REDUCTION
AB In this paper, a new method of image upscaling along with de-blocking of compressed images has been presented. In the case of highly compressed images, there is a high probability that these images may contain the noise in the form of blocking artifacts. In this presented work, a spatial domain-based approach has been suggested with two roles, one of which is to process the image for reduction of compression-based blocking artifacts and other is to upscale the low-resolution image to high-resolution image. Image upscaling is one of the implementation techniques of image super-resolution (SR). It is a type of SR where only a single image-based SR is being implemented. In the proposed technique, image de-blocking along with interpolation based super resolution has been developed in the spatial domain, therefore it is a practical and realistic method. The results of the proposed method in the form of quality metrics like PSNR, MSE and MSSIM have been compared with other methods of interpolation along with de-blocking method.
C1 [Singh, Amanjot] IKG PTU, Jalandhar Kapurthala Highway, Kapurthala 144603, Punjab, India.
   [Singh, Amanjot] Lovely Profess Univ, SEEE, Phagwara 144411, Punjab, India.
   [Singh, Jagroop] DAVIET, Dept Elect & Commun Engn, Jalandhar 144008, Punjab, India.
C3 I. K. Gujral Punjab Technical University; Lovely Professional
   University; DAV Institute of Engineering & Technology
RP Singh, A (corresponding author), IKG PTU, Jalandhar Kapurthala Highway, Kapurthala 144603, Punjab, India.; Singh, A (corresponding author), Lovely Profess Univ, SEEE, Phagwara 144411, Punjab, India.
EM er.ajotsingh@gmail.com; roopasidhu@yahoo.com
OI singh, Jagroop/0000-0002-2090-2891
CR [Anonymous], 2016, International Journal of Computer Applications, DOI DOI 10.5120/IJCA2016911458
   [Anonymous], 2014, ACCV WORKSH IM REST
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Bevilacqua M, 2014, IEEE T IMAGE PROCESS, V23, P5334, DOI 10.1109/TIP.2014.2364116
   Carrato S, 2000, IEEE SIGNAL PROC LET, V7, P132, DOI 10.1109/97.844630
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   HaCohen Y., 2010, ICCP, P1
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Kim J, 2009, IEEE T CONSUM ELECTR, V55, P933, DOI 10.1109/TCE.2009.5174477
   Kim KI, 2008, LECT NOTES COMPUT SC, V5096, P456
   Kim Y, 2003, IEEE T CONSUM ELECTR, V49, P1438, DOI 10.1109/TCE.2003.1261252
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Liew AWC, 2004, IEEE T CIRC SYST VID, V14, P450, DOI 10.1109/TCSVT.2004.825555
   List P, 2003, IEEE T CIRC SYST VID, V13, P614, DOI 10.1109/TCSVT.2003.815175
   Luo Y, 2003, IEEE T IMAGE PROCESS, V12, P838, DOI 10.1109/TIP.2003.814252
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Prasad Jaiswal S, 2012, IEEE INT INSTR MEAS
   Ruangsang W., 2017, Consumer Electronics, P1
   Sajjad M, 2014, MULTIMED TOOLS APPL, V72, P2063, DOI 10.1007/s11042-012-1325-4
   Sajjad M, 2015, MULTIMED TOOLS APPL, V74, P8961, DOI 10.1007/s11042-013-1570-1
   Singh J, 2011, AEU-INT J ELECTRON C, V65, P827, DOI 10.1016/j.aeue.2011.01.012
   Singh S, 2007, DIGIT SIGNAL PROCESS, V17, P225, DOI 10.1016/j.dsp.2005.08.003
   Tang Y, 2013, J VIS COMMUN IMAGE R, V24, P148, DOI 10.1016/j.jvcir.2012.02.003
   Thévenaz P, 2000, BIOMED EN S, P393
   Timofte R, 2015, LECT NOTES COMPUT SC, V9006, P111, DOI 10.1007/978-3-319-16817-3_8
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   UNSER M, 1991, IEEE T PATTERN ANAL, V13, P277, DOI 10.1109/34.75515
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang C, 2013, SIGNAL PROCESS-IMAGE, V28, P522, DOI 10.1016/j.image.2013.01.006
   Wang J, 2015, DIGIT SIGNAL PROCESS, V42, P80, DOI 10.1016/j.dsp.2015.03.009
   Wu SH, 2001, IEEE T CIRC SYST VID, V11, P1193, DOI 10.1109/76.964789
   Xiong ZW, 2010, IEEE T IMAGE PROCESS, V19, P2017, DOI 10.1109/TIP.2010.2045707
   Yang CY, 2013, IEEE I CONF COMP VIS, P561, DOI 10.1109/ICCV.2013.75
   Yang JH, 2008, CRYST RES TECHNOL, V43, P999, DOI 10.1002/crat.200800010
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Zhou D, 2012, IET IMAGE PROCESS, V6, P627, DOI 10.1049/iet-ipr.2011.0534
NR 37
TC 2
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 7
BP 11095
EP 11131
DI 10.1007/s11042-020-10112-3
EA JAN 2021
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA RC8BM
UT WOS:000604816700003
DA 2024-07-18
ER

PT J
AU Yong, Y
   Xin, G
   Zhang, SC
AF Yong, Yang
   Xin, Gu
   Shichang, Zhang
TI Multimedia based risk forecasting model for frequent natural disasters
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Natural disasters; Frequently-happening environment; Agricultural
   economy; Risk prediction; Model research; Parallel random tree
AB Agricultural catastrophe risk assessment is not only a practical problem which needs to be solved for the stable development of China's agriculture under the overall background of global climate change, but also a scientific issue which urgently needs to be solved for the discipline of agricultural risk assessment. At present, the academic circle mainly studies the theories and methods of agricultural catastrophe risk assessment from different perspectives based on risk factors, risk loss as well as risk mechanism, but fails to provide a clear answer to the loss degree of agricultural production caused by extreme weather events as well as the probability distribution of agricultural catastrophe loss. In view of this problem, and on the basis of modern risk analysis and assessment theory, a basic framework for agricultural catastrophe risk assessment was constructed in this thesis, and the parallel random tree algorithm was adopted to construct an agricultural economic risk prediction model in the environment of frequent natural disasters, which could be effectively applied to agricultural economic risk prevention and control.
C1 [Yong, Yang] Northeast Agr Univ, Humanity & Law Sch, Harbin, Heilongjiang, Peoples R China.
   [Xin, Gu] Heilongjiang Univ Chinese Med, Coll Humanities & Management, Harbin, Heilongjiang, Peoples R China.
   [Shichang, Zhang] Harbin Inst Technol, Sch Marxism, Harbin, Heilongjiang, Peoples R China.
C3 Northeast Agricultural University - China; Heilongjiang University of
   Chinese Medicine; Harbin Institute of Technology
RP Yong, Y (corresponding author), Northeast Agr Univ, Humanity & Law Sch, Harbin, Heilongjiang, Peoples R China.
EM yyong179@163.com
CR Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   Ambrus A, 2014, AM ECON REV, V104, P149, DOI 10.1257/aer.104.1.149
   Arunkumar N, 2017, PATTERN RECOGN LETT, V94, P112, DOI 10.1016/j.patrec.2017.05.007
   BALL T, 1993, SIGPLAN NOTICES, V28, P300, DOI 10.1145/173262.155119
   Berry M, 2015, COMPUT ENVIRON URBAN, V51, P13, DOI 10.1016/j.compenvurbsys.2014.12.004
   Brioude J, 2013, GEOSCI MODEL DEV, V6, P1889, DOI 10.5194/gmd-6-1889-2013
   Bucklin RE, 2003, J MARKETING RES, V40, P249, DOI 10.1509/jmkr.40.3.249.19241
   Carrère C, 2006, EUR ECON REV, V50, P223, DOI 10.1016/j.euroecorev.2004.06.001
   FRIEDMAN BM, 1989, BROOKINGS PAP ECO AC, P137
   Gerbessiotis A. V., 1996, SPAA '96. 8th Annual ACM Symposium on Parallel Algorithms and Architectures, P223, DOI 10.1145/237502.237561
   Hernandez YJ, 1999, J VIROL, V73, P8549, DOI 10.1128/JVI.73.10.8549-8558.1999
   Jacques B., 2010, Entomologia Experimentalis Et Applicata, V97, P93
   Jerrett M, 2005, J TOXICOL ENV HEAL A, V68, P1207, DOI 10.1080/15287390590936085
   KAPSALIS A, 1993, J OPER RES SOC, V44, P397, DOI 10.1057/jors.1993.69
   Louberge H., 1999, J RISK INSUR, V22, P125
   Magnani F, 2000, PLANT CELL ENVIRON, V23, P251, DOI 10.1046/j.1365-3040.2000.00537.x
   Morris DW, 2009, ANN NY ACAD SCI, V1162, P334, DOI 10.1111/j.1749-6632.2009.04494.x
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Zhou DM, 2018, J POWER SOURCES, V399, P314, DOI 10.1016/j.jpowsour.2018.06.098
   Zhou DM, 2018, IEEE T IND ELECTRON, V65, P6787, DOI 10.1109/TIE.2018.2803723
   Zhou DM, 2017, J POWER SOURCES, V366, P278, DOI 10.1016/j.jpowsour.2017.08.107
NR 21
TC 1
Z9 1
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35463
EP 35474
DI 10.1007/s11042-019-07790-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000595980900041
DA 2024-07-18
ER

PT J
AU Holla, MR
   Pais, AR
AF Holla, M. Raviraja
   Pais, Alwyn R.
TI An effective secret image sharing using quantum logic and GPGPU based
   EDNN super-resolution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Halftoning; Share generation; Embedded shares; Reconstruction;
   Super-resolution
ID PROGRESSIVE VISUAL CRYPTOGRAPHY
AB This paper presented an effective secret image sharing with super-resolution utilizing quantum logic and enthalpy based adaptive deep neural network. The proposed technique is processed as; at the sender side, initially secret input image is converted into a halftone image format by utilizing Error diffusion with varying thresholds (EDVT) method. Then in share generation phase, shares are produced with the basis matrix. Here, the basis matrix is created utilizing the quantum logic methodology. Then in embedding phase, discrete wavelet transform (DWT) is utilized for encoding shares. At the receiver side, encoded image is reconstructed using XOR operation and results the low-resolution image. Finally, enthalpy based adaptive deep neural network (EDNN) is designed with the General Purpose Graphic Processing Unit (GPGPU) to enhance the resolution of the reconstructed images and to lessen the time complexity of deep learning. Here, the EDNN is adapted with the enthalpy based normalization to mitigate the over fitting in layers of deep neural network. Furthermore, the proficiency of the proposed work improved in terms of normalized cross correlation, normalized absolute error, peak signal to noise ratio, mean square error and execution time by deploying images among CPU and GPGPU in an enhanced manner.
C1 [Holla, M. Raviraja; Pais, Alwyn R.] Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Informat Secur Res Lab, Surathkal 575025, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Holla, MR (corresponding author), Natl Inst Technol Karnataka, Dept Comp Sci & Engn, Informat Secur Res Lab, Surathkal 575025, India.
EM raviraj.holla@manipal.edu
RI M, Raviraja/AAQ-4561-2021
OI M, Raviraja/0000-0003-1627-552X; Pais, Alwyn/0000-0003-4571-4608
CR Al-Khalid R. I., 2017, Journal of Software Engineering and Applications, V10, P1, DOI [10.4236/JSEA.2017.101001, DOI 10.4236/JSEA.2017.101001]
   [Anonymous], 2018, IEEE T CIRCUITS SYST
   Bharanivendhan N, 2014, INT J COMPUT APPL, V92
   Cao YP, 2019, SIGNAL PROCESS, V162, P115, DOI 10.1016/j.sigpro.2019.03.018
   De Prisco R, 2014, IEEE T INF FOREN SEC, V9, P653, DOI 10.1109/TIFS.2014.2305574
   Deka B, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101941
   Hou YC, 2012, BPVSS
   Hou YC, 2018, INT ARAB J INF TECHN, V15, P321
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   JoshiJesalkumari A., 2013, INT J COMPUT APPL TE, V2, P350
   Lai WS, 2019, IEEE T PATTERN ANAL, V41, P2599, DOI 10.1109/TPAMI.2018.2865304
   Liu F, 2012, J VIS COMMUN IMAGE R, V23, P331, DOI 10.1016/j.jvcir.2011.11.003
   Mayya V., 2017, P INT C ADV IM PROC, P62
   Mhala NC, 2019, SIGNAL PROCESS, V162, P253, DOI 10.1016/j.sigpro.2019.04.023
   Mhala NC, 2019, INT CONF COMMUN SYST, P823, DOI [10.1109/comsnets.2019.8711327, 10.1109/COMSNETS.2019.8711327]
   Monoth Thomas, 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 105), P179, DOI 10.1007/978-981-13-1927-3_18
   Naphade, 2015, IOSR J COMP ENG IOSR, P1
   Padiya I, 2015, INT J ADV RES ELECT
   Qin JH, 2020, NEUROCOMPUTING, V379, P334, DOI 10.1016/j.neucom.2019.10.076
   Qiu DF, 2020, COMPUT METH PROG BIO, V187, DOI 10.1016/j.cmpb.2019.105059
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Srividhya S., 2019, Innovations in Computer Science and Engineering. Proceedings of the Fifth ICICSE 2017. Lecture Notes in Networks and Systems (LNNS 32), P289, DOI 10.1007/978-981-10-8201-6_33
   Tong T., 2017, P IEEE INT C COMP VI, P4799
   Ulutas M, 2010, MATH PROBL ENG, V2010, DOI 10.1155/2010/593236
   Yamada H, 2014, 2014 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP), P27, DOI 10.1109/ISANP.2014.7026513
   Yan B, 2016, MULTIMED TOOLS APPL, V75, P11157, DOI 10.1007/s11042-015-2838-4
   Yan XH, 2018, J REAL-TIME IMAGE PR, V14, P61, DOI 10.1007/s11554-015-0540-4
   Yuan Y, 2019, J REAL-TIME IMAGE PR, V16, P81, DOI 10.1007/s11554-018-0774-z
   Zeng K, 2019, APPL INTELL, V49, P292, DOI 10.1007/s10489-018-1270-7
NR 30
TC 0
Z9 0
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9255
EP 9280
DI 10.1007/s11042-020-10065-7
EA NOV 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587972400001
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, BK
AF Kumar, Sanjay
   Singh, Binod Kumar
TI Entropy based spatial domain image watermarking and its performance
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Entropy; Spatial domain; Hill cipher; Imperceptibility; PSNR
ID ROBUST
AB Digital image watermarking technique based on LSB Substitution and Hill Cipher is presented and examined in this paper. For better imperceptibility watermark is inserted in the spatial domain. Further the watermark is implanted in the Cover Image block having the highest entropy value. To improve the security of the watermark hill cipher encryption is used. Both subjective and objective image quality assessment technique has been used to evaluate the imperceptibility of the proposed scheme.Further, the perceptual perfection of the watermarked pictures accomplished in the proposed framework has been contrasted and some state-of-art watermarking strategies. Test results demonstrates that the displayed method is robust against different image processing attacks like Salt and Peppers, Gaussian filter attack, Median filter attacks, etc.
C1 [Kumar, Sanjay; Singh, Binod Kumar] Natl Inst Technol Jamshedpur, Jamshedpur, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Kumar, S (corresponding author), Natl Inst Technol Jamshedpur, Jamshedpur, Bihar, India.
EM 2017rscs001@nitjsr.ac.in
RI Singh, Binod/AAB-8663-2019; Kumar, Dr. Sanjay/V-3889-2019
OI Singh, Binod/0000-0002-2697-8918; Kumar, Dr. Sanjay/0000-0002-4564-1085
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   Alquwayfili N, 2016, IMAGING SCI J, V64, P425, DOI 10.1080/13682199.2016.1227514
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Anbarasi LJ, 2017, IMAGING SCI J, V65, P409, DOI 10.1080/13682199.2017.1359992
   BAL SN, 2018, J KING SAUD U COMP I
   Bouslimi D, 2016, SIGNAL PROCESS-IMAGE, V47, P263, DOI 10.1016/j.image.2016.06.012
   Cheng WT, 2019, NEURAL COMPUT APPL, V31, P309, DOI 10.1007/s00521-018-3775-8
   Dawahdeh ZE, 2018, J KING SAUD UNIV-COM, V30, P349, DOI 10.1016/j.jksuci.2017.06.004
   Fatahbeygi A, 2019, J INF SECUR APPL, V45, P71, DOI 10.1016/j.jisa.2019.01.005
   Islam M, 2020, NEURAL COMPUT APPL, V32, P1379, DOI 10.1007/s00521-018-3647-2
   Kumar S, 2020, MULTIMED TOOLS APPL, V79, P20149
   Li GF, 2019, IEEE ACCESS, V7, P11533, DOI 10.1109/ACCESS.2019.2891749
   Li LD, 2009, AEU-INT J ELECTRON C, V63, P123, DOI 10.1016/j.aeue.2007.11.007
   Mansoori EG, 2016, IMAGING SCI J, V64, P204, DOI 10.1080/13682199.2016.1159816
   Parah SA, 2017, INT J ELECTRON, V104, P659, DOI 10.1080/00207217.2016.1242162
   Patvardhan C, 2018, MULTIMED TOOLS APPL, V77, P12655, DOI 10.1007/s11042-017-4909-1
   Qi JX, 2019, IEEE ACCESS, V7, P61378, DOI 10.1109/ACCESS.2019.2914728
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Singh RK, 2018, J INFORM OPTIM SCI, V39, DOI 10.1080/02522667.2017.1372153
   Singh S., 2016, 2016 14 INT C CONTR, P1, DOI DOI 10.1109/ICARCV.2016.7838807
   Su YG, 2019, J MOD OPTIC, V66, P377, DOI 10.1080/09500340.2018.1530387
   Thung KH, 2009, 2009 INTERNATIONAL CONFERENCE FOR TECHNICAL POSTGRADUATES (TECHPOS 2009), P153
   Wazirali R, 2015, 2015 ASIA-PACIFIC CONFERENCE ON COMPUTER-AIDED SYSTEM ENGINEERING - APCASE 2015, P238, DOI 10.1109/APCASE.2015.49
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Yan X, 2017, ENTERP INF SYST-UK, V11, P223, DOI 10.1080/17517575.2015.1033767
   Yao YZ, 2019, SIGNAL PROCESS, V164, P386, DOI 10.1016/j.sigpro.2019.06.034
   Zhang H, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9030045
NR 27
TC 27
Z9 28
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2021
VL 80
IS 6
BP 9315
EP 9331
DI 10.1007/s11042-020-09943-x
EA NOV 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QP9GZ
UT WOS:000587972400006
DA 2024-07-18
ER

PT J
AU Jahangeer, GSB
   Rajkumar, TD
AF Jahangeer, Gul Shaira Banu
   Rajkumar, T. Dhiliphan
TI Early detection of breast cancer using hybrid of series network and
   VGG-16
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast Cancer; Mammogram image; Decision based partial median filter;
   VGG-16 and series network; BAT-SURF feature extraction and gradient
   descent decision tree classifier
ID SEGMENTATION
AB Breast cancer is nowadays becoming a serious problem and acts as a main reason for death of women around the world. Hence various devices are being utilized for the detection of breast cancer at an earlier stage and diagnosing it in an earlier stage might even results in complete cure of the disease. Among the wide range of devices available, mammogram is one of the commonly employed and most effective approaches involved in the detection of breast cancer. It records the affected area in the form of mammogram images and these images are processed through image processing techniques for the detection of cancer affected regions. In this paper, novelties have given in all the image processing aspects such as filtering, segmentation, feature extraction and classification. The salt and pepper noises in the mammogram images are eliminated by the usage of novel decision based partial median filter. Then the filtered images are segmented based utilizing a novel technique which is formed on integrating the deep learning techniques of VGG-16 and series network. Features of the segmented images have extracted through BAT-SURF feature extraction, where the orientation of the interest points are extracted using Bat optimization algorithm along with SURF (i.e.) Speeded up Robust Features. It extract most important key points from SURF features and then the extracted image has classified by using the novel Gradient descent decision tree classifier in which a stable learning path provided for easy convergence. Then the performance of the proposed system has analyzed based on the performance metrics like accuracy, specificity, sensitivity, recall, precision, Jaccard coefficient, F score and missed classification. Based on the results obtained, the conclusion of the proposed work has attained enhanced results on comparing with other state of the art approaches. The accuracy value of the proposed hybrid VGG-16 and series network segmentation technique determined as 96.45 and similarly the accuracy value of the proposed Gradient Descent Decision Tree Classification technique has value shows 95.15.
C1 [Jahangeer, Gul Shaira Banu; Rajkumar, T. Dhiliphan] Kalasalingam Acad Res & Educ, Sch Comp, Dept CSE, Krishnankoil, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education
RP Jahangeer, GSB (corresponding author), Kalasalingam Acad Res & Educ, Sch Comp, Dept CSE, Krishnankoil, Tamil Nadu, India.
EM shairaamjath@gmail.com; t.dhiliphan@klu.ac.in
OI thambidurai, dhiliphanrajkumar/0000-0001-6309-0275; Banu Jahangeer, Gul
   Shaira/0000-0003-4877-8738
CR Abdel-Zaher AM, 2016, EXPERT SYST APPL, V46, P139, DOI 10.1016/j.eswa.2015.10.015
   Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   [Anonymous], 2015, Biosci, Biotechnol Res Asia, DOI DOI 10.13005/BBRA/1627
   Becker AS, 2017, INVEST RADIOL, V52, P434, DOI 10.1097/RLI.0000000000000358
   Chougrad H, 2018, COMPUT METH PROG BIO, V157, P19, DOI 10.1016/j.cmpb.2018.01.011
   Danaee P, 2017, BIOCOMPUT-PAC SYM, P219
   Ghosh S, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329784
   Hesamian MH, 2019, J DIGIT IMAGING, V32, P582, DOI 10.1007/s10278-019-00227-x
   Ho D. J., 2019, ARXIV191013042
   Houssami N, 2017, CANCER EPIDEMIOL, V47, P94, DOI 10.1016/j.canep.2017.01.008
   Jang HJ, 2019, ARCH PHARM RES, P1
   Jiménez G, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00145
   Kaur P, 2019, INFORM MED UNLOCKED, P100151
   Singh VK, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112855
   Li SY, 2019, IEEE ACCESS, V7, P59037, DOI 10.1109/ACCESS.2019.2914873
   Punitha S., 2018, Future Computing and Informatics Journal, V3, P348, DOI 10.1016/j.fcij.2018.10.005
   Raghavendra U, 2016, APPL SOFT COMPUT, V46, P151, DOI 10.1016/j.asoc.2016.04.036
   Rastghalam R, 2016, PATTERN RECOGN, V51, P176, DOI 10.1016/j.patcog.2015.09.009
   Saba T, 2019, MICROSC RES TECHNIQ, V82, P775, DOI 10.1002/jemt.23222
   Sahni Poorti, 2019, Advances in Interdisciplinary Engineering. Select Proceedings of FLAME 2018. Lecture Notes in Mechanical Engineering (LNME), P813, DOI 10.1007/978-981-13-6577-5_79
   Saknure S, 2020, MULTISCALE SEGMENTAT
   Selvathi D, 2018, L N COMPUT VIS BIOME, V25, P159, DOI 10.1007/978-3-319-61316-1_8
   Shayma'a AH, 2019, MULTIMED TOOLS APPL, P1
   Shi P, 2018, COMPUT BIOL MED, V96, P178, DOI 10.1016/j.compbiomed.2018.03.011
   Singh AK, 2015, PROCEDIA COMPUT SCI, V54, P676, DOI 10.1016/j.procs.2015.06.079
   Urooj S, 2018, SENSORS IMAGE PROCES, P85
   Wang SH, 2017, FUND INFORM, V151, P191, DOI 10.3233/FI-2017-1487
   Wang ZQ, 2019, IEEE ACCESS, V7, P105146, DOI 10.1109/ACCESS.2019.2892795
NR 28
TC 26
Z9 26
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 5
BP 7853
EP 7886
DI 10.1007/s11042-020-09914-2
EA OCT 2020
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA QM1VQ
UT WOS:000587058000008
DA 2024-07-18
ER

PT J
AU Li, C
   Li, Y
   Wang, CH
   Dong, SF
   Gao, HF
   Zhao, Q
   Wu, W
AF Li, Chen
   Li, Yu
   Wang, Chunhua
   Dong, Shifeng
   Gao, Haofei
   Zhao, Qian
   Wu, Wei
TI The multimedia recommendation algorithm based on probability graphical
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia recommendation; Probability graphical model; Undirected
   graphical model; Collaborative filtering; Bayesians Network
ID SYSTEMS
AB In the multimedia big data, the demand for personalized multimedia recommendation algorithm is increasing to ease the multimedia information overload. The multimedia recommendation system has been applied in various industries and has been playing a significant role. With the development of multimedia big data, developing multimedia recommendation algorithms can effectively be used in multimedia data. However, a large number of prevailing recommendation systems cannot meet the multimedia recommendation requirements, since they ignore the user-item interactions with multimedia content. This essay realizes the multimedia recommendation based on probability graphical model, to deal with the cold start and data sparsity involved in collaborative filtering recommendation, proposing that add the user tag to user-item model. The essay optimizes the multimedia recommendation algorithm based on undirected graphical model and tests it with singular value decomposition, clustering and Naive Bayes separately. The essay also builds the checklist recommendation model and experiments extensively for comparison with the conditional multimedia recommendation algorithm, by using PersonalRank algorithm based on random-walk to work out the weight coefficient of the user tag. At the same time, the essay enhances the probability-graph multimedia recommendation algorithm by dimensionality reduction and clustering, with the result of noticeably improved precision and recall.
C1 [Li, Chen; Li, Yu] Commun Univ China, Beijing, Peoples R China.
   [Wang, Chunhua; Dong, Shifeng; Gao, Haofei; Zhao, Qian; Wu, Wei] Beijing Aerosp Changfeng Sci & Ind Grp, Beijing, Peoples R China.
C3 Communication University of China
RP Li, C (corresponding author), Commun Univ China, Beijing, Peoples R China.
EM lichengood@cuc.edu.cn; liyu@cuc.edu.cn; wangchunhua06@163.com;
   dongshileng01@126.com; gaohaofei01@126.com; zhaoqian022@126.com;
   wuweihtcf@163.com
FU Fundamental Research Funds for the Central Universities; National Key
   Research and Development Program of China [2018YFC0832000]
FX The work is supported by the Fundamental Research Funds for the Central
   Universities and National Key Research and Development Program of China
   (2018YFC0832000). We thank the reviewers and editor for their helpful
   comments.
CR Abu Arqub O, 2019, FUND INFORM, V166, P87, DOI 10.3233/FI-2019-1795
   Abu Arqub O, 2019, FUND INFORM, V166, P111, DOI 10.3233/FI-2019-1796
   Anitha G, 2019, CLUSTER COMPUT, V22, P13583, DOI 10.1007/s10586-018-2010-9
   Arnab A, 2018, IEEE SIGNAL PROC MAG, V35, P37, DOI 10.1109/MSP.2017.2762355
   Boutemedjet S, 2008, IEEE T MULTIMEDIA, V10, P52, DOI 10.1109/TMM.2007.911226
   Chen JY, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P335, DOI 10.1145/3077136.3080797
   Cui LZ, 2018, FUTURE GENER COMP SY, V86, P1459, DOI 10.1016/j.future.2017.07.017
   Fontenla-Romero O, 2018, IEEE T NEUR NET LEAR, V29, P3900, DOI 10.1109/TNNLS.2017.2738118
   Fu MS, 2019, IEEE T CYBERNETICS, V49, P1084, DOI 10.1109/TCYB.2018.2795041
   Hameed Farhan Mahmuod H, 2016, INT J COMPUT APPL, V134, P32
   Hernando A, 2016, KNOWL-BASED SYST, V97, P188, DOI 10.1016/j.knosys.2015.12.018
   Huang FH, 2018, IEEE T NEUR NET LEAR, V29, P3034, DOI 10.1109/TNNLS.2017.2710090
   Huang FH, 2018, IEEE T KNOWL DATA EN, V30, P703, DOI 10.1109/TKDE.2017.2777462
   Ji Jingzhou T, 2019, ELECT DES ENG, V9, P1
   Kassák O, 2016, INFORM PROCESS MANAG, V52, P459, DOI 10.1016/j.ipm.2015.10.001
   Khalili A. A., 2019, MICROSYST TECHNOL, P1
   Kim KJ, 2017, INT J PROD RES, V55, P5037, DOI 10.1080/00207543.2017.1287443
   Lee S, 2020, J AMB INTEL HUM COMP, V11, P363, DOI 10.1007/s12652-019-01226-0
   Li B, 2015, IEEE T CYBERNETICS, V45, P1054, DOI 10.1109/TCYB.2014.2343982
   [李琳 Li Lin], 2020, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V33, P32
   Li ZS, 2019, MULTIMED TOOLS APPL, V78, P605, DOI 10.1007/s11042-017-5291-8
   [刘建伟 Liu Jianwei], 2016, [电子学报, Acta Electronica Sinica], V44, P1219
   [刘建伟 Liu Jianwei], 2014, [计算机科学, Computer Science], V41, P1
   Lu X., 2016, THESIS
   Musella F, 2017, INT J QUAL SERV SCI, V9, P347, DOI 10.1108/IJQSS-02-2017-0007
   Nie S, 2018, IEEE SIGNAL PROC MAG, V35, P101, DOI 10.1109/MSP.2017.2763440
   Peng YH, 2019, CLUSTER COMPUT, V22, pS6871, DOI 10.1007/s10586-017-1673-y
   Rohit, 2018, C INF COMM TECHN
   Roy Sushmita, 2009, Proc Int Conf Mach Learn, V382, P905
   Tang JH, 2020, IEEE T KNOWL DATA EN, V32, P855, DOI 10.1109/TKDE.2019.2893638
   Varando G, 2015, J MACH LEARN RES, V16, P2725
   Vasimuddin M, 2018, INT PARALL DISTRIB P, P34, DOI 10.1109/IPDPS.2018.00014
   Wang Dong, 2017, Computer Engineering and Applications, V53, P146, DOI 10.3778/j.issn.1002-8331.1511-0002
   Wu XY, 2015, PLOS ONE, V10, DOI [10.1371/journal.pone.0118041, 10.1371/journal.pone.0119607]
   Wu XW, 2019, NAT PROD RES, V33, P204, DOI 10.1080/14786419.2018.1443095
   Xiangqian C, 2015, SOFTW GUIDE, V7, P64
   Xiao ZL, 2015, IEEE T MOBILE COMPUT, V14, P2286, DOI 10.1109/TMC.2015.2398431
   Xu QD, 2018, ACM/SIGIR PROCEEDINGS 2018, P981, DOI 10.1145/3209978.3210117
   Yang JC, 2017, FUTURE GENER COMP SY, V70, P94, DOI 10.1016/j.future.2016.06.015
   Yang XW, 2017, IEEE T COMPUT SOC SY, V4, P1, DOI 10.1109/TCSS.2017.2665122
   Yanjun Z, 2017, RECENT PATENTS COMPU, V10, P171
   [张顶立 Zhang Dingli], 2018, [水力发电学报, Journal of Hydroelectric Engineering], V37, P1
   Zhang SN, 2019, COMMUN STAT-SIMUL C, V48, P1346, DOI 10.1080/03610918.2017.1414244
   Zhang Y, 2019, IEEE T IND INFORM, V15, P1393, DOI 10.1109/TII.2018.2856842
   Zhang ZK, 2019, RESEARCH-CHINA, V2019, DOI 10.34133/2019/2391486
   Zhang ZY, 2019, IEEE ACCESS, V7, P117749, DOI 10.1109/ACCESS.2019.2934898
   Zheleva Elena., 2010, Proceedings of the 19th international conference on World wide web, WWW '10, P1019
   Zhou B., 2019, Dianli Jianshe/Electr. Power Constr., V40, P68, DOI [/10.3969/j.issn.1000-7229.2019.01.009, DOI 10.3969/J.ISSN.1000-7229.2019.01.009]
   Zhou ML, 2019, INT J PATTERN RECOGN, V33, DOI 10.1142/S0218001419540375
NR 49
TC 2
Z9 3
U1 0
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2022
VL 81
IS 14
BP 19035
EP 19050
DI 10.1007/s11042-020-10129-8
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 1L8ZN
UT WOS:000584947400001
DA 2024-07-18
ER

PT J
AU Xie, YF
   Yang, HN
   Yuan, X
   He, Q
   Zhang, RT
   Zhu, QY
   Chu, ZH
   Yang, CM
   Qin, PW
   Yan, CG
AF Xie, Yifeng
   Yang, Hongnan
   Yuan, Xi
   He, Qian
   Zhang, Ruitao
   Zhu, Qianyun
   Chu, Zhenhai
   Yang, Chengming
   Qin, Peiwu
   Yan, Chenggang
TI Stroke prediction from electrocardiograms by deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Electrocardiograms; Stroke; Convolutional neural network; Classification
ID AUTOMATED DETECTION; ECG; SYSTEM
AB The brain is an energy-consuming organ that heavily relies on the heart for energy supply. Heart abnormalities detected by electrocardiogram (ECG) might provide diagnostic indicators for brain dysfunctions such as stroke. Diagnosis of brain diseases by ECG requires proficient domain knowledge, which is both time and labor consuming. Deep learning is capable of constructing a nonlinear correlation between ECG and stroke without prior expert knowledge. Here, we propose a data-driven classifier-Dense convolutional neural Network (DenseNet) for stroke prediction based on 12-leads ECG data. With our finely-tuned model, we obtain the training accuracy of 99.99% and the prediction accuracy of 85.82%. To our knowledge, this is the first report studying the correlation between stroke and ECG with the aid of deep learning. The results indicate that ECG is a valuable complementary technique for stroke diagnostics.
C1 [Xie, Yifeng; Yang, Hongnan; Yan, Chenggang] Hangzhou Dianzi Univ, Dept Automat, Hangzhou 310016, Zhejiang, Peoples R China.
   [Yuan, Xi; He, Qian; Zhang, Ruitao; Zhu, Qianyun; Qin, Peiwu] Tsinghua Berkeley Shenzhen Inst, Ctr Precis Med & Healthcare, Shenzhen 518055, Guangdong, Peoples R China.
   [Chu, Zhenhai] Southern Univ Sci & Technol Hosp, Div Neurol, Shenzhen 518055, Guangdong, Peoples R China.
   [Yang, Chengming] Southern Univ Sci & Technol Hosp, Div Ophthalmol, Shenzhen 518055, Guangdong, Peoples R China.
C3 Hangzhou Dianzi University; Tsinghua Shenzhen International Graduate
   School; Southern University of Science & Technology; Southern University
   of Science & Technology
RP Xie, YF (corresponding author), Hangzhou Dianzi Univ, Dept Automat, Hangzhou 310016, Zhejiang, Peoples R China.
EM xieyifeng0717@gmail.com; pwqin@sz.tsinghua.edu.cn; cgyan@hdu.edu.cn
RI lin, lin/KCZ-0185-2024; Qin, Peiwu/JNJ-1089-2023
FU National Key Research and Development Program of China [2017YFC0820605];
   National Natural Science Major Foundation of Research Instrumentation of
   PR China [61427808]; Zhejiang Province Nature Science Foundation of
   China [LR17F030006]; Zhejiang Province Nature Science Foundation of
   China (111 Project) [D17019]; Shenzhen Municipal Development and Reform
   Commission Subject Construction Project [[2017] 1434]
FX We thank AUSA Shenzhen Inc for data collection. This work is supported
   by the National Key Research and Development Program of China
   (2017YFC0820605), National Natural Science Major Foundation of Research
   Instrumentation of PR China (61427808), Zhejiang Province Nature Science
   Foundation of China (LR17F030006, 111 Project, No. D17019); and Shenzhen
   Municipal Development and Reform Commission Subject Construction Project
   [2017] 1434.
CR Acharya UR, 2017, INFORM SCIENCES, V415, P190, DOI 10.1016/j.ins.2017.06.027
   Acharya UR, 2017, INFORM SCIENCES, V405, P81, DOI 10.1016/j.ins.2017.04.012
   Andreotti F, 2017, COMPUT CARDIOL CONF, V44, DOI 10.22489/CinC.2017.360-239
   Asadi P, 2019, ARCH ACAD EMERG MED, V1, P7
   Censi F, 2016, SCI REP-UK, V6, DOI 10.1038/srep26799
   Cox AM, 2006, LANCET NEUROL, V5, P181, DOI 10.1016/S1474-4422(06)70351-9
   de Chazal P, 2006, IEEE T BIO-MED ENG, V53, P2535, DOI 10.1109/TBME.2006.883802
   Dong JY, 2018, INT C PATT RECOG, P3433, DOI 10.1109/ICPR.2018.8545596
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   GOLDSTEIN DS, 1979, STROKE, V10, P253, DOI 10.1161/01.STR.10.3.253
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Holst H, 1999, CLIN PHYSIOL, V19, P410, DOI 10.1046/j.1365-2281.1999.00195.x
   Jin YR, 2020, KNOWL-BASED SYST, V193, DOI 10.1016/j.knosys.2019.105460
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Jung M, 2020, J CLIN MED, V9, DOI 10.3390/jcm9041134
   Kaouter K, 2019, AIP CONF PROC, V2190, DOI 10.1063/1.5138541
   Khandoker AH, 2009, IEEE T INF TECHNOL B, V13, P37, DOI 10.1109/TITB.2008.2004495
   Kingma D. P., 2014, arXiv
   Kleinberg R., 2018, PR MACH LEARN RES
   Mukkamala MC, 2017, PR MACH LEARN RES, V70
   Parvaneh S, 2019, J ELECTROCARDIOL, V57, pS70, DOI 10.1016/j.jelectrocard.2019.08.004
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Shim HM, 2015, J CENT SOUTH UNIV, V22, P1801, DOI 10.1007/s11771-015-2698-0
   Sidek KA, 2014, IEEE T SYST MAN CY-S, V44, P1498, DOI 10.1109/TSMC.2014.2336842
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Verma AK, 2019, BRAIN SCI, V9, DOI 10.3390/brainsci9070162
   Yeh YC, 2009, MEASUREMENT, V42, P778, DOI 10.1016/j.measurement.2009.01.004
   Zhou Zhou B. B., arXiv:1807.01257 arXiv:1807.01257
   Zubair M, 2016, INT CONF IT CONVERGE, P335
NR 31
TC 18
Z9 18
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17291
EP 17297
DI 10.1007/s11042-020-10043-z
EA OCT 2020
PG 7
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000583943600001
DA 2024-07-18
ER

PT J
AU Hyun, J
   Kim, Y
   Kim, J
   Moon, B
AF Hyun, Jongkil
   Kim, Younghyeon
   Kim, Junghwan
   Moon, Byungin
TI Hardware-friendly architecture for a pseudo 2D weighted median filter
   based on sparse-window approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereo vision; Stereo matching; Post-processing; Weighted median filter;
   Hardware implementation
AB Stereo matching, which is conventionally used for three-dimensional (3D) information acquisition through cameras, is the most actively studied subject in computer vision. To obtain sophisticated 3D information, refining the disparity map in stereo vision is important. The weighted median filter (WMF) is extensively used to eliminate outliers in post-processing. To this end, various studies have implemented WMFs in hardware for real-time processing. Among them, the separable weighted median filter (sWMF) vertically and horizontally separates a two-dimensional WMF into two one-dimensional WMFs to reduce hardware resource usage. Herein, we propose a hardware architecture that can reduce the hardware resource usage of the sWMF by applying the sparse-window approach, which is a method of creating a window by selecting pixels sparsely. This approach makes it possible to reduce drastically the number of elements to be computed. Although the proposed architecture has an insignificant disparity error rate, similar to that of the sWMF, it saves 33% slice lookup tables (LUTs) and 69% slice registers when using a window size of 37 x 37 pixels as the synthesis result on the Xilinx XC7K325T FPGA. When a window size of 49 x 13 pixels with the best performance is used, the proposed architecture uses 7335 slice LUTs, 4126 slice registers, and 21 block RAMs. The proposed architecture operates at frequencies of up to 167.95 MHz; hence, it can operate in real time. The proposed WMF architecture is suitable for application in embedded systems and low-resource environments as it is hardware-friendly.
C1 [Hyun, Jongkil; Kim, Junghwan] Kyungpook Natl Univ, Sch Elect & Elect Engn, Daegu, South Korea.
   [Kim, Younghyeon] Kyungpook Natl Univ, Dept Mobile Telecommun Engn, Daegu, South Korea.
   [Moon, Byungin] Kyungpook Natl Univ, Sch Elect Engn, Daegu, South Korea.
C3 Kyungpook National University; Kyungpook National University; Kyungpook
   National University
RP Moon, B (corresponding author), Kyungpook Natl Univ, Sch Elect Engn, Daegu, South Korea.
EM bihmoon@knu.ac.kr
RI Moon, Byungin/ACE-5308-2022
OI Moon, Byungin/0000-0002-8102-4818
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A3B01015379]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2016R1D1A3B01015379).
CR BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chen S, IEEE INT S CIRCUITS, V1, P4
   Choi S, 2015, ETRI J, V37, P752, DOI 10.4218/etrij.15.0114.1421
   Fahmy Suhaib A., 2008, 2008 International Conference on Reconfigurable Computing and FPGAs (ReConFig), P331, DOI 10.1109/ReConFig.2008.15
   Fahmy SA, 2009, IET COMPUT DIGIT TEC, V3, P384, DOI 10.1049/iet-cdt.2008.0119
   Gavrila D. M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P87, DOI 10.1109/ICCV.1999.791202
   Gelautz M, 2004, REMOTE SENSING SPATI, P998
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Horisaki R, 2007, OPT REV, V14, P347, DOI 10.1007/s10043-007-0347-z
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Hyun J, 2020, INT WORKSH FUT TECHN, P50
   Ji XY, 2016, MULTIMED TOOLS APPL, V75, P12941, DOI 10.1007/s11042-014-2335-1
   Justusson BI, 1981, MEDIAN FILTERING STA, P161, DOI DOI 10.1007/BFB0057597
   Kanbara M, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P97, DOI 10.1109/ISAR.2000.880931
   MENZE M, 2015, PROC CVPR IEEE, P3061, DOI DOI 10.1109/CVPR.2015.7298925
   Paliwal N., 2019, International Journal of Social and Humanistic Computing, V3, P191, DOI [10.1504/IJSHC.2019.101602, DOI 10.1504/IJSHC.2019.101602]
   Park SY, 2005, MACH VISION APPL, V16, P148, DOI 10.1007/s00138-004-0165-2
   Perez-Andrade R, 2009, MICROELECTRON J, V40, P1705, DOI 10.1016/j.mejo.2009.08.006
   POLLARD SB, 1990, NATURE, V347, P553, DOI 10.1038/347553a0
   Yang QX, 2014, IEEE T PATTERN ANAL, V36, P1026, DOI 10.1109/TPAMI.2013.186
   Yang QX, 2009, PROC CVPR IEEE, P557, DOI 10.1109/CVPRW.2009.5206542
   Yang Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P274, DOI 10.1109/CVPR.1993.340969
   Zhang Q, 2014, PROC CVPR IEEE, P2830, DOI 10.1109/CVPR.2014.362
   Zhu SP, 2014, COMPUT ELECTR ENG, V40, P236, DOI 10.1016/j.compeleceng.2014.03.015
NR 24
TC 5
Z9 5
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 26-27
BP 34221
EP 34236
DI 10.1007/s11042-020-09906-2
EA OCT 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA WW6GF
UT WOS:000575795600007
DA 2024-07-18
ER

PT J
AU Sekhavat, YA
   Sisi, MJ
   Roohi, S
AF Sekhavat, Yoones A.
   Sisi, Milad Jafari
   Roohi, Samad
TI Affective interaction: Using emotions as a user interface in games
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective Computing; Affective User Interface; Virtual Scenario; User
   Experience; Facial Expressions
ID COMPUTER; EXPRESSION; DESIGN
AB Affective computing, as a novel paradigm, adds a new feature into the human-computer interactions era that brings emotions into the process of design and evaluation. Such condition influences digital games' not only structural dimension but also content and evaluation areas. This study aims to evaluate the effect of using emotions in the form of facial expressions as a User Interface (UI) and the input of a system in virtual scenarios. After studying the findings and methods of previous researches, a conceptual framework for Affective User Interface Design and Evaluation (AFFUIDE) has been proposed. Then, a game in the genre of shoot 'em up (called Facial Battle) in four interaction modes has been developed. The evaluation of this study has been performed in terms of the players' performance and experience. For this purpose, 18 male students of the Multimedia Faculty of Tabriz Islamic Art University took part in the experiments, who were asked to play all four modes of the game. Then, after analyzing the normalization of collected data, one-way ANOVA and U Mann Whitney tests were used for the statistical analysis. The findings indicate that the Traditional UI is the most usable and the Full Affective UI has the best sense of fun and user experience among other methods. However, the hybrid mode (affective shooting), is not only usable as traditional mode, but it also works better in terms of user experience compared to other modes.
C1 [Sekhavat, Yoones A.; Sisi, Milad Jafari; Roohi, Samad] Tabriz Islamic Art Univ, Fac Multimedia, Tabriz, Iran.
RP Sekhavat, YA (corresponding author), Tabriz Islamic Art Univ, Fac Multimedia, Tabriz, Iran.
EM sekhavat@tabriziau.ac.ir; m.jafarisisi@tabriziau.ac.ir;
   s.roohi@tabriziau.ac.ir
RI Sekhavat, Yoones A./ABC-4693-2020; Roohi, Samad/AAB-7211-2022; Sekhavat,
   Yoones A./KGK-5867-2024
OI Sekhavat, Yoones A./0000-0003-3654-9583; Roohi,
   Samad/0000-0003-4747-5452; Sekhavat, Yoones A./0000-0003-3654-9583
CR Andersson AT, 2016, FACIAL FEATURE TRACK
   [Anonymous], 1997, Circumplex models of personality and emotions, DOI [10.1037/10261-001, DOI 10.1037/10261-001]
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], 2009, P INT C ADV COMPUTER
   [Anonymous], 2008, P INT C ADV COMPUTER, DOI [DOI 10.1145/1501750.1501809, 10.1145/1501750.1501809]
   Bahreini K, 2019, MULTIMED TOOLS APPL, V78, P18943, DOI 10.1007/s11042-019-7250-z
   Bannon Liam, 2011, Interactions, V18, P50, DOI 10.1145/1978822.1978833
   Benyon David, 2019, Designing user experience: a guide to HCI, UX and interaction design, V4th
   Badia SBI, 2019, IEEE J BIOMED HEALTH, V23, P1877, DOI 10.1109/JBHI.2018.2878846
   Bernays R, 2012, ADJUNCT PROCEEDINGS OF THE 25TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P79
   Blom P. M., 2014, 10 ART INT INT DIG E
   Bogdanovych A, 2016, CONNECT SCI, V28, P83, DOI 10.1080/09540091.2015.1130021
   Bowman ND, 2017, J GAMING VIRTUAL WOR, V9, P71, DOI 10.1386/jgvw.9.1.71_1
   Brooke J, 1996, USABILITY EVALUATION, V189, P4
   Browne C, 2012, IEEE T COMP INTEL AI, V4, P149, DOI 10.1109/TCIAIG.2012.2212900
   Burns Andrew, 2017, 2017 IEEE Conference on Computational Intelligence and Games (CIG), P45, DOI 10.1109/CIG.2017.8080414
   Cai LQ, 2017, MULTIMED TOOLS APPL, V76, P5851, DOI 10.1007/s11042-015-2547-z
   Caschera MC, 2016, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON MANAGEMENT OF DIGITAL ECOSYSTEMS (MEDES 2016), P137, DOI 10.1145/3012071.3012089
   Cerekovic A, 2011, MULTIMED TOOLS APPL, V54, P143, DOI 10.1007/s11042-010-0530-2
   Collins K., 2014, SMART TABLE COMPUTER
   de Byl P, 2015, CYBERPSYCHOLOGY, V9, DOI 10.5817/CP2015-3-4
   de Peuter A., 2014, DEV ADAPTIVE GAME RU
   Dekker A, 2007, DIGRA C, P43
   DeWitt A, 2007, LECT NOTES COMPUT SC, V4738, P523
   Drachen A., 2010, Proceedings of the 5th ACM SIGGRAPH Symposium on Video Games, P49, DOI DOI 10.1145/1836135.1836143
   Dudley JJ, 2018, ACM T INTERACT INTEL, V8, DOI 10.1145/3185517
   Dzedzickis A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030592
   Fu LP, 2018, 2018 CHI C HUM FACT
   Ghosh M, 2019, MULTIMED TOOLS APPL, V78, P25753, DOI 10.1007/s11042-019-07811-x
   Gilleade K.M., 2005, Proceedings of DIGRA 2005 Conference on Changing Views: Worlds in Play, V8, P547
   Guthier B, 2016, LECT NOTES COMPUT SC, V9970, P402, DOI 10.1007/978-3-319-46152-6_16
   Hamdy S, 2018, 19 ANN EUR GAME ON C
   Hassenzahl M., 2003, AttrakDiff: Ein FragebogenZur Messung Wahrgenommener Hedonischer Und Pragmatischer Qual-itat, P187, DOI [DOI 10.1007/978-3-322-80058-9_19, 10.1007/978-3-322-80058-9_19]
   Högberg J, 2019, USER MODEL USER-ADAP, V29, P619, DOI 10.1007/s11257-019-09223-w
   Hubbard JA, 2001, CHILD DEV, V72, P1426, DOI 10.1111/1467-8624.00357
   Ilves M, 2014, ENTERTAIN COMPUT, V5, P147, DOI 10.1016/j.entcom.2014.04.005
   Ip B, 2011, GAMES CULT, V6, P103, DOI 10.1177/1555412010364982
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Ji H, 2018, CLUSTER COMPUT, V21, P1045, DOI 10.1007/s10586-017-0999-9
   Johnson D, 2003, ERGONOMICS, V46, P1332, DOI 10.1080/00140130310001610865
   KLEINGINNA P R JR, 1981, Motivation and Emotion, V5, P345, DOI 10.1007/BF00992553
   Korn O, 2017, COMPUT ENTERTAIN, V15, DOI 10.1145/2974026
   Kowalska M., 2017, HDB COGNITION EMOTIO, P1, DOI [https://doi.org/10.1007/978-3-319-28099-8495-1, DOI 10.1002/0470013494.CH3, 10.1002/0470013494.ch3]
   Kromand D, 2007, DIGRA C
   Landowska A, 2016, ACSIS-ANN COMPUT SCI, V8, P1631, DOI 10.15439/2016F535
   LANG PJ, 1995, AM PSYCHOL, V50, P372, DOI 10.1037/0003-066X.50.5.372
   Lim MY, 2012, AUTON AGENT MULTI-AG, V24, P287, DOI 10.1007/s10458-010-9161-2
   Liu CC, 2009, INT J HUM-COMPUT INT, V25, P506, DOI 10.1080/10447310902963944
   Mandel T., 1997, The Elements of User Interface Design
   Mandryk RL, 2006, BEHAV INFORM TECHNOL, V25, P141, DOI 10.1080/01449290500331156
   Mansilla WA, 2006, LECT NOTES COMPUT SC, V4161, P90
   McDuff D., 2016, P CHI C HUM FACT COM, P3723
   Mohammadi HS, 2018, 2018 2ND NATIONAL AND 1ST INTERNATIONAL DIGITAL GAMES RESEARCH CONFERENCE: TRENDS, TECHNOLOGIES, AND APPLICATIONS (DGRC), P167, DOI 10.1109/DGRC.2018.8712048
   Muller N, 2018, 17TH INTERNATIONAL CONFERENCE ON MOBILE AND UBIQUITOUS MULTIMEDIA (MUM 2018), P335, DOI 10.1145/3282894.3282918
   Mungra D, 2020, MULTIMED TOOLS APPL, V79, P2285, DOI 10.1007/s11042-019-08397-0
   Ng YY, 2014, INT CONF USER SCI, P79, DOI 10.1109/IUSER.2014.7002681
   Obaid M, 2008, P 5 AUSTR C INT ENT, P6
   Pan S, 2016, 30 AAAI C ART INT
   Partala T, 2005, AFFECTIVE INFORM HUM
   Pawar S., 2020, HDB GAME BASED LEARN, V347
   PICARD R.W, 1995, M.I.T Media Laboratory Perceptual Computing Section Technical Report No. 321
   Picard R.W., 2000, Affective Computing
   Preece J, 1994, HUMAN COMPUTER INTER, V9
   Prema P, 2008, WORLD ACAD SCI ENG T, V2, P1870
   Przybylski AK, 2012, PSYCHOL SCI, V23, P69, DOI 10.1177/0956797611418676
   Raheel A, 2019, MULTIMED TOOLS APPL, V78, P13971, DOI 10.1007/s11042-018-6907-3
   Robison S.M., 2009, Proc. Int. Conf. Affective Computing and Intelligent Interaction, P37
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sawyer R, 2017, PROCEEDINGS OF THE 25TH CONFERENCE ON USER MODELING, ADAPTATION AND PERSONALIZATION (UMAP'17), P192, DOI 10.1145/3079628.3079686
   SEKHAVAT Y, 2020, IEEE T GAMES
   Sekhavat YA, 2020, ENTERTAIN COMPUT, V34, DOI 10.1016/j.entcom.2020.100360
   Sekhavat YA, 2020, MULTIMED TOOLS APPL, V79, P3449, DOI 10.1007/s11042-019-07963-w
   Sharma M, 2019, MULTIMED TOOLS APPL, V78, P16195, DOI 10.1007/s11042-018-7030-1
   Shaw M., 1986, 1986 SIGCHI Conference on Human Factors in Computing Systems, P261
   Shilling R, 2002, P GAMEON C
   Song W, 2017, MULTIMED TOOLS APPL, V76, P11159, DOI 10.1007/s11042-015-2986-6
   Souza Alice D., 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P337, DOI 10.1109/ICSSIT46314.2019.8987893
   Takatalo J, 2010, HUM-COMPUT INT-SPRIN, P23, DOI 10.1007/978-1-84882-963-3_3
   Turekova S, 2016, USING PLAYERS FACIAL
   Valli A, 2008, MULTIMED TOOLS APPL, V38, P295, DOI 10.1007/s11042-007-0190-z
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   Werbach K., 2012, For the win: How game thinking can revolutionize your business
   Xie L, 2015, MULTIMED TOOLS APPL, V74, P9845, DOI 10.1007/s11042-015-2460-5
   Yannakakis GN, 2015, INT CONF AFFECT, P519, DOI 10.1109/ACII.2015.7344619
   Yeh YC, 2016, COMPUT HUM BEHAV, V55, P817, DOI 10.1016/j.chb.2015.10.037
NR 85
TC 12
Z9 12
U1 6
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2021
VL 80
IS 4
BP 5225
EP 5253
DI 10.1007/s11042-020-10006-4
EA OCT 2020
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA QB1CT
UT WOS:000575795600003
DA 2024-07-18
ER

PT J
AU Abdurrazzaq, A
   Junoh, AK
   Yahya, Z
   Mohd, I
AF Abdurrazzaq, Achmad
   Junoh, Ahmad Kadri
   Yahya, Zainab
   Mohd, Ismail
TI New white blood cell detection technique by using singular value
   decomposition concept White blood cell detection technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Singular value decomposition; Image detection; White blood cell; Image
   segmentation
AB Segmentation technique is a commonly used method to detect white blood cells. The segmentation technique aims to separate the blood image into several parts based on the similarity of features in the image. Therefore, the detection results do not completely contain white blood cells but also contain other parts with similar features to white blood cells. This study proposes a new detection technique that directly considers the features of white blood cells using singular value decomposition approach. The experimental results show that the proposed method works better in detecting white blood cell nuclei than the existing methods. The existing methods only work well for white blood cells with dense color intensities such as basophil and monocyte. Meanwhile, the proposed method works well overall as it directly compares the level of similarity in white blood cells.
C1 [Abdurrazzaq, Achmad; Junoh, Ahmad Kadri; Yahya, Zainab] Univ Malaysia Perlis, Inst Engn Math, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.
   [Abdurrazzaq, Achmad] Indonesia Def Univ, Fac Mil Math & Nat Sci, Dept Math, IPSC Area, Bogor 16810, Indonesia.
   [Mohd, Ismail] Univ Putra Malaysia, Inst Math Res, Akad Ilmuwan Sains Matemat Malaysia, Serdang 43400, Selangor, Malaysia.
C3 Universiti Malaysia Perlis; Universiti Putra Malaysia
RP Abdurrazzaq, A (corresponding author), Univ Malaysia Perlis, Inst Engn Math, Kampus Pauh Putra, Arau 02600, Perlis, Malaysia.; Abdurrazzaq, A (corresponding author), Indonesia Def Univ, Fac Mil Math & Nat Sci, Dept Math, IPSC Area, Bogor 16810, Indonesia.
EM achmad.abdurrazzaq@idu.ac.id
RI Abdurrazzaq, Achmad/AAD-5753-2021
OI Abdurrazzaq, Achmad/0000-0002-9227-023X
FU Ministry of Education Malaysia (MOE) under Fundamental Research Grant
   Scheme (FRGS) [FRGS/1/2019/STG06/UNIMAP/02/3]; Jurnal KALAM Enterprise
   [JK/IBM/BIAYA/PHD/2017, Lot 3116]; Jalan Pantai, Kampung Pengkalan
   Maras, Mengabang Telipot, Malaysia
FX Authors would like to thank Ministry of Education Malaysia (MOE) under
   Fundamental Research Grant Scheme (FRGS) (Ref:
   FRGS/1/2019/STG06/UNIMAP/02/3) and Jurnal KALAM Enterprise
   (JK/IBM/BIAYA/PHD/2017), Lot 3116, Jalan Pantai, Kampung Pengkalan
   Maras, Mengabang Telipot, 21030 Kuala Terengganu, Malaysia for the
   financial support provided for this research.
CR [Anonymous], 2018, J MED SYST
   Chen YT, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8822777
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7435, DOI 10.1007/s10586-018-1772-4
   Chen YT, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.5533
   Chen YT, 2019, J AMB INTEL HUM COMP, V10, P4855, DOI 10.1007/s12652-018-01171-4
   Chen YT, 2019, IEEE ACCESS, V7, P58791, DOI 10.1109/ACCESS.2019.2911892
   Chen YT, 2019, CLUSTER COMPUT, V22, pS7665, DOI 10.1007/s10586-018-2368-8
   Dhar PK, 2019, ADVANCES IN AUDIO WA
   Izhakian Z, 2018, SEMIGROUP FORUM, V96, P178, DOI 10.1007/s00233-017-9894-1
   Kashyap A, 2017, INT J ENG TECHNOLOGY, V7, DOI [10.14419/ijet.v7i2.13.11604, DOI 10.14419/IJET.V7I2.13.11604]
   Kumar P., 2017, J Biomed Imaging Bioeng, V1, P20
   Madhloom H. T., 2010, Journal of Applied Sciences, V10, P959, DOI 10.3923/jas.2010.959.966
   Nicolay, 2018, P IEEE INT C SMART I, P1, DOI DOI 10.1109/ICSIMA.2018.8688781
   Patgiri C, 2019, 2019 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, SIGNAL PROCESSING AND NETWORKING (WISPNET 2019): ADVANCING WIRELESS AND MOBILE COMMUNICATIONS TECHNOLOGIES FOR 2020 INFORMATION SOCIETY, P474, DOI [10.1109/wispnet45539.2019.9032790, 10.1109/WiSPNET45539.2019.9032790]
   Safuan SNM, 2017, AIP CONF PROC, V1883, DOI 10.1063/1.5002036
   Sonar SC, 2015, IJSER, V6, P172
   Sukhia KN, 2017, RADIOENGINEERING, V26, P1177, DOI 10.13164/re.2017.1177
   Tavakolipour H, 2018, LINEAR ALGEBRA APPL, V539, P198, DOI 10.1016/j.laa.2017.11.009
   Thaghizadeh D, 2020, BANACH J MATH ANAL, V14, P1773, DOI 10.1007/s43037-020-00082-x
   Vincent JL, 2015, P IEEE SEMICOND THER, P1, DOI 10.1109/SEMI-THERM.2015.7100130
   Vogado LHS, 2016, IEEE INT SYM MULTIM, P451, DOI [10.1109/ISM.2016.30, 10.1109/ISM.2016.0103]
   Wang J, 2019, MATH BIOSCI ENG, V16, P5851, DOI 10.3934/mbe.2019292
   Zheng X, 2018, MENDELEY DATA, DOI [10.17632/w7cvnmn4c5.1#file-86a24fe7-be10-45c3-bf35-cad6418ba8f6, DOI 10.17632/W7CVNMN4C5.1#FILE-86A24FE7-BE10-45C3-BF35-CAD6418BA8F6]
NR 23
TC 4
Z9 4
U1 6
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4627
EP 4638
DI 10.1007/s11042-020-09946-8
EA SEP 2020
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000574101100008
DA 2024-07-18
ER

PT J
AU Shih, CY
   Chen, YH
   Lee, TY
AF Shih, Chiao-Yin
   Chen, Ya-Hsuan
   Lee, Tong-Yee
TI Map art style transfer with multi-stage framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Map art images; NPR (Non-photorealistic rendering); Stylization;
   Portraiture; Deep learning
AB We propose a multi-stage framework to create the stylized map art images. Existing techniques are successful in transferring style in photos. Yet, the noise in results and the harmonization in the generated art images still need to be investigated. We address these issues with a proposed algorithm that defines a good portrait for map art application in the initial round. A refinement strategy is then applied to produce the final map arts that meet the aforementioned expectations. Beside our plausible results, the objective evaluation presented in this paper shows that our proposed method can interactively achieve better and appealing map art results in the comparison with those of other works. In addition, our method can also create ocean or landscape stylized paintings using our map art collage.
C1 [Shih, Chiao-Yin; Chen, Ya-Hsuan; Lee, Tong-Yee] Natl Cheng Kung Univ, Tainan, Taiwan.
C3 National Cheng Kung University
RP Lee, TY (corresponding author), Natl Cheng Kung Univ, Tainan, Taiwan.
EM tonylee@mail.ncku.edu.tw
CR Chi MT, 2006, IEEE T VIS COMPUT GR, V12, P61, DOI 10.1109/TVCG.2006.14
   Cornish D., 2001, No description on Graphics interface 2001, P151
   Deussen O, 2000, COMP GRAPH, P13, DOI 10.1145/344779.344792
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Jing YH, 2021, IEEE T CYBERNETICS, V51, P568, DOI 10.1109/TCYB.2019.2904768
   Kalnins R., 2002, P 29 ANN C COMPUTER, P755, DOI DOI 10.1145/566570.566648
   Lee TY, 2007, COMPUT SCI ENG, V9, P13, DOI 10.1109/MCSE.2007.17
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Lin DY, 2018, ALGORITHMS, V11, DOI 10.3390/a11010004
   Lin SS, 2015, IEEE T MULTIMEDIA, V17, P1515, DOI 10.1109/TMM.2015.2437711
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Lu M, 2018, IEEE ACCESS, V6, P58532, DOI 10.1109/ACCESS.2018.2874203
   Luan FJ, 2018, COMPUT GRAPH FORUM, V37, P95, DOI 10.1111/cgf.13478
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Meier B. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P477, DOI 10.1145/237170.237288
   Praun E, 2001, COMP GRAPH, P581, DOI 10.1145/383259.383328
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selim A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925968
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu H, 2004, RENDERING TECHNIQUES, P45
   Yan CR, 2008, IEEE T VIS COMPUT GR, V14, P468, DOI 10.1109/TVCG.2007.70440
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 25
TC 4
Z9 5
U1 2
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 4279
EP 4293
DI 10.1007/s11042-020-09788-4
EA SEP 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000573572200003
DA 2024-07-18
ER

PT J
AU Bao, JQ
   Luo, L
   Zhang, Y
   Yang, K
   Peng, CY
   Peng, JP
   Li, R
AF Bao, Jiaqi
   Luo, Lin
   Zhang, Yu
   Yang, Kai
   Peng, Chaoyong
   Peng, Jianping
   Li, Ran
TI Half quadratic splitting method combined with convolution neural network
   for blind image deblurring
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind image deblurring; Variable splitting technique; Convolutional
   neural network
AB Blind image deblurring is the process of recovering the original image from a degraded image under unknown point spread function, and it is the solution to an ill-posed inverse problem. In this paper, the blurry image is firstly divided into skeleton image and blur kernel, aiming to achieve accurate blur kernel estimation. Then the advantages of model-based optimization method and discriminative learning method are integrated through variable splitting technique. Finally, a trained convolutional neural network (CNN) is used as a module to be inserted into a model-based optimization method to solve the problem of blind image deblurring more effectively. By comparing visual and quantitative experimental data, the network proposed in this paper can provide powerful prior information for blind image deblurring and the restoration effects can approximate or exceed those of some representative algorithms.
C1 [Bao, Jiaqi; Luo, Lin; Zhang, Yu; Yang, Kai; Peng, Chaoyong; Peng, Jianping; Li, Ran] Southwest Jiaotong Univ, Sch Phys Sci & Technol, Chengdu 610031, Peoples R China.
C3 Southwest Jiaotong University
RP Zhang, Y (corresponding author), Southwest Jiaotong Univ, Sch Phys Sci & Technol, Chengdu 610031, Peoples R China.
EM zhang.yuer@163.com
RI Zhang, Yixuan/JER-2518-2023
FU Southwest Jiaotong University Photoelectric Engineering Institute;
   National Natural Science Foundation of China [61471304]
FX We thank Southwest Jiaotong University Photoelectric Engineering
   Institute for their support in this experiment. This work was supported
   by grants from National Natural Science Foundation of China (Grant No.
   61471304).
CR [Anonymous], CoRR abs/1511.07122
   Bai YC, 2019, IEEE T IMAGE PROCESS, V28, P1404, DOI 10.1109/TIP.2018.2874290
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Brifman A., 2016, 2016 IEEE INT C IM P
   Cai JF, 2012, IEEE T IMAGE PROCESS, V21, P562, DOI 10.1109/TIP.2011.2164413
   Chambolle A, 1998, IEEE T IMAGE PROCESS, V7, P319, DOI 10.1109/83.661182
   Chan SH, 2017, IEEE T COMPUT IMAG, V3, P84, DOI 10.1109/TCI.2016.2629286
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cho S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618491
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   González JD, 2007, RICYDE-REV INT CIENC, V3
   Fang HZ, 2013, OPT LETT, V38, P389, DOI 10.1364/OL.38.000389
   Fereus R, 2006, ACM T GRAPHIC, V25, P787
   Fergus R, 2006, ACM T GRAPHIC, V25, P787, DOI 10.1145/1141911.1141956
   Figueiredo MAT, 2003, IEEE T IMAGE PROCESS, V12, P906, DOI 10.1109/TIP.2003.814255
   Gao HY, 2019, PROC CVPR IEEE, P3843, DOI 10.1109/CVPR.2019.00397
   GEMAN D, 1995, IEEE T IMAGE PROCESS, V4, P932, DOI 10.1109/83.392335
   Hirsch M, 2011, IEEE I CONF COMP VIS, P463, DOI 10.1109/ICCV.2011.6126276
   Hoi, 2020, P IEEE CVF C COMP VI, P8960, DOI DOI 10.1109/CVPR42600.2020.00898
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Kupyn O, 2019, IEEE I CONF COMP VIS, P8877, DOI 10.1109/ICCV.2019.00897
   Kupyn O, 2018, PROC CVPR IEEE, P8183, DOI 10.1109/CVPR.2018.00854
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Levin A, 2011, IEEE T PATTERN ANAL, V33, P2354, DOI 10.1109/TPAMI.2011.148
   Li LRH, 2019, INT J COMPUT VISION, V127, P1025, DOI 10.1007/s11263-018-01146-0
   Lu BY, 2019, PROC CVPR IEEE, P10217, DOI 10.1109/CVPR.2019.01047
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Malczewski K, 2008, IEEE IMAGE PROC, P341, DOI 10.1109/ICIP.2008.4711761
   Pan JS, 2016, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR.2016.180
   Pan ZX, 2013, IEEE T GEOSCI REMOTE, V51, P4864, DOI 10.1109/TGRS.2012.2230270
   PARIKH N., 2014, FDN TRENDS OPTIM, V1, P3, DOI DOI 10.1561/2400000003
   Romano Yaniv, 2016, ARXIV161102862
   Rond A, 2016, J VIS COMMUN IMAGE R, V41, P96, DOI 10.1016/j.jvcir.2016.09.009
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Shan Q, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360672
   Shen ZY, 2019, IEEE I CONF COMP VIS, P5571, DOI 10.1109/ICCV.2019.00567
   Sreehari S, 2016, IEEE T COMPUT IMAG, V2, P408, DOI 10.1109/TCI.2016.2599778
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Teodoro AM, 2016, IEEE IMAGE PROC, P3518, DOI 10.1109/ICIP.2016.7533014
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Whyte O, 2010, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2010.5540175
   Xu L., 2010, LECT NOTES COMPUT SC, DOI 10.1007/ 978-3-642-15549-9_12
   Zhang JW, 2017, PROC CVPR IEEE, P6969, DOI 10.1109/CVPR.2017.737
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhou SC, 2019, PROC CVPR IEEE, P10988, DOI 10.1109/CVPR.2019.01125
NR 52
TC 6
Z9 6
U1 4
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 3
BP 3489
EP 3504
DI 10.1007/s11042-020-09821-6
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS9RK
UT WOS:000572039400001
DA 2024-07-18
ER

PT J
AU Zhang, LK
   Wang, XC
   Hu, RM
   Li, DS
   Tu, WP
AF Zhang, Lingkun
   Wang, Xiaochen
   Hu, Ruimin
   Li, Dengshi
   Tu, Weipin
TI Optimization of sound fields reproduction based Higher-Order Ambisonics
   (HOA) using the Generative Adversarial Network (GAN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spherical harmonics; Loudspeaker array; Sound field reproduction;
   Generative adversarial network
ID DESIGN; DIMENSIONALITY
AB Sound field reproduction using Higher-order Ambisonics (HOA) has many studies in recent years. However, in the HOA, sound fields are reproduced with the least square solution of spherical harmonics (SH) coefficients and not the global sound fields. In this paper, we try to reduce the reproduction error with a data-driven method. As we all known, the Generative Adversarial Networks (GAN) can be used to generate data similar to a data set. With the GAN, the target sound fields are converted to sound fields that can be reproduced accurately in the proposed approach. The data set of target sound fields is updated with the generated fields which have less reproduction error, and thus reproduction errors are reduced. We simulated the performance with four loudspeakers, sound fields of 4 orders SH coefficients are reproduced with GAN and HOA at 1000 Hz, with average reproduction errors of 0.3 and 0.6, respectively. Simulations show that the space between the least-square solution and the optimization solution is reduced with our method. Furthermore, the performances of HOA are optimized.
C1 [Zhang, Lingkun; Wang, Xiaochen; Hu, Ruimin; Li, Dengshi; Tu, Weipin] Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Zhang, Lingkun; Wang, Xiaochen; Hu, Ruimin] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
   [Li, Dengshi; Tu, Weipin] Collaborat Innovat Ctr Geospatial Technol, Wuhan 430079, Peoples R China.
C3 Wuhan University; Wuhan University
RP Wang, XC (corresponding author), Wuhan Univ, Sch Comp Sci, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.; Wang, XC (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
EM clowang@whu.edu.cn
FU National Key R&D Program of China [2017YFB1002803]; National Nature
   Science Foundation of China [U1736206, 61761044]; Hubei Province
   Technological Innovation Major Project [2017AAA123]
FX This research is partially supported by the National Key R&D Program of
   China (No. 2017YFB1002803), National Nature Science Foundation of China
   (No. U1736206, No. 61761044), Hubei Province Technological Innovation
   Major Project (No. 2017AAA123).
CR Abhayapala TD, 2002, INT CONF ACOUST SPEE, P1949
   Ahrens J, 2008, INT CONF ACOUST SPEE, P373, DOI 10.1109/ICASSP.2008.4517624
   Ahrens J, 2011, J ACOUST SOC AM, V130, P2807, DOI 10.1121/1.3640850
   Ando A, 2011, IEEE T AUDIO SPEECH, V19, P1467, DOI 10.1109/TASL.2010.2092429
   [Anonymous], 2017, IEEE T PATTERN ANAL
   BERKHOUT AJ, 1993, J ACOUST SOC AM, V93, P2764, DOI 10.1121/1.405852
   Bi HB, 2019, IEEE IMAGE PROC, P3876, DOI [10.1109/ICIP.2019.8803629, 10.1109/icip.2019.8803629]
   Bishop Christopher M., 2006, Pattern Recognition and Machine Learning, V4
   Cai WW, 2020, IEEE ACCESS, V8, P48451, DOI 10.1109/ACCESS.2020.2979348
   Chollet F, 2015, KERAS
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   Esmaeilpour M, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105912
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fernando T, 2020, IEEE-ACM T AUDIO SPE, V28, P1159, DOI 10.1109/TASLP.2020.2982297
   Firtha G, 2017, J ACOUST SOC AM, V142, P551, DOI 10.1121/1.4996126
   Fliege J, INTEGRATION NODES SP
   Frank M, 2017, J AUDIO ENG SOC, V65, P749, DOI 10.17743/jaes.2017.0026
   Fu K., 2020, P IEEE CVF C COMP VI, P3052
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   GERZON MA, 1985, J AUDIO ENG SOC, V33, P859
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han ZR, 2019, J ACOUST SOC AM, V145, pEL488, DOI 10.1121/1.5110746
   Huygens C, 1920, TRAITE LUMIERE CHEZ
   Kennedy RA, 2007, IEEE T SIGNAL PROCES, V55, P2542, DOI 10.1109/TSP.2007.893738
   Kentgens M, 2019, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2019.8682250
   Kingma D. P., 2014, arXiv
   KIRKEBY O, 1993, J ACOUST SOC AM, V94, P2992, DOI 10.1121/1.407330
   Lecomte P, 2018, J ACOUST SOC AM, V143, P811, DOI 10.1121/1.5023326
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   NELSON PA, 1994, J SOUND VIB, V177, P447, DOI 10.1006/jsvi.1994.1446
   Okamoto T, 2016, INT CONF ACOUST SPEE, P326, DOI 10.1109/ICASSP.2016.7471690
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Rafaely B, 2005, IEEE T SPEECH AUDI P, V13, P135, DOI 10.1109/TSA.2004.839244
   Ueno N, 2019, IEEE-ACM T AUDIO SPE, V27, P1852, DOI 10.1109/TASLP.2019.2934834
   Wang S, 2015, INT CONF ACOUST SPEE, P634, DOI 10.1109/ICASSP.2015.7178046
   Ward DB, 2001, IEEE T SPEECH AUDI P, V9, P697, DOI 10.1109/89.943347
   Williams E.G., 1999, FOURIER ACOUSTICS SO
   Wu YJ, 2009, IEEE T AUDIO SPEECH, V17, P107, DOI 10.1109/TASL.2008.2005340
   Xiang Y, 2020, IEEE ACM T AUDIO SPE
   Yu GZ, 2018, J ACOUST SOC AM, V143, pEL194, DOI 10.1121/1.5027019
   Zhang J., 2020, P IEEE CVF C COMP VI, P8579, DOI DOI 10.1109/CVPR42600.2020.00861
   Zhang JQ, 2020, J ACOUST SOC AM, V147, P1404, DOI 10.1121/10.0000797
   Zhang W, 2014, IEEE-ACM T AUDIO SPE, V22, P1184, DOI 10.1109/TASLP.2014.2324182
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QX, 2020, J ACOUST SOC AM, V147, P161, DOI 10.1121/10.0000474
NR 48
TC 2
Z9 2
U1 3
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 2
BP 2205
EP 2220
DI 10.1007/s11042-020-09735-3
EA SEP 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PS6WQ
UT WOS:000569366600003
DA 2024-07-18
ER

PT J
AU Laishram, D
   Tuithung, T
AF Laishram, Debina
   Tuithung, Themrichon
TI A novel minimal distortion-based edge adaptive image steganography
   scheme using local complexity (BEASS)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Adaptive image steganography; Image Quality Metrics (IQM); Least
   Significant Bit (LSB); Local complexity analysis; Statistical
   distortion; Mean Square Error (MSE); Steganalysis
ID LSB; STEGANALYSIS
AB The advantage of spatial domain image steganography techniques is their capacity to embed high payloads of data by directly modifying image pixels. While these techniques have a high-embedding capacity, they often create visual and statistical distortion in smoother regions. Most existing edge steganography techniques divide an image into blocks and insert data by processing the blocks in a linear order, but these method also has multiple drawbacks. First, if the selected block has an insufficient number of edge pixels, it may result in multiple blocks being processed. Second, at high embedding rates, the method creates severe distortion as multiple message bits are hidden in edge pixels and surrounding non-edge pixels without analyzing the statistical dependencies and correlation of pixels, compromising data security. The aim of the proposed method is to construct aBlock-wise Edge Adaptive Steganography Scheme (BEASS)using textured regions, particularly edges and surrounding pixels. This scheme dynamically chooses the region to embed messages using a local complexity measure ofStandard Deviation. It offers high payload, minimal distortion embedding by hiding three message bits into edge pixels using the minimalMean Square Errorto determine the embedding capacity of neighboring non-edge pixels within the block to preserve the statistical dependencies. The practical merit of this approach was validated and compared with existing algorithms, and experimental results find that the proposed method surpasses IQM tests, achieves a high PSNR of 61 similar to 65, proves to be robust against kurtosis and skewness distortion, resists histogram attack, RS steganalysis and high dimensional ensemble classifier at 80% block modifications.
C1 [Laishram, Debina; Tuithung, Themrichon] Natl Inst Technol, Dept Comp Sci & Engn, Nagaland, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Nagaland
RP Laishram, D (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Nagaland, India.
EM debinalaishram@gmail.com
CR Al-Dmour H, 2015, EXPERT SYST APPL, V46(C)
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   Bassil Y, 2012, INT J COMPUT APPL, V60, P55
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P7973, DOI 10.1007/s11042-016-3449-4
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chandramouli R, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1019, DOI 10.1109/ICIP.2001.958299
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Chen WJ, 2010, EXPERT SYST APPL, V37, P3292, DOI 10.1016/j.eswa.2009.09.050
   Du J, 2017, PROC SPIE, V10462, DOI 10.1117/12.2285187
   Fawcett T., 2004, MACH LEARN, V31, P1
   Ferzli R, 2010, P SPIE INT SOC OPTIC, P7532
   Fridrich J, 2002, PROC SPIE, V4675, P1, DOI 10.1117/12.465263
   Hempstalk K., 2006, Hiding Behind Corners Using Edges in Images For Better Steganography
   Islam S, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-8
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Ki-Hyun Jung, 2018, WSEAS Transactions on Systems and Control, V13, P103
   Kodovsky J, 2011, PROC SPIE, V7880, DOI 10.1117/12.872279
   Koo HI, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.1.013020
   Kumar S, 2019, DEF TECHNOL, V15, P162, DOI 10.1016/j.dt.2018.08.003
   Laishram D., 2018, SSRN Electron J, V10, P2139, DOI [10.2139/ssrn.3171494, DOI 10.2139/SSRN.3171494]
   Lee YK, 2000, IEE P-VIS IMAGE SIGN, V147, P288, DOI 10.1049/ip-vis:20000341
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu Y., 2018, ARXIV180402864
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Pevny T, 2010, IEEE T INF FOREN SEC, V5, P215, DOI 10.1109/TIFS.2010.2045842
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Tseng HW, 2014, IET IMAGE PROCESS, V8, P647, DOI 10.1049/iet-ipr.2013.0584
   Yang CH, 2008, IEEE T INF FOREN SEC, V3, P488, DOI 10.1109/TIFS.2008.926097
NR 30
TC 21
Z9 22
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2021
VL 80
IS 1
BP 831
EP 854
DI 10.1007/s11042-020-09519-9
EA SEP 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PR6IB
UT WOS:000566318900003
DA 2024-07-18
ER

PT J
AU Di Benedetto, M
   Carrara, F
   Meloni, E
   Amato, G
   Falchi, F
   Gennaro, C
AF Di Benedetto, Marco
   Carrara, Fabio
   Meloni, Enrico
   Amato, Giuseppe
   Falchi, Fabrizio
   Gennaro, Claudio
TI Learning accurate personal protective equipment detection from virtual
   worlds
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Virtual dataset; Transfer learning; Domain adaptation;
   Detection; Personal protective equipment
AB Deep learning has achieved impressive results in many machine learning tasks such as image recognition and computer vision. Its applicability to supervised problems is however constrained by the availability of high-quality training data consisting of large numbers of humans annotated examples (e.g. millions). To overcome this problem, recently, the AI world is increasingly exploiting artificially generated images or video sequences using realistic photo rendering engines such as those used in entertainment applications. In this way, large sets of training images can be easily created to train deep learning algorithms. In this paper, we generated photo-realistic synthetic image sets to train deep learning models to recognize the correct use of personal safety equipment (e.g., worker safety helmets, high visibility vests, ear protection devices) during at-risk work activities. Then, we performed the adaptation of the domain to real-world images using a very small set of real-world images. We demonstrated that training with the synthetic training set generated and the use of the domain adaptation phase is an effective solution for applications where no training set is available.
C1 [Di Benedetto, Marco; Carrara, Fabio; Meloni, Enrico; Amato, Giuseppe; Falchi, Fabrizio; Gennaro, Claudio] CNR, Inst Informat Sci & Technol, Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Di Benedetto, M (corresponding author), CNR, Inst Informat Sci & Technol, Pisa, Italy.
EM marco.dibenedetto@isti.cnr.it; fabio.carrara@isti.cnr.it;
   enrico.meloni@isti.cnr.it; giuseppe.amato@isti.cnr.it;
   fabrizio.falchi@isti.cnr.it; claudio.gennaro@isti.cnr.it
RI Falchi, Fabrizio/J-2920-2012; Gennaro, Claudio/AAH-5171-2019; Amato,
   Giuseppe/F-2227-2013; Meloni, Enrico/AAU-2714-2021; Carrara,
   Fabio/R-2275-2019
OI Falchi, Fabrizio/0000-0001-6258-5313; Gennaro,
   Claudio/0000-0002-3715-149X; Amato, Giuseppe/0000-0003-0171-4315;
   Meloni, Enrico/0000-0002-7806-849X; Carrara, Fabio/0000-0001-5014-5089;
   DI BENEDETTO, MARCO/0000-0001-5781-7060
FU "Automatic Data and documents Analysis to enhance human-based processes"
   (ADA) [CUP CIPE D55F17000290009]; AI4EU project - EC (H2020) [825619]
FX This work was partially supported by "Automatic Data and documents
   Analysis to enhance human-based processes" (ADA), funded by CUP CIPE
   D55F17000290009, and by the AI4EU project, funded by EC (H2020 -
   Contract n. 825619). We gratefully acknowledge the support of NVIDIA
   Corporation with the donation of a Jetson TX2 board used for this
   research.
CR [Anonymous], 2017, Beyond grand theft auto v for training, testing and enhancing deep learning in self driving cars
   Aubry M, 2015, IEEE I CONF COMP VIS, P2875, DOI 10.1109/ICCV.2015.329
   Bewley A, 2018, ARXIV181203823
   Bochinski E, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P278, DOI 10.1109/AVSS.2016.7738056
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   di Benedetto M, 2019, INT C CONTENT BASED, P8
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fabbri M, 2018, LECT NOTES COMPUT SC, V11208, P450, DOI 10.1007/978-3-030-01225-0_27
   Filipowicz A, 2017, TECH REP
   Hong ZW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4912
   Johnson-Roberson M, 2016, ARXIV 161001983
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lai KT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1356, DOI 10.1145/3240508.3243653
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Marín J, 2010, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2010.5540218
   Meloni E, 2019, PROJECT WEBSITE
   Peng LJ, 2019, IEEE VTS VEH TECHNOL, DOI 10.1109/vtcspring.2019.8746702
   Qiu WC, 2016, LECT NOTES COMPUT SC, V9915, P909, DOI 10.1007/978-3-319-49409-8_75
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Rockstar Games Inc, 2013, GRAND THEFT AUT 5
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Vázquez D, 2014, IEEE T PATTERN ANAL, V36, P797, DOI 10.1109/TPAMI.2013.163
   Vázquez D, 2012, INT C PATT RECOG, P3492
NR 29
TC 8
Z9 8
U1 3
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2021
VL 80
IS 15
BP 23241
EP 23253
DI 10.1007/s11042-020-09597-9
EA AUG 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA TD4QX
UT WOS:000562360100003
DA 2024-07-18
ER

PT J
AU Pan, H
   Xie, L
   Lv, ZP
   Li, J
   Wang, ZL
AF Pan, Hang
   Xie, Lun
   Lv, Zeping
   Li, Juan
   Wang, Zhiliang
TI Hierarchical support vector machine for facial micro-expression
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Micro-expression recognition; Sample imbalance; Features fusion;
   Hierarchical support vector machine
ID BINARY PATTERNS; CLASSIFICATION
AB The sample category distribution of spontaneous facial micro-expression datasets is unbalanced, due to the experimental environment, collection equipment, and individualization of subjects, which brings great challenges to micro-expression recognition. Therefore, this paper introduces a micro-expression recognition model based on the Hierarchical Support Vector Machine (H-SVM) to reduce the interference of sample category distribution imbalance. First, we calculated the position of the apex frame in the micro-expression image sequence. To keep micro-expression frames balanced, we sparsely sample the images sequence according to the apex frame. Then, the Low-level Descriptors of the region of interest of the micro-expression image sequence and the High-level Descriptors of apex frame are extracted. Finally, the H-SVM model is used to classify the fusion features of different levels. The experimental results on SMIC, CAMSE2, SAMM, and their composite datasets show that our method can achieve superior performance in micro-expression recognition.
C1 [Pan, Hang; Xie, Lun; Wang, Zhiliang] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing, Peoples R China.
   [Lv, Zeping] Natl Res Ctr Rehabil Tech Aids, Affiliated Rehabil Hosp, Beijing, Peoples R China.
   [Li, Juan] Chinese Acad Sci, Ctr Aging Psychol, Inst Psychol, Key Lab Mental Hlth, Beijing, Peoples R China.
C3 University of Science & Technology Beijing; Chinese Academy of Sciences;
   Institute of Psychology, CAS
RP Xie, L (corresponding author), Univ Sci & Technol Beijing, Sch Comp & Commun Engn, Beijing, Peoples R China.
EM xielun@ustb.edu.cn
RI Pan, Hang/GVT-3336-2022; Yan, Jun/IXD-7801-2023; Wang,
   Zhiliang/W-9144-2019
OI Pan, Hang/0000-0002-0522-018X; 
FU National Key R&D Program of China [2018YFC 2001700]; National Natural
   Science Foundation of China [61672093]; Beijing Municipal Natural
   Science Foundation [L192005]; Advanced Innovation Center for Intelligent
   Robots and Systems Open Research Project [2018IRS01]
FX This work was supported by the National Key R&D Program of China (No.
   2018YFC 2001700), National Natural Science Foundation of China (No.
   61672093), Beijing Municipal Natural Science Foundation (No. L192005),
   and Advanced Innovation Center for Intelligent Robots and Systems Open
   Research Project (No.2018IRS01).
CR [Anonymous], 2014, Proceedings of the Asian Conference on Computer Vision
   [Anonymous], 1966, Methods of research in psychotherapy, DOI [DOI 10.1007/978-1-4684-6045-2_14, 10.1007/978-1-4684-6045-2_14]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Davison C, 2014, TRANSLATION AS COLLABORATION: VIRGINIA WOOLF, KATHERINE MANSFIELD AND S. S. KOTELIANSKY, P111
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   Fernández A, 2018, J ARTIF INTELL RES, V61, P863, DOI 10.1613/jair.1.11192
   Gan YS, 2019, SIGNAL PROCESS-IMAGE, V74, P129, DOI 10.1016/j.image.2019.02.005
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Khan SA, 2015, J INTELL FUZZY SYST, V28, P2881, DOI 10.3233/IFS-151567
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   Li QY, 2019, MULTIMED TOOLS APPL, V78, P29307, DOI 10.1007/s11042-018-6857-9
   Li Xiu, 2015, SIGIR2015 WORK NEURO
   Li Xueyi, 2013, ScientificWorldJournal, V2013, P624512, DOI 10.1155/2013/624512
   LIONG ST, 2015, P 3 IAPR AS C PATT, P00665
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Ma Yuxin, 2017, [Computational Visual Media, 计算可视媒体], V3, P161
   Matsumoto D, 2011, MOTIV EMOTION, V35, P181, DOI 10.1007/s11031-011-9212-2
   Merghani W, 2019, MULTIMED TOOLS APPL, V78, P21613, DOI 10.1007/s11042-019-7434-6
   Merghani W, 2018, IEEE INT CONF AUTOMA, P662, DOI 10.1109/FG.2018.00104
   Munir A, 2018, OPTIK, V158, P1016, DOI 10.1016/j.ijleo.2018.01.003
   Nie Guang Yu, 2019, 2019 IEEE INT C COMP, P3283
   O'Sullivan M, 2009, LAW HUMAN BEHAV, V33, P530, DOI 10.1007/s10979-008-9166-4
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Patel D, 2016, INT C PATT RECOG, P2258, DOI 10.1109/ICPR.2016.7899972
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Russell TA, 2006, BRIT J CLIN PSYCHOL, V45, P579, DOI 10.1348/014466505X90866
   Salter F, 2005, HUM NATURE-INT BIOS, V16, P306, DOI 10.1007/s12110-005-1013-4
   Shabat AMM, 2018, IET COMPUT VIS, V12, P603, DOI 10.1049/iet-cvi.2017.0340
   Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451
   TAKAGI M, 2017, 2017 IEEE INN SMART, P00590
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Weiss J, 2009, AM J CLIN HYPN, V53, P287
   Xiao-Bin Huang, 2015, 2015 Asia-Pacific Microwave Conference (APMC). Proceedings, P1, DOI 10.1109/APMC.2015.7413025
   Yan WJ, 2013, IEEE INT CONF AUTOMA
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
NR 47
TC 16
Z9 19
U1 1
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31451
EP 31465
DI 10.1007/s11042-020-09475-4
EA AUG 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000561259300001
DA 2024-07-18
ER

PT J
AU Cevik, N
AF Cevik, Nazife
TI A dynamic inverse distance weighting-based local face descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial recognition; Local descriptor; Inverse distance weighting;
   Classification; Rotation invariant
ID INVARIANT TEXTURE CLASSIFICATION; SPATIAL INTERPOLATION; COMPONENT
   ANALYSIS; RECOGNITION; PATTERN; REPRESENTATION; EIGENFACES; ELEVATION;
   FRAMEWORK; SCALE
AB This paper proposes a novel high-performance dynamic inverse distance weighting based local descriptor (DIDWLD) for facial recognition. Studies proposed thus far have focused on finding local descriptors that can represent the texture of the face best. However, the robustness of the descriptors against rotational variances and noise affects have been largely omitted. Thus, this study does not only concern with proposing a high-discriminative descriptor, but also a robust one against rotational changes and noise affects. DIDWLD mainly basis on Inverse Distance Weighting (IDW). That is, for each pixel in the image, a new descriptive value is calculated, taking into account the intensity values of the neighboring pixels and their distance to the reference pixels. A dynamic distance-decay parameter is applied throughout the image rather than keeping it uniform as done in ordinary IDW. The calculated descriptor is independent of the changes in the rotation. Because, when calculating the descriptor, the intensity values of the surrounding pixels with their distances to the reference pixel are taken into consideration, yet their directional relation to the reference pixel is ignored. Furthermore, when a pixel is suffered to noise, inherently, its neighboring pixels are also affected. Hence, by taking into account the effect of the surrounding pixels and also the original intensity value of the pixel, the degrading impact of noise on recognition performance is mitigated. The results of extensive simulations show the remarkable and competitive performance of the proposed method regarding recognition accuracy, and robustness against rotational variances and, noise effects.
C1 [Cevik, Nazife] Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul Arel University
RP Cevik, N (corresponding author), Istanbul Arel Univ, Dept Comp Engn, Istanbul, Turkey.
EM nazifecevik@arel.edu.tr
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Bailey T., 1995, Interactive Spatial Data Analysis
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cevik N, 2019, IET IMAGE PROCESS, V13, P1097, DOI 10.1049/iet-ipr.2018.6423
   Chakraborty S, 2017, MULTIMED TOOLS APPL, V76, P1201, DOI 10.1007/s11042-015-3111-6
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Dahmane M., 2011, IEEE INT C AUT FAC G, P884, DOI DOI 10.1109/FG.2011.5771368
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Doshi NP, 2012, INT C PATT RECOG, P2760
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Fernández A, 2013, J MATH IMAGING VIS, V45, P76, DOI 10.1007/s10851-012-0349-8
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Goovaerts P, 2000, J HYDROL, V228, P113, DOI 10.1016/S0022-1694(00)00144-X
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Isaaks E.H., 1989, An introduction to applied geostatistics, DOI DOI 10.1016/0098-3004(91)90055-I
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jafari-Khouzani K, 2005, IEEE T PATTERN ANAL, V27, P1004, DOI 10.1109/TPAMI.2005.126
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Jain A, 2000, COMMUN ACM, V43, P90, DOI 10.1145/328236.328110
   JUTTEN C, 1991, SIGNAL PROCESS, V24, P1, DOI 10.1016/0165-1684(91)90079-X
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lee JE, 2008, 2008 BIOMETRICS SYMPOSIUM (BSYM), P1, DOI [10.1109/PLASMA.2008.4591032, 10.1109/BSYM.2008.4655515]
   Leng L, 2010, P IEEE INT C INF COM, V2010, P467, DOI DOI 10.1109/ICTC.2010.5674791
   Li J, 2014, ENVIRON MODELL SOFTW, V53, P173, DOI 10.1016/j.envsoft.2013.12.008
   Libor S, 2000, FACE RECOGNITION DAT
   Lin J, 2017, IET IMAGE PROCESS, V11, P1179, DOI 10.1049/iet-ipr.2016.1074
   Liu LT, 2016, IEEE INT CONF ROBOT, P56, DOI 10.1109/ICRA.2016.7487115
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Lloyd CD, 2005, J HYDROL, V308, P128, DOI 10.1016/j.jhydrol.2004.10.026
   Lu GY, 2008, COMPUT GEOSCI-UK, V34, P1044, DOI 10.1016/j.cageo.2007.07.010
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Melendez J, 2008, PATTERN ANAL APPL, V11, P365, DOI 10.1007/s10044-007-0097-3
   Mika S., 1999, NNSP, V1999, P41, DOI DOI 10.1109/NNSP.1999.788121
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nanni L, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0083554
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Nisenson M, 2003, LECT NOTES ARTIF INT, V2838, P363
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Rivera AR, 2015, IEEE T PATTERN ANAL, V37, P2146, DOI 10.1109/TPAMI.2015.2392774
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Su Y, 2018, IET IMAGE PROCESS, V12, P826, DOI 10.1049/iet-ipr.2017.0757
   Takallou HM, 2014, IET IMAGE PROCESS, V8, P300, DOI 10.1049/iet-ipr.2013.0003
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tseng S, 2003, THESIS
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XG, 2004, IEEE T PATTERN ANAL, V26, P1222, DOI 10.1109/TPAMI.2004.57
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yin QB, 2008, CHINESE J ELECTRON, V17, P646
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang H, 2017, P IEEE 2 ADV INF TEC
   Zhang PY, 2016, PATTERN RECOGN, V52, P249, DOI 10.1016/j.patcog.2015.09.024
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao X, 2017, IEEE C ELEC DEVICES
   Zhou Q, 2018, MULTIMED TOOLS APPL, V77, P10501, DOI 10.1007/s11042-017-4569-1
   Zhu ZQ, 2015, PATTERN RECOGN, V48, P2592, DOI 10.1016/j.patcog.2015.01.001
NR 66
TC 1
Z9 1
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31087
EP 31102
DI 10.1007/s11042-020-09581-3
EA AUG 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560645900002
DA 2024-07-18
ER

PT J
AU Silwal, R
   Alsadoon, A
   Prasad, PWC
   Alsadoon, OH
   Al-Qaraghuli, A
AF Silwal, Raj
   Alsadoon, Abeer
   Prasad, P. W. C.
   Alsadoon, Omar Hisham
   Al-Qaraghuli, Ammar
TI A novel deep learning system for facial feature extraction by fusing CNN
   and MB-LBP and using enhanced loss function
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Facial image recognition; Multi-block local binary
   pattern; Convolutional neural network
ID FACE RECOGNITION
AB Extensive use of surveillance cameras for human tracking and observation have been fostering the research on face recognition technique for individual identification in an unconstrained environment. However, face recognition is a challenging task in an unconstrained environment, where the captured images are affected by illumination effect, varying poses, noise and occlusion. The main objective of this research is to improve the accuracy and processing time in extracting facial features by using the fusion of deep learning and handcrafted architecture for recognizing individuals in unconstrained conditions, thereby providing accurate information about the individuals to security systems. The proposed system consists of Multi-Block Local Binary Pattern (MB-LBP) modules for extracting the handcrafted features and Convolutional Neural Network (CNN) for extracting the high-level distinctive features. The features from both modules are fused and passed through fully connected layer with Softmax classifier to identify individuals. The results show that the enhanced algorithm based on Softmax loss function aided classifier with regularization improves the accuracy and processing time for face recognition. The proposed model improves accuracy by 94.37% against 90.01% for the state-of-the-art solution. In addition to that, it improves the processing time of 307 ms against 357 ms. The proposed system focuses on fusing hand-crafted and deep learned features to extract face features accurately and thus improving the accuracy and overall performance of the proposed system in an unconstrained environment.
C1 [Silwal, Raj; Alsadoon, Abeer; Prasad, P. W. C.] Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Bathurst, NSW, Australia.
   [Alsadoon, Omar Hisham] Al Iraqia Univ, Dept Islamic Sci, Baghdad, Iraq.
   [Al-Qaraghuli, Ammar] Sheridan Coll, Oakville, ON, Canada.
C3 Charles Sturt University; Al-Iraqia University
RP Alsadoon, A (corresponding author), Charles Sturt Univ, Sch Comp & Math, Sydney Campus, Bathurst, NSW, Australia.
EM alsadoon.abeer@gmail.com
RI Alsadoon, A/Prof. Abeer/AAU-1532-2021; Al-Qaraghuli, Ammar/HOF-9447-2023
OI Alsadoon, A/Prof. Abeer/0000-0002-2309-3540; Al-Qaraghuli,
   Ammar/0000-0001-8445-9238; withana, chandana/0000-0002-3007-687X;
   Alsadoon, Omar Hisham/0000-0001-7797-6392
CR Al-Waisy AS, 2018, MACH VISION APPL, V29, P35, DOI 10.1007/s00138-017-0870-2
   Alghamdi A, 2024, MULTIMED TOOLS APPL, V83, P14913, DOI 10.1007/s11042-020-08769-x
   Bong K, 2018, IEEE J SOLID-ST CIRC, V53, P115, DOI 10.1109/JSSC.2017.2767705
   Chaudhry S, 2017, APPL SOFT COMPUT, V53, P168, DOI 10.1016/j.asoc.2016.12.035
   Chen GH, 2018, MACH VISION APPL, V29, P513, DOI 10.1007/s00138-018-0907-1
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Ding YY, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0188-z
   El-Rahiem BA, 2019, EFFICIENT DEEP CONVO
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Kamencay P, 2017, ADV ELECTR ELECTRON, V15, P663, DOI 10.15598/aeee.v15i4.2389
   Leng BA, 2016, NEUROCOMPUTING, V215, P232, DOI 10.1016/j.neucom.2015.08.134
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Li J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072080
   Li Y, ACM T SENSOR NETWORK
   Li YF, 2018, WIRELESS PERS COMMUN, V103, P1195, DOI 10.1007/s11277-018-5377-2
   Liu JZ, 2016, J ELECTR COMPUT ENG, V2016, DOI 10.1155/2016/8637260
   Moon HM, 2017, SOFT COMPUT, V21, P4995, DOI 10.1007/s00500-016-2095-0
   Nielsen M. A., 2015, NEURAL NETWORKS DEEP, DOI DOI 10.1145/2939672.2945397
   Peng JL, 2013, IEICE T INF SYST, VE96D, P1886, DOI 10.1587/transinf.E96.D.1886
   Tripathi BK, 2017, APPL INTELL, V47, P382, DOI 10.1007/s10489-017-0902-7
   Wang N, 2014, MULTIMED TOOLS APPL, V72, P2339, DOI 10.1007/s11042-013-1551-4
   Wang N, 2013, 2013 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES (ISBAST), P217, DOI 10.1109/ISBAST.2013.38
   Zhao JW, 2017, NEURAL NETWORKS, V94, P115, DOI 10.1016/j.neunet.2017.06.013
NR 23
TC 6
Z9 6
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 31027
EP 31047
DI 10.1007/s11042-020-09559-1
EA AUG 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000560297200003
DA 2024-07-18
ER

PT J
AU Yuan, ZH
   Liu, DC
   Zhang, XT
   Wang, HY
   Su, QT
AF Yuan, Zihan
   Liu, Decheng
   Zhang, Xueting
   Wang, Huanying
   Su, Qingtang
TI DCT-based color digital image blind watermarking method with variable
   steps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blind watermarking; Color image; Discrete cosine transform; Variable
   steps
ID WAVELET TRANSFORM; SCHEME; DECOMPOSITION; FRAMEWORK
AB In this paper, a blind watermarking method for color digital image based on DCT domain with variable steps is proposed to solve the copyright protection of color digital image. In this method, partial DCT coefficients of the image block transformed by two-dimensional discrete cosine transform (2D-DCT) are selected in the transform domain firstly, then these selected DCT coefficients at different positions are quantized by different quantization steps, and the embedding and blind extraction of digital watermark are completed. This method used color digital image as watermark image instead of gray image or binary image, and the color host image used in this scheme is selected from two public image databases (CVG-UGR and USC-SIPI). The experimental result shows that this scheme embedded color digital image watermark into host image successfully not merely has high invisibility, but also has strong robustness, which is suitable for digital image copyright protection.
C1 [Yuan, Zihan; Liu, Decheng; Zhang, Xueting; Wang, Huanying; Su, Qingtang] Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
C3 Ludong University
RP Su, QT (corresponding author), Ludong Univ, Sch Informat & Elect Engn, Yantai 264025, Peoples R China.
EM sdytsqt@163.com
FU National Natural Science Foundations of China [61771231, 61772253,
   61572258, 61602229]; Key Research and Development Program of Shandong
   Province [2019GGX101025, 2019GGX101032]
FX This work was supported by the National Natural Science Foundations of
   China (No. 61771231, 61772253, 61572258, and 61602229), and the Key
   Research and Development Program of Shandong Province (No.
   2019GGX101025, 2019GGX101032).
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Araghi TK, 2018, EXPERT SYST APPL, V112, P208, DOI 10.1016/j.eswa.2018.06.024
   Botta M, 2016, SIGNAL PROCESS, V119, P102, DOI 10.1016/j.sigpro.2015.07.018
   Cedillo-Hernandez A, 2018, J VIS COMMUN IMAGE R, V52, P106, DOI 10.1016/j.jvcir.2018.02.007
   Ernawan F, 2018, IEEE ACCESS, V6, P20464, DOI 10.1109/ACCESS.2018.2819424
   Golea N., 2010, IEEE INT C COMPUTER, P1
   Jane O, 2014, J APPL RES TECHNOL, V12, P750, DOI 10.1016/S1665-6423(14)70091-4
   JINDAL H, 2016, P INT C REC COGN WIR, P1
   Jindal H, 2018, P INT C PAR DISTR GR, P12
   Jindal H, 2018, WIREL NETW, V24, P3241, DOI 10.1007/s11276-017-1532-z
   Jindal H, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318500133
   Jindal H, 2017, AD HOC SENS WIREL NE, V39, P1
   Jindal H, 2017, WIRELESS PERS COMMUN, V97, P881, DOI 10.1007/s11277-017-4542-3
   Jindal H, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P251, DOI 10.1109/PDGC.2014.7030751
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P333, DOI 10.1007/s11042-015-3058-7
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liu SH, 2018, DISCRETE APPL MATH, V241, P48, DOI 10.1016/j.dam.2016.06.028
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Makbol NM, 2017, INFORM SCIENCES, V417, P381, DOI 10.1016/j.ins.2017.07.026
   Mander Kuldeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P17, DOI 10.5815/ijigsp.2017.08.03
   Mehta S, 2015, INT J ENG RES COMPUT, V2, P47
   Mittal Archie, 2017, International Journal of Image, Graphics and Signal Processing, V9, P28, DOI 10.5815/ijigsp.2017.05.04
   Mourya G, 2015, 2015 1ST INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTING TECHNOLOGIES (NGCT), P187, DOI 10.1109/NGCT.2015.7375109
   Ouyang JL, 2015, COMPUT ELECTR ENG, V46, P419, DOI 10.1016/j.compeleceng.2015.03.004
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Rasti P, 2016, J VIS COMMUN IMAGE R, V38, P838, DOI 10.1016/j.jvcir.2016.05.001
   Sahu N, 2017, J VIS COMMUN IMAGE R, V45, P77, DOI 10.1016/j.jvcir.2017.02.013
   Saxena S, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P176, DOI 10.1109/PDGC.2014.7030737
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2019, IEEE ACCESS, V7, P30398, DOI 10.1109/ACCESS.2019.2895062
   Su QT, 2019, IEEE ACCESS, V7, P4358, DOI 10.1109/ACCESS.2018.2888857
   Su QT, 2017, AEU-INT J ELECTRON C, V78, P64, DOI 10.1016/j.aeue.2017.05.025
   Su QT, 2016, IET IMAGE PROCESS, V10, P817, DOI 10.1049/iet-ipr.2016.0048
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Tang MW, 2015, OPTIK, V126, P4136, DOI 10.1016/j.ijleo.2015.07.200
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   University of Southern California Signal and Inage Processing Institute n, USC SIPI IM DAT
   Yuan ZH, 2020, OPTIK, V204, DOI 10.1016/j.ijleo.2019.164152
NR 42
TC 21
Z9 22
U1 6
U2 61
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2020
VL 79
IS 41-42
BP 30557
EP 30581
DI 10.1007/s11042-020-09499-w
EA AUG 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NZ1NQ
UT WOS:000559953900016
DA 2024-07-18
ER

PT J
AU Shah, D
   Shah, T
AF Shah, Dawood
   Shah, Tariq
TI A novel discrete image encryption algorithm based on finite algebraic
   structures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ring of integers modulo n; Galois field; Irreducible polynomials; Group
   action; S-box; Image encryption
ID HYPER-CHAOTIC SYSTEM; DNA ENCRYPTION; COLOR; SCHEME; CML
AB The arithmetic properties of a finite field have a remarkable impact on the security features of symmetric and asymmetric cryptosystems. Conventionally, in modern symmetric-key cryptosystems, a 256 elements Galois field depending on a single 8 degree primitive irreducible polynomial overDOUBLE-STRUCK CAPITAL Z(2)is used for designing an S-box, the main nonlinear component in AES. The experience of S-box based image encryption schemes is not appreciable than chaotic systems based methods. In this study, we improve the S-box based image encryption algorithms by the usage of all 16 distinct degree 8 primitive irreducible polynomials overDOUBLE-STRUCK CAPITAL Z(2)and by introducing a new role of the ringDOUBLE-STRUCK CAPITAL Z(n)of integers modulonin the permutation steps. The strength of this novel 2-algebraic structures based image encryption scheme is evaluated by some statistical analyses and a significant performance level is achieved. A comparison of encryption quality with some of the recent chaos-based image encryption algorithms is given and evidently the newly launched scheme spectacles high performance. Thus this new development in image encryption methods may provide an alternative to chaos dependent image encryption.
C1 [Shah, Dawood; Shah, Tariq] Quaid I Azam Univ Islamabad, Dept Math, Islamabad, Pakistan.
C3 Quaid I Azam University
RP Shah, D (corresponding author), Quaid I Azam Univ Islamabad, Dept Math, Islamabad, Pakistan.
EM dawoodshah@math.qau.edu.pk
CR Al-Maadeed S., 2012, J ELECT COMPUT ENG, V2012, DOI DOI 10.1155/2012/179693
   Al-Najjar HM, 2011, P INT AR C INF TECHN
   Alghafis A, 2020, PHYSICA A, V554, DOI 10.1016/j.physa.2019.123908
   Chai XL, 2016, CHINESE PHYS B, V25, DOI 10.1088/1674-1056/25/10/100503
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chattopadhyay D., 2011, INDIAN J SCI TECHNOL, V4, P593, DOI 10.17485/ijst/2011/v4i5.27
   Doanaksoy A, 2015, MATH PROB ENG
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fu C, 2012, OPT EXPRESS, V20, P2363, DOI 10.1364/OE.20.002363
   Gupta Kamlesh., 2011, Journal of Information Security, V2, P139, DOI DOI 10.4236/JIS.2011.24014
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huang ZJ, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105821
   Hussain I, 2013, NEURAL COMPUT APPL, V22, P1085, DOI 10.1007/s00521-012-0870-0
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Khan M, 2008, NEURAL COMPUT APPL, V27.3, P677
   Khan M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206460
   Khan M, 2015, NEURAL COMPUT APPL, V26, P1137, DOI 10.1007/s00521-014-1800-0
   Khan M, 2013, NONLINEAR DYNAM, V71, P489, DOI 10.1007/s11071-012-0675-9
   Khan MA, 2019, MATER RES FOUND, V50, P1, DOI 10.21741/9781644900239-1
   Kim J, 2009, CRYPTOLOGIA, V33, P246, DOI 10.1080/01611190802653228
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liu HJ, 2015, SIGNAL PROCESS, V113, P104, DOI 10.1016/j.sigpro.2015.01.016
   Matsui M, 1993, LINEAR CRYPTANALYSIS, P386, DOI DOI 10.1007/3-540-48285-7
   Naseer Y, 2019, CRYPTOGRAPHY-BASEL, V3, DOI 10.3390/cryptography3010006
   Naseer Y, 2019, MICROPROCESS MICROSY, V65, P1, DOI 10.1016/j.micpro.2018.12.003
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Pareschi F, 2012, IEEE T INF FOREN SEC, V7, P491, DOI 10.1109/TIFS.2012.2185227
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Shah Dawood, 2018, 2018 International Conference on Applied and Engineering Mathematics (ICAEM), P38, DOI 10.1109/ICAEM.2018.8536281
   Shah T, 2019, MULTIMED TOOLS APPL, V78, P1219, DOI 10.1007/s11042-018-6250-8
   Tran Minh Triet, INT C COMP INT SEC, V1
   Wang XY, 2016, BIOSYSTEMS, V144, P18, DOI 10.1016/j.biosystems.2016.03.011
   Wang XY, 2012, SIGNAL PROCESS, V92, P1101, DOI 10.1016/j.sigpro.2011.10.023
   Waseem HM, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063022
   Wu JH, 2017, SIGNAL PROCESS, V141, P109, DOI 10.1016/j.sigpro.2017.04.006
   Wu XJ, 2018, SIGNAL PROCESS, V148, P272, DOI 10.1016/j.sigpro.2018.02.028
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Yao LL, 2017, OPT LASER ENG, V89, P72, DOI 10.1016/j.optlaseng.2016.06.006
   Yu SS, 2020, OPT LASER ENG, V124, DOI 10.1016/j.optlaseng.2019.105816
   Zhang Y, 2012, NONLINEAR DYNAM, V69, P1091, DOI 10.1007/s11071-012-0329-y
   Zhang YS, 2014, NONLINEAR DYNAM, V76, P1645, DOI 10.1007/s11071-014-1235-2
NR 47
TC 11
Z9 11
U1 4
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 28023
EP 28042
DI 10.1007/s11042-020-09182-0
EA JUL 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000554334600001
DA 2024-07-18
ER

PT J
AU Gan, CQ
   Saini, A
   Zhu, QY
   Xiang, Y
   Zhang, ZF
AF Gan, Chenquan
   Saini, Akanksha
   Zhu, Qingyi
   Xiang, Yong
   Zhang, Zufan
TI Blockchain-based access control scheme with incentive mechanism for
   eHealth systems: patient as supervisor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE eHealth system; Medical data; Blockchain; Access control; Incentive
   mechanism
ID AUTHENTICATION SCHEME; HEALTH; SECURITY; CHALLENGES
AB This paper is dedicated to investigating the application of blockchain in eHealth systems. Unlike the previous work, patients here play a supervisory role and allow medical institutions to legally use their medical data without prior authorization but own the right to manage the medical data. This concept is able to protect the rights and interests of patients without affecting the normal diagnosis and research work of medical institutions. On this basis, a blockchain-based access control scheme for eHealth systems is proposed. To encourage patients to actively share their medical data, an incentive mechanism is also included. Finally, a case study on Ethereum is given to illustrate the feasibility and practicality of the proposed method.
C1 [Gan, Chenquan; Zhang, Zufan] Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing, Peoples R China.
   [Gan, Chenquan; Zhang, Zufan] Chongqing Key Lab Mobile Commun Technol, Chongqing 400065, Peoples R China.
   [Gan, Chenquan; Zhang, Zufan] Minist Educ, Engn Res Ctr Mobile Commun, Chongqing 400065, Peoples R China.
   [Saini, Akanksha; Xiang, Yong] Deakin Univ, Sch Informat Technol, Melbourne, Vic 3000, Australia.
   [Zhu, Qingyi] Chongqing Univ Posts & Telecommun, Sch Cyber Secur & Informat Law, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Deakin University;
   Chongqing University of Posts & Telecommunications
RP Saini, A (corresponding author), Deakin Univ, Sch Informat Technol, Melbourne, Vic 3000, Australia.
EM gcq2010cqu@163.com; sainiakan@deakin.edu.au; zhuqy@cqupt.edu.cn;
   yxiang@deakin.edu.cn; zhangzf@cqupt.edu.cn
RI Zhu, Qingyi/A-6494-2018
OI Zhu, Qingyi/0000-0002-1168-1599; Saini, Akanksha/0000-0002-7191-2854
FU Natural Science Foundation of China [61702066, 11747125]; Major Project
   of Science and Technology Research Program of Chongqing Education
   Commission of China [KJZD-M201900601]; Chongqing Research Program of
   Basic Research and Frontier Technology [cstc2017jcyjAX0256,
   cstc2018jcyjAX0154]; Chongqing Municipal Key Laboratory of Institutions
   of Higher Education [cqupt-mct-201901]; Technology Foundation of Guizhou
   Province [QianKeHeJiChu[2020]1Y269]; New academic seedling cultivation
   and exploration innovation project [QianKeHe Platform
   Talents[2017]5789-21]
FX The authors are grateful to the anonymous reviewers and the editor for
   their valuable comments and suggestions. This work is supported by
   Natural Science Foundation of China (Grant Nos. 61702066 and 11747125),
   Major Project of Science and Technology Research Program of Chongqing
   Education Commission of China (Grant No. KJZD-M201900601), Chongqing
   Research Program of Basic Research and Frontier Technology (Grant Nos.
   cstc2017jcyjAX0256 and cstc2018jcyjAX0154), Project Supported by
   Chongqing Municipal Key Laboratory of Institutions of Higher Education
   (Grant No. cqupt-mct-201901), Technology Foundation of Guizhou Province
   (QianKeHeJiChu[2020]1Y269), and New academic seedling cultivation and
   exploration innovation project (QianKeHe Platform Talents[2017]5789-21).
CR Al Omar Abdullah, 2017, Security, Privacy and Anonymity in Computation, Communication and Storage, SpaCCS 2017: International Workshops. Proceedings: LNCS 10658, P534, DOI 10.1007/978-3-319-72395-2_49
   Al Omar A, 2019, FUTURE GENER COMP SY, V95, P511, DOI 10.1016/j.future.2018.12.044
   [Anonymous], 2005, E2369 ASTM
   Azaria A, 2016, PROCEEDINGS 2016 2ND INTERNATIONAL CONFERENCE ON OPEN AND BIG DATA - OBD 2016, P25, DOI 10.1109/OBD.2016.11
   Chen Hannah S, 2019, Biomed J Sci Tech Res, V20, P15017
   Chen LX, 2019, FUTURE GENER COMP SY, V95, P420, DOI 10.1016/j.future.2019.01.018
   Chen Y, 2019, J MED SYST, V43, DOI 10.1007/s10916-018-1121-4
   Chenthara S, 2019, IEEE ACCESS, V7, P74361, DOI 10.1109/ACCESS.2019.2919982
   Dagher GG, 2018, SUSTAIN CITIES SOC, V39, P283, DOI 10.1016/j.scs.2018.02.014
   Dias JP, 2018, BLOCKCHAIN ACCESS CO
   Ekblaw A., 2016, A Case Study for Blockchain in Healthcare:"MedRec" prototype for electronic health records and medical research data, DOI DOI 10.1109/OBD.2016.11
   Esposito C, 2018, IEEE CLOUD COMPUT, V5, P31
   Fan K, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0993-7
   Gao YL, 2018, IEEE ACCESS, V6, P27205, DOI 10.1109/ACCESS.2018.2827203
   Gordon WJ, 2018, COMPUT STRUCT BIOTEC, V16, P224, DOI 10.1016/j.csbj.2018.06.003
   Griggs KN, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0982-x
   Guo H, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON BLOCKCHAIN (BLOCKCHAIN 2019), P44, DOI 10.1109/Blockchain.2019.00015
   Hyla T, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11030076
   Khatoon A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010094
   Khezr S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9091736
   Kish LJ, 2015, NAT BIOTECHNOL, V33, P921, DOI 10.1038/nbt.3340
   Li HW, 2020, IEEE T CLOUD COMPUT, V8, P484, DOI 10.1109/TCC.2017.2769645
   Li HY, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0997-3
   Mehmood A, 2018, IEEE ACCESS, V6, P33552, DOI 10.1109/ACCESS.2018.2841972
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Nguyen DC, 2019, IEEE ACCESS, V7, P66792, DOI 10.1109/ACCESS.2019.2917555
   Premarathne U, 2016, IEEE CLOUD COMPUT, V3, P58, DOI 10.1109/MCC.2016.76
   Pussewalage HSG, 2018, IEEE 2018 INTERNATIONAL CONGRESS ON CYBERMATICS / 2018 IEEE CONFERENCES ON INTERNET OF THINGS, GREEN COMPUTING AND COMMUNICATIONS, CYBER, PHYSICAL AND SOCIAL COMPUTING, SMART DATA, BLOCKCHAIN, COMPUTER AND INFORMATION TECHNOLOGY, P1204, DOI 10.1109/Cybermatics_2018.2018.00214
   Rabah K., 2017, MARA RES J MED HLTH, V1, P45
   Rifi N, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN BIOMEDICAL ENGINEERING (ICABME), P198
   Tang F, 2019, IEEE ACCESS, V7, P41678, DOI 10.1109/ACCESS.2019.2904300
   Tanwar S, 2020, J INF SECUR APPL, V50, DOI 10.1016/j.jisa.2019.102407
   Thwin TT, 2018, SECUR COMMUN NETW, V2018, P1
   Tripathi G, 2020, HEALTHCARE-J DEL SCI, V8, DOI 10.1016/j.hjdsi.2019.100391
   Wang H, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0994-6
   Wang JC, 2020, FUTURE GENER COMP SY, V110, P675, DOI 10.1016/j.future.2019.09.049
   Wang RY, 2019, IEEE WIREL COMMUN, V26, P30, DOI 10.1109/MWC.001.1900108
   Xia Q, 2017, INFORMATION, V8, DOI 10.3390/info8020044
   Zhang AQ, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-0995-5
   Zhang P, 2018, COMPUT STRUCT BIOTEC, V16, P267, DOI 10.1016/j.csbj.2018.07.004
   Zhu QY, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3359982
NR 41
TC 17
Z9 19
U1 4
U2 39
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2021
VL 80
IS 20
BP 30605
EP 30621
DI 10.1007/s11042-020-09322-6
EA JUL 2020
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA UQ8WP
UT WOS:000553718200002
DA 2024-07-18
ER

PT J
AU Dhingra, S
   Bansal, P
AF Dhingra, Shefali
   Bansal, Poonam
TI Experimental analogy of different texture feature extraction techniques
   in image retrieval systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Local binary pattern; Precision; F-measure;
   Relevance feedback; Recall
ID FEATURE DESCRIPTOR; PATTERNS
AB Content based image retrieval (CBIR) is an extrusive technique of retrieving the relevant images from vast image archives by extracting their low level features. In this research paper, the pursuance of five most prominent texture feature extraction techniques used in CBIR systems are experimentally compared in detail. The main issue with the CBIR systems is the proper selection of techniques for the extraction of low level features which comprises of color, texture and shape. Among these features, texture is one of the most decisive and dominant features. This selection of features completely depends upon the type of images to be retrieved from the database. The texture techniques explored here are Grey level co-occurrence matrix (GLCM), Discrete wavelet transform (DWT), Gabor transform, Curvelet and Local binary pattern (LBP). These are experimented on three touchstone databases which are Wang, Corel-5 K and Corel-10 K. The chief parameters of CBIR systems are evaluated here such as precision, recall and F-measure on all these databases using all the techniques. After detailed investigation it is figured out that LBP, GLCM and DWT provide highlighted and comparable results in all these datasets in terms of average precision. Besides practical implementation, the precised conceptual examination of these three texture techniques is also proposed in this article. So, this analysis is extremely beneficial for selecting the appropriate feature extraction technique by taking into consideration the experimental results along with image conditions such as noise, rotation etc.
C1 [Dhingra, Shefali] Guru Gobind Singh Indraprastha Univ, New Delhi, India.
   [Bansal, Poonam] Maharaja Surajmal Inst Technol, New Delhi, India.
C3 GGS Indraprastha University; Maharaja Surajmal Institute of Technology
RP Dhingra, S (corresponding author), Guru Gobind Singh Indraprastha Univ, New Delhi, India.
EM shefalidhingra38@yahoo.com; pbansal89@gmail.com
RI Bansal, Poonam/GPC-5397-2022; Bansal, Poonam/ABG-2840-2020
OI Bansal, Poonam/0000-0002-8214-2840
CR Agarwal S, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS AND COMPUTER NETWORKS (ISCON), P19, DOI 10.1109/ICISCON.2013.6524166
   Al-Rawi SS, 2011, INT ARAB J INF TECHN, P1
   [Anonymous], INT J SIGNAL PROCESS
   Chaudhari R., 2012, International Journal of Advanced Research in Electrical, Electronics and Instrumentation Engineering, V1, P386
   Cui CR, 2017, J VIS COMMUN IMAGE R, V48, P367, DOI 10.1016/j.jvcir.2017.03.011
   Fadaei S, 2017, IET IMAGE PROCESS, V11, P89, DOI 10.1049/iet-ipr.2016.0542
   Jin C, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0132-0
   Liu GH, 2013, PATTERN RECOGN, V46, P188, DOI 10.1016/j.patcog.2012.06.001
   Mosbah M, 2017, EGYPT INFORM J, V18, P1, DOI 10.1016/j.eij.2016.09.001
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Mutasem K.A., 2017, Egyptian Journal of Basic and Applied Sciences, V4, P112, DOI 10.1016/j.ejbas.2017.02.004
   Pavithra LK, 2018, COMPUT ELECTR ENG, V70, P580, DOI 10.1016/j.compeleceng.2017.08.030
   Prabhu Jeyanthi, 2014, Journal of Computer Science, V10, P15, DOI 10.3844/jcssp.2014.15.22
   Prakasa E., 2015, INKOM J, V9, P45, DOI DOI 10.14203/J.INKOM.420
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Sai NST, 2016, PROCEDIA COMPUT SCI, V79, P579, DOI 10.1016/j.procs.2016.03.073
   Shahbahrami A, 2008, S APPL MACH INTELL I, V27648, P221
   Sharma R, 2014, INT J CRIME JUSTICE, V3, P4
   Sheshasaayee A, 2014, INT J ENG TREND TECH, V10, P166
   Singh S. M., 2012, Mach. Learn., V9, P299
   Srivastava D., 2015, Int. J. Comput. Eng. Manage., V18, P9
   Sumana IJ, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P11, DOI 10.1109/MMSP.2008.4665041
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Wang HB, 2016, IEEE T MULTIMEDIA, V18, P1579, DOI 10.1109/TMM.2016.2569412
   Wang L, 2017, SIGNAL PROCESS-IMAGE, V53, P86, DOI 10.1016/j.image.2017.02.006
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Zhao M, 2016, J VIS COMMUN IMAGE R, V38, P73, DOI 10.1016/j.jvcir.2016.02.016
NR 27
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2020
VL 79
IS 37-38
BP 27391
EP 27406
DI 10.1007/s11042-020-09317-3
EA JUL 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NW1GT
UT WOS:000552190000003
DA 2024-07-18
ER

PT J
AU Papapicco, C
   Mininni, G
AF Papapicco, Concetta
   Mininni, Giuseppe
TI Impact memes: PhDs HuMor(e)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE PhD memes; Mediated humor; Emotional analysis; Semiotic analysis of
   imagines; Diatextual analysis
ID STYLES; MEDIA
AB The era of User Generated Content (USG) on Social Networks has invested different areas of human experience, including one of the highest levels of education, i.e., the PhD grade. As regards the opportunity to "imitate" a virtual content, the phenomenon of Memes (Shifman, J Vis Cult 13(3):340-358,56) is spreading. The present research aims at the understanding how the online functions and practices of humor signification are featured considering linguistic and visual aspects. In particular it has a twofold goals: a) analyzing which differences emerged in terms of functions and emotions between humor in PhD Memes on Facebook and Instagram by means of 'diatextual' analysis; b) performing a fine-grained qualitative analysis about rethorical aspects based on linguistic and visual elements of Phd Memes in order to contribute to the field of humor automatic detection. To satisfy these purposes, 70 memes about the PhD on Facebook and Instagram were collected and, then, analyzed in two levels: (1) the quanti-qualitative, aiming to detect the semi-automatic emotional involvement, expression of humor in "meme discourses"; (2) the semiotic analysis of meme images. The results highlight first of all typical cases of incongruences in automatic and diatextual analysis in coding the effective emotions; furthermore they also show the peculiar function of humor, mediated by communication through memes, which is mainly a kind of 'emotional sharing' consisting in the complaint against a complex and precarious career path; in addition some differences in relation to the type of social media (Facebook or Instagram) are reported.
C1 [Papapicco, Concetta; Mininni, Giuseppe] Univ Bari, Dept Psychol, Bari, Italy.
C3 Universita degli Studi di Bari Aldo Moro
RP Papapicco, C (corresponding author), Univ Bari, Dept Psychol, Bari, Italy.
EM concetta.papapicco@uniba.it
RI Papapicco, Concetta/AAG-1834-2019
OI Papapicco, Concetta/0000-0003-3240-8740
CR Alvarado M. B., 2006, INTERLINGUISTICA, V16, P151
   Alvarado M. Belen, 2009, Dime como ironizas y te dire quien eres: una aproximacion pragmatica a la ironia, P333
   Alvarado MB, 2012, ORALIA, V15, P63
   Alvarado MB, 2010, FORMULAS RUTINARIAS
   Ortega MBA, 2013, PROCD SOC BEHV, V95, P594, DOI 10.1016/j.sbspro.2013.10.687
   Attardo S., 2001, HUMOROUS TEXTS SEMAN
   Attardo Salvatore., 2001, Say Not to Say, P166
   Attardo Salvatore., 2008, PRIMER HUMOR RES
   Attardo Salvatore., 1991, HUMOR, V4, P293, DOI [DOI 10.1515/HUMR.1991.4.3-4.293, 10.1515/humr.1991.4.3-4.293, 10.1515/humr.1991.4.34.293, DOI 10.1515/HUMR.1991.4.34.293]
   Barbotti I, 2015, INSTAGRAM MARKETING
   Berger A. A., 1993, AN ANATOMY OF HUMOR, DOI https://doi.org/10.4324/9781315082394
   BERGER AA, 1976, J COMMUN, V26, P113, DOI 10.1111/j.1460-2466.1976.tb01913.x
   Bergson H, 1950, PSYCHOL REV, V8, P98, DOI [10.1037/h0069028, DOI 10.1037/H0069028]
   Bergson H, 1994, RIRE PARIS
   Bergson Henri., 1911, Laughter: An Essay on the Meaning of the Comic
   Berlo D., 1960, PROCESS COMMUNICATIO
   Biondi G, 2017, LECT NOTES COMPUT SC, V10406, P718, DOI 10.1007/978-3-319-62398-6_51
   Buijzen M, 2004, MEDIA PSYCHOL, V6, P147, DOI 10.1207/s1532785xmep0602_2
   Byrd G, 2016, COMPUTER, V49, P102, DOI 10.1109/MC.2016.13
   Catanescu Codruta., 2001, REV BUS, V22, P92
   Choi M, 2014, COMPUT HUM BEHAV, V36, P530, DOI 10.1016/j.chb.2014.04.026
   D'Errico F, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01144
   D'Errico F, 2012, J MULTIMODAL USER IN, V6, P163, DOI 10.1007/s12193-012-0098-4
   DAWKINS R, 1976, SELFISH GENE
   de Koning E, 2002, AM J FAM THER, V30, P1, DOI 10.1080/019261802753455615
   Freud S., 1905, 3 ESSAYS THEORY SEXU
   Greimas AJ, 1991, SEMIOTICA FIGURATIVA
   Grice P, 1975, LOGIC CONVERSATION S, P41
   Hay J, 2000, J PRAGMATICS, V32, P709, DOI 10.1016/S0378-2166(99)00069-7
   Herzig J, 2017, ICTIR'17: PROCEEDINGS OF THE 2017 ACM SIGIR INTERNATIONAL CONFERENCE THEORY OF INFORMATION RETRIEVAL, P269, DOI 10.1145/3121050.3121093
   Holmes J., DISCOURSE STUD, V2, P159, DOI [DOI 10.1177/1461445600002002002, 10.1177/1461445600002002002]
   Iannella A, 2018, THAMYRIS NOVA SERIES, V9, P319
   Johann M, 2019, INT J COMMUN-US, V13, P1720
   Levecque K, 2017, RES POLICY, V46, P868, DOI 10.1016/j.respol.2017.02.008
   Mangold WG, 2009, BUS HORIZONS, V52, P357, DOI 10.1016/j.bushor.2009.03.002
   Martin RA, 2003, J RES PERS, V37, P48, DOI 10.1016/S0092-6566(02)00534-2
   McGhee P.E., 1979, HUMOR ITS ORIGIN DEV
   MCGHEE PE, 1971, CHILD DEV, V42, P123
   MCGHEE PE, 1976, J COMMUN, V26, P176, DOI 10.1111/j.1460-2466.1976.tb01922.x
   Meyer JC, 2000, COMMUN THEOR, V10, P310, DOI 10.1111/j.1468-2885.2000.tb00194.x
   Mihalcea R, 2006, COMPUT INTELL-US, V22, P126, DOI 10.1111/j.1467-8640.2006.00278.x
   Mininni G, 2013, PSICOLOGIA CULTURALE
   Mininni G, 2017, TEXT TALK, V37, P243, DOI 10.1515/text-2017-0005
   Nijholt A, 2003, HUM FACT COMP SYST C, DOI [10.1145/765891.766143, DOI 10.1145/765891.766143]
   Novielli N, 2015, 7TH INTERNATIONAL WORKSHOP ON SOCIAL SOFTWARE ENGINEERING (SSE 2015), P33, DOI 10.1145/2804381.2804387
   Osterroth Andreas., 2015, IMAGE. Zeitschrift fur interdisziplinare Bildwissenschaft, V22, P26
   Pang B., 2008, INFORM RETRIEVAL, V2, P1, DOI [10.1561/1500000011, DOI 10.1561/1500000011, https://doi.org/10.1561/1500000011]
   Papapicco C, 2020, J TOUR CULT CHANGE, V18, P545, DOI 10.1080/14766825.2019.1611839
   Poggi I, 2013, J MULTIMODAL USER IN, V7, P67, DOI 10.1007/s12193-012-0102-z
   Poggi I, 2010, J MULTIMODAL USER IN, V3, P79, DOI 10.1007/s12193-009-0021-9
   Raskin V., 1985, SEMANTIC MECH HUMOR
   Roach M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0184130
   Rothwell J.D., 2010, CO OTHERS INTRO COMM, V3rd
   Russell JA, 2009, COGNITION EMOTION, V23, P1259, DOI 10.1080/02699930902809375
   Scardigno R., 2020, World Futures, V76, P81, DOI [10.1080/02604027.2019.1703158, DOI 10.1080/02604027.2019.1703158]
   Shifman L, 2014, J VIS CULT, V13, P340, DOI 10.1177/1470412914546577
   Skakni I, 2019, HIGH EDUC RES DEV, V38, P1489, DOI 10.1080/07294360.2019.1657806
   Stock O, 2002, P 20 TWENT WORKSH LA
   Taecharungroj V, 2015, J CREAT COMMUN, V10, P288, DOI 10.1177/0973258615614420
   Turkle S, 2005, SECOND SELF: COMPUTERS AND THE HUMAN SPIRIT, TWENTIETH ANNIVERSARY EDITION, P1
   van Leeuwen T., 2000, Handbook o f Visual Analysis, P92
   Veatch TC, 1998, HUMOR, V11, P161, DOI 10.1515/humr.1998.11.2.161
   Wiggins BE, 2016, INT J COMMUN-US, V10, P451
   Yus Ramos Francisco, 1996, Pragmalinguistica, V3, P497
NR 64
TC 6
Z9 6
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35973
EP 35994
DI 10.1007/s11042-020-09166-0
EA JUL 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000552190000008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kukreja, S
   Kasana, G
   Kasana, SS
AF Kukreja, Sonal
   Kasana, Geeta
   Kasana, Singara Singh
TI Curvelet transform based robust copyright protection scheme for color
   images using extended visual cryptography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copyright protection; Curvelet transform; k-means clustering; Extended
   visual cryptography; Henon map; Normalized correlation; PSNR
ID WATERMARKING SCHEME
AB A copyright protection scheme based on curvelet transform,k-means clustering and extended visual cryptography is proposed for color images. Unlike the existing schemes, the proposed scheme creates meaningful shares to provide better security and handles false positive cases efficiently. Curvelet Transform is applied onYcomponent of host image to generate six-scale layers. Out of these layers, non fine scale layers are selected to generate the master share, which is further processed by Henon map to enhance its security. Two watermarks are used in the proposed scheme. One of them is provided by the user and other one is constructed by usingC(b)andC(r)components of the host image. Second watermark is used to to handle false positives. Meaningful ownership share is constructed from the master share, both watermarks and cover image by using extended visual secret sharing. Master share is overlapped with its corresponding ownership share to reveal the watermark which is further used to prove the ownership. Experimental results show that the proposed scheme clearly verifies the copyright of the digital images, is robust to withstand several image processing attacks and handles false positive cases efficiently. Comparison with the existing copyright protection schemes shows that the proposed scheme gives better performance.
C1 [Kukreja, Sonal; Kasana, Geeta; Kasana, Singara Singh] Thapar Institue Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kukreja, S (corresponding author), Thapar Institue Engn & Technol, Comp Sci & Engn Dept, Patiala 147004, Punjab, India.
EM kukreja.sonal@gmail.com; gkasana@thapar.edu; singara@thapar.edu
RI Kukreja, Dr. Sonal/HLQ-2114-2023
CR Abraham J, 2019, J KING SAUD UNIV-COM, V31, P125, DOI 10.1016/j.jksuci.2016.12.004
   Agarwal S, 2018, INT J ENG TECHNOL IN, V8, P77
   Al-Otum HM, 2020, J VIS COMMUN IMAGE R, V66, DOI 10.1016/j.jvcir.2019.102726
   ATENIESE G, 1996, THEORETICAL COMPUTER, V250, P1
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Chen TH, 2009, COMPUT STAND INTER, V31, P1, DOI 10.1016/j.csi.2007.09.001
   Devi BP, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-2733-0
   Fares K, 2020, OPTIK, V208, DOI 10.1016/j.ijleo.2020.164562
   Fatahbeygi A, 2019, J INF SECUR APPL, V45, P71, DOI 10.1016/j.jisa.2019.01.005
   HENON M, 1976, COMMUN MATH PHYS, V50, P69, DOI 10.1007/BF01608556
   Hou YC, 2000, 2000 5TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS I-III, P992, DOI 10.1109/ICOSP.2000.891692
   Hou YC, 2016, TURK J ELECTR ENG CO, V24, P4063, DOI 10.3906/elk-1405-180
   Hsieh S-L, 2005, P WORLD ACAD SCI ENG, V10
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Hwang R.-J, 2000, TAMKANG J SCI ENG, V3, P97
   Lou DC, 2007, COMPUT STAND INTER, V29, P125, DOI 10.1016/j.csi.2006.02.003
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rawat S, 2012, AEU-INT J ELECTRON C, V66, P955, DOI 10.1016/j.aeue.2012.04.004
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Shao ZH, 2016, SIGNAL PROCESS-IMAGE, V48, P12, DOI 10.1016/j.image.2016.09.001
   Wang MS, 2007, OPT ENG, V46, DOI 10.1117/1.2746906
   Xia ZQ, 2019, SIGNAL PROCESS, V157, P108, DOI 10.1016/j.sigpro.2018.11.011
   Xue M, 2019, SECURITY COMMUNICATI
NR 24
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 26155
EP 26179
DI 10.1007/s11042-020-09130-y
EA JUL 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000547355800002
DA 2024-07-18
ER

PT J
AU Li, Y
   Mei, FJ
AF Li, Ying
   Mei, Fangjun
TI Deep learning-based method coupled with small sample learning for
   solving partial differential equations
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Partial differential equations; Neural network; Numerical solution;
   Small sample learning
ID NEURAL-NETWORKS; NUMERICAL-SOLUTION; ALGORITHM
AB Partial differential equations (PDEs) are existing widely in the field of mathematics, physics and engineering. They are often used to describe natural phenomena and model dynamical systems, but how to solve the equations efficiently is still a hard task. In this paper, we develop a deep learning-based general numerical method coupled with small sample learning (SSL) for solving PDEs. To be more specific, we approximate the solution via a deep feedforward neural network, which is trained to satisfy the PDEs with the initial and boundary conditions. Then the proposed method is modeled to solve an optimization problem by minimizing a designed cost function, which involves the residual of the differential equations, the initial/boundary conditions and the residual of a handful of observations. With a few of sample data, the model can be rectified effectively and the predictive accuracy can be improved. The effectiveness of the proposed method is demonstrated by a wide range of benchmark problems in mathematical physics, including the classical Burgers equations, Schrodinger equations, Buckley-Leverett equation, Navier-Stokes equation, and Carburizing diffusion equations, which are applied in carburizing diffusion problems in material science. And the results validate that the proposed algorithm is effective, flexible and robust without relying on trial solutions.
C1 [Li, Ying; Mei, Fangjun] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
C3 Shanghai University
RP Li, Y (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
EM yinglotus@t.shu.edu.cn
CR Berg J, 2018, NEUROCOMPUTING, V317, P28, DOI 10.1016/j.neucom.2018.06.056
   Berkani MS, 2013, IEEE T MAGN, V49, P2149, DOI 10.1109/TMAG.2013.2245871
   E WN, 2017, COMMUN MATH STAT, V5, P349, DOI 10.1007/s40304-017-0117-6
   Eymard R, 2000, HDBK NUM AN, V7, P713
   Fang ZZ, 2016, INT GEOSCI REMOTE SE, P2610, DOI 10.1109/IGARSS.2016.7729674
   Han J, 2018, P NATL ACAD SCI USA, V115, P8505, DOI 10.1073/pnas.1718942115
   Kitchin R, 2015, GEOJOURNAL, V80, P463, DOI 10.1007/s10708-014-9601-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lagaris IE, 1998, IEEE T NEURAL NETWOR, V9, P987, DOI 10.1109/72.712178
   Lagaris IE, 2000, IEEE T NEURAL NETWOR, V11, P1041, DOI 10.1109/72.870037
   Lake BM, 2015, SCIENCE, V350, P1332, DOI 10.1126/science.aab3050
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Meng XH, 2020, J COMPUT PHYS, V401, DOI 10.1016/j.jcp.2019.109020
   Nabian MA, 2019, PROBABILIST ENG MECH, V57, P14, DOI 10.1016/j.probengmech.2019.05.001
   Ouyang WL, 2016, PROC CVPR IEEE, P864, DOI 10.1109/CVPR.2016.100
   Owhadi H, 2015, ELECTRON J STAT, V9, P1, DOI 10.1214/15-EJS989
   Platte RB, 2010, MATH INDUST, V15, P69, DOI 10.1007/978-3-642-12110-4_5
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Raissi M, 2018, SIAM J SCI COMPUT, V40, pA172, DOI 10.1137/17M1120762
   Raissi M, 2018, J COMPUT PHYS, V357, P125, DOI 10.1016/j.jcp.2017.11.039
   Raissi M, 2017, J COMPUT PHYS, V348, P683, DOI 10.1016/j.jcp.2017.07.050
   Raissi M, 2017, J COMPUT PHYS, V335, P736, DOI 10.1016/j.jcp.2017.01.060
   Rudy SH, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1602614
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Shirvany Y, 2009, APPL SOFT COMPUT, V9, P20, DOI 10.1016/j.asoc.2008.02.003
   Shirvany Y, 2008, COMMUN NONLINEAR SCI, V13, P2132, DOI 10.1016/j.cnsns.2007.04.024
   Sirignano J, 2018, J COMPUT PHYS, V375, P1339, DOI 10.1016/j.jcp.2018.08.029
   Squires TM, 2010, ANNU REV FLUID MECH, V42, P413, DOI 10.1146/annurev-fluid-121108-145608
   STEIN M, 1987, TECHNOMETRICS, V29, P143, DOI 10.2307/1269769
   Sun ZJ, 2019, ENG ANAL BOUND ELEM, V104, P1, DOI 10.1016/j.enganabound.2019.03.014
   Tatari M, 2010, ENG ANAL BOUND ELEM, V34, P206, DOI 10.1016/j.enganabound.2009.09.003
   Taylor CA, 1998, COMPUT METHOD APPL M, V158, P155, DOI 10.1016/S0045-7825(98)80008-X
   Valan M, 2019, SYST BIOL, V68, P876, DOI 10.1093/sysbio/syz014
   Wang R, 2018, IEEE-ACM T AUDIO SPE, V26, P1727, DOI 10.1109/TASLP.2018.2837223
   Weinan E, 2018, COMMUN MATH STAT, V6, P1, DOI 10.1007/s40304-018-0127-z
   Williams CKI, 1998, IEEE T PATTERN ANAL, V20, P1342, DOI 10.1109/34.735807
   Yang XJ, 2019, APPL MATH COMPUT, V358, P394, DOI 10.1016/j.amc.2019.04.023
   Zhang Y, 2009, APPL MATH COMPUT, V215, P524, DOI 10.1016/j.amc.2009.05.018
   Zhu FY, 2019, NEUROCOMPUTING, V328, P182, DOI 10.1016/j.neucom.2018.02.099
NR 40
TC 18
Z9 20
U1 1
U2 57
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 17391
EP 17413
DI 10.1007/s11042-020-09142-8
EA JUL 2020
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000546532400002
DA 2024-07-18
ER

PT J
AU Zhou, ZP
   Zhang, R
   Yin, D
AF Zhou, Zhipeng
   Zhang, Rui
   Yin, Dong
TI A strong feature representation for siamese network tracker
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Siamese network; Feature representation; mPSR
AB Because AlexNet is too shallow to form a strong feature representation, the trackers based on the Siamese network have an accuracy gap comparing with state-of-the-art algorithms. Both deep features and appearance features benefit tracking accuracy. To combine these two kinds features, the modified pre-trained VGG16 network is fine-tuned as one branch of the backbone network. Secondly, an AlexNet branch is attached after the third convolutional layer of VGG16. Thus the response maps from both branches are merged to form a preliminary strong feature representation with deep features and shallow appearance features. Thirdly, a new mean Peak-to-side ratio(mPSR) loss is designed to help network learn target features adaptively. A channel attention block and the Average-Peak-to-Correlation Energy(APCE) are designed to help select contributed features and suppress distractors. SiamPF only takes ILSVRC2015-VID as training dataset, but it achieves excellent performance on OTB-2013 / OTB-2015 / VOT2015 / VOT2016 / VOT2017 while maintaining the real-time performance of 41FPS on the GTX 1080Ti.
C1 [Zhou, Zhipeng; Zhang, Rui; Yin, Dong] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.
   [Zhou, Zhipeng; Zhang, Rui; Yin, Dong] Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences
RP Yin, D (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Anhui, Peoples R China.; Yin, D (corresponding author), Chinese Acad Sci, Key Lab Electromagnet Space Informat, Hefei 230027, Anhui, Peoples R China.
EM yindong@ustc.edu.cn
OI Zhou, Zhipeng/0000-0002-1564-5800
FU National Natural Science Foundation of China (NSFC) [61671423, 61271403]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) under Grant No. 61671423 and Grant No. 61271403.
CR [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, CVPR
   [Anonymous], 2017, CVPR
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen K, 2018, IEEE T IMAGE PROCESS, V27, P3611, DOI 10.1109/TIP.2018.2819362
   Danelljan M., 2017, P IEEE C COMP VIS PA, P6638
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dong X, 2019, IEEE T PATTERN ANAL
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Fan H., 2017, P IEEE C COMP VIS PA, P42
   Gundogdu E, 2018, IEEE T IMAGE PROCESS, V27, P2526, DOI 10.1109/TIP.2018.2806280
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hua Y, 2015, IEEE I CONF COMP VIS, P3092, DOI 10.1109/ICCV.2015.354
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li Y., 2019, INT C NEUR INF PROC
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang Z, 2019, IEEE T IMAGE PROCESS
   Lukezic A., 2017, PROC IEEE C COMPUT V, P6309
   Shen J., 2019, IEEE T CYBERNETICS
   Shen JB, 2019, IEEE T CYBERNETICS, V49, P1990, DOI 10.1109/TCYB.2018.2803217
   Valmadre J., 2017, P IEEE C COMP VIS PA, P2805
   Wang N, 2015, ICML, P1107
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
NR 39
TC 1
Z9 1
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 35-36
BP 25873
EP 25887
DI 10.1007/s11042-020-09164-2
EA JUL 2020
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0IW
UT WOS:000546222400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Saha, T
   Gupta, D
   Saha, S
   Bhattacharyya, P
AF Saha, Tulika
   Gupta, Dhawal
   Saha, Sriparna
   Bhattacharyya, Pushpak
TI A hierarchical approach for efficient multi-intent dialogue policy
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-intent; Dialogue management; Hierarchical; Deep reinforcement
   learning (DRL)
AB This paper proposes a hierarchical method for learning an efficient Dialogue Management (DM) strategy for task-oriented conversations serving multiple intents of a domain. Deep Reinforcement Learning (DRL) networks specializing in individual intents communicate with each other, having the capability of sharing overlapping information across intents. The sharing of information across state space and the presence of global slot tracker prohibits the agent to reask known information. Thus, the system is able to handle sub-dialogues based on subset of intents covered by different Reinforcement Learning (RL) models, thereby, completing the dialogue without again asking already provided information common across intents. The developed system has been demonstrated for "Air Travel" domain. The experimental results indicate that the developed system is efficient, scalable and can serve multiple intents based dialogues adequately. The proposed system when applied to 5-intent dialogue systems attains an improvement of 41% in terms of dialogue length as compared to a single-intent based system serving the same 5-intents.
C1 [Saha, Tulika; Gupta, Dhawal; Saha, Sriparna; Bhattacharyya, Pushpak] Indian Inst Technol Patna, Patna, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Patna
RP Saha, S (corresponding author), Indian Inst Technol Patna, Patna, Bihar, India.
EM sahatulika15@gmail.com; dhawal.gupta.iitp@gmail.com;
   sriparna.saha@gmail.com
RI Saha, Tulika/AAA-6724-2022
OI Saha, Tulika/0000-0002-3252-0997
FU Visvesvaraya Ph.D. Scheme for Electronics and IT, Ministry of
   Electronics and Information Technology (MeitY), Government of India
FX Dr. Sriparna Saha gratefully acknowledges the Young Faculty Research
   Fellowship (YFRF) Award, supported by Visvesvaraya Ph.D. Scheme for
   Electronics and IT, Ministry of Electronics and Information Technology
   (MeitY), Government of India, being implemented by Digital India
   Corporation (formerly Media Lab Asia) for carrying out this research.
CR [Anonymous], 2016, Learning end-to-end goal-oriented dialog
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2016, SIGDIAL, DOI DOI 10.1109/QRS-C.2016.5
   [Anonymous], 1998, REINFORCEMENT LEARNI
   Arulkumaran K, 2017, IEEE SIGNAL PROC MAG, V34, P26, DOI 10.1109/MSP.2017.2743240
   Budzianowski P, 2017, 18TH ANNUAL MEETING OF THE SPECIAL INTEREST GROUP ON DISCOURSE AND DIALOGUE (SIGDIAL 2017), P86
   Casanueva Inigo, 2018, NAACL HLT 2018 2018, V2, P714, DOI DOI 10.18653/V1/N18-2112
   Cuayahuitl H, 2016, NIPS WORKSH DEEP REI
   Cuayahuitl H., 2017, Dialogues with Social Robots, P109
   Cuayahuitl H., 2015, ARXIV151108099
   Fazel-Zarandi M., 2017, NIPS WORKSH CONV AI
   Fraser N., 1998, HDB STANDARDS RESOUR, P564
   Ilievski V, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4115
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Keizer Simon., 2017, P SOFTW DEM 15 C EUR, V2, P480
   Levin E, 1998, INT CONF ACOUST SPEE, P201, DOI 10.1109/ICASSP.1998.674402
   Li X., 2017, P 8 INT JOINT C NAT, V1, P733
   Lipton Z, 2018, AAAI CONF ARTIF INTE, P5237
   McTear MF, 2002, ACM COMPUT SURV, V34, P90, DOI 10.1145/505282.505285
   McTear Michael F., 1998, 5 INT C SPOK LANG PR
   Meng TL, 2019, DATA, V4, DOI 10.3390/data4030110
   Mnih V, 2013, ARXIV
   Peng Baolin, 2017, P 2017 C EMP METH NA, P2231
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Price P. J., 1990, SPEECH NATURAL LANGU, P91
   Saha Tulika, 2018, Neural Information Processing. 25th International Conference, ICONIP 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11303), P359, DOI 10.1007/978-3-030-04182-3_32
   Schaul T., 2015, Prioritized experience replay
   Serban IV, 2016, AAAI CONF ARTIF INTE, P3776
   Tang D, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P2298
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   Wen David, 2016, ARXIV160404562
   Xu PY, 2013, INTERSPEECH, P3752
   Yu S., 2017, DEEP REINFORCEMENT L
NR 33
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2021
VL 80
IS 28-29
BP 35025
EP 35050
DI 10.1007/s11042-020-09070-7
EA JUL 2020
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA XF6FU
UT WOS:000545796600004
DA 2024-07-18
ER

PT J
AU Krobba, A
   Debyeche, M
   Selouani, SA
AF Krobba, Ahmed
   Debyeche, Mohamed
   Selouani, Sid-Ahmed
TI Mixture linear prediction Gammatone Cepstral features for robust speaker
   verification under transmission channel noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Automatic speaker verification; Mixture linear prediction; Gammatone
   Frequency Cepstral Coefficients (GFCCs); I-vector GPLDA; Transmission
   channel noise
ID AUDITORY FILTER SHAPES; RECOGNITION; PERFORMANCE
AB In this paper, we present a Mixture Linear Prediction based approach for robust Gammatone Cepstral Coefficients extraction (MLPGCCs). The proposed method provides performance improvement of Automatic Speaker Verification (ASV) using i-vector and Gaussian Probabilistic Linear Discriminant Analysis GPLDA modeling under transmission channel noise. The performance of the extracted MLPGCCs was evaluated using the NIST 2008 database where a single channel microphone recorded conversational speech. The system is analyzed in the presence of different channel transmission noises such as Additive White Gaussian (AWGN) and Rayleigh fading at various Signals to Noise Ratio (SNR) levels. The evaluation results show that the MLPGCCs features are a promising way for the ASV task. Indeed, the speaker verification performance using the MLPGCCs proposed features is significantly improved compared to the conventional Gammatone Frequency Cepstral Coefficients (GFCCs) and Mel Frequency Cepstral Coefficients (MFCCs) features. For speech signals corrupted with AWGN noise at SNRs ranging from (-5 dB to 15 dB), we obtain a significant reduction of the Equal Error Rate (EER) ranging from 9.41% to 6.65% and 3.72% to 1.50%, compared with conventional MFCCs and GFCCs features respectively. In addition, when the test speech signals are corrupted with Rayleigh fading channel we achieve an EER reduction ranging from 23.63% to 7.8% and from 10.88% to 6.8% compared with conventional MFCCs and GFCCs, respectively. We also found that the combination of GFCCs and MLPGCCs gives the highest performance of speaker verification system. The best performance combination achieved is around EER from 0.43% to 0.59% and 1.92% to 3.88%.
C1 [Krobba, Ahmed; Debyeche, Mohamed] USTHB, LCPTS, Algiers, Algeria.
   [Selouani, Sid-Ahmed] Univ Moncton, LARIHS Lab, Campus Shappaing, Moncton, NB, Canada.
C3 University Science & Technology Houari Boumediene; University of Moncton
RP Krobba, A (corresponding author), USTHB, LCPTS, Algiers, Algeria.
EM akrobba@usthb.dz
CR Ajmera PK, 2012, INT J SPEECH TECHNOL, V15, P433, DOI 10.1007/s10772-012-9153-5
   Al-Momani O, 2014, INT J TELEMED APPL, P1
   [Anonymous], 2011, NIST SRE11 SPEAK REC
   [Anonymous], 2010, PROC 5 INT C DESIGN
   Apsingekar VR, 2011, SPEECH COMMUN, V53, P110, DOI 10.1016/j.specom.2010.07.001
   Daqrouq Khaled, 2013, WSEAS Transactions on Signal Processing, V9, P216
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Fedila M., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P1034, DOI 10.1109/ISSPA.2012.6310441
   Fedila M, 2017, MULTIMED TOOLS APPL, P1
   Fernandez Gallardo L., 2016, HUMAN AUTOMATIC SPEA
   GLASBERG BR, 1990, HEARING RES, V47, P103, DOI 10.1016/0378-5955(90)90170-T
   GLASBERG BR, 1986, J ACOUST SOC AM, V79, P1020, DOI 10.1121/1.393374
   Hansen JHL, 2015, IEEE SIGNAL PROC MAG, V32, P74, DOI 10.1109/MSP.2015.2462851
   Jeevan M, 2017, LECT NOTES ELECTR EN, V395, P85, DOI 10.1007/978-81-322-3592-7_9
   Johannesma P., 1972, The pre-response stimulus ensemble of neurons in the cochlear nucleusJ, P58
   Kanagasundaram A, 2018, INT J SPEECH TECHNOL, V21, P533, DOI 10.1007/s10772-018-9513-x
   Kenny P, 2013, INT CONF ACOUST SPEE, P7649, DOI 10.1109/ICASSP.2013.6639151
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Krobba A, 2018, 4 INT C SIGN IM VIS
   Li XY, 2017, LECT NOTES COMPUT SC, V10193, P146, DOI 10.1007/978-3-319-56608-5_12
   Li ZQ, 2016, MULTIMED TOOLS APPL, V75, P7391, DOI 10.1007/s11042-015-2660-z
   Man-Wai Mak, 2016, IEEE/ACM Transactions on Audio, Speech and Language Processing, V24, P130, DOI 10.1109/TASLP.2015.2499038
   Ming J, 2007, IEEE T AUDIO SPEECH, V15, P1711, DOI 10.1109/TASL.2007.899278
   NIST Year, 2008, SPEAK REC EV PLAN
   Padilla M, 2006, CSLP 9 INT C SPOK LA
   Pahlavan Kaveh., 2011, Principles of wireless networks: A unified approach
   Pelecanos J., 2001, Proc. Speaker Odyssey, V13, P1
   Pohjalainen Jouni, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6285, DOI 10.1109/ICASSP.2014.6854813
   Pohjalainen J, 2010, P INTERSPEECH
   Pohjalainen J, 2014, IEEE SIGNAL PROC LET, V21, P1516, DOI 10.1109/LSP.2014.2339632
   Prince SJD, 2007, IEEE I CONF COMP VIS, P1751
   Rahman MH, 2018, COMPUT SPEECH LANG, V47, P240, DOI 10.1016/j.csl.2017.08.001
   Rao W, 2013, IEEE T AUDIO SPEECH, V21, P1012, DOI 10.1109/TASL.2013.2243436
   Ravindran Sourabh., 2006, STAT PERCEPTUAL AUDI, P48
   Recommendation G, 2003, 722 2 WIDEBAND CODIN
   Riadh A, 2014, INT J COMMUN, V9, P114
   Saeidi R, 2010, IEEE SIGNAL PROC LET, V17, P599, DOI 10.1109/LSP.2010.2048649
   Seyed OS, 2013, P IEEE SIGN PROC SPE
   Sreenivasa RK, 2014, SPEECH PROCESSING MO
   Zhang Y, 2017, INT J SPEECH TECHNOL, V20, P753, DOI 10.1007/s10772-017-9447-8
   Zhao XJ, 2013, INT CONF ACOUST SPEE, P7204, DOI 10.1109/ICASSP.2013.6639061
   Zhao XJ, 2012, IEEE T AUDIO SPEECH, V20, P1608, DOI 10.1109/TASL.2012.2186803
NR 42
TC 4
Z9 4
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 18679
EP 18693
DI 10.1007/s11042-020-08748-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800063
DA 2024-07-18
ER

PT J
AU Xiao, S
   Li, TX
   Wang, JW
AF Xiao, Shuo
   Li, Tianxu
   Wang, Jiawei
TI Optimization methods of video images processing for mobile object
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vedio image processing; Mobile object recognition; Convolutional neural
   network; Adaptive genetic algorithm
ID NEURAL-NETWORK
AB Recognition of moving objects in video images is mainly based on acquiring the target information in a certain time series. After image processing, relevant algorithms are used to get the internal features and effectively identify the target object. However, image background, noise, definition and other factors will have impacts on mobile object recognition. Therefore, the mobile objects in video images are more complicated than the static objects in the fixed images. The traditional convolutional neural network (CNN) uses gradient descent algorithm for learning and training, and uses gradient descent algorithm to determine the initial thresholds, weights, which may cause the training to fall into a local optimal state. Therefore, this paper proposes an improved adaptive genetic algorithm combined with CNN. The thresholds and weights of CNN can be optimized by using adaptive genetic algorithm (AGA), which can overcome the shortcomings of the original genetic algorithm such as slow convergence. Experimental results shows that the recognition accuracy rate of the experiment increased from 83.75% to 92%, the method can effectively improve the accuracy and efficiency of mobile object recognition.
C1 [Xiao, Shuo; Li, Tianxu; Wang, Jiawei] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Xiao, S (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Jiangsu, Peoples R China.
EM sxiao@cumt.edu.cn
RI Wang, Jiawei/ABD-2573-2021
OI Wang, Jiawei/0000-0003-2627-4897
CR [Anonymous], 2015, INT J MODERN TRENDS
   Cao YQ, 2015, INT J COMPUT VISION, V113, P54, DOI 10.1007/s11263-014-0788-3
   Cao Y, 2019, CLUSTER COMPUT, V22, P14135, DOI 10.1007/s10586-018-2258-0
   Cao Y, 2019, CHAOS, V29, DOI 10.1063/1.5085397
   Cao Y, 2018, FUTURE GENER COMP SY, V88, P279, DOI 10.1016/j.future.2018.05.038
   Ghamisi P, 2016, IEEE GEOSCI REMOTE S, V13, P1537, DOI 10.1109/LGRS.2016.2595108
   Ijjina EP, 2016, PATTERN RECOGN, V59, P199, DOI 10.1016/j.patcog.2016.01.012
   Kim JS, 2011, IEEE T CONSUM ELECTR, V57, P1165, DOI 10.1109/TCE.2011.6018870
   Li P, 2017, IEEE T SMART GRID, V8, P2871, DOI 10.1109/TSG.2016.2611595
   Muralitharan K, 2018, NEUROCOMPUTING, V273, P199, DOI 10.1016/j.neucom.2017.08.017
   Qi TQ, 2017, NEUROCOMPUTING, V267, P475, DOI 10.1016/j.neucom.2017.06.041
   Rikhtegar A, 2016, IET COMPUT VIS, V10, P559, DOI 10.1049/iet-cvi.2015.0037
   SRINIVAS M, 1994, IEEE T SYST MAN CYB, V24, P656, DOI 10.1109/21.286385
   Teng Xiuhua, 2014, Applied Mechanics and Materials, V541-542, P2678, DOI 10.4028/www.scientific.net/AMM.543-547.2678
   Unal Muhammet, 2010, 2010 IEEE 18th Signal Processing and Communications Applications Conference (SIU 2010), P471, DOI 10.1109/SIU.2010.5653917
   Waris MA, 2017, NEUROCOMPUTING, V266, P631, DOI 10.1016/j.neucom.2017.05.071
   Wu H, 2017, OPTIK, V150, P76, DOI 10.1016/j.ijleo.2017.09.071
   Xie GS, 2017, PATTERN RECOGN, V71, P118, DOI 10.1016/j.patcog.2017.06.002
   Xu Y, 2018, SIGNAL PROCESS-IMAGE, V60, P131, DOI 10.1016/j.image.2017.09.013
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Zhang YZ, 2018, CHINESE J ELECTRON, V27, P439, DOI 10.1049/cje.2017.10.009
NR 21
TC 4
Z9 4
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17245
EP 17255
DI 10.1007/s11042-019-7423-9
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000587677800001
DA 2024-07-18
ER

PT J
AU Wang, DW
AF Wang, Dengwei
TI Local reverse entropy weighted LBF model solving by Split Bregman for
   image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Local binary fitting; Level set; Local reverse entropy; Split Bregman;
   Segmentation
ID ACTIVE CONTOURS; DRIVEN
AB In this paper, an efficient level set model is proposed for image segmentation. Firstly, the original local binary fitting (LBF) model is redefined as a weighted energy integral, whose weight coefficient is the fast local reverse entropy of the image, and the total energy functional is then incorporated into a variational level set formulation. Secondly, the global convex segmentation method is used to construct a simplified convex segmentation model, at the same time, the edge information obtained by an edge indicator function is embedded into the total variation norm to further enhance the model's target capture capability. Thirdly, the Split Bregman method is introduced to solve the generated convex optimization problem. Experimental results on synthetic and real images demonstrate that the proposed model has considerable improvements in terms of quantitative evaluation (being verified on the complete PASCAL VOC 2012 dataset), convergence rate, sensitivity to initial contour and robustness to noise interference compared with the state-of-the-art models. We also compare the proposed model with the famous FCN and Mask R-CNN, and make a special analysis on the adaptability of our method to occluded targets.
C1 [Wang, Dengwei] Univ Elect Sci & Technol China, Sch Aeronaut & Astronaut, Chengdu 611731, Peoples R China.
   [Wang, Dengwei] Aircraft Swarm Intelligent Sensing & Cooperat Con, Chengdu 611731, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Wang, DW (corresponding author), Univ Elect Sci & Technol China, Sch Aeronaut & Astronaut, Chengdu 611731, Peoples R China.; Wang, DW (corresponding author), Aircraft Swarm Intelligent Sensing & Cooperat Con, Chengdu 611731, Peoples R China.
EM wdengwei@126.com
FU Fundamental Research Funds for the Central Universities of China
   [ZYGX2018J079]; China Scholarship Council (CSC) [201706075068]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities of China under Grant No. ZYGX2018J079. The authors
   gratefully acknowledge the financial support from China Scholarship
   Council (CSC) under Grant No. 201706075068. The authors would like to
   thank the anonymous reviewers for their valuable comments and advices.
CR Abdelsamea MM, 2017, SOFT COMPUT, V21, P2047, DOI 10.1007/s00500-015-1906-z
   [Anonymous], 2007, P IEEE COMP SOC C CO
   Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI [10.1016/0041-5553(67)90040-7, DOI 10.1016/0041-5553(67)90040-7]
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Deng H, 2013, IET COMPUT VIS, V7, P405, DOI 10.1049/iet-cvi.2012.0240
   Fang JX, 2019, IEEE ACCESS, V7, P97492, DOI 10.1109/ACCESS.2019.2929659
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Guo Q, 2018, NEUROCOMPUTING, V275, P2307, DOI 10.1016/j.neucom.2017.11.003
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Li Q, 2016, SIGNAL PROCESS, V120, P185, DOI 10.1016/j.sigpro.2015.08.020
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Vovk U, 2007, IEEE T MED IMAGING, V26, P405, DOI 10.1109/TMI.2006.891486
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zheng Q, 2013, COMPUT BIOL MED, V43, P459, DOI 10.1016/j.compbiomed.2013.01.002
   Zhi XH, 2018, PATTERN RECOGN, V80, P241, DOI 10.1016/j.patcog.2018.03.010
   Zhu SP, 2016, BIOMED SIGNAL PROCES, V26, P1, DOI 10.1016/j.bspc.2015.12.004
NR 21
TC 0
Z9 0
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2020
VL 79
IS 33-34
BP 23669
EP 23693
DI 10.1007/s11042-020-09094-z
EA JUN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NI0JZ
UT WOS:000539889900001
DA 2024-07-18
ER

PT J
AU Li, D
   Song, DY
   Liu, S
   Ji, JW
   Zeng, K
   Hu, YS
   Ling, HF
AF Li, Dan
   Song, Danya
   Liu, Shuang
   Ji, Junwen
   Zeng, Kang
   Hu, Yingsong
   Ling, Hefei
TI Camera pose estimation based on global structure from motion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Global structure from motion; Weighted total least squares; Rotation
   averaging; 3D reconstruction
AB In this paper, a new global camera pose estimation algorithm WTLS-IRLS is proposed, which can effectively solve the global rotation when there are outliers. Firstly, according to the relationship between the rotation vector and the rotation matrix, we simplify the product operation of the rotation matrix into the subtraction operation of the rotation vector, which reduces the complexity of the algorithm. Secondly, the weighted total least squares (WTLS) and the iteratively reweighted least squares (IRLS) are used to average relative rotations. As the initialization of IRLS, WTLS provides a good initial guess by correcting the linearization equation and adding weight information to the relative rotations. IRLS continues to add weight information to the relative rotation matrices to optimize the global rotations. We demonstrate the performance of our approach by a number of large-scale data sets, the results show that our method has been greatly improved in efficiency, accuracy and iteration. In order to verify the correctness of our proposed method, we completed the complete reconstruction process, the experimental results show that our proposed WTLS-IRLS rotation averaging algorithm can obtain dense point clouds with more three-dimensional points.
C1 [Li, Dan; Song, Danya; Liu, Shuang; Ji, Junwen; Zeng, Kang; Hu, Yingsong; Ling, Hefei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Liu, S (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM m201873109@hust.edu.cn
OI Liu, Shuang/0000-0003-4901-6639
FU National Natural Science Foundation of China [61502185, U1536203];
   Fundamental Research Funds for the Central Universities [2017KFYXJJ071]
FX This work is supported by National Natural Science Foundation of China
   (No. 61502185 and U1536203) and the Fundamental Research Funds for the
   Central Universities (No: 2017KFYXJJ071).
CR Aftab K, 2015, IEEE T PATTERN ANAL, V37, P728, DOI 10.1109/TPAMI.2014.2353625
   [Anonymous], 2010, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2010.5539801
   Arrigoni F., 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P491, DOI 10.1109/3DV.2014.48
   Cao MW, 2017, MULTIMED TOOLS APPL, V76, P21843, DOI 10.1007/s11042-017-4581-5
   Changchang Wu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3057, DOI 10.1109/CVPR.2011.5995552
   Chatterjee A, 2018, IEEE T PATTERN ANAL, V40, P958, DOI 10.1109/TPAMI.2017.2693984
   Chatterjee A, 2013, IEEE I CONF COMP VIS, P521, DOI 10.1109/ICCV.2013.70
   Crandall D., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3001, DOI 10.1109/CVPR.2011.5995626
   Cui HN, 2016, INT C PATT RECOG, P3727, DOI 10.1109/ICPR.2016.7900214
   Cui ZP, 2015, IEEE I CONF COMP VIS, P864, DOI 10.1109/ICCV.2015.105
   DAPENG C, 2017, MULTIMED TOOLS APPL, V77, P10651
   Furukawa Y, 2010, PROC CVPR IEEE, P1434, DOI 10.1109/CVPR.2010.5539802
   Govindu VM, 2006, LECT NOTES COMPUT SC, V3852, P457
   Govindu VM, 2004, PROC CVPR IEEE, P684
   Govindu VM, 2001, PROC CVPR IEEE, P218
   Hartley R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3041, DOI 10.1109/CVPR.2011.5995745
   Huang XR, 2019, PROC CVPR IEEE, P8074, DOI 10.1109/CVPR.2019.00827
   Ke FK, 2014, INT C INTEL HUM MACH, P309, DOI 10.1109/IHMSC.2014.176
   Li HD, 2006, INT C PATT RECOG, P630
   Long GC, 2015, PROC CVPR IEEE, P1247, DOI 10.1109/CVPR.2015.7298729
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Roberts R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3137, DOI 10.1109/CVPR.2011.5995549
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Toldo R, 2015, COMPUT VIS IMAGE UND, V140, P127, DOI 10.1016/j.cviu.2015.05.011
   Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3
   Tron R, 2008, 2008 SECOND ACM/IEEE INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS, P245
   Tron R, 2011, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2011.5995654
   Wang X, 2019, ISPRS J PHOTOGRAMM, V147, P19, DOI 10.1016/j.isprsjprs.2018.11.009
   Wilson K, 2014, LECT NOTES COMPUT SC, V8691, P61, DOI 10.1007/978-3-319-10578-9_5
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
NR 30
TC 1
Z9 1
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 23223
EP 23242
DI 10.1007/s11042-020-09045-8
EA JUN 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000538382000001
DA 2024-07-18
ER

PT J
AU Nuguri, SS
   Calyam, P
   Oruche, R
   Gulhane, A
   Valluripally, S
   Stichter, J
   He, Z
AF Nuguri, Sai Shreya
   Calyam, Prasad
   Oruche, Roland
   Gulhane, Aniket
   Valluripally, Samaikya
   Stichter, Janine
   He, Zhihai
TI vSocial: a cloud-based system for social virtual reality learning
   environment applications in special education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent network services; Social virtual reality; Learning
   environments; Special education; Web applications
ID ADOLESCENTS; ADULTS
AB Virtual Learning Environments (VLEs) are spaces designed to educate student groups remotely via online platforms. Although traditional VLEs have shown promise in educating students, they offer limited immersion that overall diminishes learning effectiveness. In this paper, we describe vSocial, a cloud-based virtual reality learning environment (VRLE) system that can be deployed over high-speed networks using the High Fidelity "social VR" platform. vSocial provides flexible control of group learning content and compliance with established VLE standards with improved immersive user experience for both instructor(s) and students. For our vSocial development, we build upon the use case of an existing special education VLE viz., iSocial that trains youth with Autism Spectrum Disorder by implementing the Social Competence Intervention (SCI) curriculum. The vSocial can be used to: (a) implement multiple learning modules using wearable VR technologies, (b) integrate cognitive state sensing devices, and (c) organize learning session data securely using web applications hosted on cloud resources. Our experiment results show that the VR mode of content delivery in vSocial better stimulates the generalization of lessons to the real world than non-VR lessons, and provides improved immersion when compared to an equivalent desktop version. Further, usability study results show that users can successfully use the web application features in vSocial for group learning activities with ease-of-use and consistency.
C1 [Nuguri, Sai Shreya; Valluripally, Samaikya; He, Zhihai] Univ Missouri, Columbia, MO USA.
   [Calyam, Prasad] Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
   [Oruche, Roland; Gulhane, Aniket] Univ Missouri, Comp Sci, Columbia, MO USA.
   [Stichter, Janine] Univ Missouri, Dept Special Educ, Columbia, MO USA.
C3 University of Missouri System; University of Missouri Columbia;
   University of Missouri System; University of Missouri Columbia;
   University of Missouri System; University of Missouri Columbia;
   University of Missouri System; University of Missouri Columbia
RP Calyam, P (corresponding author), Univ Missouri, Dept Comp Sci, Columbia, MO 65211 USA.
EM calyamp@missouri.edu
OI Nuguri, Sai Shreya/0009-0008-8723-100X
FU National Science Foundation [CNS-1647213, CNS-1659134]
FX This material is based upon work supported by the National Science
   Foundation under Award Numbers: CNS-1647213 and CNS-1659134. Any
   opinions, findings, and conclusions or recommendations expressed in this
   publication are those of the authors and do not necessarily reflect the
   views of the National Science Foundation.
CR Abulrub A. G., 2011, 2011 IEEE Global Engineering Education Conference (EDUCON), P751, DOI 10.1109/EDUCON.2011.5773223
   Allcoat D, 2018, RES LEARN TECHNOL, V26, DOI 10.25304/rlt.v26.2140
   ASD Society, 2019, WHAT IS ASD
   Austin R, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON COMPLEX, INTELLIGENT, AND SOFTWARE INTENSIVE SYSTEMS (CISIS), P523, DOI 10.1109/CISIS.2013.95
   Bangor A, 2008, INT J HUM-COMPUT INT, V24, P574, DOI 10.1080/10447310802205776
   Bekele E, 2013, IEEE T VIS COMPUT GR, V19, P711, DOI 10.1109/TVCG.2013.42
   Bekele ET, 2013, IEEE T NEUR SYS REH, V21, P289, DOI 10.1109/TNSRE.2012.2230188
   Bellani M, 2011, EPIDEMIOL PSYCH SCI, V20, P235, DOI 10.1017/S2045796011000448
   Berman M, 2014, COMPUT NETW, V61, P5, DOI 10.1016/j.bjp.2013.12.037
   Casey P, 2019, IEEE T DEPENDABLE SE
   Dennison MS, 2016, DISPLAYS, V44, P42, DOI 10.1016/j.displa.2016.07.002
   Didehbani N, 2016, COMPUT HUM BEHAV, V62, P703, DOI 10.1016/j.chb.2016.04.033
   Docker, 2019, BUILD SHIP RUN AN AP
   Emotiv Insight, 2019, BRAINW MON COGN HLTH
   Fan J, 2015, IEEE ENG MED BIO, P3767, DOI 10.1109/EMBC.2015.7319213
   Fazlay R, 2018, P ACM INT MOB WEAR U, V2
   Gillott A, 2007, J INTELLECT DISABILI, V11, P359, DOI 10.1177/1744629507083585
   Gulhane A, 2018, P IEEE CONS COMM NET
   Halabi O., 2017, International Journal of Interactive Mobile Technologies, V11, P146, DOI 10.3991/ijim.v11i2.6555
   High Fidelity, 2019, SOC VR PLATF
   HumHub, 2019, FLEX OP SOURC SOC NE
   Jie Hu, 2012, 2012 International Conference on Audio, Language and Image Processing (ICALIP 2012). Proceedings, P1167, DOI 10.1109/ICALIP.2012.6376794
   Jih-Wei W, 2014, IEEE INT C INT THING
   Kandalaft MR, 2013, J AUTISM DEV DISORD, V43, P34, DOI 10.1007/s10803-012-1544-6
   Laszka A, 2018, P IEEE ICII
   Maskey M, 2019, J AUTISM DEV DISORD, V49, P1912, DOI 10.1007/s10803-018-3861-x
   Mennecke BE, 2011, DECISION SCI, V42, P413, DOI 10.1111/j.1540-5915.2011.00317.x
   Mourning R, 2016, P IEEE INT C SYST MA, V1, P848
   Muse, 2019, BRAIN SENS HEADB REA
   NetLimiter, 2019, INT TRAFF CONTR MON
   Oculus Rift, 2019, VIRT REAL SYST IMM V
   Osso VR, 2019, OSSO VR USES VIRTUAL
   Pan ZG, 2006, COMPUT GRAPH-UK, V30, P20, DOI 10.1016/j.cag.2005.10.004
   Pioggia G, 2005, IEEE T NEUR SYS REH, V13, P507, DOI 10.1109/TNSRE.2005.856076
   Prendinger H, 2013, IEEE INTERNET COMPUT, V17, P30, DOI 10.1109/MIC.2013.87
   Schmidt M, 2012, COMPUT HUM BEHAV, V28, P405, DOI 10.1016/j.chb.2011.10.011
   Stichter JP, 2014, J AUTISM DEV DISORD, V44, P417, DOI 10.1007/s10803-013-1881-0
   Taylor L., 2011, CURRENT ISSUES ED, V14
   Vaccari A, 2015, VIRTUAL REALITY MEET
   Valluripally S, 2020, CONSUM COMM NETWORK
   Vive, 2019, DISC VIRT REAL IM
   Wang MT, 2010, AM EDUC RES J, V47, P633, DOI 10.3102/0002831209361209
   You D, 2018, IEEE ACCESS, P6
   Zizza C., 2018, P 2018 15 IEEE ANN C, P1
NR 44
TC 9
Z9 9
U1 3
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16827
EP 16856
DI 10.1007/s11042-020-09051-w
EA JUN 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000537042100002
DA 2024-07-18
ER

PT J
AU Diwakar, M
   Kumar, P
   Singh, AK
AF Diwakar, Manoj
   Kumar, Pardeep
   Singh, Amit Kumar
TI CT image denoising using NLM and its method noise thresholding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Wavelet transform; Thresholding; Method noise;
   Aggregation
ID PEDIATRIC CT; REDUCTION; QUALITY; SPARSE
AB Computed Tomography (CT) is one of the major tools to identify diagnose in medical science. The quality of CT images is dependent of X-ray amount. If X-ray dose is higher, the quality of CT image is better but it may generate bed impact to the patients. Low dose CT images are noisy due to some major reasons such as statistical uncertainty in all physical measurements. If noise can be reduced or removed from low dose CT images, then quality of low dose CT images can be improved without increasing dose. Hence in this paper, a method is proposed in which Non-local means (NLM) filter and wavelet packet based thresholding are processed. For better edge preservation and noise reduction, method noise concept is used. The results of proposed method is analyzed and also compared with some existing methods. From comparative result analysis, it was observed that performance of the proposed scheme is superior to the existing methods in terms of visual quality, Image Quality Index (IQI), PSNR and Entropy Difference (ED).
C1 [Diwakar, Manoj] DIT Univ Dehradun, Dept Comp Sci & Engn, Mussoorie, Uttarakhand, India.
   [Kumar, Pardeep] Jaypee Univ Informat Technol, Dept CSE & IT, Solan, Himachal Prades, India.
   [Singh, Amit Kumar] NIT Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 DIT University; Jaypee University of Information Technology; National
   Institute of Technology (NIT System); National Institute of Technology
   Patna
RP Kumar, P (corresponding author), Jaypee Univ Informat Technol, Dept CSE & IT, Solan, Himachal Prades, India.
EM manoj.diwakar@gmail.com; pardeepkumarkhokhar@gmail.com;
   amit_245singh@yahoo.com
RI Diwakar, Manoj/AAS-2520-2021
OI Diwakar, Manoj/0000-0002-4435-675X
CR Ali SH, 2011, ADV EXP MED BIOL, V696, P471, DOI 10.1007/978-1-4419-7046-6_47
   [Anonymous], 2015, COMPUTATIONAL MATH M
   Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Boone JM, 2003, RADIOLOGY, V228, P352, DOI 10.1148/radiol.2282020471
   Borsdorf A, 2008, IEEE T MED IMAGING, V27, P1685, DOI 10.1109/TMI.2008.923983
   Borsdorf A, 2008, INT J COMPUT ASS RAD, V2, P255, DOI [10.1007/s11548-007-0139-8, 10.1007/s11548-007-0139-]
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Diwakar M, 2018, IET IMAGE PROCESS, V12, P708, DOI 10.1049/iet-ipr.2017.0639
   Diwakar M, 2018, BIOMED SIGNAL PROCES, V42, P73, DOI 10.1016/j.bspc.2018.01.010
   Dong WS, 2011, PROC CVPR IEEE, P457, DOI 10.1109/CVPR.2011.5995478
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Goldstein T, 2009, SIAM J IMAGING SCI, V2, P323, DOI 10.1137/080725891
   Gopalan B, 2015, IEEE SIGNAL PROC LET, V22, P1698, DOI 10.1109/LSP.2015.2426432
   Huda W, 2000, RADIOLOGY, V217, P430, DOI 10.1148/radiology.217.2.r00nv35430
   Jain P, 2015, VISUAL COMPUT, V31, P657, DOI 10.1007/s00371-014-0993-7
   Ke L, 2010, INT CONF BIOMED, P428, DOI 10.1109/BMEI.2010.5639560
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Li Yunhong, 2013, J INFORM COMPUTATION, V10, P2711, DOI DOI 10.12733/jics20101845
   Li ZB, 2014, MED PHYS, V41, DOI 10.1118/1.4851635
   Lu H, 2018, FUTURE GENERATION CO
   Lu HM, 2018, MOBILE NETW APPL, V23, P368, DOI 10.1007/s11036-017-0932-8
   Lu HM, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.3927
   Lu L, 2015, IEEE SIGNAL PROC LET, V22, P833, DOI 10.1109/LSP.2014.2371332
   Mustafa Z. A., 2011, 2011 1st Middle East Conference on Biomedical Engineering (MECBME), P180, DOI 10.1109/MECBME.2011.5752095
   Rabbani H, 2009, IEEE T BIO-MED ENG, V56, P2826, DOI 10.1109/TBME.2009.2028876
   Rabbani H, 2009, PATTERN RECOGN, V42, P2181, DOI 10.1016/j.patcog.2009.01.005
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Serikawa S, 2014, COMPUT ELECTR ENG, V40, P41, DOI 10.1016/j.compeleceng.2013.10.016
   Sharma A, 2018, J INTELL SYST, V27, P91, DOI 10.1515/jisys-2017-0032
   Shen Y, 2017, IEEE SIGNAL PROC LET, V24, P877, DOI 10.1109/LSP.2017.2688707
   Shi Wenxuan, 2010, Wuhan University Journal of Natural Sciences, V15, P148, DOI 10.1007/s11859-010-0212-y
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1211, DOI 10.1007/s11760-012-0389-y
   Siegel MJ, 2004, RADIOLOGY, V233, P515, DOI 10.1148/radiol.2332032107
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wu H, 2011, J MED BIOL ENG, V31, P437, DOI 10.5405/jmbe.866
   Xu TG, 2017, IEEE INT INTERC TECH
   Zear Aditi, 2017, International Journal of Information and Computer Security, V9, P20
   Zheng X, 2013, COMP MATH MATH PHYS, P2013
   Zhu F, 2012, PHYS MED BIOL, V57, pN183, DOI 10.1088/0031-9155/57/12/N183
NR 43
TC 34
Z9 35
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 21-22
BP 14449
EP 14464
DI 10.1007/s11042-018-6897-1
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LV8HQ
UT WOS:000538675900008
DA 2024-07-18
ER

PT J
AU Liu, TT
   Xiao, MY
AF Liu Tingting
   Xiao Mengyu
TI Analysis and evaluation on the quality of news text machine translation
   based on neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Neural network; Text machine; Translation quality; Analysis and
   evaluation
AB Machine translation quality estimation is an important task in natural language processing. Unlike traditional automatic machine translation evaluation methods, the quality of machine translation is evaluated by the translation quality estimation method without using manual reference translation. In view of the fact that the feature extraction of current sentence-level machine translation quality estimation relies heavily on linguistic analysis, which leads to insufficient generalization ability and restricts the performance of subsequent support vector regression algorithm, it is proposed to extract the features of sentence vectors by using contextual word prediction model and matrix decomposition model in deep learning, and combine them with the features of recurrent neural network language model to improve the correlation between automatic estimation of translation quality and manual evaluation. The experimental results on WMT15 and WMT16 translation quality estimation subtask data sets show that the performance statistics of the method of extracting sentence vector features by adopting context word prediction model are consistently superior to that of the traditional Quest method and continuous space language model sentence vector feature extraction method. It reveals that the proposed feature extraction method not only requires no linguistic analysis, but also significantly improves the effect of translation quality estimation.
C1 [Liu Tingting] Fuyang Normal Univ, Coll Foreign Languages, Fuyang, Peoples R China.
   [Xiao Mengyu] Fuyang Normal Univ, Coll Informat & Engn, Fuyang, Peoples R China.
C3 Fuyang Normal University; Fuyang Normal University
RP Liu, TT (corresponding author), Fuyang Normal Univ, Coll Foreign Languages, Fuyang, Peoples R China.
EM ltxiao154@163.com
RI liu, liu/JEO-6900-2023; liu, ting/GZM-3326-2022
CR Abdulhay E, 2020, NEURAL COMPUT APPL, V32, P10947, DOI 10.1007/s00521-018-3738-0
   Acharya UR, 2019, FUTURE GENER COMP SY, V91, P290, DOI 10.1016/j.future.2018.08.044
   [Anonymous], 2008, P C EMP METH NAT LAN
   Arunkumar N, 2019, SOFT COMPUT, V23, P9083, DOI 10.1007/s00500-018-3618-7
   Arunkumar N, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.4962
   Bagyalakshmi G, 2018, IEEE ACCESS, V6, P57144, DOI 10.1109/ACCESS.2018.2872775
   Baker K, 2012, COMPUT LINGUIST, V38, P411, DOI 10.1162/COLI_a_00099
   [曹冬林 Cao Donglin], 2004, [计算机应用研究, Application Research of Computers], V21, P29
   El-Haj M, 2015, LANG RESOUR EVAL, V49, P549, DOI 10.1007/s10579-014-9274-3
   Elamaran V, 2018, IEEE ACCESS, V6, P62874, DOI 10.1109/ACCESS.2018.2876119
   Elamaran V, 2018, IEEE ACCESS, V6, P59672, DOI 10.1109/ACCESS.2018.2870557
   Elhoseny M, 2020, NEURAL COMPUT APPL, V32, P10979, DOI 10.1007/s00521-018-3801-x
   Jiao DD, 2019, FUTURE GENER COMP SY, V92, P324, DOI 10.1016/j.future.2018.10.019
   Kell DB, 2006, FEBS J, V273, P873, DOI 10.1111/j.1742-4658.2006.05136.x
   Khamparia A, 2020, NEURAL COMPUT APPL, V32, P11083, DOI 10.1007/s00521-018-3896-0
   Lakshmanaprabu SK, 2019, FUTURE GENER COMP SY, V92, P374, DOI 10.1016/j.future.2018.10.009
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Li HM, 2004, PROCEEDINGS OF THE 2004 CHINA-JAPAN JOINT MEETING ON MICROWAVES, P605
   Liu JJ, 2018, IEEE ACCESS, V6, P61457, DOI 10.1109/ACCESS.2018.2876135
   Mohammed MA, 2020, J SUPERCOMPUT, V76, P1086, DOI 10.1007/s11227-018-2587-z
   Oh SL, 2020, NEURAL COMPUT APPL, V32, P10927, DOI 10.1007/s00521-018-3689-5
   Peixoto SA, 2020, NEURAL COMPUT APPL, V32, P10935, DOI 10.1007/s00521-018-3736-2
   Pereira RF, 2020, J SUPERCOMPUT, V76, P1212, DOI 10.1007/s11227-018-2579-z
   Popovic M, 2014, LANG RESOUR EVAL, V48, P541, DOI 10.1007/s10579-014-9286-z
   Santamaria-Granados L, 2019, IEEE ACCESS, V7, P57, DOI 10.1109/ACCESS.2018.2883213
   Sathishkumar BR, 2020, NEURAL COMPUT APPL, V32, P11097, DOI 10.1007/s00521-018-3919-x
   Venkatraman V, 2018, INT J HEAVY VEH SYST, V25, P344, DOI 10.1504/IJHVS.2018.094829
   Wu ZC, 2019, FUTURE GENER COMP SY, V93, P170, DOI 10.1016/j.future.2018.10.018
   Zhang WN, 2016, IEEE T KNOWL DATA EN, V28, P888, DOI 10.1109/TKDE.2015.2502944
   Zhou DM, 2018, J POWER SOURCES, V399, P314, DOI 10.1016/j.jpowsour.2018.06.098
   Zhou DM, 2017, ENERG CONVERS MANAGE, V151, P778, DOI 10.1016/j.enconman.2017.08.079
NR 31
TC 2
Z9 2
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2020
VL 79
IS 23-24
BP 17015
EP 17026
DI 10.1007/s11042-019-7532-5
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ME6DR
UT WOS:000544744600067
DA 2024-07-18
ER

PT J
AU Ullah, S
   Li, XY
   Lan, Z
AF Ullah, Shamsher
   Li, Xiang-Yang
   Lan, Zhang
TI A novel trusted third party based signcryption scheme
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Signcryption; Cloud computing; Session key; Session key
   exchange protocol; Secret key
ID ENCRYPTION SCHEME; EFFICIENT; SECURITY
AB To prevent man-in-the-middle attack, Diffie-Hellman first proposed the concept of the session key exchange protocol, in which the author remove the long term keying material at the end of the session. In our scheme, we apply the session key concept of Diffie-Hellman for cloud computing in the presence of the Trusted Third Party (TTP). Our proposed scheme provides SEVEN security properties by using the session key exchange protocols as symmetric. In our scheme, TTP becomes free from a burden of activities, like to encrypt the requests (R-i) of the Cloud Service Users (CSUs) and to decrypt the services (S-i) of the Cloud Service Providers (CSPs) again and again. By using S Performance (EP) for Elliptic Curve Point Multiplication (ECPM), Hash (H), Inversion (Inv), Exclusive oR (XoR), Encryption (Enc), and Decryption (Dec) is (87.5%, 62.5%, 57.14%), (87.5% and 75%), (75%), (97.82% and <= 1%), (92.85%) and (50%) respectively. The security requirements of our scheme are; data integrity, data confidentiality, authenticity, non-repudiation, forward secrecy, unforgeability, and untraceability. Our proposed scheme also outperformed performance in terms of flexibility, reliability, and efficiency as compared to existing schemes.
C1 [Ullah, Shamsher; Li, Xiang-Yang; Lan, Zhang] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS
RP Ullah, S (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230026, Anhui, Peoples R China.
EM shamsher@mail.ustc.edu.cn; xiangyang.li@gmail.com; zhanglan@ustc.edu.cn
RI LI, Xiang-Yang/JZE-0275-2024; Ullah, Shamsher/GXN-2692-2022; Han,
   Liang/KFR-6745-2024; zhang, han/I-8297-2015
OI Ullah, Shamsher/0000-0002-8726-3123; zhang, han/0000-0002-0166-1973;
   Ullah, Shamsher/0009-0003-6399-8461
FU National Key R & D Program of China [2018YFB0803400]; China National
   Funds for Distinguished Young Scientists [61625205]; China National
   Natural Science Foundation [61751211, 61520106007]; Key Research Program
   of Frontier Sciences, CAS [QYZDY-SSW-JSC002]
FX The research is partially supported by National Key R & D Program of
   China 2018YFB0803400, China National Funds for Distinguished Young
   Scientists with No. 61625205, China National Natural Science Foundation
   with No. 61751211, No. 61520106007, Key Research Program of Frontier
   Sciences, CAS. No. QYZDY-SSW-JSC002. Helpful discussion with Muhammad
   Wasif Sardar (Assistant Professor) is appreciated. The authors also
   thankful to anonymous reviewers for their valuable comments.
CR Abd El-Latif AA, 2018, IEEE ACCESS, V6, P21075, DOI 10.1109/ACCESS.2018.2820603
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P10332, DOI 10.1109/ACCESS.2018.2799879
   Abd El-Latif AA, 2018, IEEE ACCESS, V6, P1073, DOI 10.1109/ACCESS.2017.2777869
   Abd El-Latif AA, 2014, MULTIMED TOOLS APPL, V70, P1559, DOI 10.1007/s11042-012-1173-2
   Abd El-Latif AA, 2013, OPT LASER TECHNOL, V54, P389, DOI 10.1016/j.optlastec.2013.04.018
   Abd El-Latif AA, 2013, SIGNAL PROCESS, V93, P2986, DOI 10.1016/j.sigpro.2013.03.031
   Al-Afandy KA, 2018, MULTIMED TOOLS APPL, V77, P25709, DOI 10.1007/s11042-018-5814-y
   Amin M, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3360179
   [Anonymous], 1991, Proceedings of Advances in Cryptology
   Baek J, 2007, J CRYPTOL, V20, P203, DOI 10.1007/s00145-007-0211-0
   Bassem Abd-El-Atty, 2017, QUANTUM COMPUTING EN, P3
   Belazi A, 2017, OPTIK, V130, P1438, DOI 10.1016/j.ijleo.2016.11.152
   Belazi A, 2017, NONLINEAR DYNAM, V87, P337, DOI 10.1007/s11071-016-3046-0
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Belazi A, 2015, INT WIREL COMMUN, P606, DOI 10.1109/IWCMC.2015.7289152
   Benrhouma O, 2013, IMAGE VIDEO PROCESS, V9, P1281, DOI DOI 10.1007/S11760-013-0570-Y
   Chandana Gamage, 1999, INT WORKSH PUBL KEY, P69
   Chang CC, 2003, 2003 INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY, VOL 1 AND 2, PROCEEDINGS, P203
   DIFFIE W, 1976, IEEE T INFORM THEORY, V22, P644, DOI 10.1109/TIT.1976.1055638
   Dolev D, 1991, STOC 91
   El-Latif AAA, 2013, 5 INT C DIG IM PROC, V8878
   El-Shafai W, 2018, 3D RES, V9, DOI 10.1007/s13319-017-0153-8
   El-Shafai W, 2018, INT J COMMUN SYST, V31, DOI 10.1002/dac.3478
   El-Shafai W, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0131-1
   El-Shafai W, 2019, MULTIMED TOOLS APPL, P1
   El-Shafai W, 2018, MULTIMED TOOLS APPL, V77, P30911, DOI 10.1007/s11042-018-6036-z
   Faragallah OS, 2019, IEEE ACCESS, V7, P4184, DOI 10.1109/ACCESS.2018.2879857
   Feng Bao, 1998, INT WORKSH PUBL KEY, P55
   GOLDWASSER S, 1984, J COMPUT SYST SCI, V28, P270, DOI 10.1016/0022-0000(84)90070-9
   Han Y., 2004, P 3 INT C INF SEC SH, P216, DOI [10.1145/1046290.1046336, DOI 10.1145/1046290.1046336]
   Hea An Jee, 2002, INT C THEOR APPL CRY, P83
   Hellman Diffie, KEY EXCHANGE
   Hwang RJ, 2005, APPL MATH COMPUT, V167, P870, DOI 10.1016/j.amc.2004.06.124
   John Black, 2003, INT WORKSH SEL AR CR, P62
   Jung H. Y., 2001, PROC INFO SECU APPL, P403
   Kerby F, 2011, UNDERSTANDING ENCRYP
   Koblitz N, 2000, DESIGN CODE CRYPTOGR, V19, P173, DOI 10.1023/A:1008354106356
   Li WM, 2012, CHINA COMMUN, V9, P64
   Peng JL, 2017, INT CONF UBIQ FUTUR, P989
   Pitchay SA, 2015, UKSIM INT CONF COMP, P201, DOI 10.1109/UKSim.2015.74
   RIVEST RL, 1978, COMMUN ACM, V21, P120, DOI [10.1145/359340.359342, 10.1145/357980.358017]
   Rizvi S, 2014, PROCEDIA COMPUT SCI, V36, P381, DOI 10.1016/j.procs.2014.09.009
   Rohit Chadha, 2012, EUR S PROGR, P108
   Tiejun Zhang, 2014, Advanced Materials Research, V981, P327, DOI 10.4028/www.scientific.net/AMR.981.327
   Toorani M, 2009, IEEE SYMP COMP COMMU, P712
   Toorani M, 2008, INT C COMP ELEC ENG, P428, DOI 10.1109/ICCEE.2008.147
   Tsai KL, 2016, IEEE ACCESS, V4, P6261, DOI 10.1109/ACCESS.2016.2613442
   Zaghloul A, 2014, INT SOC OPT PHOTON, V9159, P915
   Zhang TJ, 2015, INT J SECUR APPL, V9, P217, DOI 10.14257/ijsia.2015.9.7.19
   Zheng YL, 1997, LECT NOTES COMPUT SC, V1294, P165
   Zheng YL, 1998, INFORM PROCESS LETT, V68, P227, DOI 10.1016/S0020-0190(98)00167-7
NR 51
TC 7
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22749
EP 22769
DI 10.1007/s11042-020-09027-w
EA MAY 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000554789500007
DA 2024-07-18
ER

PT J
AU Shoba, VBT
   Sam, IS
AF Shoba, V. Betcy Thanga
   Sam, I. Shatheesh
TI A Hybrid Features Extraction on Face for Efficient Face Recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; SURF features; MSER features; HOG features; Recognition
   rate; Holistic features and Local features
ID EIGENFACES; ROBUST
AB Image Processing is one of the vibrant research areas nowadays and particularly face recognition is given much importance in all the sectors. Accordingly this research paper proposes a hybrid Face Recognition System to find facial changes due to the aging factor in a robust manner. The highly qualified sharp features are extracted using the algorithms SURF(Speed Up Robust Features), HOG(Histogram of Oriented Gradient) and MSER(Maximally Stable Extremal Regions) to get better results. The proposed method divides the face into five regions. The whole face area is named Region1 can have a complete set of face features extracted using the SURF and it acts as a holistic feature. The Region 2, the nasal bridge features are extracted using the HOG. The Region 3 and Region 4 extract the features of the eyes of the face and the Region 5 extracts the features of the region around the nose and the mouth. The features of these regions are extracted using MSER. These different features from five regions are matched by point matching technique with the database of the target image. Experimental results are evaluated using the datasets such as Yale, FGNET and MORPH dataset. The experimental results show that the proposed face recognition algorithm is superior to traditional methods in terms of recognition rate and time complexity.
C1 [Shoba, V. Betcy Thanga; Sam, I. Shatheesh] ManonmaniamSundaranar Univ, Dept PG Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University
RP Shoba, VBT (corresponding author), ManonmaniamSundaranar Univ, Dept PG Comp Sci, Nesamony Mem Christian Coll, Tirunelveli 627012, Tamil Nadu, India.
EM shobarobertdec27@gmail.com; shatheeshsam@yahoo.com
RI Edwin, Shoba/HTP-4513-2023
OI Shoba.V, Betcy Thanga/0000-0002-5513-9929
CR Arashloo SR, 2011, IEEE T PATTERN ANAL, V33, P1274, DOI 10.1109/TPAMI.2010.209
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Binbin W, 2013, IISA 2013 4 INT C IN, P155, DOI [10.1109/IISA.2013.6623705, DOI 10.1109/IISA.2013.6623705]
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Choi SI, 2011, PATTERN RECOGN LETT, V32, P561, DOI 10.1016/j.patrec.2010.11.021
   Chowdhury S., 2010, 2010 IEEE INT C COMP, P519, DOI DOI 10.1109/ICCIC.2010.5705827
   Dadi H.S., 2016, IOSR J. Electron. Commun.Eng., V11, P34, DOI 10.9790/2834-1104013444
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Du G., 2009, Face recognition using SURF features
   Fan DP, 2019, IEEE I CONF COMP VIS, P5611, DOI 10.1109/ICCV.2019.00571
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Hu HL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Hussain SU, 2013, FACE RECOGNITION USI
   Image EF, 2015, HONGYA TUO, V1, P1498
   Khan SA, 2018, IEEE ACCESS, V6, P67459, DOI 10.1109/ACCESS.2018.2878601
   Khan SA, 2018, J COMPUT SCI-NETH, V28, P94, DOI 10.1016/j.jocs.2018.08.005
   Khan SA, 2015, J INTELL FUZZY SYST, V28, P1819, DOI 10.3233/IFS-141468
   Khan SA, 2014, J INTELL FUZZY SYST, V27, P3131, DOI 10.3233/IFS-141270
   Kimmel R, 2011, IEEE T PATTERN ANAL, V33, P2316, DOI 10.1109/TPAMI.2011.133
   Lee Y, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138859
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Li YT, 2020, IEEE INTERNET COMPUT, V24, P49, DOI 10.1109/MIC.2020.2971447
   Li YT, 2019, IEEE INTERNET THINGS, V6, P628, DOI 10.1109/JIOT.2018.2851185
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lu XK, 2021, IEEE T CIRC SYST VID, V31, P1268, DOI 10.1109/TCSVT.2019.2944654
   Mehta N, 2016, ACG CASE REP J, V3, DOI 10.14309/crj.2016.137
   Nie GY, 2019, PROC CVPR IEEE, P3278, DOI 10.1109/CVPR.2019.00340
   Ouyang AJ, 2020, NEUROCOMPUTING, V393, P214, DOI 10.1016/j.neucom.2019.01.117
   Pan J, 2016, IEEE ACCESS, V4, P2873, DOI 10.1109/ACCESS.2016.2574366
   Ricanek Jr K., 2006, P 7 INT C AUT FAC GE
   Schaeferling M., 2010, Proceedings 2010 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2010), P458, DOI 10.1109/ReConFig.2010.11
   Science C National S, 2005, SING LOB
   Tan X, 2011, RECOGNITION DIFFICUL
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang L, 2018, J VIS COMMUN IMAGE R, V53, P13, DOI 10.1016/j.jvcir.2018.02.004
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Yang J, 2017, IEEE T PATTERN ANAL, V39, P156, DOI 10.1109/TPAMI.2016.2535218
   Zhang P, 2012, DIGIT SIGNAL PROCESS, V22, P987, DOI 10.1016/j.dsp.2012.07.003
   Zhao Z, 2019, KNOWL-BASED SYST, V163, P533, DOI 10.1016/j.knosys.2018.09.014
   Zhou D, 2006, PATTERN RECOGN LETT, V27, P536, DOI 10.1016/j.patrec.2005.09.015
   Zhou D, 2004, LECT NOTES COMPUT SC, V3212, P692
   Zhu WJ, 2017, SIGNAL PROCESS-IMAGE, V55, P32, DOI 10.1016/j.image.2017.03.012
NR 45
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 31-32
BP 22595
EP 22616
DI 10.1007/s11042-020-08997-1
EA MAY 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA NB5OB
UT WOS:000553994700001
DA 2024-07-18
ER

PT J
AU Al-Zinati, M
   Alrashdan, R
   Al-Duwairi, B
   Alogaily, M
AF Al-Zinati, Mohammad
   Alrashdan, Reem
   Al-Duwairi, Basheer
   Alogaily, Moayad
TI A re-organizing biosurveillance framework based on fog and mobile edge
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mobile edge computing; Fog computing; Biosurveillance systems; Edge
   cloud data management
ID SYNDROMIC SURVEILLANCE; HEALTH; SYSTEM; BIOTERRORISM; SENSOR; TIME;
   NOTIFICATION; PREPAREDNESS; INTERNET; NETWORK
AB Biological threats are becoming a serious security issue for many countries across the world. Effective biosurveillance systems can primarily support appropriate responses to biological threats and consequently save human lives. Nevertheless, biosurveillance systems are costly to implement and hard to operate. Furthermore, they rely on static infrastructures that might not cope with the evolving dynamics of the monitored environment. In this paper, we present a reorganizing biosurveillance framework for the detection and localization of biological threats with fog and mobile edge computing support. In the proposed framework, a hierarchy of fog nodes are responsible for aggregating monitoring data within their regions and detecting potential threats. Although fog nodes are deployed on a fixed base station infrastructure, the framework provides an innovative technique for reorganizing the monitored environment structure to adapt to the evolving environmental conditions and to overcome the limitations of the static base station infrastructure. Evaluation results illustrate the ability of the framework to localize biological threats and detect infected areas. Moreover, the results show the effectiveness of the reorganization mechanisms in adjusting the environment structure to cope with the highly dynamic environment.
C1 [Al-Zinati, Mohammad; Alrashdan, Reem] Jordan Univ Sci & Technol, Dept Software Engn, Irbid 22110, Jordan.
   [Al-Duwairi, Basheer] Jordan Univ Sci & Technol, Dept Network Engn & Secur, Irbid 22110, Jordan.
   [Alogaily, Moayad] Al Ain Univ, Al Ain, U Arab Emirates.
C3 Jordan University of Science & Technology; Jordan University of Science
   & Technology
RP Al-Zinati, M (corresponding author), Jordan Univ Sci & Technol, Dept Software Engn, Irbid 22110, Jordan.
EM mhzinati@just.edu.jo; rmalrashdan15@cit.just.edu.jo;
   basheer@just.edu.jo; maloqaily@ieee.org
RI Aloqaily, Moayad/AAJ-2598-2020; Aloqaily, Moayad/AAV-9016-2021
OI Aloqaily, Moayad/0000-0003-2443-7234; Al-Zinati,
   Mohammad/0000-0003-2221-5515
CR Ahmad M, 2016, J SUPERCOMPUT, V72, P3677, DOI 10.1007/s11227-016-1634-x
   Ahmed E, 2017, IEEE COMMUN MAG, V55, P138, DOI 10.1109/MCOM.2017.1700120
   Ahmed E, 2017, FUTURE GENER COMP SY, V70, P59, DOI 10.1016/j.future.2016.09.015
   Al-Zinati M, 2013, IEEE ACM DIS SIM, P105, DOI 10.1109/DS-RT.2013.19
   Al-Zinati M, 2019, SIMUL MODEL PRACT TH, V93, P65, DOI 10.1016/j.simpat.2018.10.013
   Alabdulatif A, 2019, IEEE ACCESS, V7, P31010, DOI 10.1109/ACCESS.2019.2899323
   Althouse BM, 2015, EPJ DATA SCI, V4, DOI 10.1140/epjds/s13688-015-0054-0
   Ansaldi F, 2008, J Prev Med Hyg, V49, P131
   Backer HD, 2016, PUBLIC HLTH REPORTS
   Balasubramanian V, 2019, IEEE INT CON MULTI, P1684, DOI 10.1109/ICME.2019.00290
   Bandopadhaya S, 2020, SUSTAIN COMPUT-INFOR, V26, DOI 10.1016/j.suscom.2020.100378
   Betancourt JA, 2007, MIL MED, V172, P346, DOI 10.7205/MILMED.172.4.346
   Bhatia M, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0547-9
   Buehler JW, 2003, EMERG INFECT DIS, V9, P1197, DOI 10.3201/eid0910.030231
   Centers for Disease Control and Prevention, BIOSENSE
   Centers for Disease Control and Prevention (CDC), GLOB HLTH PROD SEC
   Clifton L, 2014, IEEE J BIOMED HEALTH, V18, P722, DOI 10.1109/JBHI.2013.2293059
   Flanagan Tatiana, 2019, EVOLUTION DEV COMPLE, P355
   Fricker Ronald D.  Jr., 2008, Quality Engineering, V20, P465, DOI 10.1080/08982110802334096
   Gardy JL, 2018, NAT REV GENET, V19, P9, DOI 10.1038/nrg.2017.88
   Giger JT, 2015, COMPUT HUM BEHAV, V44, P174, DOI 10.1016/j.chb.2014.11.044
   Heffernan R., 2004, SYNDROMIC SURVEILLAN, V53, P25
   Hoffman SJ, 2018, AM J PUBLIC HEALTH, V108, P329, DOI [10.2105/ajph.2017.304245, 10.2105/AJPH.2017.304245]
   Hossain MS, 2016, COMPUT NETW, V101, P192, DOI 10.1016/j.comnet.2016.01.009
   Hutwagner L, 2003, J URBAN HEALTH, V80, pI89
   Karwa Manoj, 2005, Crit Care Med, V33, pS75, DOI 10.1097/01.CCM.0000151070.56915.22
   Kman NE, 2012, ADV PREVENTIVE MED, V2012, P9
   Lomotey RK, 2017, PERVASIVE MOB COMPUT, V40, P692, DOI 10.1016/j.pmcj.2017.06.020
   Mahmud R, 2018, ICDCN'18: PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING AND NETWORKING, DOI 10.1145/3154273.3154347
   Nandyala C., 2016, Internation Journal of Smart Homes, V10, P187, DOI [DOI 10.14257/IJSH.2016.10.2.18, 10.14257/ijsh.2016.10.2.18]
   Negash B, 2018, Leveraging fog computing for healthcare IoT, Fog computing in the internet of things, P145
   Pinto Violet N, 2013, J Nat Sci Biol Med, V4, P24, DOI 10.4103/0976-9668.107256
   Plianbangchang S, 2005, ASIAN BIOTECHN DEV R, V8, P77
   Quwaider M, 2016, PERVASIVE MOB COMPUT, V28, P35, DOI 10.1016/j.pmcj.2015.07.012
   Quwaider M, 2015, SIMUL MODEL PRACT TH, V50, P57, DOI 10.1016/j.simpat.2014.06.015
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Ramanathan A, 2013, TECHNICAL REPORT
   Regan JF, 2008, ANAL CHEM, V80, P7422, DOI 10.1021/ac801125x
   Salahuddin MA, 2017, COMPUTER, V50, P74, DOI 10.1109/MC.2017.195
   Sandhu R, 2016, J SUPERCOMPUT, V72, P3033, DOI 10.1007/s11227-015-1474-0
   Sandhu R, 2016, J COMPUT SCI-NETH, V12, P11, DOI 10.1016/j.jocs.2015.11.001
   Sareen S, 2017, ENTERP INF SYST-UK, V11, P1436, DOI 10.1080/17517575.2016.1277558
   Sood SK, 2018, FUTURE GENER COMP SY, V88, P764, DOI 10.1016/j.future.2018.01.008
   Sood SK, 2018, IEEE INTERNET THINGS, V5, P794, DOI 10.1109/JIOT.2017.2768407
   Sood SK, 2017, COMPUT IND, V91, P33, DOI 10.1016/j.compind.2017.05.006
   Sood SK, 2020, J AMB INTEL SMART EN, V12, P5, DOI 10.3233/AIS-200547
   Tao CY, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1
   Tsui FC, 2003, J AM MED INFORM ASSN, V10, P399, DOI 10.1197/jamia.M1345
   Gia TN, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P356, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.51
   Uscher-Pines L, 2009, DISASTER MED PUBLIC, V3, pS29, DOI 10.1097/DMP.0b013e31819f4483
   Verma P, 2018, IEEE INTERNET THINGS, V5, P1789, DOI 10.1109/JIOT.2018.2803201
   Wagar EA, 2010, ARCH PATHOL LAB MED, V134, P1490, DOI 10.1043/2010-0098-CP.1
   Wang MH, 2018, J MED INTERNET RES, V20, DOI 10.2196/10886
   World Health Organization, 2020, WHO2019NCOVIPCPPEUSE
   Xu BY, 2014, IEEE T IND INFORM, V10, P1578, DOI 10.1109/TII.2014.2306382
   Yan SJ, 2017, INT J INFECT DIS, V63, P77, DOI 10.1016/j.ijid.2017.07.020
   Yang G, 2014, IEEE T IND INFORM, V10, P2180, DOI 10.1109/TII.2014.2307795
   Yang JC, 2015, SENSORS-BASEL, V15, P29535, DOI 10.3390/s151129535
   Yih W Katherine, 2004, MMWR Suppl, V53, P43
   Zelicoff A, 2001, J AM MED INFORM ASSN, P771
NR 60
TC 6
Z9 6
U1 1
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16805
EP 16825
DI 10.1007/s11042-020-09050-x
EA MAY 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000534982800001
PM 32837246
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU Cegovnik, T
   Stojmenova, K
   Tartalja, I
   Sodnik, J
AF Cegovnik, Tomaz
   Stojmenova, Kristina
   Tartalja, Igor
   Sodnik, Jaka
TI Evaluation of different interface designs for human-machine interaction
   in vehicles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interface design; Infotainment; Free hand; Touchpad; Vehicle; Driving
   safety; User experience; Usability
ID CONSTRUCTION; LOAD; CAR
AB In this paper we report on a user study in which we compared three different interaction designs in an in-vehicle infotainment system. Touchpad, free-hand and ordinary button interface designs were compared for usability, user experience and how they affect driving safety in different driving conditions. The study was performed in a high-fidelity driving simulator. Thirty participants were divided into two groups, one with less demanding and one with more demanding driving conditions, with the purpose of evaluating the interaction designs also in different driving environments. Each participant completed a set of tasks on each interface design and evaluated it with the User Experience Questionnaire. The conclusion from this study is that using a buttons-based input design on the steering wheel is the most efficient type of interaction compared to touchpad and free-hand input designs. On the other hand, we found that although newer input designs could be very attractive, their implementation into the vehicles infotainment system should be done wisely and carefully.
C1 [Cegovnik, Tomaz; Stojmenova, Kristina; Sodnik, Jaka] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
   [Tartalja, Igor] Univ Belgrade, Elect Engn Dept, Belgrade, Serbia.
C3 University of Ljubljana; University of Belgrade
RP Cegovnik, T (corresponding author), Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
EM tomaz.cegovnik@fe.uni-lj.si
RI Tartalja, Igor/ABB-6170-2020; Tartalja, Igor I/G-7060-2011
OI Cegovnik, Tomaz/0009-0004-1150-4308
FU Slovenian Research Agency [P2-0246, L2-8178]
FX This work has been supported by the Slovenian Research Agency within the
   research program ICT4QoL - Information and Communications Technologies
   for Quality of Life, grant number P2-0246, and the research project
   Neurophysiological and Cognitive Profiling of Driving Skills, grant
   number L2-8178. The authors thank Nervtech for providing the driving
   simulator software.
CR AVSimulation, 2019, AVSIMULATION INN SIM
   Bach KM, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1139
   Burnett G, 2011, BEHAV INFORM TECHNOL, V30, P403, DOI 10.1080/0144929X.2011.553743
   Cegovnik T, 2018, APPL ERGON, V68, P1, DOI 10.1016/j.apergo.2017.10.011
   Frokjaer E., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P345, DOI 10.1145/332040.332455
   Geiger M., 2001, P 9 INT C HUM COMP I, V1, P263
   Geiser G., 1985, ATZ, V87, P74
   Georgiou O, 2017, AUTOMOTIVEUI'17: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P233, DOI 10.1145/3131726.3132045
   Graichen L, 2019, HUM FACTORS, V61, P774, DOI 10.1177/0018720818824253
   Haeuslschmid R, 2017, IUI'17: PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P319, DOI 10.1145/3025171.3025198
   Harbluk J. L., 2002, 13889E TP
   Harrington K, 2018, AUTOMOTIVEUI'18: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P11, DOI 10.1145/3239060.3239089
   HESS EH, 1964, SCIENCE, V143, P1190, DOI 10.1126/science.143.3611.1190
   Jeong H, 2019, TRANSPORT RES F-TRAF, V60, P157, DOI 10.1016/j.trf.2018.10.015
   KAHNEMAN D, 1966, SCIENCE, V154, P1583, DOI 10.1126/science.154.3756.1583
   Kim J, 2015, ETRI J, V37, P793, DOI 10.4218/etrij.15.0114.0076
   Kun A. L, 2014, P 6 INT C AUT US INT, P1
   Lamble D, 1999, ACCIDENT ANAL PREV, V31, P617, DOI 10.1016/S0001-4575(99)00018-4
   Large DR, 2016, 8TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS (AUTOMOTIVEUI 2016), P161, DOI 10.1145/3003715.3005459
   Laugwitz B, 2008, LECT NOTES COMPUT SC, V5298, P63, DOI 10.1007/978-3-540-89350-9_6
   Loehmann S, 2011, P WORKSH US EXP CARS, P54
   Mahlke S., 2007, MMI-Interaktiv, V13
   May K.R., 2014, Adjunct Proceedings of the 6th International Conference on Automotive User Interfaces and Interactive Vehicular Applications, P1, DOI [10.1145/2667239.2667280, DOI 10.1145/2667239.2667280]
   Norberg S, 2009, 1 INT C DRIV DISTR I
   Pfleging B, 2014, INFORM SPEKTRUM, V37, P418, DOI [10.1007/s00287-014-0804-6, DOI 10.1007/S00287-014-0804-6]
   Riener A., 2011, P AUTOMOTIVEUI 11, P2
   Sabey B. E., 1980, SOC RISK ASSESSMENT, P43, DOI DOI 10.1007/978-1-4899-0445-4_3
   Schrepp M., 2014, Design, User Experience, and Usability. Theories, Methods, and Tools for Designing the User Experience, P383, DOI [DOI 10.1007/978-3-319-07668-3_37, 10.9781/ijimai.2017.445, DOI 10.9781/IJIMAI.2017.445, DOI 10.1007/978-3-319-07668-337]
   Schrepp M, 2017, INT J INTERACT MULTI, V4, P40, DOI 10.9781/ijimai.2017.445
   Trontelj K, 2017, ICIST 2017 P, V1, P299
   van Huysduynen HH, 2017, AUTOMOTIVEUI 2017: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON AUTOMOTIVE USER INTERFACES AND INTERACTIVE VEHICULAR APPLICATIONS, P293, DOI 10.1145/3122986.3122992
   Vetro A, 2011, IEEE MULTIMEDIA, V18, P98, DOI 10.1109/MMUL.2011.14
   Vilimek R, 2007, LECT NOTES ARTIF INT, V4562, P842
NR 33
TC 2
Z9 2
U1 9
U2 79
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21361
EP 21388
DI 10.1007/s11042-020-08920-8
EA MAY 2020
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000530602000001
DA 2024-07-18
ER

PT J
AU Kumar, K
   Mishra, RK
AF Kumar, Kaushal
   Mishra, Ritesh Kumar
TI A heuristic SVM based pedestrian detection approach employing shape and
   texture descriptors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Histogram of gradients; Non redundant uniform local
   binary pattern; Pedestrian detection; SVM
ID OBJECT DETECTION; PERFORMANCE; FRAMEWORK; SCALE
AB Pedestrian detection is a vital issue in various computer vision applications such as smart security system, driverless car, smart traffic management system and so forth. However, the issue of low detection accuracy and high computational complexity still makes a prompt topic of research. In the current scenario, Histogram of Oriented Gradients (HOG) with linear Support Vector Machine (SVM) is considered to be the most discriminative detector and has been adopted in various advance systems. In this paper, a novel method for pedestrian detection is proposed with the objective of improving the detection accuracy, precision and other metrics values. The proposed approach combines Histogram of Significant Gradients (HSG) and Non Redundant Uniform Local Binary Pattern (NRULBP) to generate a competent descriptor to be used in our detection model. The proposed approach is used in conjunction with various classifiers and the linear SVM classifier is found to provide better metric values over others. Different datasets like INRIA, TUD-brussels-motion pairs and ETH are utilized for performing experiments and to obtain detection results. Experimental results show that the proposed descriptor outperforms HSG by 2.59%, 8.97%, 8.5% and NRULBP by 3.19%, 39.55%, 19.66% in terms of detection accuracy, precision and F1 score respectively.
C1 [Kumar, Kaushal; Mishra, Ritesh Kumar] Natl Inst Technol, Dept Elect & Commun Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Kumar, K (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Patna, Bihar, India.
EM kaushal.ec16@nitp.ac.in; ritesh@nitp.ac.in
RI MISHRA, RITESH KUMAR/AAA-6689-2019
OI MISHRA, RITESH KUMAR/0000-0002-7996-2231; KUMAR,
   KAUSHAL/0000-0003-3306-3406
CR Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Bilal M, 2017, IEEE T CIRC SYST VID, V27, P2260, DOI 10.1109/TCSVT.2016.2581660
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhiman C, 2019, IEEE SENS J, V19, P5195, DOI 10.1109/JSEN.2019.2903645
   Nguyen DT, 2010, IEEE IMAGE PROC, P4609, DOI 10.1109/ICIP.2010.5651633
   ELMIKATY M, 2012, SENSOR SIGNAL PROCES, P1
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Ess A, 2009, IEEE INT CONF ROBOT, P4451
   Freeman W. T., 1995, IEEE INT WORKSH AUT
   Guangyuan Zhang, 2010, Proceedings 2010 Sixth International Conference on Natural Computation (ICNC 2010), P3257, DOI 10.1109/ICNC.2010.5582537
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Li DW, 2019, IEEE T IMAGE PROCESS, V28, P1575, DOI 10.1109/TIP.2018.2878349
   LIAO S, 2007, COMPUTER VISION ACCV
   Liu HH, 2013, IEEE T IND INFORM, V9, P1222, DOI 10.1109/TII.2013.2255616
   Liu W, 2015, IEEE T INTELL TRANSP, V16, P813, DOI 10.1109/TITS.2014.2342936
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oren Michael., 1997, PROC CVPR IEEE, P193, DOI DOI 10.1109/CVPR.1997.609319
   Porikli F, 2012, STUD COMPUT INTELL, V409, P3
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Vishwakarma DK, 2015, ADV ROBOTICS, V29, DOI 10.1080/01691864.2015.1061701
   Vishwakarma DK, 2015, PROCEDIA COMPUT SCI, V57, P438, DOI 10.1016/j.procs.2015.07.515
   Vishwakarma DK, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT (INDIACOM), P336
   Wang J, 2011, IEEE SYS MAN CYBERN, P2449, DOI 10.1109/ICSMC.2011.6084045
   Wang XG, 2014, IEEE T PATTERN ANAL, V36, P361, DOI 10.1109/TPAMI.2013.124
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wojek C, 2008, LECT NOTES COMPUT SC, V5096, P82, DOI 10.1007/978-3-540-69321-5_9
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Wu JX, 2013, IEEE T IMAGE PROCESS, V22, P4096, DOI 10.1109/TIP.2013.2270111
   Yao SH, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134242
   Yuan G, 2011, IEEE INTELL SYST, V26, P10, DOI 10.1109/MIS.2011.88
   Yuan X, 2011, 2011 IEEE STATISTICAL SIGNAL PROCESSING WORKSHOP (SSP), P1, DOI [10.1109/SSP.2011.5967658, 10.1109/FOI.2011.6154829]
   Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460
   Zhang S, 2015, IEEE SENS J, V15, P2679, DOI 10.1109/JSEN.2014.2382174
   Zhu C, 2015, IEEE T IMAGE PROCESS, V24, P5619, DOI 10.1109/TIP.2015.2483376
NR 37
TC 11
Z9 11
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21389
EP 21408
DI 10.1007/s11042-020-08864-z
EA MAY 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000531339200006
DA 2024-07-18
ER

PT J
AU Kang, S
   Park, H
   Park, JI
AF Kang, Sanghoon
   Park, Hanhoon
   Park, Jong-Il
TI Combining LSB embedding with modified Octa-PVD embedding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image steganography; Least significant bit (LSB); Pixel value difference
   (PVD); Data hiding; Multi-directional embedding; Content-adaptive
   embedding
ID STEGANOGRAPHIC METHOD; SUBSTITUTION; IMAGES
AB This paper proposes a new image steganographic method that effectively combines LSB embedding with Octa-PVD embedding. A cover image is divided into non-overlapping 3 x 3 sub-blocks, the n least significant bits of the center pixel of each sub-block is first substituted by secret data (n-LSB substitution). Then, the differences between the center pixel and its eight neighbors are calculated. For each direction, if the difference is equal or larger than a threshold (predefined by users or automatically determined by image analysis), secret data is embedded into the neighbor pixel by n-LSB substitution. Otherwise, secret data is embedded by PVD embedding, but into the neighbor pixel only. Consequently, depending on the conditions of each sub-block, a single embedding method can be used to the whole sub-block, or two embedding methods can be used alternately within a sub-block. Comparisons with existing LSB or multi-directional PVD embedding methods demonstrate that the proposed method has more optimized and higher embedding capacity and PSNR.
C1 [Kang, Sanghoon; Park, Hanhoon] Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
   [Park, Jong-Il] Hanyang Univ, Dept Comp Sci, Seoul, South Korea.
C3 Pukyong National University; Hanyang University
RP Park, H (corresponding author), Pukyong Natl Univ, Dept Elect Engn, Busan 48513, South Korea.
EM hanhoon_park@pknu.ac.kr
FU Signal Intelligence Research Center; National Research Foundation of
   Korea [22A20130012575, 22A20130012635] Funding Source: Korea Institute
   of Science & Technology Information (KISTI), National Science &
   Technology Information Service (NTIS)
FX This work was supported by the research fund of Signal Intelligence
   Research Center supervised by Defense Acquisition Program Administration
   and Agency for Defense Development of Korea.
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2019, MULTIMED TOOLS APPL, V78, P17799, DOI 10.1007/s11042-019-7166-7
   [Anonymous], P IEEE C COMP VIS PA
   Bin Li, 2018, IEEE Signal Processing Letters, V25, P650, DOI 10.1109/LSP.2018.2816569
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Darabkh KA, 2017, INF TECHNOL CONTROL, V46, P16, DOI 10.5755/j01.itc.46.1.15253
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Filler T, 2011, PROC SPIE, V7880, DOI 10.1117/12.872192
   Fridrich Jessica., 2006, MMSEC 06, P2
   Gao ZZ, 2019, J INTERNET TECHNOL, V20, P205, DOI 10.3966/160792642019012001019
   Holub V, 2012, P 4 IEEE INT WORKSH
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Karampidis K, 2018, J INF SECUR APPL, V40, P217, DOI 10.1016/j.jisa.2018.04.005
   Khodaei M, 2012, IET IMAGE PROCESS, V6, P677, DOI 10.1049/iet-ipr.2011.0059
   Ko-Chin Chang, 2008, Journal of Multimedia, V3, P37
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Modi MR, 2013, LECT NOTES COMPUT SC, V7995, P593, DOI 10.1007/978-3-642-39479-9_69
   Pevny T, 2010, LECT NOTES COMPUT SC, V6387, P161, DOI 10.1007/978-3-642-16435-4_13
   Pradhan A, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/1804953
   Sahu AK, 2019, SENS IMAGING, V21, DOI 10.1007/s11220-019-0262-y
   SWAIN G, 2014, INDIAN J SCI TECHNOL, V7, P1444
   Swain G, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/1505896
   Swain G, 2016, PROCEDIA COMPUT SCI, V85, P39, DOI 10.1016/j.procs.2016.05.174
   Tang WX, 2019, IEEE T INF FOREN SEC, V14, P2074, DOI 10.1109/TIFS.2019.2891237
   Thanekar S, 2013, P 2013 IEEE INT C CO
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xu GS, 2016, IEEE SIGNAL PROC LET, V23, P708, DOI 10.1109/LSP.2016.2548421
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
NR 31
TC 9
Z9 10
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 21155
EP 21175
DI 10.1007/s11042-020-08925-3
EA MAY 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000529768400001
DA 2024-07-18
ER

PT J
AU Yadav, KS
   Singha, J
AF Yadav, Kuldeep Singh
   Singha, Joyeeta
TI Facial expression recognition using modified Viola-John's algorithm and
   KNN classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-verbal communication; Social interaction; Hybrid approach; Viola -
   John's algorithm; HOG; LBP; SVM; KNN; Feature
AB In the way of communication, facial expression act as non-verbal communication and play an important role in social interaction by providing some contextual information. Facial expressions also express human's inner emotional state, which is very effective for communication with the actual emotions. In this paper, an algorithm has been proposed to detect the face and facial parts more accurate to the Viola - John's algorithm, and a fast-tracking algorithm for face tracking in real-time scenarios. The fusion of the facial features is used for feature extraction and comparative work on the several classifiers has been presented. In this approach, the images were acquired and seven significant facial parts from the image were cropped, then extract and store the features of several facial expressions. Finally, the expressions in the images were recognized using the classifiers. The algorithm was tested on four kinds of database and achieved accurate performance through the designed system.
C1 [Yadav, Kuldeep Singh] Natl Inst Technol, Dept ECE, Silchar, Assam, India.
   [Singha, Joyeeta] LNM Inst Informat & Technol, Dept ECE, Jaipur, Rajasthan, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar; LNM Institute of Information Technology
RP Yadav, KS (corresponding author), Natl Inst Technol, Dept ECE, Silchar, Assam, India.
EM kuldeeptheyadav@gmail.com; joyeeta.singha@lnmiit.ac.in
RI Yadav, Kuldeep Singh/JKJ-1356-2023
OI Yadav, Kuldeep Singh/0000-0002-9761-9023
CR Ahmed M, 2019, J ELECTRON IMAGING, V28, DOI 10.1117/1.JEI.28.3.033009
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], P INT C MULT INT
   [Anonymous], 2019, Computer Aided Design and Applications
   [Anonymous], 2011, P ACM WORKSH HUM GES
   Bartlett MS, 2003, P CVPR WORKSH COMP V, V5
   Buciu I, 2004, INT C PATT RECOG, P288, DOI 10.1109/ICPR.2004.1334109
   Chen J, 2014, INT WORKSHOPS ELECT, P884
   Chibelushi ClaudeC., 2003, CVONLINE ON LINE COM, V9
   Cristinacce D., 2004, BMVC, P231
   EKMAN P, 1969, SCIENCE, V164, P86, DOI 10.1126/science.164.3875.86
   Ekweariri AN, 2017, INT CONF COMPUT INTE, P43, DOI [10.1109/CICN.2017.8319353, 10.1109/CICN.2017.12]
   El Maghraby A, 2013, INT J COMPUT APPL, V71, P15
   Feng X., 2005, Pattern Recognition and Image Analysis, V15, P546
   Joho H, 2011, MULTIMED TOOLS APPL, V51, P505, DOI 10.1007/s11042-010-0632-x
   Kasim S., 2017, International Journal on Advanced Science, Engineering and Information Technology, V7, P1621, DOI 10.18517/ijaseit.7.5.3390
   Kotsia I, 2008, IMAGE VISION COMPUT, V26, P1052, DOI 10.1016/j.imavis.2007.11.004
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Marcolin F, 2017, MULTIMED TOOLS APPL, V77, P1
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Murthy G.R. S., 2009, INT J COMPUTER THEOR, V1, P638
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Punitha A, 2013, INT J COMPUT APPL
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Sarode N., 2010, Int. J. Comput. Sci. Eng, V2, P1552
   Sawardekara S, 2008, FACIAL EXPRESSION RE, V05
   Sobottka K, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P483, DOI 10.1109/ICIP.1996.560536
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vupputuri A, 2015, INT C COMM SIGN PROC, P0349
   Wang J, 2007, COMPUT VIS IMAGE UND, V108, P19, DOI 10.1016/j.cviu.2006.10.011
   Yadav KS, 2019, P 4 IEEE INT C INF S
   Yang S, 2015, IEEE I CONF COMP VIS, P3676, DOI 10.1109/ICCV.2015.419
   Yang X, 2017, P 2017 INT C ROB ART, P33
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
NR 40
TC 15
Z9 16
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13089
EP 13107
DI 10.1007/s11042-019-08443-x
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000534818700015
DA 2024-07-18
ER

PT J
AU He, ZH
   Yang, B
   Chen, CX
   Mu, QL
   Li, ZS
AF He, Zhihai
   Yang, Bo
   Chen, Chaoxian
   Mu, Qilin
   Li, Zesong
TI CLDA: an adversarial unsupervised domain adaptation method with
   classifier-level adaptation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unsupervised domain adaptation; Generative adversarial nets;
   Classifier-level adaptation
AB Domain adaptation is an active and important research field in transfer learning. Unsupervised domain adaptation, which is better in line with real-world scenarios than supervised and semi-supervised domain adaptation, has attracted much attention and research. Inspired by generative adversarial networks (GANs), adversarial unsupervised domain adaptation methods are proposed in recent years, which are shown to achieve state-of-the-art performance. Existing adversarial unsupervised domain adaptation methods generally adopt feature-level adaptation to reduce the cross-domain shifts, which is shown to have some limitations in related research. In this paper, we propose a classifier-level adaptation approach to further reducing the cross-domain shifts. The classifier-level adaptation uses two different but related classifiers for source domain and target domain, different from existing adversarial unsupervised domain adaptation methods. In addition, not only domain-invariant feature representations but also auxiliary information of class labels is used to exploit the joint distribution of category information and extracted features. Based on the above-mentioned approaches, a classifier-level domain adaptation (CLDA) method is proposed. Experimental results show that the proposed CLDA method outperforms state-of-the-art unsupervised domain adaptation methods on Digits and Office-31 datasets.
C1 [He, Zhihai; Yang, Bo; Chen, Chaoxian] Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.
   [He, Zhihai; Mu, Qilin; Li, Zesong] Big Data Applicat Improving Govt Governance Capab, Natl Engn Lab, Guiyang 550022, Peoples R China.
   [He, Zhihai; Mu, Qilin] CETC Big Data Res Inst Co Ltd, Guiyang 550022, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Yang, B (corresponding author), Univ Elect Sci & Technol China, Sch Comp Sci & Engn, Chengdu 611731, Sichuan, Peoples R China.
EM hezhihaics@163.com; yangbo@uestc.edu.cn; chenchaoxian@std.uestc.edu.cn;
   muqilin@cetcbigdata.com; lizesongcd@cetcbigdata.com
OI Yang, Bo/0000-0003-0805-7928
FU National Natural Science Foundation of China [61977013]; Sichuan Science
   and Technology Program [2019YJ0164]; Big Data Application on Improving
   Government Governance Capabilities National Engineering Laboratory Open
   Fund Project [w-2019006]
FX This work is supported by National Natural Science Foundation of China
   (Project No. 61977013), Sichuan Science and Technology Program (Project
   No. 2019YJ0164), and Big Data Application on Improving Government
   Governance Capabilities National Engineering Laboratory Open Fund
   Project (Contract No. w-2019006). The authors would like to thank Mr.
   Haodong Liu, an M. Eng. candidate in School of Computer Science and
   Engineering, University of Electronic Science and Technology of China,
   for his help in conducting some of the experiments during the revision
   process of this paper.
CR Bavirisetti DP, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P701
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   Courty N, 2017, IEEE T PATTERN ANAL, V39, P1853, DOI 10.1109/TPAMI.2016.2615921
   Ding ZM, 2018, IEEE INT CONF AUTOMA, P1, DOI 10.1109/FG.2018.00011
   Ding ZM, 2019, IEEE T NEUR NET LEAR, V30, P1768, DOI 10.1109/TNNLS.2018.2874567
   Domhan T, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3460
   Donahue J, 2014, PR MACH LEARN RES, V32
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grandvalet Y, 2004, Advances in neural information processing systems, V17
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang ZW, 2017, MULTIMED TOOLS APPL, V76, P6785, DOI 10.1007/s11042-016-3354-x
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Kang ZF, 2019, KNOWL-BASED SYST, V176, P133, DOI 10.1016/j.knosys.2019.03.024
   Kingma D. P., 2014, arXiv
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LING X, 2008, P 14 ACM SIGKDD INT, P488
   Long M., 2017, 34th Int. Conf. on Machine Learning, V5, P3470
   Long M., 2018, P ADV NEURAL INFORM, VVolume 31
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   NIE L, 2016, LEARNING MULTIPLE SO
   Nie LQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1192, DOI 10.1145/3123266.3123313
   Odena A, 2017, PR MACH LEARN RES, V70
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Saito K, 2017, PR MACH LEARN RES, V70
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang YY, 2018, RAILWAY DEVELOPMENT, OPERATIONS, AND MAINTENANCE, P36
   Yamada M, 2014, IEEE T PATTERN ANAL, V36, P235, DOI 10.1109/TPAMI.2013.123
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Yu D, 2013, INT CONF ACOUST SPEE, P7893, DOI 10.1109/ICASSP.2013.6639201
   Yu X, 2018, KNOWL-BASED SYST, V141, P80, DOI 10.1016/j.knosys.2017.11.010
   Zhang LB, 2018, IEEE INT CON MULTI
NR 40
TC 8
Z9 10
U1 28
U2 115
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33973
EP 33991
DI 10.1007/s11042-020-08877-8
EA APR 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000528819100002
DA 2024-07-18
ER

PT J
AU Handa, A
   Agarwal, R
   Kohli, N
AF Handa, Anand
   Agarwal, Rashi
   Kohli, Narendra
TI A multimodel keyword spotting system based on lip movement and speech
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Keyword spotting and recognition; Convolutional neural networks; Lip
   movement and lip reading; Long short term memory; Speech analysis
ID RECOGNITION; IMAGE
AB The spoken keyword recognition and its localization are one of the fundamental aspects of speech recognition and known as keyword spotting. In automatic keyword spotting systems, the Lip-reading (LR) methods have a broader role when audio data is not present or has corrupted information. The available works from the literature have focussed on recognizing a limited number of words or phrases and require the cropped region of face or lip. Whereas the proposed model does not require the cropping of the video frames and it is recognition free. The proposed model is utilizing Convolutional Neural Networks and Long Short Term Memory networks to improve the overall performance. The model creates a 128-dimensional subspace to represent the feature vectors for speech signals and corresponding lip movements (focused viseme sequences). Thus the proposed model can tackle lip reading as an unconstrained natural speech signal in the video sequences. In the experiments, different standard datasets as LRW (Oxford-BBC), MIRACL-VC1, OuluVS, GRID, and CUAVE are used for the evaluation of the proposed model. The experiments also have a comparative analysis of the proposed model with current state-of-the-art methods for Lip-Reading task and keyword spotting task. The proposed model obtain excellent results for all datasets under consideration.
C1 [Handa, Anand] Dr APJ Abdul Kalam Tech Univ, Dept CSE, Lucknow, Uttar Pradesh, India.
   [Agarwal, Rashi] CSJM Univ, UIET, Dept Informat Technol, Kanpur, Uttar Pradesh, India.
   [Kohli, Narendra] HBTU, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
C3 Dr. A.P.J. Abdul Kalam Technical University (AKTU); Harcourt Butler
   Technical University (HBTU)
RP Handa, A (corresponding author), Dr APJ Abdul Kalam Tech Univ, Dept CSE, Lucknow, Uttar Pradesh, India.
EM anandhanda1986@gmail.com; dr.rashiagrawal@gmail.com;
   kohli.hbti@gmail.com
RI agarwal, rashi/AFM-1023-2022
OI agarwal, rashi/0000-0002-5768-5894
CR [Anonymous], 2004, Issues in visual and audio-visual speech processing
   Arganda-Carreras I, 2015, FRONT NEUROANAT, V9, DOI 10.3389/fnana.2015.00142
   Bakry A, 2013, PROC CVPR IEEE, P684, DOI 10.1109/CVPR.2013.94
   Basu S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P337, DOI 10.1109/ICCV.1998.710740
   Bourlard H., 2012, Connectionist speech recognition: a hybrid approach, V247
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Cox S., 2008, The challenge of multispeaker lip-reading
   Estellers V, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-51
   Galatas G, 2012, EUR SIGNAL PR CONF, P2714
   Giotis AP, 2017, PATTERN RECOGN, V68, P310, DOI 10.1016/j.patcog.2017.02.023
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Gowdy JN, 2004, 2004 IEEE INT C AC S, V1, pi
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jha A., 2019, MACH VISION APPL, V30, P217
   Jha A, 2018, IEEE WINT CONF APPL, P150, DOI 10.1109/WACV.2018.00023
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Krishnan P, 2013, PROC INT CONF DOC, P733, DOI 10.1109/ICDAR.2013.150
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lucey P. J, 2008, CONTINUOUS POSE INVA
   Manmatha R, 1996, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.1996.517139
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Papandreou G, 2009, IEEE T AUDIO SPEECH, V17, P423, DOI 10.1109/TASL.2008.2011515
   Patterson Eric K., 2002, 2002 IEEE INT C AC S, V2
   Pei YR, 2013, IEEE I CONF COMP VIS, P129, DOI 10.1109/ICCV.2013.23
   Rekik A, 2016, MULTIMED TOOLS APPL, V75, P8609, DOI 10.1007/s11042-015-2774-3
   Rekik A, 2014, LECT NOTES COMPUT SC, V8815, P21, DOI 10.1007/978-3-319-11755-3-3
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saenko K, 2005, IEEE I CONF COMP VIS, P1424, DOI 10.1109/ICCV.2005.251
   Shaikh AA., 2010, IEEE International Congress on Image and Signal Processing, V1, P327, DOI [10.1109/CISP.2010.5646264., DOI 10.1109/CISP.2010.5646264]
   Shin J, 2011, PATTERN RECOGN, V44, P559, DOI 10.1016/j.patcog.2010.09.011
   Tamura S, 2015, ASIAPAC SIGN INFO PR, P575, DOI 10.1109/APSIPA.2015.7415335
   Wang K, 2010, LECT NOTES COMPUT SC, V6311, P591, DOI 10.1007/978-3-642-15549-9_43
   Yargiç A, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON INNOVATIONS IN INTELLIGENT SYSTEMS AND APPLICATIONS (IEEE INISTA)
   Yu HP, 2019, MULTIMED TOOLS APPL, V78, P11779, DOI 10.1007/s11042-018-6735-5
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhou ZH, 2014, IMAGE VISION COMPUT, V32, P590, DOI 10.1016/j.imavis.2014.06.004
   Ziheng Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P523, DOI 10.1109/ICPR.2010.133
NR 45
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20461
EP 20481
DI 10.1007/s11042-020-08837-2
EA APR 2020
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000527911700001
DA 2024-07-18
ER

PT J
AU Khan, JA
   Chen, YF
   Rehman, Y
   Shin, H
AF Khan, Jameel Ahmed
   Chen, Yunfan
   Rehman, Yawar
   Shin, Hyunchul
TI Performance enhancement techniques for traffic sign recognition using a
   deep neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic sign recognition; Deep neural network; Pre-processing;
   Optimization; YOLOv3
AB An advanced traffic sign recognition (ATSR) system using novel pre-processing techniques and optimization techniques has been proposed. During the pre-processing of input road images, color contrasts are enhanced and edges are made clearer, for easier detection of small-sized traffic signs. YOLOv3 has been modified to build our traffic sign detector, since it is an efficient and effective deep neural network. In this YOLOv3 modifications, grid optimization and anchor box optimization were done to optimize the detection performance on small-sized traffic signs. We trained the system on our traffic sign dataset and tested the recognition performance using the Mean Average Precision (MAP) on the Korean Traffic Sign Dataset (KTSD) and German Traffic Sign Detection Benchmark (GTSDB). We used the bisection method for selecting the optimum threshold of confidence score to reduce false predictions. Our ATSR system is capable of recognizing Prohibitory, Mandatory, and Danger class traffic signs from road images. ATSR can detect small-sized traffic signs accurately along with big-sized traffic signs. It shows the best recognition performance of 98.15% on the challenging KTSD (the previously reported best performance was 90.07%) and 100% on the GTSDB. Result comparisons show that ATSR significantly outperforms ITSR, TS detector, YOLOv3, and D-patches, on KTSD.
C1 [Khan, Jameel Ahmed; Chen, Yunfan; Shin, Hyunchul] Hanyang Univ, Div Elect Engn, Ansan 15588, South Korea.
   [Rehman, Yawar] NED Univ, Dept Elect Engn, Karachi 75270, Pakistan.
C3 Hanyang University; Ned University of Engineering & Technology
RP Shin, H (corresponding author), Hanyang Univ, Div Elect Engn, Ansan 15588, South Korea.
EM shin@hanyang.ac.kr
RI Chen, Yunfan/AAH-3320-2019; Rehman, Yawar/ACL-3068-2022
OI Chen, Yunfan/0000-0003-4808-6352; Rehman, Yawar/0000-0001-9743-729X
FU Ministry of Trade, Industry & Energy (MOTIE, Korea) under Industrial
   Technology Innovation Program [10080619]
FX This material is based upon work supported by the Ministry of Trade,
   Industry & Energy (MOTIE, Korea) under Industrial Technology Innovation
   Program (10080619).
CR Chen Y, 2018, IET COMPUT VIS, V12, P1179, DOI 10.1049/iet-cvi.2018.5315
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Ellahyani A, 2016, INT J ADV COMPUT SC, V7, P686
   Houben S, 2013, IEEE IJCNN
   JAMEEL H, 2018, IJAERD, V5
   Jia WJ, 2019, MULTIMED TOOLS APPL, V78, P4045, DOI 10.1007/s11042-017-5174-z
   Khan JA, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113776
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li D, 2018, IEEE IJCNN
   Manocha P, 2018, INT SOC DESIGN CONF, P247, DOI 10.1109/ISOCC.2018.8649887
   Mathias M, 2013, IEEE IJCNN
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rehman Y, 2017, IET COMPUT VIS, V11, P368, DOI 10.1049/iet-cvi.2016.0303
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   WANG CY, 2016, TECH REP
   Yang Y, 2016, IEEE T INTELL TRANSP, V17, P2022, DOI 10.1109/TITS.2015.2482461
   Zhang YD, 2019, MULTIMED TOOLS APPL, V78, P3613, DOI 10.1007/s11042-017-5243-3
   Zhu Z., 2016, PROC CVPR IEEE, P2110, DOI DOI 10.1109/CVPR.2016.232
NR 19
TC 10
Z9 10
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2020
VL 79
IS 29-30
BP 20545
EP 20560
DI 10.1007/s11042-020-08848-z
EA APR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MZ1ZZ
UT WOS:000527911700002
DA 2024-07-18
ER

PT J
AU Das, S
   Mukherjee, H
   Obaidullah, SM
   Roy, K
   Saha, CK
AF Das, Sahana
   Mukherjee, Himadri
   Obaidullah, Sk. Md.
   Roy, Kaushik
   Saha, Chanchal Kumar
TI Ensemble based technique for the assessment of fetal health using
   cardiotocograph - a case study with standard feature reduction
   techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cardiotocograph; FHR; UCP; Confusion matrix; MRMR; Kappa
ID HEART-RATE; FIGO
AB Intrauterine fetal hypoxia is one of the leading cause of perinatal mortality and morbidity. This can eventually lead to severe neurological damage like cerebral palsy and in extreme cases to fetal demise. It is thus necessary to monitor the fetus during intrapartum and antepartum period. Cardiotocograph (CTG) as a method of assessing the status of the fetus had been in use for last six decades. Nowadays it is the most widely used non-invasive technique for the continuous monitoring of the fetal heart rate (FHR) and the uterine contraction pressure (UCP). Though its introduction limited the birth related problems, the accuracy of interpretation was hindered by quite a few factors. Different guidelines that are provided for the interpretation are based on crisp logic which fails to capture the inherent uncertainty present in the medical diagnosis. Misinterpretations had led to inaccurate diagnosis which resulted in many medico-legal litigations. The vagueness present in the physician's evaluation is best modeled using soft-computing based techniques. In this paper authors used the CTG dataset from UCI Irvine Machine Learning Data Repository which contains 2126 data and each data-point is represented by 37 features. Dimensionality of the feature set was reduced using different automated methods as well as manually by the physicians. The resulting data sets were classified using various machine learning algorithms. Aim of this study is to establish which set of features is best suited to give good insight into the status of the fetus and also determine the most effective machine learning technique for this purpose. The accuracy of the outcomes were measured using statistical methods such as sensitivity, specificity, precision, F-Measure, confusion matrix and kappa value. We obtained an accuracy of 99.91% and kappa measure of 0.997 when the feature set was reduced using MRMR.
C1 [Das, Sahana; Mukherjee, Himadri; Roy, Kaushik] West Bengal State Univ, Dept Comp Sci, Kolkata, India.
   [Obaidullah, Sk. Md.] Aliah Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Saha, Chanchal Kumar] Biraj Mohini Matrisadan & Hosp, Kolkata, India.
C3 West Bengal State University; Aliah University
RP Roy, K (corresponding author), West Bengal State Univ, Dept Comp Sci, Kolkata, India.
EM sahana.das73@gmail.com; himadrim027@gmail.com; sk.obaidullah@gmail.com;
   kaushik.mrg@gmail.com; chanchal1069@yahoo.com
RI Roy, Kaushik/O-7021-2019; Sk, Obaidullah/ABF-9198-2020; Das, Dr.
   Sahana/JKI-5146-2023
OI Roy, Kaushik/0000-0002-3360-7576; Sk, Md Obaidullah/0000-0002-5207-3709
CR ALONSOBETANZOS A, 1995, ARTIF INTELL MED, V7, P297, DOI 10.1016/0933-3657(95)00007-S
   [Anonymous], **DATA OBJECT**
   Ayres-De-Campos D, 2015, INT J GYNECOL OBSTET, V131, P13, DOI 10.1016/j.ijgo.2015.06.020
   Barber DC., 1975, Journal of Applied Statistics, V2, P39
   Barquero-Pérez O, 2017, FRONT PHYSIOL, V8, DOI 10.3389/fphys.2017.00113
   Cömert Z, 2019, ADV INTELL SYST COMP, V763, P239, DOI 10.1007/978-3-319-91186-1_25
   Das S, 2017, ADV WIREL TECHNOL TE, P471, DOI 10.4018/978-1-5225-1785-6.ch018
   DAWES GS, 1981, AM J OBSTET GYNECOL, V141, P43, DOI 10.1016/0002-9378(81)90673-6
   Georgoulas G, 2006, IEEE T BIO-MED ENG, V53, P875, DOI 10.1109/TBME.2006.872814
   Ghodsi A., 2006, DIMENSIONALITY REDUC
   Gogolewski K, 2019, J COMPUT BIOL, V26, P782, DOI 10.1089/cmb.2018.0255
   Guijarro-Berdiñas B, 2002, ARTIF INTELL, V136, P1, DOI 10.1016/S0004-3702(01)00163-1
   Huang M.-L., 2012, Journal of Biomedical Science and Engineering, V5, P526, DOI 10.4236/jbise.2012.59065
   Macones GA, 2008, OBSTET GYNECOL, V112, P661, DOI 10.1097/AOG.0b013e3181841395
   Maeda K, 2014, J HLTH MED INFORM, DOI [10.1891/9780826172310.0015, DOI 10.1891/9780826172310.0015]
   Maeda K, 2015, ALGORITHMS, V8, P395, DOI 10.3390/a8030395
   Murotsuki J, 1997, AM J OBSTET GYNECOL, V176, P282, DOI 10.1016/S0002-9378(97)70486-1
   Ocak H, 2013, J MED SYST, V37, DOI 10.1007/s10916-012-9913-4
   Özyilmaz L, 2004, LECT NOTES ARTIF INT, V3070, P1026
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Petrozziello A, 2019, IEEE ACCESS, V7, P112026, DOI 10.1109/ACCESS.2019.2933368
   Preti M, 2018, INT J GYNECOLOGY REP, V1, P11
   Santo S, 2017, ACTA OBSTET GYN SCAN, V96, P166, DOI 10.1111/aogs.13064
   Thakur S, 2013, 2013 COMPUTING, COMMUNICATIONS AND IT APPLICATIONS CONFERENCE (COMCOMAP), P120, DOI 10.1109/ComComAp.2013.6533621
   Yilmaz E, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/487179
   Ylmaz E, 2013, COMPUT MATH METHODS, V2013, P1307
   Zhang ZH, 2017, ANN TRANSL MED, V5, DOI 10.21037/atm.2017.07.12
   Zhu M, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/794586
NR 28
TC 1
Z9 1
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 47-48
BP 35147
EP 35168
DI 10.1007/s11042-020-08853-2
EA APR 2020
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA PA9WZ
UT WOS:000557498400001
DA 2024-07-18
ER

PT J
AU Afrasiabi, M
   Khotanlou, H
   Gevers, T
AF Afrasiabi, Mahlagha
   Khotanlou, Hassan
   Gevers, Theo
TI Spatial-temporal dual-actor CNN for human interaction prediction in
   video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Interaction prediction; Dual-actor CNN
ID HUMAN INTERACTION RECOGNITION; HISTOGRAMS
AB Predicting the interaction between two humans, when viewed as a part of video is one of the most challenging issues in the field of computer vision, due to its various applications. This paper presents a new interaction prediction method that has a high accuracy in detecting the interactions when a small percentage of the video is viewed. At first, the interacting people are detected and then a dual-actor CNN model is utilized to recognize the type of interaction between the detected people. This model consists of two CNN networks while the parameters of which are shared. Each branch of this model extracts deep temporal or spatial features. The spatial and the temporal models are learned with Long Short Term Memory (LSTM) networks to model time information. Finally, the spatial and temporal models are combined to predict the interaction. The results show that the proposed model gives improvements on standard interaction recognition datasets including the TV Human Interaction, BIT interaction and UT Interaction.
C1 [Afrasiabi, Mahlagha; Khotanlou, Hassan] Bu Ali Sina Univ, Dept Comp Engn, Hamadan, Hamadan, Iran.
   [Gevers, Theo] Univ Amsterdam, Comp Vis Lab, Amsterdam, Netherlands.
C3 Bu Ali Sina University; University of Amsterdam
RP Khotanlou, H (corresponding author), Bu Ali Sina Univ, Dept Comp Engn, Hamadan, Hamadan, Iran.
EM m.afrasiabi@basu.ac.ir; Khotanlou@basu.ac.ir; th.gevers@uva.nl
RI afrasiabi, mahlagha/AAC-7717-2021
OI afrasiabi, mahlagha/0000-0001-9472-4453; Khotanlou,
   Hassan/0000-0001-7351-9397
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Ahmadipour Z, 2016, 2016 EIGHTH INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE TECHNOLOGY (IKT), P61, DOI 10.1109/IKT.2016.7777779
   [Anonymous], UT-Interaction Dataset, ICPR contest on Semantic Description of Human Activities (SDHA)
   [Anonymous], 2017, ARXIV170600931
   [Anonymous], 2017, IEEE T MULTIMEDIA
   [Anonymous], 1999, INT SERIES COMPUTATI
   [Anonymous], 2019, VISUAL COMPUT
   Berlin SJ, 2016, INT CARN CONF SECU, P143
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dyer C, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P334
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hoai M, 2014, PROC CVPR IEEE, P875, DOI 10.1109/CVPR.2014.117
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Ji XF, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7060567
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Ke QH, 2016, LECT NOTES COMPUT SC, V9914, P403, DOI 10.1007/978-3-319-48881-3_28
   Ko T, 2008, IEEE APP IMG PAT, P84
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kong Y, 2012, LECT NOTES COMPUT SC, V7572, P300, DOI 10.1007/978-3-642-33718-5_22
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Trong NP, 2017, LECT NOTES COMPUT SC, V10404, P411, DOI 10.1007/978-3-319-62392-4_30
   Patron-Perez Alonso., 2010, BMVC, V1, P2
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Ramanathan M, 2014, IEEE T HUM-MACH SYST, V44, P650, DOI 10.1109/THMS.2014.2325871
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Vahdat A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1729, DOI 10.1109/ICCVW.2011.6130458
   Wang XL, 2016, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2016.291
   Xu C, 2015, IEEE T PATTERN ANAL, V37, P2531, DOI 10.1109/TPAMI.2015.2417578
   Yang Y, 2018, IEEE T IMAGE PROCESS, V27, P5600, DOI 10.1109/TIP.2018.2855422
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Yu CJ, 2018, LECT NOTES COMPUT SC, V11220, P595, DOI 10.1007/978-3-030-01270-0_35
   Zhang JP, 2019, MED IMAGE ANAL, V54, P10, DOI 10.1016/j.media.2019.02.010
   Zhang SG, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/3090343
   Zhao YR, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND COMMUNICATION ENGINEERING (ICTCE 2018), P154, DOI [10.1145/3291842.3291895, 10.1016/j.patcog.2018.01.012]
   Zhu LC, 2017, PROC CVPR IEEE, P1339, DOI 10.1109/CVPR.2017.147
NR 47
TC 4
Z9 4
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 20019
EP 20038
DI 10.1007/s11042-020-08845-2
EA APR 2020
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000524620600001
DA 2024-07-18
ER

PT J
AU Gomathi, P
   Baskar, S
   Shakeel, PM
   Dhulipala, VRS
AF Gomathi, P.
   Baskar, S.
   Shakeel, P. Mohamed
   Dhulipala, V. R. Sarma
TI RETRACTED: Identifying brain abnormalities from electroencephalogram
   using evolutionary gravitational neocognitron neural network (Retracted
   article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Brain abnormality; Electroencephalogram (EEG); Multi-linear principal
   component; Affine invariant component analysis; Multi-layer virtual
   cortex; Mathew correlation coefficient and accuracy
ID INFORMATION
AB Now-a-day's brain abnormality is one among the dangerous neurological disorders that occurs because of the birth defects, brain stroke, brain injuries, genetic mutation and brain tumor. This brain disorder creates continue melancholia, bipolar disorder, stress disorder (PTSD) and so on. Due to this serious impact of the brain abnormalities, need to be identified within the beginning stage for eliminating the difficulties in humans day to day life. So, the automatic brain abnormality prediction process is created by utilizing electroencephalogram (EEG) for avoiding risk factor in future. As per the discussion, this paper introduces the evolutionary gravitational Neocognitron neural network(GNNN) for recognizing brain abnormalities with effective manner and it is especially suited for humans in war field. Initially, EEG signal is collected from patient; unwanted signal information is eliminated by using multi-linear principal component analysis from pre-processed signal, various features are extracted using affine invariant component analysis method and greedy global optimized features are chosen. The chosen features are analyzed using multi-layer virtual cortex model for predicting abnormal features. Finally the potency of the brain related abnormality prediction process developed using MATLAB tool and efficiency is examined using F-measure, Mathew correlation coefficient error rate, sensitivity, specificity, and accuracy. Along these lines the proposed framework effectively perceives the cerebrum variation from the norm with most astounding precision up to 99.48% with error rate.
C1 [Gomathi, P.] NSN Coll Engn & Technol, Dept Elect & Elect Engn, Karur, India.
   [Baskar, S.] Karpagam Acad Higher Educ, Ctr Interdisciplinary Res, Dept Elect & Commun Engn, Coimbatore, Tamil Nadu, India.
   [Shakeel, P. Mohamed] Univ Tekn Malaysia, Fac Informat & Commun Technol, Melaka, Malaysia.
   [Dhulipala, V. R. Sarma] Anna Univ, Dept Phys, BIT Campus, Tiruchirappalli, India.
C3 Karpagam Academy of Higher Education (KAHE); University Teknikal
   Malaysia Melaka; Anna University; Anna University of Technology
   Tiruchirappalli
RP Gomathi, P (corresponding author), NSN Coll Engn & Technol, Dept Elect & Elect Engn, Karur, India.
EM gomathirnd@gmail.com
RI S, Baskar/R-6346-2017
OI S, Baskar/0000-0003-3570-3059
CR [Anonymous], 2014, DIGIT SIGNAL PROCESS, V6, P194
   Baskar S, 2018, J MED IMAG HEALTH IN, V8, P805, DOI 10.1166/jmihi.2018.2361
   Baskar S., 2018, J COMPUT THEOR NANOS, V15, P1395, DOI [10.1166/jctn.2018.7249, DOI 10.1166/jctn.2018.7249]
   Black P.E., 2005, GREEDY ALGORITHM DIC
   De Lucia M, 2007, MED BIO ENGCOMPUT, P1
   Dong Kang, 2012, Proceedings of the 2012 International Conference on Computer Science and Electronics Engineering (ICCSEE 2012), P322, DOI 10.1109/ICCSEE.2012.105
   Fesenfeld Martha Dow, 2009, LETT S BECKETT, P622, DOI DOI 10.7763/IJCTE.2009.V1.101
   Fong S, IEEE IT PROF MAG, V16, P24
   Kalaivani M., 2014, Int. J. Comput. Appl, V1, P1
   Khan R., 2017, Proceedings of the 2017 IEEE PES Innovative Smart Grid Technologies Conference Europe, ISGT-Europe 2017, Torino, Italy, 26-29 September 2017, P1
   Kumar SU, 2017, NEURAL COMPUT APPL, V28, P3239, DOI 10.1007/s00521-016-2236-5
   Kumari P, 2015, IEEE SENS J, V15, P4950, DOI 10.1109/JSEN.2015.2423152
   Lehnertz F, 2003, IEEE ENG MED BIOL MA
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez-Leon JA, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/781207
   Mashford BS, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2663978
   Nguyen H, 2010, P INT C PATT REC ICP
   Panagakis Y, 2010, IEEE T AUDIO SPEECH, V18, P576, DOI 10.1109/TASL.2009.2036813
   Pavan Kumar K, 2013, INT J NETW SEC APPL, V5
   Pazhanirajan D, 2014, INT J INNOVATIVE RES, V3, P15391, DOI [10.15680/IJIRSET.2014.0308044, DOI 10.15680/IJIRSET.2014.0308044]
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Rao DDV, 2014, GREEN COMPUTING COMM
   Satapathy SK., 2016, Int J Appl Eng Res, V11, P120
   Shakeel PM, 2020, NEURAL COMPUT APPL, V32, P777, DOI 10.1007/s00521-018-03972-2
   Shakeel PM, 2020, HEALTH TECHNOL-GER, V10, P157, DOI 10.1007/s12553-018-0279-6
   Shakeel PM, 2019, IEEE ACCESS, V7, P5577, DOI 10.1109/ACCESS.2018.2883957
   Shakeel PM, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0054-0
   Shakeel PM, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1045-z
   Sridhar KP, 2019, J AMB INTEL HUM COMP, V10, P3287, DOI 10.1007/s12652-018-1058-y
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Vatankhah Maryam, 2016, International Journal of Engineering and Technology, V8, P380, DOI 10.7763/IJET.2016.V8.917
   Vikhar Pradnya A., 2016, 2016 International Conference on Global Trends in Signal Processing, Information Computing and Communication (ICGTSPICC). Proceedings, P261, DOI 10.1109/ICGTSPICC.2016.7955308
   Wen TX, 2018, IEEE ACCESS, V6, P25399, DOI 10.1109/ACCESS.2018.2833746
   Xue B, 2014, 2014 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P3119, DOI 10.1109/CEC.2014.6900472
NR 34
TC 30
Z9 30
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10609
EP 10628
DI 10.1007/s11042-019-7301-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600048
DA 2024-07-18
ER

PT J
AU Guo, JQ
   Li, CY
   Zhang, GZ
   Sun, YC
   Bie, RF
AF Guo, Junqi
   Li, Chuyang
   Zhang, Guangzhi
   Sun, Yunchuan
   Bie, Rongfang
TI Blockchain-enabled digital rights management for multimedia resources of
   online education
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain-enabled; Digital rights management; Multimedia resources;
   Online education; Smart contract
AB Nowadays, various online education platforms (such as MOOCs, Coursera, XuetangX and so on) not only provide a broad Internet environment for sharing multimedia learning resources, but also bring a series of challenges in digital rights management, such as the infringement of digital copyrights of multimedia learning resources, the insecurity of digital education certificates, and the low degree of openness of multimedia learning resources. To sovle these issues, we propose a blockchain-enabled digital rights management system, which includes an entirely new network architecture for sharing and managing multimedia resources of online education on the basis of the combination of the public and private blockchains, as well as three specific smart contract schemes for the realization of the recording of multimedia digital rights, the secure storage and the unmediated verification of digital certificates, respectively. The proposed blockchain-enabled digital rights management system has been demonstrated as a promising candidate solution to the blockchain-based multimedia data protection in an online education environment.
C1 [Guo, Junqi; Li, Chuyang; Zhang, Guangzhi; Bie, Rongfang] Beijing Normal Univ, Sch Artif Intelligence, Beijing, Peoples R China.
   [Guo, Junqi; Li, Chuyang; Zhang, Guangzhi; Sun, Yunchuan; Bie, Rongfang] Beijing Normal Univ, Res Ctr Knowledge BlockChain, Beijing, Peoples R China.
   [Sun, Yunchuan] Beijing Normal Univ, Business Sch, Int Inst Big Data Finance, Beijing, Peoples R China.
C3 Beijing Normal University; Beijing Normal University; Beijing Normal
   University
RP Bie, RF (corresponding author), Beijing Normal Univ, Sch Artif Intelligence, Beijing, Peoples R China.; Bie, RF (corresponding author), Beijing Normal Univ, Res Ctr Knowledge BlockChain, Beijing, Peoples R China.
EM guojunqi@bnu.edu.cn; 1025360322@qq.com; zgz_bnu@mail.bnu.edu.cn;
   yunch@bnu.edu.cn; rfbie@bnu.edu.cn
RI Zhang, Guangzhi/HMF-5722-2023; Sun, Yunchuan/AAN-8060-2020
CR Androulaki E, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190538
   [Anonymous], 2018 26 SIGN PROC CO
   [Anonymous], 2017, DOCUMENT TRAVAIL CTR
   [Anonymous], 2015, DIGITAL EC OUTLOOK
   [Anonymous], COPYRIGHT MADE SIMPL
   [Anonymous], 2018, ARXIV181210792
   [Anonymous], MONEGRAPH IS CREATIV
   [Anonymous], 2014, P 19 NAT YOUTH COMM
   [Anonymous], SINGULARDTV DECENTRA
   [Anonymous], 2018, Philosophy & Technology, DOI [DOI 10.1007/S13347-016-0243, 10.1007/s13347-016-0243-1, DOI 10.1007/S13347-016-0243-1]
   [Anonymous], RES POTENTIAL BLOCKC
   [Anonymous], EMPOWERING CREATORS
   [Anonymous], ADV LEARN TECHN 2003
   [Anonymous], IEEE INT C IM SYST T
   [Anonymous], ADULT ED
   [Anonymous], MSC DIG CURR
   [Anonymous], 2018, ARXIV180100933
   Bhowmik D, 2017, INT CONF DIGIT SIG
   Castro M, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE THIRD SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '99), P173, DOI 10.1145/571637.571640
   Chuen D., 2015, Handbook of digital currency: Bitcoin, innovation, financial instruments, and big data
   Croman K, 2016, LECT NOTES COMPUT SC, V9604, P106, DOI 10.1007/978-3-662-53357-4_8
   Giechaskiel I, 2018, IEEE SECUR PRIV, V16, P46, DOI 10.1109/MSP.2018.3111253
   Grech A., 2017, Blockchain in education, DOI [10.2760/60649, DOI 10.2760/60649]
   Huckle S, 2016, PROCEDIA COMPUT SCI, V98, P461, DOI 10.1016/j.procs.2016.09.074
   Johnson D., 2001, International Journal of Information Security, V1, P36, DOI 10.1007/s102070100002
   Li Q., 2017, J DISTANCE ED, V01, P36, DOI [10.15881/j.cnki.cn33-1304/g4.2017.01.004, DOI 10.15881/j.cnki.cn33-1304/g4.2017.01.004]
   Li WT, 2017, LECT NOTES COMPUT SC, V10436, P297, DOI 10.1007/978-3-319-67816-0_17
   Meng ZX, 2018, P INT COMP SOFTW APP, P359, DOI 10.1109/COMPSAC.2018.10258
   [闵新平 Min Xinping], 2018, [计算机学报, Chinese Journal of Computers], V41, P1005
   Nakamoto S, 2008, BITCOIN PEER TO PEER, DOI DOI 10.1007/S10838-008-9062-0
   Peters DW, 2018, 2018 IEEE INT INSTR, P1, DOI DOI 10.1109/I2MTC.2018.8409668
   Scherer M., 2017, Performance and Scalability of Blockchain Networks and Smart Contracts
   Sukhwani H, 2017, SYM REL DIST SYST, P253, DOI 10.1109/SRDS.2017.36
   Swan Melanie, 2015, BLOCKCHAIN BLUEPRINT
   Dinh TTA, 2018, IEEE T KNOWL DATA EN, V30, P1366, DOI 10.1109/TKDE.2017.2781227
   Tschorsch F, 2016, IEEE COMMUN SURV TUT, V18, P2084, DOI 10.1109/COMST.2016.2535718
   Yang XM., 2017, Modern distance education research, V2, P34, DOI DOI 10.3969/J.ISSN.1009-5195.2017.02.005
   Zheng ZB, 2017, IEEE INT CONGR BIG, P557, DOI 10.1109/BigDataCongress.2017.85
NR 38
TC 54
Z9 57
U1 7
U2 121
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 9735
EP 9755
DI 10.1007/s11042-019-08059-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600002
DA 2024-07-18
ER

PT J
AU Han, KY
   Lee, M
   Lee, YS
AF Han, Kyung Yeop
   Lee, Minho
   Lee, Young-Sup
TI Implementation of autonomous driving of a ground vehicle for narrow
   high-curvature roads using surround view images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Autonomous vehicle; Signal processing; Surround view image; Narrow and
   high-curvature roads; Segmentation of images
ID LANE DETECTION; SYSTEM
AB In this paper, a new approach for the implementation of autonomous driving of a ground vehicle on narrow and high-curvature roads using a surround view system is proposed. The approach called the independent frame consecutive searching technique is an algorithm which is developed to detect the left and right lane markers of a lane stably and to generate virtual lane marker lines especially when the roads are narrow and have sudden corners and windings with some faded lane markers. Then the steering angle of an autonomous vehicle is calculated so that the vehicle drives along the desired path after deriving the smoothed virtual centerline. In the real-time experiment, the suggested approach achieved robust detection of lane markers using surround view images and drove a test vehicle autonomously with the generated desired paths on such narrow and high-curvature roads with any lane departures. Therefore, this study shows that the method can be applied to the development of autonomous vehicles.
C1 [Han, Kyung Yeop; Lee, Minho; Lee, Young-Sup] Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
C3 Incheon National University
RP Lee, YS (corresponding author), Incheon Natl Univ, Dept Embedded Syst Engn, Incheon, South Korea.
EM ysl@inu.ac.kr
CR Alvarez JM, 2007, LECT NOTES COMPUT SC, V4478, P9
   Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   Bar Hillel A, 2014, MACH VISION APPL, V25, P727, DOI 10.1007/s00138-011-0404-2
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   Boggavarapu LNP, 2011, INT J ADV COMPUT SC, V2, P71
   Chen Y, 2014, INTELL SYST SER, P1
   Cheng HY, 2006, IEEE T INTELL TRANSP, V7, P571, DOI 10.1109/TITS.2006.883940
   Huang JG, 2007, 2007 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, VOLS 1 AND 2, P597
   Hughes C, 2010, IEEE T PATTERN ANAL, V32, P2289, DOI 10.1109/TPAMI.2010.159
   Jazar R. N., 2017, Vehicle Dynamics: Theory and Application
   Kaneko T, 2006, VEHICLE SYST DYN, V44, P741, DOI 10.1080/00423110600885731
   Kang DJ, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P189, DOI 10.1109/IVS.1996.566376
   Katramados I, 2009, LECT NOTES COMPUT SC, V5815, P265, DOI 10.1007/978-3-642-04667-4_27
   Kiss D, 2017, J ADV TRANSPORT, DOI 10.1155/2017/2521638
   Koopman P, 2017, IEEE INTEL TRANSP SY, V9, P90, DOI 10.1109/MITS.2016.2583491
   Kum CH, 2013, INT SOC DESIGN CONF, P215, DOI 10.1109/ISOCC.2013.6864011
   Lan XD, 2015, 2015 EUROPEAN CONTROL CONFERENCE (ECC), P2360, DOI 10.1109/ECC.2015.7330891
   Lee H, 2017, IEEE INT VEH SYM, P1434, DOI 10.1109/IVS.2017.7995911
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Rossle S., 1993, P INT VEH C 93, P340, DOI DOI 10.1109/IVS.1993.697348
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Takahashi A, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P148
   Thrun S, 2006, J FIELD ROBOT, V23, P661, DOI 10.1002/rob.20147
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   Yu B, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P748, DOI 10.1109/ICIP.1997.638604
   Zhou Y, 2011, PROCEEDINGS OF THE 3RD (2011) INTERNATIONAL CONFERENCE ON FINANCIAL RISK AND CORPORATE FINANCE MANAGEMENT, VOLS 1 AND 2, P44
NR 26
TC 0
Z9 0
U1 1
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 8379
EP 8398
DI 10.1007/s11042-018-6485-4
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600004
DA 2024-07-18
ER

PT J
AU Liu, J
   Pi, J
   Xia, LR
AF Liu, Jun
   Pi, Jie
   Xia, Liru
TI A novel and high precision tomato maturity recognition algorithm based
   on multi-level deep residual network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tomato detection; Deep learning; DenseNet; Structuring sparse; Network
   tailoring; Loss function
ID FIRE
AB Since the existing tomato picking system uses multispectral sensors, color and other passive sensors for tomato detection and recognition, its detection range is very small, anti-interference ability is also weak, and tomato maturity detection cannot be performed accurately in real-time. How to detect tomato information from the massive image data obtained from tomato picking equipment and improve the recognition accuracy is a challenging research topic at home and abroad. This paper proposes an improved DenseNet deep neural network architecture, and uses it to solve the detection problems of maturity tomato in complex images. In order to enhance the accuracy of feature propagation and reduce the amount of stored data, a structured sparse operation is proposed. By dividing the network convolution kernel into multiple groups, the unimportant parameter connections in each group are gradually reduced during the network training process. In addition, since the dataset constructed in the field of tomato picking has imbalance, we introduce the Focal loss function to identify the tomato in the classification layer so as to enhance the accuracy of the final classification prediction of the tomato detection system. A large number of qualitative and quantitative experiments show that our improved network in this paper is superior to other existing deep models in terms of detection rate and FPPI, and its computational complexity is lower than that of DenseNet algorithm 18% under the same hardware and software configuration.
C1 [Liu, Jun; Pi, Jie; Xia, Liru] Minist Agr, Key Lab Protected Agr Engn Middle & Lower Reaches, Jiangsu Acad Agr Sci, Inst Agr Facil & Equipment, Nanjing 210014, Peoples R China.
C3 Ministry of Agriculture & Rural Affairs; Jiangsu Academy of Agricultural
   Sciences
RP Xia, LR (corresponding author), Minist Agr, Key Lab Protected Agr Engn Middle & Lower Reaches, Jiangsu Acad Agr Sci, Inst Agr Facil & Equipment, Nanjing 210014, Peoples R China.
EM nkyliu@163.com; pijiejaas@163.com; xlrjaas@126.com
CR Ahlin K, 2016, IFAC PAPERSONLINE, V49, P177, DOI 10.1016/j.ifacol.2016.10.033
   [Anonymous], T CHINESE SOC AGR EN
   [Anonymous], CVPR
   [Anonymous], OPTOELECTRONICS INST
   [Anonymous], INT S COMP BUS INT I
   [Anonymous], 2017, P 4 INT WORKSHOP SEN
   [Anonymous], REG 10 C IEEE
   [Anonymous], IEEE RAS INT C HUM R
   Brahimi M, 2017, APPL ARTIF INTELL, V31, P299, DOI 10.1080/08839514.2017.1315516
   Cai ZY, 2017, MULTIMED TOOLS APPL, V76, P4313, DOI 10.1007/s11042-016-3374-6
   Dimitropoulos K, 2015, IEEE T CIRC SYST VID, V25, P339, DOI 10.1109/TCSVT.2014.2339592
   Fuentes A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092022
   Gubbi J, 2009, FIRE SAFETY J, V44, P1110, DOI 10.1016/j.firesaf.2009.08.003
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kerfin O, 2017, IEEE INT SYMP ELEC
   Kung CC, 2005, IEEE INT CONF FUZZY, P708
   Listyorini T., 2018, World Trans Eng Technol Educ, V16, P42
   Liu W., 2016, LECT NOTES COMPUT SC, P21, DOI DOI 10.1007/978-3-319-46448-0_2
   Misra I, 2017, PROC CVPR IEEE, P1160, DOI 10.1109/CVPR.2017.129
   Sermanet P, 2012, INT C PATT RECOG, P3288
   Shimoda W, 2015, LECT NOTES COMPUT SC, V9281, P449, DOI 10.1007/978-3-319-23222-5_55
   Tian L, 2018, INT J REMOTE SENS, V39, P3801, DOI 10.1080/01431161.2018.1437294
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yu Z, 2017, LANGMUIR, V33, P322, DOI 10.1021/acs.langmuir.6b03798
   Zeng A., 2016, Multi-view self-supervised deep learning for 6d pose estimation in the amazon picking challenge," 09
   Zhang L, 2020, IEEE T DEPEND SECURE, V17, P634, DOI 10.1109/TDSC.2018.2797190
   Zhou YunCheng Zhou YunCheng, 2017, Transactions of the Chinese Society of Agricultural Engineering, V33, P219
NR 28
TC 15
Z9 17
U1 5
U2 59
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9403
EP 9417
DI 10.1007/s11042-019-7648-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600059
DA 2024-07-18
ER

PT J
AU Ramu, T
   Suthendran, K
   Arivoli, T
AF Ramu, T.
   Suthendran, K.
   Arivoli, T.
TI Machine learning based soft biometrics for enhanced keystroke
   recognition system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Machine learning; Fusion; Gaussian probability density function;
   Keystroke biometrics; Soft biometrics; Support vector machine
ID DESIGN
AB The proposed work investigates the performance enhancement of keystroke biometric recognition using soft biometric with filter and Score Boost Weighting (SBW) scheme. Usually, Keystroke recognition performance is lower due to user's emotional behaviour or distraction, typing patterns vary from user normal position which causes recognition error of genuine user for degrading the recognition accuracy. To address this problem, this work presents Dual Matcher with fusion to reduce the false rejection of genuine user to improve the accuracy of keystroke recognition. In this paper, soft biometric is used as secondary information to improve the recognition accuracy for primary keystroke biometric system. Specifically, soft biometrics provides additional support for keystroke biometric recognition at the combination approach. The performance of keystroke system can be further improved using SVM as machine learning under the score level fusion in the combination approach. Lastly, the fusion technique is used to combine the primary and secondary biometric. The new approach with score fusion enhances the overall performance of keystroke biometric system with 99% accuracy. Maximum of 2% improvement is achieved compared to existing works.
C1 [Ramu, T.] Kalasalingam Univ, Dept Elect & Commun Engn, Krishnankoil 626126, Tamil Nadu, India.
   [Suthendran, K.] Kalasalingam Univ, Sch Comp, Krishnankoil 626126, Tamil Nadu, India.
   [Arivoli, T.] Vickram Coll Engn, Dept Elect & Commun Engn, Enathi 630561, Tamil Nadu, India.
C3 Kalasalingam Academy of Research & Education; Kalasalingam Academy of
   Research & Education
RP Ramu, T (corresponding author), Kalasalingam Univ, Dept Elect & Commun Engn, Krishnankoil 626126, Tamil Nadu, India.
EM ramuthangayan@gmail.com
RI Suthendran, K./ABE-6015-2021
OI Suthendran, K./0000-0002-7030-4398
CR Ahilan A, 2016, ADV INTELL SYST, V412, P237, DOI 10.1007/978-981-10-0251-9_24
   Ahilan A, 2015, MICROELECTRON RELIAB, V55, P2108, DOI 10.1016/j.microrel.2015.06.075
   Ahilan A, 2011, 2011 THIRD INTERNATIONAL CONFERENCE ON ADVANCED COMPUTING (ICOAC), P353, DOI 10.1109/ICoAC.2011.6165201
   Ailisto H, 2006, PATTERN RECOGN LETT, V27, P325, DOI 10.1016/j.patrec.2005.08.018
   [Anonymous], 2012, INF SECUR TECH REP, DOI [DOI 10.1016/J.ISTR.2012.02.001, 10.1016/j.istr.2012.02.001]
   [Anonymous], 1999, P DARPA BROADC NEWS
   [Anonymous], 1999, Biometrics: Personal Identification in Networked Society
   [Anonymous], P CARD TECH SEC TECH
   Appathurai Ahilan, 2018, IET NETWORKS, DOI [10.1049/iet-net.2018.517, DOI 10.1049/IET-NET.2018.517]
   Bhardwaj I, 2017, IETE TECH REV, V34, P478, DOI 10.1080/02564602.2016.1203271
   Bixler R., 2013, Proceedings of the 2013 International Conference on Intelligent User Interfaces, New York, NY, USA, P225, DOI DOI 10.1145/2449396.2449426
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Denman S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P462, DOI 10.1109/AVSS.2011.6027377
   Dong Y, 2011, INT JOINT C BIOM IJC
   Epp C, 2011, 29TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P715
   Giot Romain, 2012, International Journal of Information Technology and Management, V11, P35, DOI 10.1504/IJITM.2012.044062
   Giot R., 2011, Biometrics IntechOpen, V1, P157
   Guodong Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3392, DOI 10.1109/ICPR.2010.828
   Heckathorn DD, 1997, ANN M AM SOC ASS TOR
   Idrus SZS, 2014, COMPUT SECUR, V45, P147, DOI 10.1016/j.cose.2014.05.008
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jeng RH, 2017, IETE TECH REV, V34, P91, DOI 10.1080/02564602.2016.1149039
   Koakowska A, 2018, ADV INTELLIGENT SYST
   Kumar JS, 2019, CLUSTER COMPUT, V22, P15007, DOI 10.1007/s10586-018-2486-3
   Marcialis GL, 2009, J VISUAL LANG COMPUT, V20, P101, DOI 10.1016/j.jvlc.2009.01.005
   Moradi A, 2016, IEEE CSC ESAS SUPERC, P1
   Obaidat M.S., 1999, Biometrics. Personal Identification in Networked Society, P213
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Prathiba G, 2018, MICROELECTRON RELIAB, V88-90, P91, DOI 10.1016/j.microrel.2018.07.095
   Roy S, 2017, LECT NOTES COMPUT SC, V10590, P320, DOI 10.1007/978-3-319-70742-6_30
   Sivasankari B, 2018, MICROELECTRON RELIAB, V88-90, P1316, DOI 10.1016/j.microrel.2018.07.078
   Teh PS, 2013, SCI WORLD J, DOI 10.1155/2013/408280
   Teh PS, 2012, P 2012 INT C CYB SEC
   Thanganayagam R, 2016, SMART INNOV SYST TEC, V43, P85, DOI 10.1007/978-81-322-2538-6_10
   Vapnik VN, 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
NR 35
TC 3
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10029
EP 10045
DI 10.1007/s11042-019-7201-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000534781600016
DA 2024-07-18
ER

PT J
AU Yu, HF
AF Yu, Hua-Feng
TI Bibliographic automatic classification algorithm based on semantic space
   transformation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Chinese bibliographic classification; Semantic space
   transformation; Word frequency; inverse document frequency; Support
   vector machine
ID TEXT CLASSIFICATION
AB In view of the Chinese bibliographic data mining application of Chinese bibliography, an improved semantic space transformation method is proposed. Firstly, the ICTCLAS system is used to preprocess the texts and construct lemma vectors based on word frequency features. Then, the frequency features of the word frequency and the frequency of the inverse frequency document are fused to construct the feature matrix of the training sample set. Then, the matrix is decomposed and transformed by the singular value to obtain a semantic space, which is for the goal of performing semantic space transformation on the text eigenvectors to obtain semantic vectors. Finally, a joint SVM classifier is constructed to automatically classify the semantic vectors corresponding to Chinese bibliography. Extensive experimental results show that the classification accuracy of this method is higher than the existing methods.
C1 [Yu, Hua-Feng] Zhejiang Tech Inst Econ, Sch Digital Informat Technol, Hangzhou 310018, Peoples R China.
RP Yu, HF (corresponding author), Zhejiang Tech Inst Econ, Sch Digital Informat Technol, Hangzhou 310018, Peoples R China.
EM 107885339@qq.com
CR Borges AV, 2011, OCEANS AND THE ATMOSPHERIC CARBON CONTENT, P47, DOI 10.1007/978-90-481-9821-4_3
   Caruntu A, 2006, 2006 IEEE-TTTC INTERNATIONAL CONFERENCE ON AUTOMATION, QUALITY AND TESTING, ROBOTICS, VOL 1, PROCEEDINGS, P448
   Chen D, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-370
   Chen P, 2016, J CHINESE AGR MECH, V12, P144
   Cooper C, 2017, RES SYNTH METHODS, V3, P1102
   Du JH, 2017, J COMPUT SCI-NETH, V21, P195, DOI 10.1016/j.jocs.2017.06.010
   He W, 2013, INT J INFORM MANAGE, V33, P464, DOI 10.1016/j.ijinfomgt.2013.01.001
   Huh J, 2013, J BIOMED INFORM, V46, P998, DOI 10.1016/j.jbi.2013.08.011
   Kopf S, 2005, STORAGE RETRIEVAL ME
   Lin YS, 2014, IEEE T KNOWL DATA EN, V26, P1575, DOI 10.1109/TKDE.2013.19
   Luss R, 2015, QUANT FINANC, V15, P999, DOI 10.1080/14697688.2012.672762
   Ma L, 2012, J CONVERGENCE INFORM, V7, P74, DOI [10.4156/jcit.vol7.issue11.10, DOI 10.4156/JCIT.VOL7.ISSUE11.10]
   Mostafa MM, 2013, EXPERT SYST APPL, V40, P4241, DOI 10.1016/j.eswa.2013.01.019
   Murtagh F, 2016, J CLASSIF, V33, P6, DOI 10.1007/s00357-016-9196-4
   Nassirtoussi AK, 2014, EXPERT SYST APPL, V41, P7653, DOI 10.1016/j.eswa.2014.06.009
   Sarker A, 2015, J BIOMED INFORM, V53, P196, DOI 10.1016/j.jbi.2014.11.002
   SCHIMINOVICH S, 1971, INFORM STORAGE RET, V6, P417, DOI 10.1016/0020-0271(71)90008-8
   Uysal AK, 2014, INFORM PROCESS MANAG, V50, P104, DOI 10.1016/j.ipm.2013.08.006
   Weldon SP, 2013, ISIS, V104, P540, DOI 10.1086/673273
   Wu Desheng., 2006, International Journal of Data Warehousing and Mining, V2, P16
NR 20
TC 2
Z9 2
U1 1
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 13-14
BP 9283
EP 9297
DI 10.1007/s11042-019-7400-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA LB9LP
UT WOS:000524950600052
DA 2024-07-18
ER

PT J
AU Goel, N
   Kaur, H
   Saxena, J
AF Goel, Navdeep
   Kaur, Harpreet
   Saxena, Jyoti
TI Modified decision based unsymmetric adaptive neighborhood trimmed mean
   filter for removal of very high density salt and pepper noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Salt and pepper noise; Partial trimmed global mean; Modified winsorized
   mean; Non linear filters
ID IMAGE QUALITY ASSESSMENT
AB In this paper, a novel and efficient algorithm, Modified Decision Based Unsymmetric Adaptive Neighborhood Trimmed Mean Filter, for removal of very high density salt and pepper noise (SPN) is proposed. The proposed technique comprises of two phases. The first phase involves the fusion of decision based partial trimmed global mean filter, decision based unsymmetric trimmed modified Winsorized mean filter and decision based adaptive neighborhood median filter which takes the benefits of partial trimmed global mean, unsymmetric trimmed modified Winsorized mean and neighborhood pixel technique. The second phase is applied to wipe out the left over noisy pixels by replacing the processing pixel with the Winsorized mean of the first ordered neighborhood pixels. The proposed algorithm is examined upto 99% levels of salt and pepper noise for grey scale and color bitmap images and it gives better Peak Signal to Noise Ratio (PSNR), Image Enhancement Factor (IEF) and Structural Similarity Index (SSIM) values for high noise densities.
C1 [Goel, Navdeep] Punjabi Univ, Yadavindra Coll Engn, Guru Kashi Campus, Talwandi Sabo 151302, Punjab, India.
   [Kaur, Harpreet] RP World Telecom Pvt Ltd, Chandigarh 160022, India.
   [Saxena, Jyoti] MRSPTU, Giani Zail Singh Campus Coll Engn & Technol, Bathinda 151001, Punjab, India.
C3 Punjabi University
RP Goel, N (corresponding author), Punjabi Univ, Yadavindra Coll Engn, Guru Kashi Campus, Talwandi Sabo 151302, Punjab, India.
EM navdeepgoel@pbi.ac.in
RI Kaur, Harpreet/HTN-0358-2023
OI Goel, Navdeep/0000-0001-5485-7999
CR Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   Astola J., 1997, FUNDAMENTALS NONLINE, V8
   Bhadouria VS, 2014, SIGNAL IMAGE VIDEO P, V8, P71, DOI 10.1007/s11760-013-0487-5
   BOVIK AC, 1987, IEEE T ACOUST SPEECH, V35, P493, DOI 10.1109/TASSP.1987.1165153
   BOVIK AC, 1987, IEEE T PATTERN ANAL, V9, P181, DOI 10.1109/TPAMI.1987.4767894
   Bovik A, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, pV, DOI 10.1016/B978-012119792-6/50062-0
   Brown C. E., 1998, Applied Multivariate Statistics in Geohydrology and Related Sciences, P155, DOI [DOI 10.1007/978-3-642-80328-413, 10.1007/978-3-642-80328-4, DOI 10.1007/978-3-642-80328-4_13]
   Christo MS, 2020, MULTIMED TOOLS APPL, V79, P415, DOI 10.1007/s11042-019-08124-9
   Djurovic I, 2017, SIGNAL IMAGE VIDEO P, V11, P753, DOI 10.1007/s11760-016-1019-x
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Gabarda S, 2018, J VIS COMMUN IMAGE R, V52, P101, DOI 10.1016/j.jvcir.2018.02.008
   Goel N, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P315
   Hendricks WA, 1936, ANN MATH STAT, V7, P129, DOI 10.1214/aoms/1177732503
   Hossain MS, 2019, INT J HYDROGEN ENERG, V44, P14571, DOI 10.1016/j.ijhydene.2019.04.028
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   Jayaraj V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/690218
   Nair MS, 2012, SIGNAL IMAGE VIDEO P, V6, P579, DOI 10.1007/s11760-010-0186-4
   Raza M.T., 2012, P IEEE INT C ENG NUI, P1
   Samantaray AK, 2015, PROCEDIA COMPUT SCI, V48, P222, DOI 10.1016/j.procs.2015.04.174
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Vasanth K, 2015, PROCEDIA COMPUT SCI, V54, P595, DOI 10.1016/j.procs.2015.06.069
   Vasanth K, 2015, SIGNAL IMAGE VIDEO P, V9, P1833, DOI 10.1007/s11760-014-0665-0
   Veerakumar T., 2012, INT J COMPUTER APPL, V39, P29, DOI DOI 10.5120/4874-7303
NR 24
TC 7
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19739
EP 19768
DI 10.1007/s11042-020-08687-y
EA MAR 2020
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000522013800001
DA 2024-07-18
ER

PT J
AU Pak, M
   Bayazit, U
AF Pak, Mesut
   Bayazit, Ulug
TI Regional bit allocation with visual attention and distortion sensitivity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual attention; Visual distortion sensitivity; Fixation duration; Bit
   allocation; Texture; Edge; JPEG2000; Image coding
ID CODING SYSTEM; VIDEO; FOVEATION; MODEL
AB This paper proposes a regional rate allocation method for enhancing the perceived quality in image compression. Bit allocation to image regions should be performed by considering the viewer's attention and distortion sensitivity maps in order to address subjective quality concerns. The paper first proposes an exponential model for the relation between the viewer's fixation duration and perceived information. The human visual system is more sensitive to the distortion around edges than the distortion in complex textured regions. Therefore, a novel distortion sensitivity method is also proposed that distinguishes true edges from complex textures without using edge detectors or gradient magnitude thresholds. The estimates for the visual attention level and the distortion sensitivity level are jointly used to modify the distortion contribution of each codeblock for determining its quantization parameter. The experiments validate the improved perceptual quality of decoded images due to the integrated use of the visual distortion sensitivity and the visual attention level in bit allocation. Moreover, the proposed bit allocation method is experimentally shown to yield a substantially higher subjective evaluation score than the other well-known bit allocation methods based on post-compression rate-distortion optimization, saliency maps, foveation of fixations and foveated just-noticeable-difference maps.
C1 [Pak, Mesut; Bayazit, Ulug] Istanbul Tech Univ, Dept Comp Engn, Istanbul, Turkey.
C3 Istanbul Technical University
RP Pak, M (corresponding author), Istanbul Tech Univ, Dept Comp Engn, Istanbul, Turkey.
EM pakme@itu.edu.tr
RI Bayazit, Ulug/ABB-2362-2020
OI Bayazit, Ulug/0000-0001-6556-4104; Pak, Mesut/0000-0001-6017-414X
CR Acharya T, 2005, JPEG2000 STAND IMG C
   Agrafiotis D, 2006, SIGNAL PROCESS-IMAGE, V21, P531, DOI 10.1016/j.image.2006.02.003
   Alshawi T, 2018, IEEE T IMAGE PROCESS, V27, P2818, DOI 10.1109/TIP.2018.2813159
   Battiato S, 2002, IEEE T CONSUM ELECTR, V48, P400, DOI 10.1109/TCE.2002.1037021
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bradley AP, 2003, J VIS COMMUN IMAGE R, V14, P232, DOI 10.1016/S1047-3203(03)00037-3
   Bylinskii Zoya, 2012, MIT saliency benchmark
   Chandler DM, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/649316
   Chen Z., 2010, CIRC SYS VID TECH IE, V20, P1105
   Cormack LK, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P325, DOI 10.1016/B978-012119792-6/50083-8
   Daly S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P443, DOI 10.1109/ICIP.1998.727233
   Franzen R., 2004, KODAK LOSSLESS TRUE
   Guan YY, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P151, DOI 10.1109/SERA.2017.7965721
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Hosu V, 2016, PICT COD SYMP
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Hu YS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1079
   Ishikura K, 2018, IEEE T IMAGE PROCESS, V27, P703, DOI 10.1109/TIP.2017.2767288
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2004, P SOC PHOTO-OPT INS, V5292, P272, DOI 10.1117/12.527057
   ITU, 2016, REC ITU T P 913 TERM
   ITU, 2012, ITU T T 800 INF TECH
   ITU-R, 2002, ITU R BT 500 11 METH
   ITU-R, 2012, GEN VIEW COND SUBJ A
   Jia S., 2018, ARXIV180501047
   Jiang M, 2014, SALIENCY CROWD
   JIANG M, 2015, PROC CVPR IEEE, P1072, DOI DOI 10.1109/CVPR.2015.7298710
   Judd T., 2012, A benchmark of computational models of saliency to predict human fixations
   Kortum P, 1996, P SOC PHOTO-OPT INS, V2657, P350, DOI 10.1117/12.238732
   Kummerer M, 2016, ARXIV16101563
   Kuo-Cheng Liu, 2011, Proceedings 2011 Fourth International Conference on Information Management, Innovation Management and Industrial Engineering (ICIII 2011), P442, DOI 10.1109/ICIII.2011.387
   Li YM, 2016, J VIS COMMUN IMAGE R, V40, P600, DOI 10.1016/j.jvcir.2016.07.025
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Liang Z, 2010, IEEE IMAGE PROC, P1105, DOI 10.1109/ICIP.2010.5651804
   Liu Z, 2006, IEEE T IMAGE PROCESS, V15, P1763, DOI 10.1109/TIP.2006.873460
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Manohar SG, 2013, FRONT HUM NEUROSCI, V7, DOI 10.3389/fnhum.2013.00711
   Mantiuk RK, 2012, COMPUTER GRAPHICS FO
   Rahul K, 2018, IET IMAGE PROCESS, V12, P1142, DOI 10.1049/iet-ipr.2017.0554
   Rawzor, 2008, NEW IM COMPR TEST SE
   Tan DM, 2010, IEEE T IMAGE PROCESS, V19, P374, DOI 10.1109/TIP.2009.2033625
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Tang CW, 2004, IEEE IMAGE PROC, P3225
   Tao DP, 2018, IEEE T IMAGE PROCESS, V27, P325, DOI 10.1109/TIP.2017.2762588
   Vargic R, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061610
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2001, IEEE T IMAGE PROCESS, V10, P1397, DOI 10.1109/83.951527
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Xia Q, 2012, IET IMAGE PROCESS, V6, P910, DOI 10.1049/iet-ipr.2011.0174
   Yang XK, 2005, IEEE T CIRC SYST VID, V15, P742, DOI 10.1109/TCSVT.2005.848313
   Zhang LB, 2017, IEEE GEOSCI REMOTE S, V14, P23, DOI 10.1109/LGRS.2016.2623670
   Zhang Z, 2017, Comput. Modern., V2017, P1, DOI DOI 10.1016/J.SCIT0TENV.2017.01.179
NR 54
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 27-28
BP 19239
EP 19263
DI 10.1007/s11042-020-08686-z
EA MAR 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA MY6SM
UT WOS:000520811300003
DA 2024-07-18
ER

PT J
AU Alshanbari, HS
AF Alshanbari, Hanan S.
TI Medical image watermarking for ownership & tamper detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Discrete wavelet transform; Image security; Robust watermarking; Tamper
   detection; Multiple watermarking
ID SCHEME
AB Image watermarking can provide ownership identification as well as tamper protection. Transform domain based image watermarking has been proven to be more robust than the spatial domain watermarking against different signal processing attacks. On the other hand, tamper detection is found to be working well in spatial domain. In the proposed work, the focus is on the improvement of the medical image watermarking by incorporating the concept of multiple watermarking of the host image. The principal components (PC) based insertion make the scheme secured towards ownership attack. On the other hand, LZW (Lempel-Ziv-Welch) based fragile watermarking is used to hide compressed image's ROI (region of interest) to tackle the intentional tampering attacks. The ROI based watermark generation provides the complete reversibility of the ROI. In this way, proposed scheme provides perfect reversibility of ROI, good imperceptibility in addition to satisfactory robustness. The tamper handing ability of proposed scheme is also tested against various attacks, which turns out to be quite good. The proposed scheme is found to be more useful, when compared with recently proposed schemes in term of features and usefulness.
C1 [Alshanbari, Hanan S.] Umm Al Qura Univ, Coll Comp Sci & Informat Syst, Mecca, Saudi Arabia.
C3 Umm Al Qura University
RP Alshanbari, HS (corresponding author), Umm Al Qura Univ, Coll Comp Sci & Informat Syst, Mecca, Saudi Arabia.
EM hsshanbari@uqu.edu.sa
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   ANDREWS HC, 1976, IEEE T ACOUST SPEECH, V24, P26, DOI 10.1109/TASSP.1976.1162766
   [Anonymous], 2015, International Journal of Emerging Technology and Advanced Engineering
   [Anonymous], 2012, INT J COMP SCI NETW
   Ansari IA, 2018, INT J SYST ASSUR ENG, V9, P274, DOI 10.1007/s13198-016-0568-2
   Ansari IA, 2017, MULTIMED TOOLS APPL, V76, P18001, DOI 10.1007/s11042-016-3680-z
   Badshah G, 2016, J DIGIT IMAGING, V29, P216, DOI 10.1007/s10278-015-9822-4
   Blessie A. A., 2011, INT J COMP SCI ISSUE, V8, P449
   Dugad R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P419, DOI 10.1109/ICIP.1998.723406
   Fatema Mariya, 2018, International Conference on Wireless, Intelligent, and Distributed Environment for Communication. WIDECOM 2018. Lecture Notes on Data Engineering and Communications Technologies (LNDECT 18), P1, DOI [10.1080/1206212X.2018.1517713, 10.1007/978-3-319-75626-4_1]
   Feng B, 2019, IEEE ACCESS, V7, P28031, DOI 10.1109/ACCESS.2018.2875923
   Ganic E, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137650
   Haouzia A, 2008, MULTIMED TOOLS APPL, V39, P1, DOI 10.1007/s11042-007-0154-3
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Ishtiaq M, 2018, IEEE ACCESS, V6, P13213, DOI 10.1109/ACCESS.2018.2803301
   Jane O, 2014, TURK J ELECTR ENG CO, V22, P1354, DOI 10.3906/elk-1212-75
   Khor HL, 2017, J DIGIT IMAGING, V30, P328, DOI 10.1007/s10278-016-9930-9
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Mendel F, 2006, LECT NOTES COMPUT SC, V4047, P126
   Nayak N.R., 2017, INT J APPL EVOLUTION, P1788, DOI [10.4018/IJAEC.2015040104, DOI 10.4018/IJAEC.2015040104]
   [牛少彰 Niu Shaozhang], 2004, [电子与信息学报, Journal of electronics & information technology], V26, P1620
   Qin C, 2018, SIGNAL PROCESS-IMAGE, V60, P160, DOI 10.1016/j.image.2017.10.003
   Rastegar S, 2011, AEU-INT J ELECTRON C, V65, P658, DOI 10.1016/j.aeue.2010.09.008
   Rocek A, 2016, BIOMED SIGNAL PROCES, V29, P44, DOI 10.1016/j.bspc.2016.05.005
   Singh AK, 2015, J MED IMAG HEALTH IN, V5, P607, DOI 10.1166/jmihi.2015.1432
   Thabit R, 2015, DIGIT SIGNAL PROCESS, V38, P77, DOI 10.1016/j.dsp.2014.12.005
   Xiao-Long Liu, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P1047, DOI 10.1109/TCSVT.2016.2633878
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang CE, 2008, IEEE T INF FOREN SEC, V3, P611, DOI 10.1109/TIFS.2008.2004288
   Zhang ZW, 2018, ARAB J SCI ENG, V43, P979, DOI 10.1007/s13369-017-2898-z
NR 31
TC 62
Z9 64
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2021
VL 80
IS 11
BP 16549
EP 16564
DI 10.1007/s11042-020-08814-9
EA MAR 2020
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA SE7XP
UT WOS:000564403600003
DA 2024-07-18
ER

PT J
AU Qu, T
   Li, HY
   Wu, ZS
   Shang, QC
   Wu, JJ
   Kong, WQ
AF Qu, Tan
   Li, Haiying
   Wu, Zhensen
   Shang, Qingchao
   Wu, Jiaji
   Kong, Wanqiu
TI Scattering of aerosol by a high-order Bessel vortex beam for multimedia
   information transmission in atmosphere
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Aerosol; Scattering; High-order Bessel vortex beam; Transmission
ID ORBITAL ANGULAR-MOMENTUM; CLASSICAL ELECTROMAGNETIC SCATTERING; VECTOR
   WAVE ANALYSIS; CONSUMMATE SOLUTION; OPTICAL-PROPERTIES;
   LIGHT-SCATTERING; SPECTRUM; SPHERES; APPROXIMATION; AGGREGATE
AB The essence of wireless communication and multimedia information transmission is the propagation of electromagnetic waves in the atmosphere. Within the framework of Generalized Lorenz Mie theory, and combining the vector wave theory with the generalized multi-spheres Mie theory, the analytical solution to the scattering of the high-order Bessel vortex beam (HOBVB) by aerosol aggregation in atmosphere is investigated. The angle distributions of the scattered field of soot, silicate and nitrate aerosol cluster particles illuminated by a HOBVB are numerically discussed. The examples are selected to illustrate the effects of aggregation configuration, mean value, particle number, topological charge and half-cone angle of the beam on the angle distribution of scattered field. It is noticed that the angle distribution of scattered field is sensitive to the configuration of the cluster for the multiple refraction and interactive scattering. The variation of the mean value of radius of the aerosol aggregation will result in different scattering characteristics and different transmission efficiency. The integration of the scattering algorithm and deep learning can be used in inversion of the shape and components of the aerosol clusters and in the improvement of transmission efficiency of multimedia information in atmosphere.
C1 [Qu, Tan; Wu, Jiaji; Kong, Wanqiu] Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
   [Li, Haiying; Wu, Zhensen; Shang, Qingchao] China Res Inst Radiowave Propagat, Natl Key Lab Electromagnet Environm, Qingdao, Peoples R China.
   [Li, Haiying] Xidian Univ, Sch Phys & Optoelect Engn, Xian 710071, Peoples R China.
C3 Xidian University; Xidian University
RP Qu, T (corresponding author), Xidian Univ, Sch Elect Engn, Xian 710071, Peoples R China.
EM tqu@xidian.edu.cn
RI Wu, Zhenhua/M-9894-2017; kong, wanqiu/E-4341-2016
OI Wu, Zhenhua/0000-0003-4552-883X; kong, wanqiu/0000-0002-9814-2028
FU National Natural Science Foundation of China [61601355, 61571355,
   61701382, 61875156]; China Postdoctoral Science Foundation [2016
   M602770]; National Natural Science Foundation of Shaanxi Province
   [2019JQ-405]; Postdoctoral Science Foundation in Shaanxi Province;
   Fundamental Research Funds for the Central Universities [XJS190209]
FX This research was funded by National Natural Science Foundation of China
   (61601355, 61571355, 61701382, and 61875156), China Postdoctoral Science
   Foundation (2016 M602770), the National Natural Science Foundation of
   Shaanxi Province under Grant no 2019JQ-405, Postdoctoral Science
   Foundation in Shaanxi Province and Fundamental Research Funds for the
   Central Universities (XJS190209).
CR Al Naboulsi M, 2004, OPT ENG, V43, P319, DOI 10.1117/1.1637611
   CHANG H, 1990, P R SOC-MATH PHYS SC, V430, P577, DOI 10.1098/rspa.1990.0107
   Chen LWA, 2003, J AIR WASTE MANAGE, V53, P946, DOI 10.1080/10473289.2003.10466240
   Chu XX, 2011, OPT LETT, V36, P2701, DOI 10.1364/OL.36.002701
   Cincotti G, 2002, J OPT SOC AM A, V19, P1680, DOI 10.1364/JOSAA.19.001680
   DRAINE BT, 1988, ASTROPHYS J, V333, P848, DOI 10.1086/166795
   FULLER KA, 1988, OPT LETT, V13, P1063, DOI 10.1364/OL.13.001063
   FULLER KA, 1988, OPT LETT, V13, P90, DOI 10.1364/OL.13.000090
   Garbin V, 2008, 2008 C LAS EL 2008 C, P1
   Gibson G, 2004, OPT EXPRESS, V12, P5448, DOI 10.1364/OPEX.12.005448
   Gouesbet G, 2017, J QUANT SPECTROSC RA, V201, P229, DOI 10.1016/j.jqsrt.2017.07.023
   Huang C, 2013, ACTA OPT SINICA, V33, DOI 10.3788/AOS201333.0601004
   Iatì MA, 2004, J QUANT SPECTROSC RA, V89, P43, DOI 10.1016/j.jqsrt.2004.05.010
   Jacquier S, 2007, J QUANT SPECTROSC RA, V106, P133, DOI 10.1016/j.jqsrt.2006.12.007
   Jiang YS, 2013, OPT COMMUN, V303, P38, DOI 10.1016/j.optcom.2013.04.013
   Lin J, 2007, APPL OPTICS, V46, P4680, DOI 10.1364/AO.46.004680
   Liu B, 2007, J OPT A-PURE APPL OP, V9, P828, DOI 10.1088/1464-4258/9/10/008
   Liu YD, 2008, OPT EXPRESS, V16, P7091, DOI 10.1364/OE.16.007091
   MEAKIN P, 1983, PHYS REV LETT, V51, P1119, DOI 10.1103/PhysRevLett.51.1119
   Menon S, 2008, ENVIRON RES LETT, V3, DOI 10.1088/1748-9326/3/2/024004
   Mie G, 1908, ANN PHYS-BERLIN, V25, P377, DOI 10.1002/andp.19083300302
   MISHCHENKO MI, 1994, OPT LETT, V19, P1604, DOI 10.1364/OL.19.001604
   MISHRA SR, 1991, OPT COMMUN, V85, P159, DOI 10.1016/0030-4018(91)90386-R
   Mitri FG, 2017, J QUANT SPECTROSC RA, V187, P97, DOI 10.1016/j.jqsrt.2016.09.023
   Mitri FG, 2011, OPT LETT, V36, P606, DOI 10.1364/OL.36.000606
   Mitri F. G., 2017, J PHYS COMMUN, V1
   Mitri FG, 2011, IEEE T ANTENN PROPAG, V59, P4375, DOI 10.1109/TAP.2011.2164228
   Moll F, 2007, P SOC PHOTO-OPT INS, V6709, P70916, DOI 10.1117/12.734269
   Paterson C, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.153901
   PETERSON B, 1973, PHYS REV D, V8, P3661, DOI 10.1103/PhysRevD.8.3661
   PINNICK RG, 1976, J ATMOS SCI, V33, P304, DOI 10.1175/1520-0469(1976)033<0304:SAMIOM>2.0.CO;2
   PURCELL EM, 1973, ASTROPHYS J, V186, P705, DOI 10.1086/152538
   Qu T, 2018, J QUANT SPECTROSC RA, V217, P363, DOI 10.1016/j.jqsrt.2018.06.014
   Reddy SG, 2014, OPT LETT, V39, P4364, DOI 10.1364/OL.39.004364
   Rodríguez I, 2009, ENVIRON GEOL, V56, P1551, DOI 10.1007/s00254-008-1253-9
   ROULEAU F, 1991, ASTROPHYS J, V377, P526, DOI 10.1086/170382
   Simpson NB, 1997, OPT LETT, V22, P52, DOI 10.1364/OL.22.000052
   Wang C, 2015, IEEE T GEOSCI REMOTE, V53, P3442, DOI 10.1109/TGRS.2014.2376957
   Wang C, 2014, IEEE T ANTENN PROPAG, V62, P4664, DOI 10.1109/TAP.2014.2333055
   WITTEN TA, 1983, PHYS REV B, V27, P5686, DOI 10.1103/PhysRevB.27.5686
   Xu YL, 1997, APPL OPTICS, V36, P9496, DOI 10.1364/AO.36.009496
   XU YL, 1995, APPL OPTICS, V34, P4573, DOI 10.1364/AO.34.004573
   Yu MP, 2017, J QUANT SPECTROSC RA, V195, P107, DOI 10.1016/j.jqsrt.2017.01.005
NR 43
TC 6
Z9 6
U1 0
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 34159
EP 34171
DI 10.1007/s11042-020-08773-1
EA MAR 2020
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000563173700001
DA 2024-07-18
ER

PT J
AU Bekhet, S
   Ahmed, A
AF Bekhet, Saddam
   Ahmed, Amr
TI Evaluation of similarity measures for video retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Distance metrics; Similarity measures; Video retrieval; Video matching
ID DISTANCE
AB Similarity measures are very crucial especially in the field of information retrieval. Thus, various distance/similarity measures were proposed throughout the literature. In the video retrieval field, videos are represented as multi-dimensional features vector. Once this features vector is extracted from video shots; the retrieval task is primarily performed based on the measurement of similarity between respective videos' feature vectors. Moreover, the retrieval quality could be greatly improved with careful distance measure selection. This paper presents an extensive analysis regarding the most commonly used video retrieval similarity measures. The results are consolidated with a multifaceted analysis, i.e. multiple challenging video datasets, retrieval curves and confusion matrices. The major contribution of this paper is investigating the effectiveness of the common similarity measures from a video retrieval perspective. This would give the field researchers the required knowledge to select the most suitable distance measure for their video retrieval research work.
C1 [Bekhet, Saddam] South Valley Univ, Qena, Egypt.
   [Ahmed, Amr] Univ Nottingham, Sch Comp Sci, Malaysia Campus, Nottingham, Malaysia.
C3 Egyptian Knowledge Bank (EKB); South Valley University Egypt
RP Bekhet, S (corresponding author), South Valley Univ, Qena, Egypt.
EM saddam.bekhet@gmail.com
RI Bekhet, Saddam/U-7038-2019
OI Bekhet, Saddam/0000-0002-3028-6500
CR Altadmri A, 2014, MULTIMED TOOLS APPL, V72, P1167, DOI 10.1007/s11042-013-1363-6
   [Anonymous], 2006, DISTANCE METRIC LEAR
   [Anonymous], 1975, Taxicab Geometry: An Adventure in Non-Euclidean Geometry
   [Anonymous], 2004, Dictionary of Algorithms and Data Structures
   [Anonymous], 2007, INT J MATH MODELS ME
   Basharat A, 2008, COMPUT VIS IMAGE UND, V110, P360, DOI 10.1016/j.cviu.2007.09.016
   Bekhet S, 2014, T ENG TECHNOLOGIES, P513
   Bekhet S, 2019, J REAL-TIME IMAGE PR, V16, P1999, DOI 10.1007/s11554-017-0700-9
   Bekhet S, 2018, ACM T INFORM SYST, V36, DOI 10.1145/3190784
   Bekhet S, 2018, SIGNAL IMAGE VIDEO P, V12, P291, DOI 10.1007/s11760-017-1157-9
   Bekhet S, 2016, MULTIMED TOOLS APPL, V75, P15763, DOI 10.1007/s11042-015-2887-8
   CHARDY P, 1976, ESTUAR COAST MAR SCI, V4, P179, DOI 10.1016/0302-3524(76)90041-4
   Dubuisson Severine, 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P373, DOI 10.1109/IPTA.2010.5586745
   Jiang LX, 2019, KNOWL INF SYST, V60, P949, DOI 10.1007/s10115-018-1229-3
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Ng CW, 2001, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II, P184
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Sathya N., 2018, International Journal of Advanced Studies in Computer Science and Engineering, V7, P9
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TrecVid, 2011, TREC VID RETR TASK B
   Van Der Heijden F, 2005, CLASSIFICATION PARAM
   Yang L, 2010, IEEE T PATTERN ANAL, V32, P30, DOI 10.1109/TPAMI.2008.273
   Yu J, 2017, IEEE T CYBERNETICS, V47, P4014, DOI 10.1109/TCYB.2016.2591583
   Zhang DS, 2003, PROCEEDINGS OF 2003 INTERNATIONAL CONFERENCE ON NEURAL NETWORKS & SIGNAL PROCESSING, PROCEEDINGS, VOLS 1 AND 2, P928
NR 29
TC 9
Z9 9
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6265
EP 6278
DI 10.1007/s11042-019-08539-4
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900037
DA 2024-07-18
ER

PT J
AU Kumar, A
   Kansal, A
   Singh, K
AF Kumar, Amit
   Kansal, Ankush
   Singh, Kulbir
TI Anti-forensic approach for JPEG compressed images with enhanced image
   quality and forensic undetectability
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image restoration; Anti-forensics; JPEG compression; TV-based
   deblocking; Image tampering; Machine learning-based forensic detectors
ID COSINE
AB Most of the detectors employed in digital image forensics are based on JPEG compression. To determine the capability of these forensic detectors, proficient anti-forensic techniques that challenge and help in the upgradation of forensic techniques are required. This paper proposes an anti-forensic technique based on the shifted block Discrete Fractional Cosine Transform (DFrCT) approach. Afterwards, Total variation (TV) -based deblocking operation is used in order to remove the compression blocking artifacts. Due to the shifted block approach, the proposed method performs histogram smoothing without adding any dithering signal, which means that it is capable of applying dithering by itself. Further, to remove blocking artifacts which are left during the JPEG compression TV-based deblocking is used. The DFrCT approach provides an additional fractional parameter to improve the accuracy of the proposed approach. The proposed scheme is evaluated based on the UCID dataset images by considering the scalar based and machine learning-based forensic detectors. It is observed from the experimental results that the proposed approach provides improved performance in terms of PSNR, SSIM, and forensic undetectability when compared to existing techniques. The analysis performed in this paper challenges the security and robustness of JPEG compression forensic techniques.
C1 [Kumar, Amit; Kansal, Ankush; Singh, Kulbir] TIET, Dept Elect & Commun Engn, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kansal, A (corresponding author), TIET, Dept Elect & Commun Engn, Patiala, Punjab, India.
EM akumar2_phd16@thapar.edu; akansal@thapar.edu; ksingh@thapar.edu
RI Kansal, Ankush/AAM-4521-2020
OI KUMAR, AMIT/0000-0003-0922-2606
CR Alter F, 2005, J MATH IMAGING VIS, V23, P199, DOI 10.1007/s10851-005-6467-9
   [Anonymous], 2013, INT J COMPUT APPL
   [Anonymous], 2011, P INT WORKSHOP DIGIT
   [Anonymous], 2019, MULTIDIM SYST SIGN P
   Arora Manisha, 2014, 2014 9th International Conference on Industrial and Information Systems (ICIIS), P1, DOI 10.1109/ICIINFS.2014.7036615
   Bas Patrick, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P59, DOI 10.1007/978-3-642-24178-9_5
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bohme R., 2012, DIGITAL IMAGE FORENS, P327, DOI [DOI 10.1007/978-1-4614-0757-7_12, 10.1007/978-1-4614-0757-7_12]
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cariolaro G, 2002, IEEE T SIGNAL PROCES, V50, P902, DOI 10.1109/78.992138
   Chutani S, 2019, MULTIMED TOOLS APPL, P1
   Das TK, 2018, MULTIMED TOOLS APPL, V77, P31835, DOI 10.1007/s11042-018-6170-7
   Fan W, 2014, IEEE T INF FOREN SEC, V9, P1211, DOI 10.1109/TIFS.2014.2317949
   Fan W, 2013, INT CONF ACOUST SPEE, P3058, DOI 10.1109/ICASSP.2013.6638220
   Fan ZG, 2003, IEEE T IMAGE PROCESS, V12, P230, DOI 10.1109/TIP.2002.807361
   Gerek ON, P IEEE BALKAN C SIGN
   Jindal N, 2014, IMAGING SCI J, V62, P265, DOI 10.1179/1743131X13Y.0000000062
   Kamenicky J, 2018, J SIGNAL PROCESS SYS, P1
   Kim D, 2018, IEEE SIGNAL PROC LET, V25, DOI 10.1109/LSP.2017.2782363
   Kumar A, 2019, MIN TECHNOL, V128, P88, DOI 10.1080/25726668.2019.1575053
   Li HD, 2018, IEEE T CIRC SYST VID, V28, P31, DOI 10.1109/TCSVT.2016.2599849
   Li YM, 2015, IEEE SIGNAL PROC LET, V22, P2219, DOI 10.1109/LSP.2015.2472561
   Lin WS, 2009, IEEE T INF FOREN SEC, V4, P460, DOI 10.1109/TIFS.2009.2024715
   Lohmann AW, 1996, OPT COMMUN, V125, P18, DOI 10.1016/0030-4018(95)00748-2
   Mohit A, 2016, IMPROVED ALGORITHM D
   NARASIMHA MJ, 1978, IEEE T COMMUN, V26, P934, DOI 10.1109/TCOM.1978.1094144
   Pei SC, 2001, IEEE T SIGNAL PROCES, V49, P1198, DOI 10.1109/78.923302
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Shelke PM, 2018, IMAGING SCI J, V66, P169, DOI 10.1080/13682199.2017.1389832
   ShiYue Lai, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P285, DOI 10.1007/978-3-642-24178-9_20
   Singh G, 2019, IEEE T INF FOREN SEC, V14, P1194, DOI 10.1109/TIFS.2018.2871751
   Singh G, 2017, FORENSIC SCI INT, V277, P133, DOI 10.1016/j.forsciint.2017.06.003
   Stamm MC, 2012, IEEE T INF FOREN SEC, V7, P1315, DOI 10.1109/TIFS.2012.2205568
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Stamm MC, 2010, IEEE IMAGE PROC, P2109, DOI 10.1109/ICIP.2010.5652553
   Stamm MC, 2010, INT CONF ACOUST SPEE, P1694, DOI 10.1109/ICASSP.2010.5495491
   Valenzise G, 2014, IEEE IMAGE PROC, P5337, DOI 10.1109/ICIP.2014.7026080
   Valenzise G, 2011, INT CONF ACOUST SPEE, P1884
   Vapnik V., 2013, The nature of statistical learning theory
   Wang W, 2016, MULTIDIM SYST SIGN P, V27, P541, DOI 10.1007/s11045-015-0318-7
   Wu JH, 2010, OPT COMMUN, V283, P1720, DOI 10.1016/j.optcom.2009.12.066
   Zhang YS, 2018, MULTIDIM SYST SIGN P, V29, P999, DOI 10.1007/s11045-017-0482-z
NR 44
TC 2
Z9 2
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8061
EP 8084
DI 10.1007/s11042-019-08599-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100053
DA 2024-07-18
ER

PT J
AU Naro, D
   Delgado, J
   Llorente, S
AF Naro, Daniel
   Delgado, Jaime
   Llorente, Silvia
TI Reversible fingerprinting for genomic information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Genomic information; Information leakage; MPEG-G;
   Fingerprinting
ID IMAGE WATERMARKING; FORMAT; SEQUENCE
AB New genome sequencing technologies have simplified the generation of genomic data, making them more common but in turn a likely target of attack. Security strategies have been devised such as restricting the amount of information that can be queried or using new encryption techniques. These solutions might not be enough if the entire file has to be shared, as the recipient might leak the accessible information. This contribution addresses this issue using watermarking. Each read in a genomic file is modified depending on its content and a secret key. This allows generating different watermarked instances of the original file. Each watermark acts as a fingerprint: if a leak occurs, the unique modifications of the instance points to who originated the unauthorized publication. Using the key, the modifications can be undone. This allows sharing a leak-discouraging version with which the relevance of a file can be assessed, and can be reversed to the original if needed.
C1 [Naro, Daniel; Delgado, Jaime; Llorente, Silvia] Univ Politecn Cataluna, DAC, BarcelonaTECH, C Jordi Girona 1-3, ES-08034 Barcelona, Spain.
C3 Universitat Politecnica de Catalunya
RP Llorente, S (corresponding author), Univ Politecn Cataluna, DAC, BarcelonaTECH, C Jordi Girona 1-3, ES-08034 Barcelona, Spain.
EM dnaro@ac.upc.edu; jaime.delgado@ac.upc.edu; silviall@ac.upc.edu
RI Delgado, Jaime/AAA-8489-2019; Llorente, Silvia/B-1212-2012
OI Delgado, Jaime/0000-0003-1366-663X; Llorente, Silvia/0000-0003-2000-6912
CR Agarwal N, 2019, MULTIMED TOOLS APPL, V78, P8603, DOI 10.1007/s11042-018-7128-5
   [Anonymous], P 13 WORKSH PRIV GEN
   [Anonymous], ILLUMINA HISEQ 2000
   [Anonymous], ARXIV170801023
   [Anonymous], SCI REPORTS
   [Anonymous], UTAH RESIDENTS CEPH
   Ayday E, 2014, P 13 WORKSH PRIV EL, P11
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Cock PJA, 2010, NUCLEIC ACIDS RES, V38, P1767, DOI 10.1093/nar/gkp1137
   Danecek P, 2011, BIOINFORMATICS, V27, P2156, DOI 10.1093/bioinformatics/btr330
   Delgado J, 2017, STUD HEALTH TECHNOL, V235, P318, DOI 10.3233/978-1-61499-753-5-318
   Fiume M, 2019, NAT BIOTECHNOL, V37, P220, DOI 10.1038/s41587-019-0046-x
   Giakoumaki A, 2006, IEEE T INF TECHNOL B, V10, P722, DOI 10.1109/TITB.2006.875655
   Heider D, 2008, BMC MOL BIOL, V9, DOI 10.1186/1471-2199-9-40
   Heider D, 2007, BMC BIOINFORMATICS, V8, DOI 10.1186/1471-2105-8-176
   Ibaida A, 2011, COMPUT CARDIOL CONF, V38, P393
   Lander ES, 2001, NATURE, V409, P860, DOI 10.1038/35057062
   Leng L, 2017, MULTIMED TOOLS APPL, V76, P8373, DOI 10.1007/s11042-016-3458-3
   Li H, 2009, BIOINFORMATICS, V25, P2078, DOI 10.1093/bioinformatics/btp352
   Metzker ML, 2010, NAT REV GENET, V11, P31, DOI 10.1038/nrg2626
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/502007
   Popa R., 1998, ANAL STEGANOGRAPHIC
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Tang HX, 2016, BMC MED GENOMICS, V9, DOI 10.1186/s12920-016-0224-3
   Venter JC, 2001, SCIENCE, V291, P1304, DOI 10.1126/science.1058040
   Zarrabi H, 2018, IEEE ENG MED BIO, P798, DOI 10.1109/EMBC.2018.8512431
NR 26
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 8161
EP 8180
DI 10.1007/s11042-019-08496-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000523441100058
DA 2024-07-18
ER

PT J
AU Wang, X
   Chang, CC
   Lin, CC
AF Wang, Xu
   Chang, Chin-Chen
   Lin, Chia-Chen
TI Adaptive reversible data hiding scheme for AMBTC compressed images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; AMBTC; Adaptive data hiding scheme; Pixel value
   adjusting strategy
ID HISTOGRAM-MODIFICATION
AB Protecting the security of information transmission over the Internet has become a critical contemporary issue. Compressed images are now widely used in mobile devices and the Internet cloud due to low storage requirements; therefore, many researchers have treated compressed images as a popular carrier in studies of studied reversible data hiding (RDH) schemes. However, the hiding capacity and image quality offered by the reversible data hiding schemes designed for a compression domain are all still limited. To reverse this situation, this paper presents an adaptive reversible data hiding scheme for absolute moment block truncation coding (AMBTC) compressed image using a pixel-value adjusting strategy. Experimental results confirm that the proposed scheme outperforms in both hiding capacity and image quality compared with prior AMBCT-based RDH schemes.
C1 [Wang, Xu; Chang, Chin-Chen] Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
   [Lin, Chia-Chen] Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
C3 Feng Chia University; Providence University - Taiwan
RP Lin, CC (corresponding author), Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
EM wx1990555@gmail.com; alan3c@gmail.com; mhlin3@pu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023; 王, 旭/JAX-6722-2023; 王, 旭/GPX-0697-2022
OI Lin, Chia-Chen/0000-0003-4480-7351
CR [Anonymous], 2019, IEEE T CIRCUITS SYST
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Chang CC, 2009, SOFT COMPUT, V13, P321, DOI 10.1007/s00500-008-0332-x
   Chen Yung-Yao, 2023, Journal of Ambient Intelligence and Humanized Computing, P14785, DOI 10.1007/s12652-018-1048-0
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Hong W, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P13, DOI 10.1109/CISP.2008.638
   Kim C, 2018, DISPLAYS, V55, P71, DOI 10.1016/j.displa.2018.04.002
   Kim C, 2018, J REAL-TIME IMAGE PR, V14, P101, DOI 10.1007/s11554-016-0641-8
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Liao X, 2017, SIGNAL PROCESS-IMAGE, V58, P146, DOI 10.1016/j.image.2017.07.006
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Lou DC, 2009, COMPUT STAND INTER, V31, P329, DOI 10.1016/j.csi.2008.05.009
   Malik A, 2018, MULTIDIM SYST SIGN P, V29, P1801, DOI 10.1007/s11045-017-0530-8
   Mohammad Nur, 2011, Information Technology Journal, V10, P1415, DOI 10.3923/itj.2011.1415.1420
   Huynh NT, 2018, MULTIMED TOOLS APPL, V77, P5767, DOI 10.1007/s11042-017-4487-2
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2012, SIGNAL PROCESS, V92, P54, DOI 10.1016/j.sigpro.2011.06.006
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Potlapally NR, 2006, IEEE T MOBILE COMPUT, V5, P128, DOI 10.1109/TMC.2006.16
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang MW, 2016, OPTIK, V127, P471, DOI 10.1016/j.ijleo.2015.09.216
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   Wang K, 2013, J SYST SOFTWARE, V86, P1965, DOI 10.1016/j.jss.2013.03.083
   Wu M, 2004, IEEE T MULTIMEDIA, V6, P528, DOI 10.1109/tmm.2004.830814
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yang B, 2005, Proceedings of the Fifth IASTED International Conference on Visualization, Imaging, and Image Processing, P298
   Yin Z., 2018, MULTIMED TOOLS APPL, P1
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
   Zhao Z, 2012, INT J DIGIT CONTENT, V6
NR 33
TC 11
Z9 11
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6547
EP 6568
DI 10.1007/s11042-019-08237-1
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900050
DA 2024-07-18
ER

PT J
AU Zhang, QY
   Ge, ZX
   Hu, YJ
   Bai, J
   Huang, YB
AF Zhang, Qiu-yu
   Ge, Zi-xian
   Hu, Ying-jie
   Bai, Jian
   Huang, Yi-bo
TI An encrypted speech retrieval algorithm based on Chirp-Z transform and
   perceptual hashing second feature extraction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encrypted speech retrieval; Perceptual hashing; Chirp-Z transform;
   Sparse random matrix; Speech clustering; Speech denoising
AB In order to satisfy the requirements of retrieval time-efficiency and security for encrypted speech data retrieval in the cloud environment, and to improve the impact of noise on the robustness and discrimination for the speech perceptual hashing scheme, an encrypted speech retrieval algorithm based on Chirp-Z transform and perceptual hashing second feature extraction is proposed in this paper. The speech owner first processes the original speech file by pre-processing, framing, and adding window. The features of the original speech file is extracted by Chirp-Z transform combined with the sparse random matrix to construct a hash sequence. Then encrypt the original speech file based on the m sequence and upload it to the cloud to ensure the security of information. By processing the speech perceptual hashing feature, the speech features are re-extracted, and the speech is evenly classified by k-means clustering technique. The binary string of several hundred bits is converted into a decimal number. Finally, the second feature is stored in system hash index table of the cloud. When the user retrieves, the query speech is denoised and the hash sequence is extracted. Then the secondary features of the hash sequence are extracted and matched with the encrypted speech features in the cloud system hash index table to obtain the retrieval result. The experimental results show that the proposed algorithm greatly compresses the information capacity of speech features, significantly improves the retrieval time-efficiency, with strong robustness and discrimination, and has a good retrieval effect on noisy speech.
C1 [Zhang, Qiu-yu; Ge, Zi-xian; Hu, Ying-jie; Bai, Jian] Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
   [Huang, Yi-bo] Northwest Normal Univ, Coll Phys & Elect Engn, Lanzhou 730070, Peoples R China.
C3 Lanzhou University of Technology; Northwest Normal University - China
RP Zhang, QY (corresponding author), Lanzhou Univ Technol, Sch Comp & Commun, Lanzhou 730050, Peoples R China.
EM zhangqylz@163.com; zxge727@foxmail.com; modaoshiyan@163.com;
   bai.jian@foxmal.com; huangyibo1982@163.com
RI Zhang, Qiu-yu/V-9223-2019
OI Zhang, Qiu-yu/0000-0003-1488-388X
CR [Anonymous], 2015, DIABETES CARE, V38, pS1, DOI 10.2337/dc15-S001
   [Anonymous], RES SPEECH VERIFICAT
   [Anonymous], 2016 NTERN C INT C I
   [Anonymous], INT J HIGH PERFORM C
   [Anonymous], 2014, STUDY ENCRYPTION TEC
   [Anonymous], STUDY RETRIEVAL ENCR
   Bagwe GR, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1790, DOI 10.1109/ICCSP.2016.7754475
   Bao TT, 2018, LECT NOTES COMPUT SC, V10954, P266, DOI 10.1007/978-3-319-95930-6_25
   Brown S, 2018, IEEE T VEH TECHNOL, V67, P4677, DOI 10.1109/TVT.2018.2790436
   Chen N, 2014, ELECTRON LETT, V50, P241, DOI 10.1049/el.2013.3554
   Glackin C, 2017, INT CONF ACOUST SPEE, P6414, DOI 10.1109/ICASSP.2017.7953391
   Goli-Malekabadi Z, 2016, COMPUT METH PROG BIO, V132, P75, DOI 10.1016/j.cmpb.2016.04.016
   Gui YN, 2014, 28TH INTERNATIONAL SYMPOSIUM ON BALLISTICS, VOLS 1 AND 2, P350
   He SF, 2017, COMPUT SCI INF SYST, V14, P703, DOI 10.2298/CSIS170112024H
   Hermassi H, 2017, MULTIMED TOOLS APPL, V76, P1177, DOI 10.1007/s11042-015-3030-6
   Huang ZY, 2018, PODS'18: PROCEEDINGS OF THE 37TH ACM SIGMOD-SIGACT-SIGAI SYMPOSIUM ON PRINCIPLES OF DATABASE SYSTEMS, P395, DOI 10.1145/3196959.3196977
   Ibrahim A, 2012, 2012 IEEE ASIA-PACIFIC SERVICES COMPUTING CONFERENCE (APSCC), P263, DOI 10.1109/APSCC.2012.59
   Ibtihal M, 2017, INT J CLOUD APPL COM, V7, P27, DOI 10.4018/IJCAC.2017040103
   Lagendijk RL, 2013, IEEE SIGNAL PROC MAG, V30, P82, DOI 10.1109/MSP.2012.2219653
   Lee YJ, 2015, COLLOID INTERFAC SCI, V8, P1, DOI 10.1016/j.colcom.2015.12.002
   [李金凤 Li Jinfeng], 2015, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V38, P89
   Lotia P, 2013, IJRCCT, V2, P579
   Pu Y, 2016, 2016 INTERNATIONAL CONFERENCE ON SMART CITY AND SYSTEMS ENGINEERING (ICSCSE), P197, DOI [10.1109/ICSCSE.2016.49, 10.1109/ICSCSE.2016.0061]
   Qiao G, 2018, OCEANS 2018 MTS/IEEE CHARLESTON
   Shen Zhi-Rong, 2014, Journal of Software, V25, P880
   Su JH, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON GRANULAR COMPUTING (GRC), P259, DOI 10.1109/GRC.2014.6982846
   Thangavel M, 2016, 2016 INT C REC TREND, P1, DOI DOI 10.1109/ICRTIT.2016.7569581
   Vavrek J, 2018, J INTELL INF SYST, V51, P439, DOI 10.1007/s10844-018-0499-2
   Wang K, 2013, SIXTH INTERNATIONAL CONFERENCE ON NONLINEAR MECHANICS (ICNM-VI), P423
   Wang W, 2016, VLDB J, V25, P79, DOI 10.1007/s00778-015-0391-4
   Yao SS, 2016, 2016 IEEE SECOND INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P307, DOI 10.1109/BigMM.2016.27
   Zhang KJ, 2016, 2016 INTERNATIONAL CONFERENCE ON NETWORK AND INFORMATION SYSTEMS FOR COMPUTERS (ICNISC), P274, DOI 10.1109/ICNISC.2016.66
   Zhang QY, 2019, MULTIMED TOOLS APPL, V78, P17825, DOI 10.1007/s11042-019-7180-9
   [张秋余 Zhang Qiuyu], 2016, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V39, P77
   [张兴忠 Zhang Xingzhong], 2015, [计算机研究与发展, Journal of Computer Research and Development], V52, P2025
   Zhao H, 2016, 2016 12TH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (ICNC-FSKD), P1840, DOI 10.1109/FSKD.2016.7603458
   Zkik K, 2017, INT J CLOUD APPL COM, V7, P62, DOI 10.4018/IJCAC.2017040105
NR 37
TC 11
Z9 13
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6337
EP 6361
DI 10.1007/s11042-019-08450-y
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000519969900040
DA 2024-07-18
ER

PT J
AU Shanthakumar, VA
   Peng, C
   Hansberger, J
   Cao, LZ
   Meacham, S
   Blakely, V
AF Shanthakumar, Vaidyanath Areyur
   Peng, Chao
   Hansberger, Jeffrey
   Cao, Lizhou
   Meacham, Sarah
   Blakely, Victoria
TI Design and evaluation of a hand gesture recognition approach for
   real-time interactions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture-based interactive system; Motion tracking; Gesture recognition
ID HUMAN-COMPUTER INTERACTION; INDEPENDENCE; ACCEPTANCE; MODEL
AB Hand gestures are a natural and intuitive form for human-environment interaction and can be used as an input alternative in human-computer interaction (HCI) to enhance usability and naturalness. Many existing approaches have employed vision -based systems to detect and recognize hand gestures. However, vision-based systems usually require users to move their hands within restricted space, where the optical device can capture the motion of hands. Also, vision-based systems may suffer from self-occlusion issues due to sophisticated finger movements. In this work, we use a sensor-based motion tracking system to capture 3D hand and finger motions. To detect and recognize hand gestures, we propose a novel angular-velocity method, which is directly applied to real-time 3D motion data streamed by the sensor-based system. Our approach is capable of recognizing both static and dynamic gestures in real-time. We assess the recognition accuracy and execution performance with two interactive applications that require gesture input to interact with the virtual environment. Our experimental results show high recognition accuracy, high execution performance, and high-levels of usability.
C1 [Shanthakumar, Vaidyanath Areyur] Univ Alabama, Comp Sci Dept, Huntsville, AL 35899 USA.
   [Peng, Chao; Cao, Lizhou] Rochester Inst Technol, Golisano Coll Comp & Informat Sci, 1 Lomb Mem Dr, Rochester, NY 14623 USA.
   [Hansberger, Jeffrey] US Army, Res Lab, Huntsville, AL USA.
   [Meacham, Sarah; Blakely, Victoria] Univ Alabama, SMAP Ctr, Huntsville, AL 35899 USA.
C3 University of Alabama System; University of Alabama Huntsville;
   Rochester Institute of Technology; United States Department of Defense;
   US Army Research, Development & Engineering Command (RDECOM); US Army
   Research Laboratory (ARL); University of Alabama System; University of
   Alabama Huntsville
RP Peng, C (corresponding author), Rochester Inst Technol, Golisano Coll Comp & Informat Sci, 1 Lomb Mem Dr, Rochester, NY 14623 USA.
EM cxpigm@rit.edu
OI Peng, Chao/0000-0001-8838-2469
FU DOD [W911NF-16-2-0016]
FX This work was supported by DOD grant W911NF-16-2-0016. We thank
   anonymous reviewers for their comments. We thank the people who
   participated in the user study.
CR Aigner R, 2012, TECH REP
   Alavi S, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050605
   [Anonymous], 2011, P SANDB 11
   Bangor A, 2009, J USABILITY STUD, V4, P114
   Brodie M., 2008, Sports Technol, V1, P17, DOI [DOI 10.1080/19346182.2008.9648447, 10.1002/jst.6, DOI 10.1002/JST.6]
   Brooke J., 1996, USABILITY EVALUATION, P189, DOI DOI 10.1201/9781498710411-35
   Cassell J., 1998, Computer Vision in Human-Machine Interaction, P191, DOI DOI 10.1017/CBO9780511569937.013
   Cohen Y, 2008, ANAL VARIANCE STAT D
   DAVIS FD, 1989, MIS QUART, V13, P319, DOI 10.2307/249008
   Diliberti N, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P401, DOI 10.1145/3343031.3350958
   Guna J, 2014, SENSORS-BASEL, V14, P3702, DOI 10.3390/s140203702
   Häger-Ross C, 2000, J NEUROSCI, V20, P8542, DOI 10.1523/JNEUROSCI.20-22-08542.2000
   Hansberger JT, 2019, LECT NOTES COMPUT SC, V11574, P59, DOI 10.1007/978-3-030-21607-8_5
   Hansberger JT, 2017, DISPELLING GORILLA A, P505
   Hauptmann A. G., 1989, SIGCHI Bulletin, P241, DOI 10.1145/67450.67496
   Hummels C, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P591, DOI 10.1109/AFGR.1998.671012
   Hutchins Edwin L, 1985, Human-Computer Interaction, V1, P311, DOI DOI 10.1207/S15327051HCI0104_2
   Kessler GD., 1995, ACM Transactions on Computer-Human Interaction, V2, P263
   Kieras D., 2001, CHI 2001 Conference Proceedings. Conference on Human Factors in Computing Systems, P128, DOI 10.1145/365024.365069
   Lang CE, 2004, J NEUROPHYSIOL, V92, P2802, DOI 10.1152/jn.00480.2004
   LEE JT, 1995, IEEE COMPUT GRAPH, V15, P77, DOI 10.1109/38.403831
   Lin J, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P121, DOI 10.1109/HUMO.2000.897381
   Liu K, 2016, J REAL-TIME IMAGE PR, V11, P201, DOI 10.1007/s11554-013-0333-6
   Lu ZY, 2014, IEEE T HUM-MACH SYST, V44, P293, DOI 10.1109/THMS.2014.2302794
   Luzhnica G, 2016, 2016 IEEE SYMPOSIUM ON 3D USER INTERFACES (3DUI), P81, DOI 10.1109/3DUI.2016.7460035
   Marin G, 2016, MULTIMED TOOLS APPL, V75, P14991, DOI 10.1007/s11042-015-2451-6
   Morris M. R., 2010, P GRAPHICS INTERFACE, P261
   Neto P, 2013, IEEE INT CONF ROBOT, P178, DOI 10.1109/ICRA.2013.6630573
   Nielsen M, 2003, LECT NOTES ARTIF INT, V2915, P409
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Peng C, 2018, 2018 IEEE GAMES, ENTERTAINMENT, MEDIA CONFERENCE (GEM), P453, DOI 10.1109/GEM.2018.8516520
   Peng C, 2017, P IEEE VIRT REAL ANN, P331, DOI 10.1109/VR.2017.7892311
   Ramamoorthy A, 2003, PATTERN RECOGN, V36, P2069, DOI 10.1016/S0031-3203(03)00042-6
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Sharma RP, 2015, PROCEDIA COMPUT SCI, V54, P721, DOI 10.1016/j.procs.2015.06.085
   Siek KA, 2005, LECT NOTES COMPUT SC, V3585, P267, DOI 10.1007/11555261_24
   Song Y, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133371
   Venkatesh V, 2000, MANAGE SCI, V46, P186, DOI 10.1287/mnsc.46.2.186.11926
   Vogel Daniel., 2012, Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, CHI'12, P2307, DOI [10.1145/2207676.2208390, DOI 10.1145/2207676.2208390]
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wobbrock JO, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P1083
   Xu DY, 2006, INT C PATT RECOG, P519
NR 43
TC 30
Z9 31
U1 4
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17707
EP 17730
DI 10.1007/s11042-019-08520-1
EA FEB 2020
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516363300004
DA 2024-07-18
ER

PT J
AU Sheela, CJJ
   Suganthi, G
AF Sheela, C. Jaspin Jeba
   Suganthi, G.
TI Morphological edge detection and brain tumor segmentation in Magnetic
   Resonance (MR) images based on region growing and performance evaluation
   of modified Fuzzy C-Means (FCM) algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain tumor segmentation; FCM; Region growing; Magnetic resonance
   imaging; Sobel operator
AB The medical image processing has become indispensable with an increased demand for systematic and efficient detection of brain tumor in a short period of time. There are various techniques for medical image segmentation. Detecting a wide variety of brain images in terms of shape and intensity is a challenging and difficult task to bring out a reliable and authentic data for diagnosing brain tumor diseases. This paper presents an algorithm which combines Region of Interest (ROI), Region Growing and Morphological Operation (Dilation and Erosion). This method initially identifies the approximate Region Growing (RG). Region growing is a procedure that groups pixels into larger regions, which starts from the seed points. Region growing based techniques are better than the edge-based techniques in noisy images where edges are difficult to detect. The Morphological Edge Detection of the input image is done and the input image is reconstructed on the basis of dilation and erosion for the enhancement of the image. The proposed work is divided into preprocessing to reduce the noise, Fuzzy C-Means is used to Region growing, Morphological edge detection is to enhance the image. Then the morphological edge detection can be classified into two categories, one is dilation and another is Erosion. Finally apply Gaussian filter to get output. After that, Fuzzy C-Means clustering (FCM), followed by seeded region growing is applied to detect and segment the tumor from the brain MRI image.
C1 [Sheela, C. Jaspin Jeba] Palayamkottai Manonmaniam Sundaranar Univ, St Xaviers Autonomous Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Suganthi, G.] Nagercoil Manonmaniam Sundaranar Univ, Womens Christian Coll, Dept Comp Sci, Tirunelveli 627012, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Sheela, CJJ (corresponding author), Palayamkottai Manonmaniam Sundaranar Univ, St Xaviers Autonomous Coll, Tirunelveli 627012, Tamil Nadu, India.
EM jaspinjebasheela@gmail.com; dr_suganthi_wcc@yahoo.co.in
CR Abdel-Maksoud E, 2015, EGYPT INFORM J, V16, P71, DOI 10.1016/j.eij.2015.01.003
   [Anonymous], 2005, IEEE T INFORM TECHNO
   BAHADURE NB, 2018, J DIGITAL IMAGING
   Bal A, 2018, J KING SAUD U COMPUT
   BILENIA A, 2019, BRAIN TUMOR SEGMENTA
   CHOUHAN SS, 2018, ARCH COMPUTATIONAL M
   HOODA H, 2014, IEEE INT C ADV COMM
   KAUR T, 2017, AUSTRALASIAN PHYS EN
   KAURET H, 2016, IOSR J COMPUTER ENG, V18, P5
   KHALIFA I, 2012, J COMPUTER APPL, V47
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   LI BN, 2010, COMPUTERS BIOL MED
   MOHAMED NA, 1998, INT C IEEE ENG MED B, V20
   MOUMEN T, 2014, J IMAGE VIDEO PROCES
   PATIL SS, 2017, INT J ENG SCI COMPUT
   PRIYA SS, 2019, EFFICIENT FUZZY C ME
   RAJENDRAN A, 2012, INT J COMPUT COMMUN
   RAJENDRAN A, 2011, RES ARTICLE COMPUTER
   SAHA M, 2018, INT J SCI RES COMPUT, V3, P2456
   SHANKER R, 2018, BRAIN TUMOR SEGMENTA
   SHARMA M, 2013, ADV COMPUTING INFORM
   SHARMA V, 2014, TRENDS LIFE SCI, V3, P5
   SOMPONG C, 2016, INT JOINT C COMP SCI
   SRIKANTH B, 2019, AUTOMATIC BRAIN TUMO
   SRINIVAS B, 2019, PERFORMANCE EVALUATI
   WADGURE S, 2014, INT J SCI ENG TECHNO, P8
NR 26
TC 39
Z9 40
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2020
VL 79
IS 25-26
BP 17483
EP 17496
DI 10.1007/s11042-020-08636-9
EA FEB 2020
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OO9FA
UT WOS:000516490800003
DA 2024-07-18
ER

PT J
AU Altulyan, M
   Yao, LN
   Kanhere, SS
   Wang, XH
   Huang, CR
AF Altulyan, May
   Yao, Lina
   Kanhere, Salil S.
   Wang, Xianzhi
   Huang, Chaoran
TI A unified framework for data integrity protection in people-centric
   smart cities
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things; Smart cities; Blockchain; Data integrity
ID IOT; CLOUD
AB With the rapid increase in urbanisation, the concept of smart cities has attracted considerable attention. By leveraging emerging technologies such as the Internet of Things (IoT), artificial intelligence and cloud computing, smart cities have the potential to improve various indicators of residents' quality of life. However, threats to data integrity may affect the delivery of such benefits, especially in the IoT environment where most devices are inherently dynamic and have limited resources. Prior work has focused on ensuring integrity of data in a piecemeal manner and covering only some parts of the smart city ecosystem. In this paper, we address integrity of data from an end-to-end perspective, i.e., from the data source to the data consumer. We propose a holistic framework for ensuring integrity of data in smart cities that covers the entire data lifecycle. Our framework is founded on three fundamental concepts, namely, secret sharing, fog computing and blockchain. We provide a detailed description of various components of the framework and also utilize smart healthcare as use case.
C1 [Altulyan, May; Yao, Lina; Kanhere, Salil S.; Huang, Chaoran] UNSW, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
   [Wang, Xianzhi] Univ Technol Sydney, Sch Software, POB 123, Broadway, NSW 2007, Australia.
C3 University of New South Wales Sydney; University of Technology Sydney
RP Altulyan, M (corresponding author), UNSW, Sch Comp Sci & Engn, Sydney, NSW 2052, Australia.
EM m.altulyan@student.unsw.edu.au; lina.yao@unsw.edu.au;
   salil.kanhere@unsw.edu.au; xianzhi.wang@uts.edu.au;
   chaoran.huang@unsw.edu.au
RI Wang, Xianzhi/B-5403-2018; Yao, Lina/AAH-5088-2019; Altulyan,
   May/HGB-9572-2022; Huang, Chaoran/E-1640-2015; kanhere,
   salil/ABA-2025-2021
OI Wang, Xianzhi/0000-0001-9582-3445; Yao, Lina/0000-0003-1018-5646; Huang,
   Chaoran/0000-0003-3496-0731; kanhere, salil/0000-0002-1835-3475
CR Alghamdi W., 2017, P 28 IRISH SIGN SYST, P1, DOI [10.1109/ISSC.2017.7983636, DOI 10.1109/ISSC.2017.7983636]
   [Anonymous], 2015, STELLAR DEV FDN
   [Anonymous], DIGITAL COMMUNICATIO
   [Anonymous], 2017, J INFO P SYST
   [Anonymous], 2017, MANAGING WEB THINGS
   [Anonymous], 2018, ARXIV180403903
   Bakici T, 2013, J KNOWL ECON, V4, P135, DOI 10.1007/s13132-012-0084-9
   Baliga A, 2017, PERSISTENT
   Biswas K, 2016, PROCEEDINGS OF 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS; IEEE 14TH INTERNATIONAL CONFERENCE ON SMART CITY; IEEE 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1392, DOI [10.1109/HPCC-SmartCity-DSS.2016.178, 10.1109/HPCC-SmartCity-DSS.2016.0198]
   Chakrabarty Shaibal, 2016, 2016 13th IEEE Annual Consumer Communications & Networking Conference (CCNC), P812, DOI 10.1109/CCNC.2016.7444889
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Dorri Ali, 2017, 2017 IEEE/ACM Second International Conference on Internet-of-Things Design and Implementation (IoTDI), P173, DOI 10.1145/3054977.3055003
   Farooq MU, 2015, INT J COMPUT APPL, V7, P111
   Ferreira C, 2018, CURRENT OPINION ENV
   Gope P, 2016, IEEE SENS J, V16, P1368, DOI 10.1109/JSEN.2015.2502401
   Jararweh Y, 2018, FUTURE GENERATION CO
   Jose Joyce, 2014, CIT. Journal of Computing and Information Technology, V22, P1, DOI 10.2498/cit.1002318
   Li X., 2017, FUTURE GENERATION CO
   Liu B, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P468, DOI 10.1109/ICWS.2017.54
   Liu C, 2015, FUTURE GENER COMP SY, V49, P58, DOI 10.1016/j.future.2014.08.007
   Patil NS, 2010, IEEE INT C COMP INT, V6
   Perera C, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3057266
   Rezvani M, 2015, IEEE T DEPEND SECURE, V12, P98, DOI 10.1109/TDSC.2014.2316816
   Rifi N, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON ADVANCES IN BIOMEDICAL ENGINEERING (ICABME), P198
   Salama U, 2017, 2017 IEEE 24TH INTERNATIONAL CONFERENCE ON WEB SERVICES (ICWS 2017), P878, DOI 10.1109/ICWS.2017.111
   Sandhu RS, 1993, P 7 IFIP WG113 WORKI, P257, DOI [10.5555/646113.758632, DOI 10.5555/646113.758632]
   Sharma PK, 2018, IEEE ACCESS, V6, P115, DOI 10.1109/ACCESS.2017.2757955
   Sivathanu G, 2005, P 2005 ACM WORKSHOP, P26, DOI DOI 10.1145/1103780.1103784
   Song TY, 2017, IEEE INTERNET THINGS, V4, P1844, DOI 10.1109/JIOT.2017.2707489
   Su KH, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P1028, DOI 10.1109/ICECC.2011.6066743
   Yang Y, 2008, ACM T INFORM SYST SE, V11, DOI 10.1145/1380564.1380568
   Yao L, 2016, ACM T INTERNET TECHN, V16, DOI 10.1145/2837024
   Yao L, 2015, IEEE INTERNET COMPUT, V19, P60, DOI 10.1109/MIC.2015.77
   Yi S., 2015, P 2015 WORKSH MOB BI, P37
   Zeng ZQ, 2018, IEEE T IND INFORM, V14, P3179, DOI 10.1109/TII.2017.2767557
   Zheng Z., 2016, BLOCKCHAIN CHALLENGE
NR 36
TC 15
Z9 16
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4989
EP 5002
DI 10.1007/s11042-019-7182-7
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500041
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, AA
   Zhou, HY
   Li, MJ
   Nie, WZ
AF Liu, An-An
   Zhou, He-Yu
   Li, Meng-Jie
   Nie, Wei-Zhi
TI 3D model retrieval based on multi-view attentional convolutional neural
   network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; Multi-view; CNN; LSTM
ID SHAPE DESCRIPTOR
AB We propose a discriminative Multi-View Attentional Convolutional Neural Network, dubbed as MVA-CNN, which takes the multiple views of an shape as input and output the object category. Unlike previous view-based approaches that simply "compile" the view features into a compact 3D descriptors, our method can discover the context among multiple views in both the visual and spatial domain. First, we extract multiple rendered images from a 3D object by virtual cameras, and then we use Convolutional Neural Network (CNN) to abstract the information of the views. Second, we aggregate the visual views by two steps: 1). an element-wise maximum operation across the view features is adopted to discover discriminative features. 2). a soft attention mechanism is used to dynamically adjust the shape descriptors for better representing the spatial information. The entire network can be trained in an end-to-end way with the standard backpropagation. We verify the effectiveness of MVA-CNN on two widely used datasets: ModelNet10, ModelNet40 by comparing our method with state-of-the-art methods.
C1 [Liu, An-An; Zhou, He-Yu; Li, Meng-Jie; Nie, Wei-Zhi] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Liu, AA; Nie, WZ (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM liuanan@tju.edu.cn; zhouheyu@tju.edu.cn; limengjie@tju.edu.cn;
   weizhinie@tju.edu.cn
RI li, mengjie/GRS-3931-2022; Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
CR [Anonymous], 2016, IEEE IJCNN, DOI DOI 10.1109/IJCNN.2016.7727386
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   [Anonymous], 2016, ARXIV160306208
   [Anonymous], ARXIV180400586
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Bosche F, 2008, AUTOMAT CONSTR, V17, P499, DOI 10.1016/j.autcon.2007.09.001
   Cheng Zhiyong, 2018, ARXIV181105318
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Gao Y, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2967502
   Gao Y, 2016, IEEE T MULTIMEDIA, V18, P2115, DOI 10.1109/TMM.2016.2581483
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Guétat G, 2006, IEEE T INF TECHNOL B, V10, P362, DOI 10.1109/TITB.2005.863875
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Ip CY, 2002, P 7 ACM S SOL MOD AP, P273, DOI 10.1145/566282.566322
   Johns E, 2016, PROC CVPR IEEE, P3813, DOI 10.1109/CVPR.2016.414
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Little JJ, 1985, P INT C ART INT AUG, P960
   Liu AA, 2019, IEEE T IMAGE PROCESS, V28, P853, DOI 10.1109/TIP.2018.2872879
   Liu AA, 2018, IEEE T CYBERNETICS, V48, P916, DOI 10.1109/TCYB.2017.2664503
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu SK, 2018, INT CONF 3D VISION, P542, DOI 10.1109/3DV.2018.00068
   Liu W, 2018, NEUROINFORMATICS, V16, P457, DOI 10.1007/s12021-018-9362-4
   Liu W, 2017, J VIS COMMUN IMAGE R, V48, P502, DOI 10.1016/j.jvcir.2017.01.010
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Ma HD, 2018, IEEE MULTIMEDIA, V25, P76, DOI 10.1109/MMUL.2017.265091429
   Makadia A, 2010, INT J COMPUT VISION, V89, P193, DOI 10.1007/s11263-009-0280-7
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Ren M., 2017, ARXIV171110108
   Sfikas Konstantinos, 2017, EUR WORKSH 3D OBJ RE
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tabia H, 2015, IEEE T MULTIMEDIA, V17, P1591, DOI 10.1109/TMM.2015.2457676
   Tangelder JWH, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P119
   Wang XY, 2015, NEUROCOMPUTING, V151, P620, DOI 10.1016/j.neucom.2014.03.091
   Wong HS, 2007, IEEE T MULTIMEDIA, V9, P1026, DOI 10.1109/TMM.2007.898915
   Wu J, 2016, 2016 2ND INTERNATIONAL CONFERENCE ON SOCIAL, EDUCATION AND MANAGEMENT ENGINEERING (SEME 2016), P82
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Zanuttigh P, 2017, IEEE IMAGE PROC, P3615, DOI 10.1109/ICIP.2017.8296956
   Zaremba W., 2014, RECURRENT NEURAL NET, P1, DOI DOI 10.1016/S0893-6080(96)00073-1
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhao X., 2017, IEEE Trans. Reliab., V99, P1
NR 47
TC 7
Z9 8
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 4699
EP 4711
DI 10.1007/s11042-019-7521-8
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500025
DA 2024-07-18
ER

PT J
AU Palanikkumar, D
   Priya, S
AF Palanikkumar, D.
   Priya, S.
TI Ant colony based graph theory (ACGT) and resource virtual network
   mapping (RVNM) algorithm for home healthcare system in cloud environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual network mapping (VNM); Ant colony based graph theory (ACGT);
   Cloud networking; Virtualization; Quality of services (QoS);
   Distributed; Cloud computing (CC); And optimization
ID ALLOCATION
AB In recent decades, new efficient heuristic algorithms are introduced which helps in alleviating both large virtual and physical networks in the case when there are a host of healthcare service providers that are part of the evaluation and analysis. Demarcating virtual resources as separate physical nodes as well as co-localization of prerequisites inherent in physical nodes is relatively time consuming. To solve this problem in this work Ant Colony based Graph Theory (ACGT) is proposed for selection of resources which eliminates infeasible mappings between fundamental and material resources available. The major aim of the study here is to provide better resource allocation mapping. This ACGT additionally in conjunction maps jointly nodes as well as links and offers the most probable optimized solutions. Algorithm here breaks-down the graph as topological sequences that are followed by ACGT to resolve mapping related issues. Any possible mapping occurs only when the virtual node capacity that is requested less in comparison than the remainder candidate physical node capacity and also when virtual link latency is comparatively greater than candidate physical path latency or that of the link. ACGT performance and its precise, heuristic and two-stage algorithms have been analyzed and studied in this cloud environment. All the methods are implemented via the use of JAVA environment and applied to google cloud.
C1 [Palanikkumar, D.] Dr NGP Inst Technol, Dept Informat & Technol, Coimbatore, Tamil Nadu, India.
   [Priya, S.] Coimbatore Inst Technol, Dept Comp Sci & Engn, Coimbatore, Tamil Nadu, India.
C3 Coimbatore Institute of Technology
RP Palanikkumar, D (corresponding author), Dr NGP Inst Technol, Dept Informat & Technol, Coimbatore, Tamil Nadu, India.
EM palanikkumard@gmail.com; dazzlerpriya@gmail.com
RI S, Priya/AAV-9944-2020; D, PALANIKKUMAR/ABG-4845-2021
OI D, PALANIKKUMAR/0000-0001-6607-7252
CR Abu Sharkh M, 2013, IEEE COMMUN MAG, V51, P46, DOI 10.1109/MCOM.2013.6658651
   Alha K., 2014, P NORD DIGRA 2014, P1
   Amazon Web Services, 2014, AMAZON ELASTIC COMPU
   [Anonymous], 2014 16 INT C TRANSP
   [Anonymous], IEEE SYSTEMS J
   [Anonymous], 2014, MICROSOFT AZURE
   Bavier A, 2006, P ACM SIGCOMM, P3, DOI DOI 10.1145/1151659.1159916
   Cao Y, 2017, COMPUT J, V60, P287, DOI 10.1093/comjnl/bxw063
   Chowdhury M, 2012, IEEE ACM T NETWORK, V20, P206, DOI 10.1109/TNET.2011.2159308
   Chowdhury NMMK, 2010, COMPUT NETW, V54, P862, DOI 10.1016/j.comnet.2009.10.017
   Chu SC, 2004, INFORM SCIENCES, V167, P63, DOI 10.1016/j.ins.2003.10.013
   Feamster N, 2007, ACM SIGCOMM COMP COM, V37, P61, DOI 10.1145/1198255.1198265
   Gang Sun, 2012, GLOBECOM 2012 - 2012 IEEE Global Communications Conference, P2517, DOI 10.1109/GLOCOM.2012.6503495
   Jammal M, 2015, 2015 IEEE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, P477, DOI 10.1109/CLOUD.2015.70
   Kim YK, 2003, COMPUT OPER RES, V30, P1151, DOI 10.1016/S0305-0548(02)00063-1
   Li H, 2012, INT CONF COMP SCI ED, P1719, DOI 10.1109/ICCSE.2012.6295397
   Lischka J, 2009, VISA 09, P81, DOI 10.1145/1592648.1592662
   Mechtri M., 2015, IEEE T CLOUD COMPUT, P1
   Papagianni C, 2013, IEEE T COMPUT, V62, P1060, DOI 10.1109/TC.2013.31
   Rimal BP, 2009, P INT C UBIQ INFORM, P448
   Turner JS, 2005, GLOB TELECOMM CONF, P755
   Yu ML, 2008, ACM SIGCOMM COMP COM, V38, P19, DOI 10.1145/1355734.1355737
   Zampelli S, 2010, CONSTRAINTS, V15, P327, DOI 10.1007/s10601-009-9074-3
   Zhu Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P13, DOI 10.1109/ICME.2006.262502
NR 24
TC 5
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3743
EP 3760
DI 10.1007/s11042-018-6908-2
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700035
DA 2024-07-18
ER

PT J
AU Ramesh, GP
   Kumar, NM
AF Ramesh, G. P.
   Kumar, N. Mohan
TI Design of RZF antenna for ECG monitoring using IoT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RZF antenna; ECG; Heart beat rate; Doppler system; Folded arms;
   Radiation pattern; IoT
ID DIPOLE ANTENNA; NONCONTACT
AB The application of smart health by using the Internet of Things as a medium between the transmissions of the Electro-cardio gram signal acquired from the human body to the care takers. We implemented a ECG monitoring system. Here place the electrodes on the surface of the patient's body by time to time. These signals are transferred to the cloud by using the transmission modules which has been implemented using Rectangular Zig Fractional (RZF) antenna. The design and implementation of RZF antenna with triple-band Doppler system for contactless heartbeat monitoring is proposed. It consists of a slotted rectangular shaped ground plane and a modified radiating patch with four-folded arms that integrates microwave transceivers and power amplifier, which occupies a compact size of 12 x 18 mm(2) to be easily embedded within a portable device as an internal antenna. The antenna shows omnidirectional radiation pattern with the gain value of 8.4 dBi, 9.5 dBi and 13.5dBi resonates at 2.4/3.5/5.8 GHz with the stability factor greater than 1 and the 50 omega impedance matching with Smith Chart is achieved. The RZF Antenna system is satisfactory for monitoring heart beat and heart beat rate variability vital signs. The antenna is tested at 2.4/3.5/5.8 GHz frequency for transmitted power levels ranges 0 dBm and-5 dBm. With Doppler system, the heart beat rate and heart rate variability are acquired from the reflected signals and compared to the simultaneous ECG signals and the information of HR and HRV is then transferred to the receiver or doctor end by means of IoT server.
C1 [Ramesh, G. P.] Anna Univ, Chennai, Tamil Nadu, India.
   [Kumar, N. Mohan] SKP Engn Coll, Dept ECE, Tiruvanamalai, India.
C3 Anna University; Anna University Chennai
RP Ramesh, GP (corresponding author), Anna Univ, Chennai, Tamil Nadu, India.
EM gpramesh75@gmail.com; nmkskpec@gmail.com
RI Ramesh, GP/AAM-5596-2020; N, Mohankumar/AFT-5100-2022
OI Ramesh, GP/0000-0002-6470-4029; N, Mohankumar/0000-0002-9766-8802
CR [Anonymous], IEEE AP S INT S
   [Anonymous], IEEE T
   [Anonymous], IEEE T ANTENNAS PROP
   Asthana S, 2017, 2017 IEEE 6TH INTERNATIONAL CONFERENCE ON AI & MOBILE SERVICES (AIMS), P14, DOI 10.1109/AIMS.2017.11
   Chen XX, 2014, 2014 38TH ANNUAL IEEE INTERNATIONAL COMPUTER SOFTWARE AND APPLICATIONS CONFERENCE WORKSHOPS (COMPSACW 2014), P662, DOI 10.1109/COMPSACW.2014.111
   Garbey M, 2007, IEEE T BIO-MED ENG, V54, P1418, DOI 10.1109/TBME.2007.891930
   Kuo FY, 2010, IEEE T ANTENN PROPAG, V58, P2737, DOI 10.1109/TAP.2010.2050434
   Liu S, 2014, IEEE T ANTENN PROPAG, V62, P4895, DOI 10.1109/TAP.2014.2335816
   Nazli H, 2010, IEEE ANTENN WIREL PR, V9, P264, DOI 10.1109/LAWP.2010.2046999
   Neyja M, 2017, IEEE GLOB COMM CONF
   Penzel T, 2003, IEEE T BIO-MED ENG, V50, P1143, DOI 10.1109/TBME.2003.817636
   Poh MZ, 2011, IEEE T BIO-MED ENG, V58, P7, DOI 10.1109/TBME.2010.2086456
   Shambavi K, 2010, IEEE ANTENN WIREL PR, V9, P1029, DOI 10.1109/LAWP.2010.2089966
   Shao DD, 2014, IEEE T BIO-MED ENG, V61, P2760, DOI 10.1109/TBME.2014.2327024
   Wu Q, 2010, IEEE T ANTENN PROPAG, V58, P3839, DOI 10.1109/TAP.2010.2078465
NR 15
TC 3
Z9 3
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4011
EP 4026
DI 10.1007/s11042-019-7581-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700051
DA 2024-07-18
ER

PT J
AU Sun, L
   Al Osman, H
   Lang, J
AF Sun, Lu
   Al Osman, Hussein
   Lang, Jochen
TI A hybrid remote rendering method for mobile applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote rendering; Mobile computing; User study
ID 3D GRAPHICS; SCREEN; SCENES
AB We present a hybrid remote rendering method for applications on mobile devices. In our remote rendering approach, we adopt a client-server model, where the server is responsible for rendering high-fidelity models, encoding the rendering results and sending them to the client, while the client renders low-fidelity models and overlays the high-fidelity frames received from the server on its rendering results. With this configuration, we are able to minimize the bandwidth requirements and interaction latency, since only key models are rendered in high-fidelity mode. We perform a quantitive analysis on the effectiveness of our method. Moreover, we conduct a user study on the subjective and objective effects of our method on the user experience. The results show that key model fidelity has a significant influence on the objective difficulty, while interaction latency plays an important role in the subjective difficulty. The results of the user study show how our method can benefit the users while minimizing resource requirements.
C1 [Sun, Lu; Al Osman, Hussein; Lang, Jochen] Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Lang, J (corresponding author), Univ Ottawa, Sch Elect Engn & Comp Sci, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM lsun100@uottawa.ca; halosman@uottawa.ca; jlang@eecs.uottawa.ca
CR [Anonymous], 2015, PROC 7 INT WORKSHOP
   Bao P, 2006, IEEE T MULTIMEDIA, V8, P382, DOI 10.1109/TMM.2005.864337
   Bao P, 2006, IEEE T MULTIMEDIA, V8, P444, DOI 10.1109/TMM.2006.870746
   Boukerche A., 2006, ACM Multimedia, P691, DOI DOI 10.1145/1180639.1180785
   Cecil J., 2013, 2013 IEEE International Conference on Automation Science and Engineering (CASE), P133, DOI 10.1109/CoASE.2013.6654045
   Chang CF, 2002, LECT NOTES COMPUT SC, V2532, P1105
   Chang CL, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1623, DOI 10.1109/ICME.2004.1394561
   Chen KT, 2014, IEEE T MULTIMEDIA, V16, P480, DOI 10.1109/TMM.2013.2291532
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Crassin Cyril., 2015, Journal of Computer Graphics Techniques Vol, V4, P1
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   Hemmati M., 2013, Proceeding of the 23rd ACM Workshop on Network and Operating Systems Support for Digital Audio and Video, P7
   Hong HJ, 2015, IEEE T CIRC SYST VID, V25, P2078, DOI 10.1109/TCSVT.2015.2450173
   Lamberti F, 2007, IEEE T VIS COMPUT GR, V13, P247, DOI 10.1109/TVCG.2007.29
   Levoy M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P21, DOI 10.1145/218380.218392
   Liu C, 2017, SIGSIM-PADS'17: PROCEEDINGS OF THE 2017 ACM SIGSIM CONFERENCE ON PRINCIPLES OF ADVANCED DISCRETE SIMULATION, P221, DOI 10.1145/3064911.3064933
   Liu Y, 2014, IEEE J EM SEL TOP C, V4, P43, DOI 10.1109/JETCAS.2014.2298921
   Lu Y, 2011, IEEE MULTIMEDIA, V18, P4, DOI 10.1109/MMUL.2011.33
   Lu Y, 2017, MULTIMED TOOLS APPL, V76, P18291, DOI 10.1007/s11042-016-3798-z
   Ma Z, 2017, IEEE T MULTIMEDIA, V19, P2322, DOI 10.1109/TMM.2017.2737944
   Noimark Y, 2003, IEEE COMPUT GRAPH, V23, P58, DOI 10.1109/MCG.2003.1159614
   Shi S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2719921
   Shi S, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2348816.2348825
   Simoens P, 2012, MULTIMED TOOLS APPL, V61, P447, DOI 10.1007/s11042-011-0849-3
   Suznjevic M., 2016, P 8 INT C QUAL MULT, P1, DOI DOI 10.1109/QOMEX.2016.7498968
   Zhu WW, 1998, IEEE T CIRC SYST VID, V8, P9, DOI 10.1109/76.660823
NR 26
TC 3
Z9 3
U1 2
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 3333
EP 3358
DI 10.1007/s11042-019-7306-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700014
DA 2024-07-18
ER

PT J
AU Suresh, K
   Sakthi, U
AF Suresh, K.
   Sakthi, U.
TI A soft-computing based hybrid tool to extract the tumour section from
   brain MRI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain MRI; Tumour extraction; Social group optimization; Shannon's
   entropy; Picture similarity measures
ID ACTIVE CONTOUR; SEGMENTATION; OPTIMIZATION; ALGORITHM; ENTROPY; IMAGES
AB In recent days, examination of medical images had been carried out using a number of image processing tools, specifically implemented for such purposes. This proposed work is based on a hybrid image processing technique focuses on extracting the tumour section from the brain Magnetic-Resonance-Image (MRI) recorded with various MR sequences. The proposed technique aims to identify the best possible image processing methodology for brain MRI investigation and subsequently to extract the tumour section for clinical setting. For exploring the proposed technique, most popular Radiopedia database, BraTS 2015 dataset is primarily considered for the assessment and later, real time clinical brain MRI slices are investigated. The proposed work implements Shannon Entropy (SE) objective function assisted with Social Group Optimization (SGO) algorithm to enhance the image. The results produced by SGO are compared with the other heuristic approaches like the Firefly-Algorithm (FA), Bat-Algorithm (BA) and Differential-Evolution (DE). Then Distance-Regularized-Level-Set (DRLS) segmentation technique is performed for extracting the tumour part from the enhanced slices. Further, the segmentation comparison of DRLS against traditional Active-Contour (AC) is also adopted for the evaluation. This integrated approach offers better picture-similarity-measures (PSM) compared with the alternatives.
C1 [Suresh, K.] Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
   [Suresh, K.] St Josephs Coll Engn, Dept Informat Technol, Chennai 600119, Tamil Nadu, India.
   [Sakthi, U.] St Josephs Inst Technol, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.
C3 Sathyabama Institute of Science & Technology; St. Joseph's College of
   Engineering, Chennai
RP Suresh, K (corresponding author), Sathyabama Inst Sci & Technol, Dept Comp Sci & Engn, Chennai 600119, Tamil Nadu, India.; Suresh, K (corresponding author), St Josephs Coll Engn, Dept Informat Technol, Chennai 600119, Tamil Nadu, India.
EM sureshk@stjosephs.ac.in; sakthi.ulaganathan@gmail.com
RI Sakthi, U./AAE-9941-2020; K, Suresh/AAH-8183-2020
OI Sakthi, U./0000-0002-4559-6616; 
CR [Anonymous], LNNS
   [Anonymous], 2018, ADV ELECT COMMUNICAT
   [Anonymous], 2016, INT J COMPUTER SCI I
   [Anonymous], 3 INT C BIOS IM INST
   [Anonymous], CLUSTER COMPUT
   Bao SX, 2019, MAGN RESON IMAGING, V59, P143, DOI 10.1016/j.mri.2019.03.014
   Beagum S, 2017, MICROSC RES TECHNIQ, V80, P419, DOI 10.1002/jemt.22811
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Chaddad Ahmad, 2016, Brain Inform, V3, P53, DOI 10.1007/s40708-016-0033-7
   Chan TF, 2002, MATH VIS, P63
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cuete D., Subacute middle cerebral artery infarct
   Dey N, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10020051
   Dey N, 2015, J IMAGING, V1, P60, DOI 10.3390/jimaging1010060
   Jiang J, 2013, COMPUT MED IMAG GRAP, V37, P512, DOI 10.1016/j.compmedimag.2013.05.007
   Kamalanand K, 2015, J MED IMAG HEALTH IN, V5, P147, DOI 10.1166/jmihi.2015.1370
   KANNAPPAN P, 1972, Z WAHRSCHEINLICHKEIT, V22, P95, DOI 10.1007/BF00532728
   Lu HP, 2004, IEEE SIGNAL PROC LET, V11, P228, DOI 10.1109/LSP.2003.821748
   Menze BH, 2015, IEEE T MED IMAGING, V34, P1993, DOI 10.1109/TMI.2014.2377694
   Mini TV, 2017, INT CONF ADV COMPU, P19, DOI 10.1109/ICoAC.2017.7951738
   Moghaddam RF, 2010, PATTERN RECOGN, V43, P2186, DOI 10.1016/j.patcog.2009.12.024
   Naik A, 2018, NEURAL COMPUT APPL, V30, P271, DOI 10.1007/s00521-016-2686-9
   Osher S, 2001, J COMPUT PHYS, V169, P463, DOI 10.1006/jcph.2000.6636
   Paul S, 2014, IEEE STUDENT TECHNOL, P56, DOI 10.1109/TechSym.2014.6807914
   Qian XH, 2013, MED PHYS, V40, DOI 10.1118/1.4774359
   Raja N. Sri Madhava, 2024, Journal of Ambient Intelligence and Humanized Computing, V15, P961, DOI 10.1007/s12652-018-0854-8
   Raja NSM, 2019, HISTOPATHOLOGICAL IM, P1, DOI [10.4018/978-1-5225-6316-7.ch001, DOI 10.4018/978-1-5225-6316-7.CH001]
   Rajinikanth V., 2019, Smart Intelligent Computing and Applications. Proceedings of the Second International Conference on SCI 2018. Smart Innovation, Systems and Technologies (SIST 104), P193, DOI 10.1007/978-981-13-1921-1_19
   Rajinikanth V, 2018, ARAB J SCI ENG, V43, P4365, DOI 10.1007/s13369-017-3053-6
   Rajinikanth V., 2018, Microelectronics, Electromagnetics and Telecommunications. Proceedings of ICMEET 2017. LNEE 471, P453, DOI 10.1007/978-981-10-7329-8_46
   Rajinikanth V, 2017, J MED IMAG HEALTH IN, V7, P1837, DOI 10.1166/jmihi.2017.2265
   Rajinikanth V, 2017, CONTROL ENG APPL INF, V19, P97
   Rajinikanth V., 2018, 2nd International Conference on Micro-Electronics, Electromagnetics and Telecommunications, ICMEET 2016. Proceedings: LNEE 434, P313, DOI 10.1007/978-981-10-4280-5_33
   Rajinikanth V, 2017, PATTERN RECOGN LETT, V94, P87, DOI 10.1016/j.patrec.2017.05.028
   Satapathy S, 2016, COMPLEX INTELL SYST, V2, P173, DOI 10.1007/s40747-016-0022-8
   Sengupta A, 2019, J MAGN RESON IMAGING, V50, P1295, DOI 10.1002/jmri.26704
   Shriranjani D., 2018, Computational Signal Processing and Analysis. Select Proceedings of ICNETS2: LNEE 490, P287, DOI 10.1007/978-981-10-8354-9_26
   Thanaraj P, 2017, AUSTRALAS PHYS ENG S, V40, P413, DOI 10.1007/s13246-017-0550-6
   Thivya Roopini I., 2018, Computational Signal Processing and Analysis. Select Proceedings of ICNETS2: LNEE 490, P297, DOI 10.1007/978-981-10-8354-9_27
   Vaishnavi G. K., 2014, J BIOINFORM INTELL C, V3, P147, DOI [10.1166/jbic.2014.1080, DOI 10.1166/JBIC.2014.1080]
   Wang Y, 2019, APPL SOFT COMPUT, V74, P40, DOI 10.1016/j.asoc.2018.10.006
   Yang Y, 2019, J MAGN RESON IMAGING, V49, P1263, DOI 10.1002/jmri.26524
   Yushkevich PA, 2006, NEUROIMAGE, V31, P1116, DOI 10.1016/j.neuroimage.2006.01.015
   Zhu Y, 2019, J MAGN RESON IMAGING, V49, P1149, DOI 10.1002/jmri.26337
NR 44
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 5-6
BP 4133
EP 4147
DI 10.1007/s11042-019-07934-1
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU0OH
UT WOS:000519410700058
DA 2024-07-18
ER

PT J
AU Wang, HJ
   Kan, ST
   Zhang, XL
   Lu, XM
   Zhou, LQ
AF Wang, Hongjuan
   Kan, Shuting
   Zhang, Xingli
   Lu, Xinming
   Zhou, Longquan
TI Robust Boolean operations algorithm on regularized triangular mesh and
   implementation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boolean operations; Intersection computation; Subdivision and mark; 3D
   geological modeling
AB Boolean operations are an essential tool for creating complex entities in many fields. In order to implement complex entity modeling, we proposed a method based on robust Boolean operations that focused on the robustness of geometric calculations caused by computational errors and data error. This method used a uniform logical judgment to analyze the specific conditions of the intersection of vertices or edges in advance, and avoided the inconsistency between logical judgment results and geometric relations. We correspondingly obtained the positions of the two triangles, the validity of the intersection and the intersection edges from tetrahedral-volume calculations, the triangle-area calculations, and the topology information to mark the triangles instead of intersecting lines tracking and the judgment of the triangles inside the entities. Finally, the experimental results indicate that this method realized the three-dimensional modeling of any complex geological body.
C1 [Wang, Hongjuan] Shandong Univ Sci & Technol, Dept Informat Engineer, Tai An, Shandong, Peoples R China.
   [Kan, Shuting; Zhang, Xingli; Lu, Xinming; Zhou, Longquan] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
C3 Shandong University of Science & Technology; Shandong University of
   Science & Technology
RP Wang, HJ (corresponding author), Shandong Univ Sci & Technol, Dept Informat Engineer, Tai An, Shandong, Peoples R China.
EM wanghongjuan@sdust.edu.cn
CR Aghdaii N, 2012, COMPUT GRAPH-UK, V36, P1072, DOI 10.1016/j.cag.2012.09.005
   Attene M, 2014, GRAPH MODELS, V76, P658, DOI 10.1016/j.gmod.2014.09.002
   Barki H, 2015, COMPUT MATH APPL, V70, P1235, DOI 10.1016/j.camwa.2015.06.016
   Bi Lin, 2008, Journal of Huazhong University of Science and Technology, V36, P82
   Pereira AMB, 2012, ENG COMPUT-GERMANY, V28, P225, DOI 10.1007/s00366-011-0228-8
   Du Q, 2006, J COMPUT APPL MATH, V195, P8, DOI 10.1016/j.cam.2005.07.014
   Feito FR, 2013, COMPUT AIDED DESIGN, V45, P705, DOI 10.1016/j.cad.2012.11.004
   Ferley E, 2000, VISUAL COMPUT, V16, P469, DOI 10.1007/PL00007216
   Frisken SF, 2000, COMP GRAPH, P249, DOI 10.1145/344779.344899
   Guo Kaibo, 2006, Journal of Huazhong University of Science and Technology, V34, P96
   Guocan W, 2015, EARTH SCI J CHIN U G, V40, P397
   Jessell M, 2016, SOC EC GEOL SPEC PUB, V18, P261
   Karamete BK, 2013, FINITE ELEM ANAL DES, V68, P10, DOI 10.1016/j.finel.2013.01.003
   Krishnan S, 2001, INT J COMPUT GEOM AP, V11, P105, DOI 10.1142/S0218195901000419
   Landier S, 2017, COMPUT AIDED DESIGN, V85, P138, DOI 10.1016/j.cad.2016.07.013
   Li J, 2017, COMPUT AIDED DESIGN, V87, P20, DOI 10.1016/j.cad.2017.02.001
   Li YY, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866179
   Li Zhaoliang, 2016, Earth Science - Journal of China University of Geosciences, V41, P2136, DOI 10.3799/dqkx.2016.149
   Lo SH, 2013, INT J NUMER METH ENG, V93, P1191, DOI 10.1002/nme.4425
   McLaurin D, 2013, INT J NUMER METH ENG, V93, P266, DOI 10.1002/nme.4385
   Pan M, 2012, ACTA GEOL SIN-ENGL, V86, P1031, DOI 10.1111/j.1755-6724.2012.00727.x
   Sun Dianzhu, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P1232
   Tournois J, 2008, PROCEEDINGS OF THE 16TH INTERNATIONAL MESHING ROUNDTABLE, P83, DOI 10.1007/978-3-540-75103-8_5
   Turner AK, 2006, B ENG GEOL ENVIRON, V65, P109, DOI 10.1007/s10064-005-0015-0
   Updegrove A, 2016, ADV ENG SOFTW, V95, P16, DOI 10.1016/j.advengsoft.2016.01.015
   Vartziotis D, 2008, COMPUT METHOD APPL M, V197, P3760, DOI 10.1016/j.cma.2008.02.028
   Wang CCL, 2011, IEEE T VIS COMPUT GR, V17, P836, DOI 10.1109/TVCG.2010.106
   Xiang-rong L, 2008, GEOGRAPH GEOINF SCI, V24, P6
   Xiao ZF, 2016, COMPUT GRAPH-UK, V59, P13, DOI 10.1016/j.cag.2016.04.004
   Xu SG, 2013, COMPUT AIDED DESIGN, V45, P529, DOI 10.1016/j.cad.2012.10.036
   Zhou LQ, 2018, INT J PATTERN RECOGN, V32, DOI 10.1142/S0218001418550170
NR 31
TC 3
Z9 3
U1 2
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2020
VL 79
IS 7-8
BP 5301
EP 5320
DI 10.1007/s11042-018-6479-2
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU1MT
UT WOS:000519474500061
DA 2024-07-18
ER

PT J
AU Zhang, FH
   Xu, SB
   Zhang, XP
AF Zhang, Feihu
   Xu, Shibiao
   Zhang, Xiaopeng
TI High accuracy correspondence field estimation via MST based patch
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical flow; Minimum spanning tree; PatchMatch
ID ADAPTIVE SUPPORT; OPTICAL-FLOW; STEREO
AB This paper presents an effective framework for correspondence field estimation. The core idea is to construct pixel-level and superpixel-level patch matching to achieve high accuracy estimation as well as fast speed computation. To this end, a hybrid edge-preserving supported weighting approach is first developed, which contributes to better performance on the pixel level, especially on those in the regions of fine structures. Then, a local Minimum Spanning Tree (MST) is constructed to describe regions and develop the adaptive smooth penalty weights, so that the over-patching in large textureless regions can be effectively avoided. In addition, the MST is further extended to handle occlusions in way of edge preserving strategy. Finally, all the above treatments are collected into an optimization model where the objective function is developed in terms of Markov Random Filed (MRF). In computation, a fast yet efficient iterative optimization strategy is developed. Our approach achieves favorable place on optical flow benchmark, which locates at the top two and top four for endpoint error and angular error evaluations among more than 130 approaches listed in the webpage.
C1 [Zhang, Feihu; Xu, Shibiao; Zhang, Xiaopeng] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Xu, SB; Zhang, XP (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
EM shibiao.xu@ia.ac.cn; xiaopeng.zhang@ia.ac.cn
FU National Key R&D Program of China [2018YFB2100602]; National Natural
   Science Foundation of China [61620106003, 61971418, 61771026, 61671451,
   61571046]
FX This work was also supported by the National Key R&D Program of China
   (Grant 2018YFB2100602). This work is supported by the National Natural
   Science Foundation of China (Nos. 61620106003, 61971418, 61771026,
   61671451 and 61571046).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Bao L, 2014, IEEE TIP
   Bao LC, 2014, IEEE T IMAGE PROCESS, V23, P555, DOI 10.1109/TIP.2013.2291328
   Barnes C., 2011, PATCHMATCH FAST RAND
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Besse F, 2014, INT J COMPUT VISION, V110, P2, DOI 10.1007/s11263-013-0653-9
   Bleyer M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.14
   Chen ZY, 2013, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR.2013.316
   Dai LQ, 2015, IEEE SIGNAL PROC LET, V22, P623, DOI 10.1109/LSP.2014.2365527
   Drulea M, 2013, IEEE T IMAGE PROCESS, V22, P3260, DOI 10.1109/TIP.2013.2263149
   Gupta R., 2010, J Comput Multiphase Flow, V2, P1, DOI DOI 10.1260/1757-482X.2.1.1
   Hornácek M, 2014, LECT NOTES COMPUT SC, V8691, P220, DOI 10.1007/978-3-319-10578-9_15
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Kim TH, 2013, IEEE I CONF COMP VIS, P3344, DOI 10.1109/ICCV.2013.415
   Lempitsky V, 2010, IEEE T PATTERN ANAL, V32, P1392, DOI 10.1109/TPAMI.2009.143
   Lu JB, 2013, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2013.242
   Mohamed MA, 2012, LECT NOTES COMPUT SC, V7431, P482, DOI 10.1007/978-3-642-33179-4_46
   Olsson C, 2013, PROC CVPR IEEE, P1730, DOI 10.1109/CVPR.2013.226
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shen SH, 2013, IEEE T IMAGE PROCESS, V22, P1901, DOI 10.1109/TIP.2013.2237921
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Taniai T, 2014, PROC CVPR IEEE, P1613, DOI 10.1109/CVPR.2014.209
   Tombari F, 2007, LECT NOTES COMPUT SC, V4872, P427
   Xu L, 2010, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2010.5539820
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
NR 27
TC 1
Z9 1
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2020
VL 79
IS 19-20
BP 13291
EP 13309
DI 10.1007/s11042-020-08633-y
EA JAN 2020
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ2DE
UT WOS:000515728500005
DA 2024-07-18
ER

PT J
AU Sukumar, A
   Subramaniyaswamy, V
   Vijayakumar, V
   Ravi, L
AF Sukumar, Arunkumar
   Subramaniyaswamy, V.
   Vijayakumar, V.
   Ravi, Logesh
TI A secure multimedia steganography scheme using hybrid transform and
   support vector machine for cloud-based storage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia security; Image steganography; Discrete Rajan transform;
   Support vector machine; Diamond embedding
ID IMAGE STEGANOGRAPHY; COLOR IMAGE
AB Cloud computing is widely accepted by both individuals and enterprises alike for the storage of multimedia contents. It is due to the introduction of a new architecture where the cost of computation, storage, and services needed for maintenance for storage of multimedia are less. Cloud computing addresses the scarcity of resources for clients by offering options to pay for services only as they are used. But once the organization's multimedia contents are uploaded into cloud space, the user loses control over their contents which may no longer be safe. The cloud user has to take some measure to avoid privacy issues. Steganography is preferred over encryption for providing multimedia security as content concealed in a cover image is not revealed. The multimedia content is transformed using Discrete Rajan Transform (DRT) and embedded into a chosen cover image which is created by Integer Wavelet using Diamond Encoding Scheme. Generated stego images are stored in the cloud. When the multimedia content is required, stego images are downloaded from the cloud and are subjected to inverse transform of IWT. SVM provides Good learning ability to our extraction process which makes our algorithm more robust to various attacks, viz., salt and pepper noise, Gaussian noise, cropping, compression, etc. Experimental values for Peak Signal to Noise Ratio (PSNR) for two secret images are 53 and 50 respectively which is better over the available schemes in the literature. Similarly for robustness and security evaluation, our scheme provides a better result.
C1 [Sukumar, Arunkumar; Subramaniyaswamy, V.] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
   [Vijayakumar, V.] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Ravi, Logesh] Sri Ramachandra Inst Higher Educ & Res, Sri Ramachandra Fac Engn & Technol, Chennai, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA); Vellore
   Institute of Technology (VIT); VIT Chennai; Sri Ramachandra Institute of
   Higher Education & Research
RP Subramaniyaswamy, V (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
EM vgsarun@gmail.com; vsubramaniyaswamy@gmail.com;
   vijayakumar.varadarajan@gmail.com; LogeshPhD@gmail.com
RI S, Arunkumar/GOG-8221-2022; varadarajan, vijayakumar/K-8007-2017
OI , Subramaniyaswamy/0000-0001-5328-7672; Arunkumar,
   Sukumar/0000-0002-6538-8902; R, Logesh/0000-0002-0034-4714
CR [Anonymous], 2011, INT J COMPUTER SCI C
   Arunkumar S, 2018, BIOMED RES, P29
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Atawneh S, 2013, IETE TECH REV, V30, P344, DOI 10.4103/0256-4602.116724
   Atta R, 2018, J VIS COMMUN IMAGE R, V53, P42, DOI 10.1016/j.jvcir.2018.03.009
   Chang V, 2017, 2017 INT C ENG TECHN, P1
   Chang V, 2016, P IEEE 7 INT C CLOUD, P16
   Chang V, 2018, NEURAL COMPUT APPL, V29, P1243, DOI 10.1007/s00521-017-3000-1
   Dumitrescu S, 2002, INT WORKSH INF HID, P55
   Fan L, 2013, COMPUT ELECTR ENG, V39, P873, DOI 10.1016/j.compeleceng.2012.06.014
   Hallman R, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2645, DOI 10.1145/3133956.3137043
   Hemalatha S., 2013, INT J CRYPTOGRAPHY I, V3, P17
   Hon WK, 2018, COMPUT LAW SECUR REV, V34, P4, DOI 10.1016/j.clsr.2017.11.005
   Hong JB, 2019, COMPUT NETW, V150, P46, DOI 10.1016/j.comnet.2018.12.009
   Houssein EH, 2016, ACSIS-ANN COMPUT SCI, V8, P641, DOI 10.15439/2016F521
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Kuo CT, 2018, FUTURE GENER COMP SY, V86, P1424, DOI 10.1016/j.future.2017.12.069
   Li CH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1255
   Lin YK, 2014, COMPUT STAND INTER, V36, P855, DOI 10.1016/j.csi.2013.12.013
   Mandalapu EN, 2009, INFORM-J COMPUT INFO, V33, P205
   Mielikainen J, 2006, IEEE SIGNAL PROC LET, V13, P285, DOI 10.1109/LSP.2006.870357
   Nag A., 2011, INT J COMPUT SCI SEC, V4, P561
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Rohit Thanki, 2017, J KING SAUD U COMPUT
   Sohal AS, 2018, COMPUT SECUR, V74, P340, DOI 10.1016/j.cose.2017.08.016
   Srinivasan B., 2015, INDIAN J SCI TECHNOL, V8, P228, DOI 10.17485/ijst/2015/v8iS7/
   Subhedar MS, 2016, COMPUT ELECTR ENG, V54, P406, DOI 10.1016/j.compeleceng.2016.04.017
   Subhedar MS, 2014, COMPUT SCI REV, V13-14, P95, DOI 10.1016/j.cosrev.2014.09.001
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Verma A, 2013, INT J COMPUT SCI BUS, V1
   Zafar F, 2017, COMPUT SECUR, V65, P29, DOI 10.1016/j.cose.2016.10.006
NR 32
TC 7
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2020
VL 79
IS 15-16
BP 10825
EP 10849
DI 10.1007/s11042-019-08476-2
EA JAN 2020
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA LQ1PC
UT WOS:000505414100004
DA 2024-07-18
ER

PT J
AU Ming, Y
   Zhang, YS
AF Ming, Yue
   Zhang, Yashu
TI Efficient scalable spatiotemporal visual tracking based on recurrent
   neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scalable spatiotemporal visual tracking (SSVT); Direction prediction
   model (DPM); Recurrent network model (RNN); Kernelized correlation
   filter (KCF)
AB Robust and accurate visual tracking is challenging as targets undergo significant changes in appearance by scale variance, occlusion and fast motion. We propose a novel tracking framework, called scalable spatiotemporal visual tracking algorithm (SSVT). First, we construct the Direction Prediction Model (DPM) to predict the spatiotemporal correlation of the target in the next frame. That will efficiently narrow down the search area and improve the accuracy of spatial location. Then, Occlusion Detection algorithm (ODA) is presented to overcome the wrong updates stemming from the region of interest (ROI) based on the estimated direction and Kalman filter. Finally, the multi-scale pyramid kernelized correlation filter (MSPKCF) is presented in tracking to realize the adaptive adjustment of the varying scales of the targets and the ROI size. Extensive experiments on OTB100 and VOT2016 datasets demonstrate that our tracker performs favorably against state-of-the-art trackers, which can effectively reduce computation redundancy and improve tracking accuracy.
C1 [Ming, Yue] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
   [Zhang, Yashu] Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Ming, Y (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
EM myname35875235@126.com
CR [Anonymous], AS C COMP VIS
   [Anonymous], 2017, IEEE INT S CIRC SYST
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2019, INSTRUM SCI TECHNOL, DOI DOI 10.1080/10739149.2019.1599010
   [Anonymous], ARXIV150104587
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cliff D., 1992, Toward a Practice of Autonomous Systems. Proceedings of the First European Conference on Artificial Life, P78
   Cui Z, 2016, PROC CVPR IEEE, P1449, DOI 10.1109/CVPR.2016.161
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   ELMAN JL, 1990, COGNITIVE SCI, V14, P179, DOI 10.1207/s15516709cog1402_1
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Han BY, 2005, IEEE I CONF COMP VIS, P1492
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huh JH, 2019, J SUPERCOMPUT, V75, P1831, DOI 10.1007/s11227-018-2342-5
   Huh JH, 2017, HUM-CENTRIC COMPUT I, V7, DOI 10.1186/s13673-017-0101-x
   Kahou SE, 2017, IEEE COMPUT SOC CONF, P1613, DOI 10.1109/CVPRW.2017.206
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Lu H, 2013, CHIN CONTR CONF, P4311
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang QR, 2019, IEEE T MULTIMEDIA, V21, P930, DOI 10.1109/TMM.2018.2869277
   Wang X, 2019, IEEE T CYBERNETICS, V49, P146, DOI 10.1109/TCYB.2017.2768570
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu XQ, 2017, IEEE IMAGE PROC, P1152, DOI 10.1109/ICIP.2017.8296462
   Yang TY, 2018, LECT NOTES COMPUT SC, V11213, P153, DOI 10.1007/978-3-030-01240-3_10
   Yao YJ, 2018, LECT NOTES COMPUT SC, V11213, P560, DOI 10.1007/978-3-030-01240-3_34
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang MD, 2018, LECT NOTES COMPUT SC, V11207, P484, DOI 10.1007/978-3-030-01219-9_29
   Zhang SP, 2012, ACM T INTEL SYST TEC, V3, DOI 10.1145/2168752.2168757
   Zhou Y, 2018, IEEE T IMAGE PROCESS, V27, P6159, DOI 10.1109/TIP.2018.2865278
   Zhu L, 2017, IEEE T MULTIMEDIA, V19, P2066, DOI 10.1109/TMM.2017.2729025
   Zhu L, 2017, IEEE T KNOWL DATA EN, V29, P472, DOI 10.1109/TKDE.2016.2562624
NR 50
TC 2
Z9 2
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 3-4
BP 2239
EP 2261
DI 10.1007/s11042-019-08331-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KO3FJ
UT WOS:000515433000024
DA 2024-07-18
ER

PT J
AU Agarwal, R
   Verma, OP
AF Agarwal, Ritu
   Verma, Om Prakash
TI An efficient copy move forgery detection using deep learning feature
   extraction and matching algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forgery; Copy-move detection; Tampered image
   identification
AB The image forgery activities are on the rise because of the development of various image editing tools. Such activities are done by attackers with intentions of defaming people and websites or for gaining monetary advantage, extortion etc. Image forgeries are carried out through various ways, among one is the copy-move forgery. The basic process of copy-move image forgery is copying the objects present in an image and create the new image by using the copied objects or placing the copied object on the same image on a different location, hence the need for a forgery detection system to protect the authenticity of images. The existing forgery detection techniques detect the tampered regions with less efficiency because of the large size and lower contrast of the images. This article proposes an efficient technique for detecting the copy-move forged image based on deep learning. The proposed algorithm initializes the tampered image as the input for our system to detect the tampered region. Our system includes processes like segmentation, feature extraction, dense depth reconstruction, and finally identifying the tampered areas. The proposed deep learning based system can save on computational time and detect the duplicated regions with more accuracy.
C1 [Agarwal, Ritu] Delhi Technol Univ, Dept Informat Technol, New Delhi, India.
   [Verma, Om Prakash] Delhi Technol Univ, Dept Elect & Commun Engn, New Delhi, India.
C3 Delhi Technological University; Delhi Technological University
RP Agarwal, R (corresponding author), Delhi Technol Univ, Dept Informat Technol, New Delhi, India.
EM ritu.jeea@gmail.com; opverma.dce@gmail.com
RI Agarwal, Ritu/KRP-8451-2024; Verma, Om/AAD-1007-2019
OI Agarwal, Ritu/0000-0002-0420-1892; Verma, Om/0000-0002-7421-295X
CR Abd Warif NB, 2016, J NETW COMPUT APPL, V75, P259, DOI 10.1016/j.jnca.2016.09.008
   Al-Qershi OM, 2019, MULTIDIM SYST SIGN P, V30, P1671, DOI 10.1007/s11045-018-0624-y
   Al-Qershi Osamah M., 2016, 9 INT C ROB VIS SIGN, P209
   AlZahir Saif, 2017, 2017 IEEE International Conference on Consumer Electronics (ICCE), P436, DOI 10.1109/ICCE.2017.7889387
   Ansari MD, 2018, INT J SIGNAL IMAGING, V11, P44, DOI 10.1504/IJSISE.2018.10011742
   Bi XL, 2018, PATTERN RECOGN, V81, P161, DOI 10.1016/j.patcog.2018.03.028
   Bi XL, 2018, MULTIMED TOOLS APPL, V77, P363, DOI 10.1007/s11042-016-4276-3
   Bi XL, 2017, INFORM SCIENCES, V418, P531, DOI 10.1016/j.ins.2017.08.044
   Chao-Lung Chou, 2018, Security with Intelligent Computing and Big-data Services. Advances in Intelligent Systems and Computing (AISC 733), P47, DOI 10.1007/978-3-319-76451-1_5
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Ma JL, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT), P10, DOI 10.1109/ICOT.2015.7498477
   Mahmood A, 2016, IEEE IMAGE PROC, P519, DOI 10.1109/ICIP.2016.7532411
   Mahmood T, 2018, J VIS COMMUN IMAGE R, V53, P202, DOI 10.1016/j.jvcir.2018.03.015
   Manu VT, 2018, SIGNAL IMAGE VIDEO P, V12, P549, DOI 10.1007/s11760-017-1191-7
   Novozámsky A, 2018, FORENSIC SCI INT, V283, P47, DOI 10.1016/j.forsciint.2017.11.031
   Oyiza AH, 2018, INT J INNOVATIVE COM, V8
   Panda Santoshini, 2017, LECT NOTES ELECT ENG, P281
   Soni B, 2018, PROCEEDINGS OF 2018 INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS PROCESSING (ICIGP 2018), P53, DOI 10.1145/3191442.3191465
   Wang XY, 2018, PATTERN ANAL APPL, V21, P451, DOI 10.1007/s10044-016-0588-1
   Wu Y, 2018, IEEE WINT CONF APPL, P1907, DOI 10.1109/WACV.2018.00211
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yu LY, 2016, MULTIMED TOOLS APPL, V75, P1159, DOI 10.1007/s11042-014-2362-y
   Zhong JL, 2017, MULTIMED TOOLS APPL, V76, P14887, DOI 10.1007/s11042-016-4201-9
NR 25
TC 40
Z9 41
U1 1
U2 31
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 11-12
BP 7355
EP 7376
DI 10.1007/s11042-019-08495-z
EA DEC 2019
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KZ7LW
UT WOS:000504164600006
DA 2024-07-18
ER

PT J
AU Guidi, B
   Michienzi, A
   De Salve, A
AF Guidi, Barbara
   Michienzi, Andrea
   De Salve, Andrea
TI Community evaluation in Facebook groups
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Community detection; Social network analysis; Social networks; Social
   groups
ID EGO NETWORKS; ONLINE; AVAILABILITY; INTERNET
AB One of the main points of the Next Generation Internet is to have a user-centric approach where daily behavior and social life of the users are studied and analyzed in order to model networks and services. Indeed, social life represents the general overview of the behaviour of people, because it can provide information about hobby, relationships, but also similarity, etc. Today, the main channels to study the behaviour of people are Social Media. A great trend in current Social Media platforms is to offer the opportunity to establish and join groups of people, which represents one of the main characteristics of offline social network, where people are clustering, usually based on their interest (work, family, etc.). Despite human behaviour in current Online Social Media have been studied in depth, characteristics of online content-based social groups are still unknown. In this paper, we investigate whether communities can be recognized also in groups defined by users of Social Media platforms and we study how these communities evolve over time. For this purpose, we exploited a real Facebook dataset which consists of 18 Facebook groups of different categories and 3 different community detection algorithms. Our results provide important insights about the behaviour of users in the context of social groups and reveal that the majority of the groups present interactions-based communities, and in particular there is one massive core community which attracts other users and communities.
C1 [Guidi, Barbara; Michienzi, Andrea] Univ Pisa, Dept Comp Sci, Pisa, Italy.
   [De Salve, Andrea] Univ Palermo, Dept Math & Comp Sci, Palermo, Italy.
C3 University of Pisa; University of Palermo
RP Guidi, B (corresponding author), Univ Pisa, Dept Comp Sci, Pisa, Italy.
EM guidi@di.unipi.it; andrea.michienzi@di.unipi.it; andrea.desalve@unipa.it
RI Guidi, Barbara/ABD-2970-2020; Michienzi, Andrea/JDD-8184-2023
OI Guidi, Barbara/0000-0002-0151-6469; Michienzi,
   Andrea/0000-0001-8005-8701
CR [Anonymous], 2012, P 18 ACM SIGKDD INT, DOI DOI 10.1145/2339530.2339630
   Backstrom L., 2008, the international conference on Web search and web data mining, P117
   Backstrom L., 2006, P 12 ACM SIGKDD INT, P44, DOI DOI 10.1145/1150402.1150412
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Boyd DM, 2007, J COMPUT-MEDIAT COMM, V13, P210, DOI 10.1111/j.1083-6101.2007.00393.x
   Clauset A, 2004, PHYS REV E, V70, DOI 10.1103/PhysRevE.70.066111
   Conti M, 2018, COMPUT COMMUN, V131, P51, DOI 10.1016/j.comcom.2018.07.034
   Conti M, 2017, PERVASIVE MOB COMPUT, V41, P1, DOI 10.1016/j.pmcj.2017.07.009
   Coscia M, 2014, ACM T KNOWL DISCOV D, V9, DOI 10.1145/2629511
   De Salve A, 2018, GOODTECHS '18: PROCEEDINGS OF THE 4TH EAI INTERNATIONAL CONFERENCE ON SMART OBJECTS AND TECHNOLOGIES FOR SOCIAL GOOD (GOODTECHS), P165, DOI 10.1145/3284869.3284904
   De Salve A, 2018, MOBILE NETW APPL, V23, P1715, DOI 10.1007/s11036-018-1067-2
   De Salve A, 2018, MOBILE NETW APPL, V23, P155, DOI 10.1007/s11036-017-0830-0
   De Salve A, 2016, COMPUT COMMUN, V73, P211, DOI 10.1016/j.comcom.2015.09.001
   Everett M, 2005, SOC NETWORKS, V27, P31, DOI 10.1016/j.socnet.2004.11.007
   Forsyth D. R., 2018, Groupdynamics, V7th, DOI DOI 10.1057/PALGRAVE.JORS.2602169
   Fortunato S, 2007, P NATL ACAD SCI USA, V104, P36, DOI 10.1073/pnas.0605965104
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Guidi B, 2019, J GRID COMPUT, V17, P23, DOI 10.1007/s10723-018-9448-0
   Guidi B, 2018, LECT NOTES COMPUT SC, V10659, P517, DOI 10.1007/978-3-319-75178-8_42
   Kietzmann JH, 2011, BUS HORIZONS, V54, P241, DOI 10.1016/j.bushor.2011.01.005
   Laine M.S. Stanley., 2011, Proceedings of the 2011 44th Hawaii International Conference on System Sciences, P1, DOI [DOI 10.1109/HICSS.2011.472, 10.1109/HICSS.2011.472]
   Maia M., 2008, P 1 WORKSHOP SOCIAL, P1, DOI [10.1145/1435497.1435498, DOI 10.1145/1435497.1435498]
   Martin-Borregon D, 2014, EPJ DATA SCI, V3, DOI 10.1140/epjds/s13688-014-0008-y
   Miranda J, 2015, IEEE INTERNET COMPUT, V19, P40, DOI 10.1109/MIC.2015.24
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Partridge SR, 2018, J MED INTERNET RES, V20, DOI 10.2196/jmir.7558
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Sani L, 2018, LECT NOTES COMPUT SC, V10784, P125, DOI 10.1007/978-3-319-77538-8_10
NR 28
TC 15
Z9 16
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2020
VL 79
IS 45-46
BP 33603
EP 33622
DI 10.1007/s11042-019-08494-0
EA DEC 2019
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA OZ3UJ
UT WOS:000574620100002
DA 2024-07-18
ER

PT J
AU Yang, TJ
   Peng, S
   Huang, L
AF Yang, Tiejun
   Peng, Shan
   Huang, Lin
TI Surface defect detection of voltage-dependent resistors using
   convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surface defect detection; Convolutional neural networks;
   Voltage-dependent resistors; Image recognition
ID INSPECTION
AB Surface defect detection is an important way to improve the production quality of voltage-dependent resistors (VDRs). To improve the accuracy and efficiency of VDR surface quality detection, an end-to-end surface quality detection method based on deep convolutional neural networks (CNNs) was proposed. The method includes four stages: data preparation, convolution neural network design, CNN training, and testing. First, images of VDRs were acquired from three perspectives, i.e., the front, back, and side, and then training, validation and testing sets were obtained. Second, the proposed CNN models for VDR surface defect detection were constructed. Third, during the training stage, the images with class labels from the established training sets were input to the proposed network for training and validation. Finally, in the testing stage, test images from a total of 408 samples of two VDR models were used to test the trained network. The sensitivity, specificity, accuracy, precision and F measure of the proposed algorithm were compared with those of state-of-the-art methods, and the experimental results showed that the proposed method has a high recognition speed and accuracy and meets the requirements of online real-time detection.
C1 [Yang, Tiejun; Peng, Shan; Huang, Lin] Guilin Univ Technol, Guangxi Key Lab Embedded Technol & Intelligent Sy, Guilin 541004, Guangxi, Peoples R China.
C3 Guilin University of Technology
RP Huang, L (corresponding author), Guilin Univ Technol, Guangxi Key Lab Embedded Technol & Intelligent Sy, Guilin 541004, Guangxi, Peoples R China.
EM hlcucu@qq.com
RI Yang, Tiejun/AAJ-8197-2020
OI Yang, Tiejun/0000-0002-8644-4651; Huang, Lin/0000-0002-2678-2085
FU Guangxi Natural Science Foundation [2018GXNSFBA281081]; Guangxi Basic
   Ability Promotion Project for Young and Middle-aged Teachers
   [2017KY0247]; Project of Cultivating a Thousand Young and Middle-aged
   Teachers in Guangxi Universities; Guangxi Key Laboratory Fund of
   Embedded Technology and Intelligent System [2018A-07]; Guangxi
   Universities Key Laboratory Fund of Embedded Technology [2017-1-1,
   2017-2-4]; Guangxi Universities Key Laboratory Fund of Intelligent
   Information Processing [2017-1-1, 2017-2-4]
FX This research was partly supported by the Guangxi Natural Science
   Foundation (2018GXNSFBA281081), the Guangxi Basic Ability Promotion
   Project for Young and Middle-aged Teachers (2017KY0247), the Project of
   Cultivating a Thousand Young and Middle-aged Teachers in Guangxi
   Universities, the Guangxi Key Laboratory Fund of Embedded Technology and
   Intelligent System (2018A-07) and the Guangxi Universities Key
   Laboratory Fund of Embedded Technology and Intelligent Information
   Processing (2017-1-1, 2017-2-4).
CR [Anonymous], 2016, ARXIV160207360
   ASIEGBU GO, 2012, P 4 INT C SIGN IM PR, P247
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chen HY, 2020, J INTELL MANUF, V31, P453, DOI 10.1007/s10845-018-1458-z
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   JIA Y, 1408, P 22 ACM INT C MULT, P675
   Koch C, 2015, ADV ENG INFORM, V29, P196, DOI 10.1016/j.aei.2015.01.008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo CFJ, 2014, J INTELL MANUF, V25, P1235, DOI 10.1007/s10845-012-0725-7
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin HD, 2007, J MATER PROCESS TECH, V189, P19, DOI 10.1016/j.jmatprotec.2006.12.051
   Lin M., 2013, ARXIV13124400
   LIU L, 2018, MULTIMED TOOLS APPL
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shen H, 2012, MEASUREMENT, V45, P719, DOI 10.1016/j.measurement.2011.12.018
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao X, 2018, IEEE T COMP PACK MAN, V8, P689, DOI 10.1109/TCPMT.2018.2794540
   Wang YL, 2018, MULTIMED TOOLS APPL, V77, P16741, DOI 10.1007/s11042-017-5238-0
   Xi JQ, 2017, APPL OPTICS, V56, P184, DOI 10.1364/AO.56.000184
   Yu HM, 2019, IEEE T INSTRUM MEAS, V68, P656, DOI 10.1109/TIM.2018.2853958
NR 22
TC 3
Z9 4
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2020
VL 79
IS 9-10
BP 6531
EP 6546
DI 10.1007/s11042-019-08407-1
EA DEC 2019
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8NV
UT WOS:000502584400004
DA 2024-07-18
ER

PT J
AU Ji, PL
   Liu, XG
AF Ji, Penglei
   Liu, Xinguo
TI A fast and efficient 3D reflection symmetry detector based on neural
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reflection symmetry; Point cloud; Neural networks
AB Determining the 3D reflection symmetry planes from 3D models is very difficult and time-consuming. In this paper, we formulate the symmetry detection as a per-point classification problem and present a deep neural network based method to solve it. During the training procedure, we firstly collect a lot of CAD mesh models with reflection symmetry as the training data, and then convert each mesh model into a dense point cloud with points located on the symmetry planes labeled as positive. Based on the PointNet++ architecture, we train a multiscale deep neural network to capture the reflection symmetry property from the point cloud automatically. In addition, a novel weighted cross-entropy loss function is adopted to balance the positive and the negative samples. During the inference procedure, we firstly feed the down-sampled point cloud into the trained neural network. Then, the output per-point classification result is used to calculate an initial symmetry plane equation with RANSAC strategy and the least square method. Finally, iterative closest point algorithm is performed to optimize the fitted symmetry plane. Experimental results on both the synthetic and the real data demonstrate the efficiency, robustness and flexibility of our approach. Our method is pretty fast and generates comparable or better results than the existing methods.
C1 [Ji, Penglei; Liu, Xinguo] Zhejiang Univ, State Key Lab CAD, CG, Hangzhou, Peoples R China.
C3 Zhejiang University
RP Liu, XG (corresponding author), Zhejiang Univ, State Key Lab CAD, CG, Hangzhou, Peoples R China.
EM jpl@zju.edu.cn; xgliu@cad.zju.edu.cn
FU National Natural Science Foundation of China [61872317]
FX The authors would like to thank the anonymous reviewers for their
   valuable comments. This work was supported by the National Natural
   Science Foundation of China under Grants Nos. 61872317
CR [Anonymous], 2006, ECCV
   [Anonymous], 2015, CVPR
   [Anonymous], P 2004 EUR ACM SIGGR
   [Anonymous], 2009, ACM T GRAPHICS TOG
   [Anonymous], 2017, NIPS
   [Anonymous], ICCV
   [Anonymous], 2016, 12 USENIX S OPERATIN
   [Anonymous], 2019, IEEE T IND ELECT
   [Anonymous], 2002, P S DAT VIS, DOI DOI 10.5555/509740.509782
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], HYBRIDSN EXPLORING 3
   [Anonymous], 2012, ACM Transactions on Graphics (TOG)
   [Anonymous], S GEOM PROC
   [Anonymous], CVPR
   [Anonymous], 2018, NIPS
   [Anonymous], ECCV
   [Anonymous], 2017, ICCV
   [Anonymous], COMPUT GRAPH FORUM
   [Anonymous], CVPR
   [Anonymous], LEARNING BASED SYMME
   [Anonymous], ICCV WORKSH
   [Anonymous], 2018, PATTERN RECOGNITION
   [Anonymous], 2016, ECCV
   [Anonymous], ICML
   [Anonymous], ICCV WORKSH
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bokeloh M, 2009, COMPUT GRAPH FORUM, V28, P697, DOI 10.1111/j.1467-8659.2009.01410.x
   Ecins A, 2016, IEEE INT CONF ROBOT, P2271, DOI 10.1109/ICRA.2016.7487376
   Kim VG, 2010, COMPUT GRAPH FORUM, V29, P1689, DOI 10.1111/j.1467-8659.2010.01778.x
   Korman S, 2015, COMPUT GRAPH FORUM, V34, P2, DOI 10.1111/cgf.12454
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Li B, 2016, GRAPH MODELS, V83, P2, DOI 10.1016/j.gmod.2015.09.003
   Lu YX, 2009, FOUND TRENDS COMPUT, V5, P1, DOI 10.1561/0600000008
   Maron H, 2017, ACM T GRAPHIC, V36, P1, DOI DOI 10.1145/3072959.3073616
   Mitra NJ, 2006, ACM T GRAPHIC, V25, P560, DOI 10.1145/1141911.1141924
   Mitra NJ, 2013, COMPUT GRAPH FORUM, V32, P1, DOI 10.1111/cgf.12010
   Qi C.R., 2017, CVPR
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun CM, 1997, IEEE T PATTERN ANAL, V19, P164, DOI 10.1109/34.574800
   Wang LT, 2020, IEEE T COGN DEV SYST, V12, P98, DOI 10.1109/TCDS.2019.2900506
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiao J, 2016, SIGNAL PROCESS, V120, P702, DOI 10.1016/j.sigpro.2014.11.020
   Xie J, 2017, IEEE T IMAGE PROCESS, V26, P1231, DOI 10.1109/TIP.2017.2651408
   Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z
NR 47
TC 14
Z9 16
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 35471
EP 35492
DI 10.1007/s11042-019-08043-9
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800055
DA 2024-07-18
ER

PT J
AU Yang, HY
   Qi, SR
   Niu, Y
   Niu, PP
   Wang, XY
AF Yang, Hong-Ying
   Qi, Shu-Ren
   Niu, Ying
   Niu, Pan-Pan
   Wang, Xiang-Yang
TI Copy-move forgery detection based on adaptive keypoints extraction and
   matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Adaptive keypoints; BRISK descriptor;
   Embedded random ferns; Fast NNPROD
ID CLASSIFICATION; SEGMENTATION; CMFD
AB Copy-move (region duplication) is one of the most common types of image forgeries, in which at least one part of an image is copied and pasted onto another area of the same image. The main aims of the copy-move forgery are to overemphasize a concept or conceal objects by duplicating some regions. Keypoint-based copy-move forgery detection (CMFD) schemes extract image keypoints and employ local image features to identify duplicated regions, which exhibits remarkable detection performance with respect to memory requirement, computational cost, and robustness. To enhance the performance of keypoint-based CMFD approaches, here are three issues that need to be solved: the non-uniform distribution of image keypoints, the low discriminatory power of local image descriptor, and the high computational cost and low matching efficiency of feature matching strategy. In order to overcome these issues, we propose a new copy-move forgery detection method based on adaptive keypoints extraction and matching in this paper. First, we extract the image keypoints using the adaptive uniform distribution threshold. Second, the binary robust invariant scalable keypoints (BRISK) descriptor is introduced to represent the local image feature of image keypoints. Afterwards, local BRISK descriptors are employed to match image keypoints by using embedded random ferns approach, which formulates the required matching as a discriminative classification problem. Finally, the falsely matched keypoints pairs are eliminated by utilizing the random sample consensus (RANSAC), and the fast mean-residual normalized intensity correlation (NNPROD) is employed to locate the tampering area. We evaluate the performance of the proposed CMFD method in detail by conducting several simulation experiments, and the experimental results have shown that the detection and localization accuracy of the proposed method is superior to that of the state-of-the-art approaches recently proposed in the literature, even in adverse conditions.
C1 [Yang, Hong-Ying; Qi, Shu-Ren; Niu, Ying; Niu, Pan-Pan; Wang, Xiang-Yang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Niu, PP; Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM niupanpan3333@163.com; wxy37@126.com
RI Qi, Shuren/JAX-8354-2023; Niu, Panpan/Q-9953-2017; Yang,
   Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [61701212, 61472171]; China
   Postdoctoral Science Foundation [2017 M621135, 2018 T110220]; High-level
   Innovation Talents Foundation of Dalian [2017RQ055]
FX This work was supported partially by the National Natural Science
   Foundation of China (Nos. 61701212 & 61472171), China Postdoctoral
   Science Foundation (No. 2017 M621135, 2018 T110220), and High-level
   Innovation Talents Foundation of Dalian (No.2017RQ055).
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   [Anonymous], P INT C INT COMM CON
   [Anonymous], PERCEPTUAL HASHING B
   Asikuzzaman M, 2018, IEEE T CIRC SYST VID, V28, P2131, DOI 10.1109/TCSVT.2017.2712162
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Bravo-Solorio S, 2011, INT CONF ACOUST SPEE, P1880
   Chao L, 2016, CHIN CONTR CONF, P10264, DOI 10.1109/ChiCC.2016.7554980
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2014, IEEE IMAGE PROC, P5312, DOI 10.1109/ICIP.2014.7026075
   Dixit R, 2017, IET IMAGE PROCESS, V11, P746, DOI 10.1049/iet-ipr.2016.0322
   Donoser M, 2014, PROC CVPR IEEE, P516, DOI 10.1109/CVPR.2014.73
   Fridrich A.J., 2003, P DIGITAL FORENSIC R
   Gong Jiachang, 2016, Transactions of Tianjin University, V22, P151, DOI 10.1007/s12209-016-2705-z
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Jin GN, 2017, SIGNAL PROCESS-IMAGE, V57, P113, DOI 10.1016/j.image.2017.05.010
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Korus P, 2017, DIGIT SIGNAL PROCESS, V71, P1, DOI 10.1016/j.dsp.2017.08.009
   Lepetit Vincent., 2013, Decision Forests for Computer Vision and Medical Image Analysis, P111
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li YM, 2019, IEEE T INF FOREN SEC, V14, P1307, DOI 10.1109/TIFS.2018.2876837
   Manu VT, 2016, ADV INTELL SYST COMP, V425, P645, DOI 10.1007/978-3-319-28658-7_55
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Muzaffer G., 2017, P INT ARTIFICIAL INT, P1
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Qureshi MA, 2015, SIGNAL PROCESS-IMAGE, V39, P46, DOI 10.1016/j.image.2015.08.008
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Soni B, 2018, IET IMAGE PROCESS, V12, P167, DOI 10.1049/iet-ipr.2017.0441
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Teerakanok S, 2019, IEEE ACCESS, V7, P40550, DOI 10.1109/ACCESS.2019.2907316
   Tong GE, 2016, ABDOM RADIOL, V41, P91, DOI 10.1007/s00261-015-0611-9
   Wang H, 2017, MULTIMED TOOLS APPL, V76, P12627, DOI 10.1007/s11042-016-3687-5
   Wang XY, 2017, MULTIMED TOOLS APPL, V76, P23353, DOI 10.1007/s11042-016-4140-5
   Yang B, 2018, MULTIMED TOOLS APPL, V77, P837, DOI 10.1007/s11042-016-4289-y
   Yang F, 2017, ENG APPL ARTIF INTEL, V59, P73, DOI 10.1016/j.engappai.2016.12.022
   Yao H, 2018, MULTIMED TOOLS APPL, V77, P18139, DOI 10.1007/s11042-017-5206-8
   Yao H, 2017, MULTIMED TOOLS APPL, V76, P12457, DOI 10.1007/s11042-016-3660-3
   Yavuz AA, 2017, IEEE T INF FOREN SEC, V12, P2627, DOI 10.1109/TIFS.2017.2716911
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zhao J, 2013, FORENSIC SCI INT, V233, P158, DOI 10.1016/j.forsciint.2013.09.013
NR 47
TC 11
Z9 12
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 24
BP 34585
EP 34612
DI 10.1007/s11042-019-08169-w
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JX9MV
UT WOS:000504051800016
DA 2024-07-18
ER

PT J
AU Zheng, XH
   Zheng, WF
   Yang, Y
   Guo, WZ
   Chang, V
AF Zheng, Xianghan
   Zheng, Wenfei
   Yang, Yang
   Guo, Wenzhong
   Chang, Victor
TI Clustering based interest prediction in social networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Social network; Clustering; Gaussian mixture model; Multi-Markov chain
ID FRAMEWORK
AB Efficient interest prediction for social networks is critical for both users and service providers for behavior analysis and a series of extension services. However, most existing approaches are inefficient, incomplete or isolated. In this paper, we propose combination of Gaussian and Markov approaches (namely, GAM) as typical soft computing technology for interest prediction of social intelligent multimedia systems. GAM model considers "the number of posted messages" as the only parameter, and defines selection logic to implement either Gaussian or Markov based approaches. Our proposed solution takes the advantage of Gaussian model in prediction accuracy and computation complexity, and advantage of Markov model in high availability. Further experiments illustrate that our solution achieves higher prediction accuracy of 94.3% (without considering the influence of swing users), with the best result achieved ever.
C1 [Zheng, Xianghan; Zheng, Wenfei; Yang, Yang; Guo, Wenzhong] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.
   [Zheng, Xianghan; Zheng, Wenfei; Yang, Yang; Guo, Wenzhong] Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.
   [Chang, Victor] Xian Jiaotong Liverpool Univ, Int Business Sch Suzhou, Suzhou, Peoples R China.
C3 Fuzhou University; Xi'an Jiaotong-Liverpool University
RP Zheng, XH (corresponding author), Fuzhou Univ, Coll Math & Comp Sci, Fuzhou, Fujian, Peoples R China.; Zheng, XH (corresponding author), Fujian Key Lab Network Comp & Intelligent Informa, Fuzhou, Fujian, Peoples R China.
EM xianghan.zheng@fzu.edu.cn
RI Chang, Victor/AAC-7582-2019
OI Chang, Victor/0000-0002-8012-5852
CR Abel F, 2013, USER MODEL USER-ADAP, V23, P169, DOI 10.1007/s11257-012-9131-2
   Abel F, 2011, LECT NOTES COMPUT SC, V6757, P28, DOI 10.1007/978-3-642-22233-7_3
   Agarwal V, 2013, SOC NETW ANAL MIN, V3, P359, DOI 10.1007/s13278-012-0083-7
   [Anonymous], P INT C MACH LEARN
   [Anonymous], 2014, CLUSTER ANAL APPL PR, DOI DOI 10.1016/C2013-0-06161-0
   [Anonymous], 2014, KALMAN FILTERING THE
   Attenberg J, 2009, KDD-09: 15TH ACM SIGKDD CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1067
   Baltrunas L, 2014, USER MODEL USER-ADAP, V24, P7, DOI 10.1007/s11257-012-9137-9
   Banerjee N., 2009, Proceedings of the 18th ACM conference on Information and knowledge management, P1823, DOI DOI 10.1145/1645953.1646240
   Carpineto C, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071390
   Erra U, 2015, INFORM SCIENCES, V292, P143, DOI 10.1016/j.ins.2014.08.062
   Fadaee Saber Shokat, 2015, SOCIAL NETWORK ANAL, V5, P1
   Felix W, 2016, IEEE ACM T NETWORK, V24, P2512
   González E, 2015, MACH LEARN, V98, P217, DOI 10.1007/s10994-013-5394-z
   Han X, 2015, DECIS SUPPORT SYST, V69, P92, DOI 10.1016/j.dss.2014.11.008
   HECKERMAN D, 1995, MACH LEARN, V20, P197, DOI 10.1023/A:1022623210503
   Herrmann JW, 2015, IEEE T ENG MANAGE, V62, P507, DOI 10.1109/TEM.2015.2456833
   Kunaver M, 2017, DIVERSITY RECOMMENDE
   Luo X, 2018, FUTUR GEN COMPUT SYS
   Melnykov V, 2012, COMPUT STAT DATA AN, V56, P1381, DOI 10.1016/j.csda.2011.11.002
   Meng ZM, 2012, CHIN OPT LETT, V10, DOI 10.3788/COL201210.112202
   Nori N., 2011, IJCAI, V11, P2507
   Scott John, 2012, Social network analysis
   Sharma P, 2017, FUTUR GEN COMPUT SYS
   Singhal S, 2013, INT J INNOV TECHNOL, V2
   Sun XL, 2015, EXPERT SYST APPL, V42, P4229, DOI 10.1016/j.eswa.2015.01.020
   Tang J, 2014, IEEE T KNOWL DATA EN, V26, P2914, DOI 10.1109/TKDE.2014.2320728
   Phan XH, 2011, IEEE T KNOWL DATA EN, V23, P961, DOI 10.1109/TKDE.2010.27
   Yager RR, 2013, IEEE T FUZZY SYST, V21, P672, DOI 10.1109/TFUZZ.2012.2227263
   Yan Q, 2013, PHYSICA A, V392, P1712, DOI 10.1016/j.physa.2012.12.008
   Yang MS, 2012, PATTERN RECOGN, V45, P3950, DOI 10.1016/j.patcog.2012.04.031
   Yu K, 2014, KNOWL DATA ENG IEEE, V27, P1
   Zarrinkalam F, 2018, INFORM RETRIE J
   Zhang ZK, 2010, PHYSICA A, V389, P179, DOI 10.1016/j.physa.2009.08.036
   Zheng XH, 2016, CONCURR COMP-PRACT E, V28, P3895, DOI 10.1002/cpe.3572
   Zheng XH, 2014, J INTERNET TECHNOL, V15, P1043, DOI 10.6138/JIT.2014.15.6.15
   Zhepeng L, 2017, MANAGE SCI, V63, P1938
   Zhiheng Xu, 2011, 2011 IEEE/WIC/ACM International Joint Conferences on Web Intelligence (WI) and Intelligent Agent Technologies, P422, DOI 10.1109/WI-IAT.2011.47
NR 38
TC 6
Z9 7
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2019
VL 78
IS 23
BP 32755
EP 32774
DI 10.1007/s11042-018-7009-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JS0JO
UT WOS:000500000600008
DA 2024-07-18
ER

PT J
AU Karmouni, H
   Jahid, T
   Hmimid, A
   Sayyouri, M
   Qjidaa, H
AF Karmouni, Hicham
   Jahid, Tarik
   Hmimid, Abdeslam
   Sayyouri, Mhamed
   Qjidaa, Hassan
TI Fast computation of inverse Meixner moments transform using Clenshaw's
   formula
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clenshaw's formula; Meixner moments; Fast computation; Inverse
   transform; image reconstruction
ID DISCRETE COSINE TRANSFORM; IMAGE-ANALYSIS; RECURSIVE COMPUTATION;
   RECOGNITION; ALGORITHM
AB Orthogonal moments are recognized as useful tools for object representation and image analysis. It was shown that they have better image representation capability than the continuous orthogonal moments. One problem concerning the use of moments is the high computational cost, which may limit where the online computation is required. In this paper, we propose a recursive method based on Clenshaw's recurrence formula that can be implemented to transform kernels of Meixner moments and its inverse for fast computation. There is no need for the proposed method to compute the Meixner polynomial values of various orders on various data points, where the computational complexity is reduced. Experimental results show that the proposed method performs better than the existing methods in term of computation speed and the effectiveness of image reconstruction capability in both noise-free and noisy conditions.
C1 [Karmouni, Hicham; Jahid, Tarik; Hmimid, Abdeslam; Qjidaa, Hassan] Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mahrez, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
   [Sayyouri, Mhamed] Sidi Mohamed Ben Abdellah Univ, Natl Sch Appl Sci, Engn Syst & Applicat Lab, BP 72,My Abdallah Ave Km 5 Imouzzer Rd, Fes, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Sidi Mohamed Ben Abdellah
   University of Fez
RP Karmouni, H (corresponding author), Univ Sidi Mohamed Ben Abdellah, Fac Sci Dhar El Mahrez, Lab Elect Signals & Syst Informat LESSI, CED ST,STIC, Fes, Morocco.
EM hicham.karmouni@usmba.ac.ma
RI Karmouni, Hicham/ACB-0232-2022; Sayyouri, Mhamed/AAB-5496-2020
OI Karmouni, Hicham/0000-0001-9225-8380; Sayyouri,
   Mhamed/0000-0002-1615-419X; Hassan, qjidaa/0000-0003-4505-5243
CR ABURDENE MF, 1995, IEEE SIGNAL PROC LET, V2, P155, DOI 10.1109/97.404131
   [Anonymous], 2017, MULTIMED TOOLS APPL
   [Anonymous], IEEE T IND ELECT
   Chau LP, 2000, IEEE SIGNAL PROC LET, V7, P276, DOI 10.1109/97.870678
   CHAU LP, 1994, ELECTRON LETT, V30, P197, DOI 10.1049/el:19940182
   Hosny KM, 2012, DIGIT SIGNAL PROCESS, V22, P476, DOI 10.1016/j.dsp.2012.01.002
   Hosny KM, 2011, PATTERN RECOGN LETT, V32, P795, DOI 10.1016/j.patrec.2011.01.006
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jahid T., 2018, J MATH IMAGING VIS, P1
   Karmouni H, 2017, J REAL-TIME IMAGE PR, V2019, P1
   Karmouni H, 2019, CIRC SYST SIGNAL PR, V38, P3715, DOI 10.1007/s00034-019-01025-0
   Karmouni H, 2018, CIRC SYST SIGNAL PR, V37, P4015, DOI 10.1007/s00034-018-0755-2
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Koekoek R, 2010, SPRINGER MONOGR MATH, P1, DOI 10.1007/978-3-642-05014-5
   Kozick RJ, 2000, TELECOMMUN SYST, V13, P69, DOI 10.1023/A:1019175519056
   Lan X., 2018, PATTERN RECOGN LETT
   Lan X, 2019, IEEE ACCESS
   Lan XY, 2018, IEEE T IMAGE PROCESS, V27, P2022, DOI 10.1109/TIP.2017.2777183
   Lan XY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2481325
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Nikiforov AF, 1991, CLASSICAL ORTHOGONAL
   Nikolajevic V, 2003, IEEE T SIGNAL PROCES, V51, P1439, DOI 10.1109/TSP.2002.808123
   Press W. H, 1992, NUMERICAL RECIPES C
   Sayyouri M., 2012, IEEE INT C COMPL SYS, P1
   Sayyouri M, 2012, COLLOQ INF SCI TECH, P101, DOI 10.1109/CIST.2012.6388071
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Wang GB, 2006, PATTERN RECOGN, V39, P47, DOI 10.1016/j.patcog.2005.05.015
   Wang GB, 2004, IEEE SIGNAL PROC LET, V11, P929, DOI 10.1109/LSP.2004.838187
   Wang ZD, 1994, IEEE SIGNAL PROC LET, V1, P101, DOI 10.1109/97.311803
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang H, 2010, IMAGE VISION COMPUT, V28, P38, DOI 10.1016/j.imavis.2009.04.004
   Zhu H, 2010, IET IMAGE PROCESS, V4, P335, DOI 10.1049/iet-ipr.2009.0195
NR 34
TC 19
Z9 19
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31245
EP 31265
DI 10.1007/s11042-019-07961-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000013
DA 2024-07-18
ER

PT J
AU Tang, LL
   Lu, HF
   Pang, Z
   Li, ZY
   Su, JY
AF Tang, Linlin
   Lu, Huifen
   Pang, Zhen
   Li, Zhangyan
   Su, Jingyong
TI A distance weighted linear regression classifier based on optimized
   distance calculating approach for face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Linear regression; Nearest subspace classifier; Object
   recognition
ID FEATURE-SELECTION; APPEARANCE
AB Linear regression technique is an efficient method to solve face recognition problem. It's based on the theory that images in the same class will also belong to same linear subspace and they can be represented through a linear equation. However, this method suffers from some misclassification problems for the infinite ductility of regression equation, moreover, it also doesn't make a proper and full use of the information in each sample. For overcoming these problems, a novel algorithm named the Distance Weighted Regression Classifier (DWLRC) is proposed here. It can be used for face recognition under different expression and illumination conditions through a distance weighted method, and it can also be used for optimizing the error in the final distance calculating stage. Experiments on three benchmarks show the better performance of our DWLRC compared with the traditional LRC and some state-of-art methods.
C1 [Tang, Linlin] Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
   [Lu, Huifen; Pang, Zhen; Li, Zhangyan] Harbin Inst Technol, Shenzhen, Peoples R China.
   [Su, Jingyong] Texas Tech Univ, Dept Math & Stat, Lubbock, TX 79409 USA.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Texas
   Tech University System; Texas Tech University
RP Tang, LL (corresponding author), Harbin Inst Technol, Shenzhen Grad Sch, Sch Comp Sci & Technol, Shenzhen, Peoples R China.
EM hittang@126.com
RI Xi, Yang/KEH-5204-2024
FU Shenzhen Science and Technology Plan [JCYJ20180306171938767]; Shenzhen
   Foundational Research Funding [JCYJ20180507183527919]
FX This work was supported by Shenzhen Science and Technology Plan under
   grant number JCYJ20180306171938767 and the Shenzhen Foundational
   Research Funding JCYJ20180507183527919.
CR [Anonymous], HDB FACE RECOGNITION
   [Anonymous], 2019, ADV INTELLIGENT SYST
   [Anonymous], 1996, EUR C COMP VIS
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Chien JT, 2002, DISCRIMINANT WAVELET
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   Feng QX, 2015, IEEE IMAGE PROC, P3630, DOI 10.1109/ICIP.2015.7351481
   Feng QX, 2015, J MOD OPTIC, V62, P288, DOI 10.1080/09500340.2014.975848
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332
   Jiang XD, 2008, IEEE T PATTERN ANAL, V30, P383, DOI 10.1109/TPAMI.2007.70708
   Leibe B, 2003, PROC CVPR IEEE, P409
   Lu JW, 2006, IEEE T NEURAL NETWOR, V17, P166, DOI 10.1109/TNN.2005.860853
   Lu YW, 2014, NEURAL COMPUT APPL, V24, P1843, DOI 10.1007/s00521-013-1435-6
   Mi JX, 2013, NEUROCOMPUTING, V113, P241, DOI 10.1016/j.neucom.2013.01.003
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Nefian A. V., 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P133, DOI 10.1109/ICME.2002.1035530
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Semwal VB, 2017, MULTIMED TOOLS APPL, V76, P24457, DOI 10.1007/s11042-016-4110-y
   Semwal VB, 2017, NEURAL COMPUT APPL, V28, P565, DOI 10.1007/s00521-015-2089-3
   Semwal VB, 2015, ROBOT AUTON SYST, V65, P65, DOI 10.1016/j.robot.2014.11.010
   Xu Y, 2011, IEEE T CIRC SYST VID, V21, P1255, DOI 10.1109/TCSVT.2011.2138790
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhu ML, 2003, COMPUTER SCI, P1457
NR 25
TC 5
Z9 6
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32485
EP 32501
DI 10.1007/s11042-019-07943-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000063
DA 2024-07-18
ER

PT J
AU Xiong, ZG
   Wu, Y
   Ye, CH
   Zhang, XM
   Xu, F
AF Xiong, Zenggang
   Wu, Yuan
   Ye, Conghuan
   Zhang, Xuemin
   Xu, Fang
TI Color image chaos encryption algorithm combining CRC and nine palace map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image encryption; Cyclic redundancy check (CRC); Nine palace map;
   Logistic map; Cross shift
ID PERMUTATION; NETWORK; SYSTEM
AB The color image encryption algorithm based on the chaos theory is not strong enough. In this paper, we proposed a color image chaos encryption algorithm combining Cyclic Redundancy Check (CRC) and nine palace map. Firstly, the pixel data of the plain image were moved and shuffled based on the theory of nine palace map. And the R, G and B components were extracted and converted into a binary sequence matrix that was then cyclically shifted based on the technology of generating CRC code. Finally, the encrypted image was derived from the XOR operation with random key matrix. The average entropy of encrypted image by our algorithm is 7.9993, which is slight improved compared with the coupled hyper chaotic Lorenz algorithm in previous studies. In addition, the algorithm has the advantages of large key space, high key sensitivity, anti-robust attack, and feasible encryption efficiency.
C1 [Xiong, Zenggang; Wu, Yuan; Ye, Conghuan; Zhang, Xuemin; Xu, Fang] Hubei Engn Univ, Sch Comp & Informat Sci, Xiaogan 432000, Hubei, Peoples R China.
   [Xiong, Zenggang; Wu, Yuan; Ye, Conghuan; Xu, Fang] Hubei Univ, Sch Comp Sci & Informat Engn, Wuhan 430062, Hubei, Peoples R China.
C3 Hubei Engineering University; Hubei University
RP Xiong, ZG; Wu, Y (corresponding author), Hubei Engn Univ, Sch Comp & Informat Sci, Xiaogan 432000, Hubei, Peoples R China.; Xiong, ZG; Wu, Y (corresponding author), Hubei Univ, Sch Comp Sci & Informat Engn, Wuhan 430062, Hubei, Peoples R China.
EM xzg@hbeu.edu.cn; yuanywu@126.com
OI Xiong, Zenggang/0000-0003-4467-9599
FU National Natural Science Foundation of China [61502154, 61370092]; Hubei
   Provincial Department of Education Outstanding Youth Scientific
   Innovation Team Support Foundation [T201410]; MOE (Ministry of Education
   in China) Project of Humanities and Social Sciences [17YJCZH203]
FX This work was supported by the National Natural Science Foundation of
   China (No.61502154, 61370092), Hubei Provincial Department of Education
   Outstanding Youth Scientific Innovation Team Support Foundation
   (T201410), the MOE (Ministry of Education in China) Project of
   Humanities and Social Sciences (17YJCZH203).
CR AqeelurRehman LX, 2018, OPTIK, V153
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P1159, DOI 10.1007/s11042-015-3088-1
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Chen JX, 2018, OPT LASER TECHNOL, V99, P238, DOI 10.1016/j.optlastec.2017.09.008
   Cheng XL, 2018, IEEE J SEL AREA COMM, V36, P2218, DOI 10.1109/JSAC.2018.2869958
   Cheng YT, 2006, INT CONF NANO MICRO, P1
   Fu C, 2017, 2017 18TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNDP 2017), P121, DOI 10.1109/SNPD.2017.8022710
   Hu F., 2017, BIG DATA COMPUTATION
   Hua Z, 2017, SIGNAL PROCESS, V144
   Huang CW, 2017, 2017 IEEE 28TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), DOI 10.1109/PIMRC.2017.8292737
   Kadir A, 2017, OPTIK, V129, P231, DOI 10.1016/j.ijleo.2016.10.036
   Kanafchian M, 2017, INT J E-NAVIG MARIT, V6, P53, DOI 10.1016/j.enavi.2017.05.007
   Kanso A, 2017, OPT LASER ENG, V90, P196, DOI 10.1016/j.optlaseng.2016.10.009
   Kumar M, 2016, SIGNAL PROCESS, V125, P187, DOI 10.1016/j.sigpro.2016.01.017
   Lan RS, 2018, SIGNAL PROCESS, V147, P133, DOI 10.1016/j.sigpro.2018.01.026
   Li YB, 2016, IEEE T COMPUT, V65, P1339, DOI 10.1109/TC.2015.2470247
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu H, 2017, 3D RES, V8, DOI 10.1007/s13319-016-0114-7
   Ma YX, 2018, IEEE ACCESS, V6, P14451, DOI 10.1109/ACCESS.2018.2806483
   Mahesh M, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P1849, DOI 10.1109/ICCSP.2015.7322844
   Martin K, 2005, PATTERN RECOGN, V38, P1111, DOI 10.1016/j.patcog.2005.01.002
   Mollaeefar M, 2017, MULTIMED TOOLS APPL, V76, P607, DOI 10.1007/s11042-015-3064-9
   Parvaz R, 2017, COMBINATION CHAOTIC
   Ping P, 2017, NEUROCOMPUTING
   Qiu H, 2014, IEEE INT S MULT
   Qiu H, 2017, IEEE INT C CYB SEC C
   Sankpal PR, 2014, 2014 FIFTH INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP 2014), P102, DOI 10.1109/ICSIP.2014.80
   Sokouti M, 2018, COMPUT SCI REV, V29, P14, DOI 10.1016/j.cosrev.2018.05.002
   Sosa C, 2010, IEEE INT C PAR DISTR
   Su YG, 2017, OPT LASER ENG, V88, P20, DOI 10.1016/j.optlaseng.2016.07.012
   Teng L, 2018, MULTIMED TOOLS APPL, V77, P6883, DOI 10.1007/s11042-017-4605-1
   Wang XY, 2015, OPT COMMUN, V342, P51, DOI 10.1016/j.optcom.2014.12.043
   Ye CH, 2016, INT J SECUR APPL, V10, P125, DOI 10.14257/ijsia.2016.10.1.13
   Ye CH, 2014, J VISUAL LANG COMPUT, V25, P658, DOI 10.1016/j.jvlc.2014.10.020
   Ye G, 2017, EFFICIENT SYMMETRIC
   Zhang XQ, 2017, OPT LASER ENG, V92, P6, DOI 10.1016/j.optlaseng.2016.12.005
   Zhang YJ, 2015, IEEE T VLSI SYST, V23, P1170, DOI 10.1109/TVLSI.2014.2326797
   Zhang YQ, 2016, OPT LASER ENG, V82, P95, DOI 10.1016/j.optlaseng.2016.02.002
   Zhou NR, 2018, QUANTUM INF PROCESS, V17, DOI 10.1007/s11128-018-1902-1
   Zhu LH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P601
NR 41
TC 125
Z9 127
U1 1
U2 82
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 31035
EP 31055
DI 10.1007/s11042-018-7081-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000003
DA 2024-07-18
ER

PT J
AU Zakaria, Y
   Nassar, RM
   Zahran, O
   Hussein, GA
   El-Rabaie, ESM
   El-Khamy, SE
   Al-Nuaimy, W
   El-Dokany, IM
   Abd El-Samie, FE
AF Zakaria, Y.
   Nassar, Rana M.
   Zahran, Osama
   Hussein, Gamal Attia
   El-Rabaie, El-Sayed M.
   El-Khamy, Said E.
   Al-Nuaimy, Waleed
   El-Dokany, Ibrahim M.
   Abd El-Samie, Fathi E.
TI Cancelable multi-biometric security system based on double random phase
   encoding and cepstral analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cancelable biometrics; Compression; Encryption; DCT; DRPE; Cepstral
   analysis
ID FOURIER PLANE
AB Biometric systems are widely used now for security applications. Two major problems are encountered in biometric systems: the security problem and the dependence on a single biometric for verification. The security problem arises from the utilization of the original biometrics in databases. So, if these databases are attacked, the biometrics are lost forever. Hence, there is a need to secure original biometrics by keeping them away from utilization in biometric databases. Cancelable biometrics is an emerging security trend in the field of biometric authentication. The objective of cancelable biometrics is to generate fake versions of the biometrics through non-invertible transforms or encryption methods to save the original biometrics from being compromised to guarantee their security. The other problem of biometric verification is the dependence on a single biometric, which reduces the trustiness of the verification results. Hence, there is a bad need to use multiple biometrics for trusted verification results. Multiple biometrics can be acquired for the same person and used for verification with a majority voting scenario to ensure trusted verification results. So, there is a need to save all biometrics in a secure way, which allows authentication from each of them, afterwards. The storage of multiple biometrics consumes storage space. Hence, there is a need for some sort of compression to save this storage space, while keeping the discrimination ability of subjects. This paper presents a novel approach that solves the security, trustiness, and storage problems of biometric systems. It is a cancelable multi-biometric security system based on Double Random Phase Encoding (DRPE) and cepstral analysis. Four biometrics are comprised in a unified biometric template for each person using Discrete Cosine Transform (DCT) compression. This unified biometric template is encrypted with the DRPE algorithm for security purposes. The cancelability is guaranteed through the ability to change the random phase sequences of the DRPE algorithm if the database is compromised. The multi-biometric compression is performed through keeping the most significant coefficients in the DCT domain for all four biometrics. The biometric recognition is performed by decrypting the unified biometric template and applying a cepstral approach for verification of the subject. A majority voting scheme can be followed for biometric verification at the receivers of remote-access biometric systems. The main advantage of the proposed cancelable multi-biometric system is the large degree of security, the immunity to communication channel effects through the utilization of a majority voting strategy at the receiver, the ability to withstand the compression effect, and the irreversibility through the implementation of cepstral features for biometric verification.
C1 [Zakaria, Y.; Nassar, Rana M.; Zahran, Osama; El-Rabaie, El-Sayed M.; El-Dokany, Ibrahim M.; Abd El-Samie, Fathi E.] Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
   [Zakaria, Y.] Giza Syst, Cairo, Egypt.
   [Hussein, Gamal Attia] Alexandria Higher Inst Engn & Technol AIET, Alexandria, Egypt.
   [El-Khamy, Said E.] Alexandria Univ, Dept Elect Engn, Fac Engn, Alexandria, Egypt.
   [Al-Nuaimy, Waleed] Univ Liverpool, Dept Elect & Elect Engn, Liverpool, Merseyside, England.
C3 Egyptian Knowledge Bank (EKB); Menofia University; Egyptian Knowledge
   Bank (EKB); Alexandria University; University of Liverpool
RP Nassar, RM (corresponding author), Menoufia Univ, Dept Elect & Elect Commun Engn, Fac Elect Engn, Menoufia 32952, Egypt.
EM y.z.hatem@gmail.com; engrana48@yahoo.com;
   osama_zahran@el-eng.menofia.edu.eg; gamal_ertu_sat@yahoo.com;
   srabie1@yahoo.com; elkhamy@ieee.org; wax@liv.ac.uk;
   dokany_2006@hotmail.com; fathi_sayed@yahoo.com
RI El-Khamy, Said E./AAE-6748-2020; Sayed, Fathi/HRA-4752-2023
OI Sayed, Fathi/0000-0001-8749-9518; Zahran, Osama/0000-0001-5334-5908;
   EL-Rabaie, El-Sayed/0000-0001-6854-5881
CR Abd El-Samie FE, 2011, SPRINGERBRIEF SPEECH, P1, DOI 10.1007/978-1-4419-9698-5_1
   Ali MM, 2018, CANCELABLE BIOMETRIC, P434
   Alkolidi A, 2007, J SIGNAL PROCESSING, V87, P569, DOI [10.1016/j.sigpro.2006.06.011, DOI 10.1016/J.SIGPRO.2006.06.011]
   [Anonymous], 2017, INTEGRATED MALWARE A, DOI DOI 10.1109/TENCONSPRING.2017.8070066
   Falou AA, 2005, P SOC PHOTO-OPT INS, V5823, P183, DOI 10.1117/12.604881
   Gowthami AT, 2015, PROCEDIA COMPUT SCI, V58, P552, DOI 10.1016/j.procs.2015.08.072
   Guitter H, 1995, COMPRESSION IMAGES N, P1
   Neifeld MA, 2006, APPL OPTICS, V45, P2857, DOI 10.1364/AO.45.002857
   Qiu J., 2018, IOP Conference Series: Materials Science and Engineering, P60, DOI [10.1088/1757-899X/322/5/052050, DOI 10.1088/1757-899X/322/5/052050]
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rathgeb C, 2015, CANCELABLE MULTIBIOM, P1
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Reif J. H., 1992, DCC '92. Data Compression Conference (Cat. No.92TH0436-6), P32, DOI 10.1109/DCC.1992.227478
   Sandhya M, 2017, INT J PATTERN RECOGN, V31, DOI 10.1142/S0218001417560043
   So liman RF, 2018, P NATL ACAD SCI
   Soliman RF, 2018, APPL OPTICS, V57, P10305, DOI 10.1364/AO.57.010305
   Soliman RF, 2018, OPT QUANT ELECTRON, V50, DOI 10.1007/s11082-018-1591-0
   Soliman RF, 2018, MODIFIED CANCELABLE, P1
   Soualmi S, 2007, J OPT A-PURE APPL OP, V9, P73, DOI 10.1088/1464-4258/9/1/013
NR 19
TC 11
Z9 11
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2019
VL 78
IS 22
BP 32333
EP 32355
DI 10.1007/s11042-019-07824-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JL2ZI
UT WOS:000495400000056
DA 2024-07-18
ER

PT J
AU Kim, JH
   Lee, J
AF Kim, Jong-Hyun
   Lee, Jung
TI Layered non-photorealistic rendering with anisotropic depth-of-field
   filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Anisotropic depth of field; Image abstraction; Non-photorealistic
   rendering; Image processing
AB In this paper, we provide a layered non-photorealistic rendering (NPR) technique that automatically extracts the depth of field (DoF) shown in the picture and adjusts the degree of abstraction accordingly. We use an RGB channel to efficiently classify the DoF region anisotropically. Based on the DoF values, we abstract the color and adjust the thickness of the line. We use anisotropic DoF-based filtering to improve the abstraction quality by finding the blur region using cross-correlation filtering and anisotropically calculating the weight map. Our approach has greatly improved the quality of abstraction in terms of performance and design. The algorithm is also fast and simple to implement. Experimental results show well the characteristics and style of the DoF of the original photograph.
C1 [Kim, Jong-Hyun] Hallym Univ, Chunchon, Gangwon, South Korea.
   [Lee, Jung] Hallym Univ, Dept Convergence Software, Chunchon, Gangwon, South Korea.
C3 Hallym University; Hallym University
RP Lee, J (corresponding author), Hallym Univ, Dept Convergence Software, Chunchon, Gangwon, South Korea.
EM airjung@hallym.ac.kr
OI Lee, Jung/0000-0003-0458-1474
CR Allison W., 2002, P 2 INT S NONPHOTORE, P21
   [Anonymous], 2002, P 2 INT S NONPH AN R, DOI DOI 10.1145/508535.508537
   [Anonymous], 2002, CRC SER EXERC PHSIOL
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Collomosse JP, 2006, GRAPH MODELS, V68, P402, DOI 10.1016/j.gmod.2006.05.003
   Collomosse JP, 2003, IEEE T VIS COMPUT GR, V9, P443, DOI 10.1109/TVCG.2003.1260739
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DeCarlo D, 2003, ACM T GRAPHIC, V22, P848, DOI 10.1145/882262.882354
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Deussen O, 2000, COMPUT GRAPH FORUM, V19, pC41, DOI 10.1111/1467-8659.00396
   Durand F, 2001, SPRING EUROGRAP, P71
   Fels S., 1999, Proc. ofthe Workshop on New Paradigms for Interactive Visualization and Manipulation (NPIVM), P78
   Finkelstein A., 1998, Electronic Publishing, Artistic Imaging, and Digital Typography. 7th International Conference on Electronic Publishing, EP'98, Held Jointly with the 4th International Conference on Raster Imaging and Digital Typography, RIDT'98 Proceedings, P11, DOI 10.1007/BFb0053259
   Fischer J, 2005, P IEEE VIRT REAL ANN, P195
   Gal R, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P7
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   Gooch B., 2002, 2 INT S NONPHOTOREAL, P83
   Hausner A, 2001, COMP GRAPH, P573, DOI 10.1145/383259.383327
   Hays J., 2004, PROC NPAR 01, P113
   Hertzmann A., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P453, DOI 10.1145/280814.280951
   Isenberg T, 2003, IEEE COMPUT GRAPH, V23, P28, DOI 10.1109/MCG.2003.1210862
   Kalnins RD, 2003, ACM T GRAPHIC, V22, P856, DOI 10.1145/882262.882355
   Kang H, 2009, IEEE T VIS COMPUT GR, V15, P62, DOI 10.1109/TVCG.2008.81
   Kaplan CS, 2000, COMP GRAPH, P499, DOI 10.1145/344779.345022
   KLEIN A, 2001, MSRTR200145
   Litwinowicz P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P407, DOI 10.1145/258734.258893
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Mi X., 2009, Proc. NPAR '09, P15
   Morel J.-M., 2006, Texture synthesis by abstract painting technique
   Mureika JR, 2005, PHYS REV E, V72, DOI 10.1103/PhysRevE.72.046101
   Orchard J., 2008, P 6 INT S NONPH AN R, P79, DOI DOI 10.1145/1377980.1377997
   Orzan A, 2007, NPAR 2007: 5TH INTERNATIONAL SYMPOSIUM ON NON-PHOTOREALISTIC ANIMATION AND RENDERING, PROCEEDINGS, P103
   Ostromoukhov V, 1999, COMP GRAPH, P417, DOI 10.1145/311535.311604
   Raskar R., 2004, NONPHOTOREALISTIC AN, P85, DOI DOI 10.1145/987657.987671
   Salisbury M. P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P101, DOI 10.1145/192161.192185
   Salisbury M. P., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P401, DOI 10.1145/258734.258890
   Smith K., 2005, Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, SCA '05, P201
   Sousa MC, 2000, COMPUT GRAPH FORUM, V19, P27, DOI 10.1111/1467-8659.00386
   Sousa MC, 2003, COMPUT GRAPH FORUM, V22, P381, DOI 10.1111/1467-8659.00685
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wallraven C, 2009, COMPUT GRAPH-UK, V33, P484, DOI 10.1016/j.cag.2009.04.003
   Wang J, 2004, ACM T GRAPHIC, V23, P574, DOI 10.1145/1015706.1015763
   Wen F., 2006, PROC INT S NONPHOTOR, P47
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
NR 44
TC 6
Z9 6
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2020
VL 79
IS 1-2
BP 1291
EP 1309
DI 10.1007/s11042-019-08387-2
EA OCT 2019
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KS0FL
UT WOS:000492944000001
DA 2024-07-18
ER

PT J
AU Chen, J
   Wang, BH
   Liao, J
   Cai, CH
AF Chen, Jing
   Wang, Bohan
   Liao, Jie
   Cai, Canhui
TI Fast 3D-HEVC inter mode decision algorithm based on the texture
   correlation of viewpoints
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D-HEVC; Inter prediction; Video compression; Skip mode
AB To reduce the computational complexity of 3D-HEVC, a fast inter mode decision algorithm based on texture correlation of adjacent viewpoints is proposed (FMD_inter). By studying the statistical probability of inter prediction mode distributions in 3D-HEVC coding scheme, the mode of dependent view is highly correlated with the base one, which enables the early mode decision. Moreover, by analyzing the relationship between video texture and the inter prediction mode, selectively skip checking symmetric motion partition (SMP) mode and asymmetric motion partition (AMP) mode according to the texture features of coding unit is reasonable. The proposed algorithm is able to achieve a reduction of computational complexity by 18.71% on average, while maintaining the coding efficiency. The subjective quality of the synthesized views also shows the effectiveness of the algorithm.
C1 [Chen, Jing; Wang, Bohan; Liao, Jie; Cai, Canhui] Huaqiao Univ, Sch Informat Sci & Enginnering, Xiamen, Fujian, Peoples R China.
   [Chen, Jing; Wang, Bohan; Liao, Jie; Cai, Canhui] Xiamen Key Lab Mobile Multimedia Commun, Xiamen, Fujian, Peoples R China.
C3 Huaqiao University
RP Chen, J (corresponding author), Huaqiao Univ, Sch Informat Sci & Enginnering, Xiamen, Fujian, Peoples R China.; Chen, J (corresponding author), Xiamen Key Lab Mobile Multimedia Commun, Xiamen, Fujian, Peoples R China.
EM chenjing8005@gmail.com; 806119020@qq.com; 397562747@qq.com;
   chcai@hqu.edu.cn
FU National Natural Science Foundation of China [61802136, 61871434];
   Natural Science Foundation of Fujian Province [2017 J05103, 2016
   J01308]; Fujian-100 Talented People Program; High-level Talent
   Innovation Program of Quanzhou City [2017G027]; Promotion Program for
   Young andMiddle-aged Teacher in Science and Technology Research of
   Huaqiao University [ZQN-YX403]; High-Level Talent Project Foundation of
   Huaqiao University [16BS709, 14BS201, 14BS204]
FX This work was partially supported by National Natural Science Foundation
   of China (Grant Nos. 61802136 and 61871434), Natural Science Foundation
   of Fujian Province (Grant Nos. 2017 J05103 and 2016 J01308), Fujian-100
   Talented People Program, High-level Talent Innovation Program of
   Quanzhou City (Grant No. 2017G027), Promotion Program for Young
   andMiddle-aged Teacher in Science and Technology Research of Huaqiao
   University (Grant No. ZQN-YX403), High-Level Talent Project Foundation
   of Huaqiao University (Grant Nos. 16BS709, 14BS201 and 14BS204).
CR [Anonymous], 2018, 3D HEVC REFERENCE SO
   Bjotegaard G., 2001, VCEGM33
   Chen J, 2017, J VIS COMMUN IMAGE R, V48, P329, DOI 10.1016/j.jvcir.2017.05.006
   Chen Y., 2015, JCT3VJ1003
   Chen Y, 2014, J VIS COMMUN IMAGE R, V25, P679, DOI 10.1016/j.jvcir.2013.03.013
   Chi G, 2015, VIS COMM IM PROC C V, P374
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Hsia CH, 2016, IEEE SENS J, V16, P4521, DOI 10.1109/JSEN.2016.2542259
   Jaballah S, 2018, SIGNAL PROCESS-IMAGE, V67, P34, DOI 10.1016/j.image.2018.05.007
   JCT-VC, 2011, CALL PROP 3D VID COD
   Lie WN, 2015, IEEE IMAGE PROC, P2685, DOI 10.1109/ICIP.2015.7351290
   Lin JL, 2018, J VIS COMMUN IMAGE R, V50, P83, DOI 10.1016/j.jvcir.2017.11.003
   Muller K., 2014, COMMON TEST CONDITIO
   Park CS, 2015, IEEE T IMAGE PROCESS, V24, P155, DOI 10.1109/TIP.2014.2375653
   Shen LQ, 2018, IEEE T IMAGE PROCESS, V27, P4195, DOI 10.1109/TIP.2018.2837379
   Song YX, 2015, J VIS COMMUN IMAGE R, V33, P60, DOI 10.1016/j.jvcir.2015.07.001
   Tan SC, 2017, IEEE T CIRC SYST VID, V27, P337, DOI 10.1109/TCSVT.2015.2511878
   Tohidypour HR, 2016, IEEE T CIRC SYST VID, V26, P1870, DOI 10.1109/TCSVT.2015.2477955
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Zhang HouJiang Zhang HouJiang, 2016, Journal of Forestry Engineering, V1, P1
NR 20
TC 7
Z9 8
U1 3
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29291
EP 29305
DI 10.1007/s11042-018-6832-5
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700048
DA 2024-07-18
ER

PT J
AU Hou, RC
   Nie, RC
   Zhou, DM
   Cao, JD
   Liu, D
AF Hou, Ruichao
   Nie, Rencan
   Zhou, Dongming
   Cao, Jinde
   Liu, Dong
TI Infrared and visible images fusion using visual saliency and optimized
   spiking cortical model in non-subsampled shearlet transform domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image fusion; Non-subsampled shearlet transform; Visual saliency map;
   Multi-objective artificial bee colony; Spiking cortical model
ID GENERALIZED NEURAL-NETWORKS; EXPONENTIAL STABILITY; PERFORMANCE;
   DISSIPATIVITY; INFORMATION
AB Aiming at some problems in existing infrared and visible image fusion methods such as edge blurring, low contrast, loss of details, a novel fusion scheme based on non-subsampled shearlet transform (NSST), visual saliency and multi-objective artificial bee colony (MOABC) optimizing spiking cortical mode (SCM) is proposed. NSST has many advantages such as multi-scale features and sparse representation. Moreover, the visual saliency map can improve the low frequency fusion strategy, and SCM has coupling and pulse synchronization properties. Firstly, NSST is utilized to decompose the source image into a low-frequency subband and a series of high-frequency subbands. Secondly, the low-frequency subband is fused by SCM, where SCM is motivated by the edge saliency map of the low-frequency subband of the source image, and then the high-frequency subbands are also fused by SCM, where the modified spatial frequency of the high-frequency subbands of the source image is adopted as the input stimulus of SCM, the parameters of SCM are optimized by the novel multi-objective artificial bee colony technique. Finally, the fused image is reconstructed by inverse NSST. Experimental results indicate that the proposed scheme performs well and has obvious superiorities over other current typical ones in both subjective visual performance and objective criteria.
C1 [Hou, Ruichao; Nie, Rencan; Zhou, Dongming; Liu, Dong] Yunnan Univ, Informat Coll, Kunming 650504, Yunnan, Peoples R China.
   [Nie, Rencan; Cao, Jinde] Southeast Univ, Dept Math, Nanjing 210096, Jiangsu, Peoples R China.
C3 Yunnan University; Southeast University - China
RP Zhou, DM (corresponding author), Yunnan Univ, Informat Coll, Kunming 650504, Yunnan, Peoples R China.
EM zhoudm@ynu.edu.cn
RI Cao, Jinde/D-1482-2012
OI Cao, Jinde/0000-0003-3133-7119
FU National Natural Science Foundation of China [61463052, 61365001]
FX The authors' work is supported by the National Natural Science
   Foundation of China (no. 61463052 and no.61365001).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Akbari R, 2012, SWARM EVOL COMPUT, V2, P39, DOI 10.1016/j.swevo.2011.08.001
   Banharnsakun A, 2015, NEURAL COMPUT APPL, P1, DOI [10.1007/s00521-015-2061-2, DOI 10.1007/S00521-015-2061-2(2015)]
   Current John R, 1990, COMPUT OPER RES, V17, P187
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Gan W, 2015, INFRARED PHYS TECHN, V72, P37, DOI 10.1016/j.infrared.2015.07.003
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Hou XD, 2007, PROC CVPR IEEE, P2280
   ITO Y, 1991, NEURAL NETWORKS, V4, P385, DOI 10.1016/0893-6080(91)90075-G
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jin X, 2017, STRUCTURE, V1298, P1
   Jin X, 2017, INFRARED PHYS TECHN, V85, P478, DOI 10.1016/j.infrared.2017.07.010
   Jin X, 2016, J SENSORS, V2016, DOI 10.1155/2016/8359602
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Karaboga D, 2008, APPL SOFT COMPUT, V8, P687, DOI 10.1016/j.asoc.2007.05.007
   Kong WW, 2013, ELECTRON LETT, V49, P802, DOI 10.1049/el.2013.1192
   Kong WW, 2015, INFRARED PHYS TECHN, V71, P87, DOI 10.1016/j.infrared.2015.02.008
   Kong WW, 2014, INFRARED PHYS TECHN, V65, P103, DOI 10.1016/j.infrared.2014.04.003
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Liu Z, 2018, INFORM FUSION, V42, P127, DOI 10.1016/j.inffus.2017.10.010
   Luo LH, 2018, COGENT ENG, V5, P1, DOI 10.1080/23311916.2018.1491264
   Ma JL, 2017, INFRARED PHYS TECHN, V82, P8, DOI 10.1016/j.infrared.2017.02.005
   Manivannan R, 2017, J FRANKLIN I, V354, P6312, DOI 10.1016/j.jfranklin.2017.07.040
   Manivannan R, 2017, J FRANKLIN I, V354, P4353, DOI 10.1016/j.jfranklin.2017.04.007
   Manivannan R, 2017, NEURAL NETWORKS, V87, P149, DOI 10.1016/j.neunet.2016.12.005
   Manivannan R, 2017, INF SCI, V424, P175
   Nasiraghdam H, 2012, SOL ENERGY, V86, P3057, DOI 10.1016/j.solener.2012.07.014
   Petrovic V, 2004, LECT NOTES COMPUT SC, V3023, P380
   Song YD, 2016, IEEE GEOSCI REMOTE S, V13, P18, DOI 10.1109/LGRS.2015.2492569
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wang Q, 2016, PROC SPIE, V10033, DOI 10.1117/12.2245043
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei CM, 2010, INFORM FUSION, V11, P301, DOI 10.1016/j.inffus.2009.10.006
   Xu XZ, 2016, APPL SOFT COMPUT, V46, P588, DOI 10.1016/j.asoc.2016.03.028
   Yang XM, 2018, IEEE ACCESS, V6, P5511, DOI 10.1109/ACCESS.2018.2790482
   Yang XH, 2010, INT CONF COMP SCI, P262, DOI 10.1109/ICCSIT.2010.5565051
   Zhan K, 2017, ARCH COMPUT METHOD E, V24, P573, DOI 10.1007/s11831-016-9182-3
   Zhan K, 2009, IEEE T NEURAL NETWOR, V20, P1980, DOI 10.1109/TNN.2009.2030585
   Zhang BH, 2015, INFRARED PHYS TECHN, V73, P286, DOI 10.1016/j.infrared.2015.10.004
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 44
TC 27
Z9 27
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28609
EP 28632
DI 10.1007/s11042-018-6099-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700015
DA 2024-07-18
ER

PT J
AU Liu, HB
   Chang, FL
   Liu, CS
AF Liu, Hongbin
   Chang, Faliang
   Liu, Chunsheng
TI Multi-target tracking with hierarchical data association using
   main-parts and spatial-temporal feature models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data association; Appearance variation; Main-parts; Spatial-temporal
   feature; Multi-target tracking
ID ONLINE MULTIOBJECT TRACKING; MULTIPLE-PERSON TRACKING; CONFIDENCE
AB Multi-target tracking in complex scenes is challenging because target appearance features generate partial or significant variations frequently. In order to solve the problem, we propose a multi-target tracking method with hierarchical data association using main-parts and spatial-temporal feature models. In our tracking framework, target feature models and tracklets are initialized when the new targets appear. Main-parts feature model is presented to represent target with partial or no appearance variations. It is established by partitioning a target template into several parts and formulating appearance variation densities of these parts. For the target with significant appearance variations, the tracker learns its global spatial-temporal feature model by integrating appearance with histogram of optical flow features. During tracking, tracklet confidence is exploited to implement hierarchical data association. According to different tracklet confidence values, main-parts and global data association are respectively performed by employing main-parts and spatial-temporal feature models. As a result, our approach uses the Hungarian algorithm to obtain optimal associated pairs between target tracklets and detections. Finally, target feature models and tracklets are updated by the association detections for subsequently tracking. Experiments conducted on CAVIAR, Parking Lot and MOT15 datasets verify the effectiveness and improvement of our multi-target tracking method.
C1 [Liu, Hongbin; Chang, Faliang; Liu, Chunsheng] Shandong Univ, Sch Control Sci & Engn, Jingshi Rd, Jinan 250061, Shandong, Peoples R China.
C3 Shandong University
RP Chang, FL (corresponding author), Shandong Univ, Sch Control Sci & Engn, Jingshi Rd, Jinan 250061, Shandong, Peoples R China.
EM flchang@sdu.edu.cn
RI Liu, Chunsheng/L-1636-2017
FU National Natural Science Foundation of China [61673244, 61703240]
FX =This work was supported by the National Natural Science Foundation of
   China, No. 61673244 and 61703240.
CR Ahuja R. K., 1993, Network flows: theory, algorithms, and applications
   [Anonymous], 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]
   [Anonymous], P 14 IEEE INT C ADV
   Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015
   Dong WH, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.1.013006
   Hao T, 2018, MULTIMED TOOLS APPL, V77, P3623, DOI 10.1007/s11042-017-5218-4
   Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42
   Izadinia H, 2012, LECT NOTES COMPUT SC, V7577, P100, DOI 10.1007/978-3-642-33783-3_8
   Ju J, 2017, J OPT SOC AM A, V34, P280, DOI 10.1364/JOSAA.34.000280
   Ju J, 2017, IET COMPUT VIS, V11, P87, DOI 10.1049/iet-cvi.2016.0068
   Kim TK, 2011, INT J COMPUT VISION, V91, P216, DOI 10.1007/s11263-010-0381-3
   Kuo CH, 2011, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2011.5995384
   Leal-Taixe L., 2015, ARXIV15041942
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   Lv L, 2016, OPT ENG, V55, DOI 10.1117/1.OE.55.8.083106
   Meinhardt-Llopis E, 2013, IMAGE PROCESS ON LIN, V3, P151, DOI 10.5201/ipol.2013.20
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Naiel MA, 2017, COMPUT VIS IMAGE UND, V154, P94, DOI 10.1016/j.cviu.2016.07.003
   Pòiesi F, 2013, COMPUT VIS IMAGE UND, V117, P1257, DOI 10.1016/j.cviu.2012.08.008
   Redmon J, 2016, IEEE C COMP VIS PATT, P51
   Robert F, 2001, CAVIAR CONTEXT AWARE
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Sun X, 2014, SIGNAL IMAGE VIDEO P, V8, pS95, DOI 10.1007/s11760-014-0674-z
   Topkaya IS, 2016, SIGNAL IMAGE VIDEO P, V10, P795, DOI 10.1007/s11760-015-0817-x
   Wang N, 2013, P ADV NEURAL INFORM
   Wang NN, 2018, IEEE T CIRC SYST VID, V28, P2154, DOI 10.1109/TCSVT.2017.2709465
   Wang NN, 2018, PATTERN RECOGN, V76, P215, DOI 10.1016/j.patcog.2017.11.008
   Wang NN, 2017, IEEE T IMAGE PROCESS, V26, P1264, DOI 10.1109/TIP.2017.2651375
   Xiang J, 2016, IEEE T CIRC SYST VID, V26, P2028, DOI 10.1109/TCSVT.2015.2489438
   YANG B, 2012, PROC CVPR IEEE, P1918, DOI DOI 10.1109/CVPR.2012.6247892
   Yang M, 2016, COMPUT VIS IMAGE UND, V153, P16, DOI 10.1016/j.cviu.2016.05.003
   Yang M, 2009, IEEE I CONF COMP VIS, P1554, DOI 10.1109/ICCV.2009.5459252
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Zhang W, 2018, IEEE T CIRC SYST VID, V28, P2768, DOI 10.1109/TCSVT.2017.2718188
   Zhang W, 2018, IEEE T MULTIMEDIA, V20, P880, DOI 10.1109/TMM.2017.2760102
   Zhang W, 2018, NEUROCOMPUTING, V275, P781, DOI 10.1016/j.neucom.2017.09.012
   Zhang YM, 2018, NEUROCOMPUTING, V273, P190, DOI 10.1016/j.neucom.2017.08.018
NR 41
TC 6
Z9 6
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 29161
EP 29181
DI 10.1007/s11042-018-6667-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700042
DA 2024-07-18
ER

PT J
AU Peng, F
   Long, Q
   Lin, ZX
   Long, M
AF Peng, Fei
   Long, Qin
   Lin, Zi-Xing
   Long, Min
TI A reversible watermarking for authenticating 2D CAD engineering graphics
   based on iterative embedding and virtual coordinates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; 2D CAD engineering graphics; Iterative
   embedding; Virtual coordinate
ID SCHEME
AB Aim to authenticate the integrity of 2D CAD engineering graphics, a reversible watermarking method based on iterative embedding and virtual coordinates is proposed. For each vertex in 2D CAD engineering graphics, two neighboring virtual coordinates are generated to form an embedding data unit, which is good for the improvement of the correlation of them. Meanwhile, iterative embedding policy is implemented to enhance the capacity. Experimental results and analysis show that it is strictly reversible, and the capacity is positive proportion to the embedding times. Meanwhile, the distortion can be well controlled in a small range, and it is robust against translation and scaling. It has potential application in the integrity protection of 2D CAD engineering graphics with low correlation and high data precision requirements.
C1 [Peng, Fei; Long, Qin; Lin, Zi-Xing] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   [Long, Min] Changsha Univ Sci & Technol, Coll Comp & Commun Engn, Changsha 410014, Hunan, Peoples R China.
C3 Hunan University; Changsha University of Science & Technology
RP Peng, F (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM eepengf@gmail.com
RI Long, Min/AGW-6059-2022; Peng, Fei/H-6951-2017
OI Peng, Fei/0000-0001-8053-4587
FU National Natural Science Foundation of China [61370225, 61572182]; Hunan
   Provincial Natural Science Foundation of China [15JJ2007]; Scientific
   Research Plan of Hunan Provincial Science and Technology Department of
   China [2014FJ4161]
FX This work was supported in part by project supported by National Natural
   Science Foundation of China (Grant No. No. 61370225, 61572182), project
   supported by Hunan Provincial Natural Science Foundation of China (Grant
   No. 15JJ2007), supported by the Scientific Research Plan of Hunan
   Provincial Science and Technology Department of China (2014FJ4161).
CR [Anonymous], J COMPUT AIDED DESIG
   Cao L, 2014, SIGNAL IMAGE VIDEO P, P1, DOI DOI 10.1007/S11760-013-0606-3
   Cao L, 2012, NONLINEAR SCRAMBLING
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chaoguang Men, 2010, 2010 IEEE International Conference on Mechatronics and Automation (ICMA), P276, DOI 10.1109/ICMA.2010.5589062
   [李黎 LI Li], 2010, [中国图象图形学报, Journal of Image and Graphics], V15, P372
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Peng F, 2014, COMPUT AIDED DESIGN, V49, P42, DOI 10.1016/j.cad.2013.12.006
   Peng F, 2011, INT J DIGIT CRIME FO, V3, P53, DOI 10.4018/jdcf.2011010104
   [彭飞 Peng Fei], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P1134
   Peng F, 2011, COMPUT AIDED DESIGN, V43, P1018, DOI 10.1016/j.cad.2011.03.011
   [邵承永 SHAO Chengyong], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P206
   Tian J., 2002, Proceedings of workshop on multimedia and security p, P19
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
   Wang NN, 2014, COMPUT AIDED DESIGN, V47, P108, DOI 10.1016/j.cad.2013.10.005
   Wang X, 2007, IEEE T INF FOREN SEC, V2, P311, DOI 10.1109/TIFS.2007.902677
   Wu D, 2009, 2009 WRI INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND MOBILE COMPUTING: CMC 2009, VOL 3, P385, DOI 10.1109/CMC.2009.86
   Xiaoyun Wu, 2007, 2007 Inaugural IEEE International Conference on Digital Ecosystems and Technologies, P501
   Xuan GR, 2006, LECT NOTES COMPUT SC, V4283, P323
   Yang B, 2004, PROC SPIE, V5306, P405, DOI 10.1117/12.527216
   Zhou Lu, 2009, Journal of Computer Applications, V29, P990, DOI 10.3724/SP.J.1087.2009.00990
NR 22
TC 27
Z9 28
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 26885
EP 26905
DI 10.1007/s11042-017-4362-1
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000004
DA 2024-07-18
ER

PT J
AU Qi, MP
   Chen, JH
AF Qi, Mingping
   Chen, Jianhua
TI Anonymous biometrics-based authentication with key agreement scheme for
   multi-server environment using ECC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Elliptic curve cryptography; Multi-server; Biometrics; Authentication;
   Three-factor; Smart-card
ID USER ANONYMITY; SMART CARDS; SECURE; PROTOCOL
AB The rapidly evolving communication technology has now made it easy for people to enjoy kinds of online services over the insecure public internet. However, with convenience, ensuring data security as well as user privacy and authentication is particularly important and urgent. In view of this, this work presents a new biometrics-based three-factor authentication with key agreement scheme for multi-server environment using ECC. The formal authentication proof using BAN logic confirms that the new scheme can achieve mutual authentication and agree on a common session key; and the heuristic cryptanalysis shows that the new scheme provides perfect forward secrecy, preserves user anonymity and secures against various known security vulnerabilities. Furthermore, the performance evaluation demonstrates that our scheme is efficient.
C1 [Qi, Mingping; Chen, Jianhua] Wuhan Univ, Sch Math & Stat, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Chen, JH (corresponding author), Wuhan Univ, Sch Math & Stat, Wuhan 430072, Hubei, Peoples R China.
EM mpqi_math@163.com; chenjh_ecc@163.com
CR [Anonymous], WIREL PERS COMMUN
   BURROWS M, 1990, ACM T COMPUT SYST, V8, P18, DOI [10.1145/77648.77649, 10.1145/74851.74852]
   Chandrakar P, 2017, COMPUT COMMUN, V110, P26, DOI 10.1016/j.comcom.2017.05.009
   Chaudhry SA, 2015, J SUPERCOMPUT, P1
   Chaudhry SA, 2017, PEER PEER NETW APPL, V10, P1, DOI 10.1007/s12083-015-0400-9
   Chuang MC, 2014, EXPERT SYST APPL, V41, P1411, DOI 10.1016/j.eswa.2013.08.040
   Dodis Y, 2008, SIAM J COMPUT, V38, P97, DOI 10.1137/060651380
   Farash MS, 2016, PEER PEER NETW APPL, V9, P82, DOI 10.1007/s12083-014-0315-x
   Farash MS, 2014, J SUPERCOMPUT, V69, P395, DOI 10.1007/s11227-014-1170-5
   Giri D, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0145-7
   He DB, 2015, IEEE SYST J, V9, P816, DOI 10.1109/JSYST.2014.2301517
   Irshad A, 2017, MULTIMED TOOLS APPL, V76, P16463, DOI 10.1007/s11042-016-3921-1
   Islam SKH, 2011, J SYST SOFTWARE, V84, P1892, DOI 10.1016/j.jss.2011.06.061
   Kilinc HH, 2014, IEEE COMMUN SURV TUT, V16, P1005, DOI 10.1109/SURV.2013.091513.00050
   Kim H, 2012, LECT NOTES COMPUT SC, V7335, P391, DOI 10.1007/978-3-642-31137-6_30
   Lu YR, 2015, SECUR COMMUN NETW, V8, P3219, DOI 10.1002/sec.1246
   Maitra T, 2016, SECUR COMMUN NETW, V9, P4166, DOI 10.1002/sec.1596
   Mishra D, 2014, EXPERT SYST APPL, V41, P8129, DOI 10.1016/j.eswa.2014.07.004
   Odelu V, 2015, IEEE T INF FOREN SEC, V10, P1953, DOI 10.1109/TIFS.2015.2439964
   Qi MP, 2018, INT J SATELL COMM N, V36, P296, DOI 10.1002/sat.1218
   Qi MP, 2017, INT J COMMUN SYST, V30, DOI 10.1002/dac.3341
   Shen H, 2015, J AMB INTEL HUM COMP, V6, P825, DOI 10.1007/s12652-015-0305-8
   Wang RC, 2011, COMPUT COMMUN, V34, P274, DOI 10.1016/j.comcom.2010.04.005
   Wu F, 2015, SECUR COMMUN NETW, V8, P3847, DOI 10.1002/sec.1305
   Yoon EJ, 2013, J SUPERCOMPUT, V63, P235, DOI 10.1007/s11227-010-0512-1
NR 25
TC 14
Z9 14
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 19
BP 27553
EP 27568
DI 10.1007/s11042-019-07812-w
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IW9FD
UT WOS:000485298000035
DA 2024-07-18
ER

PT J
AU Shin, H
   Park, JS
AF Shin, Heehoon
   Park, Joon-Sang
TI Reducing energy consumption of RNC based media streaming on smartphones
   via sampling
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Energy efficiency; Random network coding; Smartphone
AB There have been lots of research efforts on applying random network coding (RNC) technology in media streaming for increased reliability, throughput, etc. In an RNC based media streaming system, it is critical to optimize its RNC implementation; otherwise, the system cannot benefit from RNC due to its high computational cost. For example, an RNC decoder implemented in streaming applications on smartphones may exhibit excessive energy consumption draining batteries too quickly. In this paper, we deal with reducing the energy consumption of RNC based media streaming applications on smartphones especially in presence of other resource-competing applications. To reduce the energy consumption of RNC applications, we try to control the processor clock frequency via manipulating the frequency controllers in smartphone operating systems and the manipulation is accomplished through regulating the processor utilization for RNC applications. To estimate the processor utilization for RNC applications, we rely on a simple sampling approach, i.e., reading system files on a regular basis. Through experimental results, we show that our proposal reduces significantly the energy consumption of RNC applications on smartphones in presence of other intervening applications.
C1 [Shin, Heehoon; Park, Joon-Sang] Hongik Univ, Dept Comp Engn, Wausan Ro 94, Seoul 04066, South Korea.
C3 Hongik University
RP Park, JS (corresponding author), Hongik Univ, Dept Comp Engn, Wausan Ro 94, Seoul 04066, South Korea.
EM jsp@hongik.ac.kr
OI Park, Joon-Sang/0000-0002-6459-1060
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2016R1D1A1B03930393]
FX This work was supported by the Basic Science Research Program
CR Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   [Anonymous], P 2010 ACM MULT WORK
   Chen CC, 2011, J ADV RES, V2, P241, DOI 10.1016/j.jare.2011.05.002
   Choi SM, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/974836
   Ho T, 2006, IEEE T INFORM THEORY, V52, P4413, DOI 10.1109/TIT.2006.881746
   Keller L., 2012, P ACM MOBISYS LOW WO
   Kim M, 2013, J NETW COMPUT APPL, V36, P293, DOI 10.1016/j.jnca.2012.05.014
   Lee S, 2012, COMPUT J, V55, P21, DOI 10.1093/comjnl/bxq087
   MAYMOUNKOV P, 2006, P 44 ANN ALL C COMM
   Park JS, 2014, COMPUT J, V57, P233, DOI 10.1093/comjnl/bxs173
   Park K, 2010, IEEE T PARALL DISTR, V21, P1547, DOI 10.1109/TPDS.2010.40
   Shin H, 2017, MOBILE NETW APPL, V22, P880, DOI 10.1007/s11036-017-0856-3
   Shin H, 2017, MULTIMED TOOLS APPL, V76, P19379, DOI 10.1007/s11042-015-3089-0
   Shojania H., 2007, P 15 IEEE INT WORKSH
   Shojania H, 2009, P IEEE INFOCOM 09 CO
   Shojania H., 2009, P 18 INT WORKSH NETW
   Shojania H, 2009, INT CON DISTR COMP S, P490, DOI 10.1109/ICDCS.2009.68
   Song T, 2015, P 48 IEEE ACM INT S
   SOrensen S, 2016, P WIR COMM NETW C WC
   WANG M, 2007, P IEEE INFOCOM
   Wunderlich S, 2017, IEEE INTERNET THINGS, V4, P917, DOI 10.1109/JIOT.2017.2703813
NR 21
TC 5
Z9 5
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2019
VL 78
IS 20
BP 28461
EP 28475
DI 10.1007/s11042-017-5494-z
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX9HC
UT WOS:000485997700008
DA 2024-07-18
ER

PT J
AU Al-Bandawi, H
   Deng, G
AF Al-Bandawi, Hussein
   Deng, Guang
TI Classification of image distortion based on the generalized Benford's
   law
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Generalized Benford's law; Image distortion classification
ID QUALITY ASSESSMENT
AB Distortion classification is an important step in blind image quality assessment. In this paper, a new image distortion classification algorithm is presented. Classification is based on features extracted from the distribution of the first digit of transform coefficients of the image. The generalized Benford's law is used to model the distribution. The discrete cosine transform with three different patch sizes and the wavelet transform have been tested. Features, such as distribution data and model parameters, are extracted from an image. A kernel support vector machine is trained using these features. The LIVE database is used for both training and testing, while other four databases, namely, TID2008, CSIQ, Waterloo exploration database and McGill calibrated colour image database, are used for validation. Experimental results show that the performance of the proposed algorithm outperforms state-of-the-art algorithms in terms of classification accuracy.
C1 [Al-Bandawi, Hussein; Deng, Guang] La Trobe Univ, Dept Engn, Bundoora, Vic 3086, Australia.
C3 La Trobe University
RP Al-Bandawi, H (corresponding author), La Trobe Univ, Dept Engn, Bundoora, Vic 3086, Australia.
EM h.hussein@latrobe.edu.au; d.deng@latrobe.edu.au
FU Higher Committee for Eduction Development in Iraq
FX Hussein Al-Bandawi has been supported by the Higher Committee for
   Eduction Development in Iraq. The authors thank the reviewers for
   providing critical and constructive comments.
CR Alaql O, 2017, P INT C COMP SCI COM, P653
   [Anonymous], 2016, CoRR, DOI DOI 10.1109/QOMEX.2016.7498955
   Benford F., 1938, P AM PHILOS SOC, V78, P551, DOI DOI 10.2307/984802
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Cohen E, 2010, SIGNAL IMAGE VIDEO P, V4, P289, DOI 10.1007/s11760-009-0117-4
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fu DD, 2007, PROC SPIE, V6505, DOI 10.1117/12.704723
   Gu K, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2439035
   Kang L, 2015, IEEE IMAGE PROC, P2791, DOI 10.1109/ICIP.2015.7351311
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li LD, 2016, IEEE T CYBERNETICS, V46, P39, DOI 10.1109/TCYB.2015.2392129
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P856, DOI 10.1016/j.image.2014.06.006
   Liu LX, 2014, SIGNAL PROCESS-IMAGE, V29, P494, DOI 10.1016/j.image.2014.02.004
   Liu YM, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508391
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P1004, DOI 10.1109/TIP.2016.2631888
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Moorthy AK, 2010, INT CONF ACOUST SPEE, P962, DOI 10.1109/ICASSP.2010.5495298
   Moorthy AK, 2011, IEEE T IMAGE PROCESS, V20, P3350, DOI 10.1109/TIP.2011.2147325
   Moorthy AK, 2010, IEEE SIGNAL PROC LET, V17, P513, DOI 10.1109/LSP.2010.2043888
   Nafchi HZ, 2018, IEEE T BROADCAST, V64, P518, DOI 10.1109/TBC.2018.2818402
   Olmos A, 2004, PERCEPTION, V33, P1463, DOI 10.1068/p5321
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Qadir G., 2010, P SOC PHOTO-OPT INS, V7723, P1
   Saad MA, 2012, IEEE T IMAGE PROCESS, V21, P3339, DOI 10.1109/TIP.2012.2191563
   Sazzad ZMP, 2008, SIGNAL PROCESS-IMAGE, V23, P257, DOI 10.1016/j.image.2008.03.005
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Shen JB, 2018, IEEE T IMAGE PROCESS, V27, P2688, DOI 10.1109/TIP.2018.2795740
   Shen JB, 2017, IEEE T IMAGE PROCESS, V26, P4911, DOI 10.1109/TIP.2017.2722691
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Song X, 2018, NEURAL COMPATIBILITY
   Song XM, 2016, ACM T INFORM SYST, V34, DOI 10.1145/2832907
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2019, IEEE T PATTERN ANAL, V41, P1531, DOI 10.1109/TPAMI.2018.2840724
   Wang WG, 2015, IEEE T IMAGE PROCESS, V24, P3137, DOI 10.1109/TIP.2015.2438550
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Ye P, 2012, PROC CVPR IEEE, P1098, DOI 10.1109/CVPR.2012.6247789
NR 40
TC 7
Z9 7
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 25611
EP 25628
DI 10.1007/s11042-019-7668-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700017
DA 2024-07-18
ER

PT J
AU Guo, R
   Ma, SB
   Han, YH
AF Guo, Rui
   Ma, Shubo
   Han, Yahong
TI Image captioning: from structural tetrad to translated sentences
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image description; Structural words; Multi-task; LSTM; Machine
   translation
AB Generating semantic descriptions for images becomes more and more prevalent in recent years. Sentence which contains objects with their attributes and activity or scene involved is more informative and able to express more details of image semantic. In this paper, we focus on the generation of descriptions for images from the structural words we have generated, i.e., a semantically-layered structural tetrad of <object, attribute, activity, scene>. We propose to use deep machine translation method to generate semantically meaningful descriptions. In particular, the generated sentences describe objects with attributes, such as color, size, and corresponding activities or scenes involved. We propose to use a multi-task learning method to recognize structural words. Taking the words sequence as source language, we train a LSTM encoder-decoder machine translation model to output the target caption. In order to demonstrate the effectiveness of using multi-task learning method to generate structural words, we do experiments on benchmark datasets, i.e., aPascal and aYahoo. We also use UIUC Pascal, Flickr8k, Flickr30k, and MSCOCO datasets to justify that translating structural words to sentences achieves promising performance compared to the state-of-the-art methods of image captioning in terms of language generation metrics.
C1 [Guo, Rui] Southeast Univ, Sch Energy & Environm, Natl Engn Res Ctr Turbo Generator Vibrat, Nanjing 210096, Jiangsu, Peoples R China.
   [Ma, Shubo; Han, Yahong] Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
C3 Southeast University - China; Tianjin University
RP Han, YH (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin 300350, Peoples R China.
EM gr@seu.edu.cn; shuboma@tju.edu.cn; yahong@tju.edu.cn
FU NSFC [U1509206,61472276, 61876130]; Tianjin Natural Science Foundation
   [15JCYBJC15400]
FX This work is supported by the NSFC (under Grant U1509206,61472276,
   61876130) and Tianjin Natural Science Foundation (no. 15JCYBJC15400).
CR [Anonymous], P 25 INT JOINT C ART
   [Anonymous], P 5 ACM INT C MULT R
   [Anonymous], 2014, COMPUTER VISION ECCV
   [Anonymous], P 20 ACM INT C MULT
   [Anonymous], CVPR
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2015, ARXIV151103292
   [Anonymous], 2015, P CVPR
   [Anonymous], P 13 C EUR CHAPT ASS
   [Anonymous], 2005, WORKSH INTR EXTR EV
   [Anonymous], 2004, P ACL
   [Anonymous], P ACM INT C MULT ACM
   [Anonymous], 2011, P C EMP METH NAT LAN
   [Anonymous], 2014, P 31 INT C MACH LEAR
   [Anonymous], P IEEE
   [Anonymous], 2014, P SSST 8 8 WORKSHOP
   [Anonymous], 2018, CVPR
   [Anonymous], 2011 INT C COMP VIS
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], NIPS DEEP LEARN WORK
   [Anonymous], P 25 INT C COMP LING
   Baldridge Jason., 2005, The opennlp project
   Chen GR, 2017, INT J AUTOM COMPUT, V14, P1, DOI [10.1007/s11633-016-1052-9, 10.1080/15623599.2017.1354514]
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cheng G, 2018, IEEE T GEOSCI REMOTE, V56, P2811, DOI 10.1109/TGRS.2017.2783902
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Cui H, 2020, PATTERN RECOGN LETT, V130, P174, DOI 10.1016/j.patrec.2018.08.033
   Devlin J, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL) AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (IJCNLP), VOL 2, P100
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Guo JM, 2015, IEEE T CIRC SYST VID, V25, P466, DOI 10.1109/TCSVT.2014.2358011
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Hodosh M, 2013, J ARTIF INTELL RES, V47, P853, DOI 10.1613/jair.3994
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jing PG, 2019, IEEE T CIRC SYST VID, V29, P1296, DOI 10.1109/TCSVT.2018.2832095
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lee S, 2014, INT CONF UBIQ FUTUR, P140, DOI 10.1109/ICUFN.2014.6876768
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li JJ, 2016, NEUROCOMPUTING, V173, P501, DOI 10.1016/j.neucom.2015.06.041
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XB, 2019, IEEE T CIRC SYST VID, V29, P2431, DOI 10.1109/TCSVT.2018.2862891
   Liu XB, 2018, IEEE T CIRC SYST VID, V28, P2884, DOI 10.1109/TCSVT.2017.2781738
   Lu X, 2019, SIGNAL PROCESS, V154, P217, DOI 10.1016/j.sigpro.2018.09.007
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Mekhalfi ML, 2015, IEEE T CIRC SYST VID, V25, P1246, DOI 10.1109/TCSVT.2014.2372371
   Pan JS, 2015, IEEE T CIRC SYST VID, V25, P387, DOI 10.1109/TCSVT.2014.2351092
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Schuster S, 2015, P 4 WORKSH VIS LANG, P7080
   Socher R., 2014, Trans Assoc Comput Linguist, V2, P207, DOI [DOI 10.1162/TACLA00177, 10.1162/tacl_a_00177, DOI 10.1162/TACL_A_00177]
   Song XM, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P239, DOI 10.1145/3240508.3240563
   Sutskever I, 2014, ADV NEUR IN, V27
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang B, 2018, AAAI CONF ARTIF INTE, P7380
   Wang C., 2009, CVPR
   Wang HL, 2015, IEEE T CIRC SYST VID, V25, P1900, DOI 10.1109/TCSVT.2015.2477939
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yang Y, 2011, BRILL HUM CHINA LIBR, V4, P1
   Yang ZW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P146, DOI 10.1145/3123266.3123327
   Young P., 2014, T ASSOC COMPUT LING, V2, P67, DOI [DOI 10.1162/TACL_A_00166, 10.1162/tacl_a_00166]
   Zhang LN, 2014, IEEE T CIRC SYST VID, V24, P346, DOI 10.1109/TCSVT.2013.2276172
   Zhao SC, 2018, IEEE T CIRC SYST VID, V28, P1839, DOI 10.1109/TCSVT.2017.2682196
NR 70
TC 2
Z9 2
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24321
EP 24346
DI 10.1007/s11042-018-7118-7
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900029
DA 2024-07-18
ER

PT J
AU Huang, PC
   Li, YH
   Chang, CC
   Liu, YJ
AF Huang, Peng-Cheng
   Li, Yung-Hui
   Chang, Chin-Chen
   Liu, Yanjun
TI Efficient QR code authentication mechanism based on Sudoku
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE QR code; Authentication; Sudoku; Reed-Solomon code
AB QR code is an important means for delivering information which has been widely used in our daily life. As an ISO international standard, the QR code encoding and decoding process are disclosed publicly, thus it is easy to decode a QR code then forge a new QR code with the same QR code public message. It can lead to the problems of information forgery and ease the spreading of fake news. To overcome this weakness, we propose a simple and efficient QR code authentication mechanism to embed the authentication information in the padding region of QR code based on the characteristics of Sudoku and Reed-Solomon code. Different from the previous scheme, the proposed scheme embeds the authentication information without consuming the QR code error correction capacity and is able to achieve a higher embedding capacity. Experimental results show that the proposed scheme has high security, low power consumption and is robust to common QR code attacks.
C1 [Huang, Peng-Cheng] Xiamen Univ Technol, Dept Comp Sci & Technol, Xiamen, Fujian, Peoples R China.
   [Huang, Peng-Cheng; Chang, Chin-Chen; Liu, Yanjun] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
   [Li, Yung-Hui] Natl Cent Univ, Dept Comp Sci & Informat Engn, Taoyuan, Taiwan.
C3 Xiamen University of Technology; Feng Chia University; National Central
   University
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
EM alan3c@gmail.com
RI 刘, 严君/GZL-5764-2022; zhang, ling/JXW-6931-2024; Chang,
   Ching-Chun/JAN-6210-2023; liu, yan/HCI-5542-2022; liu, yan/HGV-1365-2022
FU NSFC [61672442, 61872436]; Fujian NSF [2016Y0079, 2016 J01327]; Quanzhou
   Science and Technology Plan Project [2017G030]
FX This study was funded by the NSFC (grant number 61672442 and grand
   number 61872436), the Fujian NSF (grant number 2016Y0079 and grand
   number 2016 J01327), the Quanzhou Science and Technology Plan Project
   (grant number 2017G030).
CR Black J., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P216, DOI 10.1007/3-540-48405-1_14
   Chen CS, 2017, MOBILE NETW APPL, V22, P383, DOI 10.1007/s11036-016-0772-y
   Chen YY, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0158-x
   Conde-Lagoa D, 2010, IEEE INT C CONS EL I, P257
   Cox R., 2012, QArt codes
   Fan Li, 2016, International Journal of Network Security, V18, P410
   Felgenhauer B, 2003, SUDOKU ENUMERATION P
   Inc. D-W, 2003, QR COD STAND
   ISO B, 2005, 180042006 ISO B IEC
   Jiaohua Qin, 2016, International Journal of Network Security, V18, P1102
   Jing PG, 2018, IEEE T KNOWL DATA EN, V30, P1519, DOI 10.1109/TKDE.2017.2785784
   KNUTH DE, 1985, J ALGORITHM, V6, P163, DOI 10.1016/0196-6774(85)90036-7
   Lerner Adam., 2015, P 13 ANN INT C MOBIL, P359, DOI DOI 10.1145/2742647.2742650
   Li Li, 2011, J HANGZHOU DIANZI U, V31, P46
   Liu M, 2019, IEEE T IMAGE PROCESS, V28, P1235, DOI 10.1109/TIP.2018.2875363
   Lu JF, 2017, MOB INF SYST, V2017, DOI 10.1155/2017/4356038
   Mazurczyk W, 2015, IEEE COMMUN SURV TUT, V17, P334, DOI 10.1109/COMST.2014.2350994
   Motahari A, 2015, IEEE T MULTIMEDIA, V17, P118, DOI 10.1109/TMM.2014.2366601
   Nazemzadeh P, 2017, IEEE-ASME T MECH, V22, P2588, DOI 10.1109/TMECH.2017.2762598
   POUNTAIN D, 1987, BYTE, V12, P317
   Qian JP, 2017, COMPUT ELECTRON AGR, V139, P56, DOI 10.1016/j.compag.2017.05.009
   REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018
   Sun M, 2007, NEW ZEAL J AGR RES, V50, P861, DOI 10.1080/00288230709510361
   Tkachenko I, 2016, SIGNAL PROCESS-IMAGE, V41, P46, DOI 10.1016/j.image.2015.11.007
   Tkachenko I, 2016, IEEE T INF FOREN SEC, V11, P571, DOI 10.1109/TIFS.2015.2506546
NR 25
TC 9
Z9 9
U1 3
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 18
BP 26023
EP 26045
DI 10.1007/s11042-019-07795-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IU6NT
UT WOS:000483703700035
DA 2024-07-18
ER

PT J
AU Khalid, T
   Khan, AN
   Ali, M
   Adeel, A
   Khan, AUR
   Shuja, J
AF Khalid, Tauqeer
   Khan, Abdul Nasir
   Ali, Mazhar
   Adeel, Adil
   Khan, Atta ur Rehman
   Shuja, Junaid
TI A fog-based security framework for intelligent traffic light control
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fog; Traffic light control system; Edge computing; IoT
ID PRIVACY
AB The world is facing many problems including that of traffic congestion. To highlight the issue of traffic congestion worldwide specially in urban areas and to make it more efficient, research community is working on Intelligent Transportation Systems (ITS). However, there is very limited work in security aspects of ITS which makes it less secure against increasing security threats. Most of the existing frameworks provide security services for ITS with many unrealistic assumptions. In this paper, we propose a Fog-based Security Framework for Intelligent Traffic Light Control System that provides security services with realistic assumptions. Moreover, the proposed framework is compared with a similar framework called secure intelligent traffic light control based on security, performance, and applicability in real world scenario. The results show that the proposed framework is more secure as compared to the existing secure intelligent traffic light control framework and realistic for real world scenario. The proposed framework possesses confidentiality, integrity, and authenticity features. The security features of the proposed framework are verified through the Automated Validation of Internet Security Protocols and Applications tool.
C1 [Khalid, Tauqeer; Khan, Abdul Nasir; Ali, Mazhar; Adeel, Adil; Shuja, Junaid] COMSATS Univ Islamabad, Abbottabad Campus, Abbottabad, Pakistan.
   [Khan, Atta ur Rehman] Sohar Univ, Fac Comp & Informat Technol, Sohar, Oman.
C3 COMSATS University Islamabad (CUI); Sohar University
RP Khalid, T (corresponding author), COMSATS Univ Islamabad, Abbottabad Campus, Abbottabad, Pakistan.
EM tauqeerkhalid@ciit.net.pk; anasir@ciit.net.pk; mazhar@ciit.net.pk;
   adiladeel@ciit.net.pk; dr@attaurrehman.com; junaidshuja@ciit.net.pk
RI Khan, Atta ur Rehman/M-7800-2019; Shuja, Junaid/A-3103-2013; Ali,
   Mazhar/AAH-8301-2019
OI Khan, Atta ur Rehman/0000-0003-2930-6508; Shuja,
   Junaid/0000-0003-0726-5311; Ali, Mazhar/0000-0003-2351-6520; Khan, Abdul
   Nasir/0000-0001-9742-1669
CR Abbas muhammad awais, 2011, NONLINEAR MODEL PRED, P1
   [Anonymous], 2009, 2009 12 INT IEEE C I
   Baldi S, 2019, TRANSPORT SCI, V53, P6, DOI 10.1287/trsc.2017.0754
   Basudan S, 2017, IEEE INTERNET THINGS, V4, P772, DOI 10.1109/JIOT.2017.2666783
   Chen WJ, 2005, INT CONF PARA PROC, P258
   Dastjerdi Amir Vahid, 2016, Internet of Things, P61, DOI [10.1016/B978 -0-12-805395-9.00004-6. arXiv: 1601.02752, DOI 10.1016/B978-0-12-805395-9.00004-6.ARXIV:1601.02752]
   Deniz F, 2016, AD HOC NETW, V44, P104, DOI 10.1016/j.adhoc.2016.02.018
   Díaz M, 2016, J NETW COMPUT APPL, V67, P99, DOI 10.1016/j.jnca.2016.01.010
   Eydi A., 2017, INT J TRANSPORTATION, V4, P147
   Gongjun Yan, 2009, 2009 IEEE 6th International Conference on Mobile Adhoc and Sensor Systems. MASS 2009, P804, DOI 10.1109/MOBHOC.2009.5336914
   Hancock P, 2018, AUTOMATION HUMAN PER, P203
   He W, 2014, IEEE T IND INFORM, V10, P1587, DOI 10.1109/TII.2014.2299233
   Hounsell N, 1998, INTELLIGENT SYSTEMS
   Jeong E, 2017, ACCIDENT ANAL PREV, V104, P115, DOI 10.1016/j.aap.2017.05.002
   Kumar P, 2005, IEEE T INTELL TRANSP, V6, P43, DOI 10.1109/TITS.2004.838219
   Kwatirayo S, 2013, INT WIREL COMMUN, P752, DOI 10.1109/IWCMC.2013.6583651
   Lai Y, 2007, LECT NOTES COMPUT SC, V4494, P37
   Lin J, 2017, IEEE T VEH TECHNOL, V66, P2551, DOI 10.1109/TVT.2016.2572123
   Liu J, 2018, FUTURE GENER COMP SY, V78, P817, DOI 10.1016/j.future.2017.02.017
   Liu JQ, 2017, IEEE COMMUN MAG, V55, P34, DOI 10.1109/MCOM.2017.1600371CM
   Mukherjee M, 2017, IEEE ACCESS, V5, P19293, DOI 10.1109/ACCESS.2017.2749422
   Nguyen-Minh H, 2016, CONTRIBUTION INTELLI
   Ni JB, 2017, IEEE T SMART GRID, V8, P2483, DOI 10.1109/TSG.2017.2673843
   Novikov A, 2017, TRANSP RES PROC, V20, P455, DOI 10.1016/j.trpro.2017.01.074
   ORACLE, JAV CRYPT ARCH JCA J
   Puthal D, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P246, DOI [10.1109/Trustcom-2015.381, 10.1109/Trustcom.2015.381]
   Puthal D, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NETWORKS (CINE), P116, DOI 10.1109/CINE.2015.31
   Rabieh K, 2017, IEEE T VEH TECHNOL, V66, P2703, DOI 10.1109/TVT.2016.2583466
   Solodkiy A, 2017, TRANSP RES PROC, V20, P630
   Song J, 2016, SECUR COMMUN NETW, V9, P2789, DOI 10.1002/sec.1211
   Useche S.A., 2017, EC NEUROL, V5, P71
   Viganò L, 2006, ELECTRON NOTES THEOR, V155, P61, DOI 10.1016/j.entcs.2005.11.052
   Wann-Ming Wey, 2000, Computers, Environment and Urban Systems, V24, P355, DOI 10.1016/S0198-9715(00)00002-8
   Yan L., 2018, NEURAL PROCESS LETT, V1, P1
   Zhang L, 2016, IEEE T COMPUT, V65, P2562, DOI 10.1109/TC.2015.2485225
   Zhang YF, 2017, J PHYS CONF SER, V910, DOI 10.1088/1742-6596/910/1/012070
NR 36
TC 21
Z9 21
U1 1
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24595
EP 24615
DI 10.1007/s11042-018-7008-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900043
DA 2024-07-18
ER

PT J
AU Qi, YD
   Zhang, HX
   Zhang, B
   Wang, L
   Zheng, SX
AF Qi, Yudan
   Zhang, Huaxiang
   Zhang, Bin
   Wang, Li
   Zheng, Shunxin
TI Cross-media retrieval based on linear discriminant analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross-media retrieval; Correlation analysis; Semantic information;
   Linear discriminant analysis
AB Existing cross-media retrieval approaches usually project low-level features from different modalities of data into a common subspace, in which the similarity of multi-modal data can be measured directly. However, most of the previous subspace learning methods ignore the discriminative property of multi-modal data which may lead to suboptimal cross-media retrieval performance. To address this problem, we propose a novel approach to cross-media retrieval framework based on Linear Discriminant Analysis (LDA), which integrates the correlation between textual features and visual features to learn a pair of projection matrices so that we can project the low-level heterogeneous features into a shared feature space by the transformation matrices. Thus the discriminative characteristic of textual modality is transferred to the corresponding visual features via the correlation analysis process. Experiments on three benchmark datasets show the effectiveness of our approach.
C1 [Qi, Yudan; Zhang, Huaxiang; Zhang, Bin; Wang, Li; Zheng, Shunxin] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.
   [Zhang, Huaxiang] Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
C3 Shandong Normal University; Shandong Normal University
RP Zhang, HX (corresponding author), Shandong Normal Univ, Sch Informat Sci & Engn, Jinan 250014, Shandong, Peoples R China.; Zhang, HX (corresponding author), Shandong Normal Univ, Inst Data Sci & Technol, Jinan 250014, Shandong, Peoples R China.
EM huaxzhang@163.com
RI Zhang, Bin/IWU-4448-2023
OI Zhang, Bin/0000-0001-9214-1588; zhang, hua xiang/0000-0001-6259-7533
FU National Natural Science Foundation of China [61572298, 61772322]; Key
   Research and Development Foundation of Shandong Province China
   [2017CXGC0703, 2017GGX10117, 2016GGX101009]
FX The work is partially supported by the National Natural Science
   Foundation of China (Nos. 61572298, 61772322) and the Key Research and
   Development Foundation of Shandong Province China (Nos. 2017CXGC0703,
   2017GGX10117, 2016GGX101009).
CR Andrew G., 2013, P ICML, P1247
   [Anonymous], 2003, P ACM INT C MULT ACM
   [Anonymous], 2016, P 25 INT JOINT C ART
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2010, LEARNING SIMILARITY
   [Anonymous], ENCY MEASUREMENT STA
   [Anonymous], 2005, P INT C MUS INF RETR
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Blaschko MB, 2008, PROC CVPR IEEE, P93, DOI 10.1109/CVPR.2008.4587353
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Gong YC, 2014, INT J COMPUT VISION, V106, P210, DOI 10.1007/s11263-013-0658-4
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hauptmann A, 2007, IEEE T MULTIMEDIA, V9, P958, DOI 10.1109/TMM.2007.900150
   Li J, 2018, IEEE T COMPUT SOC SY, V5, P324, DOI 10.1109/TCSS.2018.2797225
   Li JJ, 2017, IEEE T CYBERNETICS, V47, P3516, DOI 10.1109/TCYB.2016.2565898
   Li JJ, 2016, NEUROCOMPUTING, V173, P501, DOI 10.1016/j.neucom.2015.06.041
   Li ZH, 2017, IEEE T KNOWL DATA EN, V29, P2100, DOI 10.1109/TKDE.2017.2728531
   Lu X, 2018, SIGNAL PROCESS-IMAGE, V65, P221, DOI 10.1016/j.image.2018.04.009
   Luo MN, 2017, COMPUT VIS IMAGE UND, V163, P67, DOI 10.1016/j.cviu.2017.07.001
   Ma ZZ, 2020, IEEE T SYST MAN CY-S, V50, P2421, DOI 10.1109/TSMC.2018.2815716
   Nie L., 2016, Synthesis Lectures on Information Concepts Retrieval & Services, V8, P1, DOI 10.2200/S00714ED1V01Y201603ICR048
   Nie LQ, 2013, IEEE T MULTIMEDIA, V15, P426, DOI 10.1109/TMM.2012.2229971
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Nie XS, 2017, IEEE T MULTIMEDIA, V19, P785, DOI 10.1109/TMM.2016.2629758
   Park Y, 2015, INT SOC DESIGN CONF, P229, DOI 10.1109/ISOCC.2015.7401731
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Sharma A, 2012, PROC CVPR IEEE, P2160, DOI 10.1109/CVPR.2012.6247923
   Wang KY, 2016, IEEE T PATTERN ANAL, V38, P2010, DOI 10.1109/TPAMI.2015.2505311
   Wang W, 2016, VLDB J, V25, P79, DOI 10.1007/s00778-015-0391-4
   Wei Y, 2014, 2014 INTERNATIONAL CONFERENCE ON OPTICAL NETWORK DESIGN AND MODELING, P1
   Wei YC, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2775109
   Wu JL, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P917, DOI 10.1145/3077136.3080678
   Wu YL, 2017, IEEE INT CON MULTI, P823, DOI 10.1109/ICME.2017.8019528
   Xie L, 2016, MULTIMED TOOLS APPL, V75, P9185, DOI 10.1007/s11042-016-3432-0
   Xie L, 2016, SIGNAL PROCESS, V124, P81, DOI 10.1016/j.sigpro.2015.10.010
   Zhang L, 2018, IEEE T MULTIMEDIA, V20, P128, DOI 10.1109/TMM.2017.2723841
   Zhu L., 2016, IJCAI, P3959
   Zhu L, 2018, IEEE T NEUR NET LEAR, V29, P5264, DOI 10.1109/TNNLS.2018.2797248
   Zhu L, 2017, IEEE T CYBERNETICS, V47, P3941, DOI 10.1109/TCYB.2016.2591068
   Zhu L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P843, DOI 10.1145/2733373.2806345
   Zhu Li, 2017, IEEE T VEHICULAR TEC, V12, P1
NR 42
TC 5
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24249
EP 24268
DI 10.1007/s11042-018-6994-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900025
DA 2024-07-18
ER

PT J
AU Stavrinides, GL
   Karatza, HD
AF Stavrinides, Georgios L.
   Karatza, Helen D.
TI A hybrid approach to scheduling real-time IoT workflows in fog and cloud
   environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Internet of Things; Fog computing; Cloud computing; Real-time workflows;
   Scheduling
ID PERFORMANCE; SYSTEMS; IMPACT
AB In this paper, we propose a hybrid fog and cloud-aware heuristic for the dynamic scheduling of multiple real-time Internet of Things (IoT) workflows in a three-tiered architecture. In contrast to traditional approaches where the main processing of IoT jobs is performed in the fog layer, our approach attempts to schedule computationally demanding tasks with low communication requirements in the cloud and communication intensive tasks with low computational demands in the fog, utilizing possible gaps in the schedule of the fog and cloud virtual machines. Furthermore, during the scheduling process, our approach takes into account the communication cost incurred by the transfer of data from the sensors and devices in the IoT layer to the fog layer. The performance of the proposed heuristic is evaluated and compared via simulation to a baseline cloud-unaware strategy, under different cases of workload. The simulation results reveal that the proposed scheduling heuristic provides on average 76.69% lower deadline miss ratio, compared to the baseline policy. However, this is achieved at a significant monetary cost, due to the usage of cloud resources.
C1 [Stavrinides, Georgios L.; Karatza, Helen D.] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Stavrinides, GL (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
EM gstavrin@csd.auth.gr; karatza@csd.auth.gr
RI Stavrinides, Georgios L./AAS-9503-2021
OI Stavrinides, Georgios L./0000-0001-7289-9682; Karatza,
   Helen/0000-0002-9789-0585
CR [Anonymous], 2016, OPFWP0010216
   Arabnejad H, 2014, IEEE T PARALL DISTR, V25, P682, DOI 10.1109/TPDS.2013.57
   Bittencourt LF, 2017, IEEE CLOUD COMPUT, V4, P26, DOI 10.1109/MCC.2017.27
   Buttazzo GC, 2011, HARD REAL-TIME COMPUTING SYSTEMS: PREDICTABLE SCHEDULING ALGORITHMS AND APPLICATIONS, THIRD EDITION, P1, DOI 10.1007/978-1-14614-0676-1
   Chen Yinong., 2015, Service-Oriented Computing and Web Software Integration, V5th
   Chen Yinong., 2018, SERVICE ORIENTED COM, V6th
   Cisco, 2015, C1173443500 CISCO SY
   Dastjerdi AV, 2016, COMPUTER, V49, P112, DOI 10.1109/MC.2016.245
   Deng RL, 2016, IEEE INTERNET THINGS, V3, P1171, DOI 10.1109/JIOT.2016.2565516
   Hao ZJ, 2017, IEEE INTERNET COMPUT, V21, P44, DOI 10.1109/MIC.2017.26
   Jararweh Y, 2016, 2016 23RD INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS (ICT), DOI 10.1109/ICT.2016.7500486
   Jiang HJ, 2011, LECT NOTES COMPUT SC, V7916, P282, DOI 10.1007/978-3-642-24650-0_24
   Liu J, 2018, FUTURE GENER COMP SY, V78, P817, DOI 10.1016/j.future.2017.02.017
   Masip-Bruin X, 2016, IEEE WIREL COMMUN, V23, P120, DOI 10.1109/MWC.2016.7721750
   Nan YC, 2016, 15TH IEEE INTERNATIONAL SYMPOSIUM ON NETWORK COMPUTING AND APPLICATIONS (IEEE NCA 2016), P162, DOI 10.1109/NCA.2016.7778612
   Pham XQ, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147717742073
   Pham Xuan-Qui., 2016, Network Operations and Management Symposium (APNOMS), 2016 18th Asia-Pacific, P1, DOI 10.1109/APNOMS.2016.7737240
   Rahmani AM, 2018, FUTURE GENER COMP SY, V78, P641, DOI 10.1016/j.future.2017.02.014
   Shah-Mansouri H, 2018, IEEE INTERNET THINGS, V5, P3246, DOI 10.1109/JIOT.2018.2838022
   Stavrinides G. L., 2018, Modeling and Simulation in HPC and Cloud Systems, P19
   Stavrinides G. L., 2014, P 1 INT WORKSH SUST, P13
   Stavrinides GL, 2018, SIMUL MODEL PRACT TH, V89, P135, DOI 10.1016/j.simpat.2018.09.013
   Stavrinides GL, 2018, 2018 IEEE 6TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2018), P33, DOI 10.1109/FiCloud.2018.00013
   Stavrinides GL, 2017, ICPE'17: COMPANION OF THE 2017 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING, P49, DOI 10.1145/3053600.3053611
   Stavrinides GL, 2017, IEEE ACM DIS SIM, P180
   Stavrinides GL, 2017, 2017 IEEE 5TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD (FICLOUD 2017), P10, DOI 10.1109/FiCloud.2017.26
   Taneja Mohit, 2017, 2017 IFIP/IEEE Symposium on Integrated Network and Service Management (IM), P1222, DOI 10.23919/INM.2017.7987464
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   Gia TN, 2015, CIT/IUCC/DASC/PICOM 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY - UBIQUITOUS COMPUTING AND COMMUNICATIONS - DEPENDABLE, AUTONOMIC AND SECURE COMPUTING - PERVASIVE INTELLIGENCE AND COMPUTING, P356, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.51
   Wen Z, 2017, IEEE INTERNET COMPUT, V21, P16, DOI 10.1109/MIC.2017.36
NR 30
TC 77
Z9 79
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2019
VL 78
IS 17
BP 24639
EP 24655
DI 10.1007/s11042-018-7051-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IS8SN
UT WOS:000482419900045
DA 2024-07-18
ER

PT J
AU Chen, JG
   Li, XX
   Wang, MM
   Ma, LL
   Xu, BG
AF Chen, Jinguang
   Li, Xiaoxing
   Wang, Mingming
   Ma, Lili
   Xu, Bugao
TI Fast compressive tracking combined with Kalman filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compressive tracking; Kalman filter; Secondary localization; Object
   tracking
ID VISUAL TRACKING; OBJECT TRACKING
AB Compressive tracking refers to a group of high-speed algorithms for real-time object tracking. Many tracking algorithms may not generate accurate tracking results because they used fixed learning rates, and sometime lose targets when objects are occluded or deformed. To address these problems, a fast tracking algorithm combined with Kalman filter was proposed in this research. Firstly, an object location was initialized by the predicted value of Kalman filter when it was occluded, and the Kalman update was implemented only when the object was detected. The object location obtained in the Kalman update stage was used later as the initial position in the next frame. Secondly, when the distribution of positive samples satisfied a threshold, an adaptive learning rate was then updated. Finally, the naive Bayes classifier was updated with samples which had more different features. In the experiment, the proposed algorithm was compared with other state-of-the-art algorithms on seven publicly tested sequences, demonstrating that it had higher tracking accuracy and robustness in conditions such as occlusion, deformation and rotation.
C1 [Chen, Jinguang; Li, Xiaoxing; Wang, Mingming; Ma, Lili; Xu, Bugao] Xian Polytech Univ, Sch Comp Sci, Xian 710048, Shaanxi, Peoples R China.
   [Xu, Bugao] Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA.
C3 Xi'an Polytechnic University; University of North Texas System;
   University of North Texas Denton
RP Xu, BG (corresponding author), Xian Polytech Univ, Sch Comp Sci, Xian 710048, Shaanxi, Peoples R China.; Xu, BG (corresponding author), Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76203 USA.
EM xacjg@163.com; Bugao.xu@unt.edu
FU National Natural Science Foundation of China [61601358]; Natural Science
   Basic Research Plan in Shaanxi Province of China [2016JM6030]; Shaanxi
   Provincial Education Department [18JK0349]
FX This work was supported by National Natural Science Foundation of China
   (61601358), the Natural Science Basic Research Plan in Shaanxi Province
   of China (2016JM6030), the Scientific Research Program funded by Shaanxi
   Provincial Education Department (18JK0349).
CR [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Han D, 2019, IEEE T CIRCUITS-I, V66, P1794, DOI 10.1109/TCSI.2018.2880363
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kim HI, 2018, IEEE SIGNAL PROC LET, V25, P1029, DOI 10.1109/LSP.2018.2835768
   Liu Q., 2016, IEEE T CYBERNETICS, P1
   Liu QB, 2018, IEEE ACCESS, V6, P43302, DOI 10.1109/ACCESS.2018.2861827
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nai K, 2018, IEEE T IMAGE PROCESS, V27, P4958, DOI 10.1109/TIP.2018.2848465
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Shengluan Huang, 2011, 2011 International Conference on Consumer Electronics, Communications and Networks (CECNet), P1423, DOI 10.1109/CECNET.2011.5769081
   Simon D, 2006, OPTIMAL STATE ESTIMA, P218
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Wang Jiang-tao, 2007, Journal of System Simulation, V19, P4216
   Wang T, 2018, IEEE T PATTERN ANAL, V40, P1494, DOI 10.1109/TPAMI.2017.2716350
   Wu TF, 2017, IEEE T PATTERN ANAL, V39, P2465, DOI 10.1109/TPAMI.2016.2644963
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yan Jun-hua, 2014, Journal of Chinese Inertial Technology, V22, P536, DOI 10.13695/j.cnki.12-1222/o3.2014.04.021
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhao SC, 2018, IEEE T CYBERNETICS, V48, P2086, DOI 10.1109/TCYB.2017.2727138
   Zhou XL, 2018, IEEE ACCESS, V6, P43262, DOI 10.1109/ACCESS.2018.2861824
   Zhu H, 2017, IEEE T IMAGE PROCESS, V26, P821, DOI 10.1109/TIP.2016.2633874
NR 36
TC 4
Z9 5
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22463
EP 22477
DI 10.1007/s11042-019-7514-7
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400013
DA 2024-07-18
ER

PT J
AU Singh, BK
   Jain, P
   Banchhor, SK
   Verma, K
AF Singh, Bikesh K.
   Jain, Pankaj
   Banchhor, Sumit K.
   Verma, Kesari
TI Performance evaluation of breast lesion detection systems with expert
   delineations: a comparative investigation on mammographic images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mammogram; Lesion detection; Breast cancer; Performance evaluation;
   Manual delineations
ID COMPUTER-AIDED DETECTION; INTEROBSERVER VARIABILITY; CANCER;
   SEGMENTATION; TUMOR; CLASSIFICATION; IDENTIFICATION; GENERATION;
   DIAGNOSIS; MRI
AB Performance of computerized diagnostic systems yearning to be approved by medical regulatory bodies must meet the expectations of human experts. Highly accurate lesion segmentation techniques have thus turned out to be an essential part for clinical acceptability of mammography based computer-aided diagnosis systems. The objective of this study is to evaluate the performance of six popular breast tumor detection techniques with manual delineations provided by two experienced radiologists on the mammographic images. In our study, 20 mammographic images from the mini-MIAS database are utilized. For the analysis, input mammographic images are first manually cropped to generate the region of interest (ROI). The ROI images are then pre-processed and segmentation is performed using different techniques, namely: expected maximization, K-means, Fuzzy c-Means (FCM), multilevel thresholding, region growing, and particle swarm optimization. The results were compared against the manual tracings. Among the other five segmentation techniques, FCM achieves the highest Jaccard Index (0.73 +/- 0.06) and Dice Similarity Coefficient (0.82 +/- 0.08) values. Statistical analysis (t-test, Mann Whitney U test, Wilcoxon test, Chi-Square test, and Kolmogorov-Smirnov test) and graphical analysis (Bland Altman and Regression plots) further prove the stability and reliability of the segmentation methods. Segmentation using FCM demonstrates the most accurate results and can be employed for the detection of breast cancer in the mammographic images. Further, it is concluded that computer-aided lesion detection systems can be used to assist Radiologists in routine clinical practice for the detection of breast tumors in mammographic images.
C1 [Singh, Bikesh K.; Jain, Pankaj; Banchhor, Sumit K.] Natl Inst Technol Raipur, Dept Biomed Engn, Raipur 492001, CG, India.
   [Verma, Kesari] Natl Inst Technol Raipur, Dept Comp Applicat, Raipur, CG, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Raipur; National Institute of Technology (NIT System);
   National Institute of Technology Raipur
RP Singh, BK (corresponding author), Natl Inst Technol Raipur, Dept Biomed Engn, Raipur 492001, CG, India.
EM bsingh.bme@nitrr.ac.in
RI Jain, Pankaj/AGU-1054-2022; Verma, Kesari/AAT-3000-2020; Banchhor, Sumit
   Kumar/ABB-1940-2020; Singh, Bikesh Kumar/AAT-2203-2020
OI Jain, Pankaj/0000-0001-7957-5138; Verma, Kesari/0000-0002-5755-3111;
   Banchhor, Sumit Kumar/0000-0003-0406-7184; Singh, Bikesh
   Kumar/0000-0002-5052-9768; Jain, Pankaj/0000-0002-6206-497X
FU Chhatisgarh Council of Science AMP; Technology, Raipur, India
   [2481/CCOST/MRP/2016]
FX This work was supported by the Chhatisgarh Council of Science &
   Technology, Raipur, India (grant number 2481/CCOST/MRP/2016). The
   authors of this article are extremely grateful to them.
CR Al-Faris AQ, 2014, J DIGIT IMAGING, V27, P133, DOI 10.1007/s10278-013-9640-5
   Arodz T, 2006, COMPUT METH PROG BIO, V81, P56, DOI 10.1016/j.cmpb.2005.10.002
   Banchhor SK, 2017, J CLIN DIAGN RES, V11, pTC09, DOI 10.7860/JCDR/2017/26336.10030
   Chen Y, 2010, CONSUM COMM NETWORK, P1
   Choi JY, 2016, EXPERT SYST APPL, V46, P106, DOI 10.1016/j.eswa.2015.10.014
   Ciecholewski M, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9110277
   Costa DD, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-55
   Dheeba J, 2014, J BIOMED INFORM, V49, P45, DOI 10.1016/j.jbi.2014.01.010
   du Prel JB, 2010, DTSCH ARZTEBL INT, V107, P343, DOI 10.3238/arztebl.2010.0343
   Duijm LEM, 2009, BRIT J CANCER, V100, P901, DOI 10.1038/sj.bjc.6604954
   ELMORE JG, 1994, NEW ENGL J MED, V331, P1493, DOI 10.1056/NEJM199412013312206
   Elmoufidi A, 2015, IEEE IMTC P, P533, DOI 10.1109/I2MTC.2015.7151324
   Fan HP, 2005, PATTERN RECOGN LETT, V26, P1139, DOI 10.1016/j.patrec.2004.10.010
   GokilaDeepa G, 2012, INT J ENG INNOVATIVE, V2
   Gopi Raju N., 2013, INT J ENG RES APPL, V3, P1572
   Guliato D, 2003, J ELECTRON IMAGING, V12, P369, DOI 10.1117/1.1579017
   Gumaei A., 2012, 2012 Symposium on Broadband Networks and Fast Internet (RELABIRA), P97, DOI 10.1109/RELABIRA.2012.6235102
   Harrabi R, 2012, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2012-11
   He WD, 2015, COMPUT BIOL MED, V67, P61, DOI 10.1016/j.compbiomed.2015.10.002
   Jalalian A, 2017, EXCLI J, V16, P113, DOI [10.17179/excli201-701, 10.17179/excli2016-701]
   Jen CC, 2015, EXPERT SYST APPL, V42, P3048, DOI 10.1016/j.eswa.2014.11.061
   Karmilasari, 2014, INT J ADV COMPUT SC, V5, P86
   Keller B, 2011, LECT NOTES COMPUT SC, V6893, P562, DOI 10.1007/978-3-642-23626-6_69
   Keller BM, 2013, ACAD RADIOL, V20, P560, DOI 10.1016/j.acra.2013.01.003
   Li YP, 2015, J DIGIT IMAGING, V28, P626, DOI 10.1007/s10278-015-9814-4
   Malvia S, 2017, ASIA-PAC J CLIN ONCO, V13, P289, DOI 10.1111/ajco.12661
   Melouah A, 2015, IFIP ADV INF COMM TE, V456, P119, DOI 10.1007/978-3-319-19578-0_10
   Neto OPS, 2015, INT CONF SYST SIGNAL, P109, DOI 10.1109/IWSSIP.2015.7314189
   Ng K.H., 2003, J HK COLL RADIOL, V6, P126
   Nurhasanah, 2016, AIP CONF PROC, V1719, DOI 10.1063/1.4943731
   Oliver A, 2010, MED IMAGE ANAL, V14, P87, DOI 10.1016/j.media.2009.12.005
   Pompe E, 2016, EUR RADIOL, V26, P3046, DOI 10.1007/s00330-015-4145-x
   Raja NSM, 2015, PROCEDIA COMPUT SCI, V48, P524, DOI 10.1016/j.procs.2015.04.130
   Ramani R., 2013, INT J COMPUT APPL, V62
   Redondo A, 2012, BRIT J RADIOL, V85, P1465, DOI 10.1259/bjr/21256379
   Rejani Y, 2009, PREPRINT
   Saba L, 2018, INDIAN HEART J, V70, P649, DOI 10.1016/j.ihj.2018.01.024
   Saba L, 2018, J CLIN DIAGN RES, V12, pKC01, DOI 10.7860/JCDR/2018/34311.11217
   Saba L, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0504-7
   Sadad T, 2018, J COMPUT SCI-NETH, V29, P34, DOI 10.1016/j.jocs.2018.09.015
   Saha A, 2016, MED PHYS, V43, P4558, DOI 10.1118/1.4955435
   Sathish A, 2004, INT J COMPUTATIONAL, P6
   Satyendra SA, 2017, INT J ADV RES IDEAS, V3, P437
   Senthilkumar B., 2010, 2010 IEEE INT C COMP, V3, P1
   Sheshadri H S, 2005, J Cancer Res Ther, V1, P232
   Siegel R, 2013, CA-CANCER J CLIN, V63, P11, DOI 10.3322/caac.21166
   Spandana P, 2013, 2013 IEEE POINT-OF-CARE HEALTHCARE TECHNOLOGIES (PHT), P105, DOI 10.1109/PHT.2013.6461295
   SUCKLING J, 1994, INT CONGR SER, V1069, P375
   Sujata RB, 2012, INT J ADV COMPUTER R, V2, P2277
   Thyagarajan R, 2012, ANNU IEEE IND CONF, P1090
   Valarmathie P, 2016, BIOMED RES-INDIA, V27, pS310
   Vedanarayanan V, 2017, BIOMED RES-INDIA, V28, P2753
   Vesal S., 2018, BILDVERARBEITUNG MED INFORM AKTUELL, P257, DOI [10.1007/978-3-662-56537-7_68 10.1007/978-3-662-56537-7_68, DOI 10.1007/978-3-662-56537-7_68]
   Wang J, 2014, MED PHYS, V41, DOI 10.1118/1.4870959
   Wang Y, 2014, NEUROCOMPUTING, V144, P107, DOI 10.1016/j.neucom.2013.11.050
   Yuvaraj K, 2013, 3 INT C EL BIOM ENG, P29
   Zheng YJ, 2015, MED PHYS, V42, P4149, DOI 10.1118/1.4921996
NR 57
TC 8
Z9 8
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2019
VL 78
IS 16
BP 22421
EP 22444
DI 10.1007/s11042-019-7570-z
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IO0FS
UT WOS:000479055400011
DA 2024-07-18
ER

PT J
AU Abdulhussain, SH
   Ramli, A
   Mahmmod, BM
   Saripan, MI
   Al-Haddad, SAR
   Jassim, WA
AF Abdulhussain, Sadiq H.
   Ramli, Abd Rahman
   Mahmmod, Basheera M.
   Saripan, M. Iqbal
   Al-Haddad, S. A. R.
   Jassim, Wissam A.
TI Shot boundary detection based on orthogonal polynomial
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Shot boundary detection; Temporal video segmentation; Hard transition;
   Abrupt transition; Orthogonal polynomial; Orthogonal moments
ID CUT DETECTION; OPTIMIZATION
AB Shot boundary detection (SBD) is a substantial step in video content analysis, indexing, retrieval, and summarization. SBD is the process of automatically partitioning video into its basic units, known as shots, through detecting transitions between shots. The design of SBD algorithms developed from simple feature comparison to rigorous probabilistic and using of complex models. Nevertheless, accelerate the detection of transitions with higher accuracy need to be improved. Extensive research has employed orthogonal polynomial (OP) and their moments in computer vision and signal processing owing to their powerful performance in analyzing signals. A new SBD algorithm based on OP has been proposed in this paper. The Features are derived from orthogonal transform domain (moments) to detect the hard transitions in video sequences. Moments are used because of their ability to represent signal (video frame) without information redundancy. These features are the moments of smoothed and gradients of video frames. The moments are computed using a developed OP which is squared Krawtchouk-Tchebichef polynomial. These moments (smoothed and gradients) are fused to form a feature vector. Finally, the support vector machine is utilized to detect hard transitions. In addition, a comparison between the proposed algorithm and other state-of-the-art algorithms is performed to reinforce the capability of the proposed work. The proposed algorithm is examined using three well-known datasets which are TRECVID2005, TRECVID2006, and TRECVID2007. The outcomes of the comparative analysis show the superior performance of the proposed algorithm against other existing algorithms.
C1 [Abdulhussain, Sadiq H.; Mahmmod, Basheera M.] Univ Baghdad, Dept Comp Engn, Baghdad, Iraq.
   [Ramli, Abd Rahman; Saripan, M. Iqbal; Al-Haddad, S. A. R.] Univ Putra Malaysia, Dept Comp & Commun Syst Engn, Serdang, Malaysia.
   [Jassim, Wissam A.] Univ Dublin, Trinity Coll Dublin, Sch Engn, ADAPT Ctr, Dublin 2, Ireland.
C3 University of Baghdad; Universiti Putra Malaysia; Trinity College Dublin
RP Abdulhussain, SH (corresponding author), Univ Baghdad, Dept Comp Engn, Baghdad, Iraq.
EM sadiqh76@yahoo.com; arr@upm.edu.my; basheera412@yahoo.com;
   iqbal@upm.edu.my; sar@upm.edu; wissam.jassim@tcd.ie
RI Al-Haddad, S. A. R./AAM-6449-2020; Mahmmod, Basheera M./M-2973-2019;
   Abdulhussain, Sadiq H./ISU-8825-2023; Abdulhussain, Sadiq
   H./A-1740-2018; Saripan, M Iqbal/A-9582-2010
OI Abdulhussain, Sadiq H./0000-0002-6439-0082; Abdulhussain, Sadiq
   H./0000-0002-6439-0082; Jassim, Wissam/0000-0001-5998-142X; Saripan, M
   Iqbal/0000-0002-3005-5331; MAHMMOD, BASHEERA M./0000-0002-4121-0843
CR Abdulhussain SH, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20040214
   Abdulhussain SH, 2018, J MATH IMAGING VIS, V60, P285, DOI 10.1007/s10851-017-0758-9
   Abdulhussain SH, 2017, INT J IMAGE DATA FUS, V8, P293, DOI 10.1080/19479832.2017.1326405
   Abdulhussan SH, 2017, IEEE ACCESS, V5, P2470, DOI 10.1109/ACCESS.2017.2669218
   [Anonymous], SAMOVA SHOT BOUNDARY
   [Anonymous], 2016, COMPUT INTELL NEUROS
   [Anonymous], TRECVID 2005 AN OVER
   [Anonymous], 1995, P ACM MULT, DOI DOI 10.1145/217279.215266
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   [Anonymous], IEEE T CIRC SYST
   Birinci M, 2014, SIGNAL PROCESS-IMAGE, V29, P410, DOI 10.1016/j.image.2013.12.003
   Camara-Chavez G., 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P197, DOI 10.1109/IWSSIP.2007.4381187
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaves GC, 2007, THESIS
   Chen X, 2019, MULTIMED TOOLS APPL, V78, P11173, DOI 10.1007/s11042-018-6690-1
   Cooper M, 2003, PROCEEDINGS OF THE T
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Hu WM, 2011, IEEE T SYST MAN CY C, V41, P797, DOI 10.1109/TSMCC.2011.2109710
   Janwe NJ, 2013, 2013 IEEE SECOND INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P476, DOI 10.1109/ICIIP.2013.6707637
   Kar T, 2017, SIGNAL IMAGE VIDEO P, V11, P1237, DOI 10.1007/s11760-017-1080-0
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   Krulikovská L, 2010, ELMAR PROC, P89
   Küçüktunç O, 2010, COMPUT VIS IMAGE UND, V114, P125, DOI 10.1016/j.cviu.2009.09.008
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Liu CL, 2013, IEEE T MULTIMEDIA, V15, P884, DOI 10.1109/TMM.2013.2238522
   Liu LX, 2016, SIGNAL PROCESS-IMAGE, V40, P1, DOI 10.1016/j.image.2015.10.005
   Mahmmod BM, 2018, IET SIGNAL PROCESS, V12, P129, DOI 10.1049/iet-spr.2016.0449
   Mahmmod BM, 2017, IEEE ACCESS, V5, P9866, DOI 10.1109/ACCESS.2017.2699782
   Mondal J, 2018, MULTIMED TOOLS APPL, V77, P8139, DOI 10.1007/s11042-017-4707-9
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Over P, 2006, TRECVID 2006 OVERVIE, P1
   Pacheco F, 2017, EXPERT SYST APPL, V71, P69, DOI 10.1016/j.eswa.2016.11.024
   Parmar M, 2015, COMPUT J, V58, P2135, DOI 10.1093/comjnl/bxv042
   Porter SV, 2000, INT C PATT RECOG, P409, DOI 10.1109/ICPR.2000.903571
   Priya GGL, 2014, IEEE T IMAGE PROCESS, V23, P5187, DOI 10.1109/TIP.2014.2362652
   Priya GGL, 2012, PROC TECH, V1, P247, DOI 10.1016/j.protcy.2012.10.030
   Qing-Ge Ji, 2010, Proceedings 2010 First International Conference on Pervasive Computing, Signal Processing and Applications (PCSPA 2010), P273, DOI 10.1109/PCSPA.2010.73
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Solomon C., 2011, Fundamentals of Digital Image Processing: A Practical Approach with Examples in MATLAB, V1st ed.
   SRRR AS., 2016, IJCTA, V9, P3231
   Swanberg D., 1993, Proceedings of the SPIE - The International Society for Optical Engineering, V1908, P13, DOI 10.1117/12.143647
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Tong WJ, 2015, IEEE INT SYM BROADB
   Urhan O, 2006, IEEE T CIRC SYST VID, V16, P753, DOI 10.1109/TCSVT.2006.875210
   Vlachos T, 2000, IEEE SIGNAL PROC LET, V7, P173, DOI 10.1109/97.847360
   Xu J, 2015, IEEE T NEUR NET LEAR, V26, P628, DOI 10.1109/TNNLS.2014.2361026
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yoo HW, 2006, MULTIMED TOOLS APPL, V28, P283, DOI 10.1007/s11042-006-7715-8
   Youssef B, 2017, COMPUT VIS IMAGE UND, V161, P20, DOI 10.1016/j.cviu.2017.06.003
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
NR 55
TC 35
Z9 35
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 20361
EP 20382
DI 10.1007/s11042-019-7364-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800064
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Nasrullah, N
   Sang, J
   Mateen, M
   Akbar, MA
   Xiang, H
   Xia, XF
AF Nasrullah, Nasrullah
   Sang, Jun
   Mateen, Muhammad
   Akbar, Muhammad Azeem
   Xiang, Hong
   Xia, Xiaofeng
TI Reversible data hiding in compressed and encrypted images by using
   Kd-tree
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Compression; Encryption; Integer wavelet transform (IWT); Kd-tree;
   Reversible data hiding (RDH); Set partition in hierarchical tree (SPIHT)
ID WATERMARKING TECHNIQUE; HISTOGRAM-MODIFICATION; ROBUST; DOMAIN
AB In this paper, a joint scheme and a separable scheme for reversible data hiding (RDH) in compressed and encrypted images by reserving room through Kd-tree were proposed. Firstly, the plain cover image was losslessly compressed and encrypted with lifting based integer wavelet transform (IWT) and set partition in hierarchical tree (SPIHT) encoding. Then, several shift operations were performed on the generated SPIHT bit-stream. The shifted bit-stream was restructured into small chunks and packed in the form of a large square matrix. The binary square matrix was exposed to Kd-tree with random permutations and reserving uniform areas of ones and zeros for secret data hiding. After that, a joint or a separable RDH scheme can be performed in these reserved spaces. In the joint RDH scheme, the secret data were embedded in the reserved spaces before encrypting with multiple chaotic maps. Thus, secret data extraction and cover image recovery were achieved together. In the separable RDH scheme, the secret data were embedded in the reserved spaces after encrypting with multiple chaotic maps. Since message extraction and cover image recovery are performed separately, anyone who has the embedding key can extract the secret message from the marked encrypted copy, while cannot recover the cover image. A complete encoding and decoding procedure of RDH for compressed and encrypted images was elaborated. The imperceptibility analysis showed that the proposed methods bring no distortion to the cover image because there was no change to the original cover image. The experimental results showed that the proposed schemes can perform better for secret data extraction and can restore the original image with 100% reversibility with much more embedding capacity and security. The proposed schemes significantly outperform the state-of-the-art RDH methods in the literature on compressed and encrypted images.
C1 [Nasrullah, Nasrullah; Sang, Jun; Mateen, Muhammad; Akbar, Muhammad Azeem; Xiang, Hong; Xia, Xiaofeng] Chongqing Univ, Key Lab Dependable Serv Comp, Cyber Phys Soc, Minist Educ, Chongqing 400044, Peoples R China.
   [Nasrullah, Nasrullah; Sang, Jun; Mateen, Muhammad; Akbar, Muhammad Azeem; Xiang, Hong; Xia, Xiaofeng] Chongqing Univ, Sch Big Data & Software Engn, Chongqing 401331, Peoples R China.
C3 Chongqing University; Chongqing University
RP Sang, J (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp, Cyber Phys Soc, Minist Educ, Chongqing 400044, Peoples R China.; Sang, J (corresponding author), Chongqing Univ, Sch Big Data & Software Engn, Chongqing 401331, Peoples R China.
EM jsang@cqu.edu.cn
RI Mateen, Muhammad/S-7278-2019; Akbar, Muhammad Azeem/ABD-5149-2021;
   Xiang, Hongbing/AAP-1588-2020; Akbar, Muhammad Azeem/AAB-2338-2022;
   nasrullah, nasrullah/ABI-7910-2020
OI Akbar, Muhammad Azeem/0000-0002-6880-4991; nasrullah,
   nasrullah/0000-0002-9154-1456; Sang, Jun/0000-0002-8703-7310
FU National Key R&D Program of China [2017YFB0802400]
FX This research was supported by National Key R&D Program of China (No.
   2017YFB0802400).
CR AMIRTHARAJAN R, 2013, RES J INFORM TECHNOL, V5, P341
   [Anonymous], 2017, Micro Electro Mech. Syst, DOI DOI 10.1007/978-981-10-2798-7_34-1
   Arivazhagan S, 2014, 2014 INTERNATIONAL CONFERENCE ON COMMUNICATION AND NETWORK TECHNOLOGIES (ICCNT), P100, DOI 10.1109/CNT.2014.7062733
   Chang CC, 2008, PATTERN RECOGN, V41, P2347, DOI 10.1016/j.patcog.2007.12.009
   Chang CC, 2007, INFORM SCIENCES, V177, P2768, DOI 10.1016/j.ins.2007.02.019
   Chang CC, 2009, PATTERN RECOGN, V42, P1597, DOI 10.1016/j.patcog.2008.11.040
   Chang JC, 2017, SIGNAL PROCESS, V133, P135, DOI 10.1016/j.sigpro.2016.11.003
   Kamstra L, 2005, IEEE T IMAGE PROCESS, V14, P2082, DOI 10.1109/TIP.2005.859373
   Kavin BE, 2014, INF COMM EMB SYST IC, P1
   Khanam FTZ, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9040050
   Lee JD, 2010, IEEE T INF FOREN SEC, V5, P638, DOI 10.1109/TIFS.2010.2066971
   Li Q., 2018, MATH PROBL ENG, P1
   Li Z, 2016, LECT NOTES COMPUT SC, V9722, P198, DOI 10.1007/978-3-319-40253-6_12
   Lin CC, 2015, MULTIMED TOOLS APPL, V74, P3823, DOI 10.1007/s11042-013-1801-5
   Loan NA, 2018, IEEE ACCESS, V6, P19876, DOI 10.1109/ACCESS.2018.2808172
   Ma KD, 2013, IEEE T INF FOREN SEC, V8, P553, DOI 10.1109/TIFS.2013.2248725
   McCartney M, 2011, CHAOS, V21, DOI 10.1063/1.3645185
   Mohan AK, 2014, INT J SIMULATION SYS, V15
   Nasrullah, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8101963
   Parah S. A., 2018, NONLINEAR DYNAM, P1
   Parah SA, 2018, MULTIDIM SYST SIGN P, V29, P1095, DOI 10.1007/s11045-017-0490-z
   Parah SA, 2017, J GLOB INF MANAG, V25, P80, DOI 10.4018/JGIM.2017100106
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Qian Z., 2016, IEEE T DEPENDABLE SE
   Shi YQ, 2016, IEEE ACCESS, V4, P3210, DOI 10.1109/ACCESS.2016.2573308
   Tai WL, 2009, IEEE T CIRC SYST VID, V19, P904, DOI 10.1109/TCSVT.2009.2017409
   Tang Z., 2018, MULTIMED TOOLS APPL, P1
   Thanikaiselvan V, 2017, STUD COMPUT INTELL, V660, P65, DOI 10.1007/978-3-319-44790-2_4
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Xu D, 2015, PROC INT C TOOLS ART, P369, DOI 10.1109/ICTAI.2015.63
   Yin Z., 2018, MULTIMED TOOLS APPL, P1
NR 31
TC 9
Z9 9
U1 1
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 13
BP 17535
EP 17554
DI 10.1007/s11042-018-7130-y
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BM
UT WOS:000475703200010
DA 2024-07-18
ER

PT J
AU Yao, L
   Han, YD
   Li, XM
AF Yao, Li
   Han, Yingdong
   Li, Xiaomin
TI Fast and high-quality virtual view synthesis from multi-view plus depth
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE View synthesis; Artifacts removal; Depth-aided inpainting; GPU
   acceleration
ID COLOR CORRECTION; IMAGES; DIBR
AB Depth image based rendering (DIBR) is an effective method for virtual view synthesis from Multi-view Plus Depth(MVD) video. Synthetic images, however, often contain ghost effect and some holes of varying sizes. This paper uses color correction of reference views, and combines depth-based image fusion with direct color image fusion to decrease the ghost effect. Meanwhile, the cracks are filled using depth filtering and inverse warping. What's more, the image depth-aided inpainting with GPU acceleration is used to fill the remaining big disocclusions. Experimental results show that our proposed method improved the quality of virtual view synthetic images and reduced the processing time sharply.
C1 [Yao, Li; Han, Yingdong; Li, Xiaomin] Southeast Univ, Coll Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.
   [Yao, Li] Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing 211189, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Yao, L (corresponding author), Southeast Univ, Coll Comp Sci & Engn, Nanjing, Jiangsu, Peoples R China.; Yao, L (corresponding author), Southeast Univ, Minist Educ, Key Lab Comp Network & Informat Integrat, Nanjing 211189, Jiangsu, Peoples R China.
EM Yao.li@seu.edu.cn; han_yd2010@163.com; 675567876@qq.com
OI yao, li/0000-0003-2930-8407
FU natural science foundation of Jiangsu Province [BK20181267]; Industrial
   Prospective Project of Jiangsu Technology Department [BE2018119]
FX This work is supported by natural science foundation of Jiangsu Province
   under Grant No. BK20181267, Industrial Prospective Project of Jiangsu
   Technology Department under Grant No. BE2018119.
CR Chen Y, 2005, I C COMP SYST APPLIC
   Criminisi A., 2003, PROC CVPR IEEE, V2, pII, DOI DOI 10.1109/CVPR.2003.1211538
   Daribo I, 2007, IEEE WORKSH MULT SIG
   Do L, 2010, 3DTV C TRUE VIS CAPT, V7524, P1
   Fehn C, 2004, PROC SPIE, V5291, P93, DOI 10.1117/12.524762
   Fezza SA, 2014, IEEE T CIRC SYST VID, V24, P1486, DOI 10.1109/TCSVT.2014.2309776
   Fickel GP, 2015, IEEE INT C IM PROC, V29, P5387
   Jung JI, 2013, J SIGNAL PROCESS SYS, V72, P107, DOI 10.1007/s11265-012-0717-z
   Leonard Mcmillan J, 1997, IMAGE BASED APPROACH
   Li S, 2018, IEEE T MULTIMEDIA, V20, P1948, DOI 10.1109/TMM.2018.2791810
   Loghman M, 2015, MULTIMED TOOLS APPL, V74, P1611, DOI 10.1007/s11042-013-1747-7
   Luo G, 2016, 2016 IEEE C COMP VIS
   Marcelino S, 2016, J VIS COMMUN IMAGE R, V40, P589, DOI 10.1016/j.jvcir.2016.07.024
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Rahaman DMM, 2018, IEEE T IMAGE PROCESS, V27, P1190, DOI 10.1109/TIP.2017.2772858
   Tanimoto M, 2006, SIGNAL PROCESS-IMAGE, V21, P454, DOI 10.1016/j.image.2006.03.009
   Tanimoto M, 2012, SIGNAL PROCESS-IMAGE, V27, P555, DOI 10.1016/j.image.2012.02.016
   Vetro A, 2011, P IEEE, V99, P626, DOI 10.1109/JPROC.2010.2098830
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao L, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P365, DOI 10.1145/2993369.2996351
   ZAMARIN M, 2013, IEEE INT CON MULTI, pNI565
   Zhang L, 2005, IEEE T BROADCAST, V51, P191, DOI 10.1109/TBC.2005.846190
   Zhang L, 2004, INTERNATIONAL CONFER
   Zinger S, 2010, J VIS COMMUN IMAGE R, V21, P533, DOI 10.1016/j.jvcir.2010.01.004
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 25
TC 6
Z9 9
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2019
VL 78
IS 14
BP 19325
EP 19340
DI 10.1007/s11042-019-7236-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IJ2BS
UT WOS:000475703800018
DA 2024-07-18
ER

PT J
AU Abdulrahman, AK
   Ozturk, S
AF Abdulrahman, Ahmed Khaleel
   Ozturk, Serkan
TI A novel hybrid DCT and DWT based robust watermarking algorithm for color
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image watermarking; RGB; DCT; DWT; Arnold transform
ID BLIND WATERMARKING; SVD; DOMAIN; SCHEME; TRANSFORM; WAVELET; EFFICIENT;
   SECURE
AB In this paper, a novel robust color image watermarking method based on Discrete Cosine Transform (DCT) and Discrete Wavelet Transform (DWT) is proposed. In this method, RGB cover image is divided into red, green and blue components. DCT and DWT are applied to each color components. Grayscale watermark image is scrambled by using Arnold transform. DCT is performed to the scrambled watermark image. Transformed watermark image is then divided into equal smaller parts. DCT coefficients of each watermark parts are embedded into four DWT bands of the color components of the cover image. The robustness of the proposed color image watermarking has been demonstrated by applying various image processing operations such as rotating, resizing, filtering, jpeg compression, and noise adding to the watermarked images. Experimental results show that the proposed method is robust to the linear and nonlinear attacks and the transparency of the watermarked images has been protected.
C1 [Abdulrahman, Ahmed Khaleel; Ozturk, Serkan] Erciyes Univ, Dept Comp Engn, Talas Cad, TR-38039 Kayseri, Turkey.
C3 Erciyes University
RP Abdulrahman, AK (corresponding author), Erciyes Univ, Dept Comp Engn, Talas Cad, TR-38039 Kayseri, Turkey.
EM ahmedkhaleel.ahkh@gmail.com; serkan@erciyes.edu.tr
RI Ozturk, Serkan/B-4673-2013
CR Ahmad Asma, 2014, International Journal of Computer Network and Information Security, V6, P58, DOI 10.5815/ijcnis.2014.12.07
   Al-Afandy KA, 2018, MULTIMED TOOLS APPL, V77, P25709, DOI 10.1007/s11042-018-5814-y
   Ali M, 2018, MULTIMED TOOLS APPL, V77, P11751, DOI 10.1007/s11042-017-4815-6
   [Anonymous], 2018, MULTIMEDIA TOOLS APP
   Aslantas V, 2007, LECT NOTES COMPUT SC, V4628, P358
   Aslantas V, 2009, OPT COMMUN, V282, P2806, DOI 10.1016/j.optcom.2009.04.034
   Aslantas V, 2009, OPT COMMUN, V282, P769, DOI 10.1016/j.optcom.2008.11.024
   Bajracharya S., 2017, INT J ENG MANUF, V7, P49
   Barni M, 2002, J ELECTRON IMAGING, V11, P87, DOI 10.1117/1.1426383
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Botta M, 2015, SOFT COMPUT, V19, P1905, DOI 10.1007/s00500-014-1373-y
   Cedillo-Hernandez M, 2015, SIGNAL IMAGE VIDEO P, V9, P1163, DOI 10.1007/s11760-013-0555-x
   Chaitanya K., 2014, Int. J. Comput. Sci. Inf. Technol., V5, P2413
   Chang TC, 2018, METHODS MOL BIOL, V1823, P1, DOI 10.1007/978-1-4939-8624-8_1
   Chen L, 2018, MULTIMED TOOLS APPL, V77, P7187, DOI 10.1007/s11042-017-4628-7
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Divecha N, 2013, 2013 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND SIGNAL PROCESSING (ISSP), P204, DOI 10.1109/ISSP.2013.6526903
   Etemad E, 2018, MULTIMED TOOLS APPL, V77, P2033, DOI 10.1007/s11042-016-4278-1
   Gao H., 2013, TELKOMNIKA, V11, P3271
   Gill R., 2017, INT J ADV RES COMPUT, V8, P1304
   Giri Kaiser J., 2018, International Journal of Information Technology, V10, P139, DOI 10.1007/s41870-017-0075-y
   Giri Kaiser J, 2015, IJ IMAGE GRAPH SIGNA, P47
   Gupta M, 2015, INT J COMPUT INT SYS, V8, P364, DOI 10.1080/18756891.2015.1001958
   Hai T, 2014, J APPL RES TECHNOL, V12, P122, DOI 10.1016/S1665-6423(14)71612-8
   Hallur SR., 2015, INT J CURR ENG TECHN, V5, P2722
   He Y, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P212, DOI 10.1109/ROBIO.2018.8665138
   Hsu LY, 2017, J VIS COMMUN IMAGE R, V46, P33, DOI 10.1016/j.jvcir.2017.03.009
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Huang HC, 2009, INFORM HIDING APPL, V227
   Huang JW, 2000, IEEE T CIRC SYST VID, V10, P974, DOI 10.1109/76.867936
   Islam M, 2018, J INTELL FUZZY SYST, V34, P1691, DOI 10.3233/JIFS-169462
   Jeswani J., 2014, INT J COMPUTER APPL, V92, P50
   Kalra GS, 2015, MULTIMED TOOLS APPL, V74, P6849, DOI 10.1007/s11042-014-1932-3
   Kang XB, 2018, MULTIMED TOOLS APPL, V77, P13197, DOI 10.1007/s11042-017-4941-1
   Kaur Sandeep, 2017, International Journal of Image, Graphics and Signal Processing, V9, P23, DOI 10.5815/ijigsp.2017.07.03
   Kumar C, 2018, MULTIMED TOOLS APPL, V77, P3597, DOI 10.1007/s11042-017-5222-8
   Lakrissi Y, 2018, MULTIMED TOOLS APPL, V77, P13531, DOI 10.1007/s11042-017-4974-5
   Li JZ, 2018, MULTIMED TOOLS APPL, V77, P4545, DOI 10.1007/s11042-017-4452-0
   Lin SD, 2010, COMPUT STAND INTER, V32, P54, DOI 10.1016/j.csi.2009.06.004
   Lutovac B, 2017, MULTIMED TOOLS APPL, V76, P23333, DOI 10.1007/s11042-016-4127-2
   Moeinaddini E, 2018, MULTIMED TOOLS APPL, V77, P26083, DOI 10.1007/s11042-018-5838-3
   Moosazadeh M, 2017, OPTIK, V140, P975, DOI 10.1016/j.ijleo.2017.05.011
   Nikolaidis N, 1998, SIGNAL PROCESS, V66, P385, DOI 10.1016/S0165-1684(98)00017-6
   Pan J.-S., 2004, INTELLIGENT WATERMAR, V7
   Pandey Mahendra Kumar, 2018, ICTACT Journal on Image and Video Processing, V9, P1814, DOI 10.21917/ijivp.2018.0255
   Parah SA, 2018, NONLINEAR DYNAM, V93, P1933, DOI 10.1007/s11071-018-4299-6
   Parah SA, 2016, DIGIT SIGNAL PROCESS, V53, P11, DOI 10.1016/j.dsp.2016.02.005
   Patel H.A., 2018, ADV COMPUTER COMPUTA, P455, DOI DOI 10.1007/978-981-10-3773-3_44
   Pradhan C, 2012, PROC TECH, V1, P897, DOI 10.1016/j.protcy.2012.10.109
   Prakash B, 2018, SYNTHESIS OF MEDICINAL AGENTS FROM PLANTS, P25, DOI 10.1016/B978-0-08-102071-5.00002-7
   Qin C, 2017, SIGNAL PROCESS, V138, P280, DOI 10.1016/j.sigpro.2017.03.033
   Qin C, 2017, MULTIMED TOOLS APPL, V76, P2267, DOI 10.1007/s11042-015-3218-9
   Rasti P, 2017, SIG PROCESS COMMUN
   Raviya MKH, 2018, EUR J ACAD ESSAYS, V5, P98
   Riad R, 2017, CONTROL ENG APPL INF, V19, P25
   Rosales-Roldan L, 2018, MULTIMED TOOLS APPL, V77, P16031, DOI 10.1007/s11042-017-5178-8
   Roy A, 2018, INT J IMAGE GRAPH, V18, DOI 10.1142/S0219467818500158
   Roy S, 2018, IEEE GEOSCI REMOTE S, P1
   Roy S, 2018, WIRELESS PERS COMMUN, V98, P2223, DOI 10.1007/s11277-017-4971-z
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Sari CA, 2017, P EECSI, V4, P187
   Saxena V., 2010, International Journal of Computer Applications, V3, P28
   Sheth Ravi K., INT C ADV COMPUTING, DOI DOI 10.1109/ICACCA.2016.7578861
   Sikander, 2018, MICRO SYST TECHNOL, P1
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Siva Shankar S., 2016, ICTACT Journal on Image and Video Processing, V7, P1339, DOI 10.21917/ijivp.2016.0194
   Solachidis V, 2001, IEEE T IMAGE PROCESS, V10, P1741, DOI 10.1109/83.967401
   Sreenivas K, 2018, INT J MACH LEARN CYB, V9, P1193, DOI 10.1007/s13042-017-0641-4
   Su QT, 2018, SOFT COMPUT, V22, P91, DOI 10.1007/s00500-017-2489-7
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P8781, DOI 10.1007/s11042-016-3522-z
   Su QT, 2017, MULTIMED TOOLS APPL, V76, P707, DOI 10.1007/s11042-015-3071-x
   Su QT, 2015, SIGNAL IMAGE VIDEO P, V9, P991, DOI 10.1007/s11760-013-0534-2
   Thakur S, 2019, MULTIMED TOOLS APPL, V78, P3457, DOI 10.1007/s11042-018-6263-3
   Thanki R, 2018, J INF SECUR APPL, V40, P92, DOI 10.1016/j.jisa.2018.03.004
   Thien HT, 2018, INFORM SCIENCES, V426, P1, DOI 10.1016/j.ins.2017.10.016
   Vaidya SP, 2017, MULTIMED TOOLS APPL, V76, P25623, DOI 10.1007/s11042-017-4355-0
   Wang Q, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 5, PROCEEDINGS, P494, DOI 10.1109/ICNC.2008.105
   Wang XL, 2010, COMM TECHNOL, V4, P78
   Xu HC, 2018, INT J ELECTRON SECUR, V10, P79, DOI 10.1504/IJESDF.2018.089215
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zebbiche K, 2018, MULTIMED TOOLS APPL, V77, P21281, DOI 10.1007/s11042-017-5451-x
   Zhou N. R., 2018, MULTIMED TOOLS APPL, P1
   Zhou X, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10030077
NR 84
TC 79
Z9 84
U1 8
U2 76
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17027
EP 17049
DI 10.1007/s11042-018-7085-z
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500058
DA 2024-07-18
ER

PT J
AU Al-Ghamdi, M
   Al-Ghamdi, M
   Gutub, A
AF Al-Ghamdi, Maimoona
   Al-Ghamdi, Manal
   Gutub, Adnan
TI Security enhancement of shares generation process for multimedia
   counting-based secret-sharing technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Secret Sharing; Shares Generation; Shares Construction; Key Management;
   Key Distribution; Information Security
ID ELLIPTIC CURVE; SCHEME
AB Secret sharing is a cryptographic tool to ensure reliable and secure access to information. Counting-based secret sharing is a new secret sharing technique that generate the preprocessing shares using simple replacements operations of specific bits. This work considers addressing the challenges within the shares generation process of original multimedia counting based secret sharing scheme by studying the limitations in the number of shares, according to the range, trying to avoid the number of zero-bits boundaries within the original secret target key hindering the system performance. We also overcome the weakness of bits similarities between shares and the secret target key to enhance security. The research proposes a verification tool to test the shares proper validity in relation to the secret target key providing interesting features. The enhanced shares generation methods is found obtaining attractive results showing that our proposed scheme achieve high level of security, reliability and efficiency, compared to the original secret sharing work.
C1 [Al-Ghamdi, Maimoona; Gutub, Adnan] Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
   [Al-Ghamdi, Manal] Umm Al Qura Univ, Dept Comp Sci, Mecca, Saudi Arabia.
C3 Umm Al Qura University; Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Dept Comp Engn, Mecca, Saudi Arabia.
EM alghamdi.maimoona@gmail.com; maalghamdi@uqu.edu.sa; aagutub@uqu.edu.sa
RI Al-Ghamdi, Maimoona/AAN-5906-2020; Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X
FU Computer Engineering Department at Umm Al-Qura University
FX The authors acknowledge all support provided by Computer Engineering
   Department at Umm Al-Qura University (UQU) for encouraging this research
   work.
CR Abu-Marie W., 2010, International Journal of Signal and Image Processing, V1, P196
   Adnan G., 2010, Bahria University Journal of Information Communication Technology, V3, P68
   Ahmadoh Esraa Mohammad, 2015, Lecture Notes on Information Theory, V3, P42, DOI 10.18178/lnit.3.1.42-47
   Al-Juaid N, 2018, J INFORM SECURITY CY, V1
   Al-Nofaie S., 2016, J COMPUTER SCI COMPU, V6, P59, DOI [10.20967/jcscm.2016.03.004, DOI 10.20967/jcscm.2016.03.004]
   Al-Otaibi Nouf A., 2014, Lecture Notes on Information Theory, V2, P151, DOI 10.12720/lnit.2.2.151-157
   Alaseri K., 2018, IJRDO J COMPUTER SCI, V4, P1
   Almazrooie M, 2018, J KING SAUD U COMPUT
   [Anonymous], WOSPA 2008 5 IEEE IN
   ASMUTH C, 1983, IEEE T INFORM THEORY, V29, P208, DOI 10.1109/TIT.1983.1056651
   Bai L, 2006, INT S WORLD WIR MOB
   Beimel Amos, 2011, Coding and Cryptology. Proceedings of the Third International Workshop, IWCC 2011, P11, DOI 10.1007/978-3-642-20901-7_2
   Binu VP, 2017, WIRELESS PERS COMMUN, V92, P1531, DOI 10.1007/s11277-016-3619-8
   Blakley G. R., 1979, P 1979 AFIPS NAT COM, P313
   Fuji Y., 2005, P CSS2005, P631
   Gutub A., 2007, WASET INT C COMP INF
   Gutub A, 2018, J. Comput. Hardw. Eng, V1, P1
   Gutub Adnan Abdul-Aziz, 2011, International Journal of New Computer Architectures and their Applications, V1, P474
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2011, KUWAIT J SCI ENG, V38, P125
   Harn L, 2014, INFORM PROCESS LETT, V114, P504, DOI 10.1016/j.ipl.2014.04.006
   Khan F, 2007, 4 IEEE GCC C EXH MAN
   Kurihara J, 2008, IEICE T FUND ELECTR, VE91A, P2365, DOI 10.1093/ietfec/e91-a.9.2365
   Kurihara J, 2008, IEICE T FUND ELECTR, VE91A, P127, DOI 10.1093/ietfec/e91-a.1.127
   Liao-Jun P, 2005, WUHAN U J NAT SCI, V10, P191, DOI [10.1007/BF02828647, DOI 10.1007/BF02828647]
   Lin HC, 2013, J VIS COMMUN IMAGE R, V24, P318, DOI 10.1016/j.jvcir.2013.01.003
   Naskar P. K., 2011, Proceedings of the Second International Conference on Emerging Applications of Information Technology (EAIT 2011), P177, DOI 10.1109/EAIT.2011.43
   Osamu T, 2005, J NATL I INFORM COMM, V52
   Parvez MT, 2011, KUWAIT J SCI ENG, V38, P127
   Parvez MT, 2008, APSCC 2008 P 3 IEEE
   Raphel RK, 2015, LECT NOTES COMPUT SC, V9532, P476, DOI 10.1007/978-3-319-27161-3_43
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shima K, 2016, 11 AS JOINT C INF SE
   Stinson D. R., 1992, Designs, Codes and Cryptography, V2, P357, DOI 10.1007/BF00125203
   Tentu A. N., 2014, CRYPTOGRAPHY SECURIT, V448, P100
   Wang K, 2009, 33 ANN IEEE INT COMP
   Yang CC, 2004, APPL MATH COMPUT, V151, P483, DOI 10.1016/S0096-3003(03)00355-2
   Yang CN, 2011, J SYST SOFTWARE, V84, P1726, DOI 10.1016/j.jss.2011.05.008
   Yang CN, 2010, OPT COMMUN, V283, P1750, DOI 10.1016/j.optcom.2009.12.077
NR 40
TC 42
Z9 43
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16283
EP 16310
DI 10.1007/s11042-018-6977-2
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500025
DA 2024-07-18
ER

PT J
AU An, FP
   Liu, ZW
AF An, Feng-Ping
   Liu, Zhi-Wen
TI Bi-dimensional empirical mode decomposition (BEMD) algorithm based on
   particle swarm optimization-fractal interpolation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fractal; Particle swarm optimization; Bi-dimensional empirical mode
   decomposition; Optimization; Image interpolation
ID NOISE-REDUCTION; IMAGE-ANALYSIS
AB The performance of interpolation algorithm used in bi-dimensional empirical mode decomposition directly affects its popularization and application. Therefore, the research on interpolation algorithm is more reasonable, accurate and fast. So far, in the interpolation algorithm adopted by the bi-dimensional empirical mode decomposition, an adaptive interpolation algorithm can be proposed according to the image characteristics. In view of this, this paper proposes an image interpolation algorithm based on the particle swarm and fractal. Its procedure includes: to analyze the given image by using the fractal brown function, to pick up the feature quantity from the image, and then to operate the adaptive image interpolation in terms of the obtained feature quantity. The parameters involved in the interpolation process are optimized by particle swarm optimization algorithm, and the optimal parameters are obtained, which can solve the problem of low efficiency and low precision of interpolation algorithm used in bi-dimensional empirical mode decomposition. It solves the problem that the image cannot be decomposed to obtain accurate and reliable bi-dimensional intrinsic modal function, and realize the fast decomposition of the image. It lays the foundation for the further popularization and application of the bi-dimensional empirical mode decomposition algorithm.
C1 [An, Feng-Ping] Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223300, JS, Peoples R China.
   [An, Feng-Ping; Liu, Zhi-Wen] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, BJ, Peoples R China.
C3 Huaiyin Normal University; Beijing Institute of Technology
RP An, FP (corresponding author), Huaiyin Normal Univ, Sch Phys & Elect Elect Engn, Huaian 223300, JS, Peoples R China.; An, FP (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, BJ, Peoples R China.
EM anfengping@163.com
OI AN, FENGPING/0000-0002-2220-2987
FU National Science Foundation Project of P. R. China [61701188]
FX This work is supported by National Science Foundation Project of P. R.
   China (No. 61701188).
CR Al-Baddai S, 2016, INFORM SCIENCES, V348, P305, DOI 10.1016/j.ins.2016.01.089
   [Anonymous], 2014, SEARCH METHODOLOGIES, DOI DOI 10.1007/978-1-4614-6940-7_4
   Bernini MB, 2008, APPL OPTICS, V47, P2592, DOI 10.1364/AO.47.002592
   Bernini MB, 2009, APPL OPTICS, V48, P6862, DOI 10.1364/AO.48.006862
   Bhuiyan SMA, 2009, ADV DATA SCI ADAPT, V1, P309, DOI 10.1142/S1793536909000084
   Bornert M, 2017, OPT LASER ENG, V91, P124, DOI 10.1016/j.optlaseng.2016.11.014
   Clerc M, 2010, PARTICLE SWARM OPTIM, P321
   de Boor C., 1987, Computer-Aided Geometric Design, V4, P269, DOI 10.1016/0167-8396(87)90002-1
   [邓蕾 Deng Lei], 2011, [振动、测试与诊断, Journal of Vibration, Measurement and Diagnosis], V31, P344
   Falconer K, 2004, FRACTAL GEOMETRY MAT, P109
   Falconer K, 2012, FRACTALS THEORY APPL, P201
   Goldberg DE, 2013, DESIGN INNOVATION LE, P138
   Grefenstette JJ, 2013, P P 2 INT C GEN ALG, P109
   Grefenstette JJ, 2013, P 2 INT C GEN ALG, P309
   He Z, 2013, IEEE T INSTRUM MEAS, V62, P889, DOI 10.1109/TIM.2013.2246917
   Ke Y, 2004, PROC CVPR IEEE, P506
   Li TJ, 2011, INFORM FUSION, V12, P85, DOI 10.1016/j.inffus.2010.03.007
   Lin DC, 2012, MECH SYST SIGNAL PR, V31, P13, DOI 10.1016/j.ymssp.2012.02.012
   Linderhed A, 2005, INT J WAVELETS MULTI, V3, P435, DOI 10.1142/S0219691305000932
   Liu ZX, 2004, IEEE IMAGE PROC, P279
   Nunes J, 2005, MACH VISION APPL, V16, P177, DOI 10.1007/s00138-004-0170-5
   Nunes JC, 2003, IMAGE VISION COMPUT, V21, P1019, DOI 10.1016/S0262-8856(03)00094-5
   Panichella A, 2013, PROCEEDINGS OF THE 35TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING (ICSE 2013), P522, DOI 10.1109/ICSE.2013.6606598
   RUBIN SG, 1977, J COMPUT PHYS, V24, P217, DOI 10.1016/0021-9991(77)90036-5
   Sadeghi B, 2018, IEEE T SIGNAL PROCES, V66, P101, DOI 10.1109/TSP.2017.2759100
   Scrucca L, 2013, J STAT SOFTW, V53, P1
   Steeb WH, 2014, NONLINEAR WORKBOOK C, P307
   Torres IC, 2012, J FOOD ENG, V109, P721, DOI 10.1016/j.jfoodeng.2011.11.016
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Wielgus M, 2011, APPL OPTICS, V50, P5513, DOI 10.1364/AO.50.005513
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P339, DOI 10.1142/S1793536909000187
   Xu GM, 2016, J GEOCHEM EXPLOR, V164, P65, DOI 10.1016/j.gexplo.2015.09.013
   Yin SF, 2010, INFRARED PHYS TECHN, V53, P146, DOI 10.1016/j.infrared.2009.10.007
   Zhao J, 2016, COMPUT GEOSCI-UK, V88, P132, DOI 10.1016/j.cageo.2015.12.016
   Zhou Y, 2011, OPT EXPRESS, V19, P18207, DOI 10.1364/OE.19.018207
NR 35
TC 5
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 17239
EP 17264
DI 10.1007/s11042-018-7097-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500066
DA 2024-07-18
ER

PT J
AU Choi, S
   Aizawa, K
AF Choi, Saemi
   Aizawa, Kiyoharu
TI Emotype: Expressing emotions by changing typeface in mobile messenger
   texting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Typeface; Font; Emotion; Computer-mediate-communication; Mobile
   messenger
ID COMPUTER-MEDIATED COMMUNICATION; ONLINE
AB Instant messaging is a popular form of text-based communication. However, text-based messaging lacks the ability to communicate nonverbal information such as that conveyed through facial expressions and voice tones, although a multitude of emotions may underlie the text of a conversation between participants. In this paper, we propose an approach that uses typefaces to communicate emotions. We investigated which typefaces are useful for delivering emotions and introduced these typefaces into a mobile chat app. We conducted a survey to demonstrate how changes in the typeface of a message affected the meaning of the message conveyed. Our user study provides an understanding of the actual user experience with the application. The results show that the use of multiple typefaces in a message can affect and intensify the valence received by users and the use of multiple typefaces elicited an active response and brought about a livelier mood during texting.
C1 [Choi, Saemi; Aizawa, Kiyoharu] Univ Tokyo, Fac Engn Bldg 2, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
C3 University of Tokyo
RP Choi, S (corresponding author), Univ Tokyo, Fac Engn Bldg 2, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
EM merrycsm@hal.t.u-tokyo.ac.jp; aizawa@hal.t.u-tokyo.ac.jp
FU KAKENHI [17K19963]; Grants-in-Aid for Scientific Research [17K19963]
   Funding Source: KAKEN
FX This research is partially supported by KAKENHI 17K19963.
CR Ali Ahmad Zamzuri Mohamad, 2013, International Education Studies, V6, P26, DOI DOI 10.5539/IES.V6N3P26
   Alm CO, 2005, P C HUM LANG TECHN E, P579, DOI DOI 10.3115/1220575.1220648
   Amare N., 2012, 2012 IEEE INT PROFES, P1, DOI [https://doi.org/10.1109/IPCC.2012.6408605, DOI 10.1109/IPCC.2012.6408605]
   [Anonymous], 2016, ATLAS
   [Anonymous], 2016, LINE STICKERS
   [Anonymous], 2010, 11 INT SOC MUS INF R
   [Anonymous], 2018, IEEE C COMP VIS PATT
   Arditi A, 2005, VISION RES, V45, P2926, DOI 10.1016/j.visres.2005.06.013
   Baron NS, 2004, J LANG SOC PSYCHOL, V23, P397, DOI 10.1177/0261927X04269585
   Byron K., 2007, Journal of Business Communication, V44, P137, DOI 10.1177/0021943606297902
   Candello H, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3476, DOI 10.1145/3025453.3025919
   Chen XF, 2013, KEY ENG MATER, V538, P193, DOI 10.4028/www.scientific.net/KEM.538.193
   Childers TL, 2002, J CONSUM PSYCHOL, V12, P93, DOI 10.1207/S15327663JCP1202_03
   Choi S, 2018, IUI 2018: PROCEEDINGS OF THE 23RD INTERNATIONAL CONFERENCE ON INTELLIGENT USER INTERFACES, P37, DOI 10.1145/3172944.3173001
   Choi Saemi, 2016, P 1 INT WORKSH MULT, P37
   COLLINS NL, 1994, PSYCHOL BULL, V116, P457, DOI 10.1037/0033-2909.116.3.457
   Dawn Shaikh A., 2006, Usability News, V8, P1
   Derks D, 2008, COMPUT HUM BEHAV, V24, P766, DOI 10.1016/j.chb.2007.04.004
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   GOTTSCHALK L.A., 1969, MEASUREMENT PSYCHOL
   Guest G, 2017, FIELD METHOD, V29, P3, DOI 10.1177/1525822X16639015
   Gyurak A, 2011, COGNITION EMOTION, V25, P400, DOI 10.1080/02699931.2010.544160
   Hancock JT, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P929
   HEERY MW, 1989, J TRANSPERSONAL PSY, V21, P73
   Henderson PW, 2004, J MARKETING, V68, P60, DOI 10.1509/jmkg.68.4.60.42736
   Huang SP, 2018, PATTERN RECOGN, V77, P395, DOI 10.1016/j.patcog.2017.10.018
   Inc. G, 2016, ALL APPS
   Joonhwan Lee, 2006, Designing Interactive Systems. DIS2006, P41
   Kalman YM, 2014, COMPUT HUM BEHAV, V34, P187, DOI 10.1016/j.chb.2014.01.047
   Kim M, 2016, DIS 2016: PROCEEDINGS OF THE 2016 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P276, DOI 10.1145/2901790.2901835
   Larissa A., 2014, The 29th Annual ACM Symposium on Applied Computing, P628
   Li Y., 2010, P 9 IAPR INT WORKSHO, P231
   Limited CG, 2016, FONT INF ITUNES
   Machajdik J., 2010, P 18 ACM INT C MULT, P83, DOI DOI 10.1145/1873951.1873965
   Mehrabian A., 1980, BASIC DIMENSIONS GEN
   Min F, 2016, FONT DRESS ITUNES
   Montefinese M, 2014, BEHAV RES METHODS, V46, P887, DOI 10.3758/s13428-013-0405-3
   O'Donovan P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601110
   Oyama T., 2003, Empirical Studies of the Arts, V21, P137, DOI [10.2190/eyft-b5ue-appw-10b6, DOI 10.2190/EYFT-B5UE-APPW-10B6]
   Park TW, 2014, LECT NOTES COMPUT SC, V8512, P155, DOI 10.1007/978-3-319-07227-2_16
   Rello L, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P3637, DOI 10.1145/2858036.2858204
   Rubinstein Richard., 1988, Digital typography: an introduction to type and compositionfor the computer system design
   Tewell J, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P1756, DOI 10.1145/3025453.3025844
   Walther JB, 2005, J LANG SOC PSYCHOL, V24, P36, DOI 10.1177/0261927X04273036
   Wang ZY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P451, DOI 10.1145/2733373.2806219
   Zhang Yexun, 2018, P IEEE C COMP VIS PA, V1
NR 46
TC 10
Z9 12
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 14155
EP 14172
DI 10.1007/s11042-018-6753-3
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700003
OA hybrid
DA 2024-07-18
ER

PT J
AU Huang, W
   Lin, LP
   Huang, TQ
   Lin, J
   Zhang, XL
AF Huang, Wei
   Lin, Lingpeng
   Huang, Tianqiang
   Lin, Jing
   Zhang, Xueli
TI Scale-adaptive tracking based on perceptual hash and correlation filter
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Correlation filter; Scale-adaptive; Perceptual hash
ID VISUAL TRACKING; OBJECT TRACKING; ROBUST TRACKING
AB In the research on computer vision, object tracking has encountered various challenges, such as occlusion and scale variation. In recent years, tracking-by-detection methods have performed competitively. Some of these methods have focused on solving the problem of scale variation. Regardless, these algorithms perform poorly in real time. Recently, correlation filters have been widely used in object tracking because of their high efficiency; however, conventional correlation filter-based trackers cannot handle scale variation. Most correlation filter-based trackers update the template for each frame, and tracking offsets occur when a tracking error is present. To overcome these problems, we propose a novel scale-adaptive tracking algorithm that uses perceptual hash and correlation filter on the basis of tracking-by-detection methods. We employ kernel ridge regression to minimize the mean square error between the training image and the regression object, and construct a robust filter template to track the target center location. By tracking the 4 sub-blocks of the target image, the length and width expansion coefficients are calculated separately to update the target scale. We finally use the adaptive update strategy based on perceptual hash to effectively prevent the tracking offset caused by the template update error. Owing to the insensitivity to the scale variation and high efficiency of the perceptual hash, tracking becomes more robust in real time. Both quantitative and qualitative evaluations on Object Tracking Benchmark (OTB) indicate that the proposed tracking method performs more favorably compared with other state-of-the-art methods.
C1 [Huang, Wei; Lin, Lingpeng; Huang, Tianqiang; Zhang, Xueli] Fujian Normal Univ, Coll Math & Informat, Fuzhou 350117, Fujian, Peoples R China.
   [Huang, Wei; Lin, Lingpeng; Huang, Tianqiang; Zhang, Xueli] Fujian Engn Res Ctr Publ Serv Big Data Min & Appl, Fuzhou 350007, Fujian, Peoples R China.
   [Lin, Jing] Fuzhou Polytech, Dept Comp Sci, Fuzhou 350108, Fujian, Peoples R China.
C3 Fujian Normal University
RP Lin, LP (corresponding author), Fujian Normal Univ, Coll Math & Informat, Fuzhou 350117, Fujian, Peoples R China.; Lin, LP (corresponding author), Fujian Engn Res Ctr Publ Serv Big Data Min & Appl, Fuzhou 350007, Fujian, Peoples R China.
EM fjnu510@163.com
FU National Natural Science Foundation of China [61070062, 61502103];
   Industry-University Cooperation Major Projects in Fujian Province
   [2015H6007]; Science and Technology Program of Fujian [2014-G-76];
   Program for New Century Excellent Talents in University in Fujian
   Province [JAI1038]; Science and Technology Department of Fujian Province
   K-Class Foundation Project [2011007]; Education Department of Fujian
   Province A-Class Foundation Project [JA10064]
FX This study was supported by National Natural Science Foundation of China
   (No.61070062, No.61502103), Industry-University Cooperation Major
   Projects in Fujian Province (No.2015H6007), Science and Technology
   Program of Fujian (No.2014-G-76), Program for New Century Excellent
   Talents in University in Fujian Province (No. JAI1038), Science and
   Technology Department of Fujian Province K-Class Foundation Project
   (No.2011007) and Education Department of Fujian Province A-Class
   Foundation Project (No.JA10064).
CR [Anonymous], HAMMING DISTANCE ENC
   [Anonymous], COMPUT SCI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], SEGMENTATION BASED P
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], J SE U
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2016, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2015.2509974
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], 2007, ACTA ELECT SIN
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Lee DY, 2014, PROC CVPR IEEE, P3486, DOI 10.1109/CVPR.2014.446
   Li X., 2008, Computer Vision and Pattern Recognition
   Li Y, 2015, PROC CVPR IEEE, P353, DOI 10.1109/CVPR.2015.7298632
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Liu T, 2015, IEEE SIGNAL PROC LET, V22, P1452, DOI 10.1109/LSP.2014.2365363
   Lucey S., 2008, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587564
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Ning J, 2012, IET COMPUT VIS, V6, P52, DOI 10.1049/iet-cvi.2010.0112
   Ntu Xia-mu, 2008, Acta Electronica Sinica, V36, P1405
   Qing Wang, 2012, 2012 IEEE Workshop on Applications of Computer Vision (WACV), P425, DOI 10.1109/WACV.2012.6162999
   Rodriguez A, 2013, IEEE T IMAGE PROCESS, V22, P631, DOI 10.1109/TIP.2012.2220151
   Ronghong Chen, 2014, Applied Mechanics and Materials, V539, P146, DOI 10.4028/www.scientific.net/AMM.539.146
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Vojir T, 2013, LECT NOTES COMPUT SC, V7944, P652
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wang SM, 2017, DESTECH TRANS SOC, P1
   Wang XY, 2010, LECT NOTES COMPUT SC, V6313, P200
   Wu W, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING WORKSHOP PROCEEDINGS, VOLS 1 AND 2, P4, DOI 10.1109/KAMW.2008.4810409
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xiao ZY, 2014, IEEE T CIRC SYST VID, V24, P1301, DOI 10.1109/TCSVT.2013.2291355
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2014, LECT NOTES COMPUT SC, V8693, P127, DOI 10.1007/978-3-319-10602-1_9
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhu G, 2015, IEEE WINT CONF APPL, P63, DOI 10.1109/WACV.2015.16
   Zuo Z, 2015, PATTERN RECOGN, V48, P3004, DOI 10.1016/j.patcog.2015.02.003
NR 58
TC 3
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 12
BP 16011
EP 16032
DI 10.1007/s11042-018-6956-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IE0RM
UT WOS:000472094500013
DA 2024-07-18
ER

PT J
AU Xiao, QK
   Zhao, YD
   Huan, W
AF Xiao, Qinkun
   Zhao, Yidan
   Huan, Wang
TI Multi-sensor data fusion for sign language recognition based on dynamic
   Bayesian network and convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE SLR; DBN; CNN; Graph model; Multi-sensors data
ID PARALLEL FRAMEWORK
AB A new multi-sensor fusion framework is proposed, which is based on the Convolutional Neural Network (CNN) and the Dynamic Bayesian Network (DBN) for Sign Language Recognition (SLR). In this framework, a Microsoft Kinect, which is a low-cost RGB-D sensor, is used as tools of the Human-Computer-Interaction (HCI). In our method, at first, the color and depth videos are collected using the Kinect, the next, all image sequences features are extracted out using the CNN. The color and depth feature sequences are input into the DBN as observation data. Based on graph model fusion, the maximum recognition rate of dynamic isolated sign language is calculated. The proposed the DBN + CNN SLR framework is tested in our dataset, the highest recognition rate can up to 99.40%. The test results show that our approach is effective.
C1 [Xiao, Qinkun; Zhao, Yidan; Huan, Wang] Xian Technol Univ, Dept Elect Informat & Engn, Xian 710032, Shaanxi, Peoples R China.
C3 Xi'an Technological University
RP Xiao, QK (corresponding author), Xian Technol Univ, Dept Elect Informat & Engn, Xian 710032, Shaanxi, Peoples R China.
EM xiaoqinkun10000@163.com; yidanzhao0110@163.com; 3087133863@qq.com
FU Nature Science Foundation of China [60972095, 61271362, 61671362];
   Nature Science Basic Research Plan in Shaanxi Province of China
   [2017JM6041]
FX This work is supported by the Nature Science Foundation of China (Nos.
   60972095, 61271362, 61671362) and Nature Science Basic Research Plan in
   Shaanxi Province of China (Nos. 2017JM6041).
CR Almeida SGM, 2014, EXPERT SYST APPL, V41, P7259, DOI 10.1016/j.eswa.2014.05.024
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Celebi Sait, 2013, International Conference on Computer Vision Theory and Applications (VISAPP 2013). Proceedings, P620
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Chu SM, 2002, INT CONF ACOUST SPEE, P2009
   DAGUM P, 1992, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P41
   Elons AS, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER ENGINEERING & SYSTEMS (ICCES), P368, DOI 10.1109/ICCES.2014.7030987
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Lang S, 2012, LECT NOTES ARTIF INT, V7267, P394, DOI 10.1007/978-3-642-29347-4_46
   Marin G, 2015, MULTIMED TOOLS APPL, V25
   Marin G, 2014, IEEE IMAGE PROC, P1565, DOI 10.1109/ICIP.2014.7025313
   Nefian AV, 2002, INT CONF ACOUST SPEE, P2013
   Pedersoli F, 2014, VISUAL COMPUT, V30, P1107, DOI 10.1007/s00371-014-0921-x
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Russell S., 2010, ARTIF INTELL, V3rd
   Suk HI, 2010, PATTERN RECOGN, V43, P3059, DOI 10.1016/j.patcog.2010.03.016
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P220, DOI 10.1109/TITS.2017.2749977
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
NR 20
TC 18
Z9 20
U1 0
U2 34
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15335
EP 15352
DI 10.1007/s11042-018-6939-8
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700052
DA 2024-07-18
ER

PT J
AU Zhou, WL
   Zhu, Z
   Liang, PY
AF Zhou, Weili
   Zhu, Zhen
   Liang, Peiying
TI Speech denoising using Bayesian NMF with online base update
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speech denoising; NMF, Bayesian; Online base update
ID NONNEGATIVE MATRIX FACTORIZATION; STATISTICAL-MODEL; NOISE-ESTIMATION;
   ENHANCEMENT
AB A new speech denoising method based on online non-negative matrix factorization (NMF) is proposed in this paper. To achieve an efficient model for the temporal dependencies of speech and noise, and to improve the robustness for the actual non-stationary noisy environments, the Bayesian NMF is extended to the proposed model and a new noise basis matrix online update method is exploited. Firstly, the speech basis matrix is pre-trained off-line with the Bayesian NMF method. In speech denoising stage, the noise basis matrix is continuously updated by utilizing the noise frames in the noisy observation with the Bayesian NMF. The noise basis matrix is initialized via a pre-trained universal noise NMF model and the noise data for the matrix adaption are selected using a likelihood ratio test (LRT) speech decision criterion. Then the updated noise basis matrix and the pre-trained speech basis matrix are employed to the enhancement of the noisy signal. Finally, to address the incomplete separation and the speech distortion problem, a speech activity probability based noise suppression filter is presented to further eliminate the residue noise in the enhanced result. The experiment results show that the proposed method outperforms the comparative denoising algorithms in terms of objective measurement.
C1 [Zhou, Weili; Zhu, Zhen; Liang, Peiying] Foshan Univ, Sch Elect & Informat Engn, Foshan, Peoples R China.
C3 Foshan University
RP Zhou, WL (corresponding author), Foshan Univ, Sch Elect & Informat Engn, Foshan, Peoples R China.
EM willychow@163.com
FU Foshan University Research Foundation for Advanced Talents [GG07005]
FX This work is supported by the Foshan University Research Foundation for
   Advanced Talents (GG07005).
CR [Anonymous], 2013, COMPUT REV
   Cemgil Ali Taylan, 2009, Comput Intell Neurosci, P785152, DOI 10.1155/2009/785152
   Chen Y, 2018, IEEE T CIRC SYST VID, V28, P414, DOI 10.1109/TCSVT.2016.2615444
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Cohen I, 2005, IEEE T SPEECH AUDI P, V13, P870, DOI 10.1109/TSA.2005.851940
   Cohen I, 2002, IEEE SIGNAL PROC LET, V9, P12, DOI 10.1109/97.988717
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Févotte C, 2009, NEURAL COMPUT, V21, P793, DOI 10.1162/neco.2008.04-08-771
   Guan N, 2012, IEEE T NEURAL NETW L, V23
   Hazan Elad., 2015, Introduction to online convex optimization
   ITU-T Recommendation, 2001, 862 ITUT
   Kwon K, 2015, IEEE SIGNAL PROC LET, V22, P450, DOI 10.1109/LSP.2014.2362556
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee S, 2017, APPL ACOUST, V117, P257, DOI 10.1016/j.apacoust.2016.04.024
   Loizou PC, 2005, IEEE T SPEECH AUDI P, V13, P857, DOI 10.1109/TSA.2005.851929
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   Martin R, 2005, IEEE T SPEECH AUDI P, V13, P845, DOI 10.1109/TSA.2005.851927
   Mohammadiha N, 2013, IEEE T AUDIO SPEECH, V21, P2140, DOI 10.1109/TASL.2013.2270369
   Mohammadiha N, 2012, INT CONF ACOUST SPEE, P4561, DOI 10.1109/ICASSP.2012.6288933
   Mysore GJ, 2011, P IEEE INT C AC SPEE
   Rangachari S, 2006, SPEECH COMMUN, V48, P220, DOI 10.1016/j.specom.2005.08.005
   Rebhan S, 2009, LECT NOTES COMPUT SC, V5507, P960, DOI 10.1007/978-3-642-03040-6_117
   Scalart P, 1996, INT CONF ACOUST SPEE, P629, DOI 10.1109/ICASSP.1996.543199
   Schmidt MN, 2008, MACHINE LEARN SIGN P, P486, DOI 10.1109/MLSP.2008.4685528
   Sohn J, 1999, IEEE SIGNAL PROC LET, V6, P1, DOI 10.1109/97.736233
   Sohn J, 1998, INT CONF ACOUST SPEE, P365, DOI 10.1109/ICASSP.1998.674443
   Virtanen T, 2007, IEEE T AUDIO SPEECH, V15, P1066, DOI 10.1109/TASL.2006.885253
   Wang D, 2011, ONLINE PATTERN LEARN, P65
   Wilson KW, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P411
   Zhou WL, 2017, IET SIGNAL PROCESS, V11, P486, DOI 10.1049/iet-spr.2016.0555
NR 30
TC 5
Z9 7
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2019
VL 78
IS 11
BP 15647
EP 15664
DI 10.1007/s11042-018-6990-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IH1KM
UT WOS:000474249700066
OA Bronze
DA 2024-07-18
ER

PT J
AU Brahim, W
   Betrouni, N
   Mestiri, M
   Hamrouni, K
AF Brahim, Wael
   Betrouni, Nacim
   Mestiri, Makram
   Hamrouni, Kamel
TI The pleural thickening approximation from thoracic CT scans
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Pleural thickening approximation; Malignant pleural mesothelioma
   segmentation; Chest cavity segmentation; Computed tomography
ID SOLID TUMORS; MESOTHELIOMA
AB The involvement of medical imaging in medical procedures plays an important role in the diagnosis and planning of a therapeutic treatment. Computerized tomography (CT), which is a tomographic acquisition imaging modality, is commonly used in combination with a medical diagnostic aid system. Therapists use these systems to properly diagnose and plan the therapeutic gesture in the preoperative phase. The aim of this study is to propose a diagnostic aid system that is capable of segmenting and measuring the pleural thickening caused by a pleural disease called "Malignant Pleural Mesothelioma". In the clinical case, radiologists perform linear measurements to take several one-dimensional (1D) segments on specic sections in each CT scan of the patient. As a result they can estimate the tumor thickness. Disease progression and response to therapy are then quantied by comparing the representative lengths calculated for the same patient at two dierent time points. Adjacent structures such as the thoracic cage may provide useful information about the pleural thickening location in the CT volume. We have used this property to propose a computerized method, which aims to delimit the chest cavity and approximate the pleural thickening in order to determine the stage of cancer and its progression. The method was validated on a representative database and the results obtained for ten test series were very encouraging.
C1 [Brahim, Wael; Mestiri, Makram; Hamrouni, Kamel] Univ Tunis El Manar, LR SITI Signal Image & Technol Informat, Ecole Natl Ingenieurs Tunis, Tunis 1002, Tunisia.
   [Betrouni, Nacim] Univ Lille, INSERM, U1189, OncoTHAI,CHRU Lille, 1 Ave Oscar Lambert, F-59037 Lille, France.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT); Universite de Lille; CHU Lille; Institut National de la Sante et
   de la Recherche Medicale (Inserm)
RP Brahim, W (corresponding author), Univ Tunis El Manar, LR SITI Signal Image & Technol Informat, Ecole Natl Ingenieurs Tunis, Tunis 1002, Tunisia.
EM waelbrahimisamm@gmail.com
RI Betrouni, Nacim/M-5591-2018
CR A. J. C. on Cancer, 2010, AJCC CANC STAG MAN S, V7, P271
   Association TNEM, 2016, DICOM STAND NAT EL M
   Brahim W, 2016, 2016 INT IMAGE PROCE, P5
   Brahim W, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL AND IMAGE PROCESSING (ATSIP), P220
   Byrne N, 2003, OXFORD J, V15, P257
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Chen Y, 2014, IEEE T MED IMAGING, V33, P2271, DOI 10.1109/TMI.2014.2336860
   Eisenhauer EA, 2009, EUR J CANCER, V45, P228, DOI 10.1016/j.ejca.2008.10.026
   Frauenfelder T, 2011, EUR RESPIR J, V38, P162, DOI 10.1183/09031936.00146110
   Furuhashi S, 2009, J DIGIT IMAGING, V22, P689, DOI 10.1007/s10278-008-9162-8
   James K, 1999, J NATL CANCER I, V91, P523, DOI 10.1093/jnci/91.6.523
   Liu F, 2010, J THORAC ONCOL, V5, P879, DOI 10.1097/JTO.0b013e3181dd0ef1
   Liu J, 2017, IEEE T MED IMAGING, V36, P2499, DOI 10.1109/TMI.2017.2739841
   Mensi C, 2015, ENVIRON INT, V74, P191, DOI 10.1016/j.envint.2014.10.016
   Oxnard GR, 2006, LUNG CANCER, V52, P141, DOI 10.1016/j.lungcan.2005.12.013
   Pele O, 2010, LECT NOTES COMPUT SC, V6312, P749, DOI 10.1007/978-3-642-15552-9_54
   Scherpereel A, 2015, REV MALADIES RESP AC, V7, P511
   Sensakovic W. F., 2010, AM ASS PHYS MED, V38, P238
   Stephens RJ, 2015, LUNG CANCER, V89, P175, DOI 10.1016/j.lungcan.2015.05.021
   Yan CG, 2018, IEEE T INTELL TRANSP, V19, P284, DOI 10.1109/TITS.2017.2749965
   Zucali PA, 2006, EUR J CANCER, V42, P2706, DOI 10.1016/j.ejca.2006.07.011
NR 21
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 10
BP 13033
EP 13046
DI 10.1007/s11042-018-6400-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IG3FK
UT WOS:000473688100001
DA 2024-07-18
ER

PT J
AU Fu, B
   Zhao, XY
   Song, CM
   Li, XM
   Wang, XH
AF Fu, Bo
   Zhao, Xiaoyang
   Song, Chuanming
   Li, Ximing
   Wang, Xianghai
TI A salt and pepper noise image denoising method based on the generative
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image denoising; Patch clustering; Salt and pepper noise; Non-local
   switching filter
ID IMPULSE NOISE; REMOVAL; FILTER; DENSITY
AB In this paper, an image denoising algorithm is proposed for salt and pepper noise. First, a generative model is built on a patch as a basic unit and then the algorithm locates the image noise within that patch in order to better describe the patch and obtain better subsequent clustering. Second, the algorithm classifies patches using a generative clustering method, which provides additional similarity information for noise repairing, suppresses the interference of noise and abandons those classes that consist of a smaller number of patches. Finally, the algorithm builds a non-local switching filter to remove the salt and pepper noise. Simulation results show that the proposed algorithm effectively denoises salt and pepper noise of various densities. It obtains a better visual quality and higher peak signal-to-noise ratio score than several state-of-the-art algorithms. In short, our algorithm uses a noisy patch as the basic unit, a patch clustering method to optimize the repair data set as well as obtains a better denoising effect, and provides a guideline for future denoising and repair methods.
C1 [Fu, Bo; Zhao, Xiaoyang; Song, Chuanming; Wang, Xianghai] Liaoning Normal Univ, Coll Comp & Informat Technol, Dalian, Peoples R China.
   [Li, Ximing] Jilin Univ, Coll Comp Sci & Technol, Changchun, Jilin, Peoples R China.
C3 Liaoning Normal University; Jilin University
RP Fu, B (corresponding author), Liaoning Normal Univ, Coll Comp & Informat Technol, Dalian, Peoples R China.
EM fubo@lnnu.edu.cn
RI Wang, Xianghai/GRR-4512-2022
OI Wang, Xianghai/0000-0002-7600-9939; Fu, Bo/0000-0001-7030-821X
FU National Natural Science Foundation of China (NSFC) [61702246, 61402214,
   61602204, 41671439]; Liaoning Province of China General Project of
   Scientific Research [L2015285]; Liaoning Province of China Doctoral
   Research Fund [201601243]; Liaoning University Youth Project
   [LS2014L014]
FX This work is supported by the National Natural Science Foundation of
   China (NSFC) Grant No. 61702246, 61402214, 61602204, and 41671439,
   Liaoning Province of China General Project of Scientific Research No.
   L2015285, Liaoning Province of China Doctoral Research Fund No.
   201601243, and Liaoning University Youth Project No. LS2014L014.
CR Aiswarya K., 2010, Proceedings of the 2010 Second International Conference on Computer Modeling and Simulation (ICCMS 2010), P409, DOI 10.1109/ICCMS.2010.310
   AlZubi S., 2011, IEEE INT S MEDICAL M, P619, DOI [DOI 10.1109/MEMEA.2011.5966667, 10.1109/MeMeA.2011.5966667]
   AlZubi S, 2012, INT C INN INF TECHN
   Astola J., 1997, Fundamentals of nonlinear digital filtering, DOI DOI 10.1201/9781003067832
   BUADES A, 2008, CVPR 2005, V2, P60
   Buades A, 2011, COMMUN ACM, V54, P109, DOI 10.1145/1941487.1941513
   Dabov K, 2013, IEEE T IMAGE PROCESS, V22, P119, DOI [10.1109/TIP.2012.2210725, DOI 10.1109/TIP.2012.2210725]
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dawood H, 2014, PATTERN RECOGN LETT, V49, P121, DOI 10.1016/j.patrec.2014.06.016
   Delon J, 2016, IMAGE PROCESS ON LIN, V6, P130, DOI 10.5201/ipol.2016.161
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   Erkan U, 2018, TURK J ELECTR ENG CO, V26, P162, DOI 10.3906/elk-1705-256
   Esakkirajan S, 2011, IEEE SIGNAL PROC LET, V18, P287, DOI 10.1109/LSP.2011.2122333
   Fu B, 2015, NEUROCOMPUTING, V169, P119, DOI 10.1016/j.neucom.2014.11.094
   HWANG H, 1995, IEEE T IMAGE PROCESS, V4, P499, DOI 10.1109/83.370679
   JAFAR IF, 1931, TIP, V22, P1223, DOI DOI 10.1109/TIP.2012.2228496
   Nair MS, 2012, SIGNAL IMAGE VIDEO P, V6, P579, DOI 10.1007/s11760-010-0186-4
   Nasri M, 2013, SCI IRAN, V20, P760, DOI 10.1016/j.scient.2013.01.001
   Ng PE, 2006, IEEE T IMAGE PROCESS, V15, P1506, DOI 10.1109/TIP.2005.871129
   Novoselac V, 2015, ADAPTIVE CTR WEIGHTE
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   TOH KKV, 1961, ELECTRON, V54, P1956, DOI DOI 10.1109/TCE.2008.4711258
   Varghese J, 2015, ARAB J SCI ENG, V40, P3233, DOI 10.1007/s13369-015-1799-2
   Vasanth K, 2013, P COMPUT SCI, V54, P595
   Wang W, 2011, IEEE SIGNAL PROC LET, V18, P551, DOI 10.1109/LSP.2011.2162583
   Wang Y, 2018, IEEE T NEURAL NETWOR
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Zhang SQ, 2002, IEEE SIGNAL PROC LET, V9, P360, DOI 10.1109/LSP.2002.805310
   Zhang W., 2016, P INT JOINT C ART IN, P2153
   Zhang XM, 2013, SIGNAL PROCESS, V93, P517, DOI 10.1016/j.sigpro.2012.08.022
   Zhou YY, 2012, IET IMAGE PROCESS, V6, P976, DOI 10.1049/iet-ipr.2011.0312
NR 32
TC 27
Z9 28
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12043
EP 12053
DI 10.1007/s11042-018-6732-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900043
DA 2024-07-18
ER

PT J
AU Ghosh, S
   Chandra, A
   Mudi, RK
AF Ghosh, Sukanta
   Chandra, Abhijit
   Mudi, Rajani K.
TI A novel fuzzy pixel intensity correlation based segmentation algorithm
   for early detection of Alzheimer's disease
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Alzheimer's disease (AD); Edge detection; Fuzzy connectedness algorithm;
   Fuzzy inference system; MRI scans
ID EDGE-DETECTION; DESIGN
AB Alzheimer's disease (AD) is considered to be one of the most fatal neurological disorders and is identified as significant tissue loss in the hippocampus region of human brain. This paper presents a fuzzy based novel segmentation algorithm for brain MRI images. A structuring element for opening of gray scale converted test MRI scans has been proposed in this regard. It effectively enhances the contrast of lateral ventricle region of brain which contains crucial information for mild cognitive impairment (MCI). Proposed rule-base of higher order fuzzy system dynamically chooses edge pixels and accordingly predicts the next probable edge pixel. Proposed fuzzy inference system is inspired by fuzzy connectedness algorithm and converts probable edge pixels into edge pixels depending on the intensity correlation between ordered pixels in support of rule-base and assembles it into an edge contour. Our proposition is finally tested over several ADNI brain images of different subject and orientation. Experimental results identify a promising improvement in detection of object boundaries and enhance contrast both qualitatively and quantitatively.
C1 [Ghosh, Sukanta; Chandra, Abhijit; Mudi, Rajani K.] Jadavpur Univ, Dept Instrumentat & Elect Engn, Kolkata, W Bengal, India.
C3 Jadavpur University
RP Ghosh, S (corresponding author), Jadavpur Univ, Dept Instrumentat & Elect Engn, Kolkata, W Bengal, India.
EM sukantarpe@gmail.com; abhijit922@yahoo.co.in; rkmudi@yahoo.com
OI GHOSH, SUKANTA/0000-0002-4284-8718
FU Visvesvaraya PhD Scheme for Electronics & IT under Ministry of
   Electronics and Information Technology, Government of India
FX Authors would like to thank Visvesvaraya PhD Scheme for Electronics & IT
   under Ministry of Electronics and Information Technology, Government of
   India for extending necessary financial support to carry out this
   research work. We thank radiologist Dr. Tapan K. Biswas for providing
   public large scale brain MRI data set as a part of this research work.
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   Ali ES, 2011, APPL SOFT COMPUT, V11, P4883, DOI [10.1016/j.asoc.2011.06.011, DOI 10.1016/J.ASOC.2011.06.011]
   Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448
   Becerikli Y, 2005, LECT NOTES COMPUT SC, V3512, P943
   BOVIK AC, 2009, THE ESSENTIAL GUIDE, V498, P500
   Butkiewicz BS, FUZZY APPROACH CORRE
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chandra A, 2017, MULTIMED TOOLS APPL, V76, P23957, DOI 10.1007/s11042-016-4149-9
   Chen SM, 2013, IEEE T FUZZY SYST, V21, P412, DOI 10.1109/TFUZZ.2012.2226942
   Chen Y, 2016, IEEE T IMAGE PROCESS, V25, P988, DOI 10.1109/TIP.2015.2496279
   Deng Y, 2017, IEEE T FUZZY SYST, V25, P1006, DOI 10.1109/TFUZZ.2016.2574915
   Ferreira D, 2017, SCI REP-UK, V7, DOI 10.1038/srep46263
   Fu WL, 2014, IEEE T CYBERNETICS, V44, P1459, DOI 10.1109/TCYB.2013.2286611
   Gao WS, 2010, INT CONF COMP SCI, P67, DOI 10.1109/ICCSIT.2010.5563693
   Gonzalez RC., Digital image processing third edition Pearson international edition prepared by Pearson Education
   Hsu CH, 2013, IEEE T FUZZY SYST, V21, P100, DOI 10.1109/TFUZZ.2012.2202665
   Kong YY, 2015, IEEE SIGNAL PROC LET, V22, P573, DOI 10.1109/LSP.2014.2364612
   Li XJ, 2013, IEEE T FUZZY SYST, V21, P385, DOI 10.1109/TFUZZ.2012.2212908
   Lopez-Molina C, 2010, PATTERN RECOGN, V43, P3730, DOI 10.1016/j.patcog.2010.05.035
   Melin P, 2014, IEEE T FUZZY SYST, V22, P1515, DOI 10.1109/TFUZZ.2013.2297159
   Noh Y, 2014, NEUROLOGY, V83, P1936, DOI 10.1212/WNL.0000000000001003
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   Salinas RA, 1996, IEEE T IND ELECTRON, V43, P355, DOI 10.1109/41.499807
   Setayesh M., 2012, 2012 IEEE C EVOLUTIO, P1, DOI DOI 10.1109/CEC.2012.6256104
   Setayesh M, 2013, INFORM SCIENCES, V246, P28, DOI 10.1016/j.ins.2013.05.031
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sun GY, 2007, PATTERN RECOGN, V40, P2766, DOI 10.1016/j.patcog.2007.01.006
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   Verma OP, 2017, IEEE T FUZZY SYST, V25, P114, DOI 10.1109/TFUZZ.2016.2551289
   Zhiping Chen, 2017, 2017 International Conference on Industrial Informatics - Computing Technology, Intelligent Technology, Industrial Information Integration (ICIICII). Proceedings, P5, DOI 10.1109/ICIICII.2017.27
   Zhou HB, 2013, IEEE T FUZZY SYST, V21, P447, DOI 10.1109/TFUZZ.2012.2226891
NR 33
TC 7
Z9 7
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 12465
EP 12489
DI 10.1007/s11042-018-6773-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900062
DA 2024-07-18
ER

PT J
AU Mary, NAB
   Dharma, D
AF Mary, N. Ani Brown
   Dharma, Dejey
TI A novel framework for real-time diseased coral reef image classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Classification; Feature extraction; Feature descriptor; Classifiers;
   HSV; RGB
ID LOCAL BINARY PATTERN; FEATURE DESCRIPTOR
AB The new challenge in image processing is in processing submarine coral reef images. The coral reef disease classification from such submarine coral reef images has become an important research activity that helps marine biologist. An automated system is required to extract texture features so as to classify coral reef diseases from captured images. The proposed framework encompasses an efficient feature descriptor that classifies different submarine images of coral reef with diseases. The proposed framework employs most excellent image processing and machine learning techniques for classification. At first, the diseased coral reef images are segmented using Gradient-based sobel operator. Then, texture features are extracted from HSV color space using the proposed Mean Direct Code Pattern (MDCP) and from RGB space using proposed Diagonal Direction Value Pattern (DDVP). The proposed feature descriptors provide codes considering elements in diagonal directions. The resultant feature vector is then given as input to various classifiers to classify the diseased images. The efficiency of the proposed framework is demonstrated using real-time coral reef diseased images. The performance of various classifiers such as Decision Tree (DT), Classification And Regression Tree (CART), C4.5, Adaboost, Rotation Forest (RoF), Random Forest (RF), SVM, KNN, CNN, PCCNN and Naive Bayes is analysed. Performance results of the proposed framework for diseased coral reef image classification show that the framework outperforms recent works where feature descriptors such as LBP, LDP, CLBP, ILDP, DLBP, LTxXORP, CS-LBP, RLTP, Z circle plus TZLBP, OC-LBP, LTrP and PRI-CoLBP are used. Classification results are validated by marine biologists.
C1 [Mary, N. Ani Brown; Dharma, Dejey] Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli 627007, Tirunelveli Reg, India.
C3 Anna University; Anna University of Technology Tirunelveli
RP Mary, NAB (corresponding author), Anna Univ, Dept Comp Sci & Engn, Reg Campus, Tirunelveli 627007, Tirunelveli Reg, India.
EM anibrownvimal@gmail.com
RI Mary, Ani Brown/AAZ-5896-2020
OI Dharma, Dejey/0000-0002-5173-4878
CR [Anonymous], 2001, P 18 INT C MACH LEAR
   [Anonymous], P 13 AAAI C ART INT
   [Anonymous], 2008, OCEANS
   Bala A, 2016, ENG SCI TECHNOL, V19, P101, DOI 10.1016/j.jestch.2015.06.008
   Beijbom O, 2012, P IEEE C COMP VIS PA, P16
   Bourne DG, 2014, CORAL REEFS
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Grover Nidhi., 2014, International Journal of Engineering Research, V3, P177, DOI [DOI 10.17950/ijer, DOI 10.17950/IJER/V3S3/310]
   Guo Zhenhua, 2010, IEEE T IMAGE P, V19
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Kavzoglu T, 2015, REMOTE SENS LETT, V6, P834, DOI 10.1080/2150704X.2015.1084550
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lin SW, 2012, SOFT COMPUT, V16, P63, DOI 10.1007/s00500-011-0734-z
   Liu Y., 2016, 2016 3 INT C ARTIFIC, V2016, P2576
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liuy Y, 2015, ACTION2ACTIVITY RECO
   Mantovani RGHorvathT, 2016, 5 BRAZ C INT SYST
   Marcos MSA, 2008, ENVIRON MONIT ASSESS, V145, P177, DOI 10.1007/s10661-007-0027-2
   Mary NAB, 2018, MULTIMED TOOLS APPL, V77, P31545, DOI 10.1007/s11042-018-6148-5
   Mary NAB, 2018, WIRELESS PERS COMMUN, V98, P2427, DOI 10.1007/s11277-017-4981-x
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Moberg F, 1999, ECOL ECON, V29, P215, DOI 10.1016/S0921-8009(99)00009-9
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perez JF, 2015, 6 LAT AM C NETW EL M
   Pollock FJ, 2011, PLOS PATHOG, V7, DOI 10.1371/journal.ppat.1002183
   Qi X, 2013, PAIRWISE ROTATION IN
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Shakoor MH, 2018, MULTIMED TOOLS APPL, V77, P2561, DOI 10.1007/s11042-017-4394-6
   Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
   Spalding MD, 1997, CORAL REEFS, V16, P225, DOI 10.1007/s003380050078
   Stokes MD, 2009, LIMNOL OCEANOGR-METH, V7, P157, DOI 10.4319/lom.2009.7.157
   Villon S., 2016, 17 INT C ADV CONC IN
   Xu Y, 2011, TRACKING GENERIC HUM
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   ZHU C, 1963, ELSEVIER PATTERN REC, V46, P1949, DOI DOI 10.1016/j.patcog.2013.01.003
NR 38
TC 12
Z9 12
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2019
VL 78
IS 9
BP 11387
EP 11425
DI 10.1007/s11042-018-6673-2
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX8MB
UT WOS:000467658900014
DA 2024-07-18
ER

PT J
AU Akhtarkavan, E
   Majidi, B
   Manzuri, MT
AF Akhtarkavan, Ehsan
   Majidi, Babak
   Manzuri, Mohammad Taghi
TI Secure communication and archiving of low altitude remote sensing data
   using high capacity fragile data hiding
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fragile data hiding; Watermarking; Remote sensing; Security
ID DESCRIPTION VECTOR QUANTIZATION; BIG DATA; WATERMARKING; PROTECTION;
   IMAGES; ARCHITECTURE; ALGORITHM; TRACKING
AB Fragile data hiding has been extensively used for secure transmission of the sensitive data using cover images, audios and videos. In the past decade, increasingly the remote sensing applications require transmission and archiving of large number of aerial images and videos. Storage and processing of remote sensing data in the public cloud computing and storage platforms, with servers outside the control of the data owners, requires sufficient attention to persevering the privacy of the data. Furthermore, in the past few years the applications of drones and unmanned aerial vehicles demand algorithms designed especially for low altitude remote sensing data. In this paper, a novel fragile data hiding algorithm for secure transmission and archiving of sensitive data in low altitude aerial videos is presented. The proposed method incorporates Integer-to-Integer discrete wavelet transform and lattice vector quantization to present a high capacity data hiding algorithm. The fragility of the proposed algorithm results in the loss of the embedded authentication credential by any tampering attempt. The experimental results show that the proposed fragile data hiding algorithm is capable of hiding significantly higher amount of data in the aerial videos compared to other existing algorithms while keeping the perceptual quality of the cover media in an acceptable range.
C1 [Akhtarkavan, Ehsan; Majidi, Babak] Khatam Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.
   [Akhtarkavan, Ehsan] PIAIS, Tehran, Iran.
   [Manzuri, Mohammad Taghi] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
C3 Sharif University of Technology
RP Akhtarkavan, E (corresponding author), Khatam Univ, Fac Engn, Dept Comp Engn, Tehran, Iran.; Akhtarkavan, E (corresponding author), PIAIS, Tehran, Iran.
EM e.akhtarkavan@khatam.ac.ir
RI Akhtarkavan, Ehsan/AAR-5007-2021; Majidi, Babak/AAB-2365-2019
OI Akhtarkavan, Ehsan/0000-0003-2468-8359; Majidi,
   Babak/0000-0001-6309-6407; Manzuri Shalmani, Mohammad
   Taghi/0000-0002-3451-0338
CR Ahuja R, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION & AUTOMATION (ICCCA), P1048, DOI 10.1109/CCAA.2015.7148559
   Akhtarkavan E, 2012, IEEE T IMAGE PROCESS, V21, P653, DOI 10.1109/TIP.2011.2164419
   Akhtarkavan E, 2010, IEICE ELECTRON EXPR, V7, P1233, DOI 10.1587/elex.7.1233
   [Anonymous], 1993, 244 U SO CAL DEP EL
   Quirita VAA, 2017, IEEE J-STARS, V10, P409, DOI 10.1109/JSTARS.2016.2603120
   Bao AM, 2017, ECOL INDIC, V74, P261, DOI 10.1016/j.ecolind.2016.11.007
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Conway JH, 1999, CAN J MATH, V51, P1300, DOI 10.4153/CJM-1999-059-5
   Goyal VK, 2002, IEEE T INFORM THEORY, V48, P781, DOI 10.1109/18.986048
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hong W, 2009, J SYST SOFTWARE, V82, P1833, DOI 10.1016/j.jss.2009.05.051
   Hsu PH, 2016, ROBUST DIGITAL WATER
   Hwang HH, 2010, PROCEEDINGS OF THE 21ST PAN-ASIAN CONGRESS OF SPORTS AND PHYSICAL EDUCATION, VOL 4, P12
   Jiang L, 2015, IEEE J-STARS, V8, P2232, DOI 10.1109/JSTARS.2015.2412691
   Jiang L, 2013, INT GEOSCI REMOTE SE, P2577, DOI 10.1109/IGARSS.2013.6723349
   Kiho Cho, 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P122, DOI 10.1109/IIH-MSP.2012.35
   Li LL, 2012, ADV MATER RES-SWITZ, V433-440, P2504, DOI 10.4028/www.scientific.net/AMR.433-440.2504
   Li P, 2016, IEEE CLOUD COMPUT, V3, P34, DOI 10.1109/MCC.2016.107
   Li XL, 2015, IEEE T INF FOREN SEC, V10, P2016, DOI 10.1109/TIFS.2015.2444354
   Li XL, 2013, IEEE T IMAGE PROCESS, V22, P2181, DOI 10.1109/TIP.2013.2246179
   Liu S, 2015, INT J DISTRIB SENSOR
   Majidi B, 2009, MACH VISION APPL, V20, P23, DOI 10.1007/s00138-007-0102-2
   Majidi B., 2007, LAND COVER BOUNDARY, P311
   Majidi B., 2005, Digital Image Computing: Techniques and Applications, P65, DOI DOI 10.1109/DICTA.2005.68
   Majidi B, 2014, DIGIT SIGNAL PROCESS, V26, P127, DOI 10.1016/j.dsp.2013.12.006
   Masoumi M, 2013, AEU-INT J ELECTRON C, V67, P528, DOI 10.1016/j.aeue.2012.11.009
   Moguel E, 2015, IEEE J-STARS, V8, P4714, DOI 10.1109/JSTARS.2015.2415583
   Mstafa RJ, 2016, MULTIMED TOOLS APPL, V75, P10311, DOI 10.1007/s11042-015-3060-0
   Natgunanathan I, 2016, IEEE ACCESS, V4, P880, DOI 10.1109/ACCESS.2016.2535120
   Olaguer EP, 2017, ATMOS ENVIRON, V150, P220, DOI 10.1016/j.atmosenv.2016.11.058
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Poursanidis Dimitris, 2017, Remote Sensing Applications: Society and Environment, V6, P25, DOI 10.1016/j.rsase.2017.02.001
   Rathje EM, 2016, SOIL DYN EARTHQ ENG, V91, P304, DOI 10.1016/j.soildyn.2016.09.016
   Rathore MMU, 2015, IEEE J-STARS, V8, P4610, DOI 10.1109/JSTARS.2015.2424683
   Romero-Trigueros C, 2017, AGR WATER MANAGE, V183, P60, DOI 10.1016/j.agwat.2016.09.014
   Sabri AQM, 2016, METADATA HIDING UAV, P1
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Shirafkan MH, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED ENGINEERING AND INNOVATION (KBEI), P177, DOI 10.1109/KBEI.2015.7436041
   Stek TD, 2016, J CULT HERIT, V22, P1066, DOI 10.1016/j.culher.2016.06.006
   Thanh TM, 2014, AEU-INT J ELECTRON C, V68, P1007, DOI 10.1016/j.aeue.2014.05.004
   Vaishampayan VA, 2001, IEEE T INFORM THEORY, V47, P1718, DOI 10.1109/18.930913
   Wang C, 2010, IEEE IMAGE PROC, P3673, DOI 10.1109/ICIP.2010.5652508
   Wang LZ, 2014, IEEE T EMERG TOP COM, V2, P324, DOI 10.1109/TETC.2014.2356499
   [朱长青 Zhu Changqing], 2010, [测绘通报, Bulletin of Surveying and Mapping], P1
   Zope-Chaudhari S, 2015, IEEE J-STARS, V8, P5388, DOI 10.1109/JSTARS.2015.2475169
NR 47
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10325
EP 10351
DI 10.1007/s11042-018-6607-z
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400037
DA 2024-07-18
ER

PT J
AU Guan, H
   Cheng, BZ
AF Guan, Hao
   Cheng, Baozhong
TI Taking full advantage of convolutional network for robust visual
   tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Convolutional network; Correlation classifier; Online
   learning
ID OBJECT
AB Model-free visual object tracking has always been a challenging task in computer vision and multimedia analysis. How to alleviate the stability-plasticity dilemma plays a key role in making a robust tracker. In this paper, we propose a novel tracking framework which leverages convolutional network to tackle this fundamental problem. First, we construct a two-stream convolutional network which is pre-trained on a large number of sequential images. During tracking, hierarchical features of target are extracted by the network and an adaptive correlation classifier is trained on them to estimate the position change. In addition, the fully-connected layer with frozen weights of the network is deliberately designed as a self-correction agent which can re-detect the target in case of tracking failure. Through taking full advantage of the network by using both of its feature learning and fully-connected parts, the proposed tracking system can make a good balance between stability and plasticity. Experiments on large scale benchmark video sequences have shown that the proposed tracker outperforms many state-of-the-art tracking methods both in precision and robustness.
C1 [Guan, Hao; Cheng, Baozhong] Beijing Univ Posts & Telecommun, Sch Software Engn, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Guan, H (corresponding author), Beijing Univ Posts & Telecommun, Sch Software Engn, Beijing, Peoples R China.
EM guanhao@bupt.edu.cn
RI Chen, John/GPW-8839-2022
FU Fundamental Research Funds for the Central Universities [500417061]
FX This work was supported by The Fundamental Research Funds for the
   Central Universities (Grant No. 500417061).
CR [Anonymous], 2014, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2013.230
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   Gao CX, 2017, IEEE T CIRC SYST VID, V27, P300, DOI 10.1109/TCSVT.2015.2513700
   Gundogdu E, 2018, IEEE T IMAGE PROCESS, V27, P2526, DOI 10.1109/TIP.2018.2806280
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hu JL, 2016, IEEE T CIRC SYST VID, V26, P2056, DOI 10.1109/TCSVT.2015.2477936
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar B.V. K. Vijaya., 2005, Correlation Pattern Recognition
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Qi YK, 2016, PROC CVPR IEEE, P4303, DOI 10.1109/CVPR.2016.466
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sui Y, 2018, IEEE T CYBERNETICS, V48, P1290, DOI 10.1109/TCYB.2017.2690860
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Tao DP, 2016, IEEE T NEUR NET LEAR, V27, P1122, DOI 10.1109/TNNLS.2015.2461554
   Tao DP, 2016, IEEE T CYBERNETICS, V46, P756, DOI 10.1109/TCYB.2015.2414920
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang XH, 2017, INFORM SCIENCES, V385, P338, DOI 10.1016/j.ins.2017.01.011
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
NR 37
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 11011
EP 11025
DI 10.1007/s11042-018-6679-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400065
DA 2024-07-18
ER

PT J
AU Lagunas, M
   Garces, E
   Gutierrez, D
AF Lagunas, Manuel
   Garces, Elena
   Gutierrez, Diego
TI Learning icons appearance similarity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Iconography; Illustration; Visualization; Appearance similarity; Machine
   learning
ID IMAGE RETRIEVAL; RECOGNITION
AB Selecting an optimal set of icons is a crucial step in the pipeline of visual design to structure and navigate through content. However, designing the icons sets is usually a difficult task for which expert knowledge is required. In this work, to ease the process of icon set selection to the users, we propose a similarity metric which captures the properties of style and visual identity. We train a Siamese Neural Network with an on-line dataset of icons organized in visually coherent collections that are used to adaptively sample training data and optimize the training process. As the dataset contains noise, we further collect human-rated information on the perception of icon's similarity which will be used for evaluating and testing the proposed model. We present several results and applications based on searches, kernel visualizations and optimized set proposals that can be helpful for designers and non-expert users while exploring large collections of icons.
C1 [Lagunas, Manuel; Gutierrez, Diego] Univ Zaragoza, I3A, Zaragoza, Spain.
   [Garces, Elena] Technicolor, 975 Ave Champs Blancs, F-35576 Cesson Sevigne, France.
C3 University of Zaragoza; Technicolor SA
RP Lagunas, M (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM mlagunas@unizar.es
RI Lagunas, Manuel/KQG-3800-2024
OI Lagunas, Manuel/0000-0003-0838-1795; Garces, Elena/0000-0003-3509-8485;
   Gutierrez Perez, Diego/0000-0002-7503-7022
FU European Research Council (ERC) under the European Union [682080]
FX We want to thank the anonymous reviewers and Adrian Jarabo for their
   insightful comments on the manuscript. This project has received funding
   from the European Research Council (ERC) under the European Union's
   Horizon 2020 research and innovation programme (CHAMELEON project, grant
   agreement No 682080).
CR [Anonymous], P C COMP VIS PATT RE
   [Anonymous], 2015, P BRIT MACH VIS
   [Anonymous], ACM TOG
   [Anonymous], 2014, WEAKLY SUPERVISED LE
   [Anonymous], LOGO DESIGN LOVE GUI
   [Anonymous], [No title captured]
   [Anonymous], NIPS P
   [Anonymous], ACM T GRAPH P SIGGRA
   [Anonymous], [No title captured]
   [Anonymous], 2016, P JOINT S COMP AESTH
   [Anonymous], ARXIV151205193 CORR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], PROTOPAPADAKIS E DEE
   [Anonymous], 2015, ARXIV150203167 CORR
   [Anonymous], ARXIV160302003 CORR
   [Anonymous], 2016, ICON SET SELECTION V
   [Anonymous], PAC GRAPH
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Barnard M., 2013, Graphic design as communication
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bernstein GL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766980
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Crandall DJ, 2006, LECT NOTES COMPUT SC, V3951, P16
   Demiralp C, 2014, IEEE T VIS COMPUT GR, V20, P1933, DOI 10.1109/TVCG.2014.2346978
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P656, DOI 10.1109/TCSVT.2004.826752
   El-Naqa I, 2004, IEEE T MED IMAGING, V23, P1233, DOI 10.1109/TMI.2004.834601
   Garces Elena, 2014, ACM Transactions on Graphics, V33, DOI 10.1145/2601097.2601131
   Garces E, 2017, MULTIMED TOOLS APPL, V76, P13067, DOI 10.1007/s11042-016-3702-x
   Glorot X., 2010, P INT C ART INT STAT, P249
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gramazio CC, 2017, IEEE T VIS COMPUT GR, V23, P521, DOI 10.1109/TVCG.2016.2598918
   Horton W., 1994, ICON BOOK VISUAL SYM
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   King DB, 2015, ACS SYM SER, V1214, P1
   Kleiman Y, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818116
   Kwan KC, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980234
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lewis JP, 2004, ACM T GRAPHIC, V23, P416, DOI 10.1145/1015706.1015739
   Liu TQ, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766898
   Lun ZL, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766929
   Lupton E., 2015, GRAPHIC DESIGN NEW B
   Lupton Ellen., 2004, Thinking with type: a critical guide for designers, writers, editors, students
   O'Donovan P, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601110
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Setlur V, 2005, COMPUT GRAPH FORUM, V24, P647, DOI 10.1111/j.1467-8659.2005.00889.x
   Setlur V, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P541, DOI 10.1145/2556288.2557408
   Shugrina M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073690
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Simonyan K., 2014, 14091556 ARXIV
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wu P., 2013, P 21 ACM INT C MULT, P153, DOI DOI 10.1145/2502081.2502112
   Xia H, 2014, IEEE T PATTERN ANAL, V36, P536, DOI 10.1109/TPAMI.2013.149
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 59
TC 9
Z9 10
U1 3
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 8
BP 10733
EP 10751
DI 10.1007/s11042-018-6628-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HX6DX
UT WOS:000467495400054
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Xue, YM
   Yang, LR
   Wen, J
   Niu, SZ
   Zhong, P
AF Xue, Yiming
   Yang, Liran
   Wen, Juan
   Niu, Shaozhang
   Zhong, Ping
TI A subspace learning-based method for JPEG mismatched steganalysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mismatched steganalysis; JPEG images; Subspace learning; Low-rank and
   sparse constraints
ID KERNEL
AB The prevailing steganalysis detector trained by a source is used to recognize images from another different source, the detection accuracy typically drops owing to the mismatch between the two sources. In contrast to previous mismatched steganalysis methods, in this paper, we develop an unsupervised subspace learning-based method which has some differences from the ones common used in mismatched steganalysis. The proposed method employs low-rank and sparse constraints on the reconstruction coefficient matrix to maintain the global and local structures of the data. In this way, we can obtain new feature representations so that the feature distributions of the training and test data are close. We further promote the performance of the proposed method by employing the l(2,1)-norm on the error matrix. Comprehensive experiments on the JPEG mismatched steganalysis are conducted, and the experimental results show that the proposed method can improve the detection accuracy.
C1 [Xue, Yiming; Yang, Liran; Wen, Juan] China Agr Univ, Coll Informat & Elect Engn, Beijing 100083, Peoples R China.
   [Niu, Shaozhang] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
   [Zhong, Ping] China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
C3 China Agricultural University; Beijing University of Posts &
   Telecommunications; China Agricultural University
RP Zhong, P (corresponding author), China Agr Univ, Coll Sci, Beijing 100083, Peoples R China.
EM zping@cau.edu.cn
RI Wen, Juan/ADU-0902-2022
FU National Natural Science Foundation of China [61872368, 61802410,
   U1536121, 11171346]
FX The work is supported by the National Natural Science Foundation of
   China (Grant No. 61872368, No. 61802410, No. U1536121, No.11171346). The
   authors also gratefully acknowledge the helpful comments and suggestions
   of the reviewers, which have improved the presentation.
CR An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   [Anonymous], 2012, IEEE T INF FORENSICS, DOI DOI 10.1109/TIFS.2011.2175919
   [Anonymous], INT SOC OPT PHOTON
   [Anonymous], ACM WORKSH INF HID M
   [Anonymous], 2012, P MULTIMEDIA SECURIT
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2016, TIP, DOI DOI 10.1109/TIP.2015.2510498
   [Anonymous], INT SOC OPT PHOTON
   [Anonymous], 2011, INT WORKSHOP INF HID
   Blitzer J., 2006, PROC C EMPIRICAL MET, P120, DOI DOI 10.3115/1610075.1610094
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Denemark T, 2016, IEEE T INF FOREN SEC, V11, P1747, DOI 10.1109/TIFS.2016.2555281
   Feng CY, 2017, IEEE IMAGE PROC, P500, DOI 10.1109/ICIP.2017.8296331
   Fridrich J, 2004, LECT NOTES COMPUT SC, V3200, P67
   Fridrich Jessica, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P102, DOI 10.1007/978-3-642-24178-9_8
   Fridrich J, 2012, IEEE T INF FOREN SEC, V7, P868, DOI 10.1109/TIFS.2012.2190402
   Fridrich J, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P3
   Goljan M., 2015, 2015 National Conference on Parallel Computing Technologies (PARCOMPTECH), P185
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Guo L, 2013, P IEEE INT WORKSH IN, P169
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Jhuo IH, 2012, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2012.6247924
   Johnson NF, 2000, ART H COMP SCI LIBR, P43
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2143, DOI 10.1007/s11042-013-1832-y
   KODOVSKY J, 2009, PROCEEDINGS OF THE 1, V11, P63
   Kodovsky Jan, 2012, P SPIE MEDIA WATERMA, V8303, P1
   Kong XW, 2016, NEUROCOMPUTING, V214, P458, DOI 10.1016/j.neucom.2016.06.037
   Li XF, 2013, IEEE IMAGE PROC, P4432, DOI 10.1109/ICIP.2013.6738913
   LIU G, 2013, TPAMI, V35, P171, DOI DOI 10.1109/TPAMI.2012.88
   Liu YX, 2015, NEUROCOMPUTING, V151, P1076, DOI 10.1016/j.neucom.2014.03.089
   Luo XY, 2016, MULTIMED TOOLS APPL, V75, P13557, DOI 10.1007/s11042-015-2759-2
   Ma YY, 2019, IEEE T CIRC SYST VID, V29, P336, DOI 10.1109/TCSVT.2018.2799243
   Modaghegh H, 2015, MULTIMED TOOLS APPL, V74, P5825, DOI 10.1007/s11042-014-1890-9
   Mukherjee S, 2018, MULTIMED TOOLS APPL, V3, P1
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Pevny T, 2008, MM&SEC'08: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2008, P167, DOI 10.1145/1411328.1411357
   Rabee AM, 2018, MULTIMED TOOLS APPL, V77, P7763, DOI 10.1007/s11042-017-4676-z
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Wang HQ, 2004, COMMUN ACM, V47, P76, DOI 10.1145/1022594.1022597
   Wang W, 2011, P INT COMP SOFTW APP, P541, DOI 10.1109/COMPSAC.2011.75
   XIA C, 2017, PROCEEDINGS OF THE 5, V5, P55, DOI DOI 10.1109/CSE-EUC.2017.20
   Yang JF, 2009, SIAM J IMAGING SCI, V2, P569, DOI 10.1137/080730421
   Yang Y, 2018, MULTIMED TOOLS APPL, V454, P1
   Zhang Y, 2018, SIGNAL PROCESS, V146, P99, DOI 10.1016/j.sigpro.2018.01.011
   Zhang Y, 2017, MULTIMED TOOLS APPL, V76, P3649, DOI 10.1007/s11042-016-3914-0
NR 49
TC 4
Z9 4
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2019
VL 78
IS 7
BP 8151
EP 8166
DI 10.1007/s11042-018-6719-5
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HW0OW
UT WOS:000466381800015
DA 2024-07-18
ER

PT J
AU Cai, B
   Ye, W
   Zhao, JH
AF Cai, Bo
   Ye, Wei
   Zhao, Jianhui
TI A dynamic texture based segmentation method for ultrasound images with
   Surfacelet, HMT and parallel computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic texture; Surfacelet transform; HMT model; Parallel computing;
   Ultrasound images
ID B-MODE; CLASSIFICATION; TRANSFORM; TRACKING; 2-D
AB To segment regions of interest (ROIs) from ultrasound images, one novel dynamic texture based algorithm is presented with surfacelet transform, hidden Markov tree (HMT) model and parallel computing. During surfacelet transform, the image sequence is decomposed by pyramid model, and the 3D signals with high frequency are decomposed by directional filter banks. During HMT modeling, distribution of coefficients is described with Gaussian mixture model (GMM), and relationship of scales is described with scale continuity model. From HMT parameters estimated through expectation maximization, the joint probability density is calculated and taken as feature value of image sequence. Then ROIs and non-ROIs in collected sample videos are used to train the support vector machine (SVM) classifier, which is employed to identify the divided 3D blocks from input video. To improve the computational efficiency, parallel computing is implemented with multi-processor CPU. Our algorithm has been compared with the existing texture based approaches, including gray level co-occurrence matrix (GLCM), local binary pattern (LBP), Wavelet, for ultrasound images, and the experimental results prove its advantages of processing noisy ultrasound images and segmenting higher accurate ROIs.
C1 [Cai, Bo; Ye, Wei; Zhao, Jianhui] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
C3 Wuhan University
RP Zhao, JH (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Hubei, Peoples R China.
EM jianhuizhao@whu.edu.cn
OI Cai, Bo/0000-0001-5261-0191; Zhao, Jianhui/0000-0001-5803-2564
FU National Basic Research Program of China (973 Program) [2011CB707904]
FX This work was supported by National Basic Research Program of China (973
   Program, No. 2011CB707904).
CR Ackermann D, 2016, IEEE T ULTRASON FERR, V63, P72, DOI 10.1109/TUFFC.2015.2500266
   Akbari H, 2012, MED PHYS, V39, P2972, DOI 10.1118/1.4709607
   Ban ZH, 2018, IEEE T IMAGE PROCESS, V27, P4105, DOI 10.1109/TIP.2018.2836306
   Cary TW, 2014, MED PHYS, V41, DOI 10.1118/1.4862508
   Ding JR, 2012, J DIGIT IMAGING, V25, P620, DOI 10.1007/s10278-012-9499-x
   Faisal A, 2015, IEEE T MED IMAGING, V34, P2162, DOI 10.1109/TMI.2015.2425144
   Gómez W, 2012, IEEE T MED IMAGING, V31, P1889, DOI 10.1109/TMI.2012.2206398
   Hajati F, 2017, IEEE T HUM-MACH SYST, V47, P970, DOI 10.1109/THMS.2017.2681425
   Hassan M, 2014, COMPUT METH PROG BIO, V113, P593, DOI 10.1016/j.cmpb.2013.10.012
   Krishnan KR, 2017, IET IMAGE PROCESS, V11, P530, DOI 10.1049/iet-ipr.2016.1072
   Liao CH, 2016, IEEE T COMPUT AID D, V35, P971, DOI 10.1109/TCAD.2015.2481868
   Liu Y, 2012, J DIGIT IMAGING, V25, P580, DOI 10.1007/s10278-011-9450-6
   Loizou CP, 2017, IEEE J TRANSL ENG HE, V5, DOI 10.1109/JTEHM.2017.2728662
   Lu YM, 2007, IEEE T IMAGE PROCESS, V16, P918, DOI 10.1109/TIP.2007.891785
   Machucho-Cadena R, 2014, PATTERN RECOGN, V47, P1968, DOI 10.1016/j.patcog.2013.10.021
   Mahdavi SS, 2012, IEEE T MED IMAGING, V31, P2073, DOI 10.1109/TMI.2012.2209204
   Mendizabal-Ruiz EG, 2013, MED IMAGE ANAL, V17, P649, DOI 10.1016/j.media.2013.02.003
   Nguyen NQ, 2016, IEEE T MED IMAGING, V35, P98, DOI 10.1109/TMI.2015.2456982
   Pazinato DV, 2016, IEEE J BIOMED HEALTH, V20, P256, DOI 10.1109/JBHI.2014.2386796
   Pereyra M, 2012, IEEE T MED IMAGING, V31, P1509, DOI 10.1109/TMI.2012.2190617
   Ravichandran A, 2013, IEEE T PATTERN ANAL, V35, P342, DOI 10.1109/TPAMI.2012.83
   Rezaeifar B, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P396, DOI 10.1109/ICCKE.2017.8167911
   Rueda S, 2014, IEEE T MED IMAGING, V33, P797, DOI 10.1109/TMI.2013.2276943
   Shin J, 2017, IEEE T MED IMAGING, V36, P396, DOI 10.1109/TMI.2016.2610758
   Sridar P, 2017, IEEE J BIOMED HEALTH, V21, P1069, DOI 10.1109/JBHI.2016.2582175
   Tan T, 2013, IEEE T MED IMAGING, V32, P1698, DOI 10.1109/TMI.2013.2263389
   Tian XL, 2014, SIGNAL IMAGE VIDEO P, V8, P901, DOI 10.1007/s11760-012-0338-9
   Torbati N, 2014, COMPUT BIOL MED, V44, P76, DOI 10.1016/j.compbiomed.2013.10.029
   Tsiaparas NN, 2011, IEEE T INF TECHNOL B, V15, P130, DOI 10.1109/TITB.2010.2091511
   Xu XY, 2012, COMPUT MED IMAG GRAP, V36, P248, DOI 10.1016/j.compmedimag.2011.06.007
   Yang X, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/345968
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
   Zhou Y, 2013, MED IMAGE ANAL, V17, P892, DOI 10.1016/j.media.2013.05.009
NR 33
TC 3
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 5
BP 5381
EP 5401
DI 10.1007/s11042-018-6366-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HT7RW
UT WOS:000464763100018
DA 2024-07-18
ER

PT J
AU Yousefi, MHN
   Kavian, YS
   Mahmoudi, A
AF Yousefi, Mehdi Hadadian Nejad
   Kavian, Yousef S.
   Mahmoudi, Alimorad
TI RTMCH: real-time multichannel MAC for wireless video sensor networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multichannel; Channel allocation; WVSN; End-to-end delay; Real-time
   protocol; Transmission power control
ID TRANSMISSION POWER-CONTROL; AD HOC; PROTOCOL; ALGORITHM; TREE
AB Exclusive benefits gained by using the image and video sensors in Wireless Sensor Networks (WSNs), make the Wireless Video Sensor Networks (WVSNs), design and development of their structures, a trending topic. The main challenges of WSNs which are more critical in WVSNs are throughput and end-to-end delay. The radio transceivers recently used in WSN motes can work on different channels with very low switching time. Therefore, many multichannel protocols are proposed to improve the efficiency and throughput and decrease the packet drop rate of the network. Proposed algorithms rarely provide a particular solution to the end-to-end problem. Such delays are necessary parameters in real-time applications. In this paper a real-time multichannel protocol called RTMCH is suggested to address the end-to-end delay of a stream in WVSN. A flow-based channel assignment strategy is used for this purpose. Orthogonal channels are assigned to each flows based on many-to-one data-flow to minimize the contention and collision between different flows. Transmission power is a parameter that can be controlled to achieve desired link quality and to control link delay. Channel assignment problem aligns to a constrained optimization problem to make the specified end-to-end delay of each flow. A channel assignment and real-time packet forwarding scheme are then presented. Simulation results based on realistic channel and radio model shows that the RTMCH can efficiently use multiple channels and transmission power to meet specified end-to-end delay. The results also show better performance for RTMCH over a recent real-time protocol and basic multichannel schemes.
C1 [Yousefi, Mehdi Hadadian Nejad; Kavian, Yousef S.; Mahmoudi, Alimorad] Shahid Chamran Univ Ahvaz, Fac Engn, Ahvaz, Khouzestan, Iran.
C3 Shahid Chamran University of Ahvaz
RP Kavian, YS (corresponding author), Shahid Chamran Univ Ahvaz, Fac Engn, Ahvaz, Khouzestan, Iran.
EM y.s.kavian@scu.ac.ir
RI Mahmoudi, Alimorad/Q-6999-2019
OI Mahmoudi, Alimorad/0000-0002-4621-5117
FU Shahid Chamran University of Ahvaz [96/3/02/16670]
FX The paper was supported by Shahid Chamran University of Ahvaz under
   grant number 96/3/02/16670.
CR Ahmed AA, 2017, PERVASIVE MOB COMPUT, V40, P495, DOI 10.1016/j.pmcj.2017.01.010
   [Anonymous], 2011, IFIP WIREL DAYS WD
   [Anonymous], 2003, P 23 INT C DISTR COM
   Banerjee K, 2006, ASIA S PACIF DES AUT, P223, DOI 10.1109/ASPDAC.2006.1594686
   Chipara O, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P313
   Chipara O, 2006, INT WORKSH QUAL SERV, P83, DOI 10.1109/IWQOS.2006.250454
   Civelek M, 2017, IEEE SENS J, V17, P1116, DOI 10.1109/JSEN.2016.2638853
   Correia LHA, 2007, COMPUT NETW, V51, P4765, DOI 10.1016/j.comnet.2007.07.008
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Egea-López E, 2008, PERS UBIQUIT COMPUT, V12, P111, DOI 10.1007/s00779-006-0111-6
   Farag H, 2018, IEEE SENS J, V18, P2607, DOI 10.1109/JSEN.2018.2793946
   Fouad M.R., 2005, P 1 ACM INT WORKSHOP, P31
   Frankiewicz A, 2011, COMM COM INF SC, V160, P439
   Gomes RD, 2017, AD HOC NETW, V59, P116, DOI 10.1016/j.adhoc.2017.02.007
   Guo ZQ, 2013, IEEE SENS J, V13, P3605, DOI 10.1109/JSEN.2013.2272054
   Gupta P, 2000, IEEE T INFORM THEORY, V46, P388, DOI 10.1109/18.825799
   Incel ÖD, 2012, IEEE T MOBILE COMPUT, V11, P86, DOI 10.1109/TMC.2011.22
   Incel OD, 2011, AD HOC NETW, V9, P73, DOI 10.1016/j.adhoc.2010.05.003
   Jae-Hwan Chang, 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P22, DOI 10.1109/INFCOM.2000.832170
   Jiang DD, 2016, IEEE INTERNET THINGS, V3, P1437, DOI 10.1109/JIOT.2016.2613111
   Jiang DD, 2017, NEUROCOMPUTING, V220, P160, DOI 10.1016/j.neucom.2016.07.056
   Jiang DD, 2016, J COMMUN NETW-S KOR, V18, P713, DOI 10.1109/JCN.2016.000101
   Jiang DD, 2015, J SYST SOFTWARE, V104, P152, DOI 10.1016/j.jss.2015.03.006
   Kumar Pardeep, 2010, Proceedings of the 2010 IEEE 24th International Conference on Advanced Information Networking and Applications Workshops (WAINA 2010), P692, DOI 10.1109/WAINA.2010.139
   Kyasanur Pradeep., 2005, MobiCom '05: Proceedings of the 11th annual international conference on Mobile computing and networking, P43
   Le HK, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL SYMPOSIUM ON INFORMATION PROCESSING IN SENSOR NETWORKS, P31, DOI 10.1145/1236360.1236365
   Li YJ, 2009, IEEE T IND INFORM, V5, P113, DOI 10.1109/TII.2009.2017938
   LIN S, 2015, NETWORKS, V11, P1, DOI DOI 10.1145/2700272
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Park HW, 2010, IMMUNOL IMMUNE SYST, P1
   Prabh K. Shashi, 2011, 2011 International Conference on Networking, Sensing and Control (ICNSC 2011), P451, DOI 10.1109/ICNSC.2011.5874874
   Rehan W, 2017, J NETW COMPUT APPL, V95, P1, DOI 10.1016/j.jnca.2017.07.006
   RONEN D, 1984, NETWORKS, V14, P531, DOI 10.1002/net.3230140405
   Santi P, 2005, ACM COMPUT SURV, V37, P164, DOI 10.1145/1089733.1089736
   Seada K., 2004, P 2 INT C EMBEDDED N, P108
   Singh BK, 2009, INT CONF ELECTRO INF, P336
   Srinivasan K, 2006, P 3 WORK EMB NETW SE
   Stankovic JA, 2003, P IEEE, V91, P1002, DOI 10.1109/JPROC.2003.814620
   Wang XR, 2011, ACM T SENSOR NETWORK, V8, DOI 10.1145/1993042.1993044
   Wu Y, 2008, IEEE INFOCOM SER, P1013
   Xiao L, 2003, APCC 2003: 9TH ASIA-PACIFIC CONFERENCE ON COMMUNICATION, VOLS 1-3, PROCEEDINGS, P1
   Zhang JB, 2007, IEEE ICC, P3554, DOI 10.1109/ICC.2007.587
   Zheng Teng, 2010, Communications and Network, V2, P104, DOI 10.4236/cn.2010.22017
   Zhou Gang., 2006, P 25 IEEE INT C COMP, DOI DOI 10.1109/INFOCOM.2006.250
   Zhuo SG, 2016, IEEE T MOBILE COMPUT, V15, P1600, DOI 10.1109/TMC.2015.2473852
NR 46
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7803
EP 7818
DI 10.1007/s11042-018-6480-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700062
DA 2024-07-18
ER

PT J
AU Zhong, ZY
   Hu, YM
AF Zhong, Zhiyan
   Hu, Yueming
TI Detection of oxidation region of flexible integrated circuit substrate
   based on topology mapping
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Flexible integrated circuit packaging substrates; Topology mapping;
   Defect inspection; Image segmentation
ID INSPECTION; SYSTEM; ALGORITHM
AB Vision inspection has been extensively used in the field of defect measurement field as a non-contact and nondestructive measurement technique. The conventional methods of visual defect detection rely heavily on the standard templates and features of image, but the standard templates are difficult to obtain or even don't exist in many application fields especially for the field of flexible Integrated Circuit (IC) substrate defect detection based on micro vision. To solve the above problems, an algorithm of oxidation defects detection based on topology mapping. First, the filter template of weighted average neighborhood closed curve based on topology mapping is used to remove the image noise. Second, an image segmentation method is proposed by using the idea of maximum variance between classes to find out the threshold, then the spatially filtered is used to remove the normal surface texture and the structure of the substrate which is introduced by metallographic microscope enlargement. Finally, experiments are performed to show that the filter template of weighted average neighborhood closed curve is better than the existing filters and effectively removes image noise, then the segmentation method in this paper works better.
C1 [Zhong, Zhiyan; Hu, Yueming] South China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.
   [Zhong, Zhiyan; Hu, Yueming] Minist Educ, Engn Res Ctr Precis Elect Mfg Equipments, Guangzhou 510640, Guangdong, Peoples R China.
C3 South China University of Technology
RP Hu, YM (corresponding author), South China Univ Technol, Coll Automat Sci & Engn, Guangzhou 510640, Guangdong, Peoples R China.; Hu, YM (corresponding author), Minist Educ, Engn Res Ctr Precis Elect Mfg Equipments, Guangzhou 510640, Guangdong, Peoples R China.
EM zzy150735@163.com; auymhu@scut.edu.cn
RI Hu, Yueming/GLN-2642-2022
FU National Natural Science Foundation of China [61573146]; National
   Science and Technology Major Project of the Ministry of Science and
   Technology of China [2014ZX 02503]; Applied Science and Technology
   Research and Development Special Fund Project of Guangdong Province,
   China [2015B010133003]; Natural Science Foundation of Guangdong
   Province, China [2016A030313454]
FX This study was funded by the National Natural Science Foundation of
   China (Grant No.61573146), the National Science and Technology Major
   Project of the Ministry of Science and Technology of China (Grant
   No.2014ZX 02503), the Applied Science and Technology Research and
   Development Special Fund Project of Guangdong Province, China (Grant
   No.2015B010133003), the Natural Science Foundation of Guangdong
   Province, China (Grant No.2016A030313454).
CR [Anonymous], MULTIMED TOOLS APPL
   Broqvist P, 2008, MAT SCI SEMICON PROC, V11, P226, DOI 10.1016/j.mssp.2008.10.010
   Chen CY, 2016, MULTIMED TOOLS APPL, V75, P9723, DOI 10.1007/s11042-015-2795-y
   Chen SH, 2016, J INTELL MANUF, V27, P915, DOI 10.1007/s10845-014-0924-5
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Feng YC, 2017, MULTIMED TOOLS APPL, V76, P23139, DOI 10.1007/s11042-016-4098-3
   Glowacz A, 2015, MULTIMED TOOLS APPL, V74, P4253, DOI 10.1007/s11042-013-1537-2
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   Huang JX, 2011, CIRCUIT WORLD, V37, P46, DOI 10.1108/03056121111101287
   Kondala R, 2008, OPTICAL PATTERN INSP, P8196
   Kottari K, 2018, MULTIMED TOOLS APPL, V77, P9307, DOI 10.1007/s11042-017-4891-7
   Li SP, 2006, MAT SCI SEMICON PROC, V9, P371, DOI 10.1016/j.mssp.2006.01.019
   Liang LQ, 2016, MULTIMED TOOLS APPL, V75, P2655, DOI 10.1007/s11042-015-2559-8
   Liao CT, 2012, J SIGNAL PROCESS SYS, V67, P279, DOI 10.1007/s11265-010-0556-8
   Lisanti G, 2018, MULTIMED TOOLS APPL, V77, P1583, DOI 10.1007/s11042-017-4351-4
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Ma W, 2016, MULTIMED TOOLS APPL, V75, P10935, DOI 10.1007/s11042-015-2817-9
   Malarvel M, 2017, OPTIK, V142, P109, DOI 10.1016/j.ijleo.2017.05.066
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Moganti M., 1995, IEEE Potentials, V14, P6, DOI 10.1109/45.464686
   Mohedano E, 2015, MULTIMED TOOLS APPL, V74, P10137, DOI 10.1007/s11042-015-2805-0
   Mu HB, 2010, 2010 IITA INT C INT, V1, P40
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qiao X, 2017, MAR TECHNOL SOC J, V51, P75
   Qin LJ, 2017, MULTIMED TOOLS APPL, V76, P14815, DOI 10.1007/s11042-016-4042-6
   Qingxiang Wang, 2010, 2010 2nd International Conference on Industrial and Information Systems (IIS 2010), P324, DOI 10.1109/INDUSIS.2010.5565716
   Shui PL, 2007, SIGNAL PROCESS, V87, P1721, DOI 10.1016/j.sigpro.2007.01.021
   Shui PL, 2005, IEEE SIGNAL PROC LET, V12, P681, DOI 10.1109/LSP.2005.855555
   Simpkins BS, 2006, MAT SCI SEMICON PROC, V9, P308, DOI 10.1016/j.mssp.2006.01.025
   Song EM, 2019, MULTIMED TOOLS APPL, V78, P9083, DOI 10.1007/s11042-017-5484-1
   Tan N, 2016, IEEE ROBOT AUTOM LET, V1, P638, DOI 10.1109/LRA.2016.2523550
   Tan N, 2014, ELECTRON LETT, V50, P1853, DOI 10.1049/el.2014.0926
   Taneja A, 2018, MULTIMED TOOLS APPL, V77, P9271, DOI 10.1007/s11042-017-4864-x
   Wang LY, 2016, CIRCUIT WORLD, V42, P49, DOI 10.1108/CW-07-2014-0027
   Wang QX, 2008, 2008 INTERNATIONAL SYMPOSIUM ON INTELLIGENT INFORMATION TECHNOLOGY APPLICATION, VOL I, PROCEEDINGS, P321, DOI 10.1109/IITA.2008.348
   WEST GAW, 1984, IEEE T SYST MAN CYB, V14, P767, DOI 10.1109/TSMC.1984.6313300
   Wu WY, 1996, COMPUT IND, V28, P103, DOI 10.1016/0166-3615(95)00063-1
   Yang YX, 2018, MULTIMED TOOLS APPL, V77, P23227, DOI 10.1007/s11042-018-5639-8
   Ye F, 2012, CIRCUIT WORLD, V38, P142, DOI 10.1108/03056121211250669
   Zhang J, 2013, OPTIK, V124, P4472, DOI 10.1016/j.ijleo.2013.03.012
   Zhang Yun-Hang, 2017, COMPUTER VISION PATT, V1, P1, DOI DOI 10.1084/JEM.20061440.LIU
   Zheng H, 2002, J MATER PROCESS TECH, V125, P427, DOI 10.1016/S0924-0136(02)00294-7
   Zhu H, 2017, MULTIMED TOOLS APPL, V76, P1, DOI DOI 10.1007/s11042-016-3486-z
NR 45
TC 3
Z9 3
U1 0
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2019
VL 78
IS 6
BP 7871
EP 7892
DI 10.1007/s11042-018-6466-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HZ0KO
UT WOS:000468529700065
DA 2024-07-18
ER

PT J
AU Ahmad, K
   Pogorelov, K
   Riegler, M
   Conci, N
   Halvorsen, P
AF Ahmad, Kashif
   Pogorelov, Konstantin
   Riegler, Michael
   Conci, Nicola
   Halvorsen, Pal
TI Social media and satellites: Disaster event detection, linking and
   summarization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information retrieval; Event detection; Natural disaster; Social media
ID TWITTER
AB Being able to automatically link social media and satellite imagery holds large opportunities for research, with a potentially considerable impact on society. The possibility of integrating different information sources opens in fact to new scenarios where the wide coverage of satellite imaging can be used as a collector of the fine-grained details provided by the social media. Remote-sensed data and social media data can well complement each other, integrating the wide perspective provided by the satellite view with the information collected locally, being it textual, audio, or visual. Among the possible applications, natural disasters are certainly one of the most interesting scenarios, where global and local perspectives are needed at the same time. In this paper, we present a system called JORD that is able to autonomously collect social media data (including the text analysis in local languages) about technological and environmental disasters, and link it automatically to remote-sensed data. Moreover, in order to ensure the quality of retrieved information, JORD is equipped with a hierarchical filtering mechanism relying on the temporal information and the content analysis of retrieved multimedia data. To show the capabilities of the system, we present a large number of disaster events detected by the system, and we evaluate both the quality of the provided information about the events and the usefulness of JORD from potential users viewpoint, using crowdsourcing.
C1 [Ahmad, Kashif; Pogorelov, Konstantin; Riegler, Michael; Conci, Nicola; Halvorsen, Pal] Univ Trento, DISI, Via Sammarive 5, Trento, Italy.
C3 University of Trento
RP Ahmad, K (corresponding author), Univ Trento, DISI, Via Sammarive 5, Trento, Italy.
EM kashif.ahmad@unitn.it
RI Conci, Nicola/AAH-4671-2020; ahmad, kashif/AAV-8323-2021; Ahmad,
   Kashif/JJE-8424-2023; Riegler, Michael A/E-5443-2015
OI Conci, Nicola/0000-0002-7858-0928; Ahmad, Kashif/0000-0002-0931-9275;
   Halvorsen, Pal/0000-0003-2073-7029
CR Ahmad K, 2017, P MEDIAEVAL WORKSH
   Ahmad K, 2018, SIGNAL PROCESS-IMAGE, V60, P42, DOI 10.1016/j.image.2017.09.009
   Ahmad K, 2016, IEEE GLOB CONF SIG, P1223, DOI 10.1109/GlobalSIP.2016.7906036
   Amit SNKB, 2016, INT GEOSCI REMOTE SE, P5189, DOI 10.1109/IGARSS.2016.7730352
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], NY TIMES
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], 2015, P INT AAAI C WEB SOC
   [Anonymous], PRENAFETA BOLDU FX D
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2003, P 11 ACM INT C MULT
   [Anonymous], 2016, 2016 14 INT WORKSH C, DOI DOI 10.1109/CBMI.2016.7500256
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], PLANET APPL PROGRAM
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], 2010, P 19 ACM INT C INF K
   [Anonymous], P ACM MMSYS
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], P 15 INT WORKSH CONT
   [Anonymous], 2014, Comput. Sci.
   [Anonymous], 2016, IMAGE VISION COMPUTI
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], PROGR PHYS GEOGRAPHY
   [Anonymous], SPRINGER ACIIDS
   [Anonymous], USE EARTH OBSERVING
   [Anonymous], 2013 INT C ICT SMART
   [Anonymous], 2017, Retinal Vessel Segmentation in Fundoscopic Images with Generative Adversarial Networks
   [Anonymous], P MEDIAEVAL WORKSH D
   [Anonymous], 2017, DOMAIN BASED LATE FU
   Atefeh F, 2015, COMPUT INTELL-US, V31, P132, DOI 10.1111/coin.12017
   Bakillah M, 2015, INT J GEOGR INF SCI, V29, P258, DOI 10.1080/13658816.2014.964247
   Bischke B, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P1077, DOI 10.1145/2964284.2984063
   Bischke Benjamin, 2017, DETECTION FLOODING E
   Campbell J. B., 2011, INTRO REMOTE SENSING
   Chang SF, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P5, DOI 10.1145/2911996.2930063
   CHAVEZ PS, 1991, PHOTOGRAMM ENG REM S, V57, P295
   Crooks A, 2013, T GIS, V17, P124, DOI 10.1111/j.1467-9671.2012.01359.x
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Rong DY, 2014, UBICOMP'14: PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P425, DOI 10.1145/2632048.2632063
   Earle PS, 2011, ANN GEOPHYS-ITALY, V54, P708, DOI 10.4401/ag-5364
   Fisher A, 2016, REMOTE SENS ENVIRON, V175, P167, DOI 10.1016/j.rse.2015.12.055
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guha-Sapir D., 2015, Em-dat: International Disaster Database
   Guille A, 2015, SOC NETW ANAL MIN, V5, DOI 10.1007/s13278-015-0258-0
   Jung M, 2006, REMOTE SENS ENVIRON, V101, P534, DOI 10.1016/j.rse.2006.01.020
   Kansas J, 2016, INT J WILDLAND FIRE, V25, P597, DOI 10.1071/WF15170
   Li C., 2012, Cikm, P155, DOI DOI 10.1145/2396761.2396785
   Liu Y, 2016, PROCEDIA COMPUT SCI, V91, P566, DOI 10.1016/j.procs.2016.07.144
   Manjunath TN, 2010, INT J COMPUT SCI NET, V10, P165
   Mathioudakis M., 2010, P 2010 ACM SIGMOD IN, P1155
   Oliva N, 2017, INT EL DEVICES MEET
   Paul F, 2009, J GLACIOL, V55, P607, DOI 10.3189/002214309789471003
   Pogorelov K, 2017, MULTIMED TOOLS APPL, V76, P22493, DOI 10.1007/s11042-017-4989-y
   Pogorelov K, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P164, DOI 10.1145/3083187.3083212
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Simonyan K., 2014, 14091556 ARXIV
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Takahashi B, 2015, COMPUT HUM BEHAV, V50, P392, DOI 10.1016/j.chb.2015.04.020
   Xu Z, 2016, EURASIP J WIREL COMM, DOI 10.1186/s13638-016-0553-0
   Yin J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4234
   Zhou BL, 2014, ADV NEUR IN, V27
NR 63
TC 35
Z9 35
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 2837
EP 2875
DI 10.1007/s11042-018-5982-9
PG 39
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600011
DA 2024-07-18
ER

PT J
AU Al-Hami, M
   Lakaemper, R
   Rawashdeh, M
   Hossain, MS
AF Al-Hami, Mo'taz
   Lakaemper, Rolf
   Rawashdeh, Majdi
   Hossain, M. Shamim
TI Camera localization for a human-pose in 3D space using a single 2D
   human-pose image with landmarks: a multimedia social network emerging
   demand
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-pose; Projection; Camera localization; Multimedia; Logistic
   regression; 2D shape context; 3D reconstruction; Rotation matrix;
   Translation; Extrinsic camera; Intrinsic camera; Principal component
   analysis; Features; Projection error
AB Recovering a 3D human-pose in the form of an abstracted skeleton from a 2D image suffers from loss of depth information. Assuming the projected human-pose is represented by a set of 2D landmarks capturing the human-pose limbs, recovering back the original 3D locations is an ill posed problem. To recover a 3D configuration, camera localization in 3D space plays a major role, an inaccurate camera localization might mislead the recovery process. In this paper, we propose a 3D camera localization model using only human-pose appearance in a 2D image (i.e., the set of 2D landmarks). We apply a supervised multi-class logistic regression to assign the camera location in 3D space. In the learning process, we assume a set of predefined labeled camera locations. The features we train consist of relative length of limbs and 2D shape context. The goal is to build a relation between these projected landmarks and the camera location in 3D space. This kind of analysis allows us to reconstruct 3D human-poses based on the 2D projection only without any predefined camera parameters. Also, makes real-time multimedia exchange more reliable specially for human-pose related tasks. We test our model on a set of real images showing a variety of camera locations.
C1 [Al-Hami, Mo'taz] Hashemite Univ, Dept Comp Informat Syst, Zarqa 13115, Jordan.
   [Lakaemper, Rolf] Temple Univ, Dept Comp & Informat Sci, Philadelphia, PA 19122 USA.
   [Rawashdeh, Majdi] Princess Sumaya Univ Technol, Dept Business Informat Technol, Amman 11941, Jordan.
   [Hossain, M. Shamim] King Saud Univ, Coll Comp & Informat Sci, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.
   [Hossain, M. Shamim] King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
C3 Hashemite University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); Temple University; Princess Sumaya University for
   Technology; King Saud University; King Saud University
RP Hossain, MS (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Res Chair Pervas & Mobile Comp, Riyadh 11543, Saudi Arabia.; Hossain, MS (corresponding author), King Saud Univ, Dept Software Engn, Coll Comp & Informat Sci, Riyadh, Saudi Arabia.
EM motaz@hu.edu.jo; lakamper@temple.edu; m.rawashdeh@psut.edu.jo;
   mshossain@ksu.edu.sa
RI Guizani, Mohsen/AAX-4534-2021; Hossain, M. Shamim/K-1362-2014
OI Guizani, Mohsen/0000-0002-8972-8094; Hossain, M.
   Shamim/0000-0001-5906-9422; Al-Hami, Mo'taz/0000-0003-4633-9870
CR Akhter I, 2015, PROC CVPR IEEE, P1446, DOI 10.1109/CVPR.2015.7298751
   Al-Badarneh Amer F., 2008, American Journal of Biochemistry and Biotechnology, V4, P375, DOI 10.3844/ajbbsp.2008.375.384
   Al-Hami Mo'taz, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P420
   Al-Hami M, 2017, INT CONF 3D VISION, P440, DOI 10.1109/3DV.2017.00057
   Al-Hami M, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P137, DOI 10.1109/ARSO.2014.7020994
   [Anonymous], KINECTTCP DOCUMENTAT
   [Anonymous], VIDEO STREAMING WIRE
   [Anonymous], THESIS
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46484-8_29
   [Anonymous], RECONSTRUCTING 3D HU
   [Anonymous], 2005, REGULARIZED LO UNPUB
   [Anonymous], HUMAN POSE SEMANTIC
   [Anonymous], 2015, FUSION SMART MULTIME
   [Anonymous], IEEE SOC C COMP VIS
   [Anonymous], 2001, CMU MOTION BODY MOBO
   [Anonymous], 2017, Computer Vision and Pattern Recognition, 2017 IEEE Computer Society Conference on
   Awad G, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P3, DOI 10.1145/3078971.3079044
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Gavrila D., 2000, PROC EUROPEAN C COMP, P37, DOI [DOI 10.1007/3-540-45053-X, 10.1007/3-540-45053-X-3., DOI 10.1007/3-540-45053-X-3]
   Jokinen K., 2014, Natural interaction with robots, knowbots and smartphones: Putting spoken dialog systems into practice, P213, DOI DOI 10.1007/978-1-4614-8280-2_19
   Lan XY, 2005, IEEE I CONF COMP VIS, P470
   Lin CJ, 2008, J MACH LEARN RES, V9, P627
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Mousas C, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0124-0
   Ramanan D., 2006, NIPS
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451
   Taylor CJ, 2000, PROC CVPR IEEE, P677, DOI 10.1109/CVPR.2000.855885
   Varadarajan J, 2018, INT J COMPUT VISION, V126, P410, DOI 10.1007/s11263-017-1026-6
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhou XW, 2016, PROC CVPR IEEE, P4966, DOI 10.1109/CVPR.2016.537
NR 35
TC 4
Z9 5
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3587
EP 3608
DI 10.1007/s11042-018-6789-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600050
DA 2024-07-18
ER

PT J
AU Chang, YS
   Chen, YS
   Chiang, CW
AF Chang, Yuh-Shihing
   Chen, You-Shyang
   Chiang, Cheng-Wei
TI RETRACTED: The differences in pleasing value and learning performance
   among different groups using mobile augmented reality system for
   cultural environment learning (Retracted article. See SEP, 2022)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Retracted Publication
DE Mobile augmented reality; Mobile learning; and Cultural learning
ID CURIOSITY
AB Mobile Augmented Reality (MAR) has becomes more widely used and provides the great context of an immersive virtual learning environment. However, sometimes the learning effect is influenced by the pleasing value, which is always subjective and learning driven. In order to ensure a successful launch of the MAR cultural interactive learning tool, it is extremely important to predict the pleasing value of design alternatives based on the common language understood by students. For learners, in the learning process, the value of pleasure comes from the improvement of external emotional interest as well as internal cognitive interest that learners already have. This research will examine if students have problems with operating the MAR, and to understand whether they have pleasing value and a learning performance. Thus, this research has proposed a difference of visual perception and a construction for the evaluation of pleasing value as well as the culture of learning performance between media students and students in other majors. The research team has chosen different cultural temples in Shi-lin and Tam-sui in Taiwan using the MAR systems to evaluate the correctness and speed of the reaction in between the two groups represented as: the experimental group and the control group. The research objects will be the second year/sophomore studentsat Taipei University of Marine Technology. There were two classes with different majors and there were 35 students in each class. This research took one of the classes as the experimental group with MAR empirical teaching in cultural and environmental learning and other class will be the control group using the traditional teaching method. The result from the experiment and the ANCOVA analysis indicates: (1) Based on the results of experiments, the participants appreciated the MAR approach. The learning performance of the students did improve significantly via ACNOVA. (2) The experimental group has a more significant effect compared to the control group in the aspect from the four learning performance constructions: stylistic, cultural value, cultural characterization and innovation services. (3) Through the bi-variance statistical analysis (One-Way, ANOVA), there was a significant positive correlation between pleasing value and the improvement of post-learning interest in the experimental group. This research found that based on the exploration factor from that the results the interfaces were built on a mobile phone with a touch-screen can be a model for the effectiveness examination, It can also expand the MAR application scope by incorporating it into teaching.
C1 [Chang, Yuh-Shihing] Asia Univ, Dept Digital Media Design, 500 Lioufeng Rd, Taichung 41354, Taiwan.
   [Chen, You-Shyang] Hwa Hsia Univ Technol, Dept Informat Management, 111 Gongzhuan Rd, New Taipei 235, Taiwan.
   [Chiang, Cheng-Wei] Ling Tung Univ, Dept Digital Content Design, 1 Ling Tung Rd, Taichung 408, Taiwan.
C3 Asia University Taiwan
RP Chen, YS (corresponding author), Hwa Hsia Univ Technol, Dept Informat Management, 111 Gongzhuan Rd, New Taipei 235, Taiwan.; Chiang, CW (corresponding author), Ling Tung Univ, Dept Digital Content Design, 1 Ling Tung Rd, Taichung 408, Taiwan.
EM ys_chen@cc.hwh.edu.tw; mailtowaylan@gmail.com
CR [Anonymous], THESIS
   AZUMA R, 1993, COMMUN ACM, V36, P50, DOI 10.1145/159544.159581
   Azuma RT, 1997, PRESENCE-VIRTUAL AUG, V6, P355, DOI 10.1162/pres.1997.6.4.355
   Bates J., 1995, Multimedia Tools and Applications, V1, P47, DOI 10.1007/BF01261225
   Berlyne DE, 1950, B J PSYCHOL-GEN SECT, V41, P68, DOI 10.1111/j.2044-8295.1950.tb00262.x
   Chang G., 2010, P SOC INFORM TECHNOL, P1380
   Chen YS, 2003, J COMPUT ASSIST LEAR, V19, P347, DOI 10.1046/j.0266-4909.2003.00036.x
   Craig A.B., 2013, UNDERSTANDING AUGMEN, DOI DOI 10.1016/B978-0-240-82408-6.00001-1
   HIDI S, 1988, READ RES QUART, V23, P465, DOI 10.2307/747644
   Höllerer TH, 2004, TELEGEOINFORMATICS: LOCATION-BASED COMPUTING AND SERVICES, P221
   Huang MH, 2001, J BUS PSYCHOL, V16, P239, DOI 10.1023/A:1011109200392
   Hull C.L., 1943, Principles of Behavior: an Introduction to Behavior Theory
   Hyung-Keun J, 2011, MULTIMED TOOLS APPL, V68, P225
   Janelle C, 2018, 10 WAYS MAKE LEARNIN
   Liu F, 2017, MULTIMED TOOLS APPL, V76, P15279, DOI 10.1007/s11042-016-3817-0
   LOEWENSTEIN G, 1994, PSYCHOL BULL, V116, P75, DOI 10.1037/0033-2909.116.1.75
   Mackay WE, 1996, RECHERCHE, P32
   MILGRAM P, 1994, IEICE T INF SYST, VE77D, P1321
   Milgram P, 1974, TAXONOMY MIXED REALI, V12, P1321
   SAATY TL, 1986, EUR J OPER RES, V26, P229, DOI 10.1016/0377-2217(86)90184-0
   Schiefele U, 1996, CONTEMP EDUC PSYCHOL, V21, P3, DOI 10.1006/ceps.1996.0002
   Sefton-Green J., 2003, Literature Review in Informal Learning with Technology Outside School
   Shulman L.S., 1968, 50597 US OFF ED COOP
   Wagner D, 2006, LECT NOTES COMPUT SC, V4282, P85
   Zsole B, 2017, NEO BLOG
NR 25
TC 14
Z9 14
U1 1
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4965
EP 4986
DI 10.1007/s11042-018-6928-y
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200053
DA 2024-07-18
ER

PT J
AU Cho, S
   Shrestha, B
   Jang, W
   Seo, C
AF Cho, Seongsoo
   Shrestha, Bhanu
   Jang, Wook
   Seo, Changho
TI Trajectory tracking optimization of mobile robot using artificial immune
   system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Artificial immune system; Optimization; Mobile robot; Trajectory
   tracking
ID CONTROLLER; NETWORKS
AB In this paper, an optimization method that provides quick response using artificial immune system, is proposed and applied to a mobile robot for trajectory tracking. The study focuses on the immune theory to derive a quick optimization method that puts emphasis on immunity feedback using memory cells by the expansion and suppression of the test group rather than to derive a specific mathematical model of the artificial immune system. Various trajectories were selected in mobile environment to evaluate the performance of the proposed artificial immune system. The global inputs to the mobile robot are reference position and reference velocity, which are time variables. The global output of mobile robot is a current position. The tracking controller makes position error to be converged to zero. In order to reduce position error, compensation velocities on the track of trajectory are necessary. Input variables of fuzzy are position errors in every sampling time. The output values of fuzzy are compensation velocities. Immune algorithm is implemented to adjust the scaling factor of fuzzy automatically. The results of the computer simulation proved the system to be efficient and effective for tracing the trajectory to the final destination by the mobile robot.
C1 [Cho, Seongsoo] Soongsil Univ, Sch Comp Sci & Engn, Seoul 07027, South Korea.
   [Shrestha, Bhanu] Kwangwoon Univ, Dept Elect Engn, Seoul 01897, South Korea.
   [Jang, Wook; Seo, Changho] Kongju Natl Univ, Dept Appl Math, Kong Ju 32588, South Korea.
C3 Soongsil University; Kwangwoon University; Kongju National University
RP Shrestha, B (corresponding author), Kwangwoon Univ, Dept Elect Engn, Seoul 01897, South Korea.
EM css3617@gmail.com; bnu@kw.ac.kr; jw85@kongju.ac.kr; chseo@kongju.ac.kr
RI Shrestha, Bhanu/ABB-8066-2021
OI Shrestha, Bhanu/0000-0002-2557-8699
FU National Research Foundation of Korea (NRF) - Korea Government (MISP)
   [2016R1A4A1011761]; Kwangwoon University
FX This research was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea Government (MISP)(2016R1A4A1011761).
   This research was conducted by the grant of Kwangwoon University, 2018.
CR [Anonymous], 2013, INT J COMPUTER APPL
   [Anonymous], IMMUNOLOGICAL COMPUT
   Chun JS, 1997, IEEE T MAGN, V33, P1876, DOI 10.1109/20.582650
   Duan QJ, 2005, ISADS 2005: INTERNATIONAL SYMPOSIUM ON AUTONOMOUS DECENTRALIZED SYSTEMS,PROCEEDINGS, P69, DOI 10.1109/ISADS.2005.1452022
   Fahimi F, 2009, AUTONOMOUS ROBOTS: MODELING, PATH PLANNING, AND CONTROL, P1, DOI 10.1007/978-0-387-09538-7
   Gao W, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P198
   JERNE NK, 1984, IMMUNOL REV, V79, P5, DOI 10.1111/j.1600-065X.1984.tb00484.x
   JERNE NK, 1973, SCI AM, V229, P52, DOI 10.1038/scientificamerican0773-52
   Kim S, 2005, PROC SPIE, V6042, DOI 10.1117/12.664653
   Kim SH, 2001, IEEE T IND ELECTRON, V48, P467, DOI 10.1109/41.915427
   Leandro N, 2002, ARTIFICIAL IMMUNITIE
   Lin P, 2011, ARTIF INTELL, V175, P942, DOI 10.1016/j.artint.2010.11.026
   Luh GC, 2008, APPL SOFT COMPUT, V8, P30, DOI 10.1016/j.asoc.2006.10.009
   Meshref H, 2000, IEEE SYS MAN CYBERN, P61, DOI 10.1109/ICSMC.2000.884965
   Munagamage R, 2015, INT RES S ENG ADV 20, P208
   Ozcelik S, 2011, PROCEDIA COMPUT SCI, V6, DOI 10.1016/j.procs.2011.08.058
   Pedraza C, 2011, J SUPERCOMPUT, V58, P244, DOI 10.1007/s11227-010-0401-7
   Nguyen QH, 2017, MULTIMED TOOLS APPL, V76, P2645, DOI 10.1007/s11042-015-3204-2
   Rawlik K, 2018, SPR PROC ADV ROBOT, V3, P145, DOI 10.1007/978-3-319-60916-4_9
   Razafimandimby C, 2016, PROCEEDINGS 2016 IEEE FIRST INTERNATIONAL CONFERENCE ON INTERNET-OF-THINGS DESIGN AND IMPLEMENTATION IOTDI 2016, P241, DOI 10.1109/IoTDI.2015.10
   Russo M, 2000, IEEE T EVOLUT COMPUT, V4, P259, DOI 10.1109/4235.873236
   SHETH PN, 1971, J ENG IND, V93, P102, DOI 10.1115/1.3427855
   Siegwart R., 2004, Autonomous Mobile Robots
   Pham TT, 2012, MULTIMED TOOLS APPL, V60, P419, DOI 10.1007/s11042-010-0598-8
   Wang SZ, 2015, INT CONF INTEL INFOR, P197, DOI 10.1109/ICIIBMS.2015.7439511
   Whitbrook AM, 2007, IEEE T SYST MAN CY B, V37, P1581, DOI 10.1109/TSMCB.2007.907334
   Yong B, 2016, J SUPER COMPUTING, P1
NR 27
TC 11
Z9 11
U1 1
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 3
BP 3203
EP 3220
DI 10.1007/s11042-018-6413-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HK7MC
UT WOS:000458171600029
DA 2024-07-18
ER

PT J
AU Song, WJ
   Wang, LZ
   Liu, P
   Choo, KKR
AF Song, Weijing
   Wang, Lizhe
   Liu, Peng
   Choo, Kim-Kwang Raymond
TI Improved t-SNE based manifold dimensional reduction for remote sensing
   data processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing big data; Manifold learning; T-SNE; 2-mixed Gaussian
   model (GMM); Probability distribution
ID IMAGE; EIGENFACES
AB In our increasingly data-abundant society, remote sensing big data perform massive, high dimension and heterogeneity features, which could result in dimension disaster to various extent. It is worth mentioning that the past two decades have witnessed a number of dimensional reductions to weak the spatiotemporal redundancy and simplify the calculation in remote sensing information extraction, such as the linear learning methods or the manifold learning methods. However, the crowding and mixing when reducing dimensions of remote sensing categories could degrade the performance of existing techniques. Then in this paper, by analyzing probability distribution of pairwise distances among remote sensing datapoints, we use the 2-mixed Gaussian model(GMM) to improve the effectiveness of the theory of t-Distributed Stochastic Neighbor Embedding (t-SNE). A basic reducing dimensional model is given to test our proposed methods. The experiments show that the new probability distribution capable retains the local structure and significantly reveals differences between categories in a global structure.
C1 [Song, Weijing; Wang, Lizhe] China Univ Geosci, Coll Comp Sci, Wuhan 430074, Peoples R China.
   [Liu, Peng] Chinese Acad Sci, Inst Remote Sensing & Digital Earth, Beijing 100094, Peoples R China.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Informat Syst & Cyber Secur, San Antonio, TX 78249 USA.
   [Choo, Kim-Kwang Raymond] Univ Texas San Antonio, Dept Elect & Comp Engn, San Antonio, TX 78249 USA.
C3 China University of Geosciences; Chinese Academy of Sciences; The
   Institute of Remote Sensing & Digital Earth, CAS; University of Texas
   System; University of Texas at San Antonio (UTSA); University of Texas
   System; University of Texas at San Antonio (UTSA)
RP Wang, LZ (corresponding author), China Univ Geosci, Coll Comp Sci, Wuhan 430074, Peoples R China.
EM lizhe.wang@gmail.com
RI Choo, Kim-Kwang Raymond/A-3634-2009; Liu, Peng/KMX-5167-2024; Wang,
   Lizhe/L-7453-2014
OI Choo, Kim-Kwang Raymond/0000-0001-9208-5336; 
FU National Natural Science Foundation of China [41471368, 41571413]; Hubei
   Provincial Natural Science Foundation of China [2017CFB279]
FX This work is supported by the National Natural Science Foundation of
   China (No. 41471368, No. 41571413) and the Hubei Provincial Natural
   Science Foundation of China (No.2017CFB279).
CR Bachmann CM, 2005, IEEE T GEOSCI REMOTE, V43, P441, DOI 10.1109/TGRS.2004.842292
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Brand M., 2002, Adv. Neural Inf. Process. Syst., V15
   Chen SB, 2015, IEEE T CYBERNETICS, V45, P1744, DOI 10.1109/TCYB.2014.2359984
   Chen WT, 2013, ENVIRON EARTH SCI, V70, P673, DOI 10.1007/s12665-012-2151-8
   Chen YL, 2017, INFORM FUSION, V36, P225, DOI 10.1016/j.inffus.2016.11.015
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Deren L, 2014, ACTA GEODAETICA CART, V43, P211
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Feng RY, 2016, IEEE J-STARS, V9, P5791, DOI 10.1109/JSTARS.2016.2570947
   Gomez D, 2008, SOFT COMPUT, V12, P243, DOI 10.1007/s00500-007-0201-z
   [郭华东 Guo Huadong], 2014, [科学通报, Chinese Science Bulletin], V59, P1047
   Han T, 2005, INT GEOSCI REMOTE SE, P1237
   Hassanzadeh A, 2016, INT GEOSCI REMOTE SE, P3326, DOI 10.1109/IGARSS.2016.7729860
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Hinton G. E., 2002, Advances in Neural InformationProcessing Systems, P857
   Huang HB, 2014, IEEE T GEOSCI REMOTE, V52, P1677, DOI 10.1109/TGRS.2013.2253559
   Jiang JJ, 2016, IEEE T CIRC SYST VID, V26, P1674, DOI 10.1109/TCSVT.2015.2433538
   Li F, 2015, IEEE GEOSCI REMOTE S, V12, P2486, DOI 10.1109/LGRS.2015.2487226
   Li XJ, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060514
   Ma L, 2010, IEEE T GEOSCI REMOTE, V48, P4099, DOI 10.1109/TGRS.2010.2055876
   Palmieri F, 2014, CONCURR COMP-PRACT E, V26, P1113, DOI 10.1002/cpe.3061
   Roth V, 2000, ADV NEUR IN, V12, P568
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samat A, 2016, IEEE T GEOSCI REMOTE, V54, P6803, DOI 10.1109/TGRS.2016.2591066
   Schölkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tian T, 2017, MULTIMED TOOLS APPL, V76, P22943, DOI 10.1007/s11042-016-4167-7
   Tian T, 2017, MULTIMED TOOLS APPL, V76, P18731, DOI 10.1007/s11042-016-4252-y
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vural E, 2016, IEEE T IMAGE PROCESS, V25, P1410, DOI 10.1109/TIP.2016.2520368
   Wang LZ, 2018, SOFT COMPUT, V22, P3331, DOI 10.1007/s00500-017-2568-9
   Wang LZ, 2016, CLUSTER COMPUT, V19, P793, DOI 10.1007/s10586-016-0569-6
   Weijing S, 2014, J ENGL STUD, V6, P259
   Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Zhang YS, 2014, IEEE GEOSCI REMOTE S, V11, P464, DOI 10.1109/LGRS.2013.2267091
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhiyong W, 2012, RES DIMENSION REDUCT
NR 44
TC 20
Z9 21
U1 1
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2019
VL 78
IS 4
BP 4311
EP 4326
DI 10.1007/s11042-018-5715-0
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HS5NE
UT WOS:000463917200021
DA 2024-07-18
ER

PT J
AU Lin, CY
   Chen, HS
AF Lin, Chen-Yi
   Chen, Han-Shen
TI Personalized channel recommendation on live streaming platforms
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation system; Live streaming; Clustering; Personal preference
ID TRACKING
AB With unceasing technological advancements, an increasing number of viewers are watching channels through live streaming platforms, and live streaming technologies are developing rapidly. However, as thousands of channels are broadcasting on live streaming platforms, it is difficult for viewers to find their favorite channels. As a result, an accurate channel recommendation technique is required for the viewers. The current method of promoting live streaming channels recommends the most popular channels to viewers, but this ignores viewers' personal preferences. Therefore, we cluster viewers based on their personal preferences so that one cluster of viewers contains the viewers with similar favorite channels. In this way, the channels liked by viewers can be recommended to other viewers in the same group. In addition, our recommendation technique also considers viewers' loyalty towards a particular channel. In the experiment, a currently popular live streaming gaming platform, Twitch, is used for the analysis. The results confirm that our proposed recommendation technique is more accurate than the existing recommendation techniques.
C1 [Lin, Chen-Yi] Natl Taichung Univ Sci & Technol, Dept Informat Management, Taichung, Taiwan.
   [Chen, Han-Shen] Natl Chiao Tung Univ, Inst Comp Sci & Engn, Hsinchu, Taiwan.
C3 National Taichung University of Science & Technology; National Yang Ming
   Chiao Tung University
RP Lin, CY (corresponding author), Natl Taichung Univ Sci & Technol, Dept Informat Management, Taichung, Taiwan.
EM cylin@nutc.edu.tw; lf963@hotmail.com
OI Lin, Chen-Yi/0000-0002-8271-1935
FU Ministry of Science and Technology of Republic of China [MOST
   105-2221-E-025-011, MOST 106-2221-E-025-012]
FX We would like to thank the anonymous reviewers for their comments. This
   work was supported by the Ministry of Science and Technology of Republic
   of China under grant MOST 105-2221-E-025-011 and MOST
   106-2221-E-025-012.
CR Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Agrawal Rakesh., 1993, P 1993 ACM SIGMOD IN, P207, DOI DOI 10.1145/170035.170072
   [Anonymous], 1967, P 5 BERK S MATH STAT
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Das M, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P203
   Davidson James, 2010, P 4 ACM C REC SYST, P293, DOI [DOI 10.1145/1864708.1864770, 10.1145/1864708]
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Dong X, 2017, AAAI CONF ARTIF INTE, P1309
   Elkahky A, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P278, DOI 10.1145/2736277.2741667
   Han J, 2006, IEEE INT C FUZZ SYST
   Hastie T., 2001, ELEMENTS STAT LEARNI, DOI 10.1007/978-0-387-84858-7_2
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Huang JL, 2015, INT C CONS EL TAIW
   Hwang W-S, 2015, 9 INT C UB INF MAN C
   Karkali M, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P1117
   Kim E, 2011, IEEE T BROADCAST, V57, P674, DOI 10.1109/TBC.2011.2161409
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Krauss C, 2013, P 2 INT WORKSH BIG D, P63
   Lee H, 2006, IEEE T CONSUM ELECTR, V52, P1064, DOI 10.1109/TCE.2006.1706508
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Ni B, 2016, APPL MATH SER B, V31, P37, DOI 10.1007/s11766-016-3340-0
   Pera M.S., 2013, ACM Conference on Recommender Systems RecSys, P113
   Schabetsberger C, 2013, INT C ADV MOB COMP M
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xu M, 2013, 7 ACM C REC SYST, P285
   Yang TW, 2013, CONF TECHNOL APPL, P188, DOI 10.1109/TAAI.2013.46
   Yang Y, 2014, 2014 INT C COMP COMM, P1
   Yu HP, 2018, MULTIMED TOOLS APPL, V77, P24097, DOI 10.1007/s11042-018-5697-y
   Zheng L, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P425, DOI 10.1145/3018661.3018665
NR 34
TC 16
Z9 17
U1 4
U2 86
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 1999
EP 2015
DI 10.1007/s11042-018-6323-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700033
DA 2024-07-18
ER

PT J
AU Lin, XM
   Li, J
   Zeng, HL
   Ji, RR
AF Lin, Xianming
   Li, Jie
   Zeng, Hualin
   Ji, Rongrong
TI Font generation based on least squares conditional generative
   adversarial nets
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Least squares conditional GAN; Font generation; Stroke extraction
AB With the rapid growth of multimedia information, the font library has become a part of people's work life. Compared to the Western alphabet language, it is difficult to create new font due to huge quantity and complex shape. At present, most of the researches on automatic generation of fonts use traditional methods requiring a large number of rules and parameters set by experts, which are not widely adopted. This paper divides Chinese characters into strokes and generates new font strokes by fusing the styles of two existing font strokes and assembling them into new fonts. This approach can effectively improve the efficiency of font generation, reduce the costs of designers, and is able to inherit the style of existing fonts. In the process of learning to generate new fonts, the popular of deep learning areas, Generative Adversarial Nets has been used. Compared with the traditional method, it can generate higher quality fonts without well-designed and complex loss function.
C1 [Lin, Xianming; Li, Jie; Zeng, Hualin; Ji, Rongrong] Xiamen Univ, Sch Informat Sci & Engn, Xiamen 361005, Peoples R China.
   [Lin, Xianming; Li, Jie; Zeng, Hualin; Ji, Rongrong] Xiamen Univ, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
C3 Xiamen University; Xiamen University
RP Ji, RR (corresponding author), Xiamen Univ, Sch Informat Sci & Engn, Xiamen 361005, Peoples R China.; Ji, RR (corresponding author), Xiamen Univ, Fujian Key Lab Sensing & Comp Smart City, Xiamen 361005, Peoples R China.
EM rrji@xmu.edu.cn
OI Lin, Xianming/0000-0003-4739-8936; Li, Jie/0000-0003-3102-6425
FU National Key Technology RD Program [2017YFC011300, 2016YFB1001503];
   Nature Science Foundation of China [61422210, 61373076, 61402388,
   61572410]; Nature Science Foundation of Fujian Province, China
   [2017J01125]
FX This work is supported by the National Key Technology R&D Program (No.
   2017YFC011300, No. 2016YFB1001503), the Nature Science Foundation of
   China (No. 61422210, No. 61373076, No. 61402388, and No. 61572410),the
   Nature Science Foundation of Fujian Province, China (No. 2017J01125).
CR [Anonymous], INT C MACH LEARN ICM
   [Anonymous], ARXIV170406933V3
   [Anonymous], J S CHINA U TECHNOLO
   [Anonymous], J CHINESE INFORM PRO
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T AFFECT COMPUT
   [Anonymous], 2015, ARXIV150806576V2
   [Anonymous], ARXIV161104076V3
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], ARXIV171001255
   [Anonymous], ARXIV150204623V2
   [Anonymous], COMPUTER SCI
   [Anonymous], 2015, ARXIV151106390V2
   [Anonymous], 2016, ARXIV160308155V1
   [Anonymous], 2016, ARXIV161107004V1
   [Anonymous], ARXIV161102200V1
   [Anonymous], SIGGRAPH ASIA 2016 T
   [Anonymous], 2016, ARXIV161009585
   [Anonymous], 2009, C INN APPL ART INT J
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   [Anonymous], STROKEBANK AUT PERS
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   [Anonymous], ARXIV160607536V2
   Arjovsky M., 2017, ARXIV170107875
   Cao R, 2000, INT C PATT RECOG, P368, DOI 10.1109/ICPR.2000.902935
   Chen X, 2016, NEURAL INFORM PROCES
   Denton E., 2015, ARXIV150605751
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Lyu P., 2017, ARXIV170608789
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Radford A., 2015, ARXIV
   Sicheng Zhao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P795, DOI 10.1109/ICIG.2011.181
   Simonyan K., 2014, 14091556 ARXIV
   Zhang Xiafen, 2016, Journal of Computer Aided Design & Computer Graphics, V28, P301
   Zhang XY, 2018, IEEE T PATTERN ANAL, V40, P849, DOI 10.1109/TPAMI.2017.2695539
   Zhao S, 2018, IEEE J BIOMED HEALTH, V22, P1571, DOI 10.1109/JBHI.2017.2776246
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhao Sicheng, 2016, P 24 ACM INT C MULT, P1385, DOI DOI 10.1145/2964284.2964289
NR 38
TC 11
Z9 15
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 1
BP 783
EP 797
DI 10.1007/s11042-017-5457-4
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ6QO
UT WOS:000457317500044
DA 2024-07-18
ER

PT J
AU Rehman, AU
   Liao, XF
AF Rehman, Aqeel Ur
   Liao, Xiaofeng
TI A novel robust dual diffusion/confusion encryption technique for color
   image based on Chaos, DNA and SHA-2
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 2D logistic map; Chaos theory; DNA rules; SHA-256; Color image
   encryption; Dual diffusion; confusion
ID SEQUENCE OPERATION; ALGORITHM; CRYPTANALYSIS; PERMUTATION
AB In the proposed article, a novel way of confusion is designed by introducing intra-permutation and Exclusive-OR operation with complementary DNA rules that bringsrandomness in the image. A SHA-256 hash function is used for modification of the initial conditions for 2-Dimensional Logistic map. In the 1st phase of diffusion, the rows of the three colored channels are exchanged by selecting DC-Boxes chaotically and then same operation is applied on the columns. In 2nd diffusion phase, each color channel is permuted independently using chaotic sequence. Before confusion, DNA encoding is applied at pixel level chaotically and transformed each color channel into a linear array. These three arrays are combined into a matrix of three rows and multiple columns. This matrix is divided into blocks; each of size of three DNA bases; one from each color channel and substituted by Intra-channel diffusion using DC-Boxes. In 2nd phase of confusion, matrix is transformed into a large 1D array representing DNA bases of a color image. This large array is split into groups of size of four DNA bases; representing a pixel. These groups are substituted by Exclusive-OR operation with DNA complementary rules thatselected chaotically. The proposed algorithm requires only single round of confusion/diffusion operationto achieve high quality of encryption results. This scheme is quite different for color image encryption based on DNA and has better results for different tests like NPCR, UACI, information entropy etc. Besides the larger key space, resistance against common transmission noise is another significant advantage of proposed scheme over some existing systems.
C1 [Rehman, Aqeel Ur] COMSATS Univ, Dept Comp Sci, Vehari Campus, Vehari, Pakistan.
   [Liao, Xiaofeng] Southwest Univ, Coll Elect & Informat Engn, Chongqing, Peoples R China.
C3 COMSATS University Islamabad (CUI); Southwest University - China
RP Rehman, AU (corresponding author), COMSATS Univ, Dept Comp Sci, Vehari Campus, Vehari, Pakistan.
EM rehmancqu@gmail.com
RI Rehman, Aqeel ur/R-4559-2018; Liao, Xiaofeng/HPD-6655-2023
OI Rehman, Aqeel ur/0000-0002-3083-6066; 
FU National Key Research and Development Program of China [2016YFB
   0800601]; National Natural Science Foundation of China [61472331];
   Talents of Science and Technology Promote Plan, Chongqing Science AMP;
   Technology Commission; Fundamental Research Funds for the Central
   Universities [XDJK2015C078]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016YFB 0800601, in part by the
   National Natural Science Foundation of China under Grant 61472331, in
   part by the Talents of Science and Technology Promote Plan, Chongqing
   Science & Technology Commission and in part by the Fundamental Research
   Funds for the Central Universities under Grant XDJK2015C078.
CR Ahmad M., 2009, Int. J. Comput. Sci. Eng., V2, P46
   Aqeel-ur-Rehman, 2018, OPTIK, V153, P117, DOI 10.1016/j.ijleo.2017.09.099
   Aqeel-ur-Rehman, 2016, MULTIMED TOOLS APPL, V75, P11241, DOI 10.1007/s11042-015-2851-7
   Behnia S, 2008, CHAOS SOLITON FRACT, V35, P408, DOI 10.1016/j.chaos.2006.05.011
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Biham E., 1993, Advances in Cryptology - CRYPTO '92. 12th Annual International Cryptology Conference Proceedings, P487
   Biham E., 1991, Journal of Cryptology, V4, P3, DOI 10.1007/BF00630563
   Çavusoglu Ü, 2017, CHAOS SOLITON FRACT, V95, P92, DOI 10.1016/j.chaos.2016.12.018
   Chai XL, 2017, MULTIMED TOOLS APPL, V76, P9907, DOI 10.1007/s11042-016-3585-x
   Chai XL, 2017, OPT LASER ENG, V88, P197, DOI 10.1016/j.optlaseng.2016.08.009
   Enayatifar R, 2015, OPT LASER ENG, V71, P33, DOI 10.1016/j.optlaseng.2015.03.007
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Gan ZH, 2018, MULTIMED TOOLS APPL, V77, P8759, DOI 10.1007/s11042-017-4772-0
   Gotz M, 1997, IEEE T CIRCUITS-I, V44, P963, DOI 10.1109/81.633885
   Hua ZY, 2018, SIGNAL PROCESS, V149, P148, DOI 10.1016/j.sigpro.2018.03.010
   Kalpana J, 2015, OPTIK, V126, P5703, DOI 10.1016/j.ijleo.2015.09.091
   Kulsoom A, 2016, MULTIMED TOOLS APPL, V75, P1, DOI 10.1007/s11042-014-2221-x
   Laiphrakpam DS, 2017, MULTIMED TOOLS APPL
   Li Bowen, 2017, MATH PROGRAM, P1
   Li CQ, 2016, SIGNAL PROCESS, V118, P203, DOI 10.1016/j.sigpro.2015.07.008
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Li YP, 2017, OPT LASER ENG, V90, P238, DOI 10.1016/j.optlaseng.2016.10.020
   Liu HJ, 2008, PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE FOR YOUNG COMPUTER SCIENTISTS, VOLS 1-5, P3016, DOI 10.1109/ICYCS.2008.449
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu LL, 2012, COMPUT ELECTR ENG, V38, P1240, DOI 10.1016/j.compeleceng.2012.02.007
   Luo YL, 2018, MULTIMED TOOLS APPL, V77, P26191, DOI 10.1007/s11042-018-5844-5
   Norouzi B, 2014, NONLINEAR DYNAM, V78, P995, DOI 10.1007/s11071-014-1492-0
   Norouzi B, 2014, MULTIMEDIA SYST, V20, P45, DOI 10.1007/s00530-013-0314-4
   Pak C, 2017, SIGNAL PROCESS, V138, P129, DOI 10.1016/j.sigpro.2017.03.011
   Rehman AU, 2018, OPTIK, V159, P348, DOI 10.1016/j.ijleo.2018.01.064
   Rehman AU, 2015, MULTIMED TOOLS APPL, V74, P4655, DOI 10.1007/s11042-013-1828-7
   Rhouma R, 2008, PHYS LETT A, V372, P5973, DOI 10.1016/j.physleta.2008.07.057
   Sheela S, 2018, IMAGE ENCRYPTION BAS
   Silva-García VM, 2018, APPL MATH COMPUT, V332, P123, DOI 10.1016/j.amc.2018.03.019
   Wang H, 2018, SIGNAL PROCESS, V144, P444, DOI 10.1016/j.sigpro.2017.11.005
   WATSON JD, 1953, NATURE, V171, P737, DOI 10.1038/171737a0
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wu XJ, 2015, APPL SOFT COMPUT, V37, P24, DOI 10.1016/j.asoc.2015.08.008
   Xie EY, 2017, SIGNAL PROCESS, V132, P150, DOI 10.1016/j.sigpro.2016.10.002
   Xie T, 2014, OPTIK, V125, P7166, DOI 10.1016/j.ijleo.2014.07.111
   Yavuz E, 2016, COMPUT ELECTR ENG, V54, P471, DOI 10.1016/j.compeleceng.2015.11.008
   Yen JC, 2000, IEE P-VIS IMAGE SIGN, V147, P167, DOI 10.1049/ip-vis:20000208
   Zhang Q, 2013, OPTIK, V124, P3596, DOI 10.1016/j.ijleo.2012.11.018
   Zhang XQ, 2017, COMPUT ELECTR ENG, V62, P401, DOI 10.1016/j.compeleceng.2016.12.025
   Zhang Y, 2018, INFORM SCIENCES, V450, P361, DOI 10.1016/j.ins.2018.03.055
   Zhou GM, 2015, NEUROCOMPUTING, V169, P150, DOI 10.1016/j.neucom.2014.11.095
NR 48
TC 47
Z9 47
U1 2
U2 58
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2019
VL 78
IS 2
BP 2105
EP 2133
DI 10.1007/s11042-018-6346-1
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA HJ7HD
UT WOS:000457365700037
DA 2024-07-18
ER

PT J
AU Ashwini, K
   Amutha, R
AF Ashwini, K.
   Amutha, R.
TI Fast and secured cloud assisted recovery scheme for compressively sensed
   signals using new chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaotic map; Sensing matrix; Compression; Compressive sensing; Data
   outsourcing; Security; Cloud assisted recovery
ID MEASUREMENT MATRIX; ENCRYPTION; INCOHERENCE; NETWORK; SERVICE
AB With recent advancement in Sensors technology, multimedia data has been exponentially generated every day. As a result, there is always a huge demand for fast data processing and storage. In order to effectively acquire and process such a huge amount of data, the concept of compressive sensing (CS) as well as the abundant computing and storage resources of cloud have been increasingly used nowadays. In this paper, we propose a novel secured cloud assisted recovery scheme for compressively sensed signals using a proposed new chaotic map that has wider chaotic range and better attributes when compared to existing maps. With pseudo randomness and unpredictability of the chaotic sequence, generated using the proposed chaotic map, sensing matrix for CS problem and the encryption algorithm are designed. The proposed system ensures that the data owners securely outsource the compressively sensed samples to cloud which occupies less storage. Data users then insist cloud to perform the complex reconstruction problem in an encrypted domain with substantial computational cost being shifted to cloud. Cloud performs the expensive reconstruction problem and provides the reconstructed signal in encrypted form which is later decrypted by the data users. Cloud thus gets no knowledge about the original underlying data samples ensuring privacy of the proposed system. Empirical analysis on the proposed system shows satisfactory compression and security performance on both one dimensional and two dimensional data. The simulation results prove the efficiency of the proposed cloud assisted scheme.
C1 [Ashwini, K.; Amutha, R.] SSN Coll Engn, Dept Elect & Commun, Chennai, Tamil Nadu, India.
C3 SSN College of Engineering
RP Ashwini, K (corresponding author), SSN Coll Engn, Dept Elect & Commun, Chennai, Tamil Nadu, India.
EM ashwini88.k@gmail.com
RI Amutha, R./AAB-9399-2020
OI Ashwini, K/0000-0003-1974-2162
CR Amiribesheli M, 2015, J AMB INTEL HUM COMP, V6, P495, DOI 10.1007/s12652-015-0270-2
   Ashwini K, 2018, MULTIMED TOOLS APPL, V77, P25889, DOI 10.1007/s11042-018-5824-9
   Belazi A, 2016, SIGNAL PROCESS, V128, P155, DOI 10.1016/j.sigpro.2016.03.021
   Candes E. J., 2006, PROC INT C MATH, V17, P1433, DOI DOI 10.4171/022-3/69
   Candès E, 2007, INVERSE PROBL, V23, P969, DOI 10.1088/0266-5611/23/3/008
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen F, 2016, IEEE T COMPUT, V65, P1936, DOI 10.1109/TC.2015.2456027
   Chen XF, 2015, IEEE T INF FOREN SEC, V10, P69, DOI 10.1109/TIFS.2014.2363765
   Devaraj P, 2017, OPTIK INT J LIGHT EL
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dreier J., 2011, Proceedings of the 2011 IEEE Third International Conference on Privacy, Security, Risk and Trust and IEEE Third International Conference on Social Computing (PASSAT/SocialCom 2011), P916, DOI 10.1109/PASSAT/SocialCom.2011.19
   Fan FH, 2014, FIFTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P19, DOI 10.1109/ICICIP.2014.7010279
   George SN, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0085-9
   Gibson RM, 2017, BIOMED SIGNAL PROCES, V33, P96, DOI 10.1016/j.bspc.2016.10.016
   Hu GQ, 2017, J VIS COMMUN IMAGE R, V44, P116, DOI 10.1016/j.jvcir.2017.01.022
   Hu GQ, 2017, INFORM SCIENCES, V387, P132, DOI 10.1016/j.ins.2016.09.045
   Hua ZY, 2014, IEEE SYS MAN CYBERN, P3229, DOI 10.1109/SMC.2014.6974425
   Huang ZA, 2017, INFORM SCIENCES, V412, P223, DOI 10.1016/j.ins.2017.05.031
   Li J, 2015, IEEE T PARALL DISTR, V26, P1206, DOI 10.1109/TPDS.2014.2318320
   Li J, 2015, IEEE T COMPUT, V64, P425, DOI 10.1109/TC.2013.208
   Li J, 2014, IEEE T PARALL DISTR, V25, P2201, DOI 10.1109/TPDS.2013.271
   Li P, 2017, FUTURE GENER COMP SY, V74, P76, DOI 10.1016/j.future.2017.02.006
   Lu X., 2017, IEEE T GEOSCI REMOTE
   Nazare AC, 2016, COMPUT VIS IMAGE UND, V144, P258, DOI 10.1016/j.cviu.2015.10.014
   Peng ZR, 2017, COMPUT METH PROG BIO, V145, P157, DOI 10.1016/j.cmpb.2017.04.015
   Phamila AVY, 2015, ELECTRON LETT, V51, DOI 10.1049/el.2015.0411
   Phamila YAV, 2013, INFORM PROCESS LETT, V113, P672, DOI 10.1016/j.ipl.2013.06.008
   Phamila YAV, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041107
   PINCUS S, 1995, CHAOS, V5, P110, DOI 10.1063/1.166092
   Rashid Fatema, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P569, DOI 10.1109/PST.2016.7907018
   Singh A, 2017, J NETW COMPUT APPL, V79, P88, DOI 10.1016/j.jnca.2016.11.027
   Tatlas NA, 2015, SIGNAL PROCESS, V107, P153, DOI 10.1016/j.sigpro.2014.08.012
   Verma P, 2018, J AMB INTEL HUM COMP, V9, P1293, DOI 10.1007/s12652-017-0520-6
   Wang C, 2014, IEEE INFOCOM SER, P2130, DOI 10.1109/INFOCOM.2014.6848155
   Wang C, 2013, IEEE T EMERG TOP COM, V1, P166, DOI 10.1109/TETC.2013.2273797
   Xinyu Lei, 2013, IEEE Transactions of Cloud Computing, V1, P1, DOI 10.1109/TCC.2013.7
   Yao SH, 2017, MULTIMED TOOLS APPL, V76, P17699, DOI 10.1007/s11042-015-2953-2
   Yaseen Q, 2018, MULTIMED TOOLS APPL, V77, P18249, DOI 10.1007/s11042-017-5288-3
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Yu L, 2010, IEEE SIGNAL PROC LET, V17, P731, DOI 10.1109/LSP.2010.2052243
   Yuan XL, 2016, IEEE T MULTIMEDIA, V18, P2002, DOI 10.1109/TMM.2016.2602758
   Zhang FG, 2014, INFORM SCIENCES, V286, P19, DOI 10.1016/j.ins.2014.07.017
   Zhang L, 2016, J MED SYST, V40, DOI [10.1007/s10916-016-0480-y, 10.1007/s10916-016-0644-9]
   Zhang YS, 2021, IEEE T BIG DATA, V7, P717, DOI 10.1109/TBDATA.2017.2711040
   Zhou NR, 2016, OPT LASER TECHNOL, V82, P121, DOI 10.1016/j.optlastec.2016.02.018
   Zhou NR, 2014, OPTIK, V125, P5075, DOI 10.1016/j.ijleo.2014.06.054
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
   Zhu CX, 2014, INT J SECUR APPL, V8, P61, DOI 10.14257/ijsia.2014.8.6.06
NR 51
TC 5
Z9 5
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31581
EP 31606
DI 10.1007/s11042-018-6112-4
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000003
DA 2024-07-18
ER

PT J
AU Bideh, PN
   Mahdavi, M
   Borujeni, SE
   Arasteh, S
AF Bideh, Pegah Nikbakht
   Mahdavi, Mojtaba
   Borujeni, Shahram Etemadi
   Arasteh, Sima
TI Security analysis of a key based color image watermarking vs. a non-key
   based technique in telemedicine applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital watermarking; Security analysis; QR factorization; Singular
   value decomposition; Telemedicine applications; Medical images
ID SVD
AB Recently, digital watermarking has become an important technique to preserve patients' privacy in telemedicine applications. Since, medical information are highly sensitive, security of watermarked medical images becomes a critical issue in telemedicine applications. In this paper, two targeted attacks have been proposed against a key based color image watermarking scheme and also a non-key based one, in order to evaluate their security in telemedicine applications. The target schemes are SVD-based and QR-based color image watermarking algorithms, which their embedding procedures are quit the same. The proposed attacks exploit the prior knowledge of the watermarking algorithms to make changes in the exact embedding spaces. Thus, these changes would cause disruption in extraction procedure. Our experimental results show that the key based watermarking scheme is more secure than the non-key based one. This is because the proposed targeted attack needs to distort the key based watermarked images more than non-key based ones to remove the embedded watermarks. Our proposed targeted attacks also have more efficient performance in removing watermarks than other general attacks such as JPEG compression, Gaussian noise and etc. Finally, these attacks have been proposed to show the vulnerabilities of watermarking schemes in order to help the designers to implement more secure schemes.
C1 [Bideh, Pegah Nikbakht; Mahdavi, Mojtaba; Borujeni, Shahram Etemadi; Arasteh, Sima] Univ Isfahan, Dept Comp Engn, Esfahan, Iran.
C3 University of Isfahan
RP Bideh, PN (corresponding author), Univ Isfahan, Dept Comp Engn, Esfahan, Iran.
EM Pegah_niky@yahoo.com; M.mahdavi@eng.ui.ac.ir; Etemadi@eng.ui.ac.ir;
   S.arasteh@eng.ui.ac.ir
RI etemadi, shahram/ABF-3797-2021; Mahdavi, Mojtaba/G-7565-2019
OI etemadi, shahram/0000-0002-0959-3952; 
CR Ali M, 2014, OPTIK, V125, P428, DOI 10.1016/j.ijleo.2013.06.082
   Baker K, 2005, SINGULAR VALUE DECOM
   Calagna M., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P1341, DOI 10.1145/1141277.1141590
   Cox IJ., 2007, DIGITAL WATERMARKING
   Huang FJ, 2004, PATTERN RECOGN LETT, V25, P1769, DOI 10.1016/j.patrec.2004.07.003
   Lai CC, 2011, OPT COMMUN, V284, P938, DOI 10.1016/j.optcom.2010.10.047
   Ling HC, 2011, LECT NOTES COMPUT SC, V7087, P257, DOI 10.1007/978-3-642-25367-6_23
   Loukhaoukha K., 2015, INT J APPL MATH INFO, V9, P1159, DOI [10.12785/amis/090307, DOI 10.12785/AMIS/090307]
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Meerwald P, 2009, IEEE T MULTIMEDIA, V11, P1037, DOI 10.1109/TMM.2009.2021793
   Mehta AK, 2013, 2013 INT C POW EN CO
   Mehta S, 2013, HEALTHC INF ICHI 201
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Nikbakht P., 2015, COMP KNOWL ENG ICCKE
   Nikbakht P, 2015, 2015 7th Conference on Information and Knowledge Technology (IKT)
   Pomponiu Victor, 2011, International Journal of Multimedia Intelligence and Security, V2, P120, DOI 10.1504/IJMIS.2011.041362
   Rey C, 2002, IM PROC 2002 P 2002, P3
   Rezazadeh S, 2006, P WORLD ACAD SCI ENG, P13
   Sadicoff M, 2004, SEC LACCEI INT LAT A
   Song C., 2010, CONS COMM NETW C CCN
   Song W, 2011, J CENT SOUTH UNIV T, V18, P116, DOI 10.1007/s11771-011-0668-8
   Su QT, 2014, SIGNAL PROCESS, V94, P219, DOI 10.1016/j.sigpro.2013.06.025
   Su QT, 2013, APPL MATH COMPUT, V219, P8455, DOI 10.1016/j.amc.2013.03.013
   Sun S, 2009, IM AN SIGN PROC 2009
   Voloshynovskiy S, 2001, IEEE COMMUN MAG, V39, P118, DOI 10.1109/35.940053
   Zhou X, 2013, SENS NETW SEC TECHN
NR 26
TC 4
Z9 4
U1 1
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 24
BP 31713
EP 31735
DI 10.1007/s11042-018-6218-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ9QN
UT WOS:000449836000009
DA 2024-07-18
ER

PT J
AU Ebrahimi, A
   Loghmani, GB
AF Ebrahimi, A.
   Loghmani, G. Barid
TI Shape modeling based on specifying the initial B-spline curve and scaled
   BFGS optimization method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Geometric modeling; Curve fitting; Initial B-spline curve; Optimization
   method; Scaled BFGS method
ID QUASI-NEWTON METHODS; CAPTURING OUTLINES; GENETIC-ALGORITHM; MATRIX
   ALGEBRAS; BEZIER; APPROXIMATION; INTERPOLATION; COMPUTATION; POINTS;
   ENERGY
AB In this paper, we consider the problem of fitting the B-spline curves to a set of ordered points, by finding the control points and the location parameters. The presented method takes two main steps: specifying initial B-spline curve and optimization. The method determines the number and the position of control points such that the initial B-spline curve is very close to the target curve. The proposed method introduces a length parameter in which this allows us to adjust the number of the control points and increases the precision of the initial B-spline curve. Afterwards, the scaled BFGS algorithm is used to optimize the control points and the foot points simultaneously and generates the final curve. Furthermore, we present a new procedure to insert a new control point and repeat the optimization method, if it is necessary to modify the fitting accuracy of the generated B-spline fitting curve. Associated examples are also offered to show that the proposed approach performs accurately for complex shapes with a large number of data points and is able to generate a precise fitting curve with a high degree of approximation.
C1 [Ebrahimi, A.; Loghmani, G. Barid] Yazd Univ, Fac Math Sci, Comp Geometry & Dynam Syst Lab, Yazd, Iran.
C3 University of Yazd
RP Loghmani, GB (corresponding author), Yazd Univ, Fac Math Sci, Comp Geometry & Dynam Syst Lab, Yazd, Iran.
EM a.ebrahimi@stu.yazd.ac.ir; loghmani@yazd.ac.ir
RI Ebrahimi, Alireza/R-6799-2019
OI Ebrahimi, Alireza/0000-0001-9023-5812
CR Andrei N, 2017, NUMER ALGORITHMS, V77, P1
   Bergstrom P, 2012, INT J MATH MODELLING, V3, P319, DOI [10.1504/IJMMNO.2012.049600, DOI 10.1504/IJMMNO.2012.049600]
   Bergström P, 2012, BIT, V52, P571, DOI 10.1007/s10543-012-0371-7
   Bhimani J, 2017, IEEE HIGH PERF EXTR
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Borges CF, 2002, COMPUT AIDED GEOM D, V19, P275, DOI 10.1016/S0167-8396(02)00088-2
   Broyden C. G., 1970, Journal of the Institute of Mathematics and Its Applications, V6, P222
   Carlier A, 2016, COMPUT GRAPH-UK, V58, P23, DOI 10.1016/j.cag.2016.05.009
   Carlson N, 2008, WSEAS INT C P MATH C, P13
   Cheng WY, 2010, J OPTIMIZ THEORY APP, V146, P305, DOI 10.1007/s10957-010-9652-y
   Deng CY, 2014, COMPUT AIDED DESIGN, V47, P32, DOI 10.1016/j.cad.2013.08.012
   Di Fiore C, 2003, NUMER MATH, V94, P479, DOI 10.1007/s00211-002-0410-4
   Di Fiore C, 2001, LINEAR ALGEBRA APPL, V335, P1, DOI 10.1016/S0024-3795(00)00137-3
   Ebrahimi A, 2019, IRAN J SCI TECHNOL A, V43, P947, DOI 10.1007/s40995-017-0347-1
   Farin G.E., 2002, Curves and Surfaces for CAGD: A Practical Guide
   FLETCHER R, 1970, COMPUT J, V13, P317, DOI 10.1093/comjnl/13.3.317
   Gálvez A, 2016, APPL MATH COMPUT, V275, P195, DOI 10.1016/j.amc.2015.11.050
   Gálvez A, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/528215
   Gálvez A, 2013, SCI WORLD J, DOI 10.1155/2013/283919
   Gálvez A, 2013, APPL SOFT COMPUT, V13, P1491, DOI 10.1016/j.asoc.2012.05.030
   Gálvez A, 2011, COMPUT AIDED DESIGN, V43, P1683, DOI 10.1016/j.cad.2011.07.010
   Gálvez A, 2012, INFORM SCIENCES, V182, P56, DOI 10.1016/j.ins.2010.09.031
   Gill PE, 2001, SIAM J OPTIMIZ, V12, P209, DOI 10.1137/S1052623400307950
   GOLDFARB D, 1970, MATH COMPUT, V24, P23, DOI 10.2307/2004873
   Goshtasby AA, 2000, ACM T GRAPHIC, V19, P185, DOI 10.1145/353981.353992
   Hasegawa A. Y., 2014, INT J COMPUT SCI APP, V11, P1
   Hoschek J., 1988, Computer-Aided Geometric Design, V5, P27, DOI 10.1016/0167-8396(88)90017-9
   Hoschek J., 1988, Computer-Aided Geometric Design, V5, P33, DOI 10.1016/0167-8396(88)90018-0
   Hoschek J., 1993, FUNDAMENTALS COMPUTE
   Iglesias A, 2016, LECT NOTES COMPUT SC, V9590, P127, DOI 10.1007/978-3-662-53090-0_7
   Irshad M, 2016, APPL MATH COMPUT, V274, P661, DOI 10.1016/j.amc.2015.10.014
   Isard M., 1998, ACTIVE CONTOURS
   Javidrad F, 2012, INT J CAD CAM, V12, P9
   Khan MA, 2012, SIGNAL IMAGE VIDEO P, V6, P19, DOI 10.1007/s11760-010-0165-9
   LAURENTGENGOUX P, 1993, COMPUT AIDED DESIGN, V25, P699, DOI 10.1016/0010-4485(93)90011-C
   Leu MC, 2005, CIRP ANN-MANUF TECHN, V54, P131, DOI 10.1016/S0007-8506(07)60066-3
   Liu H, 2015, CALCOLO, V52, P233, DOI 10.1007/s10092-014-0115-y
   Liu Y, 2008, LECT NOTES COMPUT SC, V4975, P384
   LU F, 1994, SIGNAL PROCESS, V37, P129, DOI 10.1016/0165-1684(94)90171-6
   Masood A, 2009, IMAGE VISION COMPUT, V27, P704, DOI 10.1016/j.imavis.2008.07.012
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Park H, 2001, COMPUT AIDED DESIGN, V33, P967, DOI 10.1016/S0010-4485(00)00133-0
   Park H, 2007, COMPUT AIDED DESIGN, V39, P439, DOI 10.1016/j.cad.2006.12.006
   Piegl L., 2012, The NURBS book
   Piegl LA, 2000, VISUAL COMPUT, V16, P386, DOI 10.1007/PL00013393
   Plass M., 1983, COMPUT GRAPH, V17, P229
   Pottmann H, 2003, VISUALIZATION AND MATHEMATICS III, P221
   Pottmann H, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P8, DOI 10.1109/PCCGA.2002.1167835
   Prasad M., 2006, Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1345
   ROGERS DF, 1989, COMPUT AIDED DESIGN, V21, P641, DOI 10.1016/0010-4485(89)90162-0
   Sarfraz M, 2007, COMPUT GRAPH-UK, V31, P719, DOI 10.1016/j.cag.2007.05.002
   Sarfraz M, 2006, J COMPUT APPL MATH, V189, P494, DOI 10.1016/j.cam.2005.10.005
   Sarkar B., 1991, Computer-Aided Geometric Design, V8, P267, DOI 10.1016/0167-8396(91)90016-5
   Sato H., 2001, US Patent, Patent No. [6,304,133, 6304133]
   Saux E, 2003, COMPUT AIDED GEOM D, V20, P513, DOI 10.1016/j.cagd.2003.06.004
   Sevaux M, 2007, EUR J OPER RES, V179, P895, DOI 10.1016/j.ejor.2005.03.065
   SHANNO DF, 1970, MATH COMPUT, V24, P647, DOI 10.2307/2004840
   Speer T, 1998, COMPUT AIDED GEOM D, V15, P869, DOI 10.1016/S0167-8396(98)00024-7
   Vassilev TI, 1996, COMPUT AIDED DESIGN, V28, P753, DOI 10.1016/0010-4485(95)00087-9
   Wang WP, 2006, ACM T GRAPHIC, V25, P214, DOI 10.1145/1138450.1138453
   Wang XF, 1997, COMPUT AIDED DESIGN, V29, P485, DOI 10.1016/S0010-4485(96)00087-5
   Yang HP, 2004, COMPUT AIDED DESIGN, V36, P639, DOI 10.1016/S0010-4485(03)00140-4
   Yang YJ, 2008, COMPUT AIDED DESIGN, V40, P223, DOI 10.1016/j.cad.2007.10.011
   Yang Z, 2017, 36 IEEE INT PERF COM
   Yang Z, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/7364216
   Yoshimoto F, 2003, COMPUT AIDED DESIGN, V35, P751, DOI 10.1016/S0010-4485(03)00006-X
   Yoshimoto F, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P162, DOI 10.1109/SMA.1999.749336
   YUAN YX, 1991, IMA J NUMER ANAL, V11, P325, DOI 10.1093/imanum/11.3.325
   Zhao XY, 2011, COMPUT AIDED DESIGN, V43, P598, DOI 10.1016/j.cad.2011.01.015
   Zheng WN, 2012, COMPUT AIDED GEOM D, V29, P448, DOI 10.1016/j.cagd.2012.03.004
NR 70
TC 11
Z9 11
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30331
EP 30351
DI 10.1007/s11042-018-6109-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600009
DA 2024-07-18
ER

PT J
AU Yasakethu, SLP
   Hewage, CTER
AF Yasakethu, S. L. P.
   Hewage, C. T. E. R.
TI Efficient decoding algorithm for 3D video over wireless channels
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D video; DVC; Wireless channels; Quality of Experience (QoE)
AB In wireless communication networks, additive channel noise and time varying multipath fading are considered amongst the main challenges and these effects will bring significant quality degradation to the transmitted 2D/3D video streams. This paper presents an efficient decoding algorithm for Distributed Video Coding (DVC) for enhanced performance of colour and depth based 3D video over error prone wireless channels. The maximum a-posteriori (MAP) algorithm for turbo decoding is modified considering the effects of the channel errors on both Wyner-Ziv and key frame bit streams of colour and depth videos. The proposed codec is simulated using a W-CDMA wireless channel model and the results are analyzed to determine the effect of the modifications. The performance of the state-of-the-art H.264/AVC video codec is also presented for comparison under similar conditions. The results show that the proposed modifications provide a significant improvement in the DVC codec performance under unfavourable channel conditions for colour plus depth based 3D video.
C1 [Yasakethu, S. L. P.] SLTC, Dept Elect Elect & Comp Sci, Padukka, Sri Lanka.
   [Hewage, C. T. E. R.] Cardiff Metropolitan Univ, Cardiff Sch Technol, Cardiff, S Glam, Wales.
C3 Cardiff Metropolitan University
RP Hewage, CTER (corresponding author), Cardiff Metropolitan Univ, Cardiff Sch Technol, Cardiff, S Glam, Wales.
EM lasithy@sltc.edu.lk; chewage@cardiffmet.ac.uk
RI Yasakethu, S L P/IAQ-4138-2023; E. R. Hewage, Chaminda T./AAJ-3221-2020
OI Yasakethu, S L P/0000-0002-9571-6866; E. R. Hewage, Chaminda
   T./0000-0001-7593-6661
CR [Anonymous], ERROR CONTROL CODING
   [Anonymous], PICT COD S LISB PORT
   [Anonymous], P IEEE GLOB 1998
   [Anonymous], P AS C SIGN SYST PAC
   [Anonymous], D1 ATTEST
   [Anonymous], P IEEE ICASSP
   [Anonymous], PERCEPTUAL QUALITY D
   [Anonymous], BT50013 ITUR
   Bhimani J, 2017, IEEE HIGH PERF EXTR
   Bhimani J, 2017, IEEE INT CONF CLOUD, P359, DOI 10.1109/CLOUD.2017.53
   Guillemot C, 2007, IEEE SIGNAL PROC MAG, V24, P67, DOI 10.1109/MSP.2007.904808
   Hewage C. T. E. R., 2008, THESIS
   Hewage CTER, 2009, IEEE J-STSP, V3, P304, DOI 10.1109/JSTSP.2009.2014805
   Montalbano G, 2003, IEEE VTS VEH TECHNOL, P1253, DOI 10.1109/VETECF.2003.1285223
   Ouaret M., 2006, Proc. ACM Int. Workshop on Video Surveillance and Sensor Networks, P139, DOI DOI 10.1145/1178782.1178803
   Yang JH, 2017, 2017 31ST IEEE INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS WORKSHOPS (IEEE WAINA 2017), P1, DOI [10.1109/ULTSYM.2017.8092547, 10.1109/WAINA.2017.29]
   Yang Z, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/7364216
   Yasakethu SLP, 2008, IEEE T CONSUM ELECTR, V54, P1969, DOI 10.1109/TCE.2008.4711260
NR 18
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2018
VL 77
IS 23
BP 30683
EP 30701
DI 10.1007/s11042-018-6157-4
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY2VI
UT WOS:000448401600025
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU An, J
   Zhao, SZ
   Lu, XN
   Liu, NN
AF An, Jun
   Zhao, Songzheng
   Lu, Xiaoni
   Liu, Ningning
TI A two-stage multiple-factor aware method for travel product
   recommendation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Travel product recommendation; Two-stage recommendation; Multiple-factor
   aware; Sparsity; Complexity
ID MATRIX FACTORIZATION MODEL; TOURISM; SYSTEMS; ALGORITHMS
AB The great quantity of travel products available online has increased demand for travel product recommendation system. Due to the relatively high value and time cost of travel products, users consider more factors (personal preference, social preference and seasonality factor etc.) in making this type of low-frequent purchase decisions, compared to other products (e.g. music, movies or news). Thus, recommending travel products generally faces sparsity and complexity problems. In this study, we propose a two-stage multiple-factor aware method named TSMFA. In the topic stage, a user-topic matrix is constructed using travel products' topic attributions to alleviate sparsity problem, while a preference-aware topic selection is introduced to consider both social and personal preference in recommendation. In the product stage, seasonal prevalence is employed to adjust the recommended product order to incorporate seasonality factor. The proposed method is validated with real transaction dataset from a leading OTA (Online Travel Agent) website in western China. The experimental results demonstrate that it outperforms the state-of-the-art recommendation methods in terms of effectiveness and usefulness.
C1 [An, Jun] Northwestern Polytech Univ, Sch Management, Management Sci & Engn, Xian, Shaanxi, Peoples R China.
   [Zhao, Songzheng] Northwestern Polytech Univ, Sch Management, Xian, Shaanxi, Peoples R China.
   [Lu, Xiaoni] Xi An Jiao Tong Univ, Sch Management, Management Sci & Engn, Xian, Shaanxi, Peoples R China.
   [Liu, Ningning] Univ Int Business & Econ, Sch Informat Technol & Management, Beijing, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University; Xi'an Jiaotong University; University of International
   Business & Economics
RP Lu, XN (corresponding author), Xi An Jiao Tong Univ, Sch Management, Management Sci & Engn, Xian, Shaanxi, Peoples R China.
EM AJ369@126.com; zhaosongzheng@263.com; luxiaoni1204@stu.xjtu.edu.cn;
   ningning.liu@uibe.edu.cn
RI Ningning, Liu/I-8438-2018
OI Ningning, Liu/0000-0001-5471-9625
FU National Nature Science Foundation of China [91746111, 71702143];
   Ministry of Education & China Mobile Joint Research Fund Program
   [MCM20160302]; Shaanxi provincial development and Reform Commission
   [SFG2016789]; Xi'an Municipal Science & Technology Commission
   [2017111SF/RK005-(7)]; Natural Science Foundation of Shaanxi
   [2017JQ7004]; China Postdoctoral Science Fund [2016M602840]
FX This work is supported by the National Nature Science Foundation of
   China (Grant No. 91746111, Grant No. 71702143), Ministry of Education &
   China Mobile Joint Research Fund Program (No. MCM20160302), Shaanxi
   provincial development and Reform Commission (No. SFG2016789), Xi'an
   Municipal Science & Technology Commission (No. 2017111SF/RK005-(7)),
   Natural Science Foundation of Shaanxi (NO. 2017JQ7004), China
   Postdoctoral Science Fund (No. 2016M602840).
CR Agrawal S, 2016, P 2 INT C INF COMM T, P21
   [Anonymous], 2004, Proceedings of the international ACM SIGIR conference on Research and development in information retrieval(SIGIR), DOI [10.1145/1008992.1009051, DOI 10.1145/1008992.1009051]
   [Anonymous], 2000, Tech. Rep.
   Barragáns-Martínez AB, 2010, INFORM SCIENCES, V180, P4290, DOI 10.1016/j.ins.2010.07.024
   Bokde D, 2015, PROCEDIA COMPUT SCI, V49, P136, DOI 10.1016/j.procs.2015.04.237
   Borràs J, 2014, EXPERT SYST APPL, V41, P7370, DOI 10.1016/j.eswa.2014.06.007
   Breese J. S., 1998, Uncertainty in Artificial Intelligence. Proceedings of the Fourteenth Conference (1998), P43
   Burke R, 2002, USER MODEL USER-ADAP, V12, P331, DOI 10.1023/A:1021240730564
   Cui L, 2017, FUTURE GENERATION CO
   De Pessemier T, 2017, MULTIMED TOOLS APPL, V76, P2787, DOI 10.1007/s11042-016-3265-x
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Foster D. P., 1998, AAAI WORKSH REC SYST, P114
   Ge Y., 2011, Proceedings of the 17th ACM SIGKDD international con- ference on Knowledge discovery and data mining, P983, DOI DOI 10.1145/2020408.2020568
   Ge Y, 2014, ACM T INFORM SYST, V32, DOI 10.1145/2559169
   Gui-Rong Xue, 2005, SIGIR 2005. Proceedings of the Twenty-Eighth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P114
   Herlocker JL, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P230, DOI 10.1145/312624.312682
   Khoshgoftaar T.M., 2009, ADV ARTIFICIAL INTEL, DOI [10.1155/2009/421425, DOI 10.1155/2009/421425]
   Li H., 2016, P 2016 SIAM INT C DA, P117
   Li YM, 2017, DECIS SUPPORT SYST, V94, P97, DOI 10.1016/j.dss.2016.11.004
   Liu Q, 2014, IEEE T KNOWL DATA EN, V26, P278, DOI 10.1109/TKDE.2012.233
   Lucas JP, 2013, EXPERT SYST APPL, V40, P3532, DOI 10.1016/j.eswa.2012.12.061
   LUNDTORP S., 2001, Seasonality in tourism, P23, DOI [DOI 10.1016/B978-0-08-043674-6.50006-4, 10.1016/B978-0-08-043674-6.50006-4]
   MOUTINHO L, 1987, EUR J MARKETING, V21, P1, DOI 10.1108/EUM0000000004718
   Paunovic I, 2014, FACULTY TOURISM HOSP, P601
   Qi Liu, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P407, DOI 10.1109/ICDM.2011.118
   Ren XY, 2017, NEUROCOMPUTING, V241, P38, DOI 10.1016/j.neucom.2017.02.005
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Ricci F, 2002, IEEE INTELL SYST, V17, P55
   Sarwar B., 2001, P 10 INT C WORLD WID, P285, DOI 10.1145/371920.372071
   Tan F, 2016, PATTERN ANAL APPL, V19, P857, DOI 10.1007/s10044-015-0510-2
   Vargas S., 2011, P 5 ACM C RECOMMENDE, P109, DOI DOI 10.1145/2043932.2043955
   Verma SK, 2013, 2013 4TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER & COMMUNICATION TECHNOLOGY (ICCCT), P116, DOI 10.1109/ICCCT.2013.6749613
   Wang J., 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P501, DOI 10.1145/1148170.1148257
   Yun YD, 2018, J INF SCI, V44, P331, DOI 10.1177/0165551517692955
   Zhang H, 2018, MULTIMED TOOLS APPL, V77, P4187, DOI 10.1007/s11042-017-4553-9
   Zhang Y, 2013, KNOWL-BASED SYST, V54, P310, DOI 10.1016/j.knosys.2013.09.018
   Zhu GX, 2017, MULTIMED TOOLS APPL, V76, P17595, DOI 10.1007/s11042-017-4406-6
NR 37
TC 6
Z9 7
U1 1
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28991
EP 29012
DI 10.1007/s11042-018-5992-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500051
DA 2024-07-18
ER

PT J
AU Li, X
   Makihara, Y
   Xu, C
   Yagi, Y
   Ren, MW
AF Li, Xiang
   Makihara, Yasushi
   Xu, Chi
   Yagi, Yasushi
   Ren, Mingwu
TI Gait-based human age estimation using age group-dependent manifold
   learning and regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human age estimation; Age group classification; Support vector
   regression; Manifold learning
ID RECOGNITION; CLASSIFICATION; PERFORMANCE; IMAGE
AB Human age estimation from gait is expected to be an important technology for a variety of applications such as automatic customer counting for marketing research or automatic age-based access control restriction for a specific area because the gait can be observable at a distance from a camera (e.g., CCTV). Although the aging process of gait significantly differs among age groups (e.g., children, adults, and the elderly), previous studies on gait-based human age estimation employ a single age group-independent estimation model that suffers from large estimation errors when the age variation increases. We therefore propose an age group-dependent gait-based human age estimation method for better accuracy. Specifically, in the training phase, we first compose age groups that are well-separated from each other by clustering gait features along with their age labels. We then learn a classifier that classifies the gait features for multiple age groups using a directed acyclic graph support vector machine. Next, we learn an age regression model for each age group using support vector regression with a Gaussian kernel in conjunction with a manifold learning technique, i.e., orthogonal locality preserving projection, to better characterize the gait feature. In the test phase, given a gait feature, it is first classified into an age group and then its age is estimated with the age regression model of the classified age group. Experimental results on a gait database that has the world's largest population of participants ranging from 2 to 90 years old demonstrate the state-of-the-art performance of the proposed method.
C1 [Li, Xiang; Xu, Chi; Ren, Mingwu] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Jiangsu, Peoples R China.
   [Li, Xiang; Makihara, Yasushi; Xu, Chi; Yagi, Yasushi] Osaka Univ, Inst Sci & Ind Res, Osaka 5670046, Japan.
C3 Nanjing University of Science & Technology; Osaka University
RP Makihara, Y (corresponding author), Osaka Univ, Inst Sci & Ind Res, Osaka 5670046, Japan.
EM lixiangmzlx@gmail.com; makihara@am.sanken.osaka-u.ac.jp;
   xuchisherry@gmail.com; yagi@am.sanken.osaka-u.ac.jp;
   renmingwu@mail.njust.edu.cn
RI Li, Xiang/HNQ-3047-2023
OI Li, Xiang/0000-0002-8044-7050
FU JSPS [JP16H02848, JP15H01693]; JST CREST "Behavior Understanding based
   on Intention-Gait Model" project; National Natural Science Foundation of
   China [61231014, 61403202]
FX This work was supported by JSPS Grants-in-Aid for Scientific Research
   (B) JP16H02848, (A) JP15H01693, the JST CREST "Behavior Understanding
   based on Intention-Gait Model" project and the National Natural Science
   Foundation of China (Grants 61231014, 61403202). We thank Kim Moravec,
   PhD, from Edanz Group for editing a draft of this manuscript
   (www.edanzediting.com/ac).
CR [Anonymous], 2010, IEEE COMPUTER SOC IE
   [Anonymous], 2016, ASIAN C COMPUTER VIS
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 2010, P 10 AS C COMP VIS Q
   Begg RK, 2005, IEEE T BIO-MED ENG, V52, P828, DOI 10.1109/TBME.2005.845241
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chang KY, 2015, IEEE T IMAGE PROCESS, V24, P785, DOI 10.1109/TIP.2014.2387379
   Chuen BKY, 2015, ASIAPAC SIGN INFO PR, P800, DOI 10.1109/APSIPA.2015.7415382
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Davis JW, 2001, VISUAL CATEGORIZATIO, P295
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Ince Omer F., 2014, International Journal of Computer and Communication Engineering, V3, P120, DOI 10.7763/IJCCE.2014.V3.304
   Iwama H, 2013, Information and Media Technologies, V5, P163
   Iwama H, 2012, IEEE T INF FOREN SEC, V7, P1511, DOI 10.1109/TIFS.2012.2204253
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Lu JW, 2010, IEEE T INF FOREN SEC, V5, P761, DOI 10.1109/TIFS.2010.2069560
   Lynnerup N, 2014, IET BIOMETRICS, V3, P47, DOI 10.1049/iet-bmt.2013.0090
   Makihara Y., 2008, P 19 INT C PATT REC
   Makihara Y., 2011, 2011 INT JOINT C BIO, P1, DOI 10.1109/IJCB.2011.6117531
   Makihara Y., 2016, PROC INT C BIOMETRIC, P1
   Makihara Y, 2006, LECT NOTES COMPUT SC, V3953, P151, DOI 10.1007/11744078_12
   Miljkovic D, 2016, LECT NOTES COMPUT SC, V9605, P209, DOI 10.1007/978-3-319-50478-0_10
   Nabila M, 2018, IET BIOMETRICS, V7, P116, DOI 10.1049/iet-bmt.2016.0176
   Nixon MS, 2005, HUMAN IDENTIFIACTION
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Punyani P, 2018, INT J IMAGE DATA FUS, P1
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xu C., 2017, IPSJ TCVA, V9, P24, DOI DOI 10.1186/S41074-017-0035-2
   Xu C, 2016, P AS C COMP VIS, P52
   Zhang Y, 2010, P IEEE COMP SOC C CO, P1
NR 40
TC 22
Z9 24
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 28333
EP 28354
DI 10.1007/s11042-018-6049-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500024
OA hybrid
DA 2024-07-18
ER

PT J
AU Lipus, B
   Zalik, B
AF Lipus, Bogdan
   Zalik, Borut
TI Robust watermarking of airborne LiDAR data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D point-sampled geometry; Digital watermarking; Security; 3D point
   cloud authentication and identification; Data hiding; Light Detection
   And Ranging (LiDAR)
ID POINT; COMPRESSION
AB This paper presents a novel robust approach developed specially for watermarking airborne LiDAR data, which consist of a large cloud of geo-referenced points and has some unique characteristics. The approach consists of the following steps: (1) Defining the marker circular areas, in which the watermark bit will be embedded; (2) Dividing the marker circular areas uniformly into smaller circular areas by applying the sunflower seed distribution algorithm; (3) Using the points in these smaller circular areas to construct the input values for the Discrete Cosine Transformation (DCT); (4) Changing the last DCT coefficient; (5) Perform Inverse Discrete Cosine Transformation (IDCT), and perturbing the points within smaller circular areas according to the output values from this inverse transformation. Applying our approach, the watermark was dispersed into a set of points within the marker circular areas. The watermark bits are embedded multiple times in different marker circular areas. Thus, the robustness of the watermark was increased against various attacks. The watermark extraction process is practically the same, except in the final step, in which only the sign of each last DCT coefficient is checked, and decisions are made about the value of the watermark bits. Several experiments were performed to analyse the robustness of our watermarking schema against the most probable attacks.
C1 [Lipus, Bogdan; Zalik, Borut] Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, SI-2000 Maribor, Slovenia.
C3 University of Maribor
RP Lipus, B (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Koroska Cesta 46, SI-2000 Maribor, Slovenia.
EM bogdan.lipus@um.si
RI Žalik, Borut/X-1320-2019; Lipus, Bogdan/Z-6203-2019
OI Lipus, Bogdan/0000-0001-6529-4263
FU Slovenian Research Agency [P2-0041, J2-6764]
FX This work was supported by the Slovenian Research Agency under Grants
   P2-0041 and J2-6764.
CR Agarwal P, 2009, IEEE T INF FOREN SEC, V4, P36, DOI 10.1109/TIFS.2008.2011081
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Cotting D, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P233, DOI 10.1109/SMI.2004.1314510
   Cox IJ., 2007, DIGITAL WATERMARKING
   Dugelay Jean-Luc., 2008, 3D Object Processing: Compression, Indexing and Watermarking
   Gao XF, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2344436.2344440
   Gao XF, 2010, MM&SEC 2010: 2010 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, PROCEEDINGS, P137
   Horvat D, 2016, ISPRS J PHOTOGRAMM, V116, P1, DOI 10.1016/j.isprsjprs.2016.02.011
   Isenburg M, 2013, PHOTOGRAMM ENG REM S, V79, P209, DOI 10.14358/PERS.79.2.209
   Lipus B, 2012, ELECTRON LETT, V48, P1267, DOI 10.1049/el.2012.1080
   Lipus B, 2015, REMOTE SENS LETT, V6, P190, DOI 10.1080/2150704X.2015.1022267
   Lukac N., 2015, GPU COMPUTING APPL, P221, DOI DOI 10.1007/978-981-287-134-3_14
   Luo H, 2006, 2006 IEEE International Symposium on Signal Processing and Information Technology, Vols 1 and 2, P863, DOI 10.1109/ISSPIT.2006.270919
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Mongus D, 2014, ISPRS J PHOTOGRAMM, V93, P145, DOI 10.1016/j.isprsjprs.2013.12.002
   Mongus D, 2011, INT J REMOTE SENS, V32, P2507, DOI 10.1080/01431161003698385
   Muja M., 2012, 2012 Canadian Conference on Computer and Robot Vision, P404, DOI 10.1109/CRV.2012.60
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Prusinkiewicz P., 2012, e algorithmic beauty of plants, DOI DOI 10.1007/978-1-4613-8476-2
   Qi K., 2013, INT INFORM I, V16, P3621
   Qi K, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 1, P287, DOI 10.1109/WCINS.2010.5541785
   Rupnik B, 2015, J UNIVERS COMPUT SCI, V21, P587
   Shan J., 2009, Topographic Laser Ranging and Scanning: Principles and Processing
   Shih F.Y., 2007, DIGITAL WATERMARKING
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   VOGEL H, 1979, MATH BIOSCI, V44, P179, DOI 10.1016/0025-5564(79)90080-4
   Wang CM, 2006, COMPUT GRAPH-UK, V30, P244, DOI 10.1016/j.cag.2006.01.030
   Wang CM, 2005, IEICE T COMMUN, VE88B, P190, DOI 10.1093/ietcom/E88-B.1.190
   Wang K, 2008, IEEE T MULTIMEDIA, V10, P1513, DOI 10.1109/TMM.2008.2007350
   Wang PC, 2007, J INF SCI ENG, V23, P1889
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 36
TC 5
Z9 5
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2018
VL 77
IS 21
BP 29077
EP 29097
DI 10.1007/s11042-018-6039-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GW1AL
UT WOS:000446601500055
DA 2024-07-18
ER

PT J
AU Dahmouni, A
   El Moutaouakil, K
   Satori, K
AF Dahmouni, Abdellatif
   El Moutaouakil, Karim
   Satori, Khalid
TI Face description using electric virtual binary pattern (EVBP):
   application to face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LBP; Virtual electric field; Fictitious charges; eLBPH; EVBP
ID 2-DIMENSIONAL PCA; LEVEL FUSION; 2DPCA
AB In this paper, we present a novel efficient face description method called Electric Virtual Binary Pattern (EVBP). The main idea of EVBP descriptor is to combine Local Binary Pattern (LBP) and our new Model based on the Virtual Electric Field. This model consider the neighborhood of each pixel as a grid of virtual electric charges that are electrostatically balanced. Then, we apply the LBP principle for this neighborhood to generate the new EVBP pixel representation. Based on the four trivial space directions, this representation is computed using the corresponding four electrical interactions. Moreover, the spatially enhanced Local Binary Pattern Histogram (eLBPH) algorithm is employed to extract features. Therefore, the proposed EVBP descriptor led to reduce the features vector size by 93.75%. Consequently, we moved from 255 bin-histograms for LBP to 16 bin-histograms for EVBP descriptor. Extensive experiments were carried on relevant databases have proved the effectiveness of the proposed approach.
C1 [Dahmouni, Abdellatif; Satori, Khalid] Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, LIIAN, BP 1796, Atlas Fez 30000, Fez, Morocco.
   [El Moutaouakil, Karim] Mohamed1 Univ, Polydisciplinary Fac Nador, AICSMT, Nador, Morocco.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed First University
   of Oujda
RP Dahmouni, A (corresponding author), Sidi Mohamed Ben Abdellah Univ, Fac Sci Dhar Mahraz, LIIAN, BP 1796, Atlas Fez 30000, Fez, Morocco.
EM abdellatif.dahmouni@usmba.ac.ma
RI satori, khalid/GSE-3077-2022
OI Dahmouni, Abdellatif/0000-0002-1636-439X; El moutaouakil,
   Karim/0000-0003-3922-5592; SATORI, khalid/0000-0001-6055-4169
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Albiol A, 2008, PATTERN RECOGN LETT, V29, P1537, DOI 10.1016/j.patrec.2008.03.017
   [Anonymous], INT ACAD J SCI ENG
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Dahmouni A, 2016, LECT NOTES ELECTR EN, V380, P277, DOI 10.1007/978-3-319-30301-7_29
   Dahmouni A, 2016, I C COMP GRAPH IM VI, P73, DOI 10.1109/CGiV.2016.23
   Déniz O, 2003, PATTERN RECOGN LETT, V24, P2153, DOI 10.1016/S0167-8655(03)00081-3
   Dornaika F, 2016, ADV FACE IMAGE ANAL
   Forczmanski P, 2015, LECT NOTES COMPUT SC, V9164, P229, DOI 10.1007/978-3-319-20801-5_25
   Geng C, 2011, PATTERN RECOGN, V44, P2565, DOI 10.1016/j.patcog.2011.03.011
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Houam L, 2014, PATTERN ANAL APPL, V17, P179, DOI 10.1007/s10044-012-0288-4
   Huang S, 2015, PATTERN ANAL APPL, V18, P639, DOI 10.1007/s10044-014-0434-2
   Huang WL, 2012, IMAGE VISION COMPUT, V30, P355, DOI 10.1016/j.imavis.2012.03.004
   Huang ZH, 2015, IMAGE VISION COMPUT, V37, P12, DOI 10.1016/j.imavis.2014.12.005
   Huang ZH, 2015, INFORM FUSION, V22, P95, DOI 10.1016/j.inffus.2014.06.001
   Huu-Tuan Nguyen, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P85, DOI 10.1007/978-3-642-37410-4_8
   Jabid T., 2010, Digest of Technical Papers Int. Conf. Consumer Electronics, P329, DOI DOI 10.1109/ICCE.2010.5418801
   Jain A. K., 2011, HDB FACE RECOGNITION
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Lin GF, 2016, PATTERN RECOGN, V53, P1, DOI 10.1016/j.patcog.2015.10.013
   Liu F, 2013, NEUROCOMPUTING, V120, P325, DOI 10.1016/j.neucom.2012.06.061
   Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926
   Martinez A, 1998, 24 CVC
   Mashhoori A, 2013, NEUROCOMPUTING, V108, P111, DOI 10.1016/j.neucom.2012.12.005
   Mehta R, 2016, PATTERN RECOGN LETT, V71, P16, DOI 10.1016/j.patrec.2015.11.019
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pal Anabik, 2013, Pattern Recognition and Machine Intelligence. 5th International Conference, PReMI 2013. Proceedings: LNCS 8251, P355, DOI 10.1007/978-3-642-45062-4_48
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Ren HR, 2014, OPTIK, V125, P1922, DOI 10.1016/j.ijleo.2013.09.079
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vu NS, 2012, PATTERN RECOGN, V45, P2478, DOI 10.1016/j.patcog.2011.12.021
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yan H, 2015, AER ADV ENG RES, V20, P245
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yektaii M, 2011, SIGNAL IMAGE VIDEO P, V5, P93, DOI 10.1007/s11760-009-0145-0
   Yu W, 2014, SIGNAL IMAGE VIDEO P, V8, pS155, DOI 10.1007/s11760-014-0652-5
   Zhou SR, 2013, NEUROCOMPUTING, V116, P260, DOI 10.1016/j.neucom.2012.05.036
   Zhu Q, 2013, NEURAL COMPUT APPL, V23, P169, DOI 10.1007/s00521-012-0851-3
NR 40
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 27471
EP 27489
DI 10.1007/s11042-018-5932-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500055
DA 2024-07-18
ER

PT J
AU Hosny, KM
   Darwish, MM
AF Hosny, Khalid M.
   Darwish, Mohamed M.
TI Robust color image watermarking using invariant quaternion
   Legendre-Fourier moments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternion Legendre-Fourier moments; Color image watermarking; Geometric
   attacks; Rotation invariant
ID GEOMETRICALLY INVARIANT; SCHEME; TRANSFORMS; MULTIMEDIA
AB In this paper, a geometrically invariant color image watermarking method using Quaternion Legendre-Fourier moments (QLFMs) is presented. A highly accurate, fast and numerically stable method is proposed to compute the QLFMs in polar coordinates. The proposed watermarking method consists of three main steps. First, the Arnold scrambling algorithm is applied to a binary watermark image. Second, the QLFMs of the original host color image are computed. Third, the binary digital watermark is embedding by performing the quantization of selected QLFMs. Two different groups of attacks are considered. The first group includes geometric attacks such as rotation, scaling and translation while the second group includes the common signal processing attacks such as image compression and noise. Experiments are performed where the performance of proposed method is compared with the existing moment-based watermarking methods. The proposed method is superior over all existing quaternion moment-based watermarking in terms of visual imperceptibility capability and robustness to different attacks.
C1 [Hosny, Khalid M.] Zagazig Univ, Fac Comp & Informat, Dept Informat Technol, Zagazig 44519, Egypt.
   [Darwish, Mohamed M.] Assiut Univ, Dept Math, Fac Sci, Assiut 71516, Egypt.
C3 Egyptian Knowledge Bank (EKB); Zagazig University; Egyptian Knowledge
   Bank (EKB); Assiut University
RP Hosny, KM (corresponding author), Zagazig Univ, Fac Comp & Informat, Dept Informat Technol, Zagazig 44519, Egypt.
EM k_hosny@yahoo.com
RI Hosny, Khalid M./B-1404-2008; Darwish, SMIEEE, M. M. F./AAE-5964-2021
OI Hosny, Khalid M./0000-0001-8065-8977; Darwish, SMIEEE, M. M.
   F./0000-0001-9782-8813
CR Al-Otum HA, 2009, COMPUT ELECTR ENG, V35, P673, DOI 10.1016/j.compeleceng.2009.01.007
   Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   [Anonymous], INT J IMAGE GRAPH SI
   [Anonymous], J INFO HIDING MULT S
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], J INF HIDING MULTIME
   [Anonymous], COMPUTATIONALLY EFFI
   [Anonymous], RECENT SURVEY IMAGE
   [Anonymous], MULTIMED TOOLS APPL
   Battiato S, 2012, IEEE MULTIMEDIA, V19, P17, DOI 10.1109/MMUL.2012.10
   Bianchi T, 2013, IEEE SIGNAL PROC MAG, V30, P87, DOI 10.1109/MSP.2012.2228342
   Chauhan DS, 2019, MULTIMED TOOLS APPL, V78, P3911, DOI 10.1007/s11042-017-4886-4
   Chou CH, 2010, IEEE T IMAGE PROCESS, V19, P2966, DOI 10.1109/TIP.2010.2052261
   Chu SC, 2008, CIRC SYST SIGNAL PR, V27, P171, DOI 10.1007/s00034-008-9025-z
   Cox Ingemar, 2008, DIGITAL WATERMARKING, V2
   Ell TA, 2007, IEEE T IMAGE PROCESS, V16, P22, DOI 10.1109/TIP.2006.884955
   Hamilton W., 1866, ELEMENTS QUATERNIONS
   Hosny Khalid Mohamed, 2011, Journal of Computer Sciences, V7, P715, DOI 10.3844/jcssp.2011.715.722
   Hosny KM, 2017, COMPUT ELECTR ENG, V62, P429, DOI 10.1016/j.compeleceng.2017.05.015
   Hosny KM, 2019, J REAL-TIME IMAGE PR, V16, P1235, DOI 10.1007/s11554-016-0622-y
   Ismail Ismail A., 2010, Journal of Computer Sciences, V6, P52, DOI 10.3844/jcssp.2010.52.59
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Liu KC, 2010, AEU-INT J ELECTRON C, V64, P112, DOI 10.1016/j.aeue.2008.11.006
   Niu PP, 2011, EXPERT SYST APPL, V38, P2081, DOI 10.1016/j.eswa.2010.07.147
   Pan JS, 2004, ELECTRON LETT, V40, P1409, DOI 10.1049/el:20046454
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Singh Amit Kumar, 2018, Future Generation Computer Systems, V86, P926, DOI 10.1016/j.future.2016.11.023
   Singh AK, 2017, MULTIMED SYST APPL, P1, DOI 10.1007/978-3-319-57699-2
   Singh AK, 2015, WIRELESS PERS COMMUN, V80, P1415, DOI 10.1007/s11277-014-2091-6
   Singh C, 2013, OPT LASER TECHNOL, V54, P176, DOI 10.1016/j.optlastec.2013.05.016
   Suk T, 2009, LECT NOTES COMPUT SC, V5702, P334, DOI 10.1007/978-3-642-03767-2_41
   Tsougenis ED, 2014, EXPERT SYST APPL, V41, P6408, DOI 10.1016/j.eswa.2014.04.021
   Tsougenis ED, 2013, OPT LASER TECHNOL, V54, P84, DOI 10.1016/j.optlastec.2013.05.004
   Tsui TK, 2008, IEEE T INF FOREN SEC, V3, P16, DOI 10.1109/TIFS.2007.916275
   Wang CP, 2016, SIGNAL PROCESS-IMAGE, V45, P10, DOI 10.1016/j.image.2016.03.007
   Wang XY, 2016, J VIS COMMUN IMAGE R, V38, P678, DOI 10.1016/j.jvcir.2016.04.011
   Wang XY, 2014, INFORM SCIENCES, V277, P731, DOI 10.1016/j.ins.2014.02.158
   Wang XY, 2010, COMPUT ELECTR ENG, V36, P31, DOI 10.1016/j.compeleceng.2009.04.005
   [王向阳 Wang Xiangyang], 2016, [计算机研究与发展, Journal of Computer Research and Development], V53, P651
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao B, 2014, IMAGE VISION COMPUT, V32, P994, DOI 10.1016/j.imavis.2014.09.002
   Xin YQ, 2007, PATTERN RECOGN, V40, P3740, DOI 10.1016/j.patcog.2007.05.004
   Xin YQ, 2007, IEEE T IMAGE PROCESS, V16, P581, DOI 10.1109/TIP.2006.888346
   Yang HY, 2015, ACM T MULTIM COMPUT, V11, DOI 10.1145/2700299
   Yang HY, 2015, AEU-INT J ELECTRON C, V69, P389, DOI 10.1016/j.aeue.2014.10.012
   Yang HY, 2014, OPTIK, V125, P4456, DOI 10.1016/j.ijleo.2014.02.028
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zear A, 2018, MULTIMED TOOLS APPL, V77, P4863, DOI 10.1007/s11042-016-3862-8
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhu HQ, 2010, DIGIT SIGNAL PROCESS, V20, P1612, DOI 10.1016/j.dsp.2010.01.010
NR 50
TC 57
Z9 57
U1 2
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 24727
EP 24750
DI 10.1007/s11042-018-5670-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400008
DA 2024-07-18
ER

PT J
AU Noshadian, S
   Ebrahimzade, A
   Kazemitabar, SJ
AF Noshadian, Saeed
   Ebrahimzade, Ata
   Kazemitabar, Seyed Javad
TI Optimizing chaos based image encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Logistic map; TLBO algorithm; GSA; Knuth shuffle
ID HYBRID GENETIC ALGORITHM; OPTIMIZATION; CIPHER
AB Due to its inherent properties such as sensitivity to initial condition, ergodicity and systematic parametrization chaos systems have been extensively used in image encryption. However, one needs to optimize the chaos for each image being encrypted to provide high quality encryption. Features such as high entropy or low pixel correlation are measures of interest in image encryption. In this paper, we propose a novel technique to optimize a chaos based image encryption algorithm. The image is confused using logistic map as chaos function and diffused by modified Knuth shuffling algorithm. We use the logistic map parameters as encryption key. We then harness TLBO and GSA evolutionary algorithms to speed up the optimization process of these parameters. The optimization method yields parameters that lead to lowest correlation among adjacent pixels or highest entropy. We compare the quality and security of our cryptosystem with some famous image encryption methods in the literature.
C1 [Noshadian, Saeed; Ebrahimzade, Ata; Kazemitabar, Seyed Javad] Babaol Noshirvani Univ Technol, Babol Sar, Iran.
RP Kazemitabar, SJ (corresponding author), Babaol Noshirvani Univ Technol, Babol Sar, Iran.
EM s.noshadian@stu.nit.ac.ir; e-zadeh@nit.ac.ir; j.kazemitabar@nit.ac.ir
RI Kazemitabar, Javad/AAE-1602-2022
CR Abdullah AH, 2012, AEU-INT J ELECTRON C, V66, P806, DOI 10.1016/j.aeue.2012.01.015
   Alligood K.T., 1997, Chaos, P105, DOI DOI 10.1007/978-3-642-59281-2_3
   [Anonymous], INFORM SCIENCES
   [Anonymous], 1998, The art of computer programming: Sorting and searching
   [Anonymous], APPL SOFT COMPUT
   Belkhouche F, 2003, IEEE REGION 5 2003 ANNUAL TECHNICAL CONFERENCE, CONFERENCE RECORD, P39, DOI 10.1109/REG5.2003.1199708
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Enayatifar R., 2011, INT J PHYS SCI, V6, P221
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Fard EB, 2013, PROCEEDINGS OF THE 3RD INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE 2013), P190, DOI 10.1109/ICCKE.2013.6682835
   Guan ZH, 2005, PHYS LETT A, V346, P153, DOI 10.1016/j.physleta.2005.08.006
   Jolfaei Alireza, 2010, International Journal of Computer and Network Security, V2, P38
   Kamali S., 2010, EL INF ENG ICEIE 201, V1, pV1, DOI DOI 10.1109/ICEIE.2010.5559902
   Khan J., 2015, 2015 6 INT C MODELIN, P1
   Lafe O, 1996, IEEE INTERNATIONAL JOINT SYMPOSIA ON INTELLIGENCE AND SYSTEMS, PROCEEDINGS, P234, DOI 10.1109/IJSIS.1996.565074
   Li CQ, 2005, EURASIP J APPL SIG P, V2005, P1277, DOI 10.1155/ASP.2005.1277
   Lian SG, 2005, CHAOS SOLITON FRACT, V26, P117, DOI 10.1016/j.chaos.2004.11.096
   Liao XF, 2010, SIGNAL PROCESS, V90, P2714, DOI 10.1016/j.sigpro.2010.03.022
   Maniccam SS, 2004, PATTERN RECOGN, V37, P725, DOI 10.1016/j.patcog.2003.08.011
   Mitra A., 2006, INT J COMPUTER SCI, V1, P127
   Norouzi B, 2014, MULTIMED TOOLS APPL, V71, P1469, DOI 10.1007/s11042-012-1292-9
   Rao RV, 2012, INFORM SCIENCES, V183, P1, DOI 10.1016/j.ins.2011.08.006
   Rao RV, 2011, COMPUT AIDED DESIGN, V43, P303, DOI 10.1016/j.cad.2010.12.015
   Rashedi E, 2009, INFORM SCIENCES, V179, P2232, DOI 10.1016/j.ins.2009.03.004
   Sabri N.M., 2013, International Journal of Advances in Soft Computing and Its Applications, V5, P1
   Sinha A, 2003, OPT COMMUN, V218, P229, DOI 10.1016/S0030-4018(03)01261-6
   Sreelaja NK, 2012, APPL SOFT COMPUT, V12, P2879, DOI 10.1016/j.asoc.2012.04.002
   Van Droogenbroeck M., 2002, ACIVS'2002: Advanced Concepts for Intelligent Vision Systems, P90
   Wang W, 2016, J SENSORS, V2016, DOI 10.1155/2016/2646205
   Zefreh E. Zarei, 2011, 2011 CSI International Symposium on Computer Science and Software Engineering (CSSE 2011), P77, DOI 10.1109/CSICSSE.2011.5963985
   Zhang GJ, 2011, OPT COMMUN, V284, P2775, DOI 10.1016/j.optcom.2011.02.039
   Zhang Q, 2010, MATH COMPUT MODEL, V52, P2028, DOI 10.1016/j.mcm.2010.06.005
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhou YC, 2013, IEEE T CYBERNETICS, V43, P515, DOI 10.1109/TSMCB.2012.2210706
   [No title captured]
   [No title captured]
NR 37
TC 31
Z9 31
U1 1
U2 49
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 19
BP 25569
EP 25590
DI 10.1007/s11042-018-5807-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GS1AG
UT WOS:000443244400042
DA 2024-07-18
ER

PT J
AU Prakash, CS
   Kumar, A
   Maheshkar, S
   Maheshkar, V
AF Prakash, Choudhary Shyam
   Kumar, Avinash
   Maheshkar, Sushila
   Maheshkar, Vikas
TI An integrated method of copy-move and splicing for image forgery
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Copy-move forgery; Duplicate region detection; Image
   splicing; BDCT; Zernike moment
ID TRANSFORM; FEATURES; DCT
AB Splicing and copy-move are two well known methods of passive image forgery. In this paper, splicing and copy-move forgery detection are performed simultaneously on the same database CASIA v1.0 and CASIA v2.0. Initially, a suspicious image is taken and features are extracted through BDCT and enhanced threshold method. The proposed technique decides whether the given image is manipulated or not. If it is manipulated then support vector machine (SVM) classify that the given image is gone through splicing forgery or copy-move forgery. For copy-move detection, ZM-polar (Zernike Moment) is used to locate the duplicated regions in image. Experimental results depict the performance of the proposed method.
C1 [Prakash, Choudhary Shyam; Kumar, Avinash; Maheshkar, Sushila; Maheshkar, Vikas] Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (Indian School of Mines) Dhanbad
RP Prakash, CS (corresponding author), Indian Sch Mines, Indian Inst Technol, Dept Comp Sci & Engn, Dhanbad, Bihar, India.
EM shyamprakash2008@yahoo.com
RI Maheshkar, Sushila/KPY-5418-2024; Maheshkar, Sushila/V-7269-2019;
   Prakash, Choudhary/Y-2314-2019
OI Maheshkar, Sushila/0000-0003-3879-2800; Prakash, Dr. Choudhary
   Shyam/0000-0002-9305-3472; Kumar, Avinash/0000-0003-1562-7829
CR Amerini I, 2013, SIGNAL PROCESS-IMAGE, V28, P659, DOI 10.1016/j.image.2013.03.006
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Andreopoulos A, 2013, COMPUT VIS IMAGE UND, V117, P827, DOI 10.1016/j.cviu.2013.04.005
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bayram S, 2009, INT CONF ACOUST SPEE, P1053, DOI 10.1109/ICASSP.2009.4959768
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P1759, DOI 10.1016/j.sigpro.2011.01.022
   Campos FM, 2015, J INTELL ROBOT SYST, V77, P377, DOI 10.1007/s10846-013-0016-3
   Cao YJ, 2012, FORENSIC SCI INT, V214, P33, DOI 10.1016/j.forsciint.2011.07.015
   Chen LK, 2013, J VIS COMMUN IMAGE R, V24, P244, DOI 10.1016/j.jvcir.2013.01.008
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   El-Alfy ESM, 2015, PATTERN ANAL APPL, V18, P713, DOI 10.1007/s10044-014-0396-4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fridrich AJ, 2003, INPR DIG FOR RES WOR
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Guo JM, 2013, EXPERT SYST APPL, V40, P707, DOI 10.1016/j.eswa.2012.08.002
   Hakimi F, 2015, ELECT INF PLAN, V3
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hu WC, 2015, DIGIT SIGNAL PROCESS, V39, P50, DOI 10.1016/j.dsp.2015.01.006
   Huang DY, 2017, MULTIMED TOOLS APPL, V76, P1509, DOI 10.1007/s11042-015-3152-x
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Jain Anil K., 2011, Introduction to Biometrics, DOI [DOI 10.1007/978-0-387-77326-1, 10.1007/978-0-387-77326-1_1]
   Jing Dong, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P422, DOI 10.1109/ChinaSIP.2013.6625374
   Kakar P, 2012, IEEE T INF FOREN SEC, V7, P1018, DOI 10.1109/TIFS.2012.2188390
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Langille A., 2006, CRV '06: Proceedings of the The 3rd Canadian Conference on Computer and Robot Vision, Washington, DC, USA, IEEE Computer Society, P64, DOI DOI 10.1109/CRV.2006.9
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Li LD, 2014, COMPUT ELECTR ENG, V40, P1951, DOI 10.1016/j.compeleceng.2013.11.034
   Li X., 2010, IEEE International Conference on Information Theory and Information Security (ICITIS), P1127, DOI DOI 10.1109/ICITIS.2010.5689754
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu S, 2012, PATTERN RECOGN LETT, V33, P744, DOI 10.1016/j.patrec.2011.12.008
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Muhammad G, 2012, DIGIT INVEST, V9, P49, DOI 10.1016/j.diin.2012.04.004
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Pevny T, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P75
   Pun CM, 2016, J VIS COMMUN IMAGE R, V38, P195, DOI 10.1016/j.jvcir.2016.03.005
   Qiu X., 2014, P 2 ACM WORKSH INF H, P165, DOI DOI 10.1145/2600918.2600941
   Rahmani R., 2005, ACM WORKSHOP MULTIME, P227, DOI DOI 10.1145/1101826.1101863
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Ryu SJ, 2010, LECT NOTES COMPUT SC, V6387, P51, DOI 10.1007/978-3-642-16435-4_5
   Shi YQ, 2007, MM&SEC'07: PROCEEDINGS OF THE MULTIMEDIA & SECURITY WORKSHOP 2007, P51
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   Su B, 2014, EURASIP J WIREL COMM, DOI 10.1186/1687-1499-2014-7
   Sutthiwan P, 2011, LECT NOTES COMPUT SC, V6730, P1, DOI 10.1007/978-3-642-24556-5_1
   Sutthiwan P, 2010, IEEE INT CON MULTI, P1463, DOI 10.1109/ICME.2010.5583264
   Sutthiwan P, 2010, IEEE INT SYMP CIRC S, P3064, DOI 10.1109/ISCAS.2010.5537980
   Wang W, 2009, IEEE IMAGE PROC, P1257, DOI 10.1109/ICIP.2009.5413549
   Wang W, 2010, IEEE IMAGE PROC, P2101, DOI 10.1109/ICIP.2010.5652660
   Xin YQ, 2007, IEEE T IMAGE PROCESS, V16, P581, DOI 10.1109/TIP.2006.888346
   Xuemin Wu, 2011, 2011 3rd International Conference on Multimedia Information Networking and Security, P600, DOI 10.1109/MINES.2011.135
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Zhang QB, 2016, J VIS COMMUN IMAGE R, V40, P449, DOI 10.1016/j.jvcir.2016.07.013
   Zhao J, 2013, MATH PROBL ENG, V2013, P12
   Zhao XD, 2015, IEEE T CIRC SYST VID, V25, P185, DOI 10.1109/TCSVT.2014.2347513
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
   Zou DK, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1365, DOI 10.1109/ICME.2006.262792
NR 64
TC 28
Z9 28
U1 1
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2018
VL 77
IS 20
BP 26939
EP 26963
DI 10.1007/s11042-018-5899-3
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GT1EF
UT WOS:000444201500032
DA 2024-07-18
ER

PT J
AU Fei, X
   Yu, RP
   Li, L
   Wang, GC
AF Fei, Xuan
   Yu, Renping
   Li, Lei
   Wang, Guicai
TI Adaptive PCA transforms with geometric morphological grouping for image
   noise removal
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image noise removal; Image feature representation; Adaptive principal
   component analysis; Geometric morphological patch grouping
ID WAVELET; SPARSE; CURVELET; DICTIONARIES; ALGORITHM
AB This paper presents a novel approach of image noise removal via integrating geometric morphological patch grouping and adaptive principal component analysis (PCA) transform domain choosing. Image noise removal based on PCA has acquired much attention and success because of the essential difference: the energy of signal concentrates on the small subset of PCA transformed dataset, while the energy of noise evenly spreads over the whole data set. In this paper, the noisy image will be firstly decomposed into overlap patches that contain different content and structure information. However, some of them potentially have similar geometric morphology. So, their gradient map is utilized to compute the dominant orientation of gradient field to group these geometric morphology patches. Such a grouping procedure guarantees that only similar patches are used to perform hard thresholding on the coefficients to remove the noise. Furthermore, as the result and effect of feature extraction are different in different transform domain, a proper one could be adaptively chosen for different types. Finally, a comprehensive empirical evaluation of the proposed method is carried out in terms of accuracy and visuality, and the results reveal that our method appears to be competitive with the state-of-the-art noise removal methods.
C1 [Fei, Xuan; Li, Lei; Wang, Guicai] Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou 450001, Henan, Peoples R China.
   [Fei, Xuan] Minist Educ, Key Lab Grain Informat Proc & Control, Zhengzhou 450001, Henan, Peoples R China.
   [Yu, Renping] Zhengzhou Univ, Sch Elect Engn, Zhengzhou 450001, Henan, Peoples R China.
C3 Henan University of Technology; Zhengzhou University
RP Fei, X (corresponding author), Henan Univ Technol, Coll Informat Sci & Engn, Zhengzhou 450001, Henan, Peoples R China.; Fei, X (corresponding author), Minist Educ, Key Lab Grain Informat Proc & Control, Zhengzhou 450001, Henan, Peoples R China.; Yu, RP (corresponding author), Zhengzhou Univ, Sch Elect Engn, Zhengzhou 450001, Henan, Peoples R China.
EM feixuan@haut.edu.cn; yurenping91@163.com
RI Li, Lei/AAB-9317-2022
FU Key Research Foundation of Henan Province [15A520056]; Research
   Foundation for Advanced Talents [31401918]; Fundamental Research Funds
   for the Henan Provincial Colleges and Universities in Henan University
   of Technology [2016QNJH26]; Ministry of Education Key Laboratory Open
   Funded Project for Grain Information Processing and Control
   [KFJJ-2017-105]
FX This work was supported in part by the Key Research Foundation of Henan
   Province (No. 15A520056), the Research Foundation for Advanced Talents
   (No. 31401918), the Fundamental Research Funds for the Henan Provincial
   Colleges and Universities in Henan University of Technology (No.
   2016QNJH26), and the Ministry of Education Key Laboratory Open Funded
   Project for Grain Information Processing and Control (No.
   KFJJ-2017-105).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Chaudhury KN, 2015, IEEE IMAGE PROC, P108, DOI 10.1109/ICIP.2015.7350769
   Chen RP, 2013, IEEE GEOSCI REMOTE S, V10, P826, DOI 10.1109/LGRS.2012.2225594
   [程正东 CHENG Zheng-dong], 2009, [工程数学学报, Chinese Journal of Engineering Mathematics], V26, P951
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Deledalle CA, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.25
   EDELMAN A, 1988, SIAM J MATRIX ANAL A, V9, P543, DOI 10.1137/0609045
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Feng XG, 2002, CONF REC ASILOMAR C, P478
   Ho J, 2013, IEEE T IMAGE PROCESS, V22, P1277, DOI 10.1109/TIP.2012.2220150
   Isidoro JR, 2016, IEEE IMAGE PROC, P1968, DOI 10.1109/ICIP.2016.7532702
   Kamble VM, 2016, ARTIF INTELL REV, V45, P509, DOI 10.1007/s10462-015-9453-7
   Kazubek M, 2003, IEEE SIGNAL PROC LET, V10, P324, DOI 10.1109/LSP.2003.818225
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Li JH, 2017, IEEE J-STARS, V10, P3810, DOI 10.1109/JSTARS.2017.2685628
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Sharma A, 2014, 2014 INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED AND GRID COMPUTING (PDGC), P1, DOI 10.1109/PDGC.2014.7030705
   Wang C, 2012, IEEE T IMAGE PROCESS, V21, P115, DOI 10.1109/TIP.2011.2159985
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu KZ, 2014, AEU-INT J ELECTRON C, V68, P37, DOI 10.1016/j.aeue.2013.07.011
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang JX, 2016, IEEE T GEOSCI REMOTE, V54, P1818, DOI 10.1109/TGRS.2015.2489218
   Yang SY, 2013, IEEE T IMAGE PROCESS, V22, P4161, DOI 10.1109/TIP.2013.2271114
   Yang SY, 2012, IEEE T IMAGE PROCESS, V21, P4016, DOI 10.1109/TIP.2012.2201491
   Zhang L, 2010, PATTERN RECOGN, V43, P1531, DOI 10.1016/j.patcog.2009.09.023
NR 28
TC 3
Z9 4
U1 1
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 23353
EP 23369
DI 10.1007/s11042-018-5676-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900013
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Xiang, S
   Liu, AA
AF Nie, Weizhi
   Xiang, Shu
   Liu, Anan
TI Multi-scale CNNs for 3D model retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D model retrieval; CNN multi-view; Multi-scale
ID OBJECT RETRIEVAL; RECOGNITION; NETWORKS; SEARCH
AB Recent advancements in low-cost 3D sensors and mobile devices of virtual 3D models have additionally facilitated the accessibility of 3D data. 3D model retrieval is becoming an indispensable function for modern search engines. An effective retrieval model is at the core of computer vision. With the continuous improvement of 3D data, there are large number of methods to solve this problem. Existing works proposed numerous works to deal with feature extraction and object matching. Most of them are unable to fully exploit the information of 3D representations. To address this problem, we propose a novel multi-layer deep network in this paper. First, multiple rendered images are extracted from a 3D object, and combined into one representative view, which is the actual input of the network. Then, the novel multi-layer network structure is trained and tested on these representative views, generating the feature leaning model, which owns the local and global information of a 3D object. Finally, simple Euclidean metric is used to compute the similarity between two different 3D models to complete the retrieval problem. Extensive experiments and corresponding experimental results have demonstrated the superiority of our approach.
C1 [Nie, Weizhi; Xiang, Shu; Liu, Anan] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Nie, WZ (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM weizhinie@tju.edu.cn
RI Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61502337]
FX The work is partially supported by the National Natural Science
   Foundation of China (No. 61502337).
CR Akgül CB, 2009, IEEE T PATTERN ANAL, V31, P1117, DOI 10.1109/TPAMI.2009.25
   [Anonymous], 2017, IEEE T CYBERNETICS
   [Anonymous], J APPL MATH
   [Anonymous], 2015, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2015.7298801, 10.1109/CVPR.2015.7298801]
   Ansary TF, 2007, IEEE T MULTIMEDIA, V9, P78, DOI 10.1109/TMM.2006.886359
   Bu SH, 2014, IEEE T MULTIMEDIA, V16, P2154, DOI 10.1109/TMM.2014.2351788
   Bustos B, 2005, ACM COMPUT SURV, V37, P345, DOI 10.1145/1118890.1118893
   Cao B, 2016, J INTELL FUZZY SYST, V31, P2637, DOI 10.3233/JIFS-169104
   Chen DY, 2003, COMPUT GRAPH FORUM, V22, P223, DOI 10.1111/1467-8659.00669
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding GG, 2017, NEUROCOMPUTING, V257, P24, DOI 10.1016/j.neucom.2017.01.055
   Gao Y, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2967502
   Gao Y, 2016, IEEE T MULTIMEDIA, V18, P2115, DOI 10.1109/TMM.2016.2581483
   Gao Y, 2014, IEEE MULTIMEDIA, V21, P52, DOI 10.1109/MMUL.2014.20
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Hong RC, 2016, IEEE T IMAGE PROCESS, V25, P5814, DOI 10.1109/TIP.2016.2614132
   Hu F, 2015, REMOTE SENS-BASEL, V7, P14680, DOI 10.3390/rs71114680
   Irfanoglu MO, 2004, INT C PATT RECOG, P183, DOI 10.1109/ICPR.2004.1333734
   Kalogerakis E., 2016, ABS161202808 CORR
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   LeCun Y, 2004, PROC CVPR IEEE, P97
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Liu AA, 2016, IEEE T IMAGE PROCESS, V25, P2103, DOI 10.1109/TIP.2016.2540802
   Liu A, 2015, INFORM SCIENCES, V320, P429, DOI 10.1016/j.ins.2015.04.042
   Liu Q, 2012, ARXIV12083670
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Nie LQ, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P695
   Nie LQ, 2012, ACM T INFORM SYST, V30, DOI 10.1145/2180868.2180875
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Shi BG, 2015, IEEE SIGNAL PROC LET, V22, P2339, DOI 10.1109/LSP.2015.2480802
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tangelder JWH, 2003, SMI 2003: SHAPE MODELING INTERNATIONAL 2003, PROCEEDINGS, P119
   Wang D, 2017, NEUROCOMPUTING, V252, P58, DOI 10.1016/j.neucom.2016.06.095
   Xie J, 2017, IEEE T PATTERN ANAL, V39, P1335, DOI 10.1109/TPAMI.2016.2596722
   Xu XF, 2016, LECT NOTES COMPUT SC, V9756, P147, DOI 10.1007/978-3-319-41778-3_15
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Zhao SC, 2017, IEEE T MULTIMEDIA, V19, P632, DOI 10.1109/TMM.2016.2617741
   Zhao S, 2015, SIGNAL PROCESS, V112, P110, DOI 10.1016/j.sigpro.2014.09.038
   Zhao SC, 2015, NEUROCOMPUTING, V151, P533, DOI 10.1016/j.neucom.2014.03.092
   Zhao X., 2017, IEEE Trans. Reliab., V99, P1
   Zhao XB, 2015, COMMUN STAT-THEOR M, V44, P5240, DOI 10.1080/03610926.2013.815207
   Zhao XB, 2013, J SYST ENG ELECTRON, V24, P1029, DOI 10.1109/JSEE.2013.00120
NR 44
TC 4
Z9 5
U1 3
U2 29
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22953
EP 22963
DI 10.1007/s11042-018-5641-1
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500063
DA 2024-07-18
ER

PT J
AU Tew, Y
   Wong, K
   Phan, RCW
   Ngan, KN
AF Tew, Yiqi
   Wong, KokSheik
   Phan, Raphael C-W
   Ngan, King Ngi
TI Separable authentication in encrypted HEVC video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Separable; HEVC; Encryption; Authentication; Coding unit size;
   Information hiding
ID STANDARD; IMAGE
AB A joint encryption and authentication scheme for HEVC compressed video is proposed in this work. It produces a HEVC format compliant video stream that permits the authentication process to be carried out irregardless of the video being in the encrypted or plaintext (i.e., decrypted) form. To achieve this separable property, one set of syntax elements within the HEVC standard is utilized to achieve authentication, while another set is exploited for encryption. Specifically, for authentication, information such as coding unit size in each video slice is utilized to generate the authentication code, which is then embedded into each video slice to detect the tampered regions. A two-level authentication method is implemented to facilitate the legitimacy verification process. On the other hand, for video encryption, syntax elements in the HEVC standard including Sign Bins, Transform Skip Bins and Suffix Bins are randomized to perceptually distort the video. Experiment results show that by using the proposed encryption modules, the perceptual quality of the plaintext video can be distorted, and the distorted video can be restored to the original HEVC compressed video. Furthermore, the proposed joint scheme is verified to be viable in detecting and localizing the tampered regions. Finally, a pragmatic comparison among the proposed and conventional joint schemes is performed.
C1 [Tew, Yiqi] Tunku Abdul Rahman Univ Coll, Kuala Lumpur, Malaysia.
   [Wong, KokSheik] Monash Univ, Selangor, Malaysia.
   [Phan, Raphael C-W] Multimedia Univ, Selangor, Malaysia.
   [Ngan, King Ngi] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
C3 Tunku Abdul Rahman University College (TAR UC); Monash University;
   Monash University Malaysia; Multimedia University; Chinese University of
   Hong Kong
RP Wong, K (corresponding author), Monash Univ, Selangor, Malaysia.
EM yiqi@tarc.edu.my; wong.koksheik@monash.edu; raphael@mmu.edu.my;
   knngan@ee.cuhk.edu.hk
RI Phan, Raphael C.-W./I-7266-2013; Tew, Yiqi/AAR-1026-2020; Ngan,
   N/E-8240-2014; Wong, KokSheik/B-9796-2011
OI Tew, Yiqi/0000-0002-9395-2937; Ngan, N/0000-0003-1946-3235; Phan,
   Raphael C.-W./0000-0001-7448-4595; Wong, KokSheik/0000-0002-4893-2291
CR Alassaf N, 2017, J RES ENG APPL SCI
   Aljuaid N, 2015, 12 LEARN TECHN C WEA
   Aljuaid N, 2014, LECT NOTES INF THEOR, V2, P151
   [Anonymous], 2014, INT C ADV ENG TECHN
   [Anonymous], 2013, 2300822013 ISOIEC
   [Anonymous], 4 IEEE GCC C EXH
   [Anonymous], 2002, FIPS PUB
   Atrey P K., 2009, Digital video authentication
   Bjontegaard G, 2001, TECHNICAL REPORT
   Budagavi M, 2014, HIGH EFFICIENY VIDEO
   Gutub A, 2012, INT C ADV COMP SCI A
   Gutub Adnan Abdul-Aziz, 2010, Journal of Emerging Technologies in Web Intelligence, V2, P56, DOI 10.4304/jetwi.2.1.56-64
   Hofbauer Heinz, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1986, DOI 10.1109/ICASSP.2014.6853946
   Karim MSA, 2015, SIGNAL PROCESS, V108, P56, DOI 10.1016/j.sigpro.2014.08.037
   Kundur D, 2004, P IEEE, V92, P918, DOI 10.1109/JPROC.2004.827356
   Ma S, 2015, IEEE T INF FOREN SEC, V10, P458, DOI 10.1109/TIFS.2014.2378592
   Ong SY, 2015, SIGNAL PROCESS-IMAGE, V31, P47, DOI 10.1016/j.image.2014.11.008
   Ong S, 2015, SIGNAL PROCESS, V109, P38, DOI 10.1016/j.sigpro.2014.10.028
   Qian ZX, 2016, IEEE T CIRC SYST VID, V26, P636, DOI 10.1109/TCSVT.2015.2418611
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Shahid Z, 2014, IEEE T MULTIMEDIA, V16, P24, DOI 10.1109/TMM.2013.2281029
   Stallings W., 2010, Cryptography and Network Security: Principles and Practice, V5
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Sze V, 2012, IEEE T CIRC SYST VID, V22, P1778, DOI 10.1109/TCSVT.2012.2221526
   Tew YQ, 2016, J VIS COMMUN IMAGE R, V40, P502, DOI 10.1016/j.jvcir.2016.07.017
   Tew Y, 2014, IEEE IMAGE PROC, P5502, DOI 10.1109/ICIP.2014.7026113
   Waddilove R, 2015, BEST FREE VIDEO EDIT
   Wien M, 2014, HIGH EFFICIENY VIDEO
   Zhang XP, 2012, IEEE T INF FOREN SEC, V7, P826, DOI 10.1109/TIFS.2011.2176120
   Zhou JT, 2016, IEEE T CIRC SYST VID, V26, P441, DOI 10.1109/TCSVT.2015.2416591
NR 30
TC 17
Z9 19
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24165
EP 24184
DI 10.1007/s11042-018-5611-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900047
DA 2024-07-18
ER

PT J
AU Wang, YT
   Ren, TW
   Zhong, SH
   Liu, Y
   Wu, GS
AF Wang, Yuantian
   Ren, Tongwei
   Zhong, Sheng-Hua
   Liu, Yan
   Wu, Gangshan
TI Adaptive saliency cuts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency cuts; Segmentation seeds generation; Rough-labeled map
   generation; Object boundary refinement; Adaptive GrabCut
ID SPARSE REPRESENTATION; OBJECT DETECTION; EXTRACTION
AB Saliency cuts aims to segment salient objects from a given saliency map. The existing saliency cuts methods are fixed to the input cues. It limits their performance when the input cues are changed. In this paper, we propose a novel saliency cuts method named adaptive saliency cuts, which takes advantage of all the input cues in a unified framework and adjusts its components adaptively. Given a saliency map, we first generate segmentation seeds with adaptive triple thresholding. Next, we extend GrabCut by combining different input cues, and use it to generate a rough-labeled map of salient objects. Finally, we refine the boundaries of the salient objects with adaptive initialized segmentation, and produce an accurate binary mask. To the best of our knowledge, this method is the first adaptive saliency cuts method for different input cues. We validated the proposed method on MSRA10K and NJU2000. The experimental results demonstrate that our method outperforms the state-of-the-art methods.
C1 [Wang, Yuantian; Ren, Tongwei; Wu, Gangshan] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
   [Zhong, Sheng-Hua] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Liu, Yan] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
C3 Nanjing University; Shenzhen University; Hong Kong Polytechnic
   University
RP Ren, TW (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing, Jiangsu, Peoples R China.
EM wangyt@smail.nju.edu.cn; rentw@nju.edu.cn; csshzhong@szu.edu.cn;
   csyliu@comp.polyu.edu.hk; gswu@nju.edu.cn
RI liu, yan/HGV-1365-2022
OI LIU, Yan/0000-0003-4242-4840
FU National Science Foundation of China [61321491, 61202320]; Collaborative
   Innovation Center of Novel Software Technology and Industrialization
FX This work is supported by National Science Foundation of China
   (61321491, 61202320), and Collaborative Innovation Center of Novel
   Software Technology and Industrialization.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2008, 2008 19 INT C PATT R
   [Anonymous], 2013, P INT ACM C MULTIMED, DOI DOI 10.1145/2502081.2502093
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Banica D, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P283, DOI 10.1109/ICCVW.2013.45
   Bao BK, 2013, IEEE T IMAGE PROCESS, V22, P860, DOI 10.1109/TIP.2012.2219543
   Bao BK, 2012, IEEE T IMAGE PROCESS, V21, P3794, DOI 10.1109/TIP.2012.2192742
   Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Gao Z, 2017, J VIS COMMUN IMAGE R, V48, P442, DOI 10.1016/j.jvcir.2017.03.014
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gao Z, 2014, MULTIMED TOOLS APPL, V68, P641, DOI 10.1007/s11042-012-1071-7
   Ge L, 2015, PAC RIM C MULT
   Giró-i-Nieto X, 2014, MULTIMED TOOLS APPL, V70, P475, DOI 10.1007/s11042-013-1374-3
   Guo JF, 2019, MULTIMEDIA SYST, V25, P35, DOI 10.1007/s00530-017-0546-9
   Guo YD, 2007, LECT NOTES COMPUT SC, V4781, P322
   Guo YD, 2007, LECT NOTES COMPUT SC, V4781, P205
   Huang Y, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P701, DOI 10.1109/CISP.2008.76
   Ju R, 2015, IEEE I CONF COMP VIS, P1724, DOI 10.1109/ICCV.2015.201
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Leibe Bastian, 2004, WORKSH STAT LEARN CO
   Li SZ, 2015, IEEE IMAGE PROC, P4609, DOI 10.1109/ICIP.2015.7351680
   Liu J, 2017, NEUROCOMPUTING, V236, P134, DOI 10.1016/j.neucom.2016.09.111
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Song H, 2017, INTELL DAT CENT SYST, P1
   Tang JH, 2017, IEEE T PATTERN ANAL, V39, P1662, DOI 10.1109/TPAMI.2016.2608882
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang Y, 2017, INT C INT MULT COMP
   Wang Y, 2017, PAC RIM C MULT
   Xu N, 2007, INT C PATT REC, V2
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Zhang HW, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/2978656
   Zhang YK, 2010, IEEE INT VEH SYM, P34, DOI 10.1109/IVS.2010.5548140
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 44
TC 2
Z9 3
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22213
EP 22230
DI 10.1007/s11042-018-5859-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500026
DA 2024-07-18
ER

PT J
AU Yu, HP
   He, FZ
   Pan, YT
AF Yu, Haiping
   He, Fazhi
   Pan, Yiteng
TI A novel region-based active contour model via local patch similarity
   measure for image segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Spatial constraint; Patch similarity measure; Image segmentation;
   Computer vision; Active contour model
ID LEVEL SET METHOD; PARTICLE SWARM OPTIMIZATION; RE-INITIALIZATION;
   DISTANCE; ALGORITHM; TRACKING; SUPERRESOLUTION; EVOLUTION; COMPUTE
AB It is always difficult to accurately segment images with intensity inhomogeneity because most of the representative local-based models only take into account rough local information and do not consider the spatial relationship between the central pixel and its neighborhood. In fact, the pixels on an image are closely correlated to their local neighborhood. Therefore, the spatial relationship of neighboring pixels is a crucial feature that can play a vital role in image segmentation. In this paper, we propose a novel region-based active contour model via local patch similarity measure for image segmentation. In the model, we make full use of the spatial constraints on local region-based models for controlling the amplitude of spatial neighborhood to the center pixel in the image domain. Specifically, we first construct a local patch similarity measure as the spatial constraint, which balances the noise suppression and the image details reservation. Second, we construct the novel model by integrating the patch similarity measure into a region-based active contour model. Finally, we add a regularization information term to the objective function to ensure the smoothness and stability of the curve evolution. Experimental results show that the model is better than other classical local region-based models.
C1 [Yu, Haiping; Pan, Yiteng] Wuhan Univ, Sch Comp Sci, Wuhan, Hubei, Peoples R China.
   [He, Fazhi] Wuhan Univ, Sch Comp Sci, State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.
C3 Wuhan University; Wuhan University
RP He, FZ (corresponding author), Wuhan Univ, Sch Comp Sci, State Key Lab Software Engn, Wuhan, Hubei, Peoples R China.
EM seaping@whu.edu.cn; fzhe@whu.edu.cn; panyiteng@whu.edu.cn
RI He, Fazhi/Q-3691-2018; Pan, Yi/AAJ-2341-2021
FU National Natural Science Foundation of China [61472289, 61502356];
   National Key Research and Development Project [2016YFC0106305]
FX We would like to thank all the anonymous reviewers for their valuable
   comments. We are also grateful to Professor Zhang Kaihua and Professor
   Li Chunming to provide source code for comparison with our model. This
   work was supported by the National Natural Science Foundation of China
   (Grant Nos. 61472289 and Nos. 61502356) and the National Key Research
   and Development Project (Grant No. 2016YFC0106305).
CR Alsmirat MA, 2017, MULTIMED TOOLS APPL, V76, P3537, DOI 10.1007/s11042-016-3884-2
   Bo CJ, 2018, MULTIMED TOOLS APPL, V77, P10419, DOI 10.1007/s11042-017-4403-9
   Cambria E, 2013, IEEE INTELL SYST, V28, P6, DOI 10.1109/MIS.2013.68
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen JY, 2015, MULTIMED TOOLS APPL, V74, P671, DOI 10.1007/s11042-014-1944-z
   Chen YL, 2017, PATTERN RECOGN, V67, P139, DOI 10.1016/j.patcog.2017.02.013
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Cui XH, 2016, 2016 THIRD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION (AIPR)
   Fister I, 2015, CHAOS SOLITON FRACT, V73, P29, DOI 10.1016/j.chaos.2014.12.019
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   Goldstein T, 2010, J SCI COMPUT, V45, P272, DOI 10.1007/s10915-009-9331-z
   Gomes J, 2000, J VIS COMMUN IMAGE R, V11, P209, DOI 10.1006/jvci.1999.0439
   Gong MG, 2013, IEEE T IMAGE PROCESS, V22, P573, DOI 10.1109/TIP.2012.2219547
   Gu J, 2017, KNOWL-BASED SYST, V119, P113, DOI 10.1016/j.knosys.2016.12.006
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Kim CG, 2014, MULTIMED TOOLS APPL, V68, P237, DOI 10.1007/s11042-011-0906-y
   Krissian K, 2005, PATTERN RECOGN LETT, V26, P1532, DOI 10.1016/j.patrec.2004.12.005
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2011, IEEE T IMAGE PROCESS, V20, P2007, DOI 10.1109/TIP.2011.2146190
   Li CM, 2007, PROC CVPR IEEE, P339
   Li CM, 2005, PROC CVPR IEEE, P430
   Li K, 2019, FRONT COMPUT SCI-CHI, V13, P1116, DOI 10.1007/s11704-018-6442-4
   Li K, 2018, J COMPUT SCI TECH-CH, V33, P223, DOI 10.1007/s11390-017-1764-5
   Li K, 2017, APPL MATH SER B, V32, P294, DOI 10.1007/s11766-017-3466-8
   Li K, 2016, FRONT COMPUT SCI-CHI, V10, P689, DOI 10.1007/s11704-016-5106-5
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu SG, 2012, PATTERN RECOGN, V45, P2769, DOI 10.1016/j.patcog.2011.11.019
   Liu Y, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P1617
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu T, 2017, IEEE INT CON MULTI, P1362, DOI 10.1109/ICME.2017.8019298
   Lu T, 2017, IEEE ACCESS, V5, P13103, DOI 10.1109/ACCESS.2017.2717963
   Luo Y, IEEE GEOSCI REMOTE S
   Lv X, 2018, FUTURE GENER COMP SY, V82, P41, DOI 10.1016/j.future.2017.11.046
   Lv X, 2017, ADV ENG INFORM, V33, P397, DOI 10.1016/j.aei.2016.10.005
   Ma JY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4492
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Ni B, 2016, APPL MATH SER B, V31, P37, DOI 10.1007/s11766-016-3340-0
   Niu SJ, 2017, PATTERN RECOGN, V61, P104, DOI 10.1016/j.patcog.2016.07.022
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Shen TA, 2011, IEEE T MED IMAGING, V30, P774, DOI 10.1109/TMI.2010.2094623
   Sun J, 2016, APPL MATH SER B, V31, P177, DOI 10.1007/s11766-016-3378-z
   Wang B, 2014, IEEE T CYBERNETICS, V44, P418, DOI 10.1109/TCYB.2013.2256891
   Wang JZ, 2008, COMPUT MED IMAG GRAP, V32, P685, DOI 10.1016/j.compmedimag.2008.08.004
   Wang L, 2009, SIGNAL PROCESS, V89, P2435, DOI 10.1016/j.sigpro.2009.03.014
   Wang XF, 2015, PATTERN RECOGN, V48, P189, DOI 10.1016/j.patcog.2014.07.008
   Wang Y, 2006, IEEE T PATTERN ANAL, V28, P279, DOI 10.1109/TPAMI.2006.25
   Wu YQ, 2018, IEEE T SERV COMPUT, V11, P341, DOI 10.1109/TSC.2015.2501981
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xiao ZY, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/401413
   Yan XH, 2017, J COMPUT SCI TECH-CH, V32, P340, DOI 10.1007/s11390-017-1714-2
   Yan XH, 2018, INT J COOP INF SYST, V27, DOI 10.1142/S0218843017410015
   Yang X, 2016, IEEE T NEUR NET LEAR, V27, P32, DOI 10.1109/TNNLS.2015.2411613
   Yang X, 2014, INFORM SCIENCES, V277, P794, DOI 10.1016/j.ins.2014.03.014
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Yezzi A, 2002, J VIS COMMUN IMAGE R, V13, P195, DOI 10.1006/jvci.2001.0500
   Yu HP, 2016, J ADV MECH DES SYST, V10, DOI 10.1299/jamdsm.2016jamdsm0100
   Zhang DJ, 2016, INTEGR COMPUT-AID E, V23, P31, DOI 10.3233/ICA-150499
   Zhang DJ, 2017, INTEGR COMPUT-AID E, V24, P261, DOI 10.3233/ICA-170544
   Zhang KH, 2016, IEEE T CYBERNETICS, V46, P546, DOI 10.1109/TCYB.2015.2409119
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang LP, 2016, IEEE T GEOSCI REMOTE, V54, P6138, DOI 10.1109/TGRS.2016.2582209
   Zhao F, 2011, SIGNAL PROCESS, V91, P988, DOI 10.1016/j.sigpro.2010.10.001
   Zhou HY, 2010, MULTIMED TOOLS APPL, V49, P447, DOI 10.1007/s11042-009-0443-0
   Zhou Y, 2018, FUTURE GENER COMP SY, V79, P473, DOI 10.1016/j.future.2017.09.073
   Zhou Y, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-015-0594-2
   Zhou Y, 2016, J SUPERCOMPUT, V72, P2394, DOI 10.1007/s11227-016-1738-3
   Zhou YF, 2016, J ADV MECH DES SYST, V10, DOI 10.1299/jamdsm.2016jamdsm0102
   Zhu WZ, 2016, MULTIMED TOOLS APPL, V75, P2815, DOI 10.1007/s11042-015-2582-9
   Zou Q, 2016, NEUROCOMPUTING, V173, P346, DOI 10.1016/j.neucom.2014.12.123
NR 72
TC 88
Z9 90
U1 2
U2 44
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 18
BP 24097
EP 24119
DI 10.1007/s11042-018-5697-y
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ5VH
UT WOS:000441760900044
DA 2024-07-18
ER

PT J
AU Zeng, ZQ
   Wang, XD
   Yan, F
   Chen, YM
   Hong, CQ
AF Zeng, Zhiqiang
   Wang, Xiaodong
   Yan, Fei
   Chen, Yuming
   Hong, Chaoqun
TI Robust Discriminative multi-view K-means clustering with feature
   selection and group sparsity learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE K-means clustering; Feature selection; Group sparsity learning;
   Discriminative learning
ID FEATURE-EXTRACTION; INFORMATION; REGRESSION; SUBSPACE; MODELS
AB With the rapid development of information technologies, more and more data are collected from multiple sources, which contain different perspectives of the data. To accurately explore the shared information among multiple views, K-means based multi-view clustering methods are designed and widely used in various applications for their simplicity and efficiency. However, all of these methods cluster data in the original high-dimensional feature space which is extremely time-consuming and sensitive to outliers, or cluster data in the embedded feature space for each view, which is hard to find the optimal reduced dimensionality. To solve these problems, we propose a robust discriminative multi-view K-means clustering with feature selection and group sparsity learning. Compared to the state-of-the-arts, the proposed algorithm has two advantages: 1) Discriminative K-means clustering and feature learning are integrated jointly into a single framework, where robust and accurate clustering results are obtained in the embedded feature space with an l (2, 1)-norm based loss function. 2) Group sparsity constraints are imposed to select the most relevant features and the most important views. We apply the proposed algorithm to serval kinds of multimedia understanding applications. Experimental results demonstrate the effectiveness of the proposed algorithm.
C1 [Zeng, Zhiqiang; Wang, Xiaodong; Yan, Fei; Chen, Yuming; Hong, Chaoqun] Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
C3 Xiamen University of Technology
RP Wang, XD (corresponding author), Xiamen Univ Technol, Coll Comp & Informat Engn, Xiamen 361024, Peoples R China.
EM xdwangjsj@xmut.edu.cn
RI Chen, Yumin/JDD-4884-2023; wang, xiao/HZI-9156-2023
OI Chen, Yumin/0000-0003-1981-5827; 
FU National Natural Science Foundation of Fujian Province, China [2016
   J01324, 2017 J01511]; Xiamen Science and Technology Planning Project
   [3502Z20143030, 3502Z20103037, 3502Z20133043]; Scientific Research Fund
   of Fujian Provincial Education Department [JA15385, JAT170417]
FX This paper is supported by National Natural Science Foundation of Fujian
   Province, China (Grant Nos. 2016 J01324, 2017 J01511), Xiamen Science
   and Technology Planning Project (Nos. 3502Z20143030, 3502Z20103037,
   3502Z20133043), Scientific Research Fund of Fujian Provincial Education
   Department (Nos. JA15385, JAT170417).
CR [Anonymous], ACCV, DOI DOI 10.1007/978-3-642-37331-2
   [Anonymous], 2011, INT C NEURAL INF PRO
   [Anonymous], 2013, P AAAI
   Cai D., 2010, KDD, P333
   Chang XJ, 2015, AAAI CONF ARTIF INTE, P2532
   De Wang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P306, DOI 10.1007/978-3-662-44845-8_20
   Ding C., 2007, P 24 INT C MACH LEAR, P521
   Du L, 2013, IEEE DATA MINING, P131, DOI 10.1109/ICDM.2013.23
   Dueck D, 2007, IEEE I CONF COMP VIS, P198
   Hou CP, 2015, IEEE T NEUR NET LEAR, V26, P1287, DOI 10.1109/TNNLS.2014.2337335
   Hou CP, 2013, INFORM PROCESS MANAG, V49, P871, DOI 10.1016/j.ipm.2013.01.004
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Li YQ, 2015, AAAI CONF ARTIF INTE, P2750
   Li Z., 2012, P AAAI C ART INT, P1026
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Nie F., 2016, IJCAI, P1881
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Nie FP, 2016, AAAI CONF ARTIF INTE, P1302
   Nie FP, 2012, PATTERN RECOGN LETT, V33, P485, DOI 10.1016/j.patrec.2011.11.028
   Shang RH, 2016, PATTERN RECOGN, V55, P172, DOI 10.1016/j.patcog.2016.01.035
   Siddiqi MH, 2016, MULTIMED TOOLS APPL, V75, P935, DOI 10.1007/s11042-014-2333-3
   Song JK, 2014, IEEE T CYBERNETICS, V44, P1225, DOI 10.1109/TCYB.2013.2289351
   Wang H., 2013, INT C MACHINE LEARNI, P352
   Wang H, 2012, BIOINFORMATICS, V28, pI127, DOI 10.1093/bioinformatics/bts228
   Wang H, 2012, BIOINFORMATICS, V28, P229, DOI 10.1093/bioinformatics/btr649
   Wang S., 2016, LNCS LNAI, V9851, P281, DOI [10.1007/978-3-319-46128-1_18, DOI 10.1007/978-3-319-46128-1_18]
   Wang XD, 2018, MULTIMED TOOLS APPL, V77, P3083, DOI 10.1007/s11042-017-4990-5
   Wang XD, 2017, IMAGE VISION COMPUT, V63, P10, DOI 10.1016/j.imavis.2017.05.004
   Wang XD, 2016, J VIS COMMUN IMAGE R, V41, P272, DOI 10.1016/j.jvcir.2016.10.007
   Wang XD, 2016, NEUROCOMPUTING, V200, P47, DOI 10.1016/j.neucom.2016.03.017
   Xu JL, 2017, IEEE T IMAGE PROCESS, V26, P3016, DOI 10.1109/TIP.2017.2665976
   Xu JL, 2016, PROC CVPR IEEE, P5356, DOI 10.1109/CVPR.2016.578
   Yan Y, 2016, IEEE T MULTIMEDIA, V18, P2494, DOI 10.1109/TMM.2016.2602938
   Yang XS, 2016, MODEL OPTIM SCI TECH, V7, P1, DOI 10.1007/978-3-319-26245-1_1
   Yang Y, 2008, IEEE T MULTIMEDIA, V10, P437, DOI 10.1109/TMM.2008.917359
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P572, DOI 10.1109/TMM.2012.2234731
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yang Y, 2010, IEEE T IMAGE PROCESS, V19, P2761, DOI 10.1109/TIP.2010.2049235
   Yang Yi., 2011, Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI'11, P555
   Yang YC, 2011, CURR NEUROVASC RES, V8, P1, DOI 10.2174/156720211794520215
   Yang YS, 2009, PROCEEDINGS OF 2009 CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE & SYSTEM DYNAMICS, VOL 8, P175, DOI 10.1145/1631272.1631298
   Zhang HW, 2014, IEEE T IMAGE PROCESS, V23, P2996, DOI 10.1109/TIP.2014.2325784
   Zhuge WZ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176769
NR 48
TC 3
Z9 3
U1 0
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2018
VL 77
IS 17
BP 22433
EP 22453
DI 10.1007/s11042-018-6033-2
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GQ1DD
UT WOS:000441364500037
DA 2024-07-18
ER

PT J
AU Hu, H
   Zhang, HQ
   Yang, YJ
AF Hu, Hao
   Zhang, Hongqi
   Yang, Yingjie
TI Security risk situation quantification method based on threat prediction
   for multimedia communication network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication network; Situation awareness; Threat
   prediction; Risk quantification; Vulnerability analysis; Attack-defense
ID TIME-SERIES; MODEL
AB Multimedia communication network has gained remarkable popularity by a wide spectrum of users nowadays. It is easier that the potential threats conceal within the large-scale net flow of multimedia communication traffic. Once vulnerability exploitation occurs, the latent risk will be brought to the surface, causing a series of safety problems. Thus, the vulnerability analysis and threat prediction are becoming critical issues. Recently years, many investigations have been made. However, they are not sufficient. To provide a comprehensive view of the threat scenario and present a quantitative risk-aware approach, we propose a novel method for threat identification, and further we build a quantitative security risk model with it. Actually, two algorithms are proposed, namely dynamic Bayesian attack graph based threat prediction algorithm, and threat prediction based security risk quantification algorithm. The first algorithm aims to provide full prediction information with threat scenario. The second algorithm quantifies the threat in the first algorithm into the security risk from two levels: host and network. The examples indicate that our method is feasible and scalable, which enables a manager to quantify the risks of any identified threat or ongoing attack and to recognize the vulnerable multimedia devices to keep secure multimedia communication.
C1 [Hu, Hao; Yang, Yingjie] Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Henan, Peoples R China.
   [Zhang, Hongqi] Zhengzhou Informat Sci & Technol Inst, Zhengzhou, Henan, Peoples R China.
   [Hu, Hao; Zhang, Hongqi; Yang, Yingjie] Henan Key Lab Informat Secur, Zhengzhou, Henan, Peoples R China.
C3 PLA Information Engineering University; PLA Information Engineering
   University
RP Hu, H (corresponding author), Zhengzhou Informat Sci & Technol Inst, Dept Comp Sci & Informat Engn, Zhengzhou, Henan, Peoples R China.; Hu, H (corresponding author), Henan Key Lab Informat Secur, Zhengzhou, Henan, Peoples R China.
EM wjjhh_908@163.com
RI Yang, Yingjie/B-4162-2013
OI Hu, Hao/0000-0003-4888-6368
FU National High Technology Research and Development Program of China
   [2012AA012704, 2015AA016006]; National Key Research and Development
   Program of China [2016YFF0204003]; Equipment Pre-research Foundation
   during the 13th Five-Year Plan [61400020201]; CCF-Venus "Hongyan"
   research plan of China [2017003]; Key Lab of Information Network
   Security, Ministry of Public Security [C15604]
FX The authors would like to thank the reviewers for their detailed reviews
   and constructive comments. The authors would like to thank to Dr. Yuling
   Liu and Prof. Runguo Ye for their valuable discussions. This work is
   supported by the National High Technology Research and Development
   Program of China (2012AA012704, 2015AA016006), the National Key Research
   and Development Program of China (2016YFF0204003), the Equipment
   Pre-research Foundation during the 13th Five-Year Plan (61400020201),
   CCF-Venus "Hongyan" research plan of China (2017003) and the Key Lab of
   Information Network Security, Ministry of Public Security (C15604).
CR Ahmad A, 2015, 2015 1ST IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM), P286, DOI 10.1109/BigMM.2015.48
   [Anonymous], 2016, NATL VULNERABILITY D
   [Anonymous], 2016, ARCSIGHT ESM ENTERPR
   Bass T, 2000, COMMUN ACM, V43, P99, DOI 10.1145/332051.332079
   Ben Fredj O, 2015, SECUR COMMUN NETW, V8, P2477, DOI 10.1002/sec.1190
   Cai Z., 2014, Comput. Model. New Technol, V18, P151
   Chen G, 2006, P 9 INT C INF FUS FL, P789
   Dai FF, 2015, IET INFORM SECUR, V9, P344, DOI 10.1049/iet-ifs.2014.0272
   Endsley M. R., 1988, P HUM FACT SOC ANN M, V32, P97, DOI DOI 10.1177/154193128803200221
   Fava DS, 2008, IEEE T INF FOREN SEC, V3, P359, DOI 10.1109/TIFS.2008.924605
   Ge P, 2013, INT J ENVIRON POLLUT, V51, P206, DOI 10.1504/IJEP.2013.054030
   GhasemiGol M, 2016, COMPUT SECUR, V58, P83, DOI 10.1016/j.cose.2015.11.005
   Hao YH, 2016, PHYSICA A, V462, P674, DOI 10.1016/j.physa.2016.06.130
   Jiang D, 2016, MULTIMED TOOLS APPL, V75, P1, DOI DOI 10.1007/S11042-015-3239-4
   Kim J, 2016, J REAL-TIME IMAGE PR, V12, P465, DOI 10.1007/s11554-015-0501-y
   King JA, 2010, METRICS AND METHODS FOR SECURITY RISK MANAGEMENT, P3, DOI 10.1016/B978-1-85617-978-2.00007-1
   Kong-wei L., 2005, INT J INF SECUR, V4, P71, DOI DOI 10.1007/S10207-004-0060-X
   Koukopoulos Dimitrios, 2008, 2008 Third International Conference on Communications and Networking in China (CHINACOM), P1259, DOI 10.1109/CHINACOM.2008.4685256
   Koukopoulos D, 2009, MINES 2009: FIRST INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION NETWORKING AND SECURITY, VOL 1, PROCEEDINGS, P439, DOI 10.1109/MINES.2009.237
   Li A, 2017, MULTIMED TOOLS APPL, V76, P26249, DOI 10.1007/s11042-016-4115-6
   Lian SG, 2015, TELECOMMUN SYST, V59, P289, DOI 10.1007/s11235-014-9935-y
   Liang Ying, 2010, Proceedings of the 2nd International Conference on Software Engineering and Data Mining (SEDM 2010), P101
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Liu SC, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P517, DOI 10.1109/SNPD.2016.7515951
   Musa S, 2007, IEEE INT CONF INF VI, P726
   Nandi AK, 2016, COMPUT OPER RES, V75, P118, DOI 10.1016/j.cor.2016.05.005
   Ou XM, 2005, USENIX ASSOCIATION PROCEEDINGS OF THE 14TH USENIX SECURITY SYMPOSIUM, P113
   Paul A, 1999, 5 INT C INF SYST AN, P443
   Schiffman M., COMMON VULNERABILITY
   Serra E, 2015, ACM T INFORM SYST SE, V17, DOI 10.1145/2699907
   Tse R, 2017, MOBILE NETW APPL, P1
   Wang L, 2013, SYST RES BEHAV SCI, V30, P244, DOI 10.1002/sres.2179
   Wang Y, 2013, SCI CHINA INFORM SCI, V6, P1
   Wu J, 2018, IEEE T BIG DATA, V4, P408, DOI 10.1109/TBDATA.2016.2616146
   Wu YM, 2017, IEEE MULTIMEDIA, V24, P48, DOI 10.1109/MMUL.2017.19
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yang TH, 2017, MULTIMED TOOLS APPL, V76, P19411, DOI 10.1007/s11042-015-3139-7
   Ye J, 2012, PERVASIVE MOB COMPUT, V8, P36, DOI 10.1016/j.pmcj.2011.01.004
   Yi S, 2014, P 2013 IE INT C ANT
   Yu W, 2010, IEEE T PARALL DISTR, V21, P1501, DOI 10.1109/TPDS.2009.161
   Zhang W., 2012, J INFORM COMPUTATION, V9, P1548
   Zhao-Yang Qu, 2010, 2010 2nd Conference on Environmental Science and Information Application Technology (ESIAT 2010), P496, DOI 10.1109/ESIAT.2010.5567380
NR 42
TC 9
Z9 13
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2018
VL 77
IS 16
BP 21693
EP 21723
DI 10.1007/s11042-017-5602-0
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GP9JM
UT WOS:000441233300060
DA 2024-07-18
ER

PT J
AU Ali, HH
   Sunar, MS
   Kolivand, H
AF Ali, Hatam H.
   Sunar, Mohd Shahrizal
   Kolivand, Hoshang
TI Realistic real-time rendering of light shafts using blur filter:
   considering the effect of shadow maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Light shafts; Soft shadows; Bilateral filter; Downsamling
ID VOLUMETRIC SHADOWS; SCENES
AB The ray marching method has become the most attractive method to provide realism in rendering the effects of light scattering in the participating media of numerous applications. This has attracted significant attention from scientific community. Up-sampling of ray marching method is suitable for rendering light shafts of realistic scenes, but suffers of consume a lot of time for rendering. Therefore, some encouraging outcomes have been achieved by using down-sampling of ray marching approach to accelerate rendered scenes. However, these methods are inherently prone to artifacts, aliasing and incorrect boundaries due to the reduced number of sample points along view rays. This research proposes a realistic real-time technique to generate soft light shafts by making use downsampling of ray marching in generating light shafts. The bilateral filtering is then applied to overcome all defects that caused by downsampling process to make a scene with smoothing transition while preserving on the edges. The contribution of this technique is to improve the boundaries of light shafts taking into account the effect of shadows. This technique allows obtaining soft marvelous light shafts, having a good performance and high quality. Thus, it is suitable for interactive applications.
C1 [Ali, Hatam H.; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, Inst Human Ctr Engn, IRDA Digital Media Ctr, Skudai 81310, Johor, Malaysia.
   [Ali, Hatam H.; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, Inst Human Ctr Engn, Game Innovat Ctr Excellence, Skudai 81310, Johor, Malaysia.
   [Ali, Hatam H.; Sunar, Mohd Shahrizal] Univ Teknol Malaysia, Fac Comp, Dept Software Engn, Skudai 81310, Johor, Malaysia.
   [Kolivand, Hoshang] Liverpool John Moores Univ, Dept Comp Sci, Liverpool L3 3AF, Merseyside, England.
C3 Universiti Teknologi Malaysia; Universiti Teknologi Malaysia; Universiti
   Teknologi Malaysia; University of Liverpool; Liverpool John Moores
   University
RP Ali, HH (corresponding author), Univ Teknol Malaysia, Inst Human Ctr Engn, IRDA Digital Media Ctr, Skudai 81310, Johor, Malaysia.; Ali, HH (corresponding author), Univ Teknol Malaysia, Inst Human Ctr Engn, Game Innovat Ctr Excellence, Skudai 81310, Johor, Malaysia.
EM ali_hattam@yahoo.com; shahrizal@utm.my; h.kolivand@ljmu.ac.uk
RI ali, hatem/ABB-4403-2020; Kolivand, Hoshang/F-4736-2011; Sunar, Mohd
   Shahrizal/AFQ-7366-2022; Kolivand, Hoshang/B-2501-2016
OI Sunar, Mohd Shahrizal/0000-0002-0244-1622; Ali, Hatem
   Salama/0000-0002-7306-3454; Kolivand, Hoshang/0000-0001-5460-5679
FU MaGIC- X (Media and Games Innovation Centre of Excellence) UTM-IRDA
   Digital Media Centre Universiti Teknologi Malaysia Skudai Johor MALAYSIA
FX This research was supported by MaGIC- X (Media and Games Innovation
   Centre of Excellence) UTM-IRDA Digital Media Centre Universiti Teknologi
   Malaysia 81310 Skudai Johor MALAYSIA.
CR Ali HH, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178415
   Ali HH, 2017, MULTIMED TOOLS APPL, V76, P2591, DOI 10.1007/s11042-016-3254-0
   Ament M, 2014, IEEE T VIS COMPUT GR, V20, P2437, DOI 10.1109/TVCG.2014.2346333
   Baran I, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866200
   Bavoil L, 2011, NVIDIA DIRECTX, V11
   Billeter M., 2010, P C HIGH PERF GRAPH, P39
   Chandrasekhar S., 2013, RAD TRANSFER
   Chen J, 2016, U.S. Patent, Patent No. [9,280,848, 9280848]
   Chen J, 2011, S INT 3D GRAPH GAM A
   Chen SY, 2006, LECT NOTES COMPUT SC, V4291, P161
   Dobashi Y, 2000, COMP GRAPH, P19, DOI 10.1145/344779.344795
   Dobashi Y, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P31, DOI 10.1109/PCCGA.2000.883864
   DOBASHI Y., 2002, GRAPHICS HARDWARE, P99
   Engelhardt T., 2010, Proceedings_of_the_2010_ ACM_SIGGRAPH_symposium_on_Interactive_3D_Graphics_and_Games, P119
   Forest V, 2011, OBJECT BASED SHADOWE
   Imagire T, 2007, VISUAL COMPUT, V23, P935, DOI 10.1007/s00371-007-0140-9
   Klehm O., 2015, P 41 GRAPH INT C, P115
   Klehm O., 2014, J COMPUT GRAPH TECHN, V3, P7
   Lawonn K, 2014, VISION, DOI [10.2312/VMV.20141273, DOI 10.2312/VMV.20141273]
   Li S, 2007, INT C COMP AID DES C, P161
   Lin HY, 2013, IET IMAGE PROCESS, V7, P762, DOI 10.1049/iet-ipr.2013.0067
   Max N. L., 1986, Computer Graphics, V20, P117, DOI 10.1145/15886.15899
   NOWROUZEZAHRAI D, 2011, ACM T GRAPHIC, V30
   Pharr M., 2004, Physically Based Rendering: From Theory to Implementation
   Shin T, 2013, RENDERING PARTICLES
   Siegel R., 1992, Thermal Radiation Heat Transfer
   Stumpfel J., 2004, THESIS
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Toth B., 2009, P EUROGRAPHICS, P57
   Wang D. L., 2014, 2014 International Conference on Information Science, Electronics and Electrical Engineering (ISEEE), P619, DOI 10.1109/InfoSEEE.2014.6948188
   Wyman C, 2011, PROC ACM SIGGRAPH S, P33
   Wyman C, 2008, RT08: IEEE/EG SYMPOSIUM ON INTERACTIVE RAY TRACING 2008, PROCEEDINGS, P87, DOI 10.1109/RT.2008.4634627
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
NR 33
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17007
EP 17022
DI 10.1007/s11042-017-5267-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300046
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Douglas, M
   Bailey, K
   Leeney, M
   Curran, K
AF Douglas, Mandy
   Bailey, Karen
   Leeney, Mark
   Curran, Kevin
TI An overview of steganography techniques applied to the protection of
   biometric data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganograpy; Biometrics; Image analysis; Security
AB Identification of persons by way of biometric features is an emerging phenomenon. Over the years, biometric recognition has received much attention due to its need for security. Amongst the many existing biometrics, fingerprints are considered to be one of the most practical ones. Techniques such as watermarking and steganography have been used in attempt to improve security of biometric data. Watermarking is the process of embedding information into a carrier file for the protection of ownership/copyright of music, video or image files, whilst steganography is the art of hiding information. This paper presents an overview of steganography techniques applied in the protection of biometric data in fingerprints. It is novel in that we also discuss the strengths and weaknesses of targeted and blind steganalysis strategies for breaking steganography techniques.
C1 [Douglas, Mandy; Bailey, Karen; Leeney, Mark] LetterkennyPort RoadCo, Inst Technol, Donegal, Ireland.
   [Curran, Kevin] Ulster Univ, Fac Comp & Engn, Ambient Intelligence & Virtual Worlds Res Grp, Coleraine, Londonderry, North Ireland.
C3 Ulster University
RP Douglas, M (corresponding author), LetterkennyPort RoadCo, Inst Technol, Donegal, Ireland.
EM mandy.douglas@lyit.ie; karen.bailey@lyit.ie; mark.leeney@lyit.ie;
   kj.curran@ulster.ac.uk
RI Curran, Kevin/AAC-4865-2019
OI Curran, Kevin/0000-0001-5237-5355
CR Al-Ani MS., 2013, SCI TECHNOLOGY, V3, P112
   Al-Hussain A, 2008, BIOMETRIC BASED AUTH
   Amritha G, 2013, INT J COMPUT TRENDS, V4
   ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   [Anonymous], THESIS
   [Anonymous], 2014, CORR
   [Anonymous], 2017, NY TIMES
   Ataby A, 2010, INT ARAB J INFORM TE, V7
   Awasthi V, 2012, INT J EMERG TECHNOL, V2
   Bailey K, 2006, MULTIMED TOOLS APPL, V30, P55, DOI 10.1007/s11042-006-0008-4
   Bandyopadhyay T, 2010, P 4 NAT C COMP NAT D
   Bansal R, 2008, FIFTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 3, PROCEEDINGS, P266, DOI 10.1109/FSKD.2008.80
   Barnes JG, 2011, FINGERPRINT SOURCEBO, pP7
   Barve S, 2011, INT J COMPUT SCI COM, V1
   Bateman P., 2008, IMAGE STEGANOGRAPHY
   Bhattacharyya S, 2012, COMPUT NETW INF SECU, V7
   Bhowmik P, 2012, INT J SCI TECHNOL RE, V1
   Cant F, 2009, SECRET YOUR CHILDS F
   Chandramouli R, 2004, IMAGE STEGANOGRAPHY
   Chapman C, 2010, EVERYTHING YOU NEED
   Cheddad A, 2008, INT C WORKSH ENG COM
   Chedded A, 2009, STEGANOFLAGE NEW IMA
   Chedded A, 2010, SIGNAL PROCESS, V90
   Chen P.Y., 2006, INT J APPL SCI ENG, V4, P275, DOI DOI 10.6703/IJASE/2006.4(3).275
   Chhikara R, 2013, INT J ENG INNOV TECH, V3
   COX IJ, 2008, MKS MULTIMED INFORM, P1
   Cummins J., 2004, STEGANOGRAPHY DIGITA
   Currie DL, 1996, P 19 NAT INF SYST SE
   Danti A, 2010, RECENT TRENDS IMAGE
   El-Sayed M, 2012, 2 INT C COMM INF TEC
   Elysium Ltd, 2007, WHAT DISCE WAV TRANS
   Eriksson M, 2001, THESIS, P29
   Farid H, 2002, P IEEE INT C IMAGE P
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Fridrich J, 2002, P MULT SEC WORKSH AC
   Fu DongdongYQ, 2006, MULTIMEDIA SIGNAL PR
   Galbally J, 2011, TELECOMMUN SYST, V47, P243, DOI 10.1007/s11235-010-9316-0
   Ganic E, 2004, ACM MULTIMEDIA SECUR
   Ghasemi E., 2011, P INT MULTICONFERENC, V1
   Goel P., 2008, DATA HIDING DIGITAL
   Golabi S, 2012, INT J COMPUTER THEOR, V4
   Guillermito A, 2004, FEW TOOLS DISCOVER H
   Gunjal BL, 2010, J EMERGING TRENDS CO, V2
   Gupta S, 2012, MODERN ED COMPUTER S, V6
   Haque SMRafizul, 2008, INTERACTION SYSTEM D
   Harmanpreet K, 2014, INT J SCI RES DEV, V2
   Hashemi AS, 2011, 7 INT C INF TECHN AP
   Hong L, 1997, LECT NOTES COMPUT SC, V1206, P103, DOI 10.1007/BFb0015985
   Jain A.K., 1999, Biometrics: Personal identification in networked society, DOI DOI 10.1007/978-0-387-32659-7
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2012, COMPUTER, V45, P87, DOI 10.1109/MC.2012.364
   Johnson N, 1999, C WORKSH INTR DET RE, P10
   Johnson N F., 1998, Steganalysis of images created using current steganography software
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Jung KH, 2017, MULTIMED TOOLS APPL, V76, P13127, DOI 10.1007/s11042-016-3739-x
   Jung KH, 2016, IETE TECH REV, V33, P441, DOI 10.1080/02564602.2015.1102099
   Kamble S, 2012, DWT SVD BASED SECURE
   Kavitha M, 2012, STEGANOGRAPHY USING, V2
   Ker AD, 2004, QUANTITATIVE EVALUAT
   King R, 2013, NEXT ROUND SMARTPHON
   Kocharyan D, 2001, INT J MULTIMEDIA TEC, V1
   Koeling JM, 2004, DIGITAL IMAGING PRAC
   Kumar M, 2011, LAP LAMBERT, P2
   Kumari Meenu, 2010, Journal of Advances in Information Technology, V1, P141, DOI 10.4304/jait.1.3.141-145
   Kumari M., 2010, J ADV INFORM TECHNOL, V1
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Lavanya N, 2012, INT J COMPUTER SCI I, V3
   Lewis N., 2003, P IASTED INT C COMM, V33, P85
   Liao PS, 2001, J INF SCI ENG, V17, P713
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Lussan F, 2011, NOVEL APPROACH DIGIT
   Maio D., 1997, IEEE Transactions on Pattern Analysis and Machine Intelligence, V19
   Majumder S, 2013, IET BIOMETRICS, V2, P21, DOI 10.1049/iet-bmt.2012.0052
   Malkhasyan N, 2013, INT J BINFORMATION T, V20
   Maltoni D., 2009, Handbook of Fingerprint Recognition, P57
   Maltoni D, 2009, HDB FINGERPRINT RECO, P58
   Mayhew S, 2012, EXPLAINER DYNAMIC SI
   Memon N, 2001, SECURITY WATERMARKIN, V4314
   Morkel T, 2005, P 5 ANN INF SEC S AF
   Nagar A, 2012, IEEE T INF FOREN SEC, V7, P255, DOI 10.1109/TIFS.2011.2166545
   O'Gorman Lawrence., 1998, Information Security Technical Report, V3, P21
   Patil K, 2012, INT C ADV COMM COMP
   Patra A, 2006, DEV EFFICIENT METHOD, pp4
   Payra AK, 2013, STEGANOLOGY COMPUTER
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Pevny T, 2006, IEEE T INFORM FORENS, V3
   Po WH, 2013, REVERSIBLE DATA HIDI
   Prabakaran G, 2013, INT J COMPUTER ENG T, V4
   Praveen AR, 2011, INT J COMPUTER SCI, V1
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Provos N, 2002, P 2002 NETW DIST SYS
   Rakhi S, 2013, INT J ELECT COMMUNIC, V2
   Reddy P, 2007, 562 U NEW ORL THES
   Redinbo RG, 2008, OVERVIEW JPEG IMAGE
   Rocha A, 2007, J THEORETICAL APPL C, V14
   Rowayda SA, 2012, INT J ADV COMPUT SCI, V3
   Saha B, 2012, DEFENCE SCI J, V62, P11, DOI 10.14429/dsj.62.1436
   Schaathun HG, 2012, MACHINE LEARNING IMA, P12
   Schaathun HG, 2012, STEGANALYSIS JPEG DO, DOI [10.1002/9781118437957.ch8, DOI 10.1002/9781118437957.CH8]
   Shanthini B, 2012, J COMPUTER SCI, V7
   Shaw AK, 2013, PROC TECH, V10, P172, DOI 10.1016/j.protcy.2013.12.350
   Shejul A, 2010, INT C DATA STORAGE D
   Singh AK, 2013, LECT NOTES COMPUT SC, V8271, P235, DOI 10.1007/978-3-642-44949-9_22
   Solanki K, 2007, INFORM HIDING 9 INT
   Subhedar M, 2015, INT C INF COMM TECHN
   Sukhdeep K, 2014, INT J COMPUTER SCI M, V3, pp821
   Sumak M, 2008, STEGANOGRAPHY DETECT
   Sverdlov A, 2005, ROBUST DCT SVD DOMAI
   Traynor K, 2014, VOICE BIOMETRICS SEC
   Uludag U Jain, 2004, CASE STUDY FINGERPRI
   Vaghela DG, 2013, J INFORM KNOWLEDGE R, V2
   Wang CM, 2008, J SYST SOFTWARE, V81, P150, DOI 10.1016/j.jss.2007.01.049
   Wayner P, 2009, DISAPPEARING CRYPTOG, P344
   Wayner Peter., 2002, DISAPPEARING CRYPTOG
   Westfeld A, 2000, LECT NOTES COMPUT SC, V1768, P61
   Westfeld A, 2003, INFORM HIDING LECT N, V2578
   Westfeld A, 1999, P INT WORKSH INF HID
   Woodward J., 2003, Biometrics A Look at Facial Recognition
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Xiaomei Q, 2007, ASPECTS THEORETICAL, V4681, P970
   Zaheera ZA, 2013, C K SISW SAINS KOMP, P44
   Zin WW, 2013, INT J SCI RES, V2
NR 124
TC 47
Z9 52
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17333
EP 17373
DI 10.1007/s11042-017-5308-3
PG 41
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300061
DA 2024-07-18
ER

PT J
AU Koutlemanis, P
   Zabulis, X
AF Koutlemanis, Panagiotis
   Zabulis, Xenophon
TI Tracking of multiple planar projection boards for interactive
   mixed-reality applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mixed reality; Augmented reality; Pose estimation; Detection; Tracking;
   Interactive system; Projector camera system
AB The case of mixed-reality projector-camera systems is considered and, in particular, those which employ hand-held boards as interactive displays. This work focuses upon the accurate, robust, and timely detection and pose estimation of such boards, to achieve high-quality augmentation and interaction. The proposed approach operates a camera in the near infrared spectrum to filter out the optical projection from the sensory input. However, the monochromaticity of input restricts the use of color for the detection of boards. In this context, two methods are proposed. The first regards the pose estimation of boards which, being computationally demanding and frequently used by the system, is highly parallelized. The second uses this pose estimation method to detect and track boards, being efficient in the use of computational resources so that accurate results are provided in real-time. Accurate pose estimation facilitates touch detection upon designated areas on the boards and high-quality projection of visual content upon boards. An implementation of the proposed approach is extensively and quantitatively evaluated, as to its accuracy and efficiency. This evaluation, along with usability and pilot application investigations, indicate the suitability of the proposed approach for use in interactive, mixed-reality applications.
C1 [Koutlemanis, Panagiotis; Zabulis, Xenophon] Fdn Res & Technol Hellas FORTH, Inst Comp Sci, N Plastira 100, Iraklion 70013, Greece.
RP Zabulis, X (corresponding author), Fdn Res & Technol Hellas FORTH, Inst Comp Sci, N Plastira 100, Iraklion 70013, Greece.
EM koutle@ics.forth.gr; zabulis@ics.forth.gr
RI Zabulis, Xenophon/D-6186-2011
OI Zabulis, Xenophon/0000-0002-1520-4327
FU Foundation for Research and Technology Hellas-Institute of Computer
   Science (FORTH-ICS) internal RTD Programme "Ambient Intelligence and
   Smart Environments"
FX This work was supported by the Foundation for Research and Technology
   Hellas-Institute of Computer Science (FORTH-ICS) internal RTD Programme
   "Ambient Intelligence and Smart Environments". Authors are grateful to
   Mr. Antonis Hatziantoniou for the implementation of the pilot
   application and to Mr. Antonis Katzourakis for its graphical design.
CR Angeline P. J., 1998, Evolutionary Programming VII. 7th International Conference, EP98. Proceedings, P601, DOI 10.1007/BFb0040811
   [Anonymous], 2011, P 24 ANN ACM S US IN, DOI DOI 10.1145/2047196.2047255
   [Anonymous], 2015, SIGGRAPH Asia 2015 Emerging Technologies, DOI DOI 10.1145/2818466.2818485
   [Anonymous], COMPUTER VISION PATT
   [Anonymous], 2013, PROC ASIAN C COMPUT
   [Anonymous], INT C PERV COMP
   [Anonymous], 2005, P 18 ANN ACM S US IN, DOI [10.1145/1095034.1095054, DOI 10.1145/1095034.1095054]
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1977, TECHNIQUES AUTOMATIC
   [Anonymous], PROC WORKSH IEEE COM
   [Anonymous], VISUAL COMPUTER
   [Anonymous], 2015, Open Source Computer Vision Library
   [Anonymous], IEEE INT AUGM REAL T
   [Anonymous], 2005, Proceedings of the 18th annual ACM symposium on User interface software and technology
   [Anonymous], 1995, 1995 IEEE INT C
   [Anonymous], INT C COMP VIS GRAPH
   [Anonymous], 2009 IEEE 12 INT C C
   Audet Samuel, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P47, DOI 10.1109/CVPR.2009.5204319
   Audet S, 2013, VIRTUAL REAL-LONDON, V17, P157, DOI 10.1007/s10055-012-0210-9
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bonnard Q., 2013, Chilitags 2: Robust fiducial markers for augmented reality and robotics
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Choi CH, 2012, IEEE INT C INT ROBOT, P3877, DOI 10.1109/IROS.2012.6386065
   Grammenos D., 2011, e-Perimetron, V6, P57
   Grammenos D, 2011, TEI 2011: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION, P57
   Gross Tom., 2008, CHI '08 extended abstracts on Human factors in computing systems, P3465
   Gupta Shilpi, 2006, 2006 IEEE/ACM International Symposium on Mixed and Augmented Reality, P177, DOI 10.1109/ISMAR.2006.297811
   Hodan T, 2015, IEEE INT C INT ROBOT, P4421, DOI 10.1109/IROS.2015.7354005
   Jones B. R., 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P165, DOI 10.1109/ISMAR.2010.5643566
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Kjeldsen R, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P402, DOI 10.1109/AFGR.2002.1004187
   Launius R., 2005, Arkham Horror
   Lee Johnny C., 2004, P UIST, P123
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   Nakamura T, 2012, INT C PATT RECOG, P85
   Okumura K, 2013, IEEE INT CON MULTI
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Padeleris P., 2012, COMPUTER VISION PATT, P42
   Pinhanez Claudio., 2001, CHI 01, P369, DOI DOI 10.1145/634067.634285
   Raskar R, 2004, ACM T GRAPHIC, V23, P406, DOI 10.1145/1015706.1015738
   Rekimoto J., 2002, Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2002, P113, DOI 10.1145/503376.503397
   Roccetti M, 2014, MULTIMED TOOLS APPL, V69, P1131, DOI 10.1007/s11042-013-1512-y
   Roccetti M, 2012, J VIS COMMUN IMAGE R, V23, P426, DOI 10.1016/j.jvcir.2011.12.006
   Song P, 2007, LECT NOTES COMPUT SC, V4551, P956
   Sueishi T, 2015, P IEEE VIRT REAL ANN, P97, DOI 10.1109/VR.2015.7223330
   Summet J, 2005, LECT NOTES COMPUT SC, V3468, P37
   Tseng H.-Y., 2016, 2016 IEEE Winter Conference on Applications of Computer Vision (WACV), P1
   Xie X., 2014, Proc. of Solid-State Sensors, Actuators, P127
   Xie X, 2017, PROC IEEE MICR ELECT, P813, DOI 10.1109/MEMSYS.2017.7863532
   Xie X, 2014, J MICROMECH MICROENG, V24, DOI 10.1088/0960-1317/24/12/125014
   Xu QZ, 2018, MULTIMED TOOLS APPL, V77, P6311, DOI 10.1007/s11042-017-4537-9
   Yang J, 2017, MULTIMED TOOLS APPL, P1, DOI DOI 10.3389/FRNICB.2017.00832
   Yuancheng Luo, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563088
   Zabulis X, 2015, LECT NOTES COMPUT SC, V9163, P263, DOI 10.1007/978-3-319-20904-3_25
   Zhang Zhengyou., 2001, WORKSHOP PERCEPTIVE, P1, DOI DOI 10.1145/971478.971522
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 57
TC 2
Z9 2
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 13
BP 17457
EP 17487
DI 10.1007/s11042-017-5313-6
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO1WI
UT WOS:000439750300066
DA 2024-07-18
ER

PT J
AU Liu, YQ
   Guan, QX
   Zhao, XF
AF Liu, Yaqi
   Guan, Qingxiao
   Zhao, Xianfeng
TI Copy-move forgery detection based on convolutional kernel network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Copy-move forgery detection; Convolutional kernel network; Keypoint
   distribution strategy; Adaptive oversegmentation; Image forensics
ID IMAGE RETRIEVAL; SEGMENTATION; FUSION; CLOUD
AB Conventional copy-move forgery detection methods mostly make use of hand-crafted features to conduct feature extraction and patch matching. However, the discriminative capability and the invariance to particular transformations of hand-crafted features are not good enough, which imposes restrictions on the performance of copy-move forgery detection. To solve this problem, we propose to utilize Convolutional Kernel Network to conduct copy-move forgery detection. Convolutional Kernel Network is a kind of data-driven local descriptor with the deep convolutional architecture. It can achieve competitive performance for its excellent discriminative capability. To well adapt to the condition of copy-move forgery detection, three significant improvements are made: First of all, our Convolutional Kernel Network is reconstructed for GPU. The GPU-based reconstruction results in high efficiency and makes it possible to apply to thousands of patches matching in copy-move forgery detection. Second, a segmentation-based keypoint distribution strategy is proposed to generate homogeneous distributed keypoints. Last but not least, an adaptive oversegmentation method is adopted. Experiments on the publicly available datasets are conducted to testify the state-of-the-art performance of the proposed method.
C1 [Liu, Yaqi; Guan, Qingxiao; Zhao, Xianfeng] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.
   [Liu, Yaqi; Guan, Qingxiao; Zhao, Xianfeng] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Information Engineering, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Zhao, XF (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing 100093, Peoples R China.; Zhao, XF (corresponding author), Univ Chinese Acad Sci, Sch Cyber Secur, Beijing 100093, Peoples R China.
EM zhaoxianfeng@iie.ac.cn
RI Zhao, Xianfeng/AAE-7278-2021
OI Zhao, Xianfeng/0000-0002-5617-8399
FU NSFC [U1636102, U1536105]; National Key Technology RD Program
   [2016YFB0801003, 2016QY15Z2500]
FX This work was supported by the NSFC under U1636102 and U1536105, and
   National Key Technology R&D Program under 2016YFB0801003 and
   2016QY15Z2500.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Amin R, 2017, MULTIMED TOOLS APPL, P1
   Amin R, 2018, FUTURE GENER COMP SY, V78, P1005, DOI 10.1016/j.future.2016.12.028
   [Anonymous], 2015, P 24 INT JOINT C
   [Anonymous], ARXIV170607842
   [Anonymous], URBAN WATER QUALITY
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, ARXIV161009462
   [Anonymous], 2014, CoRR
   [Anonymous], ARXIV1409155
   [Anonymous], NEUROCOMPUTING
   [Anonymous], 2010, IEEE T IMAGE PROCESS
   [Anonymous], 2016, ARXIV160305027
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], 2017, Math. Models Methods Appl. Sci., DOI DOI 10.1142/S0218202517500373
   [Anonymous], 2014, ARXIV14126537
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], ECCV
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Chang V, 2017, J SYST SOFTWARE, V124, P195, DOI 10.1016/j.jss.2015.12.031
   Chang V, 2016, FUTURE GENER COMP SY, V57, P56, DOI 10.1016/j.future.2015.10.003
   Chang V, 2016, IEEE T SERV COMPUT, V9, P138, DOI [10.1109/ISSNIP.2015.7106910, 10.1109/TSC.2015.2491281]
   Christlein V., 2012, IEEE T INF FOREN SEC, V7, P1841, DOI DOI 10.1109/TIFS.2012.2218597
   Cozzolino D., 2015, IEEE T INF FOREN SEC, V10, P2284, DOI DOI 10.1109/TIFS.2015.2455334
   Cui JS, 2013, IEEE T SYST MAN CY-S, V43, P996, DOI 10.1109/TSMCA.2012.2223670
   Ferreira A, 2016, IEEE T IMAGE PROCESS, V25, P4729, DOI 10.1109/TIP.2016.2593583
   Fridrich J., 2003, P DIG FOR RES WORKSH, P133
   Li GH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1750
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li L., 2013, J. Inf. Hiding Multimedia Signal Process., V4, P46
   Li YA, 2013, FORENSIC SCI INT, V224, P59, DOI 10.1016/j.forsciint.2012.10.031
   Liu L, 2016, AAAI CONF ARTIF INTE, P1266
   Liu Y, 2015, IEEE IMAGE PROC, P4062, DOI 10.1109/ICIP.2015.7351569
   Liu Y, 2016, AAAI CONF ARTIF INTE, P201
   Liu Y, 2016, NEUROCOMPUTING, V181, P108, DOI 10.1016/j.neucom.2015.08.096
   Liu Y, 2012, INT C PATT RECOG, P898
   Lu YG, 2017, MULTIMED TOOLS APPL, V76, P10701, DOI 10.1007/s11042-015-3188-y
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mostajahi M, 2015, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2015.7298959
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Paulin M, 2017, INT J COMPUT VISION, V121, P149, DOI 10.1007/s11263-016-0924-3
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Popescu A., 2004, Hanover, Department of Computer Science, P32
   Preotiuc-Pietro D, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P729, DOI 10.18653/v1/P17-1068
   Pun CM, 2015, IEEE T INF FOREN SEC, V10, P1705, DOI 10.1109/TIFS.2015.2423261
   Rao Y, 2016, IEEE INT WORKS INFOR
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Shivakumar B.L., 2011, International Journal of Computer Science Issues (IJCSI), V8
   Silva E, 2015, J VIS COMMUN IMAGE R, V29, P16, DOI 10.1016/j.jvcir.2015.01.016
   Simo-Serra E, 2015, IEEE I CONF COMP VIS, P118, DOI 10.1109/ICCV.2015.22
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sohal A. S., 2017, COMPUT SECUR, P1
   Stamm Matthew C., 2016, P 4 ACM WORKSH INF H, P5
   Sun G, 2017, J NETW COMPUT APPL, V86, P34, DOI 10.1016/j.jnca.2016.11.024
   Tralic Dijana, 2013, Proceedings of the 2013 55th International Symposium. ELMAR-2013, P49
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang Y, 2018, FUTURE GENER COMP SY, V84, P160, DOI 10.1016/j.future.2017.06.025
   Yang Y, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4211
   Ye Liu, 2010, 2010 Proceedings of 16th International Conference on Virtual Systems and Multimedia (VSMM 2010), P26, DOI 10.1109/VSMM.2010.5665969
   Zandi M, 2016, IEEE T INF FOREN SEC, V11, P2499, DOI 10.1109/TIFS.2016.2585118
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang LM, 2017, MULTIMEDIA SYST, V23, P1, DOI 10.1007/s00530-016-0527-4
   Zhang XY, 2015, IEEE T NEUR NET LEAR, V26, P3034, DOI 10.1109/TNNLS.2015.2401595
   Zhang XY, 2015, NEUROCOMPUTING, V162, P163, DOI 10.1016/j.neucom.2015.03.056
NR 69
TC 68
Z9 77
U1 0
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 18269
EP 18293
DI 10.1007/s11042-017-5374-6
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900038
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, Y
   Kong, XW
   Feng, CY
AF Yang, Yong
   Kong, Xiangwei
   Feng, Chaoyu
TI Double-compressed JPEG images steganalysis with transferring feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE JPEG; Mismatched steganalysis; Double compression; Feature transform
AB Steganalysis is a technology of detecting the presence of secret messages in digital media. Recently, many algorithms have been proposed and achieved satisfactory detection accuracy. However, the performance of these algorithms will be reduced by double-compression, due to the mismatch between training and testing sets. To address this problem, we proposed Transferring Feature on Double-compressed JPEG images (TFD) to improve the detection accuracy. Specifically, our algorithm consists of two parts. First, we detect the double-compression of testing images by constructing multi-classifier with Markov feature. Then we transfer the steganalysis feature into a new feature space, in order to reduce the difference of feature distributions between training and testing sets. We intend to obtain a transformation matrix by adjusting the expectation and standard deviation of training set, minimizing the feature discrepancy between both sets and keeping classification ability of training set, simultaneously. The experimental results show that the proposed algorithm has better performance in double-compressed mismatched steganalysis.
C1 [Yang, Yong; Kong, Xiangwei; Feng, Chaoyu] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Kong, XW (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
EM kongxw@dlut.edu.cn
RI Kong, Xiangwei/IWL-9350-2023
FU Foundation for Innovative Research Groups of the NSFC [71421001];
   National Natural Science Foundation of China [61772111]
FX This work is supported by the Foundation for Innovative Research Groups
   of the NSFC (Grant no. 71421001), National Natural Science Foundation of
   China (Grant no. 61772111).
CR [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], INT SOC OPT PHOTON
   [Anonymous], SPIE IS AMP T ELECT
   [Anonymous], 2012, P MULTIMEDIA SECURIT
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2001, INF HID 4 INT WORKSH, DOI 10.1007/3-540-
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], INT SOC OPT PHOTON
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2011, INT WORKSHOP INF HID
   [Anonymous], MULTIMED TOOLS APPL
   Borgwardt KM, 2006, BIOINFORMATICS, V22, pE49, DOI 10.1093/bioinformatics/btl242
   El-Alfy ESM, 2017, MULTIMED TOOLS APPL, V76, P14535, DOI 10.1007/s11042-016-3855-7
   Holub V, 2014, EURASIP J INF SECUR, DOI 10.1186/1687-417X-2014-1
   Holub V, 2015, IEEE T INF FOREN SEC, V10, P219, DOI 10.1109/TIFS.2014.2364918
   Ker A.D., 2013, P 1 ACM WORKSH INF H, P4558, DOI DOI 10.1145/2482513.2482965
   Kong XW, 2016, NEUROCOMPUTING, V214, P458, DOI 10.1016/j.neucom.2016.06.037
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li XF, 2013, IEEE IMAGE PROC, P4432, DOI 10.1109/ICIP.2013.6738913
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Pevny T, 2008, IEEE T INF FOREN SEC, V3, P247, DOI 10.1109/TIFS.2008.922456
   Pevny T, 2007, PROC SPIE, V6505, DOI 10.1117/12.696774
   Provos N, 2001, USENIX ASSOCIATION PROCEEDINGS OF THE 10TH USENIX SECURITY SYMPOSIUM, P323
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Song Xinzhang, 2016, Ecosystem Health and Sustainability, V2, pe01202, DOI 10.1002/ehs2.1202
   Taimori A, 2017, MULTIMED TOOLS APPL, V76, P7749, DOI 10.1007/s11042-016-3409-z
   Wang JY, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P433
   Zheng L, 2016, INT J COMPUT VISION, V120, P1, DOI 10.1007/s11263-016-0889-2
NR 33
TC 6
Z9 6
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2018
VL 77
IS 14
BP 17993
EP 18005
DI 10.1007/s11042-018-5734-x
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GO5HT
UT WOS:000440050900023
DA 2024-07-18
ER

PT J
AU Das, SK
   Dhara, BC
AF Das, Sujit Kumar
   Dhara, Bibhas Chandra
TI An LSB based novel data hiding method using extended LBP
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LBP; Extended LBP; Image coding; LSB; Data hiding; Steganalysis
ID STEGANOGRAPHIC METHOD; BLOCKING ARTIFACTS; GRAY-SCALE; IMAGES;
   SUBSTITUTION; REDUCTION; EXPANSION
AB In this paper we have proposed an LSB based data hiding method. Here, first cover image is encoded by LBP based method (call as ELBP). In ELBP method, a 3 x 3 block is encoded by k bits (1 aek ae9) respect to the central pixel. For data hiding purpose, the cover image is encoded by ELBP then r (1 aer < k) bits are embedded into each neighbor pixel by replacing least r bits of the encoded stream and then modified pixel is processed by OPAP method to improve the quality of the stego image. Proposed method gives high quality stego images with higher embedding rate compare to the state-of-the-art methods. The security of the proposed data hiding method is tested against the attacks like RS steganalysis and Chi-square attack and these methods fail to detect hidden data.
C1 [Das, Sujit Kumar; Dhara, Bibhas Chandra] Jadavpur Univ, Dept Informat Technol, Kolkata 700098, India.
C3 Jadavpur University
RP Das, SK (corresponding author), Jadavpur Univ, Dept Informat Technol, Kolkata 700098, India.
EM sujit.cse.jgec@gmail.com; bibhas@it.jusl.ac.in
RI Dhara, Bibhas Chandra/ABF-9007-2020; Das, Sujit Kumar/JAN-9609-2023;
   Das, Sujit Kumar/AFV-7797-2022
OI Das, Sujit Kumar/0000-0002-8505-0044; 
CR Ash S, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P471, DOI 10.1109/ICACCE.2015.74
   Augot Daniel, 2011, Cryptography and Coding. 13th IMA International Conference, IMACC 2011. Proceedings, P244, DOI 10.1007/978-3-642-25516-8_15
   Bhattacharya T., 2012, ARXIV12080950
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chanu Yambem Jina, 2012, 2012 3rd National Conference on Emerging Trends and Applications in Computer Science (NCETACS), P52, DOI 10.1109/NCETACS.2012.6203297
   Chen B, 2014, MULTIMED TOOLS APPL, V72, P1985, DOI 10.1007/s11042-013-1493-x
   Chen CC, 2010, SIGNAL PROCESS, V90, P2141, DOI 10.1016/j.sigpro.2010.01.018
   Chen LST, 2010, OPT ENG, V49, DOI 10.1117/1.3366654
   Chen XL, 2016, SPRINGERPLUS, V5, DOI 10.1186/s40064-016-3503-8
   Chen YH, 2016, MULTIMED TOOLS APPL, V75, P13679, DOI 10.1007/s11042-015-2825-9
   Dhara BC, 2004, PATTERN RECOGN, V37, P2131, DOI 10.1016/j.patcog.2004.02.008
   Dhara BC, 2012, J VIS COMMUN IMAGE R, V23, P313, DOI 10.1016/j.jvcir.2011.11.005
   Fridrich J, 2005, IEEE T SIGNAL PROCES, V53, P3923, DOI 10.1109/TSP.2005.855393
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Gui XL, 2014, SIGNAL PROCESS, V98, P370, DOI 10.1016/j.sigpro.2013.12.005
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Jiang J, 2002, ELECTRON LETT, V38, P1424, DOI 10.1049/el:20020946
   Jung KH, 2015, MULTIMED TOOLS APPL, V74, P2179, DOI 10.1007/s11042-014-2081-4
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kim HJ, 2008, IEEE T INF FOREN SEC, V3, P456, DOI 10.1109/TIFS.2008.924600
   KOSSENTINI F, 1995, IEEE T IMAGE PROCESS, V4, P1349, DOI 10.1109/83.465100
   Lee K, 2006, LECT NOTES COMPUT SC, V4283, P35
   Li XL, 2013, SIGNAL PROCESS, V93, P198, DOI 10.1016/j.sigpro.2012.07.025
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Lin C.-C., 2010, J. Inf. Hiding Multimed. Signal Process, V1, P220
   Liu YJ, 2016, IET IMAGE PROCESS, V10, P130, DOI 10.1049/iet-ipr.2014.1015
   Lopes IO, 2006, LECT NOTES COMPUT SC, V4179, P746
   Mali SN, 2012, DIGIT SIGNAL PROCESS, V22, P314, DOI 10.1016/j.dsp.2011.09.003
   Manikandaprabu N, 2014, INT J NOVEL RES ENG, V1, P1
   Nedelcu T, 2015, 2015 INT S SIGN CIRC, P1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ou DH, 2015, MULTIMED TOOLS APPL, V74, P9117, DOI 10.1007/s11042-014-2059-2
   Parah S. A., 2016, MULTIMED TOOLS APPL, P1
   Pourreza-Shahri R, 2014, SIGNAL PROCESS-IMAGE, V29, P1079, DOI 10.1016/j.image.2014.09.008
   Powell RD, 2000, US Patent, Patent No. [6,137,892, 6137892]
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P5861, DOI 10.1007/s11042-014-1894-5
   Rabie T., 2017, MULTIMED TOOLS APPL, P1
   Rabie T, 2017, MULTIMED TOOLS APPL, V76, P8627, DOI 10.1007/s11042-016-3501-4
   Ranjani JJ, 2017, MULTIMED TOOLS APPL, V76, P3715, DOI 10.1007/s11042-016-3974-1
   Ren J, 2013, IEEE DATA COMPR CONF, P516, DOI 10.1109/DCC.2013.95
   Stanley C.A., 2005, Pairs of values and the chi-squared attack
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Varsaki EE, 2013, SIGNAL IMAGE VIDEO P, V7, P247, DOI 10.1007/s11760-011-0229-5
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang YY, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P1369, DOI 10.1109/ICALIP.2008.4590210
   Wen-Hung Liao, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1003, DOI 10.1109/ICPR.2010.251
   Westfeld A., 1999, LECT NOTES COMPUTER, P61, DOI [10.1007/107197245, DOI 10.1007/107197245]
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Wu HC, 2005, IEE P-VIS IMAGE SIGN, V152, P611, DOI 10.1049/ip-vis:20059022
   Wu QS, 2016, IEEE MICROW WIREL CO, V26, P1, DOI 10.1109/LMWC.2015.2505619
   Yang CH, 2008, PATTERN RECOGN, V41, P2674, DOI 10.1016/j.patcog.2008.01.019
   Zhang WM, 2007, IEEE SIGNAL PROC LET, V14, P848, DOI 10.1109/LSP.2007.903255
   Zhang WM, 2010, IEEE T INFORM THEORY, V56, P1262, DOI 10.1109/TIT.2009.2039087
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 58
TC 5
Z9 6
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 12
BP 15321
EP 15351
DI 10.1007/s11042-017-5117-8
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GK7ZD
UT WOS:000436433200040
DA 2024-07-18
ER

PT J
AU Pang, YH
   Teoh, ABJ
   Ooi, SY
   Low, CY
AF Pang, Ying Han
   Teoh, Andrew Beng Jin
   Ooi, Shih Yin
   Low, Cheng Yaw
TI Enhanced independent spectral histogram representations in face
   recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Independent filter responses; Spectral histogram descriptor; XOR bitwise
   operator; Face recognition
ID COMPONENT ANALYSIS; STATISTICS; EIGENFACES; PATTERNS; IMAGES; MODEL
AB A spectral histogram descriptor computes a set of marginal distributions based on the filter bank's responses, and further encodes them into the images. The encoding process for local image structure takes place during the filtering stage, whereas the encoding process of global image feature is conducted during the histogram stage. One drawback of spectral histogram descriptors is their performances will be greatly deteriorated when the filter bank's responses are not stochastically independent. To tackle this problem, a computational technique named Enhanced Independent Spectral Histogram Feature (EISHF) is proposed. EISHF is composed of four working modules: (1) unsupervised independent filter bank responses computation, (2) binary hashing, (3) XOR bitwise operation and feature encoding, and lastly, (4) block-wise histogramming. To ensure the performance of ordinary spectral histogram descriptors, an XOR operation has been delicately adopted to increase the independency of the filter responses. Tested on three public face databases, the experimental results have substantiated the performance of EISHF in handling different kinds of facial expressions, illuminations, time spans as well as facial makeup effects.
C1 [Pang, Ying Han; Ooi, Shih Yin; Low, Cheng Yaw] Multimedia Univ, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Seoul, South Korea.
C3 Multimedia University; Yonsei University
RP Pang, YH (corresponding author), Multimedia Univ, Jalan Ayer Keroh Lama, Melaka 75450, Malaysia.
EM yhpang@mmu.edu.my; bjteoh@yonsei.ac.kr; syooi@mmu.edu.my;
   cylow@mmu.edu.my
RI Low, Cheng/AFS-4768-2022; Pang, Ying Han/AGW-5132-2022; Teoh, Andrew
   Beng Jin/F-4422-2010
OI Low, Cheng/0000-0002-6764-0614; PANG, YING HAN/0000-0002-3781-6623
FU Fundamental Research Grant Scheme (FRGS) under the Ministry of Education
   and Multimedia University, Malaysia [MMUE/140020]; Multimedia University
   Mini Fund [MMUI/170037]
FX This research work was supported by Fundamental Research Grant Scheme
   (FRGS) under the Ministry of Education and Multimedia University,
   Malaysia (Project ID: MMUE/140020) and Multimedia University Mini Fund
   (Project ID: MMUI/170037).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2014, Modeling of food waste digestion using ADM1 integrated with Aspen Plus
   [Anonymous], 2011, EEE T SYST MAN CYBER
   [Anonymous], BRIT MACH VIS C
   Barlow HB., 1961, SENS COMMUN, V1, P217, DOI 10.7551/mitpress/9780262518420.003.0013
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Bicego M., 2006, COMP VIS PATT REC WO, P35, DOI DOI 10.1109/CVPRW.2006.149
   Buccigrossi RW, 1999, IEEE T IMAGE PROCESS, V8, P1688, DOI 10.1109/83.806616
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dantcheva A., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P391, DOI 10.1109/BTAS.2012.6374605
   Dantcheva A, 2013, SPIE NEWSROOM, P1
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   DAVIS RICARDO FRENCH, 2002, EXCLUSIVE OR XOR HAR, P1
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Fan ZZ, 2014, IEEE T NEUR NET LEAR, V25, P1538, DOI 10.1109/TNNLS.2013.2294492
   Felix JX, 2015, LECT NOTES COMPUT SC, V8926, P148, DOI 10.1007/978-3-319-16181-5_11
   Graña M, 2011, INFORM SCIENCES, V181, P1910, DOI 10.1016/j.ins.2010.09.023
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Hyvarinen A, 2009, COMPUT IMAGING VIS, V39, P151
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Kannala J, 2012, INT C PATT RECOG, P1363
   Lei Z, 2014, INT C PATT RECOG, P387, DOI 10.1109/ICPR.2014.75
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liu XW, 2003, J OPT SOC AM A, V20, P1271, DOI 10.1364/JOSAA.20.001271
   Liu XW, 2003, IEEE T IMAGE PROCESS, V12, P661, DOI 10.1109/TIP.2003.812327
   Liu XW, 2002, VISION RES, V42, P2617, DOI 10.1016/S0042-6989(02)00297-3
   Low CY, 2016, ARXIV160407057
   Lu GM, 2003, PATTERN RECOGN LETT, V24, P1463, DOI 10.1016/S0167-8655(02)00386-0
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Marques I, 2012, SOFT COMPUT, V16, P1525, DOI 10.1007/s00500-012-0826-4
   Maturana D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P470, DOI 10.1109/FG.2011.5771444
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Pentland A., 1993, P LOOK PEOPL WORKSH, P1
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ren C-X, 2015, IEEE T CYBERNETICS, V46, P1
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Schwartz O, 2001, NAT NEUROSCI, V4, P819, DOI 10.1038/90526
   Shang L, 2006, NEUROCOMPUTING, V69, P1782, DOI 10.1016/j.neucom.2005.11.004
   Simoncelli EP, 1998, CONF REC ASILOMAR C, P673, DOI 10.1109/ACSSC.1997.680530
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Teoh ABJ, 2015, BIOMETRIC SECURITY
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   ul Hussain S, 2012, LECT NOTES COMPUT SC, V7573, P716, DOI 10.1007/978-3-642-33709-3_51
   UNSER M, 1986, SIGNAL PROCESS, V11, P61, DOI 10.1016/0165-1684(86)90095-2
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Wainwright MJ, 2002, NEURAL INF PROCESS S, P203
   Waring CA, 2005, IEEE T SYST MAN CY B, V35, P467, DOI 10.1109/TSMCB.2005.846655
   Wen L., 2013, Journal of Computer Vision and Image Processing, V3, P63
   Yamazaki M, 2009, IEICE T INF SYST, VE92D, P1745, DOI 10.1587/transinf.E92.D.1745
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yi J, 2013, LECT NOTES ELECT ENG, V278, P35
   Ylioinas Juha, 2015, Image Analysis. 19th Scandinavian Conference, SCIA 2015. Proceedings: LNCS 9127, P516, DOI 10.1007/978-3-319-19665-7_44
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
NR 60
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 14259
EP 14284
DI 10.1007/s11042-017-5028-8
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900051
DA 2024-07-18
ER

PT J
AU Wu, YZ
   Liu, HZ
   Yuan, JZ
   Zhang, QK
AF Wu, Yanzhang
   Liu, Hongzhe
   Yuan, Jiazheng
   Zhang, Qikun
TI Is visual saliency useful for content-based image retrieval?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; Saliency detection; Bag of words; Salient regions; Non-salient
   regions
ID QUERY; ATTENTION
AB In the real world, people often focus on the distinctive objects (Salient Regions, SR) in a scene. Thus, a number of saliency detection methods are introduced into content-based image retrieval (CBIR), which is often with Bag of Words (BoW) model. These methods aim to use the saliency map to prune keypoints or discard the keypoints from the background. However, these methods do not consider the background of the image and the characteristics of the dataset itself. In this paper we focus on the following two issues: 1) whether the saliency pruning method is useful for image retrieval in different kinds of datasets (e.g., salient/cluttered, mixed image database); 2) we test the effectiveness of the discarded parts from the background (Non-Salient Regions, Non-SR) for different kinds of image database. In order to demonstrate the performance of using visual saliency, we conduct experiments on two publicly available database (Ukbench, Holidays). The experiments reveal that the way of using saliency map to filter a small amount of key-points can clearly improve the performance of CBIR, and the keypoints in the background are also useful in some kinds of image datasets.
C1 [Wu, Yanzhang; Liu, Hongzhe; Zhang, Qikun] Beijing Union Univ, Beijing 100101, Peoples R China.
   [Wu, Yanzhang; Liu, Hongzhe; Zhang, Qikun] Beijing Key Lab Informat Serv Engn, Beijing 100101, Peoples R China.
   [Yuan, Jiazheng] Beijing Open Univ, Beijing 100081, Peoples R China.
C3 Beijing Union University
RP Liu, HZ (corresponding author), Beijing Union Univ, Beijing 100101, Peoples R China.; Liu, HZ (corresponding author), Beijing Key Lab Informat Serv Engn, Beijing 100101, Peoples R China.
EM wuyanzhang2013@buu.edu.cn; liuhongzhe@buu.edu.cn;
   xxtjiazheng@buu.edu.cn; 151083520411@buu.edu.cn
OI Liu, Hongzhe/0000-0003-2314-5272
FU National Natural Science Foundation of China [61571045, 61372148];
   Beijing Natural Science Foundation [4152016]; National Key Technology RD
   Program [2014BAK08B02, 2015BAH55F03]
FX This paper is supported by the following projects: The National Natural
   Science Foundation of China (No. 61571045, No. 61372148); Beijing
   Natural Science Foundation (4152016); The National Key Technology R&D
   Program (2014BAK08B02, 2015BAH55F03).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], AAAI
   [Anonymous], 2015, COMPLEX EVENT DETECT
   [Anonymous], ICMR
   [Anonymous], 2015, IJCAI
   [Anonymous], 2000, THESIS PASADENA CALI
   [Anonymous], 7 IEEE ACIS INT C CO
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], INT J COMPUT VIS C
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], IIR
   [Anonymous], THESIS
   [Anonymous], SIGN SYST C ISSC
   [Anonymous], 2013, AAAI
   [Anonymous], P NIPS
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Awad D, 2012, LECT NOTES COMPUT SC, V7517, P290, DOI 10.1007/978-3-642-33140-4_26
   Nguyen BV, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P102, DOI 10.1109/ISM.2014.63
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Chang XJ, 2016, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2016.208
   Chang XJ, 2017, IEEE T PATTERN ANAL, V39, P1617, DOI 10.1109/TPAMI.2016.2608901
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Foo J., 2007, P 18 C AUSTRALASIAN, P63
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Fu H, 2006, PATTERN RECOGN, V39, P1604, DOI 10.1016/j.patcog.2005.12.015
   Gao Y, 2014, IEEE T IMAGE PROCESS, V23, P5400, DOI 10.1109/TIP.2014.2364536
   Giouvanakis E, 2014, INT CONF DIGIT SIG, P280, DOI 10.1109/ICDSP.2014.6900671
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gupta A, 1997, COMMUN ACM, V40, P70, DOI 10.1145/253769.253798
   Huang S, 2014, IEEE IMAGE PROC, P3087, DOI 10.1109/ICIP.2014.7025624
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Li B, 2015, IEEE T IMAGE PROCESS, V24, P5193, DOI 10.1109/TIP.2015.2479400
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Liang Z, 2010, LECT NOTES COMPUT SC, V6474, P62, DOI 10.1007/978-3-642-17688-3_7
   Liu J, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P766, DOI 10.1109/FSKD.2014.6980933
   Liu TY, 2011, LEARNING TO RANK FOR INFORMATION RETRIEVAL, P33, DOI 10.1007/978-3-642-14267-3_2
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Nister David, 2006, CVPR
   Papushoy A, 2015, DIGIT SIGNAL PROCESS, V36, P156, DOI 10.1016/j.dsp.2014.09.005
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   PHILBIN J., 2008, IEEE C COMPUTER VISI, P1
   Qin DF, 2013, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2013.211
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Soares RD, 2012, PROC INT C TOOLS ART, P1070, DOI 10.1109/ICTAI.2012.151
   Tolias G, 2013, IEEE I CONF COMP VIS, P1401, DOI 10.1109/ICCV.2013.177
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Wen ZK, 2014, ADV INTELL SYST COMP, V277, P177, DOI 10.1007/978-3-642-54924-3_17
   Wu JF, 2014, 2014 IEEE 12TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC)/2014 IEEE 12TH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING (EMBEDDEDCOM)/2014 IEEE 12TH INTERNATIONAL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING (PICOM), P338, DOI 10.1109/DASC.2014.67
   Wu L, 2013, IEEE T PATTERN ANAL, V35, P716, DOI 10.1109/TPAMI.2012.124
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Zhang YM, 2011, PROC CVPR IEEE, P809, DOI 10.1109/CVPR.2011.5995528
   Zheng L, 2015, IEEE T MULTIMEDIA, V17, P648, DOI 10.1109/TMM.2015.2408563
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zheng L, 2013, PROC CVPR IEEE, P1626, DOI 10.1109/CVPR.2013.213
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 64
TC 7
Z9 7
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2018
VL 77
IS 11
BP 13983
EP 14006
DI 10.1007/s11042-017-5001-6
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GI5AO
UT WOS:000434382900039
DA 2024-07-18
ER

PT J
AU Amin, R
   Islam, SKH
   Vijayakumar, P
   Khan, MK
   Chang, V
AF Amin, Ruhul
   Islam, S. K. Hafizul
   Vijayakumar, Pandi
   Khan, Muhammad Khurram
   Chang, Victor
TI A robust and efficient bilinear pairing based mutual authentication and
   session key verification over insecure communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE AVISPA tool; Bilinear pairing; User authentication; User anonymity;
   Password
ID USER AUTHENTICATION; PROVABLY SECURE; POWER ANALYSIS; SCHEME; PROTOCOL;
   NETWORKS; ACCESS
AB Remote mutual authentication provides an efficient platform through which an user accesses several resources of the remote serve at anytime over insecure channel and makes their life more comfortable. In this context, lot of key agreement methods have been put forward for enhancing securities. Preserving complete security requirements of the authentication scheme are now becoming challenging research. Hsu et al. proposed similar type of work using bilinear pairing for improving the security weaknesses of the Fang's scheme, and Das et al.'s scheme. We have studied Hsu et al.'s scheme and pointed out that the scheme is ill-suited since off-line password guessing and new smartcard issue attacks are possible in this scheme. It is our further study that Hsu et al.'s scheme is not preserving session key negotiation and mutual authentication. The same problems also exist in Fang's scheme and Das et al.'s scheme. The objective of this article is to provide an efficient scheme, which resolves all the existing problems. The AVISPA simulation results on our scheme ensured that active and passive attacks are protected. The informal security discussion claims that the scheme resists all kinds of security attacks. We have shown that the performance of our scheme is relatively superior in comparison with existing works. As an application area, anyone can execute our protocol in multimedia big data environment for making secure connection between the client and server.
C1 [Amin, Ruhul] Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Islam, S. K. Hafizul] Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, WB, India.
   [Vijayakumar, Pandi] Univ Coll Engn, Dept Comp Sci & Engn, Tindivanam 604001, TN, India.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh, Saudi Arabia.
   [Chang, Victor] Xian Jiaotong Liverpool Univ, IBSS, Informat Management & Informat Syst, Suzhou, Jiangsu, Peoples R China.
C3 Thapar Institute of Engineering & Technology; King Saud University;
   Xi'an Jiaotong-Liverpool University
RP Islam, SKH (corresponding author), Indian Inst Informat Technol Kalyani, Dept Comp Sci & Engn, Kalyani 741235, WB, India.
EM hafi786@gmail.com
RI Amin, Ruhul/AAQ-3893-2020; Khan, Muhammad/IXN-8470-2023; Islam, SK
   Hafizul/K-5724-2017; Pandi, Vijayakumar/Y-4636-2019; Nusa,
   Nuhammad/JXY-5819-2024; Chang, Victor/AAC-7582-2019; KHAN, MUHAMMAD
   KHURRAM/E-4836-2014
OI Pandi, Vijayakumar/0000-0001-5451-8946; Chang,
   Victor/0000-0002-8012-5852; KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533
FU Scientific Research at King Saud University [RG-288]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University for funding this work through Research
   Group no. RG-288.
CR Amin R, 2015, ADV INTELL SYST, V339, P525, DOI 10.1007/978-81-322-2250-7_52
   [Anonymous], P TENCON 07
   [Anonymous], 2006, IACR CRYPTOLOGY EPRI
   [Anonymous], 2013, INT J COMPUTER APPL
   [Anonymous], 2012, INT J APPL MATH COMP
   [Anonymous], IMPROVEMENT MANIK ET
   [Anonymous], 2006, IACR CRYPTOL EPRINT
   [Anonymous], WORLD ACAD SCI ENG T
   Bayat M., 2010, Proceedings 2010 IEEE/IFIP 8th International Conference on Embedded and Ubiquitous Computing (EUC 2010), P578, DOI 10.1109/EUC.2010.93
   Boneh D, 2003, SIAM J COMPUT, V32, P586, DOI 10.1137/S0097539701398521
   Boyd Colin., 2003, INF SECUR CRYTOGR
   Cheon JungHee., 2002, Diffie-Hellman problems and bilinear maps
   Das ML, 2006, COMPUT SECUR, V25, P184, DOI 10.1016/j.cose.2005.09.002
   Eisenbarth T, 2008, LECT NOTES COMPUT SC, V5157, P203, DOI 10.1007/978-3-540-85174-5_12
   FREY G, 1994, MATH COMPUT, V62, P865, DOI 10.2307/2153546
   Giri D, 2015, J MED SYST, V39, DOI 10.1007/s10916-014-0145-7
   Goriparthi T., 2006, IACR CRYPTOLOGY EPRI, V2006, P28
   Goriparthi T, 2009, COMPUT STAND INTER, V31, P181, DOI 10.1016/j.csi.2007.11.016
   Gupta B., 2016, Handbook of research on modern cryptographic solutions for computer and cyber security
   Hafizul Islam S. K., 2014, Journal of Electronics (China), V31, P473, DOI 10.1007/s11767-014-4002-0
   He LJ, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0196-4
   Hsu CL, 2015, WIRELESS PERS COMMUN, V83, P163, DOI 10.1007/s11277-015-2386-2
   ISLAM S.H., 2012, Theoretical and Applied Informatics, V24, P293, DOI [10.2478/v10179-012-0018-z, DOI 10.2478/V10179-012-0018-Z]
   Islam SKH, 2015, WIRELESS PERS COMMUN, V84, P2013, DOI 10.1007/s11277-015-2542-8
   Islam SKH, 2015, WIRELESS PERS COMMUN, V82, P2727, DOI 10.1007/s11277-015-2375-5
   Islam SKH, 2015, INFORM SCIENCES, V312, P104, DOI 10.1016/j.ins.2015.03.050
   Islam SKH, 2015, ARAB J SCI ENG, V40, P1069, DOI 10.1007/s13369-015-1568-2
   Islam SKH, 2014, WIRELESS PERS COMMUN, V79, P1975, DOI 10.1007/s11277-014-1968-8
   Islam SKH, 2014, J KING SAUD UNIV-COM, V26, P55, DOI 10.1016/j.jksuci.2013.03.004
   Islam SKH, 2013, MATH COMPUT MODEL, V57, P2703, DOI 10.1016/j.mcm.2011.07.001
   Islam SK Hafizul, 2013, Journal of Applied Mathematics and Informatics, V31, P425
   Jia ZT, 2006, ISDA 2006: SIXTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, P1091
   Joshi JBD, 2002, IEEE T MULTIMEDIA, V4, P215, DOI 10.1109/TMM.2002.1017735
   Juang WS, 2008, MATH COMPUT MODEL, V47, P1238, DOI 10.1016/j.mcm.2007.08.001
   Khan MK, 2013, J MED SYST, V37, DOI 10.1007/s10916-013-9954-3
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   MENEZES AJ, 1993, IEEE T INFORM THEORY, V39, P1639, DOI 10.1109/18.259647
   Messerges TS, 2002, IEEE T COMPUT, V51, P541, DOI 10.1109/TC.2002.1004593
   Pippal RS, 2013, WIRELESS PERS COMMUN, V72, P729, DOI 10.1007/s11277-013-1039-6
   Samuel A, 2015, IEEE T MULTIMEDIA, V17, P1484, DOI 10.1109/TMM.2015.2458299
   Shin S, 2015, PEER PEER NETW APPL, V8, P674, DOI 10.1007/s12083-013-0218-2
   Tewari Aakanksha, 2017, International Journal of Advanced Intelligence Paradigms, V9, P111
   Tewari A, 2017, J SUPERCOMPUT, V73, P1085, DOI 10.1007/s11227-016-1849-x
   Wang B, 2013, WIRELESS PERS COMMUN, V68, P361, DOI 10.1007/s11277-011-0456-7
   Wei JH, 2014, WIRELESS PERS COMMUN, V77, P2255, DOI 10.1007/s11277-014-1636-z
   Wu TY, 2010, COMPUT NETW, V54, P1520, DOI 10.1016/j.comnet.2009.12.008
   Zhang K, 2014, IEEE COMMUN MAG, V52, P58, DOI 10.1109/MCOM.2014.6766086
NR 47
TC 14
Z9 14
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 9
BP 11041
EP 11066
DI 10.1007/s11042-017-4996-z
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GF3XA
UT WOS:000431889900039
DA 2024-07-18
ER

PT J
AU Chiu, YC
   Liu, LY
   Wang, TP
AF Chiu, Yen-Chia
   Liu, Li-Yi
   Wang, Tsaipei
TI Automatic segmentation and summarization for videos taken with smart
   glasses
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Google Glass; Smart glasses; Egocentric video; Video abstraction; Video
   segmentation; Video summarization; Video diary
ID FRAMEWORK; ATTENTION
AB This paper discusses the topic of automatic segmentation and extraction of important segments of videos taken with Google Glasses. Using the information from both the video images and additional sensor data that are recorded concurrently, we devise methods that automatically divide the video into coherent segments and estimate the importance of the each segment. Such information then enables automatic generation of video summary that contains only the important segments. The features used include colors, image details, motions, and speeches. We then train multi-layer perceptrons for the two tasks (segmentation and importance estimation) according to human annotations. We also present a systematic evaluation procedure that compares the automatic segmentation and importance estimation results with those given by multiple users and demonstrate the effectiveness of our approach.
C1 [Chiu, Yen-Chia; Liu, Li-Yi; Wang, Tsaipei] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Wang, TP (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu, Taiwan.
EM wangts@cs.nctu.edu.tw
FU Ministry of Science and Technology of Taiwan [MOST-104-3115-E-009-001]
FX This work is supported by the Ministry of Science and Technology of
   Taiwan under grant number MOST-104-3115-E-009-001.
CR Abdollahian G, 2010, IEEE T MULTIMEDIA, V12, P28, DOI 10.1109/TMM.2009.2036286
   Ajmal M, 2012, LECT NOTES COMPUT SC, V7594, P1, DOI 10.1007/978-3-642-33564-8_1
   [Anonymous], MULTIMEDIA EXPO ICME
   Boreczky JS, 1998, INT CONF ACOUST SPEE, P3741, DOI 10.1109/ICASSP.1998.679697
   Cheatle P, 2004, INT C PATT RECOG, P979, DOI 10.1109/ICPR.2004.1333937
   Cricri F, 2014, MULTIMED TOOLS APPL, V70, P119, DOI 10.1007/s11042-012-1085-1
   Damnjanovic Uros, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P63, DOI 10.1109/WIAMIS.2008.53
   Ferman AM, 2002, IEEE T IMAGE PROCESS, V11, P497, DOI 10.1109/TIP.2002.1006397
   Fujimura K, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P49, DOI 10.1109/ICME.2002.1035715
   Han JW, 2009, IEEE T CONSUM ELECTR, V55, P1597, DOI 10.1109/TCE.2009.5278032
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P572, DOI 10.1109/TCSVT.2004.826750
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Kannan R, 2013, 4 NAT C COMP VIS PAT, P1
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Li Y, 2006, IEEE SIGNAL PROC MAG, V23, P79
   Li Y, 2013, IEEE I CONF COMP VIS, P3216, DOI 10.1109/ICCV.2013.399
   Lie WN, 2004, LECT NOTES COMPUT SC, V3332, P246
   Lienhart R, 1997, COMMUN ACM, V40, P54, DOI 10.1145/265563.265572
   Lienhart R., 1999, ACM MULTIMEDIA, P37, DOI DOI 10.1145/319878.319888
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Money AG, 2008, J VIS COMMUN IMAGE R, V19, P121, DOI 10.1016/j.jvcir.2007.04.002
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   Nakamura Y, 2000, INT C PATT RECOG, P222, DOI 10.1109/ICPR.2000.902899
   Peng WT, 2010, IEEE INT CON MULTI, P849, DOI 10.1109/ICME.2010.5582606
   Poleg Y, 2014, PROC CVPR IEEE, P2537, DOI 10.1109/CVPR.2014.325
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Rallapalli S, 2014, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '14), P115, DOI 10.1145/2639108.2639126
   Su YC, 2016, LECT NOTES COMPUT SC, V9909, P454, DOI 10.1007/978-3-319-46454-1_28
   Tse K., 1995, ELECT COMPUTER ENG, V2, P827
   Yamada K, 2012, ADV IMAGE VIDEO TECH, P277
   ZHANG HJ, 1994, P SOC PHOTO-OPT INS, V2182, P142, DOI 10.1117/12.171062
   Zhang LM, 2015, IEEE T IND ELECTRON, V62, P1309, DOI 10.1109/TIE.2014.2336639
   Zhu B, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P414, DOI 10.1109/ICSESS.2014.6933595
NR 33
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 12679
EP 12699
DI 10.1007/s11042-017-4910-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100046
DA 2024-07-18
ER

PT J
AU Wang, YZ
   Peng, GH
   Zhou, M
AF Wang, Yanzhao
   Peng, Guohua
   Zhou, Min
TI Saliency detection by hierarchically integrating compactness, contrast
   and boundary connectivity
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Saliency detection; Manifold ranking; Boundary connectivity;
   Compactness; contrast; Hierarchy
ID REGION DETECTION; VISUAL SALIENCY; ATTENTION
AB Saliency detection is one of the most challenging problems in computer vision and has extensive applications in many fields. In this work, instead of simply defining the compactness and contrast, we design novel versions of these two cues based on manifold ranking, and then propose a saliency detection model by integrating the newly modified compactness and contrast with boundary connectivity. Since various scales salient detections highlight different parts of the objects, to further improve the performance, we perform the model hierarchically on four different scales and then fuse the results to obtain the final saliency map. Experiments on four benchmark datasets demonstrate the effectiveness of the proposed method. The method can further improve the accuracy of saliency detection than other 15 state-of-the-art methods on MSRA10k, ASD, DUT-OMRON and ECSSD.
C1 [Wang, Yanzhao; Peng, Guohua; Zhou, Min] Northwestern Polytech Univ, Sch Nat & Appl Sci, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Wang, YZ (corresponding author), Northwestern Polytech Univ, Sch Nat & Appl Sci, Xian 710072, Shaanxi, Peoples R China.
EM wangyz@mail.nwpu.edu.cn; penggh@nwpu.edu.cn; zhouminfive@nwpu.edu.cn
FU Natural Science Basic Research Plan in Shaanxi Province of China
   [2015JM6296]
FX This work is supported by the Natural Science Basic Research Plan in
   Shaanxi Province of China(No. 2015JM6296).
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jian MW, 2011, IMAGING SCI J, V59, P219, DOI 10.1179/136821910X12867873897355
   Jian MW, 2015, IEEE T CYBERNETICS, V45, P1575, DOI 10.1109/TCYB.2014.2356200
   Jian MW, 2014, INFORM SCIENCES, V262, P1, DOI 10.1016/j.ins.2013.12.001
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Li XH, 2013, IEEE I CONF COMP VIS, P2976, DOI 10.1109/ICCV.2013.370
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Pradeep A., 2015, INT J INNOV RES COMP, V3, P9778
   Rahtu E, 2010, LECT NOTES COMPUT SC, V6315, P366, DOI 10.1007/978-3-642-15555-0_27
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tong N, 2015, PATTERN RECOGN, V48, P3258, DOI 10.1016/j.patcog.2014.12.005
   Wang JP, 2015, NEUROCOMPUTING, V152, P359, DOI 10.1016/j.neucom.2014.10.056
   Wang L, 2011, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2011.6126231
   Wei YC, 2012, LECT NOTES COMPUT SC, V7574, P29, DOI 10.1007/978-3-642-33712-3_3
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   YANG JM, 2012, PROC CVPR IEEE, P2296, DOI [DOI 10.1109/CVPR.2012.6247940, 10.1109/CVPR.2012.6247940]
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou L, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2438546
   Zhou XF, 2016, IEEE SIGNAL PROC LET, V23, P517, DOI 10.1109/LSP.2016.2536743
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 37
TC 6
Z9 7
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2018
VL 77
IS 10
BP 11883
EP 11901
DI 10.1007/s11042-017-4839-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GH1ZV
UT WOS:000433202100013
DA 2024-07-18
ER

PT J
AU Amiri, SA
   Hassanpour, H
AF Amiri, Sekine Asadi
   Hassanpour, Hamid
TI Image compression using JPEG with reduced blocking effects via adaptive
   down-sampling and self-learning image sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image compression; Blocking effects; Low bit-rate; Adaptive
   down-sampling; Self-learning sparse representation
ID PARALLEL FRAMEWORK; DEBLOCKING FILTER; DICTIONARY; ARTIFACTS; ALGORITHM;
   REMOVAL; HEVC; SUPERRESOLUTION; RECONSTRUCTION
AB Blocking is an annoying effect in image compression using JPEG especially at low bit-rates. In this paper, a two-phase method is proposed for reducing JPEG blocking effects. In the first phase, the image is adaptively down-sampled via assessing the DCT coefficients of the image blocks. Since the blocks have a fixed size, independent to the size of the image, down-sampling can reduce the number of blocks, and hence reduce the blocking effects. Appropriate down-sampling before compression can improve coding performance, especially at low bit-rate. The decoder, after decompression, up-samples the image to its original resolution. Although, down-sampling alleviates the blocking effects, yet some blocking effects are remained in the result and the image is damaged due to resizing. Hence, self-learning sparse representation is applied in the second phase for a better deblocking and also for alleviating the degradation due to resizing. Experimental results demonstrate that the proposed method can efficiently improve the subjective and objective quality of JPEG compressed images at low bit-rates and outperforms the existing methods.
C1 [Amiri, Sekine Asadi; Hassanpour, Hamid] Shahrood Univ Technol, Fac Comp Engn & IT, Shahrood, Iran.
C3 Shahrood University of Technology
RP Hassanpour, H (corresponding author), Shahrood Univ Technol, Fac Comp Engn & IT, Shahrood, Iran.
EM h.hassanpour@shahroodut.ac.ir
RI Hassanpour, Hamid/AAL-7271-2020
OI Hassanpour, Hamid/0000-0002-5513-9822
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Asadi Amiri S, 2016, NO REFERENCE IMAGE Q
   Cong YL, 2015, INT SYM COMPUT INTEL, P254, DOI 10.1109/ISCID.2015.148
   Dong C, 2016, IEEE SIGNAL PROCESS, V26, P509
   Dong C, 2015, IEEE I CONF COMP VIS, P576, DOI 10.1109/ICCV.2015.73
   Fadili MJ, 2010, P IEEE, V98, P983, DOI 10.1109/JPROC.2009.2024776
   Gao W, 2014, IEEE T SIGNAL PROCES, V62, P2765, DOI 10.1109/TSP.2014.2318132
   Hassanpour H, 2013, IJE T B APPL, V26, P267
   Jeong Y, 2000, IEEE T CIRC SYST VID, V10, P617, DOI 10.1109/76.845007
   Jung C, 2012, SIGNAL PROCESS-IMAGE, V27, P663, DOI 10.1016/j.image.2012.03.002
   Kang LW, 2015, IEEE T MULTIMEDIA, V17, P921, DOI 10.1109/TMM.2015.2434216
   Kang LW, 2012, IEEE INT SYMP CIRC S, P1871
   Kang LW, 2012, IEEE T IMAGE PROCESS, V21, P1742, DOI 10.1109/TIP.2011.2179057
   Kim J, 2011, IEEE T CONSUM ELECTR, V57, P1944, DOI 10.1109/TCE.2011.6131175
   Kim Y, 2003, IEEE T CONSUM ELECTR, V49, P1438, DOI 10.1109/TCE.2003.1261252
   Lin WS, 2006, IEEE T IMAGE PROCESS, V15, P2513, DOI 10.1109/TIP.2006.877415
   Longère P, 2002, P IEEE, V90, P123, DOI 10.1109/5.982410
   Ma L, 2011, IEEE INT SYMP CIRC S, P97
   Mairal J, 2010, J MACH LEARN RES, V11, P19
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Nejati M, 2016, IEEE T IMAGE PROCESS, V25, P4900, DOI 10.1109/TIP.2016.2598483
   Florentín-Nuñez MN, 2013, NEUROCOMPUTING, V121, P32, DOI 10.1016/j.neucom.2012.10.029
   Paek H, 1998, IEEE T CIRC SYST VID, V8, P358, DOI 10.1109/76.678636
   Shen YF, 2015, NEUROCOMPUTING, V151, P1153, DOI 10.1016/j.neucom.2014.06.082
   Singh J, 2011, AEU-INT J ELECTRON C, V65, P827, DOI 10.1016/j.aeue.2011.01.012
   Tai SC, 2005, IEEE T CIRC SYST VID, V15, P733, DOI 10.1109/TCSVT.2005.848314
   Tsaig Y, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P219
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Wang J, 2011, J COMPUT APPL MATH, V236, P675, DOI 10.1016/j.cam.2011.06.025
   Wu XL, 2009, IEEE T IMAGE PROCESS, V18, P552, DOI 10.1109/TIP.2008.2010638
   Xu M, 2014, IEEE T CIRC SYST VID, V24, P1743, DOI 10.1109/TCSVT.2014.2317886
   Yan CG, 2014, IEEE T CIRC SYST VID, V24, P2077, DOI 10.1109/TCSVT.2014.2335852
   Yan CG, 2014, ELECTRON LETT, V50, P367, DOI 10.1049/el.2013.3235
   Yan CG, 2014, IEEE SIGNAL PROC LET, V21, P573, DOI 10.1109/LSP.2014.2310494
   Yang YY, 1993, IEEE T CIRC SYST VID, V3, P421, DOI 10.1109/76.260198
   Yeh CH, 2012, IET IMAGE PROCESS, V6, P534, DOI 10.1049/iet-ipr.2010.0545
   Yeh CH, 2014, J VIS COMMUN IMAGE R, V25, P891, DOI 10.1016/j.jvcir.2014.02.012
   Yu K, 2016, PREPRINT
   Zeng B., 1993, ICASSP-93. 1993 IEEE International Conference on Acoustics, Speech, and Signal Processing (Cat. No.92CH3252-4), P393, DOI 10.1109/ICASSP.1993.319830
   Zhai GT, 2008, IEEE T CIRC SYST VID, V18, P122, DOI 10.1109/TCSVT.2007.906942
   Zhang S, 2003, NEUROCOMPUTING, V50, P249, DOI 10.1016/S0925-2312(01)00709-3
   Zhang XJ, 2008, DCC: 2008 DATA COMPRESSION CONFERENCE, PROCEEDINGS, P302, DOI 10.1109/DCC.2008.81
   Zhang XJ, 2007, IEEE DATA COMPR CONF, P193
   Zhang YH, 2013, NEURAL COMPUT APPL, V22, P3, DOI 10.1007/s00521-011-0740-1
NR 44
TC 7
Z9 7
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8677
EP 8693
DI 10.1007/s11042-017-4763-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800040
DA 2024-07-18
ER

PT J
AU Jana, B
AF Jana, Biswapati
TI Reversible data hiding scheme using sub-sampled image exploiting
   Lagrange's interpolating polynomial
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Sub-sampled image; Reversible data hiding; Lagrange
   interpolation; Image interpolation; RS analysis; Relative entropy
ID DYNAMIC-PROGRAMMING STRATEGY; LSB SUBSTITUTION; MODULUS FUNCTION
AB In this paper, a new reversible data hiding scheme has been proposed using lagrange's interpolating polynomial on interpolated sub-sampled images. First, we generate sub-sampled images from original image and enlarge its size using image interpolation. Now, we convert secret message using lagrange interpolating polynomial and generate new secret message. The new secret message is divided and stored within interleaved pixel of each interpolated sub-sampled images. At the receiver end, new secret message is extracted from interleaved pixel of each sub-sampled stego images and then lagrange's interpolation is applied to generate original secret message. The security has been enhanced due to the distributive nature of hidden data within multiple images. The original pixels are not effected during data embedding which assure reversibility. The proposed scheme provides average embedding capacity with good visual quality measured by peak signal to noise ratio (PSNR) which is greater than 50 dB. It is observed that the proposed scheme provides better performance than other existing data hiding schemes in terms of data embedding capacity, visual quality and security. We have analyzed our stego images through RS analysis, calculate relative entropy, standard deviation and correlation coefficient of original and stego image to show the robustness under various steganographic attacks.
C1 [Jana, Biswapati] Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
C3 Vidyasagar University
RP Jana, B (corresponding author), Vidyasagar Univ, Dept Comp Sci, Midnapore 721102, W Bengal, India.
EM biswapatijana@gmail.com
RI Jana, Prof. Biswapati/AAA-2154-2019
OI Jana, Prof. Biswapati/0000-0003-4476-3459
FU UGC Innovative project grant under Vidyasagar University
   [VU/Innovative/Sc/06/2015]
FX The author is grateful to the anonymous reviewers for their invaluable
   comments and recommendations to improve our paper. This work is
   supported by UGC Innovative project grant under Vidyasagar University
   (Grant Nos: VU/Innovative/Sc/06/2015, Dated: 17.06.2015).
CR Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chang CC, 2006, PATTERN RECOGN, V39, P1155, DOI 10.1016/j.patcog.2005.12.011
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Debasis G, 2016, ADV INTELL SYST, V434, P403, DOI 10.1007/978-81-322-2752-6_40
   Fridrich J, 2001, P SPIE SEC WAT MULT, V4314
   Hwang J, 2006, LECT NOTES COMPUTER, V4283
   Jana B., 2016, Int. J. Electron. Inf. Eng, V5, P6
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Kuo WC, 2007, LECT NOTES ARTIF INT, V4682, P1152
   Lee CF, 2013, 2013 NINTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2013), P485, DOI 10.1109/IIH-MSP.2013.126
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Luo H, 2011, INFORM SCI, V181
   Mondal S. K, 2016, MULTIMED TOOLS APPL, P1
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Tsai P, 2009, SIGNAL PROCESS, V89, P1129, DOI 10.1016/j.sigpro.2008.12.017
   VARSAKI E, 2006, HOUCSTR200608GR HELL
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang SJ, 2005, APPL MATH COMPUT, V164, P99, DOI 10.1016/j.amc.2004.04.059
   Wang XT, 2013, DIGIT SIGNAL PROCESS, V23, P569, DOI 10.1016/j.dsp.2012.06.015
NR 20
TC 13
Z9 14
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8805
EP 8821
DI 10.1007/s11042-017-4775-x
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800046
DA 2024-07-18
ER

PT J
AU Kong, TL
   Isa, NAM
AF Kong, Teck Long
   Isa, Nor Ashidi Mat
TI Bi-histogram modification method for non-uniform illumination and
   low-contrast images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-uniform illumination; Image enhancement; Contrast; Histogram;
   Entropy
ID ENHANCEMENT ALGORITHM; MULTISCALE RETINEX; EQUALIZATION
AB Researchers face non-uniform illumination and low-contrast image challenges during the image-processing stage. A new contrast enhancement method is proposed in this paper to address these challenges. The proposed method first separates the dark and bright regions of an image. Then, these regions are enhanced using two new enhancers, namely, dark and bright. Modified clipped histogram equalization is then applied for contrast enhancement. Finally, the details of the image are added back into the illumination-corrected and contrast-enhanced image for the final output image. Visually, the proposed method successfully produces better images with more uniform illumination and better contrast than the state-of-the-art methods. This claim is supported by quantitative analysis that shows that the proposed method produces the best average measure of enhancement, natural image quality evaluator, and entropy values of 797 test images compared with other state-of-the-art methods.
C1 [Kong, Teck Long; Isa, Nor Ashidi Mat] Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
C3 Universiti Sains Malaysia
RP Isa, NAM (corresponding author), Univ Sains Malaysia, Sch Elect & Elect Engn, Imaging & Intelligent Syst Res Team ISRT, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM konglyng@gmail.com; ashidi@usm.my
RI Mat Isa, Nor Ashidi/I-7826-2017
OI Mat Isa, Nor Ashidi/0000-0002-2675-4914
FU Fundamental Research Grant Scheme of the Ministry of Education, Malaysia
FX This project entitled "Formulation of a robust framework of image
   enhancement for non-uniform illumination and low-contrast images" is
   supported by the Fundamental Research Grant Scheme of the Ministry of
   Education, Malaysia.
CR Acharya T, 2005, IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS, P1, DOI 10.1002/0471745790
   Agaian S.S., 2000, IASTED INT C SIGNAL, P19
   [Anonymous], TECHN INN C 2009 ITI
   [Anonymous], 2009, FUZZY IMAGE PROCESSI
   Bovik A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P1
   Dippel S, 2002, IEEE T MED IMAGING, V21, P343, DOI 10.1109/TMI.2002.1000258
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   Hasikin K, 2012, MED MEAS APPL P MEME, P1, DOI DOI 10.1007/S11042-011-0985-9
   Hasikin K, 2014, SIGNAL IMAGE VIDEO P, V8, P1591, DOI 10.1007/s11760-012-0398-x
   Hasikin K, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING APPLICATIONS (IEEE ICSIPA 2013), P275, DOI 10.1109/ICSIPA.2013.6708017
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P451, DOI 10.1109/83.557356
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Kim T, 2008, IEEE T CONSUM ELECTR, V54, P1803, DOI 10.1109/TCE.2008.4711238
   Lamberti F, 2006, IEEE T CONSUM ELECTR, V52, P966, DOI 10.1109/TCE.2006.1706495
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lee E, 2013, IEEE GEOSCI REMOTE S, V10, P62, DOI 10.1109/LGRS.2012.2192412
   Leung CC, 2005, PATTERN RECOGN LETT, V26, P769, DOI 10.1016/j.patrec.2004.09.032
   Liang K, 2012, INFRARED PHYS TECHN, V55, P309, DOI 10.1016/j.infrared.2012.03.004
   Lin HN, 2014, OPTIK, V125, P7143, DOI 10.1016/j.ijleo.2014.07.118
   Liu B, 2011, IEEE T CONSUM ELECTR, V57, P583, DOI 10.1109/TCE.2011.5955195
   Liu HD, 2014, IEEE T CIRC SYST VID, V24, P1833, DOI 10.1109/TCSVT.2014.2329373
   Magudeeswaran V, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/891864
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Nafornita C, 2014, 2014 11TH INTERNATIONAL SYMPOSIUM ON ELECTRONICS AND TELECOMMUNICATIONS (ISETC), DOI 10.1109/ISETC.2014.7010797
   Panetta KA, 2008, IEEE T SYST MAN CY B, V38, P174, DOI 10.1109/TSMCB.2007.909440
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Rahman Z, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P1003, DOI 10.1109/ICIP.1996.560995
   Raju G, 2014, AEU-INT J ELECTRON C, V68, P237, DOI 10.1016/j.aeue.2013.08.015
   Rubin SH, 2006, IRI 2006: PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION, P602
   Rumsey D.J., 2015, U CAN STAT DUMMIES
   Russ J.C., 2006, The Image Processing Handbook
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sridhar S., 2011, Digital Image Processing'
   Wan Y, 2007, IEEE T IMAGE PROCESS, V16, P2245, DOI 10.1109/TIP.2007.902332
   Wang C, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON CONTROL AUTOMATION ROBOTICS & VISION: ICARV 2008, VOLS 1-4, P939, DOI 10.1109/ICARCV.2008.4795644
   Wang SH, 2013, IEEE T IMAGE PROCESS, V22, P3538, DOI 10.1109/TIP.2013.2261309
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Weber M., 1999, COMPUTATIONAL VISION
   Wei W, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P604, DOI 10.1109/CISP.2013.6745238
   Welinder P, 2010, COMPUTATIONAL VISION
   Wharton E, 2007, INT CONF ACOUST SPEE, P729
   You XG, 2010, IEEE T IMAGE PROCESS, V19, P3271, DOI 10.1109/TIP.2010.2055570
NR 43
TC 9
Z9 9
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8955
EP 8978
DI 10.1007/s11042-017-4789-4
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800052
DA 2024-07-18
ER

PT J
AU Petscharnig, S
   Schöffmann, K
AF Petscharnig, Stefan
   Schoeffmann, Klaus
TI Learning laparoscopic video shot classification for gynecological
   surgery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video classification; Deep learning; Convolutional Neural Network
ID CONVOLUTIONAL NEURAL-NETWORKS; DEEP; RECOGNITION; TASKS
AB Videos of endoscopic surgery are used for education of medical experts, analysis in medical research, and documentation for everyday clinical life. Hand-crafted image descriptors lack the capabilities of a semantic classification of surgical actions and video shots of anatomical structures. In this work, we investigate how well single-frame convolutional neural networks (CNN) for semantic shot classification in gynecologic surgery work. Together with medical experts, we manually annotate hours of raw endoscopic gynecologic surgery videos showing endometriosis treatment and myoma resection of over 100 patients. The cleaned ground truth dataset comprises 9 h of annotated video material (from 111 different recordings). We use the well-known CNN architectures AlexNet and GoogLeNet and train these architectures for both, surgical actions and anatomy, from scratch. Furthermore, we extract high-level features from AlexNet with weights from a pre-trained model from the Caffe model zoo and feed them to an SVM classifier. Our evaluation shows that we reach an average recall of .697 and .515 for classification of anatomical structures and surgical actions respectively using off-the-shelf CNN features. Using GoogLeNet, we achieve a mean recall of .782 and .617 for classification of anatomical structures and surgical actions respectively. With AlexNet the achieved recall is .615 for anatomical structures and .469 for surgical action classification respectively. The main conclusion of our work is that advances in general image classification methods transfer to the domain of endoscopic surgery videos in gynecology. This is relevant as this domain is different from natural images, e.g. it is distinguished by smoke, reflections, or a limited amount of colors.
C1 [Petscharnig, Stefan; Schoeffmann, Klaus] Alpen Adria Univ Klagenfurt, Fak Tech Wissensch, Univ Str 65-67, A-9020 Klagenfurt, Austria.
C3 University of Klagenfurt
RP Petscharnig, S (corresponding author), Alpen Adria Univ Klagenfurt, Fak Tech Wissensch, Univ Str 65-67, A-9020 Klagenfurt, Austria.
EM stefan.petscharnig@itec.aau.at; ks@itec.aau.at
OI Petscharnig, Stefan/0000-0003-2791-7110
FU University of Klagenfurt; Universitat Klagenfurt; Lakeside Labs GmbH,
   Klagenfurt, Austria; European Regional Development Fund; Carinthian
   Economic Promotion Fund (KWF) [KWF 20214 u. 3520/26336/38165]
FX Open access funding provided by University of Klagenfurt. This work was
   supported by Universitat Klagenfurt and Lakeside Labs GmbH, Klagenfurt,
   Austria and funding from the European Regional Development Fund and the
   Carinthian Economic Promotion Fund (KWF) under grant KWF 20214 u.
   3520/26336/38165.
CR Albarqouni S, 2016, IEEE T MED IMAGING, V35, P1313, DOI 10.1109/TMI.2016.2528120
   [Anonymous], ENDOSCOPIC VIDEO RET
   [Anonymous], 2014, CVPR
   [Anonymous], 2017, ARXIV170205747
   [Anonymous], 2015, P 2015 13 INT WORKSH
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], SPIE MED IMAGING
   [Anonymous], SPIE MED IMAGING
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Dixit M, 2015, PROC CVPR IEEE, P2974, DOI 10.1109/CVPR.2015.7298916
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Q, 2014, I C CONT AUTOMAT ROB, P844, DOI 10.1109/ICARCV.2014.7064414
   Loukas C, 2016, INT J COMPUT ASS RAD, V11, P1937, DOI 10.1007/s11548-016-1431-2
   Münzer B, 2018, MULTIMED TOOLS APPL, V77, P1323, DOI 10.1007/s11042-016-4219-z
   Münzer B, 2014, COMP MED SY, P153, DOI 10.1109/CBMS.2014.58
   Münzer B, 2013, IEEE INT SYM MULTIM, P84, DOI 10.1109/ISM.2013.22
   OpenCV, 2015, Open source computer vision library
   Park SY, 2016, SPIE MED IMAGING
   Primus M.J., 2016, 2016 14 INT WORKSHOP, P1, DOI DOI 10.1109/CBMI.2016.7500249
   Quellec G, 2014, IEEE T MED IMAGING, V33, P2352, DOI 10.1109/TMI.2014.2340473
   Ribeiro E., 2016, INT WORKSH COMP ASS, P1
   Schoeffmann K, 2015, MULTIMED TOOLS APPL, V74, P11187, DOI 10.1007/s11042-014-2224-7
   Shin HC, 2016, IEEE T MED IMAGING, V35, P1285, DOI 10.1109/TMI.2016.2528162
   Szegedy C., 2015, PROC IEEE C COMPUT V, P1
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Twinanda AP, 2017, IEEE T MED IMAGING, V36, P86, DOI 10.1109/TMI.2016.2593957
   Xing FY, 2016, IEEE T MED IMAGING, V35, P550, DOI 10.1109/TMI.2015.2481436
   Yan ZN, 2016, IEEE T MED IMAGING, V35, P1332, DOI 10.1109/TMI.2016.2524985
NR 30
TC 44
Z9 57
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 7
BP 8061
EP 8079
DI 10.1007/s11042-017-4699-5
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GB8WK
UT WOS:000429355800014
OA hybrid
DA 2024-07-18
ER

PT J
AU Togootogtokh, E
   Shih, TK
   Kumara, WGCW
   Wu, SJ
   Sun, SW
   Chang, HH
AF Togootogtokh, Enkhtogtokh
   Shih, Timothy K.
   Kumara, W. G. C. W.
   Wu, Shih-Jung
   Sun, Shih-Wei
   Chang, Hon-Hang
TI 3D finger tracking and recognition image processing for real-time music
   playing with depth sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 3D finger gesture; 3D finger tracking; 3D finger recognition; Gesture
   recognition; Neural network; Senz3D; Leap motion; Virtual musical
   instruments
ID VIRTUAL-REALITY
AB In this research, we propose a state-of-the-art 3D finger gesture tracking and recognition method. We use the depth sensors for both hands in real time music playing. In line with the development of 3D depth cameras, we implemented a set of 3D gesture-based instruments, such as Virtual Cello and Virtual Piano, which need precise finger tracking in 3D space. For hands tracking, model-based tracking for left hand and appearance-based tracking for right hand techniques are proposed. To detect finger gestures, our approaches consist number of systematic steps as reducing noise in depth map and geometrical processing for Virtual Cello. For Virtual Piano, we introduce the Neural Network (NN) method to detect special hand gestures. It has Multilayer Perceptron (MLP) structure with back propagation training. Literature has few examples using touch screen as medium, with fixed-coordinates, and 2D-gestures to control MIDI input. The end users should no longer carry anything on their hands. We use Senz3D and Leap Motion due to a few technical benefits. Senz3D and Leap Motion use a closer distance to hands, thus detailed finger gestures can be precisely identified. In the past years, we announced a set of virtual musical instruments and the MINE Virtual Band. Our research work is tested on lab environment and professional theatrical stage. More information and demonstrations of the proposed method can be accessed at:http://video.minelab.tw/DETS/VMIB/.
C1 [Togootogtokh, Enkhtogtokh; Shih, Timothy K.; Kumara, W. G. C. W.; Wu, Shih-Jung; Sun, Shih-Wei; Chang, Hon-Hang] Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.
   [Togootogtokh, Enkhtogtokh; Shih, Timothy K.; Kumara, W. G. C. W.; Wu, Shih-Jung; Sun, Shih-Wei; Chang, Hon-Hang] Tamkang Univ, Dept Innovat Informat & Technol, Taipei, Taiwan.
   [Togootogtokh, Enkhtogtokh; Shih, Timothy K.; Kumara, W. G. C. W.; Wu, Shih-Jung; Sun, Shih-Wei; Chang, Hon-Hang] Taipei Natl Univ Arts, Dept New Media Art, Taipei, Taiwan.
C3 National Central University; Tamkang University
RP Shih, TK (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, 300 Jhongda Rd, Taoyuan 32001, Taiwan.; Shih, TK (corresponding author), Tamkang Univ, Dept Innovat Informat & Technol, Taipei, Taiwan.; Shih, TK (corresponding author), Taipei Natl Univ Arts, Dept New Media Art, Taipei, Taiwan.
EM enkhtogtokh.java@gmail.com; timothykshih@gmail.com;
   chintakawk@gmail.com; wushihjung@mail.tku.edu.tw;
   swsun@vaplab.ee.ncu.edu.tw; sicachang@gmail.com
RI Kumara, W. G. C. W./AAU-8923-2021
OI Kumara, W. G. C. W./0000-0002-4613-275X; Sun,
   Shih-Wei/0000-0003-2761-7484
CR [Anonymous], 2011, 2011 8 INT C INF COM, DOI DOI 10.1109/ICICS.2011.6174264
   [Anonymous], 2013, P GRAPHICS INTERFACE
   Bai Huidong., 2013, SIGGRAPH Asia 2013 Symposium on Mobile Graphics and Interactive Applications, P22
   Fels S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P55, DOI 10.1109/MMCS.1997.609561
   Hsu MH, 2013, 2013 INTERNATIONAL JOINT CONFERENCE ON AWARENESS SCIENCE AND TECHNOLOGY & UBI-MEDIA COMPUTING (ICAST-UMEDIA), P707, DOI 10.1109/ICAwST.2013.6765529
   Kilteni K, 2013, IEEE T VIS COMPUT GR, V19, P597, DOI 10.1109/TVCG.2013.29
   Mubashar KA, 2013, P SOC PHOTO-OPT INS, V8768, P1
   Murthy GRS, 2010, 2010 IEEE 2ND INTERNATIONAL ADVANCE COMPUTING CONFERENCE, P134, DOI 10.1109/IADCC.2010.5423024
   Neto P, 2013, IEEE INT CONF ROBOT, P178, DOI 10.1109/ICRA.2013.6630573
   Paine G, 2013, IEEE MULTIMEDIA, V20, P76, DOI 10.1109/MMUL.2013.60
   Qian C, 2014, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.2014.145
   Raheja J. L., 2011, 2011 Third International Conference on Computational Intelligence, Modelling and Simulation, P248, DOI 10.1109/CIMSim.2011.51
   Valbom L, 2007, IEEE COMPUT GRAPH, V27, P14, DOI 10.1109/MCG.2007.76
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Van den Bergh M., 2009, WORKSH APPL COMP VIS, P1
   Von Hardenberg Christian, 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, PUI'01, P1, DOI DOI 10.1145/971478.971513
   Wang RY., 2009, ACM transactions on graphics (TOG), V28, P1, DOI DOI 10.1145/1531326.1531369
   Xu DY, 2006, INT C PATT RECOG, P519
   Yi Li, 2012, Proceedings of the 2012 IEEE 3rd International Conference on Software Engineering and Service Science (ICSESS), P196, DOI 10.1109/ICSESS.2012.6269439
NR 19
TC 12
Z9 12
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 9233
EP 9248
DI 10.1007/s11042-017-4784-9
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200003
DA 2024-07-18
ER

PT J
AU Vijayanandh, T
   Shenbagavalli, A
AF Vijayanandh, T.
   Shenbagavalli, A.
TI Tamper detection of medical images using statistical moments against
   various attacks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authentication; Hu moments; Zernike moments; Image distortion; Hausdorff
   distance
ID FRAGILE WATERMARKING; ZERNIKE MOMENTS; AUTHENTICATION; ROBUST; SYSTEM;
   RECONSTRUCTION; FEATURES; SCHEME; SECURE
AB Medical Imaging has evolved to digital means to make it suitable for transmission and storage purposes. This aids in transfer of medical images for medical transcriptions, tele-medicine and Content Based Image Retrieval (CBIR) applications. Medical images need to be transported with enough security to preserve the contents from intruders, to verify the contents of Hospital Information system for legal purposes and to protect the images from disclosure to unauthorized persons. Data authentication using watermarking preserves the content against modification and also can be used for ready reference anytime. In this work, zernike and Hu moments were used for generation of Hash for the original and distorted images. Hash generated is compared with the Hausdorff distance. It was found that the variance of Hu moments is higher than that of zernike moments and hence the use of Hu moments enhances the security of medical images used for transmission and storage purposes.
C1 [Vijayanandh, T.; Shenbagavalli, A.] Natl Engn Coll, Dept Elect & Commun Engn, Kovilpatti, Tamil Nadu, India.
C3 National Engineering College - India
RP Vijayanandh, T (corresponding author), Natl Engn Coll, Dept Elect & Commun Engn, Kovilpatti, Tamil Nadu, India.
EM tvijayanandh09@gmail.com
RI T, VIJAYANANDH/ISU-2351-2023
OI T, VIJAYANANDH/0000-0002-6307-4272
CR Al-Haj A, 2015, IET INFORM SECUR, V9, P365, DOI 10.1049/iet-ifs.2014.0245
   [Anonymous], 2010, J COMPUT INFORM SYST
   [Anonymous], J IMAGE VIDEO PROC
   Aznaveh AM, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/738972
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1132, DOI 10.1109/TCYB.2015.2423678
   Chen HS, 2017, IEEE SIGNAL PROC LET, V24, P574, DOI 10.1109/LSP.2017.2679043
   El Mallahi Mostafa, 2015, WSEAS Transactions on Computers, V14, P513
   Honarvar B, 2014, SIGNAL PROCESS, V98, P224, DOI 10.1016/j.sigpro.2013.11.037
   Jie Z, 2013, IJ COMPUT SCI ISSUES, V10, P3
   Kougianos E, 2016, IEEE ACCESS, V4, P1222, DOI 10.1109/ACCESS.2016.2542800
   Li XY, 2017, OPT LASER ENG, V89, P59, DOI 10.1016/j.optlaseng.2016.04.021
   Lin PY, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0155-0
   Nafornita C, 2011, DISCRETE WAVELET TRA, DOI [10.5772/817, DOI 10.5772/817]
   Nagarajan S.K., 2012, IOSR Journal of Engineering, P814
   Nikolaidis A, 2015, IET IMAGE PROCESS, V9, P560, DOI 10.1049/iet-ipr.2014.0689
   Nyeem H, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-135
   Piper A, 2013, IET INFORM SECUR, V7, P300, DOI 10.1049/iet-ifs.2010.0059
   Preda RO, 2015, ELECTRON LETT, V51, P1873, DOI 10.1049/el.2015.2522
   Qian ZX, 2016, IEEE SIGNAL PROC LET, V23, P1672, DOI 10.1109/LSP.2016.2585580
   Rad Reza Moradi, 2014, IEEE Trans Image Process, V23, P1463, DOI 10.1109/TIP.2014.2302681
   Ragamathunisa Begum AH, 2016, TURK J ELECTR ENG CO, V24, P3321, DOI 10.3906/elk-1403-318
   Ramos CC, 2011, DISCRETE WAVELET TRA, DOI [10.5772/817, DOI 10.5772/817]
   Shu HZ, 2007, PATTERN RECOGN, V40, P670, DOI 10.1016/j.patcog.2006.05.035
   Singh C, 2014, IET IMAGE PROCESS, V8, P373, DOI 10.1049/iet-ipr.2013.0382
   Sun R, 2011, INT J WIREL MICROWAV, V1, P9
   Tabatabaei SAH, 2015, IEEE T MULTIMEDIA, V17, P945, DOI 10.1109/TMM.2015.2432672
   Tang ZJ, 2012, APPL MATH INFORM SCI, V6, p643S
   Vellaisamy S, 2014, IET IMAGE PROCESS, V8, P718, DOI 10.1049/iet-ipr.2013.0558
   Walia E, 2013, IET COMPUT VIS, V7, P9, DOI 10.1049/iet-cvi.2012.0109
   Wu WC, 2016, J VIS COMMUN IMAGE R, V38, P18, DOI 10.1016/j.jvcir.2016.02.005
   Yu M, 2015, AEU-INT J ELECTRON C, V69, P361, DOI 10.1016/j.aeue.2014.10.006
   Zhao Y, 2013, IEEE T INF FOREN SEC, V8, P55, DOI 10.1109/TIFS.2012.2223680
   Zheng D, 2009, IEEE T IMAGE PROCESS, V18, P1055, DOI 10.1109/TIP.2009.2014807
NR 33
TC 4
Z9 4
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2018
VL 77
IS 8
BP 10273
EP 10284
DI 10.1007/s11042-017-5473-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GD8BM
UT WOS:000430737200057
DA 2024-07-18
ER

PT J
AU Bouslehi, H
   Seddik, H
AF Bouslehi, Hamdi
   Seddik, Hassene
TI A new rapid hyperchaotic system for more efficient 2D data encryption
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hyperchaos; Lyapunov exponent; Bifurcation; Periodic orbit; Encryption;
   Sensitivity
ID ATTRACTOR
AB This paper presents a new rapid four-dimensional (4D) chaotic system which is able to perform hyper-chaos, chaos and periodic behaviors. This new system has the characteristics to present a unique equilibrium.The detailed dynamical behaviors of this hyper-chaotic system are explained and assessed using many tests of stability along with giving experimental observations. Simulations are performed and comparative studies are conducted to assess this technique which is applied to be tested on image encryption.
C1 [Bouslehi, Hamdi; Seddik, Hassene] ENSIT Ecole Natl Super Sci & Ingenieur Tunis, Dept Elect, 05 Taha Housain, Tunis, Tunisia.
RP Bouslehi, H (corresponding author), ENSIT Ecole Natl Super Sci & Ingenieur Tunis, Dept Elect, 05 Taha Housain, Tunis, Tunisia.
EM Hamdi.bouslehi@gmail.com; seddik-hassene@ieee.org
OI hassene, seddik/0000-0003-0848-8285
CR Banerjee S., 2011, INT J NONLINEAR SCI, V11, P338
   Cafagna D, 2003, INT J BIFURCAT CHAOS, V13, P2889, DOI 10.1142/S0218127403008284
   Chen AM, 2006, PHYSICA A, V364, P103, DOI 10.1016/j.physa.2005.09.039
   Chen GR, 1999, INT J BIFURCAT CHAOS, V9, P1465, DOI 10.1142/S0218127499001024
   Chen Y, 2015, J MATH COMPUTERS SIM
   Chen ZQ, 2007, PHYS LETT A, V360, P696, DOI 10.1016/j.physleta.2006.08.085
   El-Sayed AMA, 2015, MATH COMPUT SIMULAT, V239, P333
   Li QD, 2015, NONLINEAR DYNAM, V79, P2295, DOI 10.1007/s11071-014-1812-4
   Li YX, 2005, INT J CIRC THEOR APP, V33, P235, DOI 10.1002/cta.318
   Lin ZS, 2015, IEEE T CIRC SYST VID, V25, P1203, DOI 10.1109/TCSVT.2014.2369711
   Liu CX, 2004, CHAOS SOLITON FRACT, V22, P1031, DOI 10.1016/j.chaos.2004.02.060
   Liu Y, 2016, MULTIMED TOOLS APPL, V75, P7739, DOI 10.1007/s11042-015-2691-5
   LORENZ EN, 1963, J ATMOS SCI, V20, P130, DOI 10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2
   Lu JH, 2002, INT J BIFURCAT CHAOS, V12, P1001, DOI 10.1142/S0218127402004851
   Ma J, 2015, NONLINEAR DYNAM, V81, P1275, DOI 10.1007/s11071-015-2067-4
   Mazloom S, 2009, CHAOS SOLITON FRACT, V42, P1745, DOI 10.1016/j.chaos.2009.03.084
   Nana B, 2011, COMMUN NONLINEAR SCI, V16, P1725, DOI 10.1016/j.cnsns.2010.03.009
   Norouzi B, 2013, MULTIMED SYST
   Pang SQ, 2011, J COMPUT APPL MATH, V235, P2775, DOI 10.1016/j.cam.2010.11.029
   ROSSLER OE, 1979, PHYS LETT A, V71, P155, DOI 10.1016/0375-9601(79)90150-6
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   SHANNON CE, 1949, BELL SYST TECH J, V28, P656, DOI 10.1002/j.1538-7305.1949.tb00928.x
   Shen CW, 2014, IEEE T CIRCUITS-I, V61, P2380, DOI 10.1109/TCSI.2014.2304655
   Shen CW, 2014, IEEE T CIRCUITS-I, V61, P854, DOI 10.1109/TCSI.2013.2283994
   Shen XY, 2013, CHINESE PHYS B, V22, DOI 10.1088/1674-1056/22/9/094213
   Thamilmaran K, 2004, INT J BIFURCAT CHAOS, V14, P221, DOI 10.1142/S0218127404009119
   Tong XJ, 2015, ENTROPY-SWITZ, V17, P181, DOI 10.3390/e17010181
   Wang FQ, 2006, CHINESE PHYS, V15, P963, DOI 10.1088/1009-1963/15/5/016
   Wang QX, 2016, IEEE T CIRCUITS-I, V63, P401, DOI 10.1109/TCSI.2016.2515398
   Wei ZC, 2014, MATH COMPUT SIMULAT, V100, P13, DOI 10.1016/j.matcom.2014.01.001
   Xiang T, 2006, PHYS LETT A, V349, P109, DOI 10.1016/j.physleta.2005.02.083
   Zhou P, 2009, CHINESE PHYS B, V18, P1394, DOI 10.1088/1674-1056/18/4/018
   Zhou XB, 2008, CHAOS SOLITON FRACT, V36, P1385, DOI 10.1016/j.chaos.2006.09.008
NR 33
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 7741
EP 7762
DI 10.1007/s11042-017-4675-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700059
DA 2024-07-18
ER

PT J
AU Huang, YC
   Feng, JQ
AF Huang, Yuncen
   Feng, Jieqing
TI Efficient skeleton-guided displaced subdivision surfaces
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Displacement mapping; Subdivision surfaces; GPU; Skeleton; Raycasting
ID CATMULL-CLARK
AB Displacement mapping is a computer graphics technique that uses scalar offsets along normals on a base surface to represent and render a model with highly geometric details. The technique natively compresses the model and saves memory I/O. A subdivision surface is the ideal base surface, due to its good geometric properties, such as arbitrary topology, global smoothness, and multi-resolution via hardware tessellation, among others. Two of the main challenges in displacement mapping representation are constructing the base surface faithfully and generating displacement maps efficiently. In this paper, we propose an efficient skeleton-guided displaced subdivision surfaces method. The construction of the base mesh is guided by a sketched skeleton. To make the shape of the base surface fit the input model well, we develop an efficient progressive GPU-based subdivision fitting method. Finally, a GPU-based raycasting method is proposed to sample the input model and generate the displacement maps. The experimental results demonstrate that the proposed method can efficiently generate a high-quality displacement mapping representation. Compared with the traditional displaced subdivision surface method, the proposed method is more suitable for the modern rendering pipeline and has higher efficiency.
C1 [Huang, Yuncen; Feng, Jieqing] Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Feng, JQ (corresponding author), Zhejiang Univ, State Key Lab CAD&CG, Hangzhou 310058, Zhejiang, Peoples R China.
EM cathy0612@gmail.com; jqfeng@cad.zju.edu.cn
FU National Natural Science Foundation of China [61170138, 61472349]
FX We would like to thank Dr. Chen Xue for her helpful discussions, and
   also thank the anonymous reviewers who gave valuable suggestions to
   improve the quality of the paper. This work was supported by the
   National Natural Science Foundation of China under Grant Nos. 61472349
   and 61170138.
CR Amanatides John, 1987, EG 1987 TECHNICAL PA
   Ara K, 2010, INTRO MUDBOX
   Blinn J., 1978, Proceedings of the 5th annual conference on Computer graphics and interactive techniques-SIGGRAPH'78, V12, P286
   Burley B, 2008, COMPUT GRAPH FORUM, V27, P1155, DOI 10.1111/j.1467-8659.2008.01253.x
   Cashman TJ, 2012, COMPUT GRAPH FORUM, V31, P42, DOI 10.1111/j.1467-8659.2011.02083.x
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   Chen ZX, 2008, COMPUT GRAPH FORUM, V27, P1823, DOI 10.1111/j.1467-8659.2008.01328.x
   Cohen J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P115, DOI 10.1145/280814.280832
   Cook R. L., 1984, Computers & Graphics, V18, P223
   de Aguiar E, 2008, COMPUT GRAPH FORUM, V27, P389, DOI 10.1111/j.1467-8659.2008.01136.x
   DeRose T., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P85, DOI 10.1145/280814.280826
   DOO D, 1978, COMPUT AIDED DESIGN, V10, P356, DOI 10.1016/0010-4485(78)90111-2
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Gumhold S., 1999, Proceedings 1999 EUROGRAPHICS/SIGGRAPH Workshop on Graphics Hardware, P55, DOI 10.1145/311534.311578
   Hirche J, 2004, PROC GRAPH INTERF, P153
   Hoppe H., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P99, DOI 10.1145/237170.237216
   Hoppe H., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P295, DOI 10.1145/192161.192233
   Jang H, 2013, COMPUT AIDED DESIGN, V45, P517, DOI 10.1016/j.cad.2012.10.034
   Jang H, 2012, COMPUT GRAPH FORUM, V31, P1880, DOI 10.1111/j.1467-8659.2012.03068.x
   Kaneko T., 2001, Proceedings of ICAT, V2001, P205
   Keller Eric., 2011, Introducing ZBrush
   Kobbelt LP, 2000, COMPUT GRAPH FORUM, V19, pC249, DOI 10.1111/1467-8659.00417
   Krishnamurthy V., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P313, DOI 10.1145/237170.237270
   Lee A, 2000, COMP GRAPH, P85, DOI 10.1145/344779.344829
   Lee H, 2010, ACM SIGGRAPH ASIA 20
   Lin HW, 2015, COMPUT AIDED DESIGN, V67-68, P107, DOI 10.1016/j.cad.2015.05.004
   Loop C, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330519
   Niessner M, 2016, COMPUT GRAPH FORUM, V35, P113, DOI 10.1111/cgf.12714
   Niessner M, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2487228.2487234
   Pottmann H, 2004, LECT NOTES COMPUTER, V3024
   Stam J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P395, DOI 10.1145/280814.280945
   Szirmay-Kalos L, 2008, COMPUT GRAPHICS FORU, V27
   Wang LF, 2003, ACM T GRAPHIC, V22, P334, DOI 10.1145/882262.882272
   Wang X., 2004, EUR WORKSH REND, DOI [10.2312/EGWR/EGSR04/227-233, DOI 10.2312/EGWR/EGSR04/227-233]
   Yao CY, 2009, COMPUT ANIMAT VIRT W, V20, P101, DOI 10.1002/cav.313
NR 35
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5367
EP 5384
DI 10.1007/s11042-017-4439-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800012
DA 2024-07-18
ER

PT J
AU Jin, BW
   Xu, SH
   Geng, WD
AF Jin, Bingwen
   Xu, Songhua
   Geng, Weidong
TI Learning to sketch human facial portraits using personal styles by
   case-based reasoning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial portraits; Sketch generation; Style-transferring; Artistic
   rendering; Personalized exaggeration; Case-based reasoning
ID MUTUAL INFORMATION; IMAGE
AB This paper employs case-based reasoning (CBR) to capture the personal styles of individual artists and generate the human facial portraits from photos accordingly. For each human artist to be mimicked, a series of cases are firstly built-up from her/his exemplars of source facial photo and hand-drawn sketch, and then its stylization for facial photo is transformed as a style-transferring process of iterative refinement by looking-for and applying best-fit cases in a sense of style optimization. Two models, fitness evaluation model and parameter estimation model, are learned for case retrieval and adaptation respectively from these cases. The fitness evaluation model is to decide which case is best-fitted to the sketching of current interest, and the parameter estimation model is to automate case adaptation. The resultant sketch is synthesized progressively with an iterative loop of retrieval and adaptation of candidate cases until the desired aesthetic style is achieved. To explore the effectiveness and advantages of the novel approach, we experimentally compare the sketch portraits generated by the proposed method with that of a state-of-the-art example-based facial sketch generation algorithm as well as a couple commercial software packages. The comparisons reveal that our CBR based synthesis method for facial portraits is superior both in capturing and reproducing artists' personal illustration styles to the peer methods.
C1 [Jin, Bingwen; Geng, Weidong] Zhejiang Univ, Dept Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
   [Xu, Songhua] New Jersey Inst Technol, Dept Informat Syst, Newark, NJ 07102 USA.
C3 Zhejiang University; New Jersey Institute of Technology
RP Jin, BW (corresponding author), Zhejiang Univ, Dept Comp Sci & Technol, Hangzhou, Zhejiang, Peoples R China.
EM jinbw@zju.edu.cn; gengwd@zju.edu.cn; songhua.xu@njit.edu
FU National High Technology Research and Development Program of China (863
   Program) [2013AA013705]; National Natural Science Foundation of China
   [61379067]; National Program on Key Basic Research Project of China (973
   Program) [2013CB329504]; Ministry of Science and Technology
   [2012BAH03F03]
FX This work was supported by a grant from National Program on Key Basic
   Research Project of China (973 Program, 2013CB329504), National High
   Technology Research and Development Program of China (863 Program,
   2013AA013705), National Natural Science Foundation of China (N0.
   61379067), and National Key Technology R & D Program of the Ministry of
   Science and Technology (2012BAH03F03).
CR AAMODT A, 1994, AI COMMUN, V7, P39
   AKVIS, 2012, AKV SKETCH V 13 0
   [Anonymous], 2009, P 7 INT S NONPH AN R, DOI DOI 10.1145/1572614.1572622
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berger I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461964
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Burgess CM, 2005, COSMETIC DERMATOLOGY
   Chen C.-T., 1998, Linear System Theory and Design
   Chen Hong., 2004, P 3 INT S NONPHOTORE, P95, DOI DOI 10.1145/987
   Gao W, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTELLIGENT SYSTEMS, PROCEEDINGS, VOL 4, P219, DOI 10.1109/ICICISYS.2009.5357708
   Gonzalez RC, 2002, DIGITAL IMAGE PROCES
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Kalogerakis E, 2012, ACM T GRAPHIC, V31
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kyprianidis JE, 2013, IEEE T VIS COMPUT GR, V19, P866, DOI 10.1109/TVCG.2012.160
   Leake D. B., 1995, Case-Based Reasoning Research and Development. First International Conference, ICCBR-95. Proceedings, P229, DOI 10.1007/3-540-60598-3_21
   Lee HC, 2010, TRANSP ISSUES POLICI, P43
   Lee SY, 1996, J VISUAL COMP ANIMAT, V7, P3, DOI 10.1002/(SICI)1099-1778(199601)7:1<3::AID-VIS131>3.0.CO;2-U
   Liang L, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P386, DOI 10.1109/PCCGA.2002.1167882
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Lu Cewu., 2012, Proc. NPAR, P65
   Lu J., 2010, PROC ACM SIGGRAPH S, P127
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Microsoft, 2003, MICR OFF HOM TRIAL E
   Milborrow S, 2008, LOCATING FACIAL FEAT
   Min F, 2007, LECT NOTES COMPUT SC, V4679, P184
   Mish F.C., 1994, Merriam Webster's collegiate dictionary, V10th
   Modat M, 2010, COMPUT METH PROG BIO, V98, P278, DOI 10.1016/j.cmpb.2009.09.002
   Papari G, 2007, IEEE T IMAGE PROCESS, V16, P2449, DOI 10.1109/TIP.2007.903912
   Papari G, 2009, IEEE T IMAGE PROCESS, V18, P652, DOI 10.1109/TIP.2008.2009800
   Parke FrederickI., 1972, Proceedings of the ACM annual conference, V1, P451
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Powell M. J. D., 1998, Acta Numerica, V7, P287, DOI 10.1017/S0962492900002841
   Redman L, 2012, DRAW CARICATURES
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Salesin DH, 2002, COMMUNICATION   0603
   Schaefer S, 2006, ACM T GRAPHIC, V25, P533, DOI 10.1145/1141911.1141920
   SCHAFFER C, 1993, MACH LEARN, V13, P135, DOI 10.1023/A:1022639714137
   Song Y, 2014, REAL TIME EXEMPLAR B, P800
   Sonka M., 1993, IMAGE PROCESSING ANA
   Thévenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976
   Tu CT, 2010, IEEE T SYST MAN CY B, V40, P1158, DOI 10.1109/TSMCB.2009.2035154
   Wang N, 2013, RESULTS CUHK FACE SK
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wu CY, 2004, IEEE T PATTERN ANAL, V26, P322, DOI 10.1109/TPAMI.2004.1262319
   Zhang YJ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/463930
   Zhao M., 2011, Proceedings of the ACM SIGGRAPH/Eurographics Symposium on Non-Photorealistic Animation and Rendering, P117
   Zhao M., 2010, PROC INT S NONPHOTOR, P99, DOI DOI 10.1145/1809939.1809951
   Zhou H, 2012, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2012.6247788
NR 53
TC 4
Z9 4
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5417
EP 5441
DI 10.1007/s11042-017-4457-8
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Karamti, H
   Tmar, M
   Visani, M
   Urruty, T
   Gargouri, F
AF Karamti, H.
   Tmar, M.
   Visani, M.
   Urruty, T.
   Gargouri, F.
TI Vector space model adaptation and pseudo relevance feedback for
   content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vectorization; CBIR; Neural network; Late fusion; Vector space model;
   Pseudo-relevance feedback
ID DESCRIPTOR; COLOR
AB Image retrieval is an important problem for researchers in computer vision and content-based image retrieval (CBIR) fields. Over the last decades, many image retrieval systems were based on image representation as a set of extracted low-level features such as color, texture and shape. Then, systems calculate similarity metrics between features in order to find similar images to a query image. The disadvantage of this approach is that images visually and semantically different may be similar in the low level feature space. So, it is necessary to develop tools to optimize retrieval of information. Integration of vector space models is one solution to improve the performance of image retrieval. In this paper, we present an efficient and effective retrieval framework which includes a vectorization technique combined with a pseudo relevance model. The idea is to transform any similarity matching model (between images) to a vector space model providing a score. A study on several methodologies to obtain the vectorization is presented. Some experiments have been undertaken on Wang, Oxford5k and Inria Holidays datasets to show the performance of our proposed framework.
C1 [Karamti, H.] Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
   [Tmar, M.; Gargouri, F.] Inst Super Informat & Multimedia Sfax, Sfax, Tunisia.
   [Visani, M.] Univ La Rochelle, Comp Sci Lab L3i, La Rochelle, France.
   [Visani, M.] USTH, ICT Lab, Hanoi, Vietnam.
   [Urruty, T.] Univ Poitiers, Poitiers, France.
C3 Universite de Sfax; Ecole Nationale dIngenieurs de Sfax (ENIS);
   Universite de Sfax; La Rochelle Universite; Vietnam Academy of Science &
   Technology (VAST); University of Science & Technology of Hanoi (USTH);
   Universite de Poitiers
RP Karamti, H (corresponding author), Univ Sfax, Natl Sch Engineers Sfax, Sfax, Tunisia.
EM karamti.hanen@gmail.com; mohamed.tmar@isimsf.rnu.tn;
   muriel.visani@univ-lr.fr; thierry.urruty@univ-poitiers.fr;
   faiez.gargouri@fsegs.rnu.tn
OI Urruty, Thierry/0000-0003-1339-1920; Gargouri,
   Faiez/0000-0003-2575-8654; karamti, hanen/0000-0001-5162-2692
CR Aidos H, 2014, IEEE IMAGE PROC, P21, DOI 10.1109/ICIP.2014.7025003
   Alpkocak A, 2010, INFORM RETRIEVAL SER, V32, P261, DOI 10.1007/978-3-642-15181-1_14
   Angelova A, 2013, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2013.110
   [Anonymous], 2012, P 35 INT ACM SIGIR C
   [Anonymous], P ACM MULT
   [Anonymous], 2010, P BRIT MACH VIS C 20
   [Anonymous], 2000, Em: Proceedings of the 2000 ACM workshops on Multimedia, DOI DOI 10.1145/357744.357758
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   Arandjelovic R., 2015, NetVLAD: CNN architecture for weakly supervised place recognition
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Atreya Avinash, 2010, SIGKDD EXPLORATIONS, P5
   Babenko A, 2015, AGGREGATING DEEP CON
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Becker C, 2013, LECT NOTES COMPUT SC, V8149, P526, DOI 10.1007/978-3-642-40811-3_66
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Claveau V., 2010, CORIA, P313
   Deserno TM, 2009, J DIGIT IMAGING, V22, P202, DOI 10.1007/s10278-007-9092-x
   Donahue J, 2014, PR MACH LEARN RES, V32
   Douze Matthijs, 2009, P 8 ACM INT C IM VID
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Geirinhas Ramos H., 1994, Journal of Magnetism and Magnetic Materials, V133, P574, DOI 10.1016/0304-8853(94)90626-2
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gong YC, 2011, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2011.5995432
   Gony J, 2007, P 6 ACM INT C IMAGE, P93
   Hsu W, 2007, STUD HEALTH TECHNOL, V129, P188
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jégou H, 2012, LECT NOTES COMPUT SC, V7573, P774, DOI 10.1007/978-3-642-33709-3_55
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Jordan C, 2004, 2 INT ATL WEB INT C, P135
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Karamti Hanen, 2015, 11th International Conference on Web Information Systems and Technologies (WEBIST 2015). Proceedings, P287
   Karamti H., 2013, CORIA RJCRI, P335
   Karamti H, 2012, IKE, P129
   Karamti H, 2014, I C COMP SYST APPLIC, P723, DOI 10.1109/AICCSA.2014.7073271
   Kasutani E, 2001, IEEE IMAGE PROC, P674, DOI 10.1109/ICIP.2001.959135
   Kulkarni S., 1999, Proceedings. Tenth International Workshop on Database and Expert Systems Applications. DEXA 99, P899, DOI 10.1109/DEXA.1999.795301
   Lee H, 2011, COMMUN ACM, V54, P95, DOI 10.1145/2001269.2001295
   Lindeberg T, 1996, PROC CVPR IEEE, P465, DOI 10.1109/CVPR.1996.517113
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mandal S, 2015, IEEE ENG MED BIO, P707, DOI 10.1109/EMBC.2015.7318460
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Ming A., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P364, DOI 10.1145/1282280.1282335
   Nguyen DA, 2010, LECT NOTES ARTIF INT, V5990, P294
   Ortiz-Jaramillo B, 2010, 10 QUANT INFR THERM
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   Philbin J, 2007, IEEE COMP SOC COMP V
   Philbin J, 2010, LECT NOTES COMPUT SC, V6313, P677
   Ramanathan V., 2011, IEEE WORKSH APPL COM, P139
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Ruthven I, 2003, KNOWL ENG REV, V18, P95, DOI 10.1017/S0269888903000638
   Salembier P, 2002, EURASIP J APPL SIG P, V2002, P343, DOI 10.1155/S1110865702000781
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Schettini R., 2009, Encyclopedia of Database Systems, P1115, DOI [10.1007/978-0-387-39940-9_162, DOI 10.1007/978-0-387-39940-9_162]
   Sheikholeslami G, 2002, IEEE T KNOWL DATA EN, P988
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Stathopoulos Vassilios, 2011, P 2 WORKSH APPL PATT, P41
   Teran L, 2014, LECT NOTES COMPUT SC, V8689, P159, DOI 10.1007/978-3-319-10590-1_11
   Tolias G, 2015, RONAN SICRE HERVE JE
   Tsai CF, 2015, J ASSOC INF SCI TECH, V66, P40, DOI 10.1002/asi.23154
   Wang D., 2014, C SVDDNET EFFECTIVE
   Wang YH, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508393
   Wengert C., 2011, P 19 ACM INT C MULT, P1437, DOI [DOI 10.1145/2072298.2072034, 10.1145/2072298.2072034]
   Westerveld T, 2003, EURASIP J APPL SIG P, V2003, P186, DOI 10.1155/S111086570321101X
   Winder S, 2009, PROC CVPR IEEE, P178, DOI 10.1109/CVPRW.2009.5206839
   Ye Z, 2014, SIGIR'14: PROCEEDINGS OF THE 37TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P323, DOI 10.1145/2600428.2609636
   Yue J, 2011, MATH COMPUT MODEL, V54, P1121, DOI 10.1016/j.mcm.2010.11.044
   Zhang D, 2001, P IEEE INT C MULT EX
NR 71
TC 13
Z9 14
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 5
BP 5475
EP 5501
DI 10.1007/s11042-017-4463-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FY8RP
UT WOS:000427132800017
DA 2024-07-18
ER

PT J
AU Po, LM
   Feng, LT
   Li, YM
   Xu, XY
   Cheung, TCH
   Cheung, KW
AF Po, Lai-Man
   Feng, Litong
   Li, Yuming
   Xu, Xuyuan
   Cheung, Terence Chun-Ho
   Cheung, Kwok-Wai
TI Block-based adaptive ROI for remote photoplethysmography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mean-shift; Photoplethysmography (PPG); Region of interest (ROI); Remote
   imaging; Thresholding
ID IMAGING PHOTOPLETHYSMOGRAPHY; NONCONTACT; AGREEMENT
AB Remote photoplethysmography (rPPG) can achieve contactless human vital signs monitoring, but its signal quality is limited by the remote operation nature. In practical applications, improving the rPPG signal quality becomes an essential task. As a remote imaging technique, rPPG utilizes a camera to capture a video of a skin area, especially the facial area, then focuses on a particular sub-area as the region of interest (ROI). In this paper, we investigated a novel adaptive ROI (AROI) approach for improving the rPPG signal quality. In this approach, block-based spatial-temporal division is performed on a captured face video. Based on these segmented video pipelines, the spatial-temporal quality distribution of the rPPG signals is estimated using a signal-to-noise ratio (SNR) feature. Afterwards, AROIs are calculated through mean-shift clustering and adaptive thresholding in SNR maps. As the AROI can be dynamically adjusted according to the spatial-temporal quality distribution of rPPG signals on the face, the quality of the final recovered rPPG signal is improved. The performance of the proposed AROI approach was evaluated with both still and moving subjects. Compared to conventional ROI methods for rPPG, the proposed AROI obtained a higher accuracy in heart rate measurement. And the state-of-the-art motion-resistant rPPG techniques can be effectively enhanced through being integrated with the AROI.
C1 [Po, Lai-Man; Feng, Litong; Li, Yuming; Xu, Xuyuan] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   [Cheung, Terence Chun-Ho] City Univ Hong Kong, Dept Informat Syst, Hong Kong, Hong Kong, Peoples R China.
   [Cheung, Kwok-Wai] Chu Hai Coll Higher Educ, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong; City University of Hong Kong
RP Feng, LT (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Hong Kong, Peoples R China.
EM lightedfeng@gmail.com
RI wang, yi/HOF-6668-2023
OI FENG, LITONG/0000-0002-6716-3520
CR Allen J, 2007, PHYSIOL MEAS, V28, pR1, DOI 10.1088/0967-3334/28/3/R01
   [Anonymous], THESIS
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benesty J., 2009, NOISE REDUCTION SPEE, P1, DOI [10.1007/978-3-642-00296-0_5, DOI 10.1007/978-3-642-00296-05]
   Bland JM, 2007, J BIOPHARM STAT, V17, P571, DOI 10.1080/10543400701329422
   BLAND JM, 1986, LANCET, V1, P307, DOI 10.1016/s0140-6736(86)90837-8
   Bousefsaf F, 2013, BIOMED SIGNAL PROCES, V8, P568, DOI 10.1016/j.bspc.2013.05.010
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   CROWE JA, 1992, P IEEE EMBS, V14, P2423
   de Haan G, 2013, IEEE T BIO-MED ENG, V60, P2878, DOI 10.1109/TBME.2013.2266196
   Feng L, 2015, BLOCK BASED ADAPTIVE
   Feng LT, 2015, IEEE T CIRC SYST VID, V25, P879, DOI 10.1109/TCSVT.2014.2364415
   Fitzpatrick Thomas B, 1975, J MED ESTHETIQUE, V2, P33, DOI DOI 10.1159/000251345
   Han JW, 2015, IEEE T CIRC SYST VID, V25, P1309, DOI 10.1109/TCSVT.2014.2381471
   Hayes MJ, 1998, APPL OPTICS, V37, P7437, DOI 10.1364/AO.37.007437
   He ZY, 2017, IEEE T CYBERNETICS, V47, P354, DOI 10.1109/TCYB.2016.2514714
   Holton BD, 2013, PHYSIOL MEAS, V34, P1499, DOI 10.1088/0967-3334/34/11/1499
   Huang J, 2010, NEUROCOMPUTING, V73, P883, DOI 10.1016/j.neucom.2009.09.016
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Lempe G., 2013, BILDVERARBEITUNG MED, P99
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Ma X, 2016, KNOWL-BASED SYST, V106, P26, DOI 10.1016/j.knosys.2016.05.028
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Poh MZ, 2010, OPT EXPRESS, V18, P10762, DOI 10.1364/OE.18.010762
   Sun Y, 2013, J BIOMED OPT, V18, DOI 10.1117/1.JBO.18.6.061205
   Sun Y, 2011, J BIOMED OPT, V16, DOI 10.1117/1.3602852
   Tarassenko L, 2014, PHYSIOL MEAS, V35, P807, DOI 10.1088/0967-3334/35/5/807
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tsouri GR, 2012, J BIOMED OPT, V17, DOI 10.1117/1.JBO.17.7.077011
   Verkruysse W, 2008, OPT EXPRESS, V16, P21434, DOI 10.1364/OE.16.021434
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Zarzoso V, 2010, IEEE T NEURAL NETWOR, V21, P248, DOI 10.1109/TNN.2009.2035920
   Zhang D, 2009, INT J PATTERN RECOGN, V23, P521, DOI 10.1142/S0218001409007260
   Zhang DW, 2016, IEEE T NEUR NET LEAR, V27, P1163, DOI 10.1109/TNNLS.2015.2495161
NR 35
TC 22
Z9 33
U1 6
U2 54
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2018
VL 77
IS 6
BP 6503
EP 6529
DI 10.1007/s11042-017-4563-7
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FZ9JV
UT WOS:000427927700004
DA 2024-07-18
ER

PT J
AU Chen, Y
   Zhang, Y
   Lu, HM
   Chen, XQ
   Li, JW
   Wang, SH
AF Chen, Yi
   Zhang, Yin
   Lu, Hui-Min
   Chen, Xian-Qing
   Li, Jian-Wu
   Wang, Shui-Hua
TI Wavelet energy entropy and linear regression classifier for detecting
   abnormal breasts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast abnormality; Digital mammography; Wavelet energy entropy; Linear
   regression classifier; Least-squares estimation
ID MAMMARY CARCINOGENESIS; MASS DETECTION; CANCER; TRANSFORM; HISTOGRAM;
   BIOPSY; NOISE
AB Breast abnormalities are the early symptoms of breast cancers. They may also bring in psychoemotional stresses to women. In this study, we developed a new automatic program based on wavelet energy entropy (WEE) and linear regression classifier (LRC): First, we segment region of interest from mammogram images. Second, we calculate WEE from the segmented images. Third, LRC was used as the classifier. We named our method as "WEE + LRC". The experiment used 10-fold stratified cross validation that was repeated 10 times. The statistical results showed the classification result was the best when the decomposition level was 4, with a sensitivity of 92.00 +/- 3.20%, a specificity of 91.70 +/- 3.27%, and an accuracy of 91.85 +/- 2.21%. The proposed method was superior to other five state-of-the-art methods. In all, our method is effective in detecting abnormal breasts.
C1 [Chen, Yi; Wang, Shui-Hua] Nanjing Normal Univ, Sch Comp Sci & Technol, 1 Wenyuan, Nanjing 210023, Jiangsu, Peoples R China.
   [Chen, Yi] Hunan Policy Acad, Hunan Prov Key Lab Network Invest Technol, Changsha 410138, Hunan, Peoples R China.
   [Chen, Yi] Nanjing Univ Sci & Technol, Key Lab Image & Video Understanding Social Safety, Nanjing 210094, Jiangsu, Peoples R China.
   [Zhang, Yin] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan 430073, Hubei, Peoples R China.
   [Lu, Hui-Min] Kyushu Inst Technol, Dept Mech & Control Engn, Kitakyushu, Fukuoka 8048550, Japan.
   [Chen, Xian-Qing] Zhejiang Normal Univ, Dept Elect Engn, Coll Engn, Jinhua 321004, Zhejiang, Peoples R China.
   [Chen, Xian-Qing] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
   [Li, Jian-Wu] Beijing Inst Technol, Sch Comp Sci & Technol, Beijing 100081, Peoples R China.
   [Wang, Shui-Hua] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
C3 Nanjing Normal University; Nanjing University of Science & Technology;
   Zhongnan University of Economics & Law; Kyushu Institute of Technology;
   Zhejiang Normal University; Columbia University; Beijing Institute of
   Technology; City University of New York (CUNY) System; City College of
   New York (CUNY)
RP Wang, SH (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, 1 Wenyuan, Nanjing 210023, Jiangsu, Peoples R China.; Wang, SH (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
EM wangshuihua@njnu.edu.cn
RI Zhang, Yin/O-2149-2015; xianqing, chen/C-7474-2012; Zhang,
   Yin/K-2414-2019; Wang, shuihua/G-7326-2016
OI Zhang, Yin/0000-0002-1772-0763; Zhang, Yin/0000-0002-8103-8937; Wang,
   shuihua/0000-0003-4713-2791; Chen, Yi/0000-0002-8762-4523
FU NSFC [61602250, 61503188, 61562041, 61271374]; Natural Science
   Foundation of Jiangsu Province [BK20150983, BK20150982]; Program of
   Natural Science Research of Jiangsu Higher Education Institutions
   [14KJB520021]; Open Research Fund of Hunan Provincial Key Laboratory of
   Network Investigational Technology [2016WLZC013]; Open Fund of Fujian
   Provincial Key Laboratory of Data Intensive Computing [BD201607];
   Jiangsu Key Laboratory of Image and Video Understanding for Social
   Safety, Nanjing University of Science and Technology [30916014107]
FX This paper was supported by NSFC (61602250, 61503188, 61562041,
   61271374), Natural Science Foundation of Jiangsu Province (BK20150983,
   BK20150982), Program of Natural Science Research of Jiangsu Higher
   Education Institutions (14KJB520021), Open Research Fund of Hunan
   Provincial Key Laboratory of Network Investigational Technology
   (2016WLZC013), Open Fund of Fujian Provincial Key Laboratory of Data
   Intensive Computing (BD201607), Jiangsu Key Laboratory of Image and
   Video Understanding for Social Safety, Nanjing University of Science and
   Technology (30916014107).
CR Abdel-Nasser M, 2015, EXPERT SYST APPL, V42, P9499, DOI 10.1016/j.eswa.2015.07.072
   Adámeková E, 2003, BIOLOGIA, V58, P991
   Ammari ML, 2016, CAN J ELECT COMPUT E, V39, P42, DOI 10.1109/CJECE.2015.2436054
   [Anonymous], 2016, MINIMIAS DATABASE MA
   Arnawa IBKS, 2015, INT J ADV COMPUT SC, V6, P250
   Denis G, 2015, J IMMUNOL, V194
   Domingo L, 2016, EUR RADIOL, V26, P2520, DOI 10.1007/s00330-015-4074-8
   Evangelista AL, 2012, SUPPORT CARE CANCER, V20, P1499, DOI 10.1007/s00520-011-1238-1
   Görgel P, 2015, EXPERT SYST, V32, P155, DOI 10.1111/exsy.12073
   Hemmati F, 2016, APPL ACOUST, V104, P101, DOI 10.1016/j.apacoust.2015.11.003
   Ignatiadis M, 2016, EUR J CANCER, V63, P97, DOI 10.1016/j.ejca.2016.04.024
   Javed A, 2016, IEEE T BIO-MED ENG, V63, P431, DOI 10.1109/TBME.2015.2462750
   Jeon S, 2014, IEICE T INF SYST, VE97D, P361, DOI 10.1587/transinf.E97.D.361
   Kam JWY, 2016, CLIN NEUROPHYSIOL, V127, P369, DOI 10.1016/j.clinph.2015.03.007
   Kassayová M, 2007, ACTA VET BRNO, V76, P371, DOI 10.2754/avb200776030371
   Kolade VO, 2016, J GEN INTERN MED, V31, P411, DOI 10.1007/s11606-016-3594-5
   Leng XX, 2016, PHOTOGRAMM REC, V31, P166, DOI 10.1111/phor.12145
   Liu G., 2016, ENTROPY, V8, P11
   Liu Y, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON MEDICAL IMAGING PHYSICS AND ENGINEERING (ICMIPE), P254, DOI 10.1109/ICMIPE.2013.6864546
   Lu DY, 2016, J COMPUT APPL MATH, V302, P224, DOI 10.1016/j.cam.2016.02.013
   Majdak-Paredes EJ, 2015, J PLAST RECONSTR AES, V68, P1386, DOI 10.1016/j.bjps.2015.05.015
   Makandar A, 2016, J COMPUT, V11, P472, DOI 10.17706/jcp.11.6.472-478
   Martel-Billard C, 2016, GYNECOL OBSTET FERTI, V44, P211, DOI 10.1016/j.gyobfe.2016.02.016
   Matsuoka J, 2016, OPT REV, V23, P195, DOI 10.1007/s10043-016-0184-z
   Milosevic M, 2015, BIOMED ENG-BIOMED TE, V60, P49, DOI 10.1515/bmt-2014-0047
   Mojra A, 2009, IFMBE PROC, V25, P115, DOI 10.1007/978-3-642-03893-8_33
   Munir A, 2016, CANCER RES, V76, P2
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Oztekin A, 2016, EUR J OPER RES, V253, P697, DOI 10.1016/j.ejor.2016.02.056
   Phillips M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0090226
   Racz JM, 2016, CURR ONCOL, V23, pE260, DOI 10.3747/co.23.3017
   Renaudeau C, 2016, BREAST, V28, P54, DOI 10.1016/j.breast.2016.04.006
   Seal A, 2014, LECT NOTES COMPUT SC, V8537, P367
   Seigneurin A, 2016, BREAST, V28, P60, DOI 10.1016/j.breast.2016.04.013
   Tagliafico AS, 2016, BREAST, V28, P13, DOI 10.1016/j.breast.2016.04.008
   Tahir MA, 2011, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2011.6116667
   Talib Z, 2016, BREAST J, V22, P330, DOI 10.1111/tbj.12618
   Wang SH, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00106
   Wang SH, 2016, J ALZHEIMERS DIS, V50, P233, DOI 10.3233/JAD-150848
   Wantanajittikul K, 2016, COMPUT METH PROG BIO, V130, P76, DOI 10.1016/j.cmpb.2016.03.015
   Winkel RR, 2016, BMC CANCER, V16, DOI 10.1186/s12885-016-2450-7
   Xiao LM, 2016, NEUROCOMPUTING, V195, P56, DOI 10.1016/j.neucom.2015.08.113
   Yang SN, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0128404
   Yu J, 2013, PROCEEDINGS 2013 INTERNATIONAL CONFERENCE ON MECHATRONIC SCIENCES, ELECTRIC ENGINEERING AND COMPUTER (MEC), P39, DOI 10.1109/MEC.2013.6885047
   Yu WB, 2016, LECT NOTES ELECTR EN, V378, P27, DOI 10.1007/978-3-662-49370-0_4
   Yu XY, 2016, BMC CANCER, V16, DOI 10.1186/s12885-016-2537-1
   Zaharescu E, 2007, Proceedings of the 2007 15th International Conference on Digital Signal Processing, P171, DOI 10.1109/ICDSP.2007.4288546
   Zhang YD, 2016, ADV MECH ENG, V8, DOI 10.1177/1687814016634243
   Zhang YD, 2008, SCI CHINA SER F, V51, P2115, DOI 10.1007/s11432-008-0124-z
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P873, DOI 10.1177/0037549716667834
   Zhang YD, 2016, SIMUL-T SOC MOD SIM, V92, P861, DOI 10.1177/0037549716666962
   Zhang YD, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/3871575
   Zhang YD, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18030077
   Zhang YD, 2016, J ALZHEIMERS DIS, V50, P1163, DOI 10.3233/JAD-150988
   Zhang YD, 2015, BIOMED SIGNAL PROCES, V21, P58, DOI 10.1016/j.bspc.2015.05.014
   Zhang YD, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00066
   Zhang YD, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/840491
   Zhang YD, 2010, SCI CHINA INFORM SCI, V53, P1963, DOI 10.1007/s11432-010-4075-9
   Zubor P, 2015, MOL BIOL REP, V42, P977, DOI 10.1007/s11033-014-3834-x
NR 59
TC 27
Z9 29
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2018
VL 77
IS 3
BP 3813
EP 3832
DI 10.1007/s11042-016-4161-0
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FW2KT
UT WOS:000425132600051
DA 2024-07-18
ER

PT J
AU Devi, SS
   Roy, A
   Singha, J
   Sheikh, SA
   Laskar, RH
AF Devi, Salam Shuleenda
   Roy, Amarjit
   Singha, Joyeeta
   Sheikh, Shah Alam
   Laskar, Rabul Hussain
TI Malaria infected erythrocyte classification based on a hybrid classifier
   using microscopic images of thin blood smear
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Microscopic image; Erythrocyte; Co-occurrence of linear binary pattern
   (LBP-GLCM); Hybrid classifier
ID FEATURE-SELECTION; IDENTIFICATION; PARASITES; MACHINE; SVM
AB This paper aims to develop the computer assisted malaria infected erythrocyte classification based on a hybrid classifier. The major issues are feature extraction, optimal feature selection and erythrocytes classification. 54 dimensional features formed by the combination of the proposed features and the existing features have been used to define the feature set. The features such as prediction error, co-occurrence of linear binary pattern, chrominance channel histogram, R-G color channel difference histogram are the newly proposed features in our system. For feature selection, the different techniques have been explored to obtain the optimal feature set. Further, the performance of the different individual classifiers (SVM, k-NN and Naive Bayes) and hybrid classifier, obtained by combining the individual classifiers, is evaluated using the optimal feature set. Using the proposed optimal feature set and hybrid model, better performances (i.e. sensitivity 95.86%, accuracy 98.5%, F-score 93.82%) have been achieved on the collected clinical database. Based on the experimental results it may be concluded that hybrid classifier provides satisfactory results with an improvement in sensitivity (1.09%, 12.04%, 0%), accuracy (0.12%, 1.15%, 1.27%) and F-score (0.7%, 5.77%, 4.61%) as compared to the individual classifiers i.e. SVM, k-NN and Naive Bayes respectively.
C1 [Devi, Salam Shuleenda; Roy, Amarjit; Singha, Joyeeta; Laskar, Rabul Hussain] Natl Inst Technol, Dept Elect & Commun Engn, Speech & Image Proc Grp, Silchar 788010, Assam, India.
   [Sheikh, Shah Alam] Silchar Med Coll & Hosp, Silchar 788014, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Devi, SS (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Speech & Image Proc Grp, Silchar 788010, Assam, India.
EM shuleenda26@gmail.com; royamarjit90@gmail.com;
   joyeetasingha26@gmail.com; shahalamsheikh61@gmail.com; rabul18@yahoo.com
RI Devi, Salam Shuleenda/IAP-2132-2023; Roy, Amarjit/ABD-1033-2020; Laskar,
   Rabul Hussain/AFU-7180-2022
OI Laskar, Rabul Hussain/0000-0003-3988-394X; Roy,
   Amarjit/0000-0003-3725-4568; Devi, Salam Shuleenda/0000-0002-3356-7658
FU Speech and Image Processing Lab under Department of ECE at National
   Institute of Technology, Silchar, India
FX This work is supported by the Speech and Image Processing Lab under
   Department of ECE at National Institute of Technology, Silchar, India.
CR Abdul-Nasir Aimi Salihah, 2013, WSEAS Transactions on Biology and Biomedicine, V10, P41
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], DIAGNOSING MED PARAS
   [Anonymous], THESIS
   [Anonymous], 2015, 4 INT C SOFT COMP PR
   [Anonymous], P SIGN PROC COMM APP
   [Anonymous], 2009, AUTOMATIC MALARIA DI
   [Anonymous], 2014, OPEN J CLIN DIAGN, DOI DOI 10.4236/OJCD.2014.42014
   [Anonymous], 2014, International Journal of Emerging Engineering Research and Technology
   [Anonymous], THESIS
   [Anonymous], ADV THERAPEUTIC ENG
   [Anonymous], INTRO PATTERN RECOGN
   [Anonymous], P INT C IM INF IND
   [Anonymous], P IEEE INT JOINT C N
   Bairagi VK, 2016, INT J BIOMED IMAGING, V2016, DOI 10.1155/2016/7214156
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chen W, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0047843
   Cheng JR, 2009, IEEE T BIO-MED ENG, V56, P741, DOI 10.1109/TBME.2008.2008635
   Chowdhury S, 2015, EXPERT SYST APPL, V42, P5047, DOI 10.1016/j.eswa.2015.02.047
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Das DK, 2013, MICRON, V45, P97, DOI 10.1016/j.micron.2012.11.002
   Dash JK, 2017, MULTIMED TOOLS APPL, V76, P2535, DOI 10.1007/s11042-015-3231-z
   Dhiman S, 2010, DEFENCE SCI J, V60, P213, DOI 10.14429/dsj.60.342
   Di Ruberto C, 2002, IMAGE VISION COMPUT, V20, P133, DOI 10.1016/S0262-8856(01)00092-0
   Díaz G, 2007, LECT NOTES COMPUT SC, V4756, P812
   Díaz G, 2009, J BIOMED INFORM, V42, P296, DOI 10.1016/j.jbi.2008.11.005
   Ding H, 2014, MOL BIOSYST, V10, P2229, DOI 10.1039/c4mb00316k
   Eun SJ, 2015, MULTIMED TOOLS APPL, V74, P6273, DOI 10.1007/s11042-014-2089-9
   Fan D, 2016, MULTIMED TOOLS APPL, V75, P12227, DOI 10.1007/s11042-016-3459-2
   Ghosh Madhumala, 2013, International Journal of Artificial Intelligence and Soft Computing, V3, P203
   Jung C, 2010, IEEE T BIO-MED ENG, V57, P2600, DOI 10.1109/TBME.2010.2060336
   Khan M.I., 2011, Int. J. Biom. Bioinform, V5, P97
   Kumarasamy SK, 2011, MACH VISION APPL, V22, P461, DOI 10.1007/s00138-010-0284-x
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   Maity M., 2012, INT J COMPUTER APPL, V52, P31, DOI [DOI 10.5120/8279-1906, 10.5120/8279-1906]
   Mejdoub M, 2013, MULTIMED TOOLS APPL, V64, P197, DOI 10.1007/s11042-011-0900-4
   Moore A.W., 2001, CROSS VALIDATION DET
   Murphy SC, 2013, AM J TROP MED HYG, V89, P824, DOI 10.4269/ajtmh.12-0675
   Niu B, 2013, BIOMED RES INT, V2013, DOI 10.1155/2013/674215
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Prasad K, 2012, J DIGIT IMAGING, V25, P542, DOI 10.1007/s10278-011-9442-6
   Proakis J. G., 2001, Digital Signal Processing: Principles Algorithms and Applications
   Purwar Y, 2011, MALARIA J, V10, DOI 10.1186/1475-2875-10-364
   Rodríguez A, 2005, MULTIMED TOOLS APPL, V25, P37, DOI 10.1023/B:MTAP.0000046381.73660.64
   Ross NE, 2006, MED BIOL ENG COMPUT, V44, P427, DOI 10.1007/s11517-006-0044-2
   Roy A, 2016, SIGNAL PROCESS, V128, P262, DOI 10.1016/j.sigpro.2016.04.007
   Russell S., 2016, Artificial intelligence a modern approach
   Ruta D., 2005, Information Fusion, V6, P63, DOI 10.1016/j.inffus.2004.04.008
   Savkare S.S., 2011, International Journal of Computer Science and Security (IJCSS), V5, P310
   Sertel O, 2011, COMPUT MED IMAG GRAP, V35, P616, DOI 10.1016/j.compmedimag.2011.01.009
   Soni J., 2011, Int J Adv Eng Technol, V1, P290
   Sun FM, 2016, MULTIMED TOOLS APPL, V75, P1427, DOI 10.1007/s11042-014-2141-9
   Tek F.B., 2006, P BRIT MACH VIS C 20, P347
   Tek FB, 2010, COMPUT VIS IMAGE UND, V114, P21, DOI 10.1016/j.cviu.2009.08.003
   Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P54, DOI 10.1109/AFGR.2000.840612
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wongsrichanalai C, 2007, AM J TROP MED HYG, V77, P119, DOI 10.4269/ajtmh.2007.77.119
   Zhu WZ, 2016, MULTIMED TOOLS APPL, V75, P2815, DOI 10.1007/s11042-015-2582-9
   2013, WORLD MALARIA REPORT, P1
NR 60
TC 21
Z9 22
U1 1
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 631
EP 660
DI 10.1007/s11042-016-4264-7
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400026
DA 2024-07-18
ER

PT J
AU Fang, SS
   Yang, JC
   Liu, N
   Sun, WH
   Zhao, TT
AF Fang, Shanshan
   Yang, Jucheng
   Liu, Na
   Sun, Wenhui
   Zhao, Tingting
TI Face recognition using weber local circle gradient pattern method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Feature extraction; Weber local descriptor; Weber
   local circle gradient pattern; Infrared face database
ID NEURAL-NETWORK; EIGENFACES; SCALE
AB The Weber Local Descriptor (WLD) is a classical and efficient face representation method, but it has the shortage that it employs the contrast information between the center pixel and its eight nearest pixels, which can also be sensitive to illumination variation. In order to overcome the shortcomings mentioned above and solve the problem of sensitivity to the illumination, we propose a novel face recognition algorithm, Weber Local Circle Gradient Pattern (WLCGP), which not only takes the relationship between the target pixel and the surrounding pixels into account, but also considers the relationship among the surrounding pixels. Through calculating the overall gradient information and the cycle gradient information of an image, the WLCGP method can produce the fusion characteristic and extract more effective and discriminative feature information. Finally, we demonstrate the superiority of the proposed WLCGP method over the traditional methods on the ORL, AR face database and the Singapore infrared face database.
C1 [Fang, Shanshan; Yang, Jucheng; Liu, Na; Sun, Wenhui; Zhao, Tingting] Tianjin Univ Sci & Technol, Coll Comp Sci & Informat Engn, Tianjin 300222, Peoples R China.
C3 Tianjin University Science & Technology
RP Yang, JC (corresponding author), Tianjin Univ Sci & Technol, Coll Comp Sci & Informat Engn, Tianjin 300222, Peoples R China.
EM jcyang@tust.edu.cn
FU National Natural Science Foundation of China [61502338, 61502339]; key
   projects of Tianjin science and technology support program
   [15ZCZDGX00200]; Guangdong Provincial Key Laboratory of Petrochemical
   Equipment Fault Diagnosis [GDUPTKLAB201504]; Tianjin Food Safety & Low
   Carbon Manufacturing Collaborative Innovation Center
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61502338 and No. 61502339, the 2015 key projects
   of Tianjin science and technology support program No. 15ZCZDGX00200, the
   Open Fund of Guangdong Provincial Key Laboratory of Petrochemical
   Equipment Fault Diagnosis No. GDUPTKLAB201504, and the Fund of Tianjin
   Food Safety & Low Carbon Manufacturing Collaborative Innovation Center.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bellil W, 2016, MULTIMED TOOLS APPL, V75, P365, DOI 10.1007/s11042-014-2294-6
   Borgi MA, 2015, MULTIMED TOOLS APPL, V74, P11281, DOI 10.1007/s11042-014-2228-3
   Boughrara H, 2016, MULTIMED TOOLS APPL, V75, P709, DOI 10.1007/s11042-014-2322-6
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   Fang SS, 2015, LECT NOTES COMPUT SC, V9428, P186, DOI 10.1007/978-3-319-25417-3_23
   Ghiass RS, 2014, PATTERN RECOGN, V47, P2807, DOI 10.1016/j.patcog.2014.03.015
   Heikkilä M, 2006, LECT NOTES COMPUT SC, V4338, P58
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jiang YY, 2015, NEUROCOMPUTING, V165, P190, DOI 10.1016/j.neucom.2015.03.009
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Lei Z, 2011, IEEE T IMAGE PROCESS, V20, P247, DOI 10.1109/TIP.2010.2060207
   Bui L, 2011, LECT NOTES COMPUT SC, V6881, P436, DOI 10.1007/978-3-642-23851-2_45
   Li ST, 2013, NEUROCOMPUTING, V122, P272, DOI 10.1016/j.neucom.2013.05.038
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang B, 2011, IEEE SIGNAL PROC LET, V18, P462, DOI 10.1109/LSP.2011.2158998
   Wu Y, 2014, NEUROCOMPUTING, V136, P262, DOI 10.1016/j.neucom.2014.01.006
   Yin JJ, 2016, STAT METHODOL, V32, P91, DOI 10.1016/j.stamet.2016.04.001
   Zhang N, 2012, PATTERN RECOGN LETT, V33, P1689, DOI 10.1016/j.patrec.2012.05.020
   Zhang XY, 2014, LECT NOTES COMPUT SC, V8833, P103, DOI 10.1007/978-3-319-12484-1_11
   Zhang Z, 2015, KNOWL-BASED SYST, V84, P78, DOI 10.1016/j.knosys.2015.04.003
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 27
TC 9
Z9 10
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2807
EP 2822
DI 10.1007/s11042-017-4412-8
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400056
DA 2024-07-18
ER

PT J
AU Verma, R
   Pandey, R
AF Verma, Rajiv
   Pandey, Rajoo
TI A statistical approach to adaptive search region selection for NLM-based
   image denoising algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Non-local means; Denoising; Search region size; Region pixels
   contribution ratio
ID NONLOCAL MEANS ALGORITHM; ANSCOMBE TRANSFORMATION; OPTIMAL INVERSION
AB Non-local means (NLM) filtering is an effective and popular image denoising algorithm. It estimates the pixel by taking advantage of redundancy present in a whole image or in a predefined fixed search region. NLM algorithm using fixed size search region for all pixels is unable to preserve the important details such as edges and texture in an image due to inclusion of unrelated pixels in the averaging. The selection of variable size search region for each pixel in an image is a critical issue in NLM algorithm. This paper focuses on the selection of optimal size search region for each pixel according to the characteristics of the region. The proposed algorithm adaptively selects an optimal size search region for a pixel based on maximization of ratio of contribution of similar pixels to dissimilar pixels for different search regions centered on that pixel. Experimental results on standard natural test images show that the proposed algorithm performs consistently better than the conventional NLM and other state-of-the-art NLM variants in terms of PSNR (dB), SSIM and visual quality at various noise levels.
C1 [Verma, Rajiv; Pandey, Rajoo] Natl Inst Technol, Dept Elect & Commun Engn, Kurukshetra 136119, Haryana, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Verma, R (corresponding author), Natl Inst Technol, Dept Elect & Commun Engn, Kurukshetra 136119, Haryana, India.
EM rajiv_6120043@nitkkr.ac.in; rajoo_pandey@nitkkr.ac.in
RI Verma, Dr. Rajiv/ADY-3318-2022; Verma, Dr. Rajiv/F-1330-2015
OI Verma, Dr. Rajiv/0000-0003-1873-0899; Verma, Dr.
   Rajiv/0000-0003-1873-0899
CR [Anonymous], 1999, COMP VIS 1999 P 7 IE
   [Anonymous], 1965, Statistical theory and methodology in science and engineering
   Berkovich H, 2013, IM SIGN PROC AN ISPA
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2010, SIAM REV, V52, P113, DOI 10.1137/090773908
   Buades A, 2011, IMAGE PROCESS ON LIN, V1, P208, DOI 10.5201/ipol.2011.bcm_nlm
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   de la Rosa Vargas JI, 2016, 2013 INT C EL COMM C
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hu J, 2013, OPTIK, V124, P5639, DOI 10.1016/j.ijleo.2013.04.009
   Lefkimmiatis S, 2009, IEEE T IMAGE PROCESS, V18, P1724, DOI 10.1109/TIP.2009.2022008
   Mahmoudi M, 2005, IEEE SIGNAL PROC LET, V12, P839, DOI 10.1109/LSP.2005.859509
   Mäkitalo M, 2013, IEEE T IMAGE PROCESS, V22, P91, DOI 10.1109/TIP.2012.2202675
   Mäkitalo M, 2011, IEEE T IMAGE PROCESS, V20, P99, DOI 10.1109/TIP.2010.2056693
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Milanfar P, 2013, IEEE SIGNAL PROC MAG, V30, P106, DOI 10.1109/MSP.2011.2179329
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1211, DOI 10.1007/s11760-012-0389-y
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1159, DOI 10.1007/s11760-012-0372-7
   Tasdizen T, 2009, IEEE T IMAGE PROCESS, V18, P2649, DOI 10.1109/TIP.2009.2028259
   Thacker NA, 2010, IET COMPUT VIS, V4, P162, DOI 10.1049/iet-cvi.2008.0076
   Tiku M, 2004, ENCY STAT SCI, DOI [10.1002/0471667196.ess1798.pub2, DOI 10.1002/0471667196.ESS1798.PUB2]
   Tomasi C., 1998, P ICCV
   Van de Ville D, 2011, IEEE T IMAGE PROCESS, V20, P2683, DOI 10.1109/TIP.2011.2121083
   Van De Ville D, 2009, IEEE SIGNAL PROC LET, V16, P973, DOI 10.1109/LSP.2009.2027669
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P763, DOI 10.1109/LSP.2013.2263135
   Wu Y, 2013, IEEE SIGNAL PROC LET, V20, P411, DOI 10.1109/LSP.2013.2247755
   Xiao F, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.749
   Zeng WL, 2011, ELECTRON LETT, V47, P1125, DOI 10.1049/el.2011.2456
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P1093, DOI 10.1109/TIP.2008.924386
   Zhu SJ, 2014, OPTIK, V125, P7040, DOI 10.1016/j.ijleo.2014.07.102
NR 33
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 1
BP 549
EP 566
DI 10.1007/s11042-016-4227-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FS7RL
UT WOS:000419995400023
DA 2024-07-18
ER

PT J
AU Wang, J
   Bacic, B
   Yan, WQ
AF Wang, Jia
   Bacic, Boris
   Yan, Wei Qi
TI An effective method for plate number recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Registration plate recognition; HSV colour space; Edge detection;
   Template matching
ID LOCALIZATION METHOD; EDGE-DETECTION; LICENSE; EXTRACTION; VIDEO
AB In this paper, a novel plate number localization algorithm called Secondary Positioning (SP) is proposed and tested on locally acquired data set. The rough position of a plate number is identified at the first stage by searching red light regions in HSV colour space, and then an accurate position of the plate number is localized in the second stage by finding out vertical edge of the plate number. Template matching which is implemented for recognizing individual character incorporates correction coefficient calculated between the templates and testing images. The test dataset includes two subsets from our local plate numbers, namely, 120 images are used for plate number localization, and 80 images for plate number recognition. The precisions obtained from plate number localization and recognition are approximately 75% and 70% respectively, indicating the performances are better than expected compared to the relevant contexts from the literature survey.
C1 [Wang, Jia; Bacic, Boris; Yan, Wei Qi] Auckland Univ Technol, Auckland 1010, New Zealand.
C3 Auckland University of Technology
RP Yan, WQ (corresponding author), Auckland Univ Technol, Auckland 1010, New Zealand.
EM dcsyanwq@gmail.com
RI Bačić, Boris/M-3952-2019
OI Bačić, Boris/0000-0003-0305-4322
CR Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   [Anonymous], 2005, P INT C COMP SCI RIV
   [Anonymous], [No title captured]
   Bai HL, 2004, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2004.1334387
   BAILEY DG, 2002, P 1 IEEE INT WORKSH
   COMELLI P, 1995, IEEE T VEH TECHNOL, V44, P790, DOI 10.1109/25.467963
   Cui YT, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P126, DOI 10.1109/ICIP.1997.632014
   Di Stefano L, 2005, PATTERN RECOGN LETT, V26, P2129, DOI 10.1016/j.patrec.2005.03.022
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   JIN C, 2013, 9 TH INT C INT INF, P395, DOI DOI 10.1109/IIH-MSP.2013.105
   Kim S, 2002, INT C PATT RECOG, P216, DOI 10.1109/ICPR.2002.1047833
   LEE ER, 1994, IEEE IMAGE PROC, P301, DOI 10.1109/ICIP.1994.413580
   LEE JSJ, 1987, IEEE T ROBOTIC AUTOM, V3, P142, DOI 10.1109/JRA.1987.1087088
   Lin CH, 2007, 2007 Power Conversion Conference - Nagoya, Vols 1-3, P227, DOI 10.1109/ICICIC.2007.372
   Mahini H, 2006, INT C PATT RECOG, P841
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Megalingam Rajesh Kannan, 2010, 2010 2nd International Conference on Mechanical and Electrical Technology (ICMET), P496, DOI 10.1109/ICMET.2010.5598409
   Naimi A, 2016, LECT NOTES COMPUT SC, V9948, P462, DOI 10.1007/978-3-319-46672-9_52
   Naito T, 2000, IEEE T VEH TECHNOL, V49, P2309, DOI 10.1109/25.901900
   Oliveira V. A., 2009, SKIN DETECTION USING
   Omachi M, 2009, 2009 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND INFORMATION TECHNOLOGY, VOL 2, P284, DOI 10.1109/ICCSIT.2009.5234518
   Parisi R., 1998, ISCAS '98. Proceedings of the 1998 IEEE International Symposium on Circuits and Systems (Cat. No.98CH36187), P195, DOI 10.1109/ISCAS.1998.703970
   Patel A., 2013, INT J COMPUTER APPL, V69, P0975, DOI [10.5120/11871-7665, DOI 10.5120/11871-7665]
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Roomi S. Mohamed Mansoor, 2011, 2011 Proceedings of International Conference on Computer, Communication and Electrical Technology (ICCCET 2011), P92, DOI 10.1109/ICCCET.2011.5762445
   Shi X, 2005, COMPUTATIONAL SCI IT
   Suryanarayana PV, 2005, INDICON 2005 PROCEEDINGS, P24
   Tarabek P, 2012, FED CONF COMPUT SCI, P149
   Wei W, 2001, NEURAL NETWORKS FOR SIGNAL PROCESSING XI, P529, DOI 10.1109/NNSP.2001.943157
   Wu HHR, 2006, INT C PATT RECOG, P824
   Xu J-F, 2004, P INT C MACH LEARN C, V96, P623
   Yu M, 2000, IEEE SYS MAN CYBERN, P2975, DOI 10.1109/ICSMC.2000.884453
   Zheng D, 2005, PATTERN RECOGN LETT, V26, P2431, DOI 10.1016/j.patrec.2005.04.014
NR 33
TC 10
Z9 10
U1 0
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 1679
EP 1692
DI 10.1007/s11042-017-4356-z
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400009
DA 2024-07-18
ER

PT J
AU Zhang, D
   Liao, XF
   Yang, B
   Zhang, YS
AF Zhang, Di
   Liao, Xiaofeng
   Yang, Bo
   Zhang, Yushu
TI A fast and efficient approach to color-image encryption based on
   compressive sensing and fractional Fourier transform
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image encryption; Compressive sensing; Kronecker product; Skew tent map;
   Fraction Fourier transform
ID ALGORITHM; CHAOS
AB This paper introduces a novel method of fast and efficient measurement matrices and random phase masks for color image encryption, in which Kronecker product (KP) is combined with chaotic map. The encryption scheme is based on two-dimension (2D) compressive sensing (CS) and fraction Fourier transform (FrFT). In this algorithm, the KP is employed to extend low dimension seed matrices to obtain high dimension measurement matrices and random phase masks. The low dimension seed matrices are generated by controlling chaotic map. The original image is simultaneously encrypted and compressed by the 2D CS, then re-encrypted with FrFT. The proposed encryption scheme fulfills high speed, low complexity and high security. Numerical simulation results demonstrate the excellent performance and security of the proposed scheme.
C1 [Zhang, Di; Liao, Xiaofeng; Yang, Bo; Zhang, Yushu] Southwest Univ, Coll Elect & Informat Engn, Chongqing Key Lab Nonlinear Circuits & Intelligen, Chongqing 400715, Peoples R China.
C3 Southwest University - China
RP Liao, XF (corresponding author), Southwest Univ, Coll Elect & Informat Engn, Chongqing Key Lab Nonlinear Circuits & Intelligen, Chongqing 400715, Peoples R China.
EM xfliao@cqu.edu.cn
RI Liao, Xiaofeng/HPD-6655-2023
FU National Key Research and Development Program of China [2016
   YFB0800601]; National Nature Science Foundation of China [61472331];
   Ministry of Education of China [20110191130005]; Fundamental Research
   Funds for the Central Universities [XDJK2015C078]; Talents of Science
   and Technology promote plan, Chongqing Science & Technology Commission
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant 2016 YFB0800601, in part by the
   National Nature Science Foundation of China under Grant 61472331, in
   part by the Research Found of preferential Development Domain for the
   Doctoral program of Ministry of Education of China under Grant
   20110191130005, in part by the Fundamental Research Funds for the
   Central Universities under Grant XDJK2015C078, in part by the Talents of
   Science and Technology promote plan, Chongqing Science & Technology
   Commission.
CR Baraniuk RG, 2007, IEEE SIGNAL PROC MAG, V24, P6, DOI 10.1109/MSP.2007.909718
   Bianchi Tiziano, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3992, DOI 10.1109/ICASSP.2014.6854351
   Candès EJ, 2008, CR MATH, V346, P589, DOI 10.1016/j.crma.2008.03.014
   Chen F, 2014, THEOR COMPUT SCI, V552, P13, DOI 10.1016/j.tcs.2014.08.002
   Chen JX, 2015, OPT LASER ENG, V67, P191, DOI 10.1016/j.optlaseng.2014.11.017
   Chen JX, 2015, OPT LASER ENG, V66, P1, DOI 10.1016/j.optlaseng.2014.08.010
   CHEN SB, 1994, CONF REC ASILOMAR C, P41, DOI 10.1109/ACSSC.1994.471413
   Do TT, 2012, IEEE T SIGNAL PROCES, V60, P139, DOI 10.1109/TSP.2011.2170977
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Gan L., 2008, 2008 16th European Signal Processing Conference, P1
   George SN, 2014, SENS IMAGING, V15, DOI 10.1007/s11220-014-0085-9
   Hua W, 2016, MULTIMED TOOLS APPL, P1
   Huang R, 2014, MULTIMED TOOLS APPL, V72, P71, DOI 10.1007/s11042-012-1337-0
   Hwang HE, 2011, OPT COMMUN, V284, P3243, DOI 10.1016/j.optcom.2011.03.030
   Lin QZ, 2012, INT J BIFURCAT CHAOS, V22, DOI 10.1142/S0218127412502562
   Liu H, 2015, OPTIK, V126, P2663, DOI 10.1016/j.ijleo.2015.06.079
   Liu XY, 2013, OPTIK, V124, P6590, DOI 10.1016/j.ijleo.2013.05.092
   Liu XB, 2014, J MOD OPTIC, V61, P1570, DOI 10.1080/09500340.2014.946565
   Lui OY, 2012, APPL SOFT COMPUT, V12, P125, DOI 10.1016/j.asoc.2011.09.003
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Tsiligianni EV, 2014, IEEE T INFORM THEORY, V60, P2319, DOI 10.1109/TIT.2014.2308171
   Tu GY, 2013, OPTIK, V124, P5411, DOI 10.1016/j.ijleo.2013.03.113
   Van CF, 2000, J COMPUT APPL MATH, V123, P85
   Zhang L, 2015, IOP CONF SER-MAT SCI, V72, DOI 10.1088/1757-899X/72/2/022015
   Zhang Y, 2014, ARXIV14036213
   Zhang YS, 2015, SIGNAL PROCESS-IMAGE, V39, P202, DOI 10.1016/j.image.2015.09.001
   Zhang YS, 2015, ELECTRON LETT, V51, P1572, DOI 10.1049/el.2015.0927
   Zhang YS, 2013, OPT LETT, V38, P4506, DOI 10.1364/OL.38.004506
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhou NR, 2015, OPT COMMUN, V354, P112, DOI 10.1016/j.optcom.2015.05.043
   Zhou NR, 2015, OPT COMMUN, V343, P10, DOI 10.1016/j.optcom.2014.12.084
   Zhou NR, 2014, OPT LASER TECHNOL, V62, P152, DOI 10.1016/j.optlastec.2014.02.015
NR 33
TC 79
Z9 80
U1 2
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2018
VL 77
IS 2
BP 2191
EP 2208
DI 10.1007/s11042-017-4370-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FT0DJ
UT WOS:000422790400031
DA 2024-07-18
ER

PT J
AU Chen, HK
AF Chen, Hung-Kuang
TI Evaluation of triangular mesh layout techniques using large mesh
   simplification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Mesh layout; Graph layout; Matrix bandwidth; Mesh simplification
ID BANDWIDTH; ALGORITHM
AB Highly detailed polygonal meshes nowadays were created vastly from a great number of multimedia applications. Insufficient main memory space and inferior locality-of-reference nature of the input mesh sequence incurred frequent page swaps and extremely low runtime efficiency. To address this issue, techniques based on the models of graph layout, matrix bandwidth minimization, and space-filling-curves were reported. However, such models merely considered the optimization of vertex layout on the basis of the graph distance or matrix bandwidths while leave the optimization of face layout either unoptimized or resorted an additional sorting procedure. In this paper, we propose an improved theoretic model suggesting the optimization of index-faced triangular mesh layout on the basis of a jointly consideration on both the vertex and face layout. Unlike previous attempts, we do not need additional efforts in optimizing one layout after the other by sorting, the optimized layouts are generated on the fly with each other with respect to both the vertex or triangle bandwidths. According to the experimental results, our approach outperforms the CM and SFC methods not only at yielding better theoretical results but also at improving the runtime efficiency of large mesh simplification.
C1 [Chen, Hung-Kuang] Natl Chin Yi Univ Technol, Elect Engn Dept, Taichung 40109, Taiwan.
C3 National Chin-Yi University of Technology
RP Chen, HK (corresponding author), Natl Chin Yi Univ Technol, Elect Engn Dept, Taichung 40109, Taiwan.
EM hankchentw@gmail.com
RI Chen, Hung-Kuang/R-1255-2019
OI Chen, Hung-Kuang/0000-0002-3994-9745
CR Ahn M, 2006, IEEE T VIS COMPUT GR, V12, P1221, DOI 10.1109/TVCG.2006.169
   [Anonymous], 1987, REMOTE SENSING IMAGE
   [Anonymous], 2011, Analysis, Restoration, and Reconstruction of Ancient Artworks
   BarYehuda R, 1996, ACM T GRAPHIC, V15, P141, DOI 10.1145/234972.234976
   Bender MA, 2011, THEOR COMPUT SYST, V48, P269, DOI 10.1007/s00224-009-9242-2
   Bogomjakov A, 2002, COMPUT GRAPH FORUM, V21, P137, DOI 10.1111/1467-8659.00573
   Bolitho M., 2007, Symposium on Geometry Processing (SGP), P69
   Brodal GS, 2004, LECT NOTES COMPUT SC, V3111, P3
   Cabiddu D, 2015, COMPUT GRAPH-UK, V51, P81, DOI 10.1016/j.cag.2015.05.015
   Chen HK, 2007, LECT NOTES COMPUT SC, V4563, P3
   Chen HK, 2006, J INF SCI ENG, V22, P843
   Chow MM, 1997, VISUALIZATION '97 - PROCEEDINGS, P347, DOI 10.1109/VISUAL.1997.663902
   Cignoni P, 2003, IEEE T VIS COMPUT GR, V9, P525, DOI 10.1109/TVCG.2003.1260746
   Cuthill E., 1969, P 1969 24 NAT C, P157, DOI [10.1145/800195.805928, DOI 10.1145/800195.805928]
   Deering M., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P13, DOI 10.1145/218380.218391
   Demaine E.D., 2002, Lecture Notes from the EEF Summer School on Massive Data Sets, P1
   Derzapf Evgenij, 2010, Realismus der Echtzeitgrafik, V61
   Díaz J, 2002, ACM COMPUT SURV, V34, P313, DOI 10.1145/568522.568523
   Esposito A, 1998, OPER RES LETT, V23, P99, DOI 10.1016/S0167-6377(98)00040-6
   Farias R, 2001, IEEE COMPUT GRAPH, V21, P42, DOI 10.1109/38.933523
   Frigo M, 2012, ACM T ALGORITHMS, V8, DOI 10.1145/2071379.2071383
   Garland M., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P209, DOI 10.1145/258734.258849
   GIBBS NE, 1976, SIAM J NUMER ANAL, V13, P236, DOI 10.1137/0713023
   Hoppe H, 1998, VISUALIZATION '98, PROCEEDINGS, P35, DOI 10.1109/VISUAL.1998.745282
   Hoppe H, 1999, COMP GRAPH, P269, DOI 10.1145/311535.311565
   Isenburg M, 2005, IEEE Visualization 2005, Proceedings, P231
   Isenburg M, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P465, DOI 10.1109/VISUAL.2003.1250408
   Isenburg M, 2003, ACM T GRAPHIC, V22, P935, DOI 10.1145/882262.882366
   Isenburg Martin., 2005, ACM SIGGRAPH 2005 Sketches, P136
   Koller D., 2006, J ROMAN ARCHAEOL S3, P237
   Li L, 2002, ROBOT CIM-INT MANUF, V18, P53, DOI 10.1016/S0736-5845(01)00026-6
   Lin G, 2006, IEEE T VIS COMPUT GR, V12, P640, DOI 10.1109/TVCG.2006.59
   Lindstrom P, 2002, IEEE T VIS COMPUT GR, V8, P239, DOI 10.1109/TVCG.2002.1021577
   Lindstrom P, 2001, IEEE VISUAL, P363, DOI 10.1109/VISUAL.2001.964533
   Lindstrom P, 2000, COMP GRAPH, P259, DOI 10.1145/344779.344912
   Liu R, 2006, LECT NOTES COMPUT SC, V4077, P630
   Miller GL, 1998, SIAM J SCI COMPUT, V19, P364, DOI 10.1137/S1064827594262613
   Park JS, 2006, CLIN ANAT, V19, P216, DOI 10.1002/ca.20275
   Pascucci Valerio., 2001, Proceedings of the 2001 ACM/IEEE conference on Supercom- puting (CDROM), Supercomputing '01, P2
   Petit J., 2013, B EATCS, V3
   Sagan H., 1994, SPACE FILLING CURVES
   Sajadi B., 2011, Symposium on Interactive 3D Graphics and Games, P175, DOI DOI 10.1145/1944745.1944775
   Sander P-V, 2008, ACM SIGGRAPH AS 2008
   Spitzer V, 1996, J AM MED INFORM ASSN, V3, P118, DOI 10.1136/jamia.1996.96236280
   Spitzer VM, 2015, DIGITAL PATIENT ADV, P51
   Tchiboukdjian M, 2010, IEEE T VIS COMPUT GR, V16, P815, DOI 10.1109/TVCG.2010.19
   Varadhan G, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P69, DOI 10.1109/VISUAL.2002.1183759
   Vo T., 2012, J. Graph. Tools, V16, P25, DOI DOI 10.1080/2151237X.2012.641828
   Wang C, 2014, MOSIM 2014
   Wu JH, 2003, PROC GRAPH INTERF, P185
   Yoon SE, 2005, ACM T GRAPHIC, V24, P886, DOI 10.1145/1073204.1073278
   Yoon SE, 2006, IEEE T VIS COMPUT GR, V12, P1213, DOI 10.1109/TVCG.2006.162
   Yotov K, 2007, SPAA'07: PROCEEDINGS OF THE NINETEENTH ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P93
   Zhang SX, 2006, CLIN ANAT, V19, P204, DOI 10.1002/ca.20273
   ZHANG SX, 2013, FASEB J S, V27
NR 55
TC 4
Z9 6
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25391
EP 25419
DI 10.1007/s11042-017-4607-z
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300046
DA 2024-07-18
ER

PT J
AU Fraj, O
   Ghozi, R
   Jaïdane-Saïdane, M
AF Fraj, Olfa
   Ghozi, Raja
   Jaidane-Saidane, Meriem
TI Audio texturedness indicator based on a direct and reverse short
   listening time analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio texturedness indicator; Audio textures; Short listening time;
   Direct and reverse listening; Cumulative entropy; Auditory information
   content
AB In this paper, we present an objective evaluation of audio texturedness level motivated by a subjective study which emphasizes the relevance of a direct and reverse short listening time analysis. This study was based on 77 undergraduate engineering students, where the concept of audio texturedness relied on audio and image analogies. Audio texturedness evaluation of a large audio database using a discrete [1 - 5] texturedness scale was performed. As a result, an objective audio texturedness indicator is proposed based on the cumulative average signal informational content change in the direct and reverse directions. This bidirectional cumulative entropy tracking was done in analogy with a classical multidirectional homogeneity method for image texture discrimination. As expected, the proposed indicator has ranked the class of noise on the high end of the [1 - 5] scale, whereas highly motivational speech signals ranked low on the proposed scale due to the large variations in their average informational content in the direct and reverse directions. This audio texturedness indicator offers a continuum of audio classes, in contrast with the classical noise, speech, and music sound categorization. The relevance of the proposed objective indicator auditory parameters was explored for a maximum objective-subjective cross-correlation and illustrated in a preliminary audio stream segmentation application.
C1 [Fraj, Olfa; Ghozi, Raja; Jaidane-Saidane, Meriem] Univ Tunis El Manar, Ecole Natl Ingenieurs Tunis, Signals & Syst Lab, BP37, Tunis 1002, Tunisia.
C3 Universite de Tunis-El-Manar; Ecole Nationale d'Ingenieurs de Tunis
   (ENIT)
RP Jaïdane-Saïdane, M (corresponding author), Univ Tunis El Manar, Ecole Natl Ingenieurs Tunis, Signals & Syst Lab, BP37, Tunis 1002, Tunisia.
EM olfa.fraj@enit.utm.tn; meriem.jaidane@enit.utm.tn
OI Jaidane, Meriem/0000-0002-9096-6161
FU Tunisian-French inter-disciplinary and cooperation research project
   (CMCU-PHC UTIQUE) [23242VJ]; "Center for RESearch on SONic Space and
   urban environment" at the Graduate School of Architecture of Grenoble
   [CRESSON-UMR CNRS 1563]
FX This work is a part of a Tunisian-French inter-disciplinary and
   cooperation research project (CMCU-PHC UTIQUE project 23242VJ), "Altered
   Perceptions of Urban Sound ambiances: Characterization and Correction:
   Audio Texture Contributions", between: "Unite de recherche Signaux et
   Systemes" (U2S) of the National School of Engineering of Tunis, the
   "Equipe de Recherche sur les Ambiances" (ERA) at the National School of
   Architecture of Tunis, the "Center for RESearch on SONic Space and urban
   environment" (CRESSON-UMR CNRS 1563) at the Graduate School of
   Architecture of Grenoble, the "Institut de Recherche en Sciences et
   Techniques de la Ville" (IRSTV), Nantes, and the 'CEntre de Recherche
   Methodologique d'Architecture" (CERMA, converted to CRENAU since 2015),
   at Nantes, France.
CR [Anonymous], 2013, ARXIV13110407
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], TEXTURE PHOTOGRAPHIC
   [Anonymous], 1998, HDB PATTERN RECOGNIT
   Arnaud A. S., 1998, COMPUTATIONAL AUDITO
   Bacha S, 2012, 11 INT C INF SCI SIG
   Baddeley A, 2003, NAT REV NEUROSCI, V4, P829, DOI 10.1038/nrn1201
   Bregman AS., 1994, AUDITORY SCENE ANAL
   Bromiley PA, BOUHOVA THACKER SHAN
   Dubnov S., 1999, P INT COMP MUS C BEI
   Fraj O, 2015, IEEE INT C AC SPEECH
   Fröjd M, 2009, J AUDIO ENG SOC, V57, P29
   Ghozi R., 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1531
   Ghozi R, 2006, 3 INT S VID COMM
   Ghozi R., 2010, INT SOUND ACT C WORK
   Ghozi R, 2015, J AUDIO ENG SOC, V63, P475, DOI 10.17743/jaes.2015.0057
   Greenberg S., 2001, 7th International Conference on Speech Communication Technology, Scandinavia, P473
   Heittola T, 2014, EURASIP J AUDIO SPEE, DOI 10.1186/1687-4722-2014-9
   Hurst W, 2005, P HCI2005
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Larbi S, 2010, P 38 AUD ENG SOC INT
   Lartillot O., 2008, DATA ANAL MACHINE LE
   Lie L, 2004, IEEE T SPEECH AUDI P, V12, P156, DOI 10.1109/TSA.2003.819947
   Likert R., 1932, TECHNIQUE MEASUREMEN, DOI 1933-01885-001
   Loizou P. C., 2007, Speech Enhancement: Theory and Practice
   Lu L, 2002, IEEE T AUDIO SPEECH, V10
   McDermott JH, 2013, NAT NEUROSCI, V16, P493, DOI 10.1038/nn.3347
   Mirmehdi Majid., 2009, Handbook of texture analysis
   Misra A., 2006, P 9 INT C DIG AUD EF
   Mzah Y, 2016, 60 INT C AUD ENG SOC
   Norris MJ, 2004, J ACOUST SOC AM, V115, P2613
   Robert M, 2010, MAINTAINING SONIC TE, P129
   Saberi K., 1999, NATURE, P398
   Schödl A, 2000, COMP GRAPH, P489, DOI 10.1145/344779.345012
   Schwarz D., 2011, P INT C DIG AUD EFF
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Sundaram H., 2000, IEEE INT C AC SPEECH
   Tupin F, 2000, IEEE C IM PROC
   Van Nort D, 2012, J ACOUST SOC AM, V132, P2734, DOI 10.1121/1.4751535
NR 39
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26177
EP 26200
DI 10.1007/s11042-016-4031-9
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500031
DA 2024-07-18
ER

PT J
AU Hu, HM
   Fang, W
   Zeng, GD
   Hu, ZH
   Li, B
AF Hu, Hai-Miao
   Fang, Wen
   Zeng, Guodong
   Hu, Zihao
   Li, Bo
TI A person re-identification algorithm based on pyramid color topology
   feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Person re-identification; Spatial structure; Video surveillance; Pyramid
   color topology
ID CLASSIFICATION
AB Due to illumination variations, person re-identification algorithms based on color features are not robust in practical applications. Different persons may have similar statistical distribution in terms of color histogram, while same person may have different statistical distributions. On the other hand, the color spatial distribution can remain stable, even for illumination variations. In our previous work, a new feature, namely the weighted color topology (WCT), is proposed to describe the color spatial distribution. However, since WCT is extracted on a single scale of region-division, it only represents part of color spatial distribution information. In this paper, a pyramid color topology (PCT) is proposed to extract WCTs on different scales of region-division. PCT can achieve a full description of multi-scales topology information. Based on PCT, a person re-identification algorithm is implemented. The experimental results demonstrate that the proposed algorithm can improve the recognition performance compared with both WCT and the state-of-the-art algorithms.
C1 [Hu, Hai-Miao; Fang, Wen; Zeng, Guodong; Hu, Zihao; Li, Bo] Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Hu, Hai-Miao] Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Technol, Xueyuan Rd 37, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Hu, HM (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.; Hu, HM (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Technol, Xueyuan Rd 37, Beijing 100191, Peoples R China.
EM frank0139@163.com
RI Li, Bo/AAA-8968-2020; Zeng, Guodong/U-1292-2019; Li, bo/IWL-9318-2023
OI Li, Bo/0000-0002-7294-6888; 
FU National Key Research and Development Program [2016YFC0801003]; National
   Natural Science Foundation of China [61370121, 61421003]
FX This work was partially supported by the National Key Research and
   Development Program (Grant No. 2016YFC0801003), and the National Natural
   Science Foundation of China (No. No. 61370121, 61421003).
CR An L, 2016, NEUROCOMPUTING, V182, P247, DOI 10.1016/j.neucom.2015.12.029
   [Anonymous], 2007, 10 INT WORKSH PERF E
   [Anonymous], P BMVC
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2008, WORKSH MULT MULT SEN
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE INT C IM PROC I
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bazzani L, 2014, ADV COMPUT VIS PATT, P43, DOI 10.1007/978-1-4471-6296-4_3
   Bazzani L, 2013, COMPUT VIS IMAGE UND, V117, P130, DOI 10.1016/j.cviu.2012.10.008
   Bazzani L, 2012, PATTERN RECOGN LETT, V33, P898, DOI 10.1016/j.patrec.2011.11.016
   Bedagkar-Gala A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1721, DOI 10.1109/ICCVW.2011.6130457
   Cai Y, 2011, LECT NOTES COMPUT SC, V6468, P205
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ess A, 2007, IEEE C COMPUT VIS IC, P1
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   García J, 2016, J VIS COMMUN IMAGE R, V38, P115, DOI 10.1016/j.jvcir.2016.02.009
   Geng YB, 2015, J VIS COMMUN IMAGE R, V29, P89, DOI 10.1016/j.jvcir.2015.02.001
   Hu M, 2004, INT C PATT RECOG, P724, DOI 10.1109/ICPR.2004.1334361
   Jeong K, 2008, MACH VISION APPL, V19, P443, DOI 10.1007/s00138-007-0079-x
   Jiang F, 2016, NEUROCOMPUTING, V175, P146, DOI 10.1016/j.neucom.2015.10.044
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leng QM, 2015, MULTIMED TOOLS APPL, V74, P6989, DOI 10.1007/s11042-014-1949-7
   Li W, 2016, J VIS COMMUN IMAGE R, V40, P67, DOI 10.1016/j.jvcir.2016.06.009
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin Y, 2016, NEUROCOMPUTING, V217, P19, DOI 10.1016/j.neucom.2016.04.060
   Liu H, 2015, IEEE SIGNAL PROC LET, V22, P910, DOI 10.1109/LSP.2014.2377204
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu HC, 2012, IEEE T CIRC SYST VID, V22, P1365, DOI 10.1109/TCSVT.2012.2201794
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma LY, 2011, IEEE IMAGE PROC, P1441, DOI 10.1109/ICIP.2011.6115774
   Martinel N, 2015, IEEE SIGNAL PROC LET, V22, P455, DOI 10.1109/LSP.2014.2362573
   Ming Z, 2009, 2009 IEEE YOUTH CONFERENCE ON INFORMATION, COMPUTING AND TELECOMMUNICATION, PROCEEDINGS, P90, DOI 10.1109/YCICT.2009.5382421
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Ren ZX, 2014, IEEE T CIRC SYST VID, V24, P769, DOI 10.1109/TCSVT.2013.2280096
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Yang H, 2016, NEUROCOMPUTING, V212, P65, DOI 10.1016/j.neucom.2016.03.096
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang Y, 2014, LECT NOTES COMPUT SC, V8689, P536, DOI 10.1007/978-3-319-10590-1_35
   Zhang Y, 2014, IEEE T IMAGE PROCESS, V23, P4112, DOI 10.1109/TIP.2014.2344296
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
NR 42
TC 10
Z9 11
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26633
EP 26646
DI 10.1007/s11042-016-4188-2
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500049
DA 2024-07-18
ER

PT J
AU Kim, TK
   Kwon, JH
   Kim, EJ
AF Kim, Tae-Kook
   Kwon, Jung-Hyok
   Kim, Eui-Jik
TI Categorization-based video streaming for traffic mitigation in content
   delivery services
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content categorization; Content delivery service; Periodic time
   interval; Traffic mitigation; YouTube
AB This paper presents a categorization-based video streaming approach (CVS) to mitigate the Internet traffic in content delivery services. The CVS uses the statistical information related to the users' view patterns (i.e., the average view duration in accordance with the playback time of the content) to adjust the request period of content chunks. Therefore, it can reduce the amount of Internet traffic by reducing unnecessary chunk requests and content chunks. The operation of the CVS is based on the average view duration provided by the content provider (CP). However, even if the CP does not provide the average view duration of the content, the CVS can properly predict the average view duration by using the content categorization and adjust the request period of content chunks. The simulation results show that the CVS achieves better performance in terms of the average waste ratio of network resources, the amount of network traffic, and the number of chunk requests.
C1 [Kim, Tae-Kook] Tongmyong Univ, Dept Informat & Commun Engn, 428 Sinseon Ro, Busan 48520, South Korea.
   [Kwon, Jung-Hyok; Kim, Eui-Jik] Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
C3 Tongmyong University; Hallym University
RP Kim, EJ (corresponding author), Hallym Univ, Dept Convergence Software, 1 Hallymdaehak Gil, Chuncheon Si 24252, Gangwon Do, South Korea.
EM ejkim32@hallym.ac.kr
FU Leading Human Resource Training Program of Regional Neo Industry through
   the National Research Foundation of Korea (NRF) - Ministry of Science,
   ICT and Future Planning [2016H1D5A1910427]; NRF (National Research
   Foundation of Korea) - Korean Government [2016H1A2A1908620]
FX This research was supported by the Leading Human Resource Training
   Program of Regional Neo Industry through the National Research
   Foundation of Korea (NRF) funded by the Ministry of Science, ICT and
   Future Planning (2016H1D5A1910427). This work was also supported by NRF
   (National Research Foundation of Korea) Grant funded by the Korean
   Government (NRF-2016-Fostering Core Leaders of the Future Basic Science
   Program/Global Ph.D. Fellowship Program) (2016H1A2A1908620).
CR [Anonymous], 2014, Cisco Visual Networking Index: Forecast and Methodology, 2013 - 2018
   Biernacki A, 2014, MULTIMED TOOLS APPL, V72, P1143, DOI 10.1007/s11042-013-1424-x
   Che XH, 2015, IEEE MULTIMEDIA, V22, P56, DOI 10.1109/MMUL.2015.34
   Chen LB, 2017, J SUPERCOMPUT, V73, P3547, DOI 10.1007/s11227-016-1649-3
   Forouzan BA, 2010, TCP IP PROTOCOL SUIT, P728
   Kim T, 2016, MULTIMED TOOLS APPL, V75, P12693, DOI 10.1007/s11042-015-3077-4
   Kim T, 2015, MULTIMED TOOLS APPL, V74, P1697, DOI 10.1007/s11042-014-2215-8
   Kurose J, 2013, COMPUTER NETWORKING, P593
   Ma KJ, 2011, IEEE COMMUN MAG, V49, P166, DOI 10.1109/MCOM.2011.5741161
   Mathew V, 2012, IEEE INFOCOM SER, P954, DOI 10.1109/INFCOM.2012.6195846
   Yu HF, 2015, MULTIMED TOOLS APPL, V74, P5811, DOI 10.1007/s11042-014-1889-2
   Zhao DF, 2016, IEEE T SERV COMPUT, V9, P96, DOI 10.1109/TSC.2015.2456889
   Zhou L, 2016, ACM T MULTIM COMPUT, V12, DOI 10.1145/2886776
   Zhou L, 2013, IEEE T MULTIMEDIA, V15, P946, DOI 10.1109/TMM.2013.2237895
   Zhou WA, 2016, INT J COMMUN NETW DI, V16, P197
NR 15
TC 1
Z9 2
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25495
EP 25510
DI 10.1007/s11042-017-4770-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300050
DA 2024-07-18
ER

PT J
AU Liu, TS
   Jiang, HX
   Li, HY
   Li, B
   Duan, MY
AF Liu, Tingshan
   Jiang, Hongxu
   Li, Huiyong
   Li, Bo
   Duan, Miyi
TI Efficient PCIe transmission for Multi-Channel video using dynamic
   splicing and conditional prefetching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-channel video; PCIe transmission; Dynamic splicing; Conditional
   prefetching
ID ACQUISITION; EXPRESS
AB PCI Express (PCIe) interface has been extensively used in high-speed digital systems for multimedia communication. With the migration of the video processing algorithms from host to embedded hardware, multi-channel video capturing systems will produce not only different channels of raw video data but also different types of auxiliary data, such as analyzed data and compressed stream. In order to display multi-channel video in real-time and explore the auxiliary data, conventional transmission strategies are no longer applicable, due to the fact that heterogeneous data will cause frequent interactions and lead to the waste of PCIe bandwidth. In this paper, an efficient PCIe transmission method for multi-channel video is presented. Firstly, for the transmission of multi-type video data, a dynamic splicing mechanism is proposed to combine the video analyzed data and the compressed stream with the raw video to avoid the individual transmission of the auxiliary data. Secondly, as the spliced data are from different channels, a conditional prefetching mechanism is employed to determine whether there exists any entire video frame in other channel buffers, so that multi-channel video data can be transmitted possibly at one time. Finally, in the host-side driver, direct kernel buffer access technique is used to improve the application I/O request packet (IRP) performance. And to ensure the transmission efficiency of the conditional prefetching, DMA circular queue buffer and timer self-feedback monitor techniques are designed to avoid the possible visit bursts and abnormal interruptions. Experimental results demonstrate that compared with the conventional methods, the proposed method reduces the interrupt interactions by 60%, increases the transmission channel number by 94%, and also increases the application IRP number by 54%. The peak transmission speed of PCIe is up to 155 MB/s, which can meet 7 channels 704 x 576 YUV raw video and its auxiliary data transmission requirements using one 1-lane PCIe endpoint.
C1 [Liu, Tingshan; Jiang, Hongxu; Li, Huiyong; Li, Bo; Duan, Miyi] Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Jiang, HX (corresponding author), Beihang Univ, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM jianghx@buaa.edu.cn
RI Jiang, Hongxu/GRY-0379-2022; Li, Bo/AAA-8968-2020; Li, bo/IWL-9318-2023
OI Li, Bo/0000-0002-7294-6888; 
FU National Key Research and Development Program of China [2016YFC0801003];
   NSFC [61272347]
FX This work was partially supported by the National Key Research and
   Development Program of China (Grant No. 2016YFC0801003) and the NSFC
   (No. 61272347).
CR Antony A, 2017, MULTIMED TOOLS APPL, V76, P1639, DOI 10.1007/s11042-015-3138-8
   Bahri N, 2017, J SIGNAL PROCESS SYS, V86, P67, DOI 10.1007/s11265-015-1098-x
   Berg R, 2018, J REAL-TIME IMAGE PR, V14, P341, DOI 10.1007/s11554-014-0457-3
   Bittner R., 2009, ACM SIGDA INT S FIEL, P273
   Bittner R, 2014, CLUSTER COMPUT, V17, P339, DOI 10.1007/s10586-013-0280-9
   Caselle M, 2013, IEEE T NUCL SCI, V60, P3669, DOI 10.1109/TNS.2013.2252528
   Cucchiara R, 2003, MULTIMED TOOLS APPL, V20, P159, DOI 10.1023/A:1023687722225
   Greisen P, 2011, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2011-18
   Han L, 2014, 2014 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P95, DOI 10.1109/SPAC.2014.6982664
   Huang Z-W, 2012, IEEE 6 INT S ADV OPT
   Kavianipour H, 2014, IEEE T NUCL SCI, V61, P745, DOI 10.1109/TNS.2014.2304691
   Kuan Jen Lin, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P255, DOI 10.1109/ISCE.2009.5157006
   Li B, 2009, J ELECT SCI TECH CHI, DOI [10.1109/CAS-ICTD.2009.4960747, DOI 10.1109/CAS-ICTD.2009.4960747]
   Liu C, 2011, C IND ELECT APPL, P2231, DOI 10.1109/ICIEA.2011.5975961
   Makowski D, 2015, IEEE T NUCL SCI, V62, P925, DOI 10.1109/TNS.2015.2415582
   Marcus G., 2011, Proceedings of the 2011 VII Southern Conference on Programmable Logic (SPL), P155, DOI 10.1109/SPL.2011.5782641
   Mielczarek A, 2013, MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, MIXDES 2013, P137
   Minami S, 2011, IEEE T NUCL SCI, V58, P1816, DOI 10.1109/TNS.2011.2159808
   Rota L, 2015, IEEE T NUCL SCI, V62, P972, DOI 10.1109/TNS.2015.2426877
   Sahlbach H, 2017, J REAL-TIME IMAGE PR, V13, P291, DOI 10.1007/s11554-014-0403-4
   Santos J, 2011, IEEE T NUCL SCI, V58, P1751, DOI 10.1109/TNS.2011.2143428
   Sun SM, 2016, MULTIMED TOOLS APPL, V75, P8019, DOI 10.1007/s11042-015-2721-3
   Texas Instruments, 2010, TMS320C6678 TEX INST
   Thoma Y, 2015, MICROPROCESS MICROSY, V39, P565, DOI 10.1016/j.micpro.2015.02.005
   Tsao SL, 2012, J INF SCI ENG, V28, P537
   Wang S-M, 2014, IEEE 20 INT S HIGH P
   Yoon H, 2015, WIRELESS PERS COMMUN, V82, P1225, DOI 10.1007/s11277-015-2277-6
   Zhuang JC, 2011, IEEE T CIRCUITS-II, V58, P289, DOI 10.1109/TCSII.2011.2124870
NR 28
TC 0
Z9 1
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 23
BP 25057
EP 25078
DI 10.1007/s11042-017-4410-x
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FO1TQ
UT WOS:000416548300027
DA 2024-07-18
ER

PT J
AU Wang, HZ
   Wang, XD
AF Wang, Hanzhang
   Wang, Xiaodong
TI Important macroblock distinction model for multi-view plus depth video
   transmission over error-prone network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transmission distortion; Virtual view synthesis distortion;
   Free-viewpoint video; Network congestion
ID WIRELESS NETWORKS; RESOURCE-ALLOCATION; BIT ALLOCATION; DISTORTION;
   TEXTURE; H.264/AVC; MAPS
AB Multi-view plus depth (MVD) video is an efficient three dimensional (3D) video representation format that allows the sender only transmit two pairs of texture and depth videos, arbitrary virtual view can be synthesized at the receiver. However, constrained by the limited-bandwidth, inevitable packet loss will induce transmission distortion, which will propagate to virtual views thereby affects user's stereoscopic perception. In order to relieve the virtual view's quality degradation induced by packet loss, an important macroblock (MB) distinction model for both texture and depth videos is proposed. MBs with low important level will be actively discarded once congestion occurs. The model includes two main parts: Firstly, by considering temporal and spatial correlation of the coding structure and the distortion diffusion due to lost packets, a transmission distortion model is proposed. Secondly, a gradient based synthesis distortion model is adopted to analyze the distortion induced by depth-error. Finally, a low-complexity important MB distinction model is proposed for MVD video transmission. Experiment results show that, compared with random packet loss condition, Peak Signal-to-Noise Ratio (PSNR) of the virtual view increase by up to 15.65 dB at 20% packet loss rate, both objective and subjective quality of the virtual view are close to error-free transmission.
C1 [Wang, Hanzhang] Tongji Univ, Coll Elect & Informat Engn, Shanghai, Peoples R China.
   [Wang, Hanzhang; Wang, Xiaodong] Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
C3 Tongji University; Ningbo University
RP Wang, HZ (corresponding author), Tongji Univ, Coll Elect & Informat Engn, Shanghai, Peoples R China.; Wang, HZ (corresponding author), Ningbo Univ, Fac Informat Sci & Engn, Ningbo, Zhejiang, Peoples R China.
EM hanzhang.mon.wang@gmail.com; xiaodongwang@nbu.edu.cn
RI wang, xiao/HGB-7081-2022; wang, xiao/HZI-9156-2023
OI wang, xiao/0000-0002-4088-3341; 
CR Alajel KM, 2012, IEEE T CONSUM ELECTR, V58, P731, DOI 10.1109/TCE.2012.6311311
   Chen ZF, 2012, IEEE T CIRC SYST VID, V22, P636, DOI 10.1109/TCSVT.2011.2171262
   Fang L, 2014, IEEE T IMAGE PROCESS, V23, P185, DOI 10.1109/TIP.2013.2287608
   Gao P, 2014, IEEE T MULTIMEDIA, V16, P1797, DOI 10.1109/TMM.2014.2331013
   Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136
   ISO/IEC MPEG ITU-T VCEG, 2012, JOINT MULT VIEW VID
   Kim WS, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2447737
   Lambert P, 2006, J VIS COMMUN IMAGE R, V17, P358, DOI 10.1016/j.jvcir.2005.05.008
   Li F, 2010, IET COMMUN, V4, P1012, DOI 10.1049/iet-com.2009.0618
   Li F, 2015, MULTIMED TOOLS APPL, V74, P10259, DOI 10.1007/s11042-014-2163-3
   Liu QW, 2006, IEEE T VEH TECHNOL, V55, P839, DOI 10.1109/TVT.2006.873832
   Liu Y, 2013, ADV MATH PHYS, V2013, DOI 10.1155/2013/787891
   Loghman M, 2015, MULTIMED TOOLS APPL, V74, P1611, DOI 10.1007/s11042-013-1747-7
   Luo L, 2013, IEEE T CONSUM ELECTR, V59, P657, DOI 10.1109/TCE.2013.6626253
   Macchiavello B, 2014, IEEE T MULTIMEDIA, V16, P711, DOI 10.1109/TMM.2014.2299768
   Merkle P, 2007, IEEE IMAGE PROC, P201
   Moving Picture Experts Group Geneva, 2009, TECH REP
   Oh BT, 2011, IEEE J-STSP, V5, P1344, DOI 10.1109/JSTSP.2011.2164893
   Pahalawatta P, 2007, IEEE J SEL AREA COMM, V25, P749, DOI 10.1109/JSAC.2007.070511
   Shen C, 2008, IEEE T WIREL COMMUN, V7, P3546, DOI 10.1109/TWC.2008.070337
   Stockhammer T, 2004, IEEE IMAGE PROC, P545
   Wang X., 2014, J APPL MATH, V2014, P9, DOI DOI 10.1155/2014/681364
   Wu J, 2013, MULTIMED TOOLS APPL, V74, P4117
   Xiao JM, 2015, IEEE T CIRC SYST VID, V25, P139, DOI 10.1109/TCSVT.2014.2334011
   Xu LF, 2015, IEEE SIGNAL PROC LET, V22, P131, DOI 10.1109/LSP.2014.2350028
   Yang H, 2010, IEEE T IMAGE PROCESS, V19, P108, DOI 10.1109/TIP.2009.2032895
   Yuan H, 2014, IEEE T CIRC SYST VID, V24, P443, DOI 10.1109/TCSVT.2013.2280071
   Yuan H, 2011, IEEE T CIRC SYST VID, V21, P485, DOI 10.1109/TCSVT.2011.2125610
   Zhang C, 2009, 2009 I E INT WORKSH, V278, P287
   Zhang R, 2000, IEEE J SEL AREA COMM, V18, P966, DOI 10.1109/49.848250
   Zhang T., 2012, P IEEE VIS COMM IM P, P1, DOI DOI 10.1109/VCIP.2012.6410848
   Zhou Y.F., 2012, INN MONG TRADIT CHIN, V31, P1
   Zhou Y, 2015, IEEE SENS J, V15, P1892, DOI 10.1109/JSEN.2014.2366511
   Zhou Y, 2011, IEEE T CIRC SYST VID, V21, P1679, DOI 10.1109/TCSVT.2011.2133390
NR 34
TC 2
Z9 2
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2017
VL 76
IS 24
BP 26745
EP 26767
DI 10.1007/s11042-016-4204-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FP5BQ
UT WOS:000417633500054
DA 2024-07-18
ER

PT J
AU Chaabouni, S
   Benois-Pineau, J
   Tison, F
   Ben Amar, C
   Zemmari, A
AF Chaabouni, Souad
   Benois-Pineau, Jenny
   Tison, Francois
   Ben Amar, Chokri
   Zemmari, Akka
TI Prediction of visual attention with deep CNN on artificially degraded
   videos for studies of attention of patients with Dementia
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep CNN; Saliency; Normal video; Degraded video; Dementia diseases
ID POPULATIONS
AB Studies of visual attention of patients with Dementia such as Parkinson's Disease Dementia and Alzheimer Disease is a promising way for non-invasive diagnostics. Past research showed, that people suffering from dementia are not reactive with regard to degradations on still images. Attempts are being made to study their visual attention relatively to the video content. Here the delays in their reactions on novelty and "unusual" novelty of the visual scene are expected. Nevertheless, large-scale screening of population is possible only if sufficiently robust automatic prediction models can be built. In the medical protocols the detection of Dementia behavior in visual content observation is always performed in comparison with healthy, "normal control" subjects. Hence, it is a research question per see as to develop an automatic prediction models for specific visual content to use in psycho-visual experience involving Patients with Dementia (PwD). The difficulty of such a prediction resides in a very small amount of training data. In this paper the reaction of healthy normal control subjects on degraded areas in videos was studied. Furthermore, in order to build an automatic prediction model for salient areas in intentionally degraded videos for PwD studies, a deep learning architecture was designed. Optimal transfer learning strategy for training the model in case of very small amount of training data was deployed. The comparison with gaze fixation maps and classical visual attention prediction models was performed. Results are interesting regarding the reaction of normal control subjects against degraded areas in videos.
C1 [Chaabouni, Souad; Benois-Pineau, Jenny; Zemmari, Akka] Univ Bordeaux, LaBRI UMR 5800, F-33400 Talence, France.
   [Chaabouni, Souad; Ben Amar, Chokri] Univ Sfax, REGIM Lab LR11ES48, Sfax 3029, Tunisia.
   [Tison, Francois] CHU Bordeaux GH Pellegrin, Bordeaux, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS); Universite de Sfax; CHU Bordeaux
RP Chaabouni, S (corresponding author), Univ Bordeaux, LaBRI UMR 5800, F-33400 Talence, France.; Chaabouni, S (corresponding author), Univ Sfax, REGIM Lab LR11ES48, Sfax 3029, Tunisia.
EM souad.chaabouni@u-bordeaux.fr; benois-p@labri.fr;
   francois.tison@chu-bordeaux.fr; chokri.benamar@ieee.org;
   zemmari@labri.fr
RI Chokri, BEN AMAR/K-5237-2012; Benois-Pineau, Jenny/ABG-6325-2020
OI Benois-Pineau, Jenny/0000-0003-0659-8894; ZEMMARI,
   Akka/0000-0002-9776-0449
FU University of Bordeaux; University of Sfax; grant UNetBA
FX This research has been supported by University of Bordeaux, University
   of Sfax and the grant UNetBA.
CR [Anonymous], ARXIV160408010
   [Anonymous], YEUX ONT ANOMALIES S
   [Anonymous], BEHAV RES METHODS
   [Anonymous], 2014, WORKSHOP INT C LEARN
   [Anonymous], ARCH NEUROL
   [Anonymous], PLOS ONE
   [Anonymous], 2013, EVALUATION PLAN ALZH
   [Anonymous], 2020, INT TELECOMMUNICATIO
   [Anonymous], BRAIN J NEUROLOGIE
   [Anonymous], ARXIV14111045 CORR
   [Anonymous], ARXIV150701422 CORR
   [Anonymous], THESIS
   [Anonymous], P SPIE
   [Anonymous], CONV NEUR NETW VIS R
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Boujut H, 2012, LECT NOTES COMPUT SC, V7585, P436, DOI 10.1007/978-3-642-33885-4_44
   Chaabouni S., 2016, 2016 IEEE INT C IM P, V91
   Chaabouni S., 2016, 2016 14 INT WORKSH C, V91, P1
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Kruthiventi SSS, 2016, PROC CVPR IEEE, P5781, DOI 10.1109/CVPR.2016.623
   Long Mai, 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P91, DOI 10.1109/ISM.2011.23
   Lu Y, 2010, NEUROSCI LETT, V480, P69, DOI 10.1016/j.neulet.2010.06.006
   Marszalek M., 2009, IEEE C COMP VIS PATT
   Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154
   Pinto Y, 2013, J VISION, V13, DOI 10.1167/13.3.16
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shen CY, 2014, NEUROCOMPUTING, V138, P61, DOI 10.1016/j.neucom.2013.09.053
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Tseng PH, 2013, J NEUROL, V260, P275, DOI 10.1007/s00415-012-6631-2
   Vig E., 2014, IEEE COMPUTER VISION
   Wooding DS, 2002, BEHAV RES METH INS C, V34, P518, DOI 10.3758/BF03195481
   Yosinski J, 2014, ADV NEUR IN, V27
NR 33
TC 10
Z9 10
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22527
EP 22546
DI 10.1007/s11042-017-4796-5
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200033
DA 2024-07-18
ER

PT J
AU De Marsico, M
   Nappi, M
   Riccio, D
   Wechsler, H
AF De Marsico, Maria
   Nappi, Michele
   Riccio, Daniel
   Wechsler, Harry
TI Leveraging implicit demographic information for face recognition using a
   multi-expert system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometric systems; Demographics; Face recognition; Interoperability;
   Soft biometrics; A-posteriori demographics categorization
ID BIAS; FEATURES; GENDER
AB This paper describes a novel biometric architecture to implement unsupervised face recognition across varying demographics. The present proposal deals with ethnicity, gender and age, but the same strategy can be crafted for any mix of soft/hard biometrics, sensors, and/or methods. Our aim is not to explicitly distinguish demographic features of a subject (e.g., male vs. female). We rather aim at implicitly exploiting such information to improve the accuracy of subject identification. The role demographics plays in authentication has been reported by many recent studies. Exploiting demographic information can entail two possible strategies. Both require pre-determination of relevant demographic classes, that drive the choice of the best suited recognizer in a set of ad-hoc trained ones. In the first strategy, a human operator visually classifies demographic features of the subject to recognize, and runs the appropriate "strong" recognizer. In the second one, the identification of the most appropriate "strong" recognizer follows the results obtained from a set of upstream classifiers for soft biometrics. Both solutions are poorly suited to most real world applications, e.g., video - surveillance. Our architecture mediates recognition across different demographics without any pre-determination of demographic features. We still have different "strong" classifiers, each trained on a demographic class. The probe is submitted to all of them at once. A supervisor module estimates reliability of the single responses, and the most reliable result is returned. In this approach, classifier reliability is not a static feature, but it is estimated for each probe. The proposed multiple-expert system provides similar performance to pre-determination of demographics. Experimental results show higher flexibility, efficacy and interoperability. We also focus on interoperability across face datasets by adopting EGA (Ethnicity, Gender and Age) database as a benchmark, which is obtained by combining images from several publicly available face datasets.
C1 [De Marsico, Maria] Sapienza Univ Rome, Rome, Italy.
   [Nappi, Michele] Univ Salerno, Comp Sci, Salerno, Italy.
   [Riccio, Daniel] Univ Naples Federico II, Naples, Italy.
   [Wechsler, Harry] George Mason Univ, Comp Sci, Fairfax, VA 22030 USA.
C3 Sapienza University Rome; University of Salerno; University of Naples
   Federico II; George Mason University
RP De Marsico, M (corresponding author), Sapienza Univ Rome, Rome, Italy.
EM demarsico@di.uniroma1.it
RI Riccio, Daniel/JGM-4522-2023; Nappi, Michele/X-3089-2019; De Marsico,
   Maria/K-6684-2015
OI De Marsico, Maria/0000-0002-1391-8502; Riccio,
   Daniel/0000-0002-5844-0602
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 1892, Finger Prints
   [Anonymous], ARXIV12041611
   [Anonymous], P IEEE INT WORKSH AN
   [Anonymous], FACE RECOGNITION SOM
   [Anonymous], THE ESSEX DATABASE
   [Anonymous], P 2012 IEEE WORKSH B
   [Anonymous], 2013, ICB, DOI DOI 10.1109/ICB.2013.6613022
   [Anonymous], P IEEE C COMP VIS PA
   Branson S, 2014, INT J COMPUT VISION, V108, P3, DOI 10.1007/s11263-014-0698-4
   Bruyer R, 2004, PERCEPTION, V33, P169, DOI 10.1068/p5094
   Burton AM, 2011, BRIT J PSYCHOL, V102, P943, DOI 10.1111/j.2044-8295.2011.02039.x
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   CHIRORO P, 1995, Q J EXP PSYCHOL-A, V48, P879, DOI 10.1080/14640749508401421
   Cole S.A., 2004, DNA and the Criminal Justice System: The Technology ofJustice, P63
   De Marsico M, 2011, IEEE T SYST MAN CY C, V41, P481, DOI 10.1109/TSMCC.2010.2060326
   El Khiyari H., 2012, Biometric Measurements and Systems for Security and Medical Applications (BIOMS), 2012 IEEE Workshop on, P1
   GOLDSTEIN AG, 1979, B PSYCHONOMIC SOC, V13, P191, DOI 10.3758/BF03335056
   GOLDSTEIN AG, 1979, B PSYCHONOMIC SOC, V13, P187, DOI 10.3758/BF03335055
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Haibin Ling, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Hancock PJB, 2000, TRENDS COGN SCI, V4, P330, DOI 10.1016/S1364-6613(00)01519-9
   Herlitz A, 2013, VIS COGN, V21, P1306, DOI 10.1080/13506285.2013.823140
   Hosoi S, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P195, DOI 10.1109/AFGR.2004.1301530
   Huang G.B., 2008, PROC WORKSHOP FACES
   Jain V., 2002, The Indian Face Database
   Kasinski A., 2008, Image Processing and Communications, V13, P59
   Klare BF, 2012, IEEE T INF FOREN SEC, V7, P1789, DOI 10.1109/TIFS.2012.2214212
   Leng L, 2011, LECT NOTES COMPUT SC, V6786, P458, DOI 10.1007/978-3-642-21934-4_37
   Leng L, 2010, INT J PHYS SCI, V5, P2543
   Lu Leng, 2010, 2010 International Conference on Information and Communication Technology Convergence (ICTC), P467, DOI 10.1109/ICTC.2010.5674791
   Lu XG, 2004, P SOC PHOTO-OPT INS, V5404, P114, DOI 10.1117/12.542847
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   McGarry DP, 2004, P SOC PHOTO-OPT INS, V5404, P362, DOI 10.1117/12.543054
   Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8
   Modi SK, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P19, DOI 10.1109/AUTOID.2007.380586
   NG WJ, 1994, J CROSS CULT PSYCHOL, V25, P217, DOI 10.1177/0022022194252004
   O'Toole AJ, 2007, IEEE T PATTERN ANAL, V29, P1642, DOI 10.1109/TPAMI.2007.1107
   O'Toole AJ, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2355598.2355599
   Phillips P. Jonathon, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P346, DOI 10.1109/FG.2011.5771424
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rhodes MG, 2012, PSYCHOL BULL, V138, P146, DOI 10.1037/a0025750
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Ross A, 2004, LECT NOTES COMPUT SC, V3087, P134
   Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124
   Sun Y, 2014, ADV NEUR IN, V27
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Toderici G, 2010, INT J COMPUT VISION, V89, P382, DOI 10.1007/s11263-009-0300-7
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Vasuhi S, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING SYSTEMS, P718, DOI 10.1109/ICSPS.2009.158
   Veropoulos K, 2005, LECT NOTES COMPUT SC, V3804, P207
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 54
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 22
BP 23383
EP 23411
DI 10.1007/s11042-016-4085-8
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FK9OW
UT WOS:000413841700012
DA 2024-07-18
ER

PT J
AU Ngo, QT
   Abu, LM
   Pham, XQ
   Lee, S
   Huh, EN
AF Quang Thai Ngo
   Abu, Layek Md.
   Xuan Qui Pham
   Lee, Seungkyu
   Eui-Nam Huh
TI A remote display QoE improvement scheme for interactive applications in
   low network bandwidth environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Desktop as a service; Screen content encoding; Adaptive quality setting;
   Image quality refinement; File size inference; Quality of experience
AB Screen transmission is an essential part of Desktop as a Service (DaaS) which directly influence the quality of experience (QoE). In this paper, we propose a novel QoE improvement scheme that dynamically controls the quality setting of the image compression before the screen transmission to decrease response time of the system still maintaining the satisfactory image quality, hence improves the QoE in interactive applications in a band-limited environment. The proposed scheme first selects the best quality setting appropriate for current network bandwidth quota, then uses the remaining bandwidth to improve the quality setting of low motion regions without any adverse effect on response time. To enable the adaptive quality selection and image quality refinement, we propose a compressed image file size inference model and a block priority calculation method respectively. Particularly, we implement our QoE Improvement Scheme to work with screen content coding. Both quantitative measurements and users' evaluations in the experiments show that our QoE improvement scheme improves QoS as well as QoE by utilizing the available network bandwidth efficiently.
C1 [Quang Thai Ngo; Abu, Layek Md.; Xuan Qui Pham; Lee, Seungkyu; Eui-Nam Huh] Kyung Hee Univ, Dept Comp Sci & Engn, Global Campus, Yongin, South Korea.
C3 Kyung Hee University
RP Huh, EN (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Global Campus, Yongin, South Korea.
EM quangthaiptit@gmail.com; layek@khu.ac.kr; pxuanqui@khu.ac.kr;
   seungkyu@khu.ac.kr; johnhuh@khu.ac.kr
RI Pham, Xuan-Qui/ADY-1178-2022
OI Pham, Xuan-Qui/0000-0003-3684-2923
FU MSIP(Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC(Information Technology Research Center) support program
   [IITP-2017-2013-0-00717]; National Research Foundation of Korea
   [21A20131612192] Funding Source: Korea Institute of Science & Technology
   Information (KISTI), National Science & Technology Information Service
   (NTIS)
FX This research was supported by the MSIP(Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC(Information Technology Research
   Center) support program (IITP-2017-2013-0-00717) supervised by the
   IITP(Institute for Information & communications Technology Promotion)).
   Professor Eui-Nam Huh is the corresponding author.
CR Abu Layek M, 2016, KSII T INTERNET INF, V10, P5074, DOI 10.3837/tiis.2016.10.024
   Abu Layek M, 2016, COMPUT J, V59, P260, DOI 10.1093/comjnl/bxv116
   An N, 2014, MULTIMED TOOLS APPL, P1
   [Anonymous], 2004, Workshop on Generative Model Based Vision
   [Anonymous], 2011, IEEE COMSOC MULTIMED
   Deboosere L, 2007, 3 INT C NETW SERV IC, DOI [10.1109/ICNS.2007.115, DOI 10.1109/ICNS.2007.115]
   Fenner WC, 1995, 592260274 IETF, V59, P260
   International Telecommunications Union, 2016, H 264 ADV VID COD GE
   ITU-T Recommendation, 2014, REQ DESKT SERV
   ITU-T Recommendations, 2012, METH SUBJ ASS QUAL T, P1
   Kaplinsky KV, 2001, MODERN TECHNIQUES AND TECHNOLOGY, P155, DOI 10.1109/MTT.2001.983781
   Kaplinsky KV, 2001, VNC TIGHT ENCODER CO
   L W., 2019, J CHEM INF MODEL, V53, P1689, DOI [DOI 10.1017/CBO9781107415324, DOI 10.1017/CBO9781107415324.004, 10.1017/CBO9781107415324.004, DOI 10.1093/OXFORDHB/9780199682393.013.12]
   Lin T, 2005, IEEE T IMAGE PROCESS, V14, P993, DOI 10.1109/TIP.2005.849776
   Microsoft, 2016, MICR REM DESKT PROT
   Simoens P, 2008, ATNAC: 2008 AUSTRALASIAN TELECOMMUNICATION NETWOKS AND APPLICATIONS CONFERENCE, P391, DOI 10.1109/ATNAC.2008.4783356
   Song B, 2013, J SUPERCOMPUT, V66, P1729, DOI 10.1007/s11227-013-0972-1
   Theora, 2011, THEOR SPEC VID EV
   Tolia N, 2006, COMPUTER, V39, P46, DOI 10.1109/MC.2006.101
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang J, 2013, 2013 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM DESIGN AND ENGINEERING APPLICATIONS (ISDEA), P266, DOI 10.1109/ISDEA.2012.66
   Wikipedia, 2016, PEAK SIGN TO NOIS RA
   Zhang X.J., 2007, SYST CYBERN INF, V5, P2
NR 23
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 22217
EP 22241
DI 10.1007/s11042-017-4692-z
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200020
DA 2024-07-18
ER

PT J
AU Wei, JB
   Huang, YK
AF Wei, Jingbo
   Huang, Yukun
TI NMPE: A normalized metric for measuring generalized spatial distortion
   of multispectral panshapening fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Remote sensing; Image fusion; Pansharpen; Human vision system; Markov
   random fields
ID IMAGE FUSION; INFORMATION
AB Adaptivity is important in remote sensing image fusion because of the data-intensive and mass-driven processing platforms that call for reliable evaluation metrics to assess the runtime fusion procedure. Spatial distortion, including poor detail, visual disorder, or over-injection, has not been measured as effectively as in the spectral domain. A new metric, namely normalized mean potential energy (NMPE), is proposed in this paper to check the generalized spatial distortion of fused images by calculating the potential energy of marginal filtering distributions using information of high-order Markov random fields. NMPE is defined based on the GFoE model, which is a new high-order model that we built for remote sensing image applications. To incorporate the evaluation experience of human vision system into the GFoE model, the real zero-mean Gabor filters with multiple directions and scales are used as feature extractors, and the Gaussian scale mixture model as the expert function. The model parameters are trained from 200 images of the Berkeley segmentation dataset. Poor detail in a fused image tends to result in small NMPE evaluation with respect to small Gabor scales. Our observation shows that scale invariance exists only for "good" details, so we use large scales of Gabor functions to detect visual disorder. Over-injection is checked when the fused NMPE is much higher than 1. In the experimental procedure, satellite images from Quickbird, LandSat-7, and SPOT-5 were put to fusion with five popular methods to produce different images for visual and digital comparison. It can be concluded from the experiment that NMPE is in line with our subjective judgment to measure the pansharpening quality in terms of enhanced detail, visual distortion, and over-injection.
C1 [Wei, Jingbo] Nanchang Univ, Inst Space Sci & Technol, Nanchang, Jiangxi, Peoples R China.
   [Huang, Yukun] Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang, Jiangxi, Peoples R China.
C3 Nanchang University; Jiangxi University of Finance & Economics
RP Huang, YK (corresponding author), Jiangxi Univ Finance & Econ, Sch Informat Technol, Nanchang, Jiangxi, Peoples R China.
EM huang-yukun@163.com
RI Huang, Yukun/HMD-5040-2023
OI Wei, Jingbo/0000-0002-1621-4674
FU National Natural Science Foundation of China [41571413]; China
   Postdoctoral Science Foundation [2016M591280]; Open Research Fund of Key
   Laboratory of Digital Earth Science, Chinese Academy of Sciences
   [2015LDE004]; Special Fund for the Development Plan of the Young
   Teachers in the Ordinary Universities of Jiangxi Province
FX This work is funded by the National Natural Science Foundation of China
   (No. 41571413), the China Postdoctoral Science Foundation (No.
   2016M591280), the Open Research Fund of Key Laboratory of Digital Earth
   Science, Chinese Academy of Sciences (No. 2015LDE004), and the Special
   Fund for the Development Plan of the Young Teachers in the Ordinary
   Universities of Jiangxi Province.
CR Alparone L, 2008, PHOTOGRAMM ENG REM S, V74, P193, DOI 10.14358/PERS.74.2.193
   Alparone L, 2004, IEEE GEOSCI REMOTE S, V1, P313, DOI 10.1109/LGRS.2004.836784
   [Anonymous], 2000, PROCESS ENHANCING SP
   Chen H, 2007, INFORM FUSION, V8, P193, DOI 10.1016/j.inffus.2005.10.001
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   DERICHE R, 1990, IEEE T PATTERN ANAL, V12, P78, DOI 10.1109/34.41386
   Garzelli A, 2015, IEEE T GEOSCI REMOTE, V53, P2096, DOI 10.1109/TGRS.2014.2354471
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Han Y, 2010, INFORM FUSION, V11, P381, DOI 10.1016/j.inffus.2010.03.005
   Huang W, 2015, IEEE GEOSCI REMOTE S, V12, P1037, DOI 10.1109/LGRS.2014.2376034
   Lin WS, 2011, J VIS COMMUN IMAGE R, V22, P297, DOI 10.1016/j.jvcir.2011.01.005
   Ranchin T, 2000, PHOTOGRAMM ENG REM S, V66, P49
   Roth S, 2009, INT J COMPUT VISION, V82, P205, DOI 10.1007/s11263-008-0197-6
   Schmidt U, 2010, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2010.5539844
   Tang L, 2007, INT C WAVEL ANAL PAT, P305
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Wei JC, 2015, J NANOMATER, V2015, DOI 10.1155/2015/561742
   Wei JB, 2014, CONCURR COMP-PRACT E, V26, P1375, DOI 10.1002/cpe.3037
   Xu QZ, 2015, IEEE GEOSCI REMOTE S, V12, P28, DOI 10.1109/LGRS.2014.2324817
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Zhang Y., 2008, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, P1101
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
NR 23
TC 0
Z9 1
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2017
VL 76
IS 21
BP 23099
EP 23116
DI 10.1007/s11042-017-4518-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FJ4XX
UT WOS:000412748200062
DA 2024-07-18
ER

PT J
AU Li, JW
   Yang, F
   Lu, W
   Sun, W
AF Li, Jingwei
   Yang, Fan
   Lu, Wei
   Sun, Wei
TI Keypoint-based copy-move detection scheme by adopting MSCRs and improved
   feature matching
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Digital image forensics; Region duplication detection; Copy-move
   forgery; Maximally stable color region
ID IMAGE-ANALYSIS; FORGERY
AB Copy-move detection is to find the existence of duplicated regions in an image. In this paper, an effective method based on region features is proposed to detect copy-move forgeries, especially when the image is multiple copied or with multiple copy-move groups. Firstly, maximally stable color region detector is applied to extract features, and these features are represented by Zernike moments. Then an improved matching strategy considering n best-matching features is applied to deal with the multiple-copied problem. Moreover, a hierarchical cluster algorithm is developed to estimate transformation matrices and confirm the existence of forgery. Based on these matrices, the duplicated regions can be located at pixel level. Experimental results indicate that the proposed scheme outperforms other similar state-of-the-art techniques.
C1 [Li, Jingwei; Lu, Wei] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Yang, Fan; Sun, Wei] Sun Yat Sen Univ, Sch Elect & Informat Engn, Key Lab Informat Technol, Minist Educ, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Sun Yat Sen University
RP Lu, W (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM ljw.sysu@qq.com; yangfan6720093@foxmail.com; luwei3@mail.sysu.edu.cn;
   sunwei@mail.sysu.edu.cn
FU Natural Science Foundation of Guangdong [2016A030313350]; Special Funds
   for Science and Technology Development of Guangdong [2016KZ010103];
   Fundamental Research Funds for the Central Universities [16LGJC83];
   National Natural Science Foundation of China [U1536203, 61272409]
FX This work is supported by the Natural Science Foundation of Guangdong
   (No. 2016A030313350), the Special Funds for Science and Technology
   Development of Guangdong (No. 2016KZ010103), the Fundamental Research
   Funds for the Central Universities (No. 16LGJC83). This work is
   supported in part by the National Natural Science Foundation of China
   (Nos. U1536203 and 61272409).
CR Amerini I, 2011, IEEE T INF FOREN SEC, V6, P1099, DOI 10.1109/TIFS.2011.2129512
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chen YH, 2015, NEURAL COMPUT APPL, V26, P291, DOI 10.1007/s00521-014-1615-z
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Farid H, 2009, ADV COMPUT, V77, P1, DOI 10.1016/S0065-2458(09)01201-7
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forssen P.-E., 2007, IEEE International Conference on Computer Vision (ICCV), P1, DOI DOI 10.1109/CVPR.2007.383120
   Fridrich J., 2003, P DIG FOR RES WORKSH, V3, P652
   Ghorbani M.A., 2011, 19 IR C EL ENG, P1
   Hastie T., 2009, ELEMENTS STAT LEARNI
   Huang HL, 2008, PACIIA: 2008 PACIFIC-ASIA WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION, VOLS 1-3, PROCEEDINGS, P1241
   Huang YP, 2011, FORENSIC SCI INT, V206, P178, DOI 10.1016/j.forsciint.2010.08.001
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Pan XY, 2010, IEEE T INF FOREN SEC, V5, P857, DOI 10.1109/TIFS.2010.2078506
   Popescu A.C., 2004, Comput. Sci. Tech. Rep, P1
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Shieh CS, 2003, J INF SCI ENG, V19, P381
   Shivakumar B., 2011, Int J Comput Sci Issues (IJCSI), V8, P199
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Vedaldi A, 2007, TECH REP
   Wazirali R., 2016, J INFORM HIDING MULT, V7, P1
   Zhang ZW., 2016, J INFORM HIDING MULT, V7, P530
NR 27
TC 17
Z9 18
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 20483
EP 20497
DI 10.1007/s11042-016-3967-0
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400005
DA 2024-07-18
ER

PT J
AU Pan, H
   Shi, Y
   Wang, X
   Li, TH
AF Pan, He
   Shi, Ying
   Wang, Xin
   Li, Taihao
TI Modeling wireless sensor networks radio frequency signal loss in corn
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wireless sensor network; Signal loss; Corn field; Planting density
AB In order to arrange cornfield wireless sensor network nodes rationally, fields of corn were studied in signal loss of 2.4GHZ wireless sensor radio frequency signal, and selecting 3 levels of planting density the field random test were carried out with the transmission distance and antenna height as influencing factors, and then curve fitting and analysis were made by MATLAB simulation. Research shows that different planting density has certain influence on signal attenuation degree, when planting density, intensive plants as well as plant's scattering, reflection and diffuse will be more serious, leading to the increase of slope signal attenuation; in RF signal propagation model, environmental impact factors and antenna height exist linear relationship, establishing the mathematical model, its correlation between theory value and measurement value is in 0.937 and 0.9888.
C1 [Pan, He; Shi, Ying; Wang, Xin; Li, Taihao] Jilin Agr Univ, Informat Technol Teaching & Management Ctr, Changchun 130118, Jilin, Peoples R China.
C3 Jilin Agricultural University
RP Li, TH (corresponding author), Jilin Agr Univ, Informat Technol Teaching & Management Ctr, Changchun 130118, Jilin, Peoples R China.
EM thlee@jlau.edu.cn
FU Key Subject of the Twelfth-five Scientific Research in the Education
   Department of Jilin Province [201356]
FX Foundation item: he Key Subject of the Twelfth-five Scientific Research
   in the Education Department of Jilin Province (No.: 201356).
CR Akyildiz IF, 2002, IEEE COMMUN MAG, V40, P102, DOI 10.1109/MCOM.2002.1024422
   ANDRADESANCHEZ P, 2007, 2007 ASABE ANN INT M
   Darr MJ, 2008, 2008 ASABE ANN INT M
   Foran R. A., 1999, MILCOM 1999. IEEE Military Communications. Conference Proceedings (Cat. No.99CH36341), P336, DOI 10.1109/MILCOM.1999.822699
   HEBEL MA, 2007, 2007 ASABE ANN INT M
   Joshi GG, 2005, IEE P-MICROW ANTEN P, V152, P589, DOI 10.1049/ip-map:20050013
   Li S Y, 2009, T CSAE S2, V25, P184
   Liu Hui, 2010, Journal of Jiangsu University Natural Science Edition, V31, P1, DOI 10.3969/j.issn.1671-7775.2010.01.001
   Lu Qin, 2010, Optics and Precision Engineering, V18, P240
   Luo XW, 2000, T CHIN SOC AGR ENG, V22, P167
   Martnez-Sala A, 2005, J COMMUNICATIONS NET, V7, P1
   Meng YS, 2009, IEEE T ANTENN PROPAG, V57, P1461, DOI 10.1109/TAP.2009.2016703
   Phaebua K, 2008, ECTI-CON 2008: PROCEEDINGS OF THE 2008 5TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING/ELECTRONICS, COMPUTER, TELECOMMUNICATIONS AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P241, DOI 10.1109/ECTICON.2008.4600417
   Roos T., 2002, IEEE Transactions on Mobile Computing, V1, P59, DOI 10.1109/TMC.2002.1011059
   Shen Jie, 2008, Optics and Precision Engineering, V16, P141
   Sikka P, 2006, IPSN 2006: The Fifth International Conference on Information Processing in Sensor Networks, P492
   Wang Dai-hua, 2012, Optics and Precision Engineering, V20, P1406, DOI 10.3788/OPE.20122006.1406
   Wen Tao Wen Tao, 2010, Transactions of the Chinese Society of Agricultural Engineering, V26, P211
   [袁佐清 YUAN Zuoqing], 2007, [干旱地区农业研究, Agricultural Research in the Arid Areas], V25, P235
   Yue XueJun Yue XueJun, 2013, Nongye Jixie Xuebao = Transactions of the Chinese Society for Agricultural Machinery, V44, P213
   Zhao WY, 2013, CHINA SEED IND, V06, P12
NR 21
TC 8
Z9 8
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19479
EP 19490
DI 10.1007/s11042-015-3150-z
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500009
DA 2024-07-18
ER

PT J
AU Shin, H
   Park, JS
AF Shin, Heehoon
   Park, Joon-Sang
TI Optimizing random network coding for multimedia content distribution
   over smartphones
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia content distribution; Random network coding; Smartphone;
   Performance; Energy efficiency
ID FLOW
AB It is known that random network coding (RNC) technology helps enhance multimedia content distribution systems in various ways; however, the enhancement can vary widely depending on how the technology is realized in the systems. RNC technology entails an encoding process at the server-side and a decoding process at the clients. Typically, the decoding process is the bottleneck especially when resource-limited mobile clients such as smartphones are employed. Thus, to fully exploit the benefit of RNC technology, it is crucial to maximize throughput and minimize latency of the decoding process of RNC at the client-side. In this paper, we explore the implementation space of RNC on smartphone platforms and propose best practices that optimize RNC performance on smartphone in terms of decoding throughput (or delay) as well as energy consumption. Via experimental results, we show that our proposal for optimizing RNC achieves throughput enhancement along with energy conservation at the same time on smartphones.
C1 [Shin, Heehoon; Park, Joon-Sang] Hongik Univ, Dept Comp Engn, Wausan Ro 94, Seoul 04066, South Korea.
C3 Hongik University
RP Park, JS (corresponding author), Hongik Univ, Dept Comp Engn, Wausan Ro 94, Seoul 04066, South Korea.
EM jsp@hongik.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [NRF-2013R1A1A1A05005876]
FX This work was supported by the Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (NRF-2013R1A1A1A05005876).
CR Ahlswede R, 2000, IEEE T INFORM THEORY, V46, P1204, DOI 10.1109/18.850663
   [Anonymous], APPL MATH INFORM SCI
   [Anonymous], P 2010 ACM MULT WORK
   [Anonymous], 2003, 51 ALL C COMM CONTR
   Bisseling RH, 1989, P SHELL C PAR COMP 8
   Chen CC, 2011, J ADV RES, V2, P241, DOI 10.1016/j.jare.2011.05.002
   Choi S, 2014, INT J DISTRIB SENS N, V2014
   Chu X, 2009, J COMMUNICATIONS, P4
   Gkantsidis C, 2005, IEEE INFOCOM SER, P2235
   Ho T, 2006, IEEE T INFORM THEORY, V52, P4413, DOI 10.1109/TIT.2006.881746
   Keller L., 2012, P ACM MOBISYS LOW WO
   Kim M, 2013, J NETW COMPUT APPL, V36, P293, DOI 10.1016/j.jnca.2012.05.014
   Lee S, 2012, COMPUT J, V55, P21, DOI 10.1093/comjnl/bxq087
   Lee U, 2008, J COMMUN NETW, P10
   MAYMOUNKOV P, 2006, P 44 ANN ALL C COMM
   Melab N, 2000, J SUPERCOMPUT, P17
   Park JS, 2014, COMPUT J, V57, P233, DOI 10.1093/comjnl/bxs173
   Park K, 2010, IEEE T PARALL DISTR, V21, P1547, DOI 10.1109/TPDS.2010.40
   Plank J. S., 2013, P 11 USENIX C FIL ST, P95
   Ramasubramoniana A, 2009, P VIS COMM IM PROC
   Shojania H., 2009, P IEEE INT C DISTR C
   Shojania H, 2007, PROC 15 INT WORKSH Q
   Shojania H., 2009, P 18 INT WORKSH NETW
   Shojania H, 2009, INT CON DISTR COMP S, P490, DOI 10.1109/ICDCS.2009.68
   WANG M, 2007, P IEEE INFOCOM
   Wang M, 2007, IEEE J SEL AREA COMM, V25, P1655, DOI 10.1109/JSAC.2007.071205
   Yang X., 2009, P 8 INT WORKSH PEER
NR 27
TC 17
Z9 17
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 19
BP 19379
EP 19395
DI 10.1007/s11042-015-3089-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FF7EY
UT WOS:000409180500003
DA 2024-07-18
ER

PT J
AU Singh, P
   Raman, B
AF Singh, Priyanka
   Raman, Balasubramanian
TI A secured robust watermarking scheme based on majority voting concept
   for rightful ownership assertion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human visual system (HVS); Discrete cosine transform (DCT); Robust
   watermarking scheme
ID DOUBLE IMAGE ENCRYPTION; VISUAL-CRYPTOGRAPHY; SYSTEM
AB A novel secured robust blind watermarking scheme has been proposed in this paper. It exploits the human visual system (HVS) insensitivity to detect color changes as compared to brightness changes for embedding of watermark. The color space is converted from RGB to YCbCr and one of its components is chosen arbitrarily for hiding copyright information. The scheme is made very secured by Arnold chaotic maps and usage of multiple secret keys. Three diagonal pairs of discrete cosine transform coefficients are chosen in each sampled block of the color channel and a threshold criteria based embedding is done in each pair corresponding to a single bit of the encoded copyright information. To handle various image processing attacks and enhance robustness of the scheme, extraction of the watermark bits is done based on majority voting concept using two separate counters for representing watermark bits. The efficacy of the proposed scheme has been tested against variety of image processing and geometrical attacks and evaluated using peak signal to noise ratio (PSNR), structural similarity index matrix (SSIM) and normalized cross correlation (NCC) metrics. Comparative results based on different aspects of robust watermarking scheme is also presented to build the appropriateness of the proposed scheme over existing state of art approaches.
C1 [Singh, Priyanka; Raman, Balasubramanian] Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Singh, P (corresponding author), Indian Inst Technol Roorkee, Dept Comp Sci & Engn, Roorkee, Uttar Pradesh, India.
EM priyankiitr@iitr.ac.in; balarfma@iitr.ac.in
RI Singh, Priyanka/GRF-6098-2022; singh, priyanka/JWP-2636-2024; Singh,
   Priyanka/N-1372-2018
OI Singh, Priyanka/0000-0001-7874-7778; Singh,
   Priyanka/0000-0003-0841-1544; SINGH, PRIYANKA/0000-0001-5002-8800
FU Information Security Education and Awareness (ISEA) Project (phase II),
   DeitY, New Delhi, INDIA
FX This work was supported by Information Security Education and Awareness
   (ISEA) Project (phase II), DeitY, New Delhi, INDIA.
CR Abuturab MR, 2012, APPL OPTICS, V51
   Abuturab MR, 2012, APPL OPTICS, V51
   Abuturab MR, 2013, APPL OPTICS, V52
   Amirgholipour S, 2014, INT ARAB J INF TECHN, V11, P178
   Barni M, 1998, SIGNAL PROCESS, V66, P357, DOI 10.1016/S0165-1684(98)00015-2
   Barni M, 1998, P EUR SIGN PROC C, P1720
   Bohra A, 2009, AEU-INT J ELECTRON C, V63, P703, DOI 10.1016/j.aeue.2008.05.010
   Chang C., 2005, PATTERN RECOGN LETT, V26, P15771586
   Chen BJ, 2014, DIGIT SIGNAL PROCESS, V28, P106, DOI 10.1016/j.dsp.2014.02.010
   Chen LF, 2010, OPT COMMUN, V283, P2043, DOI 10.1016/j.optcom.2010.01.009
   Chu WC, 2003, IEEE T MULTIMEDIA, V5, P34, DOI 10.1109/TMM.2003.808816
   Consultants T, 2010, BUILD DIG EC IMP SAV
   Cox I.J., 1997, IEEE TRANS IMAGE PRO, V6
   Das C, 2014, AEU-INT J ELECTRON C, V68, P244, DOI 10.1016/j.aeue.2013.08.018
   Feng LP, 2010, INT CONF COMP SCI, P455, DOI 10.1109/ICCSIT.2010.5565101
   Gangyi J, 2002, 6 INT C SIGN PROC, V2
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Hernández JR, 2000, IEEE T IMAGE PROCESS, V9, P55, DOI 10.1109/83.817598
   Hsu CS, 2005, OPT ENG, V44, DOI 10.1117/1.1951647
   Hsu CT, 1999, IEEE T IMAGE PROCESS, V8, P58, DOI 10.1109/83.736686
   Hwang HE, 2006, J OPT SOC AM A, V23, P1870, DOI 10.1364/JOSAA.23.001870
   Kalantari N, 2010, IEEE T CIRCUITS SYST, V20
   Li Z, 2011, IEEE IMAGE PROC
   Liu JL, 2006, COMPUTER STANDARDS I, V28
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Liu ZJ, 2009, OPT COMMUN, V282, P1536, DOI 10.1016/j.optcom.2009.01.002
   Lu Z, 2007, 3 INT C INT INF HID, V1
   Maity SP, 2010, AEU-INT J ELECTRON C, V64, P243, DOI 10.1016/j.aeue.2008.10.004
   Mohan B. Chandra, 2008, Journal of Multimedia, V3, P7, DOI 10.4304/jmm.3.1.7-15
   Mohanty SP, 2003, SIPS 2003: IEEE WORKSHOP ON SIGNAL PROCESSING SYSTEMS, P183
   Morita Y, 2009, MIDWEST SYMP CIRCUIT, P683, DOI 10.1109/MWSCAS.2009.5236002
   Patra JC, 2010, DIGIT SIGNAL PROCESS, V20, P1597, DOI 10.1016/j.dsp.2010.03.010
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Rani A, 2014, MULTIMED TOOLS APPL, V72, P2225, DOI 10.1007/s11042-013-1528-3
   Rawat S, 2012, INT J ELECT COMMUN, V66
   Rawat S, 2011, INT J IMAGE GRAPH, V11, P471, DOI 10.1142/S0219467811004263
   Rawat S, 2013, INT J SIGNAL IMAGING, V6, P158, DOI 10.1504/IJSISE.2013.054794
   Sadreazami H, 2012, INT J ELECT COMMUN, V66
   Singh P, 2016, MULTIMED TOOLS APPL, V75, P8165, DOI 10.1007/s11042-015-2736-9
   Situ GH, 2004, OPT LETT, V29, P1584, DOI 10.1364/OL.29.001584
   Suhail M, 2003, IEEE T INSTRUM MEAS, V52
   Tao R, 2007, OPT EXPRESS, V15, P16067, DOI 10.1364/OE.15.016067
   Tseng HW, 2008, ADV COMMUN SYST ELEC, P4
   Unnikrishnan G, 2000, OPT LETT, V25, P887, DOI 10.1364/OL.25.000887
   Wang MS, 2009, COMPUT STAND INTER, V31, P757, DOI 10.1016/j.csi.2008.09.003
   Yang C, 2008, 3 INT C INN COMP INF, P2020
   Zhao DW, 2004, CHAOS SOLITON FRACT, V22, P47, DOI 10.1016/j.chaos.2003.12.104
NR 47
TC 7
Z9 7
U1 1
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21497
EP 21517
DI 10.1007/s11042-016-4006-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400052
DA 2024-07-18
ER

PT J
AU Zhu, SP
   Zhang, CY
AF Zhu, Shiping
   Zhang, Chunyan
TI A fast algorithm of intra prediction modes pruning for HEVC based on
   decision trees and a new three-step search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High efficiency video coding (HEVC); Intra mode decision; Machine
   learning; Decision trees
ID STANDARD; TERMINATION
AB The High Efficiency Video Coding (HEVC) standard is a new generation video coding scheme, succeeding to H.264/AVC. HEVC requires only 50 % bitrate of H.264/AVC at the same perceptual quality by adopting new coding tools and more flexible block structures. HEVC specifies 35 different intra prediction directions that can be associated to different block sizes. Each possible combination needs to be tested within the Rate Distortion (RD) process to enable selecting the optimal intra mode and block splitting depth. This leads to a significant processing weight and therefore any improvement that might be achieved will bring significative increase in the computational efficiency of the algorithm. This paper proposes a novel intra prediction modes pruning method based on decision trees and a new three-step search algorithm, aiming at achieving higher encoding efficiency compared to the standard-HEVC. This fast algorithm is composed of two algorithms. The first algorithm is a modes pruning algorithm depending on decision trees. We first calculate variances of the above side, the left side and all the reference samples of all the PUs (Prediction Units), which are used to divide the PUs into three groups of different candidate intra prediction modes. The first group only includes Planar mode and DC mode, the optimal mode will be selected from the two modes. The second and third groups include 19 and 35 intra modes, respectively. Then the decision trees are trained using the information obtained previously by the software WEKA. The classification process has an accuracy of 85.29 %. The second algorithm is a three-step search algorithm which is defined to be suitable for prediction units classified into class two and class three after the execution of decision trees. The detailed implementations of three-step search algorithms for prediction units belong to those two classes are subtly different. Experimental results verify that, compared with the reference software HM15.0, on average, the proposed algorithm reduces the encoding time by 37.87 % with a slightly decreasing of BD-PSNR (0.058 dB) and increasing of BD-Rate (1.19 %).
C1 [Zhu, Shiping; Zhang, Chunyan] Beihang Univ, Sch Instrumentat Sci & Optoelect Engn, Dept Measurement Control & Informat Technol, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhu, SP (corresponding author), Beihang Univ, Sch Instrumentat Sci & Optoelect Engn, Dept Measurement Control & Informat Technol, Beijing 100191, Peoples R China.
EM spzhu@163.com
RI zhang, cl/JDW-6549-2023; Zhang, Chun/GRE-8915-2022; zhang,
   chunmei/IUQ-7038-2023; Zhu, Shiping/C-3754-2012
FU National Natural Science Foundation of China (NSFC) [61375025, 61075011,
   60675018]; Scientific Research Foundation for the Returned Overseas
   Chinese Scholars from the State Education Ministry of China
FX This project is funded by the National Natural Science Foundation of
   China (NSFC) under grants No. 61375025, No. 61075011, and No. 60675018,
   also the Scientific Research Foundation for the Returned Overseas
   Chinese Scholars from the State Education Ministry of China. We express
   our appreciations to the reviewers for their thorough review and very
   helpful comments, which help improving this paper.
CR Bjontegaard G, 2001, VCEGM33ITUTQ616
   Bossen F., 2012, JOINT COLL TEAM VID
   Brahmasury Jain H., 2014, Polibits, V0, P5
   Cancellier L. H., 2014, INT CIRC SYST DES SB, P1
   Cen YF, 2015, INFORM PROCESS LETT, V115, P719, DOI 10.1016/j.ipl.2015.04.001
   Chau LP, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P421
   Correa G, 2015, IEEE T CIRC SYST VID, V25, P660, DOI 10.1109/TCSVT.2014.2363753
   Correa G, 2014, EUR SIGNAL PR CONF, P276
   Daehyeok Gwon, 2015, 2015 Asia Pacific Conference on Multimedia and Broadcasting (APMediaCast). Proceedings, P1, DOI 10.1109/APMediaCast.2015.7210287
   Garrido-Cantos R, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-82
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Lainema J, 2012, IEEE T CIRC SYST VID, V22, P1792, DOI 10.1109/TCSVT.2012.2221525
   Lei HJ, 2013, ADV INTEL SYS RES, V68, P34
   Lim K, 2015, IEEE T CIRC SYST VID, V25, P1335, DOI 10.1109/TCSVT.2014.2380194
   Lin YC, 2014, 2014 INTERNATIONAL SYMPOSIUM ON COMPUTER, CONSUMER AND CONTROL (IS3C 2014), P39, DOI 10.1109/IS3C.2014.23
   Min B, 2015, IEEE T CIRC SYST VID, V25, P892, DOI 10.1109/TCSVT.2014.2363739
   Park SJ, 2016, SIGNAL PROCESS-IMAGE, V42, P79, DOI 10.1016/j.image.2015.12.006
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Ruiz-Coll D, 2014, IEEE IMAGE PROC, P4112, DOI 10.1109/ICIP.2014.7025835
   Sharabayko MP, 2014, 2014 9TH INTERNATIONAL FORUM ON STRATEGIC TECHNOLOGY (IFOST), P56, DOI 10.1109/IFOST.2014.6991071
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shi W, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P17, DOI 10.1109/APCCAS.2014.7032708
   Shi YF, 2013, IEEE INT SYMP CIRC S, P225, DOI 10.1109/ISCAS.2013.6571823
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Utgoff P. E., 1989, Machine Learning, V4, P161, DOI 10.1023/A:1022699900025
   Wang LL, 2013, IEEE T CIRC SYST VID, V23, P1686, DOI 10.1109/TCSVT.2013.2255398
   Wiegand T, 2013, P SPIE INT SOC OPTIC, V13, P417
   Zhang Q, 2015, MULT SIGN PROC MMSP
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
   Zhao Liang, 2011, VISUAL COMMUN-US, P1, DOI DOI 10.1109/VCIP.2011.6115979
   Zhou W, 2015, EURASIP J ADV SIG PR, V2015, P1
NR 33
TC 20
Z9 20
U1 0
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2017
VL 76
IS 20
BP 21707
EP 21728
DI 10.1007/s11042-016-4056-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FH0YB
UT WOS:000410865400062
DA 2024-07-18
ER

PT J
AU Chang, JR
   Juang, HC
   Chen, YS
   Chang, CM
AF Chang, Jieh-Ren
   Juang, Hung-Chi
   Chen, You-Shyang
   Chang, Cheng-Ming
TI Safe binary particle swam algorithm for an enhanced unsupervised label
   refinement in automatic face annotation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Particle swam algorithm; Automatic face annotation; Unsupervised label
   refinement
ID PARAMETER-IDENTIFICATION; CONVERGENCE; SIMULATION
AB Mining web facial images on the internet has become as a profitable and important paradigm towards auto face annotation technique. The unsupervised label refinement (ULR) is an effective method that can fix weakly labeled facial images data which are collected from the internet and included some images with wrong label. In order to improve the correction accuracy of ULR, particle swarm optimization (PSO) and binary particle swarm optimization (BPSO) are used for solving binary constraint optimization task in this study. A novel method named safe binary particle swam optimization (SBPSO) is also proposed to improve BPSO which has the probability over range problem for using the ULR. In addition, SBPSO is also employed for an enhanced ULR (EULR) objective function which is created by modifying the original formula of ULR to improve the accuracy of labeled facial image. An experimental database is queried from IMDb website which collected the actors who were bored in 1950 to 1990. Some error flags are randomly added in the database for the correction tests by different methods. The results showed that the SBPSO Algorithm for the EULR in automatic face annotation have the better label correction rate and convergence effect.
C1 [Chang, Jieh-Ren; Juang, Hung-Chi] Natl Ilan Univ, Dept Elect Engn, 1,Sec 1,Shennong Rd, Yilan 260, Taiwan.
   [Chen, You-Shyang; Chang, Cheng-Ming] Hwa Hsia Univ Technol, Dept Informat Management, New Taipei, Taiwan.
C3 National Ilan University
RP Chang, JR (corresponding author), Natl Ilan Univ, Dept Elect Engn, 1,Sec 1,Shennong Rd, Yilan 260, Taiwan.
EM jrchang@niu.edu.tw
CR Asthana A, 2011, PATTERN RECOGN, V44, P2598, DOI 10.1016/j.patcog.2011.03.014
   Berg TL, 2004, PROC CVPR IEEE, P848
   Bu J., 2012, P 20 ACM INT C MULT, P219
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Chapelle O, 2006, IEEE T NEURAL NETW, V20
   Docherty P.D., 2012, IFAC P, V45, P490
   Docherty PD, 2014, COMPUT METH PROG BIO, V114, pE70, DOI 10.1016/j.cmpb.2013.06.017
   Docherty PD, 2012, MED BIOL ENG COMPUT, V50, P127, DOI 10.1007/s11517-011-0851-y
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Esmin A. A. A., 2002, 2002 IEEE International Conference on Systems, Man and Cybernetics. Conference Proceedings (Cat. No.02CH37349), DOI 10.1109/ICSMC.2002.1176020
   Fan Jianping., 2004, ACM International Conference on Multimedia, P540, DOI [DOI 10.1145/1027527, DOI 10.1145/1027527.1027660]
   Hoi TE, 2013, PROCEEDINGS OF THE 22ND INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'13 COMPANION), P317
   Hu XH, 2003, PROCEEDINGS OF THE 2003 IEEE SWARM INTELLIGENCE SYMPOSIUM (SIS 03), P243, DOI 10.1109/SIS.2003.1202275
   Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference, P405
   Khanpour M., 2007, 2007 IEEE Compound Semiconductor Integrated Circuit Symposium, P1
   LUO ZQ, 1993, MATH OPER RES, V18, P846, DOI 10.1287/moor.18.4.846
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Mao Q, 2013, IEEE T IMAGE PROCESS, V22, P1583, DOI 10.1109/TIP.2012.2233490
   Page L., 1999, PAGERANK CITATION RA, DOI DOI 10.1109/IISWC.2012.6402911
   Pang L, 2015, IEEE T MULTIMEDIA, V17, P854, DOI 10.1109/TMM.2015.2419452
   Paul E, 2015, 2015 INTERNATIONAL CONFERENCE ON CONTROL COMMUNICATION & COMPUTING INDIA (ICCC), P724, DOI 10.1109/ICCC.2015.7432989
   Phi TP, 2010, IEEE INT CON MULTI, P1528, DOI 10.1109/ICME.2010.5583271
   Salerno J, 1997, PROC INT C TOOLS ART, P45, DOI 10.1109/TAI.1997.632235
   Satoh S, 1999, IEEE MULTIMEDIA, V6, P22, DOI 10.1109/93.752960
   Shi YH, 1998, IEEE C EVOL COMPUTAT, P69, DOI 10.1109/ICEC.1998.699146
   Siagian C, 2007, IEEE T PATTERN ANAL, V29, P300, DOI 10.1109/TPAMI.2007.40
   Sousa T, 2004, PARALLEL COMPUT, V30, P767, DOI 10.1016/j.parco.2003.12.015
   Tseng P, 2001, J OPTIMIZ THEORY APP, V109, P475, DOI 10.1023/A:1017501703105
   Wang CB, 2006, LECT NOTES COMPUT SC, V4035, P647, DOI 10.1145/1180639.1180774
   Wang D., 2012, ACM INT C P SER, P1392, DOI DOI 10.1145/2396761.2398444
   Wang DY, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P443
   Wang DY, 2014, IEEE T PATTERN ANAL, V36, P550, DOI 10.1109/TPAMI.2013.145
   Wang DY, 2014, IEEE T KNOWL DATA EN, V26, P166, DOI 10.1109/TKDE.2012.240
   Wang KP, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P1583, DOI 10.1109/ICMLC.2003.1259748
   Yang J., 2004, P 12 ANN ACM INT C M, P580
   Zhou Y., 2010, JMLR WORKSHOP C P, P988
   Zhu JK, 2008, IEEE T MULTIMEDIA, V10, P86, DOI 10.1109/TMM.2007.911245
NR 37
TC 2
Z9 2
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 18339
EP 18359
DI 10.1007/s11042-016-4058-y
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800008
DA 2024-07-18
ER

PT J
AU Singh, R
   Om, H
AF Singh, Rishav
   Om, Hari
TI Newborn face recognition using deep convolutional neural network
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face recognition; Deep convolutional neural network; Newborn
AB Development of expertise in Face Recognition has led researchers to apply its various techniques for newborn recognition as some of the problems such as swapping, kidnapping are still prevalent. The paper proposes to apply Deep Convolutional Neural Network(CNN) to IIT(BHU) newborn database. The database has its own advantages where the quality of images is high and segregation has been done for various expressions of newborn. The Deep CNN applied in this paper is more advantageous when compared to regular MLP. Along with this the results taken from application of proposed technique have been compared to state-of-the-art technique applied on the same database and it shows improved results. It has been found Deep CNN improves PCA by 22.09%, LDA by 12.98%, ICA by 11.35%, LBP by 17.08% and SURF by 10.8% for Neutral-Neutral faces. Along with this results have also been gathered to understand which Deep CNN architecture is most suitable for the database. The CNN architecture with 2 convolutional layers and 1 hidden layer is the best solution. The results have also been cross validated using 10-fold cross validation.
C1 [Singh, Rishav] Infosys Ltd, Educ & Res, Chandigarh, India.
   [Om, Hari] Indian Sch Mines, Dept Comp Sci, Dhanbad, Bihar, India.
C3 Infosys Limited; Indian Institute of Technology System (IIT System);
   Indian Institute of Technology (Indian School of Mines) Dhanbad
RP Singh, R (corresponding author), Infosys Ltd, Educ & Res, Chandigarh, India.
EM rishvsingh559@gmail.com; hariom4india@gmail.com
RI singh, rishav/AAB-7472-2020; OM, HARI/AAY-6011-2021; singh,
   rishav/AAA-6991-2021
OI singh, rishav/0000-0003-2947-9046; OM, HARI/0000-0002-9750-2706; singh,
   rishav/0000-0003-2947-9046
CR [Anonymous], MAXOUT NETWORKS
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2015, Neural Networks (IJCNN), 2015 International Joint Conference on
   [Anonymous], 2011, AISTATS
   [Anonymous], P NAT AC SCI IND SEC
   Bharadwaj S, 2016, IEEE T INF FOREN SEC, V11, P1630, DOI 10.1109/TIFS.2016.2538744
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Geoffrey EHinton., 2012, Improving neural networks by preventing co-adaptation of feature detectors
   Goodfellow I.J., 2013, MULTIDIGIT NUMBER RE
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Sainath TN, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P315, DOI 10.1109/ASRU.2013.6707749
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K., 2014, 14091556 ARXIV
   Singh R, 2016, ADV INTELL SYST COMP, V410, P29, DOI 10.1007/978-81-322-2734-2_4
   Tiwari S, 2012, IET BIOMETRICS, V1, P200, DOI 10.1049/iet-bmt.2012.0040
NR 20
TC 23
Z9 28
U1 1
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2017
VL 76
IS 18
BP 19005
EP 19015
DI 10.1007/s11042-016-4342-x
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FD9SG
UT WOS:000407861800040
DA 2024-07-18
ER

PT J
AU Li, J
AF Li, Jun
TI A synthetic research on the multimedia data encryption based mobile
   computing security enhancement model and multi-channel mobile human
   computer interaction framework
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data encryption; Mobile computing; Security enhancement; Human computer
   interaction; Mobile multimedia; Multi-channel framework
ID NEURAL-NETWORKS; INFORMATION; INTEGRATION; MANAGEMENT
AB With the development of computer network, people could obtain information through the network with stronger impulsion, the dependence of the requirements also becomes higher, this is not only reflected in the increase of information, but to obtain and submit more reflected in real-time and easy to access to information on the pressing needs of the. Therefore, people devoted all aspects from the terminal, network and software platforms to make unremitting efforts. Under this basis, we conduct synthetic research on the data encryption based mobile computing security enhancement model and multi-channel mobile human computer interaction framework in this paper. We firstly introduce the discrete-time Hopfield neural network based data encryption algorithm beyond the analysis on the information flow security and type based model, data security review and attack model under mobile computing environment. We improve learning algorithm of the MD method to avoid the sample mobile and cross interference problems of Hebb rule. Later, we integrate the multi-channel concept to propose the new multi-channel man-machine interaction. In our framework, the 3D interactive technology, speech recognition and synthesis technology, natural language understanding and processing technology, eye tracking technology, posture, input, tactile, force display basic technology are taken into consideration for the synthetic analysis. The result from the experimental simulation proves that our methodology obtains better effectiveness and feasibility from both the angels of data security and interface experience.
C1 [Li, Jun] Chinese Acad Sci, Quanzhou Inst Equipment Mfg, Haixi Inst, Quanzhou 362200, Peoples R China.
C3 Chinese Academy of Sciences
RP Li, J (corresponding author), Chinese Acad Sci, Quanzhou Inst Equipment Mfg, Haixi Inst, Quanzhou 362200, Peoples R China.
EM lijuncas@163.com
RI wang, xiao/HZI-9156-2023
CR Abolfazli S, 2014, J NETW COMPUT APPL, V40, P345, DOI 10.1016/j.jnca.2013.09.009
   Ahmad A, 2014, J INTELL MANUF, V25, P357, DOI 10.1007/s10845-012-0683-0
   Baccarelli E, 2016, IEEE NETWORK, V30, P54, DOI 10.1109/MNET.2016.7437025
   Balliu M, 2012, 2012 IE 25 COMP SEC
   Bao G, 2016, NEUROCOMPUTING
   Ben-Artzi G., 2014, ARXIV14121455
   Berger BJ, 2013, 2013 17 EUR C SOFTW
   BIALKOWSKI A, 2012, 2012 INT C DIG IM CO
   Boche H, 2015, IEEE T INF FOREN SEC, V10, P2531, DOI 10.1109/TIFS.2015.2465937
   Carli V, 2012, J MED ETHICS, V38, P127, DOI 10.1136/jme.2011.044552
   Charisis V, 2015, ACCESS HUMAN ENV CUL, P29
   Cheng YW, 2012, J COGNITIVE NEUROSCI, V24, P1411, DOI 10.1162/jocn_a_00214
   Coutaz J, 2012, HUM FACTORS ERGON, P1195
   Dwivedi A, 2013, ADV INTELL SYST, V178, P367
   Fernando N, 2013, FUTURE GENER COMP SY, V29, P84, DOI 10.1016/j.future.2012.05.023
   Gallos LK, 2012, P NATL ACAD SCI USA, V109, P2825, DOI 10.1073/pnas.1106612109
   Gaver W.W., 2013, P SIGCHI C HUM FACT, P3451
   Gikas J, 2013, INTERNET HIGH EDUC, V19, P18, DOI 10.1016/j.iheduc.2013.06.002
   Gkatzikis L, 2013, IEEE WIREL COMMUN, V20, P24, DOI 10.1109/MWC.2013.6549280
   Greisen P, 2013, IEEE T CIRC SYST VID, V23, P1402, DOI 10.1109/TCSVT.2013.2244797
   Gupta N, 2015, 2015 2 INT C COMP SU
   Harrison R., 2013, J INTERACTION SCI, V1, P1, DOI [10.1186/2194-0827-1-1, DOI 10.1186/2194-0827-1-1]
   Hedin D, 2012, 2012 IE 25 COMP SEC
   Hong Xiaopeng, 2015, NEUROCOMPUTING
   Hu Q, 2012, DECISION SCI, V43, P615, DOI 10.1111/j.1540-5915.2012.00361.x
   Huang DJ, 2013, IEEE NETWORK, V27, P6, DOI 10.1109/MNET.2013.6616109
   Iacob C, 2013, 2013 10 IEEE WORK C
   Ifinedo P, 2012, COMPUT SECUR, V31, P83, DOI 10.1016/j.cose.2011.10.007
   Jararweh Y, 2013, 2013 IE 9 INT C MOB
   Jinye L, 2012, INT J ADV COMPUT TEC, V4
   Karapanos E, 2012, CHI 12 HUM FACT COMP
   Kim C, 2013, AUTOMAT CONSTR, V35, P415, DOI 10.1016/j.autcon.2013.05.027
   Kim N-U, 2013, 2013 INT C INF SCI A
   Kovács M, 2012, LECT NOTES COMPUT SC, V7159, P46, DOI 10.1007/978-3-642-28166-2_6
   Kulshreshth A, 2013, 2013 IE S 3D US INT
   Kuo C-H, 2013, 2013 AS PAC SIGN INF
   Lei Yang, 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P794, DOI 10.1109/CLOUD.2012.97
   Li S, 2013, RES PERFORMANCE ENCR
   Long M., 2013, P IEEE C COMP VIS PA
   Lopes O, 2014, IEEE T CYBERNETICS, V44, P2379, DOI 10.1109/TCYB.2014.2307121
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Mandal S, 2015, 2015 INT C GREEN COM
   Mathiyalagan K, 2015, IEEE T CYBERNETICS, V45, P676, DOI 10.1109/TCYB.2014.2332356
   Mathur A., 2012, INT J COMPUTER SCI E, V4, P1650
   Mazrooei-Sebdani R, 2013, NEUROCOMPUTING, V99, P154, DOI 10.1016/j.neucom.2012.06.007
   Melicher W, 2016, P 2016 ANN ACM C HUM, V16
   Moghaddam F Fatemi, 2013, 2013 IE 2 INT C CLOU
   Mu DJ, 2014, IET INFORM SECUR, V8, P12, DOI 10.1049/iet-ifs.2012.0342
   Nasseri M, 2013, 2013 IE 2 INT C CLOU
   Parsons KM, 2015, J COGN ENG DECIS MAK, V9, P117, DOI 10.1177/1555343415575152
   Qi H., 2012, 2012 2 INT C DIG INF
   Sanaei Z, 2012, ARXIV12053247
   Sanaei Z, 2012, 2012 1 IEEE INT C CO
   Sandulescu V, 2015, 2015 E HLTH BIOENG C
   Shafiu I, 2016, INT J INF SYST SUPPL, V9, P1, DOI 10.4018/IJISSCM.2016010101
   Shaikh AA, 2015, TELEMAT INFORM, V32, P129, DOI 10.1016/j.tele.2014.05.003
   Shi P, 2015, NEUROCOMPUTING, V151, P168, DOI 10.1016/j.neucom.2014.09.059
   Shiraz M, 2013, IEEE COMMUN SURV TUT, V15, P1294, DOI 10.1109/SURV.2012.111412.00045
   Subramanyan P, 2014, P C DES AUT TEST EUR
   Wang H, 2013, 2013 6 INT C ADV COM
   Wang Haoxiang, 2014, 2014 IE 26 INT C TOO
   Wang H, 2015, NEUROCOMPUTING, V154, P15, DOI 10.1016/j.neucom.2014.12.031
   Williams A, 2014, HUM-COMPUT INTERACT, V29, P78, DOI 10.1080/07370024.2013.823819
   Williams PAH, 2013, RAPIDLY MOVING TARGE
   Xiong H, 2012, ANONYMOUS AUTHENTICA
   Xu C, 2012, 2012 IE C COMP VIS P
   Xu Y., 2012, OPT ENG, V51
   Yamada K, 2015, NEUROIMAGE, V113, P289, DOI 10.1016/j.neuroimage.2015.03.059
   Yang YJ, 2015, LECT NOTES COMPUT SC, V9327, P146, DOI 10.1007/978-3-319-24177-7_8
   Zanin M, 2014, INFORM SCIENCES, V270, P288, DOI 10.1016/j.ins.2014.02.131
   Zhang Y, 2015, ASME 2015 INT COMB E
   Zhou Z, 2012, P 8 INT C NETW SERV
NR 72
TC 10
Z9 10
U1 1
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 16963
EP 16987
DI 10.1007/s11042-016-3662-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500006
DA 2024-07-18
ER

PT J
AU Lu, YF
   Chen, BW
   Sun, J
   Tan, X
AF Lu, Yunfan
   Chen, Baowen
   Sun, Jie
   Tan, Xu
TI Research on 3D reconstruction method of human-computer interaction scene
   based on support vector machine in cloud manufacturing environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Support vector machine; Human-computer interaction; Image
   reconstruction; Cloud manufacturing environment
ID GENERALIZED M-SET; MICROSTRUCTURE
AB In three dimensional (3D) reconstruction of human-computer interaction scene images in cloud manufacturing environment, the traditional method recovers the depth information directly for projection mapping, which reduces 3D image reconstruction accuracy. A 3D reconstruction method for human-computer interaction scene images is proposed based on support vector machine, the human-computer interaction scene image in cloud manufacturing environment is pretreated, using extremum algorithm to detect noise in human-computer interaction scene images, through multi windows filtering method to filter pixels contaminated by noise. Using dynamic scene estimation method to enhance the human-computer interaction scene images in cloud manufacturing environment. Corner features of the human-computer interaction image are inquired, and extracted feature vectors are input into support vector machine to learn, and the immune algorithm is introduced to adjust the parameters and get the outlined structure of 3D human-computer interaction scene images, to realize the image 3D reconstruction. The experimental results show that in cloud manufacturing environment, the proposed method has high accuracy on reconstruction and authenticity.
C1 [Lu, Yunfan; Chen, Baowen; Sun, Jie; Tan, Xu] Shenzhen Inst Informat Technol, Dept Software Engn, Shenzhen Longgang Dragon Rd 2188, Shenzhen 518000, Guangdong, Peoples R China.
C3 Shenzhen Institute of Information Technology
RP Tan, X (corresponding author), Shenzhen Inst Informat Technol, Dept Software Engn, Shenzhen Longgang Dragon Rd 2188, Shenzhen 518000, Guangdong, Peoples R China.
EM tanxu78546@163.com
RI Chen, Baowen/IZP-5806-2023
FU Field research and breeding project - oriented interactive scene
   reconstruction of three dimensional registration method research
   [lg201404]
FX This work is supported by the Field research and breeding project -
   oriented interactive scene reconstruction of three dimensional
   registration method research (lg201404)
CR Black J, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P169, DOI 10.1109/MOTION.2002.1182230
   Boshkovikj V, 2014, AMB EXPRESS, V4, DOI 10.1186/2191-0855-4-3
   Brown CH, 2013, INT ORTHOP, V37, P253, DOI 10.1007/s00264-012-1772-6
   Caviedes J, 2015, INT C CONS EL, P897
   Choi NH, 2013, KNEE, V20, P31, DOI 10.1016/j.knee.2012.05.009
   Cui Y, 2015, SIGGRAPH 2015
   Dai YC, 2014, INT J COMPUT VISION, V107, P101, DOI 10.1007/s11263-013-0684-2
   Groeber MA, 2014, INTEGR MATER MANUF I, V3, DOI 10.1186/2193-9772-3-5
   Groebera MA, SCIENCE, V57, P259
   Hall DL, 2013, MATH TECHNIQUES MULT
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Hofbauer M, 2013, KNEE SURG SPORT TR A, V21, P2072, DOI 10.1007/s00167-013-2470-7
   Hu Chun-yu, 2014, Application Research of Computers, V31, P1909, DOI 10.3969/j.issn.1001-3695.2014.06.073
   Huang Jin-Wei, 2015, Maxillofac Plast Reconstr Surg, V37, P20, DOI 10.1186/s40902-015-0017-1
   Ideses I, 2015, P SPIE, V6490
   Jarvela T, 2014, KNEE SURG SPORT TR A, V15, P500
   Kong SG, 2015, IEEE T IMAGE PROCESS, V24, P1801, DOI 10.1109/TIP.2015.2405483
   Li JQ, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440760
   Liu S, 2014, APPL MATH COMPUT, V243, P767, DOI 10.1016/j.amc.2014.06.016
   Liu S, 2013, APPL MATH COMPUT, V220, P668, DOI 10.1016/j.amc.2013.06.096
   Maggio E, 2014, IEEE T ACOUST SPEECH, V1, P1101
   MIAO Y., 2015, Computational Visual Media, V1, P3
   Osawa T, 2014, P IEEE C ADV VID SIG, P224
   Shade PA, 2013, INTEGR MATER MANUF I, V2, DOI 10.1186/2193-9772-2-5
   St-Pierre L, 2015, INT J PLASTICITY, V24, P1516
   Sundararaghavan V, 2014, INTEGR MATER MANUF I, V3, DOI 10.1186/s40192-014-0019-3
   Tang JH, 2015, IEEE T IMAGE PROCESS, V24, P2827, DOI 10.1109/TIP.2015.2421443
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Trucco E, 2015, INTRO TECHNIQUES 3 D
   Tsai R, 2014, IEEE J ROBOTIC AUTOM, V3, P323
   Webster KE, 2015, KNEE SURG SPORT TR A, V9, P86
   Xu Y, 2015, IEEE T IMAGE PROCESS, V24, P1315, DOI 10.1109/TIP.2015.2397314
NR 32
TC 2
Z9 2
U1 2
U2 33
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17145
EP 17162
DI 10.1007/s11042-016-3639-0
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500015
DA 2024-07-18
ER

PT J
AU Yoo, S
   Ryu, ES
AF Yoo, Seehwan
   Ryu, Eun-Seok
TI Parallel HEVC decoding with asymmetric mobile multicores
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Parallel video processing; Mobile processor; Asymmetric multicore
ID AMDAHLS LAW; PERFORMANCE; EFFICIENCY; POWER; ARM
AB Recently, the necessity of parallel ultra-high definition (UHD) video processing has been emerging, and the usage of the computing systems that have asymmetric processors, such as ARM big.LITTLE, is actively increasing. Thus, a new parallel UHD video processing method optimized for asymmetric multicore systems is essential. This paper proposes a novel High Efficiency Video Coding (HEVC) Tile partitioning method for the parallel processing by analyzing the computational power of asymmetric multicores. (1) The proposed method analyzes the computing power of asymmetric multicores and (2) the regression model of computational complexity per video resolution. Lastly, (3) the model determines the optimal HEVC Tile resolution for each core and partitions and allocates the Tiles to suitable cores. Experimental results with the test sequences of common test condition (CTC) show that the decoding speed improved by 17 % with implemented multi-threading module on ARM asymmetric multicore systems.
C1 [Yoo, Seehwan] Dankook Univ, 152 Jukjeon Ro, Yongin 16890, Gyeonggi Do, South Korea.
   [Ryu, Eun-Seok] Gachon Univ, 1342 Seongnam Daero, Seongnam Si 13120, Gyeonggi Do, South Korea.
C3 Dankook University; Gachon University
RP Ryu, ES (corresponding author), Gachon Univ, 1342 Seongnam Daero, Seongnam Si 13120, Gyeonggi Do, South Korea.
EM seehwan.yoo@dankook.ac.kr; esryu@gachon.ac.kr
RI Yoo, Seehwan/R-1489-2019; Ryu, Eun-Seok/AAA-3536-2021
OI Yoo, Seehwan/0000-0001-5464-4619; Ryu, Eun-Seok/0000-0003-4894-6105
FU National Research Foundation of Korea(NRF) - Ministry of Science, ICT &
   Future Planning [NRF-2015R1C1A1A02037743, NRF-2015R1C1A1A02037330];
   Gachon University research fund [GCU-2015-0045]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Science, ICT & Future Planning (NRF-2015R1C1A1A02037743 and
   NRF-2015R1C1A1A02037330), and this research was also partially supported
   by the Gachon University research fund of 2015.(GCU-2015-0045).
CR [Anonymous], P INT C COMP ARCH SY
   [Anonymous], ASPLOS 16 16 INT C, DOI DOI 10.1145/1950365.1950402
   Azizi O, 2010, CONF PROC INT SYMP C, P26, DOI 10.1145/1816038.1815967
   Baik H, 2015, IEEE IMAGE PROC, P4298, DOI 10.1109/ICIP.2015.7351617
   Belviranli ME, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400716
   Bhadauria Major, 2010, 24th ACM International Conference on Supercomputing 2010, P189
   Blem E, 2013, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2013.6522302
   Bossen F, 2012, IEEE T CIRC SYST VID, V22, P1685, DOI 10.1109/TCSVT.2012.2221255
   Carroll A, 2014, IEEE REAL TIME, P287, DOI 10.1109/RTAS.2014.6926010
   Cassidy AS, 2012, IEEE T COMPUT, V61, P1110, DOI 10.1109/TC.2011.169
   Chen JA, 2009, DES AUT CON, P927
   Chen Q, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2579674
   Chi CC, 2012, IEEE T CIRC SYST VID, V22, P1827, DOI 10.1109/TCSVT.2012.2223056
   Esmaeilzadeh H, 2012, ACM T COMPUT SYST, V30, DOI 10.1145/2324876.2324879
   Esmaeilzadeh H, 2012, IEEE MICRO, V32, P110, DOI 10.1109/MM.2012.20
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Ghiasi S., 2005, 2 C COMPUTING, P199, DOI DOI 10.1145/1062261.1062295
   Göddeke D, 2013, J COMPUT PHYS, V237, P132, DOI 10.1016/j.jcp.2012.11.031
   Govindan MSS, 2014, IEEE T COMPUT, V63, P2025, DOI 10.1109/TC.2013.48
   Hill MD, 2008, COMPUTER, V41, P33, DOI 10.1109/MC.2008.209
   Koufaty D, 2010, EUROSYS'10: PROCEEDINGS OF THE EUROSYS 2010 CONFERENCE, P125
   Kumar R, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P81
   Lakshminarayana NB, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Le Sueur Etienne, 2010, Proceedings of the 2010 international conference on Power aware computing and systems, HotPower'10, P1, DOI DOI 10.5555/1924920.1924921
   Lin FX, 2014, ACM SIGPLAN NOTICES, V49, P285, DOI 10.1145/2541940.2541975
   Lukefahr A, 2014, INT CONFER PARA, P237, DOI 10.1145/2628071.2628078
   Morad T. Y., 2006, IEEE Computer Architecture Letters, V5, P14, DOI 10.1109/L-CA.2006.6
   Pagani S, 2015, IEEE T PARALL DISTR, V26, P1608, DOI 10.1109/TPDS.2014.2323260
   Pricopi M, 2014, IEEE T COMPUT, V63, P2590, DOI 10.1109/TC.2013.115
   Shelepov Daniel, 2009, Operating Systems Review, V43, P66, DOI 10.1145/1531793.1531804
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Van Craeynest K, 2012, CONF PROC INT SYMP C, P213, DOI 10.1109/ISCA.2012.6237019
   Van Craeynest K, 2013, INT CONFER PARA, P177, DOI 10.1109/PACT.2013.6618815
   Woo DH, 2008, COMPUTER, V41, P24, DOI 10.1109/MC.2008.494
   Zhu YH, 2013, INT S HIGH PERF COMP, P13, DOI 10.1109/HPCA.2013.6522303
   Zidenberg T, 2012, IEEE COMPUT ARCHIT L, V11, P65, DOI 10.1109/L-CA.2012.3
NR 36
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2017
VL 76
IS 16
BP 17337
EP 17352
DI 10.1007/s11042-016-4269-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA FA6BO
UT WOS:000405528500025
DA 2024-07-18
ER

PT J
AU Elleuch, Z
   Marzouki, K
AF Elleuch, Zied
   Marzouki, Kirmene
TI Multi-index structure based on SIFT and color features for large scale
   image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image retrieval; Multi-IDF; Multi-index; Multiple assignment;
   Soft-weighting
ID OPTIMIZATION
AB During the past few years, the Bag-of-Words (BoW) model based on SIFT features has been one of the most adopted approaches by the Content-Based Image Retrieval (CBIR) systems. However, these CBIR systems have shown some weaknesses and shortcomings especially for large scale image collections. This is due to two main causes: First, information is lost in the quantization step and second, the SIFT features describe only the local gradient. To tackle these issues, we proposed to take advantage of the Hamming Embedding, soft assignment and multiple assignment techniques, on the one hand, and to fuse SIFT and color features at the indexing level in a multi-index structure, on the other. In fact, in this paper, generic and non-parametric image retrieval schemes as well as a novel multi-IDF design based on multi-index structure were proposed.
   Extensive experiments were conducted on three public datasets (Holidays, Ukbench and MIR Flickr 1 M as distractor). The experimental results are promising and outperform the state-of-the-art CBIR systems. In addition, only 117 bits are needed to represent each key-point which enables us to make our image retrieval schema suitable for large-scale experiments.
C1 [Elleuch, Zied] Univ Gafsa, Higher Inst Appl Sci & Technol Gafsa, Gafsa, Tunisia.
   [Elleuch, Zied; Marzouki, Kirmene] Univ Carthage, Natl Inst Appl Sci & Technol Tunis, Informat Ind Syst Lab, LISI INSAT, Tunis, Tunisia.
   [Marzouki, Kirmene] Univ Sousse, Higher Inst Appl Sci & Technol Sousse, Sousse, Tunisia.
C3 Universite de Gafsa; Universite de Carthage; Universite de Sousse
RP Elleuch, Z (corresponding author), Univ Gafsa, Higher Inst Appl Sci & Technol Gafsa, Gafsa, Tunisia.; Elleuch, Z (corresponding author), Univ Carthage, Natl Inst Appl Sci & Technol Tunis, Informat Ind Syst Lab, LISI INSAT, Tunis, Tunisia.
EM elleuch.zied@gmail.com; kirmene@marzouki.tn
RI Elleuch, Zied/AAQ-9701-2021
OI ZIED, ELLEUCH/0000-0002-8022-560X
CR Andoni A, 2008, COMMUN ACM, V51, P117, DOI 10.1145/1327452.1327494
   [Anonymous], CORR
   ARANDJELOVIC R, 2012, PROC CVPR IEEE, P2911, DOI DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2012, PROC CVPR IEEE, P3069, DOI 10.1109/CVPR.2012.6248038
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Chen X, 2009, LECT NOTES ARTIF INT, V5476, P867, DOI 10.1007/978-3-642-01307-2_90
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Elleuch Z, 2013, LECT NOTES COMPUT SC, V7887, P330
   Fernando B, 2012, PROC CVPR IEEE, P3434, DOI 10.1109/CVPR.2012.6248084
   Fu Y., 2008, P 2008 INT C CONT BA, P127, DOI DOI 10.1145/1386352.1386373
   Hua X-S, 2011, ACM MULTIMEDIA
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jain M., 2011, Proceedings of the 19th ACM international conference on Multimedia, P1441
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Jegou Herve, 2008, Emerging Trends in Visual Computing. LIX Fall Colloquium, ETVC 2008. Revised Invited Papers, P305
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Ji RR, 2009, PROC CVPR IEEE, P1161, DOI 10.1109/CVPRW.2009.5206680
   Jiang K, 2015, PROC CVPR IEEE, P4933, DOI 10.1109/CVPR.2015.7299127
   Ke Y, 2004, PROC CVPR IEEE, P506
   Khan FS, 2013, INT J COMPUT VISION, V105, P205, DOI 10.1007/s11263-013-0633-0
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Liu XY, 2011, 2011 SECOND INTERNATIONAL CONFERENCE ON EDUCATION AND SPORTS EDUCATION (ESE 2011), VOL II, P1
   Liu Z., 2012, P ACM INT C MULTIMED, P199
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Norouzi M.E., 2011, ICML
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Philbin J, 2008, 2008 I E COMP SOC C
   Khan FS, 2012, INT J COMPUT VISION, V98, P49, DOI 10.1007/s11263-011-0495-2
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Tolias G, 2014, PATTERN RECOGN, V47, P3466, DOI 10.1016/j.patcog.2014.04.007
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2006, IEEE T PATTERN ANAL, V28, P150, DOI 10.1109/TPAMI.2006.3
   Wang J, 2013, CORR
   Wang XY, 2011, IEEE I CONF COMP VIS, P209, DOI 10.1109/ICCV.2011.6126244
   Weiss Y., 2008, PROC ADV NEURAL INFO, V21, P1753
   Wengert C., 2011, Proceedings of ACM international conference on Multimedia, P1437, DOI DOI 10.1145/2072298.2072034
   Yanai K, 2005, IEICE T INF SYST, VE88D, P2432, DOI 10.1093/ietisy/e88-d.10.2432
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3604, DOI 10.1109/TIP.2014.2329182
   Zheng L, 2014, IEEE T IMAGE PROCESS, V23, P3368, DOI 10.1109/TIP.2014.2330763
   Zhou WG, 2015, MULTIMEDIA SYST, V21, P245, DOI 10.1007/s00530-013-0330-4
   Zhou WG, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2422956.2422960
   Ziqiong Liu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6889, DOI 10.1109/ICASSP.2014.6854935
NR 53
TC 7
Z9 7
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 12
BP 13929
EP 13951
DI 10.1007/s11042-016-3788-1
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EW7XY
UT WOS:000402732800011
DA 2024-07-18
ER

PT J
AU Wang, FS
   Li, XC
   Lu, MY
AF Wang, Fasheng
   Li, Xucheng
   Lu, Mingyu
TI Adaptive Hamiltonian MCMC sampling for robust visual tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual tracking; Adaptive Hamiltonian Monte Carlo sampling; Locality
   sensitive histogram; Abruption capture rate
ID ABRUPT MOTION TRACKING
AB Recent researches on visual tracking have shown significant improvement in accuracy by handling the large uncertainties induced by appearance variation and abrupt motion. Most studies concentrate on random walk based Markov chain Monte Carlo(MCMC) tracking methods which have shown inefficiency in sampling from complex and high-dimensional distributions. This paper proposes an adaptive Hamiltonian Monte Carlo sampling based tracking method within the Bayesian filtering framework. In order to suppress the random walk behavior in Gibbs sampling stage, the ordered over-relaxation method is used to draw the momentum item for the joint state variable. An adaptive step-size based scheme is used to simulate the Hamiltonian dynamics in order to reduce the simulation error and improve acceptance rate of the proposed samples. Furthermore, in designing the appearnce model, we introduce the locality sensitive histogram (LSH) to deal with appearance changes induced by illumination change. The proposed tracking method is compared with several state-of-the-art trackers using different quantitative measures: success rate and abruption capture rate. Extensive experimental results have shown its superiority to several other trackers.
C1 [Li, Xucheng] Dalian Neusoft Univ Informat, Dept Software Engn, 8 Software Pk Rd, Dalian 116023, Peoples R China.
   [Wang, Fasheng; Lu, Mingyu] Dalian Maritime Univ, Sch Informat Sci & Technol, 1 Linghai Rd, Dalian 116026, Peoples R China.
C3 Dalian Maritime University
RP Wang, FS; Lu, MY (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, 1 Linghai Rd, Dalian 116026, Peoples R China.
EM fswang@dlut.edu.cn; lumingyu@dlmu.edu.cn
RI liu, jianyang/JXL-6273-2024; Wang, Fasheng/AAD-9930-2020
OI Wang, Fasheng/0000-0002-0946-0789
FU National Natural Science Foundation of China [61300082, 61272369,
   61402069]; Program for Liaoning Excellent Talents in University
   [LJQ2015006]; Liaoning Natural Science Foundation [2015020015]
FX This work was supported by the National Natural Science Foundation of
   China (No. 61300082,61272369,61402069), Program for Liaoning Excellent
   Talents in University No. LJQ2015006, Liaoning Natural Science
   Foundation No. 2015020015.
CR Brooks S, 2011, CH CRC HANDB MOD STA, pXIX
   Chung-Ching Lin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P828, DOI 10.1109/ICCVW.2009.5457616
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Holder T, 2001, APPL NUMER MATH, V39, P367, DOI 10.1016/S0168-9274(01)00089-7
   Huang WZ, 1997, SIAM J SCI COMPUT, V18, P239, DOI 10.1137/S1064827595284658
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kwon J, 2008, LECT NOTES COMPUT SC, V5302, P387, DOI 10.1007/978-3-540-88682-2_30
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P1011, DOI 10.1109/TPAMI.2012.161
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li W, 2009, IEEE IMAGE PROC, P3593, DOI 10.1109/ICIP.2009.5414311
   Li X., 2012, J NATL LIB CHINA, V2012, P20, DOI DOI 10.1016/J.ENERGY.2012.12.020
   Lim MK, 2014, INFORM SCIENCES, V283, P267, DOI 10.1016/j.ins.2014.01.003
   Neal R, 1995, TECHNICAL REPORT, P1
   Oron S, P INT C COMP VIS PAT, P1940
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Su YY, 2014, PATTERN RECOGN, V47, P1826, DOI 10.1016/j.patcog.2013.11.028
   Wang FS, 2014, LECT NOTES ARTIF INT, V8862, P52, DOI 10.1007/978-3-319-13560-1_5
   Wang FS, 2012, INT C PATT RECOG, P3066
   Wang FS, 2013, COMPUT J, V56, P1102, DOI 10.1093/comjnl/bxs141
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang XQ, 2015, INT J COMPUT VISION, V115, P279, DOI 10.1007/s11263-015-0819-8
   Zhou TF, 2015, NEUROCOMPUTING, V165, P350, DOI 10.1016/j.neucom.2015.03.024
   Zhou XZ, 2012, IEEE T IMAGE PROCESS, V21, P789, DOI 10.1109/TIP.2011.2168414
   Zhou XZ, 2010, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR.2010.5539856
   Zhou Y, 2014, IEEE INT CONGR BIG, P1, DOI 10.1109/BigData.Congress.2014.11
NR 27
TC 17
Z9 17
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2017
VL 76
IS 11
BP 13087
EP 13106
DI 10.1007/s11042-016-3699-1
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV8TE
UT WOS:000402055900006
DA 2024-07-18
ER

PT J
AU Cho, SR
   Nam, GP
   Shin, KY
   Nguyen, DT
   Pham, TD
   Lee, EC
   Park, KR
AF Cho, So Ra
   Nam, Gi Pyo
   Shin, Kwang Yong
   Dat Tien Nguyen
   Tuyen Danh Pham
   Lee, Eui Chul
   Park, Kang Ryoung
TI Periocular-based biometrics robust to eye rotation based on polar
   coordinates
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Periocular recognition; Biometrics; In-plane rotation of head; Eye
   rotation; Polar coordinates
ID IRIS RECOGNITION
AB Conventional iris recognition requires a high-resolution camera equipped with a zoom lens and a near-infrared illuminator to observe iris patterns. Moreover, with a zoom lens, the viewing angle is small, restricting the user's head movement. To address these limitations, periocular recognition has recently been studied as biometrics. Because the larger surrounding area of the eye is used instead of iris region, the camera having the high-resolution sensor and zoom lens is not necessary for the periocular recognition. In addition, the image of user's eye can be captured by using the camera having wide viewing angle, which reduces the constraints to the head movement of user's head during the image acquisition. Previous periocular recognition methods extract features in Cartesian coordinates sensitive to the rotation (roll) of the eye region caused by in-plane rotation of the head, degrading the matching accuracy. Thus, we propose a novel periocular recognition method that is robust to eye rotation (roll) based on polar coordinates. Experimental results with open database of CASIA-Iris-Distance database (CASIA-IrisV4) show that the proposed method outperformed the others.
C1 [Cho, So Ra; Nam, Gi Pyo; Shin, Kwang Yong; Dat Tien Nguyen; Tuyen Danh Pham; Park, Kang Ryoung] Dongguk Univ, Div Elect & Elect Engn, Seoul, South Korea.
   [Lee, Eui Chul] Sangmyung Univ, Dept Comp Sci, Seoul, South Korea.
C3 Dongguk University; Sangmyung University
RP Park, KR (corresponding author), Dongguk Univ, Div Elect & Elect Engn, Seoul, South Korea.
EM soracho@dgu.edu; oscar1201@dgu.edu; skyandla@dgu.edu;
   nguyentiendat@dongguk.edu; phamdanhtuyen@gmail.com; eclee@smu.ac.kr;
   parkgr@dgu.edu
RI lee, eui chul/E-1107-2013
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   ITRC (Information Technology Research Center) [IITP-2015-H8501-15-1014]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the ITRC (Information Technology Research
   Center) support program (IITP-2015-H8501-15-1014) supervised by the IITP
   (Institute for Information & communications Technology Promotion).
   Portions of the research in this paper use the CASIA-IrisV4 collected by
   the Chinese Academy of Sciences' Institute of Automation (CASIA).
CR Adams J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P205, DOI 10.1109/ICPR.2010.59
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], J CONVERG
   [Anonymous], 2010, P 2010 ACM S APPL CO, DOI DOI 10.1145/1774088.1774408
   [Anonymous], P IEEE INT C BIOM TH
   [Anonymous], OPT ENG
   Bharadwaj Samarth, 2010, P IEEE INT C BIOM TH
   Bhattacharjee D, 2014, COMPUT INF SCI, V4, P1
   Cho SR, 2015, LECT NOTES ELECTR EN, V352, P99, DOI 10.1007/978-3-662-47487-7_15
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Elmir Y, 2014, J INF PROCESS SYST, V10, P555, DOI 10.3745/JIPS.02.0007
   Kim BS, 2010, IEEE T CONSUM ELECTR, V56, P2498, DOI 10.1109/TCE.2010.5681133
   Lyle JR, 2010, P IEEE INT C BIOM TH
   Merkow J, 2010, P IEEE INT C BIOM TH
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Prabhakar S., 2003, IEEE Security & Privacy, V1, P33, DOI 10.1109/MSECP.2003.1193209
   Shin K. Y., 2013, OPT ENG, V52
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Woodard D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P162, DOI DOI 10.1109/CVPRW.2010.5544621
   Woodard Damon L., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P201, DOI 10.1109/ICPR.2010.58
   Xu J, 2010, P IEEE INT C BIOM TH
   Zhu Z., 2007, MULTIMODAL SURVEILLA
NR 24
TC 10
Z9 10
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 9
BP 11177
EP 11197
DI 10.1007/s11042-015-3052-0
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EU2GE
UT WOS:000400845000003
DA 2024-07-18
ER

PT J
AU Hu, HM
   Zhou, ML
   Liu, Y
   Yin, NY
AF Hu, Hai-Miao
   Zhou, Mingliang
   Liu, Yang
   Yin, Naiyu
TI A region-based intra-frame rate control scheme by jointing inter-frame
   dependency and inter-frame correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE I frame rate control; Video flicker; Inter-framedependency;
   Inter-framecorrelation; Region-division; HEVC
ID BIT ALLOCATION; NOTICEABLE DISTORTION; FLICKER SUPPRESSION; VIDEO;
   REDUCTION; QUANTIZATION
AB During I frame switching, the subjective quality between I frame and P frames usually have obvious fluctuation due to different coding methods. The periodic temporal visual fluctuation will cause video flicker. According to extensive experiments, we observe that I frame flicker possess a strong regional characteristics and different region have different degree of flicker. Based on this observation, a region-based I frame rate control scheme is proposed to suppress I frame flicker according to the different characteristics of the moving and non-moving regions. Firstly, by jointly considering the inter-frame dependency between I frame and subsequent un-encoded P frames and the inter-frame correlation between I frame and previous encoded P frame, an optimization model is proposed to achieve the optimal QPs for different regions. Secondly, a region-based inter-frame dependency model is proposed to separately describe the inter-frame dependency of different regions, which can accurately describe their description of the inter-frame dependency. The experimental results demonstrate that the proposed scheme can efficiently suppress I frame flicker and maintain the smoothness of subjective quality. Moreover, the proposed scheme can achieve a PSNR gain by 0.26 dB on average when compared with the rate control scheme adopted by the HEVC reference software HM15.0.
C1 [Hu, Hai-Miao; Zhou, Mingliang; Yin, Naiyu] Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Hu, Hai-Miao] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Liu, Yang] Beijing Inst Graph, Beijing 100029, Peoples R China.
C3 Beihang University; Beihang University
RP Hu, HM (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.; Hu, HM (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM frank0139@163.com
RI Zhou, Mingliang/HPC-0298-2023
FU National Natural Science Foundation of China [61370121]; National
   Hi-Tech Research and Development Program (863 Program) of China
   [2014AA015102]
FX This work was partially supported by the National Natural Science
   Foundation of China (No. 61370121), and the National Hi-Tech Research
   and Development Program (863 Program) of China (No. 2014AA015102).
CR [Anonymous], 2003, JVTG012
   [Anonymous], 2002, JVTE070
   [Anonymous], 2004, ITU T REC H 264 I 10
   [Anonymous], 144962 ISOIEC
   [Anonymous], 2012, ITUTSG16 WP3
   Becker A, 2004, IEEE DATA COMPR CONF, P252
   Changuel N, 2010, INT CONF ACOUST SPEE, P914, DOI 10.1109/ICASSP.2010.5495280
   Chao JS, 2015, IEEE T CIRC SYST VID, V25, P958, DOI 10.1109/TCSVT.2014.2367354
   Chen ZZ, 2010, IEEE T CIRC SYST VID, V20, P806, DOI 10.1109/TCSVT.2010.2045912
   Choi H., 2012, JOINT COLL TEAM VID
   Chono K, 2006, IEEE IMAGE PROC, P1713, DOI 10.1109/ICIP.2006.312711
   Chun SS, 2006, IEEE IMAGE PROC, P2025, DOI 10.1109/ICIP.2006.312844
   Chun SS, 2006, IEEE T CONSUM ELECTR, V52, P1303, DOI 10.1109/TCE.2006.273149
   Hong SH, 2003, IEEE T BROADCAST, V49, P1, DOI 10.1109/TBC.2003.808912
   Hu HM, 2012, IEEE T CIRC SYST VID, V22, P1564, DOI 10.1109/TCSVT.2012.2199398
   Jia YT, 2006, IEEE T CIRC SYST VID, V16, P820, DOI 10.1109/TCSVT.2006.877397
   Jing X, 2008, IEEE SIGNAL PROC LET, V15, P373, DOI 10.1109/LSP.2008.920010
   Jing XA, 2006, IEEE INT SYMP CIRC S, P5019
   Kuge T, 2002, IEEE INT C IM PROC I
   Lee B, 2014, IEEE T CIRC SYST VID, V24, P465, DOI 10.1109/TCSVT.2013.2276880
   Lee J, 2006, IEEE T CIRC SYST VID, V16, P1271, DOI 10.1109/TCSVT.2006.881856
   Lee YG, 2009, IEEE T CIRC SYST VID, V19, P747, DOI 10.1109/TCSVT.2009.2017413
   Leontaris A, 2006, IEEE INT C AC SPEECH
   Leontaris A, 2007, INT CONF ACOUST SPEE, P1117
   Li B, 2012, P 11 M JOINT COLL TE
   Li B, 2014, IEEE T IMAGE PROCESS, V23, P3841, DOI 10.1109/TIP.2014.2336550
   Li SX, 2015, SIGNAL PROCESS-IMAGE, V38, P127, DOI 10.1016/j.image.2015.04.011
   Li X, 2011, IEEE T CIRC SYST VID, V21, P957, DOI 10.1109/TCSVT.2011.2133750
   Li Y, 2014, SIGNAL PROCESSING IM
   Lin LJ, 1998, IEEE T CIRC SYST VID, V8, P446, DOI 10.1109/76.709411
   Lin LJ, 1997, VIDEO BIT RATE CONTR
   Liu S, 2005, IEEE T CIRC SYST VID, V15, P15, DOI 10.1109/TCSVT.2004.839996
   Matsumura A, 2005, PICTURE QUALITY APPL, P569
   Pan F, 2004, IEEE IMAGE PROC, P781
   Pang C, 2011, P IEEE INT WORKSH MU, P1
   Pang C, 2011, IEEE INT SYMP CIRC S, P2149
   Seo CW, 2013, IEEE T IMAGE PROCESS, V22, P2442, DOI 10.1109/TIP.2013.2251647
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tang CW, 2007, IEEE T MULTIMEDIA, V9, P231, DOI 10.1109/TMM.2006.886328
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Tian L, 2009, IEEE IMAGE PROC, P3445, DOI 10.1109/ICIP.2009.5413847
   Tsai WJ, 2010, IEEE T CIRC SYST VID, V20, P1882, DOI 10.1109/TCSVT.2010.2087473
   Vo DT, 2009, IEEE T IMAGE PROCESS, V18, P1166, DOI 10.1109/TIP.2009.2017341
   Wang MH, 2015, IEEE SIGNAL PROC LET, V22, P896, DOI 10.1109/LSP.2014.2377032
   Wang P, 2013, IEEE IMAGE PROC, P1986, DOI 10.1109/ICIP.2013.6738409
   Wang SS, 2013, IEEE J-STSP, V7, P1101, DOI 10.1109/JSTSP.2013.2272240
   Wang Y, 2009, 9 PAC RIM C MULT PCM, P935
   Wei ZY, 2009, IEEE T CIRC SYST VID, V19, P337, DOI 10.1109/TCSVT.2009.2013518
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Xiangfang Li., 2009, INT C E BUSINESS INF, P1, DOI DOI 10.1007/S00213-008-1432-0
   Yan B, 2012, IEEE T CIRC SYST VID, V22, P790, DOI 10.1109/TCSVT.2011.2180949
   Yan B, 2009, IEEE SIGNAL PROC LET, V16, P145, DOI 10.1109/LSP.2008.2010813
   Yang H, 2008, IEEE IMAGE PROC, P2868, DOI 10.1109/ICIP.2008.4712393
   Yang JX, 2010, IEEE T CIRC SYST VID, V20, P458, DOI 10.1109/TCSVT.2009.2035850
   Zhou M, 2014, ASIAPAC SIGN INFO PR
   Zhou YM, 2009, SIGNAL PROCESS-IMAGE, V24, P345, DOI 10.1016/j.image.2009.02.014
NR 56
TC 5
Z9 5
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2017
VL 76
IS 10
BP 12917
EP 12940
DI 10.1007/s11042-016-3666-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EV7DS
UT WOS:000401935200033
DA 2024-07-18
ER

PT J
AU Cai, ZQ
   Liang, YH
   Huang, H
AF Cai, Zhaoquan
   Liang, Yihui
   Huang, Han
TI Unsupervised segmentation evaluation: an edge-based method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image segmentation; Objective evaluation; Unsupervised evaluation
AB Unsupervised segmentation evaluation method quantifies the quality of segmentation without the reference segmentation or user assistance. Although some methods have been proposed to statistically analyze the pixel values, these methods are not sensitive enough to provide a metric of segmentation quality. This paper uses the image edge, a more robust feature, to measure the quality of segmentation. An edge-based segmentation evaluation method is introduced in this paper, which can be applied to both image and single region segmentation evaluation. The proposed method evaluates the quality of segmentation with three edge-based measures: the edge fitness, the intra-region edge error, and the out-of-bound error. These measures encourage the outline of segmentation to align with the edge and punish the segmentation that exceeds the edge. Experiments results show that our method is more sensitive to under-segmentation and over-segmentation. Using the parameters optimized by the proposed method, the segmentation produced by the classic region growing method is visually similar to the state-of-the-art segmentation method.
C1 [Cai, Zhaoquan] Huizhou Univ, Huizhou, Guangdong, Peoples R China.
   [Liang, Yihui] South China Univ Technol, Guangzhou, Guangdong, Peoples R China.
   [Huang, Han] South China Univ Technol, Sch Software Engn, Guangzhou, Guangdong, Peoples R China.
C3 Huizhou University; South China University of Technology; South China
   University of Technology
RP Liang, YH (corresponding author), South China Univ Technol, Guangzhou, Guangdong, Peoples R China.
EM yihuiliangchn@gmail.com
RI Zhang, Can/JUU-9511-2023
FU National Natural Science Foundation of China [61170193, 61370102,
   61370185]; Guangdong Natural Science Foundation [S2012010009865,
   S2012020011081, S2013010013432, S2013010015940, 2014A030306050]; Science
   and Technology Planning Project of Guangdong Province [2011B090400041,
   2012B010100039, 2012B040305011, 2012B010100040]; Education and Science
   Programs of Guangdong Province [11JXZ012, 14JXN065]; Guangdong Higher
   Education Discipline and Profession Special Fund Projects
   [2013KJCX0174]; Science and Technology Planning Project of Huizhou City
   [2011P002, 2011g012, 2011P005, 2011P003, 2011g011, 2013B020015008,
   2014B020004026]; Fundamental Research Funds for the Central
   Universities, SCUT [2015PT022]
FX This work is supported by National Natural Science Foundation of China
   (61170193, 61370102, 61370185), Guangdong Natural Science Foundation
   (S2012010009865, S2012020011081, S2013010013432, S2013010015940,
   2014A030306050), Science and Technology Planning Project of Guangdong
   Province (2011B090400041, 2012B010100039, 2012B040305011,
   2012B010100040), Education and Science Programs of Guangdong Province
   (11JXZ012,14JXN065), Guangdong Higher Education Discipline and
   Profession Special Fund Projects(2013KJCX0174), Science and Technology
   Planning Project of Huizhou City (2011P002, 2011g012, 2011P005,
   2011P003, 2011g011, 2013B020015008, 2014B020004026) and the Fundamental
   Research Funds for the Central Universities, SCUT (2015PT022).
CR [Anonymous], IEEE T NEURAL NETW L
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587420
   [Anonymous], 2007, BRIT MACH VIS C BMVC
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chabrier S, 2006, EURASIP J APPL SIG P, P217
   Chen HC, 2004, IEEE INT C AC SPEECH, V3
   Corcoran P, 2010, INT J REMOTE SENS, V31, P617, DOI 10.1080/01431160902894475
   Donoser M, 2014, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2014.404
   Kim TH, 2013, IEEE T PATTERN ANAL, V35, P1690, DOI 10.1109/TPAMI.2012.237
   LEVINE MD, 1985, IEEE T PATTERN ANAL, V7, P155, DOI 10.1109/TPAMI.1985.4767640
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Miao QG, 2011, OPT COMMUN, V284, P1540, DOI 10.1016/j.optcom.2010.11.048
   Miao QG, 2013, IEEE T IMAGE PROCESS, V22, P1546, DOI 10.1109/TIP.2012.2233487
   Sobel I., 1968, STANF ART PROJ, P271
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Zhang H, 2004, P SOC PHOTO-OPT INS, V5307, P38
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
   Zhang XL, 2012, IEEE GEOSCI REMOTE S, V9, P156, DOI 10.1109/LGRS.2011.2163056
NR 20
TC 1
Z9 2
U1 5
U2 45
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 8
BP 11097
EP 11110
DI 10.1007/s11042-016-3542-8
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ET8SE
UT WOS:000400570400045
DA 2024-07-18
ER

PT J
AU Islam, MB
   Lai-Kuan, W
   Chee-Onn, W
AF Islam, Md Baharul
   Lai-Kuan, Wong
   Chee-Onn, Wong
TI A survey of aesthetics-driven image recomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computational photography; Image aesthetics; Image enhancement; Image
   recomposition; Photographic composition rules
ID PHOTO COMPOSITION; ENHANCEMENT; QUALITY
AB The advancement of digital photography and the popularity of photo sharing social media such as Instagram and Facebook have undoubtedly stimulated growing interest in aesthetics quality improvement. One aspect of photography that contributes to high quality photos is image composition; the spatial arrangement of photo subjects in the image frame. Professional photographers often apply a wealth of photographic composition rules, e.g., rule of thirds, visual balance and simplicity to capture compelling photos. In the recent years, aesthetics-driven recomposition that attempts to computationally modify the composition of an image to mimic a professional photo has started to receive considerable research interest. Researchers have proposed numerous recomposition techniques that utilize a single or a combination of multiple image operators, i.e., cropping, warping and patch rearrangement operators, to modify the composition of an image. In this paper, we present a survey on the state-of-the-arts aesthetic-driven image recomposition. We define the image recomposition problem, outline its objectives, and provide a comprehensive review of the existing image recompositoin techniques, together with a detailed analysis of the effectiveness of each technique in achieving the recomposition objectives. This survey is intended as a good reference for researchers interested in image recomposition.
C1 [Islam, Md Baharul; Lai-Kuan, Wong; Chee-Onn, Wong] Multimedia Univ, Cyberjaya 63100, Selangor, Malaysia.
C3 Multimedia University
RP Islam, MB; Lai-Kuan, W (corresponding author), Multimedia Univ, Cyberjaya 63100, Selangor, Malaysia.
EM bahar_mag@yahoo.com; lkwong@mmu.edu.my
RI Wong, Lai Kuan/AAO-7014-2021; Wong, Chee Onn/AGW-5722-2022; Islam, Md
   Baharul/R-3751-2019
OI Wong, Lai Kuan/0000-0002-4517-0391; Islam, Md
   Baharul/0000-0002-9928-5776
FU Fundamental Research Grant Scheme (FRGS) [EP20130326018]; Multimedia
   University (MMU) [IP20131108001]
FX The authors would like to thank all anonymous photographers who shared
   their photos in Flickr (license free). This work is supported by the
   Fundamental Research Grant Scheme (FRGS), Grant No. EP20130326018 and
   Multimedia University (MMU) Internal Grant, No IP20131108001.
CR [Anonymous], AS C COMP VIS
   [Anonymous], 2013, P 21 ACM INT C MULT
   [Anonymous], WORKSH COMP ATT APPL
   [Anonymous], 2012, P 30 COMP GRAPH INT
   [Anonymous], 2007, 2007 IEEE 11 INT C C, DOI DOI 10.1109/ICCV.2007.4409010
   Avidan S, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239461
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Bhattacharya S, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037678
   Chang HT, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P957, DOI 10.1145/2647868.2654976
   Chang HT, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P927, DOI 10.1145/2733373.2806366
   Cho TS, 2010, IEEE T PATTERN ANAL, V32, P1489, DOI 10.1109/TPAMI.2009.133
   Cho Taeg Sang, 2008, PROC IEEE C COMPUT V, P1
   Cour T., 2007, P NIPS, P1
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Fang C, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1105, DOI 10.1145/2647868.2654979
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Greco L, 2013, LECT NOTES COMPUT SC, V8157, P151, DOI 10.1007/978-3-642-41184-7_16
   Guo YW, 2012, COMPUT GRAPH FORUM, V31, P2193, DOI 10.1111/j.1467-8659.2012.03212.x
   Hsu CC, 2014, IEEE J-STSP, V8, P377, DOI 10.1109/JSTSP.2014.2311884
   Islam MB, 2015, AS C PATT REC ACPR
   Jin Y, 2012, COMPUT GRAPH-UK, V36, P955, DOI 10.1016/j.cag.2012.07.007
   Ke Y., 2006, P IEEE COMP SOC C CO, V1, P419, DOI DOI 10.1109/CVPR.2006.303
   Li K, 2015, SIGNAL PROCESS-IMAGE, V39, P509, DOI 10.1016/j.image.2015.07.005
   Liu L, 2010, J MATER SCI TECHNOL, V26, P1, DOI 10.1016/S1005-0302(10)60001-1
   Liu LG, 2010, COMPUT GRAPH FORUM, V29, P469, DOI 10.1111/j.1467-8659.2009.01616.x
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Luo YW, 2008, LECT NOTES COMPUT SC, V5304, P386
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Park J, 2012, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP.2012.6467466
   Pritch Y, 2009, IEEE I CONF COMP VIS, P151, DOI 10.1109/ICCV.2009.5459159
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Samii A, 2015, COMPUT GRAPH FORUM, V34, P141, DOI 10.1111/cgf.12465
   Santella A., 2006, Conference on Human Factors in Computing Systems. CHI2006, P771
   Suh Bongwon, 2003, P ACM S US INT SOFTW, P95, DOI DOI 10.1145/964696.964707
   Tian XM, 2015, IEEE T MULTIMEDIA, V17, P2035, DOI 10.1109/TMM.2015.2479916
   Wong L.-K., 2012, PROC 20 ACM INT C MU, P845
   Wong LK, 2009, IEEE IMAGE PROC, P997, DOI 10.1109/ICIP.2009.5413825
   Yan JZ, 2013, PROC CVPR IEEE, P971, DOI 10.1109/CVPR.2013.130
   Zhang FL, 2013, IEEE T MULTIMEDIA, V15, P1480, DOI 10.1109/TMM.2013.2268051
   Zhang MJ, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P438
NR 43
TC 15
Z9 25
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9517
EP 9542
DI 10.1007/s11042-016-3561-5
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300019
DA 2024-07-18
ER

PT J
AU Su, ZP
   Chang, LJ
   Zhang, GF
   Jiang, JG
   Yue, F
AF Su, Zhaopin
   Chang, Lejie
   Zhang, Guofu
   Jiang, Jianguo
   Yue, Feng
TI Window switching strategy based semi-fragile watermarking for MP3 tamper
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tamper detection; MP3; Semi-fragile watermarking; Window switching
ID AUDIO WATERMARKING; SCHEME; TRANSFORM; H.264/AVC; BLIND
AB MP3 is a promising carrier format for covert communication, and how to secure its fidelity and integrity is a significant problem. In this paper, we propose a semi-fragile MP3 watermarking method for tamper detection by exploiting the rule of window switching during encoding. The method carries out embedding by establishing a mapping relationship between the type of window and the MD5 of authentication information. Moreover, we design a tamper detection method by analysing the watermark bits sequence. The experimental results show the effectiveness of the proposed method in terms of accuracy for tamper detection, time efficiency, imperceptibility and advisable robustness with compressed MP3 audio.
C1 [Su, Zhaopin; Chang, Lejie; Zhang, Guofu; Jiang, Jianguo; Yue, Feng] Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
C3 Hefei University of Technology
RP Su, ZP (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Hefei 230009, Peoples R China.
EM szp@hfut.edu.cn
RI Yue, Feng/S-6565-2017
FU National Natural Science Foundation of China [61573125, 61371155]; Anhui
   Provincial Natural Science Foundation [1608085MF131, 1508085MF132,
   1508085QF129]
FX This work was partially supported by the National Natural Science
   Foundation of China under Grants 61573125 and 61371155, and the Anhui
   Provincial Natural Science Foundation under Grants 1608085MF131,
   1508085MF132, and 1508085QF129. The authors would like to thank the
   Editors and anonymous referees for their comments and suggestions. They
   would also like to thank Dr. X. Liu for his help in academic writing.
CR [Anonymous], 2000, Digital Watermarking
   Brandenburg  K., 1992, AUD ENG SOC C 11 INT
   Chen F, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 5, PROCEEDINGS, P135, DOI 10.1109/CISP.2008.298
   Cvejic N, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P151
   Di Martino F, 2012, INFORM SCIENCES, V195, P62, DOI 10.1016/j.ins.2012.01.014
   Erfani Y, 2013, IEEE GLOB CONF SIG, P249, DOI 10.1109/GlobalSIP.2013.6736862
   Fan MQ, 2013, INT J COMPUT MATH, V90, P2588, DOI 10.1080/00207160.2013.805752
   Ghobadi A, 2013, INT CONF ADV COMMUN, P1077
   Ghosal SK, 2014, J INF SECUR APPL, V19, P272, DOI 10.1016/j.jisa.2014.07.004
   Hong Zhao, 2010, 2010 IEEE International Conference on Information Theory and Information Security, P807, DOI 10.1109/ICITIS.2010.5689694
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   International Telecommunication Union, 1998, 13871 ITURBS, P1387
   ISO/IEC, 1993, 111723 ISOIEC
   Lei BY, 2011, SIGNAL PROCESS, V91, P1973, DOI 10.1016/j.sigpro.2011.03.001
   Li J, 2014, MULTIMED TOOLS APPL, V68, P571, DOI 10.1007/s11042-012-1058-4
   Liu F, 2012, INFORM SECURITY THEO, P49
   Megias D, 2003, ADV TECHNIQUES NETWO
   PETITCOLAS FAP, 2004, STIRMARK BENCHMARK 4
   Preda RO, 2013, MEASUREMENT, V46, P367, DOI 10.1016/j.measurement.2012.07.010
   Quan XM, 2004, INT C PATT RECOG, P867, DOI 10.1109/ICPR.2004.1334396
   Rivest Ronald, 2004, RFC1321 INT ENG TASK
   Su PC, 2011, SIGNAL PROCESS-IMAGE, V26, P413, DOI 10.1016/j.image.2011.07.004
   Tong XJ, 2013, SIGNAL PROCESS-IMAGE, V28, P301, DOI 10.1016/j.image.2012.12.003
   Unoki M., 2012, 2012 Eighth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIH-MSP), P118, DOI 10.1109/IIH-MSP.2012.34
   Wang CC, 2010, DIGIT SIGNAL PROCESS, V20, P780, DOI 10.1016/j.dsp.2009.10.005
   Wang HX, 2010, SCI CHINA INFORM SCI, V53, P619, DOI 10.1007/s11432-010-0058-0
   Wang J, 2011, SIGNAL PROCESS, V91, P1693, DOI 10.1016/j.sigpro.2011.01.014
   Wang XY, 2011, J SYST SOFTWARE, V84, P1408, DOI 10.1016/j.jss.2011.03.033
   Wang XJ, 2012, PHYSCS PROC, V25, P1264, DOI 10.1016/j.phpro.2012.03.231
   Wang XY, 2005, LECT NOTES COMPUT SC, V3494, P19
   Xu DW, 2011, SIGNAL PROCESS-IMAGE, V26, P267, DOI 10.1016/j.image.2011.04.008
   Yan DQ, 2012, COMPUT SECUR, V31, P704, DOI 10.1016/j.cose.2012.04.006
   Yan DQ, 2011, MULTIMED TOOLS APPL, V52, P291, DOI 10.1007/s11042-009-0430-5
   You JY, 2010, SIGNAL PROCESS-IMAGE, V25, P482, DOI 10.1016/j.image.2010.02.002
   Yu D, 2006, PATTERN RECOGN, V39, P935, DOI 10.1016/j.patcog.2005.11.023
   Zhang JZ, 2011, 2011 INTERNATIONAL FORUM ON BIOMEDICAL TEXTILE MATERIALS, PROCEEDINGS, P333
NR 36
TC 6
Z9 6
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2017
VL 76
IS 7
BP 9363
EP 9386
DI 10.1007/s11042-016-3539-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TL
UT WOS:000399016300011
DA 2024-07-18
ER

PT J
AU Kumar, GVS
   Vasuki, S
AF Kumar, Veera Senthil G.
   Vasuki, S.
TI Clustering based band selection for endmember extraction using simplex
   growing algorithm in hyperspectral images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Virtual dimensionality; Band selection;
   K-means; Endmember extraction; SGA; FCLS
AB With the advancement in technology, hyperspectral images have potential applications in the field of remote sensing due to their high spectral resolution. Despite the hyperspectral image providing abundant information, its analysis suffers from the problem of high dimensionality. Hence, Dimensionality Reduction (DR) is an essential task in all hyperspectral image analysis. Band Selection, which is one of the DR techniques, is still a challenging issue even though many algorithms have been developed. To provide remedy for this issue, this paper explores a novel approach for band selection using K-means clustering on statistical feature in hyperspectral images. The proposed method of clustering based band selection for DR is simple and accurate. A reliable estimate of number of bands to be selected is provided by Virtual Dimensionality (VD). Informative bands preserving maximum information are selected based on the statistical feature, the variance using K-means Clustering technique. Further, our proposed work involves the utilization of the effectiveness of Simplex Growing Algorithm (SGA) on endmember extraction in association with clustering based band selection. Using Fully Constrained Least Squares (FCLS) method, abundance fraction is estimated based on endmember signatures, which are derived using Endmember Extraction Algorithm (EEA). The proposed work is investigated and compared with that of N-FINDR and Vertex Component Analysis (VCA) algorithms. The performance of the proposed algorithm is evaluated using Root Mean Square Error (RMSE), Spectral Angle Distance (SAD) and computation time. Experimental results show that the proposed clustering based band selection with SGA endmember extraction algorithm reduces the average SAD by 8 to 10 % and the average RMSE by nearly 1 %, compared to that of N-FINDR and VCA algorithms. In terms of computation time, the proposed band selection based DR with SGA algorithm is seven times faster than conventional transform based DR with SGA algorithm.
C1 [Kumar, Veera Senthil G.; Vasuki, S.] Velammal Coll Engn & Technol, ECE Dept, Madurai, Tamil Nadu, India.
RP Kumar, GVS (corresponding author), Velammal Coll Engn & Technol, ECE Dept, Madurai, Tamil Nadu, India.
EM gvs@vcet.ac.in; sv@vcet.ac.in
RI ECE0909, Dr. Vasuki.S/ABG-3155-2021
OI ECE0909, Dr. Vasuki.S/0000-0003-0815-6424
CR Ahmad M., 2011, Int. J. Eng. Technol., V3, P606
   [Anonymous], 2013, OVERVIEW HYPERSPECTR
   [Anonymous], 1993, P 9 THEM C GEOL REM
   Asl MG, 2014, IEEE T GEOSCI REMOTE, V52, P3774, DOI 10.1109/TGRS.2013.2275831
   Chang C. I., 2003, HYPERSPECTRAL IMAGIN
   Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P2804, DOI 10.1109/TGRS.2006.881803
   Chang CI, 2006, IEEE T GEOSCI REMOTE, V44, P1575, DOI 10.1109/TGRS.2006.864389
   Chang CI, 2013, IEEE T GEOSCI REMOTE, V51, P1693, DOI 10.1109/TGRS.2012.2207389
   Chang CI, 2010, IEEE T GEOSCI REMOTE, V48, P1834, DOI 10.1109/TGRS.2009.2034979
   Chang CI, 1999, IEEE T GEOSCI REMOTE, V37, P2631, DOI 10.1109/36.803411
   Chang CI, 2004, IEEE T GEOSCI REMOTE, V42, P608, DOI 10.1109/TGRS.2003.819189
   Du Q, 2008, IEEE GEOSCI REMOTE S, V5, P564, DOI 10.1109/LGRS.2008.2000619
   Geng XR, 2014, IEEE T GEOSCI REMOTE, V52, P7111, DOI 10.1109/TGRS.2014.2307880
   HARSANYI JC, 1994, IEEE T GEOSCI REMOTE, V32, P779, DOI 10.1109/36.298007
   HASKELL KH, 1981, MATH PROGRAM, V21, P98, DOI 10.1007/BF01584232
   Heinz DC, 2001, IEEE T GEOSCI REMOTE, V39, P529, DOI 10.1109/36.911111
   Lawson C L, 1995, SOLVING LEAST SQUARE, P15
   Martinez-Uso A, 2007, IEEE T GEOSCI REMOTE, V45, P4158, DOI 10.1109/TGRS.2007.904951
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Nascimento JMP, 2005, IEEE T GEOSCI REMOTE, V43, P898, DOI 10.1109/TGRS.2005.844293
   Qian Y, 2009, IET COMPUT VIS, V3, P213, DOI 10.1049/iet-cvi.2009.0034
   Sohaib Muhammad, 2013, International Journal of Computer and Communication Engineering, V2, P101
   Sun K, 2014, IEEE J-STARS, V7, P2697, DOI 10.1109/JSTARS.2014.2320299
   Winter ME, 1999, PROC SPIE, V3753, P266, DOI 10.1117/12.366289
   Zhu FY, 2014, IEEE T IMAGE PROCESS, V23, P5412, DOI 10.1109/TIP.2014.2363423
   Zhu FY, 2014, ISPRS J PHOTOGRAMM, V88, P101, DOI 10.1016/j.isprsjprs.2013.11.014
NR 26
TC 13
Z9 13
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8355
EP 8371
DI 10.1007/s11042-016-3420-4
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800033
DA 2024-07-18
ER

PT J
AU Lai, DH
   Chen, YW
   Luo, XY
   Du, JX
   Wang, T
AF Lai, Dehe
   Chen, Yewang
   Luo, Xiangyu
   Du, Jixiang
   Wang, Tian
TI Age estimation with dynamic age range
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Age estimation; Density peak; Local binary pattern(LBP); Confidence
   interval/confidence level
ID CLASSIFICATION
AB Age estimation has been widely used and became more and more important, for its usefulness in various applications. However, accurately predict the age for an unlabeled image is difficult, because there are many factors that have impact on the appearance of a person. Some people look younger than his/her true age, while the others look much older. Therefore, predict an age group or a specific age for a facial image is not good enough. In this paper, we propose a new method to estimate the age of facial image into a dynamic range or a discrete age set rather than a single age or age group. Furthermore, we introduce a new measurement, i. e. Confidence Interval/Confidence Level to evaluate the performance of proposed method. Our experimental results show that the proposed method is promising.
C1 [Lai, Dehe; Chen, Yewang; Luo, Xiangyu; Du, Jixiang; Wang, Tian] Huaqiao Univ Xiamen, Coll Comp Sci & Technol, Xiamen, Peoples R China.
C3 Huaqiao University
RP Chen, YW; Luo, XY; Du, JX (corresponding author), Huaqiao Univ Xiamen, Coll Comp Sci & Technol, Xiamen, Peoples R China.
EM 1300220009@hqu.edu.cn; ywchen@hqu.edu.cn; luoxy@hqu.edu.cn;
   jxdu@hqu.edu.cn
RI Chen, Yewang/AAN-6803-2020
OI Chen, Yewang/0000-0001-9691-0807
FU National Natural Science Foundation of China [61170028, 61572206,
   61175121, 51305142]; Program for New Century Excellent Talents in Fujian
   Province University [2013FJ-NCET-ZR03]; Grant of the National Science
   Foundation of Fujian Province [2013J06014]; Promotion Program for Young
   and Middle-aged Teacher in Science and Technology Research of Huaqiao
   University [ZQNYX109, ZQNYX108]
FX This work is supported by National Natural Science Foundation of China
   (No. 61170028,61572206,61175121,51305142); Program for New Century
   Excellent Talents in Fujian Province University (No. 2013FJ-NCET-ZR03);
   the Grant of the National Science Foundation of Fujian Province (No.
   2013J06014); Promotion Program for Young and Middle-aged Teacher in
   Science and Technology Research of Huaqiao University (No. ZQNYX109,
   ZQNYX108).
CR [Anonymous], 2008, P 2008 23 INT S COMP
   [Anonymous], 2009, 2009 IEEE 3 INT C BI, DOI DOI 10.1109/BTAS.2009.5339053
   [Anonymous], INT J APPL MATH MACH
   [Anonymous], P 8 IEEE INT C AUT F
   [Anonymous], 2007, P IEEE 11 INT C COMP
   [Anonymous], 2005, P 12 INT C NEUR INF
   Chen Y, 2015, CHEM ENG SCI, V132, P1, DOI 10.1016/j.ces.2015.04.006
   Chen YL, 2013, IEEE T INF FOREN SEC, V8, P2164, DOI 10.1109/TIFS.2013.2286265
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fukai Hironobu, 2007, 2007 International Conference on Control, Automation and Systems - ICCAS '07, P2146
   Gao F, 2009, LECT NOTES COMPUT SC, V5558, P132
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Liu KH, 2014, IEEE WINT CONF APPL, P445, DOI 10.1109/WACV.2014.6836068
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Ricanek K, IEEE INT C AUT FAC G
   Rodriguez A, 2014, SCIENCE, V344, P1492, DOI 10.1126/science.1242072
   Wang XL, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P309, DOI 10.1109/ICMLA.2013.141
NR 23
TC 5
Z9 5
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6551
EP 6573
DI 10.1007/s11042-015-3230-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400021
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Lin, TL
   Chou, CC
AF Liu, Zhaoyi
   Lin, Ting-Lan
   Chou, Chi-Chan
TI HEVC coding-unit decision algorithm using tree-block classification and
   statistical data analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC (high-efficiency video coding); CU (coding unit) decision; Early
   termination algorithm; Statistical analysis; LCU (largest coding unit)
   classification
ID MODE DECISION; STANDARD
AB We propose a fast coding unit (CU) depth decision algorithm in the High Efficiency Video Coding (HEVC) procedure based on statistical analysis. First, we derive a set of optimized weights of surrounding CU decisions to predict the current CU decision for 3 different Largest Coding Unit (LCU) classes. Second, for a given predicted current CU decision, we analyze the possible true current CU decisions, aiming to find the correspondence. A corresponding table is found and can be used to achieve target prediction accuracy. Third, for early termination of the encoding processes, the 3 early termination methods in a state-of-the-art work, as well as their different combinations, are evaluated. We show that using one of them is sufficient for saving time while encoding to keep the implementation complexity low. Compared with full CU search in HEVC standards, the proposed method reduces the encoding time by 57 and 49 % on average with Low Delay and Random Access profiles, respectively, with acceptable bitrate and PSNR performances. Compared with two state-of-the-art methods, the encoding time reduction is up to 23 and 13 % with Low Delay profile, 7 and 3 % with Random Access profile, on average, whereas the performances of bitrate and PSNR are similar.
C1 [Liu, Zhaoyi] Beijing Inst Technol, Sch Informat & Elect, 5 Zhongguancunnan St, Beijing 100081, Peoples R China.
   [Lin, Ting-Lan; Chou, Chi-Chan] Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
C3 Beijing Institute of Technology; Chung Yuan Christian University
RP Lin, TL (corresponding author), Chung Yuan Christian Univ, Dept Elect Engn, 200 Zhongbei Rd, Zhongli City 320, Taoyuan County, Taiwan.
EM 20091305@bit.edu.cn; tinglan@cycu.edu.tw
FU National Science Council, Taiwan [NSC 101-2221-E-033-036, NSC
   102-2221-E-033-018]; Ministry of Science and Technology, Taiwan [MOST
   103-2221-E-033-020, MOST 104-2221-E-033-041, MOST 104-2218-E-033-010]
FX This research is supported by the National Science Council, Taiwan,
   under Grants NSC 101-2221-E-033-036 and NSC 102-2221-E-033-018, and by
   the Ministry of Science and Technology, Taiwan, under Grant MOST
   103-2221-E-033-020, MOST 104-2221-E-033-041 and MOST 104-2218-E-033-010.
CR [Anonymous], 2001, ITU-T SG16/Q6
   [Anonymous], 2011, JCTVCF900
   Cassa MB, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P493, DOI 10.1109/PCS.2012.6213262
   Choi K, 2011, SG16WP3 ITUT
   Correa G, 2013, 2013 IEEE EUROCON, P81, DOI 10.1109/EUROCON.2013.6624969
   Correa G, 2013, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2013.12
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Kim IK, 2012, IEEE T CIRC SYST VID, V22, P1697, DOI 10.1109/TCSVT.2012.2223011
   Kim J, 2013, IEEE ICCE, P637, DOI 10.1109/ICCE.2013.6487050
   Pan ZQ, 2014, IEEE T BROADCAST, V60, P405, DOI 10.1109/TBC.2014.2321682
   Pateux S., 2007, SG16Q6 ITUT
   Sangsoo A., 2015, CIRCUITS SYSTEMS VID, V25, P422
   Shen LQ, 2014, IEEE T CIRC SYST VID, V24, P1709, DOI 10.1109/TCSVT.2014.2313892
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tan HL, 2012, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.2012.6288011
   Vanne J, 2014, IEEE T CIRC SYST VID, V24, P1579, DOI 10.1109/TCSVT.2014.2308453
   Wiegand T, 2010, IEEE T CIRC SYST VID, V20, P1661, DOI 10.1109/TCSVT.2010.2095692
   Zhang YF, 2013, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2013.13
   Zhang Y, 2015, IEEE T IMAGE PROCESS, V24, P2225, DOI 10.1109/TIP.2015.2417498
NR 20
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 9051
EP 9072
DI 10.1007/s11042-016-3530-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800064
DA 2024-07-18
ER

PT J
AU Mao, JF
   Sheng, WG
   Hu, YH
   Xiao, G
   Qu, ZG
   Niu, XX
   Zhu, LN
AF Mao, Jia-Fa
   Sheng, Wei-Guo
   Hu, Ya-Hong
   Xiao, Gang
   Qu, Zhi-Guo
   Niu, Xin-Xin
   Zhu, Li-Nan
TI Research on watermarking payload under the condition of keeping JPEG
   image transparency
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transparency; Watermarking payload; Image complexity; Visual
   sensitivity; Embedding intensity
ID FRAGILE WATERMARKING
AB This work focuses on the problem of maximum watermarking payload under the condition of keeping image transparency. The maximum watermarking payload of JPEG images is influenced by internal factors such as the size, complexity and visual sensitivity of images, as well as external factors including embedding operators, carrier frequency bands and embedding intensity, etc. Through the construction of payload mathematical model, theoretic analysis and experimental derivation we propose an estimation method of maximum watermarking payload based on the DCT coefficients. The feasibility and efficiency of the proposed method has been demonstrated in our experiments by adopting two embedding operators and three carrier frequency bands. Our results show, in comparison with previously related work, the proposed method can be more practical.
C1 [Mao, Jia-Fa; Sheng, Wei-Guo; Hu, Ya-Hong; Xiao, Gang; Zhu, Li-Nan] ZheJiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
   [Qu, Zhi-Guo] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Qu, Zhi-Guo] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Niu, Xin-Xin] Beijing Univ Posts & Telecommun, Informat Secur Ctr, Beijing 100876, Peoples R China.
C3 Zhejiang University of Technology; Nanjing University of Information
   Science & Technology; Nanjing University of Information Science &
   Technology; Beijing University of Posts & Telecommunications
RP Mao, JF (corresponding author), ZheJiang Univ Technol, Coll Comp Sci & Technol, Hangzhou 310023, Zhejiang, Peoples R China.
EM maojiafa@zjut.edu.cn; wsheng@zjut.edu.cn; huyahong@zjut.edu.cn;
   xg@zjut.edu.cn; qzghhh@126.com; xxniu@bupt.edu.cn; zln@zjut.edu.cn
RI Qu, Zhiguo/N-9008-2015
OI Mao, Jiafa/0000-0002-2777-8803
FU National Natural Science Foundation of China [61573316, 61373131,
   61272310, 61170271]; ZheJiang province Natural Science Foundation of
   China [LY15F020032, LQ15E050006]; PAPD; CICAEET
FX This work is supported by the National Natural Science Foundation of
   China (No. 61573316, 61373131, 61272310, 61170271) and the ZheJiang
   province Natural Science Foundation of China (No. LY15F020032,
   LQ15E050006), PAPD, and CICAEET.
CR Al-Otum HM, 2014, J VIS COMMUN IMAGE R, V25, P1064, DOI 10.1016/j.jvcir.2013.12.017
   Ali M, 2014, ENG APPL ARTIF INTEL, V31, P15, DOI 10.1016/j.engappai.2013.07.009
   [Anonymous], 2002, QUEST ITU R 211 11 M, P31
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Cohen AS, 2002, IEEE T INFORM THEORY, V48, P1639, DOI 10.1109/TIT.2002.1003844
   Delaigle JF, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA489
   Eichkitz CG, 2013, COMPUT GEOSCI-UK, V60, P176, DOI 10.1016/j.cageo.2013.07.006
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Guitart O, 2006, P SPIE INT C SEC WAT
   Han QL, 2014, J VIS COMMUN IMAGE R, V25, P1044, DOI 10.1016/j.jvcir.2014.03.001
   Hu HT, 2014, DIGIT SIGNAL PROCESS, V31, P115, DOI 10.1016/j.dsp.2014.04.014
   Hu HT, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-12
   Jamzad M., 2006, SCIENTIA IRANICA JOU, V13, P404
   Ker AD, 2007, IEEE SIGNAL PROC LET, V14, P525, DOI 10.1109/LSP.2006.891319
   Khan A, 2014, INFORM SCIENCES, V279, P251, DOI 10.1016/j.ins.2014.03.118
   Kim HC, 2005, P SPIE INT C SEC WAT
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   [李晟 LI Sheng], 2007, [中国图象图形学报, Journal of Image and Graphics], V12, P212
   Li XW, 2014, OPT COMMUN, V319, P45, DOI 10.1016/j.optcom.2013.12.089
   Lie WN, 2005, IEEE T MULTIMEDIA, V7, P1007, DOI 10.1109/TMM.2005.858377
   Liu KC, 2014, IET IMAGE PROCESS, V8, P363, DOI 10.1049/iet-ipr.2013.0284
   Liu QZ, 2010, INFORM SCIENCES, V180, P1643, DOI 10.1016/j.ins.2010.01.001
   Mao JF, 2011, EURASIP J INF SECUR, DOI 10.1155/2011/502748
   Moulin P, 2003, IEEE T INFORM THEORY, V49, P563, DOI 10.1109/TIT.2002.808134
   Moulin P, 2005, P IEEE, V93, P2083, DOI 10.1109/JPROC.2005.859599
   Piper A, 2013, IET INFORM SECUR, V7, P300, DOI 10.1049/iet-ifs.2010.0059
   Sajedi H, 2009, INT J INF SECUR, V8, P433, DOI 10.1007/s10207-009-0089-y
   Singh C, 2014, IET IMAGE PROCESS, V8, P373, DOI 10.1049/iet-ipr.2013.0382
   Somekh-Baruch A, 2004, IEEE T INFORM THEORY, V50, P511, DOI 10.1109/TIT.2004.824920
   Urvoy M, 2014, IEEE T INF FOREN SEC, V9, P1108, DOI 10.1109/TIFS.2014.2322497
   Wang Xiang-Yang, 2010, Acta Automatica Sinica, V36, P1489, DOI 10.3724/SP.J.1004.2010.01489
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Xia ZH, 2014, SECUR COMMUN NETW, V7, P1283, DOI 10.1002/sec.864
   Zhang Y, 2015, PROCEEDINGS 10TH INTERNATIONAL CONFERENCE ON AVAILABILITY, RELIABILITY AND SECURITY ARES 2015, P461, DOI 10.1109/ARES.2015.53
   Zhao GH, 2013, IET SIGNAL PROCESS, V7, P791, DOI 10.1049/iet-spr.2012.0329
NR 35
TC 1
Z9 1
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8423
EP 8448
DI 10.1007/s11042-016-3477-0
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800036
DA 2024-07-18
ER

PT J
AU Moustakas, K
   Lalos, AS
AF Moustakas, Konstantinos
   Lalos, Aris S.
TI An information-theoretic treatment of passive haptic media
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Haptic rendering; Information theory; Haptic information loss; Haptic
   filter; Haptic coding
ID TELEPRESENCE; SYSTEMS
AB Haptic rendering has been long considered as the process of estimating the force that stems from the interaction of a user and an object. Even if this approach follows the principles of natural haptic interaction, it places severe limitations in processing haptic media. This paper presents an information theoretic framework that aims to provide a new view of haptic rendering that can accommodate for open-loop synthetic haptic media, where interaction-based rendering is a special case. As a result, using the proposed information-theoretic approach, the haptic signal can be precomputed as a force field, stored and then filtered by taking into account device and perceptual capabilities of the receiver in order to lower the required bandwidth of the resulting stream, thus opening new possibilities for the representation and processing of haptic media.
C1 [Moustakas, Konstantinos; Lalos, Aris S.] Univ Patras, Elect & Comp Engn Dept, GR-26500 Patras, Greece.
C3 University of Patras
RP Moustakas, K (corresponding author), Univ Patras, Elect & Comp Engn Dept, GR-26500 Patras, Greece.
EM moustakas@upatras.gr; aris.lalos@ece.upatras.gr
RI Lalos, Aris/W-6443-2019
OI Lalos, Aris/0000-0003-0511-9302; Moustakas,
   Konstantinos/0000-0001-7617-227X
CR [Anonymous], 2008, HAPTIC RENDERING FDN
   Borst CW, 2005, World Haptics Conference: First Joint Eurohaptics Conference and Symposium on Haptic Interfaces for Virutual Environment and Teleoperator Systems, Proceedings, P596
   Cha J, 2009, IEEE MULTIMEDIA, V16, P16, DOI 10.1109/MMUL.2009.42
   El Saddik A, 2007, IEEE T INSTRUM MEAS, V56, P895, DOI 10.1109/TIM.2006.887174
   El Saddik A, 2007, IEEE INSTRU MEAS MAG, V10, P10, DOI 10.1109/MIM.2007.339540
   Guruswamy VL, 2011, IEEE T INSTRUM MEAS, V60, P93, DOI 10.1109/TIM.2010.2065751
   Hamam A, 2013, IEEE T INSTRUM MEAS, V62, P3315, DOI 10.1109/TIM.2013.2272859
   Hayward V, 2011, PHILOS T R SOC B, V366, P3115, DOI 10.1098/rstb.2011.0150
   Hinterseer P, 2008, IEEE T SIGNAL PROCES, V56, P588, DOI 10.1109/TSP.2007.906746
   Hirche S, 2005, IEEE INTL CONF CONTR, P328
   Hossain SKA, 2011, IEEE T INSTRUM MEAS, V60, P3547, DOI 10.1109/TIM.2011.2161148
   Kim M, 2014, IEEE T HAPTICS, V7, P394, DOI 10.1109/TOH.2013.58
   Kostopoulos K, 2007, J MULTIMODAL USER IN, V1, P13, DOI 10.1007/BF02910055
   Kron A, 2004, IEEE INT CONF ROBOT, P1968, DOI 10.1109/ROBOT.2004.1308112
   Kuschel M, 2009, IEEE T SYST MAN CY A, V39, P1142, DOI 10.1109/TSMCA.2009.2027219
   Laycock S. D., 2007, Computer Graphics Forum, V26, P50, DOI 10.1111/j.1467-8659.2007.00945.x
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Vu MH, 2011, IEEE T INSTRUM MEAS, V60, P3510, DOI 10.1109/TIM.2011.2164285
   Moustakas K, 2005, IEEE T CIRC SYST VID, V15, P1065, DOI 10.1109/TCSVT.2005.852401
   Moustakas K, 2013, IEEE INT S HAPT AUD
   Moustakas K, 2007, IEEE MULTIMEDIA, V14, P62, DOI 10.1109/MMUL.2007.10
   Moustakas K, 2007, IEEE T VIS COMPUT GR, V13, P80, DOI 10.1109/TVCG.2007.20
   Nikolakis G, 2006, WILEY ENCY BIOMEDICA
   Ortega A, 2002, PREN HAL IMSC P MULT, P119
   Ou E, 2002, P NAT C UND RES WHIT
   Robles-De-La-Torre G, 2006, IEEE MULTIMEDIA, V13, P24, DOI 10.1109/MMUL.2006.69
   Sakr N, 2011, IEEE T INSTRUM MEAS, V60, P3534, DOI 10.1109/TIM.2011.2161144
   Sakr N, 2009, IEEE T INSTRUM MEAS, V58, P1727, DOI 10.1109/TIM.2008.2009146
   Shen XJ, 2004, EIGHTH IEEE INTERNATIONAL SYMPOSIUM ON DISTRIBUTED SIMULATION AND REAL-TIME APPLICATIONS, PROCEEDINGS, P53
   Srinivasan MA, 1997, COMPUT GRAPH-UK, V21, P393, DOI 10.1016/S0097-8493(97)00030-7
   Ternes D, 2008, LECT NOTES COMPUT SC, V5024, P199, DOI 10.1007/978-3-540-69057-3_24
   Wang HR, 2011, IEEE T INSTRUM MEAS, V60, P3501, DOI 10.1109/TIM.2011.2161141
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
NR 33
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 5
BP 6189
EP 6208
DI 10.1007/s11042-016-3281-x
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EP3JK
UT WOS:000397278400006
DA 2024-07-18
ER

PT J
AU Pakdaman, Z
   Saryazdi, S
   Nezamabadi-Pour, H
AF Pakdaman, Zahra
   Saryazdi, Saeid
   Nezamabadi-Pour, Hossein
TI A prediction based reversible image watermarking in Hadamard domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible watermarking; Reversible Hadamard transform; Prediction
   error; Adaline neural network
ID DIFFERENCE EXPANSION; AUTHENTICATION; SCHEME; TRANSFORMATIONS; HISTOGRAM
AB Reversible watermarking is a special kind of the lossless data hiding techniques which allows lossless recovering of both the watermark and the host image. In this paper, a new reversible watermarking scheme based on error prediction in Hadamard domain is presented. In the proposed method, the original image is divided into blocks and transformed to Hadamard domain. If a block is in a smooth area, its AC coefficients will be predicted using a linear predictor function. Then the value of error between the original and the predicted coefficient is computed. At last, a watermark bit will be embedded in the error. To reduce the error value, an Adaline neural network is used to determine coefficients of the predictor function. The experimental results show that the proposed method provides higher capacity and quality in comparison to some well-known methods.
C1 [Pakdaman, Zahra; Saryazdi, Saeid; Nezamabadi-Pour, Hossein] Shahid Bahonar Univ Kerman, Dept Elect Engn, POB 76169-133, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Pakdaman, Z (corresponding author), Shahid Bahonar Univ Kerman, Dept Elect Engn, POB 76169-133, Kerman, Iran.
EM Zh_pakdaman@yahoo.com
RI Nezamabadi-pour, Hossein/I-9578-2014; Nezamabadi-pour,
   Hossein/AAB-4009-2019; Saryazdi, Saeid/GQY-9790-2022; Saryazdi,
   Saeid/GQZ-0186-2022; Saryazdi, Saeid/D-4488-2015
OI Nezamabadi-pour, Hossein/0000-0002-3350-7348; Saryazdi,
   Saeid/0000-0002-4577-1971; Saryazdi, Saeid/0000-0002-4577-1971
CR Al-Qershi OM, 2013, SIGNAL PROCESS, V93, P154, DOI 10.1016/j.sigpro.2012.07.012
   An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   An LL, 2012, NEUROCOMPUTING, V79, P1, DOI 10.1016/j.neucom.2011.08.019
   An LL, 2012, NEUROCOMPUTING, V77, P1, DOI 10.1016/j.neucom.2011.06.012
   Arsalan M, 2012, J SYST SOFTWARE, V85, P883, DOI 10.1016/j.jss.2011.11.005
   Aznaveh AM, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/738972
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Chan YK, 2009, J SYST SOFTWARE, V82, P411, DOI 10.1016/j.jss.2008.07.008
   Chang CC, 2010, INFORM SCIENCES, V180, P2286, DOI 10.1016/j.ins.2010.01.034
   Coltuc D, 2007, IEEE SIGNAL PROC LET, V14, P255, DOI 10.1109/LSP.2006.884895
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Du Y, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL I, PROCEEDINGS, P301, DOI 10.1109/AICI.2009.30
   Feng J.B., 2006, IJ Network Security, V2, P161
   Gao L, 2012, P IEEE INT C WAV AN, P33
   Gao XB, 2011, IEEE T CIRC SYST VID, V21, P1061, DOI 10.1109/TCSVT.2011.2130410
   Gao XB, 2009, SIGNAL PROCESS, V89, P2053, DOI 10.1016/j.sigpro.2009.04.015
   Iliyasu AM, 2012, INFORM SCIENCES, V186, P126, DOI 10.1016/j.ins.2011.09.028
   Kamran, 2014, INFORM SCIENCES, V256, P162, DOI 10.1016/j.ins.2013.07.035
   Kim KS, 2009, PATTERN RECOGN, V42, P3083, DOI 10.1016/j.patcog.2009.04.004
   Lei BY, 2014, EXPERT SYST APPL, V41, P3178, DOI 10.1016/j.eswa.2013.11.019
   Li C, 2016, ADV METEOROL, V2016, DOI 10.1155/2016/6583906
   Lin CC, 2008, PATTERN RECOGN, V41, P3582, DOI 10.1016/j.patcog.2008.05.015
   Lin YK, 2012, J SYST SOFTWARE, V85, P2395, DOI 10.1016/j.jss.2012.05.032
   Lou DC, 2012, OPT COMMUN, V285, P2510, DOI 10.1016/j.optcom.2012.01.021
   Mao Q, 2015, INFORM SCIENCES, V317, P170, DOI 10.1016/j.ins.2015.05.013
   Narawade Navnath, 2011, INT J COMPUT SCI TEL, V2, P46
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Sarukhanyan H, 2007, FACTA U NIS, V20, P309, DOI DOI 10.2298/FUEE0703309S
   Saryazdi S, 2005, PROC WRLD ACAD SCI E, V3, P126
   Thodi DM, 2004, 6TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P21, DOI 10.1109/IAI.2004.1300937
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Wang N, 2012, COMPUT AIDED DESIGN, V44, P320, DOI 10.1016/j.cad.2011.11.001
   Widrow Bernard, 1960, 1960 IRE WESCON convention record, part 4, P96
   Wu XY, 2006, LECT NOTES COMPUT SC, V3919, P135
   Wu XL, 1997, IEEE T IMAGE PROCESS, V6, P656, DOI 10.1109/83.568923
   Yang C. Y., 2010, J INFORM HIDING MULT, V1, P91
   Zhao ZF, 2011, AEU-INT J ELECTRON C, V65, P814, DOI 10.1016/j.aeue.2011.01.014
NR 40
TC 16
Z9 16
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8517
EP 8545
DI 10.1007/s11042-016-3490-3
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800040
DA 2024-07-18
ER

PT J
AU Zhu, HJ
   Zhuang, ZH
   Zhou, JL
   Zhang, F
   Wang, XJ
   Wu, YH
AF Zhu, Haijiang
   Zhuang, Zhanhong
   Zhou, Jinglin
   Zhang, Fan
   Wang, Xuejing
   Wu, Yihong
TI Segmentation of liver cyst in ultrasound image based on adaptive
   threshold algorithm and particle swarm optimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Ultrasound image; Wellner's thresholding algorithm; Particle swarm
   optimization; Segmentation of liver cyst
ID CLASSIFICATION
AB To find the optimum threshold of an image is still an important research topic in the recent years. This paper presents a segmentation of liver cyst for ultrasound image through combining Wellner's thresholding algorithm with particle swarm optimization (PSO). The proposed method firstly obtains an optimal parameter, which expressed as a percentage or fixed amount of dark objects against a white background in a gray image, of Wellner's thresholding algorithm by PSO method. And then the gray image is binarized according to the optimized parameter. Finally, a semi-automatic method for locating and identifying multiple liver cysts or single liver cyst of ultrasound images is performed. For a validation, the results of the proposed technique are compared with those of other segmented methods. We also tested 92 ultrasound images of the liver cysts by our software. The corrected identification rate of the single liver cysts is 97.7%, and that of multiple liver cysts is 87.5 %. Experimental results demonstrate that the proposed technique is reliable on segmenting the contour of liver cyst and identifying single or multiple liver cysts.
C1 [Zhu, Haijiang; Zhuang, Zhanhong; Zhou, Jinglin; Zhang, Fan; Wang, Xuejing] Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
   [Wu, Yihong] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, Beijing 100190, Peoples R China.
C3 Beijing University of Chemical Technology; Chinese Academy of Sciences;
   Institute of Automation, CAS
RP Zhu, HJ (corresponding author), Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
EM zhuhj@mail.buct.edu.cn
FU National High Technology Research and Development Program of China (863
   Program) [2015AA020504]; National Natural Science Foundation of China
   [61473025]; Fundamental Research Funds for the Central Universities
   [YS1404]; State Key Laboratory of Synthetical Automation for Process
   Industry at the Northeastern University in China
FX This work was supported in part by Supported by the National High
   Technology Research and Development Program of China (863 Program) under
   grant No. 2015AA020504 and the National Natural Science Foundation of
   China under grant No. 61473025, the Fundamental Research Funds for the
   Central Universities (YS1404) and the open-project grant funded by the
   State Key Laboratory of Synthetical Automation for Process Industry at
   the Northeastern University in China.
CR Bradley Derek, 2007, Journal of Graphics Tools, V12, P13
   Chen CM, 2002, ULTRASOUND MED BIOL, V28, P1061, DOI 10.1016/S0301-5629(02)00531-8
   Chen MF, 2013, IMAGING SCI J, V61, P579, DOI 10.1179/1743131X12Y.0000000028
   Crespo J, 1998, PATTERN RECOGN, V31, P419, DOI 10.1016/S0031-3203(97)00062-9
   Feng X, 2013, P SPIE BIOM OPT IM
   Huang QH, 2014, NEUROCOMPUTING, V129, P216, DOI 10.1016/j.neucom.2013.09.038
   Jeon JH, 2013, EXPERT SYST APPL, V40, P450, DOI 10.1016/j.eswa.2012.07.053
   Kotropoulos C, 2003, PATTERN RECOGN LETT, V24, P715, DOI 10.1016/S0167-8655(02)00177-0
   Latifoglu F, 2013, COMPUT METH PROG BIO, V111, P561, DOI 10.1016/j.cmpb.2013.05.009
   Lee WL, 2005, INFORM SCIENCES, V175, P177, DOI 10.1016/j.ins.2005.01.007
   Linguraru MG, 2012, IEEE T MED IMAGING, V31, P1965, DOI 10.1109/TMI.2012.2211887
   Milko S, 2008, INT J COMPUT ASS RAD, V3, P143, DOI 10.1007/s11548-008-0217-6
   Mittal D, 2010, MED BIOL ENG COMPUT, V48, P1281, DOI 10.1007/s11517-010-0650-x
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   Noble JA, 2006, IEEE T MED IMAGING, V25, P987, DOI 10.1109/TMI.2006.877092
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Öziç MÜ, 2014, SIG PROCESS COMMUN, P1999, DOI 10.1109/SIU.2014.6830650
   Phee SJ, 2010, MED BIOL ENG COMPUT, V48, P103, DOI 10.1007/s11517-009-0568-3
   Ribeiro RT, 2013, IEEE T BIO-MED ENG, V60, P1336, DOI 10.1109/TBME.2012.2235438
   Singh M, 2014, INFORM FUSION, V19, P91, DOI 10.1016/j.inffus.2013.05.007
   Slabaugh G, 2009, ULTRASOUND MED BIOL, V35, P781, DOI 10.1016/j.ultrasmedbio.2008.10.014
   Smeets D, 2010, MED IMAGE ANAL, V14, P13, DOI 10.1016/j.media.2009.09.002
   Virmani J, 2013, J DIGIT IMAGING, V26, P530, DOI 10.1007/s10278-012-9537-8
   Weijers G, 2010, ULTRASONIC IMAGING, V32, P143, DOI 10.1177/016173461003200303
   Wellner P.D., 1993, EPC93110
   Xian GM, 2010, EXPERT SYST APPL, V37, P6737, DOI 10.1016/j.eswa.2010.02.067
   Xiao GF, 2002, IEEE T MED IMAGING, V21, P48, DOI 10.1109/42.981233
   Yoshida H, 1998, ULTRASON, P1713, DOI 10.1109/ULTSYM.1998.765279
   Zhang D, 2012, P S PHOT OPT
   Zhang QH, 2012, ADV DIFFER EQU-NY, DOI 10.1186/1687-1847-2012-136
NR 30
TC 13
Z9 15
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2017
VL 76
IS 6
BP 8951
EP 8968
DI 10.1007/s11042-016-3486-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA ER7TZ
UT WOS:000399017800059
DA 2024-07-18
ER

PT J
AU Cai, LQ
   Liu, BB
   Yu, JM
   Zhang, JR
AF Cai, Linqin
   Liu, Binbin
   Yu, Jimin
   Zhang, Jianrong
TI Human behaviors modeling in multi-agent virtual environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Virtual environment; Virtual human; Emotion; Multi-agent
ID DYNAMICS; EMOTIONS; AGENTS; DESIGN; GAMES
AB Human behavior Modeling and simulation has become one of the most challenging research topics in many sectors where safety and organizational complexity are key issues. This paper involves constructing an integrative behavior framework for autonomous virtual miner agents that populate believably virtual coalmine environment to simulate human behaviors of underground coalmine. In this study, we present an emotional behavior model for virtual miner based on cognitive appraisal theories. The proposed models can generate more believable behaviors in virtual environment based on the personalized emotion states, internal motivation needs, and behavior selection thresholds of virtual miners. In addition, we take into account the impacts of underground mine workers' personality straits on the intensity threshold of emotions, the emotion's decay, and the motivation update process. Finally, we implement an interactive virtual environment for underground human behavior simulation. The behavior believability of virtual miner was evaluated with user assessment method. Experimental results show that the proposed models can create more realistic real-time virtual coalmine environments to simulate human behavior resulting in underground accidents.
C1 [Cai, Linqin] Chongqing Univ Posts & Telecommun, Minist Educ, Key Lab Ind Internet Things & Networked Control, Chongqing 400065, Peoples R China.
   [Cai, Linqin; Liu, Binbin; Yu, Jimin; Zhang, Jianrong] Chongqing Univ Posts & Telecommun, Res Ctr Complex Syst Anal & Control, Chongqing, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Cai, LQ (corresponding author), Chongqing Univ Posts & Telecommun, Minist Educ, Key Lab Ind Internet Things & Networked Control, Chongqing 400065, Peoples R China.
EM iamlqcai@163.com
RI Yu, Jimin/I-7770-2012; Liu, Binbin/AAE-4313-2022; CAI,
   Linqin/AAC-8471-2022; cai, linqin/AFQ-8642-2022
OI CAI, Linqin/0000-0002-5663-8113; cai, linqin/0000-0002-5663-8113
FU National Natural Science Foundation of China [50804061]; Research
   Project of Chongqing Municipal Education Commission [KJ130522]
FX This work is supported by the National Natural Science Foundation of
   China (No. 50804061) and the Research Project of Chongqing Municipal
   Education Commission (No. KJ130522)
CR [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478
   Brnich MJ, 2010, CO SOC MIN METALL EX, P363
   Cai LQ, 2008, J HUAZHONG U SCI S1, V36, P4
   Castellano G, 2010, J MULTIMODAL USER IN, V3, P89, DOI 10.1007/s12193-009-0033-5
   de Rosis F, 2003, INT J HUM-COMPUT ST, V59, P81, DOI 10.1016/S1071-5819(03)00020-X
   El-Nasr MS, 2000, AUTON AGENT MULTI-AG, V3, P219, DOI 10.1023/A:1010030809960
   Gratch J., 2004, Cogn. Syst. Res, V5, P269, DOI [10.1016/j.cogsys.2004.02.002, DOI 10.1016/J.COGSYS.2004.02.002]
   Kazemifard M, 2011, EXPERT SYST APPL, V38, P2640, DOI 10.1016/j.eswa.2010.08.054
   Kim DH, 2013, J CONVERGENCE INF TE, V8, P582
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Liu J.M., 2011, CASE ANAL COALMINE T
   Liu S, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/503924
   Magnenat-Thalmann N, 2012, GRAPH INTERFACES C, V2012, P1
   Malkawi M., 2013, J HUMAN CENTRIC COMP, V3, P1
   Mallett L., 2007, P 2007 SME ANN M EXH, V2, P1
   Marsella SC, 2009, COGN SYST RES, V10, P70, DOI 10.1016/j.cogsys.2008.03.005
   McCrae R.R., 2009, The Five-Factor Model of personality traits: consensus and controversy, P148
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Niewiadomski R, 2011, IEEE T AFFECT COMPUT, V2, P134, DOI 10.1109/T-AFFC.2011.5
   Ochs M, 2009, IEEE T COMP INTEL AI, V1, P281, DOI 10.1109/TCIAIG.2009.2036247
   Orozco H, 2011, VISUAL COMPUT, V27, P275, DOI 10.1007/s00371-011-0549-z
   Ortony Andrew., 1998, COGNITIVE STRUCTURE
   Picard RosalindW., 1998, Affective Computing, V2
   Reilly SN, 1996, THESIS
   Rodríguez LF, 2014, COGN COMPUT, V6, P351, DOI 10.1007/s12559-013-9244-x
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   Si M, 2010, AUTON AGENT MULTI-AG, V20, P14, DOI 10.1007/s10458-009-9093-x
   Silverman BG, 2006, PRESENCE-TELEOP VIRT, V15, P163, DOI 10.1162/pres.2006.15.2.163
   Su WP, 2007, IEEE T VIS COMPUT GR, V13, P281, DOI 10.1109/TVCG.2007.44
   Sung Y, 2012, J INF PROCESS SYST, V8, P409, DOI 10.3745/JIPS.2012.8.3.409
   Van Wyk E., 2009, P 6 INT C COMP GRAPH, P53, DOI DOI 10.1145/1503454.1503465
   [杨宏伟 Yang Hongwei], 2008, [计算机研究与发展, Journal of Computer Research and Development], V45, P579
NR 32
TC 10
Z9 11
U1 1
U2 56
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5851
EP 5871
DI 10.1007/s11042-015-2547-z
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500052
DA 2024-07-18
ER

PT J
AU Cao, JJ
   Zhang, J
   Wen, ZJ
   Wang, NN
   Liu, XP
AF Cao, Junjie
   Zhang, Jie
   Wen, Zhijie
   Wang, Nannan
   Liu, Xiuping
TI Fabric defect inspection using prior knowledge guided least squares
   regression
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Low-rank; Fabric defect detection; Prior knowledge; Least squares
   regression
ID AUTOMATED INSPECTION; CLASSIFICATION; FOURIER
AB This paper proposes an unsupervised model to inspect various detects in fabric images with diverse textures. A fabric image with defects is usually composed of a relatively consistent background texture and some sparse defects, which can be represented as a low-rank matrix plus a sparse matrix in a certain feature space. The process is formulated as a least squares regression based subspace segmentation model, which is convex, smooth and can be solved efficiently. A simple and effective prior is also learnt from local texture features of the image itself. Instead of considering only the feature space's global structure, the local prior is incorporated with it seamlessly by the proposed subspace segmentation model to guide and improve the segmentation. Experiments on a variety of fabric images demonstrate the effectiveness and robustness of the proposed method. Compared with existing methods, our method is more robust and locates various defects more precisely.
C1 [Cao, Junjie; Zhang, Jie; Wang, Nannan; Liu, Xiuping] Dalian Univ Technol, Sch Math Sci, Dalian, Peoples R China.
   [Wen, Zhijie] Shanghai Univ, Coll Sci, Dept Math, Shanghai, Peoples R China.
C3 Dalian University of Technology; Shanghai University
RP Liu, XP (corresponding author), Dalian Univ Technol, Sch Math Sci, Dalian, Peoples R China.; Wen, ZJ (corresponding author), Shanghai Univ, Coll Sci, Dept Math, Shanghai, Peoples R China.
EM jjcao1231@gmail.com; wenzhijie@shu.edu.cn; xpliu@dlut.edu.cn
RI Liu, Xiufang/I-8003-2015; Liu, Xiu/IYJ-9134-2023; Wang,
   Nannan/U-8505-2019
OI Wang, Nannan/0000-0001-8995-5302
FU NSFC China [61363048, 91230103, 11471208, 61173102, 61370143]
FX The authors would like to thank Huanhuan Zhang for her images of TILDA
   Textile Texture Database. Junjie Cao is supported by the NSFC China
   (61363048, 91230103). Zhijie Wen is supported by the NSFC China
   (11471208). Xiuping Liu is supported by the NSFC China (61173102,
   61370143).
CR Ahn I, 2010, KOR JAP JOINT WORKSH
   Alata O, 2005, PATTERN RECOGN LETT, V26, P1069, DOI 10.1016/j.patrec.2004.10.002
   [Anonymous], 2010, P 16 ACM SIGKDD INT
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Cheng B, 2011, IEEE I CONF COMP VIS, P2439, DOI 10.1109/ICCV.2011.6126528
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chetverikov D, 2008, LECT NOTES COMPUT SC, P143
   CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Hajimowlana SH, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P318, DOI 10.1109/MWSCAS.1998.759496
   Hou X, 2007, CVPR, P18
   Hung-Yam Chan, 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V6001, p60010D, DOI 10.1117/12.633204
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Kumar A, 2002, IEEE T SYST MAN CY B, V32, P553, DOI 10.1109/TSMCB.2002.1033176
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu J, 2013, IEEE T PATTERN ANAL, V35, P208, DOI 10.1109/TPAMI.2012.39
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Mak KL, 2008, ROBOT CIM-INT MANUF, V24, P359, DOI 10.1016/j.rcim.2007.02.019
   Navalpakkam Vidhya, 2006, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern Recognit, V2, P2049, DOI DOI 10.1109/CVPR.2006.54
   Ngan HYT, 2011, IMAGE VISION COMPUT, V29, P442, DOI 10.1016/j.imavis.2011.02.002
   Ngan HYT, 2005, PATTERN RECOGN, V38, P559, DOI 10.1016/j.patcog.2004.07.009
   Ogata N, 2005, I S INTELL SIG PROC, P65
   Ozdemir S, 1996, ETFA '96 - 1996 IEEE CONFERENCE ON EMERGING TECHNOLOGIES AND FACTORY AUTOMATION, PROCEEDINGS, VOLS 1 AND 2, P697, DOI 10.1109/ETFA.1996.573989
   Tajeripour F, 2008, INT C COMP INT MULT, P261
   TSAI IS, 1995, TEXT RES J, V65, P123, DOI 10.1177/004051759506500301
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Wen ZJ, 2014, INT J CLOTH SCI TECH, V26, P202, DOI 10.1108/IJCST-03-2013-0031
   WOOD EJ, 1990, TEXT RES J, V60, P212, DOI 10.1177/004051759006000404
   Yang X, 2005, IEE P-VIS IMAGE SIGN, V152, P715, DOI 10.1049/ip-vis:20045131
   Yang XZ, 2004, PATTERN RECOGN, V37, P889, DOI 10.1016/j.patcog.2003.10.011
   Ying SH, 2014, NEUROIMAGE, V84, P626, DOI 10.1016/j.neuroimage.2013.09.023
   Yu Y., 2011, P INT JOINT C ARTIFI, P778
   Zeng PF, 2002, IEEE IND APPLIC SOC, P320, DOI 10.1109/IAS.2002.1044107
   ZHANG YXF, 1995, TEXT RES J, V65, P1, DOI 10.1177/004051759506500101
   Zhi YX, 2001, INT CONF ACOUST SPEE, P3697, DOI 10.1109/ICASSP.2001.940645
NR 38
TC 52
Z9 53
U1 2
U2 35
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4141
EP 4157
DI 10.1007/s11042-015-3041-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200046
DA 2024-07-18
ER

PT J
AU Ji, XU
   Zhang, G
AF Ji, Xiuxia
   Zhang, Gong
TI Contourlet domain SAR image de-speckling via self-snake diffusion and
   sparse representation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-snake diffusion; Sparse representation; Contourlet transform;
   Speckle noise; Orthogonalmatching pursuit algorithm
AB In this paper, A contourlet domain SAR image de-speckling algorithm via selfsnake diffusion and sparse representation theory is presented in order to reduce the influence of the SAR image speckle noise on the large-scale target edge information of the low frequency subband and the texture information of the high frequency subband. For this algorithm, firstly, the contourlet transform is applied to the speckled SAR image, adjusts the directional number of each dimension to represent SAR image in the high dimensional space. Then, the low frequency subband without sparsity is filtered by self-snake diffusion and the filtered coefficient is regarded as the local average estimate of the low-frequency subband in the contourlet domain. Sparse representation optimization model of SAR image is presented for suppressing the speckle noise of the high frequency subbands with sparsity, and solves sparse coefficients of the high frequency subbands by using the improved orthogonal matching pursuit algorithm. Finally, the de-speckled image is reconstructed from all of the filtered subband coefficients by the inverse contourlet transform. This paper simulates three representative experiments and the experimental results demonstrate that the proposed algorithm has a better de-speckling performance with preserving the edge of the SAR image.
C1 [Ji, Xiuxia; Zhang, Gong] Nanjing Univ Aeronaut & Astronaut, Key Lab Radar Imaging & Microwave Photon, Minist Educ, Nanjing 210016, Jiangsu, Peoples R China.
   [Ji, Xiuxia] Nanjing Univ Aeronaut & Astronaut, Jincheng Coll, Nanjing 211156, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; Nanjing University of
   Aeronautics & Astronautics
RP Ji, XU (corresponding author), Nanjing Univ Aeronaut & Astronaut, Key Lab Radar Imaging & Microwave Photon, Minist Educ, Nanjing 210016, Jiangsu, Peoples R China.; Ji, XU (corresponding author), Nanjing Univ Aeronaut & Astronaut, Jincheng Coll, Nanjing 211156, Jiangsu, Peoples R China.
EM 104066779@qq.com
FU National Science Foundation of China [61471191, 61071163, 61271327];
   Natural Science Foundation of Jiangsu colleges and universities
   [14KJD510004]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments and advices which contributed much to the improvement
   of this paper. The work was jointly supported by the National Science
   Foundation of China under grant No. 61471191, 61071163, 61271327, the
   Natural Science Foundation of Jiangsu colleges and universities under
   grant No. 14KJD510004.
CR Achim A, 2003, IEEE T GEOSCI REMOTE, V41, P1773, DOI 10.1109/TGRS.2003.813488
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen SB, 2010, RES DE SPECKLING SAR
   Debotosh B, 2014, HUM CENTRIC COMPUT I, V4, P1
   Foucher S., 2008, IGARSS 2008 2008 IE, V1, pI229
   Ghimire D, 2014, J INF PROCESS SYST, V10, P443, DOI 10.3745/JIPS.02.0004
   GOODMAN JW, 1976, J OPT SOC AM, V66, P1145, DOI 10.1364/JOSA.66.001145
   Hebar M, 2009, IEEE T GEOSCI REMOTE, V47, P2818, DOI 10.1109/TGRS.2009.2013697
   [季秀霞 Ji Xiuxia], 2013, [宇航学报, Journal of Astronautics], V34, P1146
   Khalighi SP, 2014, J SIGNAL PROCESS SYS, V6, P14
   [李恒建 Li Hengjian], 2010, [铁道学报, Journal of the China Railway Society], V32, P108
   Liu JL, 2014, MULTIMED TOOLS APPL, V70, P1667, DOI 10.1007/s11042-012-1189-7
   [刘帅奇 Liu Shuaiqi], 2012, [电子与信息学报, Journal of Electronics & Information Technology], V34, P2110
   Ourabia S, 2013, 2013 8TH INTERNATIONAL WORKSHOP ON SYSTEMS, SIGNAL PROCESSING AND THEIR APPLICATIONS (WOSSPA), P429, DOI 10.1109/WoSSPA.2013.6602403
   Patel VM, 2010, P SPIE
   Tosic I, 2011, IEEE J-STSP, V5, P941, DOI 10.1109/JSTSP.2011.2158063
   Weickert J, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P43, DOI 10.1007/0-387-21810-6_3
   Xu PF, 2014, MULTIMED TOOLS APPL, V71, P1529, DOI 10.1007/s11042-012-1290-y
   Yang M, 2012, ELECTRON LETT, V48, P596, DOI 10.1049/el.2011.3305
   Zhao RZ, 2009, SCI CHINA SER F, V52, P1371, DOI 10.1007/s11432-009-0116-7
   Zhu L, J XIDIAN U, V39, P80
NR 22
TC 9
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 5873
EP 5887
DI 10.1007/s11042-015-2560-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500053
DA 2024-07-18
ER

PT J
AU Plantard, P
   Shum, HPH
   Multon, F
AF Plantard, Pierre
   Shum, Hubert P. H.
   Multon, Franck
TI Filtered pose graph for efficient kinect pose reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect; Pose reconstruction; Occlusion; Motion analysis
ID MICROSOFT KINECT; SENSOR; ACCURACY; VALIDITY
AB Being marker-free and calibration free, Microsoft Kinect is nowadays widely used in many motion-based applications, such as user training for complex industrial tasks and ergonomics pose evaluation. The major problem of Kinect is the placement requirement to obtain accurate poses, as well as its weakness against occlusions. To improve the robustness of Kinect in interactive motion-based applications, real-time data-driven pose reconstruction has been proposed. The idea is to utilize a database of accurately captured human poses as a prior to optimize the Kinect recognized ones, in order to estimate the true poses performed by the user. The key research problem is to identify the most relevant poses in the database for accurate and efficient reconstruction. In this paper, we propose a new pose reconstruction method based on modelling the pose database with a structure called Filtered Pose Graph, which indicates the intrinsic correspondence between poses. Such a graph not only speeds up the database poses selection process, but also improves the relevance of the selected poses for higher quality reconstruction. We apply the proposed method in a challenging environment of industrial context that involves sub-optimal Kinect placement and a large amount of occlusion. Experimental results show that our real-time system reconstructs Kinect poses more accurately than existing methods.
C1 [Plantard, Pierre] FAURECIA Automot Seating, Etampes, France.
   [Plantard, Pierre; Multon, Franck] Univ Rennes 2, Rennes, France.
   [Shum, Hubert P. H.] Northumbria Univ, Newcastle Upon Tyne, Tyne & Wear, England.
   [Multon, Franck] Inria, Rennes, France.
C3 Universite Rennes 2; Universite de Rennes; Northumbria University; Inria
RP Plantard, P (corresponding author), FAURECIA Automot Seating, Etampes, France.; Plantard, P (corresponding author), Univ Rennes 2, Rennes, France.; Shum, HPH (corresponding author), Northumbria Univ, Newcastle Upon Tyne, Tyne & Wear, England.
EM pierre.plantard@irisa.fr; hubert.shum@northumbria.ac.uk
RI Shum, Hubert P. H./E-8060-2015
OI Shum, Hubert P. H./0000-0001-5651-6039; Multon,
   Franck/0000-0003-2690-0077
FU Cifre convention [N1222/2012]; Faurecia Company; Engineering and
   Physical Sciences Research Council (EPSRC) [EP/M002632/1]; EPSRC
   [EP/M002632/1] Funding Source: UKRI
FX This work was partially funded by the Cifre convention N1222/2012 and
   Faurecia Company. It was also partially funded by the Engineering and
   Physical Sciences Research Council (EPSRC) (Ref: EP/M002632/1).
CR [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   [Anonymous], 1988, ANTHROPOMETRY MASS D
   Diego-Mas JA, 2014, APPL ERGON, V45, P976, DOI 10.1016/j.apergo.2013.12.001
   Auvinet E, 2014, GAIT POSTURE
   Auvinet E, 2012, IEEE ENG MED BIO, P6793, DOI 10.1109/EMBC.2012.6347554
   Beaudoin P, 2008, P EUR ACM SIGGRAPH S
   Bideau B, 2010, IEEE COMPUT GRAPH, V30, P14, DOI 10.1109/MCG.2009.134
   Cassola F., 2014, Procedia Technology, V13, P130, DOI [10.1016/j.protcy.2014.02.017, DOI 10.1016/J.PROTCY.2014.02.017, DOI 10.1016/J.PR0TCY.2014.02.017]
   Chai JX, 2005, ACM T GRAPHIC, V24, P686, DOI 10.1145/1073204.1073248
   Clark RA, 2013, J BIOMECH, V46, P2722, DOI 10.1016/j.jbiomech.2013.08.011
   Clark RA, 2012, GAIT POSTURE, V36, P372, DOI 10.1016/j.gaitpost.2012.03.033
   Dutta T, 2012, APPL ERGON, V43, P645, DOI 10.1016/j.apergo.2011.09.011
   Fern'ndez-Baena A., 2012, 2012 4th International Conference on Intelligent Networking and Collaborative Systems (INCoS 2012), P656, DOI 10.1109/iNCoS.2012.66
   Field A., 2013, DISCOVERING STAT USI
   Galna B, 2014, GAIT POSTURE, V39, P1062, DOI 10.1016/j.gaitpost.2014.01.008
   Gameiro J., 2014, Procedia Technology, V17, P384, DOI [DOI 10.1016/J.PROTCY.2014.10.199, 10.1016/j.protcy.2014.10.199]
   Gleicher M., 2003, P 2003 S INTERACTIVE, P181
   Han J, 2013, IEEE T CYBERN, V43
   Han JG, 2012, IEEE T CONSUM ELECTR, V58, P255, DOI 10.1109/TCE.2012.6227420
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Huang SY, 2015, MULTIMED TOOLS APPL, V74, P10679, DOI 10.1007/s11042-014-2198-5
   Jinxiang Chai, 2007, ACM Transactions on Graphics, V26, P8, DOI 10.1145/1276377.1276387
   Kovar L, 2002, ACM T GRAPHIC, V21, P473, DOI 10.1145/566570.566605
   LEE G, 2014, MULTIMED TOOLS APPL, P00001
   Liu H, 2011, 2011 SECOND INTERNATIONAL CONFERENCE ON EDUCATION AND SPORTS EDUCATION (ESE 2011), VOL II, P133
   Martin CJ, 2012, CAMB STUD COMPAR, P50, DOI 10.1109/SIEDS.2012.6215130
   Maynard A, 2012, MCGRAW HILL IND ORG
   MCATAMNEY L, 1993, APPL ERGON, V24, P91, DOI 10.1016/0003-6870(93)90080-S
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Plantard P, 2015, SENSORS-BASEL, V15, P1785, DOI 10.3390/s150101785
   Reitsma PSA, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1289603.1289609
   Safonova A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239557
   Shen W, 2012, PROC CVPR IEEE, P1784, DOI 10.1109/CVPR.2012.6247875
   Shin HJ, 2006, P 2006 ACM SIGGRAPH
   Shum H. P. H., 2012, P ACM S VIRT REAL SO, P17
   Shum HPH, 2013, IEEE T CYBERNETICS, V43, P1357, DOI 10.1109/TCYB.2013.2275945
   Tautges J, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1966394.1966397
   Vignais N, 2013, APPL ERGON, V44, P566, DOI 10.1016/j.apergo.2012.11.008
   Zhao L, 2009, P EUR ACM SIGGRAPH S
   Zhao LM, 2009, GRAPH MODELS, V71, P139, DOI 10.1016/j.gmod.2009.04.001
   Zhou L., 2014, Proceedings of the 20th ACM Symposium on Virtual Reality Software and Technology, VRST '14, New York, NY, USA, P117
   Zollhöfer M, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601165
NR 42
TC 22
Z9 24
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4291
EP 4312
DI 10.1007/s11042-016-3546-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200055
PM 32226275
OA Green Published, Green Accepted, Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Shaikh, MK
   Lawgaly, A
   Tahir, MA
   Bouridane, A
AF Shaikh, Muhammad Khurram
   Lawgaly, Ashref
   Tahir, Muhammad Atif
   Bouridane, Ahmed
TI Modality identification for heterogeneous face recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Heterogeneous face recognition; Modality pattern noise; Modality
   identification
ID DISCRIMINANT-ANALYSIS
AB Identifying the type of modalities of the query image which can be of types visual, NIR, digital camera, web camera etc. have been assumed to be available before face matching. This leads to a major drawback in achieving fully automated heterogeneous face recognition as real world scenarios cannot be reflected. Therefore, modality identification is an important component of the heterogeneous face recognition system which is being overlooked by majority of the state-of-the-art methods. This component should be given similar attention when comparing with other face recognition modules identifying pose, gesture, camera source etc. In this paper inspired from sensor pattern noise (SPN) estimation based approaches, a novel image sharpening based modality pattern noise technique is proposed for modality identification. The proposed system has been evaluated on three challenging benchmarks of heterogeneous face databases. The proposed technique has produced outstanding results and will open new avenues of research for automated HFR methods in future.
C1 [Shaikh, Muhammad Khurram; Lawgaly, Ashref; Tahir, Muhammad Atif; Bouridane, Ahmed] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne, Tyne & Wear, England.
   [Tahir, Muhammad Atif] FAST Natl Univ Comp & Emerging Sci, Syst Res Lab Comp Sci, Karachi, Pakistan.
C3 Northumbria University
RP Shaikh, MK (corresponding author), Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne, Tyne & Wear, England.
EM muhammad.shaikh@northumbria.ac.uk; ashref.lawgaly@northumbria.ac.uk
CR [Anonymous], 2013, 2013 INT C BIOMETRIC, DOI DOI 10.1109/ICB.2013.6612968
   [Anonymous], 2015, IEEE MTT S INT MICR
   Cai XY, 2013, IEEE IMAGE PROC, P2772, DOI 10.1109/ICIP.2013.6738571
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chingovska I, 2013, IEEE COMPUT SOC CONF, P98, DOI 10.1109/CVPRW.2013.22
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Garcia J., 2010, P IEEE INT C PATT AN, V32, P1097
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Huang X., 2013, ITIP, V22, P1513
   Jain AnilK., 2005, Handbook of Face Recognition
   Kang XG, 2012, IEEE T INF FOREN SEC, V7, P393, DOI 10.1109/TIFS.2011.2168214
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Kose N., 2013, 2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition FG, P1
   Lawgaly A, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P113, DOI 10.1109/EST.2013.25
   LEE YH, 1990, IEEE T CIRCUITS SYST, V37, P940, DOI 10.1109/31.55069
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041
   Li CT, 2010, IEEE T INF FOREN SEC, V5, P280, DOI 10.1109/TIFS.2010.2046268
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Li SZ, 2009, HFB FACE DATABASE HE
   Li ZF, 2014, IEEE T IMAGE PROCESS, V23, P2436, DOI 10.1109/TIP.2014.2315920
   Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13
   Liu L., 2013, 23 INT JOINT C ART I
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/CVBVS.2000.855246
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P2303, DOI 10.1109/TNNLS.2014.2308519
   Sutcu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P24
   Van Lanh T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P16
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Yi D, 2015, P 11 IEEE INT C AUT
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
NR 38
TC 3
Z9 3
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 3
BP 4635
EP 4650
DI 10.1007/s11042-016-3635-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EN5NA
UT WOS:000396051200070
DA 2024-07-18
ER

PT J
AU Zampoglou, M
   Papadopoulos, S
   Kompatsiaris, Y
AF Zampoglou, Markos
   Papadopoulos, Symeon
   Kompatsiaris, Yiannis
TI Large-scale evaluation of splicing localization algorithms for web
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image forensics; Image splicing; Forgery localization; Web multimedia
   verification
ID FORGERY DETECTION; FORENSICS
AB With the proliferation of smartphones and social media, journalistic practices are increasingly dependent on information and images contributed by local bystanders through Internet-based applications and platforms. Verifying the images produced by these sources is integral to forming accurate news reports, given that there is very little or no control over the type of user-contributed content, and hence, images found on the Web are always likely to be the result of image tampering. In particular, image splicing, i.e. the process of taking an area from one image and placing it in another is a typical such tampering practice, often used with the goal of misinforming or manipulating Internet users. Currently, the localization of splicing traces in images found on the Web is a challenging task. In this work, we present the first, to our knowledge, exhaustive evaluation of today's state-of-the-art algorithms for splicing localization, that is, algorithms attempting to detect which pixels in an image have been tampered with as the result of such a forgery. As our aim is the application of splicing localization on images found on the Web and social media environments, we evaluate a large number of algorithms aimed at this problem on datasets that match this use case, while also evaluating algorithm robustness in the face of image degradation due to JPEG recompressions. We then extend our evaluations to a large dataset we formed by collecting real-world forgeries that have circulated the Web during the past years. We review the performance of the implemented algorithms and attempt to draw broader conclusions with respect to the robustness of splicing localization algorithms for application in Web environments, their current weaknesses, and the future of the field. Finally, we openly share the framework and the corresponding algorithm implementations to allow for further evaluations and experimentation.
C1 [Zampoglou, Markos; Papadopoulos, Symeon; Kompatsiaris, Yiannis] Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km Harilaou Thermi, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Zampoglou, M (corresponding author), Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km Harilaou Thermi, Thessaloniki 57001, Greece.
EM markzampoglou@iti.gr
RI Kompatsiaris, Ioannis/P-8594-2015; Zampoglou, Markos/AAP-1579-2021;
   Papadopoulos, Symeon/AET-0683-2022; Zampoglou, Markos/K-6742-2013
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Zampoglou,
   Markos/0000-0001-7296-5942; Papadopoulos, Symeon/0000-0002-5441-7341
FU REVEAL project; European Commission [FP7-610928]
FX This work was supported by the REVEAL project, partially funded by the
   European Commission (contract no. FP7-610928).
CR Amerini I, 2015, MATH PROBL ENG, V2015, DOI 10.1155/2015/653164
   Amerini I, 2014, IEEE INT WORKS INFOR, P143, DOI 10.1109/WIFS.2014.7084318
   [Anonymous], 2004, COLUMBIA IMAGE SPLIC
   [Anonymous], CASIA TIDEV2 0
   [Anonymous], 2014, IEEE 11 INT MULT SYS
   [Anonymous], INT C ACC SPEECH SIG
   [Anonymous], NEW DEV IMAGE TAMPER
   [Anonymous], 2014, SCIENTIFICWORLDJOURN
   [Anonymous], 2016, P INT AAAI C WEB SOC
   Ardizzone E, 2015, IEEE T INF FOREN SEC, V10, P2084, DOI 10.1109/TIFS.2015.2445742
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P842, DOI 10.1109/TIFS.2011.2170836
   Bianchi T, 2011, INT CONF ACOUST SPEE, P2444
   Birajdar GK, 2013, DIGIT INVEST, V10, P226, DOI 10.1016/j.diin.2013.04.007
   Chang IC, 2013, IMAGE VISION COMPUT, V31, P57, DOI 10.1016/j.imavis.2012.09.002
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Christlein V, 2012, IEEE T INF FOREN SEC, V7, P1841, DOI 10.1109/TIFS.2012.2218597
   Costa FD, 2014, IEEE T INF FOREN SEC, V9, P1533, DOI 10.1109/TIFS.2014.2340017
   Cozzolino D, 2015, IEEE T INF FOREN SEC, V10, P2284, DOI 10.1109/TIFS.2015.2455334
   Cozzolino D, 2015, IEEE INT WORKS INFOR
   Cozzolino D, 2014, IEEE IMAGE PROC, P5297, DOI 10.1109/ICIP.2014.7026072
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   de Carvalho TJ, 2013, IEEE T INF FOREN SEC, V8, P1182, DOI 10.1109/TIFS.2013.2265677
   de Oliveira AA, 2016, IEEE T INF FOREN SEC, V11, P328, DOI 10.1109/TIFS.2015.2493989
   Dirik AE, 2009, IEEE IMAGE PROC, P1497, DOI 10.1109/ICIP.2009.5414611
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Ferrara P, 2015, IEEE INT CONF MULTI
   Ferrara P, 2012, IEEE T INF FOREN SEC, V7, P1566, DOI 10.1109/TIFS.2012.2202227
   Fontani M, 2013, IEEE T INF FOREN SEC, V8, P593, DOI 10.1109/TIFS.2013.2248727
   Gaborini L, 2014, IEEE INT WORKS INFOR, P125, DOI 10.1109/WIFS.2014.7084315
   He ZW, 2012, PATTERN RECOGN, V45, P4292, DOI 10.1016/j.patcog.2012.05.014
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Kakar P, 2011, IEEE T MULTIMEDIA, V13, P443, DOI 10.1109/TMM.2011.2121056
   Kee E, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629646
   Kennedy L., 2008, ACM International Conference on Multimedia (MM), P349
   Krawetz N., 2007, PICTURES WORTH DIGIT
   Li CT, 2012, IEEE T CIRC SYST VID, V22, P260, DOI 10.1109/TCSVT.2011.2160750
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li WH, 2009, SIGNAL PROCESS, V89, P1821, DOI 10.1016/j.sigpro.2009.03.025
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Liu QG, 2011, IEEE T INF FOREN SEC, V6, P1111, DOI 10.1109/TIFS.2011.2139209
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Muhammad G, 2014, MACH VISION APPL, V25, P985, DOI 10.1007/s00138-013-0547-4
   Pasquini C., 2015, IEEE INT CONF MULTI, P1, DOI 10.1109/ICMEW.2015.7169801
   Patel H., 2015, International Journal of Computer Applications, V111, P26, DOI DOI 10.5120/19615-1508
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Ryu SJ, 2013, IEEE T INF FOREN SEC, V8, P1355, DOI 10.1109/TIFS.2013.2272377
   Stamm MC, 2013, IEEE ACCESS, V1, P167, DOI 10.1109/ACCESS.2013.2260814
   Wang W, 2011, LECT NOTES COMPUT SC, V6526, P120, DOI 10.1007/978-3-642-18405-5_10
   Ye SM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P12
   Yerushalmy I, 2011, INT J COMPUT VISION, V92, P71, DOI 10.1007/s11263-010-0403-1
   Zampoglou M, 2015, IEEE INT CONF MULTI
   Zhao XD, 2011, LECT NOTES COMPUT SC, V6526, P12, DOI 10.1007/978-3-642-18405-5_2
NR 55
TC 91
Z9 102
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4801
EP 4834
DI 10.1007/s11042-016-3795-2
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500008
DA 2024-07-18
ER

PT J
AU Zeng, H
   Zhan, YF
   Kang, XG
   Lin, XD
AF Zeng, Hui
   Zhan, Yifeng
   Kang, Xiangui
   Lin, Xiaodan
TI Image splicing localization using PCA-based noise level estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image splicing; Image splicing localization; Noise level; Principal
   component analysis (PCA); K-means clustering
ID FORGERY
AB Image splicing is one of the most common image tampering operations, where the content of the tampered image usually significantly differs from that of the original one. As a consequence, forensic methods aiming to locate the spliced areas are of great realistic significance. Among these methods, the noise based ones, which utilize the fact that images from different sources tend to have various noise levels, have drawn much attention due to their convenience to implement and the relaxation of some operation specific assumptions. However, the performances of the existing noise based image splicing localization methods are unsatisfactory when the noise difference between the original and spliced regions is relatively small. In this paper, through incorporation of a recent developed noise level estimation algorithm, we propose an effective image splicing localization method. The proposed method performs blockwise noise level estimation of a test image with principal component analysis (PCA)-based algorithm, and segments the tampered region from the original region by k-means clustering. The experimental results demonstrate the superiority of the proposed method over several state-of-the-art methods, especially for practical image splicing, where the noise difference between the original and spliced regions is typically small.
C1 [Zeng, Hui; Zhan, Yifeng; Kang, Xiangui; Lin, Xiaodan] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China.
C3 Sun Yat Sen University
RP Kang, XG (corresponding author), Sun Yat Sen Univ, Sch Data & Comp Sci, Guangdong Key Lab Informat Secur, Guangzhou 510006, Guangdong, Peoples R China.
EM zengh5@mail2.sysu.edu.cn; isskxg@mail.sysu.edu.cn; xd_lin@hqu.edu.cn
RI Kang, Xiangui/AAO-5527-2020
OI Zeng, Hui/0000-0002-3776-4309
FU NSFC [61379155, U1536204, 61332012, 61502547]; NSF of Guangdong province
   [s2013020012788]
FX This work was supported by NSFC (Grant nos. 61379155, U1536204,
   61332012, and 61502547), and NSF of Guangdong province (Grant no.
   s2013020012788).
CR Al-Qershi OM, 2013, FORENSIC SCI INT, V231, P284, DOI 10.1016/j.forsciint.2013.05.027
   [Anonymous], P SPIE
   [Anonymous], DEPENDENCE PARAMETER
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], 2011, P 13 INF HID C PRAG
   Bahrami K, 2015, IEEE T INF FOREN SEC, V10, P999, DOI 10.1109/TIFS.2015.2394231
   Bianchi T, 2012, IEEE T INF FOREN SEC, V7, P1003, DOI 10.1109/TIFS.2012.2187516
   Chen M, 2008, IEEE T INF FOREN SEC, V3, P74, DOI 10.1109/TIFS.2007.916285
   Chen YL, 2011, IEEE T INF FOREN SEC, V6, P396, DOI 10.1109/TIFS.2011.2106121
   Chierchia G, 2014, IEEE T INF FOREN SEC, V9, P554, DOI 10.1109/TIFS.2014.2302078
   Chierchia Giovanni., 2010, Proceedings of the 2nd ACM workshop on Multimedia in forensics, security, and intelligence, MiFor '10, P117, DOI DOI 10.1145/1877972.1878002
   Cozzolino D, 2014, IEEE IMAGE PROC, P5302, DOI 10.1109/ICIP.2014.7026073
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Faraji H, 2006, IEEE T IMAGE PROCESS, V15, P2676, DOI 10.1109/TIP.2006.877363
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hsu YF, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P549, DOI 10.1109/ICME.2006.262447
   Kang XG, 2013, IEEE T INF FOREN SEC, V8, P1456, DOI 10.1109/TIFS.2013.2273394
   Lin XF, 2013, IEEE IMAGE PROC, P4467, DOI 10.1109/ICIP.2013.6738920
   Liu XH, 2012, IEEE IMAGE PROC, P665, DOI 10.1109/ICIP.2012.6466947
   Lyu SW, 2014, INT J COMPUT VISION, V110, P202, DOI 10.1007/s11263-013-0688-y
   Mahdian B, 2009, IMAGE VISION COMPUT, V27, P1497, DOI 10.1016/j.imavis.2009.02.001
   Pan X., 2012, IEEE INT C COMPUTATI, P1
   Pan XY, 2011, MM&SEC 11: PROCEEDINGS OF THE 2011 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P15
   Popescu AC, 2004, LECT NOTES COMPUT SC, V3200, P128
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Pyatykh S, 2013, IEEE T IMAGE PROCESS, V22, P687, DOI 10.1109/TIP.2012.2221728
   Stamm MC, 2011, IEEE T INF FOREN SEC, V6, P1050, DOI 10.1109/TIFS.2011.2119314
   Zhu Y, 2016, MULTIMED TOOLS APPL, V75, P3221, DOI 10.1007/s11042-014-2431-2
   Zoran D, 2009, IEEE I CONF COMP VIS, P2209, DOI 10.1109/ICCV.2009.5459476
NR 31
TC 44
Z9 50
U1 1
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2017
VL 76
IS 4
BP 4783
EP 4799
DI 10.1007/s11042-016-3712-8
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EO9PL
UT WOS:000397020500007
DA 2024-07-18
ER

PT J
AU Cai, ZQ
   Hu, SY
   Shi, YK
   Wang, Q
   Zhang, DY
AF Cai, Zhaoquan
   Hu, Shiyi
   Shi, Yukai
   Wang, Qing
   Zhang, Dongyu
TI Multiple human tracking based on distributed collaborative cameras
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-object tracking; Collaborative cameras; Video surveillance
ID REPRESENTATION; PEOPLE
AB Due to the horizon limitation of single camera, it is difficult for single camera based multi-object tracking system to track multiple objects accurately. In addition, the possible object occlusion and ambiguous appearances often degrade the performance of single camera based tracking system. In this paper, we propose a new method of multi-object tracking by using multi-camera network. This method can handle many problems in the existing tracking systems, such as partial and total occlusion, ambiguity among objects, time consuming and etc. Experimental results of the prototype of our system on three pedestrian tracking benchmarks demonstrate the effectiveness and practical utility of the proposed method.
C1 [Cai, Zhaoquan] Huizhou Univ, Comp Sci, Huizhou, Peoples R China.
   [Hu, Shiyi] Sun Yat Sen Univ, Sch Data & Comp Sci, Comp Sci, Guangzhou, Guangdong, Peoples R China.
   [Shi, Yukai] Sun Yat Sen Univ, Sch Data & Comp Sci, Software Engn, Guangzhou, Guangdong, Peoples R China.
   [Wang, Qing] Sun Yat Sen Univ, Sch Software, Guangzhou, Guangdong, Peoples R China.
   [Zhang, Dongyu] Sun Yat Sen Univ, Guangzhou, Guangdong, Peoples R China.
C3 Huizhou University; Sun Yat Sen University; Sun Yat Sen University; Sun
   Yat Sen University; Sun Yat Sen University
RP Zhang, DY (corresponding author), Sun Yat Sen Univ, Guangzhou, Guangdong, Peoples R China.
EM cszhangdy@163.com
RI Hu, Shiyi/HHS-4731-2022
FU National High Technology Research and Development Program of China (863
   program) [2013AA013801]; NSFC funds of China [61370185, 61170193,
   61401125]; Natural Science Foundation of Guangdong Province, China
   [S2013010013432, S2012020011081, S2013040012570]; Science and Technology
   Plane of Guangdong Province [2013B010406005]
FX This work is partially supported by National High Technology Research
   and Development Program of China (863 program) under Contract No.
   2013AA013801, the NSFC funds of China under Contract No. 61370185,
   61170193, 61401125, the Natural Science Foundation of Guangdong
   Province, China, under Contract No. S2013010013432, S2012020011081,
   S2013040012570, and the Science and Technology Plane of Guangdong
   Province, under Contract No. 2013B010406005.
CR Andriluka M., 2008, P IEEE C COMPUTER VI
   [Anonymous], 2007, P SE SAS US GROUP SE
   [Anonymous], 2004, Multiple View Geometry in Computer Vision
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P 6 INT C DISTR SMAR
   [Anonymous], ICCV
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bredereck M., 2012, Proceedings of the 6th International Conference on Distributed Smart Cameras, P1
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Breitenstein MD, 2009, IEEE I CONF COMP VIS, P1515, DOI 10.1109/ICCV.2009.5459278
   Choi W, 2010, LECT NOTES COMPUT SC, V6314, P553, DOI 10.1007/978-3-642-15561-1_40
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Fragkiadaki K, 2012, LECT NOTES COMPUT SC, V7576, P552, DOI 10.1007/978-3-642-33715-4_40
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Jiang XY, 2012, LECT NOTES COMPUT SC, V7594, P743, DOI 10.1007/978-3-642-33564-8_89
   Khan SM, 2009, IEEE T PATTERN ANAL, V31, P505, DOI 10.1109/TPAMI.2008.102
   Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Lin L, 2016, IEEE T CYBERNETICS, V46, P2447, DOI 10.1109/TCYB.2015.2478515
   Lin L, 2015, IEEE T PATTERN ANAL, V37, P959, DOI 10.1109/TPAMI.2014.2359888
   Lin L, 2014, IEEE T IMAGE PROCESS, V23, P3191, DOI 10.1109/TIP.2014.2326776
   Lin L, 2013, IEEE T CIRC SYST VID, V23, P577, DOI 10.1109/TCSVT.2012.2210804
   Lin L, 2012, IEEE T IMAGE PROCESS, V21, P4844, DOI 10.1109/TIP.2012.2211373
   Lin L, 2009, PATTERN RECOGN, V42, P1297, DOI 10.1016/j.patcog.2008.10.033
   Liu N, 2015, IEEE T CYBERNETICS, V45, P89, DOI 10.1109/TCYB.2014.2320493
   Liu XB, 2011, IEEE T CIRC SYST VID, V21, P393, DOI 10.1109/TCSVT.2010.2087570
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Orwell J., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P1104, DOI 10.1109/ICIAP.1999.797748
   Schindler K, 2007, P IEEE INT C COMPUTE, P1
   Shitrit H., 2013, IEEE Transactions on Pattern Analysis and Machine Intelligence, V36, P1614
   Wan JQ, 2015, INT J DISTRIB SENS N, DOI 10.1155/2015/591067
   Wang KZ, 2015, IEEE T IMAGE PROCESS, V24, P3019, DOI 10.1109/TIP.2015.2432712
   Zhang L, 2008, P IEEE C COMPUTER VI, P1
NR 39
TC 4
Z9 4
U1 1
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1941
EP 1957
DI 10.1007/s11042-015-3163-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000016
DA 2024-07-18
ER

PT J
AU Chong, SC
   Teoh, ABJ
   Ong, TS
AF Chong, Siew-Chin
   Teoh, Andrew Beng Jin
   Ong, Thian-Song
TI Unconstrained face verification with a dual-layer block-based metric
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Unconstrained face; Metric learning; Block-based; Verification;
   Restricted
AB In this paper, a dual-layer block-based metric learning technique is proposed to better discriminate the face image pairs and accelerate the overall verification process under the unconstrained environment. The input images are processed as blocks to provide a richer base of face features. Our proposed method is formed by two layers, in which the first layer assists in extracting the compact block-based descriptors without the existence of full class label information and to refine the within-class and between-class scatter matrices while the second layer integrates the face descriptors of all blocks. The proposed scheme has computational advantage over the single metric learning method while it exploits the correlations among the multiple metrics from different descriptors. The performance of our proposed method is evaluated on the Labeled Faces in the Wild database and achieves an improved performance when compared with the state-of-the-art methods in terms of verification rate and computation time.
C1 [Chong, Siew-Chin; Ong, Thian-Song] Multimedia Univ, Fac Informat Sci & Technol, Melaka, Malaysia.
   [Teoh, Andrew Beng Jin] Yonsei Univ, Sch Elect & Elect Engn, Seoul, South Korea.
C3 Multimedia University; Yonsei University
RP Teoh, ABJ (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul, South Korea.
EM chong.siew.chin@mmu.edu.my; bjteoh@yonsei.ac.kr; tsong@mmu.edu.my
RI CHONG, SIEW CHIN/B-3508-2010; Ong, Thian Song/Q-6932-2018; Teoh, Andrew
   Beng Jin/F-4422-2010
OI Ong, Thian Song/0000-0002-5867-9517; Chong, Siew
   Chin/0000-0003-0421-4367; Teoh, Andrew Beng Jin/0000-0001-5063-9484
FU Fundamental Research Grant Scheme (FRGS) of Malaysia [MMUE/140026]
FX This research is supported by Fundamental Research Grant Scheme (FRGS)
   of Malaysia under grants MMUE/140026.
CR Ahonen T, 2007, P FINN SIGN PROC S F
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Anila S, 2012, GLOBAL J COMPUTER SC
   [Anonymous], AS C COMP VIS ACCV
   [Anonymous], BRIT MACH VIS C
   [Anonymous], CVPR
   [Anonymous], TR115 NEC
   Barkan O, 2013, IEEE I CONF COMP VIS, P1960, DOI 10.1109/ICCV.2013.246
   Cao Q, 2013, INT C COMP VIS ICCV
   Censor Y., 1998, PARALLEL OPTIMIZATIO
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen D, 2013, COMPUT VISION PATTER
   Chen LM, 2013, IEEE ICC
   Cui Z, 2013, IEEE C COMP VIS PATT
   Davis J. V., 2007, ICML, P209
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fan H, 2014, TECHNICAL REPORT
   Guillaumin M, 2009, INT C COMP VIS ICCV
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang D, 2011, IEEE T SYSTEMS MAN C
   Huang D, 2007, LECT NOTES COMPUT SC, V4842, P437
   Kan M, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011
   Li Z, 2010, INT C PATT REC
   Nguyen H.V., 2011, THESIS
   Pollard D., 2002, A User's Guide to Measure Theoretic Probability
   Simonyan K, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.8
   Sun Y, 2014, LECT NOTES COMPUT SC, V8835, P279, DOI 10.1007/978-3-319-12640-1_34
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Welling M., 2005, Technical Report
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wolf L, 2008, EUR C COMP VIS
   Wolf L, 2011, IEEE T PATTERN ANAL
   Yang H, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P645, DOI 10.1109/ICIG.2007.144
   Zhang N., 2007, Tech. Rep. 07-49, P7
NR 38
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 1703
EP 1719
DI 10.1007/s11042-015-3120-5
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000005
DA 2024-07-18
ER

PT J
AU Lee, SS
   Huang, YJ
   Lin, JC
AF Lee, Suiang-Shyan
   Huang, Yi-Jheng
   Lin, Ja-Chen
TI Protection of 3D models using cross recovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cross recovery; Sharing of 3D models; Authentication; Mutual support;
   Size-estimation formula
ID WATERMARKING; ALGORITHM; STEGANOGRAPHY; TECHNOLOGIES; COMPRESSION;
   MESHES
AB This paper proposes a cross recovery scheme to protect a group of 3D models. The lost or damaged models can be reconstructed using the mutual support of the survived authenticated models. In the encoding phase, we convert a group of n given models (called host models) into n stego* models. The n stego* models would still preserve the appearance of the n host models. In the decoding phase, we divide the received models into two groups: authenticated vs. non-authenticated. Then, we rebuild the recovered models of the non-authenticated group by the mutual support of any t authenticated models (t < n is a given parameter). The experimental results show that the visual quality of our stego* models is very similar to that of the host models, and the size of the stego* models is also very similar to that of the host models. Moreover, after hacker's attack or disk crash, if the number of attacked or crashed stego* models is not larger than n - t, then the damaged or lost models can be recovered, and the recovered models still have acceptable quality. We also provide an equation which can estimate the suitable size of the recovered model in advance.
C1 [Lee, Suiang-Shyan; Huang, Yi-Jheng; Lin, Ja-Chen] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30050, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Lee, SS (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 30050, Taiwan.
EM sslee@cs.nctu.edu.tw; jennyhuang914@gmail.com; jclin@cs.nctu.edu.tw
CR Alregib G, 2005, ACM T GRAPHIC, V24, P182, DOI 10.1145/1061347.1061349
   Bischoff S, 2002, COMPUT GRAPH-UK, V26, P665, DOI 10.1016/S0097-8493(02)00122-X
   Blakley G. R., 1979, 1979 International Workshop on Managing Requirements Knowledge (MARK), P313, DOI 10.1109/MARK.1979.8817296
   Bogomjakov A, 2008, COMPUT GRAPH FORUM, V27, P637, DOI 10.1111/j.1467-8659.2008.01161.x
   Cayre F, 2003, IEEE T SIGNAL PROCES, V51, P939, DOI 10.1109/TSP.2003.809380
   Chao MW, 2009, IEEE T VIS COMPUT GR, V15, P274, DOI 10.1109/TVCG.2008.94
   Chen XB, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531379
   Cheng YM, 2006, VISUAL COMPUT, V22, P845, DOI 10.1007/s00371-006-0069-4
   Chou CM, 2007, INT J COMPUT SCI NET, V7, P328
   Chung IL, 2011, INT J INNOV COMPUT I, V7, P3419
   Deng H, 2012, INT C MULTIMED INFO, P549, DOI 10.1109/MINES.2012.11
   Elsheh E, 2011, EXPERT SYST APPL, V38, P13906, DOI 10.1016/j.eswa.2011.04.197
   HANSEN C.D., 2005, The visualization handbook
   Lin C. K., 2009, P 2009 APSIPA ANN SU, P178
   Lin CH, 2013, INT J INNOV COMPUT I, V9, P1321
   Ohbuchi R, 2004, 2004 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P392, DOI 10.1109/CW.2004.70
   Ohbuchi R, 2002, COMPUT GRAPH FORUM, V21, P373, DOI 10.1111/1467-8659.t01-1-00597
   Peng JL, 2005, J VIS COMMUN IMAGE R, V16, P688, DOI 10.1016/j.jvcir.2005.03.001
   REED IS, 1960, J SOC IND APPL MATH, V8, P300, DOI 10.1137/0108018
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Tsai YY, 2014, MULTIMED TOOLS APPL, V69, P859, DOI 10.1007/s11042-012-1135-8
   Tu S., 2010, INT J VIRTUAL REALIT, V9, P55
   Tu SC, 2012, COMPUT GRAPH-UK, V36, P767, DOI 10.1016/j.cag.2012.06.002
   Wang CM, 2005, COMPUT GRAPH FORUM, V24, P591, DOI 10.1111/j.1467-8659.2005.00884.x
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Wicker S.B., 1999, Reed-Solomon codes and their applications
   Yu F., 2011, 3 DIMENSIONAL MODEL
NR 28
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 243
EP 264
DI 10.1007/s11042-015-3032-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000012
DA 2024-07-18
ER

PT J
AU Mollaeefar, M
   Sharif, A
   Nazari, M
AF Mollaeefar, Majid
   Sharif, Amir
   Nazari, Mahboubeh
TI A novel encryption scheme for colored image based on high level chaotic
   maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Chaos; Image cryptography; Lyapunov exponent; Security
ID ALGORITHM; SYSTEM
AB In the following paper, the novel method for color image encryption has proposed based on high level chaotic maps . We introduced two novel chaotic maps "Cosinus-Arcsinus (CA)" and "Sinus-Power Logistic (SPL)", which have better chaotic behaviour against other available chaotic maps. Our scheme like other image encryption schemes has two main phases, which are pixel shuffling and pixel diffusion. We made an efficient chaotic permutation method, which is extremely dependent on plain image. The proposed method compared with other availabale permutation methods in pixel shuffling stage has a better performance with a lower computational overhead. Another advantage of our permutation method is less correlation between adjacent pixels in the permuted image, which causes high confusion levels with lower iterations. In pixel diffusion phase, we introduced coupled map based on SPL map to change each color component distinctly. Moreover, we used CA map to generate three chaotic sequences for deriving initial seeds of coupled map in a random manner. Followed by three chaotic matrix will be created to change pixels color component values. The proposed diffusion phase implies desirable uniformly distributation in color histogram of encrypted image and makes the scheme robust against statistical attacks. In addition, creating secret keys in a large size and high sensitivity to the original pictures leads acceptable results in the average of NPCR (99.67), UACI (33.45), and resistance against brute-force attack. The experimental results reveal that the new image encryption scheme has the charectristics of 'secure encryption algorithm' such as, large key space, high security and high sensitivity.
C1 [Mollaeefar, Majid; Sharif, Amir] Imam Reza Int Univ, Dept Comp & Informat Technol, Mashhad, Iran.
   [Nazari, Mahboubeh] Ferdowsi Univ Mashhad, Dept Math, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Sharif, A (corresponding author), Imam Reza Int Univ, Dept Comp & Informat Technol, Mashhad, Iran.
EM m.mollaeefar@imamreza.ac.ir; amir-sharif@hotmail.com
RI Nikooghadam, Morteza/AAR-7984-2020; Sharif, Amir/Y-7447-2019
OI Nikooghadam, Morteza/0000-0003-3894-3103; Sharif,
   Amir/0000-0001-6290-3588; /0000-0002-0277-3029
CR [Anonymous], 2014, 3D RES
   [Anonymous], 2010, IJ NETWORK SECURITY
   Arshad H, 2016, MULTIMED TOOLS APPL, V75, P181, DOI 10.1007/s11042-014-2282-x
   Arshad H, 2015, J SUPERCOMPUT, V71, P3163, DOI 10.1007/s11227-015-1434-8
   Arshad H, 2015, J MED SYST, V39, DOI 10.1007/s10916-015-0259-6
   Arshad H, 2014, J MED SYST, V38, DOI 10.1007/s10916-014-0136-8
   Chen JY, 2011, IEEE T CIRCUITS-II, V58, P110, DOI 10.1109/TCSII.2011.2106316
   Dong CE, 2014, SIGNAL PROCESS-IMAGE, V29, P628, DOI 10.1016/j.image.2013.09.006
   Gao HJ, 2006, CHAOS SOLITON FRACT, V29, P393, DOI 10.1016/j.chaos.2005.08.110
   Huang CK, 2009, OPT COMMUN, V282, P2123, DOI 10.1016/j.optcom.2009.02.044
   Huang XL, 2012, NONLINEAR DYNAM, V67, P2411, DOI 10.1007/s11071-011-0155-7
   Hussain I, 2014, NONLINEAR DYNAM, V76, P1355, DOI 10.1007/s11071-013-1214-z
   Kaur R, 2013, IOSR J COMPUT ENG IO
   Li JH, 2013, IET INFORM SECUR, V7, P265, DOI 10.1049/iet-ifs.2012.0304
   Liu HJ, 2015, OPT COMMUN, V338, P340, DOI 10.1016/j.optcom.2014.10.021
   SaberiKamarposhti M, 2014, NONLINEAR DYNAM, V75, P407, DOI 10.1007/s11071-013-0819-6
   Sam IS, 2012, NONLINEAR DYNAM, V69, P1995, DOI 10.1007/s11071-012-0402-6
   Seyedzadeh S. M., 2015, NONLINEAR DYNAM, V81, P1
   Seyedzadeh SM, 2012, SIGNAL PROCESS, V92, P1202, DOI 10.1016/j.sigpro.2011.11.004
   Si HQ, 2014, SCI WORLD J, DOI 10.1155/2014/371045
   Solak E, 2010, OPT COMMUN, V283, P232, DOI 10.1016/j.optcom.2009.09.070
   Wang Y, 2011, APPL SOFT COMPUT, V11, P514, DOI 10.1016/j.asoc.2009.12.011
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Zhang Y., 2010, P INT C COMPUTER COM
   Zhang YS, 2014, AEU-INT J ELECTRON C, V68, P361, DOI 10.1016/j.aeue.2013.10.002
   Zhou YC, 2014, SIGNAL PROCESS, V97, P172, DOI 10.1016/j.sigpro.2013.10.034
   Zhu CX, 2012, OPT COMMUN, V285, P29, DOI 10.1016/j.optcom.2011.08.079
   Zhu ZL, 2011, INFORM SCIENCES, V181, P1171, DOI 10.1016/j.ins.2010.11.009
NR 28
TC 71
Z9 71
U1 2
U2 52
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 607
EP 629
DI 10.1007/s11042-015-3064-9
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000027
DA 2024-07-18
ER

PT J
AU Saavedra, JM
AF Saavedra, Jose M.
TI RST-SHELO: sketch-based image retrieval using sketch tokens and square
   root normalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sketch based image retrieval; Histogram of orientations; Sketch tokens
ID PERFORMANCE EVALUATION; HISTOGRAM
AB Sketch-based image retrieval (SBIR) is an emergent research area with a variety of applications, specially when an example image is not available for querying. Moreover, making a sketch has become a very attractive and simple task due to the already ubiquitous touch-screen and mobile technologies. Although a sketch is a natural way for representing the structure of a thought object, it may easily get confused in a dataset with high variability turning the retrieval task a quite challenging problem. Indeed, the state-of-the-art methods still show low performance on diverse evaluation datasets. Thereby, a robust sketch descriptor together with a better strategy for representing regular images as sketches are demanded. In this work, we present RST-SHELO, and improved version of SHELO (Soft Histogram of Edge Logal Orientations), an efficient state-of-the-art method for describing sketches. The proposed improvements comes from two aspects: a better technique for obtaining sketch-like representations and a better normalization strategy of SHELO. For the first case, we propose to use the sketch token approach [21], aiming to detect image contours by means of mid-level features. For the second case, we demonstrate that a square root normalization positively affect the effectiveness on the retrieval task. Based on our improvements, we present new state-of-the-art performance. To validate our achievements, we have conducted diverse experiments using two public datasets, Flickr15K and Saavedra's. Our results show an effectiveness gain of 62 % in the first and 5 % in the second dataset.
C1 [Saavedra, Jose M.] Orand SA, Orand Res, Estado 360 702, Santiago, Chile.
RP Saavedra, JM (corresponding author), Orand SA, Orand Res, Estado 360 702, Santiago, Chile.
EM jose.saavedra@orand.cl
OI Saavedra Rondo, Jose Manuel/0000-0002-9644-5164
FU CONICYT [PAI-781204025, 14STIC-01]; CORFO-INNOVA [15ITE2-38948]
FX We are grateful for financial support from two chilean institutions:
   CONICYT, through the projects PAI-781204025 and 14STIC-01, and
   CORFO-INNOVA, through the project 15ITE2-38948.
CR [Anonymous], SIGGRAPH 2009 TALKS
   ARANDJELOVIC R, 2012, PROC CVPR IEEE, P2911, DOI DOI 10.1109/CVPR.2012.6248018
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Eitz Mathias., 2009, P 6 EUR S SKETCH BAS, P29
   Fei-Fei L, 2004, LENING GENERATIVE VI
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LI B., 2012, EurographicsWorkshop on 3D Object Retrieval, P109
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Rui Hu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3661, DOI 10.1109/ICIP.2011.6116513
   Saavedra JM, 2013, SKETCH BASED IMAGE R
   Saavedra JM, 2014, INT C IM PR IN PRESS
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Won CS, 2002, ETRI J, V24, P23, DOI 10.4218/etrij.02.0102.0103
NR 28
TC 10
Z9 14
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 1
BP 931
EP 951
DI 10.1007/s11042-015-3076-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2BT
UT WOS:000392292000040
DA 2024-07-18
ER

PT J
AU Xing, XF
   Qiu, FH
   Xu, XM
   Qing, CM
   Wu, YR
AF Xing, Xiaofen
   Qiu, Fuhao
   Xu, Xiangmin
   Qing, Chunmei
   Wu, Yinrong
TI Robust object tracking based on sparse representation and incremental
   weighted PCA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Tracking; Sparse representation; Incremental weighted PCA
ID VISUAL TRACKING
AB Object tracking plays a crucial role in many applications of computer vision, but it is still a challenging problem due to the variations of illumination, shape deformation and occlusion. A new robust tracking method based on incremental weighted PCA and sparse representation is proposed. An iterative process consisting of a soft segmentation step and a foreground distribution update step is adpoted to estimate the foreground distribution, cooperating with incremental weighted PCA, we can get the target appearance in terms of the PCA components with less impact of the background in the target templates. In order to make the target appearance model more discriminative, trivial and background templates are both added to the dictionary for sparse representation of the target appearance. Experiments show that the proposed method with some level of background awareness is robust against illumination change, occlusion and appearance variation, and outperforms several latest important tracking methods in terms of tracking performance.
C1 [Xing, Xiaofen; Qiu, Fuhao; Xu, Xiangmin; Qing, Chunmei; Wu, Yinrong] South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
C3 South China University of Technology
RP Xu, XM (corresponding author), South China Univ Technol, Sch Elect & Informat Engn, Guangzhou, Guangdong, Peoples R China.
EM xmxu@scut.edu.cn
FU National Natural Science Foundation of China [61171142, 61401163];
   Science and Technology Planning Project of Guangdong Province of China
   [2011A010801005]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No.61171142, 61401163), and the Science and Technology
   Planning Project of Guangdong Province of China (No. 2011A010801005).
CR [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247881
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Cehovin L, 2013, IEEE T PATTERN ANAL, V35, P941, DOI 10.1109/TPAMI.2012.145
   Cehovin L, 2011, IEEE I CONF COMP VIS, P1363, DOI 10.1109/ICCV.2011.6126390
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Cota N, 2015, 2015 6 INT C INF COM, P1, DOI DOI 10.1109/ICTEMSYS.2015.7110833
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Grabner H., 2006, BMVC, P47
   Guo KL, 2013, IEEE IMAGE PROC, P3914, DOI 10.1109/ICIP.2013.6738806
   Hale ET, 2008, SIAM J OPTIMIZ, V19, P1107, DOI 10.1137/070698920
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Klein DA, 2010, IEEE INT C INT ROBOT, P772, DOI 10.1109/IROS.2010.5650583
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Oron S, 2012, PROC CVPR IEEE, P1940, DOI 10.1109/CVPR.2012.6247895
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Zha Y, 2015, MULTIMED TOOLS APPL, P1
   Zhang BC, 2015, IEEE WINT CONF APPL, P25, DOI 10.1109/WACV.2015.11
   Zhang K, ARXIV13111939
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 32
TC 4
Z9 4
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2017
VL 76
IS 2
BP 2039
EP 2057
DI 10.1007/s11042-015-3164-6
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EI2GN
UT WOS:000392305000021
DA 2024-07-18
ER

PT J
AU Ding, IJ
   Chang, CW
AF Ding, Ing-Jr
   Chang, Che-Wei
TI An adaptive hidden Markov model-based gesture recognition approach using
   Kinect to simplify large-scale video data processing for humanoid robot
   imitation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Kinect; Humanoid robot; Gesture recognition; Hidden Markov model; User
   adaptation
ID SYSTEM
AB Human gesture recognition to be a new type of natural user interface (NUI) using the person's gesture action for operating the device is attracting much attention nowadays. In this study, an adaptive hidden Markov model (HMM)-based gesture recognition method with user adaptation (UA) using the Kinect camera to simplify large-scale video processing is designed to be the NUI of a humanoid robot device. The popular Kinect camera is employed for acquiring the gesture signals made by the active user, and the gesture action from the user can then be recognized and used to be as the control command for driving the humanoid robot to imitate the user's actions. The large-scale video data can be reduced by the Kinect camera where the data from the Kinect camera for representing gesture signals includes the depth measurement information, and therefore only simple 3-axis coordinate information of the joints in a human skeleton is analyzed, categorized and managed in the developed system. By the presented scheme, the humanoid robot will imitate the human active gesture according to the content of the received gesture command. The well-known HMM pattern recognition method with the support of the Kinect device is explored to classify the human's active gestures where a user adaptation scheme of MAP+GoSSRT that enhances MAP by incorporating group of states shifted by referenced transfer (GoSSRT) is proposed for adjusting HMM parameters, which will further increase the recognition accuracy of HMM gesture recognition. Human gesture recognition experiments for controlling the activity of the humanoid robot were performed on the indicated 14 classes of human active gestures. Experimental results demonstrated the superiority of the NUI by presented HMM gesture recognition with user adaptation for humanoid robot imitation applications.
C1 [Ding, Ing-Jr; Chang, Che-Wei] Natl Formosa Univ, Dept Elect Engn, 64 Wunhua Rd, Huwei Township 632, Yunlin, Taiwan.
C3 National Formosa University
RP Ding, IJ (corresponding author), Natl Formosa Univ, Dept Elect Engn, 64 Wunhua Rd, Huwei Township 632, Yunlin, Taiwan.
EM ingjr@nfu.edu.tw
FU Ministry of Science and Technology (MOST) in Taiwan [MOST
   103-2218-E-150-004]
FX This research is partially supported by the Ministry of Science and
   Technology (MOST) in Taiwan under Grant MOST 103-2218-E-150-004.
CR Afthoni R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS, BIOMIMETICS, AND INTELLIGENT COMPUTATIONAL SYSTEMS (ROBIONETICS), P24, DOI 10.1109/ROBIONETICS.2013.6743572
   [Anonymous], J CONVERGENCE
   Bhattacharjee D, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0004-z
   Chakravarty K, 2014, LECT NOTES COMPUT SC, V8511, P215, DOI 10.1007/978-3-319-07230-2_21
   Cheng LY, 2012, CHIN CONT DECIS CONF, P971, DOI 10.1109/CCDC.2012.6242992
   Ding IJ, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/898729
   Ding IJ, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/542680
   Ding IJ, 2013, INT J INNOV COMPUT I, V9, P555
   Ding IJ, 2013, J INTELL FUZZY SYST, V25, P49, DOI 10.3233/IFS-2012-0613
   Feese S, 2014, HUMAN CENTRIC COMPUT, V4, P18
   Hoang T, 2013, J INF PROCESS SYST, V9, P333, DOI 10.3745/JIPS.2013.9.2.333
   Kim E, 2014, J INF PROCESS SYST, V10, P335, DOI 10.3745/JIPS.04.0005
   Kim J.S., 2013, J CONVERG, V4, P31
   Malkawi M, 2013, HUM-CENT COMPUT INFO, V3, DOI 10.1186/2192-1962-3-3
   Oh J, 2014, J CONVERG, V5, P21
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Sinha A, 2013, IEEE SYS MAN CYBERN, P497, DOI 10.1109/SMC.2013.91
   Tashev I, 2013, IEEE SIGNAL PROC MAG, V30, P129, DOI 10.1109/MSP.2013.2266959
   Verma OP, 2013, J INF PROCESS SYST, V9, P575, DOI 10.3745/JIPS.2013.9.4.575
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 20
TC 22
Z9 23
U1 0
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15537
EP 15551
DI 10.1007/s11042-015-2505-9
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700026
DA 2024-07-18
ER

PT J
AU Grzejszczak, T
   Kawulok, M
   Galuszka, A
AF Grzejszczak, Tomasz
   Kawulok, Michal
   Galuszka, Adam
TI Hand landmarks detection and localization in color images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gesture recognition; Hand pose estimation; Hand landmarks detection;
   Human-computer interaction; Directional image
ID GESTURE RECOGNITION; POSE ESTIMATION; TRACKING
AB This paper introduces a new method for detecting and localizing hand landmarks in 2D color images. Location of the hand landmarks is an important source of information for recognizing hand gestures, effectively exploited in a number of recent methods which operate from the depth maps. However, this problem has not yet been satisfactorily solved for 2D color images. Here, we propose to analyze the skin-presence masks, as well as the directional image of a hand using the distance transform and template matching. This makes it possible to detect the landmarks located both at the contour and inside the hand masks. Moreover, we performed an extensive experimental study to compare the proposed method with a number of state-of-the-art algorithms. The obtained quantitative and qualitative results clearly indicate that our approach outperforms other methods, which may help improve the existing gesture recognition systems.
C1 [Grzejszczak, Tomasz; Galuszka, Adam] Silesian Tech Univ, Inst Automat Control, Gliwice, Poland.
   [Kawulok, Michal] Silesian Tech Univ, Inst Informat, Gliwice, Poland.
C3 Silesian University of Technology; Silesian University of Technology
RP Grzejszczak, T (corresponding author), Silesian Tech Univ, Inst Automat Control, Gliwice, Poland.
EM tomasz.grzejszczak@polsl.pl; michal.kawulok@polsl.pl;
   adam.galuszka@polsl.pl
RI Grzejszczak, Tomasz/ABY-2058-2022; Galuszka, Adam/ABB-2203-2021;
   Galuszka, Adam/GSN-7717-2022; Kawulok, Michal/K-9359-2017
OI Galuszka, Adam/0000-0002-6176-0500; Galuszka, Adam/0000-0002-6176-0500;
   Kawulok, Michal/0000-0002-3669-5110; Grzejszczak,
   Tomasz/0000-0002-1114-3619
FU Institute of Automatic Control [BK-227/RAu1/2015/1]; Institute of
   Informatics internal funds [BKM-515/RAu2/2015]; "GeCONiI-Upper Silesian
   Center for Computational Science and Engineering
   [POIG.02.03.01-24-099/13]
FX The work of TG and AG has been supported by Institute of Automatic
   Control BK-227/RAu1/2015/1 funds in the year 2015. The work of MK has
   been supported by Institute of Informatics internal funds no.
   BKM-515/RAu2/2015. The research was performed on the infrastructure
   supported by POIG.02.03.01-24-099/13 grant: "GeCONiI-Upper Silesian
   Center for Computational Science and Engineering.
CR Ankit Chaudhary J.L, 2013, ABS13032292 CORR
   [Anonymous], 2013, P 10 IEEE INT C WORK
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   Appenrodt J., 2010, International Journal of Signal Process- ing, Image Processing and Pattern Recognition, V3, P37
   Bellal A, 2011, INT REV RED CROSS, V93, P47, DOI 10.1017/S1816383111000051
   Boyle, 2014, CENGAGE LEARNING
   Cooper H, 2007, LECT NOTES COMPUT SC, V4796, P88
   Czupryna M, 2012, ELMAR PROC, P49
   Dung L, 2009, J ROBOT MECHATRON, V21, P726, DOI 10.20965/jrm.2009.p0726
   Dutagaci H, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2890986
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Feng ZQ, 2011, PATTERN RECOGN, V44, P1089, DOI 10.1016/j.patcog.2010.08.007
   Ge SS, 2008, IMAGE VISION COMPUT, V26, P1607, DOI 10.1016/j.imavis.2008.03.004
   Grzejszczak T, 2013, ADV INTELL SYST, V226, P439, DOI 10.1007/978-3-319-00969-8_43
   Grzejszczak T, 2014, IFIP ADV INF COMM TE, V423, P167
   Grzejszczak T, 2012, LECT NOTES COMPUT SC, V7594, P407, DOI 10.1007/978-3-642-33564-8_49
   Hagara M, 2013, 2013 23RD INTERNATIONAL CONFERENCE RADIOELEKTRONIKA (RADIOELEKTRONIKA), P356, DOI 10.1109/RadioElek.2013.6530945
   Hoshino K, 2010, INTEL SERV ROBOT, V3, P11, DOI 10.1007/s11370-009-0052-9
   Ibraheem N.A., 2012, INT J COMPUTER APPL, V50, P38
   Infantino I, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1266
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Kawulok M, 2012, IET IMAGE PROCESS, V6, P95, DOI 10.1049/iet-ipr.2010.0495
   Kawulok M., 2014, Advances in Low-Level Color Image Processing. Lecture Notes in Computational Vision and Biomechanics, V11, P329
   Kawulok M, 2014, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2014-170
   Kawulok M, 2014, PATTERN RECOGN LETT, V41, P3, DOI 10.1016/j.patrec.2013.08.028
   Kawulok M, 2012, LECT NOTES COMPUT SC, V7626, P557, DOI 10.1007/978-3-642-34166-3_61
   Kerdvibulvech C, 2014, EURASIP J EMBED SYST, DOI 10.1186/s13639-014-0018-7
   Kim D, 2013, J SUPERCOMPUT, V65, P336, DOI 10.1007/s11227-010-0541-9
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Koller O., 2013, P 2013 10 IEEE INT C, P1, DOI DOI 10.1109/FG.2013.6553777
   Liang H, 2013, VISUAL COMPUT, V29, P837, DOI 10.1007/s00371-013-0822-4
   Licsár A, 2004, LECT NOTES COMPUT SC, V3058, P83
   Liu L., 2013, 23 INT JOINT C ART I
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Molina J, 2013, MACH VISION APPL, V24, P187, DOI 10.1007/s00138-011-0364-6
   Nalepa J, 2014, COMM COM INF SC, V424, P364
   Nalepa J, 2014, ADV INTEL SOFT COMPU, V242, P79, DOI 10.1007/978-3-319-02309-0_8
   Nalepa J, 2013, IEEE INT SYM MULTIM, P401, DOI 10.1109/ISM.2013.76
   Oka K, 2002, IEEE COMPUT GRAPH, V22, P64, DOI 10.1109/MCG.2002.1046630
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Ren Z., 2011, P 19 ACM INT C MULT, P759
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Ruiz-del-Solar J, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P463, DOI 10.1109/AFGR.2004.1301576
   Sato Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P462, DOI 10.1109/AFGR.2000.840675
   Shi Y, 2010, INT CONF SIGN PROCES, P893, DOI 10.1109/ICOSP.2010.5656041
   Shirazi AS, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P3483, DOI 10.1145/2556288.2557208
   Sridhar S, 2013, IEEE I CONF COMP VIS, P2456, DOI 10.1109/ICCV.2013.305
   Srivastava A, 2012, IMAGE VISION COMPUT, V30, P398, DOI 10.1016/j.imavis.2012.03.006
   Stergiopoulou E, 2009, ENG APPL ARTIF INTEL, V22, P1141, DOI 10.1016/j.engappai.2009.03.008
   Suau X, 2014, IMAGE VISION COMPUT, V32, P522, DOI 10.1016/j.imavis.2014.04.015
   Sun Y, 2008, RECOGNIZING PARTIAL
   Tang M., 2011, Recognizing hand gestures with microsofts kinect
   Tanibata N., 2002, PROC INT C VISION IN, P391
   Thalmann Daniel., 2012, P 20 ACM INT C MULTI, P785, DOI DOI 10.1145/2393347.2396312
   Tsagaris A, 2012, P INT S MECHATRONIKA, P1
   Vanco M, 2014, INT CONF SYST SIGNAL, P83
   Wang Y, 2014, MULTIMED TOOLS APPL, V71, P555, DOI 10.1007/s11042-013-1524-7
   Wilcox S, 1992, THE PHONETICS OF FIN, V4
   Yang HD, 2013, PATTERN RECOGN LETT, V34, P2051, DOI 10.1016/j.patrec.2013.06.022
   Yogarajah P, 2010, IEEE IMAGE PROC, P2225, DOI 10.1109/ICIP.2010.5652798
NR 62
TC 41
Z9 42
U1 2
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 16363
EP 16387
DI 10.1007/s11042-015-2934-5
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700066
OA hybrid
DA 2024-07-18
ER

PT J
AU Kang, M
   Islam, S
   Islam, R
   Kim, JM
AF Kang, Myeongsu
   Islam, Shohidul
   Islam, Rashedul
   Kim, Jong-Myon
TI Accelerating the formant synthesis of haegeum sounds using a
   general-purpose graphics processing unit
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Formant synthesis; General-purpose graphics processing unit; Haegeum;
   Sound synthesis
ID SPECTRAL MODELING SYNTHESIS; TIME; GPU
AB Sound synthesis is recently indispensable with sophisticated audio effects for mimicking rich and natural sounds of the musical instruments, and thus sound synthesis acceleration has been an urgent issue. The formant synthesis is employed to produce the various single notes of the haegeum, a representative traditional Korean bowed string instrument. In this study, the formant synthesis process using multiple pairs of digital resonators and band-pass filters is accelerated with the power of a general-purpose graphics processing unit (GPGPU). This paper compares the performance of the proposed GPGPU-based parallel approach with the CPU-based sequential approach in order to validate the effectiveness of the proposed massively parallel method. Experimental results indicate that the proposed parallel approach achieves at least 79 times speedup over the CPU-based approach by exploiting the massive parallelism inherent in the formant sound synthesis algorithm.
C1 [Kang, Myeongsu; Islam, Shohidul; Islam, Rashedul; Kim, Jong-Myon] Univ Ulsan, Sch Elect Elect & Comp Engn, 93 Daehak Ro Mugeo Dong, Ulsan 680749, South Korea.
C3 University of Ulsan
RP Kim, JM (corresponding author), Univ Ulsan, Sch Elect Elect & Comp Engn, 93 Daehak Ro Mugeo Dong, Ulsan 680749, South Korea.
EM jongmyon.kim@gmail.com
RI Islam, Rashedul/AAA-7366-2019; Islam, Md Rashedul/HNB-8604-2023
OI Islam, Rashedul/0000-0001-8676-6338; 
FU National Research Foundation of Korea (NRF) grant - Korean government
   (MEST) [NRF-2013R1A2A2A05004566]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korean government (MEST) (No.
   NRF-2013R1A2A2A05004566).
CR [Anonymous], P NETW DISTR SYST SE
   [Anonymous], J CONVERG
   Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648
   Belloch JA, 2011, J SUPERCOMPUT, V58, P449, DOI 10.1007/s11227-011-0610-8
   Choi J, 2013, J PARALLEL DISTR COM, V73, P1506, DOI 10.1016/j.jpdc.2012.07.013
   Chowning John., 1977, COMPUT MUSIC J, V1, P46
   Divya UJ, 2013, J CONVERS, V4, P6
   Goodwin M, 1996, INT CONF ACOUST SPEE, P1005, DOI 10.1109/ICASSP.1996.543293
   Hsu B, 2013, COMMUN ACM, V56, P54, DOI 10.1145/2461256.2461272
   KLATT DH, 1980, J ACOUST SOC AM, V67, P971, DOI 10.1121/1.383940
   Navalyal GU, 2014, HUM-CENTRIC COMPUT I, V4, DOI 10.1186/s13673-014-0011-0
   Pakarinen J, 2005, INT CONF ACOUST SPEE, P1
   Ranjan R, 2014, P IEEE INT C AC SPEE, P4
   Savloja L, 2010, 128 AES CONVENTIONS, P1
   SERRA X, 1990, COMPUT MUSIC J, V14, P12, DOI 10.2307/3680788
   Trebien F, 2009, VISUAL COMPUT, V25, P469, DOI 10.1007/s00371-009-0341-5
   Tsai Pei-Yin, 2010, P 13 INT C DIG AUD E, P1
   Välimäki V, 2005, IEEE SIGNAL PROC LET, V12, P214, DOI 10.1109/LSP.2004.842271
   Valimaki V, 1996, J AUDIO ENG SOC, V44, P331
   Verma TS, 2000, COMPUT MUSIC J, V24, P47, DOI 10.1162/014892600559317
   Yeh DT, 2010, IEEE T AUDIO SPEECH, V18, P728, DOI 10.1109/TASL.2009.2033978
NR 21
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15445
EP 15459
DI 10.1007/s11042-014-2297-3
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700020
DA 2024-07-18
ER

PT J
AU Kim, DH
   Kim, JM
   Jeong, YS
   Park, KR
AF Kim, Dong-Hyun
   Kim, Jin-Mook
   Jeong, Young-Sik
   Park, Koo-Rack
TI A risk probability-map generation model on multimedia services
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crime prevention; Crime prediction; Markov Chain; Multimedia services;
   Smartphones
AB The rapid growth of modern society has been a double-edged sword; it has led to positive results such as income growth due to the diversification of our society, but also negative results such as an increase in crime. For this reason, cities are confronting a wide range of issues. Social issues, especially criminal offenses, stir up more fear of crime among residents. The rapid societal penetration of digital devices such as smart phones, along with an increase in IT knowledge, has made our lives more convenient. However, cyber-crime and violent crime taking advantage of these benefits are also increasing. There is an increasing need for crime prevention and crime prediction in order to solve these problems, and many studies on crime are under way as part of our effort to respond to various changes in our society using a variety of prediction tools. Thus, in this study, a combined risk probability map generation model was suggested by predicting crime frequency through a Markov Chain Analysis, quantifying risks through objective classification of urban spaces and applying attribute-specific risk indexes and interpretation keys across the entire scope of the study. The crime prediction model based on risk probability map suggested in this study facilitates multimedia services using mobile devices such as smartphones and thus can be used to optimally plan patrol routes of police officers in zones vulnerable to crimes as well as placement of surveillance systems, which will in turn contribute to relieving many citizens' anxiety about crime. Our model's approach is too small environment in this research time. But we will try to more experiment environment is big such as town and state next research time.
C1 [Kim, Dong-Hyun] Woosong Univ, Dept IT Management, Daejeon, South Korea.
   [Kim, Jin-Mook] Sunmoon Univ, Div Informat Technol Educ, Asan, South Korea.
   [Jeong, Young-Sik] Dongguk Univ, Dept Multimedia Engn, Seoul, South Korea.
   [Park, Koo-Rack] Kongju Natl Univ, Div Comp Sci & Engn, Cheonan, South Korea.
C3 Woosong University; Sun Moon University; Dongguk University; Kongju
   National University
RP Kim, JM (corresponding author), Sunmoon Univ, Div Informat Technol Educ, Asan, South Korea.
EM dhkim@wsu.ac.kr; calf0425@sunmoon.ac.kr; ysjeong@dongguk.edu;
   ecgrpark@kongju.ac.kr
RI Kim, Dong-Hyun/AAH-3043-2020
CR Andrienko G, 2007, INT J GEOGR INF SCI, V21, P839, DOI 10.1080/13658810701349011
   [Anonymous], J CONVERGENCE
   [Anonymous], 2010, THESIS
   Balram S, 2006, COLLABORATIVE GEOGRAPHIC INFORMATION SYSTEMS, P1, DOI 10.4018/978-1-59140-845-1
   안상현, 2004, [Journal of the Korean Association of Geographic Information Studies, 한국지리정보학회지], V7, P57
   Cozens P., 2001, PROP MANAG, V19, P136
   Grinstead CM, 1997, AM MATH SOC, P405
   Kim C, 2006, P KOREAN SOC REMOTE, P267
   Lee HJ, 2011, J INF PROCESS SYST, V7, P543, DOI 10.3745/JIPS.2011.7.3.543
   Malkawi M., 2013, J HUMAN CENTRIC COMP, V3, P1
   Park Cheol-Hyun, 2003, [Korean Criminological Review, 형사정책연구], V14, P243
   Saha T, 2011, J INF PROCESS SYST, V7, P653, DOI 10.3745/JIPS.2011.7.4.653
   Welsh BC, 2006, CAMB STUD CRIMINOL, P305
   Young-Gab Kim, 2006, Journal of KISS: Computer Systems and Theory, V33, P524
   노찬숙, 2012, [Journal of The Korea Society of Computer and Information, 한국컴퓨터정보학회논문지], V17, P107
   노찬숙, 2012, [Journal of Korean Institute of Information Technology, 한국정보기술학회논문지], V10, P89
NR 16
TC 1
Z9 2
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15709
EP 15727
DI 10.1007/s11042-014-2441-0
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700037
DA 2024-07-18
ER

PT J
AU Lv, YJ
   Zhao, G
   Yu, Y
AF Lv, Yanjie
   Zhao, Gang
   Yu, Yong
TI A novel method for adaptive knowledge map construction in the aircraft
   development
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Transportation facilities; Aircraft; Knowledge map; Knowledge overload;
   Domain ontology
ID INFORMATION-RETRIEVAL; DOMAIN KNOWLEDGE; MANAGEMENT; SERVICES; INDUSTRY;
   MODEL
AB Aircraft is a typical transportation facility and its development need to refer to the existing knowledge. With the rapid increase of knowledge, a knowledge map may deliver excess knowledge to users that they cannot manage at once, thereby causing the problem of knowledge overload. Hence, a novel method for adaptive knowledge map construction was proposed to solve this problem. First, the knowledge was semantically annotated and stored with the domain ontology and a knowledge model that integrates context. Then, user requirement was described by the context of product design, and knowledge nodes that met users' requirement could be extracted from the knowledge retrieval technology on the basis of context similarity. Finally, the connection between knowledge nodes was constructed with a composite connection model, and the knowledge map was visualized using a hierarchical approach. To verify the effectiveness of the proposed method, the constructed knowledge map was applied in an airplane wing design to assist users in browsing the knowledge base. Results indicate that the proposed method can change the displayed contents according to user requirement and identify the displayed knowledge nodes at a highly acceptable level, the constructed knowledge map can guide users efficiently, and the knowledge overload can be reduced significantly.
C1 [Lv, Yanjie; Zhao, Gang; Yu, Yong] Beihang Univ, Sch Mech Engn & Automat, Beijing, Peoples R China.
C3 Beihang University
RP Lv, YJ; Zhao, G (corresponding author), Beihang Univ, Sch Mech Engn & Automat, Beijing, Peoples R China.
EM lvyanjie_std@163.com; zhaog@buaa.edu.cn
RI Zhao, Gang/JMC-6248-2023
FU Chinese 863 - program - "the High Technology Research and Development
   Program" [2009AA043302]
FX The research was supported by Chinese 863 - program - "the High
   Technology Research and Development Program". The project number is
   2009AA043302.
CR Afacan Y, 2011, KNOWL-BASED SYST, V24, P530, DOI 10.1016/j.knosys.2011.01.002
   Bergamaschi S, 2010, IEEE INTERNET COMPUT, V14, P10, DOI 10.1109/MIC.2010.140
   Chen TY, 2008, COMPUT IND, V59, P502, DOI 10.1016/j.compind.2007.12.004
   Chiu DY, 2014, KNOWL-BASED SYST, V67, P412, DOI 10.1016/j.knosys.2014.03.008
   Hammiche S., 2007, Journal of Digital Information Management, V5, P75
   Hao J, 2014, DECIS SUPPORT SYST, V61, P106, DOI 10.1016/j.dss.2014.02.001
   Hu MC, 2014, SCI TECHNOL SOC, V19, P27, DOI 10.1177/0971721813514263
   Jiang DD, 2011, COMPUT NETW, V55, P3533, DOI 10.1016/j.comnet.2011.06.027
   Lee C, 2014, MULTIMED TOOLS APPL, V71, P195, DOI 10.1007/s11042-013-1740-1
   Lee S, 2009, TECHNOVATION, V29, P481, DOI 10.1016/j.technovation.2008.10.006
   Li H, 2009, LIB INF SCI, V53, P85
   Li T., 2015, CONCURR COMP-PRACT E, P1
   Lin FR, 2006, INFORM PROCESS MANAG, V42, P551, DOI 10.1016/j.ipm.2005.03.026
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv Y, 2013, J ENG SCI TECHNOL RE, V6, P82
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Ong TH, 2005, DECIS SUPPORT SYST, V39, P583, DOI 10.1016/j.dss.2004.03.008
   Shi Mei-hong, 2011, Computer Integrated Manufacturing Systems, V17, P882
   Nguyen SH, 2013, J AM SOC INF SCI TEC, V64, P1235, DOI 10.1002/asi.22830
   Su Hai, 2005, Journal of Shanghai Jiaotong University, V39, P2034
   Sveen FO, 2007, INFORM SYST FRONT, V9, P481, DOI 10.1007/s10796-007-9052-5
   Tao TY, 2012, J INTEGR AGR, V11, P800, DOI 10.1016/S2095-3119(12)60070-7
   Vail EF, 1999, INFORM SYST MANAGE, V16, P16, DOI 10.1201/1078/43189.16.4.19990901/31199.3
   Wan S, 2010, J WEB SEMANT, V8, P196, DOI 10.1016/j.websem.2010.03.002
   Wang JJY, 2015, EXPERT SYST APPL, V42, P1278, DOI 10.1016/j.eswa.2014.09.008
   Wang K., 2015, CELLULAR MOL NEUROBI, P1
   Wang Y, 2015, P 27 INT C SCI STAT, V4
   Watthananon J, 2012, PROCEDIA ENGINEER, V32, P1169, DOI 10.1016/j.proeng.2012.02.073
   Wexler MN, 1997, J KNOWL MANAG, V5, P249
   Woo JH, 2004, AUTOMAT CONSTR, V13, P203, DOI 10.1016/j.autcon.2003.09.003
   Xu Y, 2011, KNOWL-BASED SYST, V24, P166, DOI 10.1016/j.knosys.2010.08.001
   Yang C, 2013, INT J TECHNOL DES ED, V23, P1063, DOI 10.1007/s10798-013-9239-7
   Yoon B, 2010, SCIENTOMETRICS, V85, P803, DOI 10.1007/s11192-010-0294-5
   Zhang S, 2011, MODULAR MACH TOOL AU, V1, P18
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
   Zhang XT, 2013, NEUROCOMPUTING, V116, P382, DOI 10.1016/j.neucom.2011.12.057
NR 37
TC 7
Z9 7
U1 1
U2 26
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17465
EP 17486
DI 10.1007/s11042-015-3113-4
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600033
DA 2024-07-18
ER

PT J
AU Oh, JM
   Moon, N
   Hong, S
AF Oh, Jung-Min
   Moon, Nammee
   Hong, Sangjin
TI Trajectory based database management for intelligent surveillance system
   with heterogeneous sensors
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intelligent surveillance; Consistency management; Iterative decision
   process; Heterogeneous sensor network; Database
ID COVERAGE
AB In this paper, we present a database management scheme for an intelligent surveillance system utilizing multiple visual sensors and RFID readers. The objects are tracked and identified by multiple visual sensors and RFID readers. We define three different types of data structure to consistently store data for effective data storage. They contain global object number and identification as the common information of the same object. The global object number is uniquely assigned for each track object. The previously stored data without the common information is back-annotated when it is available in the system. Moreover, when the global object number changes because of imperfect detection and tracking, the system maintains consistency information between global object numbers for the same object by comparing their local target information or positions. The fragmented information for an object is also stitched through map information. The simulation results demonstrate that the database information for objects is successfully recovered with consistency.
C1 [Oh, Jung-Min; Hong, Sangjin] SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
   [Moon, Nammee] Hoseo Univ, Dept Comp Engn, Asan 336795, South Korea.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook; Hoseo University
RP Moon, N (corresponding author), Hoseo Univ, Dept Comp Engn, Asan 336795, South Korea.
EM mnm@hoseo.edu
FU 'Cross-Ministry Giga KOREA Project' of the Ministry of Science, ICT and
   Future Planning, Republic of Korea (ROK) [GK15P0100]
FX This research was supported by the 'Cross-Ministry Giga KOREA Project'
   of the Ministry of Science, ICT and Future Planning, Republic of Korea
   (ROK). [GK15P0100, Development of Tele-Experience Service SW Platform
   based on Giga Media]
CR [Anonymous], J CONVERGENCE
   Cho SH, 2014, J COMPUT SCI TECH-CH, V29, P4, DOI 10.1007/s11390-013-1408-3
   Cho SH, 2011, KSII T INTERNET INF, V5, P1166, DOI 10.3837/tiis.2011.06.005
   Cho SH, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/591582
   Cho SH, 2010, KSII T INTERNET INF, V4, P1169, DOI 10.3837/tiis.2010.12.011
   Cho SH, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P553, DOI 10.1109/AVSS.2009.86
   Cho SH, 2010, KSII T INTERNET INF, V4, P358, DOI 10.3837/tiis.2010.06.010
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Kim K., 2012, JPN J APPL PHYS, V51, P1
   Ma JB, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P382, DOI 10.1109/AVSS.2009.25
   Oh J-M, 2011, MULTIMED TOOLS APPL, V52, P1
   Okadome T, 2006, IEEE INT C MOB DAT M, V62
   Porikli F, 2013, IEEE SIGNAL PROC MAG, V30, P190, DOI 10.1109/MSP.2013.2241312
   Räty TD, 2010, IEEE T SYST MAN CY C, V40, P493, DOI 10.1109/TSMCC.2010.2042446
   Salim K, 2014, J INF PROCESS SYST, V10, P145, DOI 10.3745/JIPS.2014.10.1.145
   Shahabi C, 2014, J INF PROCESS SYST, V10, P1, DOI 10.3745/JIPS.2014.10.1.001
   Shu CF, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P318
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wasserkrug S, 2008, IEEE T KNOWL DATA EN, V20, P1111, DOI 10.1109/TKDE.2008.74
   Yang X., 2013, J CONVERG, V4, P11
   Yap FGH, 2014, SENSORS-BASEL, V14, P3506, DOI 10.3390/s140203506
NR 22
TC 3
Z9 3
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 23
BP 15429
EP 15444
DI 10.1007/s11042-015-2725-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EC4RS
UT WOS:000388121700019
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhu, DJ
AF Zhu, Dingju
TI Big data-based multimedia transcoding method and its application in
   multimedia data mining-based smart transportation and telemedicine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Big data; Multimedia transcoding; Multimedia data mining; Smart
   transportation; Telemedicine
AB The method and system proposed in this paper obtain different data and same data between current multimedia data and pre-stored data by comparing current multimedia data and pre-stored data and encode the attribute information of same data from encoding big data. It is not necessary to encode all multimedia data, but to encode different data and attribute information only. Different data account for a small proportion of the entire multimedia data, while same data represent most of the entire multimedia data. Besides, the encoding of same data is concerned with the attribute information of same data, so the quantity of encoding data is very small and hence the compression ratio is very higher.
C1 [Zhu, Dingju] South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Guangdong, Peoples R China.
C3 South China Normal University
RP Zhu, DJ (corresponding author), South China Normal Univ, Sch Comp Sci, Guangzhou 510631, Guangdong, Peoples R China.
EM zhudj@scnu.edu.cn
FU Major Project of Guangdong Province [2014B090901064]; Project of
   Guangdong Province [2015A010103013]; Major Project of National Social
   Science Fund [14ZDB101]; National Natural Science Foundation of China
   [61105133]
FX This research was supported by Major Project of Guangdong Province under
   Grant No. 2014B090901064, Project of Guangdong Province under Grant No.
   2015A010103013, Major Project of National Social Science Fund under
   Grant No. 14ZDB101, and National Natural Science Foundation of China
   under Grant No. 61105133.
CR Ahmad I, 2005, IEEE T MULTIMEDIA, V7, P793, DOI 10.1109/TMM.2005.854472
   BABU DV, 2014, ASIAN J SCI RES, V7, P85, DOI DOI 10.3923/ajsr.2014.85.93
   Desai S., 2011, 2011 3rd International Conference on Electronics Computer Technology (ICECT 2011), P389, DOI 10.1109/ICECTECH.2011.5941629
   Diaz-Honrubia Antonio Jesus, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P593, DOI 10.1007/978-3-319-04114-8_50
   Kim S, 2014, IEEE T IMAGE PROCESS, V23, P445, DOI 10.1109/TIP.2013.2293428
   Lin YC, 2015, SENSORS-BASEL, V15, P20925, DOI 10.3390/s150820925
   Lv ZH, 2015, PERS UBIQUIT COMPUT, V19, P551, DOI 10.1007/s00779-015-0844-1
   Lv Z, 2014, ACM T MULTIM COMPUT, V11, DOI 10.1145/2645860
   Lv ZH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0057990
   Mcphillen J, 2013, U. S. Patent Application, Patent No. [13/787,559, 13787559]
   Morris BT, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.041113
   Rasche KR, 2014, U. S. Patent, Patent No. [8,666,186, 8666186]
   Su TY, 2016, COMPUT GRAPH-UK, V54, P65, DOI 10.1016/j.cag.2015.07.019
   Tengfei Yin, 2011, Journal of Networks, V6, P990, DOI 10.4304/jnw.6.7.990-998
   Vetro A, 2001, IEEE T CIRC SYST VID, V11, P387, DOI 10.1109/76.911163
   Wang K, 2014, IEEE INT CONF BIG DA, P119, DOI 10.1109/BigData.2014.7004220
   Wang YX, 2015, PROCEEDINGS OF 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P4
   Yang JC, 2017, MULTIMED TOOLS APPL, V76, P17735, DOI 10.1007/s11042-015-2967-9
   Yi Wang, 2014, 2014 IEEE 28th International Parallel & Distributed Processing Symposium Workshops (IPDPSW). Proceedings, P508, DOI 10.1109/IPDPSW.2014.64
   Zhang Su., 2014, P 9 ACM S INFORM COM, P317, DOI DOI 10.1145/2590296.2590300
NR 20
TC 4
Z9 4
U1 0
U2 23
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2016
VL 75
IS 24
BP 17647
EP 17668
DI 10.1007/s11042-016-3466-3
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EE4VV
UT WOS:000389604600042
DA 2024-07-18
ER

PT J
AU Fu, WN
   Zhou, JT
   Liu, S
   Ma, M
   Ma, YD
AF Fu, Weina
   Zhou, Jiantao
   Liu, Shuai
   Ma, Ming
   Ma, Yingdong
TI Differential trajectory tracking with automatic learning of background
   reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Trajectory tracking; Background reconstruction; Direction; Automatic
   learning; Real-time
AB Nowadays, trajectory tracking technology is widely used in many outdoor applications, such as intelligent traffic and video surveillance. However, most of trajectory-tracking technologies rely on a static background, which is hard to obtain in many situations. Obviously, these methods are out of action in the case of dynamic background. In this paper, a novel trajectory tracking method is presented, which is implemented with a new background reconstruction algorithm. Firstly, the background is assumed to be a blank scene. Then, the background is reconstructed by means of video detection that places moving objects in the scene. Finally, real-time trajectories of moving objects are computed based on the reconstructed background. Experimental results show its robustness and practicability even in a cluttered background.
C1 [Fu, Weina; Zhou, Jiantao; Liu, Shuai; Ma, Ming; Ma, Yingdong] Inner Mongolia Univ, Coll Comp Sci, Room A211,Comp Bldg,235 Western Univ St, Hohhot 010012, Peoples R China.
C3 Inner Mongolia University
RP Zhou, JT (corresponding author), Inner Mongolia Univ, Coll Comp Sci, Room A211,Comp Bldg,235 Western Univ St, Hohhot 010012, Peoples R China.
EM wn_fu@sohu.com; cszjtao@imu.edu.cn; cs_liushuai@imu.edu.cn;
   csmaming@imu.edu.cn; csmyd@imu.edu.cn
RI 马, 马颖东/ISA-2042-2023; Liu, Shuai/AAX-1239-2021; Fu, Weina/AAF-5699-2020;
   Liu, Shuai/AAB-1960-2019; Liu, Shuai/P-3939-2017
OI Liu, Shuai/0000-0001-9909-0664; Liu, Shuai/0000-0001-9909-0664
FU National Natural Science Foundation of China [61262082, 61261019,
   61461039]; Chinese Ministry of Education [212025]; Scientific Projects
   of Higher School of Inner Mongolia [NJZY13004]; Natural Science
   Foundation of Inner Mongolia [2014BS0606]; Inner Mongolia Science
   Foundation [2012JQ03]; Enhancing Comprehensive Strength Foundation of
   Inner Mongolia University [14020202]; Program of Higher-level talents of
   Inner Mongolia University [125130, 135103]
FX This work is supported by National Natural Science Foundation of China
   [No: 61262082,61261019, 61461039], Key Project of Chinese Ministry of
   Education [No. 212025], Scientific Projects of Higher School of Inner
   Mongolia [No. NJZY13004], Natural Science Foundation of Inner Mongolia
   [No. 2014BS0606], Inner Mongolia Science Foundation for Distinguished
   Young Scholars [2012JQ03], Enhancing Comprehensive Strength Foundation
   of Inner Mongolia University [No. 14020202], Program of Higher-level
   talents of Inner Mongolia University (125130, 135103).
CR [Anonymous], J SOFTWARE
   [Anonymous], J MULTIMEDIA
   [Anonymous], IM AN SIGN PROC IASP
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P757, DOI 10.1109/TCSVT.2004.828348
   Doulamis ND, 2010, MULTIMED TOOLS APPL, V50, P173, DOI 10.1007/s11042-009-0370-0
   Ganapathi V, 2010, PROC CVPR IEEE, P755, DOI 10.1109/CVPR.2010.5540141
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Guerrero J, 2007, IEEE T MED IMAGING, V26, P1079, DOI 10.1109/TMI.2007.899180
   Halliday I, 1996, METORIT PLANET SCI, V31, P185, DOI 10.1111/j.1945-5100.1996.tb02014.x
   Hou Zhi-Qiang, 2006, Acta Automatica Sinica, V32, P603
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Liu S, 2013, MATH PROBL ENG, V2013, DOI 10.1155/2013/503924
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Schoenemann T, 2010, IEEE T PATTERN ANAL, V32, P1153, DOI 10.1109/TPAMI.2009.79
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Wei XL, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366207
   Yeo HS, 2013, MULTIMEDIA TOOLS APP, P1
   Zhang SP, 2013, PATTERN RECOGN, V46, P1772, DOI 10.1016/j.patcog.2012.10.006
   Zhang XQ, 2014, IEEE T IND ELECTRON, V61, P1072, DOI 10.1109/TIE.2013.2258306
NR 23
TC 8
Z9 8
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13001
EP 13013
DI 10.1007/s11042-014-2391-6
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800001
DA 2024-07-18
ER

PT J
AU Yang, Y
   Zhang, WM
   Hu, XC
   Yu, NH
AF Yang, Yang
   Zhang, Weiming
   Hu, Xiaocheng
   Yu, Nenghai
TI Improving visual quality of reversible data hiding by twice sorting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Reversible data hiding; Visual quality; Just noticeable difference
ID PREDICTION-ERROR EXPANSION; DIFFERENCE EXPANSION; WATERMARKING;
   ALGORITHM
AB In most literatures on reversible data hiding (RDH), the visual quality of marked images is only assessed by PSNR, and the smoothness-priority-based sorting technique is efficient for improving PSNR. However, modifications in smooth areas are conflict with other criterion of visual quality such as Just Noticeable Difference (JND). To reconcile this contradiction, we propose a twice sorting scheme, in which the pixels are first sorted and divided into several levels with a smoothness criterion, and then sorted twice with JND in each level. According to the sorted order, message bits are embedded into the predicted errors of pixels based on rhombus prediction. Experimental results show that this novel method significantly outperforms previous JND-related RDH schemes on not only PSNR but also SSIM and JND distortion.
C1 [Yang, Yang; Zhang, Weiming; Hu, Xiaocheng; Yu, Nenghai] Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Peoples R China.
   [Yang, Yang] Anhui Univ, Sch Elect & Informat Engn, Hefei 230601, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Anhui University
RP Zhang, WM (corresponding author), Univ Sci & Technol China, Sch Informat Sci & Technol, Hefei 230027, Peoples R China.
EM skyyang@mail.ustc.edu.cn; zhangwm@ustc.edu.cn; hxc@mail.ustc.edu.cn;
   ynh@ustc.edu.cn
OI Yang, Yang/0000-0003-1048-7994
FU Natural Science Foundation of China [61170234]; Strategic Priority
   Research Program of the Chinese Academy of Sciences [XDA06030600];
   Science and Technology on Information Assurance Laboratory [KJ-13-02];
   Doctoral Scientific Research Foundation of Anhui University [J01001319];
   Backbone Teacher Training Program of Anhui University
FX This work was supported in part by the Natural Science Foundation of
   China under Grant 61170234, by the Strategic Priority Research Program
   of the Chinese Academy of Sciences under Grant XDA06030600, by the
   Funding of Science and Technology on Information Assurance Laboratory
   under Grant KJ-13-02, by the Doctoral Scientific Research Foundation of
   Anhui University under Grant J01001319, and by the Backbone Teacher
   Training Program of Anhui University.
CR [Anonymous], P 42 ANN ALL C COMM
   Bao F, 2005, IEEE T INF TECHNOL B, V9, P554, DOI 10.1109/TITB.2005.855556
   Dragoi IC, 2014, IEEE T IMAGE PROCESS, V23, P1779, DOI 10.1109/TIP.2014.2307482
   Hu XC, 2013, IEEE T INF FOREN SEC, V8, P779, DOI 10.1109/TIFS.2013.2256131
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Li XL, 2011, IEEE T IMAGE PROCESS, V20, P3524, DOI 10.1109/TIP.2011.2150233
   Ni ZC, 2006, IEEE T CIRC SYST VID, V16, P354, DOI 10.1109/TCSVT.2006.869964
   Ou B, 2013, IEEE T IMAGE PROCESS, V22, P5010, DOI 10.1109/TIP.2013.2281422
   Qin C, 2015, MULTIMED TOOLS APPL, V74, P1983, DOI 10.1007/s11042-013-1733-0
   Qin C, 2013, IEEE T CIRC SYST VID, V23, P1109, DOI 10.1109/TCSVT.2012.2224052
   Qin C, 2012, PATTERN RECOGN LETT, V33, P2166, DOI 10.1016/j.patrec.2012.08.004
   Sachnev V, 2009, IEEE T CIRC SYST VID, V19, P989, DOI 10.1109/TCSVT.2009.2020257
   Thodi DM, 2007, IEEE T IMAGE PROCESS, V16, P721, DOI 10.1109/TIP.2006.891046
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   WATSON AB, 1993, P SOC PHOTO-OPT INS, V1913, P202, DOI 10.1117/12.152694
   Zhang WM, 2013, IEEE T IMAGE PROCESS, V22, P2775, DOI 10.1109/TIP.2013.2257814
   Zhang WM, 2012, IEEE T IMAGE PROCESS, V21, P2991, DOI 10.1109/TIP.2012.2187667
NR 18
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2016
VL 75
IS 21
BP 13663
EP 13678
DI 10.1007/s11042-015-2824-x
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EA6ZD
UT WOS:000386776800035
DA 2024-07-18
ER

PT J
AU Cao, JT
   Yu, SQ
   Liu, HH
   Li, P
AF Cao, Jiangtao
   Yu, Siquan
   Liu, Honghai
   Li, Ping
TI Hand posture recognition based on heterogeneous features fusion of
   multiple kernels learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hand posture recognition; Heterogeneous feature fusion; Multiple kernel
   learning; SVM
AB As a rapid developing research topic in the machine vision field, image-based hand posture recognition has the potential to be an efficient and intuitive tool of human-computer interaction. For improving the accuracy of multi-class hand postures and extending the algorithm generalization,a novel hand posture recognition method is proposed by integrating the multiple image features and multiple kernels learning support vector machine(SVM). Firstly, three types of feature descriptors are extracted to describe the characteristics of a hand posture image. Shape context descriptor represents distribution characteristics of the edge points of the hand posture image. Pyramid histogram of oriented gradient describes characteristics of local and global shape effectively. The Bag of Feature(BOF) algorithm describes the surface texture characteristics of the posture image. Secondly, the Chamfer kernel and histogram intersection kernel are rebuilt to obtain the basis kernels of the features. And the combined kernel is constructed by weighting the basis kernels.So the heterogeneous features fusion realizes. Finally, the classification model and optimal fusion weights are calculated by using multiple kernels learning algorithm. The unknown category posture can be recognized by the trained multiple kernels of SVM. Experiments on Jochen Triesch's hand posture dataset demonstrate that the proposed method obtains higher recognition rate than the traditional single-kernel classifier and other recent methods.
C1 [Cao, Jiangtao; Yu, Siquan; Li, Ping] Liaoning Shihua Univ, Sch Informat & Control Engn, Fushun, Peoples R China.
   [Liu, Honghai] Univ Portsmouth, Sch Comp, Portsmouth, Hants, England.
C3 Liaoning Petrochemical University; University of Portsmouth
RP Cao, JT (corresponding author), Liaoning Shihua Univ, Sch Informat & Control Engn, Fushun, Peoples R China.
EM cigroup@126.com
OI Liu, Honghai/0000-0002-2880-4698
FU National Natural Science Foundation of China [61103123, 61203021]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61103123 and No. 61203021.
CR [Anonymous], HAND POSTURE RECOGNI
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bach Francis R, 2004, P 21 INT C MACH LEAR, P6, DOI 10.1145/1015330.1015424
   Barla A, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P513
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bosch A., 2007, THESIS
   Brehar R, 2013, IEEE INT C INTELL TR, P1077, DOI 10.1109/ITSC.2013.6728375
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chuang Yue-long, 2013, Journal of Zhejiang University. Engineering Science, V47, P1531, DOI 10.3785/j.issn.1008-973X.2013.09.003
   Chuang YL, 2011, IEEE IMAGE PROC, P1777, DOI 10.1109/ICIP.2011.6115805
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dardas NH, 2011, IEEE T INSTRUM MEAS, V60, P3592, DOI 10.1109/TIM.2011.2161140
   Deng Lawrence Y., 2010, IET International Conference on Frontier Computing. Theory, Technologies and Applications, P436, DOI 10.1049/cp.2010.0602
   Deng-Yuan Huang, 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1, DOI 10.1109/IIH-MSP.2009.96
   Fang YK, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P995
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Hu MQ, 2009, IEEE T NEURAL NETWOR, V20, P827, DOI 10.1109/TNN.2009.2014229
   Ju ZJ, 2011, IEEE T FUZZY SYST, V19, P901, DOI 10.1109/TFUZZ.2011.2150756
   Just A, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P351
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Li XY, 2012, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2012/06/001
   Murthy G.R.S., 2009, International Journal of Information Technology and Knowledge Management, V2, P405
   Ren Y, 2011, B SCI TECHNOL, V27, P211
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Triesch J, 2002, IMAGE VISION COMPUT, V20, P937, DOI 10.1016/S0262-8856(02)00100-2
   Triesch J, 2014, HAND POSTURE GESTURE
   Tuia D, 2010, IEEE T GEOSCI REMOTE, V48, P3780, DOI 10.1109/TGRS.2010.2049496
   Vapnik VN, 1995, NATURE STAT LEARNING, P83
   Varma M, 2007, IEEE I CONF COMP VIS, P369
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Yen-Ting Chen, 2007, Proceedings of the 3rd Annual IEEE Conference on Automation Science and Engineering, P527
   Zhang Han-ling, 2013, Journal of Hunan University (Natural Science), V40, P87
NR 34
TC 8
Z9 8
U1 1
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2016
VL 75
IS 19
BP 11909
EP 11928
DI 10.1007/s11042-015-2628-z
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1JW
UT WOS:000382678200018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Niemiec, M
   Machnik, P
AF Niemiec, Marcin
   Machnik, Petr
TI Authentication in virtual private networks based on quantum key
   distribution methods
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Security; Authentication; Quantum key distribution; Virtual private
   networks; IPsec protocol
ID AMPLIFICATION
AB Quantum physics has a major influence on modern computer science and communications. New quantum-based solutions continue to be proposed by researchers. However, only a few techniques are possible to implement in practice. One of them is quantum key distribution, which ensures the confidentiality of digital data. This article introduces a new concept: quantum distribution of pre-shared keys. This approach provides end-users with very secure authentication, impossible to achieve using currently-available techniques. Secure authentication is a key requirement in virtual private networks (VPN)-popular protection in computer networks. The authors simulated quantum-based distribution of a shared secret in a typical VPN connection. Using a dedicated simulator, all individual steps of the quantum key distribution process were presented. Based on the created secret, a secure IPsec tunnel in a StrongSwan environment was established between AGH (Poland) and VSB (Czech Republic). It allows end-users to communicate at very high security levels.
C1 [Niemiec, Marcin] AGH Univ Sci & Technol, Mickiewicza 30 Ave, PL-30059 Krakow, Poland.
   [Machnik, Petr] VSB Tech Univ Ostrava, 17 Listopadu 15, Ostrava 70833, Czech Republic.
C3 AGH University of Krakow; Technical University of Ostrava
RP Niemiec, M (corresponding author), AGH Univ Sci & Technol, Mickiewicza 30 Ave, PL-30059 Krakow, Poland.
EM niemiec@kt.agh.edu.pl; petr.machnik@vsb.cz
RI Niemiec, Marcin/D-1271-2011; Machnik, Petr/G-5341-2017
OI Niemiec, Marcin/0000-0002-3909-9592; Machnik, Petr/0000-0003-0021-9777
FU European Union [218086]
FX This work has been partially funded by the European Union, project
   INDECT (Intelligent information system supporting observation, searching
   and detection for security of citizens in urban environment) - grant
   agreement number: 218086.
CR [Anonymous], 1999, 2631 RFC
   [Anonymous], C P INT S COMM INF T
   [Anonymous], SECRET KEY RECONCILI
   [Anonymous], 2010, RANDOM NUMBER GENERA
   [Anonymous], 1991, RECOMMENDATION X 800
   Assche G. V., 2006, QUANTUM CRYPTOGRAPHY
   Bennett C. H., 1992, Journal of Cryptology, V5, P3, DOI 10.1007/BF00191318
   Bennett C H, 1984, IEEE INT C COMP SYST, V175, P175
   Bennett CH, 1995, IEEE T INFORM THEORY, V41, P1915, DOI 10.1109/18.476316
   BENNETT CH, 1988, SIAM J COMPUT, V17, P210, DOI 10.1137/0217014
   Bouwmeester D., 2000, PHYS QUANTUM INFORM
   Buchmann J., 2004, INTRO CRYPTOGRAPHY
   Deal R, 2006, COMPLETE CISCO VPN C
   Dixon AR, 2010, APPL PHYS LETT, V96, DOI 10.1063/1.3385293
   Ekert A, 2014, NATURE, V507, P443, DOI 10.1038/nature13132
   Niemiec M, 2012, IEEE GLOB TEL C GLOB
   Niemiec M, 2013, IEEE COMMUN MAG, V51, P36, DOI 10.1109/MCOM.2013.6576336
   Niemiec M, 2011, COMM COM INF SC, V149, P286
   Peev M, 2009, EUR C OPT COMM ECOC
   Scarani V, 2009, REV MOD PHYS, V81, P1301, DOI 10.1103/RevModPhys.81.1301
   WOOTTERS WK, 1982, NATURE, V299, P802, DOI 10.1038/299802a0
NR 21
TC 3
Z9 3
U1 0
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 17
BP 10691
EP 10707
DI 10.1007/s11042-014-2299-1
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KB
UT WOS:000382678800029
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Zhu, HJ
   Sheng, JH
   Zhang, F
   Zhou, JL
   Wang, J
AF Zhu, Haijiang
   Sheng, Junhui
   Zhang, Fan
   Zhou, Jinglin
   Wang, Jing
TI Improved maximally stable extremal regions based method for the
   segmentation of ultrasonic liver images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Modified Maximally Stable Extremal Region; Ultrasound liver image;
   Segmentation of liver lesions
ID DUAL-SNAKE MODEL; 3D SEGMENTATION
AB The goal of this paper is to propose a modified maximally stable extremal region (MSER) based method for the segmentation of ultrasound liver images. Firstly, the feature regions including liver lesions are extracted using the modified MSER detector. Unlike the MSER algorithm, the improved MSER detector merely needs dozens of gray levels rather than 256 possible gray levels ranging from 0 to 255. Next, the edges of the liver lesions are detected from the binary images, and a merging strategy is designed to refine the contour of the liver lesion. The last step is the segmentation of the liver lesion according to the refined contour. The segmentation results of ultrasound liver images demonstrate that there is a significant correlation between the liver lesions selected by a medical expert and the liver lesions segmented by the proposed method. A comparison of the proposed method and other segmented methods shows that the proposed method can detect a more accurate contour of liver lesion images.
C1 [Zhu, Haijiang; Sheng, Junhui; Zhang, Fan; Zhou, Jinglin; Wang, Jing] Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
C3 Beijing University of Chemical Technology
RP Zhu, HJ (corresponding author), Beijing Univ Chem Technol, Coll Informat & Technol, Beijing 100029, Peoples R China.
EM zhuhj@mail.buct.edu.cn
FU National Natural Science Foundation of China [61473025]; Fundamental
   Research Funds for the Central Universities [YS1404]; Beijing University
   of Chemical Technology Interdisciplinary Funds for "Visual Media
   Computing"; open-project grant - State Key Laboratory of Synthetical
   Automation for Process Industry at the Northeastern University in China
FX This work was part supported by the National Natural Science Foundation
   of China under grant No. 61473025, the Fundamental Research Funds for
   the Central Universities (YS1404), Beijing University of Chemical
   Technology Interdisciplinary Funds for "Visual Media Computing" and the
   open-project grant funded by the State Key Laboratory of Synthetical
   Automation for Process Industry at the Northeastern University in China.
CR Akbari H, 2012, MED PHYS, V39, P2972, DOI 10.1118/1.4709607
   Chen CM, 2002, ULTRASOUND MED BIOL, V28, P1061, DOI 10.1016/S0301-5629(02)00531-8
   Chen CM, 2001, ULTRASOUND MED BIOL, V27, P1651, DOI 10.1016/S0301-5629(01)00484-7
   Chen CM, 2000, ULTRASONIC IMAGING, V22, P214, DOI 10.1177/016173460002200403
   Chen MF, 2013, IMAGING SCI J, V61, P579, DOI 10.1179/1743131X12Y.0000000028
   Ciecholewski M, 2014, J SIGNAL PROCESS SYS, V74, P151, DOI 10.1007/s11265-013-0755-1
   Crespo J, 1998, PATTERN RECOGN, V31, P419, DOI 10.1016/S0031-3203(97)00062-9
   Cvancarova M, 2005, INT CONGR SER, V1281, P218, DOI 10.1016/j.ics.2005.03.190
   Donoser M, 2006, P C COMP VIS PATT RE
   Donoser M, 2006, INT C PATT RECOG, P63
   Elamvazuthi I, 2013, MATH COMPUT MODEL, V57, P152, DOI 10.1016/j.mcm.2011.07.021
   Fabbrini L, 2014, IEEE GEOSCI REMOTE S, V11, P99, DOI 10.1109/LGRS.2013.2247377
   Feng XT, 2013, PROC SPIE, V8669, DOI 10.1117/12.2006758
   Gui Y, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-83
   Hame Y, 2011, MED IMAGE ANAL
   Jiang HY, 2009, INT C COMP AID DES C, P540, DOI 10.1109/CADCG.2009.5246845
   Kotropoulos C, 2003, PATTERN RECOGN LETT, V24, P715, DOI 10.1016/S0167-8655(02)00177-0
   Lee M, 2012, COMPUT BIOL MED, V42, P523, DOI 10.1016/j.compbiomed.2012.01.005
   Lee WL, 2005, INFORM SCIENCES, V175, P177, DOI 10.1016/j.ins.2005.01.007
   Li CM, 2005, PROC CVPR IEEE, P430
   Li K, 2012, PATTERN RECOGN, V45, P1255, DOI 10.1016/j.patcog.2011.09.018
   Liu CC, 2012, EXPERT SYST APPL, V39, P4505, DOI 10.1016/j.eswa.2011.09.136
   Masoumi H, 2012, BIOMED SIGNAL PROCES, V7, P429, DOI 10.1016/j.bspc.2012.01.002
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Milko S, 2008, INT J COMPUT ASS RAD, V3, P143, DOI 10.1007/s11548-008-0217-6
   Min Zhifang, 2009, Journal of Computer Aided Design & Computer Graphics, V21, P752
   Moraru L, 2014, MED ENG PHYS, V36, P129, DOI 10.1016/j.medengphy.2013.05.013
   Nowatschin S, 2007, P ANN INT IEEE EMBS, P1346, DOI 10.1109/IEMBS.2007.4352547
   Ostu N, 1978, P 4IJCPR, P592
   Pan SY, 2001, PROC SPIE, V4322, P128, DOI 10.1117/12.431019
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pohle R, 2001, PROC SPIE, V4322, P1337, DOI 10.1117/12.431013
   Rani N, 2013, INT J RECENT TECHNOL, V1, P101
   Rodtook A, 2013, J VIS COMMUN IMAGE R, V24, P1414, DOI 10.1016/j.jvcir.2013.09.009
   Smeets D, 2010, MED IMAGE ANAL, V14, P13, DOI 10.1016/j.media.2009.09.002
   Tian Y, 2013, NEUROCOMPUTING, V121, P392, DOI 10.1016/j.neucom.2013.05.031
   Torbati N, 2014, COMPUT BIOL MED, V44, P76, DOI 10.1016/j.compbiomed.2013.10.029
   Wu XG, 2009, COMPUT BIOL MED, V39, P650, DOI 10.1016/j.compbiomed.2009.05.001
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
NR 39
TC 9
Z9 9
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2016
VL 75
IS 18
BP 10979
EP 10997
DI 10.1007/s11042-015-2822-z
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DV1KL
UT WOS:000382679900008
DA 2024-07-18
ER

PT J
AU Pushpalatha, K
   Ananthanarayana, VS
AF Pushpalatha, K.
   Ananthanarayana, V. S.
TI Feature pattern based representation of multimedia documents for
   efficient knowledge discovery
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia document representation; Domain conversion; Unified
   representation; Feature pattern; Multimedia search and retrieval
ID VECTOR-SPACE MODEL; RETRIEVAL
AB The rapid growth of multimedia documents has raised huge demand for sophisticated multimedia knowledge discovery systems. The knowledge extraction of the documents mainly relies on the data representation model and the document representation model. As the multimedia document comprised of multimodal multimedia objects, the data representation depends on modality of the objects. The multimodal objects require distinct processing and feature extraction methods resulting in different features with different dimensionalities. Managing multiple types of features is challenging for knowledge extraction tasks. The unified representation of multimedia document benefits the knowledge extraction process, as they are represented by same type of features. The appropriate document representation will benefit the overall decision making process by reducing the search time and memory requirements. In this paper, we propose a domain converting method known as Multimedia to Signal converter (MSC) to represent the multimodal multimedia document in an unified representation by converting multimodal objects as signal objects. A tree based approach known as Multimedia Feature Pattern (MFP) tree is proposed for the compact representation of multimedia documents in terms of features of multimedia objects. The effectiveness of the proposed framework is evaluated by performing the experiments on four multimodal datasets. Experimental results show that the unified representation of multimedia documents helped in improving the classification accuracy for the documents. The MFP tree based representation of multimedia documents not only reduces the search time and memory requirements, also outperforms the competitive approaches for search and retrieval of multimedia documents.
C1 [Pushpalatha, K.; Ananthanarayana, V. S.] Natl Inst Technol Karnataka, Mangalore 575025, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Pushpalatha, K (corresponding author), Natl Inst Technol Karnataka, Mangalore 575025, India.
EM pushpak35@gmail.com
RI Alsaif, Amal/IUO-9428-2023; K, Pushpalatha/AAF-3437-2019
OI Alsaif, Amal/0000-0002-8204-0326; KOTIAN,
   PUSHPALATHA/0000-0001-7570-4967
CR Adams WH, 2003, EURASIP J APPL SIG P, V2003, P170, DOI 10.1155/S1110865703211173
   Ananthanarayana VS, 2003, PATTERN RECOGN LETT, V24, P851, DOI 10.1016/S0167-8655(02)00197-6
   Andrew G., 2013, ICML, P1247
   [Anonymous], MULTIMEDIA DATA MINI
   Caicedo JC, 2012, NEUROCOMPUTING, V76, P50, DOI 10.1016/j.neucom.2011.04.037
   Cazan Alexandru, 2007, 2007 14th International Workshop in Systems, Signals and Image Processing and 6th EURASIP Conference focused on Speech and Image Processing, Multimedia Communications and Services - EC-SIPMCS 2007, P471, DOI 10.1109/IWSSIP.2007.4381143
   Chen YL, 2011, INFORM PROCESS MANAG, V47, P309, DOI 10.1016/j.ipm.2010.06.001
   Chim H, 2008, IEEE T KNOWL DATA EN, V20, P1217, DOI 10.1109/TKDE.2008.50
   Pereira JC, 2014, IEEE T PATTERN ANAL, V36, P521, DOI 10.1109/TPAMI.2013.142
   Daras P, 2012, IEEE T MULTIMEDIA, V14, P734, DOI 10.1109/TMM.2011.2181343
   Eissen S.M. Z., 2005, Proceedings of the 5th International Conference on Knowledge Management, P596
   Fisher B., 1996, Hypermedia image processing reference
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Hunt M. J., 1980, ICASSP 80 Proceedings. IEEE International Conference on Acoustics, Speech and Signal Processing, P880
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Levy M, 2009, IEEE T MULTIMEDIA, V11, P383, DOI 10.1109/TMM.2009.2012913
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li HZ, 2007, IEEE T AUDIO SPEECH, V15, P271, DOI 10.1109/TASL.2006.876860
   Li YJ, 2008, DATA KNOWL ENG, V64, P381, DOI 10.1016/j.datak.2007.08.001
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Mao WL, 2007, DATA KNOWL ENG, V61, P76, DOI 10.1016/j.datak.2006.02.008
   Mao X., 2013, P 21 ACM INT C MULT, P897
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   Muneesawang P, 2010, J SIGNAL PROCESS SYS, V59, P177, DOI 10.1007/s11265-008-0290-7
   Nefian AV, 2002, EURASIP J APPL SIG P, V2002, P1274, DOI 10.1155/S1110865702206083
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Porter MF, 2006, PROGRAM-ELECTRON LIB, V40, P211, DOI [10.1108/00330330610681286, 10.1108/eb046814]
   Rafailidis D, 2013, PATTERN RECOGN, V46, P3358, DOI 10.1016/j.patcog.2013.05.023
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Santos I, 2012, EXPERT SYST APPL, V39, P437, DOI 10.1016/j.eswa.2011.07.034
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   Taylor P., 2009, Text-to-Speech Synthesis
   Tsatsaronis G., 2009, EACL_2009,_12th_Conference_of_the European_Chapter_of_the_Association_for_Computational_Linguistics,_Proceedings_of the_Conference,_Athens,_Greece,_March_30_-_April_3,_2009, P70
   Wang S, 2013, PROC CVPR IEEE, P3111, DOI 10.1109/CVPR.2013.400
   Wang XY, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1865106.1865109
   Worawitphinyo P, 2011, LECT NOTES ARTIF INT, V7121, P55
   Wu P., 2013, P 21 ACM INT C MULT, P153, DOI DOI 10.1145/2502081.2502112
   Yan Y., 2014, Asian Conference on Computer Vision, P522
   Yan Y, 2016, IEEE T PATTERN ANAL, V38, P1070, DOI 10.1109/TPAMI.2015.2477843
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P2984, DOI 10.1109/TIP.2015.2438540
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2013, IEEE I CONF COMP VIS, P1177, DOI 10.1109/ICCV.2013.150
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yang YS, 2009, PROCEEDINGS OF 2009 CONFERENCE ON SYSTEMS SCIENCE, MANAGEMENT SCIENCE & SYSTEM DYNAMICS, VOL 8, P175, DOI 10.1145/1631272.1631298
   Yoshitaka A, 1999, IEEE T KNOWL DATA EN, V11, P81, DOI 10.1109/69.755617
   Zamir O., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P46, DOI 10.1145/290941.290956
   Zhai XH, 2014, IEEE T CIRC SYST VID, V24, P965, DOI 10.1109/TCSVT.2013.2276704
   Zhao R, 2002, IEEE T MULTIMEDIA, V4, P189, DOI 10.1109/TMM.2002.1017733
NR 52
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9461
EP 9487
DI 10.1007/s11042-016-3434-y
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500034
DA 2024-07-18
ER

PT J
AU Wang, F
   Hu, L
   Hu, JJ
   Zhao, K
AF Wang, Feng
   Hu, Liang
   Hu, Jiejun
   Zhao, Kuo
TI Computer forensic analysis model for the reconstruction of chain of
   evidence of volatile memory data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer forensics; Chain of evidence; Time relevance; Volatile; Memory
   data
ID ACQUISITION
AB Digital forensic data from volatile system memory possesses the following distinctive features: volatility, transience, phased stability, complexity, relevance of collected data, and phased behavior predictability. We present a computer forensic analysis model (CERM) for the reconstruction of a chain of evidence of volatile memory data. CERM frees analysts from being confined to the traditional analysis approach of digital forensic data that requires single evidence-oriented analysis. In CERM, they can focus on higher abstract levels involving the relationships of independent pieces of evidence and analyze patterns to construct a chain of evidence from the perspective of Evidence Law. In addition to CERM, we have designed a correlation analysis algorithm based on time series. Experimental tests have been conducted to verify the established model and designed algorithm. The experimental result shows that CERM is feasible and efficient, thus providing a new analysis perspective for digital forensic data from volatile system memory.
C1 [Wang, Feng; Hu, Liang; Hu, Jiejun; Zhao, Kuo] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University
RP Zhao, K (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM wangfeng12@mails.jlu.edu.cn; hul@jlu.edu.cn; hujc12@mails.jlu.edu.cn;
   zhaokuo@jlu.edu.cn
RI Hu, Jiejun/AAP-8555-2020
FU European Framework Program (FP7) [FP7-PEOPLE-2011-IRSES]; National
   Natural Science Foundation of China [61073009, 61103197]; National High
   Tech R&D Program 863 of China [2011AA010101]; National Sci-Tech Support
   Plan of China [2014BAH02F03]; National Sci-Tech Major Projects of China
   [SinoProbe-09-01-03, 2012ZX01039-004-04-3]; Key Sci-Tech Program of
   Jilin Province of China [2011ZDGG007, 20150204035GX]; Fundamental
   Research Funds for Central Universities of China [JCKY-QKJC46,
   2412015KJ005]
FX This work is funded by European Framework Program (FP7) under Grant No.
   FP7-PEOPLE-2011-IRSES, National Natural Science Foundation of China
   under Grant No. 61073009 & 61103197, National High Tech R&D Program 863
   of China under Grant No. 2011AA010101, National Sci-Tech Support Plan of
   China under Grant No. 2014BAH02F03, National Sci-Tech Major Projects of
   China under Grant No. SinoProbe-09-01-03 & 2012ZX01039-004-04-3, Key
   Sci-Tech Program of Jilin Province of China under Grant No. 2011ZDGG007
   & 20150204035GX, and Fundamental Research Funds for Central Universities
   of China under Grant No. JCKY-QKJC46 & 2412015KJ005.
CR Chambers J., 2014, MULTIMED TOOLS APPL, P1, DOI DOI 10.1007/S11042-013-1809-X
   Chu HC, 2012, SECUR COMMUN NETW, V5, P1193, DOI 10.1002/sec.511
   Garfinkel SL, 2010, DIGIT INVEST, V7, pS64, DOI 10.1016/j.diin.2010.05.009
   Hasan R, 2012, P 2012 UKACC INT C C, P400, DOI [10.1109/CON-TROL.2012.6334663, DOI 10.1109/CON-TROL.2012.6334663]
   Lee S, 2014, MOBILE NETW APPL, V19, P382, DOI 10.1007/s11036-014-0504-0
   Okolica JS, 2011, COMPUT SECUR, V30, P770, DOI 10.1016/j.cose.2011.08.001
   Olajide F, 2012, 7 INT C INT TECHN SE, P715
   Olajide F, 2011, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON INTERNET TECHNOLOGIES AND APPLICATIONS (ITA 11), P229
   Qian ZX, 2014, J SYST SOFTWARE, V91, P100, DOI 10.1016/j.jss.2013.12.043
   Satpathy S, 2015, ADV INTELL SYST, V309, P367, DOI 10.1007/978-81-322-2009-1_42
   Seo J., 2013, T 22 INT C STRUCTURA, P1
   Stuettgen J, 2013, DIGIT INVEST, V10, pS105, DOI 10.1016/j.diin.2013.06.012
   Thomas S, 2013, 2013 IEEE CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGIES (ICT 2013), P937
   Vomel S, 2013, P 13 ANN DFRWS C 13, V10, pS30, DOI [10.1016/j.diin.2013.06.004, DOI 10.1016/J.DIIN.2013.06.004]
   Zhang YP, 2012, SECUR COMMUN NETW, V5, P422, DOI 10.1002/sec.331
NR 15
TC 2
Z9 2
U1 0
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 16
BP 10097
EP 10107
DI 10.1007/s11042-015-2798-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LO
UT WOS:000382112500031
DA 2024-07-18
ER

PT J
AU Wang, H
   Cai, YF
   Chen, XB
   Chen, L
AF Wang, Hai
   Cai, Yingfeng
   Chen, Xiaobo
   Chen, Long
TI Occluded vehicle detection with local connected deep model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Vehicle detection; Occluded vehicle; Deep model; Occlusion type
   matching.; Monocular vision
ID FEATURES
AB Traditional vehicle detection algorithms do not include targeted processing to handle the vehicle occlusion phenomenon. To address this issue, this paper proposes a locally-connected, deep-model-based, occluded vehicle detection algorithm. Firstly, a suspected occluded vehicle is generated using a cascaded Adaboost Classifier. Any sub-images that are rejected during the last two stages of the cascaded Adaboost Classifier are considered as a suspected occluded vehicle. Then, eight types of vehicle occlusion visual models are manually established. The suspected occluded vehicle will be assigned to a certain type of model by color histogram matching. Finally, the sub image of the suspected occluded vehicle will be loaded into a locally connected deep model of the corresponding type to make the final determination. An experiment using the KITTI dataset has demonstrated that compared with existing vehicle detection algorithms such as the cascaded Adaboost, the Deformable Part Model (DPM), Deep Convolutional Neural Networks (DCNN) and the Deep Belief Network (DBN), this algorithm has a much higher occluded vehicle detection rate. Additionally, this method requires minimal extra processing time, at around 5 % higher than the cascaded Adaboost.
C1 [Wang, Hai] Jiangsu Univ, Sch Automot & Traff Engn, Zhenjiang 212013, Jiangsu, Peoples R China.
   [Cai, Yingfeng; Chen, Xiaobo; Chen, Long] Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Jiangsu, Peoples R China.
C3 Jiangsu University; Jiangsu University
RP Cai, YF (corresponding author), Jiangsu Univ, Automot Engn Res Inst, Zhenjiang 212013, Jiangsu, Peoples R China.
EM caicaixiao0304@126.com
RI long, chen/JVM-8568-2024; Yan, Jing/JFA-6705-2023
OI Chen, Xiaobo/0000-0001-9940-1637
FU National Natural Science Foundation of China [61573171, 61403172,
   61203244, 51305167]; China Postdoctoral Science Foundation [2014
   M561592, 2015 T80511]; Information Technology Research Program of
   Transport Ministry of China [2013364836900]; Natural Science Foundation
   of Jiangsu Province [BK20140555]
FX This work has been supported by the National Natural Science Foundation
   of China under the grant (61573171, 61403172, 61203244, 51305167), China
   Postdoctoral Science Foundation (2014 M561592, 2015 T80511), Information
   Technology Research Program of Transport Ministry of China under the
   grant (2013364836900), Natural Science Foundation of Jiangsu Province
   (BK20140555).
CR [Anonymous], P 2 ACM INT C MULT R
   [Anonymous], 2013, T PAMI
   Chen XY, 2014, IEEE GEOSCI REMOTE S, V11, P1797, DOI 10.1109/LGRS.2014.2309695
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Eum S, 2013, IEEE T INTELL TRANSP, V14, P1003, DOI 10.1109/TITS.2012.2233736
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hsieh JW, 2014, IEEE T INTELL TRANSP, V15, P6, DOI 10.1109/TITS.2013.2294646
   Kaâniche MB, 2012, IEEE T PATTERN ANAL, V34, P2247, DOI 10.1109/TPAMI.2012.19
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Moranduzzo T, 2012, INT GEOSCI REMOTE SE, P6868, DOI 10.1109/IGARSS.2012.6352585
   Pauplin O, 2012, PATTERN RECOGN LETT, V33, P685, DOI 10.1016/j.patrec.2011.12.010
   Pedersoli M, 2014, IEEE T INTELL TRANSP, V15, P355, DOI 10.1109/TITS.2013.2281207
   Ponsa D, 2007, LECT NOTES COMPUT SC, V4678, P980
   Song XM, 2015, SIGIR 2015: PROCEEDINGS OF THE 38TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P213, DOI 10.1145/2766462.2767726
   Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Withopf Daniel, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P642, DOI 10.1109/ITSC.2007.4357644
   Yoo H, 2013, IEEE T INTELL TRANSP, V14, P1083, DOI 10.1109/TITS.2013.2252427
NR 22
TC 10
Z9 10
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2016
VL 75
IS 15
BP 9277
EP 9293
DI 10.1007/s11042-015-3141-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LY
UT WOS:000382113500025
DA 2024-07-18
ER

PT J
AU Sandeep, R
   Sharma, S
   Thakur, M
   Bora, PK
AF Sandeep, R.
   Sharma, Saksham
   Thakur, Mayank
   Bora, P. K.
TI Perceptual video hashing based on Tucker decomposition with application
   to indexing and retrieval of near-identical videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Perceptual video hashing; PARAllel FACtor analysis; Achlioptas's random
   matrix; Tucker decomposition; Video indexing and retrieval;
   Near-identical videos
ID PRINCIPAL COMPONENT ANALYSIS; SINGULAR-VALUE DECOMPOSITION;
   JOHNSON-LINDENSTRAUSS; TRANSFORM
AB The perceptual video hash function defines a feature vector that characterizes a video depending on its perceptual contents. This function must be robust to the content preserving manipulations and sensitive to the content changing manipulations. In the literature, the subspace projection techniques such as the reduced rank PARAllel FACtor analysis (PARAFAC), have been successfully applied to extract perceptual hash for the videos. We propose a robust perceptual video hash function based on Tucker decomposition, a multi-linear subspace projection method. We also propose a method to find the optimum number of components in the factor matrices of the Tucker decomposition. The Receiver Operating Characteristics (ROC) curves are used to evaluate the performance of the proposed algorithm compared to the other state-of-the-art projection techniques. The proposed algorithm shows superior performance for most of the image processing attacks. An application for indexing and retrieval of near-identical videos is developed using the proposed algorithm and the performance is evaluated using average recall/precision curves. The experimental results show that the proposed algorithm is suitable for indexing and retrieval of near-identical videos.
C1 [Sandeep, R.; Sharma, Saksham; Thakur, Mayank; Bora, P. K.] Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati
RP Sandeep, R (corresponding author), Indian Inst Technol Guwahati, Dept Elect & Elect Engn, Gauhati 781039, India.
EM r.sandeep@iitg.ernet.in; sakshamsharmaiitg@gmail.com;
   t.mayank@iitg.ernet.in; prabin@iitg.ernet.in
RI R, Sandeep/AAT-7289-2020
OI R, Sandeep/0000-0001-8420-1990
CR Abdafllah EE, 2007, P 4 INT C IM AN REC
   Achlioptas D, 2003, J COMPUT SYST SCI, V66, P671, DOI 10.1016/S0022-0000(03)00025-4
   Achlioptas D., 2001, Database-friendly random projections, P274
   Ailon N., 2006, STOC'06. Proceedings of the 38th Annual ACM Symposium on Theory of Computing, P557, DOI 10.1145/1132516.1132597
   Ailon N, 2009, SIAM J COMPUT, V39, P302, DOI 10.1137/060673096
   [Anonymous], 2013, 2013 4 NAT C COMP VI
   Baranyi P, 2004, IEEE T IND ELECTRON, V51, P387, DOI 10.1109/TIE.2003.822037
   Bergqvist G, 2010, IEEE SIGNAL PROC MAG, V27, P151, DOI 10.1109/MSP.2010.936030
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI 10.1002/9780470747278
   Coskun B, 2004, PROCEEDINGS OF THE IEEE 12TH SIGNAL PROCESSING AND COMMUNICATIONS APPLICATIONS CONFERENCE, P292, DOI 10.1109/SIU.2004.1338317
   Coskun B, 2006, IEEE T MULTIMEDIA, V8, P1190, DOI 10.1109/TMM.2006.884614
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   De Roover C, 2005, ROBUST VIDEO HASHING, V153, P4020
   DEMENTHON D, 2003, ACM MM, P508
   Dittmann J, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P209, DOI 10.1109/MMCS.1999.778274
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Hamon K, 2006, AXMEDIS 2006: SECOND INTERNATIONAL CONFERENCE ON AUTOMATED PRODUCTION OF CROSS MEDIA CONTENT FOR MULTI-CHANNEL DISTRIBUTION, PROCEEDINGS, P236
   HENRION R, 1994, CHEMOMETR INTELL LAB, V25, P1, DOI 10.1016/0169-7439(93)E0086-J
   Jiang Y. G., 2014, EUR C COMP VIS ECCV
   Kiers HAL, 2001, PSYCHOL METHODS, V6, P84, DOI 10.1037/1082-989X.6.1.84
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   KROONENBERG PM, 1980, PSYCHOMETRIKA, V45, P69, DOI 10.1007/BF02293599
   Lan Z, HAUPTMANN INFORMEDIA
   Lee S, 2008, IEEE T CIRC SYST VID, V18, P983, DOI 10.1109/TCSVT.2008.920739
   Lee S, 2008, INT CONF ACOUST SPEE, P1237
   Li M., 2011, P IEEE RAD FREQ INT, P1, DOI DOI 10.1109/RFIC.2011.5940608
   Li M, 2012, IEEE T IMAGE PROCESS, V21, P4397, DOI 10.1109/TIP.2012.2206036
   Li Z, 2013, IJCSI INT J COMPUT S, V10, P382
   Lu HP, 2006, INT C PATT RECOG, P776
   Lv XD, 2012, IEEE T INF FOREN SEC, V7, P1081, DOI 10.1109/TIFS.2012.2190594
   Muti D, 2005, SIGNAL PROCESS, V85, P2338, DOI 10.1016/j.sigpro.2004.11.029
   Omberg L, 2007, P NATL ACAD SCI USA, V104, P18371, DOI 10.1073/pnas.0709146104
   Roover C. D., 2005, P 12 INT C IM PROC, V3
   Savas B, 2007, PATTERN RECOGN, V40, P993, DOI 10.1016/j.patcog.2006.08.004
   Schneider M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P227, DOI 10.1109/ICIP.1996.560425
   Singhal A., 2001, IEEE DATA ENG B, V24, P35
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Tucker LR, 1963, IMPLICATIONS FACTOR, P122
   Vasilescu MAO, 2002, LECT NOTES COMPUT SC, V2350, P447
   Venkatesan R, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2000.899541
   Yan Y, 2015, AAAI CONF ARTIF INTE, P3841
   Yan Y, 2015, IEEE T IMAGE PROCESS, V24, P1867, DOI 10.1109/TIP.2015.2413294
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Zhou B, 2010, J INTELL INF SYST, V34, P227, DOI 10.1007/s10844-009-0096-5
NR 44
TC 19
Z9 20
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 13
BP 7779
EP 7797
DI 10.1007/s11042-015-2695-1
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DR5EA
UT WOS:000379924600016
DA 2024-07-18
ER

PT J
AU Yan, XH
   Wang, S
   Niu, XM
AF Yan, Xuehu
   Wang, Shen
   Niu, Xiamu
TI Threshold progressive visual cryptography construction with unexpanded
   shares
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Visual secret sharing; Progressive visual cryptography; Progressive
   visual secret sharing; Threshold; Pixel expansion; Quality-adaptive
ID IMAGE ENCRYPTION; QUALITY
AB Differently from traditional secret sharing, progressive secret sharing can gain clearer recovered secret image with more shares. However, previous progressive visual secret sharing (PVSS) schemes with unexpanded shares are only for case (2, n) other than general threshold (case), which will restrict the application range. In this paper, a general threshold PVSS construction method from case (2, n) with unexpanded shares is proposed. It has the feature of (k, n) threshold with no pixel expansion, which could be loss-tolerant and control access for a wider application. Based on the proposed construction method, a new threshold PVSS scheme is constructed. Compared with relative approaches, the proposed scheme has improved performances.
C1 [Yan, Xuehu] Inst Elect Engn, Hefei 230000, Peoples R China.
   [Yan, Xuehu; Wang, Shen; Niu, Xiamu] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Yan, XH (corresponding author), Inst Elect Engn, Hefei 230000, Peoples R China.; Yan, XH; Wang, S (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM xuehu.yan@ict.hit.edu.cn; 768588166@qq.com; xiamu.niu@ict.hit.edu.cn
RI Yan, Xuehu/AFK-3139-2022; Yan, Xuehu/AAG-1718-2022
OI Yan, Xuehu/0000-0001-6388-1720; Yan, Xuehu/0000-0001-6388-1720
FU National Natural Science Foundation of China [61100187, 61301099,
   61361166006]
FX The authors would like to thank the anonymous reviewers for their
   valuable discussions and comments. This work is supported by the
   National Natural Science Foundation of China (Grant Number: 61100187,
   61301099, 61361166006).
CR Chen SK, 2009, OPT ENG, V48, DOI 10.1117/1.3262345
   Chen TH, 2013, J SYST SOFTWARE, V86, P1267, DOI 10.1016/j.jss.2012.12.022
   Chen TH, 2011, J SYST SOFTWARE, V84, P1197, DOI 10.1016/j.jss.2011.02.023
   Guo T, 2013, J SYST SOFTWARE, V86, P2094, DOI 10.1016/j.jss.2013.03.062
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Hou YC, 2013, INFORM SCIENCES, V233, P290, DOI 10.1016/j.ins.2013.01.006
   Hou YC, 2011, IEEE T CIRC SYST VID, V21, P1760, DOI 10.1109/TCSVT.2011.2106291
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   Shyu SH, 2007, PATTERN RECOGN, V40, P1014, DOI 10.1016/j.patcog.2006.02.025
   Shyu SJ, 2009, PATTERN RECOGN, V42, P1582, DOI 10.1016/j.patcog.2008.08.023
   Wang DS, 2007, PATTERN RECOGN, V40, P2776, DOI 10.1016/j.patcog.2006.11.018
   Wang ZM, 2009, IEEE T INF FOREN SEC, V4, P383, DOI 10.1109/TIFS.2009.2024721
   Weir J, 2010, LECT NOTES COMPUT SC, V6010, P70, DOI 10.1007/978-3-642-14298-7_5
   Wu XT, 2013, SIGNAL PROCESS, V93, P977, DOI 10.1016/j.sigpro.2012.11.014
   Wu XT, 2013, J VIS COMMUN IMAGE R, V24, P48, DOI 10.1016/j.jvcir.2012.11.001
   Yan X, 2014, LNCS, V9, P68, DOI DOI 10.1007/978-3-642-55046-1
   Yan X, 2013, J CHEM-NY, V2013, DOI 10.1155/2013/476236
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 19
TC 17
Z9 17
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2016
VL 75
IS 14
BP 8657
EP 8674
DI 10.1007/s11042-015-2779-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DU3LW
UT WOS:000382113300024
DA 2024-07-18
ER

PT J
AU Nguyen, HQ
   Lee, SW
   Tian, XH
   Dong, MH
   Chng, ES
AF Hy Quy Nguyen
   Lee, Siu Wa
   Tian, Xiaohai
   Dong, Minghui
   Chng, Eng Siong
TI High quality voice conversion using prosodic and high-resolution
   spectral features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Voice conversion; Deep neural network (DNN); Spectral transformation;
   Fundamental frequency (F0); Duration modeling; Pretraining
ID DEEP NEURAL-NETWORKS; SPARSE REPRESENTATION; F0
AB Voice conversion methods have advanced rapidly over the last decade. Studies have shown that speaker characteristics are captured by spectral feature as well as various prosodic features. Most existing conversion methods focus on the spectral feature as it directly represents the timbre characteristics, while some conversion methods have focused only on the prosodic feature represented by the fundamental frequency. In this paper, a comprehensive framework using deep neural networks to convert both timbre and prosodic features is proposed. The timbre feature is represented by a high-resolution spectral feature. The prosodic features include F0, intensity and duration. It is well known that DNN is useful as a tool to model high-dimensional features. In this work, we show that DNN initialized by our proposed autoencoder pretraining yields good quality DNN conversion models. This pretraining is tailor-made for voice conversion and leverages on autoencoder to capture the generic spectral shape of source speech. Additionally, our framework uses segmental DNN models to capture the evolution of the prosodic features over time. To reconstruct the converted speech, the spectral feature produced by the DNN model is combined with the three prosodic features produced by the DNN segmental models. Our experimental results show that the application of both prosodic and high-resolution spectral features leads to quality converted speech as measured by objective evaluation and subjective listening tests.
C1 [Hy Quy Nguyen; Tian, Xiaohai; Chng, Eng Siong] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Hy Quy Nguyen; Tian, Xiaohai; Chng, Eng Siong] Nanyang Technol Univ, Joint NTU UBC Res Ctr Excellence Act Living Elder, Singapore, Singapore.
   [Lee, Siu Wa; Dong, Minghui] ASTAR, Inst Infocomm Res, Human Language Technol Dept, Singapore, Singapore.
C3 Nanyang Technological University; Nanyang Technological University;
   Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R)
RP Nguyen, HQ (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.; Nguyen, HQ (corresponding author), Nanyang Technol Univ, Joint NTU UBC Res Ctr Excellence Act Living Elder, Singapore, Singapore.
EM ng0002hy@e.ntu.edu.sg; swylee@i2r.a-star.edu.sg; xhtian@ntu.edu.sg;
   mhdong@i2r.a-star.edu.sg; aseschng@ntu.edu.sg
RI Eng-Siong, CHNG/ABH-6779-2020; Dong, Minghui/J-1356-2017
OI Eng-Siong, CHNG/0000-0001-6257-7399; Dong, Minghui/0000-0001-6543-2929
FU National Research Foundation, Prime Ministers Office, Singapore under
   its IDM Futures Funding Initiative
FX This research is supported by the National Research Foundation, Prime
   Ministers Office, Singapore under its IDM Futures Funding Initiative and
   administered by the Interactive and Digital Media Programme Office.
CR Adami AG, 2003, INT CONF ACOUST SPEE, P788
   [Anonymous], 1999, P EUROSPEECH
   [Anonymous], 2003, COMPUT SYST
   Barlow M, 1988, P AUSTR INT C SPEECH, P80
   Chen L.-H., 2014, P INTERSPEECH, P2313
   Chen LH, 2013, JOINT SPECTRAL DISTR
   Chen LH, 2014, IEEE-ACM T AUDIO SPE, V22, P1859, DOI 10.1109/TASLP.2014.2353991
   Dahan D, 1996, LANG SPEECH, V39, P341, DOI 10.1177/002383099603900402
   Desai S, 2009, INT CONF ACOUST SPEE, P3893, DOI 10.1109/ICASSP.2009.4960478
   Erro D, 2013, IEEE T AUDIO SPEECH, V21, P556, DOI 10.1109/TASL.2012.2227735
   Erro D, 2010, IEEE T AUDIO SPEECH, V18, P922, DOI 10.1109/TASL.2009.2038663
   Helander E, 2012, IEEE T AUDIO SPEECH, V20, P806, DOI 10.1109/TASL.2011.2165944
   Helander E, 2010, IEEE T AUDIO SPEECH, V18, P912, DOI 10.1109/TASL.2010.2041699
   Helander EE, 2007, INT CONF ACOUST SPEE, P509
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hwang H.-T., 2013, P APSIPA KAOHS TAIW, P1
   Kain A, 1998, INT CONF ACOUST SPEE, P285, DOI 10.1109/ICASSP.1998.674423
   Kawahara H, 2008, INT CONF ACOUST SPEE, P3933, DOI 10.1109/ICASSP.2008.4518514
   Lamere P., 2003, Proc. of the 8th European Conference on Speech Communications and Technology, P1181
   Le Q. V., 2011, P 28 INT C INT C MAC, P265
   Lee S., 2014, INTERSPEECH, P2499
   Lee SW, 2012, INT CONF ACOUST SPEE, P429, DOI 10.1109/ICASSP.2012.6287908
   Ling ZH, 2015, IEEE SIGNAL PROC MAG, V32, P35, DOI 10.1109/MSP.2014.2359987
   Liu LJ, 2015, INT CONF ACOUST SPEE, P4849, DOI 10.1109/ICASSP.2015.7178892
   Meyer GA, 1961, SEMANTICS STRESS PIT
   Nakashika T., 2014, P ISCA INTERSPEECH, P2278
   Nakashika T, 2013, INTERSPEECH, P369
   NARENDRANATH M, 1995, SPEECH COMMUN, V16, P207, DOI 10.1016/0167-6393(94)00058-I
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sanchez G., 2014, P ANN C INT SPEECH C, P2318
   Shriberg E, 2005, SPEECH COMMUN, V46, P455, DOI 10.1016/j.specom.2005.02.018
   Sorin A, 2015, INT CONF ACOUST SPEE, P4914, DOI 10.1109/ICASSP.2015.7178905
   Srikanth R., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P556
   Stylianou Y, 1998, IEEE T SPEECH AUDI P, V6, P131, DOI 10.1109/89.661472
   Sündermann D, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P676, DOI 10.1109/ASRU.2003.1318521
   Takashima R, 2012, IEEE W SP LANG TECH, P313, DOI 10.1109/SLT.2012.6424242
   Tian XH, 2015, INT CONF ACOUST SPEE, P4235, DOI 10.1109/ICASSP.2015.7178769
   Tian XH, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P211, DOI 10.1109/ISCSLP.2014.6936725
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820
   van Donzel ME, 1997, P 7 S MAT REL MICR M, P211
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wu CH, 2006, IEEE T AUDIO SPEECH, V14, P1109, DOI 10.1109/TASL.2006.876112
   Wu Z., 2014, Proc. Interspeech, P2509
   Wu ZZ, 2014, IEEE-ACM T AUDIO SPE, V22, P1506, DOI 10.1109/TASLP.2014.2333242
   Xie FL, 2014, 2014 9TH INTERNATIONAL SYMPOSIUM ON CHINESE SPOKEN LANGUAGE PROCESSING (ISCSLP), P197, DOI 10.1109/ISCSLP.2014.6936599
   Xie Feng-Long., 2014, Proc. Interspeech 2014, P2283
   Ye H, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P9
   Yu D, 2015, SIGNALS COMMUN TECHN, P1, DOI 10.1007/978-1-4471-5779-3
   Yu D, 2011, IEEE SIGNAL PROC MAG, V28, P145, DOI 10.1109/MSP.2010.939038
   Yutani K, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1072
   Zhizheng Wu, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P104, DOI 10.1109/ChinaSIP.2013.6625307
NR 52
TC 19
Z9 20
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 5265
EP 5285
DI 10.1007/s11042-015-3039-x
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700025
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kim, SC
   Sung, KJ
   Park, CS
   Kim, SK
AF Kim, Soo-Cheol
   Sung, Kyoung-Jun
   Park, Chan-Soo
   Kim, Sung Kwon
TI Improvement of collaborative filtering using rating normalization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Recommendation system; Preference prediction; Collaborative filtering;
   Rating normalization
AB With the advent of the Internet, the types and amount of information one can access have increased dramatically. In today's overwhelming information environment, recommendation systems that quickly analyze large amounts of available information and help users find items of interest are increasingly needed. This paper proposes an improvement of an existing preference prediction algorithm to increase the accuracy of recommendation systems. In a recommendation system, prediction of items preferred by users is based on their ratings. However, individual users with the same degree of satisfaction to an item may give different ratings to the item. We intend to make more precise preference prediction by perceiving differences in users' rating dispositions. The proposed method consists of two processes of perceiving users' rating dispositions with clustering and of performing rating normalization according to such rating dispositions. The experimental results show that our method yields higher performance than ordinary collaborative filtering approach.
C1 [Kim, Soo-Cheol; Sung, Kyoung-Jun; Park, Chan-Soo; Kim, Sung Kwon] Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
C3 Chung Ang University
RP Kim, SK (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul 156756, South Korea.
EM sckim@alg.cse.cau.ac.kr; kjsung@alg.cse.cau.ac.kr;
   cspark@alg.cse.cau.ac.kr; skkim@cau.ac.kr
FU Chung-Ang University
FX This research was supported by the Chung-Ang University Research
   Scholarship Grant in 2011.
CR [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], 2008, AIRWeb'08: Proceedings of the 4th international workshop on Adversarial information retrieval on the web
   Celma S, MUSIC RECOMMENDATION
   Clauset A, 2009, SIAM REV, V51, P661, DOI 10.1137/070710111
   Golder SA, 2006, J INF SCI, V32, P198, DOI 10.1177/0165551506062337
   Kim S, 2012, LECT NOTES ELECT ENG, V181, P107
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lekakos G, 2006, INTERACT COMPUT, V18, P410, DOI 10.1016/j.intcom.2005.11.004
   LIPMAN DJ, 1985, SCIENCE, V227, P1435, DOI 10.1126/science.2983426
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Markines B, 2009, P AIRWEB
   Massa P, 2004, LECT NOTES COMPUT SC, V3290, P492, DOI 10.1007/978-3-540-30468-5_31
   Melville P, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P187
   Papagelis M, 2005, LECT NOTES COMPUT SC, V3477, P224
   Resnick P, 1997, COMMUN ACM, V40, P56, DOI 10.1145/245108.245121
   Resnick P., 1994, Transcending Boundaries, CSCW '94. Proceedings of the Conference on Computer Supported Cooperative Work, P175, DOI 10.1145/192844.192905
   Rho S, 2013, MULTIMED TOOLS APPL, V65, P259, DOI 10.1007/s11042-011-0803-4
   Rho S, 2011, MULTIMEDIA SYST, V17, P313, DOI 10.1007/s00530-010-0212-y
   Shepitsen A, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P259
NR 19
TC 12
Z9 13
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4957
EP 4968
DI 10.1007/s11042-013-1814-0
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700007
DA 2024-07-18
ER

PT J
AU Oyun-Erdene, M
   Byambasuren, BE
   Matson, ET
   Kim, D
AF Oyun-Erdene, Mandakh
   Byambasuren, Bat-Erdene
   Matson, Eric T.
   Kim, Donghan
TI Detection and localization of illegal electricity usage in power
   distribution line
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Illegal electricity usage; Localization method of illegal electricity
   usage; Inspection robot; Remote detection of illegal electricity usage
AB Detection and localization of illegal electricity usage are important issue for power distribution companies. In order to detect illegal electricity usage, network current-based methods using smart meters were mostly used in previous researches. The main disadvantages of those methods are that they are unable to detect the exact location of illegal electricity usage. In addition, all users must be disconnected from the power system to detect the exact location. In this research, an inspection robot proposed for detecting and localizing of illegal electricity usage. The inspection robot can define location of illegal electricity usage on the air transmission line without disconnecting the end user's electric connection. In addition, this method can indicate fault location of transmission line. This paper presents a novel mobile sensing-based localization method for illegal electricity usage by using an inspection robot, and it is verified through simulation and experiment results.
C1 [Oyun-Erdene, Mandakh; Byambasuren, Bat-Erdene; Matson, Eric T.; Kim, Donghan] Kyung Hee Univ, Dept Elect & Radio Engn, Yongin, South Korea.
   [Matson, Eric T.] Purdue Univ, Dept Comp & Informat Technol, W Lafayette, IN 47907 USA.
   [Matson, Eric T.] Dongguk Univ, Dept Comp Engn, Seoul, South Korea.
C3 Kyung Hee University; Purdue University System; Purdue University;
   Dongguk University
RP Kim, D (corresponding author), Kyung Hee Univ, Dept Elect & Radio Engn, Yongin, South Korea.
EM mandakh@khu.ac.kr; baterdene@khu.ac.kr; ematson@purdue.edu;
   donghani@khu.ac.kr
RI Bat-Erdene, Byambasuren/C-1347-2018; Kim, Donghan/AAK-7185-2020;
   Bat-Erdene, Byambasuren/IZP-8474-2023
OI Bat-Erdene, Byambasuren/0000-0001-6090-0404; Kim,
   Donghan/0000-0003-0477-3847; Oyun-Erdene, Mandakh/0000-0003-2432-6331
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012R1A1A2043822]; Technology Innovation Program of the Knowledge
   economy - Ministry of Knowledge Economy (MKE, Korea) [10041834,
   10045351]; MKE (Ministry of Knowledge Economy); NIPA (National IT
   Industry Promotion Agency); KOFST (The Korean Federation of Science and
   Technology Societies) [H5701-12-1002]
FX This work was supported by a grant from the Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education, Science and Technology (2012R1A1A2043822)
   and the Technology Innovation Program of the Knowledge economy (No.
   10041834, 10045351) funded by the Ministry of Knowledge Economy (MKE,
   Korea). In addition, it was supported by MKE (Ministry of Knowledge
   Economy), NIPA (National IT Industry Promotion Agency), and KOFST (The
   Korean Federation of Science and Technology Societies), 2012 Science and
   Technical Support specialists Supporters (H5701-12-1002).
CR Bat-Erdene B, 2011, COMM COM INF SC, V185, P214
   Cavdar IH, 2004, IEEE T POWER DELIVER, V19, P1663, DOI 10.1109/TPWRD.2003.822540
   Deaver BJ, 2008, United States Patent, Patent No. [US 2008/0109387 A1, 20080109387]
   Durand M, 1998, United States patent, Patent No. 5767668
   Fu SY, 2008, PROCEEDINGS OF THE SEVENTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, P411, DOI 10.1109/COGINF.2008.4639195
   Katrasnik Jaka, 2008, 2008 IEEE Conference on Robotics, Automation and Mechatronics (RAM), P1195, DOI 10.1109/RAMECH.2008.4681335
   Katrasnik J, 2010, IEEE T POWER DELIVER, V25, P485, DOI 10.1109/TPWRD.2009.2035427
   Magnus D, 2012, THESIS UPPSALA U
   Pasdar A, 2007, SOFA 2007: 2nd IEEE International Workshop on Soft Computing Applications, Proceedings, P163, DOI 10.1109/SOFA.2007.4318322
   Phillips A., 2012, 2012 2nd International Conference on Applied Robotics for the Power Industry (CARPI 2012), P94, DOI 10.1109/CARPI.2012.6473343
   Rui G., 2010, P INT C APPL ROB POW, P1, DOI DOI 10.1109/CARPI.2010.5624455
   Sreenadh Reddy Depuru SomaShekara., 2010, IEEE, North American Power Symposium (NAPS), P1, DOI DOI 10.1109/NAPS.2010.5619966
   Tobin NP, 2001, CIRED C PUBLICATION, V482
   Zoran V, 2000, TUTORIAL ADAPTIVE CO
NR 14
TC 4
Z9 4
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2016
VL 75
IS 9
BP 4997
EP 5012
DI 10.1007/s11042-014-2022-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DM8HE
UT WOS:000376601700010
DA 2024-07-18
ER

PT J
AU Li, YS
   Liu, WM
   Huang, QH
AF Li, Yanshan
   Liu, Weiming
   Huang, Qinghua
TI Traffic anomaly detection based on image descriptor in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Traffic anomaly detection; Image description; Local invariant feature;
   Video analysis
ID CLASSIFICATION
AB The huge and ever growing volume of traffic video poses a compelling demand for efficient automatic detection of traffic anomaly. In this paper, a new traffic anomaly detection algorithm is introduced. It firstly divides a traffic video into several video cubes in temporal domain, and each video cube is divided into video blocks in spatial domain. Each image block of a video block is described using the local invariant features and the visual codebook approach. Based on the descriptor of the image block, we count the category number of the block (CNB) of a video block. Then, a Gaussian distribution model for estimating the probability of normal traffic with respect to the CNB is learned. The learned Gaussian distribution model is then used to detect the traffic anomaly from the test traffic video. Eventually, the results of all video blocks are fused to achieve the final decision. Experimental results show that the proposed algorithm performs better than two existing algorithms on both the intersection traffic videos and main road traffic videos.
C1 [Li, Yanshan; Liu, Weiming] S China Univ Technol, Sch Civil Engn & Transportat, Guangzhou 510640, Guangdong, Peoples R China.
   [Li, Yanshan; Huang, Qinghua] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
   [Li, Yanshan] Shenzhen Univ, Informat Engn Coll, Shenzhen 518060, Peoples R China.
C3 South China University of Technology; South China University of
   Technology; Shenzhen University
RP Huang, QH (corresponding author), S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510640, Guangdong, Peoples R China.
EM qhhuang@scut.edu.cn
RI Huang, Qinghua/L-8708-2019
OI Huang, Qinghua/0000-0003-1080-6940; liu, Weiming/0000-0003-3700-4307
FU National Natural Science Funds of China [61401286, 61372007]; Guangdong
   Provincial Project of Transportation Science and Technology
   [2012-02-084]; Natural Science Funds of Guangdong Province
   [S2012010009885, S2013010012966]; Projects of innovative science and
   technology, Department of Education, Guangdong Province [2013KJCX0012];
   Natural Science Foundation of SZU [201415]
FX This work was supported by National Natural Science Funds of China (Nos.
   61401286 and 61372007), Guangdong Provincial Project of Transportation
   Science and Technology (No. 2012-02-084), Natural Science Funds of
   Guangdong Province (Nos. S2012010009885 and S2013010012966), Projects of
   innovative science and technology, Department of Education, Guangdong
   Province (No. 2013KJCX0012), and Natural Science Foundation of SZU (No.
   201415).
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Aköz Ö, 2014, MACH VISION APPL, V25, P613, DOI 10.1007/s00138-011-0390-4
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], INF SCI
   [Anonymous], 1931, EC CONTROL QUALITY M
   [Anonymous], 2011, J CHINA U POSTS TELE
   Ballan L, 2010, MULTIMED TOOLS APPL, V48, P69, DOI 10.1007/s11042-009-0351-3
   Einicke GA, 2009, IEEE T SIGNAL PROCES, V57, P370, DOI 10.1109/TSP.2008.2007090
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Guo LH, 2014, NEUROCOMPUTING, V143, P14, DOI 10.1016/j.neucom.2014.06.029
   Helbing D, 1997, PHYS REV E, V55, P3735, DOI 10.1103/PhysRevE.55.3735
   Huang QH, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2598779
   HUNT HEM, 1991, J SOUND VIB, V144, P41, DOI 10.1016/0022-460X(91)90731-X
   Jin X, 2001, IEEE T NEURAL NETWOR, V12, P1173, DOI 10.1109/72.950145
   Kamijo S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P108, DOI 10.1109/6979.880968
   Ki YK, 2007, IEEE T INTELL TRANSP, V8, P188, DOI 10.1109/TITS.2006.890070
   Kuncheva LI, 1999, PATTERN RECOGN LETT, V20, P1149, DOI 10.1016/S0167-8655(99)00082-3
   Lee IJ, 2012, ASIA-PAC CONF COMMUN, P522
   Li Y, 2013, INFORM SCI, V281, P559
   Li Y, 2014, MULTIMED TO IN PRESS
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mei T, 2013, ACM T MULTIM COMPUT, V9, DOI 10.1145/2487268.2487269
   Mei T, 2012, ACM T MULTIM COMPUT, V8, DOI 10.1145/2071396.2071402
   Mei T, 2011, ACM T INFORM SYST, V29, DOI 10.1145/1961209.1961213
   Mo X, 2014, IEEE T CIRC SYST VID, V24, P631, DOI 10.1109/TCSVT.2013.2280061
   Qu XB, 2014, TRAFFIC INJ PREV, V15, P89, DOI 10.1080/15389588.2013.782400
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Yang F, 2014, NEUROCOMPUTING
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Zhang TZ, 2013, IEEE T IND INFORM, V9, P149, DOI 10.1109/TII.2012.2218251
   Zhang TZ, 2009, PROC CVPR IEEE, P1940, DOI 10.1109/CVPRW.2009.5206809
   Zhou J, 2012, OPT ENG, V51
   Zhou X., 2008, MM 08 P 2008 ACM INT, P229, DOI DOI 10.1145/1459359.1459391.ISBN
NR 34
TC 28
Z9 29
U1 2
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2016
VL 75
IS 5
BP 2487
EP 2505
DI 10.1007/s11042-015-2637-y
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DG4FN
UT WOS:000372027000006
DA 2024-07-18
ER

PT J
AU Liu, W
   Zhang, H
   Tao, D
   Wang, Y
   Lu, K
AF Liu, W.
   Zhang, H.
   Tao, D.
   Wang, Y.
   Lu, K.
TI Large-scale paralleled sparse principal component analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sparse principal; Component analysis; Power method; GPU; Large-scale;
   Parallel method
ID DISCRIMINANT-ANALYSIS; RELEVANCE-FEEDBACK; SUBSPACE
AB Principal component analysis (PCA) is a statistical technique commonly used in multivariate data analysis. However, PCA can be difficult to interpret and explain since the principal components (PCs) are linear combinations of the original variables. Sparse PCA (SPCA) aims to balance statistical fidelity and interpretability by approximating sparse PCs whose projections capture the maximal variance of original data. In this paper we present an efficient and paralleled method of SPCA using graphics processing units (GPUs), which can process large blocks of data in parallel. Specifically, we construct parallel implementations of the four optimization formulations of the generalized power method of SPCA (GP-SPCA), one of the most efficient and effective SPCA approaches, on a GPU. The parallel GPU implementation of GP-SPCA (using CUBLAS) is up to eleven times faster than the corresponding CPU implementation (using CBLAS), and up to 107 times faster than a MatLab implementation. Extensive comparative experiments in several real-world datasets confirm that SPCA offers a practical advantage.
C1 [Liu, W.; Zhang, H.; Wang, Y.] China Univ Petr East China, Qingdao, Shandong, Peoples R China.
   [Tao, D.] S China Univ Technol, Guangzhou 510641, Guangdong, Peoples R China.
   [Lu, K.] Univ Chinese Acad Sci, Beijing, Peoples R China.
C3 China University of Petroleum; South China University of Technology;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Tao, D (corresponding author), S China Univ Technol, Guangzhou 510641, Guangdong, Peoples R China.
EM liuwf@upc.edu.cn; dtao.scut@gmail.com
RI Tao, Dacheng/A-5449-2012
OI Tao, Dacheng/0000-0001-7225-5449
FU National Natural Science Foundation of China [61271407, 61301242];
   Shandong Provincial Natural Science Foundation, China [ZR2011FQ016];
   Fundamental Research Funds for the Central Universities, China
   University of Petroleum (East China) [13CX02096A, CX2013057,
   27R1105019A]
FX This work was supported in part by the following projects: the National
   Natural Science Foundation of China (61271407, 61301242), Shandong
   Provincial Natural Science Foundation, China (ZR2011FQ016), the
   Fundamental Research Funds for the Central Universities, China
   University of Petroleum (East China) (13CX02096A, CX2013057,
   27R1105019A).
CR [Anonymous], CUBLAS LIB
   [Anonymous], CUDA C PROGR GUID VE
   [Anonymous], 2006, KDD
   Bache K, 2013, UCI machine learning repository
   CADIMA J, 1995, J APPL STAT, V22, P203, DOI 10.1080/757584614
   Cai D, 2011, VLDB J, V20, P21, DOI 10.1007/s00778-010-0189-3
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Chiang CC, 2015, MULTIMED TOOLS APPL, V74, P2861, DOI 10.1007/s11042-013-1750-z
   d'Aspremont A, 2008, J MACH LEARN RES, V9, P1269
   d'Aspremont A, 2007, SIAM REV, V49, P434, DOI 10.1137/050645506
   Du YT, 2013, MULTIMED TOOLS APPL, V66, P545, DOI 10.1007/s11042-012-1213-y
   Fanty Mark, 1990, SPOKEN LETT RECOGNII
   Galassi M., 2003, GNU SCI LIB
   Guan NY, 2012, IEEE T NEUR NET LEAR, V23, P1087, DOI 10.1109/TNNLS.2012.2197827
   Guan NY, 2012, IEEE T SIGNAL PROCES, V60, P2882, DOI 10.1109/TSP.2012.2190406
   Guan NY, 2011, IEEE T NEURAL NETWOR, V22, P1218, DOI 10.1109/TNN.2011.2157359
   Guan NY, 2011, IEEE T IMAGE PROCESS, V20, P2030, DOI 10.1109/TIP.2011.2105496
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   JOLLIFFE IT, 1995, J APPL STAT, V22, P29, DOI 10.1080/757584395
   Jolliffe IT, 2003, J COMPUT GRAPH STAT, V12, P531, DOI 10.1198/1061860032148
   Journée M, 2010, J MACH LEARN RES, V11, P517
   Li J, 2006, IEEE T IMAGE PROCESS, V15, P3597, DOI 10.1109/TIP.2006.881938
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Moghaddam B., 2006, Advances in Neural Information Processing Systems, P915
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Tao DC, 2006, IEEE T MULTIMEDIA, V8, P716, DOI 10.1109/TMM.2005.861375
   Tao DC, 2009, IEEE T PATTERN ANAL, V31, P260, DOI 10.1109/TPAMI.2008.70
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Xu C, 2014, IEEE T PATTERN ANAL, V36, P1559, DOI 10.1109/TPAMI.2013.2296528
   Zha Z., 2008, CVPR
   Zha ZJ, 2012, IEEE T MULTIMEDIA, V14, P17, DOI 10.1109/TMM.2011.2174782
   Zheng YT, 2011, MULTIMED TOOLS APPL, V51, P77, DOI 10.1007/s11042-010-0630-z
   Zou H, 2006, J COMPUT GRAPH STAT, V15, P265, DOI 10.1198/106186006X113430
NR 36
TC 46
Z9 47
U1 3
U2 41
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 3
BP 1481
EP 1493
DI 10.1007/s11042-014-2004-4
PG 13
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HW
UT WOS:000371309600008
DA 2024-07-18
ER

PT J
AU Yao, YB
   Li, XJ
   Lu, Y
AF Yao, Yingbiao
   Li, Xiaojuan
   Lu, Yu
TI Fast intra mode decision algorithm for HEVC based on dominant edge
   assent distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE HEVC; Mode decision; Intra prediction; Dominant edge assent distribution
ID SIZE DECISION; EFFICIENCY
AB As the latest video coding standard, high efficiency video coding (HEVC) is a successor to H.264/AVC. To improve the coding efficiency of intra coding, HEVC employs a flexible quad-tree coding block partitioning structure and 35 intra prediction modes. The optimal prediction mode is selected through rough mode decision (RMD) and rate distortion optimisation (RDO) process. Due to the huge search space of all of the possible depth levels (CU sizes) and intra prediction modes, intra coding of HEVC is a very time-consuming and complicated process, which limits the application of HEVC. In order to reduce the intra coding complexity, we propose a fast mode decision algorithm for HEVC intra prediction which is based on dominant edge assent (DEA) and its distribution. The four DEAs in the directions of degree 0, 45, 90 and 135 are computed first; then, the dominant edge is decided according to the minimum DEA. Next, a subset of prediction modes in accordance with the dominant edge is chosen for the RMD process. The rule is as follows: When the standard deviation of DEA is distinctly small, we skip the RMD process and take the direct current (DC) mode and planar modes as the candidate modes for the RDO process; when the minimum DEA is distinctly small, we select seven modes as the candidate modes for the RMD process; otherwise, we select 11 modes for the RMD process. Lastly, the prediction unit (PU) size-based number of RDO candidate modes (3 for PU size 4 x 4 and 8 x 8 and 1 for the other PU sizes) is modified according to experimental analysis. Compared with HM 9.1, Shen's proposal and da Silva's proposal, which are two state-of-the-art fast intra mode decision algorithms, the experimental results reveal that the proposed algorithm can save 36.26, 13.85 and 20.81 % coding time on average with a negligible loss of coding efficiency, respectively.
C1 [Yao, Yingbiao; Li, Xiaojuan; Lu, Yu] Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Hangzhou Dianzi University
RP Yao, YB (corresponding author), Hangzhou Dianzi Univ, Coll Commun Engn, Hangzhou 310018, Zhejiang, Peoples R China.
EM yaoyb@hdu.edu.cn; 354577289@qq.com; y_lu@hdu.edu.cn
RI yao, yao/HHZ-7438-2022
FU National Natural Science Foundation of China [61100044]
FX We thank the anonymous reviewers for their helpful comments and insights
   to improve this manuscript significantly. The work was supported in part
   by the National Natural Science Foundation of China (61100044).
CR [Anonymous], ELECTRONIC JOURNAL O, DOI DOI 10.1109/VCIP.2011.6115979
   Bjontegaard G., 2001, ITU T VCEG M AUST TE
   Bossen F, 2012, JCTVSK1100 ITUTISOTE
   Chen G, 2013, IEEE INT SYMP CIRC S, P53, DOI 10.1109/ISCAS.2013.6571780
   Cho S, 2013, IEEE T CIRC SYST VID, V23, P1555, DOI 10.1109/TCSVT.2013.2249017
   da Silva TL, 2012, EUR SIGNAL PR CONF, P1214
   Fang CM, 2013, I SYMP CONSUM ELECTR, P61
   Gaoxing Chen, 2013, 2013 IEEE China Summit and International Conference on Signal and Information Processing (ChinaSIP), P514, DOI 10.1109/ChinaSIP.2013.6625393
   Johar S, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P721, DOI 10.1109/CCNC.2013.6488534
   Khan MUK, 2013, IEEE IMAGE PROC, P1578, DOI 10.1109/ICIP.2013.6738325
   Kim J, 2013, IEEE ICCE, P637, DOI 10.1109/ICCE.2013.6487050
   Ma SW, 2013, IEEE DATA COMPR CONF, P73, DOI 10.1109/DCC.2013.15
   McCann K., 2012, JCTVCK1002 ITUTISOIE
   Ohm JR, 2012, IEEE T CIRC SYST VID, V22, P1669, DOI 10.1109/TCSVT.2012.2221192
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Piao Y, 2010, JCTVCC207 ITUTISOIEC
   Shen LQ, 2013, IEEE T CONSUM ELECTR, V59, P207, DOI 10.1109/TCE.2013.6490261
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tsai AC, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1587
   Wei Jiang, 2012, 2012 2nd International Conference on Consumer Electronics, Communications and Networks (CECNet), P1836, DOI 10.1109/CECNet.2012.6201851
   Wiegand T, 2010, IEEE T CIRC SYST VID, V20, P1661, DOI 10.1109/TCSVT.2010.2095692
   [晏轲 Yan Ke], 2014, [光电子·激光, Journal of Optoelectronics·Laser], V25, P156
NR 22
TC 27
Z9 31
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2016
VL 75
IS 4
BP 1963
EP 1981
DI 10.1007/s11042-014-2382-7
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DF4HQ
UT WOS:000371309000011
DA 2024-07-18
ER

PT J
AU Li, F
   Zhang, DY
   Wang, LJ
AF Li, Fan
   Zhang, Danyang
   Wang, Liejun
TI Packet importance based scheduling strategy for H.264 video transmission
   in wireless networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Packet distortion; Packet loss; Scheduling
   algorithms
ID RESOURCE-ALLOCATION; ALGORITHM
AB This paper investigates the problem of H.264 video transmission in wireless networks. We propose a packet scheduling algorithm based on the packet quality contribution index (PQCI) of H.264 video packet. The PQCI is estimated not only by the quality distortion made for the current frame, but also by that made for the frames which are directly or indirectly related with current frame. A dual-decoder-model (DDM) algorithm is proposed for the PQCI estimation. In DDM algorithm, we develop a novel architecture with two simulated decoders in the sender. To reduce the computational complexity, an estimated-model (EM) algorithm is also proposed. In EM algorithm, the coding characters of video that are pre-coded are extracted for the PQCI estimation. The results demonstrate that our schemes can bring a significant gain to the end-to-end video quality with respect to traditional methods.
C1 [Li, Fan; Zhang, Danyang] Xi An Jiao Tong Univ, Sch Elect & Informat Engn, Xian 710049, Peoples R China.
   [Wang, Liejun] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.
C3 Xi'an Jiaotong University; Xinjiang University
RP Wang, LJ (corresponding author), Xinjiang Univ, Sch Informat Sci & Engn, Urumqi 830046, Peoples R China.
EM wlj@mail.xjtu.edu.cn
FU National Natural Science Foundation of China [61372091, 61261036];
   Natural Science Basic Research Plan in Shaanxi Province of China
   [2014JM8318]; Fundamental Research Funds for Central Universities
FX This study was supported in part by National Natural Science Foundation
   of China 61372091, 61261036, Natural Science Basic Research Plan in
   Shaanxi Province of China 2014JM8318, and the Fundamental Research Funds
   for the Central Universities.
CR [Anonymous], 2006, 80216E2005 IEEE COMP
   Baccaglini E, 2011, MULTIMED TOOLS APPL, V55, P247, DOI 10.1007/s11042-010-0574-3
   Capozzi F, 2013, IEEE COMMUN SURV TUT, V15, P678, DOI 10.1109/SURV.2012.060912.00100
   Dua A, 2007, IEEE T MOBILE COMPUT, V6, P1410, DOI 10.1109/TMC.2007.1055
   Fattah H, 2002, IEEE WIREL COMMUN, V9, P76, DOI 10.1109/MWC.2002.1043857
   Fotis L, 2013, J SYST SOFT
   High Speed Downlink Packet Access, 2006, 25308 TS 3GPP
   Hossain E, 2014, RESOURCE ALLOCATION, P206
   Li F, 2010, IET COMMUN, V4, P1012, DOI 10.1049/iet-com.2009.0618
   Li P, 2011, IEEE T CONSUM ELECTR, V57, P1128, DOI 10.1109/TCE.2011.6018865
   Liu QW, 2006, IEEE T VEH TECHNOL, V55, P839, DOI 10.1109/TVT.2006.873832
   Liu QW, 2004, IEEE T WIREL COMMUN, V3, P1746, DOI 10.1109/TWC.2004.833474
   LIU QW, 2004, P 1 INT C QSHINE TX, P65
   Pahalawatta P, 2007, IEEE J SEL AREA COMM, V25, P749, DOI 10.1109/JSAC.2007.070511
   Rubio L, 2007, AEU-INT J ELECTRON C, V61, P135, DOI 10.1016/j.aeue.2006.03.004
   Shen C, 2008, IEEE T WIREL COMMUN, V7, P3546, DOI 10.1109/TWC.2008.070337
   Wu J, 2013, MULTIMEDIA TOOLS APP
NR 17
TC 2
Z9 2
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 23
BP 10259
EP 10275
DI 10.1007/s11042-014-2163-3
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV7YQ
UT WOS:000364493700005
DA 2024-07-18
ER

PT J
AU Luo, J
   Yang, XH
   Liu, LH
AF Luo, Jun
   Yang, Xiaohua
   Liu, Liheng
TI A fast motion estimation algorithm based on adaptive pattern and search
   priority
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Motion estimation; Block matching; Search priority; Adaptive pattern;
   Video coding
AB Block matching algorithm (BMA) has been widely used in motion estimation for various video coding standards since it can remove temporal redundancy effectively. However, motion estimation is the key problem in realizing real-time video coding due to the high computation complexity of BMA. In this manuscript, we present a fast motion estimation algorithm according to the adaptive pattern and search priority (APSP). Based on the distribution characteristics of motion vector (MV) that achieved by a series of experiments, the improved algorithm defines different efficient patterns and adopts the appropriate pattern adaptively. Firstly, the search can be stopped after checking one point by the features of the current block. And then the starting pattern is determined based on the motion vectors from the neighboring blocks. The subsequent pattern can be further adjusted according to the current best matching point. Furthermore, the proposed method assigns search priority to each point of every pattern. Therefore, the search is performed under the guidance of the search priority, with the result that each pattern can be interrupted in any position by using priority and threshold. Compared to conventional fast algorithms, the experimental results demonstrate that the proposed algorithm improves the performance of the search algorithm with significant reduction in computational complexity on the premise of ensuring the image quality and searching precision.
C1 [Luo, Jun; Yang, Xiaohua; Liu, Liheng] Chongqing Univ, Minist Educ, Key Lab Optoelect Technol & Syst, Chongqing 400030, Peoples R China.
C3 Chongqing University
RP Luo, J (corresponding author), Chongqing Univ, Minist Educ, Key Lab Optoelect Technol & Syst, Chongqing 400030, Peoples R China.
EM luojun@cqu.edu.cn
RI Liu, Liheng/AAB-3914-2022; Luo, Jun/JPX-3855-2023
FU National Defense Basic Scientific Research program of China [JG201104]
FX The authors are grateful for the support from the National Defense Basic
   Scientific Research program of China under Grand no.JG201104. We would
   also like to thank the editor and the anonymous reviewers for their
   valuable comments and suggestions.
CR Bajaj M, 2012, IETE J RES, V58, P171, DOI 10.4103/0377-2063.96184
   Cuevas E, 2013, APPL INTELL, V39, P165, DOI 10.1007/s10489-012-0403-7
   Cuevas E, 2013, APPL SOFT COMPUT, V13, P3047, DOI 10.1016/j.asoc.2012.09.020
   Goel S, 2012, COMPUT J, V55, P35, DOI 10.1093/comjnl/bxr034
   Hosur P, 1999, P 2 INT C INF COMM S, P7
   Hsieh LL, 2011, EXPERT SYST APPL, V38, P11608, DOI 10.1016/j.eswa.2011.03.039
   Ismail Y, 2012, IEEE T CIRC SYST VID, V22, P28, DOI 10.1109/TCSVT.2011.2148450
   Ko YH, 2011, IEEE T CONSUM ELECTR, V57, P726, DOI 10.1109/TCE.2011.5955214
   Koga T, 1981, NTC 81
   Kuo CM, 2009, IEEE T CIRC SYST VID, V19, P893, DOI 10.1109/TCSVT.2009.2017420
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   Lin ML, 2012, PHYSCS PROC, V33, P1526, DOI 10.1016/j.phpro.2012.05.248
   Ng KH, 2009, IEEE T CIRC SYST VID, V19, P753, DOI 10.1109/TCSVT.2009.2017414
   Pandian SIA, 2013, ENG APPL ARTIF INTEL, V26, P1811, DOI 10.1016/j.engappai.2013.04.003
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Purwar RK, 2013, SIGNAL IMAGE VIDEO P, V7, P151, DOI 10.1007/s11760-011-0283-z
   Shen LQ, 2012, IEEE T IMAGE PROCESS, V21, P2582, DOI 10.1109/TIP.2011.2177849
   Shi ZR, 2011, IEEE T CONSUM ELECTR, V57, P1354, DOI 10.1109/TCE.2011.6018894
   Tedmori S., 2012, IET Computer Vision, V6, P21, DOI 10.1049/iet-cvi.2010.0188
   Tsai AC, 2012, IEEE T CIRC SYST VID, V22, P981, DOI 10.1109/TCSVT.2011.2165592
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 23
TC 18
Z9 18
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11821
EP 11836
DI 10.1007/s11042-014-2280-z
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600038
DA 2024-07-18
ER

PT J
AU Zhong, GY
   He, XH
   Qing, LB
   Li, Y
AF Zhong, Guoyun
   He, Xiaohai
   Qing, Linbo
   Li, Yuan
TI A fast inter-prediction algorithm for HEVC based on temporal and spatial
   correlation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE High Efficiency Video Coding (HEVC); inter-prediction; Coding Unit (CU);
   Prediction Unit (PU)
ID DECISION METHOD
AB In HEVC, the structure of coding unit (CU) and prediction unit (PU) is defined, which brings about higher coding efficiency than H.264/AVC. However, the rate distortion (RD) cost calculations of all depths of CUs and partition modes have yielded tremendous coding computational complexity. In order to reduce the complexity, a fast inter-prediction algorithm is proposed based on temporal and spatial correlations in this paper. In the proposed algorithm, the optimal partition mode in HEVC is selected based on its occurrence probability among all the partition modes and the similarity of the CU segmentation and partition mode between two adjacent frames is counted. Based on the optimal mode and similarity of CU segmentation and partition mode, at most two partition modes are evaluated for each CU to save computational complexity. In addition, the spatial correlation of CU segmentation and partition mode between the corresponding located (co-located) CU and its four surrounding CUs are analyzed. Based on this spatial correlation, only the optimal partition mode is evaluated to save the computational complexity for the deeper depths of CUs of the current CU. Simulation results show that the proposed algorithm achieves 65 % coding time reduction with negligible loss in coding efficiency and peak signal-to-noise ratio (PSNR), compared to previous fast mode decision algorithm.
C1 [Zhong, Guoyun; He, Xiaohai; Qing, Linbo; Li, Yuan] Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Peoples R China.
   [Zhong, Guoyun] E China Inst Technol, Coll Informat Engn, Fuzhou, Peoples R China.
C3 Sichuan University; East China University of Technology
RP He, XH (corresponding author), Sichuan Univ, Coll Elect & Informat Engn, Chengdu 610064, Peoples R China.
EM gyzhong55@163.com; hxh@scu.edu.cn
FU Doctor Station Foundation of National Ministry of Education of China
   [20, 110, 181, 120, 009]; National Natural Science Foundations of China
   [61, 201, 388]; Science and Technology Project of Jiangxi Province
   Office of Education [GJJ14490]
FX This work was supported by Doctor Station Foundation of National
   Ministry of Education of China (20,110,181,120,009), the National
   Natural Science Foundations of China (61,201,388), and the Science and
   Technology Project of the Jiangxi Province Office of Education
   (GJJ14490). The authors would like to thank the anonymous reviewers for
   their valuable comments and helpful suggestions.
CR Alshina E., 2008, P 86 MPEG M
   [Anonymous], 2008, 35 M BERL GERM 16 18
   Bull DR, 2011, IEEE J-STSP, V5, P1277, DOI 10.1109/JSTSP.2011.2170331
   Choi K, 2012, ELECTRON LETT, V48, P689, DOI 10.1049/el.2012.0277
   Correa G, 2013, IEEE DATA COMPR CONF, P43, DOI 10.1109/DCC.2013.12
   Corrêa G, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P425, DOI 10.1109/PCS.2012.6213378
   Corrêa G, 2011, IEEE T CONSUM ELECTR, V57, P1866, DOI 10.1109/TCE.2011.6131165
   De Simone F, 2011, J VIS COMMUN IMAGE R, V22, P734, DOI 10.1016/j.jvcir.2011.01.008
   Goswami Kalyan, 2013, MULTIMEDIA TOOLS APP
   Han WJ, 2010, IEEE T CIRC SYST VID, V20, P1709, DOI 10.1109/TCSVT.2010.2092612
   Il-Koo Kim, 2013, JCTVCO1002 ISOIEC IT
   Kim J, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P449, DOI 10.1109/PCS.2012.6213251
   Kim J, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE), P261, DOI 10.1109/ICCE.2012.6161857
   Lee KH, 2008, P 85 MPEG M
   Shen LQ, 2013, IEEE T MULTIMEDIA, V15, P465, DOI 10.1109/TMM.2012.2231060
   Shen XL, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-4
   Shen XL, 2012, 2012 PICTURE CODING SYMPOSIUM (PCS), P453, DOI 10.1109/PCS.2012.6213252
   Ugur K, 2010, IEEE T CIRC SYST VID, V20, P1688, DOI 10.1109/TCSVT.2010.2092613
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhang YF, 2013, IEEE DATA COMPR CONF, P53, DOI 10.1109/DCC.2013.13
NR 20
TC 10
Z9 10
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2015
VL 74
IS 24
BP 11023
EP 11043
DI 10.1007/s11042-014-2216-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CX1HG
UT WOS:000365446600004
DA 2024-07-18
ER

PT J
AU Mohedano, E
   Healy, G
   McGuinness, K
   Giró-i-Nieto, X
   O'Connor, NE
   Smeaton, AF
AF Mohedano, Eva
   Healy, Graham
   McGuinness, Kevin
   Giro-i-Nieto, Xavier
   O'Connor, Noel E.
   Smeaton, Alan F.
TI Improving object segmentation by using EEG signals and rapid serial
   visual presentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Brain-computer interfaces; Electroencephalography; Rapid serial visual
   presentation; Object segmentation; Interactive segmentation; GrabCut
   algorithm
ID EYE
AB This paper extends our previous work on the potential of EEG-based brain computer interfaces to segment salient objects in images. The proposed system analyzes the Event Related Potentials (ERP) generated by the rapid serial visual presentation of windows on the image. The detection of the P300 signal allows estimating a saliency map of the image, which is used to seed a semi-supervised object segmentation algorithm. Thanks to the new contributions presented in this work, the average Jaccard index was improved from 0.47 to 0.66 when processed in our publicly available dataset of images, object masks and captured EEG signals. This work also studies alternative architectures to the original one, the impact of object occupation in each image window, and a more robust evaluation based on statistical analysis and a weighted F-score.
C1 [Mohedano, Eva; Healy, Graham; McGuinness, Kevin; O'Connor, Noel E.; Smeaton, Alan F.] Dublin City Univ, Insight Ctr Data Analyt, Dublin 9, Ireland.
   [Giro-i-Nieto, Xavier] Univ Politecn Cataluna, Image Proc Grp, Catalunya, Spain.
C3 Dublin City University; Universitat Politecnica de Catalunya
RP Mohedano, E (corresponding author), Dublin City Univ, Insight Ctr Data Analyt, Dublin 9, Ireland.
EM eva.mohedano@insight-centre.org
RI Giró-i-Nieto, Xavier/M-5834-2013; McGuinness, Kevin/V-2424-2019
OI Giró-i-Nieto, Xavier/0000-0002-9935-5332; McGuinness,
   Kevin/0000-0003-1336-6477; Healy, Graham/0000-0001-6429-6339; O'Connor,
   Noel/0000-0002-4033-9135; Smeaton, Alan F./0000-0003-1028-8389
FU Science Foundation Ireland (SFI) [SFI/12/RC/2289]; Spanish Government
   [TEC2013-43935-R BigGraph]
FX This publication has emanated from research conducted with the financial
   support of Science Foundation Ireland (SFI) under grant number
   SFI/12/RC/2289 and partially funded by the Project TEC2013-43935-R
   BigGraph of the Spanish Government.
CR [Anonymous], 2014, CVPR
   [Anonymous], 2012, EVENT RELATED POTENT
   [Anonymous], P 1 IEEE WORKSH US C
   [Anonymous], THESIS NE U
   [Anonymous], 2009, P 17 ACM INT C MULT, DOI DOI 10.1145/1631272.1631463
   BAUER G, 1979, J NEUROL, V221, P77, DOI 10.1007/BF00313105
   Bell CJ, 2008, J NEURAL ENG, V5, P214, DOI 10.1088/1741-2560/5/2/012
   Bigdely-Shamlo N, 2008, IEEE T NEUR SYS REH, V16, P432, DOI 10.1109/TNSRE.2008.2003381
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Cruse D, 2011, LANCET, V378, P2088, DOI 10.1016/S0140-6736(11)61224-5
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Healy G, 2011, IEEE ENG MED BIO, P4203, DOI 10.1109/IEMBS.2011.6091043
   Hu XT, 2012, IEEE T MULTIMEDIA, V14, P314, DOI 10.1109/TMM.2011.2172201
   Huang YH, 2011, NEUROCOMPUTING, V74, P2041, DOI 10.1016/j.neucom.2010.12.025
   Kapoor A, 2008, PROC CVPR IEEE, P2150
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mohedano E, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P417, DOI 10.1145/2647868.2654896
   Motomura S, 2009, LECT NOTES ARTIF INT, V5819, P63, DOI 10.1007/978-3-642-04954-5_17
   Orhan U, 2013, J NEURAL ENG, V10, DOI 10.1088/1741-2560/10/6/066003
   Pathirage I, 2013, IEEE ASME INT C ADV, P188, DOI 10.1109/AIM.2013.6584090
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sajda P, 2010, P IEEE, V98, P462, DOI 10.1109/JPROC.2009.2038406
   Spence R., 2002, Information Visualization, V1, P13, DOI 10.1057/palgrave/ivs/9500008
   Yazdani A, 2010, IEEE IMAGE PROC, P3169, DOI 10.1109/ICIP.2010.5654346
NR 25
TC 5
Z9 5
U1 1
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2015
VL 74
IS 22
BP 10137
EP 10159
DI 10.1007/s11042-015-2805-0
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CV1LQ
UT WOS:000364019400017
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Choi, SP
   Shin, SH
   Jung, HM
   Lee, D
AF Choi, Sung-Pil
   Shin, Sung-Ho
   Jung, Hanmin
   Lee, Daesung
TI Finding hidden relevant documents buried in scientific documents by
   terminological paraphrases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE facto relevant documents; Terminological paraphrase; Scientific
   information retrieval; Terminology; Text mining; Predicate argument
   tuple
ID QUERY EXPANSION
AB Technical terms play an important role of effective queries for many users to search scientific databases. However, authors of scientific literature often employ alternative expressions to represent the meanings of specific terms, in other words, Terminological Paraphrases (TPs) in the literature for certain reasons, which leads to producing relevant documents that are not captured by conventional terms above. In this paper, we propose an effective way to retrieve "de facto relevant documents" which only contain those TPs and cannot be searched by conventional models in an environment with only controlled vocabularies by adapting Predicate Argument Tuple (PAT). The experiment confirms that PAT-based document retrieval is an effective and promising method to discover those kinds of documents and to improve the recall of terminology-based scientific information access models.
C1 [Choi, Sung-Pil; Shin, Sung-Ho; Jung, Hanmin] KISTI, Taejon 305806, South Korea.
   [Choi, Sung-Pil; Shin, Sung-Ho; Lee, Daesung] Catholic Univ Pusan, Dept Comp Engn, Sch Appl Sci, Pusan 609757, South Korea.
C3 Korea Institute of Science & Technology Information (KISTI); Catholic
   University Pusan
RP Lee, D (corresponding author), Catholic Univ Pusan, Dept Comp Engn, Sch Appl Sci, 9 Bugok 3 Dong, Pusan 609757, South Korea.
EM spchoi@kisti.re.kr; maximus74@kisti.re.kr; jhm@kisti.re.kr;
   dslee@cup.ac.kr
RI Lee, Daesung/P-7946-2018
OI Lee, Daesung/0000-0002-2435-6867
CR Abdou S., 2005, 14 TEXT RETR C P TRE, P863
   Aronson A R, 1996, Proc AMIA Annu Fall Symp, P373
   Bacchin M, 2005, SYMBOL BASED QUERY E
   Choi S-P, 2012, SCI LIT RETRIEVAL BA
   Cohen J, 1968, PSYCHOL BULL, V70, P687
   InfoTerm, 2010, TERM STAND
   Lavrenko V., 2001, SIGIR Forum, P120
   Lu ZY, 2009, INFORM RETRIEVAL, V12, P69, DOI 10.1007/s10791-008-9074-8
   Macdonald C, 2007, LECT NOTES COMPUT SC, V4425, P431
   Miyao Y, 2008, COMPUT LINGUIST, V34, P35, DOI 10.1162/coli.2008.34.1.35
   Ponte JM, 1998, P 21 ANN INT ACM SIG, P275, DOI DOI 10.1145/290941.291008
   Srinivasan P, 1996, INFORM PROCESS MANAG, V32, P431, DOI 10.1016/0306-4573(95)00076-3
   TURTLE H, 1991, ACM T INFORM SYST, V9, P187, DOI 10.1145/125187.125188
NR 13
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 20
BP 8729
EP 8743
DI 10.1007/s11042-013-1484-y
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA CR6XU
UT WOS:000361492600002
DA 2024-07-18
ER

PT J
AU Hu, W
   Pan, QH
AF Hu, Wen
   Pan, Qing He
TI Data clustering and analyzing techniques using hierarchical clustering
   method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE RSS; Hierarchical clustering; Pearson correlation coefficient
AB Data clustering and analyzing techniques are studied by using hierarchical clustering method. A matrix of words is constructed with a randomly chosen RSS list. By collecting data from this list a matrix is built. In the matrix each row corresponds to a article and each column represents a word. Based on the matrix a hierarchical clustering algorithm is designed. In this algorithm the Pearson correlation coefficient is used to compute the distances among different contents. The dendrogram is used to describe the hierarchical relationship of contents and words. And the 2-D graph also is used to represent the dendrogram in another format.
C1 [Hu, Wen; Pan, Qing He] Harbin Univ Commerce, Sch Comp & Informat Engn, Harbin 150028, Peoples R China.
C3 Harbin University of Commerce
RP Pan, QH (corresponding author), Harbin Univ Commerce, Sch Comp & Informat Engn, Harbin 150028, Peoples R China.
EM 570749130@qq.com
RI Hu, Wen/B-5784-2011
FU Natural Science Foundation of Heilongjiang Province [F201034];
   Scientific Research Foundation for Doctor of Harbin University of
   Commerce [12DL024]
FX This research is supported by Natural Science Foundation of Heilongjiang
   Province (F201034); Scientific Research Foundation for Doctor of Harbin
   University of Commerce (12DL024)
CR Capota M, 2013, EUROMICRO WORKSHOP P, P437, DOI 10.1109/PDP.2013.70
   Getahun F, 2013, INFORM SCIENCES, V237, P313, DOI 10.1016/j.ins.2013.02.025
   Hoffman D, 2009, 2009 TESTING: ACADEMIC AND INDUSTRIAL CONFERENCE-PRACTICE AND RESEARCH TECHNIQUES, TAIC PART 2009, P105, DOI 10.1109/TAICPART.2009.34
   Hoffman D, 2010, J SYST SOFTWARE, V83, P2369, DOI 10.1016/j.jss.2010.07.048
   Kim S, 2013, GRID PERVASIVE COMPU, V7861, P443
   Parimala LopezSenthilkumar., 2011, INT J ADV SCI TECHNO, V31, P59
   Segaran T., 2007, PROGRAMMING COLLECTI
   Shi P, 2009, INT J ADV SCI TECHNO, V5, P1
   Wang L, 2009, INT J ADV SCI TECHNO, V2, P72
NR 9
TC 10
Z9 10
U1 2
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2015
VL 74
IS 19
BP 8495
EP 8504
DI 10.1007/s11042-013-1611-9
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CQ4HE
UT WOS:000360564600016
DA 2024-07-18
ER

PT J
AU Yeh, KH
   Tsai, KY
   Fan, CY
AF Yeh, Kuo-Hui
   Tsai, Kuo-Yu
   Fan, Chuan-Yen
TI An efficient certificateless signature scheme without bilinear pairings
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Certificateless; Digital signature; Bilinear pairings; Cryptanalysis
ID GENERIC CONSTRUCTION
AB During these years, the research field of certificateless signature (CLS) scheme is promptly investigated as the key escrow problem in identity-based cryptography can be solved via CLS concept. However, due to the bandwidth limitation of mobile communication and the resource-constraint property of handheld mobile devices, most CLS schemes cannot fulfill the requirement of computation efficiency for mobile communication architecture. Hence, the design of lightweight CLS protocol refined from traditional cryptosystem technologies for existing mobile communication environment becomes one of the most important research trends. In this paper, we demonstrate a novel CLS scheme which is immune against bilinear pairings. Without the heavy computation of bilinear pairings, our proposed scheme is efficient and practical for mobile communication. Meanwhile, the proposed CLS scheme possesses strong security density owing to the adoption of point addition of elliptic curve cryptography. A formal security analysis is presented to guarantee the security robustness of our CLS protocol under the hardness of breaking elliptic curve discrete logarithm problem.
C1 [Yeh, Kuo-Hui] Natl Dong Hwa Univ, Dept Informat Management, Hualien 974, Taiwan.
   [Tsai, Kuo-Yu] Hwa Hsia Inst Technol, Dept Management Informat Syst, New Taipei City 235, Taiwan.
   [Fan, Chuan-Yen] Inst Informat Ind, CyberTrust Technol Inst, CTTI, New Taipei City 10622, Taiwan.
C3 National Dong Hwa University
RP Tsai, KY (corresponding author), Hwa Hsia Inst Technol, Dept Management Informat Syst, New Taipei City 235, Taiwan.
EM KuoYu.Nicklas.Tsai@gmail.com
FU Taiwan Information Security Center (TWISC); National Science Council,
   Taiwan [NSC 102-2218-E-259-004, NSC 102-2218-E-146-002, NSC
   102-2218-E-011-012]
FX This work was partly supported by the Taiwan Information Security Center
   (TWISC) and National Science Council, Taiwan, under the Grants Numbers
   NSC 102-2218-E-259-004, NSC 102-2218-E-146-002 and NSC
   102-2218-E-011-012.
CR Al-Riyami SS, 2003, LECT NOTES COMPUT SC, V2894, P452
   [Anonymous], 2013, 2013 INT C IT CONV S
   Gorantla MC, 2005, LECT NOTES ARTIF INT, V3802, P110
   He D, 2012, INT J COMMUN SYST, V25, P1432, DOI 10.1002/dac.1330
   He DB, 2012, INT J COMMUN SYST, V25, P221, DOI 10.1002/dac.1265
   Hu BC, 2006, LECT NOTES COMPUT SC, V4058, P235
   Huang XY, 2007, LECT NOTES COMPUT SC, V4586, P308
   Huang XY, 2005, LECT NOTES COMPUT SC, V3810, P13
   Li X., 2005, LITH MATH J, V45, P76, DOI DOI 10.1007/S10986-005-0008-5
   Liu YC, 2015, INT J COMMUN SYST, V28, P842, DOI 10.1002/dac.2708
   Shamir A., 1985, Advances in Cryptology, V84 4, P47, DOI 10.1007/3-540-39568-7_5
   Tian MM, 2013, INT J COMMUN SYST, V26, P1375, DOI 10.1002/dac.2310
   Tsai JL, 2014, INT J COMMUN SYST, V27, P1083, DOI 10.1002/dac.2388
   Yum DH, 2004, LECT NOTES COMPUT SC, V3108, P200
NR 14
TC 36
Z9 38
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2015
VL 74
IS 16
BP 6519
EP 6530
DI 10.1007/s11042-014-2154-4
PG 12
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CP4PN
UT WOS:000359864700028
DA 2024-07-18
ER

PT J
AU Nazir, S
   Vukobratovic, D
   Stankovic, V
   Andonovic, I
   Nybom, K
   Grönroos, S
AF Nazir, Sajid
   Vukobratovic, Dejan
   Stankovic, Vladimir
   Andonovic, Ivan
   Nybom, Kristian
   Gronroos, Stefan
TI Unequal error protection for data partitioned H.264/AVC video
   broadcasting
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video compression; Rateless coding; Digital Video Broadcasting; Joint
   source-channel coding
ID DVB-H; TRANSMISSION
AB Application Layer Forward Error Correction (AL-FEC) is becoming a popular addition to protocols for real-time video delivery over IP-based wireless networks. In particular, rateless codes are identified as suitable solution for AL-FEC due to their flexibility and capacity-approaching performance. Since each part of video data is not equally important for video reconstruction, it is beneficial to group it based on its importance, and then provide different degree of protection using Unequal Error Protection (UEP). Data partitioning (DP) is one such low-cost feature in H.264/AVC enabling partitioning of video data based on its importance. We propose schemes for the DP H.264/AVC video transmission using Raptor and Random Linear Codes (RLC) and investigate their performance as AL-FEC solutions in Digital Video Broadcasting. We provide comparisons between optimized Non-Overlapping Window RLC and Expanding Window (EW) RLC, which are two effective UEP RLC strategies. The results using realistic channel traces show viability of the EW RLC as a promising solution for multimedia broadcast applications.
C1 [Nazir, Sajid; Stankovic, Vladimir; Andonovic, Ivan] Univ Strathclyde, Dept EEE, Glasgow, Lanark, Scotland.
   [Vukobratovic, Dejan] Univ Novi Sad, Dept Power Elect & Commun Engn, Novi Sad 21000, Serbia.
   [Nybom, Kristian; Gronroos, Stefan] Abo Akad Univ, Turku, Finland.
C3 University of Strathclyde; University of Novi Sad; Abo Akademi
   University
RP Stankovic, V (corresponding author), Univ Strathclyde, Dept EEE, Glasgow, Lanark, Scotland.
EM dejanv@uns.ac.rs; vladimir.stankovic@eee.strath.ac.uk;
   kristian.nybom@abo.fi
RI Vukobratovic, Dejan/HHZ-7827-2022; Andonovic, Ivan/M-3985-2019;
   Stankovic, Vladimir/L-6584-2016
OI Andonovic, Ivan/0000-0001-9093-5245; Stankovic,
   Vladimir/0000-0002-1075-2420; Vukobratovic, Dejan/0000-0002-5305-8420
CR Al-Jobouri L., 2011, WIREL ENG TECHNOL, V2, P70
   Amine B., 2006, Journal of Zhejiang University (Science), V7, P27, DOI 10.1631/jzus.2006.AS0027
   Angelopoulos G, 2011, LECT NOTES COMPUT SC, V6827, P137, DOI 10.1007/978-3-642-23041-7_14
   [Anonymous], 2003, IEEE T CIRC SYST VID, DOI DOI 10.1109/TCSVT.2003
   [Anonymous], 302755 ETSI EN
   Barmada B, 2005, IEEE SIGNAL PROC LET, V12, P577, DOI 10.1109/LSP.2005.851261
   Benacem L., 2010, 2010 International Conference on Green Circuits and Systems (ICGCS 2010), P527, DOI 10.1109/ICGCS.2010.5543006
   Connie T, 2008, P 4 ACM WORKSH WIR M, P32
   Dhondt Y, 2007, LECT NOTES COMPUT SC, V4678, P720
   ETSI Technical Specification, 2005, 126346 ETSI TS
   Faria G, 2006, P IEEE, V94, P194, DOI 10.1109/JPROC.2005.861011
   Gómez-Barquero D, 2009, IEEE T BROADCAST, V55, P396, DOI 10.1109/TBC.2008.2012024
   Hellge C, 2011, IEEE T MULTIMEDIA, V13, P551, DOI 10.1109/TMM.2011.2129499
   Jin J, 2008, P IEEE INFOCOM 2008
   Katti S., 2006, P ACM SIGCOMM 2006 C
   Luby M, 2007, IEEE T BROADCAST, V53, P235, DOI 10.1109/TBC.2007.891703
   Lun D., 2008, PHYS COMMUN, V1, P22
   Nybom K, 2010, P ICME 2010 IEEE INT
   Poikonen J, 2006, IEEE ICC, P1861
   Razavi R, 2009, P ICIP 2009 INT C IM
   Schierl T, 2007, IEEE T CIRC SYST VID, V17, P1204, DOI 10.1109/TCSVT.2007.905528
   Schwarz H, 2007, IEEE T CIRC SYST VID, V17, P1103, DOI 10.1109/TCSVT.2007.905532
   Shojania H., 2007, P IWQOS 2007 15 INT
   Shojania H, 2009, P NOSSDAV 2009 WILL
   Shokrollahi A, 2006, IEEE T INFORM THEORY, V52, P2551, DOI 10.1109/TIT.2006.874390
   Stockhammer T, 2004, IEEE IMAGE PROC, P545
   Stockhammer T, 2008, INTERNET COMMUN, P239
   Teerapittayanon S, 2012, P MACOM 2012 INT WOR
   Vangelista L, 2009, IEEE COMMUN MAG, V47, P146, DOI 10.1109/MCOM.2009.5273822
   Vingelmann P, 2011, P CCNC IEEE CONS COM
   Vukobratovic D, 2012, IEEE T COMMUN, V60, P1243, DOI 10.1109/TCOMM.2012.030712.100454
   Vukobratovic D, 2009, IEEE T MULTIMEDIA, V11, P1094, DOI 10.1109/TMM.2009.2026087
   Wenger S, 2003, IEEE T CIRC SYST VID, V13, P645, DOI 10.1109/TCSVT.2003.814966
NR 33
TC 6
Z9 6
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5787
EP 5809
DI 10.1007/s11042-014-1883-8
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100020
DA 2024-07-18
ER

PT J
AU Nguyen, TD
   Arch-int, S
   Arch-int, N
AF Tuan Duc Nguyen
   Arch-int, Somjit
   Arch-int, Ngamnij
TI A novel secure block data-hiding algorithm using cellular automata to
   enhance the performance of JPEG steganography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Block data-hiding; Cellular automata; Ensemble classifier; Steganography
AB The computational complexity of matrix embedding (ME)-based steganography is high due to the use of the Hamming parity check matrix and matrix multiplication. Furthermore, with only one embedding change solution, ME cannot minimize embedding distortions when applied to joint photographic experts group (JPEG) steganography. In this paper, we propose a novel block data-hiding (BDH) algorithm to improve the performance of JPEG steganography. BDH allows a byte of data to be hidden in a binary block by modifying a maximum of two bits of the binary block must be changed. Moreover, BDH can be applied to the new channel selection rule for JPEG steganography with more available embedding solutions and less computational complexity than modified matrix embedding (MME). In addition, to increase the security of hidden data against extraction attacks, the secret message is encrypted by a cipher based on cellular automata (CA). The bitwise XOR operator is employed in the encryption process to maintain speed and security when a non-repeating key stream is used. The experimental results indicate that the proposed approach has a high anti-detection property against ensemble classifiers (universal steganalyzers), high security against recovery attacks, and good perceptual quality.
C1 [Tuan Duc Nguyen; Arch-int, Somjit; Arch-int, Ngamnij] Khon Kaen Univ, Fac Sci, Dept Comp Sci, Khon Kaen, Thailand.
C3 Khon Kaen University
RP Nguyen, TD (corresponding author), Khon Kaen Univ, Fac Sci, Dept Comp Sci, Khon Kaen, Thailand.
EM nguyenductuan1982@gmail.com; somjit@kku.ac.th; ngamnij@kku.ac.th
OI DUC TUAN, NGUYEN/0000-0001-5261-271X
CR Adamatzky A, 2010, GAME OF LIFE CELLULAR AUTOMATA, P1, DOI 10.1007/978-1-84996-217-9
   [Anonymous], P 4 INF HID WORKSH
   [Anonymous], CIRC SYST 2008 ISCAS
   [Anonymous], CHAOS BASED ENCRYPTI
   [Anonymous], INT MULT C P 2004 WO
   [Anonymous], P 9 INT C INF HID SA
   [Anonymous], 2007, P 9 WORKSH MULT SEC
   [Anonymous], 2009, P 11 ACM WORKSH MULT
   [Anonymous], NEV COMPR IM DAT
   [Anonymous], 2007, ELECT IMAGING SECURI
   Bandyopadhyay Samir Kumar, 2011, International Journal of Advanced Computer Science and Applications, V2, P129
   Brown R., 2004, Dieharder, a random number test suite
   Crandall R., 1998, SOME NOTES STEGANOGR
   Cvejic N, 2005, J UNIVERS COMPUT SCI, V11, P56
   Huang FJ, 2012, IEEE T INF FOREN SEC, V7, P1181, DOI 10.1109/TIFS.2012.2198213
   Kim Y, 2007, LECT NOTES COMPUT SC, V4437, P314
   Kodovsky J, 2012, IEEE T INF FOREN SEC, V7, P432, DOI 10.1109/TIFS.2011.2175919
   Langelaar GC, 2000, IEEE SIGNAL PROC MAG, V17, P20, DOI 10.1109/79.879337
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Mazurczyk W, 2014, MULTIMED TOOLS APPL, V70, P2139, DOI 10.1007/s11042-012-1224-8
   Omoomi M, 2011, MULTIMED TOOLS APPL, V54, P201, DOI 10.1007/s11042-010-0517-z
   Qazanfari K, 2013, J ELECTRON IMAGING, V22, DOI 10.1117/1.JEI.22.4.043009
   Sallee P, 2004, LECT NOTES COMPUT SC, V2939, P154
   Sarkar A, 2010, IEEE T INF FOREN SEC, V5, P225, DOI 10.1109/TIFS.2010.2046218
   Su PC, 2013, MULTIMED TOOLS APPL, V66, P247, DOI 10.1007/s11042-011-0799-9
   Wang C, 2012, IEEE T INF FOREN SEC, V7, P346, DOI 10.1109/TIFS.2011.2164907
NR 26
TC 3
Z9 3
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2015
VL 74
IS 15
BP 5661
EP 5682
DI 10.1007/s11042-014-1877-6
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CN1XM
UT WOS:000358214100014
DA 2024-07-18
ER

PT J
AU Drgas, S
   Dabrowski, A
AF Drgas, Szymon
   Dabrowski, Adam
TI Speaker recognition based on multilevel speech signal analysis on Polish
   corpus
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Speaker recognition; High-level features; Kernel combination; Boosting
ID SUPPORT VECTOR MACHINES
AB This article deals with a new approach to the text-independent speaker verification task. It is namely proposed to combine spectral and the so-called high-level features (prosodic, articulatory, and lexical) in order to increase accuracy of speaker verification. The presented experiments were performed using a Polish language corpus developed by the authors, the so-called PUEPS corpus. It contains semi-spontaneous telephone conversations (acted emergency telephone notifications) recorded in laboratory conditions. As the Polish language is under resourced and the PUEPS corpus is relatively small, in this case a new approach is needed, other than these well known from NIST (National Institute of Standards and Technology) evaluations. The authors proposed to use the fast scoring instead of more complex classifiers and the AdaBoost (adaptive boosting) algorithm for features combination. Combination of features resulted in the equal error rate (EER) reduction for various SNR (signal-to-noise ratio) conditions. Additionally, score normalization methods were evaluated. It was shown that significant benefits can be obtained using the z-norm2 method.
C1 [Drgas, Szymon; Dabrowski, Adam] Poznan Univ Tech, Chair Control & Syst Engn, Div Signal Proc & Elect Syst, Poznan, Poland.
C3 Poznan University of Technology
RP Drgas, S (corresponding author), Poznan Univ Tech, Chair Control & Syst Engn, Div Signal Proc & Elect Syst, Ul Piotrowo 3A, Poznan, Poland.
EM szymon.drgas@put.poznan.pl; adam.dabrowski@put.poznan.pl
OI Drgas, Szymon/0000-0002-4603-8894
CR Adami AG, 2007, SPEECH COMMUN, V49, P277, DOI 10.1016/j.specom.2007.02.005
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], P 12 ANN C INT SPEEC
   Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360
   BAKER B, 2008, THESIS QUEENSLAND U
   Balcerek J, 2009, SPA C
   Campbell WM, 2007, IEEE T AUDIO SPEECH, V15, P2085, DOI 10.1109/TASL.2007.902874
   Campbell WM, 2006, IEEE SIGNAL PROC LET, V13, P308, DOI 10.1109/LSP.2006.870086
   Cetnarowicz D, 2010, SPA 2010: SIGNAL PROCESSING ALGORITHMS, ARCHITECTURES, ARRANGEMENTS, AND APPLICATIONS CONFERENCE PROCEEDINGS, P99
   Dabrowski A, 2012, P LANG RES PUBL SEC
   Dehak N., 2009, INT 2009
   Doddington G., 2001, P EUROSPEECH, P2521
   Drgas S, 2011, 5 LANG TECHN C
   Frankel J, 2007, INT 2007
   Kinnunen T, 2010, SPEECH COMMUN, V52, P12, DOI 10.1016/j.specom.2009.08.009
   Ozimek E, 2009, INT J AUDIOL, V48, P433, DOI 10.1080/14992020902725521
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Reynolds D, 2003, INT CONF ACOUST SPEE, P784
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Shriberg E, 2007, LECT NOTES COMPUTER
   Vapnik V., 1999, NATURE STAT LEARNING
   Wijitha Senadeera Wijitha Senadeera, 2006, International Journal of Food Engineering, V2, P7
NR 22
TC 5
Z9 5
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 12
BP 4195
EP 4211
DI 10.1007/s11042-013-1502-0
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CK4CW
UT WOS:000356168600002
OA hybrid
DA 2024-07-18
ER

PT J
AU Madzin, H
   Zainuddin, R
   Sharef, NM
AF Madzin, Hizmawati
   Zainuddin, Roziati
   Sharef, Nurfadhlina Mohd
TI IFM3IRS: Information fusion retrieval system with knowledge-assisted
   text and visual features based on medical conceptual model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Information fusion; Late fusion technique; Text-based retrieval;
   Visual-based image retrieval; Query expansion; Boolean model; Supervised
   classification
ID IMAGE RETRIEVAL
AB The technology of medical data production has been rapidly changed over the past few years. Modern computer technology has created the possibility of creating multi-modal medical images. Medical data often contain multi-modal information such as visual information (image) as well as textual information. Both types of information are important for medical retrieval system (MRS). Due to the information limitation at different levels of sources, the application of information fusion becomes a real need in medical application. In this research, an information fusion framework was built to develop the multi-modality medical image retrieval system (IFM3IRS). The framework utilizes two sources of information involving text and visual-based retrieval process. The application is based on sequential order where the result from text-based process will automatically be the input in visual-based process. The main contributions of this paper are the development of a new ranking model called MedHieCon ranking model which applies semantic concepts of modality, anatomy and pathology in text-based process and also the learning approach of medical images using medical concept model in visual-based process. ImageCLEFmed 2010 data collection was used to evaluate IFM3IRS and it shows that our information fusion framework is in top list among other researchers. Although text-based retrieval system has proven to be a better performance in MRS; it is significant to determine the overall performance improvements which include the fusion of text and image.
C1 [Madzin, Hizmawati] Univ Putra Malaysia, Multimedia Dept, Fac Comp Sci & Informat Technol, Serdang 43400, Malaysia.
   [Zainuddin, Roziati] Univ Malaya, Fac Comp Sci & Informat Technol, Dept Artificial Intelligence, Kuala Lumpur, Malaysia.
   [Sharef, Nurfadhlina Mohd] Univ Putra Malaysia, Dept Comp Sci, Fac Comp Sci & Informat Technol, Serdang 43400, Malaysia.
C3 Universiti Putra Malaysia; Universiti Malaya; Universiti Putra Malaysia
RP Madzin, H (corresponding author), Univ Putra Malaysia, Multimedia Dept, Fac Comp Sci & Informat Technol, Serdang 43400, Malaysia.
EM iezma.madzin@gmail.com; roziati@um.edu.my; nurfadhlina@upm.edu.my
RI /FSKTM, NURFADHLINA BINTI MOHD SHAREF/AAK-2591-2020
OI /FSKTM, NURFADHLINA BINTI MOHD SHAREF/0000-0003-4335-0513; madzin,
   hizmawati/0000-0003-0098-2086
CR Adiego J, 2004, IEEE DATA COMPR CONF, P522
   [Anonymous], 2007, On the Definition of Information Fusion as a Field of Research
   Apweiler R, 2004, NUCLEIC ACIDS RES, V32, pD115, DOI [10.1093/nar/gkh131, 10.1093/nar/gkw1099]
   Bedrick S., 2010, CLEF (Notebook Papers/LABs/Workshops)'10
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   Cavnar W.B., 1994, Proceedings of SDAIR-94, 3rd Annual Symposium on Document Analysis and Information Retrieval, V48113, P161
   Chbeir R, 2000, MIMS PROTOTYPE MED I
   Chevallet JP, 2005, WORK NOT 2005 CLEF W
   Depeursinge A, 2010, INFORM RETRIEVAL SER, V32, P95, DOI 10.1007/978-3-642-15181-1_6
   Diaz-Galiano M., 2009, SINAI at ImageCLEF 2010 medical task
   Díaz-Galiano MC, 2009, COMPUT BIOL MED, V39, P396, DOI 10.1016/j.compbiomed.2009.01.012
   Durao F, 2012, MULTIMED TOOLS APPL
   Hall DL, 1997, P IEEE, V85, P6, DOI [10.1109/5.554205, 10.1109/ISCAS.1998.705329]
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hearst MA, 2007, BIOINFORMATICS, V23, P2196, DOI 10.1093/bioinformatics/btm301
   Hiemstra D., 2000, International Journal on Digital Libraries, V3, P131, DOI 10.1007/s007999900025
   Hsu William, 2009, Int J Med Inform, V78 Suppl 1, pS13, DOI 10.1016/j.ijmedinf.2008.09.006
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Ibrahim R, 2010, MED IMAGE RETRIVAL I
   Lehmann TM, 2003, P SOC PHOTO-OPT INS, V5033, P109, DOI 10.1117/12.481942
   Müller H, 2004, INT J MED INFORM, V73, P1, DOI 10.1016/j.ijmedinf.2003.11.024
   Muller H, 2010, CLEF NOTEBOOK PAPERS
   Muller H., 2011, Multimedia Experiments, P72
   Ozer S, 2010, MED PHYS, V37, P1873, DOI 10.1118/1.3359459
   Parikshit Sondhi JS, 2010, CLEF NOTEBOOK PAPERS
   Peters C, 2001, WORKSH CROSS LANG EV
   Prasad M, 2009, PATTERN ANAL APPL, V12, P9, DOI 10.1007/s10044-007-0093-7
   Rahman Md Mahmudur, 2012, Medical Content-Based Retrieval for Clinical Decision Support. Second MICCAI International Workshop, MCBR-CDS 2011. Revised Selected Papers, P24, DOI 10.1007/978-3-642-28460-1_3
   SALTON G, 1975, COMMUN ACM, V18, P613, DOI 10.1145/361219.361220
   Stougiannis A., 2010, CLEF (Notebook Papers/LABs/Workshops)
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Wang W, 2006, T ASABE, V49, P1607, DOI 10.13031/2013.22035
   Xin Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1590, DOI 10.1109/ICPR.2010.393
NR 34
TC 1
Z9 1
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 11
BP 3651
EP 3674
DI 10.1007/s11042-013-1792-2
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CI6UQ
UT WOS:000354898800003
DA 2024-07-18
ER

PT J
AU Orozco, ALS
   González, DMA
   Garcia, LJ
   Hernández-Castro, J
AF Sandoval Orozco, Ana Lucila
   Arenas Gonzalez, David Manuel
   Javier Garcia, Luis
   Hernandez-Castro, Julio
TI Analysis of errors in exif metadata on mobile devices
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera mobile phones; Exif metadata; Forensics analysis
ID IMAGE; INFORMATION; RECOVERY
AB Nowadays the number of cameras integrated in mobile phones is growing very fast, making it essential to design new specific forensic analysis techniques aimed towards the pictures created with these devices. Most of these phones automatically add relevant Exif metadata in the process of image acquisition. This metadata, even if it is vulnerable to tampering, can be very helpful for a variety of forensic analysis techniques. That is why the existence of efficient, robust and specialized tools is a necessity. These should allow metadata to be extracted in a consistent, fast and sound way. Besides, metadata extraction must never manipulate the image and it needs to take into account possible departures from the Exif specification, including the insertion of the metadata in the image acquisition process by the makers, as well as any modification, whether malicious or not. This paper will show the multiple anomalies in the Exif specification we have found during our study, which can produce serious problems in classical tools for the extraction of image metadata, including crashes and wrong results, and even interoperability problems among different devices. We will also show some anomalies found in the operation of different well-known forensic tools.
C1 [Sandoval Orozco, Ana Lucila; Arenas Gonzalez, David Manuel; Javier Garcia, Luis] UCM, Dept Software Engn & Artificial Intelligence DISI, Sch Comp Sci, GASS, Madrid 28040, Spain.
   [Hernandez-Castro, Julio] Univ Kent, Sch Comp, Canterbury CT2 7NF, Kent, England.
C3 Complutense University of Madrid; University of Kent
RP Garcia, LJ (corresponding author), UCM, Dept Software Engn & Artificial Intelligence DISI, Sch Comp Sci, GASS, Off 431,Calle Prof Jose Garcia Santesmases S-N, Madrid 28040, Spain.
EM asandoval@fdi.ucm.es; darenas@fdi.ucm.es; javiergv@fdi.ucm.es;
   J.C.Hernandez-Castro@kent.ac.uk
RI Garcia Villalba, Luis Javier/N-4631-2014; Sandoval Orozco, Ana
   Lucila/H-4148-2012
OI Garcia Villalba, Luis Javier/0000-0001-7573-6272; Hernandez-Castro,
   Julio C./0000-0002-6432-5328; Sandoval Orozco, Ana
   Lucila/0000-0002-2846-9017
CR Avcibas I, 2003, IEEE T IMAGE PROCESS, V12, P221, DOI 10.1109/TIP.2002.807363
   Bayram S, 2005, ICIP 2005, P1
   Bayram S, 2006, P WG 119 INT DIG FOR
   Boutell M, 2005, PATTERN RECOGN, V38, P935, DOI 10.1016/j.patcog.2004.11.013
   Boutell M, 2004, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2004.1333918
   Chamlawi R, 2010, INFORM SCIENCES, V180, P4909, DOI 10.1016/j.ins.2010.08.039
   Chang CC, 2002, INFORM SCIENCES, V141, P123, DOI 10.1016/S0020-0255(01)00194-3
   Choi KS, 2006, PROC SPIE, V6069, DOI 10.1117/12.649775
   Committee S, 2010, EXCHANGEABLE IMAGE F
   Geradts ZJ, 2000, PROC SPIE, V4232, P505, DOI 10.1117/12.417569
   Gloe T., 2007, Proceedings of the 15th international conference on Multimedia, P78, DOI [10.1145/1291233.1291252, DOI 10.1145/1291233.1291252]
   Hamilton E, 2004, INTERCHANGE, V81, P467
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Lyons M, 2001, EXIF INFORM READER
   Raskin A, 2007, EXIF VIEWER 1 81
   Romero NL, 2008, LIBR HI TECH, V26, P302, DOI 10.1108/07378830810880388
   Tesic J, 2005, IEEE MULTIMEDIA, V12, P86, DOI 10.1109/MMUL.2005.50
   Thing VLL, 2010, DIGIT INVEST, V7, pS74, DOI 10.1016/j.diin.2010.05.010
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Van Lanh T, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P16
   Wandel M, 2010, EXIF JPEG HEADER MAN
NR 21
TC 7
Z9 10
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2015
VL 74
IS 13
BP 4735
EP 4763
DI 10.1007/s11042-013-1837-6
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA CL7DG
UT WOS:000357130400014
DA 2024-07-18
ER

PT J
AU Eg, R
   Griwodz, C
   Halvorsen, P
   Behne, D
AF Eg, Ragnhild
   Griwodz, Carsten
   Halvorsen, Pal
   Behne, Dawn
TI Audiovisual robustness: exploring perceptual tolerance to asynchrony and
   quality distortion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audiovisual asynchrony; Temporal integration; Perceived quality;
   Multimedia streaming; Active adaptation
ID TEMPORAL-ORDER; SYNCHRONY PERCEPTION; SPEECH; RECOGNITION; HEARING;
   VISION; MUSIC; CUES
AB Rules-of-thumb for noticeable and detrimental asynchrony between audio and video streams have long since been established from the contributions of several studies. Although these studies share similar findings, none have made any discernible assumptions regarding audio and video quality. Considering the use of active adaptation in present and upcoming streaming systems, audio and video will continue to be delivered in separate streams; consequently, the assumption that the rules-of-thumb hold independent of quality needs to be challenged. To put this assumption to the test, we focus on the detection, not the appraisal, of asynchrony at different levels of distortion. Cognitive psychologists use the term temporal integration to describe the failure to detect asynchrony. The term refers to a perceptual process with an inherent buffer for short asynchronies, where corresponding auditory and visual signals are merged into one experience. Accordingly, this paper discusses relevant causes and concerns with regards to asynchrony, it introduces research on audiovisual perception, and it moves on to explore the impact of audio and video quality on the temporal integration of different audiovisual events. Three content types are explored, speech from a news broadcast, music presented by a drummer, and physical action in the form of a chess game. Within these contexts, we found temporal integration to be very robust to quality discrepancies between the two modalities. In fact, asynchrony detection thresholds varied considerably more between the different content than they did between distortion levels. Nevertheless, our findings indicate that the assumption concerning the independence of asynchrony and audiovisual quality may have to be reconsidered.
C1 [Eg, Ragnhild] Univ Oslo, Dept Psychol, N-0316 Oslo, Norway.
   [Eg, Ragnhild] Simula Res Lab, Media Dept, Oslo, Norway.
   [Griwodz, Carsten; Halvorsen, Pal] Univ Oslo, Dept Informat, N-0316 Oslo, Norway.
   [Griwodz, Carsten; Halvorsen, Pal] Simula Res Lab, Oslo, Norway.
   [Behne, Dawn] Norwegian Univ Sci & Technol, Dept Psychol, NTNU Speech Lab, Oslo, Norway.
C3 University of Oslo; University of Oslo; Norwegian University of Science
   & Technology (NTNU)
RP Eg, R (corresponding author), Univ Oslo, Dept Psychol, N-0316 Oslo, Norway.
EM rage@simula.no; griff@simula.no; paalh@simula.no; dawn.behne@svt.ntnu.no
RI Eg, Ragnhild/AAQ-5857-2021
OI Eg, Ragnhild/0000-0002-9550-0424; /0000-0002-2263-4480; Halvorsen,
   Pal/0000-0003-2073-7029
FU Research Council of Norway through the VERDIKT programme [193034]
FX The authors would like to thank the editors and the anonymous reviewers
   for their helpful comments and suggestions. Thanks are also extended to
   Dr. Alexander Eichhorn and Dr. Knut Inge Fostervold, for their feedback
   along the way, to Camilla Hellum Foyn for her assistance, and to all the
   participants who volunteered their time. This work was completed as a
   contribution to Perceval, project number 193034, and was funded by the
   Research Council of Norway through the VERDIKT programme.
CR Alm M, 2013, J ACOUST SOC AM, V134, P3001, DOI 10.1121/1.4820798
   [Anonymous], 2012, J. Eng. Sci. Technol. Rev.
   Arrighi R, 2006, J VISION, V6, P260, DOI 10.1167/6.3.6
   Bolognini N, 2005, EXP BRAIN RES, V160, P273, DOI 10.1007/s00221-004-2005-z
   Burton AM, 1999, PSYCHOL SCI, V10, P243, DOI 10.1111/1467-9280.00144
   Conrey B, 2006, J ACOUST SOC AM, V119, P4065, DOI 10.1121/1.2195091
   Cook LA, 2011, ATTEN PERCEPT PSYCHO, V73, P2286, DOI 10.3758/s13414-011-0185-8
   Davies M, 2012, P 10 INT C ADV MOB C, P109
   DIXON NF, 1980, PERCEPTION, V9, P719, DOI 10.1068/p090719
   DODD B, 1977, PERCEPTION, V6, P31, DOI 10.1068/p060031
   Eg R., 2009, INTERSPEECH, P2903
   Eldridge M, 2010, EUR J COGN PSYCHOL, V22, P1078, DOI 10.1080/09541440903316136
   Grant K. W., 2003, INT C AUD VIS SPEECH, P31
   Grant KW, 2000, J ACOUST SOC AM, V108, P1197, DOI 10.1121/1.1288668
   Gulliver SR, 2006, ACM T MULTIM COMPUT, V2, P241, DOI 10.1145/1201730.1201731
   Howell D.C., 1997, STAT METHODS PSYCHOL, VForth
   ITU-T, 1998, Recommendation P.911
   JACK CE, 1973, PERCEPT MOTOR SKILL, V37, P967, DOI 10.2466/pms.1973.37.3.967
   Knoche H., 2005, CHI 05 EXTENDED ABST, P1553
   Krasic C., 2001, Interactive Distributed Multimedia Systems. 8th International Workshop, IDMS 2001. Proceedings (Lecture Notes in Computer Science Vol.2158), P213
   Lewkowicz DJ, 1996, J EXP PSYCHOL HUMAN, V22, P1094, DOI 10.1037/0096-1523.22.5.1094
   Li L., 1994, Multimedia Systems, V1, P154
   Liu CM, 2008, IEEE T AUDIO SPEECH, V16, P681, DOI 10.1109/TASL.2008.918979
   MacDonald J, 2000, PERCEPTION, V29, P1155, DOI 10.1068/p3020
   MARCEL AJ, 1983, COGNITIVE PSYCHOL, V15, P197, DOI 10.1016/0010-0285(83)90009-9
   MCGRATH M, 1985, J ACOUST SOC AM, V77, P678, DOI 10.1121/1.392336
   Miner N, 1998, PRESENCE-TELEOP VIRT, V7, P396, DOI 10.1162/105474698565802
   Navarra J, 2010, BRAIN RES, V1323, P84, DOI 10.1016/j.brainres.2010.01.059
   Petlund Andreas, 2008, 2008 33rd IEEE Conference on Local Computer Networks (LCN 2008), P176, DOI 10.1109/LCN.2008.4664167
   Pierce CA, 2004, EDUC PSYCHOL MEAS, V64, P916, DOI 10.1177/0013164404264848
   Ross LA, 2007, CEREB CORTEX, V17, P1147, DOI 10.1093/cercor/bhl024
   Santangelo V, 2007, J EXP PSYCHOL HUMAN, V33, P1311, DOI 10.1037/0096-1523.33.6.1311
   Steinmetz R, 1996, IEEE J SEL AREA COMM, V14, P61, DOI 10.1109/49.481694
   Stockhammer T., 2011, P 2 ANN ACM C MULTIM, P133
   van Eijk RLJ, 2008, PERCEPT PSYCHOPHYS, V70, P955, DOI 10.3758/PP.70.6.955
   van Wassenhove V, 2007, NEUROPSYCHOLOGIA, V45, P598, DOI 10.1016/j.neuropsychologia.2006.01.001
   Vatakis A, 2006, NEUROSCI LETT, V393, P40, DOI 10.1016/j.neulet.2005.09.032
   Vatakis A, 2008, EXP BRAIN RES, V185, P521, DOI 10.1007/s00221-007-1168-9
   Vatakis A, 2006, NEUROSCI LETT, V405, P132, DOI 10.1016/j.neulet.2006.06.041
   Vatakis A, 2006, BRAIN RES, V1111, P134, DOI 10.1016/j.brainres.2006.05.078
   Vatakis A, 2008, J VISION, V8, DOI 10.1167/8.9.14
   Vroomen J, 2010, ATTEN PERCEPT PSYCHO, V72, P871, DOI 10.3758/APP.72.4.871
   Wilson G. M., 2000, Affective Interactions. Towards a New Generation of Computer Interfaces (Lecture Notes in Artificial Intelligence Vol.1814), P9
   Wilson GM, 2000, BCS CONFERENCE S, P327
NR 44
TC 13
Z9 14
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 2
BP 345
EP 365
DI 10.1007/s11042-014-2136-6
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AZ8DP
UT WOS:000348445300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Xie, YX
   Zhang, XP
   Luan, XD
   Liu, L
   Zhang, X
AF Xie, Yuxiang
   Zhang, Xiao-Ping
   Luan, Xidao
   Liu, Li
   Zhang, Xin
TI A novel specific image scenes detection method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Scene detection; Feature extraction; Local invariant feature; SIFT
ID CLASSIFICATION
AB Automatic image scene detection is a crucial step for various tasks in computer vision. Current scene detection methods are often computationally expensive for use in real-time image classification. In this paper, a novel and efficient scene detection method based on local invariant features is presented. First, the SIFT feature detector and descriptor has been utilized to extract local image features since the SIFT descriptor has been proved to be an excellent local method that yields high quality features. However, the SIFT descriptor has been shown to produce high dimensional and redundant local features, which can create processing difficulty and computational burden in the successive classification stage. Therefore, two new feature selection strategies are proposed to reduce the number of SIFT keypoints and hence reduce the computational complexity. In both strategies, each image is represented by a single feature vector which assures the efficiency. Finally, a multi-classifier based on a support vector machine is applied to perform the scene detection task. Experimental results show that the proposed method can achieve accurate satisfactory classification results with significantly reduced computational complexity.
C1 [Xie, Yuxiang; Liu, Li; Zhang, Xin] Natl Univ Def Technol, Sci & Technol Informat Syst Engn Lab, Changsha 410073, Hunan, Peoples R China.
   [Zhang, Xiao-Ping] Ryerson Univ, Dept Elect & Comp Engn, CASPAL, Toronto, ON, Canada.
   [Luan, Xidao] Changsha Univ, Changsha 410003, Hunan, Peoples R China.
C3 National University of Defense Technology - China; Toronto Metropolitan
   University; Changsha University
RP Xie, YX (corresponding author), Natl Univ Def Technol, Sci & Technol Informat Syst Engn Lab, Changsha 410073, Hunan, Peoples R China.
EM xyx89@163.com; xzhang@ee.ryerson.ca
RI Zhang, Xiao-Ping (Steven)/B-1436-2016
OI Zhang, Xiao-Ping (Steven)/0000-0001-5241-0069
FU National Natural Science Foundation of China [61201337]; Changsha
   Municipal Science and Technology Project [K1205045-11]
FX This work has been supported by the National Natural Science Foundation
   of China under contract No. 61201337 and by Changsha Municipal Science
   and Technology Project under contract No. K1205045-11. The authors are
   grateful to the anonymous reviewers for valuable comments.
CR [Anonymous], 2007, Computer Vision
   [Anonymous], 2007, MIR
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Horster E., 2007, IEEE C COMP VIS PATT, P1
   Jin B, 2012, IEEE SIGNAL PROC LET, V19, P151, DOI 10.1109/LSP.2012.2184091
   Keller Mikaela., 2004, LEARNING METHODS TEX
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MURPHY K, 2003, ADV NEURAL INF PROCE, V16
   Nikhil R., 2008, 2008 IEEE C COMP VIS, P1
   Qin JZ, 2012, PATTERN RECOGN, V45, P1671, DOI 10.1016/j.patcog.2011.09.027
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Wan Hua-Lin, 2003, Journal of Software, V14, P1891
   Zeng P, 2007, P SPIE 5 INT S MULT, P1
NR 23
TC 0
Z9 0
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2015
VL 74
IS 1
BP 105
EP 122
DI 10.1007/s11042-013-1496-7
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ6UP
UT WOS:000348356300007
DA 2024-07-18
ER

PT J
AU Labayen, M
   Olaizola, IG
   Aginako, N
   Florez, J
AF Labayen, Mikel
   Olaizola, Igor G.
   Aginako, Naiara
   Florez, Julian
TI Accurate ball trajectory tracking and 3D visualization for
   computer-assisted sports broadcast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer graphics; Camera calibration; Tracking; Segmentation; Sports
   events broadcast
AB The application of computer-aided controversial plays resolution in sport events significantly benefits organizers, referees and audience. Nowadays, especially in ball sports, very accurate technological solutions can be found. Themain drawback of these systems is the need of complex and expensive hardware which makes them not affordable for less-known regional/traditional sports events. The lack of competitive systems with reduced hardware/software complexity and requirements motivates this research. Visual Analytics technologies permit system detecting the ball trajectory, solving with precision possible controversial plays. Ball is extracted from the video scene exploiting its shape features and velocity vector properties. Afterwards, its relative position to border line is calculated based on polynomial approximations. In order to enhance user visual experience, real-time rendering technologies are introduced to obtain virtual 3D reconstruction in quasi real-time. Comparing to other set ups, the main contribution of this work lays on the utilization of an unique camera per border line to extract 3D bounce point information. In addition, the system has no camera location/orientation limit, provided that line view is not occluded. Testing of the system has been done in real world scenarios, comparing the system output with referees' judgment. Visual results of the system have been broadcasted during Basque Pelota matches.
C1 [Labayen, Mikel; Olaizola, Igor G.; Aginako, Naiara; Florez, Julian] Vicomtech Ik4 Res Alliance, Dept Digital Televis & Multimedia Serv, San Sebastian, Spain.
RP Aginako, N (corresponding author), Vicomtech Ik4 Res Alliance, Dept Digital Televis & Multimedia Serv, San Sebastian, Spain.
EM mlabayen@vicomtech.org; iolaizola@vicomtech.org; naginako@vicomtech.org;
   jflorez@vicomtech.org
RI Olaizola, Igor García/C-2957-2009
OI Olaizola, Igor García/0000-0002-9965-2038
FU SPRI17 (Society for Industrial Promotion and Restructuring of Basque
   Country)
FX The authors are also grateful for the collaboration offered by
   ASPE<SUP>16</SUP> (ASPE Jugadores de Pelota) in providing access to its
   professional pelota player training sessions and in advising in game
   rule issues as well as for the financial support offered by research
   project programs of the SPRI<SUP>17</SUP> (Society for Industrial
   Promotion and Restructuring of Basque Country).
CR Ahn SungJoon., 2004, Lecture Notes in Computer Science
   Cavallaro R, 1997, IEEE COMPUT GRAPH, V17, P6, DOI 10.1109/38.574652
   Erik Cueva DZ, 2005, KALMAN FILTER VISION
   Haines E., 2002, Real-time rendering
   Innovations HE, 2013, HAWK EYE ACCURACY BE
   Inurrategi Maider Laka, 2008, 2008 3DTV-Conference: The True Vision - Capture, Transmission and Display of 3D Video, P405, DOI 10.1109/3DTV.2008.4547894
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Miller FP, 2009, ATSC STANDARDS MPEG
   Naidoo W., 2006, PROC 2006 ANN RES C, P51, DOI DOI 10.1145/1216262.1216268
   Owens N., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P182, DOI 10.1049/cp:20030517
   Pingali G, 2000, INT C PATT RECOG, P152, DOI 10.1109/ICPR.2000.902885
   Richardson I.E.G., 2002, Video Codec Design: Developing Image and Video Compression Systems
   Richardson IainE.G., 2003, The H.264 Advanced Video Compression Standard
   Sullivan GJ, 2004, P SOC PHOTO-OPT INS, V5558, P454, DOI 10.1117/12.564457
   Wu W, 2010, TENNIS TOUCHING POIN
   Yan F., 2005, BRIT MACHINE VISION, P619
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu X., 2003, PROC 11 ACM INT C MU, P11
   Yu XG, 2006, IEEE T MULTIMEDIA, V8, P1164, DOI 10.1109/TMM.2006.884621
NR 19
TC 6
Z9 6
U1 1
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 1819
EP 1842
DI 10.1007/s11042-013-1558-x
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200032
DA 2024-07-18
ER

PT J
AU Xiao, ZM
   Qi, XJ
AF Xiao, Zhongmiao
   Qi, Xiaojun
TI Complementary relevance feedback-based content-based image retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-based image retrieval; Relevance feedback model; Semantic
   features; Long-term learning
AB We propose a complementary relevance feedback-based content-based image retrieval (CBIR) system. This system exploits the synergism between short-term and long-term learning techniques to improve the retrieval performance. Specifically, we construct an adaptive semantic repository in long-term learning to store retrieval patterns of historical query sessions. We then extract high-level semantic features from the semantic repository and seamlessly integrate low-level visual features and high-level semantic features in short-term learning to effectively represent the query in a single retrieval session. The high-level semantic features are dynamically updated based on users' query concept and therefore represent the image's semantic concept more accurately. Our extensive experimental results demonstrate that the proposed system outperforms its seven state-of-the-art peer systems in terms of retrieval precision and storage space on a large scale imagery database.
C1 [Xiao, Zhongmiao; Qi, Xiaojun] Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
C3 Utah System of Higher Education; Utah State University
RP Qi, XJ (corresponding author), Utah State Univ, Dept Comp Sci, Logan, UT 84322 USA.
EM zhongmiao.xiao@aggiemail.usu.edu; Xiaojun.Qi@usu.edu
FU National Science Foundation [0850825]; Div Of Information & Intelligent
   Systems; Direct For Computer & Info Scie & Enginr [0850825] Funding
   Source: National Science Foundation
FX This material is based upon work supported in part by the National
   Science Foundation under Grant No. 0850825.
CR Aksoy S, 2001, PATTERN RECOGN LETT, V22, P563, DOI 10.1016/S0167-8655(00)00112-4
   [Anonymous], 2009, P ACM INT C IM VID R
   Chang R., 2011, P IEEE INT C IM PROC, P2473
   Chang R, 2012, IEEE IMAGE PROC, P2401, DOI 10.1109/ICIP.2012.6467381
   Chen Y., 2006, P ACM INT C MULT, DOI [10.1145/1291233.1291300, DOI 10.1145/1291233.1291300]
   Cheng H, 2008, P ACM C IM VID RETR, P27
   Chua T.-S., 2009, P ACM INT C IM VID R, P1
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Fechser S, 2010, INT CONF ACOUST SPEE, P1246, DOI 10.1109/ICASSP.2010.5495405
   Han JW, 2005, IEEE T IMAGE PROCESS, V14, P511, DOI 10.1109/TIP.2004.841205
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   Hoi SCH, 2006, IEEE T KNOWL DATA EN, V18, P509, DOI 10.1109/TKDE.2006.1599389
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu Y, 2009, J VIS COMMUN IMAGE R, V20, P157, DOI 10.1016/j.jvcir.2008.11.006
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Qi X, 2007, P 4 INT C IM AN REC, P637
   Qi XJ, 2011, INT J INTELL SYST, V26, P1153, DOI 10.1002/int.20503
   Shah-Hosseini A., 2006, P 14 ACM INT C MULT, P703
   Thomee B, 2010, THESIS LEIDEN U NETH
   XIAO ZM, 2012, 2012 IEEE INT C AC, P1033
   Yin PY, 2008, IEEE T KNOWL DATA EN, V20, P352, DOI 10.1109/TKDE.2007.190697
   Yoshizawa T., 2004, P 6 ACM SIGMM INT WO, DOI [10.1145/1026711.1026739, DOI 10.1145/1026711.1026739]
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 23
TC 5
Z9 5
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2014
VL 73
IS 3
BP 2157
EP 2177
DI 10.1007/s11042-013-1693-4
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AT2EH
UT WOS:000344744200047
DA 2024-07-18
ER

PT J
AU Jeong, HY
   Yeo, SS
AF Jeong, Hwa-Young
   Yeo, Sang-Soo
TI The quality model for e-learning system with multimedia contents: a
   pairwise comparison approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi criteria decision making; Quality model; Pairwise comparison;
   Quality evaluation; E-learning system; Mulimedia learning contents
ID SUCCESS MODEL; SATISFACTION; PERFORMANCE; USABILITY; FRAMEWORK; OUTCOMES
AB E-learning system used various multimedia types or learning materials to support the learners a method to get advanced learning effect. Moreover, many education scholars have pointed out that emotions are directly related to and affect learning performance. Therefore, it is very important to know what is the most important or influence factor to learner in online education. However, assessing the effects of multimedia materials in e-learning emotions has never been investigated. The aim of this paper is to classify the criteria for multimedia based learning contents and make a quality model corresponding multimedia factors. For this purpose, this research extracts 9 criteria from the past studies. To evaluate the quality model, pairwise comparison method is used.
C1 [Jeong, Hwa-Young] Kyung Hee Univ, Humanitas Coll, Seoul, South Korea.
   [Yeo, Sang-Soo] Mokwon Univ, Div Comp Engn, Taejon, South Korea.
C3 Kyung Hee University; Mokwon University
RP Yeo, SS (corresponding author), Mokwon Univ, Div Comp Engn, Taejon, South Korea.
EM hyjeong@khu.ac.kr; sangsooyeo@gmail.com
RI Yeo, Sang-Soo/D-3216-2016; Yeo, Sang-Soo/AAD-6176-2020
OI Yeo, Sang-Soo/0000-0002-0224-0150; Jeong, Hwa-Young/0000-0002-5017-934X
FU National Research Foundation of Korea(NRF) - Ministry of Education,
   Science and Technology [2011-0014394]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology(2011-0014394).
CR Alkhattabi M, 2011, COMPUT HUM BEHAV, V27, P862, DOI 10.1016/j.chb.2010.11.011
   Andreou AS, 2007, INFORM SOFTWARE TECH, V49, P122, DOI 10.1016/j.infsof.2006.03.007
   [Anonymous], 1993, HDB EMOTIONS
   BAHTIJAREVICSIB.F, 1999, HUMAN RESOURCE MANAG, P717
   Bany M, 2005, VIDEO SERVICES  1205
   Bartsch RA, 2003, COMPUT EDUC, V41, P77, DOI 10.1016/S0360-1315(03)00027-7
   Bozóki S, 2010, MATH COMPUT MODEL, V52, P318, DOI 10.1016/j.mcm.2010.02.047
   Brinck T., 2002, DESIGNING WEB SITES
   Chang YC, 2009, COMPUT EDUC, V53, P273, DOI 10.1016/j.compedu.2009.02.008
   ChanLin L.J., 1998, J INSTR PSYCHOL, V25, P166
   Chao RJ, 2009, EXPERT SYST APPL, V36, P10657, DOI 10.1016/j.eswa.2009.02.047
   Chen CM, 2011, LIBR INFORM SCI RES, V33, P244, DOI 10.1016/j.lisr.2010.09.010
   Chen HJ, 2010, COMPUT EDUC, V55, P1628, DOI 10.1016/j.compedu.2010.07.005
   Choo EU, 2004, COMPUT OPER RES, V31, P893, DOI 10.1016/S0305-0548(03)00042-X
   CLARK RE, 1985, ECTJ-EDUC COMMUN TEC, V33, P249
   Cukusic M, 2010, COMPUT EDUC, V55, P554, DOI 10.1016/j.compedu.2010.02.017
   DeLone WH, 2003, J MANAGE INFORM SYST, V19, P9, DOI 10.1080/07421222.2003.11045748
   Desmet P., 2002, The Design Journal, V6, P2
   Elliott MA, 2010, RELIAB ENG SYST SAFE, V95, P750, DOI 10.1016/j.ress.2010.02.013
   González-Pachón J, 2004, EUR J OPER RES, V158, P351, DOI 10.1016/j.ejor.2003.06.009
   Tzeng GH, 2007, EXPERT SYST APPL, V32, P1028, DOI 10.1016/j.eswa.2006.02.004
   Jeong HY, 2013, MULTIMED TOOLS APPL, V64, P491, DOI 10.1007/s11042-012-1026-z
   Jeong HY, 2013, MULTIMED TOOLS APPL, V63, P217, DOI 10.1007/s11042-012-1027-y
   Jeong HY, 2012, MULTIMED TOOLS APPL, V61, P225, DOI 10.1007/s11042-010-0708-7
   Lazarus R.S., 1991, EMOTION ADAPTATION
   Liaw SS, 2007, COMPUT EDUC, V49, P1066, DOI 10.1016/j.compedu.2006.01.001
   Lin HF, 2010, COMPUT EDUC, V54, P877, DOI 10.1016/j.compedu.2009.09.017
   Mackey TP, 2008, COMPUT EDUC, V50, P386, DOI 10.1016/j.compedu.2006.08.006
   MOUSAVI SY, 1995, J EDUC PSYCHOL, V87, P319, DOI 10.1037/0022-0663.87.2.319
   Nielsen Jakob, 2006, Designing Web Usability
   Ortony A., 1988, COGNITIVE STRUCTURE
   Osei-Bryson KM, 2006, EUR J OPER RES, V174, P234, DOI 10.1016/j.ejor.2005.01.061
   Ozkan S, 2009, COMPUT EDUC, V53, P1285, DOI 10.1016/j.compedu.2009.06.011
   Rosenberg M.J., 2001, E LEARNING STRATEGIE
   Rubin B, 2010, INTERNET HIGH EDUC, V13, P82, DOI 10.1016/j.iheduc.2009.10.008
   Saaty T.L., 2006, Fundamentals of Decision Making and Priority Theory with the Analytic Hierarchy Process Vol VI of the AHP series
   SAATY TL, 1984, MATH MODELLING, V5, P309, DOI 10.1016/0270-0255(84)90008-3
   SAATY TL, 1994, ANAL HIERARCHY PROCE, V6
   Shee DY, 2008, COMPUT EDUC, V50, P894, DOI 10.1016/j.compedu.2006.09.005
   Sun PC, 2007, COMPUT EDUC, V49, P662, DOI 10.1016/j.compedu.2005.11.016
   Um ER, 2007, P WORLD C ED MULT HY
   Vichuda K., 2001, International Journal of Human-Computer Studies, V54, P541
   Wang YS, 2003, INFORM MANAGE-AMSTER, V41, P75, DOI 10.1016/S0378-7206(03)00028-4
   Yengin I, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2011.01.021
NR 44
TC 16
Z9 18
U1 0
U2 38
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 887
EP 900
DI 10.1007/s11042-013-1445-5
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700016
DA 2024-07-18
ER

PT J
AU Ripolles, O
   Simó, JE
   Benet, G
   Vivó, R
AF Ripolles, Oscar
   Simo, Jose E.
   Benet, Gines
   Vivo, Roberto
TI Smart video sensors for 3D scene reconstruction of large infrastructures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Surveillance; Smart video sensors; Tracking; 3D reconstruction
AB This paper introduces a new 3D-based surveillance solution for large infrastructures. Our proposal is based on an accurate 3D reconstruction using the rich information obtained from a network of intelligent video-processing nodes. In this manner, if the scenario to cover is modeled in 3D with high precision, it will be possible to locate the detected objects in the virtual representation. Moreover, as an improvement over previous 2D solutions, having the possibility of modifying the view point enables the application to choose the perspective that better suits the current state of the scenario. In this sense, the contextualization of the events detected in a 3D environment can offer a much better understanding of what is happening in the real world and where it is exactly happening. Details of the video processing nodes are given, as well as of the 3D reconstruction tasks performed afterwards. The possibilities of such a system are described and the performance obtained is analyzed.
C1 [Ripolles, Oscar; Simo, Jose E.; Benet, Gines; Vivo, Roberto] Univ Politecn Valencia, Inst Univ Automat & Informat Ind, E-46071 Valencia, Spain.
C3 Universitat Politecnica de Valencia
RP Ripolles, O (corresponding author), Univ Politecn Valencia, Inst Univ Automat & Informat Ind, Camino Vera S-N, E-46071 Valencia, Spain.
EM oripolles@ai2.upv.es; jsimo@disca.upv.es; gbenet@disca.upv.es;
   rvivo@dsic.upv.es
RI Benet, Gines/L-6535-2014; Vivó, Roberto/L-7436-2014; Simo,
   Jose/L-6969-2014
OI Benet, Gines/0000-0003-3856-5501; Simo, Jose/0000-0003-4677-7627;
   Ripolles, Oscar/0000-0002-5450-6758
FU ViCoMo project (ITEA2 project) - Spanish MICINN [IP08009,
   TSI-020400-2011-57]; Spanish Government [TIN2009-14103-C03-03,
   DPI2008-06737-C02-01/02, DPI 2011-28507-C02-02]; European FEDER funds
FX This work has been partially supported by the ViCoMo project (ITEA2
   project IP08009 funded by the Spanish MICINN with project
   TSI-020400-2011-57), the Spanish Government (TIN2009-14103-C03-03,
   DPI2008-06737-C02-01/02 and DPI 2011-28507-C02-02) and European FEDER
   funds.
CR Atienza V., 2008, International_Conference_on_Pattern Recognition, P1
   Chang F, 2003, PROC INT CONF DOC, P741
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Fleck S, 2006, C COMP VIS PATT REC, P118
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Javed O, 2008, AUTOMATED MULTICAMER
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Lloyd D.H., 1968, Visual Education, V21, P23
   Rieffel EG, 2007, IEEE INT C DISTR SMA
   Sánchez J, 2012, SENSORS-BASEL, V12, P1509, DOI 10.3390/s120201509
   Sebe I.O., 2003, IWVS 03 1 ACM SIGMM, P107
   SENSE Consortium, 2006, SMART EMB NETW SENS
   Vouzounaras G, 2014, MULTIMED TOOLS APPL, V70, P361, DOI 10.1007/s11042-011-0823-0
   Yan WQ, 2011, MULTIMED TOOLS APPL, V55, P443, DOI 10.1007/s11042-010-0560-9
   Zuniga M, 2006, P INT C VIS INF ENG, P26
NR 15
TC 4
Z9 5
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 2
BP 977
EP 993
DI 10.1007/s11042-012-1184-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AQ8MX
UT WOS:000343080700022
OA Green Published
DA 2024-07-18
ER

PT J
AU Xie, L
   Sun, NC
   Fan, B
AF Xie, Lei
   Sun, Naicai
   Fan, Bo
TI A statistical parametric approach to video-realistic text-driven talking
   avatar
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Taking avatar; Visual speech synthesis; Facial animation; Hidden Markov
   model; Active appearance model
ID SPEECH SYNTHESIS; FACES
AB This paper proposes a statistical parametric approach to video-realistic text-driven talking avatar. We follow the trajectory HMM approach where audio and visual speech are jointly modeled by HMMs and continuous audiovisual speech parameter trajectories are synthesized based on the maximum likelihood criterion. Previous trajectory HMM approaches only focus on mouth animation, which synthesizes simple geometric mouth shapes or video-realistic effects of the lip motion. Our approach uses trajectory HMM to generate visual parameters of the lower face and it realizes video-realistic animation of the whole face. Specifically, we use active appearance model (AAM) to model the visual speech, which offers a convenient and compact statistical model of both the shape and the appearance variations of the face. To realize video-realistic effects with high fidelity, we use Poisson image editing technique to stitch the synthesized lower-face image to a whole face image seamlessly. Objective and subjective experiments show that the proposed approach can produce natural facial animation.
C1 [Xie, Lei; Sun, Naicai; Fan, Bo] Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University
RP Xie, L (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Xian 710072, Peoples R China.
EM xielei21st@gmail.com
RI Xie, Lei/JWO-8567-2024
FU National Natural Science Foundation of China [61175018]; Natural Science
   Basic Research Plan of Shaanxi Province [2011JM8009]; Fok Ying Tung
   Education Foundation [131059]
FX This work is supported by the National Natural Science Foundation of
   China (61175018), the Natural Science Basic Research Plan of Shaanxi
   Province (2011JM8009) and the Fok Ying Tung Education Foundation
   (131059).
CR [Anonymous], INTERSPEECH
   [Anonymous], SPEECH TECHNOL
   [Anonymous], TMH QPSR
   [Anonymous], P WORKSH VIS VID GRA
   [Anonymous], HEARING EYE PSYCHOL
   [Anonymous], EUROSPEECH
   [Anonymous], ISSUES VISUAL AUDIO
   [Anonymous], P INT
   [Anonymous], P INT
   [Anonymous], INTERSPEECH
   [Anonymous], 2008, DATA DRIVEN 3D FACIA
   [Anonymous], AVSP
   [Anonymous], SIGGRAPH
   Berger MA, 2011, IEEE COMPUT GRAPH, V31, P80, DOI 10.1109/MCG.2011.71
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Brand M, 1999, COMP GRAPH, P21, DOI 10.1145/311535.311537
   Chen TH, 2001, IEEE SIGNAL PROC MAG, V18, P9
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cosatto E, 2003, P IEEE, V91, P1406, DOI 10.1109/JPROC.2003.817141
   Ezzat T, 2000, INT J COMPUT VISION, V38, P45, DOI 10.1023/A:1008166717597
   Ezzat T, 2002, ACM T GRAPHIC, V21, P388, DOI 10.1145/566570.566594
   Fagel S, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/826091
   Fu SL, 2005, IEEE T MULTIMEDIA, V7, P243, DOI 10.1109/TMM.2005.843341
   Jia J, 2014, MULTIMED TOOLS APPL, V73, P439, DOI 10.1007/s11042-013-1604-8
   Jia J, 2011, IEEE T AUDIO SPEECH, V19, P570, DOI 10.1109/TASL.2010.2052246
   Kessentini Y, 2010, PATTERN RECOGN LETT, V31, P60, DOI 10.1016/j.patrec.2009.08.009
   Kyoung Ho Choi, 1999, 1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451), P175, DOI 10.1109/MMSP.1999.793816
   Liu K, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/174192
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Meng FB, 2014, MULTIMED TOOLS APPL, V73, P463, DOI 10.1007/s11042-013-1601-y
   Ostermann J, 2004, INT C PATT RECOG, P826, DOI 10.1109/ICPR.2004.1334656
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Salvi G, 2009, EURASIP J AUDIO SPEE, DOI 10.1155/2009/191940
   Tokuda K, 2000, INT CONF ACOUST SPEE, P1315, DOI 10.1109/ICASSP.2000.861820
   Wang L., 2011, INTERSPEECH, P3307
   Weise T., 2011, SIGGRAPH
   Wu ZY, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1802
   Xie L, 2007, IEEE T MULTIMEDIA, V9, P500, DOI 10.1109/TMM.2006.888009
   Yamagishi J, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P716
   Yamamoto E, 1998, SPEECH COMMUN, V26, P105, DOI 10.1016/S0167-6393(98)00054-5
   Zeng ZH, 2008, IEEE T MULTIMEDIA, V10, P570, DOI 10.1109/TMM.2008.921737
NR 44
TC 13
Z9 15
U1 0
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2014
VL 73
IS 1
BP 377
EP 396
DI 10.1007/s11042-013-1633-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AP9RX
UT WOS:000342418700019
DA 2024-07-18
ER

PT J
AU Chen, CN
   Chen, JZ
   Xia, T
   Ju, ZW
   Po, LM
AF Chen, Changnian
   Chen, Jiazhong
   Xia, Tao
   Ju, Zengwei
   Po, Lai-Man
TI An improved hybrid fast mode decision method for H.264/AVC intra coding
   with local information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intra prediction; Edge filter; Most probable mode; H.264/AVC
ID PREDICTION; ALGORITHM; INTRAPREDICTION; STANDARD
AB In this paper, an improved hybrid fast mode decision method for H.264/AVC intra coding is proposed, which is based on the analysis of edge filter and more efficient mode selection. In contrast to the conventional fast mode decision methods where multiple neighbor modes are determined by the same filter, a unique filter is applied to each directional mode to eliminate the correlation among neighbor modes. To reduce the complexity, the filters are only applied to the selected pixels that cover most of the block region. After that, the results along prediction residuals of these pixels are summed for fast mode decision. Moreover, local information is also taken into account through Most Probable Mode (MPM) from neighbor-coded blocks. Experimental results demonstrated that better coding performance is achieved as compared with well-known conventional fast mode decision algorithms for H.264/AVC intra coding.
C1 [Chen, Changnian; Chen, Jiazhong; Xia, Tao; Ju, Zengwei] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Po, Lai-Man] City Univ Hong Kong, Dept Elect Engn, Kowloon 999077, Hong Kong, Peoples R China.
C3 Huazhong University of Science & Technology; City University of Hong
   Kong
RP Chen, JZ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM hust_scs@yahoo.com.cn; eelmpo@cityu.edu.hk
OI Po, Lai Man/0000-0002-5185-1492
CR BJONTEGAARD G, 2001, ITUTQ6SG16 VCEG
   Chen CN, 2013, MULTIMED TOOLS APPL, V62, P719, DOI 10.1007/s11042-011-0862-6
   de-Frutos-López M, 2010, SIGNAL PROCESS-IMAGE, V25, P709, DOI 10.1016/j.image.2010.10.005
   Elyousfi A, 2013, SIGNAL IMAGE VIDEO P, V7, P53, DOI 10.1007/s11760-011-0232-x
   Hahm J, 2010, IEEE T CIRC SYST VID, V20, P310, DOI 10.1109/TCSVT.2009.2031378
   Huang YH, 2010, IEEE T CIRC SYST VID, V20, P1122, DOI 10.1109/TCSVT.2010.2057018
   Lee S, 2011, OPT ENG, V50, DOI 10.1117/1.3646749
   Marpe D, 2003, IEEE T CIRC SYST VID, V13, P620, DOI 10.1109/TCSVT.2003.815173
   Marpe D, 2004, SPIE, P129
   Milani S, 2011, IEEE T IMAGE PROCESS, V20, P121, DOI 10.1109/TIP.2010.2055572
   Pan F, 2005, IEEE T CIRC SYST VID, V15, P813, DOI 10.1109/TCSVT.2005.848356
   Su XQ, 2011, MULTIMED TOOLS APPL, V52, P65, DOI 10.1007/s11042-009-0452-z
   Tan T.K., 2008, Recommended simulation common conditions for coding efficiency experiments revision 3
   Tsai AC, 2008, IEEE T CIRC SYST VID, V18, P694, DOI 10.1109/TCSVT.2008.919113
   Wang JC, 2007, IEEE T CIRC SYST VID, V17, P1414, DOI 10.1109/TCSVT.2007.903786
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zeng HQ, 2010, IEEE T CIRC SYST VID, V20, P907, DOI 10.1109/TCSVT.2010.2045802
NR 17
TC 6
Z9 6
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 687
EP 704
DI 10.1007/s11042-013-1388-x
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800031
DA 2024-07-18
ER

PT J
AU Lee, S
   De Neve, W
   Ro, YM
AF Lee, Sihyoung
   De Neve, Wesley
   Ro, Yong Man
TI Visually weighted neighbor voting for image tag relevance learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Folksonomy; Neighbor voting; Tag relevance learning
AB The presence of non-relevant tags in image folksonomies hampers the effective organization and retrieval of user-contributed images. In this paper, we propose to learn the relevance of user-supplied tags by means of visually weighted neighbor voting, a variant of the popular baseline neighbor voting algorithm proposed by Li et al. (IEEE Trans Multimedia 11(7):1310-1322, 2009). To gain insight into the effectiveness of baseline and visually weighted neighbor voting, we qualitatively analyze the difference in tag relevance when using a different number of neighbors, for both tags relevant and tags not relevant to the content of a seed image. Our qualitative analysis shows that tag relevance values computed by means of visually weighted neighbor voting are more stable and representative than tag relevance values computed by means of baseline neighbor voting. This is quantitatively confirmed through extensive experimentation with MIRFLICKR-25000, studying the variation of tag relevance values as a function of the number of neighbors used (for both tags relevant and tags not relevant with respect to the content of a seed image), as well as the influence of tag relevance learning on the effectiveness of image tag refinement, tag-based image retrieval, and image tag recommendation.
C1 [Lee, Sihyoung; De Neve, Wesley; Ro, Yong Man] Korea Adv Inst Sci & Technol, Image & Video Syst Lab, Taejon 305701, South Korea.
   [De Neve, Wesley] Univ Ghent, Multimedia Lab, IMinds, B-9000 Ghent, Belgium.
C3 Korea Advanced Institute of Science & Technology (KAIST); Ghent
   University; IMEC
RP Ro, YM (corresponding author), Korea Adv Inst Sci & Technol, Image & Video Syst Lab, Taejon 305701, South Korea.
EM ijiat@kaist.ac.kr; wesley.deneve@kaist.ac.kr; ymro@ee.kaist.ac.kr
RI Ro, Yong Man/C-1731-2011; Ro, Yong Man/ABF-6817-2020; De Neve, Wesley
   Marcel/C-6480-2008
OI Ro, Yong Man/0000-0001-5306-6853; De Neve, Wesley
   Marcel/0000-0002-8190-3839
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education, Science and Technology
   [2012K2A1A2033054]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education, Science and Technology (2012K2A1A2033054).
CR Agrawal G., 2011, 2011 2nd International Conference on Computer and Communication Technology, P169, DOI 10.1109/ICCCT.2011.6075169
   [Anonymous], 2010, ACM INT C MULTIMEDIA
   [Anonymous], 2009, Proceedings of the 18th international conference on World wide web, DOI [10.1145/1526709.1526758, DOI 10.1145/1526709.1526758]
   [Anonymous], 2009, P ACM INT C IM VID R
   [Anonymous], OECD STUD PART WEB U
   Feng SH, 2011, NEUROCOMPUTING, V74, P3619, DOI 10.1016/j.neucom.2011.06.014
   Ferreira J, 2004, IADIS E SOC C, P1
   Flickr's Photostream, 2012, TREND REP SUMM 12
   Huiskes Mark J., 2008, Proceedings of the 1st ACM international conference on Multimedia information retrieval, P39, DOI DOI 10.1145/1460096.1460104
   Jin Y., 2005, P 13 ANN ACM INT C M, P706
   Kennedy L., 2009, Proc. Workshop on Web-scale Multimedia Corpus, P17
   Lee S, 2010, SIGNAL PROCESS-IMAGE, V25, P761, DOI 10.1016/j.image.2010.10.002
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li Xirong., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, CIVR '10, P10
   Lindstaedt S, 2009, MULTIMED TOOLS APPL, V42, P97, DOI 10.1007/s11042-008-0247-7
   Liu D, 2009, IEEE INT CON MULTI, P350, DOI 10.1109/ICME.2009.5202506
   Liu Dong., 2009, P 18 INT C WORLD WID, P351
   MANJUNATH BS, 2003, INTRO MPEG 7 MULTIME
   PlanetTech, 2012, FAC REV STAGG NEW ST
   Singh K, 2005, KEY ENG MATER, V277-279, P375, DOI 10.4028/www.scientific.net/KEM.277-279.375
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Vanderwal T., 2007, Folksonomy coinage and definition
   von Ahn Luis., 2004, CHI, DOI DOI 10.1145/985692.985733
   Wang X., 2011, Informatization Construction, P6
   Zhuang Jinfeng., 2011, WSDM, P625
NR 25
TC 18
Z9 19
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1363
EP 1386
DI 10.1007/s11042-013-1439-3
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300016
DA 2024-07-18
ER

PT J
AU Liu, YX
   Li, ZT
   Ma, XJ
   Liu, J
AF Liu, Yunxia
   Li, Zhitang
   Ma, Xiaojing
   Liu, Jian
TI A robust without intra-frame distortion drift data hiding algorithm
   based on H.264/AVC
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data hiding; H.264/advanced video coding (AVC); BCH code; Intra-frame
   distortion drift
ID WATERMARKING; VIDEO
AB This paper presents an improved robust data hiding algorithm based on BCH syndrome code (BCH code) technique and without distortion drift technique. The BCH code technique, which can correct the error bits caused by network transmission, packet loss, video-processing operations, various attacks, etc., encodes the embedded data by using BCH code before data hiding. The without distortion drift technique in this paper is that we exploit several paired-coefficients of a 4 x 4 discrete cosine transform (DCT) block to accumulate the embedding induced distortion, and the directions of intra-frame prediction are utilized to avert the distortion drift. It is proved analytically and shown experimentally that the new data hiding algorithm can get more robustness, effectively avert intra-frame distortion drift and get high visual quality.
C1 [Liu, Yunxia; Li, Zhitang; Ma, Xiaojing; Liu, Jian] Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
   [Liu, Yunxia] Zhoukou Normal Univ, Zhoukou, Peoples R China.
C3 Huazhong University of Science & Technology; Zhoukou Normal University
RP Liu, YX (corresponding author), Huazhong Univ Sci & Technol, Wuhan 430074, Peoples R China.
EM liuyunxia0110@hust.edu.cn
RI MA, XIAO/HHN-5611-2022; LIU, Qing Yu/IWV-1159-2023; wang,
   xiao/HZI-9156-2023
FU National Natural Science Foundation of China [61272407]; National High
   Technology Research and Development Program of China (863 Program)
   [2007AA01Z420]
FX This work is supported by the National Natural Science Foundation of
   China under Grant No. 61272407 and by the National High Technology
   Research and Development Program of China (863 Program) under Grant No.
   2007AA01Z420.
CR [Anonymous], 2003, H.264 and MPEG-4 video compression: video coding for next generation multimedia
   Gong X, 2008, IEEE INT SYM MULTIM, P649, DOI 10.1109/ISM.2008.16
   Kok Sheik Wong, 2009, IEEE Transactions on Circuits and Systems for Video Technology, V19, P1499, DOI 10.1109/TCSVT.2009.2022781
   Li X, 2014, MULTIMED TOOLS APPL, V68, P1051, DOI 10.1007/s11042-012-1112-2
   Luo WQ, 2011, MULTIMED TOOLS APPL, V52, P407, DOI 10.1007/s11042-009-0440-3
   Ma X., 2009, Proc. of the ACM SOSP Workshop on Power Aware Computing and Systems (Hot-Power), P1
   Ma XJ, 2010, IEEE T CIRC SYST VID, V20, P1320, DOI 10.1109/TCSVT.2010.2070950
   Ni ZC, 2008, IEEE T CIRC SYST VID, V18, P497, DOI 10.1109/TCSVT.2008.918761
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   Sachnev V, 2009, MM&SEC'09: PROCEEDINGS OF THE 2009 ACM SIGMM MULTIMEDIA AND SECURITY WORKSHOP, P131
   Schönfeld D, 2007, LECT NOTES COMPUT SC, V4567, P145
   Shi-Huang Chen, 2008, 2008 IEEE International Conference on Sensor Networks, Ubiquitous, and Trustworthy Computing (SUTC '08), P507
   Wang LY, 2012, IEEE MULTIMEDIA, V19, P70, DOI 10.1109/MMUL.2011.76
   Zhang RY, 2009, LECT NOTES COMPUT SC, V5806, P48, DOI 10.1007/978-3-642-04431-1_4
NR 14
TC 19
Z9 23
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 613
EP 636
DI 10.1007/s11042-013-1393-0
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800028
DA 2024-07-18
ER

PT J
AU Ma, B
   Wang, YH
   Li, CL
   Zhang, ZX
   Huang, D
AF Ma, Bin
   Wang, Yunhong
   Li, Chunlei
   Zhang, Zhaoxiang
   Huang, Di
TI Secure multimodal biometric authentication with wavelet quantization
   based fingerprint watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Biometrics; Digital watermarking; DWT; Dither modulation
ID IMAGE WATERMARKING; FACE-RECOGNITION; SIGNIFICANT DIFFERENCE; ENHANCING
   SECURITY; ROBUST; OWNERSHIP
AB As malicious attacks greatly threaten the security and reliability of biometric systems, ensuring the authenticity of biometric data is becoming increasingly important. In this paper we propose a watermarking-based two-stage authentication framework to address this problem. During data collection, face features are embedded into a fingerprint image of the same individual as data credibility token and secondary authentication source. At the first stage of authentication, the credibility of input data is established by checking the validness of extracted patterns. Due to the specific characteristics of face watermarks, the face detection based classification strategies are introduced for reliable watermark verification instead of conventional correlation based watermark detection. If authentic, the face patterns can further serve as supplemental identity information to facilitate subsequential biometric authentication. In this framework, one critical issue is to guarantee the robustness and capacity of watermark while preserving the discriminating features of host fingerprints. Hence a wavelet quantization based watermarking approach is proposed to adaptively distribute watermark energy on significant DWT coefficients of fingerprint images. Experimental results which evaluate both watermarking and biometric authentication performance demonstrate the effectiveness of this work.
C1 [Ma, Bin; Wang, Yunhong; Zhang, Zhaoxiang; Huang, Di] Beihang Univ, Intelligent Recognit & Image Proc Lab IRIP, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
   [Li, Chunlei] Zhongyuan Univ Technol, Sch Elect & Informat Engn, Zhengzhou 450007, Peoples R China.
C3 Beihang University; Zhongyuan University of Technology
RP Zhang, ZX (corresponding author), Beihang Univ, Intelligent Recognit & Image Proc Lab IRIP, Beijing Key Lab Digital Media, Sch Comp Sci & Engn, Beijing 100191, Peoples R China.
EM zxzhang@buaa.edu.cn
RI Huang, Di/JBJ-3541-2023
OI Huang, Di/0000-0001-7877-7301
FU National Basic Research Program of China [2010CB327902]; National
   Natural Science Foundation of China [60873158, 61005016, 61061130560];
   Fundamental Research Funds for the Central Universities
FX This work is funded by the National Basic Research Program of China (No.
   2010CB327902), the National Natural Science Foundation of China (No.
   60873158, No. 61005016, No. 61061130560) and the Fundamental Research
   Funds for the Central Universities.
CR [Anonymous], PATTERN RECOGNIT SUP
   Araque JL, 2002, INT C PATT RECOG, P422, DOI 10.1109/ICPR.2002.1048329
   Asif MS, 2010, IEEE J-STSP, V4, P421, DOI 10.1109/JSTSP.2009.2039174
   Bin Ma, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1277, DOI 10.1109/ICPR.2010.318
   Bradley J. N., 1994, 1994 IEEE International Symposium on Circuits and Systems (Cat. No.94CH3435-5), P205, DOI 10.1109/ISCAS.1994.409142
   Candes EJ, 2005, IEEE T INFORM THEORY, V51, P4203, DOI 10.1109/TIT.2005.858979
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Feng JJ, 2011, IEEE T PATTERN ANAL, V33, P209, DOI 10.1109/TPAMI.2010.77
   Gunsel B, 2002, PATTERN RECOGN, V35, P2739, DOI 10.1016/S0031-3203(01)00250-3
   Guo HP, 2005, MULTIMED TOOLS APPL, V27, P323, DOI 10.1007/s11042-005-3812-3
   Hammerle-Uhl Jutta, 2011, Information Hiding. 13th International Conference, IH 2011. Revised Selected Papers, P238, DOI 10.1007/978-3-642-24178-9_17
   He HJ, 2011, MULTIMED TOOLS APPL, V52, P307, DOI 10.1007/s11042-010-0474-6
   Jain A. K., 2005, P EUSIPCO 05 EUR SIG, P469
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/579416
   Kim WG, 2009, SIGNAL PROCESS, V89, P2385, DOI 10.1016/j.sigpro.2009.04.014
   Klare Brendan., 2010, Fourth IEEE International Conference on Biometrics: Theory Applications and Systems (BTAS). IEEE, P1, DOI DOI 10.1109/BTAS.2010.5634533
   Li CL, 2013, MULTIMED TOOLS APPL, V64, P757, DOI 10.1007/s11042-011-0974-z
   Lin WH, 2008, IEEE T MULTIMEDIA, V10, P746, DOI 10.1109/TMM.2008.922795
   Ma B, 2012, P INT C PATT REC
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maiorana E, 2007, PROC SPIE, V6579, DOI 10.1117/12.718673
   Meerwald P, 2009, IEEE T MULTIMEDIA, V11, P1037, DOI 10.1109/TMM.2009.2021793
   Neurotechnology, 2010, VER SOFTW
   Noore A, 2007, FORENSIC SCI INT, V169, P188, DOI 10.1016/j.forsciint.2006.08.019
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Sae-Bae N., 2012, Proceedings of the 2012 ACM Annual Conference on Human Factors in Computing Systems, P977, DOI DOI 10.1145/2207676.2208543
   Schneier B, 1999, COMMUN ACM, V42, P136, DOI 10.1145/310930.310988
   Schouten B, 2008, LECT NOTES COMPUT SC, V5372, P228, DOI 10.1007/978-3-540-89991-4_24
   Swaminathan A, 2006, IEEE T INF FOREN SEC, V1, P215, DOI 10.1109/TIFS.2006.873601
   Vatavu Radu-Daniel., 2012, Proceedings of the Designing Interactive Systems Conference, P328, DOI DOI 10.1145/2317956.2318006
   Vatsa M, 2006, IEICE ELECTRON EXPR, V3, P23, DOI 10.1587/elex.3.23
   Vatsa M, 2005, IEICE ELECTRON EXPR, V2, P362, DOI 10.1587/elex.2.362
   Vatsa M, 2009, IMAGE VISION COMPUT, V27, P293, DOI 10.1016/j.imavis.2007.05.003
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weng L, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P879
   Wong PW, 2001, IEEE T IMAGE PROCESS, V10, P1593, DOI 10.1109/83.951543
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Zhang JS, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P939, DOI 10.1109/ICME.2004.1394356
NR 41
TC 12
Z9 12
U1 0
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 1
BP 637
EP 666
DI 10.1007/s11042-013-1372-5
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IF
UT WOS:000339889800029
DA 2024-07-18
ER

PT J
AU Wang, XY
   Wang, CP
   Wang, AL
   Yang, HY
AF Wang, Xiang-yang
   Wang, Chun-peng
   Wang, Ai-long
   Yang, Hong-ying
TI SVM correction based geometrically invariant digital watermarking
   algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image watermarking; Geometric distortion; Image correction; Support
   vector machine; Pseudo-Zernike moments; Significant bitplane
ID HUMAN VISUAL-SYSTEM; IMAGE WATERMARKING; DESYNCHRONIZATION; RESILIENT;
   MOMENTS; SCHEME
AB Geometric distortion is known as one of the most difficult attacks to resist, for it can desynchronize the location of the watermark and hence causes incorrect watermark detection. It is a challenging work to design a robust image watermarking scheme against geometric distortions. Based on the Support Vector Machine (SVM) geometric distortions correction, we propose a new image watermarking algorithm with good visual quality and reasonable resistance toward geometric distortions in this paper. Firstly, the significant bitplane image is extracted from original host, and DWT is performed on the significant bitplane image. Then, the corresponding low-pass subband is divided into small blocks. Finally, the digital watermark is embedded into host image by adaptively modulating the selected wavelet coefficients in small blocks. The main steps of digital watermark detecting procedure include: (1) the significant bitplane image is extracted from test image, and some low-order pseudo-Zernike moments of the significant bitplane image are computed, which are regarded as the effective feature vectors; (2) the appropriate kernel function is selected for training, and a SVM training model can be obtained; (3) the test image is corrected with the well trained SVM model; (4) the digital watermark is extracted from the corrected test image. Experimental results show that the proposed image watermarking is not only invisible and robust against common image processing operations such as filtering, noise adding, and JPEG compression etc., but also robust against the geometrical distortions.
C1 [Wang, Xiang-yang; Wang, Chun-peng; Wang, Ai-long; Yang, Hong-ying] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
EM wxy37@126.com; yhy_65@126.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU National Natural Science Foundation of China [61272416, 60873222,
   60773031]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61272416, 60873222, & 60773031.
CR Barni M, 2005, IEEE SIGNAL PROC LET, V12, P158, DOI 10.1109/LSP.2004.840872
   Bartoli A, 2008, IEEE T PATTERN ANAL, V30, P2098, DOI 10.1109/TPAMI.2008.22
   Cheddad A, 2010, SIGNAL PROCESS, V90, P727, DOI 10.1016/j.sigpro.2009.08.010
   Deng C, 2009, SIGNAL PROCESS, V89, P1531, DOI 10.1016/j.sigpro.2009.02.005
   Fu Y, 2004, ELECTRON LETT, V40, P986, DOI 10.1049/el:20040600
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P278, DOI 10.1109/TSMCC.2009.2037512
   Jung SW, 2011, IEEE SIGNAL PROC LET, V18, P95, DOI 10.1109/LSP.2010.2095498
   Kang XG, 2010, IEEE T INF FOREN SEC, V5, P1, DOI 10.1109/TIFS.2009.2039604
   Kaur M, 2009, 2009 INTERNATIONAL CONFERENCE ON INFORMATION AND MULTIMEDIA TECHNOLOGY, PROCEEDINGS, P296, DOI 10.1109/ICIMT.2009.81
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KUMAR A, 1994, INT J DEV NEUROSCI, V12, P31, DOI 10.1016/0736-5748(94)90093-0
   Li CH, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1255
   Liu Y, 2007, MULTIMED TOOLS APPL, V34, P57, DOI 10.1007/s11042-006-0072-9
   Muhammad KK, 2011, MULTIMED TOOLS APPL, V52, P257
   Peng H, 2010, J SYST SOFTWARE, V83, P1470, DOI 10.1016/j.jss.2010.03.006
   Qi HY, 2008, SIGNAL PROCESS, V88, P174, DOI 10.1016/j.sigpro.2007.07.020
   Seo JS, 2006, IEEE T SIGNAL PROCES, V54, P1537, DOI 10.1109/TSP.2006.870581
   Tsai HH, 2007, INFORM SCIENCES, V177, P550, DOI 10.1016/j.ins.2006.05.002
   Vapnik V., 1999, NATURE STAT LEARNING
   Wang XY, 2010, MULTIDIM SYST SIGN P, V21, P179, DOI 10.1007/s11045-009-0096-1
   Wang XY, 2009, EXPERT SYST APPL, V36, P9056, DOI 10.1016/j.eswa.2008.12.040
   Wang XY, 2007, IEEE T INF FOREN SEC, V2, P655, DOI 10.1109/TIFS.2007.908233
   Wu JZ, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P572, DOI 10.1109/IAS.2009.176
   Zheng D, 2007, ACM COMPUT SURV, V39, DOI 10.1145/1242471.1242473
NR 24
TC 8
Z9 8
U1 0
U2 15
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2014
VL 72
IS 2
BP 1933
EP 1960
DI 10.1007/s11042-013-1483-z
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AM5IR
UT WOS:000339891300040
DA 2024-07-18
ER

PT J
AU Ibrahim, LF
   Abulkhair, M
   AlShomrani, AD
   AL-Garni, M
   AL-Mutiry, A
   AL-Gamdi, F
   Kalenen, R
AF Ibrahim, Lamiaa Fattouh
   Abulkhair, Maysoon
   AlShomrani, Amal D.
   AL-Garni, Manal
   AL-Mutiry, Ameerah
   AL-Gamdi, Fadiah
   Kalenen, Roa'a
TI Using Haar classifiers to detect driver fatigue and provide alerts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Driver fatigue; Image processing; Haar classifier; Correlation matching
   algorithm
AB Drowsiness is a transition state between being awake and asleep and can have serious consequences when occurring in tasks that require sustained attention such as driving. During the state of drowsiness, reaction time is slower, vigilance is reduced, and information processing is less efficient, which may cause accidents. The proposed Driver Fatigue Detection System (called FDS) aims to monitor the alertness of drivers to prevent them from falling asleep at the wheel. The system monitors the driver's face using Haar feature classifiers with an increased training set to detect changes in the face of the driver quickly. A correlation matching algorithm is used to accurately provide the target's position and track the target's eyes according to the intensity, shape, and size of the pupils. FDS uses an IR illuminator to produce the desired bright pupil effect when the driver is wearing sunglasses. The resulting system operates in real-time, and is more accurate and less intrusive to the driver than other systems currently available.
C1 [Ibrahim, Lamiaa Fattouh; Abulkhair, Maysoon; AL-Garni, Manal; AL-Mutiry, Ameerah; AL-Gamdi, Fadiah; Kalenen, Roa'a] King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Technol, Girl Sect, Jeddah 21551, Saudi Arabia.
   [Ibrahim, Lamiaa Fattouh] Cairo Univ, Inst Stat Studies & Res, Dept Comp Sci & Informat, Cairo, Egypt.
   [AlShomrani, Amal D.] Umm AL Qura Univ, Mecca, Saudi Arabia.
C3 King Abdulaziz University; Egyptian Knowledge Bank (EKB); Cairo
   University; Umm Al Qura University
RP Ibrahim, LF (corresponding author), King Abdulaziz Univ, Fac Comp & Informat Technol, Dept Informat Technol, Girl Sect, BP 42808, Jeddah 21551, Saudi Arabia.
EM lfibrahim@kau.edu.sa
RI Ibrahim, Lamiaa Fattouh/J-7904-2012; Abulkhair, Maysoon F/K-8986-2012
OI Ibrahim, Lamiaa Fattouh/0000-0001-5671-8941; 
FU Deanship of Scientific Research (DSR), King Abdulaziz University, Jeddah
   [611-008-D1433]; DSR
FX This work was funded by the Deanship of Scientific Research (DSR), King
   Abdulaziz University, Jeddah, under grant No. (611-008-D1433). The
   authors, therefore, acknowledge with thanks DSR technical and financial
   support.
CR Adolf F., 2003, BUILD CASCADE BOOSTE
   [Anonymous], 2007, DRIV STAT SENS US MA
   [Anonymous], DIGITAL WEB MAGAZINE
   Boyraz Pinar, 2008, 2008 IEEE International Conference on Vehicular Electronics and Safety, P293, DOI 10.1109/ICVES.2008.4640863
   Breuer J., 2008, ATTENTION ASSIST DON
   Cho J, 2009, ACM SIGDA INT S FIEL, pxx
   Coetzer RC, 2011, IEEE INT VEH SYM, P66, DOI 10.1109/IVS.2011.5940406
   Coetzer RC, 2009, P AFRICON 09 C, P8587
   Devi Mandalapu Sarada, 2008, 2008 1st International Conference on Emerging Trends in Engineering and Technology (ICETET), P649, DOI 10.1109/ICETET.2008.17
   Dinges DF, 1998, 808762 DEP TRANSP SA, V808
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Eskandarian A, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1284
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Grace G, 2012, DROWSY DRIVER MONITO
   Intel Corporation, 2001, CCSC S CENTR C
   Konstantin P., 2010, STAT RELATED DROWSY
   Lal SKL, 2003, J SAFETY RES, V34, P321, DOI 10.1016/S0022-4375(03)00027-6
   Rasolzadeh B, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P348
   Sangkyun Park, 2011, 2011 International SoC Design Conference (ISOCC 2011), P262, DOI 10.1109/ISOCC.2011.6138760
   Sayed R, 2001, P I MECH ENG D-J AUT, V215, P969, DOI 10.1243/0954407011528536
   Sivaraman S, 2009, IEEE INT VEH SYM, P399, DOI 10.1109/IVS.2009.5164311
   SmartEye, 2010, ANT 2 0
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Tabrizi Pooneh R., 2009, Proceedings of the 2009 Fifth International Conference on Intelligent Information Hiding and Multimedia Signal Processing. IIH-MSP 2009, P1310, DOI 10.1109/IIH-MSP.2009.186
   Tianyi Hong, 2007, 2007 IEEE International Conference on Control and Automation, ICCA 2007, P1449, DOI 10.1109/ICCA.2007.4376601
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XW, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5361
   Wei Zheng, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2703, DOI 10.1109/CVPRW.2009.5206642
   Wierwille W, 1994, 808247 NAT HIGHW TRA, V808
   Wilson P., 2005, ASEE GULF SW ANN C
   Yun Seong Kim, 2007, 6th International Special Topic Conference on Information Technology Applications in Biomedicine, 2007, P191
   Zhang ZT, 2006, INT C PATT RECOG, P1262
NR 33
TC 13
Z9 14
U1 1
U2 40
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1857
EP 1877
DI 10.1007/s11042-012-1308-5
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000039
DA 2024-07-18
ER

PT J
AU Srivastava, R
   Roy, S
AF Srivastava, Ruchir
   Roy, Sujoy
TI Utilizing 3D flow of points for facial expression recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial expression recognition; 3D flow; 3D facial models; Expression
   intensity
ID FACE
AB This paper presents an approach to recognize Facial Expressions of different intensities using 3D flow of facial points. 3D flow is the geometrical displacement (in 3D) of a facial point from its position in a neutral face to that in the expressive face. Experiments are performed on 3D face models from the BU-3DFE database. Four different intensities of expressions are used for analyzing the relevance of intensity of the expression for the task of FER. It was observed that high intensity expressions are easier to recognize and there is a need to develop algorithms for recognizing low intensity facial expressions. The proposed features outperform difference of facial distances and 2D optical flow. Performances of two classifiers, SVM and LDA are compared wherein SVM performs better. Feature selection did not prove useful.
C1 [Srivastava, Ruchir] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
   [Roy, Sujoy] Inst Infocomm Res, Singapore 138632, Singapore.
C3 National University of Singapore; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Srivastava, R (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
EM ruchir@nus.edu.sg; sujoy@i2r.a-star.edu.sg
CR [Anonymous], P 9 INT C INT TUT SY
   [Anonymous], ENCY ARTIF INTELL
   [Anonymous], P IEEE INT C PATT RE
   [Anonymous], P IEEE REG 10 C TENC
   [Anonymous], AN MOD FAC GEST 2 IN
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], P 2 IEEE INT C BIOM
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], INT C IM PROC
   [Anonymous], P IEEE COMP SOC C CO
   [Anonymous], P 17 INT C MULT MOD
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], P 10 EUR C COMP VIS
   [Anonymous], IEEE CVPR WORKSH COM
   [Anonymous], P 5 IEEE INT C AUT F
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P INT C DIG IM PROC
   [Anonymous], IEEE INT C PATT REC
   [Anonymous], P IEEE INT C MULT EX
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Bartlett M.S., 2003, CVPR WORKSH COMP VIS
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Chandrasiri NP, 2004, IEEE MULTIMEDIA, V11, P20, DOI 10.1109/MMUL.2004.10
   Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P, 1978, FACIAL ACTION CODING
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fasel B., 2004, Proc. of the 6th ACM International Workshop on Multimedia Information Retrieval, P181
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   Hähnel M, 2006, LECT NOTES COMPUT SC, V4174, P324
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Mpiperis I, 2008, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2008.4518064
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Sha T, 2011, NEUROCOMPUTING, V74, P2135, DOI 10.1016/j.neucom.2011.01.008
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Soyel H, 2010, TURK J ELECTR ENG CO, V18, P1031, DOI 10.3906/elk-0908-158
   Stylianou G, 2009, INT J IMAGE GRAPH, V9, P217, DOI 10.1142/S0219467809003411
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Suwa M., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P408
   Tang H, 2008, PROC 8 IEEE INT C AU, P1
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Venkatesh YV, 2009, PATTERN RECOGN LETT, V30, P1128, DOI 10.1016/j.patrec.2009.04.007
   WEISS S.M., 1998, PREDICTIVE DATA MINI
   Whitehill J, 2008, PROC IEEE COMPUTER S, P1
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Yin LJ, 2006, INT C PATT RECOG, P1248
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhan YQ, 2005, PATTERN RECOGN, V38, P157, DOI 10.1016/j.patcog.2004.06.001
NR 52
TC 4
Z9 5
U1 0
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2014
VL 71
IS 3
BP 1953
EP 1974
DI 10.1007/s11042-012-1322-7
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AL8KJ
UT WOS:000339387000044
DA 2024-07-18
ER

PT J
AU Kim, UH
   Kang, JM
   Lee, JS
   Kim, HS
   Jung, SY
AF Kim, Ui-Hyong
   Kang, Jung-Min
   Lee, Jae-Sung
   Kim, Hyong-Shik
   Jung, Soon-Young
TI Practical firewall policy inspection using anomaly detection and its
   visualization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Firewall; Policy; Anomaly; Visualization; FPA; FPC
AB Due to the increasing cyber threats, firewall has become the one of the core elements in network security. The effectiveness of firewall security is dependent on providing policy management techniques. For this reason, it is highly required to have an automatic tool that is real applicable to running firewalls and it should help administrators use in easy. This paper represents a first step toward a practically applicable tool called Firewall Policy Checker for firewall policy inspection based on four anomaly types. It also focuses on detecting dangerous services such as telnet, ftp and so on which many administrators set as time goes and detecting illegal servers. In addition, this tool supports a large number of rules with the high speed using efficient N-ary tree module. The experimental results using real organizations' rules are introduced. Finally, this paper illustrates an easy 3D visualization even for non experts.
C1 [Kim, Ui-Hyong; Kim, Hyong-Shik] Chungnam Natl Univ, Dept Comp Sci & Engn, Taejon, South Korea.
   [Kang, Jung-Min; Jung, Soon-Young] Korea Univ, Seoul, South Korea.
   [Lee, Jae-Sung] ETRI, Cyber Secur Res Dept, Attached Inst, Taejon, South Korea.
C3 Chungnam National University; Korea University; Electronics &
   Telecommunications Research Institute - Korea (ETRI)
RP Kang, JM (corresponding author), Korea Univ, Anam Dong 5 Ga, Seoul, South Korea.
EM kuhpinocchio@hanmail.net; jim003@naver.com; berise@ensec.re.kr;
   hkim@cnu.kr; jsy@korea.ac.kr
CR Al-Shaer Ehab S., 2002, CTITECHREP0801
   AlShaer ES, 2003, IFIP IEEE 8 INT S IN
   [Anonymous], 2009, Applied Security Visualization
   CHESWICK WR, 1995, FIREWALLS INTERNET S
   Ellson J, 2004, MATH VIS, P127
   Glatz E, 2010, VIZSEC 10 P 7 INT S
   Goodall JR, 2007, VIZSEC 07 P 4 INT S
   Lee CP., 2005, P IEEE WORKSH VIS CO
   Nidhi S, 2005, THESIS MIT
   Pearlman J., 2007, VIZSEC 07 P 4 INT S
   Tran T, 2007, P 21 LARG INST SYST
   Yin Xiaoxin, 2005, P 3 IEEE INT WORKSH
NR 12
TC 7
Z9 9
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2014
VL 71
IS 2
BP 627
EP 641
DI 10.1007/s11042-013-1673-8
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AK3IS
UT WOS:000338317400015
DA 2024-07-18
ER

PT J
AU Gravier, G
   Demarty, CH
   Baghdadi, S
   Gros, P
AF Gravier, Guillaume
   Demarty, Claire-Helene
   Baghdadi, Siwar
   Gros, Patrick
TI Classification-oriented structure learning in Bayesian networks for
   multimodal event detection in videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia; Video analysis; Multimodal event detection; Bayesian
   networks; Structure learning
ID AUDIOVISUAL INTEGRATION
AB We investigate the use of structure learning in Bayesian networks for a complex multimodal task of action detection in soccer videos. We illustrate that classical score-oriented structure learning algorithms, such as the K2 one whose usefulness has been demonstrated on simple tasks, fail in providing a good network structure for classification tasks where many correlated observed variables are necessary to make a decision. We then compare several structure learning objective functions, which aim at finding out the structure that yields the best classification results, extending existing solutions in the literature. Experimental results on a comprehensive data set of 7 videos show that a discriminative objective function based on conditional likelihood yields the best results, while augmented approaches offer a good compromise between learning speed and classification accuracy.
C1 [Gravier, Guillaume] CNRS IRISA, F-35042 Rennes, France.
   [Demarty, Claire-Helene; Baghdadi, Siwar] Technicolor, Rennes, France.
   [Gros, Patrick] INRIA, Rennes, France.
C3 Universite de Rennes; Centre National de la Recherche Scientifique
   (CNRS); Technicolor SA; Inria
RP Gravier, G (corresponding author), CNRS IRISA, Campus Beaulieu, F-35042 Rennes, France.
EM Guillaume.Gravier@irisa.fr
FU OSEO, French state agency for innovation
FX This work was partially funded by OSEO, French state agency for
   innovation, in the framework of the Quaero project.
CR [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], 2004, P 21 INT C MACH LEAR
   Bae TM, 2005, LECT NOTES COMPUT SC, V3568, P113
   Baghdadi S, 2008, IEEE INT C MULT EXH, P667
   Chickering D., 1995, P 5 C ART INT STAT, P112
   Choudhury T, 2002, IEEE INT C PATT REC
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   COOPER GF, 1992, MACH LEARN, V9, P309, DOI 10.1007/BF00994110
   Delakis M, 2008, COMPUT VIS IMAGE UND, V111, P142, DOI 10.1016/j.cviu.2007.09.002
   Friedman N, 2000, J COMPUT BIOL, V7, P601, DOI 10.1089/106652700750050961
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   GEIGER D, 1992, P 8 C UNC AI, P92
   Ghahramani Z, 1998, LECT NOTES ARTIF INT, V1387, P168, DOI 10.1007/BFb0053999
   Gibert X, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P345
   Greiner R, 2005, MACH LEARN, V59, P297, DOI 10.1007/s10994-005-0469-0
   Haering N, 2000, IEEE T CIRC SYST VID, V10, P857, DOI 10.1109/76.867923
   Heckerman D., 1995, MSRTR9506
   Huang C-L, 2006, IEEE T MULTIMEDIA, V15, P1225
   Huang J., 1999, 1999 IEEE Third Workshop on Multimedia Signal Processing (Cat. No.99TH8451), P53, DOI 10.1109/MMSP.1999.793797
   Jensen F. V., 1990, Computational Statistics Quarterly, V5, P269
   Kijak E, 2006, MULTIMED TOOLS APPL, V30, P289, DOI 10.1007/s11042-006-0031-5
   Kim J.H., 1983, P 8 INT JOINT C ARTI, V1, P190
   Kruskal J. B., 1956, Proceedings of the American Mathematical Society, V7, P48
   Lakka C, 2011, SIGNAL PROCESS-IMAGE, V26, P175, DOI 10.1016/j.image.2011.01.004
   Mizutani M, 2005, INT CONF ACOUST SPEE, P157
   Murphy Kevin Patrick, 2002, Dynamic bayesian networks: representation, inference and learning
   Pearl J., 1992, Statistics and Computing, V2, P91, DOI 10.1007/BF01889587
   Perlovsky LI, 1998, IEEE T PATTERN ANAL, V20, P666, DOI 10.1109/34.683784
   Petkovic M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P817, DOI 10.1109/ICME.2002.1035907
   Pfeiffer S, 2001, MULTIMED TOOLS APPL, V15, P59, DOI 10.1023/A:1011315803415
   Qian XM, 2010, LECT NOTES COMPUT SC, V6298, P439, DOI 10.1007/978-3-642-15696-0_41
   Saraceno C, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P363, DOI 10.1109/ICIP.1998.723500
   Snoek CGM, 2005, IEEE T MULTIMEDIA, V7, P638, DOI 10.1109/TMM.2005.850966
   Spirtes P, 1993, CAUSATION PREDECTION
   Tovinkere V., 2001, PROC IEEE INT C MULT, P833, DOI 10.1109/ICME.2001.1237851
   Wang F, 2004, IEEE IMAGE PROC, P633
   Xu G, 2002, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2002.1048431
   Zhong D., 2001, IEEE International Conference on Multimedia and Expo, P713, DOI DOI 10.1109/ICME.2001.1237820
NR 38
TC 3
Z9 3
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 1421
EP 1437
DI 10.1007/s11042-012-1169-y
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Krishnamoorthy, R
   Punidha, R
AF Krishnamoorthy, R.
   Punidha, R.
TI Low bit-rate multi stage vector quantization based on energy clustered
   training set
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Color image coding; Energy clustered training set; Multi stage vector
   quantization; Orthogonal polynomials transform
ID IMAGE COMPRESSION; CODEBOOK DESIGN; ALGORITHM
AB In this paper, a new multi stage vector quantization with energy clustered training set is proposed for color image coding. The input image is applied with orthogonal polynomials based transformation and the energy clustered transformed training vectors are obtained with reduced dimension. The stage-by-stage codebook for vector quantization is constructed from the proposed transformed training vectors so as to reduce computational complexity. This method also generates a single codebook for all the three color components, utilizing the inter-correlation property of individual color planes and interactions among the color planes due to the proposed transformation. As a result, the color image encoding time is only slightly higher than that of gray scale image coding time and in contrast to the existing color image coding techniques, whose time is thrice greater than that of gray scale image coding. The experimental results reveal that only 35 % and 10 % of transform coefficients are sufficient for smaller and larger blocks respectively, for the reconstruction of images with good quality. The proposed multi stage vector quantization technique is faster when compared to existing techniques and yields better trade-off between image quality and block size for encoding.
C1 [Krishnamoorthy, R.; Punidha, R.] Anna Univ Technol, Dept CSE, Comp Vis Lab, Tiruchirappalli 620024, Tamil Nadu, India.
C3 Anna University; Anna University of Technology Tiruchirappalli
RP Krishnamoorthy, R (corresponding author), Anna Univ Technol, Dept CSE, Comp Vis Lab, Tiruchirappalli 620024, Tamil Nadu, India.
EM rkrish26@hotmail.com; r_punidha@yahoo.co.in
RI ; Punidha, R/G-7904-2016
OI Ramasamy, Krishnamoorthy/0000-0003-1823-5855; Punidha,
   R/0000-0002-2149-6696
CR Adams MD, 2000, IEEE T IMAGE PROCESS, V9, P1010, DOI 10.1109/83.846244
   Annadurai1 S., 2009, ICGST GVIP J, V9, P9
   BARLAUD M, 1994, IEEE T IMAGE PROCESS, V3, P367, DOI 10.1109/83.298393
   Canta GR, 1998, IEEE T IMAGE PROCESS, V7, P668, DOI 10.1109/83.668024
   Chang CC, 2006, PATTERN RECOGN LETT, V27, P1077, DOI 10.1016/j.patrec.2005.12.017
   Courant R, 1975, METHODS MATH PHYS
   EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395
   ESAKKIRAJAN S, 2006, GVIP J, V6, P19
   FISCHER TR, 1986, IEEE T INFORM THEORY, V32, P568, DOI 10.1109/TIT.1986.1057198
   Flanagan J. K., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1759, DOI 10.1109/ICASSP.1989.266790
   Gersho A., 2003, Vector Quantization and Signal Compression
   GOLDBERG M, 1986, IEEE T COMMUN, V34, P180, DOI 10.1109/TCOM.1986.1096503
   Hsieh CH, 2000, J VIS COMMUN IMAGE R, V11, P374, DOI 10.1006/jvci.2000.0452
   Hsieh CH, 1992, IEEE T CIRC SYST VID, V2, P401, DOI 10.1109/76.168905
   Huang HC, 2001, SIGNAL PROCESS, V81, P1513, DOI 10.1016/S0165-1684(01)00048-2
   Kim JW, 1992, IEEE T CIRC SYST VID, V2, P3, DOI 10.1109/76.134367
   Krishnamoorthi R., 2009, INT J SIGNAL PROCESS, V5, P67
   Krishnamoorthy R, 2010, COMM COM INF SC, V123, P146
   Krishnamoorthy R, 2010, INT C MACH VIS, P92
   Lai JZC, 2008, PATTERN RECOGN, V41, P315, DOI 10.1016/j.patcog.2007.04.015
   Lai JZC, 2009, PATTERN RECOGN, V42, P3065, DOI 10.1016/j.patcog.2009.02.001
   Li RY, 2002, IMAGE VISION COMPUT, V20, P37, DOI 10.1016/S0262-8856(01)00075-0
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liou RJ, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P252, DOI 10.1109/ICALIP.2008.4590117
   NASRABADI NM, 1990, IEEE T COMMUN, V38, P2166, DOI 10.1109/26.64659
   PAN JS, 1995, ELECTRON LETT, V31, P1418, DOI 10.1049/el:19951031
   Salleh M.F.M., 2007, EURASIP J APPL SIG P, V2007, P1
   Shen F, 2006, NEURAL NETWORKS, V19, P694, DOI 10.1016/j.neunet.2005.05.001
   Shen GB, 2003, IEEE T IMAGE PROCESS, V12, P283, DOI 10.1109/TIP.2003.810915
   Sun HW, 2005, NEURAL COMPUT APPL, V14, P203, DOI 10.1007/s00521-004-0455-7
   Swilem A, 2010, IMAGE VISION COMPUT, V28, P1637, DOI 10.1016/j.imavis.2010.05.002
   Tsai CW, 2009, PATTERN RECOGN LETT, V30, P653, DOI 10.1016/j.patrec.2009.02.003
   Wang M, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL 1, PROCEEDINGS, P415
   Yang SB, 2008, PATTERN RECOGN, V41, P689, DOI 10.1016/j.patcog.2007.05.011
NR 34
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2014
VL 70
IS 3
BP 2293
EP 2308
DI 10.1007/s11042-012-1244-4
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI8IP
UT WOS:000337156500041
DA 2024-07-18
ER

PT J
AU Azevedo, RGA
   Araújo, EC
   Lima, B
   Soares, LFG
   Moreno, MF
AF Azevedo, Roberto Gerson A.
   Araujo, Eduardo Cruz
   Lima, Bruno
   Soares, Luiz Fernando G.
   Moreno, Marcelo F.
TI <i>Composer</i>: meeting non-functional aspects of hypermedia authoring
   environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypermedia authoring tools; Non-functional requirements;
   Microkernel-based architecture
ID MULTIMEDIA; INTERFACE
AB This paper discusses the importance of non-functional requirements in the design of hypermedia authoring tools, which typically provides multiple graphical abstractions (views). It focuses on creating products and services that operate robustly across a broad range of environments, and that take into account the changeable needs of their users over time, as they become more familiar with the tool. In order to meet these non-functional aspects, this paper proposes a microkernel-based architecture for authoring tools, where the microkernel is responsible for instantiating the requested extensions (plugins), maintaining the core data model that represents the hypermedia document under development, and notifying changes in this model to plugins interested in them. Based on the proposed architecture, a new version of Composer (an NCL authoring tool) is presented, rewritten from scratch. Results from experiments show that the discussed nonfunctional requirements are adequately met.
C1 [Azevedo, Roberto Gerson A.; Araujo, Eduardo Cruz; Lima, Bruno; Soares, Luiz Fernando G.; Moreno, Marcelo F.] Pontificia Univ Catolica Rio de Janeiro, BR-22451900 Rio De Janeiro, RJ, Brazil.
RP Azevedo, RGA (corresponding author), Pontificia Univ Catolica Rio de Janeiro, Rua Marques Sao Vicente 225, BR-22451900 Rio De Janeiro, RJ, Brazil.
EM robertogerson@telemidia.puc-rio.br; edcaraujo@telemidia.puc-rio.br;
   bslima@telemidia.puc-rio.br; lfgs@telemidia.puc-rio.br;
   moreno@telemidia.puc-rio.br
RI Azevedo, Roberto/AAE-9288-2019
OI Moreno, Marcelo/0000-0002-0030-0885
FU CNPq; CAPES; MCT
FX The authors would like to thank Carlos Salles and all TeleMidia Lab's
   researchers who provided a thoughtful discussion of this work. The
   authors also thank CNPq, CAPES and MCT for their support.
CR Albanese M, 2010, MULTIMED TOOLS APPL, V50, P563, DOI 10.1007/s11042-010-0480-8
   Amiri F, 2011, INT J ART DES EDUC, V30, P200, DOI 10.1111/j.1476-8070.2011.01680.x
   [Anonymous], 1999, Open sources: voices from the open source revolution
   [Anonymous], 2011, PROC IEEE POWER ENER
   [Anonymous], 1996, PATTERN ORIENTED SOF
   Associacao Brasileira de Normas Tecnicas, 2011, 156062 NBR ASS BRAS
   Azevedo R.G.A., 2011, P 9 INT INT C INT TE, P235, DOI [10.1145/2000119.2000169, DOI 10.1145/2000119.2000169]
   Bouyakoub S, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870123
   Bulterman D.C., 2009, SMIL 3 0 FLEXIBLE MU
   Bulterman DCA, 1998, COMPUT NETWORKS ISDN, V30, P519, DOI 10.1016/S0169-7552(98)00128-7
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Cha KA, 2005, MULTIMED TOOLS APPL, V25, P111, DOI 10.1023/B:MTAP.0000046384.83647.54
   Chung L, 2009, LECT NOTES COMPUT SC, V5600, P363, DOI 10.1007/978-3-642-02463-4_19
   Costa RMR, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P289
   d SS Neto C., 2010, Journal of the Brazilian Computer Society, V16, P229, DOI [10.1007/s13173-010-0017-z, DOI 10.1007/S13173-010-0017-Z]
   Eclipse Foundation, 2004, ECL PUBL LIC V 1 0
   Fuentes L, 2008, ICSE'08 PROCEEDINGS OF THE THIRTIETH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, P955
   Geerts D, 2009, CHI2009: PROCEEDINGS OF THE 27TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1-4, P595
   Gérard S, 2010, LECT NOTES COMPUT SC, V6100, P361, DOI 10.1007/978-3-642-16277-0_19
   Geuer O, 2005, P 3 EUR C INT TV VID, P253
   Greenberg S, 2007, MULTIMED TOOLS APPL, V32, P139, DOI 10.1007/s11042-006-0062-y
   Guimaraes RL, 2008, LECT NOTES COMPUT SC, V5066, P61, DOI 10.1007/978-3-540-69478-6_7
   Jourdan M, 2000, MULTIMED TOOLS APPL, V12, P257, DOI 10.1023/A:1009675809463
   Leino KRM, 2011, FUTURE OF SOFTWARE ENGINEERING, P115, DOI 10.1007/978-3-642-15187-3_7
   Lima B.S., 2011, P 2011 ACM S APPL CO, P1259
   Malan R., 2001, Defining non functional requirements
   Mantzari E., 2008, Proceedings of the 1st international conference on designing interactive user experiences for tv and video, P81, DOI DOI 10.1145/1453805.1453823
   MIKAC J, 2008, P 8 ACM S DOC ENG DO, P28
   Muchaluat D, 1998, P 5 IEEE INT C MULT
   Nokia Corp, 2012, QT ONL REF DOC
   Quintella F., 2010, P 15 INT C WEB 3D TE, P45
   Simonson, 2011, Patent, Patent No. [7,929,475 B2, 7929475]
   Soares LFG, 2006, 3506 MCC PUC RIO INF
   Soares LFG, 2005, D91 SECURESCM
   Soares Neto CS, 2010, J BRAZILIAN IN PRESS, P147
   Soares Neto CS, 2010, THESIS PUC RIO
   Song JH, 1996, IEEE SYMPOSIUM ON VISUAL LANGUAGES, PROCEEDINGS, P276, DOI 10.1109/VL.1996.545298
   Summa G., 2011, THESIS SLOAN SCH MAN
   Teixeira CC, 2011, MULTIMED TOOLS APPL, V55, P178
   Vazirgiannis M, 1999, IEEE MULTIMEDIA, V6, P24, DOI 10.1109/93.790609
   WEB3D Consortium, 2009, 19776122009 ISOIEC W
   WECK D, 2005, LIMSEE2 OFFICIAL USE
   Williams M, 2002, ACTIONSCRIPT CODING
   Zhou Qian, 2011, Video Engineering, V35, P58
NR 44
TC 7
Z9 7
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1199
EP 1228
DI 10.1007/s11042-012-1216-8
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900027
DA 2024-07-18
ER

PT J
AU Rashed, KAN
   Renzel, D
   Klamma, R
   Jarke, M
AF Rashed, Khaled Ahmed Nagi
   Renzel, Dominik
   Klamma, Ralf
   Jarke, Matthias
TI Community and trust-aware fake media detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Community-based approach; Trust-awareness; Multimedia Quality Profile;
   Collaborative fake media detection; Multimedia reputation; Semantics for
   faked multimedia
ID INTERNET; SYSTEMS
AB Nowadays, it becomes increasingly difficult to find reliable multimedia content in the Web 2.0. Open decentralized networks (on the Web) are populated with lots of unauthenticated agents providing fake multimedia. Conventional automatic detection and authentication approaches lack scalability and the ability to capture media semantics by means of forgery. Using them in online scenarios is computationally expensive. Thus, our aim was to develop a trust-aware community approach to facilitate fake media detection. In this paper, we present our approach and highlight four important outcomes. First, a Media Quality Profile (MQP) is proposed for multimedia evaluation and semantic classification with one substantial part on estimating media authenticity based on trust-aware community ratings. Second, we employ the concept of serious gaming in our collaborative fake media detection approach overcoming the cold-start problem and providing sufficient data powering our Media Quality Profile. Third, we identify the notion of confidence, trust, distrust and their dynamics as necessary refinements of existing trust models. Finally, we improve the precision of trust-aware aggregated media authenticity ratings by introducing a trust inference algorithm for yet unknown sources uploading and rating media.
C1 [Rashed, Khaled Ahmed Nagi; Renzel, Dominik; Klamma, Ralf; Jarke, Matthias] Rhein Westfal TH Aachen, D-52056 Aachen, Germany.
C3 RWTH Aachen University
RP Rashed, KAN (corresponding author), Rhein Westfal TH Aachen, Ahornstr 55, D-52056 Aachen, Germany.
EM rashed@dbis.rwth-aachen.de; renzel@dbis.rwth-aachen.de;
   klamma@dbis.rwth-aachen.de; jarke@dbis.rwth-aachen.de
RI Klamma, Ralf/K-5908-2016
OI Klamma, Ralf/0000-0002-2296-3401
FU B-IT Research School; European Community [231396]
FX The research leading to these results has received funding from B-IT
   Research School and the European Community's Seventh Framework Programme
   (FP7/2007-2013) under grant agreement no 231396 (ROLE project).
CR Abdul-Rahman A., 2000, P 33 ANN HAW INT C S, DOI [10.1109/HICSS.2000.926814, DOI 10.1109/HICSS.2000.926814]
   Albert R, 1999, NATURE, V401, P130, DOI 10.1038/43601
   [Anonymous], 2002, Introduction to MPEG- 7: Multimedia content description interface
   [Anonymous], 2004, Designing the User Interface: Strategies for Eff ective Human-Computer Interaction
   [Anonymous], J UCS J UNIVERSAL CO
   [Anonymous], DIGITAL INVEST
   [Anonymous], 2002, EXCH IM FIL FORM DIG
   [Anonymous], 2009, MM 09 P 2009 ACM MUL, DOI DOI 10.1145/1631272.1631456
   [Anonymous], THESIS RWTH AACHEN U
   [Anonymous], P 2 WORKSH FOC SEM M
   [Anonymous], YOUR ONLINE COMMUNIT
   [Anonymous], 2002, THESIS MIT
   [Anonymous], RFC 3920 EXTENSIBLE
   [Anonymous], 2006, SIGCAS Computing Society
   [Anonymous], 2007, SERIOUS GAMES OVERVI
   [Anonymous], BRIT J SOCIOLOGY
   [Anonymous], THESIS RWTH AACHEN U
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], J UCS J UNIVERSAL CO
   [Anonymous], P 11 INT WORKSH INT
   [Anonymous], P 4 WORKSH DEC FRAUD
   [Anonymous], 1996, MEANINGS TRUST
   [Anonymous], ISOIEC159383
   [Anonymous], 2000, Community Building on the Web
   [Anonymous], THESIS UC BERKELEY B
   [Anonymous], 2006, QUADERNS FILOLOGIA E
   [Anonymous], CEUR WORKSHOP P
   [Anonymous], PHOTOFAKERY HIST TEC
   Arrow KJ., 1974, The Fels lectures on public policy analysis (1970-1971)
   Bashan A, 2011, PHYS REV E, V83, DOI 10.1103/PhysRevE.83.051127
   Bober M, 2009, IEEE INT CON MULTI, P1540, DOI 10.1109/ICME.2009.5202798
   Callaway DS, 2000, PHYS REV LETT, V85, P5468, DOI 10.1103/PhysRevLett.85.5468
   Cheng R., 2005, Proceedings of the 38th Hawaii International Conference on System Sciences, P193, DOI DOI 10.1109/HICSS.2005.653
   Clary EG, 1998, J PERS SOC PSYCHOL, V74, P1516, DOI 10.1037/0022-3514.74.6.1516
   Cofta P, 2006, 2006 ICEC: Eighth International Conference on Electronic Commerce, Proceedings, P250
   Cohen R, 2001, PHYS REV LETT, V86, P3682, DOI 10.1103/PhysRevLett.86.3682
   Deutsch M., 1958, J CONFLICT RESOLUT, V2, P265
   Douceur JR, 2002, LECT NOTES COMPUT SC, V2429, P251, DOI 10.1007/3-540-45748-8_24
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Fox A., 1974, CONTRACT WORK POWER
   Golbeck J, 2003, LECT NOTES ARTIF INT, V2782, P238
   Golbeck J, 2009, HUM-COMPUT INT-SPRIN, P1, DOI 10.1007/978-1-84800-356-9
   Golbeck J. A., 2005, THESIS U MARYLAND CO, DOI DOI 10.1016/j.physa.2012.03.021
   Golle P., 2001, EC'01. Proceedings of the 3rd ACM Conference on Electronic Commerce, P264, DOI 10.1145/501158.501193
   Grandison T, 2000, IEEE Communications Surveys Tutorials, V3, P2, DOI [DOI 10.1109/COMST.2000.5340804, 10.1109/COMST.2000.5340804]
   Gretarsson B, 2010, COMPUT GRAPH FORUM, V29, P833, DOI 10.1111/j.1467-8659.2009.01679.x
   Herlocker J. L., 2000, CSCW 2000. ACM 2000 Conference on Computer Supported Cooperative Work, P241, DOI 10.1145/358916.358995
   Hinduja S, 2008, DEVIANT BEHAV, V29, P129, DOI 10.1080/01639620701457816
   Iwata M., 2010, 2010 International Symposium On Information Theory & Its Applications (ISITA 2010), P309, DOI 10.1109/ISITA.2010.5649171
   Josang A, 2007, DECIS SUPPORT SYST, V43, P618, DOI 10.1016/j.dss.2005.05.019
   Kamvar M. T., 2003, P 12 INT C WORLD WID, P640
   Keith S., 2005, Reclaiming Children and Youth, V13, P224, DOI DOI 10.1016/J.PAID.2006.03.008
   Kleinberg JM, 1999, J ACM, V46, P604, DOI 10.1145/324133.324140
   Levien R, 2009, HUM-COMPUT INT-SPRIN, P121, DOI 10.1007/978-1-84800-356-9_5
   LEWIS JD, 1985, SOC FORCES, V63, P967, DOI 10.2307/2578601
   Li XY, 2009, J COMPUT SCI TECH-CH, V24, P868, DOI 10.1007/s11390-009-9278-4
   Lux M., 2003, Proceedings of Conference on Advanced Information Systems Engineering, P85
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Manovich Lev, 2001, The Language of new media
   Marsh S, 2009, HUM-COMPUT INT-SPRIN, P9, DOI 10.1007/978-1-84800-356-9_2
   Massa P, 2004, LECT NOTES COMPUT SC, V2995, P221
   MILGRAM S, 1967, PSYCHOL TODAY, V1, P61
   Misrha A.K., 1996, TRUST ORG, P261, DOI DOI 10.4135/9781452243610.N13
   Mui L., 2002, Proceedings of the 35th Annual Hawaii International Conference on System Sciences, P2431, DOI 10.1109/HICSS.2002.994181
   O'Donovan J, 2008, CHI 2008: 26TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS VOLS 1 AND 2, CONFERENCE PROCEEDINGS, P1085
   Rafelsberger W, 2009, 20TH ACM CONFERENCE ON HYPERTEXT AND HYPERMEDIA (HYPERTEXT 2009), P193
   Renzel Dominik, 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P139, DOI 10.1109/WIAMIS.2008.52
   Resnick P, 2000, COMMUN ACM, V43, P45, DOI 10.1145/355112.355122
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Richardson M, 2003, LECT NOTES COMPUT SC, V2870, P351
   Schein A. I., 2002, Proceedings of SIGIR 2002. Twenty-Fifth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P253, DOI 10.1145/564376.564421
   Shneiderman B., 2004, INTERACTIONS, V11, P48, DOI DOI 10.1145/1015530.1015552
   Skopik F, 2009, LECT NOTES COMPUT SC, V5802, P275, DOI 10.1007/978-3-642-04409-0_30
   Victor P., 2011, Trust Networks for Recommender Systems
   von Ahn L, 2008, COMMUN ACM, V51, P58, DOI 10.1145/1378704.1378719
   von Ahn L, 2006, COMPUTER, V39, P92, DOI 10.1109/MC.2006.196
   WANG RY, 1995, DECIS SUPPORT SYST, V13, P349, DOI 10.1016/0167-9236(93)E0050-N
   Watts DJ, 1998, NATURE, V393, P440, DOI 10.1038/30918
   Webster A, 2006, LECT NOTES COMPUT SC, V4018, P223
   Wu B., 2005, WWW 05, P820
   Yang Y., 2009, Proceedings of the 2009 ACM symposium on Applied Computing, P1308
   Yaniv I, 2000, ORGAN BEHAV HUM DEC, V83, P260, DOI 10.1006/obhd.2000.2909
   Zaihrayeu I, 2005, LECT NOTES COMPUT SC, V3477, P384
   ZAJONC RB, 1965, SCIENCE, V149, P269, DOI 10.1126/science.149.3681.269
   Ziegler CN, 2007, DECIS SUPPORT SYST, V43, P460, DOI 10.1016/j.dss.2006.11.003
   Ziegler CN, 2005, INFORM SYST FRONT, V7, P337, DOI 10.1007/s10796-005-4807-3
   Zyda M, 2005, COMPUTER, V38, P25, DOI 10.1109/MC.2005.297
NR 87
TC 3
Z9 4
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1069
EP 1098
DI 10.1007/s11042-012-1103-3
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900022
DA 2024-07-18
ER

PT J
AU Spampinato, C
   Palazzo, S
   Boom, B
   van Ossenbruggen, J
   Kavasidis, I
   Di Salvo, R
   Lin, FP
   Giordano, D
   Hardman, L
   Fisher, RB
AF Spampinato, Concetto
   Palazzo, Simone
   Boom, Bastian
   van Ossenbruggen, Jacco
   Kavasidis, Isaak
   Di Salvo, Roberto
   Lin, Fang-Pang
   Giordano, Daniela
   Hardman, Lynda
   Fisher, Robert B.
TI Understanding fish behavior during typhoon events in real-life
   underwater environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Event detection; Fish detection; Covariance tracking; Behavior
   understanding
ID BACKGROUND SUBTRACTION; OBJECT DETECTION; CORAL-REEF; TRACKING; HABITAT;
   IMAGES
AB The study of fish populations in their own natural environment is a task that has usually been tackled in invasive ways which inevitably influenced the behavior of the fish under observation. Recent projects involving the installation of permanent underwater cameras (e.g. the Fish4Knowledge (F4K) project, for the observation of Taiwan's coral reefs) allow to gather huge quantities of video data, without interfering with the observed environment, but at the same time require the development of automatic processing tools, since manual analysis would be impractical for such amounts of videos. Event detection is one of the most interesting aspects from the biologists' point of view, since it allows the analysis of fish activity during particular events, such as typhoons. In order to achieve this goal, in this paper we present an automatic video analysis approach for fish behavior understanding during typhoon events. The first step of the proposed system, therefore, involves the detection of "typhoon" events and it is based on video texture analysis and on classification by means of Support Vector Machines (SVM). As part of our behavior understanding efforts, trajectory extraction and clustering have been performed to study the differences in behavior when disruptive events happen. The integration of event detection with fish behavior understanding surpasses the idea of simply detecting events by low-level features analysis, as it supports the full semantic comprehension of interesting events.
C1 [Spampinato, Concetto; Palazzo, Simone; Kavasidis, Isaak; Di Salvo, Roberto; Giordano, Daniela] Univ Catania, Dept Elect Elect & Comp Engn, Catania, Italy.
   [Boom, Bastian; Fisher, Robert B.] Univ Edinburgh, Sch Informat, Edinburgh, Midlothian, Scotland.
   [van Ossenbruggen, Jacco; Hardman, Lynda] Univ Amsterdam, Ctr Wiskunde & Informat, Amsterdam, Netherlands.
   [Lin, Fang-Pang] Natl Ctr High Performance Comp, Hsinchu, Taiwan.
C3 University of Catania; University of Edinburgh; University of Amsterdam
RP Spampinato, C (corresponding author), Univ Catania, Dept Elect Elect & Comp Engn, Catania, Italy.
EM cspampin@dieei.unict.it; simone.palazzo@dieei.unict.it;
   bboom@inf.ed.ac.uk; Jacco.van.Ossenbruggen@cwi.nl;
   isaak.kavasidis@dieei.unict.it; roberto.disalvo@dieei.unict.it;
   fplin@nchc.narl.org.tw; dgiordan@dieei.unict.it; lynda.hardman@cwi.nl;
   rbf@inf.ed.ac.uk
RI van Ossenbruggen, Jacco/L-5190-2018
OI Boom, Bas/0000-0002-8344-6491; Palazzo, Simone/0000-0002-2441-0982
FU European Commission [257024]
FX This research was funded by European Commission FP7 grant 257024, for
   the Fish4Knowledge project (www.fish4knowledge.eu).
CR Albiol A, 2009, 3 INT C CRIM DET PRE, P1
   [Anonymous], 9 INT WORKSH CONT BA
   [Anonymous], P IEEE MOT MULT
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 2006, P 4 ACM INT WORKSH V
   [Anonymous], P INT C MULT
   [Anonymous], 2009, 2009 IEEE AEROSPACE
   [Anonymous], 2005, P IEEE C COMP VIS PA
   [Anonymous], P WORKSH IM AN MULT
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Benson B., 2009, American Academy of Underwater Science
   Bertails A, 2011, P 6 INT C KNOWL CAPT, P129
   Bouaynaya N, 2005, P IEEE INT C AC SPEE
   Brehmer P, 2006, J EXP MAR BIOL ECOL, V334, P139, DOI 10.1016/j.jembe.2006.01.017
   Cannavó F, 2006, 15TH IEEE INTERNATIONAL WORKSHOPS ON ENABLING TECHNOLOGIES: INFRASTRUCTURE FOR COLLABORATIVE ENTERPRISES, PROCEEDINGS, P227, DOI 10.1109/WETICE.2006.72
   Chau D, 2009, 3 INT C IM CRIM DET, P1
   Cheung SCS, 2005, EURASIP J APPL SIG P, V2005, P2330, DOI 10.1155/ASP.2005.2330
   Chou H, 2009, HPC AS 2009
   Cline DE, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P196
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Costa C, 2004, EURASIP J APPL SIG P, V2004, P1899, DOI 10.1155/S1110865704402248
   Dasiopoulou S, 2005, IEEE T CIRC SYST VID, V15, P1210, DOI 10.1109/TCSVT.2005.854238
   Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888
   Edgington DR, 2003, OCEANS 2003 MTS/IEEE: CELEBRATING THE PAST...TEAMING TOWARD THE FUTURE, P2749
   Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Erdem CE, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P69, DOI 10.1109/ICIP.2001.958426
   Evans FH, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P1029
   Faro A, 2011, IET INTELL TRANSP SY, V5, P197, DOI 10.1049/iet-its.2010.0141
   Faro A, 2006, COMPUT IMAGING VIS, V32, P968, DOI 10.1007/1-4020-4179-9_141
   Faro A, 2011, IEEE T INTELL TRANSP, V12, P1398, DOI 10.1109/TITS.2011.2159266
   Forstner W., 1999, METRIC COVARIANCE MA
   Hariharakrishnan K, 2005, IEEE T MULTIMEDIA, V7, P853, DOI 10.1109/TMM.2005.854437
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Iqbal K, 2002, AENG INT J COMPUTER, V35, P31
   Junejo IN, 2008, IMAGE VISION COMPUT, V26, P512, DOI 10.1016/j.imavis.2007.07.006
   Khan ZH, 2010, IEEE T INF FOREN SEC, V5, P591, DOI 10.1109/TIFS.2010.2050312
   Kuo C, 2011, ZOOLOGICAL STUDIES E, V50, P457
   Larsen R, 2009, LECT NOTES COMPUT SC, V5575, P745
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Morais EF, 2005, SIBGRAPI 2005: XVIII BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, CONFERENCE PROCEEDINGS, P367
   Nagashima Y, 1998, MVA98, pxx
   Nanami A, 2002, ENVIRON BIOL FISH, V63, P353, DOI 10.1023/A:1014952932694
   Nguyen H, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P375, DOI 10.1109/ICME.2004.1394207
   Papadopoulos GT, 2008, IEEE IMAGE PROC, P41, DOI 10.1109/ICIP.2008.4711686
   Porikli F, 2006, J REAL-TIME IMAGE PR, V1, P33, DOI 10.1007/s11554-006-0011-z
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Rouse W, 2007, MARINE BIOL RES EXPT
   Sankaranarayanan AC, 2008, P IEEE, V96, P1606, DOI 10.1109/JPROC.2008.928758
   Scherp A, 2009, K-CAP'09: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P137
   Schettini R, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/746052
   Shaish L, 2010, RESTOR ECOL, V18, P285, DOI 10.1111/j.1526-100X.2009.00647.x
   Shaw R, 2009, LECT NOTES COMPUT SC, V5926, P153, DOI 10.1007/978-3-642-10871-6_11
   Sheng H, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P550, DOI 10.1109/ITSC.2008.4732677
   Shi J, 2008, P IEEE INT C COMP VI, P593
   Sillito RR, 2009, BMVC
   Soori U, 2009, INDIAN J MAR SCI, V38, P359
   Spampinato C., 2010, P 1 ACM INT WORKSH A, P45, DOI [DOI 10.1145/1877868, DOI 10.1145/1877868.1877881]
   Spampinato C, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P514
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sugar CA, 2003, J AM STAT ASSOC, V98, P750, DOI 10.1198/016214503000000666
   Tew KS, 2002, ENVIRON BIOL FISH, V65, P457
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Traiperm C, 2005, P NETW COMM SYST, P189
   Tuzel O, 2006, P 9 EUR C COMP VIS
   van Hage WR, 2012, MULTIMED TOOLS APPL, V57, P175, DOI 10.1007/s11042-010-0680-2
   Varcheie PDZ, 2010, SENSORS-BASEL, V10, P1041, DOI 10.3390/s100201041
   Walther D, 2004, PROC CVPR IEEE, P544
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhou J., 2006, 3 CAN C COMP ROB VIS, P68
   Zhou S, 2003, P INT C MULT EXP
NR 71
TC 27
Z9 28
U1 0
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 1
BP 199
EP 236
DI 10.1007/s11042-012-1101-5
PG 38
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI4AK
UT WOS:000336807300009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Vanoirbeek, C
   Quint, V
   Sire, S
   Roisin, C
AF Vanoirbeek, Christine
   Quint, Vincent
   Sire, Stephane
   Roisin, Cecile
TI A lightweight framework for authoring XML multimedia content on the web
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Authoring paradigms; Authoring for the web; End user authoring
AB This paper addresses the issue of authoring XML multimedia content on the web. It focuses on methods that apply to different kinds of contents, including structured documents, factual data, and multimedia objects. It argues in favor of a template-based approach that enhances the ability for multiple applications to use the produced content. This approach is illustrated by AXEL, an innovative multipurpose client-side authoring framework (previously described in Sire et al. (2010)), intended for web users with limited skills. The versatility of the tool is illustrated through a series of use cases that demonstrate the flexibility of the approach for creating various kinds of web content.
C1 [Vanoirbeek, Christine; Sire, Stephane] Ecole Polytech Fed Lausanne, EPFL IC GR VA, CH-1015 Lausanne, Switzerland.
   [Quint, Vincent] INRIA, F-38334 Montbonnot St Martin, France.
   [Roisin, Cecile] Univ Grenoble, F-38334 Montbonnot St Martin, France.
   [Roisin, Cecile] INRIA, F-38334 Montbonnot St Martin, France.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Inria; Communaute Universite Grenoble Alpes;
   Universite Grenoble Alpes (UGA); Inria
RP Quint, V (corresponding author), INRIA, 655 Ave Europe, F-38334 Montbonnot St Martin, France.
EM christine.vanoirbeek@epfl.ch; vincent.quint@inria.fr;
   stephane.sire@epfl.ch; cecile.roisin@inria.fr
CR [Anonymous], P 2006 ACM S DOC ENG
   Boughoufalah S, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P175, DOI 10.1109/ICME.2000.869572
   Bulterman DCA, 1999, GRINS AUTHORING ENV
   Bulterman Dick., 2008, SYNCHRONIZED MULTIME, p3.0
   Bulterman DCA, 2005, ACM T MULTIM COMPUT, V1, P89, DOI 10.1145/1047936.1047943
   Cazenave F, 2011, DECLARATIVE APPROACH
   Cazenave F, 2011, DOCENG 2011: PROCEEDINGS OF THE 2011 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P43
   Deltour R, 2005, ERCIM NEWS, P41
   dos Santos J.A.F., 2010, P 2010 ACM S APPL CO, P1892
   easyDITA, CONT MAN AUTH PROD A
   dos Santos JAF, 2012, MULTIMED TOOLS APPL, V61, P645, DOI 10.1007/s11042-011-0732-2
   FLORES FC, 2006, P 2006 ACM S DOC ENG, P188
   Furuta R., 1988, Electronic Publishing: Origination, Dissemination and Design, V1, P19
   Guimaraes RL, 2008, LECT NOTES COMPUT SC, V5066, P61, DOI 10.1007/978-3-540-69478-6_7
   Hill C, 2006, IBM SYST J, V45, P663, DOI 10.1147/sj.454.0663
   Huynh D.F., 2007, P 16 INT C WORLD WID, P737
   Ko A. J., 2005, S US INT SOFTW TECHN, P3, DOI [DOI 10.1145/1095034.1095037, 10.1145/1095034, DOI 10.1145/1095034]
   Lumley J, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P76
   Pokorny J, 2009, INFORMATICA-LITHUAN, V20, P417
   Quint V, 1986, GRIF INTERACTIVE SYS, P200
   Quint V, 2010, DOCENG2010: PROCEEDINGS OF THE 2010 ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P61
   Sire S, 2010, XTIGER XML LANGUAGE
   Sire S., 2010, P XML PRAG 2010, P125
   Soares LFG, 2000, MULTIMEDIA SYST, V8, P118, DOI 10.1007/s005300050155
   VUORIMAA P, 2008, SMIL TIMESHEETS 1 0
   Vuorimaa P, 2007, TIMESHEET JAVASCRIPT
NR 26
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 1229
EP 1250
DI 10.1007/s11042-012-1159-0
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900028
DA 2024-07-18
ER

PT J
AU Zhong, SH
   Liu, Y
   Liu, Y
   Chung, FL
AF Zhong, Sheng-hua
   Liu, Yan
   Liu, Yang
   Chung, Fu-lai
TI Region level annotation by fuzzy based contextual cueing label
   propagation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Label to region assignment; Contextual cueing; Fuzzy Theory
ID OBJECT; MEMORY
AB This paper investigates the challenging issue of assigning given image-level annotations to precise regions on images. We propose a novel label to region assignment (LRA) technique called Fuzzy-based Contextual-cueing Label Propagation (FCLP) with four parts: First, an image is over-segmented into a set of atomic patches and the local visual information of color features and texture features are extracted. Second, fuzzy representation and fuzzy logic are used to model spatial invariants of contextual cueing information, especially for the imprecise position information and ambiguous spatial topological relationships. Third, labels are propagated inter images and intra images in visual space and in contextual cueing space. Finally, the fuzzy C-means clustering based on K-nearest neighbor (KNN-FCM) is utilized to segment the images into semantic regions and associate with corresponding annotations. Experiments on two public datasets demonstrate the effectiveness of the proposed technique.
C1 [Zhong, Sheng-hua; Liu, Yan; Liu, Yang; Chung, Fu-lai] Hong Kong Polytech Univ, Dept Comp, Kowloon 999077, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Zhong, SH (corresponding author), Hong Kong Polytech Univ, Dept Comp, Kowloon 999077, Hong Kong, Peoples R China.
EM csshzhong@comp.polyu.edu.hk; csyliu@comp.polyu.edu.hk;
   csygliu@comp.polyu.edu.hk; cskchung@comp.polyu.edu.hk
RI Liu, Yanping/B-5266-2009; liu, yan/HGV-1365-2022
OI CHUNG, Fu Lai Korris/0000-0001-5294-8168; LIU, Yan/0000-0003-4242-4840
CR [Anonymous], 2007, ACM MULTIMEDIA, DOI DOI 10.1145/1291233.1291379
   [Anonymous], 2009, PROC 17 ACM INT C MU
   Bar M, 2004, NAT REV NEUROSCI, V5, P617, DOI 10.1038/nrn1476
   BIEDERMAN I, 1974, J EXP PSYCHOL, V103, P597, DOI 10.1037/h0037158
   Biederman I, 1982, COGNIT PSYCHOL, V14
   Chun MM, 2000, TRENDS COGN SCI, V4, P170, DOI 10.1016/S1364-6613(00)01476-5
   Chun MM, 1998, COGNITIVE PSYCHOL, V36, P28, DOI 10.1006/cogp.1998.0681
   Davenport JL, 2004, PSYCHOL SCI, V15, P559, DOI 10.1111/j.0956-7976.2004.00719.x
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Galleguillos C., 2008, OBJECT CATEGORIZATIO
   INTRAUB H, 1984, J EXP PSYCHOL LEARN, V10, P115, DOI 10.1037/0278-7393.10.1.115
   Jiang Y.-G., 2009, Proc. ACM MM, P155, DOI DOI 10.1145/1631272.1631296
   Li J, 2009, CVPR
   Meng H, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS I-V, CONFERENCE PROCEEDINGS, P88, DOI 10.1109/ICMA.2007.4303521
   MIYAJIMA K, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P100, DOI 10.1109/FUZZY.1994.343710
   POTTER MC, 1976, J EXP PSYCHOL-HUM L, V2, P509, DOI 10.1037/0278-7393.2.5.509
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Zahid N, 2001, FUZZY SET SYST
NR 18
TC 1
Z9 1
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2014
VL 70
IS 2
BP 625
EP 645
DI 10.1007/s11042-011-0954-3
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AI6OW
UT WOS:000336995900003
DA 2024-07-18
ER

PT J
AU Li, J
   Wang, RD
   Yan, DQ
   Li, YM
AF Li, Juan
   Wang, Rangding
   Yan, Diqun
   Li, Youming
TI A multipurpose audio aggregation watermarking based on multistage vector
   quantization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio aggregation; Vector quantization; Huffman coding; Multipurpose
   watermarking
ID IMAGE AUTHENTICATION; ALGORITHM
AB Watermarking technology can achieve multipurpose such as copyright protection, copy protection, and integrity authentication. We propose a novel watermarking approach which involves robust watermark and fragile watermark in a two-stage quantization technique. Traditional watermarking algorithms mostly have poor performance in imperceptibility as the codeword selected from the modified codebook is not optimal. In our method, we select the codeword in the original codebook to ensure optimality. Furthermore, we use Huffman encoding to pick up property which is sensitive to many attacks in the entire aggregation. For copyright protection, the proposed scheme can resist attacks such as lossy compression, noise addition, and normalization. As for content authentication, the proposed scheme is sensitive to various attacks provided by Stirmark Benchmark for Audio. Experimental results show that the proposed method can be used respectively for protecting the copyright and authenticating the integrity of the audio aggregation.
C1 [Li, Juan; Wang, Rangding; Yan, Diqun; Li, Youming] Ningbo Univ, Coll Informat Sci & Engn, Ningbo 315211, Zhejiang, Peoples R China.
C3 Ningbo University
RP Wang, RD (corresponding author), Ningbo Univ, Coll Informat Sci & Engn, 818 Feng Hua Rd, Ningbo 315211, Zhejiang, Peoples R China.
EM houguolei570057@yahoo.com; wangrangding@nbu.edu.cn; yandiqun@nbu.edu.cn;
   liyouming@nbu.edu.cn
RI Yan, Diqun/AAY-6775-2021
OI Yan, Diqun/0000-0002-5241-7276
FU National Natural Science Foundation of China [60873220, 61170137];
   Ministry of Education of China [20103305110002]; Zhejiang Natural
   Science Foundation of China [Y108022, Z1090622, Y1090285]; Zhejiang
   Science & Technology Preferred Projects of China [2010 C11025]; Zhejiang
   Province Education Department Key Project of China [ZD2009012]; Ningbo
   Science & Technology Preferred Projects of China [2009B10003]; Ningbo
   Key Service Professional Education Project of China [2010A610115];
   Scientific Research Fund of Zhejiang Provincial Education Department
   [Y201119434]; Key Innovation Team of Zhejiang Province [C01416124200];
   The Outstanding (Postgraduate) Dissertation Growth Foundation of Ningbo
   University [10Y20100002]; Ningbo Natural Science Foundation
   [2009A610085]; Ningbo University Foundation [XYL10002, XK1087]; High
   School Special Fields Construction of Computer Science and Technology
   [TS10860]; Zhejiang Province Excellent Course Project; Zhejiang Province
   Key Teaching Material Construction Project [ZJB2009074]; K.C. Wong Magna
   Fund in Ningbo University
FX This work is supported by the National Natural Science Foundation of
   China (60873220,61170137), Doctoral Fund of Ministry of Education of
   China(20103305110002), Zhejiang Natural Science Foundation of China
   (Y108022, Z1090622, Y1090285), Zhejiang Science & Technology Preferred
   Projects of China (2010 C11025), Zhejiang Province Education Department
   Key Project of China (ZD2009012), Ningbo Science & Technology Preferred
   Projects of China (2009B10003), Ningbo Key Service Professional
   Education Project of China (2010A610115), Scientific Research Fund of
   Zhejiang Provincial Education Department (Y201119434), Key Innovation
   Team of Zhejiang Province (C01416124200), The Outstanding (Postgraduate)
   Dissertation Growth Foundation of Ningbo University (10Y20100002) Ningbo
   Natural Science Foundation (2009A610085) and Ningbo University
   Foundation (XYL10002, XK1087). In addition, our programs are supported
   by High School Special Fields Construction of Computer Science and
   Technology (TS10860), Zhejiang Province Excellent Course Project (2007),
   Zhejiang Province Key Teaching Material Construction Project
   (ZJB2009074). This work is sponsored by K.C. Wong Magna Fund in Ningbo
   University.
CR Anderberg M.R., 1973, Probability and Mathematical Statistics
   Behnia S, 2010, COMMUN NONLINEAR SCI, V15, P2469, DOI 10.1016/j.cnsns.2009.09.042
   Biing-Hwang Juang, 1982, Proceedings of ICASSP 82. IEEE International Conference on Acoustics, Speech and Signal Processing, P597
   Bravo-Solorio S, 2011, SIGNAL PROCESS, V91, P728, DOI 10.1016/j.sigpro.2010.07.019
   Chang CC, 2009, J SYST SOFTWARE, V82, P516, DOI 10.1016/j.jss.2008.08.024
   Chen Ning, 2007, Journal of China Universities of Posts and Telecommunications, V14, P64, DOI 10.1016/S1005-8885(08)60040-0
   Chen TS, 1997, IEEE T IMAGE PROCESS, V6, P1185, DOI 10.1109/83.605415
   Dittmann J., 2006, AUDIO BENCHMARKING T
   Huang HC, 2001, ELECTRON LETT, V37, P826, DOI 10.1049/el:20010567
   Juan Li, 2011, Information Technology Journal, V10, P1001, DOI 10.3923/itj.2011.1001.1008
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Liu HY, 2008, 2008 7TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION, VOLS 1-23, P8409, DOI 10.1109/WCICA.2008.4594248
   Liu JX, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 3, PROCEEDINGS, P541, DOI 10.1109/ISDA.2008.31
   Lu CS, 2001, IEEE T IMAGE PROCESS, V10, P1579, DOI 10.1109/83.951542
   Lu ZM, 2005, IEEE T IMAGE PROCESS, V14, P822, DOI 10.1109/TIP.2005.847324
   Lu ZM, 2000, ELECTRON LETT, V36, P303, DOI 10.1049/el:20000309
   Lu ZM, 2003, ELECTRON LETT, V39, P35, DOI 10.1049/el:20030041
   MANDRIDAKE E, 1993, 1993 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS : PROCEEDINGS, VOLS 1-4 ( ISCAS 93 ), P699, DOI 10.1109/ISCAS.1993.393817
   [Perceptual Evaluation of Audio Quality ( PEAQ) ITU- R Recommendation], 1998, BS1387 ITUR
   Samiappan Dhandapani, 2011, Journal of Computer Sciences, V7, P1, DOI 10.3844/jcssp.2011.1.5
   Steinebach M, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P49, DOI 10.1109/ITCC.2001.918764
   Wang XY, 2011, J SYST SOFTWARE, V84, P1408, DOI 10.1016/j.jss.2011.03.033
   Wu HC, 2005, COMPUT SECUR, V24, P460, DOI 10.1016/j.cose.2005.05.001
   Xiong YQ, 2009, PROCEEDINGS OF THE 2009 SIXTH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS, VOLS 1-3, P366, DOI 10.1109/ITNG.2009.19
   Yun Zhou, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P4011, DOI 10.1109/CISP.2010.5648018
   Yun Zhou, 2010, 2010 2nd International Conference on Future Computer and Communication (ICFCC 2010), P1625, DOI 10.1109/ICFCC.2010.5497710
   Zanuy MF, 2001, IEEE INT C AC SPEECH, P453
   Zhao H, 2009, 2009 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTATIONAL INTELLIGENCE, VOL III, PROCEEDINGS, P299, DOI 10.1109/AICI.2009.70
   Zou DK, 2006, IEEE T CIRC SYST VID, V16, P1294, DOI 10.1109/TCSVT.2006.881857
NR 29
TC 5
Z9 5
U1 1
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2014
VL 68
IS 3
BP 571
EP 593
DI 10.1007/s11042-012-1058-4
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AA4RO
UT WOS:000331084000004
DA 2024-07-18
ER

PT J
AU Epelde, G
   Valencia, X
   Carrasco, E
   Posada, J
   Abascal, J
   Diaz-Orueta, U
   Zinnikus, I
   Husodo-Schulz, C
AF Epelde, Gorka
   Valencia, Xabier
   Carrasco, Eduardo
   Posada, Jorge
   Abascal, Julio
   Diaz-Orueta, Unai
   Zinnikus, Ingo
   Husodo-Schulz, Christian
TI Providing universally accessible interactive services through TV sets:
   implementation and validation with elderly users
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Inclusive TV; Universal remote console; Multimodal interaction;
   Interactive TV; Interactive services; Universal access; Elderly users
ID INTERFACES; VISION; HOME
AB One of the challenges that Ambient Intelligence (AmI) faces is the provision of a usable interaction concept to its users, especially for those with a weak technical background. In this paper, we describe a new approach to integrate interactive services provided by an AmI environment with the television set, which is one of the most widely used interaction client in the home environment. The approach supports the integration of different TV set configurations, guaranteeing the possibility to develop universally accessible solutions. An implementation of this approach has been carried out as a multimodal/multi-purpose natural human computer interface for elderly people, by creating adapted graphical user interfaces and navigation menus together with multimodal interaction (simplified TV remote control and voice interaction). In addition, this user interface can also be suited to other user groups. We have tested a prototype that adapts the videoconference and the information service with a group of 83 users. The results from the user tests show that the group found the prototype to be both satisfactory and efficient to use.
C1 [Epelde, Gorka; Valencia, Xabier; Carrasco, Eduardo; Posada, Jorge] Vicomtech ik4, Donostia San Sebastian 20009, Spain.
   [Abascal, Julio] Univ Basque Country, Sch Informat, Dept Comp Architecture & Technol, Donostia San Sebastian 20018, Spain.
   [Diaz-Orueta, Unai] Ingema, Donostia San Sebastian 20009, Spain.
   [Zinnikus, Ingo; Husodo-Schulz, Christian] DFKI GmbH, D-66123 Saarbrucken, Germany.
C3 University of Basque Country; German Research Center for Artificial
   Intelligence (DFKI)
RP Epelde, G (corresponding author), Vicomtech ik4, 57 Parque Tecnol, Donostia San Sebastian 20009, Spain.
EM gepelde@vicomtech.org; xvalencia@vicomtech.org; ecarrasco@vicomtech.org;
   jposada@vicomtech.org; julio.abascal@ehu.es; unai.diaz@ingema.es;
   ingo.zinnikus@dfki.de; chschulz@dfki.de
RI Posada, Jorge/A-3524-2011; Akalugwu, Kenneth/F-4815-2014; Diaz-Orueta,
   Unai/R-9802-2018; Unanue, Gorka Epelde/B-8899-2018; Abascal,
   Julio/JBS-1157-2023; Parafita, Xabier Valencia/AAJ-5792-2021; Carrasco
   Alonso, Eduardo/K-9980-2014
OI Posada, Jorge/0000-0001-7985-9915; Diaz-Orueta,
   Unai/0000-0002-0349-8890; Abascal, Julio/0000-0002-6551-1616; Parafita,
   Xabier Valencia/0000-0001-9974-1367; Carrasco Alonso,
   Eduardo/0000-0002-4908-3121; Epelde, Gorka/0000-0002-5179-415X
FU EU [FP6-030600]
FX This work was partially funded by the EU 6th Framework Program under
   grant FP6-030600 (VITAL). The opinions herein are those of the authors
   and not necessarily those of the funding agencies.
CR Abrams M, 1999, COMPUT NETW, V31, P1695, DOI 10.1016/S1389-1286(99)00044-4
   Anderson John R., 1998, The Atomic Components of Thought
   [Anonymous], 2010, 102796V111 TS ETSI
   [Anonymous], 1992, The logic of typed feature structures
   [Anonymous], 2006, 300743 EN ETSI
   [Anonymous], 2005, 1530202005 UNE AENOR
   [Anonymous], 2003, 1530102003 UNE AENOR
   Baddeley A, 2003, J COMMUN DISORD, V36, P189, DOI 10.1016/S0021-9924(03)00019-4
   Berglund A., 2006, Universal Access in the Information Society, V4, P300, DOI 10.1007/s10209-004-0108-8
   Berglund A., 2004, Universal Access in the Information Society, V3, P224, DOI 10.1007/s10209-004-0106-x
   Berglund A, 2006, TECHNICAL REPORT
   Bos B, 2011, TECHNICAL REPORT
   Boyer JM, 2009, TECHNICAL REPORT
   Carmichael A., 2003, PsychNology Journal, V1, P229
   Carmichael A, 1999, TECHNICAL REPORT
   Cesar Pablo, 2008, Foundations and Trends in Human-Computer Interaction, V2, P279, DOI 10.1561/1100000008
   Chorianopoulos K., 2006, Universal Access in The Information Society, V5, P209, DOI [DOI 10.1007/S10209-006-0032-1, 10.1007/s10209-006-0032-1]
   Diaz U, 2011, P 4 INT C PERV TECHN
   Echt KV, 2002, OLDER ADULTS, HEALTH INFORMATION, AND THE WORLD WIDE WEB, P61
   Epelde G, 2009, EUROITV'09: PROCEEDINGS OF THE SEVENTH EUROPEAN INTERACTIVE TELEVISION CONFERENCE, P111
   Eronen L., 2006, UNIVERSAL ACCESS INF, V5, P219
   Fisk A.D., 2004, DESIGNING OLDER ADUL
   Gill J, 2003, P 1 EUR C INT TEL EU, P83
   Hamisu P, 2011, LECT NOTES COMPUT SC, V6766, P32, DOI 10.1007/978-3-642-21663-3_4
   Hawthorn D, 2000, INTERACT COMPUT, V12, P507, DOI 10.1016/S0953-5438(99)00021-1
   International Organization for Standardization, 2008, 247522008 ISOIEC
   KIM SH, 2004, CHI 04 HUM FACT COMP, P1548
   Klein DJA, 2003, TECHNICAL REPORT
   Klima M, 2009, AMB INTELL SMART ENV, V1, P144, DOI 10.3233/978-1-58603-946-2-144
   Kurniawan S., 2005, Proceedings of the 7th international ACM SIGACCESS conference on Computers and accessibility, Assets'05, P129, DOI [DOI 10.1145/1090785.1090810, 10.1145/1090785.1090810]
   MCGUINNESS D, 2004, TECHNICAL REPORT
   Miller E, 2004, TECHNICAL REPORT
   Obrenovic Z, 2007, COMMUN ACM, V50, P83, DOI 10.1145/1230819.1241668
   Obrist M, 2007, LECT NOTES COMPUT SC, V4471, P66
   Peng C., 2002, THESIS HELSINKI U TE
   Pfleger N, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1778
   Puerta A., 2002, IUI 02. 2002 International Conference on Intelligent User Interfaces, P214
   Rice M., 2008, Comput Entertain, V6, P1, DOI DOI 10.1145/1350843.1350849
   Rice M. D., 2004, Proceedings of the 2nd Cambridge Workshop on Universal Access and Assistive Technology, P45
   SEGAL ES, 1996, PRACTICAL HDB CLIN G, P451
   Shirehjini AAN, 2004, COMPUT GRAPH-UK, V28, P667, DOI 10.1016/j.cag.2004.06.006
   Shirehjini AAN, 2005, P 2005 JOINT C SMART, P207
   Springett M.V., 2008, P 1 INT C DESIGNING, P49
   Springett MV, 2007, LECT NOTES COMPUT SC, V4471, P76
   Tazari MR, 2010, LECT NOTES COMPUT SC, V6439, P227, DOI 10.1007/978-3-642-16917-5_23
   Trewin S, 2004, INTERACT COMPUT, V16, P477, DOI 10.1016/j.intcom.2004.04.005
   Vatavu RD, 2012, MULTIMED TOOLS APPL, V59, P113, DOI 10.1007/s11042-010-0698-5
   Vlachogiannis E, 2011, UNIVERSAL ACCESS INF, V10, P151, DOI 10.1007/s10209-010-0195-7
   Wang SC, 2011, MULTIMED TOOLS APPL, V51, P1013, DOI 10.1007/s11042-009-0435-0
   Yang S, 2004, ETRI J, V26, P195, DOI 10.4218/etrij.04.0603.0007
   Zajicek M, 2000, BCS CONFERENCE S, P299
   Zillmann Dolf., 2000, MEDIA ENTERTAINMENT
   Zimmermann G, 2007, LECT NOTES COMPUT SC, V4551, P1040
NR 55
TC 13
Z9 13
U1 0
U2 36
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 2
BP 497
EP 528
DI 10.1007/s11042-011-0949-0
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 205HY
UT WOS:000323435800009
DA 2024-07-18
ER

PT J
AU Lee, JS
   Goldmann, L
   Ebrahimi, T
AF Lee, Jong-Seok
   Goldmann, Lutz
   Ebrahimi, Touradj
TI Paired comparison-based subjective quality assessment of stereoscopic
   images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Stereoscopic image; Subjective quality; Paired comparison; Quality of
   experience (QoE)
ID BRADLEY-TERRY MODEL; TIES
AB As 3D image and video content has gained significant popularity, subjective 3D quality assessment has become an important issue for the creation, processing, and distribution of high quality 3D content. Reliable subjective quality assessment of 3D content is often difficult due to the subjects' limited 3D experience, the interaction of multiple quality factors, minor quality differences between stimuli, etc. Among subjective evaluation methodologies, paired comparison has the advantage of improved simplicity and reliability, which can be useful to tackle the aforementioned difficulties. In this paper, we propose a new method to analyze the results of paired comparison-based subjective tests. We assume that ties convey information about the significance of quality score differences between two stimuli. Then, a maximum likelihood estimation is performed to obtain confidence intervals providing intuitive measures of significance of the quality differences. We describe the complete test procedure using the proposed method, from subjective experiment design to outlier detection and score analysis for 3D image quality assessment. Especially, we design the test procedure in a way that quality comparison across different contents is enabled while the number of pair-wise comparisons is minimized. Experimental results on a stereoscopic image database with varying camera distances demonstrate the usefulness of the proposed method and enhanced quality discriminability of paired comparison in comparison to the conventional single stimulus methodology.
C1 [Lee, Jong-Seok] Yonsei Univ, Sch Integrated Technol, Inchon 406840, South Korea.
   [Goldmann, Lutz; Ebrahimi, Touradj] Swiss Fed Inst Technol Lausanne EPFL, Multimedia Signal Proc Grp MMSPG, CH-1015 Lausanne, Switzerland.
C3 Yonsei University; Swiss Federal Institutes of Technology Domain; Ecole
   Polytechnique Federale de Lausanne
RP Lee, JS (corresponding author), Yonsei Univ, Sch Integrated Technol, Inchon 406840, South Korea.
EM jong-seok.lee@yonsei.ac.kr; lutz.goldmann@epfl.ch;
   touradj.ebrahimi@epfl.ch
RI Lee, Jong-Seok/AAF-5197-2020
OI Lee, Jong-Seok/0000-0001-5255-4425; Ebrahimi,
   Touradj/0000-0002-9900-3687
FU Ministry of Knowledge Economy, Korea, under the IT Consilience Creative
   Program [NIPA-2010-C1515-1001-0001]; Yonsei University Research Fund;
   COST Action IC1003 European Network on Quality of Experience in
   Multimedia Systems and Services (Qualinet)
FX This work was supported in part by the Ministry of Knowledge Economy,
   Korea, under the IT Consilience Creative Program
   (NIPA-2010-C1515-1001-0001), in part by Yonsei University Research Fund
   of 2011, and in part by the COST Action IC1003 European Network on
   Quality of Experience in Multimedia Systems and Services (Qualinet).
CR [Anonymous], 2010, P INT WORKSH VID PRO
   BERCOVITZ J, 1998, P SPIE, V3295
   Bosc E, 2011, IEEE J-STSP, V5, P1332, DOI 10.1109/JSTSP.2011.2166245
   BRADLEY RA, 1952, BIOMETRIKA, V39, P324, DOI 10.1093/biomet/39.3-4.324
   Chen KT, 2009, MATH COMPUT SCI ENG, P491, DOI 10.1145/1631272.1631339
   DAVIDSON RR, 1970, J AM STAT ASSOC, V65, P317, DOI 10.2307/2283595
   Eichhorn A, 2010, NOSSDAV 2010: PROCEEDINGS OF THE 20TH INTERNATIONAL WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO, P63
   Glickman ME, 1999, J ROY STAT SOC C-APP, V48, P377, DOI 10.1111/1467-9876.00159
   Gotchev A, 2011, P IEEE, V99, P708, DOI 10.1109/JPROC.2010.2103290
   Huynh-Thu Q, 2011, IEEE T BROADCAST, V57, P421, DOI 10.1109/TBC.2011.2128250
   Huynh-Thu Q, 2010, IEEE IMAGE PROC, P4025, DOI 10.1109/ICIP.2010.5650571
   IJsselsteijn WA, 2000, IEEE T CIRC SYST VID, V10, P225, DOI 10.1109/76.825722
   International Telecommunication Union, 2000, SUBJ ASS STER TEL PI
   International Telecommunication Union, 2002, METH SUBJ ASS QUAL T
   Jumisko-Pyykkö S, 2011, MULTIMED TOOLS APPL, V55, P185, DOI 10.1007/s11042-010-0573-4
   Kooi FL, 2004, DISPLAYS, V25, P99, DOI 10.1016/j.displa.2004.07.004
   Lee J.-S., 2010, Proceedings of ACM international conference on Multimedia, MULTIMEDIA '10, P65, DOI DOI 10.1145/1873951.1873981
   Liu XA, 2012, FUTURE GENER COMP SY, V28, P947, DOI 10.1016/j.future.2011.05.013
   Meesters LMJ, 2004, IEEE T CIRC SYST VID, V14, P381, DOI 10.1109/TCSVT.2004.823398
   P ITU-T RECOMMENDATION, 1999, SUBJ VID QUAL ASS ME
   RAO PV, 1967, J AM STAT ASSOC, V62, P194, DOI 10.2307/2282923
   Seuntiens P., 2006, ACM T APPL PERCEPT, V3, P95
   Smolic A, 2011, P IEEE, V99, P607, DOI 10.1109/JPROC.2010.2098350
   Zilly F, 2011, P IEEE, V99, P590, DOI 10.1109/JPROC.2010.2095810
NR 24
TC 103
Z9 106
U1 2
U2 32
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2013
VL 67
IS 1
BP 31
EP 48
DI 10.1007/s11042-012-1011-6
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 196PN
UT WOS:000322787800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hwang, M
   Jeong, DH
   Kim, J
   Song, SK
   Jung, H
   Shin, J
   Kim, P
AF Hwang, Myunggwon
   Jeong, Do-Heon
   Kim, Jinhyung
   Song, Sa-Kwang
   Jung, Hanmin
   Shin, Juhyun
   Kim, Pankoo
TI A term normalization method for efficient knowledge acquisition through
   text processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Term normalization; Knowledge acquisition; Text mining; Appearance
   similarity; Context similarity
ID SIMILARITY MEASURE; RECOGNITION; INFORMATION; COMMUNITY
AB The importance of research on knowledge management is growing due to recent issues on Big Data. One of the most fundamental steps in knowledge management is the extraction of terminologies. Terms are often expressed in various forms and the variations often play a negative role, becoming an obstacle which causes knowledge systems to extract unnecessary ones. To solve the problem, we propose a method of term normalization which finds a normalized form (original and standard form defined in dictionaries) of variant terms. The method employs two characteristics of terms: appearance similarity measuring how similar terms are, context similarity measuring how many clue words they share. Through experiment, we show its positive influence of both similarities in term normalization.
C1 [Hwang, Myunggwon; Kim, Jinhyung] Korea Inst Sci & Technol Informat KISTI, Dept Software Res, Taejon, South Korea.
   [Jeong, Do-Heon] Korea Inst Sci & Technol Informat KISTI, Analyt Serv Dev Team, Software Res Ctr, Taejon, South Korea.
   [Jung, Hanmin] Korea Inst Sci & Technol Informat KISTI, Taejon, South Korea.
   [Shin, Juhyun; Kim, Pankoo] Chosun Univ, Dept Comp Engn, Kwangju, South Korea.
C3 Korea Institute of Science & Technology (KIST); Korea Institute of
   Science & Technology Information (KISTI); Korea Institute of Science &
   Technology (KIST); Korea Institute of Science & Technology Information
   (KISTI); Korea Institute of Science & Technology Information (KISTI);
   Korea Institute of Science & Technology (KIST); Chosun University
RP Jeong, DH (corresponding author), 245 Daehak Ro, Taejon 305806, South Korea.
EM mg.hwang@gmail.com; heon@kisti.re.kr; jinhyung@kisti.re.kr;
   esmallj@kisti.re.kr; jhm@kisti.re.kr; jhshinkr@chosun.ac.kr;
   pkkim@chosun.ac.kr
RI Shin, Juhyun/ITW-2431-2023
OI Shin, Juhyun/0000-0003-0568-9743
CR Bawakid A., 2010, P IEEE INT C CYB INT, P1
   Brank J, 2008, J UNIVERS COMPUT SCI, V14, P1562
   Dowdall J., 2003, P ACL 2003 WORKSHOP, P1
   Duong TH, 2009, J UNIVERS COMPUT SCI, V15, P877
   Fogarolli A, 2009, 2009 IEEE THIRD INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING (ICSC 2009), P77, DOI 10.1109/ICSC.2009.7
   Hwang M, 2012, INT C ART INT SOFT C, P682
   Hwang M, 2010, INFORMATION-TOKYO, V13, P253
   Hwang M, 2010, INFORMATION-TOKYO, V13, P1599
   Hwang M, 2009, INT J SEMANT WEB INF, V5, P48, DOI 10.4018/jswis.2009010102
   Ibekwe-Sanjuan F., 1998, P INT C COMP LING, V1, P564
   Jung H, 2005, INFORM PROCESS MANAG, V41, P217, DOI 10.1016/S0306-4573(03)00066-9
   Jung JJ, 2012, EXPERT SYST APPL, V39, P8066, DOI 10.1016/j.eswa.2012.01.136
   Jung JJ, 2012, COMPUT J, V55, P337, DOI 10.1093/comjnl/bxr102
   Jung JJ, 2010, INFORM SCIENCES, V180, P3248, DOI 10.1016/j.ins.2010.04.018
   Jung JJ, 2009, EXPERT SYST APPL, V36, P11013, DOI 10.1016/j.eswa.2009.02.086
   PORTER MF, 1980, PROGRAM-AUTOM LIBR, V14, P130, DOI 10.1108/eb046814
   Song SK, 2011, COMM COM INF SC, V264, P233
   Toutanova K, 2000, PROCEEDINGS OF THE 2000 JOINT SIGDAT CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND VERY LARGE CORPORA, P63, DOI 10.3115/1117794.1117802
   Tsai RTH, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-S5-S11
   Velardi P, 2007, IEEE T KNOWL DATA EN, V19, P180, DOI 10.1109/TKDE.2007.21
NR 20
TC 1
Z9 2
U1 0
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2013
VL 65
IS 1
BP 75
EP 91
DI 10.1007/s11042-012-1144-7
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 126OI
UT WOS:000317626800006
DA 2024-07-18
ER

PT J
AU Choi, K
   Jo, S
   Lee, H
   Jeong, C
AF Choi, Kiyoung
   Jo, Sungup
   Lee, Hwamin
   Jeong, Changsung
TI CPU-based speed acceleration techniques for shear warp volume rendering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CPU-based speed acceleration technique; Shear warp algorithm; Volume
   rendering
AB The shear-warp algorithm with run-length-encoded volume is one of the fastest CPU-based speed acceleration techniques developed so far for direct volume rendering. But it has some defects, such as the increases in memory consumption and preprocessing time as well as the deterioration in image quality. This paper provides two kinds of techniques that can solve such defects without degrading rendering speed. One technique concentrates on enhancing image quality and decreasing memory consumption without reducing rendering speed, by making direct access to the memory space where initially loaded volume data is stored. The other technique concentrates on accelerating rendering speed and decreasing preprocessing time, by creating only one run-length-encoded volume and by combining non-photorealistic rendering techniques with shear-warp algorithm. In the present research, both techniques efficiently decreased the memory consumption and preprocessing time of shear-warp algorithm. They also showed optimal results in rendering speed and image quality.
C1 [Choi, Kiyoung; Jo, Sungup] Korea Univ, Sch Elect Engn, Radio Engn Lab 203, Seoul, South Korea.
   [Lee, Hwamin] Soonchunhyang Univ, Dept Comp Software Engn, Asan, Chungnam, South Korea.
   [Jeong, Changsung] Korea Univ, Sch Elect Engn, Seoul, South Korea.
C3 Korea University; Soonchunhyang University; Korea University
RP Jeong, C (corresponding author), Korea Univ, Sch Elect Engn, 721 Engn Bldg,Anam Campus,Anam Dong 5 Ga, Seoul, South Korea.
EM 2xx195@korea.ac.kr; easyup@korea.ac.kr; leehm@sch.ac.kr;
   csjeong@korea.ac.kr
RI Lee, HwaMin/AAM-7102-2020
OI Lee, HwaMin/0000-0002-6482-3511
FU MKE(Ministry of Knowledge Economy), Korea, under the ITRC(Information
   Technology Research Center) support program [NIPA-2010-C1090-1001-0008];
   Future-based Technology Development Program through the National
   Research Foundation of Korea(NRF); Ministry of Education, Science and
   Technology [2010-0020-732]; Korea University
FX This research was supported by MKE(Ministry of Knowledge Economy),
   Korea, under the ITRC(Information Technology Research Center) support
   program supervised by the NIPA(National IT Industry Promotion Agency)
   (NIPA-2010-C1090-1001-0008), Future-based Technology Development Program
   through the National Research Foundation of Korea(NRF) funded by the
   Ministry of Education, Science and Technology(2010-0020-732), a Brain
   Korea 21 project and a grant of Korea University.
CR [Anonymous], J CONVERG
   [Anonymous], J CONVERGENCE
   Bentoumi H, 2010, INT J ELECT ELECT EN, V4, P1
   Busking S, 2008, VISUAL COMPUT, V24, P335, DOI 10.1007/s00371-007-0192-x
   Camerojn G. G., 1992, Proceedings of the Third Eurographics Workshop on Rendering, P135
   Csébfalvi B, 2001, COMPUT GRAPH FORUM, V20, pC452, DOI 10.1111/1467-8659.00538
   Drebin R. A., 1988, Computer Graphics, V22, P65, DOI 10.1145/378456.378484
   Grimm S, 2004, P IEEE S VOL VIS GRA
   Hiller S, 2003, COMPUT GRAPH FORUM, V22, P515, DOI 10.1111/1467-8659.00699
   KAUFMAN A, 1993, COMPUTER, V26, P51, DOI 10.1109/MC.1993.274942
   Koning AHJ, 2011, P VIS BIOM COMP CHAP, P324
   Krueger J, 2003, P IEEE VIS
   Kye H, 2005, COMPUT ANIMAT VIRT W, V16, P547, DOI 10.1002/cav.67
   Lacroute P., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P451, DOI 10.1145/192161.192283
   LEVOY M, 1988, IEEE COMPUT GRAPH, V8, P29, DOI 10.1109/38.511
   Lu AD, 2003, IEEE T VIS COMPUT GR, V9, P127, DOI 10.1109/TVCG.2003.1196001
   Lu AD, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P211, DOI 10.1109/VISUAL.2002.1183777
   Reottger S., 2003, Data Visualisation 2003. Joint Eurographics/IEEE TCVG. Symposium on Visualization, P231
   Sathappan O. L., 2011, International Journal of Information Technology, Communications and Convergence, V1, P146, DOI 10.1504/IJITCC.2011.039282
   Schroder P, 2003, P 1992 WORKSH VOL VI, P25
   Stegmaier S, 2005, VOLUME GRAPHICS 2005, P187
   Strothotte T, 2002, NONPHOTOREALISTIC CO
   Surendran D., 2011, International Journal of Information Technology, Communications and Convergence, V1, P159, DOI 10.1504/IJITCC.2011.039283
   Sweeney Jon., 2002, PROC S DATA VISUALIS, P95
   Udupa JK, 2011, IEEE COMPUT GRAPH, V58
   Westover L., 1990, Computer Graphics, V24, P367, DOI 10.1145/97880.97919
   Yagel R, 2011, EUR 92 CAMBR UK, V92, pC
NR 27
TC 2
Z9 3
U1 0
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2013
VL 64
IS 2
BP 309
EP 329
DI 10.1007/s11042-012-1010-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 116IM
UT WOS:000316876200006
DA 2024-07-18
ER

PT J
AU Ding, JH
   Wang, YG
   Geng, WD
AF Ding, Jianhao
   Wang, Yigang
   Geng, Weidong
TI An HOG-CT human detector with histogram-based search
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human detection; Histogram-based search; Cascade classifier; Feature
   extraction
AB This paper addresses the problem of human detection in still images. We first describe a novel descriptor concatenating the local normalized histogram of oriented gradients (HOG) and the global normalized histogram of census transform (CT) of images for human detection. The detector is trained by using cascade learning method based on AdaBoost. In addition, we propose an easy histogram-based search method, termed the block histogram, which can reduce the computational cost and speed up the process of detection when sliding in the test image. Experimental results on the INRIA person dataset show that the proposed method can achieve competitive results both in discriminating power and detection speed as compared to the state-of-the-art.
C1 [Ding, Jianhao; Geng, Weidong] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
   [Ding, Jianhao; Wang, Yigang] Hangzhou Dianzi Univ, Inst Comp Graph & Image Proc, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University; Hangzhou Dianzi University
RP Ding, JH (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou 310003, Zhejiang, Peoples R China.
EM djh@hdu.edu.cn
CR [Anonymous], 2009, ICCV
   [Anonymous], 2007, CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], 2009, CVPR
   [Anonymous], 10 EUR C COMP VIS MA
   [Anonymous], CVPR
   [Anonymous], IEEE COMP SOC INT C
   [Anonymous], 2009, ICCV
   [Anonymous], 2009, ICCV
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], CVPR
   [Anonymous], 2004, ICPR
   [Anonymous], 2007, CVPR
   [Anonymous], 2005, ICCV
   [Anonymous], CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], DAGM
   Begard J., 2008, CVPR WORKSH
   Chen YT, 2008, IEEE T IMAGE PROCESS, V17, P1452, DOI 10.1109/TIP.2008.926152
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maji S., 2009, ICCV
   Mu Y., 2008, CVPR
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Sabzmeydani P., 2007, CVPR
   Schwartz WilliamRobson., 2009, ICCV
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI [10.1109/CVPR.2001.990517, DOI 10.1109/CVPR.2001.990517]
   Watanabe Tomoki, 2010, Information and Media Technologies, V5, P659
   Wei Yichen., 2010, CVPR
   Wu B., 2008, CVPR
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Xiangsheng Huang, 2004, Proceedings. Third International Conference on Image and Graphics, P184
   Zabih Ramin, 1996, PAMI
   Zhang Wei., 2007, ICCV
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 40
TC 4
Z9 5
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2013
VL 63
IS 3
BP 791
EP 807
DI 10.1007/s11042-011-0896-9
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 110YF
UT WOS:000316483000009
DA 2024-07-18
ER

PT J
AU Chouvatut, V
   Madarasmi, S
   Tuceryan, M
AF Chouvatut, Varin
   Madarasmi, Suthep
   Tuceryan, Mihran
TI 3D face and motion estimation from sparse points using adaptive
   bracketed minimization
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Camera pose; Gradient descent; Model reconstruction; Powell's
   multidimensional minimization
ID RECONSTRUCTION
AB This paper presents a novel method for estimating camera motion and reconstructing human face from a video sequence. The coarse-to-fine method is applied via combining the concepts of Powell's minimization with gradient descent. Sparse points defining the human face in every frame are tracked using the active appearance model. The case of occluded points, even for self-occlusion, does not pose a problem in the proposed method. Robustness in the presence of noise and 3D accuracy using this method is also demonstrated. Examples of face reconstruction using other methods including trifocal tensor, Powell's minimization, and gradient descent are also compared to the proposed method. Experiments on both synthetic and real faces are presented and analyzed. Also, different camera movement paths are illustrated. All real-world experiments used an off-the-shelf digital camera carried by a human walking without using any dolly to demonstrate the robustness and practicality of the proposed method.
C1 [Chouvatut, Varin; Madarasmi, Suthep] King Mongkuts Univ Technol Thonburi, Dept Comp Engn, Bangkok, Thailand.
   [Tuceryan, Mihran] Indiana Univ Purdue Univ, Comp & Informat Sci Dept, Indianapolis, IN 46202 USA.
C3 King Mongkuts University of Technology Thonburi; Indiana University
   System; Indiana University Indianapolis
RP Chouvatut, V (corresponding author), King Mongkuts Univ Technol Thonburi, Dept Comp Engn, Bangkok, Thailand.
EM varin@cpe.kmutt.ac.th; suthep@kmutt.ac.th; tuceryan@cs.iupui.edu
RI Tuceryan, Mihran/O-8134-2019; Tuceryan, Mihran/C-6893-2011
OI Tuceryan, Mihran/0000-0003-3828-6123; Chouvatut,
   Varin/0009-0008-9125-4650
CR [Anonymous], WORLD ACAD SCI ENG T
   [Anonymous], 2002, ALGORITHMS MINIMIZAT
   Avidan S, 1998, IEEE T VIS COMPUT GR, V4, P293, DOI 10.1109/2945.765324
   Bozek J, 2010, ELMAR PROC, P1
   Chen OTC, 2000, IEEE T CIRC SYST VID, V10, P608, DOI 10.1109/76.845006
   Chouvatut V, 2010, COMM COM INF SC, V54, P282
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Galpin F, 2002, EURASIP J APPL SIG P, V2002, P1088, DOI 10.1155/S1110865702206095
   Hartley R., 2006, Multiple view geometry in computer vision, V2nd
   HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005
   Karayiannis NB, 1999, IEEE T NEURAL NETWOR, V10, P657, DOI 10.1109/72.761725
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Li J., 2005, P IEEE WORKSHOP MOTI, P154
   Okuma T, 2000, INT C PATT RECOG, P482, DOI 10.1109/ICPR.2000.902962
   Parker Susan, 2008, Canaveral National Seashore: Historic Resource Study, P1
   Po LM, 2009, IEEE T CIRC SYST VID, V19, P1189, DOI 10.1109/TCSVT.2009.2020320
   Press W. H., 2007, NUM REC ART SCI COMP
   Repko J, 2005, IEEE C 3 D DIG IM MO
   SMOLIC A, 2002, 4 EURASIP IEEE REG 8, P431
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Xu XY, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P732
   Zheng Y, 2007, IEEE INT C IM PROC I, V3
   Zheng Y, 2008, IEEE IMAGE PROC, P1516, DOI 10.1109/ICIP.2008.4712055
NR 24
TC 3
Z9 3
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2013
VL 63
IS 2
BP 569
EP 589
DI 10.1007/s11042-011-0925-8
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 105MH
UT WOS:000316074200013
DA 2024-07-18
ER

PT J
AU Lee, M
   Lee, K
   Park, J
AF Lee, Minho
   Lee, Kyogu
   Park, Jaeheung
TI Music similarity-based approach to generating dance motion sequence
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Choreography; Dance motion generation; Music similarity; Music-motion
   database; Motion capture; Motion synthesis
AB In this paper, we propose a novel approach to generating a sequence of dance motions using music similarity as a criterion to find the appropriate motions given a new musical input. Based on the observation that dance motions used in similar musical pieces can be a good reference in choreographing a new dance, we first construct a music-motion database that comprises a number of segment-wise music-motion pairs. When a new musical input is given, it is divided into short segments and for each segment our system suggests the dance motion candidates by finding from the database the music cluster that is most similar to the input. After a user selects the best motion segment, we perform music-dance synchronization by means of cross-correlation between the two music segments using the novelty functions as an input. We evaluate our system's performance using a user study, and the results show that the dance motion sequence generated by our system achieves significantly higher ratings than the one generated randomly.
C1 [Lee, Minho; Lee, Kyogu; Park, Jaeheung] Seoul Natl Univ, Adv Inst Convergence Technol, Grad Sch Convergence Sci & Technol, Seoul, South Korea.
C3 Seoul National University (SNU)
RP Lee, K (corresponding author), Seoul Natl Univ, Adv Inst Convergence Technol, Grad Sch Convergence Sci & Technol, Seoul, South Korea.
EM setiem@snu.ac.kr; kglee@snu.ac.kr; park73@snu.ac.kr
RI Lee, Kyogu/D-3049-2013; Park, Jaeheung/IXD-1501-2023; Park,
   Jaeheung/D-3032-2013
FU Advanced Institutes of Convergence Technology (AICT) [2011-P3-15]
FX This study was supported by the grant (No. 2011-P3-15) of Advanced
   Institutes of Convergence Technology (AICT). Also, we greatly
   acknowledge Dr. Junghoon Kwon for his help on the use of the motion
   capture system.
CR Alankus G, 2005, COMPUT ANIMAT VIRT W, V16, P259, DOI 10.1002/cav.99
   Bartsch MA, 2001, PROCEEDINGS OF THE 2001 IEEE WORKSHOP ON THE APPLICATIONS OF SIGNAL PROCESSING TO AUDIO AND ACOUSTICS, P15, DOI 10.1109/ASPAA.2001.969531
   Foote J, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P452, DOI 10.1109/ICME.2000.869637
   Foote J, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P77, DOI 10.1145/319463.319472
   Gray JM, 1975, THESIS STANFORD U ST
   Grunberg D., 2009, Proceedings of the 2009 International Conference on Hybrid Information Technology, P221
   K-C Loi, 2009, P APSIPA ANN SUMM C, P216
   Kang KK, 2007, LECT NOTES COMPUT SC, V4569, P216
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kim JW, 2009, COMPUT ANIMAT VIRT W, V20, P375, DOI 10.1002/cav.314
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   Nakahara N, 2009, LECT NOTES COMPUT SC, V5709, P36, DOI 10.1007/978-3-642-04052-8_4
   Nakaoka S, 2010, IEEE INT C INT ROBOT, P1675, DOI 10.1109/IROS.2010.5649038
   Ofli F, 2010, INT CONF ACOUST SPEE, P2466, DOI 10.1109/ICASSP.2010.5494891
   Sandholm A, 2009, LECT NOTES COMPUT SC, V5903, P110, DOI 10.1007/978-3-642-10470-1_10
   Sauer D, 2009, ACM T MULTIM COMPUT, V5, DOI 10.1145/1596990.1596991
   Shiratori T, 2008, IPSJ ONLINE T, V1, P80
   Shiratori T, 2006, COMPUT GRAPH FORUM, V25, P449, DOI 10.1111/j.1467-8659.2006.00964.x
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
NR 19
TC 35
Z9 38
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2013
VL 62
IS 3
BP 895
EP 912
DI 10.1007/s11042-012-1288-5
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 086VF
UT WOS:000314715500016
DA 2024-07-18
ER

PT J
AU Teixeira, RMA
   Yamasaki, T
   Aizawa, K
AF Teixeira, Rene Marcelino Abritta
   Yamasaki, Toshihiko
   Aizawa, Kiyoharu
TI Determination of emotional content of video clips by low-level
   audiovisual features A dimensional and categorial experimental approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Affective processing; Categorial models; Dimensional models
ID CONTENT REPRESENTATION; RECOGNITION; SEGMENTATION; AUDIO; FRAMEWORK;
   COLOR
AB Affective analysis of video content has greatly increased the possibilities of the way we perceive and deal with media. Different kinds of strategies have been tried, but results are still opened to improvements. Most of the problems come from the lack of standardized test set and real affective models. In order to cope with these issues, in this paper we describe the results of our work on the determination of affective models for evaluation of video clips using audiovisual low-level features. The affective models were developed following two classes of psychological theories of affect: categorial and dimensional. The affective models were created from real data, acquired through a series of user experiments. They reflect the affective state of a viewer after watching a certain scene from a movie. We evaluate the detection of Pleasure, Arousal and Dominance coefficients as well as the detection rate of six affective categories. For this end, two Bayesian network topologies are used, a Hidden Markov Model and an Autoregressive Hidden Markov Model. The measurements were done using audio-only models, video-only models and fused models. Fusion is done using two different methods, a Decision Level Fusion and Feature Level Fusion. All tests were conducted using localized affective models, both categorial and dimensional. Results are presented in terms of detection rate and accuracy for affective families, affective dimensions and probabilistic networks. Arousal was the best detected dimension, followed by dominance and pleasure.
C1 [Teixeira, Rene Marcelino Abritta; Yamasaki, Toshihiko] Univ Tokyo, Dept Informat & Commun Engn, Grad Sch Informat Sci & Technol, Tokyo, Japan.
   [Aizawa, Kiyoharu] Univ Tokyo, Interfac Initiat Informat Studies, Tokyo, Japan.
C3 University of Tokyo; University of Tokyo
RP Teixeira, RMA (corresponding author), Univ Tokyo, Dept Informat & Commun Engn, Grad Sch Informat Sci & Technol, Tokyo, Japan.
EM rene@hal.t.u-tokyo.ac.jp; yamasaki@hal.t.u-tokyo.ac.jp;
   aizawa@hal.t.u-tokyo.ac.jp
CR Akira I, 2009, PLUTCHIKS WHEEL EMOT
   [Anonymous], 1997, Circumplex models of personality and emotions, DOI [10.1037/10261-001, DOI 10.1037/10261-001]
   [Anonymous], 2005, INT JOINT C AUTONOMO, DOI DOI 10.1145/1082473.1082478
   Arifin S., 2007, Proceedings of the 15th International Conference on Multimedia, P68
   Arifin S, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P147, DOI 10.1109/ICSC.2007.22
   Bradley M., 1994, J. Behav. Ther. Exp. Psychiat, V25, P49, DOI [DOI 10.1016/0005-7916(94)90063-9, 10.1016/0005-7916, 10.1016/0005-7916(94)90063-9]
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   Bulut M., 2004, P 6 INT C MULT INT, P205
   Collins A, 1990, The cognitive structure of emotions
   Corporation I, 2003, PROB NETW LIB US GUI
   Dailianas A, 1996, P SOC PHOTO-OPT INS, V2615, P2, DOI 10.1117/12.229193
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   Ekman P., 2000, Handbook of cognition and emotion pp, P45, DOI 10.1002/0470013494.ch3
   Gargi U, 2000, IEEE T CIRC SYST VID, V10, P1, DOI 10.1109/76.825852
   Gerhard D, 2003, 6 TRCS U REG
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Herrera P., 2002, Music and Artificial Intelligence. Second International Conference, ICMAI 2002. Proceedings (Lecture Notes in Artificial Intelligence Vol.2445), P69, DOI 10.1007/3-540-45722-4_8
   Irie G, 2009, IEEE INT CON MULTI, P522, DOI 10.1109/ICME.2009.5202548
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jensen K., 1999, TIMBRE MODELS MUSICA
   Krimphoff J., 1994, J PHYS S, VIII, pC5, DOI DOI 10.1051/JP4:19945134
   Lang P. J., 1997, NIMH CTR STUDY EMOTI, V1, P39
   Lu L, 2006, IEEE T AUDIO SPEECH, V14, P5, DOI 10.1109/TSA.2005.860344
   Lu L, 2003, MULTIMEDIA SYST, V8, P482, DOI 10.1007/s00530-002-0065-0
   MEHRABIAN A, 1995, GENET SOC GEN PSYCH, V121, P339
   Mehrabian A, 1996, CURR PSYCHOL, V14, P261, DOI 10.1007/BF02686918
   Morris JD, 1995, J ADVERTISING RES, V35, P63
   Murphy Kevin Patrick, 2002, Dynamic bayesian networks: representation, inference and learning
   Osgood C. E., 1957, The measurement of meaning
   Ou LC, 2004, COLOR RES APPL, V29, P232, DOI 10.1002/col.20010
   Peeters G., 2004, CUIDADO Ist Project Report, V54, P1
   Pollard H.F., 1982, ACUSTICA, V51
   Rasheed Z, 2005, IEEE T CIRC SYST VID, V15, P52, DOI 10.1109/TCSVT.2004.839993
   REISENZEIN R, 1994, J PERS SOC PSYCHOL, V67, P525, DOI 10.1037/0022-3514.67.3.525
   Reisenzein R., 1992, The structuralist program in psychology: Foundations and applications, P141
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Saastamoinen J, 2005, EURASIP J APPL SIG P, V2005, P2816, DOI 10.1155/ASP.2005.2816
   Sebe N, 2006, INT C PATT RECOG, P1136
   Sun K, 2007, LECT NOTES COMPUT SC, V4738, P594
   VALDEZ P, 1994, J EXP PSYCHOL GEN, V123, P394, DOI 10.1037/0096-3445.123.4.394
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Xu M., 2008, Proceeding of the 16th ACM International Conference on Multimedia, P677, DOI DOI 10.1145/1459359.1459457
   Xu M, 2005, IEEE INT C MULT EXP, P121
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 46
TC 32
Z9 33
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2012
VL 61
IS 1
BP 21
EP 49
DI 10.1007/s11042-010-0702-0
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 973FP
UT WOS:000306345000003
DA 2024-07-18
ER

PT J
AU Le Borgne, H
   Honnorat, N
AF Le Borgne, Herve
   Honnorat, Nicolas
TI Fast shared boosting for large-scale concept detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Boosting; Content based retrieval; Classification; Imageclef; Visual
   concept detection
AB Visual concept detection consists in assigning labels to an image or keyframe based on its semantic content. Visual concepts are usually learned from an annotated image or video database with a machine learning algorithm, posing this problem as a multiclass supervised learning task. Some practical issues appear when the number of concept grows, in particular in terms of available memory and computing time, both for learning and testing. To cope with these issues, we propose to use a multiclass boosting algorithm with feature sharing and reduce its computational complexity with a set of efficient improvements. For this purpose, we explore a limited part of the possible parameter space, by adequately injecting randomness into the crucial steps of our algorithm. This makes our algorithm able to handle a problem of classification with many classes in a reasonable time, thanks to a linear complexity with regards to the number of concepts considered as well as the number of feature and their size. The relevance of our algorithm is evaluated in the context of information retrieval, on the benchmark proposed into the ImageCLEF international evaluation campaign and shows competitive results.
C1 [Le Borgne, Herve] CEA, LIST, Lab Vis & Content Engn, F-92265 Fontenay Aux Roses, France.
   [Honnorat, Nicolas] Ecole Cent Paris, MAS Lab, Chatenay Malabry, France.
C3 CEA; Universite Paris Saclay; Universite Paris Saclay
RP Le Borgne, H (corresponding author), CEA, LIST, Lab Vis & Content Engn, 18 Route Panorama,BP6, F-92265 Fontenay Aux Roses, France.
EM herve.le-borgne@cea.fr; nicolas.honnorat@ecp.fr
FU ANR; DGCIS
FX We would like to thank the two reviewers for their fruitful comments. We
   acknowledge support from the ANR (project Yoji) and the DGCIS for
   funding us through the regional business cluster Cap Digital (projects
   Georama and Romeo).
CR [Anonymous], CLEF WORKING NOTES
   [Anonymous], CLEF WORKING NOTES
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2004, ECCV INT WORKSH STAT
   [Anonymous], 2007, VIS REC CHALL WORKSH
   [Anonymous], CORESA TOUL FRANC
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], SPIE ELECTRONICIMAGI
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Breiman L., 2001, Mach. Learn., V45, P5
   Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263
   Efron B., 1993, INTRO BOOTSTRAP, VVolume 914, DOI DOI 10.1007/978-1-4899-4541-9
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   FREUND Y, 1995, INFORM COMPUT, V121, P256, DOI 10.1006/inco.1995.1136
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   Lazebnik S., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.68
   Le Borgne H, 2007, IEEE T CIRC SYST VID, V17, P286, DOI 10.1109/TCSVT.2007.890635
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perronnin F., 2007, IEEE C COMPUTER VISI
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   SCHAPIRE RE, 1990, MACH LEARN, V5, P197, DOI 10.1023/A:1022648800760
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 26
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 389
EP 402
DI 10.1007/s11042-010-0607-y
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400008
DA 2024-07-18
ER

PT J
AU Li, BH
   Liu, SY
   Li, ZG
AF Li, Bing Han
   Liu, San Yang
   Li, Zhan Guo
TI Improved algorithm based on mutual information for learning Bayesian
   network structures in the space of equivalence classes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Data mining; Bayesian network; Structure learning; Mutual information;
   Conditional independence test
ID DIAGNOSIS
AB As is well known, greedy algorithm is usually used as local optimization method in many heuristic algorithms such as ant colony optimization, taboo search, and genetic algorithms, and it is significant to increase the convergence speed and learning accuracy of greedy search in the space of equivalence classes of Bayesian network structures. An improved algorithm, I-GREEDY-E is presented based on mutual information and conditional independence tests to firstly make a draft about the real network, and then greedily explore the optimal structure in the space of equivalence classes starting from the draft. Numerical experiments show that both the BIC score and structure error have some improvement, and the number of iterations and running time are greatly reduced. Therefore the structure with highest degree of data matching can be relatively faster determined by the improved algorithm.
C1 [Li, Bing Han; Liu, San Yang] Xian Elect & Sci Univ, Dept Sci, Xian 710071, Peoples R China.
   [Li, Zhan Guo] Xi An Jiao Tong Univ, Dept Mech Engn, Xian 710049, Peoples R China.
C3 Xidian University; Xi'an Jiaotong University
RP Li, BH (corresponding author), Xian Elect & Sci Univ, Dept Sci, Xian 710071, Peoples R China.
EM binghan2020@126.com
CR [Anonymous], P 2 INT C ART INT SC
   Beiser JA, 1997, IEEE T RELIAB, V46, P291, DOI 10.1109/24.589959
   Bromberg F, 2006, SIAM PROC S, P141
   Chen XW, 2008, IEEE T KNOWL DATA EN, V20, P628, DOI 10.1109/TKDE.2007.190732
   Chickering D. M., 2003, Journal of Machine Learning Research, V3, P507, DOI 10.1162/153244303321897717
   Chickering D. M., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P87
   Chickering D.M., 1994, LEARNING BAYESIAN NE
   Chickering DM, 2002, J MACH LEARN RES, V2, P445, DOI 10.1162/153244302760200696
   Chickering DM, 1995, PREL PAP 5 INT WORKS
   Dong XC, 2010, THIRD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING: WKDD 2010, PROCEEDINGS, P466, DOI 10.1109/WKDD.2010.84
   HANSEN JF, 1980, DAN MED BULL, V27, P280
   Heckerman D, 2008, STUD COMPUT INTELL, V156, P33
   Huang Z, 2007, DECIS SUPPORT SYST, V43, P1207, DOI 10.1016/j.dss.2006.02.002
   Ji Jun-Zhong, 2009, Acta Automatica Sinica, V35, P281, DOI 10.3724/SP.J.1004.2009.00281
   Jing Zhao, 2009, Proceedings of the 2009 Fifth International Conference on Natural Computation (ICNC 2009), P86, DOI 10.1109/ICNC.2009.297
   Kojima K, 2010, J MACH LEARN RES, V11, P285
   Larranaga P, 1996, IEEE T SYST MAN CY A, V26, P487, DOI 10.1109/3468.508827
   Larranaga P, 1996, IEEE T PATTERN ANAL, V18, P912, DOI 10.1109/34.537345
   Lobona B, 2010, EXPERT SYST APPL, V37, P5470
   MADIGAN D, 1995, INT STAT REV, V63, P215, DOI 10.2307/1403615
   Pinto PC, 2009, IEEE T EVOLUT COMPUT, V13, P767, DOI 10.1109/TEVC.2009.2024142
   Proakis J., 2008, Digital Communication, Vthird
   Rangarajan A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P671
   Ronan D, 2009, J ARTIF INTELL RES, V35, P391
   Studeny M, 2009, INT J APPROX REASON, V50, P385, DOI 10.1016/j.ijar.2008.09.001
   Wolbrecht E, 2000, AI EDAM, V14, P53, DOI 10.1017/S0890060400141058
NR 26
TC 6
Z9 12
U1 0
U2 24
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 1
BP 129
EP 137
DI 10.1007/s11042-011-0801-6
PG 9
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 951FY
UT WOS:000304707500006
DA 2024-07-18
ER

PT J
AU Vieux, R
   Benois-Pineau, J
   Domenger, JP
   Braquelaire, A
AF Vieux, Remi
   Benois-Pineau, Jenny
   Domenger, Jean-Philippe
   Braquelaire, Achille
TI Segmentation-based multi-class semantic object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Segmentation; Relaxation labelling; Late fusion; SVM
ID IMAGE SEGMENTATION; RETRIEVAL
AB In this paper we study the problem of the detection of semantic objects from known categories in images. Unlike existing techniques which operate at the pixel or at a patch level for recognition, we propose to rely on the categorization of image segments. Recent work has highlighted that image segments provide a sound support for visual object class recognition. In this work, we use image segments as primitives to extract robust features and train detection models for a predefined set of categories. Several segmentation algorithms are benchmarked and their performances for segment recognition are compared. We then propose two methods for enhancing the segments classification, one based on the fusion of the classification results obtained with the different segmentations, the other one based on the optimization of the global labelling by correcting local ambiguities between neighbor segments. We use as a benchmark the Microsoft MSRC-21 image database and show that our method competes with the current state-of-the-art.
C1 [Vieux, Remi; Benois-Pineau, Jenny; Domenger, Jean-Philippe; Braquelaire, Achille] LaBRI CNRS UMR 5800, Talence, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Bordeaux
RP Vieux, R (corresponding author), LaBRI CNRS UMR 5800, Talence, France.
EM remi.vieux@labri.fr
RI Domenger, jean-philippe/AAX-5021-2021; Benois-Pineau,
   Jenny/ABG-6325-2020
OI Benois-Pineau, Jenny/0000-0003-0659-8894; Domenger,
   Jean-philippe/0000-0001-5398-9340
CR Arthur D., 2007, P 18 ANN ACM SIAM S, V18, P1027, DOI [DOI 10.1145/1283383.1283494, 10.1145/1283383.1283494]
   Athanasiadis T, 2007, IEEE T CIRC SYST VID, V17, P298, DOI 10.1109/TCSVT.2007.890636
   Ayache S, 2007, LECT NOTES COMPUT SC, V4425, P494
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang S-f, 2008, TRECVID 08
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chevalier F, 2007, PATTERN RECOGN LETT, V28, P939, DOI 10.1016/j.patrec.2006.12.009
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Freixenet J, 2002, ECCV 02
   Galleguillos C, 2008, CVPR 08 ANCH AK
   Gokalp D., 2007, Computer Vision and Pattern Recognition, CVPR, IEEE Conference on, P1
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   He XM, 2004, PROC CVPR IEEE, P695
   Hoiem D, 2005, ICCV 05
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Malisiewicz T, 2007, BRIT MACH VIS C 2007
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Nowak E, 2006, ECCV 06
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Peng Y, 2008, TRECVID 08 NIST
   Platt JC, 2000, ADV NEUR IN, P61
   Prasad L, 2006, PATTERN RECOGN, V39, P501, DOI 10.1016/j.patcog.2005.10.014
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Verbeek J., 2007, PROC IEEE C COMPUTER, P1, DOI DOI 10.1109/CVPR.2007.383098
   Verbeek J, 2007, CVPR 07
   Wu TF, 2004, J MACH LEARN RES, V5, P975
   Yang L., 2007, CVPR
NR 36
TC 13
Z9 14
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2012
VL 60
IS 2
BP 305
EP 326
DI 10.1007/s11042-010-0611-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 958YH
UT WOS:000305276400004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Spala, P
   Malamos, AG
   Doulamis, A
   Mamakis, G
AF Spala, Patti
   Malamos, Athanasios G.
   Doulamis, Anastasios
   Mamakis, George
TI Extending MPEG-7 for efficient annotation of complex web 3D scenes
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE MPEG-7; ISO 15938; Web-3D; X3D; 3D annotation
ID TEXTURE BROWSING DESCRIPTOR; VISUALIZATION; EXTRACTION; RETRIEVAL
AB In this paper, we propose an annotation scheme for web-3D scenes based on the MPEG-7 standard. We focus on the annotation of 3D scenes that are encoded with the X3D modeling language which is the descendant of VRML. X3D has been adopted by the web service industry as the appropriate framework for developing interne friendly and flexible 3D visualization applications. We introduce MPEG-7 extensions that are necessary in order to fulfill the requirements of the X3D scene structure and we adapt the MPEG-7 schema encoding accordingly. In the annotation scheme, we consider animation and interactivity issues along with geometrical and appearance characteristics of the 3D content providing a more efficient description of the scene. Thus, the extensions proposed in this paper cover all the information required for a complete and efficient description on the position and relative size of 3D objects, specific characteristics such as object type, curvature properties and available textures, combined with the objects' innate animation properties and its interactions with other objects in the scene or with the end user. The extensions are MPEG-7 Visual and Metadata Descriptors, which fully conform to the standardization restrictions, and we also provide the modifications to the corresponding schema of the ISO 15938 standard that are essential for validating against the proposed MPEG-7 implementation.
C1 [Spala, Patti; Malamos, Athanasios G.; Mamakis, George] Technol Educ Inst Crete, Dept Appl Informat & Multimedia, Iraklion, Greece.
   [Spala, Patti; Mamakis, George] Univ Glamorgan, Fac Adv Technol, Treforest, Wales.
   [Doulamis, Anastasios] Tech Univ Crete, Decis Support Lab, Khania, Greece.
C3 Hellenic Mediterranean University; University of South Wales; Technical
   University of Crete
RP Malamos, AG (corresponding author), Technol Educ Inst Crete, Dept Appl Informat & Multimedia, Iraklion, Greece.
EM pspala@epp.teicrete.gr; amalamos@epp.teicrete.gr; adoulam@cs.ntua.gr;
   gmamakis@epp.teicrete.gr
RI Doulamis, Anastasios/AAL-5972-2021; snaith, melissa/E-8935-2012
OI Malamos, Athanasios/0000-0001-5910-5702
CR [Anonymous], 2003, 159385 ISO
   Attene M, 2007, LECT NOTES COMPUT SC, V4816, P126
   Bilasco I. M., 2005, 13th Annual ACM International Conference on Multimedia, P471, DOI 10.1145/1101149.1101254
   Bilasco I. M., 2006, P 11 INT C 3D WEB TE, P65, DOI DOI 10.1145/1122591.1122601
   Bilasco IM, 2007, WEB3D 2007 - 12TH INTERNATIONAL CONFERENCE ON 3D WEB TECHNOLOGY, PROCEEDINGS, P97
   Chmielewski J, 2008, MOMM 08, P397, DOI DOI 10.1145/1497185.1497270
   Chmielewski J, 2008, EUROGR TECH REP SER, P18, DOI 10.1109/HSI.2008.4581401
   Dasiopoulou S, 2010, MULTIMED TOOLS APPL, V46, P331, DOI 10.1007/s11042-009-0387-4
   Döller M, 2008, J SYST SOFTWARE, V81, P1559, DOI 10.1016/j.jss.2006.03.051
   Doulamis N, 2006, 15 IST MOB WIR COMM
   Glantz A, 2010, MULTIMED TOOLS APPL, V49, P483, DOI 10.1007/s11042-010-0469-3
   Grana C, 2006, 2 IT RES C DIG LIB M
   Halabala P., 2003, 7th Central European Seminar on Computer Graphics (CESCG 2003), P15
   Halkos D, 2009, MULTIMED TOOLS APPL, V42, P343, DOI 10.1007/s11042-008-0234-z
   Hejazi MR, 2007, ELECTRON LETT, V43, P709, DOI 10.1049/el:20070208
   Hejazi MR, 2007, INT J IMAG SYST TECH, V17, P295, DOI 10.1002/ima.20120
   ISO, 2002, 159383 ISO
   *ISO IEC, 2001, 1449622001 ISO IEC
   Kapetanakis K., 2010, P INT C TEL MULT TEM
   Koller D., 2010, ACM J COMPUT CULT HE, V2, p7:1
   Lee KL, 2005, IMAGE VISION COMPUT, V23, P479, DOI 10.1016/j.imavis.2004.12.002
   Loewenstein Y, 2009, GENOME BIOL, V10, DOI 10.1186/gb-2009-10-2-207
   Malamos AG, 2006, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON WEB-BASED EDUCATION, P19
   Malamos AG, 2009, WBE 09 PHUK THAIL MA, P644
   Mikolajczyk Krystian., 2003, BRIT MACHINE VISION, V2, P779
   Min P, 2004, LECT NOTES COMPUT SC, V3232, P209
   Panagiotakis C, 2009, IEEE T CIRC SYST VID, V19, P447, DOI 10.1109/TCSVT.2009.2013517
   Papaleo L, 2009, LECT NOTES COMPUT SC, V5716, P103, DOI 10.1007/978-3-642-04146-4_13
   Pavlopoulos GA, 2008, BIODATA MIN, V1, DOI 10.1186/1756-0381-1-12
   Pein RP, 2008, 2008 IEEE 8TH INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, VOLS 1 AND 2, P173, DOI 10.1109/CIT.2008.4594669
   PITARELLO F, 2006, P WEB3D S 2006 COL M, P85, DOI DOI 10.1145/1122591.1122603
   Ro YM, 2001, ETRI J, V23, P41, DOI 10.4218/etrij.01.0101.0201
   Shen Y, 2008, COMPUT AIDED DESIGN, V40, P963, DOI 10.1016/j.cad.2008.07.003
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   Sylaiou S, 2009, J CULT HERIT, V10, P520, DOI 10.1016/j.culher.2009.03.003
   Tangelder JH, 2008, MULTIMED TOOLS APPL, V39, P441, DOI 10.1007/s11042-007-0181-0
   Walczak K, 2008, EUROGR TECH REP SER, P135, DOI 10.1109/HSI.2008.4581455
   WEB3D CONSORTIUM, 2004, 197752004 WEB3D CONS
   Yang NC, 2008, J VIS COMMUN IMAGE R, V19, P92, DOI 10.1016/j.jvcir.2007.05.003
   Zaharia T., 2001, P SPIE EI C NONL IM
   ZHANG L, 2007, INT C SOFTW ENG ART, V3, P798, DOI DOI 10.1109/SNPD.2007.302
   Zhou NN, 2009, INT J AUTOM COMPUT, V6, P319, DOI 10.1007/s11633-009-0319-9
NR 42
TC 12
Z9 12
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2012
VL 59
IS 2
BP 463
EP 504
DI 10.1007/s11042-011-0790-5
PG 42
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 943OP
UT WOS:000304134000004
DA 2024-07-18
ER

PT J
AU Mujacic, S
   Debevc, M
   Kosec, P
   Bloice, M
   Holzinger, A
AF Mujacic, Samra
   Debevc, Matjaz
   Kosec, Primoz
   Bloice, Marcus
   Holzinger, Andreas
TI Modeling, design, development and evaluation of a hypervideo
   presentation for digital systems teaching and learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hypervideo; e-Learning; Multimedia service; Navigation; SMIL
ID MULTIMEDIA; EDUCATION; VIDEO; PERFORMANCE; SMIL-2.0; MEDIA; TIME
AB Hypervideos are multimedia files, which differ from traditional video files in that they can be navigated by using links that are embedded in them. Students can therefore easily access content that explains and clarifies certain points of the lectures that are difficult to understand, while at the same time not interrupting the flow of the original video presentation. In this paper we report on the design, development and evaluation of a hypermedia e-Learning tool for university students. First, the structure of the hypervideo model is presented; once the structure is known, the process of creating hypervideo content is described in detail, as are the various ways in which content can be linked together. Finally, an evaluation is presented, which has been carried out in the context of an engineering class by use of an interactive experiment, involving N=88 students from a digital systems course. In this study the students were randomly assigned to two groups; one group participated in the course as usual, whilst the second group participated in the same course while also combining the conventional learning with the hypervideo content developed for the course. The students' learning results showed that the students who had access to the hypervideo content performed significantly better than the comparison group.
C1 [Bloice, Marcus; Holzinger, Andreas] Med Univ Graz, Inst Informat Syst & Comp Media, Res Unit HCI4MED, Inst Med Informat Stat & Documentat, A-8036 Graz, Austria.
   [Bloice, Marcus; Holzinger, Andreas] Med Univ Graz, Graz Univ Technol, A-8036 Graz, Austria.
   [Mujacic, Samra] Univ Tuzla, Fac Elect Engn, Tuzla, Bosnia & Herceg.
   [Mujacic, Samra] Univ Tuzla, Univ Ctr Distance Educ Dev, Tuzla, Bosnia & Herceg.
   [Debevc, Matjaz; Kosec, Primoz] Univ Maribor, Fac Elect Engn & Comp Sci, SLO-2000 Maribor, Slovenia.
   [Debevc, Matjaz] Univ Maribor, Ctr Distance Educ Dev, SLO-2000 Maribor, Slovenia.
   [Kosec, Primoz] Univ Maribor, Inst Automat, SLO-2000 Maribor, Slovenia.
C3 Medical University of Graz; Medical University of Graz; Graz University
   of Technology; University of Tuzla; University of Tuzla; University of
   Maribor; University of Maribor; University of Maribor
RP Holzinger, A (corresponding author), Med Univ Graz, Inst Informat Syst & Comp Media, Res Unit HCI4MED, Inst Med Informat Stat & Documentat, Auenbruggerpl 2-5, A-8036 Graz, Austria.
EM samra.mujacic@untz.ba; matjaz.debevc@uni-mb.si; pkosec@uni-mb.si;
   marcus.bloice@medunigraz.at; andreas.holzinger@medunigraz.at
RI Holzinger, Andreas/E-9530-2010; Debevc, Matjaž/AAY-3715-2021
OI Holzinger, Andreas/0000-0002-6786-5194; Debevc,
   Matjaž/0000-0003-4638-7864
FU project "Interactive web pages with hypervideo on demand for e-education
   field"; Boulder, Colorado, USA
FX This project has been partially supported within the framework of the
   bilateral project between Slovenia and Bosnia and Herzegovina-the
   project "Interactive web pages with hypervideo on demand for e-education
   field", 2006-2007, and in collaboration with Dr. Beth Meyer from
   Boulder, Colorado, USA.
CR Barua S, 2001, IEEE T EDUC, V44, P41, DOI 10.1109/13.912709
   Bocconi S, 2005, EEE USING RHETORICAL
   Bota F, 2002, HYP PAR HOTSP APPR I, P620
   BRONDMO HP, 1991, HYPERTEXT STATE ART, P43
   Bulterman DCA, 2003, IEEE MULTIMEDIA, V9, P74
   Bulterman DCA, SUPPORTING ADAPTIVE
   Chambel T, 2002, MULTIMEDIA CONT PERC, P85
   Chang FCI, 2003, MULTIMED TOOLS APPL, V20, P51, DOI 10.1023/A:1023470400109
   CROOKS TJ, 1988, REV EDUC RES, V58, P438, DOI 10.2307/1170281
   Dakss J, 1998, HYPERLINKED VIDEO SP, V3528, P2
   Debevc M, 2008, COMPUT APPL ENG EDUC, V16, P31, DOI 10.1002/cae.20116
   Ess C, 1991, PEDAGOGY COMPUTING H, P277
   Fronk A, 2002, J UNIVERS COMPUT SCI, V8, P892
   HALASZ F, 1994, COMMUN ACM, V37, P30, DOI 10.1145/175235.175237
   HARDMAN L, 1994, COMMUN ACM, V37, P50, DOI 10.1145/175235.175239
   Hardman L, 1995, US AMST HYP MOD ABST
   Hardman L, 1994, CMIFED TRANSPORTABLE
   Hardman L, 1993, STRUCTURED MULTIMEDI, P283
   Hardman L, 1999, P ACM HYP 99
   Hardman L, THESIS
   Holzinger A, 2008, EDUC TECHNOL SOC, V11, P279
   Holzinger A, 2009, COMPUT EDUC, V52, P292, DOI 10.1016/j.compedu.2008.08.008
   Hong PS, 2004, IEEE T EDUC, V47, P301, DOI 10.1109/TE.2004.825571
   Kleinberger Thomas, 2008, Universal Access in the Information Society, V7, P223, DOI 10.1007/s10209-008-0122-3
   Ko CC, 2001, IEEE T EDUC, V44, P76, DOI 10.1109/13.912713
   Kommers P.A. M., 1996, HYPERMEDIA LEARNING
   Layaida N, 1997, MADEUS SYSTEME DEDIT
   LOCATIS C, 1990, ETR&D-EDUC TECH RES, V38, P41, DOI 10.1007/BF02298268
   Ma WH, 1999, 9952 UMSI
   Mayer RE, 2005, J EXP PSYCHOL-APPL, V11, P256, DOI 10.1037/1076-898X.11.4.256
   NACK F, 2000, P ACM MULT WORKSH MA, P21
   Rutledge L, 2001, IEEE INTERNET COMPUT, V5, P78, DOI 10.1109/4236.957898
   Sawhney N, 1997, IEEE MULTIMEDIA, V4, P30, DOI 10.1109/93.641877
   SAWHNEY N., 1996, P 7 ACM C HYPERTEXT, P1, DOI DOI 10.1145/234828.234829
   Shephard K, 2003, BRIT J EDUC TECHNOL, V34, P295, DOI 10.1111/1467-8535.00328
   So WWM, 2008, AUSTRALAS J EDUC TEC, V24, P73
   Soares LFG, 2000, MULTIMEDIA SYST, V8, P118, DOI 10.1007/s005300050155
   Stiggins R.J., 1986, ED MEASUREMENT, V5, P5
   Tolva J, MEDIALOOM INTERACTIV
   Yang CC, 2003, MULTIMED TOOLS APPL, V21, P243, DOI 10.1023/A:1025770817293
NR 40
TC 13
Z9 13
U1 0
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 2
BP 435
EP 452
DI 10.1007/s11042-010-0665-1
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering
GA 921NO
UT WOS:000302484500009
DA 2024-07-18
ER

PT J
AU Mys, S
   Slowack, J
   Skorupa, J
   Deligiannis, N
   Lambert, P
   Munteanu, A
   Van de Walle, R
AF Mys, Stefaan
   Slowack, Juergen
   Skorupa, Jozef
   Deligiannis, Nikos
   Lambert, Peter
   Munteanu, Adrian
   Van de Walle, Rik
TI Decoder-driven mode decision in a block-based distributed video codec
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Skip mode; Intra mode; Mode decision; Distributed video coding;
   Wyner-Ziv coding
ID INFORMATION
AB Distributed Video Coding (DVC) is a video coding paradigm in which the computational complexity is shifted from the encoder to the decoder. DVC is based on information theoretic results suggesting that, under ideal conditions, the same rate-distortion performance can be achieved as for traditional video codecs. In practice however, there is still a significant performance gap between the two coding architectures. One of the main reasons for this gap is the lack of multiple coding modes in current DVC solutions. In this paper, we propose a block-based distributed video codec that supports three coding modes: Wyner-Ziv, skip, and intra. The mode decision process is entirely decoder-driven. Skip blocks are selected based on the estimated accuracy of the side information. The choice between intra and Wyner-Ziv coding modes is made on a rate-distortion basis, by selecting the coding mode with the lowest rate while assuring equal distortion for both modes. Experimental results illustrate that the proposed block-based architecture has some advantages over classical bitplane-based approaches. Introducing skip and intra coded blocks yields average bitrate gains of up to 33.7% over our basic configuration supporting Wyner-Ziv mode only, and up to 29.7% over the reference bitplane-based DISCOVER codec.
C1 [Mys, Stefaan; Slowack, Juergen; Skorupa, Jozef; Lambert, Peter; Van de Walle, Rik] Ghent Univ IBBT, Multimedia Lab, Dept Elect & Informat Syst ELIS, Gaston Crommenlaan 8 Bus 201, B-9050 Ghent, Belgium.
   [Deligiannis, Nikos; Munteanu, Adrian] Vrije Univ Brussel IBBT, Elect & Informat Dept ETRO, B-1050 Brussels, Belgium.
C3 Ghent University
RP Slowack, J (corresponding author), Ghent Univ IBBT, Multimedia Lab, Dept Elect & Informat Syst ELIS, Gaston Crommenlaan 8 Bus 201, B-9050 Ghent, Belgium.
EM stefaan.mys@ugent.be; jurgen.slowack@ugent.be
RI Munteanu, Adrian/HKO-9955-2023; Deligiannis, Nikos/ABH-2381-2020;
   Lambert, Peter/D-7776-2016
OI Munteanu, Adrian/0000-0001-7290-0428; Deligiannis,
   Nikos/0000-0001-9300-5860; Lambert, Peter/0000-0001-5313-4158
FU Ghent University; Interdisciplinary Institute for Broadband Technology
   (IBBT); Institute for the Promotion of Innovation by Science and
   Technology in Flanders (IWT-Flanders); Fund for Scientific
   Research-Flanders (FWO-Flanders); European Union
FX The research activities that have been described in this paper were
   funded by Ghent University, the Interdisciplinary Institute for
   Broadband Technology (IBBT), the Institute for the Promotion of
   Innovation by Science and Technology in Flanders (IWT-Flanders), the
   Fund for Scientific Research-Flanders (FWO-Flanders), and the European
   Union.
CR Aaron A., 2004, P SPIE VIS COMM IM P
   Artigas X, 2007, P PICT COD S PCS
   Ascenso J., 2005, 5 EURASIP C SPEECH I
   Ascenso J, 2009, P INT C MULT EXP ICM
   Belkoura Z, 2006, P EUR SIGN PROC C
   Benierbah S, 2009, P IEEE INT C IM PROC
   Chien W-J, 2007, P IEEE INT C AC SPEE
   Chien WJ, 2010, MULTIMED TOOLS APPL, V48, P437, DOI 10.1007/s11042-009-0314-8
   Do T, 2009, P INT C COMP SCI INF
   Esmaili G, 2009, P DAT COMPR C DCC
   Feng Y, 2008, P SATELLITE DATA COM
   Girod B, 2005, P IEEE, V93, P71, DOI 10.1109/JPROC.2004.839619
   Jakubowski M, 2009, PROC SPIE, V7502, DOI 10.1117/12.838164
   Kubasov D, 2007, P IEEE MULT SIGN PRO
   Ma SW, 2005, IEEE T CIRC SYST VID, V15, P1533, DOI 10.1109/TCSVT.2005.857300
   Mys S, 2009, SIGNAL PROCESS-IMAGE, V24, P200, DOI 10.1016/j.image.2008.12.004
   Pereira F, 2008, SIGNAL PROCESS-IMAGE, V23, P339, DOI 10.1016/j.image.2008.04.002
   PURI R, 2003, P IEEE INT C IM PROC
   Puri R., 2002, P ALL C COMM CONTR C
   Puri R, 2007, IEEE T IMAGE PROCESS, V16, P2436, DOI 10.1109/TIP.2007.904949
   Skorupa J, 2009, P PICT COD S PCS
   SLEPIAN D, 1973, IEEE T INFORM THEORY, V19, P471, DOI 10.1109/TIT.1973.1055037
   Slowack J, 2009, P PICT COD S PCS
   Sofke S, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/978581
   Tagliasacchi M, 2007, P EURASIP EUR SIGN P
   Tagliasacchi M., 2006, P IEEE INT C AC SPEE
   Trapanese A, 2005, P INT WORKSH VERY LO
   Tsai D.-C., 2007, P IEEE INT C IM PROC
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   WYNER AD, 1976, IEEE T INFORM THEORY, V22, P1, DOI 10.1109/TIT.1976.1055508
NR 30
TC 6
Z9 6
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2012
VL 58
IS 1
BP 239
EP 266
DI 10.1007/s11042-010-0718-5
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 917BS
UT WOS:000302147600010
DA 2024-07-18
ER

PT J
AU Wan, KW
   Tan, AH
   Lim, JH
   Chia, LT
AF Wan, Kong-Wah
   Tan, Ah-Hwee
   Lim, Joo-Hwee
   Chia, Liang-Tien
TI A non-parametric visual-sense model of images-extending the cluster
   hypothesis beyond text
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Hierarchical Dirichlet Process; Non-parametric models; Image clustering;
   Sense disambiguation
AB The main challenge of a search engine is to find information that are relevant and appropriate. However, this can become difficult when queries are issued using ambiguous words. Rijsbergen first hypothesized a clustering approach for web pages wherein closely associated pages are treated as a semantic group with the same relevance to the query (Rijsbergen 1979). In this paper, we extend Rijsbergen's cluster hypothesis to multimedia content such as images. Given a user query, the polysemy in the return image set is related to the many possible meanings of the query. We develop a method to cluster the polysemous images into their semantic categories. The resulting clusters can be seen as the visual senses of the query, which collectively embody the visual interpretations of the query. At the heart of our method is a non-parametric Bayesian approach that exploits the complementary text and visual information of images for semantic clustering. Latent structures of polysemous images are mined using the Hierarchical Dirichlet Process (HDP). HDP is a non-parametric Bayesian model that represents images using a mixture of components. The main advantage of our model is that the number of mixture components is not fixed a priori, but is determined during the posterior inference process. This allows our model to grow with the level of polysemy (and visual diversity) of images. The same set of components is used to model all images, with only the mixture weights varying amongst images. Evaluation results on a large collection of web images show the efficacy of our approach.
C1 [Wan, Kong-Wah; Lim, Joo-Hwee] Inst Infocomm Res, Singapore, Singapore.
   [Tan, Ah-Hwee; Chia, Liang-Tien] Nanyang Technol Univ, Sch Comp Engn, Singapore, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); Nanyang Technological University
RP Wan, KW (corresponding author), Inst Infocomm Res, 1 Fusionopolis Way, Singapore, Singapore.
EM kongwah@i2r.a-star.edu.sg; asahtan@ntu.edu.sg;
   joohwee@i2r.a-star.edu.sg; asltchia@ntu.edu.sg
RI Tan, Ah-Hwee/A-3729-2011; Chia, Liang-Tien/A-9874-2008
OI Tan, Ah Hwee/0000-0003-0378-4069
CR Agrawal Rakesh, 2009, P 2 ACM INT C WEB SE, P5, DOI DOI 10.1145/1498759.1498766
   Ali Kamal, 2004, KDD'04: Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, P394, DOI DOI 10.1145/1014052.1014097
   [Anonymous], 2004, Proceedings of the 12th ACM International Conference on Multimedia, DOI DOI 10.1145/1027527.1027747
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], P COMP VIS PATT REC
   Arni T, 2008, WORK NOT 2008 CLEF W
   Blei DM, 2010, J ACM, V57, DOI 10.1145/1667053.1667056
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bradley P. S., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P91
   Carbonell J., 1998, Proceedings of the 21st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P335, DOI 10.1145/290941.291025
   Cilibrasi RL, 2007, IEEE T KNOWL DATA EN, V19, P370, DOI 10.1109/TKDE.2007.48
   Clarke C. L., 2008, P 31 ANN INT ACM SIG, P659, DOI [DOI 10.1145/1390334.1390446, 10.1145/1390334.1390446]
   CUTTING DR, 1992, P ACM SIGIR C RES DE
   FERGUS R, 2005, P INT C COMP VIS
   FERGUSON TS, 1973, ANN STAT, V1, P209, DOI 10.1214/aos/1176342360
   Grauman K, 2006, P COMP VIS PATT REC
   HOFFMAN M, 2008, P INT C MUS INF RETR
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li H., 2008, PROC 16 ACM INT C MU, P813
   LI LJ, 2007, P COMP VIS PATT REC
   Loeff N., 2006, P COLINGACL, P547
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mihalcea R, 2007, P ANN C N AM ASS COM
   Ng AY, 2002, ADV NEUR IN, V14, P849
   QUELHAS P, 2005, P INT C COMP VIS
   Rasmussen C, 2000, NEURAL INFORM PROCES
   Saenko K., 2008, P NEUR INF PROC SYST
   SCHROFF F, 2007, P INT C COMP VIS
   Sivic J, 2008, P COMP VIS PATT REC
   Song K., 2006, ACM Multimedia, P707
   Teh Y, 2007, J AM STAT ASSOC, V101, P1556
   Turney PD, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P417
   Van Leuken Reinier H, 2009, P 18 INT C WORLD WID, P341, DOI 10.1145/1526709.1526756
   Van Rijsbergen C. J., 1979, Information Retrieval, V2nd
   Vivisimo, 2009, VIV WEB CLUST
   Wan K, 2009, P BRIT MACH VIS C
   Wan K, 2010, P INT C MULT EXP
   Wang S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P587
   Wikipedia, 2010, ENGL DUMPS SQL XML
   Xing E, 2006, P INT C MACH LEARN
   Xing Wei, 2006, Proceedings of the Twenty-Ninth Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P178
   ZENG H, 2004, P ACM SIGIR C RES DE
   ZHAI C.X., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in informaion Retrieval (Toronto, Canada, July 28 - August 01, 2003), P10, DOI [10.1145/860435.860440, DOI 10.1145/860435.860440]
   Ziegler Cai-Nicolas, 2005, P 14 INT C WORLD WID, P22, DOI DOI 10.1145/1060745.1060754
NR 46
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2012
VL 56
IS 3
BP 509
EP 534
DI 10.1007/s11042-010-0615-y
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 891AX
UT WOS:000300189700006
OA Green Published
DA 2024-07-18
ER

PT J
AU Cerekovic, A
   Pandzic, IS
AF Cerekovic, Aleksandra
   Pandzic, Igor S.
TI Multimodal behavior realization for embodied conversational agents
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimodal behavior realization; Virtual characters; Character animation
   system
ID CHARACTERS
AB Applications with intelligent conversational virtual humans, called Embodied Conversational Agents (ECAs), seek to bring human-like abilities into machines and establish natural human-computer interaction. In this paper we discuss realization of ECA multimodal behaviors which include speech and nonverbal behaviors. We devise RealActor, an open-source, multi-platform animation system for real-time multimodal behavior realization for ECAs. The system employs a novel solution for synchronizing gestures and speech using neural networks. It also employs an adaptive face animation model based on Facial Action Coding System (FACS) to synthesize face expressions. Our aim is to provide a generic animation system which can help researchers create believable and expressive ECAs.
C1 [Cerekovic, Aleksandra; Pandzic, Igor S.] Univ Zagreb, Fac Elect Engn & Comp, Zagreb 41000, Croatia.
C3 University of Zagreb
RP Cerekovic, A (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Zagreb 41000, Croatia.
EM aleksandra.cerekovic@fer.hr; igor.pandzic@fer.hr
CR Albrecht I, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P283
   [Anonymous], 1991, Research on Language and Social Interaction, DOI DOI 10.1080/08351819109389361
   [Anonymous], 1997, P C HUM FACT COMP SY
   [Anonymous], FEATURE BASED FACE T
   [Anonymous], 2006, EUROGRAPHICS
   Bianchi-Berthouze N, 2003, CONNECT SCI, V15, P259, DOI 10.1080/09540090310001658793
   Brkic M, 2008, LECT NOTES ARTIF INT, V5178, P73, DOI 10.1007/978-3-540-85565-1_10
   Cassell J, 2001, COMP GRAPH, P477, DOI 10.1145/383259.383315
   Cassell J., 2000, Embodied Conversational Agents
   CEREKOVIC A, 2010, P COST ACT 2102 INT
   CEREKOVIC A, 2009, INT C ACT MED TECHN
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   DARIOUCH B, 2004, WORKSH HUM SANT SEPT
   Ekman P., 1979, BROWS EMOTIONAL CONV, P169
   Ekman P, 1978, FACIAL ACTION CODING
   Ekman P., 1973, Darwin and facial expression: A century of research in review, P169
   *FAC GEN, FAC GEN 3D HUM FAC
   Foster M.E., 2007, Enhancing Human-Computer Interaction with Embodied Conversational Agents
   FRATARCANGELI M, 2009, P 10 INT C TEL CONTE
   Gebhard P, 2008, LECT NOTES COMPUT SC, V5208, P426
   Georganas ND, 1996, IEEE J SEL AREA COMM, V14, P1, DOI 10.1109/JSAC.1996.481690
   GOSSELIN P, 1995, CANADIAN J EXPT PSYC, P313
   Hartmann B, 2002, COMP ANIM CONF PROC, P111, DOI 10.1109/CA.2002.1017516
   Heck R, 2007, I3D 2007: ACM SIGGRAPH SYMPOSIUM ON INTERACTIVE 3D GRAPHICS AND GAMES, PROCEEDINGS, P129
   Heloir A, 2009, LECT NOTES ARTIF INT, V5773, P393, DOI 10.1007/978-3-642-04380-2_43
   *HORDE3D, NEXT GEN GRAPH ENG
   Johnston M, 1997, 35TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 8TH CONFERENCE OF THE EUROPEAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P281
   Johnston Michael., 2000, Proceedings of the 18th conference on Computational linguistics - COLINGS 2000, P369
   Kleinsmith A, 2007, LECT NOTES COMPUT SC, V4738, P48, DOI 10.1007/978-3-540-74889-2_5
   Kopp S, 2004, COMPUT ANIMAT VIRT W, V15, P39, DOI 10.1002/cav.6
   Kopp S, 2006, LECT NOTES ARTIF INT, V4133, P205
   KOVAR L, 2004, THESIS U WISCONSIN M
   Lee J, 2006, LECT NOTES ARTIF INT, V4133, P243
   McNeill D., 1992, Hand and Mind: What Gestures Reveal about Thought
   *MICR, MICR SPEECH API
   Neff M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330516
   OGRE, OP SOURC 3D GRAPH EN
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   PANDZIC IS, 2003, P 2 INT C MOB UB MUL, P49
   PEJSA T, 2009, P 10 INT C TEL CONTE
   PELACHAUD C, 2009, COMMUNICATI IN PRESS
   Rojas R., 1996, NEURAL NETWORKS, P149, DOI 10.1007/978-3-642-61068-4{\_}7
   SCHROEDER M, 2007, P BLIZZ CHALL 2007
   SMID K, 2006, P 6 INT C INT VIRT A, P256
   SPIERLING U, 2005, ACM SIGGRAPH 2005 ED
   SPIERLING U, 2005, DIGRA 2005 S FRAS U
   Stone M, 2004, ACM T GRAPHIC, V23, P506, DOI 10.1145/1015706.1015753
   Taylor P., 1998, 3 ESCA WORKSHOP SPEE, P147
   THIEBAUX M, 2008, P AUT AG MULT SYST A
   VANDEEMTER K, 2008, ARTICIAL INTELLIGENC, P1219
   Vilhjálmsson H, 2007, LECT NOTES ARTIF INT, V4722, P99
   Wehrle T, 2000, J PERS SOC PSYCHOL, V78, P105, DOI 10.1037/0022-3514.78.1.105
   ZORIC G, 2005, P INT C MULT EXP ICM
   Zoric G, 2009, LECT NOTES ARTIF INT, V5398, P112
   BML SPECIFICATION
NR 55
TC 8
Z9 9
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 1
SI SI
BP 143
EP 164
DI 10.1007/s11042-010-0530-2
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 770BD
UT WOS:000291061100008
DA 2024-07-18
ER

PT J
AU Rao, YB
   Chen, LT
   Liu, QH
   Lin, WY
   Li, YM
   Zhou, J
AF Rao, Yunbo
   Chen, Leiting
   Liu, Qihe
   Lin, Weiyao
   Li, Yanmei
   Zhou, Jun
TI Real-time control of individual agents for crowd simulation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Crowd simulation; Path planning; Virtual environments; Individual agents
   controlling
AB This paper presents a novel approach for individual agent's motion simulation in real-time virtual environments. In our model, we focus on addressing two problems: 1) the control model for local motions. We propose to represent a combination of psychological and geometrical rules with a social and physical forces model so that it can avoid individual agent's local collision. 2) Global path planning algorithm with moving obstacle. We propose a more efficient algorithm by extending the indicative route method. Experimental results show that the proposed approach can be tuned to simulate different types of crowd behaviors under a variety of conditions, and can naturally exhibit emergent phenomena that have been observed in real crowds.
C1 [Rao, Yunbo; Liu, Qihe; Li, Yanmei; Zhou, Jun] Univ Elect Sci & Technol China, Sch Engn & Comp Sci, Dept Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
   [Lin, Weiyao] Univ Washington, Seattle, WA 98195 USA.
   [Zhou, Jun] Southwest Univ, Sch Engn & Comp Sci, Chongqing, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Washington; University of Washington Seattle; Southwest University -
   China
RP Rao, YB (corresponding author), Univ Elect Sci & Technol China, Sch Engn & Comp Sci, Dept Comp Sci & Engn, Chengdu 610054, Sichuan, Peoples R China.
EM uestc2008@126.com
RI lin, yuxi/HKF-6212-2023
OI Lin, Weiyao/0000-0001-8307-7107
FU National High-Tech Program 863 of China [2007AA01Z322]; National Arm
   Research Program of China [9140A06060208DZ0207]
FX The authors would like to thank the anonymous reviewers for their
   helpful comments. We would like to thank Prof Ming-ting Sun for
   improving the writing of the paper. This work is partly supported by
   National High-Tech Program 863 of China (Grant No. 2007AA01Z322) and
   National Arm Research Program of China (Grant No. 9140A06060208DZ0207).
CR ADRIEN T, 2006, ACM T GRAPHIC, V25, P1160
   [Anonymous], 4 INT C FDN DIG GAM
   Chenney Stephen., 2004, Proceedings of the 2004 ACM SIGGRAPH/Euro- graphics symposium on Computer animation, P233, DOI [10.1145/1028523.1028553, DOI 10.1145/1028523.1028553.]
   Durupinar Funda., 2008, AAMAS '08: Proceedings of the 7th international joint conference on Autonomous agents and multiagent systems, P1217
   Helbing D, 2005, TRANSPORT SCI, V39, P1, DOI 10.1287/trsc.1040.0108
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   Jin XG, 2008, IEEE COMPUT GRAPH, V28, P37, DOI 10.1109/MCG.2008.117
   KARAMOUZAS I, 2008, COMPUTER ANIMATION V, P283
   KIRCHNER A, 2003, PHYS REV E, V67, P51
   Liew PS, 2009, COMPUT ANIMAT VIRT W, V20, P257, DOI 10.1002/cav.316
   LOKOBA T, 2005, SIMULATION, V81, P339
   Loscos C, 2003, THEORY AND PRACTICE OF COMPUTER GRAPHICS, PROCEEDINGS, P122
   Narain R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618468
   PATIL S, 2010, IEEE T VISUALIZ 0209
   Pelechano N., 2008, Proceedings of Autonomous Agents and Multiagent Systems, P136
   Pelechano N., 2007, EUR ACM SIGGRAPH S C
   Reynolds C. W., 1999, P GAM DEV C, P763
   Reynolds CW., 1987, SIGGRAPH Comput. Graph., V21, P25, DOI [10.1145/37402.37406, DOI 10.1145/37402.37406]
   ROLAND G, 2008, COMPUTER ANIMATION S, P64
   Shao W, 2007, GRAPH MODELS, V69, P246, DOI 10.1016/j.gmod.2007.09.001
   TECCHIA F, 2001, P ACM EG GAM TECHN C
NR 21
TC 6
Z9 8
U1 0
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2011
VL 54
IS 2
BP 397
EP 414
DI 10.1007/s11042-010-0542-y
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 781SK
UT WOS:000291953700010
DA 2024-07-18
ER

PT J
AU Fallahpour, M
   Megías, D
AF Fallahpour, Mehdi
   Megias, David
TI High capacity audio watermarking using the high frequency band of the
   wavelet domain
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Audio watermarking; Digital wavelet transform
AB This paper proposes a novel high capacity robust audio watermarking algorithm by using the high frequency band of the wavelet decomposition at which the human auditory system (HAS) is not very sensitive to alteration. The main idea is to divide the high frequency band into frames and, for embedding, to change the wavelet samples depending on the average of relevant frame's samples. The experimental results show that the method has a very high capacity (about 11,000 bps), without significant perceptual distortion (ODG in [-1 ,0] and SNR about 30dB), and provides robustness against common audio signal processing such as additive noise, filtering, echo and MPEG compression (MP3).
C1 [Fallahpour, Mehdi; Megias, David] Univ Oberta Catalunya, Barcelona 08018, Spain.
C3 UOC Universitat Oberta de Catalunya
RP Fallahpour, M (corresponding author), Univ Oberta Catalunya, Rambla del Poblenou 156, Barcelona 08018, Spain.
EM MFallahpour@uoc.edu; DMegias@uoc.edu
RI Megías, David/L-1720-2014
OI Megías, David/0000-0002-0507-7731
FU Spanish Ministry of Science and Innovation; FEDER [TSI2007-65406-C03-03
   E-AEGIS]; CONSOLIDERINGENIO [CSD2007-00004]
FX This work is partially supported by the Spanish Ministry of Science and
   Innovation and the FEDER funds under the grants TSI2007-65406-C03-03
   E-AEGIS and CONSOLIDERINGENIO 2010 CSD2007-00004 ARES.
CR AKHAEE MA, 2009, IEEE T MULTIMEDIA, V11, P1
   Chen B, 2001, IEEE T INFORM THEORY, V47, P1423, DOI 10.1109/18.923725
   Fallahpour M, 2009, IEICE ELECTRON EXPR, V6, P1057, DOI 10.1587/elex.6.1057
   Fallahpour M, 2009, COMM COM INF SC, V36, P91
   Garcia-Hernandez JJ, 2008, IEICE ELECTRON EXPR, V5, P217, DOI 10.1587/elex.5.217
   Kang H, 2008, IEICE T INF SYST, VE91D, P2731, DOI 10.1093/ietisy/e91-d.11.2731
   Kim HJ, 2003, IEEE T CIRC SYST VID, V13, P885, DOI 10.1109/TCSVT.2003.815950
   LIE N, 2005, IEEE T SIGNAL PROCES, V53, P806
   Megías D, 2005, LECT NOTES COMPUT SC, V3783, P427
   *OPTICOM, OPTICOM OPERA SOFTW
   Pooyan M, 2007, 2007 THIRD INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, VOL II, PROCEEDINGS, P287
   Thiede T, 2000, J AUDIO ENG SOC, V48, P3
   Wang XY, 2006, IEEE T SIGNAL PROCES, V54, P4835, DOI 10.1109/TSP.2006.881258
   Wu SQ, 2005, IEEE T BROADCAST, V51, P69, DOI 10.1109/TBC.2004.838265
   Xiang SJ, 2008, SIGNAL PROCESS, V88, P2372, DOI 10.1016/j.sigpro.2008.03.019
   XU Z, 2006, IEEE P INT C INT INF
   STIRMARK BENCHMARK A
   NO REALLY RUST
NR 18
TC 34
Z9 35
U1 0
U2 16
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2011
VL 52
IS 2-3
SI SI
BP 485
EP 498
DI 10.1007/s11042-010-0495-1
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 732IA
UT WOS:000288177000014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Song, HJ
   Shen, ML
AF Song, Hua-jun
   Shen, Mei-li
TI Target tracking algorithm based on optical flow method using corner
   detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 2nd International Congress on Image and Signal Processing
CY OCT 17-19, 2009
CL Tianjin, PEOPLES R CHINA
SP Tianjin Univ Technol, IEEE Engn Med & Biol Soc (EMBS)
DE Optical flow; Target tracking; Corner detection
AB The tracking speed and accuracy are two most important parameters for a target tracking system. In our study, the proposed target tracking algorithm combines the Harris method and the optical flow method. To improve the tracking speed, the Harris method is initially used to extract some target corner features, and the optical flow method is then used to more accurately match corner features for the subsequent video frames. When the tracked target is rotated or distorted, the barycenter algorithm is employed to compute the barycenter of those matched features of target. To meet the real-time-tracking requirement, a small-zone image searching method and a high speed digital signal processing system are also designed. Our experimental study shows that the method described in this paper has high accuracy of target tracking, and can be applied to the situations of rotated, distorted, and/or shielded targets, although it has a limitation that it is only suitable for smaller targets.
C1 [Song, Hua-jun] China Univ Petr E China, Coll Informat & Control Engn, Dongying, Peoples R China.
   [Shen, Mei-li] Qingdao Technol Univ, Sch Sci, Qingdao, Peoples R China.
C3 China University of Petroleum; Qingdao University of Technology
RP Song, HJ (corresponding author), China Univ Petr E China, Coll Informat & Control Engn, Dongying, Peoples R China.
EM Huajun.song@gmail.com; Meili.shenqd@gmail.com
CR Barron J, 2002, INT C PATT RECOG, P251, DOI 10.1109/ICPR.2002.1047444
   CHEN L, 2005, TECHNIQUES AUTOMATIO, V24, P5
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X
   Fermüller C, 2001, COMPUT VIS IMAGE UND, V82, P1, DOI 10.1006/cviu.2000.0900
   Fusiello A, 1999, PATTERN ANAL APPL, V2, P312, DOI 10.1007/s100440050039
   Georgescu B, 2004, IEEE T PATTERN ANAL, V26, P674, DOI 10.1109/TPAMI.2004.2
   Griffin A, 2002, PATTERN RECOGN LETT, V23, P443, DOI 10.1016/S0167-8655(01)00176-3
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   SONG HJ, 2004, P SPIE PASSIVE COMPO, V5623, P274
   *TEX INSTR, 2005, TMS320C6414T TEX INS
   Tommasini T, 1998, PROC CVPR IEEE, P178, DOI 10.1109/CVPR.1998.698606
NR 14
TC 14
Z9 18
U1 1
U2 14
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2011
VL 52
IS 1
BP 121
EP 131
DI 10.1007/s11042-010-0464-8
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 716RF
UT WOS:000286990500010
DA 2024-07-18
ER

PT J
AU Atrey, PK
   El Saddik, A
   Kankanhalli, MS
AF Atrey, Pradeep K.
   El Saddik, Abdulmotaleb
   Kankanhalli, Mohan S.
TI Effective multimedia surveillance using a human-centric approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Human-centered; Multimedia surveillance; Relevance feedback; Eyes
   tracking; Importance computation; Camera view selection and scheduling
AB Large-scale multimedia surveillance installations usually consist of a number of spatially distributed video cameras that are installed in a premise and are connected to a central control station, where human operators (e.g., security personnel) remotely monitor the scene images captured by the cameras. In the majority of these systems the ratio of human operators to the number of camera views is very low. This potentially raises the problem that some important events may be missed. Studies have shown that a human operator can effectively monitor only four camera views. Moreover, the visual attention of human operator drops below the acceptable level while performing the task of visual monitoring. Therefore, there is a need for the selection of the four most relevant camera views at a given time instant. This paper proposes a human-centric approach to solve the problem of dynamically selecting and scheduling the four best camera views. In the proposed approach we use a feedback camera to observe the human monitoring the surveillance camera feeds. Using this information, the system computes the operator's attention to the camera views to automatically determine the importance of events being captured by the respective cameras. This real-time non-invasive relevance feedback is then augmented with the automatic detection of events to compute the four best feeds. The experiments show the effectiveness of the proposed approach by improving the identification of important events occurring in the environment.
C1 [Atrey, Pradeep K.] Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
   [El Saddik, Abdulmotaleb] Univ Ottawa, Multimedia Commun Res Lab, Ottawa, ON K1N 6N5, Canada.
   [Kankanhalli, Mohan S.] Natl Univ Singapore, Sch Comp, Singapore 117417, Singapore.
C3 University of Winnipeg; University of Ottawa; National University of
   Singapore
RP Atrey, PK (corresponding author), Univ Winnipeg, Dept Appl Comp Sci, Winnipeg, MB R3B 2E9, Canada.
EM p.atrey@uwinnipeg.ca; abed@mrclab.uottawa.ca; mohan@comp.nus.edu.sg
RI Kankanhalli, Mohan/Q-9284-2019; /D-4159-2009
OI Kankanhalli, Mohan/0000-0002-4846-2015; /0000-0002-7690-8547
FU National Sciences and Engineering Research Council of Canada [408206];
   University of Winnipeg [607062]
FX This work was supported by the National Sciences and Engineering
   Research Council of Canada Discovery Grant 408206 and the University of
   Winnipeg Major Research Grant 607062.
CR Amarnag S, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P557
   Asteriadis S, 2009, MULTIMED TOOLS APPL, V41, P469, DOI 10.1007/s11042-008-0240-1
   ATREY PK, 2009, 1 ACM INT WORKSH EV, P57
   Atrey PK, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P325, DOI 10.1109/ICME.2008.4607437
   Atrey PK, 2006, MULTIMEDIA SYST, V12, P239, DOI 10.1007/s00530-006-0063-8
   Baumann Matthew A., 2010, 2010 IEEE Haptics Symposium (Formerly known as Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems), P149, DOI 10.1109/HAPTIC.2010.5444662
   DAVIS M, 2003, IEEE INT C MULT EXP, V2, P185
   Dee HM, 2008, MACH VISION APPL, V19, P329, DOI 10.1007/s00138-007-0077-z
   Hampapur I, 2005, IEEE SIGNAL PROC MAG, V22, P38
   Hossain MA, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/1870121.1870124
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Leykin Alex, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563059
   Liu AA, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1473, DOI 10.1109/ICME.2008.4607724
   Ma Y.-F., 2002, ACM MULTIMEDIA, P533
   Menezes P., 2004, 5 S INT AUT VEH, P5
   PETERS C., 2003, P ACM SIGGRAPH 03, P1
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   Reinders M., 1997, Third Annual Conference of ASCI, ASCI, Delft, P85
   Rowe LA, 2005, ACM T MULTIM COMPUT, V1, P3, DOI 10.1145/1047936.1047938
   Savas Z., 2008, TrackEye: Real-Time Tracking Of Human Eyes Using a Webcam
   SAVAS Z, 2005, THESIS MIDDLE EAST T
   Smith P, 2000, INT C PATT RECOG, P636, DOI 10.1109/ICPR.2000.902999
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Taylor JG, 2004, IEEE IJCNN, P501, DOI 10.1109/IJCNN.2004.1379960
   Vaiapury K, 2008, J MULTIMEDIA, V3, P1
   Vilaplana V, 2008, IEEE IMAGE PROC, P2712, DOI 10.1109/ICIP.2008.4712354
   Vural U, 2009, PATTERN RECOGN LETT, V30, P1151, DOI 10.1016/j.patrec.2009.03.002
   Wallace E., 1988, CCTV Control Room Ergonomics
   Wang Jun., 2003, First ACM SIGMM international workshop on Video surveillance, P77
   Wu C, 2005, IEEE SYS MAN CYBERN, P760
   Wu JW, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1671962.1671964
NR 32
TC 15
Z9 16
U1 1
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 2
SI SI
BP 697
EP 721
DI 10.1007/s11042-010-0649-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 709WO
UT WOS:000286472300012
DA 2024-07-18
ER

PT J
AU Zheng, YT
   Zha, ZJ
   Chua, TS
AF Zheng, Yan-Tao
   Zha, Zheng-Jun
   Chua, Tat-Seng
TI Research and applications on georeferenced multimedia: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Georeferenced media; Geotagged photo; Survey
ID PHOTOGRAPHS; VISION; SCALE; WORLD
AB In recent years, the emergence of georeferenced media, like geotagged photos, on the Internet has opened up a new world of possibilities for geographic related research and applications. Despite of its short history, georeferenced media has been attracting attentions from several major research communities of Computer Vision, Multimedia, Digital Libraries and KDD. This paper provides a comprehensive survey on recent research and applications on online georeferenced media. Specifically, the survey focuses on four aspects: (1) organizing and browsing georeferenced media resources, (2) mining semantic/social knowledge from georeferenced media, (3) learning landmarks in the world, and (4) estimating geographic location of a photo. Furthermore, based on the current technical achievements, open research issues and challenges are identified, and directions that can lead to compelling applications are suggested.
C1 [Zheng, Yan-Tao] Inst Infocomm Res, Singapore, Singapore.
   [Zha, Zheng-Jun; Chua, Tat-Seng] Natl Univ Singapore, Dept Comp Sci, Singapore 117548, Singapore.
C3 Agency for Science Technology & Research (A*STAR); A*STAR - Institute
   for Infocomm Research (I2R); National University of Singapore
RP Zheng, YT (corresponding author), Inst Infocomm Res, Singapore, Singapore.
EM yzheng@i2r.a-star.edu.sg; zhazj@comp.nus.edu.sg; dcscts@comp.nus.edu.sg
RI Zha, Zheng-Jun/AAF-8667-2020; Zha, Zheng-Jun/AAE-8408-2020
OI Zha, Zheng-Jun/0000-0003-2510-8993
CR Abbasi R, 2009, LECT NOTES COMPUT SC, V5478, P654, DOI 10.1007/978-3-642-00958-7_62
   Agarwal S, 2010, COMPUTER, V43, P40, DOI 10.1109/MC.2010.175
   Ahern S, 2007, ACM-IEEE J CONF DIG, P1, DOI 10.1145/1255175.1255177
   [Anonymous], 1996, Sigmod Workshop on Research Issues on Data Mining and Knowledge Discovery (DMKD)
   [Anonymous], P 8 ACM INT WORKSH M
   [Anonymous], 2009, P 18 INT C WORLD WID
   [Anonymous], P 18 INT C WORLD WID
   [Anonymous], P ACM INT C MULT
   [Anonymous], 2009, P 2 INT WORKSH LOC W
   [Anonymous], P 14 ACM INT C MULT
   [Anonymous], 1989, Categorical and Directional Data
   [Anonymous], 2008, P 7 INT C MOB UB MUL, DOI DOI 10.1145/1543137.1543167
   [Anonymous], 2008, 2008 IEEE C COMPUTER
   [Anonymous], P INT C WORLD WID WE
   [Anonymous], P 6 WORKSH GEOGR INF
   [Anonymous], P INT C COMP VIS KYO
   Anselin L., 1992, SPATIAL DATA ANAL GI
   Asakura Y, 2007, TRANSPORT RES A-POL, V41, P684, DOI 10.1016/j.tra.2006.07.003
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   BERG TL, 2007, UCBEECS200713
   Berry J.K., 1993, Beyond Mapping Concepts, Algorithms, and Issues in GIS
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Camara A., 1999, SPATIAL MULTIMEDIA V
   CAYZER S, 2004, SEMANTIC PHOTOS
   Chippendale P, 2009, 2009 CONFERENCE FOR VISUAL MEDIA PRODUCTION: CVMP 2009, P188, DOI 10.1109/CVMP.2009.30
   CHIPPENDALE P, VISUAL ENV MONITORIN
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   Diaconis P, 2009, B AM MATH SOC, V46, P179
   DONOSER M, 2006, P C COMP VIS PATT RE, P553
   Dubinko Micah., 2006, WWW 06, P193
   Ester M, 1997, LECT NOTES COMPUT SC, V1262, P47, DOI 10.1007/3-540-63238-7_24
   GIONIS A, 2003, P 7 INT C RES COMP M, P123
   GOESELE M, 2007, P IEEE C COMP VIS RI
   Goldberger J, 2008, PATTERN RECOGN LETT, V29, P1632, DOI 10.1016/j.patrec.2008.04.003
   Graham A., 2002, Proceedings of the second ACM/IEEE-CS joint conference on Digital libraries, P326
   Hakeem A, 2006, INT C PATT RECOG, P82
   Han J., 2001, GEOGRAPHIC DATA MINI
   Hao Q., 2010, P 19 INT C WORLD WID, P401, DOI [DOI 10.1145/1772690.1772732, 10.1145/1772690.1772732]
   Hao Qiang., 2009, Proceedings of the ACM International Conference on Multimedia, P801
   Harada S, 2004, ACM-IEEE J CONF DIG, P325
   Heuer J.T., 2007, P 5 GEOGRAPHIC INFOR, P199
   HOFMANN T, 1999, P UNC ART INT UAI ST
   ISHIKAWA Y., 2004, STDBM, P9
   JESDANUN A, 2008, ABC NEWS TECHNOLOGY
   JUNG V, 1999, 4 INVISIP
   KALOGERAKIS E, P INT C COMP VIS KYO
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   Kennedy Lyndon., 2007, P 15 INT C MULTIMEDI, P631
   Kuipers B, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P174
   Lau G, 2006, TOUR HOSP RES, V7, P39, DOI 10.1057/palgrave.thr.6050027
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lew A, 2006, ANN TOURISM RES, V33, P403, DOI 10.1016/j.annals.2005.12.002
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Lim E.-P., 2002, JCDL 2002. Proceedings of the Second ACM/IEEE-CS Joint Conference on Digital Libraries, P351, DOI 10.1145/544220.544307
   Lisin D. A., 2005, COMBINING LOCAL GLOB, P47
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McKercher B, 2008, TOURISM GEOGR, V10, P355, DOI 10.1080/14616680802236352
   Mei Q., 2006, P 15 INT C WORLD WID, P533, DOI DOI 10.1145/1135777.1135857
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Miller H., 2001, GEOGRAPHIC DATA MINI
   Naaman M, 2004, ACM-IEEE J CONF DIG, P53, DOI 10.1145/996350.996366
   NAAMAN M, 2004, ADVENTURES SPACE TIM
   Naaman M., 2004, P 12 ANN ACM INT C M, P196
   NI K, 2007, P INT C COMP VIS RIO
   Niculescu D, 2001, GLOB TELECOMM CONF, P2926, DOI 10.1109/GLOCOM.2001.965964
   Pigeau A, 2004, J VIS COMMUN IMAGE R, V15, P425, DOI 10.1016/j.jvcir.2004.04.002
   Pope AR, 2000, INT J COMPUT VISION, V40, P149, DOI 10.1023/A:1026502202780
   Quack T., 2008, CIVR, P47
   Rattenbury T., 2007, Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval, P103
   ROTA GC, 1979, INTRO PROBABILITY RA
   Se S, 2001, IEEE INT CONF ROBOT, P2051, DOI 10.1109/ROBOT.2001.932909
   Serdyukov P, 2009, PROCEEDINGS 32ND ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P484, DOI 10.1145/1571941.1572025
   Simon I, 2007, IEEE I CONF COMP VIS, P274
   Smith TR, 1996, COMPUTER, V29, P54, DOI 10.1109/2.493457
   SNAVELY N, 2008, P C COMP VIS PATT RE
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Spinellis DD, 2003, IEEE PERVAS COMPUT, V2, P72, DOI 10.1109/MPRV.2003.1203756
   SRINIVASAN A, 1993, INT J GEOGR INF SYST, V7, P479, DOI 10.1080/02693799308901978
   SZELISKI R, 2009, P 17 ACM INT C MULT, P961
   Torniai C., 2007, SHARING DISCOVERING
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Toyama Kentaro., 2003, P 11 ACM INT C MULTI, P156
   ULRICH W, 2000, P IEEE INT C ROB AUT, P1023
   VALENTINODEVRIE.J, 2010, WALL STREET J   0723
   WAGENAAR WA, 1986, COGNITIVE PSYCHOL, V18, P225, DOI 10.1016/0010-0285(86)90013-7
   Yibin Li, 2009, 2009 IEEE International Conference on Automation and Logistics (ICAL), P1957, DOI 10.1109/ICAL.2009.5262626
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
   Zheng Y., 2009, WWW, P791, DOI [10.1145/1526709.1526816, DOI 10.1145/1526709.1526816]
   Zheng Yan-Tao., 2009, Proceedings of the 17th ACM international conference on Multimedia, P961, DOI DOI 10.1145/1631272.1631468
   ZHENG YT, 2011, P ACM C MULT MOD TAI
   ZHENG YT, 2009, P INT C COMP VIS PAT
NR 97
TC 56
Z9 64
U1 0
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2011
VL 51
IS 1
BP 77
EP 98
DI 10.1007/s11042-010-0630-z
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 705BO
UT WOS:000286103800004
DA 2024-07-18
ER

PT J
AU Zhang, C
   Sadjadi, SM
   Sun, WX
   Rangaswami, R
   Deng, Y
AF Zhang, Chi
   Sadjadi, S. Masoud
   Sun, Weixiang
   Rangaswami, Raju
   Deng, Yi
TI A user-centric network communication broker for multimedia collaborative
   computing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia collaborative applications; Multimedia communication;
   Middleware; Self-management
AB The development of collaborative multimedia applications today follows a vertical development approach, where each application is built on top of low-level network abstractions such as the socket interface. This stovepipe development process is a major inhibitor that drives up the cost of development and slows down the innovation pace of new generations of communication applications. In this paper, we propose a network communication broker (NCB) that provides a unified higher-level abstraction for the class of multimedia collaborative applications. We demonstrate how NCB encapsulates the complexity of network-level communication control and media delivery, and expedites the development of applications with various communication logics. We investigate the minimum necessary requirements for the NCB abstraction. We identify that the concept of user-level sessions involving multiple parties and multiple media, is critical to designing a reusable NCB to facilitate next-generation multimedia communications. Furthermore, the internal design of NCB decouples the user-level sessions from network-level sessions, so that the NCB framework can accommodate heterogeneous networks, and applications can be easily ported to new network environments. In addition, we demonstrate how the extensible and self-managing design of NCB supports dynamic adaptation in response to changes in network conditions and user requirements.
C1 [Zhang, Chi] Juniper Networks, Sunnyvale, CA USA.
   [Sadjadi, S. Masoud; Rangaswami, Raju] Florida Int Univ, Sch Comp & Informat Sci, Miami, FL 33199 USA.
   [Sun, Weixiang] Amazon, Seattle, WA USA.
   [Deng, Yi] Univ N Carolina, Coll Comp & Informat, Charlotte, NC 28223 USA.
C3 Juniper Networks; State University System of Florida; Florida
   International University; Amazon.com; University of North Carolina;
   University of North Carolina Charlotte
RP Zhang, C (corresponding author), Juniper Networks, Sunnyvale, CA USA.
EM chizhang@juniper.net; sadjadi@cis.fiu.edu; weixiang@amazon.com;
   raju@cis.fiu.edu; Yi.Deng@uncc.edu
RI Sun, Weixiang/B-3245-2010
OI Rangaswami, Raju/0009-0000-5243-9451
CR Aksit M., 2003, P 23 INT C DISTR COM
   BLAIR GS, 1998, MIDDL 98 SEPT
   BOND G.W., 2004, ACM Transactions on Internet Technology, V4, P83
   Chen WK, 2001, INT CON DISTR COMP S, P635, DOI 10.1109/ICDSC.2001.918994
   DENG Y, 2006, 30 ANN INT COMP SOFT
   DEY AK, 2000, 22 INT C SOFTW ENG I
   Fide S, 2007, CLUSTER COMPUT, V10, P409, DOI 10.1007/s10586-007-0026-7
   Handley M., 1999, SIP: Session Initiation Protocol
   HILTUNEN MA, 1996, INT J COMPUTER SYSTE, V11, P125
   *ITU T, 2000, H323V4 ITUT
   JUSZCZYK L, 2008, 6 INT WORKSH MIDDL P
   Kephart JO, 2003, COMPUTER, V36, P41, DOI 10.1109/MC.2003.1160055
   Kortuem G., 2001, P 2001 INT C PEER TO
   LENNOX J, 2003, ACM NOSSDAV
   McKinley PK, 2004, COMPUTER, V37, P56, DOI 10.1109/MC.2004.48
   McKinley PK, 2003, IEEE T COMPUT, V52, P713, DOI 10.1109/TC.2003.1204828
   *PARL GROUP, PARL OS SPEC
   Pereira FAQ, 2006, SOFTWARE PRACT EXPER, V36, P495, DOI 10.1002/spe.706
   Rosenberg J., 2003, 3489 RFC
   SCHMIDT DC, 1993, CONCURRENCY-PRACT EX, V5, P269, DOI 10.1002/cpe.4330050405
   Schulzrinne H., 2003, RTP TRANSPORT PROTOC
   Sousa J.P., 2002, SOFTWARE ARCHITECTUR, P29
   *SUN, JAV TEL API
   van Renesse Robbert., 1998, Software Practice Expert, V28
   ZHANG C, 2006, P 2 INT C COLL COMP
   ZHANG J, 2007, ACM IFIP USENIX 8 IN
NR 26
TC 2
Z9 2
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2010
VL 50
IS 2
BP 335
EP 357
DI 10.1007/s11042-009-0385-6
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 622XE
UT WOS:000279698700003
DA 2024-07-18
ER

PT J
AU Chatzichristofis, SA
   Boutalis, YS
AF Chatzichristofis, Savvas A.
   Boutalis, Yiannis S.
TI Content based radiology image retrieval using a fuzzy rule based
   scalable composite descriptor
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBMIR; Image retrieval; Fuzzy methods; Medical images
ID COLOR
AB The rapid advances made in the field of radiology, the increased frequency in which oncological diseases appear, as well as the demand for regular medical checks, led to the creation of a large database of radiology images in every hospital or medical center. There is now an imperative need to create an effective method for the indexing and retrieval of these images. This paper proposes a new method of content based radiology medical image retrieval. The description of images relies on a Fuzzy Rule Based Compact Composite Descriptor (CCD), which includes global image features capturing both brightness and texture characteristics in a 1D Histogram. Furthermore, the proposed descriptor includes the spatial distribution of the information it describes. The most important feature of the proposed descriptor is that its size adapts according to the storage capabilities of the application that uses it. Experiments carried out on a large group of images show that even at 48 bytes per image, the proposed descriptor demonstrates a high level of accuracy in its results. To evaluate the performance of the proposed feature, the mean average precision was used.
C1 [Chatzichristofis, Savvas A.; Boutalis, Yiannis S.] Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
   [Boutalis, Yiannis S.] Univ Erlangen Nurnberg, Dept Elect Elect & Commun Engn, Chair Automat Control, D-91058 Erlangen, Germany.
C3 Democritus University of Thrace; University of Erlangen Nuremberg
RP Chatzichristofis, SA (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
EM schatzic@ee.duth.gr; ybout@ee.duth.gr
RI Chatzichristofis, Savvas/AAA-2698-2020
OI Chatzichristofis, Savvas/0000-0002-4657-4435
CR [Anonymous], 1999, P 7 IEEE INTL C COMP
   [Anonymous], 9 INT WORKSH IM AN M
   [Anonymous], 2008, DIGITAL IMAGING COMM
   CAICEDO JC, 2007, LECT NOTES COMPUTER, V4872
   CHATZICHRISTOFI.SA, 2009, 6 IASTED INT C SIGN, P1
   CHATZICHRISTOFI.SA, 2009, 2 INT WORKSH SIM SEA
   Chatzichristofis S, 2007, IASTED INT C ART INT
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   CHEE SW, 2002, ETRI J, V23, P7
   CHI Z, 1996, ADV FUZZY SYSTEMS AP, V10
   Chu WW, 1998, IEEE T KNOWL DATA EN, V10, P872, DOI 10.1109/69.738355
   Comaniciu D, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P76, DOI 10.1109/ACV.1998.732861
   Datta AK, 2008, OPT LASER TECHNOL, V40, P1, DOI 10.1016/j.optlastec.2007.04.006
   DESELAERS T, 2006, LECT NOTES COMPUTER, V4022
   Deselaers T, 2008, PATTERN RECOGN LETT, V29, P1988, DOI 10.1016/j.patrec.2008.03.001
   Deselaers T, 2008, INFORM RETRIEVAL, V11, P77, DOI 10.1007/s10791-007-9039-3
   Dhawan AP., 2003, MED IMAGE ANAL
   Glatard T., 2004, P 6 INT WORKSHOP MUL, P135, DOI DOI 10.1145/1026711.1026734
   Guld Mark O, 2006, LECT NOTES COMPUTER
   Güld MO, 2004, PRO BIOMED OPT IMAG, V5, P211, DOI 10.1117/12.535914
   Gustafson D. E., 1979, Proceedings of the 1978 IEEE Conference on Decision and Control Including the 17th Symposium on Adaptive Processes, P761
   JEONG SJ, 1999, IEEE TENCON, P982
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Korn PF, 1998, IEEE T KNOWL DATA EN, V10, P889, DOI 10.1109/69.738356
   Lehmann TM, 2004, LECT NOTES COMPUT SC, V3214, P989
   LUX M, 2008, ACM MULTIMEDIA, P1085
   LUZA, 2006, P 19 IEEE S COMP BAS, P93
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MERTZIOS B, 2004, LOGIC FILTERS THEORY, pCH11
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Nikolaou N, 2002, ENG APPL ARTIF INTEL, V15, P81, DOI 10.1016/S0952-1976(02)00028-3
   Poullot S., 2007, Proceedings of the ACM International Conference on Image and Video Retrieval, P348
   Prusinkiewicz P, 1989, LINDENMAYER SYSTEMS
   Sagan H., 1994, SPACE FILLING CURVES
   Serratosa F, 2006, PATTERN RECOGN, V39, P921, DOI 10.1016/j.patcog.2005.12.005
   Tagare HD, 1997, J AM MED INFORM ASSN, V4, P184, DOI 10.1136/jamia.1997.0040184
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Vonikakis V, 2008, IET IMAGE PROCESS, V2, P19, DOI 10.1049/iet-ipr:20070012
   Willy PM, 2004, 17TH IEEE SYMPOSIUM ON COMPUTER-BASED MEDICAL SYSTEMS, PROCEEDINGS, P103, DOI 10.1109/CBMS.2004.1311699
   Yao J, 2008, NEUROCOMPUTING, V71, P2012, DOI 10.1016/j.neucom.2007.10.021
   ZAGORIS K, 2009, 2 INT WORKSH SIM SEA
NR 41
TC 20
Z9 22
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2010
VL 46
IS 2-3
SI SI
BP 493
EP 519
DI 10.1007/s11042-009-0349-x
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 542GF
UT WOS:000273480300014
DA 2024-07-18
ER

PT J
AU Natarajan, A
   Cai, Y
   Wong, J
AF Natarajan, Ashwin
   Cai, Ying
   Wong, Johnny
TI An enhanced client-centric approach for efficient video broadcast
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multimedia communication; Video on demand; Periodic broadcast; Service
   latency
ID ON-DEMAND; POPULAR VIDEOS; SERVICE; SCHEME
AB Periodic broadcast is a cost-effective solution for large-scale distribution of popular videos. Regardless of the number of video requests, this strategy guarantees a constant worst service latency to all clients, making it possible to serve a large community with a minimal amount of broadcast bandwidth. Although many efficient periodic broadcast techniques have been proposed, most of them impose rigid requirements on client receiving bandwidth. They either demand clients to have the same bandwidth as the video server, or limit them to receive no more than two video streams at any one time. In our previous work, we addressed this problem with a Client-Centric Approach (CCA). This scheme takes into consideration both server broadcast bandwidth and client receiving bandwidth and allows clients to use all their receiving capability for prefetching broadcast data. As a result, given a fixed broadcast bandwidth, a shorter broadcast period can be achieved with an improved client communication capability. In this paper, we present an enhanced version of CCA to further leverage client bandwidth for more efficient video broadcast. The new scheme reduces the broadcast latency up to 50% as compared to CCA. We prove the correctness of this new technique and provide an analytical evaluation to show its performance advantage as compared with some existing techniques.
C1 [Natarajan, Ashwin; Cai, Ying; Wong, Johnny] Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
C3 Iowa State University
RP Cai, Y (corresponding author), Iowa State Univ, Dept Comp Sci, Ames, IA 50011 USA.
EM ashwin@cs.iastate.edu; yingcai@cs.iastate.edu; wong@cs.iastate.edu
CR AGGARWAL CC, 1996, P IEEE INT C MUL SYS
   BAGOUET O, 2003, P SPIE C MULT COMP N, P220
   Banerjee S, 2002, ACM SIGCOMM COMP COM, V32, P205, DOI 10.1145/964725.633045
   Cai Y, 2007, IEEE J SEL AREA COMM, V25, P140, DOI 10.1109/JSAC.2007.070114
   Cai Y, 2006, IEEE T KNOWL DATA EN, V18, P1711, DOI 10.1109/TKDE.2006.181
   Chu YH, 2000, PERF E R SI, V28, P1, DOI 10.1145/345063.339337
   Cui Y, 2004, IEEE J SEL AREA COMM, V22, P91, DOI 10.1109/JSAC.2003.818799
   Dan A., 1994, Proceedings ACM Multimedia '94, P15, DOI 10.1145/192593.192614
   Dan A, 1996, MULTIMEDIA SYST, V4, P112, DOI 10.1007/s005300050016
   Eager D, 2001, IEEE T KNOWL DATA EN, V13, P742, DOI 10.1109/69.956098
   Gao LX, 2002, MULTIMEDIA SYST, V8, P284, DOI 10.1007/s005300100049
   Griwodz C, 2000, PERF E R SI, V27, P20, DOI 10.1145/346000.346006
   Hua K. A., 1998, Proceedings ACM Multimedia 98, P191, DOI 10.1145/290747.290771
   HUA KA, 1997, P ACM SIGCOMM 97 CAN
   Juhn LS, 1997, IEEE T BROADCAST, V43, P268, DOI 10.1109/11.632927
   KUA KA, 2001, J APPL SYST STUD JAS, V2, P686
   KUA KA, 1998, P INT C COMP COMM NE, P848
   PARIS J, 2000, P EUR C, P107
   Pâris JF, 2001, IEEE IC COMP COM NET, P418, DOI 10.1109/ICCCN.2001.956299
   PARIS JF, 1999, P 1999 MULT COMP NET, P317
   Sheu JP, 2004, IEEE T BROADCAST, V50, P120, DOI 10.1109/TBC.2004.828754
   Sheu S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P110, DOI 10.1109/MMCS.1997.609583
   Tantaoui MA, 2004, IEEE T BROADCAST, V50, P289, DOI 10.1109/TBC.2004.834202
   TRAN DA, 2004, IEEE J SEL AREA COMM, V22, P91
   Tseng YC, 2002, IEEE T COMMUN, V50, P1348, DOI 10.1109/TCOMM.2002.801466
   Viswanathan S, 1996, MULTIMEDIA SYST, V4, P197, DOI 10.1007/s005300050023
   Yu HF, 2007, IEEE T BROADCAST, V53, P103, DOI 10.1109/TBC.2006.888917
NR 27
TC 11
Z9 11
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2009
VL 43
IS 2
BP 179
EP 193
DI 10.1007/s11042-009-0263-2
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 430WI
UT WOS:000265021100004
DA 2024-07-18
ER

PT J
AU Montagnuolo, M
   Messina, A
AF Montagnuolo, Maurizio
   Messina, Alberto
TI Parallel neural networks for multimodal video genre classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video annotation; Genre recognition; Neural network; Feature extraction;
   Multimedia semantics
ID MODELS
AB Improvements in digital technology have made possible the production and distribution of huge quantities of digital multimedia data. Tools for high-level multimedia documentation are becoming indispensable to efficiently access and retrieve desired content from such data. In this context, automatic genre classification provides a simple and effective solution to describe multimedia contents in a structured and well understandable way. We propose in this article a methodology for classifying the genre of television programmes. Features are extracted from four informative sources, which include visual-perceptual information (colour, texture and motion), structural information (shot length, shot distribution, shot rhythm, shot clusters duration and saturation), cognitive information (face properties, such as number, positions and dimensions) and aural information (transcribed text, sound characteristics). These features are used for training a parallel neural network system able to distinguish between seven video genres: football, cartoons, music, weather forecast, newscast, talk show and commercials. Experiments conducted on more than 100 h of audiovisual material confirm the effectiveness of the proposed method, which reaches a classification accuracy rate of 95%.
C1 [Montagnuolo, Maurizio] Univ Turin, Dept Comp Sci, I-10149 Turin, Italy.
   [Messina, Alberto] RAI Radiotelevis Italiana, Ctr Res & Technol Innovat, I-10135 Turin, Italy.
C3 University of Turin
RP Montagnuolo, M (corresponding author), Univ Turin, Dept Comp Sci, Corso Svizzera 185, I-10149 Turin, Italy.
EM montagnuolo@di.unito.it; a.messina@rai.it
OI Messina, Alberto/0000-0002-8262-2449
CR ALBIOL A, 2004, INT WORKSH IM AN MUL
   [Anonymous], 1999, The Nature Statist. Learn. Theory
   [Anonymous], 1961, Adaptive control processes: a guided tour, DOI DOI 10.1515/9781400874668
   [Anonymous], 2000, P 2 INT S NEUR COMP
   BLUM DW, 1992, Patent No. 5151788
   BOGGS J, 2006, ART WATCHING FILMS T
   BRUGNARA F, 2000, RIAO CONTENT BASED M
   CALIC J, 2004, THESIS U LONDON
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   CHENG W, 2006, 8 INT C ADV CONC INT, P1210
   Covell M, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P461, DOI 10.1109/MMSP.2006.285351
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   DIMITROVA N, 2000, EUR C SIGN PROC TAMP
   DINH PQ, 2002, ACCV2002
   Dorado A, 2004, IEEE T CIRC SYST VID, V14, P622, DOI 10.1109/TCSVT.2004.826764
   *EBU UER, 2007, TECHN REV EBU, V3322
   FISCHER S, 1995, ACM MULTIMEDIA, P295
   GLASBERG R, 2005, 13 EUR SIGN PROC C E
   GOH KS, 2004, 2004008 MERL
   Ianeva TI, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I, PROCEEDINGS, P449
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Liu Z, 1998, 1998 IEEE SECOND WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P27, DOI 10.1109/MMSP.1998.738908
   Liu Z, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P343
   LOIACONO A, 2005, TECHNICAL REV EBU, V303
   MESSINA A, 2008, INT WORKSH AMB MED D
   MESSINA A, 2008, IEEE INT C MULT EXP
   Messina A., 2006, IEEE INT C SIGN IM T
   Montagnuolo M., 2007, Journal of Digital Information Management, V5, P67
   MONTAGNUOLO M, 2008, 2 INT WORKSH MULT DA
   Montagnuolo M, 2007, DEXA 2007: 18TH INTERNATIONAL CONFERENCE ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P99, DOI 10.1109/DEXA.2007.92
   NOVAK AP, 1988, Patent No. 4750213
   PARNAL S, 2003, TV ANYTIME NEW STAND
   POLI JP, 2006, CIMCA 06, P31
   Polikar R., 2006, IEEE Circuits and Systems Magazine, V6, P21, DOI 10.1109/MCAS.2006.1688199
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Roach M, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P146, DOI 10.1109/ISIMP.2001.925353
   Roach MJ, 2001, INT CONF ACOUST SPEE, P1557, DOI 10.1109/ICASSP.2001.941230
   ROACH MJ, 2002, THESIS U WALES SWANS
   Rumelhart D., 1986, PARALLEL DISTRIBUTED, P318
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sanchez J. M., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P237
   Satterwhite B, 2004, IEEE POTENTIALS, V23, P9, DOI 10.1109/MP.2004.1309790
   Snoek CGM, 2005, MULTIMED TOOLS APPL, V25, P5, DOI 10.1023/B:MTAP.0000046380.27575.a5
   Suresh V, 2005, 2005 INTERNATIONAL CONFERENCE ON INTELLIGENT SENSING AND INFORMATION PROCESSING, PROCEEDINGS, P187
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Takagi S, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P461
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   Taskiran C. M., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4676, P276, DOI 10.1117/12.451098
   TASKIRAN CM, 2003, 8 INT WORKSH VIS CON, P84
   Tekalp M., 1995, DIGITAL VIDEO PROCES
   TOMASI C, 2005, ESTIMATING GAUSSIAN
   Truong BT, 2000, INT C PATT RECOG, P230, DOI 10.1109/ICPR.2000.902901
   Vasconcelos N, 2000, IEEE T IMAGE PROCESS, V9, P3, DOI 10.1109/83.817595
   VROOMEN J, 1993, EUROSPEECH 93 BERL S, P577
   Wang J, 2006, J CHEM THEORY COMPUT, V2, P18, DOI 10.1021/ct050118b
   Wickenberg-Bolin U, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-127
   Xu LQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P485
   Yuan X, 2006, IEEE IMAGE PROC, P2905, DOI 10.1109/ICIP.2006.313037
   YUAN Y, 2002, IEEE 1 INT C MACH LE, V3, P1153
   ZHIWEN Y, 2004, IEEE INT C INF TECHN, P658
   [No title captured]
NR 62
TC 29
Z9 31
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2009
VL 41
IS 1
BP 125
EP 159
DI 10.1007/s11042-008-0222-3
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 387LJ
UT WOS:000261953400006
DA 2024-07-18
ER

PT J
AU Onasoglou, E
   Daras, P
AF Onasoglou, Efstathios
   Daras, Petros
TI Semantic force relevance feedback, content-free 3D object retrieval and
   annotation propagation: bridging the gap and beyond
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE relevance feedback; semantic propagation; clustering
ID FRAMEWORK; IMAGE
AB Relevance Feedback is a technique used for enhancing retrieval accuracy in multimedia database systems. In this paper two novel relevance feedback algorithms are proposed for 3D object databases, in which the relative scores of various users, which express users' subjectivity, are kept accumulatively as additional descriptors. Each object is interpreted as a charged particle, whose relative scores represent the value of the charge. Based on these charges, semantic forces are calculated between the 3D objects, which are repelled or attracted properly in the feature space. The forces are of dual nature, semantic and geometric, in the first algorithm, whereas they are purely semantic in the second one. Furthermore, a novel algorithm for annotation propagation is developed, which is based on a linear prediction scheme of the changes that must be made in the feature vector of a newly added 3D object in the database, according to alterations that has already taken place to objects in the database. The combination of low and high level features in one formula, is able to fill the semantic gap as much as possible till time being, while the proposed content-free retrieval method illustrates the fact that in the long run, a purely semantic algorithm can provide excellent retrieval results.
C1 [Onasoglou, Efstathios; Daras, Petros] Ctr Res & Technol Hellas, Informat & Telemat Inst, Thessaloniki 57001, Greece.
C3 Centre for Research & Technology Hellas
RP Onasoglou, E (corresponding author), Ctr Res & Technol Hellas, Informat & Telemat Inst, 1st Km Thermi Panorama Rd,POB 60361, Thessaloniki 57001, Greece.
EM onaso@iti.gr; daras@iti.gr
RI Daras, Petros/F-5284-2012
OI Daras, Petros/0000-0003-3814-6710
CR [Anonymous], 1998, STAT LEARNING THEORY
   Atmosukarto I, 2005, 11TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P334, DOI 10.1109/MMMC.2005.39
   Bang HY, 2002, IEEE IMAGE PROC, P968
   BLACHNIK M, 2005, P 12 INT C NEUR INF, P445
   CHAN LW, 2005, P INT C IM VID RETR, P425
   Chen Q, 2003, NAT MATER, V2, P324, DOI 10.1038/nmat878
   CHEN T, 2005, IEEE P INT C AC SPEE
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   COX IJ, 1996, P INT C PATT REC, P36
   Daras P, 2006, IEEE T MULTIMEDIA, V8, P101, DOI 10.1109/TMM.2005.861287
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   He X., 2002, PROC ACM MULTIMEDIA, P343
   Ishikawa A, 1998, KAGAKU KOGAKU RONBUN, V24, P24, DOI 10.1252/kakoronbunshu.24.24
   KANADE T, 2004, P INT S DIG LIB KNOW, P24
   Kazhdan M., 2003, P EUR ACM SIGGRAPH S, V6, P156
   Leifman G, 2005, VISUAL COMPUT, V21, P865, DOI 10.1007/s00371-005-0341-z
   Liu D, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P89, DOI 10.1109/ICME.2006.262557
   Ljung L., 1987, SYSTEM IDENTIFICATIO
   Oh S, 2004, LECT NOTES COMPUT SC, V3115, P448
   Rui Y., 1998, STORAGE RETRIEVAL IM, P25
   Sayood Khalid., 2003, INTRO DATA COMPRESSI, VSecond
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Stork D.G., 2000, Pattern Classification, V2nd
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tian Q, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1199, DOI 10.1109/ICME.2000.871576
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   TSANG V, 2004, P 8 C COMP NAT LANG, P81
   Wang EC, 2006, BRIT J NEUROSURG, V20, P24, DOI 10.1080/02688690600598257
   Wang JG, 2007, NEUROCOMPUTING, V70, P801, DOI 10.1016/j.neucom.2006.10.023
   Willett P, 1998, J CHEM INF COMP SCI, V38, P983, DOI 10.1021/ci9800211
   Zhang C, 2002, IEEE T MULTIMEDIA, V4, P260, DOI 10.1109/TMM.2002.1017738
   ZHANG HJ, 2001, P INT WORKSH MULT CO, P83
   ZITNICK C, 2003, THESIS CARNEGIE MELL
NR 35
TC 3
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2008
VL 39
IS 2
BP 217
EP 241
DI 10.1007/s11042-008-0216-1
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 322NA
UT WOS:000257381400005
DA 2024-07-18
ER

PT J
AU Furini, M
   Montangero, M
AF Furini, Marco
   Montangero, Manuela
TI The impact of incentive mechanisms in multi-channel mobile music
   distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE multi-channel mobile music; mobile technologies; cellphones
AB Record labels and telecoms are using the pervasiveness of mobile technologies to create a mobile music market, where customers can have their preferred music at any time and in any place. The idea is to replicate the successful strategy of the Internet-based music market into the mobile scenario. In this paper we first analyze the current mobile music market and we show that this strategy leads to several problems (e.g., excessive download time, cost and protection). As a second contribution, we propose and analyze a multi-channel distribution strategy, where customers can cooperate to music distribution. The approach is based on the cellphone network, the free-of-charge communication technologies provided by cellphones, and on an incentive mechanism that financially compensates users for their cooperation in music distribution. The approach evaluation shows that the employment of an effective incentive mechanism can mitigate the problems of the current mobile music scenario, as it provides benefits to customers, cellphone network providers and music stores.
C1 [Furini, Marco] Univ Piemonte Orientale, Alessandria, Italy.
   [Montangero, Manuela] Univ Modena & Reggio Emilia, Modena, Italy.
C3 University of Eastern Piedmont Amedeo Avogadro; Universita di Modena e
   Reggio Emilia
RP Furini, M (corresponding author), Univ Piemonte Orientale, Alessandria, Italy.
EM furini@mfn.unipmn.it; montangero.manuela@unimo.it
RI Furini, Marco/O-2867-2016; MONTANGERO, Manuela/O-2400-2016
OI Furini, Marco/0000-0003-1094-6521; MONTANGERO,
   Manuela/0000-0001-8827-5495
CR ALMEROTH KC, 2004, P IEEE GLOB DEC
   ANAGNOSTAKIS KG, 2004, INT C DISTR COMP SYS
   [Anonymous], 2002, Proceedings of the 5th ACM international workshop on Modeling analysis and simulation of wireless and mobile systems-MSWiM '02, DOI [DOI 10.1145/570764.570768, DOI 10.1145/570758.570768]
   Antoniadis P, 2005, ACM SIGECOM EXCH, V5, P11
   BIDDLE K, 2002, P ACM WORKSH DRM
   BROWN B, 2001, P ECSCW 2001 BOHN GE
   Buttyán L, 2003, MOBILE NETW APPL, V8, P579, DOI 10.1023/A:1025146013151
   COBB CJ, 1986, J RETAILING, V62, P384
   DINGLEDINE R, 2002, P 6 INT FIN CRYPT C
   Feldman M., 2004, EC 04, P102, DOI [10.1145/988772.988788, DOI 10.1145/988772.988788]
   HARJULA E, 2004, P 3 INT C MOB UB MUL
   HATT N, 2005, TIKMA200516
   Hu THT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATIONS, VOLS 1-7, P1411, DOI 10.1109/ICC.2004.1312744
   Hughes D., 2005, IEEE Distributed Systems Online, V6
   *IFIP, 2006, DIG MUS REP 2006 FAC
   LIANG J, 2005, IEEE INF MIAM FL US
   Messerges T.S., 2003, Digital Rights Management in a 3G Mobile Phone and Beyond
   *MICR CORP, 2007, MICR PLAYREADY POW N
   O'Grady MJ, 2004, IEEE MULTIMEDIA, V11, P62, DOI 10.1109/MMUL.2004.30
   Premkumar GP, 2003, COMMUN ACM, V46, P89, DOI 10.1145/903893.903899
   Resnick P, 2000, COMMUN ACM, V43, P45, DOI 10.1145/355112.355122
   ROCZNIAK A, 2005, P 13 ANN ACM INT C M, P311
   ROOK DW, 1987, J CONSUM RES, V14, P189, DOI 10.1086/209105
   SALEM NB, 2003, P MOBIHOC JUN
   SUN Q, 2004, INT C DISTR COMP SYS
   TENNENT P, 2005, P 7 INT C HUM COMP I
   *WIR INT, 2005, WORLD CELL CONN RES
NR 27
TC 12
Z9 12
U1 0
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2008
VL 37
IS 3
BP 365
EP 382
DI 10.1007/s11042-007-0158-z
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 274BI
UT WOS:000253976400006
DA 2024-07-18
ER

PT J
AU Babu, RV
   Perkis, A
   Hillestad, OI
AF Babu, R. Venkatesh
   Perkis, Andrew
   Hillestad, Odd Inge
TI Evaluation and monitoring of video quality for UMA enabled video
   streaming systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE video quality metrics; UMA; blockiness metric; pocket loss metric; NR
   metrics
AB This paper deals with monitoring user perception of multimedia presentations in a Universal Multimedia Access (UMA) enabled system using objective no-reference (NR) metrics. These NR metrics are designed for an UMA-enabled system, in a novel architecture, for a multimedia viewer. The first metric measures block-edge impairments in a video frame at the receiver end, based on the observation that they occur in regions with low spatial activity. The second metric evaluates the quality of the reconstructed video frame in the event of packet loss. Here, the structure of the artifact is itself exploited for the evaluation. Both the metrics involve low computational complexity and are feasible for real-time monitoring of streaming video in a multimedia communication scenario. Further, in rate-adaptive streaming of video, these metrics could serve as feedback parameters to dynamically adapt the bit rates based on network congestion.
C1 [Babu, R. Venkatesh] Yahoo R&D, Bangalore, Karnataka, India.
   [Perkis, Andrew; Hillestad, Odd Inge] Norwegian Univ Sci & Technol, Ctr Quantifiable Qual Serv Commun Syst, N-7034 Trondheim, Norway.
C3 Yahoo! Inc; Yahoo! Inc India; Norwegian University of Science &
   Technology (NTNU)
RP Babu, RV (corresponding author), Yahoo R&D, Bangalore, Karnataka, India.
EM venkatesh.babu@gmail.com; andrew@Q2S.ntnu.no; hillesta@Q2S.ntnu.no
RI Perkis, Andrew/AAI-4792-2020; Radhakrishnan, Venkatesh Babu/D-5313-2009
OI Perkis, Andrew/0000-0003-1414-2870; Radhakrishnan, Venkatesh
   Babu/0000-0002-1926-1804
CR BOYCE JM, 1998, ACM MULTIMEDIA, P181
   Caviedes J, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P53, DOI 10.1109/ICIP.2002.1038901
   Farias MCQ, 2005, IEEE T CONSUM ELECTR, V51, P983, DOI 10.1109/TCE.2005.1510512
   FEAMSTER N, 2002, INT PACK VID WORKSH
   Gao WF, 2002, IEEE T CIRC SYST VID, V12, P1150, DOI 10.1109/TCSVT.2002.806817
   KIMURA J, 1999, SPIE INT S VOIC VID
   Lu LG, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P61, DOI 10.1109/ICME.2002.1035718
   Marziliano P, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P57, DOI 10.1109/ICIP.2002.1038902
   *NTT DOCOMO, 1996, ERR GEN SOFTW
   Pereira F, 2003, IEEE SIGNAL PROC MAG, V20, P63, DOI 10.1109/MSP.2003.1184340
   Perkis A, 2001, CIRC SYST SIGNAL PR, V20, P387, DOI 10.1007/BF01201409
   SUTHAHARAN S, 2003, P IEEE INT C AC SPEE, V3, P681
   Verscheure O, 1999, REAL-TIME IMAGING, V5, P305, DOI 10.1006/rtim.1999.0175
   Vlachos T, 2000, ELECTRON LETT, V36, P1106, DOI 10.1049/el:20000847
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P981, DOI 10.1109/ICIP.2000.899622
   Winkler S, 1999, PROC SPIE, V3644, P175, DOI 10.1117/12.348438
   WINKLER S, 2001, P 4 INT S WIR PERS M, P553
   WU HR, 1996, INT C SIGN PROC, V2, P962
   Yang FZ, 2005, IEEE SIGNAL PROC LET, V12, P685, DOI 10.1109/LSP.2005.855553
   Yuen M, 1998, SIGNAL PROCESS, V70, P247, DOI 10.1016/S0165-1684(98)00128-5
   YUEN M, 1997, SIGNAL PROCESS, V4, P317
NR 23
TC 6
Z9 7
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2008
VL 37
IS 2
BP 211
EP 231
DI 10.1007/s11042-007-0140-9
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 267PV
UT WOS:000253522600006
DA 2024-07-18
ER

PT J
AU Bailenson, JN
   Yee, N
AF Bailenson, Jeremy N.
   Yee, Nick
TI Virtual interpersonal touch: Haptic interaction and copresence in
   collaborative virtual environments
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE presence; social touch; haptic interaction; collaborative virtual
   environments
ID GENDER
AB As digital communication becomes more commonplace and sensory rich, understanding the manner in which people interact with one another is crucial. In the current study, we examined the manners in which people touch digital representations of people, and compared those behaviors to the manner in which they touch digital representations of nonhuman objects. Results demonstrated that people used less force when touching people than other nonhuman objects, and that people touched the face with less force than the torso area. Finally, male digital representations were touched with more force than female representations by subjects of both genders. We discuss the implications of these data to the development of haptic communication systems as well as for a methodology of measuring the amount of copresence in virtual environments.
C1 [Bailenson, Jeremy N.; Yee, Nick] Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
C3 Stanford University
RP Bailenson, JN (corresponding author), Stanford Univ, Dept Commun, Stanford, CA 94305 USA.
EM Bailenson@stanford.edu
CR [Anonymous], 2004, P 7 ANN INT WORKSH P
   [Anonymous], TELEPHONIC ARM WREST
   Bailenson JN, 2005, PRESENCE-VIRTUAL AUG, V14, P379, DOI 10.1162/105474605774785235
   Bailenson JN, 2005, PSYCHOL SCI, V16, P814, DOI 10.1111/j.1467-9280.2005.01619.x
   Bailenson JN, 2002, J VISUAL COMP ANIMAT, V13, P313, DOI 10.1002/vis.297
   BAILENSON JN, 2007, IN PRESS HUM COMPUT, V22
   Bailyn B, 2003, HIST REFLECTIONS, V29, P1
   BENTE G, 2004, INT COMM ASS C MAY 2
   Blascovich J, 2002, PSYCHOL INQ, V13, P103, DOI 10.1207/S15327965PLI1302_01
   BRAVE S, 2001, UNIVERSAL ACCESS HCI, P145
   BRAVE S, 1998, P 1998 ACM C COMP SU, P169
   BURGOON JK, 1990, HUM COMMUN RES, V17, P232, DOI 10.1111/j.1468-2958.1990.tb00232.x
   Burgoon JK, 1999, J MANAGE INFORM SYST, V16, P33, DOI 10.1080/07421222.1999.11518255
   BURGOON JK, 1991, J NONVERBAL BEHAV, V15, P233, DOI 10.1007/BF00986924
   CHANG A, 2002, ACM DIS 2002 DES INT
   Chaplin WF, 2000, J PERS SOC PSYCHOL, V79, P110, DOI 10.1037/0022-3514.79.1.110
   Churchill E. F., 2001, COLLABORATIVE VIRTUA
   CRUSCO AH, 1984, PERS SOC PSYCHOL B, V10, P512, DOI 10.1177/0146167284104003
   FOGG B, 1998, CHI 98 C HUM FAC COM
   Garau M, 2005, PRESENCE-TELEOP VIRT, V14, P104, DOI 10.1162/1054746053890242
   GOLDBERG K, 1993, SIGGRAPH 93 INT C CO
   Greenwald AG, 1998, J PERS SOC PSYCHOL, V74, P1464, DOI 10.1037/0022-3514.74.6.1464
   HO C, 1998, BT PRES WORKSH
   HOFFMAN HG, 2004, SCI AM MAGAZINE  AUG
   Hubbard ASE, 2003, J APPL SOC PSYCHOL, V33, P2427
   Kim J, 2004, PRESENCE-TELEOP VIRT, V13, P328, DOI 10.1162/1054746041422370
   LANIER J, 2001, VIRTUALLY THERE, P66
   Lee KM, 2004, COMMUN THEOR, V14, P27, DOI 10.1111/j.1468-2885.2004.tb00302.x
   Lee KM, 2004, HUM COMMUN RES, V30, P182, DOI 10.1111/j.1468-2958.2004.tb00730.x
   Loomis J.M., 1992, Presence: Teleoperators and Virtual Environments, V1, P113, DOI 10.1162/pres.1992.1.1.113
   MANTOVANI F, 2001, VIRTUAL REALITY LEAR, pCH12
   MARSELLA S, 2003, SPRINGER COGNITIVE T
   Meehan M, 2002, ACM T GRAPHIC, V21, P645, DOI 10.1145/566570.566630
   NOMA S, 1997, P 13 HUM INT S, P11
   OAKLEY I, 2001, SOLVING MULTI TARGET, P357
   Parise S., 1996, P 1996 ACM C COMPUTE, P399, DOI DOI 10.1145/240080.240351
   REEVES B, 1996, NEDUA EQUATION PEOPL
   RIZZO A, 2004, INT C HUM COMP INT
   Sallnas E.-L., 2000, ACM Transactions on Computer-Human Interaction, V7, P461, DOI 10.1145/365058.365086
   Slater M, 2004, PRESENCE-VIRTUAL AUG, V13, P484, DOI 10.1162/1054746041944849
   SPROULL L, 1986, MANAGE SCI, V32, P1492, DOI 10.1287/mnsc.32.11.1492
   STEPHEN R, 1986, J SOC PSYCHOL, V126, P141, DOI 10.1080/00224545.1986.9713586
   STRONG R, 1996, FEATHER SCENT SHAKER, P444
   WOODCOCK B, 2005, MMOG CHART
   Yee N, 2006, PRESENCE-VIRTUAL AUG, V15, P309, DOI 10.1162/pres.15.3.309
NR 45
TC 53
Z9 61
U1 1
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2008
VL 37
IS 1
BP 5
EP 14
DI 10.1007/s11042-007-0171-2
PG 10
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 261AT
UT WOS:000253052200002
DA 2024-07-18
ER

PT J
AU Ahmed, M
   Harroud, H
   Impey, R
   Karmouch, A
AF Ahmed, Mohamed
   Harroud, Hamid
   Impey, Roger
   Karmouch, Ahmed
TI Agent-based multimedia presentation and adaptation service
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE agent protocol; authorization policies; agent negotiation; service
   presentation; multimedia abstraction; XML
AB In this paper, we aim to provide adaptive multimedia services especially video ones to end-users in an efficient and secure manner. Users moving outside the office should be able to maintain an office-like environment at their current locations. First, the agents within our proposed architecture negotiate the different communication and interaction factors autonomously and dynamically. Moreover, we needed to develop a user agent in addition to service and system agents that could negotiate the requirements and capabilities at run time to furnish best possible service results. Thus we designed and integrated a video indexing and key framing service within our overall agent-based architecture. We integrated this video indexing and content-based analysis service to adapt the video content according to run time conditions. We designed a video XML schema to validate the media content out of this multimedia service according to specific requirements and features, as we will describe later.
C1 Natl Res Council Canada, HPC Grp, Ottawa, ON K1A 0R6, Canada.
   Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
C3 National Research Council Canada; University of Ottawa
RP Ahmed, M (corresponding author), Natl Res Council Canada, HPC Grp, 1200 Montreal Rd,M50, Ottawa, ON K1A 0R6, Canada.
EM Mohamed.Ahmed@nrc.ca; hharroud@site.uottawa.ca; Roger.Impey@nrc.ca;
   karmouch@site.uottawa.ca
CR Agnihotri L, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1943, DOI 10.1109/ICME.2004.1394641
   Ahmed M, 2002, OPT ENG, V41, P505, DOI 10.1117/1.1429233
   BELLAVISTA P, 2004, IEEE COMPUT, V34, P73
   BUCKLE P, 2000, HOL MAN SYST FIPA WO
   *CAM CONS, 1999, AC341 CAM CONS
   CRANLEY N, 2004, 7 IFIP IEEE INT C MA, P39
   *EUR TEL STAND I, U MOB TEL SYST
   *FIPA ACL, 61 FIPA ACL
   Graham S., 2002, BUILDING WEB SERVICE
   HARROUD H, 2001, IEEE 3 INT C ENT INF, P1110
   HARTMANN J, 1998, 1 ACM INT WORKSH WIR
   HOODA A, 1998, 5 C INT NETW BORD FR
   HOODA A, 1998, P 2 INT WORKSH INT A
   *ISO IEC JTCI, 2001, JTCISC29WG11 ISOIEC
   Kotz D., 1997, IEEE Internet Computing, V1, P58, DOI 10.1109/4236.612217
   KOVACS E, 1998, P MOB AG INT WORKSH, P124
   Lipperts S, 1999, COMPUT NETW, V31, P2053, DOI 10.1016/S1389-1286(99)00079-1
   *MIT CORP, 1996, MIT CATA MICMAC SOFT
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   ZHENG C, 1999, MOB AG TEL APPL WORK, P375
NR 20
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2007
VL 34
IS 3
BP 299
EP 315
DI 10.1007/s11042-007-0113-z
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 189SJ
UT WOS:000248008500002
DA 2024-07-18
ER

PT J
AU de Lange, F
   Nesvadba, J
AF de Lange, Fons
   Nesvadba, Jan
TI Early evaluation of future consumer AV content analysis applications
   with PC networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 4th International Conference on Intelligent Multimedia Computing and
   Networking
CY JUL, 2005
CL Salt Lake City, UT
DE multimedia content analysis; PC networking; prototyping; UPnP; service
   oriented architecture
AB The paper deals with software productivity improvement for consumer multimedia devices by means of PC and component technology and shows how this is done for complex real-time content analysis applications used in advanced new storage products of the future. Content analysis is a relatively new and immature technology. It is used for browsing and searching particular content items among thousands of others on "big" embedded storage devices like hard disks. As the storage capacity of hard disk and flash continues to grow rapidly, content analysis is bound to become a key enabling technology in future storage products. A major problem with content analysis features (and many other features as well) is that underlying algorithms are unstable, sometimes unavailable, or at least, very much in their infancy, and as such, subject to frequent changes. The paper describes an approach to facilitate early evaluation and integration of such immature features. This is done by packing each feature, as-is, into components and by providing PC network technology to interconnect them. In our prototyping framework, each component is an independent executable program that runs on some PC in the network, streaming AV data via TCP/IP and being controlled through UPnP networking. Experiences with large-scale prototyping activities we have carried out for the assessment of future content analysis systems, show that a PC based prototyping approach enables the integration of many different media processing features in a short time and that it allows for accurate analysis of the resource (CPU/memory) requirements of such components.
C1 Philips Res Labs, Eindhoven, Netherlands.
C3 Philips; Philips Research
RP de Lange, F (corresponding author), Philips Res Labs, Eindhoven, Netherlands.
EM Fons.de.Lange@philips.com; Jan.Nesvadba@philips.com
CR de Haan G., 2000, VIDEO PROCESSING MUL
   DEKOCK EA, P 37 C DES AUT
   DELANGE A, Patent No. 050002
   DIMITROVA N, 2002, 9 INT C INF PROC MAN
   Hashimi S., 2003, Service-Oriented Architecture Explained
   HOLLEMANS G, 2003, MEANINGFUL NAVIGATIO
   MA Q, 2001, VIRTUAL TV CHANNEL F
   *MAXT, BIG DRIV MAXT TECHN
   MCKINNEY M, 2003, 4 INT S MUS INF RETR
   Nesvadba J., 2004, Proceedings of 11th International Workshop on Systems, Signals and Image Processing. Ambient Multimedia, P235
   NESVADBA J, 2005, INT C MULT EXP AMST
   NESVADBA J, 2004, IEEE SMC DEN HAAG NE
   Nieuwland A, 2002, DES AUTOM EMBED SYST, V7, P233, DOI 10.1023/A:1019782306621
   *UHAPI, NEW APPL PROGR INT C
   *UPNP, UN PLU PLAY FOR
   MULTIMEDIAN MULTIMED
   CASSANDRA PROJECT
NR 17
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2007
VL 34
IS 2
BP 201
EP 220
DI 10.1007/s11042-006-0090-7
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 178AX
UT WOS:000247194700005
OA hybrid
DA 2024-07-18
ER

PT J
AU Atrey, PK
   Yan, WQ
   Kankanhalli, MS
AF Atrey, Pradeep K.
   Yan, Wei-Qi
   Kankanhalli, Mohan S.
TI A scalable signature scheme for video authentication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE digital video; video authentication; authentication signature; secret
   sharing
AB This paper addresses the problem of ensuring the integrity of a digital video and presents a scalable signature scheme for video authentication based on cryptographic secret sharing. The proposed method detects spatial cropping and temporal jittering in a video, yet is robust against frame dropping in the streaming video scenario. In our scheme, the authentication signature is compact and independent of the size of the video. Given a video, we identify the key frames based on differential energy between the frames. Considering video frames as shares, we compute the corresponding secret at three hierarchical levels. The master secret is used as digital signature to authenticate the video. The proposed signature scheme is scalable to three hierarchical levels of signature computation based on the needs of different scenarios. We provide extensive experimental results to show the utility of our technique in three different scenarios-streaming video, video identification and face tampering.
C1 Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117543, Singapore.
C3 National University of Singapore
RP Atrey, PK (corresponding author), Natl Univ Singapore, Sch Comp, Dept Comp Sci, Singapore 117543, Singapore.
EM pradeepk@comp.nus.edu.sg; yanwq@comp.nus.edu.sg; mohan@comp.nus.edu.sg
RI Kankanhalli, Mohan/Q-9284-2019
OI Kankanhalli, Mohan/0000-0002-4846-2015
CR Atrey PK, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P330, DOI 10.1109/MULMM.2004.1265004
   Celik MU, 2002, PROC SPIE, V4675, P531, DOI 10.1117/12.465311
   DANIEL C, 2002, IEEE INT C IM PROC R, V2, P913
   DITTMAN J, 1999, IEEE INT C MULT COMP, V2, P204
   Divakaran A, 2002, IEEE IMAGE PROC, P932
   Du R, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P893
   ESKICIOGLU AM, 2001, 5 JOINT WORK C COMM, P363
   HE D, 2003, IEEE INT S CIRC SYST, V3, P814
   Lang A, 2003, PROC SPIE, V5020, P452, DOI 10.1117/12.476850
   Lin C Y, 1999, IEEE INT C AC SPEECH, P54
   Mobasseri BG, 2000, IEEE IMAGE PROC, P458, DOI 10.1109/ICIP.2000.900994
   QI Y, 2004, IEEE INT C MULT EXP, V2, P689
   Quisquater JJ, 1997, P SOC PHOTO-OPT INS, V3022, P290, DOI 10.1117/12.263417
   Radhakrishnan R, 2003, P SOC PHOTO-OPT INS, V5020, P644, DOI 10.1117/12.477340
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   STINSON DR, 1995, CRYPTOGRAPHY THEORY, pCH11
   TZENG CH, 2001, MULT SEC WORKSH ACM
   YAN WQ, 2003, IEEE INT S CIRC SYST, V3, P810
   Yin P, 2002, INT CONF ACOUST SPEE, P3461
   Zhang HJ, 1997, PATTERN RECOGN, V30, P643, DOI 10.1016/S0031-3203(96)00109-4
NR 20
TC 23
Z9 25
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2007
VL 34
IS 1
BP 107
EP 135
DI 10.1007/s11042-006-0074-7
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 169VE
UT WOS:000246619400005
DA 2024-07-18
ER

PT J
AU Shyu, ML
   Chen, SC
   Chen, M
   Zhang, CC
   Sarinnapakorn, K
AF Shyu, Mei-Ling
   Chen, Shu-Ching
   Chen, Min
   Zhang, Chengcui
   Sarinnapakorn, Kanoksri
TI Capturing high-level image concepts via affinity relationships in image
   database retrieval
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Content-Based Image Retrieval (CBIR); Markov Model Mediator (MMM);
   Principal Component Analysis (PCA)
AB In this paper, we present a mechanism called Markov Model Mediator (MMM) to facilitate the efficient and effective capturing of high-level image concepts in content-based image retrieval (CBIR). MMM serves as the retrieval engine of the CBIR system and uses affinity-based similarity measures. This mechanism is effective in capturing subjective user concepts in that it not only takes into consideration the global image features, but also learns the high-level concepts of the images from the history of user access patterns and access frequencies on the images in the image database, which differentiates it from the common methods in CBIR. The advantage of our proposed mechanism is that it exploits the richness in the structured description of visual contents as well as the relative affinity relationships among the images. Consequently, it provides the capability to bridge the gap between the low-level features and the high-level concepts. This mechanism is also efficient in that it integrates Principal Component Analysis (PCA) to significantly reduce the image search space at a low cost before performing exact similarity matching. An off-line training subsystem for this framework was implemented and integrated into our system. The experimental results demonstrate that MMM can effectively capture user's high-level concept more quickly.
C1 Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
   Florida Int Univ, Sch Comp Sci, Distributed Multimedia Informat Syst Lab, Miami, FL 33199 USA.
   Univ Alabama Birmingham, Dept Comp & Informat Sci, Birmingham, AL 35294 USA.
C3 University of Miami; State University System of Florida; Florida
   International University; University of Alabama System; University of
   Alabama Birmingham
RP Shyu, ML (corresponding author), Univ Miami, Dept Elect & Comp Engn, Coral Gables, FL 33124 USA.
EM shyu@miami.edu; chens@cs.fiu.edu; mchen005@cs.fiu.edu;
   zhang@cis.uab.edu; ksarin@miami.edu
CR Aksoy S, 2000, INT C PATT RECOG, P812, DOI 10.1109/ICPR.2000.903041
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chen SC, 2000, P SOC PHOTO-OPT INS, V3972, P262
   Chen Shu-Ching., 2003, P 11 ACM INT C MULTI, P446
   Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   FAUQUEUR J, 2002, VISUAL INFORMATION I, P24
   Guttman A., 1984, ACM SIGMOD INT C MAN, P47, DOI DOI 10.1145/602259.602266
   HUANG X, 2003, P IEEE INT C MULT EX, V1, P321
   Jing F., 2002, PROC ACM INTERCONF M, P456
   Jobson J.D., 1992, APPL MULTIVARIATE DA, VII
   Johnson R.A., 1999, Applied multivariate statistical analysis, V4th
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kakade Sham, 2002, P 19 INT C MACH LEAR
   Lin HC, 1997, IEEE T IMAGE PROCESS, V6, P332, DOI 10.1109/83.551706
   LU Y, 2000, P ACM MULT, P31
   MA WY, 1999, HDB MULTIMEDIA COMPU, pCH13
   Natsev A, 2004, IEEE T KNOWL DATA EN, V16, P301, DOI 10.1109/TKDE.2003.1262183
   Ortega M, 1998, IEEE T KNOWL DATA EN, V10, P905, DOI 10.1109/69.738357
   Rabinowicz E., 1986, Tribology and Mechanics of Magnetic Storage Systems, V3, P1
   Rui Y., 1999, P 7 ACM INT C MULTIM, P67, DOI DOI 10.1145/319878.319896
   Shyu ML, 2004, IEEE T SYST MAN CY B, V34, P2035, DOI 10.1109/TSMCB.2004.833599
   Shyu ML, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P467, DOI 10.1109/ICME.2000.869640
   SHYU ML, 2001, P 7 INT C DISTR MULT, P494
   Su Z., 2001, ACM MULTIMEDIA, P98
   WIEDERHOLD G, 1992, COMPUTER, V25, P38, DOI 10.1109/2.121508
   Zhang DS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P425, DOI 10.1109/ICME.2002.1035809
NR 29
TC 1
Z9 1
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2007
VL 32
IS 1
BP 73
EP 92
DI 10.1007/s11042-006-0059-6
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 119YC
UT WOS:000243049400004
DA 2024-07-18
ER

PT J
AU Li, Q
   Ye, JP
   Kambhamettu, C
AF Li, Qi
   Ye, Jieping
   Kambhamettu, Chandra
TI Spatial interest pixels (SIPs): useful low-level features of visual
   media data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE dimension reduction; low-level features; spatial interest pixels; facial
   expression recognition; face recognition
ID RECOGNITION
AB Visual media data such as an image is the raw data representation for many important applications. Reducing the dimensionality of raw visual media data is desirable since high dimensionality degrades not only the effectiveness but also the efficiency of visual recognition algorithms. We present a comparative study on spatial interest pixels (SIPs), including eight-way (a novel SIP detector), Harris, and Lucas-Kanade, whose extraction is considered as an important step in reducing the dimensionality of visual media data. With extensive case studies, we have shown the usefulness of SIPs as low-level features of visual media data. A class-preserving dimension reduction algorithm (using GSVD) is applied to further reduce the dimension of feature vectors based on SIPs. The experiments showed its superiority over PCA.
C1 Western Kentucky Univ, Dept Comp Sci, Bowling Green, KY 42101 USA.
   Arizona State Univ, Tempe, AZ 85281 USA.
   Univ Delaware, Video Image Modeling & Synth Lab Comp Informat &, Newark, DE 19716 USA.
C3 Western Kentucky University; Arizona State University; Arizona State
   University-Tempe; University of Delaware
RP Li, Q (corresponding author), Western Kentucky Univ, Dept Comp Sci, Bowling Green, KY 42101 USA.
EM qi.li@wku.edu; jieping.ye@asu.edu; chandra@cis.udel.edu
CR [Anonymous], 1976, PICTURES FACIAL AFFE
   ARYA S, 1995, THESIS U MARYLAND CO
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   GEVERS T, 1998, ICCV, P576
   Hancock PJB, 1996, MEM COGNITION, V24, P26, DOI 10.3758/BF03197270
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Howland P, 2003, SIAM J MATRIX ANAL A, V25, P165, DOI 10.1137/S0895479801393666
   Huber P., 1981, Robust Statistics
   Jolliffe I.T., 1986, J EDUC PSYCHOL, V24, P417
   JOYCE DW, 2000, P SOC PHOTO-OPT INS, V3972, P132
   Landy M., 1991, COMPUTATIONAL MODELS, P253
   LIN WH, 2002, ACM MULTIMEDIA, P323
   LOUPIAS E, 1999, 9911 RR INSA LYON LA
   Lu Y, 2000, ACM MULTIMEDIA, P31
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Martinez A., 1998, AR FACE DATABASE
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   SIM T, P 4 INT C FG 00, P214
   Smith J., 1997, THESIS COLUMBIA U NE
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VANLOAN CF, 1976, SIAM J NUMER ANAL, V13, P76, DOI 10.1137/0713009
   YE J, 2003, TR02603 U MINN DEP C
   Ye JP, 2003, THIRD IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P419
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
   ZHAO WY, 2000, CARTR948
NR 30
TC 1
Z9 1
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2006
VL 30
IS 1
BP 89
EP 108
DI 10.1007/s11042-006-0009-3
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 082CF
UT WOS:000240363400004
DA 2024-07-18
ER

PT J
AU Wang, DH
   Huang, XD
   Kim, YS
   Lim, JS
   Han, MM
   Lee, BW
AF Wang, Dianhui
   Huang, Xiaodi
   Kim, Yong-Soo
   Lim, Joon Shik
   Han, Myung-Mook
   Lee, Byung-Wook
TI A structure-based approach for multimedia information filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT International Workshop on Multimedia and Web Design
CY DEC   13, 2004
CL Miami, FL
DE multimedia documents; display algorithms; search and retrieval;
   information filtering
ID SYSTEMS
AB While multimedia documents are sequentially presented to users, an information filtering (IF) system is useful to achieve a good retrieval performance in terms of both quality and efficiency. Conventional approaches for designing an IF system are based on the user's evaluation on information relevance degree (IRD), but ignore other attributes in system design such as relative importance of the data in a collection of multimedia documents. In this paper, we aim at developing a framework of designing structure-based multimedia IF systems, which incorporates the characteristics of the importance and relevance of multimedia documents. A method of calculating the values of relative importance degree of multimedia documents is proposed, Furthermore, these values are combined into the IRD of multimedia documents to improve the representation of user profiles. An illustrative example is given to demonstrate the proposed techniques.
C1 La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic 3086, Australia.
   Univ New England, Sch Math Stat & Comp Sci, Armidale, NSW 2351, Australia.
   Kyungwon Univ, Software Coll, Songnam 405760, Gyeonggi Do, South Korea.
C3 La Trobe University; University of New England; Gachon University
RP Wang, DH (corresponding author), La Trobe Univ, Dept Comp Sci & Comp Engn, Melbourne, Vic 3086, Australia.
EM dh.wang@latrobe.edu.au
RI Huang, Xiaodi/ABE-6432-2020; Wang, Dianhui/R-6289-2019; Huang,
   Xiaodi/E-9204-2012
OI Wang, Dianhui/0000-0002-5356-7268; Huang, Xiaodi/0000-0002-6084-1851
CR [Anonymous], RELEVANCE FEEDBACK I
   BELKIN NJ, 1992, COMMUN ACM, V35, P29, DOI 10.1145/138859.138861
   FREEMAN LC, 1979, SOC NETWORKS, V1, P215, DOI 10.1016/0378-8733(78)90021-7
   Hanani U, 2001, USER MODEL USER-ADAP, V11, P203, DOI 10.1023/A:1011196000674
   Kleinberg J, 1998, P ACM SIAM S DISCR A
   LINDA S, 1994, ANN REV INFORMATION, V29, P3
   Lopez Jose., 2000, SOCIAL STRUCTURE
   MALONE TW, 1987, ACM T INFORM SYST, V5, P115, DOI 10.1145/27636.27637
   MALONE TW, 1987, COMMUN ACM, V30, P390, DOI 10.1145/22899.22903
   Mostafa J, 1997, ACM T INFORM SYST, V15, P368, DOI 10.1145/263479.263481
   OARD WD, 1997, USER MODEL USER-ADAP, V7, P141
   ROBERTSON SF, 1977, J DOC, P294
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
NR 13
TC 1
Z9 1
U1 0
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD APR
PY 2006
VL 29
IS 1
BP 73
EP 89
DI 10.1007/s11042-006-7814-6
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 061AH
UT WOS:000238843100005
DA 2024-07-18
ER

PT J
AU Lee, SY
   Won, Y
   Kim, WY
AF Lee, SY
   Won, Y
   Kim, WY
TI Zikimi: A case study in micro kernel design for multimedia applications
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE micro-kernel; multimedia; operating system; Linux
ID SET-TOP-BOX; DISPLAY
AB Due to recent rapid deployment of Internet Appliances and PostPC products, the importance of developing lightweight embedded operating system is being emphasized more. In this article, we like to present the details of design and implementation experience of low cost embedded system, Zikimi, for multimedia data processing. We use the skeleton of existing Linux operating system and develop a micro-kernel to perform a number of specific tasks efficiently and effectively. Internet Appliances and PostPC products usually have very limited amount of hardware resources to execute very specific tasks. We carefully analyze the system requirement of multimedia processing device. We remove the unnecessary features, e.g. virtual memory, multitasking, a number of different file systems, and etc. The salient features of Zikimi micro kernel are (i) linear memory system and (ii) user level control of I/O device. The result of performance experiment shows that LMS (linear memory system) of Zikimi micro kernel achieves significant performance improvement on memory allocation against legacy virtual memory management system of Linux. By exploiting the computational capability of graphics processor and its local memory, we achieve 2.5 times increase in video processing speed.
C1 Samyook Univ, Fac Informat Management Syst, Dept Management Informat Syst, Seoul, South Korea.
   Hanyang Univ, Sch Elect & Comp Engn, Seoul 133791, South Korea.
C3 Sahmyook University; Hanyang University
RP Lee, SY (corresponding author), Samyook Univ, Div Elect & Comp Engn, Seoul, South Korea.
EM zikimi@syu.ac.kr; yjwon@ece.hanyang.ac.kr; wykim@hanyang.ac.kr
CR BAHADUR S, 1998, P 36 ANN C, P241
   Bershad B. N., 1994, ACM SIGOPS EUR WORKS, P68
   Fandrianto J, 1996, DIGEST OF PAPERS: COMPCON SPRING 96, FORTY-FIRST IEEE COMPUTER SOCIETY INTERNATIONAL CONFERENCE - INTELLECTUAL LEVERAGE, P469, DOI 10.1109/CMPCON.1996.501813
   Gogniat G, 2000, ACM T DES AUTOMAT EL, V5, P492, DOI 10.1145/348019.348156
   Hand SM, 1999, USENIX ASSOCIATION PROCEEDINGS OF THE THIRD SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '99), P73
   HILDEBRAND D, 1992, 1 USENIX WORKSH MICR, P113
   HURLEY TR, 1996, INT BROADCASTING CON, V428, P277
   Jaspers EGT, 1999, IEEE T CONSUM ELECTR, V45, P706, DOI 10.1109/30.793577
   Kohiyama K, 1996, IEEE T CONSUM ELECTR, V42, P667, DOI 10.1109/30.536170
   Li RX, 1997, IEEE T CONSUM ELECTR, V43, P496, DOI 10.1109/30.628664
   Pekowsky S, 1998, IEEE T CONSUM ELECTR, V44, P833, DOI 10.1109/30.713202
NR 11
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD DEC
PY 2005
VL 27
IS 3
BP 351
EP 366
DI 10.1007/s11042-005-3813-2
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 988CF
UT WOS:000233568300003
DA 2024-07-18
ER

PT J
AU Adams, B
   Venketesh, S
   Bui, HH
   Dorai, C
AF Adams, B
   Venketesh, S
   Bui, HH
   Dorai, C
TI A probabilistic framework for extracting narrative Act boundaries and
   semantics in motion pictures
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE narrative structure; semantics; multimedia content management; film
AB This work constitutes the first attempt to extract the important narrative structure, the 3-Act storytelling paradigm in film. Widely prevalent in the domain of film, it forms the foundation and framework in which a film can be made to function as an effective tool for story telling, and its extraction is a vital step in automatic content management for film data. The identification of act boundaries allows for structuralizing film at a level far higher than existing segmentation frameworks, which include shot detection and scene identification, and provides a basis for inferences about the semantic content of dramatic events in film. A novel act boundary likelihood function for Act 1 and 2 is derived using a Bayesian formulation under guidance from film grammar, tested under many configurations and the results are reported for experiments involving 25 full-length movies. The result proves to be a useful tool in both the automatic and semi-interactive setting for semantic analysis of film, with potential application to analogues occuring in many other domains, including news, training video, sitcoms.
C1 Curtin Univ Technol, Dept Comp Sci, Perth, WA 6845, Australia.
   IBM Corp, Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   Curtin Univ, Dept Comp Sci, Curtin, WA, Australia.
C3 Curtin University; International Business Machines (IBM); Curtin
   University
RP Curtin Univ Technol, Dept Comp Sci, GPO Box U1987, Perth, WA 6845, Australia.
EM adamsb@cs.curtin.edu.au; svetha@cs.curtin.edu.au; bui@ai.sri.com;
   dorai@watson.ibm.com
OI Venkatesh, Svetha/0000-0001-8675-6631
CR Adams B, 2002, INT S VIDEO COMP, V4, P57
   Adams B, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P641, DOI 10.1109/ICME.2000.871444
   [Anonymous], 1976, Grammar of the film language
   [Anonymous], 1972, An Introduction to Bayesian Inference and Decision
   Aronson Linda., 2000, Scriptwriting Updated: New and Conventional Ways of Writing for the screen: Allen
   DORAI C, 2001, IEEE MULTIMEDIA, V8, P10
   DORAI C, 2002, MEDIA COMPUTING COMP
   Field Syd., 1994, Screenplay: The Foundations of Screenwriting
   GOLDMAN W, 2000, ADVENTURES SCREEN TR
   *IBM, 2002, MAD ORD IBM MAK SENS
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Keane Christopher., 1998, How to Write a Selling Screenplay: A Step-by-Step Approach to Developing Your Story and Writing Your Screenplay by One of Today's Most Successful Screenwriters and Teachers
   LI Y, 2001, IEEE INT C MULT EXP, P804
   LIENHART R, 1999, EEE MULTIMEDIA COMPU
   McKee R., 1997, STORY SUBSTANCE STRU
   Mehring M., 1990, The screenplay: A blend of film form and content
   Monaco James., 1981, READ FILM ART TECHNO
   SKOV M, COSIGN 2001
   Sobchack T., 1987, INTRO FILM, V2nd
   Thompson Kristin, 1999, Storytelling in the New Hollywood: Understanding Classical Narrative Technique
   Vogler C., 1999, The Writer's Journey: Mythic Structure/or Storytellers and Screenwriters, V2nd
NR 21
TC 4
Z9 4
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2005
VL 27
IS 2
BP 195
EP 213
DI 10.1007/s11042-005-2574-2
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 961OP
UT WOS:000231672000002
DA 2024-07-18
ER

PT J
AU Fayzullin, M
   Subrahmanian, VS
   Picariello, A
   Sapino, M
AF Fayzullin, M
   Subrahmanian, VS
   Picariello, A
   Sapino, M
TI The CPR model for summarizing video
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Proceedings Paper
CT 1st ACM International Workshop on Multimedia Databases
CY NOV 07, 2003
CL New Orleans, LA
SP ACM
DE multimedia; video; databases; summarization; framework; algorithms
AB Most past work on video summarization has been based on selecting key frames from videos. We propose a model of video summarization based on three important parameters: Priority (of frames), Continuity (of the summary), and non-Repetition (of the summary). In short, a summary must include high priority frames and must be continuous and non-repetitive. An optimal summary is one that maximizes an objective function based on these three parameters. We show examples of how CPR parameters can be computed and provide algorithms to find optimal summaries based on the CPR approach. Finally, we briefly report on the performance of these algorithms.
C1 Univ Maryland, Dept Comp Sci, College Pk, MD 20742 USA.
   Univ Naples Federico II, Dipartimento Informat & Sistemist, I-80125 Naples, Italy.
   Univ Turin, Dipartimento Informat, I-10149 Turin, Italy.
C3 University System of Maryland; University of Maryland College Park;
   University of Naples Federico II; University of Turin
RP Univ Maryland, Dept Comp Sci, AV Williams Bldg, College Pk, MD 20742 USA.
RI Subrahmanian, Venkatramanan/ABA-7399-2021; Picariello,
   Antonio/G-9062-2012; Sapino, Maria Luisa/C-6257-2011; PICARIELLO,
   Antonio/L-6820-2015
OI PICARIELLO, Antonio/0000-0003-4804-1007
CR Adali S, 1996, MULTIMEDIA SYST, V4, P172, DOI 10.1007/s005300050021
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   DeMenthon D., 1998, Proceedings ACM Multimedia 98, P211, DOI 10.1145/290747.290773
   He LW, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P489, DOI 10.1145/319463.319691
   Ju SX, 1998, IEEE T CIRC SYST VID, V8, P686, DOI 10.1109/76.718513
   MA YP, 2002, P ACM MULT
   MARTIN H, 2000, NETWORKING INFORMATI, V3, P53
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   OOMOTO E, 1993, IEEE T KNOWL DATA EN, V5, P629, DOI 10.1109/69.234775
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Subrahmanian V.S., 1998, Principles of multimedia database systems
   ZHONG D, 1997, IEEE INT C CIRC SYST
   Zhou W., 2000, ACM Workshops on Multimedia, P213
NR 13
TC 13
Z9 15
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2005
VL 26
IS 2
BP 153
EP 173
DI 10.1007/s11042-005-0451-7
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering
GA 931TJ
UT WOS:000229508100002
DA 2024-07-18
ER

PT J
AU Roccetti, M
   Salomoni, P
   Ghini, V
   Ferretti, S
AF Roccetti, M
   Salomoni, P
   Ghini, V
   Ferretti, S
TI Bringing the wireless Internet to UMTS devices: A case study with music
   distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE digital media; music on demand; wireless multimedia applications; CDN;
   UMTS
ID MOBILE; PERFORMANCE
AB Wireless networking is becoming an increasingly important communication means. Entry points to content delivery networks (e.g. portals) have to cope with the primary necessity of distributing multimedia contents to 3G mobile devices. In this paper we discuss the software architecture of a wireless Internet application we have designed and implemented to support the distribution of Mp3-based songs to 3G UNITS devices. Alongside the operational description of the proposed architecture, efforts have been made to examine the effects that Internet traffic has on the performance of UNITS networks, due to the distribution of Mp3 files by means of our wireless application. The download time measurements we have experimentally obtained show that combining modem 3G mobile network technologies with an appropriate structuring of the wireless Internet application may be very effective for the fast distribution of pre-recorded music to mobile clients.
C1 Univ Bologna, Dept Comp Sci, I-40127 Bologna, Italy.
C3 University of Bologna
RP Univ Bologna, Dept Comp Sci, Mura A Zamboni 7, I-40127 Bologna, Italy.
EM roccetti@cs.unibo.it; salomoni@cs.unibo.it; ghini@cs.unibo.it;
   sferrett@cs.unibo.it
OI Ferretti, Stefano/0000-0002-1911-4708; ROCCETTI,
   MARCO/0000-0003-1264-8595
CR BAKRE A, 1995, P INT C DISTR COMP S
   BALAKRISHNAN H, 1995, P MOB 95 BERK CAL US
   BARBIR A, 2001, KNOWN CDN REQUEST RO
   BHAGWAT P, 1997, WIRELESS NETWORKS, V3
   CACERES R, 1995, IEEE J SEL AREA COMM, V13, P850, DOI 10.1109/49.391749
   CONTI M, 2001, CLUSTER COMPUT, V4, P105
   DAY M, 2001, CDN PEERING SCENARIO
   DAY M, 2001, MODEL CONTENT INTERN
   ECKHARDT D, 1998, P 6 IEEE INT C NETW
   Elaarag H, 2002, ACM COMPUT SURV, V34, P357, DOI 10.1145/568522.568524
   FIEGER A, 1997, P 2 GLOB INT C PHOEN
   FOROUZAN A, 2000, TCP IP PROTOCOL SUIT
   *FREEN PROJ INC, FREEN PROJ
   GHINI V, 2001, P 34 INT C SYST SCI
   Goff T., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P1537, DOI 10.1109/INFCOM.2000.832552
   Gong L, 2001, IEEE INTERNET COMPUT, V5, P88, DOI 10.1109/4236.935182
   GREEN M, CONTENT INTERNETWORK
   HAAS ZJ, 1997, P IEEE ICC 97, P1054
   Huston G, 2001, IEEE INTERNET COMPUT, V5, P82, DOI 10.1109/4236.914651
   Ingham DB, 2000, IEEE INTERNET COMPUT, V4, P25, DOI 10.1109/4236.815846
   JOHNSON K, 2000, P 5 INT WEB CACH CON
   Kalden R, 2000, IEEE PERS COMMUN, V7, P8, DOI 10.1109/98.839328
   Kanter T, 2001, IEEE PERS COMMUN, V8, P8, DOI 10.1109/98.972161
   Krishnamurthy B, 2001, P ACM SIGCOMM INT ME
   Lawton G, 2001, COMPUTER, V34, P18, DOI 10.1109/2.970548
   PARSA, 2000, ACM MOBILE NETWORKS, V5, P57
   ROCCETTI M, 2002, P ACM S APPL COMP MA, P1066
   ROCCETTI M, 2002, P 2002 SCS EUR C MOD, P147
   RODRIGUEZ P, 2002, IEEE ACM T NETW AUG
   Saha S, 2001, COMPUTER, V34, P54, DOI 10.1109/2.928622
   Samaraweera N. K. G., 1998, Computer Communication Review, V28, P30, DOI 10.1145/279345.279348
   Staehle D., 2001, P 4 ACM INT WORKSHOP, P57
   STEVENS WR, 1998, TCP IP ILLUSTRATED, V1
   Wang KY, 1998, IEEE INFOCOM SER, P1046, DOI 10.1109/INFCOM.1998.662914
   YAVATKAR R, 1994, P INT WORKSH MOB COM
   [No title captured]
NR 36
TC 4
Z9 4
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2005
VL 25
IS 2
BP 217
EP 251
DI 10.1007/s11042-005-5606-z
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 897BM
UT WOS:000226979000003
DA 2024-07-18
ER

PT J
AU Moussa, KH
   El Den, AMM
   Mohamed, IA
   Abdelrassoul, RA
AF Moussa, Karim H.
   El Den, Ahmed M. Mohy
   Mohamed, Islam Abd Ellattif
   Abdelrassoul, Roshdy A.
TI Various pseudo random number generators based on memristive chaos map
   model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE IOT; PRNG; Memristive; 2D-MSM; 2D-MLM; NIST; DIEHARD
AB The telecommunications industry has made huge strides, and multimedia information transmission is exploding. Text, sound, and video can all be used to create multimedia data. As a result, having systems in place to protect private or sensitive data and keep its security is critical. In this article, completely random numbers were generated in two different ways, and the extent of their randomness was tested in many ways to ensure their suitability for use in different cryptographic applications. The proposed models in this article depend on a chaos based Pseudo-random number generators (PRNGs). PRNGs, which create bit sequences, have evolved into a critical component in many industries, including encrypted communication, Wireless communication using a spread spectrum, computational simulations, RF identification networks, and coding for error correction. The PRNGs is designed by combining the memristor that is discrete with the logistic map and the memristor that is discrete with sine map both separately to construct the novel algorithms called a two-dimensional memristive logistic map (2D-MLM) and two dimensional memristive sine map (2D-MSM) and each cycle yields a sequence of 32 random bits. The binary64 dual precision format is employed for arithmetic using floating-point in accordance with the IEEE 754-2008 standard. To assess the generator's performance, several statistical analyses are utilized. The results of the tests that evaluated the presented algorithms showed that the space key was improved and increased by 3.2% compared to other generators, and the performance speed was increased by 12.22%. The findings reveal that the sequences that are created have an elevated degree of unpredictability and a high level of security, which renders them excellent for cryptographic use in terms of the speed, the large key space, and high data rate.
C1 [Moussa, Karim H.] Xian Jiaotong Liverpool Univ, Sch Internet Things, Suzhou 215123, Peoples R China.
   [El Den, Ahmed M. Mohy; Mohamed, Islam Abd Ellattif; Abdelrassoul, Roshdy A.] Arab Acad Sci Technol & Maritime Transport AASTMT, Elect & Commun Engn Dept, Alexandria, Egypt.
C3 Xi'an Jiaotong-Liverpool University; Egyptian Knowledge Bank (EKB); Arab
   Academy for Science, Technology & Maritime Transport
RP Moussa, KH (corresponding author), Xian Jiaotong Liverpool Univ, Sch Internet Things, Suzhou 215123, Peoples R China.; El Den, AMM (corresponding author), Arab Acad Sci Technol & Maritime Transport AASTMT, Elect & Commun Engn Dept, Alexandria, Egypt.
EM karim.moussa@xjtlu.edu.cn; Ahmed.Elden@student.aast.edu
RI Moussa, Karim H./D-3562-2019
CR Alhadawi HS, 2019, CRYPTOLOGIA, V43, P190, DOI 10.1080/01611194.2018.1548390
   Aljohani M, 2019, IEEE ACCESS, V7, P39794, DOI 10.1109/ACCESS.2019.2907079
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Bao BC, 2020, ELECTRON LETT, V56, P769, DOI 10.1049/el.2020.1172
   Bao H, 2020, SCI CHINA TECHNOL SC, V63, P603, DOI 10.1007/s11431-019-1450-6
   Biham E., 2012, DIFFERENTIAL CRYPTAN
   Chua L., 2019, Handbook of Memristor Networks, P197, DOI [DOI 10.1007/S00339-011-6264-9, 10.1007/978-3-319-76375-0]
   Chua L, 2014, SEMICOND SCI TECH, V29, DOI 10.1088/0268-1242/29/10/104001
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Demir K, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20120957
   François M, 2014, INFORM-J COMPUT INFO, V38, P115
   Francois M, 2013, INFORMATICA-LITHUAN, V24, P181
   Guyeux C, 2015, J SUPERCOMPUT, V71, P3877, DOI 10.1007/s11227-015-1479-8
   Hamdi M., 2015, Int J Comput Electr Autom Control Inf Eng, V9, P481
   Huang X, 2019, MATH PROBL ENG, V2019, DOI 10.1155/2019/7685359
   Krishnamoorthi S, 2021, NONLINEAR DYNAM, V104, P1627, DOI 10.1007/s11071-021-06346-x
   Krishnamoorthi S, 2021, SADHANA-ACAD P ENG S, V46, DOI 10.1007/s12046-020-01537-5
   L'Ecuyer P, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1268776.1268777
   Li HZ, 2021, IEEE T IND ELECTRON, V68, P9931, DOI 10.1109/TIE.2020.3022539
   Liu MQ, 2013, IEEE T NEUR NET LEAR, V24, P1114, DOI 10.1109/TNNLS.2013.2251000
   Murillo-Escobar MA, 2017, NONLINEAR DYNAM, V87, P407, DOI 10.1007/s11071-016-3051-3
   Nesa N, 2019, J INF SECUR APPL, V47, P320, DOI 10.1016/j.jisa.2019.05.017
   Rukhin Andrew L., 2001, A statistical test suite for random and pseudorandom number generators for cryptographic applications, V22
   Singamaneni KK, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22186741
   Vajargah BF, 2015, Sci Int (Lahore), P27
   Wang LY, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21100960
   WOLF A, 1985, PHYSICA D, V16, P285, DOI 10.1016/0167-2789(85)90011-9
   Zuras D., 2008, 7542008 IEEE, V754-2008, P1, DOI [DOI 10.1109/IEEESTD.2008.4610935, DOI 10.1109/IEEESTD.2008.5976968]
NR 28
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 29
PY 2023
DI 10.1007/s11042-023-17863-9
EA DEC 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL1O1
UT WOS:001132108500003
DA 2024-07-18
ER

PT J
AU Saad, MH
   Salman, AE
AF Saad, Mohamed H.
   Salman, Ahmed E.
TI A plant disease classification using one-shot learning technique with
   field images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Plant Disease Classification; SVM; Siamese; One-Shot Learning;
   Fine-Tuning; Deep Learning
AB Early diagnosis of plant diseases is crucial for preventing plagues and mitigating their effects on crops. The most precise automatic methods for identifying plant diseases using images of plant fields are powered by deep learning. Big image datasets should always be gathered and annotated for these methods to work, which is often not technically or financially feasible. This paper offers one-shot learning (OSL) techniques for plant disease classification with limited datasets utilizing Siamese Neural Network (SNN). There are five different crop kinds in the dataset: grape, wheat, cotton, cucumber, and corn. Five sets of images showing both healthy and diseased crops are used to represent each of the new crops. The dataset's includes 25 classes with 875 leaf images. Data augmentation techniques are used to enhance the size and dimension of the plant leaf disease image dataset. To provide effective segmentation, this paper provides a unique method for region-based image segmentation that divides an image into its most prominent regions. It also addresses issues with earlier region-based segmentation methods. SVM-based classifiers have better generalization properties as their efficiency does not depend on the number of features. Such merit is beneficial in primary diagnostics decisions to check if the input image is included in the database or not to reduce the consumed time. OSL was applied and compared to standard fine-tuning transfer learning utilizing Siamese networks and triplet loss. Siamese provides superior classification accuracy and localization accuracy with minimal errors than other approaches. The proposed approach has a total processing time of 5 ms, which makes it appropriate for real-time applications. In terms of specificity, sensitivity, precision, accuracy, MCC, and F-measure, the proposed approach beats all current machine learning algorithms for small training sets.
C1 [Saad, Mohamed H.; Salman, Ahmed E.] Egyptian Atom Energy Author, Natl Ctr Radiat Res & Technol NCRRT, Radiat Biol Dept, Cairo, Egypt.
C3 Egyptian Knowledge Bank (EKB); Egyptian Atomic Energy Authority (EAEA);
   National Center for Radiation Research & Technology
RP Saad, MH (corresponding author), Egyptian Atom Energy Author, Natl Ctr Radiat Res & Technol NCRRT, Radiat Biol Dept, Cairo, Egypt.
EM m.hassansaad@gmail.com
OI Salman, Ahmed Eslam/0000-0002-5979-8526
FU Egyptian Atomic Energy Authority
FX No Statement Available
CR Abbass MY, 2022, J ELECTR ENG TECHNOL, V17, P2971, DOI 10.1007/s42835-022-01010-9
   Abbass MY, 2021, ARTIF INTELL REV, V54, P3349, DOI 10.1007/s10462-020-09905-7
   Abbass MY, 2021, MULTIMED TOOLS APPL, V80, P5403, DOI 10.1007/s11042-020-09824-3
   Abbass MY, 2021, VISUAL COMPUT, V37, P993, DOI 10.1007/s00371-020-01848-y
   Al-Hiary H., 2011, International Journal of Computer Applications, V17, P31, DOI [10.5120/2183-2754, DOI 10.5120/2183-2754]
   Argüeso D, 2020, COMPUT ELECTRON AGR, V175, DOI 10.1016/j.compag.2020.105542
   Bertinetto L, 2019, Arxiv, DOI arXiv:1805.08136
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Camacho A, 2018, PROC SPIE, V10783, DOI 10.1117/12.2502125
   Chen JD, 2020, COMPUT ELECTRON AGR, V173, DOI 10.1016/j.compag.2020.105393
   Chen WY, 2020, Arxiv, DOI arXiv:1904.04232
   Chug A, 2023, SOFT COMPUT, V27, P13613, DOI 10.1007/s00500-022-07177-7
   Cuan BN, 2018, IEEE INT WORKSH MULT
   Dombi J, 2022, INT J APPROX REASON, V143, P121, DOI 10.1016/j.ijar.2022.01.006
   Ferentinos KP, 2018, COMPUT ELECTRON AGR, V145, P311, DOI 10.1016/j.compag.2018.01.009
   Geetharamani G, 2019, COMPUT ELECTR ENG, V76, P323, DOI 10.1016/j.compeleceng.2019.04.011
   Ghassemi N, 2020, BIOMED SIGNAL PROCES, V57, DOI 10.1016/j.bspc.2019.101678
   Goncharov P, 2019, ADV NEURAL COMPUTATI, P151
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   Hu GS, 2019, COMPUT ELECTRON AGR, V163, DOI 10.1016/j.compag.2019.104852
   Hudec L, 2018, INT CONF SYST SIGNAL, DOI 10.1109/IWSSIP.2018.8439387
   Jahan I, 2023, ICT EXPRESS, V9, P320, DOI 10.1016/j.icte.2021.12.012
   Johannes A, 2017, COMPUT ELECTRON AGR, V138, P200, DOI 10.1016/j.compag.2017.04.013
   Kavindi Gunasinghe U. L. D., 2022, Advances in Information and Communication: Proceedings of the 2022 Future of Information and Communication Conference (FICC). Lecture Notes in Networks and Systems (439), P273, DOI 10.1007/978-3-030-98015-3_19
   Kim J, 2019, PROC CVPR IEEE, P11, DOI 10.1109/CVPR.2019.00010
   Koch G., 2015, P INT C MACH LEARN W, V2, P1
   Larochelle H, 2020, Few-shot learning. Computer vision: a reference guide
   Lu JZ, 2021, AGRICULTURE-BASEL, V11, DOI 10.3390/agriculture11080707
   Martinelli F, 2015, AGRON SUSTAIN DEV, V35, P1, DOI 10.1007/s13593-014-0246-1
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Novotny P, 2013, BIOSYST ENG, V115, P444, DOI 10.1016/j.biosystemseng.2013.04.007
   Palaiahnakote S, 2020, Revised Selected Papers, V12046
   Perez H, 2021, STRUCT CONTROL HLTH, V28, DOI 10.1002/stc.2751
   Picon A, 2019, COMPUT ELECTRON AGR, V161, P280, DOI 10.1016/j.compag.2018.04.002
   Prasvita D.S., 2013, Int J Adv Sci Eng Inf Technol, V3, P103, DOI [10.18517/ijaseit.3.2.287, DOI 10.18517/IJASEIT.3.2.287]
   Rumpf T, 2010, COMPUT ELECTRON AGR, V74, P91, DOI 10.1016/j.compag.2010.06.009
   Sannakki SS, 2011, INT J COMP TECH APPL, V2, P1709
   Sinha BB, 2022, FUTURE GENER COMP SY, V126, P169, DOI 10.1016/j.future.2021.08.006
   Sladojevic S, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3289801
   Snell J, 2017, ADV NEUR IN, V30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Uzhinskiy A., 2019, P CEUR WORKSH P BUDV, P110
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vi Nguyen Thanh Le, 2019, Information Processing in Agriculture, V6, P116, DOI 10.1016/j.inpa.2018.08.002
   Wang G, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/2917536
   Wang MY, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020205
   Zhang WC, 2021, VISUAL COMPUT, V37, P881, DOI 10.1007/s00371-020-01839-z
NR 47
TC 2
Z9 2
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 28
PY 2023
DI 10.1007/s11042-023-17830-4
EA DEC 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DL0A9
UT WOS:001132069200009
OA hybrid
DA 2024-07-18
ER

PT J
AU Sharma, M
   Singh, H
   Gupta, AK
   Khosla, D
AF Sharma, Manvinder
   Singh, Harjinder
   Gupta, Anuj Kumar
   Khosla, Dishant
TI Target identification and control model of autopilot for passive homing
   missiles
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Autopilot guidance; Imaging; Object detection; Missile guidance; Passive
   homing; Tracking; Hit target
ID GUIDANCE
AB With the advancement of technology in both combat and defensive situations, the requirement of the use of autonomous vehicles which carry payload is increasing. For the different types of targets, missiles are used. The missile guidance system calculates the miss distance and the trajectory dynamics through automated system. Using image processing, multiple types of target can be identifies. The use of image processing in the guiding system to differentiate between the objects may provide the contemporary error correction in the flight path. In this paper, multiple approaches are used for target identification, tracking and control of trajectory dynamics. The approach identifies two targets, a massive missile truck and an airplane. The algorithm successfully identifies target despite colour variances and almost equivalent structural arrangements. Further trajectory estimation of target is done through constant velocity and constant turn models. When utilising motion estimates and detection, real-world success depends on the ability to recognise visual targets. The Type 1 system's main objective is flight path management using the yaw, pitch, and roll axes. A common atmospheric model and a set of equations are used by the missile autopilot system to describe the aircraft. In MATLAB Simulink, a simulated missile attack travelling at 328 m/s is modelled and simulated. In the model, the missile and its intended target came together at 3.5 s.
C1 [Sharma, Manvinder] Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
   [Singh, Harjinder] Punjabi Univ, Patiala, Punjab, India.
   [Gupta, Anuj Kumar; Khosla, Dishant] Chandigarh Grp Coll, Landran, India.
C3 Chitkara University, Punjab; Punjabi University
RP Sharma, M (corresponding author), Chitkara Univ, Chitkara Univ Inst Engn & Technol, Rajpura, Punjab, India.
EM manvinder.sharma@gmail.com; hrjindr@gmail.com; anuj.coecse@cgc.edu.in;
   dishant.coeece@cgc.edu.in
CR Aulinas J, 2008, FRONT ARTIF INTEL AP, V184, P363, DOI 10.3233/978-1-58603-925-7-363
   Barrera Alejandro, 2020, 2020 IEEE 23rd International Conference on Intelligent Transportation Systems (ITSC), DOI 10.1109/ITSC45102.2020.9294293
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BEZICK S, 1995, J GUID CONTROL DYNAM, V18, P441, DOI 10.2514/3.21407
   BHANU B, 1986, IEEE T AERO ELEC SYS, V22, P364, DOI 10.1109/TAES.1986.310772
   Braun RD, 2013, AIAA GUIDANCE NAVIGA, P5123
   Cherry G, 1964, ASTR GUID CONTR C, P638
   Deng ZL, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9010198
   Fedaravicius A, 2023, ELEKTRON ELEKTROTECH, V29, P27, DOI 10.5755/j02.eie.33634
   Ferrara M., 2019, 2019 INT C BIOMETRIC, P1
   Fowers SG, 2007, 2007 INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, P294
   Heidari M, 2023, IEEE WINT CONF APPL, P6191, DOI 10.1109/WACV56688.2023.00614
   Hussien Mostafa A., 2022, 2022 13th International Conference on Electrical Engineering (ICEENG)., P9, DOI 10.1109/ICEENG49683.2022.9782033
   Jindal A., 2018, Pattern Recognition and Image Analysis, V28, P288, DOI 10.1134/S1054661818020086
   Kamel Mohamed M., 2019, IOP Conference Series: Materials Science and Engineering, V610, DOI 10.1088/1757-899X/610/1/012033
   Ko T, 2010, PROC CVPR IEEE, P1331, DOI 10.1109/CVPR.2010.5539813
   Lee K.-Y., 2020, PROC IEEECVF C COMPU, P8198
   Li SY, 2019, IEEE ACCESS, V7, P50300, DOI 10.1109/ACCESS.2019.2910659
   Li YF, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3172223
   Liu HK, 2020, IEEE T GEOSCI REMOTE, V58, P8689, DOI 10.1109/TGRS.2020.2989825
   Mapanga K, 2012, PROCEDIA ENGINEER, V41, P395, DOI 10.1016/j.proeng.2012.07.190
   Masum Abdullah Al, 2023, IPMV '23: Proceedings of the 2023 5th International Conference on Image Processing and Machine Vision, P12, DOI 10.1145/3582177.3582180
   Miratabzadeh SA, 2016, WORLD AUTOMAT CONG
   Mujica F, 1997, P SOC PHOTO-OPT INS, V3024, P787, DOI 10.1117/12.263290
   Nayak SR, 2019, IMAGE VISION COMPUT, V89, P21, DOI 10.1016/j.imavis.2019.06.015
   Nikolic J, 2016, IEEE SENS J, V16, P5433, DOI 10.1109/JSEN.2016.2556662
   Oniga F, 2018, INT C INTELL COMP CO, P209, DOI 10.1109/ICCP.2018.8516642
   Oshino S, 2022, IECON 2022 48 ANN C, P1
   Pan TY, 2023, MECH SYST SIGNAL PR, V195, DOI 10.1016/j.ymssp.2023.110271
   Pandey D., 2022, AS, V5, P553, DOI [10.1007/s42401-022-00150-0, DOI 10.1007/S42401-022-00150-0]
   Park J, 2006, IEEE IMAGE PROC, P1849, DOI 10.1109/ICIP.2006.312840
   Peng XL, 2021, IEEE T GEOSCI REMOTE, V59, P7296, DOI 10.1109/TGRS.2020.3033009
   Raj KDS, 2015, 2015 INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND SIGNAL PROCESSING (ICCSP), P398, DOI 10.1109/ICCSP.2015.7322916
   Rathore PS, 2021, J SUPERCOMPUT, V77, P7649, DOI 10.1007/s11227-020-03593-4
   Sahingil MC, 2013, PROC SPIE, V8752, DOI 10.1117/12.2015723
   Sharma M, 2022, IETE J Res1-11
   Sharma M, 2023, MULTIMED TOOLS APPL, V82, P6849, DOI 10.1007/s11042-022-13578-5
   Sharma M, 2022, J ELECTRON MATER, V51, P2131, DOI 10.1007/s11664-022-09482-1
   Sharma M, 2020, LECT NOTES ELECTR EN, V597, P561, DOI 10.1007/978-3-030-29407-6_40
   Siouris GM., 2005, The American Society of Mechanical Engineers (ASME), V57, DOI DOI 10.1115/1.1849174
   Song TL, 1996, IEEE T AERO ELEC SYS, V32, P434, DOI 10.1109/7.481284
   Srinivas M., 2012, Int J Syst Algorithms Appl, V2, P17
   Stone M. L., 2000, Lincoln Laboratory Journal, V12, P217
   Wang CY, 2019, IEEE ACCESS, V7, P170032, DOI 10.1109/ACCESS.2019.2955308
   Wang Rui, 2011, 2011 6th International Conference on Computer Science & Education (ICCSE 2011), P830, DOI 10.1109/ICCSE.2011.6028766
   Zhou H, 2020, Arxiv, DOI arXiv:2008.01550
   Zhou JP, 2023, J SYST ENG ELECTRON, V34, P160, DOI 10.23919/JSEE.2022.000154
NR 47
TC 1
Z9 1
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 22
PY 2023
DI 10.1007/s11042-023-17804-6
EA DEC 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DB8U4
UT WOS:001129672000012
DA 2024-07-18
ER

PT J
AU Sagar, GV
   Kumar, MR
   Ahammad, SH
   Santhosh, C
AF Sagar, G. Vidya
   Kumar, M. Ravi
   Ahammad, Sk. Hasane
   Santhosh, Chella
TI Image classification of intracranial tumor using deep residual learning
   technique
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain tumor; Convolutional Neural Network; Intracranial tumor; Deep
   residual learning; Image processing; Image classification
ID AUGMENTED REALITY; STUDENTS; SYSTEM
AB Classifying brain tumours is essential for diagnosing tumour progression and planning effective treatments. Different imaging modalities are used to diagnose brain tumours. The opposite is true for magnetic resonance imaging (MRI), which has gained widespread use due to its superior image quality and the fact that it does not require ionizing radiation. Image classification of intracranial tumors using deep residual learning technique is an application of deep learning in the field of medical imaging analysis. It involves using convolutional neural networks (CNNs) to automatically classify brain images into different categories based on the presence or absence of tumors. ResNet is a deep neural network that addresses the problem of vanishing gradients during training of very deep networks.The deep learning subfield of machine learning has recently shown remarkable success, especially in classification and segmentation. We trained a deep residual network using picture datasets to distinguish between several brain cancers. The information generated by MRI scans is extensive. A radiologist analyses these images. The three most common brain tumours are meningioma, glioma, and pituitary tumour. Brain tumours are complex diseases, and a manual examination may be fraught with error. Experimental outcomes based on various techniques under augmentation with image-based datasets are presented. The accuracy with no augmentation is about 98% and under augmentation is approximately 99.08%.By leveraging deep residual learning techniques, image classification of intracranial tumors can benefit from the ability of deep neural networks to automatically learn complex representations from raw image data.Classification methods that use machine learning to automate the process have proven superior to human curation. Thus, we present a system that can identify and classify utilizing deep CNN-based residual networks.
C1 [Sagar, G. Vidya; Kumar, M. Ravi; Ahammad, Sk. Hasane; Santhosh, Chella] Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Vaddeswaram 522302, Andhra Pradesh, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Sagar, GV; Santhosh, C (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Elect & Commun Engn, Vaddeswaram 522302, Andhra Pradesh, India.
EM vidyagampala66@gmail.com; ravikumar@kluniversity.in;
   ahammadklu@gmail.com; csanthosh@kluniversity.in
RI , hasane/R-4445-2019
OI , hasane/0000-0002-2587-4164; Santhosh, Chella/0000-0002-5301-2000
CR [Anonymous], 2023, Vuforia Engine Developer Portal
   [Anonymous], 2023, Android Studio & APP Tools
   Blum T, 2012, IEEE VIRTUAL REALITY CONFERENCE 2012 PROCEEDINGS, P115, DOI 10.1109/VR.2012.6180909
   Bobek E, 2016, COGN RES, V1, DOI 10.1186/s41235-016-0031-6
   Brooke J., 1986, Digital equipment co ltd
   Campbell M.A., 2005, Australian Journal of Guidance and Counselling, V15, P68, DOI [10.1375/ajgc.15.1.68, DOI 10.1375/AJGC.15.1.68]
   Chang KE, 2014, COMPUT EDUC, V71, P185, DOI 10.1016/j.compedu.2013.09.022
   Chen Y.C., 2006, Proceedings of the 2006 ACM international conference on Virtual reality continuum and its applications, P369
   Ewais A, 2019, J EDUC COMPUT RES, V57, P1643, DOI 10.1177/0735633119855609
   Goyal S, 2016, PROCEEDINGS OF THE TENTH ANNIVERSARY CONFERENCE ON TANGIBLE EMBEDDED AND EMBODIED INTERACTION (TEI16), P441, DOI 10.1145/2839462.2856541
   Henderson PB, 2007, SIGCSE 2007: PROCEEDINGS OF THE THIRTY-EIGHTH SIGCSE TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P195, DOI 10.1145/1227504.1227378
   Horn MS, 2007, TEI 07, P159, DOI [10.1145/1226969.1227003, DOI 10.1145/1226969.1227003]
   Iwata T, 2011, IEEE INT CONF EMBED, P105, DOI 10.1109/RTCSA.2011.43
   Jablon J.R., 2006, YC: Young Children, V61, P12
   Johnson L., 2010, The 2010 Horizon Report
   Kawasumi Y, 2004, Global Survey On Rural Communications
   Kerawalla L., 2006, Virtual Real, V10, P163, DOI [10.1007/s10055-006-0036-4, DOI 10.1007/S10055-006-0036-4]
   KIRKPATRICK E.A., 1894, PSYCHOL REV, V1, P602, DOI [10.1037/h0068244, DOI 10.1037/H0068244]
   Lee Irene, 2011, ACM Inroads, V2, P32, DOI 10.1145/1929887.1929902
   Matsutomo S, 2012, IEEE T MAGN, V48, P531, DOI 10.1109/TMAG.2011.2174208
   McNerney T S., 2000, Tangible programming bricks: An approach to making programming accessible to everyone
   Papert S., 1980, MINDSTORMS CHILDREN
   Radu I., 2009, Proceedings of the 8th International Conference on Interaction Design and Children, P210, DOI DOI 10.1145/1551788.1551831
   Raina P, 2011, Meet Aakash, India's 35 Laptop
   Raykov T, 2019, EDUC PSYCHOL MEAS, V79, P200, DOI 10.1177/0013164417725127
   Rebollo C, 2022, MULTIMED TOOLS APPL, V81, P14851, DOI 10.1007/s11042-021-10821-3
   ROUSSOU M, 2004, COMPUT ENTERTAIN, V2, DOI [10.1145/973801.973818, DOI 10.1145/973801.973818]
   Ryan RM, 2000, AM PSYCHOL, V55, P68, DOI 10.1037/0003-066X.55.1.68
   Sauro Jeff., 2011, MeasuringU
   Shelton B.E., 2004, Tech., Inst., P323
   Shelton B.E., 2002, 1 IEEE INT WORKSHOP
   SOLOWAY E, 1993, COMMUN ACM, V36, P21, DOI 10.1145/163430.164061
   Suzuki H, 1995, PROCEEDINGS OF CSCL '95 - THE FIRST INTERNATIONAL CONFERENCE ON COMPUTER SUPPORT FOR COLLABORATIVE LEARNING, P349, DOI 10.3115/222020.222828
   Taylor P, 2023, Market share of mobile operating systems worldwide from 1st quarter 2009 to 2nd quarter 2023
   Unity Real-time Development Platform, 2023, 3D, 2D, VR & AR Engine
   Vaughan-Nichols SJ, 2009, COMPUTER, V42, P19, DOI 10.1109/MC.2009.380
   Wing JM, 2006, COMMUN ACM, V49, P33, DOI 10.1145/1118178.1118215
   Zhang ZN, 2021, MULTIMED TOOLS APPL, V80, P575, DOI 10.1007/s11042-020-09684-x
NR 38
TC 0
Z9 0
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 11
PY 2023
DI 10.1007/s11042-023-17712-9
EA DEC 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AZ2A4
UT WOS:001122190800020
DA 2024-07-18
ER

PT J
AU Jiang, WJ
   Wang, J
AF Jiang, Wenjing
   Wang, Jian
TI Classification of ECG signals based on local fractal feature
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hurst exponent; Sliding window; MF-DFA
ID KNOWLEDGE; SYSTEM; MODEL
AB Accurate and automatic analysis of electrocardiogram (ECG) signals plays a key role in the diagnosis of cardiovascular disease. This paper aims to investigate the performance of the multifractal detrending fluctuation analysis (MF-DFA) method based on a sliding window in ECG signal classification. We apply ECG signals to the detrended fluctuation analysis (DFA) method to obtain a group of local Hurst exponents and compose the DFA series. Afterwards, we use the MF-DFA method to get 6 generalized Hurst exponents of atrial premature beats (APB) and ECG signals with normal sinus rhythm (NSR), respectively. The 6 generalized Hurst exponents compose a feature vector and it is used in support vector machine (SVM) to examine the accuracy of ECG signal classification. The calculated results show that the MF-DFA method combined with a sliding window (SWD-MF-DFA) method performs well. Compared with directly using the MF-DFA method, with the same parameters, the accuracy of SWD-MF-DFA is higher, so as is the sensitivity and the specificity. As well, the proposed model can better analyze the local detailed features of time series and allows the application of MF-DFA in different parts of the time series, enabling the detection and analysis of time series variability.
C1 [Jiang, Wenjing; Wang, Jian] Nanjing Univ Informat Sci & Technol, Sch Math & Stat, Nanjing 210044, Peoples R China.
   [Wang, Jian] Nanjing Univ Informat Sci & Technol, Ctr Appl Math Jiangsu Prov, Nanjing 210044, Peoples R China.
   [Wang, Jian] Nanjing Univ Informat Sci & Technol, Jiangsu Int Joint Lab Syst Modeling & Data Anal, Nanjing 210044, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Information Science & Technology
RP Wang, J (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Math & Stat, Nanjing 210044, Peoples R China.; Wang, J (corresponding author), Nanjing Univ Informat Sci & Technol, Ctr Appl Math Jiangsu Prov, Nanjing 210044, Peoples R China.; Wang, J (corresponding author), Nanjing Univ Informat Sci & Technol, Jiangsu Int Joint Lab Syst Modeling & Data Anal, Nanjing 210044, Peoples R China.
EM 20211215023@nuist.edu.cn; 003328@nuist.edu.cn
FU Open Project of Center for Applied Mathematics of Jiangsu Province
   (Nanjing University of Information Science and Technology)
FX The corresponding author Jian Wang was supported by the Open Project of
   Center for Applied Mathematics of Jiangsu Province (Nanjing University
   of Information Science and Technology). In addition, the authors are
   grateful to Haixiao Wang for his contributions in language editing and
   polishing. Meanwhile, the authors express deep gratitude to the
   reviewers for their valuable suggestions and comments, which
   significantly improved the quality of this article.
CR Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   da Silva AM, 2021, PHYSICA A, V567, DOI 10.1016/j.physa.2020.125653
   Dalal S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-94363-6
   Diker A, 2021, MULTIMED TOOLS APPL, V80, P24777, DOI 10.1007/s11042-021-10517-8
   Dong XD, 2017, NEUROCOMPUTING, V240, P1, DOI 10.1016/j.neucom.2017.02.056
   Einthoven W, 1902, HERINNERINGSBUNDEL, P101
   He RN, 2019, IEEE ACCESS, V7, P102119, DOI 10.1109/ACCESS.2019.2931500
   Jeon H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20174996
   Ji YS, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112558
   Jiao DZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123234
   Kantelhardt JW, 2002, PHYSICA A, V316, P87, DOI 10.1016/S0378-4371(02)01383-3
   Kuila S, 2022, MULTIMED TOOLS APPL, V81, P25233, DOI 10.1007/s11042-022-11957-6
   Li HF, 2009, EXPERT SYST APPL, V36, P1466, DOI 10.1016/j.eswa.2007.11.061
   Li SS, 2020, PHYSICA A, V559, DOI 10.1016/j.physa.2020.125029
   Li YW, 2018, IEEE ACCESS, V6, P39734, DOI 10.1109/ACCESS.2018.2855420
   Liang YB, 2020, FRONT PHYSIOL, V11, DOI 10.3389/fphys.2020.569050
   Liu D, 2016, WATER RESOUR MANAG, V30, P505, DOI 10.1007/s11269-015-1174-9
   Ma S, 2022, MEASUREMENT, V203, DOI 10.1016/j.measurement.2022.111978
   Mishra AK, 2010, BIOMED SIGNAL PROCES, V5, P114, DOI 10.1016/j.bspc.2010.01.002
   Naqvi SF, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164400
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Papaloukas C, 2001, MED BIOL ENG COMPUT, V39, P105, DOI 10.1007/BF02345273
   PENG CK, 1994, PHYS REV E, V49, P1685, DOI 10.1103/PhysRevE.49.1685
   PENG CK, 1995, CHAOS, V5, P82, DOI 10.1063/1.166141
   Pranata AA, 2017, CONSUM COMM NETWORK, P126, DOI 10.1109/CCNC.2017.7983093
   Romdhane TF, 2020, COMPUT BIOL MED, V123, DOI 10.1016/j.compbiomed.2020.103866
   Méndez-Gordillo AR, 2021, CHAOS SOLITON FRACT, V143, DOI 10.1016/j.chaos.2020.110592
   Sangaiah AK, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101788
   Tseng KK, 2021, COMPUT ELECTR ENG, V96, DOI 10.1016/j.compeleceng.2021.107521
   Tsipouras MG, 2005, ARTIF INTELL MED, V33, P237, DOI 10.1016/j.artmed.2004.03.007
   Vafaie MH, 2014, BIOMED SIGNAL PROCES, V14, P291, DOI 10.1016/j.bspc.2014.08.010
   Vapnik V., 1999, NATURE STAT LEARNING
   Venkatesan C, 2018, MULTIMED TOOLS APPL, V77, P10365, DOI 10.1007/s11042-018-5762-6
   Wang J, 2021, INT J MOD PHYS B, V35, DOI 10.1142/S0217979221503276
   Wang J, 2021, FRACTALS, V29, DOI 10.1142/S0218348X21500298
   Wang SH, 2021, J HEALTHC ENG, V2021, DOI 10.1155/2021/6630643
   Yang RP, 2021, NEURAL NETWORKS, V142, P564, DOI 10.1016/j.neunet.2021.07.018
   Zhang ZN, 2017, J X-RAY SCI TECHNOL, V25, P261, DOI 10.3233/XST-17258
NR 38
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 8
PY 2023
DI 10.1007/s11042-023-17787-4
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AE1J4
UT WOS:001116691800003
DA 2024-07-18
ER

PT J
AU Liu, T
   Yan, S
   Wang, GF
AF Liu, Ting
   Yan, Shun
   Wang, Guofeng
TI Remove and recover: two stage convolutional autoencoder based sonar
   image enhancement algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Underwater object detection; Sonar image; Convolutional autoencoders;
   Speckle reduction; Image enhancement
AB High-quality forward-looking sonar images are the basic guarantee for underwater object detection and classification of autonomous underwater vehicle (AUV). However, the sonar image has been suffering from two main problem with complex and changeable underwater environment: high speckle noises and the lack of high frequency information. In this paper, a two-stage sonar image enhancement algorithm based on convolutional autoencoder is proposed to solve the above two problems to allow low-frequency sonar images to obtain resolutions approximate to high-frequency sonar images. For the high speckle noise, we proposed a convolutional denoising autoencoder based speckle reduction method for low-frequency sonar image to avoid noise enhanced as the image enhancement process. Skip connections and newly designed loss function is incorporated to better suppress noise with varying degrees. To solve the problem of insufficient high frequency information, a convolutional sparse autoencoder is further introduced to achieve image super resolution enhancement. In order to verify the effectiveness of the enhancement network proposed in this paper, we conducted extensive experimental analysis have been conducted from two aspects: image enhancement effect and underwater target detection effect. Specifically, underwater sonar images have been collected was conducted based on our self-owned AUV platform equipped with a dual frequency forward looking sonar in a water tank for network training. And three datasets are constructed for speckle reduction, high-frequency restoration, and underwater target detection. Through extensive experimental verification, our proposed enhancement method achieves high performance improvement on speckle reduction and high-frequency information restoration than the state-of-the-art image speckle reduction and image enhancement algorithms with a better PSNR, SSIM, and EPI. Finally, the YOLO V5 network model is used for underwater target detection and the experimental results show that combining image enhancement networks can effectively alleviate the problems of false and missed detections in the original network, which greatly improving the detection accuracy of the algorithm with a high detection speed. All the experiments have shown that the method proposed in this paper can effectively improve the underwater perception ability of sonar equipment.
C1 [Liu, Ting; Wang, Guofeng] Dalian Maritime Univ, Dalian 116026, Peoples R China.
   [Yan, Shun] Yiqiyin Hangzhou Technol CO LTD, Hangzhou 310000, Peoples R China.
C3 Dalian Maritime University
RP Liu, T (corresponding author), Dalian Maritime Univ, Dalian 116026, Peoples R China.
EM liuting0910@dlmu.edu.cn
FU Postdoctoral Research Foundation of China
FX No Statement Available
CR Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI [10.5555/3045796.3045801., DOI 10.1561/2200000006, 10.1561/2200000006]
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Cao X, 2023, IEEE T NEUR NET LEAR, V34, P9198, DOI 10.1109/TNNLS.2022.3156907
   Chen Z, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107853
   Dong WS, 2019, IEEE T PATTERN ANAL, V41, P2305, DOI 10.1109/TPAMI.2018.2873610
   Fan XN, 2022, MULTIMED TOOLS APPL, V81, P10091, DOI 10.1007/s11042-022-12054-4
   Gerg ID, 2020, 2020 IEEE INT GEOSCI
   Glorot X., 2011, JMLR Proceedings, V15, P315, DOI DOI 10.1002/ECS2.1832
   Gondara L, 2016, INT CONF DAT MIN WOR, P241, DOI [10.1109/ICDMW.2016.102, 10.1109/ICDMW.2016.0041]
   Goodman J. W., 2007, Speckle Phenomena in Optics: Theory and Applications
   Gunjan V., 2022, J Electron Imaging, V31
   Guo CL, 2020, PROC CVPR IEEE, P1777, DOI 10.1109/CVPR42600.2020.00185
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Jin Y, 2019, IEEE GEOSCI REMOTE S, V16, P1215, DOI 10.1109/LGRS.2019.2895843
   Karimanzira D, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071180
   Kim J, 2017, IEEE OES INT S UNDER
   Kim J, 2017, 2017 IEEE UNDERWATER
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee B., 2020, IEEE Geosci Remote Sens Lett, VPP, P1
   Li SB, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12142336
   Ling HF, 2021, NAT COMPUT, V20, P3, DOI 10.1007/s11047-019-09749-3
   McMahon J, 2021, IEEE ROBOT AUTOM LET, V6, P1832, DOI 10.1109/LRA.2021.3060709
   Najibzadeh M, 2023, NEURAL PROCESS LETT, V55, P8689, DOI 10.1007/s11063-023-11173-9
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sakshi, 2023, ARCH COMPUT METHOD E, V30, P457, DOI 10.1007/s11831-022-09805-9
   Shi PF, 2024, MULTIMED TOOLS APPL, V83, P10233, DOI 10.1007/s11042-023-15837-5
   Sung MS, 2020, INT J CONTROL AUTOM, V18, P523
   Sutskever I, 2014, ADV NEUR IN, V27
   Wang Wan-Jiang, 2019, Journal of Zhejiang University (Engineering Science), V53, P1728, DOI 10.3785/j.issn.1008-973X.2019.09.012
   Wang Y, 2022, J MAR SCI ENG, V10, DOI 10.3390/jmse10020181
   Xinxu Wei, 2021, 2021 6th International Conference on Robotics and Automation Engineering (ICRAE), P275, DOI 10.1109/ICRAE53653.2021.9657795
   Yang C, 2023, MACH VISION APPL, V34, DOI 10.1007/s00138-023-01406-1
   Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P292, DOI 10.5201/ipol.2011.ys-dct
   Yuan F, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.102995
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhao K, 2020, E3S WEB CONF, V206, DOI 10.1051/e3sconf/202020603019
   Zou SF, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401276
NR 37
TC 1
Z9 1
U1 11
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 5
PY 2023
DI 10.1007/s11042-023-17673-z
EA DEC 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8R0
UT WOS:001121582900004
DA 2024-07-18
ER

PT J
AU Karthickmanoj, R
   Sasilatha, T
AF Karthickmanoj, R.
   Sasilatha, T.
TI Development of plant disease detection for smart agriculture
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Classification; Machine learning; Plant disease; Deep learning; Smart
   agriculture
ID IOT
AB Plant leaf diseases have become a serious concern for the agricultural industry, yet timely diagnosis and recognition are challenging in numerous regions of the globe owing to a shortage of automated crop disease identification methods. If plant diseases are not recognized in a prompt way, food insecurity will rise, affecting the country's income. Plant disease identification is critical for successful crop prevention and control of diseases, as well as farm production management and decision-making. Plant disease detection technologies aid in finding infected plants in their early phases and also help the user in cost-effectively expanding plant disease identification system to a variety of plants. This paper's major contribution is a stacked ensemble technique based on Machine learning and Deep learning techniques. This research article also elaborates on how plant disease detection framework will be realized using novel segmentation and feature extraction strategies for extracting significant features for classification. Once the features are extracted, they are transmitted to the cloud platform to implement web enabled automated monitoring system. The proposed stacked ensemble learning is evaluated by comparing different machine learning and Deep learning techniques models utilizing precision, recall, and F_score. When compared to traditional machine learning and deep learning techniques approaches, the findings show that the proposed technique achieves about 99% accuracy.
C1 [Karthickmanoj, R.; Sasilatha, T.] Deemed Be Univ, Acad Maritime Educ & Training, Dept Elect & Elect Engn, Chennai, Tamil Nadu, India.
RP Karthickmanoj, R (corresponding author), Deemed Be Univ, Acad Maritime Educ & Training, Dept Elect & Elect Engn, Chennai, Tamil Nadu, India.
EM karthickmanoj.r@gmail.com
RI .R, Karthickmanoj/AFA-7532-2022
OI .R, Karthickmanoj/0000-0001-9077-6109
CR Ahmed S, 2022, IEEE ACCESS, V10, P68868, DOI 10.1109/ACCESS.2022.3187203
   Alguliyev R, 2021, SOFT COMPUT, V25, P13229, DOI 10.1007/s00500-021-06176-4
   Cedric LS, 2022, SMART AGR TECHNOL, V2, DOI 10.1016/j.atech.2022.100049
   Chhabra P, 2020, NEURAL COMPUT APPL, V32, P2725, DOI 10.1007/s00521-018-3677-9
   Debnath O, 2022, MICROPROCESS MICROSY, V94, DOI 10.1016/j.micpro.2022.104631
   Dhaka VS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21144749
   Domingues T, 2022, AGRICULTURE-BASEL, V12, DOI 10.3390/agriculture12091350
   Jackulin C., 2022, Measurement: Sensors
   Jiang P, 2019, IEEE ACCESS, V7, P59069, DOI 10.1109/ACCESS.2019.2914929
   Jumat MH, 2018, Smart farm prototype for plant disease detection, diagnosis & treatment using IoT device in a greenhouse, P48
   Latif G, 2022, PLANTS-BASEL, V11, DOI 10.3390/plants11172230
   Liu ZY, 2022, IEEE ACCESS, V10, P44934, DOI 10.1109/ACCESS.2022.3169147
   Mahendran T., 2022, J Posit School Psychol, V6, P2553
   Mustafa H, 2023, MULTIMED TOOLS APPL, V82, P12065, DOI 10.1007/s11042-022-13737-8
   Nagasubramanian G, 2021, IEEE INTERNET THINGS, V8, P12847, DOI 10.1109/JIOT.2021.3072908
   Pietikäinen M, 2011, COMPUT IMAGING VIS, V40, P13, DOI 10.1007/978-0-85729-748-8_2
   Raghuvanshi A, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/3955514
   Saravanan G, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P462, DOI 10.1109/ICCSP.2016.7754179
   Shoaib M, 2023, FRONT PLANT SCI, V14, DOI 10.3389/fpls.2023.1158933
   Shoaib M, 2022, FRONT PLANT SCI, V13, DOI 10.3389/fpls.2022.1031748
   Singh V, 2019, ARTIF INTELL AGR, V3, P62, DOI 10.1016/j.aiia.2019.09.002
   Srivastava D, 2020, NEURAL COMPUT APPL, V32, P10819, DOI 10.1007/s00521-018-3611-1
   Sunil CK, 2022, IEEE ACCESS, V10, P789, DOI 10.1109/ACCESS.2021.3138920
   Thorat A, 2017, 2017 INTERNATIONAL CONFERENCE ON BIG DATA, IOT AND DATA SCIENCE (BID), P193, DOI 10.1109/BID.2017.8336597
   Turkoglu M, 2022, SIGNAL IMAGE VIDEO P, V16, P301, DOI 10.1007/s11760-021-01909-2
   Zamani A, 2022, J FOOD QUALITY, V2022, DOI 10.1155/2022/1598796
NR 26
TC 1
Z9 1
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 DEC 4
PY 2023
DI 10.1007/s11042-023-17687-7
EA DEC 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA AW8Q2
UT WOS:001121582100005
DA 2024-07-18
ER

PT J
AU Sharma, M
   Biswas, M
AF Sharma, Monika
   Biswas, Mantosh
TI A deep learning based hybrid framework for semisupervised classification
   of hyperspectral remote sensing images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Remote sensing; Semisupervised; Deep learning; Hyperspectral image
   classification
ID SPECTRAL-SPATIAL CLASSIFICATION; TRANSDUCTIVE SVM; INFORMATION;
   ALGORITHM; SUBSPACE; COVER; VIEWS
AB Since performance of traditional classification methods is extremely dependent on the number of labeled samples and, to gather ground-truth information of hyperspectral images from the earth's surface is an expensive and time-consuming process. Semisupervised classification is extensively utilized for hyperspectral images to deal with the issue of restricted training samples by combining the power of labeled and unlabeled data. In this paper, a unique semisupervised classification technique depends on a deep learning based hybrid framework (DL-HF) is described in order to utilize the more information as feasible in order to complete the hyperspectral classification issues. To begin, the proposed semisupervised based method DL-HF uses mainly two arrangements for pre labeling of unlabeled data: the neighboring samples create local arrangement based on neighborhood weighted information, and the most similar training data samples perform global arrangement based on deep learning. Then, to expand the training set, a few unlabeled samples along with superior confidence have been chosen. Finally, using the revised training data, self-arrangement which is based on the self-features developed through deep learning used to extract spectral as well as spatial features and generate a classified map. Evaluation results confirmed that the classification effects of proposed DL-HF algorithm are significantly better in contrast to other competing classification schemes on two benchmark hyperspectral datasets: AVIRIS Indian pines and AVIRIS salina valley dataset, in terms of Overall Accuracy (OA), Average Accuracy (AA) and kappa coefficient (k). The overall classification accuracy achieved is more than 94% which is superior to other related classification methods.
C1 [Sharma, Monika] BK Birla Inst Engn & Technol Pilani, Dept Comp Sci & Engn, Pilani, Rajasthan, India.
   [Biswas, Mantosh] Univ Delhi, Dept Comp Sci, New Delhi, India.
C3 University of Delhi
RP Sharma, M (corresponding author), BK Birla Inst Engn & Technol Pilani, Dept Comp Sci & Engn, Pilani, Rajasthan, India.
EM monikasharma2207@gmail.com; mantoshb@gmail.com
RI Sharma, Monika/KOC-1765-2024
CR Amini S, 2014, INT GEOSCI REMOTE SE, DOI 10.1109/IGARSS.2014.6947074
   Bai J, 2023, IEEE T NEURAL NETW L
   Banerjee A, 2006, IEEE T GEOSCI REMOTE, V44, P2282, DOI 10.1109/TGRS.2006.873019
   Bannari A, 2006, REMOTE SENS ENVIRON, V104, P447, DOI 10.1016/j.rse.2006.05.018
   Bhatti UA, 2023, EXPERT SYST APPL, V229, DOI 10.1016/j.eswa.2023.120496
   Bruzzone L, 2006, IEEE T GEOSCI REMOTE, V44, P3363, DOI 10.1109/TGRS.2006.877950
   Camps-Valls G, 2007, IEEE T GEOSCI REMOTE, V45, P3044, DOI 10.1109/TGRS.2007.895416
   Chapel L, 2014, IEEE J-STARS, V7, P1070, DOI 10.1109/JSTARS.2014.2304304
   Chen HY, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15133402
   Chen YS, 2014, IEEE J-STARS, V7, P2094, DOI 10.1109/JSTARS.2014.2329330
   Chi MM, 2007, IEEE T GEOSCI REMOTE, V45, P1870, DOI 10.1109/TGRS.2007.894550
   Datta D., 2022, Comput Intell Neurosci, V2022, P1
   Di W, 2012, IEEE T GEOSCI REMOTE, V50, P1942, DOI 10.1109/TGRS.2011.2168566
   Ding Y, 2023, EXPERT SYST APPL, V223, DOI 10.1016/j.eswa.2023.119858
   Dópido I, 2013, IEEE T GEOSCI REMOTE, V51, P4032, DOI 10.1109/TGRS.2012.2228275
   Feng ZX, 2021, IEEE T CYBERNETICS, V51, P346, DOI 10.1109/TCYB.2018.2883472
   Gao LR, 2015, IEEE GEOSCI REMOTE S, V12, P349, DOI 10.1109/LGRS.2014.2341044
   Ghamisi P, 2015, IEEE T GEOSCI REMOTE, V53, P2335, DOI 10.1109/TGRS.2014.2358934
   Gualtieri J., 1999, Support vector machine classifiers as applied to AVIRIS data, presented at the Airborne Geosci
   Han W, 2018, ISPRS J PHOTOGRAMM, V145, P23, DOI 10.1016/j.isprsjprs.2017.11.004
   HUGHES GF, 1968, IEEE T INFORM THEORY, V14, P55, DOI 10.1109/TIT.1968.1054102
   Im DJ, 2015, IEEE GEOSCI REMOTE S, V12, P1913, DOI 10.1109/LGRS.2015.2438227
   Jin G, 2013, INT CONF ACOUST SPEE, P3302, DOI 10.1109/ICASSP.2013.6638269
   Jun G, 2013, IEEE T GEOSCI REMOTE, V51, P273, DOI 10.1109/TGRS.2012.2198654
   Kang XD, 2014, IEEE T GEOSCI REMOTE, V52, P2666, DOI 10.1109/TGRS.2013.2264508
   Kaul A, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6945
   Khodadadzadeh M, 2014, IEEE GEOSCI REMOTE S, V11, P2105, DOI 10.1109/LGRS.2014.2320258
   Khodadadzadeh M, 2014, IEEE T GEOSCI REMOTE, V52, P6298, DOI 10.1109/TGRS.2013.2296031
   Landgrebe DA, 2001, IEEE T GEOSCI REMOTE, V39, P1343, DOI 10.1109/TGRS.2001.934066
   Li J, 2013, IEEE GEOSCI REMOTE S, V10, P318, DOI 10.1109/LGRS.2012.2205216
   Li W, 2014, IEEE J-STARS, V7, P1012, DOI 10.1109/JSTARS.2013.2295313
   Li XF, 2022, NEUROCOMPUTING, V500, P499, DOI 10.1016/j.neucom.2022.05.093
   Liu DF, 2021, PROC CVPR IEEE, P9811, DOI 10.1109/CVPR46437.2021.00969
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Ma XR, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0071-8
   Manolakis D, 2002, IEEE SIGNAL PROC MAG, V19, P29, DOI 10.1109/79.974724
   Maulik U, 2013, ISPRS J PHOTOGRAMM, V77, P66, DOI 10.1016/j.isprsjprs.2012.12.003
   Melgani F, 2004, IEEE T GEOSCI REMOTE, V42, P1778, DOI 10.1109/TGRS.2004.831865
   Melgani F, 2002, PATTERN RECOGN LETT, V23, P1053, DOI 10.1016/S0167-8655(02)00052-1
   Niazmardi S, 2013, IEEE J-STARS, V6, P831, DOI 10.1109/JSTARS.2013.2244851
   Pan B, 2016, IEEE GEOSCI REMOTE S, V13, P1782, DOI 10.1109/LGRS.2016.2608963
   Patel NK, 2001, INT J REMOTE SENS, V22, P2401, DOI 10.1080/014311601300229881
   Pu HY, 2014, IEEE T GEOSCI REMOTE, V52, P7008, DOI 10.1109/TGRS.2014.2306687
   Tan K, 2015, IEEE GEOSCI REMOTE S, V12, P1765, DOI 10.1109/LGRS.2015.2424963
   Tan K, 2015, ISPRS J PHOTOGRAMM, V105, P19, DOI 10.1016/j.isprsjprs.2015.03.006
   Wang LG, 2014, ISPRS J PHOTOGRAMM, V97, P123, DOI 10.1016/j.isprsjprs.2014.08.016
   Xi BB, 2023, IEEE T NEUR NET LEAR, V34, P9337, DOI 10.1109/TNNLS.2022.3158280
   Yan L., 2022, P 31 INT JOINT C ART, P1
   Yang LX, 2014, IEEE GEOSCI REMOTE S, V11, P651, DOI 10.1109/LGRS.2013.2273792
   Yang Z., 2023, Remote Sens, V15, P15
   Yao D, 2023, DEF TECHNOL, V23, P164, DOI 10.1016/j.dt.2022.02.007
   Zhang LF, 2012, IEEE T GEOSCI REMOTE, V50, P879, DOI 10.1109/TGRS.2011.2162339
   Zhang XR, 2014, IEEE J-STARS, V7, P2044, DOI 10.1109/JSTARS.2014.2325741
   Zhang Y, 2022, INT J PROD RES, V60, P2553, DOI 10.1080/00207543.2021.1897178
   Zhang YX, 2023, IEEE T IMAGE PROCESS, V32, P1498, DOI 10.1109/TIP.2023.3243853
   Zhang ZY, 2020, MICROPROCESS MICROSY, V75, DOI 10.1016/j.micpro.2020.103070
   Zhao CH, 2023, IEEE T IMAGE PROCESS, V32, P3606, DOI 10.1109/TIP.2023.3287738
   Zhong YF, 2014, IEEE J-STARS, V7, P1235, DOI 10.1109/JSTARS.2014.2303634
   Zhong YF, 2006, IEEE T GEOSCI REMOTE, V44, P420, DOI 10.1109/TGRS.2005.861548
NR 59
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 16
PY 2023
DI 10.1007/s11042-023-17641-7
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9GJ6
UT WOS:001101450500002
DA 2024-07-18
ER

PT J
AU Revathi, A
   Sasikaladevi, N
   Arunprasanth, D
   Raju, N
AF Revathi, A.
   Sasikaladevi, N.
   Arunprasanth, D.
   Raju, N.
TI Raspberry Pi-based robust speech command recognition for normal and
   hearing-impaired (HI)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Speech command recognition; Hearing-impaired; Spectrogram; CNN; Machine
   learning techniques; Raspberry Pi hardware
ID ENHANCEMENT; AID
AB The speech command identification system has become a necessary tool to transcribe speech into text, for performing hands-free control of devices and hazardous processes, etc. It also finds applications in searching the contents online over voice and speech-to-text conversion for differently-abled persons. This work includes the extraction of the spectrogram from speech signals, applying 80% of the features to the 2D convolutional neural network (CNN) layered architecture, and creating CNN group models.CNN models are used to test features to recognize the words uttered by normal and Hearing-impaired (HI). The system's performance is assessed based on the recognition rate for spectrogram, Melspectrogram and Gammatonegram features and CNN. In addition, the speech intelligibility of HI speeches is enhanced using the phase spectrum compensation (PSC) technique. Decision-level fusion of spectrogram features for regular speech recognition, HI speech recognition without PSC and HI speech recognition with PSC have provided an accuracy of 95%, 98% and 99%, respectively. Twenty isolated words are considered for regular speech command recognition, and ten isolated digits are regarded for a HI speech recognition system. This automated speech command recognition is implemented in real-time using Raspberry Pi hardware, and the validation error for the test data is 0.57692%.
C1 [Revathi, A.; Raju, N.] SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
   [Sasikaladevi, N.] SASTRA Univ, Sch Comp, Thanjavur 613401, India.
   [Arunprasanth, D.] Thanjavur Med Coll & Hosp, Thanjavur 613004, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA);
   Shanmugha Arts, Science, Technology & Research Academy (SASTRA)
RP Revathi, A (corresponding author), SASTRA Univ, Sch Elect & Elect Engn, Thanjavur 613401, India.
EM revathi@ece.sastra.edu
CR Akbarzadeh S, 2019, IEEE ENG MED BIO, P3119, DOI [10.1109/embc.2019.8857952, 10.1109/EMBC.2019.8857952]
   Algabri M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21041205
   Arias-Vergara T, 2021, PATTERN ANAL APPL, V24, P423, DOI 10.1007/s10044-020-00921-5
   Arunachalam R, 2019, MULTIMED TOOLS APPL, V78, P20787, DOI 10.1007/s11042-019-7329-6
   Bai ZX, 2021, NEURAL NETWORKS, V140, P65, DOI 10.1016/j.neunet.2021.03.004
   Bernstein LE, 2022, AM J AUDIOL, V31, P453, DOI 10.1044/2021_AJA-21-00112
   Bhat GS, 2019, IEEE ACCESS, V7, P78421, DOI [10.1109/ACCESS.2019.2922370, 10.1109/access.2019.2922370]
   Brookes C, 2000, IEE SEM SPEECH LANG
   CARLSON GS, 1988, INT J REHABIL RES, V11, P396, DOI 10.1097/00004356-198812000-00013
   Chee LS, 2009, IEEE ST CONF RES DEV, P146, DOI 10.1109/SCORED.2009.5443210
   Chen HW, 2024, EVOL INTELL, V17, P9, DOI 10.1007/s12065-020-00462-0
   de Andrade DC, 2018, Arxiv, DOI arXiv:1808.08929
   DELLER JR, 1991, COMPUT METH PROG BIO, V35, P125, DOI 10.1016/0169-2607(91)90071-Z
   Ding N, 2023, HEARING RES, V431, DOI 10.1016/j.heares.2023.108725
   Dogaru D-C., 2019, 6 INT S EL EL ENG IS, V2019, P1, DOI [10.1109/ISEEE48094.2019.9136152, DOI 10.1109/ISEEE48094.2019.9136152]
   Dominguez-Morales J. P., 2018, 2018 INT JOINT C NEU, P1
   Du YC, 2022, IEEE SENS J, V22, P21163, DOI 10.1109/JSEN.2022.3206140
   Fontan L, 2020, TRENDS HEAR, V24, DOI 10.1177/2331216520914769
   Garofolo J. S., 1993, Timit acoustic phonetic continuous speech corpus
   Ghosh R, 2022, IEEE T BIO-MED ENG, V69, P1251, DOI 10.1109/TBME.2021.3123241
   Girgin MC, 2008, World Appl Sci J, V4, P891
   Gonzalez-Huitron V, 2021, COMPUT ELECTRON AGR, V181, DOI 10.1016/j.compag.2020.105951
   Gudi AB, 2010, Int J Eng Technol, V2, P169
   Han ZY, 2009, INT J MODEL IDENTIF, V8, P240, DOI 10.1504/IJMIC.2009.029269
   Hasan MR, 2021, J ENG-JOE, V2021, P817, DOI 10.1049/tje2.12082
   Hawley MS, 2013, IEEE T NEUR SYS REH, V21, P23, DOI 10.1109/TNSRE.2012.2209678
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   Hu FH, 2020, ADV INTELL SYST COMP, V1039, P1, DOI 10.1007/978-3-030-30465-2_1
   Ismail A, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12062403
   Jamil MHM, 2011, COMM COM INF SC, V251, P42
   Jeyalakshmi C, 2018, INT J BIOMED ENG TEC, V26, P84, DOI 10.1504/IJBET.2018.089261
   Johnston SJ, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6030051
   Joshi S, 2021, IEEE T INF FOREN SEC, V16, P4811, DOI 10.1109/TIFS.2021.3116438
   Karjalainen M, 1997, 5 EUR C SPEECH COMM
   LEVITT H, 1972, IEEE T ACOUST SPEECH, VAU20, P35, DOI 10.1109/TAU.1972.1162351
   Lyashenko V, 2021, Recognition of Voice Commands Based on Neural Network, DOI [10.18421/TEM102-13, DOI 10.18421/TEM102-13]
   Mahmoudi Z, 2010, 10 INT C INF SCI SIG, V1, P304
   Mengistu KT, 2011, INT CONF ACOUST SPEE, P4924
   Newman CW, 2004, CLEV CLIN J MED, V71, P225, DOI 10.3949/ccjm.71.3.225
   Omar Ahmed, 2020, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2020). Advances in Intelligent Systems and Computing (AISC 1153), P247, DOI 10.1007/978-3-030-44289-7_24
   Phung Hung Binh, 2021, 2021 International Conference on System Science and Engineering (ICSSE), P96, DOI 10.1109/ICSSE52999.2021.9537942
   PICKETT JM, 1969, IEEE T ACOUST SPEECH, VAU17, P283, DOI 10.1109/TAU.1969.1162064
   Pitts AB, 2010, Comparing Speech Assessments: The Usefulness of the DEAP as Compared tothe GFTA-2, Independent Studies and Capstones, Program in Audiology and Communication Sciences
   Polur PD, 2006, MED ENG PHYS, V28, P741, DOI 10.1016/j.medengphy.2005.11.002
   Lin ZQ, 2018, Arxiv, DOI arXiv:1810.08559
   Rabiner L. R., 1999, Fundamentals of speech recognition
   Revathi A, 2017, J ENG RES-KUWAIT, V5, P110
   Salehi H, 2018, IEEE-ACM T AUDIO SPE, V26, P2277, DOI 10.1109/TASLP.2018.2860786
   Sangwan P, 2023, INT J COMMUN SYST, V36, DOI 10.1002/dac.4418
   Schädler MR, 2020, TRENDS HEAR, V24, DOI 10.1177/2331216520938929
   Soliman A, 2021, 2020 INT C COMP CONT, P1, DOI [10.1109/ICCCEEE49695.2021.9429684, DOI 10.1109/ICCCEEE49695.2021.9429684]
   Sridhar C., 2023, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/2466/1/012008
   Tseng S.-C., 2011, 17 INT C PHON SCI, P2030
   Vashistha Piyush, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P974, DOI 10.1109/ICECA.2019.8821892
   Vavrek L, 2021, 2021 IEEE 19TH WORLD SYMPOSIUM ON APPLIED MACHINE INTELLIGENCE AND INFORMATICS (SAMI 2021), P245, DOI 10.1109/SAMI50585.2021.9378656
   Wang ZB, 2022, IEEE T MOBILE COMPUT, V21, P2398, DOI 10.1109/TMC.2020.3038303
   Yamada Y, 2000, SPEECH COMMUN, V30, P179, DOI 10.1016/S0167-6393(99)00039-4
   Yamanoor NS, 2017, IEEE GLOB HUMANIT C
   Yang CHH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6523, DOI 10.1109/ICASSP39728.2021.9413453
   Yang SZ, 2020, IEEE ACCESS, V8, P81468, DOI 10.1109/ACCESS.2020.2990974
   Zhang JJ, 2017, PROC INT C TOOLS ART, P336, DOI 10.1109/ICTAI.2017.00060
   Zhiyan Han, 2008, 2008 2nd International Conference on Bioinformatics and Biomedical Engineering (ICBBE '08), P2036
NR 62
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 14
PY 2023
DI 10.1007/s11042-023-17543-8
EA NOV 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA JF3O4
UT WOS:001171713900009
DA 2024-07-18
ER

PT J
AU Anisha, PR
   Reddy, CKK
   Hanafiah, MM
   Murthy, BR
   Mohana, RM
   Pragathi, YVSS
AF Anisha, P. R.
   Reddy, C. Kishor Kumar
   Hanafiah, Marlia M.
   Murthy, Bhamidipati Ramana
   Mohana, R. Madana
   Pragathi, Y. V. S. S.
TI An intelligent deep feature based metabolism syndrome prediction system
   for sleep disorder diseases
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Metabolism syndrome; Sleep disorder; Severity classification; Feature
   analysis; Biological parameters
ID APNEA; DIAGNOSIS
AB The Obstructive Sleep Apnea (OSA) analysis and prediction is the hottest topic in the medical healthcare industry. However, identifying the sleep disorder and its Severity is too complex because of the unique biological parameters of every human. So, the current research plans to develop a novel Chimp-based Recurrent Mets Framework (CbRMF) for predicting metabolism syndrome features. It is functioned based on artificial intelligence and bio-inspired optimization principles. Hence, based on the abnormal metabolism syndrome density, the severity score of OSA has been forecasted. The noise features were removed in the hidden layer of the CbRMF, and then the feature analyzing and prediction function was performed. Moreover, the designed model is tested in the Python environment, and the performance has been measured based on prediction accuracy rate, sensitivity score, F-value, precision, and misclassification rate. Incorporating the chimp fitness function has afforded the finest OSA symptoms detection and severity classification outcome. The efficiency of the proposed technique is measured by testing it with different databases like metabolism syndrome data, stroke unit data and Polysomnography data. The proposed novel CbRMF has defined the finest outcome for the Polysomnography data, which is 99.3% accuracy for sleep disorder prediction and has recorded a 0.7% error rate. Hence, the presented novel CbRMF has earned the finest OSA severity categorization exactness than the other compared models.
C1 [Anisha, P. R.; Reddy, C. Kishor Kumar; Murthy, Bhamidipati Ramana; Pragathi, Y. V. S. S.] Stanley Coll Engn & Technol Women, Dept Comp Sci & Engn, Hyderabad 500001, Telangana, India.
   [Hanafiah, Marlia M.] Univ Kebangsaan Malaysia, Fac Sci & Technol, Dept Earth Sci & Environm, Bangi 43600, Malaysia.
   [Hanafiah, Marlia M.] Univ Kebangsaan Malaysia, Inst Climate Change, Fac Sci & Technol, Ctr Trop Climate Change Syst, Bangi 43600, Malaysia.
   [Mohana, R. Madana] Chaitanya Bharathi Inst Technol, Dept Artificial Intelligence & Data Sci, Hyderabad, Telangana, India.
C3 Universiti Kebangsaan Malaysia; Universiti Kebangsaan Malaysia;
   Chaitanya Bharathi Institute of Technology
RP Murthy, BR (corresponding author), Stanley Coll Engn & Technol Women, Dept Comp Sci & Engn, Hyderabad 500001, Telangana, India.
EM anishanaidu.pushpala@gmail.com; kishoar23@gmail.com;
   mhmarlia@ukm.edu.my; drbvrm@gmail.com; rmmnaidu@gmail.com;
   pragathiyellanki@gmail.com
RI Reddy C, Kishor Kumar/G-6599-2016; Madana Mohana, R/AAX-6435-2021
OI Reddy C, Kishor Kumar/0000-0002-3762-0137; Madana Mohana,
   R/0000-0002-7652-6266; Bhamidipati, Ramana Murthy B
   V/0000-0002-9785-8972
CR Abdel-Basset M, 2020, INFORM FUSION, V61, P84, DOI 10.1016/j.inffus.2020.03.010
   Ahmed Sohail, 2016, 2016 13th International Conference on Service Systems and Service Management (ICSSSM), P1, DOI 10.1109/ICSSSM.2016.7538459
   Ahmed ST, 2022, MALAYS J COMPUT SCI, P53, DOI 10.22452/mjcs.sp2022no2.5
   Bernardini A, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01272-y
   Bitners AC, 2020, LUNG, V198, P257, DOI 10.1007/s00408-020-00342-5
   El Chaar M, 2019, SURG OBES RELAT DIS, V15, P1138, DOI 10.1016/j.soard.2019.03.005
   Eyvazlou M, 2020, BMC ENDOCR DISORD, V20, DOI 10.1186/s12902-020-00645-x
   Fagundes NCF, 2023, J EVID-BASED DENT PR, V23, DOI 10.1016/j.jebdp.2022.101786
   Farrahi V, 2023, INT J MED INFORM, V172, DOI 10.1016/j.ijmedinf.2023.105004
   Fritz BA, 2019, BRIT J ANAESTH, V123, P688, DOI 10.1016/j.bja.2019.07.025
   Garate-Escamila Anna Karen, 2020, Informatics in Medicine Unlocked, V19, P193, DOI 10.1016/j.imu.2020.100330
   Gupta N, 2022, AUTONOMOUS CONNECTED, P183, DOI [10.1016/B978-0-323-90592-3.00010-0, DOI 10.1016/B978-0-323-90592-3.00010-0]
   Guptha NS, 2022, PATTERN RECOGN LETT, V159, P16, DOI 10.1016/j.patrec.2022.04.038
   Guptha NS, 2017, INT J SIGNAL IMAGING, V10, P39, DOI 10.1504/IJSISE.2017.084568
   Guptha NS., 2018, INT J INTELL ENG SYS, V11, P256, DOI [10.22266/ijies2018.0430.28, DOI 10.22266/IJIES2018.0430.28]
   Hajipour F, 2020, MED BIOL ENG COMPUT, V58, P2517, DOI 10.1007/s11517-020-02206-9
   Kamalalochana S., 2019, INT J ENG ADV TECHNO, V8, P244, DOI DOI 10.35940/IJEAT.E1049.0585S19
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Kim J, 2022, BMC PUBLIC HEALTH, V22, DOI [10.1186/s12889-022-13131-x, 10.1186/s12905-022-01918-4, 10.1186/s12906-022-03694-y]
   Korompili G, 2021, SCI DATA, V8, DOI 10.1038/s41597-021-00977-w
   Lu M, 2019, SLEEP BREATH, V23, P1371, DOI 10.1007/s11325-019-01922-3
   Mencar C, 2020, HEALTH INFORM J, V26, P298, DOI 10.1177/1460458218824725
   Mendonça F, 2019, IEEE J BIOMED HEALTH, V23, P825, DOI 10.1109/JBHI.2018.2823265
   Meng YW, 2020, IEEE J BIOMED HEALTH, V24, P878, DOI 10.1109/JBHI.2019.2922178
   Molin NL, 2021, MACH LEARN APPL, V4, DOI 10.1016/j.mlwa.2021.100022
   Nandhini K, 2023, NEURAL PROCESS LETT, V55, P9117, DOI 10.1007/s11063-023-11195-3
   Nandhini K, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103840
   Nirmala SG., 2014, International Journal of Computer Networking, V4, P65
   Pan CK, 2020, AM J OPHTHALMOL, V218, P148, DOI 10.1016/j.ajo.2020.05.040
   Pépin JL, 2020, RESPIROLOGY, V25, P486, DOI 10.1111/resp.13669
   Praveena HD, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/3297316
   Satapathy Santosh Kumar, 2023, Soft Computing for Problem Solving: Proceedings of the SocProS 2022. Lecture Notes in Networks and Systems (547), P55, DOI 10.1007/978-981-19-6525-8_6
   Sghaireen MG, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12123117
   Sharma M, 2018, COMPUT BIOL MED, V100, P100, DOI 10.1016/j.compbiomed.2018.06.011
   Staffini A, 2023, BIOENGINEERING-BASEL, V10, DOI 10.3390/bioengineering10060683
   Sudhamathy G, 2023, 2023 INT C INT SYST, DOI [10.1109/ICISCoIS56541.2023.10100489, DOI 10.1109/ICISCOIS56541.2023.10100489]
   Sundari SLK., 2019, INT J ENG ADV TECHNO, V8, P214, DOI DOI 10.35940/IJEAT.E1044.0585S19
   Sweed RA, 2019, SLEEP BREATH, V23, P1079, DOI 10.1007/s11325-019-01783-w
   Tunca C, 2020, IEEE J BIOMED HEALTH, V24, P1994, DOI 10.1109/JBHI.2019.2958879
   Wang YB, 2023, IEEE T PATTERN ANAL, V45, P2208, DOI 10.1109/TPAMI.2022.3165153
   Wen WW, 2019, CLIN CHIM ACTA, V490, P39, DOI 10.1016/j.cca.2018.12.017
   Xu HJ, 2019, BMC PULM MED, V19, DOI 10.1186/s12890-019-0782-1
   Yang WB, 2023, CLIN EPIDEMIOL, V15, P177, DOI 10.2147/CLEP.S395938
NR 43
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 10
PY 2023
DI 10.1007/s11042-023-17296-4
EA NOV 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9QP0
UT WOS:001101716100005
DA 2024-07-18
ER

PT J
AU Goh, KM
   Lim, L
   Krishnamoorthy, S
   Lai, WK
   Maul, T
   Chaw, JK
AF Goh, Kam Meng
   Lim, Li Li
   Krishnamoorthy, Santhi
   Lai, Weng Kin
   Maul, Tomas
   Chaw, Jun Kit
TI Recent advancement of intelligent-systems in edible birds nest: A review
   from production to processing
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE Birds nest; EBN; Intelligent-system; Swiftlets
ID AMINO-ACID; FAILURE MODES; AUTHENTICATION; IDENTIFICATION;
   DIFFERENTIATION; SPECTROMETRY; HOUSE
AB Edible Bird Nest (EBN) constitutes a thriving industry in several Southeast Asian nations where its value chain encompasses several critical processes starting with nest harvesting to processing, and finally sales. However, a detailed review addressing EBN production from an intelligent system perspective is currently missing. Hence, this paper aims to document a comprehensive study of the various parts of the EBN value chain, where machine-intelligence has been incorporated into various solutions. We classified all the EBN processes into three primary segments: farming and production, quality control, and market analysis. In farming and production, two key areas emerge. First, there is process analysis which involves Failure Mode and Effect Analysis (FMEA) as well as profit, cost, and efficiency analysis, while swiftlet house monitoring pinpoints the optimal environment for swiftlets to flourish. On the other hand, works related to the second segment of quality control can be divided two primary approaches: image analysis which involves either auto-grading or automatic impurities inspection, and chemical analysis to ascertain the origin and authenticity of the EBN. The third and final domain of market analysis, covers both business strategy and customer behavior analysis. We have identified the integration of cutting-edge intelligent methods in each area while offering recommendations for future work. Our findings also unveiled intricate patterns, networks, relationships, and trends in the application of machine intelligence within the EBN value chain. These insights highlight many underexplored areas as well as several strategic aspects in this emerging industry.
C1 [Goh, Kam Meng; Lim, Li Li; Lai, Weng Kin] Tunku Abdul Rahman Univ Management & Technol, Fac Engn & Technol, Ctr Multimodal Signal Proc, Kuala Lumpur 53300, Malaysia.
   [Krishnamoorthy, Santhi] Guru Nanak Inst Tech Campus, Dept Elect & Elect Engn, Hyderabad, India.
   [Maul, Tomas] Univ Nottingham Malaysia Campus, Sch Comp Sci, Semenyih, Selangor Darul, Malaysia.
   [Chaw, Jun Kit] Univ Kebangsaan Malaysia, Inst IR4 0, Bangi 43600, Malaysia.
C3 Guru Nanak Institutions Technical Campus; University of Nottingham
   Malaysia; Universiti Kebangsaan Malaysia
RP Goh, KM (corresponding author), Tunku Abdul Rahman Univ Management & Technol, Fac Engn & Technol, Ctr Multimodal Signal Proc, Kuala Lumpur 53300, Malaysia.
EM gohkm@tarc.edu.my; lllim@tarc.edu.my; santhikeee.gnitc@gmail.com;
   laiwk@tarc.edu.my; Tomas.Maul@nottingham.edu.my; chawjk@ukm.edu.my
RI Chaw, Jun Kit/ABD-2056-2021; Goh, Kam Meng/AAE-3941-2020; Chaw,
   Jun-Kit/AAN-1738-2021
OI Chaw, Jun Kit/0000-0002-6839-0784; Goh, Kam Meng/0000-0003-0378-7390
CR Adenan MNH, 2020, FORENSIC CHEM, V17, DOI 10.1016/j.forc.2019.100197
   Alpandi RM, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14105870
   Ang KM, 2022, FOOD CONTROL, V137, DOI 10.1016/j.foodcont.2022.108921
   Azmi NA, 2021, PERTANIKA J SCI TECH, V29, P677, DOI 10.47836/pjst.29.1.36
   Barry G., 2021, Prog Eng Appl Technol, V2, P396
   Chai KC, 2016, APPL SOFT COMPUT, V49, P734, DOI 10.1016/j.asoc.2016.08.043
   Chang WL, 2015, EXPERT SYST APPL, V42, P7235, DOI 10.1016/j.eswa.2015.04.036
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chok KC, 2021, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.746656
   Chua LS, 2016, J INTEGR MED-JIM, V14, P415, DOI 10.1016/S2095-4964(16)60282-0
   Chua YG, 2015, J AGR FOOD CHEM, V63, P279, DOI 10.1021/jf503157n
   Chua YG, 2014, RAPID COMMUN MASS SP, V28, P1387, DOI 10.1002/rcm.6914
   Dai YW, 2021, FOOD RES INT, V140, DOI 10.1016/j.foodres.2020.109875
   Doucet MS., 2003, Encyclopedia of Information Systems, P601, DOI [10.1016/B0-12-227240-4/00143-X, DOI 10.1016/B0-12-227240-4/00143-X]
   Gan JE, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC CONTROL AND INTELLIGENT SYSTEMS (I2CACIS), P73, DOI [10.1109/I2CACIS.2019.8825077, 10.1109/i2cacis.2019.8825077]
   Gan SH, 2017, DRY TECHNOL, V35, P4, DOI 10.1080/07373937.2016.1155053
   Gan SH, 2016, DRY TECHNOL, V34, P1330, DOI 10.1080/07373937.2015.1106552
   Guo CT, 2006, ANTIVIR RES, V70, P140, DOI 10.1016/j.antiviral.2006.02.005
   Guo LL, 2018, J SCI FOOD AGR, V98, P3057, DOI 10.1002/jsfa.8805
   Guo LL, 2014, FOOD CONTROL, V44, P220, DOI 10.1016/j.foodcont.2014.04.006
   Hong TK., 2020, J Adv Perform Inf Value, V10, P38, DOI [10.37265/japiv.v10i1.21, DOI 10.37265/JAPIV.V10I1.21]
   Huan XW, 2019, J FOOD DRUG ANAL, V27, P876, DOI 10.1016/j.jfda.2019.06.004
   Huang J, 2020, RELIAB ENG SYST SAFE, V199, DOI 10.1016/j.ress.2020.106885
   Huang XW, 2020, J FOOD MEAS CHARACT, V14, P514, DOI 10.1007/s11694-019-00251-z
   Hudaya R., 2021, In Proc-2nd International Seminar of Science and Applied Technology, ISSAT, V2021, P88, DOI [10.2991/aer.k.211106.015, DOI 10.2991/AER.K.211106.015]
   Ibrahim Ahmad Rizan, 2018, 2018 2nd International Conference on Smart Sensors and Application (ICSSA), P33, DOI 10.1109/ICSSA.2018.8535955
   Ibrahim A, 2018, PHD FORUM '18: PROCEEDINGS OF THE 2018 WORKSHOP ON MOBISYS 2018 PH.D. FORUM, P1, DOI [10.1109/USBEREIT.2018.8384535, 10.1145/3212711.3212712]
   Ibrahim RM, 2021, FOODS, V10, DOI 10.3390/foods10071574
   Idrees MO, 2016, INT J SPELEOL, V45, P289, DOI 10.5038/1827-806X.45.3.1988
   Indra Evta, 2022, IOP Conference Series: Earth and Environmental Science, DOI 10.1088/1755-1315/1083/1/012058
   Indrajaya D, 2022, Khazanah Inform J Ilmu Komput dan Inform, V8, DOI [10.23917/khif.v8i2.16489, DOI 10.23917/KHIF.V8I2.16489]
   Ismail M, 2021, NUTRIENTS, V13, DOI 10.3390/nu13031028
   Ito Y, 2021, ECOSYST HEALTH SUST, V7, DOI 10.1080/20964129.2021.1960200
   Jamalluddin NH, 2019, FOOD CONTROL, V104, P247, DOI 10.1016/j.foodcont.2019.04.042
   Jong CH., 2014, Advances in Intelligent Systems and Computing, V223, P165, DOI [10.1007/978-3-319-00930-8_15, DOI 10.1007/978-3-319-00930-8_15]
   Jong CH, 2013, COMPUT ELECTRON AGR, V96, P90, DOI 10.1016/j.compag.2013.04.015
   Jordon D, 2004, INT DEV PLANN REV, V26, P97, DOI 10.3828/idpr.26.1.6
   Koay MY., 2018, In Proc-10th Int Conf Bioinfo and Biomed Tech, V2018, P25, DOI [10.1145/3232059.3232075, DOI 10.1145/3232059.3232075]
   Lai Weng Kin, 2020, Advances in Natural Computation, Fuzzy Systems and Knowledge Discovery. Advances in Intelligent Systems and Computing (AISC 1074), P472, DOI 10.1007/978-3-030-32456-8_51
   Lai WK, 2021, J Inst Eng Malaysia, V82, DOI [10.54552/v82i1.73, DOI 10.54552/V82I1.73]
   Lalung JBI., 2016, Discrimination between Cave and House-Farmed Edible Bird's Nest Based on Major Mineral Profiles
   Lee TH, 2022, J FOOD COMPOS ANAL, V107, DOI 10.1016/j.jfca.2022.104399
   Lee TH, 2021, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.626233
   Lee TH, 2017, FOOD RES INT, V100, P14, DOI 10.1016/j.foodres.2017.07.036
   Lee Wei Wen, 2021, 2021 IEEE International Conference on Automatic Control & Intelligent Systems (I2CACIS), P140, DOI 10.1109/I2CACIS52118.2021.9495911
   Looi QH, 2016, PJSRR, V2, P32
   Ma FC, 2012, FOOD RES INT, V48, P559, DOI 10.1016/j.foodres.2012.06.001
   Ma XT, 2020, MATER EXPRESS, V10, P1141, DOI 10.1166/mex.2020.1742
   Mahfurdz A, 2015, WORLD J ENG, V12, P407, DOI 10.1260/1708-5284.12.4.407
   Mamduh SM, 2012, CHEM ENGINEER TRANS, V30, P331, DOI 10.3303/CET1230056
   Maulana Hata, 2020, 2020 3rd International Conference on Computer and Informatics Engineering (IC2IE), P372, DOI 10.1109/IC2IE50715.2020.9274679
   McFarlane DA, 2015, INT J SPELEOL, V44, P191, DOI 10.5038/1827-806X.44.2.8
   MEDWAY LORD, 1962, PROC ZOOL SOC LONDON, V138, P305
   Meei Chien Quek, 2015, Information Processing in Agriculture, V2, P1, DOI 10.1016/j.inpa.2014.12.002
   Meng GK, 2017, PROCEDIA COMPUT SCI, V112, P1072, DOI 10.1016/j.procs.2017.08.123
   Nazri NAM., 2022, J Adv Geospatial Sci Technol, V2, P154
   Nematollahi MA., 2017, J Telecommun Electron Comput Eng, V9, P89
   Ng JS, 2022, FOODS, V11, DOI 10.3390/foods11162401
   Noor AS, 2020, J Halal Ind Serv, V3, DOI [10.36877/jhis.a0000168, DOI 10.36877/JHIS.A0000168]
   Norhayati M K Jr, 2010, Malays J Nutr, V16, P389
   Noverta R, 2022, PROC 9 INT GRADUATE, P93
   Popovic D., 2000, SINHA NK, GUPTA MM, P309
   Quek MC, 2018, INT J FOOD PROP, V21, P1680, DOI 10.1080/10942912.2018.1503303
   Rahman MA, 2018, J SUSTAIN SCI MANAG, V13, P127
   Rahman N., 2018, Int J Eng Technol, V7, P56
   Sa'ad FSA, 2015, J TEKNOL, V76, P17
   Seow EK, 2016, LWT-FOOD SCI TECHNOL, V65, P428, DOI 10.1016/j.lwt.2015.08.047
   Septiarini A., 2022, In Proc -IEEE Int Conf on Cybernetics and Computational Intelligence, CyberneticsCom, V2022, P474, DOI [10.1109/CyberneticsCom55287.2022.9865498, DOI 10.1109/CYBERNETICSCOM55287.2022.9865498]
   Sharifuddin J, 2014, J FOOD PROD MARK, V20, P75, DOI 10.1080/10454446.2014.946169
   Shi JY, 2017, FOOD CHEM, V229, P235, DOI 10.1016/j.foodchem.2017.02.075
   Shi JY, 2017, ANAL METHODS-UK, V9, P1297, DOI 10.1039/c6ay03352k
   Shim EKS, 2017, FOOD RES INT, V95, P9, DOI 10.1016/j.foodres.2017.02.018
   Shim EKS, 2016, J FOOD SCI TECH MYS, V53, P3602, DOI 10.1007/s13197-016-2344-3
   Shim EKS, 2020, CHEM-ASIAN J, V15, P2487, DOI 10.1002/asia.202000520
   Shukri NNHM., 2019, Int J Supply Chain Manag, V8, P554
   Shukri NNHM., 2018, Int Food Res J, V25, pS165
   Shukri NNHM, 2019, J FOOD PROD MARK, V25, P849, DOI 10.1080/10454446.2019.1691105
   Sjofjan Osfar, 2022, E3S Web of Conferences, V335, DOI 10.1051/e3sconf/202233500016
   Snell J, 2017, ADV NEUR IN, V30
   Subramaniam Y, 2015, J TEKNOL, V72
   Syahir Fathinul A. S., 2012, Proceedings of the 2012 3rd International Conference on Intelligent Systems, Modelling and Simulation (ISMS 2012), P325, DOI 10.1109/ISMS.2012.75
   Tangjitmanngamkul J., 2019, Eur J Bus Manag, DOI [10.7176/ejbm/11-13-08, DOI 10.7176/EJBM/11-13-08]
   Tay KM, 2015, NEURAL COMPUT APPL, V26, P551, DOI 10.1007/s00521-014-1647-4
   Tong SR, 2021, FRONT NUTR, V8, DOI 10.3389/fnut.2021.658634
   Tristanto D., 2011, P 2011 INT C EL ENG, P1
   Usmanto B., 2022, J Electron Comput Netw Appl Math ISSN, V2799-1156, P54
   van der Spoel E, 2015, ICML DEEP LEARNING W, V7, P956, DOI 10.1017/CBO9781107415324
   Weng WH, 2021, IEEE ACCESS, V9, P16591, DOI 10.1109/ACCESS.2021.3053408
   Wong CF, 2017, FOOD QUAL SAF-OXFORD, V1, P83, DOI 10.1093/fqs/fyx002
   Yaacob FF, 2022, International Journal of Academic Research in Business and Social Sciences, V12, P449, DOI [10.6007/IJARBSS/v12-i1/11643, DOI 10.6007/IJARBSS/V12-I1/11643]
   Yalcin AS, 2022, TECHNOL FORECAST SOC, V174, DOI 10.1016/j.techfore.2021.121193
   Yee CK, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01124-y
   Yeo BH, 2021, FRONT PHARMACOL, V12, DOI 10.3389/fphar.2021.631136
   Yeo YH, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.5.051603
   Yeo YH, 2021, INT J ENG TECHNOL IN, V11, P135, DOI 10.46604/ijeti.2021.6891
   Yong CH, 2022, FOOD CONTROL, V132, DOI 10.1016/j.foodcont.2021.108542
   Zhang MJ, 2022, FOOD CONTROL, V140, DOI 10.1016/j.foodcont.2022.109111
   Zhang SX, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030427
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 99
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 9
PY 2023
DI 10.1007/s11042-023-17490-4
EA NOV 2023
PG 51
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X9MX6
UT WOS:001101620700010
DA 2024-07-18
ER

PT J
AU Elewi, A
   Kahveci, S
   Avaroglu, E
AF Elewi, Abdullah
   Kahveci, Semih
   Avaroglu, Erdinc
TI Image contrast enhancement using a low-discrepancy population
   initialized gray wolf optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Contrast enhancement; Metaheuristic; GWO; Optimization; Swarm
   intelligence; Halton sequence
ID HISTOGRAM EQUALIZATION
AB Image contrast is an important factor in distinguishing objects in the image from their background. Low-contrast images, caused by various factors such as poor lighting, are insufficient for human visual perception and many image processing applications. Therefore, image contrast enhancement (ICE) is a necessary preprocessing step in different image processing applications. The main purpose of ICE is to make image objects more easily distinguishable and to improve the quality of visual information in the image. In this paper, image contrast enhancement is studied as an optimization problem. First, a modified version of the gray wolf optimization (GWO) algorithm, a population-based meta-heuristic that mimics the social leadership and hunting behavior of gray wolves in nature, is adapted to the ICE problem. Second, a novel variant of GWO is proposed using Halton low-discrepancy sequence in the population initialization phase, instead of starting completely randomly. Third, unlike previous studies, an effective metric is used as a fitness function to measure the image quality by focusing on the contrast change without using a reference image. The experimental results on the TID2013 and CSIQ datasets show that the proposed Halton sequence-initialized GWO outperforms other variant metaheuristic algorithms and traditional histogram equalization-based methods, according to all utilized various evaluation metrics.
C1 [Elewi, Abdullah; Kahveci, Semih; Avaroglu, Erdinc] Mersin Univ, Dept Comp Engn, Mersin, Turkiye.
C3 Mersin University
RP Elewi, A (corresponding author), Mersin Univ, Dept Comp Engn, Mersin, Turkiye.
EM elewi@mersin.edu.tr
RI Kahveci, semih/ADJ-7196-2022; Elewi, Abdullah/K-4670-2015
OI Kahveci, semih/0000-0002-1495-6295; Elewi, Abdullah/0000-0001-9774-5292
FU The authors would like to thank Dr. Denise De Pauw and Language Centre
   at University of Leeds for offering language support during the writing
   of this paper.
FX The authors would like to thank Dr. Denise De Pauw and Language Centre
   at University of Leeds for offering language support during the writing
   of this paper.
CR Agarwal M, 2018, PROCEDIA COMPUT SCI, V125, P149, DOI 10.1016/j.procs.2017.12.021
   Chen J, 2018, SWARM EVOL COMPUT, V38, P287, DOI 10.1016/j.swevo.2017.09.002
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1301, DOI 10.1109/TCE.2003.1261233
   Chen SD, 2003, IEEE T CONSUM ELECTR, V49, P1310, DOI 10.1109/TCE.2003.1261234
   Fu X., 2019, arXiv
   Gonzalez R.C., 2018, Digital Image Processing
   HALTON JH, 1964, COMMUN ACM, V7, P701, DOI 10.1145/355588.365104
   Hashemi S, 2010, PATTERN RECOGN LETT, V31, P1816, DOI 10.1016/j.patrec.2009.12.006
   Karaboga D, 2007, J GLOBAL OPTIM, V39, P459, DOI 10.1007/s10898-007-9149-x
   Kim YT, 1997, IEEE T CONSUM ELECTR, V43, P1, DOI 10.1109/30.580378
   Krömer P, 2020, LECT NOTES COMPUT SC, V11968, P370, DOI 10.1007/978-3-030-38629-0_30
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Luque-Chang A, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106607
   Mahmood A, 2019, IEEE ACCESS, V7, P161584, DOI 10.1109/ACCESS.2019.2951468
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mittal N, 2016, APPL COMPUT INTELL S, V2016, DOI 10.1155/2016/7950348
   Mondal SK, 2019, INT C COMM DEV NETW, P207, DOI [10.1007/978-981-15-4932-8_23, DOI 10.1007/978-981-15-4932-8_23]
   Murali K., 2016, J Multidiscip Sci Technol, V7, P77
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Rao BS, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106114
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Santhi K, 2015, OPTIK, V126, P1809, DOI 10.1016/j.ijleo.2015.05.023
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P430, DOI 10.1109/TIP.2005.859378
   Solomon C., 2011, Dans Fundamentals of Digital Image Processing: A Practical Approach with Examples in Matlab vol, V46, P1, DOI DOI 10.1002/9780470689776
   Srinivasan S., 2006, P 9 AS S INF DISPL, P152
   TUBBS JD, 1987, PATTERN RECOGN, V20, P617, DOI 10.1016/0031-3203(87)90031-8
   Vidyasaraswathi HN., 2020, Int J New Innov Eng Technol, V15, P19
   Vinothini J., 2016, Int J Emerg Trends Sci Technol, V3, P4049, DOI [10.18535/ijetst/v3i05.28, DOI 10.18535/IJETST/V3I05.28]
   Wang Y, 1999, IEEE T CONSUM ELECTR, V45, P68, DOI 10.1109/30.754419
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
NR 31
TC 0
Z9 0
U1 3
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 6
PY 2023
DI 10.1007/s11042-023-17366-7
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X6AZ8
UT WOS:001099271500002
DA 2024-07-18
ER

PT J
AU Alphonse, AS
   Mary, NAB
AF Alphonse, A. Sherly
   Mary, N. Ani Brown
TI Classification of anti-oxidant proteins using novel physiochemical and
   conjoint-quad (PCQ) feature composition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Antioxidant proteins; Feature; Classification; Accuracy; SRBM
ID ENSEMBLE CLASSIFIER; STRUCTURAL CLASSES; PREDICTION; DIAGNOSIS
AB The anti-oxidant proteins have a closer relation to disease control. Hence an accurate classification of antioxidant proteins by automated analysis is an essential process for the expansion of drugs for various diseases. Wet-lab experimental approaches are generally expensive and inefficient for the identification of anti-oxidant proteins. Novel methodologies like Physiochemical and Conjoint-Quad (PCQ) feature composition using the physio-chemical features combined with moment-based features is proposed in this work for the accurate classification of anti-oxidant proteins. In this proposed work, four techniques namely, proposed PCQ, k-spaced Amino Acid Pairs (CKSAAP), g-gap, and N-gram (N = 3) were applied to create different hybrid features from the anti-oxidant proteins efficiently. The Pearson Kernel-based Supervised Principal Component Analysis (PKSPCA) is proposed for the dimension reduction of the features and effective classification. To evaluate the proposed technique, ten-fold cross-validation and independent test datasets were utilized. On the testing data, the proposed method attained the best performance when compared with the previous techniques. This proposed method achieves 99% accuracy, sensitivity of 98% and specificity of 91% during the classification of the anti-oxidant proteins.
C1 [Alphonse, A. Sherly] Vellore Inst Technol, Kelambakkam Vandalur Rd, Chennai 600127, Tamil Nadu, India.
   [Mary, N. Ani Brown] Sarah Tucker Coll, MPXR G74, Tirunelveli 627007, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Alphonse, AS (corresponding author), Vellore Inst Technol, Kelambakkam Vandalur Rd, Chennai 600127, Tamil Nadu, India.
EM sherly.a@vit.ac.in; anibrownmarycs@sarahtuckercollege.edu.in
CR Ahmad A, 2022, CHEMOMETR INTELL LAB, V222, DOI 10.1016/j.chemolab.2022.104516
   Ahmed S, 2022, CHEMOMETR INTELL LAB, V228, DOI 10.1016/j.chemolab.2022.104623
   Akmal MA, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0181966
   Alphonse AS, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12040836
   Alphonse AS, 2021, J AMB INTEL HUM COMP, V12, P3447, DOI 10.1007/s12652-020-02517-7
   Alphonse AS, 2020, ANAL BIOCHEM, V606, DOI 10.1016/j.ab.2020.113845
   Alphonse AS, 2019, MULTIMED TOOLS APPL, V78, P23369, DOI 10.1007/s11042-019-7646-9
   Alphonse AS, 2017, EXPERT SYST APPL, V90, P127, DOI 10.1016/j.eswa.2017.08.013
   [Anonymous], 2001, BIOCOMPUTING 2002, DOI DOI 10.1142/97898127996230053
   Ao CY, 2020, GENOMICS, V112, P4666, DOI 10.1016/j.ygeno.2020.08.016
   Bakkouri I, 2023, SIGNAL IMAGE VIDEO P, V17, P1181, DOI 10.1007/s11760-022-02325-w
   Bakkouri I, 2020, MULTIMED TOOLS APPL, V79, P20483, DOI 10.1007/s11042-019-07988-1
   Basini G, 2008, REPROD FERT DEVELOP, V20, P269, DOI 10.1071/RD07147
   Behera M, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10193532
   Brown P. F., 1992, Computational Linguistics, V18, P467
   Butt AH., 2016, A prediction model for membrane proteins using moments based features
   Butt AH, 2019, J THEOR BIOL, V473, P1, DOI 10.1016/j.jtbi.2019.04.019
   Butt AH, 2018, MOL BIOL REP, V45, P2295, DOI 10.1007/s11033-018-4391-5
   Butt AH, 2017, J MEMBRANE BIOL, V250, P55, DOI 10.1007/s00232-016-9937-7
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen K, 2008, J COMPUT CHEM, V29, P1596, DOI 10.1002/jcc.20918
   Chen K, 2007, BMC STRUCT BIOL, V7, DOI 10.1186/1472-6807-7-25
   Cheng L, 2018, BIOINFORMATICS, V34, P1953, DOI 10.1093/bioinformatics/bty002
   Cui FF, 2022, COMPUT STRUCT BIOTEC, V20, P2020, DOI 10.1016/j.csbj.2022.04.029
   Daoui A, 2020, CIRC SYST SIGNAL PR, V39, P4552, DOI 10.1007/s00034-020-01384-z
   Ding H, 2013, CHEMOMETR INTELL LAB, V124, P9, DOI 10.1016/j.chemolab.2013.03.005
   Ehsan A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19491-y
   Feng PM, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/567529
   Feng PM, 2016, INTERDISCIP SCI, V8, P186, DOI 10.1007/s12539-015-0124-9
   Fernández-Blanco E, 2013, J THEOR BIOL, V317, P331, DOI 10.1016/j.jtbi.2012.10.006
   Freitas AA, 2011, BMC GENOMICS, V12, DOI 10.1186/1471-2164-12-27
   Geethu S, 2021, PROTEIN J, V40, P669, DOI 10.1007/s10930-021-10016-7
   Lam LHT, 2020, BIOLOGY-BASEL, V9, DOI 10.3390/biology9100325
   Jemimah S, 2020, BIOINFORMATICS, V36, P1725, DOI 10.1093/bioinformatics/btz829
   Jiang QH, 2010, BMC SYST BIOL, V4, DOI 10.1186/1752-0509-4-S1-S2
   Jisna VA, 2021, PROTEIN J, V40, P522, DOI 10.1007/s10930-021-10003-y
   Khan YD, 2018, ANAL BIOCHEM, V550, P109, DOI 10.1016/j.ab.2018.04.021
   Li WZ, 2006, BIOINFORMATICS, V22, P1658, DOI 10.1093/bioinformatics/btl158
   Li XH, 2020, FRONT BIOENG BIOTECH, V8, DOI 10.3389/fbioe.2020.00858
   Liu ML, 2020, CURR PROTEIN PEPT SC, V21, P1229, DOI 10.2174/1389203721666200117153412
   Lv ZB, 2019, PROTEOMICS, V19, DOI 10.1002/pmic.201900119
   Mary NAB, 2019, MULTIMED TOOLS APPL, V78, P11387, DOI 10.1007/s11042-018-6673-2
   Meng CL, 2019, FRONT BIOENG BIOTECH, V7, DOI 10.3389/fbioe.2019.00224
   NayaknAff PK, 2022, J FOOD SCI TECH MYS, V59, P4253, DOI 10.1007/s13197-022-05488-z
   Pallavi M, 2022, 2022 INT C FUT TECHN, P1
   Radovic M, 2017, BMC BIOINFORMATICS, V18, DOI 10.1186/s12859-016-1423-9
   RAMANA V, 2023, J SURV FISH SCI, V10, P117
   Shen C, 2019, IEEE ACCESS, V7, P13486, DOI 10.1109/ACCESS.2019.2894225
   Shen HB, 2006, BIOINFORMATICS, V22, P1717, DOI 10.1093/bioinformatics/btl170
   Shen Y, 2022, FOOD CONTROL, V131, DOI 10.1016/j.foodcont.2021.108439
   Staudacher V, 2018, REDOX BIOL, V14, P549, DOI 10.1016/j.redox.2017.10.017
   Swamy SR, 2023, COMPUT SYST SCI ENG, V45, P869, DOI 10.32604/csse.2023.029822
   Tan JX, 2019, MATH BIOSCI ENG, V16, P2466, DOI 10.3934/mbe.2019123
   Tang J, 2019, MOL CELL PROTEOMICS, V18, P1683, DOI 10.1074/mcp.RA118.001169
   Tang J, 2020, BRIEF BIOINFORM, V21, P621, DOI 10.1093/bib/bby127
   Usman M, 2021, CURR ISSUES MOL BIOL, V43, P1489, DOI 10.3390/cimb43030105
   Visibelli A, 2022, Life Sci Healthcare, DOI [10.25434/visibelli-anna_phd2022, DOI 10.25434/VISIBELLI-ANNA_PHD2022]
   Wang GH, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0011794
   Williams N, 2006, ACM SIGCOMM COMP COM, V36, P7, DOI 10.1145/1163593.1163596
   Wu J, 2010, PROTEIN J, V29, P62, DOI 10.1007/s10930-009-9222-z
   Xu L, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19061773
   Yigit AA, 2014, WORLD POULTRY SCI J, V70, P563, DOI 10.1017/S0043933914000610
   Zhai YX, 2020, FRONT CELL DEV BIOL, V8, DOI 10.3389/fcell.2020.591487
   Zhang LN, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0163274
   Zhu L, 2009, PROTEIN J, V28, P384, DOI 10.1007/s10930-009-9205-0
   Zhu XJ, 2019, KNOWL-BASED SYST, V163, P787, DOI 10.1016/j.knosys.2018.10.007
   Zou Q, 2016, NEUROCOMPUTING, V173, P346, DOI 10.1016/j.neucom.2014.12.123
NR 67
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17498-w
EA NOV 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500022
DA 2024-07-18
ER

PT J
AU Guleria, V
   Kumar, Y
   Mishra, DC
AF Guleria, Vandana
   Kumar, Yashavant
   Mishra, D. C.
TI Multiple colour image encryption using multiple parameter FrDCT, 3D
   Arnold transform and RSA
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE RSA Cryotosystem; Image encryption; Image decryption; 3D Arnold
   transform and multi-parameter fractional discrete cosine transform
ID DISCRETE COSINE TRANSFORM; FRACTIONAL FOURIER-TRANSFORM; GYRATOR
   TRANSFORM; OPTICAL ENCRYPTION; SECURITY; TRUNCATION; CHAOS
AB We introduce a novel image encryption and decryption algorithm for multiple images incorporating multiple parameter fractional discrete cosine transform (MPFrDCT), 3D Arnold transform and RSA cryptosystem. Before encryption, the images are changed into their indexed formats by removing their color maps. The indexed formats of the images are taken as the red, green and blue channel of an RGB image. Firstly, the RGB image is taken as the input of 3D Arnold transform. The 3D Arnold transform not only dislocates the pixel positions, but also changes the pixel values. Mathematically, the 3D map performs both permutation as well as substitution. The distorted image is now encrypted using RSA cryptosystem which is a public key cryptosystem. The RSA cryptosystem makes the image secure in public domain as the hard problem is the factorization of large primes which is unbreakable. Lastly, the domain of the encrypted image is changed to frequency domain using MPFrDCT. If the secret keys are known to an unauthorized person, the encryption algorithm is still secure as the security of the presented cryptosystem depends upon the secret keys and the arrangements of the secret keys. The proposed image encryption algorithm is storage efficient. The statistical and simulation analysis are conducted to evaluate the robustness of the presented encryption and decryption processes.
C1 [Guleria, Vandana; Kumar, Yashavant] Birla Inst Technol Mesra, Dept Math, Ranchi, India.
   [Mishra, D. C.] Govt PG Coll Jaiharikhal, Dept Math, Janda Laga Sari, Uttrakhand, India.
C3 Birla Institute of Technology Mesra
RP Guleria, V (corresponding author), Birla Inst Technol Mesra, Dept Math, Ranchi, India.
EM vandana.math@gmail.com; kumar.yashavant154@gmail.com;
   deepiitdelhi@gmail.com
CR Abuturab MR, 2013, OPT LASER ENG, V51, P230, DOI 10.1016/j.optlaseng.2012.10.007
   Abuturab MR, 2013, OPT LASER ENG, V51, P317, DOI 10.1016/j.optlaseng.2012.09.008
   Abuturab MR, 2012, OPT LASER ENG, V50, P1383, DOI 10.1016/j.optlaseng.2012.04.011
   Abuturab MR, 2012, APPL OPTICS, V51, P3006, DOI 10.1364/AO.51.003006
   Abuturab MR, 2012, OPT LASER ENG, V50, P772, DOI 10.1016/j.optlaseng.2011.12.006
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Cariolaro G, 2002, IEEE T SIGNAL PROCES, V50, P902, DOI 10.1109/78.992138
   Chen LF, 2008, OPTIK, V119, P286, DOI 10.1016/j.ijleo.2006.11.005
   Chen LF, 2006, OPT LETT, V31, P3438, DOI 10.1364/OL.31.003438
   Hahn J, 2006, OPT EXPRESS, V14, P11103, DOI 10.1364/OE.14.011103
   Hennelly B, 2003, OPT LETT, V28, P269, DOI 10.1364/OL.28.000269
   Joshi AB, 2021, INT J IMAGE GRAPH, V21, DOI 10.1142/S0219467821500066
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Joshi M, 2008, OPT COMMUN, V281, P5713, DOI 10.1016/j.optcom.2008.08.024
   Kumar D, 2020, RESULTS OPT, V1, DOI 10.1016/j.rio.2020.100031
   Kumar M, 2014, OPT LASER ENG, V52, P27, DOI 10.1016/j.optlaseng.2013.07.015
   Li HJ, 2013, OPT LASER ENG, V51, P1327, DOI 10.1016/j.optlaseng.2013.05.011
   Liu H, 2013, OPT LASER TECHNOL, V50, P1, DOI 10.1016/j.optlastec.2013.02.003
   Liu ST, 2001, OPT LETT, V26, P1242, DOI 10.1364/OL.26.001242
   Liu ZJ, 2007, OPT LETT, V32, P2088, DOI 10.1364/OL.32.002088
   Liu ZJ, 2013, OPT LASER ENG, V51, P967, DOI 10.1016/j.optlaseng.2013.02.015
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Liu ZJ, 2009, OPT COMMUN, V282, P518, DOI 10.1016/j.optcom.2008.10.068
   Mishra DC, 2017, J INF SECUR APPL, V37, P65, DOI 10.1016/j.jisa.2017.09.006
   Mishra DC, 2017, FRACTALS, V25, DOI 10.1142/S0218348X17500116
   Prasad A, 2012, OPT COMMUN, V285, P1005, DOI 10.1016/j.optcom.2011.10.019
   Qiu T, 2022, OPT APPL, V52, P669, DOI 10.37190/oa220415
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Shan MG, 2012, OPT COMMUN, V285, P4227, DOI 10.1016/j.optcom.2012.06.023
   Shi XY, 2013, OPT COMMUN, V306, P90, DOI 10.1016/j.optcom.2013.05.041
   Singh N, 2009, OPT LASER ENG, V47, P539, DOI 10.1016/j.optlaseng.2008.10.013
   Situ GH, 2005, OPT LETT, V30, P1306, DOI 10.1364/OL.30.001306
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Wang XG, 2011, OPT COMMUN, V284, P4441, DOI 10.1016/j.optcom.2011.06.025
   Wang XG, 2011, OPT COMMUN, V284, P148, DOI 10.1016/j.optcom.2010.09.034
   Wu JH, 2017, J MOD OPTIC, V64, P334, DOI 10.1080/09500340.2016.1236990
   Wu JH, 2014, OPTIK, V125, P4474, DOI 10.1016/j.ijleo.2014.02.026
   Wu JH, 2013, OPT LASER TECHNOL, V45, P571, DOI 10.1016/j.optlastec.2012.05.030
   Yong-Liang XA, 2011, OPT LASER TECHNOL, V43, P889, DOI 10.1016/j.optlastec.2010.10.003
   Zhang SQ, 1999, MICROW OPT TECHN LET, V21, P318, DOI 10.1002/(SICI)1098-2760(19990605)21:5<318::AID-MOP4>3.0.CO;2-A
   Zhang Y, 2002, OPT COMMUN, V202, P277, DOI 10.1016/S0030-4018(02)01113-6
   Zhang YS, 2013, OPT LASER ENG, V51, P472, DOI 10.1016/j.optlaseng.2012.11.001
   Zhong Z, 2012, OPT COMMUN, V285, P584, DOI 10.1016/j.optcom.2011.11.025
   Zhou NR, 2012, OPT LASER TECHNOL, V44, P2270, DOI 10.1016/j.optlastec.2012.02.027
NR 44
TC 0
Z9 0
U1 14
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 3
PY 2023
DI 10.1007/s11042-023-17166-z
EA NOV 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X4ZJ4
UT WOS:001098545500002
DA 2024-07-18
ER

PT J
AU Albahli, S
   Nawaz, M
AF Albahli, Saleh
   Nawaz, Marriam
TI MedNet: Medical deepfakes detection using an improved deep learning
   approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Medical deepfakes; Deep learning; Lung cancer; EfficientNet-V2; CT-Scan
AB Recently, the massive development in the field of deep learning (DL) and artificial intelligence (AI)-aware tools have forced the requirement of caution when using several types of digital data. Serious security and privacy concerns have risen due to the significant advancements in the creation of the manipulated technique known as deepfakes. One avenue of deepfakes is to add and eliminate tumors from medical images. The inability of the automated systems to detect medical deepfakes can cause serious security and privacy problems resulting in an extensive burden on hospital assets or even loss of human life. To counter such effects a reliable deepfakes detector that can tackle the latest manipulation generation approaches is required. In the presented work, we attempt to solve the problem by introducing a DL method called the MedNet model to detect lung CT-Scan-based deepfakes samples. Descriptively, we have proposed a custom EfficientNetV2-B4 framework with extra added dense layers at the last of the network. To further increase the feature computation ability of the introduced approach, we proposed a spatial-channel attention mechanism to emphasize the altered areas of samples which result in improved classification performance. Extensive experimentation containing a standard dataset called the CT-GAN dataset is performed to show the efficiency of the presented work. We have attained an accuracy score of 85.49% which is showing the effectiveness of the presented work in reliably detecting the real samples of lung CT-Scan from the deepfake images.
C1 [Albahli, Saleh] Qassim Univ, Coll Comp, Dept Informat Technol, Buraydah 51452, Saudi Arabia.
   [Nawaz, Marriam] Univ Engn & Technol Taxila, Dept Software Engn, Taxila 47050, Pakistan.
C3 Qassim University; University of Engineering & Technology Taxila
RP Nawaz, M (corresponding author), Univ Engn & Technol Taxila, Dept Software Engn, Taxila 47050, Pakistan.
EM salbahli@qu.edu.sa; Marriam.nawaz@uettaxila.edu.pk
RI Nawaz, Marriam/JVD-9229-2023
CR Alheeti KMA, 2022, 2022 7TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND MACHINE LEARNING APPLICATIONS (CDMA 2022), P25, DOI 10.1109/CDMA54072.2022.00010
   Asuncion A., 2007, Uci machine learning repository
   Beek C, 2018, McAfee Blogs
   Ezzat D, 2020, arXiv
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jaiswal A, 2021, J BIOMOL STRUCT DYN, V39, P5682, DOI 10.1080/07391102.2020.1788642
   Kadam KD, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/6845326
   Khan RN, 2022, WAVE RANDOM COMPLEX, DOI 10.1080/17455030.2022.2091807
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liao FZ, 2019, IEEE T NEUR NET LEAR, V30, P3484, DOI 10.1109/TNNLS.2019.2892409
   Masood M, 2021, 2021 INT C DIG FUT T, P1
   Masood M, 2021, FRONT COMPUT SCI-CHI, V15, DOI 10.1007/s11704-020-0105-y
   Mirsky Yisroel, 2022, WDC '22: Proceedings of the 1st Workshop on Security Implications of Deepfakes and Cheapfakes, P31, DOI 10.1145/3494109.3527191
   Mirsky Y, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P461
   Mohammed Ahmed A., 2021, IOP Conference Series: Materials Science and Engineering, V1152, DOI 10.1088/1757-899X/1152/1/012025
   Nawaz M., 2023, Multimed. Tools Appl., P1
   Nawaz M, 2023, VISUAL COMPUT, V39, P6323, DOI 10.1007/s00371-022-02732-7
   Nawaz M, 2022, INT J IMAG SYST TECH, V32, P2137, DOI 10.1002/ima.22750
   Nawaz M, 2021, CMC-COMPUT MATER CON, V69, P1927, DOI 10.32604/cmc.2021.018052
   Nawaz M, 2021, J INTELL FUZZY SYST, V40, P10351, DOI 10.3233/JIFS-191700
   Nawaz M, 2021, MULTIMED TOOLS APPL, V80, P28953, DOI 10.1007/s11042-021-11120-7
   Nazir Tahira, 2021, Proceedings of 2021 International Conference on Artificial Intelligence (ICAI), P33, DOI 10.1109/ICAI52203.2021.9445228
   Ngugi LC, 2021, INFORM PROCESS AGR, V8, P27, DOI 10.1016/j.inpa.2020.04.004
   Quinlan JR, 1996, ACM COMPUT SURV, V28, P71, DOI 10.1145/234313.234346
   Rafique R, 2021, 4 INT C COMP INF SCI, P1
   Rigatti Steven J, 2017, J Insur Med, V47, P31, DOI 10.17849/insm-47-01-31-39.1
   Savaridass MP, 2021, IOP Conference Series: Materials Science and Engineering, V1084
   School HM, 2020, Radiation risk from medical imaging
   Sera T., 2021, Transparency in Biology, P167, DOI DOI 10.1007/978-981-15-9627-8_8
   Singh P, 2022, IEEE ACCESS, V10, P8974, DOI 10.1109/ACCESS.2022.3143801
   Solaiyappan S, 2022, MACH LEARN APPL, V8, DOI 10.1016/j.mlwa.2022.100298
   Su C, 2020, Math Problems Eng, V2020
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thakur T., 2018, Int J Comput Appl, V975, P8887
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhu BQ, 2020, PROCEEDINGS OF THE 3RD AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY AIES 2020, P414, DOI 10.1145/3375627.3375849
   Zhu XY, 2022, FORESTS, V13, DOI 10.3390/f13010001
NR 43
TC 1
Z9 1
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17562-5
EA NOV 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900001
DA 2024-07-18
ER

PT J
AU Bearly, EM
   Chitra, R
AF Bearly, E. Mary
   Chitra, R.
TI Automatic drowsiness detection for preventing road accidents via 3dgan
   and three-level attention
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Fatigue detection; Eye detection; Mouth detection; Driver drowsiness;
   Safety; Deep learning; Object detection
ID TRACKING; GAN
AB Driver drowsiness is one of the reasons for large number of road accidents these days. With the advancement in computer vision technologies, smart/intelligent cameras are developed to identify drowsiness in drivers, thereby alerting drivers which in turn reduce accidents when they are in fatigue. Deep learning is a powerful technique for detecting drowsiness in drivers to prevent road accidents. It uses advanced neural networks to analyze data to detect subtle changes in a driver's facial expressions, eye movements, and head position that may indicate drowsiness. Some of the limitations reviewed from the existing works are false alarm and limited applicability. Hence to overcome these issues, this work proposed Dependent Generative Adversarial Network (DGAN) for detecting drowsiness. With the help of eye blinking, eye closure and also yawning indications, the proposed model will detect whether the person is driving the vehicle in drunken drowsy state. Additionally, the proposed method detect whether the driver is wearing glasses or not and also the lighting conditions. This phase also causes a significant increase in eyes and mouth detection percentage in the next stage. This system alerts driver with an alarm when the driver is in sleepy mood. In order to train the proposed network a custom dataset of about 6000 images was compiled and labeled with the objects face, eye open and eye closed. Out of these, around 1000 images were randomly separated and used to test the trained model. The proposed model can used for various background and environmental changes like indoor, outdoor, day and night. Experimental results confirm that the proposed method efficiently detects the driver behavior. The proposed model achieves a high driver drowsiness with RD of 91.3%, RFA of 7.62% and RA of 91.82%.
C1 [Bearly, E. Mary] Noorul Islam Ctr Higher Educ, Kanyakumari 629180, Tamil Nadu, India.
   [Chitra, R.] Karunya Inst Technol & Sci, Coimbatore, India.
C3 Karunya Institute of Technology & Sciences
RP Bearly, EM (corresponding author), Noorul Islam Ctr Higher Educ, Kanyakumari 629180, Tamil Nadu, India.
EM emarybearly@gmail.com; chitrajegan5@gmail.com
CR Adhinata FD, 2021, Eng. Bus. Intell, V7, P22
   Anizy G.J., 2015, Asian Journal Appl. Sci. Papers, V8, P149, DOI [DOI 10.3923/AJAPS.2015.149.157, 10.3923/ajaps.2015.149.157]
   Bagci AM, 2004, INT C PATT RECOG, P818, DOI 10.1109/ICPR.2004.1334654
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu YC, 2020, IEEE T CIRC SYST VID, V30, P4755, DOI 10.1109/TCSVT.2019.2958188
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khan SA, 2018, IEEE ACCESS, V6, P67459, DOI 10.1109/ACCESS.2018.2878601
   Lemkaddem A., 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P9, DOI 10.1109/BHI.2018.8333357
   Liu PK, 2021, AUTOMAT CONSTR, V132, DOI 10.1016/j.autcon.2021.103901
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Manu BN, 2016, IEEE INT CONF INNOV, P78
   Mbouna RO, 2013, IEEE T INTELL TRANSP, V14, P1462, DOI 10.1109/TITS.2013.2262098
   Midanarime T, 2022, Drowsiness Driving Detection, Pnediction and warning detection, V7
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Pauly L, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON RESEARCH IN COMPUTATIONAL INTELLIGENCE AND COMMUNICATION NETWORKS (ICRCICN), P181, DOI 10.1109/ICRCICN.2015.7434232
   Punitha A, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON CIRCUIT, POWER AND COMPUTING TECHNOLOGIES (ICCPCT-2014), P1405, DOI 10.1109/ICCPCT.2014.7055020
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabet M., 2012, 2012 20th Iranian Conference on Electrical Engineering (ICEE 2012), P1247, DOI 10.1109/IranianCEE.2012.6292547
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   SHENSA MJ, 1992, IEEE T SIGNAL PROCES, V40, P2464, DOI 10.1109/78.157290
   Shih TH, 2017, LECT NOTES COMPUT SC, V10118, P146, DOI 10.1007/978-3-319-54526-4_11
   Singh H.K., 2020, Evaluation of Driver Status Assessment System Based on Deep Learning
   Sinopoli B, 2004, IEEE T AUTOMAT CONTR, V49, P1453, DOI 10.1109/TAC.2004.834121
   Tadesse E, 2014, IEEE INT CONF ROBOT, P4003, DOI 10.1109/ICRA.2014.6907440
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tibrewal Madhar D.R.K., 2021, A Deep learning Approach to Detect Driver Drowsiness, V10, P183
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828
   Wu Qing, 2010, 2010 Proceedings of the Third International Symposium on Information Processing (ISIP 2010), P437, DOI 10.1109/ISIP.2010.116
   Huynh XP, 2017, LECT NOTES COMPUT SC, V10118, P134, DOI 10.1007/978-3-319-54526-4_10
   Zafeiriou S, 2013, P HAW INT C SYST SCI, P1
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang Y, 2019, J VIS COMMUN IMAGE R, V59, P501, DOI 10.1016/j.jvcir.2019.02.007
   Zhou P, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2016), VOL 2, P207, DOI 10.18653/v1/p16-2034
NR 42
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 NOV 2
PY 2023
DI 10.1007/s11042-023-17272-y
EA NOV 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X2PW2
UT WOS:001096936900011
DA 2024-07-18
ER

PT J
AU Kallel, IF
   Mahfoudhi, O
   Kammoun, S
AF Kallel, Imen Fourati
   Mahfoudhi, Oussema
   Kammoun, Sonda
TI Deep learning models based on CNN architecture for early keratoconus
   detection using corneal topographic maps
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE CNN architecture; Deep learning; GAN; Hybrid model; Keratoconus;
   SyntEyes; Transfer learning
ID SUPPORT VECTOR MACHINE; STATISTICAL EYE MODEL; NEURAL-NETWORKS;
   CLASSIFICATION; ELEVATION; SYNTEYES
AB With the progressive growth of artificial intelligence technologies, applying deep learning methods for medical imaging have successfully solved various medical imaging problems with high accuracy, efficiency and stability, particularly in the field of ophthalmology. In this vein, there is practically an urgent need to develop new tools by relying on artificial intelligence to early detect keratoconus and to lately prevent its progression as a disease. Two data augmentation methods, known as SyntEyes models and GANs networks, are applied to generate synthetic corneal topographic maps and increase data availability. Accordingly, in this paper, seven different deep learning models, based on CNN architecture, and which allow an efficient classification of corneal topographic and maps, are introduced. Thus, accuracy ranges from 95.31% to 99.74%, recall between 98.71% and 95.74% and lastly precision between 99.10% and 93.42%. The findings show that the notably customised classic CNN model outperforms the two hybrid models named CNN-SVM and CNN-LSTM and the four transfer learning models, known as VGG19, Xception, ResNet 50 and MobileNetV2, not only with respect to accuracy, recall, precision and F1 score, but also computation time and model complexity.
C1 [Kallel, Imen Fourati] Univ Sfax, ESSE Lab, ENET com, Sfax, Tunisia.
   [Mahfoudhi, Oussema] Carthage Univ, Dept Comp Sci, ISTIC, Carthage, Tunisia.
   [Kammoun, Sonda] Sfax Univ, Habib Bourguiba Hosp, Dept Ophthalmol, Sfax, Tunisia.
C3 Universite de Sfax; Universite de Carthage; Universite de Sfax; Hopital
   Habib Bourguiba
RP Kallel, IF (corresponding author), Univ Sfax, ESSE Lab, ENET com, Sfax, Tunisia.
EM imen.fourati@enetcom.usf.tn; oussamamahfoudhi1999@gmail.com;
   kammounsonda@yahoo.fr
FU We owe gratitude to the team of the ophthalmology section in the
   Hospital of Hedi Chaker, Sfax for their continuous support during our
   data collection.
FX We owe gratitude to the team of the ophthalmology section in the
   Hospital of Hedi Chaker, Sfax for their continuous support during our
   data collection.
CR Ahmed SM, 2023, Ain Shams Eng J
   Al-Amri AM, 2018, J OPHTHALMOL, V2018, DOI 10.1155/2018/5983530
   Al-Timemy AH, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13101689
   Al-Timemy AH, 2021, TRANSL VIS SCI TECHN, V10, DOI 10.1167/tvst.10.14.16
   Arbelaez MC, 2012, OPHTHALMOLOGY, V119, P2231, DOI 10.1016/j.ophtha.2012.06.005
   Bjorck J, 2018, ADV NEUR IN, V31
   Cao K, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.24
   Cervantes J, 2020, NEUROCOMPUTING, V408, P189, DOI 10.1016/j.neucom.2019.10.118
   Chandapura R, 2019, J BIOPHOTONICS, V12, DOI 10.1002/jbio.201900126
   Chen X, 2021, BMJ OPEN OPHTHALMOL, V6, DOI 10.1136/bmjophth-2021-000824
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirahara D., 2021, J COMPUT COMMUN, V9, P150, DOI DOI 10.4236/JCC.2021.911010
   Hosmer DW, 2013, WILEY SER PROBAB ST, P1
   Issarti I, 2019, COMPUT BIOL MED, V109, P33, DOI 10.1016/j.compbiomed.2019.04.024
   Kaur Manjot, 2019, 2019 International Conference on Smart Systems and Inventive Technology (ICSSIT). Proceedings, P460, DOI 10.1109/ICSSIT46314.2019.8987837
   Kingma D. P., 2014, arXiv
   Kraus M, 2020, EUR J OPER RES, V281, P628, DOI 10.1016/j.ejor.2019.09.018
   Kuo BI, 2020, TRANSL VIS SCI TECHN, V9, DOI 10.1167/tvst.9.2.53
   Lavric A, 2021, IEEE ACCESS, V9, P84344, DOI 10.1109/ACCESS.2021.3086021
   Lavric A, 2020, IEEE ACCESS, V8, P149113, DOI 10.1109/ACCESS.2020.3016060
   Lavric A, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8162567
   Lo WW, 2019, INT CONF NEW TECHNOL, DOI 10.1109/ntms.2019.8763852
   Mukti IZ, 2019, INT CONF ELECTR ENG, DOI 10.1109/eict48899.2019.9068805
   Mumuni A, 2022, Array
   Nwankpa C, 2018, Arxiv, DOI arXiv:1811.03378
   Rabinowitz YS, 1996, BRIT J OPHTHALMOL, V80, P610, DOI 10.1136/bjo.80.7.610
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Reyes Luis JL, 2021, Artif Intell Ophthalmol, P193
   Rozema JJ, 2017, OPHTHAL PHYSL OPT, V37, P358, DOI 10.1111/opo.12369
   Rozema JJ, 2016, INVEST OPHTH VIS SCI, V57, P683, DOI 10.1167/iovs.15-18067
   Ruby U., 2020, Int. J. Adv. Trends Comput. Sci. Eng., V9, DOI DOI 10.30534/IJATCSE/2020/175942020
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Santhiago MR, 2023, Keratoconus, P191
   Santodomingo-Rubido J, 2022, CONTACT LENS ANTERIO, V45, DOI 10.1016/j.clae.2021.101559
   Setiawan Agung W., 2020, 2020 International Conference on Computer Engineering, Network, and Intelligent Multimedia (CENIM), P97, DOI 10.1109/CENIM51130.2020.9297970
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smadja D, 2013, AM J OPHTHALMOL, V156, P237, DOI 10.1016/j.ajo.2013.03.034
   Smagulova K, 2019, EUR PHYS J-SPEC TOP, V228, P2313, DOI 10.1140/epjst/e2019-900046-x
   Smolek MK, 1997, INVEST OPHTH VIS SCI, V38, P2290
   Song Y, 2023, ACM Comput Surv, V55, P1
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Tadepalli Y, 2021, TRAIT SIGNAL, V38, P1485, DOI 10.18280/ts.380524
   Tanabe T, 2002, OPHTHALMOLOGY, V109, P1298, DOI 10.1016/S0161-6420(02)01030-8
   Twa MD, 2005, OPTOMETRY VISION SCI, V82, P1038, DOI 10.1097/01.opx.0000192350.01045.6f
   WILSON SE, 1993, OPHTHALMOLOGY, V100, P1723
   Yousefi S, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205998
   Zéboulon P, 2020, AM J OPHTHALMOL, V219, P33, DOI 10.1016/j.ajo.2020.06.005
NR 51
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 28
PY 2023
DI 10.1007/s11042-023-17551-8
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W7FP7
UT WOS:001093249700001
DA 2024-07-18
ER

PT J
AU Wu, SB
   Sheng, BY
   Fu, GC
   Zhang, DD
   Jian, YC
AF Wu, Shengbao
   Sheng, Buyun
   Fu, Gaocai
   Zhang, Daode
   Jian, Yuchao
TI Multiscale fire image detection method based on CNN and Transformer
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Deep learning; Fire detection; CNN; Multiscale feature extraction;
   Transformer; Hybrid model; Attention mechanism
ID CONVOLUTIONAL NEURAL-NETWORKS; REAL-TIME FIRE; VIDEO FIRE; COLOR;
   SURVEILLANCE
AB Fire is one of the most harmful hazards that affect daily life. The existing fire detection methods have the problems of large computation, slow detection speed, and low detection accuracy to varying degrees, and do not achieve a better trade-off between model complexity, accuracy, and detection speed. In this paper, a multiscale fire image detection method combining Convolutional Neural Network(CNN) and Transformer is proposed. In the shallow layer of the model, the CNN-based multiscale feature extraction module is used to obtain rich fire image information. In the deep layers of the model, the powerful global learning ability of the Transformer is used to carry out overall perception and macroscopic understanding of images. The experimental results show that the best detection accuracy of the model can reach 94.62%, and the fastest detection speed can reach 158.12FPS, F1 score is stable at around 94%, which is fully capable of real-time and accurate detection of fire. Compared with the existing detection methods, this method has higher detection accuracy under similar model complexity and detection speed. With similar detection accuracy, our method has a faster detection speed. The proposed method achieves a better balance between model complexity, detection speed, and accuracy.
C1 [Wu, Shengbao; Sheng, Buyun; Fu, Gaocai; Jian, Yuchao] Wuhan Univ Technol, Sch Mech & Elect Engn, Wuhan 430070, Peoples R China.
   [Sheng, Buyun; Zhang, Daode] Hubei Univ Technol, Sch Mech Engn, Wuhan 430068, Peoples R China.
C3 Wuhan University of Technology; Hubei University of Technology
RP Fu, GC (corresponding author), Wuhan Univ Technol, Sch Mech & Elect Engn, Wuhan 430070, Peoples R China.
EM fgc1989@whut.edu.cn
OI Fu, Gaocai/0000-0002-2046-1758
FU This research was supported by the Major scientific and technological
   project of Hubei Province, China [grant number 2021AAA007].
   [2021AAA007]; Major scientific and technological project of Hubei
   Province, China
FX This research was supported by the Major scientific and technological
   project of Hubei Province, China [grant number 2021AAA007].
CR Abdusalomov A, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196519
   Cao JM, 2022, IEEE T IMAGE PROCESS, V31, P3726, DOI 10.1109/TIP.2022.3175432
   Çelik T, 2007, INT CONF ACOUST SPEE, P1205
   Celik T, 2010, ETRI J, V32, P881, DOI 10.4218/etrij.10.0109.0695
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Changwoo Ha, 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P526, DOI 10.1109/CISIS.2012.25
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Das H., 2020, Appl. Intell. Decision Making Mach. Learn., P213
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P38643, DOI 10.1007/s11042-022-13068-8
   Gomes P, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58821
   Graham B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12239, DOI 10.1109/ICCV48922.2021.01204
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeon M, 2021, FIRE TECHNOL, V57, P2533, DOI 10.1007/s10694-021-01132-y
   Ko BC, 2011, IEEE T CIRC SYST VID, V21, P1903, DOI 10.1109/TCSVT.2011.2157190
   Ko BC, 2009, FIRE SAFETY J, V44, P322, DOI 10.1016/j.firesaf.2008.07.006
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li SB, 2020, IEEE T IMAGE PROCESS, V29, P8467, DOI 10.1109/TIP.2020.3016431
   Li YM, 2022, ENG APPL ARTIF INTEL, V116, DOI 10.1016/j.engappai.2022.105492
   Mao WT, 2018, FIRE TECHNOL, V54, P531, DOI 10.1007/s10694-017-0695-6
   Marbach G, 2006, FIRE SAFETY J, V41, P285, DOI 10.1016/j.firesaf.2006.02.001
   Muhammad K, 2019, IEEE T IND INFORM, V15, P3113, DOI 10.1109/TII.2019.2897594
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, IEEE ACCESS, V6, P18174, DOI 10.1109/ACCESS.2018.2812835
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   National Fire and Rescue Administration, 2023, About us
   Park M, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12223715
   Piri J, 2022, IEEE ACCESS, V10, P1756, DOI 10.1109/ACCESS.2021.3138403
   Qiu T, 2012, IEEE T INSTRUM MEAS, V61, P1486, DOI 10.1109/TIM.2011.2175833
   Rinsurongkawong S, 2012, 2012 9 INT C EL ENG, P1
   Sharma J, 2017, COMM COM INF SC, V744, P183, DOI 10.1007/978-3-319-65172-9_16
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Wang WH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P548, DOI 10.1109/ICCV48922.2021.00061
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Xu H, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app122312312
   [叶铭亮 Ye Mingliang], 2022, [中南林业科技大学学报, Journal of Central South University of Forestry & Technology], V42, P101
   Yu CY, 2010, FIRE TECHNOL, V46, P651, DOI 10.1007/s10694-009-0110-z
   Zhang DY, 2009, FIRST IITA INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P290, DOI 10.1109/JCAI.2009.79
   Zhang jianxin, 2021, Journal of Zhengzhou University (Engineering Science), V42, P13, DOI 10.13705/j.issn.1671-6833.2021.05.016
NR 42
TC 0
Z9 0
U1 8
U2 22
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 27
PY 2023
DI 10.1007/s11042-023-17482-4
EA OCT 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0GO3
UT WOS:001088502300007
DA 2024-07-18
ER

PT J
AU Bouhlel, F
   Mliki, H
   Hammami, M
AF Bouhlel, Fatma
   Mliki, Hazar
   Hammami, Mohamed
TI MOD-IR: moving objects detection from UAV-captured video sequences based
   on image registration
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Moving objects detection; UAV; Feature extraction and matching; Image
   registration; Max entropy thresholding; Quick-shift segmentation
ID BACKGROUND SUBTRACTION; MEAN SHIFT; TRACKING; CAMERA; SEGMENTATION;
   TARGETS; TREES; RANK
AB The moving objects detection from freely moving camera like the one mounted on Unmanned Aerial Vehicle (UAV) stands as an important and challenging issue. This paper introduced a new MOD-IR method for moving objects detection from UAV-captured video sequences. The proposed method consists of four steps: (1) feature extraction and matching, (2) frame registration, (3) moving objects detection and (4) moving objects detection post-processing. Our method stands out from those of the literature in a number of ways. First, we enhanced the method effectiveness and robustness by handling the constraints related to this field through extracting robust features, on the one hand, and automatically defining the optimum threshold, on the other. Second, we proposed an efficient method able to deal with real-time applications by extracting keypoint features instead of pixel-to-pixel model estimation, and by simulating the search for the matching features among multiple trees. Finally, we involved the quick-shift segmentation in parallel with the three first steps, in order to enhance and accelerate the moving objects detection task. Relying on quantitative and qualitative evaluations of the proposed method on a variety of sequences extracted from several datasets (such as DARPA VIVID-EgTest05, Hopkins 155, UCF Aerial Action, etc.), we assessed the performance of our method compared to the state-of-the-art reference methods. Furthermore, the time cost evaluation has enabled us to emphasize that our MOD-IR method is the optimal choice for real-time applications, owing to its lower computational time requirement compared to the reference methods.
C1 [Bouhlel, Fatma; Hammami, Mohamed] Univ Sfax, MIRACL FSS, Fac Sci Sfax, Rd Sokra Km 3, Sfax 3018, Tunisia.
   [Mliki, Hazar] Univ Sfax, MIRACL Lab, Sfax, Tunisia.
   [Mliki, Hazar] Univ Carthage, Natl Inst Appl Sci & Technol, Tunis, Tunisia.
C3 Multimedia, InfoRmation Systems & Advancing Computing Laboratory
   (MIRACL); Universite de Sfax; Faculty of Sciences Sfax; Multimedia,
   InfoRmation Systems & Advancing Computing Laboratory (MIRACL);
   Universite de Sfax; Universite de Carthage
RP Bouhlel, F (corresponding author), Univ Sfax, MIRACL FSS, Fac Sci Sfax, Rd Sokra Km 3, Sfax 3018, Tunisia.
EM fatma.bouhlel@fss.usf.tn
CR Amri S, 2010, MULTIMED TOOLS APPL, V46, P175, DOI 10.1007/s11042-009-0348-y
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Bouguet, 2001, INTEL CORP, V5, P4, DOI DOI 10.1109/HPDC.2004.1323531
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Cho J, 2018, J SEMICOND TECH SCI, V18, P491, DOI 10.5573/JSTS.2018.18.4.491
   Choi J, 2012, COMPUT VIS IMAGE UND, V116, P179, DOI 10.1016/j.cviu.2011.10.007
   Collins R., 2005, IEEE INT WORKSHOP PE
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cucchiara R., 2006, IEEE INT WORKSH VIS, P334
   Dey S, 2012, LECT NOTES COMPUT SC, V7576, P860, DOI 10.1007/978-3-642-33715-4_62
   Dubrofsky E., 2009, Ph.D. Thesis
   ElTantawy A, 2019, IEEE T CIRC SYST VID, V29, P1672, DOI 10.1109/TCSVT.2018.2843761
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Fulkerson B., 2012, Trends and Topics in Computer Vision, Lecture Notes in Computer Science, V6554, P350
   Galar M, 2012, IEEE T SYST MAN CY C, V42, P463, DOI 10.1109/TSMCC.2011.2161285
   Guillot C., 2010, P BRIT MACH VIS C, P34
   Guo H., 2004, SIGKDD EXPLORATIONS, V6, P30, DOI DOI 10.1145/1007730.1007736
   HARALICK RM, 1989, PATTERN RECOGN, V22, P225, DOI 10.1016/0031-3203(89)90071-X
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hong G, 2007, INT GEOSCI REMOTE SE, P377, DOI 10.1109/IGARSS.2007.4422809
   Huang JJ, 2019, CHIN CONT DECIS CONF, P5272, DOI [10.1109/CCDC.2019.8833206, 10.1109/ccdc.2019.8833206]
   Huang Y, 2021, IEEE T CIRC SYST VID, V31, P2217, DOI 10.1109/TCSVT.2020.3023175
   Jackson BP, 2010, IEEE T IMAGE PROCESS, V19, P795, DOI 10.1109/TIP.2009.2036668
   Kalantar B, 2017, IEEE T GEOSCI REMOTE, V55, P5198, DOI 10.1109/TGRS.2017.2703621
   Kang BM, 2003, PROC CVPR IEEE, P267
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2015, IEEE T GEOSCI REMOTE, V53, P6469, DOI 10.1109/TGRS.2015.2441954
   Márquez-Neila P, 2016, J REAL-TIME IMAGE PR, V11, P141, DOI 10.1007/s11554-012-0314-1
   Minaeian S, 2018, IEEE T INTELL TRANSP, V19, P497, DOI 10.1109/TITS.2017.2782790
   Mittal A, 2000, PROC CVPR IEEE, P160, DOI 10.1109/CVPR.2000.854767
   Mliki H, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107140
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Peng Suo, 2008, 2008 9th International Conference on Signal Processing (ICSP 2008), P1436, DOI 10.1109/ICOSP.2008.4697402
   Pharr M., 2016, Physically Based Rendering: From Theory to Implementation, V3rd ed.
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Reilly V, 2010, LECT NOTES COMPUT SC, V6313, P186
   Robinault L, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P609
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sand P, 2008, INT J COMPUT VISION, V80, P72, DOI 10.1007/s11263-008-0136-6
   Sengar SS, 2020, MULTIMED TOOLS APPL, V79, P5919, DOI 10.1007/s11042-019-08506-z
   Sheikh Y, 2009, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2009.5459334
   Silpa-Anan C, 2008, PROC CVPR IEEE, P2308
   Song K, 2019, IEEE transactions on circuits and systems for video technology
   Spagnolo P, 2006, IMAGE VISION COMPUT, V24, P411, DOI 10.1016/j.imavis.2006.01.001
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Takacs G, 2012, Applications of digital image processing XXXV, V8499
   Tron R, 2007, PROC CVPR IEEE, P41, DOI 10.1109/cvpr.2007.382974
   University of central florida, 2021, ucf aerial action data set
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Vinay A., 2019, Effective Utilization of Whitening for Person Identification
   Walha A, 2015, MULTIMED TOOLS APPL, V74, P6745, DOI 10.1007/s11042-014-1928-z
   Wang B, 2023, REMOTE SENS-BASEL, V15, DOI 10.3390/rs15092230
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P230, DOI 10.1109/TITS.2017.2749964
   Wang Q, 2018, IEEE T INTELL TRANSP, V19, P1457, DOI 10.1109/TITS.2017.2726546
   Wu MJ, 2011, MEAS SCI TECHNOL, V22, DOI 10.1088/0957-0233/22/2/025108
   Wu SD, 2011, IEEE I CONF COMP VIS, P1419, DOI 10.1109/ICCV.2011.6126397
   Wu YY, 2017, IEEE T CIRC SYST VID, V27, P236, DOI 10.1109/TCSVT.2015.2493499
   Xiao JJ, 2010, PROC CVPR IEEE, P679, DOI 10.1109/CVPR.2010.5540151
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Yu Y, 2019, INT J CONTROL AUTOM, V17, P1866, DOI 10.1007/s12555-018-0234-3
   Yuan Y, 2017, IEEE T INTELL TRANSP, V18, P3339, DOI 10.1109/TITS.2017.2686871
   Yun KM, 2017, PATTERN RECOGN LETT, V88, P57, DOI 10.1016/j.patrec.2017.01.017
   Zhang G, 2007, 2007 IEEE 11 INT C C, P1
   Zheng AH, 2019, NEUROCOMPUTING, V328, P113, DOI 10.1016/j.neucom.2018.02.101
   Zheng Y, 2022, IEEE transactions on automation science and engineering
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 74
TC 0
Z9 0
U1 7
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 26
PY 2023
DI 10.1007/s11042-023-16667-1
EA OCT 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2WU9
UT WOS:001090292500011
DA 2024-07-18
ER

PT J
AU Patil, PB
   Ijeri, D
   Kulkarni, SA
   Burkaposh, SS
   Bhuyyar, R
   Gugawad, V
AF Patil, Pushpa B.
   Ijeri, Dakshayani
   Kulkarni, Shashikiran A.
   Burkaposh, Sayed Salman
   Bhuyyar, Rani
   Gugawad, Vijayalaxmi
TI Comparative study of machine learning algorithms for Kannada twitter
   sentimental analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Sentimental analysis; Logistic Regression Classifier; Stochastic
   Gradient Descent Classifier; K Neighbors Classifier; Multinomial Naive
   Bayes Classifier; Gaussian Naive Bayes Classifier
AB Analyzing the client's reviews from various online platform helps to improvise the business to higher levels. These User's opinions can be analyzed using Sentiment Analysis. Sentimental analysis on Indian languages is a tedious work as there is a wide diversity in different languages of the India. Kannada is one of the prominent languages in India as 43 million of Indian population use Kannada as their native language for communication and it holds 27th rank among top 30 languages across the world, as there is very less work carried out on Indian languages, especially in Kannada language, more work is required to process the Kannada language across different domains. The sentimental analysis on the Kannada language has the accuracy about 72% from the previous work. So, in this work, we have made comparative study of various machine learning algorithms for Kannada Twitter sentimental analysis. It is experimented on live Twitter data and found that Multinomial Naive Bayes Classifier has performed better with accuracy of 75%.
C1 [Patil, Pushpa B.; Ijeri, Dakshayani; Kulkarni, Shashikiran A.; Burkaposh, Sayed Salman; Bhuyyar, Rani; Gugawad, Vijayalaxmi] BLDEAs V P Dr P G Halakatti Coll Engn & Technol, Dept Comp Sci & Engn, Vijayapur, Karnataka, India.
RP Ijeri, D (corresponding author), BLDEAs V P Dr P G Halakatti Coll Engn & Technol, Dept Comp Sci & Engn, Vijayapur, Karnataka, India.
EM cs.pushpa@bldeacet.ac.in; cse.ijeri@bldeacet.ac.in;
   shashikirankulkarni@gmail.com; salman.burkaposh@gmail.com;
   ranibhuyyar1999@gmail.com; vijayalaxmigugawad@yahoo.com
OI Ijeri, Dakshayani/0000-0002-3904-628X
FU Authors acknowledges Vision Group of Science and Technology (VGST),
   Govt. of Karnataka (Grant No. KSTePS/VGST-KFIST(L1)/2016-17
   /GRD-570/2017-18/137/345/936) [(L1)/2016-17
   /GRD-570/2017-18/137/345/936]; Vision Group of Science and Technology
   (VGST)
FX Authors acknowledges Vision Group of Science and Technology (VGST),
   Govt. of Karnataka (Grant No. KSTePS/VGST-KFIST(L1)/2016-17
   /GRD-570/2017-18/137/345/936)
CR Ankita S., 2020, Procedia Comput. Sci, V173, P325, DOI [10.1016/j.procs.2020.06.038, DOI 10.1016/J.PROCS.2020.06.038]
   Bera A, 2021, INT J SYST DYN APPL, V10, DOI 10.4018/IJSDA.20211001.oa16
   Bhanu KN., 2021, IOP Conference Series: Materials Science and Engineering
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Hegde Y, 2017, IEEE INT ADV COMPUT, P777, DOI [10.1109/IACC.2017.0160, 10.1109/IACC.2017.151]
   Hegde Y, 2015, IEEE INT ADV COMPUT, P822, DOI 10.1109/IADCC.2015.7154821
   Impana P, 2017, 2017 INT C EL EL COM
   Kannadaguli P, 2021, 2021 6 INT C IM INF, P131, DOI [10.1109/ICIIP53038.2021.9702548, DOI 10.1109/ICIIP53038.2021.9702548]
   Kumar KMA, 2015, PROCEDIA COMPUT SCI, V54, P247, DOI 10.1016/j.procs.2015.06.029
   Madan A, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P784, DOI 10.1109/Confluence51648.2021.9377142
   Mandalam Asrita Venkata, 2021, P 1 WORKSH SPEECH LA, P46
   Naidu R, 2017, 2017 INT C WIR COMM
   Phani S., 2016, P 6 WORKSHOP S SE AS, P93
   Rakshitha K., 2021, Glob. Trans. Proc, V2, P414, DOI DOI 10.1016/J.GLTP.2021.08.039
   Rohini V, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P503, DOI 10.1109/RTEICT.2016.7807872
NR 15
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 24
PY 2023
DI 10.1007/s11042-023-17333-2
EA OCT 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W0VW7
UT WOS:001088903700004
DA 2024-07-18
ER

PT J
AU Liu, C
   Luo, Y
   Xu, YC
   Du, B
AF Liu, Chang
   Luo, Yong
   Xu, Yongchao
   Du, Bo
TI HPFL: hyper-network guided personalized federated learning for
   multi-center tuberculosis chest x-ray diagnosis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Hyper-network; Federated learning; Tuberculosis; Chest x-ray
ID SEGMENTATION; FEATURES
AB Tuberculosis (TB) is one of the widespread infectious disease, and the early diagnosis and treatment can greatly improve the survival rate. Recently, machine learning has been introduced for assisting the diagnosis of TB, and to train a reliable diagnosis model, we need large amounts of data, which are often distributed in multiple medical centers. To protect the data privacy of different centers, we introduce federated learning (FL) in tuberculosis diagnosis. Since the data distributions of TB data vary significantly across different centers, we propose a personalized FL (PFL) method to explore the specific property of each client (i.e., medical center), and reduce its negative impacts from other clients. In particular, the contribution of each layer parameter is quantified by a hyper-network customized by the server for each client. Besides, a parameterization mechanism is introduced to update the hierarchical aggregation weights. To the best of our knowledge, this is the first PFL method for distributed TB diagnosis. Experimental results on several public datasets of chest X-ray images show that the proposed method significantly outperforms the state-of-the-art approaches in terms of both higher accuracy and faster convergence speed.
C1 [Liu, Chang; Luo, Yong; Xu, Yongchao; Du, Bo] Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.
   [Liu, Chang; Luo, Yong; Xu, Yongchao; Du, Bo] Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.
   [Liu, Chang; Luo, Yong; Xu, Yongchao; Du, Bo] Wuhan Univ, Inst Artificial Intelligence, Wuhan 430072, Peoples R China.
   [Liu, Chang; Luo, Yong; Xu, Yongchao; Du, Bo] Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
C3 Wuhan University; Wuhan University; Wuhan University; Wuhan University
RP Du, B (corresponding author), Wuhan Univ, Sch Comp Sci, Wuhan 430072, Peoples R China.; Du, B (corresponding author), Wuhan Univ, Natl Engn Res Ctr Multimedia Software, Wuhan 430072, Peoples R China.; Du, B (corresponding author), Wuhan Univ, Inst Artificial Intelligence, Wuhan 430072, Peoples R China.; Du, B (corresponding author), Wuhan Univ, Hubei Key Lab Multimedia & Network Commun Engn, Wuhan 430072, Peoples R China.
EM computerscience@whu.edu.cn; luoyong@whu.edu.cn; yongchao.xu@whu.edu.cn;
   dubo@whu.edu.cn
RI Xu, Yongchao/F-2080-2019
FU This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 62225113, 62222112, 62176186, and
   62276195). [62225113, 62222112, 62176186, 62276195]; National Natural
   Science Foundation of China
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 62225113, 62222112, 62176186, and
   62276195).
CR [Anonymous], 2022, Global tuberculosisreport2022
   Bae J., 2020, Advances in Neural Systems, V33, P21725
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Candemir S, 2014, IEEE T MED IMAGING, V33, P577, DOI 10.1109/TMI.2013.2290491
   Chauhan A, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112980
   Chen HY, 2022, Arxiv, DOI arXiv:2107.00778
   Collins L, 2021, PR MACH LEARN RES, V139
   De Brabandere B, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fallah A., 2020, Advances in Neural Information Processing Systems, V33, P3557
   Arivazhagan MG, 2019, Arxiv, DOI arXiv:1912.00818
   Ha D, 2016, Arxiv, DOI arXiv:1609.09106
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hwang S, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216198
   Jaeger S, 2014, QUANT IMAG MED SURG, V4, P475, DOI 10.3978/j.issn.2223-4292.2014.11.20
   Jaeger S, 2014, IEEE T MED IMAGING, V33, P233, DOI 10.1109/TMI.2013.2284099
   Kairouz P, 2021, FOUND TRENDS MACH LE, V14, P1, DOI 10.1561/2200000083
   Karargyris A, 2016, INT J COMPUT ASS RAD, V11, P99, DOI 10.1007/s11548-015-1242-x
   Li T, 2021, PR MACH LEARN RES, V139
   Li X, 2020, Arxiv, DOI arXiv:1907.02189
   Li XX, 2021, Arxiv, DOI arXiv:2102.07623
   Li XX, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101765
   Li Y., 2020, PROCEEDING EUROPEAN, P608
   Littwin E., 2020, P INT C NEUR INF PRO, V33, P13226
   Littwin G, 2019, IEEE I CONF COMP VIS, P1824, DOI 10.1109/ICCV.2019.00191
   Liu Y, 2020, PROC CVPR IEEE, P2643, DOI 10.1109/CVPR42600.2020.00272
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lomonaco V, 2020, IEEE COMPUT SOC CONF, P989, DOI 10.1109/CVPRW50498.2020.00131
   Lopes UK, 2017, COMPUT BIOL MED, V89, P135, DOI 10.1016/j.compbiomed.2017.08.001
   Lorraine J, 2018, Arxiv, DOI arXiv:1802.09419
   Ma Xiaosong, 2022, P IEEECVF C COMPUTER, P10092
   MacKay M, 2019, Arxiv, DOI arXiv:1903.03088
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Nirkin Y, 2021, PROC CVPR IEEE, P4060, DOI 10.1109/CVPR46437.2021.00405
   Oh J, 2022, Arxiv, DOI arXiv:2106.06042
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   Qi XM, 2022, LECT NOTES COMPUT SC, V13435, P256, DOI 10.1007/978-3-031-16443-9_25
   Rahman T, 2020, IEEE ACCESS, V8, P191586, DOI 10.1109/ACCESS.2020.3031384
   Rajaraman S, 2020, PEERJ, V8, DOI 10.7717/peerj.8693
   Santosh KC, 2022, J MED SYST, V46, DOI 10.1007/s10916-022-01870-8
   Serrà J, 2018, PR MACH LEARN RES, V80
   Shamsian A, 2021, PR MACH LEARN RES, V139
   Shen Y, 2022, IEEE Trans. on Medical Imaging
   Sitzmann V., 2020, ADV NEURAL INF PROCE, V33, P7462
   Suarez J, 2017, ADV NEUR IN, V30
   WHO, 2012, GLOBAL TUBERCULOSIS REPORT 2012, P1
   Woo S., 2023, arXiv, DOI DOI 10.48550/ARXIV.2301.00808
   Wortsman M., 2020, Advances in Neural Information Processing Systems, V33, P15173
   Zhao Dominic, 2020, Meta-learning via hypernetworks
NR 50
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 23
PY 2023
DI 10.1007/s11042-023-17194-9
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U9NV8
UT WOS:001088011000007
DA 2024-07-18
ER

PT J
AU Yang, FC
   Tasi, PW
AF Yang, Feng-Chao
   Tasi, Po-Wen
TI Measuring the mediating effect of satisfaction and compatibility on the
   relationship between podcast features and users' intention of continuous
   usage and word of mouth
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Podcast; Technology affinity; Multitasking; Social presence; Continuous
   usage intention
ID SOCIAL PRESENCE; ACADEMIC-PERFORMANCE; CORPORATE AFFINITY;
   SELF-EFFICACY; TECHNOLOGY; MULTITASKING; ACCEPTANCE; ONLINE; IMPACT;
   ENJOYMENT
AB Amid the expanding podcast market, a myriad of podcasters and advertisers have ventured into hosting and endorsements. The paramount objective of this research was to ascertain the moderating roles of satisfaction (SAT) and Compatibility (COM) in the relationship between podcast characteristics and the Continued Use Intention (CUI) of users. To assess the ramifications of podcast attributes-technology affinity (TA), perceived playfulness (PP), multitasking (MT), social presence (SP), SAT, and COM-on Word of Mouth Intention (WOMI) and CUI, a questionnaire was disseminated among seasoned podcast users. From an aggregate of 250 returned questionnaires, 227 were adjudged as valid post invalidation scrutiny, yielding a 90% retention quotient. Employing the Structural Equation Modeling (SEM) approach for data analysis, the findings revealed the following: TA positively influenced both SAT and COM; PP favorably influenced SAT; MT cast a positive impact on COM; SP constructively affected both SAT and COM; COM positively influenced SAT; and WOMI constructively impacted CUI. This research propounds that podcast platforms might metamorphose into voice-anchored social platforms by curating compelling content, interweaving interactive constituents such as inducements or contests, and galvanizing listener engagement. We advocate for listeners' indulgence in classical or ambient music during engagements, without requiring excessive focus on the host's content.
C1 [Yang, Feng-Chao; Tasi, Po-Wen] Da Yeh Univ, Dept Informat Management, Changhua 51591, Taiwan.
C3 Da Yeh University
RP Yang, FC (corresponding author), Da Yeh Univ, Dept Informat Management, Changhua 51591, Taiwan.
EM yfc@mail.dyu.edu.tw
RI Yang, Feng-Chao/GPW-6411-2022
OI Yang, Feng-Chao/0000-0001-6291-8958
FU We would like to acknowledge that there are no acknowledgments to be
   made for this research.
FX We would like to acknowledge that there are no acknowledgments to be
   made for this research.
CR Aagaard J, 2019, THEOR PSYCHOL, V29, P87, DOI 10.1177/0959354318815766
   Aldás-Manzano J, 2009, IND MANAGE DATA SYST, V109, P739, DOI 10.1108/02635570910968018
   Aldholay A, 2019, INFORM TECHNOL PEOPL, V33, P106, DOI 10.1108/ITP-02-2018-0095
   Alghamdi A, 2020, COMPUT HUM BEHAV, V102, P214, DOI 10.1016/j.chb.2019.08.018
   [Anonymous], 2022, PwC perspectives from global entertainment & media outlook 2022-2026
   Ashfaq M, 2020, TELEMAT INFORM, V54, DOI 10.1016/j.tele.2020.101473
   Bagozzi RP, 1998, Journal of the academy of marketing science, V16, P76
   Barreda A.A., 2015, Journal of Relationship Marketing, V14, P16, DOI [DOI 10.1080/15332667.2015.1006002, 10.1080/15332667.2015.1006002]
   Belanche D, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12104275
   Benton G, 2020, Arxiv, DOI arXiv:2009.03859
   Berry R, 2020, Podcasting: new aural cultures and digital media
   Besser J, 2010, ONLINE INFORM REV, V34, P395, DOI 10.1108/14684521011054053
   Beuckels E, 2021, J ADVERTISING, V50, P197, DOI 10.1080/00913367.2020.1867263
   Bhattacherjee A, 2001, MIS QUART, V25, P351, DOI 10.2307/3250921
   Biocca F, 2003, PRESENCE-VIRTUAL AUG, V12, P456, DOI 10.1162/105474603322761270
   Buttle F.A., 1998, J. Strateg. Mark., V6, P241, DOI DOI 10.1080/096525498346658
   Chen SC, 2018, COMPUT STAND INTER, V57, P49, DOI 10.1016/j.csi.2017.11.004
   Chen XY, 2021, INTERNET RES, V31, P1405, DOI 10.1108/INTR-09-2019-0388
   Chin WW, 1998, QUANT METH SER, P295
   Choi J, 2011, INT J ELECTRON COMM, V16, P129, DOI 10.2753/JEC1086-4415160105
   Chou SY, 2023, J RADIO AUDIO MEDIA, V30, P643, DOI 10.1080/19376529.2022.2044818
   COHEN J, 1988, APPL PSYCH MEAS, V12, P425, DOI 10.1177/014662168801200410
   DAVIS FD, 1992, J APPL SOC PSYCHOL, V22, P1111, DOI 10.1111/j.1559-1816.1992.tb00945.x
   Dharmowijoyo DBE, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su132011347
   Duarte P, 2018, J RETAIL CONSUM SERV, V44, P161, DOI 10.1016/j.jretconser.2018.06.007
   Eyden S., 2023, JDIH, V4, P1, DOI [10.31355/89, DOI 10.31355/89]
   Farzin M., 2021, ASIAN J EC BANKING, V5, P136, DOI [https://doi.org/10.1108/ajeb-10-2020-0085, DOI 10.1108/AJEB-10-2020-0085]
   Fleming DE, 2010, J PERS SELL SALES M, V30, P167, DOI 10.2753/PSS0885-3134300207
   Fleming DE, 2018, J MARKET THEORY PRAC, V26, P230, DOI 10.1080/10696679.2017.1369127
   FORNELL C, 1981, J MARKETING RES, V18, P39, DOI 10.2307/3151312
   Franke T, 2019, INT J HUM-COMPUT INT, V35, P456, DOI 10.1080/10447318.2018.1456150
   Hair J.F., 1998, MULTIVARIATE DATA AN, V5th, P87
   Hair JF, 2010, Multivariate data analysis
   Hair JF, 2014, EUR BUS REV, V26, P106, DOI 10.1108/EBR-10-2013-0128
   Hazari Sunil, 2017, International Journal of Technology Marketing, V12, P230
   Heilesen SB, 2010, COMPUT EDUC, V55, P1063, DOI 10.1016/j.compedu.2010.05.002
   Henseler J, 2009, ADV INT MARKETING, V20, P277, DOI 10.1108/S1474-7979(2009)0000020014
   Heo J, 2011, ACT ADAPT AGING, V35, P43, DOI 10.1080/01924788.2010.545975
   Höhne JK, 2020, COMPUT HUM BEHAV, V111, DOI 10.1016/j.chb.2020.106417
   Holdack E, 2022, J RETAIL CONSUM SERV, V65, DOI 10.1016/j.jretconser.2020.102259
   Hooper D, 2007, Electronic Journal of Business Research Methods, V6, P53, DOI [DOI 10.21427/D7CF7R, 10.21427/D7CF7R]
   Hu LT, 1999, STRUCT EQU MODELING, V6, P1, DOI 10.1080/10705519909540118
   Huang L, 2023, PSYCHOL RES BEHAV MA, V16, P3001, DOI 10.2147/PRBM.S411337
   Huang RT, 2018, COMPUT HUM BEHAV, V80, P103, DOI 10.1016/j.chb.2017.11.007
   Hulland J, 1999, STRATEGIC MANAGE J, V20, P195, DOI 10.1002/(SICI)1097-0266(199902)20:2<195::AID-SMJ13>3.3.CO;2-Z
   Isaac O, 2019, COMPUT EDUC, V136, P113, DOI 10.1016/j.compedu.2019.02.012
   Joo YJ, 2017, COMPUT HUM BEHAV, V69, P83, DOI 10.1016/j.chb.2016.12.025
   Kang M, 2012, TOUR MANAG PERSPECT, V4, P155, DOI 10.1016/j.tmp.2012.08.007
   Kaur P, 2020, J RETAIL CONSUM SERV, V56, DOI 10.1016/j.jretconser.2020.102091
   Kenyon S, 2007, TRANSPORT RES A-POL, V41, P161, DOI 10.1016/j.tra.2006.02.004
   Kim M, 2022, J RETAIL CONSUM SERV, V64, DOI 10.1016/j.jretconser.2021.102778
   Kline R.B., 2023, Principles and practice of structural equation modeling: Methodology in the social sciences, V5th
   Kock N, 2012, J ASSOC INF SYST, V13, P546, DOI 10.17705/1jais.00302
   Kumar A, 2018, INT J BANK MARK, V36, P1170, DOI 10.1108/IJBM-04-2017-0077
   Lai JY, 2011, ONLINE INFORM REV, V35, P558, DOI 10.1108/14684521111161936
   le Roux DB, 2017, COMPUT HUM BEHAV, V77, P86, DOI 10.1016/j.chb.2017.08.030
   Lee C., 2021, Athens J Mass Media Commun, V7, P107, DOI [10.30958/ajmmc.7-2-2, DOI 10.30958/AJMMC.7-2-2]
   Lee J, 2019, TELEMAT INFORM, V39, P37, DOI 10.1016/j.tele.2018.12.006
   Lee KY, 2021, INTERNET RES, V31, P1899, DOI 10.1108/INTR-06-2020-0327
   Lee MC, 2010, COMPUT EDUC, V54, P506, DOI 10.1016/j.compedu.2009.09.002
   Lin PH, 2019, INT J HUM-COMPUT INT, V35, P1736, DOI 10.1080/10447318.2019.1571784
   Lin SJ, 2013, COMPUT EDUC, V68, P416, DOI 10.1016/j.compedu.2013.06.003
   Lu BZ, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103504
   Lu JN, 2017, J COMPUT INFORM SYST, V57, P1, DOI 10.1080/08874417.2016.1181463
   Lui KFH, 2021, Q J EXP PSYCHOL, V74, P344, DOI 10.1177/1747021820960707
   Lundström M, 2021, INT J SOC RES METHOD, V24, P289, DOI 10.1080/13645579.2020.1778221
   May KE, 2018, INT J EDUC TECHNOL H, V15, DOI 10.1186/s41239-018-0096-z
   McLean G, 2022, PSYCHOL MARKET, V39, P150, DOI 10.1002/mar.21584
   Moghavvemi S, 2017, INT J MANAG EDUC-OXF, V15, P1, DOI 10.1016/j.ijme.2016.11.002
   Moon JW, 2001, INFORM MANAGE-AMSTER, V38, P217, DOI 10.1016/S0378-7206(00)00061-6
   Mouakket S, 2015, COMPUT HUM BEHAV, V53, P102, DOI 10.1016/j.chb.2015.06.045
   Nadeem W, 2020, J RETAIL CONSUM SERV, V55
   Natarajan J, 2022, NURS FORUM, V57, P42, DOI 10.1111/nuf.12649
   Ogara SO, 2014, COMPUT HUM BEHAV, V36, P453, DOI 10.1016/j.chb.2014.03.064
   Ozturk AB, 2017, INT J CONTEMP HOSP M, V29, P2027, DOI [10.1108/ijchm-04-2016-0192, 10.1108/IJCHM-04-2016-0192]
   Ozturk AB, 2016, INT J INFORM MANAGE, V36, P1350, DOI 10.1016/j.ijinfomgt.2016.04.005
   Pereira R, 2021, INFORM MANAGE-AMSTER, V58, DOI 10.1016/j.im.2021.103501
   Perks LG, 2019, J BROADCAST ELECTRON, DOI 10.1080/08838151.2019.1688817
   Qin H, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2021.102680
   Rogers EM, 2003, DIFFUSION INNOVATION
   Mafé CR, 2010, J SERV MANAGE, V21, P69, DOI 10.1108/09564231011025128
   Ruiz-Mafé C, 2006, INTERNET RES, V16, P380, DOI 10.1108/10662240610690016
   Sana F, 2013, COMPUT EDUC, V62, P24, DOI 10.1016/j.compedu.2012.10.003
   Sebetci Ö, 2018, HEALTH POLICY TECHN, V7, P265, DOI 10.1016/j.hlpt.2018.06.001
   Seo EJ, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12041691
   Shin M, 2019, INT J HUM-COMPUT ST, V126, P81, DOI 10.1016/j.ijhcs.2019.02.001
   Song H, 2019, INT J HUM-COMPUT INT, V35, P448, DOI 10.1080/10447318.2018.1455126
   Sun T, 2020, COMPUT HUM BEHAV, V104, DOI 10.1016/j.chb.2019.09.027
   Talwar M, 2021, J RETAIL CONSUM SERV, V63, DOI 10.1016/j.jretconser.2020.102396
   TORNATZKY LG, 1982, IEEE T ENG MANAGE, V29, P28, DOI 10.1109/TEM.1982.6447463
   Tseng FC, 2019, IND MANAGE DATA SYST, V119, P1357, DOI 10.1108/IMDS-09-2018-0415
   Tufan F, 2020, Digital transformation in media & society, P63
   van der Heijden H, 2004, MIS QUART, V28, P695, DOI 10.2307/25148660
   Vartakavi A, 2020, Arxiv, DOI arXiv:2009.10315
   Wang YW, 2020, COMPUT HUM BEHAV, V110, DOI 10.1016/j.chb.2020.106373
   Wei KN, 2016, COMPUT HUM BEHAV, V64, P859, DOI 10.1016/j.chb.2016.08.003
   Wetzels M, 2009, MIS QUART, V33, P177, DOI 10.2307/20650284
   Wiradhany W, 2021, MEDIA PSYCHOL, V24, P276, DOI 10.1080/15213269.2019.1685393
   Wood E, 2012, COMPUT EDUC, V58, P365, DOI 10.1016/j.compedu.2011.08.029
   Xu F, 2019, J ACAD LIBR, V45, DOI 10.1016/j.acalib.2019.102072
   Xu F, 2018, COMPUT HUM BEHAV, V83, P64, DOI 10.1016/j.chb.2018.01.029
   Yang LP, 2021, INT J HUM-COMPUT ST, V145, DOI 10.1016/j.ijhcs.2020.102507
   Yang ZW, 2022, ONLINE INFORM REV, V46, P1225, DOI 10.1108/OIR-01-2021-0015
   Ye S, 2020, J HOSP TOUR MANAG, V42, P119, DOI 10.1016/j.jhtm.2019.11.008
   Yilmaz FGK, 2016, COMPUT EDUC, V95, P163, DOI 10.1016/j.compedu.2016.01.006
   Zhong B, 2013, COMPUT HUM BEHAV, V29, P1742, DOI 10.1016/j.chb.2013.02.016
NR 106
TC 1
Z9 1
U1 11
U2 21
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 18
PY 2023
DI 10.1007/s11042-023-17417-z
EA OCT 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U6VJ6
UT WOS:001086159600017
OA hybrid
DA 2024-07-18
ER

PT J
AU Ma, JY
   Li, XF
   Li, J
   Wan, J
   Liu, T
   Li, GH
AF Ma, Jinyan
   Li, Xuefei
   Li, Jing
   Wan, Jun
   Liu, Tong
   Li, Guohao
TI Quality-aware face alignment using high-resolution spatial dependencies
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Face alignment; Transformer; Semi-supervised learning; Heatmap
   detection; Knowledge distillation
ID NETWORK
AB Although CNN-based face alignment algorithms have got promising results. However, their alignment accuracy are still suffer from faces with severe occlusions and large poses, which mainly because (1) the inability to model long-range dependencies, construct effective face shape constraints and (2) the limitation on the size of the labeled facial datasets. To address the above problems, this study proposed a transformer-based data distillation semi-supervised face alignment algorithm. The transformer-based heatmap detection network introduces the transformer to model more efficient face shape constraint relationships, thus improving algorithm robustness under partial occlusion. Moreover, a quality-aware pseudolabeled sample distillation network is designed to help transformer obtain the CNNs inherent inductive biases by evaluating the quality of pseudolabeled data generated by transformer-based heatmap detection networks. This study also proposed intensive training strategy to use more unlabeled data without the need for manual operation to further improve the performance of transformer thermal map detection networks. Experimental results on the 300W, AFLW, and 300VW datasets demonstrate the superiority of our method over state-of-the-art face alignment methods.
C1 [Ma, Jinyan; Li, Xuefei; Li, Jing; Liu, Tong; Li, Guohao] Wuhan Univ, Sch Comp Sci, Bayi Rd, Wuhan 430072, Hubei, Peoples R China.
   [Wan, Jun] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, South Lake St, Wuhan 430073, Hubei, Peoples R China.
C3 Wuhan University; Zhongnan University of Economics & Law
RP Li, XF; Li, J (corresponding author), Wuhan Univ, Sch Comp Sci, Bayi Rd, Wuhan 430072, Hubei, Peoples R China.
EM Jinyan.Ma@whu.edu.cn; snowfly_li@163.com; leejingcn@whu.edu.cn;
   junwan2014@whu.edu.cn; tong.liu@whu.edu.cn; ghli156@whu.edu.cn
RI wu, jd/IST-2336-2023
FU This research was made benefited from a grant from National Science
   Foundation of China (Grant No. 62002233) and National Natural Science
   Foundation of China (Grant No. 62372335). [62002233]; National Science
   Foundation of China [62372335]; National Natural Science Foundation of
   China
FX This research was made benefited from a grant from National Science
   Foundation of China (Grant No. 62002233) and National Natural Science
   Foundation of China (Grant No. 62372335).
CR Ahuja K., 2023, INT C MACH LEARN, P372
   Browatzki B, 2020, PROC CVPR IEEE, P6109, DOI 10.1109/CVPR42600.2020.00615
   Bulat A, 2018, PROC CVPR IEEE, P109, DOI 10.1109/CVPR.2018.00019
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126
   Dong XY, 2019, IEEE I CONF COMP VIS, P783, DOI 10.1109/ICCV.2019.00087
   Dong XY, 2018, PROC CVPR IEEE, P360, DOI 10.1109/CVPR.2018.00045
   Dong XY, 2018, PROC CVPR IEEE, P379, DOI 10.1109/CVPR.2018.00047
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan Y, 2018, Arxiv, DOI arXiv:1805.03643
   Feng ZH, 2018, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2018.00238
   Guo XJ, 2019, Arxiv, DOI [arXiv:1902.10859, DOI 10.48550/ARXIV.1902.10859]
   Honari S, 2018, PROC CVPR IEEE, P1546, DOI 10.1109/CVPR.2018.00167
   Jiang K, 2022, IEEE T NEUR NET LEAR, V33, P378, DOI 10.1109/TNNLS.2020.3027849
   Jiang K, 2020, IEEE T MULTIMEDIA, V22, P2734, DOI 10.1109/TMM.2019.2960586
   Jin HB, 2021, INT J COMPUT VISION, V129, P3174, DOI 10.1007/s11263-021-01521-4
   Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347
   Khan MH, 2017, IEEE I CONF COMP VIS, P3811, DOI 10.1109/ICCV.2017.409
   Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254
   Kumar A, 2020, IEEE COMPUT SOC CONF, P3275, DOI 10.1109/CVPRW50498.2020.00387
   Kumar A, 2018, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2018.00052
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Kumar Vikas, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12535), P756, DOI 10.1007/978-3-030-66415-2_53
   Liang-Chieh Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P695, DOI 10.1007/978-3-030-58545-7_40
   Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393
   Ma JY, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108297
   Martin Koestinger P.M.R. Paul, 2011, PROC 1 IEEE INT WORK
   Meng RY, 2020, Arxiv, DOI arXiv:2012.06711
   Miao X, 2018, PROC CVPR IEEE, P5040, DOI 10.1109/CVPR.2018.00529
   Qian SJ, 2019, IEEE I CONF COMP VIS, P10152, DOI 10.1109/ICCV.2019.01025
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Robinson JP, 2019, IEEE I CONF COMP VIS, P10102, DOI 10.1109/ICCV.2019.01020
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Si JX, 2021, COMPUT VIS IMAGE UND, V203, DOI 10.1016/j.cviu.2020.103125
   Sun K, 2019, Arxiv, DOI arXiv:1904.04514
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wan J, 2021, NEURAL NETWORKS, V136, P233, DOI 10.1016/j.neunet.2020.11.001
   Wan J, 2021, IEEE T IMAGE PROCESS, V30, P121, DOI 10.1109/TIP.2020.3032029
   Wang XY, 2019, IEEE I CONF COMP VIS, P6970, DOI 10.1109/ICCV.2019.00707
   Wolf T, 2020, Arxiv, DOI arXiv:1910.03771
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Wu WY, 2018, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2018.00227
   Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4
   Xiao Y, 2023, INFORM FUSION, V96, P297, DOI 10.1016/j.inffus.2023.03.021
   Yang S, 2020, arXiv:2012.14214, V2
   Yue XQ, 2021, NEUROCOMPUTING, V437, P261, DOI 10.1016/j.neucom.2021.01.027
   Zhu J-Y, 2017, P IEEE INT C COMPUTE
   Zhu ML, 2019, PROC CVPR IEEE, P3481, DOI 10.1109/CVPR.2019.00360
NR 50
TC 0
Z9 0
U1 4
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17295-5
EA OCT 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400015
DA 2024-07-18
ER

PT J
AU Paul, H
   Ghatak, S
   Chakraborty, S
   Pandey, SK
   Dey, L
   Show, D
   Maity, S
AF Paul, Hrithik
   Ghatak, Sayani
   Chakraborty, Sanjay
   Pandey, Saroj Kumar
   Dey, Lopamudra
   Show, Debashis
   Maity, Saikat
TI A study and comparison of deep learning based potato leaf disease
   detection and classification techniques using explainable AI
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Potato leaf disease detection; Classification; CNN-SVM; DenseNet-169;
   Ensemble Deep Learning; Explainable AI
ID PREDICTION
AB The goal of artificial intelligence (AI), a field with a solid scientific foundation, is to enable machines to simulate human intelligence and problem-solving abilities. AI focuses on the study, development, and application of complex algorithms and computational models, with a particular focus on deep learning techniques. The application of artificial intelligence to potato leaf disease detection can reduce the restrictions brought on by the artificial selection of spotted disease features and improve the efficiency and speedup. It has also turned into a research hotspot in the agricultural sector. This work consists of four types of potato leaf diseases, such as early-blight disease, septoria disease, late-blight disease, and black-leg disease. It is a challenging task to identify and classify such diseases from the healthy images. As a result, this work uses a set of benchmark deep learning models to identify and categorize these four disease types in potato leaves. Furthermore, compared to existing models, our recommended models provide better accuracy and have visible results. In comparison to other cutting-edge models, the results of the proposed deep ensemble algorithm (CNN, CNN-SVM, and DNN) offers the best accuracy of 99.98%. All the sample images (healthy and unhealthy) are collected from different farms of the West Bengal state and prepare the experimented dataset. The working model has an additional benefit in terms of running time complexity (O(Ei)(1ik) and 17.86 s) and statistical comparison. Finally, LIME and SHAP are used to evaluate the findings, create more trust, and improve performance by providing explanations for predictions.
C1 [Paul, Hrithik; Ghatak, Sayani; Show, Debashis] JIS Univ, Dept Comp Sci & Engn, Kolkata, India.
   [Chakraborty, Sanjay] Techno Int New Town, Dept Comp Sci & Engn, Kolkata, India.
   [Pandey, Saroj Kumar] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
   [Dey, Lopamudra] Meghnad Saha Inst Technol, Dept Comp Sci & Engn, Kolkata, India.
   [Maity, Saikat] Sister Nivedita Univ, Dept Comp Sci & Engn, Kolkata, India.
C3 GLA University
RP Chakraborty, S (corresponding author), Techno Int New Town, Dept Comp Sci & Engn, Kolkata, India.
EM schakraborty770@gmail.com
OI Chakraborty, Sanjay/0000-0002-0023-7038
CR Adedoja A., 2019, 2019 INT C ADV BIG D, P1, DOI 10.1109/ICABCD.2019.8851029
   Agarwal M, 2020, PROCEDIA COMPUT SCI, V167, P293, DOI 10.1016/j.procs.2020.03.225
   Ahmed K, 2019, 2019 INT C SUSTAINAB, P1
   Al-Otaibi MB, 2017, FRONT ARTIF INTEL AP, V296, P469, DOI 10.3233/978-1-61499-785-6-469
   Annabel L. Sherly Puspha, 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0538, DOI 10.1109/ICCSP.2019.8698004
   [Anonymous], 2015, International Journal of Computer Applications, DOI 10.5120/20071-1993
   Aqel D, 2022, CLUSTER COMPUT, V25, P2007, DOI 10.1007/s10586-021-03397-y
   Aversano L, 2020, PROCEEDINGS OF 2020 IEEE INTERNATIONAL WORKSHOP ON METROLOGY FOR AGRICULTURE AND FORESTRY (METROAGRIFOR), P129, DOI [10.1109/metroagrifor50201.2020.9277626, 10.1109/MetroAgriFor50201.2020.9277626]
   Badah N, 2023, LECT NOTE NETW SYST, V475, P773, DOI 10.1007/978-981-19-2840-6_58
   Bezemer D, 2008, WORLD DEV, V36, P1342, DOI 10.1016/j.worlddev.2007.07.001
   Bhandari M, 2023, J IMAGING, V9, DOI 10.3390/jimaging9020053
   Bhowmik S, 2020, 2020 ADVANCED COMMUNICATION TECHNOLOGIES AND SIGNAL PROCESSING (IEEE ACTS), DOI 10.1109/ACTS49415.2020.9350413
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Chaki J, 2019, OPTIK, V181, P639, DOI 10.1016/j.ijleo.2018.12.107
   Chakraborty S., 2022, Data Classification and Incremental Clustering in Data Mining and Machine Learning, DOI [10.1007/978-3-030-93088-2, DOI 10.1007/978-3-030-93088-2]
   Chao XF, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11104614
   Chaudhari DJ, 2023, OPT MEMORY NEURAL, V32, P39, DOI 10.3103/S1060992X2301006X
   Chhachhar A.R. B., 2014, J. Basic Appl. Res. Int, V4, P281
   Dey L, 2020, BIOMED J, V43, P438, DOI 10.1016/j.bj.2020.08.003
   Dhingra G, 2018, MULTIMED TOOLS APPL, V77, P19951, DOI 10.1007/s11042-017-5445-8
   Duan KB, 2005, LECT NOTES COMPUT SC, V3541, P278
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hussain N, 2022, CMC-COMPUT MATER CON, V70, P3281, DOI 10.32604/cmc.2022.019036
   Iqbal MA, 2020, 2020 INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS SIGNAL PROCESSING AND NETWORKING (WISPNET), P43, DOI [10.1109/wispnet48689.2020.9198563, 10.1109/WiSPNET48689.2020.9198563]
   Javidan SM, 2023, SMART AGR TECHNOL, V3, DOI 10.1016/j.atech.2022.100081
   Kamal MS, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3171613
   Khan MA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020593
   Kinger S., 2022, 2022 INT C TRENDS QU, P1, DOI [10.1109/TQCEBT54229.2022.10041630, DOI 10.1109/TQCEBT54229.2022.10041630]
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Li KZ, 2020, INFORMATION, V11, DOI 10.3390/info11020095
   Li LL, 2021, IEEE ACCESS, V9, P56683, DOI 10.1109/ACCESS.2021.3069646
   Maria SK, 2022, SMART INNOV SYST TEC, V235, P359, DOI 10.1007/978-981-16-2877-1_33
   McMichael P, 2007, Socialist register, V43
   Mehedi MHK, 2022, 2022 IEEE 13 ANN INF
   Mithu MA, 2022, SMART INNOV SYST TEC, V235, P347, DOI 10.1007/978-981-16-2877-1_32
   Mohanty SP, 2016, FRONT PLANT SCI, V7, DOI 10.3389/fpls.2016.01419
   Moid MA, 2021, 2021 5 INT C I SMAC, P1
   Mokhtar U, 2015, 2015 11TH INTERNATIONAL COMPUTER ENGINEERING CONFERENCE (ICENCO), P246, DOI 10.1109/ICENCO.2015.7416356
   Mukhopadhyay S, 2021, MULTIMED TOOLS APPL, V80, P753, DOI 10.1007/s11042-020-09567-1
   Ni JJ, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3244819
   Ni JJ, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3146923
   Nishad Md Ashiqur Rahaman, 2022, Procedia Computer Science, P220, DOI 10.1016/j.procs.2022.11.006
   Padol PB, 2016, 2016 CONFERENCE ON ADVANCES IN SIGNAL PROCESSING (CASP), P175
   Pan SQ, 2022, J INTEGR AGR, V21, P1094, DOI 10.1016/S2095-3119(21)63707-3
   Pinkus A., 1999, Acta Numerica, V8, P143, DOI 10.1017/S0962492900002919
   Praveen P, 2023, Intell Syst Design, V494, P239
   Rashid J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10172064
   Rathod ArtiN., 2013, International Journal of Advanced Research in Computer Science and Software Engineering, V3
   Rocha MMM, 2023, MULTIMED TOOLS APPL, V82, P19299, DOI 10.1007/s11042-022-14206-y
   Saleem MH, 2019, PLANTS-BASEL, V8, DOI 10.3390/plants8110468
   Sankaran S, 2010, COMPUT ELECTRON AGR, V72, P1, DOI 10.1016/j.compag.2010.02.007
   Sardogan M, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P382, DOI 10.1109/UBMK.2018.8566635
   Saxena DK, 2022, LECT NOTES ELECTR EN, V771, P77, DOI 10.1007/978-981-16-2818-4_8
   Shaha Manali, 2018, 2018 Second International Conference on Electronics, Communication and Aerospace Technology (ICECA), P656, DOI 10.1109/ICECA.2018.8474802
   Sharma M, 2022, ARCH PHYTOPATH PLANT, V55, P259, DOI 10.1080/03235408.2021.2015866
   Singh S, 2022, CMC-COMPUT MATER CON, V71, P1849, DOI 10.32604/cmc.2022.021875
   Singh S, 2022, INT J IMAGE GRAPH, V22, DOI 10.1142/S021946782140009X
   Tharwat A, 2016, Advances in Intelligent Systems and Computing, V407, DOI [10.1007/978-3, DOI 10.1007/978-3]
   Yu HL, 2022, MULTIMED TOOLS APPL, V81, P7759, DOI 10.1007/s11042-022-11915-2
   Zhang LJ, 2022, APPL SOFT COMPUT, V123, DOI 10.1016/j.asoc.2022.108969
NR 60
TC 1
Z9 1
U1 7
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17235-3
EA OCT 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400016
DA 2024-07-18
ER

PT J
AU Sharma, GK
   Kumar, S
   Ranga, V
   Murmu, MK
AF Sharma, Gourav Kumar
   Kumar, Santosh
   Ranga, Virender
   Murmu, Mahendra Kumar
TI Artificial intelligence in cerebral stroke images classification and
   segmentation: A comprehensive study
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Brain stroke classification; Cerebral stroke segmentation; Artificial
   intelligence; Stroke lesion; Machine learning; Ischemic stroke;
   Hemorrhagic stroke; Deep learning
ID ISCHEMIC-STROKE; BRAIN; LESION; CT
AB A brain stroke, commonly called as a cerebral vascular accident (CVA) is one of the deadliest diseases across the globe and may lead to various physical impairments or even death. Therefore, timely detection, diagnosis, and treatment of said medical emergency are urgent requirements to minimize life loss, which is not affordable in any sense. Nowadays, with the advancements in Artificial Intelligence, Machine Learning, and Deep Learning, these techniques are popularly used in the domain of medical image analysis in general, and brain stroke imaging in particular, to automate image analysis more accurately and less human error-prone. The aim of this state-of-the-art study is to explore the latest computer-aided diagnosis (CAD) techniques to detect, classify, and segment cerebral strokes. Available methods or techniques, and tools used for analysis have been presented and compared with their attained results. In this study, available open-access datasets in the domain of brain stroke analysis have been explored and presented. Moreover, the research also includes the major challenges and provides researchers with applicable future directions.
C1 [Sharma, Gourav Kumar; Kumar, Santosh; Murmu, Mahendra Kumar] Natl Inst Technol Kurukshetra, Kurukshetra, India.
   [Ranga, Virender] Delhi Technol Univ, Delhi, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra; Delhi Technological University
RP Sharma, GK (corresponding author), Natl Inst Technol Kurukshetra, Kurukshetra, India.
EM gourav03vatsa@gmail.com
RI Ranga, Virender/Q-2447-2015
OI Ranga, Virender/0000-0002-2046-8642
CR Acharya UR, 2019, COGN SYST RES, V58, P134, DOI 10.1016/j.cogsys.2019.05.005
   ADNI|Alzheimer's Disease Neuroimaging Initiative, about us
   Altuve M, 2022, PHYS MEDICA, V99, P113, DOI 10.1016/j.ejmp.2022.05.015
   Alzubi J. A., 2019, Indian J. Public Health Res. Dev, V10, P267, DOI [10.5958/0976-5506.2019.00298.5, DOI 10.5958/0976-5506.2019.00298.5]
   Alzubi O, 2018, INT ARAB J INF TECHN, V15, P76
   Alzubi OA, 2020, NEURAL COMPUT APPL, V32, P16091, DOI 10.1007/s00521-020-04761-6
   Anbumozhi S, 2020, INT J IMAG SYST TECH, V30, P196, DOI 10.1002/ima.22380
   Anupama CSS, 2020, PERS UBIQUIT COMPUT, DOI 10.1007/s00779-020-01492-2
   Bao QQ, 2022, IEEE J BIOMED HEALTH, V26, P1628, DOI 10.1109/JBHI.2021.3113460
   Bontempi D, 2020, MED IMAGE ANAL, V62, DOI 10.1016/j.media.2020.101688
   books.google, The Central Nervous System: Structure and Function-Per Brodal-Google Books
   Calhoun V, 2018, DIALOGUES CLIN NEURO, V20, P87
   Casillo SM, 2020, WORLD NEUROSURG, V134, P353, DOI 10.1016/j.wneu.2019.10.155
   Cetinoglu YK, 2021, EUR J RADIOL, V145, DOI 10.1016/j.ejrad.2021.110050
   Chen M, 2021, IEEE T BIG DATA, V7, P750, DOI 10.1109/TBDATA.2017.2717439
   Chen TH, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101986
   Chen YT, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040807
   de Bruijne M, 2016, MED IMAGE ANAL, V33, P94, DOI 10.1016/j.media.2016.06.032
   Deepa B, 2022, IEEE ACCESS, V10, P3848, DOI 10.1109/ACCESS.2021.3100549
   Deepa B, 2019, MULTIDIM SYST SIGN P, V30, P2081, DOI 10.1007/s11045-019-00642-x
   Demeestere J, 2020, STROKE, V51, P1017, DOI 10.1161/STROKEAHA.119.028337
   Dick S., 2019, Harv Data Sci Rev, V1, DOI [DOI 10.1162/99608F92.92FE150C, 10.1162/99608f92.92fe150c]
   Din MS, 2022, MED ENG PHYS, V105, DOI 10.1016/j.medengphy.2022.103819
   Dogan S, 2022, BIOCYBERN BIOMED ENG, V42, P815, DOI 10.1016/j.bbe.2022.06.004
   Dourado CMJM Jr, 2019, COMPUT NETW, V152, P25, DOI 10.1016/j.comnet.2019.01.019
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   fcon_1000, Anatomical Tracings of Lesions After Stroke (ATLAS).
   Gautam A, 2023, MULTIMED TOOLS APPL, V82, P15927, DOI 10.1007/s11042-021-11342-9
   Gautam A, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102178
   Gautam A, 2020, PATTERN ANAL APPL, V23, P797, DOI 10.1007/s10044-019-00838-8
   Gautam A, 2019, MULTIMED TOOLS APPL, V78, P6559, DOI 10.1007/s11042-018-6418-2
   Herzog L, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101790
   Ho KC, 2019, IEEE T MED IMAGING, V38, P1666, DOI 10.1109/TMI.2019.2901445
   Inamdar MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21248507
   ISLES, Ischemic Stroke Lesion Segmentation Challenge 2022
   itksnap, ITK-SNAP Home
   Karimi D, 2020, IEEE T MED IMAGING, V39, P499, DOI 10.1109/TMI.2019.2930068
   Karthik R, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105728
   Karthik R, 2018, IMAGING SCI J, V66, P1, DOI 10.1080/13682199.2017.1370879
   Karthik R, 2017, MEASUREMENT, V100, P223, DOI 10.1016/j.measurement.2017.01.001
   King M, 2019, NAT NEUROSCI, V22, P1371, DOI 10.1038/s41593-019-0436-x
   Li L, 2021, IEEE J BIOMED HEALTH, V25, P1646, DOI 10.1109/JBHI.2020.3028243
   Libbrecht MW, 2015, NAT REV GENET, V16, P321, DOI 10.1038/nrg3920
   Liu LL, 2020, NEURAL COMPUT APPL, V32, P6545, DOI 10.1007/s00521-019-04096-x
   Macellari F, 2014, STROKE, V45, P903, DOI 10.1161/STROKEAHA.113.003701
   Meijs M, 2020, MED IMAGE ANAL, V66, DOI 10.1016/j.media.2020.101810
   Movassagh AA, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02623-6
   Mutasa S, 2021, CLIN IMAG, V80, P72, DOI 10.1016/j.clinimag.2021.06.033
   Naser M.Z., 2021, Architecture, Structures and Construction, P1, DOI DOI 10.1007/S44150-021-00015-8
   Nazari-Farsani S, 2020, J NEUROSCI METH, V333, DOI 10.1016/j.jneumeth.2019.108575
   nbia, Brain Structure And Function | Brain Injury | British Columbia
   Neethi AS, 2022, BIOMED SIGNAL PROCES, V76, DOI 10.1016/j.bspc.2022.103720
   Nishio M, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105711
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   oasis-brains, OASIS Brains-Open Access Series of Imaging Studies
   OpenNeuro, About us
   Patel A, 2019, IEEE ACCESS, V7, P92355, DOI 10.1109/ACCESS.2019.2927792
   PhysioNet, About us
   Shamir RR, 2019, Arxiv, DOI [arXiv:1906.11031, DOI 10.48550/ARXIV.1906.11031]
   Rebouças PP, 2017, COMPUT METH PROG BIO, V148, P27, DOI 10.1016/j.cmpb.2017.06.011
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Schober P, 2021, ANESTH ANALG, V132, P365, DOI 10.1213/ANE.0000000000005247
   Sclocco R, 2018, NEUROIMAGE, V168, P412, DOI 10.1016/j.neuroimage.2017.02.052
   Shahid N, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212356
   Shin H, 2022, BIOCYBERN BIOMED ENG, V42, P285, DOI 10.1016/j.bbe.2022.01.002
   Sivakumar P, 2017, INT J IMAG SYST TECH, V27, P265, DOI 10.1002/ima.22231
   Subudhi A, 2020, BIOCYBERN BIOMED ENG, V40, P277, DOI 10.1016/j.bbe.2019.04.004
   Subudhi A, 2018, COMPUT BIOL MED, V103, P116, DOI 10.1016/j.compbiomed.2018.10.016
   Tasci B, 2022, BIOMED SIGNAL PROCES, V78, DOI 10.1016/j.bspc.2022.103948
   Thayumanavan M, 2021, CONCURRENT ENG-RES A, V29, P266, DOI 10.1177/1063293X211010542
   Tomasetti L, 2022, IEEE J BIOMED HEALTH, V26, P660, DOI 10.1109/JBHI.2021.3097591
   Tsao CW, 2022, CIRCULATION, V145, pE153, DOI 10.1161/CIR.0000000000001052
   v7labs, BraTS-V7 Open Datasets
   Vasconcelos FFX, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103585
   Vilela P, 2017, EUR J RADIOL, V96, P162, DOI 10.1016/j.ejrad.2017.08.014
   Wang SQ, 2022, NEURAL COMPUT APPL, V34, P8657, DOI 10.1007/s00521-021-06816-8
   Wickramasinghe I, 2021, SOFT COMPUT, V25, P2277, DOI 10.1007/s00500-020-05297-6
   World Health Organization, 2014, The top 10 causes of death
   Xu YZ, 2021, IEEE SENS J, V21, P24941, DOI 10.1109/JSEN.2020.3032897
   Yalçin S, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105941
   Yeghiazaryan V, 2018, J MED IMAGING, V5, DOI 10.1117/1.JMI.5.1.015006
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Zhang L, 2021, IET IMAGE PROCESS, V15, P2818, DOI 10.1049/ipr2.12267
   Zhang RZ, 2018, IEEE T MED IMAGING, V37, P2149, DOI 10.1109/TMI.2018.2821244
NR 84
TC 0
Z9 0
U1 3
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 16
PY 2023
DI 10.1007/s11042-023-17324-3
EA OCT 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EY6P9
UT WOS:001142539400006
DA 2024-07-18
ER

PT J
AU Hassan, S
   Mujtaba, G
   Rajput, A
   Fatima, N
AF Hassan, Saif
   Mujtaba, Ghulam
   Rajput, Asif
   Fatima, Noureen
TI Multi-object tracking: a systematic literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Multi-Object tracking; Computer vision; Deep learning; Multi-tracking;
   Re-identification augmentation
ID OBJECT TRACKING; VEHICLE REIDENTIFICATION; NEURAL-NETWORK; ONLINE;
   ASSOCIATION; ATTENTION; CAMERAS; VISION; MODEL
AB The field of computer vision is revolutionized with the advancement of deep learning and the availability of high computational power. In addition, in the field of computer vision, object detection, and tracking have gained much interest. Several authors are proposing new approaches to detect and track multiple objects from a given video frame and publishing their novel approaches in well-reputed academic journals and proceedings. However, a comprehensive systematic literature review is needed to summarize and critically appraise the existing primary works on multi-object tracking approaches. Therefore, to address this, we aim to produce a systematic literature review on multi-object tracking approaches published from 2019 to 2021. In addition, in this paper, we have systematically reviewed different datasets, multi object-tracking approaches, and performances of existing approaches. Further, we have also presented the critical appraisal of existing primary studies on the subject matter. Finally, we have also provided seven future research directions for future researchers who are interested in further contributing to the field of multi-object tracking. We believe that this work will be beneficial for novice as well as expert researchers who are further willing to contribute to the field of multi-object tracking.
C1 [Hassan, Saif; Mujtaba, Ghulam; Rajput, Asif; Fatima, Noureen] Sukkur IBA Univ, Ctr Excellence Robot Artificial Intelligence & Blo, Dept Comp Sci, Sukkur, Pakistan.
C3 Sukkur IBA University
RP Hassan, S (corresponding author), Sukkur IBA Univ, Ctr Excellence Robot Artificial Intelligence & Blo, Dept Comp Sci, Sukkur, Pakistan.
EM saif.hassan@iba-suk.edu.pk; mujtaba@iba-suk.edu.pk;
   asifali@iba-suk.edu.pk; noureen.mscss19@iba-suk.edu.pk
RI Hassan, saif m./AAO-6969-2020; Mujtaba, Ghulam/AAJ-9326-2020
OI Hassan, saif m./0000-0003-4655-8045; Mujtaba,
   Ghulam/0000-0001-9244-5346; Hassan, Saif/0000-0001-9040-3177
CR Aggarwal A.K., 2022, Int J Biol Biomed, V7
   Aghaei M, 2021, IEEE WINT CONF APPL, P2784, DOI 10.1109/WACV48630.2021.00283
   Alippi C, 2018, 2018 17TH ACM/IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING IN SENSOR NETWORKS (IPSN), P212, DOI 10.1109/IPSN.2018.00049
   Bae SH, 2020, IEEE ACCESS, V8, P90324, DOI 10.1109/ACCESS.2020.2994000
   Barquero German, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P495, DOI 10.1109/TBIOM.2021.3099568
   Bartol K, 2020, arXiv
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Butt Asad A., 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P163, DOI 10.1007/978-3-642-37431-9_13
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   Chen JY, 2021, IEEE ACCESS, V9, P2294, DOI 10.1109/ACCESS.2020.3046763
   Chen L, 2019, IEEE SIGNAL PROC LET, V26, P1613, DOI 10.1109/LSP.2019.2940922
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen Y, 2021, IEEE ACCESS, V9, P103184, DOI 10.1109/ACCESS.2021.3087168
   Chohan M., 2020, Image, V11
   Chohan M., 2020, Int. J. Recent Technol. Eng, V9, P909
   Choi J, 2016, PROC CVPR IEEE, P4321, DOI 10.1109/CVPR.2016.468
   Cowton J, 2019, IEEE ACCESS, V7, P108049, DOI 10.1109/ACCESS.2019.2933060
   Cui ZJ, 2020, IEEE ACCESS, V8, P154800, DOI 10.1109/ACCESS.2020.3017179
   Dendorfer P., 2020, arXiv
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Erhan D, 2014, PROC CVPR IEEE, P2155, DOI 10.1109/CVPR.2014.276
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Feng J, 2021, ISPRS J PHOTOGRAMM, V177, P116, DOI 10.1016/j.isprsjprs.2021.05.005
   Fiaz M, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3309665
   Gao S, 2021, IEEE T CIRC SYST VID, V31, P4305, DOI 10.1109/TCSVT.2021.3049397
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han G, 2019, IEEE ACCESS, V7, P123934, DOI 10.1109/ACCESS.2019.2937998
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hsieh MR, 2017, IEEE I CONF COMP VIS, P4165, DOI 10.1109/ICCV.2017.446
   Hu C., 2003, Journal of Global Positioning Systems, V2, P42, DOI DOI 10.5081/JGPS.2.1.42
   Huang K., 2023, P IEEECVF C COMPUTER, P3162
   Jain Neeraj Kumar, 2019, Soft Computing: Theories and Applications. Proceedings of SoCTA 2017. Advances in Intelligent Systems and Computing (AISC 742), P569, DOI 10.1007/978-981-13-0589-4_53
   Javed O, 2002, LECT NOTES COMPUT SC, V2353, P343
   Jiang MX, 2019, IEEE ACCESS, V7, P32400, DOI 10.1109/ACCESS.2019.2901300
   Jinlong Peng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P145, DOI 10.1007/978-3-030-58548-8_9
   Jocher G., 2020, YOLOv5
   Joshi K. A., 2012, INT J SOFT COMPUT EN, V2, P44
   Kalake L, 2021, IEEE ACCESS, V9, P32650, DOI 10.1109/ACCESS.2021.3060821
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kaputa DS, 2021, IEEE ACCESS, V9, P82497, DOI 10.1109/ACCESS.2021.3080136
   Katper SH, 2020, INT J ADV COMPUT SC, V11, P178
   Ke B, 2019, NEURAL PROCESS LETT, V50, P283, DOI 10.1007/s11063-019-10046-4
   Khan S, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/5763837
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kim J.H., 2023, ICASSP 2023 2023 IEE, P1
   Krizhevsky A, 2012, ADV NEURAL INF PROC, V25
   Le N, 2016, LECT NOTES COMPUT SC, V9914, P43, DOI 10.1007/978-3-319-48881-3_4
   Leal-Taix‚ L, 2015, Arxiv, DOI arXiv:1504.01942
   Lee J, 2021, IEEE ACCESS, V9, P114535, DOI 10.1109/ACCESS.2021.3105118
   Lee J, 2020, IEEE ACCESS, V8, P182828, DOI 10.1109/ACCESS.2020.3028770
   Lee Y, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196358
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XC, 2018, IEEE T MULTIMEDIA, V20, P645, DOI 10.1109/TMM.2017.2751966
   Lixuan Du, 2020, Journal of Physics: Conference Series, V1544, DOI 10.1088/1742-6596/1544/1/012033
   Luo WH, 2021, ARTIF INTELL-AMST, V293, DOI 10.1016/j.artint.2020.103448
   Ma C, 2018, 2018 IEEE INT C MULT, P1
   Medsker Larry R., 2001, INT SER COMPUTAT INT, V5, P64
   Mhalla A, 2019, IMAGE VISION COMPUT, V88, P120, DOI 10.1016/j.imavis.2019.03.002
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Moher D, 2011, EPIDEMIOLOGY, V22, P128, DOI 10.1097/EDE.0b013e3181fe7825
   Mousavi H, 2015, IEEE IMAGE PROC, P2354, DOI 10.1109/ICIP.2015.7351223
   Murtaza G, 2020, ARTIF INTELL REV, V53, P1655, DOI 10.1007/s10462-019-09716-5
   Ndonhong V, 2019, Wellbore schematics to structured data using artificial intelligence tools, V04
   Nodehi H, 2022, IEEE T CIRC SYST VID, V32, P147, DOI 10.1109/TCSVT.2021.3059250
   Noor S, 2021, IEEE ACCESS, V9, P106550, DOI 10.1109/ACCESS.2021.3101054
   Olatunji JR, 2020, COMPUT ELECTRON AGR, V177, DOI 10.1016/j.compag.2020.105699
   Pal SK, 2021, APPL INTELL, V51, P6400, DOI 10.1007/s10489-021-02293-7
   Pang B, 2020, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR42600.2020.00634
   Park Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10192406
   Porikli F, 2012, STUD COMPUT INTELL, V409, P3
   Possegger H, 2013, PROC CVPR IEEE, P2395, DOI 10.1109/CVPR.2013.310
   Qureshi F, 2022, MULTIMED TOOLS APPL, V81, P18223, DOI 10.1007/s11042-022-12097-7
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren WH, 2021, IEEE T IMAGE PROCESS, V30, P1439, DOI 10.1109/TIP.2020.3044219
   Samal K, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207677
   Shao S, 2018, Arxiv, DOI [arXiv:1805.00123, DOI 10.48550/ARXIV.1805.00123]
   Shen GJ, 2019, IEEE ACCESS, V7, P42718, DOI 10.1109/ACCESS.2019.2892469
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh J, 2013, J PHARMACOL PHARMACO, V4, P76, DOI 10.4103/0976-500X.107697
   Son J, 2017, PROC CVPR IEEE, P3786, DOI 10.1109/CVPR.2017.403
   Song SJ, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11073061
   Srivastava S, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-021-00434-w
   Sun SJ, 2021, IEEE T PATTERN ANAL, V43, P104, DOI 10.1109/TPAMI.2019.2929520
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tian YC, 2019, IEEE T PATTERN ANAL, V41, P2146, DOI 10.1109/TPAMI.2018.2849374
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Wan XY, 2020, Arxiv, DOI arXiv:2007.06344
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang QR, 2019, IEEE T MULTIMEDIA, V21, P930, DOI 10.1109/TMM.2018.2869277
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xia Yu, 2021, Personal and Ubiquitous Computing, V25, P979, DOI 10.1007/s00779-019-01278-1
   Xiang J, 2021, IEEE T CIRC SYST VID, V31, P275, DOI 10.1109/TCSVT.2020.2975842
   Xiang J, 2019, IEEE ACCESS, V7, P27923, DOI 10.1109/ACCESS.2019.2901520
   Xiong ZX, 2021, IEEE T INTELL TRANSP, V22, P7619, DOI 10.1109/TITS.2020.3006047
   Xu N, 2018, Arxiv, DOI arXiv:1809.03327
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang J., 2021, Applied Intelligence
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yoon K, 2020, IEEE ACCESS, V8, P38060, DOI 10.1109/ACCESS.2020.2975912
   Zamir AR, 2012, LECT NOTES COMPUT SC, V7573, P343, DOI 10.1007/978-3-642-33709-3_25
   Zeng YJ, 2020, IEEE ACCESS, V8, P47863, DOI 10.1109/ACCESS.2020.2978539
   Zhang HT, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P899, DOI 10.1145/3343031.3350933
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P6694, DOI 10.1109/TIP.2020.2993073
   Zhang YF, 2021, INT J COMPUT VISION, V129, P3069, DOI 10.1007/s11263-021-01513-4
   Zhou H, 2019, IEEE T CIRC SYST VID, V29, P1011, DOI 10.1109/TCSVT.2018.2825679
   Zhu PF, 2022, IEEE T PATTERN ANAL, V44, P7380, DOI 10.1109/TPAMI.2021.3119563
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 138
TC 1
Z9 1
U1 37
U2 60
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 13
PY 2023
DI 10.1007/s11042-023-17297-3
EA OCT 2023
PG 54
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U7JA3
UT WOS:001086519900006
DA 2024-07-18
ER

PT J
AU Ghose, P
   Ghose, A
   Sadhukhan, D
   Pal, S
   Mitra, M
AF Ghose, Priyanka
   Ghose, Arpan
   Sadhukhan, Deboleena
   Pal, Saurabh
   Mitra, Madhuchanda
TI Improved polyp detection from colonoscopy images using finetuned YOLO-v5
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Colonoscopy image; Image processing; Data augmentation; Deep learning;
   Object detection; YOLO-v5
AB Object detection plays an important role to accelerate the medical diagnosis and automatic polyp detection from colonoscopy images is one of the prominent examples. Visual examination is an error prone and time-consuming process to determine the shape, size, and location of polyps in colonoscopy images. Deep learning models are extensively accepted in the field of object detection. YOLO-v5 is an object detection model which is powered by deep learning technique. In this study we suggest a finetuned YOLO-v5 model for polyp detection from colonoscopy images. Effective data augmentation is also done to improvise the performance of the model. To quantify the efficiency of our solution against other works, two aspects have been fundamentally considered - qualitative performance and practical reliability, which have been achieved successfully. A detailed comparison study has been shared to justify the performance of our proposed method against other deep learning techniques - R-CNN, Faster RCNN and YOLO-v4. Our proposed solution deliberated high value of performance metrics which are comparatively better than other solutions.
C1 [Ghose, Priyanka] GCETTS Govt Coll Engn & Text Technol, Serampore, India.
   [Ghose, Arpan] Capgemini Technol Serv India Ltd, Kolkata, India.
   [Sadhukhan, Deboleena] Inst Langevin Paris, Paris, France.
   [Pal, Saurabh; Mitra, Madhuchanda] Univ Calcutta, Fac Council Postgrad Studies Engn & Technol, Kolkata, India.
C3 University of Calcutta
RP Sadhukhan, D (corresponding author), Inst Langevin Paris, Paris, France.
EM deboleena.rainbow@gmail.com
CR Agrawal P, 2014, LECT NOTES COMPUT SC, V8695, P329, DOI 10.1007/978-3-319-10584-0_22
   Akshatha KR, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071151
   Angermann Q, 2017, LECT NOTES COMPUT SC, V10550, P29, DOI 10.1007/978-3-319-67543-5_3
   Bardhi O, 2017, IEEE INT SYMP SIGNAL, P445, DOI 10.1109/ISSPIT.2017.8388684
   Bernal J., 2018, P 32 CARS C
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cao CT, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0250632
   Cepni S, 2020, BALT J MOD COMPUT, V8, P347, DOI 10.22364/bjmc.2020.8.2.10
   Chen BL, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103019
   Chou YC, 2023, MULTIMED TOOLS APPL, V82, P16817, DOI 10.1007/s11042-022-13995-6
   García-Aguilar I, 2022, EXPERT SYST, V39, DOI 10.1111/exsy.12930
   Ghose P., 2021, Advances in medical physics and healthcare engineering, DOI [10.1007/978-981-33-6915-3_23, DOI 10.1007/978-981-33-6915-3_23]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   glenn-jocher, 2021, Ultralytics: Github
   Godkhindi Akshay M., 2017, 2017 International Conference on Energy, Communication, Data Analytics and Soft Computing (ICECDS), P1722, DOI 10.1109/ICECDS.2017.8389744
   Hasan MM, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12250-2
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   Ieamsaard Jirarat, 2021, Proceedings of 2021 9th International Electrical Engineering Congress (iEECON), P428, DOI 10.1109/iEECON51072.2021.9440346
   Krenzer A, 2023, J IMAGING, V9, DOI 10.3390/jimaging9020026
   Hong LTT, 2020, IEEE RIVF INT CONF, P12, DOI 10.1109/rivf48685.2020.9140793
   Lee JY., 2020, Sci Rep, V10, P180
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Ma YT, 2021, LECT NOTES COMPUT SC, V12905, P387, DOI 10.1007/978-3-030-87240-3_37
   Magalhaes SA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103569
   Mo X, 2018, Arxiv, DOI arXiv:1809.01263
   Mohammed A, 2018, BRIT MACH VIS C BMVC, DOI [10.48550/arXiv.1806.01907, DOI 10.48550/ARXIV.1806.01907]
   Nadimi ES, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106531
   Nogueira-Rodriguez A, 2021, Deep neural networks approaches for detecting and classifying colorectal polyps
   Nogueira-Rodríguez A, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040898
   Nogueira-Rodríguez A, 2022, NEURAL COMPUT APPL, V34, P10375, DOI 10.1007/s00521-021-06496-4
   Pacal I, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105031
   Pacal I, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104519
   Qadir HA, 2019, INT SYM MED INFORM, P181, DOI 10.1109/ismict.2019.8743694
   Qian ZQ, 2021, IEEE SENS J, V21, P11374, DOI 10.1109/JSEN.2020.3036005
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sánchez-Peralta LF, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10238501
   Sornapudi S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9122404
   Stoffel EM, 2020, GASTROENTEROLOGY, V158, P341, DOI 10.1053/j.gastro.2019.07.055
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, DOI 10.48550/ARXIV.1409.4842]
   Tas M, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106959
   Thomaz VD, 2021, ARTIF INTELL MED, V111, DOI 10.1016/j.artmed.2020.101988
   Wan JJ, 2021, DIAGNOSTICS, V11, DOI 10.3390/diagnostics11122264
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Yang XY, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038011
   Younas F, 2023, MULTIMED TOOLS APPL, V82, P18925, DOI 10.1007/s11042-022-14177-0
   Zhang X, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0214133
   Zhou DF, 2019, INT CONF 3D VISION, P85, DOI 10.1109/3DV.2019.00019
NR 49
TC 2
Z9 2
U1 13
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 12
PY 2023
DI 10.1007/s11042-023-17138-3
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GU6C6
UT WOS:001155215300002
DA 2024-07-18
ER

PT J
AU Tsai, MC
AF Tsai, Ming-Chi
TI A homogenous forecast model based on the hybrid imputation method for
   forecasting national patent application numbers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Patent applications; Economic indicators; Forecast model; Imputation
   Method
ID NETWORKS
AB Technological innovation is the key solution to promoting economic growth and improving quality of living. The number of patent applications in highly developed countries has become one of the standards for measuring national research and development. Therefore, this study reviews the literature to obtain 17 economic indicators that affect the number of patent applications in highly developed countries and collects data from the World Bank database. The collected data have many missing values. Hence, this study proposes a homogeneous model based on a hybrid imputation method for forecasting national patent applications. Specifically, this study uses k-means and self-organized maps to cluster the imputed dataset and applies an ensemble extra tree to forecast the number of patent applications of each cluster. The proposed hybrid imputation uses Google searching to obtain the variable value and then replaces the missing values of each country. If the Google searching provides no result for the country's attribute value, then apply the neighboring year data of the country to impute the missing values. For verification, this study uses listwise and pairwise methods to compare forecast performance with the proposed hybrid imputation method, and apply random forest, extra tree, Gaussian processes regression, radial basis function network, convolutional neural network, and long short-term memory to compare with the forecast performance of the proposed homogeneous model. The results show that the proposed homogeneous model with hybrid imputation have a better forecast performance in terms of the root mean square error, relative absolute error, and mean absolute error.
C1 [Tsai, Ming-Chi] I Shou Univ, Dept Business Adm, Kaohsiung 84001, Taiwan.
C3 I Shou University
RP Tsai, MC (corresponding author), I Shou Univ, Dept Business Adm, Kaohsiung 84001, Taiwan.
EM mct@isu.edu.tw
OI Tsai, Ming-Chi/0000-0002-0560-7819
FU The authors appreciate Dr. Ching-Hsue Cheng and Dr. Hsien-Hsiu Chen for
   their valuable insights and suggestions.
FX The authors appreciate Dr. Ching-Hsue Cheng and Dr. Hsien-Hsiu Chen for
   their valuable insights and suggestions.
CR Adams K, 1997, J POLICY MODEL, V19, P491, DOI 10.1016/S0161-8938(96)00060-9
   Akhmat G, 2014, J INFORMETR, V8, P349, DOI 10.1016/j.joi.2014.01.007
   Amiri M, 2016, NEUROCOMPUTING, V205, P152, DOI 10.1016/j.neucom.2016.04.015
   Amrehn M, 2018, arXiv, DOI [10.48550/arXiv.1812.08102, DOI 10.48550/ARXIV.1812.08102]
   [Anonymous], 2006, The Economist
   Benny V, 2020, Gedrag Organisatie Rev
   Berge TJ, 2011, AM ECON J-MACROECON, V3, P246, DOI 10.1257/mac.3.2.246
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Broomhead D. S., 1988, Complex Systems, V2, P321
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Changsheng Zhu, 2019, Informatics in Medicine Unlocked, V17, P19, DOI 10.1016/j.imu.2019.100179
   Evan T, 2018, PRAGUE ECON PAP, V27, P73, DOI 10.18267/j.pep.644
   Fischer T, 2018, EUR J OPER RES, V270, P654, DOI 10.1016/j.ejor.2017.11.054
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Ginarte JC, 1997, RES POLICY, V26, P283, DOI 10.1016/S0048-7333(97)00022-X
   Hair JF, 2010, Multivariate data analysis
   Harhoff D, 1999, REV ECON STAT, V81, P511, DOI 10.1162/003465399558265
   HDI, 2021, Human Development Index
   Hingley P, 2017, TECHNOL FORECAST SOC, V116, P76, DOI 10.1016/j.techfore.2016.11.003
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Irshad K, 2023, J BUILD ENG, V65, DOI 10.1016/j.jobe.2022.105729
   Jiang HX, 2023, J INFORMETR, V17, DOI 10.1016/j.joi.2023.101402
   Jovic S, 2019, PHYSICA A, V520, P93, DOI 10.1016/j.physa.2019.01.009
   Jung WG, 2011, IEICE T INF SYST, VE94D, P2219, DOI 10.1587/transinf.E94.D.2219
   Karabell Z., 2014, LEADING INDICATORS S
   Kim T, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0212320
   Kohonen T., 1989, Self-Organization and Associative Memory, V8, DOI DOI 10.1007/978-3-642-88163-3
   Lee CW, 2022, AXIOMS, V11, DOI 10.3390/axioms11060253
   Liu FY, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/3680419
   Manni U.H., 2012, Journal of Business Economics, V1, P37
   OECD, 2004, Patents and innovation: trends and policy
   PCT, 2021, Patent Cooperation Treaty Yearly Review 2021
   Raghupathi V., 2017, J. Innov. Entrep, V6, P4, DOI DOI 10.1186/S13731-017-0065-0
   Rasmussen CE, 2002, ADV NEUR IN, V14, P881
   ROMER PM, 1986, J POLIT ECON, V94, P1002, DOI 10.1086/261420
   Ryder AB, 2011, J IMMIGR MINOR HEALT, V13, P1099, DOI 10.1007/s10903-010-9415-8
   Sajana T., 2017, J Adv Res Dyn Control Syst, V9, P349
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Sinaga KP, 2020, IEEE ACCESS, V8, P80716, DOI 10.1109/ACCESS.2020.2988796
   WIPO, 2019, The world intellectual property organization (WIPO) in the 2019 Facts and Figures report
   World Bank Data, About us
   Xiao XQ, 2022, APPL MATH NONLIN SCI, DOI 10.2478/amns.2022.2.0058
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Ye YC, 2022, CHAOS SOLITON FRACT, V160, DOI 10.1016/j.chaos.2022.112234
   Yoon J, 2021, COMPUT ECON, V57, P247, DOI 10.1007/s10614-020-10054-w
   Zerouaoui H, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103226
   Zgurovsky M., 2020, Probl Perspect Manag, V18, P441, DOI [10.21511/ppm.18(2).2020.36, DOI 10.21511/PPM.18(2).2020.36]
   Zhao J, 2017, INFORM FUSION, V38, P43, DOI 10.1016/j.inffus.2017.02.007
NR 49
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 11
PY 2023
DI 10.1007/s11042-023-17125-8
EA OCT 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U3QO4
UT WOS:001083978800005
DA 2024-07-18
ER

PT J
AU Göker, H
AF Goker, Hanife
TI Multi-channel EEG-based classification of consumer preferences using
   multitaper spectral analysis and deep learning model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Neuromarketing; Deep learning; Multitaper; Signal processing; Consumer
   preferences; EEG
ID BIDIRECTIONAL LSTM
AB Neuromarketing relies on brain-computer interface technology to understand consumer preferences for products and services. Marketers spend approximately 400 billion dollars each year on advertising and promotion in traditional marketing. Traditional marketing approaches cannot fully explain or capture consumers' real-time decision-making. On the other hand, neuromarketing promises to get around these limitations. In this study, we presented a multi-channel electroencephalography (EEG)-based deep learning approach to classify consumers' preferences. The EEG signals were recorded from 25 subjects using 14 channels. The channels were categorized according to the frontal, parietal, temporal, and occipital brain regions. The multitaper spectral analysis approach was then used to extract the feature vectors. Using the extracted feature vectors, the performances of bidirectional long-short-term memory (Bidirectional-LSTM) deep learning, support vector machine (SVM), and k-nearest neighbors (k-NN) machine learning algorithms were compared. The performance of the algorithms was analyzed using frontal, central, parietal, temporal, and occipital brain regions and all channels. Bidirectional-LSTM deep learning algorithm attained the highest accuracy among the other experiments. According to the placement of the channels in the brain regions, the highest accuracy value was 96.83% using Bidirectional-LSTM deep learning algorithm and this was achieved by using electrodes in the frontal region. The performance results analysis was found to be 0.99 recall, 0.95 precision, 0.94 specificity, and 0.97 f1-measure. As a result, this study offers proof of deep learning algorithms' effectiveness in neuromarketing applications.
C1 [Goker, Hanife] Gazi Univ, Hlth Serv Vocat Coll, TR-06830 Ankara, Turkiye.
C3 Gazi University
RP Göker, H (corresponding author), Gazi Univ, Hlth Serv Vocat Coll, TR-06830 Ankara, Turkiye.
EM gokerhanife@gazi.edu.tr
RI GÖKER, Hanife/HPD-1608-2023
OI GÖKER, Hanife/0000-0003-0396-7885
CR Agarwal M, 2019, WEARSYS'19: PROCEEDINGS OF THE 5TH ACM WORKSHOP ON WEARABLE SYSTEMS AND APPLICATIONS, P47, DOI 10.1145/3325424.3329660
   Aldayel M, 2021, FRONT HUM NEUROSCI, V14, DOI 10.3389/fnhum.2020.604639
   Aldayel M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10041525
   Alimardani M., 2021, 12 AUGM HUM INT C, P1, DOI DOI 10.1145/3460881.3460930
   Amin CR, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P2061, DOI 10.1109/SSCI47803.2020.9308358
   Arora P, 2022, MULTIMED TOOLS APPL, V81, P32215, DOI 10.1007/s11042-022-12960-7
   Fisher CE, 2010, HARVARD REV PSYCHIAT, V18, P230, DOI 10.3109/10673229.2010.496623
   Göker H, 2023, SIGNAL IMAGE VIDEO P, V17, P1255, DOI 10.1007/s11760-022-02333-w
   H Alsharif AHMED., 2021, J Contemp Issues Bus Gov, V27, P344, DOI DOI 10.47750/CIBG.2021.27.03.048
   Hakim A, 2021, INT J RES MARK, V38, P770, DOI 10.1016/j.ijresmar.2020.10.005
   Hakim A, 2019, WIRES COGN SCI, V10, DOI 10.1002/wcs.1485
   Hou XY, 2015, 2015 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P153, DOI 10.1109/CW.2015.58
   Kasim Ö, 2021, APPL ARTIF INTELL, V35, P1407, DOI 10.1080/08839514.2021.1981660
   Khaksarighiri S, 2020, LIFE SCI SPACE RES, V27, P33, DOI 10.1016/j.lssr.2020.07.003
   Khurana V, 2021, IEEE T COGN DEV SYST, V13, P732, DOI 10.1109/TCDS.2021.3065200
   Kumar M, 2021, ACM T ASIAN LOW-RESO, V20, DOI 10.1145/3439798
   Lee EJ, 2014, J BUS ETHICS, V122, P511, DOI 10.1007/s10551-013-1775-2
   Li WH, 2021, J POWER SOURCES, V482, DOI 10.1016/j.jpowsour.2020.228863
   Libert A, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21101014
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Ma QG, 2021, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.610890
   Mahapatra S, 2022, COMPUT BIOL MED, V147, DOI 10.1016/j.compbiomed.2022.105770
   Manshouri N, 2020, BIOMED SIGNAL PROCES, V55, DOI 10.1016/j.bspc.2019.101642
   Mileti A, 2016, PSYCHOL MARKET, V33, P664, DOI 10.1002/mar.20907
   Murugappan M, 2014, 2014 IEEE 10TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2014), P25, DOI 10.1109/CSPA.2014.6805714
   Ohme R, 2010, J ECON PSYCHOL, V31, P785, DOI 10.1016/j.joep.2010.03.008
   Oliveira GHBS, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113331
   Özbeyaz A, 2021, NEURAL COMPUT APPL, V33, P4579, DOI 10.1007/s00521-021-05779-0
   Paulmurugan K, 2021, BIOSENSORS-BASEL, V11, DOI 10.3390/bios11100389
   Ravi S, 2022, MULTIMED TOOLS APPL, V81, P6585, DOI 10.1007/s11042-021-11608-2
   Settouti N, 2016, INT J INTERACT MULTI, V4, P46, DOI 10.9781/ijimai.2016.419
   Tosun M, 2021, PHYS ENG SCI MED, V44, P693, DOI 10.1007/s13246-021-01018-x
   Ullah A, 2022, INT J ADV COMPUT SC, V13, P298
   Venkatachalam K, 2020, ARTIF INTELL MED, V103, DOI 10.1016/j.artmed.2019.101787
   Venkatraman V, 2015, J MARKETING RES, V52, P436, DOI 10.1509/jmr.13.0593
   Yadava M, 2017, MULTIMED TOOLS APPL, V76, P19087, DOI 10.1007/s11042-017-4580-6
   Yao Zhou, 2022, IEEE Transactions on Artificial Intelligence, V3, P436, DOI 10.1109/TAI.2021.3134600
   Yildirim Ö, 2018, COMPUT BIOL MED, V96, P189, DOI 10.1016/j.compbiomed.2018.03.016
   Yuvaraj R, 2017, BRAIN TOPOGR, V30, P333, DOI 10.1007/s10548-016-0524-0
   Zeng L, 2022, FRONT HUM NEUROSCI, V15, DOI 10.3389/fnhum.2021.793952
   Zhang Z.G., 2019, EEG Signal Processing and feature extraction, P89, DOI [10.1007/978-981-13-9113-2_6, DOI 10.1007/978-981-13-9113-2_6]
   Zito M, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.625570
NR 42
TC 3
Z9 3
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 10
PY 2023
DI 10.1007/s11042-023-17114-x
EA OCT 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2RB1
UT WOS:001083315100003
DA 2024-07-18
ER

PT J
AU Sujithra, BS
   Jerome, SA
AF Sujithra, B. S.
   Jerome, S. Albert
TI Glaucoma detection and classification by using hysteresis thresholding
   based IAOAWTO and ICNNBTL classifier
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Glaucoma detection; Bilateral with Unsharp Filter; Hysteresis
   thresholding with morphological post segmentation process; Improved
   Archimedes Optimization Algorithm with Transfer Operator (IAOAWTO);
   Improved convolutional neural network based transfer learning (ICNNBTL)
   classifier
ID SEGMENTATION
AB Nowadays, a lot of patients undergo eye screening per day, therefore ophthalmologists face a lot of challenges during the screening of glaucoma. Also, manual screening leads to errors and is more time-consuming, the patients have to wait for much time in the clinic. Hence an automated system is essential to help the ophthalmologist as a secondary opinion in retinal screening. In this research work, the initial step is image acquisition; here the input images are collected from public ORIGA and in-house Clinical Fundus Images. The next step image enhancement is performed using a Bilateral with Unsharp Filter, which can eradicate the noise discerned in the input images. In the subsequent step, the Hysteresis thresholding with the morphological post-segmentation process is implemented on an enhanced image sequence for Retina Blood vessel extraction. Then the segmented output is fed to the Improved Archimedes Optimization Algorithm with Transfer Operator (IAOAWTO). Ultimately, the Fundus images are classified by utilizing an improved convolutional neural network-based transfer learning (ICNNBTL) classifier. The accuracy is 96.6% and 5 FP is predicted. The results show the improvement of diagnosis in the proposed method compared to other methods.
C1 [Sujithra, B. S.] Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, Tamil Nadu, India.
   [Jerome, S. Albert] Noorul Islam Ctr Higher Educ, Dept Biomed Engn, Kumaracoil, Tamil Nadu, India.
RP Sujithra, BS (corresponding author), Noorul Islam Ctr Higher Educ, Dept Elect & Commun Engn, Kumaracoil, Tamil Nadu, India.
EM drsujithrasbabu@gmail.com; albertjerome@niuniv.com
RI JEROME, S ALBERT/AAJ-5555-2021; B S, Sujithra/KRQ-7428-2024
OI JEROME, S ALBERT/0009-0008-0155-8053; B S, Sujithra/0000-0002-6841-6251
FU The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of the freely-accessible public ORIGA database.
   Then we would like to acknowledge Dr. Somervel; Noorul Islam Center for
   Higher Education
FX The Authors thank the management of the Noorul Islam Center for Higher
   Education for their continuous support and encouragement. Also, we
   acknowledge the creator of the freely-accessible public ORIGA database.
   Then we would like to acknowledge Dr. Somervell Memorial C.S.I. Medical
   College & Hospital, Kerala, India for providing the in-house clinical
   data. Finally, we would like to thank the anonymous reviewers for
   helping to organize this text.
CR Ali MAS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11111763
   Bajwa MN, 2019, BMC MED INFORM DECIS, V19, DOI 10.1186/s12911-019-0842-8
   Braganca CP, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10122345
   Chen XY, 2015, IEEE ENG MED BIO, P715, DOI 10.1109/EMBC.2015.7318462
   ConduracheAP AachT, 2005, P 9 IAPR C MACH VIS, P269
   Dash Jyotiprava, 2017, Future Computing and Informatics Journal, V2, P103, DOI 10.1016/j.fcij.2017.10.001
   Dash S, 2021, INT J IMAG SYST TECH, V31, P351, DOI 10.1002/ima.22461
   Deng LZ, 2022, IEEE T INTELL TRANSP, V23, P25249, DOI 10.1109/TITS.2022.3199805
   Dhal KG, 2023, ARCH COMPUT METHOD E, V30, P2543, DOI 10.1007/s11831-022-09876-8
   Dinç B, 2023, WIRELESS PERS COMMUN, V129, P2727, DOI 10.1007/s11277-023-10255-0
   Elbalaoui A, 2016, I C COMP GRAPH IM VI, P324, DOI 10.1109/CGiV.2016.69
   Guo F, 2018, IEEE ACCESS, V6, P77414, DOI 10.1109/ACCESS.2018.2882946
   Hashim FA, 2021, APPL INTELL, V51, P1531, DOI 10.1007/s10489-020-01893-z
   He C, 2023, Weakly-Supervised Concealed Object Segmentation with SAM-based Pseudo Labeling and Multi-scale Feature Grouping, DOI [10.48550/arXiv.2305.1100, DOI 10.48550/ARXIV.2305.1100]
   He CM, 2023, PROC CVPR IEEE, P22046, DOI 10.1109/CVPR52729.2023.02111
   Hemelings R, 2023, NPJ DIGIT MED, V6, DOI 10.1038/s41746-023-00857-0
   Hemelings R, 2019, COMPUT MED IMAG GRAP, V76, DOI 10.1016/j.compmedimag.2019.05.004
   Jero S, 2021, IEEE REAL TIME, P1, DOI 10.1109/RTAS52030.2021.00009
   Juneja M, 2022, COMPUT ELECTR ENG, V101, DOI 10.1016/j.compeleceng.2022.108009
   Kashyap R, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10122497
   Koozekanani D, 2001, IEEE T MED IMAGING, V20, P900, DOI 10.1109/42.952728
   Krishnamoorthy S, 2023, ARTIF INTELL REV, V56, P483, DOI 10.1007/s10462-023-10516-1
   Latif J, 2022, SN APPL SCI, V4, DOI 10.1007/s42452-022-04984-3
   Lu Y, 2021, IET IMAGE PROCESS, V15, P3063, DOI 10.1049/ipr2.12290
   Martins J, 2020, COMPUT METH PROG BIO, V192, DOI 10.1016/j.cmpb.2020.105341
   Mayer MA, 2010, BIOMED OPT EXPRESS, V1, P1358, DOI 10.1364/BOE.1.001358
   Nawaz M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020434
   Neggaz I, 2023, NEURAL COMPUT APPL, V35, P3903, DOI 10.1007/s00521-022-07925-8
   Neggaz I, 2022, SOFT COMPUT, V26, P10435, DOI 10.1007/s00500-022-06886-3
   Noronha KP, 2014, BIOMED SIGNAL PROCES, V10, P174, DOI 10.1016/j.bspc.2013.11.006
   Phan S, 2019, JPN J OPHTHALMOL, V63, P276, DOI 10.1007/s10384-019-00659-6
   Ragab M, 2023, HEALTHCARE-BASEL, V11, DOI 10.3390/healthcare11040590
   Rani KV, 2022, IETE J RES, V68, P1485, DOI 10.1080/03772063.2019.1654935
   Rani KV, 2023, SIGNAL IMAGE VIDEO P, V17, P3873, DOI 10.1007/s11760-023-02616-w
   Rani KV, 2023, MULTIMED TOOLS APPL, V82, P47477, DOI 10.1007/s11042-023-15716-z
   Rani KV, 2021, J AMB INTEL HUM COMP, V12, P7667, DOI 10.1007/s12652-020-02485-y
   Rani KV, 2020, INT J IMAG SYST TECH, V30, P899, DOI 10.1002/ima.22422
   Regan D, 2019, Int J Recent Technol Eng (IJRTE), V8, DOI [10.35940/ijrte.D4364.118419, DOI 10.35940/IJRTE.D4364.118419]
   Sallow AB, 2019, Acad J Nawroz Univ, V8, P67, DOI [10.25007/ajnu.v8n3a398, DOI 10.25007/AJNU.V8N3A398]
   Sarkar D, 2017, SPRINGER PROC PHYS, V194, P381, DOI 10.1007/978-981-10-3908-9_46
   Sau Paresh Chandra, 2021, Proceedings of International Conference on Big Data, Machine Learning and their Applications. ICBMA 2019. Lecture Notes in Networks and Systems (LNNS 150), P85, DOI 10.1007/978-981-15-8377-3_8
   Shabbir A, 2021, MATH BIOSCI ENG, V18, P2033, DOI 10.3934/mbe.2021106
   Shiney TSS, 2023, J DIGIT IMAGING, V36, P510, DOI 10.1007/s10278-022-00715-7
   Sudhan MB, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/1601354
   Altay EV, 2023, ARTIF INTELL REV, V56, P6885, DOI 10.1007/s10462-022-10340-z
   Velpula VK, 2023, FRONT PHYSIOL, V14, DOI 10.3389/fphys.2023.1175881
   Rani KV, 2020, IET IMAGE PROCESS, V14, P3355, DOI 10.1049/iet-ipr.2020.0407
   Xu YW, 2014, LECT NOTES COMPUT SC, V8673, P788, DOI 10.1007/978-3-319-10404-1_98
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
   Zilly J, 2017, COMPUT MED IMAG GRAP, V55, P28, DOI 10.1016/j.compmedimag.2016.07.012
NR 50
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 9
PY 2023
DI 10.1007/s11042-023-17148-1
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U2OJ4
UT WOS:001083245400010
DA 2024-07-18
ER

PT J
AU Adreani, L
   Bellini, P
   Colombo, C
   Fanfani, M
   Nesi, P
   Pantaleo, G
   Pisanu, R
AF Adreani, L.
   Bellini, P.
   Colombo, C.
   Fanfani, M.
   Nesi, P.
   Pantaleo, G.
   Pisanu, R.
TI Implementing integrated digital twin modelling and representation into
   the Snap4City platform for smart city solutions
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Digital Twin; 3D City model; Smart City Modelling
ID RESOLUTION; LIDAR
AB Recently, Digital Twins solutions have attracted a growing interest as a fundamental paradigm for managing data driven processes on smart cities. They are complex modelling that should include 3D interactive representations of buildings and infrastructures, integrated with a wide range of data for Smart City cyber-physical ecosystem monitoring and controlling. This paper presents a framework for modelling, generating and distributing Digital Twin representations with 3D models from a various set of data, as well as its integration into the open-source Smart City framework, where many kinds of real time and historical data are available. The proposed solution offers a method for creating integrated data rendering of 3D city entities coupled with Smart City data (e.g., IoT Devices with time-series and historical data, heatmaps, geometries and shapes related to traffic flows, bus routes/stops, cycling paths). The solution for generating 3D representation is based on a number of computer vision and machine learning solutions, thus shortening the activities of passing from raw data (i.e., Lidar, shapes, patterns, etc.) to 3D representations. Implementation has been enforced into the quite widespread open-source Snap4City Smart City platform and has been validated by using hundreds of buildings in Florence city central area, Italy, plus hundreds of thousands of data as points of interest, IoT Devices, traffic flows, dynamic heatmaps, etc.
C1 [Adreani, L.; Bellini, P.; Fanfani, M.; Nesi, P.; Pantaleo, G.] DISIT Lab, Florence, Italy.
   [Adreani, L.; Bellini, P.; Colombo, C.; Fanfani, M.; Nesi, P.; Pantaleo, G.; Pisanu, R.] Univ Florence, Florence, Italy.
   [Colombo, C.; Fanfani, M.; Pisanu, R.] Univ Florence, Computat Vis Grp, Florence, Italy.
C3 University of Florence; University of Florence
RP Nesi, P (corresponding author), DISIT Lab, Florence, Italy.; Nesi, P (corresponding author), Univ Florence, Florence, Italy.
EM Lorenzo.Adreani@unifi.it; Pierfrancesco.Bellini@unifi.it;
   Carlo.Colombo@unifi.it; Marco.Fanfani@unifi.it; Paolo.Nesi@unifi.it;
   Gianni.Pantaleo@unifi.it; Riccrdo.Pisanu@unifi.it
RI Pantaleo, Gianni/J-1864-2016
OI Pantaleo, Gianni/0000-0002-9235-437X; nesi, paolo/0000-0003-1044-3107
FU Universita degli Studi di Firenze
FX Open access funding provided by Universita degli Studi di Firenze within
   the CRUI-CARE Agreement.
CR 3drotterdam, Rotterdam 3D
   Adreani L, 2022, DMSVIVA 2022 28 INT
   Awrangjeb M, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10101512
   Badii C, 2019, Sensors, MDPI, DOI [10.3390/s19010001, DOI 10.3390/S19010001]
   Baldi G., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P171
   Baluyan H., 2013, ISRN Mach Vis, V2013, P11
   Belgiu M, 2016, ISPRS J PHOTOGRAMM, V114, P24, DOI 10.1016/j.isprsjprs.2016.01.011
   Bellini E, 2021, An IoE and Big Multimedia Data approach for Urban Transport System resilience management in Smart City
   Bellini P, 2019, 19 IEEE INT C SCALAB
   Berlin 3D 3dcitydb, About us
   Bilotta S, 2022, IEEE ACCESS, V10, P113086, DOI 10.1109/ACCESS.2022.3217240
   Bonczak B, 2019, COMPUT ENVIRON URBAN, V73, P126, DOI 10.1016/j.compenvurbsys.2018.09.004
   Bosch M, 2016, IEEE APP IMG PAT
   Building Reconstruction CityGML builder, About us
   Campello R., 2013, PACIFIC ASIA C KNOWL, P160, DOI [DOI 10.1007/978-3-642-37456-2_14, 10.1007/978-3-642-37456-2\\\\ _14, DOI 10.1007/978-3-642-37456-2, 10.1007/978-3-642-37456-2, DOI 10.1007/978-3-642-37456-214]
   Caprari G, 2022, SUSTAINABILITY-BASEL, V14, DOI 10.3390/su14106263
   Castello R, 2021, J PHYS CONF SER, V2042, DOI 10.1088/1742-6596/2042/1/012002
   Chaturvedi K, 2019, FUTURE GENER COMP SY, V101, P723, DOI 10.1016/j.future.2019.07.002
   Chen M, 2019, arXiv
   Collini E, 2022, IEEE ACCESS, V10, P31175, DOI 10.1109/ACCESS.2022.3158328
   Deng TH, 2021, J MANAGE SCI ENG, V6, P125, DOI 10.1016/j.jmse.2021.03.003
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fissore E, 2019, Int Arch Photogramm Remote Sens Spatial Inf Sci, VXLII-2/W13, P1539, DOI [10.5194/isprs-archives-XLII-2-W13-1539-2019, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W13-1539-2019]
   Garau C, 2020, LECT NOTES COMPUT SC, V12255, P393, DOI 10.1007/978-3-030-58820-5_30
   Girard N, 2019, LECT NOTES COMPUT SC, V11365, P675, DOI 10.1007/978-3-030-20873-8_43
   Gröger G, 2012, ISPRS J PHOTOGRAMM, V71, P12, DOI 10.1016/j.isprsjprs.2012.04.004
   Gui SX, 2021, ISPRS J PHOTOGRAMM, V181, P1, DOI 10.1016/j.isprsjprs.2021.08.025
   Han Q, 2020, P IEEE ICHMS 2020 IN
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Izadi M., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P472, DOI 10.1109/ICPR.2010.123
   Jovanovic D, 2020, ISPRS Int J Geo-Inf, P16
   kartta, Helsinki 3D city model
   Lafioune N, 2020, INNOV MANAG REV, V17, P285, DOI 10.1108/INMR-03-2019-0033
   Ma L, 2019, ISPRS J PHOTOGRAMM, V152, P166, DOI 10.1016/j.isprsjprs.2019.04.015
   Mountrakis G, 2011, ISPRS J PHOTOGRAMM, V66, P247, DOI 10.1016/j.isprsjprs.2010.11.001
   Mylonas G, 2021, IEEE ACCESS, V9, P143222, DOI 10.1109/ACCESS.2021.3120843
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Rasheed A, 2020, IEEE ACCESS, V8, P21980, DOI 10.1109/ACCESS.2020.2970143
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shahat E, 2021, SUSTAINABILITY-BASEL, V13, DOI 10.3390/su13063386
   Stockholm Opencities Planner, About us
   Thompson JA, 2001, GEODERMA, V100, P67, DOI 10.1016/S0016-7061(00)00081-1
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   varcity, ETH Zurich VarCity project
   Wang Y., 2021, P IEEECVF C COMPUTER
   Xue F, 2020, ISPRS J PHOTOGRAMM, V167, P418, DOI 10.1016/j.isprsjprs.2020.07.020
   Ye YX, 2017, IEEE T GEOSCI REMOTE, V55, P2941, DOI 10.1109/TGRS.2017.2656380
   Zampieri A, 2018, Arxiv, DOI arXiv:1802.09816
NR 49
TC 5
Z9 5
U1 5
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 6
PY 2023
DI 10.1007/s11042-023-16838-0
EA OCT 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EX9N7
UT WOS:001142351700001
OA hybrid
DA 2024-07-18
ER

PT J
AU Meng, HJ
   Yang, Q
   Zhou, JL
   Gao, DX
AF Meng, Huijuan
   Yang, Qing
   Zhou, Jili
   Gao, Dexin
TI An underwater organisms recognition method based on machine vision in
   complex marine environment
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE YOLOv5; Image enhancement; Convolutional neural networks; Target
   detection; UWCNN
AB To meet the requirements for parallelity and accuracy in marine biosensing, this article proposes an improved YOLOv5 algorithm based on lightweight enhanced networks. Before training improved models, UWCNN algorithms enhanced underwater target images to solve problems such as color deviation, image noise and image vagueness.In improving the YOLOv5 algorithm, this paper introduced, first, the Swin-Transformer main core module to improve the model's generalization capabilities; secondly, the use of the EMA structure in the head prediction section and the introduction of the GAM attention mechanism in the main core to enhance the robustness of the model; and finally, the introducation of Focal-EIOU Loss for precision boundary frame regression efficient losses.The results showed that the detection speed improved by 2 points compared to the original YOLOv5 algorithm, with the AP of sea cucumber, sea urchins, scallops, and starfish increased by 14%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}, 1%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document},5%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} and 5%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document} respectively, and the mAP increased 6.26%\documentclass[12pt]{minimal} \usepackage{amsmath} \usepackage{wasysym} \usepackage{amsfonts} \usepackage{amssymb} \usepackage{amsbsy} \usepackage{mathrsfs} \usepackage{upgreek} \setlength{\oddsidemargin}{-69pt} \begin{document}$$\%$$\end{document}. Furthermore, the fps value has increased to 38.86 phases per second.The method is directly targeted at detection of shallow-sea organisms and can provide useful reference to the intelligent equipment of underwater robots.
C1 [Meng, Huijuan; Yang, Qing; Zhou, Jili] Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Shandong, Peoples R China.
   [Gao, Dexin] Qingdao Univ Sci & Technol, Sch Automat & Elect Engn, Qingdao 266061, Shandong, Peoples R China.
C3 Qingdao University of Science & Technology; Qingdao University of
   Science & Technology
RP Yang, Q (corresponding author), Qingdao Univ Sci & Technol, Sch Informat Sci & Technol, Qingdao 266061, Shandong, Peoples R China.
EM 4021110043@mails.qust.edu.cn; 03390@qust.edu.cn;
   4020110064@mails.qust.edu.cn; gaodexin@qust.edu.cn
FU Natural Science Foundation of Shandong Province [U1806201]; National
   Natural Science Foundation of China [ZR2021ZD12]; Major Basic Natural
   Science Foundation of Shandong Province [ZR2022ME194]; Natural Science
   Foundation of Shandong Province
FX This work is partially supported by the National Natural Science
   Foundation of China (grant number U1806201) and the Major Basic Natural
   Science Foundation of Shandong Province (grant number ZR2021ZD12) and
   the Natural Science Foundation of Shandong Province (Grant No.
   ZR2022ME194).
CR Chauhan S., 2021, Data Science and Data Analytics: Opportunities and Challenges, V1
   [陈学磊 Chen Xuelei], 2022, [计算机工程, Computer Engineering], V48, P243
   Dubey SR, 2021, MULTIMED TOOLS APPL, V80, P23181, DOI 10.1007/s11042-020-10269-x
   [范新南 Fan Xinnan], 2022, [计算机辅助设计与图形学学报, Journal of Computer-Aided Design & Computer Graphics], V34, P264
   Fang M, 2021, J ELECTRON INF TECHN, V43, P3513, DOI 10.11999/JEIT200836
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   [洪亮 Hong Liang], 2021, [农业工程学报, Transactions of the Chinese Society of Agricultural Engineering], V37, P304
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kumar A., 2014, Rapport Technique
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li Yu, 2022, Journal of Shanghai Jiao Tong University, V56, P134, DOI 10.16183/j.cnki.jsjtu.2021.075
   Lin S, 2020, ACTA PHOTONICA SINIC, V49, DOI 10.3788/gzxb20204903.0310003
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y., 2021, arXiv, DOI DOI 10.48550/ARXIV.2112.05561
   Nishiyama T, 2020, IEEE SYMP COMP COMMU, P524
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   [吴睿 Wu Rui], 2022, [哈尔滨工程大学学报, Journal of Harbin Engineering University], V43, P580
   Yong Zi-Ye, 2021, Journal of Zhejiang University (Engineering Science), V55, P555, DOI 10.3785/j.issn.1008-973X.2021.03.016
   Zhang YF, 2022, NEUROCOMPUTING, V506, P146, DOI 10.1016/j.neucom.2022.07.042
   [赵海英 Zhao Haiying], 2022, [北京邮电大学学报, Journal of Beijing University of Posts Telecommunications], V45, P69
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou JL, 2022, SYST SCI CONTROL ENG, V10, P590, DOI 10.1080/21642583.2022.2082579
NR 25
TC 0
Z9 0
U1 6
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 5
PY 2023
DI 10.1007/s11042-023-16995-2
EA OCT 2023
PG 15
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GZ4I6
UT WOS:001156484900005
DA 2024-07-18
ER

PT J
AU Merryton, AR
   Augasta, MG
AF Merryton, Adline Rajasenah
   Augasta, M. Gethsiyal
TI An Attribute-wise Attention model with BiLSTM for an efficient Fake News
   Detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Natural Language Processing; Bi-LSTM; CNN; Attention Mechanism; Fake
   News Detection; Auto encoder
AB Nowadays, fake news propaganda is the main threat to society, as it has the potential to misdirect public behaviour and provoke violence and extremism. Recently, to prevent the spread of misinformation, researchers have devised various fake news detection models with deep learning techniques. This research aims to develop a unique deep architecture to capture the basic insights about the document in the form of a summarised feature vector representation for better fake news detection. The proposed model, namely AA-BiLSTM includes Bi-directional Long Short-Term Memory (Bi-LSTM) and an attribute-wise attention mechanism based on Convolutional Neural Network (CNN) as the CNN models extract higher-level features using convolutional layers and average pooling layers. Moreover, this model suitably pays attention to the word or sentence based on the dependent attribute by applying the attention mechanism after the fusing process. The performance of the proposed AA-BiLSTM has been experimentally evaluated on four benchmark datasets, namely Kaggle fake_real_news [2022], Kaggle fake_real_news [2016], ISOT and Liar datasets, and compared with the existing state-of-the-art fake news detection methods. For the Kaggle fake_real_news 2016 and ISOT fake news datasets, the AA-BiLSTM algorithm achieved an accuracy of more than 99%. In the Liar dataset, the AA-BiLSTM method surpassed all basic models with an accuracy of 60.31%.
C1 [Merryton, Adline Rajasenah] Manonmaniam Sundarnar Univ, Sarah Tucker Coll, Tirunelveli 627012, Tamil Nadu, India.
   [Augasta, M. Gethsiyal] Manonmaniam Sundaranar Univ, Kamaraj Coll, Thoothukudi, Tamil Nadu, India.
C3 Manonmaniam Sundaranar University; Manonmaniam Sundaranar University
RP Augasta, MG (corresponding author), Manonmaniam Sundaranar Univ, Kamaraj Coll, Thoothukudi, Tamil Nadu, India.
EM adlinesamuel@gmail.com; augastaglady@gmail.com
RI M, Gethsiyal Augasta/AAS-2164-2020
OI M, Gethsiyal Augasta/0000-0002-1975-7623
FU The authors are very grateful to the family members and research
   committee for their constant support and to the editors and reviewers
   for their valuable and prolific suggestions to refine the quality of the
   paper.
FX The authors are very grateful to the family members and research
   committee for their constant support and to the editors and reviewers
   for their valuable and prolific suggestions to refine the quality of the
   paper.
CR Abedalla A., 2019, P 3 INT C ADV ART IN, P24
   Alameri SA, 2021, 2021 3RD INTERNATIONAL CYBER RESILIENCE CONFERENCE (CRC), P101, DOI 10.1109/CRC50527.2021.9392458
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Brownlee J, 2021, Machine Learning Mastery
   Chung JY, 2014, Arxiv, DOI arXiv:1412.3555
   Elhadad MK, 2019, IEEE PAC RIM CONF CO, DOI 10.1109/pacrim47961.2019.8985062
   Fang Y, 2019, PLOS ONE, V14, DOI 10.1371/journal.pone.0222713
   GloVe, Global Vectors for Word Representation, "Website
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Hiramath Chaitra K., 2019, 2019 1st International Conference on Advances in Information Technology (ICAIT). Proceedings, P411, DOI 10.1109/ICAIT47043.2019.8987258
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kumar S, 2020, T EMERG TELECOMMUN T, V31, DOI 10.1002/ett.3767
   Lin ZH, 2017, Arxiv, DOI [arXiv:1703.03130, DOI 10.48550/ARXIV.1703.03130]
   Rezaeinia SM, 2017, Arxiv, DOI [arXiv:1711.08609, 10.48550/arXiv.1711.08609]
   Monti F, 2019, Arxiv, DOI arXiv:1902.06673
   Nguyen DM, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P1391
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Risdal M., 2016, Getting real about fake news
   Rodr¡guez AI, 2019, Arxiv, DOI [arXiv:1910.03496, DOI 10.48550/ARXIV.1910.03496]
   Sahoo SR, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106983
   Sharma P., 2020, Keras dense layer explained for beginners
   Shu K., 2017, ACM SIGKDD EXPLOR NE, V19, P22, DOI [DOI 10.1145/3137597.3137600, 10.1145/3137597.3137600]
   Singhania S, 2017, LECT NOTES COMPUT SC, V10635, P572, DOI 10.1007/978-3-319-70096-0_59
   Sridhar S, 2021, 2021 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, DATA SCIENCE & ENGINEERING (CONFLUENCE 2021), P905, DOI 10.1109/Confluence51648.2021.9377080
   Tech JS, 2022, Kaggle
   Thota A, 2018, SMU Data Sci Rev, V1
   Trueman TE, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107600
   Wang W. Y., 2015, P 2015 C EMP METH NA, P2557, DOI DOI 10.18653/V1/D15-1306
   Wang WY, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 2, P422, DOI 10.18653/v1/P17-2067
   Wang WY, 2017, Dataset for Fake News Detection
   Wani A, 2021, Communications in Computer and Information Science, V1402
   Yang S, 2019, AAAI CONF ARTIF INTE, P5644
   Yang Z., 2016, P 2016 C N AM CHAPT, P1480, DOI [DOI 10.18653/V1/N16-1174, 10.18653/v1/n16-1174]
   Zhao ZW, 2016, INTERSPEECH, P705, DOI 10.21437/Interspeech.2016-354
NR 35
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 3
PY 2023
DI 10.1007/s11042-023-16824-6
EA OCT 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM0
UT WOS:001076638500014
DA 2024-07-18
ER

PT J
AU Shastry, A
   Jidesh, P
   George, S
   Bini, A
AF Shastry, Architha
   Jidesh, P.
   George, Santhosh
   Bini, Aa
TI A weighted nuclear norm (WNN)-based retinex DIP framework for restoring
   aerial and satellite images corrupted by gamma distributed speckle noise
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Despeckling; Enhancement; Deep image prior; Weighted nuclear norm;
   Variational retinex model
ID MODEL; ALGORITHM; MINIMIZATION; ENHANCEMENT
AB Restoration and enhancement are crucial preprocessing steps in the satellite domain. Mainly in active remote sensing such as Synthetic Aperture Radar (SAR), the images are more prone to speckle distortions and their reduction is not so trivial. Traditional deep learning models require large training datasets, limiting their applicability. This paper introduces a novel approach that combines the Deep Image Prior (DIP) model with a weighted nuclear norm (WNN) within a variational retinex framework to address these challenges. DIP leverages prior knowledge about noise distribution and works effectively with a single noisy image, eliminating the need for a large number of training images or ground truth. The WNN assigns non-negative weights to singular values, capturing the significance of each value and preserving crucial information during restoration. This approach offers a promising solution for satellite image restoration without relying on huge training data. The proposed method is evaluated through extensive experiments using various image quality metrics, including PSNR, SSIM, ENL, CNR, Entropy, and GCF. The comparative studies provide compelling evidence that the proposed method surpasses existing techniques in effectively restoring and enhancing speckled input images. Furthermore, statistical analysis performed using the Friedman test demonstrates the superior denoising performance of the model. Additionally, an ablation study is conducted to empirically determine the optimal regularization parameters, ensuring the optimal performance of the model. However, the theoretical selection of parameters for achieving optimal results remains an area that requires further exploration.
C1 [Shastry, Architha; Jidesh, P.; George, Santhosh] Natl Inst Technol Karnataka, Dept Math & Computat Sci, Mangalore 575025, India.
   [Bini, Aa] Natl Inst Technol Calicut, Dept Elect & Commun Engn, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka; National Institute of Technology (NIT System);
   National Institute of Technology Calicut
RP Jidesh, P (corresponding author), Natl Inst Technol Karnataka, Dept Math & Computat Sci, Mangalore 575025, India.
EM jidesh@nitk.edu.in
RI P, J/KCK-9262-2024; George, Santhosh/ABH-5401-2020; George,
   Santhosh/P-9357-2018; P, Jidesh/C-6030-2017
OI George, Santhosh/0000-0002-3530-5539; George,
   Santhosh/0000-0002-3530-5539; P, Jidesh/0000-0001-9448-1906
FU Science and Engineering Research Board, Govt. of India [CRG/2020/000476]
FX The Authors would like to thank Science and Engineering Research Board,
   Govt. of India for providing financial support under grant no.
   CRG/2020/000476.
CR Argyros I.K., 2022, The Theory and Applications of Iteration Methods with Applications, Engineering Series, V2nd ed.
   Aubert G, 2008, SIAM J APPL MATH, V68, P925, DOI 10.1137/060671814
   Austria DATAtab, 2023, e.U. Graz. Datatab: Online statistics calculator
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès E, 2012, COMMUN ACM, V55, P111, DOI 10.1145/2184319.2184343
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061
   Dalsasso E, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3128621
   Dalsasso E, 2021, IEEE J-STARS, V14, P4321, DOI 10.1109/JSTARS.2021.3071864
   Dalsasso E, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12162636
   Deng HY, 2020, INFORM SCIENCES, V528, P246, DOI 10.1016/j.ins.2020.04.028
   Eriksson A, 2010, PROC CVPR IEEE, P771, DOI 10.1109/CVPR.2010.5540139
   Fan WS, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050784
   Fang J, 2016, J SYST ENG ELECTRON, V27, P807, DOI 10.21629/JSEE.2016.04.09
   Febin IP, 2020, IEEE J-STARS, V13, P941, DOI 10.1109/JSTARS.2020.2975044
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   FROST VS, 1982, IEEE T PATTERN ANAL, V4, P157, DOI 10.1109/TPAMI.1982.4767223
   George S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10183365
   Gilboa G, 2008, MULTISCALE MODEL SIM, V7, P1005, DOI 10.1137/070698592
   Goldfarb D, 2011, FOUND COMPUT MATH, V11, P183, DOI 10.1007/s10208-011-9084-6
   Gomez L, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9040389
   Gonzalez R C, 2009, PEARSON ED INDIA
   Gu SH, 2017, INT J COMPUT VISION, V121, P183, DOI 10.1007/s11263-016-0930-5
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Hu LS, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13010062
   Jet Propulsion Laboratory, 2021, Space radar image of flevoland, netherlands
   Johnson DH., 2006, SCHOLARPEDIA, V1, P2088, DOI [DOI 10.4249/SCHOLARPEDIA.2088, 10.4249/scholarpedia.2088]
   Karathanassi V, 2007, INT J REMOTE SENS, V28, P2309, DOI 10.1080/01431160600606890
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LAND EH, 1977, SCI AM, V237, P108, DOI 10.1038/scientificamerican1277-108
   Lee DD, 2001, ADV NEUR IN, V13, P556
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Liu XW, 2014, MATH COMPUT SIMULAT, V97, P224, DOI 10.1016/j.matcom.2013.10.001
   Liu YY, 2013, PATTERN RECOGN, V46, P284, DOI 10.1016/j.patcog.2012.06.011
   LOPES A, 1990, IEEE T GEOSCI REMOTE, V28, P992, DOI 10.1109/36.62623
   Lu CY, 2014, PROC CVPR IEEE, P4130, DOI 10.1109/CVPR.2014.526
   Matkovic K., 2005, Computational Aesthetics, P159
   Merced Universityof California, 2022, MERC 2020 AER PHOT
   Molini AB, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3065461
   Naga Srinivasu P., 2021, BIOINSPIRED NEUROCOM, P1
   Ng MK, 2011, SIAM J IMAGING SCI, V4, P345, DOI 10.1137/100806588
   Parrilli S, 2012, IEEE T GEOSCI REMOTE, V50, P606, DOI 10.1109/TGRS.2011.2161586
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SandiaNational Laboratories, 2021, Pathfinder radar isr & sar systems:sar imagery
   Shastry A, 2022, PFG-J PHOTOGRAMM REM, V90, P497, DOI 10.1007/s41064-022-00226-8
   Smitha A, 2021, J MOD OPTIC, V68, P1002, DOI 10.1080/09500340.2021.1968052
   Srebro N., 2003, P 20 INT C MACH LEAR, P720
   Tikhonov A.N., 1963, SOV MATH DOKL, V4, P1624
   Timischl F, 2015, SCANNING, V37, P54, DOI 10.1002/sca.21179
   Ulyanov D, 2020, INT J COMPUT VISION, V128, P1867, DOI 10.1007/s11263-020-01303-4
   Volodina O. S., 2020, Computational Mathematics and Modeling, V31, P402, DOI 10.1007/s10598-020-09500-z
   Wang PY, 2017, 2017 IEEE 7TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL ADVANCES IN MULTI-SENSOR ADAPTIVE PROCESSING (CAMSAP)
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wei SJ, 2020, IEEE ACCESS, V8, P120234, DOI 10.1109/ACCESS.2020.3005861
   Xu J, 2017, IEEE I CONF COMP VIS, P1105, DOI 10.1109/ICCV.2017.125
   Yair N, 2018, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2018.00334
   Yang H., 2020, Mathematical Problems in Engineering, V2020
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Yu YB, 2019, NEUROCOMPUTING, V332, P283, DOI 10.1016/j.neucom.2018.12.034
   Zhang Q, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10020196
   Zhao HY, 2020, LECT NOTES ELECTR EN, V516, P661, DOI 10.1007/978-981-13-6504-1_80
   Zhao ZJ, 2022, IEEE T CIRC SYST VID, V32, P1076, DOI 10.1109/TCSVT.2021.3073371
   Zosso D, 2015, SIAM J IMAGING SCI, V8, P787, DOI 10.1137/140972664
NR 66
TC 0
Z9 0
U1 2
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 OCT 2
PY 2023
DI 10.1007/s11042-023-17159-y
EA OCT 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U1KJ9
UT WOS:001082459100014
DA 2024-07-18
ER

PT J
AU Divya, AK
   Keshaveni, N
AF Divya, A. K.
   Keshaveni, N.
TI An AVOA-LSTM with MRCNN for segmenting and classifying the sunglass
   image-based eye region identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Mask-RCNN; OLSTM; eye region; AVOA; Segmentation; Classification; Deep
   Learning
ID RECOGNITION; FACE; TRACKING; FATIGUE
AB The recognition of the eye region from images is a challenging task, particularly when dealing with dark or thick sunglasses that cause reflections and interfere with accurate identification. To address this issue, a novel system called AVOA-MRCNN-OLSTM has been proposed. This system combines Optimization-driven Long Short-Term Memory (LSTM) with Mask RCNN to achieve precise eye recognition even in the presence of eyeglass frame interference. A mean histogram equalization approach is used in the system's first stage to eliminate noise, which improves the image quality. The system then uses Mask RCNN for segmentation and localization. A potent deep learning model called Mask RCNN can precisely recognize and isolate particular items inside an image. It is used in this instance to identify and divide the eye region. The AVOA-MRCNN-OLSTM framework makes use of LSTM, a recurrent neural network variety that can retain patterns for longer periods. It can efficiently acquire and use temporal information to increase eye recognition accuracy by integrating LSTM into the system. The proposed AVOA-MRCNN-OLSTM system's effectiveness is shown by experimental findings. It outperforms the performance of existing algorithms, achieving a remarkable accuracy of 99% in just 0.02 seconds of computing time. The potential uses of this development include biometric identity, surveillance systems, and human-computer interfaces, all of which need precise eye recognition.
C1 [Divya, A. K.] VTU, KVG Coll Engn, CS&E Dept, Belagavi, India.
   [Keshaveni, N.] VTU, KVG Coll Engn, E&CE Dept, Belagavi, India.
C3 Visvesvaraya Technological University; Visvesvaraya Technological
   University
RP Divya, AK (corresponding author), VTU, KVG Coll Engn, CS&E Dept, Belagavi, India.
EM divyaak11@gmail.com
FU All the data is collected from the simulation reports of the software
   and tools used by the authors. Authors are working on implementing the
   same using real world data with appropriate permissions.
FX All the data is collected from the simulation reports of the software
   and tools used by the authors. Authors are working on implementing the
   same using real world data with appropriate permissions.
CR Akhtar Z, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.119
   Anitha C, 2019, LECT NOTE DATA ENG, V21, P157, DOI 10.1007/978-3-319-93940-7_7
   Chellappa R, 2016, 2016 INFORMATION THEORY AND APPLICATIONS WORKSHOP (ITA)
   Cristina S, 2018, IMAGE VISION COMPUT, V74, P21, DOI 10.1016/j.imavis.2018.04.002
   Cyganek B, 2014, NEUROCOMPUTING, V126, P78, DOI 10.1016/j.neucom.2013.01.048
   Egger B, 2018, INT J COMPUT VISION, V126, P1269, DOI 10.1007/s11263-018-1064-8
   Fuhl W, 2016, MACH VISION APPL, V27, P1275, DOI 10.1007/s00138-016-0776-4
   Funes-Mora KA, 2016, INT J COMPUT VISION, V118, P194, DOI 10.1007/s11263-015-0863-4
   Gou C, 2017, PATTERN RECOGN, V67, P23, DOI 10.1016/j.patcog.2017.01.023
   Hernandez-Matamoros A, 2016, KNOWL-BASED SYST, V110, P1, DOI 10.1016/j.knosys.2016.07.011
   Ibrahim LF, 2014, MULTIMED TOOLS APPL, V71, P1857, DOI 10.1007/s11042-012-1308-5
   Jamshidi S, 2021, MULTIMED TOOLS APPL, V80, P16045, DOI 10.1007/s11042-021-10542-7
   Kuo HF, 2016, IEEE ACCESS, V4, P6225, DOI 10.1109/ACCESS.2016.2612687
   Lu F, 2015, IEEE T IMAGE PROCESS, V24, P3680, DOI 10.1109/TIP.2015.2445295
   Myllyneva A, 2015, COGNITION, V134, P100, DOI 10.1016/j.cognition.2014.09.011
   Pires R, 2019, ARTIF INTELL MED, V96, P93, DOI 10.1016/j.artmed.2019.03.009
   Priya GN, 2014, SADHANA-ACAD P ENG S, V39, P303, DOI 10.1007/s12046-013-0216-3
   Savas BK, 2020, IEEE ACCESS, V8, P12491, DOI 10.1109/ACCESS.2020.2963960
   Shi Y, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2019.102740
   Skodras E, 2015, SIGNAL PROCESS-IMAGE, V36, P29, DOI 10.1016/j.image.2015.05.007
   Skodras E, 2015, IMAGE VISION COMPUT, V36, P51, DOI 10.1016/j.imavis.2015.01.006
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Vu HN, 2022, APPL INTELL, V52, P5497, DOI 10.1007/s10489-021-02728-1
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850932
   Yang SM, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.850945
   Yang SM, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24040455
   Yiu YH, 2019, J NEUROSCI METH, V324, DOI 10.1016/j.jneumeth.2019.05.016
   Yu MJ, 2020, PATTERN RECOGN LETT, V131, P166, DOI 10.1016/j.patrec.2020.01.016
NR 28
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16800-0
EA SEP 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200009
DA 2024-07-18
ER

PT J
AU Dogan, H
AF Dogan, Hulya
TI A higher performance shape from focus strategy based on unsupervised
   deep learning for 3D shape reconstruction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Auto-encoder; Shape from focus; Unsupervised deep learning; 3D shape
   reconstruction; Focus measurement operator
ID IMAGE FOCUS; DEPTH; ALGORITHM; MICROSCOPY; RECOVERY; FUSION
AB Shape From Focus (SFF) is one of the most popular strategies for reconstructing object's 3D shape, which doesn't require any additional technology. SFF strategies generate the object's 3D shape using a sequence of 2D images with the same field of perspective and various areas in-focus. Although SFF has many literature studies and is one of the most preferred strategies in computer vision to produce 3D shapes of objects, this research field still contains critical shortcomings such as high computational costs and complexity, less effectiveness in noisy or poorly textured areas, insufficient focus information to be extracted from the input images, generally adapting a pre- or post-processing technique and using only gray levels of original images to acquire the pixel's focus values. In order to minimize these shortcomings, an unsupervised deep learning-based SFF strategy that gives higher performance than current strategies is suggested in this study. When compared with the studies generated for 3D shape reconstruction in the literature, the proposed SFF strategy provides various fundamental contributions such as the first study proposing SFF strategy based on unsupervised deep learning, providing a high-quality focus measurement operator, acquiring the pixel's focus values from deep features and not requiring any pre- or post-processing technique. In order to assess the efficiency of the proposed SFF strategy, well-known focus measurement operators are analyzed using 4 different synthetic and microscope image sequences. In order to determine which SFF strategy can extract more essential details from the 2D images with various areas in-focus on these sequences, quality assessment criteria with and without requiring a ground-truth are preferred, which are Root Mean Square Error (RMSE), Peak Signal Noise Ratio (PSNR), Universal Quality Index (UQI), Correlation Coefficient (CC), Standard Deviation (SD) and Kurtosis Metric (KM). Both qualitative and quantitative evaluations reveal that the suggested SFF strategy with highest PSNR (28.1725, 25.0854), UQI (0.9454, 0.7543), CC (0.9457, 0.7132), and lowest RMSE (0.0390, 0.0563), SD (3.1666, 1.1768), KM (2.1254, 3.6362) values produces higher performance, and the designed unsupervised deep learning model is more efficient to transmit crucial details from 2D images.
C1 [Dogan, Hulya] Karadeniz Tech Univ, Dept Software Engn, TR-61080 Trabzon, Turkiye.
C3 Karadeniz Technical University
RP Dogan, H (corresponding author), Karadeniz Tech Univ, Dept Software Engn, TR-61080 Trabzon, Turkiye.
EM hulya@ktu.edu.tr
CR Aguet F, 2008, IEEE T IMAGE PROCESS, V17, P1144, DOI 10.1109/TIP.2008.924393
   Ahmad MB, 2007, IEEE T CONSUM ELECTR, V53, P1, DOI 10.1109/TCE.2007.339492
   Ali U, 2023, COMPUT VIS IMAGE UND, V227, DOI 10.1016/j.cviu.2022.103619
   Ali U, 2020, J MATH IMAGING VIS, V62, P54, DOI 10.1007/s10851-019-00918-8
   Ali U, 2019, INFORM SCIENCES, V489, P155, DOI 10.1016/j.ins.2019.03.056
   Alok N, 2021, Mach. Learn. Healthc. Appl., P187, DOI DOI 10.1002/9781119792611.CH12
   Billiot B, 2013, SENSORS-BASEL, V13, P5040, DOI 10.3390/s130405040
   Chakraborty C, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107778
   Chen M, 2018, Sensor Review, V0
   Dogan H, 2023, Muhendislik Bilimleri ve Arastirmalari Dergisi, V5, P9
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan FL, 2021, IEEE T RADIAT PLASMA, V5, P741, DOI 10.1109/TRPMS.2021.3066428
   Fan TT, 2018, OPT COMMUN, V410, P254, DOI 10.1016/j.optcom.2017.10.019
   Fu BY, 2023, OPT LASER ENG, V160, DOI 10.1016/j.optlaseng.2022.107320
   Geusebroek JM, 2000, CYTOMETRY, V39, P1
   Helmli FS, 2001, ISPA 2001: PROCEEDINGS OF THE 2ND INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P188, DOI 10.1109/ISPA.2001.938626
   Hermessi H, 2021, SIGNAL PROCESS, V183, DOI 10.1016/j.sigpro.2021.108036
   Hou L, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23010265
   Huang MX, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/8476000
   Jang HS, 2021, MICROSC RES TECHNIQ, V84, P2483, DOI 10.1002/jemt.23781
   Jang HS, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163276
   Jang HS, 2019, IEEE ACCESS, V7, P74393, DOI 10.1109/ACCESS.2019.2920421
   Jang HS, 2019, J IMAGING SCI TECHN, V63, DOI 10.2352/J.ImagingSci.Technol.2019.63.2.020501
   Jang HS, 2018, Microscopy Research and Technique, ppp1
   Jose J, 2021, BIOMED SIGNAL PROCES, V66, DOI 10.1016/j.bspc.2021.102480
   Kishor A, 2021, Wireless Personal Commun, P1
   Kishor A, 2021, MULTIMED TOOLS APPL, V80, P23983, DOI 10.1007/s11042-021-10840-0
   Kumar A, 2021, C P ICDLAIR2019, ppp153
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Kumar GP, 2017, IEEE INT CONF COMP V, P563, DOI 10.1109/ICCVW.2017.73
   Lee I, 2013, OPT LASER TECHNOL, V45, P21, DOI 10.1016/j.optlastec.2012.08.003
   Lee SY, 2008, IEEE T CIRC SYST VID, V18, P1237, DOI 10.1109/TCSVT.2008.924105
   Lee SY, 2009, IEEE SIGNAL PROC LET, V16, P133, DOI 10.1109/LSP.2008.2008938
   Lee SA, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19112566
   Li S, 2017, ISPRS INT GEO-INF, V6, DOI 10.3390/ijgi6050133
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2022, Front Comput Neurosci, V15, P133
   Liu W, 2015, 2015 3 IAPR AS C PAT, ppp624
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lorenzo J, 2008, 2008 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MODELLING CONTROL & AUTOMATION, VOLS 1 AND 2, P855, DOI 10.1109/CIMCA.2008.123
   Ma ZQ, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107302
   Mahmood F, 2018, 10 INT C MACH VIS IC
   Malik AS, 2008, PATTERN RECOGN, V41, P2200, DOI 10.1016/j.patcog.2007.12.014
   Minhas R, 2011, PATTERN RECOGN, V44, P839, DOI 10.1016/j.patcog.2010.10.015
   Minhas R, 2009, LECT NOTES COMPUT SC, V5627, P573, DOI 10.1007/978-3-642-02611-9_57
   Muhammad MS, 2014, INT C INFO SCI APPL
   Muhammad MS, 2012, IEEE T PATTERN ANAL, V34, P564, DOI 10.1109/TPAMI.2011.144
   Mutahira H, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-18150-7
   Mutahira H, 2021, IEEE ACCESS, V9, P102520, DOI 10.1109/ACCESS.2021.3097814
   Nanda Harsh., 2001, Technical Sketches, CVPR'01
   Nayar S. K., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P218, DOI 10.1109/ROBOT.1990.125976
   Nayar S. K., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P302, DOI 10.1109/CVPR.1992.223259
   Negi A, 2021, Agricultural informatics: automation using the IoT and machine learning, ppp117
   Negi A, 2021, BIG DATA ANAL 9 INT, V9, ppp296
   Negi A., 2021, Computational Intelligence and Healthcare Informatics, P255
   Negi A., 2021, Data Science and Its Applications, P63
   Onogi S, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10161870
   Pech-Pacheco JL, 2000, INT C PATT RECOG, P314, DOI 10.1109/ICPR.2000.903548
   Pertuz S, 2013, IMAGE VISION COMPUT, V31, P725, DOI 10.1016/j.imavis.2013.07.005
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Salahuddin Z, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105111
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Shen C, 2006, INT EL DEVICES MEET, P69
   Shim SO, 2022, MICROSC RES TECHNIQ, V85, P940, DOI 10.1002/jemt.23963
   Shim SO, 2009, MICROSC RES TECHNIQ, V72, P362, DOI 10.1002/jemt.20662
   Shirvaikar MV, 2004, SE SYM SYS THRY, P472
   Surh J, 2017, PROC CVPR IEEE, P2444, DOI 10.1109/CVPR.2017.262
   Tan W, 2020, NEURAL COMPUT APPL, DOI 10.1007/s00521-020-05173-2
   Tang JJ, 2019, MEASUREMENT, V133, P495, DOI 10.1016/j.measurement.2018.10.006
   Thelen A, 2009, IEEE T IMAGE PROCESS, V18, P151, DOI 10.1109/TIP.2008.2007049
   Tsai DC, 2016, IEEE T IMAGE PROCESS, V25, P818, DOI 10.1109/TIP.2015.2509427
   Tseng CY, 2014, IEEE T CIRC SYST VID, V24, P2063, DOI 10.1109/TCSVT.2014.2358873
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Wang KP, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082169
   Wang WG, 2022, Arxiv, DOI arXiv:2209.07383
   Wee CY, 2007, INFORM SCIENCES, V177, P2533, DOI 10.1016/j.ins.2006.12.023
   Xie H, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P229, DOI 10.1109/IROS.2006.282641
   Xie H, 2007, MICROSC RES TECHNIQ, V70, P987, DOI 10.1002/jemt.20506
   Yan T, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107065
   Yap PT, 2004, IEE P-VIS IMAGE SIGN, V151, P128, DOI 10.1049/ip-vis:20040395
   Ye FJ, 2019, MULTIMED TOOLS APPL, V78, P14683, DOI 10.1007/s11042-018-6850-3
   Youngeun An, 2008, 2008 Second International Conference on Future Generation Communication and Networking (FGCN), P46, DOI 10.1109/FGCN.2008.139
NR 84
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-16721-y
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200016
DA 2024-07-18
ER

PT J
AU Singh, VK
   Kumar, N
   Nand, P
AF Singh, Vivek Kumar
   Kumar, Nitin
   Nand, Parma
TI Region-based feature combination for robust salient object detection
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Salient features; Fusion; Region-based weight; Saliency; Optimization
AB The diversity of natural images in terms of visual features is useful in saliency detection. The complementary visual features jointly improve the performance of salient object detection. In this paper, we introduce a novel region-based feature combination approach that utilizes the diversity of visual features over image regions for robust salient object detection. The proposed approach works in four steps: (i) region formation, (ii) feature extraction, (iii) region-wise weight learning and (iv) region-based feature combination. Region formation is carried out using simple linear iterative clustering (SLIC) algorithm. Then, the features are extracted using Boundary Connectivity (BC), Contrast Cluster (CC), and Minimum Directional Contrast (MDC) methods. These features are then used for learning weights vectors for each region. Our major contribution is in step four where a novel dynamic weighted feature combination method is proposed. In this step region-wise integration weights are obtained by using a nature inspirited optimization algorithm called Constrained Particle swarm optimization (CPSO). Then salient features are region-wise combined with their dynamic relevance for final saliency map. The proposed method is compared with eight state-of-the-art saliency detection methods on five public available saliency benchmark datasets namely MSRA10K, DUT-OMRON, ECSSD, PASCAL, and SED2. The experimental results demonstrate that the proposed method performs better than state-of-the-art methods in terms of Precision, Recall, F-measure and Mean Absolute Error while comparable in terms of AUC and ROC curve.
C1 [Singh, Vivek Kumar; Nand, Parma] Sharda Univ, Dept Comp Sci Engn, Greater Noida, Uttar Pradesh, India.
   [Kumar, Nitin] Punjab Engn Coll, Dept Comp Sci & Engn, Chandigarh, India.
C3 Sharda University; Punjab Engineering College (Deemed University)
RP Singh, VK (corresponding author), Sharda Univ, Dept Comp Sci Engn, Greater Noida, Uttar Pradesh, India.
EM singh.vivekrajput@gmail.com; nitink@pec.edu.in; parma.nand@sharda.ac.in
CR Achanta R., 2010, EPFL Technical Report 149300, V6, P15
   Alpert S, 2007, PROC CVPR IEEE, P359
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Gao H., 2022, IEEE T NEURAL NETWOR
   Gao HH, 2022, IEEE T COMPUT SOC SY, V9, P336, DOI 10.1109/TCSS.2021.3102591
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Hou XD, 2007, PROC CVPR IEEE, P2280
   Huang XM, 2017, IEEE T IMAGE PROCESS, V26, P4243, DOI 10.1109/TIP.2017.2710636
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Li XL, 2020, IEEE T IMAGE PROCESS, V29, P9165, DOI 10.1109/TIP.2020.3023774
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Murray N, 2011, PROC CVPR IEEE, P433, DOI 10.1109/CVPR.2011.5995506
   Nouri F, 2018, SIGNAL IMAGE VIDEO P, V12, P659, DOI 10.1007/s11760-017-1205-5
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shen XH, 2012, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.2012.6247758
   Simon D, 2008, IEEE T EVOLUT COMPUT, V12, P702, DOI 10.1109/TEVC.2008.919004
   Singh N, 2014, PATTERN RECOGN, V47, P1731, DOI 10.1016/j.patcog.2013.11.012
   Singh VK, 2021, SIGNAL IMAGE VIDEO P, V15, P1777, DOI 10.1007/s11760-021-01917-2
   Wang F, 2021, NEUROCOMPUTING, V458, P33, DOI 10.1016/j.neucom.2021.03.131
   Wang JD, 2017, INT J COMPUT VISION, V123, P251, DOI 10.1007/s11263-016-0977-3
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang YZ, 2019, SIGNAL IMAGE VIDEO P, V13, P1603, DOI 10.1007/s11760-019-01507-3
   Wang ZC, 2016, APPL INTELL, V45, P1, DOI 10.1007/s10489-015-0739-x
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang F, 2015, IEEE T GEOSCI REMOTE, V53, P2175, DOI 10.1109/TGRS.2014.2357078
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zhu XZ, 2018, NEUROCOMPUTING, V312, P239, DOI 10.1016/j.neucom.2018.05.106
NR 34
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 28
PY 2023
DI 10.1007/s11042-023-17083-1
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T2WM7
UT WOS:001076639200002
DA 2024-07-18
ER

PT J
AU Soltani, H
   Amroune, M
   Bendib, I
   Haouam, MY
   Benkhelifa, E
   Fraz, MM
AF Soltani, Hama
   Amroune, Mohamed
   Bendib, Issam
   Haouam, Mohamed-Yassine
   Benkhelifa, Elhadj
   Fraz, Muhammad Moazam
TI Breast lesions segmentation and classification in a two-stage process
   based on Mask-RCNN and Transfer Learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Breast Cancer; Lesion Detection and Classification; Deep Learning;
   Transfer Learning; Mask-RCNN
ID COMPUTER-AIDED DIAGNOSIS; MAMMOGRAMS; FULL
AB The most prevalent malignancy of concern among women is breast cancer. Early detection plays a crucial role in improving survival chances. However, the current reliance on mammography for breast cancer detection has limitations due to the delicate nature of breast tissue, human visual system constraints, and variations in accumulated experience, leading to significant false positive and false negative results. This study aims to minimize these errors by developing an intelligent computer-based diagnosis method for breast cancer utilizing digital mammography, employing the Transfer Learning approach. The proposed technique involves two stages. In the first stage, we fine-tune the pre-trained Mask R-CNN model on the COCO dataset to identify and segment breast lesions. In the second stage, various convolutional Deep Learning models such as ResNet101, ResNet34, VGG16, VGG19, AlexNet, and DenseNet121 classify the segmented lesions as benign or malignant. The lesion detection and segmentation stages achieved an average precision of 96.26%, while breast lesion classification using the DenseNet121 model obtained 99.44% accuracy on the INbreast dataset. An additional benefit of this study is the development of a new dataset extracted from the INbreast dataset, containing solely lesion images. This novel dataset reduces storage capacity and computational complexity during Deep neural network training and testing as it avoids the use of entire images. Moreover, the lesion dataset holds potential for use in breast cancer diagnosis research and may be integrated into an advanced computer-assisted diagnostic system for breast cancer screening.
C1 [Soltani, Hama; Amroune, Mohamed; Bendib, Issam; Haouam, Mohamed-Yassine] Echahid Cheikh Laarbi Tbessi Univ, LAMIS Lab, Tebessa, Algeria.
   [Benkhelifa, Elhadj] Staffordshire Univ, Stoke On Trent, England.
   [Fraz, Muhammad Moazam] Natl Univ Sci & Technol NUST, Islamabad, Pakistan.
   [Fraz, Muhammad Moazam] Alan Turing Inst, 96 Euston Rd, London NW12DB, England.
C3 Staffordshire University; National University of Sciences & Technology -
   Pakistan
RP Soltani, H (corresponding author), Echahid Cheikh Laarbi Tbessi Univ, LAMIS Lab, Tebessa, Algeria.
EM hama.soltani@univ-tebessa.dz; mohamed.amroune@univ-tebessa.dz;
   issam.bendib@univ-tebessa.dz; mohamed-yassine.haouam@univ-tebessa.dz;
   e.benkhelifa@staffs.ac.uk; moazam.fraz@seecs.edu.pk
RI HAOUAM, Mohamed Yassine/KFT-1015-2024; Amroune, Pr.Mohamed/HGC-7134-2022
OI Amroune, Pr.Mohamed/0000-0002-4252-4561; Haouam, Mohamed
   Yassine/0000-0001-8989-6656; soltani, hama/0000-0001-7256-7100
FU This work is related to a research project of a mixed team of
   researchers titled "Intelligence Artificielle au Service de la detection
   du cancer du sein" at the Echahid Cheikh Laarbi tebessi University,
   Tebessa-Algeria.; Service de la detection du cancer du sein" at the
   Echahid Cheikh Laarbi tebessi University
FX This work is related to a research project of a mixed team of
   researchers titled "Intelligence Artificielle au Service de la detection
   du cancer du sein" at the Echahid Cheikh Laarbi tebessi University,
   Tebessa-Algeria.
CR Abdelhafiz D, 2020, BMC BIOINFORMATICS, V21, DOI 10.1186/s12859-020-3521-y
   Agarwal R, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103774
   Ahmed L, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01680-1
   Al-antari MA, 2020, ADV EXP MED BIOL, V1213, P59, DOI 10.1007/978-3-030-33128-3_4
   Al-antari MA, 2018, INT J MED INFORM, V117, P44, DOI 10.1016/j.ijmedinf.2018.06.003
   Baccouche A, 2021, NPJ BREAST CANCER, V7, DOI 10.1038/s41523-021-00358-x
   Basu AK, 2018, INT J MOL SCI, V19, DOI 10.3390/ijms19040970
   Casado-García A, 2019, BMC BIOINFORMATICS, V20, DOI 10.1186/s12859-019-2931-1
   Chakraborty Aditya, 2021, Proceedings of 5th International Conference on Computing Methodologies and Communication (ICCMC 2021), P1624, DOI 10.1109/ICCMC51019.2021.9418042
   Ekpo Ernest Usang, 2018, Asian Pac J Cancer Prev, V19, P291, DOI 10.22034/APJCP.2018.19.2.291
   Guo ZC, 2022, OPEN LIFE SCI, V17, P1600, DOI 10.1515/biol-2022-0517
   Hamed G, 2021, IEEE ACCESS, V9, P116898, DOI 10.1109/ACCESS.2021.3105924
   Hassan NM, 2022, MULTIMED TOOLS APPL, V81, P20043, DOI 10.1007/s11042-022-12332-1
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hekal AA, 2021, SIGNAL IMAGE VIDEO P, V15, P1497, DOI 10.1007/s11760-021-01882-w
   Howard J, 2020, INFORMATION, V11, DOI 10.3390/info11020108
   Jalloul R, 2023, DIAGNOSTICS, V13, DOI 10.3390/diagnostics13142460
   Jung H, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0203355
   L‚vy D, 2016, Arxiv, DOI arXiv:1612.00542
   Maxim LD, 2014, INHAL TOXICOL, V26, P811, DOI 10.3109/08958378.2014.955932
   Michael E, 2021, BIOMED RES INT-UK, V2021, DOI 10.1155/2021/9962109
   Moreira IC, 2012, ACAD RADIOL, V19, P236, DOI 10.1016/j.acra.2011.09.014
   Sheba KU, 2018, COGENT ENG, V5, DOI 10.1080/23311916.2018.1444320
   Siegel RL, 2021, CA-CANCER J CLIN, V71, P7, DOI [10.3322/caac.21387, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21601, 10.3322/caac.21254, 10.3322/caac.21654, 10.3322/caac.20006, 10.3322/caac.21551]
   Soltani H, 2021, 2021 INT C REC ADV M, P1
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu Y, 2022, IET OPTOELECTRON, V16, P257, DOI 10.1049/ote2.12070
   Zhu ZQ, 2023, CMES-COMP MODEL ENG, V136, P2127, DOI 10.32604/cmes.2023.025484
NR 28
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16895-5
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000019
DA 2024-07-18
ER

PT J
AU Zhang, ZW
   Xiao, WE
   Liu, TF
   Li, Y
   Jin, SH
   Li, FF
   Wang, HY
AF Zhang, Zhengwei
   Xiao, Weien
   Liu, Tianfu
   Li, Yao
   Jin, Shenghua
   Li, Fenfen
   Wang, Hongya
TI A reversible image watermarking algorithm for tamper detection based on
   SIFT
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Tamper localization; Reversible image watermarking; SIFT
   (Scale-invariant feature transform); Invariant distance; Authentication
   watermark
ID RECOVERY; AUTHENTICATION; SCHEME; SYSTEM
AB The integrity of the digital image content is very important for special types of images. To better locate tampered regions in the image, this paper proposes a reversible watermarking technology for tamper localization based on SIFT. By dividing the original image into blocks, the feature information of each sub-block is computed as the authentication watermark. The carrier image is then processed to extract the feature region of the image, and the authentication watermark generated by each sub-block is embedded into the corresponding feature region through mapping. When the watermarked image is attacked, the related attack is detected by the invariant moment, and the sub-block feature value and the authentication watermark extracted from the feature region are calculated to determine if the sub-block has been tampered with, and if so, the position of the tampered region is given. The experimental result illustrates this scheme can detect and locate the tamper region effectively and accurately, and the scheme has certain robustness and invisibility.
C1 [Zhang, Zhengwei; Xiao, Weien; Liu, Tianfu; Li, Yao; Jin, Shenghua; Li, Fenfen; Wang, Hongya] Huaiyin Inst Technol, Fac Comp & Software Engn, Huaian 223003, Jiangsu, Peoples R China.
C3 Huaiyin Institute of Technology
RP Zhang, ZW (corresponding author), Huaiyin Inst Technol, Fac Comp & Software Engn, Huaian 223003, Jiangsu, Peoples R China.
EM zzw49010650@sina.com
RI li, fang/KDO-8841-2024; zou, yao/KCK-8222-2024; chen,
   huan/KEC-2019-2024; wang, rong/KFQ-7187-2024; Liu, Zhen/KFS-2748-2024;
   Zhao, Hang/KCL-7278-2024; wang, haoyu/KHY-6295-2024; Wang,
   Ling/KBA-9814-2024; Wang, Ling/AGR-4917-2022; Ma, Wei/JXY-5019-2024;
   Wang, Yuhan/KGL-5855-2024; yan, su/KHT-1728-2024; Li,
   Chun/KBC-9591-2024; YANG, DAN/KCL-5217-2024; WANG, YUHAO/KBB-0213-2024;
   Zhou, Xinyi/KGM-6689-2024; CAO, ying/KFA-2972-2024; Wang,
   Siying/KHX-1894-2024; Liu, Chang/KGL-6678-2024; xie, jing/KDO-9486-2024;
   Wang, Yifan/KDO-8319-2024; Sun, Yang/KHY-5117-2024; Wang,
   YuHan/KGY-2933-2024; liu, zhen/KFS-0275-2024; Li, Fan/KBB-8931-2024
OI wang, haoyu/0009-0001-2467-5331; Wang, Ling/0000-0003-0272-2974; Wang,
   Ling/0000-0003-0272-2974; Ma, Wei/0000-0002-7344-998X; Zhang,
   Zhengwei/0000-0002-3207-0586
FU This work is supported by National Statistical Science Research Project
   (2018LY12). At the same time this work is also supported by the Opening
   Project of GuangDong Province Key Laboratory of Information Security
   Technology (2020B1212060078). [2018LY12]; National Statistical Science
   Research Project [2020B1212060078]; Opening Project of GuangDong
   Province Key Laboratory of Information Security Technology
FX This work is supported by National Statistical Science Research Project
   (2018LY12). At the same time this work is also supported by the Opening
   Project of GuangDong Province Key Laboratory of Information Security
   Technology (2020B1212060078).
CR Ansari IA, 2016, INT J MACH LEARN CYB, V7, P1225, DOI 10.1007/s13042-015-0455-1
   Chiang KH, 2008, J DIGIT IMAGING, V21, P77, DOI 10.1007/s10278-007-9012-0
   Dadkhah S, 2014, SIGNAL PROCESS-IMAGE, V29, P1197, DOI 10.1016/j.image.2014.09.001
   Fang YX, 2022, MULTIMED TOOLS APPL, V81, P16863, DOI 10.1007/s11042-022-12592-x
   Farid H, 2009, IEEE T INF FOREN SEC, V4, P154, DOI 10.1109/TIFS.2008.2012215
   Gao GY, 2018, IEEE SIGNAL PROC LET, V25, P1099, DOI 10.1109/LSP.2018.2844562
   Gong XH, 2020, MULTIMED TOOLS APPL, V79, P18071, DOI 10.1007/s11042-019-08594-x
   Gul E, 2019, MULTIMED TOOLS APPL, V78, P17701, DOI 10.1007/s11042-018-7084-0
   Gull S, 2020, J AMB INTEL HUM COMP, V11, P1799, DOI 10.1007/s12652-018-1158-8
   Hong WE, 2017, SIGNAL PROCESS-IMAGE, V58, P111, DOI 10.1016/j.image.2017.07.001
   Hu YC, 2017, MULTIMED TOOLS APPL, V76, P15435, DOI 10.1007/s11042-016-3847-7
   Huo YR, 2014, MULTIMED TOOLS APPL, V72, P123, DOI 10.1007/s11042-012-1317-4
   Hurrah NN, 2019, FUTURE GENER COMP SY, V94, P654, DOI 10.1016/j.future.2018.12.036
   Li CL, 2012, COMPUT STAND INTER, V34, P367, DOI 10.1016/j.csi.2012.01.003
   Lin CC, 2017, MULTIMED TOOLS APPL, V76, P463, DOI 10.1007/s11042-015-3059-6
   Nazari M, 2017, MULTIMED TOOLS APPL, V76, P16107, DOI 10.1007/s11042-016-3897-x
   Pal P, 2019, SECUR PRIVACY, V2, DOI 10.1002/spy2.59
   Phadikar A, 2012, J VIS COMMUN IMAGE R, V23, P454, DOI 10.1016/j.jvcir.2012.01.005
   Prasad S, 2020, MULTIMED TOOLS APPL, V79, P1673, DOI 10.1007/s11042-019-08144-5
   Raj NRN, 2021, MULTIMED TOOLS APPL, V80, P19307, DOI 10.1007/s11042-021-10664-y
   Sahu AK, 2023, MULTIMED TOOLS APPL, V82, P24069, DOI 10.1007/s11042-022-13630-4
   Sahu AK, 2023, PATTERN ANAL APPL, V26, P571, DOI 10.1007/s10044-022-01104-0
   Sahu AK, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03365-9
   Singh D, 2016, J VIS COMMUN IMAGE R, V38, P775, DOI 10.1016/j.jvcir.2016.04.023
   Su GD, 2021, MULTIMED TOOLS APPL, V80, P12881, DOI 10.1007/s11042-020-10451-1
   Swaraja K., 2021, Biomed Signal Process Control, V55, P1
   Trivedy S, 2017, IJST-T ELECTR ENG, V41, P103, DOI 10.1007/s40998-017-0021-9
   Xiang YP, 2019, SIGNAL PROCESS, V162, P282, DOI 10.1016/j.sigpro.2019.04.022
   Zhang ZW, 2023, MULTIMED TOOLS APPL, V82, P11005, DOI 10.1007/s11042-022-13770-7
   Zhang ZW, 2018, ARAB J SCI ENG, V43, P979, DOI 10.1007/s13369-017-2898-z
   Zhang ZW, 2017, INT J DISTRIB SENS N, V13, DOI 10.1177/1550147716686577
NR 31
TC 0
Z9 0
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 27
PY 2023
DI 10.1007/s11042-023-16976-5
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T1YW6
UT WOS:001076019000015
DA 2024-07-18
ER

PT J
AU Amrish
   Arya, S
   Kumar, S
AF Amrish
   Arya, Shwetank
   Kumar, Saurabh
TI Convolutional neural network for human crowd analysis: a review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review; Early Access
DE CNN; Human Crowd Analysis; Density Estimation
ID DENSITY-ESTIMATION; MANAGEMENT; MODEL; PREDICTION; PEOPLE
AB This research paper presents a review of the use of convolutional neural networks (CNNs) for human crowd analysis. The paper discusses the challenges and limitations of methods and highlights the potential of CNNs in addressing these limitations. This study reveals and provides an in-depth analysis of the different techniques, architectures, and algorithms used in CNNs for human crowd analysis and their respective advantages and limitations. Additionally, the paper discusses the potential applications of CNNs in crowd analysis, including pedestrian detection, crowd counting, and crowd behavior recognition. The review also provides insights into the performance evaluation metrics commonly used in this area and the datasets used for training and testing CNNs. Overall, this review provides a comprehensive overview of the latest developments in the use of CNNs for human crowd analysis, as well as insights into future research directions in this field.
C1 [Amrish; Arya, Shwetank] Gurukula Kangri, Dept Comp Sci, Haridwar, Uttaranchal, India.
   [Kumar, Saurabh] Noida Int Univ, Dept Biotechnol, Greater Noida, Uttar Pradesh, India.
C3 Gurukul Kangri Vishwavidyalaya; Noida International University
RP Amrish (corresponding author), Gurukula Kangri, Dept Comp Sci, Haridwar, Uttaranchal, India.
EM rs.amrishkumar@gkv.ac.in
RI Arya, Shwetank/KVB-6680-2024
OI Arya, Shwetank/0000-0002-9123-9388; , Amrish/0000-0002-3023-5922
FU The authors extend our gratitude to Haridwar Administration,
   Uttarakhand, India for providing Kumbh Mela 2010 data in form of videos
   and images and giving permission to collect raw data in Kumbh Mela 2021
   for this research work.
FX The authors acknowledge that this research work has been funded through
   the project number UCS&T/R&D-09/19-20/17533 titled "An Intelligent
   Computational Model for Crowd Demonstration and Risk Analysis during
   Spiritual Events in Haridwar" by the Uttarakhand Council for Science and
   Technology (UCOST), India.r The authors are grateful to the
   SuperAnnotate team for providing a free subscription to the
   SuperAnnotate Pro version for 6 months for the annotation work of this
   research.r The authors extend our gratitude to Haridwar Administration,
   Uttarakhand, India for providing Kumbh Mela 2010 data in form of videos
   and images and giving permission to collect raw data in Kumbh Mela 2021
   for this research work.
CR Aich S, 2018, Arxiv, DOI arXiv:1803.05494
   Albattah W, 2021, CMC-COMPUT MATER CON, V66, P2183, DOI 10.32604/cmc.2020.014227
   Alginahi YM, 2019, ARAB J SCI ENG, V44, P3289, DOI 10.1007/s13369-018-3411-z
   Almagbile A, 2019, GEO-SPAT INF SCI, V22, P23, DOI 10.1080/10095020.2018.1539553
   Alotibi MH., 2019, Procedia Comput. Sci, V163, P134
   Amirgholipour S, 2021, NEUROCOMPUTING, V451, P215, DOI 10.1016/j.neucom.2021.04.037
   Anees VM, 2018, PROCEEDINGS OF THE 2018 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2018), P16, DOI 10.1109/ISED.2018.8704051
   [Anonymous], 2013, Modeling, Simulation and Visual Analysis of Crowds: A Multidisciplinary Perspective
   [Anonymous], 2006, COMPUTER VISION PATT, DOI 10.1109/CVPR.2006.92
   Arteta C, 2016, LECT NOTES COMPUT SC, V9911, P483, DOI 10.1007/978-3-319-46478-7_30
   Bansod VL., 2020, Int J Recent Technol Eng., V8, P1113, DOI [10.35940/ijrte.e6283.018520, DOI 10.35940/IJRTE.E6283.018520]
   Basalamah S, 2019, IEEE ACCESS, V7, P71576, DOI 10.1109/ACCESS.2019.2918650
   Bharti Yashna, 2019, Information and Communication Technology for Intelligent Systems. Proceedings of ICTIS 2018. Smart Innovation, Systems and Technologies (SIST 106), P545, DOI 10.1007/978-981-13-1742-2_54
   Boominathan L, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P640, DOI 10.1145/2964284.2967300
   Bour P, 2019, COMPUT VIS PATT REC, P289, DOI 10.1016/B978-0-12-814601-9.00023-7
   Brostow G.J., 2006, CVPR, P594, DOI DOI 10.1109/CVPR.2006.320
   Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chan AB, 2008, PROC CVPR IEEE, P1766, DOI 10.1109/cvpr.2008.4587569
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Chan AB, 2009, IEEE I CONF COMP VIS, P545, DOI 10.1109/ICCV.2009.5459191
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Chen K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.21
   Chen XY, 2020, NEUROCOMPUTING, V407, P399, DOI 10.1016/j.neucom.2020.04.117
   Cheng ZW, 2014, NEUROCOMPUTING, V136, P124, DOI 10.1016/j.neucom.2014.01.019
   Choudhary S, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P936, DOI 10.1109/ICCONS.2017.8250602
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding XH, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1942, DOI 10.1109/ICASSP.2018.8461772
   Dong Li, 2024, IEEE Trans Neural Netw Learn Syst, V35, P6408, DOI 10.1109/TNNLS.2022.3209918
   Dou YM, 2019, CHIN CONT DECIS CONF, P653, DOI [10.1109/ccdc.2019.8833188, 10.1109/CCDC.2019.8833188]
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fang YY, 2020, NEUROCOMPUTING, V392, P98
   Fradi H, 2017, IEEE T CIRC SYST VID, V27, P589, DOI 10.1109/TCSVT.2016.2615443
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Fu M, 2015, ENG APPL ARTIF INTEL, V43, P81, DOI 10.1016/j.engappai.2015.04.006
   Gao JY, 2021, IEEE T CYBERNETICS, V51, P4822, DOI 10.1109/TCYB.2020.3034316
   Gao ML, 2019, CHIN CONT DECIS CONF, P5329, DOI [10.1109/ccdc.2019.8832598, 10.1109/CCDC.2019.8832598]
   Gnouma Mariem, 2020, International Joint Conference: 12th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2019) and 10th International Conference on EUropean Transnational Education (ICEUTE 2019). Proceedings. Advances in Intelligent Systems and Computing (AISC 951), P87, DOI 10.1007/978-3-030-20005-3_9
   He GQ, 2019, IEEE INT CON MULTI, P1120, DOI 10.1109/ICME.2019.00196
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu XM, 2015, OPTIK, V126, P123, DOI 10.1016/j.ijleo.2014.08.132
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Idrees H, 2013, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2013.329
   Ilyas N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010043
   Jiang XH, 2020, IEEE T NEUR NET LEAR, V31, P2705, DOI 10.1109/TNNLS.2019.2933920
   Kang D, 2020, INT J COMPUT VISION, V128, P2897, DOI 10.1007/s11263-020-01345-8
   Kang D, 2019, IEEE T CIRC SYST VID, V29, P1408, DOI 10.1109/TCSVT.2018.2837153
   Karpagavalli P, 2017, MULTIMED TOOLS APPL, V76, P14129, DOI 10.1007/s11042-016-3777-4
   Khan SD, 2019, IEEE IMAGE PROC, P4474, DOI [10.1109/icip.2019.8803409, 10.1109/ICIP.2019.8803409]
   Khozium MO, 2012, LIFE SCI J, V9, P277
   Kumagai S, 2017, Arxiv, DOI arXiv:1703.09393
   Lamba S., 2017, Adv Comput Comput Sci, V1, P21, DOI [10.1007/978-981-10-3770-23, DOI 10.1007/978-981-10-3770-23]
   Laradji IH, 2018, LECT NOTES COMPUT SC, V11206, P560, DOI 10.1007/978-3-030-01216-8_34
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li T, 2015, IEEE T CIRC SYST VID, V25, P367, DOI 10.1109/TCSVT.2014.2358029
   Li ZQ, 2016, 8TH INTERNATIONAL CONFERENCE ON INTERNET MULTIMEDIA COMPUTING AND SERVICE (ICIMCS2016), P57, DOI 10.1145/3007669.3007745
   Liang DK, 2023, IEEE T MULTIMEDIA, V25, P6040, DOI 10.1109/TMM.2022.3203870
   Liang DK, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3445-y
   Liu LB, 2021, PROC CVPR IEEE, P4821, DOI 10.1109/CVPR46437.2021.00479
   Liu S., 2022, P ACM SIGSAC C COMP, P2055, DOI DOI 10.1145/3548606.3560566
   Liu XL, 2019, IEEE T PATTERN ANAL, V41, P1862, DOI 10.1109/TPAMI.2019.2899857
   Liu YT, 2020, IEEE T IMAGE PROCESS, V29, P6800, DOI 10.1109/TIP.2020.2994410
   Loh YP, 2019, COMPUT VIS IMAGE UND, V178, P30, DOI 10.1016/j.cviu.2018.10.010
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo A, 2020, AAAI CONF ARTIF INTE, V34, P11693
   Marsden Mark, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078482
   Marsden M, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P27, DOI 10.5220/0006097300270033
   Martella C, 2017, SAFETY SCI, V91, P381, DOI 10.1016/j.ssci.2016.09.006
   Mohamed SAE, 2019, PROCEEDINGS OF 2019 INTERNATIONAL CONFERENCE ON INNOVATIVE TRENDS IN COMPUTER ENGINEERING (ITCE 2019), P260, DOI [10.1109/itce.2019.8646529, 10.1109/ITCE.2019.8646529]
   Moosmann F, 2007, Adv Neural Inf Process Syst, P985
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Mundhenk TN, 2016, LECT NOTES COMPUT SC, V9907, P785, DOI 10.1007/978-3-319-46487-9_48
   Nasser N, 2017, P 2017 INT C WIR NET, DOI [10.1109/WINCOM.2017.8238202, DOI 10.1109/WINCOM.2017.8238202]
   Olmschenk G, 2019, COMPUT VIS IMAGE UND, V186, P1, DOI 10.1016/j.cviu.2019.06.004
   Oñoro-Rubio D, 2016, LECT NOTES COMPUT SC, V9911, P615, DOI 10.1007/978-3-319-46478-7_38
   Palanisamy G, 2017, 2017 INTERNATIONAL CONFERENCE ON TECHNICAL ADVANCEMENTS IN COMPUTERS AND COMMUNICATIONS (ICTACC), P11, DOI 10.1109/ICTACC.2017.14
   Paragios N, 2001, PROC CVPR IEEE, P1034
   Pu SL, 2017, PROCEDIA COMPUT SCI, V111, P154, DOI 10.1016/j.procs.2017.06.022
   Rao AS, 2016, ADV INTELL SYST, V425, P407, DOI 10.1007/978-3-319-28658-7_35
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Regina Lourdhu Suganthi S, 2018, ICSNS 2018 P IEEE IN, V7, P614, DOI [10.1109/ICSNS.2018.8573655, DOI 10.1109/ICSNS.2018.8573655]
   Rodriguez M, 2011, IEEE I CONF COMP VIS, P2423, DOI 10.1109/ICCV.2011.6126526
   Ryan D, 2015, COMPUT VIS IMAGE UND, V130, P1, DOI 10.1016/j.cviu.2014.07.008
   Sadiq FI, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050487
   Saeed SN, 2016, IEEE INT CONF INNOV, P111
   Sajid U, 2020, IEEE T CIRC SYST VID, V30, P3499, DOI 10.1109/TCSVT.2020.2978717
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Sang J, 2019, IEEE ACCESS, V7, P24411, DOI 10.1109/ACCESS.2019.2899939
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Shehzed Ahsan, 2019, 2019 International Conference on Applied and Engineering Mathematics (ICAEM), P163, DOI 10.1109/ICAEM.2019.8853756
   Sheng BY, 2018, IEEE T CIRC SYST VID, V28, P1788, DOI 10.1109/TCSVT.2016.2637379
   Shi ZL, 2018, IEEE T IND INFORM, V14, P4953, DOI 10.1109/TII.2018.2852481
   Sindagi VA, 2017, 2017 14TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS)
   Sindagi VA, 2022, IEEE T PATTERN ANAL, V44, P2594, DOI 10.1109/TPAMI.2020.3035969
   Sindagi VA, 2019, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2019.00131
   Sindagi VA, 2020, IEEE T IMAGE PROCESS, V29, P323, DOI 10.1109/TIP.2019.2928634
   Sindagi VA, 2018, PATTERN RECOGN LETT, V107, P3, DOI 10.1016/j.patrec.2017.07.007
   Sreenu G, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0212-5
   Sivakumar ANV, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12132136
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Walach E, 2016, LECT NOTES COMPUT SC, V9906, P660, DOI 10.1007/978-3-319-46475-6_41
   Wan J, 2021, IEEE T IMAGE PROCESS, V30, P2114, DOI 10.1109/TIP.2021.3049938
   Wang C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1299, DOI 10.1145/2733373.28063370-12345-67-8/90/01
   Wang HB, 2014, J MED IMAGING, V1, DOI 10.1117/1.JMI.1.3.034003
   Wang J., 2015, IET Semin Dig, V2015, P2, DOI [10.1049/ic.2015.0102, DOI 10.1049/IC.2015.0102]
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang Q, 2021, INT J COMPUT VISION, V129, DOI 10.1007/s11263-020-01365-4
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang Y, 2016, IEEE IMAGE PROC, P3653, DOI 10.1109/ICIP.2016.7533041
   Wang Z, 2019, BR MACH VIS C 2018
   Wei XL, 2019, PATTERN RECOGN LETT, V119, P12, DOI 10.1016/j.patrec.2017.12.002
   Wen D., 2019, arXiv
   Xiang J, 2022, SCI PROGRAMMING-NETH, V2022, DOI 10.1155/2022/1990951
   Xu FC, 2017, 2017 INTERNATIONAL CONFERENCE ON SECURITY, PATTERN ANALYSIS, AND CYBERNETICS (SPAC), P219, DOI 10.1109/SPAC.2017.8304279
   Yang B, 2020, NEUROCOMPUTING, V390, P207, DOI 10.1016/j.neucom.2019.02.071
   Yang M, 2018, 2018 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P346
   Yang YF, 2021, IEEE T IMAGE PROCESS, V30, P1395, DOI 10.1109/TIP.2020.3043122
   Yutao Hu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P747, DOI 10.1007/978-3-030-58542-6_45
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang Q, 2019, PROC CVPR IEEE, P8289, DOI 10.1109/CVPR.2019.00849
   Zhang YJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071196
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhang YM, 2019, NEUROCOMPUTING, V329, P144, DOI 10.1016/j.neucom.2018.10.058
   Zhao ZY, 2016, LECT NOTES COMPUT SC, V9912, P712, DOI 10.1007/978-3-319-46484-8_43
   Zheng HC, 2019, IEEE T CIRC SYST VID, V29, P787, DOI 10.1109/TCSVT.2018.2807806
   Zhong X, 2022, IEEE SIGNAL PROC LET, V29, P1794, DOI 10.1109/LSP.2022.3198371
   Zhu F, 2014, LECT NOTES COMPUT SC, V8694, P139, DOI 10.1007/978-3-319-10599-4_10
   Zitouni MS, 2016, NEUROCOMPUTING, V186, P139, DOI 10.1016/j.neucom.2015.12.070
   Zou ZK, 2018, IEEE ACCESS, V6, P60745, DOI 10.1109/ACCESS.2018.2875495
NR 131
TC 0
Z9 0
U1 9
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 SEP 25
PY 2023
DI 10.1007/s11042-023-16841-5
EA SEP 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA T0WG5
UT WOS:001075272400012
DA 2024-07-18
ER

PT J
AU Ghosh, R
AF Ghosh, Rajib
TI Newspaper text recognition in Bengali script using support vector
   machine
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Newspaper text recognition; Bengali script; Support vector machine
ID HANDWRITTEN WORD RECOGNITION; OCR SYSTEM; DEVANAGARI
AB Newspapers contain huge amount of important information on current affairs as well as notable past events. Browsing the digital versions of newspaper documents will become much easier if the documents are indexed or transcribed. To enable the automatic transcription, some computer based systems need to be developed for automatic recognition of newspaper text. However, no such recognition system exists for Bengali script, the second most popular Indian script. This article proposes a newspaper text recognition system in Bengali script for the first time in the literature. Initially, each newspaper article is segmented into image and text portions. Then the text document is segmented into various text lines, then each text line into various words and each word into various characters. Various discriminating features have then been extracted from each character using different feature extraction techniques. The feature vector of each character has then been fed to the support vector machine (SVM) classifier to recognize each character of the newspaper document image. The performance of the proposed system has been evaluated on a self-generated dataset and it provides a text recognition accuracy of 97.78%.
C1 [Ghosh, Rajib] Natl Inst Technol Patna, Dept Comp Sci & Engn, Ashok Rajpath, Patna 800005, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Ghosh, R (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Ashok Rajpath, Patna 800005, India.
EM rajib.ghosh@nitp.ac.in
RI GHOSH, RAJIB/C-9927-2017
OI GHOSH, RAJIB/0000-0002-8553-8656
CR Ahmad I, 2016, PATTERN RECOGN, V51, P97, DOI 10.1016/j.patcog.2015.09.011
   Ait-Mohand K, 2014, IEEE T PATTERN ANAL, V36, P1716, DOI 10.1109/TPAMI.2014.2306423
   Ali S, 2023, IEEE T NETW SERV MAN, V20, P1199, DOI 10.1109/TNSM.2022.3200741
   Amin A, 2000, PATTERN RECOGN, V33, P1309, DOI 10.1016/S0031-3203(99)00114-4
   Aparna KG, 2002, LECT NOTES COMPUT SC, V2423, P53
   Ashwin TV, 2002, SADHANA-ACAD P ENG S, V27, P35, DOI 10.1007/BF02703311
   Bazzi I, 1999, IEEE T PATTERN ANAL, V21, P495, DOI 10.1109/34.771314
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   El-Sappagh S, 2022, NEUROCOMPUTING, V512, P203, DOI 10.1016/j.neucom.2022.09.009
   Ghosh R., 2020, RECENT ADV COMPUT SC, V13, P200, DOI [10.2174/2213275912666181127124711, DOI 10.2174/2213275912666181127124711]
   Ghosh R, 2024, MULTIMED TOOLS APPL, V83, P7135, DOI 10.1007/s11042-023-15633-1
   Ghosh R, 2022, EXPERT SYST APPL, V205, DOI 10.1016/j.eswa.2022.117730
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P38643, DOI 10.1007/s11042-022-13068-8
   Ghosh R, 2022, MULTIMED TOOLS APPL, V81, P24245, DOI 10.1007/s11042-022-12767-6
   Ghosh R, 2019, INT J MACH LEARN CYB, V10, P2467, DOI 10.1007/s13042-018-0883-9
   Ghosh R, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114249
   Ghosh R, 2019, SADHANA-ACAD P ENG S, V44, DOI 10.1007/s12046-019-1159-0
   Ghosh R, 2019, PATTERN RECOGN, V92, P203, DOI 10.1016/j.patcog.2019.03.030
   Ghosh R, 2018, INT CONF FRONT HAND, P517, DOI 10.1109/ICFHR-2018.2018.00096
   Ghosh R, 2018, INT J INF SYST MODEL, V9, P21, DOI 10.4018/IJISMD.2018010102
   Ghosh R, 2016, INT CONF FRONT HAND, P435, DOI [10.1109/ICFHR.2016.0087, 10.1109/ICFHR.2016.82]
   Ghosh R, 2015, PROC INT CONF DOC, P401, DOI 10.1109/ICDAR.2015.7333792
   Ghosh R, 2015, 2ND INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN) 2015, P483, DOI 10.1109/SPIN.2015.7095313
   Ghosh R, 2018, ADV EXP MED BIOL, V1049, P1, DOI 10.1007/978-3-319-71779-1_1
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Jindal Amar, 2023, International Journal of Information Technology, P1975, DOI 10.1007/s41870-023-01247-1
   Jindal A, 2023, EXPERT SYST APPL, V225, DOI 10.1016/j.eswa.2023.120127
   Juraev F, 2022, J BIOMED INFORM, V135, DOI 10.1016/j.jbi.2022.104216
   Kaur RP, 2020, MULTIMED TOOLS APPL, V79, P7435, DOI 10.1007/s11042-019-08365-8
   Khawaja A, 2006, 10TH IEEE INTERNATIONAL MULTITOPIC CONFERENCE 2006, PROCEEDINGS, P169
   Khorsheed MS, 2007, PATTERN RECOGN LETT, V28, P1563, DOI 10.1016/j.patrec.2007.03.014
   Kunte RS, 2007, SADHANA-ACAD P ENG S, V32, P521, DOI 10.1007/s12046-007-0039-1
   Lakshmi CV, 2006, LECT NOTES COMPUT SC, V4338, P786
   Lu N, 2021, PATTERN RECOGN, V117, DOI 10.1016/j.patcog.2021.107980
   Mandal M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165571
   Mathew M, 2017, PROC INT CONF DOC, P42, DOI 10.1109/ICDAR.2017.364
   Mukherjee J, 2020, SADHANA-ACAD P ENG S, V45, DOI 10.1007/s12046-020-01492-1
   Prasad R, 2008, INT C PATT RECOG, P769
   Seethalakshmi R., 2005, Journal of Zhejiang University (Science), V6A, P1297, DOI 10.1631/jzus.2005.A1297
   Zhong ZY, 2015, PROC INT CONF DOC, P96, DOI 10.1109/ICDAR.2015.7333733
NR 40
TC 0
Z9 0
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32973
EP 32991
DI 10.1007/s11042-023-16862-0
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400010
DA 2024-07-18
ER

PT J
AU Wang, CX
   Gao, B
   Pan, XO
   Li, ZH
   Ji, Y
   Liu, ST
   Liu, ZJ
AF Wang, Chenxuan
   Gao, Bin
   Pan, Xiaoou
   Li, Zhihui
   Ji, Yu
   Liu, Shutian
   Liu, Zhengjun
TI A dual-color watermarking algorithm based on elliptical monogenic
   wavelet transform and singular value decomposition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dual-color watermarking; Elliptical monogenic wavelet transforms;
   Singular value decomposition; Arnold scrambling
ID CONVOLUTIONAL NEURAL-NETWORK; TEETH; CLASSIFICATION
AB A dual-color watermarking algorithm using elliptical monogenic wavelet transform and singular value decomposition is proposed. Firstly, the original host image and two color watermark images are decomposed into RGB components. Arnold transform is employed to scramble the RGB components of the second watermark image. Secondly, those RGB components of the color host image and two watermark images go through by gray monogenic wavelet transform and an elliptical monogenic wavelet transform. Thirdly, the amplitude and phase are selected as embedded features from the ellipse parameters generated by the host image. The unitary matrix is obtained by singular value decomposition with the amplitude of the first watermark image and the phase of the second watermark image. According to our proposed embedding rules, the watermark is embedded into the unitary matrix. Finally, the watermarked image can be extracted by inverse singular value decomposition and inverse elliptical monogenic wavelet transform. The experimental results show that the proposed algorithm performs very robustly against non-geometric attacks, such as salt & pepper noise, Gaussian noise, median filtering, mean filtering, JPEG compression, and geometric attacks, including rotation, clipping, and translation. Furthermore, our method demonstrates extraordinary performances when compared to related methods in certain aspects.
C1 [Wang, Chenxuan; Gao, Bin; Pan, Xiaoou; Li, Zhihui] Heilongjiang Univ, Coll Data Sci & Technol, Harbin 150080, Peoples R China.
   [Ji, Yu; Liu, Shutian; Liu, Zhengjun] Harbin Inst Technol, Sch Phys, Harbin 150001, Peoples R China.
C3 Heilongjiang University; Harbin Institute of Technology
RP Gao, B (corresponding author), Heilongjiang Univ, Coll Data Sci & Technol, Harbin 150080, Peoples R China.
EM gaobin1979@gmail.com
RI Gao, Bin/HSH-6083-2023; gao, bin/JYW-5418-2024
OI Gao, Bin/0000-0003-4458-3917; 
FU This work was supported by the National Natural Science Foundation of
   China (Nos. 11874132, 61975044, 12074094). [11874132, 61975044,
   12074094]; National Natural Science Foundation of China
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 11874132, 61975044, 12074094).
CR Abdallah Emad E., 2007, Proceedings Graphics Interface 2007, P327, DOI 10.1145/1268517.1268570
   Abdallah EE, 2006, INT C PATT RECOG, P673
   Abdallah EE, 2009, SIGNAL IMAGE VIDEO P, V3, P375, DOI 10.1007/s11760-008-0079-y
   Alessandrini M, 2013, IEEE T IMAGE PROCESS, V22, P1084, DOI 10.1109/TIP.2012.2226903
   Anand A, 2021, SUSTAIN CITIES SOC, V75, DOI 10.1016/j.scs.2021.103398
   Annaby MH, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116434
   Bhatnagar G, 2008, 2008 FIRST INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES, VOLS 1 AND 2, P526, DOI 10.1109/ICADIWT.2008.4664404
   Darwish SM, 2020, MULTIMED TOOLS APPL, V79, P6503, DOI 10.1007/s11042-019-08290-w
   Dhall S, 2021, MULTIMED TOOLS APPL, V80, P18069, DOI 10.1007/s11042-021-10531-w
   Thakkar F, 2021, MULTIMED TOOLS APPL, V80, P12275, DOI 10.1007/s11042-020-10220-0
   Fkirin A, 2021, OPT QUANT ELECTRON, V53, DOI 10.1007/s11082-021-02875-2
   Fu HS, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115774
   Gao B, 2016, PHYS MED BIOL, V61, P8640, DOI 10.1088/1361-6560/61/24/8640
   Khare P, 2021, J INTELL SYST, V30, P297, DOI 10.1515/jisys-2019-0046
   Liang XY, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116462
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu ZJ, 2011, OPT COMMUN, V284, P123, DOI 10.1016/j.optcom.2010.09.013
   Liu ZJ, 2010, OPT EXPRESS, V18, P12033, DOI 10.1364/OE.18.012033
   Ma B, 2021, J MATH IMAGING VIS, V63, P1160, DOI 10.1007/s10851-021-01048-w
   Memon MHammd, 2017, 2017 14 INT COMP C W, DOI [10.1109/ICCWAMTIP.2017.8301481, DOI 10.1109/ICCWAMTIP.2017.8301481]
   Memon MH, 2017, MULTIMED TOOLS APPL, V76, P15377, DOI 10.1007/s11042-016-3834-z
   Salehnia T, 2021, EXPERT SYST APPL, V179, DOI 10.1016/j.eswa.2021.115058
   Shaikh RA, 2015, 2015 12TH INTERNATIONAL COMPUTER CONFERENCE ON WAVELET ACTIVE MEDIA TECHNOLOGY AND INFORMATION PROCESSING (ICCWAMTIP), P179, DOI 10.1109/ICCWAMTIP.2015.7493970
   Sharma N, 2023, MULTIMED TOOLS APPL, V82, P5031, DOI 10.1007/s11042-021-11519-2
   Sharma S, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105696
   Soulard R, 2016, IEEE T SIGNAL PROCES, V64, P1535, DOI 10.1109/TSP.2015.2505664
   Juarez-Sandoval OU, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9192374
   Varish N, 2020, IEEE ACCESS, V8, P117639, DOI 10.1109/ACCESS.2020.3003911
   Velazquez-Garcia L, 2022, SIGNAL PROCESS-IMAGE, V102, DOI 10.1016/j.image.2021.116593
   Wang JW, 2012, SIGNAL PROCESS, V92, P893, DOI 10.1016/j.sigpro.2011.09.029
   Wu JJ, 2021, MULTIMED TOOLS APPL, V80, P2647, DOI 10.1007/s11042-020-09828-z
   Yuan XC, 2018, SIGNAL PROCESS, V149, P103, DOI 10.1016/j.sigpro.2018.03.007
   Zermi N, 2021, FORENSIC SCI INT, V320, DOI 10.1016/j.forsciint.2021.110691
   Zhou NR, 2023, SIGNAL PROCESS, V211, DOI 10.1016/j.sigpro.2023.109107
   Zhu T, 2022, J SUPERCOMPUT, V78, P222, DOI 10.1007/s11227-021-03886-2
NR 37
TC 0
Z9 0
U1 3
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33051
EP 33069
DI 10.1007/s11042-023-16948-9
EA SEP 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001075272400006
DA 2024-07-18
ER

PT J
AU Kumar, A
   Dua, M
AF Kumar, Atul
   Dua, Mohit
TI Image encryption using a novel hybrid chaotic map and dynamic
   permutation-diffusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Encryption; Chaos; Hybrid Map; PSNR; CC; Image Encryption; Sine-Cosine
   map
AB In last few years, chaotic maps are being used extensively by the researchers to build image cryptosystems. This paper proposes a novel Hybrid chaotic map, and discusses the implementation of an image encryption method that uses an existing Sine-Cosine (SC) chaotic map, and the proposed novel Hybrid chaotic map. The proposed image encryption method uses these two maps in pairs, but dynamically, in both permutation and diffusion phases, where if one map is used for permutation of one-pixel block based on dynamic selection, then the other map will be used for diffusion of the same pixel block. This encryption mechanism uses 128-bit shared key along with the 128-bit Initial vector. The initialization phase of this encryption scheme consists of the initialization of the intermediate key, seeds and the control parameters for the chaotic maps. After that, the two different chaotic initial sequences are created using the SC and Hybrid chaotic map, respectively, where sequence from one map will be used for permutation, and sequence from other map will be used for diffusion. The chaotic range of proposed Hybrid map lies between 5.5 to 15, and its chaotic properties have been validated using Lyapunov exponent, Bifurcation diagram, and Shannon Entropy. The results show that the Bifurcation diagram of the Hybrid map is uniform in entire range. Also, the Lyapunov Exponent of the Hybrid map is greater than 0, and the value of the Shannon entropy of the Hybrid map is close to 10. Also, the proposed image encryption scheme is capable of resisting different types of security attacks.
C1 [Kumar, Atul; Dua, Mohit] NIT, Dept Comp Engn, Kurukshetra, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Kurukshetra
RP Kumar, A (corresponding author), NIT, Dept Comp Engn, Kurukshetra, India.
EM atul.kumar1995@gmail.com; er.mohitdua@nitkkr.ac.in
RI DUA, MOHIT/A-1409-2016
OI DUA, MOHIT/0000-0001-7071-8323; Kumar, Atul/0000-0002-6895-0104
CR Arif J, 2022, IEEE ACCESS, V10, P12966, DOI 10.1109/ACCESS.2022.3146792
   Ben Farah MA, 2020, NONLINEAR DYNAM, V99, P3041, DOI 10.1007/s11071-019-05413-8
   Benaissi S, 2023, OPTIK, V272, DOI 10.1016/j.ijleo.2022.170316
   Buell D, 2021, SPRINGER NATURE, DOI [10.1007/978-3-030-73492-3, DOI 10.1007/978-3-030-73492-3]
   Datta B, 2020, MULTIMED TOOLS APPL, V79, P22673, DOI 10.1007/s11042-020-08979-3
   Datta B, 2019, MULTIMED TOOLS APPL, V78, P1511, DOI 10.1007/s11042-018-6195-y
   Dua M, 2021, HDB RES MACHINE LEAR, P139
   Dua M, 2021, INT J ELECT ENG INFO, V13, P898, DOI [10.15676/ijeei.2021.13.4.9, DOI 10.15676/IJEEI.2021.13.4.9]
   Dua M, 2022, OPEN COMPUT SCI, V12, P37, DOI 10.1515/comp-2020-0225
   Dua M, 2021, COMPLEX INTELL SYST, V7, P327, DOI 10.1007/s40747-020-00201-z
   Erkan U, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.119076
   Guesmi R, 2021, MULTIMED TOOLS APPL, V80, P1925, DOI 10.1007/s11042-020-09672-1
   Hu MT, 2023, NONLINEAR DYNAM, V111, P2815, DOI 10.1007/s11071-022-07942-1
   Huang Y, 2023, MULTIMED TOOLS APPL, V82, P41879, DOI 10.1007/s11042-023-15012-w
   Ibada Ali Jawad, 2021, Journal of Physics: Conference Series, DOI 10.1088/1742-6596/1962/1/012061
   Kumar Atul, 2022, 2022 IEEE 7th Forum on Research and Technologies for Society and Industry Innovation (RTSI), P43, DOI 10.1109/RTSI55261.2022.9905195
   Kumar A, 2023, APPL ACOUST, V203, DOI 10.1016/j.apacoust.2022.109196
   Kumar A, 2021, IMAGING SCI J, V69, P219, DOI 10.1080/13682199.2022.2156669
   Kumar A, 2023, MULTIMED TOOLS APPL, V82, P18381, DOI 10.1007/s11042-022-13902-z
   Lai Q, 2023, APPL MATH COMPUT, V442, DOI 10.1016/j.amc.2022.127738
   Lai Q, 2023, EXPERT SYST APPL, V213, DOI 10.1016/j.eswa.2022.118845
   Liang Q, 2023, OPT LASER TECHNOL, V160, DOI 10.1016/j.optlastec.2022.109033
   Liu LF, 2023, MATH COMPUT SIMULAT, V204, P89, DOI 10.1016/j.matcom.2022.07.030
   Lv WR, 2023, NONLINEAR DYNAM, V111, P3887, DOI 10.1007/s11071-022-08021-1
   Manne Suneetha, 2014, International Conference on Computing and Communication Technologies (ICCCT). Proceedings, P1, DOI 10.1109/ICCCT2.2014.7066695
   Nancharla BK, 2020, 2020 5 INT C COMM EL, P1309, DOI DOI 10.1109/ICCES48766.2020.09138102
   Pankaj S, 2021, NETW MODEL ANAL HLTH, V10, DOI 10.1007/s13721-021-00324-4
   Ping P, 2022, MULTIMED TOOLS APPL, V81, P7323, DOI 10.1007/s11042-021-11799-8
   Qasim IM, 2023, OPT COMMUN, V533, DOI 10.1016/j.optcom.2023.129262
   Ravi Renjith V., 2023, The 3rd International Conference on Artificial Intelligence and Computer Vision (AICV2023). Lecture Notes on Data Engineering and Communications Technologies (164), P305, DOI 10.1007/978-3-031-27762-7_29
   Rezaei B, 2023, J REAL-TIME IMAGE PR, V20, DOI 10.1007/s11554-023-01289-5
   Sadique Kazi Masum, 2021, Intelligent Computing and Innovation on Data Science: Proceedings of ICTIDS 2021. Lecture Notes in Networks and Systems (248), P289, DOI 10.1007/978-981-16-3153-5_32
   Sangavi V, 2020, J INF SECUR APPL, V55, DOI 10.1016/j.jisa.2020.102626
   Shahna KU, 2023, CHAOS SOLITON FRACT, V170, DOI 10.1016/j.chaos.2023.113383
   Tegue GAG, 2023, ARAB J SCI ENG, V48, P10653, DOI 10.1007/s13369-023-07715-x
   Tuli R, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6990
   Wang L, 2023, INT J THEOR PHYS, V62, DOI 10.1007/s10773-023-05295-y
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xian YJ, 2023, MULTIMED TOOLS APPL, V82, P407, DOI 10.1007/s11042-022-13280-6
   Zhou QM, 2023, OPT LASER ENG, V162, DOI 10.1016/j.optlaseng.2022.107415
NR 40
TC 0
Z9 0
U1 10
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32789
EP 32812
DI 10.1007/s11042-023-16817-5
EA SEP 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001078145100007
DA 2024-07-18
ER

PT J
AU Li, KF
   Qi, BZ
   Wang, MJ
AF Li, Kefan
   Qi, Baozhu
   Wang, Mingjia
TI Magnetic resonance image segmentation of rectal tumors based on improved
   CycleGAN and U-Net models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Medical image segmentation; Data enhancement; U-Net; Attention
   mechanism; CycleGAN
AB Accurate segmentation of rectal tumor lesion regions can provide an essential basis for clinical treatment and prognosis monitoring of tumors. However, there are many problems in the rectal tumor segmentation task at present: the lack of high-quality datasets; the mainstream segmentation network cannot complete the high-precision segmentation task of rectal tumors. In this paper, we investigate image enhancement and segmentation algorithms for convolutional neural networks and construct a rectal tumor MRI dataset by improving the CycleGAN network and loss function to achieve domain migration and reconstruction of rectal tumor CT and MRI images, given the small amount of rectal tumor image data and the existence of different modalities and regimes in CT and MRI. For the rectal tumor segmentation problem, a novel segmentation network DCMSG-UNet was designed based on the U-Net network. this network uses dilated convolution and multi-headed self-attention mechanisms to improve the base feature extraction module of the segmentation network, adds a decoder path, and uses the GAM hybrid attention mechanism to amplify the dimensional interaction features of the additional decoder path. Comparison experiments with six network models, DeepLabV3+, U-Net, UNet++, UNet3+, TransUNet, and Swin-Unet, show that the segmented region obtained from the DCMSG-UNet model proposed in this paper is closer to the real tumor region, with a DICE metric of 0.8416 and a Hausdorff distance of 11.3229, which can effectively segment the tumor. The experimental results show that our proposed method performs significantly better than the above methods, with a DICE metrics improvement of about 6%. To visualize the segmentation results, this paper designed a rectal tumor MRI image segmentation system based on PyQt5 to realize human-computer interaction and assist doctors in clinical diagnosis.
C1 [Li, Kefan; Qi, Baozhu; Wang, Mingjia] Qingdao Univ Sci & Technol, Coll Automat & Elect Engn, Qingdao, Peoples R China.
C3 Qingdao University of Science & Technology
RP Wang, MJ (corresponding author), Qingdao Univ Sci & Technol, Coll Automat & Elect Engn, Qingdao, Peoples R China.
EM mingjiawang@126.com
RI 齐, 宝柱/GWC-0072-2022
OI 齐, 宝柱/0009-0003-3227-7039
FU National Natural Science Foundation of China
FX This work was supported by National Natural Science Foundation of China
   (Grant No.61971253).
CR Bello I, 2019, IEEE I CONF COMP VIS, P3285, DOI 10.1109/ICCV.2019.00338
   Cai YT, 2022, PROC SPIE, V12167, DOI 10.1117/12.2628519
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chalana V, 1997, IEEE T MED IMAGING, V16, P642, DOI 10.1109/42.640755
   Chen JP, 2021, NAT PHOTONICS, V15, P570, DOI 10.1038/s41566-021-00828-5
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chikkara SB., 2023, CHEM BIOL LETT, V10, P451
   Dou M, 2023, MED BIOL ENG COMPUT, V61, P2379, DOI 10.1007/s11517-023-02828-9
   Fitzke M, 2021, ARXIV
   Fukui H, 2019, PROC CVPR IEEE, P10697, DOI 10.1109/CVPR.2019.01096
   Ganin Y, 2014, 2 INT C PERS TECHN, P536
   Gao YH, 2021, LECT NOTES COMPUT SC, V12903, P61, DOI 10.1007/978-3-030-87199-4_6
   Gilbert A, 2021, IEEE T MED IMAGING, V40, P2783, DOI 10.1109/TMI.2021.3051806
   Hague C, 2019, RADIOTHER ONCOL, V130, P56, DOI 10.1016/j.radonc.2018.10.030
   Hu F, 2022, LECT NOTES COMPUT SC, V13674, P444, DOI 10.1007/978-3-031-19781-9_26
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang HM, 2020, INT CONF ACOUST SPEE, P1055, DOI [10.1109/ICASSP40776.2020.9053405, 10.1109/icassp40776.2020.9053405]
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Y., 2021, ARXIV
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Poder J, 2017, PHYS MEDICA, V43, P43, DOI 10.1016/j.ejmp.2017.10.015
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saraf V., 2020, ADV COMPUTING TECHNO, P293, DOI [10.1007/978-981- 15- 3242-9_ 28, DOI 10.1007/978-981-15-3242-928]
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Verma R, 2021, IEEE T MED IMAGING, V40, P3413, DOI 10.1109/TMI.2021.3085712
   Wang MJ, 2022, MULTIMED TOOLS APPL, V81, P43821, DOI 10.1007/s11042-022-13256-6
   Wang Y, 2022, AIP C P, V2511
   Wang ZK, 2021, COMPUT BIOL MED, V134, DOI 10.1016/j.compbiomed.2021.104449
   Wei B, 2019, 2019 6 INT C SYST IN, P522, DOI DOI 10.1109/ICSAI48974.2019.9010191
   Woo S., 2018, P EUR C COMP VIS ECC, DOI DOI 10.1007/978-3-030-01234-2_1
   Xu ZH, 2022, NEUROCOMPUTING, V500, P177, DOI 10.1016/j.neucom.2022.05.053
   Zheng R S, 2019, Zhonghua Zhong Liu Za Zhi, V41, P19, DOI 10.3760/cma.j.issn.0253-3766.2019.01.005
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou Zongwei, 2018, Deep Learn Med Image Anal Multimodal Learn Clin Decis Support (2018), V11045, P3, DOI [10.1007/978-3-030-00889-5_1, 10.1007/978-3-030-00689-1_1]
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zunair H, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104699
NR 38
TC 0
Z9 0
U1 2
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 33555
EP 33571
DI 10.1007/s11042-023-16866-w
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069514100008
DA 2024-07-18
ER

PT J
AU Gilal, NU
   Al-Thelaya, K
   Al-Saeed, JK
   Abdallah, M
   Schneider, J
   She, J
   Awan, JH
   Agus, M
AF Gilal, Nauman Ullah
   Al-Thelaya, Khaled
   Al-Saeed, Jumana Khalid
   Abdallah, Mohamed
   Schneider, Jens
   She, James
   Awan, Jawad Hussain
   Agus, Marco
TI Evaluating machine learning technologies for food computing from a data
   set perspective
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Food computing; Food data sets; Applications; Food recognition; Food
   classification; Caloric estimation; Machine learning; Deep learning
ID DIETARY ASSESSMENT; CLASSIFICATION; RECOGNITION
AB Food plays an important role in our lives that goes beyond mere sustenance. Food affects behavior, mood, and social life. It has recently become an important focus of multimedia and social media applications. The rapid increase of available image data and the fast evolution of artificial intelligence, paired with a raised awareness of people's nutritional habits, have recently led to an emerging field attracting significant attention, called food computing, aimed at performing automatic food analysis. Food computing benefits from technologies based on modern machine learning techniques, including deep learning, deep convolutional neural networks, and transfer learning. These technologies are broadly used to address emerging problems and challenges in food-related topics, such as food recognition, classification, detection, estimation of calories and food quality, dietary assessment, food recommendation, etc. However, the specific characteristics of food image data, like visual heterogeneity, make the food classification task particularly challenging. To give an overview of the state of the art in the field, we surveyed the most recent machine learning and deep learning technologies used for food classification with a particular focus on data aspects. We collected and reviewed more than 100 papers related to the usage of machine learning and deep learning for food computing tasks. We analyze their performance on publicly available state-of-art food data sets and their potential for usage in multimedia food-related applications for various needs (communication, leisure, tourism, blogging, reverse engineering, etc.). In this paper, we perform an extensive review and categorization of available data sets: to this end, we developed and released an open web resource in which the most recent existing food data sets are collected and mapped to the corresponding geographical regions. Although artificial intelligence methods can be considered mature enough to be used in basic food classification tasks, our analysis of the state-of-the-art reveals that challenges related to the application of this technology need to be addressed. These challenges include, among others: poor representation of regional gastronomy, incorporation of adaptive learning schemes, and reverse engineering for automatic food creation and replication.
C1 [Gilal, Nauman Ullah; Al-Thelaya, Khaled; Al-Saeed, Jumana Khalid; Abdallah, Mohamed; Schneider, Jens; She, James; Agus, Marco] Hamad Bin Khalifa Univ, Qatar Fdn, Coll Sci & Engn, Div Informat & Comp Technol, Doha, Qatar.
   [Awan, Jawad Hussain] Shaheed Zulfikar Ali Bhutto Inst Sci & Technol, Dept Comp Sci, Gharo Campus, Sindh, Pakistan.
C3 Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar; Shaheed
   Zulfikar Ali Bhutto Institute of Science & Technology
RP Agus, M (corresponding author), Hamad Bin Khalifa Univ, Qatar Fdn, Coll Sci & Engn, Div Informat & Comp Technol, Doha, Qatar.
EM giul30541@hbku.edu.qa; kalthelaya@hbku.edu.qa; jakalsaeed@hbku.edu.qa;
   moabdallah@hbku.edu.qa; jeschneider@hbku.edu.qa; pshe@hbku.edu.qa;
   dr.jawad@ghr.szabist.edu.pk; magus@hbku.edu.qa
RI Agus, Marco/AAM-5898-2020
OI Agus, Marco/0000-0003-2752-3525
FU Qatar National Library; Qatar National Library
FX Open Access funding provided by the Qatar National Library.
CR Abbar S, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3197, DOI 10.1145/2702123.2702153
   Aguilar E, 2018, IEEE T MULTIMEDIA, V20, P3266, DOI 10.1109/TMM.2018.2831627
   Ahmad Z, 2014, PROC SPIE, V9030, DOI 10.1117/12.2041334
   Aktas H, 2022, J FOOD MEAS CHARACT, V16, P1983, DOI 10.1007/s11694-022-01313-5
   [Anonymous], 2010, Multimedia (ISM), 2010 IEEE International Symposium on
   [Anonymous], 2017, Frontiers in ICT, DOI DOI 10.3389/FICT.2017.00015
   [Anonymous], 2019, ARXIV, DOI DOI 10.48550/ARXIV.1907.06167
   [Anonymous], 2012, Proceedings of the 2nd ACM international workshop on Interactive multimedia on mobile and portable devices
   Anthimopoulos MM, 2014, IEEE J BIOMED HEALTH, V18, P1261, DOI 10.1109/JBHI.2014.2308928
   Arslan Berker, 2022, IEEE Transactions on Artificial Intelligence, V3, P238, DOI 10.1109/TAI.2021.3108126
   Beijbom O, 2015, IEEE WINT CONF APPL, P844, DOI 10.1109/WACV.2015.117
   Bosch M, 2011, IEEE IMAGE PROC, P1789, DOI 10.1109/ICIP.2011.6115809
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Bozinovski S, 2020, INFORM-INT J COMPUT, V44, P291, DOI 10.31449/inf.v44i3.2828
   Bruno Vieira, 2017, J Health Med Inform, V8, DOI 10.4172/2157-7420.1000272
   Chen JJ, 2021, IEEE T IMAGE PROCESS, V30, P1514, DOI 10.1109/TIP.2020.3045639
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen X, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1705.02743
   Christodoulidis S, 2015, LECT NOTES COMPUT SC, V9281, P458, DOI 10.1007/978-3-319-23222-5_56
   Ciocca G, 2020, IEEE ACCESS, V8, P32003, DOI 10.1109/ACCESS.2020.2973704
   Ciocca G, 2017, LECT NOTES COMPUT SC, V10590, P426, DOI 10.1007/978-3-319-70742-6_41
   Ciocca G, 2017, IEEE J BIOMED HEALTH, V21, P588, DOI 10.1109/JBHI.2016.2636441
   Ciocca G, 2015, LECT NOTES COMPUT SC, V9281, P334, DOI 10.1007/978-3-319-23222-5_41
   Culotta A, 2014, 32ND ANNUAL ACM CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2014), P1335, DOI 10.1145/2556288.2557139
   DAMEN D, 2018, P EUROPEAN C COMPUTE, P720, DOI DOI 10.48550/ARXIV.1804.02748
   Dinic R, 2017, PROCEEDINGS OF THE 19TH INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI '17), DOI 10.1145/3098279.3125434
   Ege T, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P198, DOI 10.23919/MVA.2017.7986835
   Fanyu Kong, 2011, 2011 8th International Conference on Body Sensor Networks (BSN), P127, DOI 10.1109/BSN.2011.19
   Farinella GM, 2016, COMPUT BIOL MED, V77, P23, DOI 10.1016/j.compbiomed.2016.07.006
   Farinella GM, 2015, LECT NOTES COMPUT SC, V8927, P584, DOI 10.1007/978-3-319-16199-0_41
   Feng Y, 2021, STAT ANAL DATA MIN, V14, P383, DOI 10.1002/sam.11538
   Foret P., 2020, ARXIV, DOI DOI 10.48550/ARXIV.2010.01412
   Freitas CNC, 2020, SIBGRAPI, P234, DOI 10.1109/SIBGRAPI51738.2020.00039
   Gilal NU, 2021, SMART TOOLS APPS GRA, P73, DOI [10.2312/stag.20211476, DOI 10.2312/STAG.20211476]
   Goncalves Diogo Nunes, 2021, Information Processing in Agriculture, V8, P560, DOI 10.1016/j.inpa.2020.11.004
   Harashima J, 2017, SIGIR'17: PROCEEDINGS OF THE 40TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1229, DOI 10.1145/3077136.3080686
   Hassannejad H, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P41, DOI 10.1145/2986035.2986042
   He JP, 2021, IEEE INT CONF COMP V, P2337, DOI 10.1109/ICCVW54120.2021.00265
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, P1, DOI [DOI 10.48550/ARXIV.1503.02531, 10.48550/arXiv.1503.02531]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Ismail N, 2022, INFORM PROCESS AGR, V9, P24, DOI 10.1016/j.inpa.2021.01.005
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jalal M, 2019, MADIMA'19: PROCEEDINGS OF THE 5TH INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P50, DOI 10.1145/3347448.3357170
   Jiang LD, 2020, IEEE ACCESS, V8, P47477, DOI 10.1109/ACCESS.2020.2973625
   Jiang SQ, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3391624
   Jiang SQ, 2020, IEEE T IMAGE PROCESS, V29, P265, DOI 10.1109/TIP.2019.2929447
   Kawano Y, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P589, DOI 10.1145/2638728.2641339
   Kawano Y, 2015, MULTIMED TOOLS APPL, V74, P5263, DOI 10.1007/s11042-014-2000-8
   Kawano Y, 2015, LECT NOTES COMPUT SC, V8927, P3, DOI 10.1007/978-3-319-16199-0_1
   Kawano Y, 2013, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW.2013.5
   Kazi A, 2022, MULTIMED TOOLS APPL, V81, P7611, DOI 10.1007/s11042-022-12150-5
   König LM, 2022, HEALTH PSYCHOL REV, V16, P526, DOI 10.1080/17437199.2021.2016066
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lam MB, 2020, IEEE ACCESS, V8, P88360, DOI 10.1109/ACCESS.2020.2993053
   Latif Ghazanfar, 2020, ICCTA '20: Proceedings of the 2020 6th International Conference on Computer and Technology Applications, P17, DOI 10.1145/3397125.3397154
   Lee GG, 2019, TENCON IEEE REGION, P802, DOI [10.1109/tencon.2019.8929715, 10.1109/TENCON.2019.8929715]
   Liang HZ, 2021, IEEE T MULTIMEDIA, V23, P3551, DOI 10.1109/TMM.2020.3028478
   Liang Y, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1705.07632
   LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346
   Lindeberg T., 1994, Scale-Space Theory in Computer Vision, DOI DOI 10.1007/978-1-4757-6465-9
   Liu C, 2018, IEEE T SERV COMPUT, V11, P249, DOI 10.1109/TSC.2017.2662008
   Liu C, 2016, LECT NOTES COMPUT SC, V9677, P37, DOI 10.1007/978-3-319-39601-9_4
   Lo FPW, 2019, BRIT MACH VIS C, DOI 10.48550/arXiv.2207.03692
   Lo FPW, 2020, IEEE J BIOMED HEALTH, V24, P1926, DOI 10.1109/JBHI.2020.2987943
   Ma PH, 2022, FOOD CHEM, V373, DOI 10.1016/j.foodchem.2021.130994
   Mandal B, 2019, IEEE SENSOR LETT, V3, DOI 10.1109/LSENS.2018.2886427
   Marin J, 2021, IEEE T PATTERN ANAL, V43, P187, DOI 10.1109/TPAMI.2019.2927476
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   Matsuda Y., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P25, DOI 10.1109/ICME.2012.157
   McAllister P, 2018, COMPUT BIOL MED, V95, P217, DOI 10.1016/j.compbiomed.2018.02.008
   McDonnell ErinMetz., 2016, Food, Media and Contemporary Culture: The Edible Image, P239, DOI [https://doi.org/10.1057/9781137463234_14, DOI 10.1057/9781137463234_14]
   Medus LD, 2021, FOOD CONTROL, V125, DOI 10.1016/j.foodcont.2021.107962
   Mejova Y, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1603.00229
   Mezgec S, 2019, IEEE INT CONF BIG DA, P5149, DOI 10.1109/BigData47090.2019.9006181
   Min W, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.16107
   Min WQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P393, DOI 10.1145/3394171.3414031
   Min WQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1331, DOI 10.1145/3343031.3350948
   Min WQ, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329168
   Min WQ, 2018, IEEE T MULTIMEDIA, V20, P950, DOI 10.1109/TMM.2017.2759499
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Nguyen HT, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108470
   Ofli F, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P509, DOI 10.1145/3038912.3052663
   Pan LL, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON COLLABORATION AND INTERNET COMPUTING (CIC), P181, DOI 10.1109/CIC.2017.00033
   Pandey P, 2017, IEEE SIGNAL PROC LET, V24, P1758, DOI 10.1109/LSP.2017.2758862
   Poply Parth, 2020, SPML 2020: Proceedings of the 2020 3rd International Conference on Signal Processing and Machine Learning, P73, DOI 10.1145/3432291.3432295
   Pouladzadeh P, 2015, LECT NOTES COMPUT SC, V9281, P441, DOI 10.1007/978-3-319-23222-5_54
   Pouladzadeh P, 2015, MULTIMED TOOLS APPL, V74, P5243, DOI 10.1007/s11042-014-2116-x
   Qi XB, 2014, IEEE T PATTERN ANAL, V36, P2199, DOI 10.1109/TPAMI.2014.2316826
   Qiu JN, 2021, IEEE J BIOMED HEALTH, V25, P1471, DOI 10.1109/JBHI.2020.3022815
   Rachakonda L, 2020, IEEE T CONSUM ELECTR, V66, P115, DOI 10.1109/TCE.2020.2976006
   Raikwar H., 2018, International Journal on Future Revolution in Computer Science & Communication Engineering, V4, P98
   Ramdani Assyifa, 2020, 2020 IEEE International Conference on Industry 4.0, Artificial Intelligence, and Communications Technology (IAICT). Proceedings, P91, DOI 10.1109/IAICT50021.2020.9172024
   Ruede R, 2020, ARXIV, DOI DOI 10.48550/ARXIV.2011.01082
   Sadler CR, 2021, TRENDS FOOD SCI TECH, V112, P149, DOI 10.1016/j.tifs.2021.02.059
   Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327
   Sarda E, 2021, P INT C COMP INT DAT, P435, DOI [10.1007/978-981-15-8767-2_36, DOI 10.1007/978-981-15-8767-2_36]
   Sener O, 2018, ADV NEURAL INFORM PR, V31, DOI [10.48550/arXiv.2110.07301, DOI 10.48550/ARXIV.2110.07301]
   Siddiqi R, 2019, ICDLT 2019: 2019 3RD INTERNATIONAL CONFERENCE ON DEEP LEARNING TECHNOLOGIES, P91, DOI 10.1145/3342999.3343002
   Siemon MSN, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79677-1
   Subhi MA, 2018, IEEE EMBS CONF BIO, P284, DOI 10.1109/IECBES.2018.8626720
   Sun JM, 2021, IEEE T CLOUD COMPUT, V9, P1195, DOI 10.1109/TCC.2019.2902380
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tahir GA, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9121676
   Tahir GA, 2020, IEEE ACCESS, V8, P82328, DOI 10.1109/ACCESS.2020.2991810
   Tan M., 2020, INT C MACH LEARN, DOI DOI 10.48550/ARXIV.1905.11946
   Tawara N, 2015, APSIPA TRANS SIGNAL, V4, DOI 10.1017/ATSIP.2015.19
   Temdee P, 2017, 2017 GLOBAL WIRELESS SUMMIT (GWS), P132, DOI 10.1109/GWS.2017.8300490
   Teng CY, 2012, PROCEEDINGS OF THE 3RD ANNUAL ACM WEB SCIENCE CONFERENCE, 2012, P298
   Thames Q, 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.03375
   Van Houdt G, 2020, ARTIF INTELL REV, V53, P5929, DOI 10.1007/s10462-020-09838-1
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Vu T, 2017, COMPUTERS, V6, DOI 10.3390/computers6010004
   Wang X, 2015, PROD LOGIST, P1, DOI 10.1007/978-3-658-06869-1
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wibisono A, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00347-0
   Won CS, 2020, IEEE ACCESS, V8, P116663, DOI 10.1109/ACCESS.2020.3005150
   Yanai K, 2015, 2015 IEEE INT C MULT, P1, DOI DOI 10.1109/ICMEW.2015.7169816
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Yu N, 2013, P IJC WORKSH COOK CO, P3
   Zhao H, 2020, IEEE J-STSP, V14, P665, DOI 10.1109/JSTSP.2020.2969328
   Zhao H, 2021, IEEE WINT CONF APPL, P1710, DOI 10.1109/WACV48630.2021.00175
   Zhidong Shen, 2020, Procedia Computer Science, V174, P448, DOI 10.1016/j.procs.2020.06.113
   Zhu FQ, 2015, IEEE J BIOMED HEALTH, V19, P377, DOI 10.1109/JBHI.2014.2304925
NR 127
TC 0
Z9 0
U1 9
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 32041
EP 32068
DI 10.1007/s11042-023-16513-4
EA SEP 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001069156900023
OA hybrid
DA 2024-07-18
ER

PT J
AU Khosa, S
   Rustam, F
   Mehmood, A
   Choi, GS
   Ashraf, I
AF Khosa, Saima
   Rustam, Furqan
   Mehmood, Arif
   Choi, Gyu Sang
   Ashraf, Imran
TI Incorporating Word Embedding and Hybrid Model Random Forest Softmax
   Regression for Predicting News Categories
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE News classification; Softmax regression; Preprocessing; Random forest;
   Text mining; TF-IDF
ID CLASSIFICATION
AB Online media reshaped the news industry leading to information richness, timely dissemination, and immense diversity. In addition, recent technological advancements enable on-spot, prompt and frequent reporting which can be viewed on smartphones, personal computers, and mobile devices. These recent developments enhanced the importance of news categorization. Accurate news categorization has become an important element to increase user satisfaction by providing the news of their interest and desired category. Despite the available approaches for news categorization, such approaches lack the desired accuracy and require further research to improve their performance. For this purpose, this research proposes a hybrid model that comprises random forest (RF) and SoftMax regression. To further increase the accuracy, special emphasis is placed on preprocessing steps to remove the noise from the textual data. Moreover, term frequency-inverse document frequency (TF-IDF) and bag of words (BoW) approaches are leveraged for the proposed model due to their reported efficacy for the task at hand. Experimental results indicate that the proposed model achieves 98.1% accuracy and outperforms individual machine learning classifiers regarding the accuracy, precision, recall, and F1 score. Hybrid approaches of RF and SMR tend to show better results than individual, as well as, state-of-the-art approaches.
C1 [Khosa, Saima] Khwaja Fareed Univ Engn & Informat Technol, Rahim Yar Khan 64200, Pakistan.
   [Rustam, Furqan] Univ Coll Dublin, Sch Comp Sci, Dublin D04V1W8, Ireland.
   [Mehmood, Arif] Islamia Univ Bahawalpur, Dept CS & IT, Bahawalpur 63100, Punjab, Pakistan.
   [Choi, Gyu Sang; Ashraf, Imran] Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
C3 Khwaja Fareed University of Engineering & Information Technology,
   Pakistan; University College Dublin; Islamia University of Bahawalpur;
   Yeungnam University
RP Ashraf, I (corresponding author), Yeungnam Univ, Dept Informat & Commun Engn, Gyongsan 38541, South Korea.
EM saimakhosa@yahoo.com; arifnhmp@gmail.com; castchoi@ynu.ac.kr;
   imranashraf@ynu.ac.kr
RI Rustam, Furqan/ABE-4772-2020
OI Rustam, Furqan/0000-0001-8403-1047; Ashraf, Imran/0000-0002-8271-6496
FU Basic Science Research Program through the National Research Foundation
   of Korea(NRF) - Ministry of Education [NRF-2019R1A2C1006159,
   NRF-2021R1A6A1A03039493]
FX This work was supported in part by Basic Science Research Program
   through the National Research Foundation of Korea(NRF) funded by the
   Ministry of Education (NRF-2019R1A2C1006159) and
   (NRF-2021R1A6A1A03039493).
CR [Anonymous], 2022, Nord Stream leaks: Sabotage to blame, says EU
   [Anonymous], 2008, Springer Science+ Business Media, DOI DOI 10.1007/978-0-387-74101-7
   Biro I., 2009, AIRWeb '09: Proceedings of the 5th International Workshop on Adversarial Information, P37, DOI [DOI 10.1145/1531914.1531922, 10.1145/1531914.1531922]
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bounabi M, 2017, POWERTECH 2017 IEEE, P1
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Dadgar SMH, 2016, PROCEEDINGS OF 2ND IEEE INTERNATIONAL CONFERENCE ON ENGINEERING & TECHNOLOGY ICETECH-2016, P112, DOI 10.1109/ICETECH.2016.7569223
   Dandeniya D, 2018, INT CONF ADV ICT, P196, DOI 10.1109/ICTER.2018.8615480
   Elghannam F, 2019, J KING SAUD UNIV-COM
   Glorot X., 2011, P 28 INT C INT C MAC, P513
   Gupta RK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P139, DOI 10.1145/3343031.3351048
   Haryanto Ardy Wibowo, 2018, 2018 3rd International Seminar on Application for Technology of Information and Communication. Proceedings, P229, DOI 10.1109/ISEMANTIC.2018.8549748
   Kadhim AI, 2014, PROCEEDINGS 2014 4TH INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE WITH APPLICATIONS IN ENGINEERING AND TECHNOLOGY ICAIET 2014, P69, DOI 10.1109/ICAIET.2014.21
   Karaman Yunus, 2023, Innovations in Smart Cities Applications: The Proceedings of the 7th International Conference on Smart City Applications. Lecture Notes in Networks and Systems (629), P473, DOI 10.1007/978-3-031-26852-6_44
   Khalid M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10082788
   Kim D, 2019, INFORM SCIENCES, V477, P15, DOI 10.1016/j.ins.2018.10.006
   Lee ERS, 2022, IEEE ACCESS, V10, P10333, DOI 10.1109/ACCESS.2022.3144659
   McCallum A., 1998, AAAI 98 WORKSH LEARN, V752, P41, DOI DOI 10.1109/TSMC.1985.6313426
   Mehmood A, 2018, J PHYS CONF SER, V933, DOI 10.1088/1742-6596/933/1/012012
   Méndez JR, 2006, LECT NOTES ARTIF INT, V4177, P449
   Neelakantan A, 2015, ARXIV
   Osowska-Kurczab AM, 2021, B POL ACAD SCI-TECH, V69, DOI 10.24425/bpasts.2021.136749
   Pal M, 2005, INT J REMOTE SENS, V26, P217, DOI 10.1080/01431160412331269698
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Rana MI, 2014, 17TH IEEE INTERNATIONAL MULTI TOPIC CONFERENCE 2014, P211, DOI 10.1109/INMIC.2014.7097339
   Reshi AA, 2022, HEALTHCARE-BASEL, V10, DOI 10.3390/healthcare10030411
   Rustam F, 2020, EEE ACCESS
   Rustam F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21111078
   Sadeghi D, 2022, COMPUT BIOL MED, V146, DOI 10.1016/j.compbiomed.2022.105554
   Salman, 2021, J HUNAN U NATURALSCI, V48
   Shoeibi A, 2022, AUTOMATED DETECTION
   Shoeibi A, 2021, COMPUT BIOL MED, V136, DOI 10.1016/j.compbiomed.2021.104697
   Tariq S, 2019, IEEE ACCESS, V7, P166165, DOI 10.1109/ACCESS.2019.2953087
   Wongso R, 2017, PROCEDIA COMPUT SCI, V116, P137, DOI 10.1016/j.procs.2017.10.039
   Zhang Y, 2010, INT J MACH LEARN CYB, V1, P43, DOI 10.1007/s13042-010-0001-0
   Zhu W, 2016, IEEE INT C BIOINFORM, P1415, DOI 10.1109/BIBM.2016.7822730
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 11
BP 31279
EP 31295
DI 10.1007/s11042-023-16491-7
EA SEP 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KF5H9
UT WOS:001066067700001
DA 2024-07-18
ER

PT J
AU Mammeri, S
   Amroune, M
   Haouam, MY
   Bendib, I
   Silva, AC
AF Mammeri, Selma
   Amroune, Mohamed
   Haouam, Mohamed-Yassine
   Bendib, Issam
   Silva, Aristofanes Correa
TI Early detection and diagnosis of lung cancer using YOLO v7, and transfer
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Lung cancer; Computer vision; Deep learning; YOLO; Object detection;
   Lung nodules classification
ID CT IMAGES; ALGORITHM
AB Lung cancer is a very dangerous disease and one of the leading causes of cancer-related deaths worldwide. It often goes undetected until it reaches an advanced stage. Early detection of lung nodules, especially those ranging between 3mm-30mm, can aid radiologists in diagnosing the disease, as it poses a significant challenge for them. In this study, we propose a method for the detection and classification of these nodules using the LIDR-IDRI dataset. Our method consists of two parts. The first part focuses on introducing object detection algorithms using one of the recent version of YOLO (YOLO v7) to detect lung nodules. These algorithms enable the drawing of bounding boxes around the lung nodules without losing any vital information, thus assisting radiologists in identifying and tracking the nodules in adjacent computed tomography slices. We also evaluated the impact of different input images on nodule detection, including whole images (images without preprocessing and segmentation), lung segmented images (the lung area is extracted from the whole images), and preprocessed images (applying some filtering methods on the whole images). Our findings revealed that using whole images resulted in the best performance, achieving a detection mAP (mean average precision) of 81.28%. In the second part, we present a multi-class classification using transfer learning with the VGG16 model. This classification process demonstrated good performance in classifying the nodules detected in the first step by the YOLO object detector into three classes: benign, suspect, and malignant. The classification is based on the degree of malignancy given by each radiologist, which varies from (1 to 5) depending on the nodule malignancy. This approach has the potential to enhance the accuracy of nodule classification and improve the overall diagnostic process for lung cancer.
C1 [Mammeri, Selma; Amroune, Mohamed; Haouam, Mohamed-Yassine; Bendib, Issam] Echahid Cheikh Larbi Tebessi Univ, Lab Math Informat & Syst LAMIS, Tebessa 12002, Algeria.
   [Silva, Aristofanes Correa] Univ Fed Maranhao, Dept Elect Engn, BR-65080805 Sao Luis, Maranhao, Brazil.
C3 Echahid Cheikh Larbi Tebessi University; Universidade Federal do
   Maranhao
RP Mammeri, S (corresponding author), Echahid Cheikh Larbi Tebessi Univ, Lab Math Informat & Syst LAMIS, Tebessa 12002, Algeria.
EM selma.mammeri@univ-tebessa.dz; mohamed.amroune@univ-tebessa.dz;
   mohamed-yassine.haouam@univ-tebessa.dz; issam.bendib@univ-tebessa.dz;
   aricsilva@gmail.com
RI Amroune, Pr.Mohamed/HGC-7134-2022; HAOUAM, Mohamed Yassine/KFT-1015-2024
OI Amroune, Pr.Mohamed/0000-0002-4252-4561; Haouam, Mohamed
   Yassine/0000-0001-8989-6656
CR [Anonymous], 2021, CANC IMAGING ARCH
   [Anonymous], 2022, SIZES LUNG NODULES
   [Anonymous], 2021, ERODING DILATING
   Bhandary A, 2020, PATTERN RECOGN LETT, V129, P271, DOI 10.1016/j.patrec.2019.11.013
   de Carvalho AS, 2017, J DIGIT IMAGING, V30, P812, DOI 10.1007/s10278-017-9973-6
   Ewaidat HA, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2301.02166
   Haider A, 2020, PROCEEDINGS OF 2020 IEEE APPLIED SIGNAL PROCESSING CONFERENCE (ASPCON 2020), P198, DOI 10.1109/ASPCON49795.2020.9276715
   Jin X., 2010, K-Means Clustering, P563
   Kaviarasu K, 2016, S ASIAN J ENG TECHNO, V2
   Kejia Xu, 2020, ICCAI '20: Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence, P233, DOI 10.1145/3404555.3404609
   Lung Image Database Consortium (LIDC), 2020, NOD SIZ REP
   Luo SQ, 2001, P ANN INT IEEE EMBS, V23, P2727, DOI 10.1109/IEMBS.2001.1017347
   Mohamed A, 2021, 2021 INT C NETW ADV, P1, DOI [10.1109/ICNAS53565.2021.9628946, DOI 10.1109/ICNAS53565.2021.9628946]
   Noviana R, 2017, AIP CONF PROC, V1867, DOI 10.1063/1.4994425
   Pydicom, 2021, US
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sawant A, 1999, P SOC PHOTO-OPT INS, V3661, P1263, DOI 10.1117/12.348522
   Soltani H, 2021, 2021 INT C RECENT AD, P1
   Su Y, 2021, COMPUT METH PROG BIO, V200, DOI 10.1016/j.cmpb.2020.105866
   Suji RJ, 2021, INDIAN J COMPUT SCI, V12, DOI [10.21817/indjcse/2021/v12i4/211204270, DOI 10.21817/INDJCSE/2021/V12I4/211204270]
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Xie HT, 2019, PATTERN RECOGN, V85, P109, DOI 10.1016/j.patcog.2018.07.031
   Xie YT, 2019, IEEE T MED IMAGING, V38, P991, DOI 10.1109/TMI.2018.2876510
   Yan C-M., 2022, J COMPUT, V33, P113, DOI [10.53106/199115992022063303009, DOI 10.53106/199115992022063303009]
NR 25
TC 2
Z9 2
U1 17
U2 19
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 30965
EP 30980
DI 10.1007/s11042-023-16864-y
EA SEP 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066762000014
DA 2024-07-18
ER

PT J
AU Khullar, V
AF Khullar, Vikas
TI K Means clustering and descriptive analytics based performance
   recommending system for Kabaddi team and player
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sports analytics; Machine learning; Regression; Clustering; Correlation
   analysis; Forecasting
ID SPORTS ANALYTICS
AB In the contemporary era, Kabaddi is considered as a commercial game. Manual analytics were used in old times in which the best team or player was selected based on the background. However, in the present era, statistical analysis and machine learning are used in place of conventional methods of sports analytics in commercial sports such as Cricket, Football, etc. This study intends to analyze correlations for features of accumulated online datasets and to make predictions for the team and player performance using correlated features by using statistical machine learning approaches. The suggested methodology includes feature extraction, correlation identification, and implementing appropriate machine learning approaches. Initially, the parameters of the Kabaddi game concerns such as the impact of tosses, cards, and home ground on results were analysed. Subsequently, based on team and player data correlation and cluster analysis, important characteristics were identified and appropriate rank-based scoring was established. Finally, the regression-based prediction was suggested with an r2 score and a cross-validation score greater than 0.91 with the least errors. Finally, a trained machine-learning model with greater outcomes was suggested by verifying the parameters that were analysed. After the completion of analysis, the proposed techniques would be utilized in real-time scenarios using visual dashboards, deep learning, the Internet of Things, etc.
C1 [Khullar, Vikas] Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
C3 Chitkara University, Punjab
RP Khullar, V (corresponding author), Chitkara Univ, Inst Engn & Technol, Rajpura, Punjab, India.
EM vikas.khullar@gmail.com
OI KHULLAR, VIKAS/0000-0002-0404-3652
CR [Anonymous], 2021, SCROLL
   Apostolou K, 2019, INT CONF INFORM INTE, P469, DOI 10.1109/iisa.2019.8900754
   Bhagavatula M, 2022, ESPN
   Constantinou A., 2017, KNOWL-BASED SYST, DOI [10.1016/j.knosys.2017.01.015, DOI 10.1016/J.KNOSYS.2017.01.015]
   Dieu O, 2020, J SPORT SCI, V38, P1943, DOI 10.1080/02640414.2020.1764812
   Fujii K, 2021, DATA DRIVEN ANAL UND, P1
   Ghosh SS, 2018, EVOLUTION PROKABADDI, V4, P23
   Kaur Amanpreet, 2023, 2023 International Conference on Intelligent and Innovative Technologies in Computing, Electrical and Electronics (IITCEE), P1209, DOI 10.1109/IITCEE57236.2023.10090874
   Kaur A., 2021, SN COMPUT SCI, V2, P1, DOI [10.1007/s42979-021-00575-y, DOI 10.1007/S42979-021-00575-Y]
   Knobbe A, 2017, DATA MIN KNOWL DISC, V31, P1872, DOI 10.1007/s10618-017-0512-3
   Maier T, 2018, J SPORT SCI, V36, P2333, DOI 10.1080/02640414.2018.1455261
   Malik V, 2022, P 2022 5 INT C COMP, P370, DOI [10.1109/CCiCT56684.2022.00073, DOI 10.1109/CCICT56684.2022.00073]
   Ofoghi B, 2016, J SPORT SCI, V34, P607, DOI 10.1080/02640414.2015.1065341
   Parmar MK, 2017, 5 INT C BUS AN INT L
   Passfield L, 2017, INT J SPORT PHYSIOL, V12, P851, DOI 10.1123/ijspp.2016-0644
   Pro Kabaddi Hackathon, 2021, US
   Pro Kabaddi League, 2020, US
   Pro-Kabaddi League, 2019, US
   Sanjit S., 2016, INDIAN J PHYS ED SPO, V6, P27
   Sarlis V, 2020, INFORM SYST, V93, DOI 10.1016/j.is.2020.101562
   Singh P., 2023, LECT NOTES NETW SYST, V554, P243, DOI [10.1007/978-981-19-6661-3_22, DOI 10.1007/978-981-19-6661-3_22]
   Singh S., 2023, J STAT APPL PROB, V12, P313, DOI [10.18576/jsap/120127, DOI 10.18576/JSAP/120127]
   Vasudevan S, 2021, HINDU
   VIVO Pro Kabaddi League: A HIT amongst the masses, 2021, VIVO PROKAB LEAG HIT
NR 24
TC 0
Z9 0
U1 6
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 29897
EP 29914
DI 10.1007/s11042-023-16819-3
EA SEP 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001066065600002
DA 2024-07-18
ER

PT J
AU Sahu, S
   Singh, AK
AF Sahu, Sima
   Singh, Amit Kumar
TI Genetic algorithm based multi-resolution approach for de-speckling OCT
   image
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Optical Coherence Tomography (OCT); Genetic Algorithm (GA); Wavelet
   transform; Optimization
ID OPTICAL COHERENCE TOMOGRAPHY; REDUCTION; ENHANCEMENT; REMOVAL
AB Reduction of noise has a considerable effect in medical image processing and computer vision analysis. Medical images are affected by noise due to low radiation exposure, physiological sources and electronic hardware noise. This affects diagnosis quality and quantitative measurements. In this paper, optical coherence tomography images are de-noised through wavelet transform, and the wavelet threshold value is further optimised using genetic algorithm (GA). The optimal levels of wavelet decomposition and threshold correction are performed through GA. The efficacy of the proposed method is verified by comparing the results with other reported wavelet- and GA-based methods in terms of Peak-Signal-to-Noise Ratio (PSNR) parameters. The quality of the resulting image is measured through structural similarity index measure (SSIM), correlation of coefficient (COC) and edge preservation index (EPI) parameters. The improvement of the proposed approach in terms of performance parameters PSNR, COC, SSIM and EPI is respectively 2.24%, 7.9%, 17.18% and 6.32% more than the existing GA-based method considering retinal OCT image. The results indicate that the suggested algorithm effectively suppresses the speckle noise of different noise variances, and the de-noised medical image is more suitable for clinical diagnosis.
C1 [Sahu, Sima] Malla Reddy Engn Coll Autonomous, Dept Elect & Commun Engn, Hyderabad, Telangana, India.
   [Singh, Amit Kumar] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Singh, AK (corresponding author), Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, India.
EM simahal@mrec.ac.in; amit.singh@nitp.ac.in
CR Achim A, 2001, IEEE T MED IMAGING, V20, P772, DOI 10.1109/42.938245
   Agrawal S, 2021, SUSTAIN COMPUT-INFOR, V31, DOI 10.1016/j.suscom.2021.100565
   Arun PS, 2022, OPTIK, V263, DOI 10.1016/j.ijleo.2022.169332
   Ben Abdallah M, 2016, NEURAL COMPUT APPL, V27, P1273, DOI 10.1007/s00521-015-1933-9
   Bian LH, 2015, J BIOMED OPT, V20, DOI 10.1117/1.JBO.20.3.036006
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chen HG, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107298
   Chen JK, 2023, IEEE T MED IMAGING, V42, P594, DOI 10.1109/TMI.2022.3213372
   Chen Q, 2015, J DIGIT IMAGING, V28, P346, DOI 10.1007/s10278-014-9742-8
   Esmaeili Mahdad, 2017, J Med Signals Sens, V7, P86
   Gholami P, 2020, COMPUT ELECTR ENG, V81, DOI 10.1016/j.compeleceng.2019.106532
   Gonzalez RC, 2002, DIGITAL IMAGE PROCES, P6627
   Iftimia N, 2003, J BIOMED OPT, V8, P260, DOI 10.1117/1.1559060
   Jorgensen T.M., 2007, Proceedings of SPIE, V6627, P6627
   Kandati DR, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11172714
   Lahmiri S, 2017, OPT LASER TECHNOL, V90, P128, DOI 10.1016/j.optlastec.2016.11.015
   Liu H, 2023, NEURAL COMPUT APPL, V35, P12331, DOI 10.1007/s00521-020-05687-9
   Liu HZ, 2020, OSA CONTINUUM, V3, P2630, DOI 10.1364/OSAC.402623
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Mukhopadhyay S, 2013, PROC TECH, V10, P680, DOI 10.1016/j.protcy.2013.12.410
   Om H, 2014, OPT LASER TECHNOL, V57, P252, DOI 10.1016/j.optlastec.2013.07.018
   Paulinas M, 2007, INF TECHNOL CONTROL, V36, P278
   Pircher M, 2003, J BIOMED OPT, V8, P565, DOI 10.1117/1.1578087
   Sahu S, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03681-0
   Sahu S, 2019, IN HDB MULTIMEDIA IN, P449
   Sahu S, 2019, MULTIMED TOOLS APPL, V78, P4089, DOI 10.1007/s11042-017-5221-9
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Sudeep PV, 2016, COMPUT BIOL MED, V71, P97, DOI 10.1016/j.compbiomed.2016.02.003
   Tang C, 2017, LASER PHYS LETT, V14, DOI DOI 10.1088/1612-202X/AA5690
   Vaiyapuri T, 2021, J INTELL FUZZY SYST, V41, P1575, DOI 10.3233/JIFS-210429
   Viedma IA, 2022, NEUROCOMPUTING, V507, P247, DOI 10.1016/j.neucom.2022.08.021
   Wong A, 2010, OPT EXPRESS, V18, P8338, DOI 10.1364/OE.18.008338
   Xu JB, 2013, OPT LETT, V38, P2900, DOI 10.1364/OL.38.002900
   Yacoub H, 2009, IEEE T GEOSCI REMOTE, V47, P1318, DOI 10.1109/TGRS.2009.2012866
   Yu W, 2016, P 2015 INT C EL INF, P27
   Zhou Q, 2023, BIOMED SIGNAL PROCES, V80, DOI 10.1016/j.bspc.2022.104348
NR 36
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 10
BP 31081
EP 31102
DI 10.1007/s11042-023-16575-4
EA SEP 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KU8C7
UT WOS:001059026300002
DA 2024-07-18
ER

PT J
AU Gagandeep
   Kaur, J
   Mathur, S
   Kaur, S
   Nayyar, A
   Singh, SP
   Mathur, S
AF Gagandeep
   Kaur, Jaskirat
   Mathur, Sanket
   Kaur, Sukhpreet
   Nayyar, Anand
   Singh, Simar Preet
   Mathur, Sandeep
TI Evaluating and mitigating gender bias in machine learning based resume
   filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gender Bias; Information extraction; Resume filtering; Resume
   classification; Word Embeddings; Vectorization; Gender masking
ID INFORMATION
AB Shortlisting resumes for the companies are being automated using artificial intelligence however, training systems to do that incorporate high social biases in the models. Considering the vitality of mitigating gender bias present in society, the research introduces a method for hiding gender specific terms from data, termed as Gender Masking, before finding the similarity with the job requirements. The paper ideates a method of reduction in indulgence of social biases in machine learning based resume filtering algorithms. In addition, an evaluation method is proposed to justify exclusion of gender specific terms from classification of resumes short-listed for a particular role based upon requirements. The novelty of the proposed method is that upon extraction of information from the resume based on probabilistic indexing, the gender specific terms are masked. This corpus is used as the received information in form of word encoding, across the stated requirements in order to retrieve a similarity score of the information using cosine similarity in correspondence to the posting. The proposed model is evaluated using gender-swapped corpus to ensure unbiased performance of the algorithm. The evaluation method represents the performance variation of the text on swapping the gender, it represents the unintentional differences the algorithm captures based on the biases present in the society. The experimental research is taken out on preprocessed datasets (Online Resume Datasets), from which an average of 15.46% are observed to have been affected by gender bias, which is omitted through the proposed method. From the results computed, an average increase of 1.2% accuracy on the trained Random Forest model is experienced outperforming state-of-the-art techniques of training generic Linear SVM, Logistic Regression and Multinomial Naive Bayes models. The model is regularized to have 100 maximum trees in the ensemble along with 20 maximum depth and 10 minimum samples to split the nodes.
C1 [Gagandeep; Mathur, Sanket; Kaur, Sukhpreet] Chandigarh Engn Coll CGC, Landran, Mohali, India.
   [Kaur, Jaskirat] Punjab Engn Coll Deemed Be Univ, Chandigarh, India.
   [Nayyar, Anand] Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang, Vietnam.
   [Singh, Simar Preet] Bennett Univ, Greater Noida, India.
   [Mathur, Sandeep] Noida Int Univ, Greater Noida, India.
C3 Punjab Engineering College (Deemed University); Duy Tan University;
   Noida International University
RP Nayyar, A (corresponding author), Duy Tan Univ, Fac Informat Technol, Grad Sch, Da Nang, Vietnam.
EM gaganpec@yahoo.com; jaskiratkaur17@gmail.com; rajeev.sanket@gmail.com;
   sukhpreet.4479@cgc.edu.in; anandnayyar@duytan.edu.vn;
   dr.simarpreetsingh@gmail.com; sandeep2809@gmail.com
RI Singh, Dr. Simar Preet/T-7056-2018; Nayyar, Anand/F-3732-2015
OI Singh, Dr. Simar Preet/0000-0002-2443-7835; Nayyar,
   Anand/0000-0002-9821-6146
CR [Anonymous], 2015, Int J Comput Appl, DOI DOI 10.5120/IJAIS15-451394
   [Anonymous], 2007, CRFsuite: a fast implementation of Conditional Random Fields CRFs
   Bennett Krista, 2004, Linguistic steganography: survey, analysis, and robustness concerns for hiding information in text
   Bolukbasi T, 2016, ADV NEUR IN, V29
   Breaugh JA, 2009, HUM RESOUR MANAGE R, V19, P219, DOI 10.1016/j.hrmr.2009.02.003
   Çelik D, 2016, TURK J ELECTR ENG CO, V24, P141, DOI 10.3906/elk-1304-130
   Chen J., 2016, Electronic Imaging, V2016, P1
   Chen J, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/5761287
   Chicco D, 2021, METHODS MOL BIOL, V2190, P73, DOI 10.1007/978-1-0716-0826-5_3
   Christian H., 2016, COMTECH COMPUT MATH, V7, P285, DOI DOI 10.21512/COMTECH.V7I4.3746
   Cowgill Bo, 2018, Bias and productivity in humans and algorithms: theory and evidence from resume screening, DOI DOI 10.2139/SSRN.343373729
   Deep G, 2022, J HEALTHC ENG, V2022, DOI 10.1155/2022/9505229
   Deshpande KV, 2020, ADJUNCT PUBLICATION, P268, DOI DOI 10.1145/3386392.3399569
   Faloutsos C, 2012, MOR KAUF D, P39
   Guo SQ, 2016, EXPERT SYST APPL, V60, P169, DOI 10.1016/j.eswa.2016.04.013
   Howard JL, 1996, J APPL SOC PSYCHOL, V26, P112, DOI 10.1111/j.1559-1816.1996.tb01841.x
   Islam A., 2008, ACM Trans. Knowl. Discov. Data, V2, P1, DOI [10.1145/1376815.1376819, DOI 10.1145/1376815.1376819]
   Kaur H., 2021, Artificial Intelligence to Solve Pervasive Internet of Things Issues, P183
   Kiritchenko S, 2018, P 7 JOINT C LEX COMP, DOI [10.48550/arXiv.1805.04508, DOI 10.48550/ARXIV.1805.04508]
   Li YH, 2006, IEEE T KNOWL DATA EN, V18, P1138, DOI 10.1109/TKDE.2006.130
   Lin Y, 2016, Arxiv, DOI [arXiv:1607.07657, 10.48550/arXiv.1607.07657, DOI 10.48550/ARXIV.1607.07657]
   Lu K., 2020, Gender Bias in Neural Natural Language Processing, P189, DOI DOI 10.1007/978-3-030-62077-6
   Maheshwari S., 2010, An approach to extract special skills to improve the performance of resume selection. In International workshop on databases in networked information systems (pp. 256-273)
   Mikolov T., 2013, P 2013 C N AM CHAPT
   Narayana VL, 2018, Ingenierie des Systemes d'Information, V23, P115
   Park K, 2020, APPL ARTIF INTELL, V34, P396, DOI 10.1080/08839514.2020.1723868
   Roy PK, 2018, INT J INFORM MANAGE, V42, P25, DOI 10.1016/j.ijinfomgt.2018.05.003
   Roy PK, 2020, PROCEDIA COMPUT SCI, V167, P2318, DOI 10.1016/j.procs.2020.03.284
   RUBENSTEIN H, 1965, COMMUN ACM, V8, P627, DOI 10.1145/365628.365657
   Singh S, 2023, MICROSYST TECHNOL, V29, P457, DOI 10.1007/s00542-022-05315-7
   Solanki A, 2019, Smart computing and self-adaptive systems, P251
   Stamatatos E, 2018, J ASSOC INF SCI TECH, V69, P461, DOI 10.1002/asi.23968
   Sun T, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P1630
   Van Rijsbergen C.J., 1979, PROC JOINT IBMUNIV N, P1
   Wang TL, 2019, IEEE I CONF COMP VIS, P5309, DOI 10.1109/ICCV.2019.00541
   Wang Z, 2016, P COL 2016, DOI [10.48550/arXiv.1602.07019, DOI 10.48550/ARXIV.1602.07019]
   Xia PP, 2015, INFORM SCIENCES, V307, P39, DOI 10.1016/j.ins.2015.02.024
   Yu K., 2005, P 43 ANN M ASS COMPU, P499, DOI [10.3115/1219840.1219902, DOI 10.3115/1219840.1219902]
   Zhang BH, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P335, DOI 10.1145/3278721.3278779
   Zhang LL, 2015, PROCEDIA COMPUT SCI, V60, P1128, DOI 10.1016/j.procs.2015.08.163
   Zhao J, 2018, P 2018 C N AM CHAPT, V2, P15, DOI DOI 10.18653/V1/N18-2003
   Zu S., 2019, Int J Nat Lang Comput, V8, P29
NR 42
TC 0
Z9 0
U1 3
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26599
EP 26619
DI 10.1007/s11042-023-16552-x
EA SEP 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062557000001
DA 2024-07-18
ER

PT J
AU Devrari, A
   Kumar, A
   Kuchhal, P
AF Devrari, Aakanksha
   Kumar, Adesh
   Kuchhal, Piyush
TI Global aspects and overview of 5G multimedia communication
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE 5G communication technology; Filtered OFDM; SC-FDMA; NOMA; LDPC; Polar
   codes
ID NONORTHOGONAL MULTIPLE-ACCESS; TO-DEVICE COMMUNICATIONS; MIMO-NOMA;
   MASSIVE-MIMO; WIRELESS NETWORKS; WAVE-FORMS; DESIGN; PERFORMANCE;
   CAPACITY; SYSTEMS
AB The fifth generation (5G) of mobile technology is a new universal wireless standard that permits the formation of an original form of network that associates everything and everyone globally, comprising objects, gadgets, and machines. The 5G wireless technology has proven to offer quick data rates, low latency, full connection and availability across the wideband spectrum, enormous network capacity, and a more dependable user experience for more users. For creative and user-friendly experiences in industrial contacts, higher efficiency and performance are agreed upon. Higher data speeds are possible with 5G networks, with peak rates of 20 Gbps and average rates of 100 Mbps or more. The paper presents the study on 5G technology in terms of network evolution, generation networks, issues in current cell networks, 5G potential areas, standardization, and network needs. The different aspects are discussed for 5G systems in terms of modulation techniques, multiple carrier schemes such as Orthogonal frequency division multiplexing (OFDM), Single carrier frequency division multiplexing (SC-FDMA), Generalized Frequency Division Multiplexing (GFDM), Universal Filtered Multi-Carrier (UFMC), Filter Bank Multicarrier (FBMC), Filtered OFDM, Spectral OFDM (SP-OFDM) and advanced multiple access functionalities such as Non-Orthogonal Multiple Access (NOMA), cognitive radio and. An overview of the different channel coding schemes is also discussed such as turbo codes, Low-Density Parity Check Code (LDPC), and polar codes. 5G communication has the novelty to integrate scalable computing devices with low latency and embedding artificial intelligence, and deep learning techniques that can be employed to make the systems more agile, smart, and robust. The networks are scalable and support device-to-device communication with fast switching, fast data rates in Gbps, very low latency, massive network capacity, improved dependability, increased accessibility, and a more reliable user experience for a larger user base.
C1 [Devrari, Aakanksha; Kumar, Adesh; Kuchhal, Piyush] Univ Petr & Energy Studies, Sch Engn, Dept Elect & Elect Engn, Dehra Dun 248007, India.
C3 University of Petroleum & Energy Studies (UPES)
RP Kumar, A (corresponding author), Univ Petr & Energy Studies, Sch Engn, Dept Elect & Elect Engn, Dehra Dun 248007, India.
EM adeshmanav@gmail.com
RI kuchhal, piyush/T-1544-2019; KUMAR, ADESH/AAP-1581-2020
OI kuchhal, piyush/0000-0002-6326-9440; KUMAR, ADESH/0000-0002-0209-9206
CR 5G-DOCOMO, 2015, 5G RAD ACC REQ CONC
   Abdoli J, 2015, IEEE INT WORK SIGN P, P66, DOI 10.1109/SPAWC.2015.7227001
   Adhikari P., 2008, Understanding Millimeter Wave Wireless Communication, P1
   Agiwal M, 2016, IEEE COMMUN SURV TUT, V18, P1617, DOI 10.1109/COMST.2016.2532458
   Agyapong PK, 2014, IEEE COMMUN MAG, V52, P65, DOI 10.1109/MCOM.2014.6957145
   Akpakwu GA, 2017, IEEE ACCESS, P99
   Akyildiz IF, 2016, COMPUT NETW, V106, P17, DOI 10.1016/j.comnet.2016.06.010
   Al-Falahy N, 2017, IT PROF, V19, P12, DOI 10.1109/MITP.2017.9
   Al-Imari M, 2014, 2014 11TH INTERNATIONAL SYMPOSIUM ON WIRELESS COMMUNICATIONS SYSTEMS (ISWCS), P781, DOI 10.1109/ISWCS.2014.6933459
   Andrews JG, 2014, IEEE J SEL AREA COMM, V32, P1065, DOI 10.1109/JSAC.2014.2328098
   [Anonymous], 2015, Recommendation ITU
   [Anonymous], 2016, PROC GLOB COMMUN C G
   [Anonymous], 2016, IEEE POW EN SOC GEN, DOI DOI 10.1109/PESGM.2016.7741781
   Arikan E, 2009, IEEE T INFORM THEORY, V55, P3051, DOI 10.1109/TIT.2009.2021379
   Baliyan N., 2017, P INT C INT COMM CON, DOI [10.1007/978-981-10-1708-7_132, DOI 10.1007/978-981-10-1708-7_132]
   Bangerter B, 2014, IEEE COMMUN MAG, V52, P90, DOI 10.1109/MCOM.2014.6736748
   Bektas C, 2022, 2022 IEEE FUTURE NETWORKS WORLD FORUM, FNWF, P652, DOI 10.1109/FNWF55208.2022.00120
   Ben-Dor E, 2011, GLOB TELECOMM CONF
   Boccardi F, 2014, IEEE COMMUN MAG, V52, P74, DOI 10.1109/MCOM.2014.6736746
   Bockelmann C, 2016, IEEE COMMUN MAG, V54, P59, DOI 10.1109/MCOM.2016.7565189
   Boroujeny BF., 2009, PHYDYAS WORKSH
   Buccheri L, 2018, IEEE WCNC
   Cai DH, 2016, IEEE VTS VEH TECHNOL, DOI 10.1109/VTCSpring.2016.7504356
   Casaccia L, 2018, 1 5G STANDARD IS COM
   Cha YO, 2023, IEEE ANTENN PROPAG M, V65, P10, DOI 10.1109/MAP.2023.3290385
   Chen H, 2018, IEEE COMMUN MAG, V56, P119, DOI 10.1109/MCOM.2018.1701178
   Chen SZ, 2017, IEEE T VEH TECHNOL, V66, P3185, DOI 10.1109/TVT.2016.2596438
   Chen XJ, 2017, IEEE WIREL COMMUN, V24, P24, DOI 10.1109/MWC.2017.1600344
   Chhaya L., 2017, J. Electr. Electron. Eng., V10, P43
   Chhaya L, 2018, ADV INTELL SYST COMP, V624, P981, DOI 10.1007/978-981-10-5903-2_103
   Chhaya L, 2018, SMART CITIES-BASEL, V1, P176, DOI 10.3390/smartcities1010011
   Chhaya L, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6010005
   Choi J, 2015, IEEE T COMMUN, V63, P791, DOI 10.1109/TCOMM.2015.2394393
   Choi J, 2014, IEEE COMMUN LETT, V18, P313, DOI 10.1109/LCOMM.2013.123113.132450
   Cirik AC, 2014, IEEE T SIGNAL PROCES, V62, P3874, DOI 10.1109/TSP.2014.2330806
   Cosovic M, 2017, 5G MOBILE CELLULAR N
   Cui JJ, 2016, IEEE SIGNAL PROC LET, V23, P1226, DOI 10.1109/LSP.2016.2591561
   Dai LL, 2015, IEEE COMMUN MAG, V53, P74, DOI 10.1109/MCOM.2015.7263349
   Devrari A., 2017, PROCEEDING INT C INT, P425
   Diamantoulakis PD, 2016, IEEE T WIREL COMMUN, V15, P8422, DOI 10.1109/TWC.2016.2614937
   Diao QJ, 2016, IEEE T INFORM THEORY, V62, P2947, DOI 10.1109/TIT.2015.2508455
   Ding ZG, 2016, IEEE WIREL COMMUN LE, V5, P416, DOI 10.1109/LWC.2016.2574709
   Ding ZG, 2016, IEEE T WIREL COMMUN, V15, P4438, DOI 10.1109/TWC.2016.2542066
   Ding ZG, 2016, IEEE ACCESS, V4, P1393, DOI 10.1109/ACCESS.2016.2551040
   Ding ZG, 2016, IEEE SIGNAL PROC LET, V23, P629, DOI 10.1109/LSP.2016.2543025
   Ding ZG, 2016, IEEE T WIREL COMMUN, V15, P537, DOI 10.1109/TWC.2015.2475746
   Ding ZG, 2015, IEEE COMMUN LETT, V19, P1462, DOI 10.1109/LCOMM.2015.2441064
   Doré JB, 2014, IEEE GLOBE WORK, P983, DOI 10.1109/GLOCOMW.2014.7063561
   Ericsson, 2018, 5G TRIAL CAS STOR
   Ericsson, 2015, CISC VIS NETW IND GL
   Fang D, 2016, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2016.7841947
   Fang F, 2016, IEEE T COMMUN, V64, P3722, DOI 10.1109/TCOMM.2016.2594759
   Farhang-Boroujeny B, 2016, IEEE COMMUN SURV TUT, V18, P2474, DOI 10.1109/COMST.2016.2565566
   Farhang-Boroujeny B, 2011, IEEE SIGNAL PROC MAG, V28, DOI 10.1109/MSP.2011.940267
   Fei D, 2006, IEEE T PARALL DISTR, V17, P335, DOI 10.1109/TPDS.2006.46
   Feng DQ, 2014, IEEE COMMUN MAG, V52, P49, DOI 10.1109/MCOM.2014.6807946
   GAMAGE H, 2017, 2017 EUR C NETW COMM, P1, DOI DOI 10.1109/EUCNC.2017.7980697
   Garau M, 2017, IEEE INT SYM BROADB, P357
   Garzón-Bohórquez R, 2018, IEEE T COMMUN, V66, P1833, DOI 10.1109/TCOMM.2017.2783971
   Gomaa N, 2022, MULTIMED TOOLS APPL, V81, P5645, DOI 10.1007/s11042-021-11703-4
   Gong MX, 2011, IEEE ICC
   Goyal S, 2015, IEEE COMMUN MAG, V53, P121, DOI 10.1109/MCOM.2015.7105650
   GSMA Intelligence, 2014, CISC VIS NETW IND GL
   Gupta N, 2022, COMPUT SYST SCI ENG, V40, P1073, DOI 10.32604/csse.2022.019911
   Higuchi K., 2013, P IEEE VEH TECHN C V, P1, DOI DOI 10.1109/VTCFALL.2013.6692307
   Higuchi K, 2015, IEICE T COMMUN, VE98B, P403, DOI 10.1587/transcom.E98.B.403
   Hilal W, 2023, P IEEE, V111, P575, DOI 10.1109/JPROC.2023.3272577
   Hoeschele T, 2021, TELECOMMUN POLICY, V45, DOI 10.1016/j.telpol.2020.102091
   Höglund A, 2017, IEEE NETWORK, V31, P16, DOI 10.1109/MNET.2017.1700082
   Holma H., 2015, LTE SMALL CELL OPTIM, DOI [10.1002/9781118912560, DOI 10.1002/9781118912560]
   Hong WB, 2017, IEEE T ANTENN PROPAG, V65, P6250, DOI 10.1109/TAP.2017.2740963
   Horvat M, 2011, SCIENCE, V334, P1066, DOI 10.1126/science.1214295
   Huawei, 2013, CISC VIS NETW IND GL
   Islam SMR, 2017, IEEE COMMUN SURV TUT, V19, P721, DOI 10.1109/COMST.2016.2621116
   Kassam J, 2023, ELECTRONICS-SWITZ, V12, DOI 10.3390/electronics12041001
   Khan AA, 2016, IEEE COMMUN SURV TUT, V18, P860, DOI 10.1109/COMST.2015.2481722
   Khan F, 2012, ANN ALLERTON CONF, P1517, DOI 10.1109/Allerton.2012.6483399
   Kim C, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417044
   Kim JB, 2015, IEEE COMMUN LETT, V19, P2037, DOI 10.1109/LCOMM.2015.2474856
   Komoro TT., 2017, NTT DOCOMO TECH J, V18, P1
   Krause J, 2016, REF, V38
   Kulkarni V, 2021, DIGIT POLICY REGUL G, V23, P337, DOI 10.1108/DPRG-12-2020-0178
   Kumar A, 2017, ADV INTELLIGENT SYST, V479, DOI [10.1007/978-981-10-1708-7_33, DOI 10.1007/978-981-10-1708-7_33]
   Kumar A, 2017, P INT C INT COMM CON, P1079
   Kumar A, 2019, WIRELESS PERS COMMUN, V106, P1855, DOI 10.1007/s11277-018-5724-3
   Kumar A, 2018, WIRELESS PERS COMMUN, V102, P2211, DOI 10.1007/s11277-018-5376-3
   Kumar A, 2017, WIRELESS PERS COMMUN, V97, P3043, DOI 10.1007/s11277-017-4660-y
   Kumar A, 2015, PROCEDIA COMPUT SCI, V48, P454, DOI 10.1016/j.procs.2015.04.119
   Kumar A, 2022, COMPUT SYST SCI ENG, V40, P645, DOI 10.32604/csse.2022.019449
   Kumar A, 2021, INT J ELECTRON, V108, P1124, DOI 10.1080/00207217.2020.1819441
   Lee D, 2012, IEEE COMMUN MAG, V50, P148, DOI 10.1109/MCOM.2012.6146494
   Lin C, 2016, IEEE COMMUN MAG, V54, P124, DOI 10.1109/MCOM.2016.1600306CM
   Lin C, 2016, IEEE T WIREL COMMUN, V15, P4660, DOI 10.1109/TWC.2016.2543733
   Liu F, 2015, 2015 IEEE 26TH ANNUAL INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P1127, DOI 10.1109/PIMRC.2015.7343467
   Liu YW, 2016, IEEE COMMUN LETT, V20, P1465, DOI 10.1109/LCOMM.2016.2559459
   Liu YW, 2016, IEEE J SEL AREA COMM, V34, P938, DOI 10.1109/JSAC.2016.2549378
   Lu L, 2014, IEEE J-STSP, V8, P742, DOI 10.1109/JSTSP.2014.2317671
   Lv L, 2016, IEEE COMMUN LETT, V20, P2059, DOI 10.1109/LCOMM.2016.2596763
   Men JJ, 2015, IEEE COMMUN LETT, V19, P1686, DOI 10.1109/LCOMM.2015.2472006
   Nilopour H, 2013, 2013 IEEE 24TH INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR, AND MOBILE RADIO COMMUNICATIONS (PIMRC), P332, DOI 10.1109/PIMRC.2013.6666156
   Nokia Networks, 2014, FUTUREWORKS LOOK AH
   Ompal, 2021, WIRELESS PERS COMMUN, V119, P1321, DOI 10.1007/s11277-021-08282-w
   Osseiran A, 2014, IEEE COMMUN MAG, V52, P26, DOI 10.1109/MCOM.2014.6815890
   Otao N., 2012, 2012 9th International Symposium on Wireless Communication Systems (ISWCS 2012), P476, DOI 10.1109/ISWCS.2012.6328413
   Oughton E, 2018, TECHNOL FORECAST SOC, V133, P141, DOI 10.1016/j.techfore.2018.03.016
   Qaddus A, 2016, 2016 INTERNATIONAL CONFERENCE ON OPEN SOURCE SYSTEMS AND TECHNOLOGIES (ICOSST), P13, DOI 10.1109/ICOSST.2016.7838330
   Qiao J, 2015, IEEE COMMUN MAG, V53, P209, DOI 10.1109/MCOM.2015.7010536
   Qin ZJ, 2016, IEEE ICC, P584, DOI 10.1109/ICC.2016.7510755
   Rischke J, 2021, IEEE ACCESS, V9, P121786, DOI 10.1109/ACCESS.2021.3108423
   Saghezchi FB, 2017, INT WIREL COMMUN, P121, DOI 10.1109/IWCMC.2017.7986273
   Sahin A, 2015, 2015 IEEE GLOB WORKS, P1, DOI [10.1109/GLOCOMW.2015.7414173, DOI 10.1109/GLOCOMW.2015.7414173]
   Sahin A, 2014, IEEE COMMUN SURV TUT, V16, P1312, DOI 10.1109/SURV.2013.121213.00263
   Saito Y, 2013, IEEE VTS VEH TECHNOL
   Salameh HB, 2023, IEEE ACCESS, V11, P12949, DOI 10.1109/ACCESS.2023.3242645
   Salazar Z, 2023, IEEE ACCESS, V11, P43925, DOI 10.1109/ACCESS.2023.3268759
   Sampath H, 2002, IEEE COMMUN MAG, V40, P143, DOI 10.1109/MCOM.2002.1031841
   Saxena N, 2017, IEEE T IND INFORM, V13, P1471, DOI 10.1109/TII.2017.2681105
   Schaich F., 2014, 2014 IEEE 79 VEH TEC, P1, DOI [DOI 10.1109/VTCSPRING.2014.7023145, 10.1109/VTCSpring.2014.7023145]
   Service Requirements for Machine-Type Communications (MTC), 2014, 22368 3GPP TS
   Shin H, 2020, TECHNOL FORECAST SOC, V153, DOI 10.1016/j.techfore.2020.119948
   Shin W, 2017, IEEE COMMUN MAG, V55, P176, DOI 10.1109/MCOM.2017.1601065
   Shin W, 2017, IEEE COMMUN LETT, V21, P84, DOI 10.1109/LCOMM.2016.2615097
   Sood SWATI., 2013, SINGAPOREAN J SCI RE, V5, P47
   Stenumgaard P, 2013, IEEE COMMUN MAG, V51, P186, DOI 10.1109/MCOM.2013.6515064
   Stüber GL, 2004, P IEEE, V92, P271, DOI 10.1109/JPROC.2003.821912
   Sun Q, 2015, IEEE WIREL COMMUN LE, V4, P405, DOI 10.1109/LWC.2015.2426709
   Sun Y, 2016, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2016.7842087
   Tao YZ, 2015, CHINA COMMUN, V12, P1, DOI 10.1109/CC.2015.7315054
   Tian Y, 2016, IEEE COMMUN LETT, V20, P998, DOI 10.1109/LCOMM.2016.2545672
   Timotheou S, 2015, IEEE SIGNAL PROC LET, V22, P1647, DOI 10.1109/LSP.2015.2417119
   Trigka M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176692
   Ul Hassan M, 2022, COGN COMPUT, V14, P475, DOI 10.1007/s12559-021-09969-9
   Vakilian V, 2013, IEEE GLOBE WORK, P223, DOI 10.1109/GLOCOMW.2013.6824990
   Wang H, 2017, IEEE COMMUN SURV TUT, V19, P2621, DOI 10.1109/COMST.2017.2721379
   Wen MW, 2022, IEEE J-STSP, V16, P7, DOI 10.1109/JSTSP.2021.3137669
   Wunder G, 2014, IEEE GLOBE WORK, P565, DOI 10.1109/GLOCOMW.2014.7063492
   Wunder G, 2014, IEEE COMMUN MAG, V52, P97, DOI 10.1109/MCOM.2014.6736749
   Yaghoubi F, 2018, IEEE WIREL COMMUN, V25, P56, DOI 10.1109/MWC.2018.1700233
   Yu XL, 2023, IEEE T VEH TECHNOL, V72, P14396, DOI 10.1109/TVT.2023.3285074
   Zabetian N, 2016, 2016 8TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P62, DOI 10.1109/ISTEL.2016.7881783
   Zeng M, 2016, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2016.7842156
   Zeng M, 2017, IEEE J SEL AREA COMM, V35, P2413, DOI 10.1109/JSAC.2017.2725879
   Zeng M, 2017, IEEE WIREL COMMUN LE, V6, P534, DOI 10.1109/LWC.2017.2712149
   Zhang W., 2019, HDB COGNITIVE RADIO, P122, DOI [10.1007/978-981-10-1394-2, DOI 10.1007/978-981-10-1394-2]
   Zhang X, 2015, IEEE GLOB COMM CONF, DOI 10.1109/GLOCOM.2015.7417854
   Zhang Y, 2017, IEEE T VEH TECHNOL, V66, P2852, DOI 10.1109/TVT.2016.2578949
   Zheng G, 2015, IEEE T SIGNAL PROCES, V63, P555, DOI 10.1109/TSP.2014.2376885
NR 147
TC 1
Z9 1
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2024
VL 83
IS 9
BP 26439
EP 26484
DI 10.1007/s11042-023-16549-6
EA AUG 2023
PG 46
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA KN2R1
UT WOS:001062556300008
DA 2024-07-18
ER

PT J
AU Zouache, D
   Got, A
   Alarabiat, D
   Abualigah, L
   Talbi, E
AF Zouache, Djaafar
   Got, Adel
   Alarabiat, Deemah
   Abualigah, Laith
   Talbi, El-Ghazali
TI A novel multi-objective wrapper-based feature selection method using
   quantum-inspired and swarm intelligence techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Firefly algorithm; Quantum computing; Particle swarm optimization;
   Multi-objective optimization; Feature selection; Classification
ID FIREFLY ALGORITHM; OPTIMIZATION
AB Feature selection plays a pivotal role in machine learning, serving as a critical preprocessing step. Its impact extends beyond enhancing the classification capabilities of learning algorithms; it also enables the reduction of dataset dimensionality. Consequently, feature selection entails a multi-objective optimization problem, striving to minimize the number of features while maximizing classification accuracy. Surprisingly, there are only a few studies that approach feature selection from a multi-objective perspective, compared to the more prevalent single-objective viewpoint.Motivated by this gap, we present a novel multi-objective algorithm for tackling the feature selection problem. Our approach draws inspiration from quantum computing and combines the strengths of the Firefly Algorithm (FA) and the Particle Swarm Optimizer (PSO). Leveraging quantum computing enhances solution distribution, while the cooperative nature of FA and PSO facilitates effective exploration of the feature space. Additionally, we introduce two fixed-size external archives, dedicated to storing the best solutions. The archive sizes are controlled using the epsilon dominance relation. We evaluate the efficiency of our algorithm through an extensive comparison against both single and multi-objective feature selection algorithms that enjoy high regard in the field. Furthermore, we propose a high-performance detection system that harnesses our algorithm alongside three Convolutional Neural Network Algorithms. This system demonstrates its potential in accurately identifying COVID-19 disease from X-ray images. Our experimental results unequivocally establish the superiority of our proposed algorithm over its competitors. It consistently delivers feature subsets with a smaller number of features and achieves higher classification accuracy.
C1 [Zouache, Djaafar] Univ Mohamed El Bachir El Ibrahimi, Dept Comp Sci, Bordj Bou Arreridj, Algeria.
   [Zouache, Djaafar; Got, Adel] Univ Sci & Technol Houari Boumediene, LRIA Lab, Algiers, Algeria.
   [Alarabiat, Deemah] Saudi Elect Univ, Coll Comp & Informat, Abha, Saudi Arabia.
   [Abualigah, Laith] Al al Bayt Univ, Prince Hussein Bin Abdullah Fac Informat Technol, Comp Sci Dept, Mafraq 25113, Jordan.
   [Abualigah, Laith] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos 135053, Lebanon.
   [Abualigah, Laith] Al Ahliyya Amman Univ, Hourani Ctr Appl Sci Res, Amman 19328, Jordan.
   [Abualigah, Laith] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
   [Abualigah, Laith] Appl Sci Private Univ, Appl Sci Res Ctr, Amman 11931, Jordan.
   [Abualigah, Laith] Univ Sains Malaysia, Sch Comp Sci, Gelugor 11800, Pulau Pinang, Malaysia.
   [Abualigah, Laith] Sunway Univ Malaysia, Sch Engn & Technol, Petaling Jaya 27500, Malaysia.
   [Talbi, El-Ghazali] Univ Lille, Polytech Lille, CNRS, INRIA CRISTAL, Lille, France.
C3 University Science & Technology Houari Boumediene; Saudi Electronic
   University; Al al-Bayt University; Lebanese American University;
   Al-Ahliyya Amman University; Middle East University; Universiti Sains
   Malaysia; Sunway University; Universite de Lille; Centre National de la
   Recherche Scientifique (CNRS)
RP Zouache, D (corresponding author), Univ Mohamed El Bachir El Ibrahimi, Dept Comp Sci, Bordj Bou Arreridj, Algeria.; Zouache, D (corresponding author), Univ Sci & Technol Houari Boumediene, LRIA Lab, Algiers, Algeria.
EM djaafarzouache@yahoo.fr; adeladl34@yahoo.fr; d.alarabiat@seu.edu.sa;
   aligah.2020@gmail.com; el-ghazali.talbi@univ-lille.fr
RI Abualigah, Laith/ABC-9695-2020
OI Abualigah, Laith/0000-0002-2203-4549
CR Abualigah L, 2022, EXPERT SYST APPL, V192, DOI 10.1016/j.eswa.2021.116368
   Abualigah L, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116158
   Abualigah L, 2021, COMPUT IND ENG, V157, DOI 10.1016/j.cie.2021.107250
   Abualigah L, 2021, COMPUT METHOD APPL M, V376, DOI 10.1016/j.cma.2020.113609
   Agrawal RK, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106092
   Agushaka JO, 2022, COMPUT METHOD APPL M, V391, DOI 10.1016/j.cma.2022.114570
   Amoozegar M, 2018, EXPERT SYST APPL, V113, P499, DOI 10.1016/j.eswa.2018.07.013
   Auger A, 2009, FOGA'09: PROCEEDINGS OF THE 10TH ACM SIGRVO CONFERENCE ON FOUNDATIONS OF GENETIC ALGORITHMS, P87
   Canayaz M, 2021, BIOMED SIGNAL PROCES, V64, DOI 10.1016/j.bspc.2020.102257
   Chowdhury MEH, 2020, IEEE ACCESS, V8, P132665, DOI 10.1109/ACCESS.2020.3010287
   Coello CAC, 2004, IEEE T EVOLUT COMPUT, V8, P256, DOI 10.1109/tevc.2004.826067
   Dabba A, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03441-0
   Dash M., 1997, Intelligent Data Analysis, V1
   Frank A., 2010, UCI MACHINE LEARNING
   Got A, 2021, EXPERT SYST APPL, V183, DOI 10.1016/j.eswa.2021.115312
   Jin C, 2015, SIGNAL PROCESS, V109, P172, DOI 10.1016/j.sigpro.2014.10.031
   Jovic A, 2015, 2015 8TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1200, DOI 10.1109/MIPRO.2015.7160458
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Kermany Daniel, 2018, Mendeley Data, V2
   Khan A, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0235668
   Labani M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113276
   MARILL T, 1963, IEEE T INFORM THEORY, V9, P11, DOI 10.1109/TIT.1963.1057810
   Mirjalili S, 2016, EXPERT SYST APPL, V47, P106, DOI 10.1016/j.eswa.2015.10.039
   Nama S, 2023, SWARM EVOL COMPUT, V79, DOI 10.1016/j.swevo.2023.101304
   Oyelade ON, 2022, IEEE ACCESS, V10, P16150, DOI 10.1109/ACCESS.2022.3147821
   Paul A, 2022, APPL INTELL, V52, P3499, DOI 10.1007/s10489-021-02355-w
   Cohen JP, 2020, Arxiv, DOI [arXiv:2006.11988, 10.59275/j.melba.2020-48g7, DOI 10.59275/J.MELBA.2020-48G7]
   Piri J, 2021, COMPUT BIOL MED, V135, DOI 10.1016/j.compbiomed.2021.104558
   Pitchaimanickam B, 2020, NEURAL COMPUT APPL, V32, P7709, DOI 10.1007/s00521-019-04441-0
   Farshi TR, 2021, MULTIMEDIA SYST, V27, P125, DOI 10.1007/s00530-020-00716-y
   Rathee S, 2020, PROCEDIA COMPUT SCI, V167, P1656, DOI 10.1016/j.procs.2020.03.376
   Sahoo A, 2016, INT J BIO-INSPIR COM, V8, P367, DOI 10.1504/IJBIC.2016.081326
   Talbi EG, 2012, INT T OPER RES, V19, P283, DOI 10.1111/j.1475-3995.2011.00808.x
   Too J, 2019, AXIOMS, V8, DOI 10.3390/axioms8030079
   Too J, 2019, COMPUTATION, V7, DOI 10.3390/computation7010012
   Too J, 2018, COMPUTERS, V7, DOI 10.3390/computers7040058
   WHITNEY AW, 1971, IEEE T COMPUT, VC 20, P1100, DOI 10.1109/T-C.1971.223410
   wu Q, 2019, IEEE ACCESS, V7, P80588, DOI 10.1109/ACCESS.2019.2919956
   Wu X, 2021, ANN NUCL ENERGY, V160, DOI 10.1016/j.anucene.2021.108404
   Xi ML, 2016, COMPUT MATH METHOD M, V2016, DOI 10.1155/2016/3572705
   Xue B, 2013, IEEE T CYBERNETICS, V43, P1656, DOI 10.1109/TSMCB.2012.2227469
   Xue Y, 2021, IEEE T EMERGING TOPI
   Yang XS, 2009, LECT NOTES COMPUT SC, V5792, P169, DOI 10.1007/978-3-642-04944-6_14
   Ying ZQ, 2017, LECT NOTES COMPUT SC, V10425, P36, DOI 10.1007/978-3-319-64698-5_4
   Zare M., 2023, J. Bionic Eng., V5, P1
   Zhang Y, 2020, INFORM SCIENCES, V507, P67, DOI 10.1016/j.ins.2019.08.040
   Zhang Y, 2017, INFORM SCIENCES, V418, P561, DOI 10.1016/j.ins.2017.08.047
   Zhang Y, 2016, NEUROCOMPUTING, V171, P1281, DOI 10.1016/j.neucom.2015.07.057
   Zhang YX, 2017, SCI REP-UK, V7, DOI [10.1038/srep40290, 10.1038/srep42085]
   Zhou Y, 2021, IEEE T ARTIF INTELL
   Zouache D, 2018, COMPUT IND ENG, V115, P26, DOI 10.1016/j.cie.2017.10.025
   Zouache D, 2016, SOFT COMPUT, V20, P2781, DOI 10.1007/s00500-015-1681-x
NR 52
TC 2
Z9 2
U1 2
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 AUG 9
PY 2023
DI 10.1007/s11042-023-16411-9
EA AUG 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA O6VD2
UT WOS:001045151400008
DA 2024-07-18
ER

PT J
AU Memon, ZA
   Hussain, SM
AF Memon, Zulfiqar Ali
   Hussain, Syed Muneeb
TI Predicting movie success based on pre-released features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Box-Office; Revenue; Movie Success; Predictive Analytics; Machine
   Learning; Success Criteria
ID MODEL
AB Movie making is a billion-dollar industry. Every month hundreds of movies get released and earn millions of dollars in revenue. However, majority of the movies fail to create an impact on the Box-Office and flop. This not only put a bad impression on the entire cast and crew but also creates a huge setback in financial terms. As a producer or investor, it is crucial for them to have some certainty that the money they are investing in will give a good return otherwise they'll lose all their capital eventually. The idea of this research is to predict based on certain pre-released variables of the movie, whether an upcoming movie is going to succeed or fail in monetary terms. Many researches have already been doing that in this domain based on different techniques and around different datasets. The novelty of this research is that the proposed approach is not only based on classical movie features, but incorporates all other dependencies as well such as star power, popularity of the cast, track record of director, and actors, to predict whether movie will succeed or fail and whether an investor should invest in the movie proposal or not. This article uses multiple machine learning algorithms and tested them over various evaluation metrics. Among them, CatBoostRegression and Stacking Regression outperformed the remaining by giving the maximum model accuracy of 83.84% and 83.5% respectively. The article have used IMDB Movies Extensive Dataset. This dataset contains information of movies from 1894 to 2020 and has at least 100 votes.
C1 [Memon, Zulfiqar Ali; Hussain, Syed Muneeb] Natl Univ Comp & Emerging Sci NUCES FAST, Dept Comp Sci, Karachi, Pakistan.
RP Memon, ZA (corresponding author), Natl Univ Comp & Emerging Sci NUCES FAST, Dept Comp Sci, Karachi, Pakistan.
EM memon.zulfiqar@gmail.com; muneebhussain94@gmail.com
RI /O-2002-2013
OI /0000-0001-6448-097X
CR Abbasi MA, 2021, CLUSTER COMPUT, V24, P2133, DOI 10.1007/s10586-021-03243-1
   Bhave A, 2015, 2015 INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING (ICPC)
   Bosse T, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON INTELLIGENT AGENT TECHNOLOGY (IAT 2007), P207, DOI 10.1109/IAT.2007.61
   Bosse T, 2015, COGN COMPUT, V7, P111, DOI 10.1007/s12559-014-9277-9
   Bosse T, 2012, COGN SYST RES, V19-20, P39, DOI 10.1016/j.cogsys.2012.04.002
   Bosse T, 2010, LECT NOTES ARTIF INT, V6334, P14, DOI 10.1007/978-3-642-15314-3_3
   Bosse T, 2009, LECT NOTES ARTIF INT, V5925, P292, DOI 10.1007/978-3-642-11161-7_20
   Bosse T, 2008, LECT NOTES COMPUT SC, V5355, P141, DOI 10.1007/978-3-540-89617-3_10
   Bristi WR, 2019, INT CONF COMPUT
   Hoogendoorn M, 2013, COMPUT BIOL MED, V43, P444, DOI 10.1016/j.compbiomed.2013.01.021
   Kashif UA, 2018, INT J CLOUD APPL COM, V8, P47, DOI 10.4018/IJCAC.2018040103
   Kashif UA, 2015, 2015 12TH INTERNATIONAL BHURBAN CONFERENCE ON APPLIED SCIENCES AND TECHNOLOGY (IBCAST), P275, DOI 10.1109/IBCAST.2015.7058516
   Khan MA, 2012, INT CONF ADV COMPUT, P167, DOI 10.1109/ACSAT.2012.52
   Laeeq K, 2018, INT J EMERG TECHNOL, V13, P252, DOI 10.3991/ijet.v13i09.8000
   Laghari A, 2018, IEEE ACCESS, V6, P37444, DOI 10.1109/ACCESS.2018.2851540
   Laghari A, 2016, INT BHURBAN C APPL S, P381, DOI 10.1109/IBCAST.2016.7429906
   Memon Zulfiqar, 2008, 2008 IEEE/WIC/ACM International Conference on Intelligent Agent Technology, P308, DOI 10.1109/WIIAT.2008.311
   Memon ZA, 2009, BRAIN INFORMATICS BI, V5819, DOI [10.1007/978-3-642-04954-5_12, DOI 10.1007/978-3-642-04954-5_12]
   Memon ZA, 2012, LECT NOTES COMPUT SC, V7190, P56, DOI 10.1007/978-3-642-29356-6_3
   Memon ZA, 2010, COGN NEURODYNAMICS, V4, P377, DOI 10.1007/s11571-010-9136-7
   Samad F, 2018, INT J FUTUR GENER CO, V11, P13, DOI 10.14257/ijfgcn.2018.11.1.02
   Siddiqi S, 2016, INT CONF FRONT INFO, P63, DOI [10.1109/FIT.2016.020, 10.1109/FIT.2016.18]
NR 22
TC 2
Z9 2
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20975
EP 20996
DI 10.1007/s11042-023-16319-4
EA AUG 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001042485500003
DA 2024-07-18
ER

PT J
AU Tao, L
   Nakamura, S
   Wang, XT
   Kawahara, T
   Tamura, G
   Yamasaki, T
AF Tao, Li
   Nakamura, Shunsuke
   Wang, Xueting
   Kawahara, Tatsuya
   Tamura, Gen
   Yamasaki, Toshihiko
TI A large-scale television advertising dataset for detailed impression
   analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE TV advertisement dataset; Multi-modal regression; Impression analysis;
   Impression prediction
ID SENTIMENT ANALYSIS; EMOTION RECOGNITION; MEMORABILITY; MODELS
AB Creating impressive video content such as movies and advertisements is a very important yet challenging task in business that requires both a sense of creativity and a lot of experience. Even professionals cannot necessarily invoke the impressions and emotions that they have aimed at. Many video advertisements are created and then disappear without giving a large impact on viewers. This paper presents a large-scale dataset of television (TV) advertisements that consists of 14,490 videos. The impressions of each video such as the recognition rate and interestingness rate are from the results of questionnaires answered by 620 participants. We also present a baseline for predicting the impression effects of TV advertisements by using visual and audio information, metadata such as broadcasting pattern, business category, the popularity of the casts, and text information including texts appearing on videos and narrations in audios. We predict four impressions of the viewers: 1) how much participants remember the video afterward, 2) how much they feel like buying the product/service, 3) how much they become interested in the product/service, and 4) how much they like the content of the advertisement itself. By combining images, audio, metadata, cast data, and text data, our baseline method is able to predict such impressions with a correlation of 0.69-0.82, much better than using a single-modal feature such as visual data or audio data only. This paper also gives some possible applications such as estimating the importance scores of each key frame, which gives us informative insights about how to make the advertisement content more impressive.
C1 [Tao, Li; Nakamura, Shunsuke; Yamasaki, Toshihiko] Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
   [Wang, Xueting] CyberAgent AI Lab, Tokyo, Japan.
   [Kawahara, Tatsuya; Tamura, Gen] Video Res Ltd, Tokyo, Japan.
C3 University of Tokyo
RP Yamasaki, T (corresponding author), Univ Tokyo, Grad Sch Informat Sci & Technol, Tokyo, Japan.
EM chntaoli@gmail.com; kreski.linux.sea@gmail.com; wangxueting12@gmail.com;
   tatsuya.kawahara@videor.co.jp; gen.tamura@videor.co.jp;
   yamasaki@cvm.t.u-tokyo.ac.jp
RI li, lan/KCJ-5061-2024; zhang, jiahao/KEE-9357-2024; zhou,
   you/KBC-3567-2024; chen, yue/JXW-9556-2024; Li, Xinyue/JVN-4601-2024;
   Liu, Shaobo/JUU-5767-2023; Li, Yuan/JXW-8930-2024; zhang,
   xiaoyu/KEJ-0657-2024; zhang, xinyi/JWA-0980-2024; Liu,
   Jingyi/JWP-6326-2024; Zhang, Xiaoyu/JXR-6386-2024; Zhang,
   Xiaoxi/KBP-8753-2024; zhang, ling/JXW-6931-2024; Yu, Yan/KCL-1047-2024;
   wang, xueting/JPY-2782-2023; zheng, Li/JVN-7465-2024; zhang,
   xu/JXX-7692-2024
OI Li, Yuan/0009-0004-1325-0954; Yu, Yan/0000-0003-2233-344X; 
FU JSPS [JP19K20289, JP18H03339]
FX AcknowledgementsThis work was partially financially supported by the
   Grants-in-Aid for Scientific Research Numbers JP19K20289 and JP18H03339
   from JSPS.
CR Aaker DA, 1982, J ADVERT RES
   Adamov AZ, 2016, I C APPL INF COMM TE, P187
   Al-Moslmi T, 2017, IEEE ACCESS, V5, P16173, DOI 10.1109/ACCESS.2017.2690342
   Aytar Y, 2016, ADV NEUR IN, V29
   Bainbridge WA, 2017, NEUROIMAGE, V149, P141, DOI 10.1016/j.neuroimage.2017.01.063
   Bakshi RK, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P452
   Baveye Y, 2018, IEEE T AFFECT COMPUT, V9, P396, DOI 10.1109/TAFFC.2017.2661284
   Bazzani L, 2016, IEEE WINT CONF APPL, DOI 10.1109/wacv.2016.7477688
   Benitez-Quiroz CF, 2016, PROC CVPR IEEE, P5562, DOI 10.1109/CVPR.2016.600
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Bylinskii Z, 2017, UIST'17: PROCEEDINGS OF THE 30TH ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P57, DOI 10.1145/3126594.3126653
   Cakir E, 2015, IEEE IJCNN
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chae Y, 2018, IEEE IMAGE PROC, P1428, DOI 10.1109/ICIP.2018.8451513
   Chen H, 2015, PROC CVPR IEEE, P1836, DOI 10.1109/CVPR.2015.7298793
   Chen Junxuan, 2016, ACM MM, P811, DOI DOI 10.1145/2964284.2964325
   Chiranjeevi P, 2015, IEEE T IMAGE PROCESS, V24, P2701, DOI 10.1109/TIP.2015.2421437
   Cohendet R, 2019, IEEE I CONF COMP VIS, P2531, DOI 10.1109/ICCV.2019.00262
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Dubey R, 2015, IEEE I CONF COMP VIS, P1089, DOI 10.1109/ICCV.2015.130
   Ebrahimi M, 2017, IEEE INTELL SYST, V32, P70, DOI 10.1109/MIS.2017.3711649
   EKMAN P, 1987, J PERS SOC PSYCHOL, V53, P712, DOI 10.1037/0022-3514.53.4.712
   Eyben F., 2013, P 21 ACM INT C MULT, P835, DOI DOI 10.1145/2502081.2502224
   Fajtl J, 2018, PROC CVPR IEEE, P6363, DOI 10.1109/CVPR.2018.00666
   Fei M, 2017, NEUROCOMPUTING
   Fire M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P1053, DOI 10.1109/iThings-GreenCom-CPSCom-SmartData.2017.160
   Gregov J, 2008, ANN M NCA 94 ANN CON
   Han JW, 2015, IEEE T CYBERNETICS, V45, P1692, DOI 10.1109/TCYB.2014.2358647
   Hannun Awni, 2014, ARXIV
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XN, 2020, PROCEEDINGS OF THE 43RD INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '20), P639, DOI 10.1145/3397271.3401063
   Hou SJ, 2017, PATTERN RECOGN, V68, P66, DOI 10.1016/j.patcog.2017.03.003
   Hussain Z, 2017, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.2017.123
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Ikeda J, 2021, INT C PATT RECOG, P2995, DOI 10.1109/ICPR48806.2021.9412666
   Irie G, 2010, IEEE T MULTIMEDIA, V12, P523, DOI 10.1109/TMM.2010.2051871
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kar A, 2017, PR INT CONF DATA SC, P373, DOI 10.1109/DSAA.2017.37
   Kaushik L, 2017, IEEE-ACM T AUDIO SPE, V25, P1668, DOI 10.1109/TASLP.2017.2678164
   Kay W., 2017, CORR ABS170506950
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Kim S, 2017, P 2017 CHI C HUM FAC, P2706
   Kosti R, 2017, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2017.212
   Kosti R, 2017, IEEE COMPUT SOC CONF, P2309, DOI 10.1109/CVPRW.2017.285
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Li T, 2015, IEEE T CYBERNETICS, V45, P2336, DOI 10.1109/TCYB.2015.2392156
   Liang Y, 2018, BIOSCI BIOTECH BIOCH, V82, P2130, DOI [10.1080/09168451.2018.1514247, 10.1109/ISGT-Asia.2018.8467956]
   Lu JS, 2016, ADV NEUR IN, V29
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Mathews A, 2016, AAAI CONF ARTIF INTE, P3574
   Mencattini A, 2017, IEEE T AFFECT COMPUT, V8, P314, DOI 10.1109/TAFFC.2016.2531664
   Noroozi F, 2019, IEEE T AFFECT COMPUT, V10, P60, DOI 10.1109/TAFFC.2017.2713783
   Nwana AO, 2013, IEEE GLOB COMM CONF, P3138, DOI 10.1109/GLOCOM.2013.6831554
   Okada G, 2018, ITE TRANS MEDIA TECH, V6, P131, DOI 10.3169/mta.6.131
   Pan YT, 2020, WORLD WIDE WEB, V23, P2259, DOI 10.1007/s11280-020-00793-z
   Pan YT, 2020, FRONT COMPUT SCI-CHI, V14, DOI 10.1007/s11704-019-8123-3
   Pan YT, 2019, NEUROCOMPUTING, V332, P137, DOI 10.1016/j.neucom.2018.12.025
   Pang B, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P79, DOI 10.3115/1118693.1118704
   Park KW., 2021, APPL SOFT COMPUT, V107116, P103
   Peng KC, 2015, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2015.7298687
   Perera S, 2019, IEEE COMPUT SOC CONF, P800, DOI 10.1109/CVPRW.2019.00108
   Plutchik R, 2001, AM SCI, V89, P344, DOI 10.1511/2001.4.344
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Redi M, 2014, PROC CVPR IEEE, P4272, DOI 10.1109/CVPR.2014.544
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Saleh B., 2015, Proceedings of the 41st Graphics Interface Conference, P59
   Shekhar S, 2017, IEEE INT CONF COMP V, P2730, DOI 10.1109/ICCVW.2017.321
   Shukla A., 2017, Proceedings of the 19th ACM International Conference on Multimodal Interaction, P402
   Shukla A, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1148, DOI 10.1145/3123266.3123444
   Siarohin A, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P327, DOI 10.1145/3078971.3078986
   Soomro K, 2012, 12120402 ARXIV, P1
   Takahashi N, 2018, IEEE T MULTIMEDIA, V20, P513, DOI 10.1109/TMM.2017.2751969
   Tao L, 2021, IEEE T IMAGE PROCESS, V30, P9231, DOI 10.1109/TIP.2021.3124156
   Tao L, 2020, IEEE IMAGE PROC, P1786, DOI 10.1109/ICIP40778.2020.9191133
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Van den Oord A., 2013, P NIPS
   Vaswani A, 2017, ADV NEUR IN, V30
   VAUGHN R, 1980, J ADVERTISING RES, V20, P27
   Wang JC, 2015, IEEE T AFFECT COMPUT, V6, P261, DOI 10.1109/TAFFC.2015.2415212
   Wang KX, 2015, IEEE T AFFECT COMPUT, V6, P69, DOI 10.1109/TAFFC.2015.2392101
   Wilber MJ, 2017, IEEE I CONF COMP VIS, P1211, DOI 10.1109/ICCV.2017.136
   Xia BH, 2020, INT J SEMANT COMPUT, V14, P71, DOI 10.1142/S1793351X20400048
   Xia BH, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P162, DOI [10.1109/BigMM.2019.00033, 10.1109/BigMM.2019.00-29]
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu BH, 2018, IEEE T AFFECT COMPUT, V9, P255, DOI 10.1109/TAFFC.2016.2622690
   Yadati K, 2014, IEEE T MULTIMEDIA, V16, P15, DOI 10.1109/TMM.2013.2282128
   Yang SF, 2014, IEEE T AFFECT COMPUT, V5, P432, DOI 10.1109/TAFFC.2014.2364581
   Yashima T., 2016, Asian Conference on Computer Vision, P85
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   You QZ, 2017, AAAI CONF ARTIF INTE, P231
   Zhang HJ, 2017, IEEE T IND INFORM, V13, P520, DOI 10.1109/TII.2016.2605629
   Zhang SQ, 2018, IEEE T MULTIMEDIA, V20, P1576, DOI 10.1109/TMM.2017.2766843
   Zhao NX, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201355
   Zhen QK, 2019, IEEE T AFFECT COMPUT, V10, P524, DOI 10.1109/TAFFC.2017.2747553
NR 100
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18779
EP 18802
DI 10.1007/s11042-023-14704-7
EA AUG 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040962400007
OA hybrid
DA 2024-07-18
ER

PT J
AU Farek, L
   Benaidja, A
AF Farek, Lazhar
   Benaidja, Amira
TI A non-redundant feature selection method for text categorization based
   on term co-occurrence frequency and mutual information
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Feature selection; Text categorization; Context-based co-occurrence;
   Co-occurrence frequency; Mutual information; Redundancy
ID CLASSIFICATION; REDUNDANCY; ALGORITHM
AB Feature selection is a crucial preprocessing step for text categorization that can help to reduce the feature space, speed up the learning process, and improve the accuracy of classification algorithms. Efficient and popular filter-based feature selection methods based on document frequency, such as Information Gain, Chi-Square Test, Improved Gini Index, etc., are most widely used due to their high performance and low time complexity compared to information-theoretic methods, which have effective performance on low-dimensional data but are less efficient in front of high-dimensional data. However, the main issue of statistical filter-based methods is feature redundancy; assessing the feature's importance independently of other ones leads to selecting a large number of features that do not provide additional information for the class variable, resulting in additional training time and low classification performance. To take advantage of the effectiveness of information-theoretic methods in the treatment of redundancy issues but with low time complexity, we propose a new non-sequential selection method with low time complexity, named Co-occurrence-level Feature Selection and Redundancy Removal (CFSRR), which uses mutual information to evaluate the importance of each feature with respect to its co-occurring ones instead of using already selected features as in classical theoretic-information-based methods. The idea is that co-occurring features in the same context are semantically correlated, forming candidate redundant features and helping to avoid feature-by-feature redundancy evaluation. Compared to ten effective feature selection metrics, empirical results show the efficiency of CFSRR in terms of micro-F1 and macro-F1 scores obtained from Naive Bayes and SVM classifiers on five publicly available datasets, showing its robustness for balanced, unbalanced, binary, and multi-class classification problems.
C1 [Farek, Lazhar; Benaidja, Amira] Univ Guelma, Comp Sci Dept, Guelma, Algeria.
   [Farek, Lazhar; Benaidja, Amira] Univ Setif 1, Comp Sci Dept, Setif, Algeria.
C3 Universite 8 Mai 1945 de Guelma; Universite Ferhat Abbas Setif
RP Farek, L (corresponding author), Univ Guelma, Comp Sci Dept, Guelma, Algeria.; Farek, L (corresponding author), Univ Setif 1, Comp Sci Dept, Setif, Algeria.
EM farek.lazhar@univ-guelma.dz; amira.benaidja@univ-setif.dz
RI LAZHAR, FAREK/JLM-1815-2023
OI LAZHAR, FAREK/0000-0002-6958-736X; BENAIDJA, AMIRA/0000-0003-4982-9744
CR [Anonymous], 1995, P 4 ANN S DOCUMENT A
   Attieh J, 2023, KNOWL-BASED SYST, V261, DOI 10.1016/j.knosys.2022.110215
   Basu A., 2003, Proceedings of the 36th Annual Hawaii International Conference on System Sciences, HICSS 2003, DOI DOI 10.1109/HICSS.2003.1174243
   BATTITI R, 1994, IEEE T NEURAL NETWOR, V5, P537, DOI 10.1109/72.298224
   Bell AJ, 2003, P SOC PHOTO-OPT INS, V5102, P383
   Chen JN, 2009, EXPERT SYST APPL, V36, P5432, DOI 10.1016/j.eswa.2008.06.054
   Chen YF, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P598, DOI 10.1109/FSKD.2014.6980902
   Cover Thomas M., 1991, ELEMENTS INFORM THEO, DOI DOI 10.1002/0471200611
   Cover Thomas M, 1999, Elements of information theory
   Craven M, 1998, FIFTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-98) AND TENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICAL INTELLIGENCE (IAAI-98) - PROCEEDINGS, P509
   Eliguzel N, 2022, EXPERT SYST APPL, V202, DOI 10.1016/j.eswa.2022.117433
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Gao WF, 2020, APPL INTELL, V50, P1272, DOI 10.1007/s10489-019-01597-z
   Georgieva-Trifonova Tsvetanka, 2021, IOP Conference Series: Materials Science and Engineering, V1031, DOI 10.1088/1757-899X/1031/1/012048
   Gomez Hidalgo J. M., 2006, P 2006 ACM S DOC ENG, P107, DOI [10.1145/1166160.1166191, DOI 10.1145/1166160.1166191]
   Günal S, 2012, TURK J ELECTR ENG CO, V20, P1296, DOI 10.3906/elk-1101-1064
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hussain SF, 2020, IEEE ACCESS, V8, P181763, DOI 10.1109/ACCESS.2020.3028469
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kolluri J, 2020, Mater Today Proc, DOI [10.1016/j.matpr.2020.10.058, DOI 10.1016/J.MATPR.2020.10.058]
   Kou G, 2016, TECHNOL ECON DEV ECO, V22, P649, DOI 10.3846/20294913.2016.1202353
   Kumar V., 2014, SMART COMPUTING REV, V4, P211, DOI [10.6029/smartcr.2014.03.007, DOI 10.6029/SMARTCR.2014.03.007, DOI 10.1145/2740070.2626320]
   Labani M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113276
   Li B, 2016, P 2016 ACM S DOC ENG
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Li SJ, 2020, IEEE ACCESS, V8, P139512, DOI 10.1109/ACCESS.2020.3012768
   Liu W, 2022, PLOS ONE, V17
   Manochandar S, 2018, COMPUT IND ENG, V124, P139, DOI 10.1016/j.cie.2018.07.008
   Mao KZ, 2004, IEEE T SYST MAN CY B, V34, P629, DOI 10.1109/TSMCB.2002.804363
   McGill William, 1954, Transactions of the IRE Professional Group on Information Theory, P93, DOI 10.1007/BF02289159
   Mielniczuk J, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24081079
   Mishra NK, 2020, INFORM PROCESS MANAG, V57, DOI 10.1016/j.ipm.2020.102240
   Pang B., 2004, ANN M ASS COMP LING, P271, DOI [10.3115/1218955.1218990, DOI 10.3115/1218955.1218990]
   Pintas JT, 2021, ARTIF INTELL REV, V54, P6149, DOI 10.1007/s10462-021-09970-6
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Rehman A, 2017, INFORM PROCESS MANAG, V53, P473, DOI 10.1016/j.ipm.2016.12.004
   Sanderson M, 1996, REPORT GLASGOW IR GR
   Sebastiani F, 2002, ACM COMPUT SURV, V34, P1, DOI 10.1145/505282.505283
   Shang WQ, 2007, EXPERT SYST APPL, V33, P1, DOI 10.1016/j.eswa.2006.04.001
   Stearns S. D., 1976, 3rd International Joint Conference on Pattern Recognition, P71
   Tang J., 2014, Data Classification, V37, DOI DOI 10.1201/B17320
   Tang Z, 2022, EXPERT SYST APPL, V189, DOI 10.1016/j.eswa.2021.115985
   Timme N, 2014, J COMPUT NEUROSCI, V36, P119, DOI 10.1007/s10827-013-0458-4
   Uysal AK, 2016, EXPERT SYST APPL, V43, P82, DOI 10.1016/j.eswa.2015.08.050
   Uysal AK, 2014, EXPERT SYST APPL, V41, P5938, DOI 10.1016/j.eswa.2014.03.041
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   Wah YB, 2018, PERTANIKA J SCI TECH, V26, P329
   Wang JQ, 2021, LECT NOTES COMPUT SC, V12682, P136, DOI 10.1007/978-3-030-73197-7_9
   Webkb, 2019, 4 U DAT SET, DOI [10.1007/s00500-016-2093-25, DOI 10.1007/S00500-016-2093-25]
   Witten I. H., 2005, DATA MINING PRACTICA
   Wolf D, 1996, GEN MUTUAL INFORM IN
   Wu GH, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND MECHANICAL AUTOMATION (CSMA), P157, DOI 10.1109/CSMA.2015.38
   Yang JM, 2012, INFORM PROCESS MANAG, V48, P741, DOI 10.1016/j.ipm.2011.12.005
   Zheng Z., 2004, ACM Sigkdd Explorations Newsletter, V6, P80, DOI DOI 10.1145/1007730.1007741
NR 54
TC 0
Z9 0
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 20193
EP 20214
DI 10.1007/s11042-023-15876-y
EA JUL 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040925900015
DA 2024-07-18
ER

PT J
AU Kaur, S
   Bawa, S
   Kumar, R
AF Kaur, Sukhandeep
   Bawa, Seema
   Kumar, Ravinder
TI Heuristic-based text segmentation of bilingual handwritten documents for
   Gurumukhi-Latin scripts
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Bilingual documents; Line segmentation; Word segmentation;
   Gurumukhi-Latin; Handwritten
ID WORD SEGMENTATION; LINE EXTRACTION; RECOGNITION
AB This paper focuses on the segmentation of unconstrained handwritten documents containing bilingual data at the word level. Most of the official documents available in India are bilingual, i.e., in the regional language as well as English language. For the purpose of current research work, the handwritten documents from the academic domain containing Punjabi from Gurumukhi script and English language from Latin script have been considered. A heuristic approach based on projection profiles, statistical and structural properties of script has been designed to segment the textual data of documents. The proposed approach can segment the closed, curved, skewed and touched text lines having large variations in pattern and size. For word segmentation, an end-point detection algorithm has been designed to segment the words with intra word gap. The proposed approaches have been evaluated by designing a domain-based bilingual handwritten dataset after having consultations with academicians, and experts in the field. For text line segmentation, an average accuracy of 95.89% and 92.95% has been achieved for IAM and bilingual dataset respectively. However, for word segmentation, there has been an accuracy of 89.74% and 92.25% respectively for IAM and bilingual dataset. As many as 280 documents with various writing styles and content have been selected for the purpose.
C1 [Kaur, Sukhandeep; Bawa, Seema; Kumar, Ravinder] Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147001, Punjab, India.
C3 Thapar Institute of Engineering & Technology
RP Kumar, R (corresponding author), Thapar Inst Engn & Technol, Comp Sci & Engn Dept, Patiala 147001, Punjab, India.
EM shergillsukhandeep@gmail.com; seema@thapar.edu; ravinder@thapar.edu
RI Kumar, Ravinder/JLL-7567-2023
OI Kumar, Ravinder/0000-0002-0271-2373
FU Council of Scientific and Industrial Research (CSIR) - Ministry of
   Science and Technology [09/677(0031)/2018/EMR-I]; Government of India
FX AcknowledgmentThis research was supported by Council of Scientific and
   Industrial Research (CSIR) funded by the Ministry of Science and
   Technology (09/677(0031)/2018/EMR-I) as well as the Government of India.
CR Ahmad I, 2017, IEEE ACCESS, V5, P10924, DOI 10.1109/ACCESS.2017.2703155
   Alginahi YM, 2015, KSII T INTERNET INF, V9, P3701, DOI 10.3837/tiis.2015.09.023
   Basu S, 2007, PATTERN RECOGN, V40, P1825, DOI 10.1016/j.patcog.2006.10.002
   Bera SK, 2021, EXPERT SYST APPL, V186, DOI 10.1016/j.eswa.2021.115666
   Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792
   dos Santos RP, 2009, 2009 10 INT C DOC AN
   Eskenazi S, 2017, PATTERN RECOGN, V64, P1, DOI 10.1016/j.patcog.2016.10.023
   Gupta D, 2019, MULTIMED TOOLS APPL, V78, P19361, DOI 10.1007/s11042-019-7286-0
   Jindal G. S., 2012, P WORKSH DOC AN REC, P74
   Jindal M.K., 2007, International Journal of Computational Intelligence Research, V3, P277, DOI DOI 10.5019/J.IJCIR.2007.109
   Jindal P, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN ENGINEERING & COMPUTATIONAL SCIENCES (RAECS)
   Jo J, 2020, MULTIMED TOOLS APPL, V79, P32137, DOI 10.1007/s11042-020-09624-9
   Kaur S, 2021, PREPRINTS
   Kaur S, 2020, ARTIF INTELL REV, V53, P1813, DOI 10.1007/s10462-019-09720-9
   Kavitha S, 2015, MALAYS J COMPUT SCI, V28, P283, DOI 10.22452/mjcs.vol28no4.2
   Kundu S, 2020, EXPERT SYST APPL, V140, DOI 10.1016/j.eswa.2019.112916
   Li M, 2022, MOL PSYCHIATR, DOI 10.1038/s41380-022-01580-0
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1313, DOI 10.1109/TPAMI.2007.70792
   Louloudis G, 2009, PATTERN RECOGN, V42, P3169, DOI 10.1016/j.patcog.2008.12.016
   Louloudis G, 2006, 10 INT WORKSH FRONT
   Ma LL, 2020, IEEE ACCESS, V8, P52641, DOI 10.1109/ACCESS.2020.2975023
   Mechi O, 2021, INT J DOC ANAL RECOG, V24, P197, DOI 10.1007/s10032-021-00377-1
   Mohammad K, 2021, MULTIMED TOOLS APPL, V80, P2177, DOI 10.1007/s11042-020-09737-1
   Mondal R, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3038277
   Mukherjee J., 2021, T ASIAN LOW RESOUR L, V21.2, P1
   Pal U, 2003, PROC INT CONF DOC, P1128
   Ptak R, 2017, INT J AP MAT COM-POL, V27, P195, DOI 10.1515/amcs-2017-0014
   Rehman A, 2011, IMAGING SCI J, V59, P177, DOI 10.1179/136821910X12863758415649
   Ryu J, 2015, IEEE SIGNAL PROC LET, V22, P1161, DOI 10.1109/LSP.2015.2389852
   Saba T, 2014, ARTIF INTELL REV, V42, P1047, DOI 10.1007/s10462-011-9271-5
   Sanasam I, 2020, MULTIMED TOOLS APPL, V79, P30135, DOI 10.1007/s11042-020-09416-1
   Sharma DV, 2006, INT C PATT RECOG, P1022
   Sharma MK, 2019, PATTERN ANAL APPL, P1
   Suleyman E, 2021, WIREL NETW, V27, P3483, DOI 10.1007/s11276-019-02221-1
   Sun Y, 2007, APPL SOFT COMPUT, V7, P71, DOI 10.1016/j.asoc.2004.10.009
   Susan S, 2020, PATTERN ANAL APPL, V23, P869, DOI 10.1007/s10044-019-00811-5
   Tian SX, 2016, PATTERN RECOGN, V51, P125, DOI 10.1016/j.patcog.2015.07.009
   Ul-Hasan A, 2015, PROC INT CONF DOC, P1046, DOI 10.1109/ICDAR.2015.7333921
   Vuckovic V, 2017, EXPERT SYST APPL, V80, P210, DOI 10.1016/j.eswa.2017.03.027
   Zahour A, 2007, 9 INT C DOC AN REC I, V1
   Zhao JY, 2020, INT J DOC ANAL RECOG, V23, P267, DOI 10.1007/s10032-020-00358-w
NR 41
TC 0
Z9 0
U1 4
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 18667
EP 18697
DI 10.1007/s11042-023-15335-8
EA JUL 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037377100003
DA 2024-07-18
ER

PT J
AU Liu, Y
   Meng, SY
   Wang, HZ
   Liu, J
AF Liu, Ye
   Meng, Shiyang
   Wang, Hongzhang
   Liu, Jun
TI Deep learning based object detection from multi-modal sensors: an
   overview
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Object detection; Multi-modal; Sensor fusion; Deep learning
ID MULTISPECTRAL PEDESTRIAN DETECTION; REAL-TIME; SEMANTIC SEGMENTATION;
   OBSTACLE DETECTION; VEHICLE DETECTION; NEURAL-NETWORKS; FUSION NETWORK;
   IMAGERY; COMPONENT; TRACKING
AB Object detection is an important problem and has a wide range of applications. In recent years, deep learning based object detection with conventional RGB cameras has made great progress. At the same time, people are more and more aware of the limitations of RGB cameras. The progress of algorithms alone can not fundamentally resolve the challenges of object detection. Unmanned vehicles or mobile robot platforms are often equipped with a variety of sensors in addition to RGB camera, each of which have its own characteristics, and can expand the sensing range of RGB camera from different dimensions. For example, infrared thermal imaging camera and multispectral camera broaden sensing range from spectral dimension, while LiDARs and depth cameras are able to broaden sensing range from the spatial dimension. This paper mainly summarizes the deep learning based object detection methods under the condition of multi-modal sensors, and surveys and categorizes the methods from the perspective of data fusion manner. The datasets of different modality are summarized, and the advantages and disadvantages with different combination of sensors are also discussed in this paper.
C1 [Liu, Ye; Meng, Shiyang; Wang, Hongzhang] Nanjing Univ Posts & Telecommun, Sch Automation & Artificial Intelligence, 9 Wenyuan Rd, Nanjing 210042, Jiangsu, Peoples R China.
   [Liu, Jun] Singapore Univ Technol & Design, Informat Syst Technol & Design Pillar, 8 Somapah Rd, Singapore, Singapore.
C3 Nanjing University of Posts & Telecommunications; Singapore University
   of Technology & Design
RP Liu, J (corresponding author), Singapore Univ Technol & Design, Informat Syst Technol & Design Pillar, 8 Somapah Rd, Singapore, Singapore.
EM yeliu@njupt.edu.cn; 1020051432@njupt.edu.cn; 1219054113@njupt.edu.cn;
   jun_liu@sutd.edu.sg
RI Liu, Shaobo/JUU-5767-2023; Wang, Zejun/KBB-8454-2024; Wang,
   Jiacheng/ABE-5948-2020; wang, zhe/JNE-3510-2023; CHEN,
   WENJIE/JQW-1608-2023; zhao, wei/JZD-4475-2024; Zhang,
   Xiaofeng/JMC-6060-2023; PENG, CHENG/KCL-2506-2024
OI Wang, Jiacheng/0000-0003-4327-1508; Zhang, Xiaofeng/0000-0003-2738-3286;
   
FU Natural science fund for colleges and universities in Jiangsu Province
   [21KJB520015]; Post doctoral fund of Jiangsu Province [2021K398C]
FX AcknowledgementsThe research work of this paper is sponsored by Natural
   science fund for colleges and universities in Jiangsu Province NO.
   21KJB520015, and Post doctoral fund of Jiangsu Province NO. 2021K398C
CR An P, 2022, COMPUT VIS IMAGE UND, V214, DOI 10.1016/j.cviu.2021.103295
   An ZJ, 2022, IEEE SIGNAL PROC LET, V29, P2562, DOI 10.1109/LSP.2022.3229571
   Bahnsen CH, 2019, IEEE T INTELL TRANSP, V20, P2802, DOI 10.1109/TITS.2018.2872502
   Benavides JM, 2003, OPT EXPRESS, V11, P1223, DOI 10.1364/OE.11.001223
   Bhatti UA, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3090410
   Blin R, 2019, IEEE INT C INTELL TR, P27, DOI [10.1109/ITSC.2019.8916853, 10.1109/itsc.2019.8916853]
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Cao H, 2021, IEEE SENS J, V21, P24540, DOI 10.1109/JSEN.2021.3115016
   Cao YP, 2019, ISPRS J PHOTOGRAMM, V150, P70, DOI 10.1016/j.isprsjprs.2019.02.005
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen KY, 2023, KNOWL-BASED SYST, V268, DOI 10.1016/j.knosys.2023.110423
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen Y, 2018, IET COMPUT VIS, V12, P1179, DOI 10.1049/iet-cvi.2018.5315
   Choe G, 2018, IEEE ROBOT AUTOM LET, V3, P1808, DOI 10.1109/LRA.2018.2801390
   Choi WG, 2013, IEEE T PATTERN ANAL, V35, P1577, DOI 10.1109/TPAMI.2012.248
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Clark GA, 2000, IEEE T GEOSCI REMOTE, V38, P304, DOI 10.1109/36.823923
   Cui YD, 2022, IEEE T INTELL TRANSP, V23, P722, DOI 10.1109/TITS.2020.3023541
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis JW, 2007, COMPUT VIS IMAGE UND, V106, P162, DOI 10.1016/j.cviu.2006.06.010
   Deng Z, 2017, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2017.50
   Devaguptapu C, 2019, IEEE COMPUT SOC CONF, P1029, DOI 10.1109/CVPRW.2019.00135
   Dhawan AP, 2009, IEEE ENG MED BIO, P5352, DOI 10.1109/IEMBS.2009.5334045
   Ding L, 2020, SIGNAL PROCESS-IMAGE, V82, DOI 10.1016/j.image.2019.115764
   Du XX, 2018, IEEE INT CONF ROBOT, P3194
   Fayyad J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20154220
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   Gebhardt E, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P37
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gibson KD, 2004, WEED TECHNOL, V18, P742, DOI 10.1614/WT-03-170R1
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   González A, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060820
   Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017
   Guan DY, 2018, APPL OPTICS, V57, pD108, DOI 10.1364/AO.57.00D108
   Guerrero J, 2017, AUSTR UNIV POWER ENG
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han YJ, 2020, ALGORITHMS, V13, DOI 10.3390/a13110271
   Herrmann C, 2018, PROC SPIE, V10643, DOI 10.1117/12.2304400
   Hoffman J, 2016, IEEE INT CONF ROBOT, P5032, DOI 10.1109/ICRA.2016.7487708
   Hou CC, 2019, MEASUREMENT, V143, P246, DOI 10.1016/j.measurement.2019.05.010
   Hou YL, 2018, INFRARED PHYS TECHN, V94, P69, DOI 10.1016/j.infrared.2018.08.029
   Hu XX, 2019, IEEE IMAGE PROC, P1440, DOI [10.1109/ICIP.2019.8803025, 10.1109/icip.2019.8803025]
   Huang SQ, 2020, IET IMAGE PROCESS, V14, P3324, DOI 10.1049/iet-ipr.2019.0772
   Hwang S, 2015, PROC CVPR IEEE, P1037, DOI 10.1109/CVPR.2015.7298706
   Iacono M, 2018, 2018 IEEE RSJ INT C, P1
   Jaus A, 2023, IEEE T INTELL TRANSP, V24, P4438, DOI 10.1109/TITS.2022.3232897
   Jiang QY, 2022, IEEE ACCESS, V10, P53797, DOI 10.1109/ACCESS.2022.3175303
   Jin LJ, 2017, IEEE T DIELECT EL IN, V24, P3530, DOI 10.1109/TDEI.2017.006516
   Jnawali K, 2020, INT J COMPUT ASS RAD, V15, P309, DOI 10.1007/s11548-019-02101-1
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kailai Zhou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P787, DOI 10.1007/978-3-030-58523-5_46
   Kalkan H, 2011, COMPUT ELECTRON AGR, V77, P28, DOI 10.1016/j.compag.2011.03.005
   Karasawa T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P35, DOI 10.1145/3126686.3126727
   Kesten R., 2019, Lyft level 5 perception dataset 2020
   Kim J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122757
   Kim J, 2021, IEEE ROBOT AUTOM LET, V6, P7846, DOI 10.1109/LRA.2021.3099870
   Kim JU, 2021, IEEE T CIRC SYST VID
   Kim MS, 2002, T ASAE, V45, P2027
   Kirk R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010275
   Koenig D, 2017, IEEE COMPUT SOC CONF, P243, DOI 10.1109/CVPRW.2017.36
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Lahoud J, 2017, IEEE I CONF COMP VIS, P4632, DOI 10.1109/ICCV.2017.495
   Lauricella A, 2017, ANTIQUITY, V91, P1344, DOI 10.15184/aqy.2017.90
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li C.T., 2018, ARXIV
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li GB, 2019, IEEE T IMAGE PROCESS, V28, P1591, DOI 10.1109/TIP.2018.2878956
   Li JB, 2016, POSTHARVEST BIOL TEC, V112, P121, DOI 10.1016/j.postharvbio.2015.10.007
   Li SY, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13173510
   Li X, 2022, LECT NOTES COMPUT SC, V13698, P691, DOI 10.1007/978-3-031-19839-7_40
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liang SP, 2022, PATTERN ANAL APPL, V25, P1025, DOI 10.1007/s10044-022-01067-2
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Linder T, 2020, IEEE INT CONF ROBOT, P1000, DOI [10.1109/icra40945.2020.9196899, 10.1109/ICRA40945.2020.9196899]
   Liu C., 2022, ARXIV
   Liu F, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.9.094101
   Liu H., 2022, arXiv
   Liu HL, 2016, INT J ADV ROBOT SYST, V13, DOI 10.1177/1729881416657746
   Liu HJ, 2018, COMPUT ELECTRON AGR, V150, P279, DOI 10.1016/j.compag.2018.05.002
   Liu J, 2016, 27 BRIT MACHINE VISI
   Liu J, 2013, IEEE IMAGE PROC, P3088, DOI 10.1109/ICIP.2013.6738636
   Liu J, 2015, PATTERN RECOGN LETT, V53, P16, DOI 10.1016/j.patrec.2014.09.013
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZY, 2022, IEEE T CIRC SYST VID, V32, P4486, DOI 10.1109/TCSVT.2021.3127149
   Lu C, 2014, IEEE J BIOMED HEALTH, V18, P594, DOI 10.1109/JBHI.2013.2277837
   Luo QH, 2020, NEUROCOMPUTING, V378, P364, DOI 10.1016/j.neucom.2019.10.025
   Mei JR, 2022, LECT NOTES COMPUT SC, V13689, P53, DOI 10.1007/978-3-031-19818-2_4
   Meyer GP, 2019, IEEE COMPUT SOC CONF, P1230, DOI 10.1109/CVPRW.2019.00162
   Meyer GP, 2019, PROC CVPR IEEE, P12669, DOI 10.1109/CVPR.2019.01296
   Mitrokhin A., 2018, 2018 IEEE RSJ INT C, P1, DOI DOI 10.1109/IROS.2018.8593805
   My Kieu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P546, DOI 10.1007/978-3-030-58542-6_33
   Nissimov S, 2015, COMPUT ELECTRON AGR, V113, P104, DOI 10.1016/j.compag.2015.02.001
   Novikova T, 2018, 2018 INTERNATIONAL CONFERENCE LASER OPTICS (ICLO 2018), P553, DOI 10.1109/LO.2018.8435231
   Park K, 2018, PATTERN RECOGN, V80, P143, DOI 10.1016/j.patcog.2018.03.007
   Pei DS, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2019.103178
   Qi CR, 2020, PROC CVPR IEEE, P4403, DOI 10.1109/CVPR42600.2020.00446
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2017, arXiv
   Qiming Zhu, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P1154, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.172
   Qin J, 2011, T ASABE, V54, P2331, DOI 10.13031/2013.40643
   Pham QH, 2020, IEEE INT CONF ROBOT, P2267, DOI [10.1109/icra40945.2020.9197385, 10.1109/ICRA40945.2020.9197385]
   Rahman MM, 2019, INFORM SCIENCES, V476, P147, DOI 10.1016/j.ins.2018.09.040
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roblyer D, 2008, J BIOMED OPT, V13, DOI 10.1117/1.2904658
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sakla W, 2017, IEEE WINT CONF APPL, P916, DOI 10.1109/WACV.2017.107
   Schlosser J, 2016, IEEE INT CONF ROBOT, P2198, DOI 10.1109/ICRA.2016.7487370
   Schwartz CR, 1996, P SOC PHOTO-OPT INS, V2742, P286, DOI 10.1117/12.243007
   Schwarz M, 2018, INT J ROBOT RES, V37, P437, DOI 10.1177/0278364917713117
   Shen XK, 2020, IEEE WINT CONF APPL, P1687, DOI 10.1109/WACV45572.2020.9093276
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shin U, 2023, ARXIV
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sindagi VA, 2019, IEEE INT CONF ROBOT, P7276, DOI [10.1109/ICRA.2019.8794195, 10.1109/icra.2019.8794195]
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song XR, 2021, ALEX ENG J, V60, P73, DOI 10.1016/j.aej.2020.05.035
   Spinello L, 2011, IEEE INT C INT ROBOT, P3838, DOI 10.1109/IROS.2011.6048835
   Sun L, 2020, IEEE ROBOT AUTOM LET, V5, P5558, DOI 10.1109/LRA.2020.3007457
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Tengteng Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P35, DOI 10.1007/978-3-030-58555-6_3
   Tian LC, 2018, IEEE T MULTIMEDIA, V20, P2249, DOI 10.1109/TMM.2018.2803526
   Tomatis S, 2005, PHYS MED BIOL, V50, P1675, DOI 10.1088/0031-9155/50/8/004
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Tu SQ, 2018, BIOSYST ENG, V175, P156, DOI 10.1016/j.biosystemseng.2018.09.004
   Vandersteegen M, 2018, LECT NOTES COMPUT SC, V10882, P419, DOI 10.1007/978-3-319-93000-8_47
   Vázquez-Arellano M, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16050618
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vora S, 2020, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR42600.2020.00466
   Wagner J., 2016, EUR S ART NEUR NETW
   WANCHAITANAWONG N, 2021, 2021 17 INT C MACHIN, P1
   Wang CW, 2021, PROC CVPR IEEE, P11789, DOI 10.1109/CVPR46437.2021.01162
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang YK, 2022, PROC CVPR IEEE, P12104, DOI 10.1109/CVPR52688.2022.01180
   Wolpert A, 2020, 31 BRIT MACH VIS C B
   Wu XP, 2022, PROC CVPR IEEE, P5408, DOI 10.1109/CVPR52688.2022.00534
   Xiang JJ, 2022, INT GEOSCI REMOTE SE, P3532, DOI 10.1109/IGARSS46834.2022.9883131
   Xiang KT, 2021, OPT EXPRESS, V29, P4802, DOI 10.1364/OE.416130
   Xie L, 2020, AAAI CONF ARTIF INTE, V34, P12460
   Xu SQ, 2021, IEEE INT C INTELL TR, P3047, DOI 10.1109/ITSC48978.2021.9564951
   Xu XY, 2017, PATTERN RECOGN, V72, P300, DOI 10.1016/j.patcog.2017.07.026
   Yan C, 2023, NEURAL COMPUT APPL, P1
   Yang HH, 2022, LECT NOTES COMPUT SC, V13668, P662, DOI 10.1007/978-3-031-20074-8_38
   Yang XX, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION (ICRA 2022), P2920, DOI 10.1109/ICRA46639.2022.9811999
   Yoo JH, 2020, SELECTED PAPERS FROM THE NINETEENTH BIENNIAL IEEE CONFERENCE ON ELECTROMAGNETIC FIELD COMPUTATION (IEEE CEFC 2020), DOI [10.1109/CEFC46938.2020.9451336, 10.1007/978-3-030-58583-9_43]
   You Y, 2022, PROC CVPR IEEE, P1183, DOI 10.1109/CVPR52688.2022.00126
   Zhang DY, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0187470
   Zhang GY, 2017, IEEE SIGNAL PROC LET, V24, P1666, DOI 10.1109/LSP.2017.2731952
   Zhang H, 2021, IEEE WINT CONF APPL, P72, DOI 10.1109/WACV48630.2021.00012
   Zhang H, 2020, IEEE IMAGE PROC, P276, DOI [10.1109/ICIP40778.2020.9191080, 10.1109/icip40778.2020.9191080]
   Zhang JM, 2021, IEEE INT C INT ROBOT, P1132, DOI 10.1109/IROS51168.2021.9636109
   Zhang Li., 2021, IEEE Trans. Neural Netw. Learn. Syst, P1
   Zhang L, 2019, IEEE I CONF COMP VIS, P5126, DOI 10.1109/ICCV.2019.00523
   Zhang L, 2019, INFORM FUSION, V50, P20, DOI 10.1016/j.inffus.2018.09.015
   Zhang Mabel M., 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P10, DOI 10.1109/CVPRW.2015.7301291
   Zhang Q, 2021, IEEE T CIRC SYST VID, V31, P1804, DOI 10.1109/TCSVT.2020.3014663
   Zhang Y, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3251414
   Zhang YF, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104042
   Zhao CH, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3128183
   Zhao JW, 2017, IEEE INT CON MULTI, P1536, DOI 10.1109/ICME.2017.8019323
   Zheng Y, 2019, ARXIV
   Zhou KY, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P306, DOI 10.23919/MVA.2017.7986862
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou X., 2019, arXiv
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu Pengfei, 2020, ARXIV
NR 175
TC 0
Z9 0
U1 10
U2 28
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19841
EP 19870
DI 10.1007/s11042-023-16275-z
EA JUL 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001040586800002
DA 2024-07-18
ER

PT J
AU Chen, XH
   Chen, T
AF Chen, Xiuhong
   Chen, Tong
TI Low-rank approximation-based bidirectional linear discriminant analysis
   for image data
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dimensionality reduction; Linear discriminant analysis; Low-rank
   approximation; Left and right projection matrices; Classification;
   Convergence
ID FACE REPRESENTATION; EFFICIENT APPROACH; 2-DIMENSIONAL PCA; RECOGNITION;
   LDA
AB Dimensionality reduction methods for images directly without matrix-to-vector conversion have been widely concerned and achieved good classification results, especially for face recognition problem. However, the existing methods work in the column or/and row direction of images respectively, then project the given image onto the obtained left and right projective matrices to obtain the corresponding feature matrix. On the other hand, the low-rank approximation of matrix (LRAM) is a low-rank representation, which can approximate the original matrix as much as possible through a low-rank matrix and preserve the features in the original data. In this paper, we propose a low-rank approximation-based two-directional linear discriminant analysis method for image data, in which the left and right projection matrices are extracted simultaneously from the image data directly and the low-rank transformed feature matrices of training images are obtained by low-rank approximation of matrix. By minimizing the total reconstruction error and the within-class scatter of the transformed feature matrices and maximizing the between-class scatter of the transformed feature matrices, the proposed method can avoid huge feature matrix problem in some existing methods, and make full use of the discriminant and descriptive information of the images. An efficient iterative optimization algorithm is also devised to solve the proposed model. Experiment results on several datasets demonstrate the effectiveness and superiority of the proposed method.
C1 [Chen, Xiuhong; Chen, Tong] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
   [Chen, Xiuhong] Jiangnan Univ, Jiangsu Key Lab Media Design & Software Technol, Wuxi, Jiangsu, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Chen, XH (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.; Chen, XH (corresponding author), Jiangnan Univ, Jiangsu Key Lab Media Design & Software Technol, Wuxi, Jiangsu, Peoples R China.
EM xiuhongc@jiangnan.edu.cn
OI Chen, Xiuhongc/0000-0001-7600-1673
CR Ahmadi S, 2020, PATT RECOGNIT, V108, P107
   Benavente R, 1998, 24 COMP VIS CTR
   Chen L, 2021, IEEE T IMAGE PROCESS, V30, P3434, DOI 10.1109/TIP.2021.3061908
   Ding C, 2005, SIAM PROC S, P32
   Fu Y, 2008, IEEE T PATTERN ANAL, V30, P2229, DOI 10.1109/TPAMI.2008.154
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Jain A, 1997, IEEE T PATTERN ANAL, V19, P153, DOI 10.1109/34.574797
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Li HX, 2020, INFORM SCIENCES, V510, P283, DOI 10.1016/j.ins.2019.09.032
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Liao L, 2022, PREPRINT
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   Noushath S, 2006, PATTERN RECOGN, V39, P1396, DOI 10.1016/j.patcog.2006.01.018
   Park H, 2022, J MULTIVARIATE ANAL, V188, DOI 10.1016/j.jmva.2021.104836
   Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311
   Qi YF, 2009, APPL MATH COMPUT, V213, P1, DOI 10.1016/j.amc.2009.03.014
   Ren CX, 2010, PATTERN RECOGN, V43, P3742, DOI 10.1016/j.patcog.2010.04.029
   Sanguansat P, 2006, IEICE T INF SYST, VE89D, P2164, DOI 10.1093/ietisy/e89-d.7.2164
   Shi JR, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0138028
   Stork D.G., 2000, Pattern Classification, V2nd
   Tai Y, 2016, PATTERN RECOGN, V50, P1, DOI 10.1016/j.patcog.2015.08.010
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Ye JP, 2005, MACH LEARN, V61, P167, DOI 10.1007/s10994-005-3561-6
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
   Zhang DQ, 2005, LECT NOTES COMPUT SC, V3497, P659
NR 28
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19369
EP 19389
DI 10.1007/s11042-023-16239-3
EA JUL 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001037378900009
DA 2024-07-18
ER

PT J
AU Zhu, XF
   Liu, JY
   Zhou, XY
   Qian, SH
   Yu, JH
AF Zhu, Xingfei
   Liu, Jiayi
   Zhou, Xingyu
   Qian, Shanhua
   Yu, Jinghu
TI Detection of irregular small defects on metal base surface of infrared
   laser diode based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Object detection; Irregular small defects; Attention
   mechanism; Yolo v5s
ID ATTENTION
AB The rapid development of deep learning has promoted the research progress in the field of visual object detection. In metal surface irregular small defect object detection, the traditional metal surface defect detection methods were not effective in detecting small and irregular defects. Therefore, how to improve the detection accuracy of small irregular defects on metal surfaces is a hot and difficult research problem. In this study, we propose a deep learning-based method for detecting small irregular defects on metal surfaces. Firstly, we make our own infrared laser diode metal base surface defect dataset to fill the gap of the dataset. Secondly, a new shallow feature extraction layer based on You Only Look Once (YOLO) v5s (an improved YOLO model) is designed for detecting irregular small object defects in the metal surface defect dataset. Thirdly, an attention mechanism was introduced into the network model to enhance the network's ability to extract features of small target defects. The improved model was trained and evaluated on the laser diode metal base surface defect detection dataset, and the results showed that the accuracy of the improved algorithm improved by 3.8% over the original detection algorithm. The detection accuracy also achieves very significant results when compared with other excellent object detection algorithms.
C1 [Zhu, Xingfei; Liu, Jiayi; Zhou, Xingyu; Qian, Shanhua; Yu, Jinghu] Jiangnan Univ, Wuxi 214122, Jiangsu, Peoples R China.
   [Zhu, Xingfei; Liu, Jiayi; Zhou, Xingyu; Qian, Shanhua; Yu, Jinghu] Jiangsu Key Lab Adv Food Mfg Equipment & Technol, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Yu, JH (corresponding author), Jiangnan Univ, Wuxi 214122, Jiangsu, Peoples R China.; Yu, JH (corresponding author), Jiangsu Key Lab Adv Food Mfg Equipment & Technol, Wuxi 214122, Jiangsu, Peoples R China.
EM jnjxjinghuyu@163.com
FU Jiangsu Key Laboratory of Advanced Food Manufacturing Equipment and
   Technology [FMZ201901]; National Natural Science Foundation of China
   "Research on bionic chewing robot for physical property detection and
   evaluation of food materials" [51375209]
FX AcknowledgementsThe paper work was Supported by Jiangsu Key Laboratory
   of Advanced Food Manufacturing Equipment and Technology (FMZ201901, and
   the National Natural Science Foundation of China "Research on bionic
   chewing robot for physical property detection and evaluation of food
   materials" (51375209).
CR Bao YQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3083561
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Cheng-Yang F, 2017, ARXIV
   Chorowski J, 2015, ADV NEUR IN, V28
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Y, 2020, IEEE T INSTRUM MEAS, V69, P1493, DOI 10.1109/TIM.2019.2915404
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang SQ, 2020, IET IMAGE PROCESS, V14, P3324, DOI 10.1049/iet-ipr.2019.0772
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kisantal M., 2019, ARXIV
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Simard PY, 2003, PROC INT CONF DOC, P958
   Song KC, 2013, APPL SURF SCI, V285, P858, DOI 10.1016/j.apsusc.2013.09.002
   Sutskever I, 2014, ADV NEUR IN, V27
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhu LL, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13183776
NR 44
TC 1
Z9 1
U1 31
U2 71
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 7
BP 19181
EP 19197
DI 10.1007/s11042-023-16352-3
EA JUL 2023
PG 17
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IB3T8
UT WOS:001035535000003
DA 2024-07-18
ER

PT J
AU Ha, TV
   Nguyen, HM
   Thanh, SH
   Nguyen, BT
AF Ha, Thao V.
   Nguyen, Hoang M.
   Thanh, Son H.
   Nguyen, Binh T.
TI Fall detection using mixtures of convolutional neural networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Fall detection; Deep learning; Mixture of experts; Convolutional neural
   network; Data augmentation
AB Falls may happen to everyone; however, with geriatrics, this factor is one of their primary concerns as it might cause detrimental effects on their health or perhaps unintentional death if the case is terrible. To tackle this problem, many scientists have undertaken a considerable amount of research to create a fall detection system. This paper presents a fall detection architecture using a Mixture of Experts (MoE) and CNN3D models on a large public dataset called UP-Fall Detection. Furthermore, we also utilize the data augmentation approach to tackle imbalanced problems in this dataset. Our methods can gain a significant result with 99.67% in weighted average F1 score, which is necessary to build a fall detection system. Model and code are available at https://github.com/hoangNguyen210/Fall-Detection-Research-2.
C1 [Ha, Thao V.; Nguyen, Hoang M.; Thanh, Son H.; Nguyen, Binh T.] Univ Sci, Vietnam Natl Univ Ho Chi Minh City, Ho Chi Minh City, Vietnam.
   [Thanh, Son H.; Nguyen, Binh T.] AISIA Res Lab, Ho Chi Minh City, Vietnam.
C3 Vietnam National University Hochiminh City
RP Nguyen, BT (corresponding author), Univ Sci, Vietnam Natl Univ Ho Chi Minh City, Ho Chi Minh City, Vietnam.; Nguyen, BT (corresponding author), AISIA Res Lab, Ho Chi Minh City, Vietnam.
EM ngtbinh@hcmus.edu.vn
OI Nguyen, Thanh Binh/0000-0001-5249-9702
CR Aggarwal AK, 2022, INT J BIOMED SCI, V7
   Attar M, 2021, CUREUS J MED SCIENCE, V13, DOI 10.7759/cureus.14863
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chahyati D, 2020, INT C ADV COMP SCI I, P371, DOI [10.1109/ICACSIS51025.2020.9263201, 10.1109/icacsis51025.2020.9263201]
   Chen Z., 2022, PREPRINT
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Espinosa R, 2019, COMPUT BIOL MED, V115, DOI 10.1016/j.compbiomed.2019.103520
   Fang Hao-Shu, 2022, IEEE T PATTERN ANAL
   Fix E., 1985, Discriminatory Analysis: Nonparametric Discrimination, Consistency Properties
   Girgis M.R., 2015, Int. J. Comput. Appl., V116
   Gormley IC, 2019, CH CRC HANDB MOD STA, P271
   Ha TV, 2022, LECT NOTES COMPUT SC, V13141, P392, DOI 10.1007/978-3-030-98358-1_31
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Inturi AR, 2023, ARAB J SCI ENG, V48, P1143, DOI 10.1007/s13369-022-06684-x
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Kingma D. P., 2014, arXiv
   Lai K, 2021, PATTERN RECOGN LETT, V147, P164, DOI 10.1016/j.patrec.2021.04.008
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martínez-Villaseñor L, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19091988
   O'Shea K., 2015, PREPRINT
   Ramirez H, 2021, IEEE ACCESS, V9, P33532, DOI 10.1109/ACCESS.2021.3061626
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Sun J, 2021, PREPRINT
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Le TM, 2021, IEEE ACCESS, V9, P115895, DOI 10.1109/ACCESS.2021.3105581
   Xu HY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9142867
   Yadav SK, 2022, KNOWL-BASED SYST, V239, DOI 10.1016/j.knosys.2021.107948
   Zeiler M. D., 2012, PREPRINT
   Zhao ZX, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155482
NR 33
TC 0
Z9 0
U1 5
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 18091
EP 18118
DI 10.1007/s11042-023-16214-y
EA JUL 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001035725700020
DA 2024-07-18
ER

PT J
AU Sahoo, SS
   Chaurasiya, VK
AF Sahoo, Sujit Sangram
   Chaurasiya, Vijay Kumar
TI <i>VIBE:</i> Blockchain-based Virtual Payment in IoT Ecosystem: A Secure
   Decentralized Marketplace
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Blockchain; IoT; Perun; Scalability issue; Smart contract; Flood and
   Loot Attack
ID CHALLENGES; INTEGRATION; INTERNET
AB Internet of Things generates massive amounts of data that is essential for organizations interested in collecting, processing, and trading personal data. Therefore, there is a great demand for an open IoT ecosystem that provides stakeholders with an appropriate platform to publish, search, trade, secure, and control their data. Our solution is a fully decentralized smart contracts-based model incorporating Blockchain-based off-chain payment with the IoT ecosystem. It is the first Perun-based scheme with the BIoTope H2020 project to resolve the scalability problem of existing blockchain models and trade IoT data to consumers in micro-units or as per their requirements. The proposed model provides (i) A novel algorithm to integrate Ethereum virtual payment with the IoT ecosystem and IoT data trading between client and supplier by suppressing the platform service provider with incentives, (ii) Flood and loot attack free payment model that secures payment without compromise the privacy with intermediaries in virtual payment and (iii) Ensures no single point failure and penalties for malicious participants and contract violators. The resultant model ensures faster payment, which takes 99% less time than other existing blockchain models. However, the data storage efficiency achieve through the Interplanetary File System(IPFS) and SHA3 algorithm that uses cryptographic tokens. Further, the proposed review system enhances participants' responsibility to create a secure market environment, and theorems ensure the validation against malicious activities. The results demonstrate the implementation of the resultant scheme using the gas consumption of different smart contracts and computation costs, and it compares with other existing works to illustrate the efficiency.
C1 [Sahoo, Sujit Sangram; Chaurasiya, Vijay Kumar] Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Sahoo, SS (corresponding author), Indian Inst Informat Technol Allahabad, Dept Informat Technol, Prayagraj, India.
EM rsi2018005@iiita.ac.in; vijayk@iiita.ac.in
RI sahoo, sujit sangram/ABS-8552-2022
OI sahoo, sujit sangram/0000-0003-0963-8038
CR AIOTI, 2015, ABOUT US
   [Anonymous], WELCOME REMIX DOCUME
   Aryal A, 2018, INT J SUPPLY CHAIN M
   Aryal A., 2018, Supply Chain Manag. Int. J.
   Botta A, 2016, FUTURE GENER COMP SY, V56, P684, DOI 10.1016/j.future.2015.09.021
   Bucherer E, 2011, ARCHITECTING THE INTERNET OF THINGS, P253
   Casado-Vara R, 2019, INFORM FUSION, V49, P227, DOI 10.1016/j.inffus.2018.12.007
   Dannen Chris, 2017, Introducing Ethereum and solidity, V1
   Dasaklis TK, 2019, INTERNATIONAL CONFERENCE ON OMNI-LAYER INTELLIGENT SYSTEMS (COINS), P184, DOI 10.1145/3312614.3312652
   de Vass T, 2021, INT J LOGIST-RES APP, V24, P605, DOI 10.1080/13675567.2020.1787970
   Dziembowski S, 2019, P IEEE S SECUR PRIV, P106, DOI 10.1109/SP.2019.00020
   Fernández-Caramés TM, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19153319
   Främling K, 2014, IEEE INTERNET THINGS, V1, P319, DOI 10.1109/JIOT.2014.2332005
   Gnimpieba DR, 2015, PROCEDIA COMPUT SCI, V56, P550, DOI 10.1016/j.procs.2015.07.251
   Guinard D., 2016, Building the Web of Things: With Examples in Node.js and Raspberry Pi
   Hao ZJ, 2018, 2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC), P410, DOI 10.1109/SEC.2018.00055
   Harris Jona, 2020, AFT '20: Proceedings of the 2nd ACM Conference on Advances in Financial Technologies, P202, DOI 10.1145/3419614.3423248
   Huh S, 2017, INT CONF ADV COMMUN, P464, DOI 10.23919/ICACT.2017.7890132
   Islam Md Milon, 2020, SN Comput Sci, V1, P185, DOI 10.1007/s42979-020-00195-y
   Kecskemeti G, 2017, IEEE CLOUD COMPUT, V4, P62, DOI 10.1109/MCC.2017.18
   Khan MA, 2018, FUTURE GENER COMP SY, V82, P395, DOI 10.1016/j.future.2017.11.022
   Khan Nida, 2020, Blockchain and Applications. International Congress. Advances in Intelligent Systems and Computing (AISC 1010), P11, DOI 10.1007/978-3-030-23813-1_2
   Kolbe N, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3284316
   Kubler S, 2017, IEEE ACCESS, V5, P7064, DOI 10.1109/ACCESS.2017.2692247
   Kumar KA, 2022, J AMB INTEL HUM COMP, V13, P183, DOI 10.1007/s12652-021-03605-y
   Li JX, 2018, INFORM SCIENCES, V465, P219, DOI 10.1016/j.ins.2018.06.071
   Li Z, 2017, IND MANAGE DATA SYST, V117, P1906, DOI 10.1108/IMDS-11-2016-0489
   Moin S, 2019, FUTURE GENER COMP SY, V100, P325, DOI 10.1016/j.future.2019.05.023
   Nasr M, 2021, IEEE ACCESS, V9, P145248, DOI 10.1109/ACCESS.2021.3118960
   Noura M, 2019, MOBILE NETW APPL, V24, P796, DOI 10.1007/s11036-018-1089-9
   Pouraghily A, 2019, INT CONF COMPUT NETW, P617, DOI [10.1109/ICCNC.2019.8685545, 10.1109/iccnc.2019.8685545]
   Reyna A, 2018, FUTURE GENER COMP SY, V88, P173, DOI 10.1016/j.future.2018.05.046
   Robert Jeremy, 2020, Future Generation Computer Systems, V112, P283, DOI 10.1016/j.future.2020.05.033
   Robert J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122849
   Ropsten, ETH TESTN
   Seok B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183740
   Singh SK, 2020, FUTURE GENER COMP SY, V110, P721, DOI 10.1016/j.future.2019.09.002
   Sonmez R, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03610-1
   Swetina J, 2014, IEEE WIREL COMMUN, V21, P20, DOI 10.1109/MWC.2014.6845045
   Tsang YP, 2019, IEEE ACCESS, V7, P129000, DOI 10.1109/ACCESS.2019.2940227
   Wettinger J, 2015, P 5 INT C CLOUD COMP
   Wood G., 2014, Ethereum project yellow paper, V151, P1
   Zhou J, 2017, IEEE COMMUN MAG, V55, P26, DOI 10.1109/MCOM.2017.1600363CM
NR 43
TC 1
Z9 1
U1 2
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16869
EP 16894
DI 10.1007/s11042-023-15634-0
EA JUL 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001032703400005
DA 2024-07-18
ER

PT J
AU Joseph, JS
   Vidyarthi, A
   Singh, VP
AF Joseph, J. Sharmila
   Vidyarthi, Abhay
   Singh, Vibhav Prakash
TI An improved approach for initial stage detection of laryngeal cancer
   using effective hybrid features and ensemble learning method
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Laryngeal cancer; Computer-aided diagnosis; DenseNet 201; Ensemble
   learning
ID CLASSIFICATION; DIAGNOSIS; PREDICTION
AB Squamous cell carcinoma (SCC) is one of the most common as well as deadliest kinds of laryngeal cancer. The precise and early identification of laryngeal cancer plays a pivotal role in reducing mortality and maintaining laryngeal structure and vocal fold function. But small variations in the laryngeal tissues may go undetected by the human eye, which leads to misdiagnosis. In this study, we devise an early laryngeal cancer classification framework using the hybridization of deep and handcrafted features. The deep features of the DenseNet 201 using transfer learning and handcrafted features using Local Binary Pattern (LBP) and First-order statistics (STAT)s are extracted from the endoscopic narrowband images of the larynx and fused together which resulted in more representative features. From these hybridized features, the optimal features are selected by the Recursive Feature Elimination with Random Forest (RFE- RF) method. Firstly, the selected hybrid features are classified with three effective Machine Learning classifiers like Random Forest (RF), Support Vector Machine (SVM), and k-Nearest Neighbor (k-NN), and the results are compared with a stacking-based ensemble learning classification method using (SVM), (RF) and (k-NN) in order to distinguish early-stage SCC tissues, healthy tissues and precancerous tissues. The combination of hybrid features, effective feature selection, and an Ensemble classifier produced a median categorization recall of 99.5% on a standard dataset, which surpasses the state of the art (recall = 98%).
C1 [Joseph, J. Sharmila] VIT Bhopal Univ Bhopal Indore Highway, Sehore 466114, MP, India.
   [Vidyarthi, Abhay; Singh, Vibhav Prakash] Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, Uttar Pradesh, India.
C3 National Institute of Technology (NIT System); Motilal Nehru National
   Institute of Technology
RP Vidyarthi, A (corresponding author), Motilal Nehru Natl Inst Technol Allahabad, Prayagraj 211004, Uttar Pradesh, India.
EM abhay.vidyarthi@vitbhopal.ac.in
CR Ali M, 2022, AURIS NASUS LARYNX, V49, P676, DOI 10.1016/j.anl.2021.11.008
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Araujo T, 2019, MED BIOL ENG COMPUT, V57, P2683, DOI 10.1007/s11517-019-02051-5
   Barbalata C, 2016, IEEE J BIOMED HEALTH, V20, P322, DOI 10.1109/JBHI.2014.2374975
   Bellmann P, 2018, STUD COMPUT INTELL, V777, P83, DOI 10.1007/978-3-319-89629-8_4
   Bethanney J, 2018, INT J ENG TECHNOLOGY, V7, P1, DOI [10.14419/ijet.v7i2.25.12351, DOI 10.14419/IJET.V7I2.25.12351]
   Boongoen T, 2018, COMPUT SCI REV, V28, P1, DOI 10.1016/j.cosrev.2018.01.003
   Bosetti C, 2002, BRIT J CANCER, V87, P516, DOI 10.1038/sj.bjc.6600469
   Cho WK, 2021, LARYNGOSCOPE, V131, P2558, DOI 10.1002/lary.29595
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Cunningham P, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3459665
   Deepak S, 2021, J AMB INTEL HUM COMP, V12, P8357, DOI 10.1007/s12652-020-02568-w
   Duran-Lopez L, 2020, IEEE ACCESS, V8, P128613, DOI 10.1109/ACCESS.2020.3008868
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fausser S, 2015, NEURAL PROCESS LETT, V41, P55, DOI 10.1007/s11063-013-9334-5
   Fekri-Ershad S, 2019, MULTIMED TOOLS APPL, V78, P31121, DOI 10.1007/s11042-019-07937-y
   Hameed Z, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164373
   Hasan MK, 2020, IEEE ACCESS, V8, P76516, DOI 10.1109/ACCESS.2020.2989857
   Hsieh SL, 2012, J MED SYST, V36, P2841, DOI 10.1007/s10916-011-9762-6
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang P, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21010122
   Jadhav S. B., 2019, International Journal of Electrical and Computer Engineering, V9, P4077, DOI DOI 10.11591/IJECE.V9I5.PP4077-4091
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Kachele M, 2015, ENSEMBLE METHODS CON, DOI [10.1145/2808196.2811637, DOI 10.1145/2808196.2811637]
   Kanavati F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66333-x
   Kraft M, 2016, HEAD NECK-J SCI SPEC, V38, P15, DOI 10.1002/hed.23838
   Kumar G, 2014, INT C ADV COMPUT COM, P5, DOI 10.1109/ACCT.2014.74
   Lan RS, 2018, MULTIMED TOOLS APPL, V77, P10853, DOI 10.1007/s11042-017-5341-2
   Liang P, 2012, COMPUTER AIDED LESIO, DOI [10.1109/ICInfA.2012.6246904, DOI 10.1109/ICINFA.2012.6246904]
   Lin K, 2012, BIOSENS BIOELECTRON, V35, P213, DOI 10.1016/j.bios.2012.02.050
   Lin YQ, 2011, PROC CVPR IEEE, P1689, DOI 10.1109/CVPR.2011.5995477
   Markou K, 2013, HIPPOKRATIA, V17, P313
   Misawa M, 2017, INT J COMPUT ASS RAD, V12, P757, DOI 10.1007/s11548-017-1542-4
   Moccia S, 2018, COMPUT METH PROG BIO, V158, P21, DOI 10.1016/j.cmpb.2018.01.030
   Moccia S, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.3.034502
   Moccia S, 2016, IEEE ENG MED BIO, P1188, DOI 10.1109/EMBC.2016.7590917
   Nanni L, 2021, APPL COMPUT INFORM, V17, P19, DOI 10.1016/j.aci.2018.06.002
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Patrini I, 2020, MED BIOL ENG COMPUT, V58, P1225, DOI 10.1007/s11517-020-02127-7
   Piazza C, 2012, CURR OPIN OTOLARYNGO, V20, P472, DOI 10.1097/MOO.0b013e32835908ac
   Popek B, 2019, POL J OTOLARYNGOL, V73, P17, DOI 10.5604/01.3001.0013.3401
   Poplin R, 2018, NAT BIOMED ENG, V2, P158, DOI 10.1038/s41551-018-0195-0
   Prakash JA, 2023, MULTIMED TOOLS APPL, V82, P21311, DOI 10.1007/s11042-022-13844-6
   SaranyaJothi C., 2018, RES J PHARM TECHNOL, V11, P851, DOI [10.5958/0974-360X.2018.00158.0, DOI 10.5958/0974-360X.2018.00158.0]
   Schwenker F, 2006, LEARNING DECISION FU
   Shankar K, 2021, COMPLEX INTELL SYST, V7, P1277, DOI 10.1007/s40747-020-00216-6
   Sharmila J, 2022, ALGORITHMS INTELL SY, DOI [10.1007/978-981-16-9650-3_18, DOI 10.1007/978-981-16-9650-3_18]
   Shen X, 2012, LESION DETECTION ELE, DOI [10.1109/ICSPCC.2012.6335638, DOI 10.1109/ICSPCC.2012.6335638]
   Singh VP, 2021, MACHINE LEARNING HEA, P353, DOI DOI 10.1002/9781119792611.CH23
   Sirinukunwattana K, 2016, IEEE T MED IMAGING, V35, P1196, DOI 10.1109/TMI.2016.2525803
   Turkmen HI, 2015, COMPUT BIOL MED, V62, P76, DOI 10.1016/j.compbiomed.2015.02.001
   Unger J, 2015, CANCER RES, V75, P31, DOI 10.1158/0008-5472.CAN-14-1458
   van der Sommen F, 2013, PROC SPIE, V8670, DOI 10.1117/12.2001068
   Wu Yimin., 2004, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, V2, pII, DOI [10.1109/cvpr.2004.1315171, DOI 10.1109/CVPR.2004.1315171, 10.1109/CVPR.2004.1315171]
   Xu Y, 2015, INT CONF ACOUST SPEE, P947, DOI 10.1109/ICASSP.2015.7178109
   Zhang Y, 2017, J MED IMAGING, V4, DOI 10.1117/1.JMI.4.1.015001
NR 56
TC 2
Z9 2
U1 0
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 17897
EP 17919
DI 10.1007/s11042-023-16077-3
EA JUL 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001031485100002
DA 2024-07-18
ER

PT J
AU Patel, J
   Tailor, D
   Panchal, K
   Patel, S
   Gupta, R
   Shah, MA
AF Patel, Jay
   Tailor, Dev
   Panchal, Kevin
   Patel, Samir
   Gupta, Rajeev
   Shah, Manan
TI All phase discrete cosine biorthogonal transform versus discrete cosine
   transform in digital watermarking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Image processing; Image watermarking; PN; Sequence; Robustness;
   Capacity; Imperceptibility; Security
ID IMAGE WATERMARKING; DWT-SVD; DCT; ROBUST
AB The field of digital image watermarking has collected considerable attention from researchers and scholars, that eventually presents interesting challenges and opportunities for technological advancements. We can successfully address issues with multimedia access control by utilizing technological advancements, such as transform domain techniques, steganography, multimedia synchronization, robust watermark extraction, and many. This can be used to enhance technology in many ways like intellectual property protection, data integrity and security, and others. Photographic Image Watermarking is the process of inserting a message as a watermark to host image in some multimedia format. We can try to restrict multimedia from unwanted access through the help of digital watermarking. A few elements such as capacity, security, imperceptibility, and robustness must be considered while creating an effective and productive digital watermarked image. This paper compares All Phase Discrete Cosine Biorthogonal Transform (APDCBT) and Discrete Cosine Transform (DCT) in the field of image authentication and Digital Watermarking. Our proposed system uses a PN - Sequence algorithm and a secret user key called K to generate random vectors for selected coefficients to increase the security and robustness. The above two algorithms are combined with commonly used algorithms like Discrete Wavelet Transform (DWT) and Singular Value Decomposition (SVD) for effective Digital Watermarking. For evaluating the imperceptibility of Watermarked Image, Peak Signal to Noise Ratio (PSNR) and Mean Square Error (MSE) are taken into consideration.
C1 [Patel, Jay; Tailor, Dev; Panchal, Kevin; Patel, Samir; Gupta, Rajeev] Pandit Deendayal Energy Univ, Sch Technol, Dept Comp Sci & Engn, Gandhinagar 382426, Gujarat, India.
   [Shah, Manan] Pandit Deendayal Energy Univ, Sch Energy Technol, Dept Chem Engn, Gandhinagar 382426, Gujarat, India.
C3 Pandit Deendayal Energy University; Pandit Deendayal Energy University
RP Shah, MA (corresponding author), Pandit Deendayal Energy Univ, Sch Energy Technol, Dept Chem Engn, Gandhinagar 382426, Gujarat, India.
EM manan.shah@spt.pdpu.ac.in
RI Patel, Samir/AAF-1944-2019; Shah, Manan/Y-9430-2019
OI Patel, Samir/0000-0002-4280-6446; Shah, Manan/0000-0002-8665-5010
CR Ahmed IT, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188308
   Anand A, 2020, COMPUT COMMUN, V152, P72, DOI 10.1016/j.comcom.2020.01.038
   Awasthi Y, 2019, PROCEEDINGS OF THE 2019 8TH INTERNATIONAL CONFERENCE ON SYSTEM MODELING & ADVANCEMENT IN RESEARCH TRENDS (SMART-2019), P250, DOI [10.1109/smart46866.2019.9117522, 10.1109/SMART46866.2019.9117522]
   Bharati S, 2018, 2018 INT C INN ENG T, P1, DOI [10.1109/CIET.2018.8660796, DOI 10.1109/ICAEEE.2018.8643004]
   Cox IJ., 2007, DIGITAL WATERMARKING
   Fazli S, 2016, OPTIK, V127, P964, DOI 10.1016/j.ijleo.2015.09.205
   Gupta P, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATIONS AND ELECTRONICS (COMPTELIX), P527, DOI 10.1109/COMPTELIX.2017.8004026
   Hamidi M, 2021, J IMAGING, V7, DOI 10.3390/jimaging7100218
   Hamidi M, 2018, MULTIMED TOOLS APPL, V77, P27181, DOI 10.1007/s11042-018-5913-9
   Handito KW, 2018, J PHYS CONF SER, V971, DOI 10.1088/1742-6596/971/1/012006
   Hou ZX, 2009, SIGNAL PROCESS-IMAGE, V24, P791, DOI 10.1016/j.image.2009.08.002
   Khalifa F., 2020, POLYTECH J, V10, P68, DOI [10.25156/ptj.v10n1y2020.pp68-73, DOI 10.25156/PTJ.V10N1Y2020.PP68-73]
   Khalifa O. O., 2012, Proceedings of the 2012 8th International Conference on Information Science and Digital Content Technology (ICIS and IDCTA), P533
   Lia L, 2022, INT J APPL MATH CONT, P114
   Navas KA, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON COMMUNICATION SYSTEM SOFTWARE AND MIDDLEWARE AND WORKSHOPS, VOLS 1 AND 2, P271, DOI 10.1109/COMSWA.2008.4554423
   Nwoke EC, 2023, INT C SMART SEC SUST, P169
   Roy S, 2017, AEU-INT J ELECTRON C, V72, P149, DOI 10.1016/j.aeue.2016.12.003
   Singh AK, 2017, MULTIMED TOOLS APPL, V76, P8881, DOI 10.1007/s11042-016-3514-z
   Singh AK, 2014, NATL ACAD SCI LETT, V37, P351, DOI 10.1007/s40009-014-0241-8
   Singh D, 2017, MULTIMED TOOLS APPL, V76, P13001, DOI 10.1007/s11042-016-3706-6
   Singh OP, 2023, COMPLEX INTELL SYST, V9, P2759, DOI 10.1007/s40747-021-00309-w
   Singh SP, 2018, J VIS COMMUN IMAGE R, V53, P86, DOI 10.1016/j.jvcir.2018.03.006
   Singha A, 2019, TRANSFORM DOMAIN DIG, V2019
   Singha A, 2021, MULTIMEDIA SYST, V27, P89, DOI 10.1007/s00530-020-00708-y
   Thakkar FN, 2017, MULTIMED TOOLS APPL, V76, P3669, DOI 10.1007/s11042-016-3928-7
   Wang JY, 2019, J VIS COMMUN IMAGE R, V64, DOI 10.1016/j.jvcir.2019.102627
   Wang M, 2021, INT J REMOTE SENS, V42, P3166, DOI 10.1080/2150704X.2020.1843732
   Wang XY, 2017, J INF PROCESS SYST, V13, P114, DOI 10.3745/JIPS.02.0053
   Yang FF, 2015, INT J SECUR APPL, V9, P125
   Yu XY, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11101227
   Yuqi He, 2018, 2018 2nd IEEE Advanced Information Management, Communicates, Electronic and Automation Control Conference (IMCEC). Proceedings, P1214, DOI 10.1109/IMCEC.2018.8469626
   Zhang YP, 2017, ALGORITHMS, V10, DOI 10.3390/a10020041
   Zhang YP, 2017, FUTURE INTERNET, V9, DOI 10.3390/fi9020013
   ZHOU X, 2018, SYMMETRY-BASEL, V10
NR 34
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16121
EP 16138
DI 10.1007/s11042-023-16106-1
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600011
DA 2024-07-18
ER

PT J
AU Shafay, M
   Ahmed, A
   Hassan, T
   Dias, J
   Werghi, N
AF Shafay, Muhammad
   Ahmed, Abdelfatah
   Hassan, Taimur
   Dias, Jorge
   Werghi, Naoufel
TI Programmable broad learning system for baggage threat recognition
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Broad learning systems; Greedy search; Baggage classification; Baggage
   X-ray scans
ID SHAPE
AB Detecting illegal and harmful objects in baggage at airports, subways, and bus stations has always been a difficult task that requires intense focus and concentration. Despite recent advances, developing systems for robust autonomous threat recognition still remains a challenge. In this paper, we propose a novel CNN-driven Broad Learning System, dubbed Programmable BLS, for identifying threat objects from the security X-ray scans. The proposed framework first extracts latent features from the input scan utilizing the CNN backbone. Then, the BLS model uses these features to assess whether or not the candidate scan contains the threat items. Unlike existing approaches, the design adaptation of the BLS architecture (within the proposed framework) is fully autonomous, requiring no human efforts to formulate the optimized combination of layers that gives the best classification performance for the given application. This unique design adaption is based on heuristics and greedy searches that measure the relevance of fusing adjacent node pairs in order to improve the overall network performance. Apart from this, across three datasets, namely, GDXray, SIXray, and COMPASS-XP, we rigorously tested the proposed framework on which it outperforms the state-of-the-art by 0.996%, 4.82%, and 0.934%, respectively, in terms of accuracy, and by 3.56%, 1.71%, and 1.30%, respectively, in terms of F1-score.
C1 [Shafay, Muhammad; Ahmed, Abdelfatah; Dias, Jorge; Werghi, Naoufel] Khalifa Univ, Dept Elect Engn & Comp Sci, Abu Dhabi, U Arab Emirates.
   [Hassan, Taimur] Abu Dhabi Univ, Dept Elect Comp & Biomed Engn, Abu Dhabi, U Arab Emirates.
C3 Khalifa University of Science & Technology; Abu Dhabi University
RP Ahmed, A (corresponding author), Khalifa Univ, Dept Elect Engn & Comp Sci, Abu Dhabi, U Arab Emirates.
EM 100059689@ku.ac.ae
RI Dias, Jorge Miranda/A-1842-2011; Hassan, Taimur/HIR-9794-2022
OI Dias, Jorge Miranda/0000-0002-2725-8867; Hassan,
   Taimur/0000-0002-5896-8677; Ahmed, Abdelfatah/0000-0002-8455-6123
FU Khalifa University [CIRA-2019-047, CIRA-2021-052]; Abu Dhabi Department
   of Education and Knowledge (ADEK) [AARE19-156]
FX This work is supported by a research fund from Khalifa University, Ref:
   CIRA-2019-047 and CIRA-2021-052, and the Abu Dhabi Department of
   Education and Knowledge (ADEK), Ref: AARE19-156.
CR Ahmed A., 2023, P 15 INT C MACH LEAR
   Air Transport, PASS CARR
   Akcay S., 2020, ARXIV
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Akcay S, 2018, IEEE T INF FOREN SEC, V13, P2203, DOI 10.1109/TIFS.2018.2812196
   An JY, 2019, LECT NOTES COMPUT SC, V11935, P495, DOI 10.1007/978-3-030-36189-1_41
   Bastan M, 2011, LECT NOTES COMPUT SC, V6854, P360, DOI 10.1007/978-3-642-23672-3_44
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Benyi Hu, 2021, Computer Vision - ACCV 2020 15th Asian Conference on Computer Vision. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12647), P173, DOI 10.1007/978-3-030-69544-6_11
   Chen C. L. Philip, 2018, IEEE Transactions on Neural Networks and Learning Systems, V29, P10, DOI 10.1109/TNNLS.2017.2716952
   Council N.R., 1996, AIRL PASS SEC SCREEN
   Devereux M., 2016, 7 INT C IM CRIM DET, V12, DOI [10.1049/ic.2016.0080, DOI 10.1049/IC.2016.0080]
   Dhiraj, 2019, PATTERN RECOGN LETT, V120, P112, DOI 10.1016/j.patrec.2019.01.014
   GOLDEN B, 1976, OPER RES, V24, P1164, DOI 10.1287/opre.24.6.1164
   Griffin, COMP XP
   Hassan T., 2020, METATRANSFER LEARNIN
   Hassan T., 2020, AS C COMP VIS ACCV
   Hassan T, 2020, IEEE IMAGE PROC, P2016, DOI 10.1109/ICIP40778.2020.9190711
   Hassan T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226450
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heitz G, 2010, PROC CVPR IEEE, P2093, DOI 10.1109/CVPR.2010.5539887
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Jaccard N., 2016, USING DEEP LEARNING
   Jin JW, 2018, NEUROCOMPUTING, V322, P58, DOI 10.1016/j.neucom.2018.09.028
   Jin JW, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9421-3
   Kingma D. P., 2014, arXiv
   Kong Y, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10050685
   Li GH, 2020, PROC CVPR IEEE, P1617, DOI 10.1109/CVPR42600.2020.00169
   Liu H., 2018, ARXIV
   Megherbi N, 2010, IEEE IMAGE PROC, P1833, DOI 10.1109/ICIP.2010.5653676
   Mery D, 2017, IEEE T SYST MAN CY-S, V47, P682, DOI 10.1109/TSMC.2016.2628381
   Mery D, 2016, LECT NOTES COMPUT SC, V9431, P709, DOI 10.1007/978-3-319-29451-3_56
   Mery D, 2015, J NONDESTRUCT EVAL, V34, DOI 10.1007/s10921-015-0315-7
   Miao CJ, 2019, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR.2019.00222
   Ozeki K, 2011, GRAPH COMBINATOR, V27, P1, DOI 10.1007/s00373-010-0973-2
   Qureshi SA, 2022, FRONT PHYSIOL, V12, DOI 10.3389/fphys.2021.737233
   Riffo V, 2016, IEEE T SYST MAN CY-S, V46, P472, DOI 10.1109/TSMC.2015.2439233
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tao R., 2021, REV IEEE T MULTIMEDI
   Turcsany D, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1140, DOI 10.1109/ICIT.2013.6505833
   Wang Q., 2020, MULTICLASS 3D OBJECT
   Wang Q., 2020, EVALUATION PROHIBITE
   Wei YL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P138, DOI 10.1145/3394171.3413828
   Zhang HJ, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P1460, DOI 10.1109/ICECC.2011.6066546
   Zhang J, 2014, IEEE COMPUT SOC CONF, P266, DOI 10.1109/CVPRW.2014.48
NR 45
TC 1
Z9 1
U1 4
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 6
BP 16179
EP 16196
DI 10.1007/s11042-023-16057-7
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX5S6
UT WOS:001027492600002
DA 2024-07-18
ER

PT J
AU Oliaei, H
   Azghani, M
AF Oliaei, Hayde
   Azghani, Masoumeh
TI Video motion forgery detection using motion residual and object tracking
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Intra-frame forgery detection; Motion forgery; Motion residual; Video
   forgery detection; Video forgery localization
ID DETECTION ALGORITHM; FRAME; LOCALIZATION
AB Dueto the extensive application of the video editing tools, video authentification has become an interesting topic. Video motion forgery is one of the most significant manipulations which alter the video sequence both temporally and spatially. We suggest an intra-frame motion forgery detection algorithm in this paper that detects the motion forgery throughout the video sequence. The motion residuals are applied to extract the moving parts. The moving objects are then analyzed to identify the similar ones. Then, the moving objects are tracked throughout the video sequence using the meanshift algorithm to determine the motion sequences. The two motion sequences are selected as matched if both the objects and their displacements are similar in the consecutive frames. By matching the motion sequences, the forged ones are determined. Various simulations have been conducted in different datasets to investigate the performance of the proposed scheme. We test video sequences at both frame and pixel levels and detect temporal and spatial motion forgery. For the frame level, the F-1 score of the proposed method on both the datasets of SULFA and GRIP was 89%. Also, at the pixel level, the F-1 scores of the proposed method for the SULFA and GRIP datasets are 89% and 81%, respectively. The simulation results confirm the efficiency of the suggested method in locating the forged motion sequences and outperforming its rivals.
C1 [Oliaei, Hayde; Azghani, Masoumeh] Sahand Univ Technol, Fac Elect Engn, Lab Wireless Commun & Signal Proc WCSP, Tabriz, Iran.
C3 Sahand University of Technology
RP Azghani, M (corresponding author), Sahand Univ Technol, Fac Elect Engn, Lab Wireless Commun & Signal Proc WCSP, Tabriz, Iran.
EM mazghani@sut.ac.ir
CR [Anonymous], 2014, 10 INT S TELECOMMUNI
   Azghani M., 2010, 2010 5th International Symposium on Telecommunications (IST), P806, DOI 10.1109/ISTEL.2010.5734133
   Bakas Jamimamul, 2021, Computers & Electrical Engineering, V89, DOI 10.1016/j.compeleceng.2020.106929
   BAKAS J, 2021, J AMB INTEL HUM COMP, P1
   Bakas J, 2019, MULTIMED TOOLS APPL, V78, P4905, DOI 10.1007/s11042-018-6570-8
   Bani NT, 2019, ELECTRON LIBR, V37, P650, DOI 10.1108/EL-03-2019-0067
   Bestagini P, 2013, IEEE INT WORKSH MULT, P488, DOI 10.1109/MMSP.2013.6659337
   Bidokhti A, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P13, DOI 10.1109/AISP.2015.7123529
   Chao J, 2012, INT WORKSH DIG WAT, P267, DOI DOI 10.1007/978-3-642-40099-5_22
   Chen SD, 2016, IEEE T CIRC SYST VID, V26, P2138, DOI 10.1109/TCSVT.2015.2473436
   D'Amiano L, 2015, IEEE INT CONF MULTI
   D'Amiano L, 2019, IEEE T CIRC SYST VID, V29, P669, DOI 10.1109/TCSVT.2018.2804768
   Elaskily MA, 2019, MULTIMED TOOLS APPL, V78, P15353, DOI 10.1007/s11042-018-6891-7
   Fadl S, 2021, SIGNAL PROCESS-IMAGE, V90, DOI 10.1016/j.image.2020.116066
   Feng CH, 2017, IEEE T CIRC SYST VID, V27, P2543, DOI 10.1109/TCSVT.2016.2593612
   Hammami A, 2021, MULTIMED TOOLS APPL, V80, P7479, DOI 10.1007/s11042-020-09982-4
   Hou ZY, 2011, 2011 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMMUNICATIONS AND CONTROL (ICECC), P4354, DOI 10.1109/ICECC.2011.6067709
   Jia S, 2018, IEEE ACCESS, V6, P25323, DOI 10.1109/ACCESS.2018.2819624
   Jin X, 2021, MULTIMED TOOLS APPL, P1
   Johnston P, 2020, NEURAL COMPUT APPL, V32, P12243, DOI 10.1007/s00521-019-04272-z
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kancherla K, 2012, LECT NOTES ARTIF INT, V7198, P308, DOI 10.1007/978-3-642-28493-9_33
   Kharat J, 2020, MULTIMED TOOLS APPL, V79, P8107, DOI 10.1007/s11042-019-08272-y
   Lian SG, 2007, IEEE T CIRC SYST VID, V17, P774, DOI 10.1109/TCSVT.2007.896635
   Liao SY, 2013, 2013 6TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), VOLS 1-3, P864, DOI 10.1109/CISP.2013.6745286
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Mathai M, 2016, IEEE SW SYMP IMAG, P149, DOI 10.1109/SSIAI.2016.7459197
   Pandey Ramesh Chand, 2014, 2014 5th International Conference on Computer and Communication Technology (ICCCT), P301, DOI 10.1109/ICCCT.2014.7001509
   Raskar PS, 2021, FORENSIC SCI INT, V327, DOI 10.1016/j.forsciint.2021.110979
   Saddique M, 2020, IEEE ACCESS, V8, P56782, DOI 10.1109/ACCESS.2020.2980951
   Sharma S, 2016, ADV COMP COMM SYST I, V1, P1
   Shelke NA, 2021, MULTIMED TOOLS APPL, V80, P6247, DOI 10.1007/s11042-020-09974-4
   Singh GM, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124845
   Singh G, 2019, MULTIMED TOOLS APPL, V78, P11527, DOI 10.1007/s11042-018-6585-1
   Singh RD, 2017, FORENSIC SCI INT, V281, P75, DOI 10.1016/j.forsciint.2017.10.028
   Sitara K, 2016, DIGIT INVEST, V18, P8, DOI 10.1016/j.diin.2016.06.003
   Su LC, 2019, IEEE ACCESS, V7, P109719, DOI 10.1109/ACCESS.2019.2933871
   Su LC, 2018, IEEE T MULTIMEDIA, V20, P825, DOI 10.1109/TMM.2017.2760098
   Su LC, 2018, MULTIDIM SYST SIGN P, V29, P1173, DOI 10.1007/s11045-017-0496-6
   Ulutas G, 2017, IET IMAGE PROCESS, V11, P333, DOI 10.1049/iet-ipr.2016.0321
   Wahab AWA, 2014, INT C INFORM ASSUR S, P29, DOI 10.1109/ISIAS.2014.7064616
   Wang W, 2014, LECT NOTES COMPUT SC, V8389, P244, DOI 10.1007/978-3-662-43886-2_18
   Xu JW, 2016, 2016 30TH ANNIVERSARY OF VISUAL COMMUNICATION AND IMAGE PROCESSING (VCIP)
   Yin LG, 2014, INT CONF INFO SCI, P148, DOI 10.1109/ICIST.2014.6920352
   Yuxing Wu, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P2674, DOI 10.1109/ICASSP.2014.6854085
   Zhenzhen Zhang, 2016, Digital Forensics and Watermarking. 14th International Workshop, IWDW 2015. Revised Selected Papers: LNCS 9569, P94, DOI 10.1007/978-3-319-31960-5_9
   Zhong J, 2022, J EARTHQ ENG, V26, P8185, DOI 10.1080/13632469.2021.1989348
   Zhong JL, 2020, INFORM SCIENCES, V537, P184, DOI 10.1016/j.ins.2020.05.134
NR 48
TC 0
Z9 0
U1 0
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12651
EP 12668
DI 10.1007/s11042-023-15763-6
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027814600001
DA 2024-07-18
ER

PT J
AU Liang, Z
   Fang, TY
   Hu, YZ
   Wang, YJ
AF Liang, Zhen
   Fang, Tiyu
   Hu, Yanzhu
   Wang, Yingjian
TI Sparse depth densification for monocular depth estimation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Monocular depth estimation; Unsupervised image segmentation; Sparse
   depth densification; Multi-scale fusion
ID IMAGE
AB Now the dense depth prediction by single image and a few sparse depth measurements has attracted more and more attention because it provides a low-cost and efficient solution for estimating high-quality depth information. But the current existing methods for the field only take sparse depth as an independent dimension, and the relationship between sparse depth and image itself is always ignored, which undoubtedly limits the improvement of prediction accuracy. For solving the problem, in this paper, a sparse depth densification method is proposed to fully mine the relationship between sparse depth and image for achieving more accurate depth estimation. Based on a priori that the object areas of same category have similar depth values, a Depth Densification Map (DDM) is constructed by the segmentation label obtained from unsupervised image segmentation and sparse depth to realize sparse depth densification. Meantime, considering the potential error of DDM, a Depth Error Map (DEM) is designed to further correct DDM. Then, we use the idea of multi-scale fusion to build a depth estimation network. Finally, the proposed maps are combined with single image as the input of the network, and used to carry out the actual training and testing. Extensive experiments on NYU Depth v2 and Make3D datasets demonstrate the superiority of our proposed approach. Our code is available at . .
C1 [Liang, Zhen; Hu, Yanzhu; Wang, Yingjian] Beijing Univ Posts & Telecommun, Beijing Key Lab Work Safety Intelligent Monitoring, Beijing 100876, Peoples R China.
   [Liang, Zhen; Hu, Yanzhu; Wang, Yingjian] Beijing Univ Posts & Telecommun, Sch Modern Post, Sch Automat, Beijing 100876, Peoples R China.
   [Fang, Tiyu] Shandong Univ, Sch Control Sci & Engn, Jinan 250100, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications; Shandong University
RP Hu, YZ (corresponding author), Beijing Univ Posts & Telecommun, Beijing Key Lab Work Safety Intelligent Monitoring, Beijing 100876, Peoples R China.; Hu, YZ (corresponding author), Beijing Univ Posts & Telecommun, Sch Modern Post, Sch Automat, Beijing 100876, Peoples R China.
EM bupt_automation_safety_yzhu@bupt.edu.cn
FU National Key Research and Development Program of China [2020YFC1511700]
FX AcknowledgementsThis work was supported by National Key Research and
   Development Program of China (No. 2020YFC1511700).
CR Atapour-Abarghouei A, 2019, PROC CVPR IEEE, P3368, DOI 10.1109/CVPR.2019.00349
   Bhat SF, 2021, PROC CVPR IEEE, P4008, DOI 10.1109/CVPR46437.2021.00400
   Bian JW, 2021, INT J COMPUT VISION, V129, P2548, DOI 10.1007/s11263-021-01484-6
   Bian Jia-Wang, 2021, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Chen PY, 2019, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2019.00273
   Chen Z, 2018, LECT NOTES COMPUT SC, V11208, P176, DOI 10.1007/978-3-030-01225-0_11
   Eigen D, 2014, ADV NEUR IN, V27
   Gao HB, 2018, IEEE T IND INFORM, V14, P4224, DOI 10.1109/TII.2018.2822828
   Han JH, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13060886
   Han YH, 2022, IEEE ROBOT AUTOM LET, V7, P6886, DOI 10.1109/LRA.2022.3178791
   Hu JJ, 2019, IEEE I CONF COMP VIS, P3868, DOI 10.1109/ICCV.2019.00397
   Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116
   Jiao JB, 2018, LECT NOTES COMPUT SC, V11219, P55, DOI 10.1007/978-3-030-01267-0_4
   Johnston A, 2020, PROC CVPR IEEE, P4755, DOI 10.1109/CVPR42600.2020.00481
   Jung G, 2022, MULTIMED TOOLS APPL, V81, P33759, DOI 10.1007/s11042-022-12301-8
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Kim W, 2020, IEEE T IMAGE PROCESS, V29, P8055, DOI 10.1109/TIP.2020.3011269
   Konrad J, 2013, IEEE T IMAGE PROCESS, V22, P3485, DOI 10.1109/TIP.2013.2270375
   Kumar ACS, 2018, IEEE COMPUT SOC CONF, P396, DOI 10.1109/CVPRW.2018.00066
   Kundu JN, 2018, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2018.00281
   Ladicky L, 2014, PROC CVPR IEEE, P89, DOI 10.1109/CVPR.2014.19
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Liu MM, 2014, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2014.97
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Lore Kin Gwn, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P1258, DOI 10.1109/CVPRW.2018.00163
   Ma FC, 2018, IEEE INT CONF ROBOT, P4796
   Mancini M, 2017, IEEE ROBOT AUTOM LET, V2, P1778, DOI 10.1109/LRA.2017.2657002
   Poggi M, 2022, IEEE T PATTERN ANAL, V44, P5314, DOI 10.1109/TPAMI.2021.3070917
   Poggi M, 2020, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR42600.2020.00329
   Qi XJ, 2018, PROC CVPR IEEE, P283, DOI 10.1109/CVPR.2018.00037
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Ranftl R, 2016, PROC CVPR IEEE, P4058, DOI 10.1109/CVPR.2016.440
   Saxena A., 2005, ADV NEURAL INFORM PR, V18, P1
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Shi JP, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818136
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sun L, 2022, MULTIMED TOOLS APPL, V81, P42485, DOI 10.1007/s11042-021-11212-4
   Tonioni A, 2020, IEEE T PATTERN ANAL, V42, P2396, DOI 10.1109/TPAMI.2019.2940948
   Wang C, 2021, IEEE T CYBERNETICS, V51, P4770, DOI 10.1109/TCYB.2020.2999492
   Wang LJ, 2020, PROC CVPR IEEE, P538, DOI 10.1109/CVPR42600.2020.00062
   Wang TH, 2019, IEEE INT CONF ROBOT, P5880, DOI [10.1109/ICRA.2019.8794404, 10.1109/icra.2019.8794404]
   Wang WY, 2018, LECT NOTES COMPUT SC, V11215, P144, DOI 10.1007/978-3-030-01252-6_9
   Xia ZH, 2020, PROC CVPR IEEE, P62, DOI 10.1109/CVPR42600.2020.00014
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Yang GL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16249, DOI 10.1109/ICCV48922.2021.01596
   Ye XC, 2021, IEEE T IMAGE PROCESS, V30, P4492, DOI 10.1109/TIP.2021.3072215
   Zhang ZY, 2019, PROC CVPR IEEE, P4101, DOI 10.1109/CVPR.2019.00423
   Zhao SS, 2019, PROC CVPR IEEE, P9780, DOI 10.1109/CVPR.2019.01002
   Zhao YH, 2020, PROC CVPR IEEE, P3327, DOI 10.1109/CVPR42600.2020.00339
   Zhuo W, 2015, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2015.7298660
NR 54
TC 0
Z9 0
U1 4
U2 20
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 14821
EP 14838
DI 10.1007/s11042-023-15757-4
EA JUL 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001027813700008
DA 2024-07-18
ER

PT J
AU Song, JQ
   Liu, ZZ
   Xie, CC
   Lu, C
   Zhao, JZ
   Gao, SL
AF Song, Jianqiang
   Liu, Zuozhi
   Xie, Chaochen
   Lu, Chao
   Zhao, Jianzhou
   Gao, Suling
TI Relaxed support vector based dictionary learning for image
   classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Relaxed support vector; Discriminative dictionary learning; Coefficiant
   representation; Image classification
ID LEAST-SQUARES REGRESSION; FACE RECOGNITION; K-SVD; SPARSE
AB Discriminative dictionary learning (DDL) has attracted significant attention in the field of image classification. To enhance the classification performance, most existing discriminative dictionary learning methods introduce supervision information on the dictionary to project raw training samples into a coefficient subspace. However, the strict constraint on coefficient features may not conducive to the separation of the training samples from different classes for dictionary learning. In this paper, we propose Relaxed Support Vector based Dictionary Learning (RSVDL) for image recognition, which can efficiently learn coefficient features with powerful discrimination and representation capabilities. By constructing a relaxed coefficient subspace that is closely associated with label information, the discriminative of the learned dictionary is also improved. Experimental results on several benchmark datasets show that the proposed RSVDL method is very effective for various image classification tasks. Moreover, the experiments on more challenging datasets further reveal the state-of-art performance of our method by using with the CNN features.
C1 [Song, Jianqiang; Xie, Chaochen; Lu, Chao; Zhao, Jianzhou; Gao, Suling] Anyang Inst Technol, Coll Elect Informat & Elect Engn, Anyang 455000, Peoples R China.
   [Liu, Zuozhi] Guizhou Univ Finance & Econ, Sch Math & Stat, Guiyang 550025, Peoples R China.
C3 Anyang Institute of Technology; Guizhou University of Finance &
   Economics
RP Song, JQ; Zhao, JZ (corresponding author), Anyang Inst Technol, Coll Elect Informat & Elect Engn, Anyang 455000, Peoples R China.
EM songjiebang@163.com; jianzhouzhao@126.com
RI Zhao, Jianzhou/L-7652-2016; Song, Jianqiang/JSL-5579-2023
OI Song, Jianqiang/0000-0002-9643-799X
FU Project of Science and Technology of Henan [232102210049]; Science and
   Technology Foundation of Guizhou Province [QKHJC[2020]1Y253,
   QKHJC-ZK[2022]YB024]; third batch of First class undergraduate courses
   in Henan Province [324]; first batch of Undergraduate college curriculum
   ideological and political model course in Henan Province [531]; Research
   Start-up Foundation [BSJ2022026]
FX This paper is supported by the Project of Science and Technology of
   Henan (No. 232102210049), the Science and Technology Foundation of
   Guizhou Province (Nos. QKHJC[2020]1Y253, QKHJC-ZK[2022]YB024), the
   Higher Education Teaching Reform Research and Practice Project of Henan
   (No. 2021SJGLX271), the third batch of First class undergraduate courses
   in Henan Province "Information Theory and Coding" (Department of Higher
   Education[2022], No. 324), the first batch of Undergraduate college
   curriculum ideological and political model course in Henan Province
   "Information Theory and Coding" (Department of Higher Education[2020],
   No. 531), and the Research Start-up Foundation of Dr. Song Jianqiang
   (No. BSJ2022026).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akhtar N, 2017, PATTERN RECOGN, V65, P136, DOI 10.1016/j.patcog.2016.12.017
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.322
   AprilPyone M, 2022, IEEE MULTIMEDIA, V29, P23, DOI 10.1109/MMUL.2022.3168441
   Bhadoriya Varun, 2022, ECS Transactions, V107, P7771, DOI 10.1149/10701.7771ecst
   Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91
   Boyd S., 2011, FOUND TRENDS MACH LE, V3, P1, DOI DOI 10.1561/2200000016
   Cai SJ, 2014, LECT NOTES COMPUT SC, V8692, P624, DOI 10.1007/978-3-319-10593-2_41
   Cai YH, 2022, PATTERN ANAL APPL, V25, P425, DOI 10.1007/s10044-021-01046-z
   Chen Z, 2022, IEEE T NEUR NET LEAR, V33, P3645, DOI 10.1109/TNNLS.2021.3053941
   Chen Z, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107118
   Donahue J, 2014, PR MACH LEARN RES, V32
   Dong J, 2022, NEURAL NETWORKS, V155, P498, DOI 10.1016/j.neunet.2022.08.031
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Elhamifar E., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1873, DOI 10.1109/CVPR.2011.5995664
   Fang XZ, 2018, IEEE T NEUR NET LEAR, V29, P1006, DOI 10.1109/TNNLS.2017.2648880
   Gao Z., 2022, IEEE Trans. Circuits Syst. Video Technol., P1, DOI [10.1109/TCSVT.2022.3232112, DOI 10.1109/TCSVT.2022.3232112]
   Goh H, 2014, IEEE T NEUR NET LEAR, V25, P2212, DOI 10.1109/TNNLS.2014.2307532
   Gu SH, 2014, ADV NEUR IN, V27
   He Y, 2014, P SIAM INT C DAT MIN, P902, DOI [10.1137/1.9781611973440.103, DOI 10.1137/1.9781611973440.103]
   Jiang K, 2022, MULTIMED TOOLS APPL, P1
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu YL, 2016, PATTERN RECOGN, V55, P58, DOI 10.1016/j.patcog.2016.01.030
   Lu XK, 2022, IEEE T PATTERN ANAL, V44, P7885, DOI 10.1109/TPAMI.2021.3115815
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Pham DS, 2008, PROC CVPR IEEE, P517
   Quan YH, 2016, PROC CVPR IEEE, P5839, DOI 10.1109/CVPR.2016.629
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Sun YL, 2020, IEEE T NEUR NET LEAR, V31, P4303, DOI 10.1109/TNNLS.2019.2954545
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885
   Wang DH, 2014, PATTERN RECOGN, V47, P885, DOI 10.1016/j.patcog.2013.08.004
   Wang XD, 2017, IEEE T IMAGE PROCESS, V26, P3859, DOI 10.1109/TIP.2017.2703101
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721
   Yan XY, 2016, IEEE IMAGE PROC, P2762, DOI 10.1109/ICIP.2016.7532862
   Yang BQ, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107690
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang M, 2017, NEUROCOMPUTING, V269, P13, DOI 10.1016/j.neucom.2016.08.146
   Yang M, 2017, NEUROCOMPUTING, V219, P404, DOI 10.1016/j.neucom.2016.09.037
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang SF, 2015, IEEE I CONF COMP VIS, P1215, DOI 10.1109/ICCV.2015.144
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang SZ, 2017, PATTERN RECOGN, V64, P130, DOI 10.1016/j.patcog.2016.10.032
   Zhang XY, 2015, IEEE T NEUR NET LEAR, V26, P2206, DOI 10.1109/TNNLS.2014.2371492
   Zhang Z, 2021, IEEE T NEUR NET LEAR, V32, P947, DOI 10.1109/TNNLS.2020.2979748
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou P, 2017, IEEE T IMAGE PROCESS, V26, P1173, DOI 10.1109/TIP.2016.2623487
NR 61
TC 0
Z9 0
U1 2
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD FEB
PY 2024
VL 83
IS 5
SI SI
BP 12731
EP 12755
DI 10.1007/s11042-023-15907-8
EA JUN 2023
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA IX6H7
UT WOS:001022083300004
DA 2024-07-18
ER

PT J
AU Zeng, W
   Ma, LM
   Zhang, Y
AF Zeng, Wei
   Ma, Limin
   Zhang, Yu
TI Detection of knee osteoarthritis based on recurrence quantification
   analysis, fuzzy entropy and shallow classifiers
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Knee osteoarthritis (OA); Dynamical features; Gait classification;
   Recurrence quantification analysis (RQA); Fuzzy entropy; Machine
   learning
ID GAIT VARIABILITY; MOTION ANALYSIS; MOTOR CONTROL; CLASSIFICATION;
   WALKING; PERFORMANCE; PATTERNS; FEATURES; SYSTEM; FORCE
AB Knee osteoarthritis (OA) is the most common joint disorder which results in mobility impairment and altered gait patterns. For the purpose of developing an automatic and highly accurate diagnosis system for knee OA, this study investigated the classification capability of different dynamical features extracted from gait kinematic signals when evaluating their impact on different classification models. A general feature extraction framework was proposed and various dynamical features, such as recurrence rate, determinism and entropy from the recurrence quantification analysis (RQA), Fuzzy entropy and statistical analysis, were included. Different shallow classifiers, including support vector machine (SVM) classifier, K-nearest neighbor (KNN), naive Bayes (NB) classifier, decision tree (DT) and ensemble learning based Adaboost (ELA) classifier, derived for discriminant analysis of multiple dynamical gait features were evaluated on the classification accuracy for a comparative study. The effectiveness of this strategy was verified using a dataset of tibiofemoral joint angle and translation waveforms from 26 patients with knee OA and 26 age-matched asymptomatic healthy controls (HCs). When evaluated with two-fold and leave-one-subject-out cross-validation methods, the highest classification accuracy for discriminating between groups of patients with knee OA and HCs was reported to be 92.31% and 100%, respectively, by using the SVM classifier. Compared with other state-of-the-art methods, the results demonstrate superior performance and support the validity of the proposed method.
C1 [Zeng, Wei] Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.
   [Ma, Limin; Zhang, Yu] Guangdong Prov Peoples Hosp, Dept Orthoped, Guangzhou 510080, Peoples R China.
C3 Longyan University; Guangdong Academy of Medical Sciences & Guangdong
   General Hospital
RP Zeng, W (corresponding author), Longyan Univ, Sch Phys & Mech & Elect Engn, Longyan 364012, Peoples R China.; Ma, LM (corresponding author), Guangdong Prov Peoples Hosp, Dept Orthoped, Guangzhou 510080, Peoples R China.
EM zengwei@lyun.edu.cn; malimin_7@126.com
FU National Natural Science Foundation of China [61773194, 31700880];
   Natural Science Foundation of Fujian Province [2023J01966]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61773194, 31700880) and by the Natural Science
   Foundation of Fujian Province (Grant No. 2023J01966).
CR Acharya UR, 2011, INT J NEURAL SYST, V21, P199, DOI 10.1142/S0129065711002808
   Ali A, 2022, NEURAL NETWORKS, V145, P233, DOI 10.1016/j.neunet.2021.10.021
   Ali A, 2021, INFORM SCIENCES, V577, P852, DOI 10.1016/j.ins.2021.08.042
   Ali A, 2021, MULTIMED TOOLS APPL, V80, P31401, DOI 10.1007/s11042-020-10486-4
   Alkjaer T, 2015, GAIT POSTURE, V42, P479, DOI 10.1016/j.gaitpost.2015.07.063
   ALTMAN R, 1986, ARTHRITIS RHEUM-US, V29, P1039, DOI 10.1002/art.1780290816
   Armi L., 2019, International Online Journal of Image Processing and Pattern Recognition, V2, P1, DOI DOI 10.48550/ARKXIV.1904.06554
   Armi L, 2019, MULTIMED TOOLS APPL, V78, P18995, DOI 10.1007/s11042-019-7207-2
   Azar AT, 2014, NEURAL COMPUT APPL, V24, P1163, DOI 10.1007/s00521-012-1324-4
   Befrui N, 2018, MED BIOL ENG COMPUT, V56, P1499, DOI 10.1007/s11517-018-1785-4
   Berger J. O., 1985, STAT DECISION THEORY, DOI DOI 10.1007/978-1-4757-4286-2
   Beynon MJ, 2006, IEEE T SYST MAN CY A, V36, P173, DOI 10.1109/TSMCA.2006.859098
   Blanco FJ, 2012, NAT REV RHEUMATOL, V8, P130, DOI 10.1038/nrrheum.2012.11
   Buckley JJ., 2006, FUZZY PROBABILITY ST, P223
   Chan Sophal, 2022, International Journal of Computers and Applications, V44, P571, DOI 10.1080/1206212X.2020.1838145
   Chen HC, 2014, IEEE T BIO-MED ENG, V61, P171, DOI 10.1109/TBME.2013.2278780
   Chen WT, 2007, IEEE T NEUR SYS REH, V15, P266, DOI 10.1109/TNSRE.2007.897025
   Chu K., 1999, Emerg Med, V11, P175, DOI DOI 10.1046/J.1442-2026.1999.00041.X
   Debi R, 2017, ORTHOP TRAUMATOL-SUR, V103, P603, DOI 10.1016/j.otsr.2017.02.006
   Deluzio KJ, 2007, GAIT POSTURE, V25, P86, DOI 10.1016/j.gaitpost.2006.01.007
   ECKMANN JP, 1987, EUROPHYS LETT, V4, P973, DOI 10.1209/0295-5075/4/9/004
   Esrafilian A, 2013, RHEUMATOL INT, V33, P1753, DOI 10.1007/s00296-012-2639-2
   Faisal A, 2018, MED BIOL ENG COMPUT, V56, P657, DOI 10.1007/s11517-017-1710-2
   Fan GF, 2022, INT J ELEC POWER, V139, DOI 10.1016/j.ijepes.2022.108073
   Fan GF, 2021, UTIL POLICY, V73, DOI 10.1016/j.jup.2021.101294
   Fekri-Ershad S, 2022, COMPUT BIOL MED, V144, DOI 10.1016/j.compbiomed.2022.105392
   Felson DT, 2000, ANN INTERN MED, V133, P635, DOI 10.7326/0003-4819-133-8-200010170-00016
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Gustafson JA, 2015, CLIN BIOMECH, V30, P475, DOI 10.1016/j.clinbiomech.2015.03.007
   Hada S, 2017, ARTHRITIS RES THER, V19, DOI 10.1186/s13075-017-1411-0
   Huang YP, 2018, ULTRASOUND MED BIOL, V44, P94, DOI 10.1016/j.ultrasmedbio.2017.08.1884
   Josinski H, 2015, AIP CONF PROC, V1648, DOI 10.1063/1.4912882
   Karg M, 2015, IEEE T NEUR SYS REH, V23, P319, DOI 10.1109/TNSRE.2014.2362862
   Kaufman KR, 2001, J BIOMECH, V34, P907, DOI 10.1016/S0021-9290(01)00036-7
   KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494
   Kotti M, 2017, MED ENG PHYS, V43, P19, DOI 10.1016/j.medengphy.2017.02.004
   Kubkaddi S., 2017, IJSEAT, V5, P259
   Lundberg HJ, 2012, J BIOMECH, V45, P990, DOI 10.1016/j.jbiomech.2012.01.015
   McCarthy I, 2013, BMC MUSCULOSKEL DIS, V14, DOI 10.1186/1471-2474-14-169
   Mezghani N, 2008, IEEE T BIO-MED ENG, V55, P1230, DOI 10.1109/TBME.2007.905388
   Middleton A, 2015, J AGING PHYS ACTIV, V23, P314, DOI 10.1123/japa.2013-0236
   Mills K, 2013, ARTHRIT CARE RES, V65, P1643, DOI 10.1002/acr.22015
   Mukhopadhyay S, 2018, PROC SPIE, V10506, DOI 10.1117/12.2290326
   Orellana JN, 2018, BIOMED SIGNAL PROCES, V39, P431, DOI 10.1016/j.bspc.2017.08.017
   Ornetti P, 2010, JOINT BONE SPINE, V77, P421, DOI 10.1016/j.jbspin.2009.12.009
   Park HJ, 2013, EUR J RADIOL, V82, P112, DOI 10.1016/j.ejrad.2012.02.023
   Peixoto JG, 2019, AGING CLIN EXP RES, V31, P67, DOI 10.1007/s40520-018-0942-9
   Phinyomark A, 2018, J MED BIOL ENG, V38, P244, DOI 10.1007/s40846-017-0297-2
   Prabhu P, 2020, PATTERN RECOGN LETT, V139, P10, DOI 10.1016/j.patrec.2018.05.006
   Procházka A, 2015, NEURAL COMPUT APPL, V26, P1621, DOI 10.1007/s00521-015-1827-x
   Ramdani S, 2013, ANN BIOMED ENG, V41, P1713, DOI 10.1007/s10439-013-0790-x
   Riad R, 2018, COMPUT ELECTR ENG, V68, P181, DOI 10.1016/j.compeleceng.2018.04.004
   Roos EM, 2016, NAT REV RHEUMATOL, V12, P92, DOI 10.1038/nrrheum.2015.135
   Segal NA, 2015, PHYSICIAN SPORTSMED, V43, P213, DOI 10.1080/00913847.2015.1074854
   Sen Köktas N, 2010, PATTERN RECOGN LETT, V31, P898, DOI 10.1016/j.patrec.2010.01.003
   Smith JW, 2014, WORLD J ORTHOP, V5, P69, DOI 10.5312/wjo.v5.i2.69
   Takens F, 1981, Lecture Notes in Mathematics, V898, P366, DOI [10.1007/BFb0091924, DOI 10.1007/BFB0091924]
   Tanha J, 2017, INT J MACH LEARN CYB, V8, P355, DOI 10.1007/s13042-015-0328-7
   Tarnita D, 2017, P ROMANIAN ACAD A, V18, P353
   Tawy GF, 2018, GAIT POSTURE, V59, P272, DOI 10.1016/j.gaitpost.2017.08.015
   van der Straaten R, 2018, GAIT POSTURE, V59, P229, DOI 10.1016/j.gaitpost.2017.10.005
   van Egmond N, 2017, KNEE SURG SPORT TR A, V25, P2904, DOI 10.1007/s00167-016-4045-x
   Vapnik V. N., 1998, STAT LEARNING THEORY
   Wang G, 2014, DECIS SUPPORT SYST, V57, P77, DOI 10.1016/j.dss.2013.08.002
   Webber C.L., 2015, THEORY BEST PRACTICE
   Xie HB, 2018, IEEE T FUZZY SYST, V26, P1970, DOI 10.1109/TFUZZ.2017.2756829
   Xie HB, 2011, APPL SOFT COMPUT, V11, P2871, DOI 10.1016/j.asoc.2010.11.020
   Xu BB, 2013, IEEE ENG MED BIO, P3274, DOI 10.1109/EMBC.2013.6610240
   Yang JH, 2020, ANN REHABIL MED-ARM, V44, P415, DOI 10.5535/arm.20071
   Yang MJ, 2012, MED ENG PHYS, V34, P740, DOI 10.1016/j.medengphy.2011.09.018
   Yuan QF, 2007, COMM COM INF SC, V2, P1250
   Zbilut JP, 1998, PHYS LETT A, V237, P131, DOI 10.1016/S0375-9601(97)00843-8
   Zhang SC, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2990508
   Zhang Y, 2015, GAIT POSTURE, V41, P763, DOI 10.1016/j.gaitpost.2015.01.020
   Zhou DG, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00411-5
NR 75
TC 2
Z9 2
U1 1
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11977
EP 11998
DI 10.1007/s11042-023-15772-5
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001022136100004
DA 2024-07-18
ER

PT J
AU Khanna, D
   Jindal, N
   Rana, PS
   Singh, H
AF Khanna, Deepanshu
   Jindal, Neeru
   Rana, Prashant Singh
   Singh, Harpreet
TI Enhanced spatio-temporal 3D CNN for facial expression classification in
   videos
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Face expression recognition; Video pre-processing; Hybrid deep network
ID RECOGNITION; FACE
AB This article proposes a hybrid network model for video-based human facial expression recognition (FER) system consisting of an end-to-end 3D deep convolutional neural networks. The proposed network combines two commonly used deep 3-dimensional Convolutional Neural Networks (3D CNN) models, ResNet-50 and DenseNet-121, in an end-to-end manner with slight modifications. Currently, various methodologies exist for FER, such as 2-dimensional Convolutional Neural Networks (2D CNN), 2D CNN-Recurrent Neural Networks, 3D CNN, and features extracting algorithms such as PCA and Histogram of oriented gradients (HOG) combined with machine learning classifiers. For the proposed model, we choose 3D CNN over other methods since they preserve temporal information of the videos, unlike 2D CNN. Moreover, these aren't labor-intensive such as various handcrafted feature extracting methods. The proposed system relies on the temporal averaging of information from frame sequences of the video. The databases are pre-processed to remove unwanted backgrounds for training 3D deep CNN from scratch. Initially, feature vectors from video frame sequences are extracted using the 3D ResNet model. These feature vectors are fed to the 3D DenseNet model's blocks, which are then used to classify the predicted emotion. The model is evaluated on three benchmarking databases: Ravdess, CK + , and BAUM1s, which achieved 91.69%, 98.61%, and 73.73% accuracy for the respective databases and outperformed various existing methods. We prove that the proposed architecture works well even for the classes with less amount of training data where many existing 3D CNN networks fail.
C1 [Khanna, Deepanshu; Jindal, Neeru] Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
   [Rana, Prashant Singh; Singh, Harpreet] Thapar Inst Engn & Technol, Comp Sci Engn Dept, Patiala, Punjab, India.
C3 Thapar Institute of Engineering & Technology; Thapar Institute of
   Engineering & Technology
RP Khanna, D (corresponding author), Thapar Inst Engn & Technol, Elect & Commun Engn Dept, Patiala, Punjab, India.
EM dkhanna_be19@thapar.edu; neeru.jindal@thapar.edu;
   prashant.singh@thapar.edu; harpreet.s@thapar.edu
CR Akilan T, 2020, IEEE T INTELL TRANSP, V21, P959, DOI 10.1109/TITS.2019.2900426
   Aly S, 2016, IEEE WINT CONF APPL
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   Dhankhar P, 2019, RESNET 50 VGG 16 REC, V13, P1, DOI [10.21172/ijiet.134.18, DOI 10.21172/IJIET.134.18]
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   García M, 2020, IEEE LAT AM T, V18, P1311, DOI 10.1109/TLA.2020.9099774
   Ghaleb E, 2019, INT CONF AFFECT, DOI [10.1109/acii.2019.8925444, 10.1109/ACII.2019.8925444]
   Haddad Jad, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P298, DOI 10.1007/978-3-030-64559-5_23
   Hara K, 2018, CAN SPATIOTEMPORAL 3, DOI [10.1109/ACCESS.2019.2901521, DOI 10.1109/ACCESS.2019.2901521]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZH, 2019, ICMLC 2019: 2019 11TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P374, DOI 10.1145/3318299.3318321
   Ho TT, 2021, 3D CNN MODEL CT BASE, DOI [10.1038/s41598-020-79336-5, DOI 10.1038/S41598-020-79336-5]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ji F, 2021, FUTURE GENER COMP SY, V116, P365, DOI 10.1016/j.future.2020.10.025
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Khorrami P, 2016, IEEE IMAGE PROC, P619, DOI 10.1109/ICIP.2016.7532431
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Li B., 2021, International Journal of Cognitive Computing in Engineering, V2, P57
   Li C, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23020823
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Miao Y, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3311747
   Mohammadi MR, 2014, J VIS COMMUN IMAGE R, V25, P1082, DOI 10.1016/j.jvcir.2014.03.006
   Peña D, 2020, ACM T HUM-ROBOT INTE, V9, DOI 10.1145/3388469
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sharma G, 2019, 3D RES, V10, DOI 10.1007/s13319-019-0224-0
   Singh Rajesh, 2023, Int J Inf Technol, V15, P1819, DOI 10.1007/s41870-023-01183-0
   Tariq U., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P872, DOI 10.1109/FG.2011.5771365
   Yang B, 2018, IEEE ACCESS, V6, P4630, DOI 10.1109/ACCESS.2017.2784096
   Zhalehpour S, 2017, IEEE T AFFECT COMPUT, V8, P300, DOI 10.1109/TAFFC.2016.2553038
   Zhang SQ, 2019, IEEE ACCESS, V7, P32297, DOI 10.1109/ACCESS.2019.2901521
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
NR 38
TC 0
Z9 0
U1 4
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9911
EP 9928
DI 10.1007/s11042-023-16066-6
EA JUN 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001018078900002
DA 2024-07-18
ER

PT J
AU Arora, N
   Sharma, SC
AF Arora, Nitin
   Sharma, Subhash Chander
TI ETLBP and ERDLBP descriptors for efficient facial image retrieval in
   CBIR systems
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE CBIR; LBP; t-LBP; RD-LBP; Feature descriptor
ID TEXTURE FEATURE; PATTERN-A
AB The traditional Local Binary Pattern (LBP) employs a 3x3 pixel window and examines the intensity differences between the center pixel and nearby neighbourhood pixels. However, LBP excludes the magnitude of difference information entirely, which highly enhances the discriminative performance between classes. In this work, we propose two new feature descriptors called Extended Transition-LBP (ETLBP) and Extended Radial Difference-LBP (ERDLBP) that include the mean of the magnitude difference of each neighbourhood pixel from the central pixel. The robustness of the proposed descriptors is investigated on four publicly available facial databases. The study has established the effectiveness of the feature descriptors. The experimental findings show that the suggested methods statistically outperformed the existing state-of-the-art methods.
C1 [Arora, Nitin; Sharma, Subhash Chander] Indian Inst Technol, Roorkee, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Roorkee
RP Arora, N (corresponding author), Indian Inst Technol, Roorkee, India.
EM nitinarora.iitr@gmail.com; scs60fpt@gmail.com
OI ARORA, NITIN/0000-0002-0132-2648
CR Ahmed F., 2011, 2011 Proceedings of IEEE 12th International Symposium on Computational Intelligence and Informatics (CINTI 2011), P391, DOI 10.1109/CINTI.2011.6108536
   Allagwail S, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11020157
   [Anonymous], YALEFACES YALE FACE
   [Anonymous], 2010, Computer Vision Winter Workshop
   Arora N, 2023, MULTIMED TOOLS APPL, P1
   Arora N, 2019, INT J IMAGE GRAPHIC, V11
   AT, 2021, T LAB CAMBR T DAT FA
   Banerjee P, 2018, EXPERT SYST APPL, V113, P100, DOI 10.1016/j.eswa.2018.06.044
   Bedi AK, 2021, MULTIMED TOOLS APPL, V80, P20773, DOI 10.1007/s11042-021-10758-7
   Bedi AK, 2020, PATTERN RECOGN IMAGE, V30, P578
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dubey SR, 2020, MULTIMED TOOLS APPL, V79, P6363, DOI 10.1007/s11042-019-08370-x
   GeorgiaTech, 2021, GEORGIA TECH FACE DA
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Gupta S, 2020, PATTERN ANAL APPL, V23, P1569, DOI 10.1007/s10044-020-00879-4
   Hafiane A, 2007, LECT NOTES COMPUT SC, V4633, P387
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Hongliang Jin, 2004, Proceedings. Third International Conference on Image and Graphics, P306
   Jabid T., 2010, 2010 7th IEEE International Conference of Advanced Video and Signal Based Surveillance, P482
   Karanwal S, 2021, OPTIK, V241, DOI 10.1016/j.ijleo.2021.166965
   Karanwal S, 2021, PATTERN ANAL APPL, V24, P741, DOI 10.1007/s10044-020-00948-8
   KRUSKAL WH, 1952, J AM STAT ASSOC, V47, P583, DOI 10.1080/01621459.1952.10483441
   Liu BY, 2019, IEEE I CONF COMP VIS, P10051, DOI 10.1109/ICCV.2019.01015
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Long FH, 2003, SIG COM TEC, P1
   Martolia M., 2020, Int. J. Adv. Sci. Technol., V29, P1630
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Perumal RS, 2016, EXPERT SYST APPL, V63, P66, DOI 10.1016/j.eswa.2016.06.031
   Rakshit RD, 2017, J CHIN INST ENG, V40, P82, DOI 10.1080/02533839.2016.1259020
   Singhal A, 2021, MULTIMED TOOLS APPL, V80, P15901, DOI 10.1007/s11042-020-10319-4
   Spacek L, 2021, FACE RECOGNITION DAT
   Sucharitha G, 2020, MULTIMED TOOLS APPL, V79, P1847, DOI 10.1007/s11042-019-08215-7
   Sun Y, 2015, ARXIV
   Swati ZNK, 2019, IEEE ACCESS, V7, P17809, DOI 10.1109/ACCESS.2019.2892455
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Trappey AJC, 2021, ADV ENG INFORM, V48, DOI 10.1016/j.aei.2021.101291
   Verma M, 2018, MULTIMED TOOLS APPL, V77, P11843, DOI 10.1007/s11042-017-4834-3
   Verma M, 2016, DIGIT SIGNAL PROCESS, V51, P62, DOI 10.1016/j.dsp.2016.02.002
   Wang XB, 2019, IEEE I CONF COMP VIS, P9357, DOI 10.1109/ICCV.2019.00945
   Xiangsheng Huang, 2004, Proceedings. Third International Conference on Image and Graphics, P184
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
NR 44
TC 1
Z9 1
U1 1
U2 2
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9817
EP 9851
DI 10.1007/s11042-023-15832-w
EA JUN 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001021028900018
DA 2024-07-18
ER

PT J
AU Krithiga, R
   Geetha, P
AF Krithiga, R.
   Geetha, P.
TI Proliferation score prediction using novel SMHC feature using adaptive
   XGBoost model
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Breast cancer grading; Supervised learning; Mitosis detection; XGBoost;
   Salient detection
ID MITOSIS DETECTION; SEGMENTATION
AB Mitosis cell counting from histopathology image is one of the important process as a part of proliferative activity for cancer grading. It provides a level of progression and estimate the aggressiveness of particular diseases. Unfortunately, manual mitosis counting evaluation is a tedious, very labor intensive, and challenging task in analysing grade of a particular cancer. Since breast cancer recurrence and metastasis are intrinsically related to mortality, it is critical to predict the recurrence and metastasis risk of an individual patient, which is essential for adjutant therapy and early intervention. The aim of this study is to propose supervised model to solve the problem of mitosis detection and reduced the time lapse of process compared to the manual counting. We formulate a Low-Rank Matrix Recovery (LRMR) model to find salient regions from microscopy images and extract candidate patch sequences, which potentially contain mitosis cells. Once the patches are segmented, a novel Sparse Patch based Mitosis Handcrafted Feature (SMHCF) are extracted and based on the feature values a eXtreme Gradient Boosting (XGBoost) model are used to classify the mitosis and non-mitosis cells and count of the each cells. Our method is compared with the manual counting values and other state of the art methods. In that performances of our model achieved with better precision is 0.971, recall is 0.960, F1-score is 0.963 rates.
C1 [Krithiga, R.] Vellore Inst Technol, Dept Comp Sci & Engn, Chennai, India.
   [Geetha, P.] Anna Univ, Coll Engn, Dept Comp Sci & Engn, Chennai, Guindy, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Anna University;
   Anna University Chennai
RP Krithiga, R (corresponding author), Vellore Inst Technol, Dept Comp Sci & Engn, Chennai, India.
EM rkrithigarajesh@gmail.com
CR Beevi KS, 2019, BIOCYBERN BIOMED ENG, V39, P214, DOI 10.1016/j.bbe.2018.10.007
   Chan KS, 2012, CELL DEATH DIS, V3, DOI 10.1038/cddis.2012.148
   Chanchal AK, 2022, MULTIMED TOOLS APPL, V81, P9201, DOI 10.1007/s11042-021-11873-1
   Chen H, 2016, AAAI CONF ARTIF INTE, P1160
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Elangovan P, 2021, INT J IMAG SYST TECH, V31, P955, DOI 10.1002/ima.22494
   ELSTON CW, 1993, J CLIN PATHOL, V46, P189
   Freeman EA, 2016, CAN J FOREST RES, V46, P323, DOI 10.1139/cjfr-2014-0562
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Golbabaee M, 2012, INT CONF ACOUST SPEE, P2741, DOI 10.1109/ICASSP.2012.6288484
   Hou L, 2017, ARXIV
   Li C, 2018, MED IMAGE ANAL, V45, P121, DOI 10.1016/j.media.2017.12.002
   Li YX, 2018, PHARMACOL BIOCHEM BE, V175, P69, DOI 10.1016/j.pbb.2018.09.006
   Liu AA, 2012, IEEE T MED IMAGING, V31, P359, DOI 10.1109/TMI.2011.2169495
   Liu Y, 2017, ARXIV, DOI [10.48550/arXiv.1703, DOI 10.48550/ARXIV.1703]
   Macenko M, 2009, I S BIOMED IMAGING, P1107, DOI 10.1109/ISBI.2009.5193250
   Mahmood T, 2018, J MED IMAG HEALTH IN, V8, P932, DOI 10.1166/jmihi.2018.2382
   Medri L, 2003, MODERN PATHOL, V16, P1067, DOI 10.1097/01.MP.0000093625.20366.9D
   MITOS, 2014, ICPR 2014 CONT IP UM
   Nie WZ, 2016, IEEE COMPUT SOC CONF, P1359, DOI 10.1109/CVPRW.2016.171
   Pang SC, 2019, MED BIOL ENG COMPUT, V57, P107, DOI 10.1007/s11517-018-1819-y
   Paul A, 2015, IEEE T IMAGE PROCESS, V24, P4041, DOI 10.1109/TIP.2015.2460455
   Peng YG, 2012, IEEE T PATTERN ANAL, V34, P2233, DOI 10.1109/TPAMI.2011.282
   Prajna Y, 2022, J INTELL FUZZY SYST, P1, DOI DOI 10.3233/JIFS-211479
   Razavi Salar, 2022, J Pathol Inform, V13, P100002, DOI 10.1016/j.jpi.2022.100002
   Saha M, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2020.107200
   Saha M, 2018, COMPUT MED IMAG GRAP, V64, P29, DOI 10.1016/j.compmedimag.2017.12.001
   Sebai M, 2020, MED BIOL ENG COMPUT, V58, P1603, DOI 10.1007/s11517-020-02175-z
   Shamseddine A, 2014, POPUL HEALTH METR, V12, DOI 10.1186/1478-7954-12-4
   Sharma Harshita, 2015, The Diagnostic Pathology Journal, V1, P08, DOI [10.17629/www.diagnosticpathology.eu-2015-1:61, DOI 10.17629/WWW.DIAGNOSTICPATHOLOGY.EU-2015-1:61]
   Sohail A, 2021, MED IMAGE ANAL, V72, DOI 10.1016/j.media.2021.102121
   Srivastava A., 2017, Int. J. Latest Technol. Eng. Manag. Appl. Sci. (IJLTEMAS) VI, VVI
   Tang P, 2017, PATTERN RECOGN, V71, P446, DOI 10.1016/j.patcog.2017.05.001
   Tellez D, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101544
   Tellez D, 2018, IEEE T MED IMAGING, V37, P2126, DOI 10.1109/TMI.2018.2820199
   TUPAC, 2016, TUMOR PROLIFERATION
   Veta M, 2015, MED IMAGE ANAL, V20, P237, DOI 10.1016/j.media.2014.11.010
   Wang YX, 2019, NEURAL COMPUT APPL, V31, P3455, DOI 10.1007/s00521-017-3291-2
   Wei BZ, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA 2017), P348, DOI 10.1109/ICCCBDA.2017.7951937
   Wright J, 2009, ADV NEURAL INFORM PR, P2080, DOI DOI 10.1109/NNSP.2000.889420
   Yunxiang Mao, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P685, DOI 10.1007/978-3-319-46723-8_79
   Zerhouni E, 2017, I S BIOMED IMAGING, P924, DOI 10.1109/ISBI.2017.7950667
   Zhang H., 2017, ARXIV
NR 44
TC 0
Z9 0
U1 1
U2 1
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 11845
EP 11860
DI 10.1007/s11042-023-15987-6
EA JUN 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800009
DA 2024-07-18
ER

PT J
AU Oliveira, J
   Alarcao, SM
   Chambel, T
   Fonseca, MJ
AF Oliveira, Joao
   Alarcao, Soraia M.
   Chambel, Teresa
   Fonseca, Manuel J.
TI metaFERA: a meta-framework for creating emotion recognition frameworks
   for physiological signals
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Emotion recognition; Physiological signals; Software as a service;
   Software framework
AB Recognizing emotions from physiological signals has proven to be important in various scenarios. To assist in developing emotion recognizers, software frameworks and toolboxes have emerged, offering ready-to-use components. However,these have limitations regarding the type of physiological signals supported, the recognition steps covered, or the acquisition of multiple physiological signals. This paper presents metaFERA, an architectural meta-framework for creating software frameworks for end-to-end emotion recognition from physiological signals. The modularity and flexibility of the meta-framework and the resulting frameworks allow the fast prototyping of emotion recognition systems and experiments to test and validate new algorithms. To that end, metaFERA offers: (i) a set of pre-configured blocks to which we can add behavior to create framework components; (ii) an easy way to add behavior to the pre-configured blocks; (iii) a channel-based communication mechanism that transparently and efficiently supports the exchange of information between components; (iv) a simple and easy way to use and link components from a resulting framework to create applications. Additionally, we provide a set of Web services, already configured, to make the resulting recognition systems available as a service. To validate metaFERA, we created a framework for Electrodermal Activity, an emotion recognizer to identify high/low arousal using the aforementioned framework, and a layer to offer the recognizer as a service.
C1 [Oliveira, Joao; Alarcao, Soraia M.; Chambel, Teresa; Fonseca, Manuel J.] Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
C3 Universidade de Lisboa
RP Fonseca, MJ (corresponding author), Univ Lisbon, Fac Ciencias, LASIGE, Lisbon, Portugal.
EM joliveira@lasige.di.fc.ul.pt; smalarcao@ciencias.ulisboa.pt;
   mtchambel@ciencias.ulisboa.pt; mjfonseca@ciencias.ulisboa.pt
RI Fonseca, Manuel J./D-5120-2011; Meneses Alarcão, Soraia/HLP-7664-2023;
   Chambel, Teresa/Q-2485-2015
OI Fonseca, Manuel J./0000-0002-3559-828X; Meneses Alarcão,
   Soraia/0000-0002-0794-2979; Chambel, Teresa/0000-0002-0306-3352
FU FCT [PTDC/CCI-INF/29234/2017, SFRH/BD/138263/2018]; LASIGE Research Unit
   [UIDB/00408/2020, UIDP/00408/2020]
FX This work was supported by FCT through project AWESOME, ref.
   PTDC/CCI-INF/29234/2017, and the LASIGE Research Unit, ref.
   UIDB/00408/2020 and ref. UIDP/00408/2020. Soraia M. Alarcao is funded by
   an FCT grant, ref. SFRH/BD/138263/2018.
CR Alves Ana Priscila, 2013, Proceedings of the 6th International Conference on Biomedical Electronics and Devices. BIODEVICES 2013, P261
   [Anonymous], 2001, IMOTIONS BIOMETRIC R
   Blechert J, 2016, BEHAV RES METHODS, V48, P1528, DOI 10.3758/s13428-015-0665-1
   Brunet D, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/813870
   Delorme A, 2004, J NEUROSCI METH, V134, P9, DOI 10.1016/j.jneumeth.2003.10.009
   Duin, 2000, P SOC PHOTO-OPT INS, P1331
   Frank E, 2004, BIOINFORMATICS, V20, P2479, DOI 10.1093/bioinformatics/bth261
   Gramfort A, 2014, NEUROIMAGE, V86, P446, DOI 10.1016/j.neuroimage.2013.10.027
   gtec, BSANALYZE OFFLINE BI
   Higham D.J., 2016, MATLAB Guide
   HJORTH B, 1970, ELECTROEN CLIN NEURO, V29, P306, DOI 10.1016/0013-4694(70)90143-4
   Hofmann M., 2016, RapidMiner: Data Mining Use Cases and Business Analytics Applications
   Jayaram V, 2018, J NEURAL ENG, V15, DOI 10.1088/1741-2552/aadea0
   Li H., 2016, SMILE STAT MACHINE I
   Liapis A, 2021, INT J HUM-COMPUT INT, V37, P470, DOI 10.1080/10447318.2020.1825205
   Michalska M., 2009, Openbci: Framework for braincomputer interfaces
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Muñoz JE, 2018, MULTIMED TOOLS APPL, V77, P11521, DOI 10.1007/s11042-017-5069-z
   Oliphant TE, 2007, COMPUT SCI ENG, V9, P10, DOI 10.1109/MCSE.2007.58
   Oostenveld R, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/156869
   Palestra G, 2020, MULTIMED TOOLS APPL, V79, P35829, DOI 10.1007/s11042-020-10092-4
   Pedregosa F., 2018, SCIKIT LEARN MACHINE
   Pham MT, 2013, INT J RES MARK, V30, P383, DOI 10.1016/j.ijresmar.2013.04.004
   Soleymani M., 2017, Frontiers in ICT, V4, DOI DOI 10.3389/FICT.2017.00001
   Tadel F, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/879716
   Tijs TJW, 2008, LECT NOTES COMPUT SC, V5294, P88, DOI 10.1007/978-3-540-88322-7_9
   Vidaurre C, 2011, COMPUT INTEL NEUROSC, V2011, DOI 10.1155/2011/935364
   Virtanen P, 2020, NAT METHODS, V17, P261, DOI 10.1038/s41592-019-0686-2
NR 28
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 9785
EP 9815
DI 10.1007/s11042-023-15249-5
EA JUN 2023
PG 31
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016469800011
OA hybrid
DA 2024-07-18
ER

PT J
AU Nijhawan, R
   Sinha, G
   Batra, A
   Kumar, M
   Sharma, H
AF Nijhawan, Rahul
   Sinha, Garima
   Batra, Ashita
   Kumar, Manoj
   Sharma, Himanshu
TI VTnet plus Handcrafted based approach for food cuisines classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Food pattern detection; Food recognition; Transformer; Hand-crafted
   features; Feature extraction; Multi-class classification
ID NETWORK; RECOGNITION; RETRIEVAL
AB In this paper, we propose a novel hybrid transformer architecture for food cuisine detection and classification. The work carried out within this paper develops a combination of Vision Transformer ensemble architecture with hand-crafted features, thereby making a hybrid Vision Transformer food recognition system. Recently, Vision transformers have been introduced as an alternative means of classification to convolutional neural networks. It performs pattern detection and classification without convolutions and interprets an image as a sequence of patches. The combination of Vision Transformer and hand-crafted features like GIST, HoG (Histogram of Oriented Gradients), and LBP (Local Binary Pattern) were employed on the dataset. The dataset was specifically created (for this work) from the public logging system. It consisted of 13 food categories with 400 images of Indian food items like Ghevar, Idli, Dosa, and much more. It helped to capture a variety of images from every domain and culture. This work made use of the common and readily available food items, which can further be increased by adding on the specialties (dishes) from different regions. Various experiments were performed on CNN with various classifiers like Random forest, and SVM. Further, we compared our proposed approach with several ensembles of CNN architectures. The experiments proved that our proposed approach outperformed the state-of-the-art ensemble CNN architectures for detecting food cuisines. The proposed hybrid approach achieved an accuracy of 94.63%, sensitivity 84.42%, specificity 95.23%, and kappa coefficient 0.93, which was the best amongst all approaches.
C1 [Nijhawan, Rahul] Thapar Univ, Dept Comp Sci & Engn, Patiala, Punjab, India.
   [Sinha, Garima] Jain Deemed Univ, Dept Comp Sci, Bangalore, Karnataka, India.
   [Batra, Ashita; Sharma, Himanshu] IIT Guwahati, Dept Comp Sci, Gauhati, Assam, India.
   [Kumar, Manoj] Univ Wollongong Dubai, Sch Comp Sci, FEIS, Dubai Knowledge Pk, Dubai, U Arab Emirates.
   [Kumar, Manoj] Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
C3 Thapar Institute of Engineering & Technology; Jain University; Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Guwahati; University of Wollongong; Middle East
   University
RP Kumar, M (corresponding author), Univ Wollongong Dubai, Sch Comp Sci, FEIS, Dubai Knowledge Pk, Dubai, U Arab Emirates.; Kumar, M (corresponding author), Middle East Univ, MEU Res Unit, Amman 11831, Jordan.
EM rahulnijhawan2010@gmail.com; mailatgarima@yahoo.co.in;
   b.ashita@iitg.ac.in; wss.manojkumar@gmail.com; h.sharma@iitg.ac.in
RI Sinha, Garima/O-3270-2014; Kumar, Manoj/AFS-0700-2022
OI Sinha, Garima/0000-0001-6037-6235; Kumar, Manoj/0000-0001-9598-0280
FU CAUL and its Member Institutions
FX Open Access funding enabled and organized by CAUL and its Member
   Institutions.
CR [Anonymous], 2010, Multimedia (ISM), 2010 IEEE International Symposium on
   Bai JW, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108331
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen M, 2009, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2009.5413511
   Ciocca G, 2017, IEEE J BIOMED HEALTH, V21, P588, DOI 10.1109/JBHI.2016.2636441
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fahira PK, 2020, ICICOS 2020 P 4 INT, P1, DOI DOI 10.1109/ICICOS51170.2020.9299039
   Fakhrou A, 2021, MULTIMED TOOLS APPL, V80, P33011, DOI 10.1007/s11042-021-11329-6
   Farinella GM, 2016, COMPUT BIOL MED, V77, P23, DOI 10.1016/j.compbiomed.2016.07.006
   Groenendijk R, 2020, COMPUT VIS IMAGE UND, V190, DOI 10.1016/j.cviu.2019.102848
   Hu H, 2019, IEEE I CONF COMP VIS, P3463, DOI 10.1109/ICCV.2019.00356
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Isa NAM, 2011, APPL SOFT COMPUT, V11, P1457, DOI 10.1016/j.asoc.2010.04.017
   Heravi EJ, 2018, PATTERN RECOGN LETT, V105, P50, DOI 10.1016/j.patrec.2017.12.007
   Jiang B, 2017, J VIS COMMUN IMAGE R, V48, P356, DOI 10.1016/j.jvcir.2017.02.011
   Kawano Y, 2015, LECT NOTES COMPUT SC, V8927, P3, DOI 10.1007/978-3-319-16199-0_1
   Kawano Y, 2013, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW.2013.5
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li X, 2022, PATTERN RECOGN LETT
   Matsuda Y., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P25, DOI 10.1109/ICME.2012.157
   Matsuda Y, 2012, INT C PATT RECOG, P2017
   Mazzia V, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108487
   Oliveira L, 2014, PATTERN RECOGN, V47, P1941, DOI 10.1016/j.patcog.2013.12.006
   Setyono NFP, 2018, INT C ADV COMP SCI I, P441, DOI 10.1109/ICACSIS.2018.8618175
   Sharma P., 2022, INT J ADV COMPUT TEC, V11, P1
   Simon Philomina., 2023, Advances in Cognitive Science and Communications, Cognitive Science and Technology, P531
   Su H, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P565, DOI 10.1145/2638728.2641335
   Su TC, 2016, EUR J REMOTE SENS, V49, P531, DOI 10.5721/EuJRS20164928
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang BH, 2021, SCI TOTAL ENVIRON, V765, DOI 10.1016/j.scitotenv.2020.144632
   Wang GJ, 2018, J VIS COMMUN IMAGE R, V55, P404, DOI 10.1016/j.jvcir.2018.04.005
   Wang L, 2014, J VIS COMMUN IMAGE R, V25, P313, DOI 10.1016/j.jvcir.2013.11.002
   Wang X, 2017, PATTERN RECOGN, V72, P59, DOI 10.1016/j.patcog.2017.07.001
   XinWang Devinder Kumar, 2015, 2015 IEEE INT C MULT, DOI DOI 10.1109/ICMEW.2015.7169757
   Yuan Y, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108495
   Zahisham Z., 2020, 2020 IEEE 2 INT C AR, P1, DOI DOI 10.1109/IICAIET49801.2020.9257825
   Zhu FQ, 2015, IEEE J BIOMED HEALTH, V19, P377, DOI 10.1109/JBHI.2014.2304925
   Zhu YS, 2020, NEUROCOMPUTING, V379, P162, DOI 10.1016/j.neucom.2019.10.106
NR 41
TC 2
Z9 2
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10695
EP 10715
DI 10.1007/s11042-023-15800-4
EA JUN 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001019903000019
OA hybrid
DA 2024-07-18
ER

PT J
AU Long, XZ
   Du, H
   Li, Y
AF Long, Xianzhong
   Du, Han
   Li, Yun
TI Two momentum contrast in triplet for unsupervised visual representation
   learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Self-supervised learning; Contrastive learning; End-to-end; Momentum
   update; Image classification
AB In unsupervised representational learning, self-supervised learning has made great progress due to its combination with contrastive learning. The core idea of self-supervised learning is to make positive sample pairs closer and negative sample pairs far away. However, the disadvantage of such methods, such as MoCo, is that some of the positive samples can be misclassified as negative samples, which affects the learning ability of the model. To address this problem, we propose two momentum contrast in triplet (TMCT) for unsupervised visual representation learning. The method maps the obtained representations to another space and employs the samples of the third network as the target for the final learning of the model. Experimental results on three benchmark datasets demonstrate the effectiveness of our proposed method. TMCT obtains classification accuracy of 84.50% on CIFAR10, which is 2.47% higher than SimCLR.
C1 [Long, Xianzhong; Du, Han; Li, Yun] Nanjing Univ Posts & Telecommun, Nanjing 210023, Peoples R China.
C3 Nanjing University of Posts & Telecommunications
RP Long, XZ (corresponding author), Nanjing Univ Posts & Telecommun, Nanjing 210023, Peoples R China.
EM lxz@njupt.edu.cn; 1220044926@njupt.edu.cn; liyun@njupt.edu.cn
OI Long, Xianzhong/0000-0001-6281-0832
FU National Nature Science Foundation of China [619006098]
FX AcknowledgementsThis work is supported by the National Nature Science
   Foundation of China (Grant Number 619006098).
CR Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cai T., 2021, ARXIV
   Caron I., 2020, Advances in Neural Information Processing Systems, P1
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chen Ting, 2019, 25 AMERICAS C INFORM
   Chen X, 2021, AUTOPHAGY, V17, P2054, DOI 10.1080/15548627.2020.1810918
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Gidaris S., 2018, Int. Conf. on Learning Representations (ICLR), P1, DOI DOI 10.48550/ARXIV.1803.07728
   Grill J., 2020, ADV NEURAL INFORM PR, V33, P21271, DOI DOI 10.48550/ARXIV.2006.07733
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Jaiswal A, 2021, ARXIV
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Pouransari H, 2015, TINY IMAGENET VISUAL
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tian Y., 2020, NeurIPS, V33, P6827
   Wang XL, 2021, PROC CVPR IEEE, P3023, DOI 10.1109/CVPR46437.2021.00304
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
NR 23
TC 0
Z9 0
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10467
EP 10480
DI 10.1007/s11042-023-15998-3
EA JUN 2023
PG 14
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001016831200009
DA 2024-07-18
ER

PT J
AU Pandey, M
   Litoriya, R
   Pandey, P
AF Pandey, Mamta
   Litoriya, Ratnesh
   Pandey, Prateek
TI Investigating and prioritising different issues in wearable apps: An
   spherical Fuzzy-DEMATEL approach
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wearable apps; Issues; Multi-criteria decision making; Spherical
   Fuzzy-DEMATEL
ID CONFLICT; MODEL; SETS
AB The growing availability of applications (apps) for smart gadgets has been phenomenal in recent years. Both independent developers and multinational corporations are working to boost their app ratings in order to stay competitive in the mobile app industry. Therefore, it is crucial to consider apps from the perspective of the end user. In recent years, there has been a meteoric rise in the use of wearable apps. However, there have been surprisingly few investigations of the difficulties inherent with wearable apps. The purpose of this research is to mine user evaluations in order to get an understanding of consumer concerns about wearable apps. In this paper, fifteen app issues have been identified. Then we applied the DEMATEL (Decision Making Trial and Evaluation Laboratory) method to analyse the wearable app issues (WIs) and divide these issues into cause-and-effect groups. To begin, multiple experts assess the direct relationships between influential issues in wearable apps. The evaluation results are presented as spherical fuzzy numbers (SFN). Secondly, convert the linguistic terms into SFN. Thirdly, based on DEMATEL, the cause-effect classifications of issues are obtained. Finally, the issues in the cause category are identified as WIs in wearable apps. The outcome of the research is compared with the other variants of DEMATEL, like rough Z-number-based DEMATEL and spherical fuzzy DEMATEL, and the comparative results suggest that spherical fuzzy DEMATEL is the most suitable method to analyse the interrelationship of different issues in wearable apps. The outcome of this work definitely assists the app and software industry in the successful identification of the issues on which professionals and project managers could really focus.
C1 [Pandey, Mamta] Aditya Engn Coll, Kakinada, India.
   [Litoriya, Ratnesh] Med caps Univ, Indore, India.
   [Pandey, Prateek] Jaypee Univ Engn & Technol, Guna, India.
C3 Aditya Engineering College, Surampalem
RP Litoriya, R (corresponding author), Med caps Univ, Indore, India.; Pandey, P (corresponding author), Jaypee Univ Engn & Technol, Guna, India.
EM mamta.pandey07@gmail.com; litoriya.ratnesh@gmail.com;
   pandeyprat@yahoo.com
RI Pandey, Dr. Mamta/AAQ-2725-2021; Pandey, Prateek/JHU-1353-2023
OI Pandey, Prateek/0000-0001-5384-6606; Litoriya,
   Ratnesh/0000-0002-7285-422X
CR Agnew JMR, 2022, JMIR FORM RES, V6, DOI 10.2196/34339
   Ashraf S, 2019, J INTELL FUZZY SYST, V36, P6089, DOI 10.3233/JIFS-181941
   Ashraf S, 2019, J INTELL FUZZY SYST, V36, P2829, DOI 10.3233/JIFS-172009
   Baig MM, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1365-7
   Chang B, 2011, EXPERT SYST APPL, V38, P1850, DOI 10.1016/j.eswa.2010.07.114
   Chung M, 2023, MANUFACTURING SERVIC
   Dey M, 2023, HANDBOOK OF BIG DATA AND ANALYTICS IN ACCOUNTING AND AUDITING, P309, DOI 10.1007/978-981-19-4460-4_14
   Falatoonitoosi E, 2014, SCI WORLD J, DOI 10.1155/2014/103846
   Ferreira D, 2014, PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON HUMAN-COMPUTER INTERACTION WITH MOBILE DEVICES AND SERVICES (MOBILEHCI'14), P91, DOI 10.1145/2628363.2628367
   Finkelstein A, 2017, INFORM SOFTWARE TECH, V87, P119, DOI 10.1016/j.infsof.2017.03.002
   Fu B, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1276
   Gul M, 2021, SOFT COMPUT, V25, P6157, DOI 10.1007/s00500-021-05605-8
   Gül S, 2021, INT J INF TECH DECIS, V20, P1011, DOI 10.1142/S0219622021500267
   Gül S, 2020, INT J INTELL SYST, V35, P1329, DOI 10.1002/int.22255
   Gündogdu FK, 2019, J INTELL FUZZY SYST, V37, P1197, DOI 10.3233/JIFS-182651
   Ha E, 2013, 2013 IEEE CONSUMER COMMUNICATIONS AND NETWORKING CONFERENCE (CCNC), P149, DOI 10.1109/CCNC.2013.6488439
   Hafiz P, 2019, UBICOMP/ISWC'19 ADJUNCT: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING AND PROCEEDINGS OF THE 2019 ACM INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, P1162, DOI 10.1145/3341162.3347077
   Harman M., 2012, 2012 9th IEEE Working Conference on Mining Software Repositories (MSR 2012), P108, DOI 10.1109/MSR.2012.6224306
   Hoon L., 2012, AUSTR COMP HUM INT C, P245
   Hsiao KL, 2018, TELEMAT INFORM, V35, P103, DOI 10.1016/j.tele.2017.10.002
   Hua Z., 2023, APPL INTELL, V19, P1
   Iacob C, 2013, IEEE WORK CONF MIN S, P41, DOI 10.1109/MSR.2013.6624001
   Jabangwe R, 2018, J SYSTEMS SOFTWARE, V145
   Jiang W, 2017, J INTELL FUZZY SYST, V32, P1931, DOI 10.3233/JIFS-16139
   Kang Bingyi., 2012, J. Inf. Comput. Sci., V9, P703, DOI [10.51582/interconf.19-20.05.2022.045, DOI 10.51582/INTERCONF.19-20.05.2022.045]
   Khalid H, 2015, IEEE SOFTWARE, V32, P70, DOI 10.1109/MS.2014.50
   Lee HS, 2013, APPL MATH MODEL, V37, P6746, DOI 10.1016/j.apm.2013.01.016
   Li Y, 2014, APPL SOFT COMPUT, V22, P504, DOI 10.1016/j.asoc.2014.03.042
   Lin Y, 2016, J SUPERCOMPUT, V72, P2874, DOI 10.1007/s11227-016-1681-3
   Liu WR, 2006, ARTIF INTELL, V170, P909, DOI 10.1016/j.artint.2006.05.002
   Majumdar A, 2019, KSII T INTERNET INF, V13, P3794, DOI 10.3837/tiis.2019.07.025
   Masroor M, 2023, STOCH ENV RES RISK A, V37, P233, DOI 10.1007/s00477-022-02292-1
   Mohsen O, 2017, SAFETY SCI, V92, P160, DOI 10.1016/j.ssci.2016.10.006
   Mujahid Suhaib, 2017, 2017 IEEE/ACM 4th International Conference on Mobile Software Engineering and Systems (MOBILESoft). Proceedings, P96, DOI 10.1109/MOBILESoft.2017.25
   Mujahid S., 2017, THESIS MONTREAL CONC
   Mujahid S., THESIS CONCORDIA U
   Mujahid S, 2018, EMPIR SOFTW ENG, V23, P3476, DOI 10.1007/s10664-018-9615-8
   Mujahid S, 2017, ESEC/FSE 2017: PROCEEDINGS OF THE 2017 11TH JOINT MEETING ON FOUNDATIONS OF SOFTWARE ENGINEERING, P1065, DOI 10.1145/3106237.3121279
   Padgaonkar L., 2019, ENGIN TECHNOL, V8, P5806
   Palomba F, 2018, J SYST SOFTWARE, V137, P143, DOI 10.1016/j.jss.2017.11.043
   Pawlak Z., 1996, Fundamenta Informaticae, V27, P103
   Phetrungnapha K, 2019, PROCEEDINGS OF 2019 12TH INTERNATIONAL CONFERENCE ON INFORMATION & COMMUNICATION TECHNOLOGY AND SYSTEM (ICTS), P229, DOI [10.1109/icts.2019.8850962, 10.1109/ICTS.2019.8850962]
   Seker S, 2017, SUSTAINABILITY-BASEL, V9, DOI 10.3390/su9112083
   Shieh JI, KNOWL-BASED SYST, V23
   Si SL, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/3696457
   Siddiqui S, 2022, INTELL AUTOM SOFT CO, V32, P877, DOI 10.32604/iasc.2022.022266
   Singh S, 2023, INDIAN J PSYCHOL MED
   Song WY, 2017, COMPUT IND ENG, V110, P353, DOI 10.1016/j.cie.2017.06.020
   Tseng ML, 2009, EXPERT SYST APPL, V36, P7738, DOI 10.1016/j.eswa.2008.09.011
   Vasa R., 2012, AUSTR COMP HUM INT C, P241, DOI DOI 10.1145/2414536.2414577
   Vu PM, 2013, ARXIV
   Wang WC, 2012, EXPERT SYST APPL, V39, P4978, DOI 10.1016/j.eswa.2011.10.016
   Wang ZX, 2023, IEEE T CONTROL NETW, V10, P1603, DOI [10.1109/TCNS.2023.3235425, 10.1109/ICASSP49357.2023.10094992]
   Welinder Yana., 2013, Santa Clara High Tech. L.J, V30, P89
   Wentzel J, 2016, P 13 WEB ALL C, P1
   Widyassari A.P., 2020, J KING SAUD UNIV-COM
   Wu M., 2019, Online J. Nurs. Inform., V23
   Ho XH, 2022, J RETAIL CONSUM SERV, V66, DOI 10.1016/j.jretconser.2022.102950
   Yazdi M, 2020, SAFETY SCI, V127, DOI 10.1016/j.ssci.2020.104705
   Yüksel S, 2022, INT J ENERG RES, V46, P10796, DOI 10.1002/er.7880
   Zhang L, 2017, J COMPUT SCI TECH-CH, V32, P1076, DOI 10.1007/s11390-017-1784-1
   Zhang T, 2021, IEEE T SOFTWARE ENG, V47, P2590, DOI 10.1109/TSE.2019.2956941
   Zhang W, 2019, SOFT COMPUT, V23
   Zhou Q, 2011, SAFETY SCI, V49, P243, DOI 10.1016/j.ssci.2010.08.005
   Zhu GN, 2021, INT J INTELL SYST, V36, P3645, DOI 10.1002/int.22431
NR 65
TC 3
Z9 3
U1 3
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 4
BP 10061
EP 10090
DI 10.1007/s11042-023-15874-0
EA JUN 2023
PG 30
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA EM0G5
UT WOS:001015589400011
DA 2024-07-18
ER

PT J
AU Hsieh, YZ
   Ku, XL
   Lin, SS
AF Hsieh, Yi-Zeng
   Ku, Xiang-Long
   Lin, Shih-Syun
TI The development of assisted- visually impaired people robot in the
   indoor environment based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep learning; Convolutional neural network; Indoor positioning;
   Visually impaired people
ID TOUCH-SCREEN
AB The indoor positioning for visually impaired people has influence on their daily life in unknown indoor environment. This study designs the robot that can assist the blind walking safety and navigate in indoor environment by a single camera. The sense classification is proposed to position the blind in indoor environment by proposed convolutional neural network framework and integrate the semantic segmentation to find the road surface through a depth camera to guide the blind walking. The proposed vision-based sense classification method is compared with the traditional WiFi triangular-positioning method, and the average error of x-y coordinate position result as (9.25,3.65) is better. From the experiment, the designed robot can help the visually impaired people to indoor navigation in unknown indoor environment.
C1 [Hsieh, Yi-Zeng; Ku, Xiang-Long] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei City 106, Taiwan.
   [Lin, Shih-Syun] Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung City, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   Ocean University
RP Lin, SS (corresponding author), Natl Taiwan Ocean Univ, Dept Comp Sci & Engn, Keelung City, Taiwan.
EM linss@mail.ntou.edu.tw
FU Ministry of Science and Technology, Taiwan [MOST 110-2221-E-019 -051 -,
   MOST 109-2221-E-019 -057, MOST 110-2634-F-019 -001, MOST 110-2634-F-008
   -005]
FX This paper was partly supported by Ministry of Science and Technology,
   Taiwan, under MOST 110-2221-E-019 -051 -, 109-2221-E-019 -057 -,
   110-2634-F-019 -001 - and 110-2634-F-008 -005 -.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bharathi S., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P956, DOI 10.1109/ICCEET.2012.6203916
   Bourbakis N, 2005, BIBE 2005: 5TH IEEE SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, P222
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   COCO, About us
   Costilla-Reyes O, 2014, INT C INDOOR POSIT, P271, DOI 10.1109/IPIN.2014.7275493
   Dakopoulos D, 2007, PROCEEDINGS OF THE 7TH IEEE INTERNATIONAL SYMPOSIUM ON BIOINFORMATICS AND BIOENGINEERING, VOLS I AND II, P930
   Dos Santos ADP, 2021, IEEE ACCESS, V9, P162306, DOI 10.1109/ACCESS.2021.3132887
   Du Y, 2020, ARXIV, DOI DOI 10.48550/ARXIV.1812.02224
   El Lahib M, 2018, INT J HUM-COMPUT ST, V112, P16, DOI 10.1016/j.ijhcs.2018.01.005
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   groups csail mit edu, ADE20K
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Hayat S, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC), P194, DOI 10.1109/ICIVC.2018.8492777
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hsieh YZ, 2020, MULTIMED TOOLS APPL, V79, P29473, DOI 10.1007/s11042-020-09464-7
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kalmegh Sonali K., 2010, 2010 International Conference on Emerging Trends in Robotics and Communication Technologies (INTERACT 2010), P8, DOI 10.1109/INTERACT.2010.5706156
   Kumar N, 2016, IEEE INT CONF INTELL, P219, DOI 10.1109/INES.2016.7555123
   Lee N, 2017, INT C INDOOR POSIT
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sokic E, 2015, PROCEEDINGS OF ELMAR-2015 57TH INTERNATIONAL SYMPOSIUM ELMAR-2015, P141, DOI 10.1109/ELMAR.2015.7334516
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Swaminathan R, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P921, DOI 10.1109/ICME.2008.4607586
   Tekli J, 2018, INT J HUM-COMPUT ST, V110, P115, DOI 10.1016/j.ijhcs.2017.10.009
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Yubin Xu, 2010, Proceedings of the 2010 Fourth International Conference on Genetic and Evolutionary Computing (ICGEC 2010), P134, DOI 10.1109/ICGEC.2010.41
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 33
TC 0
Z9 0
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 6555
EP 6578
DI 10.1007/s11042-023-15644-y
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001006598900011
DA 2024-07-18
ER

PT J
AU Kumar, V
   Sharma, S
AF Kumar, Vijay
   Sharma, Sahil
TI Steganography-based facial re-enactment using generative adversarial
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Steganography; Deep learning; Cover image; Secret image; Container
   image; Steganalysis; Information hiding; Facial motion; Facial
   re-enactment; Facial synthesis; Face swapping
AB This paper presents a technique for hiding secret messages in images while transferring them over a network using steganography. The preprocessed standard datasets create steganographic datasets for facial re-enactment purposes. The facial re-enactment GAN (FRe-GAN) technique and qualitative and quantitative results have been presented over various datasets. A comparative study has been conducted that showcase the drawbacks of existing literature and motivated their work. We propose a steganography-based GAN model and used benchmark datasets such as Flickr-Faces-HQ (FFHQ), IMPA-FACE3D, FaceForensics++, and CelebFaces Attributes (CelebA) facial datasets in the experimentation. We have derived a Generative Adversarial Networks-based approach to face re-synthesis and re-enactment that adjusts for facial expressions and pose. The face blending network is used to blend two faces seamlessly. We have compared the proposed approach with existing state-of-the-art systems and show that our method achieves qualitatively and quantitatively better results.
C1 [Kumar, Vijay] Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, Punjab, India.
   [Sharma, Sahil] Punjab Engn Coll, Comp Sci & Engn Dept, Chandigarh, India.
C3 National Institute of Technology (NIT System); Dr B R Ambedkar National
   Institute of Technology Jalandhar; Punjab Engineering College (Deemed
   University)
RP Kumar, V (corresponding author), Dr BR Ambedkar Natl Inst Technol, Dept Informat Technol, Jalandhar, Punjab, India.
EM vijaykumarchahar@gmail.com; sahil301290@gmail.com
RI Sharma, Sahil/AAE-2833-2022; Sharma, Sahil/JXM-8658-2024; Chahar, Vijay
   Kumar/A-2782-2015
OI Sharma, Sahil/0000-0002-3187-4929; Chahar, Vijay
   Kumar/0000-0002-3460-6989
CR Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   [Anonymous], 2019, HDB RES DEEP LEARNIN
   Boroumand M, 2019, IEEE T INF FOREN SEC, V14, P1181, DOI 10.1109/TIFS.2018.2871749
   Bounareli S., 2022, ARXIV
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Ciftci Umur Aybars, 2020, IEEE Trans Pattern Anal Mach Intell, VPP, DOI 10.1109/TPAMI.2020.3009287
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duan J, 2022, SPIE, V12287, P345
   figshare, TNO IM FUS DAT
   github, NVLABS FFHQ DAT FLIC
   Hao H., 2020, ARXIV
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hiwe S., 2014, INT J ENG RES TECHNO, V3, P2155
   Hu C, 2023, IMAGE VISION COMPUT, V130, DOI 10.1016/j.imavis.2022.104611
   Kae A, 2013, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2013.263
   kaggle, STREET VIEW HOUS NUM
   Kamal S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10122001
   Kerry CF, 2018, NEW YORK TIMES
   Korshunov P., 2018, arXiv
   Kowalski M., GITHUB
   Kumar V, 2023, INT J DIGIT CRIME FO, V15, DOI 10.4018/IJDCF.318666
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li YZ, 2020, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR42600.2020.00327
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Z., 2018, LARGE SCALE CELEBFAC, V15, P2018
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Nirkin Y, 2023, IEEE T PATTERN ANAL, V45, P560, DOI 10.1109/TPAMI.2022.3155571
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   paperswithcode, FAC REEN PAP COD
   Patil K, 2023, ARXIV
   Ramaneti K, 2021, COMPUTER INFORM SCI, P169
   Rao YJ, 2023, INFORM FUSION, V92, P336, DOI 10.1016/j.inffus.2022.12.007
   Rosberg F, 2022, P IEEE CVF WINT C AP, P3454
   Rossi A, 2020, IEEE T INTELL TRANSP, V21, P2980, DOI 10.1109/TITS.2019.2922002
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P26517, DOI 10.1007/s11042-020-09331-5
   Sharma S, 2020, MULTIMED TOOLS APPL, V79, P17303, DOI 10.1007/s11042-020-08688-x
   Shi W., 2022, ACM T MULTIM COMPUT, V18, P1
   Shu ZX, 2017, PROC CVPR IEEE, P5444, DOI 10.1109/CVPR.2017.578
   Singh B, 2022, MULTIMED TOOLS APPL, V81, P40511, DOI 10.1007/s11042-022-13172-9
   Singla S, 2021, ARXIV
   Svanera M, 2016, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2016.7532494
   Teng Zhang, 2020, 2020 IEEE 3rd International Conference on Computer and Communication Engineering Technology (CCET), P67, DOI 10.1109/CCET50901.2020.9213159
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Tripathy S, 2021, IEEE WINT CONF APPL, P1328, DOI 10.1109/WACV48630.2021.00137
   Tripathy S, 2020, IEEE WINT CONF APPL, P3374, DOI [10.1109/wacv45572.2020.9093474, 10.1109/WACV45572.2020.9093474]
   us, TRUE COLOR KODAK IMA
   visgraf, FAC FAC
   Wang D, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24060749
   Weber A. G., 1997, USC-SIPI Report, V315
   Wei P, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P1621, DOI 10.1145/3503161.3548217
   Wu P, 2018, FUTURE INTERNET, V10, DOI 10.3390/fi10060054
   Wu XT, 2021, IEEE T IMAGE PROCESS, V30, P8658, DOI 10.1109/TIP.2021.3112059
   Yang Y, 2023, INFORM SCIENCES, V629, P566, DOI 10.1016/j.ins.2023.02.013
   Yu F, 2016, ARXIV, DOI DOI 10.48550/ARXIV.1506.03365
   Zhang Kevin, 2019, ARXIV
   Zhao Y., 2023, P IEEE CVF WINT C AP, P4602
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 59
TC 0
Z9 0
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7609
EP 7630
DI 10.1007/s11042-023-15946-1
EA JUN 2023
PG 22
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001005496300001
DA 2024-07-18
ER

PT J
AU Gupta, H
   Singh, H
   Kumar, A
   Vishwakarma, A
   Singh, GK
AF Gupta, Himanshu
   Singh, Himanshu
   Kumar, Anil
   Vishwakarma, Amit
   Singh, Girish Kumar
TI Variational mode decomposition based image denoising using semi-adaptive
   conductance function inspired diffusion filtering
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Variational mode decomposition; Anisotropic diffusion filter; Wiener
   filter; Bilateral filter; Image denoising; Intrinsic mode functions
ID IMPULSE NOISE; MEDIAN FILTER; PEPPER NOISE; ANISOTROPIC DIFFUSION;
   REMOVAL
AB In day-to-day life, images are the most frequent and casual way of information sharing. These images are susceptible to external disturbances or noise. Thus, to curb noise, image denoising algorithms are utilized. In this paper, the variational mode decomposition, with its concurrent and a non-recursive process for determining the mode functions that also provides a robust method for image denoising, has been introduced. This decomposition process divides the whole spectrum of the signal into a number of sub-bands or mode functions, centered around their respective center frequencies. To these mode functions, spatial filters such as bilateral filter, wiener filter, and modified anisotropic diffusion filter are employed. These filters help in enhancing the yield of the quality assessment metrics; such as mean square error (MSE), peak signal-to-noise ratio (PSNR), and structural similarity index (SSIM), together with the semi-adaptive conductance function in the diffusion filter. The parameters of these respective spatial filters are calibrated, and then selected in order to get the best possible metric scores. The applicability and ability of the algorithm to suppress noise are compared visually and quantitatively for the noisy image using modified variational mode decomposition and other denoising algorithms in both low and high noise levels. The algorithm provides an average decrease of 62% in case of MSE, 28% increase in PSNR, and 110% increase in SSIM when compared with other denoising techniques. The estimated metric score values signify that the proposed method has a better prospect as a denoising algorithm.
C1 [Gupta, Himanshu; Kumar, Anil; Vishwakarma, Amit] Indian Inst Informat Technol Design & Mfg, Dept Elect & Commun Engn, Jabalpur 482005, India.
   [Singh, Himanshu] Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Surathkal 575025, Karnataka, India.
   [Singh, Girish Kumar] Indian Inst Technol Roorkee, Dept Elect Engn, Roorkee 247667, Uttrakhand, India.
C3 Indian Institute of Information Technology Design & Manufacturing,
   Jabalpur; National Institute of Technology (NIT System); National
   Institute of Technology Karnataka; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Roorkee
RP Gupta, H (corresponding author), Indian Inst Informat Technol Design & Mfg, Dept Elect & Commun Engn, Jabalpur 482005, India.
EM himanshu.gupta.signal@gmail.com; himanshu.iiitj@gmail.com;
   anilkdee@gmail.com; amitv@iiitdmj.ac.in; gksngfee@gmail.com
RI Kumar, Anil/Q-6680-2016; Vishwakarma, Amit/ABE-7268-2020; SINGH,
   HIMANSHU/AAT-6317-2020
OI Kumar, Anil/0000-0002-3945-4646; Vishwakarma, Amit/0000-0002-0591-8940;
   SINGH, HIMANSHU/0000-0002-0410-0602; Gupta, Himanshu/0000-0002-0187-0433
CR [Anonymous], 2000, Digital Image Processing: A Practical Introduction Using Java (with CD-ROM)
   Armato SG, 2011, MED PHYS, V38, P915, DOI 10.1118/1.3528204
   Ben Hamza A, 2001, IEEE T SIGNAL PROCES, V49, P3045, DOI 10.1109/78.969512
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Egiazarian K, 1999, J ELECTRON IMAGING, V8, P233, DOI 10.1117/1.482673
   Eskicioglu A., 1993, SPACE EARTH SCI DATA, P49
   FLORENCIO DAF, 1994, P SOC PHOTO-OPT INS, V2308, P268, DOI 10.1117/12.185969
   Gilboa G, 2006, IEEE T IMAGE PROCESS, V15, P2269, DOI 10.1109/TIP.2006.875248
   Gonzalez R.C., 2002, Digital Image Processing, V2nd
   Gupta H, 2022, MULTIDIM SYST SIGN P, P1, DOI [10.1007/S11045-022-00850-Y/FIGURES/26, DOI 10.1007/S11045-022-00850-Y/FIGURES/26]
   Han DR, 2012, J OPTIMIZ THEORY APP, V155, P227, DOI 10.1007/s10957-012-0003-z
   Healey G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P90, DOI 10.1109/CVPR.1992.223222
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Ibrahim H, 2008, IEEE T CONSUM ELECTR, V54, P1920, DOI 10.1109/TCE.2008.4711254
   Kommuri SVR, 2020, CIRC SYST SIGNAL PR, V39, P5127, DOI 10.1007/s00034-020-01404-y
   Kumar M, 2021, MULTIMED TOOLS APPL, V80, P11331, DOI 10.1007/s11042-020-10189-w
   Lian JJ, 2018, MECH SYST SIGNAL PR, V107, P53, DOI 10.1016/j.ymssp.2018.01.019
   Liu K, 2023, MULTIMED TOOLS APPL, V82, P927, DOI 10.1007/s11042-022-12393-2
   Luo WB, 2006, IEEE T CONSUM ELECTR, V52, P523, DOI 10.1109/TCE.2006.1649674
   Mafi M, 2019, SIGNAL PROCESS, V157, P236, DOI 10.1016/j.sigpro.2018.12.006
   Mohanty Satish, 2014, 2014 9th International Conference on Industrial and Information Systems (ICIIS), P1, DOI 10.1109/ICIINFS.2014.7036515
   Pathak M., 2014, IOSR J ELECT COMMUN, V9, P27, DOI [10.9790/2834-09412736, DOI 10.9790/2834-09412736]
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Nguyen P, 2015, EXPERT SYST APPL, V42, P9024, DOI 10.1016/j.eswa.2015.07.064
   Regularization D, COMPUTE, P1
   Singh H, 2023, MULTIMED TOOLS APPL, V82, P1593, DOI 10.1007/s11042-022-13265-5
   Singh H, 2022, IEEE T SYST MAN CY-S, V52, P2275, DOI 10.1109/TSMC.2021.3049402
   Singh H, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114884
   Singh I., 2014, INT J COMPUTER APPL, V96, P21, DOI 10.5120/16903-6969
   Srinivasan KS, 2007, IEEE SIGNAL PROC LET, V14, P189, DOI 10.1109/LSP.2006.884018
   Toh KKV, 2010, IEEE SIGNAL PROC LET, V17, P281, DOI 10.1109/LSP.2009.2038769
   Toh KKV, 2008, IEEE T CONSUM ELECTR, V54, P1956, DOI 10.1109/TCE.2008.4711258
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tsiotsios C, 2013, PATTERN RECOGN, V46, P1369, DOI 10.1016/j.patcog.2012.11.012
   Varma Dandu Ravi, 2012, Indian J Radiol Imaging, V22, P4, DOI 10.4103/0971-3026.95396
   Vasanth K, 2015, SIGNAL IMAGE VIDEO P, V9, P1833, DOI 10.1007/s11760-014-0665-0
   Veerakumar T, 2019, EXPERT SYST APPL, V121, P18, DOI 10.1016/j.eswa.2018.12.009
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu JT, 2016, SIGNAL PROCESS, V119, P80, DOI 10.1016/j.sigpro.2015.07.017
   Xue YJ, 2016, IEEE J-STARS, V9, P3821, DOI 10.1109/JSTARS.2016.2529702
   Zhang PX, 2014, IEEE SIGNAL PROC LET, V21, P1280, DOI 10.1109/LSP.2014.2333012
NR 41
TC 0
Z9 0
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JAN
PY 2024
VL 83
IS 3
BP 7433
EP 7456
DI 10.1007/s11042-023-15863-3
EA JUN 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA GY5L7
UT WOS:001003484200003
DA 2024-07-18
ER

PT J
AU Gong, WY
   Fan, XQ
AF Gong, Wenyong
   Fan, Xu-Qian
TI Image adaptive sampling using reinforcement learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image adaptive sampling; Reinforcement learning; Delaunay triangulation;
   Multi-armed bandits
ID ALGORITHM; REPRESENTATION; APPROXIMATION; SEGMENTATION
AB Adaptive sampling and mesh representation of images play an important role in image compression and vectorization. In this paper, a multi-points stochastic gradient multi-armed bandits algorithm, a generalization of the gradient bandit algorithm, is presented to adaptively sample points in images. By modeling the adaptive image sampling as a multi-arm selection decision-making problem, we first propose an efficient action selection strategy based on a parameterized probability distribution, and then define an adaptive reward function according to the restored image of Delaunay triangulation and a feature map function, and the reward function can overcome the sparse reward issue effectively. As a result, the proposed multi-points stochastic gradient multi-armed bandits algorithm is used to evaluate the reward of each action. At last, a prescribed number of sampling points are selected using a simple and effective strategy according to the average reward of each pixel. The quality of reconstructed images based on sampled points is estimated, and experimental results demonstrate the proposed algorithm achieves a better reconstruction accuracy than that of existing methods.
C1 [Gong, Wenyong; Fan, Xu-Qian] Jinan Univ, Dept Math, Guangzhou, Peoples R China.
C3 Jinan University
RP Fan, XQ (corresponding author), Jinan Univ, Dept Math, Guangzhou, Peoples R China.
EM txqfan@jnu.edu.cn
FU Natural Science Foundation (NSF) of China [61802147]; Guangdong Basic
   and Applied Basic Research Foundation [2022A1515011538, 2022A1515012122]
FX AcknowledgmentsThis work was supported by the Natural Science Foundation
   (NSF) of China (No. 61802147), and the Guangdong Basic and Applied Basic
   Research Foundation (No. 2022A1515011538 and 2022A1515012122). Authors
   would like to thank the anonymous referees for their useful comments,
   which were of great help in improving the exposition and readability of
   this paper.
CR Abramenko O, 2019, INT CONF ACOUST SPEE, P3077, DOI 10.1109/ICASSP.2019.8683181
   Adams MD, 2011, IEEE T IMAGE PROCESS, V20, P2414, DOI 10.1109/TIP.2011.2128336
   Adams MD, 2008, IEEE SIGNAL PROC LET, V15, P629, DOI 10.1109/LSP.2008.2004516
   Ahmed AGM, 2017, IEEE T VIS COMPUT GR, V23, P2496, DOI 10.1109/TVCG.2016.2641963
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barr I, 2017, IMAGES TRIANGLES
   Battiato S., 2004, P 20 SPRING C COMP G, P185
   Brankov JG, 2004, IEEE T MED IMAGING, V23, P202, DOI 10.1109/TMI.2003.822822
   Brankov JG, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P997
   Chowdhary CL, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185162
   da Silva ES, 2018, IMAGE ANAL STEREOL, V37, P71, DOI 10.5566/ias.1591
   Dai QQ, 2020, IEEE T MULTIMEDIA, V22, P2564, DOI 10.1109/TMM.2019.2958760
   de Goes F, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366190
   Eldar Y, 1997, IEEE T IMAGE PROCESS, V6, P1305, DOI 10.1109/83.623193
   Fakhari A, 2021, MULTIMED TOOLS APPL, V80, P2047, DOI 10.1007/s11042-020-09685-w
   Fattal R, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964943
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FLOYD RW, 1976, P SID, V17, P75
   Garcia M. A., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P168, DOI 10.1109/ICIP.1999.821588
   Gevers T, 1997, PROC CVPR IEEE, P1021, DOI 10.1109/CVPR.1997.609455
   Grogan S, 2017, BODY IMAGE: UNDERSTANDING BODY DISSATISFACTION IN MEN, WOMEN AND CHILDREN, 3RD EDITION, P1
   Gu K, 2021, IEEE T NEUR NET LEAR, V32, P4278, DOI 10.1109/TNNLS.2021.3105394
   Gu K, 2021, IEEE T IND INFORM, V17, P2261, DOI 10.1109/TII.2020.2991208
   Gu K, 2020, IEEE T INSTRUM MEAS, V69, P660, DOI 10.1109/TIM.2019.2905904
   Gu K, 2020, IEEE T MULTIMEDIA, V22, P311, DOI 10.1109/TMM.2019.2929009
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hussain R, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13234941
   KO KI, 1982, INFORM CONTROL, V53, P21, DOI 10.1016/S0019-9958(82)91083-X
   Kohout J, 2007, LECT NOTES COMPUT SC, V4872, P826
   Kreylos O, 2001, IEEE T VIS COMPUT GR, V7, P17, DOI 10.1109/2945.910818
   Lawonn K, 2019, COMPUT GRAPH FORUM, V38, P221, DOI 10.1111/cgf.13526
   Li J, 2020, INFORM SCIENCES, V526, P166, DOI 10.1016/j.ins.2020.03.041
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Mark B., 2008, COMPUTATIONAL GEOMET
   Menandro FCM, 2019, ENG REP, V1, DOI 10.1002/eng2.12028
   Mnih V, 2013, Arxiv, DOI [arXiv:1312.5602, 10.48550/arxiv.1312.5602]
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Petrou M, 2006, COMPUT VIS IMAGE UND, V102, P95, DOI 10.1016/j.cviu.2005.11.003
   Picard D, 2012, INFORM SCIENCES, V192, P71, DOI 10.1016/j.ins.2010.03.003
   Prasad L, 2006, PATTERN RECOGN, V39, P501, DOI 10.1016/j.patcog.2005.10.014
   Rajesh S, 2007, 2007 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, PROCEEDINGS, VOLS 1-8, P1645, DOI 10.1109/ISIE.2007.4374851
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rila L, 1998, SIBGRAPI '98 - INTERNATIONAL SYMPOSIUM ON COMPUTER GRAPHICS, IMAGE PROCESSING, AND VISION, PROCEEDINGS, P167, DOI 10.1109/SIBGRA.1998.722747
   Robinson JA, 1997, IEEE T IMAGE PROCESS, V6, P601, DOI 10.1109/83.563325
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sarkis M, 2009, IEEE T IMAGE PROCESS, V18, P1069, DOI 10.1109/TIP.2009.2016148
   Scholefield A, 2014, IEEE T IMAGE PROCESS, V23, P1226, DOI 10.1109/TIP.2014.2300817
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Skala Vaclav, 2011, WSEAS Transactions on Computers, V10, P367
   Srinivasu PN, 2021, PEERJ COMPUT SCI, V7, DOI 10.7717/peerj-cs.654
   Srinivasu PN, 2021, J REAL-TIME IMAGE PR, V18, P1773, DOI 10.1007/s11554-021-01122-x
   Su D, 2004, COMPUT GRAPH FORUM, V23, P189, DOI 10.1111/j.1467-8659.2004.00752.x
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tamang J, 2021, IEEE ACCESS, V9, P18762, DOI 10.1109/ACCESS.2021.3054250
   Viola P., 2001, P IEEE COMP SOC C CO, P1
   Wang K, 2001, INT J GEOGR INF SCI, V15, P743, DOI 10.1080/13658810110074492
   Wang K, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 1, P70, DOI 10.5220/0006097700700081
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu WZ, 2014, GISCI REMOTE SENS, V51, P537, DOI 10.1080/15481603.2014.946666
   Wu YJ, 2023, MAR GEORESOUR GEOTEC, V41, P24, DOI 10.1080/1064119X.2021.2009070
   Yang YY, 2003, IEEE T IMAGE PROCESS, V12, P866, DOI 10.1109/TIP.2003.812757
   Ye ZP, 2020, COMPUT AIDED DESIGN, V126, DOI 10.1016/j.cad.2020.102851
   Yu XH, 2001, IEEE COMPUT GRAPH, V21, P62, DOI 10.1109/38.920628
   Zapletal J., 2009, P 2009 COMPUTER GRAP, P39, DOI [10.1145/1629739.1629744, DOI 10.1145/1629739.1629744]
NR 65
TC 0
Z9 0
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 3
PY 2023
DI 10.1007/s11042-023-15558-9
EA JUN 2023
PG 20
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0SS7
UT WOS:000999967700003
DA 2024-07-18
ER

PT J
AU Lal, S
AF Lal, Shyam
TI TC-SegNet: robust deep learning network for fully automatic two-chamber
   segmentation of two-dimensional echocardiography
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Atrous Spatial Pyramid Pooling (ASPP); Cardiac segmentation; Deep
   learning; Echocardiography; Left atrium; Left ventricle; Myocardium;
   Residual path connections; Squeeze and Excitation
AB Heart chamber quantification is an essential clinical task to analyze heart abnormalities by evaluating the heart volume estimated through the endocardial border of the chambers. A precise heart chamber segmentation algorithm using echocardiography is essential for improving the diagnosis of cardiac disease. This paper proposes a robust two chamber segmentation network (TC-SegNet) for echocardiography which follows a U-Net architecture and effectively incorporates the proposed modified skip connection, Atrous Spatial Pyramid Pooling (ASPP) modules and squeeze and excitation modules. The TC-SegNet is evaluated on the open-source fully annotated dataset of cardiac acquisitions for multi-structure ultrasound segmentation (CAMUS). The proposed TC-SegNet obtained an average value of F1-score of 0.91, an average Dice score of 0.9284 and an IoU score of 0.8322 which are higher than the reference models used here for comparison. Further, Pixel error (PE) of 1.5109 which are significantly less than the comparison models. The segmentation results and metrics show that the proposed model outperforms the state-of-the-art segmentation methods.
C1 [Lal, Shyam] Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Mangaluru 575025, Karnataka, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Karnataka
RP Lal, S (corresponding author), Natl Inst Technol Karnataka, Dept Elect & Commun Engn, Mangaluru 575025, Karnataka, India.
EM shyam.mtec@gmail.com
OI Lal, Dr. Shyam/0000-0002-4355-6354
CR Barbosa D., 2014, MIDAS J, V10, P17
   Bernier M., 2014, PROC MICCAI CHALLENG
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XY, 2019, I S BIOMED IMAGING, P430, DOI [10.1109/isbi.2019.8759555, 10.1109/ISBI.2019.8759555]
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hu J., 2018, PROC IEEECVF C COMPU, P7132, DOI DOI 10.1109/CVPR.2018.00745
   Ibtehaz N, 2020, NEURAL NETWORKS, V121, P74, DOI 10.1016/j.neunet.2019.08.025
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kim T, 2021, QUANT IMAG MED SURG, V11, P1763, DOI 10.21037/qims-20-745
   Lang RM, 2012, J AM SOC ECHOCARDIOG, V25, P3, DOI 10.1016/j.echo.2011.11.010
   Leclerc S, 2019, IEEE T MED IMAGING, V38, P2198, DOI 10.1109/TMI.2019.2900516
   Lei T., 2020, Medical Image Segmentation Using Deep Learning: A Survey
   Liu F, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101873
   Mulliqi N, 2020, IMPORTANCE SKIP CONN
   Nakphu N, 2014, 2014 IEEE CONFERENCE ON BIOMEDICAL ENGINEERING AND SCIENCES (IECBES), P644, DOI 10.1109/IECBES.2014.7047583
   Oktay O., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.03999
   Oktay O, 2014, MIDAS J CHALLENGE EN, V10
   Oktay O, 2018, IEEE T MED IMAGING, V37, P384, DOI 10.1109/TMI.2017.2743464
   Pinto A, 2013, CRIT ULTRASOUND J, V5, DOI 10.1186/2036-7902-5-S1-S1
   Robinson K, 2004, PATTERN RECOGN LETT, V25, P1759, DOI 10.1016/j.patrec.2004.07.002
   Ronneberger O., 2015, 2015 INT C MED IM CO, P234
   Seo H, 2020, IEEE T MED IMAGING, V39, P1316, DOI 10.1109/TMI.2019.2948320
   Sharma AK, 2022, IEEE ACCESS, V10, P17920, DOI 10.1109/ACCESS.2022.3149824
   Smistad Erik, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092812
   Smistad E, 2014, REAL TIME TRACKING L
   Suresh S, 2017, IEEE J-STARS, V10, P5245, DOI 10.1109/JSTARS.2017.2755068
   van Stralen M., 2014, MIDAS, P73
   Verma SS, 2022, COVXMLC HIGH PERFORM, V71
   Wan T, 2020, NEUROCOMPUTING, V408
   Wang C, 2014, MODEL BASED LEFT VEN, V10, P81
   Wang W, 2019, IEEE I CONF COMP VIS, P2142, DOI 10.1109/ICCV.2019.00223
   Yang JB, 2022, COMPUT MATH APPL, V107, P29, DOI 10.1016/j.camwa.2021.12.005
   Yang Y, 2021, SHAPE CONSTRAINTS DE
   Yodwut C, 2012, J AM SOC ECHOCARDIOG, V25, P978, DOI 10.1016/j.echo.2012.06.001
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou SH, 2020, IEEE T IMAGE PROCESS, V29, P461, DOI 10.1109/TIP.2019.2919937
   Zhou Z., 2020, IEEE T MED IMAGING, V39, P1856, DOI [10.1109/TMI.2019.2959609, DOI 10.1109/TMI.2019.2959609]
NR 42
TC 1
Z9 1
U1 4
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JUN 3
PY 2023
DI 10.1007/s11042-023-15524-5
EA JUN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0SS7
UT WOS:000999967700005
PM 37362663
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Tang, CR
   Xue, DY
   Chen, DY
AF Tang, Chunren
   Xue, Dingyu
   Chen, Dongyue
TI Feature diversity learning with sample dropout for unsupervised domain
   adaptive person re-identification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Unsupervised domain adaptation; Person re-identification; Cross domain;
   Feature learning
AB Clustering-based approach has proved effective in dealing with unsupervised domain adaptive person re-identification (ReID) tasks. However, existing works along this approach still suffer from noisy pseudo labels and the unreliable representation ability during the whole training process. In order to solve these problems, in this paper, we propose a new approach to learn the feature representation with better generalization ability through limiting noisy pseudo labels. At first, we propose a Sample Dropout (SD) method to prevent the training of the model from falling into the vicious circle caused by samples that are frequently assigned with noisy pseudo labels, our method can correct the noisy labels and boost the representation ability. In addition, we put forward a new method referred as to Feature Diversity Learning (FDL) under the classic mutual-teaching architecture, which can significantly improve the generalization ability of the feature representation on the target domain in an unsupervised fashion. Experimental results show that our proposed FDL-SD achieves the state-of-the-art performance on multiple well-known benchmark datasets.
C1 [Tang, Chunren; Xue, Dingyu; Chen, Dongyue] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
   [Chen, Dongyue] Northeastern Univ, Foshan Grad Sch Innovat, Foshan 528311, Guangdong, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Chen, DY (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.; Chen, DY (corresponding author), Northeastern Univ, Foshan Grad Sch Innovat, Foshan 528311, Guangdong, Peoples R China.
EM 1910316@stu.neu.edu.cn
FU Fundamental Research Funds for the Central Universities [N2104027];
   Innovation Fund of Chinese Universities Industry University Research
   [2020HYA06003]; Guangdong Basic and Applied Basic Research Foundation
   [2021B1515120064]
FX This work was supported in part by The Fundamental Research Funds for
   the Central Universities (N2104027), Innovation Fund of Chinese
   Universities Industry University Research (2020HYA06003) and Guangdong
   Basic and Applied Basic Research Foundation (2021B1515120064).
CR Aggarwal A.K., 2022, Int J Biol Biomed, V7
   Ahuja U, 2023, MULTIMED TOOLS APPL, V82, P7553, DOI 10.1007/s11042-022-13718-x
   Backlund H., 2011, DATA MINING TNM033, V033, P11
   Bai ZC, 2021, PROC CVPR IEEE, P12909, DOI 10.1109/CVPR46437.2021.01272
   Bansal M, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03488-z
   Bansal M, 2021, MULTIMED TOOLS APPL, V80, P18839, DOI 10.1007/s11042-021-10646-0
   Behera N, 2020, PATTERN RECOGN LETT, V138
   CHEN T, 2020, INT C MACH LEARN, P1597, DOI DOI 10.48550/ARXIV.2002.05709
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Cheng H, 2021, Arxiv, DOI arXiv:2010.02347
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Fekri-Ershad S, 2021, MULTIMED TOOLS APPL, V80, P12103, DOI 10.1007/s11042-020-10321-w
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Ge Y., 2020, ADV NEURAL INFORM PR
   Ge Yixiao, 2020, ARXIV200101526
   Ghosh A, 2017, AAAI CONF ARTIF INTE, P1919
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   Han B, 2018, Arxiv, DOI arXiv:1804.06872
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang Yangru, 2020, AAAI
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Kaur A, 2022, IEEE ACM T COMPUTATI
   Kumar A, 2021, MULTIMED TOOLS APPL, V80, P14565, DOI 10.1007/s11042-020-10457-9
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Li HF, 2022, KNOWL-BASED SYST, V251, DOI 10.1016/j.knosys.2022.109315
   Li JN, 2022, IEEE T PATTERN ANAL, V44, P622, DOI 10.1109/TPAMI.2019.2929036
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Liu JW, 2019, PROC CVPR IEEE, P7195, DOI 10.1109/CVPR.2019.00737
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shaheed K, 2022, EXPERT SYST APPL, V191, DOI 10.1016/j.eswa.2021.116288
   Shan L., 2018, BMVC 2018
   Shu J, 2019, Arxiv, DOI arXiv:1902.07379
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Ubhi JS, 2022, J VIS COMMUN IMAGE R, V85, DOI 10.1016/j.jvcir.2022.103483
   Vahdat A, 2017, Arxiv, DOI arXiv:1706.00038
   Walia S, 2023, MULTIMED TOOLS APPL, V82, P4517, DOI 10.1007/s11042-022-13610-8
   Wang GQ, 2020, PROC CVPR IEEE, P6677, DOI 10.1109/CVPR42600.2020.00671
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xi JL, 2022, NEUROCOMPUTING, V483, P116, DOI 10.1016/j.neucom.2022.01.013
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Yan C, 2022, IEEE T MULTIMEDIA, V24, P1665, DOI 10.1109/TMM.2021.3069562
   Yang Zou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P87, DOI 10.1007/978-3-030-58536-5_6
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Zhai Y, 2020, COMPUTER VISION ECCV, P594, DOI DOI 10.1007/978-3-030-58571-6_35
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zheng DY, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108941
   Zheng DY, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108615
   Zheng K, 2021, AAAI 2021
   Zheng K., 2021, P IEEE CVF C COMP VI, P5310
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou H, 2023, INT J MACH LEARN CYB, V14, P1951, DOI 10.1007/s13042-022-01739-9
   Zilong Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P20, DOI 10.1007/978-3-030-58604-1_2
NR 67
TC 1
Z9 1
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 30
PY 2023
DI 10.1007/s11042-023-15546-z
EA MAY 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I0PB2
UT WOS:000999869700014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, W
   He, LY
   Cheng, GH
   Wen, T
   Tian, Y
AF Wang, Wei
   He, Linyang
   Cheng, Guohua
   Wen, Ting
   Tian, Yan
TI Learning from ambiguous labels for X-Ray security inspection via weakly
   supervised correction
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Security inspection; Computer vision; Deep learning; Object detection
AB X-ray security inspection has been dominated by supervised learning detectors for several years. The extreme angles, overlapping occlusion, and diversity of inspected items cause ambiguous objects to appear, bringing ambiguous labels to the training processes of the supervised learning network. It is well known that the training performance of a supervised learning detector is extremely dependent on the quality of the labels. Human-annotated labels are less reliable and more inconsistent due to the loss of key features of ambiguous objects. With the increase in the proportion of unreliable labels, highly negative effects are imposed on contraband detection. To mitigate this problem, an end-to-end weakly supervised correction (WSC) method with three modules for denoising and rectifying ambiguous labels is proposed. (1) X-ray energy awareness blending (X-Blending) extracts ambiguous images and reliable images during each iteration and mixes them into a single image, which improves the stability and efficiency of ambiguous image training. (2) A weakly supervised head (WSH) is embedded in the supervised detector to rectify the noise labels of ambiguous objects. (3) An adaptive label corrector (ALC) dynamically combines object similarity and confidence measures to generate credible labels and reweights factors to adjust sample contributions. WSC is the first work to achieve end-to-end ambiguous label rectification in the field of contraband detection. Different from traditional contraband detection models, WSC innovatively combines weakly supervised learning to provide more prior knowledge for uncertainty label learning and obtain effective feature information from ambiguous objects. When applied to Faster R-CNN, experimental validations show that WSC increases the average precision (AP) by 3.3% and 4.5% on the EDXray and PIDray datasets.
C1 [Wang, Wei; He, Linyang; Cheng, Guohua; Wen, Ting] Zhejiang PeckerAI Technol Ltd, Hangzhou 310051, Zhejiang, Peoples R China.
   [Wang, Wei] Southeast Univ, Sch Automat, Sipailou Rd, Nanjing 210000, Jiangsu, Peoples R China.
   [Tian, Yan] Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Xuezheng Rd, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Southeast University - China; Zhejiang Gongshang University
RP Tian, Y (corresponding author), Zhejiang Gongshang Univ, Sch Comp Sci & Technol, Xuezheng Rd, Hangzhou 310018, Zhejiang, Peoples R China.
EM tianyan@zjgsu.edu.cn
RI He, Linyang/ABC-2993-2021
OI Wang, Wei/0000-0002-7829-6847
FU National Key Research and Development Program of China; Research on
   Intelligent Identification Technology for High-speed Intelligent
   Security Inspection of Express [2022YFF0605002]; National Natural
   Science Foundation of China [61972351, 62111530300]; Special Project for
   Basic Business Expenses of Zhejiang Provincial Colleges and Universities
   [JRK22003]
FX This work was supported by the National Key Research and Development
   Program of China and Research on Intelligent Identification Technology
   for High-speed Intelligent Security Inspection of Express under grant
   2022YFF0605002 and in part by the National Natural Science Foundation of
   China under grants 61972351 and 62111530300 and in part by the Special
   Project for Basic Business Expenses of Zhejiang Provincial Colleges and
   Universities under grant JRK22003. The authors would like to thank
   AJE(www.aje.com) for its linguistic assistance during the preparation of
   this manuscript
CR Akcay S, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108245
   Akcay S, 2017, IEEE IMAGE PROC, P1337, DOI 10.1109/ICIP.2017.8296499
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Chen K, 2019, Arxiv, DOI arXiv:1906.07155
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Ciortan M, 2021, DATA-BASEL, V6, DOI 10.3390/data6060061
   Collier M, 2021, PROC CVPR IEEE, P1551, DOI 10.1109/CVPR46437.2021.00160
   Dai XY, 2021, PROC CVPR IEEE, P7369, DOI 10.1109/CVPR46437.2021.00729
   DeVries T, 2017, Arxiv, DOI [arXiv:1708.04552, DOI 10.48550/ARXIV.1708.04552]
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Feng CJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3490, DOI 10.1109/ICCV48922.2021.00349
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hengduo Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10585, DOI 10.1109/CVPR42600.2020.01060
   Hongkai Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P260, DOI 10.1007/978-3-030-58555-6_16
   Johnson TS, 2019, BIOINFORMATICS, V35, P4696, DOI 10.1093/bioinformatics/btz295
   Kalinathan L, 2020, Nuclei detection in hepatocellular carcinoma and dysplastic liver nodules in histopathology images using bootstrap regression
   Kanmani M, 2020, MULTIMED TOOLS APPL, V79, P17859, DOI 10.1007/s11042-020-08628-9
   Li X., 2020, ADV NEURAL INF PROCE, V33, P21002, DOI DOI 10.48550/ARXIV.2006.04388
   Liao Z, 2022, IEEE T MED IMAGING
   Limberg C, 2018, LECT NOTES COMPUT SC, V11139, P518, DOI 10.1007/978-3-030-01418-6_51
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Madheswari K, INT J BIOMED ENG TEC
   Madheswari K, 2015, INT J APPL ENG RES
   Miao CJ, 2019, PROC CVPR IEEE, P2114, DOI 10.1109/CVPR.2019.00222
   Nathan SS., 2018, INT J APPL ENG RES, V13, P8187
   Nathan SS., 2018, INT J APPL ENG RES, V13, P8179
   Nishi K, 2021, PROC CVPR IEEE, P8018, DOI 10.1109/CVPR46437.2021.00793
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Panaretos VM, 2019, ANNU REV STAT APPL, V6, P405, DOI 10.1146/annurev-statistics-030718-104938
   Parameswaran T., 2012, INT J COMPUT APPL, V975, P8887
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Samet N, 2020, Arxiv, DOI arXiv:2008.01167
   Shao Z, 2023, IEEE T MULTIMEDIA
   Shao Zhuang, 2022, IEEE Trans Neural Netw Learn Syst, VPP, DOI 10.1109/TNNLS.2022.3152990
   Shen Yunhang, 2020, P IEEE CVF C COMP VI, P11326
   Song H, 2023, IEEE T NEUR NET LEAR, V34, P8135, DOI 10.1109/TNNLS.2022.3152527
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tao R., 2021, P IEEE CVF INT C COM, P10923
   Tao RS, 2022, PROC CVPR IEEE, P21157, DOI 10.1109/CVPR52688.2022.02051
   Theresa XB., 2018, INT J APPL ENG RES, V13, P8831
   Tian Y, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3504033
   Tian Y, 2022, IEEE T INTELL TRANSP, V23, P165, DOI 10.1109/TITS.2020.3009000
   Tian Y, 2020, NEUROCOMPUTING, V417, P202, DOI 10.1016/j.neucom.2020.07.078
   Tian Y, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107158
   Tian Y, 2019, IEEE T INTELL TRANSP, V20, P4466, DOI 10.1109/TITS.2018.2886283
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vignesh A., 2017, INT J RES ENG APPL M, V2, P72
   Wang B., 2021, P IEEE CVF INT C COM, P5412
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang WJ, 2023, ARTIF INTELL REV, V56, P6403, DOI 10.1007/s10462-022-10311-4
   Wei YL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P138, DOI 10.1145/3394171.3413828
   Xie XX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3500, DOI 10.1109/ICCV48922.2021.00350
   Zhang S., 2020, P IEEECVF C COMPUTER, P9759
   Zhou X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P72, DOI 10.1109/ICCV48922.2021.00014
   Zhou ZH, 2011, Arxiv, DOI arXiv:0808.3231
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 63
TC 1
Z9 1
U1 3
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 27
PY 2023
DI 10.1007/s11042-023-15299-9
EA MAY 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H4OZ4
UT WOS:000995787000001
DA 2024-07-18
ER

PT J
AU Aljarf, A
   Zamzami, H
   Gutub, A
AF Aljarf, Ahd
   Zamzami, Haneen
   Gutub, Adnan
TI Is blind image steganalysis practical using feature-based
   classification?
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Image steganalysis; Stego image; Hidden message; RBF classifier;
   Features extraction; GLCM properties
ID STEGANOGRAPHY; CRYPTOGRAPHY; ENCRYPTION; DOMAIN; CHAOS
AB Steganalysis is a known practice created to detect hidden data within covered items such as images or texts. Many researches claimed that features extraction is among the suitable methods to detect hidden data within images. Mutual studies have proven that statistical tests are a good way to detect blind steganalysis. Therefore, this paper-work verify the claim proving practicality testing analysis of steganalysis system that depicts the existence of hidden data focused on gray images, by using statistical features and artificial neural network techniques. The proposed system is built to work as blind image steganalysis scheme representing common security as looked-for the most. The research basic gray level co-occurrence matrix (GLCM) displayed the properties of correlation, contrast, homogeneity, and energy in the feature set, as focused used for analyzing this study. The research experimentations adopted LSB steganography technique to create stego-images for testing the steganalysis evaluation practicality. Additionally, machine learning (ML), radial basis function (RBF), as well as the naive bayes classifiers were determined to categorize the remarks for improving detection accuracy. From the investigational results, the proposed system exemplified reliability, and enhancement in the detection rate for most steganographic methods. Further, the correlation features displayed increased accuracy with the RBF and naive bays classifiers showing steganalysis practicality in an attractive remarking contribution.
C1 [Aljarf, Ahd] Umm Al Qura Univ, Informat Syst Dept, Mecca, Saudi Arabia.
   [Zamzami, Haneen; Gutub, Adnan] Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
C3 Umm Al Qura University; Umm Al Qura University
RP Gutub, A (corresponding author), Umm Al Qura Univ, Comp Engn Dept, Mecca, Saudi Arabia.
EM amjarf@uqu.edu.sa; Haneen.Zamzami@gmail.com; aagutub@uqu.edu.sa
RI Gutub, Adnan Abdul-Aziz/O-1240-2016
OI Gutub, Adnan Abdul-Aziz/0000-0003-0923-202X; Aljarf, Dr.
   Ahd/0009-0008-2087-7412
FU College of Computer and Information Systems at~Umm Al-Qura University
   (UQU), Saudi Arabia
FX The authors would like to express their gratitude towards College of
   Computer and Information Systems at Umm Al-Qura University (UQU), Saudi
   Arabia for the collaborative support of this study. All appreciation to
   the genius graduate students of computer information security and MS
   Graduate Research Project courses, as their overall collaborative work
   remarked attractive contribution and completion used within this paper.
   Superior thanks to our great school, Umm Al-Qura University - Makkah,
   for supporting me by this sabbatical leave year (2022-2023) to focus
   completing work-out this cybersecurity research hoping to continue
   offering the MS graduate program as well as allowing for PhD, approved
   by Ministry of Education within Saudi Arabia, opening doors for
   progressive scientific activities.
CR Abdulla A. A., 2015, Ph.D. dissertation
   Abu-Hashem M, 2023, J UMM AL QURA U ENG, DOI [10.1007/s43995-023-00026-0, DOI 10.1007/S43995-023-00026-0]
   Abu-Hashem M, 2022, CAAI T INTELL TECHNO, V7, P278, DOI 10.1049/cit2.12070
   Al-Roithy BO, 2021, MULTIMED TOOLS APPL, V80, P28521, DOI 10.1007/s11042-021-11051-3
   Al-Shaarani F, 2022, ARAB J SCI ENG, V47, P2455, DOI 10.1007/s13369-021-06165-7
   Al-Taie ZH., 2017, THESIS JORDAN MIDDLE
   AlKhodaidi T, 2021, MULTIMED TOOLS APPL, V80, P1143, DOI 10.1007/s11042-020-09720-w
   Almehmadi E, 2022, ARAB J SCI ENG, V47, P2585, DOI 10.1007/s13369-021-06200-7
   Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   [Anonymous], 2011, J. Inform. Hid. Multimed. Signal Process.
   Bin Hureib ES, 2020, INT J COMPUT SCI NET, V20, P1
   Duric Z, 2004, INFORM HIDING STEGAN
   Eichkitz C.G., 2015, First Break, V33
   Fridrich J., 2001, P ACM WORKSH MULT SE, P27
   Gutub Adnan, 2022, International Journal of Speech Technology, P997, DOI 10.1007/s10772-022-09999-0
   Gutub A, 2023, MULTIMED TOOLS APPL, V82, P46577, DOI 10.1007/s11042-023-15586-5
   Gutub A, 2023, J ENG RES-KUWAIT, V11, DOI 10.1016/j.jer.2023.100001
   Gutub A, 2023, ARAB J SCI ENG, V48, P9963, DOI 10.1007/s13369-022-07387-z
   Gutub A, 2023, CAAI T INTELL TECHNO, V8, P440, DOI 10.1049/cit2.12093
   Gutub A, 2022, PAMUKKALE U J ENG SC, V28, P324, DOI 10.5505/pajes.2021.54837
   Gutub A, 2021, J ENG RES-KUWAIT, V9, P153, DOI 10.36909/jer.v9i3A.10111
   Gutub A, 2019, MULTIMED TOOLS APPL, V78, P5591, DOI 10.1007/s11042-017-5293-6
   Gutub AAA, 2022, MULTIMED TOOLS APPL, DOI 10.1007/s11042-022-12062-4
   Hammad BT, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020236
   Hassan FS, 2022, CAAI T INTELL TECHNO, V7, P56, DOI 10.1049/cit2.12053
   Hassan FS, 2021, ARAB J SCI ENG, V46, P8441, DOI 10.1007/s13369-021-05529-3
   Huayong G, 2011, INT C IM SIGN PROC S
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Jin ZY, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2020.107455
   Johnson NF, 1998, COMPUTER, V31, P26, DOI 10.1109/MC.1998.4655281
   Kekre H., 2011, INT J IMAGE PROCESS, V5, P36, DOI DOI 10.1049/IET-IPR.2009.0374
   Ker AD, 2005, IEEE SIGNAL PROC LET, V12, P441, DOI 10.1109/LSP.2005.847889
   Khalifa IA., 2019, SCI J U ZAKHO, V7, P27, DOI [10.25271/sjuoz.2019.7.1.574, DOI 10.25271/SJUOZ.2019.7.1.574]
   Li Q, 2022, IEEE T CIRC SYST VID, V32, P5695, DOI 10.1109/TCSVT.2021.3138795
   Li Q, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107618
   Li Q, 2021, NEURAL PROCESS LETT, V53, P4037, DOI 10.1007/s11063-021-10582-y
   Li Q, 2021, INFORM SCIENCES, V553, P19, DOI 10.1016/j.ins.2020.12.002
   Malekmohamadi H, 2009, IEEE INT CON MULTI, P1740
   Ming C, 2006, INT C INT INF HID MU
   Morkel T., 2005, ISSA, V1, P1
   Provos N., 2003, IEEE Security & Privacy, V1, P32, DOI 10.1109/MSECP.2003.1203220
   Raja K. B., 2005, P 3 INT C INT SENS I, P170
   Rasool ZI, 2018, I C DEV ESYST ENG, P46, DOI 10.1109/DeSE.2018.00048
   Rasool ZI, 2015, THESIS MIDDLE E U AM
   Roslan NA, 2022, EGYPT INFORM J, V23, P177, DOI 10.1016/j.eij.2022.10.003
   Roy PK, 2023, CAAI T INTELL TECHNO, V8, P95, DOI 10.1049/cit2.12081
   Sahu AK, 2022, MULTIMED TOOLS APPL, V81, P30663, DOI 10.1007/s11042-022-13015-7
   Saritas M.M., 2019, International journal of intelligent systems and applications in engineering, V7, P88, DOI 10.18201/ijisae.2019252786
   Shankar DD, 2021, MULTIMED TOOLS APPL, V80, P4073, DOI 10.1007/s11042-020-09820-7
   Shniperov A, 2019, P 12 INT C SECURITY, P1
   Singh A, 2023, MULTIMED TOOLS APPL, V82, P21243, DOI 10.1007/s11042-022-14006-4
   Singh A, 2022, ARAB J SCI ENG, V47, P9801, DOI 10.1007/s13369-021-06348-2
   Sun Z, 2008, IEEE INT C INT INF H
   Sun Z, 2019, IOP C SERIES MAT SCI, V677
   Thabit R, 2022, IEEE ACCESS, V10, P65439, DOI 10.1109/ACCESS.2022.3182712
   Thangadurai K, 2014, INT CONF COMP COMMUN
   Umamaheswari M, 2010, INT J COMPUT SCI NET, V10, P154
   Verma A., 2014, INT J MULTIDISCIP CO, V1, P1
   Wang CP, 2020, IEEE T CIRC SYST VID, V30, P4440, DOI 10.1109/TCSVT.2019.2960507
   Wang CP, 2019, INFORM SCIENCES, V470, P109, DOI 10.1016/j.ins.2018.08.028
   Wang XY, 2021, IEEE SIGNAL PROC LET, V28, P1125, DOI 10.1109/LSP.2021.3080181
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wang XY, 2021, INFORM SCIENCES, V574, P505, DOI 10.1016/j.ins.2021.06.032
   Wang Z, 2020, EURASIP J IMAGE VIDE, V2020, DOI 10.1186/s13640-020-00513-7
   Xian YJ, 2022, IEEE T CIRC SYST VID, V32, P4028, DOI 10.1109/TCSVT.2021.3108767
   Zebari R.R., 2020, A Comprehensive Review of Dimensionality Reduction Techniques for Feature Selection and Feature Extraction, P56, DOI DOI 10.38094/JASTT1224
   Zhang T, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P545
   Zielinska E, 2014, COMMUN ACM, V57, P86, DOI 10.1145/2566590.2566610
NR 69
TC 3
Z9 3
U1 2
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 26
PY 2023
DI 10.1007/s11042-023-15682-6
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H3VP4
UT WOS:000995280400003
DA 2024-07-18
ER

PT J
AU Zhang, Q
AF Zhang, Qian
TI Big health data for elderly employees job performance of SOEs: visionary
   and enticing challenges
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Big health big health data; SOEs; Job performance; Patient pattern
ID RECOGNITION
AB The method is providing and overview of the organization in the management perspective, within the health big data analysis, especially for the elderly employees, the organizations could sign the elderly employees within the right tasks, it reducing the costs by increasing the employees' job performance and organization performance. By addressing the importance role of big health data analytics (BDHA) in the healthcare system .moreover BDHA enables a patient's medical records to be searched in a dynamic, interactive manner. One billion records were made in two hours. Current clinical reporting compares large health data profiles and meta-big health data, giving health apps basic interfaces. A combination of Hadoop/MapReduce and HBase was used to generate the necessary hospital-specific large heath data. One billion (10TB) and three billion (30TB) HBase large health data files might be created in a week or a month using the concept. Apache Hadoop technologies tested simulated medical records. Inconsistencies reduced big health data. An encounter-centered big health database was difficult to set up due to the complicated medical system connections between big health data profiles. Associated with job performance such as the gender, current/past job positions and the health conditions are important. For genders the 66.36% of respondents in the experiments are females, 33.64 are males, majority of are healthy which are 66.97%, 30.58% are common geriatric disease, rest 2.45% are suffering from occupational disease; In terms of the current/past job positions, 20% of the respondents are working as accountant, followed by sales and management level. The Diagnostic and Statistical Manual, lists 157 distinct illnesses. Individuals may be diagnosed with one or more illnesses as a consequence of medical health professionals watching and analyzing their symptoms. It has been discovered that mental health issues have a negative impact on employees' job performance. For example, research on individuals with anxiety and depression has a direct impact on concentrations, decision-making process, and risk-taking behavior, which can be determined for job performance. Machine learning focuses on approaches that can be used to create accurate predictions about future characteristics based on previous training and post training. Principles such as job task and computational learning are crucial for machine learning algorithms that use a large amount of big health data.
C1 [Zhang, Qian] Univ Utara Malaysia, Sch Business Management, Kedah, Malaysia.
   [Zhang, Qian] United Nation Int Solar Energy Technol Transferrin, Lanzhou, Peoples R China.
C3 Universiti Utara Malaysia
RP Zhang, Q (corresponding author), Univ Utara Malaysia, Sch Business Management, Kedah, Malaysia.; Zhang, Q (corresponding author), United Nation Int Solar Energy Technol Transferrin, Lanzhou, Peoples R China.
EM zhangqian102@hotmail.com
CR Aboazoum HME, ANAL FACTORS AFFECTI, P8
   Ahmad S, 2022, CLUSTER COMPUT, V25, P3733, DOI 10.1007/s10586-022-03598-z
   [Anonymous], 2017, SURVEY CHALLENGES IS
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   Atallah RR, 2018, IEEE ACCESS, V6, P28290, DOI 10.1109/ACCESS.2018.2836924
   Awasthi SK., 2020, INT J ENG MANAG RES, V10, P114, DOI [10.31033/IJEMR.10.4.17, DOI 10.31033/IJEMR.10.4.17]
   Caillier JG, 2010, PUBLIC PERFORM MANAG, V34, P139, DOI 10.2753/PMR1530-9576340201
   Chen HC, 2012, MIS QUART, V36, P1165
   Chrimes D., 2017, Advances in Science, Technology and Engineering Systems, V2, P23, DOI DOI 10.25046/AJ020104
   Chrimes D, 2018, ATHENS J TAUECHNOL E, DOI [10.30958/ajte.5-3-1, DOI 10.30958/AJTE.5-3-1]
   Chrimes D, 2018, GLOBAL J ENG SCI, DOI [10.33552/GJES.2018.01.000502, DOI 10.33552/GJES.2018.01.000502]
   Chrimes D, 2016, 2016 IEEE 14TH INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, 14TH INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, 2ND INTL CONF ON BIG DATA INTELLIGENCE AND COMPUTING AND CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/DATACOM/CYBERSC, P811, DOI 10.1109/DASC-PICom-DataCom-CyberSciTec.2016.140
   Dai SF, 2012, INT J COAL GEOL, V94, P3, DOI 10.1016/j.coal.2011.02.003
   Dauda AB, 2017, PROCEEDINGS OF THE IEEE INTERNATIONAL CONFERENCE ON COMPUTING NETWORKING AND INFORMATICS (ICCNI 2017)
   Eniola AA, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02293
   Ford MT, 2011, WORK STRESS, V25, P185, DOI 10.1080/02678373.2011.609035
   Gridwichai P., 2020, ROLE PERSONALITY TRA, V11, P10
   Hansen M M, 2014, Yearb Med Inform, V9, P21, DOI 10.15265/IY-2014-0004
   Haruna K, 2019, IEEE ACCESS, V7, P116179, DOI 10.1109/ACCESS.2019.2892778
   Haslam SA, 2005, BRIT J SOC PSYCHOL, V44, P355, DOI 10.1348/014466605X37468
   Hennekam S, 2020, EMPL RELAT, V42, P626, DOI 10.1108/ER-05-2019-0211
   Jin Z, 2021, LABUAN B INT BUSINES, P1
   KAUSAR A, 2016, 2016 LOUGHB ANT PROP, P1, DOI DOI 10.1109/BSB.2016.7552142
   Krekel C., 2019, SSRN Electron. J, DOI [DOI 10.2139/SSRN.3356581, https://doi.org/10.2139/ssrn.3356581]
   Kudtarkar P, 2010, EVOL BIOINFORM, V6, P197, DOI 10.4137/EBO.S6259
   Kumar VV, 2017, EXPLORE POTENTIAL IM
   Kuo DZ, 2011, MATERN CHILD HLTH J, V15, P794, DOI 10.1007/s10995-010-0648-x
   Manyika J., 2011, The great transformer: The impact of the internet on economic growth and prosperity
   Mohamed Al Ali RAA., 2018, INT J ENTREPRENEURIA, V1, P11, DOI [10.31580/ijer.v1i1.134, DOI 10.31580/IJER.V1I1.134]
   Nyo MT, 2022, MULTIMED TOOLS APPL, V81, P43837, DOI 10.1007/s11042-022-13215-1
   Pavlidou CT, 2021, EVAL PROGRAM PLANN, V84, DOI 10.1016/j.evalprogplan.2020.101894
   Pawirosumarto S, 2017, INT J LAW MANAG, V59, P602, DOI 10.1108/IJLMA-03-2016-0031
   Reddy, 2004, INTRO FINITE ELEMENT
   Rosenthal A, 2010, J BIOMED INFORM, V43, P342, DOI 10.1016/j.jbi.2009.08.014
   Schadt EE, 2010, NAT REV GENET, V11, P647, DOI 10.1038/nrg2857
   Singh D., 2022, J ALGEBRAIC STAT, V13, P2911
   Song JH, 2018, PERFORM IMPROV Q, V30, P249, DOI 10.1002/piq.21251
   Taylor S., 2010, ADV SOCIAL PSYCHOL, P697
   Wall TD, 2004, PERS PSYCHOL, V57, P95, DOI 10.1111/j.1744-6570.2004.tb02485.x
   Xu QZ, 2020, PHYSICA A, V540, DOI 10.1016/j.physa.2019.123205
   Xu QZ, 2019, SOFT COMPUT, V23, P9413, DOI 10.1007/s00500-018-3608-9
   Xu QZ, 2019, PHYSICA A, V531, DOI 10.1016/j.physa.2019.121808
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yu S, 2016, US, P612, DOI [10.1109/DASC-PICom-DataCom-CyberSciTec.2016.112, DOI 10.1109/DASC-PICOM-DATACOM-CYBERSCITEC.2016.112]
   Zerdoumi S, 2018, MULTIMED TOOLS APPL, V77, P10091, DOI 10.1007/s11042-017-5045-7
   Zhang Q, 2022, LABUAN B INT BUSINES, P87
NR 46
TC 0
Z9 0
U1 5
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 25
PY 2023
DI 10.1007/s11042-023-15355-4
EA MAY 2023
PG 34
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA H2CT7
UT WOS:000994103300001
PM 37362673
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Aditya, W
   Shih, TK
   Thaipisutikul, T
   Lin, CY
AF Aditya, Wisnu
   Shih, Timothy K.
   Thaipisutikul, Tipajin
   Lin, Chih-Yang
TI Multi-hop Video Super Resolution with Long-Term Consistency (MVSRGAN)
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Video super resolution; Multi-hop; Generative adversarial network;
   Long-term consistency
AB Utilizing deep learning, and especially Generative Adversarial Networks (GANs), for super-resolution images has yielded auspicious results. However, performing super resolutions with a big difference in scaling between input and output will add a certain degree of difficulty. In this paper we propose a super resolution with multiple steps, which means scaling the image gradually to stimulate maximum results. Video super resolution (VSR) needs different treatment from single image super resolution (SISR). It requires a temporal connection in between the frames, but this has not been fully explored by most of the existing studies. This temporal feature is significant to maintain the video consistency, in term of video quality and motion continuity. Using this loss functions, we can avoid the inconsistent failure in the image which accumulate continuously over time. Finally, our method has been shown to generate a super-resolution video that maintains both the video quality and its motion continuity. The quantitative result has higher Peak Signal to Noise Ratio (PSNR) scores for the Vimeo90K, Vid4, and Fireworks datasets with 37.70, 29.91, and 31.28 respectively compared to the state-of-the-art methods. The result shows that our models is better than other state-of-the-art methods using a different dataset.
C1 [Aditya, Wisnu; Shih, Timothy K.] Natl Cent Univ, Dept Comp Sci & Informat Engn, Zhongli 32001, Taoyuan, Taiwan.
   [Thaipisutikul, Tipajin] Mahidol Univ, Fac Informat & Commun Technol ICT, Salaya 73170, Nakhon Pathom, Thailand.
   [Lin, Chih-Yang] Natl Cent Univ, Dept Mech Engn, Zhongli 32001, Taoyuan, Taiwan.
C3 National Central University; Mahidol University; National Central
   University
RP Aditya, W (corresponding author), Natl Cent Univ, Dept Comp Sci & Informat Engn, Zhongli 32001, Taoyuan, Taiwan.
EM wisnuadity@gmail.com; timothykshih@gmail.com; t.greentip@gmail.com;
   andrewlin2011@gmail.com
OI Aditya, Wisnu/0000-0002-0406-8083
CR Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Caballero J, 2017, PROC CVPR IEEE, P2848, DOI 10.1109/CVPR.2017.304
   Cao YP, 2021, IEEE INT CONF ASAP, P69, DOI 10.1109/ASAP52443.2021.00019
   Chadha A, 2020, COMPUT VIS MEDIA, V6, P307, DOI 10.1007/s41095-020-0175-7
   Chu MY, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392457
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dong C, 2016, IEEE T PATTERN ANAL, V38, P295, DOI 10.1109/TPAMI.2015.2439281
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Goodfellow I., 2014, PROC NEURIPS, P2672, DOI DOI 10.1145/3422622
   Gu JJ, 2019, PROC CVPR IEEE, P1604, DOI 10.1109/CVPR.2019.00170
   Haris M, 2019, PROC CVPR IEEE, P3892, DOI 10.1109/CVPR.2019.00402
   Huang Y., 2015, ADV NEURAL INFPROCES, V28, P235
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Jo Y, 2018, PROC CVPR IEEE, P3224, DOI 10.1109/CVPR.2018.00340
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Koester E, 2019, Arxiv, DOI arXiv:1907.05283
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Li Wenbo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P335, DOI 10.1007/978-3-030-58607-2_20
   Lin Y, 2021, IEEE WINT CONF APPL, P816, DOI 10.1109/WACV48630.2021.00086
   Liu C, 2014, IEEE T PATTERN ANAL, V36, P346, DOI 10.1109/TPAMI.2013.127
   Liu D, 2017, IEEE I CONF COMP VIS, P2526, DOI 10.1109/ICCV.2017.274
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Nazeri K, 2019, IEEE INT CONF COMP V, P3275, DOI 10.1109/ICCVW.2019.00409
   Park SJ, 2018, LECT NOTES COMPUT SC, V11220, P455, DOI 10.1007/978-3-030-01270-0_27
   Sajjadi MSM, 2018, PROC CVPR IEEE, P6626, DOI 10.1109/CVPR.2018.00693
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Sushko V, 2021, IEEE COMPUT SOC CONF, P2596, DOI 10.1109/CVPRW53098.2021.00293
   Tao X, 2017, IEEE I CONF COMP VIS, P4482, DOI 10.1109/ICCV.2017.479
   Wang JL, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10040459
   Wang LG, 2020, IEEE T IMAGE PROCESS, V29, P4323, DOI 10.1109/TIP.2020.2967596
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Xue TF, 2019, INT J COMPUT VISION, V127, P1106, DOI 10.1007/s11263-018-01144-2
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
NR 38
TC 0
Z9 0
U1 5
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 22
PY 2023
DI 10.1007/s11042-023-15351-8
EA MAY 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G9PW0
UT WOS:000992398700002
DA 2024-07-18
ER

PT J
AU Arafa, DA
   Moustafa, HE
   Ali, HA
   Ali-Eldin, AMT
   Saraya, SF
AF Arafa, Doaa Ahmed
   Moustafa, Hossam El-Din
   Ali, Hesham A.
   Ali-Eldin, Amr M. T.
   Saraya, Sabry F.
TI A deep learning framework for early diagnosis of Alzheimer's disease on
   MRI images
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Alzheimer's Disease (AD); Convolution Neural Network (CNN); Deep
   Learning (DL); Transfer Learning (TL); Imaging Pre-processing
AB Numerous medical studies have shown that Alzheimer's disease (AD) was present decades before the clinical diagnosis of dementia. As a result of the development of these studies with the discovery of many ideal biomarkers of symptoms of Alzheimer's disease, it became clear that early diagnosis requires a high-performance computational tool to handle such large amounts of data, as early diagnosis of Alzheimer's disease provides us with a healthy opportunity to benefit from treatment. The main objective of this paper is to establish a complete framework that is based on deep learning approaches and convolutional neural networks (CNN). Four stages of AD, such as (I) preprocessing and data preparation, (II) data augmentation, (III) cross-validation, and (IV) classification and feature extraction based on deep learning for medical image classification, are implemented. In these stages, two methods are implemented. The first method uses a simple CNN architecture. In the second method, the VGG16 model is the pre-trained model that is trained on the ImageNet dataset but applies the same model to the different datasets. We apply transfer learning, meaning, and fine-tuning to take advantage of the pre-trained models. Seven performance metrics are used to evaluate and compare the two methods. Compared to the most recent effort, the proposed method is proficient of analyzing AD, moreover, entails less labeled training samples and minimal domain prior knowledge. A significant performance gain on classification of all diagnosis groups was achieved in our experiments. The experimental findings demonstrate that the suggested designs are appropriate for basic structures with minimal computational complexity, overfitting, memory consumption, and temporal regulation. Besides, they achieve a promising accuracy, 99.95% and 99.99% for the proposed CNN model in the classification of the AD stage. The VGG16 pre-trained model is fine-tuned and achieved an accuracy of 97.44% for AD stage classifications.
C1 [Arafa, Doaa Ahmed; Ali, Hesham A.; Ali-Eldin, Amr M. T.; Saraya, Sabry F.] Mansoura Univ, Fac Engn, Comp Engn & Control Syst Dept, Mansoura, Egypt.
   [Moustafa, Hossam El-Din] Mansoura Univ, Fac Engn, Elect & Commun Engn Dept, Mansoura, Egypt.
   [Ali, Hesham A.] Delta Univ Sci & Technol, Fac Artificial Intelligence, Mansoura, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University; Egyptian Knowledge
   Bank (EKB); Mansoura University; Delta University for Science &
   Technology
RP Arafa, DA (corresponding author), Mansoura Univ, Fac Engn, Comp Engn & Control Syst Dept, Mansoura, Egypt.
EM doaaarafa@mans.edu.eg
RI Moustafa, Hossam El-Din/AAK-8256-2020
OI Moustafa, Hossam El-Din/0000-0002-8242-942X; Ahmed Arafa,
   Doaa/0000-0003-3340-6472
FU Science, Technology & Innovation Funding Authority (STDF); Egyptian
   Knowledge Bank (EKB)
FX Open access funding provided by The Science, Technology & Innovation
   Funding Authority (STDF) in cooperation with The Egyptian Knowledge Bank
   (EKB). The authors declare that they did not receive any funding for the
   current study.
CR AbdulAzeem Y, 2021, NEURAL COMPUT APPL, V33, P10415, DOI 10.1007/s00521-021-05799-w
   Al-Adhaileh MH, 2022, SOFT COMPUT, V26, P7751, DOI 10.1007/s00500-022-06762-0
   Al-Khuzaie FEK, 2021, APPL BIONICS BIOMECH, V2021, DOI 10.1155/2021/6690539
   Alhamid Mohammed, DATA SCI
   alzint, World Alzheimer Report 2018- The state of the Art of Dementia Research: New Frontiers
   Antony F, 2023, CLASSIFICATION ALZHE, V312, DOI [10.1007/978-981-19-3575-6_22, DOI 10.1007/978-981-19-3575-6_22]
   Arafa DA, 2022, MULTIMED TOOLS APPL, V81, P23735, DOI 10.1007/s11042-022-11925-0
   Berrar D., 2019, Cross-Validation, P542, DOI DOI 10.1016/B978-0-12-809633-8.20349-X
   Bhangale KB, 2022, WIRELESS PERS COMMUN, V125, P1913, DOI 10.1007/s11277-022-09640-y
   Bin Tufail A, 2020, J DIGIT IMAGING, V33, P1073, DOI 10.1007/s10278-019-00265-5
   De Gregorio Giuseppe, 2021, Pattern Recognition. ICPR 2020 International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12661), P559, DOI 10.1007/978-3-030-68763-2_43
   Deepa N, 2022, BIOMED SIGNAL PROCES, V74, DOI 10.1016/j.bspc.2021.103455
   deepai, FEATURE EXTRACTION D
   Dubois B, 2016, ALZHEIMERS DEMENT, V12, P292, DOI 10.1016/j.jalz.2016.02.002
   Ebrahim D., 2021, P 15 INT C COMP ENG, P1, DOI [10.1109/ICCES51560.2020.9334594, DOI 10.1109/ICCES51560.2020.9334594]
   El-Sappagh S, 2022, NEURAL COMPUT APPL, V34, P14487, DOI 10.1007/s00521-022-07263-9
   image, IMAGENET
   Ishaque M, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMPUTER APPLICATIONS & INFORMATION SECURITY (ICCAIS)
   kaggle, Alzheimer's Dataset (4 class of Images)
   Kamal M, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/5261942
   Kong ZK, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103565
   Liu JX, 2021, COMPUT METH PROG BIO, V203, DOI 10.1016/j.cmpb.2021.106032
   machinelearningmastery, DO CONVOLUTIONAL LAY
   machinelearningmastery, MANUALLY SCALE IMAGE
   mayoclinic, ALZHEIMERS STAGES DI
   Mehmood A, 2022, COMPUT SYST SCI ENG, V43, P305, DOI 10.32604/csse.2022.018520
   Meng XL, 2022, FRONT NEUROINFORM, V16, DOI 10.3389/fninf.2022.856295
   Mggdadi E, 2021, INT CONF INFORM COMM, P120, DOI 10.1109/ICICS52457.2021.9464543
   Murugan S, 2021, IEEE ACCESS, V9, P90319, DOI 10.1109/ACCESS.2021.3090474
   mygreatlearning, WHAT IS FEATURE EXTR
   Poloni KM, 2022, EXPERT SYST APPL, V195, DOI 10.1016/j.eswa.2022.116622
   Raschka S., 2018, ARXIV
   Ruuska S, 2018, BEHAV PROCESS, V148, P56, DOI 10.1016/j.beproc.2018.01.004
   Sarraf S, 2017, Arxiv, DOI arXiv:1607.06583
   Savas S, 2022, ARAB J SCI ENG, V47, P2201, DOI 10.1007/s13369-021-06131-3
   Shanmugam JV, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103217
   THEODORE WH, 1986, NEUROLOGY, V36, P750, DOI 10.1212/WNL.36.6.750
   Turkson RE, 2021, NEURAL PROCESS LETT, V53, P2649, DOI 10.1007/s11063-021-10514-w
   WHO, Dementia
   Wu O, 2019, STROKE, V50, P1734, DOI 10.1161/STROKEAHA.119.025373
   Zeng NY, 2023, NEURAL COMPUT APPL, V35, P11599, DOI 10.1007/s00521-021-06149-6
NR 41
TC 5
Z9 5
U1 2
U2 12
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 MAY 19
PY 2023
DI 10.1007/s11042-023-15738-7
EA MAY 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G6US0
UT WOS:000990491400003
OA hybrid
DA 2024-07-18
ER

PT J
AU Daniel, DAJ
   Meena, MJ
AF Daniel, D. Anand Joseph
   Meena, M. Janaki
TI Deep learning-based hybrid sentiment analysis with feature selection
   using optimization algorithm
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Sentiment analysis; VADER; Convolutional neural network; Deep learning;
   Long short-term memory; Chimp optimization algorithm
ID IMPROVING ACCURACY; LEXICON; CLASSIFICATION; MODEL; LSTM
AB In the past few years, sentiment analysis (SA) of online content has gained more attention in the research area due to the enormous increase of online content from various sources like websites, social blogs, etc. Many organizations use SA techniques to determine the opinion of users and to ensure their satisfaction. Numerous techniques are suggested by many researchers to identify the sentiments of online content. Among them, hybrid of deep learning and lexicon-based SA techniques are gaining more attention due to their outstanding performance than other approaches. Though the lexicon-based SA approaches integrated with deep learning SA approaches possess more advantages they suffer from lack of accuracy and scalability issues due to the high-dimensional features. To eliminate this issue, a hybrid SA approach is proposed in this paper with a bio-inspired feature selection technique. The Valence Aware Dictionary for Sentiment Reasoning (VADER) approach is integrated with the hybrid deep learning approach of attention-based bidirectional long short-term memory and variable pooling convolutional neural network (VPCNN-ABiLSTM) for SA. The optimal features are selected to minimize the scalability issue by integrating the chimp optimization algorithm with the opposition-based learning technique. The performance of the proposed approach is evaluated for four types of benchmark datasets in terms of precision, accuracy, recall, and F1 score. The proposed approach with OBL-CHOA based feature selection technique achieved higher accuracy of 97.1% with the reduction of 13.6% features. The accuracy of the proposed approach with the feature selection technique is 6.9% higher than the existing BiLSTM-CNN based SA approach.
C1 [Daniel, D. Anand Joseph; Meena, M. Janaki] VIT Chennai, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai
RP Daniel, DAJ (corresponding author), VIT Chennai, Sch Comp Sci & Engn, Chennai 600127, Tamil Nadu, India.
EM danny02.20099@gmail.com; janakimeena.m@vit.ac.in
OI Daniel, D. Anand Joseph/0000-0002-2750-8467
CR Alarifi A, 2020, J SUPERCOMPUT, V76, P4414, DOI 10.1007/s11227-018-2398-2
   Boiy E, 2009, INFORM RETRIEVAL, V12, P526, DOI 10.1007/s10791-008-9070-z
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Borg A, 2020, EXPERT SYST APPL, V162, DOI 10.1016/j.eswa.2020.113746
   Cahyadi A, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATICS: CONCEPTS, THEORY AND APPLICATIONS (ICAICTA 2018), P124, DOI 10.1109/ICAICTA.2018.8541300
   Cai Y, 2020, KNOWL-BASED SYST, V203, DOI 10.1016/j.knosys.2020.105856
   Chen K., 2013, EFFICIENT ESTIMATION, P2
   Cho H, 2014, KNOWL-BASED SYST, V71, P61, DOI 10.1016/j.knosys.2014.06.001
   Darwich M., 2019, J DIGIT INF MANAG, V17, P296, DOI [https://doi.org/10.6025/jdim/2019/17/5/296-305, DOI 10.6025/JDIM/2019/17/5/296-305]
   Dong M, 2020, IEEE ACCESS, V8, P16174, DOI 10.1109/ACCESS.2020.2966726
   Dos Santos C., 2014, Coling, P69
   Ducange P, 2019, ENG APPL ARTIF INTEL, V78, P71, DOI 10.1016/j.engappai.2018.10.014
   Eberhart R.C., 1995, Proc Int Symp Micro Mach Hum Sci, P39, DOI [DOI 10.1109/MHS.1995.494215, 10.1109/mhs.1995.494215]
   Fathi M, 2022, ARCH COMPUT METHOD E, V29, P1247, DOI 10.1007/s11831-021-09616-4
   da Silva NFF, 2016, INFORM SCIENCES, V355, P348, DOI 10.1016/j.ins.2016.02.002
   Fu XH, 2018, IEEE ACCESS, V6, P71884, DOI 10.1109/ACCESS.2018.2878425
   Gautam G, 2014, INT CONF CONTEMP, P437, DOI 10.1109/IC3.2014.6897213
   Geetha M.P., 2021, Int. J. Intell. Netw, V2, P64, DOI [10.1016/j.ijin.2021.06.005, DOI 10.1016/J.IJIN.2021.06.005]
   Govindarajan M., 2013, International Journal of Advanced Computer Research, V3, P139
   Gupta I, 2020, J INTELL SYST, V29, P1611, DOI 10.1515/jisys-2019-0106
   Haque T. U., 2018, 2018 IEEE INT C INN, P1, DOI [DOI 10.1109/ICIRD.2018.8376299, 10.1109/ICIRD.2018.8376299]
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Hemmatian F, 2019, ARTIF INTELL REV, V52, P1495, DOI 10.1007/s10462-017-9599-6
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Hussain A, 2018, NEUROCOMPUTING, V275, P1662, DOI 10.1016/j.neucom.2017.10.010
   Hutto C., 2014, P INT AAAI C WEB SOC, V8, P216, DOI [DOI 10.1609/ICWSM.V8I1.14550, 10.1609/icwsm.v8i1.14550]
   Iqbal F, 2019, IEEE ACCESS, V7, P14637, DOI 10.1109/ACCESS.2019.2892852
   Kalarani P, 2019, SOFT COMPUT, V23, P7067, DOI 10.1007/s00500-018-3349-9
   Kang H, 2012, EXPERT SYST APPL, V39, P6000, DOI 10.1016/j.eswa.2011.11.107
   Karimi Y, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6379
   Katz G, 2015, KNOWL-BASED SYST, V84, P162, DOI 10.1016/j.knosys.2015.04.009
   Kausar S, 2020, IEEE ACCESS, V8, P3594, DOI 10.1109/ACCESS.2019.2963020
   Khishe M, 2020, EXPERT SYST APPL, V149, DOI 10.1016/j.eswa.2020.113338
   Kristiyanti DA, 2017, 2017 5TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT (CITSM 2017), P309
   Kumar SS, 2017, MINING INTELLIGENCE
   Lee G, 2018, KNOWL-BASED SYST, V152, P70, DOI 10.1016/j.knosys.2018.04.006
   Li G, 2014, APPL INTELL, V40, P441, DOI 10.1007/s10489-013-0463-3
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Minaee S, 2019, ARXIV, DOI DOI 10.48550/ARXIV.1904.04206
   Mishra RK, 2021, FRONT COMP SCI-SWITZ, V3, DOI 10.3389/fcomp.2021.775368
   Mujahid M, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188438
   Mumtaz D, 2017, STUDIES COMPUTATIONA, P165, DOI [10.1007/978-981-10-4555-4-11, DOI 10.1007/978-981-10-4555-4-11]
   Nabaei A, 2018, ARTIF INTELL REV, V49, P79, DOI 10.1007/s10462-016-9517-3
   Nandi V., 2016, INT RES J ENG TECHNO, V3, P1621
   Ortigosa A, 2014, COMPUT HUM BEHAV, V31, P527, DOI 10.1016/j.chb.2013.05.024
   Peng HY, 2018, KNOWL-BASED SYST, V148, P167, DOI 10.1016/j.knosys.2018.02.034
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Rajganesh N., 2018, INT J SCI RES COMPUT, V3, P2456
   Rana R., 2016, arXiv
   Rao GZ, 2018, NEUROCOMPUTING, V308, P49, DOI 10.1016/j.neucom.2018.04.045
   Rehman AU, 2019, MULTIMED TOOLS APPL, V78, P26597, DOI 10.1007/s11042-019-07788-7
   Shang L, 2016, SOFT COMPUT, V20, P3821, DOI 10.1007/s00500-016-2093-2
   Singhal Prerana., 2016, Sentiment Analysis and Deep Learning a Survey
   Taboada M, 2011, COMPUT LINGUIST, V37, P267, DOI 10.1162/COLI_a_00049
   Umer M, 2021, COMPUT INTELL-US, V37, P409, DOI 10.1111/coin.12415
   Verma S, 2018, 10 INT C CONT COMP I, P1, DOI [10.1109/IC3.2017.8284318, DOI 10.1109/IC3.2017.8284318]
   Wu CH, 2019, KNOWL-BASED SYST, V165, P30, DOI 10.1016/j.knosys.2018.11.018
   Xia R, 2011, INFORM SCIENCES, V181, P1138, DOI 10.1016/j.ins.2010.11.023
   Yadav A, 2020, CLUSTER COMPUT, V23, P2969, DOI 10.1007/s10586-020-03062-w
   Yuan ZG, 2018, KNOWL-BASED SYST, V155, P1, DOI 10.1016/j.knosys.2018.05.004
   Zou Q, 2016, BIG DATA RES, V5, P2, DOI 10.1016/j.bdr.2015.12.001
NR 61
TC 0
Z9 0
U1 4
U2 11
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 28
BP 43273
EP 43296
DI 10.1007/s11042-023-14767-6
EA APR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W2XI9
UT WOS:000979936300007
DA 2024-07-18
ER

PT J
AU Guiloufi, AB
   El Khediri, S
   Nasri, N
   Kachouri, A
AF Guiloufi, Awatef Benfradj
   El Khediri, Salim
   Nasri, Nejah
   Kachouri, Abdennaceur
TI A comparative study of energy efficient algorithms for IoT applications
   based on WSNs
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Clustering; Energy strategy; IoT; Network lifetime; Routing; WSNs
ID WIRELESS SENSOR NETWORKS; ROUTING PROTOCOL; ARCHITECTURE; LIFETIME;
   SELECTION; SECURITY; INTERNET; CLUSTER; THINGS
AB IoT presents a new technology that aims to interconnect numerous smart devices to provide operators with many smart services. Generally, wireless sensor networks (WSNs) are the key paradigm that ensures Internet of Things (IoT) applications. Due to the limitation of energy sensor resources, the IoT-based WSN is an energy efficiency strategy. In this context, many strategies for energy conservation have been proposed in the literature. Due to the absence of a comparative study of these methods in the literature, the present paper proposes to study 60 recent energy-efficient methods dedicated to IoT applications based on WSNs. Paper selection is accomplished based on the best citation through the Web of Science, Scopus, and SCI indexed databases. First, the different approaches proposed in the literature are classified into three categories: routing methods, clustering methods, and miscellaneous methods. Routing methods are classified into seven types: multipath routing, distributed routing, centralized routing, survivable path routing, opportunistic routing, SDN- based routing, and QoS-based routing. Moreover, clustering approaches are organized into four types: fuzzy clustering, random clustering, weighted clustering, and hybrid clustering. For the Miscellaneous part, three phases are discussed: the physical layer, MAC layer, and security. Furthermore, a comparative study is performed concerning types, performance metrics, applications, simulators, and future research directions. This analysis helps field researchers to learn the latest methods in this field. Established methods or testing those inside a testbed may be an essential path for potential studies.
C1 [Guiloufi, Awatef Benfradj] Gabes Univ, Preparatory Inst Engn Studies Gabes, Natl Engn Sch Gabes ENIG, Lab Modeling Anal & Control Syst MACS, Gabes, Tunisia.
   [El Khediri, Salim] Qassim Univ, Coll Comp, Dept Informat Technol, Buraydah, Saudi Arabia.
   [El Khediri, Salim] Gafsa Univ, Fac Sci, Dept Comp Sci, Gafsa, Tunisia.
   [Nasri, Nejah] Gafsa Univ, Comp Sci Dept Gafsa, Gafsa, Tunisia.
   [Nasri, Nejah] Sfax Univ, Lab Smart Syst Engn & Ehlth Based Technol Image &, Sfax, Tunisia.
   [Kachouri, Abdennaceur] Sfax Univ, Natl Engn Sch Sfax ENIS, Lab Adv Fluid Dynam Energet & Evironment AFD2E, Sfax, Tunisia.
C3 Universite de Gabes; Qassim University; Universite de Gafsa; Universite
   de Gafsa; Universite de Sfax; Universite de Sfax; Ecole Nationale
   dIngenieurs de Sfax (ENIS)
RP Guiloufi, AB (corresponding author), Gabes Univ, Preparatory Inst Engn Studies Gabes, Natl Engn Sch Gabes ENIG, Lab Modeling Anal & Control Syst MACS, Gabes, Tunisia.
EM benfradj_awatef@yahoo.fr
CR Abbasi MA, 2021, CLUSTER COMPUT, V24, P2133, DOI 10.1007/s10586-021-03243-1
   Abdel-Malek MA, 2021, INTERNET THINGS-NETH, V14, DOI 10.1016/j.iot.2021.100366
   Far HAN, 2021, WIREL NETW, V27, P1389, DOI 10.1007/s11276-020-02523-9
   Ahmadi Z, 2021, MULTIMED TOOLS APPL, V80, P36361, DOI 10.1007/s11042-021-11227-x
   Ahutu OR, 2020, IEEE ACCESS, V8, P63270, DOI 10.1109/ACCESS.2020.2983438
   Alazab M, 2021, SUSTAIN ENERGY TECHN, V43, DOI 10.1016/j.seta.2020.100973
   Alfian G, 2020, FOOD CONTROL, V110, DOI 10.1016/j.foodcont.2019.107016
   Anastasov JA, 2020, TELECOMMUN SYST, V74, P95, DOI 10.1007/s11235-019-00638-9
   Bangotra DK, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143887
   Behera TM, 2018, IET WIREL SENSOR SYS
   Behera TM, 2019, IEEE INTERNET THINGS, V6, P5132, DOI 10.1109/JIOT.2019.2897119
   Billet B, 2015, FLOW MANAGEMENT SYST
   Biswas C, 2020, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-01869-4
   Busaileh O, 2022, IEEE T MOBILE COMPUT, V21, P1520, DOI 10.1109/TMC.2020.3022403
   Cacciagrano D, 2019, ENERGY EFFICIENT CLU
   Chalhoub G, 2010, WSNS
   Chaudhry SA, 2021, ACM T INTERNET TECHN, V21, DOI 10.1145/3425707
   Chawra V.K., 2020, NATURE INSPIRED COMP, P41
   Chen NN, 2021, SOFT COMPUT, V25, P4609, DOI 10.1007/s00500-020-05467-6
   Chithaluru P, 2020, SUSTAIN CITIES SOC, V61, DOI 10.1016/j.scs.2020.102254
   Chiti F, 2021, J SENS ACTUAT NETW, V10, DOI 10.3390/jsan10010006
   Cifci MA, 2021, ARTIF INTELL, P204, DOI [10.4018/978-1-7998-5101-1.ch010, DOI 10.4018/978-1-7998-5101-1.CH010]
   Cuong LE., 2008, ACCESS OPTIMIZATION
   Dehkordi SA, 2020, WIREL NETW, V26, P1243, DOI 10.1007/s11276-019-02142-z
   Dhanvijay MM, 2021, WIREL NETW, V27, P537, DOI 10.1007/s11276-020-02470-5
   Ding ZM, 2020, IEEE INTERNET THINGS, V7, P9050, DOI 10.1109/JIOT.2020.3002233
   El Khediri S, 2011, ICM 2011 P, DOI [10.1109/ICM.2011.6177374, DOI 10.1109/ICM.2011.6177374]
   El Khediri S, 2013, 2013 6TH JOINT IFIP WIRELESS AND MOBILE NETWORKING CONFERENCE (WMNC 2013)
   EL-Garoui L, 2020, SMART CITIES-BASEL, V3, P1004, DOI 10.3390/smartcities3030050
   Elangovan G, 2020, ADV INTELL SYST COMP
   Elappila M, 2018, PERVASIVE MOB COMPUT, V43, P49, DOI 10.1016/j.pmcj.2017.11.004
   Elappilaa M, 2017, J PERVASIVE MOB COMP
   Esmaeilzadeh S, 2019, J PETROL SCI ENG, DOI [10.1016/j.petrol.106485, DOI 10.1016/J.PETROL.106485]
   Fanian F, 2021, APPL SOFT COMPUT, V99, DOI 10.1016/j.asoc.2020.106923
   Khan ABF, 2021, INT J INTELL UNMANNE, V9, P178, DOI 10.1108/IJIUS-06-2019-0029
   Furtak J, 2016, 2016 IEEE 3RD WORLD FORUM ON INTERNET OF THINGS (WF-IOT), P233, DOI 10.1109/WF-IoT.2016.7845508
   Ghaleb B, 2016, IEEE WCNC
   Gouda KC, 2020, GA BASED INTELLIGENT, DOI [10.1007/978-981-15-2125-64, DOI 10.1007/978-981-15-2125-64]
   Guiloufi ABF., 2013, SCIENT RES J WIREL S, V5, P67, DOI DOI 10.4236/WSN.2013.54009
   Guiloufi AB, 2016, WIRELESS PERS COMMUN, V88, P449, DOI 10.1007/s11277-015-3137-0
   Gupta P, 2020, SOFT COMPUT, V24, P1737, DOI 10.1007/s00500-019-04000-8
   Gupta SK, 2020, MODERN OPTIMIZATION METHODS FOR SCIENCE, ENGINEERING AND TECHNOLOGY, DOI 10.1088/978-0-7503-2404-5ch7
   Haddar MA, 2022, WIRELESS PERS COMMUN, V125, P209, DOI 10.1007/s11277-022-09547-8
   Kashani MH, 2020, INT J COMMUN SYST, V33, DOI 10.1002/dac.4340
   Hajian E, 2022, IEEE ACCESS, V10, P37457, DOI 10.1109/ACCESS.2022.3164693
   Haseeb K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20072081
   Hassan AAH, 2020, IEEE ACCESS, V8, P200500, DOI 10.1109/ACCESS.2020.3035624
   Hassija V, 2019, IEEE ACCESS, V7, P82721, DOI 10.1109/ACCESS.2019.2924045
   Hawbani A, 2020, IEEE ACM T NETWORK, V28, P2809, DOI 10.1109/TNET.2020.3020984
   Hawbani A, 2019, IEEE T MOBILE COMPUT, V18, P1601, DOI 10.1109/TMC.2018.2865485
   Hawbani A, 2019, IEEE T MOBILE COMPUT, V18, P728, DOI 10.1109/TMC.2018.2839746
   Hellaoui H, 2017, COMPUT NETW, V127, P173, DOI 10.1016/j.comnet.2017.08.006
   Hu SH, 2021, IEEE SENS J, V21, P7093, DOI 10.1109/JSEN.2020.3043748
   Jadhav P, 2016, PROCEDIA COMPUT SCI, V79, P603, DOI 10.1016/j.procs.2016.03.076
   Jain JK, 2019, WIRELESS PERSONAL CO
   Jaiswal Kavita, 2019, 2019 3rd International Conference on Electronics, Communication and Aerospace Technology (ICECA). Proceedings, P857, DOI 10.1109/ICECA.2019.8822173
   Jaiswal K, 2019, 2019 3 INT C ELECT C
   Jaiswal K, 2020, WIRELESS PERS COMMUN, V111, P2493, DOI 10.1007/s11277-019-07000-x
   Jan B, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/6457942
   Javaid N, 2017, IEEE ACCESS
   John S, 2019, ADV INTELL SYST, DOI [10.1007/978-981-32-9949-849, DOI 10.1007/978-981-32-9949-849]
   Kashani MH, 2021, J NETW COMPUT APPL, V192, DOI 10.1016/j.jnca.2021.103164
   Kaur G, 2021, IEEE INTERNET THINGS, V8, P11440, DOI 10.1109/JIOT.2021.3051768
   Kavita J, 2019, WIREL PERSONAL COMMU
   Khalid N, 2020, IEEE ACCESS, V8, P66888, DOI 10.1109/ACCESS.2020.2985711
   Khan ABF, 2019, SN APPL SCI, V1, DOI 10.1007/s42452-019-1628-4
   Khan F, 2020, EGYPT INFORM J, DOI [10.1016/j.eij.2020.05.004, DOI 10.1016/J.EIJ.2020.05.004]
   Khan MM, 2016, J SENSORS, V2016, DOI 10.1155/2016/2635429
   Khan R, 2021, IEEE NETWORK, V35, P202, DOI 10.1109/MNET.011.2000787
   Kim M, 2018, KSII T INTERNET INF
   Kim M, 2022, KSII T INTERNET INF, V12
   Krishnan RS, 2020, J CLEAN PROD, V252, DOI 10.1016/j.jclepro.2019.119902
   Kumar A, 2018, IEEE ACCESS, V6, P76228, DOI 10.1109/ACCESS.2018.2883391
   Lemoine F., 2019, Internet des Objets centre service autocontrole
   Li X, 2018, IEEE INTERNET THINGS, V5, P1606, DOI 10.1109/JIOT.2017.2787800
   Ling J, 2010, CONTRIBUTION STUDY U
   Liu P, 2020, IEEE T MOBILE COMPUT, V19, P2623, DOI 10.1109/TMC.2019.2928805
   Luo J, 2015, MOBILE NETW APPL
   Banh M, 2016, 2016 IEEE SIXTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P125, DOI 10.1109/CCE.2016.7562624
   Mayee Behera T., 2018, IET Wireless Sensor Systems
   Mazumdar N, 2018, 2ND INTERNATIONAL CONFERENCE ON DATA SCIENCE AND BUSINESS ANALYTICS (ICDSBA 2018), P236, DOI 10.1109/ICDSBA.2018.00049
   Mehra PS, 2019, SCALABLE COMPUT-PRAC, V20, P41, DOI 10.12694/scpe.v20i1.1443
   Muhammed T, 2020, HCDSR HIERARCHICAL C, DOI [10.1007/978-3-030-13705-225, DOI 10.1007/978-3-030-13705-225]
   Nair K, 2015, 2015 International Conference on Green Computing and Internet of Things (ICGCIoT), P589, DOI 10.1109/ICGCIoT.2015.7380533
   Nassirpour S., 2020, MAJLESI J TELECOMMUN, V9, P81
   Nayak P, 2021, ROUTING WIRELESS SEN, DOI [10.1016/j.measurement.2021.108, DOI 10.1016/J.MEASUREMENT.2021.108]
   Nayyar A, 2017, INT J ADV COMPUT SC, V8, P148
   Nguyen TD, 2017, AD HOC NETW
   Nguyen TD, 2017, IEEE ICC
   Oche M, 2020, WIREL NETW, V26, P1685, DOI 10.1007/s11276-018-1860-7
   Pasic A, 2020, IEEE ACM T NETWORK, V28, P289, DOI 10.1109/TNET.2019.2963574
   Pavconic C, 2012, GOING FUTURE INTERNE
   Prasad R., 2020, Cyber Security: The Lifeline of Information and Communication Technology, P231
   Praveen Kumar Reddy M, 2020, 2020 INT C EM TRENDS, DOI [10.1109/ic-ETITE47903.2020.298, DOI 10.1109/IC-ETITE47903.2020.298]
   Preeth S.S.L., 2018, J. Ambient Intell. Human. Comput., P1, DOI [10.1007/s12652-018-1154-z, DOI 10.1007/S12652-018-1154-Z]
   Priyadarshi R, 2020, WIRELESS PERS COMMUN, V113, P843, DOI 10.1007/s11277-020-07255-9
   Quy VK, 2021, WIRELESS PERS COMMUN, V120, P49, DOI 10.1007/s11277-021-08433-z
   Rahbari D, 2019, TURK J ELECTR ENG CO, V27, P1406, DOI 10.3906/elk-1810-47
   Rahman GME, 2022, IEEE INTERNET THINGS, V9, P1313, DOI 10.1109/JIOT.2021.3079096
   Rajasoundaran S, 2022, COMPUT COMMUN
   Rajeswari AR, 2021, J INTELL FUZZY SYST
   Rana B, 2021, T EMERG TELECOMMUN T, V32, DOI 10.1002/ett.4166
   Rani S, 2015, SENSORS-BASEL, V15, P28603, DOI 10.3390/s151128603
   Reddy PK, 2017, EVOLUTIONARY SECURE
   Reegan AS, 2021, WIRELESS PERS COMMUN, V118, P1313, DOI 10.1007/s11277-021-08076-0
   Samper L, 2008, MODELISATIONS ANAL W
   Sathya Lakshmi Preeth SK, 2018, WIREL PERSONAL COMMU
   Sathya LPSK, 2018, J AMBIENT INTELL HUM
   Sathya SK, 2018, WIRELESS PERSONAL CO
   Sekar K, 2021, WIRELESS PERS COMMUN, V117, P1279, DOI 10.1007/s11277-020-07922-x
   Seyyedabbasi A, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103325
   Shafiq M, 2020, MOBILE NETW APPL, V25, P882, DOI 10.1007/s11036-020-01523-5
   Shahraki Amin, 2021, IEEE Transactions on Network and Service Management, V18, P2242, DOI 10.1109/TNSM.2020.3035315
   Shahraki A, 2020, COMPUT NETW, V180, DOI 10.1016/j.comnet.2020.107376
   Shakya NM, 2019, DESIGN DEV ENERGY EF
   Sharma SK, 2016, INT SYM WIRELESS COM, P304, DOI 10.1109/ISWCS.2016.7600919
   Sofla MS, 2022, MULTIMED TOOLS APPL, V81, P1997, DOI 10.1007/s11042-021-11423-9
   Shekhawat RS, 2021, NOVEL STRATEGY ENERG
   Shen J, 2017, IEEE ACCESS, V5, P18469, DOI 10.1109/ACCESS.2017.2749606
   Shukla A, 2020, WIREL NETW, V26, P3471, DOI 10.1007/s11276-020-02277-4
   Shukla A, 2020, WIRELESS PERS COMMUN, V112, P2611, DOI 10.1007/s11277-020-07167-8
   Siddavaatam Prathap, 2020, CSI Transactions on ICT, V8, P319, DOI 10.1007/s40012-020-00283-7
   Singh J, 2020, J SYST ARCHITECT, V111, DOI 10.1016/j.sysarc.2020.101782
   Sobin CC, 2020, WIRELESS PERS COMMUN, V112, P1383, DOI 10.1007/s11277-020-07108-5
   Sudheendran Sijo, 2018, 2018 Advances in Science and Engineering Technology International Conferences (ASET), DOI 10.1109/ICASET.2018.8376831
   Thangaramya K, 2019, COMPUT NETW, V151, P211, DOI 10.1016/j.comnet.2019.01.024
   Thekkil TM, 2021, WIRELESS PERS COMMUN, V117, P387, DOI 10.1007/s11277-020-07874-2
   TidjaneKone C, 2011, CONCEPTION ARCHITECT
   Vaiyapuri T, 2022, WIRELESS PERS COMMUN, V127, P39, DOI 10.1007/s11277-021-08088-w
   Wang ZJ, 2018, IEEE WCNC
   Xu LN, 2017, IEEE INTERNET THINGS, V4, P1229, DOI 10.1109/JIOT.2017.2726014
   Yang SK, 2020, IEEE ACCESS, V8, P9728, DOI 10.1109/ACCESS.2020.2964815
   Yassein MB, 2016, 2016 INTERNATIONAL CONFERENCE ON ENGINEERING & MIS (ICEMIS)
   Yetgin H, 2017, IEEE COMMUN SURV TUT, V19, P828, DOI 10.1109/COMST.2017.2650979
   Yousefnezhad N, 2020, J NETW COMPUT APPL, V171, DOI 10.1016/j.jnca.2020.102779
   Yugha R, 2020, J NETW COMPUT APPL, V169, DOI 10.1016/j.jnca.2020.102763
   Zhang DG, 2020, IEEE ACCESS, V8, P69058, DOI 10.1109/ACCESS.2020.2986078
   Zhang J, 2020, IEEE ACCESS, V8, P18110, DOI 10.1109/ACCESS.2020.2968562
NR 138
TC 2
Z9 2
U1 1
U2 6
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 42239
EP 42275
DI 10.1007/s11042-023-14813-3
EA APR 2023
PG 37
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000967980300001
DA 2024-07-18
ER

PT J
AU Skouta, A
   Elmoufidi, A
   Jai-Andaloussi, S
   Ouchetto, O
AF Skouta, Ayoub
   Elmoufidi, Abdelali
   Jai-Andaloussi, Said
   Ouchetto, Ouail
TI Deep learning for diabetic retinopathy assessments: a literature review
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Review
DE Convolutional neural networks; Deep learning; Diabetic retinopathy
   dignosis; Image segmentation; Image classification; Computer-Aided
   Diagnosis (CAD)
ID CONVOLUTIONAL NEURAL-NETWORKS; BLOOD-VESSEL SEGMENTATION; RETINAL
   IMAGES; AUTOMATED DETECTION; FUNDUS IMAGES; HEMORRHAGE DETECTION; LESION
   DETECTION; ARCHITECTURE; ALGORITHMS; DIAGNOSIS
AB Diabetic retinopathy (DR) is the most important complication of diabetes. Early diagnosis by performing retinal image analysis helps avoid visual loss or blindness. A computer-aided diagnosis (CAD) system that uses images of the retinal fundus is an effective and efficient technique for the early diagnosis of diabetic retinopathy and helps specialists assess the disease. Many computer-aided diagnosis (CAD) systems have been developed to help in various stages like segmentation, detection and classification of lesions in fundus images. In the first way, the field actors have vocalized traditional machine learning (ML) techniques based on feature extraction and selection and then applied classification algorithms. The revolution of deep learning (DL) and its decisive victory over traditional ML methods for various applications motivated researchers to employ it for the diagnosis of DR and many deep learning-based methods have been introduced. In this article, we review these methods and highlight their pros and cons. We also talk about how hard it is to make deep learning methods that are good at diagnosing RD. So, our primary goal is to collaborate with experts to develop computer-aided diagnosis systems and test them in various hospital settings with varying picture quality. Finally, we highlight the remaining gaps and future research avenues to pursue.
C1 [Skouta, Ayoub; Jai-Andaloussi, Said; Ouchetto, Ouail] Hassan II Univ, Fac Sci Ain CHOCK, Dept Math & Comp Sci, Comp & Syst Lab, Casablanca 20100, Morocco.
   [Elmoufidi, Abdelali] Sultan Moulay Slimane Univ, Sci & Technol Fac, Dept Math & Comp Sci, Data4Earth Lab, Beni Mellal 523, Morocco.
C3 Hassan II University of Casablanca; Sultan Moulay Slimane University of
   Beni Mellal
RP Skouta, A (corresponding author), Hassan II Univ, Fac Sci Ain CHOCK, Dept Math & Comp Sci, Comp & Syst Lab, Casablanca 20100, Morocco.
EM ay.skouta@gmail.com; elmoufidi10@gmail.com;
   said.jaiandaloussi@etu.univh2c.ma; ouail.ouchetto@etu.univh2c.ma
OI Ouchetto, Ouail/0000-0001-8287-215X
CR Abbasi-Sureshjani S, 2017, LECT NOTES COMPUT SC, V10554, P210, DOI 10.1007/978-3-319-67561-9_24
   Abramoff MD, 2010, EXPERT REV MED DEVIC, V7, P287, DOI 10.1586/ERD.09.76
   Abràmoff MD, 2016, INVEST OPHTH VIS SCI, V57, P5200, DOI 10.1167/iovs.16-19964
   Adem K, 2018, EXPERT SYST APPL, V114, P289, DOI 10.1016/j.eswa.2018.07.053
   Akbar S., 2021, TURK J COMPUT MATH E, V12, P416
   Alyoubi W. L., 2020, Informatics in Medicine Unlocked, V20, DOI [DOI 10.1016/J.IMU.2020.100377, 10.1016/j.imu.2020.100377]
   Ananda S, 2019, ASIAPAC SIGN INFO PR, P1582, DOI [10.1109/APSIPAASC47483.2019.9023290, 10.1109/apsipaasc47483.2019.9023290]
   Asiri N, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.009
   Aziz T, 2023, SCI REP-UK, V13, DOI 10.1038/s41598-023-28680-3
   Badar M, 2020, COMPUT SCI REV, V35, DOI 10.1016/j.cosrev.2019.100203
   Badar M, 2018, COMM COM INF SC, V894, P313, DOI 10.1007/978-3-319-95921-4_29
   Bala Ruchika, 2022, Artificial Intelligence and Speech Technology: Third International Conference, AIST 2021, Revised Selected Papers. Communications in Computer and Information Science (1546), P277, DOI 10.1007/978-3-030-95711-7_25
   Bala R, 2022, ADV INTELL SYST COMP, V1411, P37, DOI 10.1007/978-981-16-6887-6_4
   Biswal B, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102770
   Bodapati JD, 2022, MULTIMED TOOLS APPL, V81, P32033, DOI 10.1007/s11042-022-12811-5
   Bodapati JD, 2021, J AMB INTEL HUM COMP, V12, P9825, DOI 10.1007/s12652-020-02727-z
   Budai A, 2013, INT J BIOMED IMAGING, V2013, DOI 10.1155/2013/154860
   Chen L, 2012, NAT REV ENDOCRINOL, V8, P228, DOI 10.1038/nrendo.2011.183
   Chen YW, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1030, DOI 10.1109/ICASSP.2018.8461427
   Cho NH, 2018, DIABETES RES CLIN PR, V138, P271, DOI 10.1016/j.diabres.2018.02.023
   Choi JY, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0187336
   Chudzik P, 2018, COMPUT METH PROG BIO, V158, P185, DOI 10.1016/j.cmpb.2018.02.016
   Colas E, 2016, ACTA OPHTHALMOL, V94, DOI 10.1111/j.1755-3768.2016.0635
   Dai L, 2018, IEEE T MED IMAGING, V37, P1149, DOI 10.1109/TMI.2018.2794988
   Das S, 2022, MULTIMED TOOLS APPL, V81, P8007, DOI 10.1007/s11042-021-11824-w
   Decencière E, 2013, IRBM, V34, P196, DOI 10.1016/j.irbm.2013.01.010
   Decencière E, 2014, IMAGE ANAL STEREOL, V33, P231, DOI 10.5566/ias.1155
   Desika Vinayaki V, 2023, CONCURR COMP-PRACT E, Ve7391
   Detection A, 2019, APTOS 2019 BLINDNESS
   Duan SX, 2022, J APPL CLIN MED PHYS, V23, DOI 10.1002/acm2.13746
   Dutta S, 2018, INT J GRID DISTRIB, V11, P89, DOI 10.14257/ijgdc.2018.11.1.09
   Eftekhari N, 2019, BIOMED ENG ONLINE, V18, DOI 10.1186/s12938-019-0675-9
   El Hossi Amine, 2021, Business Intelligence. 6th International Conference, CBI 2021. Proceedings. Lecture Notes in Business Information Processing (LNBIP 416), P425, DOI 10.1007/978-3-030-76508-8_31
   Elmoufidi A., 2022, SN Comput. Sci., V4, P78
   Elmoufidi A, 2022, PROG ARTIF INTELL, V11, P397, DOI 10.1007/s13748-022-00292-4
   Elmoufidi A, 2023, INT J IMAGE GRAPH, V23, DOI 10.1142/S0219467823500122
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   eyepacs, EYEPACS DAT
   Faust O, 2012, J MED SYST, V36, P145, DOI 10.1007/s10916-010-9454-7
   Fraz MM, 2012, COMPUT METH PROG BIO, V108, P407, DOI 10.1016/j.cmpb.2012.03.009
   Gargeya R, 2017, OPHTHALMOLOGY, V124, P962, DOI 10.1016/j.ophtha.2017.02.008
   Giancardo L, 2012, MED IMAGE ANAL, V16, P216, DOI 10.1016/j.media.2011.07.004
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gulshan V, 2016, JAMA-J AM MED ASSOC, V316, P2402, DOI 10.1001/jama.2016.17216
   Guo S, 2019, NEUROCOMPUTING, V349, P52, DOI 10.1016/j.neucom.2019.04.019
   Gupta Ankita, 2018, Procedia Computer Science, V132, P1432, DOI 10.1016/j.procs.2018.05.074
   Hagos MT, 2019, ARXIV
   Haloi M, 2015, ARXIV
   Harangi B, 2019, IEEE ENG MED BIO, P2699, DOI [10.1109/embc.2019.8857073, 10.1109/EMBC.2019.8857073]
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Hsu F-H., 2002, Behind Deep Blue: building the computer that defeated the world chess champion
   Hua CH, 2020, IEEE ENG MED BIO, P1992, DOI [10.1109/EMBC44109.2020.9175355, 10.1109/embc44109.2020.9175355]
   Huang YJ, 2020, I S BIOMED IMAGING, P1369, DOI [10.1109/ISBI45749.2020.9098319, 10.1109/isbi45749.2020.9098319]
   Ishtiaq U, 2020, MULTIMED TOOLS APPL, V79, P15209, DOI 10.1007/s11042-018-7044-8
   Islam MM, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105320
   Jena PK, 2023, BIG DATA COGN COMPUT, V7, DOI 10.3390/bdcc7010025
   Jiang HY, 2019, IEEE ENG MED BIO, P2045, DOI [10.1109/embc.2019.8857160, 10.1109/EMBC.2019.8857160]
   Johari MH., 2018, INT J ENG TECHNOLOGY, V7, P198, DOI DOI 10.14419/IJET.V7I4.11.20804
   Jolad B., 2023, INTERSPEECH, V21, P1
   kaggle, KAGGLE DIABETIC RETI
   Kalviainen R., 2007, the diaretdb1 diabetic retinopathy database and evaluation protocol
   Kandel I, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062021
   Kauppi T., 2006, Machine Vision and Pattern Recognition Research Group, V73, P1
   Kauppi T., 2007, P BRIT MACH VIS C, V1
   Kaur A, 2014, 2014 INTERNATIONAL CONFERENCE ON CONTEMPORARY COMPUTING AND INFORMATICS (IC3I), P509, DOI 10.1109/IC3I.2014.7019714
   Kaur S, 2020, 2020 IEEE SIXTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2020), P386, DOI 10.1109/BigMM50055.2020.00066
   Kavzoglu T, 2014, LANDSLIDES, V11, P425, DOI 10.1007/s10346-013-0391-7
   Kou CX, 2019, J MED IMAGING, V6, DOI 10.1117/1.JMI.6.2.025008
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar E. Sudheer, 2021, 2021 7th International Conference on Advanced Computing and Communication Systems (ICACCS), P1247, DOI 10.1109/ICACCS51430.2021.9441964
   Lahmar C., 2022, Computer Methods in Biomechanics and Biomedical Engineering: Imaging Visualization, P1
   Lam C., 2018, AMIA JT SUMMITS TRAN, V2017, P147
   Lam C, 2018, INVEST OPHTH VIS SCI, V59, P590, DOI 10.1167/iovs.17-22721
   Latha D, 2022, MULTIMED TOOLS APPL, V81, P26143, DOI 10.1007/s11042-022-12667-9
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li T, 2021, MED IMAGE ANAL, V69, DOI 10.1016/j.media.2021.101971
   Li T, 2019, INFORM SCIENCES, V501, P511, DOI 10.1016/j.ins.2019.06.011
   Li XM, 2020, IEEE T MED IMAGING, V39, P1483, DOI 10.1109/TMI.2019.2951844
   Liang Z., 2006, INFORM IDENTIFICATIO
   Lin ZW, 2018, LECT NOTES COMPUT SC, V11071, P74, DOI 10.1007/978-3-030-00934-2_9
   Liu YP, 2019, ARTIF INTELL MED, V99, DOI 10.1016/j.artmed.2019.07.002
   Lotfy M, 2017, CURR DIABETES REV, V13, P3, DOI 10.2174/1573399812666151016101622
   Mansour RF, 2018, BIOMED ENG LETT, V8, P41, DOI 10.1007/s13534-017-0047-y
   Marín D, 2011, IEEE T MED IMAGING, V30, P146, DOI 10.1109/TMI.2010.2064333
   Masood S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON COMPUTING, COMMUNICATION AND AUTOMATION (ICCCA), P1183, DOI 10.1109/CCAA.2017.8229977
   Mayyaa V, 2021, COMPUT METH PROG BIO, V1, P1, DOI 10.1016/j.cmpbup.2021.100013
   Mobeen-ur-Rehman, 2019, PROCEEDINGS 2019 AMITY INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AICAI), P244, DOI [10.1109/AICAI.2019.8701231, 10.1109/aicai.2019.8701231]
   Nahiduzzaman M, 2023, INT J AMBIENT ENERGY
   Nazir T, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10186185
   Neff T, 2017, PROC OAGM ARW JOINT, P140, DOI [10.3217/978-3-85125-524-9-30, 10.3217/978-3-85125- 524-9-30., DOI 10.3217/978-3-85125-524-9-30]
   Niemeijer M, 2010, IEEE T MED IMAGING, V29, P185, DOI 10.1109/TMI.2009.2033909
   Nirthika Rajendran, 2020, 2020 IEEE 15th International Conference on Industrial and Information Systems (ICIIS), P144, DOI 10.1109/ICIIS51140.2020.9342711
   Okur M.E., 2017, ACTA PHARM SCI, V55, DOI [DOI 10.23893/1307-2080.APS.0555, 10.23893/1307-2080.aps.0555]
   Orlando JI, 2018, COMPUT METH PROG BIO, V153, P115, DOI 10.1016/j.cmpb.2017.10.017
   Padmanayana, 2022, MATER TODAY-PROC, V58, P212, DOI 10.1016/j.matpr.2022.01.466
   Perdomo O, 2017, PROC SPIE, V10160, DOI 10.1117/12.2256939
   Pires R, 2019, ARTIF INTELL MED, V96, P93, DOI 10.1016/j.artmed.2019.03.009
   Pires R, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0096814
   Playout C, 2019, IEEE T MED IMAGING, V38, P2434, DOI 10.1109/TMI.2019.2906319
   Playout C, 2018, LECT NOTES COMPUT SC, V11071, P101, DOI 10.1007/978-3-030-00934-2_12
   Porwal P, 2018, DATA, V3, DOI 10.3390/data3030025
   Pratt H, 2016, PROCEDIA COMPUT SCI, V90, P200, DOI 10.1016/j.procs.2016.07.014
   Prentasic P, 2016, COMPUT METH PROG BIO, V137, P281, DOI 10.1016/j.cmpb.2016.09.018
   Prentasic P, 2013, INT SYMP IMAGE SIG, P711
   Qomariah D, 2022, INT CONF INFORM COMM, V15
   Quellec G, 2008, IEEE T MED IMAGING, V27, P1230, DOI 10.1109/TMI.2008.920619
   Quellec G, 2017, MED IMAGE ANAL, V39, P178, DOI 10.1016/j.media.2017.04.012
   Raman V, 2016, I C COMM SOFTW NET, P636, DOI 10.1109/ICCSN.2016.7586601
   Riaz H, 2020, DIAGNOSTICS, V10, DOI 10.3390/diagnostics10010024
   Sadek I, 2015, PROC SPIE, V9414, DOI 10.1117/12.2075824
   Saha O, 2019, ARXIV
   Salam AA, 2022, SIGNAL IMAGE VIDEO P, V16, P1869, DOI 10.1007/s11760-022-02146-x
   Sambyal N, 2020, BIOCYBERN BIOMED ENG, V40, P1094, DOI 10.1016/j.bbe.2020.05.006
   Sarhan MH, 2019, LECT NOTES COMPUT SC, V11764, P174, DOI 10.1007/978-3-030-32239-7_20
   Sayres R, 2019, OPHTHALMOLOGY, V126, P552, DOI 10.1016/j.ophtha.2018.11.016
   Schawinski K, 2017, MON NOT R ASTRON SOC, V467, pL110, DOI 10.1093/mnrasl/slx008
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P92, DOI 10.1007/978-3-642-15825-4_10
   Selçuk T, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6768
   Shaik NS, 2022, APPL INTELL, V52, P15105, DOI 10.1007/s10489-021-03043-5
   Shanthi T, 2019, COMPUT ELECTR ENG, V76, P56, DOI 10.1016/j.compeleceng.2019.03.004
   Sivaprasad S, 2014, TRIALS, V15, DOI 10.1186/1745-6215-15-458
   Sivaswamy J, 2014, I S BIOMED IMAGING, P53, DOI 10.1109/ISBI.2014.6867807
   Skouta Ayoub, 2021, Advances on Smart and Soft Computing. Proceedings of ICACIn 2020. Advances in Intelligent Systems and Computing (AISC 1188), P177, DOI 10.1007/978-981-15-6048-4_16
   Skouta A, 2022, SENSORNETS, P163
   Skouta A, 2022, J BIG DATA-GER, V9, DOI 10.1186/s40537-022-00632-0
   Sopharak A, 2008, COMPUT MED IMAG GRAP, V32, P720, DOI 10.1016/j.compmedimag.2008.08.009
   Sun K, 2022, COMPUT BIOL MED, V149, DOI 10.1016/j.compbiomed.2022.105909
   Tan JH, 2017, INFORM SCIENCES, V420, P66, DOI 10.1016/j.ins.2017.08.050
   Tymchenko B, 2020, ARXIV
   van Grinsven MJJP, 2016, IEEE T MED IMAGING, V35, P1273, DOI 10.1109/TMI.2016.2526689
   Walter T, 2002, IEEE T MED IMAGING, V21, P1236, DOI 10.1109/TMI.2002.806290
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang H, 2020, COMPUT METH PROG BIO, V191, DOI 10.1016/j.cmpb.2020.105398
   Wang JL, 2020, IET COMPUT VIS, V14, P1, DOI 10.1049/iet-cvi.2018.5508
   Wang LY, 2021, I S BIOMED IMAGING, P1141, DOI 10.1109/ISBI48211.2021.9433917
   Wang XL, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P465, DOI 10.1109/IRI.2018.00074
   Worrall DE, 2016, LECT NOTES COMPUT SC, V10008, P68, DOI 10.1007/978-3-319-46976-8_8
   Xiaotong Li, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092112
   Xu B., 2015, arXiv
   Xue J, 2019, KNOWL-BASED SYST, V183, DOI 10.1016/j.knosys.2019.104887
   Yan Y, 2019, CHIN CONT DECIS CONF, P2287, DOI [10.1109/CCDC.2019.8833190, 10.1109/ccdc.2019.8833190]
   Yan ZZ, 2019, I S BIOMED IMAGING, P597, DOI 10.1109/isbi.2019.8759579
   Zago GT, 2020, COMPUT BIOL MED, V116, DOI 10.1016/j.compbiomed.2019.103537
   Zeng XL, 2019, IEEE ACCESS, V7, P30744, DOI 10.1109/ACCESS.2019.2903171
   Zhang G, 2022, FRONT MED, V9
   Zhang W, 2019, KNOWL-BASED SYST, V175, P12, DOI 10.1016/j.knosys.2019.03.016
   Zhang Z, 2010, IEEE ENG MED BIO, P3065, DOI 10.1109/IEMBS.2010.5626137
   Zhe Wang, 2017, Medical Image Computing and Computer Assisted Intervention  MICCAI 2017. 20th International Conference. Proceedings: LNCS 10435, P267, DOI 10.1007/978-3-319-66179-7_31
   Zhixiang Qian, 2021, 2021 IEEE 5th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P2652, DOI 10.1109/IAEAC50856.2021.9390963
NR 150
TC 9
Z9 9
U1 11
U2 27
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 27
BP 41701
EP 41766
DI 10.1007/s11042-023-15110-9
EA APR 2023
PG 66
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA W6VJ3
UT WOS:000967980300003
DA 2024-07-18
ER

PT J
AU Rajasekaran, G
   Abitha, V
   Vaishnavi, SM
AF Rajasekaran, G.
   Abitha, V.
   Vaishnavi, S. M.
TI Image dehazing algorithm based on artificial multi-exposure image fusion
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Gamma-corrected underexposed images; Image dehazing; Color saturation
AB Bad weather conditions such as fog, haze, etc. reduce the visibility level of the images captured in those weather conditions. Degradation of visibility in the captured images is a serious concern nowadays. Even though there are many different devices available for dehazing several devices lack the capability of efficient dehazing, and they are not capable of effectively mitigating the visibility degradation caused by those unusual weather conditions. The image processing task which is concerned with this phenomenon is called image dehazing. In this article, an image fusion-based approach is proposed which eliminates the usage of depth information thus the need for depth calculation is avoided in this method which is a tedious process. This proposed method thus enhances the performance and robustness of the image dehazing process. To achieve this goal the hazy images, undergo a set of gamma corrections operations followed by the fusion of various Gamma-corrected underexposed images obtained from the gamma correction operation followed by color saturation adjustment thus yielding an image with better visibility which is nowadays a major concern as many devices require images with higher quality for processing. Fusion of underexposed images obtained by artificial methods can remove the haze effectively when the situations are challenging. Other image dehazing techniques tend to fail and the proposed method helps to produce better results in terms of PSNR, SSIM, Entropy, accumulation and running time.
C1 [Rajasekaran, G.; Abitha, V.; Vaishnavi, S. M.] Mepco Schlenk Engn Coll, Dept Informat Technol, Sivakasi, Tamil Nadu, India.
C3 Mepco Schlenk Engineering College
RP Rajasekaran, G (corresponding author), Mepco Schlenk Engn Coll, Dept Informat Technol, Sivakasi, Tamil Nadu, India.
EM rajasekaran@mepcoeng.ac.in; abitha2302000_it@mepcoeng.ac.in;
   vaishu2001sm_it@mepcoeng.ac.in
CR Fazlali H, 2020, MULTIMED TOOLS APPL, V79, P29493, DOI 10.1007/s11042-020-09383-7
   Galdran A, 2018, SIGNAL PROCESS, V149, P135, DOI 10.1016/j.sigpro.2018.03.008
   He KM, 2009, PROC CVPR IEEE, P1956, DOI [10.1109/CVPRW.2009.5206515, 10.1109/CVPR.2009.5206515]
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Huang J, 2019, MULTIMED TOOLS APPL, V78, P30627, DOI 10.1007/s11042-018-6536-x
   Lakshmi TRV, 2022, MULTIMED TOOLS APPL, V81, P20229, DOI 10.1007/s11042-022-12485-z
   Liu Y, 2022, MULTIMED TOOLS APPL, V81, P23941, DOI 10.1007/s11042-022-12681-x
   Raikwar SC, 2020, MULTIMED TOOLS APPL, V79, P891, DOI 10.1007/s11042-019-08120-z
   Verma P, 2022, VISUAL COMPUT, V38, P2417, DOI 10.1007/s00371-021-02120-7
   Verma P, 2020, J VIS COMMUN IMAGE R, V71, DOI 10.1016/j.jvcir.2020.102866
   Wang YB, 2021, MULTIMED TOOLS APPL, V80, P32539, DOI 10.1007/s11042-021-11209-z
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yao TT, 2023, MULTIMED TOOLS APPL, V82, P12279, DOI 10.1007/s11042-022-13772-5
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
   Zhu ZQ, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024335
NR 15
TC 0
Z9 0
U1 1
U2 17
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 41241
EP 41251
DI 10.1007/s11042-023-15210-6
EA APR 2023
PG 11
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000963639900001
DA 2024-07-18
ER

PT J
AU Rakheja, R
   Khera, S
   Turk, N
   Kamboj, S
AF Rakheja, Rohin
   Khera, Sonam
   Turk, Neelam
   Kamboj, Sangeeta
TI Parametric analysis of dynamic routing protocol for wireless sensor
   networks
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Dynamic source routing protocol; Network simulator; Wireless sensor
   network; Energy efficiency; Performance characteristics of network
   protocol
AB In the paper the adaptability of Dynamic Source Routing (DSR) Protocol to the changes in network topography, its ability to establish new routes and the viability in modern sensing devices is simulated and analyzed. For a dynamic network the distance between source and destination changes along with their position in respect to their neighboring nodes. In our experiments, three scenarios considering real world deployment techniques like fixed position, clustering and random mobility are designed and the behavior of the protocol has been studied in two networks consisting of 100 and 150 nodes respectively. Comparative analysis is performed considering characteristics such as Instantaneous throughput, Bandwidth consumption, Average throughput, Packet delivery ratios and Residual energy of the individual nodes and of the network. The experimental data provides valuable insight for real-world applications. Path selection in DSR protocol is based on control messages which are flooded throughout the network. As seen from our experiments, the protocol can be greatly enhanced by reducing the overhead (number of packets required for network communication) to conserve bandwidth. Before making changes to the header or the routing mechanism we need to make sure that the protocol can still accommodate the various types of payloads, options and adopt to fragmented or dynamic networks. Due to the severe limitations on the resources available, the selected protocol should provide high energy efficiency, reliability and robustness to attacks. Hence the analysis of networking/routing protocols should be considered and variations of the selected protocol can be developed to accommodate the challenges faced in such networks.
C1 [Rakheja, Rohin; Khera, Sonam; Turk, Neelam] JC Bose Univ Sci & Technol, Elect Engn Dept, YMCA, Faridabad, Haryana, India.
   [Kamboj, Sangeeta] Thapar Inst Engn & Technol, Elect & Instrumentat Engn Dept, Patiala, Punjab, India.
C3 J.C. Bose University of Science & Technology, YMCA; Thapar Institute of
   Engineering & Technology
RP Khera, S (corresponding author), JC Bose Univ Sci & Technol, Elect Engn Dept, YMCA, Faridabad, Haryana, India.
EM sonamkhattar23@gmail.com
OI Turk, Neelam/0000-0001-8653-9223; Khera, Sonam/0000-0002-6621-2503
CR [Anonymous], 2018, INT J ENG TECHNOL IR, V05
   [Anonymous], WIRELESS SENSOR NETW, DOI [10.1007/978-3-030-29700-8, DOI 10.1007/978-3-030-29700-8]
   [Anonymous], DYN WIR SENS NETW NE, DOI [10.1007/978-3-319-92807-4, DOI 10.1007/978-3-319-92807-4]
   Dione D, 2022, SN APPL SCI, V4, DOI 10.1007/s42452-022-05073-1
   Goswami P, 2022, IEEE T INTELL TRANSP, V23, P1670, DOI 10.1109/TITS.2021.3107527
   Gupta AnujK., 2010, International Journal of Engineering and Technology, V2, P226
   Issariyaku T, 2008, LINKAGE OTCL C NS2
   Issariyaku T, 2008, INTRO NETWORK SIMULA
   Kandris D, 2020, APPL SYST INNOV, V3, DOI 10.3390/asi3010014
   Li KF, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2169521
   Rajasoundaran S, 2022, COMPUT COMMUN, V187, P71, DOI 10.1016/j.comcom.2022.02.004
   Ruoshan Kong, 2008, 2008 International Conference on Computer Science and Software Engineering (CSSE 2008), P1070, DOI 10.1109/CSSE.2008.404
   Sabor N, 2017, WIREL COMMUN MOB COM, P1, DOI 10.1155/2017/2818542
   Shahraki A, 2020, COMPUT NETW, V180, DOI 10.1016/j.comnet.2020.107376
   Venkatesan TP, 2014, INT CONF COMM SYST, P173, DOI 10.1109/CSNT.2014.42
   Yuhong Luo, 2006, 2006 International Symposium on a World of Wireless Mobile and Multimedia Networks
NR 16
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD OCT
PY 2023
VL 82
IS 25
SI SI
BP 39035
EP 39055
DI 10.1007/s11042-023-15076-8
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA U4IQ2
UT WOS:000960423600011
DA 2024-07-18
ER

PT J
AU Saunoriene, L
   Ragulskis, M
AF Saunoriene, Loreta
   Ragulskis, Minvydas
TI A steganographic scheme based on the Wada index
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Wada index; Perfect covering; Steganography; Carrier image
ID IMAGE STEGANOGRAPHY; SPATIAL DOMAIN
AB A steganographic technique based on the Wada index is proposed in this paper. The definition of a perfect covering of the carrier image is introduced. Perfect coverings are used to produce a unique representation of the carrier image what enables the consecutive modification of pixels in the carrier image without destructing Wada indexes in previous overlapping observation windows. The only required information for the decoding step is the stego image itself. The stego image is split into dichotomous shares according to the Wada index. The decoding scheme is based on the disjunction of shares with odd indexes. Computational experiments are used to demonstrate the efficacy of the proposed scheme. The proposed steganographic scheme based on the Wada index ensures that the secret image is not leaked from the modified bit planes with lowest indexes, the stego image is robust against RS steganalysis algorithms, and the payload capacity of the carrier image is comparable to grayscale LSB schemes.
C1 [Saunoriene, Loreta; Ragulskis, Minvydas] Kaunas Univ Technol, Dept Math Modelling, Studentu 50-146, LT-51368 Kaunas, Lithuania.
C3 Kaunas University of Technology
RP Ragulskis, M (corresponding author), Kaunas Univ Technol, Dept Math Modelling, Studentu 50-146, LT-51368 Kaunas, Lithuania.
EM minvydas.ragulskis@ktu.lt
RI Ragulskis, Minvydas/A-1546-2008
OI Ragulskis, Minvydas/0000-0002-3348-9717
CR Abdulla A.A., 2015, Exploiting similarities between secret and cover images for improved embedding efficiency and security in digital steganography (Doctoral dissertation, University of Buckingham, Buckingham, United Kingdom)
   Abdulla AA, 2014, LECT NOTES COMPUT SC, V8893, P151, DOI 10.1007/978-3-319-14054-4_10
   Abdulla AA, 2013, IEEE INT SYM MULTIM, P287, DOI 10.1109/ISM.2013.55
   Agaian SS, 2006, 2006 IEEE REGION 5 C, P125, DOI [10.1109/TPSD.2006.5507446, DOI 10.1109/TPSD.2006.5507446]
   Ahmad T., 2014, SMARTCR, V4, P307, DOI [10.6029/smartcr.2014.04.007, DOI 10.6029/SMARTCR.2014.04.007]
   Aini Devita Nurul, 2019, 2019 International Seminar on Application for Technology of Information and Communication (iSemantic). Proceedings, P434, DOI 10.1109/ISEMANTIC.2019.8884333
   Alhomoud AM, 2021, INTELL AUTOM SOFT CO, V27, P69, DOI 10.32604/iasc.2021.014773
   [Anonymous], 1917, Tohoku Math. J.
   Astola, 2006, 14 EUR SIGN PROC C E, P1
   Daza A, 2016, SCI REP-UK, V6, DOI 10.1038/srep31416
   Fridrich J., 2001, IEEE Multimedia, V8, P22, DOI 10.1109/93.959097
   Gou HM, 2007, IEEE IMAGE PROC, P2893
   Hosam O., 2019, Int. J. Inf. Technol. Comput. Sci., V11, P23
   Hussain M, 2018, SIGNAL PROCESS-IMAGE, V65, P46, DOI 10.1016/j.image.2018.03.012
   Hussain M, 2015, IEEE ICCE, P21, DOI 10.1109/ICCE-TW.2015.7216859
   Kadhim IJ, 2019, NEUROCOMPUTING, V335, P299, DOI 10.1016/j.neucom.2018.06.075
   Kai Yung Lin, 2010, 2010 2nd International Conference on Education Technology and Computer (ICETC 2010), P121, DOI 10.1109/ICETC.2010.5529581
   KENNEDY J, 1991, PHYSICA D, V51, P213, DOI 10.1016/0167-2789(91)90234-Z
   Khalind O, 2015, PROC SPIE, V9497, DOI 10.1117/12.2184496
   Khan S., 2017, J ENG APPL SCI, V36, P67
   Khandelwal NamanS., 2015, International Conference on Electrical, Electronics, Signals, Communication and Optimization (EESCO), P1, DOI DOI 10.1109/ICET.2015.7389227
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE J-STSP, V14, P955, DOI 10.1109/JSTSP.2020.3002391
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Lu C-S., 2004, MULTIMEDIA SECURITY, P264
   Luo WQ, 2010, IEEE T INF FOREN SEC, V5, P201, DOI 10.1109/TIFS.2010.2041812
   Manoharan Sathiamoorthy, 2008, Third International Conference on Internet Monitoring and Protection - ICIMP 2008, P172, DOI 10.1109/ICIMP.2008.15
   Neeta D, 2006, 2006 1ST INTERNATIONAL CONFERENCE ON DIGITAL INFORMATION MANAGEMENT, P173
   Nguyen BC, 2006, LECT NOTES COMPUT SC, V4283, P61
   Osipov AV, 2018, NONLINEAR PHENOM COM, V21, P389
   Potdar VM, 2004, 2004 2ND IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS, P223, DOI 10.1109/INDIN.2004.1417333
   Pradhan A, 2016, IEEE INT C RES ADV I, P1, DOI 10.1109/RAINS.2016.7764399
   Ratan R, 2021, DEFENCE SCI J, V71, P209, DOI 10.14429/dsj.71.15643
   Safarpour M, 2016, CAPACITY ENLARGEMENT
   Sahu AK, 2020, OPEN COMPUT SCI, V10, P296, DOI 10.1515/comp-2020-0136
   Saunoriene L, 2021, NONLINEAR DYNAM, V104, P739, DOI 10.1007/s11071-021-06261-1
   Setiadi DIM, 2021, MULTIMED TOOLS APPL, V80, P8423, DOI 10.1007/s11042-020-10035-z
   Shih FY., 2017, DIGITAL WATERMARKING, P292, DOI [10.1201/9781315121109, DOI 10.1201/9781315121109]
   Swain G, 2019, ARAB J SCI ENG, V44, P2995, DOI 10.1007/s13369-018-3372-2
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Venkatraman S, 2004, ITCC 2004: INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, VOL 2, PROCEEDINGS, P347
   Wagemakers A, 2021, DISCRETE CONT DYN-B, V26, P717, DOI 10.3934/dcdsb.2020330
   Wayner P, 2009, DISAPPEARING CRYPTOGRAPHY: INFORMATION HIDING: STEGANOGRAPHY & WATERMARKING, 3RD EDITION, P337, DOI 10.1016/B978-012374479-1.50022-8
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zhang XP, 2006, IEEE COMMUN LETT, V10, P781, DOI 10.1109/LCOMM.2006.060863
   Zhang YX, 2015, NONLINEAR DYNAM, V79, P2667, DOI 10.1007/s11071-014-1839-6
   Zhang YX, 2013, NONLINEAR DYNAM, V73, P2221, DOI 10.1007/s11071-013-0936-2
   Ziaukas P, 2017, NONLINEAR DYNAM, V88, P871, DOI 10.1007/s11071-016-3281-4
NR 48
TC 0
Z9 0
U1 0
U2 0
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40503
EP 40529
DI 10.1007/s11042-023-14888-y
EA MAR 2023
PG 27
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000960423600021
DA 2024-07-18
ER

PT J
AU Varzaneh, ZA
   Hosseini, S
   Javidi, MM
AF Asghari Varzaneh, Zahra
   Hosseini, Soodeh
   Javidi, Mohammad Masoud
TI A novel binary horse herd optimization algorithm for feature selection
   problem
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Horse herd optimization algorithm (HOA); Binary horse herd optimization;
   Transfer function; Feature selection; Classification
ID SALP SWARM ALGORITHM; DIFFERENTIAL EVOLUTION; DESIGN
AB Feature selection (FS) is an essential step for machine learning problems that can improve the performance of the classification by removing useless features from the data set. FS is an NP-hard problem, so meta-heuristic algorithms can be used to find good solutions for this problem. Horse herd Optimization Algorithm (HOA) is a new meta-heuristic approach inspired by horses 'herding behavior. In this paper, an improved version of the HOA algorithm called BHOA is proposed as a wrapper-based FS method. To convert continuous to discrete search space, S-Shaped and V-Shaped transfer functions are considered. Moreover, to control selection pressure, exploration, and exploitation capabilities, the Power Distance Sums Scaling approach is used to scale the fitness values of the population. The efficiency of the proposed method is estimated on 17 standard benchmark datasets. The implementation results prove the efficiency of the proposed method based on the V-shaped category of transfer functions compared to other transfer functions and other wrapper-based FS algorithms.
C1 [Asghari Varzaneh, Zahra; Hosseini, Soodeh; Javidi, Mohammad Masoud] Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.
C3 Shahid Bahonar University of Kerman (SBUK)
RP Hosseini, S (corresponding author), Shahid Bahonar Univ Kerman, Fac Math & Comp, Dept Comp Sci, Kerman, Iran.
EM z.asghari@math.uk.ac.ir; so_hosseini@uk.ac.ir; Javidi@uk.ac.ir
RI javidi, mohammad masoud/AAE-9992-2020; Asghari Varzaneh,
   Zahra/JPY-2561-2023
OI javidi, mohammad masoud/0000-0002-7955-8220; Asghari Varzaneh,
   Zahra/0000-0003-3173-6849
CR Abdel-Basset M, 2020, EXPERT SYST APPL, V139, DOI 10.1016/j.eswa.2019.112824
   Al-Tashi Q, 2019, IEEE ACCESS, V7, P39496, DOI 10.1109/ACCESS.2019.2906757
   Al-Wajih R, 2021, IEEE ACCESS, V9, P31662, DOI 10.1109/ACCESS.2021.3060096
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Arora S, 2019, EXPERT SYST APPL, V116, P147, DOI 10.1016/j.eswa.2018.08.051
   Bello R, 2007, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, P691, DOI 10.1109/ISDA.2007.101
   Bhattacharya S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020219
   Blachnik M, 2019, INT J AP MAT COM-POL, V29, P151, DOI 10.2478/amcs-2019-0012
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chizi B., 2009, ENCY DATA WAREHOUSIN, VSecond, P1888, DOI DOI 10.4018/978-1-60566-010-3.CH289
   Cui Y, 2017, INT ARAB J INF TECHN, V14
   Dash M., 1997, Intelligent Data Analysis, V1
   Dhiman G, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106560
   Dua D., 2017, UCI MACHINE LEARNING
   Emary E, 2016, NEUROCOMPUTING, V213, P54, DOI 10.1016/j.neucom.2016.03.101
   Emary E, 2016, NEUROCOMPUTING, V172, P371, DOI 10.1016/j.neucom.2015.06.083
   Ewees AA, 2019, NEURAL COMPUT APPL, V31, P991, DOI 10.1007/s00521-017-3131-4
   Faris H, 2018, KNOWL-BASED SYST, V154, P43, DOI 10.1016/j.knosys.2018.05.009
   Fayyad U, 1996, AI MAG, V17, P37
   Gadekallu RT, 2021, Recent Advances in Computer Science and Communications (Formerly: Recent Patents on Computer Science), V14, DOI [DOI 10.2174/2213275911666181030124333, 10.2174/2213275911666181030124333]
   Gao YY, 2020, IEEE ACCESS, V8, P140936, DOI 10.1109/ACCESS.2020.3013617
   García S, 2010, INFORM SCIENCES, V180, P2044, DOI 10.1016/j.ins.2009.12.010
   Ghosh K.K., 2020, BEO: Binary Equilibrium Optimizer Combined with Simulated Annealing for Feature Selection, DOI [10.21203/rs.3.rs-28683/v1, DOI 10.21203/RS.3.RS-28683/V1]
   Ghosh KK, 2021, NEURAL COMPUT APPL, V33, P11027, DOI 10.1007/s00521-020-05560-9
   Goldberg D.E., 1989, Genetic Algorithms in Search, Optimization, and Machine Learning
   Guha R, 2020, SOFT COMPUT, V24, P12821, DOI 10.1007/s00500-020-05183-1
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Han J, 2012, MOR KAUF D, P1
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hussain K, 2021, EXPERT SYST APPL, V176, DOI 10.1016/j.eswa.2021.114778
   Kabir MM, 2011, NEUROCOMPUTING, V74, P2914, DOI 10.1016/j.neucom.2011.03.034
   Karegowda A.G., 2010, International journal of Computer applications, V1, P13
   Kashef S, 2015, NEUROCOMPUTING, V147, P271, DOI 10.1016/j.neucom.2014.06.067
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Li JD, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3136625
   Liu H., 2012, Feature Selection for Knowledge Discovery and Data Mining, V454
   Mafarja M, 2017, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON FUTURE NETWORKS AND DISTRIBUTED SYSTEMS (ICFNDS '17), DOI 10.1145/3102304.3102325
   Mafarja M, 2018, APPL SOFT COMPUT, V62, P441, DOI 10.1016/j.asoc.2017.11.006
   MiarNaeimi F, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106711
   Mirjalili S, 2017, ADV ENG SOFTW, V114, P163, DOI 10.1016/j.advengsoft.2017.07.002
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mirjalili S, 2013, SWARM EVOL COMPUT, V9, P1, DOI 10.1016/j.swevo.2012.09.002
   Neggaz N, 2020, EXPERT SYST APPL, V152, DOI 10.1016/j.eswa.2020.113364
   POLI R, 2007, SWARM INTELL-US, V1, P33, DOI [DOI 10.1007/S11721-007-0002-0, DOI 10.1109/ICNN.1995.488968]
   Punitha S, 2022, COMPUT METH PROG BIO, V214, DOI 10.1016/j.cmpb.2021.106432
   Ramírez-Gallego S, 2017, INT J INTELL SYST, V32, DOI 10.1002/int.21833
   Reddy GT, 2020, IEEE ACCESS, V8, P54776, DOI 10.1109/ACCESS.2020.2980942
   SaiSindhuTheja R, 2021, APPL SOFT COMPUT, V100, DOI 10.1016/j.asoc.2020.106997
   Song XF, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107804
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tu Q, 2019, APPL SOFT COMPUT, V76, P16, DOI 10.1016/j.asoc.2018.11.047
   Vergara JR, 2014, NEURAL COMPUT APPL, V24, P175, DOI 10.1007/s00521-013-1368-0
   WILCOXON F, 1945, BIOMETRICS BULL, V1, P80, DOI 10.1093/jee/39.2.269
   Zhang LF, 2015, NEUROCOMPUTING, V148, P3, DOI 10.1016/j.neucom.2012.07.063
   Zhang X, 2020, EXPERT SYST APPL, V141, DOI 10.1016/j.eswa.2019.112976
   Zorarpaci E, 2016, EXPERT SYST APPL, V62, P91, DOI 10.1016/j.eswa.2016.06.004
NR 56
TC 2
Z9 2
U1 4
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD NOV
PY 2023
VL 82
IS 26
BP 40309
EP 40343
DI 10.1007/s11042-023-15023-7
EA MAR 2023
PG 35
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA X7DJ1
UT WOS:000955293100004
DA 2024-07-18
ER

PT J
AU Idrissi, S
   El Fezazi, N
   Tissir, E
   Boumhidi, I
AF Idrissi, Said
   El Fezazi, Nabil
   Tissir, El Houssaine
   Boumhidi, Ismail
TI H<sub>8</sub> filter design for nonlinear systems with interval
   time-varying delay via T-S fuzzy models
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Filters; Nonlinear systems; Disturbances; T-S fuzzy approach;
   Time-varying delay
ID H-INFINITY FILTER; STABILITY
AB This paper addresses the H-infinity filters design problem for delayed nonlinear systems subject to L-2-norm disturbances via Takagi-Sugeno (T-S) fuzzy approach with interval time-varying delay. An appropriate Lyapunov-Krasovskii functional (LKF) is established in the framework of augmented system. Then, on the basis of the free-weighting matrix technique and convex method, some improved integral inequality are employed and combined with a decoupling approach without ignoring any useful terms. Therefore, less conservative delay dependent conditions are obtained in terms of linear matrix inequality (LMIs), wish can be solved by using the Matlab LMI toolbox, to achieve the desired H-infinity performance. Finally, three numerical examples are given to demonstrate the advantages and the effectiveness of the obtained results, compared with some previous method in the literature.
C1 [Idrissi, Said] Cadi Ayyad Univ, Polydisciplinary Fac Safi, LPFAS Lab, Safi, Morocco.
   [El Fezazi, Nabil; Tissir, El Houssaine; Boumhidi, Ismail] Sidi Mohammed Ben Abdellah Univ, Fac Sci Dhar El Mehraz, Dept Phys, LISAC Lab, Fes, Morocco.
C3 Cadi Ayyad University of Marrakech; Sidi Mohamed Ben Abdellah University
   of Fez
RP El Fezazi, N (corresponding author), Sidi Mohammed Ben Abdellah Univ, Fac Sci Dhar El Mehraz, Dept Phys, LISAC Lab, Fes, Morocco.
EM Said_idrissi09@yahoo.fr; nabil.elfezazi@gmail.com
RI Boumhidi, Ismail/HTT-5066-2023; EL FEZAZI, Nabil/JDV-9643-2023
OI EL FEZAZI, Nabil/0000-0001-8052-5007
CR Ahmida F., 2014, APPL MATH SCI, V8, P8179
   Ahmida F, 2015, Br J Math Comput Sci, V6, P215, DOI [10.9734/BJMCS/2015/13916, DOI 10.9734/BJMCS/2015/13916]
   Sadek BA, 2019, IET CONTROL THEORY A, V13, P1971, DOI 10.1049/iet-cta.2018.6466
   Anderson B. D. O., 1979, OPTIMAL FILTERING
   Basin M, 2011, INT J INNOV COMPUT I, V7, P1565
   Boukili B, 2016, INT CONF SYST CONTRO, P326, DOI 10.1109/ICoSC.2016.7507029
   Chaibi R, 2020, INT J CONTROL AUTOM, V18, P1872, DOI 10.1007/s12555-018-0802-6
   Cheng J, 2021, IEEE T FUZZY SYST, V29, P1375, DOI 10.1109/TFUZZ.2020.2974440
   Cheng J, 2020, NONLINEAR DYNAM, V100, P509, DOI 10.1007/s11071-020-05501-0
   El Aiss H, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON SYSTEMS AND CONTROL (ICSC), P313, DOI 10.1109/ICoSC.2018.8587814
   El Aiss H, 2017, INT J SYST SCI, V48, P3450, DOI 10.1080/00207721.2017.1384963
   El Aiss H, 2019, INT J SYST SCI, V50, P35, DOI 10.1080/00207721.2018.1543474
   El Fezazi N, 2019, IJST-T ELECTR ENG, V43, P813, DOI 10.1007/s40998-019-00204-8
   El Fezazi N, 2019, J CONTROL AUTOM ELEC, V30, P645, DOI 10.1007/s40313-019-00490-x
   El Fezazi N, 2019, INT J ROBUST NONLIN, V29, P1719, DOI 10.1002/rnc.4463
   El-Amrani A, 2018, MED C CONTR AUTOMAT, P807, DOI 10.1109/MED.2018.8443021
   El-Amrani A, 2018, INT J SYST SCI, V49, P43, DOI 10.1080/00207721.2017.1391960
   El-Kasri C, 2013, MULTIDIM SYST SIGN P, V24, P685, DOI 10.1007/s11045-013-0242-7
   Farkous R, 2016, INT CONF SYST CONTRO, P288, DOI 10.1109/ICoSC.2016.7507045
   Gao H, 2005, IEE P-CONTR THEOR AP, V152, P531, DOI 10.1049/ip-cta:20045050
   Han XJ, 2019, INT J CONTROL AUTOM, V17, P46, DOI 10.1007/s12555-018-0279-3
   Huang H, 2020, IEEE INTERNET THINGS, V7, P5713, DOI 10.1109/JIOT.2019.2948396
   Huang SJ, 2011, IEEE T FUZZY SYST, V19, P193, DOI 10.1109/TFUZZ.2010.2089632
   Hussain W, 2022, INFORM SCIENCES, V584, P280, DOI 10.1016/j.ins.2021.10.054
   Idrissi S., 2017, International Journal of Automation and Smart Technology, V7, P71, DOI 10.5875/ausmt.v7i2.1278
   Idrissi S, 2014, INT J ECOL DEV, V28, P96
   Idrissi S, 2020, 6 IEEE INT C OPTIMIZ, P1
   Idrissi S, 2013, INT J CONTROL AUTOM, V11, P885, DOI 10.1007/s12555-012-9319-6
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kim JH, 2010, INT J CONTROL AUTOM, V8, P655, DOI 10.1007/s12555-010-0319-0
   Lamrabet O, 2020, J CONTROL AUTOM ELEC, V31, P588, DOI 10.1007/s40313-020-00582-z
   Lamrabet O, 2020, INT J CONTROL AUTOM, V18, P2242, DOI [10.1007/s12555-019-0173-5, 10.1007/s12555-019-0017-5]
   Lamrabet O, 2019, CIRC SYST SIGNAL PR, V38, P2055, DOI 10.1007/s00034-018-0971-9
   Lian Z, 2020, IEEE T CYBERNETICS, V50, P2580, DOI 10.1109/TCYB.2018.2890425
   Lin C, 2008, IEEE T FUZZY SYST, V16, P739, DOI 10.1109/TFUZZ.2007.905915
   Lin YC, 2005, INT J SYST SCI, V36, P993, DOI 10.1080/00207720500404797
   Liu YJ, 2019, IEEE T FUZZY SYST, V27, P790, DOI 10.1109/TFUZZ.2018.2870079
   Liu YJ, 2018, IEEE T FUZZY SYST, V26, P2089, DOI 10.1109/TFUZZ.2017.2762633
   Qiu JB, 2009, ASIA CONTROL CONF AS, P1006
   Su YK, 2009, FUZZY SET SYST, V160, P3539, DOI 10.1016/j.fss.2009.07.003
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Wang XB, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319400010
   Wu LG, 2009, IEEE T SYST MAN CY B, V39, P1308, DOI 10.1109/TSMCB.2008.2012350
   Xu SY, 2004, ENG APPL ARTIF INTEL, V17, P645, DOI 10.1016/j.engappai.2004.08.012
   Yang FW, 2002, IEEE T AUTOMAT CONTR, V47, P1179, DOI 10.1109/TAC.2002.800668
   Yang XX, 2019, IEEE ACCESS, V7, P70662, DOI 10.1109/ACCESS.2019.2919189
   Zhang HG, 2007, IEEE T FUZZY SYST, V15, P453, DOI 10.1109/TFUZZ.2006.889841
   Zhang JH, 2009, IEEE T FUZZY SYST, V17, P128, DOI 10.1109/TFUZZ.2008.2007424
   Zhang ZY, 2016, INT J FUZZY SYST, V18, P904, DOI 10.1007/s40815-015-0126-0
   Zhou T, 2015, INT J AUTOM COMPUT, V12, P671, DOI 10.1007/s11633-015-0930-x
   Zoulagh T., 2018, INT J DIGITAL SIGNAL, V2, P150, DOI [10.1504/IJDSSS.2018.093195, DOI 10.1504/IJDSSS.2018.093195]
   Zoulagh T, 2018, INT J SYST SCI, V49, P2061, DOI 10.1080/00207721.2018.1483540
NR 52
TC 0
Z9 0
U1 3
U2 10
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25829
EP 25846
DI 10.1007/s11042-023-14582-z
EA MAR 2023
PG 18
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000946494700003
DA 2024-07-18
ER

PT J
AU Luis, M
   Daniel, L
   Isabel, A
   Deicy, A
AF Luis, Mendez
   Daniel, Ladino
   Isabel, Amaya
   Deicy, Alvarado
TI A new multimedia cryptosystem using chaos, quaternion theory and modular
   arithmetic
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Quaternions; Chaos; Cryptosystem; Multimedia; Modular arithmetic;
   Residual matrices
ID IMAGE ENCRYPTION; ALGORITHM; TRANSFORM; DNA
AB Based on the combination of quaternion numbers, residual matrices, and chaotic attractors, a new cryptosystem is proposed for multimedia processing files such as images and audio. The key employed in this encryption schema consists of an image with a wide and sensitive range, obtained from the Julia Quaternion set rendered using a computational tool. Due to the use of quaternion matrices mixing the information between RGB layers and audio samples was possible, whereas using XOR operation and residual matrices modulus 257, added high sensitivity to small perturbations during encryption, key preparation and decryption processes, to such an extent that a minimal change in the image or in the audio leads to a totally different encryption result. The use of dynamic programming also reduced the processing time for matrix operations on the Z(257) ring. To corroborate security of the algorithm, different tests were performed, including the National Institute of Standards and Technology test obtaining different indicators that were compared with other scientific references of similar works, finding behavioral patterns in accordance with those referenced works.
C1 [Luis, Mendez; Daniel, Ladino; Isabel, Amaya; Deicy, Alvarado] Univ Distrital Francisco Jose de Caldas, Engn Fac, Complex Res Grp COMPLEXUD, Bogota 110231, Colombia.
C3 Universidad Distrital Francisco Jose de Caldas
RP Luis, M (corresponding author), Univ Distrital Francisco Jose de Caldas, Engn Fac, Complex Res Grp COMPLEXUD, Bogota 110231, Colombia.
EM lemendezl@correo.udistrital.edu.co; deladinot@correo.udistrital.edu.co;
   iamaya@udistrital.edu.co; lalvarado@udistrital.edu.co
RI Deicy, Alvarado-Nieto/KCK-3912-2024; Amaya Barrera, Edilma
   Isabel/HKW-3910-2023
OI Mendez, Luis/0000-0003-2757-6379
FU Colombia Consortium
FX Open Access funding provided by Colombia Consortium
CR Abu Taha M, 2020, CRYPTOGRAPHY-BASEL, V4, DOI 10.3390/cryptography4020018
   Ahmad I, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116418
   Albahrani Ekhlas Abbas, 2017, 2017 Annual Conference on New Trends in Information & Communications Technology Applications (NTICT), P22, DOI 10.1109/NTICT.2017.7976129
   Anand R, 2009, INT J COMPUT SCI NET
   Anghelescu P., 2012, 2012 World Congress on Internet Security (WorldCIS-2012), P11
   Banik A, 2019, J INF SECUR APPL, V49, DOI 10.1016/j.jisa.2019.102398
   Bassham III LE, 2010, Sp 800-22 rev. 1a. a statistical test suite for random and pseudorandom number generators for cryptographic applications, DOI DOI 10.6028/NIST.SP.800-22R1A
   Boussif M, 2019, MULTIMED TOOLS APPL, V78, P35493, DOI 10.1007/s11042-019-08108-9
   Chen BJ, 2018, IET IMAGE PROCESS, V12, P2238, DOI 10.1049/iet-ipr.2018.5440
   Devaney R.L., 1948, INTRO CHAOTIC DYNAMI
   Dzwonkowski M, 2019, IEEE T IMAGE PROCESS, V28, P371, DOI 10.1109/TIP.2018.2868388
   Dzwonkowski M, 2015, IEEE T IMAGE PROCESS, V24, P4614, DOI 10.1109/TIP.2015.2467317
   Fang PF, 2021, IEEE ACCESS, V9, P18497, DOI 10.1109/ACCESS.2020.3040573
   Rodríguez IF, 2017, INGENIERIA-BOGOTA, V22, P396, DOI 10.14483/23448393.11976
   Kamlofsky J, DIFFIE HELLMAN COMPA, DOI [10.13140/RG.2.1.4063.1760, DOI 10.13140/RG.2.1.4063.1760]
   Kasianchuk M, 2017, EXP DES APPL CAD SYS, P222, DOI 10.1109/CADSM.2017.7916120
   Khalil M, 2017, INT J COMMUNICATION, V9
   Khan M, 2020, NEURAL COMPUT APPL, V32, P11837, DOI 10.1007/s00521-019-04667-y
   Kuipers Jack B, 2000, P INT C GEOMETRY INT, V1, P127, DOI DOI 10.7546/GIQ-1-2000-127-143
   Kumar G, 2017, SECUR COMMUN NETW, P1, DOI 10.1155/2017/9036382
   Li Q, 2022, IEEE T CIRC SYST VID, V32, P5695, DOI 10.1109/TCSVT.2021.3138795
   Lima JB, 2016, MULTIMED TOOLS APPL, V75, P8403, DOI 10.1007/s11042-015-2755-6
   Liu HJ, 2012, APPL SOFT COMPUT, V12, P1457, DOI 10.1016/j.asoc.2012.01.016
   Liu HJ, 2011, OPT COMMUN, V284, P3895, DOI 10.1016/j.optcom.2011.04.001
   Liu HJ, 2010, COMPUT MATH APPL, V59, P3320, DOI 10.1016/j.camwa.2010.03.017
   Liu ZT, 2019, IEEE ACCESS, V7, P78367, DOI 10.1109/ACCESS.2019.2922376
   Masood F, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030274
   Min LQ, 2013, PROCEEDINGS OF THE 2013 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT CONTROL AND INFORMATION PROCESSING (ICICIP), P545
   Mohamed Heba G, 2020, Entropy (Basel), V22, DOI 10.3390/e22020158
   Nagase T, 2004, 18TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 2 (REGULAR PAPERS), PROCEEDINGS, P35
   Niu YJ, 2020, MATH PROBL ENG, V2020, DOI 10.1155/2020/6795964
   Niyat AY, 2020, MULTIMED TOOLS APPL, V79, P1497, DOI 10.1007/s11042-019-08247-z
   Pak C, 2019, MULTIMED TOOLS APPL, V78, P12027, DOI 10.1007/s11042-018-6739-1
   Risqi YSS, 2017, INT C TELECOMMUN SYS
   Salim MZ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010136
   Sokouti Massoud, 2016, Open Med Inform J, V10, P11
   Soni R, 2013, INT CONF COMM SYST, P478, DOI 10.1109/CSNT.2013.105
   Su Z., 2012, Multimedia-A Multidisciplinary Approach to Complex Issues
   Tawalbeh L, 2013, IET INFORM SECUR, V7, P67, DOI 10.1049/iet-ifs.2012.0147
   Valluri M, 2016, QUATERNION PUBLIC KE, DOI [10.1109/WCICSS.2016.7882612, DOI 10.1109/WCICSS.2016.7882612]
   Wang XY, 2010, NONLINEAR DYNAM, V62, P615, DOI 10.1007/s11071-010-9749-8
   Wang XY, 2022, IEEE T CIRCUITS-I, V69, P1291, DOI 10.1109/TCSI.2021.3133318
   Wang XY, 2021, INFORM SCIENCES, V579, P128, DOI 10.1016/j.ins.2021.07.096
   Wu Y, 2013, INFORM SCIENCES, V222, P323, DOI 10.1016/j.ins.2012.07.049
   Xian YS, 2022, INT J COAL PREP UTIL, V42, P3249, DOI 10.1080/19392699.2021.1949712
   Xiang HY, 2020, MULTIMED TOOLS APPL, V79, P30329, DOI 10.1007/s11042-020-09595-x
   Xie DH, 2007, EURASIP J INF SECUR, DOI 10.1155/2007/35262
   Xing XM, 2015, KSII T INTERNET INF, V9, P5058, DOI 10.3837/tiis.2015.12.017
   Ye HS, 2020, SIGNAL PROCESS, V175, DOI 10.1016/j.sigpro.2020.107652
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   Yu CY, 2018, MULTIMED TOOLS APPL, V77, P4585, DOI 10.1007/s11042-017-4637-6
   Zhang XQ, 2021, OPT LASER TECHNOL, V141, DOI 10.1016/j.optlastec.2021.107073
   Zhang X, 2018, IEEE ACCESS, V6, P18074, DOI 10.1109/ACCESS.2018.2820724
   Zheng J, 2022, INFORM SCIENCES, V587, P226, DOI 10.1016/j.ins.2021.12.030
   Zhu SQ, 2019, IEEE ACCESS, V7, P147106, DOI 10.1109/ACCESS.2019.2946208
NR 56
TC 0
Z9 0
U1 0
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 23
BP 35149
EP 35181
DI 10.1007/s11042-023-14475-1
EA MAR 2023
PG 33
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA DA7P6
UT WOS:000946494700011
PM 37362649
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Chu, R
   Zhang, SF
   Mou, J
   Gao, XY
AF Chu, Ran
   Zhang, Shufang
   Mou, Jun
   Gao, Xinyu
TI A zero-watermarking for color image based on LWT-SVD and chaotic system
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE LWT; SVD; Chaotic system; Watermark; Zero-watermarking
ID RGB CHANNEL; ALGORITHM; ENCRYPTION; ALGEBRA
AB A zero-watermarking algorithm for color image based on lifting wavelet transform (LWT), singular value decomposition (SVD) and chaotic system is proposed in this paper. Firstly, the characteristics of a 5-D chaotic system are analyzed by phase diagrams, Lyapunov exponent spectrums and bifurcation diagrams. The initial conditions of the chaotic system are changed by hash value calculated from the watermark image. Then, feature information of low-frequency region of color image is extracted by LWT, and the maximum singular value is obtained by improved SVD. Based on chaos correction factor, the feature matrix can be extracted and encrypted by SVD simultaneously. And the watermark image is composed of meaningful single watermark or combined watermark. Finally, zero-watermarking is generated by encryption and logical operation of feature matrix and watermark image. During authentication, the watermark image can be extracted from the color image and the registered zero-watermarking, and the copyright ownership can be determined according to the registration time. This algorithm can effectively protect image copyright without changing image and has good robustness. Experiments verify the effectiveness of the algorithm and its ability to resist filtering, compression, rotation, noise and clipping attacks, and the NC value of each attack is higher than 89%.
C1 [Chu, Ran; Zhang, Shufang] Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116026, Peoples R China.
   [Chu, Ran; Mou, Jun; Gao, Xinyu] Dalian Polytech Univ, Informat Sci & Engn Coll, Dalian 116034, Peoples R China.
C3 Dalian Maritime University; Dalian Polytechnic University
RP Chu, R (corresponding author), Dalian Maritime Univ, Informat Sci & Technol Coll, Dalian 116026, Peoples R China.; Chu, R (corresponding author), Dalian Polytech Univ, Informat Sci & Engn Coll, Dalian 116034, Peoples R China.
EM shirley_churan@sina.com
RI chu, ran/GXV-4850-2022
OI chu, ran/0000-0001-5760-4903
FU National Natural Science Foundation of China [61231006, 61501078]
FX This research was funded by the National Natural Science Foundation of
   China (No. 61231006 and No. 61501078).
CR Bhatti UA, 2020, IEEE ACCESS, V8, P155783, DOI 10.1109/ACCESS.2020.3018544
   Bhatti UA, 2020, IEEE ACCESS, V8, P76386, DOI 10.1109/ACCESS.2020.2988298
   Chai XL, 2019, SIGNAL PROCESS, V155, P44, DOI 10.1016/j.sigpro.2018.09.029
   Chen J, 2021, INT C INTELLIGENT AU, P1091, DOI [10.1007/978-3-030-81007-8_125, DOI 10.1007/978-3-030-81007-8_125]
   [陈青 Chen Qing], 2016, [计算机应用研究, Application Research of Computers], V33, P2810
   Gan ZH, 2021, NEURAL COMPUT APPL, V33, P12845, DOI 10.1007/s00521-021-05937-4
   Gao XY, 2022, J KING SAUD UNIV-COM, V34, P1535, DOI 10.1016/j.jksuci.2022.01.017
   Gao XY, 2022, NONLINEAR DYNAM, V108, P613, DOI 10.1007/s11071-021-07192-7
   Hemis M, 2014, INT C ADV COMP SCI I, P189, DOI 10.1109/ICACSIS.2014.7065826
   Hosny KM, 2021, BIOMED SIGNAL PROCES, V70, DOI 10.1016/j.bspc.2021.103007
   Hosny KM, 2021, IEEE ACCESS, V9, P91209, DOI 10.1109/ACCESS.2021.3091614
   Jain M, 2017, INT J MACH LEARN CYB, V8, P1695, DOI 10.1007/s13042-016-0542-y
   Jiang FF, 2020, MULTIMED TOOLS APPL, V79, P7599, DOI 10.1007/s11042-019-08459-3
   [江泽涛 Jiang Zetao], 2016, [微电子学与计算机, Microelectronics & Computer], V33, P107
   Kaige Zhu, 2020, MATEC Web of Conferences, V309, DOI 10.1051/matecconf/202030903017
   Kang XB, 2020, MULTIMED TOOLS APPL, V79, P1169, DOI 10.1007/s11042-019-08191-y
   Kang XB, 2020, J VIS COMMUN IMAGE R, V70, DOI 10.1016/j.jvcir.2020.102804
   Kazemi MF, 2022, EVOL SYST-GER, V13, P145, DOI 10.1007/s12530-021-09369-2
   Kumar A, 2011, COMMUN NONLINEAR SCI, V16, P372, DOI 10.1016/j.cnsns.2010.04.010
   Li TF, 2022, EURASIP J WIREL COMM, V2022, DOI 10.1186/s13638-022-02106-6
   Li XJ, 2022, INT J BIFURCAT CHAOS, V32, DOI 10.1142/S0218127422500353
   Liao X, 2022, IEEE T DEPEND SECURE, V19, P897, DOI 10.1109/TDSC.2020.3004708
   Liao X, 2020, IEEE T CIRC SYST VID, V30, P685, DOI 10.1109/TCSVT.2019.2896270
   Liu F., 2018, J. Inf. Hiding Multimed. Signal Process. C, V9, P629
   Liu Wanjun, 2019, Journal of Frontiers of Computer Science and Technology, V13, P494, DOI 10.3778/j.issn.1673-9418.1712040
   Ma XJ, 2020, NONLINEAR DYNAM, V100, P2859, DOI 10.1007/s11071-020-05601-x
   Pan H., 2011, J GUILIN U ELECT TEC, V31, P399, DOI [10.3969/j.issn.1673-808X.2011.05.013, DOI 10.3969/J.ISSN.1673-808X.2011.05.013]
   Rhouma R, 2009, CHAOS SOLITON FRACT, V40, P309, DOI 10.1016/j.chaos.2007.07.083
   Salim MZ, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11010136
   Song W, 2009, ACTA PHYS SIN-CH ED, V58, P4449, DOI 10.7498/aps.58.4449
   Tan JX, 2022, IEEE T NETW SCI ENG, V9, P888, DOI 10.1109/TNSE.2021.3139671
   Wang YR, 2011, EXPERT SYST APPL, V38, P8024, DOI 10.1016/j.eswa.2010.12.129
   Wei XP, 2012, J SYST SOFTWARE, V85, P290, DOI 10.1016/j.jss.2011.08.017
   Wei-an L., 2019, MICROELECTRON COMPUT, V36, P30, DOI [10.19304/j.cnki.issn1000-7180.2019.11.007, DOI 10.19304/J.CNKI.ISSN1000-7180.2019.11.007]
   Wen JJ, 2021, IEEE ACCESS, V9, P167920, DOI 10.1109/ACCESS.2021.3136249
   Wen Q, 2001, P 3 NATL C INFORM HI, V109, DOI [10.3321/j.issn:0372-2112.2003.02.015, DOI 10.3321/J.ISSN:0372-2112.2003.02.015]
   Wu DY, 2021, SECUR COMMUN NETW, V2021, DOI 10.1155/2021/7081194
   Xiong Xiang-guang, 2017, Computer Engineering and Science, V39, P103, DOI 10.3969/j.issn.1007-130X.2017.01.014
   [熊祥光 Xiong Xiangguang], 2018, [自动化学报, Acta Automatica Sinica], V44, P160
   Yamni M, 2021, MULTIMED TOOLS APPL, V80, P21679, DOI 10.1007/s11042-021-10717-2
   Yousif SF, 2022, MULTIMED TOOLS APPL, V81, P27453, DOI 10.1007/s11042-022-12762-x
   Yousif SF, 2020, IEEE ACCESS, V8, P155184, DOI 10.1109/ACCESS.2020.3019216
   [张海涛 Zhang Haitao], 2019, [计算机应用研究, Application Research of Computers], V36, P3387
   Zheng QM, 2020, J INF PROCESS SYST, V16, P1391, DOI 10.3745/JIPS.02.0150
NR 44
TC 3
Z9 3
U1 4
U2 30
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 22
BP 34565
EP 34588
DI 10.1007/s11042-023-15015-7
EA MAR 2023
PG 24
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q5DM0
UT WOS:000945792800011
DA 2024-07-18
ER

PT J
AU Pandey, A
   Kumar, A
AF Pandey, Ankita
   Kumar, Arun
TI An integrated approach for breast cancer classification
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Binary classifier; Benign classifier; Malignant classifier; Transfer
   learning; Xception; BreaKHis
AB This proposed breast cancer classification work aims to generate an automated, reliable, robust, and combined system for early breast cancer detection. In this proposed work, three transfer learning-based classifiers Binary, Benign, and Malignant are constructed. The Binary classifier classifies breast cancer as benign and malignant, the Benign classifier classifies four sub-classes of benign cancer and the Malignant classifier classifies four sub-classes of malignant cancer. All three classifiers are individually trained for their corresponding classification task and then integrated to give the outcome of the combined proposed system. As a result, the proposed system automatically classifies cancer into its major class and then sub-class with greater accuracy. The proposed breast cancer classification work is performed on BreaKHis and Breast cancer histology image (BACH) data. The classification performance of all three classifiers and the combined system is measured in terms of accuracy, recall (sensitivity), precision, and f1-score and then further compared with state-of-the-art works.
C1 [Pandey, Ankita; Kumar, Arun] G B Pant Univ Agr & Technol, Dept Math Stat & Comp Sci, Pantnagar 263145, India.
C3 Govind Ballabh Pant University of Agriculture Technology
RP Pandey, A (corresponding author), G B Pant Univ Agr & Technol, Dept Math Stat & Comp Sci, Pantnagar 263145, India.
EM ankitapandey0595@gmail.com; Arun_pal1969@yahoo.co.in
OI Pandey, Ankita/0000-0002-5242-7255; Kumar, Arun/0000-0001-9837-1720
CR Ali MS, 2021, MACH LEARN APPL, V5, DOI 10.1016/j.mlwa.2021.100036
   [Anonymous], 2015, Breast Cancer
   [Anonymous], NEW GLOBAL BREAST CA
   [Anonymous], COMM BREAST CANC
   Aresta G, 2019, MED IMAGE ANAL, V56, P122, DOI 10.1016/j.media.2019.05.010
   Bardou D, 2018, IEEE ACCESS, V6, P24680, DOI 10.1109/ACCESS.2018.2831280
   Boumaraf S, 2021, BIOMED SIGNAL PROCES, V63, DOI 10.1016/j.bspc.2020.102192
   Budak Ü, 2019, APPL SOFT COMPUT, V85, DOI 10.1016/j.asoc.2019.105765
   Burçak KC, 2021, J SUPERCOMPUT, V77, P973, DOI 10.1007/s11227-020-03321-y
   Chen DH, 2021, IEEE ACM T COMPUT BI, V18, P891, DOI 10.1109/TCBB.2019.2955484
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chowdhury D, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030832
   Deniz E, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0057-x
   Gessert N, 2019, INT J COMPUT ASS RAD, V14, P1837, DOI 10.1007/s11548-019-02004-1
   Han T, 2020, IEEE ACCESS, V8, P71117, DOI 10.1109/ACCESS.2020.2987932
   Han Y, 2021, EUR J NUCL MED MOL I, V48, P350, DOI 10.1007/s00259-020-04771-5
   IARC Publications, WORLD CANC REP CANC
   Inan MSK, 2022, BIOMED SIGNAL PROCES, V75, DOI 10.1016/j.bspc.2022.103553
   Karimi D, 2021, ARTIF INTELL MED, V116, DOI 10.1016/j.artmed.2021.102078
   Kausar T, 2019, BIOCYBERN BIOMED ENG, V39, P967, DOI 10.1016/j.bbe.2019.09.003
   Kumar K, 2019, J VIS COMMUN IMAGE R, V58, P345, DOI 10.1016/j.jvcir.2018.12.009
   Kumar K, 2018, MULTIMED TOOLS APPL, V77, P26635, DOI 10.1007/s11042-018-5882-z
   Kumar K, 2018, IEEE T MULTIMEDIA, V20, P323, DOI 10.1109/TMM.2017.2741423
   Melekoodappattu JG, 2022, J AMB INTEL HUM COMP, DOI 10.1007/s12652-022-03713-3
   Pandey A, 2022, 2022 IEEE DELH SECT, P1, DOI [10.1109/DELCON54057.2022.9753643, DOI 10.1109/DELCON54057.2022.9753643]
   Shivhare SN, 2021, MULTIMED TOOLS APPL, V80, P26969, DOI 10.1007/s11042-021-10969-y
   Singh S, 2022, MULTIMED TOOLS APPL, V81, P5849, DOI 10.1007/s11042-021-11775-2
   Spanhol FA, 2016, IEEE T BIO-MED ENG, V63, P1455, DOI 10.1109/TBME.2015.2496264
   Togaçar M, 2020, PHYSICA A, V545, DOI 10.1016/j.physa.2019.123592
   Togaçar M, 2020, MED HYPOTHESES, V134, DOI 10.1016/j.mehy.2019.109531
   Wang YQ, 2021, IEEE ACM T COMPUT BI, V18, P951, DOI 10.1109/TCBB.2019.2911947
NR 31
TC 1
Z9 1
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 33357
EP 33377
DI 10.1007/s11042-023-14782-7
EA MAR 2023
PG 21
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943163700003
DA 2024-07-18
ER

PT J
AU Renugambal, A
   Bhuvaneswari, KS
   Tamilarasan, A
AF Renugambal, A.
   Bhuvaneswari, K. Selva
   Tamilarasan, A.
TI Hybrid SCCSA: An efficient multilevel thresholding for enhanced image
   segmentation
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multilevel thresholding; Image segmentation; Hybridization strategy;
   Metaheuristics; SCCSA algorithm
ID WOLF OPTIMIZER; ENTROPY; ALGORITHM
AB In a variety of image processing applications, multilevel thresholding image segmentation has gotten a lot of interest. When traditional approaches are utilised, however, the process of obtaining the ideal threshold values takes time. Despite the fact that Hybrid metaheuristic methods can be used to overcome these limits, such approaches may be ineffective when dealing with a local solution. The present study proposes a multi-level image thresholding based hybridization strategy based Sine-Cosine Crow Search Algorithm(SCCSA) to make more efficient image segmentation. The main limitation of the classical Crow Search Algorithm (CSA) is that search agents sometimes do not produce the best solutions. To update a solution to the best solution, each search agent can use Sine-Cosine Algorithm (SCA) movements to update its position accordingly. This ensures a good balance between two goals (exploration and exploitation) would improve the efficiency of the search algorithm. The optimal threshold values are searched by the chosen objective functions of the otsu's and kapur's entropy approaches. The hybrid algorithm is evaluated in 12 standard image sets and then compared with the performance of other state-of-the-art algorithms such as ICSA, SCA, CSA and ABC. Experimental results showed that, in different metrics of the output such as objective function values, PSNR, STD values, Mean, SSIM, FSIM and CPU time, the proposed algorithm is consistently higher than other algorithms. In addition, the wilcoxon test is performed using the proposed algorithm to detect the significant differences between the other algorithms. The findings indicated that the proposed SCCSA succeeds with other well-known algorithms and has dominance over robust, accurate and convergent values.
C1 [Renugambal, A.] Univ Coll Engn Kancheepuram, Dept Math, Kanchipuram 631552, Tamilnadu, India.
   [Bhuvaneswari, K. Selva] Univ Coll Engn Kancheepuram, Dept Comp Sci & Engn, Kanchipuram 631552, Tamilnadu, India.
   [Tamilarasan, A.] Sri Chandrasekharendra Saraswathi Viswa Mahavidya, Dept Mech Engn, Kanchipuram 631561, Tamilnadu, India.
C3 Sri Chandrasekharendra Saraswathi Viswa Mahavidyalaya
RP Renugambal, A (corresponding author), Univ Coll Engn Kancheepuram, Dept Math, Kanchipuram 631552, Tamilnadu, India.
EM renutjn2016@gmail.com
RI Tamilarasan, A/K-8597-2013
OI Tamilarasan, A/0000-0001-6181-1761; Renugambal, A/0000-0002-6153-9945
CR Abd El Aziz M, 2017, EXPERT SYST APPL, V83, P242, DOI 10.1016/j.eswa.2017.04.023
   Abd ElAziz M, 2016, HYBRID SOFT COMPUTIN, P1, DOI DOI 10.1007/978-3-319-47223-2_1
   Abualigah L, 2022, MULTIMED TOOLS APPL, V81, P16707, DOI 10.1007/s11042-022-12001-3
   Abualigah L, 2022, NEURAL COMPUT APPL, V34, P8823, DOI 10.1007/s00521-022-06906-1
   Agrawal S, 2013, SWARM EVOL COMPUT, V11, P16, DOI 10.1016/j.swevo.2013.02.001
   Agrawal V, 2018, INT J SYST ASSUR ENG, V9, P929, DOI 10.1007/s13198-017-0685-6
   Ahmadi M, 2019, MULTIMED TOOLS APPL, V78, P23003, DOI 10.1007/s11042-019-7515-6
   Alwerfali HSN, 2019, IEEE ACCESS, V7, P181405, DOI 10.1109/ACCESS.2019.2959325
   Alwerfali HSN, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22030328
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Bhandari AK, 2015, EXPERT SYST APPL, V42, P1573, DOI 10.1016/j.eswa.2014.09.049
   Bhargava A, 2021, J KING SAUD UNIV-COM, V33, P243, DOI 10.1016/j.jksuci.2018.06.002
   Chakraborty F, 2019, EVOL INTELL, V12, P445, DOI 10.1007/s12065-019-00238-1
   Chen XW, 2022, COMPUT BIOL MED, V142, DOI 10.1016/j.compbiomed.2021.105179
   Cuevas E, 2012, APPL INTELL, V37, P321, DOI 10.1007/s10489-011-0330-z
   Das S, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105273
   Dehshibi MM, 2017, MULTIMED TOOLS APPL, V76, P15951, DOI 10.1007/s11042-016-3891-3
   Du EY, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/432972
   Duan LZ, 2021, J SUPERCOMPUT, V77, P6734, DOI 10.1007/s11227-020-03566-7
   Ewees AA, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.6.063008
   Farshi T.R., 2019, IRAN J COMPUTER SCI, V2, P9, DOI [10.1007/s42044-018-0022-5, DOI 10.1007/S42044-018-0022-5]
   Fayaz S, 2022, MULTIMED TOOLS APPL, V81, P20871, DOI 10.1007/s11042-022-12502-1
   Gill HS, 2019, EGYPT INFORM J, V20, P11, DOI 10.1016/j.eij.2018.03.006
   Gonzalez R C, 2008, DIGITAL IMAGE PROCES
   Grosan C, 2007, STUD COMPUT INTELL, V75, P1
   Gupta S, 2020, NEURAL COMPUT APPL, V32, P9521, DOI 10.1007/s00521-019-04465-6
   Hammouche K, 2010, ENG APPL ARTIF INTEL, V23, P676, DOI 10.1016/j.engappai.2009.09.011
   Horng MH, 2011, EXPERT SYST APPL, V38, P14805, DOI 10.1016/j.eswa.2011.05.069
   Horng MH, 2010, EXPERT SYST APPL, V37, P4580, DOI 10.1016/j.eswa.2009.12.050
   Jiang ZQ, 2021, ARAB J SCI ENG, V46, P8371, DOI 10.1007/s13369-021-05483-0
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Karakoyun M, 2021, ENG SCI TECHNOL, V24, P1455, DOI 10.1016/j.jestch.2021.03.011
   Khairuzzaman AKM, 2017, EXPERT SYST APPL, V86, P64, DOI 10.1016/j.eswa.2017.04.029
   Khalilpourazari S, 2020, NEURAL COMPUT APPL, V32, P7725, DOI 10.1007/s00521-019-04530-0
   Kotte S, 2018, AIN SHAMS ENG J, V9, P1043, DOI 10.1016/j.asej.2016.06.007
   Mahajan S, 2021, MULTIMED TOOLS APPL, V80, P19335, DOI 10.1007/s11042-021-10641-5
   Mlakar U, 2016, EXPERT SYST APPL, V65, P221, DOI 10.1016/j.eswa.2016.08.046
   Mohan A, 2018, ALEX ENG J, V57, P787, DOI 10.1016/j.aej.2017.01.020
   Mousavirad SJ, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2019.04.002
   Mousavirad SJ, 2017, EVOL INTELL, V10, P45, DOI 10.1007/s12065-017-0152-y
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Ouadfel S, 2016, J INTELL SYST, V25, P473, DOI 10.1515/jisys-2014-0147
   Ouadfel S, 2016, EXPERT SYST APPL, V55, P566, DOI 10.1016/j.eswa.2016.02.024
   Renugambal A, 2023, IETE J RES, V69, P2817, DOI 10.1080/03772063.2021.1906765
   Resma KPB, 2021, J KING SAUD UNIV-COM, V33, P528, DOI 10.1016/j.jksuci.2018.04.007
   Saranya K, 2022, INTELL AUTOM SOFT CO, V33, P399, DOI 10.32604/iasc.2022.023149
   Sarkar S., 2013, ADV INTELLIGENT SYST, P699, DOI DOI 10.1007/978-3-642-35314-7_
   Sathya PD, 2011, EXPERT SYST APPL, V38, P15549, DOI 10.1016/j.eswa.2011.06.004
   Sathya P. D., 2010, International Journal of Computer Applications, V5, P39, DOI [10.5120/903-1279, DOI 10.5120/903-1279]
   Shen L, 2018, IEEE ACCESS, V6, P30508, DOI 10.1109/ACCESS.2018.2837062
   Tuba E, 2017, 2017 14TH INTERNATIONAL CONFERENCE ON ENGINEERING OF MODERN ELECTRIC SYSTEMS (EMES), P240, DOI 10.1109/EMES.2017.7980424
   Yamini B, 2022, INT J INF COMPUT SEC, V17, P83, DOI 10.1504/IJICS.2022.121292
   Ye Z, 2006, 2005 INT C NEURAL NE
   Ye ZW, 2015, APPL SOFT COMPUT, V31, P381, DOI 10.1016/j.asoc.2015.02.012
   Yue XF, 2020, SIGNAL IMAGE VIDEO P, V14, P575, DOI 10.1007/s11760-019-01585-3
   Zhou YQ, 2018, MULTIMED TOOLS APPL, V77, P23699, DOI 10.1007/s11042-018-5637-x
NR 56
TC 1
Z9 1
U1 1
U2 3
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 32711
EP 32753
DI 10.1007/s11042-023-14637-1
EA MAR 2023
PG 43
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000943009100014
DA 2024-07-18
ER

PT J
AU Madongo, CT
   Zhongjun, T
AF Madongo, Canaan Tinotenda
   Zhongjun, Tang
TI A movie box office revenue prediction model based on deep multimodal
   features
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Deep neural networks; Demand forecasting; Multimodal features; Movie
   poster; Movie box-office; Revenue prediction
ID GENRE CLASSIFICATION
AB Demand forecasting a film's opening weekend box office revenue is a difficult and complex task that decision-makers face due to a lack of historical data and various complex factors. We proposed a novel Deep Multimodal Feature Classifier Neural Network model (DMFCNN) for predicting a film's opening weekend box office revenue using deep multimodal visual features extracted from movie posters and movie metadata. DMFCNN is an end-to-end predictive model that fuses two different feature classifiers' predictive power in estimating the movie box office revenue. Initially, a pre-trained residual convolutional neural network (ResNet50) architecture using transfer learning techniques extracts visual, and object representations learned from movie posters. The movie posters' discriminative and financial success-related features are combined with other movie metadata to classify the movie box office revenue. The proposed DMFCNN aided in developing a robust predictive model that jointly learns and defines useful revenue-related poster features and objects semantics, which strongly correlates with movie box office revenue and aesthetic appearance. Although our main task was classification, we also analyzed regressions between our exogenous variables as a regularizer to avoid the risk of overfitting. We evaluated DMFCNN's performance and compared it to various state-of-the-art models on the Internet Movie Database by collecting 49,857 movies metadata and posters from 2006 to 2019. The learned information on movie posters and predicted outcomes outperformed existing models, achieving 59.30% prediction accuracy. The proposed fusion strategy outperformed the existing fusion schemes in precision, Area Under Cover, sensitivity, and specificity by achieving 80%, 81%, 79%, and 78%, respectively.
C1 [Madongo, Canaan Tinotenda; Zhongjun, Tang] Beijing Univ Technol, Coll Econ & Adm, Res Base Beijing Modern Mfg Dev, 100 Pingleyuan, Beijing 100124, Peoples R China.
C3 Beijing University of Technology
RP Madongo, CT (corresponding author), Beijing Univ Technol, Coll Econ & Adm, Res Base Beijing Modern Mfg Dev, 100 Pingleyuan, Beijing 100124, Peoples R China.
EM ctmadongo@yahoo.co.uk
RI Madongo, Canaan Tinotenda/IAN-9714-2023
OI Madongo, Canaan Tinotenda/0000-0002-9065-8329; Tang,
   Zhongjun/0000-0002-0300-6198
CR Abadi M, 2016, PROC 12 USENIX SYMPO
   Ahmed U, 2020, SOFT COMPUT, V24, P6635, DOI 10.1007/s00500-019-04303-w
   [Anonymous], 2010, Proceedings of the 18th International Conference on Multimedea, DOI [DOI 10.1145/1873951.1874068, 10.1145/1873951.1874068]
   Barney G., 2019, SEMANT SCH
   Beck J., 2011, SSRN ELECT J, DOI [10.2139/ssrn.931382, DOI 10.2139/SSRN.931382]
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chu W. -T., 2017, MUSA2 2017 PROC WORK, P39, DOI DOI 10.1145/3132515.3132516
   Delen D, 2007, DECIS SUPPORT SYST, V43, P1151, DOI 10.1016/j.dss.2005.07.005
   Dellarocas CN, 2011, SSRN ELECT J, DOI [10.2139/ssrn.620821, DOI 10.2139/SSRN.620821]
   Ghiassi M, 2015, EXPERT SYST APPL, V42, P3176, DOI 10.1016/j.eswa.2014.11.022
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hur M, 2016, INFORM SCIENCES, V372, P608, DOI 10.1016/j.ins.2016.08.027
   Ivasic-Kos M, 2015, LECT NOTES COMPUT SC, DOI [10.1007/978-3-319-09879-1_32, DOI 10.1007/978-3-319-09879-1_32]
   Ivasic-Kos M, 2014, 2014 37TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1198, DOI 10.1109/MIPRO.2014.6859750
   Kim T, 2017, COMPUT INTEL NEUROSC, V2017, DOI 10.1155/2017/4315419
   Kim T, 2015, INT J FORECASTING, V31, P364, DOI 10.1016/j.ijforecast.2014.05.006
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Lee KJ, 2009, EXPERT SYST APPL, V36, P280, DOI 10.1016/j.eswa.2007.09.042
   Mangolin RB, 2022, MULTIMED TOOLS APPL, V81, P19071, DOI 10.1007/s11042-020-10086-2
   Matsuzaki Y, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P538, DOI 10.23919/MVA.2017.7986919
   Moreno-Seco F, 2006, LECT NOTES COMPUT SC, V4109, P705
   Nambiar G, 2020, 2020 IEEE INT C INNO, P1, DOI [10.1109/INOCON50539.2020.9298385, DOI 10.1109/INOCON50539.2020.9298385]
   Ozkan K., 2018, 2018 9 IEEE ANN UBIQ, V2018, P1, DOI [10.1109/SIU.2018.8404649, DOI 10.1109/SIU.2018.8404649]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ru YN, 2018, COGN SYST RES, V52, P182, DOI 10.1016/j.cogsys.2018.06.018
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sharda R, 2006, EXPERT SYST APPL, V30, P243, DOI 10.1016/j.eswa.2005.07.018
   Sirattanajakarin S, 2019, ACM INT C PROC SERIE, P23, DOI [10.1145/3348445.3348475, DOI 10.1145/3348445.3348475]
   Tang ZJ, 2021, INT J PROD RES, V59, P6776, DOI 10.1080/00207543.2020.1825861
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Wang F., 2010, Journal of Interactive Advertising, V11, P50, DOI DOI 10.1080/15252019.2010.10722177
   Wang W, 2018, LECT NOTES COMPUT SC, V10942, P530, DOI 10.1007/978-3-319-93818-9_51
   Wang ZY, 2020, INFORM FUSION, V60, P25, DOI 10.1016/j.inffus.2020.02.002
   Wehrmann J., 2017, P S APPL COMP, P114
   Wehrmann J, 2017, APPL SOFT COMPUT, V61, P973, DOI 10.1016/j.asoc.2017.08.029
   Wi JA, 2020, IEEE ACCESS, V8, P66615, DOI 10.1109/ACCESS.2020.2986055
   Zhang L, 2009, EXPERT SYST APPL, V36, P6580, DOI 10.1016/j.eswa.2008.07.064
   Zhou Y, 2019, NEURAL COMPUT APPL, V31, P1855, DOI 10.1007/s00521-017-3162-x
   Zhou Y, 2018, IEEE C EVOL COMPUTAT, P1833, DOI 10.1109/CEC.2018.8477691
NR 41
TC 2
Z9 2
U1 8
U2 25
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD SEP
PY 2023
VL 82
IS 21
BP 31981
EP 32009
DI 10.1007/s11042-023-14456-4
EA MAR 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA Q3FR1
UT WOS:000940725400001
DA 2024-07-18
ER

PT J
AU Chamorro-Padial, J
   Rodríguez-Sánchez, R
AF Chamorro-Padial, Jorge
   Rodriguez-Sanchez, Rosa
TI The relevance of title, abstract, and keywords for scientific paper
   quality and potential impact
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Peer-review process; Informed authors; Authors skills; Quasi-species;
   Systematic review; Recommendation system
AB Authors, editors, and reviewers need to have a good perception regarding the quality of a manuscript in order to improve their skills, save effort, and prevent errors that can affect the submission procedure. In this paper, we compared the author's perception of a manuscript's quality with the manuscript's actual impact. In addition, we analyzed the uncertainty of the author's perception of the manuscript's quality. From there, we defined 'partition' as the author's ability to perceive the actual quality. We did this by launching a website for the use of the scientific community. This webpage provided a tool to help improve an investigator's skill in understanding and recognizing the quality of a manuscript so as to help researchers improve and maximize their works' potential impact. We carried out the experiment with 106 experienced users who tested our webpage. We found that the Abstract, the Title, and the Keywords were enough to perform a substantially decent evaluation of a manuscript. Most of the researchers were able to determine the quality of a paper in less than a minute from this small amount of information.
C1 [Chamorro-Padial, Jorge] UGR Univ Granada, CITIC, Granada 18071, Spain.
   [Rodriguez-Sanchez, Rosa] UGR Univ Granada, Dept Ciencias Comp IA, CITIC, Granada 18071, Spain.
C3 University of Granada; University of Granada
RP Chamorro-Padial, J (corresponding author), UGR Univ Granada, CITIC, Granada 18071, Spain.
EM jorgechp@correo.ugr.es; rosa@decsai.ugr.es
RI Rodriguez Sanchez, Rosa Maria/B-1847-2012
OI Rodriguez Sanchez, Rosa Maria/0000-0001-7886-9329; Chamorro Padial,
   Jorge/0000-0002-6334-3786
FU Universidad de Granada/CBUA
FX Funding for open access publishing: Universidad de Granada/CBUA.
CR Bai XM, 2017, INFORMATION, V8, DOI 10.3390/info8030073
   Callaham M, 2002, JAMA-J AM MED ASSOC, V287, P2847, DOI 10.1001/jama.287.21.2847
   Campanario JM, 1998, SCI COMMUN, V19, P181, DOI 10.1177/1075547098019003002
   Chamorro-Padial J, 2021, COMPUTER SCI ARTICLE, DOI [10.34740/KAGGLE/DS/1268595, DOI 10.34740/KAGGLE/DS/1268595]
   Chamorro-Padial J, 2019, SCIENTOMETRICS, V120, P1373, DOI 10.1007/s11192-019-03171-3
   Garcia JA, 2021, SCIENTOMETRICS, V126, P4277, DOI 10.1007/s11192-021-03918-x
   García JA, 2019, SCIENTOMETRICS, V118, P885, DOI 10.1007/s11192-019-03008-z
   García JA, 2015, SCIENTOMETRICS, V104, P361, DOI 10.1007/s11192-015-1566-x
   Johnson R., 2018, The STM report: An overview of scientific and scholarly publishing, V5th
   KASSIRER JP, 1994, JAMA-J AM MED ASSOC, V272, P96, DOI 10.1001/jama.272.2.96
   Mavrogenis AF, 2020, INT ORTHOP, V44, P413, DOI 10.1007/s00264-020-04504-1
   Mengel F, 2012, J THEOR BIOL, V307, P117, DOI 10.1016/j.jtbi.2012.05.016
   Menon V, 2021, ASIAN J PSYCHIATR, V58, DOI 10.1016/j.ajp.2021.102599
   Okike K, 2016, JAMA-J AM MED ASSOC, V316, P1315, DOI 10.1001/jama.2016.11014
   Özçakar L, 2012, EUR J PHYS REHAB MED, V48, P643
   Primack RB, 2019, BIOL CONSERV, V238, DOI 10.1016/j.biocon.2019.108232
   Rajput ASD, 2022, WEATHER, V77, P99, DOI 10.1002/wea.3967
   Rodriguez-Sánchez R, 2016, APPL MATH COMPUT, V273, P645, DOI 10.1016/j.amc.2015.10.034
   Schoenwolf GC, 2013, DEV GROWTH DIFFER, V55, P735, DOI 10.1111/dgd.12092
   SCHUSTER P, 1988, B MATH BIOL, V50, P635, DOI 10.1007/BF02460094
   Tennant JP, 2020, RES INTEGR PEER REV, V5, DOI 10.1186/s41073-020-00092-1
   Wallach JD, 2018, RES INTEGR PEER REV, V3, DOI 10.1186/s41073-017-0045-8
   Wong Victoria S S, 2017, Res Integr Peer Rev, V2, P6, DOI 10.1186/s41073-017-0032-0
NR 23
TC 2
Z9 2
U1 7
U2 13
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUN
PY 2023
VL 82
IS 15
BP 23075
EP 23090
DI 10.1007/s11042-023-14451-9
EA FEB 2023
PG 16
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA I2KP1
UT WOS:000940065100002
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Jafargholkhanloo, AF
   Shamsi, M
AF Jafargholkhanloo, Ali Fahmi
   Shamsi, Mousa
TI Cephalometry analysis of facial soft tissue based on two orthogonal
   views applicable for facial plastic surgeries
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Facial plastic surgery; Grey wolf optimization (GWO); Fuzzy C-means
   clustering (FCM); Lip segmentation; Face analysis
ID QUANTITATIVE-ANALYSIS; NEURAL-NETWORK; ALGORITHM; SEGMENTATION;
   PERFORMANCE; BEAUTY; ANGLES
AB Cephalometry analysis of facial soft tissue plays an important role for anthropologists in facial plastic surgeries. There are two important problems in the field of medical for facial anthropometry analysis. (1) Image calibration and its management during facial surgery operation by surgeons are difficult and time-consuming. (2) The manual analysis of facial cephalometry using mechanical tools such as a ruler and the caliper is highly error-inclined. A major disadvantage of manual measurement is that this method requires training and skill. To overcome the mentioned problems, this paper presents an automatic method for facial anthropometry analysis applicable for facial plastic surgeries based on orthogonal images. The proposed algorithm includes three main steps: (1) eye and mouth region detection from the frontal view, (2) facial contour extraction from the profile view, and (3) facial landmark detection. In this study, an optimized version of Fuzzy C-Means (FCM) clustering is presented using the Grey Wolf Optimization (GWO) for lip and facial skin segmentation. For facial landmark localization from the profile view, first, facial skin segmentation is done from frontal and profile views. Then, eye and mouth regions are detected from the frontal view. In facial orthogonal images, the Y coordinates of the feature points are the same, approximately. Finally, nine landmarks from the profile view are detected using the orthogonality feature. Experiment results show that the proposed algorithm is effective in the analysis of facial plastic surgeries.
C1 [Jafargholkhanloo, Ali Fahmi; Shamsi, Mousa] Sahand Univ Technol, Fac Biomed Engn, Tabriz, Iran.
C3 Sahand University of Technology
RP Shamsi, M (corresponding author), Sahand Univ Technol, Fac Biomed Engn, Tabriz, Iran.
EM a_fahmi@sut.ac.ir; shamsi@sut.ac.ir
OI Shamsi, Mousa/0000-0003-4670-0531
CR Aibinu AM, 2012, PROCEDIA ENGINEER, V41, P1183, DOI 10.1016/j.proeng.2012.07.299
   Ajami S, 2015, IRAN J ORTHO, V10, DOI [10.17795/ijo.4981, DOI 10.17795/IJO.4981]
   Al-Mohair HK, 2015, APPL SOFT COMPUT, V33, P337, DOI 10.1016/j.asoc.2015.04.046
   Asghari Alimohamad, 2014, Med J Islam Repub Iran, V28, P49
   Askarzadeh A, 2016, COMPUT STRUCT, V169, P1, DOI 10.1016/j.compstruc.2016.03.001
   Bakhshali M., 2015, J. Craniomaxillofac. Res., V2, P78
   Bakhshali MA, 2015, TURK J ELECTR ENG CO, V23, P804, DOI 10.3906/elk-1302-87
   Bakhshali MA, 2014, J COMPUT SCI-NETH, V5, P251, DOI 10.1016/j.jocs.2013.07.001
   Beugre JB, 2017, INT ORTHOD, V15, P25, DOI 10.1016/j.ortho.2016.12.015
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chaves-González JM, 2010, DIGIT SIGNAL PROCESS, V20, P806, DOI 10.1016/j.dsp.2009.10.008
   Chen FM, 2016, NEUROCOMPUTING, V177, P98, DOI 10.1016/j.neucom.2015.11.010
   Fagundes MSC, 2016, BRAZ J OTORHINOLAR, V82, P47, DOI 10.1016/j.bjorl.2015.11.003
   Csurka G, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.32
   Elazab A, 2015, COMPUT MATH METHOD M, V2015, DOI 10.1155/2015/485495
   Fariaby J, 2006, BRIT J ORAL MAX SURG, V44, P393, DOI 10.1016/j.bjoms.2005.07.029
   Ford A., 1998, COLOUR SPACE CONVERS, V1-31, P1998
   Fortes Helena Nunes da Rocha, 2014, Dental Press J. Orthod., V19, P66, DOI 10.1590/2176-9451.19.2.066-075.oar
   Fred A. L., 2020, Applications of hybrid metaheuristic algorithms for image processing, P413
   Gerós A, 2016, J BIOMED INFORM, V61, P1, DOI 10.1016/j.jbi.2016.03.011
   Gode S, 2011, AESTHET PLAST SURG, V35, P1016, DOI 10.1007/s00266-011-9726-8
   Gunes H, 2006, INT J HUM-COMPUT ST, V64, P1184, DOI 10.1016/j.ijhcs.2006.07.004
   Hong YJ, 2017, SYMMETRY-BASEL, V9, DOI 10.3390/sym9120294
   Hossain MF, 2012, INT J INNOV COMPUT I, V8, P1135
   Ji YY, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051205
   Kahu SY, 2019, COLOR RES APPL, V44, P8, DOI 10.1002/col.22291
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khan R, 2012, PATTERN RECOGN LETT, V33, P157, DOI 10.1016/j.patrec.2011.09.032
   Liu JQ, 2009, GLOB TELECOMM CONF, P6186
   Liu YJ, 2017, J VISUAL LANG COMPUT, V43, P103, DOI 10.1016/j.jvlc.2017.09.006
   Majdi A, 2019, INT J ROCK MECH MIN, V113, P172, DOI 10.1016/j.ijrmms.2018.10.030
   Malá PZ, 2018, FORENSIC SCI INT, V292, P212, DOI 10.1016/j.forsciint.2018.09.014
   Malkoç S, 2009, EUR J ORTHODONT, V31, P174, DOI 10.1093/ejo/cjn082
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mirjalili S, 2014, ADV ENG SOFTW, V69, P46, DOI 10.1016/j.advengsoft.2013.12.007
   Mohanty R, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P1392, DOI 10.1109/ICCSP.2016.7754383
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Özkan AÇ, 2017, PRS-GLOB OPEN, V5, DOI 10.1097/GOX.0000000000001399
   Park BH, 2017, EXPERT SYST APPL, V89, P66, DOI 10.1016/j.eswa.2017.07.018
   Pham Annette M, 2010, Facial Plast Surg Clin North Am, V18, P341, DOI 10.1016/j.fsc.2010.01.010
   Salazar A, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P5747
   Sameer FO, 2019, NEURAL COMPUT APPL, V31, P337, DOI 10.1007/s00521-017-3018-4
   Saremi S, 2017, ADV ENG SOFTW, V105, P30, DOI 10.1016/j.advengsoft.2017.01.004
   Shamsi M, 2008, IEICE T INF SYST, VE91D, P1543, DOI 10.1093/ietisy/e91-d.5.1543
   Singh J, 2018, J THERM BIOL, V71, P91, DOI 10.1016/j.jtherbio.2017.11.001
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Song Y, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10072547
   Tang X, 2018, NEUROCOMPUTING, V297, P22, DOI 10.1016/j.neucom.2018.01.080
   Tongbram S, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-020-02762-w
   Tuncel U, 2013, J CRANIO MAXILL SURG, V41, P98, DOI 10.1016/j.jcms.2012.05.014
   Uzun A, 2014, BRAZ J OTORHINOLAR, V80, P397, DOI 10.1016/j.bjorl.2014.07.010
   Verma H, 2021, EXPERT SYST APPL, V167, DOI 10.1016/j.eswa.2020.114121
   Wang SM, 2018, J HEALTHC ENG, V2018, DOI 10.1155/2018/1797502
   Wu Y, 2018, IEEE T PATTERN ANAL, V40, P3067, DOI 10.1109/TPAMI.2017.2787130
   Zali-Vargahan B., 2013, 2013 21 IRANIAN C EL, P1, DOI [10.1109/IranianCEE.2013.6599705, DOI 10.1109/IRANIANCEE.2013.6599705]
   Zhang D, 2011, PATTERN RECOGN, V44, P940, DOI 10.1016/j.patcog.2010.10.013
NR 56
TC 1
Z9 1
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30643
EP 30668
DI 10.1007/s11042-023-14531-w
EA FEB 2023
PG 26
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000940065100013
DA 2024-07-18
ER

PT J
AU Kumar, KH
   Srinivas, K
AF Kumar, K. Harish
   Srinivas, K.
TI An accurate analogy based software effort estimation using hybrid
   optimization and machine learning techniques
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Software engineering; Effort estimation; Prediction errors;
   Hyperparameter tuning; TL-RNN
ID DIFFERENTIAL EVOLUTION; ALGORITHM; MODEL
AB Software engineering's primary task is analogy-centric effort estimation. In this, by utilizing the existent histories, the effort needed for new software projects was estimated for the respective development along with management. Generally, the Software Effort Estimation (SEE) methodologies' higher correctness is a non-solvable issue, which was termed as a multi-objective problem. In recent days, Machine Learning (ML) methodologies are utilized by numerous authors for the same process; however, higher performance was not attained. Furthermore, bias and subjectivity issues are the complications faced by the prevailing SEE methodologies. For further improvement of effort estimation, we propose an accurate analogy based SEE (AA-SEE) created on hybrid optimization and ML techniques. The first contribution of the proposed AA-SEE technique is to introduce a multi-swarm coyote optimization (MSCO) algorithm to tune the hyper parameters for ML technique. Because, an accurate hyper parameters needed for effort estimation at the optimal level which reduce the prediction errors. The second contribution is to illustrate the teaching-learning based recurrent neural network (TL-RNN) for effort estimation. The proposed AA-SEE technique can be evaluate through different standard datasets are Albercht, Kitchenham, Maxwell, Deshernais, IKH, Telecom, ISBSG and NASA. Finally, the performance of proposed AA-SEE technique is associated with the existing state-of-art methodologies in footings of accuracy, MMRE, MdMMRE, BMMRE, MMER and MdMMER.
C1 [Kumar, K. Harish; Srinivas, K.] Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Hyderabad 500075, Telangana, India.
   [Kumar, K. Harish] Mahatma Gandhi Univ, Dept Comp Sci & Informat, Nalgonda 508254, Telangana, India.
C3 Koneru Lakshmaiah Education Foundation (K L Deemed to be University)
RP Kumar, KH (corresponding author), Koneru Lakshmaiah Educ Fdn, Dept Comp Sci & Engn, Hyderabad 500075, Telangana, India.; Kumar, KH (corresponding author), Mahatma Gandhi Univ, Dept Comp Sci & Informat, Nalgonda 508254, Telangana, India.
EM khrsharma@gmail.com; srirecw9@klh.edu.in
RI kumar, harish/IXW-9984-2023
OI KATEPALLY, HARISH KUMAR/0009-0000-9004-4522
CR Abdelali Z, 2019, PROCEDIA COMPUT SCI, V148, P343, DOI 10.1016/j.procs.2019.01.042
   Azzeh M, 2011, J SYST SOFTWARE, V84, P270, DOI 10.1016/j.jss.2010.09.028
   Benala TR, 2018, SWARM EVOL COMPUT, V38, P158, DOI 10.1016/j.swevo.2017.07.009
   Borte K, 2012, INFORM SOFTWARE TECH, V54, P985, DOI 10.1016/j.infsof.2012.03.002
   Chiu NH, 2007, J SYST SOFTWARE, V80, P628, DOI 10.1016/j.jss.2006.06.006
   Choudhari J, 2012, PROC TECH, V4, P761, DOI 10.1016/j.protcy.2012.05.124
   Dashti M, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.800
   Effendi A, 2019, PROCEDIA COMPUT SCI, V157, P691, DOI 10.1016/j.procs.2019.08.215
   Elish MO, 2009, EXPERT SYST APPL, V36, P10774, DOI 10.1016/j.eswa.2009.02.013
   Ezghari S, 2018, APPL SOFT COMPUT, V67, P540, DOI 10.1016/j.asoc.2018.03.022
   Garcia-Diaz N, 2013, PROC TECH, V7, P305, DOI 10.1016/j.protcy.2013.04.038
   Grimstad S, 2006, INFORM SOFTWARE TECH, V48, P302, DOI 10.1016/j.infsof.2005.04.004
   Huang SJ, 2008, EUR J OPER RES, V188, P898, DOI 10.1016/j.ejor.2007.07.002
   Jorgensen M, 2020, J SYST SOFTWARE, V159, DOI 10.1016/j.jss.2019.110448
   Jorgensen M, 2011, INFORM SOFTWARE TECH, V53, P1382, DOI 10.1016/j.infsof.2011.07.001
   Kumar PS, 2020, COMPUT SCI REV, V38, DOI 10.1016/j.cosrev.2020.100288
   Mensah S, 2018, INFORM SOFTWARE TECH, V94, P1, DOI 10.1016/j.infsof.2017.09.010
   Moosavi SHS, 2017, ENG APPL ARTIF INTEL, V60, P1, DOI 10.1016/j.engappai.2017.01.006
   Oliveira ALI, 2010, INFORM SOFTWARE TECH, V52, P1155, DOI 10.1016/j.infsof.2010.05.009
   Pandey M, 2020, WIRELESS PERS COMMUN, V110, P1659, DOI 10.1007/s11277-019-06805-0
   Park H, 2008, EXPERT SYST APPL, V35, P929, DOI 10.1016/j.eswa.2007.08.001
   Phannachitta P, 2020, INFORM SOFTWARE TECH, V125, DOI 10.1016/j.infsof.2020.106330
   Praynlin E, 2021, J AMB INTEL HUM COMP, V12, P8763, DOI 10.1007/s12652-020-02652-1
   Qi FM, 2017, INFORM SOFTWARE TECH, V92, P145, DOI 10.1016/j.infsof.2017.07.015
   Santos LPD, 2018, IEEE LAT AM T, V16, P2069, DOI 10.1109/TLA.2018.8447378
   Sharma A, 2012, PROC TECH, V4, P716, DOI 10.1016/j.protcy.2012.05.116
   Silhavy P, 2019, IEEE ACCESS, V7, P9618, DOI 10.1109/ACCESS.2019.2891878
   Singal P, 2020, PROCEDIA COMPUT SCI, V167, P2643, DOI 10.1016/j.procs.2020.03.343
   Usman M, 2018, J SYST SOFTWARE, V146, P286, DOI 10.1016/j.jss.2018.09.054
   Varshini AGP, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101195
   Vijay JF, 2019, NEURAL COMPUT APPL, V31, P1633, DOI 10.1007/s00521-018-3565-3
   Wen JF, 2012, INFORM SOFTWARE TECH, V54, P41, DOI 10.1016/j.infsof.2011.09.002
   Zare F, 2016, APPL SOFT COMPUT, V49, P968, DOI 10.1016/j.asoc.2016.08.004
NR 33
TC 1
Z9 1
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD AUG
PY 2023
VL 82
IS 20
BP 30463
EP 30490
DI 10.1007/s11042-023-14522-x
EA FEB 2023
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA M8NK0
UT WOS:000937854600005
DA 2024-07-18
ER

PT J
AU Dai, JZ
   Hu, XJ
   Li, M
   Li, Y
   Du, SD
AF Dai, Jingzhao
   Hu, Xuejiao
   Li, Ming
   Li, Yang
   Du, Sidan
TI The multi-learning for food analyses in computer vision: a survey
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Computer vision; Food analyses; Multi-learning; Multi-task learning
   (MTL); Multi-view learning (MVL); Multi-scale learning (MSL)
ID RECOGNITION; CLASSIFICATION; CONTEXT; MODEL
AB With the rapid development of food production and health management, analyses of food samples have been essential for preventing diseases and understanding human culture. Recently, food analyses have become increasingly complex and are not limited in food categorization. They also contain many advanced tasks (e.g., nutrition estimation and recipe retrieval). From existing works, two points can be concluded. First, food features are much more comprehensive and sophisticated than general samples. Second, for food analyses, multiple learning strategies (MLSs) usually achieve outperformance over general deep learning methods. However, there are few survey papers reporting food analyses with MLSs, and the main factors lead to difficulty of operation. Therefore, we intend to conduct a survey for applications of MLSs to food analyses. In this survey paper, three types of common MLSs, which are multi-task learning (MTL), multi-view learning (MVL) and multi-scale learning (MSL) strategies, are presented in terms of their guidance, typical works, algorithms and final aggregation methods. Additionally, food characteristics are proposed to be closely related to the difficulty of food analyses. We comprehensively conclude food characteristics as nonrigid, complex in arrangement, and large (small) in intraclass (interclass) variance. Moreover, some experimental results of MLSs are also presented and analyzed in this paper. Based on these results, insightful suggestions for MLSs implementation are proposed. Finally, the promising tendency of MLSs applications in the future is discussed.
C1 [Dai, Jingzhao; Hu, Xuejiao; Li, Ming; Li, Yang; Du, Sidan] Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
C3 Nanjing University
RP Du, SD (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
EM dg20230007@smail.nju.edu.cn; hxj@smail.nju.edu.cn;
   mingli@smail.nju.edu.cn; yogo@nju.edu.cn; coff128@nju.edu.cn
RI Du, Sidan/JVN-2413-2024
OI Du, Sidan/0000-0002-7079-0066
CR Aguilar E, 2019, J VIS COMMUN IMAGE R, V60, P360, DOI 10.1016/j.jvcir.2019.03.011
   AlZu'bi S, 2019, MULTIMED TOOLS APPL, V78, P29581, DOI 10.1007/s11042-019-7367-0
   Anis S, 2020, IEEE ACCESS, V8, P182347, DOI 10.1109/ACCESS.2020.3028390
   [Anonymous], 2010, Multimedia (ISM), 2010 IEEE International Symposium on
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Bettadapura V, 2015, IEEE WINT CONF APPL, P580, DOI 10.1109/WACV.2015.83
   Bossard L, 2014, LECT NOTES COMPUT SC, V8694, P446, DOI 10.1007/978-3-319-10599-4_29
   Chen JJ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1771, DOI 10.1145/3123266.3123428
   Chen JJ, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P32, DOI 10.1145/2964284.2964315
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen M, 2009, IEEE IMAGE PROC, P289, DOI 10.1109/ICIP.2009.5413511
   Chen XL, 2017, IEEE I CONF COMP VIS, P4106, DOI 10.1109/ICCV.2017.440
   Chen Y, 2019, PROC CVPR IEEE, P5152, DOI 10.1109/CVPR.2019.00530
   Ciocca G, 2020, IEEE ACCESS, V8, P32003, DOI 10.1109/ACCESS.2020.2973704
   Ciocca G, 2017, IEEE J BIOMED HEALTH, V21, P588, DOI 10.1109/JBHI.2016.2636441
   Doersch C, 2017, IEEE I CONF COMP VIS, P2070, DOI 10.1109/ICCV.2017.226
   Ege T, 2018, CEAMADIMA 18 JOINT W
   Ege T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P367, DOI 10.1145/3126686.3126742
   Ege T, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P198, DOI 10.23919/MVA.2017.7986835
   Fakhrou A, 2021, MULTIMED TOOLS APPL, V80, P33011, DOI 10.1007/s11042-021-11329-6
   Farinella GM, 2014, IEEE IMAGE PROC, P5212, DOI 10.1109/ICIP.2014.7026055
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Güngör C, 2017, SIG PROCESS COMMUN
   Guo S, 2018, LECT NOTES COMPUT SC, V11214, P139, DOI 10.1007/978-3-030-01249-6_9
   Han Fu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14558, DOI 10.1109/CVPR42600.2020.01458
   Hassannejad H, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P41, DOI 10.1145/2986035.2986042
   He HS, 2016, IEEE J BIOMED HEALTH, V20, P848, DOI 10.1109/JBHI.2015.2419251
   He JP, 2020, THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2020), P49, DOI 10.1109/MIPR49039.2020.00018
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2017, IEEE T MULTIMEDIA, V19, P430, DOI 10.1109/TMM.2016.2614861
   Horiguchi S, 2018, IEEE T MULTIMEDIA, V20, P2836, DOI 10.1109/TMM.2018.2814339
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huayang Wang, 2016, Advances in Multimedia Information Processing - PCM 2016. 17th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 9916, P520, DOI 10.1007/978-3-319-48890-5_51
   Jha R, 2022, MULTIMED TOOLS APPL, V81, P28583, DOI 10.1007/s11042-022-12877-1
   Jiang SQ, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3391624
   Jiang SQ, 2020, IEEE T IMAGE PROCESS, V29, P265, DOI 10.1109/TIP.2019.2929447
   Joutou T, 2009, IEEE IMAGE PROC, P285, DOI 10.1109/ICIP.2009.5413400
   Kagaya H, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1085, DOI 10.1145/2647868.2654970
   Kawano Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P761, DOI 10.1145/2647868.2654869
   Kawano Y, 2015, LECT NOTES COMPUT SC, V8927, P3, DOI 10.1007/978-3-319-16199-0_1
   Kazi A, 2022, MULTIMED TOOLS APPL, V81, P7611, DOI 10.1007/s11042-022-12150-5
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kong FY, 2015, PERVASIVE MOB COMPUT, V19, P108, DOI 10.1016/j.pmcj.2014.05.012
   Li K., 2019, Income distribution of PPP mode in transportation infrastructure construction, DOI [10.1109/TMC.2019.2921713, DOI 10.1007/978-981-15-5660-91]
   Liang HZ, 2021, IEEE T MULTIMEDIA, V23, P3551, DOI 10.1109/TMM.2020.3028478
   Liang Y, 2017, ARXIV
   Lin TY, 2018, IEEE T PATTERN ANAL, V40, P1309, DOI 10.1109/TPAMI.2017.2723400
   Liu Chenxi, 2018, P EUR C COMP VIS, P19
   Liu Q, 2018, AAAI CONF ARTIF INTE, P2347
   Liu X, 2017, ARXIV
   Liu Y, 2021, COMPUT COMMUN, V178, P245, DOI 10.1016/j.comcom.2021.08.002
   Lo FPW, 2020, IEEE J BIOMED HEALTH, V24, P1926, DOI 10.1109/JBHI.2020.2987943
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Martinel N, 2018, IEEE WINT CONF APPL, P567, DOI 10.1109/WACV.2018.00068
   Matsuda Y., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P25, DOI 10.1109/ICME.2012.157
   Min W, 2017, IEEE T MULTIMED, P1
   Min WQ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1331, DOI 10.1145/3343031.3350948
   Min WQ, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3329168
   Min WQ, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P402, DOI 10.1145/3123266.3123272
   Min WQ, 2017, IEEE T MULTIMEDIA, V19, P1100, DOI 10.1109/TMM.2016.2639382
   Ming ZY, 2018, LECT NOTES COMPUT SC, V10705, P129, DOI 10.1007/978-3-319-73600-6_12
   Mnih V, 2014, ADV NEUR IN, V27
   Myers A, 2015, IEEE I CONF COMP VIS, P1233, DOI 10.1109/ICCV.2015.146
   Nag N, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P99, DOI 10.1145/3078971.3080545
   Najam-ul-Islam M, 2019, 2019 IEEE 1ST GLOBAL POWER, ENERGY AND COMMUNICATION CONFERENCE (GPECOM2019), P1, DOI [10.1109/gpecom.2019.8778569, 10.1109/GPECOM.2019.8778569]
   Nandhini P, 2013, 2013 INTERNATIONAL CONFERENCE ON CURRENT TRENDS IN ENGINEERING AND TECHNOLOGY (ICCTET), P85, DOI 10.1109/ICCTET.2013.6675916
   Ning Z, 2014, EUR C COMP VIS ECCV
   Pandey P, 2017, IEEE SIGNAL PROC LET, V24, P1758, DOI 10.1109/LSP.2017.2758862
   Papyan V, 2016, IEEE T IMAGE PROCESS, V25, P249, DOI 10.1109/TIP.2015.2499698
   Pouladzadeh P, 2015, LECT NOTES COMPUT SC, V9281, P441, DOI 10.1007/978-3-319-23222-5_54
   Sajadmanesh S, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P1013, DOI 10.1145/3041021.3055137
   Salvador A, 2017, PROC CVPR IEEE, P3068, DOI 10.1109/CVPR.2017.327
   Sarker MMK, 2019, IEEE ACCESS, V7, P39069, DOI 10.1109/ACCESS.2019.2902225
   Sarker MMK, 2019, MACNET MULTISCALE AT, P423
   Sasano S, 2016, 2016 9TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, BIOMEDICAL ENGINEERING AND INFORMATICS (CISP-BMEI 2016), P815, DOI 10.1109/CISP-BMEI.2016.7852822
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Shimoda W, 2017, 2017 IEEE THIRD INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2017), P165, DOI 10.1109/BigMM.2017.73
   Situju SF, 2019, APPL ARTIF INTELL, V33, P732, DOI 10.1080/08839514.2019.1602318
   Song XH, 2017, IEEE T IMAGE PROCESS, V26, P2721, DOI 10.1109/TIP.2017.2686017
   Sood S, 2021, MULTIMED TOOLS APPL, V80, P27973, DOI 10.1007/s11042-021-11036-2
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Subhi MA, 2019, IEEE ACCESS, V7, P35370, DOI 10.1109/ACCESS.2019.2904519
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tanno R, 2016, MADIMA'16: PROCEEDINGS OF THE 2ND INTERNATIONAL WORKSHOP ON MULTIMEDIA ASSISTED DIETARY MANAGEMENT, P89, DOI 10.1145/2986035.2986044
   Wang ZX, 2017, IEEE I CONF COMP VIS, P464, DOI 10.1109/ICCV.2017.58
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu RB, 2015, IEEE I CONF COMP VIS, P1287, DOI 10.1109/ICCV.2015.152
   Xu D, 2018, PROC CVPR IEEE, P675, DOI 10.1109/CVPR.2018.00077
   Xu RH, 2015, IEEE T MULTIMEDIA, V17, P1187, DOI 10.1109/TMM.2015.2438717
   Yang JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1074, DOI 10.1145/3240508.3240645
   Yang S, 2010, PROC CVPR IEEE, P2249, DOI 10.1109/CVPR.2010.5539907
   Yu Q, 2018, IEEE IMAGE PROC, P171, DOI 10.1109/ICIP.2018.8451422
   Zhang HZ, 2019, KNOWL-BASED SYST, V183, DOI 10.1016/j.knosys.2019.104870
   Zhang WD, 2020, NEUROCOMPUTING, V414, P57, DOI 10.1016/j.neucom.2020.07.018
   Zhang XJ, 2016, J COMPUT SCI TECH-CH, V31, P489, DOI 10.1007/s11390-016-1642-6
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127
   Zhu YY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P99, DOI 10.1145/3240508.3240525
NR 99
TC 0
Z9 0
U1 2
U2 7
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25615
EP 25650
DI 10.1007/s11042-023-14373-6
EA JAN 2023
PG 36
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000920619400001
DA 2024-07-18
ER

PT J
AU Dong, NN
   Li, TZ
   Liu, TH
   Tu, R
   Lin, F
   Liu, H
   Bo, YY
AF Dong, Ningning
   Li, Tiezhu
   Liu, Tianhao
   Tu, Ran
   Lin, Fei
   Liu, Hui
   Bo, Yiyong
TI A method for short-term passenger flow prediction in urban rail transit
   based on deep learning
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Urban rail transit; Passenger flow; A deep learning; Prediction;
   TNS-LSTM
ID TRAFFIC FLOW
AB Short-term passenger flow prediction is a critical component of urban rail transit operations. However, predictions of passenger flow are mostly focused on one station, and land use, which has a substantial impact on passenger flow variation, has not been taken into account. A model termed the temporal-spatial network long short-term memory model (TNS-LSTM) is developed to solve the forecasting gap for the metro inbound/outbound passenger flow. The model introduces the spatial characteristics of the land use by extracting the point of interest (POI) data instead of merely considering temporal characteristics and network characteristics. The spatial-temporal network matrix is designed through the K-Means clustering model, extraction for temporal characteristics analysis for land use, and establishment of an origin-destination station matrix. Furthermore, the prediction of short-term passenger flow is implemented for multiple stations in the metro network. Finally, a case study based on actual data from the Nanjing metro is carried out, and the results demonstrate that the proposed model can not only avoid the complexity of constructing the numerous models for each station in urban rail transit but also improve the prediction accuracy and save a substantial amount of time.
C1 [Dong, Ningning; Li, Tiezhu; Liu, Tianhao; Tu, Ran] Southeast Univ, Sch Transportat, Nanjing 211189, Peoples R China.
   [Lin, Fei] Nanjing Metro Grp Co Ltd, Nanjing 211806, Peoples R China.
   [Liu, Hui; Bo, Yiyong] Nanjing Vocat Inst Railway Technol, Nanjing 210031, Peoples R China.
C3 Southeast University - China
RP Li, TZ (corresponding author), Southeast Univ, Sch Transportat, Nanjing 211189, Peoples R China.
EM nningdong@163.com; litiezhu@seu.edu.cn; t.liu.tub@gmail.com;
   turancoolgal@seu.edu.cn; linfeicallme@163.com; 1357746565@qq.com;
   41981070@qq.com
FU Jiangsu Rail Transit Industry Development Collaborative Innovation Base
   Open Fund [GCXC2103, GCXC2104]
FX This research has been supported by the Jiangsu Rail Transit Industry
   Development Collaborative Innovation Base Open Fund (No. GCXC2104 and
   No. GCXC2103)
CR Ambati L. S., 2021, AMCIS
   Ambati LS., 2019, J MIDWEST ASS INF SY, V2021, P49, DOI DOI 10.17705/3JMWA.000065
   Amiri SS, 2020, CITY ENVIRON INTERAC, V7, DOI 10.1016/j.cacint.2020.100044
   [Anonymous], 2017, IEEE T INTELL TRANSP
   Bandara K, 2021, IEEE T NEUR NET LEAR, V32, P1586, DOI 10.1109/TNNLS.2020.2985720
   Celebi ME, 2013, EXPERT SYST APPL, V40, P200, DOI 10.1016/j.eswa.2012.07.021
   El-Gayar OmarF., 2020, BIG DATAS POTENTIAL, P104, DOI DOI 10.4018/978-1-5225-9687-5.CH005
   Feng XX, 2019, IEEE T INTELL TRANSP, V20, P2001, DOI 10.1109/TITS.2018.2854913
   Govender P, 2020, ATMOS POLLUT RES, V11, P40, DOI 10.1016/j.apr.2019.09.009
   Habtemichael FG, 2016, TRANSPORT RES C-EMER, V66, P61, DOI 10.1016/j.trc.2015.08.017
   Hao SY, 2019, TRANSPORT RES C-EMER, V107, P287, DOI 10.1016/j.trc.2019.08.005
   Hassan BA, 2021, NEURAL COMPUT APPL, V33, P10987, DOI 10.1007/s00521-020-05649-1
   He YX, 2022, IEEE T INTELL TRANSP, V23, P18155, DOI 10.1109/TITS.2022.3150600
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hyndman RJ, 2006, INT J FORECASTING, V22, P679, DOI 10.1016/j.ijforecast.2006.03.001
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jeong YS, 2013, IEEE T INTELL TRANSP, V14, P1700, DOI 10.1109/TITS.2013.2267735
   Jia HW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164574
   Jiao PP, 2016, MATH PROBL ENG, V2016, DOI 10.1155/2016/9717582
   Li HY, 2019, APPL SOFT COMPUT, V83, DOI 10.1016/j.asoc.2019.105620
   Li WY, 2022, KSCE J CIV ENG, V26, P4086, DOI 10.1007/s12205-022-2051-8
   Li Y, 2019, KNOWL-BASED SYST, V181, DOI 10.1016/j.knosys.2019.05.028
   Liu Y, 2019, TRANSPORT RES C-EMER, V101, P18, DOI 10.1016/j.trc.2019.01.027
   Ma XL, 2019, IEEE T INTELL TRANSP, V20, P2278, DOI 10.1109/TITS.2018.2867042
   Nanda SJ, 2014, SWARM EVOL COMPUT, V16, P1, DOI 10.1016/j.swevo.2013.11.003
   Polson NG, 2017, TRANSPORT RES C-EMER, V79, P1, DOI 10.1016/j.trc.2017.02.024
   Roos J, 2017, TRANSP RES PROC, V26, P53, DOI 10.1016/j.trpro.2017.07.008
   Sai Ambati L., 2020, Issues Inform Syst, V21, P103
   Shahid F, 2021, ENERGY, V223, DOI 10.1016/j.energy.2021.120069
   Sohn K, 2010, CITIES, V27, P358, DOI 10.1016/j.cities.2010.05.001
   Sun YX, 2015, NEUROCOMPUTING, V166, P109, DOI 10.1016/j.neucom.2015.03.085
   Sung H, 2011, CITIES, V28, P70, DOI 10.1016/j.cities.2010.09.004
   Thiruchelvam L, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84176-y
   Wei Y, 2012, TRANSPORT RES C-EMER, V21, P148, DOI 10.1016/j.trc.2011.06.009
   Williams BM, 2003, J TRANSP ENG, V129, P664, DOI 10.1061/(ASCE)0733-947X(2003)129:6(664)
   Wu JJ, 2015, TRANSPORT RES C-EMER, V51, P1, DOI 10.1016/j.trc.2014.11.001
   Yang X, 2021, INT J PROD ECON, V231, DOI 10.1016/j.ijpe.2020.107920
   Zhang H, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/4656435
   Zhang JL, 2019, IEEE ACCESS, V7, P147653, DOI 10.1109/ACCESS.2019.2941987
NR 39
TC 5
Z9 5
U1 13
U2 43
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 17
PY 2023
DI 10.1007/s11042-023-14388-z
EA JAN 2023
PG 23
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA G4YR2
UT WOS:000989233400002
DA 2024-07-18
ER

PT J
AU Belhi, A
   Ahmed, HO
   Alfaqheri, T
   Bouras, A
   Sadka, AH
   Foufou, S
AF Belhi, Abdelhak
   Ahmed, Hosameldin Osman
   Alfaqheri, Taha
   Bouras, Abdelaziz
   Sadka, Abdul. H. H.
   Foufou, Sebti
TI An integrated framework for the interaction and 3D visualization of
   cultural heritage
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Cultural heritage; 3D modeling; Human computer interaction; Alternate
   realities; Digital twin; Leap motion controller; Machine learning
ID USABILITY EVALUATION; SYSTEM
AB In this study, the aim is to design and develop a 3D acquisition, visualization, and interaction framework to preserve cultural heritage and provide new ways to enable museum visitors and cultural audiences to virtually interact with cultural objects. Indeed, cultural assets are nowadays at higher risk and most cultural institutions prohibit visitors from physically manipulating their collections. The main motivation behind our framework is to enable end-user interaction with high valuable cultural objects while addressing cost-effectiveness concerns as well as minimizing the time required to digitize and generate 3D models of cultural heritage objects. The design idea of our framework is to allow interaction with the protected assets' 3D representation using a real-world 3D screen equipped with a depth sensor namely the leap motion controller. Our framework is an end-to-end solution that optimizes all the stages of the 3D acquisition, pre-processing, visualization, and interaction pipeline while providing contributions to its stages. It achieves good quality results thanks to the use of machine learning in the acquisition and modeling stages. Indeed, we adapted a prior preprocessing work that performs super-resolution and motion interpolation on the acquired data. The preprocessed data is then used for the generation of the 3D models using photogrammetry, which optimizes the quality of the resulting 3D models. The created 3D models are then adapted for the visualization and interaction stages. A novel visualization and interaction paradigm is introduced to enable a real-world experience for museum visitors through a 3D screen called "the Looking Glass ". The interaction with the 3D content is achieved through a motion sensor used to design our new interaction component of the framework. We propose two new interaction systems suitable for various user profiles focusing on their experience in dealing with motion sensors. The end-to-end framework tested in a museum environment was evaluated by cultural heritage curators and multimedia experts and found to provide an alternate reality tool for asset exhibition and a cost-effective alternative for asset exchange between cultural institutions. For the evaluation, we compared the end-user experience of our framework using various setups where users are visualizing the content through 2D screens and through the Looking glass while enabling and disabling motion interaction. The results of the evaluation suggest that the looking glass paired with the Leap motion sensor using our framework as a backend enables an alternate reality experience for museum visitors and new ways of interacting with cultural content, sharing of cultural knowledge, cultural education, and much more.
C1 [Belhi, Abdelhak] Joaan Bin Jassim Acad Def Studies, Al Khor, Qatar.
   [Ahmed, Hosameldin Osman; Alfaqheri, Taha; Sadka, Abdul. H. H.] Brunel Univ, London, England.
   [Bouras, Abdelaziz] Qatar Univ, CSE, Doha, Qatar.
   [Foufou, Sebti] Univ Sharjah, Dept Comp Sci, Sharjah, U Arab Emirates.
C3 Brunel University; Qatar University; University of Sharjah
RP Belhi, A (corresponding author), Joaan Bin Jassim Acad Def Studies, Al Khor, Qatar.
EM abdelhakbelhi@gmail.com; hosameldin.ahmed2@brunel.ac.uk;
   taha.alfaqheri@brunel.ac.uk; abdelaziz.bouras@qu.edu.qa;
   abdul.sadka@brunel.ac.uk; sfoufou@sharjah.ac.ae
RI Foufou, Sebti/E-2081-2015
OI Ahmed, Hosameldin/0000-0002-8523-1099
FU NPRP grant from the Qatar National Research Fund (a member of Qatar
   Foundation) [9-181-1-036]
FX This publication was made possible by NPRP grant 9-181-1-036 from the
   Qatar National Research Fund (a member of Qatar Foundation).
CR Agus M, 2009, VISUAL COMPUT, V25, P883, DOI 10.1007/s00371-009-0311-y
   [Anonymous], 1994, Human-Computer Interaction
   Bachmann D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072194
   Barbieri L, 2017, J CULT HERIT, V26, P101, DOI 10.1016/j.culher.2017.02.005
   Barsanti SG, 2015, INT ARCH PHOTOGRAMM, V40-5, P165, DOI 10.5194/isprsarchives-XL-5-W7-165-2015
   Bastanlar Y., 2008, Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci, V37 Pt B5, P1023
   Belhi A, 2023, J ENTERP INF MANAG, V36, P734, DOI 10.1108/JEIM-02-2020-0059
   Belhi A, 2020, ADV INTELL SYST COMP, V1027, P363, DOI 10.1007/978-981-32-9343-4_29
   Belhi A, 2020, J REAL-TIME IMAGE PR, V17, P1911, DOI 10.1007/s11554-020-00975-y
   Belhi A, 2019, SIGNAL PROCESS-IMAGE, V75, P188, DOI 10.1016/j.image.2019.04.005
   Belhi A, 2018, I C COMP SYST APPLIC
   Belhi A, 2017, I C SOFTWARE KNOWL I
   Boher P, 2012, ADV DISPLAY TECHNOLO, VII
   Buyuksalih I, 2017, ISPRS ANN PHOTO REM, V4-4, P161, DOI 10.5194/isprs-annals-IV-4-W4-161-2017
   De la Barre R, 2011, EL DISPL C NUR
   Diaper D., 2003, HDB TASK ANAL HUMAN
   Drossis G, 2018, COMM COM INF SC, V852, P177, DOI 10.1007/978-3-319-92285-0_25
   Factory LG, 2021, LOOK GLASS FACT
   Freire LL, 2012, WORK, V41, P1038, DOI 10.3233/WOR-2012-0281-1038
   Ghaoui C., 2005, Encyclopedia of Human Computer Interaction, DOI DOI 10.1152/jn.00458.2005
   Gray WD, 1998, HUM-COMPUT INTERACT, V13, P203, DOI 10.1207/s15327051hci1303_2
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Jacko JA, 2012, HUM FACTORS ERGON, P1, DOI 10.1201/b11963
   Jiang HZ, 2018, PROC CVPR IEEE, P9000, DOI 10.1109/CVPR.2018.00938
   Ledig C, 2017, ARXIV
   Liang W, 2019, MULTIMED TOOLS APPL, V78, P4767, DOI 10.1007/s11042-018-7070-6
   Matterandform.net, MATT SCANN F
   Mustafa AW, 2018, P INT C VIRTUAL SYST, P1
   Pavlidis G, 2007, J CULT HERIT, V8, P93, DOI 10.1016/j.culher.2006.10.007
   Pieraccini M, 2001, J CULT HERIT, V2, P63, DOI 10.1016/S1296-2074(01)01108-6
   Rojas-Sola JI, 2011, J CULT HERIT, V12, P74, DOI 10.1016/j.culher.2010.10.004
   Rubin J., 2008, Handbook of Usability Testing: how to Plan, Design, and Conduct Effective Tests, V2nd ed.
   Scopigno R, 2011, COMPUTER, V44, P48, DOI 10.1109/MC.2011.196
   Singh G, 2014, IEEE COMPUT GRAPH, V34, P4
   Spring AP, 2010, IEEE COMPUT GRAPH, V30, P15, DOI 10.1109/MCG.2010.62
   Ssemugabi S., 2007, P 2007 ANN RES C S A, P132
   Tomar S., 2006, LINUX J, V2006, P10
   Vosinakis S, 2016, INT CONF GAMES VIRTU
   Weichert F, 2013, SENSORS-BASEL, V13, P6380, DOI 10.3390/s130506380
   Yáñez-Gómez R, 2017, MULTIMED TOOLS APPL, V76, P5755, DOI 10.1007/s11042-016-3845-9
   Yang L, 2016, MULTIMED TOOLS APPL, V75, P17121, DOI 10.1007/s11042-015-2981-y
NR 41
TC 2
Z9 2
U1 16
U2 47
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2023 JAN 11
PY 2023
DI 10.1007/s11042-023-14341-0
EA JAN 2023
PG 29
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7S4JO
UT WOS:000910721500001
DA 2024-07-18
ER

PT J
AU Jain, S
   Jacob, IJ
   Mandava, AK
AF Jain, Swasthika
   Jacob, I. Jeena
   Mandava, Ajay Kumar
TI D-ResNet-PVKELM: deep neural network and paragraph vector based kernel
   extreme machine learning model for multimodal depression analysis
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Multi-modal depression analysis; Residual network based deep neural
   network and paragraph vector based kernel extreme machine learning
   (D-ResNet-PVKELM); PHQ-8 score; Psychoanalytic symptoms and ensemble
   classifiers
AB Nowadays, depression heavily affects humans' physical and mental health. Depression occurs due to changes in mood, loss of interest, and stress, which leads to self-harm events and suicide. Thus analyzing depression is very important to reduce suicidal acts. In recent years, automatic depression evaluation has been developed in computer vision technology. Several models were investigated for depression analysis, but they are limited only to video and audio data analysis. In this paper, hybrid Artificial Intelligence (AI) based Multi-modal depression analysis was proposed in which the severity of depression from multi-modal data such as video, audio and text descriptors are extracted. Initially, the proposed approach estimates the Patient Health Questionnaire (PHQ) depression scale by a hybrid framework Residual Network based Deep Neural Network (D-ResNet), which computes the PHQ-8 score from video and audio features. Then, Paragraph Vector Kernel Extreme Learning Machine (PV-KELM) is developed to infer the mental and physical states of the individuals related to the psychoanalytic features of depression. It recognizes the absence (or) presence of the measured psychoanalytic symptoms. Finally, the estimated PHQ-8 score and psychoanalytic symptoms are extracted from the Residual Network based Deep Neural Network and the Paragraph Vector based Kernel Extreme Learning Machine, which is fed together into the ensemble classifier. In the ensemble classifier, three classifiers are used, namely Support Vector Machine (SVM), Naive-Bayes (NB), and Decision Tree (DT) classifier, to classify whether the individual is depressed or not. The proposed approach is implemented in PYTHON software, and the experiments will be carried out using the Distress Analysis Interview Corpus-Wizard of -OZ interview depression dataset. By using the proposed approach, the accuracy, precision, recall, F-measure, RMSE, MAE, JSD and Contextual similarity obtained are 0.89, 0.86, 0.86 and 0.86, 0.373, 0.35, 0.355 and 0.689 respectively. Our proposed approach has been compared with the state-of-the-art approaches, and the performance result shows the efficiency of the proposed approach.
C1 [Jain, Swasthika; Jacob, I. Jeena] GITAM Sch Technol, Dept Comp Sci & Engn, Bangalore Campus, Bengaluru, India.
   [Mandava, Ajay Kumar] GITAM Sch Technol, Dept Elect Elect & Commun Engn, Bangalore Campus, Bengaluru, India.
C3 Gandhi Institute of Technology & Management (GITAM); Gandhi Institute of
   Technology & Management (GITAM)
RP Jain, S (corresponding author), GITAM Sch Technol, Dept Comp Sci & Engn, Bangalore Campus, Bengaluru, India.
EM sjain@gitam.edu
RI Mandava, Ajay Kumar/KDM-4908-2024
OI Mandava, Ajay Kumar/0009-0001-8902-6914
CR Alakus TB, 2020, CHAOS SOLITON FRACT, V140, DOI 10.1016/j.chaos.2020.110120
   Aloshban N, 2021, INTERSPEECH, P2496, DOI 10.21437/Interspeech.2021-928
   Ansari A, 2018, IEEE WRK SIG PRO SYS, P7, DOI 10.1109/SiPS.2018.8598348
   Avots E, 2021, ARXIV
   Cai HS, 2020, INFORM FUSION, V59, P127, DOI 10.1016/j.inffus.2020.01.008
   Ceccarelli F, 2022, PATTERN ANAL APPL, V25, P493, DOI 10.1007/s10044-021-01001-y
   Chen Q, 2021, PATTERN RECOGN LETT, V150, P115, DOI 10.1016/j.patrec.2021.07.005
   Chiu CY, 2021, J INTELL INF SYST, V56, P25, DOI 10.1007/s10844-020-00599-5
   Chow YY, 2022, DIABETES RES CLIN PR, V185, DOI 10.1016/j.diabres.2022.109227
   Churi H, 2021, DEEP LEARNING APPROA
   Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260
   Cohn J. F., 2018, HDB MULTIMODAL MULTI, V2, P375, DOI DOI 10.1145/3107990.3108004
   Dai ZJ, 2021, J AFFECT DISORDERS, V295, P1040, DOI 10.1016/j.jad.2021.09.001
   Das NN, 2022, IRBM, V43, P114, DOI 10.1016/j.irbm.2020.07.001
   Francese R, 2021, PROCEEDINGS OF THE 14TH BIANNUAL CONFERENCE OF THE ITALIAN SIGCHI CHAPTER (CHIITALY 2021), DOI 10.1145/3464385.3464708
   Gao S, 2018, CNS NEUROSCI THER, V24, P1037, DOI 10.1111/cns.13048
   Gray JP, 2020, AM J PSYCHIAT, V177, P422, DOI 10.1176/appi.ajp.2019.19050560
   Gui T, 2019, AAAI CONF ARTIF INTE, P110
   Islam MR, 2018, HEALTH INF SCI SYST, V6, DOI 10.1007/s13755-018-0046-0
   Kwon I, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212627
   Lalousis PA, 2021, SCHIZOPHRENIA BULL, V47, P1130, DOI 10.1093/schbul/sbaa185
   Le Quoc V., 2014, P INT C MACH LEARN I
   Li M, 2020, METHOD DEPRESSION CL
   Liu XD, 2021, PSYCHIAT RES-NEUROIM, V308, DOI 10.1016/j.pscychresns.2020.111239
   Malhotra A., 2020, EAI ENDORSED T PERVA, V6, pe1
   Mann P., 2020, P INT AAAI C WEB SOC, V14, P440
   Meng YW, 2021, IEEE J BIOMED HEALTH, V25, P3121, DOI 10.1109/JBHI.2021.3063721
   Morales M., 2018, P 5 WORKSH COMP LING, P13, DOI DOI 10.18653/V1/W18-0602
   Morales M. R., 2018, Multimodal depression detection: An investigation of features and fusion techniques for automated systems
   Nikolin S, 2021, J AFFECT DISORDERS, V284, P1, DOI 10.1016/j.jad.2021.01.084
   Pinto G, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123510
   Qureshi SA, 2019, IEEE INTELL SYST, V34, P45, DOI 10.1109/MIS.2019.2925204
   Rohanian M, 2019, INTERSPEECH, P1443, DOI 10.21437/Interspeech.2019-2283
   Rutowski T, 2019, INTERSPEECH, P3023, DOI 10.21437/Interspeech.2019-3095
   Shalu H, 2020, ARXIV
   Sharma S, 2022, IETE J RES, V68, P3798, DOI 10.1080/03772063.2020.1780164
   Sharma S, 2019, ADV INTELL SYST COMP, V748, P423, DOI 10.1007/978-981-13-0923-6_37
   Sharma S, 2017, 2017 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT)
   Sharma S, 2017, LECT NOTES COMPUT SC, V10597, P373, DOI 10.1007/978-3-319-69900-4_47
   Shi YC, 2021, EBIOMEDICINE, V66, DOI 10.1016/j.ebiom.2021.103337
   Shrestha A, 2020, NETW MODEL ANAL HLTH, V9, DOI 10.1007/s13721-020-0226-0
   Singh H, 2017, 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATION TECHNOLOGY (ICCCT - 2017), P29, DOI 10.1145/3154979.3154996
   Solieman H, 2021, IEEE NW RUSS YOUNG, P1843, DOI 10.1109/ElConRus51938.2021.9396540
   Vidal-Ribas P, 2021, AM J PSYCHIAT, V178, P321, DOI 10.1176/appi.ajp.2020.20020120
   Vijayvergia A, 2021, MULTIMED TOOLS APPL, V80, P28349, DOI 10.1007/s11042-021-10997-8
   Vijayvergia A, 2018, 2018 CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY (CICT'18)
   Villatoro-Tello Esau, 2021, ICMI '21: Proceedings of the 2021 International Conference on Multimodal Interaction, P557, DOI 10.1145/3462244.3479896
   Yang L, 2021, IEEE T AFFECT COMPUT, V12, P239, DOI 10.1109/TAFFC.2018.2870398
   Yazdavar AH, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0226248
   Zhang XW, 2019, IEEE J BIOMED HEALTH, V23, P2265, DOI 10.1109/JBHI.2019.2938247
   Zheng WY, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9348207
   Zhou XZ, 2019, ELECTRON LETT, V55, P648, DOI 10.1049/el.2019.0443
NR 52
TC 2
Z9 2
U1 2
U2 18
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 17
BP 25973
EP 26004
DI 10.1007/s11042-023-14351-y
EA JAN 2023
PG 32
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K8ET4
UT WOS:000920232800001
DA 2024-07-18
ER

PT J
AU Zhang, SQ
   Guo, XY
   Xu, XH
   Li, L
AF Zhang, Shanqing
   Guo, Xiaoyun
   Xu, Xianghua
   Li, Li
TI A video watermark algorithm based on tensor feature map
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Video watermark; High-order singular value decomposition; Tensor feature
   map; Feature tensor
AB Video has become one of the main ways of information transmission with the development of the Internet. Video copyright protection becomes an urgent task. Video watermark technology embeds copyright into the redundant information of the carrier, and video copyright protection is achieved. However, most video watermark algorithms do not use the correlation and redundancy among adjacent frames of a video and are weak to resist frame attacks. In order to make up this shortage and improve robustness, a video watermark algorithm based on a tensor feature map is proposed. A grayscale video segment with the same scene is selected and represented as a 3-order tensor, a high-order singular value decomposition is performed on the video tensor to obtain a stable core tensor and three factor matrices. A feature tensor is obtained by the mode-3 product of the video tensor with the transpose of the factor matrix that contains a time axis. It is called a tensor feature map. Since the tensor feature map contains the main information of each frame of a video, the watermark is distributed in each frame of a video by embedding the watermark into the tensor feature map. The first-order discrete wavelet transform and discrete cosine transform are used to embed the watermark into the tensor feature map. The experimental results show that the proposed watermark algorithm based on the tensor feature map has better transparency and is robust to common video attacks.
C1 [Zhang, Shanqing; Guo, Xiaoyun; Xu, Xianghua; Li, Li] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University
RP Xu, XH (corresponding author), Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Peoples R China.
EM xhxu@hdu.edu.cn
FU Key Research and Development Project of Zhejiang Province; Public
   Welfare Technology and Industry Project of Zhejiang Provincial Science
   Technology Department;  [2020C01067];  [LGG18F020013];  [LGG19F020016]
FX AcknowledgmentsThis work was supported by the Key Research and
   Development Project of Zhejiang Province, under Grant 2020C01067, Public
   Welfare Technology and Industry Project of Zhejiang Provincial Science
   Technology Department under Grant LGG18F020013, LGG19F020016.
CR Akhter R, 2010, PROC SPIE, V7524, DOI 10.1117/12.838775
   Bahrami Z, 2018, MULTIMED TOOLS APPL, V77, P327, DOI 10.1007/s11042-016-4226-0
   Belmkaddem K, 2015, IET MICROW ANTENNA P, V9, P1407, DOI 10.1049/iet-map.2014.0274
   Bhardwaj A, 2018, MULTIMED TOOLS APPL, V77, P19659, DOI 10.1007/s11042-017-5340-3
   Chandra DVS, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P264
   Cox IJ, 2005, DIGITAL WATERMARKING
   Fu YF, 2019, SIGNAL PROCESS, V161, P74, DOI 10.1016/j.sigpro.2019.03.015
   Gao SS, 2019, IEEE ACCESS, V7, P13781, DOI 10.1109/ACCESS.2018.2888499
   Hemalatha P, 2018, DISCRET MATH ALGORIT, V10, DOI 10.1142/S1793830918500556
   Hsieh CY, 2017, MULTIMED TOOLS APPL, V76, P7575, DOI 10.1007/s11042-016-3407-1
   Jia SL, 2014, OPTIK, V125, P2868, DOI 10.1016/j.ijleo.2014.01.002
   Juergen S, 2005, DIGITAL WATERMARKING, P2
   Koivisto PK, 2005, AEU-INT J ELECTRON C, V59, P379, DOI 10.1016/j.aeue.2004.11.031
   Kong WW, 2014, INFRARED PHYS TECHN, V63, P110, DOI 10.1016/j.infrared.2013.12.016
   Liu YY, 2013, IEEE SIGNAL PROC LET, V20, P307, DOI 10.1109/LSP.2013.2245416
   Makbol NM, 2013, AEU-INT J ELECTRON C, V67, P102, DOI 10.1016/j.aeue.2012.06.008
   Mobasseri B. G., 2000, Proceedings International Conference on Information Technology: Coding and Computing (Cat. No.PR00540), P68, DOI 10.1109/ITCC.2000.844185
   Nouioua I, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/6712065
   Shi QQ, 2019, IEEE T NEUR NET LEAR, V30, P1803, DOI 10.1109/TNNLS.2018.2873655
   Sun W., 2018, 2018 IEEE International Conference on Communications (ICC), P1, DOI 10.1109/MMSP.2018.8547102
   Wang LY, 2012, IEEE MULTIMEDIA, V19, P70, DOI 10.1109/MMUL.2011.76
   Xu H.C., 2018, IEEE ACCESS, V99, P1
   Zhang FY, 2019, MULTIMED TOOLS APPL, V78, P20133, DOI 10.1007/s11042-019-7326-9
   Zhang SQ, 2019, MATH BIOSCI ENG, V16, P3435, DOI 10.3934/mbe.2019172
NR 24
TC 0
Z9 0
U1 0
U2 5
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 13
BP 19557
EP 19575
DI 10.1007/s11042-022-14299-5
EA JAN 2023
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA R2DZ7
UT WOS:000908646900001
DA 2024-07-18
ER

PT J
AU Sun, JP
   Li, D
AF Sun, Jinping
   Li, Dan
TI Object Tracking with Channel Group Regularization and Smooth Constraints
   Using Improved Dynamic Convolution Kernels in ITS
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article; Early Access
DE Correlation filter; Dynamic convolution kernel; Time series smoothing;
   Sparse representation; Object tracking
ID ALGORITHM
AB Aiming at the problem that the correlation between multi-channel feature representation and filter structure is not considered in the objective function modeling, a object tracking algorithm with channel group regularization and time series smooth constraint using improved dynamic convolution kernels is proposed. Firstly, the elements in the filter are grouped using spatial and channel properties, the time-domain correlation of the object model is constrained by the low-rank kernel norm. A group regularization term is constructed to describe the correlation between channels with a mixed-norm structured sparsity constraint to learn lower-dimensional filters. Then, after extracting some channels in the feature map, part of the spatial information of each channel is retained to generate an efficient dynamic convolution kernel through the channel information de-redundant attention mechanism to obtain an optimized lightweight convolutional neural network. Finally, combining the advantages of hand-crafted features and deep convolutional features, the complementary localization of the object from coarse to fine is realized with the help of the constructed efficient feature model and the learned filter. The experimental results on public datasets show that the proposed algorithm can adapt to the tracking tasks of various complex traffic scenes, and enhance the tracking performance of the existing models. The proposed algorithm improves the discriminative property of the object model and the self-adaptability of the spatio-temporal information of the dynamic convolution kernel, and can be applied to neuromorphic vision system of intelligent transportation systems.
C1 [Sun, Jinping; Li, Dan] Xuzhou Univ Technol, Sch Informat Engn, Sch Big Data, Xuzhou 221018, Peoples R China.
C3 Xuzhou University of Technology
RP Sun, JP (corresponding author), Xuzhou Univ Technol, Sch Informat Engn, Sch Big Data, Xuzhou 221018, Peoples R China.
EM sjp@xzit.edu.cn
RI SUN, JIN/GPX-9641-2022
FU Basic Science Major Foundation (Natural Science) of the Jiangsu Higher
   Education Institutions of China [22KJA520012]; Xuzhou Science and
   Technology Plan Project [KC21303]; sixth "333 project" of Jiangsu
   Province
FX The authors acknowledge the Basic Science Major Foundation (Natural
   Science) of the Jiangsu Higher Education Institutions of China (Grant:
   22KJA520012), the Xuzhou Science and Technology Plan Project(Grant:
   KC21303) and the sixth "333 project" of Jiangsu Province.Data sharing
   agreementThe datasets used and/or analyzed during the current study are
   available from the corresponding author on reasonable request.
CR Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   [陈昭炯 Chen Zhaojiong], 2021, [自动化学报, Acta Automatica Sinica], V47, P630
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Galoogahi HK, 2017, IEEE INT C COMPUTER, P1369
   Gray RM, 2006, FOUND TRENDS COMMUN, V2, DOI 10.1561/0100000006
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2013, IEEE I CONF COMP VIS, P2760, DOI 10.1109/ICCV.2013.343
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Kong Jun, 2018, Journal of Computer Aided Design & Computer Graphics, V30, P634, DOI 10.3724/SP.J.1089.2018.16443
   Li D, 2022, J ENVIRON PUBLIC HEA, V2022, DOI 10.1155/2022/3887426
   Li D, 2021, WIREL NETW, V27, P4389, DOI 10.1007/s11276-021-02664-5
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   [孟琭 Meng Lu], 2019, [自动化学报, Acta Automatica Sinica], V45, P1244
   Qiu Lida, 2017, Journal of Computer Aided Design & Computer Graphics, V29, P459
   Russakovsky O., 2015, Int. J. Comput. Vis., V115, P211, DOI DOI 10.1007/S11263-015-0816-Y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun JP, 2020, IEEE ACCESS, V8, P208179, DOI 10.1109/ACCESS.2020.3038792
   Sun JP, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6690237
   Sun JP, 2020, DYNA-BILBAO, V95, P646, DOI 10.6036/9844
   [田丹 Tian Dan], 2019, [控制与决策, Control and Decision], V34, P2479
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu TY, 2019, RES CORRELATION FILT
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Yuan D, 2020, KNOWL-BASED SYST, V194, DOI 10.1016/j.knosys.2020.105526
NR 35
TC 0
Z9 0
U1 0
U2 9
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD 2022 DEC 19
PY 2022
DI 10.1007/s11042-022-14294-w
EA DEC 2022
PG 25
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 7D0JY
UT WOS:000900189300001
DA 2024-07-18
ER

PT J
AU Mollaei, H
   Sepehri, MM
   Khatibi, T
AF Mollaei, Hamed
   Sepehri, Mohammad Mehdi
   Khatibi, Toktam
TI Patient's actions recognition in hospital's recovery department based on
   RGB-D dataset
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Action recognition; Recovery room; Hospital; Geometric and
   spatiotemporal features; Hidden Markov Model
ID POSTANESTHESIA CARE-UNIT; FALL DETECTION; SENSOR
AB A recovery room is a necessary unit of hospital nursing that should be continued in the operating room. The goal of recovery is to provide high-quality care for patients undergoing post-surgical recovery, in contrast to the effects of anesthetic drugs, such as sudden movements of the hands and legs, standing, or falling from the bed that may occur instantaneously. Due to the shortage of nurses in the recovery room that these units face, the need to use remote monitoring systems for patients is increasing to somehow compensate for the lack of service personnel and that assist staff in better monitoring of patients. In this study, using a combination of geometric features and depth data, a patient's actions are recognized. Then, the actions that are at risk for patients in the recovery room will be identified and notified to the nursing unit before its occurrence to take necessary measures. For this purpose, RGB-D data is collected and analyzed. The proposed methodology steps in this study generally include recording video images using Kinect sensors (457 videos with 640 x 480 resolution), extracting features from video frames (color separation-based approach), training the Hidden Markov Model to classify the indicator vectors, and finally evaluation and validation of the model. Experimental results indicate that the proposed identification method can accurately detect moments that the patient is exposed to danger due to their changes in the hospital bed. The recognition rate for this approach is 91.36%.
C1 [Mollaei, Hamed; Sepehri, Mohammad Mehdi; Khatibi, Toktam] Tarbiat Modares Univ, Fac Ind & Syst Engn, Tehran 1411713116, Iran.
C3 Tarbiat Modares University
RP Sepehri, MM (corresponding author), Tarbiat Modares Univ, Fac Ind & Syst Engn, Tehran 1411713116, Iran.
EM mehdi.sepehri@modares.ac.ir
RI Sepehri, Mohammad Mehdi/A-3030-2011
OI Sepehri, Mohammad Mehdi/0000-0002-9920-7452
CR Adamina M, 2013, BRIT J SURG, V100, P38, DOI 10.1002/bjs.8990
   Ahad MAR, IOT SENSOR BASED ACT, P63
   Alazrai R, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7040316
   Arivazhagan S, 2019, COGN SYST RES, V58, P94, DOI [10.1016/j.cogsys.2019.05.002, 10.1016/j.cogsys.2019.15.002]
   Barone Claudia P, 2003, J Perianesth Nurs, V18, P237, DOI 10.1016/S1089-9472(03)00130-8
   Bellini V, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1512-1
   Berchtold M, 2010, LECT NOTES ARTIF INT, V6359, P400, DOI 10.1007/978-3-642-16111-7_46
   Childers CP, 2018, JAMA SURG, V153, DOI 10.1001/jamasurg.2017.6233
   Davidson M, 2018, ANAEST INTENS CARE M, V19, P457, DOI 10.1016/j.mpaic.2018.06.002
   Ding IJ, 2016, MULTIMED TOOLS APPL, V75, P15537, DOI 10.1007/s11042-015-2505-9
   Diraco G, 2010, DES AUT TEST EUROPE, P1536
   Dutta T, 2012, APPL ERGON, V43, P645, DOI 10.1016/j.apergo.2011.09.011
   Fairley M, 2019, HEALTH CARE MANAG SC, V22, P756, DOI 10.1007/s10729-018-9457-3
   Garcia-Agundez A, 2019, J NEUROENG REHABIL, V16, DOI 10.1186/s12984-019-0492-1
   Han J., 2006, DATA MINING CONCEPTS
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hochhausen N, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051618
   Hong P., 2000, Automatic Face and Gesture Recognition, P410
   Imran J, 2020, J AMB INTEL HUM COMP, V11, P189, DOI 10.1007/s12652-019-01239-9
   Inoue M, 2020, IEEE ENG MED BIO, P4390, DOI 10.1109/EMBC44109.2020.9175619
   Ji XP, 2018, SIGNAL PROCESS, V143, P56, DOI 10.1016/j.sigpro.2017.08.016
   Karabulut N, 2016, J PERIANESTH NURS, V31, P397, DOI 10.1016/j.jopan.2014.10.006
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Khoshelham K, 2012, SENSORS-BASEL, V12, P1437, DOI 10.3390/s120201437
   Li G, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115814
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li Wen-Jeng., 2017, 2017 INT C APPL SYST, P386, DOI [DOI 10.1109/ICASI.2017.7988433, 10.1109/ICASI.2017.7988433]
   Li Y, 2014, IEEE ENG MED BIO, P5900, DOI 10.1109/EMBC.2014.6944971
   Liu BL, 2019, PATTERN RECOGN, V94, P1, DOI 10.1016/j.patcog.2019.05.020
   Liu X, 2019, IEEE NETWORK, V33, P126, DOI 10.1109/MNET.2019.1800014
   Luckowski Amy, 2019, Nursing, V49, P62, DOI 10.1097/01.NURSE.0000554246.74635.e0
   Ludbrook G, 2021, ANAESTHESIA, V76, P480, DOI 10.1111/anae.15260
   Lun R, 2015, INT J PATTERN RECOGN, V29, DOI 10.1142/S0218001415550083
   Malasinghe LP, 2019, J AMB INTEL HUM COMP, V10, P57, DOI 10.1007/s12652-017-0598-x
   Nguyen H.D., 2020, RELIABILITY STAT COM, P207
   Ong APR, 2017, AIP CONF PROC, V1817, DOI 10.1063/1.4976789
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Overhage JM, 2020, ANN INTERN MED, V172, P169, DOI 10.7326/M18-3684
   Pachoulakis I, 2018, INT J COMPUT GAMES T, V2018, DOI 10.1155/2018/2618271
   Patsadu O., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P28, DOI 10.1109/JCSSE.2012.6261920
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Rahmani H, 2014, LECT NOTES COMPUT SC, V8690, P742, DOI 10.1007/978-3-319-10605-2_48
   Rougier C, 2011, LECT NOTES COMPUT SC, V6719, P121, DOI 10.1007/978-3-642-21535-3_16
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Schuster-Bockler Benjamin, 2007, Curr Protoc Bioinformatics, VAppendix 3, p3A, DOI 10.1002/0471250953.bia03as18
   Sepehri MM, 2014, 11 INT IND ENG C, P141
   Silverstein E, 2017, MED PHYS, V44, P2391, DOI 10.1002/mp.12241
   Stoyanov T., 2011, P EUROPEAN C MOBILE, P19
   Surasak T, 2018, PROCEEDINGS OF 2018 5TH INTERNATIONAL CONFERENCE ON BUSINESS AND INDUSTRIAL RESEARCH (ICBIR), P172, DOI 10.1109/ICBIR.2018.8391187
   Trascau M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020423
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao WB, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P762, DOI 10.1109/ICSESS.2014.6933678
NR 60
TC 0
Z9 0
U1 1
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD JUL
PY 2023
VL 82
IS 16
BP 24127
EP 24154
DI 10.1007/s11042-022-14200-4
EA DEC 2022
PG 28
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA K7VV6
UT WOS:000896363400002
DA 2024-07-18
ER

PT J
AU Ibrahim, B
   Abusham, E
   Zia, K
AF Ibrahim, Basil
   Abusham, Eimad
   Zia, Kashif
TI Digital image scrambling based on outer totalistic cellular automaton
   and gray code pixels substitution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Cellular automata; Image encryption; Image scrambling; Game of life;
   Gray code
ID ENCRYPTION; ALGORITHM; SCHEME; COMPRESSION; TRANSFORM
AB A digital image is scrambled by rearranging the pixels of an image, so that the original information contents are indistinguishable visually and relationships between initially adjacent pixels are disturbed. Cellular Automata (CA) are dynamic and discrete systems capable of generating complex behaviors based on simple rules. This characteristic makes CA an ideal candidate for developing effective image scrambling techniques. In spite of evidence that CA techniques have demonstrated effectiveness in image scrambling related literature, an original image content can still be identified from a database of scrambled images by contrasting the histograms of the suspected images and the scrambled images' histogram. This problem is addressed in the paper by replacing pixel intensities with their Gray Code equivalent values as part of resolving pixels. The Gray Code pixel substitution provides robustness of the proposed scrambling method as seen in the results. With regard to the scrambling technique itself, an image is scrambled using a 2D lattice created using different generations of lattices derived from the same randomly generated lattice by Conway's Game of Life (CGL) Outer Totalistic Cellular Automaton (OTCA) rule. Using the proposed method, the key space required to decrypt images by brute force is increased by u (2(size(original lattice))), where u is the number of generations of unique pairs. Comparing this method with other image scrambling techniques, it shows superior results with higher Gray Difference Degree (GDD) for the same image experimentation samples.
C1 [Ibrahim, Basil; Abusham, Eimad] Sohar Univ, Fac Comp & Informat Technol, Al Jamia St, Sohar 311, Oman.
   [Zia, Kashif] Univ Glasgow, Glasgow, Scotland.
C3 Sohar University; University of Glasgow
RP Abusham, E (corresponding author), Sohar Univ, Fac Comp & Informat Technol, Al Jamia St, Sohar 311, Oman.
EM basilshakkakl@gmail.com; eabusham@su.edu.om; kashif.zia@glasgow.ac.uk
RI Abusham, Eiamd/HLH-5090-2023
OI Abusham, Eimad/0000-0002-4895-2057
CR Abu Dalhoum AL, 2016, MULTIMED TOOLS APPL, V75, P17019, DOI 10.1007/s11042-015-2972-z
   Back T., 2012, Handbook of Natural Computing, DOI 10.1007/978-3-540-92910-9_22
   Chabrier, 1996, LECT NOTES COMPUT SC
   Chen JX, 2021, IEEE T CIRC SYST VID, V31, P2494, DOI 10.1109/TCSVT.2020.3021908
   Chen TG, 2016, OPT LASER TECHNOL, V84, P118, DOI 10.1016/j.optlastec.2016.05.012
   Dalhoum A. L. A., 2012, IEEE Multimedia, V19, P28, DOI 10.1109/MMUL.2011.54
   Dong YH, 2022, INFORM SCIENCES, V593, P121, DOI 10.1016/j.ins.2022.01.031
   Doran R.W., 2007, Tech. Rep
   Dursun G, 2017, TURK J ELECTR ENG CO, V25, P3515, DOI 10.3906/elk-1610-225
   Enayatifar R, 2014, OPT LASER ENG, V56, P83, DOI 10.1016/j.optlaseng.2013.12.003
   Forouzan B.A., 2011, Cryptography and Network Security (Sie)
   Furht B., 2004, MULTIMEDIA SECURITY
   GARDNER M, 1970, SCI AM, V223, P120, DOI 10.1038/scientificamerican1070-120
   Gu GS, 2014, OPTIK, V125, P4700, DOI 10.1016/j.ijleo.2014.05.023
   Guleria V, 2020, J INF SECUR APPL, V54, DOI 10.1016/j.jisa.2020.102524
   Hakeem SAA, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051969
   Irani BY, 2019, NONLINEAR DYNAM, V97, P2693, DOI 10.1007/s11071-019-05157-5
   Jeelani Zubair, 2020, International Journal of Computer Vision and Image Processing, V10, P29, DOI 10.4018/IJCVIP.2020100102
   Jeelani Z, 2021, EVOL SYST-GER, V12, P359, DOI 10.1007/s12530-020-09326-5
   Jeelani Z, 2018, INT J INTELL COMPUT, V11, P353, DOI 10.1108/IJICC-10-2017-0132
   Joshi AB, 2020, OPT LASER ENG, V133, DOI 10.1016/j.optlaseng.2020.106139
   Kaur M, 2020, ARCH COMPUT METHOD E, V27, P15, DOI 10.1007/s11831-018-9298-8
   Khalil N, 2021, OPT LASER TECHNOL, V143, DOI 10.1016/j.optlastec.2021.107326
   Kumari M, 2017, 3D RES, V8, DOI 10.1007/s13319-017-0148-5
   Liao X, 2017, MULTIMED TOOLS APPL, V76, P20739, DOI 10.1007/s11042-016-3971-4
   Liao X, 2015, J VIS COMMUN IMAGE R, V28, P21, DOI 10.1016/j.jvcir.2014.12.007
   Maleki F, 2008, ARES 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON AVAILABILITY, SECURITY AND RELIABILITY, P1266, DOI 10.1109/ARES.2008.121
   Mondal B, 2019, J INF SECUR APPL, V45, P117, DOI 10.1016/j.jisa.2019.01.010
   Naskar PK, 2020, NONLINEAR DYNAM, V100, P2877, DOI 10.1007/s11071-020-05625-3
   Niyat AY, 2017, OPT LASER ENG, V90, P225, DOI [10.1016/j.optlaseng.2016.10:019, 10.1016/j.optlaseng.2016.10.019]
   PACKARD NH, 1985, J STAT PHYS, V38, P901, DOI 10.1007/BF01010423
   Pejas J, 2021, PROCEDIA COMPUT SCI, V192, P328, DOI 10.1016/j.procs.2021.08.034
   Peng YY, 2018, J INF SECUR APPL, V40, P236, DOI 10.1016/j.jisa.2018.04.007
   Ping P, 2015, 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP), P413, DOI 10.1109/IIH-MSP.2015.78
   Qadir Fasel, 2013, International Journal of Computer Network and Information Security, V5, P36, DOI 10.5815/ijcnis.2013.02.05
   Shelke R, 2016, 2016 INTERNATIONAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (ICONSIP)
   Shi XY, 2013, OPT COMMUN, V306, P90, DOI 10.1016/j.optcom.2013.05.041
   Stapko T, 2008, EMBED TECHNOL SER, P179, DOI 10.1016/B978-075068215-2.50011-2
   Sui LS, 2013, OPT LASER TECHNOL, V48, P530, DOI 10.1016/j.optlastec.2012.11.020
   Torbey S, 2009, PARALLEL PROCESS LET, V19, P73, DOI 10.1142/S0129626409000079
   Vaish A, 2017, OPTIK, V145, P273, DOI 10.1016/j.ijleo.2017.07.041
   Wang XY, 2022, CHAOS SOLITON FRACT, V155, DOI 10.1016/j.chaos.2021.111629
   Wang XY, 2021, CHAOS SOLITON FRACT, V150, DOI 10.1016/j.chaos.2021.111117
   Wang XY, 2021, OPT LASER TECHNOL, V138, DOI 10.1016/j.optlastec.2020.106837
   Wang XY, 2020, OPT LASER TECHNOL, V132, DOI 10.1016/j.optlastec.2020.106501
   Wang X, 2021, MULTIMED TOOLS APPL, V80, P29915, DOI 10.1007/s11042-021-11143-0
   Wolfram S., 1986, Theory and applications of cellular automata
   Wolfram S., 2002, A new kind of science
   Wu Z, 2022, COMPUT NETW, V204, DOI 10.1016/j.comnet.2021.108716
   Ye RS, 2008, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, P938, DOI 10.1109/ISECS.2008.138
   Zhang H, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2020.115829
   Zhang Q, 2014, AEU-INT J ELECTRON C, V68, P186, DOI 10.1016/j.aeue.2013.08.007
NR 52
TC 0
Z9 0
U1 0
U2 8
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAY
PY 2023
VL 82
IS 12
BP 18811
EP 18829
DI 10.1007/s11042-022-14184-1
EA DEC 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA E9MO1
UT WOS:000893056800007
DA 2024-07-18
ER

PT J
AU Shaik, A
   Masilamani, V
AF Shaik, Ayesha
   Masilamani, V
TI A robust multiplicative watermarking technique for digital images in
   curvelet domain using normal inverse Gaussian distribution
SO MULTIMEDIA TOOLS AND APPLICATIONS
LA English
DT Article
DE Watermarking; Curvelet; Normal inverse Gaussian distribution; Maximum
   likelihood estimation; Expectation-maximization algorithm
ID HIDDEN MARKOV MODEL; DETECTOR; ALGORITHM; DECODER; SCHEME
AB The illegal duplication of digital copies became easier because of increased communication speed and rapid growth of internetworked multimedia systems. So it is required to authenticate the legal owner of the digital data and protect the copyrights of the content owner. But the original image requirement during the verification of the owner becomes an overhead as it requires more storage. Instead of that, the watermark extraction without original data will be helpful which is also blind watermarking as the storage complexity is reduced. This article proposes a novel blind multiplicative watermarking (WM) system in the curvelet domain for copyright protection. The proper distribution of the curvelet coefficients has known by modeling the statistics of the curvelet coefficients of a digital image which is a heavy-tailed probability distribution function. It has shown that the normal inverse Gaussian (NIG) distribution suitably fits the empirical distribution. A secure watermark is used for watermarking, a combination of the pseudo-random sequence and the unique information of the owner in the proposed article. The design of the watermark extractor has been realized using NIG for the curvelet coefficients of digital images by using the above property. The watermark is decoded from NIG curvelet coefficients with expectation-maximization (EM) algorithm using maximum likelihood estimation (MLE). The watermark has been decoded using closed-form expressions in both the noise and noiseless environments. The experimental results on standard datasets (BOWS and SIPI) show that the proposed scheme provides approximately 20% improvement in PSNR and 50% reduction in bit error rate (BER) compared to the listed method in the article. The proposed technique shows high robustness against attacks such as cropping, rotation, median filtering, salt and pepper noise, Gaussian noise, average filtering, and gamma correction.
C1 [Shaik, Ayesha] Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamilnadu, India.
   [Masilamani, V] Indian Inst Informat Technol Design & Mfg, Comp Sci & Engn, Chennai 600127, Tamilnadu, India.
C3 Vellore Institute of Technology (VIT); VIT Chennai; Indian Institute of
   Information Technology, Design & Manufacturing, Kancheepuram
RP Shaik, A (corresponding author), Vellore Inst Technol, Sch Comp Sci & Engn, Chennai 600127, Tamilnadu, India.
EM ayesha.sk@vit.ac.in; masila@iiitdm.ac.in
OI shaik, ayeshanoormd/0000-0002-9804-8031
CR Akhaee MA, 2010, IEEE T IMAGE PROCESS, V19, P967, DOI 10.1109/TIP.2009.2038774
   Amini M, 2019, IEEE T MULTIMEDIA, V21, P65, DOI 10.1109/TMM.2018.2851447
   Amini M, 2018, IEEE T CIRC SYST VID, V28, P402, DOI 10.1109/TCSVT.2016.2607299
   Amini M, 2017, SIGNAL PROCESS, V137, P213, DOI 10.1016/j.sigpro.2017.01.019
   Amirmazlaghani M, 2015, EXPERT SYST APPL, V42, P1960, DOI 10.1016/j.eswa.2014.10.015
   [Anonymous], 2008, INT J COMPUT SCI NET
   [Anonymous], 2015, About us
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Beaty MG, 2004, J FOURIER ANAL APPL, V10, P179, DOI 10.1007/s00041-004-8010-6
   Bhuiyan MIH, 2010, DCT DOMAIN WATERMARK, P1
   Bian Y, 2013, IEEE T IMAGE PROCESS, V22, P2372, DOI 10.1109/TIP.2013.2246177
   Briassouli A, 2005, IEEE T MULTIMEDIA, V7, P700, DOI 10.1109/TMM.2005.850970
   Candès EJ, 2004, COMMUN PUR APPL MATH, V57, P219, DOI 10.1002/cpa.10116
   Cheng CJ, 2014, J DISP TECHNOL, V10, P263, DOI 10.1109/JDT.2013.2295619
   Cheng Q, 2003, IEEE T SIGNAL PROCES, V51, P906, DOI 10.1109/TSP.2003.809374
   Coatrieux G, 2013, IEEE T INF FOREN SEC, V8, P111, DOI 10.1109/TIFS.2012.2224108
   Deng CZ, 2009, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION ASSURANCE AND SECURITY, VOL 1, PROCEEDINGS, P313, DOI 10.1109/IAS.2009.21
   Doncel VR, 2007, IEEE T VIS COMPUT GR, V13, P851, DOI 10.1109/TVCG.2007.1050
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Garg P, 2022, MULTIMED TOOLS APPL, P1
   Hamghalam M, 2013, IET IMAGE PROCESS, V7, P451, DOI 10.1049/iet-ipr.2012.0693
   Hanssen A, 2001, INT CONF ACOUST SPEE, P3985, DOI 10.1109/ICASSP.2001.940717
   Karlis D, 2002, STAT PROBABIL LETT, V57, P43, DOI 10.1016/S0167-7152(02)00040-8
   Lam K-Y, 2012, INFORM COMMUNICATION
   Ma JW, 2010, IEEE SIGNAL PROC MAG, V27, P118, DOI 10.1109/MSP.2009.935453
   Mahto D.K., 2022, MULTIMED TOOLS APPL, P1
   Mairgiotis A, 2007, 2007 IEEE NINTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P353, DOI 10.1109/MMSP.2007.4412889
   Minh N, 2002, THESIS CITESEER
   Moad MS, 2022, MULTIMED TOOLS APPL, V81, P44087, DOI 10.1007/s11042-022-12004-0
   Ng TM, 2005, IEEE SIGNAL PROC LET, V12, P285, DOI 10.1109/LSP.2005.843776
   Niu P, 2021, NEW STAT IMAGE WATER
   Niu PP, 2021, CIRC SYST SIGNAL PR, V40, P4516, DOI 10.1007/s00034-021-01678-w
   Oigård TA, 2005, SIGNAL PROCESS, V85, P1655, DOI 10.1016/j.sigpro.2005.03.005
   Qi XJ, 2015, J VIS COMMUN IMAGE R, V30, P312, DOI 10.1016/j.jvcir.2015.05.006
   Rahimi F, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-53
   Rahman SMM, 2009, IEEE T IMAGE PROCESS, V18, P1782, DOI 10.1109/TIP.2009.2021313
   Sadreazami H, 2015, IEEE INT SYMP CIRC S, P1050, DOI 10.1109/ISCAS.2015.7168817
   Sadreazami H, 2014, IEEE INT SYMP CIRC S, P1288, DOI 10.1109/ISCAS.2014.6865378
   Sadreazami H, 2019, IEEE T CIRCUITS-II, V66, P151, DOI 10.1109/TCSII.2018.2846547
   Sadreazami H, 2016, IEEE T MULTIMEDIA, V18, P196, DOI 10.1109/TMM.2015.2508147
   Sadreazami H, 2014, IEEE T IMAGE PROCESS, V23, P4348, DOI 10.1109/TIP.2014.2339633
   Sadreazami H, 2012, AEU-INT J ELECTRON C, V66, P364, DOI 10.1016/j.aeue.2011.09.001
   Sharma S, 2023, MULTIMED TOOLS APPL, V82, P2207, DOI 10.1007/s11042-022-13207-1
   Shoukat MU, 2020, AIPR 2020: 2020 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND PATTERN RECOGNITION, P152, DOI 10.1145/3430199.3430237
   Yingying Wang, 2020, Journal of Physics: Conference Series, V1550, DOI 10.1088/1742-6596/1550/2/022009
   Zareian M, 2013, IET IMAGE PROCESS, V7, P432, DOI 10.1049/iet-ipr.2013.0048
   Zear A, 2022, MULTIMED TOOLS APPL, V81, P26721, DOI 10.1007/s11042-020-10472-w
   Zheng P, 2012, WALSH HADAMARD TRANS, P240
   Zhou Y, 2012, IET IMAGE PROCESS, V6, P1136, DOI 10.1049/iet-ipr.2012.0148
NR 49
TC 6
Z9 6
U1 0
U2 4
PU SPRINGER
PI DORDRECHT
PA VAN GODEWIJCKSTRAAT 30, 3311 GZ DORDRECHT, NETHERLANDS
SN 1380-7501
EI 1573-7721
J9 MULTIMED TOOLS APPL
JI Multimed. Tools Appl.
PD MAR
PY 2023
VL 82
IS 6
BP 9223
EP 9241
DI 10.1007/s11042-022-14137-8
EA NOV 2022
PG 19
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering
GA 9Q6LM
UT WOS:000889417600002
DA 2024-07-18
ER

EF